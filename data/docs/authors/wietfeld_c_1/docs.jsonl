{"id": "0705.0010", "contents": "Title: Critical phenomena in complex networks Abstract: The combination of the compactness of networks, featuring small diameters,\nand their complex architectures results in a variety of critical effects\ndramatically different from those in cooperative systems on lattices. In the\nlast few years, researchers have made important steps toward understanding the\nqualitatively new critical phenomena in complex networks. We review the\nresults, concepts, and methods of this rapidly developing field. Here we mostly\nconsider two closely related classes of these critical phenomena, namely\nstructural phase transitions in the network architectures and transitions in\ncooperative models on networks as substrates. We also discuss systems where a\nnetwork and interacting agents on it influence each other. We overview a wide\nrange of critical phenomena in equilibrium and growing networks including the\nbirth of the giant connected component, percolation, k-core percolation,\nphenomena near epidemic thresholds, condensation transitions, critical\nphenomena in spin models placed on networks, synchronization, and\nself-organized criticality effects in interacting systems on networks. We also\ndiscuss strong finite size effects in these systems and highlight open problems\nand perspectives. \n\n"}
{"id": "0705.1939", "contents": "Title: Towards Informative Statistical Flow Inversion Abstract: A problem which has recently attracted research attention is that of\nestimating the distribution of flow sizes in internet traffic. On high traffic\nlinks it is sometimes impossible to record every packet. Researchers have\napproached the problem of estimating flow lengths from sampled packet data in\ntwo separate ways. Firstly, different sampling methodologies can be tried to\nmore accurately measure the desired system parameters. One such method is the\nsample-and-hold method where, if a packet is sampled, all subsequent packets in\nthat flow are sampled. Secondly, statistical methods can be used to ``invert''\nthe sampled data and produce an estimate of flow lengths from a sample.\n  In this paper we propose, implement and test two variants on the\nsample-and-hold method. In addition we show how the sample-and-hold method can\nbe inverted to get an estimation of the genuine distribution of flow sizes.\nExperiments are carried out on real network traces to compare standard packet\nsampling with three variants of sample-and-hold. The methods are compared for\ntheir ability to reconstruct the genuine distribution of flow sizes in the\ntraffic. \n\n"}
{"id": "0706.2520", "contents": "Title: Analysis of Inter-Domain Traffic Correlations: Random Matrix Theory\n  Approach Abstract: The traffic behavior of University of Louisville network with the\ninterconnected backbone routers and the number of Virtual Local Area Network\n(VLAN) subnets is investigated using the Random Matrix Theory (RMT) approach.\nWe employ the system of equal interval time series of traffic counts at all\nrouter to router and router to subnet connections as a representation of the\ninter-VLAN traffic. The cross-correlation matrix C of the traffic rate changes\nbetween different traffic time series is calculated and tested against\nnull-hypothesis of random interactions.\n  The majority of the eigenvalues \\lambda_{i} of matrix C fall within the\nbounds predicted by the RMT for the eigenvalues of random correlation matrices.\nThe distribution of eigenvalues and eigenvectors outside of the RMT bounds\ndisplays prominent and systematic deviations from the RMT predictions.\nMoreover, these deviations are stable in time.\n  The method we use provides a unique possibility to accomplish three\nconcurrent tasks of traffic analysis. The method verifies the uncongested state\nof the network, by establishing the profile of random interactions. It\nrecognizes the system-specific large-scale interactions, by establishing the\nprofile of stable in time non-random interactions. Finally, by looking into the\neigenstatistics we are able to detect and allocate anomalies of network traffic\ninteractions. \n\n"}
{"id": "0707.0808", "contents": "Title: The Cyborg Astrobiologist: Porting from a wearable computer to the\n  Astrobiology Phone-cam Abstract: We have used a simple camera phone to significantly improve an `exploration\nsystem' for astrobiology and geology. This camera phone will make it much\neasier to develop and test computer-vision algorithms for future planetary\nexploration. We envision that the `Astrobiology Phone-cam' exploration system\ncan be fruitfully used in other problem domains as well. \n\n"}
{"id": "0708.0522", "contents": "Title: Quasi-stationary distributions as centrality measures of reducible\n  graphs Abstract: Random walk can be used as a centrality measure of a directed graph. However,\nif the graph is reducible the random walk will be absorbed in some subset of\nnodes and will never visit the rest of the graph. In Google PageRank the\nproblem was solved by introduction of uniform random jumps with some\nprobability. Up to the present, there is no clear criterion for the choice this\nparameter. We propose to use parameter-free centrality measure which is based\non the notion of quasi-stationary distribution. Specifically we suggest four\nquasi-stationary based centrality measures, analyze them and conclude that they\nproduce approximately the same ranking. The new centrality measures can be\napplied in spam detection to detect ``link farms'' and in image search to find\nphoto albums. \n\n"}
{"id": "0708.0660", "contents": "Title: Network synchronizability analysis: the theory of subgraphs and\n  complementary graphs Abstract: In this paper, subgraphs and complementary graphs are used to analyze the\nnetwork synchronizability. Some sharp and attainable bounds are provided for\nthe eigenratio of the network structural matrix, which characterizes the\nnetwork synchronizability, especially when the network's corresponding graph\nhas cycles, chains, bipartite graphs or product graphs as its subgraphs. \n\n"}
{"id": "0709.3094", "contents": "Title: Transition from small to large world in growing networks Abstract: We examine the global organization of growing networks in which a new vertex\nis attached to already existing ones with a probability depending on their age.\nWe find that the network is infinite- or finite-dimensional depending on\nwhether the attachment probability decays slower or faster than $(age)^{-1}$.\nThe network becomes one-dimensional when the attachment probability decays\nfaster than $(age)^{-2}$. We describe structural characteristics of these\nphases and transitions between them. \n\n"}
{"id": "0710.2736", "contents": "Title: L2 norm performance index of synchronization and optimal control\n  synthesis of complex networks Abstract: In this paper, the synchronizability problem of dynamical networks is\naddressed, where better synchronizability means that the network synchronizes\nfaster with lower-overshoot. The L2 norm of the error vector e is taken as a\nperformance index to measure this kind of synchronizability. For the\nequilibrium synchronization case, it is shown that there is a close\nrelationship between the L2 norm of the error vector e and the H2 norm of the\ntransfer function G of the linearized network about the equilibrium point.\nConsequently, the effect of the network coupling topology on the H2 norm of the\ntransfer function G is analyzed. Finally, an optimal controller is designed,\naccording to the so-called LQR problem in modern control theory, which can\ndrive the whole network to its equilibrium point and meanwhile minimize the L2\nnorm of the output of the linearized network. \n\n"}
{"id": "0802.2587", "contents": "Title: Order-Optimal Consensus through Randomized Path Averaging Abstract: Gossip algorithms have recently received significant attention, mainly\nbecause they constitute simple and robust message-passing schemes for\ndistributed information processing over networks. However for many topologies\nthat are realistic for wireless ad-hoc and sensor networks (like grids and\nrandom geometric graphs), the standard nearest-neighbor gossip converges as\nslowly as flooding ($O(n^2)$ messages).\n  A recently proposed algorithm called geographic gossip improves gossip\nefficiency by a $\\sqrt{n}$ factor, by exploiting geographic information to\nenable multi-hop long distance communications. In this paper we prove that a\nvariation of geographic gossip that averages along routed paths, improves\nefficiency by an additional $\\sqrt{n}$ factor and is order optimal ($O(n)$\nmessages) for grids and random geometric graphs.\n  We develop a general technique (travel agency method) based on Markov chain\nmixing time inequalities, which can give bounds on the performance of\nrandomized message-passing algorithms operating over various graph topologies. \n\n"}
{"id": "0803.1908", "contents": "Title: On the Throughput Allocation for Proportional Fairness in Multirate IEEE\n  802.11 DCF under General Load Conditions Abstract: This paper presents a modified proportional fairness (PF) criterion suitable\nfor mitigating the \\textit{rate anomaly} problem of multirate IEEE 802.11\nWireless LANs employing the mandatory Distributed Coordination Function (DCF)\noption. Compared to the widely adopted assumption of saturated network, the\nproposed criterion can be applied to general networks whereby the contending\nstations are characterized by specific packet arrival rates, $\\lambda_s$, and\ntransmission rates $R_d^{s}$.\n  The throughput allocation resulting from the proposed algorithm is able to\ngreatly increase the aggregate throughput of the DCF while ensuring fairness\nlevels among the stations of the same order of the ones available with the\nclassical PF criterion. Put simply, each station is allocated a throughput that\ndepends on a suitable normalization of its packet rate, which, to some extent,\nmeasures the frequency by which the station tries to gain access to the\nchannel. Simulation results are presented for some sample scenarios, confirming\nthe effectiveness of the proposed criterion. \n\n"}
{"id": "0804.3784", "contents": "Title: On the metric distortion of nearest-neighbour graphs on random point\n  sets Abstract: We study the graph constructed on a Poisson point process in $d$ dimensions\nby connecting each point to the $k$ points nearest to it. This graph a.s. has\nan infinite cluster if $k > k_c(d)$ where $k_c(d)$, known as the critical\nvalue, depends only on the dimension $d$. This paper presents an improved upper\nbound of 188 on the value of $k_c(2)$. We also show that if $k \\geq 188$ the\ninfinite cluster of $\\NN(2,k)$ has an infinite subset of points with the\nproperty that the distance along the edges of the graphs between these points\nis at most a constant multiplicative factor larger than their Euclidean\ndistance. Finally we discuss in detail the relevance of our results to the\nstudy of multi-hop wireless sensor networks. \n\n"}
{"id": "0805.1981", "contents": "Title: P&P protocol: local coordination of mobile sensors for self-deployment Abstract: The use of mobile sensors is of great relevance for a number of strategic\napplications devoted to monitoring critical areas where sensors can not be\ndeployed manually. In these networks, each sensor adapts its position on the\nbasis of a local evaluation of the coverage efficiency, thus permitting an\nautonomous deployment.\n  Several algorithms have been proposed to deploy mobile sensors over the area\nof interest. The applicability of these approaches largely depends on a proper\nformalization of rigorous rules to coordinate sensor movements, solve local\nconflicts and manage possible failures of communications and devices.\n  In this paper we introduce P&P, a communication protocol that permits a\ncorrect and efficient coordination of sensor movements in agreement with the\nPUSH&PULL algorithm. We deeply investigate and solve the problems that may\noccur when coordinating asynchronous local decisions in the presence of an\nunreliable transmission medium and possibly faulty devices such as in the\ntypical working scenario of mobile sensor networks.\n  Simulation results show the performance of our protocol under a range of\noperative settings, including conflict situations, irregularly shaped target\nareas, and node failures. \n\n"}
{"id": "0807.3374", "contents": "Title: The Dynamics of Internet Traffic: Self-Similarity, Self-Organization,\n  and Complex Phenomena Abstract: The Internet is the most complex system ever created in human history.\nTherefore, its dynamics and traffic unsurprisingly take on a rich variety of\ncomplex dynamics, self-organization, and other phenomena that have been\nresearched for years. This paper is a review of the complex dynamics of\nInternet traffic. Departing from normal treatises, we will take a view from\nboth the network engineering and physics perspectives showing the strengths and\nweaknesses as well as insights of both. In addition, many less covered\nphenomena such as traffic oscillations, large-scale effects of worm traffic,\nand comparisons of the Internet and biological models will be covered. \n\n"}
{"id": "0809.0686", "contents": "Title: Energy Scaling Laws for Distributed Inference in Random Fusion Networks Abstract: The energy scaling laws of multihop data fusion networks for distributed\ninference are considered. The fusion network consists of randomly located\nsensors distributed i.i.d. according to a general spatial distribution in an\nexpanding region. Among the class of data fusion schemes that enable optimal\ninference at the fusion center for Markov random field (MRF) hypotheses, the\nscheme with minimum average energy consumption is bounded below by average\nenergy of fusion along the minimum spanning tree, and above by a suboptimal\nscheme, referred to as Data Fusion for Markov Random Fields (DFMRF). Scaling\nlaws are derived for the optimal and suboptimal fusion policies. It is shown\nthat the average asymptotic energy of the DFMRF scheme is finite for a class of\nMRF models. \n\n"}
{"id": "0809.2995", "contents": "Title: Navigating ultrasmall worlds in ultrashort time Abstract: Random scale-free networks are ultrasmall worlds. The average length of the\nshortest paths in networks of size N scales as lnlnN. Here we show that these\nultrasmall worlds can be navigated in ultrashort time. Greedy routing on\nscale-free networks embedded in metric spaces finds paths with the average\nlength scaling also as lnlnN. Greedy routing uses only local information to\nnavigate a network. Nevertheless, it finds asymptotically the shortest paths, a\ndirect computation of which requires global topology knowledge. Our findings\nimply that the peculiar structure of complex networks ensures that the lack of\nglobal topological awareness has asymptotically no impact on the length of\ncommunication paths. These results have important consequences for\ncommunication systems such as the Internet, where maintaining knowledge of\ncurrent topology is a major scalability bottleneck. \n\n"}
{"id": "0810.3869", "contents": "Title: Power Control in Two-Tier Femtocell Networks Abstract: In a two tier cellular network -- comprised of a central macrocell underlaid\nwith shorter range femtocell hotspots -- cross-tier interference limits overall\ncapacity with universal frequency reuse. To quantify near-far effects with\nuniversal frequency reuse, this paper derives a fundamental relation providing\nthe largest feasible cellular Signal-to-Interference-Plus-Noise Ratio (SINR),\ngiven any set of feasible femtocell SINRs. We provide a link budget analysis\nwhich enables simple and accurate performance insights in a two-tier network. A\ndistributed utility-based SINR adaptation at femtocells is proposed in order to\nalleviate cross-tier interference at the macrocell from cochannel femtocells.\nThe Foschini-Miljanic (FM) algorithm is a special case of the adaptation. Each\nfemtocell maximizes their individual utility consisting of a SINR based reward\nless an incurred cost (interference to the macrocell). Numerical results show\ngreater than 30% improvement in mean femtocell SINRs relative to FM. In the\nevent that cross-tier interference prevents a cellular user from obtaining its\nSINR target, an algorithm is proposed that reduces transmission powers of the\nstrongest femtocell interferers. The algorithm ensures that a cellular user\nachieves its SINR target even with 100 femtocells/cell-site, and requires a\nworst case SINR reduction of only 16% at femtocells. These results motivate\ndesign of power control schemes requiring minimal network overhead in two-tier\nnetworks with shared spectrum. \n\n"}
{"id": "0811.3585", "contents": "Title: The Capacity of Ad hoc Networks under Random Packet Losses Abstract: We consider the problem of determining asymptotic bounds on the capacity of a\nrandom ad hoc network. Previous approaches assumed a link layer model in which\nif a transmitter-receiver pair can communicate with each other, i.e., the\nSignal to Interference and Noise Ratio (SINR) is above a certain threshold,\nthen every transmitted packet is received error-free by the receiver thereby.\nUsing this model, the per node capacity of the network was shown to be\n$\\Theta(\\frac{1}{\\sqrt{n\\log{n}}})$. In reality, for any finite link SINR,\nthere is a non-zero probability of erroneous reception of the packet. We show\nthat in a large network, as the packet travels an asymptotically large number\nof hops from source to destination, the cumulative impact of packet losses over\nintermediate links results in a per-node throughput of only $O(\\frac{1}{n})$.\nWe then propose a new scheduling scheme to counter this effect. The proposed\nscheme provides tight guarantees on end-to-end packet loss probability, and\nimproves the per-node throughput to $\\Omega(\\frac{1}{\\sqrt{n}\n({\\log{n}})^{\\frac{\\alpha{{+2}}}{2(\\alpha-2)}}})$ where $\\alpha>2$ is the path\nloss exponent. \n\n"}
{"id": "0901.0349", "contents": "Title: Protecting infrastructure networks from cost-based attacks Abstract: It has been known that heterogeneous networks are vulnerable to the\nintentional removal of a small fraction of highly connected or loaded nodes,\nwhich implies that, to protect a network effectively, a few important nodes\nshould be allocated with more defense resources than the others. However, if\ntoo many resources are allocated to the few important nodes, the numerous\nless-important nodes will be less protected, which, when attacked all together,\nstill capable of causing a devastating damage. A natural question therefore is\nhow to efficiently distribute the limited defense resources among the network\nnodes such that the network damage is minimized whatever attack strategy the\nattacker may take. In this paper, taking into account the factor of attack\ncost, we will revisit the problem of network security and search for efficient\nnetwork defense against the cost-based attacks. The study shows that, for a\ngeneral complex network, there will exist an optimal distribution of the\ndefense resources, with which the network is well protected from cost-based\nattacks. Furthermore, it is found that the configuration of the optimal defense\nis dependent on the network parameters. Specifically, network that has a larger\nsize, sparser connection and more heterogeneous structure will be more\nbenefited from the defense optimization. \n\n"}
{"id": "0901.1936", "contents": "Title: A Lower Bound on the Capacity of Wireless Erasure Networks with Random\n  Node Locations Abstract: In this paper, a lower bound on the capacity of wireless ad hoc erasure\nnetworks is derived in closed form in the canonical case where $n$ nodes are\nuniformly and independently distributed in the unit area square. The bound\nholds almost surely and is asymptotically tight. We assume all nodes have fixed\ntransmit power and hence two nodes should be within a specified distance $r_n$\nof each other to overcome noise. In this context, interference determines\noutages, so we model each transmitter-receiver pair as an erasure channel with\na broadcast constraint, i.e. each node can transmit only one signal across all\nits outgoing links. A lower bound of $\\Theta(n r_n)$ for the capacity of this\nclass of networks is derived. If the broadcast constraint is relaxed and each\nnode can send distinct signals on distinct outgoing links, we show that the\ngain is a function of $r_n$ and the link erasure probabilities, and is at most\na constant if the link erasure probabilities grow sufficiently large with $n$.\nFinally, the case where the erasure probabilities are themselves random\nvariables, for example due to randomness in geometry or channels, is analyzed.\nWe prove somewhat surprisingly that in this setting, variability in erasure\nprobabilities increases network capacity. \n\n"}
{"id": "0901.2333", "contents": "Title: Q-CSMA: Queue-Length Based CSMA/CA Algorithms for Achieving Maximum\n  Throughput and Low Delay in Wireless Networks Abstract: Recently, it has been shown that CSMA-type random access algorithms can\nachieve the maximum possible throughput in ad hoc wireless networks. However,\nthese algorithms assume an idealized continuous-time CSMA protocol where\ncollisions can never occur. In addition, simulation results indicate that the\ndelay performance of these algorithms can be quite bad. On the other hand,\nalthough some simple heuristics (such as distributed approximations of greedy\nmaximal scheduling) can yield much better delay performance for a large set of\narrival rates, they may only achieve a fraction of the capacity region in\ngeneral. In this paper, we propose a discrete-time version of the CSMA\nalgorithm. Central to our results is a discrete-time distributed randomized\nalgorithm which is based on a generalization of the so-called Glauber dynamics\nfrom statistical physics, where multiple links are allowed to update their\nstates in a single time slot. The algorithm generates collision-free\ntransmission schedules while explicitly taking collisions into account during\nthe control phase of the protocol, thus relaxing the perfect CSMA assumption.\nMore importantly, the algorithm allows us to incorporate mechanisms which lead\nto very good delay performance while retaining the throughput-optimality\nproperty. It also resolves the hidden and exposed terminal problems associated\nwith wireless networks. \n\n"}
{"id": "0902.3210", "contents": "Title: Coverage in Multi-Antenna Two-Tier Networks Abstract: In two-tier networks -- comprising a conventional cellular network overlaid\nwith shorter range hotspots (e.g. femtocells, distributed antennas, or wired\nrelays) -- with universal frequency reuse, the near-far effect from cross-tier\ninterference creates dead spots where reliable coverage cannot be guaranteed to\nusers in either tier. Equipping the macrocell and femtocells with multiple\nantennas enhances robustness against the near-far problem. This work derives\nthe maximum number of simultaneously transmitting multiple antenna femtocells\nmeeting a per-tier outage probability constraint. Coverage dead zones are\npresented wherein cross-tier interference bottlenecks cellular and hotspot\ncoverage. Two operating regimes are shown namely 1) a cellular-limited regime\nin which femtocell users experience unacceptable cross-tier interference and 2)\na hotspot-limited regime wherein both femtocell users and cellular users are\nlimited by hotspot interference. Our analysis accounts for the per-tier\ntransmit powers, the number of transmit antennas (single antenna transmission\nbeing a special case) and terrestrial propagation such as the Rayleigh fading\nand the path loss exponents. Single-user (SU) multiple antenna transmission at\neach tier is shown to provide significantly superior coverage and spatial reuse\nrelative to multiuser (MU) transmission. We propose a decentralized\ncarrier-sensing approach to regulate femtocell transmission powers based on\ntheir location. Considering a worst-case cell-edge location, simulations using\ntypical path loss scenarios show that our interference management strategy\nprovides reliable cellular coverage with about 60 femtocells per cellsite. \n\n"}
{"id": "0903.0694", "contents": "Title: Digital Ecosystems in the Clouds: Towards Community Cloud Computing Abstract: Cloud Computing is rising fast, with its data centres growing at an\nunprecedented rate. However, this has come with concerns of privacy, efficiency\nat the expense of resilience, and environmental sustainability, because of the\ndependence on Cloud vendors such as Google, Amazon, and Microsoft. Community\nCloud Computing makes use of the principles of Digital Ecosystems to provide a\nparadigm for Clouds in the community, offering an alternative architecture for\nthe use cases of Cloud Computing. It is more technically challenging to deal\nwith issues of distributed computing, such as latency, differential resource\nmanagement, and additional security requirements. However, these are not\ninsurmountable challenges, and with the need to retain control over our digital\nlives and the potential environmental consequences, it is a challenge we must\npursue. \n\n"}
{"id": "0903.2352", "contents": "Title: A Mean Field Approach for Optimization in Particles Systems and\n  Applications Abstract: This paper investigates the limit behavior of Markov Decision Processes\n(MDPs) made of independent particles evolving in a common environment, when the\nnumber of particles goes to infinity. In the finite horizon case or with a\ndiscounted cost and an infinite horizon, we show that when the number of\nparticles becomes large, the optimal cost of the system converges almost surely\nto the optimal cost of a discrete deterministic system (the ``optimal mean\nfield''). Convergence also holds for optimal policies. We further provide\ninsights on the speed of convergence by proving several central limits theorems\nfor the cost and the state of the Markov decision process with explicit\nformulas for the variance of the limit Gaussian laws. Then, our framework is\napplied to a brokering problem in grid computing. The optimal policy for the\nlimit deterministic system is computed explicitly. Several simulations with\ngrowing numbers of processors are reported. They compare the performance of the\noptimal policy of the limit system used in the finite case with classical\npolicies (such as Join the Shortest Queue) by measuring its asymptotic gain as\nwell as the threshold above which it starts outperforming classical policies. \n\n"}
{"id": "0904.2389", "contents": "Title: Extracting the multiscale backbone of complex weighted networks Abstract: A large number of complex systems find a natural abstraction in the form of\nweighted networks whose nodes represent the elements of the system and the\nweighted edges identify the presence of an interaction and its relative\nstrength. In recent years, the study of an increasing number of large scale\nnetworks has highlighted the statistical heterogeneity of their interaction\npattern, with degree and weight distributions which vary over many orders of\nmagnitude. These features, along with the large number of elements and links,\nmake the extraction of the truly relevant connections forming the network's\nbackbone a very challenging problem. More specifically, coarse-graining\napproaches and filtering techniques are at struggle with the multiscale nature\nof large scale systems. Here we define a filtering method that offers a\npractical procedure to extract the relevant connection backbone in complex\nmultiscale networks, preserving the edges that represent statistical\nsignificant deviations with respect to a null model for the local assignment of\nweights to edges. An important aspect of the method is that it does not\nbelittle small-scale interactions and operates at all scales defined by the\nweight distribution. We apply our method to real world network instances and\ncompare the obtained results with alternative backbone extraction techniques. \n\n"}
{"id": "0904.2716", "contents": "Title: Fast dynamics in Internet topology: preliminary observations and\n  explanations Abstract: By focusing on what can be observed by running traceroute-like measurements\nat a high frequency from a single monitor to a fixed destination set, we show\nthat the observed view of the topology is constantly evolving at a pace much\nhigher than expected. Repeated measurements discover new IP addresses at a\nconstant rate, for long period of times (up to several months). In order to\nprovide explanations, we study this phenomenon both at the IP, and at the\nAutonomous System levels. We show that this renewal of IP addresses is\npartially caused by a BGP routing dynamics, altering paths between existing\nASes. Furthermore, we conjecture that an intra AS routing dynamics is another\ncause of this phenomenon. \n\n"}
{"id": "0905.1778", "contents": "Title: Encoding of Network Protection Codes Against Link and Node Failures Over\n  Finite Fields Abstract: Link and node failures are common two fundamental problems that affect\noperational networks. Hence, protection of communication networks is essential\nto increase their reliability, performance, and operations. Much research work\nhas been done to protect against link and node failures, and to provide\nreliable solutions based on pre-defined provision or dynamic restoration of the\ndomain. In this paper we develop network protection strategies against multiple\nlink failures using network coding and joint capacities. In these strategies,\nthe source nodes apply network coding for their transmitted data to provide\nbackup copies for recovery at the receivers' nodes. Such techniques can be\napplied to optical, IP, and mesh networks. The encoding operations of\nprotection codes are defined over finite fields. Furthermore, the normalized\ncapacity of the communication network is given by $(n-t)/n$ in case of $t$ link\nfailures. In addition, a bound on the minimum required field size is derived. \n\n"}
{"id": "0905.4918", "contents": "Title: Divide and Conquer: Partitioning Online Social Networks Abstract: Online Social Networks (OSNs) have exploded in terms of scale and scope over\nthe last few years. The unprecedented growth of these networks present\nchallenges in terms of system design and maintenance. One way to cope with this\nis by partitioning such large networks and assigning these partitions to\ndifferent machines. However, social networks possess unique properties that\nmake the partitioning problem non-trivial. The main contribution of this paper\nis to understand different properties of social networks and how these\nproperties can guide the choice of a partitioning algorithm. Using large scale\nmeasurements representing real OSNs, we first characterize different properties\nof social networks, and then we evaluate qualitatively different partitioning\nmethods that cover the design space. We expose different trade-offs involved\nand understand them in light of properties of social networks. We show that a\njudicious choice of a partitioning scheme can help improve performance. \n\n"}
{"id": "0907.4468", "contents": "Title: What type of distribution for packet delay in a global network should be\n  used in the control theory? Abstract: In this paper correspondence between experimental data for packet delay and\ntwo theoretical types of distribution is investigated. Calculations have shown\nthat the exponential distribution describes the data on network delay better,\nthan truncated normal distribution. Precision experimental data to within\nmicroseconds are gathered by means of the RIPE Test Box. In addition to exact\nmeasurements the data gathered by means of the utility {\\em ping} has been\nparsed that has not changed the main result. As a result, the equation for an\nexponential distribution, in the best way describing process of packet delay in\na TCP/IP based network is written. The search algorithm for key parameters as\nfor normal, and an exponential distribution is resulted. \n\n"}
{"id": "0907.5402", "contents": "Title: Optimal Scheduling for Fair Resource Allocation in Ad Hoc Networks with\n  Elastic and Inelastic Traffic Abstract: This paper studies the problem of congestion control and scheduling in ad hoc\nwireless networks that have to support a mixture of best-effort and real-time\ntraffic. Optimization and stochastic network theory have been successful in\ndesigning architectures for fair resource allocation to meet long-term\nthroughput demands. However, to the best of our knowledge, strict packet delay\ndeadlines were not considered in this framework previously. In this paper, we\npropose a model for incorporating the quality of service (QoS) requirements of\npackets with deadlines in the optimization framework. The solution to the\nproblem results in a joint congestion control and scheduling algorithm which\nfairly allocates resources to meet the fairness objectives of both elastic and\ninelastic flows, and per-packet delay requirements of inelastic flows. \n\n"}
{"id": "0908.1273", "contents": "Title: A General Class of Throughput Optimal Routing Policies in Multi-hop\n  Wireless Networks Abstract: This paper considers the problem of throughput optimal routing/scheduling in\na multi-hop constrained queueing network with random connectivity whose special\ncase includes opportunistic multi-hop wireless networks and input-queued switch\nfabrics. The main challenge in the design of throughput optimal routing\npolicies is closely related to identifying appropriate and universal Lyapunov\nfunctions with negative expected drift. The few well-known throughput optimal\npolicies in the literature are constructed using simple quadratic or\nexponential Lyapunov functions of the queue backlogs and as such they seek to\nbalance the queue backlogs across network independent of the topology. By\nconsidering a class of continuous, differentiable, and piece-wise quadratic\nLyapunov functions, this paper provides a large class of throughput optimal\nrouting policies. The proposed class of Lyapunov functions allow for the\nrouting policy to control the traffic along short paths for a large portion of\nstate-space while ensuring a negative expected drift. This structure enables\nthe design of a large class of routing policies. In particular, and in addition\nto recovering the throughput optimality of the well known backpressure routing\npolicy, an opportunistic routing policy with congestion diversity is proved to\nbe throughput optimal. \n\n"}
{"id": "0908.4288", "contents": "Title: Edge direction and the structure of networks Abstract: Directed networks are ubiquitous and are necessary to represent complex\nsystems with asymmetric interactions---from food webs to the World Wide Web.\nDespite the importance of edge direction for detecting local and community\nstructure, it has been disregarded in studying a basic type of global diversity\nin networks: the tendency of nodes with similar numbers of edges to connect.\nThis tendency, called assortativity, affects crucial structural and dynamic\nproperties of real-world networks, such as error tolerance or epidemic\nspreading. Here we demonstrate that edge direction has profound effects on\nassortativity. We define a set of four directed assortativity measures and\nassign statistical significance by comparison to randomized networks. We apply\nthese measures to three network classes---online/social networks, food webs,\nand word-adjacency networks. Our measures (i) reveal patterns common to each\nclass, (ii) separate networks that have been previously classified together,\nand (iii) expose limitations of several existing theoretical models. We reject\nthe standard classification of directed networks as purely assortative or\ndisassortative. Many display a class-specific mixture, likely reflecting\nfunctional or historical constraints, contingencies, and forces guiding the\nsystem's evolution. \n\n"}
{"id": "0909.3356", "contents": "Title: Capacity of Large-scale CSMA Wireless Networks Abstract: In the literature, asymptotic studies of multi-hop wireless network capacity\noften consider only centralized and deterministic TDMA (time-division\nmulti-access) coordination schemes. There have been fewer studies of the\nasymptotic capacity of large-scale wireless networks based on CSMA\n(carrier-sensing multi-access), which schedules transmissions in a distributed\nand random manner. With the rapid and widespread adoption of CSMA technology, a\ncritical question is that whether CSMA networks can be as scalable as TDMA\nnetworks. To answer this question and explore the capacity of CSMA networks, we\nfirst formulate the models of CSMA protocols to take into account the unique\nCSMA characteristics not captured by existing interference models in the\nliterature. These CSMA models determine the feasible states, and consequently\nthe capacity of CSMA networks. We then study the throughput efficiency of CSMA\nscheduling as compared to TDMA. Finally, we tune the CSMA parameters so as to\nmaximize the throughput to the optimal order. As a result, we show that CSMA\ncan achieve throughput as $\\Omega(\\frac{1}{\\sqrt{n}})$, the same order as\noptimal centralized TDMA, on uniform random networks. Our CSMA scheme makes use\nof an efficient backbone-peripheral routing scheme and a careful design of dual\ncarrier-sensing and dual channel scheme. We also address the implementation\nissues of our CSMA scheme. \n\n"}
{"id": "0910.2104", "contents": "Title: On cost-effective communication network designing Abstract: How to efficiently design a communication network is a paramount task for\nnetwork designing and engineering. It is, however, not a single objective\noptimization process as perceived by most previous researches, i.e., to\nmaximize its transmission capacity, but a multi-objective optimization process,\nwith lowering its cost to be another important objective. These two objectives\nare often contradictive in that optimizing one objective may deteriorate the\nother. After a deep investigation of the impact that network topology, node\ncapability scheme and routing algorithm as well as their interplays have on the\ntwo objectives, this letter presents a systematic approach to achieve a\ncost-effective design by carefully choosing the three designing aspects. Only\nwhen routing algorithm and node capability scheme are elegantly chosen can\nBA-like scale-free networks have the potential of achieving good tradeoff\nbetween the two objectives. Random networks, on the other hand, have the\nbuilt-in character for a cost-effective design, especially when other aspects\ncannot be determined beforehand. \n\n"}
{"id": "0910.4704", "contents": "Title: Performance of Joint Spectrum Sensing and MAC Algorithms for\n  Multichannel Opportunistic Spectrum Access Ad Hoc Networks Abstract: We present an analytical framework to assess the link layer throughput of\nmultichannel Opportunistic Spectrum Access (OSA) ad hoc networks. Specifically,\nwe focus on analyzing various combinations of collaborative spectrum sensing\nand Medium Access Control (MAC) protocol abstractions. We decompose\ncollaborative spectrum sensing into layers, parametrize each layer, classify\nexisting solutions, and propose a new protocol called Truncated Time Division\nMultiple Access (TTDMA) that supports efficient distribution of sensing results\nin \"k out of N\" fusion rule. In case of multichannel MAC protocols we evaluate\ntwo main approaches of control channel design with (i) dedicated and (ii)\nhopping channel. We propose to augment these protocols with options of handling\nsecondary user (SU) connections preempted by primary user (PU) by (i)\nconnection buffering until PU departure and (ii) connection switching to a\nvacant PU channel. By comparing and optimizing different design combinations we\nshow that (i) it is generally better to buffer preempted SU connections than to\nswitch them to PU vacant channels and (ii) TTDMA is a promising design option\nfor collaborative spectrum sensing process when k does not change over time. \n\n"}
{"id": "0911.1972", "contents": "Title: People-Sensing Spatial Characteristics of RF Sensor Networks Abstract: An \"RF sensor\" network can monitor RSS values on links in the network and\nperform device-free localization, i.e., locating a person or object moving in\nthe area in which the network is deployed. This paper provides a statistical\nmodel for the RSS variance as a function of the person's position w.r.t. the\ntransmitter (TX) and receiver (RX). We show that the ensemble mean of the RSS\nvariance has an approximately linear relationship with the expected total\naffected power (ETAP). We then use analysis to derive approximate expressions\nfor the ETAP as a function of the person's position, for both scattering and\nreflection. Counterintuitively, we show that reflection, not scattering, causes\nthe RSS variance contours to be shaped like Cassini ovals. Experimental tests\nreported here and in past literature are shown to validate the analysis. \n\n"}
{"id": "0911.2075", "contents": "Title: A scientific understanding of network designing Abstract: As the Internet becomes severely overburdened with exponentially growing\ntraffic demand, it becomes a general belief that a new generation data network\nis in urgent need today. However, standing at this crossroad, we find that we\nare in a situation that lacks a theory of network designing. This issue becomes\neven more serious as the recent progress of network measurement and modeling\nchallenges the foundation of network research in the past decades.\n  This paper tries to set up a scientific foundation for network designing by\nformalizing it as a multi-objective optimization process and quantifying the\nway different designing choices independently and collectively influence these\nobjectives. A cartesian coordinate system is introduced to map the effect of\neach designing scheme to a coordinate. We investigated the achievable area of\nthe network designing space and proved some boundary conditions. It is shown\nthat different kind of networks display different shapes of achievable areas in\nthe cartesian coordinate and exhibit different abilities to achieve\ncost-effective and scalable designing. In particular, we found that the\nphilosophy underlying current empirical network designing and engineering fails\nto meet the cost-effective and evolvable requirements of network designing. We\ndemonstrated that the efficient routing combined with effective betweenness\nbased link bandwidth allocation scheme is a cost-effective and scalable design\nfor BA-like scale-free networks, whereas if other designing choices cannot be\ndetermined beforehand, ER network is a markedly good candidate for\ncost-effective and scalable design. \n\n"}
{"id": "0911.5667", "contents": "Title: End-to-End Algebraic Network Coding for Wireless TCP/IP Networks Abstract: The Transmission Control Protocol (TCP) was designed to provide reliable\ntransport services in wired networks. In such networks, packet losses mainly\noccur due to congestion. Hence, TCP was designed to apply congestion avoidance\ntechniques to cope with packet losses. Nowadays, TCP is also utilized in\nwireless networks where, besides congestion, numerous other reasons for packet\nlosses exist. This results in reduced throughput and increased transmission\nround-trip time when the state of the wireless channel is bad. We propose a new\nnetwork layer, that transparently sits below the transport layer and hides non\ncongestion-imposed packet losses from TCP. The network coding in this new layer\nis based on the well-known class of Maximum Distance Separable (MDS) codes. \n\n"}
{"id": "0912.1424", "contents": "Title: Understanding edge-connectivity in the Internet through\n  core-decomposition Abstract: Internet is a complex network composed by several networks: the Autonomous\nSystems, each one designed to transport information efficiently. Routing\nprotocols aim to find paths between nodes whenever it is possible (i.e., the\nnetwork is not partitioned), or to find paths verifying specific constraints\n(e.g., a certain QoS is required). As connectivity is a measure related to both\nof them (partitions and selected paths) this work provides a formal lower bound\nto it based on core-decomposition, under certain conditions, and low complexity\nalgorithms to find it. We apply them to analyze maps obtained from the\nprominent Internet mapping projects, using the LaNet-vi open-source software\nfor its visualization. \n\n"}
{"id": "0912.2138", "contents": "Title: Effective Carrier Sensing in CSMA Networks under Cumulative Interference Abstract: This paper proposes and investigates the concept of a safe carrier-sensing\nrange that can guarantee interference safe (also termed hidden-node-free)\ntransmissions in CSMA networks under the cumulative interference model.\nCompared with the safe carrier-sensing range under the commonly assumed but\nless realistic pairwise interference model, we show that the safe\ncarrier-sensing range required under the cumulative interference model is\nlarger by a constant multiplicative factor. The concept of a safe\ncarrier-sensing range, although amenable to elegant analytical results, is\ninherently not compatible with the conventional power threshold carrier-sensing\nmechanism (e.g., that used in IEEE 802.11). Specifically, the absolute power\nsensed by a node in the conventional mechanism does not contain enough\ninformation for it to derive its distances from other concurrent transmitter\nnodes. We show that, fortunately, a carrier-sensing mechanism called\nIncremental-Power Carrier-Sensing (IPCS) can realize the carrier-sensing range\nconcept in a simple way. Instead of monitoring the absolute detected power, the\nIPCS mechanism monitors every increment in the detected power. This means that\nIPCS can separate the detected power of every concurrent transmitter, and map\nthe power profile to the required distance information. \n\n"}
{"id": "0912.4087", "contents": "Title: On the Connectivity and Multihop Delay of Ad Hoc Cognitive Radio\n  Networks Abstract: We analyze the multihop delay of ad hoc cognitive radio networks, where the\ntransmission delay of each hop consists of the propagation delay and the\nwaiting time for the availability of the communication channel (i.e., the\noccurrence of a spectrum opportunity at this hop). Using theories and\ntechniques from continuum percolation and ergodicity, we establish the scaling\nlaw of the minimum multihop delay with respect to the source-destination\ndistance in cognitive radio networks. When the propagation delay is negligible,\nwe show the starkly different scaling behavior of the minimum multihop delay in\ninstantaneously connected networks as compared to networks that are only\nintermittently connected due to scarcity of spectrum opportunities.\nSpecifically, if the network is instantaneously connected, the minimum multihop\ndelay is asymptotically independent of the distance; if the network is only\nintermittently connected, the minimum multihop delay scales linearly with the\ndistance. When the propagation delay is nonnegligible but small, we show that\nalthough the scaling order is always linear, the scaling rate for an\ninstantaneously connected network can be orders of magnitude smaller than the\none for an intermittently connected network. \n\n"}
{"id": "1001.3171", "contents": "Title: Optimal Reverse Carpooling Over Wireless Networks - A Distributed\n  Optimization Approach Abstract: We focus on a particular form of network coding, reverse carpooling, in a\nwireless network where the potentially coded transmitted messages are to be\ndecoded immediately upon reception. The network is fixed and known, and the\nsystem performance is measured in terms of the number of wireless broadcasts\nrequired to meet multiple unicast demands. Motivated by the structure of the\ncoding scheme, we formulate the problem as a linear program by introducing a\nflow variable for each triple of connected nodes. This allows us to have a\nformulation polynomial in the number of nodes. Using dual decomposition and\nprojected subgradient method, we present a decentralized algorithm to obtain\noptimal routing schemes in presence of coding opportunities. We show that the\nprimal sub-problem can be expressed as a shortest path problem on an\n\\emph{edge-graph}, and the proposed algorithm requires each node to exchange\ninformation only with its neighbors. \n\n"}
{"id": "1001.3714", "contents": "Title: Network Codes Resilient to Jamming and Eavesdropping Abstract: We consider the problem of communicating information over a network secretly\nand reliably in the presence of a hidden adversary who can eavesdrop and inject\nmalicious errors. We provide polynomial-time, rate-optimal distributed network\ncodes for this scenario, improving on the rates achievable in previous work.\nOur main contribution shows that as long as the sum of the adversary's jamming\nrate Zo and his eavesdropping rate Zi is less than the network capacity C,\n(i.e., Zo+Zi<C), our codes can communicate (with vanishingly small error\nprobability) a single bit correctly and without leaking any information to the\nadversary. We then use this to design codes that allow communication at the\noptimal source rate of C-Zo-Zi, while keeping the communicated message secret\nfrom the adversary. Interior nodes are oblivious to the presence of adversaries\nand perform random linear network coding; only the source and destination need\nto be tweaked. In proving our results we correct an error in prior work by a\nsubset of the authors in this work. \n\n"}
{"id": "1002.2385", "contents": "Title: Traffic Capacity of Large WDM Passive Optical Networks Abstract: As passive optical networks (PON) are increasingly deployed to provide high\nspeed Internet access, it is important to understand their fundamental traffic\ncapacity limits. The paper discusses performance models applicable to\nwavelength division multiplexing (WDM) EPONs and GPONs under the assumption\nthat users access the fibre via optical network units equipped with tunable\ntransmitters. The considered stochastic models are based on multiserver polling\nsystems for which explicit analytical results are not known. A large system\nasymptotic, mean-field approximation, is used to derive closed form solutions\nof these complex systems. Convergence of the mean field dynamics is proved in\nthe case of a simple network configuration. Simulation results show that, for a\nrealistic sized PON, the mean field approximation is accurate. \n\n"}
{"id": "1002.3229", "contents": "Title: A Greedy link scheduler for Wireless Networks having Gaussian Broadcast\n  and Multiple Access Channels Abstract: Information theoretic Broadcast Channels (BC) and Multiple Access Channels\n(MAC) enable a single node to transmit data simultaneously to multiple nodes,\nand multiple nodes to transmit data simultaneously to a single node\nrespectively. In this paper, we address the problem of link scheduling in\nmultihop wireless networks containing nodes with BC and MAC capabilities. We\nfirst propose an interference model that extends protocol interference models,\noriginally designed for point to point channels, to include the possibility of\nBC and MAC. Due to the high complexity of optimal link schedulers, we introduce\nthe Multiuser Greedy Maximum Weight algorithm for link scheduling in multihop\nwireless networks containing BCs and MACs. Given a network graph, we develop\nnew local pooling conditions and show that the performance of our algorithm can\nbe fully characterized using the associated parameter, the multiuser local\npooling factor. We provide examples of some network graphs, on which we apply\nlocal pooling conditions and derive the multiuser local pooling factor. We\nprove optimality of our algorithm in tree networks and show that the\nexploitation of BCs and MACs improve the throughput performance considerably in\nmultihop wireless networks. \n\n"}
{"id": "1003.0190", "contents": "Title: Generating Function For Network Delay Abstract: In this paper correspondence between experimental data for packet delay and\ntwo theoretical types of distribution is investigated. Statistical tests have\nshown that only exponential distribution can be used for the description of\npacket delays in global network. Precision experimental data to within\nmicroseconds are gathered by means of the RIPE Test Box. Statistical\nverification of hypothesis has shown that distribution parameters remain\nconstants during 500 second intervals at least. In paper cumulative\ndistribution function and generating function for packet delay in network are\nin an explicit form written down, the algorithm of search of parameters of\ndistribution is resulted. \n\n"}
{"id": "1004.1042", "contents": "Title: Spatial fairness in linear wireless multi-access networks Abstract: Multi-access networks may exhibit severe unfairness in throughput. Recent\nstudies show that this unfairness is due to local differences in the\nneighborhood structure: Nodes with less neighbors receive better access. We\nstudy the unfairness in saturated linear networks, and adapt the multi-access\nCSMA protocol to remove the unfairness completely, by choosing the activation\nrates of nodes appropriately as a function of the number of neighbors. We then\ninvestigate the consequences of this choice of activation rates on the\nnetwork-average saturated throughput, and we show that these rates perform well\nin a non-saturated setting. \n\n"}
{"id": "1005.1634", "contents": "Title: Interference Alignment in Regenerating Codes for Distributed Storage:\n  Necessity and Code Constructions Abstract: Regenerating codes are a class of recently developed codes for distributed\nstorage that, like Reed-Solomon codes, permit data recovery from any arbitrary\nk of n nodes. However regenerating codes possess in addition, the ability to\nrepair a failed node by connecting to any arbitrary d nodes and downloading an\namount of data that is typically far less than the size of the data file. This\namount of download is termed the repair bandwidth. Minimum storage regenerating\n(MSR) codes are a subclass of regenerating codes that require the least amount\nof network storage; every such code is a maximum distance separable (MDS) code.\nFurther, when a replacement node stores data identical to that in the failed\nnode, the repair is termed as exact.\n  The four principal results of the paper are (a) the explicit construction of\na class of MDS codes for d = n-1 >= 2k-1 termed the MISER code, that achieves\nthe cut-set bound on the repair bandwidth for the exact-repair of systematic\nnodes, (b) proof of the necessity of interference alignment in exact-repair MSR\ncodes, (c) a proof showing the impossibility of constructing linear,\nexact-repair MSR codes for d < 2k-3 in the absence of symbol extension, and (d)\nthe construction, also explicit, of MSR codes for d = k+1. Interference\nalignment (IA) is a theme that runs throughout the paper: the MISER code is\nbuilt on the principles of IA and IA is also a crucial component to the\nnon-existence proof for d < 2k-3. To the best of our knowledge, the\nconstructions presented in this paper are the first, explicit constructions of\nregenerating codes that achieve the cut-set bound. \n\n"}
{"id": "1005.4178", "contents": "Title: Optimal Exact-Regenerating Codes for Distributed Storage at the MSR and\n  MBR Points via a Product-Matrix Construction Abstract: Regenerating codes are a class of distributed storage codes that optimally\ntrade the bandwidth needed for repair of a failed node with the amount of data\nstored per node of the network. Minimum Storage Regenerating (MSR) codes\nminimize first, the amount of data stored per node, and then the repair\nbandwidth, while Minimum Bandwidth Regenerating (MBR) codes carry out the\nminimization in the reverse order. An [n, k, d] regenerating code permits the\ndata to be recovered by connecting to any k of the n nodes in the network,\nwhile requiring that repair of a failed node be made possible by connecting\n(using links of lesser capacity) to any d nodes. Previous, explicit and general\nconstructions of exact-regenerating codes have been confined to the case n=d+1.\nIn this paper, we present optimal, explicit constructions of MBR codes for all\nfeasible values of [n, k, d] and MSR codes for all [n, k, d >= 2k-2], using a\nproduct-matrix framework. The particular product-matrix nature of the\nconstructions is shown to significantly simplify system operation. To the best\nof our knowledge, these are the first constructions of exact-regenerating codes\nthat allow the number n of nodes in the distributed storage network, to be\nchosen independent of the other parameters. The paper also contains a simpler\ndescription, in the product-matrix framework, of a previously constructed MSR\ncode in which the parameter d satisfies [n=d+1, k, d >= 2k-1]. \n\n"}
{"id": "1005.5628", "contents": "Title: Distributed Creation and Adaptation of Random Scale-Free Overlay\n  Networks Abstract: Random scale-free overlay topologies provide a number of properties like for\nexample high resilience against failures of random nodes, small (average)\ndiameter as well as good expansion and congestion characteristics that make\nthem interesting for the use in large-scale distributed systems. A number of\nthese properties have been shown to be influenced by the exponent \\gamma of\ntheir degree distribution P(k) ~ k^{-\\gamma}. In this article, we present a\ndistributed rewiring scheme that is suitable to effectuate scale-free overlay\ntopologies with an adjustable exponent. The scheme uses a biased random walk\nstrategy to sample new endpoints of edges being rewired and relies on a simple\nequilibrium model for scale-free networks. The bias of the random walk strategy\ncan be tuned to produce random scale-free networks with arbitrary degree\ndistribution exponents greater than two. We argue that the rewiring strategy\ncan be implemented in a distributed fashion based on a node's information about\nits immediate neighbors. We present both analytical arguments as well as\nresults that have been obtained using an implementation of the proposed\nprotocol. \n\n"}
{"id": "1006.1956", "contents": "Title: A Semi-distributed Reputation Based Intrusion Detection System for\n  Mobile Adhoc Networks Abstract: A Mobile Adhoc Network (MANET) is a cooperative engagement of a collection of\nmobile nodes without any centralized access point or infrastructure to\ncoordinate among the peers. The underlying concept of coordination among nodes\nin a cooperative MANET has induced in them a vulnerability to attacks due to\nissues like lack of fixed infrastructure, dynamically changing network\ntopology, cooperative algorithms, lack of centralized monitoring and management\npoint, and lack of a clear line of defense. We propose a semi-distributed\napproach towards Reputation Based Intrusion Detection System (IDS) that\ncombines with the DSR routing protocol for strengthening the defense of a\nMANET. Our system inherits the features of reputation from human behavior,\nhence making the IDS socially inspired. It has a semi-distributed architecture\nas the critical observation results of the system are neither spread globally\nnor restricted locally. The system assigns maximum weightage to self\nobservation by nodes for updating any reputation values, thus avoiding the need\nof a trust relationship between nodes. Our system is also unique in the sense\nthat it features the concepts of Redemption and Fading with a robust Path\nManager and Monitor system. Simulation studies show that DSR fortified with our\nsystem outperforms normal DSR in terms of the packet delivery ratio and routing\noverhead even when up to half of nodes in the network behave as malicious.\nVarious parameters introduced such as timing window size, reputation update\nvalues, congestion parameter and other thresholds have been optimized over\nseveral simulation test runs of the system. By combining the semi-distributed\narchitecture and other design essentials like path manager, monitor module,\nredemption and fading concepts; Our system proves to be robust enough to\ncounter most common attacks in MANETs. \n\n"}
{"id": "1006.4225", "contents": "Title: Optimal Spectrum Sharing in MIMO Cognitive Radio Networks via\n  Semidefinite Programming Abstract: In this paper, we study the optimal secondary-link beamforming pattern that\nbalances between the SU's throughput and the interference it causes to PUs in\nMIMO cognitive radio networks. In particular, we aim to maximize the throughput\nof the SU, while keeping the interference temperature at the primary receivers\nbelow a certain threshold.\n  Unlike traditional MIMO systems, SUs may not have the luxury of knowing the\nchannel state information (CSI) on the links to PUs. This presents a key\nchallenge for a secondary transmitter to steer interference away from primary\nreceivers. In this paper, we consider three scenarios, namely when the\nsecondary transmitter has complete, partial, or no knowledge about the channels\nto the primary receivers. In particular, when complete CSI is not available,\nthe interference-temperature constraints are to be satisfied with high\nprobability, thus resulting in chance constraints that are typically hard to\ndeal with. Our contribution is fourfold. First, by analyzing the distributional\ncharacteristics of MIMO channels, we propose a unified homogeneous QCQP\nformulation that can be applied to all three scenarios. The homogeneous QCQP\nformulation, though non-convex, is amenable to semidefinite programming (SDP)\nrelaxation methods. Secondly, we show that the SDP relaxation admits no gap\nwhen the number of primary links is no larger than two. Thirdly, we propose a\nrandomized polynomial-time algorithm for constructing a near-optimal solution\nto the QCQP problem when there are more than two primary links. Finally, we\nshow that when the secondary transmitter has no CSI on the links to primary\nreceivers, the optimal solution to the QCQP problem can be found by a simple\nmatrix eigenvalue-eigenvector computation, which can be done much more\nefficiently than solving the QCQP directly. \n\n"}
{"id": "1007.3336", "contents": "Title: Active Topology Inference using Network Coding Abstract: Our goal is to infer the topology of a network when (i) we can send probes\nbetween sources and receivers at the edge of the network and (ii) intermediate\nnodes can perform simple network coding operations, i.e., additions. Our key\nintuition is that network coding introduces topology-dependent correlation in\nthe observations at the receivers, which can be exploited to infer the\ntopology. For undirected tree topologies, we design hierarchical clustering\nalgorithms, building on our prior work. For directed acyclic graphs (DAGs),\nfirst we decompose the topology into a number of two-source, two-receiver\n(2-by-2) subnetwork components and then we merge these components to\nreconstruct the topology. Our approach for DAGs builds on prior work on\ntomography, and improves upon it by employing network coding to accurately\ndistinguish among all different 2-by-2 components. We evaluate our algorithms\nthrough simulation of a number of realistic topologies and compare them to\nactive tomographic techniques without network coding. We also make connections\nbetween our approach and alternatives, including passive inference, traceroute,\nand packet marking. \n\n"}
{"id": "1007.3341", "contents": "Title: Simulation technique for available bandwidth estimation Abstract: The paper proposes a method for measuring available bandwidth, based on\ntesting network packets of various sizes (Variable Packet Size method, VPS).\nThe boundaries of applicability of the model have been found, which are based\non the accuracy of measurements of packet delays, also we have derived a\nformula of measuring the upper limit of bandwidth. The computer simulation has\nbeen performed and relationship between the measurement error of available\nbandwidth and the number of measurements has been found. Experimental\nverification with the use of RIPE Test Box measuring system has shown that the\nsuggested method has advantages over existing measurement techniques. Pathload\nutility has been chosen as an alternative technique of measurement, and to\nensure reliable results statistics by SNMP agent has been withdrawn directly\nfrom the router. \n\n"}
{"id": "1007.5032", "contents": "Title: Approximation Algorithms for Secondary Spectrum Auctions Abstract: We study combinatorial auctions for the secondary spectrum market. In this\nmarket, short-term licenses shall be given to wireless nodes for communication\nin their local neighborhood. In contrast to the primary market, channels can be\nassigned to multiple bidders, provided that the corresponding devices are well\nseparated such that the interference is sufficiently low. Interference\nconflicts are described in terms of a conflict graph in which the nodes\nrepresent the bidders and the edges represent conflicts such that the feasible\nallocations for a channel correspond to the independent sets in the conflict\ngraph.\n  In this paper, we suggest a novel LP formulation for combinatorial auctions\nwith conflict graph using a non-standard graph parameter, the so-called\ninductive independence number. Taking into account this parameter enables us to\nbypass the well-known lower bound of \\Omega(n^{1-\\epsilon}) on the\napproximability of independent set in general graphs with n nodes (bidders). We\nachieve significantly better approximation results by showing that interference\nconstraints for wireless networks yield conflict graphs with bounded inductive\nindependence number.\n  Our framework covers various established models of wireless communication,\ne.g., the protocol or the physical model. For the protocol model, we achieve an\nO(\\sqrt{k})-approximation, where k is the number of available channels. For the\nmore realistic physical model, we achieve an O(\\sqrt{k} \\log^2 n) approximation\nbased on edge-weighted conflict graphs. Combining our approach with the the\nLP-based framework of Lavi and Swamy, we obtain incentive compatible mechanisms\nfor general bidders with arbitrary valuations on bundles of channels specified\nin terms of demand oracles. \n\n"}
{"id": "1008.0053", "contents": "Title: Achieving the Scaling Law of SNR-Monitoring in Dynamic Wireless Networks Abstract: The characteristics of wireless communication channels may vary with time due\nto fading, environmental changes and movement of mobile wireless devices.\nTracking and estimating channel gains of wireless channels is therefore a\nfundamentally important element of many wireless communication systems. In\nparticular, the receivers in many wireless networks need to estimate the\nchannel gains by means of a training sequence. This paper studies the scaling\nlaw (on the network size) of the overhead for channel gain monitoring in\nwireless network. We first investigate the scenario in which a receiver needs\nto track the channel gains with respect to multiple transmitters. To be\nconcrete, suppose that there are n transmitters, and that in the current round\nof channel-gain estimation, no more than k channels suffer significant\nvariations since the last round. We proves that \"\\Theta(k\\log((n+1)/k)) time\nslots\" is the minimum number of time slots needed to catch up with the k varied\nchannels. At the same time, we propose a novel channel-gain monitoring scheme\nnamed ADMOT to achieve the overhead lower-bound. ADMOT leverages recent\nadvances in compressive sensing in signal processing and interference\nprocessing in wireless communication, to enable the receiver to estimate all n\nchannels in a reliable and computationally efficient manner within\nO(k\\log((n+1)/k)) time slots. To our best knowledge, all previous\nchannel-tracking schemes require \\Theta(n) time slots regardless of k. Note\nthat based on above results for single receiver scenario, the scaling law of\ngeneral setting is achieved in which there are multiple transmitters, relay\nnodes and receivers. \n\n"}
{"id": "1008.0227", "contents": "Title: Fast Mixing of Parallel Glauber Dynamics and Low-Delay CSMA Scheduling Abstract: Glauber dynamics is a powerful tool to generate randomized, approximate\nsolutions to combinatorially difficult problems. It has been used to analyze\nand design distributed CSMA (Carrier Sense Multiple Access) scheduling\nalgorithms for multi-hop wireless networks. In this paper we derive bounds on\nthe mixing time of a generalization of Glauber dynamics where multiple links\nare allowed to update their states in parallel and the fugacity of each link\ncan be different. The results can be used to prove that the average queue\nlength (and hence, the delay) under the parallel Glauber dynamics based CSMA\ngrows polynomially in the number of links for wireless networks with\nbounded-degree interference graphs when the arrival rate lies in a fraction of\nthe capacity region. We also show that in specific network topologies, the\nlow-delay capacity region can be further improved. \n\n"}
{"id": "1008.0420", "contents": "Title: Modeling Network Coded TCP Throughput: A Simple Model and its Validation Abstract: We analyze the performance of TCP and TCP with network coding (TCP/NC) in\nlossy wireless networks. We build upon the simple framework introduced by\nPadhye et al. and characterize the throughput behavior of classical TCP as well\nas TCP/NC as a function of erasure rate, round-trip time, maximum window size,\nand duration of the connection. Our analytical results show that network coding\nmasks erasures and losses from TCP, thus preventing TCP's performance\ndegradation in lossy networks, such as wireless networks. It is further seen\nthat TCP/NC has significant throughput gains over TCP. In addition, we simulate\nTCP and TCP/NC to verify our analysis of the average throughput and the window\nevolution. Our analysis and simulation results show very close concordance and\nsupport that TCP/NC is robust against erasures. TCP/NC is not only able to\nincrease its window size faster but also to maintain a large window size\ndespite losses within the network, whereas TCP experiences window closing\nessentially because losses are mistakenly attributed to congestion. \n\n"}
{"id": "1008.2267", "contents": "Title: Application Neutrality and a Paradox of Side Payments Abstract: The ongoing debate over net neutrality covers a broad set of issues related\nto the regulation of public networks. In two ways, we extend an idealized\nusage-priced game-theoretic framework based on a common linear demand-response\nmodel. First, we study the impact of \"side payments\" among a plurality of\nInternet service (access) providers and content providers. In the\nnon-monopolistic case, our analysis reveals an interesting \"paradox\" of side\npayments in that overall revenues are reduced for those that receive them.\nSecond, assuming different application types (e.g., HTTP web traffic,\npeer-to-peer file sharing, media streaming, interactive VoIP), we extend this\nmodel to accommodate differential pricing among them in order to study the\nissue of application neutrality. Revenues for neutral and non-neutral pricing\nare compared for the case of two application types. \n\n"}
{"id": "1008.2565", "contents": "Title: Multigraph Sampling of Online Social Networks Abstract: State-of-the-art techniques for probability sampling of users of online\nsocial networks (OSNs) are based on random walks on a single social relation\n(typically friendship). While powerful, these methods rely on the social graph\nbeing fully connected. Furthermore, the mixing time of the sampling process\nstrongly depends on the characteristics of this graph. In this paper, we\nobserve that there often exist other relations between OSN users, such as\nmembership in the same group or participation in the same event. We propose to\nexploit the graphs these relations induce, by performing a random walk on their\nunion multigraph. We design a computationally efficient way to perform\nmultigraph sampling by randomly selecting the graph on which to walk at each\niteration. We demonstrate the benefits of our approach through (i) simulation\nin synthetic graphs, and (ii) measurements of Last.fm - an Internet website for\nmusic with social networking features. More specifically, we show that\nmultigraph sampling can obtain a representative sample and faster convergence,\neven when the individual graphs fail, i.e., are disconnected or highly\nclustered. \n\n"}
{"id": "1008.2574", "contents": "Title: An Empirical Study on Content Bundling in BitTorrent Swarming System Abstract: Despite the tremendous success of BitTorrent, its swarming system suffers\nfrom a fundamental limitation: lower or no availability of unpopular contents.\nRecently, Menasche et al. has shown that bundling is a promising solution to\nmitigate this availability problem; it improves the availability and reduces\ndownload times for unpopular contents by combining multiple files into a single\nswarm. There also have been studies on bundling strategies and performance\nissues in bundled swarms. In spite of the recent surge of interest in the\nbenefits of and strategies for bundling, there are still little empirical\ngrounding for understanding, describing, and modeling it. This is the first\nempirical study that measures and analyzes how prevalent contents bundling is\nin BitTorrent and how peers access the bundled contents, in comparison to the\nother non-bundled (i.e., single-filed) ones. To our surprise, we found that\naround 70% of BitTorrent swarms contain multiple files, which indicate that\nbundling has become widespread for contents sharing. We also show that the\namount of bytes shared in bundled swarms is estimated to be around 85% out of\nall the BitTorrent contents logged in our datasets. Inspired from our findings,\nwe raise and discuss three important research questions in the field of file\nsharing systems as well as future contents-oriented networking: i) bundling\nstrategies, ii) bundling-aware sharing systems in BitTorrent, and iii)\nimplications on content-oriented networking. \n\n"}
{"id": "1008.3421", "contents": "Title: Network Utility Maximization over Partially Observable Markovian\n  Channels Abstract: We consider a utility maximization problem over partially observable Markov\nON/OFF channels. In this network instantaneous channel states are never known,\nand at most one user is selected for service in every slot according to the\npartial channel information provided by past observations. Solving the utility\nmaximization problem directly is difficult because it involves solving\npartially observable Markov decision processes. Instead, we construct an\napproximate solution by optimizing the network utility only over a good\nconstrained network capacity region rendered by stationary policies. Using a\nnovel frame-based Lyapunov drift argument, we design a policy of admission\ncontrol and user selection that stabilizes the network with utility that can be\nmade arbitrarily close to the optimal in the constrained region. Equivalently,\nwe are dealing with a high-dimensional restless bandit problem with a general\nfunctional objective over Markov ON/OFF restless bandits. Thus the network\ncontrol algorithm developed in this paper serves as a new approximation\nmethodology to attack such complex restless bandit problems. \n\n"}
{"id": "1008.3614", "contents": "Title: Control and Optimization Meet the Smart Power Grid - Scheduling of Power\n  Demands for Optimal Energy Management Abstract: The smart power grid aims at harnessing information and communication\ntechnologies to enhance reliability and enforce sensible use of energy. Its\nrealization is geared by the fundamental goal of effective management of demand\nload. In this work, we envision a scenario with real-time communication between\nthe operator and consumers. The grid operator controller receives requests for\npower demands from consumers, with different power requirement, duration, and a\ndeadline by which it is to be completed. The objective is to devise a power\ndemand task scheduling policy that minimizes the grid operational cost over a\ntime horizon. The operational cost is a convex function of instantaneous power\nconsumption and reflects the fact that each additional unit of power needed to\nserve demands is more expensive as demand load increases.First, we study the\noff-line demand scheduling problem, where parameters are fixed and known. Next,\nwe devise a stochastic model for the case when demands are generated\ncontinually and scheduling decisions are taken online and focus on long-term\naverage cost. We present two instances of power consumption control based on\nobserving current consumption. First, the controller may choose to serve a new\ndemand request upon arrival or to postpone it to the end of its deadline.\nSecond, the additional option exists to activate one of the postponed demands\nwhen an active demand terminates. For both instances, the optimal policies are\nthreshold based. We derive a lower performance bound over all policies, which\nis asymptotically tight as deadlines increase. We propose the Controlled\nRelease threshold policy and prove it is asymptotically optimal. The policy\nactivates a new demand request if the current power consumption is less than a\nthreshold, otherwise it is queued. Queued demands are scheduled when their\ndeadline expires or when the consumption drops below the threshold. \n\n"}
{"id": "1008.4264", "contents": "Title: Network Protection Design Using Network Coding Abstract: Link and node failures are two common fundamental problems that affect\noperational networks. Protection of communication networks against such\nfailures is essential for maintaining network reliability and performance.\nNetwork protection codes (NPC) are proposed to protect operational networks\nagainst link and node failures. Furthermore, encoding and decoding operations\nof such codes are well developed over binary and finite fields. Finding network\ntopologies, practical scenarios, and limits on graphs applicable for NPC are of\ninterest. In this paper, we establish limits on network protection design. We\ninvestigate several network graphs where NPC can be deployed using network\ncoding. Furthermore, we construct graphs with minimum number of edges suitable\nfor network protection codes deployment. \n\n"}
{"id": "1009.0516", "contents": "Title: A Tractable Approach to Coverage and Rate in Cellular Networks Abstract: Cellular networks are usually modeled by placing the base stations on a grid,\nwith mobile users either randomly scattered or placed deterministically. These\nmodels have been used extensively but suffer from being both highly idealized\nand not very tractable, so complex system-level simulations are used to\nevaluate coverage/outage probability and rate. More tractable models have long\nbeen desirable. We develop new general models for the multi-cell\nsignal-to-interference-plus-noise ratio (SINR) using stochastic geometry. Under\nvery general assumptions, the resulting expressions for the downlink SINR CCDF\n(equivalent to the coverage probability) involve quickly computable integrals,\nand in some practical special cases can be simplified to common integrals\n(e.g., the Q-function) or even to simple closed-form expressions. We also\nderive the mean rate, and then the coverage gain (and mean rate loss) from\nstatic frequency reuse. We compare our coverage predictions to the grid model\nand an actual base station deployment, and observe that the proposed model is\npessimistic (a lower bound on coverage) whereas the grid model is optimistic,\nand that both are about equally accurate. In addition to being more tractable,\nthe proposed model may better capture the increasingly opportunistic and dense\nplacement of base stations in future networks. \n\n"}
{"id": "1009.0619", "contents": "Title: Field Reconstruction in Sensor Networks with Coverage Holes and Packet\n  Losses Abstract: Environmental monitoring is often performed through a wireless sensor\nnetwork, whose nodes are randomly deployed over the geographical region of\ninterest. Sensors sample a physical phenomenon (the so-called field) and send\ntheir measurements to a {\\em sink} node, which is in charge of reconstructing\nthe field from such irregular samples. In this work, we focus on scenarios of\npractical interest where the sensor deployment is unfeasible in certain areas\nof the geographical region, e.g., due to terrain asperities, and the delivery\nof sensor measurements to the sink may fail due to fading or to transmission\ncollisions among sensors simultaneously accessing the wireless medium. Under\nthese conditions, we carry out an asymptotic analysis and evaluate the quality\nof the estimation of a d-dimensional field when the sink uses linear filtering\nas a reconstruction technique. Specifically, given the matrix representing the\nsampling system, V, we derive both the moments and an expression of the\nlimiting spectral distribution of VV*, as the size of V goes to infinity and\nits aspect ratio has a finite limit bounded away from zero. By using such\nasymptotic results, we approximate the mean square error on the estimated field\nthrough the eta-transform of VV*, and derive the sensor network performance\nunder the conditions described above. \n\n"}
{"id": "1009.3468", "contents": "Title: Delay Modelling for Single Cell IEEE 802.11 WLANs Using a Random Polling\n  System Abstract: In this paper, we consider the problem of modelling the average delay\nexperienced by a packet in a single cell IEEE 802.11 DCF wireless local area\nnetwork. The packet arrival process at each node i is assumed to be Poisson\nwith rate parameter \\lambda_i. Since the nodes are sharing a single channel,\nthey have to contend with one another for a successful transmission. The mean\ndelay for a packet has been approximated by modelling the system as a 1-limited\nRandom Polling system with zero switchover time. We show that even for\nnon-homogeneous packet arrival processes, the mean delay of packets across the\nqueues are same and depends on the system utilization factor and the aggregate\nthroughput of the MAC. Extensive simulations are conducted to verify the\nanalytical results. \n\n"}
{"id": "1009.3522", "contents": "Title: Open, Closed, and Shared Access Femtocells in the Downlink Abstract: A fundamental choice in femtocell deployments is the set of users which are\nallowed to access each femtocell. Closed access restricts the set to\nspecifically registered users, while open access allows any mobile subscriber\nto use any femtocell. Which one is preferable depends strongly on the distance\nbetween the macrocell base station (MBS) and femtocell. The main results of the\npaper are lemmas which provide expressions for the SINR distribution for\nvarious zones within a cell as a function of this MBS-femto distance. The\naverage sum throughput (or any other SINR-based metric) of home users and\ncellular users under open and closed access can be readily determined from\nthese expressions. We show that unlike in the uplink, the interests of home and\ncellular users are in conflict, with home users preferring closed access and\ncellular users preferring open access. The conflict is most pronounced for\nfemtocells near the cell edge, when there are many cellular users and fewer\nfemtocells. To mitigate this conflict, we propose a middle way which we term\nshared access in which femtocells allocate an adjustable number of time-slots\nbetween home and cellular users such that a specified minimum rate for each can\nbe achieved. The optimal such sharing fraction is derived. Analysis shows that\nshared access achieves at least the overall throughput of open access while\nalso satisfying rate requirements, while closed access fails for cellular users\nand open access fails for the home user. \n\n"}
{"id": "1009.3863", "contents": "Title: Outage Probability for Multi-Cell Processing under Rayleigh Fading Abstract: Multi-cell processing, also called Coordinated Multiple Point (CoMP), is a\nvery promising distributed multi-antennas technique that uses neighbour cell's\nantennas. This is expected to be part of next generation cellular networks\nstandards such as LTE-A. Small cell networks in dense urban environment are\nmainly limited by interferences and CoMP can strongly take advantage of this\nfact to improve cell-edge users' throughput. This paper provides an analytical\nderivation of the capacity outage probability for CoMP experiencing fast\nRayleigh fading. Only the average received power (slow varying fading) has to\nbe known, and perfect Channel State Information (CSI) is not required. An\noptimisation of the successfully received data-rate is then derived with\nrespect to the number of cooperating stations and the outage probability,\nillustrated by numerical examples. \n\n"}
{"id": "1009.3961", "contents": "Title: Optimization of ARQ Protocols in Interference Networks with QoS\n  Constraints Abstract: We study optimal transmission strategies in interfering wireless networks,\nunder Quality of Service constraints. A buffered, dynamic network with multiple\nsources is considered, and sources use a retransmission strategy in order to\nimprove packet delivery probability. The optimization problem is formulated as\na Markov Decision Process, where constraints and objective functions are ratios\nof time-averaged cost functions. The optimal strategy is found as the solution\nof a Linear Fractional Program, where the optimization variables are the\nsteady-state probability of state-action pairs. Numerical results illustrate\nthe dependence of optimal transmission/interference strategies on the\nconstraints imposed on the network. \n\n"}
{"id": "1009.4386", "contents": "Title: Decentralised Learning MACs for Collision-free Access in WLANs Abstract: By combining the features of CSMA and TDMA, fully decentralised WLAN MAC\nschemes have recently been proposed that converge to collision-free schedules.\nIn this paper we describe a MAC with optimal long-run throughput that is almost\ndecentralised. We then design two \\changed{schemes} that are practically\nrealisable, decentralised approximations of this optimal scheme and operate\nwith different amounts of sensing information. We achieve this by (1)\nintroducing learning algorithms that can substantially speed up convergence to\ncollision free operation; (2) developing a decentralised schedule length\nadaptation scheme that provides long-run fair (uniform) access to the medium\nwhile maintaining collision-free access for arbitrary numbers of stations. \n\n"}
{"id": "1009.4798", "contents": "Title: Role of feedback and broadcasting in the naming game Abstract: The naming game (NG) describes the agreement dynamics of a population of\nagents that interact locally in a pairwise fashion, and in recent years\nstatistical physics tools and techniques have greatly contributed to shed light\non its rich phenomenology. Here we investigate in details the role played by\nthe way in which the two agents update their states after an interaction. We\nshow that slightly modifying the NG rules in terms of which agent performs the\nupdate in given circumstances (i.e. after a success) can either alter\ndramatically the overall dynamics or leave it qualitatively unchanged. We\nunderstand analytically the first case by casting the model in the broader\nframework of a generalized NG. As for the second case, on the other hand, we\nnote that the modified rule reproducing the main features of the usual NG\ncorresponds in fact to a simplification of it consisting in the elimination of\nfeedback between the agents. This allows us to introduce and study a very\nnatural broadcasting scheme on networks that can be potentially relevant for\ndifferent applications, such as the design and implementation of autonomous\nsensor networks, as pointed out in the recent literature. \n\n"}
{"id": "1009.5012", "contents": "Title: Bulk File Download Throughput in a Single Station WLAN with Nonzero\n  Propagation Delay Abstract: We analyze TCP-controlled bulk file transfers in a single station (STA) WLAN\nwith nonzero propagation delay between the file server and the WLAN. Our\napproach is to model the flow of packets as a closed queueing network (BCMP\nnetwork) with 3 service centres, one each for the Access Point (AP) and the\nSTA, and the third for the propagation delay. The service rates of the first\ntwo are obtained by analyzing the WLAN MAC. Simulations show a very close match\nwith the theory. \n\n"}
{"id": "1010.0041", "contents": "Title: Throughput and Collision Analysis of Multi-Channel Multi-Stage Spectrum\n  Sensing Algorithms Abstract: Multi-stage sensing is a novel concept that refers to a general class of\nspectrum sensing algorithms that divide the sensing process into a number of\nsequential stages. The number of sensing stages and the sensing technique per\nstage can be used to optimize performance with respect to secondary user\nthroughput and the collision probability between primary and secondary users.\nSo far, the impact of multi-stage sensing on network throughput and collision\nprobability for a realistic network model is relatively unexplored. Therefore,\nwe present the first analytical framework which enables performance evaluation\nof different multi-channel multi-stage spectrum sensing algorithms for\nOpportunistic Spectrum Access networks. The contribution of our work lies in\nstudying the effect of the following parameters on performance: number of\nsensing stages, physical layer sensing techniques and durations per each stage,\nsingle and parallel channel sensing and access, number of available channels,\nprimary and secondary user traffic, buffering of incoming secondary user\ntraffic, as well as MAC layer sensing algorithms. Analyzed performance metrics\ninclude the average secondary user throughput and the average collision\nprobability between primary and secondary users. Our results show that when the\nprobability of primary user mis-detection is constrained, the performance of\nmulti-stage sensing is, in most cases, superior to the single stage sensing\ncounterpart. Besides, prolonged channel observation at the first stage of\nsensing decreases the collision probability considerably, while keeping the\nthroughput at an acceptable level. Finally, in realistic primary user traffic\nscenarios, using two stages of sensing provides a good balance between\nsecondary users throughput and collision probability while meeting successful\ndetection constraints subjected by Opportunistic Spectrum Access communication. \n\n"}
{"id": "1010.0476", "contents": "Title: Interference Alignment as a Rank Constrained Rank Minimization Abstract: We show that the maximization of the sum degrees-of-freedom for the static\nflat-fading multiple-input multiple-output (MIMO) interference channel is\nequivalent to a rank constrained rank minimization problem (RCRM), when the\nsignal spaces span all available dimensions. The rank minimization corresponds\nto maximizing interference alignment (IA) so that interference spans the lowest\ndimensional subspace possible. The rank constraints account for the useful\nsignal spaces spanning all available spatial dimensions. That way, we\nreformulate all IA requirements to requirements involving ranks. Then, we\npresent a convex relaxation of the RCRM problem inspired by recent results in\ncompressed sensing and low-rank matrix completion theory that rely on\napproximating rank with the nuclear norm. We show that the convex envelope of\nthe sum of ranks of the interference matrices is the normalized sum of their\ncorresponding nuclear norms and introduce tractable constraints that are\nasymptotically equivalent to the rank constraints for the initial problem. We\nalso show that our heuristic relaxation can be tuned for the multi-cell\ninterference channel. Furthermore, we experimentally show that in many cases\nthe proposed algorithm attains perfect interference alignment and in some cases\noutperforms previous approaches for finding precoding and zero-forcing matrices\nfor interference alignment. \n\n"}
{"id": "1010.0485", "contents": "Title: Distributed Storage Codes Meet Multiple-Access Wiretap Channels Abstract: We consider {\\it i)} the overhead minimization of maximum-distance separable\n(MDS) storage codes for the repair of a single failed node and {\\it ii)} the\ntotal secure degrees-of-freedom (S-DoF) maximization in a multiple-access\ncompound wiretap channel. We show that the two problems are connected.\nSpecifically, the overhead minimization for a single node failure of an {\\it\noptimal} MDS code, i.e. one that can achieve the information theoretic overhead\nminimum, is equivalent to maximizing the S-DoF in a multiple-access compound\nwiretap channel. Additionally, we show that maximizing the S-DoF in a\nmultiple-access compound wiretap channel is equivalent to minimizing the\noverhead of an MDS code for the repair of a departed node. An optimal MDS code\nmaps to a full S-DoF channel and a full S-DoF channel maps to an MDS code with\nminimum repair overhead for one failed node. We also state a general framework\nfor code-to-channel and channel-to-code mappings and performance bounds between\nthe two settings. The underlying theme for all connections presented is\ninterference alignment (IA). The connections between the two problems become\napparent when we restate IA as an optimization problem. Specifically, we\nformulate the overhead minimization and the S-DoF maximization as rank\nconstrained, sum-rank and max-rank minimization problems respectively. The\nderived connections allow us to map repair strategies of recently discovered\nrepair codes to beamforming matrices and characterize the maximum S-DoF for the\nsingle antenna multiple-access compound wiretap channel. \n\n"}
{"id": "1010.2667", "contents": "Title: Virtual Full-Duplex Wireless Communication via Rapid On-Off-Division\n  Duplex Abstract: This paper introduces a novel paradigm for design- ing the physical and\nmedium access control (MAC) layers of mobile ad hoc or peer-to-peer networks\nformed by half-duplex radios. A node equipped with such a radio cannot\nsimultaneously transmit and receive useful signals at the same frequency.\nUnlike in conventional designs, where a node's transmission frames are\nscheduled away from its reception, each node transmits its signal through a\nrandomly generated on-off duplex mask (or signature) over every frame interval,\nand receive a signal through each of its own off-slots. This is called rapid\non-off- division duplex (RODD). Over the period of a single frame, every node\ncan transmit a message to some or all of its peers, and may simultaneously\nreceive a message from each peer. Thus RODD achieves virtual full-duplex\ncommunication using half-duplex radios and can simplify the design of higher\nlayers of a network protocol stack significantly. The throughput of RODD is\nevaluated under some general settings, which is significantly larger than that\nof ALOHA. RODD is especially efficient in case the dominant traffic is\nsimultaneous broadcast from nodes to their one-hop peers, such as in\nspontaneous wireless social networks, emergency situations or on battlefield.\nImportant design issues of peer discovery, distribution of on-off signatures,\nsynchronization and error-control coding are also addressed. \n\n"}
{"id": "1010.2993", "contents": "Title: Broadcasting with an Energy Harvesting Rechargeable Transmitter Abstract: In this paper, we investigate the transmission completion time minimization\nproblem in a two-user additive white Gaussian noise (AWGN) broadcast channel,\nwhere the transmitter is able to harvest energy from the nature, using a\nrechargeable battery. The harvested energy is modeled to arrive at the\ntransmitter randomly during the course of transmissions. The transmitter has a\nfixed number of packets to be delivered to each receiver. Our goal is to\nminimize the time by which all of the packets for both users are delivered to\ntheir respective destinations. To this end, we optimize the transmit powers and\ntransmission rates intended for both users. We first analyze the structural\nproperties of the optimal transmission policy. We prove that the optimal total\ntransmit power has the same structure as the optimal single-user transmit\npower. We also prove that there exists a cut-off power level for the stronger\nuser. If the optimal total transmit power is lower than this cut-off level, all\ntransmit power is allocated to the stronger user, and when the optimal total\ntransmit power is larger than this cut-off level, all transmit power above this\nlevel is allocated to the weaker user. Based on these structural properties of\nthe optimal policy, we propose an algorithm that yields the globally optimal\noff-line scheduling policy. Our algorithm is based on the idea of reducing the\ntwo-user broadcast channel problem into a single-user problem as much as\npossible. \n\n"}
{"id": "1010.4249", "contents": "Title: Wireless Capacity with Oblivious Power in General Metrics Abstract: The capacity of a wireless network is the maximum possible amount of\nsimultaneous communication, taking interference into account.\n  Formally, we treat the following problem. Given is a set of links, each a\nsender-receiver pair located in a metric space, and an assignment of power to\nthe senders. We seek a maximum subset of links that are feasible in the SINR\nmodel: namely, the signal received on each link should be larger than the sum\nof the interferences from the other links. We give a constant-factor\napproximation that holds for any length-monotone, sub-linear power assignment\nand any distance metric.\n  We use this to give essentially tight characterizations of capacity\nmaximization under power control using oblivious power assignments.\nSpecifically, we show that the mean power assignment is optimal for capacity\nmaximization of bi-directional links, and give a tight $\\theta(\\log\nn)$-approximation of scheduling bi-directional links with power control using\noblivious power. For uni-directional links we give a nearly optimal $O(\\log n +\n\\log \\log \\Delta)$-approximation to the power control problem using mean power,\nwhere $\\Delta$ is the ratio of longest and shortest links. Combined, these\nresults clarify significantly the centralized complexity of wireless\ncommunication problems. \n\n"}
{"id": "1010.4858", "contents": "Title: S-MATE: Secure Coding-based Multipath Adaptive Traffic Engineering Abstract: There have been several approaches to provisioning traffic between core\nnetwork nodes in Internet Service Provider (ISP) networks. Such approaches aim\nto minimize network delay, increase network capacity, and enhance network\nsecurity services. MATE (Multipath Adaptive Traffic Engineering) protocol has\nbeen proposed for multipath adaptive traffic engineering between an ingress\nnode (source) and an egress node (destination). Its novel idea is to avoid\nnetwork congestion and attacks that might exist in edge and node disjoint paths\nbetween two core network nodes.\n  This paper builds an adaptive, robust, and reliable traffic engineering\nscheme for better performance of communication network operations. This will\nalso provision quality of service (QoS) and protection of traffic engineering\nto maximize network efficiency. Specifically, we present a new approach, S-MATE\n(secure MATE) is developed to protect the network traffic between two core\nnodes (routers or switches) in a cloud network. S-MATE secures against a single\nlink attack/failure by adding redundancy in one of the operational paths\nbetween the sender and receiver. The proposed scheme can be built to secure\ncore networks such as optical and IP networks. \n\n"}
{"id": "1010.4920", "contents": "Title: Jointly Optimal Channel Pairing and Power Allocation for Multichannel\n  Multihop Relaying Abstract: We study the problem of channel pairing and power allocation in a\nmultichannel multihop relay network to enhance the end-to-end data rate. Both\namplify-and-forward (AF) and decode-and-forward (DF) relaying strategies are\nconsidered. Given fixed power allocation to the channels, we show that channel\npairing over multiple hops can be decomposed into independent pairing problems\nat each relay, and a sorted-SNR channel pairing strategy is sum-rate optimal,\nwhere each relay pairs its incoming and outgoing channels by their SNR order.\nFor the joint optimization of channel pairing and power allocation under both\ntotal and individual power constraints, we show that the problem can be\ndecoupled into two subproblems solved separately. This separation principle is\nestablished by observing the equivalence between sorting SNRs and sorting\nchannel gains in the jointly optimal solution. It significantly reduces the\ncomputational complexity in finding the jointly optimal solution. It follows\nthat the channel pairing problem in joint optimization can be again decomposed\ninto independent pairing problems at each relay based on sorted channel gains.\nThe solution for optimizing power allocation for DF relaying is also provided,\nas well as an asymptotically optimal solution for AF relaying. Numerical\nresults are provided to demonstrate substantial performance gain of the jointly\noptimal solution over some suboptimal alternatives. It is also observed that\nmore gain is obtained from optimal channel pairing than optimal power\nallocation through judiciously exploiting the variation among multiple\nchannels. Impact of the variation of channel gain, the number of channels, and\nthe number of hops on the performance gain is also studied through numerical\nexamples. \n\n"}
{"id": "1010.5493", "contents": "Title: On Wireless Scheduling Using the Mean Power Assignment Abstract: In this paper the problem of scheduling with power control in wireless\nnetworks is studied: given a set of communication requests, one needs to assign\nthe powers of the network nodes, and schedule the transmissions so that they\ncan be done in a minimum time, taking into account the signal interference of\nconcurrently transmitting nodes. The signal interference is modeled by SINR\nconstraints. Approximation algorithms are given for this problem, which use the\nmean power assignment. The problem of schduling with fixed mean power\nassignment is also considered, and approximation guarantees are proven. \n\n"}
{"id": "1011.1892", "contents": "Title: Pushing BitTorrent Locality to the Limit Abstract: Peer-to-peer (P2P) locality has recently raised a lot of interest in the\ncommunity. Indeed, whereas P2P content distribution enables financial savings\nfor the content providers, it dramatically increases the traffic on inter-ISP\nlinks. To solve this issue, the idea to keep a fraction of the P2P traffic\nlocal to each ISP was introduced a few years ago. Since then, P2P solutions\nexploiting locality have been introduced. However, several fundamental issues\non locality still need to be explored. In particular, how far can we push\nlocality, and what is, at the scale of the Internet, the reduction of traffic\nthat can be achieved with locality? In this paper, we perform extensive\nexperiments on a controlled environment with up to 10,000 BitTorrent clients to\nevaluate the impact of high locality on inter-ISP links traffic and peers\ndownload completion time. We introduce two simple mechanisms that make high\nlocality possible in challenging scenarios and we show that we save up to\nseveral orders of magnitude inter-ISP traffic compared to traditional locality\nwithout adversely impacting peers download completion time. In addition, we\ncrawled 214,443 torrents representing 6,113,224 unique peers spread among 9,605\nASes. We show that whereas the torrents we crawled generated 11.6 petabytes of\ninter-ISP traffic, our locality policy implemented for all torrents could have\nreduced the global inter-ISP traffic by up to 40%. \n\n"}
{"id": "1011.2361", "contents": "Title: Distributed Storage Codes with Repair-by-Transfer and Non-achievability\n  of Interior Points on the Storage-Bandwidth Tradeoff Abstract: Regenerating codes are a class of recently developed codes for distributed\nstorage that, like Reed-Solomon codes, permit data recovery from any subset of\nk nodes within the n-node network. However, regenerating codes possess in\naddition, the ability to repair a failed node by connecting to an arbitrary\nsubset of d nodes. It has been shown that for the case of functional-repair,\nthere is a tradeoff between the amount of data stored per node and the\nbandwidth required to repair a failed node. A special case of functional-repair\nis exact-repair where the replacement node is required to store data identical\nto that in the failed node. Exact-repair is of interest as it greatly\nsimplifies system implementation. The first result of the paper is an explicit,\nexact-repair code for the point on the storage-bandwidth tradeoff corresponding\nto the minimum possible repair bandwidth, for the case when d=n-1. This code\nhas a particularly simple graphical description and most interestingly, has the\nability to carry out exact-repair through mere transfer of data and without any\nneed to perform arithmetic operations. Hence the term `repair-by-transfer'. The\nsecond result of this paper shows that the interior points on the\nstorage-bandwidth tradeoff cannot be achieved under exact-repair, thus pointing\nto the existence of a separate tradeoff under exact-repair. Specifically, we\nidentify a set of scenarios, termed `helper node pooling', and show that it is\nthe necessity to satisfy such scenarios that over-constrains the system. \n\n"}
{"id": "1011.2835", "contents": "Title: Approximately Optimal Wireless Broadcasting Abstract: We study a wireless broadcast network, where a single source reliably\ncommunicates independent messages to multiple destinations, with the aid of\nrelays and cooperation between destinations. The wireless nature of the medium\nis captured by the broadcast nature of transmissions as well as the\nsuperposition of all transmit signals plus independent Gaussian noise at the\nreceived signal at any radio. We propose a scheme that can achieve rate tuples\nwithin a constant gap away from the cut-set bound, where the constant is\nindependent of channel coefficients and power constraints.\n  The proposed scheme operates in two steps. The inner code, in which the\nrelays perform a quantize-and-encode operation, is constructed by lifting a\nscheme designed for a corresponding discrete superposition network. The outer\ncode is a Marton code for the non-Gaussian vector broadcast channel induced by\nthe relaying scheme, and is constructed by adopting a ``receiver-centric''\nviewpoint. \n\n"}
{"id": "1011.3594", "contents": "Title: Approaching Throughput-optimality in Distributed CSMA Scheduling\n  Algorithms with Collisions Abstract: It was shown recently that CSMA (Carrier Sense Multiple Access)-like\ndistributed algorithms can achieve the maximal throughput in wireless networks\n(and task processing networks) under certain assumptions. One important, but\nidealized assumption is that the sensing time is negligible, so that there is\nno collision. In this paper, we study more practical CSMA-based scheduling\nalgorithms with collisions. First, we provide a Markov chain model and give an\nexplicit throughput formula which takes into account the cost of collisions and\noverhead. The formula has a simple form since the Markov chain is \"almost\"\ntime-reversible. Second, we propose transmission-length control algorithms to\napproach throughput optimality in this case. Sufficient conditions are given to\nensure the convergence and stability of the proposed algorithms. Finally, we\ncharacterize the relationship between the CSMA parameters (such as the maximum\npacket lengths) and the achievable capacity region. \n\n"}
{"id": "1011.4654", "contents": "Title: Towards a Collision-Free WLAN: Dynamic Parameter Adjustment in CSMA/E2CA Abstract: Carrier Sense Multiple Access with Enhanced Collision Avoidance (CSMA/ECA) is\na distributed MAC protocol that allows collision-free access to the medium in\nWLAN. The only difference between CSMA/ECA and the well-known CSMA/CA is that\nthe former uses a deterministic backoff after successful transmissions.\nCollision-free operation is reached after a transient state during which some\ncollisions may occur. This article shows that the duration of the transient\nstate can be shortened by appropriately setting the contention parameters.\nStandard absorbing Markov Chain theory can be used to describe the behaviour of\nthe system in the transient state and to predict the expected number of slots\nto reach the collision-free operation.\n  The article also introduces CSMA/E2CA, in which a deterministic backoff is\nused two consecutive times after a successful transmission. CSMA/E2CA converges\nquicker to collision-free operation and delivers higher performance than\nCSMA/CA in harsh wireless scenarios with high frame error rates.\n  To achieve collision-free operations when the number of contenders is large,\nit may be necessary to dynamically adjust the contention parameter. The last\npart of the article suggests an approach for such parameter adjustment which is\nvalidated by simulation results. \n\n"}
{"id": "1011.6218", "contents": "Title: Coordinated Transmissions to Direct and Relayed Users in Wireless\n  Cellular Systems Abstract: The ideas of wireless network coding at the physical layer promise high\nthroughput gains in wireless systems with relays and multi-way traffic flows.\nThis gain can be ascribed to two principles: (1) joint transmission of multiple\ncommunication flows and (2) usage of \\emph{a priori} information to cancel the\ninterference. In this paper we use these principles to devise new transmission\nschemes in wireless cellular systems that feature both users served directly by\nthe base stations (direct users) and users served through relays (relayed\nusers). We present four different schemes for \\emph{coordinated transmission}\nof uplink and downlink traffic in which one direct and one relayed user are\nserved. These schemes are then used as building blocks in multi-user scenarios,\nwhere we present several schemes for scheduling pairs of users for coordinated\ntransmissions. The optimal scheme involves exhaustive search of the best user\npair in terms of overall rate. We propose several suboptimal scheduling\nschemes, which perform closely to the optimal scheme. The numerical results\nshow a substantial increase in the system--level rate with respect to the\nsystems with non--coordinated transmissions. \n\n"}
{"id": "1012.4815", "contents": "Title: Analytical Modeling of Saturation Throughput in Power Save Mode of an\n  IEEE 802.11 Infrastructure WLAN Abstract: We consider a single station (STA) in the Power Save Mode (PSM) of an IEEE\n802.11 infrastructure WLAN. This STA is assumed to be carrying uplink and\ndownlink traffic via the access point (AP). We assume that the transmission\nqueues of the AP and the STA are saturated, i.e., the AP and the STA always\nhave at least one packet to send. For this scenario, it is observed that uplink\nand downlink throughputs achieved are different. The reason behind the\ndifference is the long term attempt rates of the STA and the AP due to the PSM\nprotocol. In this paper we first obtain the the long term attempt rates of the\nSTA and the AP and using these, we obtain the saturation throughputs of the AP\nand the STA. We provide a validation of analytical results using the NS-2\nsimulator. \n\n"}
{"id": "1012.5174", "contents": "Title: SNEED: Enhancing Network Security Services Using Network Coding and\n  Joint Capacity Abstract: Traditional network security protocols depend mainly on developing\ncryptographic schemes and on using biometric methods. These have led to several\nnetwork security protocols that are unbreakable based on difficulty of solving\nuntractable mathematical problems such as factoring large integers.\n  In this paper, Security of Networks Employing Encoding and Decoding (SNEED)\nis developed to mitigate single and multiple link attacks. Network coding and\nshared capacity among the working paths are used to provide data protection and\ndata integrity against network attackers and eavesdroppers.\n  SNEED can be incorporated into various applications in on-demand TV,\nsatellite communications and multimedia security. Finally, It is shown that\nSNEED can be implemented easily where there are k edge disjoint paths between\ntwo core nodes (routers or switches) in an enterprize network. \n\n"}
{"id": "1101.5130", "contents": "Title: Analytical Evaluation of Fractional Frequency Reuse for OFDMA Cellular\n  Networks Abstract: Fractional frequency reuse (FFR) is an interference management technique\nwell-suited to OFDMA-based cellular networks wherein the cells are partitioned\ninto spatial regions with different frequency reuse factors. To date, FFR\ntechniques have been typically been evaluated through system-level simulations\nusing a hexagonal grid for the base station locations. This paper instead\nfocuses on analytically evaluating the two main types of FFR deployments -\nStrict FFR and Soft Frequency Reuse (SFR) - using a Poisson point process to\nmodel the base station locations. The results are compared with the standard\ngrid model and an actual urban deployment. Under reasonable special cases for\nmodern cellular networks, our results reduce to simple closed-form expressions,\nwhich provide insight into system design guidelines and the relative merits of\nStrict FFR, SFR, universal reuse, and fixed frequency reuse. We observe that\nFFR provides an increase in the sum-rate as well as the well-known benefit of\nimproved coverage for cell-edge users. Finally, a SINR-proportional resource\nallocation strategy is proposed based on the analytical expressions, showing\nthat Strict FFR provides greater overall network throughput at low traffic\nloads, while SFR better balances the requirements of interference reduction and\nresource efficiency when the traffic load is high. \n\n"}
{"id": "1101.5463", "contents": "Title: Walking on a Graph with a Magnifying Glass: Stratified Sampling via\n  Weighted Random Walks Abstract: Our objective is to sample the node set of a large unknown graph via\ncrawling, to accurately estimate a given metric of interest. We design a random\nwalk on an appropriately defined weighted graph that achieves high efficiency\nby preferentially crawling those nodes and edges that convey greater\ninformation regarding the target metric. Our approach begins by employing the\ntheory of stratification to find optimal node weights, for a given estimation\nproblem, under an independence sampler. While optimal under independence\nsampling, these weights may be impractical under graph crawling due to\nconstraints arising from the structure of the graph. Therefore, the edge\nweights for our random walk should be chosen so as to lead to an equilibrium\ndistribution that strikes a balance between approximating the optimal weights\nunder an independence sampler and achieving fast convergence. We propose a\nheuristic approach (stratified weighted random walk, or S-WRW) that achieves\nthis goal, while using only limited information about the graph structure and\nthe node properties. We evaluate our technique in simulation, and\nexperimentally, by collecting a sample of Facebook college users. We show that\nS-WRW requires 13-15 times fewer samples than the simple re-weighted random\nwalk (RW) to achieve the same estimation accuracy for a range of metrics. \n\n"}
{"id": "1102.2785", "contents": "Title: Minimizing interference in ad-hoc networks with bounded communication\n  radius Abstract: We consider a topology control problem in which we are given a set of $n$\nsensors in the plane and we would like to assign a communication radius to each\nof them. The radii assignment must generate a strongly connected network and\nhave low receiver-based interference (i.e., we minimize the largest in-degree\nof the network). We give an algorithm that generates a network with $O(\\log\n\\Delta)$ interference, where $\\Delta$ is the interference of a uniform-radius\nad-hoc network. We then adapt the construction to the case in which no sensor\ncan have a communication radius larger than $R_{\\min}$, the minimum value\nneeded to obtain connectivity. We also show that $\\log \\Delta$ interference is\nneeded for some instances, making our algorithms asymptotically optimal. \n\n"}
{"id": "1103.2662", "contents": "Title: Cost Analysis of Redundancy Schemes for Distributed Storage Systems Abstract: Distributed storage infrastructures require the use of data redundancy to\nachieve high data reliability. Unfortunately, the use of redundancy introduces\nstorage and communication overheads, which can either reduce the overall\nstorage capacity of the system or increase its costs. To mitigate the storage\nand communication overhead, different redundancy schemes have been proposed.\nHowever, due to the great variety of underlaying storage infrastructures and\nthe different application needs, optimizing these redundancy schemes for each\nstorage infrastructure is cumbersome. The lack of rules to determine the\noptimal level of redundancy for each storage configuration leads developers in\nindustry to often choose simpler redundancy schemes, which are usually not the\noptimal ones. In this paper we analyze the cost of different redundancy schemes\nand derive a set of rules to determine which redundancy scheme minimizes the\nstorage and the communication costs for a given system configuration.\nAdditionally, we use simulation to show that theoretically-optimal schemes may\nnot be viable in a realistic setting where nodes can go off-line and repairs\nmay be delayed. In these cases, we identify which are the trade-offs between\nthe storage and communication overheads of the redundancy scheme and its data\nreliability. \n\n"}
{"id": "1103.4016", "contents": "Title: Delay Constrained Throughput Analysis of a Correlated MIMO Wireless\n  Channel Abstract: The maximum traffic arrival rate at the network for a given delay guarantee\n(delay constrained throughput) has been well studied for wired channels.\nHowever, few results are available for wireless channels, especially when\nmultiple antennas are employed at the transmitter and receiver. In this work,\nwe analyze the network delay constrained throughput of a multiple input\nmultiple output (MIMO) wireless channel with time-varying spatial correlation.\nThe MIMO channel is modeled via its virtual representation, where the\nindividual spatial paths between the antenna pairs are Gilbert-Elliot channels.\nThe whole system is then described by a K-State Markov chain, where K depends\nupon the degree of freedom (DOF) of the channel. We prove that the DOF based\nmodeling is indeed accurate. Furthermore, we study the impact of the delay\nrequirements at the network layer, violation probability and the number of\nantennas on the throughput under different fading speeds and signal strength. \n\n"}
{"id": "1104.0327", "contents": "Title: Asymptotically Tight Steady-State Queue Length Bounds Implied By Drift\n  Conditions Abstract: The Foster-Lyapunov theorem and its variants serve as the primary tools for\nstudying the stability of queueing systems. In addition, it is well known that\nsetting the drift of the Lyapunov function equal to zero in steady-state\nprovides bounds on the expected queue lengths. However, such bounds are often\nvery loose due to the fact that they fail to capture resource pooling effects.\nThe main contribution of this paper is to show that the approach of \"setting\nthe drift of a Lyapunov function equal to zero\" can be used to obtain bounds on\nthe steady-state queue lengths which are tight in the heavy-traffic limit. The\nkey is to establish an appropriate notion of state-space collapse in terms of\nsteady-state moments of weighted queue length differences, and use this\nstate-space collapse result when setting the Lyapunov drift equal to zero. As\nan application of the methodology, we prove the steady-state equivalent of the\nheavy-traffic optimality result of Stolyar for wireless networks operating\nunder the MaxWeight scheduling policy. \n\n"}
{"id": "1104.1227", "contents": "Title: Intervention in Power Control Games With Selfish Users Abstract: We study the power control problem in wireless ad hoc networks with selfish\nusers. Without incentive schemes, selfish users tend to transmit at their\nmaximum power levels, causing significant interference to each other. In this\npaper, we study a class of incentive schemes based on intervention to induce\nselfish users to transmit at desired power levels. An intervention scheme can\nbe implemented by introducing an intervention device that can monitor the power\nlevels of users and then transmit power to cause interference to users. We\nmainly consider first-order intervention rules based on individual transmit\npowers. We derive conditions on design parameters and the intervention\ncapability to achieve a desired outcome as a (unique) Nash equilibrium and\npropose a dynamic adjustment process that the designer can use to guide users\nand the intervention device to the desired outcome. The effect of using\nintervention rules based on aggregate receive power is also analyzed. Our\nresults show that with perfect monitoring intervention schemes can be designed\nto achieve any positive power profile while using interference from the\nintervention device only as a threat. We also analyze the case of imperfect\nmonitoring and show that a performance loss can occur. Lastly, simulation\nresults are presented to illustrate the performance improvement from using\nintervention rules and compare the performances of different intervention\nrules. \n\n"}
{"id": "1104.2156", "contents": "Title: Structural Analysis of Network Traffic Matrix via Relaxed Principal\n  Component Pursuit Abstract: The network traffic matrix is widely used in network operation and\nmanagement. It is therefore of crucial importance to analyze the components and\nthe structure of the network traffic matrix, for which several mathematical\napproaches such as Principal Component Analysis (PCA) were proposed. In this\npaper, we first argue that PCA performs poorly for analyzing traffic matrix\nthat is polluted by large volume anomalies, and then propose a new\ndecomposition model for the network traffic matrix. According to this model, we\ncarry out the structural analysis by decomposing the network traffic matrix\ninto three sub-matrices, namely, the deterministic traffic, the anomaly traffic\nand the noise traffic matrix, which is similar to the Robust Principal\nComponent Analysis (RPCA) problem previously studied in [13]. Based on the\nRelaxed Principal Component Pursuit (Relaxed PCP) method and the Accelerated\nProximal Gradient (APG) algorithm, we present an iterative approach for\ndecomposing a traffic matrix, and demonstrate its efficiency and flexibility by\nexperimental results. Finally, we further discuss several features of the\ndeterministic and noise traffic. Our study develops a novel method for the\nproblem of structural analysis of the traffic matrix, which is robust against\npollution of large volume anomalies. \n\n"}
{"id": "1104.5200", "contents": "Title: Nearly Optimal Bounds for Distributed Wireless Scheduling in the SINR\n  Model Abstract: We study the wireless scheduling problem in the SINR model. More\nspecifically, given a set of $n$ links, each a sender-receiver pair, we wish to\npartition (or \\emph{schedule}) the links into the minimum number of slots, each\nsatisfying interference constraints allowing simultaneous transmission. In the\nbasic problem, all senders transmit with the same uniform power.\n  We give a distributed $O(\\log n)$-approximation algorithm for the scheduling\nproblem, matching the best ratio known for centralized algorithms. It holds in\narbitrary metric space and for every length-monotone and sublinear power\nassignment. It is based on an algorithm of Kesselheim and V\\\"ocking, whose\nanalysis we improve by a logarithmic factor. We show that every distributed\nalgorithm uses $\\Omega(\\log n)$ slots to schedule certain instances that\nrequire only two slots, which implies that the best possible absolute\nperformance guarantee is logarithmic. \n\n"}
{"id": "1105.2243", "contents": "Title: More about Base Station Location Games Abstract: This paper addresses the problem of locating base stations in a certain area\nwhich is highly populated by mobile stations; each mobile station is assumed to\nselect the closest base station. Base stations are modeled by players who\nchoose their best location for maximizing their uplink throughput. The approach\nof this paper is to make some simplifying assumptions in order to get\ninterpretable analytical results and insights to the problem under study.\nSpecifically, a relatively complete Nash equilibrium (NE) analysis is conducted\n(existence, uniqueness, determination, and efficiency). Then, assuming that the\nbase station location can be adjusted dynamically, the best-response dynamics\nand reinforcement learning algorithm are applied, discussed, and illustrated\nthrough numerical results. \n\n"}
{"id": "1105.3416", "contents": "Title: Implementation of Physical-layer Network Coding Abstract: This paper presents the first implementation of a two-way relay network based\non the principle of physical-layer network coding. To date, only a simplified\nversion of physical-layer network coding (PNC) method, called analog network\ncoding (ANC), has been successfully implemented. The advantage of ANC is that\nit is simple to implement; the disadvantage, on the other hand, is that the\nrelay amplifies the noise along with the signal before forwarding the signal.\nPNC systems in which the relay performs XOR or other denoising PNC mappings of\nthe received signal have the potential for significantly better performance.\nHowever, the implementation of such PNC systems poses many challenges. For\nexample, the relay must be able to deal with symbol and carrier-phase\nasynchronies of the simultaneous signals received from the two end nodes, and\nthe relay must perform channel estimation before detecting the signals. We\ninvestigate a PNC implementation in the frequency domain, referred to as FPNC,\nto tackle these challenges. FPNC is based on OFDM. In FPNC, XOR mapping is\nperformed on the OFDM samples in each subcarrier rather than on the samples in\nthe time domain. We implement FPNC on the universal soft radio peripheral\n(USRP) platform. Our implementation requires only moderate modifications of the\npacket preamble design of 802.11a/g OFDM PHY. With the help of the cyclic\nprefix (CP) in OFDM, symbol asynchrony and the multi-path fading effects can be\ndealt with in a similar fashion. Our experimental results show that\nsymbol-synchronous and symbol-asynchronous FPNC have essentially the same BER\nperformance, for both channel-coded and unchannel-coded FPNC. \n\n"}
{"id": "1106.0027", "contents": "Title: On the geometry of wireless network multicast in 2-D Abstract: We provide a geometric solution to the problem of optimal relay positioning\nto maximize the multicast rate for low-SNR networks. The networks we consider,\nconsist of a single source, multiple receivers and the only intermediate and\nlocatable node as the relay. We construct network the hypergraph of the system\nnodes from the underlying information theoretic model of low-SNR regime that\noperates using superposition coding and FDMA in conjunction (which we call the\n\"achievable hypergraph model\"). We make the following contributions. 1) We show\nthat the problem of optimal relay positioning maximizing the multicast rate can\nbe completely decoupled from the flow optimization by noticing and exploiting\ngeometric properties of multicast flow. 2) All the flow maximizing the\nmulticast rate is sent over at most two paths, in succession. The relay\nposition is dependent only on one path (out of the two), irrespective of the\nnumber of receiver nodes in the system. Subsequently, we propose simple and\nefficient geometric algorithms to compute the optimal relay position. 3)\nFinally, we show that in our model at the optimal relay position, the\ndifference between the maximized multicast rate and the cut-set bound is\nminimum. We solve the problem for all (Ps,Pr) pairs of source and relay\ntransmit powers and the path loss exponent \\alpha greater than 2. \n\n"}
{"id": "1106.0735", "contents": "Title: Cross-Layer Scheduling for Cooperative Multi-Hop Cognitive Radio\n  Networks Abstract: The paper aims to design cross-layer optimal scheduling algorithms for\ncooperative multi-hop Cognitive Radio Networks (CRNs), where secondary users\n(SUs) assist primary user (PU)'s multi-hop transmissions and in return gain\nauthorization to access a share of the spectrum. We build two models for two\ndifferent types of PUs, corresponding to elastic and inelastic service classes.\nFor CRNs with elastic service, the PU maximizes its throughput while assigning\na time-share of the channel to SUs proportional to SUs' assistance. For the\ninelastic case, the PU is guaranteed a minimum utility. The proposed algorithm\nfor elastic PU model can achieve arbitrarily close to the optimal PU\nthroughput, while the proposed algorithm for inelastic PU model can achieve\narbitrarily close to the optimal SU utility. Both algorithms provide\ndeterministic upper-bounds for PU queue backlogs. In addition, we show a\ntradeoff between throughput/utility and PU's average end-to-end delay\nupper-bounds for both algorithms. Furthermore, the algorithms work in both\nbacklogged as well as arbitrary arrival rate systems. \n\n"}
{"id": "1106.2325", "contents": "Title: SVM and Dimensionality Reduction in Cognitive Radio with Experimental\n  Validation Abstract: There is a trend of applying machine learning algorithms to cognitive radio.\nOne fundamental open problem is to determine how and where these algorithms are\nuseful in a cognitive radio network. In radar and sensing signal processing,\nthe control of degrees of freedom (DOF)---or dimensionality---is the first\nstep, called pre-processing. In this paper, the combination of dimensionality\nreduction with SVM is proposed apart from only applying SVM for classification\nin cognitive radio. Measured Wi-Fi signals with high signal to noise ratio\n(SNR) are employed to the experiments. The DOF of Wi-Fi signals is extracted by\ndimensionality reduction techniques. Experimental results show that with\ndimensionality reduction, the performance of classification is much better with\nfewer features than that of without dimensionality reduction. The error rates\nof classification with only one feature of the proposed algorithm can match the\nerror rates of 13 features of the original data. The proposed method will be\nfurther tested in our cognitive radio network testbed. \n\n"}
{"id": "1106.4288", "contents": "Title: Continuum Limits of Markov Chains with Application to Network Modeling Abstract: In this paper we investigate the continuum limits of a class of Markov\nchains. The investigation of such limits is motivated by the desire to model\nvery large networks. We show that under some conditions, a sequence of Markov\nchains converges in some sense to the solution of a partial differential\nequation. Based on such convergence we approximate Markov chains modeling\nnetworks with a large number of components by partial differential equations.\nWhile traditional Monte Carlo simulation for very large networks is practically\ninfeasible, partial differential equations can be solved with reasonable\ncomputational overhead using well-established mathematical tools. \n\n"}
{"id": "1108.0443", "contents": "Title: Sparse Recovery with Graph Constraints: Fundamental Limits and\n  Measurement Construction Abstract: This paper addresses the problem of sparse recovery with graph constraints in\nthe sense that we can take additive measurements over nodes only if they induce\na connected subgraph. We provide explicit measurement constructions for several\nspecial graphs. A general measurement construction algorithm is also proposed\nand evaluated. For any given graph $G$ with $n$ nodes, we derive order optimal\nupper bounds of the minimum number of measurements needed to recover any\n$k$-sparse vector over $G$ ($M^G_{k,n}$). Our study suggests that $M^G_{k,n}$\nmay serve as a graph connectivity metric. \n\n"}
{"id": "1108.4129", "contents": "Title: Spatial Interactions of Peers and Performance of File Sharing Systems Abstract: We propose a new model for peer-to-peer networking which takes the network\nbottlenecks into account beyond the access. This model allows one to cope with\nkey features of P2P networking like degree or locality constraints or the fact\nthat distant peers often have a smaller rate than nearby peers. We show that\nthe spatial point process describing peers in their steady state then exhibits\nan interesting repulsion phenomenon. We analyze two asymptotic regimes of the\npeer-to-peer network: the fluid regime and the hard--core regime. We get closed\nform expressions for the mean (and in some cases the law) of the peer latency\nand the download rate obtained by a peer as well as for the spatial density of\npeers in the steady state of each regime, as well as an accurate approximation\nthat holds for all regimes. The analytical results are based on a mix of\nmathematical analysis and dimensional analysis and have important design\nimplications. The first of them is the existence of a setting where the\nequilibrium mean latency is a decreasing function of the load, a phenomenon\nthat we call super-scalability. \n\n"}
{"id": "1108.4226", "contents": "Title: Research on Wireless Multi-hop Networks: Current State and Challenges Abstract: Wireless multi-hop networks, in various forms and under various names, are\nbeing increasingly used in military and civilian applications. Studying\nconnectivity and capacity of these networks is an important problem. The\nscaling behavior of connectivity and capacity when the network becomes\nsufficiently large is of particular interest. In this position paper, we\nbriefly overview recent development and discuss research challenges and\nopportunities in the area, with a focus on the network connectivity. \n\n"}
{"id": "1108.5316", "contents": "Title: Link Failure Detection in Multi-hop Control Networks Abstract: A Multi-hop Control Network (MCN) consists of a plant where the communication\nbetween sensors, actuators and computational unit is supported by a wireless\nmulti-hop communication network, and data flow is performed using scheduling\nand routing of sensing and actuation data. We characterize the problem of\ndetecting the failure of links of the radio connectivity graph and provide\nnecessary and sufficient conditions on the plant dynamics and on the\ncommunication protocol. We also provide a methodology to \\emph{explicitly}\ndesign the network topology, scheduling and routing of a communication protocol\nin order to satisfy the above conditions. \n\n"}
{"id": "1108.5893", "contents": "Title: Edge-preserving self-healing: keeping network backbones densely\n  connected Abstract: Healing algorithms play a crucial part in distributed P2P networks where\nfailures occur continuously and frequently. Several self-healing algorithms\nhave been suggested recently [IPDPS'08, PODC'08, PODC'09, PODC'11] in a line of\nwork that has yielded gradual improvements in the properties ensured on the\ngraph. This work motivates a strong general phenomenon of edge-preserving\nhealing that aims at obtaining self-healing algorithms with the constraint that\nall original edges in the graph (not deleted by the adversary), be retained in\nevery intermediate graph.\n  The previous algorithms, in their nascent form, are not explicitly edge\npreserving. In this paper, we show they can be suitably modified (We introduce\nXheal+, an edge-preserving version of Xheal[PODC'11]). Towards this end, we\npresent a general self-healing model that unifies the previous models. The main\ncontribution of this paper is not in the technical complexity, rather in the\nsimplicity with which the edge-preserving property can be ensured and the\nmessage that this is a crucial property with several benefits. In particular,\nwe highlight this by showing that, almost as an immediate corollary, subgraph\ndensities are preserved or increased. Maintaining density is a notion motivated\nby the fact that in certain distributed networks, certain nodes may require and\ninitially have a larger number of inter-connections. It is vital that a healing\nalgorithm, even amidst failures, respect these requirements. Our suggested\nmodifications yield such subgraph density preservation as a by product. In\naddition, edge preservation helps maintain any subgraph induced property that\nis monotonic. Also, algorithms that are edge-preserving require minimal\nalteration of edges which can be an expensive cost in healing - something that\nhas not been modeled in any of the past work. \n\n"}
{"id": "1109.1325", "contents": "Title: Get the Most out of Your Sample: Optimal Unbiased Estimators using\n  Partial Information Abstract: Random sampling is an essential tool in the processing and transmission of\ndata. It is used to summarize data too large to store or manipulate and meet\nresource constraints on bandwidth or battery power. Estimators that are applied\nto the sample facilitate fast approximate processing of queries posed over the\noriginal data and the value of the sample hinges on the quality of these\nestimators.\n  Our work targets data sets such as request and traffic logs and sensor\nmeasurements, where data is repeatedly collected over multiple {\\em instances}:\ntime periods, locations, or snapshots.\n  We are interested in queries that span multiple instances, such as distinct\ncounts and distance measures over selected records. These queries are used for\napplications ranging from planning to anomaly and change detection.\n  Unbiased low-variance estimators are particularly effective as the relative\nerror decreases with the number of selected record keys.\n  The Horvitz-Thompson estimator, known to minimize variance for sampling with\n\"all or nothing\" outcomes (which reveals exacts value or no information on\nestimated quantity), is not optimal for multi-instance operations for which an\noutcome may provide partial information.\n  We present a general principled methodology for the derivation of (Pareto)\noptimal unbiased estimators over sampled instances and aim to understand its\npotential. We demonstrate significant improvement in estimate accuracy of\nfundamental queries for common sampling schemes. \n\n"}
{"id": "1109.2696", "contents": "Title: Node-Disjoint Multipath Spanners and their Relationship with\n  Fault-Tolerant Spanners Abstract: Motivated by multipath routing, we introduce a multi-connected variant of\nspanners. For that purpose we introduce the $p$-multipath cost between two\nnodes $u$ and $v$ as the minimum weight of a collection of $p$ internally\nvertex-disjoint paths between $u$ and $v$. Given a weighted graph $G$, a\nsubgraph $H$ is a $p$-multipath $s$-spanner if for all $u,v$, the $p$-multipath\ncost between $u$ and $v$ in $H$ is at most $s$ times the $p$-multipath cost in\n$G$. The $s$ factor is called the stretch. Building upon recent results on\nfault-tolerant spanners, we show how to build $p$-multipath spanners of\nconstant stretch and of $\\tO(n^{1+1/k})$ edges, for fixed parameters $p$ and\n$k$, $n$ being the number of nodes of the graph. Such spanners can be\nconstructed by a distributed algorithm running in $O(k)$ rounds. Additionally,\nwe give an improved construction for the case $p=k=2$. Our spanner $H$ has\n$O(n^{3/2})$ edges and the $p$-multipath cost in $H$ between any two node is at\nmost twice the corresponding one in $G$ plus $O(W)$, $W$ being the maximum edge\nweight. \n\n"}
{"id": "1109.2992", "contents": "Title: Downlink Capacity and Base Station Density in Cellular Networks Abstract: There have been a bulk of analytic results about the performance of cellular\nnetworks where base stations are regularly located on a hexagonal or square\nlattice. This regular model cannot reflect the reality, and tends to\noverestimate the network performance. Moreover, tractable analysis can be\nperformed only for a fixed location user (e.g., cell center or edge user). In\nthis paper, we use the stochastic geometry approach, where base stations can be\nmodeled as a homogeneous Poisson point process. We also consider the user\ndensity, and derive the user outage probability that an arbitrary user is under\noutage owing to low signal-to-interference-plus-noise ratio or high congestion\nby multiple users. Using the result, we calculate the density of success\ntransmissions in the downlink cellular network. An interesting observation is\nthat the success transmission density increases with the base station density,\nbut the increasing rate diminishes. This means that the number of base stations\ninstalled should be more than $n$-times to increase the network capacity by a\nfactor of $n$. Our results will provide a framework for performance analysis of\nthe wireless infrastructure with a high density of access points, which will\nsignificantly reduce the burden of network-level simulations. \n\n"}
{"id": "1111.2251", "contents": "Title: On the Optimal Transmission Scheme to Maximize Local Capacity in\n  Wireless Networks Abstract: We study the optimal transmission scheme that maximizes the local capacity in\ntwo-dimensional (2D) wireless networks. Local capacity is defined as the\naverage information rate received by a node randomly located in the network.\nUsing analysis based on analytical and numerical methods, we show that maximum\nlocal capacity can be obtained if simultaneous emitters are positioned in a\ngrid pattern based on equilateral triangles. We also compare this maximum local\ncapacity with the local capacity of slotted ALOHA scheme and our results show\nthat slotted ALOHA can achieve at least half of the maximum local capacity in\nwireless networks. \n\n"}
{"id": "1111.2619", "contents": "Title: A Security Architecture for Data Aggregation and Access Control in Smart\n  Grids Abstract: We propose an integrated architecture for smart grids, that supports data\naggregation and access control. Data can be aggregated by home area network,\nbuilding area network and neighboring area network in such a way that the\nprivacy of customers is protected. We use homomorphic encryption technique to\nachieve this. The consumer data that is collected is sent to the substations\nwhere it is monitored by remote terminal units (RTU). The proposed access\ncontrol mechanism gives selective access to consumer data stored in data\nrepositories and used by different smart grid users. Users can be maintenance\nunits, utility centers, pricing estimator units or analyzing and prediction\ngroups. We solve this problem of access control using cryptographic technique\nof attribute-based encryption. RTUs and users have attributes and cryptographic\nkeys distributed by several key distribution centers (KDC). RTUs send data\nencrypted under a set of attributes. Users can decrypt information provided\nthey have valid attributes. The access control scheme is distributed in nature\nand does not rely on a single KDC to distribute keys. Bobba \\emph{et al.}\n\\cite{BKAA09} proposed an access control scheme, which relies on a centralized\nKDC and is thus prone to single-point failure. The other requirement is that\nthe KDC has to be online, during data transfer which is not required in our\nscheme. Our access control scheme is collusion resistant, meaning that users\ncannot collude and gain access to data, when they are not authorized to access.\nWe theoretically analyze our schemes and show that the computation overheads\nare low enough to be carried out in smart grids. To the best of our knowledge,\nours is the first work on smart grids, which integrates these two important\nsecurity components (privacy preserving data aggregation and access control)\nand presents an overall security architecture in smart grids. \n\n"}
{"id": "1111.4768", "contents": "Title: Capacity of Multiple Unicast in Wireless Networks: A Polymatroidal\n  Approach Abstract: A classical result in undirected wireline networks is the near optimality of\nrouting (flow) for multiple-unicast traffic (multiple sources communicating\nindependent messages to multiple destinations): the min cut upper bound is\nwithin a logarithmic factor of the number of sources of the max flow. In this\npaper we \"extend\" the wireline result to the wireless context.\n  Our main result is the approximate optimality of a simple layering principle:\n{\\em local physical-layer schemes combined with global routing}. We use the\n{\\em reciprocity} of the wireless channel critically in this result. Our formal\nresult is in the context of channel models for which \"good\" local schemes, that\nachieve the cut-set bound, exist (such as Gaussian MAC and broadcast channels,\nbroadcast erasure networks, fast fading Gaussian networks).\n  Layered architectures, common in the engineering-design of wireless networks,\ncan have near-optimal performance if the {\\em locality} over which\nphysical-layer schemes should operate is carefully designed. Feedback is shown\nto play a critical role in enabling the separation between the physical and the\nnetwork layers. The key technical idea is the modeling of a wireless network by\nan undirected \"polymatroidal\" network, for which we establish a max-flow\nmin-cut approximation theorem. \n\n"}
{"id": "1111.5200", "contents": "Title: Wireless Capacity and Admission Control in Cognitive Radio Abstract: We give algorithms with constant-factor performance guarantees for several\ncapacity and throughput problems in the SINR model. The algorithms are all\nbased on a novel LP formulation for capacity problems. First, we give a new\nconstant-factor approximation algorithm for selecting the maximum subset of\nlinks that can be scheduled simultaneously, under any non-decreasing and\nsublinear power assignment. For the case of uniform power, we extend this to\nthe case of variable QoS requirements and link-dependent noise terms. Second,\nwe approximate a problem related to cognitive radio: find a maximum set of\nlinks that can be simultaneously scheduled without affecting a given set of\npreviously assigned links. Finally, we obtain constant-factor approximation of\nweighted capacity under linear power assignment. \n\n"}
{"id": "1112.4944", "contents": "Title: Combining Adaptive Coding and Modulation with Hierarchical Modulation in\n  Satcom Systems Abstract: We investigate the design of a broadcast system in order to maximise the\nthroughput. This task is usually challenging due to the channel variability.\nForty years ago, Cover introduced and compared two schemes: time sharing and\nsuperposition coding. Even if the second scheme was proved to be optimal for\nsome channels, modern satellite communications systems such as DVB-SH and\nDVB-S2 mainly rely on time sharing strategy to optimize the throughput. They\nconsider hierarchical modulation, a practical implementation of superposition\ncoding, but only for unequal error protection or backward compatibility\npurposes. We propose in this article to combine time sharing and hierarchical\nmodulation together and show how this scheme can improve the performance in\nterms of available rate. We introduce the hierarchical 16-APSK to boost the\nperformance of the DVB-S2 standard. We also evaluate various strategies to\ngroup the receivers in pairs when using hierarchical modulation. Finally, we\nshow in a realistic use case based on DVB-S2 that the combined scheme can\nprovide throughput gains greater than 10% compared to the best time sharing\nstrategy. \n\n"}
{"id": "1201.0662", "contents": "Title: Transmission capacity of wireless networks Abstract: Transmission capacity (TC) is a performance metric for wireless networks that\nmeasures the spatial intensity of successful transmissions per unit area,\nsubject to a constraint on the permissible outage probability (where outage\noccurs when the SINR at a receiver is below a threshold). This volume gives a\nunified treatment of the TC framework that has been developed by the authors\nand their collaborators over the past decade. The mathematical framework\nunderlying the analysis (reviewed in Ch. 2) is stochastic geometry: Poisson\npoint processes model the locations of interferers, and (stable) shot noise\nprocesses represent the aggregate interference seen at a receiver. Ch. 3\npresents TC results (exact, asymptotic, and bounds) on a simple model in order\nto illustrate a key strength of the framework: analytical tractability yields\nexplicit performance dependence upon key model parameters. Ch. 4 presents\nenhancements to this basic model --- channel fading, variable link distances,\nand multi-hop. Ch. 5 presents four network design case studies well-suited to\nTC: i) spectrum management, ii) interference cancellation, iii) signal\nthreshold transmission scheduling, and iv) power control. Ch. 6 studies the TC\nwhen nodes have multiple antennas, which provides a contrast vs. classical\nresults that ignore interference. \n\n"}
{"id": "1201.1174", "contents": "Title: DMFSGD: A Decentralized Matrix Factorization Algorithm for Network\n  Distance Prediction Abstract: The knowledge of end-to-end network distances is essential to many Internet\napplications. As active probing of all pairwise distances is infeasible in\nlarge-scale networks, a natural idea is to measure a few pairs and to predict\nthe other ones without actually measuring them. This paper formulates the\ndistance prediction problem as matrix completion where unknown entries of an\nincomplete matrix of pairwise distances are to be predicted. The problem is\nsolvable because strong correlations among network distances exist and cause\nthe constructed distance matrix to be low rank. The new formulation circumvents\nthe well-known drawbacks of existing approaches based on Euclidean embedding.\n  A new algorithm, so-called Decentralized Matrix Factorization by Stochastic\nGradient Descent (DMFSGD), is proposed to solve the network distance prediction\nproblem. By letting network nodes exchange messages with each other, the\nalgorithm is fully decentralized and only requires each node to collect and to\nprocess local measurements, with neither explicit matrix constructions nor\nspecial nodes such as landmarks and central servers. In addition, we compared\ncomprehensively matrix factorization and Euclidean embedding to demonstrate the\nsuitability of the former on network distance prediction. We further studied\nthe incorporation of a robust loss function and of non-negativity constraints.\nExtensive experiments on various publicly-available datasets of network delays\nshow not only the scalability and the accuracy of our approach but also its\nusability in real Internet applications. \n\n"}
{"id": "1201.2937", "contents": "Title: Opportunistic Adaptive Relaying in Cognitive Radio Networks Abstract: Combining cognitive radio technology with user cooperation could be\nadvantageous to both primary and secondary transmissions. In this paper, we\npropose a first relaying scheme for cognitive radio networks (called \"Adaptive\nrelaying scheme 1\"), where one relay node can assist the primary or the\nsecondary transmission with the objective of improving the outage probability\nof the secondary transmission with respect to a primary outage probability\nthreshold. Upper bound expressions of the secondary outage probability using\nthe proposed scheme are derived over Rayleigh fading channels. Numerical and\nsimulation results show that the secondary outage probability using the\nproposed scheme is lower than that of other relaying schemes. Then, we extend\nthe proposed scheme to the case where the relay node has the ability to decode\nboth the primary and secondary signals and also can assist simultaneously both\ntransmissions. Simulations show the performance improvement that can be\nobtained due to this extension in terms of secondary outage probability. \n\n"}
{"id": "1201.4150", "contents": "Title: Optimal Threshold Control by the Robots of Web Search Engines with\n  Obsolescence of Documents Abstract: A typical web search engine consists of three principal parts: crawling\nengine, indexing engine, and searching engine. The present work aims to\noptimize the performance of the crawling engine. The crawling engine finds new\nweb pages and updates web pages existing in the database of the web search\nengine. The crawling engine has several robots collecting information from the\nInternet. We first calculate various performance measures of the system (e.g.,\nprobability of arbitrary page loss due to the buffer overflow, probability of\nstarvation of the system, the average time waiting in the buffer). Intuitively,\nwe would like to avoid system starvation and at the same time to minimize the\ninformation loss. We formulate the problem as a multi-criteria optimization\nproblem and attributing a weight to each criterion. We solve it in the class of\nthreshold policies. We consider a very general web page arrival process modeled\nby Batch Marked Markov Arrival Process and a very general service time modeled\nby Phase-type distribution. The model has been applied to the performance\nevaluation and optimization of the crawler designed by INRIA Maestro team in\nthe framework of the RIAM INRIA-Canon research project. \n\n"}
{"id": "1201.4197", "contents": "Title: A Survey of Smart Data Pricing: Past Proposals, Current Plans, and\n  Future Trends Abstract: Traditionally, network operators have used simple flat-rate broadband data\nplans for both wired and wireless network access. But today, with the\npopularity of mobile devices and exponential growth of apps, videos, and\nclouds, service providers are gradually moving towards more sophisticated\npricing schemes. This decade will therefore likely witness a major change in\nthe ways in which network resources are managed, and the role of economics in\nallocating these resources. This survey reviews some of the well-known past\nbroadband pricing proposals (both static and dynamic), including their current\nrealizations in various consumer data plans around the world, and discusses\nseveral research problems and open questions. By exploring the benefits and\nchallenges of pricing data, this paper attempts to facilitate both the\nindustrial and the academic communities' efforts in understanding the existing\nliterature, recognizing new trends, and shaping an appropriate and timely\nresearch agenda. \n\n"}
{"id": "1201.5434", "contents": "Title: Separating the Effect of Independent Interference Sources with Rayleigh\n  Faded Signal Link: Outage Analysis and Applications Abstract: We show that, for independent interfering sources and a signal link with\nexponentially distributed received power, the total probability of outage can\nbe decomposed as a simple expression of the outages from the individual\ninterfering sources. We give a mathematical proof of this result, and discuss\nsome immediate implications, showing how it results in important\nsimplifications to statistical outage analysis. We also discuss its application\nto two active topics of study: spectrum sharing, and sum of interference powers\n(e.g., lognormal) analysis. \n\n"}
{"id": "1201.5608", "contents": "Title: Combinatorial Channel Signature Modulation for Wireless ad-hoc Networks Abstract: In this paper we introduce a novel modulation and multiplexing method which\nfacilitates highly efficient and simultaneous communication between multiple\nterminals in wireless ad-hoc networks. We term this method Combinatorial\nChannel Signature Modulation (CCSM). The CCSM method is particularly efficient\nin situations where communicating nodes operate in highly time dispersive\nenvironments. This is all achieved with a minimal MAC layer overhead, since all\nusers are allowed to transmit and receive at the same time/frequency (full\nsimultaneous duplex). The CCSM method has its roots in sparse modelling and the\nreceiver is based on compressive sampling techniques. Towards this end, we\ndevelop a new low complexity algorithm termed Group Subspace Pursuit. Our\nanalysis suggests that CCSM at least doubles the throughput when compared to\nthe state-of-the art. \n\n"}
{"id": "1202.0477", "contents": "Title: On Optimality of Myopic Sensing Policy with Imperfect Sensing in\n  Multi-channel Opportunistic Access Abstract: We consider the channel access problem under imperfect sensing of channel\nstate in a multi-channel opportunistic communication system, where the state of\neach channel evolves as an independent and identically distributed Markov\nprocess. The considered problem can be cast into a restless multi-armed bandit\n(RMAB) problem that is of fundamental importance in decision theory. It is\nwell-known that solving the RMAB problem is PSPACE-hard, with the optimal\npolicy usually intractable due to the exponential computation complexity. A\nnatural alternative is to consider the easily implementable myopic policy that\nmaximizes the immediate reward but ignores the impact of the current strategy\non the future reward. In this paper, we perform an analytical study on the\noptimality of the myopic policy under imperfect sensing for the considered RMAB\nproblem. Specifically, for a family of generic and practically important\nutility functions, we establish the closed-form conditions under which the\nmyopic policy is guaranteed to be optimal even under imperfect sensing. Despite\nour focus on the opportunistic channel access, the obtained results are generic\nin nature and are widely applicable in a wide range of engineering domains. \n\n"}
{"id": "1202.3018", "contents": "Title: Using TV Receiver Information to Increase Cognitive White Space Spectrum Abstract: In this paper we investigate the usage of cognitive radio devices within the\nservice area of TV broadcast stations. Until now the main approach for a\ncognitive radio to operate in the TV bands has been to register TV broadcast\nstations locations and thus protecting the broadcast stations service area.\nThrough information about TV receivers location, we show that a cognitive radio\nshould be able to operate within this service area without causing harmful\ninterference to the TV receivers as defined by Ofcom and FCC. We provide\nsimulations based on real statistics from Norway that show that especially in\nrural areas TV receiver registration can provide a substantial gain in terms of\nexploitable frequencies for a cognitive radio. \n\n"}
{"id": "1202.3993", "contents": "Title: Internet Topology over Time Abstract: There are few studies that look closely at how the topology of the Internet\nevolves over time; most focus on snapshots taken at a particular point in time.\nIn this paper, we investigate the evolution of the topology of the Autonomous\nSystems graph of the Internet, examining how eight commonly-used topological\nmeasures change from January 2002 to January 2010. We find that the\ndistributions of most of the measures remain unchanged, except for average path\nlength and clustering coefficient. The average path length has slowly and\nsteadily increased since 2005 and the average clustering coefficient has\nsteadily declined. We hypothesize that these changes are due to changes in\npeering policies as the Internet evolves. We also investigate a surprising\nfeature, namely that the maximum degree has changed little, an aspect that\ncannot be captured without modeling link deletion. Our results suggest that\nevaluating models of the Internet graph by comparing steady-state generated\ntopologies to snapshots of the real data is reasonable for many measures.\nHowever, accurately matching time-variant properties is more difficult, as we\ndemonstrate by evaluating ten well-known models against the 2010 data. \n\n"}
{"id": "1202.5945", "contents": "Title: A Note on Interference in Random Point Sets Abstract: The (maximum receiver-centric) interference of a geometric graph (von\nRickenbach etal (2005)) is studied. It is shown that, with high probability,\nthe following results hold for a set, V, of n points independently and\nuniformly distributed in the unit d-cube, for constant dimension d: (1) there\nexists a connected graph with vertex set V that has interference O((log\nn)^{1/3}); (2) no connected graph with vertex set V has interference o((log\nn)^{1/4}); and (3) the minimum spanning tree of $V$ has interference\nTheta((\\log n)^{1/2}). \n\n"}
{"id": "1203.0536", "contents": "Title: Algorithms for Wireless Capacity Abstract: In this paper we address two basic questions in wireless communication:\nFirst, how long does it take to schedule an arbitrary set of communication\nrequests? Second, given a set of communication requests, how many of them can\nbe scheduled concurrently? Our results are derived in an interference model\nwith geometric path loss and consist of efficient algorithms that find a\nconstant approximation for the second problem and a logarithmic approximation\nfor the first problem. In addition, we analyze some important properties of the\ninterference model and show that it is robust to various factors that can\ninfluence the signal attenuation. More specifically, we prove that as long as\nsuch influences on the signal attenuation are constant, they affect the\ncapacity only by a constant factor. \n\n"}
{"id": "1203.1226", "contents": "Title: Dynamic Packet Scheduling in Wireless Networks Abstract: We consider protocols that serve communication requests arising over time in\na wireless network that is subject to interference. Unlike previous approaches,\nwe take the geometry of the network and power control into account, both\nallowing to increase the network's performance significantly. We introduce a\nstochastic and an adversarial model to bound the packet injection. Although\ntaken as the primary motivation, this approach is not only suitable for models\nbased on the signal-to-interference-plus-noise ratio (SINR). It also covers\nvirtually all other common interference models, for example the multiple-access\nchannel, the radio-network model, the protocol model, and distance-2 matching.\nPacket-routing networks allowing each edge or each node to transmit or receive\none packet at a time can be modeled as well.\n  Starting from algorithms for the respective scheduling problem with static\ntransmission requests, we build distributed stable protocols. This is more\ninvolved than in previous, similar approaches because the algorithms we\nconsider do not necessarily scale linearly when scaling the input instance. We\ncan guarantee a throughput that is as large as the one of the original static\nalgorithm. In particular, for SINR models the competitive ratios of the\nprotocol in comparison to optimal ones in the respective model are between\nconstant and O(log^2 m) for a network of size m. \n\n"}
{"id": "1203.1304", "contents": "Title: Analytical Modeling of Uplink Cellular Networks Abstract: Cellular uplink analysis has typically been undertaken by either a simple\napproach that lumps all interference into a single deterministic or random\nparameter in a Wyner-type model, or via complex system level simulations that\noften do not provide insight into why various trends are observed. This paper\nproposes a novel middle way using point processes that is both accurate and\nalso results in easy-to-evaluate integral expressions based on the Laplace\ntransform of the interference. We assume mobiles and base stations are randomly\nplaced in the network with each mobile pairing up to its closest base station.\nCompared to related recent work on downlink analysis, the proposed uplink model\ndiffers in two key features. First, dependence is considered between user and\nbase station point processes to make sure each base station serves a single\nmobile in the given resource block. Second, per-mobile power control is\nincluded, which further couples the transmission of mobiles due to\nlocation-dependent channel inversion. Nevertheless, we succeed in deriving the\ncoverage (equivalently outage) probability of a typical link in the network.\nThis model can be used to address a wide variety of system design questions in\nthe future. In this paper we focus on the implications for power control and\nsee that partial channel inversion should be used at low\nsignal-to-interference-plus-noise ratio (SINR), while full power transmission\nis optimal at higher SINR. \n\n"}
{"id": "1203.1570", "contents": "Title: In-network Sparsity-regularized Rank Minimization: Algorithms and\n  Applications Abstract: Given a limited number of entries from the superposition of a low-rank matrix\nplus the product of a known fat compression matrix times a sparse matrix,\nrecovery of the low-rank and sparse components is a fundamental task subsuming\ncompressed sensing, matrix completion, and principal components pursuit. This\npaper develops algorithms for distributed sparsity-regularized rank\nminimization over networks, when the nuclear- and $\\ell_1$-norm are used as\nsurrogates to the rank and nonzero entry counts of the sought matrices,\nrespectively. While nuclear-norm minimization has well-documented merits when\ncentralized processing is viable, non-separability of the singular-value sum\nchallenges its distributed minimization. To overcome this limitation, an\nalternative characterization of the nuclear norm is adopted which leads to a\nseparable, yet non-convex cost minimized via the alternating-direction method\nof multipliers. The novel distributed iterations entail reduced-complexity\nper-node tasks, and affordable message passing among single-hop neighbors.\nInterestingly, upon convergence the distributed (non-convex) estimator provably\nattains the global optimum of its centralized counterpart, regardless of\ninitialization. Several application domains are outlined to highlight the\ngenerality and impact of the proposed framework. These include unveiling\ntraffic anomalies in backbone networks, predicting networkwide path latencies,\nand mapping the RF ambiance using wireless cognitive radios. Simulations with\nsynthetic and real network data corroborate the convergence of the novel\ndistributed algorithm, and its centralized performance guarantees. \n\n"}
{"id": "1203.1905", "contents": "Title: Local heuristic for the refinement of multi-path routing in wireless\n  mesh networks Abstract: We consider wireless mesh networks and the problem of routing end-to-end\ntraffic over multiple paths for the same origin-destination pair with minimal\ninterference. We introduce a heuristic for path determination with two\ndistinguishing characteristics. First, it works by refining an extant set of\npaths, determined previously by a single- or multi-path routing algorithm.\nSecond, it is totally local, in the sense that it can be run by each of the\norigins on information that is available no farther than the node's immediate\nneighborhood. We have conducted extensive computational experiments with the\nnew heuristic, using AODV and OLSR, as well as their multi-path variants, as\nunderlying routing methods. For two different CSMA settings (as implemented by\n802.11) and one TDMA setting running a path-oriented link scheduling algorithm,\nwe have demonstrated that the new heuristic is capable of improving the average\nthroughput network-wide. When working from the paths generated by the\nmulti-path routing algorithms, the heuristic is also capable to provide a more\nevenly distributed traffic pattern. \n\n"}
{"id": "1203.2031", "contents": "Title: Design of modular wireless sensor Abstract: The paper addresses combinatorial approach to design of modular wireless\nsensor as composition of the sensor element from its component alternatives and\naggregation of the obtained solutions into a resultant aggregated solution. A\nhierarchical model is used for the wireless sensor element. The solving process\nconsists of three stages: (i) multicriteria ranking of design alternatives for\nsystem components/parts, (ii) composing the selected design alternatives into\ncomposite solution(s) while taking into account ordinal quality of the design\nalternatives above and their compatibility (this stage is based on Hierarchical\nMorphological Multicriteria Design - HMMD), and (iii) aggregation of the\nobtained composite solutions into a resultant aggregated solution(s). A\nnumerical example describes the problem structuring and solving processes for\nmodular alarm wireless sensor element. \n\n"}
{"id": "1203.2109", "contents": "Title: Network Cosmology Abstract: Prediction and control of the dynamics of complex networks is a central\nproblem in network science. Structural and dynamical similarities of different\nreal networks suggest that some universal laws might accurately describe the\ndynamics of these networks, albeit the nature and common origin of such laws\nremain elusive. Here we show that the causal network representing the\nlarge-scale structure of spacetime in our accelerating universe is a power-law\ngraph with strong clustering, similar to many complex networks such as the\nInternet, social, or biological networks. We prove that this structural\nsimilarity is a consequence of the asymptotic equivalence between the\nlarge-scale growth dynamics of complex networks and causal networks. This\nequivalence suggests that unexpectedly similar laws govern the dynamics of\ncomplex networks and spacetime in the universe, with implications to network\nscience and cosmology. \n\n"}
{"id": "1203.2393", "contents": "Title: Primary User Traffic Estimation for Dynamic Spectrum Access Abstract: Accurate estimation of licensed channel Primary User's (PU) temporal\nstatistics is important for Dynamic Spectrum Access (DSA) systems. With\naccurate estimation of the mean duty cycle, u, and the mean off- and on-times\nof PUs, DSA systems can more efficiently assign PU resources to its\nsubscribers, thus, increasing channel utilization. This paper presents a\nmathematical analysis of the accuracy of estimating u, as well as the PU mean\noff- and on-times, where the estimation accuracy is expressed as the mean\nsquared estimation error. The analysis applies for the traffic model assuming\nexponentially distributed PU off- and on-times, which is a common model in\ntraffic literature. The estimation accuracy is quantified as a function of the\nnumber of samples and observation window length, hence, this work provides\nguidelines on traffic parameters estimation for both energy-constrained and\ndelay-constrained applications. For estimating u, we consider uniform,\nnon-uniform, and weighted sample stream averaging, as well as maximum\nlikelihood estimation. The estimation accuracy of the mean PU off- and on-times\nis studied when maximum likelihood estimation is employed. Furthermore, we\ndevelop algorithms for the blind estimation of the traffic parameters based on\nthe derived theoretical estimation accuracy expressions. We show that the\nestimation error for all traffic parameters is lower bounded for a fixed\nobservation window length due to the correlation between the traffic samples.\nMoreover, we prove that for estimating u, maximum likelihood estimation can\nyield the same estimation error as weighted sample averaging using only half\nthe observation window length. \n\n"}
{"id": "1203.3962", "contents": "Title: A Fully Distributed Algorithm for Throughput Performance in Wireless\n  Networks Abstract: We study link scheduling in wireless networks under stochastic arrival\nprocesses of packets, and give an algorithm that achieves stability in the\nphysical (SINR) interference model. The efficiency of such an algorithm is the\nfraction of the maximum feasible traffic that the algorithm can handle without\nqueues growing indefinitely. Our algorithm achieves two important goals: (i)\nefficiency is independent of the size of the network, and (ii) the algorithm is\nfully distributed, i.e., individual nodes need no information about the overall\nnetwork topology, not even local information. \n\n"}
{"id": "1203.4863", "contents": "Title: Traffic Analysis in Random Delaunay Tessellations and Other Graphs Abstract: In this work we study the degree distribution, the maximum vertex and edge\nflow in non-uniform random Delaunay triangulations when geodesic routing is\nused. We also investigate the vertex and edge flow in Erd\\\"os-Renyi random\ngraphs, geometric random graphs, expanders and random $k$-regular graphs.\nMoreover we show that adding a random matching to the original graph can\nconsiderably reduced the maximum vertex flow. \n\n"}
{"id": "1204.1595", "contents": "Title: Femtocaching and Device-to-Device Collaboration: A New Architecture for\n  Wireless Video Distribution Abstract: We present a new architecture to handle the ongoing explosive increase in the\ndemand for video content in wireless networks. It is based on distributed\ncaching of the content in femto-basestations with small or non-existing\nbackhaul capacity but with considerable storage space, called helper nodes. We\nalso consider using the mobile terminals themselves as caching helpers, which\ncan distribute video through device-to-device communications. This approach\nallows an improvement in the video throughput without deployment of any\nadditional infrastructure. The new architecture can improve video throughput by\none to two orders-of-magnitude. \n\n"}
{"id": "1204.3259", "contents": "Title: Combinatorial Evolution and Forecasting of Communication Protocol ZigBee Abstract: The article addresses combinatorial evolution and forecasting of\ncommunication protocol for wireless sensor networks (ZigBee). Morphological\ntree structure (a version of and-or tree) is used as a hierarchical model for\nthe protocol. Three generations of ZigBee protocol are examined. A set of\nprotocol change operations is generated and described. The change operations\nare used as items for forecasting based on combinatorial problems (e.g.,\nclustering, knapsack problem, multiple choice knapsack problem). Two kinds of\npreliminary forecasts for the examined communication protocol are considered:\n(i) direct expert (expert judgment) based forecast, (ii) computation of the\nforecast(s) (usage of multicriteria decision making and combinatorial\noptimization problems). Finally, aggregation of the obtained preliminary\nforecasts is considered (two aggregation strategies are used). \n\n"}
{"id": "1204.4679", "contents": "Title: Robust Geometric Spanners Abstract: Highly connected and yet sparse graphs (such as expanders or graphs of high\ntreewidth) are fundamental, widely applicable and extensively studied\ncombinatorial objects. We initiate the study of such highly connected graphs\nthat are, in addition, geometric spanners. We define a property of spanners\ncalled robustness. Informally, when one removes a few vertices from a robust\nspanner, this harms only a small number of other vertices. We show that robust\nspanners must have a superlinear number of edges, even in one dimension. On the\npositive side, we give constructions, for any dimension, of robust spanners\nwith a near-linear number of edges. \n\n"}
{"id": "1204.5028", "contents": "Title: Regenerating Codes: A System Perspective Abstract: The explosion of the amount of data stored in cloud systems calls for more\nefficient paradigms for redundancy. While replication is widely used to ensure\ndata availability, erasure correcting codes provide a much better trade-off\nbetween storage and availability. Regenerating codes are good candidates for\nthey also offer low repair costs in term of network bandwidth. While they have\nbeen proven optimal, they are difficult to understand and parameterize. In this\npaper we provide an analysis of regenerating codes for practitioners to grasp\nthe various trade-offs. More specifically we make two contributions: (i) we\nstudy the impact of the parameters by conducting an analysis at the level of\nthe system, rather than at the level of a single device; (ii) we compare the\ncomputational costs of various implementations of codes and highlight the most\nefficient ones. Our goal is to provide system designers with concrete\ninformation to help them choose the best parameters and design for regenerating\ncodes. \n\n"}
{"id": "1204.5507", "contents": "Title: Dynamic Network Delay Cartography Abstract: Path delays in IP networks are important metrics, required by network\noperators for assessment, planning, and fault diagnosis. Monitoring delays of\nall source-destination pairs in a large network is however challenging and\nwasteful of resources. The present paper advocates a spatio-temporal Kalman\nfiltering approach to construct network-wide delay maps using measurements on\nonly a few paths. The proposed network cartography framework allows efficient\ntracking and prediction of delays by relying on both topological as well as\nhistorical data. Optimal paths for delay measurement are selected in an online\nfashion by leveraging the notion of submodularity. The resulting predictor is\noptimal in the class of linear predictors, and outperforms competing\nalternatives on real-world datasets. \n\n"}
{"id": "1204.6537", "contents": "Title: Recovery of Low-Rank Plus Compressed Sparse Matrices with Application to\n  Unveiling Traffic Anomalies Abstract: Given the superposition of a low-rank matrix plus the product of a known fat\ncompression matrix times a sparse matrix, the goal of this paper is to\nestablish deterministic conditions under which exact recovery of the low-rank\nand sparse components becomes possible. This fundamental identifiability issue\narises with traffic anomaly detection in backbone networks, and subsumes\ncompressed sensing as well as the timely low-rank plus sparse matrix recovery\ntasks encountered in matrix decomposition problems. Leveraging the ability of\n$\\ell_1$- and nuclear norms to recover sparse and low-rank matrices, a convex\nprogram is formulated to estimate the unknowns. Analysis and simulations\nconfirm that the said convex program can recover the unknowns for sufficiently\nlow-rank and sparse enough components, along with a compression matrix\npossessing an isometry property when restricted to operate on sparse vectors.\nWhen the low-rank, sparse, and compression matrices are drawn from certain\nrandom ensembles, it is established that exact recovery is possible with high\nprobability. First-order algorithms are developed to solve the nonsmooth convex\noptimization problem with provable iteration complexity guarantees. Insightful\ntests with synthetic and real network data corroborate the effectiveness of the\nnovel approach in unveiling traffic anomalies across flows and time, and its\nability to outperform existing alternatives. \n\n"}
{"id": "1205.4778", "contents": "Title: Backscatter from the Data Plane --- Threats to Stability and Security in\n  Information-Centric Networking Abstract: Information-centric networking proposals attract much attention in the\nongoing search for a future communication paradigm of the Internet. Replacing\nthe host-to-host connectivity by a data-oriented publish/subscribe service\neases content distribution and authentication by concept, while eliminating\nthreats from unwanted traffic at an end host as are common in today's Internet.\nHowever, current approaches to content routing heavily rely on data-driven\nprotocol events and thereby introduce a strong coupling of the control to the\ndata plane in the underlying routing infrastructure. In this paper, threats to\nthe stability and security of the content distribution system are analyzed in\ntheory and practical experiments. We derive relations between state resources\nand the performance of routers and demonstrate how this coupling can be misused\nin practice. We discuss new attack vectors present in its current state of\ndevelopment, as well as possibilities and limitations to mitigate them. \n\n"}
{"id": "1205.4856", "contents": "Title: Bounds on Minimum Number of Anchors for Iterative Localization and its\n  Connections to Bootstrap Percolation Abstract: Iterated localization is considered where each node of a network needs to get\nlocalized (find its location on 2-D plane), when initially only a subset of\nnodes have their location information. The iterated localization process\nproceeds as follows. Starting with a subset of nodes that have their location\ninformation, possibly using global positioning system (GPS) devices, any other\nnode gets localized if it has three or more localized nodes in its radio range.\nThe newly localized nodes are included in the subset of nodes that have their\nlocation information for the next iteration. This process is allowed to\ncontinue, until no new node can be localized. The problem is to find the\nminimum size of the initially localized subset to start with so that the whole\nnetwork is localized with high probability. There are intimate connections\nbetween iterated localization and bootstrap percolation, that is well studied\nin statistical physics. Using results known in bootstrap percolation, we find a\nsufficient condition on the size of the initially localized subset that\nguarantees the localization of all nodes in the network with high probability. \n\n"}
{"id": "1205.6862", "contents": "Title: AirSync: Enabling Distributed Multiuser MIMO with Full Spatial\n  Multiplexing Abstract: The enormous success of advanced wireless devices is pushing the demand for\nhigher wireless data rates. Denser spectrum reuse through the deployment of\nmore access points per square mile has the potential to successfully meet the\nincreasing demand for more bandwidth. In theory, the best approach to density\nincrease is via distributed multiuser MIMO, where several access points are\nconnected to a central server and operate as a large distributed multi-antenna\naccess point, ensuring that all transmitted signal power serves the purpose of\ndata transmission, rather than creating \"interference.\" In practice, while\nenterprise networks offer a natural setup in which distributed MIMO might be\npossible, there are serious implementation difficulties, the primary one being\nthe need to eliminate phase and timing offsets between the jointly coordinated\naccess points.\n  In this paper we propose AirSync, a novel scheme which provides not only time\nbut also phase synchronization, thus enabling distributed MIMO with full\nspatial multiplexing gains. AirSync locks the phase of all access points using\na common reference broadcasted over the air in conjunction with a Kalman filter\nwhich closely tracks the phase drift. We have implemented AirSync as a digital\ncircuit in the FPGA of the WARP radio platform. Our experimental testbed,\ncomprised of two access points and two clients, shows that AirSync is able to\nachieve phase synchronization within a few degrees, and allows the system to\nnearly achieve the theoretical optimal multiplexing gain. We also discuss MAC\nand higher layer aspects of a practical deployment. To the best of our\nknowledge, AirSync offers the first ever realization of the full multiuser MIMO\ngain, namely the ability to increase the number of wireless clients linearly\nwith the number of jointly coordinated access points, without reducing the per\nclient rate. \n\n"}
{"id": "1206.0641", "contents": "Title: The Cost of Mitigating Power Law Delay in Random Access Networks Abstract: Exponential backoff (EB) is a widely adopted collision resolution mechanism\nin many popular random-access networks including Ethernet and wireless LAN\n(WLAN). The prominence of EB is primarily attributed to its asymptotic\nthroughput stability, which ensures a non-zero throughput even when the number\nof users in the network goes to infinity. Recent studies, however, show that EB\nis fundamentally unsuitable for applications that are sensitive to large delay\nand delay jitters, as it induces divergent second- and higher-order moments of\nmedium access delay. Essentially, the medium access delay follows a power law\ndistribution, a subclass of heavy-tailed distribution. To understand and\nalleviate the issue, this paper systematically analyzes the tail delay\ndistribution of general backoff functions, with EB being a special case. In\nparticular, we establish a tradeoff between the tail decaying rate of medium\naccess delay distribution and the stability of throughput. To be more specific,\nconvergent delay moments are attainable only when the backoff functions $g(k)$\ngrows slower than exponential functions, i.e., when $g(k)\\in o(r^k)$ for all\n$r>1$. On the other hand, non-zero asymptotic throughput is attainable only\nwhen backoff functions grow at least as fast as an exponential function, i.e.,\n$g(k)\\in\\Omega(r^k)$ for some $r>1$. This implies that bounded delay moments\nand stable throughput cannot be achieved at the same time. For practical\nimplementation, we show that polynomial backoff (PB), where $g(k)$ is a\npolynomial that grows slower than exponential functions, obtains finite delay\nmoments and good throughput performance at the same time within a practical\nrange of user population. This makes PB a better alternative than EB for\nmultimedia applications with stringent delay requirements. \n\n"}
{"id": "1206.7111", "contents": "Title: Data Minimisation in Communication Protocols: A Formal Analysis\n  Framework and Application to Identity Management Abstract: With the growing amount of personal information exchanged over the Internet,\nprivacy is becoming more and more a concern for users. One of the key\nprinciples in protecting privacy is data minimisation. This principle requires\nthat only the minimum amount of information necessary to accomplish a certain\ngoal is collected and processed. \"Privacy-enhancing\" communication protocols\nhave been proposed to guarantee data minimisation in a wide range of\napplications. However, currently there is no satisfactory way to assess and\ncompare the privacy they offer in a precise way: existing analyses are either\ntoo informal and high-level, or specific for one particular system. In this\nwork, we propose a general formal framework to analyse and compare\ncommunication protocols with respect to privacy by data minimisation. Privacy\nrequirements are formalised independent of a particular protocol in terms of\nthe knowledge of (coalitions of) actors in a three-layer model of personal\ninformation. These requirements are then verified automatically for particular\nprotocols by computing this knowledge from a description of their\ncommunication. We validate our framework in an identity management (IdM) case\nstudy. As IdM systems are used more and more to satisfy the increasing need for\nreliable on-line identification and authentication, privacy is becoming an\nincreasingly critical issue. We use our framework to analyse and compare four\nidentity management systems. Finally, we discuss the completeness and\n(re)usability of the proposed framework. \n\n"}
{"id": "1207.0873", "contents": "Title: Hybrid performance modelling of opportunistic networks Abstract: We demonstrate the modelling of opportunistic networks using the process\nalgebra stochastic HYPE. Network traffic is modelled as continuous flows,\ncontact between nodes in the network is modelled stochastically, and\ninstantaneous decisions are modelled as discrete events. Our model describes a\nnetwork of stationary video sensors with a mobile ferry which collects data\nfrom the sensors and delivers it to the base station. We consider different\nmobility models and different buffer sizes for the ferries. This case study\nillustrates the flexibility and expressive power of stochastic HYPE. We also\ndiscuss the software that enables us to describe stochastic HYPE models and\nsimulate them. \n\n"}
{"id": "1207.2825", "contents": "Title: Guard Zones and the Near-Far Problem in DS-CDMA Ad Hoc Networks Abstract: The central issue in direct-sequence code-division multiple-access (DS-CDMA)\nad hoc networks is the prevention of a near-far problem. This paper considers\ntwo types of guard zones that may be used to control the near-far problem: a\nfundamental exclusion zone and an additional CSMA guard zone that may be\nestablished by the carrier-sense multiple-access (CSMA) protocol. In the\nexclusion zone, no mobiles are physically present, modeling the minimum\nphysical separation among mobiles that is always present in actual networks.\nPotentially interfering mobiles beyond a transmitting mobile's exclusion zone,\nbut within its CSMA guard zone, are deactivated by the protocol. This paper\nprovides an analysis of DS-CSMA networks with either or both types of guard\nzones. A network of finite extent with a finite number of mobiles is modeled as\na uniform clustering process. The analysis uses a closed-form expression for\nthe outage probability in the presence of Nakagami fading, conditioned on the\nnetwork geometry. By using the analysis developed in this paper, the tradeoffs\nbetween exclusion zones and CSMA guard zones are explored for DS-CDMA and\nunspread networks. \n\n"}
{"id": "1207.4265", "contents": "Title: Spot: An accurate and efficient multi-entity device-free WLAN\n  localization system Abstract: Device-free (DF) localization in WLANs has been introduced as a value-added\nservice that allows tracking indoor entities that do not carry any devices.\nPrevious work in DF WLAN localization focused on the tracking of a single\nentity due to the intractability of the multi-entity tracking problem whose\ncomplexity grows exponentially with the number of humans being tracked. In this\npaper, we introduce Spot as an accurate and efficient system for multi-entity\nDF detection and tracking. Spot is based on a probabilistic energy minimization\nframework that combines a conditional random field with a Markov model to\ncapture the temporal and spatial relations between the entities' poses. A novel\ncross-calibration technique is introduced to reduce the calibration overhead of\nmultiple entities to linear, regardless of the number of humans being tracked.\nThis also helps in increasing the system accuracy. We design the energy\nminimization function with the goal of being efficiently solved in mind. We\nshow that the designed function can be mapped to a binary graph-cut problem\nwhose solution has a linear complexity on average and a third order polynomial\nin the worst case. We further employ clustering on the estimated location\ncandidates to reduce outliers and obtain more accurate tracking. Experimental\nevaluation in two typical testbeds, with a side-by-side comparison with the\nstate-of-the-art, shows that Spot can achieve a multi-entity tracking accuracy\nof less than 1.1m. This corresponds to at least 36% enhancement in median\ndistance error over the state-of-the-art DF localization systems, which can\nonly track a single entity. In addition, Spot can estimate the number of\nentities correctly to within one difference error. This highlights that Spot\nachieves its goals of having an accurate and efficient software-only DF\ntracking solution of multiple entities in indoor environments. \n\n"}
{"id": "1207.5708", "contents": "Title: Improved Interference in Wireless Sensor Networks Abstract: Given a set ${\\cal V}$ of $n$ sensor node distributed on a 2-dimensional\nplane and a source node $s \\in {\\cal V}$, the {\\it interference problem} deals\nwith assigning transmission range to each $v \\in {\\cal V}$ such that the\nmembers in ${\\cal V}$ maintain connectivity predicate ${\\cal P}$, and the\nmaximum/total interference is minimum. We propose algorithm for both {\\it\nminimizing maximum interference} and {\\it minimizing total interference} of the\nnetworks. For minimizing maximum interference we present optimum solution with\nrunning time $O(({\\cal P}_n + n^2) \\log n)$ for connectivity predicate ${\\cal\nP}$ like strong connectivity, broadcast ($s$ is the source), $k$-edge(vertex)\nconnectivity, spanner, where $O({\\cal P}_n)$ is the time complexity for\nchecking the connectivity predicate ${\\cal P}$. The running time of the\nprevious best known solution was $O({\\cal P}_n \\times n^2)$ [Bil$\\grave{o}$ and\nProietti, 2008].\n  For the minimizing total interference we propose optimum algorithm for the\nconnectivity predicate broadcast. The running time of the propose algorithm is\nO(n). For the same problem, the previous best known result was $2(1 + \\ln\n(n-1))$-factor approximation algorithm [Bil$\\grave{o}$ and Proietti, 2008]. We\nalso propose a heuristic for minimizing total interference in the case of\nstrongly connected predicate and compare our result with the best result\navailable in the literature. Experimental results demonstrate that our\nheuristic outperform existing result. \n\n"}
{"id": "1207.6630", "contents": "Title: A Network Calculus Approach for the Analysis of Multi-Hop Fading\n  Channels Abstract: A fundamental problem in the delay and backlog analysis across multi-hop\npaths in wireless networks is how to account for the random properties of the\nwireless channel. Since the usual statistical models for radio signals in a\npropagation environment do not lend themselves easily to a description of the\navailable service rate on a wireless link, the performance analysis of wireless\nnetworks has resorted to higher-layer abstractions, e.g., using Markov chain\nmodels. In this work, we propose a network calculus that can incorporate common\nstatistical models of fading channels and obtain statistical bounds on delay\nand backlog across multiple nodes. We conduct the analysis in a transfer\ndomain, which we refer to as the `SNR domain', where the service process at a\nlink is characterized by the instantaneous signal-to-noise ratio at the\nreceiver. We discover that, in the transfer domain, the network model is\ngoverned by a dioid algebra, which we refer to as (min,x)-algebra. Using this\nalgebra we derive the desired delay and backlog bounds. An application of the\nanalysis is demonstrated for a simple multi-hop network with Rayleigh fading\nchannels and for a network with cross traffic. \n\n"}
{"id": "1208.1149", "contents": "Title: Uncertainty-dependent data collection in vehicular sensor networks Abstract: Vehicular sensor networks (VSNs) are built on top of vehicular ad-hoc\nnetworks (VANETs) by equipping vehicles with sensing devices. These new\ntechnologies create a huge opportunity to extend the sensing capabilities of\nthe existing road traffic control systems and improve their performance.\nEfficient utilisation of wireless communication channel is one of the basic\nissues in the vehicular networks development. This paper presents and evaluates\ndata collection algorithms that use uncertainty estimates to reduce data\ntransmission in a VSN-based road traffic control system. \n\n"}
{"id": "1208.3994", "contents": "Title: Coordination in Network Security Games: a Monotone Comparative Statics\n  Approach Abstract: Malicious softwares or malwares for short have become a major security\nthreat. While originating in criminal behavior, their impact are also\ninfluenced by the decisions of legitimate end users. Getting agents in the\nInternet, and in networks in general, to invest in and deploy security features\nand protocols is a challenge, in particular because of economic reasons arising\nfrom the presence of network externalities.\n  In this paper, we focus on the question of incentive alignment for agents of\na large network towards a better security. We start with an economic model for\na single agent, that determines the optimal amount to invest in protection. The\nmodel takes into account the vulnerability of the agent to a security breach\nand the potential loss if a security breach occurs. We derive conditions on the\nquality of the protection to ensure that the optimal amount spent on security\nis an increasing function of the agent's vulnerability and potential loss. We\nalso show that for a large class of risks, only a small fraction of the\nexpected loss should be invested.\n  Building on these results, we study a network of interconnected agents\nsubject to epidemic risks. We derive conditions to ensure that the incentives\nof all agents are aligned towards a better security. When agents are strategic,\nwe show that security investments are always socially inefficient due to the\nnetwork externalities. Moreover alignment of incentives typically implies a\ncoordination problem, leading to an equilibrium with a very high price of\nanarchy. \n\n"}
{"id": "1208.4766", "contents": "Title: Network Coding as a WiMAX Link Reliability Mechanism Abstract: We design and implement a network-coding-enabled reliability architecture for\nnext generation wireless networks. Our network coding (NC) architecture uses a\nflexible thread-based design, with each encoder-decoder instance applying\nsystematic intra-session random linear network coding as a packet erasure code\nat the IP layer, to ensure the fast and reliable transfer of information\nbetween wireless nodes.\n  Using Global Environment for Network Innovations (GENI) WiMAX platforms, a\nseries of point-to-point transmission experiments were conducted to compare the\nperformance of the NC architecture to that of the Automatic Repeated reQuest\n(ARQ) and Hybrid ARQ (HARQ) mechanisms. At the application layer, Iperf and\nUDP-based File Transfer Protocol (UFTP) are used to measure throughput, packet\nloss and file transfer delay. In our selected scenarios, the proposed\narchitecture is able to decrease packet loss from around 11-32% to nearly 0%;\ncompared to HARQ and joint HARQ/ARQ mechanisms, the NC architecture offers up\nto 5.9 times gain in throughput and 5.5 times reduction in end-to-end file\ntransfer delay. Our experiments show that network coding as a packet erasure\ncode in the upper layers of the protocol stack has the potential to reduce the\nneed for joint HARQ/ARQ schemes in the PHY/MAC layers, thus offering insights\ninto cross-layer designs of efficient next generation wireless networks. \n\n"}
{"id": "1208.5738", "contents": "Title: Efficient Construction of Dominating Set in Wireless Networks Abstract: Considering a communication topology of a wireless network modeled by a graph\nwhere an edge exists between two nodes if they are within each other's\ncommunication range. A subset $U$ of nodes is a dominating set if each node is\neither in $U$ or adjacent to some node in $U$. Assume each node has a disparate\ncommunication range and is associated with a positive weight, we present a\nrandomized algorithm to find a min-weight dominating set. Considering any\norientation of the graph where an arc $\\overrightarrow{uv}$ exists if the node\n$v$ lies in $u$'s communication range. A subset $U$ of nodes is a strongly\ndominating set if every node except $U$ has both in-neighbor(s) and\nout-neighbor(s) in $U$. We present a polynomial-time algorithm to find a\nstrongly dominating set of size at most $(2+\\epsilon)$ times of the optimum. We\nalso investigate another related problem called $K$-Coverage. Given are a set\n${\\cal D}$ of disks with positive weight and a set ${\\cal P}$ of nodes. Assume\nall input nodes lie below a horizontal line $l$ and all input disks lie above\nthis line $l$ in the plane. The objective is to find a min-weight subset ${\\cal\nD}'\\subseteq {\\cal D}$ of disks such that each node is covered at least $K$\ndisks in ${\\cal D}'$. We propose a novel two-approximation algorithm for this\nproblem. \n\n"}
{"id": "1209.2881", "contents": "Title: Far-out Vertices In Weighted Repeated Configuration Model Abstract: We consider an edge-weighted uniform random graph with a given degree\nsequence (Repeated Configuration Model) which is a useful approximation for\nmany real-world networks. It has been observed that the vertices which are\nseparated from the rest of the graph by a distance exceeding certain threshold\nplay an important role in determining some global properties of the graph like\ndiameter, flooding time etc., in spite of being statistically rare. We give a\nconvergence result for the distribution of the number of such far-out vertices.\nWe also make a conjecture about how this relates to the longest edge of the\nminimal spanning tree on the graph under consideration. \n\n"}
{"id": "1209.4605", "contents": "Title: One-side Energy costs of the RBO receiver Abstract: Let $n = 2^k$ be the length of the broadcast cycle of the RBO broadcast\nscheduling protocol (see [arXiv:1108.5095] and [arXiv:1201.3318]). Let $lb$ and\n$ub$ be the variables of the RBO receiver as defined in [ arXiv:1201.3318 ]. We\nshow that the number of changes of $lb$ (the \"left-side energy\") is not greater\nthan $k + 1$. We also show that the number of changes of $rb$ (the \"right-side\nenergy\") is not greater than $k + 2$. Thus the \"extra energy\" (defined in\n[arXiv:1201.3318]) is bounded by $2 k + 3$. This updates the previous bound\nfrom [arXiv:1201.3318], which was $4 k + 2$. \n\n"}
{"id": "1209.5604", "contents": "Title: Tail Probabilities in Queueing Processes Abstract: In the study of large scale stochastic networks with resource management,\ndifferential equations and mean-field limits are two key techniques. Recent\nresearch shows that the expected fraction vector (that is, the tailed\nprobability vector) plays a key role in setting up mean-field differential\nequations. To further apply the technique of tailed probability vector to deal\nwith resource management of large scale stochastic networks, this paper\ndiscusses tailed probabilities in some basic queueing processes including QBD\nprocesses, Markov chains of GI/M/1 type and of M/G/1 type, and also provides\nsome effective and efficient algorithms for computing the tailed probabilities\nby means of the matrix-geometric solution, the matrix-iterative solution, the\nmatrix-product solution and the two types of RG-factorizations. Furthermore, we\nconsider four queueing examples: The M/M/1 retrial queue, the M(n)/M(n)/1\nqueue, the M/M/1 queue with server multiple vacations and the M/M/1 queue with\nrepairable server, where the M/M/1 retrial queue is given a detailed\ndiscussion, while the other three examples are analyzed simply. Note that the\nresults given in this paper will be very useful in the study of large scale\nstochastic networks with resource management, including the supermarket models\nand the work stealing models. \n\n"}
{"id": "1210.3552", "contents": "Title: Large-Scale Distributed Internet-based Discovery Mechanism for Dynamic\n  Spectrum Allocation Abstract: Scarcity of frequencies and the demand for more bandwidth is likely to\nincrease the need for devices that utilize the available frequencies more\nefficiently. Radios must be able to dynamically find other users of the\nfrequency bands and adapt so that they are not interfered, even if they use\ndifferent radio protocols. As transmitters far away may cause as much\ninterference as a transmitter located nearby, this mechanism can not be based\non location alone. Central databases can be used for this purpose, but require\nexpensive infrastructure and planning to scale. In this paper, we propose a\ndecentralized protocol and architecture for discovering radio devices over the\nInternet. The protocol has low resource requirements, making it suitable for\nimplementation on limited platforms. We evaluate the protocol through\nsimulation in network topologies with up to 2.3 million nodes, including\ntopologies generated from population patterns in Norway. The protocol has also\nbeen implemented as proof-of-concept in real Wi-Fi routers. \n\n"}
{"id": "1210.3598", "contents": "Title: Modelling a Decentralized Constraint Satisfaction Solver for\n  Collision-Free Channel Access Abstract: In this paper, the problem of assigning channel slots to a number of\ncontending stations is modeled as a Constraint Satisfaction Problem (CSP). A\nlearning MAC protocol that uses deterministic backoffs after successful\ntransmissions is used as a decentralized solver for the CSP. The convergence\nprocess of the solver is modeled by an absorbing Markov chain (MC), and\nanalytical, closed-form expressions for its transition probabilities are\nderived. Using these, the expected number of steps required to reach a solution\nis found. The analysis is validated by means of simulations and the model is\nextended to account for the presence of channel errors. The results are\napplicable in various resource allocation scenarios in wireless networks. \n\n"}
{"id": "1210.4446", "contents": "Title: Wireless Network Stability in the SINR Model Abstract: We study the stability of wireless networks under stochastic arrival\nprocesses of packets, and design efficient, distributed algorithms that achieve\nstability in the SINR (Signal to Interference and Noise Ratio) interference\nmodel.\n  Specifically, we make the following contributions. We give a distributed\nalgorithm that achieves $\\Omega(\\frac{1}{\\log^2 n})$-efficiency on all networks\n(where $n$ is the number of links in the network), for all length monotone,\nsub-linear power assignments. For the power control version of the problem, we\ngive a distributed algorithm with $\\Omega(\\frac{1}{\\log n(\\log n + \\log \\log\n\\Delta)})$-efficiency (where $\\Delta$ is the length diversity of the link set). \n\n"}
{"id": "1210.5393", "contents": "Title: Enhancing Information Dissemination in Dynamic Wireless Network using\n  Stability and Beamforming Abstract: Mobility causes network structures to change. In PSNs where underlying\nnetwork structure is changing rapidly, we are interested in studying how\ninformation dissemination can be enhanced in a sparse disconnected network\nwhere nodes lack the global knowledge about the network. We use beamforming to\nstudy the enhancement in the information dissemination process. In order to\nidentify potential beamformers and nodes to which beams should be directed we\nuse the concept of stability. We first predict the stability of a node in the\ndynamic network using truncated levy walk nature of jump lengths of human\nmobility and then use this measure to identify beamforming nodes and the nodes\nto which the beams are directed. We also develop our algorithm such that it\ndoes not require any global knowledge about the network and works in a\ndistributed manner. We also show the effect of various parameters such as\nnumber of sources, number of packets, mobility parameters, antenna parameters,\ntype of stability used and density of the network on information dissemination\nin the network. We validate our findings with three validation model, no\nbeamforming, beamforming using different stability measure and when no\nstability measure is associated but same number of node beamform and the\nselection of the beamforming nodes is random. Our simulation results show that\ninformation dissemination can be enhanced using our algorithm over other\nmodels. \n\n"}
{"id": "1210.5424", "contents": "Title: Implementation of Distributed Time Exchange Based Cooperative Forwarding Abstract: In this paper, we design and implement time exchange (TE) based cooperative\nforwarding where nodes use transmission time slots as incentives for relaying.\nWe focus on distributed joint time slot exchange and relay selection in the sum\ngoodput maximization of the overall network. We formulate the design objective\nas a mixed integer nonlinear programming (MINLP) problem and provide a\npolynomial time distributed solution of the MINLP. We implement the designed\nalgorithm in the software defined radio enabled USRP nodes of the ORBIT indoor\nwireless testbed. The ORBIT grid is used as a global control plane for exchange\nof control information between the USRP nodes. Experimental results suggest\nthat TE can significantly increase the sum goodput of the network. We also\ndemonstrate the performance of a goodput optimization algorithm that is\nproportionally fair. \n\n"}
{"id": "1210.7468", "contents": "Title: Link Scheduling in Amplify-and-Forward Cooperative Wireless Networks Abstract: In this work we are concerned with the problem of link scheduling for\nthroughput maximization in wireless networks that employ a cooperative amplify\nand forward (AF) protocol. To address this problem first we define the\nsignal-to-interference plus noise ratio (SINR) expression for the complete\ncooperative AF-based transmission. Next, we formulate the problem of link\nscheduling as a mixed integer linear program (MILP) that uses as a constraint\nthe developed SINR expression. The proposed formulation is motivated by the\nobservation that the aggregate interference that affects a single cooperative\ntransmission can be decomposed into two separate SINR constraints. Results for\nthe optimal solution and a polynomial time approximation algorithm are also\npresented. \n\n"}
{"id": "1210.7837", "contents": "Title: Scheduling Under Fading and Partial Channel Information Abstract: We consider a scheduler for the downlink of a wireless channel when only\npartial channel-state information is available at the scheduler. We\ncharacterize the network stability region and provide two throughput-optimal\nscheduling policies. We also derive a deterministic bound on the mean packet\ndelay in the network. Finally, we provide a throughput-optimal policy for the\nnetwork under QoS constraints when real-time and rate-guaranteed data traffic\nmay be present. \n\n"}
{"id": "1210.8433", "contents": "Title: Green Cellular Wireless Networks: Where to Begin? Abstract: Conventional cellular wireless networks were designed with the purpose of\nproviding high throughput for the user and high capacity for the service\nprovider, without any provisions of energy efficiency. As a result, these\nnetworks have an enormous Carbon footprint. In this note, we describe the\nsources of the inefficiencies in such networks. First we quantify how much\nCarbon footprint such networks generate. We also discuss how much more mobile\ntraffic is expected to increase so that this Carbon footprint will even\nincrease tremendously more. We then discuss specific sources of inefficiency\nand potential sources of improvement at the physical layer as well as higher\nlayers of the communication protocol hierarchy. In particular, considering that\nmost of the energy inefficiency in wireless cellular networks is at the base\nstations, we discuss multi-tier networks and point to the potential of\nexploiting mobility patterns in order to use base station energy judiciously. \n\n"}
{"id": "1211.0415", "contents": "Title: Capacity and Security of Heterogeneous Distributed Storage Systems Abstract: We study the capacity of heterogeneous distributed storage systems under\nrepair dynamics. Examples of these systems include peer-to-peer storage clouds,\nwireless, and Internet caching systems. Nodes in a heterogeneous system can\nhave different storage capacities and different repair bandwidths. We give\nlower and upper bounds on the system capacity. These bounds depend on either\nthe average resources per node, or on a detailed knowledge of the node\ncharacteristics. Moreover, we study the case in which nodes may be compromised\nby an eavesdropper, and give bounds on the system secrecy capacity. One\nimplication of our results is that symmetric repair maximizes the capacity of a\nhomogeneous system, which justifies the model widely used in the literature. \n\n"}
{"id": "1211.3881", "contents": "Title: Unbiased gradient estimation in queueing networks with\n  parameter-dependent routing Abstract: A stochastic queueing network model with parameter-dependent service times\nand routing mechanism, and its related performance measures are considered. An\nestimate of performance measure gradient is proposed, and rather general\nsufficient conditions for the estimate to be unbiased are given. A gradient\nestimation algorithm is also presented, and its validity is briefly discussed. \n\n"}
{"id": "1211.5405", "contents": "Title: The MDS Queue: Analysing the Latency Performance of Erasure Codes Abstract: In order to scale economically, data centers are increasingly evolving their\ndata storage methods from the use of simple data replication to the use of more\npowerful erasure codes, which provide the same level of reliability as\nreplication but at a significantly lower storage cost. In particular, it is\nwell known that Maximum-Distance-Separable (MDS) codes, such as Reed-Solomon\ncodes, provide the maximum storage efficiency. While the use of codes for\nproviding improved reliability in archival storage systems, where the data is\nless frequently accessed (or so-called \"cold data\"), is well understood, the\nrole of codes in the storage of more frequently accessed and active \"hot data\",\nwhere latency is the key metric, is less clear.\n  In this paper, we study data storage systems based on MDS codes through the\nlens of queueing theory, and term this the \"MDS queue.\" We analytically\ncharacterize the (average) latency performance of MDS queues, for which we\npresent insightful scheduling policies that form upper and lower bounds to\nperformance, and are observed to be quite tight. Extensive simulations are also\nprovided and used to validate our theoretical analysis. We also employ the\nframework of the MDS queue to analyse different methods of performing so-called\ndegraded reads (reading of partial data) in distributed data storage. \n\n"}
{"id": "1211.6255", "contents": "Title: Keyhole and Reflection Effects in Network Connectivity Analysis Abstract: Recent research has demonstrated the importance of boundary effects on the\noverall connection probability of wireless networks, but has largely focused on\nconvex domains. We consider two generic scenarios of practical importance to\nwireless communications, in which one or more nodes are located outside the\nconvex space where the remaining nodes reside. Consequently, conventional\napproaches with the underlying assumption that only line-of-sight (LOS) or\ndirect connections between nodes are possible, fail to provide the correct\nanalysis for the connectivity. We present an analytical framework that\nexplicitly considers the effects of reflections from the system boundaries on\nthe full connection probability. This study provides a different strategy to\nray tracing tools for predicting the wireless propagation environment. A simple\ntwo-dimensional geometry is first considered, followed by a more practical\nthree-dimensional system. We investigate the effects of different system\nparameters on the connectivity of the network though analysis corroborated by\nnumerical simulations, and highlight the potential of our approach for more\ngeneral non-convex geometries.t system parameters on the connectivity of the\nnetwork through simulation and analysis. \n\n"}
{"id": "1211.6950", "contents": "Title: Dynamic Network Cartography Abstract: Communication networks have evolved from specialized, research and tactical\ntransmission systems to large-scale and highly complex interconnections of\nintelligent devices, increasingly becoming more commercial, consumer-oriented,\nand heterogeneous. Propelled by emergent social networking services and\nhigh-definition streaming platforms, network traffic has grown explosively\nthanks to the advances in processing speed and storage capacity of\nstate-of-the-art communication technologies. As \"netizens\" demand a seamless\nnetworking experience that entails not only higher speeds, but also resilience\nand robustness to failures and malicious cyber-attacks, ample opportunities for\nsignal processing (SP) research arise. The vision is for ubiquitous smart\nnetwork devices to enable data-driven statistical learning algorithms for\ndistributed, robust, and online network operation and management, adaptable to\nthe dynamically-evolving network landscape with minimal need for human\nintervention. The present paper aims at delineating the analytical background\nand the relevance of SP tools to dynamic network monitoring, introducing the SP\nreadership to the concept of dynamic network cartography -- a framework to\nconstruct maps of the dynamic network state in an efficient and scalable manner\ntailored to large-scale heterogeneous networks. \n\n"}
{"id": "1211.6988", "contents": "Title: Simultaneous Distributed Sensor Self-Localization and Target Tracking\n  Using Belief Propagation and Likelihood Consensus Abstract: We introduce the framework of cooperative simultaneous localization and\ntracking (CoSLAT), which provides a consistent combination of cooperative\nself-localization (CSL) and distributed target tracking (DTT) in sensor\nnetworks without a fusion center. CoSLAT extends simultaneous localization and\ntracking (SLAT) in that it uses also intersensor measurements. Starting from a\nfactor graph formulation of the CoSLAT problem, we develop a particle-based,\ndistributed message passing algorithm for CoSLAT that combines nonparametric\nbelief propagation with the likelihood consensus scheme. The proposed CoSLAT\nalgorithm improves on state-of-the-art CSL and DTT algorithms by exchanging\nprobabilistic information between CSL and DTT. Simulation results demonstrate\nsubstantial improvements in both self-localization and tracking performance. \n\n"}
{"id": "1212.0724", "contents": "Title: A Potential Game for Power and Frequency Allocation in Large-Scale\n  Wireless Networks Abstract: In this paper we analyze power and frequency allocation in wireless networks\nthrough potential games. Potential games are used frequently in the literature\nfor this purpose due to their desirable properties, such as convergence and\nstability. However, potential games usually assume massive message passing to\nobtain the necessary neighbor information at each user to achieve these\nproperties. In this paper we show an example of a game where we are able to\ncharacterize the necessary neighbor information in order to show that the game\nhas a potential function and the properties of potential games. We consider a\nnetwork consisting of local access points where the goal of each AP is to\nallocate power and frequency to achieve some SINR requirement. We use the\nphysical SINR model to validate a successful allocation, and show that given a\nsuitable payoff function the game emits a generalized ordinal potential\nfunction under the assumption of sufficient neighbor information. Through\nsimulations we evaluate the performance of the proposed game on a large scale\nin relation to the amount of information at each AP. \n\n"}
{"id": "1212.1735", "contents": "Title: Towards Design of System Hierarchy (research survey) Abstract: The paper addresses design/building frameworks for some kinds of tree-like\nand hierarchical structures of systems. The following approaches are examined:\n(1) expert-based procedures, (2) hierarchical clustering; (3) spanning problems\n(e.g., minimum spanning tree, minimum Steiner tree, maximum leaf spanning tree\nproblem; (4) design of organizational 'optimal' hierarchies; (5) design of\nmulti-layer (e.g., three-layer) k-connected network; (6) modification of\nhierarchies or networks: (i) modification of tree via condensing of neighbor\nnodes, (ii) hotlink assignment, (iii) transformation of tree into Steiner tree,\n(iv) restructuring as modification of an initial structural solution into a\nsolution that is the most close to a goal solution while taking into account a\ncost of the modification. Combinatorial optimization problems are considered as\nbasic ones (e.g., classification, knapsack problem, multiple choice problem,\nassignment problem). Some numerical examples illustrate the suggested problems\nand solving frameworks. \n\n"}
{"id": "1212.4915", "contents": "Title: Can P2P Technology Benefit Eyeball ISPs? A Cooperative Profit\n  Distribution Answer Abstract: Peer-to-Peer (P2P) technology has been regarded as a promising way to help\nContent Providers (CPs) cost-effectively distribute content. However, under the\ntraditional Internet pricing mechanism, the fact that most P2P traffic flows\namong peers can dramatically decrease the profit of ISPs, who may take actions\nagainst P2P and impede the progress of P2P technology. In this paper, we\ndevelop a mathematical framework to analyze such economic issues. Inspired by\nthe idea from cooperative game theory, we propose a cooperative\nprofit-distribution model based on Nash Bargaining Solution (NBS), in which\neyeball ISPs and Peer-assisted CPs (PCPs) form two coalitions respectively and\nthen compute a fair Pareto point to determine profit distribution. Moreover, we\ndesign a fair and feasible mechanism for profit distribution within each\ncoalition. We show that such a cooperative method not only guarantees the fair\nprofit distribution among network participators, but also helps to improve the\neconomic efficiency of the overall network system. To our knowledge, this is\nthe first work that systematically studies solutions for P2P caused unbalanced\nprofit distribution and gives a feasible cooperative method to increase and\nfairly share profit. \n\n"}
{"id": "1212.6627", "contents": "Title: Exploring Relay Cooperation Scheme for Load-Balance Control in Two-hop\n  Secure Communication System Abstract: This work considers load-balance control among the relays under the secure\ntransmission protocol via relay cooperation in two-hop wireless networks\nwithout the information of both eavesdropper channels and locations. The\navailable two-hop secure transmission protocols in physical layer secrecy\nframework cannot provide a flexible load-balance control, which may\nsignificantly limit their application scopes. This paper proposes a secure\ntransmission protocol in case that the path-loss is identical between all pairs\nof nodes, in which the relay is randomly selected from the first $k$ preferable\nassistant relays. This protocol enables load-balance among relays to be\nflexibly controlled by a proper setting of the parameter $k$, and covers the\navailable works as special cases, like ones with the optimal relay selection\n($k=1$) and ones with the random relay selection ($k = n$, i.e. the number of\nsystem nodes). The theoretic analysis is further provided to determine the\nmaximum number of eavesdroppers one network can tolerate by applying the\nproposed protocol to ensure a desired performance in terms of the secrecy\noutage probability and transmission outage probability. \n\n"}
{"id": "1301.1746", "contents": "Title: Generalized Secure Transmission Protocol for Flexible Load-Balance\n  Control with Cooperative Relays in Two-Hop Wireless Networks Abstract: This work considers secure transmission protocol for flexible load-balance\ncontrol in two-hop relay wireless networks without the information of both\neavesdropper channels and locations. The available secure transmission\nprotocols via relay cooperation in physical layer secrecy framework cannot\nprovide a flexible load-balance control, which may significantly limit their\napplication scopes. This paper extends the conventional works and proposes a\ngeneral transmission protocol with considering load-balance control, in which\nthe relay is randomly selected from the first $k$ preferable assistant relays\nlocated in the circle area with the radius $r$ and the center at the middle\nbetween source and destination (2HR-($r,k$) for short). This protocol covers\nthe available works as special cases, like ones with the optimal relay\nselection ($r=\\infty$, $k=1$) and with the random relay selection ($r=\\infty$,\n$k = n$ i.e. the number of system nodes) in the case of equal path-loss, ones\nwith relay selected from relay selection region ($r \\in (0, \\infty), k = 1$) in\nthe case of distance-dependent path-loss. The theoretic analysis is further\nprovided to determine the maximum number of eavesdroppers one network can\ntolerate to ensure a desired performance in terms of the secrecy outage\nprobability and transmission outage probability. The analysis results also show\nthe proposed protocol can balance load distributed among the relays by a proper\nsetting of $r$ and $k$ under the premise of specified secure and reliable\nrequirements. \n\n"}
{"id": "1301.2220", "contents": "Title: Providing Probabilistic Guarantees on the Time of Information Spread in\n  Opportunistic Networks Abstract: A variety of mathematical tools have been developed for predicting the\nspreading patterns in a number of varied environments including infectious\ndiseases, computer viruses, and urgent messages broadcast to mobile agent\n(e.g., humans, vehicles, and mobile devices). These tools have mainly focused\non estimating the average time for the spread to reach a fraction (e.g.,\n$\\alpha$) of the agents, i.e., the so-called average completion time\n$E(T_{\\alpha})$. We claim that providing probabilistic guarantee on the time\nfor the spread $T_{\\alpha}$ rather than only its average gives a much better\nunderstanding of the spread, and hence could be used to design improved methods\nto prevent epidemics or devise accelerated methods for distributing data. To\ndemonstrate the benefits, we introduce a new metric $G_{\\alpha, \\beta}$ that\ndenotes the time required to guarantee $\\alpha$ completion with probability\n$\\beta$, and develop a new framework to characterize the distribution of\n$T_\\alpha$ for various spread parameters such as number of seeds, level of\ncontact rates, and heterogeneity in contact rates. We apply our technique to an\nexperimental mobility trace of taxies in Shanghai and show that our framework\nenables us to allocate resources (i.e., to control spread parameters) for\nacceleration of spread in a far more efficient way than the state-of-the-art. \n\n"}
{"id": "1301.3230", "contents": "Title: A Framework for Quality of Service with a Multiple Access Strategy Abstract: We study a problem of scheduling real-time traffic with hard delay\nconstraints in an unreliable wireless channel. Packets arrive at a constant\nrate to the network and have to be delivered within a fixed number of slots in\na fading wireless channel. For an infrastructure mode of traffic with a\ncentralized scheduler, we are interested in the long time average throughput\nachievable for the real time traffic. In [1], the authors have stud- ied the\nfeasible throughput vectors by identifying the necessary and sufficient\nconditions using work load characterization. In our work, we provide a\ncharacterization of the feasible throughput vectors using the notion of the\nrate region. We then discuss an extension to the network model studied in [1]\nby allowing multiple access during contention and propose an enhancement to the\nrate region of the wireless network. We characterize the feasible throughput\nvectors with the multiple access technique and study throughput optimal and\nutility maximizing strategies for the network scenario. Using simulations, we\nevaluate the performance of the proposed strategy and discuss its advantages. \n\n"}
{"id": "1301.3302", "contents": "Title: Measurement Based Impromptu Deployment of a Multi-Hop Wireless Relay\n  Network Abstract: We study the problem of optimal sequential (\"as-you-go\") deployment of\nwireless relay nodes as a person walks along a line of random length (with a\nknown distribution). The objective is to create an impromptu multihop wireless\nnetwork for connecting a packet source to be placed at the end of the line with\na sink node located at the starting point, to operate in the light traffic\nregime. As the deployment person walks along the line from the sink towards the\nsource, at every step, he measures the channel quality to one (or more)\npreviously placed relays, and places the relay nodes based on these\nmeasurements, so as to minimize either the sum power or the maximum power from\nthe source to the sink node in the resultant network, subject to a constraint\non the expected number of relays placed. For each of these two objectives, two\ndifferent relay selection strategies are considered: (i) each relay\ncommunicates with the sink via its immediate previous relay, (ii) the\ncommunication path can skip some of the deployed relays. With appropriate\nmodeling assumptions, we formulate each of these problems as a Markov decision\nprocess (MDP). We provide the optimal policy structures for all these cases,\nand provide illustrations, via numerical results, for some typical parameters. \n\n"}
{"id": "1301.4909", "contents": "Title: Analyzing the Performance of LRU Caches under Non-Stationary Traffic\n  Patterns Abstract: This work presents, to the best of our knowledge of the literature, the first\nanalytic model to address the performance of an LRU (Least Recently Used)\nimplementing cache under non-stationary traffic conditions, i.e., when the\npopularity of content evolves with time. We validate the accuracy of the model\nusing Monte Carlo simulations. We show that the model is capable of accurately\nestimating the cache hit probability, when the popularity of content is\nnon-stationary.\n  We find that there exists a dependency between the performance of an LRU\nimplementing cache and i) the lifetime of content in a system, ii) the volume\nof requests associated with it, iii) the distribution of content request\nvolumes and iv) the shape of the popularity profile over time. \n\n"}
{"id": "1301.6491", "contents": "Title: SINR-based k-coverage probability in cellular networks with arbitrary\n  shadowing Abstract: We give numerically tractable, explicit integral expressions for the\ndistribution of the signal-to-interference-and-noise-ratio (SINR) experienced\nby a typical user in the down-link channel from the k-th strongest base\nstations of a cellular network modelled by Poisson point process on the plane.\nOur signal propagation-loss model comprises of a power-law path-loss function\nwith arbitrarily distributed shadowing, independent across all base stations,\nwith and without Rayleigh fading. Our results are valid in the whole domain of\nSINR, in particular for SINR<1, where one observes multiple coverage. In this\nlatter aspect our paper complements previous studies reported in [Dhillon et\nal. JSAC 2012]. \n\n"}
{"id": "1302.2185", "contents": "Title: Passive Self-Interference Suppression for Full-Duplex Infrastructure\n  Nodes Abstract: Recent research results have demonstrated the feasibility of full-duplex\nwireless communication for short-range links. Although the focus of the\nprevious works has been active cancellation of the self-interference signal, a\nmajority of the overall self-interference suppression is often due to passive\nsuppression, i.e., isolation of the transmit and receive antennas. We present a\nmeasurement-based study of the capabilities and limitations of three key\nmechanisms for passive self-interference suppression: directional isolation,\nabsorptive shielding, and cross-polarization. The study demonstrates that more\nthan 70 dB of passive suppression can be achieved in certain environments, but\nalso establishes two results on the limitations of passive suppression: (1)\nenvironmental reflections limit the amount of passive suppression that can be\nachieved, and (2) passive suppression, in general, increases the frequency\nselectivity of the residual self-interference signal. These results suggest two\ndesign implications: (1) deployments of full-duplex infrastructure nodes should\nminimize near-antenna reflectors, and (2) active cancellation in concatenation\nwith passive suppression should employ higher-order filters or per-subcarrier\ncancellation. \n\n"}
{"id": "1302.3726", "contents": "Title: Improved upper and lower bound techniques for monotone switching\n  networks for directed connectivity Abstract: In this paper, we analyze the monotone space of complexity of directed\nconnectivity for a large class of input graphs $G$ using the switching network\nmodel. The upper and lower bounds we obtain are a significant generalization of\nprevious results and the proofs involve several completely new techniques and\nideas. \n\n"}
{"id": "1302.3784", "contents": "Title: Algorithms for Enhanced Inter Cell Interference Coordination (eICIC) in\n  LTE HetNets Abstract: The success of LTE Heterogeneous Networks (HetNets) with macro cells and pico\ncells critically depends on efficient spectrum sharing between high-power\nmacros and low-power picos. Two important challenges in this context are, {(i)}\ndetermining the amount of radio resources that macro cells should {\\em offer}\nto pico cells, and {(ii)} determining the association rules that decide which\nUEs should associate with picos. In this paper, we develop a novel algorithm to\nsolve these two coupled problems in a joint manner. Our algorithm has provable\nguarantee, and furthermore, it accounts for network topology, traffic load, and\nmacro-pico interference map. Our solution is standard compliant and can be\nimplemented using the notion of Almost Blank Subframes (ABS) and Cell Selection\nBias (CSB) proposed by LTE standards. We also show extensive evaluations using\nRF plan from a real network and discuss SON based eICIC implementation. \n\n"}
{"id": "1302.4474", "contents": "Title: On the multiple unicast capacity of 3-source, 3-terminal directed\n  acyclic networks Abstract: We consider the multiple unicast problem with three source-terminal pairs\nover directed acyclic networks with unit-capacity edges. The three $s_i-t_i$\npairs wish to communicate at unit-rate via network coding. The connectivity\nbetween the $s_i - t_i$ pairs is quantified by means of a connectivity level\nvector, $[k_1 k_2 k_3]$ such that there exist $k_i$ edge-disjoint paths between\n$s_i$ and $t_i$. In this work we attempt to classify networks based on the\nconnectivity level. It can be observed that unit-rate transmission can be\nsupported by routing if $k_i \\geq 3$, for all $i = 1, \\dots, 3$. In this work,\nwe consider, connectivity level vectors such that $\\min_{i = 1, \\dots, 3} k_i <\n3$. We present either a constructive linear network coding scheme or an\ninstance of a network that cannot support the desired unit-rate requirement,\nfor all such connectivity level vectors except the vector $[1~2~4]$ (and its\npermutations). The benefits of our schemes extend to networks with higher and\npotentially different edge capacities. Specifically, our experimental results\nindicate that for networks where the different source-terminal paths have a\nsignificant overlap, our constructive unit-rate schemes can be packed along\nwith routing to provide higher throughput as compared to a pure routing\napproach. \n\n"}
{"id": "1302.4793", "contents": "Title: Opportunistic Wireless Energy Harvesting in Cognitive Radio Networks Abstract: Wireless networks can be self-sustaining by harvesting energy from ambient\nradio-frequency (RF) signals. Recently, researchers have made progress on\ndesigning efficient circuits and devices for RF energy harvesting suitable for\nlow-power wireless applications. Motivated by this and building upon the\nclassic cognitive radio (CR) network model, this paper proposes a novel method\nfor wireless networks coexisting where low-power mobiles in a secondary\nnetwork, called secondary transmitters (STs), harvest ambient RF energy from\ntransmissions by nearby active transmitters in a primary network, called\nprimary transmitters (PTs), while opportunistically accessing the spectrum\nlicensed to the primary network. We consider a stochastic-geometry model in\nwhich PTs and STs are distributed as independent homogeneous Poisson point\nprocesses (HPPPs) and communicate with their intended receivers at fixed\ndistances. Each PT is associated with a guard zone to protect its intended\nreceiver from ST's interference, and at the same time delivers RF energy to STs\nlocated in its harvesting zone. Based on the proposed model, we analyze the\ntransmission probability of STs and the resulting spatial throughput of the\nsecondary network. The optimal transmission power and density of STs are\nderived for maximizing the secondary network throughput under the given\noutage-probability constraints in the two coexisting networks, which reveal key\ninsights to the optimal network design. Finally, we show that our analytical\nresult can be generally applied to a non-CR setup, where distributed wireless\npower chargers are deployed to power coexisting wireless transmitters in a\nsensor network. \n\n"}
{"id": "1302.5945", "contents": "Title: Queue-Based Random-Access Algorithms: Fluid Limits and Stability Issues Abstract: We use fluid limits to explore the (in)stability properties of wireless\nnetworks with queue-based random-access algorithms. Queue-based random-access\nschemes are simple and inherently distributed in nature, yet provide the\ncapability to match the optimal throughput performance of centralized\nscheduling mechanisms in a wide range of scenarios. Unfortunately, the type of\nactivation rules for which throughput optimality has been established, may\nresult in excessive queue lengths and delays. The use of more\naggressive/persistent access schemes can improve the delay performance, but\ndoes not offer any universal maximum-stability guarantees. In order to gain\nqualitative insight and investigate the (in)stability properties of more\naggressive/persistent activation rules, we examine fluid limits where the\ndynamics are scaled in space and time. In some situations, the fluid limits\nhave smooth deterministic features and maximum stability is maintained, while\nin other scenarios they exhibit random oscillatory characteristics, giving rise\nto major technical challenges. In the latter regime, more aggressive access\nschemes continue to provide maximum stability in some networks, but may cause\ninstability in others. Simulation experiments are conducted to illustrate and\nvalidate the analytical results. \n\n"}
{"id": "1303.2636", "contents": "Title: Energy Cooperation in Energy Harvesting Communications Abstract: In energy harvesting communications, users transmit messages using energy\nharvested from nature during the course of communication. With an optimum\ntransmit policy, the performance of the system depends only on the energy\narrival profiles. In this paper, we introduce the concept of energy\ncooperation, where a user wirelessly transmits a portion of its energy to\nanother energy harvesting user. This enables shaping and optimization of the\nenergy arrivals at the energy-receiving node, and improves the overall system\nperformance, despite the loss incurred in energy transfer. We consider several\nbasic multi-user network structures with energy harvesting and wireless energy\ntransfer capabilities: relay channel, two-way channel and multiple access\nchannel. We determine energy management policies that maximize the system\nthroughput within a given duration using a Lagrangian formulation and the\nresulting KKT optimality conditions. We develop a two-dimensional directional\nwater-filling algorithm which optimally controls the flow of harvested energy\nin two dimensions: in time (from past to future) and among users (from\nenergy-transferring to energy-receiving) and show that a generalized version of\nthis algorithm achieves the boundary of the capacity region of the two-way\nchannel. \n\n"}
{"id": "1303.2952", "contents": "Title: Traffic Congestion in Expanders, $(p,\\delta)$--Hyperbolic Spaces and\n  Product of Trees Abstract: In this paper we define the notion of $(p,\\delta)$--Gromov hyperbolic space\nwhere we relax Gromov's {\\it slimness} condition to allow that not all but a\npositive fraction of all triangles are $\\delta$--slim. Furthermore, we study\nmaximum vertex congestion under geodesic routing and show that it scales as\n$\\Omega(p^2n^2/D_n^2)$ where $D_n$ is the diameter of the graph. We also\nconstruct a constant degree family of expanders with congestion $\\Theta(n^2)$\nin contrast with random regular graphs that have congestion $O(n\\log^{3}(n))$.\nFinally, we study traffic congestion on graphs defined as product of trees. \n\n"}
{"id": "1303.6323", "contents": "Title: Constructing Limited Scale-Free Topologies Over Peer-to-Peer Networks Abstract: Overlay network topology together with peer/data organization and search\nalgorithm are the crucial components of unstructured peer-to-peer (P2P)\nnetworks as they directly affect the efficiency of search on such networks.\nScale-free (powerlaw) overlay network topologies are among structures that\noffer high performance for these networks. A key problem for these topologies\nis the existence of hubs, nodes with high connectivity. Yet, the peers in a\ntypical unstructured P2P network may not be willing or able to cope with such\nhigh connectivity and its associated load. Therefore, some hard cutoffs are\noften imposed on the number of edges that each peer can have, restricting\nfeasible overlays to limited or truncated scale-free networks. In this paper,\nwe analyze the growth of such limited scale-free networks and propose two\ndifferent algorithms for constructing perfect scale-free overlay network\ntopologies at each instance of such growth. Our algorithms allow the user to\ndefine the desired scalefree exponent (gamma). They also induce low\ncommunication overhead when network grows from one size to another. Using\nextensive simulations, we demonstrate that these algorithms indeed generate\nperfect scale free networks (at each step of network growth) that provide\nbetter search efficiency in various search algorithms than the networks\ngenerated by the existing solutions. \n\n"}
{"id": "1303.6518", "contents": "Title: SRP-MS: A New Routing Protocol for Delay Tolerant Wireless Sensor\n  Networks Abstract: Sink Mobility is becoming popular due to excellent load balancing between\nnodes and ultimately resulting in prolonged network lifetime and throughput. A\nmajor challenge is to provide reliable and energy-efficient operations are to\nbe taken into consideration for differentmobility patterns of sink. Aim of this\npaper is lifetime maximization of Delay TolerantWireless Sensor Networks (WSNs)\nthrough the manipulation of Mobile Sink (MS) on different trajectories. We\npropose Square Routing Protocol with MS (SRP-MS) based on existing SEP (Stable\nElection Protocol) by making it Cluster Less (CL) and introducing sink\nmobility. \n\n"}
{"id": "1304.1649", "contents": "Title: Trust Estimation in Peer-to-Peer Network Using BLUE Abstract: In peer-to-peer networks, free riding is a major problem. Reputation\nmanagement systems can be used to overcome this problem. Reputation estimation\nmethods generally do not consider the uncertainties in the inputs. We propose a\nreputation estimation method using BLUE (Best Linear Unbiased estimator)\nestimator that consider uncertainties in the input variables. \n\n"}
{"id": "1304.1981", "contents": "Title: Auction-based Resource Allocation in MillimeterWave Wireless Access\n  Networks Abstract: The resource allocation problem of optimal assignment of the clients to the\navailable access points in 60 GHz millimeterWave wireless access networks is\ninvestigated. The problem is posed as a multiassignment optimisation problem.\nThe proposed solution method converts the initial problem to a minimum cost\nflow problem and allows to design an efficient algorithm by a combination of\nauction algorithms. The solution algorithm exploits the network optimization\nstructure of the problem, and thus is much more powerful than computationally\nintensive general-purpose solvers. Theoretical and numerical results evince\nnumerous properties, such as optimality, convergence, and scalability in\ncomparison to existing approaches. \n\n"}
{"id": "1304.8083", "contents": "Title: Adaptive Video Streaming for Wireless Networks with Multiple Users and\n  Helpers Abstract: We consider the optimal design of a scheduling policy for adaptive video\nstreaming in a wireless network formed by several users and helpers. A feature\nof such networks is that any user is typically in the range of multiple\nhelpers. Hence, in order to cope with user-helper association, load balancing\nand inter-cell interference, an efficient streaming policy should allow the\nusers to dynamically select the helper node to download from, and determine\nadaptively the video quality level of the download. In order to obtain a\ntractable formulation, we follow a \"divide and conquer\" approach: i) Assuming\nthat each video packet (chunk) is delivered within its playback delay (\"smooth\nstreaming regime\"), the problem is formulated as a network utility maximization\n(NUM), subject to queue stability, where the network utility function is a\nconcave and componentwise non-decreasing function of the users' video quality\nmeasure. ii) We solve the NUM problem by using a Lyapunov Drift Plus Penalty\napproach, obtaining a scheme that naturally decomposes into two sub-policies\nreferred to as \"congestion control\" (adaptive video quality and helper station\nselection) and \"transmission scheduling\" (dynamic allocation of the helper-user\nphysical layer transmission rates).Our solution is provably optimal with\nrespect to the proposed NUM problem, in a strong per-sample path sense. iii)\nFinally, we propose a method to adaptively estimate the maximum queuing delays,\nsuch that each user can calculate its pre-buffering and re-buffering time in\norder to cope with the fluctuations of the queuing delays. Through simulations,\nwe evaluate the performance of the proposed algorithm under realistic\nassumptions of a network with densely deployed helper nodes, and demonstrate\nthe per-sample path optimality of the proposed solution by considering a\nnon-stationary non-ergodic scenario with user mobility, VBR video coding. \n\n"}
{"id": "1305.3586", "contents": "Title: Utility Optimal Scheduling and Admission Control for Adaptive Video\n  Streaming in Small Cell Networks Abstract: We consider the jointly optimal design of a transmission scheduling and\nadmission control policy for adaptive video streaming over small cell networks.\nWe formulate the problem as a dynamic network utility maximization and observe\nthat it naturally decomposes into two subproblems: admission control and\ntransmission scheduling. The resulting algorithms are simple and suitable for\ndistributed implementation. The admission control decisions involve each user\nchoosing the quality of the video chunk asked for download, based on the\nnetwork congestion in its neighborhood. This form of admission control is\ncompatible with the current video streaming technology based on the DASH\nprotocol over TCP connections. Through simulations, we evaluate the performance\nof the proposed algorithm under realistic assumptions for a small-cell network. \n\n"}
{"id": "1305.3595", "contents": "Title: Binary Energy Harvesting Channel with Finite Energy Storage Abstract: We consider the capacity of an energy harvesting communication channel with a\nfinite-sized battery. As an abstraction of this problem, we consider a system\nwhere energy arrives at the encoder in multiples of a fixed quantity, and the\nphysical layer is modeled accordingly as a finite discrete alphabet channel\nbased on this fixed quantity. Further, for tractability, we consider the case\nof binary energy arrivals into a unit-capacity battery over a noiseless binary\nchannel. Viewing the available energy as state, this is a state-dependent\nchannel with causal state information available only at the transmitter.\nFurther, the state is correlated over time and the channel inputs modify the\nfuture states. We show that this channel is equivalent to an additive\ngeometric-noise timing channel with causal information of the noise available\nat the transmitter.We provide a single-letter capacity expression involving an\nauxiliary random variable, and evaluate this expression with certain auxiliary\nrandom variable selection, which resembles noise concentration and lattice-type\ncoding in the timing channel. We evaluate the achievable rates by the proposed\nauxiliary selection and extend our results to noiseless ternary channels. \n\n"}
{"id": "1305.3688", "contents": "Title: The Thinnest Path Problem Abstract: We formulate and study the thinnest path problem in wireless ad hoc networks.\nThe objective is to find a path from a source to its destination that results\nin the minimum number of nodes overhearing the message by a judicious choice of\nrelaying nodes and their corresponding transmission power. We adopt a directed\nhypergraph model of the problem and establish the NP-completeness of the\nproblem in 2-D networks. We then develop two polynomial-time approximation\nalgorithms that offer $\\sqrt{\\frac{n}{2}}$ and $\\frac{n}{2\\sqrt{n-1}}$\napproximation ratios for general directed hypergraphs (which can model\nnon-isomorphic signal propagation in space) and constant approximation ratios\nfor ring hypergraphs (which result from isomorphic signal propagation). We also\nconsider the thinnest path problem in 1-D networks and 1-D networks embedded in\n2-D field of eavesdroppers with arbitrary unknown locations (the so-called\n1.5-D networks). We propose a linear-complexity algorithm based on nested\nbackward induction that obtains the optimal solution to both 1-D and 1.5-D\nnetworks. This algorithm does not require the knowledge of eavesdropper\nlocations and achieves the best performance offered by any algorithm that\nassumes complete location information of the eavesdroppers. \n\n"}
{"id": "1305.5483", "contents": "Title: NEMESYS: Enhanced Network Security for Seamless Service Provisioning in\n  the Smart Mobile Ecosystem Abstract: As a consequence of the growing popularity of smart mobile devices, mobile\nmalware is clearly on the rise, with attackers targeting valuable user\ninformation and exploiting vulnerabilities of the mobile ecosystems. With the\nemergence of large-scale mobile botnets, smartphones can also be used to launch\nattacks on mobile networks. The NEMESYS project will develop novel security\ntechnologies for seamless service provisioning in the smart mobile ecosystem,\nand improve mobile network security through better understanding of the threat\nlandscape. NEMESYS will gather and analyze information about the nature of\ncyber-attacks targeting mobile users and the mobile network so that appropriate\ncounter-measures can be taken. We will develop a data collection infrastructure\nthat incorporates virtualized mobile honeypots and a honeyclient, to gather,\ndetect and provide early warning of mobile attacks and better understand the\nmodus operandi of cyber-criminals that target mobile devices. By correlating\nthe extracted information with the known patterns of attacks from wireline\nnetworks, we will reveal and identify trends in the way that cyber-criminals\nlaunch attacks against mobile devices. \n\n"}
{"id": "1305.6992", "contents": "Title: Coexistence and Interference Mitigation for Wireless Body Area Networks:\n  Improvements using On-Body Opportunistic Relaying Abstract: Coexistence, and hence interference mitigation, across multiple wireless body\narea networks (WBANs) is an important problem as WBANs become more pervasive.\nHere, two-hop relay-assisted cooperative communications using opportunistic\nrelaying (OR) is proposed for enhancement of coexistence for WBANs. Suitable\ntime division multiple access (TDMA) schemes are employed for both intra-WBAN\nand inter-WBANs access protocols. To emulate actual conditions of WBAN use,\nextensive on-body and inter-body \"everyday\" channel measurements are employed.\nIn addition, a realistic inter-WBAN channel model is simulated to investigate\nthe effect of body shadowing and hub location on WBAN performance in enabling\ncoexistence. When compared with single-link communications, it is found that\nopportunistic relaying can provide significant improvement, in terms of\nsignal-to-interference+noise ratio (SINR), to outage probability and level\ncrossing rate (LCR) into outages. However, average outage duration (AOD) is not\naffected. In addition a lognormal distribution shows a better fit to received\nSINR when the channel coherence time is small, and a Nakagami-m distribution is\na more common fit when the channel is more stable. According to the estimated\nSINR distributions, theoretical outage probability, LCR and AOD are shown to\nmatch the empirical results well. \n\n"}
{"id": "1305.7114", "contents": "Title: Temporal Locality in Today's Content Caching: Why it Matters and How to\n  Model it Abstract: The dimensioning of caching systems represents a difficult task in the design\nof infrastructures for content distribution in the current Internet. This paper\naddresses the problem of defining a realistic arrival process for the content\nrequests generated by users, due its critical importance for both analytical\nand simulative evaluations of the performance of caching systems. First, with\nthe aid of YouTube traces collected inside operational residential networks, we\nidentify the characteristics of real traffic that need to be considered or can\nbe safely neglected in order to accurately predict the performance of a cache.\nSecond, we propose a new parsimonious traffic model, named the Shot Noise Model\n(SNM), that enables users to natively capture the dynamics of content\npopularity, whilst still being sufficiently simple to be employed effectively\nfor both analytical and scalable simulative studies of caching systems.\nFinally, our results show that the SNM presents a much better solution to\naccount for the temporal locality observed in real traffic compared to existing\napproaches. \n\n"}
{"id": "1306.0772", "contents": "Title: Equivalence and comparison of heterogeneous cellular networks Abstract: We consider a general heterogeneous network in which, besides general\npropagation effects (shadowing and/or fading), individual base stations can\nhave different emitting powers and be subject to different parameters of\nHata-like path-loss models (path-loss exponent and constant) due to, for\nexample, varying antenna heights. We assume also that the stations may have\nvarying parameters of, for example, the link layer performance (SINR threshold,\netc). By studying the propagation processes of signals received by the typical\nuser from all antennas marked by the corresponding antenna parameters, we show\nthat seemingly different heterogeneous networks based on Poisson point\nprocesses can be equivalent from the point of view a typical user. These\nneworks can be replaced with a model where all the previously varying\npropagation parameters (including path-loss exponents) are set to constants\nwhile the only trade-off being the introduction of an isotropic base station\ndensity. This allows one to perform analytic comparisons of different network\nmodels via their isotropic representations. In the case of a constant path-loss\nexponent, the isotropic representation simplifies to a homogeneous modification\nof the constant intensity of the original network, thus generalizing a previous\nresult showing that the propagation processes only depend on one moment of the\nemitted power and propagation effects. We give examples and applications to\nmotivate these results and highlight an interesting observation regarding\nrandom path-loss exponents. \n\n"}
{"id": "1306.1556", "contents": "Title: Diversity Polynomials for the Analysis of Temporal Correlations in\n  Wireless Networks Abstract: The interference in wireless networks is temporally correlated, since the\nnode or user locations are correlated over time and the interfering\ntransmitters are a subset of these nodes. For a wireless network where\n(potential) interferers form a Poisson point process and use ALOHA for channel\naccess, we calculate the joint success and outage probabilities of n\ntransmissions over a reference link. The results are based on the diversity\npolynomial, which captures the temporal interference correlation. The joint\noutage probability is used to determine the diversity gain (as the SIR goes to\ninfinity), and it turns out that there is no diversity gain in simple\nretransmission schemes, even with independent Rayleigh fading over all links.\nWe also determine the complete joint SIR distribution for two transmissions and\nthe distribution of the local delay, which is the time until a repeated\ntransmission over the reference link succeeds. \n\n"}
{"id": "1306.6122", "contents": "Title: Downlink Rate Distribution in Heterogeneous Cellular Networks under\n  Generalized Cell Selection Abstract: Considering both small-scale fading and long-term shadowing, we characterize\nthe downlink rate distribution at a typical user equipment (UE) in a\nheterogeneous cellular network (HetNet), where shadowing, following any general\ndistribution, impacts cell selection while fading does not. Prior work either\nignores the impact of channel randomness on cell selection or lumps all the\nsources of randomness into a single variable, with cell selection based on the\ninstantaneous signal strength, which is unrealistic. As an application of the\nresults, we study the impact of shadowing on load balancing in terms of the\noptimal per-tier selection bias needed for rate maximization. \n\n"}
{"id": "1307.2690", "contents": "Title: BGP Security in Partial Deployment: Is the Juice Worth the Squeeze? Abstract: As the rollout of secure route origin authentication with the RPKI slowly\ngains traction among network operators, there is a push to standardize secure\npath validation for BGP (i.e., S*BGP: S-BGP, soBGP, BGPSEC, etc.). Origin\nauthentication already does much to improve routing security. Moreover, the\ntransition to S*BGP is expected to be long and slow, with S*BGP coexisting in\n\"partial deployment\" alongside BGP for a long time. We therefore use\ntheoretical and experimental approach to study the security benefits provided\nby partially-deployed S*BGP, vis-a-vis those already provided by origin\nauthentication. Because routing policies have a profound impact on routing\nsecurity, we use a survey of 100 network operators to find the policies that\nare likely to be most popular during partial S*BGP deployment. We find that\nS*BGP provides only meagre benefits over origin authentication when these\npopular policies are used. We also study the security benefits of other routing\npolicies, provide prescriptive guidelines for partially-deployed S*BGP, and\nshow how interactions between S*BGP and BGP can introduce new vulnerabilities\ninto the routing system. \n\n"}
{"id": "1307.3835", "contents": "Title: Joint Optimization of Radio Resources and Code Partitioning in Mobile\n  Edge Computing Abstract: The aim of this paper is to propose a computation offloading strategy for\nmobile edge computing. We exploit the concept of call graph, which models a\ngeneric computer program as a set of procedures related to each other through a\nweighted directed graph. Our goal is to derive the optimal partition of the\ncall graph establishing which procedures are to be executed locally or\nremotely. The main novelty of our work is that the optimal partition is\nobtained jointly with the selection of radio parameters, e.g., transmit power\nand constellation size, in order to minimize the energy consumption at the\nmobile handset, under a latency constraint taking into account transmit time\nand execution time. We consider both single and multi-channel transmission\nstrategies and we prove that a globally optimal solution can be achieved in\nboth cases. Finally, we propose a suboptimal strategy aimed at solving a\nrelaxed version of the original problem in order to tradeoff complexity and\nperformance of the proposed framework. Finally, several numerical results\nillustrate under what conditions in terms of call graph topology, communication\nstrategy, and computation parameters, the proposed offloading strategy provides\nlarge performance gains. \n\n"}
{"id": "1307.4538", "contents": "Title: Superprocesses as models for information dissemination in the Future\n  Internet Abstract: Future Internet will be composed by a tremendous number of potentially\ninterconnected people and devices, offering a variety of services, applications\nand communication opportunities. In particular, short-range wireless\ncommunications, which are available on almost all portable devices, will enable\nthe formation of the largest cloud of interconnected, smart computing devices\nmankind has ever dreamed about: the Proximate Internet. In this paper, we\nconsider superprocesses, more specifically super Brownian motion, as a suitable\nmathematical model to analyse a basic problem of information dissemination\narising in the context of Proximate Internet. The proposed model provides a\npromising analytical framework to both study theoretical properties related to\nthe information dissemination process and to devise efficient and reliable\nsimulation schemes for very large systems. \n\n"}
{"id": "1307.5057", "contents": "Title: Avoiding Whitewashing in Unstructured Peer-to-Peer Resource Sharing\n  Network Abstract: In peer-to-peer file sharing network, it is hard to distinguish between a\nlegitimate newcomer and a whitewasher. This makes whitewashing a big problem in\npeer-to-peer networks. Although the problem of whitewashing can be solved using\npermanent identities, it may take away the right of anonymity for users. In\nthis paper, we a have proposed a novel algorithm to avoid this problem when\nnetwork uses free temporary identities. In this algorithm, the initial\nreputation is adjusted according to the level of whitewashing in the network. \n\n"}
{"id": "1307.6373", "contents": "Title: Effect of Spatial Interference Correlation on the Performance of Maximum\n  Ratio Combining Abstract: While the performance of maximum ratio combining (MRC) is well understood for\na single isolated link, the same is not true in the presence of interference,\nwhich is typically correlated across antennas due to the common locations of\ninterferers. For tractability, prior work focuses on the two extreme cases\nwhere the interference power across antennas is either assumed to be fully\ncorrelated or fully uncorrelated. In this paper, we address this shortcoming\nand characterize the performance of MRC in the presence of spatially-correlated\ninterference across antennas. Modeling the interference field as a Poisson\npoint process, we derive the exact distribution of the signal-to-interference\nratio (SIR) for the case of two receive antennas, and upper and lower bounds\nfor the general case. Using these results, we study the diversity behavior of\nMRC and characterize the critical density of simultaneous transmissions for a\ngiven outage constraint. The exact SIR distribution is also useful in\nbenchmarking simpler correlation models. We show that the full-correlation\nassumption is considerably pessimistic (up to 30% higher outage probability for\ntypical values) and the no-correlation assumption is significantly optimistic\ncompared to the true performance. \n\n"}
{"id": "1307.7210", "contents": "Title: NOVA: QoE-driven Optimization of DASH-based Video Delivery in Networks Abstract: We consider the problem of optimizing video delivery for a network supporting\nvideo clients streaming stored video. Specifically, we consider the problem of\njointly optimizing network resource allocation and video quality adaptation.\nOur objective is to fairly maximize video clients' Quality of Experience (QoE)\nrealizing tradeoffs among the mean quality, temporal variability in quality,\nand fairness, incorporating user preferences on rebuffering and cost of video\ndelivery. We present a simple asymptotically optimal online algorithm, NOVA, to\nsolve the problem. NOVA is asynchronous, and using minimal communication,\ndistributes the tasks of resource allocation to network controller, and quality\nadaptation to respective video clients. Video quality adaptation in NOVA is\nalso optimal for standalone video clients, and is well suited for use with DASH\nframework. Further, we extend NOVA for use with more general QoE models,\nnetworks shared with other traffic loads and networks using fixed/legacy\nresource allocation. \n\n"}
{"id": "1307.7309", "contents": "Title: Optimal Rate Sampling in 802.11 Systems Abstract: In 802.11 systems, Rate Adaptation (RA) is a fundamental mechanism allowing\ntransmitters to adapt the coding and modulation scheme as well as the MIMO\ntransmission mode to the radio channel conditions, and in turn, to learn and\ntrack the (mode, rate) pair providing the highest throughput. So far, the\ndesign of RA mechanisms has been mainly driven by heuristics. In contrast, in\nthis paper, we rigorously formulate such design as an online stochastic\noptimisation problem. We solve this problem and present ORS (Optimal Rate\nSampling), a family of (mode, rate) pair adaptation algorithms that provably\nlearn as fast as it is possible the best pair for transmission. We study the\nperformance of ORS algorithms in both stationary radio environments where the\nsuccessful packet transmission probabilities at the various (mode, rate) pairs\ndo not vary over time, and in non-stationary environments where these\nprobabilities evolve. We show that under ORS algorithms, the throughput loss\ndue to the need to explore sub-optimal (mode, rate) pairs does not depend on\nthe number of available pairs, which is a crucial advantage as evolving 802.11\nstandards offer an increasingly large number of (mode, rate) pairs. We\nillustrate the efficiency of ORS algorithms (compared to the state-of-the-art\nalgorithms) using simulations and traces extracted from 802.11 test-beds. \n\n"}
{"id": "1308.0041", "contents": "Title: A Tractable Model for Non-Coherent Joint-Transmission Base Station\n  Cooperation Abstract: This paper presents a tractable model for analyzing non-coherent joint\ntransmission base station (BS) cooperation, taking into account the irregular\nBS deployment typically encountered in practice. Besides cellular-network\nspecific aspects such as BS density, channel fading, average path loss and\ninterference, the model also captures relevant cooperation mechanisms including\nuser-centric BS clustering and channel-dependent cooperation activation. The\nlocations of all BSs are modeled by a Poisson point process. Using tools from\nstochastic geometry, the signal-to-interference-plus-noise ratio\n($\\mathtt{SINR}$) distribution with cooperation is precisely characterized in a\ngenerality-preserving form. The result is then applied to practical design\nproblems of recent interest. We find that increasing the network-wide BS\ndensity improves the $\\mathtt{SINR}$, while the gains increase with the path\nloss exponent. For pilot-based channel estimation, the average spectral\nefficiency saturates at cluster sizes of around $7$ BSs for typical values,\nirrespective of backhaul quality. Finally, it is shown that intra-cluster\nfrequency reuse is favorable in moderately loaded cells with generous\ncooperation activation, while intra-cluster coordinated scheduling may be\nbetter in lightly loaded cells with conservative cooperation activation. \n\n"}
{"id": "1308.0178", "contents": "Title: Coded Caching with Nonuniform Demands Abstract: We consider a network consisting of a file server connected through a shared\nlink to a number of users, each equipped with a cache. Knowing the popularity\ndistribution of the files, the goal is to optimally populate the caches such as\nto minimize the expected load of the shared link. For a single cache, it is\nwell known that storing the most popular files is optimal in this setting.\nHowever, we show here that this is no longer the case for multiple caches.\nIndeed, caching only the most popular files can be highly suboptimal. Instead,\na fundamentally different approach is needed, in which the cache contents are\nused as side information for coded communication over the shared link. We\npropose such a coded caching scheme and prove that it is close to optimal. \n\n"}
{"id": "1308.0786", "contents": "Title: Content Distribution Strategies in Opportunistic Networks Abstract: This paper describes a mechanism for content distribution through\nopportunistic contacts between subscribers. A subset of subscribers in the\nnetwork are seeded with the content. The remaining subscribers obtain the\ninformation through opportunistic contact with a user carrying the updated\ncontent. We study how the rate of content retrieval by subscribers is affected\nby the number of initial seeders in the network. We also study the rate of\ncontent retrieval by the subscribers under coding strategies (Network Coding,\nErasure Coding) and under Flooding, Epidemic Routing. \n\n"}
{"id": "1309.0085", "contents": "Title: Artificial Intelligence Based Cognitive Routing for Cognitive Radio\n  Networks Abstract: Cognitive radio networks (CRNs) are networks of nodes equipped with cognitive\nradios that can optimize performance by adapting to network conditions. While\ncognitive radio networks (CRN) are envisioned as intelligent networks,\nrelatively little research has focused on the network level functionality of\nCRNs. Although various routing protocols, incorporating varying degrees of\nadaptiveness, have been proposed for CRNs, it is imperative for the long term\nsuccess of CRNs that the design of cognitive routing protocols be pursued by\nthe research community. Cognitive routing protocols are envisioned as routing\nprotocols that fully and seamless incorporate AI-based techniques into their\ndesign. In this paper, we provide a self-contained tutorial on various AI and\nmachine-learning techniques that have been, or can be, used for developing\ncognitive routing protocols. We also survey the application of various classes\nof AI techniques to CRNs in general, and to the problem of routing in\nparticular. We discuss various decision making techniques and learning\ntechniques from AI and document their current and potential applications to the\nproblem of routing in CRNs. We also highlight the various inference, reasoning,\nmodeling, and learning sub tasks that a cognitive routing protocol must solve.\nFinally, open research issues and future directions of work are identified. \n\n"}
{"id": "1309.0186", "contents": "Title: A Solution to the Network Challenges of Data Recovery in Erasure-coded\n  Distributed Storage Systems: A Study on the Facebook Warehouse Cluster Abstract: Erasure codes, such as Reed-Solomon (RS) codes, are being increasingly\nemployed in data centers to combat the cost of reliably storing large amounts\nof data. Although these codes provide optimal storage efficiency, they require\nsignificantly high network and disk usage during recovery of missing data. In\nthis paper, we first present a study on the impact of recovery operations of\nerasure-coded data on the data-center network, based on measurements from\nFacebook's warehouse cluster in production. To the best of our knowledge, this\nis the first study of its kind available in the literature. Our study reveals\nthat recovery of RS-coded data results in a significant increase in network\ntraffic, more than a hundred terabytes per day, in a cluster storing multiple\npetabytes of RS-coded data.\n  To address this issue, we present a new storage code using our recently\nproposed \"Piggybacking\" framework, that reduces the network and disk usage\nduring recovery by 30% in theory, while also being storage optimal and\nsupporting arbitrary design parameters. The implementation of the proposed code\nin the Hadoop Distributed File System (HDFS) is underway. We use the\nmeasurements from the warehouse cluster to show that the proposed code would\nlead to a reduction of close to fifty terabytes of cross-rack traffic per day. \n\n"}
{"id": "1309.0604", "contents": "Title: Coding for Caches in the Plane Abstract: We consider wireless caches located in the plane according to general point\nprocess and specialize the results for the homogeneous Poisson process. A large\ndata file is stored at the caches, which have limited storage capabilities.\nHence, they can only store parts of the data. Clients can contact the caches to\nretrieve the data. We compare the expected cost of obtaining the complete data\nunder uncoded as well as coded data allocation strategies. It is shown that for\nthe general class of cost measures where the cost of retrieving data is\nincreasing with the distance between client and caches, coded allocation\noutperforms uncoded allocation. The improvement offered by coding is quantified\nfor two more specific classes of performance measures. Finally, our results are\nvalidated by computing the costs of the allocation strategies for the case that\ncaches coincide with currently deployed mobile base stations. \n\n"}
{"id": "1309.5491", "contents": "Title: Anticipatory Buffer Control and Quality Selection for Wireless Video\n  Streaming Abstract: Video streaming is in high demand by mobile users, as recent studies\nindicate. In cellular networks, however, the unreliable wireless channel leads\nto two major problems. Poor channel states degrade video quality and interrupt\nthe playback when a user cannot sufficiently fill its local playout buffer:\nbuffer underruns occur. In contrast to that, good channel conditions cause\ncommon greedy buffering schemes to pile up very long buffers. Such\nover-buffering wastes expensive wireless channel capacity.\n  To keep buffering in balance, we employ a novel approach. Assuming that we\ncan predict data rates, we plan the quality and download time of the video\nsegments ahead. This anticipatory scheduling avoids buffer underruns by\ndownloading a large number of segments before a channel outage occurs, without\nwasting wireless capacity by excessive buffering. We formalize this approach as\nan optimization problem and derive practical heuristics for segmented video\nstreaming protocols (e.g., HLS or MPEG DASH). Simulation results and testbed\nmeasurements show that our solution essentially eliminates playback\ninterruptions without significantly decreasing video quality. \n\n"}
{"id": "1309.5686", "contents": "Title: On the tradeoff of average delay and average power for fading\n  point-to-point links with monotone policies Abstract: We consider a fading point-to-point link with packets arriving randomly at\nrate $\\lambda$ per slot to the transmitter queue. We assume that the\ntransmitter can control the number of packets served in a slot by varying the\ntransmit power for the slot. We restrict to transmitter scheduling policies\nthat are monotone and stationary, i.e., the number of packets served is a\nnon-decreasing function of the queue length at the beginning of the slot for\nevery slot fade state. For such policies, we obtain asymptotic lower bounds for\nthe minimum average delay of the packets, when average transmitter power is a\nsmall positive quantity $V$ more than the minimum average power required for\ntransmitter queue stability. We show that the minimum average delay grows\neither to a finite value or as $\\Omega\\brap{\\log(1/V)}$ or $\\Omega\\brap{1/V}$\nwhen $V \\downarrow 0$, for certain sets of values of $\\lambda$. These sets are\ndetermined by the distribution of fading gain, the maximum number of packets\nwhich can be transmitted in a slot, and the transmit power function of the\nfading gain and the number of packets transmitted that is assumed. We identify\na case where the above behaviour of the tradeoff differs from that obtained\nfrom a previously considered approximate model, in which the random queue\nlength process is assumed to evolve on the non-negative real line, and the\ntransmit power function is strictly convex. We also consider a fading\npoint-to-point link, where the transmitter, in addition to controlling the\nnumber of packets served, can also control the number of packets admitted in\nevery slot. Our approach, which uses bounds on the stationary probability\ndistribution of the queue length, also leads to an intuitive explanation of the\nasymptotic behaviour of average delay in the regime where $V \\downarrow 0$. \n\n"}
{"id": "1309.7066", "contents": "Title: High Throughput Data Center Topology Design Abstract: With high throughput networks acquiring a crucial role in supporting\ndata-intensive applications, a variety of data center network topologies have\nbeen proposed to achieve high capacity at low cost. While this literature\nexplores a large number of design points, even in the limited case of a network\nof identical switches, no proposal has been able to claim any notion of\noptimality. The case of heterogeneous networks, incorporating multiple\nline-speeds and port-counts as data centers grow over time, introduces even\ngreater complexity.\n  In this paper, we present the first non-trivial upper-bound on network\nthroughput under uniform traffic patterns for any topology with identical\nswitches. We then show that random graphs achieve throughput surprisingly close\nto this bound, within a few percent at the scale of a few thousand servers.\nApart from demonstrating that homogeneous topology design may be reaching its\nlimits, this result also motivates our use of random graphs as building blocks\nto explore the design of heterogeneous networks. Given a heterogeneous pool of\nnetwork switches, through experiments and analysis, we explore how the\ndistribution of servers across switches and the interconnection of switches\naffect network throughput. We apply these insights to a real-world\nheterogeneous data center topology, VL2, demonstrating as much as 43% higher\nthroughput with the same equipment. \n\n"}
{"id": "1310.0720", "contents": "Title: A Survey on Device-to-Device Communication in Cellular Networks Abstract: Device-to-Device (D2D) communication was initially proposed in cellular\nnetworks as a new paradigm to enhance network performance. The emergence of new\napplications such as content distribution and location-aware advertisement\nintroduced new use-cases for D2D communications in cellular networks. The\ninitial studies showed that D2D communication has advantages such as increased\nspectral efficiency and reduced communication delay. However, this\ncommunication mode introduces complications in terms of interference control\noverhead and protocols that are still open research problems. The feasibility\nof D2D communications in LTE-A is being studied by academia, industry, and the\nstandardization bodies. To date, there are more than 100 papers available on\nD2D communications in cellular networks and, there is no survey on this field.\nIn this article, we provide a taxonomy based on the D2D communicating spectrum\nand review the available literature extensively under the proposed taxonomy.\nMoreover, we provide new insights to the over-explored and under-explored areas\nwhich lead us to identify open research problems of D2D communication in\ncellular networks. \n\n"}
{"id": "1310.1419", "contents": "Title: On Association Cells in Random Heterogeneous Networks Abstract: Characterizing user to access point (AP) association strategies in\nheterogeneous cellular networks (HetNets) is critical for their performance\nanalysis, as it directly influences the load across the network. In this\nletter, we introduce and analyze a class of association strategies, which we\nterm stationary association, and the resulting association cells. For random\nHetNets, where APs are distributed according to a stationary point process, the\narea of the resulting association cells are shown to be the marks of the\ncorresponding point process. Addressing the need of quantifying the load\nexperienced by a typical user, a \"Feller-paradox\" like relationship is\nestablished between the area of the association cell containing origin and that\nof a typical association cell. For the specific case of Poisson point process\nand max power/SINR association, the mean association area of each tier is\nderived and shown to increase with channel gain variance and decrease in the\npath loss exponents of the corresponding tier. \n\n"}
{"id": "1310.4761", "contents": "Title: Towards Energy Neutrality in Energy Harvesting Wireless Sensor Networks:\n  A Case for Distributed Compressive Sensing? Abstract: This paper advocates the use of the emerging distributed compressive sensing\n(DCS) paradigm in order to deploy energy harvesting (EH) wireless sensor\nnetworks (WSN) with practical network lifetime and data gathering rates that\nare substantially higher than the state-of-the-art. In particular, we argue\nthat there are two fundamental mechanisms in an EH WSN: i) the energy diversity\nassociated with the EH process that entails that the harvested energy can vary\nfrom sensor node to sensor node, and ii) the sensing diversity associated with\nthe DCS process that entails that the energy consumption can also vary across\nthe sensor nodes without compromising data recovery. We also argue that such\nmechanisms offer the means to match closely the energy demand to the energy\nsupply in order to unlock the possibility for energy-neutral WSNs that leverage\nEH capability. A number of analytic and simulation results are presented in\norder to illustrate the potential of the approach. \n\n"}
{"id": "1310.4907", "contents": "Title: Message and time efficient multi-broadcast schemes Abstract: We consider message and time efficient broadcasting and multi-broadcasting in\nwireless ad-hoc networks, where a subset of nodes, each with a unique rumor,\nwish to broadcast their rumors to all destinations while minimizing the total\nnumber of transmissions and total time until all rumors arrive to their\ndestination. Under centralized settings, we introduce a novel approximation\nalgorithm that provides almost optimal results with respect to the number of\ntransmissions and total time, separately. Later on, we show how to efficiently\nimplement this algorithm under distributed settings, where the nodes have only\nlocal information about their surroundings. In addition, we show multiple\napproximation techniques based on the network collision detection capabilities\nand explain how to calibrate the algorithms' parameters to produce optimal\nresults for time and messages. \n\n"}
{"id": "1310.6443", "contents": "Title: Leveraging Physical Layer Capabilites: Distributed Scheduling in\n  Interference Networks with Local Views Abstract: In most wireless networks, nodes have only limited local information about\nthe state of the network, which includes connectivity and channel state\ninformation. With limited local information about the network, each node's\nknowledge is mismatched; therefore, they must make distributed decisions. In\nthis paper, we pose the following question - if every node has network state\ninformation only about a small neighborhood, how and when should nodes choose\nto transmit? While link scheduling answers the above question for\npoint-to-point physical layers which are designed for an interference-avoidance\nparadigm, we look for answers in cases when interference can be embraced by\nadvanced PHY layer design, as suggested by results in network information\ntheory.\n  To make progress on this challenging problem, we propose a constructive\ndistributed algorithm that achieves rates higher than link scheduling based on\ninterference avoidance, especially if each node knows more than one hop of\nnetwork state information. We compare our new aggressive algorithm to a\nconservative algorithm we have presented in [1]. Both algorithms schedule\nsub-networks such that each sub-network can employ advanced\ninterference-embracing coding schemes to achieve higher rates. Our innovation\nis in the identification, selection and scheduling of sub-networks, especially\nwhen sub-networks are larger than a single link. \n\n"}
{"id": "1310.8135", "contents": "Title: Large-Scale Sensor Network Localization via Rigid Subnetwork\n  Registration Abstract: In this paper, we describe an algorithm for sensor network localization (SNL)\nthat proceeds by dividing the whole network into smaller subnetworks, then\nlocalizes them in parallel using some fast and accurate algorithm, and finally\nregisters the localized subnetworks in a global coordinate system. We\ndemonstrate that this divide-and-conquer algorithm can be used to leverage\nexisting high-precision SNL algorithms to large-scale networks, which could\notherwise only be applied to small-to-medium sized networks. The main\ncontribution of this paper concerns the final registration phase. In\nparticular, we consider a least-squares formulation of the registration problem\n(both with and without anchor constraints) and demonstrate how this otherwise\nnon-convex problem can be relaxed into a tractable convex program. We provide\nsome preliminary simulation results for large-scale SNL demonstrating that the\nproposed registration algorithm (together with an accurate localization scheme)\noffers a good tradeoff between run time and accuracy. \n\n"}
{"id": "1311.1240", "contents": "Title: Generalized Instantly Decodable Network Coding for Relay-Assisted\n  Networks Abstract: In this paper, we investigate the problem of minimizing the frame completion\ndelay for Instantly Decodable Network Coding (IDNC) in relay-assisted wireless\nmulticast networks. We first propose a packet recovery algorithm in the single\nrelay topology which employs generalized IDNC instead of strict IDNC previously\nproposed in the literature for the same relay-assisted topology. This use of\ngeneralized IDNC is supported by showing that it is a super-set of the strict\nIDNC scheme, and thus can generate coding combinations that are at least as\nefficient as strict IDNC in reducing the average completion delay. We then\nextend our study to the multiple relay topology and propose a joint generalized\nIDNC and relay selection algorithm. This proposed algorithm benefits from the\nreception diversity of the multiple relays to further reduce the average\ncompletion delay in the network. Simulation results show that our proposed\nsolutions achieve much better performance compared to previous solutions in the\nliterature. \n\n"}
{"id": "1311.3646", "contents": "Title: Online Coded Caching Abstract: We consider a basic content distribution scenario consisting of a single\norigin server connected through a shared bottleneck link to a number of users\neach equipped with a cache of finite memory. The users issue a sequence of\ncontent requests from a set of popular files, and the goal is to operate the\ncaches as well as the server such that these requests are satisfied with the\nminimum number of bits sent over the shared link. Assuming a basic Markov model\nfor renewing the set of popular files, we characterize approximately the\noptimal long-term average rate of the shared link. We further prove that the\noptimal online scheme has approximately the same performance as the optimal\noffline scheme, in which the cache contents can be updated based on the entire\nset of popular files before each new request. To support these theoretical\nresults, we propose an online coded caching scheme termed coded least-recently\nsent (LRS) and simulate it for a demand time series derived from the dataset\nmade available by Netflix for the Netflix Prize. For this time series, we show\nthat the proposed coded LRS algorithm significantly outperforms the popular\nleast-recently used (LRU) caching algorithm. \n\n"}
{"id": "1311.4303", "contents": "Title: Applying Formal Methods to Networking: Theory, Techniques and\n  Applications Abstract: Despite its great importance, modern network infrastructure is remarkable for\nthe lack of rigor in its engineering. The Internet which began as a research\nexperiment was never designed to handle the users and applications it hosts\ntoday. The lack of formalization of the Internet architecture meant limited\nabstractions and modularity, especially for the control and management planes,\nthus requiring for every new need a new protocol built from scratch. This led\nto an unwieldy ossified Internet architecture resistant to any attempts at\nformal verification, and an Internet culture where expediency and pragmatism\nare favored over formal correctness. Fortunately, recent work in the space of\nclean slate Internet design---especially, the software defined networking (SDN)\nparadigm---offers the Internet community another chance to develop the right\nkind of architecture and abstractions. This has also led to a great resurgence\nin interest of applying formal methods to specification, verification, and\nsynthesis of networking protocols and applications. In this paper, we present a\nself-contained tutorial of the formidable amount of work that has been done in\nformal methods, and present a survey of its applications to networking. \n\n"}
{"id": "1311.4601", "contents": "Title: Achievable Rate Regions for Network Coding Abstract: Determining the achievable rate region for networks using routing, linear\ncoding, or non-linear coding is thought to be a difficult task in general, and\nfew are known. We describe the achievable rate regions for four interesting\nnetworks (completely for three and partially for the fourth). In addition to\nthe known matrix-computation method for proving outer bounds for linear coding,\nwe present a new method which yields actual characteristic-dependent linear\nrank inequalities from which the desired bounds follow immediately. \n\n"}
{"id": "1312.2177", "contents": "Title: Machine Learning Techniques for Intrusion Detection Abstract: An Intrusion Detection System (IDS) is a software that monitors a single or a\nnetwork of computers for malicious activities (attacks) that are aimed at\nstealing or censoring information or corrupting network protocols. Most\ntechniques used in today's IDS are not able to deal with the dynamic and\ncomplex nature of cyber attacks on computer networks. Hence, efficient adaptive\nmethods like various techniques of machine learning can result in higher\ndetection rates, lower false alarm rates and reasonable computation and\ncommunication costs. In this paper, we study several such schemes and compare\ntheir performance. We divide the schemes into methods based on classical\nartificial intelligence (AI) and methods based on computational intelligence\n(CI). We explain how various characteristics of CI techniques can be used to\nbuild efficient IDS. \n\n"}
{"id": "1312.2466", "contents": "Title: An Analog Baseband Approach for Designing Full-Duplex Radios Abstract: Recent wireless testbed implementations have proven that full-duplex\ncommunication is in fact possible and can outperform half-duplex systems. Many\nof these implementations modify existing half-duplex systems to operate in\nfull-duplex. To realize the full potential of full-duplex, radios need to be\ndesigned with self-interference in mind. In our work, we use an experimental\nsetup with a patch antenna prototype to characterize the self-interference\nchannel between two radios. In doing so, we form an analytical model to design\nanalog baseband cancellation techniques. We show that our cancellation scheme\ncan provide up to 10 dB improved signal strength, 2.5 bps/Hz increase in rate,\nand a 10,000 improvement in BER as compared to the RF only cancellation\nprovided by the patch antenna. \n\n"}
{"id": "1312.3702", "contents": "Title: Outage Analysis of Uplink Two-tier Networks Abstract: Employing multi-tier networks is among the most promising approaches to\naddress the rapid growth of the data demand in cellular networks. In this\npaper, we study a two-tier uplink cellular network consisting of femtocells and\na macrocell. Femto base stations, and femto and macro users are assumed to be\nspatially deployed based on independent Poisson point processes. We consider an\nopen access assignment policy, where each macro user based on the ratio between\nits distances from its nearest femto access point (FAP) and from the macro base\nstation (MBS) is assigned to either of them. By tuning the threshold, this\npolicy allows controlling the coverage areas of FAPs. For a fixed threshold,\nfemtocells coverage areas depend on their distances from the MBS; Those closest\nto the fringes will have the largest coverage areas. Under this open-access\npolicy, ignoring the additive noise, we derive analytical upper and lower\nbounds on the outage probabilities of femto users and macro users that are\nsubject to fading and path loss. We also study the effect of the distance from\nthe MBS on the outage probability experienced by the users of a femtocell. In\nall cases, our simulation results comply with our analytical bounds. \n\n"}
{"id": "1401.1258", "contents": "Title: OSCAR: A Collaborative Bandwidth Aggregation System Abstract: The exponential increase in mobile data demand, coupled with growing user\nexpectation to be connected in all places at all times, have introduced novel\nchallenges for researchers to address. Fortunately, the wide spread deployment\nof various network technologies and the increased adoption of multi-interface\nenabled devices have enabled researchers to develop solutions for those\nchallenges. Such solutions aim to exploit available interfaces on such devices\nin both solitary and collaborative forms. These solutions, however, have faced\na steep deployment barrier.\n  In this paper, we present OSCAR, a multi-objective, incentive-based,\ncollaborative, and deployable bandwidth aggregation system. We present the\nOSCAR architecture that does not introduce any intermediate hardware nor\nrequire changes to current applications or legacy servers. The OSCAR\narchitecture is designed to automatically estimate the system's context,\ndynamically schedule various connections and/or packets to different\ninterfaces, be backwards compatible with the current Internet architecture, and\nprovide the user with incentives for collaboration. We also formulate the OSCAR\nscheduler as a multi-objective, multi-modal scheduler that maximizes system\nthroughput while minimizing energy consumption or financial cost. We evaluate\nOSCAR via implementation on Linux, as well as via simulation, and compare our\nresults to the current optimal achievable throughput, cost, and energy\nconsumption. Our evaluation shows that, in the throughput maximization mode, we\nprovide up to 150% enhancement in throughput compared to current operating\nsystems, without any changes to legacy servers. Moreover, this performance gain\nfurther increases with the availability of connection resume-supporting, or\nOSCAR-enabled servers, reaching the maximum achievable upper-bound throughput. \n\n"}
{"id": "1401.1671", "contents": "Title: Distributed Energy Efficient Channel Allocation Abstract: Design of energy efficient protocols for modern wireless systems has become\nan important area of research. In this paper, we propose a distributed\noptimization algorithm for the channel assignment problem for multiple\ninterfering transceiver pairs that cannot communicate with each other. We first\nmodify the auction algorithm for maximal energy efficiency and show that the\nproblem can be solved without explicit message passing using the carrier sense\nmultiple access (CSMA) protocols. We then develop a novel scheme by converting\nthe channel assignment problem into perfect matchings on bipartite graphs. The\nproposed scheme improves the energy efficiency and does not require any\nexplicit message passing or a shared memory between the users. We derive bounds\non the convergence rate and show that the proposed algorithm converges faster\nthan the distributed auction algorithm and achieves near-optimal performance\nunder Rayleigh fading channels. We also present an asymptotic performance\nanalysis of the fast matching algorithm for energy efficient resource\nallocation and prove the optimality for large enough number of users and number\nof channels. Finally, we provide numerical assessments that confirm the energy\nefficiency gains compared to the state of the art. \n\n"}
{"id": "1401.1723", "contents": "Title: Wireless Scheduling Algorithms in Complex Environments Abstract: Efficient spectrum use in wireless sensor networks through spatial reuse\nrequires effective models of packet reception at the physical layer in the\npresence of interference. Despite recent progress in analytic and simulations\nresearch into worst-case behavior from interference effects, these efforts\ngenerally assume geometric path loss and isotropic transmission, assumptions\nwhich have not been borne out in experiments.\n  Our paper aims to provide a methodology for grounding theoretical results\ninto wireless interference in experimental reality. We develop a new framework\nfor wireless algorithms in which distance-based path loss is replaced by an\narbitrary gain matrix, typically obtained by measurements of received signal\nstrength (RSS). Gain matrices allow for the modeling of complex environments,\ne.g., with obstacles and walls. We experimentally evaluate the framework in two\nindoors testbeds with 20 and 60 motes, and confirm superior predictive\nperformance in packet reception rate for a gain matrix model over a geometric\ndistance-based model.\n  At the heart of our approach is a new parameter $\\zeta$ called metricity\nwhich indicates how close the gain matrix is to a distance metric, effectively\nmeasuring the complexity of the environment. A powerful theoretical feature of\nthis parameter is that all known SINR scheduling algorithms that work in\ngeneral metric spaces carry over to arbitrary gain matrices and achieve\nequivalent performance guarantees in terms of $\\zeta$ as previously obtained in\nterms of the path loss constant. Our experiments confirm the sensitivity of\n$\\zeta$ to the nature of the environment. Finally, we show analytically and\nempirically how multiple channels can be leveraged to improve metricity and\nthereby performance. We believe our contributions will facilitate experimental\nvalidation for recent advances in algorithms for physical wireless interference\nmodels. \n\n"}
{"id": "1401.2560", "contents": "Title: Millimeter Wave Cellular Wireless Networks: Potentials and Challenges Abstract: Millimeter wave (mmW) frequencies between 30 and 300 GHz are a new frontier\nfor cellular communication that offers the promise of orders of magnitude\ngreater bandwidths combined with further gains via beamforming and spatial\nmultiplexing from multi-element antenna arrays. This paper surveys measurements\nand capacity studies to assess this technology with a focus on small cell\ndeployments in urban environments. The conclusions are extremely encouraging;\nmeasurements in New York City at 28 and 73 GHz demonstrate that, even in an\nurban canyon environment, significant non-line-of-sight (NLOS) outdoor,\nstreet-level coverage is possible up to approximately 200 m from a potential\nlow power micro- or picocell base station. In addition, based on statistical\nchannel models from these measurements, it is shown that mmW systems can offer\nmore than an order of magnitude increase in capacity over current\nstate-of-the-art 4G cellular networks at current cell densities. Cellular\nsystems, however, will need to be significantly redesigned to fully achieve\nthese gains. Specifically, the requirement of highly directional and adaptive\ntransmissions, directional isolation between links and significant\npossibilities of outage have strong implications on multiple access, channel\nstructure, synchronization and receiver design. To address these challenges,\nthe paper discusses how various technologies including adaptive beamforming,\nmultihop relaying, heterogeneous network architectures and carrier aggregation\ncan be leveraged in the mmW context. \n\n"}
{"id": "1401.2853", "contents": "Title: Technical Report: Sleep-Route - Routing through Sleeping Sensors Abstract: In this article, we propose an energy-efficient data gathering scheme for\nwireless sensor network called Sleep-Route, which splits the sensor nodes into\ntwo sets - active and dormant (low-power sleep). Only the active set of sensor\nnodes participate in data collection. The sensing values of the dormant sensor\nnodes are predicted with the help of an active sensor node. Virtual Sensing\nFramework (VSF) provides the mechanism to predict the sensing values by\nexploiting the data correlation among the sensor nodes. If the number of active\nsensor nodes can be minimized, a lot of energy can be saved. The active nodes'\nselection must fulfill the following constraints - (i) the set of active nodes\nare sufficient to predict the sensing values of the dormant nodes, (ii) each\nactive sensor nodes can report their data to the sink node (directly or through\nsome other active node(s)). The goal is to select a minimal number of active\nsensor nodes so that energy savings can be maximized.\n  The optimal set of active node selection raise a combinatorial optimization\nproblem, which we refer as Sleep-Route problem. We show that Sleep-Route\nproblem is NP-hard. Then, we formulate an integer linear program (ILP) to solve\nthe problem optimally. To solve the problem in polynomial time, we also propose\na heuristic algorithm that performs near optimally. \n\n"}
{"id": "1401.3174", "contents": "Title: Comments on \"Optimal Utilization of a Cognitive Shared Channel with a\n  Rechargeable Primary Source Node\" Abstract: In a recent paper [1], the authors investigated the maximum stable throughput\nregion of a network composed of a rechargeable primary user and a secondary\nuser plugged to a reliable power supply. The authors studied the cases of an\ninfinite and a finite energy queue at the primary transmitter. However, the\nresults of the finite case are incorrect. We show that under the proposed\nenergy queue model (a decoupled ${\\rm M/D/1}$ queueing system with Bernoulli\narrivals and the consumption of one energy packet per time slot), the energy\nqueue capacity does not affect the stability region of the network. \n\n"}
{"id": "1401.3677", "contents": "Title: The Ginibre Point Process as a Model for Wireless Networks with\n  Repulsion Abstract: The spatial structure of transmitters in wireless networks plays a key role\nin evaluating the mutual interference and hence the performance. Although the\nPoisson point process (PPP) has been widely used to model the spatial\nconfiguration of wireless networks, it is not suitable for networks with\nrepulsion. The Ginibre point process (GPP) is one of the main examples of\ndeterminantal point processes that can be used to model random phenomena where\nrepulsion is observed. Considering the accuracy, tractability and\npracticability tradeoffs, we introduce and promote the $\\beta$-GPP, an\nintermediate class between the PPP and the GPP, as a model for wireless\nnetworks when the nodes exhibit repulsion. To show that the model leads to\nanalytically tractable results in several cases of interest, we derive the mean\nand variance of the interference using two different approaches: the Palm\nmeasure approach and the reduced second moment approach, and then provide\napproximations of the interference distribution by three known probability\ndensity functions. Besides, to show that the model is relevant for cellular\nsystems, we derive the coverage probability of the typical user and also find\nthat the fitted $\\beta$-GPP can closely model the deployment of actual base\nstations in terms of the coverage probability and other statistics. \n\n"}
{"id": "1401.4005", "contents": "Title: Studying the SINR process of the typical user in Poisson networks by\n  using its factorial moment measures Abstract: Based on a stationary Poisson point process, a wireless network model with\nrandom propagation effects (shadowing and/or fading) is considered in order to\nexamine the process formed by the signal-to-interference-plus-noise ratio\n(SINR) values experienced by a typical user with respect to all base stations\nin the down-link channel. This SINR process is completely characterized by\nderiving its factorial moment measures, which involve numerically tractable,\nexplicit integral expressions. This novel framework naturally leads to\nexpressions for the k-coverage probability, including the case of random SINR\nthreshold values considered in multi-tier network models. While the k-coverage\nprobabilities correspond to the marginal distributions of the order statistics\nof the SINR process, a more general relation is presented connecting the\nfactorial moment measures of the SINR process to the joint densities of these\norder statistics. This gives a way for calculating exact values of the coverage\nprobabilities arising in a general scenario of signal combination and\ninterference cancellation between base stations. The presented framework\nconsisting of mathematical representations of SINR characteristics with respect\nto the factorial moment measures holds for the whole domain of SINR and is\namenable to considerable model extension. \n\n"}
{"id": "1401.5099", "contents": "Title: A Stable Fountain Code Mechanism for Peer-to-Peer Content Distribution Abstract: Most peer-to-peer content distribution systems require the peers to privilege\nthe welfare of the overall system over greedily maximizing their own utility.\nWhen downloading a file broken up into multiple pieces, peers are often asked\nto pass on some possible download opportunities of common pieces in order to\nfavor rare pieces. This is to avoid the missing piece syndrome, which throttles\nthe download rate of the peer-to-peer system to that of downloading the file\nstraight from the server. In other situations, peers are asked to stay in the\nsystem even though they have collected all the file's pieces and have an\nincentive to leave right away.\n  We propose a mechanism which allows peers to act greedily and yet stabilizes\nthe peer-to-peer content sharing system. Our mechanism combines a fountain code\nat the server to generate innovative new pieces, and a prioritization for the\nserver to deliver pieces only to new peers. While by itself, neither the\nfountain code nor the prioritization of new peers alone stabilizes the system,\nwe demonstrate that their combination does, through both analytical and\nnumerical evaluation. \n\n"}
{"id": "1401.6683", "contents": "Title: Resource Allocation Under Channel Uncertainties for Relay-Aided\n  Device-to-Device Communication Underlaying LTE-A Cellular Networks Abstract: Device-to-device (D2D) communication in cellular networks allows direct\ntransmission between two cellular devices with local communication needs. Due\nto the increasing number of autonomous heterogeneous devices in future mobile\nnetworks, an efficient resource allocation scheme is required to maximize\nnetwork throughput and achieve higher spectral efficiency. In this paper,\nperformance of network-integrated D2D communication under channel uncertainties\nis investigated where D2D traffic is carried through relay nodes. Considering a\nmulti-user and multi-relay network, we propose a robust distributed solution\nfor resource allocation with a view to maximizing network sum-rate when the\ninterference from other relay nodes and the link gains are uncertain. An\noptimization problem is formulated for allocating radio resources at the relays\nto maximize end-to-end rate as well as satisfy the quality-of-service (QoS)\nrequirements for cellular and D2D user equipments under total power constraint.\nEach of the uncertain parameters is modeled by a bounded distance between its\nestimated and bounded values. We show that the robust problem is convex and a\ngradient-aided dual decomposition algorithm is applied to allocate radio\nresources in a distributed manner. Finally, to reduce the cost of robustness\ndefined as the reduction of achievable sum-rate, we utilize the \\textit{chance\nconstraint approach} to achieve a trade-off between robustness and optimality.\nThe numerical results show that there is a distance threshold beyond which\nrelay-aided D2D communication significantly improves network performance when\ncompared to direct communication between D2D peers. \n\n"}
{"id": "1402.0729", "contents": "Title: Stability and Performance Issues of a Relay Assisted Multiple Access\n  Scheme with MPR Capabilities Abstract: In this work, we study the impact of a relay node to a network with a finite\nnumber of users-sources and a destination node. We assume that the users have\nsaturated queues and the relay node does not have packets of its own; we have\nrandom access of the medium and the time is slotted. The relay node stores a\nsource packet that it receives successfully in its queue when the transmission\nto the destination node has failed. The relay and the destination nodes have\nmulti-packet reception capabilities. We obtain analytical equations for the\ncharacteristics of the relay's queue such as average queue length, stability\nconditions etc. We also study the throughput per user and the aggregate\nthroughput for the network. \n\n"}
{"id": "1402.1761", "contents": "Title: On Scalability of Wireless Networks: A Practical Primer for Large Scale\n  Cooperation Abstract: An intuitive overview of the scalability of a variety of types of wireless\nnetworks is presented. Simple heuris- tic arguments are demonstrated here for\nscaling laws presented in other works, as well as for conditions not previously\nconsidered in the literature. Unicast and multicast messages, topology,\nhierarchy, and effects of reliability protocols are discussed. We show how two\nkey factors, bottlenecks and erasures, can often domi- nate the network scaling\nbehavior. Scaling of through- put or delay with the number of transmitting\nnodes, the number of receiving nodes, and the file size is described. \n\n"}
{"id": "1402.4576", "contents": "Title: On the Average Performance of Caching and Coded Multicasting with Random\n  Demands Abstract: For a network with one sender, $n$ receivers (users) and $m$ possible\nmessages (files), caching side information at the users allows to satisfy\narbitrary simultaneous demands by sending a common (multicast) coded message.\nIn the worst-case demand setting, explicit deterministic and random caching\nstrategies and explicit linear coding schemes have been shown to be order\noptimal. In this work, we consider the same scenario where the user demands are\nrandom i.i.d., according to a Zipf popularity distribution. In this case, we\npose the problem in terms of the minimum average number of equivalent message\ntransmissions. We present a novel decentralized random caching placement and a\ncoded delivery scheme which are shown to achieve order-optimal performance. As\na matter of fact, this is the first order-optimal result for the caching and\ncoded multicasting problem in the case of random demands. \n\n"}
{"id": "1402.5196", "contents": "Title: Synchronization-Free Delay Tomography Based on Compressed Sensing Abstract: Delay tomography has so far burdened source and receiver measurement nodes in\na network with two requirements such as path establishment and clock\nsynchronization between them. In this letter, we focus on the clock\nsynchronization problem in delay tomography and propose a synchronization-free\ndelay tomography scheme. The proposed scheme selects a path between source and\nreceiver measurement nodes as a reference path, which results in a loss of\nequation in a conventional delay tomography problem. However, by utilizing\ncompressed sensing, the proposed scheme becomes robust to the loss. Simulation\nexperiments confirm that the proposed scheme works comparable to a conventional\ndelay tomography scheme in networks with no clock synchronization between\nsource and receiver measurement nodes. \n\n"}
{"id": "1402.7017", "contents": "Title: Joint Routing and STDMA-based Scheduling to Minimize Delays in Grid\n  Wireless Sensor Networks Abstract: In this report, we study the issue of delay optimization and energy\nefficiency in grid wireless sensor networks (WSNs). We focus on STDMA (Spatial\nReuse TDMA)) scheduling, where a predefined cycle is repeated, and where each\nnode has fixed transmission opportunities during specific slots (defined by\ncolors). We assume a STDMA algorithm that takes advantage of the regularity of\ngrid topology to also provide a spatially periodic coloring (\"tiling\" of the\nsame color pattern). In this setting, the key challenges are: 1) minimizing the\naverage routing delay by ordering the slots in the cycle 2) being energy\nefficient. Our work follows two directions: first, the baseline performance is\nevaluated when nothing specific is done and the colors are randomly ordered in\nthe STDMA cycle. Then, we propose a solution, ORCHID that deliberately\nconstructs an efficient STDMA schedule. It proceeds in two steps. In the first\nstep, ORCHID starts form a colored grid and builds a hierarchical routing based\non these colors. In the second step, ORCHID builds a color ordering, by\nconsidering jointly both routing and scheduling so as to ensure that any node\nwill reach a sink in a single STDMA cycle. We study the performance of these\nsolutions by means of simulations and modeling. Results show the excellent\nperformance of ORCHID in terms of delays and energy compared to a shortest path\nrouting that uses the delay as a heuristic. We also present the adaptation of\nORCHID to general networks under the SINR interference model. \n\n"}
{"id": "1403.0173", "contents": "Title: Coordinated Direct and Relay Schemes for Two-Hop Communication in VANETS Abstract: In order to accommodate increasing need and offer communication with high\nperformance, both vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications are exploited. The advantages of static nodes and vehicular\nnodes are combined to achieve an optimal routing scheme. In this paper, we\nconsider the communications between a static node and the vehicular nodes\nmoving in an adjacent area of it. The adjacent area is defined as the zone\nwhere a vehicular can communicate with the static node within maximum two hops.\nWe only consider single-hop and two-hop transmissions because these\ntransmissions can be considered as building blocks to construct transmissions\nwith a higher number of hops. Different cases in which an uplink or a downlink\nfor the two-hop user combined with an uplink or a downlink for the single-hop\nuser correspond to different CDR schemes. Using side information to\nintentionally cancel the interference, Network Coding (NC), CDR, overhearing\nand multi-way schemes aggregate communications flows in order to increase the\nperformance of the network. We apply the mentioned schemes to a V2I network and\npropose novel schemes to optimally arrange and combine the transmissions. \n\n"}
{"id": "1403.4342", "contents": "Title: Spatial Performance Analysis and Design Principles for Wireless Peer\n  Discovery Abstract: In wireless peer-to-peer networks that serve various proximity-based\napplications, peer discovery is the key to identifying other peers with which a\npeer can communicate and an understanding of its performance is fundamental to\nthe design of an efficient discovery operation. This paper analyzes the\nperformance of wireless peer discovery through comprehensively considering the\nwireless channel, spatial distribution of peers, and discovery operation\nparameters. The average numbers of successfully discovered peers are expressed\nin closed forms for two widely used channel models, i.e., the interference\nlimited Nakagami-m fading model and the Rayleigh fading model with nonzero\nnoise, when peers are spatially distributed according to a homogeneous Poisson\npoint process. These insightful expressions lead to the design principles for\nthe key operation parameters including the transmission probability, required\namount of wireless resources, level of modulation and coding scheme (MCS), and\ntransmit power. Furthermore, the impact of shadowing on the spatial performance\nand suggested design principles is evaluated using mathematical analysis and\nsimulations. \n\n"}
{"id": "1403.5007", "contents": "Title: On Throughput-Delay Optimal Access to Storage Clouds via Load Adaptive\n  Coding and Chunking Abstract: Recent literature including our past work provide analysis and solutions for\nusing (i) erasure coding, (ii) parallelism, or (iii) variable slicing/chunking\n(i.e., dividing an object of a specific size into a variable number of smaller\nchunks) in speeding the I/O performance of storage clouds. However, a\ncomprehensive approach that considers all three dimensions together to achieve\nthe best throughput-delay trade-off curve had been lacking. This paper presents\nthe first set of solutions that can pick the best combination of coding rate\nand object chunking/slicing options as the load dynamically changes. Our\nspecific contributions are as follows: (1) We establish via measurement that\ncombining variable coding rate and chunking is mostly feasible over a popular\npublic cloud. (2) We relate the delay optimal values for chunking level and\ncode rate to the queue backlogs via an approximate queueing analysis. (3) Based\non this analysis, we propose TOFEC that adapts the chunking level and coding\nrate against the queue backlogs. Our trace-driven simulation results show that\nTOFEC's adaptation mechanism converges to an appropriate code that provides the\noptimal throughput-delay trade-off without reducing system capacity. Compared\nto a non-adaptive strategy optimized for throughput, TOFEC delivers $2.5\\times$\nlower latency under light workloads; compared to a non-adaptive strategy\noptimized for latency, TOFEC can scale to support over $3\\times$ as many\nrequests. (4) We propose a simpler greedy solution that performs on a par with\nTOFEC in average delay performance, but exhibits significantly more performance\nvariations. \n\n"}
{"id": "1403.5479", "contents": "Title: Catalog Dynamics: Impact of Content Publishing and Perishing on the\n  Performance of a LRU Cache Abstract: The Internet heavily relies on Content Distribution Networks and transparent\ncaches to cope with the ever-increasing traffic demand of users. Content,\nhowever, is essentially versatile: once published at a given time, its\npopularity vanishes over time. All requests for a given document are then\nconcentrated between the publishing time and an effective perishing time.\n  In this paper, we propose a new model for the arrival of content requests,\nwhich takes into account the dynamical nature of the content catalog. Based on\ntwo large traffic traces collected on the Orange network, we use the\nsemi-experimental method and determine invariants of the content request\nprocess. This allows us to define a simple mathematical model for content\nrequests; by extending the so-called \"Che approximation\", we then compute the\nperformance of a LRU cache fed with such a request process, expressed by its\nhit ratio. We numerically validate the good accuracy of our model by comparison\nto trace-based simulation. \n\n"}
{"id": "1403.5828", "contents": "Title: A Survey on Network Tomography with Network Coding Abstract: The overhead of internal network monitoring motivates techniques of network\ntomography. Network coding (NC) presents a new opportunity for network\ntomography as NC introduces topology-dependent correlation that can be further\nexploited in topology estimation. Compared with traditional methods, network\ntomography with NC has many advantages such as the improvement of tomography\naccuracy and the reduction of complexity in choosing monitoring paths. In this\npaper we first introduce the problem of tomography with NC and then propose the\ntaxonomy criteria to classify various methods. We also present existing\nsolutions and future trend. We expect that our comprehensive review on network\ntomography with NC can serve as a good reference for researchers and\npractitioners working in the area. \n\n"}
{"id": "1403.7007", "contents": "Title: Hierarchical Coded Caching Abstract: Caching of popular content during off-peak hours is a strategy to reduce\nnetwork loads during peak hours. Recent work has shown significant benefits of\ndesigning such caching strategies not only to deliver part of the content\nlocally, but also to provide coded multicasting opportunities even among users\nwith different demands. Exploiting both of these gains was shown to be\napproximately optimal for caching systems with a single layer of caches.\n  Motivated by practical scenarios, we consider in this work a hierarchical\ncontent delivery network with two layers of caches. We propose a new caching\nscheme that combines two basic approaches. The first approach provides coded\nmulticasting opportunities within each layer; the second approach provides\ncoded multicasting opportunities across multiple layers. By striking the right\nbalance between these two approaches, we show that the proposed scheme achieves\nthe optimal communication rates to within a constant multiplicative and\nadditive gap. We further show that there is no tension between the rates in\neach of the two layers up to the aforementioned gap. Thus, both layers can\nsimultaneously operate at approximately the minimum rate. \n\n"}
{"id": "1404.1142", "contents": "Title: Two-tier Spatial Modeling of Base Stations in Cellular Networks Abstract: Poisson Point Process (PPP) has been widely adopted as an efficient model for\nthe spatial distribution of base stations (BSs) in cellular networks. However,\nreal BSs deployment are rarely completely random, due to environmental impact\non actual site planning. Particularly, for multi-tier heterogeneous cellular\nnetworks, operators have to place different BSs according to local coverage and\ncapacity requirement, and the diversity of BSs' functions may result in\ndifferent spatial patterns on each networking tier. In this paper, we consider\na two-tier scenario that consists of macrocell and microcell BSs in cellular\nnetworks. By analyzing these two tiers separately and applying both classical\nstatistics and network performance as evaluation metrics, we obtain accurate\nspatial model of BSs deployment for each tier. Basically, we verify the\ninaccuracy of using PPP in BS locations modeling for either macrocells or\nmicrocells. Specifically, we find that the first tier with macrocell BSs is\ndispersed and can be precisely modelled by Strauss point process, while Matern\ncluster process captures the second tier's aggregation nature very well. These\nstatistical models coincide with the inherent properties of macrocell and\nmicrocell BSs respectively, thus providing a new perspective in understanding\nthe relationship between spatial structure and operational functions of BSs. \n\n"}
{"id": "1404.2266", "contents": "Title: Enhanced Cluster Computing Performance Through Proportional Fairness Abstract: The performance of cluster computing depends on how concurrent jobs share\nmultiple data center resource types like CPU, RAM and disk storage. Recent\nresearch has discussed efficiency and fairness requirements and identified a\nnumber of desirable scheduling objectives including so-called dominant resource\nfairness (DRF). We argue here that proportional fairness (PF), long recognized\nas a desirable objective in sharing network bandwidth between ongoing flows, is\npreferable to DRF. The superiority of PF is manifest under the realistic\nmodelling assumption that the population of jobs in progress is a stochastic\nprocess. In random traffic the strategy-proof property of DRF proves\nunimportant while PF is shown by analysis and simulation to offer a\nsignificantly better efficiency-fairness tradeoff. \n\n"}
{"id": "1404.2387", "contents": "Title: Fast Structuring of Radio Networks for Multi-Message Communications Abstract: We introduce collision free layerings as a powerful way to structure radio\nnetworks. These layerings can replace hard-to-compute BFS-trees in many\ncontexts while having an efficient randomized distributed construction. We\ndemonstrate their versatility by using them to provide near optimal distributed\nalgorithms for several multi-message communication primitives.\n  Designing efficient communication primitives for radio networks has a rich\nhistory that began 25 years ago when Bar-Yehuda et al. introduced fast\nrandomized algorithms for broadcasting and for constructing BFS-trees. Their\nBFS-tree construction time was $O(D \\log^2 n)$ rounds, where $D$ is the network\ndiameter and $n$ is the number of nodes. Since then, the complexity of a\nbroadcast has been resolved to be $T_{BC} = \\Theta(D \\log \\frac{n}{D} + \\log^2\nn)$ rounds. On the other hand, BFS-trees have been used as a crucial building\nblock for many communication primitives and their construction time remained a\nbottleneck for these primitives.\n  We introduce collision free layerings that can be used in place of BFS-trees\nand we give a randomized construction of these layerings that runs in nearly\nbroadcast time, that is, w.h.p. in $T_{Lay} = O(D \\log \\frac{n}{D} +\n\\log^{2+\\epsilon} n)$ rounds for any constant $\\epsilon>0$. We then use these\nlayerings to obtain: (1) A randomized algorithm for gathering $k$ messages\nrunning w.h.p. in $O(T_{Lay} + k)$ rounds. (2) A randomized $k$-message\nbroadcast algorithm running w.h.p. in $O(T_{Lay} + k \\log n)$ rounds. These\nalgorithms are optimal up to the small difference in the additive\npoly-logarithmic term between $T_{BC}$ and $T_{Lay}$. Moreover, they imply the\nfirst optimal $O(n \\log n)$ round randomized gossip algorithm. \n\n"}
{"id": "1404.4818", "contents": "Title: The fifteen year struggle of decentralizing privacy-enhancing technology Abstract: Ever since the introduction of the internet, it has been void of any privacy.\nThe majority of internet traffic currently is and always has been unencrypted.\nA number of anonymous communication overlay networks exist whose aim it is to\nprovide privacy to its users. However, due to the nature of the internet, there\nis major difficulty in getting these networks to become both decentralized and\nanonymous. We list reasons for having anonymous networks, discern the problems\nin achieving decentralization and sum up the biggest initiatives in the field\nand their current status. To do so, we use one exemplary network, the Tor\nnetwork. We explain how Tor works, what vulnerabilities this network currently\nhas, and possible attacks that could be used to violate privacy and anonymity.\nThe Tor network is used as a key comparison network in the main part of the\nreport: a tabular overview of the major anonymous networking technologies in\nuse today. \n\n"}
{"id": "1404.5481", "contents": "Title: Causal study of Network Performance Abstract: The use of Internet in the every day life has pushed its evolution in a very\nfast way. The heterogeneity of the equipments supporting its networks, as well\nas the different devices from which it can be accessed, have participated in\nincreasing the complexity of understanding its global behavior and performance.\nIn our study we propose a new method for studying the performance of TCP\nprotocol based on causal graphs. Causal graphs offer models easy to interpret\nand use. They highlight the structural model of the system they represent and\ngive us access to the causal dependences between the different parameters of\nthe system. One of the major contribution of causal graphs is their ability to\npredict the effects of an intervention from observations made before this\nintervention. \n\n"}
{"id": "1404.6013", "contents": "Title: Service-Constraint Based Truthful Incentive Mechanisms for Crowd Sensing Abstract: Crowd sensing is a new paradigm which leverages the pervasive smartphones to\nefficiently collect and upload sensing data, enabling numerous novel\napplications. To achieve good service quality for a crowd sensing application,\nincentive mechanisms are necessary for attracting more user participation. Most\nof existing mechanisms apply only for the budget-constraint scenario where the\nplatform (the crowd sensing organizer) has a budget limit. On the contrary, we\nfocus on a different scenario where the platform has a service limit. Based on\nthe offline and online auction model, we consider a general problem: users\nsubmit their private profiles to the platform, and the platform aims at\nselecting a subset of users before a specified deadline for minimizing the\ntotal payment while a specific service can be completed. Specially, we design\noffline and online service-constraint incentive mechanisms for the case where\nthe value function of selected users is monotone submodular. The mechanisms are\nindividual rationality, task feasibility, computational efficiency,\ntruthfulness, consumer sovereignty, constant frugality, and also performs well\nin practice. Finally, we use extensive simulations to demonstrate the\ntheoretical properties of our mechanisms. \n\n"}
{"id": "1404.6112", "contents": "Title: Cognitive Radio Networks with Probabilistic Relaying: Stable Throughput\n  and Delay Tradeoffs Abstract: In this paper, we study and analyze fundamental throughput and delay\ntradeoffs in cooperative multiple access for cognitive radio systems. We focus\non the class of randomized cooperative policies, whereby the secondary user\n(SU) serves either the queue of its own data or the queue of the primary user\n(PU) relayed data with certain service probabilities. Moreover, admission\ncontrol is introduced at the relay queue, whereby a PU's packet is admitted to\nthe relay queue with an admission probability. The proposed policy introduces a\nfundamental tradeoff between the delays of the PU and SU. Consequently, it\nopens room for trading the PU delay for enhanced SU delay and vice versa. Thus,\nthe system could be tuned according to the demands of the intended application.\nTowards this objective, stability conditions for the queues involved in the\nsystem are derived. Furthermore, a moment generating function approach is\nemployed to derive closed-form expressions for the average delay encountered by\nthe packets of both users. The effect of varying the service and admission\nprobabilities on the system's throughput and delay is thoroughly investigated.\nResults show that cooperation expands the stable throughput region. Moreover,\nnumerical simulation results assert the extreme accuracy of the analytically\nderived delay expressions. In addition, we provide a criterion for the SU based\non which it decides whether cooperation is beneficial to the PU or not.\nFurthermore, we show the impact of controlling the flow of data at the relay\nqueue using the admission probability. \n\n"}
{"id": "1404.6687", "contents": "Title: When Queueing Meets Coding: Optimal-Latency Data Retrieving Scheme in\n  Storage Clouds Abstract: In this paper, we study the problem of reducing the delay of downloading data\nfrom cloud storage systems by leveraging multiple parallel threads, assuming\nthat the data has been encoded and stored in the clouds using fixed rate\nforward error correction (FEC) codes with parameters (n, k). That is, each file\nis divided into k equal-sized chunks, which are then expanded into n chunks\nsuch that any k chunks out of the n are sufficient to successfully restore the\noriginal file. The model can be depicted as a multiple-server queue with\narrivals of data retrieving requests and a server corresponding to a thread.\nHowever, this is not a typical queueing model because a server can terminate\nits operation, depending on when other servers complete their service (due to\nthe redundancy that is spread across the threads). Hence, to the best of our\nknowledge, the analysis of this queueing model remains quite uncharted.\n  Recent traces from Amazon S3 show that the time to retrieve a fixed size\nchunk is random and can be approximated as a constant delay plus an i.i.d.\nexponentially distributed random variable. For the tractability of the\ntheoretical analysis, we assume that the chunk downloading time is i.i.d.\nexponentially distributed. Under this assumption, we show that any\nwork-conserving scheme is delay-optimal among all on-line scheduling schemes\nwhen k = 1. When k > 1, we find that a simple greedy scheme, which allocates\nall available threads to the head of line request, is delay optimal among all\non-line scheduling schemes. We also provide some numerical results that point\nto the limitations of the exponential assumption, and suggest further research\ndirections. \n\n"}
{"id": "1405.0089", "contents": "Title: Performance Modeling of Next-Generation Wireless Networks Abstract: The industry is satisfying the increasing demand for wireless bandwidth by\ndensely deploying a large number of access points which are centrally managed,\ne.g. enterprise WiFi networks deployed in university campuses, companies,\nairports etc. This small cell architecture is gaining traction in the cellular\nworld as well, as witnessed by the direction in which 4G+ and 5G\nstandardization is moving. Prior academic work in analyzing such large-scale\nwireless networks either uses oversimplified models for the physical layer, or\nignores other important, real-world aspects of the problem, like MAC layer\nconsiderations, topology characteristics, and protocol overhead. On the other\nhand, the industry is using for deployment purposes on-site surveys and\nsimulation tools which do not scale, cannot efficiently optimize the design of\nsuch a network, and do not explain why one design choice is better than\nanother. In this paper we introduce a simple yet accurate analytical model\nwhich combines the realism and practicality of industrial simulation tools with\nthe ability to scale, analyze the effect of various design parameters, and\noptimize the performance of real- world deployments. The model takes into\naccount all central system parameters, including channelization, power\nallocation, user scheduling, load balancing, MAC, advanced PHY techniques\n(single and multi user MIMO as well as cooperative transmission from multiple\naccess points), topological characteristics and protocol overhead. The accuracy\nof the model is verified via extensive simulations and the model is used to\nstudy a wide range of real world scenarios, providing design guidelines on the\neffect of various design parameters on performance. \n\n"}
{"id": "1405.0170", "contents": "Title: Un algorithme de test pour la connexit\\'e temporelle des graphes\n  dynamiques de faible densit\\'e Abstract: We address the problem of testing whether a dynamic graph is temporally\nconnected, i.e. a temporal path ({\\em journey}) exists between all pairs of\nvertices. We consider a discrete version of the problem, where the topology is\ngiven as an evolving graph $\\G=\\{G_1,G_2,...,G_{k}\\}$ in which only the set of\n(directed) edges varies. Two cases are studied, depending on whether a single\nedge or an unlimited number of edges can be crossed in a same $G_i$ (strict\njourneys {\\it vs} non-strict journeys). For strict journeys, two existing\nalgorithms designed for other problems can be adapted. However, we show that a\ndedicated approach achieves a better time complexity than one of these two\nalgorithms in all cases, and than the other one for those graphs whose density\nis low at any time (though arbitrary over time). The time complexity of our\nalgorithm is $O(k\\mu n)$, where $k=|\\G|$ is the number of time steps and\n$\\mu=max(|E_i|)$ is the maximum {\\em instant} density, to be contrasted with\n$m=|\\cup E_i|$, the {\\em cumulated} density. Indeed, it is not uncommon for a\nmobility scenario to satisfy, for instance, both $\\mu=o(n)$ and\n$m=\\Theta(n^2)$. We characterize the key values of $k, \\mu$ and $m$ for which\nour algorithm should be used. For non-strict journeys, for which no algorithm\nis known, we show that a similar strategy can be used to answer the question,\nstill in $O(k\\mu n)$ time. \n\n"}
{"id": "1405.1008", "contents": "Title: Realistic and Efficient Channel Modeling for Vehicular Networks Abstract: To date, VANET research efforts have relied heavily on simulations, due to\nprohibitive costs of deploying real world testbeds. Existing channel models\nimplemented in discrete-event VANET simulators are by and large simple\nstochastic radio models, based on the statistical properties of the chosen\nenvironment. It was shown that such models are unable to provide satisfactory\naccuracy for typical VANET scenarios.\n  We performed extensive measurements in different environments (open space,\nhighway, suburban, urban, parking lot) to characterize in detail the impact\nthat vehicles have on communication in terms of received power, packet delivery\nrate, and effective communication range. Since the impact of vehicles was found\nto be significant, we developed a model that accounts for vehicles as\nthree-dimensional obstacles and takes into account their impact on the line of\nsight obstruction, received signal power, packet reception rate, and message\nreachability. The model is based on the empirically derived vehicle dimensions,\naccurate vehicle positioning, and realistic mobility patterns. We validate the\nmodel against extensive measurements. To enable realistic modeling in urban and\nsuburban environments, we developed a model that incorporates static objects as\nwell. The model requires minimum geographic information: the location and the\ndimensions of modeled objects (vehicles, buildings, and foliage). We validate\nthe model against measurements and show that it successfully captures both\nsmall-scale and large-scale propagation effects in different environments\n(highway, urban, suburban, open space). \n\n"}
{"id": "1405.1963", "contents": "Title: Distributed Interference-Aware Energy-Efficient Resource Allocation for\n  Device-to-Device Communications Underlaying Cellular Networks Abstract: The introduction of device-to-device (D2D) into cellular networks poses many\nnew challenges in the resource allocation design due to the co-channel\ninterference caused by spectrum reuse and limited battery life of user\nequipments (UEs). In this paper, we propose a distributed interference-aware\nenergy-efficient resource allocation algorithm to maximize each UE's energy\nefficiency (EE) subject to its specific quality of service (QoS) and maximum\ntransmission power constraints. We model the resource allocation problem as a\nnoncooperative game, in which each player is self-interested and wants to\nmaximize its own EE. The formulated EE maximization problem is a non-convex\nproblem and is transformed into a convex optimization problem by exploiting the\nproperties of the nonlinear fractional programming. An iterative optimization\nalgorithm is proposed and verified through computer simulations. \n\n"}
{"id": "1405.2000", "contents": "Title: Tier-Aware Resource Allocation in OFDMA Macrocell-Small Cell Networks Abstract: We present a joint sub-channel and power allocation framework for downlink\ntransmission an orthogonal frequency-division multiple access (OFDMA)-based\ncellular network composed of a macrocell overlaid by small cells. In this\nframework, the resource allocation (RA) problems for both the macrocell and\nsmall cells are formulated as optimization problems. Numerical results confirm\nthe performance gains of our proposed RA formulation for the macrocell over the\ntraditional resource allocation based on minimizing the transmission power.\nBesides, it is shown that the formulation based on convex relaxation yields a\nsimilar behavior to the MINLP formulation. Also, the distributed solution\nconverges to the same solution obtained by solving the corresponding convex\noptimization problem in a centralized fashion. \n\n"}
{"id": "1405.2876", "contents": "Title: Location-Aware Cross-Tier Coordinated Multipoint Transmission in\n  Two-Tier Cellular Networks Abstract: Multi-tier cellular networks are considered as an effective solution to\nenhance the coverage and data rate offered by cellular systems. In a multi-tier\nnetwork, high power base stations (BSs) such as macro BSs are overlaid by lower\npower small cells such as femtocells and/or picocells. However, co-channel\ndeployment of multiple tiers of BSs gives rise to the problem of cross-tier\ninterference that significantly impacts the performance of wireless networks.\nMulticell cooperation techniques, such as coordinated multipoint (CoMP)\ntransmission, have been proposed as a promising solution to mitigate the impact\nof the cross-tier interference in multi-tier networks. In this paper, we\npropose a novel scheme for Location-Aware Cross-Tier Cooperation (LA-CTC)\nbetween BSs in different tiers for downlink CoMP transmission in two-tier\ncellular networks. On one hand, the proposed scheme only uses CoMP transmission\nto enhance the performance of the users who suffer from high cross-tier\ninterference due to the co-channel deployment of small cells such as picocells.\nOn the other hand, users with good signal-to-interference-plus-noise ratio\n(${\\rm SINR}$) conditions are served directly by a single BS from any of the\ntwo tiers. Thus, the data exchange between the cooperating BSs over the\nbackhaul network can be reduced when compared to the traditional CoMP\ntransmission scheme. We use tools from stochastic geometry to quantify the\nperformance gains obtained by using the proposed scheme in terms of outage\nprobability, achievable data rate, and load per BS. We compare the performance\nof the proposed scheme with that of other schemes in the literature such as the\nschemes which use cooperation to serve all users and schemes that use range\nexpansion to offload users to the small cell tier. \n\n"}
{"id": "1405.2957", "contents": "Title: What Will 5G Be? Abstract: What will 5G be? What it will not be is an incremental advance on 4G. The\nprevious four generations of cellular technology have each been a major\nparadigm shift that has broken backwards compatibility. And indeed, 5G will\nneed to be a paradigm shift that includes very high carrier frequencies with\nmassive bandwidths, extreme base station and device densities and unprecedented\nnumbers of antennas. But unlike the previous four generations, it will also be\nhighly integrative: tying any new 5G air interface and spectrum together with\nLTE and WiFi to provide universal high-rate coverage and a seamless user\nexperience. To support this, the core network will also have to reach\nunprecedented levels of flexibility and intelligence, spectrum regulation will\nneed to be rethought and improved, and energy and cost efficiencies will become\neven more critical considerations. This paper discusses all of these topics,\nidentifying key challenges for future research and preliminary 5G\nstandardization activities, while providing a comprehensive overview of the\ncurrent literature, and in particular of the papers appearing in this special\nissue. \n\n"}
{"id": "1405.3477", "contents": "Title: Cache-enabled Small Cell Networks: Modeling and Tradeoffs Abstract: We consider a network model where small base stations (SBSs) have caching\ncapabilities as a means to alleviate the backhaul load and satisfy users'\ndemand. The SBSs are stochastically distributed over the plane according to a\nPoisson point process (PPP), and serve their users either (i) by bringing the\ncontent from the Internet through a finite rate backhaul or (ii) by serving\nthem from the local caches. We derive closed-form expressions for the outage\nprobability and the average delivery rate as a function of the\nsignal-to-interference-plus-noise ratio (SINR), SBS density, target file\nbitrate, storage size, file length and file popularity. We then analyze the\nimpact of key operating parameters on the system performance. It is shown that\na certain outage probability can be achieved either by increasing the number of\nbase stations or the total storage size. Our results and analysis provide key\ninsights into the deployment of cache-enabled small cell networks (SCNs), which\nare seen as a promising solution for future heterogeneous cellular networks. \n\n"}
{"id": "1405.4098", "contents": "Title: Optimal Index Policies for Anomaly Localization in Resource-Constrained\n  Cyber Systems Abstract: The problem of anomaly localization in a resource-constrained cyber system is\nconsidered. Each anomalous component of the system incurs a cost per unit time\nuntil its anomaly is identified and fixed. Different anomalous components may\nincur different costs depending on their criticality to the system. Due to\nresource constraints, only one component can be probed at each given time. The\nobservations from a probed component are realizations drawn from two different\ndistributions depending on whether the component is normal or anomalous. The\nobjective is a probing strategy that minimizes the total expected cost,\nincurred by all the components during the detection process, under reliability\nconstraints. We consider both independent and exclusive models. In the former,\neach component can be abnormal with a certain probability independent of other\ncomponents. In the latter, one and only one component is abnormal. We develop\noptimal simple index policies under both models. The proposed index policies\napply to a more general case where a subset (more than one) of the components\ncan be probed simultaneously and have strong performance as demonstrated by\nsimulation examples. The problem under study also finds applications in\nspectrum scanning in cognitive radio networks and event detection in sensor\nnetworks. \n\n"}
{"id": "1405.4120", "contents": "Title: On Energy-efficiency in Wireless Networks: A Game-theoretic Approach to\n  Cooperation Inspired by Evolutionary Biology Abstract: We develop a game-theoretic framework to investigate the effect of\ncooperation on the energy efficiency in wireless networks. We address two\nexamples of network architectures, resembling ad-hoc network and network with\ncentral infrastructure node. Most present approaches address the issue of\nenergy efficiency in communication networks by using complex algorithms to\nenforce cooperation in the network, followed by extensive signal processing at\nthe network nodes. Instead, we address cooperative communication scenarios\nwhich are governed by simple, evolutionary-like, local rules, and do not\nrequire strategic complexity of the network nodes. The approach is motivated by\nrecent results in evolutionary biology which suggest that cooperation can\nemerge in Nature by evolution, i. e. can be favoured by natural selection, if\ncertain mechanism is at work. As result, we are able to show by experiments\nthat cooperative behavior can indeed emerge and persist in wireless networks,\neven if the behavior of the individual nodes is driven by selfish decision\nmaking. The results from this work indicate that uncomplicated local rules,\nfollowed by simple fitness evaluation, can promote cooperation and generate\nnetwork behavior which yields global energy efficiency in certain wireless\nnetworks. \n\n"}
{"id": "1405.4608", "contents": "Title: Two-Tier Precoding for FDD Multi-cell Massive MIMO Time-Varying\n  Interference Networks (Full Version) Abstract: Massive MIMO is a promising technology in future wireless communication\nnetworks. However, it raises a lot of implementation challenges, for example,\nthe huge pilot symbols and feedback overhead, requirement of real-time global\nCSI, large number of RF chains needed and high computational complexity. We\nconsider a two-tier precoding strategy for multi-cell massive MIMO interference\nnetworks, with an outer precoder for inter-cell/inter-cluster interference\ncancellation, and an inner precoder for intra-cell multiplexing. In particular,\nto combat with the computational complexity issue of the outer precoding, we\npropose a low complexity online iterative algorithm to track the outer precoder\nunder time-varying channels. We follow an optimization technique and formulate\nthe problem on the Grassmann manifold. We develop a low complexity iterative\nalgorithm, which converges to the global optimal solution under static\nchannels. In time-varying channels, we propose a compensation technique to\noffset the variation of the time-varying optimal solution. We show with our\ntheoretical result that, under some mild conditions, perfect tracking of the\ntarget outer precoder using the proposed algorithm is possible. Numerical\nresults demonstrate that the two-tier precoding with the proposed iterative\ncompensation algorithm can achieve a good performance with a significant\ncomplexity reduction compared with the conventional two-tier precoding\ntechniques in the literature. \n\n"}
{"id": "1405.4697", "contents": "Title: Space Shuffle: A Scalable, Flexible, and High-Bandwidth Data Center\n  Network Abstract: Data center applications require the network to be scalable and\nbandwidth-rich. Current data center network architectures often use rigid\ntopologies to increase network bandwidth. A major limitation is that they can\nhardly support incremental network growth. Recent work proposes to use random\ninterconnects to provide growth flexibility. However routing on a random\ntopology suffers from control and data plane scalability problems, because\nrouting decisions require global information and forwarding state cannot be\naggregated. In this paper we design a novel flexible data center network\narchitecture, Space Shuffle (S2), which applies greedy routing on multiple ring\nspaces to achieve high-throughput, scalability, and flexibility. The proposed\ngreedy routing protocol of S2 effectively exploits the path diversity of\ndensely connected topologies and enables key-based routing. Extensive\nexperimental studies show that S2 provides high bisectional bandwidth and\nthroughput, near-optimal routing path lengths, extremely small forwarding\nstate, fairness among concurrent data flows, and resiliency to network\nfailures. \n\n"}
{"id": "1405.5630", "contents": "Title: Resource Allocation in Wireless Networks with RF Energy Harvesting and\n  Transfer Abstract: Radio frequency (RF) energy harvesting and transfer techniques have recently\nbecome alternative methods to power the next generation of wireless networks.\nAs this emerging technology enables proactive replenishment of wireless\ndevices, it is advantageous in supporting applications with quality-of-service\n(QoS) requirement. This article focuses on the resource allocation issues in\nwireless networks with RF energy harvesting capability, referred to as RF\nenergy harvesting networks (RF-EHNs). First, we present an overview of the\nRF-EHNs, followed by a review of a variety of issues regarding resource\nallocation. Then, we present a case study of designing in the receiver\noperation policy, which is of paramount importance in the RF-EHNs. We focus on\nQoS support and service differentiation, which have not been addressed by\nprevious literatures. Furthermore, we outline some open research directions. \n\n"}
{"id": "1405.5753", "contents": "Title: Modeling, Analysis and Impact of a Long Transitory Phase in Random\n  Access Protocols Abstract: In random access protocols, the service rate depends on the number of\nstations with a packet buffered for transmission. We demonstrate via numerical\nanalysis that this state-dependent rate along with the consideration of Poisson\ntraffic and infinite (or large enough to be considered infinite) buffer size\nmay cause a high-throughput and extremely long (in the order of hours)\ntransitory phase when traffic arrivals are right above the stability limit. We\nalso perform an experimental evaluation to provide further insight into the\ncharacterisation of this transitory phase of the network by analysing\nstatistical properties of its duration. The identification of the presence as\nwell as the characterisation of this behaviour is crucial to avoid\nmisprediction, which has a significant potential impact on network performance\nand optimisation. Furthermore, we discuss practical implications of this\nfinding and propose a distributed and low-complexity mechanism to keep the\nnetwork operating in the high-throughput phase. \n\n"}
{"id": "1405.5974", "contents": "Title: Living on the Edge: The Role of Proactive Caching in 5G Wireless\n  Networks Abstract: This article explores one of the key enablers of beyond $4$G wireless\nnetworks leveraging small cell network deployments, namely proactive caching.\nEndowed with predictive capabilities and harnessing recent developments in\nstorage, context-awareness and social networks, peak traffic demands can be\nsubstantially reduced by proactively serving predictable user demands, via\ncaching at base stations and users' devices. In order to show the effectiveness\nof proactive caching, we examine two case studies which exploit the spatial and\nsocial structure of the network, where proactive caching plays a crucial role.\nFirstly, in order to alleviate backhaul congestion, we propose a mechanism\nwhereby files are proactively cached during off-peak demands based on file\npopularity and correlations among users and files patterns. Secondly,\nleveraging social networks and device-to-device (D2D) communications, we\npropose a procedure that exploits the social structure of the network by\npredicting the set of influential users to (proactively) cache strategic\ncontents and disseminate them to their social ties via D2D communications.\nExploiting this proactive caching paradigm, numerical results show that\nimportant gains can be obtained for each case study, with backhaul savings and\na higher ratio of satisfied users of up to $22\\%$ and $26\\%$, respectively.\nHigher gains can be further obtained by increasing the storage capability at\nthe network edge. \n\n"}
{"id": "1405.6228", "contents": "Title: On The Scalability of P2P Swarming Systems Abstract: One of the fundamental problems in the realm of peer-to-peer systems is that\nof determining their service capacities. In this paper, we focus on P2P\nscalability issues and propose models to compute the achievable throughput\nunder distinct policies for selecting both peers and blocks. From these models,\nwe obtain novel insights on the behavior of P2P swarming systems that motivate\nnew mechanisms for publishers and peers to improve the overall performance. In\nparticular, we obtain operational regions for swarm system. In addition, we\nshow that system capacity significantly increases if publishers adopt the most\ndeprived peer selection and peers reduce their service rates when they have all\nthe file blocks but one. \n\n"}
{"id": "1405.6440", "contents": "Title: Optimal Downlink Power Allocation in Cellular Networks Abstract: In this paper, we introduce a novel approach for power allocation in cellular\nnetworks. In our model, we use sigmoidal-like utility functions to represent\ndifferent users' modulation schemes. Each utility function is a representation\nof the probability of successfully transmitted packets per unit of power\nconsumed by a user, when using a certain modulation scheme. We consider power\nallocation with utility proportional fairness policy, where the fairness among\nusers is in utility percentage i.e. percentage of successfully transmitted\npackets of the corresponding modulation scheme. We formulate our network\nutility maximization problem as a product of utilities of all users and prove\nthat our power allocation optimization problem is convex and therefore the\noptimal solution is tractable. We present a distributed algorithm to allocate\nbase station (BS) powers optimally with priority given to users running lower\nmodulation schemes while ensuring non-zero power allocation to users running\nhigher modulation schemes. Our algorithm prevents fluctuation in the power\nallocation process and is capable of traffic and modulation dependent pricing\ni.e. charges different price per unit power from different users depending in\npart on their modulation scheme and total power available at the BS. This is\nused to flatten traffic and decrease the service price for users. \n\n"}
{"id": "1405.6689", "contents": "Title: Modeling Multi-mode D2D Communications in LTE Abstract: In this work we propose a roadmap towards the analytical understanding of\nDevice-to-Device (D2D) communications in LTE-A networks. Various D2D solutions\nhave been proposed, which include inband and outband D2D transmission modes,\neach of which exhibits different pros and cons in terms of complexity,\ninterference, and spectral efficiency achieved. We go beyond traditional mode\noptimization and mode-selection schemes. Specifically, we formulate a general\nproblem for the joint per-user mode selection, connection activation and\nresource scheduling of connections. \n\n"}
{"id": "1405.7143", "contents": "Title: Millions of Little Minions: Using Packets for Low Latency Network\n  Programming and Visibility (Extended Version) Abstract: This paper presents a practical approach to rapidly introduce new dataplane\nfunctionality into networks: End-hosts embed tiny programs into packets to\nactively query and manipulate a network's internal state. We show how this\n\"tiny packet program\" (TPP) interface gives end-hosts unprecedented visibility\ninto network behavior, enabling them to work with the network to achieve a\ncommon goal. Our design leverages what each component does best: (a) switches\nforward and execute tiny packet programs (at most 5 instructions) at line rate,\nand (b) end-hosts perform arbitrary computation on network state, which are\neasy to evolve. Using a hardware prototype on a NetFPGA, we show our design is\nfeasible, at a reasonable cost. By implementing three different research\nproposals, we show that TPPs are also useful. And finally, we present an\narchitecture in which they can be made secure. \n\n"}
{"id": "1406.2255", "contents": "Title: Energy-Efficient Cooperative Cognitive Relaying Schemes for Cognitive\n  Radio Networks Abstract: We investigate a cognitive radio network in which a primary user (PU) may\ncooperate with a cognitive radio user (i.e., a secondary user (SU)) for\ntransmissions of its data packets. The PU is assumed to be a buffered node\noperating in a time-slotted fashion where the time is partitioned into\nequal-length slots. We develop two schemes which involve cooperation between\nprimary and secondary users. To satisfy certain quality of service (QoS)\nrequirements, users share time slot duration and channel frequency bandwidth.\nMoreover, the SU may leverage the primary feedback message to further increase\nboth its data rate and satisfy the PU QoS requirements. The proposed\ncooperative schemes are designed such that the SU data rate is maximized under\nthe constraint that the PU average queueing delay is maintained less than the\naverage queueing delay in case of non-cooperative PU. In addition, the proposed\nschemes guarantee the stability of the PU queue and maintain the average energy\nemitted by the SU below a certain value. The proposed schemes also provide more\nrobust and potentially continuous service for SUs compared to the conventional\npractice in cognitive networks where SUs transmit in the spectrum holes and\nsilence sessions of the PUs. We include primary source burstiness, sensing\nerrors, and feedback decoding errors to the analysis of our proposed\ncooperative schemes. The optimization problems are solved offline and require a\nsimple 2-dimensional grid-based search over the optimization variables.\nNumerical results show the beneficial gains of the cooperative schemes in terms\nof SU data rate and PU throughput, average PU queueing delay, and average PU\nenergy savings. \n\n"}
{"id": "1406.2738", "contents": "Title: Wireless Backhaul Networks: Capacity Bound, Scalability Analysis and\n  Design Guidelines Abstract: This paper studies the scalability of a wireless backhaul network modeled as\na random extended network with multi-antenna base stations (BSs), where the\nnumber of antennas per BS is allowed to scale as a function of the network\nsize. The antenna scaling is justified by the current trend towards the use of\nhigher carrier frequencies, which allows to pack large number of antennas in\nsmall form factors. The main goal is to study the per-BS antenna requirement\nthat ensures scalability of this network, i.e., its ability to deliver\nnon-vanishing rate to each source-destination pair. We first derive an\ninformation theoretic upper bound on the capacity of this network under a\ngeneral propagation model, which provides a lower bound on the per-BS antenna\nrequirement. Then, we characterize the scalability requirements for two\ncompeting strategies of interest: (i) long hop: each source-destination pair\nminimizes the number of hops by sacrificing multiplexing gain while achieving\nfull beamforming (power) gain over each hop, and (ii) short hop: each\nsource-destination pair communicates through a series of short hops, each\nachieving full multiplexing gain. While long hop may seem more intuitive in the\ncontext of massive multiple-input multiple-output (MIMO) transmission, we show\nthat the short hop strategy is significantly more efficient in terms of per-BS\nantenna requirement for throughput scalability. As a part of the proof, we\nconstruct a scalable short hop strategy and show that it does not violate any\nfundamental limits on the spatial degrees of freedom (DoFs). \n\n"}
{"id": "1406.3671", "contents": "Title: Max-min Fair Rate Allocation and Routing in Energy Harvesting Networks:\n  Algorithmic Analysis Abstract: This paper considers max-min fair rate allocation and routing in energy\nharvesting networks where fairness is required among both the nodes and the\ntime slots. Unlike most previous work on fairness, we focus on multihop\ntopologies and consider different routing methods. We assume a predictable\nenergy profile and focus on the design of efficient and optimal algorithms that\ncan serve as benchmarks for distributed and approximate algorithms. We first\ndevelop an algorithm that obtains a max-min fair rate assignment for any given\n(time-variable or time-invariable) unsplittable routing or a routing tree. For\ntime-invariable unsplittable routing, we also develop an algorithm that finds\nroutes that maximize the minimum rate assigned to any node in any slot. For\nfractional routing, we study the joint routing and rate assignment problem. We\ndevelop an algorithm for the time-invariable case with constant rates. We show\nthat the time-variable case is at least as hard as the 2-commodity feasible\nflow problem and design an FPTAS to combat the high running time. Finally, we\nshow that finding an unsplittable routing or a routing tree that provides\nlexicographically maximum rate assignment (i.e., that is the best in the\nmax-min fairness terms) is NP-hard, even for a time horizon of a single slot.\nOur analysis provides insights into the problem structure and can be applied to\nother related fairness problems. \n\n"}
{"id": "1406.4785", "contents": "Title: Technical Report: Performance of the Expected Force on AS-level Inernet\n  topologies Abstract: Many concepts in network science are based on idealized network models.\nInfrastructure networks, however, are strongly constrained by specific\nengineering and economic constraints which do not appear in such models. One\nresult is that concepts which are assumed to be fundamental by theoriticians\nseverely underperform in real world situations. This motivated us to test if\nthe Expected Force (ExF) metric, which was developed in the context of more\ntheoretical network models, would continue to be predictive of epidemic\noutcomes on the highly structured topology of the internet at the autonomous\nsystems (AS) level router connectivity. Results suggest that the ExF performs\nextremely well on these topologies, perhaps reflecting their design constraint\nof easing the diffusion of information. \n\n"}
{"id": "1406.4917", "contents": "Title: Max-Weight Scheduling and Quality-Aware Streaming for Device-to-Device\n  Video Delivery Abstract: We propose and analyze centralized and distributed algorithms for\ndevice-to-device video scheduling and streaming. The proposed algorithms\naddress jointly the problems of device-to-device link scheduling and video\nquality adaptation in streaming. Our simulations show that the proposed\nalgorithms significantly outperform conventional separated approaches that\ntreat these two problems independently. \n\n"}
{"id": "1406.5258", "contents": "Title: Location Aided Energy Balancing Strategy in Green Cellular Networks Abstract: Most cellular network communication strategies are focused on data traffic\nscenarios rather than energy balance and efficient utilization. Thus mobile\nusers in hot cells may suffer from low throughput due to energy loading\nimbalance problem. In state of art cellular network technologies, relay\nstations extend cell coverage and enhance signal strength for mobile users.\nHowever, busy traffic makes the relay stations in hot area run out of energy\nquickly. In this paper, we propose an energy balancing strategy in which the\nmobile nodes are able to dynamically select and hand over to the relay station\nwith the highest potential energy capacity to resume communication. Key to the\nstrategy is that each relay station merely maintains two parameters that\ncontains the trend of its previous energy consumption and then predicts its\nfuture quantity of energy, which is defined as the relay station potential\nenergy capacity. Then each mobile node can select the relay station with the\nhighest potential energy capacity. Simulations demonstrate that our approach\nsignificantly increase the aggregate throughput and the average life time of\nrelay stations in cellular network environment. \n\n"}
{"id": "1406.6321", "contents": "Title: Power-Optimal Feedback-Based Random Spectrum Access for an Energy\n  Harvesting Cognitive User Abstract: In this paper, we study and analyze cognitive radio networks in which\nsecondary users (SUs) are equipped with Energy Harvesting (EH) capability. We\ndesign a random spectrum sensing and access protocol for the SU that exploits\nthe primary link's feedback and requires less average sensing time. Unlike\nprevious works proposed earlier in literature, we do not assume perfect\nfeedback. Instead, we take into account the more practical possibilities of\noverhearing unreliable feedback signals and accommodate spectrum sensing\nerrors. Moreover, we assume an interference-based channel model where the\nreceivers are equipped with multi-packet reception (MPR) capability.\nFurthermore, we perform power allocation at the SU with the objective of\nmaximizing the secondary throughput under constraints that maintain certain\nquality-of-service (QoS) measures for the primary user (PU). \n\n"}
{"id": "1406.7572", "contents": "Title: Performance Analysis of Ad-Hoc Routing in Clustered Multi-hop Wireless\n  Networks Abstract: This paper analyzes the performance of clustered decode-and-forward multi-hop\nrelaying (CDFMR) wireless Rayleigh fading networks, and sheds light on their\ndesign principles for energy and spectral efficiency. The focus is on a general\nperformance analysis (over all SNR range) of heterogeneous wireless networks\nwith possibly different numbers of relays in clusters of various separations.\nFor clustered multi-hop relaying systems, ad-hoc routing is known as an\nefficient decentralized routing algorithm which selects the best relay node on\na hop-by-hop basis using local channel state information. In this article, we\ncombine ad-hoc routing and cooperative diversity in CDFMR systems, and we\nderive (i) a closed-form expression for the probability distribution of the\nend-to-end SNR at the destination node; (ii) the system symbol error rate (SER)\nperformance for a wide class of modulation schemes; and (iii) exact analytical\nexpressions for the system ergodic capacity, the outage probability and the\nachievable probability of the SNR (power) gain. We also provide simple\nanalytical asymptotic expressions for SER and the outage probability in high\nSNR regime. Simulation results are provided to validate the correctness of the\npresented analyses. \n\n"}
{"id": "1407.0474", "contents": "Title: Recent Advances in Joint Wireless Energy and Information Transfer Abstract: In this paper, we provide an overview of the recent advances in\nmicrowave-enabled wireless energy transfer (WET) technologies and their\napplications in wireless communications. Specifically, we divide our\ndiscussions into three parts. First, we introduce the state-of-the-art WET\ntechnologies and the signal processing techniques to maximize the energy\ntransfer efficiency. Then, we discuss an interesting paradigm named\nsimultaneous wireless information and power transfer (SWIPT), where energy and\ninformation are jointly transmitted using the same radio waveform. At last, we\nreview the recent progress in wireless powered communication networks (WPCN),\nwhere wireless devices communicate using the power harvested by means of WET.\nExtensions and future directions are also discussed in each of these areas. \n\n"}
{"id": "1407.0536", "contents": "Title: Analysis of the Decoupled Access for Downlink and Uplink in Wireless\n  Heterogeneous Networks Abstract: Wireless cellular networks evolve towards a heterogeneous infrastructure,\nfeaturing multiple types of Base Stations (BSs), such as Femto BSs (FBSs) and\nMacro BSs (MBSs). A wireless device observes multiple points (BSs) through\nwhich it can access the infrastructure and it may choose to receive the\ndownlink (DL) traffic from one BS and send uplink (UL) traffic through another\nBS. Such a situation is referred to as decoupled DL/UL access. Using the\nframework of stochastic geometry, we derive the association probability for\nDL/UL. In order to maximize the average received power, as the relative density\nof FBSs initially increases, a large fraction of devices chooses decoupled\naccess, i.e. receive from a MBS in DL and transmit through a FBS in UL. We\nanalyze the impact that this type of association has on the average throughput\nin the system. \n\n"}
{"id": "1407.1239", "contents": "Title: RepNet: Cutting Tail Latency in Data Center Networks with Flow\n  Replication Abstract: Data center networks need to provide low latency, especially at the tail, as\ndemanded by many interactive applications. To improve tail latency, existing\napproaches require modifications to switch hardware and/or end-host operating\nsystems, making them difficult to be deployed. We present the design,\nimplementation, and evaluation of RepNet, an application layer transport that\ncan be deployed today. RepNet exploits the fact that only a few paths among\nmany are congested at any moment in the network, and applies simple flow\nreplication to mice flows to opportunistically use the less congested path.\nRepNet has two designs for flow replication: (1) RepSYN, which only replicates\nSYN packets and uses the first connection that finishes TCP handshaking for\ndata transmission, and (2) RepFlow which replicates the entire mice flow. We\nimplement RepNet on {\\tt node.js}, one of the most commonly used platforms for\nnetworked interactive applications. {\\tt node}'s single threaded event-loop and\nnon-blocking I/O make flow replication highly efficient. Performance evaluation\non a real network testbed and in Mininet reveals that RepNet is able to reduce\nthe tail latency of mice flows, as well as application completion times, by\nmore than 50\\%. \n\n"}
{"id": "1407.1497", "contents": "Title: Content-Aware Network Coding over Device-to-Device Networks Abstract: Consider a scenario of broadcasting a common content to a group of\ncooperating mobile devices that are within proximity of each other. Devices in\nthis group may receive partial content from the source due to packet losses\nover wireless broadcast links. We further consider that packet losses are\ndifferent for different devices. The remaining missing content at each device\ncan then be recovered, thanks to cooperation among the devices by exploiting\ndevice-to-device (D2D) connections. In this context, the minimum amount of time\nthat can guarantee a complete acquisition of the common content at every device\nis referred to as the \"completion time\". It has been shown that instantly\ndecodable network coding (IDNC) reduces the completion time as compared to no\nnetwork coding in this scenario. Yet, for applications such as video streaming,\nnot all packets have the same importance and not all devices are interested in\nthe same quality of content. This problem is even more interesting when\nadditional, but realistic constraints, such as strict deadline, bandwidth, or\nlimited energy are added in the problem formulation. We assert that direct\napplication of IDNC in such a scenario yields poor performance in terms of\ncontent quality and completion time. In this paper, we propose a novel Content\nand Loss-Aware IDNC scheme that improves content quality and network coding\nopportunities jointly by taking into account importance of each packet towards\nthe desired quality of service (QoS) as well as the channel losses over D2D\nlinks. Our proposed Content and Loss-Aware IDNC (i) maximizes the quality under\nthe completion time constraint, and (ii) minimizes the completion time under\nthe quality constraint. We demonstrate the benefits of Content and Loss-Aware\nIDNC through simulations. \n\n"}
{"id": "1407.1931", "contents": "Title: Deterministic Near-Optimal P2P Streaming Abstract: We consider streaming over a peer-to-peer network with homogeneous nodes in\nwhich a single source broadcasts a data stream to all the users in the system.\nPeers are allowed to enter or leave the system (adversarially) arbitrarily.\nPrevious approaches for streaming in this setting have either used randomized\ndistribution graphs or structured trees with randomized maintenance algorithms.\nRandomized graphs handle peer churn well but have poor connectivity guarantees,\nwhile structured trees have good connectivity but have proven hard to maintain\nunder peer churn. We improve upon both approaches by presenting a novel\ndistribution structure with a deterministic and distributed algorithm for\nmaintenance under peer churn; our result is inspired by a recent work proposing\ndeterministic algorithms for rumor spreading in graphs. A key innovation in our\napproach is in having redundant links in the distribution structure. While this\nleads to a reduction in the maximum streaming rate possible, we show that for\nthe amount of redundancy used, the delay guarantee of the proposed algorithm is\nnear optimal. We introduce a tolerance parameter that captures the worst-case\ntransient streaming rate received by the peers during churn events and\ncharacterize the fundamental tradeoff between rate, delay and tolerance. A\nnatural generalization of the deterministic algorithm achieves this tradeoff\nnear optimally. Finally, the proposed deterministic algorithm is robust enough\nto handle various generalizations: ability to deal with heterogeneous node\ncapacities of the peers and more complicated streaming patterns where multiple\nsource transmissions are present. \n\n"}
{"id": "1407.4489", "contents": "Title: Coded Caching for Delay-Sensitive Content Abstract: Coded caching is a recently proposed technique that achieves significant\nperformance gains for cache networks compared to uncoded caching schemes.\nHowever, this substantial coding gain is attained at the cost of large delivery\ndelay, which is not tolerable in delay-sensitive applications such as video\nstreaming. In this paper, we identify and investigate the tradeoff between the\nperformance gain of coded caching and the delivery delay. We propose a\ncomputationally efficient caching algorithm that provides the gains of coding\nand respects delay constraints. The proposed algorithm achieves the optimum\nperformance for large delay, but still offers major gains for small delay.\nThese gains are demonstrated in a practical setting with a video-streaming\nprototype. \n\n"}
{"id": "1408.2335", "contents": "Title: Wireless Powered Communication: Opportunities and Challenges Abstract: The performance of wireless communication is fundamentally constrained by the\nlimited battery life of wireless devices, whose operations are frequently\ndisrupted due to the need of manual battery replacement/recharging. The recent\nadvance in radio frequency (RF) enabled wireless energy transfer (WET)\ntechnology provides an attractive solution named wireless powered communication\n(WPC), where the wireless devices are powered by dedicated wireless power\ntransmitters to provide continuous and stable microwave energy over the air. As\na key enabling technology for truly perpetual communications, WPC opens up the\npotential to build a network with larger throughput, higher robustness, and\nincreased flexibility compared to its battery-powered counterpart. However, the\ncombination of wireless energy and information transmissions also raises many\nnew research problems and implementation issues to be addressed. In this\narticle, we provide an overview of state-of-the-art RF-enabled WET technologies\nand their applications to wireless communications, with highlights on the key\ndesign challenges, solutions, and opportunities ahead. \n\n"}
{"id": "1408.2779", "contents": "Title: A Probabilistic MAC for Cognitive Radio Systems with Energy Harvesting\n  Nodes Abstract: In this paper, we consider a cognitive radio (CR) system where the secondary\nuser (SU) harvests energy from both the nature resources and the primary user\n(PU) radio frequency(RF) signal. We propose an energy-based probabilistic\naccess scheme in which SU probabilistically accesses and senses the primary\nchannel. The decision is based on the available energy and the PU's activity.\nWe investigate the problem of maximizing the SU's success rate provided that\nthe PU average quality of service (QoS) constraint is satisfied. We also assume\nmulti-packet reception (MPR) capability and sensing errors under a Rayleigh\nfading channel. Numerical results show the effectiveness of the proposed\nprobabilistic access scheme. \n\n"}
{"id": "1408.3079", "contents": "Title: A Lightweight Approach for Improving the Lookup Performance in\n  Kademlia-type Systems Abstract: Discovery of nodes and content in large-scale distributed systems is\ngenerally based on Kademlia, today. Understanding Kademlia-type systems to\nimprove their performance is essential for maintaining a high service quality\nfor an increased number of participants, particularly when those systems are\nadopted by latency-sensitive applications.\n  This paper contributes to the understanding of Kademlia by studying the\nimpact of \\emph{diversifying} neighbours' identifiers within each routing table\nbucket on the lookup performance. We propose a new, yet backward-compatible,\nneighbour selection scheme that attempts to maximize the aforementioned\ndiversity. The scheme does not cause additional overhead except negligible\ncomputations for comparing the diversity of identifiers. We present a\ntheoretical model for the actual impact of the new scheme on the lookup's hop\ncount and validate it against simulations of three exemplary Kademlia-type\nsystems. We also measure the performance gain enabled by a partial deployment\nfor the scheme in the real KAD system. The results confirm the superiority of\nthe systems that incorporate our scheme. \n\n"}
{"id": "1409.0085", "contents": "Title: Designing Path Planning Algorithms for Mobile Anchor towards Range-Free\n  Localization Abstract: Localization is one of the most important factor in wireless sensor networks\nas many applications demand position information of sensors. Recently there is\nan increasing interest on the use of mobile anchors for localizing sensors.\nMost of the works available in the literature either looks into the aspect of\nreducing path length of mobile anchor or tries to increase localization\naccuracy. The challenge is to design a movement strategy for a mobile anchor\nthat reduces path length while meeting the requirements of a good range-free\nlocalization technique. In this paper we propose two cost-effective movement\nstrategies i.e., path planning for a mobile anchor so that localization can be\ndone using the localization scheme \\cite{Lee2009}. In one strategy we use a\nhexagonal movement pattern for the mobile anchor to localize all sensors inside\na bounded rectangular region with lesser movement compared to the existing\nworks in literature. In other strategy we consider a connected network in an\nunbounded region where the mobile anchor moves in the hexagonal pattern to\nlocalize the sensors. In this approach, we guarantee localization of all\nsensors within $r/2$ error-bound where $r$ is the communication range of the\nmobile anchor and sensors. Our simulation results support theoretical results\nalong with localization accuracy. \n\n"}
{"id": "1409.0876", "contents": "Title: A Graph-based Perspective to Total Carbon Footprint Assessment of\n  Non-marginal Technology-driven Projects - Use case of OTT/IPTV Abstract: Life Cycle Assessment (LCA) of green and sustainable projects has been found\nto be a necessary analysis in order to include all upstream, downstream, and\nindirect impacts. Because of the complexity of interactions, the differential\nimpacts with respect to a baseline, i.e., a business-as-usual (BAU) scenario,\nare commonly considered to relatively compare various projects. However, as the\ndegree of penetration of a project in the baseline increases, the popular\nmarginal assumption does no longer hold, and the differential impacts may\nbecome inconsistent. Although various mythologies have been successfully\nproposed and used to contain such a side effect, the bottom-up nature, which\ninitiates the assessment from the project itself and ultimately widens the\nscope, could easily fail to acknowledge critical modifications to the baseline.\nThis is highly relevant in terms of ICT's disruptive and dynamic technologies\nwhich push the baseline to become a marginal legacy. In this work, an analytic\nformalism is presented to provide a means of comparison of such technologies\nand projects. The core idea behind the proposed methodology is a\nmagnitude-insensitive graph-based distance function to differentially compare a\nproject with a baseline. The applicability of the proposed methodology is then\nevaluated in a use case of OTT/IPTV online media distribution services. \n\n"}
{"id": "1409.1606", "contents": "Title: Power Optimal Non-contiguous Spectrum Access in Multi Front End Radio\n  Enabled Point-to-Point Link Abstract: Non-contiguous spectrum chunks allow wireless links to flexibly access a wide\namount of bandwidth. Multi- Channel Multi-Radio (MC-MR) and Non-Contiguous\nOrthogonal Frequency Division Multiplexing (NC-OFDM) are the two commercially\nviable strategies to access non-contiguous spectrum chunks. MC-MR accesses\nmultiple non-contiguous chunks by activating multiple front ends which, in\nturn, increases the circuit power consumption of each of the activated front\nends. NC-OFDM accesses non-contiguous spectrum chunks with a single front end\nby nulling remaining subchannels but increases spectrum span which, in turn,\nincreases the power consumption of ADC and DAC. This work focuses on a\npoint-to-point link where transmitter and receiver have multiple front ends and\ncan employ NC-OFDM technology. We investigate optimal spectrum fragmentation in\neach front end from a system power (summation of transmit power and circuit\npower) perspective. We formulate a mixed integer non-linear program (MINLP) to\nperform power control and scheduling, and minimize system power by providing a\ngreedy algorithm (O(M^3 I)) where M and I denote the number of channels and\nradio front ends respectively. \n\n"}
{"id": "1409.1661", "contents": "Title: Rate Optimal design of a Wireless Backhaul Network using TV White Space Abstract: The penetration of wireless broadband services in remote areas has primarily\nbeen limited due to the lack of economic incentives that service providers\nencounter in sparsely populated areas. Besides, wireless backhaul links like\nsatellite and microwave are either expensive or require strict line of sight\ncommunication making them unattractive. TV white space channels with their\ndesirable radio propagation characteristics can provide an excellent\nalternative for engineering backhaul networks in areas that lack abundant\ninfrastructure. Specifically, TV white space channels can provide \"free\nwireless backhaul pipes\" to transport aggregated traffic from broadband sources\nto fiber access points. In this paper, we investigate the feasibility of\nmulti-hop wireless backhaul in the available white space channels by using\nnoncontiguous Orthogonal Frequency Division Multiple Access (NC-OFDMA)\ntransmissions between fixed backhaul towers. Specifically, we consider joint\npower control, scheduling and routing strategies to maximize the minimum rate\nacross broadband towers in the network. Depending on the population density and\ntraffic demands of the location under consideration, we discuss the suitable\nchoice of cell size for the backhaul network. Using the example of available TV\nwhite space channels in Wichita, Kansas (a small city located in central USA),\nwe provide illustrative numerical examples for designing such wireless backhaul\nnetwork. \n\n"}
{"id": "1409.2246", "contents": "Title: DCT${^2}$Gen: A Versatile TCP Traffic Generator for Data Centers Abstract: Only little is publicly known about traffic in non-educational data centers.\nRecent studies made some knowledge available, which gives us the opportunity to\ncreate more realistic traffic models for data center research. We used this\nknowledge to create the first publicly available traffic generator that\nproduces realistic traffic between hosts in data centers of arbitrary size. We\ncharacterize traffic by using six probability distribution functions and\nconcentrate on the generation of traffic on flow-level. The distribution\nfunctions are described as step functions, which makes our generator highly\nconfigurable to generate traffic for different kinds of data centers. Moreover,\nin data centers, traffic between hosts in the same rack and hosts in different\nracks have different properties. We model this phenomenon, making our generated\ntraffic very realistic. We carefully evaluated our approach and conclude that\nit reproduces these characteristics with high accuracy. \n\n"}
{"id": "1409.6001", "contents": "Title: Reconfigurable Wireless Networks Abstract: Driven by the advent of sophisticated and ubiquitous applications, and the\never-growing need for information, wireless networks are without a doubt\nsteadily evolving into profoundly more complex and dynamic systems. The user\ndemands are progressively rampant, while application requirements continue to\nexpand in both range and diversity. Future wireless networks, therefore, must\nbe equipped with the ability to handle numerous, albeit challenging\nrequirements. Network reconfiguration, considered as a prominent network\nparadigm, is envisioned to play a key role in leveraging future network\nperformance and considerably advancing current user experiences. This paper\npresents a comprehensive overview of reconfigurable wireless networks and an\nin-depth analysis of reconfiguration at all layers of the protocol stack. Such\nnetworks characteristically possess the ability to reconfigure and adapt their\nhardware and software components and architectures, thus enabling flexible\ndelivery of broad services, as well as sustaining robust operation under highly\ndynamic conditions. The paper offers a unifying framework for research in\nreconfigurable wireless networks. This should provide the reader with a\nholistic view of concepts, methods, and strategies in reconfigurable wireless\nnetworks. Focus is given to reconfigurable systems in relatively new and\nemerging research areas such as cognitive radio networks, cross-layer\nreconfiguration and software-defined networks. In addition, modern networks\nhave to be intelligent and capable of self-organization. Thus, this paper\ndiscusses the concept of network intelligence as a means to enable\nreconfiguration in highly complex and dynamic networks. Finally, the paper is\nsupported with several examples and case studies showing the tremendous impact\nof reconfiguration on wireless networks. \n\n"}
{"id": "1409.7368", "contents": "Title: Census: Fast, scalable and robust data aggregation in MANETs Abstract: This paper describes Census, a protocol for data aggregation and statistical\ncounting in MANETs. Census operates by circulating a set of tokens in the\nnetwork using biased random walks such that each node is visited by at least\none token. The protocol is structure-free so as to avoid high messaging\noverhead for maintaining structure in the presence of node mobility. It biases\nthe random walks of tokens so as to achieve fast cover time; the bias involves\nshort albeit multi-hop gradients that guide the tokens towards hitherto\nunvisited nodes. Census thus achieves a cover time of O(N/k) and message\noverhead of O(Nlog(N)/k) where N is the number of nodes and k the number of\ntokens in the network. Notably, it enjoys scalability and robustness, which we\ndemonstrate via simulations in networks ranging from 100 to 4000 nodes under\ndifferent network densities and mobility models. \n\n"}
{"id": "1409.7433", "contents": "Title: Throughput Analysis for Wireless Networks with Full-Duplex Radios Abstract: This paper investigates the throughput for wireless network with full-duplex\nradios using stochastic geometry. Full-duplex (FD) radios can exchange data\nsimultaneously with each other. On the other hand, the downside of FD\ntransmission is that it will inevitably cause extra interference to the network\ncompared to half-duplex (HD) transmission. In this paper, we focus on a\nwireless network of nodes with both HD and FD capabilities and derive and\noptimize the throughput in such a network. Our analytical result shows that if\nthe network is adapting an ALOHA protocol, the maximal throughput is always\nachieved by scheduling all concurrently transmitting nodes to work in FD mode\ninstead of a mixed FD/HD mode or HD mode regardless of the network\nconfigurations. Moreover, the throughput gain of using FD transmission over HD\ntransmission is analytically lower and upper bounded. \n\n"}
{"id": "1409.7520", "contents": "Title: More is less: Connectivity in fractal regions Abstract: Ad-hoc networks are often deployed in regions with complicated boundaries. We\nshow that if the boundary is modeled as a fractal, a network requiring line of\nsight connections has the counterintuitive property that increasing the number\nof nodes decreases the full connection probability. We characterise this decay\nas a stretched exponential involving the fractal dimension of the boundary, and\ndiscuss mitigation strategies. Applications of this study include the analysis\nand design of sensor networks operating in rugged terrain (e.g. railway\ncuttings), mm-wave networks in industrial settings and\nvehicle-to-vehicle/vehicle-to-infrastructure networks in urban environments. \n\n"}
{"id": "1410.1255", "contents": "Title: Multi-resource Fair Allocation with Bounded Number of Tasks in Cloud\n  Computing Systems Abstract: Dominant resource fairness (DRF) is a popular mechanism for multi-resource\nallocation in cloud computing systems. In this paper, we consider a problem of\nmulti-resource fair allocation with bounded number of tasks. Firstly, we\npropose the lexicographically max-min normalized share (LMMNS) fair allocation\nmechanism, which is a natural generalization of DRF, and design a non-trivial\noptimal algorithm to find a LMMNS fair allocation, whose running time is linear\nin the number of users. Secondly, we prove that LMMNS satisfies envy-freeness\n(EF) and group strategy-proofness (GSP), and analysis the approximation ratios\nof LMMNS, by exploiting the properties of the optimal solution. Thirdly, we\npropose a modified version of LMMNS, which is the second mechanism satisfying\nsharing incentive, EF, and GSP. Finally, we have implemented LMMNS, and show\nthat it has a good average-case performance, especially when the number of\nresources is 2. \n\n"}
{"id": "1410.3507", "contents": "Title: Performance Evaluation of Flow Allocation with Successive Interference\n  Cancelation for Random Access WMNs Abstract: In this study we explore the performance gain that can be achieved at the\nnetwork level by employing successive interference cancelation (SIC) instead of\ntreating interference as noise for random access wireless mesh networks with\nmulti-packet reception capabilities. More precisely we explore both the\nthroughput and the delay of a distributed flow allocation scheme aimed at\nmaximizing average aggregate flow throughput while also providing bounded delay\ncombined with SIC. Simulation results derived from three simple topologies show\nthat the gain over treating interference as noise for this scheme can be up to\n$15\\%$ for an SINR threshold value equal to $0.5$. For SINR threshold values as\nhigh as $2.0$ however, this gain is either insignificant or treating\ninterference as noise proves a better practice. The reason is that although SIC\nimproves the throughput on a specific link, it also increases the interference\nimposed on neighboring receivers. We also show that the gain of applying SIC is\nmore profound in cases of a large degree of asymmetry among interfering links. \n\n"}
{"id": "1410.3712", "contents": "Title: Process-aware web programming with Jolie Abstract: We extend the Jolie programming language to capture the native modelling of\nprocess-aware web information systems, i.e., web information systems based upon\nthe execution of business processes. Our main contribution is to offer a\nunifying approach for the programming of distributed architectures on the web,\nwhich can capture web servers, stateful process execution, and the composition\nof services via mediation. We discuss applications of this approach through a\nseries of examples that cover, e.g., static content serving, multiparty\nsessions, and the evolution of web systems. Finally, we present a performance\nevaluation that includes a comparison of Jolie-based web systems to other\nframeworks and a measurement of its scalability. \n\n"}
{"id": "1411.2435", "contents": "Title: Large-scale Spatial Distribution Identification of Base Stations in\n  Cellular Networks Abstract: The performance of cellular system significantly depends on its network\ntopology, where the spatial deployment of base stations (BSs) plays a key role\nin the downlink scenario. Moreover, cellular networks are undergoing a\nheterogeneous evolution, which introduces unplanned deployment of smaller BSs,\nthus complicating the performance evaluation even further. In this paper, based\non large amount of real BS locations data, we present a comprehensive analysis\non the spatial modeling of cellular network structure. Unlike the related\nworks, we divide the BSs into different subsets according to geographical\nfactor (e.g. urban or rural) and functional type (e.g. macrocells or\nmicrocells), and perform detailed spatial analysis to each subset. After\nexamining the accuracy of Poisson point process (PPP) in BS locations modeling,\nwe take into account the Gibbs point processes as well as Neyman-Scott point\nprocesses and compare their accuracy in view of large-scale modeling test.\nFinally, we declare the inaccuracy of the PPP model, and reveal the general\nclustering nature of BSs deployment, which distinctly violates the traditional\nassumption. This paper carries out a first large-scale identification regarding\navailable literatures, and provides more realistic and more general results to\ncontribute to the performance analysis for the forthcoming heterogeneous\ncellular networks. \n\n"}
{"id": "1411.3617", "contents": "Title: Random geometric graphs with general connection functions Abstract: In the original (1961) Gilbert model of random geometric graphs, nodes are\nplaced according to a Poisson point process, and links formed between those\nwithin a fixed range. Motivated by wireless ad-hoc networks \"soft\" or\n\"probabilistic\" connection models have recently been introduced, involving a\n\"connection function\" H(r) that gives the probability that two nodes at\ndistance r are linked (directly connect). In many applications (not only\nwireless networks), it is desirable that the graph is connected, that is every\nnode is linked to every other node in a multihop fashion. Here, the connection\nprobability of a dense network in a convex domain in two or three dimensions is\nexpressed in terms of contributions from boundary components, for a very\ngeneral class of connection functions. It turns out that only a few quantities\nsuch as moments of the connection function appear. Good agreement is found with\nspecial cases from previous studies and with numerical simulations. \n\n"}
{"id": "1411.3757", "contents": "Title: When do wireless network signals appear Poisson? Abstract: We consider the point process of signal strengths from transmitters in a\nwireless network observed from a fixed position under models with general\nsignal path loss and random propagation effects. We show via coupling arguments\nthat under general conditions this point process of signal strengths can be\nwell-approximated by an inhomogeneous Poisson or a Cox point processes on the\npositive real line. We also provide some bounds on the total variation distance\nbetween the laws of these point processes and both Poisson and Cox point\nprocesses. Under appropriate conditions, these results support the use of a\nspatial Poisson point process for the underlying positioning of transmitters in\nmodels of wireless networks, even if in reality the positioning does not appear\nPoisson. We apply the results to a number of models with popular choices for\npositioning of transmitters, path loss functions, and distributions of\npropagation effects. \n\n"}
{"id": "1411.5173", "contents": "Title: Analytical Performance Model for Poisson Wireless Networks with Pathloss\n  and Shadowing Propagation Abstract: The SINR (signal to interference plus noise ratio) is a key factor for\nwireless networks analysis. Indeed, the SINR distribution allows the derivation\nof performance and quality of service (QoS) evaluation. Moreover, it also\nenables the analysis of radio resources allocation and scheduling policies,\nsince they depend on the SINR reached by a UE (User Equipment). Therefore, it\nis particularly interesting to develop an analytical method which allows to\nevaluate the SINR, in a simple and quick way, for a realistic environment.\nConsidering a stochastic Poisson network model, we establish the CDF\n(cumulative distributed function) of the SINR. We show that the shadowing can\nbe neglected, in many cases, as long as mobiles are connected to their best\nserving base station (BS), i.e. the BS which offers them the most powerful\nuseful signal. As a consequence, the analysis of performance and quality of\nservice, directly derived from the CDF of SINR, can be established by using a\npropagation model which takes into account only the pathloss. Moreover, we\nestablish that the Fluid network model we have proposed can be used to analyze\nstochastic Poisson distributed network. Therefore, the analysis of stochastic\nPoisson network can be done in an easy and quick way, by using the analytical\nexpression of the SINR established thanks to the Fluid network model. \n\n"}
{"id": "1411.5323", "contents": "Title: Genetic Algorithms in Wireless Networking: Techniques, Applications, and\n  Issues Abstract: In recent times, wireless access technology is becoming increasingly\ncommonplace due to the ease of operation and installation of untethered\nwireless media. The design of wireless networking is challenging due to the\nhighly dynamic environmental condition that makes parameter optimization a\ncomplex task. Due to the dynamic, and often unknown, operating conditions,\nmodern wireless networking standards increasingly rely on machine learning and\nartificial intelligence algorithms. Genetic algorithms (GAs) provide a\nwell-established framework for implementing artificial intelligence tasks such\nas classification, learning, and optimization. GAs are well-known for their\nremarkable generality and versatility, and have been applied in a wide variety\nof settings in wireless networks. In this paper, we provide a comprehensive\nsurvey of the applications of GAs in wireless networks. We provide both an\nexposition of common GA models and configuration and provide a broad ranging\nsurvey of GA techniques in wireless networks. We also point out open research\nissues and define potential future work. While various surveys on GAs exist in\nliterature, our paper is the first paper, to the best of our knowledge, which\nfocuses on their application in wireless networks. \n\n"}
{"id": "1411.5739", "contents": "Title: The Online Disjoint Set Cover Problem and its Applications Abstract: Given a universe $U$ of $n$ elements and a collection of subsets\n$\\mathcal{S}$ of $U$, the maximum disjoint set cover problem (DSCP) is to\npartition $\\mathcal{S}$ into as many set covers as possible, where a set cover\nis defined as a collection of subsets whose union is $U$. We consider the\nonline DSCP, in which the subsets arrive one by one (possibly in an order\nchosen by an adversary), and must be irrevocably assigned to some partition on\narrival with the objective of minimizing the competitive ratio. The competitive\nratio of an online DSCP algorithm $A$ is defined as the maximum ratio of the\nnumber of disjoint set covers obtained by the optimal offline algorithm to the\nnumber of disjoint set covers obtained by $A$ across all inputs. We propose an\nonline algorithm for solving the DSCP with competitive ratio $\\ln n$. We then\nshow a lower bound of $\\Omega(\\sqrt{\\ln n})$ on the competitive ratio for any\nonline DSCP algorithm. The online disjoint set cover problem has wide ranging\napplications in practice, including the online crowd-sourcing problem, the\nonline coverage lifetime maximization problem in wireless sensor networks, and\nin online resource allocation problems. \n\n"}
{"id": "1411.6137", "contents": "Title: Enhanced Multi-Parameter Cognitive Architecture for Future Wireless\n  Communications Abstract: The very original concept of cognitive radio (CR) raised by Mitola targets at\nall the environment parameters, including those in physical layer, MAC layer,\napplication layer as well as the information extracted from reasoning. Hence\nthe first CR is also referred to as \"full cognitive radio\". However, due to its\ndifficult implementation, FCC and Simon Haykin separately proposed a much more\nsimplified definition, in which CR mainly detects one single parameter, i.e.,\nspectrum occupancy, and is also called as \"spectrum sensing cognitive radio\".\nWith the rapid development of wireless communication, the infrastructure of a\nwireless system becomes much more complicated while the functionality at every\nnode is desired to be as intelligent as possible, say the self-organized\ncapability in the approaching 5G cellular networks. It is then interesting to\nre-look into Mitola's definition and think whether one could, besides obtaining\nthe \"on/off\" status of the licensed user only, achieve more parameters in a\ncognitive way. In this article, we propose a new cognitive architecture\ntargeting at multiple parameters in future cellular networks, which is a one\nstep further towards the \"full cognition\" compared to the most existing CR\nresearch. The new architecture is elaborated in detailed stages, and three\nrepresentative examples are provided based on the recent research progress to\nillustrate the feasibility as well as the validity of the proposed\narchitecture. \n\n"}
{"id": "1411.7711", "contents": "Title: Detour Planning for Fast and Reliable Failure Recovery in SDN with\n  OpenState Abstract: A reliable and scalable mechanism to provide protection against a link or\nnode failure has additional requirements in the context of SDN and OpenFlow.\nNot only it has to minimize the load on the controller, but it must be able to\nreact even when the controller is unreachable. In this paper we present a\nprotection scheme based on precomputed backup paths and inspired by MPLS\ncrankback routing, that guarantees instantaneous recovery times and aims at\nzero packet-loss after failure detection, regardless of controller\nreachability, even when OpenFlow's \"fast-failover\" feature cannot be used. The\nproposed mechanism is based on OpenState, an OpenFlow extension that allows a\nprogrammer to specify how forwarding rules should autonomously adapt in a\nstateful fashion, reducing the need to rely on remote controllers. We present\nthe scheme as well as two different formulations for the computation of backup\npaths. \n\n"}
{"id": "1411.7785", "contents": "Title: Performance laws of large heterogeneous cellular networks Abstract: We propose a model for heterogeneous cellular networks assuming a space-time\nPoisson process of call arrivals, independently marked by data volumes, and\nserved by different types of base stations (having different transmission\npowers) represented by the superposition of independent Poisson processes on\nthe plane. Each station applies a processor sharing policy to serve users\narriving in its vicinity, modeled by the Voronoi cell perturbed by some random\nsignal propagation effects (shadowing). Users' peak service rates depend on\ntheir signal-to-interference-and-noise ratios (SINR) with respect to the\nserving station. The mutual-dependence of the cells (due to the extra-cell\ninterference) is captured via some system of cell-load equations impacting the\nspatial distribution of the SINR. We use this model to study in a semi-analytic\nway (involving only static simulations, with the temporal evolution handled by\nthe queuing theoretic results) network performance metrics (cell loads, mean\nnumber of users) and the quality of service perceived by the users (mean\nthroughput) served by different types of base stations. Our goal is to identify\nmacroscopic laws regarding these performance metrics, involving averaging both\nover time and the network geometry. The reveled laws are validated against real\nfield measurement in an operational network. \n\n"}
{"id": "1412.2455", "contents": "Title: Location Verification Systems for VANETs in Rician Fading Channels Abstract: In this work we propose and examine Location Verification Systems (LVSs) for\nVehicular Ad Hoc Networks (VANETs) in the realistic setting of Rician fading\nchannels. In our LVSs, a single authorized Base Station (BS) equipped with\nmultiple antennas aims to detect a malicious vehicle that is spoofing its\nclaimed location. We first determine the optimal attack strategy of the\nmalicious vehicle, which in turn allows us to analyze the optimal LVS\nperformance as a function of the Rician $K$-factor of the channel between the\nBS and a legitimate vehicle. Our analysis also allows us to formally prove that\nthe LVS performance limit is independent of the properties of the channel\nbetween the BS and the malicious vehicle, provided the malicious vehicle's\nantenna number is above a specified value. We also investigate how tracking\ninformation on a vehicle quantitatively improves the detection performance of\nan LVS, showing how optimal performance is obtained under the assumption of the\ntracking length being randomly selected. The work presented here can be readily\nextended to multiple BS scenarios, and therefore forms the foundation for all\noptimal location authentication schemes within the context of Rician fading\nchannels. Our study closes important gaps in the current understanding of LVS\nperformance within the context of VANETs, and will be of practical value to\ncertificate revocation schemes within IEEE 1609.2. \n\n"}
{"id": "1412.5731", "contents": "Title: Optimizing User Association and Spectrum Allocation in HetNets: A\n  Utility Perspective Abstract: The joint user association and spectrum allocation problem is studied for\nmulti-tier heterogeneous networks (HetNets) in both downlink and uplink in the\ninterference-limited regime. Users are associated with base-stations (BSs)\nbased on the biased downlink received power. Spectrum is either shared or\northogonally partitioned among the tiers. This paper models the placement of\nBSs in different tiers as spatial point processes and adopts stochastic\ngeometry to derive the theoretical mean proportionally fair utility of the\nnetwork based on the coverage rate. By formulating and solving the network\nutility maximization problem, the optimal user association bias factors and\nspectrum partition ratios are analytically obtained for the multi-tier network.\nThe resulting analysis reveals that the downlink and uplink user associations\ndo not have to be symmetric. For uplink under spectrum sharing, if all tiers\nhave the same target signal-to-interference ratio (SIR), distance-based user\nassociation is shown to be optimal under a variety of path loss and power\ncontrol settings. For both downlink and uplink, under orthogonal spectrum\npartition, it is shown that the optimal proportion of spectrum allocated to\neach tier should match the proportion of users associated with that tier.\nSimulations validate the analytical results. Under typical system parameters,\nsimulation results suggest that spectrum partition performs better for downlink\nin terms of utility, while spectrum sharing performs better for uplink with\npower control. \n\n"}
{"id": "1412.6677", "contents": "Title: System Architecture and Key Technologies for 5G Heterogeneous Cloud\n  Radio Access Networks Abstract: Compared with the fourth generation (4G) cellular systems, the fifth\ngeneration wireless communication systems (5G) are anticipated to provide\nspectral and energy efficiency growth by a factor of at least 10, and the area\nthroughput growth by a factor of at least 25. To achieve these goals, a\nheterogeneous cloud radio access network (H-CRAN) is presented in this article\nas the advanced wireless access network paradigm, where cloud computing is used\nto fulfill the centralized large-scale cooperative processing for suppressing\nco-channel interferences. The state-of-the-art research achievements in aspects\nof system architecture and key technologies for H-CRANs are surveyed.\nParticularly, Node C as a new communication entity is defined to converge the\nexisting ancestral base stations and act as the base band unit (BBU) pool to\nmanage all accessed remote radio heads (RRHs), and the software-defined H-CRAN\nsystem architecture is presented to be compatible with software-defined\nnetworks (SDN). The principles, performance gains and open issues of key\ntechnologies including adaptive large-scale cooperative spatial signal\nprocessing, cooperative radio resource management, network function\nvirtualization, and self-organization are summarized. The major challenges in\nterms of fronthaul constrained resource allocation optimization and energy\nharvesting that may affect the promotion of H-CRANs are discussed as well. \n\n"}
{"id": "1412.6980", "contents": "Title: Adam: A Method for Stochastic Optimization Abstract: We introduce Adam, an algorithm for first-order gradient-based optimization\nof stochastic objective functions, based on adaptive estimates of lower-order\nmoments. The method is straightforward to implement, is computationally\nefficient, has little memory requirements, is invariant to diagonal rescaling\nof the gradients, and is well suited for problems that are large in terms of\ndata and/or parameters. The method is also appropriate for non-stationary\nobjectives and problems with very noisy and/or sparse gradients. The\nhyper-parameters have intuitive interpretations and typically require little\ntuning. Some connections to related algorithms, on which Adam was inspired, are\ndiscussed. We also analyze the theoretical convergence properties of the\nalgorithm and provide a regret bound on the convergence rate that is comparable\nto the best known results under the online convex optimization framework.\nEmpirical results demonstrate that Adam works well in practice and compares\nfavorably to other stochastic optimization methods. Finally, we discuss AdaMax,\na variant of Adam based on the infinity norm. \n\n"}
{"id": "1412.8375", "contents": "Title: Cross-Layer Scheduling for OFDMA-based Cognitive Radio Systems with\n  Delay and Security Constraints Abstract: This paper considers the resource allocation problem in an Orthogonal\nFrequency Division Multiple Access (OFDMA) based cognitive radio (CR) network,\nwhere the CR base station adopts full overlay scheme to transmit both private\nand open information to multiple users with average delay and power\nconstraints. A stochastic optimization problem is formulated to develop flow\ncontrol and radio resource allocation in order to maximize the long-term system\nthroughput of open and private information in CR system and ensure the\nstability of primary system. The corresponding optimal condition for employing\nfull overlay is derived in the context of concurrent transmission of open and\nprivate information. An online resource allocation scheme is designed to adapt\nthe transmission of open and private information based on monitoring the status\nof primary system as well as the channel and queue states in the CR network.\nThe scheme is proven to be asymptotically optimal in solving the stochastic\noptimization problem without knowing any statistical information. Simulations\nare provided to verify the analytical results and efficiency of the scheme. \n\n"}
{"id": "1412.8416", "contents": "Title: Joint Optimization of Radio and Computational Resources for Multicell\n  Mobile-Edge Computing Abstract: Migrating computational intensive tasks from mobile devices to more\nresourceful cloud servers is a promising technique to increase the\ncomputational capacity of mobile devices while saving their battery energy. In\nthis paper, we consider a MIMO multicell system where multiple mobile users\n(MUs) ask for computation offloading to a common cloud server. We formulate the\noffloading problem as the joint optimization of the radio resources-the\ntransmit precoding matrices of the MUs-and the computational resources-the CPU\ncycles/second assigned by the cloud to each MU-in order to minimize the overall\nusers' energy consumption, while meeting latency constraints. The resulting\noptimization problem is nonconvex (in the objective function and constraints).\nNevertheless, in the single-user case, we are able to express the global\noptimal solution in closed form. In the more challenging multiuser scenario, we\npropose an iterative algorithm, based on a novel successive convex\napproximation technique, converging to a local optimal solution of the original\nnonconvex problem. Then, we reformulate the algorithm in a distributed and\nparallel implementation across the radio access points, requiring only a\nlimited coordination/signaling with the cloud. Numerical results show that the\nproposed schemes outperform disjoint optimization algorithms. \n\n"}
{"id": "1412.8708", "contents": "Title: Full Duplex Operation for Small Cells Abstract: Full duplex (FD) communications has the potential to double the capacity of a\nhalf duplex (HD) system at the link level. However, FD operation increases the\naggregate interference on each communication link, which limits the capacity\nimprovement. In this paper, we investigate how much of the potential doubling\ncan be practically achieved in the resource-managed, small multi-cellular\nsystem, similar to the TDD variant of LTE, both in indoor and outdoor\nenvironments, assuming FD base stations (BSs) and HD user equipment (UEs). We\nfocus on low-powered small cellular systems, because they are more suitable for\nFD operation given practical self-interference cancellation limits. A joint UE\nselection and power allocation method for a multi-cell scenario is presented,\nwhere a hybrid scheduling policy assigns FD timeslots when it provides a\nthroughput advantage by pairing UEs with appropriate power levels to mitigate\nthe mutual interference, but otherwise defaults to HD operation. Due to the\ncomplexity of finding the globally optimum solution of the proposed algorithm,\na sub-optimal method based on a heuristic greedy algorithm for UE selection,\nand a novel solution using geometric programming for power allocation, is\nproposed. With practical self-interference cancellation, antennas and circuits,\nit is shown that the proposed hybrid FD system achieves as much as 94%\nthroughput improvement in the downlink, and 92% in the uplink, compared to a HD\nsystem in an indoor multi-cell scenario and 54% in downlink and 61% in uplink\nin an outdoor multi-cell scenario. Further, we also compare the energy\nefficiency of FD operation. \n\n"}
{"id": "1501.00078", "contents": "Title: Joint Downlink Cell Association and Bandwidth Allocation for Wireless\n  Backhauling in Two-Tier HetNets with Large-Scale Antenna Arrays Abstract: The problem of joint downlink cell association (CA) and wireless backhaul\nbandwidth allocation (WBBA) in two-tier cellular heterogeneous networks\n(HetNets) is considered. Large-scale antenna array is implemented at the macro\nbase station (BS), while the small cells within the macro cell range are\nsingle-antenna BSs and they rely on over-the-air links to the macro BS for\nbackhauling. A sum logarithmic user rate maximization problem is investigated\nconsidering wireless backhauling constraints. A duplex and spectrum sharing\nscheme based on co-channel reverse time-division duplex (TDD) and dynamic soft\nfrequency reuse (SFR) is proposed for interference management in two-tier\nHetNets with large-scale antenna arrays at the macro BS and wireless\nbackhauling for small cells. Two in-band WBBA scenarios, namely, unified\nbandwidth allocation and per-small-cell bandwidth allocation scenarios, are\ninvestigated for joint CA-WBBA in the HetNet. A two-level hierarchical\ndecomposition method for relaxed optimization is employed to solve the\nmixed-integer nonlinear program (MINLP). Solutions based on the General\nAlgorithm Modeling System (GAMS) optimization solver and fast heuristics are\nalso proposed for cell association in the per-small-cell WBBA scenario. It is\nshown that when all small cells have to use in-band wireless backhaul, the\nsystem load has more impact on both the sum log-rate and per-user rate\nperformance than the number of small cells deployed within the macro cell\nrange. The proposed joint CA-WBBA algorithms have an optimal load approximately\nequal to the size of the large-scale antenna array at the macro BS. The cell\nrange expansion (CRE) strategy, which is an efficient cell association scheme\nfor HetNets with perfect backhauling, is shown to be inefficient when in-band\nwireless backhauling for small cells comes into play. \n\n"}
{"id": "1501.02419", "contents": "Title: Delay Minimizing User Association in Cellular Networks via\n  Hierarchically Well-Separated Trees Abstract: We study downlink delay minimization within the context of cellular user\nassociation policies that map mobile users to base stations. We note the delay\nminimum user association problem fits within a broader class of network utility\nmaximization and can be posed as a non-convex quadratic program. This\nnon-convexity motivates a split quadratic objective function that captures the\noriginal problem's inherent tradeoff: association with a station that provides\nthe highest signal-to-interference-plus-noise ratio (SINR) vs. a station that\nis least congested. We find the split-term formulation is amenable to\nlinearization by embedding the base stations in a hierarchically well-separated\ntree (HST), which offers a linear approximation with constant distortion. We\nprovide a numerical comparison of several problem formulations and find that\nwith appropriate optimization parameter selection, the quadratic reformulation\nproduces association policies with sum delays that are close to that of the\noriginal network utility maximization. We also comment on the more difficult\nproblem when idle base stations (those without associated users) are\ndeactivated. \n\n"}
{"id": "1501.04328", "contents": "Title: Exploiting Network Awareness to Enhance DASH Over Wireless Abstract: The introduction of Dynamic Adaptive Streaming over HTTP (DASH) helped reduce\nthe consumption of resource in video delivery, but its client-based rate\nadaptation is unable to optimally use the available end-to-end network\nbandwidth. We consider the problem of optimizing the delivery of video content\nto mobile clients while meeting the constraints imposed by the available\nnetwork resources. Observing the bandwidth available in the network's two main\ncomponents, core network, transferring the video from the servers to edge nodes\nclose to the client, and the edge network, which is in charge of transferring\nthe content to the user, via wireless links, we aim to find an optimal solution\nby exploiting the predictability of future user requests of sequential video\nsegments, as well as the knowledge of available infrastructural resources at\nthe core and edge wireless networks in a given future time window. Instead of\nregarding the bottleneck of the end-to-end connection as our throughput, we\ndistribute the traffic load over time and use intermediate nodes between the\nserver and the client for buffering video content to achieve higher throughput,\nand ultimately significantly improve the Quality of Experience for the end user\nin comparison with current solutions. \n\n"}
{"id": "1501.07586", "contents": "Title: FAIR: Forwarding Accountability for Internet Reputability Abstract: This paper presents FAIR, a forwarding accountability mechanism that\nincentivizes ISPs to apply stricter security policies to their customers. The\nAutonomous System (AS) of the receiver specifies a traffic profile that the\nsender AS must adhere to. Transit ASes on the path mark packets. In case of\ntraffic profile violations, the marked packets are used as a proof of\nmisbehavior.\n  FAIR introduces low bandwidth overhead and requires no per-packet and no\nper-flow state for forwarding. We describe integration with IP and demonstrate\na software switch running on commodity hardware that can switch packets at a\nline rate of 120 Gbps, and can forward 140M minimum-sized packets per second,\nlimited by the hardware I/O subsystem.\n  Moreover, this paper proposes a \"suspicious bit\" for packet headers - an\napplication that builds on top of FAIR's proofs of misbehavior and flags\npackets to warn other entities in the network. \n\n"}
{"id": "1502.01222", "contents": "Title: Is There WiFi Yet? How Aggressive WiFi Probe Requests Deteriorate Energy\n  and Throughput Abstract: WiFi offloading has emerged as a key component of cellular operator strategy\nto meet the data needs of rich, mobile devices. As such, mobile devices tend to\naggressively seek out WiFi in order to provide improved user Quality of\nExperience (QoE) and cellular capacity relief. For home and work environments,\naggressive WiFi scans can significantly improve the speed on which mobile nodes\njoin the WiFi network. Unfortunately, the same aggressive behavior that excels\nin the home environment incurs considerable side effects across crowded\nwireless environments. In this paper, we show through empirical studies at both\nlarge (stadium) and small (laboratory) scales how aggressive WiFi scans can\nhave significant implications for energy and throughput, both for the mobile\nnodes scanning and other nearby mobile nodes. We close with several thoughts on\nthe disjoint incentives for properly balancing WiFi discovery speed and\nultra-dense network interactions. \n\n"}
{"id": "1502.02111", "contents": "Title: Exploiting the power of multiplicity: a holistic survey of network-layer\n  multipath Abstract: The Internet is inherently a multipath network---for an underlying network\nwith only a single path connecting various nodes would have been debilitatingly\nfragile. Unfortunately, traditional Internet technologies have been designed\naround the restrictive assumption of a single working path between a source and\na destination. The lack of native multipath support constrains network\nperformance even as the underlying network is richly connected and has\nredundant multiple paths. Computer networks can exploit the power of\nmultiplicity to unlock the inherent redundancy of the Internet. This opens up a\nnew vista of opportunities promising increased throughput (through concurrent\nusage of multiple paths) and increased reliability and fault-tolerance (through\nthe use of multiple paths in backup/ redundant arrangements). There are many\nemerging trends in networking that signify that the Internet's future will be\nunmistakably multipath, including the use of multipath technology in datacenter\ncomputing; multi-interface, multi-channel, and multi-antenna trends in\nwireless; ubiquity of mobile devices that are multi-homed with heterogeneous\naccess networks; and the development and standardization of multipath transport\nprotocols such as MP-TCP.\n  The aim of this paper is to provide a comprehensive survey of the literature\non network-layer multipath solutions. We will present a detailed investigation\nof two important design issues, namely the control plane problem of how to\ncompute and select the routes, and the data plane problem of how to split the\nflow on the computed paths. The main contribution of this paper is a systematic\narticulation of the main design issues in network-layer multipath routing along\nwith a broad-ranging survey of the vast literature on network-layer\nmultipathing. We also highlight open issues and identify directions for future\nwork. \n\n"}
{"id": "1502.02943", "contents": "Title: A Control-Theoretic Approach to Adaptive Video Streaming in Dense\n  Wireless Networks Abstract: Recently, the way people consume video content has been undergoing a dramatic\nchange. Plain TV sets, that have been the center of home entertainment for a\nlong time, are losing grounds to Hybrid TV's, PC's, game consoles, and, more\nrecently, mobile devices such as tablets and smartphones. The new predominant\nparadigm is: watch what I want, when I want, and where I want.\n  The challenges of this shift are manifold. On the one hand, broadcast\ntechnologies such as DVB-T/C/S need to be extended or replaced by mechanisms\nsupporting asynchronous viewing, such as IPTV and video streaming over\nbest-effort networks, while remaining scalable to millions of users. On the\nother hand, the dramatic increase of wireless data traffic begins to stretch\nthe capabilities of the existing wireless infrastructure to its limits.\nFinally, there is a challenge to video streaming technologies to cope with a\nhigh heterogeneity of end-user devices and dynamically changing network\nconditions, in particular in wireless and mobile networks.\n  In the present work, our goal is to design an efficient system that supports\na high number of unicast streaming sessions in a dense wireless access network.\nWe address this goal by jointly considering the two problems of wireless\ntransmission scheduling and video quality adaptation, using techniques inspired\nby the robustness and simplicity of Proportional-Integral-Derivative (PID)\ncontrollers. We show that the control-theoretic approach allows to efficiently\nutilize available wireless resources, providing high Quality of Experience\n(QoE) to a large number of users. \n\n"}
{"id": "1502.06899", "contents": "Title: Towards a Tractable Analysis of Localization Fundamentals in Cellular\n  Networks Abstract: When dedicated positioning systems, such as GPS, are unavailable, a mobile\ndevice has no choice but to fall back on its cellular network for localization.\nDue to random variations in the channel conditions to its surrounding base\nstations (BS), the mobile device is likely to face a mix of both favorable and\nunfavorable geometries for localization. Analytical studies of localization\nperformance (e.g., using the Cram\\'{e}r-Rao lower bound) usually require that\none fix the BS geometry, and favorable geometries have always been the\npreferred choice in the literature. However, not only are the resulting\nanalytical results constrained to the selected geometry, this practice is\nlikely to lead to overly-optimistic expectations of typical localization\nperformance. Ideally, localization performance should be studied across all\npossible geometric setups, thereby also removing any selection bias. This,\nhowever, is known to be hard and has been carried out only in simulation. In\nthis paper, we develop a new tractable approach where we endow the BS locations\nwith a distribution by modeling them as a Poisson point process (PPP), and use\ntools from stochastic geometry to obtain easy-to-use expressions for key\nperformance metrics. In particular, we focus on the probability of detecting\nsome minimum number of BSs, which is shown to be closely coupled with a network\noperator's ability to obtain satisfactory localization performance (e.g., meet\nFCC E911 requirements). This metric is indifferent to the localization\ntechnique (e.g., TOA, TDOA, AOA, or hybrids thereof), though different\ntechniques will presumably lead to different BS hearability requirements. In\norder to mitigate excessive interference due to the presence of dominant\ninterferers in the form of other BSs, we incorporate both BS coordination and\nfrequency reuse in the proposed framework and quantify the resulting\nperformance gains analytically. \n\n"}
{"id": "1503.00267", "contents": "Title: Distributed Cloud Association in Downlink Multicloud Radio Access\n  Networks Abstract: This paper considers a multicloud radio access network (M-CRAN), wherein each\ncloud serves a cluster of base-stations (BS's) which are connected to the\nclouds through high capacity digital links. The network comprises several\nremote users, where each user can be connected to one (and only one) cloud.\nThis paper studies the user-to-cloud-assignment problem by maximizing a\nnetwork-wide utility subject to practical cloud connectivity constraints. The\npaper solves the problem by using an auction-based iterative algorithm, which\ncan be implemented in a distributed fashion through a reasonable exchange of\ninformation between the clouds. The paper further proposes a centralized\nheuristic algorithm, with low computational complexity. Simulations results\nshow that the proposed algorithms provide appreciable performance improvements\nas compared to the conventional cloud-less assignment solutions. \n\n"}
{"id": "1503.02332", "contents": "Title: Robust Anomaly Detection in Dynamic Networks Abstract: We propose two robust methods for anomaly detection in dynamic networks in\nwhich the properties of normal traffic are time-varying. We formulate the\nrobust anomaly detection problem as a binary composite hypothesis testing\nproblem and propose two methods: a model-free and a model-based one, leveraging\ntechniques from the theory of large deviations. Both methods require a family\nof Probability Laws (PLs) that represent normal properties of traffic. We\ndevise a two-step procedure to estimate this family of PLs. We compare the\nperformance of our robust methods and their vanilla counterparts, which assume\nthat normal traffic is stationary, on a network with a diurnal normal pattern\nand a common anomaly related to data exfiltration. Simulation results show that\nour robust methods perform better than their vanilla counterparts in dynamic\nnetworks. \n\n"}
{"id": "1503.02735", "contents": "Title: Dynamic Service Placement for Mobile Micro-Clouds with Predicted Future\n  Costs Abstract: Mobile micro-clouds are promising for enabling performance-critical cloud\napplications. However, one challenge therein is the dynamics at the network\nedge. In this paper, we study how to place service instances to cope with these\ndynamics, where multiple users and service instances coexist in the system. Our\ngoal is to find the optimal placement (configuration) of instances to minimize\nthe average cost over time, leveraging the ability of predicting future cost\nparameters with known accuracy. We first propose an offline algorithm that\nsolves for the optimal configuration in a specific look-ahead time-window.\nThen, we propose an online approximation algorithm with polynomial\ntime-complexity to find the placement in real-time whenever an instance\narrives. We analytically show that the online algorithm is $O(1)$-competitive\nfor a broad family of cost functions. Afterwards, the impact of prediction\nerrors is considered and a method for finding the optimal look-ahead window\nsize is proposed, which minimizes an upper bound of the average actual cost.\nThe effectiveness of the proposed approach is evaluated by simulations with\nboth synthetic and real-world (San Francisco taxi) user-mobility traces. The\ntheoretical methodology used in this paper can potentially be applied to a\nlarger class of dynamic resource allocation problems. \n\n"}
{"id": "1503.02955", "contents": "Title: Low-Delay Adaptive Video Streaming Based on Short-Term TCP Throughput\n  Prediction Abstract: Recently, HTTP-Based Adaptive Streaming has become the de facto standard for\nvideo streaming over the Internet. It allows the client to adapt media\ncharacteristics to varying network conditions in order to maximize Quality of\nExperience (QoE). In the case of live streaming this task becomes particularly\nchallenging. An important factor than might help improving performance is the\ncapability to correctly predict network throughput dynamics on short to medium\ntimescales. It becomes notably difficult in wireless networks that are often\nsubject to continuous throughput fluctuations.\n  In the present work, we develop an adaptation algorithm for HTTP-Based\nAdaptive Live Streaming that, for each adaptation decision, maximizes a\nQoE-based utility function depending on the probability of playback\ninterruptions, average video quality, and the amount of video quality\nfluctuations. To compute the utility function the algorithm leverages\nthroughput predictions, and dynamically estimated prediction accuracy.\n  We are trying to close the gap created by the lack of studies analyzing TCP\nthroughput on short to medium timescales. We study several time series\nprediction methods and their error distributions. We observe that Simple Moving\nAverage performs best in most cases. We also observe that the relative\nunderestimation error is best represented by a truncated normal distribution,\nwhile the relative overestimation error is best represented by a Lomax\ndistribution. Moreover, underestimations and overestimations exhibit a temporal\ncorrelation that we use to further improve prediction accuracy.\n  We compare the proposed algorithm with a baseline approach that uses a fixed\nmargin between past throughput and selected media bit rate, and an oracle-based\napproach that has perfect knowledge over future throughput for a certain time\nhorizon. \n\n"}
{"id": "1503.04030", "contents": "Title: Totally Distributed Energy-Efficient Transmission in MIMO Interference\n  Channels Abstract: In this paper, we consider the problem of maximizing the energy efficiency\n(EE) for multi-input multi-output (MIMO) interference channels, subject to the\nper-link power constraint. To avoid extensive information exchange among all\nlinks, the optimization problem is formulated as a noncooperative game, where\neach link maximizes its own EE. We show that this game always admits a Nash\nequilibrium (NE) and the sufficient condition for the uniqueness of the NE is\nderived for the case of arbitrary channel matrices, which can be checked in\npractice. To reach the NE of this game, we develop a totally distributed EE\nalgorithm, in which each link updates its own transmit covariance matrix in a\ncompletely distributed and asynchronous way: Some players may update their\nsolutions more frequently than others or even use the outdated interference\ninformation. The sufficient conditions that guarantee the global convergence of\nthe proposed algorithm to the NE of the game have been given as well. We also\nstudy the impact of the circuit power consumption on the sum-EE performance of\nthe proposed algorithm in the case when the links are separated sufficiently\nfar away. Moreover, the tradeoff between the sum-EE and the sum-spectral\nefficiency (SE) is investigated with the proposed algorithm under two special\ncases: 1) low transmit power constraint regime; 2) high transmit power\nconstraint regime. Finally, extensive simulations are conducted to evaluate the\nimpact of various system parameters on the system performance. \n\n"}
{"id": "1503.05448", "contents": "Title: A Transfer Learning Approach for Cache-Enabled Wireless Networks Abstract: Locally caching contents at the network edge constitutes one of the most\ndisruptive approaches in $5$G wireless networks. Reaping the benefits of edge\ncaching hinges on solving a myriad of challenges such as how, what and when to\nstrategically cache contents subject to storage constraints, traffic load,\nunknown spatio-temporal traffic demands and data sparsity. Motivated by this,\nwe propose a novel transfer learning-based caching procedure carried out at\neach small cell base station. This is done by exploiting the rich contextual\ninformation (i.e., users' content viewing history, social ties, etc.) extracted\nfrom device-to-device (D2D) interactions, referred to as source domain. This\nprior information is incorporated in the so-called target domain where the goal\nis to optimally cache strategic contents at the small cells as a function of\nstorage, estimated content popularity, traffic load and backhaul capacity. It\nis shown that the proposed approach overcomes the notorious data sparsity and\ncold-start problems, yielding significant gains in terms of users'\nquality-of-experience (QoE) and backhaul offloading, with gains reaching up to\n$22\\%$ in a setting consisting of four small cell base stations. \n\n"}
{"id": "1504.00832", "contents": "Title: Set Covering-based Approximation Algorithm for Delay Constrained Relay\n  Node Placement in Wireless Sensor Networks Abstract: The Delay Constrained Relay Node Placement (DCRNP) problem in Wireless Sensor\nNetworks (WSNs) aims to deploy minimum relay nodes such that for each sensor\nnode there is a path connecting this sensor node to the sink without violating\ndelay constraint. As WSNs are gradually employed in time-critical applications,\nthe importance of the DCRNP problem becomes noticeable. For the NP-hard nature\nof DCRNP problem, an approximation algorithm-Set-Covering-based Relay Node\nPlacement (SCA) is proposed to solve the DCRNP problem in this paper. The\nproposed SCA algorithm deploys relay nodes iteratively from sink to the given\nsensor nodes in hops, i.e., in the $k$th iteration SCA deploys relay nodes at\nthe locations that are $k$ hops apart from the sink. Specifically, in each\niteration, SCA first finds the candidate deployment locations located within 1\nhop to the relay nodes and sensor nodes, which have already been connected to\nthe sink. Then, a subset of these candidate deployment locations, which can\nguarantee the existence of paths connecting unconnected sensor nodes to the\nsink within delay constraint, is selected to deploy relay nodes based on the\nset covering method. As the iteration of SCA algorithm, the sensor nodes are\ngradually connected to the sink with satisfying delay constraint.\n  The elaborated analysis of the approximation ratio of SCA algorithm is given\nout, and we also prove that the SCA is a polynomial time algorithm through\nrigorous time complexity analysis. To evaluate the performance of the proposed\nSCA algorithm, extensive simulations are implemented, and the simulation\nresults show that the SCA algorithm can significantly save the deployed relay\nnodes comparing to the existing algorithms, i.e., at most 31.48% deployed relay\nnodes can be saved due to SCA algorithm. \n\n"}
{"id": "1504.01185", "contents": "Title: Byzantine Attack and Defense in Cognitive Radio Networks: A Survey Abstract: The Byzantine attack in cooperative spectrum sensing (CSS), also known as the\nspectrum sensing data falsification (SSDF) attack in the literature, is one of\nthe key adversaries to the success of cognitive radio networks (CRNs). In the\npast couple of years, the research on the Byzantine attack and defense\nstrategies has gained worldwide increasing attention. In this paper, we provide\na comprehensive survey and tutorial on the recent advances in the Byzantine\nattack and defense for CSS in CRNs. Specifically, we first briefly present the\npreliminaries of CSS for general readers, including signal detection\ntechniques, hypothesis testing, and data fusion. Second, we analyze the spear\nand shield relation between Byzantine attack and defense from three aspects:\nthe vulnerability of CSS to attack, the obstacles in CSS to defense, and the\ngames between attack and defense. Then, we propose a taxonomy of the existing\nByzantine attack behaviors and elaborate on the corresponding attack\nparameters, which determine where, who, how, and when to launch attacks. Next,\nfrom the perspectives of homogeneous or heterogeneous scenarios, we classify\nthe existing defense algorithms, and provide an in-depth tutorial on the\nstate-of-the-art Byzantine defense schemes, commonly known as robust or secure\nCSS in the literature. Furthermore, we highlight the unsolved research\nchallenges and depict the future research directions. \n\n"}
{"id": "1504.01452", "contents": "Title: The Performance Analysis of Coded Cache in Wireless Fading Channel Abstract: The rapid growth of data volume and the accompanying congestion problems over\nthe wireless networks have been critical issues to content providers. A novel\ntechnique, termed as coded cache, is proposed to relieve the burden. Through\ncreating coded-multicasting opportunities, the coded-cache scheme can provide\nextra performance gain over the conventional push technique that simply\npre-stores contents at local caches during the network idle period. But\nexisting works on the coded caching scheme assumed the availability of an\nerror-free shared channel accessible by each user. This paper considers the\nmore realistic scenario where each user may experience different link quality.\nIn this case, the system performance would be restricted by the user with the\nworst channel condition. And the corresponding resource allocation schemes\naimed at breaking this obstacles are developed. Specifically, we employ the\ncoded caching scheme in time division and frequency division transmission mode\nand formulate the sub-optimal problems. Power and bandwidth are allocated\nrespectively to maximum the system throughput. The simulation results show that\nthe throughput of the technique in wireless scenario will be limited and would\ndecrease as the number of users becomes sufficiently large. \n\n"}
{"id": "1504.01809", "contents": "Title: Multi-Block ADMM for Big Data Optimization in Modern Communication\n  Networks Abstract: In this paper, we review the parallel and distributed optimization algorithms\nbased on the alternating direction method of multipliers (ADMM) for solving\n\"big data\" optimization problems in modern communication networks. We first\nintroduce the canonical formulation of the large-scale optimization problem.\nNext, we describe the general form of ADMM and then focus on several direct\nextensions and sophisticated modifications of ADMM from $2$-block to $N$-block\nsettings to deal with the optimization problem. The iterative schemes and\nconvergence properties of each extension/modification are given, and the\nimplementation on large-scale computing facilities is also illustrated.\nFinally, we numerate several applications in communication networks, such as\nthe security constrained optimal power flow problem in smart grid networks and\nmobile data offloading problem in software defined networks (SDNs). \n\n"}
{"id": "1504.01873", "contents": "Title: Location, location, location: Border effects in interference limited ad\n  hoc networks Abstract: Wireless networks are fundamentally limited by the intensity of the received\nsignals and by their inherent interference. It is shown here that in finite ad\nhoc networks where node placement is modelled according to a Poisson point\nprocess and no carrier sensing is employed for medium access, the SINR received\nby nodes located at the border of the network deployment/operation region is on\naverage greater than the rest. This is primarily due to the uneven interference\nlandscape of such networks which is particularly kind to border nodes giving\nrise to all sorts of performance inhomogeneities and access unfairness. Using\ntools from stochastic geometry we quantify these spatial variations and provide\nclosed form communication-theoretic results showing why the receiver's location\nis so important. \n\n"}
{"id": "1504.02346", "contents": "Title: Optimal User Association for Massive MIMO Empowered Ultra-Dense Wireless\n  Networks Abstract: Ultra network densification and Massive MIMO are considered major 5G enablers\nsince they promise huge capacity gains by exploiting proximity, spectral and\nspatial reuse benefits. Both approaches rely on increasing the number of access\nelements per user, either through deploying more access nodes over an area or\nincreasing the number of antenna elements per access node. At the\nnetwork-level, optimal user-association for a densely and randomly deployed\nnetwork of Massive MIMO empowered access nodes must account for both channel\nand load conditions. In this paper we formulate this complex problem, report\nits computationally intractability and reformulate it to a plausible form,\namenable to acquire a global optimal solution with reasonable complexity. We\napply the proposed optimization model to typical ultra-dense outdoor small-cell\nsetups and demonstrate: (i) the significant impact of optimal user-association\nto the achieved rate levels compared to a baseline strategy, and (ii) the\noptimality of alternative network access element deployment strategies. \n\n"}
{"id": "1504.03754", "contents": "Title: Throughput and Delay Scaling of Content-Centric Ad Hoc and Heterogeneous\n  Wireless Networks Abstract: We study the throughput and delay characteristics of wireless caching\nnetworks, where users are mainly interested in retrieving content stored in the\nnetwork, rather than in maintaining source-destination communication. Nodes are\nassumed to be uniformly distributed in the network area. Each node has a\nlimited-capacity content store, which it uses to cache contents. We propose an\nachievable caching and transmission scheme whereby requesters retrieve content\nfrom the caching point which is closest in Euclidean distance. We establish the\nthroughput and delay scaling of the achievable scheme, and show that the\nthroughput and delay performance are order-optimal within a class of schemes.\nWe then solve the caching optimization problem, and evaluate the network\nperformance for a Zipf content popularity distribution, letting the number of\ncontent types and the network size both go to infinity. Finally, we extend our\nanalysis to heterogeneous wireless networks where, in addition to wireless\nnodes, there are a number of base stations uniformly distributed at random in\nthe network area. We show that in order to achieve a better performance in a\nheterogeneous network in the order sense, the number of base stations needs to\nbe greater than the ratio of the number of nodes to the number of content\ntypes. Furthermore, we show that the heterogeneous network does not yield\nperformance advantages in the order sense if the Zipf content popularity\ndistribution exponent exceeds 3/2. \n\n"}
{"id": "1504.04076", "contents": "Title: End-to-End Service Delivery with QoS Guarantee in Software Defined\n  Networks Abstract: Software-Defined Network (SDN) is expected to have a significant impact on\nfuture networking. Although exciting progress has been made toward realizing\nSDN, application of this new networking paradigm in the future Internet to\nsupport end-to-end QoS provisioning faces some new challenges. The autonomous\nnetwork domains coexisting in the Internet and the diverse user applications\ndeployed upon the Internet call for a uniform Service Delivery Platform (SDP)\nthat enables high-level network abstraction and inter-domain collaboration for\nend-to-end service provisioning. However, the currently available SDN\ntechnologies lack effective mechanisms for supporting such a platform. In this\npaper, we first present a SDP framework that applies the Network-as-a-Service\n(NaaS) principle to provide network abstraction and orchestration for\nend-to-end service provisioning in SDN-based future Internet. Then we focus our\nstudy on two enabling technologies for such a SDP to achieve QoS guarantee;\nnamely a network abstraction model and an end-to-end resource allocation\nscheme. Specifically we propose a general model for abstracting the service\ncapabilities offered by network domains and develop a technique for determining\nthe required amounts of bandwidth in network domains for end-to-end service\ndelivery with QoS guarantee. Both the analytical and numerical results obtained\nin this paper indicate that the NaaS-based SDP not only simplifies SDN service\nand resource management but also enhances bandwidth utilization for end-to-end\nQoS provisioning. \n\n"}
{"id": "1504.06316", "contents": "Title: Interactive Communication with Unknown Noise Rate Abstract: Alice and Bob want to run a protocol over a noisy channel, where a certain\nnumber of bits are flipped adversarially. Several results take a protocol\nrequiring $L$ bits of noise-free communication and make it robust over such a\nchannel. In a recent breakthrough result, Haeupler described an algorithm that\nsends a number of bits that is conjectured to be near optimal in such a model.\nHowever, his algorithm critically requires $a \\ priori$ knowledge of the number\nof bits that will be flipped by the adversary.\n  We describe an algorithm requiring no such knowledge. If an adversary flips\n$T$ bits, our algorithm sends $L + O\\left(\\sqrt{L(T+1)\\log L} + T\\right)$ bits\nin expectation and succeeds with high probability in $L$. It does so without\nany $a \\ priori$ knowledge of $T$. Assuming a conjectured lower bound by\nHaeupler, our result is optimal up to logarithmic factors.\n  Our algorithm critically relies on the assumption of a private channel. We\nshow that privacy is necessary when the amount of noise is unknown. \n\n"}
{"id": "1504.07566", "contents": "Title: Designing Wireless Broadband Access for Energy Efficiency: Are Small\n  Cells the Only Answer? Abstract: The main usage of cellular networks has changed from voice to data traffic,\nmostly requested by static users. In this paper, we analyze how a cellular\nnetwork should be designed to provide such wireless broadband access with\nmaximal energy efficiency (EE). Using stochastic geometry and a detailed power\nconsumption model, we optimize the density of access points (APs), number of\nantennas and users per AP, and transmission power for maximal EE. Small cells\nare of course a key technology in this direction, but the analysis shows that\nthe EE improvement of a small-cell network saturates quickly with the AP\ndensity and then \"massive MIMO\" techniques can further improve the EE. \n\n"}
{"id": "1505.01920", "contents": "Title: Will the Area Spectral Efficiency Monotonically Grow as Small Cells Go\n  Dense? Abstract: In this paper, we introduce a sophisticated path loss model into the\nstochastic geometry analysis incorporating both line-of-sight (LoS) and\nnon-line-of-sight (NLoS) transmissions to study their performance impact in\nsmall cell networks (SCNs). Analytical results are obtained on the coverage\nprobability and the area spectral efficiency (ASE) assuming both a general path\nloss model and a special case of path loss model recommended by the 3rd\nGeneration Partnership Project (3GPP) standards. The performance impact of LoS\nand NLoS transmissions in SCNs in terms of the coverage probability and the ASE\nis shown to be significant both quantitatively and qualitatively, compared with\nprevious work that does not differentiate LoS and NLoS transmissions.\nParticularly, our analysis demonstrates that when the density of small cells is\nlarger than a threshold, the network coverage probability will decrease as\nsmall cells become denser, which in turn makes the ASE suffer from a slow\ngrowth or even a notable decrease. For practical regime of small cell density,\nthe performance results derived from our analysis are distinctively different\nfrom previous results, and shed new insights on the design and deployment of\nfuture dense/ultra-dense SCNs. \n\n"}
{"id": "1505.03446", "contents": "Title: Sub-Nanosecond Time of Flight on Commercial Wi-Fi Cards Abstract: Time-of-flight, i.e., the time incurred by a signal to travel from\ntransmitter to receiver, is perhaps the most intuitive way to measure distances\nusing wireless signals. It is used in major positioning systems such as GPS,\nRADAR, and SONAR. However, attempts at using time-of-flight for indoor\nlocalization have failed to deliver acceptable accuracy due to fundamental\nlimitations in measuring time on Wi-Fi and other RF consumer technologies.\nWhile the research community has developed alternatives for RF-based indoor\nlocalization that do not require time-of-flight, those approaches have their\nown limitations that hamper their use in practice. In particular, many existing\napproaches need receivers with large antenna arrays while commercial Wi-Fi\nnodes have two or three antennas. Other systems require fingerprinting the\nenvironment to create signal maps. More fundamentally, none of these methods\nsupport indoor positioning between a pair of Wi-Fi devices\nwithout~third~party~support.\n  In this paper, we present a set of algorithms that measure the time-of-flight\nto sub-nanosecond accuracy on commercial Wi-Fi cards. We implement these\nalgorithms and demonstrate a system that achieves accurate device-to-device\nlocalization, i.e. enables a pair of Wi-Fi devices to locate each other without\nany support from the infrastructure, not even the location of the access\npoints. \n\n"}
{"id": "1505.03460", "contents": "Title: Performance Analysis of Ambient RF Energy Harvesting with Repulsive\n  Point Process Modeling Abstract: Ambient RF (Radio Frequency) energy harvesting technique has recently been\nproposed as a potential solution to provide proactive energy replenishment for\nwireless devices. This paper aims to analyze the performance of a battery-free\nwireless sensor powered by ambient RF energy harvesting using a stochastic\ngeometry approach. Specifically, we consider the point-to-point uplink\ntransmission of a wireless sensor in a stochastic geometry network, where\nambient RF sources, such as mobile transmit devices, access points and base\nstations, are distributed as a Ginibre alpha-determinantal point process (DPP).\nThe DPP is able to capture repulsion among points, and hence, it is more\ngeneral than the Poisson point process (PPP). We analyze two common receiver\narchitectures: separated receiver and time-switching architectures. For each\narchitecture, we consider the scenarios with and without co-channel\ninterference for information transmission. We derive the expectation of the RF\nenergy harvesting rate in closed form and also compute its variance. Moreover,\nwe perform a worst-case study which derives the upper bound of both power and\ntransmission outage probabilities. Additionally, we provide guidelines on the\nsetting of optimal time-switching coefficient in the case of the time-switching\narchitecture. Numerical results verify the correctness of the analysis and show\nvarious tradeoffs between parameter setting. Lastly, we prove that the sensor\nis more efficient when the distribution of the ambient sources exhibits\nstronger repulsion. \n\n"}
{"id": "1505.05646", "contents": "Title: A mechanized proof of loop freedom of the (untimed) AODV routing\n  protocol Abstract: The Ad hoc On-demand Distance Vector (AODV) routing protocol allows the nodes\nin a Mobile Ad hoc Network (MANET) or a Wireless Mesh Network (WMN) to know\nwhere to forward data packets. Such a protocol is 'loop free' if it never leads\nto routing decisions that forward packets in circles. This paper describes the\nmechanization of an existing pen-and-paper proof of loop freedom of AODV in the\ninteractive theorem prover Isabelle/HOL. The mechanization relies on a novel\ncompositional approach for lifting invariants to networks of nodes. We exploit\nthe mechanization to analyse several improvements of AODV and show that\nIsabelle/HOL can re-establish most proof obligations automatically and identify\nexactly the steps that are no longer valid. \n\n"}
{"id": "1505.06856", "contents": "Title: WiFlix: Adaptive Video Streaming in Massive MU-MIMO Wireless Networks Abstract: We consider the problem of simultaneous on-demand streaming of stored video\nto multiple users in a multi-cell wireless network where multiple unicast\nstreaming sessions are run in parallel and share the same frequency band. Each\nstreaming session is formed by the sequential transmission of video \"chunks,\"\nsuch that each chunk arrives into the corresponding user playback buffer within\nits playback deadline. We formulate the problem as a Network Utility\nMaximization (NUM) where the objective is to fairly maximize users' video\nstreaming Quality of Experience (QoE) and then derive an iterative control\npolicy using Lyapunov Optimization, which solves the NUM problem up to any\nlevel of accuracy and yields an online protocol with control actions at every\niteration decomposing into two layers interconnected by the users' request\nqueues : i) a video streaming adaptation layer reminiscent of DASH, implemented\nat each user node; ii) a transmission scheduling layer where a max-weight\nscheduler is implemented at each base station. The proposed chunk request\nscheme is a pull strategy where every user opportunistically requests video\nchunks from the neighboring base stations and dynamically adapts the quality of\nits requests based on the current size of the request queue. For the\ntransmission scheduling component, we first describe the general max-weight\nscheduler and then particularize it to a wireless network where the base\nstations have multiuser MIMO (MU-MIMO) beamforming capabilities. We exploit the\nchannel hardening effect of large-dimensional MIMO channels (massive MIMO) and\ndevise a low complexity user selection scheme to solve the underlying\ncombinatorial problem of selecting user subsets for downlink beamforming, which\ncan be easily implemented and run independently at each base station. \n\n"}
{"id": "1506.06154", "contents": "Title: Network Coding Over SATCOM: Lessons Learned Abstract: Satellite networks provide unique challenges that can restrict users' quality\nof service. For example, high packet erasure rates and large latencies can\ncause significant disruptions to applications such as video streaming or\nvoice-over-IP. Network coding is one promising technique that has been shown to\nhelp improve performance, especially in these environments. However,\nimplementing any form of network code can be challenging. This paper will use\nan example of a generation-based network code and a sliding-window network code\nto help highlight the benefits and drawbacks of using one over the other.\nIn-order packet delivery delay, as well as network efficiency, will be used as\nmetrics to help differentiate between the two approaches. Furthermore, lessoned\nlearned during the course of our research will be provided in an attempt to\nhelp the reader understand when and where network coding provides its benefits. \n\n"}
{"id": "1506.06296", "contents": "Title: On Modeling Heterogeneous Wireless Networks Using Non-Poisson Point\n  Processes Abstract: Future wireless networks are required to support 1000 times higher data rate,\nthan the current LTE standard. In order to meet the ever increasing demand, it\nis inevitable that, future wireless networks will have to develop seamless\ninterconnection between multiple technologies. A manifestation of this idea is\nthe collaboration among different types of network tiers such as macro and\nsmall cells, leading to the so-called heterogeneous networks (HetNets).\nResearchers have used stochastic geometry to analyze such networks and\nunderstand their real potential. Unsurprisingly, it has been revealed that\ninterference has a detrimental effect on performance, especially if not modeled\nproperly. Interference can be correlated in space and/or time, which has been\noverlooked in the past. For instance, it is normally assumed that the nodes are\nlocated completely independent of each other and follow a homogeneous Poisson\npoint process (PPP), which is not necessarily true in real networks since the\nnode locations are spatially dependent. In addition, the interference\ncorrelation created by correlated stochastic processes has mostly been ignored.\nTo this end, we take a different approach in modeling the interference where we\nuse non-PPP, as well as we study the impact of spatial and temporal correlation\non the performance of HetNets. To illustrate the impact of correlation on\nperformance, we consider three case studies from real-life scenarios.\nSpecifically, we use massive multiple-input multiple-output (MIMO) to\nunderstand the impact of spatial correlation; we use the random medium access\nprotocol to examine the temporal correlation; and we use cooperative relay\nnetworks to illustrate the spatial-temporal correlation. We present several\nnumerical examples through which we demonstrate the impact of various\ncorrelation types on the performance of HetNets. \n\n"}
{"id": "1506.07275", "contents": "Title: Survey on Network Virtualization Hypervisors for Software Defined\n  Networking Abstract: Software defined networking (SDN) has emerged as a promising paradigm for\nmaking the control of communication networks flexible. SDN separates the data\npacket forwarding plane, i.e., the data plane, from the control plane and\nemploys a central controller. Network virtualization allows the flexible\nsharing of physical networking resources by multiple users (tenants). Each\ntenant runs its own applications over its virtual network, i.e., its slice of\nthe actual physical network. The virtualization of SDN networks promises to\nallow networks to leverage the combined benefits of SDN networking and network\nvirtualization and has therefore attracted significant research attention in\nrecent years. A critical component for virtualizing SDN networks is an SDN\nhypervisor that abstracts the underlying physical SDN network into multiple\nlogically isolated virtual SDN networks (vSDNs), each with its own controller.\nWe comprehensively survey hypervisors for SDN networks in this article. We\ncategorize the SDN hypervisors according to their architecture into centralized\nand distributed hypervisors. We furthermore sub-classify the hypervisors\naccording to their execution platform into hypervisors running exclusively on\ngeneral-purpose compute platforms, or on a combination of general-purpose\ncompute platforms with general- or special-purpose network elements. We\nexhaustively compare the network attribute abstraction and isolation features\nof the existing SDN hypervisors. As part of the future research agenda, we\noutline the development of a performance evaluation framework for SDN\nhypervisors. \n\n"}
{"id": "1506.07942", "contents": "Title: A Comprehensive Survey of Potential Game Approaches to Wireless Networks Abstract: Potential games form a class of non-cooperative games where unilateral\nimprovement dynamics are guaranteed to converge in many practical cases. The\npotential game approach has been applied to a wide range of wireless network\nproblems, particularly to a variety of channel assignment problems. In this\npaper, the properties of potential games are introduced, and games in wireless\nnetworks that have been proven to be potential games are comprehensively\ndiscussed. \n\n"}
{"id": "1507.00255", "contents": "Title: ReCon: Revealing and Controlling PII Leaks in Mobile Network Traffic Abstract: It is well known that apps running on mobile devices extensively track and\nleak users' personally identifiable information (PII); however, these users\nhave little visibility into PII leaked through the network traffic generated by\ntheir devices, and have poor control over how, when and where that traffic is\nsent and handled by third parties. In this paper, we present the design,\nimplementation, and evaluation of ReCon: a cross-platform system that reveals\nPII leaks and gives users control over them without requiring any special\nprivileges or custom OSes. ReCon leverages machine learning to reveal potential\nPII leaks by inspecting network traffic, and provides a visualization tool to\nempower users with the ability to control these leaks via blocking or\nsubstitution of PII. We evaluate ReCon's effectiveness with measurements from\ncontrolled experiments using leaks from the 100 most popular iOS, Android, and\nWindows Phone apps, and via an IRB-approved user study with 92 participants. We\nshow that ReCon is accurate, efficient, and identifies a wider range of PII\nthan previous approaches. \n\n"}
{"id": "1507.05664", "contents": "Title: Distributed Learning Algorithms for Spectrum Sharing in Spatial Random\n  Access Wireless Networks Abstract: We consider distributed optimization over orthogonal collision channels in\nspatial random access networks. Users are spatially distributed and each user\nis in the interference range of a few other users. Each user is allowed to\ntransmit over a subset of the shared channels with a certain attempt\nprobability. We study both the non-cooperative and cooperative settings. In the\nformer, the goal of each user is to maximize its own rate irrespective of the\nutilities of other users. In the latter, the goal is to achieve proportionally\nfair rates among users. Simple distributed learning algorithms are developed to\nsolve these problems. The efficiencies of the proposed algorithms are\ndemonstrated via both theoretical analysis and simulation results. \n\n"}
{"id": "1507.07141", "contents": "Title: A QoS-based Power Allocation for Cellular Users with Different\n  Modulations Abstract: In this paper, we propose a novel optimal power allocation method that\nfeatures a power limit function and is able to ensure more users reach the\ndesired Quality-of-Service (QoS). In our model we use sigmoidal-like utility\nfunctions to represent the probability of successful reception of packets at\nuser equipment (UE)s. Given that each UE has a different channel quality and\ndifferent location from base station (BS), it has different CQI and modulation.\nFor each CQI zone, we evaluate the power threshold which is required to achieve\nthe minimum QoS for each UE and show that the higher CQI the lower power\nthreshold is. We present a resource allocation algorithm that gives limited\nresources to UEs who have already reached their pre-specified minimum QoS, and\nprovides more possible resources to UEs who can not reach it. We also compare\nthis algorithm with the optimal power allocation algorithm in [1] to show the\nenhancement. \n\n"}
{"id": "1507.07159", "contents": "Title: Optimal Power Allocation for LTE Users with Different Modulations Abstract: In this paper, we demonstrate the optimal power allocation for QPSK, 16-QAM,\nand 64-QAM modulation schedules and the role of channel quality indicator\n(CQI). We used sigmoidal-like utility functions to represent the probability of\nsuccessful reception of packets at user equipment (UE). CQI as a feedback to\nthe base station (BS) indicates the data rate that a downlink channel can\nsupport. With Levenberg-Marquardt (LM) Optimization method, we present utility\nfunctions of different CQI values for standardized 15 Modulation order and\nCoding Scheme (MCS) in $3^{rd}$ Generation Partnership Project (3GPP). Finally,\nwe simulate and show the results of the optimal power allocation algorithm. \n\n"}
{"id": "1507.07161", "contents": "Title: An Optimal Resource Allocation with Frequency Reuse in Cellular Networks Abstract: In this paper, we introduce a novel approach for optimal resource allocation\nwith frequency reuse for users with elastic and inelastic traffic in cellular\nnetworks. In our model, we represent users' applications running on different\nuser equipments (UE)s by logarithmic and sigmoid utility functions. We applied\nutility proportional fairness allocation policy, i.e. the resources are\nallocated among users with fairness in utility percentage of the application\nrunning on each mobile station. Our objective is to allocate the cellular\nsystem resources to mobile users optimally from a multi-cell network. In our\nmodel, a minimum quality-of-service (QoS) is guaranteed to every user\nsubscribing for the mobile service with priority given to users with real-time\napplications. We show that the novel resource allocation optimization problem\nwith frequency reuse is convex and therefore the optimal solution is tractable.\nWe present a distributed algorithm to allocate the resources optimally from\nMobility Management Entity (MME) to base stations (BS)s sectors. Finally, we\npresent the simulation results for the performance of our rate allocation\nalgorithm. \n\n"}
{"id": "1507.08499", "contents": "Title: Low Delay Random Linear Coding and Scheduling Over Multiple Interfaces Abstract: Multipath transport protocols like MPTCP transfer data across multiple routes\nin parallel and deliver it in order at the receiver. When the delay on one or\nmore of the paths is variable, as is commonly the case, out of order arrivals\nare frequent and head of line blocking leads to high latency. This is\nexacerbated when packet loss, which is also common with wireless links, is\ntackled using ARQ. This paper introduces Stochastic Earliest Delivery Path\nFirst (S-EDPF), a resilient low delay packet scheduler for multipath transport\nprotocols. S-EDPF takes explicit account of the stochastic nature of paths and\nuses this to minimise in-order delivery delay. S-EDPF also takes account of\nFEC, jointly scheduling transmission of information and coded packets and in\nthis way allows lossy links to reduce delay and improve resiliency, rather than\ndegrading performance as usually occurs with existing multipath systems. We\nimplement S-EDPF as a multi-platform application that does not require\nadministration privileges nor modifications to the operating system and has\nnegligible impact on energy consumption. We present a thorough experimental\nevaluation in both controlled environments and into the wild, revealing\ndramatic gains in delay performance compared to existing approaches. \n\n"}
{"id": "1507.08834", "contents": "Title: Response-Time-Optimised Service Deployment: MILP Formulations of\n  Piece-wise Linear Functions Approximating Non-linear Bivariate Mixed-integer\n  Functions Abstract: A current trend in networking and cloud computing is to provide compute\nresources at widely dispersed places; this is exemplified by developments such\nas Network Function Virtualisation. This paves the way for wide-area service\ndeployments with improved service quality: e.g, a nearby server can reduce the\nuser-perceived response times. But always using the nearest server can be a bad\ndecision if that server is already highly utilised. This paper formalises the\ntwo related problems of allocating resources at different locations and\nassigning users to them with the goal of minimising the response times for a\ngiven number of resources to use -- a non-linear capacitated facility location\nproblem with integrated queuing systems. To efficiently handle the\nnon-linearity, we introduce five linear problem approximations and adapt the\ncurrently best heuristic for a similar problem to our scenario. All six\napproaches are compared in experiments for solution quality and solving time.\nSurprisingly, our best optimisation formulation outperforms the heuristic in\nboth time and quality. Additionally, we evaluate the influence ot resource\ndistributions in the network on the response time: Cut by half for some\nconfigurations. The presented formulations are applicable to a broader\noptimisation domain. \n\n"}
{"id": "1507.08979", "contents": "Title: Tractable Resource Management with Uplink Decoupled Millimeter-Wave\n  Overlay in Ultra-Dense Cellular Networks Abstract: The forthcoming 5G cellular network is expected to overlay millimeter-wave\n(mmW) transmissions with the incumbent micro-wave ({\\mu}W) architecture. The\noverall mm-{\\mu}W resource management should therefore harmonize with each\nother. This paper aims at maximizing the overall downlink (DL) rate with a\nminimum uplink (UL) rate constraint, and concludes: mmW tends to focus more on\nDL transmissions while {\\mu}W has high priority for complementing UL, under\ntime-division duplex (TDD) mmW operations. Such UL dedication of {\\mu}W results\nfrom the limited use of mmW UL bandwidth due to excessive power consumption\nand/or high peak-to-average power ratio (PAPR) at mobile users. To further\nrelieve this UL bottleneck, we propose mmW UL decoupling that allows each\nlegacy {\\mu}W base station (BS) to receive mmW signals. Its impact on mm-{\\mu}W\nresource management is provided in a tractable way by virtue of a novel\nclosed-form mm-{\\mu}W spectral efficiency (SE) derivation. In an ultra-dense\ncellular network (UDN), our derivation verifies mmW (or {\\mu}W) SE is a\nlogarithmic function of BS-to-user density ratio. This strikingly simple yet\npractically valid analysis is enabled by exploiting stochastic geometry in\nconjunction with real three dimensional (3D) building blockage statistics in\nSeoul, Korea. \n\n"}
{"id": "1508.00040", "contents": "Title: An Analysis of Device-Free and Device-Based WiFi-Localization Systems Abstract: WiFi-based localization became one of the main indoor localization techniques\ndue to the ubiquity of WiFi connectivity. However, indoor environments exhibit\ncomplex wireless propagation characteristics. Typically, these characteristics\nare captured by constructing a fingerprint map for the different locations in\nthe area of interest. This fingerprint requires significant overhead in manual\nconstruction, and thus has been one of the major drawbacks of WiFi-based\nlocalization. In this paper, we present an automated tool for fingerprint\nconstructions and leverage it to study novel scenarios for device-based and\ndevice-free WiFi-based localization that are difficult to evaluate in a real\nenvironment. In a particular, we examine the effect of changing the access\npoints (AP) mounting location, AP technology upgrade, crowd effect on\ncalibration and operation, among others; on the accuracy of the localization\nsystem. We present the analysis for the two classes of WiFi-based localization:\ndevice-based and device-free. Our analysis highlights factors affecting the\nlocalization system accuracy, how to tune it for better localization, and\nprovides insights for both researchers and practitioners. \n\n"}
{"id": "1508.00527", "contents": "Title: On the Base Station Association Problem in HetSNets Abstract: The dense deployment of small-cell base stations in HetSNets requires\nefficient resource allocation techniques. More precisely, the problem of\nassociating users to SBSs must be revised and carefully studied. This problem\nis NP-hard and requires solving an integer optimization problem. In order to\nefficiently solve this problem, we model it using non-cooperative game theory.\nFirst, we design two non-cooperative games to solve the problem and show the\nexistence of pure Nash equilibria (PNE) in both games. These equilibria are\nshown to be far from the social optimum. Hence, we propose a better game design\nin order to approach this optimum. This new game is proved to have no PNE in\ngeneral. However, simulations show, for Rayleigh fading channels, that a PNE\nalways exists for all instances of the game. In addition, we show that its\nprices of anarchy and stability are close to one. We propose a best response\ndynamics (BRD) algorithm that converges to a PNE when it exists. Because of the\nhigh information exchange of BRD, a completely distributed algorithm, based on\nthe theory of learning, is proposed. Simulations show that this algorithm has\ntight-to-optimal performance and further it converges to a PNE (when existing)\nwith high probability. \n\n"}
{"id": "1508.01742", "contents": "Title: Allocation of Heterogeneous Resources of an IoT Device to Flexible\n  Services Abstract: Internet of Things (IoT) devices can be equipped with multiple heterogeneous\nnetwork interfaces. An overwhelmingly large amount of services may demand some\nor all of these interfaces' available resources. Herein, we present a precise\nmathematical formulation of assigning services to interfaces with heterogeneous\nresources in one or more rounds. For reasonable instance sizes, the presented\nformulation produces optimal solutions for this computationally hard problem.\nWe prove the NP-Completeness of the problem and develop two algorithms to\napproximate the optimal solution for big instance sizes. The first algorithm\nallocates the most demanding service requirements first, considering the\naverage cost of interfaces resources. The second one calculates the demanding\nresource shares and allocates the most demanding of them first by choosing\nrandomly among equally demanding shares. Finally, we provide simulation results\ngiving insight into services splitting over different interfaces for both\ncases. \n\n"}
{"id": "1508.02556", "contents": "Title: Assessment of LTE Wireless Access for Monitoring of Energy Distribution\n  in the Smart Grid Abstract: While LTE is becoming widely rolled out for human-type services, it is also a\npromising solution for cost-efficient connectivity of the smart grid monitoring\nequipment. This is a type of machine-to-machine (M2M) traffic that consists\nmainly of sporadic uplink transmissions. In such a setting, the amount of\ntraffic that can be served in a cell is not constrained by the data capacity,\nbut rather by the signaling constraints in the random access channel and\ncontrol channel. In this paper we explore these limitations using a detailed\nsimulation of the LTE access reservation protocol (ARP). We find that 1)\nassigning more random access opportunities may actually worsen performance; and\n2) the additional signaling that follows the ARP has very large impact on the\ncapacity in terms of the number of supported devices; we observed a reduction\nin the capacity by almost a factor of 3. This suggests that a lightweight\naccess method, with a reduced number of signaling messages, needs to be\nconsidered in standardization for M2M applications. Additionally we propose a\ntractable analytical model to calculate the outage that can be rapidly\nimplemented and evaluated. The model accounts for the features of the random\naccess, control channel and uplink and downlink data channels, as well as\nretransmissions. \n\n"}
{"id": "1508.02668", "contents": "Title: Modeling and Performance Analysis of Clustered Device-to-Device Networks Abstract: Device-to-device (D2D) communication enables direct communication between\nproximate devices thereby improving the overall spectrum utilization and\noffloading traffic from cellular networks. This paper develops a new spatial\nmodel for D2D networks in which the device locations are modeled as a Poisson\ncluster process. Using this model, we study the performance of a typical D2D\nreceiver in terms of coverage probability under two realistic content\navailability setups: (i) content of interest for a typical device is available\nat a device chosen uniformly at random from the same cluster, which we term\nuniform content availability, and (ii) content of interest is available at the\n$k^{th}$ closest device from the typical device inside the same cluster, which\nwe term $k$-closest content availability. Using these coverage probability\nresults, we also characterize the area spectral efficiency (ASE) of the whole\nnetwork for the two setups. A key intermediate step in this analysis is the\nderivation of the distributions of distances from a typical device to both the\nintra- and inter-cluster devices. Our analysis reveals that an optimum number\nof D2D transmitters must be simultaneously activated per cluster in order to\nmaximize ASE. This can be interpreted as the classical tradeoff between more\naggressive frequency reuse and higher interference power. The optimum number of\nsimultaneously transmitting devices and the resulting ASE increase as the\ncontent is made available closer to the receivers. Our analysis also quantifies\nthe best and worst case performance of clustered D2D networks both in terms of\ncoverage and ASE. \n\n"}
{"id": "1508.03605", "contents": "Title: Reliable Prediction of Channel Assignment Performance in Wireless Mesh\n  Networks Abstract: The advancements in wireless mesh networks (WMN), and the surge in\nmulti-radio multi-channel (MRMC) WMN deployments have spawned a multitude of\nnetwork performance issues. These issues are intricately linked to the adverse\nimpact of endemic interference. Thus, interference mitigation is a primary\ndesign objective in WMNs. Interference alleviation is often effected through\nefficient channel allocation (CA) schemes which fully utilize the potential of\nMRMC environment and also restrain the detrimental impact of interference.\nHowever, numerous CA schemes have been proposed in research literature and\nthere is a lack of CA performance prediction techniques which could assist in\nchoosing a suitable CA for a given WMN. In this work, we propose a reliable\ninterference estimation and CA performance prediction approach. We demonstrate\nits efficacy by substantiating the CA performance predictions for a given WMN\nwith experimental data obtained through rigorous simulations on an ns-3 802.11g\nenvironment. \n\n"}
{"id": "1508.05648", "contents": "Title: FreeNet: Spectrum and Energy Harvesting Wireless Networks Abstract: The dramatic mobile data traffic growth is not only resulting in the spectrum\ncrunch but is also leading to exorbitant energy consumption. It is thus\ndesirable to liberate mobile and wireless networks from the constraint of the\nspectrum scarcity and to rein in the growing energy consumption. This article\nintroduces FreeNet, figuratively synonymous to \"Free Network\", which engineers\nthe spectrum and energy harvesting techniques to alleviate the spectrum and\nenergy constraints by sensing and harvesting spare spectrum for data\ncommunications and utilizing renewable energy as power supplies, respectively.\nHence, FreeNet increases the spectrum and energy efficiency of wireless\nnetworks and enhances the network availability. As a result, FreeNet can be\ndeployed to alleviate network congestion in urban areas, provision broadband\nservices in rural areas, and upgrade emergency communication capacity. This\narticle provides a brief analysis of the design of FreeNet that accommodates\nthe dynamics of the spare spectrum and employs renewable energy. \n\n"}
{"id": "1508.06093", "contents": "Title: Energy Group-Buying with Loading Sharing for Green Cellular Networks Abstract: In the emerging hybrid electricity market, mobile network operators (MNOs) of\ncellular networks can make day-ahead energy purchase commitments at low prices\nand real-time flexible energy purchase at high prices. To minimize electricity\nbills, it is essential for MNOs to jointly optimize the day-ahead and real-time\nenergy purchase based on their time-varying wireless traffic load. In this\npaper, we consider two different MNOs coexisting in the same area, and exploit\ntheir collaboration in both energy purchase and wireless load sharing for\nenergy cost saving. Specifically, we propose a new approach named energy group\nbuying with load sharing, in which the two MNOs are aggregated as a single\ngroup to make the day-ahead and real-time energy purchase, and their base\nstations (BSs) share the wireless traffic to maximally turn lightly-loaded BSs\ninto sleep mode. When the two MNOs belong to the same entity and aim to\nminimize their total energy cost, we use the two-stage stochastic programming\nto obtain the optimal day-ahead and real-time energy group buying jointly with\nwireless load sharing. When the two MNOs belong to different entities and are\nself-interested in minimizing their individual energy costs, we propose a novel\nrepeated Nash bargaining scheme for them to negotiate and share their energy\ncosts under energy group buying and load sharing. Our proposed repeated Nash\nbargaining scheme is shown to achieve Pareto-optimal and fair energy cost\nreductions for both MNOs. \n\n"}
{"id": "1509.00374", "contents": "Title: Joint Energy Minimization and Resource Allocation in C-RAN with Mobile\n  Cloud Abstract: Cloud radio access network (C-RAN) has emerged as a potential candidate of\nthe next generation access network technology to address the increasing mobile\ntraffic, while mobile cloud computing (MCC) offers a prospective solution to\nthe resource-limited mobile user in executing computation intensive tasks.\nTaking full advantages of above two cloud-based techniques, C-RAN with MCC are\npresented in this paper to enhance both performance and energy efficiencies. In\nparticular, this paper studies the joint energy minimization and resource\nallocation in C-RAN with MCC under the time constraints of the given tasks. We\nfirst review the energy and time model of the computation and communication.\nThen, we formulate the joint energy minimization into a non-convex optimization\nwith the constraints of task executing time, transmitting power, computation\ncapacity and fronthaul data rates. This non-convex optimization is then\nreformulated into an equivalent convex problem based on weighted minimum mean\nsquare error (WMMSE). The iterative algorithm is finally given to deal with the\njoint resource allocation in C-RAN with mobile cloud. Simulation results\nconfirm that the proposed energy minimization and resource allocation solution\ncan improve the system performance and save energy. \n\n"}
{"id": "1509.00940", "contents": "Title: Wireless Charging Technologies: Fundamentals, Standards, and Network\n  Applications Abstract: Wireless charging is a technology of transmitting power through an air gap to\nelectrical devices for the purpose of energy replenishment. The recent progress\nin wireless charging techniques and development of commercial products have\nprovided a promising alternative way to address the energy bottleneck of\nconventionally portable battery-powered devices. However, the incorporation of\nwireless charging into the existing wireless communication systems also brings\nalong a series of challenging issues with regard to implementation, scheduling,\nand power management. In this article, we present a comprehensive overview of\nwireless charging techniques, the developments in technical standards, and\ntheir recent advances in network applications. In particular, with regard to\nnetwork applications, we review the mobile charger dispatch strategies, static\ncharger scheduling strategies and wireless charger deployment strategies.\nAdditionally, we discuss open issues and challenges in implementing wireless\ncharging technologies. Finally, we envision some practical future network\napplications of wireless charging. \n\n"}
{"id": "1509.01094", "contents": "Title: An Ant Colonization Routing Algorithm to Minimize Network Power\n  Consumption Abstract: Rising energy consumption of IT infrastructure concerns have spurred the\ndevelopment of more power efficient networking equipment and algorithms. When\n\\emph{old} equipment just drew an almost constant amount of power regardless of\nthe traffic load, there were some efforts to minimize the total energy usage by\nmodifying routing decisions to aggregate traffic in a minimal set of links,\ncreating the opportunity to power off some unused equipment during low traffic\nperiods. New equipment, with power profile functions depending on the offered\nload, presents new challenges for optimal routing. The goal now is not just to\npower some links down, but to aggregate and/or spread the traffic so that\ndevices operate in their sweet spot in regards to network usage. In this paper\nwe present an algorithm that, making use of the ant colonization algorithm,\ncomputes, in a decentralized manner, the routing tables so as to minimize\nglobal energy consumption. Moreover, the resulting algorithm is also able to\ntrack changes in the offered load and react to them in real time. \n\n"}
{"id": "1509.01187", "contents": "Title: Unmanned Aerial Vehicle with Underlaid Device-to-Device Communications:\n  Performance and Tradeoffs Abstract: In this paper, the deployment of an unmanned aerial vehicle (UAV) as a flying\nbase station used to provide on the fly wireless communications to a given\ngeographical area is analyzed. In particular, the co-existence between the UAV,\nthat is transmitting data in the downlink, and an underlaid device-todevice\n(D2D) communication network is considered. For this model, a tractable\nanalytical framework for the coverage and rate analysis is derived. Two\nscenarios are considered: a static UAV and a mobile UAV. In the first scenario,\nthe average coverage probability and the system sum-rate for the users in the\narea are derived as a function of the UAV altitude and the number of D2D users.\nIn the second scenario, using the disk covering problem, the minimum number of\nstop points that the UAV needs to visit in order to completely cover the area\nis computed. Furthermore, considering multiple retransmissions for the UAV and\nD2D users, the overall outage probability of the D2D users is derived.\nSimulation and analytical results show that, depending on the density of D2D\nusers, optimal values for the UAV altitude exist for which the system sum-rate\nand the coverage probability are maximized. Moreover, our results also show\nthat, by enabling the UAV to intelligently move over the target area, the total\nrequired transmit power of UAV while covering the entire area, is minimized.\nFinally, in order to provide a full coverage for the area of interest, the\ntradeoff between the coverage and delay, in terms of the number of stop points,\nis discussed. \n\n"}
{"id": "1509.01552", "contents": "Title: Overview on Security Approaches in Intelligent Transportation Systems Abstract: Major standardization bodies developed and designed systems that should be\nused in vehicular ad-hoc networks. The Institute of Electrical and Electronics\nEngineers (IEEE) in America designed the wireless access in vehicular\nenvironments (WAVE) system. The European Telecommunications Standards Institute\n(ETSI) did come up with the \"ITS-G5\" system. Those Vehicular Ad-hoc Networks\n(VANETs) are the basis for Intelligent Transportation Systems (ITSs). They aim\nto efficiently communicate and provide benefits to people, ranging from\nimproved safety to convenience. But different design and architectural choices\nlead to different network properties, especially security properties that are\nfundamentally depending on the networks architecture. To be able to compare\ndifferent security architectures, different proposed approaches need to be\ndiscussed. One problem in current research is the missing focus on different\napproaches for trust establishment in VANETs. Therefore, this paper surveys\ndifferent security issues and solutions in VANETs and we furthermore categorize\nthese solutions into three basic trust defining architectures: centralized,\ndecentralized and hybrid. These categories represent how trust is build in a\nsystem, i.e., in a centralized, decentralized way or even by combining both\nopposing approaches to a hybrid solution, which aims to inherit the benefits of\nboth worlds. This survey defines those categories and finds that hybrid\napproaches are underrepresented in current research efforts. \n\n"}
{"id": "1509.01596", "contents": "Title: Inter-Layer Per-Mobile Optimization of Cloud Mobile Computing: A\n  Message-Passing Approach Abstract: Cloud mobile computing enables the offloading of computation-intensive\napplications from a mobile device to a cloud processor via a wireless\ninterface. In light of the strong interplay between offloading decisions at the\napplication layer and physical-layer parameters, which determine the energy and\nlatency associated with the mobile-cloud communication, this paper investigates\nthe inter-layer optimization of fine-grained task offloading across both\nlayers. In prior art, this problem was formulated, under a serial\nimplementation of processing and communication, as a mixed integer program,\nentailing a complexity that is exponential in the number of tasks. In this\nwork, instead, algorithmic solutions are proposed that leverage the structure\nof the call graphs of typical applications by means of message passing on the\ncall graph, under both serial and parallel implementations of processing and\ncommunication. For call trees, the proposed solutions have a linear complexity\nin the number of tasks, and efficient extensions are presented for more general\ncall graphs that include \"map\" and \"reduce\"-type tasks. Moreover, the proposed\nschemes are optimal for the serial implementation, and provide principled\nheuristics for the parallel implementation. Extensive numerical results yield\ninsights into the impact of inter-layer optimization and on the comparison of\nthe two implementations. \n\n"}
{"id": "1509.04366", "contents": "Title: Neighbor discovery latency in BLE-like duty-cycled protocols Abstract: Neighbor discovery is the procedure using which two wireless devices initiate\na first contact. In low power ad-hoc networks, radios are duty-cycled and the\nlatency until a packet meets a reception phase of another device is determined\nby a random process. Most research considers slotted protocols, in which the\npoints in time for reception are temporally coupled to beacon transmissions. In\ncontrast, many recent protocols, such as ANT/ANT+ and Bluetooth Low Energy\n(BLE) use a slotless, periodic-interval based scheme for neighbor discovery.\nHere, one device periodically broadcasts packets, whereas the other device\nperiodically listens to the channel. Both periods are independent from each\nother and drawn over continuous time. Such protocols provide 3 degrees of\nfreedom (viz., the intervals for advertising and scanning and the duration of\neach scan phase). Though billions of existing BLE devices rely on these\nprotocols, neither their expected latencies nor beneficial configurations with\ngood latency-duty-cycle relations are known. Parametrizations for the\nparticipating devices are usually determined based on a \"good guess\". In this\npaper, we for the first time present a mathematical theory which can compute\nthe neighbor discovery latencies for all possible parametrizations. Further,\nour theory shows that upper bounds on the latency can be guaranteed for all\nparametrizations, except for a finite number of singularities. Therefore,\nslotless, periodic interval-based protocols can be used in applications with\ndeterministic latency demands, which have been reserved for slotted protocols\nuntil now. Our proposed theory can be used for analyzing the neighbor discovery\nlatencies, for tweaking protocol parameters and for developing new protocols. \n\n"}
{"id": "1509.04492", "contents": "Title: Perpetual Codes for Network Coding Abstract: Random Linear Network Coding (RLNC) provides a theoretically efficient method\nfor coding. Some of its practical drawbacks are the complexity of decoding and\nthe overhead due to the coding vectors. For computationally weak and\nbattery-driven platforms, these challenges are particular important. In this\nwork, we consider the coding variant Perpetual codes which are sparse,\nnon-uniform and the coding vectors have a compact representation. The sparsity\nallows for fast encoding and decoding, and the non-uniform protection of\nsymbols enables recoding where the produced symbols are indistinguishable from\nthose encoded at the source. The presented results show that the approach can\nprovide a coding overhead arbitrarily close to that of RLNC, but at reduced\ncomputational load. The achieved gain over RLNC grows with the generation size,\nand both encoding and decoding throughput is approximately one order of\nmagnitude higher compared to RLNC at a generation size of 2048. Additionally,\nthe approach allows for easy adjustment between coding throughput and code\noverhead, which makes it suitable for a broad range of platforms and\napplications. \n\n"}
{"id": "1509.07684", "contents": "Title: A Path Generation Approach to Embedding of Virtual Networks Abstract: As the virtualization of networks continues to attract attention from both\nindustry and academia, the Virtual Network Embedding (VNE) problem remains a\nfocus of researchers. This paper proposes a one-shot, unsplittable flow VNE\nsolution based on column generation. We start by formulating the problem as a\npath-based mathematical program called the primal, for which we derive the\ncorresponding dual problem. We then propose an initial solution which is used,\nfirst, by the dual problem and then by the primal problem to obtain a final\nsolution. Unlike most approaches, our focus is not only on embedding accuracy\nbut also on the scalability of the solution. In particular, the one-shot nature\nof our formulation ensures embedding accuracy, while the use of column\ngeneration is aimed at enhancing the computation time to make the approach more\nscalable. In order to assess the performance of the proposed solution, we\ncompare it against four state of the art approaches as well as the optimal\nlink-based formulation of the one-shot embedding problem. Experiments on a\nlarge mix of Virtual Network (VN) requests show that our solution is near\noptimal (achieving about 95% of the acceptance ratio of the optimal solution),\nwith a clear improvement over existing approaches in terms of VN acceptance\nratio and average Substrate Network (SN) resource utilization, and a\nconsiderable improvement (92% for a SN of 50 nodes) in time complexity compared\nto the optimal solution. \n\n"}
{"id": "1509.08316", "contents": "Title: A Survey on Legacy and Emerging Technologies for Public Safety\n  Communications Abstract: Effective emergency and natural disaster management depend on the efficient\nmission-critical voice and data communication between first responders and\nvictims. Land Mobile Radio System (LMRS) is a legacy narrowband technology used\nfor critical voice communications with limited use for data applications.\nRecently Long Term Evolution (LTE) emerged as a broadband communication\ntechnology that has a potential to transform the capabilities of public safety\ntechnologies by providing broadband, ubiquitous, and mission-critical voice and\ndata support. For example, in the United States, FirstNet is building a\nnationwide coast-to-coast public safety network based of LTE broadband\ntechnology. This paper presents a comparative survey of legacy and the\nLTE-based public safety networks, and discusses the LMRS-LTE convergence as\nwell as mission-critical push-to-talk over LTE. A simulation study of LMRS and\nLTE band class 14 technologies is provided using the NS-3 open source tool. An\nexperimental study of APCO-25 and LTE band class 14 is also conducted using\nsoftware-defined radio, to enhance the understanding of the public safety\nsystems. Finally, emerging technologies that may have strong potential for use\nin public safety networks are reviewed. \n\n"}
{"id": "1509.08346", "contents": "Title: UB-ANC Drone: A Flexible Airborne Networking and Communications Testbed Abstract: We present the University at Buffalo's Airborne Networking and Communications\nTestbed (UB-ANC Drone). UB-ANC Drone is an open software/hardware platform that\naims to facilitate rapid testing and repeatable comparative evaluation of\nairborne networking and communications protocols at different layers of the\nprotocol stack. It combines quadcopters capable of autonomous flight with\nsophisticated command and control capabilities and embedded software-defined\nradios (SDRs), which enable flexible deployment of novel communications and\nnetworking protocols. This is in contrast to existing airborne network\ntestbeds, which rely on standard inflexible wireless technologies, e.g., Wi-Fi\nor Zigbee. UB-ANC Drone is designed with emphasis on modularity and\nextensibility, and is built around popular open-source projects and standards\ndeveloped by the research and hobby communities. This makes UB-ANC Drone highly\ncustomizable, while also simplifying its adoption. In this paper, we describe\nUB-ANC Drone's hardware and software architecture. \n\n"}
{"id": "1509.09222", "contents": "Title: On Jamming Against Wireless Networks Abstract: In this paper, we study jamming attacks against wireless networks.\nSpecifically, we consider a network of base stations (BS) or access points (AP)\nand investigate the impact of a fixed number of jammers that are randomly\ndeployed according to a Binomial point process. We shed light on the network\nperformance in terms of a) the outage probability and b) the error probability\nof a victim receiver in the downlink of this wireless network. We derive\nanalytical expressions for both these metrics and discuss in detail how the\njammer network must adapt to the various wireless network parameters in order\nto effectively attack the victim receivers. For instance, we will show that\nwith only 1 jammer per BS/AP a) the outage probability of the wireless network\ncan be increased from 1% (as seen in the non-jamming case) to 80% and b) when\nretransmissions are used, the jammers cause the effective network activity\nfactor (and hence the interference among the BSs) to be doubled. Furthermore,\nwe show that the behavior of the jammer network as a function of the BS/AP\ndensity is not obvious. In particular, an interesting concave-type behavior is\nseen which indicates that the number of jammers required to attack the wireless\nnetwork must scale with the BS density only until a certain value beyond which\nit decreases. In the context of error probability of the victim receiver, we\nstudy whether or not some recent results related to jamming in the\npoint-to-point link scenario can be extended to the case of jamming against\nwireless networks. Numerical results are presented to validate the theoretical\ninferences presented. \n\n"}
{"id": "1510.04772", "contents": "Title: Analysis of Path Loss mitigation through Dynamic Spectrum Access:\n  Software Defined Radio Abstract: In this paper, an analysis is carried out for a method to mitigate the path\nloss through the dynamic spectrum access (DSA) method. The path loss is a major\ncomponent which determines the QoS of a wireless link. Its effect is\ncomplemented by the presence of obstruction between the transmitter and\nreceiver. The future cellular network (5G) focuses on operating with the\nmillimeter-wave (mmW). In higher frequency, path loss can play a significant\nrole in degrading the link quality due to higher attenuation. In a scenario,\nwhere the operating environment is changing dynamically, sudden degradation of\noperating conditions or arrival of obstruction between transmitter and receiver\nmay result in link failure. The method analyzed here includes dynamically\nallocating spectrum at a lower frequency band for a link suffering from high\npath loss. For the analysis, a wireless link was set up using Universal\nSoftware Radio Peripherals (USRPs). The received power is observed to increase\nby dynamically changing the operating frequency from 1.9 GHz to 830 MHz.\nFinally the utility of software defined radio (SDR) in the RF front end, to\ncombat the path loss in the future cellular networks, is studied. \n\n"}
{"id": "1510.07970", "contents": "Title: An Application-Aware Spectrum Sharing Approach for Commercial Use of 3.5\n  GHz Spectrum Abstract: In this paper, we introduce an application-aware spectrum sharing approach\nfor sharing the Federal under-utilized 3.5 GHz spectrum with commercial users.\nIn our model, users are running elastic or inelastic traffic and each\napplication running on the user equipment (UE) is assigned a utility function\nbased on its type. Furthermore, each of the small cells users has a minimum\nrequired target utility for its application. In order for users located under\nthe coverage area of the small cells' eNodeBs, with the 3.5 GHz band resources,\nto meet their minimum required quality of experience (QoE), the network\noperator makes a decision regarding the need for sharing the macro cell's\nresources to obtain additional resources. Our objective is to provide each user\nwith a rate that satisfies its application's minimum required utility through\nspectrum sharing approach and improve the overall QoE in the network. We\npresent an application-aware spectrum sharing algorithm that is based on\nresource allocation with carrier aggregation to allocate macro cell permanent\nresources and small cells' leased resources to UEs and allocate each user's\napplication an aggregated rate that can at minimum achieves the application's\nminimum required utility. Finally, we present simulation results for the\nperformance of the proposed algorithm. \n\n"}
{"id": "1511.00112", "contents": "Title: A Novel Play-out Algorithm for HTTP Adaptive Streaming Abstract: In the paper, we proposed a novel algorithm dedicated to adaptive video\nstreaming based on HTTP. The algorithm employs a hybrid play-out strategy which\ncombines two popular approaches: an estimation of network bandwidth and a\ncontrol of a player buffer. The proposed algorithm was implemented in two\nversions which differ in the method of handling fluctuations of network\nthroughput.\n  The proposed hybrid algorithm was evaluated against solutions which base\ntheir play-out strategy purely on bandwidth or buffer level assessment. The\ncomparison was performed in an environment which emulated two systems: a Wi-Fi\nnetwork with a single immobile node and HSPA (High Speed Packet Access) network\nwith a mobile node. The evaluation shows that the hybrid approach in most cases\nachieves better results compared to its competitors, being able to stream the\nvideo more smoothly without unnecessary bit-rate switches. However, in certain\nnetwork conditions, this score is traded for a worse throughput utilisation\ncompared to other play-out strategies. \n\n"}
{"id": "1511.00576", "contents": "Title: Sampling Geometric Inhomogeneous Random Graphs in Linear Time Abstract: Real-world networks, like social networks or the internet infrastructure,\nhave structural properties such as large clustering coefficients that can best\nbe described in terms of an underlying geometry. This is why the focus of the\nliterature on theoretical models for real-world networks shifted from classic\nmodels without geometry, such as Chung-Lu random graphs, to modern\ngeometry-based models, such as hyperbolic random graphs.\n  With this paper we contribute to the theoretical analysis of these modern,\nmore realistic random graph models. Instead of studying directly hyperbolic\nrandom graphs, we use a generalization that we call geometric inhomogeneous\nrandom graphs (GIRGs). Since we ignore constant factors in the edge\nprobabilities, GIRGs are technically simpler (specifically, we avoid hyperbolic\ncosines), while preserving the qualitative behaviour of hyperbolic random\ngraphs, and we suggest to replace hyperbolic random graphs by this new model in\nfuture theoretical studies.\n  We prove the following fundamental structural and algorithmic results on\nGIRGs. (1) As our main contribution we provide a sampling algorithm that\ngenerates a random graph from our model in expected linear time, improving the\nbest-known sampling algorithm for hyperbolic random graphs by a substantial\nfactor O(n^0.5). (2) We establish that GIRGs have clustering coefficients in\n{\\Omega}(1), (3) we prove that GIRGs have small separators, i.e., it suffices\nto delete a sublinear number of edges to break the giant component into two\nlarge pieces, and (4) we show how to compress GIRGs using an expected linear\nnumber of bits. \n\n"}
{"id": "1511.05488", "contents": "Title: Active exploration of sensor networks from a robotics perspective Abstract: Traditional algorithms for robots who need to integrate into a wireless\nnetwork often focus on one specific task. In this work we want to develop\nsimple, adaptive and reusable algorithms for real world applications for this\nscenario. Starting with the most basic task for mobile wireless network nodes,\nfinding the position of another node, we introduce an algorithm able to solve\nthis task. We then show how this algorithm can readily be employed to solve a\nlarge number of other related tasks like finding the optimal position to bridge\ntwo static network nodes. For this we first introduce a meta-algorithm inspired\nby autonomous robot learning strategies and the concept of internal models\nwhich yields a class of source seeking algorithms for mobile nodes. The\neffectiveness of this algorithm is demonstrated in real world experiments using\na physical mobile robot and standard 802.11 wireless LAN in an office\nenvironment. We also discuss the differences to conventional algorithms and\ngive the robotics perspective on this class of algorithms. Then we proceed to\nshow how more complex tasks, which might be encountered by mobile nodes, can be\nencoded in the same framework and how the introduced algorithm can solve them.\nThese tasks can be direct (cross layer) optimization tasks or can also encode\nmore complex tasks like bridging two network nodes. We choose the bridging\nscenario as an example, implemented on a real physical robot, and show how the\nrobot can solve it in a real world experiment. \n\n"}
{"id": "1511.05498", "contents": "Title: Feasibility Study of Stochastic Streaming with 4K UHD Video Traces Abstract: This paper performs the feasibility study of stochastic video streaming\nalgorithms with up-to-date 4K ultra-high-definition (UHD) video traces. In\nprevious work, various stochastic video streaming algorithms were proposed\nwhich maximize time-average video streaming quality subject to queue stability\nbased on the information of queue-backlog length. The performance improvements\nwith the stochastic video streaming algorithms were verified with traditional\nMPEG test sequences; but there is no study how much the proposed stochastic\nalgorithm is better when we consider up-to-date 4K UHD video traces. Therefore,\nthis paper evaluates the stochastic streaming algorithms with 4K UHD video\ntraces; and verifies that the stochastic algorithms perform better than\nqueue-independent algorithms, as desired. \n\n"}
{"id": "1511.05892", "contents": "Title: Analysis and Optimization of Sparse Random Linear Network Coding for\n  Reliable Multicast Services Abstract: Point-to-multipoint communications are expected to play a pivotal role in\nnext-generation networks. This paper refers to a cellular system transmitting\nlayered multicast services to a multicast group of users. Reliability of\ncommunications is ensured via different Random Linear Network Coding (RLNC)\ntechniques. We deal with a fundamental problem: the computational complexity of\nthe RLNC decoder. The higher the number of decoding operations is, the more the\nuser's computational overhead grows and, consequently, the faster the battery\nof mobile devices drains. By referring to several sparse RLNC techniques, and\nwithout any assumption on the implementation of the RLNC decoder in use, we\nprovide an efficient way to characterize the performance of users targeted by\nultra-reliable layered multicast services. The proposed modeling allows to\nefficiently derive the average number of coded packet transmissions needed to\nrecover one or more service layers. We design a convex resource allocation\nframework that allows to minimize the complexity of the RLNC decoder by jointly\noptimizing the transmission parameters and the sparsity of the code. The\ndesigned optimization framework also ensures service guarantees to\npredetermined fractions of users. The performance of the proposed optimization\nframework is then investigated in a LTE-A eMBMS network multicasting H.264/SVC\nvideo services. \n\n"}
{"id": "1511.06098", "contents": "Title: Interference Management with Partial Uplink/Downlink Spectrum Overlap Abstract: Simultaneous reuse of spectral resources by uplink and downlink, denoted as\nin-band full duplex (FD) communication, is promoted to double the spectral\nefficiency when compared to its half-duplex (HD) counterpart. Interference\nmanagement, however, remains challenging in FD cellular networks, especially\nwhen high disparity between uplink and downlink transmission powers exists. The\nuplink performance can be particularly deteriorated when operating on channels\nthat are simultaneously occupied with downlink transmission. This paper\nconsiders a cellular wireless system with partial spectrum overlap between the\ndownlink and uplink. The performance of the system becomes, therefore, a\nfunction of the overlap fraction, as well as the power level of both the uplink\nand downlink transmissions. The paper considers the problem of maximizing an\noverall network utility to find the uplink/downlink transmission powers and the\nspectrum overlap fraction between the uplink and downlink spectrum in each\ncell, and proposes solving the problem using interior point method. Simulations\nresults confirm the vulnerability of the uplink performance to the FD\noperation, and show the superiority of the proposed scheme over the FD and HD\nschemes. The results further show that explicit uplink and downlink performance\nshould be considered for efficient design of cellular networks with overlapping\nuplink/downlink resources. \n\n"}
{"id": "1511.06735", "contents": "Title: On Feasibility of 5G-Grade Dedicated RF Charging Technology for\n  Wireless-Powered Wearables Abstract: For decades, wireless energy transfer and harvesting remained of focused\nattention in the research community, but with limited practical applications.\nRecently, with the development of fifth-generation (5G) mobile technology, the\nconcept of dedicated radio-frequency (RF) charging promises to support the\ngrowing market of wearable devices. In this work, we shed light on the\npotential of wireless RF power transfer by elaborating upon feasible system\nparameters and architecture, emphasizing the basic trade-offs behind\nomni-directional and directional out-of-band energy transmission, providing\nsystem-level performance evaluation, as well as discussing open challenges on\nthe way to sustainable wireless-powered wearables. The key aspects highlighted\nin this article include system operation choices, user mobility effects, impact\nof network and user densities, as well as regulatory issues. Ultimately, our\nresearch targets to facilitate the integration of wireless RF charging\ntechnology into the emerging 5G ecosystem. \n\n"}
{"id": "1511.08631", "contents": "Title: Dynamic Clustering and ON/OFF Strategies for Wireless Small Cell\n  Networks Abstract: In this paper, a novel cluster-based approach for maximizing the energy\nefficiency of wireless small cell networks is proposed. A dynamic mechanism is\nproposed to group locally-coupled small cell base stations (SBSs) into clusters\nbased on location and traffic load. Within each formed cluster, SBSs coordinate\ntheir transmission parameters to minimize a cost function which captures the\ntradeoffs between energy efficiency and flow level performance, while\nsatisfying their users' quality-of-service requirements. Due to the lack of\ninter-cluster communications, clusters compete with one another in order to\nimprove the overall network's energy efficiency. This inter-cluster competition\nis formulated as a noncooperative game between clusters that seek to minimize\ntheir respective cost functions. To solve this game, a distributed learning\nalgorithm is proposed using which clusters autonomously choose their optimal\ntransmission strategies based on local information. It is shown that the\nproposed algorithm converges to a stationary mixed-strategy distribution which\nconstitutes an epsilon-coarse correlated equilibrium for the studied game.\nSimulation results show that the proposed approach yields significant\nperformance gains reaching up to 36% of reduced energy expenditures and up to\n41% of reduced fractional transfer time compared to conventional approaches. \n\n"}
{"id": "1512.00137", "contents": "Title: SVC-based Multi-user Streamloading for Wireless Networks Abstract: In this paper, we present an approach for joint rate allocation and quality\nselection for a novel video streaming scheme called streamloading.\nStreamloading is a recently developed method for delivering high quality video\nwithout violating copyright enforced restrictions on content access for video\nstreaming. In regular streaming services, content providers restrict the amount\nof viewable video that users can download prior to playback. This approach can\ncause inferior user experience due to bandwidth variations, especially in\nmobile networks with varying capacity. In streamloading, the video is encoded\nusing Scalable Video Coding, and users are allowed to pre-fetch enhancement\nlayers and store them on the device, while base layers are streamed in a near\nreal-time fashion ensuring that buffering constraints on viewable content are\nmet.\n  We begin by formulating the offline problem of jointly optimizing rate\nallocation and quality selection for streamloading in a wireless network. This\nmotivates our proposed online algorithms for joint scheduling at the base\nstation and segment quality selection at receivers. The results indicate that\nstreamloading outperforms state-of-the-art streaming schemes in terms of the\nnumber of additional streams we can admit for a given video quality.\nFurthermore, the quality adaptation mechanism of our proposed algorithm\nachieves a higher performance than baseline algorithms with no (or limited)\nvideo-centric optimization of the base station's allocation of resources, e.g.,\nproportional fairness. \n\n"}
{"id": "1512.00259", "contents": "Title: NetCodCCN: a Network Coding approach for Content-Centric Networks Abstract: Content-Centric Networking (CCN) naturally supports multi-path communication,\nas it allows the simultaneous use of multiple interfaces (e.g. LTE and WiFi).\nWhen multiple sources and multiple clients are considered, the optimal set of\ndistribution trees should be determined in order to optimally use all the\navailable interfaces. This is not a trivial task, as it is a computationally\nintense procedure that should be done centrally. The need for central\ncoordination can be removed by employing network coding, which also offers\nimproved resiliency to errors and large throughput gains. In this paper, we\npropose NetCodCCN, a protocol for integrating network coding in CCN. In\ncomparison to previous works proposing to enable network coding in CCN,\nNetCodCCN permit Interest aggregation and Interest pipelining, which reduce the\ndata retrieval times. The experimental evaluation shows that the proposed\nprotocol leads to significant improvements in terms of content retrieval delay\ncompared to the original CCN. Our results demonstrate that the use of network\ncoding adds robustness to losses and permits to exploit more efficiently the\navailable network resources. The performance gains are verified for content\nretrieval in various network scenarios. \n\n"}
{"id": "1512.01271", "contents": "Title: Costly Circuits, Submodular Schedules: Hybrid Switch Scheduling for Data\n  Centers Abstract: Hybrid switching - in which a high bandwidth circuit switch (optical or\nwireless) is used in conjunction with a low bandwidth packet switch - is a\npromising alternative to interconnect servers in today's large scale\ndata-centers. Circuit switches offer a very high link rate, but incur a\nnon-trivial reconfiguration delay which makes their scheduling challenging. In\nthis paper, we demonstrate a lightweight, simple and nearly-optimal scheduling\nalgorithm that trades-off configuration costs with the benefits of\nreconfiguration that match the traffic demands. The algorithm has strong\nconnections to submodular optimization, has performance at least half that of\nthe optimal schedule and strictly outperforms state of the art in a variety of\ntraffic demand settings. These ideas naturally generalize: we see that indirect\nrouting leads to exponential connectivity; this is another phenomenon of the\npower of multi hop routing, distinct from the well-known load balancing\neffects. \n\n"}
{"id": "1512.02802", "contents": "Title: Lively quantum walks on cycles Abstract: We introduce a family of quantum walks on cycles parametrized by their\nliveliness, defined by the ability to execute a long-range move. We investigate\nthe behaviour of the probability distribution and time-averaged probability\ndistribution. We show that the liveliness parameter, controlling the magnitude\nof the additional long-range move, has a direct impact on the periodicity of\nthe limiting distribution. We also show that the introduced model provides a\nmethod for network exploration which is robust against trapping. \n\n"}
{"id": "1512.05023", "contents": "Title: Packet Transactions: High-level Programming for Line-Rate Switches Abstract: Many algorithms for congestion control, scheduling, network measurement,\nactive queue management, security, and load balancing require custom processing\nof packets as they traverse the data plane of a network switch. To run at line\nrate, these data-plane algorithms must be in hardware. With today's switch\nhardware, algorithms cannot be changed, nor new algorithms installed, after a\nswitch has been built.\n  This paper shows how to program data-plane algorithms in a high-level\nlanguage and compile those programs into low-level microcode that can run on\nemerging programmable line-rate switching chipsets. The key challenge is that\nthese algorithms create and modify algorithmic state. The key idea to achieve\nline-rate programmability for stateful algorithms is the notion of a packet\ntransaction : a sequential code block that is atomic and isolated from other\nsuch code blocks. We have developed this idea in Domino, a C-like imperative\nlanguage to express data-plane algorithms. We show with many examples that\nDomino provides a convenient and natural way to express sophisticated\ndata-plane algorithms, and show that these algorithms can be run at line rate\nwith modest estimated die-area overhead. \n\n"}
{"id": "1512.05429", "contents": "Title: DNA-GA: A New Approach of Network Performance Analysis Abstract: In this paper, we propose a new approach of network performance analysis,\nwhich is based on our previous works on the deterministic network analysis\nusing the Gaussian approximation (DNA-GA). First, we extend our previous works\nto a signal-to-interference ratio (SIR) analysis, which makes our DNA-GA\nanalysis a formal microscopic analysis tool. Second, we show two approaches for\nupgrading the DNA-GA analysis to a macroscopic analysis tool. Finally, we\nperform a comparison between the proposed DNA-GA analysis and the existing\nmacroscopic analysis based on stochastic geometry. Our results show that the\nDNA-GA analysis possesses a few special features: (i) shadow fading is\nnaturally considered in the DNAGA analysis; (ii) the DNA-GA analysis can handle\nnon-uniform user distributions and any type of multi-path fading; (iii) the\nshape and/or the size of cell coverage areas in the DNA-GA analysis can be made\narbitrary for the treatment of hotspot network scenarios. Thus, DNA-GA analysis\nis very useful for the network performance analysis of the 5th generation (5G)\nsystems with general cell deployment and user distribution, both on a\nmicroscopic level and on a macroscopic level. \n\n"}
{"id": "1512.08867", "contents": "Title: Modelling and Verifying the AODV Routing Protocol Abstract: This paper presents a formal specification of the Ad hoc On-Demand Distance\nVector (AODV) routing protocol using AWN (Algebra for Wireless Networks), a\nrecent process algebra which has been tailored for the modelling of Mobile Ad\nHoc Networks and Wireless Mesh Network protocols. Our formalisation models the\nexact details of the core functionality of AODV, such as route discovery, route\nmaintenance and error handling. We demonstrate how AWN can be used to reason\nabout critical protocol properties by providing detailed proofs of loop freedom\nand route correctness. \n\n"}
{"id": "1601.01116", "contents": "Title: On Measuring the Geographic Diversity of Internet Routes Abstract: Route diversity in networks is elemental for establishing reliable,\nhigh-capacity connections with appropriate security between endpoints. As for\nthe Internet, route diversity has already been studied at both Autonomous\nSystem- and router-level topologies by means of graph theoretical disjoint\npaths. In this paper we complement these approaches by proposing a method for\nmeasuring the diversity of Internet paths in a geographical sense. By\nleveraging the recent developments in IP geolocation we show how to map the\npaths discovered by traceroute into geographically equivalent classes. This\nallows us to identify the geographical footprints of the major transmission\npaths between end-hosts, and building on our observations, we propose a\nquantitative measure for geographical diversity of Internet routes between any\ntwo hosts. \n\n"}
{"id": "1601.01289", "contents": "Title: Internet of Drones Abstract: The Internet of Drones (IoD) is a layered network control architecture\ndesigned mainly for coordinating the access of unmanned aerial vehicles to\ncontrolled airspace, and providing navigation services between locations\nreferred to as nodes. The IoD provides generic services for various drone\napplications such as package delivery, traffic surveillance, search and rescue\nand more. In this paper, we present a conceptual model of how such an\narchitecture can be organized and we specify the features that an IoD system\nbased on our architecture should implement. For doing so, we extract key\nconcepts from three existing large scale networks, namely the air traffic\ncontrol network, the cellular network, and the Internet and explore their\nconnections to our novel architecture for drone traffic management. \n\n"}
{"id": "1601.01348", "contents": "Title: An Online Delay Efficient Packet Scheduler for M2M Traffic in Industrial\n  Automation Abstract: Some Machine-to-Machine (M2M) communication links particularly those in a\nindustrial automation plant have stringent latency requirements. In this paper,\nwe study the delay-performance for the M2M uplink from the sensors to a\nProgrammable Logic Controller (PLC) in a industrial automation scenario. The\nuplink traffic can be broadly classified as either Periodic Update (PU) and\nEvent Driven (ED). The PU arrivals from different sensors are periodic,\nsynchronized by the PLC and need to be processed by a prespecified firm latency\ndeadline. On the other hand, the ED arrivals are random, have low-arrival rate,\nbut may need to be processed quickly depending upon the criticality of the\napplication. To accommodate these contrasting Quality-of-Service (QoS)\nrequirements, we model the utility of PU and ED packets using step function and\nsigmoidal functions of latency respectively. Our goal is to maximize the\noverall system utility while being proportionally fair to both PU and ED data.\nTo this end, we propose a novel online QoS-aware packet scheduler that gives\npriority to ED data as long as that results the latency deadline is met for PU\ndata. However as the size of networks increases, we drop the PU packets that\nfail to meet latency deadline which reduces congestion and improves overall\nsystem utility. Using extensive simulations, we compare the performance of our\nscheme with various scheduling policies such as First-Come-First-Serve (FCFS),\nEarliest-Due-Date (EDD) and (preemptive) priority. We show that our scheme\noutperforms the existing schemes for various simulation scenarios. \n\n"}
{"id": "1601.03876", "contents": "Title: Streaming Big Data meets Backpressure in Distributed Network Computation Abstract: We study network response to queries that require computation of remotely\nlocated data and seek to characterize the performance limits in terms of\nmaximum sustainable query rate that can be satisfied. The available resources\ninclude (i) a communication network graph with links over which data is routed,\n(ii) computation nodes, over which computation load is balanced, and (iii)\nnetwork nodes that need to schedule raw and processed data transmissions. Our\naim is to design a universal methodology and distributed algorithm to\nadaptively allocate resources in order to support maximum query rate. The\nproposed algorithms extend in a nontrivial way the backpressure (BP) algorithm\nto take into account computations operated over query streams. They contribute\nto the fundamental understanding of network computation performance limits when\nthe query rate is limited by both the communication bandwidth and the\ncomputation capacity, a classical setting that arises in streaming big data\napplications in network clouds and fogs. \n\n"}
{"id": "1601.03926", "contents": "Title: Placing Dynamic Content in Caches with Small Population Abstract: This paper addresses a fundamental limitation for the adoption of caching for\nwireless access networks due to small population sizes. This shortcoming is due\nto two main challenges: (i) making timely estimates of varying content\npopularity and (ii) inferring popular content from small samples. We propose a\nframework which alleviates such limitations.\n  To timely estimate varying popularity in a context of a single cache we\npropose an Age-Based Threshold (ABT) policy which caches all contents requested\nmore times than a threshold $\\widetilde N(\\tau)$, where $\\tau$ is the content\nage. We show that ABT is asymptotically hit rate optimal in the many contents\nregime, which allows us to obtain the first characterization of the optimal\nperformance of a caching system in a dynamic context. We then address small\nsample sizes focusing on $L$ local caches and one global cache. On the one hand\nwe show that the global cache learns L times faster by aggregating all requests\nfrom local caches, which improves hit rates. On the other hand, aggregation\nwashes out local characteristics of correlated traffic which penalizes hit\nrate. This motivates coordination mechanisms which combine global learning of\npopularity scores in clusters and LRU with prefetching. \n\n"}
{"id": "1601.05648", "contents": "Title: Safe and Secure Wireless Power Transfer Networks: Challenges and\n  Opportunities in RF-Based Systems Abstract: RF-based wireless power transfer networks (WPTNs) are deployed to transfer\npower to embedded devices over the air via RF waves. Up until now, a\nconsiderable amount of effort has been devoted by researchers to design WPTNs\nthat maximize several objectives such as harvested power, energy outage and\ncharging delay. However, inherent security and safety issues are generally\noverlooked and these need to be solved if WPTNs are to be become widespread.\nThis article focuses on safety and security problems related WPTNs and\nhighlight their cruciality in terms of efficient and dependable operation of\nRF-based WPTNs. We provide a overview of new research opportunities in this\nemerging domain. \n\n"}
{"id": "1601.06043", "contents": "Title: The Past, Present, and Future of Transport-Layer Multipath Abstract: Multipathing in communication networks is gaining momentum due to its\nattractive features of increased reliability, throughput, fault tolerance, and\nload balancing capabilities. In particular, wireless environments and\ndatacenters are envisioned to become largely dependent on the power of\nmultipathing for seamless handovers, virtual machine (VM) migration and in\ngeneral, pooling less proficient resources together for achieving overall high\nproficiency. The transport layer, with its knowledge about end-to-end path\ncharacteristics, is well placed to enhance performance through better\nutilization of multiple paths. Realizing the importance of transport-layer\nmultipath, this paper investigates the modernization of traditional connection\nestablishment, flow control, sequence number splitting, acknowledgement, and\nflow scheduling mechanisms for use with multiple paths. Since congestion\ncontrol defines a fundamental feature of the transport layer, we study the\nworking of multipath rate control and analyze its stability and convergence. We\nalso discuss how various multipath congestion control algorithms differ in\ntheir window increase and decrease functions, their TCP-friendliness, and\nresponsiveness. To the best of our knowledge, this is the first in-depth survey\npaper that has chronicled the evolution of the transport layer of the Internet\nfrom the traditional single-path TCP to the recent development of the modern\nmultipath TCP (MPTCP) protocol. Along with describing the history of this\nevolution, we also highlight in this paper the remaining challenges and\nresearch issues. \n\n"}
{"id": "1601.06065", "contents": "Title: Adaptive CSMA under the SINR Model: Efficient Approximation Algorithms\n  for Throughput and Utility Maximization Abstract: We consider a Carrier Sense Multiple Access (CSMA) based scheduling algorithm\nfor a single-hop wireless network under a realistic\nSignal-to-interference-plus-noise ratio (SINR) model for the interference. We\npropose two local optimization based approximation algorithms to efficiently\nestimate certain attempt rate parameters of CSMA called fugacities. It is known\nthat adaptive CSMA can achieve throughput optimality by sampling feasible\nschedules from a Gibbs distribution, with appropriate fugacities.\nUnfortunately, obtaining these optimal fugacities is an NP-hard problem.\nFurther, the existing adaptive CSMA algorithms use a stochastic gradient\ndescent based method, which usually entails an impractically slow (exponential\nin the size of the network) convergence to the optimal fugacities. To address\nthis issue, we first propose an algorithm to estimate the fugacities, that can\nsupport a given set of desired service rates. The convergence rate and the\ncomplexity of this algorithm are independent of the network size, and depend\nonly on the neighborhood size of a link. Further, we show that the proposed\nalgorithm corresponds exactly to performing the well-known Bethe approximation\nto the underlying Gibbs distribution. Then, we propose another local algorithm\nto estimate the optimal fugacities under a utility maximization framework, and\ncharacterize its accuracy. Numerical results indicate that the proposed methods\nhave a good degree of accuracy, and achieve extremely fast convergence to\nnear-optimal fugacities, and often outperform the convergence rate of the\nstochastic gradient descent by a few orders of magnitude. \n\n"}
{"id": "1601.07322", "contents": "Title: On Optimal Geographical Caching in Heterogeneous Cellular Networks Abstract: In this work we investigate optimal geographical caching in heterogeneous\ncellular networks where different types of base stations (BSs) have different\ncache capacities. Users request files from a content library according to a\nknown probability distribution. The performance metric is the total hit\nprobability, which is the probability that a user at an arbitrary location in\nthe plane will find the content that it requires in one of the BSs that it is\ncovered by.\n  We consider the problem of optimally placing content in all BSs jointly. As\nthis problem is not convex, we provide a heuristic scheme by finding the\noptimal placement policy for one type of base station conditioned on the\nplacement in all other types. We demonstrate that these individual optimization\nproblems are convex and we provide an analytical solution. As an illustration,\nwe find the optimal placement policy of the small base stations (SBSs)\ndepending on the placement policy of the macro base stations (MBSs). We show\nhow the hit probability evolves as the deployment density of the SBSs varies.\nWe show that the heuristic of placing the most popular content in the MBSs is\nalmost optimal after deploying the SBSs with optimal placement policies. Also,\nfor the SBSs no such heuristic can be used; the optimal placement is\nsignificantly better than storing the most popular content. Finally, we show\nthat solving the individual problems to find the optimal placement policies for\ndifferent types of BSs iteratively, namely repeatedly updating the placement\npolicies, does not improve the performance. \n\n"}
{"id": "1602.00377", "contents": "Title: Cellular Underwater Wireless Optical CDMA Network: Potentials and\n  Challenges Abstract: Underwater wireless optical communications is an emerging solution to the\nexpanding demand for broadband links in oceans and seas. In this paper, a\ncellular underwater wireless optical code division multiple-access (UW-OCDMA)\nnetwork is proposed to provide broadband links for commercial and military\napplications. The optical orthogonal codes (OOC) are employed as signature\ncodes of underwater mobile users. Fundamental key aspects of the network such\nas its backhaul architecture, its potential applications and its design\nchallenges are presented. In particular, the proposed network is used as\ninfrastructure of centralized, decentralized and relay-assisted underwater\nsensor networks for high-speed real-time monitoring. Furthermore, a promising\nunderwater localization and positioning scheme based on this cellular network\nis presented. Finally, probable design challenges such as cell edge coverage,\nblockage avoidance, power control and increasing the network capacity are\naddressed. \n\n"}
{"id": "1602.00484", "contents": "Title: Mobile Edge Computing, Fog et al.: A Survey and Analysis of Security\n  Threats and Challenges Abstract: For various reasons, the cloud computing paradigm is unable to meet certain\nrequirements (e.g. low latency and jitter, context awareness, mobility support)\nthat are crucial for several applications (e.g. vehicular networks, augmented\nreality). To fulfil these requirements, various paradigms, such as fog\ncomputing, mobile edge computing, and mobile cloud computing, have emerged in\nrecent years. While these edge paradigms share several features, most of the\nexisting research is compartmentalised; no synergies have been explored. This\nis especially true in the field of security, where most analyses focus only on\none edge paradigm, while ignoring the others. The main goal of this study is to\nholistically analyse the security threats, challenges, and mechanisms inherent\nin all edge paradigms, while highlighting potential synergies and venues of\ncollaboration. In our results, we will show that all edge paradigms should\nconsider the advances in other paradigms. \n\n"}
{"id": "1602.01623", "contents": "Title: Connectivity of Cooperative Ad hoc Networks Abstract: The connectivity properties of ad hoc networks have been extensively studied\nover the past few years, from local observables, to global network properties.\nIn this paper we introduce a novel layer of network dynamics which lives and\nevolves on top of the ad hoc network. Nodes are assumed selfish and a\nsnow-drift type game is defined dictating the way nodes decide to allocate\ntheir cooperative resource efforts towards other nodes in the network. The\ndynamics are strongly coupled with the physical network causing the cooperation\nnetwork topology to converge towards a stable equilibrium state, a global\nmaximum of the total pay-off. We study this convergence from a connectivity\nperspective and analyse the inherent parameter dependence. Moreover, we show\nthat direct reciprocity can be an efficient incentive to promote cooperation\nwithin the network and discuss the analogies between our simple yet tractable\nframework with D2D proximity based services such as LTE-Direct. We argue that\ncooperative network dynamics have many application in ICT, not just ad hoc\nnetworks, and similar models as the one described herein can be devised and\nstudied in their own right. \n\n"}
{"id": "1602.03635", "contents": "Title: Optimization of Caching Devices with Geometric Constraints Abstract: It has been recently advocated that in large communication systems it is\nbeneficial both for the users and for the network as a whole to store content\ncloser to users. One particular implementation of such an approach is to\nco-locate caches with wireless base stations. In this paper we study\ngeographically distributed caching of a fixed collection of files. We model\ncache placement with the help of stochastic geometry and optimize the\nallocation of storage capacity among files in order to minimize the cache miss\nprobability. We consider both per cache capacity constraints as well as an\naverage capacity constraint over all caches. The case of per cache capacity\nconstraints can be efficiently solved using dynamic programming, whereas the\ncase of the average constraint leads to a convex optimization problem. We\ndemonstrate that the average constraint leads to significantly smaller cache\nmiss probability. Finally, we suggest a simple LRU-based policy for\ngeographically distributed caching and show that its performance is close to\nthe optimal. \n\n"}
{"id": "1602.03706", "contents": "Title: SDxVPN: A Software-Defined Solution for VPN Service Providers Abstract: BGP/MPLS IP VPN and VPLS services are considered to be widely used in IP/MPLS\nnetworks for connecting customers' remote sites. However, service providers\nstruggle with many challenges to provide these services. Management complexity,\nequipment costs, and last but not least, scalability issues emerging as the\ncustomers increase in number, are just some of these problems. Software-defined\nnetworking (SDN) is an emerging paradigm that can solve aforementioned issues\nusing a logically centralized controller for network devices. In this paper, we\npropose a SDN-based solution called SDxVPN which considerably lowers the\ncomplexity of VPN service definition and management. Our method eliminates\ncomplex and costly device interactions that used to be done through several\ncontrol plane protocols and enables customers to determine their service\nspecifications, define restriction policies and even interconnect with other\ncustomers automatically without operator's intervention. We describe our\nprototype implementation of SDxVPN and its scalability evaluations under\nseveral representative scenarios. The results indicate the effectiveness of the\nproposed solution for deployment to provide large scale VPN services. \n\n"}
{"id": "1602.05853", "contents": "Title: XBF: Scaling up Bloom-filter-based Source Routing Abstract: A well known drawback of IP-multicast is that it requires per-group state to\nbe stored in the routers. Bloom-filter based source-routed multicast remedies\nthis problem by moving the state from the routers to the packets. However, a\nfixed sized Bloom-filter can only store a limited number of items before the\nfalse positive ratio grows too high implying scalability issues. Several\nproposals have tried to address these scalability issues in Bloom-filter\nforwarding. These proposals, however, unnecessarily increase the forwarding\ncomplexity.\n  In this paper, we present Extensible-Bloom-filter (XBF), a new framing and\nforwarding solution which effectively circumvents the aforementioned drawbacks.\nXBF partitions a network into sub-networks that reflect the network topology\nand traffic patterns, and uses a separate fixed-length Bloom-filter in each of\nthese. We formulate this partition assignment problem into a balanced edge\npartitioning problem, and evaluate it with simulations on realistic topologies.\nOur results show that XBF scales to very large networks with minimal overhead\nand completely eliminates the false-positives that have plagued the traditional\nBloom-filter-based forwarding protocols. It furthermore integrates with SDN\nenvironments, making it highly suitable for deployments in off-the-shelf\nSDN-based networks. \n\n"}
{"id": "1602.06045", "contents": "Title: Programmable Packet Scheduling Abstract: Switches today provide a small set of scheduling algorithms. While we can\ntweak scheduling parameters, we cannot modify algorithmic logic, or add a\ncompletely new algorithm, after the switch has been designed. This paper\npresents a design for a programmable packet scheduler, which allows scheduling\nalgorithms---potentially algorithms that are unknown today---to be programmed\ninto a switch without requiring hardware redesign.\n  Our design builds on the observation that scheduling algorithms make two\ndecisions: in what order to schedule packets and when to schedule them.\nFurther, in many scheduling algorithms these decisions can be made when packets\nare enqueued. We leverage this observation to build a programmable scheduler\nusing a single abstraction: the push-in first-out queue (PIFO), a priority\nqueue that maintains the scheduling order and time for such algorithms.\n  We show that a programmable scheduler using PIFOs lets us program a wide\nvariety of scheduling algorithms. We present a detailed hardware design for\nthis scheduler for a 64-port 10 Gbit/s shared-memory switch with <4% chip area\noverhead on a 16-nm standard-cell library. Our design lets us program many\nsophisticated algorithms, such as a 5-level hierarchical scheduler with\nprogrammable scheduling algorithms at each level. \n\n"}
{"id": "1602.06925", "contents": "Title: Achieving Ultra-Low Latency in 5G Millimeter Wave Cellular Networks Abstract: The IMT 2020 requirements of 20 Gbps peak data rate and 1 millisecond latency\npresent significant engineering challenges for the design of 5G cellular\nsystems. Use of the millimeter wave (mmWave) bands above 10 GHz --- where vast\nquantities of spectrum are available --- is a promising 5G candidate that may\nbe able to rise to the occasion.\n  However, while the mmWave bands can support massive peak data rates,\ndelivering these data rates on end-to-end service while maintaining reliability\nand ultra-low latency performance will require rethinking all layers of the\nprotocol stack. This papers surveys some of the challenges and possible\nsolutions for delivering end-to-end, reliable, ultra-low latency services in\nmmWave cellular systems in terms of the Medium Access Control (MAC) layer,\ncongestion control and core network architecture. \n\n"}
{"id": "1602.07112", "contents": "Title: Multipath streaming: fundamental limits and efficient algorithms Abstract: We investigate streaming over multiple links. A file is split into small\nunits called chunks that may be requested on the various links according to\nsome policy, and received after some random delay. After a start-up time called\npre-buffering time, received chunks are played at a fixed speed. There is\nstarvation if the chunk to be played has not yet arrived. We provide lower\nbounds (fundamental limits) on the starvation probability of any policy. We\nfurther propose simple, order-optimal policies that require no feedback. For\ngeneral delay distributions, we provide tractable upper bounds for the\nstarvation probability of the proposed policies, allowing to select the\npre-buffering time appropriately. We specialize our results to: (i) links that\nemploy CSMA or opportunistic scheduling at the packet level, (ii) links shared\nwith a primary user (iii) links that use fair rate sharing at the flow level.\nWe consider a generic model so that our results give insight into the design\nand performance of media streaming over (a) wired networks with several paths\nbetween the source and destination, (b) wireless networks featuring spectrum\naggregation and (c) multi-homed wireless networks. \n\n"}
{"id": "1602.07731", "contents": "Title: Initial Access in 5G mm-Wave Cellular Networks Abstract: The massive amounts of bandwidth available at millimeter-wave frequencies\n(roughly above 10 GHz) have the potential to greatly increase the capacity of\nfifth generation cellular wireless systems. However, to overcome the high\nisotropic pathloss experienced at these frequencies, high directionality will\nbe required at both the base station and the mobile user equipment to establish\nsufficient link budget in wide area networks. This reliance on directionality\nhas important implications for control layer procedures. Initial access in\nparticular can be significantly delayed due to the need for the base station\nand the user to find the proper alignment for directional transmission and\nreception. This paper provides a survey of several recently proposed techniques\nfor this purpose. A coverage and delay analysis is performed to compare various\ntechniques including exhaustive and iterative search, and Context Information\nbased algorithms. We show that the best strategy depends on the target SNR\nregime, and provide guidelines to characterize the optimal choice as a function\nof the system parameters. \n\n"}
{"id": "1602.08156", "contents": "Title: Capacitated Kinetic Clustering in Mobile Networks by Optimal\n  Transportation Theory Abstract: We consider the problem of capacitated kinetic clustering in which $n$ mobile\nterminals and $k$ base stations with respective operating capacities are given.\nThe task is to assign the mobile terminals to the base stations such that the\ntotal squared distance from each terminal to its assigned base station is\nminimized and the capacity constraints are satisfied. This paper focuses on the\ndevelopment of \\emph{distributed} and computationally efficient algorithms that\nadapt to the motion of both terminals and base stations. Suggested by the\noptimal transportation theory, we exploit the structural property of the\noptimal solution, which can be represented by a power diagram on the base\nstations such that the total usage of nodes within each power cell equals the\ncapacity of the corresponding base station. We show by using the kinetic data\nstructure framework the first analytical upper bound on the number of changes\nin the optimal solution, i.e., its stability. On the algorithm side, using the\npower diagram formulation we show that the solution can be represented in size\nproportional to the number of base stations and can be solved by an iterative,\nlocal algorithm. In particular, this algorithm can naturally exploit the\ncontinuity of motion and has orders of magnitude faster than existing solutions\nusing min-cost matching and linear programming, and thus is able to handle\nlarge scale data under mobility. \n\n"}
{"id": "1602.08290", "contents": "Title: Explicit back-off rates for achieving target throughputs in CSMA/CA\n  networks Abstract: CSMA/CA networks have often been analyzed using a stylized model that is\nfully characterized by a vector of back-off rates and a conflict graph.\nFurther, for any achievable throughput vector $\\vec \\theta$ the existence of a\nunique vector $\\vec \\nu(\\vec \\theta)$ of back-off rates that achieves this\nthroughput vector was proven. Although this unique vector can in principle be\ncomputed iteratively, the required time complexity grows exponentially in the\nnetwork size, making this only feasible for small networks.\n  In this paper, we present an explicit formula for the unique vector of\nback-off rates $\\vec \\nu(\\vec \\theta)$ needed to achieve any achievable\nthroughput vector $\\vec \\theta$ provided that the network has a chordal\nconflict graph. This class of networks contains a number of special cases of\ninterest such as (inhomogeneous) line networks and networks with an acyclic\nconflict graph. Moreover, these back-off rates are such that the back-off rate\nof a node only depends on its own target throughput and the target throughput\nof its neighbors and can be determined in a distributed manner.\n  We further indicate that back-off rates of this form cannot be obtained in\ngeneral for networks with non-chordal conflict graphs. For general conflict\ngraphs we nevertheless show how to adapt the back-off rates when a node is\nadded to the network when its interfering nodes form a clique in the conflict\ngraph. Finally, we introduce a distributed chordal approximation algorithm for\ngeneral conflict graphs which is shown (using numerical examples) to be more\naccurate than the Bethe approximation. \n\n"}
{"id": "1602.08658", "contents": "Title: Interference Avoidance Algorithm (IAA) for Multi-hop Wireless Body Area\n  Network Communication Abstract: In this paper, we propose a distributed multi-hop interference avoidance\nalgorithm, namely, IAA to avoid co-channel interference inside a wireless body\narea network (WBAN). Our proposal adopts carrier sense multiple access with\ncollision avoidance (CSMA/CA) between sources and relays and a flexible time\ndivision multiple access (FTDMA) between relays and coordinator. The proposed\nscheme enables low interfering nodes to transmit their messages using base\nchannel. Depending on suitable situations, high interfering nodes double their\ncontention windows (CW) and probably use switched orthogonal channel.\nSimulation results show that proposed scheme has far better minimum SINR (12dB\nimprovement) and longer energy lifetime than other schemes (power control and\nopportunistic relaying). Additionally, we validate our proposal in a\ntheoretical analysis and also propose a probabilistic approach to prove the\noutage probability can be effectively reduced to the minimal. \n\n"}
{"id": "1602.08710", "contents": "Title: Dynamic Channel Access Scheme for Interference Mitigation in\n  Relay-assisted Intra-WBANs Abstract: This work addresses problems related to interference mitigation in a single\nwireless body area network (WBAN). In this paper, We propose a distributed\n\\textit{C}ombined carrier sense multiple access with collision avoidance\n(CSMA/CA) with \\textit{F}lexible time division multiple access (\\textit{T}DMA)\nscheme for \\textit{I}nterference \\textit{M}itigation in relay-assisted\nintra-WBAN, namely, CFTIM. In CFTIM scheme, non interfering sources\n(transmitters) use CSMA/CA to communicate with relays. Whilst, high interfering\nsources and best relays use flexible TDMA to communicate with coordinator (C)\nthrough using stable channels. Simulation results of the proposed scheme are\ncompared to other schemes and consequently CFTIM scheme outperforms in all\ncases. These results prove that the proposed scheme mitigates interference,\nextends WBAN energy lifetime and improves the throughput. To further reduce the\ninterference level, we analytically show that the outage probability can be\neffectively reduced to the minimal. \n\n"}
{"id": "1603.00300", "contents": "Title: Efficient 3-D Placement of an Aerial Base Station in Next Generation\n  Cellular Networks Abstract: Agility and resilience requirements of future cellular networks may not be\nfully satisfied by terrestrial base stations in cases of unexpected or\ntemporary events. A promising solution is assisting the cellular network via\nlow-altitude unmanned aerial vehicles equipped with base stations, i.e.,\ndrone-cells. Although drone-cells provide a quick deployment opportunity as\naerial base stations, efficient placement becomes one of the key issues. In\naddition to mobility of the drone-cells in the vertical dimension as well as\nthe horizontal dimension, the differences between the air-to-ground and\nterrestrial channels cause the placement of the drone-cells to diverge from\nplacement of terrestrial base stations. In this paper, we first highlight the\nproperties of the dronecell placement problem, and formulate it as a 3-D\nplacement problem with the objective of maximizing the revenue of the network.\nAfter some mathematical manipulations, we formulate an equivalent\nquadratically-constrained mixed integer non-linear optimization problem and\npropose a computationally efficient numerical solution for this problem. We\nverify our analytical derivations with numerical simulations and enrich them\nwith discussions which could serve as guidelines for researchers, mobile\nnetwork operators, and policy makers. \n\n"}
{"id": "1603.00589", "contents": "Title: Generalized Analysis of Convergence of Absolute Trust in Peer to Peer\n  Networks Abstract: Open and anonymous nature of peer to peer networks provides an opportunity to\nmalicious peers to behave unpredictably in the network. This leads the lack of\ntrust among the peers. To control the behavior of peers in the network,\nreputation system can be used. In a reputation system, aggregation of trust is\na primary issue. Algorithm for aggregation of trust should be designed such\nthat, it can converge to a certain finite value. Absolute Trust is one of the\nalgorithm, which is used for the aggregation of trust in peer to peer networks.\nIn this letter, we present the generalized analysis of convergence of the\nAbsolute Trust algorithm. \n\n"}
{"id": "1603.01921", "contents": "Title: Optimal Geographic Caching in Finite Wireless Networks Abstract: Cache-enabled device-to-device (D2D) networks turn memory of the devices at\nthe network edge, such as smart phones and tablets, into bandwidth by enabling\nasynchronous content sharing directly between proximate devices. Limited\nstorage capacity of the mobile devices necessitates the determination of\noptimal set of contents to be cached on each device. In order to study the\nproblem of optimal cache placement, we model the locations of devices in a\nfinite region (e.g., coffee shop, sports bar, library) as a uniform binomial\npoint process (BPP). For this setup, we first develop a generic framework to\nanalyze the coverage probability of the target receiver (target-Rx) when the\nrequested content is available at the $k^{th}$ closest device to it. Using this\ncoverage probability result, we evaluate optimal caching probability of the\npopular content to maximize the total hit probability. Our analysis concretely\ndemonstrates that optimal caching probability strongly depends on the number of\nsimultaneously active devices in the network. \n\n"}
{"id": "1603.02472", "contents": "Title: Anticipatory Radio Resource Management for Mobile Video Streaming with\n  Linear Programming Abstract: In anticipatory networking, channel prediction is used to improve\ncommunication performance. This paper describes a new approach for allocating\nresources to video streaming traffic while accounting for quality of service.\nThe proposed method is based on integrating a model of the user's local\nplay-out buffer into the radio access network. The linearity of this model\nallows to formulate a Linear Programming problem that optimizes the trade-off\nbetween the allocated resources and the stalling time of the media stream. Our\nsimulation results demonstrate the full power of anticipatory optimization in a\nsimple, yet representative, scenario. Compared to instantaneous adaptation, our\nanticipatory solution shows impressive gains in spectral efficiency and\nstalling duration at feasible computation time while being robust against\nprediction errors. \n\n"}
{"id": "1603.07052", "contents": "Title: Cluster Content Caching: An Energy-Efficient Approach to Improve Quality\n  of Service in Cloud Radio Access Networks Abstract: In cloud radio access networks (C-RANs), a substantial amount of data must be\nexchanged in both backhaul and fronthaul links, which causes high power\nconsumption and poor quality of service (QoS) experience for real-time\nservices. To solve this problem, a cluster content caching structure is\nproposed in this paper, which takes full advantage of distributed caching and\ncentralized signal processing. In particular, redundant traffic on the backhaul\ncan be reduced because the cluster content cache provides a part of required\ncontent objects for remote radio heads (RRHs) connected to a common edge cloud.\nTractable expressions for both effective capacity and energy efficiency\nperformance are derived, which show that the proposed structure can improve QoS\nguarantees with a lower power cost of local storage. Furthermore, to fully\nexplore the potential of the proposed cluster content caching structure, the\njoint design of resource allocation and RRH association is optimized, and two\ndistributed algorithms are accordingly proposed. Simulation results verify the\naccuracy of the analytical results and show the performance gains achieved by\ncluster content caching in C-RANs. \n\n"}
{"id": "1603.07322", "contents": "Title: On Delay-Optimal Scheduling in Queueing Systems with Replications Abstract: In modern computer systems, jobs are divided into short tasks and executed in\nparallel. Empirical observations in practical systems suggest that the task\nservice times are highly random and the job service time is bottlenecked by the\nslowest straggling task. One common solution for straggler mitigation is to\nreplicate a task on multiple servers and wait for one replica of the task to\nfinish early. The delay performance of replications depends heavily on the\nscheduling decisions of when to replicate, which servers to replicate on, and\nwhich job to serve first. So far, little is understood on how to optimize these\nscheduling decisions for minimizing the delay to complete the jobs. In this\npaper, we present a comprehensive study on delay-optimal scheduling of\nreplications in both centralized and distributed multi-server systems.\nLow-complexity scheduling policies are designed and are proven to be\ndelay-optimal or near delay-optimal in stochastic ordering among all causal and\nnon-preemptive policies. These theoretical results are established for general\nsystem settings and delay metrics that allow for arbitrary arrival processes,\narbitrary job sizes, arbitrary due times, and heterogeneous servers with data\nlocality constraints. Novel sample-path tools are developed to prove these\nresults. \n\n"}
{"id": "1603.07431", "contents": "Title: Approximate Networking for Global Access to the Internet for All (GAIA) Abstract: Decades of experience have shown that there is no single one-size-fits-all\nsolution that can be used to provision Internet globally and that invariably\nthere are tradeoffs in the design of Internet. Despite the best efforts of\nnetworking researchers and practitioners, an ideal Internet experience is\ninaccessible to an overwhelming majority of people the world over, mainly due\nto the lack of cost efficient ways of provisioning high-performance global\nInternet. In this paper, we argue that instead of an exclusive focus on a\nutopian goal of universally accessible \"ideal networking\" (in which we have\nhigh throughput and quality of service as well as low latency and congestion),\nwe should consider providing \"approximate networking\" through the adoption of\ncontext-appropriate tradeoffs. Approximate networking can be used to implement\na pragmatic tiered global access to the Internet for all (GAIA) system in which\ndifferent users the world over have different context-appropriate (but still\ncontextually functional) Internet experience. \n\n"}
{"id": "1603.07650", "contents": "Title: Decoding and File Transfer Delay Balancing in Network Coding Broadcast Abstract: Network Coding is a packet encoding technique which has recently been shown\nto improve network performance (by reducing delays and increasing throughput)\nin broadcast and multicast communications. The cost for such an improvement\ncomes in the form of increased decoding complexity (and thus delay) at the\nreceivers end. Before delivering the file to higher layers, the receiver should\nfirst decode those packets. In our work we consider the broadcast transmission\nof a large file to N wireless users. The file is segmented into a number of\nblocks (each containing K packets - the Coding Window Size). The packets of\neach block are encoded using Random Linear Network Coding (RLNC).We obtain the\nminimum coding window size so that the completion time of the file transmission\nis upper bounded by a used defined delay constraint. \n\n"}
{"id": "1603.07825", "contents": "Title: Loss Tomography in General Topology Abstract: Although there are a few works reported in the literature considering loss\ntomography in the general topology, there is few well established result since\nall of them rely either on simulations or on experiments that have many random\nfactors affecting the outcome. To improve the situation, we address a number of\nissues in this paper that include a maximum likelihood estimator (MLE) for the\ngeneral topology, the statistical properties of the MLE, the statistical\nproperties of a frequently referred estimator called the moving variance and\nweighted average (MVWA), and a renewed MVWA that removes the restriction of\nknowing variance in advance from the MVWA. The statistical properties covers\nminimum-variance unbiasedness, efficiency, and variances of the estimates\nobtained by the estimators. Given the properties, we can evaluate the\nestimators without the need of simulations. To verify the properties, a\nsimulation study is conducted that confirms the accuracy of the findings. \n\n"}
{"id": "1603.08885", "contents": "Title: On the Performance of Delay Aware Shared Access with Priorities Abstract: In this paper, we analyze a shared access network with a fixed primary node\nand randomly distributed secondary nodes whose distribution follows a Poisson\npoint process (PPP). The secondaries use a random access protocol allowing them\nto access the channel with probabilities that depend on the queue size of the\nprimary. Assuming a system with multipacket reception (MPR) receivers having\nbursty packet arrivals at the primary and saturation at the secondaries, our\nprotocol can be tuned to alleviate congestion at the primary. We study the\nthroughput of the secondary network and the primary average delay, as well as\nthe impact of the secondary node access probability and transmit power. We\nformulate an optimization problem to maximize the throughput of the secondary\nnetwork under delay constraints for the primary node, which in the case that no\ncongestion control is performed has a closed form expression providing the\noptimal access probability. Our numerical results illustrate the impact of\nnetwork operating parameters on the performance of the proposed priority-based\nshared access protocol. \n\n"}
{"id": "1603.09537", "contents": "Title: Will 5G See its Blind Side? Evolving 5G for Universal Internet Access Abstract: Internet has shown itself to be a catalyst for economic growth and social\nequity but its potency is thwarted by the fact that the Internet is off limits\nfor the vast majority of human beings. Mobile phones---the fastest growing\ntechnology in the world that now reaches around 80\\% of humanity---can enable\nuniversal Internet access if it can resolve coverage problems that have\nhistorically plagued previous cellular architectures (2G, 3G, and 4G). These\nconventional architectures have not been able to sustain universal service\nprovisioning since these architectures depend on having enough users per cell\nfor their economic viability and thus are not well suited to rural areas (which\nare by definition sparsely populated). The new generation of mobile cellular\ntechnology (5G), currently in a formative phase and expected to be finalized\naround 2020, is aimed at orders of magnitude performance enhancement. 5G offers\na clean slate to network designers and can be molded into an architecture also\namenable to universal Internet provisioning. Keeping in mind the great social\nbenefits of democratizing Internet and connectivity, we believe that the time\nis ripe for emphasizing universal Internet provisioning as an important goal on\nthe 5G research agenda. In this paper, we investigate the opportunities and\nchallenges in utilizing 5G for global access to the Internet for all (GAIA). We\nhave also identified the major technical issues involved in a 5G-based GAIA\nsolution and have set up a future research agenda by defining open research\nproblems. \n\n"}
{"id": "1604.00074", "contents": "Title: Waveform Design for Wireless Power Transfer Abstract: Far-field Wireless Power Transfer (WPT) has attracted significant attention\nin recent years. Despite the rapid progress, the emphasis of the research\ncommunity in the last decade has remained largely concentrated on improving the\ndesign of energy harvester (so-called rectenna) and has left aside the effect\nof transmitter design. In this paper, we study the design of transmit waveform\nso as to enhance the DC power at the output of the rectenna. We derive a\ntractable model of the non-linearity of the rectenna and compare with a linear\nmodel conventionally used in the literature. We then use those models to design\nnovel multisine waveforms that are adaptive to the channel state information\n(CSI). Interestingly, while the linear model favours narrowband transmission\nwith all the power allocated to a single frequency, the non-linear model\nfavours a power allocation over multiple frequencies. Through realistic\nsimulations, waveforms designed based on the non-linear model are shown to\nprovide significant gains (in terms of harvested DC power) over those designed\nbased on the linear model and over non-adaptive waveforms. We also compute\nanalytically the theoretical scaling laws of the harvested energy for various\nwaveforms as a function of the number of sinewaves and transmit antennas. Those\nscaling laws highlight the benefits of CSI knowledge at the transmitter in WPT\nand of a WPT design based on a non-linear rectenna model over a linear model.\nResults also motivate the study of a promising architecture relying on\nlarge-scale multisine multi-antenna waveforms for WPT. As a final note, results\nstress the importance of modeling and accounting for the non-linearity of the\nrectenna in any system design involving wireless power. \n\n"}
{"id": "1604.00381", "contents": "Title: The New Frontier in RAN Heterogeneity: Multi-tier Drone-Cells Abstract: In cellular networks, the locations of the radio access network (RAN)\nelements are determined mainly based on the long-term traffic behaviour.\nHowever, when the random and hard-to-predict spatio-temporal distribution of\nthe traffic (load,demand) does not fully match the fixed locations of the RAN\nelements (supply), some performance degradation becomes inevitable. The concept\nof multi-tier cells (heterogeneous networks, HetNets) has been introduced in 4G\nnetworks to alleviate this mismatch. However, as the traffic distribution\ndeviates more and more from the long-term average, even the HetNet architecture\nwill have difficulty in coping up with the erratic supply-demand mismatch,\nunless the RAN is grossly over-engineered (which is a financially non-viable\nsolution). In this article, we study the opportunistic utilization of\nlow-altitude unmanned aerial platforms equipped with base stations (BSs), i.e.,\ndrone-BSs, in 5G networks. In particular, we envisage a multi-tier drone-cell\nnetwork complementing the terrestrial HetNets. The variety of equipment, and\nnon-rigid placement options allow utilizing multitier drone-cell networks to\nserve diversified demands. Hence, drone-cells bring the supply to where the\ndemand is, which sets new frontiers for the heterogeneity in 5G networks. We\ninvestigate the advancements promised by drone-cells, and discuss the\nchallenges associated with their operation and management. We propose a\ndrone-cell management framework (DMF) benefiting from the synergy among\nsoftware defined networking (SDN), network functions virtualization (NFV), and\ncloud-computing. We demonstrate DMF mechanisms via a case study, and\nnumerically show that it can reduce the cost of utilizing drone-cells in\nmultitenancy cellular networks. \n\n"}
{"id": "1604.01276", "contents": "Title: Programmable Multi-Node Quantum Network Design and Simulation Abstract: Software-defined networking offers a device-agnostic programmable framework\nto encode new network functions. Externally centralized control plane\nintelligence allows programmers to write network applications and to build\nfunctional network designs. OpenFlow is a key protocol widely adopted to build\nprogrammable networks because of its programmability, flexibility and ability\nto interconnect heterogeneous network devices. We simulate the functional\ntopology of a multi-node quantum network that uses programmable network\nprinciples to manage quantum metadata for protocols such as teleportation,\nsuperdense coding, and quantum key distribution. We first show how the OpenFlow\nprotocol can manage the quantum metadata needed to control the quantum channel.\nWe then use numerical simulation to demonstrate robust programmability of a\nquantum switch via the OpenFlow network controller while executing an\napplication of superdense coding. We describe the software framework\nimplemented to carry out these simulations and we discuss near-term efforts to\nrealize these applications. \n\n"}
{"id": "1604.02986", "contents": "Title: Stronger wireless signals appear more Poisson Abstract: Keeler, Ross and Xia (2016) recently derived approximation and convergence\nresults, which imply that the point process formed from the signal strengths\nreceived by an observer in a wireless network under a general statistical\npropagation model can be modelled by an inhomogeneous Poisson point process on\nthe positive real line. The basic requirement for the results to apply is that\nthere must be a large number of transmitters with different locations and\nrandom propagation effects.The aim of this note is to apply some of the main\nresults of Keeler, Ross and Xia (2016) in a less general but more easily\napplicable form to illustrate how the results can be applied in practice. New\nresults are derived that show that it is the strongest signals, after being\nweakened by random propagation effects, that behave like a Poisson process,\nwhich supports recent experimental work. \n\n"}
{"id": "1604.03183", "contents": "Title: A Primer on Cellular Network Analysis Using Stochastic Geometry Abstract: This tutorial is intended as an accessible but rigorous first reference for\nsomeone interested in learning how to model and analyze cellular network\nperformance using stochastic geometry. In particular, we focus on computing the\nsignal-to-interference-plus-noise ratio (SINR) distribution, which can be\ncharacterized by the coverage probability (the SINR CCDF) or the outage\nprobability (its CDF). We model base stations (BSs) in the network as a\nrealization of a homogeneous Poisson point process of density $\\lambda$, and\ncompute the SINR for three main cases: the downlink, uplink, and finally the\nmulti-tier downlink, which is characterized by having $k$ tiers of BSs each\nwith a unique density $\\lambda_i$ and transmit power $p_i$. These three\nbaseline results have been extensively extended to many different scenarios,\nand we conclude with a brief summary of some of those extensions. \n\n"}
{"id": "1604.04457", "contents": "Title: A 3D Spatial Fluid Model for Wireless Networks Abstract: In this article we develop a three dimensional (3D) analytical model of\nwireless networks. We establish an analytical expression of the SINR (Signal to\nInterference plus Noise Ratio) of user equipments (UE), by using a 3D fluid\nmodel approach of the network. This model enables to evaluate in a simple way\nthe cumulative distribution function of the SINR, and therefore the\nperformance, the quality of service and the coverage of wireless networks, with\na high accuracy. The use of this 3D wireless network model, instead of a\nstandard two-dimensional one, in order to analyze wireless networks, is\nparticularly interesting. Indeed, this 3D model enables to establish more\naccurate performance and quality of services results than a 2D one. \n\n"}
{"id": "1604.04640", "contents": "Title: Coverage Gains from the Static Cooperation of Mutually Nearest\n  Neighbours Abstract: Cooperation in cellular networks has been recently suggested as a promising\nscheme to improve system performance. In this work, clusters are formed based\non the Mutually Nearest Neighbour relation, which defines which stations\ncooperate in pair and which do not. When node positions follow a Poisson Point\nProcess (PPP) the performance of the original clustering model can be\napproximated by another one, formed by the superposition of two PPPs (one for\nthe singles and one for the pairs) equipped with adequate marks. This allows to\nderive exact expressions for the network coverage probability under two\nuser-cluster association rules. Numerical evaluation shows coverage gains from\ndifferent signal cooperation schemes that can reach up to 15% compared to the\nstandard non-cooperative network coverage. The analysis is general and can be\napplied to any type of cooperation or coordination between pairs of\ntransmitting nodes. \n\n"}
{"id": "1604.05355", "contents": "Title: Technical Report: Design, Implementation and Deployment of\n  Intermittency-aware Cellular Edge Services for Rural areas Abstract: Rural areas continue to be plagued by limited data connectivity due to poor\nand unreliable power infrastructure, poor backhaul connectivity and lack of\neconomic incentives for telecom providers. These factors continue to be an\nimpediment to providing reliable, highly available and bandwidth intensive\nmobile services and applications to function well in such contexts. This paper\npresents the design, implementation and deployment of GreenLinks, a new\nground-up platform that enables intermittency-aware, reliable and available\ncellular services and application support in rural contexts under extreme\noperational environments with limited power and no existing cellular coverage.\nUnlike the conventional monolithic cellular network architecture, GreenLinks\nenables a distributed (and potentially disjoint) collection of open,\nprogrammable cellular base stations to offer a gamut of both conventional\ncellular services and new forms of distributed edge services. GreenLinks offers\nnew application primitives to support different types of intermittency-aware\ndistributed mobile edge services including P2P transactions, voice-based social\nmedia applications, and distributed mobile sensing applications. Using a\nparticipatory sensing white spaces approach, a GreenLinks base stati \n\n"}
{"id": "1604.05622", "contents": "Title: Understanding Noise and Interference Regimes in 5G Millimeter-Wave\n  Cellular Networks Abstract: With the severe spectrum shortage in conventional cellular bands,\nmillimeter-wave (mmWave) frequencies have been attracting growing attention for\nnext-generation micro- and picocellular wireless networks. A fundamental and\nopen question is whether mmWave cellular networks are likely to be noise- or\ninterference-limited. Identifying in which regime a network is operating is\ncritical for the design of MAC and physical-layer procedures and to provide\ninsights on how transmissions across cells should be coordinated to cope with\ninterference. This work uses the latest measurement-based statistical channel\nmodels to accurately assess the Interference-to-Noise Ratio (INR) in a wide\nrange of deployment scenarios. In addition to cell density, we also study\nantenna array size and antenna patterns, whose effects are critical in the\nmmWave regime. The channel models also account for blockage, line-of-sight and\nnon-line-of-sight regimes as well as local scattering, that significantly\naffect the level of spatial isolation. \n\n"}
{"id": "1604.05623", "contents": "Title: Channel Dynamics and SNR Tracking in Millimeter Wave Cellular Systems Abstract: The millimeter wave (mmWave) frequencies are likely to play a significant\nrole in fifth-generation (5G) cellular systems. A key challenge in developing\nsystems in these bands is the potential for rapid channel dynamics: since\nmmWave signals are blocked by many materials, small changes in the position or\norientation of the handset relative to objects in the environment can cause\nlarge swings in the channel quality. This paper addresses the issue of tracking\nthe signal to noise ratio (SNR), which is an essential procedure for rate\nprediction, handover and radio link failure detection. A simple method for\nestimating the SNR from periodic synchronization signals is considered. The\nmethod is then evaluated using real experiments in common blockage scenarios\ncombined with outdoor statistical models. \n\n"}
{"id": "1604.06588", "contents": "Title: Radio Access Network and Spectrum Sharing in Mobile Networks: A\n  Stochastic Geometry Perspective Abstract: Next generation mobile networks will rely ever more heavily on resource\nsharing. In this article we study the sharing of radio access network and\nspectrum among mobile operators. We assess the impact of sharing these two\ntypes of resources on the performance of spatially distributed mobile networks.\nWe apply stochastic geometry to observe the combined effect of, for example,\nthe level of spatial clustering among the deployed base stations, the shared\nnetwork size, or the coordination in shared spectrum use on network coverage\nand expected user data rate. We uncover some complex effects of mobile network\nresource sharing, which involve non-linearly scaling gains and performance\ntrade-offs related to the sharing scenario or the spatial clustering level. \n\n"}
{"id": "1604.07179", "contents": "Title: Modeling and Efficient Verification of Wireless Ad hoc Networks Abstract: Wireless ad hoc networks, in particular mobile ad hoc networks (MANETs), are\ngrowing very fast as they make communication easier and more available.\nHowever, their protocols tend to be difficult to design due to topology\ndependent behavior of wireless communication, and their distributed and\nadaptive operations to topology dynamism. Therefore, it is desirable to have\nthem modeled and verified using formal methods. In this paper, we present an\nactor-based modeling language with the aim to model MANETs. We address main\nchallenges of modeling wireless ad hoc networks such as local broadcast,\nunderlying topology, and its changes, and discuss how they can be efficiently\nmodeled at the semantic level to make their verification amenable. The new\nframework abstracts the data link layer services by providing asynchronous\n(local) broadcast and unicast communication, while message delivery is in order\nand is guaranteed for connected receivers. We illustrate the applicability of\nour framework through two routing protocols, namely flooding and AODVv2-11, and\nshow how efficiently their state spaces can be reduced by the proposed\ntechniques. Furthermore, we demonstrate a loop formation scenario in AODV,\nfound by our analysis tool. \n\n"}
{"id": "1604.08618", "contents": "Title: Stringer: Balancing Latency and Resource Usage in Service Function Chain\n  Provisioning Abstract: Network Functions Virtualization, or NFV, enables telecommunications\ninfrastructure providers to replace special-purpose networking equipment with\ncommodity servers running virtualized network functions (VNFs). A service\nprovider utilizing NFV technology faces the SFC provisioning problem of\nassigning VNF instances to nodes in the physical infrastructure (e.g., a\ndatacenter), and routing Service Function Chains (sequences of functions\nrequired by customers, a.k.a. SFCs) in the physical network. In doing so, the\nprovider must balance between various competing goals of performance and\nresource usage. We present an approach for SFC provisioning, consisting of\nthree elements. The first element is a fast, scalable round-robin heuristic.\nThe second element is a Mixed Integer Programming (MIP) based approach. The\nthird element is a queueing-theoretic model to estimate the average latency\nassociated with any SFC provisioning solution. Combined, these elements create\nan approach that generates a set of SFC provisioning solutions, reflecting\ndifferent tradeoffs between resource usage and performance. \n\n"}
{"id": "1604.08744", "contents": "Title: Enabling Relaying Over Heterogeneous Backhauls in the Uplink of Wireless\n  Femtocell Networks Abstract: In this paper, we develop novel two-tier interference management strategies\nthat enable macrocell users (MUEs) to improve their performance, with the help\nof open-access femtocells. To this end, we propose a rate-splitting technique\nusing which the MUEs optimize their uplink transmissions by dividing their\nsignals into two types: a coarse message that is intended for direct\ntransmission to the macrocell base station and a fine message that is decoded\nby a neighboring femtocell and subsequently relayed over a heterogeneous\n(wireless/wired) backhaul. For deploying the proposed technique, we formulate a\nnon-cooperative game between the MUEs in which each MUE can decide on its\nrelaying femtocell while maximizing a utility function that captures both the\nachieved throughput and the expected backhaul delay. Simulation results show\nthat the proposed approach yields up to 125% rate improvement and up to 2 times\ndelay reduction with wired backhaul and, 150% rate improvement and up to 10\ntimes delay reduction with wireless backhaul, relative to classical\ninterference management approaches, with no cross-tier cooperation. \n\n"}
{"id": "1604.08758", "contents": "Title: Dynamic Clustering and Sleep Mode Strategies for Small Cell Networks Abstract: In this paper, a novel cluster-based approach for optimizing the energy\nefficiency of wireless small cell networks is proposed. A dynamic mechanism\nbased on the spectral clustering technique is proposed to dynamically form\nclusters of small cell base stations. Such clustering enables intra-cluster\ncoordination among the base stations for optimizing the downlink performance\nthrough load balancing, while satisfying users' quality-of-service\nrequirements. In the proposed approach, the clusters use an opportunistic base\nstation sleep-wake switching mechanism to strike a balance between delay and\nenergy consumption. The inter-cluster interference affects the performance of\nthe clusters and their choices of active or sleep state. Due to the lack of\ninter-cluster communications, the clusters have to compete with each other to\nmake decisions on improving the energy efficiency. This competition is\nformulated as a noncooperative game among the clusters that seek to minimize a\ncost function which captures the tradeoff between energy expenditure and load.\nTo solve this game, a distributed learning algorithm is proposed using which\nthe clusters autonomously choose their optimal transmission strategies.\nSimulation results show that the proposed approach yields significant\nperformance gains in terms of reduced energy expenditures up to 40% and reduced\nload up to 23% compared to conventional approaches. \n\n"}
{"id": "1605.00105", "contents": "Title: Multi-Connectivity in 5G mmWave Cellular Networks Abstract: The millimeter wave (mmWave) frequencies offer the potential of orders of\nmagnitude increases in capacity for next-generation cellular wireless systems.\nHowever, links in mmWave networks are highly susceptible to blocking and may\nsuffer from rapid variations in quality. Connectivity to multiple cells - both\nin the mmWave and in the traditional lower frequencies - is thus considered\nessential for robust connectivity. However, one of the challenges in supporting\nmulti-connectivity in the mmWave space is the requirement for the network to\ntrack the direction of each link in addition to its power and timing. With\nhighly directional beams and fast varying channels, this directional tracking\nmay be the main bottleneck in realizing robust mmWave networks. To address this\nchallenge, this paper proposes a novel measurement system based on (i) the UE\ntransmitting sounding signals in directions that sweep the angular space, (ii)\nthe mmWave cells measuring the instantaneous received signal strength along\nwith its variance to better capture the dynamics and, consequently, the\nreliability of a channel/direction and, finally, (iii) a centralized controller\nmaking handover and scheduling decisions based on the mmWave cell reports and\ntransmitting the decisions either via a mmWave cell or conventional microwave\ncell (when control signaling paths are not available). We argue that the\nproposed scheme enables efficient and highly adaptive cell selection in the\npresence of the channel variability expected at mmWave frequencies. \n\n"}
{"id": "1605.00716", "contents": "Title: Radio Transformer Networks: Attention Models for Learning to Synchronize\n  in Wireless Systems Abstract: We introduce learned attention models into the radio machine learning domain\nfor the task of modulation recognition by leveraging spatial transformer\nnetworks and introducing new radio domain appropriate transformations. This\nattention model allows the network to learn a localization network capable of\nsynchronizing and normalizing a radio signal blindly with zero knowledge of the\nsignals structure based on optimization of the network for classification\naccuracy, sparse representation, and regularization. Using this architecture we\nare able to outperform our prior results in accuracy vs signal to noise ratio\nagainst an identical system without attention, however we believe such an\nattention model has implication far beyond the task of modulation recognition. \n\n"}
{"id": "1605.01345", "contents": "Title: A Linearization Technique for Self-Interference Cancellation in\n  Full-Duplex Radios Abstract: The fundamental problem in the design of a full-duplex radio is the\ncancellation of the self-interference (SI) signal generated by the\ntransmitter.Current techniques for suppressing SI rely on generating a copy of\nthe SI signal and subtracting it partly in the RF (radio frequency) and digital\ndomains. A critical step in replicating the self-interference is the estimation\nof the multi-path channel through which the transmitted signal propagates to\nthe antenna. Since there is no prior model on the number of multipath\nreflections, current techniques assume a tap delay line filter (in the RF and\ndigital domain) with a large number of taps, and estimate the taps in the\nanalog and the digital domain. Assuming such a model leads to a large\nform-factor for the analog and RF circuits and increased complexity in the\ndigital domain.\n  In this paper, using a linearization technique, we show that the\nself-interference channel in an indoor environment can be effectively modelled\nas $H(f)=C_0 + C_1f$ in the frequency domain. Thus, the effective\nself-interference channel can be represented by two parameters $C_0$ and $C_1$,\nirrespective of the multipath environment. We also provide experimental\nevidence to verify the above channel model and propose novel low-complexity\ndesigns for self-interference cancellation. Linearization not only aids in the\npracticality of analog cancellation by reducing the form factor, but also\nresults in a simpler SI filter model in the digital domain due to\ndimensionality reduction of the channel parameters. Therefore this method can\nenable the widespread adoption of full-duplex techniques to portable devices in\naddition to infrastructure base-stations. \n\n"}
{"id": "1605.01451", "contents": "Title: Boltzmann meets Nash: Energy-efficient routing in optical networks under\n  uncertainty Abstract: Motivated by the massive deployment of power-hungry data centers for service\nprovisioning, we examine the problem of routing in optical networks with the\naim of minimizing traffic-driven power consumption. To tackle this issue,\nrouting must take into account energy efficiency as well as capacity\nconsiderations; moreover, in rapidly-varying network environments, this must be\naccomplished in a real-time, distributed manner that remains robust in the\npresence of random disturbances and noise. In view of this, we derive a pricing\nscheme whose Nash equilibria coincide with the network's socially optimum\nstates, and we propose a distributed learning method based on the Boltzmann\ndistribution of statistical mechanics. Using tools from stochastic calculus, we\nshow that the resulting Boltzmann routing scheme exhibits remarkable\nconvergence properties under uncertainty: specifically, the long-term average\nof the network's power consumption converges within $\\varepsilon$ of its\nminimum value in time which is at most $\\tilde O(1/\\varepsilon^2)$,\nirrespective of the fluctuations' magnitude; additionally, if the network\nadmits a strict, non-mixing optimum state, the algorithm converges to it -\nagain, no matter the noise level. Our analysis is supplemented by extensive\nnumerical simulations which show that Boltzmann routing can lead to a\nsignificant decrease in power consumption over basic, shortest-path routing\nschemes in realistic network conditions. \n\n"}
{"id": "1605.01557", "contents": "Title: On the Aloha throughput-fairness tradeoff Abstract: A well-known inner bound of the stability region of the slotted Aloha\nprotocol on the collision channel with n users assumes worst-case service rates\n(all user queues non-empty). Using this inner bound as a feasible set of\nachievable rates, a characterization of the throughput--fairness tradeoff over\nthis set is obtained, where throughput is defined as the sum of the individual\nuser rates, and two definitions of fairness are considered: the Jain-Chiu-Hawe\nfunction and the sum-user alpha-fair (isoelastic) utility function. This\ncharacterization is obtained using both an equality constraint and an\ninequality constraint on the throughput, and properties of the optimal\ncontrols, the optimal rates, and the fairness as a function of the target\nthroughput are established. A key fact used in all theorems is the observation\nthat all contention probability vectors that extremize the fairness functions\ntake at most two non-zero values. \n\n"}
{"id": "1605.01930", "contents": "Title: Context Information Based Initial Cell Search for Millimeter Wave 5G\n  Cellular Networks Abstract: Millimeter wave (mmWave) communication is envisioned as a cornerstone to\nfulfill the data rate requirements for fifth generation (5G) cellular networks.\nIn mmWave communication, beamforming is considered as a key technology to\ncombat the high path-loss, and unlike in conventional microwave communication,\nbeamforming may be necessary even during initial access/cell search. Among the\nproposed beamforming schemes for initial cell search, analog beamforming is a\npower efficient approach but suffers from its inherent search delay during\ninitial access. In this work, we argue that analog beamforming can still be a\nviable choice when context information about mmWave base stations (BS) is\navailable at the mobile station (MS). We then study how the performance of\nanalog beamforming degrades in case of angular errors in the available context\ninformation. Finally, we present an analog beamforming receiver architecture\nthat uses multiple arrays of Phase Shifters and a single RF chain to combat the\neffect of angular errors, showing that it can achieve the same performance as\nhybrid beamforming. \n\n"}
{"id": "1605.02238", "contents": "Title: Latency Analysis of Systems with Multiple Interfaces for Ultra-Reliable\n  M2M Communication Abstract: One of the ways to satisfy the requirements of ultra-reliable low latency\ncommunication for mission critical Machine-type Communications (MTC)\napplications is to integrate multiple communication interfaces. In order to\nestimate the performance in terms of latency and reliability of such an\nintegrated communication system, we propose an analysis framework that combines\ntraditional reliability models with technology-specific latency probability\ndistributions. In our proposed model we demonstrate how failure correlation\nbetween technologies can be taken into account. We show for the considered\nscenario with fiber and different cellular technologies how up to 5-nines\nreliability can be achieved and how packet splitting can be used to reduce\nlatency substantially while keeping 4-nines reliability. The model has been\nvalidated through simulation. \n\n"}
{"id": "1605.05077", "contents": "Title: Ad-Blocking and Counter Blocking: A Slice of the Arms Race Abstract: Adblocking tools like Adblock Plus continue to rise in popularity,\npotentially threatening the dynamics of advertising revenue streams. In\nresponse, a number of publishers have ramped up efforts to develop and deploy\nmechanisms for detecting and/or counter-blocking adblockers (which we refer to\nas anti-adblockers), effectively escalating the online advertising arms race.\nIn this paper, we develop a scalable approach for identifying third-party\nservices shared across multiple web-sites and use it to provide a first\ncharacterization of anti-adblocking across the Alexa Top-5K websites. We map\nwebsites that perform anti-adblocking as well as the entities that provide\nanti-adblocking scripts. We study the modus operandi of these scripts and their\nimpact on popular adblockers. We find that at least 6.7% of websites in the\nAlexa Top-5K use anti-adblocking scripts, acquired from 12 distinct entities --\nsome of which have a direct interest in nourishing the online advertising\nindustry. \n\n"}
{"id": "1605.05614", "contents": "Title: Slotless Protocols for Fast and Energy-Efficient Neighbor Discovery Abstract: In mobile ad-hoc networks, neighbor discovery protocols are used to find\nsurrounding devices and to establish a first contact between them. Since the\nclocks of the devices are not synchronized and their energy-budgets are\nlimited, usually duty-cycled, asynchronous discovery protocols are applied.\nOnly if two devices are awake at the same point in time, they can rendezvous.\nCurrently, time-slotted protocols, which subdivide time into multiple intervals\nwith equal lengths (slots), are considered to be the most efficient discovery\nschemes. In this paper, we break away from the assumption of slotted time. We\npropose a novel, continuous-time discovery protocol, which temporally decouples\nbeaconing and listening. Each device periodically sends packets with a certain\ninterval, and periodically listens for a given duration with a different\ninterval. By optimizing these interval lengths, we show that this scheme can,\nto the best of our knowledge, outperform all known protocols such as DISCO,\nU-Connect or Searchlight significantly. For example, Searchlight takes up to\n740 % longer than our proposed technique to discover a device with the same\nduty-cycle. Further, our proposed technique can also be applied in widely-used\nasymmetric purely interval-based protocols such as ANT or Bluetooth Low Energy. \n\n"}
{"id": "1605.06884", "contents": "Title: Mobile Cloud Computing with a UAV-Mounted Cloudlet: Optimal Bit\n  Allocation for Communication and Computation Abstract: Mobile cloud computing relieves the tension between compute-intensive mobile\napplications and battery-constrained mobile devices by enabling the offloading\nof computing tasks from mobiles to a remote processors. This paper considers a\nmobile cloud computing scenario in which the \"cloudlet\" processor that provides\noffloading opportunities to mobile devices is mounted on unmanned aerial\nvehicles (UAVs) to enhance coverage. Focusing on a slotted communication system\nwith frequency division multiplexing between mobile and UAV, the joint\noptimization of the number of input bits transmitted in the uplink by the\nmobile to the UAV, the number of input bits processed by the cloudlet at the\nUAV, and the number of output bits returned by the cloudlet to the mobile in\nthe downlink in each slot is carried out by means of dual decomposition under\nmaximum latency constraints with the aim of minimizing the mobile energy\nconsumption. Numerical results reveal the critical importance of an optimized\nbit allocation in order to enable significant energy savings as compared to\nlocal mobile execution for stringent latency constraints. \n\n"}
{"id": "1605.07524", "contents": "Title: Hijacking Bitcoin: Routing Attacks on Cryptocurrencies Abstract: As the most successful cryptocurrency to date, Bitcoin constitutes a target\nof choice for attackers. While many attack vectors have already been uncovered,\none important vector has been left out though: attacking the currency via the\nInternet routing infrastructure itself. Indeed, by manipulating routing\nadvertisements (BGP hijacks) or by naturally intercepting traffic, Autonomous\nSystems (ASes) can intercept and manipulate a large fraction of Bitcoin\ntraffic.\n  This paper presents the first taxonomy of routing attacks and their impact on\nBitcoin, considering both small-scale attacks, targeting individual nodes, and\nlarge-scale attacks, targeting the network as a whole. While challenging, we\nshow that two key properties make routing attacks practical: (i) the efficiency\nof routing manipulation; and (ii) the significant centralization of Bitcoin in\nterms of mining and routing. Specifically, we find that any network attacker\ncan hijack few (<100) BGP prefixes to isolate ~50% of the mining power---even\nwhen considering that mining pools are heavily multi-homed. We also show that\non-path network attackers can considerably slow down block propagation by\ninterfering with few key Bitcoin messages.\n  We demonstrate the feasibility of each attack against the deployed Bitcoin\nsoftware. We also quantify their effectiveness on the current Bitcoin topology\nusing data collected from a Bitcoin supernode combined with BGP routing data.\n  The potential damage to Bitcoin is worrying. By isolating parts of the\nnetwork or delaying block propagation, attackers can cause a significant amount\nof mining power to be wasted, leading to revenue losses and enabling a wide\nrange of exploits such as double spending. To prevent such effects in practice,\nwe provide both short and long-term countermeasures, some of which can be\ndeployed immediately. \n\n"}
{"id": "1605.07685", "contents": "Title: Characterizing and Avoiding Routing Detours Through Surveillance States Abstract: An increasing number of countries are passing laws that facilitate the mass\nsurveillance of Internet traffic. In response, governments and citizens are\nincreasingly paying attention to the countries that their Internet traffic\ntraverses. In some cases, countries are taking extreme steps, such as building\nnew Internet Exchange Points (IXPs), which allow networks to interconnect\ndirectly, and encouraging local interconnection to keep local traffic local. We\nfind that although many of these efforts are extensive, they are often futile,\ndue to the inherent lack of hosting and route diversity for many popular sites.\nBy measuring the country-level paths to popular domains, we characterize\ntransnational routing detours. We find that traffic is traversing known\nsurveillance states, even when the traffic originates and ends in a country\nthat does not conduct mass surveillance. Then, we investigate how clients can\nuse overlay network relays and the open DNS resolver infrastructure to prevent\ntheir traffic from traversing certain jurisdictions. We find that 84\\% of paths\noriginating in Brazil traverse the United States, but when relays are used for\ncountry avoidance, only 37\\% of Brazilian paths traverse the United States.\nUsing the open DNS resolver infrastructure allows Kenyan clients to avoid the\nUnited States on 17\\% more paths. Unfortunately, we find that some of the more\nprominent surveillance states (e.g., the U.S.) are also some of the least\navoidable countries. \n\n"}
{"id": "1605.08023", "contents": "Title: Online Placement of Multi-Component Applications in Edge Computing\n  Environments Abstract: Mobile edge computing is a new cloud computing paradigm which makes use of\nsmall-sized edge-clouds to provide real-time services to users. These mobile\nedge-clouds (MECs) are located in close proximity to users, thus enabling users\nto seamlessly access applications running on MECs. Due to the co-existence of\nthe core (centralized) cloud, users, and one or multiple layers of MECs, an\nimportant problem is to decide where (on which computational entity) to place\ndifferent components of an application. This problem, known as the application\nor workload placement problem, is notoriously hard, and therefore, heuristic\nalgorithms without performance guarantees are generally employed in common\npractice, which may unknowingly suffer from poor performance as compared to the\noptimal solution. In this paper, we address the application placement problem\nand focus on developing algorithms with provable performance bounds. We model\nthe user application as an application graph and the physical computing system\nas a physical graph, with resource demands/availabilities annotated on these\ngraphs. We first consider the placement of a linear application graph and\npropose an algorithm for finding its optimal solution. Using this result, we\nthen generalize the formulation and obtain online approximation algorithms with\npolynomial-logarithmic (poly-log) competitive ratio for tree application graph\nplacement. We jointly consider node and link assignment, and incorporate\nmultiple types of computational resources at nodes. \n\n"}
{"id": "1606.00717", "contents": "Title: Biased Contribution Index: A Simpler Mechanism to Maintain Fairness in\n  Peer to Peer Network Abstract: To maintain fairness, in the terms of resources shared by an individual peer,\na proper incentive policy is required in a peer to peer network. This letter\nproposes, a simpler mechanism to rank the peers based on their resource\ncontributions to the network. This mechanism will suppress the free riders from\ndownloading the resources from the network. Contributions of the peers are\nbiased in such a way that it can balance the download and upload amount of\nresources at each peer. This mechanism can be implemented in a distributed\nsystem and it converges much faster than the other existing approaches. \n\n"}
{"id": "1606.02080", "contents": "Title: Random Access Protocols for Massive MIMO Abstract: 5G wireless networks are expected to support new services with stringent\nrequirements on data rates, latency and reliability. One novel feature is the\nability to serve a dense crowd of devices, calling for radically new ways of\naccessing the network. This is the case in machine-type communications, but\nalso in urban environments and hotspots. In those use cases, the high number of\ndevices and the relatively short channel coherence interval do not allow\nper-device allocation of orthogonal pilot sequences. This article motivates the\nneed for random access by the devices to pilot sequences used for channel\nestimation, and shows that Massive MIMO is a main enabler to achieve fast\naccess with high data rates, and delay-tolerant access with different data rate\nlevels. Three pilot access protocols along with data transmission protocols are\ndescribed, fulfilling different requirements of 5G services. \n\n"}
{"id": "1606.02337", "contents": "Title: Random Access in C-RAN for User Activity Detection with Limited-Capacity\n  Fronthaul Abstract: Cloud-Radio Access Network (C-RAN) is characterized by a hierarchical\nstructure in which the baseband processing functionalities of remote radio\nheads (RRHs) are implemented by means of cloud computing at a Central Unit\n(CU). A key limitation of C-RANs is given by the capacity constraints of the\nfronthaul links connecting RRHs to the CU. In this letter, the impact of this\narchitectural constraint is investigated for the fundamental functions of\nrandom access and active User Equipment (UE) identification in the presence of\na potentially massive number of UEs. In particular, the standard C-RAN approach\nbased on quantize-and-forward and centralized detection is compared to a scheme\nbased on an alternative CU-RRH functional split that enables local detection.\nBoth techniques leverage Bayesian sparse detection. Numerical results\nillustrate the relative merits of the two schemes as a function of the system\nparameters. \n\n"}
{"id": "1606.02394", "contents": "Title: Optimal quantum networks and one-shot entropies Abstract: We develop a semidefinite programming method for the optimization of quantum\nnetworks, including both causal networks and networks with indefinite causal\nstructure. Our method applies to a broad class of performance measures, defined\noperationally in terms of interactive tests set up by a verifier. We show that\nthe optimal performance is equal to a max relative entropy, which quantifies\nthe informativeness of the test. Building on this result, we extend the notion\nof conditional min-entropy from quantum states to quantum causal networks. The\noptimization method is illustrated in a number of applications, including the\ninversion, charge conjugation, and controlization of an unknown unitary\ndynamics. In the non-causal setting, we show a proof-of-principle application\nto the maximization of the winning probability in a non-causal quantum game. \n\n"}
{"id": "1606.02599", "contents": "Title: SDNFV: Flexible and Dynamic Software Defined Control of an Application-\n  and Flow-Aware Data Plane Abstract: Software Defined Networking (SDN) promises greater flexibility for directing\npacket flows, and Network Function Virtualization promises to enable dynamic\nmanagement of software-based network functions. However, the current divide\nbetween an intelligent control plane and an overly simple, stateless data plane\nresults in the inability to exploit the flexibility of a software based\nnetwork. In this paper we propose SDNFV, a framework that expands the\ncapabilities of network processing-and-forwarding elements to flexibly manage\npacket flows, while retaining both a high performance data plane and an easily\nmanaged control plane.\n  SDNFV proposes a hierarchical control framework where decisions are made\nacross the SDN controller, a host-level manager, and individual VMs to best\nexploit state available at each level. This increases the network's flexibility\ncompared to existing SDNs where controllers often make decisions solely based\non the first packet header of a flow. SDNFV intelligently places network\nservices across hosts and connects them in sequential and parallel chains,\ngiving both the SDN controller and individual network functions the ability to\nenhance and update flow rules to adapt to changing conditions. Our prototype\ndemonstrates how to efficiently and flexibly reroute flows based on data plane\nstate such as packet payloads and traffic characteristics. \n\n"}
{"id": "1606.03663", "contents": "Title: A Timed Process Algebra for Wireless Networks Abstract: This paper proposes a timed process algebra for wireless networks, an\nextension of the Algebra for Wireless Networks. It combines treatments of local\nbroadcast, conditional unicast and data structures, which are essential\nfeatures for the modelling of network protocols. In this framework we model and\nanalyse the Ad hoc On-Demand Distance Vector routing protocol, and show that,\ncontrary to claims in the literature, it fails to be loop free. We also present\nboundary conditions for a fix ensuring that the resulting protocol is indeed\nloop free. \n\n"}
{"id": "1606.04205", "contents": "Title: Robust And Optimal Opportunistic Scheduling For Downlink 2-Flow Network\n  Coding With Varying Channel Quality and Rate Adaptation (New Simulation\n  Figures) Abstract: This paper considers the downlink traffic from a base station to two\ndifferent clients. When assuming infinite backlog, it is known that\ninter-session network coding (INC) can significantly increase the throughput.\nHowever, the corresponding scheduling solution (when assuming dynamic arrivals\ninstead and requiring bounded delay) is still nascent. For the 2-flow downlink\nscenario, we propose the first opportunistic INC + scheduling solution that is\nprovably optimal for time-varying channels, i.e., the corresponding stability\nregion matches the optimal Shannon capacity. Specifically, we first introduce a\nnew binary INC operation, which is distinctly different from the traditional\nwisdom of XORing two overheard packets. We then develop a queue-length-based\nscheduling scheme and prove that it, with the help of the new INC operation,\nachieves the optimal stability region with time-varying channel quality. The\nproposed algorithm is later generalized to include the capability of rate\nadaptation. Simulation results show that it again achieves the optimal\nthroughput with rate adaptation. A byproduct of our results is a scheduling\nscheme for stochastic processing networks (SPNs) with random departure, which\nrelaxes the of deterministic departure in the existing results. \n\n"}
{"id": "1606.04778", "contents": "Title: The Learning and Prediction of Application-level Traffic Data in\n  Cellular Networks Abstract: Traffic learning and prediction is at the heart of the evaluation of the\nperformance of telecommunications networks and attracts a lot of attention in\nwired broadband networks. Now, benefiting from the big data in cellular\nnetworks, it becomes possible to make the analyses one step further into the\napplication level. In this paper, we firstly collect a significant amount of\napplication-level traffic data from cellular network operators. Afterwards,\nwith the aid of the traffic \"big data\", we make a comprehensive study over the\nmodeling and prediction framework of cellular network traffic. Our results\nsolidly demonstrate that there universally exist some traffic statistical\nmodeling characteristics, including ALPHA-stable modeled property in the\ntemporal domain and the sparsity in the spatial domain. Meanwhile, the results\nalso demonstrate the distinctions originated from the uniqueness of different\nservice types of applications. Furthermore, we propose a new traffic prediction\nframework to encompass and explore these aforementioned characteristics and\nthen develop a dictionary learning-based alternating direction method to solve\nit. Besides, we validate the prediction accuracy improvement and the robustness\nof the proposed framework through extensive simulation results. \n\n"}
{"id": "1606.05034", "contents": "Title: Search and Placement in Tiered Cache Networks Abstract: Content distribution networks have been extremely successful in today's\nInternet. Despite their success, there are still a number of scalability and\nperformance challenges that motivate clean slate solutions for content\ndissemination, such as content centric networking. In this paper, we address\ntwo of the fundamental problems faced by any content dissemination system:\ncontent search and content placement.\n  We consider a multi-tiered, multi-domain hierarchical system wherein random\nwalks are used to cope with the tradeoff between exploitation of known paths\ntowards custodians versus opportunistic exploration of replicas in a given\nneighborhood. TTL-like mechanisms, referred to as reinforced counters, are used\nfor content placement. We propose an analytical model to study the interplay\nbetween search and placement. The model yields closed form expressions for\nmetrics of interest such as the average delay experienced by users and the load\nplaced on custodians. Then, leveraging the model solution we pose a joint\nplacement-search optimization problem. We show that previously proposed\nstrategies for optimal placement, such as the square-root allocation, follow as\nspecial cases of ours, and that a bang-bang search policy is optimal if content\nallocation is given. \n\n"}
{"id": "1606.05047", "contents": "Title: Towards Characterizing International Routing Detours Abstract: There are currently no requirements (technical or otherwise) that BGP paths\nmust be contained within national boundaries. Indeed, some paths experience\ninternational detours, i.e., originate in one country, cross international\nboundaries and return to the same country. In most cases these are sensible\ntraffic engineering or peering decisions at ISPs that serve multiple countries.\nIn some cases such detours may be suspicious. Characterizing international\ndetours is useful to a number of players: (a) network engineers trying to\ndiagnose persistent problems, (b) policy makers aiming at adhering to certain\nnational communication policies, (c) entrepreneurs looking for opportunities to\ndeploy new networks, or (d) privacy-conscious states trying to minimize the\namount of internal communication traversing different jurisdictions. In this\npaper we characterize international detours in the Internet during the month of\nJanuary 2016. To detect detours we sample BGP RIBs every 8 hours from 461\nRouteViews and RIPE RIS peers spanning 30 countries. Then geolocate visible\nASes by geolocating each BGP prefix announced by each AS, mapping its presence\nat IXPs and geolocation infrastructure IPs. Finally, analyze each global BGP\nRIB entry looking for detours. Our analysis shows more than 5K unique BGP\nprefixes experienced a detour. A few ASes cause most detours and a small\nfraction of prefixes were affected the most. We observe about 544K detours.\nDetours either last for a few days or persist the entire month. Out of all the\ndetours, more than 90% were transient detours that lasted for 72 hours or less.\nWe also show different countries experience different characteristics of\ndetours. \n\n"}
{"id": "1606.05332", "contents": "Title: Spatio-temporal Interference Correlation and Joint Coverage in Cellular\n  Networks Abstract: This paper provides an analytical framework with foundations in stochastic\ngeometry to characterize the spatio-temporal interference correlation as well\nas the joint coverage probability at two spatial locations in a cellular\nnetwork. In particular, modeling the locations of cellular base stations (BSs)\nas a Poisson Point Process (PPP), we study interference correlation at two\nspatial locations $\\ell_1$ and $\\ell_2$ separated by a distance $v$, when the\nuser follows \\emph{closest BS association policy} at both spatial locations and\nmoves from $\\ell_1$ to $\\ell_2$. With this user displacement, two scenarios can\noccur: i) the user is handed off to a new serving BS at $\\ell_2$, or ii) no\nhandoff occurs and the user is served by the same BS at both locations. After\nproviding intermediate results such as probability of handoff and distance\ndistributions of the serving BS at the two user locations, we use them to\nderive exact expressions for spatio-temporal interference correlation\ncoefficient and joint coverage probability for any distance separation $v$. We\nalso study two different handoff strategies: i) \\emph{handoff skipping}, and\nii) \\emph{conventional handoffs}, and derive the expressions of joint coverage\nprobability for both strategies. The exact analysis is not straightforward and\ninvolves a careful treatment of the neighborhood of the two spatial locations\nand the resulting handoff scenarios. To provide analytical insights, we also\nprovide easy-to-use expressions for two special cases: i) static user ($v =0$)\nand ii) highly mobile user ($v \\rightarrow \\infty)$. As expected, our analysis\nshows that the interference correlation and joint coverage probability decrease\nwith increasing $v$, with $v \\rightarrow \\infty$ corresponding to a completely\nuncorrelated scenario. \n\n"}
{"id": "1606.05391", "contents": "Title: Technique Report: Scheduling Flows with Multiple Service Frequency\n  Constraints Abstract: With the fast development of wireless technologies, wireless applications\nhave invaded various areas in people's lives with a wide range of capabilities.\nGuaranteeing Quality-of-Service (QoS) is the key to the success of those\napplications. One of the QoS requirements, service frequency, is very important\nfor tasks including multimedia transmission in the Internet of Things. A\nservice frequency constraint denotes the length of time period during which a\nlink can transmit at least once. Unfortunately, it has not been well addressed\nyet. Therefore, this paper proposes a new framework to schedule multi\ntransmitting flows in wireless networks considering service frequency\nconstraint for each link. In our model, the constraints for flows are\nheterogeneous due to the diversity of users' behaviors. We first introduce a\nnew definition for network stability with service frequency constraints and\ndemonstrate that the novel scheduling policy is throughput-optimal in one\nfundamental category of network models. After that, we discuss the performance\nof a wireless network with service frequency constraints from the views of\ncapacity region and total queue length. Finally, a series of evaluations\nindicate the proposed scheduling policy can guarantee service frequency and\nachieve a good performance on the aspect of queue length of each flow. \n\n"}
{"id": "1606.06339", "contents": "Title: Optimal Storage Aware Caching Policies for Content-Centric Clouds Abstract: Caches in Content-Centric Networks (CCN) are increasingly adopting flash\nmemory based storage. The current flash cache technology stores all files with\nthe largest possible expiry date, i.e. the files are written in the memory so\nthat they are retained for as long as possible. This, however, does not\nleverage the CCN data characteristics where content is typically short-lived\nand has a distinct popularity profile. Writing files in a cache using the\nlongest retention time damages the memory device thus reducing its lifetime.\nHowever, writing using a small retention time can increase the content\nretrieval delay, since, at the time a file is requested, the file may already\nhave been expired from the memory. This motivates us to consider a joint\noptimization wherein we obtain optimal policies for jointly minimizing the\ncontent retrieval delay (which is a network-centric objective) and the flash\ndamage (which is a device-centric objective). Caching decisions now not only\ninvolve what to cache but also for how long to cache each file. We design\nprovably optimal policies and numerically compare them against prior policies. \n\n"}
{"id": "1606.06692", "contents": "Title: A Delay Optimal MAC and Packet Scheduler for Heterogeneous M2M Uplink Abstract: The uplink data arriving at the Machine-to-Machine (M2M) Application Server\n(AS) via M2M Aggregators (MAs) is fairly heterogeneous along several dimensions\nsuch as maximum tolerable packet delay, payload size and arrival rate, thus\nnecessitating the design of Quality-of-Service (QoS) aware packet scheduler. In\nthis paper, we classify the M2M uplink data into multiple QoS classes and use\nsigmoidal function to map the delay requirements of each class onto utility\nfunctions. We propose a proportionally fair delay-optimal multiclass packet\nscheduler at AS that maximizes a system utility metric. We note that the\naverage class delay under any work-conserving scheduling policy can be realized\nby appropriately time-sharing between all possible preemptive priority\npolicies. Therefore the optimal scheduler is determined using an iterative\nprocess to determine the optimal time-sharing between all priority scheduling\npolicies, such that it results in maximum system utility. The proposed\nscheduler can be implemented online with reduced complexity due to the\niterative optimization process. We then extend this work to determine jointly\noptimal MA-AS channel allocation and packet scheduling scheme at the MAs and\nAS. We first formulate a joint optimization problem that is solved centrally at\nthe AS and then propose a low complexity distributed optimization problem\nsolved independently at MAs and AS. We show that the distributed optimization\nsolution converges quickly to the centralized optimization result with minimal\ninformation exchange overhead between MAs and AS. Using Monte-Carlo\nsimulations, we verify the optimality of the proposed scheduler and show that\nit outperforms other state-of-the-art packet schedulers such as weighted round\nrobin, max-weight scheduler etc. Another desirable feature of proposed\nscheduler is low delay jitter for delay-sensitive traffic. \n\n"}
{"id": "1606.07079", "contents": "Title: SICS: Secure In-Cloud Service Function Chaining Abstract: There is an increasing trend that enterprises outsource their network\nfunctions to the cloud for lower cost and ease of management. However, network\nfunction outsourcing brings threats to the privacy of enterprises since the\ncloud is able to access the traffic and rules of in-cloud network functions.\nCurrent tools for secure network function outsourcing either incur large\nperformance overhead or do not support real-time updates. In this paper, we\npresent SICS, a secure service function chain outsourcing framework. SICS\nencrypts each packet header and use a label for in-cloud rule matching, which\nenables the cloud to perform its functionalities correctly with minimum header\ninformation leakage. Evaluation results show that SICS achieves higher\nthroughput, faster construction and update speed, and lower resource overhead\nat both enterprise and cloud sides, compared to existing solutions. \n\n"}
{"id": "1607.00773", "contents": "Title: Echo State Networks for Proactive Caching in Cloud-Based Radio Access\n  Networks with Mobile Users Abstract: In this paper, the problem of proactive caching is studied for cloud radio\naccess networks (CRANs). In the studied model, the baseband units (BBUs) can\npredict the content request distribution and mobility pattern of each user,\ndetermine which content to cache at remote radio heads and BBUs. This problem\nis formulated as an optimization problem which jointly incorporates backhaul\nand fronthaul loads and content caching. To solve this problem, an algorithm\nthat combines the machine learning framework of echo state networks with\nsublinear algorithms is proposed. Using echo state networks (ESNs), the BBUs\ncan predict each user's content request distribution and mobility pattern while\nhaving only limited information on the network's and user's state. In order to\npredict each user's periodic mobility pattern with minimal complexity, the\nmemory capacity of the corresponding ESN is derived for a periodic input. This\nmemory capacity is shown to be able to record the maximum amount of user\ninformation for the proposed ESN model. Then, a sublinear algorithm is proposed\nto determine which content to cache while using limited content request\ndistribution samples. Simulation results using real data from Youku and the\nBeijing University of Posts and Telecommunications show that the proposed\napproach yields significant gains, in terms of sum effective capacity, that\nreach up to 27.8% and 30.7%, respectively, compared to random caching with\nclustering and random caching without clustering algorithm. \n\n"}
{"id": "1607.01912", "contents": "Title: Nonlinear Self-Interference Cancellation for Full-Duplex Radios: From\n  Link- and System-Level Performance Perspectives Abstract: One of the promising technologies for LTE Evolution is full-duplex radio, an\ninnovation is expected to double the spectral efficiency. To realize\nfull-duplex in practice, the main challenge is overcoming self-interference,\nand to do so, researchers have developed self-interference cancellation\ntechniques. Since most wireless transceivers use power amplifiers, especially\nin cellular systems, researchers have revealed the importance of nonlinear\nself-interference cancellation. In this article, we first explore several\nnonlinear digital self-interference cancellation techniques. We then propose a\nlow complexity pre-calibration-based nonlinear digital self-interference\ncancellation technique. Next we discuss issues about reference signal\nallocation and the overhead of each technique. For performance evaluations, we\ncarry out extensive measurements through a real-time prototype and\nlink-/system-level simulations. For link-level analysis, we measure the amount\nof cancelled self-interference for each technique. We also evaluate\nsystem-level performances through 3D ray-tracing-based simulations. Numerical\nresults confirm the significant performance improvement over a half-duplex\nsystem even in interference-limited indoor environments. \n\n"}
{"id": "1607.03408", "contents": "Title: Performance Optimization of WSNs using External Information Abstract: The goal of this work is to describe a self-management system that correlates\ndata sensed by different Wireless Sensor Networks (WSNs) and adjusts the number\nof active nodes in each network to provide an appropriate amount of\nmeasurements. The architecture considers the factors that make the external\ndata relevant to the local network, such as the distance between covered areas,\nthe relation between the types of sensed data and the reliability of the\nmeasurements. As a result, the operation of each network will be tuned to\ntrade-off the accuracy of the measurements and the power consumption. \n\n"}
{"id": "1607.03443", "contents": "Title: A Survey about Prediction-Based Data Reduction in Wireless Sensor\n  Networks Abstract: One of the main characteristics of Wireless Sensor Networks (WSNs) is the\nconstrained energy resources of their wireless sensor nodes. Although this\nissue has been addressed in several works and got a lot of attention within the\nyears, the most recent advances pointed out that the energy harvesting and\nwireless charging techniques may offer means to overcome such a limitation.\nConsequently, an issue that had been put in second place, now emerges: the low\navailability of spectrum resources. Because of it, the incorporation of the\nWSNs into the Internet of Things and the exponential growth of the latter may\nbe hindered if no control over the data generation is taken. Alternatively,\npart of the sensed data can be predicted without triggering transmissions and\ncongesting the wireless medium. In this work, we analyze and categorize\nexisting prediction-based data reduction mechanisms that have been designed for\nWSNs. Our main contribution is a systematic procedure for selecting a scheme to\nmake predictions in WSNs, based on WSNs' constraints, characteristics of\nprediction methods and monitored data. Finally, we conclude the paper with a\ndiscussion about future challenges and open research directions in the use of\nprediction methods to support the WSNs' growth. \n\n"}
{"id": "1607.03571", "contents": "Title: Traffic Management for Heterogeneous Networks with Opportunistic\n  Unlicensed Spectrum Sharing Abstract: This paper studies how to maximize the per-user-based throughput in an M-tier\nheterogeneous wireless network (HetNet) by optimally managing traffic flows\nbetween the access points (APs) in the HetNet. The APs in the first M-1 tiers\ncan use the licensed spectrum at the same time whereas they share the\nunlicensed spectrum with the APs in the Mth tier by the proposed opportunistic\ncarrier sense multiple access with collision avoidance (CSMA/CA) protocol. The\nAPs that access the licensed and unlicensed spectra simultaneously are able to\nintegrate their spectrum resources by the carrier aggregation technique. We\nfirst characterize the distribution of the cell load and the channel access\nprobability of each AP using a generalized AP association scheme. For an AP in\neach tier, the tight lower bounds on its mean spectrum efficiencies in the\nlicensed and unlicensed spectra are derived for the general random models of\nthe channel gain and AP association weights. We define the per-user link\nthroughput and per-user network throughput based on the derived the mean\nspectrum efficiencies and maximize them by proposing the decentralized and\ncentralized traffic management schemes for the APs in the first M-1 tiers under\nthe constraint that the per-user link throughput of the tier-M APs must be\nabove some minimum required value. Finally, a numerical example of coexisting\nLTE and WiFi networks is provided to validate our derived results and findings. \n\n"}
{"id": "1607.03607", "contents": "Title: Cloud Empowered Self-Managing WSNs Abstract: Wireless Sensor Networks (WSNs) are composed of low powered and\nresource-constrained wireless sensor nodes that are not capable of performing\nhigh-complexity algorithms. Integrating these networks into the Internet of\nThings (IoT) facilitates their real-time optimization based on remote data\nvisualization and analysis. This work describes the design and implementation\nof a scalable system architecture that integrates WSNs and cloud services to\nwork autonomously in an IoT environment. The implementation relies on Software\nDefined Networking features to simplify the WSN management and exploits data\nanalytics tools to execute a reinforcement learning algorithm that takes\ndecisions based on the environment's evolution. It can automatically configure\nwireless sensor nodes to measure and transmit the temperature only at periods\nwhen the environment changes more often. Without any human intervention, the\nsystem could reduce nearly 85% the number of transmissions, showing the\npotential of this mechanism to extend WSNs lifetime without compromising the\ndata quality. Besides attending to similar use cases, such a WSN autonomic\nmanagement could promote a new business model to offer sensing tasks as a\nservice, which is also introduced in this work. \n\n"}
{"id": "1607.04330", "contents": "Title: Performance Comparison of Dual Connectivity and Hard Handover for LTE-5G\n  Tight Integration in mmWave Cellular Networks Abstract: MmWave communications are expected to play a major role in the Fifth\ngeneration of mobile networks. They offer a potential multi-gigabit throughput\nand an ultra-low radio latency, but at the same time suffer from high isotropic\npathloss, and a coverage area much smaller than the one of LTE macrocells. In\norder to address these issues, highly directional beamforming and a very\nhigh-density deployment of mmWave base stations were proposed. This Thesis aims\nto improve the reliability and performance of the 5G network by studying its\ntight and seamless integration with the current LTE cellular network. In\nparticular, the LTE base stations can provide a coverage layer for 5G mobile\nterminals, because they operate on microWave frequencies, which are less\nsensitive to blockage and have a lower pathloss. This document is a copy of the\nMaster's Thesis carried out by Mr. Michele Polese under the supervision of Dr.\nMarco Mezzavilla and Prof. Michele Zorzi. It will propose an LTE-5G tight\nintegration architecture, based on mobile terminals' dual connectivity to LTE\nand 5G radio access networks, and will evaluate which are the new network\nprocedures that will be needed to support it. Moreover, this new architecture\nwill be implemented in the ns-3 simulator, and a thorough simulation campaign\nwill be conducted in order to evaluate its performance, with respect to the\nbaseline of handover between LTE and 5G. \n\n"}
{"id": "1607.04428", "contents": "Title: On the Stability of a Full-Duplex Aloha Network Abstract: This letter offers the first characterisation of the stability for\nfull-duplex large size networks. Through stochastic geometry tools, key\nperformance metrics like delay and maximum stable arrival rate are derived for\nthe non saturated system and compared to a half-duplex counterpart, also\naccounting for imperfect self-interference cancellation. This analysis better\nidentifies that the full-duplex advantage is prominent for sparse networks,\nwhereas in dense topologies residual self-interference may hinder achievable\ngains. \n\n"}
{"id": "1607.05037", "contents": "Title: A Markov Chain Model for the Decoding Probability of Sparse Network\n  Coding Abstract: Random Linear Network Coding (RLNC) has been proved to offer an efficient\ncommunication scheme, leveraging an interesting robustness against packet\nlosses. However, it suffers from a high computational complexity and some novel\napproaches, which follow the same idea, have been recently proposed. One of\nsuch solutions is Tunable Sparse Network Coding (TSNC), where only few packets\nare combined in each transmissions. The amount of data packets to be combined\nin each transmissions can be set from a density parameter/distribution, which\ncould be eventually adapted. In this work we present an analytical model that\ncaptures the performance of SNC on an accurate way. We exploit an absorbing\nMarkov process where the states are defined by the number of useful packets\nreceived by the decoder, i.e the decoding matrix rank, and the number of\nnon-zero columns at such matrix. The model is validated by means of a thorough\nsimulation campaign, and the difference between model and simulation is\nnegligible. A mean square error less than $4 \\cdot 10^{-4}$ in the worst cases.\nWe also include in the comparison some of more general bounds that have been\nrecently used, showing that their accuracy is rather poor. The proposed model\nwould enable a more precise assessment of the behavior of sparse network coding\ntechniques. The last results show that the proposed analytical model can be\nexploited by the TSNC techniques in order to select by the encoder the best\ndensity as the transmission evolves. \n\n"}
{"id": "1607.05425", "contents": "Title: Performance Comparison of Dual Connectivity and Hard Handover for LTE-5G\n  Tight Integration Abstract: Communications at frequencies above 10 GHz (the mmWave band) are expected to\nplay a major role for the next generation of cellular networks (5G), because of\nthe potential multi-gigabit, ultra-low latency performance of this technology.\nmmWave frequencies however suffer from very high isotropic pathloss, which may\nresult in cells with a much smaller coverage area than current LTE macrocells.\nHigh directionality techniques will be used to improve signal quality and\nextend coverage area, along with a high density deployment of mmWave base\nstations (BS). However, when propagation conditions are hard and it is\ndifficult to provide high quality coverage with mmWave BS, it is necessary to\nrely on previous generation LTE base stations, which make use of lower\nfrequencies (900 MHz - 3.5 GHz), which are less sensitive to blockage and\nexperience lower pathloss. In order to provide ultra-reliable services to\nmobile users there is a need for network architectures that tightly and\nseamlessly integrate the LTE and mmWave Radio Access Technologies. In this\npaper we will present two possible alternatives for this integration and show\nhow simulation tools can be used to assess and compare their performance. \n\n"}
{"id": "1607.06044", "contents": "Title: Tail Index for a Distributed Storage System with Pareto File Size\n  Distribution Abstract: Distributed storage systems often employ erasure codes to achieve high data\nreliability while attaining space efficiency. Such storage systems are known to\nbe susceptible to long tails in response time. It has been shown that in modern\nonline applications such as Bing, Facebook, and Amazon, the long tail of\nlatency is of particular concern, with $99.9$th percentile response times that\nare orders of magnitude worse than the mean. Taming tail latency is very\nchallenging in erasure-coded storage systems since quantify tail latency (i.e.,\n$x$th-percentile latency for arbitrary $x\\in[0,1]$) has been a long-standing\nopen problem. In this paper, we propose a mathematical model to quantify {\\em\ntail index} of service latency for arbitrary erasure-coded storage systems, by\ncharacterizing the asymptotic behavior of latency distribution tails. When file\nsize has a heavy tailed distribution, we find tail index, defined as the\nexponent at which latency tail probability diminishes to zero, in closed-form,\nand further show that a family of probabilistic scheduling algorithms are\n(asymptotically) optimal since they are able to achieve the exact tail index. \n\n"}
{"id": "1608.00095", "contents": "Title: Service Function Chaining Resource Allocation: A Survey Abstract: Service Function Chaining (SFC) is a crucial technology for future Internet.\nIt aims to overcome the limitation of current deployment models which is rigid\nand static. Application of this technology relies on algorithms that can\noptimally mapping SFC to substrate network. This category of algorithms is\nreferred as \"Service Function Chaining Resource Allocation (SFC-RA)\" algorithms\nor \"VNF placement (VNFP)\" algorithms. This paper presents a survey of current\nresearches in SFC-RA algorithms. After presenting the formulation and related\nproblems, several variants of SFC-RA problem are summarized. At last, we\ndiscussed several future research directions. \n\n"}
{"id": "1608.00239", "contents": "Title: Adaptive Video Streaming over LTE Unlicensed Abstract: In this paper we consider the problem of adaptive video streaming over an\nLTE-A network that utilizes Licensed Assisted Access (LAA) which is an instance\nof LTE Unlicensed. With LTE Unlicensed users of the LTE-A network opportunisti-\ncally access radio resources from unlicensed and licensed carriers through\nCarrier Aggregation (CA). Our objective is to select the highest possible video\nquality for each LTE-A user while also try to deliver video data in time for\nplayback, and thus avoid buffer under-run events that deteriorate viewing\nexperience. However, the unpredictable nature of the wireless channel, as well\nas the unknown utilization of the unlicensed carrier by other unlicensed users,\nresult in a challenging optimization problem. We first focus on developing an\naccurate system model of the adaptive streaming system, LTE-A, and the\nstochastic availability of unlicensed resources. Then, the formulated problem\nis solved in two stages: First, we calculate a proportionally fair video\nquality for each user, and second we execute resource allocation on a shorter\ntime scale compatible with LTE-A. We compare our framework with the typical\nproportional fair scheduler as well as a state-of-the-art LTE-A adaptive video\nstreaming framework in terms of average segment quality and number of buffer\nunder- run events. Results show that the proposed quality selection and\nscheduling algorithms, not only achieve higher video segment quality in most\ncases, but also minimize the amount and duration of video freezes as a result\nof buffer under-run events. \n\n"}
{"id": "1608.00726", "contents": "Title: Infinite Unlimited Churn Abstract: We study unlimited infinite churn in peer-to-peer overlay networks. Under\nthis churn, arbitrary many peers may concurrently request to join or leave the\noverlay network; moreover these requests may never stop coming. We prove that\nunlimited adversarial churn, where processes may just exit the overlay network,\nis unsolvable. We focus on cooperative churn where exiting processes\nparticipate in the churn handling algorithm. We define the problem of unlimited\ninfinite churn in this setting. We distinguish the fair version of the problem,\nwhere each request is eventually satisfied, from the unfair version that just\nguarantees progress. We focus on local solutions to the problem, and prove that\na local solution to the Fair Infinite Unlimited Churn is impossible. We then\npresent and prove correct an algorithm UIUC that solves the Unfair Infinite\nUnlimited Churn Problem for a linearized peer-to-peer overlay network. We\nextend this solution to skip lists and skip graphs. \n\n"}
{"id": "1608.02032", "contents": "Title: Unique coverage in Boolean models Abstract: Consider a wireless cellular network consisting of small, densely scattered\nbase stations. A user $u$ is {\\em uniquely covered} by a base station $b$ if\n$u$ is the only user within distance $r$ of $b$. This makes it possible to\nassign the user $u$ to the base station $b$ without interference from any other\nuser $u'$. We investigate the maximum possible proportion of users who are\nuniquely covered. We solve this problem completely in one dimension and provide\nbounds, approximations and simulation results for the two-dimensional case. \n\n"}
{"id": "1608.02191", "contents": "Title: Bound-Based Power Optimization for Multi-Hop Heterogeneous Wireless\n  Industrial Networks Under Statistical Delay Constraints Abstract: The noticeably increased deployment of wireless networks for battery-limited\nindustrial applications in recent years highlights the need for tractable\nperformance analysis methodologies as well as efficient QoS-aware transmit\npower management schemes. In this work, we seek to combine several important\naspects of such networks, i.e., multi-hop connectivity, channel heterogeneity\nand the queuing effect, in order to address these needs. We design\ndelay-bound-based algorithms for transmit power minimization and network\nlifetime maximization of multi-hop heterogeneous wireless networks using our\npreviously developed stochastic network calculus approach for performance\nanalysis of a cascade of buffered wireless fading channels. Our analysis shows\nan overall transmit power saving of up to 95% compared to a fixed power\nallocation scheme when using a service model in terms of the Shannon capacity\nlimit. For a more realistic set-up, we evaluate the performance of the\nsuggested algorithm in a WirelessHART network, which is a widely used\ncommunication standard for process automation and other industrial\napplications. We find that link heterogeneity can significantly reduce network\nlifetime when no efficient power management is applied. Moreover, we show,\nusing extensive simulation study, that the proposed bound-based power\nallocation performs reasonably well compared to the real optimum, especially in\nthe case of WirelessHART networks. \n\n"}
{"id": "1608.02427", "contents": "Title: Maximum-Likelihood Detection for Energy-Efficient Timing Acquisition in\n  NB-IoT Abstract: Initial timing acquisition in narrow-band IoT (NB-IoT) devices is done by\ndetecting a periodically transmitted known sequence. The detection has to be\ndone at lowest possible latency, because the RF-transceiver, which dominates\ndownlink power consumption of an NB-IoT modem, has to be turned on throughout\nthis time. Auto-correlation detectors show low computational complexity from a\nsignal processing point of view at the price of a higher detection latency. In\ncontrast a maximum likelihood cross-correlation detector achieves low latency\nat a higher complexity as shown in this paper. We present a hardware\nimplementation of the maximum likelihood cross-correlation detection. The\ndetector achieves an average detection latency which is a factor of two below\nthat of an auto-correlation method and is able to reduce the required energy\nper timing acquisition by up to 34%. \n\n"}
{"id": "1608.04260", "contents": "Title: Location Aware Opportunistic Bandwidth Sharing between Static and Mobile\n  Users with Stochastic Learning in Cellular Networks Abstract: We consider location-dependent opportunistic bandwidth sharing between static\nand mobile downlink users in a cellular network. Each cell has some fixed\nnumber of static users. Mobile users enter the cell, move inside the cell for\nsome time and then leave the cell. In order to provide higher data rate to\nmobile users, we propose to provide higher bandwidth to the mobile users at\nfavourable times and locations, and provide higher bandwidth to the static\nusers in other times. We formulate the problem as a long run average reward\nMarkov decision process (MDP) where the per-step reward is a linear combination\nof instantaneous data volumes received by static and mobile users, and find the\noptimal policy. The transition structure of this MDP is not known in general.\nTo alleviate this issue, we propose a learning algorithm based on single\ntimescale stochastic approximation. Also, noting that the unconstrained MDP can\nbe used to solve a constrained problem, we provide a learning algorithm based\non multi-timescale stochastic approximation. The results are extended to\naddress the issue of fair bandwidth sharing between the two classes of users.\nNumerical results demonstrate performance improvement by our scheme, and also\nthe trade-off between performance gain and fairness. \n\n"}
{"id": "1608.04579", "contents": "Title: Endpoint-transparent Multipath Transport with Software-defined Networks Abstract: Multipath forwarding consists of using multiple paths simultaneously to\ntransport data over the network. While most such techniques require endpoint\nmodifications, we investigate how multipath forwarding can be done inside the\nnetwork, transparently to endpoint hosts. With such a network-centric approach,\npacket reordering becomes a critical issue as it may cause critical performance\ndegradation.\n  We present a Software Defined Network architecture which automatically sets\nup multipath forwarding, including solutions for reordering and performance\nimprovement, both at the sending side through multipath scheduling algorithms,\nand the receiver side, by resequencing out-of-order packets in a dedicated\nin-network buffer.\n  We implemented a prototype with commonly available technology and evaluated\nit in both emulated and real networks. Our results show consistent throughput\nimprovements, thanks to the use of aggregated path capacity. We give\ncomparisons to Multipath TCP, where we show our approach can achieve a similar\nperformance while offering the advantage of endpoint transparency. \n\n"}
{"id": "1608.04727", "contents": "Title: Covert Bits Through Queues Abstract: We consider covert communication using a queuing timing channel in the\npresence of a warden. The covert message is encoded using the inter-arrival\ntimes of the packets, and the legitimate receiver and the warden observe the\ninter-departure times of the packets from their respective queues. The\ntransmitter and the legitimate receiver also share a secret key to facilitate\ncovert communication. We propose achievable schemes that obtain non-zero covert\nrate for both exponential and general queues when a sufficiently high rate\nsecret key is available. This is in contrast to other channel models such as\nthe Gaussian channel or the discrete memoryless channel where only\n$\\mathcal{O}(\\sqrt{n})$ covert bits can be sent over $n$ channel uses, yielding\na zero covert rate. \n\n"}
{"id": "1608.05493", "contents": "Title: Network Volume Anomaly Detection and Identification in Large-scale\n  Networks based on Online Time-structured Traffic Tensor Tracking Abstract: This paper addresses network anomography, that is, the problem of inferring\nnetwork-level anomalies from indirect link measurements. This problem is cast\nas a low-rank subspace tracking problem for normal flows under incomplete\nobservations, and an outlier detection problem for abnormal flows. Since\ntraffic data is large-scale time-structured data accompanied with noise and\noutliers under partial observations, an efficient modeling method is essential.\nTo this end, this paper proposes an online subspace tracking of a Hankelized\ntime-structured traffic tensor for normal flows based on the Candecomp/PARAFAC\ndecomposition exploiting the recursive least squares (RLS) algorithm. We\nestimate abnormal flows as outlier sparse flows via sparsity maximization in\nthe underlying under-constrained linear-inverse problem. A major advantage is\nthat our algorithm estimates normal flows by low-dimensional matrices with\ntime-directional features as well as the spatial correlation of multiple links\nwithout using the past observed measurements and the past model parameters.\nExtensive numerical evaluations show that the proposed algorithm achieves\nfaster convergence per iteration of model approximation, and better volume\nanomaly detection performance compared to state-of-the-art algorithms. \n\n"}
{"id": "1608.05783", "contents": "Title: Non-Orthogonal Multiple Access (NOMA) in Cellular Uplink and Downlink:\n  Challenges and Enabling Techniques Abstract: By combining the concepts of superposition coding at the transmitter(s) and\nsuccessive interference cancellation (SIC) at the receiver(s), non-orthogonal\nmultiple access (NOMA) has recently emerged as a promising multiple access\ntechnique for 5G wireless technology. In this article, we first discuss the\nfundamentals of uplink and downlink NOMA transmissions and outline their key\ndistinctions (in terms of implementation complexity, detection and decoding at\nthe SIC receiver(s), incurred intra-cell and inter-cell interferences). Later,\nfor both downlink and uplink NOMA, we theoretically derive the NOMA dominant\ncondition for each individual user in a two-user NOMA cluster. NOMA dominant\ncondition refers to the condition under which the spectral efficiency gains of\nNOMA are guaranteed compared to conventional orthogonal multiple access (OMA).\nThe derived conditions provide direct insights on selecting appropriate users\nin two-user NOMA clusters. The conditions are distinct for uplink and downlink\nas well as for each individual user. Numerical results show the significance of\nthe derived conditions for the user selection in uplink/downlink NOMA clusters\nand provide a comparison to the random user selection. A brief overview of the\nrecent research investigations is then provided to highlight the existing\nresearch gaps. Finally, we discuss the potential applications and key\nchallenges of NOMA transmissions. \n\n"}
{"id": "1608.06249", "contents": "Title: A Survey on Honeypot Software and Data Analysis Abstract: In this survey, we give an extensive overview on honeypots. This includes not\nonly honeypot software but also methodologies to analyse honeypot data. \n\n"}
{"id": "1608.06409", "contents": "Title: Learning to Communicate: Channel Auto-encoders, Domain Specific\n  Regularizers, and Attention Abstract: We address the problem of learning efficient and adaptive ways to communicate\nbinary information over an impaired channel. We treat the problem as\nreconstruction optimization through impairment layers in a channel autoencoder\nand introduce several new domain-specific regularizing layers to emulate common\nchannel impairments. We also apply a radio transformer network based attention\nmodel on the input of the decoder to help recover canonical signal\nrepresentations. We demonstrate some promising initial capacity results from\nthis architecture and address several remaining challenges before such a system\ncould become practical. \n\n"}
{"id": "1608.07329", "contents": "Title: Scheduling Resource-Bounded Monitoring Devices for Event Detection and\n  Isolation in Networks Abstract: In networked systems, monitoring devices such as sensors are typically\ndeployed to monitor various target locations. Targets are the points in the\nphysical space at which events of some interest, such as random faults or\nattacks, can occur. Most often, these devices have limited energy supplies, and\nthey can operate for a limited duration. As a result, energy-efficient\nmonitoring of various target locations through a set of monitoring devices with\nlimited energy supplies is a crucial problem in networked systems. In this\npaper, we study optimal scheduling of monitoring devices to maximize network\ncoverage for detecting and isolating events on targets for a given network\nlifetime. The monitoring devices considered could remain active only for a\nfraction of the overall network lifetime. We formulate the problem of\nscheduling of monitoring devices as a graph labeling problem, which unlike\nother existing solutions, allows us to directly utilize the underlying network\nstructure to explore the trade-off between coverage and network lifetime. In\nthis direction, first we propose a greedy heuristic to solve the graph labeling\nproblem, and then provide a game-theoretic solution to achieve near optimal\ngraph labeling. Moreover, the proposed setup can be used to simultaneously\nsolve the scheduling and placement of monitoring devices, which yields improved\nperformance as compared to separately solving the placement and scheduling\nproblems. Finally, we illustrate our results on various networks, including\nreal-world water distribution networks. \n\n"}
{"id": "1608.07857", "contents": "Title: Optimizing Content Caching to Maximize the Density of Successful\n  Receptions in Device-to-Device Networking Abstract: Device-to-device (D2D) communication is a promising approach to optimize the\nutilization of air interface resources in 5G networks, since it allows\ndecentralized opportunistic short-range communication. For D2D to be useful,\nmobile nodes must possess content that other mobiles want. Thus, intelligent\ncaching techniques are essential for D2D. In this paper we use results from\nstochastic geometry to derive the probability of successful content delivery in\nthe presence of interference and noise. We employ a general transmission\nstrategy where multiple files are cached at the users and different files can\nbe transmitted simultaneously throughout the network. We then formulate an\noptimization problem, and find the caching distribution that maximizes the\ndensity of successful receptions (DSR) under a simple transmission strategy\nwhere a single file is transmitted at a time throughout the network. We model\nfile requests by a Zipf distribution with exponent $\\gamma_r$, which results in\nan optimal caching distribution that is also a Zipf distribution with exponent\n$\\gamma_c$, which is related to $\\gamma_r$ through a simple expression\ninvolving the path loss exponent. We solve the optimal content placement\nproblem for more general demand profiles under Rayleigh, Ricean and Nakagami\nsmall-scale fading distributions. Our results suggest that it is required to\nflatten the request distribution to optimize the caching performance. We also\ndevelop strategies to optimize content caching for the more general case with\nmultiple files, and bound the DSR for that scenario. \n\n"}
{"id": "1608.07953", "contents": "Title: Coexistence of OFDM and FBMC for Underlay D2D Communication in 5G\n  Networks Abstract: Device-to-device (D2D) communication is being heralded as an important part\nof the solution to the capacity problem in future networks, and is expected to\nbe natively supported in 5G. Given the high network complexity and required\nsignalling overhead associated with achieving synchronization in D2D networks,\nit is necessary to study asynchronous D2D communications. In this paper, we\nconsider a scenario whereby asynchronous D2D communication underlays an OFDMA\nmacro-cell in the uplink. Motivated by the superior performance of new\nwaveforms with increased spectral localization in the presence of frequency and\ntime misalignments, we compare the system-level performance of a set-up for\nwhen D2D pairs use either OFDM or FBMC/OQAM. We first demonstrate that\ninter-D2D interference, resulting from misaligned communications, plays a\nsignificant role in clustered D2D topologies. We then demonstrate that the\nresource allocation procedure can be simplified when D2D pairs use FBMC/OQAM,\nsince the high spectral localization of FBMC/OQAM results in negligible\ninter-D2D interference. Specifically, we identify that FBMC/OQAM is best suited\nto scenarios consisting of small, densely populated D2D clusters located near\nthe encompassing cell's edge. \n\n"}
{"id": "1608.08521", "contents": "Title: Profitable Task Allocation in Mobile Cloud Computing Abstract: We propose a game theoretic framework for task allocation in mobile cloud\ncomputing that corresponds to offloading of compute tasks to a group of nearby\nmobile devices. Specifically, in our framework, a distributor node holds a\nmultidimensional auction for allocating the tasks of a job among nearby mobile\nnodes based on their computational capabilities and also the cost of\ncomputation at these nodes, with the goal of reducing the overall job\ncompletion time. Our proposed auction also has the desired incentive\ncompatibility property that ensures that mobile devices truthfully reveal their\ncapabilities and costs and that those devices benefit from the task allocation.\nTo deal with node mobility, we perform multiple auctions over adaptive time\nintervals. We develop a heuristic approach to dynamically find the best time\nintervals between auctions to minimize unnecessary auctions and the\naccompanying overheads. We evaluate our framework and methods using both real\nworld and synthetic mobility traces. Our evaluation results show that our game\ntheoretic framework improves the job completion time by a factor of 2-5 in\ncomparison to the time taken for executing the job locally, while minimizing\nthe number of auctions and the accompanying overheads. Our approach is also\nprofitable for the nearby nodes that execute the distributor's tasks with these\nnodes receiving a compensation higher than their actual costs. \n\n"}
{"id": "1608.08660", "contents": "Title: Tunable QoS-Aware Network Survivability Abstract: Coping with network failures has been recognized as an issue of major\nimportance in terms of social security, stability and prosperity. It has become\nclear that current networking standards fall short of coping with the complex\nchallenge of surviving failures. The need to address this challenge has become\na focal point of networking research. In particular, the concept of\n\\textbf{\\emph{tunable survivability}} offers major performance improvements\nover traditional approaches. Indeed, while the traditional approach aims at\nproviding full (100\\%) protection against network failures through disjoint\npaths, it was realized that this requirement is too restrictive in practice.\nTunable survivability provides a quantitative measure for specifying the\ndesired level (0\\%-100\\%) of survivability and offers flexibility in the choice\nof the routing paths. Previous work focused on the simpler class of\n\"bottleneck\" criteria, such as bandwidth. In this study, we focus on the\nimportant and much more complex class of \\emph{additive} criteria, such as\ndelay and cost. First, we establish some (in part, counter-intuitive)\nproperties of the optimal solution. Then, we establish efficient algorithmic\nschemes for optimizing the level of survivability under additive end-to-end QoS\nbounds. Subsequently, through extensive simulations, we show that, at the price\nof \\emph{negligible} reduction in the level of survivability, a major\nimprovement (up to a factor of $2$) is obtained in terms of end-to-end QoS\nperformance. Finally, we exploit the above findings in the context of a network\ndesign problem, in which, for a given investment budget, we aim to improve the\nsurvivability of the network links. \n\n"}
{"id": "1608.08729", "contents": "Title: Probabilistic Medium Access Control for Full-Duplex Networks with\n  Half-Duplex Clients Abstract: The feasibility of practical in-band full-duplex radios has recently been\ndemonstrated experimentally. One way to leverage full-duplex in a network\nsetting is to enable three-node full-duplex, where a full- duplex access point\n(AP) transmits data to one node yet simultaneously receives data from another\nnode. Such three-node full-duplex communication however introduces inter-client\ninterference, directly impacting the full-duplex gain. It hence may not always\nbe beneficial to enable three-node full-duplex transmissions. In this paper, we\npresent a distributed full-duplex medium access control (MAC) protocol that\nallows an AP to adaptively switch between full-duplex and half-duplex modes. We\nformulate a model that determines the probabilities of full-duplex and\nhalf-duplex access so as to maximize the expected network throughput. A MAC\nprotocol is further proposed to enable the AP and clients to contend for either\nfull-duplex or half-duplex transmissions based on their assigned probabilities\nin a distributed way. Our evaluation shows that, by combining the advantages of\ncentralized probabilistic scheduling and distributed random access, our design\nimproves the overall throughput by 2.70x and 1.53x, on average, as compared to\nhalf-duplex 802.11 and greedy downlink-uplink client pairing. \n\n"}
{"id": "1609.00419", "contents": "Title: Spatially Correlated Content Caching for Device-to-Device Communications Abstract: We study optimal geographic content placement for device-to-device (D2D)\nnetworks in which each file's popularity follows the Zipf distribution. The\nlocations of the D2D users (caches) are modeled by a Poisson point process\n(PPP) and have limited communication range and finite storage. Inspired by the\nMat\\'{e}rn hard-core (type II) point process that captures pairwise\ninteractions between nodes, we devise a novel spatially correlated caching\nstrategy called {\\em hard-core placement} (HCP) such that the D2D nodes caching\nthe same file are never closer to each other than the {\\em exclusion radius}.\nThe exclusion radius plays the role of a substitute for caching probability. We\nderive and optimize the exclusion radii to maximize the {\\em hit probability},\nwhich is the probability that a given D2D node can find a desired file at\nanother node's cache within its communication range. Contrasting it with\nindependent content placement, which is used in most prior work, our HCP\nstrategy often yields a significantly higher cache hit probability. We further\ndemonstrate that the HCP strategy is effective for small cache sizes and a\nsmall communication radius, which are likely conditions for D2D. \n\n"}
{"id": "1609.00653", "contents": "Title: A Benchmark for the Performance of Time-varying Closed-loop Flow Control\n  with Application to TCP Abstract: Closed-loop flow control protocols, such as the prominent implementation TCP,\nare prevalent in the Internet, today. TCP has continuously been improved for\ngreedy traffic sources to achieve high throughput over networks with large\nbandwidth delay products. Recently, the increasing use for streaming and\ninteractive applications, such as voice and video, has shifted the focus\ntowards its delay performance. Given the need for real-time communication of\nnon-greedy sources via TCP, we present an estimation method for performance\nevaluation of closed-loop flow control protocols. We characterize an end-to-end\nconnection by a transfer function that provides statistical service guarantees\nfor arbitrary traffic. The estimation is based on end-to-end measurements at\nthe application level that include all effects induced by the network and by\nthe protocol stacks of the end systems. From our measurements, we identify\ndifferent causes for delays. We show that significant delays are due to\nqueueing in protocol stacks. Notably, this occurs even if the utilization is\nmoderate. Using our estimation method, we compare the impact of fundamental\nmechanisms of TCP on delays at the application level: In detail, we analyze\nparameters relevant for network dimensioning, including buffer provisioning and\nactive queue management, and parameters for server configuration, such as the\ncongestion control algorithm. By applying our method as a benchmark, we find\nthat a good selection can largely improve the delay performance of TCP. \n\n"}
{"id": "1609.00664", "contents": "Title: Transparent Clouds: An Enhancement to Abstraction Abstract: With the introduction of various hardware/software technologies such as Cloud\nTechnologies or Virtualization technologies, there has been a great potential\nto reuse ICT artifacts thanks to Abstraction and also Exchangeability features\nachieved via these technologies. These technologies also provide various\nadvantages with respect to sustainability including resource consumption\nreduction (in the use phase only or in the whole life cycle). However, there is\nan additional but untapped potential associated with the anonymization of\nresources introduced by both abstraction and exchangeability features. By\nrealizing on this potential, we can improve cloud solutions and reduce their\nby-product opacity, which usually prevents leveraging on the specialized but\ntweakable (i.e., nonessential modifications without changing the main function)\nfeatures of components that are captured in the component models. This is\nespecially a challenge in the case heterogeneous/disaggregated infrastructure\nwhere developing models to cover everything is practically impossible. In this\nwork, by leveraging on the concept of pathways, we develop a few mechanisms\nthat enable transparency and therefore tweakability of features even in the\npresence of abstraction and heterogeneity. In particular, the layered-stack\napproach to system decomposition is considered because of its role in both\nsoftware defined networking (SDN) and Network Function Virtualization (NFV)\nsystem decompositions. For a concrete example, the case of dynamic frequency\nscaling of processors is considered and it is shown that the associated\nconsumption could be considerably reduced without requiring additional changes\nto the middle components. \n\n"}
{"id": "1609.00852", "contents": "Title: Joint Caching and Pricing Strategies for Popular Content in Information\n  Centric Networks Abstract: We develop an analytical framework for distribution of popular content in an\nInformation Centric Network (ICN) that comprises of Access ICNs, a Transit ICN\nand a Content Provider. Using a generalized Zipf distribution to model content\npopularity, we devise a game theoretic approach to jointly determine caching\nand pricing strategies in such an ICN. Under the assumption that the caching\ncost of the access and transit ICNs is inversely proportional to popularity, we\nshow that the Nash caching strategies in the ICN are 0-1 (all or nothing)\nstrategies. Further, for the case of symmetric Access ICNs, we show that the\nNash equilibrium is unique and the caching policy (0 or 1) is determined by a\nthreshold on the popularity of the content (reflected by the Zipf probability\nmetric), i.e., all content more popular than the threshold value is cached. We\nalso show that the resulting threshold of the Access and Transit ICNs, as well\nas all prices can be obtained by a decomposition of the joint caching and\npricing problem into two independent caching only and pricing only problems. \n\n"}
{"id": "1609.02305", "contents": "Title: Survey of Consistent Software-Defined Network Updates Abstract: Computer networks have become a critical infrastructure. In fact, networks\nshould not only meet strict requirements in terms of correctness, availability,\nand performance, but they should also be very flexible and support fast\nupdates, e.g., due to policy changes, increasing traffic, or failures. This\npaper presents a structured survey of mechanism and protocols to update\ncomputer networks in a fast and consistent manner. In particular, we identify\nand discuss the different desirable consistency properties that should be\nprovided throughout a network update, the algorithmic techniques which are\nneeded to meet these consistency properties, and the implications on the speed\nand costs at which updates can be performed. We also explain the relationship\nbetween consistent network update problems and classic algorithmic optimization\nones. While our survey is mainly motivated by the advent of Software-Defined\nNetworks (SDNs) and their primary need for correct and efficient update\ntechniques, the fundamental underlying problems are not new, and we provide a\nhistorical perspective of the subject as well. \n\n"}
{"id": "1609.02411", "contents": "Title: Velocity-Aware Handover Management in Two-Tier Cellular Networks Abstract: While network densification is considered an important solution to cater the\never-increasing capacity demand, its effect on the handover (HO) rate is\noverlooked. In dense 5G networks, HO delays may neutralize or even negate the\ngains offered by network densification. Hence, user mobility imposes a\nnontrivial challenge to harvest capacity gains via network densification. In\nthis paper, we propose a velocity-aware HO management scheme for two-tier\ndownlink cellular network to mitigate the HO effect on the foreseen\ndensification throughput gains. The proposed HO scheme sacrifices the best BS\nconnectivity, by skipping HO to some BSs along the user's trajectory, to\nmaintain longer connection durations and reduce HO rates. Furthermore, the\nproposed scheme enables cooperative BS service and strongest interference\ncancellation to compensate for skipping the best connectivity. To this end, we\nconsider different HO skipping scenarios and develop a velocity-aware\nmathematical model, via stochastic geometry, to quantify the performance of the\nproposed HO scheme in terms of the coverage probability and user throughput.\nThe results highlight the HO rate problem in dense cellular environments and\nshow the importance of the proposed HO schemes. Finally, the value of BS\ncooperation along with handover skipping is quantified for different user\nmobility profiles. \n\n"}
{"id": "1609.03130", "contents": "Title: Gaussian Processes Online Observation Classification for RSSI-based\n  Low-cost Indoor Positioning Systems Abstract: In this paper, we propose a real-time classification scheme to cope with\nnoisy Radio Signal Strength Indicator (RSSI) measurements utilized in indoor\npositioning systems. RSSI values are often converted to distances for position\nestimation. However due to multipathing and shadowing effects, finding a unique\nsensor model using both parametric and non-parametric methods is highly\nchallenging. We learn decision regions using the Gaussian Processes\nclassification to accept measurements that are consistent with the operating\nsensor model. The proposed approach can perform online, does not rely on a\nparticular sensor model or parameters, and is robust to sensor failures. The\nexperimental results achieved using hardware show that available positioning\nalgorithms can benefit from incorporating the classifier into their measurement\nmodel as a meta-sensor modeling technique. \n\n"}
{"id": "1609.03312", "contents": "Title: Valorising the IoT Databox: Creating Value for Everyone Abstract: The Internet of Things (IoT) is expected to generate large amounts of\nheterogeneous data from diverse sources including physical sensors, user\ndevices, and social media platforms. Over the last few years, significant\nattention has been focused on personal data, particularly data generated by\nsmart wearable and smart home devices. Making personal data available for\naccess and trade is expected to become a part of the data driven digital\neconomy. In this position paper, we review the research challenges in building\npersonal Databoxes that hold personal data and enable data access by other\nparties, and potentially thus sharing of data with other parties. These\nDataboxes are expected to become a core part of future data marketplaces. \n\n"}
{"id": "1609.03363", "contents": "Title: CONDENSE: A Reconfigurable Knowledge Acquisition Architecture for Future\n  5G IoT Abstract: In forthcoming years, the Internet of Things (IoT) will connect billions of\nsmart devices generating and uploading a deluge of data to the cloud. If\nsuccessfully extracted, the knowledge buried in the data can significantly\nimprove the quality of life and foster economic growth. However, a critical\nbottleneck for realising the efficient IoT is the pressure it puts on the\nexisting communication infrastructures, requiring transfer of enormous data\nvolumes. Aiming at addressing this problem, we propose a novel architecture\ndubbed Condense, which integrates the IoT-communication infrastructure into\ndata analysis. This is achieved via the generic concept of network function\ncomputation: Instead of merely transferring data from the IoT sources to the\ncloud, the communication infrastructure should actively participate in the data\nanalysis by carefully designed en-route processing. We define the Condense\narchitecture, its basic layers, and the interactions among its constituent\nmodules. Further, from the implementation side, we describe how Condense can be\nintegrated into the 3rd Generation Partnership Project (3GPP) Machine Type\nCommunications (MTC) architecture, as well as the prospects of making it a\npractically viable technology in a short time frame, relying on Network\nFunction Virtualization (NFV) and Software Defined Networking (SDN). Finally,\nfrom the theoretical side, we survey the relevant literature on computing\n\"atomic\" functions in both analog and digital domains, as well as on function\ndecomposition over networks, highlighting challenges, insights, and future\ndirections for exploiting these techniques within practical 3GPP MTC\narchitecture. \n\n"}
{"id": "1609.04552", "contents": "Title: SCTP User Message Interleaving Integration and Validation Abstract: The Stream Control Transmission Protocol (SCTP) is a connection and message\noriented transport protocol. It supports multiple uni-directional streams in\neach direction allowing user message sequence preservation within each stream.\nThis minimizes the re-sequencing delay at the receiver side in case of message\nloss. The base protocol, although being optimized for small messages, supports\narbitrary large user messages by using fragmentation and reassembly at the cost\nof adding delays at the sender side. To overcome this limitation, a protocol\nextension called User Message Interleaving is currently being specified by the\nInternet Engineering Task Force (IETF). This paper describes the new extension,\nits integration and validation in the context of the INET framework. \n\n"}
{"id": "1609.05362", "contents": "Title: Mobile Edge Computing via a UAV-Mounted Cloudlet: Optimization of Bit\n  Allocation and Path Planning Abstract: Unmanned Aerial Vehicles (UAVs) have been recently considered as means to\nprovide enhanced coverage or relaying services to mobile users (MUs) in\nwireless systems with limited or no infrastructure. In this paper, a UAV-based\nmobile cloud computing system is studied in which a moving UAV is endowed with\ncomputing capabilities to offer computation offloading opportunities to MUs\nwith limited local processing capabilities. The system aims at minimizing the\ntotal mobile energy consumption while satisfying quality of service\nrequirements of the offloaded mobile application. Offloading is enabled by\nuplink and downlink communications between the mobile devices and the UAV that\ntake place by means of frequency division duplex (FDD) via orthogonal or\nnon-orthogonal multiple access (NOMA) schemes. The problem of jointly\noptimizing the bit allocation for uplink and downlink communication as well as\nfor computing at the UAV, along with the cloudlet's trajectory under latency\nand UAV's energy budget constraints is formulated and addressed by leveraging\nsuccessive convex approximation (SCA) strategies. Numerical results demonstrate\nthe significant energy savings that can be accrued by means of the proposed\njoint optimization of bit allocation and cloudlet's trajectory as compared to\nlocal mobile execution as well as to partial optimization approaches that\ndesign only the bit allocation or the cloudlet's trajectory. \n\n"}
{"id": "1609.05670", "contents": "Title: Load-aware Performance Analysis of Cell Center/Edge Users in Random\n  HetNets Abstract: For real-time traffic, the link quality and call blocking probability (both\nderived from coverage probability) are realized to be poor for cell edge users\n(CEUs) compared to cell center users (CCUs) as the signal reception in the cell\ncenter region is better compared to the cell edge region. In heterogeneous\nnetworks (HetNets), the uncoordinated channel access by different types of base\nstations determine the interference statistics that further arbitrates the\ncoverage probability. Thus, the spectrum allocation techniques have major\nimpact on the performance of CCU and CEU. In this paper, the performance of\nCCUs and CEUs in a random two-tier network is studied for two spectrum\nallocation techniques namely: 1) co-channel (CSA), and 2) shared (SSA). For\nperformance analysis, the widely accepted conception of modeling the tiers of\nHetNet using independent homogeneous Poisson point process (PPP) is considered\nto accommodate the spatial randomness in location of BSs. To incorporate the\nspatial randomness in the arrival of service and to aid the load-aware\nanalysis, the cellular traffic is modeled using spatio-temporal PPP. Under this\nscenario, we have developed an analytical framework to evaluate the load-aware\nperformance, including coverage and blocking probabilities, of CCUs and CEUs\nunder both spectrum allocation techniques. Further, we provide insight into\nachievable area energy efficiency for SSA and CSA. The developed analytical\nframework is validated through extensive simulations. Next, we demonstrate the\nimpact of traffic load and femto access points density on the performance of\nCCUs/CEUs under CSA and SSA. \n\n"}
{"id": "1609.06888", "contents": "Title: Analysis of Network Robustness for Finite Sized Wireless Sensor Networks Abstract: Studying network robustness for wireless sensor networks(WSNs) is an exciting\ntopic of research as sensor nodes often fail due to hardware degradation,\nresource constraints, and environmental changes. The application of spectral\ngraph theory to networked systems has generated several important results.\nHowever, previous research has often failed to consider the network parameters,\nwhich is crucial to study the real network applications. Network criticality is\none of the effective metrics to quantify the network robustness against such\nfailures and attacks. In this work, we derive the exact formulas of network\ncriticality for WSNs using r-nearest neighbor networks and we show the effect\nof nearest neighbors and network dimension on robustness using analytical and\nnumerical evaluations. Furthermore, we also show how symmetric and static\napproximations can wrongly designate the network robustness when implemented to\nWSNs. \n\n"}
{"id": "1609.08497", "contents": "Title: Cognitive Random Access for Internet-of-Things Networks Abstract: This paper focuses on cognitive radio (CR) internet- of-things (IoT) networks\nwhere spectrum sensors are deployed for IoT CR devices, which do not have\nenough hardware capability to identify an unoccupied spectrum by themselves. In\nthis sensor- enabled IoT CR network, the CR devices and the sensors are\nseparated. It induces that spectrum occupancies at locations of CR devices and\nsensors could be different. To handle this difference, we investigate a\nconditional interference distribution (CID) at the CR device for a given\nmeasured interference at the sensor. We can observe a spatial correlation of\nthe aggregate interference distribution through the CID. Reflecting the CID, we\ndevise a cognitive random access scheme which adaptively adjusts transmission\nprobability with respect to the interference measurement of the sensor. Our\nscheme improves area spectral efficiency (ASE) compared to a conventional ALOHA\nand an adaptive transmission scheme which attempts to send data when the sensor\nmeasurement is lower than an interference threshold. \n\n"}
{"id": "1609.08888", "contents": "Title: Flexible Dual-Connectivity Spectrum Aggregation for Decoupled Uplink and\n  Downlink Access in 5G Heterogeneous Systems Abstract: Maintaining multiple wireless connections is a promising solution to boost\ncapacity in fifth-generation (5G) networks, where user equipment is able to\nconsume radio resources of several serving cells simultaneously and potentially\naggregate bandwidth across all of them. The emerging dual connectivity paradigm\ncan be regarded as an attractive access mechanism in dense heterogeneous 5G\nnetworks, where bandwidth sharing and cooperative techniques are evolving to\nmeet the increased capacity requirements. Dual connectivity in the uplink\nremained highly controversial, since the user device has a limited power budget\nto share between two different access points, especially when located close to\nthe cell edge. On the other hand, in an attempt to enhance the uplink\ncommunications performance, the concept of uplink and downlink decoupling has\nrecently been introduced. Leveraging these latest developments, our work\nsignificantly advances prior art by proposing and investigating the concept of\nflexible cell association in dual connectivity scenarios, where users are able\nto aggregate resources from more than one serving cell. In this setup, the\npreferred association policies for the uplink may differ from those for the\ndownlink, thereby allowing for a truly decoupled access. With the use of\nstochastic geometry, the dual connectivity association regions for decoupled\naccess are derived and the resultant performance is evaluated in terms of\ncapacity gains over the conventional downlink received power access policies. \n\n"}
{"id": "1609.09682", "contents": "Title: Soft Cache Hits and the Impact of Alternative Content Recommendations on\n  Mobile Edge Caching Abstract: Caching popular content at the edge of future mobile networks has been widely\nconsidered in order to alleviate the impact of the data tsunami on both the\naccess and backhaul networks. A number of interesting techniques have been\nproposed, including femto-caching and \"delayed\" or opportunistic cache access.\nNevertheless, the majority of these approaches suffer from the rather limited\nstorage capacity of the edge caches, compared to the tremendous and rapidly\nincreasing size of the Internet content catalog. We propose to depart from the\nassumption of hard cache misses, common in most existing works, and consider\n\"soft\" cache misses, where if the original content is not available, an\nalternative content that is locally cached can be recommended. Given that\nInternet content consumption is increasingly entertainment-oriented, we believe\nthat a related content could often lead to complete or at least partial user\nsatisfaction, without the need to retrieve the original content over expensive\nlinks. In this paper, we formulate the problem of optimal edge caching with\nsoft cache hits, in the context of delayed access, and analyze the expected\ngains. We then show using synthetic and real datasets of related video contents\nthat promising caching gains could be achieved in practice. \n\n"}
{"id": "1609.09773", "contents": "Title: An Overview of Sustainable Green 5G Networks Abstract: The stringent requirements of a 1,000 times increase in data traffic and one\nmillisecond round trip latency have made limiting the potentially tremendous\nensuing energy consumption one of the most challenging problems for the design\nof the upcoming fifth-generation (5G) networks. To enable sustainable 5G\nnetworks, new technologies have been proposed to improve the system energy\nefficiency and alternative energy sources are introduced to reduce our\ndependence on traditional fossil fuels. In particular, various 5G techniques\ntarget the reduction of the energy consumption without sacrificing the\nquality-of-service. Meanwhile, energy harvesting technologies, which enable\ncommunication transceivers to harvest energy from various renewable resources\nand ambient radio frequency signals for communi- cation, have drawn significant\ninterest from both academia and industry. In this article, we provide an\noverview of the latest research on both green 5G techniques and energy\nharvesting for communication. In addition, some technical challenges and\npotential research topics for realizing sustainable green 5G networks are also\nidentified. \n\n"}
{"id": "1610.00355", "contents": "Title: Security and Privacy Analysis of NSF Future Internet Architectures Abstract: The Internet Protocol (IP) is the lifeblood of the modern Internet. Its\nsimplicity and universality have fueled the unprecedented and lasting global\nsuccess of the current Internet. Nonetheless, some limitations of IP have been\nemerging in recent years. Its original design envisaged supporting perhaps tens\nof thousands of static hosts operating in a friendly academic-like setting,\nmainly in order to facilitate email communication and remote access to scarce\ncomputing resources. At present IP interconnects billions of static and mobile\ndevices (ranging from supercomputers to IoT gadgets) with a large and dynamic\nset of popular applications. Starting in mid-1990s, the advent of mobility,\nwirelessness and the web substantially shifted Internet usage and communication\nparadigms. This accentuated long-term concerns about the current Internet\narchitecture and prompted interest in alternative designs.\n  The U.S. National Science Foundation (NSF) has been one of the key supporters\nof efforts to design a set of candidate next-generation Internet architectures.\nAs a prominent design requirement, NSF emphasized \"security and privacy by\ndesign\" in order to avoid the long and unhappy history of incremental patching\nand retrofitting that characterizes the current Internet architecture. To this\nend, as a result of a competitive process, four prominent research projects\nwere funded by the NSF in 2010: Nebula, Named-Data Networking (NDN),\nMobilityFirst (MF), and Expressive Internet Architecture (XIA). This paper\nprovides a comprehensive and neutral analysis of salient security and privacy\nfeatures (and issues) in these NSF-funded Future Internet Architectures. It\nalso compares the four candidate designs with the current IP-based architecture\nand discusses similarities, differences, and possible improvements. \n\n"}
{"id": "1610.02092", "contents": "Title: Energy Efficiency Optimization of Channel Access Probabilities in IEEE\n  802.15.6 UWB WBANs Abstract: Energy efficiency is essential for Wireless Body Area Network (WBAN)\napplications because of the battery-operated nodes. Other requirements such as\nthroughput, delay, quality of service, and security levels also need to be\nconsidered in optimizing the network design. In this paper, we study the case\nin which the nodes access the medium probabilistically and we formulate an\nenergy efficiency optimization problem under the rate and access probability\nconstraints for IEEE 802.15.6 Impulse Radio Ultra-wideband (IR-UWB) WBANs. The\nproposed algorithm, dubbed Energy Efficiency Optimization of Channel Access\nProbabilities (EECAP), determines the optimal access probability and payload\nframe size for each node. The simulation results show that our algorithm\nrapidly converges to the optimal solution. We also provide detailed insights on\nthe relationship between the optimal access probabilities and other network\nparameters such as the link distance, the number of nodes, and the minimum rate\nconstraints. \n\n"}
{"id": "1610.02318", "contents": "Title: Gibbsian On-Line Distributed Content Caching Strategy for Cellular\n  Networks Abstract: We develop Gibbs sampling based techniques for learning the optimal content\nplacement in a cellular network. A collection of base stations are scattered on\nthe space, each having a cell (possibly overlapping with other cells). Mobile\nusers request for downloads from a finite set of contents according to some\npopularity distribution. Each base station can store only a strict subset of\nthe contents at a time; if a requested content is not available at any serving\nbase station, it has to be downloaded from the backhaul. Thus, there arises the\nproblem of optimal content placement which can minimize the download rate from\nthe backhaul, or equivalently maximize the cache hit rate. Using similar ideas\nas Gibbs sampling, we propose simple sequential content update rules that\ndecide whether to store a content at a base station based on the knowledge of\ncontents in neighbouring base stations. The update rule is shown to be\nasymptotically converging to the optimal content placement for all nodes. Next,\nwe extend the algorithm to address the situation where content popularities and\ncell topology are initially unknown, but are estimated as new requests arrive\nto the base stations. Finally, improvement in cache hit rate is demonstrated\nnumerically. \n\n"}
{"id": "1610.02728", "contents": "Title: Lying Your Way to Better Traffic Engineering Abstract: To optimize the flow of traffic in IP networks, operators do traffic\nengineering (TE), i.e., tune routing-protocol parameters in response to traffic\ndemands. TE in IP networks typically involves configuring static link weights\nand splitting traffic between the resulting shortest-paths via the\nEqual-Cost-MultiPath (ECMP) mechanism. Unfortunately, ECMP is a notoriously\ncumbersome and indirect means for optimizing traffic flow, often leading to\npoor network performance. Also, obtaining accurate knowledge of traffic demands\nas the input to TE is elusive, and traffic conditions can be highly variable,\nfurther complicating TE. We leverage recently proposed schemes for increasing\nECMP's expressiveness via carefully disseminated bogus information (\"lies\") to\ndesign COYOTE, a readily deployable TE scheme for robust and efficient network\nutilization. COYOTE leverages new algorithmic ideas to configure (static)\ntraffic splitting ratios that are optimized with respect to all (even\nadversarially chosen) traffic scenarios within the operator's \"uncertainty\nbounds\". Our experimental analyses show that COYOTE significantly outperforms\ntoday's prevalent TE schemes in a manner that is robust to traffic uncertainty\nand variation. We discuss experiments with a prototype implementation of\nCOYOTE. \n\n"}
{"id": "1610.05238", "contents": "Title: Shortcuts to quantum network routing Abstract: A quantum network promises to enable long distance quantum communication, and\nassemble small quantum devices into a large quantum computing cluster. Each\nnetwork node can thereby be seen as a small few qubit quantum computer. Qubits\ncan be sent over direct physical links connecting nearby quantum nodes, or by\nmeans of teleportation over pre-established entanglement amongst distant\nnetwork nodes. Such pre-shared entanglement effectively forms a shortcut - a\nvirtual quantum link - which can be used exactly once.\n  Here, we present an abstraction of a quantum network that allows ideas from\ncomputer science to be applied to the problem of routing qubits, and manage\nentanglement in the network. Specifically, we consider a scenario in which each\nquantum network node can create EPR pairs with its immediate neighbours over a\nphysical connection, and perform entanglement swapping operations in order to\ncreate long distance virtual quantum links. We proceed to discuss the features\nunique to quantum networks, which call for the development of new routing\ntechniques. As an example, we present two simple hierarchical routing schemes\nfor a quantum network of N nodes for a ring and sphere topology. For these\ntopologies we present efficient routing algorithms requiring O(log N) qubits to\nbe stored at each network node, O(polylog N) time and space to perform routing\ndecisions, and O(log N) timesteps to replenish the virtual quantum links in a\nmodel of entanglement generation. \n\n"}
{"id": "1610.06138", "contents": "Title: Fundamental Limits on Throughput Capacity in Information-Centric Network Abstract: Wireless information-centric networks consider storage as one of the network\nprimitives, and propose to cache data within the network in order to improve\nlatency and reduce bandwidth consumption. We study the throughput capacity and\nlatency in an information-centric network when the data cached in each node has\na limited lifetime. The results show that with some fixed request and cache\nexpiration rates, the order of the data access time does not change with\nnetwork growth, and the maximum throughput order is not changing with the\nnetwork growth in grid networks, and is inversely proportional to the number of\nnodes in one cell in random networks. Comparing these values with the\ncorresponding throughput and latency with no cache capability (throughput\ninversely proportional to the network size, and latency of order $\\sqrt{n}$ and\nthe inverse of the transmission range in grid and random networks,\nrespectively), we can actually quantify the asymptotic advantage of caching.\nMoreover, we compare these scaling laws for different content discovery\nmechanisms and illustrate that not much gain is lost when a simple path search\nis used. \n\n"}
{"id": "1610.06468", "contents": "Title: Ten Blue Links on Mars Abstract: This paper explores a simple question: How would we provide a high-quality\nsearch experience on Mars, where the fundamental physical limit is\nspeed-of-light propagation delays on the order of tens of minutes? On Earth,\nusers are accustomed to nearly instantaneous response times from search\nengines. Is it possible to overcome orders-of-magnitude longer latency to\nprovide a tolerable user experience on Mars? In this paper, we formulate the\nsearching from Mars problem as a tradeoff between \"effort\" (waiting for\nresponses from Earth) and \"data transfer\" (pre-fetching or caching data on\nMars). The contribution of our work is articulating this design space and\npresenting two case studies that explore the effectiveness of baseline\ntechniques, using publicly available data from the TREC Total Recall and\nSessions Tracks. We intend for this research problem to be aspirational and\ninspirational - even if one is not convinced by the premise of Mars\ncolonization, there are Earth-based scenarios such as searching from a rural\nvillage in India that share similar constraints, thus making the problem worthy\nof exploration and attention from researchers. \n\n"}
{"id": "1610.06995", "contents": "Title: Modeling and Analysis of Uplink Non-Orthogonal Multiple Access (NOMA) in\n  Large-Scale Cellular Networks Using Poisson Cluster Processes Abstract: Non-orthogonal multiple access (NOMA) serves multiple users by superposing\ntheir distinct message signals. The desired message signal is decoded at the\nreceiver by applying successive interference cancellation (SIC). Using the\ntheory of Poisson cluster process (PCP), we provide a framework to analyze\nmulti-cell uplink NOMA systems. Specifically, we characterize the rate coverage\nprobability of a NOMA user who is at rank $m$ (in terms of the distance from\nits serving BS) among all users in a cell and the mean rate coverage\nprobability of all users in a cell. Since the signal-to-interference-plus-noise\nratio (SINR) of $m$-th user relies on efficient SIC, we consider three\nscenarios, i.e., perfect SIC (in which the signals of $m-1$ interferers who are\nstronger than $m$-th user are decoded successfully), imperfect SIC (in which\nthe signals of of $m-1$ interferers who are stronger than $m$-th user may or\nmay not be decoded successfully), and imperfect worst case SIC (in which the\ndecoding of the signal of $m$-th user is always unsuccessful whenever the\ndecoding of its relative $m-1$ stronger users is unsuccessful). The derived\nexpressions are customized to capture the performance of a user at rank $m$ in\nan equivalent orthogonal multiple access (OMA) system. Finally, numerical\nresults are presented to validate the derived expressions. \n\n"}
{"id": "1610.09884", "contents": "Title: Isolation probabilities in dynamic soft random geometric graphs Abstract: We consider soft random geometric graphs, constructed by distributing points\n(nodes) randomly according to a Poisson Point Process, and forming links\nbetween pairs of nodes with a probability that depends on their mutual\ndistance, the \"connection function.\" Each node has a probability of being\nisolated depending on the locations of the other nodes; we give analytic\nexpressions for the distribution of isolation probabilities. Keeping the node\nlocations fixed, the links break and reform over time, making a dynamic\nnetwork; this is a good model of a wireless ad-hoc network with communication\nchannels undergoing rapid fading. We use the above isolation probabilities to\ninvestigate the distribution of the time to transmit information to all the\nnodes, finding good agreement with numerics. \n\n"}
{"id": "1611.00688", "contents": "Title: Mitigating Inter-network Interference in LoRa Networks Abstract: Long Range (LoRa) is a popular technology used to construct Low-Power\nWide-Area Network (LPWAN) networks. Given the popularity of LoRa it is likely\nthat multiple independent LoRa networks are deployed in close proximity. In\nthis situation, neighbouring networks interfere and methods have to be found to\ncombat this interference. In this paper we investigate the use of directional\nantennae and the use of multiple base stations as methods of dealing with\ninter-network interference. Directional antennae increase signal strength at\nreceivers without increasing transmission energy cost. Thus, the probability of\nsuccessfully decoding the message in an interference situation is improved.\nMultiple base stations can alternatively be used to improve the probability of\nreceiving a message in a noisy environment. We compare the effectiveness of\nthese two approaches via simulation. Our findings show that both methods are\nable to improve LoRa network performance in interference settings. However, the\nresults show that the use of multiple base stations clearly outperforms the use\nof directional antennae. For example, in a setting where data is collected from\n600 nodes which are interfered by four networks with 600 nodes each, using\nthree base stations improves the Data Extraction Rate (DER) from 0.24 to 0.56\nwhile the use of directional antennae provides an increase to only 0.32. \n\n"}
{"id": "1611.01325", "contents": "Title: Multi-level Simulation of Internet of Things on Smart Territories Abstract: In this paper, a methodology is presented and employed for simulating the\nInternet of Things (IoT). The requirement for scalability, due to the possibly\nhuge amount of involved sensors and devices, and the heterogeneous scenarios\nthat might occur, impose resorting to sophisticated modeling and simulation\ntechniques. In particular, multi-level simulation is regarded as a main\nframework that allows simulating large-scale IoT environments while keeping\nhigh levels of detail, when it is needed. We consider a use case based on the\ndeployment of smart services in decentralized territories. A two level\nsimulator is employed, which is based on a coarse agent-based, adaptive\nparallel and distributed simulation approach to model the general life of\nsimulated entities. However, when needed a finer grained simulator (based on\nOMNeT++) is triggered on a restricted portion of the simulated area, which\nallows considering all issues concerned with wireless communications. Based on\nthis use case, it is confirmed that the ad-hoc wireless networking technologies\ndo represent a principle tool to deploy smart services over decentralized\ncountrysides. Moreover, the performance evaluation confirms the viability of\nutilizing multi-level simulation for simulating large scale IoT environments. \n\n"}
{"id": "1611.02828", "contents": "Title: What Is the True Value of Dynamic TDD: A MAC Layer Perspective Abstract: Small cell networks (SCNs) are envisioned to embrace dynamic time division\nduplexing (TDD) in order to tailor downlink (DL)/uplink (UL) subframe resources\nto quick variations and burstiness of DL/UL traffic. The study of dynamic TDD\nis particularly important because it provides valuable insights on the full\nduplex transmission technology, which has been identified as one of the\ncandidate technologies for the 5th-generation (5G) networks. Up to now, the\nexisting works on dynamic TDD have shown that the UL of dynamic TDD suffers\nfrom severe performance degradation due to the strong DL-to-UL interference in\nthe physical (PHY) layer. This conclusion raises a fundamental question:\nDespite such obvious technology disadvantage, what is the true value of dynamic\nTDD? In this paper, we answer this question from a media access control (MAC)\nlayer viewpoint and present analytical results on the DL/UL time resource\nutilization (TRU) of synchronous dynamic TDD, which has been widely adopted in\nthe existing 4th-generation (4G) systems. Our analytical results shed new light\non the dynamic TDD in future synchronous 5G networks. \n\n"}
{"id": "1611.03197", "contents": "Title: Multiple Service Chain Placement and Routing in a Network-enabled Cloud Abstract: Network Function Virtualization (NFV) aims to abstract the functionality of\ntraditional proprietary hardware into software as Virtual Network Functions\n(VNFs), which can run on commercial off the shelf (COTS) servers. Besides\nreducing dependency on proprietary support, NFV helps network operators to\ndeploy multiple services in a agile fashion. Service deployment involves\nplacement and in sequence routing through VNFs comprising a Service Chain (SC).\nOur study is the first to focus on the computationally complex problem of\nmultiple VNF SC placement and routing while considering VNF service chaining\nexplicitly. We propose a novel column generation model for placing multiple VNF\nSCs and routing, which reduces the computational complexity of the problem\nsignificantly. Our aim here is to determine the ideal NFV Infrastructure (NFVI)\nfor minimizing network resource consumption. Our results indicate that a\nNetwork enabled Cloud (NeC) results in lower networkresource consumption than a\ncentralized NFVI (e.g., Data Center) while avoiding infeasibility with a\ndistributed NFVI. \n\n"}
{"id": "1611.04268", "contents": "Title: AntMonitor: A System for On-Device Mobile Network Monitoring and its\n  Applications Abstract: In this paper, we present a complete system for on-device passive monitoring,\ncollection, and analysis of fine grained, large-scale packet measurements from\nmobile devices. First, we describe the design and implementation of AntMonitor\nas a userspace mobile app based on a VPN-service but only on the device\n(without the need to route through a remote VPN server) and using only the\nminimum resources required. We evaluate our prototype and show that it\nsignificantly outperforms prior state-of-the-art approaches: it achieves\nthroughput of over 90 Mbps downlink and 65 Mbps uplink, which is 2x and 8x\nfaster than mobile-only baselines and is 94% of the throughput without VPN,\nwhile using 2-12x less energy. Second, we show that AntMonitor is uniquely\npositioned to serve as a platform for passive on-device mobile network\nmonitoring and to enable a number of applications, including: (i) real-time\ndetection and prevention of private information leakage from the device to the\nnetwork; (ii) passive network performance monitoring; and (iii) application\nclassification and user profiling. We showcase preliminary results from a pilot\nuser study at a university campus. \n\n"}
{"id": "1611.06609", "contents": "Title: MAC Protocols for IEEE 802.11ax: Avoiding Collisions on Dense Networks Abstract: Wireless networks have become the main form of Internet access. Statistics\nshow that the global mobile Internet penetration should exceed 70\\% until 2019.\nWi-Fi is an important player in this change. Founded on IEEE 802.11, this\ntechnology has a crucial impact in how we share broadband access both in\ndomestic and corporate networks. However, recent works have indicated\nperformance issues in Wi-Fi networks, mainly when they have been deployed\nwithout planning and under high user density. Hence, different collision\navoidance techniques and Medium Access Control protocols have been designed in\norder to improve Wi-Fi performance. Analyzing the collision problem, this work\nstrengthens the claims found in the literature about the low Wi-Fi performance\nunder dense scenarios. Then, in particular, this article overviews the MAC\nprotocols used in the IEEE 802.11 standard and discusses solutions to mitigate\ncollisions. Finally, it contributes presenting future trends in MAC protocols.\nThis assists in foreseeing expected improvements for the next generation of\nWi-Fi devices. \n\n"}
{"id": "1611.06905", "contents": "Title: Security Schemes in Vehicular Ad hoc Networks with Cognitive Radios Abstract: Vehicular Ad hoc NETworks (VANETs) as the basic infrastructure can facilitate\napplications and services of connected vehicles (CVs). Cognitive radio (CR)\ntechnology is an effective supplement and enhancement for VANETs. It can reduce\nthe impact of deficiency of spectrum resource in VANETs. Although CR-VANETs can\nutilize the unused licensed spectrum effectively, the distributed nature of\nCR-VANETs may open a door for different attacks, such as spectrum sensing data\nfalsification attack. In this paper, we propose a joint RSU and vehicle-based\nlight-weighted cloud for CR-VANETs. Based on this cloud computing model, we\npropose a new service named Spectrum Sensing as a Service (SSaaS), which can\nperform a cooperative spectrum sensing in CR-VANETs with cloud computing\nassistance to secure the spectrum sensing procedure. As a result, a reliable\nservice can be obtained in CR-VANETs. Simulation results show that the cloud\ncomputing in CR-VANETs can effectively reduce latency and improve the security\nof CR-VANETs. \n\n"}
{"id": "1611.07238", "contents": "Title: Time and Space Optimal Counting in Population Protocols Abstract: This work concerns the general issue of combined optimality in terms of time\nand space complexity. In this context, we study the problem of (exact) counting\nresource-limited and passively mobile nodes in the model of population\nprotocols, in which the space complexity is crucial. The counted nodes are\nmemory-limited anonymous devices (called agents) communicating asynchronously\nin pairs (according to a fairness condition). Moreover, we assume that these\nagents are prone to failures so that they cannot be correctly initialized. This\nstudy considers two classical fairness conditions, and for each we investigate\nthe issue of time optimality of counting given the optimal space per agent. In\nthe case of randomly interacting agents (probabilistic fairness), as usual, the\nconvergence time is measured in terms of parallel time (or parallel\ninteractions), which is defined as the number of pairwise interactions until\nconvergence, divided by n (the number of agents). In case of weak fairness,\nwhere it is only required that every pair of agents interacts infinitely often,\nthe convergence time is defined in terms of non-null transitions, i.e, the\ntransitions that affect the states of the interacting agents.First, assuming\nprobabilistic fairness, we present a \"non-guessing\" time optimal protocol of\nO(n log n) expected time given an optimal space of only one bit, and we prove\nthe time optimality of this protocol. Then, for weak fairness, we show that a\nspace optimal (semi-uniform) solution cannot converge faster than in\n$\\Omega$(2^n) time (non-null transitions). This result, together with the time\ncomplexity analysis of an already known space optimal protocol, shows that it\nis also optimal in time (given the optimal space constrains). \n\n"}
{"id": "1611.09243", "contents": "Title: Energy-Efficient Resource Allocation for Mobile Edge Computing-Based\n  Augmented Reality Applications Abstract: Mobile edge computing is a provisioning solution to enable Augmented Reality\n(AR) applications on mobile devices. AR mobile applications have inherent\ncollaborative properties in terms of data collection in the uplink, computing\nat the edge, and data delivery in the downlink. In this letter, these features\nare leveraged to propose a novel resource allocation approach over both\ncommunication and computation resources. The approach, implemented via\nSuccessive Convex Approximation (SCA), is seen to yield considerable gains in\nmobile energy consumption as compared to conventional independent offloading\nacross users. \n\n"}
{"id": "1612.00397", "contents": "Title: Maximal Sections of Sheaves of Data over an Abstract Simplicial Complex Abstract: We employ techniques from topological data analysis to model sensor networks.\nOur approach to sensor integration uses the topological method of sheaves over\ncell complexes. The internal consistency of data from individual sensors is\ndetermined by a set of consistency functions assigned to elements of the\ncomplex. Using these functions we determine, for any collection of data, the\nunique set of maximal sections of consistent data received from the sensors. We\noffer a proof for the existence and uniqueness of these sections and illustrate\nthe ideas with examples. \n\n"}
{"id": "1612.01264", "contents": "Title: New Generation Value Networks for Content Delivery Abstract: In this paper we paint a broad picture of the Internet content delivery\nmarket, by taking into consideration both economical and technical challenges\nthat might drive the interactions among the stakeholders in the future. We\nfocus on a few disrupting factors, namely ubiquitous encryption, traffic boost,\nnetwork scalability, latency needs and network control; and try to figure out\nwhether the current model (CDN) is robust against their variation, which\noptimization can be envisioned and how the most accredited option (ICN) can be\nof help. \n\n"}
{"id": "1612.01436", "contents": "Title: Collaborative Multi-bitrate Video Caching and Processing in Mobile-Edge\n  Computing Networks Abstract: Recently, Mobile-Edge Computing (MEC) has arisen as an emerging paradigm that\nextends cloud-computing capabilities to the edge of the Radio Access Network\n(RAN) by deploying MEC servers right at the Base Stations (BSs). In this paper,\nwe envision a collaborative joint caching and processing strategy for on-demand\nvideo streaming in MEC networks. Our design aims at enhancing the widely used\nAdaptive BitRate (ABR) streaming technology, where multiple bitrate versions of\na video can be delivered so as to adapt to the heterogeneity of user\ncapabilities and the varying of network connection bandwidth. The proposed\nstrategy faces two main challenges: (i) not only the videos but their\nappropriate bitrate versions have to be effectively selected to store in the\ncaches, and (ii) the transcoding relationships among different versions need to\nbe taken into account to effectively utilize the processing capacity at the MEC\nservers. To this end, we formulate the collaborative joint caching and\nprocessing problem as an Integer Linear Program (ILP) that minimizes the\nbackhaul network cost, subject to the cache storage and processing capacity\nconstraints. Due to the NP-completeness of the problem and the impractical\noverheads of the existing offline approaches, we propose a novel online\nalgorithm that makes cache placement and video scheduling decisions upon the\narrival of each new request. Extensive simulations results demonstrate the\nsignificant performance improvement of the proposed strategy over traditional\napproaches in terms of cache hit ratio increase, backhaul traffic and initial\naccess delay reduction. \n\n"}
{"id": "1612.02466", "contents": "Title: Secure and reliable connectivity in heterogeneous wireless sensor\n  networks Abstract: We consider wireless sensor networks secured by the heterogeneous random key\npredistribution scheme under an on/off channel model. The heterogeneous random\nkey predistribution scheme considers the case when the network includes sensor\nnodes with varying levels of resources, features, or connectivity requirements;\ne.g., regular nodes vs. cluster heads, but does not incorporate the fact that\nwireless channel are unreliable. To capture the unreliability of the wireless\nmedium, we use an on/off channel model; wherein, each wireless channel is\neither on (with probability $\\alpha$) or off (with probability $1-\\alpha$)\nindependently. We present conditions (in the form of zero-one laws) on how to\nscale the parameters of the network model so that with high probability the\nnetwork is $k$-connected, i.e., the network remains connected even if any $k-1$\nnodes fail or leave the network. We also present numerical results to support\nthese conditions in the finite-node regime. \n\n"}
{"id": "1612.03005", "contents": "Title: No domain left behind: is Let's Encrypt democratizing encryption? Abstract: The 2013 National Security Agency revelations of pervasive monitoring have\nlead to an \"encryption rush\" across the computer and Internet industry. To push\nback against massive surveillance and protect users privacy, vendors, hosting\nand cloud providers have widely deployed encryption on their hardware,\ncommunication links, and applications. As a consequence, the most of web\ntraffic nowadays is encrypted. However, there is still a significant part of\nInternet traffic that is not encrypted. It has been argued that both costs and\ncomplexity associated with obtaining and deploying X.509 certificates are major\nbarriers for widespread encryption, since these certificates are required to\nestablished encrypted connections. To address these issues, the Electronic\nFrontier Foundation, Mozilla Foundation, and the University of Michigan have\nset up Let's Encrypt (LE), a certificate authority that provides both free\nX.509 certificates and software that automates the deployment of these\ncertificates. In this paper, we investigate if LE has been successful in\ndemocratizing encryption: we analyze certificate issuance in the first year of\nLE and show from various perspectives that LE adoption has an upward trend and\nit is in fact being successful in covering the lower-cost end of the hosting\nmarket. \n\n"}
{"id": "1612.04531", "contents": "Title: Cost Efficiency Optimization of 5G Wireless Backhaul Networks Abstract: The wireless backhaul network provides an attractive solution for the urban\ndeployment of fifth generation (5G) wireless networks that enables future ultra\ndense small cell networks to meet the ever-increasing user demands. Optimal\ndeployment and management of 5G wireless backhaul networks is an interesting\nand challenging issue. In this paper we propose the optimal gateways deployment\nand wireless backhaul route schemes to maximize the cost efficiency of 5G\nwireless backhaul networks. In generally, the changes of gateways deployment\nand wireless backhaul route are presented in different time scales.\nSpecifically, the number and locations of gateways are optimized in the long\ntime scale of 5G wireless backhaul networks. The wireless backhaul routings are\noptimized in the short time scale of 5G wireless backhaul networks considering\nthe time-variant over wireless channels. Numerical results show the gateways\nand wireless backhaul route optimization significantly increases the cost\nefficiency of 5G wireless backhaul networks. Moreover, the cost efficiency of\nproposed optimization algorithm is better than that of conventional and most\nwidely used shortest path (SP) and Bellman-Ford (BF) algorithms in 5G wireless\nbackhaul networks. \n\n"}
{"id": "1612.05291", "contents": "Title: Catalyzing Cloud-Fog Interoperation in 5G Wireless Networks: An SDN\n  Approach Abstract: The piling up storage and compute stacks in cloud data center are expected to\naccommodate the majority of internet traffic in the future. However, as the\nnumber of mobile devices significantly increases, getting massive data into and\nout of the cloud wirelessly inflicts high pressure on the bandwidth, and\nmeanwhile induces unpredictable latency. Fog computing, which advocates\nextending clouds to network edge, guarantees low latency and location-aware\nservice provisioning. In this article, we consider fog computing as an ideal\ncomplement rather than a substitute of cloud computing, and we propose a\nsoftware defined networking (SDN) enabled framework for cloud-fog\ninteroperation, aiming at improving quality of experience and optimizing\nnetwork resource usage. Two case studies are provided to illuminate the\nfeasibility and advantage of the proposed framework. At last, potential\nresearch issues are presented for further investigation. \n\n"}
{"id": "1612.05539", "contents": "Title: Greedy Routing and the Algorithmic Small-World Phenomenom Abstract: The algorithmic small-world phenomenon, empirically established by Milgram's\nletter forwarding experiments from the 60s, was theoretically explained by\nKleinberg in 2000. However, from today's perspective his model has several\nsevere shortcomings that limit the applicability to real-world networks. In\norder to give a more convincing explanation of the algorithmic small-world\nphenomenon, we study decentralized greedy routing in a more flexible random\ngraph model (geometric inhomogeneous random graphs) which overcomes all\nprevious shortcomings. Apart from exhibiting good properties in theory, it has\nalso been extensively experimentally validated that this model reasonably\ncaptures real-world networks.\n  In this model, the greedy routing protocol is purely distributed as each\nvertex only needs to know information about its direct neighbors. We prove that\nit succeeds with constant probability, and in case of success almost surely\nfinds an almost shortest path of length {\\theta}(loglog n), where our bound is\ntight including the leading constant. Moreover, we study natural local patching\nmethods which augment greedy routing by backtracking and which do not require\nany global knowledge. We show that such methods can ensure success probability\n1 in an asymptotically tight number of steps.\n  These results also address the question of Krioukov et al. whether there are\nefficient local routing protocols for the internet graph. There were promising\nexperimental studies, but the question remained unsolved theoretically. Our\nresults give for the first time a rigorous and analytical affirmative answer. \n\n"}
{"id": "1612.07862", "contents": "Title: Optimal Resource Allocation for Cellular Networks with MATLAB\n  Instructions Abstract: This report presents a more detailed description of the algorithm and\nsimulations published in papers [1, 2]. It includes a step by step description\nof the algorithm and included the corresponding flow chart. In addition,\ndetailed instructions of the MATLAB code used to simulate the proposed\nallocation algorithm in [1, 2] is presented. The report starts with a brief\nmotivation of resource allocation problem in wireless networks. Then, some of\nthe prior related work on the subject are mentioned. Finally, we provide the\ndetails instructions on MATLAB functions used in our algorithm. More rigorous\nanalysis and proofs of the problem and algorithm are present in [1, 2] and\nfurther discussions presented in [3, 4]. \n\n"}
{"id": "1612.09198", "contents": "Title: Optimizing spatial throughput in device-to-device networks Abstract: Results are presented for optimizing device-to-device communications in\ncellular networks, while maintaining spectral efficiency of the\nbase-station-to-device downlink channel. We build upon established and tested\nstochastic geometry models of signal-to-interference ratio in wireless networks\nbased on the Poisson point process, which incorporate random propagation\neffects such as fading and shadowing. A key result is a simple formula,\nallowing one to optimize the device-to-device spatial throughput by suitably\nadjusting the proportion of active devices. These results can lead to further\ninvestigation as they can be immediately applied to more sophisticated models\nsuch as studying multi-tier network models to address coverage in closed access\nnetworks. \n\n"}
{"id": "1701.02979", "contents": "Title: Multi-Antenna Coded Caching Abstract: In this paper we consider a single-cell downlink scenario where a\nmultiple-antenna base station delivers contents to multiple cache-enabled user\nterminals. Based on the multicasting opportunities provided by the so-called\nCoded Caching technique, we investigate three delivery approaches. Our baseline\nscheme employs the coded caching technique on top of max-min fair multicasting.\nThe second one consists of a joint design of Zero-Forcing (ZF) and coded\ncaching, where the coded chunks are formed in the signal domain (complex\nfield). The third scheme is similar to the second one with the difference that\nthe coded chunks are formed in the data domain (finite field). We derive\nclosed-form rate expressions where our results suggest that the latter two\nschemes surpass the first one in terms of Degrees of Freedom (DoF). However, at\nthe intermediate SNR regime forming coded chunks in the signal domain results\nin power loss, and will deteriorate throughput of the second scheme. The main\nmessage of our paper is that the schemes performing well in terms of DoF may\nnot be directly appropriate for intermediate SNR regimes, and modified schemes\nshould be employed. \n\n"}
{"id": "1701.03247", "contents": "Title: Scalable Spectrum Allocation and User Association in Networks with Many\n  Small Cells Abstract: A scalable framework is developed to allocate radio resources across a large\nnumber of densely deployed small cells with given traffic statistics on a slow\ntimescale. Joint user association and spectrum allocation is first formulated\nas a convex optimization problem by dividing the spectrum among all possible\ntransmission patterns of active access points (APs). To improve scalability\nwith the number of APs, the problem is reformulated using local patterns of\ninterfering APs. To maintain global consistency among local patterns,\ninter-cluster interaction is characterized as hyper-edges in a hyper-graph with\nnodes corresponding to neighborhoods of APs. A scalable solution is obtained by\niteratively solving a convex optimization problem for bandwidth allocation with\nreduced complexity and constructing a global spectrum allocation using\nhyper-graph coloring. Numerical results demonstrate the proposed solution for a\nnetwork with 100 APs and several hundred user equipments. For a given quality\nof service (QoS), the proposed scheme can increase the network capacity several\nfold compared to assigning each user to the strongest AP with full-spectrum\nreuse. \n\n"}
{"id": "1701.03831", "contents": "Title: Delay-Optimal Scheduling for Queueing Systems with Switching Overhead Abstract: We study the scheduling polices for asymptotically optimal delay in queueing\nsystems with switching overhead. Such systems consist of a single server that\nserves multiple queues, and some capacity is lost whenever the server switches\nto serve a different set of queues. The capacity loss due to this switching\noverhead can be significant in many emerging applications, and needs to be\nexplicitly addressed in the design of scheduling policies. For example, in\n60GHz wireless networks with directional antennas, base stations need to train\nand reconfigure their beam patterns whenever they switch from one client to\nanother. Considerable switching overhead can also be observed in many other\nqueueing systems such as transportation networks and manufacturing systems.\nWhile the celebrated Max-Weight policy achieves asymptotically optimal average\ndelay for systems without switching overhead, it fails to preserve\nthroughput-optimality, let alone delay-optimality, when switching overhead is\ntaken into account. We propose a class of Biased Max-Weight scheduling policies\nthat explicitly takes switching overhead into account. The Biased Max-Weight\npolicy can use either queue length or head-of-line waiting time as an indicator\nof the system status. We prove that our policies not only are\nthroughput-optimal, but also can be made arbitrarily close to the asymptotic\nlower bound on average delay. To validate the performance of the proposed\npolicies, we provide extensive simulation with various system topologies and\ndifferent traffic patterns. We show that the proposed policies indeed achieve\nmuch better delay performance than that of the state-of-the-art policy. \n\n"}
{"id": "1701.04065", "contents": "Title: On the Asymptotic Behavior of Ultra-Densification under a Bounded\n  Dual-Slope Path Loss Model Abstract: In this paper, we investigate the impact of network densification on the\nperformance in terms of downlink signal-to-interference (SIR) coverage\nprobability and network area spectral efficiency (ASE). A sophisticated bounded\ndual-slope path loss model and practical user equipment (UE) densities are\nincorporated in the analysis, which have never been jointly considered before.\nBy using stochastic geometry, we derive an integral expression along with\nclosed-form bounds of the coverage probability and ASE, validated by simulation\nresults. Through these, we provide the asymptotic behavior of\nultra-densification. The coverage probability and ASE have non-zero convergence\nin asymptotic regions unless UE density goes to infinity (full load).\nMeanwhile, the effect of UE density on the coverage probability is analyzed.\nThe coverage probability will reveal an U-shape for large UE densities due to\ninterference fall into the near-field, but it will keep increasing for low UE\ndensites. Furthermore, our results indicate that the performance is\noverestimated without applying the bounded dual-slope path loss model. The\nderived expressions and results in this work pave the way for future network\nprovisioning. \n\n"}
{"id": "1701.04562", "contents": "Title: A Game-Theoretic Model for Analysis and Design of Self-Organization\n  Mechanisms in IoT Abstract: We propose a framework based on Network Formation Game for self-organization\nin the Internet of Things (IoT), in which heterogeneous and multi-interface\nnodes are modeled as self-interested agents who individually decide on\nestablishment and severance of links to other agents. Through analysis of the\nstatic game, we formally confirm the emergence of realistic topologies from our\nmodel, and analytically establish the criteria that lead to stable multi-hop\nnetwork structures. \n\n"}
{"id": "1701.04673", "contents": "Title: HARE: Supporting efficient uplink multi-hop communications in\n  self-organizing LPWANs Abstract: The emergence of low-power wide area networks (LPWANs) as a new agent in the\nInternet of Things (IoT) will result in the incorporation into the digital\nworld of low-automated processes from a wide variety of sectors. The single-hop\nconception of typical LPWAN deployments, though simple and robust, overlooks\nthe self-organization capabilities of network devices, suffers from lack of\nscalability in crowded scenarios, and pays little attention to energy\nconsumption. Aimed to take the most out of devices' capabilities, the HARE\nprotocol stack is proposed in this paper as a new LPWAN technology flexible\nenough to adopt uplink multi-hop communications when proving energetically more\nefficient. In this way, results from a real testbed show energy savings of up\nto 15% when using a multi-hop approach while keeping the same network\nreliability. System's self-organizing capability and resilience have been also\nvalidated after performing numerous iterations of the association mechanism and\ndeliberately switching off network devices. \n\n"}
{"id": "1701.05007", "contents": "Title: IoTScanner: Detecting and Classifying Privacy Threats in IoT\n  Neighborhoods Abstract: In the context of the emerging Internet of Things (IoT), a proliferation of\nwireless connectivity can be expected. That ubiquitous wireless communication\nwill be hard to centrally manage and control, and can be expected to be opaque\nto end users. As a result, owners and users of physical space are threatened to\nlose control over their digital environments.\n  In this work, we propose the idea of an IoTScanner. The IoTScanner integrates\na range of radios to allow local reconnaissance of existing wireless\ninfrastructure and participating nodes. It enumerates such devices, identifies\nconnection patterns, and provides valuable insights for technical support and\nhome users alike. Using our IoTScanner, we attempt to classify actively\nstreaming IP cameras from other non-camera devices using simple heuristics. We\nshow that our classification approach achieves a high accuracy in an IoT\nsetting consisting of a large number of IoT devices. While related work usually\nfocuses on detecting either the infrastructure, or eavesdropping on traffic\nfrom a specific node, we focus on providing a general overview of operations in\nall observed networks. We do not assume prior knowledge of used SSIDs,\npreshared passwords, or similar. \n\n"}
{"id": "1701.05711", "contents": "Title: Age-Optimal Information Updates in Multihop Networks Abstract: The problem of reducing the age-of-information has been extensively studied\nin the single-hop networks. In this paper, we minimize the age-of-information\nin general multihop networks. If the packet transmission times over the network\nlinks are exponentially distributed, we prove that a preemptive Last Generated\nFirst Served (LGFS) policy results in smaller age processes at all nodes of the\nnetwork (in a stochastic ordering sense) than any other causal policy. In\naddition, for arbitrary general distributions of packet transmission times, the\nnon-preemptive LGFS policy is shown to minimize the age processes at all nodes\nof the network among all non-preemptive work-conserving policies (again in a\nstochastic ordering sense). It is surprising that such simple policies can\nachieve optimality of the joint distribution of the age processes at all nodes\neven under arbitrary network topologies, as well as arbitrary packet generation\nand arrival times. These optimality results not only hold for the age\nprocesses, but also for any non-decreasing functional of the age processes. \n\n"}
{"id": "1701.06051", "contents": "Title: The Economics of Competition and Cooperation Between MNOs and MVNOs Abstract: In this work, we consider the economics of the interaction between Mobile\nVirtual Network Operators (MVNOs) and Mobile Network Operators (MNOs). We\ninvestigate the incentives of an MNO for offering some of her resources to an\nMVNO instead of using the resources for her own. We formulate the problem as a\nsequential game. We consider a market with one MNO and one MVNO, and a\ncontinuum of undecided end-users. We assume that EUs have different preferences\nfor the MNO and the MVNO. These preferences can be because of the differences\nin the service they are offering or the reluctance of an EU to buy her plan\nfrom one of them. We assume that the preferences also depend on the investment\nlevel the MNO and the MVNO. We show that there exists a unique interior SPNE,\ni.e. the SPNE by which both SPs receive a positive mass of EUs, and\ncharacterize it. We also consider a benchmark case in which the MNO and the\nMVNO do not cooperate, characterize the unique SPNE of this case, and compare\nthe results of our model to the benchmark case to assess the incentive of the\nMNO to invest in her infrastructure and to offer it to the MVNO. \n\n"}
{"id": "1701.06303", "contents": "Title: Delivery Latency Trade-Offs of Heterogeneous Contents in Fog Radio\n  Access Networks Abstract: A Fog Radio Access Network (F-RAN) is a cellular wireless system that enables\ncontent delivery via the caching of popular content at edge nodes (ENs) and\ncloud processing. The existing information-theoretic analyses of F-RAN systems,\nand special cases thereof, make the assumption that all requests should be\nguaranteed the same delivery latency, which results in identical latency for\nall files in the content library. In practice, however, contents may have\nheterogeneous timeliness requirements depending on the applications that\noperate on them. Given per-EN cache capacity constraint, there exists a\nfundamental trade-off among the delivery latencies of different users'\nrequests, since contents that are allocated more cache space generally enjoy\nlower delivery latencies. For the case with two ENs and two users, the optimal\nlatency trade-off is characterized in the high-SNR regime in terms of the\nNormalized Delivery Time (NDT) metric. The main results are illustrated by\nnumerical examples. \n\n"}
{"id": "1701.08059", "contents": "Title: Efficient Medium Access Arbitration Among Interfering WBANs Using Latin\n  Rectangles Abstract: The overlap of transmission ranges among multiple Wireless Body Area Networks\n(WBANs) is referred to as coexistence. The interference is most likely to\naffect the communication links and degrade the performance when sensors of\ndifferent WBANs simultaneously transmit using the same channel. In this paper,\nwe propose a distributed approach that adapts to the size of the network, i.e.,\nthe number of coexisting WBANs, and to the density of sensors forming each\nindividual WBAN in order to minimize the impact of co-channel interference\nthrough dynamic channel hopping based on Latin rectangles. Furthermore, the\nproposed approach opts to reduce the overhead resulting from channel hopping,\nand lowers the transmission delay, and saves the power resource at both sensor-\nand WBAN-levels. Specifically, we propose two schemes for channel allocation\nand medium access scheduling to diminish the probability of inter-WBAN\ninterference. The first scheme, namely, Distributed Interference Avoidance\nusing Latin rectangles (DAIL), assigns channel and time-slot combination that\nreduces the probability of medium access collision. DAIL suits crowded areas,\ne.g., high density of coexisting WBANs, and involves overhead due to frequent\nchannel hopping at the WBAN coordinator and sensors. The second scheme, namely,\nCHIM, takes advantage of the relatively lower density of collocated WBANs to\nsave power by hopping among channels only when interference is detected at the\nlevel of the individual nodes. We present an analytical model that derives the\ncollision probability and network throughput. The performance of DAIL and CHIM\nis further validated through simulations. \n\n"}
{"id": "1701.08680", "contents": "Title: Fog-Assisted wIoT: A Smart Fog Gateway for End-to-End Analytics in\n  Wearable Internet of Things Abstract: Today, wearable internet-of-things (wIoT) devices continuously flood the\ncloud data centers at an enormous rate. This increases a demand to deploy an\nedge infrastructure for computing, intelligence, and storage close to the\nusers. The emerging paradigm of fog computing could play an important role to\nmake wIoT more efficient and affordable. Fog computing is known as the cloud on\nthe ground. This paper presents an end-to-end architecture that performs data\nconditioning and intelligent filtering for generating smart analytics from\nwearable data. In wIoT, wearable sensor devices serve on one end while the\ncloud backend offers services on the other end. We developed a prototype of\nsmart fog gateway (a middle layer) using Intel Edison and Raspberry Pi. We\ndiscussed the role of the smart fog gateway in orchestrating the process of\ndata conditioning, intelligent filtering, smart analytics, and selective\ntransfer to the cloud for long-term storage and temporal variability\nmonitoring. We benchmarked the performance of developed prototypes on\nreal-world data from smart e-textile gloves. Results demonstrated the usability\nand potential of proposed architecture for converting the real-world data into\nuseful analytics while making use of knowledge-based models. In this way, the\nsmart fog gateway enhances the end-to-end interaction between wearables (sensor\ndevices) and the cloud. \n\n"}
{"id": "1701.09011", "contents": "Title: Overlay Routing for Fast Video Transfers in CDN Abstract: Content Delivery Networks (CDN) are witnessing the outburst of video\nstreaming (e.g., personal live streaming or Video-on-Demand) where the video\ncontent, produced or accessed by mobile phones, must be quickly transferred\nfrom a point to another of the network. Whenever a user requests a video not\ndirectly available at the edge server, the CDN network must 1) identify the\nbest location in the network where the content is stored, 2) set up a\nconnection and 3) deliver the video as quickly as possible. For this reason,\nexisting CDNs are adopting an overlay structure to reduce latency, leveraging\nthe flexibility introduced by the Software Defined Networking (SDN) paradigm.\nIn order to guarantee a satisfactory Quality of Experience (QoE) to users, the\nconnection must respect several Quality of Service (QoS) constraints. In this\npaper, we focus on the sub-problem 2), by presenting an approach to efficiently\ncompute and maintain paths in the overlay network. Our approach allows to speed\nup the transfer of video segments by finding minimum delay overlay paths under\nconstraints on hop count, jitter, packet loss and relay processing capacity.\nThe proposed algorithm provides a near-optimal solution, while drastically\nreducing the execution time. We show on traces collected in a real CDN that our\nsolution allows to maximize the number of fast video transfers. \n\n"}
{"id": "1702.00209", "contents": "Title: On Consideration of Content Preference and Sharing Willingness in D2D\n  Assisted Offloading Abstract: Device-to-device (D2D) assisted offloading heavily depends on the\nparticipation of human users. The content preference and sharing willingness of\nhuman users are two crucial factors in the D2D assisted offloading. In this\npaper, with consideration of these two factors, the optimal content pushing\nstrategy is investigated by formulating an optimization problem to maximize the\noffloading gain measured by the offloaded traffic. Users are placed into groups\naccording to their content preferences, and share content with intergroup and\nintragroup users at different sharing probabilities. Although the optimization\nproblem is nonconvex, the closed-form optimal solution for a special case is\nobtained, when the sharing probabilities for intergroup and intragroup users\nare the same. Furthermore, an alternative group optimization (AGO) algorithm is\nproposed to solve the general case of the optimization problem. Finally,\nsimulation results are provided to demonstrate the offloading performance\nachieved by the optimal pushing strategy for the special case and AGO\nalgorithm. An interesting conclusion drawn is that the group with the largest\nnumber of interested users is not necessarily given the highest pushing\nprobability. It is more important to give high pushing probability to users\nwith high sharing willingness. \n\n"}
{"id": "1702.01018", "contents": "Title: On Robustness in Multilayer Interdependent Network Abstract: Critical Infrastructures like power and communication networks are highly\ninterdependent on each other for their full functionality. Many significant\nresearch have been pursued to model the interdependency and failure analysis of\nthese interdependent networks. However, most of these models fail to capture\nthe complex interdependencies that might actually exist between the\ninfrastructures. The \\emph{Implicative Interdependency Model} that utilizes\nBoolean Logic to capture complex interdependencies was recently proposed which\novercome the limitations of the existing models. A number of problems were\nstudies based on this model. In this paper we study the \\textit{Robustness}\nproblem in Interdependent Power and Communication Network. The robustness is\ndefined with respect to two parameters $K \\in I^{+} \\cup \\{0\\}$ and $\\rho \\in\n(0,1]$. We utilized the \\emph{Implicative Interdependency Model} model to\ncapture the complex interdependency between the two networks. The model\nclassifies the interdependency relations into four cases. Computational\ncomplexity of the problem is analyzed for each of these cases. A polynomial\ntime algorithm is designed for the first case that outputs the optimal\nsolution. All the other cases are proved to be NP-complete. An\nin-approximability bound is provided for the third case. For the general case\nwe formulate an Integer Linear Program to get the optimal solution and a\npolynomial time heuristic. The applicability of the heuristic is evaluated\nusing power and communication network data of Maricopa County, Arizona. The\nexperimental results showed that the heuristic almost always produced near\noptimal value of parameter $K$ for $\\rho < 0.42$. \n\n"}
{"id": "1702.01963", "contents": "Title: Seamless Handover in IP over ICN Networks: a Coding Approach Abstract: Seamless connectivity plays a key role in realising QoS-based delivery in\nmobile networks. However, current handover mechanisms hinder the ability to\nmeet this target, due to the high ratio of handover failures, packet loss and\nservice interruption. These challenges are further magnified in Heterogeneous\nCellular Networks (HCN) such as Advanced Long Term Evolution (LTE-Advanced) and\nLTE in unlicensed spectrum (LTE-LAA), due to the variation in handover\nrequirements. Although mechanisms, such as Fast Handover for Proxy Mobile IPv6\n(PFMIPv6), attempt to tackle these issues; they come at a high cost with\nsub-optimal outcomes. This primarily stems from various limitations of existing\nIP core networks. In this paper we propose a novel handover solution for mobile\nnetworks, exploiting the advantages of a revolutionary IP over\nInformation-Centric Networking (IP-over-ICN) architecture in supporting\nflexible service provisioning through anycast and multicast, combined with the\nadvantages of random linear coding techniques in eliminating the need for\nretransmissions. Our solution allows coded traffic to be disseminated in a\nmulticast fashion during handover phase from source directly to the\ndestination(s), without the need for an intermediate anchor as in exiting\nsolutions; thereby, overcoming packet loss and handover failures, while\nreducing overall delivery cost. We evaluate our approach with an analytical and\nsimulation model showing significant cost reduction compared to PFMIPv6. \n\n"}
{"id": "1702.02775", "contents": "Title: Software-Defined Network Controlled Switching between Millimeter Wave\n  and Terahertz Small Cells Abstract: Small cells are a cost-effective way to reliably expand network coverage and\nprovide significantly increased capacity for end users. The ultra-high\nbandwidth available at millimeter (mmWave) and Terahertz (THz) frequencies can\neffectively realize short-range wireless access links in small cells enabling\npotential uses cases such as driver-less cars, data backhauling and\nultra-high-definition infotainment services. This paper describes a new\nsoftware defined network (SDN) framework for vehicles equipped with\ntransceivers capable of dynamically switching between THz and mmWave bands. We\npresent a novel SDN controlled admission policy that preferentially handoffs\nbetween the mmWave and THz small cells, accommodates asymmetric uplink/downlink\ntraffic, performs error recovery and handles distinct link states that arise\ndue to motion along practical vehicular paths. We then analytically derive the\nresulting capacity of such a small cell network by accounting for the channel\ncharacteristics unique to both these spectrum bands, relative distance and the\ncontact times between a given transceiver pair. We then formulate the optimal\nprocedure for scheduling multiple vehicles at a given infrastructure tower,\nwith regards to practical road congestion scenarios. The search for the optimal\nschedule is shown to be a NP-hard problem. Hence, we design a\ncomputationally-feasible polynomial-time scheduling algorithm that runs at the\nSDN controller and compare its performance against the optimal procedure and\nrandom access. Additionally, we present a simulation-based case study for the\nuse case of data center backhauling in Boston city to showcase the benefits of\nour approach. \n\n"}
{"id": "1702.04020", "contents": "Title: Towards LTE-U Interference Detection, Assessment and Mitigation in\n  802.11 Networks using Commodity Hardware Abstract: We propose WiPLUS -- a system that enables WiFi to deal with the stealthy\ninvasion of LTE-U into the frequency bands used by WiFi. Using solely MAC layer\ninformation extracted passively, during runtime, out of the hardware registers\nof the WiFi NIC at the WiFi access point, WiPLUS is able to: i) detect\ninterfering LTE-U signals, ii) compute their duty-cycles, and iii) derive the\neffective medium airtime available for each WiFi link in a WiFi Basic Service\nSet (BSS). Moreover WiPLUS provides accurate timing information about the\ndetected LTE-U ON and OFF phases enabling advanced interference mitigation\nstrategies such as interference-aware scheduling of packet transmissions, rate\nadaptation and adaptive channel bonding.\n  WiPLUS does not require any modifications to the WiFi client stations and\nworks with commodity WiFi APs where it has a simple software installation\nprocess.\n  We present the design, the implementation details and the evaluation of the\nWiPLUS approach. Evaluation results reveal that it is able to accurately\nestimate the effective available medium airtime for each link in a WiFi BSS\nunder a wide range of LTE-U signal strengths with a root-mean-square error of\nless than 3% for the downlink and less 10% for the uplink. \n\n"}
{"id": "1702.04249", "contents": "Title: Experimentation with MANETs of Smartphones Abstract: Mobile AdHoc NETworks (MANETs) have been identified as a key emerging\ntechnology for scenarios in which IEEE 802.11 or cellular communications are\neither infeasible, inefficient, or cost-ineffective. Smartphones are the most\nadequate network nodes in many of these scenarios, but it is not\nstraightforward to build a network with them. We extensively survey existing\npossibilities to build applications on top of ad-hoc smartphone networks for\nexperimentation purposes, and introduce a taxonomy to classify them. We present\nAdHocDroid, an Android package that creates an IP-level MANET of (rooted)\nAndroid smartphones, and make it publicly available to the community.\nAdHocDroid supports standard TCP/IP applications, providing real smartphone\nIEEE 802.11 MANET and the capability to easily change the routing protocol. We\ntested our framework on several smartphones and a laptop. We validate the MANET\nrunning off-the-shelf applications, and reporting on experimental performance\nevaluation, including network metrics and battery discharge rate. \n\n"}
{"id": "1702.04264", "contents": "Title: Beam Alignment for Millimetre Wave Links with Motion Prediction of\n  Autonomous Vehicles Abstract: Intelligent Transportation Systems (ITSs) require ultra-low end-to-end delays\nand multi-gigabit-per-second data transmission. Millimetre Waves (mmWaves)\ncommunications can fulfil these requirements. However, the increased mobility\nof Connected and Autonomous Vehicles (CAVs), requires frequent beamforming -\nthus introducing increased overhead. In this paper, a new beamforming algorithm\nis proposed able to achieve overhead-free beamforming training. Leveraging from\nthe CAVs sensory data, broadcast with Dedicated Short Range Communications\n(DSRC) beacons, the position and the motion of a CAV can be estimated and\nbeamform accordingly. To minimise the position errors, an analysis of the\ndistinct error components was presented. The network performance is further\nenhanced by adapting the antenna beamwidth with respect to the position error.\nOur algorithm outperforms the legacy IEEE 802.11ad approach proving it a viable\nsolution for the future ITS applications and services. \n\n"}
{"id": "1702.05309", "contents": "Title: Mobile Edge Computing: A Survey on Architecture and Computation\n  Offloading Abstract: Technological evolution of mobile user equipments (UEs), such as smartphones\nor laptops, goes hand-in-hand with evolution of new mobile applications.\nHowever, running computationally demanding applications at the UEs is\nconstrained by limited battery capacity and energy consumption of the UEs.\nSuitable solution extending the battery life-time of the UEs is to offload the\napplications demanding huge processing to a conventional centralized cloud\n(CC). Nevertheless, this option introduces significant execution delay\nconsisting in delivery of the offloaded applications to the cloud and back plus\ntime of the computation at the cloud. Such delay is inconvenient and make the\noffloading unsuitable for real-time applications. To cope with the delay\nproblem, a new emerging concept, known as mobile edge computing (MEC), has been\nintroduced. The MEC brings computation and storage resources to the edge of\nmobile network enabling to run the highly demanding applications at the UE\nwhile meeting strict delay requirements. The MEC computing resources can be\nexploited also by operators and third parties for specific purposes. In this\npaper, we first describe major use cases and reference scenarios where the MEC\nis applicable. After that we survey existing concepts integrating MEC\nfunctionalities to the mobile networks and discuss current advancement in\nstandardization of the MEC. The core of this survey is, then, focused on\nuser-oriented use case in the MEC, i.e., computation offloading. In this\nregard, we divide the research on computation offloading to three key areas: i)\ndecision on computation offloading, ii) allocation of computing resource within\nthe MEC, and iii) mobility management. Finally, we highlight lessons learned in\narea of the MEC and we discuss open research challenges yet to be addressed in\norder to fully enjoy potentials offered by the MEC. \n\n"}
{"id": "1702.05706", "contents": "Title: Poisson Cluster Process: Bridging the Gap Between PPP and 3GPP HetNet\n  Models Abstract: The growing complexity of heterogeneous cellular networks (HetNets) has\nnecessitated the need to consider variety of user and base station (BS)\nconfigurations for realistic performance evaluation and system design. This is\ndirectly reflected in the HetNet simulation models considered by\nstandardization bodies, such as the third generation partnership project\n(3GPP). Complementary to these simulation models, stochastic geometry based\napproach modeling the user and BS locations as independent and homogeneous\nPoisson point processes (PPPs) has gained prominence in the past few years.\nDespite its success in revealing useful insights, this PPP-based model is not\nrich enough to capture all the spatial configurations that appear in real world\nHetNet deployments (on which 3GPP simulation models are based). In this paper,\nwe bridge the gap between the 3GPP simulation models and the popular PPP-based\nanalytical model by developing a new unified HetNet model in which a fraction\nof users and some BS tiers are modeled as Poisson cluster processes (PCPs).\nThis model captures both non-uniformity and coupling in the BS and user\nlocations. For this setup, we derive exact expression for downlink coverage\nprobability under maximum signal-to-interference ratio (SIR) cell association\nmodel. As intermediate results, we define and evaluate sum-product functionals\nfor PPP and PCP. Special instances of the proposed model are shown to closely\nresemble different configurations considered in 3GPP HetNet models. Our results\nconcretely demonstrate that the performance trends are highly sensitive to the\nassumptions made on the user and SBS configurations. \n\n"}
{"id": "1702.06772", "contents": "Title: Efficient CSMA using Regional Free Energy Approximations Abstract: CSMA (Carrier Sense Multiple Access) algorithms based on Gibbs sampling can\nachieve throughput optimality if certain parameters called the fugacities are\nappropriately chosen. However, the problem of computing these fugacities is\nNP-hard. In this work, we derive estimates of the fugacities by using a\nframework called the regional free energy approximations. In particular, we\nderive explicit expressions for approximate fugacities corresponding to any\nfeasible service rate vector. We further prove that our approximate fugacities\nare exact for the class of chordal graphs. A distinguishing feature of our work\nis that the regional approximations that we propose are tailored to conflict\ngraphs with small cycles, which is a typical characteristic of wireless\nnetworks. Numerical results indicate that the fugacities obtained by the\nproposed method are quite accurate and significantly outperform the existing\nBethe approximation based techniques. \n\n"}
{"id": "1703.00123", "contents": "Title: DTNC: A New Server-side Data Cleansing Framework for Cellular Trajectory\n  Services Abstract: It is essential for the cellular network operators to provide cellular\nlocation services to meet the needs of their users and mobile applications.\nHowever, cellular locations, estimated by network-based methods at the\nserver-side, bear with {\\it high spatial errors} and {\\it arbitrary missing\nlocations}. Moreover, auxiliary sensor data at the client-side are not\navailable to the operators. In this paper, we study the {\\em cellular\ntrajectory cleansing problem} and propose an innovative data cleansing\nframework, namely \\underline{D}ynamic \\underline{T}ransportation\n\\underline{N}etwork based \\underline{C}leansing (DTNC) to improve the quality\nof cellular locations delivered in online cellular trajectory services. We\nmaintain a dynamic transportation network (DTN), which associates a network\nedge with a probabilistic distribution of travel times updated continuously. In\naddition, we devise an object motion model, namely, {\\em travel-time-aware\nhidden semi-Markov model} ({\\em TT-HsMM}), which is used to infer the most\nprobable traveled edge sequences on DTN. To validate our ideas, we conduct a\ncomprehensive evaluation using real-world cellular data provided by a major\ncellular network operator and a GPS dataset collected by smartphones as the\nground truth. In the experiments, DTNC displays significant advantages over six\nstate-of-the-art techniques. \n\n"}
{"id": "1703.00520", "contents": "Title: Geohyperbolic Routing and Addressing Schemes Abstract: The key requirement to routing in any telecommunication network, and\nespecially in Internet-of-Things (IoT) networks, is scalability. Routing must\nroute packets between any source and destination in the network without\nincurring unmanageable routing overhead that grows quickly with increasing\nnetwork size and dynamics. Here we present an addressing scheme and a coupled\nnetwork topology design scheme that guarantee essentially optimal routing\nscalability. The FIB sizes are as small as they can be, equal to the number of\nadjacencies a node has, while the routing control overhead is minimized as\nnearly zero routing control messages are exchanged even upon catastrophic\nfailures in the network. The key new ingredient is the addressing scheme, which\nis purely local, based only on geographic coordinates of nodes and a centrality\nmeasure, and does not require any sophisticated non-local computations or\nglobal network topology knowledge for network embedding. The price paid for\nthese benefits is that network topology cannot be arbitrary but should follow a\nspecific design, resulting in Internet-like topologies. The proposed schemes\ncan be most easily deployed in overlay networks, and also in other network\ndeployments, where geolocation information is available, and where network\ntopology can grow following the design specifications. \n\n"}
{"id": "1703.02149", "contents": "Title: Decentralized Consistent Network Updates in SDN with ez-Segway Abstract: We present ez-Segway, a decentralized mechanism to consistently and quickly\nupdate the network state while preventing forwarding anomalies (loops and\nblack-holes) and avoiding link congestion. In our design, the centralized SDN\ncontroller only pre-computes information needed by the switches during the\nupdate execution. This information is distributed to the switches, which use\npartial knowledge and direct message passing to efficiently realize the update.\nThis separation of concerns has the key benefit of improving update performance\nas the communication and computation bottlenecks at the controller are removed.\nOur evaluations via network emulations and large-scale simulations demonstrate\nthe efficiency of ez-Segway, which compared to a centralized approach, improves\nnetwork update times by up to 45% and 57% at the median and the 99th\npercentile, respectively. A deployment of a system prototype in a real OpenFlow\nswitch and an implementation in P4 demonstrate the feasibility and low overhead\nof implementing simple network update functionality within switches. \n\n"}
{"id": "1703.02799", "contents": "Title: A Low-Complexity Adaptive Multisine Waveform Design for Wireless Power\n  Transfer Abstract: Far-field Wireless Power Transfer (WPT) has attracted significant attention\nin the last decade. Recently, channel-adaptive waveforms have been shown to\nsignificantly increase the DC power level at the output of the rectifier.\nHowever the design of those waveforms is generally computationally complex and\ndoes not lend itself easily to practical implementation. We here propose a\nlow-complexity channel-adaptive multisine waveform design whose performance is\nvery close to that of the optimal design. Performance evaluations confirm the\nbenefits of the new design in various rectifier topologies. \n\n"}
{"id": "1703.06060", "contents": "Title: Online Learning for Offloading and Autoscaling in Energy Harvesting\n  Mobile Edge Computing Abstract: Mobile edge computing (a.k.a. fog computing) has recently emerged to enable\nin-situ processing of delay-sensitive applications at the edge of mobile\nnetworks. Providing grid power supply in support of mobile edge computing,\nhowever, is costly and even infeasible (in certain rugged or under-developed\nareas), thus mandating on-site renewable energy as a major or even sole power\nsupply in increasingly many scenarios. Nonetheless, the high intermittency and\nunpredictability of renewable energy make it very challenging to deliver a high\nquality of service to users in energy harvesting mobile edge computing systems.\nIn this paper, we address the challenge of incorporating renewables into mobile\nedge computing and propose an efficient reinforcement learning-based resource\nmanagement algorithm, which learns on-the-fly the optimal policy of dynamic\nworkload offloading (to the centralized cloud) and edge server provisioning to\nminimize the long-term system cost (including both service delay and\noperational cost). Our online learning algorithm uses a decomposition of the\n(offline) value iteration and (online) reinforcement learning, thus achieving a\nsignificant improvement of learning rate and run-time performance when compared\nto standard reinforcement learning algorithms such as Q-learning. We prove the\nconvergence of the proposed algorithm and analytically show that the learned\npolicy has a simple monotone structure amenable to practical implementation.\nOur simulation results validate the efficacy of our algorithm, which\nsignificantly improves the edge computing performance compared to fixed or\nmyopic optimization schemes and conventional reinforcement learning algorithms. \n\n"}
{"id": "1703.06992", "contents": "Title: A Framework and Comparative Analysis of Control Plane Security of SDN\n  and Conventional Networks Abstract: Software defined networking implements the network control plane in an\nexternal entity, rather than in each individual device as in conventional\nnetworks. This architectural difference implies a different design for control\nfunctions necessary for essential network properties, e.g., loop prevention and\nlink redundancy. We explore how such differences redefine the security\nweaknesses in the SDN control plane and provide a framework for comparative\nanalysis which focuses on essential network properties required by typical\nproduction networks. This enables analysis of how these properties are\ndelivered by the control planes of SDN and conventional networks, and to\ncompare security risks and mitigations. Despite the architectural difference,\nwe find similar, but not identical, exposures in control plane security if both\nnetwork paradigms provide the same network properties and are analyzed under\nthe same threat model. However, defenses vary; SDN cannot depend on edge based\nfiltering to protect its control plane, while this is arguably the primary\ndefense in conventional networks. Our concrete security analysis suggests that\na distributed SDN architecture that supports fault tolerance and consistency\nchecks is important for SDN control plane security. Our analysis methodology\nmay be of independent interest for future security analysis of SDN and\nconventional networks. \n\n"}
{"id": "1703.07419", "contents": "Title: Optimal Routing for Delay-Sensitive Traffic in Overlay Networks Abstract: We design dynamic routing policies for an overlay network which meet delay\nrequirements of real-time traffic being served on top of an underlying legacy\nnetwork, where the overlay nodes do not know the underlay characteristics. We\npose the problem as a constrained MDP, and show that when the underlay\nimplements static policies such as FIFO with randomized routing, then a\ndecentralized policy, that can be computed efficiently in a distributed\nfashion, is optimal. Our algorithm utilizes multi-timescale stochastic\napproximation techniques, and its convergence relies on the fact that the\nrecursions asymptotically track a nonlinear differential equation, namely the\nreplicator equation. Extensive simulations show that the proposed policy indeed\noutperforms the existing policies. \n\n"}
{"id": "1703.07551", "contents": "Title: MopEye: Opportunistic Monitoring of Per-app Mobile Network Performance Abstract: Crowdsourcing mobile user's network performance has become an effective way\nof understanding and improving mobile network performance and user\nquality-of-experience. However, the current measurement method is still based\non the landline measurement paradigm in which a measurement app measures the\npath to fixed (measurement or web) servers. In this work, we introduce a new\nparadigm of measuring per-app mobile network performance. We design and\nimplement MopEye, an Android app to measure network round-trip delay for each\napp whenever there is app traffic. This opportunistic measurement can be\nconducted automatically without users intervention. Therefore, it can\nfacilitate a large-scale and long-term crowdsourcing of mobile network\nperformance. In the course of implementing MopEye, we have overcome a suite of\nchallenges to make the continuous latency monitoring lightweight and accurate.\nWe have deployed MopEye to Google Play for an IRB-approved crowdsourcing study\nin a period of ten months, which obtains over five million measurements from\n6,266 Android apps on 2,351 smartphones. The analysis reveals a number of new\nfindings on the per-app network performance and mobile DNS performance. \n\n"}
{"id": "1703.08109", "contents": "Title: Cayley graphs and symmetric interconnection networks Abstract: These lecture notes are on automorphism groups of Cayley graphs and their\napplications to optimal fault-tolerance of some interconnection networks. We\nfirst give an introduction to automorphisms of graphs and an introduction to\nCayley graphs. We then discuss automorphism groups of Cayley graphs. We prove\nthat the vertex-connectivity of edge-transitive graphs is maximum possible. We\ninvestigate the automorphism group and vertex-connectivity of some families of\nCayley graphs that have been considered for interconnection networks; we focus\non the hypercubes, folded hypercubes, Cayley graphs generated by\ntranspositions, and Cayley graphs from linear codes. New questions and open\nproblems are also discussed. \n\n"}
{"id": "1703.08206", "contents": "Title: Understand Your Chains: Towards Performance Profile-based Network\n  Service Management Abstract: Allocating resources to virtualized network functions and services to meet\nservice level agreements is a challenging task for NFV management and\norchestration systems. This becomes even more challenging when agile\ndevelopment methodologies, like DevOps, are applied. In such scenarios,\nmanagement and orchestration systems are continuously facing new versions of\nfunctions and services which makes it hard to decide how much resources have to\nbe allocated to them to provide the expected service performance. One solution\nfor this problem is to support resource allocation decisions with performance\nbehavior information obtained by profiling techniques applied to such network\nfunctions and services.\n  In this position paper, we analyze and discuss the components needed to\ngenerate such performance behavior information within the NFV DevOps workflow.\nWe also outline research questions that identify open issues and missing pieces\nfor a fully integrated NFV profiling solution. Further, we introduce a novel\nprofiling mechanism that is able to profile virtualized network functions and\nentire network service chains under different resource constraints before they\nare deployed on production infrastructure. \n\n"}
{"id": "1703.08337", "contents": "Title: Taming Tail Latency for Erasure-coded, Distributed Storage Systems Abstract: Distributed storage systems are known to be susceptible to long tails in\nresponse time. In modern online storage systems such as Bing, Facebook, and\nAmazon, the long tails of the service latency are of particular concern. with\n99.9th percentile response times being orders of magnitude worse than the mean.\nAs erasure codes emerge as a popular technique to achieve high data reliability\nin distributed storage while attaining space efficiency, taming tail latency\nstill remains an open problem due to the lack of mathematical models for\nanalyzing such systems. To this end, we propose a framework for quantifying and\noptimizing tail latency in erasure-coded storage systems. In particular, we\nderive upper bounds on tail latency in closed form for arbitrary service time\ndistribution and heterogeneous files. Based on the model, we formulate an\noptimization problem to jointly minimize the weighted latency tail probability\nof all files over the placement of files on the servers, and the choice of\nservers to access the requested files. The non-convex problem is solved using\nan efficient, alternating optimization algorithm. Numerical results show\nsignificant reduction of tail latency for erasure-coded storage systems with a\nrealistic workload. \n\n"}
{"id": "1703.08985", "contents": "Title: TCP in 5G mmWave Networks: Link Level Retransmissions and MP-TCP Abstract: MmWave communications, one of the cornerstones of future 5G mobile networks,\nare characterized at the same time by a potential multi-gigabit capacity and by\na very dynamic channel, sensitive to blockage, wide fluctuations in the\nreceived signal quality, and possibly also sudden link disruption. While the\nperformance of physical and MAC layer schemes that address these issues has\nbeen thoroughly investigated in the literature, the complex interactions\nbetween mmWave links and transport layer protocols such as TCP are still\nrelatively unexplored. This paper uses the ns-3 mmWave module, with its channel\nmodel based on real measurements in New York City, to analyze the performance\nof the Linux TCP/IP stack (i) with and without link-layer retransmissions,\nshowing that they are fundamental to reach a high TCP throughput on mmWave\nlinks and (ii) with Multipath TCP (MP-TCP) over multiple LTE and mmWave links,\nillustrating which are the throughput-optimal combinations of secondary paths\nand congestion control algorithms in different conditions. \n\n"}
{"id": "1703.09025", "contents": "Title: Service Overlay Forest Embedding for Software-Defined Cloud Networks Abstract: Network Function Virtualization (NFV) on Software-Defined Networks (SDN) can\neffectively optimize the allocation of Virtual Network Functions (VNFs) and the\nrouting of network flows simultaneously. Nevertheless, most previous studies on\nNFV focus on unicast service chains and thereby are not scalable to support a\nlarge number of destinations in multicast. On the other hand, the allocation of\nVNFs has not been supported in the current SDN multicast routing algorithms. In\nthis paper, therefore, we make the first attempt to tackle a new challenging\nproblem for finding a service forest with multiple service trees, where each\ntree contains multiple VNFs required by each destination. Specifically, we\nformulate a new optimization, named Service Overlay Forest (SOF), to minimize\nthe total cost of all allocated VNFs and all multicast trees in the forest. We\ndesign a new $3\\rho_{ST}$-approximation algorithm to solve the problem, where\n$\\rho_{ST}$ denotes the best approximation ratio of the Steiner Tree problem,\nand the distributed implementation of the algorithm is also presented.\nSimulation results on real networks for data centers manifest that the proposed\nalgorithm outperforms the existing ones by over 25%. Moreover, the\nimplementation of an experimental SDN with HP OpenFlow switches indicates that\nSOF can significantly improve the QoE of the Youtube service. \n\n"}
{"id": "1703.09989", "contents": "Title: Electrosense: Open and Big Spectrum Data Abstract: While the radio spectrum allocation is well regulated, there is little\nknowledge about its actual utilization over time and space. This limitation\nhinders taking effective actions in various applications including cognitive\nradios, electrosmog monitoring, and law enforcement. We introduce Electrosense,\nan initiative that seeks a more efficient, safe and reliable monitoring of the\nelectromagnetic space by improving the accessibility of spectrum data for the\ngeneral public. A collaborative spectrum monitoring network is designed that\nmonitors the spectrum at large scale with low-cost spectrum sensing nodes. The\nlarge set of data is stored and processed in a big data architecture and\nprovided back to the community with an open spectrum data as a service model,\nthat allows users to build diverse and novel applications with different\nrequirements. We illustrate useful usage scenarios of the Electrosense data. \n\n"}
{"id": "1703.10575", "contents": "Title: Delay versus Stickiness Violation Trade-offs for Load Balancing in\n  Large-Scale Data Centers Abstract: Most load balancing techniques implemented in current data centers tend to\nrely on a mapping from packets to server IP addresses through a hash value\ncalculated from the flow five-tuple. The hash calculation allows extremely fast\npacket forwarding and provides flow `stickiness', meaning that all packets\nbelonging to the same flow get dispatched to the same server. Unfortunately,\nsuch static hashing may not yield an optimal degree of load balancing, e.g.,\ndue to variations in server processing speeds or traffic patterns. On the other\nhand, dynamic schemes, such as the Join-the-Shortest-Queue (JSQ) scheme,\nprovide a natural way to mitigate load imbalances, but at the expense of\nstickiness violation.\n  In the present paper we examine the fundamental trade-off between stickiness\nviolation and packet-level latency performance in large-scale data centers. We\nestablish that stringent flow stickiness carries a significant performance\npenalty in terms of packet-level delay. Moreover, relaxing the stickiness\nrequirement by a minuscule amount is highly effective in clipping the tail of\nthe latency distribution. We further propose a bin-based load balancing scheme\nthat achieves a good balance among scalability, stickiness violation and\npacket-level delay performance. Extensive simulation experiments corroborate\nthe analytical results and validate the effectiveness of the bin-based load\nbalancing scheme. \n\n"}
{"id": "1704.02613", "contents": "Title: Deep Multi-User Reinforcement Learning for Distributed Dynamic Spectrum\n  Access Abstract: We consider the problem of dynamic spectrum access for network utility\nmaximization in multichannel wireless networks. The shared bandwidth is divided\ninto K orthogonal channels. In the beginning of each time slot, each user\nselects a channel and transmits a packet with a certain transmission\nprobability. After each time slot, each user that has transmitted a packet\nreceives a local observation indicating whether its packet was successfully\ndelivered or not (i.e., ACK signal). The objective is a multi-user strategy for\naccessing the spectrum that maximizes a certain network utility in a\ndistributed manner without online coordination or message exchanges between\nusers. Obtaining an optimal solution for the spectrum access problem is\ncomputationally expensive in general due to the large state space and partial\nobservability of the states. To tackle this problem, we develop a novel\ndistributed dynamic spectrum access algorithm based on deep multi-user\nreinforcement leaning. Specifically, at each time slot, each user maps its\ncurrent state to spectrum access actions based on a trained deep-Q network used\nto maximize the objective function. Game theoretic analysis of the system\ndynamics is developed for establishing design principles for the implementation\nof the algorithm. Experimental results demonstrate strong performance of the\nalgorithm. \n\n"}
{"id": "1704.02790", "contents": "Title: Performance Analysis of Reliable Video Streaming with Strict Playout\n  Deadline in Multi-Hop Wireless Networks Abstract: Motivated by emerging vision-based intelligent services, we consider the\nproblem of rate adaptation for high quality and low delay visual information\ndelivery over wireless networks using scalable video coding. Rate adaptation in\nthis setting is inherently challenging due to the interplay between the\nvariability of the wireless channels, the queuing at the network nodes and the\nframe-based decoding and playback of the video content at the receiver at very\nshort time scales. To address the problem, we propose a low-complexity,\nmodel-based rate adaptation algorithm for scalable video streaming systems,\nbuilding on a novel performance model based on stochastic network calculus. We\nvalidate the model using extensive simulations. We show that it allows fast,\nnear optimal rate adaptation for fixed transmission paths, as well as\ncross-layer optimized routing and video rate adaptation in mesh networks, with\nless than $10$\\% quality degradation compared to the best achievable\nperformance. \n\n"}
{"id": "1704.04146", "contents": "Title: Traffic Minimizing Caching and Latent Variable Distributions of Order\n  Statistics Abstract: Given a statistical model for the request frequencies and sizes of data\nobjects in a caching system, we derive the probability density of the size of\nthe file that accounts for the largest amount of data traffic. This is\nequivalent to finding the required size of the cache for a caching placement\nthat maximizes the expected byte hit ratio for given file size and popularity\ndistributions. The file that maximizes the expected byte hit ratio is the file\nfor which the product of its size and popularity is the highest -- thus, it is\nthe file that incurs the greatest load on the network. We generalize this\ntheoretical problem to cover factors and addends of arbitrary order statistics\nfor given parent distributions. Further, we study the asymptotic behavior of\nthese distributions. We give several factor and addend densities of widely-used\ndistributions, and verify our results by extensive computer simulations. \n\n"}
{"id": "1704.05125", "contents": "Title: Performance Impact of Base Station Antenna Heights in Dense Cellular\n  Networks Abstract: In this paper, we present a new and significant theoretical discovery. If the\nabsolute height difference between base station (BS) antenna and user equipment\n(UE) antenna is larger than zero, then the network performance in terms of both\nthe coverage probability and the area spectral efficiency (ASE) will\ncontinuously decrease toward zero as the BS density increases for ultra-dense\n(UD) small cell networks (SCNs). Such findings are completely different from\nthe conclusions in existing works, both quantitatively and qualitatively. In\nparticular, this performance behavior has a tremendous impact on the deployment\nof UD SCNs in the 5th-generation (5G) era. Network operators may invest large\namounts of money in deploying more network infrastructure to only obtain an\neven less network capacity. Our study results reveal that one way to address\nthis issue is to lower the SCN BS antenna height to the UE antenna height.\nHowever, this requires a revolutionized approach of BS architecture and\ndeployment, which is explored in this paper too. \n\n"}
{"id": "1704.05296", "contents": "Title: Coverage and Rate of Downlink Sequence Transmissions with Reliability\n  Guarantees Abstract: Real-time distributed control is a promising application of 5G in which\ncommunication links should satisfy certain reliability guarantees. In this\nletter, we derive closed-form maximum average rate when a device (e.g.\nindustrial machine) downloads a sequence of n operational commands through\ncellular connection, while guaranteeing a certain signal-to-interference ratio\n(SIR) coverage for all n messages. The result is based on novel closed-form\nn-successive SIR coverage bounds. The proposed bounds provide simple\napproximations that are increasingly accurate in the high reliability region. \n\n"}
{"id": "1704.05400", "contents": "Title: Waveform Design for Wireless Power Transfer with Limited Feedback Abstract: Waveform design is a key technique to jointly exploit a beamforming gain, the\nchannel frequency-selectivity and the rectifier nonlinearity, so as to enhance\nthe end-to-end power transfer efficiency of Wireless Power Transfer (WPT).\nThose waveforms have been designed assuming perfect channel state information\nat the transmitter. This paper proposes two waveform strategies relying on\nlimited feedback for multi-antenna multi-sine WPT over frequency-selective\nchannels. In the waveform selection strategy, the Energy Transmitter (ET)\ntransmits over multiple timeslots with every time a different waveform precoder\nwithin a codebook, and the Energy Receiver (ER) reports the index of the\nprecoder in the codebook that leads to the largest harvested energy. In the\nwaveform refinement strategy, the ET sequentially transmits two waveforms in\neach stage, and the ER reports one feedback bit indicating an increase/decrease\nin the harvested energy during this stage. Based on multiple one-bit feedback,\nthe ET successively refines waveform precoders in a tree-structured codebook\nover multiple stages. By employing the framework of the generalized Lloyd's\nalgorithm, novel algorithms are proposed for both strategies to optimize the\ncodebooks in both space and frequency domains. The proposed limited\nfeedback-based waveform strategies are shown to outperform a set of baselines,\nachieving higher harvested energy. \n\n"}
{"id": "1704.05684", "contents": "Title: A Distributed Scheduling Algorithm to Provide Quality-of-Service in\n  Multihop Wireless Networks Abstract: Control of multihop Wireless networks in a distributed manner while providing\nend-to-end delay requirements for different flows, is a challenging problem.\nUsing the notions of Draining Time and Discrete Review from the theory of fluid\nlimits of queues, an algorithm that meets delay requirements to various flows\nin a network is constructed. The algorithm involves an optimization which is\nimplemented in a cyclic distributed manner across nodes by using the technique\nof iterative gradient ascent, with minimal information exchange between nodes.\nThe algorithm uses time varying weights to give priority to flows. The\nperformance of the algorithm is studied in a network with interference modelled\nby independent sets. \n\n"}
{"id": "1704.06716", "contents": "Title: Service Chain (SC) Mapping with Multiple SC Instances in a Wide Area\n  Network Abstract: Network Function Virtualization (NFV) aims to simplify deployment of network\nservices by running Virtual Network Functions (VNFs) on commercial\noff-the-shelf servers. Service deployment involves placement of VNFs and\nin-sequence routing of traffic flows through VNFs comprising a Service Chain\n(SC). The joint VNF placement and traffic routing is usually referred as SC\nmapping. In a Wide Area Network (WAN), a situation may arise where several\ntraffic flows, generated by many distributed node pairs, require the same SC,\none single instance (or occurrence) of that SC might not be enough. SC mapping\nwith multiple SC instances for the same SC turns out to be a very complex\nproblem, since the sequential traversal of VNFs has to be maintained while\naccounting for traffic flows in various directions. Our study is the first to\ndeal with SC mapping with multiple SC instances to minimize network resource\nconsumption. Exact mathematical modeling of this problem results in a quadratic\nformulation. We propose a two-phase column-generation-based model and solution\nin order to get results over large network topologies within reasonable\ncomputational times. Using such an approach, we observe that an appropriate\nchoice of only a small set of SC instances can lead to solution very close to\nthe minimum bandwidth consumption. \n\n"}
{"id": "1704.06847", "contents": "Title: A hybrid primal heuristic for Robust Multiperiod Network Design Abstract: We investigate the Robust Multiperiod Network Design Problem, a\ngeneralization of the classical Capacitated Network Design Problem that\nadditionally considers multiple design periods and provides solutions protected\nagainst traffic uncertainty. Given the intrinsic difficulty of the problem,\nwhich proves challenging even for state-of-the art commercial solvers, we\npropose a hybrid primal heuristic based on the combination of ant colony\noptimization and an exact large neighborhood search. Computational experiments\non a set of realistic instances from the SNDlib show that our heuristic can\nfind solutions of extremely good quality with low optimality gap. \n\n"}
{"id": "1705.00055", "contents": "Title: Charting the Complexity Landscape of Waypoint Routing Abstract: Modern computer networks support interesting new routing models in which\ntraffic flows from a source s to a destination t can be flexibly steered\nthrough a sequence of waypoints, such as (hardware) middleboxes or\n(virtualized) network functions, to create innovative network services like\nservice chains or segment routing. While the benefits and technological\nchallenges of providing such routing models have been articulated and studied\nintensively over the last years, much less is known about the underlying\nalgorithmic traffic routing problems. This paper shows that the waypoint\nrouting problem features a deep combinatorial structure, and we establish\ninteresting connections to several classic graph theoretical problems. We find\nthat the difficulty of the waypoint routing problem depends on the specific\nsetting, and chart a comprehensive landscape of the computational complexity.\nIn particular, we derive several NP-hardness results, but we also demonstrate\nthat exact polynomial-time algorithms exist for a wide range of practically\nrelevant scenarios. \n\n"}
{"id": "1705.00370", "contents": "Title: Software-Defined Adversarial Trajectory Sampling Abstract: Today's routing protocols critically rely on the assumption that the\nunderlying hardware is trusted. Given the increasing number of attacks on\nnetwork devices, and recent reports on hardware backdoors this assumption has\nbecome questionable. Indeed, with the critical role computer networks play\ntoday, the contrast between our security assumptions and reality is\nproblematic.\n  This paper presents Software-Defined Adversarial Trajectory Sampling\n(SoftATS), an OpenFlow-based mechanism to efficiently monitor packet\ntrajectories, also in the presence of non-cooperating or even adversarial\nswitches or routers, e.g., containing hardware backdoors. Our approach is based\non a secure, redundant and adaptive sample distribution scheme which allows us\nto provably detect adversarial switches or routers trying to reroute, mirror,\ndrop, inject, or modify packets (i.e., header and/or payload). We evaluate the\neffectiveness of our approach in different adversarial settings, report on a\nproof-of-concept implementation, and provide a first evaluation of the\nperformance overheads of such a scheme. \n\n"}
{"id": "1705.01699", "contents": "Title: 3GPP-inspired HetNet Model using Poisson Cluster Process: Sum-product\n  Functionals and Downlink Coverage Abstract: The growing complexity of heterogeneous cellular networks (HetNets) has\nnecessitated a variety of user and base station (BS) configurations to be\nconsidered for realistic performance evaluation and system design. This is\ndirectly reflected in the HetNet simulation models proposed by standardization\nbodies, such as the third generation partnership project (3GPP). Complementary\nto these simulation models, stochastic geometry-based approach, modeling the\nlocations of the users and the K tiers of BSs as independent and homogeneous\nPoisson point processes (PPPs), has gained prominence in the past few years.\nDespite its success in revealing useful insights, this PPP-based K-tier HetNet\nmodel is not rich enough to capture spatial coupling between user and BS\nlocations that exists in real-world HetNet deployments and is included in 3GPP\nsimulation models. In this paper, we demonstrate that modeling a fraction of\nusers and arbitrary number of BS tiers alternatively with a Poisson cluster\nprocess (PCP) captures the aforementioned coupling, thus bridging the gap\nbetween the 3GPP simulation models and the PPP-based analytic model for\nHetNets. We further show that the downlink coverage probability of a typical\nuser under maximum signal-to-interference-ratio association can be expressed in\nterms of the sum-product functionals over PPP, PCP, and its associated\noffspring point process, which are all characterized as a part of our analysis.\nWe also show that the proposed model converges to the PPP-based HetNet model as\nthe cluster size of the PCPs tends to infinity. Finally, we specialize our\nanalysis based on general PCPs for Thomas and Matern cluster processes. Special\ninstances of the proposed model closely resemble the different configurations\nfor BS and user locations considered in 3GPP simulations. \n\n"}
{"id": "1705.02882", "contents": "Title: End-to-End Simulation of 5G mmWave Networks Abstract: Due to its potential for multi-gigabit and low latency wireless links,\nmillimeter wave (mmWave) technology is expected to play a central role in 5th\ngeneration cellular systems. While there has been considerable progress in\nunderstanding the mmWave physical layer, innovations will be required at all\nlayers of the protocol stack, in both the access and the core network.\nDiscrete-event network simulation is essential for end-to-end, cross-layer\nresearch and development. This paper provides a tutorial on a recently\ndeveloped full-stack mmWave module integrated into the widely used open-source\nns--3 simulator. The module includes a number of detailed statistical channel\nmodels as well as the ability to incorporate real measurements or ray-tracing\ndata. The Physical (PHY) and Medium Access Control (MAC) layers are modular and\nhighly customizable, making it easy to integrate algorithms or compare\nOrthogonal Frequency Division Multiplexing (OFDM) numerologies, for example.\nThe module is interfaced with the core network of the ns--3 Long Term Evolution\n(LTE) module for full-stack simulations of end-to-end connectivity, and\nadvanced architectural features, such as dual-connectivity, are also available.\nTo facilitate the understanding of the module, and verify its correct\nfunctioning, we provide several examples that show the performance of the\ncustom mmWave stack as well as custom congestion control algorithms designed\nspecifically for efficient utilization of the mmWave channel. \n\n"}
{"id": "1705.04289", "contents": "Title: Joint Spectrum Allocation and Structure Optimization in Green Powered\n  Heterogeneous Cognitive Radio Networks Abstract: We aim at maximizing the sum rate of secondary users (SUs) in OFDM-based\nHeterogeneous Cognitive Radio (CR) Networks using RF energy harvesting.\nAssuming SUs operate in a time switching fashion, each time slot is partitioned\ninto three non-overlapping parts devoted for energy harvesting, spectrum\nsensing and data transmission. The general problem of joint resource allocation\nand structure optimization is formulated as a Mixed Integer Nonlinear\nProgramming task which is NP-hard and intractable. Thus, we propose to tackle\nit by decomposing it into two subproblems. We first propose a sub-channel\nallocation scheme to approximately satisfy SUs' rate requirements and remove\nthe integer constraints. For the second step, we prove that the general\noptimization problem is reduced to a convex optimization task. Considering the\ntrade-off among fractions of each time slot, we focus on optimizing the time\nslot structures of SUs that maximize the total throughput while guaranteeing\nthe rate requirements of both real-time and non-real-time SUs. Since the\nreduced optimization problem does not have a simple closed-form solution, we\nthus propose a near optimal closed-form solution by utilizing Lambert-W\nfunction. We also exploit iterative gradient method based on Lagrangian dual\ndecomposition to achieve near optimal solutions. Simulation results are\npresented to validate the optimality of the proposed schemes. \n\n"}
{"id": "1705.04527", "contents": "Title: sOFTDP: Secure and Efficient Topology Discovery Protocol for SDN Abstract: Topology discovery is one of the most critical tasks of Software-Defined\nNetwork (SDN) controllers. Current SDN controllers use the OpenFlow Discovery\nProtocol (OFDP) as the de-facto protocol for discovering the underlying network\ntopology. In a previous work, we have shown the functional, performance and\nsecurity limitations of OFDP. In this paper, we introduce and detail a novel\nprotocol called secure and efficient OpenFlow Discovery Protocol sOTDP. sOFTDP\nrequires minimal changes to OpenFlow switch design, eliminates major\nvulnerabilities in the topology discovery process and improves its performance.\nWe have implemented sOFTDP as a topology discovery module in Floodlight for\nevaluation. The results show that our implementation is more secure than OFDP\nand previous security workarounds. Also, sOFTDP reduces the topology discovery\ntime several orders of magnitude compared to the original OFDP and existing\nOFDP improvements. \n\n"}
{"id": "1705.05566", "contents": "Title: Opportunistic Communication in Extreme Wireless Sensor Networks Abstract: Sensor networks can nowadays deliver 99.9% of their data with duty cycles\nbelow 1%. This remarkable performance is, however, dependent on some important\nunderlying assumptions: low traffic rates, medium size densities and static\nnodes. In this thesis, we investigate the performance of these same\nresource-constrained devices, but under scenarios that present extreme\nconditions: high traffic rates, high densities and mobility: the so-called\nExtreme Wireless Sensor Networks (EWSNs). \n\n"}
{"id": "1705.05690", "contents": "Title: A Long Short-Term Memory Recurrent Neural Network Framework for Network\n  Traffic Matrix Prediction Abstract: Network Traffic Matrix (TM) prediction is defined as the problem of\nestimating future network traffic from the previous and achieved network\ntraffic data. It is widely used in network planning, resource management and\nnetwork security. Long Short-Term Memory (LSTM) is a specific recurrent neural\nnetwork (RNN) architecture that is well-suited to learn from experience to\nclassify, process and predict time series with time lags of unknown size. LSTMs\nhave been shown to model temporal sequences and their long-range dependencies\nmore accurately than conventional RNNs. In this paper, we propose a LSTM RNN\nframework for predicting short and long term Traffic Matrix (TM) in large\nnetworks. By validating our framework on real-world data from GEANT network, we\nshow that our LSTM models converge quickly and give state of the art TM\nprediction performance for relatively small sized models. \n\n"}
{"id": "1705.05953", "contents": "Title: LoRa Backscatter: Enabling The Vision of Ubiquitous Connectivity Abstract: The vision of embedding connectivity into billions of everyday objects runs\ninto the reality of existing communication technologies --- there is no\nexisting wireless technology that can provide reliable and long-range\ncommunication at tens of microwatts of power as well as cost less than a dime.\nWhile backscatter is low-power and low-cost, it is known to be limited to short\nranges. This paper overturns this conventional wisdom about backscatter and\npresents the first wide-area backscatter system. Our design can successfully\nbackscatter from any location between an RF source and receiver, separated by\n475 m, while being compatible with commodity LoRa hardware. Further, when our\nbackscatter device is co-located with the RF source, the receiver can be as far\nas 2.8 km away. We deploy our system in a 4,800 $ft^{2}$ (446 $m^{2}$) house\nspread across three floors, a 13,024 $ft^{2}$ (1210 $m^{2}$) office area\ncovering 41 rooms, as well as a one-acre (4046 $m^{2}$) vegetable farm and show\nthat we can achieve reliable coverage, using only a single RF source and\nreceiver. We also build a contact lens prototype as well as a flexible\nepidermal patch device attached to the human skin. We show that these devices\ncan reliably backscatter data across a 3,328 $ft^{2}$ (309 $m^{2}$) room.\nFinally, we present a design sketch of a LoRa backscatter IC that shows that it\ncosts less than a dime at scale and consumes only 9.25 $\\mu$W of power, which\nis more than 1000x lower power than LoRa radio chipsets. \n\n"}
{"id": "1705.05954", "contents": "Title: Convergence Results on Pulse Coupled Oscillator Protocols in Locally\n  Connected Networks Abstract: This work provides new insights on the convergence of a locally connected\nnetwork of pulse coupled oscillator (PCOs) (i.e., a bio-inspired model for\ncommunication networks) to synchronous and desynchronous states, and their\nimplication in terms of the decentralized synchronization and scheduling in\ncommunication networks. Bio-inspired techniques have been advocated by many as\nfault-tolerant and scalable alternatives to produce self-organization in\ncommunication networks. The PCO dynamics in particular have been the source of\ninspiration for many network synchronization and scheduling protocols. However,\ntheir convergence properties, especially in locally connected networks, have\nnot been fully understood, prohibiting the migration into mainstream standards.\nThis work provides further results on the convergence of PCOs in locally\nconnected networks and the achievable convergence accuracy under propagation\ndelays. For synchronization, almost sure convergence is proved for $3$ nodes\nand accuracy results are obtained for general locally connected networks\nwhereas, for scheduling (or desynchronization), results are derived for locally\nconnected networks with mild conditions on the overlapping set of maximal\ncliques. These issues have not been fully addressed before in the literature. \n\n"}
{"id": "1705.06215", "contents": "Title: Mixing MACs: An Introduction to Hybrid Radio Wireless Virtualization Abstract: This study presents the design of the hybrid wireless virtualization HWV\ncontroller based network architecture. Using a HWV controller, an unified\napproach can be taken for provisioning and management of virtualized\nheterogeneous radios, irrespective of their MAC and PHY layer mechanisms. It is\nshown that the airtime occupancy by transmissions from different slices or\ngroups can be used as a single metric for tying these virtualized platforms.\nThe HWV controller can account and dynamically reprovision slice quotas, which\ncan be used for maximizing the revenue of the network operator or aggregate\nsystem throughput performance. Results from simulations show that an HWV\ncontroller based infrastructure is able to improve the revenue generated from a\nsingle virtualized basestation and an AP by up to 40 percent under tested\nconditions. \n\n"}
{"id": "1705.07524", "contents": "Title: EDOS: Edge Assisted Offloading System for Mobile Devices Abstract: Offloading resource-intensive jobs to the cloud and nearby users is a\npromising approach to enhance mobile devices. This paper investigates a hybrid\noffloading system that takes both infrastructure-based networks and Ad-hoc\nnetworks into the scope. Specifically, we propose EDOS, an edge assisted\noffloading system that consists of two major components, an Edge Assistant (EA)\nand Offload Agent (OA). EA runs on the routers/towers to manage registered\nremote cloud servers and local service providers and OA operates on the users'\ndevices to discover the services in proximity. We present the system with a\nsuite of protocols to collect the potential service providers and algorithms to\nallocate tasks according to user-specified constraints. To evaluate EDOS, we\nprototype it on commercial mobile devices and evaluate it with both experiments\non a small-scale testbed and simulations. The results show that EDOS is\neffective and efficient for offloading jobs. \n\n"}
{"id": "1705.08000", "contents": "Title: Concurrent Channel Probing and Data Transmission in Full-duplex MIMO\n  Systems Abstract: An essential step for achieving multiplexing gain in MIMO downlink systems is\nto collect accurate channel state information (CSI) from the users.\nTraditionally, CSIs have to be collected before any data can be transmitted.\nSuch a sequential scheme incurs a large feedback overhead, which substantially\nlimits the multiplexing gain especially in a network with a large number of\nusers. In this paper, we propose a novel approach to mitigate the feedback\noverhead by leveraging the recently developed Full-duplex radios. Our approach\nis based on the key observation that using Full-duplex radios, when the\nbase-station (BS) is collecting CSI of one user through the uplink channel, it\ncan use the downlink channel to simultaneously transmit data to other\n(non-interfering) users for which CSIs are already known. By allowing\nconcurrent channel probing and data transmission, our scheme can potentially\nachieve a higher throughput compared to traditional schemes using Half-duplex\nradios. The new flexibility introduced by our scheme, however, also leads to\nfundamental challenges in achieving throughout optimal scheduling. In this\npaper, we make an initial effort to this important problem by considering a\nsimplified group interference model. We develop a throughput optimal scheduling\npolicy with complexity $O((N/I)^I)$, where $N$ is the number of users and $I$\nis the number of user groups. To further reduce the complexity, we propose a\ngreedy policy with complexity $O(N\\log N)$ that not only achieves at least 2/3\nof the optimal throughput region, but also outperforms any feasible Half-duplex\nsolutions. We derive the throughput gain offered by Full-duplex under different\nsystem parameters and show the advantage of our algorithms through numerical\nstudies. \n\n"}
{"id": "1705.08304", "contents": "Title: Learning Optimal Routing for the Uplink in LPWANs Using\n  Similarity-enhanced epsilon-greedy Abstract: Despite being a relatively new communication technology, Low-Power Wide Area\nNetworks (LPWANs) have shown their suitability to empower a major part of\nInternet of Things applications. Nonetheless, most LPWAN solutions are built on\nstar topology (or single-hop) networks, often causing lifetime shortening in\nstations located far from the gateway. In this respect, recent studies show\nthat multi-hop routing for uplink communications can reduce LPWANs' energy\nconsumption significantly. However, it is a troublesome task to identify such\nenergetically optimal routings through trial-and-error brute-force approaches\nbecause of time and, especially, energy consumption constraints. In this work\nwe show the benefits of facing this exploration/exploitation problem by running\ncentralized variations of the multi-arm bandit's epsilon-greedy, a well-known\nonline decision-making method that combines best known action selection and\nknowledge expansion. Important energy savings are achieved when proper\nrandomness parameters are set, which are often improved when conveniently\napplying similarity, a concept introduced in this work that allows harnessing\nthe gathered knowledge by sporadically selecting unexplored routing\ncombinations akin to the best known one. \n\n"}
{"id": "1705.08489", "contents": "Title: Securing Real-Time Internet-of-Things Abstract: Modern embedded and cyber-physical systems are ubiquitous. A large number of\ncritical cyber-physical systems have real-time requirements (e.g., avionics,\nautomobiles, power grids, manufacturing systems, industrial control systems,\netc.). Recent developments and new functionality requires real-time embedded\ndevices to be connected to the Internet. This gives rise to the real-time\nInternet-of-things (RT-IoT) that promises a better user experience through\nstronger connectivity and efficient use of next-generation embedded devices.\nHowever RT- IoT are also increasingly becoming targets for cyber-attacks which\nis exacerbated by this increased connectivity. This paper gives an introduction\nto RT-IoT systems, an outlook of current approaches and possible research\nchallenges towards secure RT- IoT frameworks. \n\n"}
{"id": "1705.08711", "contents": "Title: Non-orthogonal Multiple Access for High-reliable and Low-latency V2X\n  Communications Abstract: In this paper, we consider a dense vehicular communication network where each\nvehicle broadcasts its safety information to its neighborhood in each\ntransmission period. Such applications require low latency and high\nreliability, and thus, we propose a non-orthogonal multiple access scheme to\nreduce the latency and to improve the packet reception probability. In the\nproposed scheme, the BS performs the semi-persistent scheduling to optimize the\ntime scheduling and allocate frequency resources in a non-orthogonal manner\nwhile the vehicles autonomously perform distributed power control. We formulate\nthe centralized scheduling and resource allocation problem as equivalent to a\nmulti-dimensional stable roommate matching problem, in which the users and\ntime/frequency resources are considered as disjoint sets of players to be\nmatched with each other. We then develop a novel rotation matching algorithm,\nwhich converges to a q-exchange stable matching after a limited number of\niterations. Simulation results show that the proposed scheme outperforms the\ntraditional orthogonal multiple access scheme in terms of the latency and\nreliability. \n\n"}
{"id": "1705.10554", "contents": "Title: Virtual Function Placement for Service Chaining with Partial Orders and\n  Anti-Affinity Rules Abstract: Software Defined Networking and Network Function Virtualization are two\nparadigms that offer flexible software-based network management. Service\nproviders are instantiating Virtualized Network Functions - e.g., firewalls,\nDPIs, gateways - to highly facilitate the deployment and reconfiguration of\nnetwork services with reduced time-to-value. They employ Service Function\nChaining technologies to dynamically reconfigure network paths traversing\nphysical and virtual network functions. Providing a cost-efficient virtual\nfunction deployment over the network for a set of service chains is a key\ntechnical challenge for service providers, and this problem has recently caught\nmuch attention from both Industry and Academia. In this paper, we propose a\nformulation of this problem as an Integer Linear Program that allows one to\nfind the best feasible paths and virtual function placement for a set of\nservices with respect to a total financial cost, while taking into account the\n(total or partial) order constraints for Service Function Chains of each\nservice and other constraints such as end-to-end latency, anti-affinity rules\nbetween network functions on the same physical node and resource limitations in\nterms of network and processing capacities. Furthermore, we propose a heuristic\nalgorithm based on a linear relaxation of the problem that performs close to\noptimum for large scale instances. \n\n"}
{"id": "1706.00307", "contents": "Title: Energy Harvesting Networks with General Utility Functions: Near Optimal\n  Online Policies Abstract: We consider online scheduling policies for single-user energy harvesting\ncommunication systems, where the goal is to characterize online policies that\nmaximize the long term average utility, for some general concave and\nmonotonically increasing utility function. In our setting, the transmitter\nrelies on energy harvested from nature to send its messages to the receiver,\nand is equipped with a finite-sized battery to store its energy. Energy packets\nare independent and identically distributed (i.i.d.) over time slots, and are\nrevealed causally to the transmitter. Only the average arrival rate is known a\npriori. We first characterize the optimal solution for the case of Bernoulli\narrivals. Then, for general i.i.d. arrivals, we first show that fixed fraction\npolicies [Shaviv-Ozgur] are within a constant multiplicative gap from the\noptimal solution for all energy arrivals and battery sizes. We then derive a\nset of sufficient conditions on the utility function to guarantee that fixed\nfraction policies are within a constant additive gap as well from the optimal\nsolution. \n\n"}
{"id": "1706.00333", "contents": "Title: Achieveing reliable UDP transmission at 10 Gb/s using BSD socket for\n  data acquisition systems Abstract: User Datagram Protocol (UDP) is a commonly used protocol for data\ntransmission in small embedded systems. UDP as such is unreliable and packet\nlosses can occur. The achievable data rates can suffer if optimal packet sizes\nare not used. The alternative, Transmission Control Protocol (TCP) guarantees\nthe ordered delivery of data and automatically adjusts transmission to match\nthe capability of the transmission link. Nevertheless UDP is often favored over\nTCP due to its simplicity, small memory and instruction footprints. Both UDP\nand TCP are implemented in all larger operating systems and commercial embedded\nframeworks. In addition UDP also supported on a variety of small hardware\nplatforms such as Digital Signal Processors (DSP) Field Programmable Gate\nArrays (FPGA). This is not so common for TCP. This paper describes how high\nspeed UDP based data transmission with very low packet error ratios was\nachieved. The near-reliable communications link is used in a data acquisition\n(DAQ) system for the next generation of extremely intense neutron source,\nEuropean Spallation Source. This paper presents measurements of UDP performance\nand reliability as achieved by employing several optimizations. The\nmeasurements were performed on Xeon E5 based CentOS (Linux) servers. The\nmeasured data rates are very close to the 10 Gb/s line rate, and zero packet\nloss was achieved. The performance was obtained utilizing a single processor\ncore as transmitter and a single core as receiver. The results show that\nsupport for transmitting large data packets is a key parameter for good\nperformance.\n  Optimizations for throughput are: MTU, packet sizes, tuning Linux kernel\nparameters, thread affinity, core locality and efficient timers. \n\n"}
{"id": "1706.02479", "contents": "Title: Risk-Informed Interference Assessment for Shared Spectrum Bands: A\n  Wi-Fi/LTE Coexistence Case Study Abstract: Interference evaluation is crucial when deciding whether and how wireless\ntechnologies should operate. In this paper we demonstrate the benefit of\nrisk-informed interference assessment to aid spectrum regulators in making\ndecisions, and to readily convey engineering insight. Our contributions are: we\napply, for the first time, risk assessment to a problem of inter-technology\nspectrum sharing, i.e. Wi-Fi/LTE in the 5 GHz unlicensed band, and we\ndemonstrate that this method comprehensively quantifies the interference\nimpact. We perform simulations with our newly publicly-available tool and we\nconsider throughput degradation and fairness metrics to assess the risk for\ndifferent network densities, numbers of channels, and deployment scenarios. Our\nresults show that no regulatory intervention is needed to ensure harmonious\ntechnical Wi-Fi/LTE coexistence: for the typically large number of channels\navailable in the 5 GHz band, the risk for Wi-Fi from LTE is negligible,\nrendering policy and engineering concerns largely moot. As an engineering\ninsight, Wi-Fi coexists better with itself in dense, but better with LTE, in\nsparse deployments. Also, both main LTE-in-unlicensed variants coexist well\nwith Wi-Fi in general. For LTE intra-technology inter-operator coexistence,\nboth variants typically coexist well in the 5 GHz band, but for dense\ndeployments, implementing listen-before-talk causes less interference. \n\n"}
{"id": "1706.03086", "contents": "Title: LoRaWAN in the Wild: Measurements from The Things Network Abstract: The Long-Range Wide-Area Network (LoRaWAN) specification was released in\n2015, primarily to support the Internet-of-Things by facilitating wireless\ncommunication over long distances. Since 2015, the role-out and adoption of\nLoRaWAN has seen a steep growth. To the best of our knowledge, we are the first\nto have extensively measured, analyzed, and modeled the performance, features,\nand use cases of an operational LoRaWAN, namely The Things Network. Our\nmeasurement data, as presented in this paper, cover the early stages up to the\nproduction-level deployment of LoRaWAN. In particular, we analyze packet\npayloads, radio-signal quality, and spatio-temporal aspects, to model and\nestimate the performance of LoRaWAN. We also use our empirical findings in\nsimulations to estimate the packet-loss. \n\n"}
{"id": "1706.03580", "contents": "Title: Fair Airtime Allocation for Content Dissemination in WiFi-Direct-Based\n  Mobile Social Networks Abstract: The vast penetration of smart mobile devices provides a unique opportunity to\nmake mobile social networking pervasive by leveraging the feature of\nshort-range wireless communication technologies (e.g. WiFi Direct). In this\npaper, we study local content dissemination in WiFi-Direct-based mobile social\nnetworks (MSNs). We propose a simple GO-coordinated dissemination strategy, as\nWiFi Direct does not originally support content dissemination. Due to mobility\nand the short transmission range, the duration of nodes in contact tends to be\nlimited and consequently they compete for the limited airtime to disseminate\ntheir own data. Therefore, fair allocation of the limited airtime among the\nnodes is required. We focus on fairness in content dissemination rate, which is\na key application-layer metric, rather than fairness in throughput or airtime\nand formulate the allocation problem as a generalized Nash bargaining game\nwherein the nodes bargain for a share of the limited airtime. The game is\nproved to have a unique optimal solution, and an algorithm with low complexity\nis designed to find the optimal solution. Furthermore, we propose a detailed\nscheduling approach to implement the optimal solution. We also present\nnumerical results to evaluate the Nash bargaining based allocation and\nscheduling. \n\n"}
{"id": "1706.06935", "contents": "Title: Agile Millimeter Wave Networks with Provable Guarantees Abstract: There is much interest in integrating millimeter wave radios (mmWave) into\nwireless LANs and 5G cellular networks to benefit from their multiple GHz of\navailable spectrum. Yet unlike existing technologies, e.g., WiFi, mmWave radios\nrequire highly directional antennas. Since the antennas have pencil-beams, the\ntransmitter and receiver need to align their antenna beams before they can\ncommunicate. Existing solutions scan the entire space to find the best\nalignment. Such a process has been shown to introduce up to seconds of delay,\nand is unsuitable for wireless networks where an access point has to quickly\nswitch between users and accommodate mobile clients.\n  This paper presents Rapid-Link, a new protocol that can find the best mmWave\nbeam alignment without scanning the space. Given all possible directions for\nsetting the antenna beam, Rapid-Link provably finds the optimal direction in\nlogarithmic number of measurements. Further, Rapid-Link works within the\nexisting 802.11ad standard for mmWave LAN, and can support both clients and\naccess points. We have implemented Rapid-Link in a mmWave radio and evaluated\nit empirically. Our results show that it reduces beam alignment delay by orders\nof magnitude. In particular, for highly directional mmWave devices operating\nunder 802.11ad, the delay drops from over a second to 2.5 ms. \n\n"}
{"id": "1707.02329", "contents": "Title: Deep Q-Learning for Self-Organizing Networks Fault Management and Radio\n  Performance Improvement Abstract: We propose an algorithm to automate fault management in an outdoor cellular\nnetwork using deep reinforcement learning (RL) against wireless impairments.\nThis algorithm enables the cellular network cluster to self-heal by allowing RL\nto learn how to improve the downlink signal to interference plus noise ratio\nthrough exploration and exploitation of various alarm corrective actions. The\nmain contributions of this paper are to 1) introduce a deep RL-based fault\nhandling algorithm which self-organizing networks can implement in a polynomial\nruntime and 2) show that this fault management method can improve the radio\nlink performance in a realistic network setup. Simulation results show that our\nproposed algorithm learns an action sequence to clear alarms and improve the\nperformance in the cellular cluster better than existing algorithms, even\nagainst the randomness of the network fault occurrences and user movements. \n\n"}
{"id": "1707.02701", "contents": "Title: Case For Static AMSDU Aggregation in WLANs Abstract: Frame aggregation is a mechanism by which multiple frames are combined into a\nsingle transmission unit over the air. Frames aggregated at the AMSDU level use\na common CRC check to enforce integrity. For longer aggregated AMSDU frames,\nthe packet error rate increases significantly for the same bit error rate.\nHence, multiple studies have proposed doing AMSDU aggregation adaptively based\non the error rate. This study evaluates if there is a \\emph{practical}\nadvantage in doing adaptive AMSDU aggregation based on the link bit error rate.\nEvaluations on a model show that instead of implementing a complex adaptive\nAMSDU frame aggregation mechanism which impact queuing and other implementation\naspects, it is easier to influence packet error rate with traditional\nmechanisms while keeping the AMSDU aggregation logic simple. \n\n"}
{"id": "1707.03203", "contents": "Title: Multi-antenna Enabled Cluster-based Cooperation in Wireless Powered\n  Communication Networks Abstract: In this paper, we consider a wireless powered communication network (WPCN)\nconsisting of a multi-antenna hybrid access point (HAP) that transfers wireless\nenergy to and receives sensing data from a cluster of low-power wireless\ndevices (WDs). To enhance the throughput performance of some far-away WDs, we\nallow one of the WDs to act as the cluster head (CH) that helps forward the\nmessages of the other cluster members (CMs). However, the performance of the\nproposed cluster-based cooperation is fundamentally limited by the high energy\nconsumption of the CH, who needs to transmit all the WDs' messages including\nits own. To tackle this issue, we exploit the capability of multi-antenna\nenergy beamforming (EB) at the HAP, which can focus more transferred power to\nthe CH to balance its energy consumption in assisting the other WDs.\nSpecifically, we first derive the throughput performance of each individual WD\nunder the proposed scheme. Then, we jointly optimize the EB design, the\ntransmit time allocation among the HAP and the WDs, and the transmit power\nallocation of the CH to maximize the minimum data rate achievable among all the\nWDs (the max-min throughput) for improved throughput fairness among the WDs. An\nefficient optimal algorithm is proposed to solve the joint optimization\nproblem. Moreover, we simulate under practical network setups and show that the\nproposed multi-antenna enabled cluster-based cooperation can effectively\nimprove the throughput fairness of WPCN. \n\n"}
{"id": "1707.03269", "contents": "Title: Q-Learning Algorithm for VoLTE Closed-Loop Power Control in Indoor Small\n  Cells Abstract: We propose a reinforcement learning (RL) based closed loop power control\nalgorithm for the downlink of the voice over LTE (VoLTE) radio bearer for an\nindoor environment served by small cells. The main contributions of our paper\nare to 1) use RL to solve performance tuning problems in an indoor cellular\nnetwork for voice bearers and 2) show that our derived lower bound loss in\neffective signal to interference plus noise ratio due to neighboring cell\nfailure is sufficient for VoLTE power control purposes in practical cellular\nnetworks. In our simulation, the proposed RL-based power control algorithm\nsignificantly improves both voice retainability and mean opinion score compared\nto current industry standards. The improvement is due to maintaining an\neffective downlink signal to interference plus noise ratio against adverse\nnetwork operational issues and faults. \n\n"}
{"id": "1707.03510", "contents": "Title: Association of Networked Flying Platforms with Small Cells for Network\n  Centric 5G+ C-RAN Abstract: 5G+ systems expect enhancement in data rate and coverage area under limited\npower constraint. Such requirements can be fulfilled by the densification of\nsmall cells (SCs). However, a major challenge is the management of fronthaul\nlinks connected with an ultra dense network of SCs. A cost effective and\nscalable idea of using network flying platforms (NFPs) is employed here, where\nthe NFPs are used as fronthaul hubs that connect the SCs to the core network.\nThe association problem of NFPs and SCs is formulated considering a number of\npractical constraints such as backhaul data rate limit, maximum supported links\nand bandwidth by NFPs and quality of service requirement of the system. The\nnetwork centric case of the system is considered that aims to maximize the\nnumber of associated SCs without any biasing, i.e., no preference for high\npriority SCs. Then, two new efficient greedy algorithms are designed to solve\nthe presented association problem. Numerical results show a favorable\nperformance of our proposed methods in comparison to exhaustive search. \n\n"}
{"id": "1707.05398", "contents": "Title: Towards Fast-Convergence, Low-Delay and Low-Complexity Network\n  Optimization Abstract: Distributed network optimization has been studied for well over a decade.\nHowever, we still do not have a good idea of how to design schemes that can\nsimultaneously provide good performance across the dimensions of utility\noptimality, convergence speed, and delay. To address these challenges, in this\npaper, we propose a new algorithmic framework with all these metrics\napproaching optimality. The salient features of our new algorithm are\nthree-fold: (i) fast convergence: it converges with only $O(\\log(1/\\epsilon))$\niterations that is the fastest speed among all the existing algorithms; (ii)\nlow delay: it guarantees optimal utility with finite queue length; (iii) simple\nimplementation: the control variables of this algorithm are based on virtual\nqueues that do not require maintaining per-flow information. The new technique\nbuilds on a kind of inexact Uzawa method in the Alternating Directional Method\nof Multiplier, and provides a new theoretical path to prove global and linear\nconvergence rate of such a method without requiring the full rank assumption of\nthe constraint matrix. \n\n"}
{"id": "1707.05836", "contents": "Title: Domain-Sharding for Faster HTTP/2 in Lossy Cellular Networks Abstract: HTTP/2 (h2) is a new standard for Web communications that already delivers a\nlarge share of Web traffic. Unlike HTTP/1, h2 uses only one underlying TCP\nconnection. In a cellular network with high loss and sudden spikes in latency,\nwhich the TCP stack might interpret as loss, using a single TCP connection can\nnegatively impact Web performance. In this paper, we perform an extensive\nanalysis of real world cellular network traffic and design a testbed to emulate\nloss characteristics in cellular networks. We use the emulated cellular network\nto measure h2 performance in comparison to HTTP/1.1, for webpages synthesized\nfrom HTTP Archive repository data.\n  Our results show that, in lossy conditions, h2 achieves faster page load\ntimes (PLTs) for webpages with small objects. For webpages with large objects,\nh2 degrades the PLT. We devise a new domain-sharding technique that isolates\nlarge and small object downloads on separate connections. Using sharding, we\nshow that under lossy cellular conditions, h2 over multiple connections\nimproves the PLT compared to h2 with one connection and HTTP/1.1 with six\nconnections. Finally, we recommend content providers and content delivery\nnetworks to apply h2-aware domain-sharding on webpages currently served over h2\nfor improved mobile Web performance. \n\n"}
{"id": "1707.05866", "contents": "Title: Asymptotically Optimal Load Balancing Topologies Abstract: We consider a system of $N$ servers inter-connected by some underlying graph\ntopology $G_N$. Tasks arrive at the various servers as independent Poisson\nprocesses of rate $\\lambda$. Each incoming task is irrevocably assigned to\nwhichever server has the smallest number of tasks among the one where it\nappears and its neighbors in $G_N$. Tasks have unit-mean exponential service\ntimes and leave the system upon service completion.\n  The above model has been extensively investigated in the case $G_N$ is a\nclique. Since the servers are exchangeable in that case, the queue length\nprocess is quite tractable, and it has been proved that for any $\\lambda < 1$,\nthe fraction of servers with two or more tasks vanishes in the limit as $N \\to\n\\infty$. For an arbitrary graph $G_N$, the lack of exchangeability severely\ncomplicates the analysis, and the queue length process tends to be worse than\nfor a clique. Accordingly, a graph $G_N$ is said to be $N$-optimal or\n$\\sqrt{N}$-optimal when the occupancy process on $G_N$ is equivalent to that on\na clique on an $N$-scale or $\\sqrt{N}$-scale, respectively.\n  We prove that if $G_N$ is an Erd\\H{o}s-R\\'enyi random graph with average\ndegree $d(N)$, then it is with high probability $N$-optimal and\n$\\sqrt{N}$-optimal if $d(N) \\to \\infty$ and $d(N) / (\\sqrt{N} \\log(N)) \\to\n\\infty$ as $N \\to \\infty$, respectively. This demonstrates that optimality can\nbe maintained at $N$-scale and $\\sqrt{N}$-scale while reducing the number of\nconnections by nearly a factor $N$ and $\\sqrt{N} / \\log(N)$ compared to a\nclique, provided the topology is suitably random. It is further shown that if\n$G_N$ contains $\\Theta(N)$ bounded-degree nodes, then it cannot be $N$-optimal.\nIn addition, we establish that an arbitrary graph $G_N$ is $N$-optimal when its\nminimum degree is $N - o(N)$, and may not be $N$-optimal even when its minimum\ndegree is $c N + o(N)$ for any $0 < c < 1/2$. \n\n"}
{"id": "1707.08074", "contents": "Title: Optimal Sensing and Data Estimation in a Large Sensor Network Abstract: An energy efficient use of large scale sensor networks necessitates\nactivating a subset of possible sensors for estimation at a fusion center. The\nproblem is inherently combinatorial; to this end, a set of iterative,\nrandomized algorithms are developed for sensor subset selection by exploiting\nthe underlying statistics. Gibbs sampling-based methods are designed to\noptimize the estimation error and the mean number of activated sensors. The\noptimality of the proposed strategy is proven, along with guarantees on their\nconvergence speeds. Also, another new algorithm exploiting stochastic\napproximation in conjunction with Gibbs sampling is derived for a constrained\nversion of the sensor selection problem. The methodology is extended to the\nscenario where the fusion center has access to only a parametric form of the\njoint statistics, but not the true underlying distribution. Therein,\nexpectation-maximization is effectively employed to learn the distribution.\nStrategies for iid time-varying data are also outlined. Numerical results show\nthat the proposed methods converge very fast to the respective optimal\nsolutions, and therefore can be employed for optimal sensor subset selection in\npractical sensor networks. \n\n"}
{"id": "1707.08569", "contents": "Title: Wisture: RNN-based Learning of Wireless Signals for Gesture Recognition\n  in Unmodified Smartphones Abstract: This paper introduces Wisture, a new online machine learning solution for\nrecognizing touch-less dynamic hand gestures on a smartphone. Wisture relies on\nthe standard Wi-Fi Received Signal Strength (RSS) using a Long Short-Term\nMemory (LSTM) Recurrent Neural Network (RNN), thresholding filters and traffic\ninduction. Unlike other Wi-Fi based gesture recognition methods, the proposed\nmethod does not require a modification of the smartphone hardware or the\noperating system, and performs the gesture recognition without interfering with\nthe normal operation of other smartphone applications.\n  We discuss the characteristics of Wisture, and conduct extensive experiments\nto compare its performance against state-of-the-art machine learning solutions\nin terms of both accuracy and time efficiency. The experiments include a set of\ndifferent scenarios in terms of both spatial setup and traffic between the\nsmartphone and Wi-Fi access points (AP). The results show that Wisture achieves\nan online recognition accuracy of up to 94% (average 78%) in detecting and\nclassifying three hand gestures. \n\n"}
{"id": "1707.08860", "contents": "Title: Approximations and Bounds for (n, k) Fork-Join Queues: A Linear\n  Transformation Approach Abstract: Compared to basic fork-join queues, a job in (n, k) fork-join queues only\nneeds its k out of all n sub-tasks to be finished. Since (n, k) fork-join\nqueues are prevalent in popular distributed systems, erasure coding based cloud\nstorages, and modern network protocols like multipath routing, estimating the\nsojourn time of such queues is thus critical for the performance measurement\nand resource plan of computer clusters. However, the estimating keeps to be a\nwell-known open challenge for years, and only rough bounds for a limited range\nof load factors have been given. In this paper, we developed a closed-form\nlinear transformation technique for jointly-identical random variables: An\norder statistic can be represented by a linear combination of maxima. This\nbrand-new technique is then used to transform the sojourn time of non-purging\n(n, k) fork-join queues into a linear combination of the sojourn times of basic\n(k, k), (k+1, k+1), ..., (n, n) fork-join queues. Consequently, existing\napproximations for basic fork-join queues can be bridged to the approximations\nfor non-purging (n, k) fork-join queues. The uncovered approximations are then\nused to improve the upper bounds for purging (n, k) fork-join queues.\nSimulation experiments show that this linear transformation approach is\npracticed well for moderate n and relatively large k. \n\n"}
{"id": "1708.02562", "contents": "Title: A Survey on Low Latency Towards 5G: RAN, Core Network and Caching\n  Solutions Abstract: The fifth generation (5G) wireless network technology is to be standardized\nby 2020, where main goals are to improve capacity, reliability, and energy\nefficiency, while reducing latency and massively increasing connection density.\nAn integral part of 5G is the capability to transmit touch perception type\nreal-time communication empowered by applicable robotics and haptics equipment\nat the network edge. In this regard, we need drastic changes in network\narchitecture including core and radio access network (RAN) for achieving\nend-to-end latency on the order of 1 ms. In this paper, we present a detailed\nsurvey on the emerging technologies to achieve low latency communications\nconsidering three different solution domains: RAN, core network, and caching.\nWe also present a general overview of 5G cellular networks composed of software\ndefined network (SDN), network function virtualization (NFV), caching, and\nmobile edge computing (MEC) capable of meeting latency and other 5G\nrequirements. \n\n"}
{"id": "1708.03066", "contents": "Title: Design and Optimization of VoD schemes with Client Caching in Wireless\n  Multicast Networks Abstract: Due to the explosive growth in multimedia traffic, the scalability of\nvideo-on-demand (VoD) services becomes increasingly important. By exploiting\nthe potential cache ability at the client side, the performance of VoD\nmulticast delivery can be improved through video segment pre-caching. In this\npaper, we address the performance limits of client caching enabled VoD schemes\nin wireless multicast networks with asynchronous requests. Both reactive and\nproactive systems are investigated. Specifically, for the reactive system where\nvideos are transmitted on demand, we propose a joint cache allocation and\nmulticast delivery scheme to minimize the average bandwidth consumption under\nthe zero-delay constraint. For the proactive system where videos are\nperiodically broadcasted, a joint design of the cache-bandwidth allocation\nalgorithm and the delivery mechanism is developed to minimize the average\nwaiting time under the total bandwidth constraint. In addition to the full\naccess pattern where clients view videos in their entirety, we further consider\nthe access patterns with random endpoints, fixed-size intervals and downloading\ndemand, respectively. The impacts of different access patterns on the\nresource-allocation algorithm and the delivery mechanism are elaborated.\nSimulation results validate the accuracy of the analytical results and also\nprovide useful insights in designing VoD networks with client caching. \n\n"}
{"id": "1708.03878", "contents": "Title: Big Data Model Simulation on a Graph Database for Surveillance in\n  Wireless Multimedia Sensor Networks Abstract: Sensors are present in various forms all around the world such as mobile\nphones, surveillance cameras, smart televisions, intelligent refrigerators and\nblood pressure monitors. Usually, most of the sensors are a part of some other\nsystem with similar sensors that compose a network. One of such networks is\ncomposed of millions of sensors connect to the Internet which is called\nInternet of things (IoT). With the advances in wireless communication\ntechnologies, multimedia sensors and their networks are expected to be major\ncomponents in IoT. Many studies have already been done on wireless multimedia\nsensor networks in diverse domains like fire detection, city surveillance,\nearly warning systems, etc. All those applications position sensor nodes and\ncollect their data for a long time period with real-time data flow, which is\nconsidered as big data. Big data may be structured or unstructured and needs to\nbe stored for further processing and analyzing. Analyzing multimedia big data\nis a challenging task requiring a high-level modeling to efficiently extract\nvaluable information/knowledge from data. In this study, we propose a big\ndatabase model based on graph database model for handling data generated by\nwireless multimedia sensor networks. We introduce a simulator to generate\nsynthetic data and store and query big data using graph model as a big\ndatabase. For this purpose, we evaluate the well-known graph-based NoSQL\ndatabases, Neo4j and OrientDB, and a relational database, MySQL.We have run a\nnumber of query experiments on our implemented simulator to show that which\ndatabase system(s) for surveillance in wireless multimedia sensor networks is\nefficient and scalable. \n\n"}
{"id": "1708.05096", "contents": "Title: Will SDN be part of 5G? Abstract: For many, this is no longer a valid question and the case is considered\nsettled with SDN/NFV (Software Defined Networking/Network Function\nVirtualization) providing the inevitable innovation enablers solving many\noutstanding management issues regarding 5G. However, given the monumental task\nof softwarization of radio access network (RAN) while 5G is just around the\ncorner and some companies have started unveiling their 5G equipment already,\nthe concern is very realistic that we may only see some point solutions\ninvolving SDN technology instead of a fully SDN-enabled RAN. This survey paper\nidentifies all important obstacles in the way and looks at the state of the art\nof the relevant solutions. This survey is different from the previous surveys\non SDN-based RAN as it focuses on the salient problems and discusses solutions\nproposed within and outside SDN literature. Our main focus is on fronthaul,\nbackward compatibility, supposedly disruptive nature of SDN deployment,\nbusiness cases and monetization of SDN related upgrades, latency of general\npurpose processors (GPP), and additional security vulnerabilities,\nsoftwarization brings along to the RAN. We have also provided a summary of the\narchitectural developments in SDN-based RAN landscape as not all work can be\ncovered under the focused issues. This paper provides a comprehensive survey on\nthe state of the art of SDN-based RAN and clearly points out the gaps in the\ntechnology. \n\n"}
{"id": "1708.06441", "contents": "Title: A Hybrid Approach for Data Analytics for Internet of Things Abstract: The vision of the Internet of Things is to allow currently unconnected\nphysical objects to be connected to the internet. There will be an extremely\nlarge number of internet connected devices that will be much more than the\nnumber of human being in the world all producing data. These data will be\ncollected and delivered to the cloud for processing, especially with a view of\nfinding meaningful information to then take action. However, ideally the data\nneeds to be analysed locally to increase privacy, give quick responses to\npeople and to reduce use of network and storage resources. To tackle these\nproblems, distributed data analytics can be proposed to collect and analyse the\ndata either in the edge or fog devices. In this paper, we explore a hybrid\napproach which means that both innetwork level and cloud level processing\nshould work together to build effective IoT data analytics in order to overcome\ntheir respective weaknesses and use their specific strengths. Specifically, we\ncollected raw data locally and extracted features by applying data fusion\ntechniques on the data on resource constrained devices to reduce the data and\nthen send the extracted features to the cloud for processing. We evaluated the\naccuracy and data consumption over network and thus show that it is feasible to\nincrease privacy and maintain accuracy while reducing data communication\ndemands. \n\n"}
{"id": "1708.06475", "contents": "Title: Device-Aware Routing and Scheduling in Multi-Hop Device-to-Device\n  Networks Abstract: The dramatic increase in data and connectivity demand, in addition to\nheterogeneous device capabilities, poses a challenge for future wireless\nnetworks. One of the promising solutions is Device-to-Device (D2D) networking.\nD2D networking, advocating the idea of connecting two or more devices directly\nwithout traversing the core network, is promising to address the increasing\ndata and connectivity demand. In this paper, we consider D2D networks, where\ndevices with heterogeneous capabilities including computing power, energy\nlimitations, and incentives participate in D2D activities heterogeneously. We\ndevelop (i) a device-aware routing and scheduling algorithm (DARS) by taking\ninto account device capabilities, and (ii) a multi-hop D2D testbed using\nAndroid-based smartphones and tablets by exploiting Wi-Fi Direct and legacy\nWi-Fi connections. We show that DARS significantly improves throughput in our\ntestbed as compared to state-of-the-art. \n\n"}
{"id": "1708.06598", "contents": "Title: Coverage Maximization for a Poisson Field of Drone Cells Abstract: The use of drone base stations to provide wireless connectivity for ground\nterminals is becoming a promising part of future technologies. The design of\nsuch aerial networks is however different compared to cellular 2D networks, as\nantennas from the drones are looking down, and the channel model becomes\nheight-dependent. In this paper, we study the effect of antenna patterns and\nheight-dependent shadowing. We consider a random network topology to capture\nthe effect of dynamic changes of the flying base stations. First we\ncharacterize the aggregate interference imposed by the co-channel neighboring\ndrones. Then we derive the link coverage probability between a ground user and\nits associated drone base station. The result is used to obtain the optimum\nsystem parameters in terms of drones antenna beamwidth, density and altitude.\nWe also derive the average LoS probability of the associated drone and show\nthat it is a good approximation and simplification of the coverage probability\nin low altitudes up to 500 m according to the required\nsignal-to-interference-plus-noise ratio (SINR). \n\n"}
{"id": "1708.06698", "contents": "Title: Optimal and Scalable Caching for 5G Using Reinforcement Learning of\n  Space-time Popularities Abstract: Small basestations (SBs) equipped with caching units have potential to handle\nthe unprecedented demand growth in heterogeneous networks. Through low-rate,\nbackhaul connections with the backbone, SBs can prefetch popular files during\noff-peak traffic hours, and service them to the edge at peak periods. To\nintelligently prefetch, each SB must learn what and when to cache, while taking\ninto account SB memory limitations, the massive number of available contents,\nthe unknown popularity profiles, as well as the space-time popularity dynamics\nof user file requests. In this work, local and global Markov processes model\nuser requests, and a reinforcement learning (RL) framework is put forth for\nfinding the optimal caching policy when the transition probabilities involved\nare unknown. Joint consideration of global and local popularity demands along\nwith cache-refreshing costs allow for a simple, yet practical asynchronous\ncaching approach. The novel RL-based caching relies on a Q-learning algorithm\nto implement the optimal policy in an online fashion, thus enabling the cache\ncontrol unit at the SB to learn, track, and possibly adapt to the underlying\ndynamics. To endow the algorithm with scalability, a linear function\napproximation of the proposed Q-learning scheme is introduced, offering faster\nconvergence as well as reduced complexity and memory requirements. Numerical\ntests corroborate the merits of the proposed approach in various realistic\nsettings. \n\n"}
{"id": "1708.07862", "contents": "Title: Wireless Access for Ultra-Reliable Low-Latency Communication (URLLC):\n  Principles and Building Blocks Abstract: Ultra-reliable low latency communication (URLLC) is an important new feature\nbrought by 5G, with a potential to support a vast set of applications that rely\non mission-critical links. In this article, we first discuss the principles for\nsupporting URLLC from the perspective of the traditional assumptions and models\napplied in communication/information theory. We then discuss how these\nprinciples are applied in various elements of the system design, such as use of\nvarious diversity sources, design of packets and access protocols. The\nimportant messages are that there is a need to optimize the transmission of\nsignaling information, as well as a need for a lean use of various sources of\ndiversity. \n\n"}
{"id": "1708.08299", "contents": "Title: The Convergence of Machine Learning and Communications Abstract: The areas of machine learning and communication technology are converging.\nToday's communications systems generate a huge amount of traffic data, which\ncan help to significantly enhance the design and management of networks and\ncommunication components when combined with advanced machine learning methods.\nFurthermore, recently developed end-to-end training procedures offer new ways\nto jointly optimize the components of a communication system. Also in many\nemerging application fields of communication technology, e.g., smart cities or\ninternet of things, machine learning methods are of central importance. This\npaper gives an overview over the use of machine learning in different areas of\ncommunications and discusses two exemplar applications in wireless networking.\nFurthermore, it identifies promising future research topics and discusses their\npotential impact. \n\n"}
{"id": "1708.09138", "contents": "Title: Cellular Network Architectures for the Society in Motion Abstract: Due to rising mobility worldwide, a growing number of people utilizes\ncellular network services while on the move. Persistent urbanization trends\nraise the number of daily commuters, leading to a situation where\ntelecommunication requirements are mainly dictated by two categories of users:\n1) Static users inside buildings, demanding instantaneous and virtually\nbandwidth unlimited access to the Internet and Cloud services; 2) moving users\noutside, expecting ubiquitous and seamless mobility even at high velocity.\nWhile most work on future mobile communications is motivated by the first\ncategory of users, we outline in this article a layered cellular network\narchitecture that has the potential to efficiently support both user groups\nsimultaneously. We deduce novel transceiver architectures and derive research\nquestions that need to be tackled to effectively maintain wireless connectivity\nfor the envisioned Society in Motion. \n\n"}
{"id": "1708.09410", "contents": "Title: Secure Communications for the Two-user Broadcast Channel with Random\n  Traffic Abstract: In this work, we study the stability region of the two-user broadcast channel\n(BC) with bursty data arrivals and security constraints. We consider the\nscenario, where one of the receivers has a secrecy constraint and its packets\nneed to be kept secret from the other receiver. This is achieved by employing\nfull-duplexing at the receiver with the secrecy constraint, so that it\ntransmits a jamming signal to impede the reception of the other receiver. In\nthis context, the stability region of the two-user BC is characterized for the\ngeneral decoding case. Then, assuming two different decoding schemes the\nrespective stability regions are derived. The effect of self-interference due\nto the full-duplex operation on the stability region is also investigated. The\nstability region of the BC with a secrecy constraint, where the receivers do\nnot have full duplex capability can be obtained as a special case of the\nresults derived in this paper. In addition, the paper considers the problem of\nmaximizing the saturated throughput of the queue, whose packets does not\nrequire to be kept secret under minimum service guarantees for the other queue.\nThe results provide new insights on the effect of the secrecy constraint on the\nstability region of the BC. In particular, it is shown that the stability\nregion with secrecy constraint is sensitive to the coefficient of\nself-interference cancelation under certain cases. \n\n"}
{"id": "1708.09561", "contents": "Title: Optimal Dynamic Cloud Network Control Abstract: Distributed cloud networking enables the deployment of a wide range of\nservices in the form of interconnected software functions instantiated over\ngeneral purpose hardware at multiple cloud locations distributed throughout the\nnetwork. We consider the problem of optimal service delivery over a distributed\ncloud network, in which nodes are equipped with both communication and\ncomputation resources. We address the design of distributed online solutions\nthat drive flow processing and routing decisions, along with the associated\nallocation of cloud and network resources. For a given set of services, each\ndescribed by a chain of service functions, we characterize the cloud network\ncapacity region and design a family of dynamic cloud network control (DCNC)\nalgorithms that stabilize the underlying queuing system, while achieving\narbitrarily close to minimum cost with a tradeoff in network delay. The\nproposed DCNC algorithms make local decisions based on the online minimization\nof linear and quadratic metrics obtained from an upper bound on the Lyapunov\ndrift-plus-penalty of the cloud network queuing system. Minimizing a quadratic\nvs. a linear metric is shown to improve the cost-delay tradeoff at the expense\nof increased computational complexity. Our algorithms are further enhanced with\na shortest transmission-plus-processing distance bias that improves delay\nperformance without compromising throughput or overall cloud network cost. We\nprovide throughput and cost optimality guarantees, convergence time analysis,\nand extensive simulations in representative cloud network scenarios. \n\n"}
{"id": "1708.09661", "contents": "Title: Context-aware Cluster Based Device-to-Device Communication to Serve\n  Machine Type Communications Abstract: Billions of Machine Type Communication (MTC) devices are foreseen to be\ndeployed in next ten years and therefore potentially open a new market for next\ngeneration wireless network. However, MTC applications have different\ncharacteristics and requirements compared with the services provided by legacy\ncellular networks. For instance, an MTC device sporadically requires to\ntransmit a small data packet containing information generated by sensors. At\nthe same time, due to the massive deployment of MTC devices, it is inefficient\nto charge their batteries manually and thus a long battery life is required for\nMTC devices. In this sense, legacy networks designed to serve human-driven\ntraffics in real time can not support MTC efficiently. In order to improve the\navailability and battery life of MTC devices, context-aware device-to-device\n(D2D) communication is exploited in this paper. By applying D2D communication,\nsome MTC users can serve as relays for other MTC users who experience bad\nchannel conditions. Moreover, signaling schemes are also designed to enable the\ncollection of context information and support the proposed D2D communication\nscheme. Last but not least, a system level simulator is implemented to evaluate\nthe system performance of the proposed technologies and a large performance\ngain is shown by the numerical results. \n\n"}
{"id": "1708.09827", "contents": "Title: Walking Through Waypoints Abstract: We initiate the study of a fundamental combinatorial problem: Given a\ncapacitated graph $G=(V,E)$, find a shortest walk (\"route\") from a source $s\\in\nV$ to a destination $t\\in V$ that includes all vertices specified by a set\n$\\mathscr{W}\\subseteq V$: the \\emph{waypoints}. This waypoint routing problem\nfinds immediate applications in the context of modern networked distributed\nsystems. Our main contribution is an exact polynomial-time algorithm for graphs\nof bounded treewidth. We also show that if the number of waypoints is\nlogarithmically bounded, exact polynomial-time algorithms exist even for\ngeneral graphs. Our two algorithms provide an almost complete characterization\nof what can be solved exactly in polynomial-time: we show that more general\nproblems (e.g., on grid graphs of maximum degree 3, with slightly more\nwaypoints) are computationally intractable. \n\n"}
{"id": "1709.00844", "contents": "Title: Optimizing Networks for Internet Access Using Tethering Abstract: We investigate scenarios where Internet access to a user device (node) is\navailable only via the cellular network. However, not every node may connect\ndirectly to it. Instead, some may use tethering to connect over WiFi to a node\nsharing its Internet connection. In effect, nodes split into hotspots and\nclients. Hotspots are nodes that connect directly to the cellular network and\ncan provide Internet connectivity to other nodes to whom they are connected\nover WiFi. Clients connect to the cellular network only via hotspots. In this\nwork, we consider the problem of determining the split of hotspots and clients,\nand the association between them, which maximizes the sum of the rates of all\nnodes, subject to the constraint that any node gets at least the rate it gets\nwhen all nodes are directly connected to the cellular network. Via tractable\nnetworks, we provide insights into the interplay between WiFi connectivity\namongst nodes and rates of their links to the cellular tower, the splits that\nmaximize sum rate, with provably optimal splits for a few cases. We propose a\nnovel heuristic approach to split any network and provide a detailed exposition\nof gains available from tethering, via simulations. \n\n"}
{"id": "1709.01282", "contents": "Title: Implicit Cooperative Positioning in Vehicular Networks Abstract: Absolute positioning of vehicles is based on Global Navigation Satellite\nSystems (GNSS) combined with on-board sensors and high-resolution maps. In\nCooperative Intelligent Transportation Systems (C-ITS), the positioning\nperformance can be augmented by means of vehicular networks that enable\nvehicles to share location-related information. This paper presents an Implicit\nCooperative Positioning (ICP) algorithm that exploits the Vehicle-to-Vehicle\n(V2V) connectivity in an innovative manner, avoiding the use of explicit V2V\nmeasurements such as ranging. In the ICP approach, vehicles jointly localize\nnon-cooperative physical features (such as people, traffic lights or inactive\ncars) in the surrounding areas, and use them as common noisy reference points\nto refine their location estimates. Information on sensed features are fused\nthrough V2V links by a consensus procedure, nested within a message passing\nalgorithm, to enhance the vehicle localization accuracy. As positioning does\nnot rely on explicit ranging information between vehicles, the proposed ICP\nmethod is amenable to implementation with off-the-shelf vehicular communication\nhardware. The localization algorithm is validated in different traffic\nscenarios, including a crossroad area with heterogeneous conditions in terms of\nfeature density and V2V connectivity, as well as a real urban area by using\nSimulation of Urban MObility (SUMO) for traffic data generation. Performance\nresults show that the proposed ICP method can significantly improve the vehicle\nlocation accuracy compared to the stand-alone GNSS, especially in harsh\nenvironments, such as in urban canyons, where the GNSS signal is highly\ndegraded or denied. \n\n"}
{"id": "1709.01313", "contents": "Title: Distributed VNF Scaling in Large-scale Datacenters: An ADMM-based\n  Approach Abstract: Network Functions Virtualization (NFV) is a promising network architecture\nwhere network functions are virtualized and decoupled from proprietary\nhardware. In modern datacenters, user network traffic requires a set of Virtual\nNetwork Functions (VNFs) as a service chain to process traffic demands. Traffic\nfluctuations in Large-scale DataCenters (LDCs) could result in overload and\nunderload phenomena in service chains. In this paper, we propose a distributed\napproach based on Alternating Direction Method of Multipliers (ADMM) to jointly\nload balance the traffic and horizontally scale up and down VNFs in LDCs with\nminimum deployment and forwarding costs. Initially we formulate the targeted\noptimization problem as a Mixed Integer Linear Programming (MILP) model, which\nis NP-complete. Secondly, we relax it into two Linear Programming (LP) models\nto cope with over and underloaded service chains. In the case of small or\nmedium size datacenters, LP models could be run in a central fashion with a low\ntime complexity. However, in LDCs, increasing the number of LP variables\nresults in additional time consumption in the central algorithm. To mitigate\nthis, our study proposes a distributed approach based on ADMM. The\neffectiveness of the proposed mechanism is validated in different scenarios. \n\n"}
{"id": "1709.01494", "contents": "Title: Latency Optimal Broadcasting in Noisy Wireless Mesh Networks Abstract: In this paper, we adopt a new noisy wireless network model introduced very\nrecently by Censor-Hillel et al. in [ACM PODC 2017, CHHZ17]. More specifically,\nfor a given noise parameter $p\\in [0,1],$ any sender has a probability of $p$\nof transmitting noise or any receiver of a single transmission in its\nneighborhood has a probability $p$ of receiving noise.\n  In this paper, we first propose a new asymptotically latency-optimal\napproximation algorithm (under faultless model) that can complete\nsingle-message broadcasting task in $D+O(\\log^2 n)$ time units/rounds in any\nWMN of size $n,$ and diameter $D$. We then show this diameter-linear\nbroadcasting algorithm remains robust under the noisy wireless network model\nand also improves the currently best known result in CHHZ17 by a\n$\\Theta(\\log\\log n)$ factor.\n  In this paper, we also further extend our robust single-message broadcasting\nalgorithm to $k$ multi-message broadcasting scenario and show it can broadcast\n$k$ messages in $O(D+k\\log n+\\log^2 n)$ time rounds. This new robust\nmulti-message broadcasting scheme is not only asymptotically optimal but also\nanswers affirmatively the problem left open in CHHZ17 on the existence of an\nalgorithm that is robust to sender and receiver faults and can broadcast $k$\nmessages in $O(D+k\\log n + polylog(n))$ time rounds. \n\n"}
{"id": "1709.01672", "contents": "Title: Throughput Optimal Decentralized Scheduling of Multi-Hop Networks with\n  End-to-End Deadline Constraints: II Wireless Networks with Interference Abstract: Consider a multihop wireless network serving multiple flows in which wireless\nlink interference constraints are described by a link interference graph. For\nsuch a network, we design routing-scheduling policies that maximize the\nend-to-end timely throughput of the network. Timely throughput of a flow $f$ is\ndefined as the average rate at which packets of flow $f$ reach their\ndestination node $d_f$ within their deadline.\n  Our policy has several surprising characteristics. Firstly, we show that the\noptimal routing-scheduling decision for an individual packet that is present at\na wireless node $i\\in V$ is solely a function of its location, and \"age\". Thus,\na wireless node $i$ does not require the knowledge of the \"global\" network\nstate in order to maximize the timely throughput. We notice that in comparison,\nunder the backpressure routing policy, a node $i$ requires only the knowledge\nof its neighbours queue lengths in order to guarantee maximal stability, and\nhence is decentralized. The key difference arises due to the fact that in our\nset-up the packets loose their utility once their \"age\" has crossed their\ndeadline, thus making the task of optimizing timely throughput much more\nchallenging than that of ensuring network stability. Of course, due to this key\ndifference, the decision process involved in maximizing the timely throughput\nis also much more complex than that involved in ensuring network-wide queue\nstabilization. In view of this, our results are somewhat surprising. \n\n"}
{"id": "1709.01786", "contents": "Title: An Efficient Loop-free Version of AODVv2 Abstract: Ad hoc On Demand distance Vector (AODV) routing protocol is one of the most\nprominent routing protocol used in Mobile Ad-hoc Networks (MANETs). Due to the\nmobility of nodes, there exists many revisions as scenarios leading to the loop\nformation were found. We demonstrate the loop freedom property violation of\nAODVv2-11, AODVv2-13, and AODVv2-16 through counterexamples. We present our\nproposed version of AODVv2 precisely which not only ensures loop freedom but\nalso improves the performance. \n\n"}
{"id": "1709.03734", "contents": "Title: Enhanced Random Access and Beam Training for mmWave Wireless Local\n  Networks with High User Density Abstract: As low frequency band becomes more and more crowded, millimeter-wave (mmWave)\nhas attracted significant attention recently. IEEE has released the 802.11ad\nstandard to satisfy the demand of ultra-high-speed communication. It adopts\nbeamforming technology that can generate directional beams to compensate for\nhigh path loss. In the Association Beamforming Training (A-BFT) phase of\nbeamforming (BF) training, a station (STA) randomly selects an A-BFT slot to\ncontend for training opportunity. Due to the limited number of A-BFT slots,\nA-BFT phase suffers high probability of collisions in dense user scenarios,\nresulting in inefficient training performance. Based on the evaluation of the\nIEEE 802.11ad standard and 802.11ay draft in dense user scenarios of mmWave\nwireless networks, we propose an enhanced A-BFT beam training and random access\nmechanism, including the Separated A-BFT (SA-BFT) and Secondary Backoff A-BFT\n(SBA-BFT). The SA-BFT can provide more A-BFT slots and divide A-BFT slots into\ntwo regions by defining a new `E-A-BFT Length' field compared to the legacy\n802.11ad A-BFT, thereby maintaining compatibility when 802.11ay devices are\nmixed with 802.11ad devices. It can also reduce the collision probability in\ndense user scenarios greatly. The SBA-BFT performs secondary backoff with very\nsmall overhead of transmission opportunities within one A-BFT slot, which not\nonly further reduces collision probability, but also improves the A-BFT slots\nutilization. Furthermore, we propose a three-dimensional Markov model to\nanalyze the performance of the SBA-BFT. The analytical and simulation results\nshow that both the SA-BFT and the SBA-BFT can significantly improve BF training\nefficiency, which are beneficial to the optimization design of dense user\nwireless networks based on the IEEE 802.11ay standard and mmWave technology. \n\n"}
{"id": "1709.05710", "contents": "Title: Fine-Grained Endpoint-Driven In-Network Traffic Control for Proactive\n  DDoS Attack Mitigation Abstract: Volumetric attacks, which overwhelm the bandwidth of a destination, are among\nthe most common DDoS attacks today. Despite considerable effort made by both\nresearch and industry, our recent interviews with over 100 potential DDoS\nvictims in over 10 industry segments indicate that today's DDoS prevention is\nfar from perfect. On one hand, few academical proposals have ever been deployed\nin the Internet; on the other hand, solutions offered by existing DDoS\nprevention vendors are not a silver bullet to defend against the entire attack\nspectrum. Guided by such large-scale study of today's DDoS defense, in this\npaper, we present MiddlePolice, the first readily deployable and proactive DDoS\nprevention mechanism. We carefully architect MiddlePolice such that it requires\nno changes from both the Internet core and the network stack of clients,\nyielding instant deployability in the current Internet architecture. Further,\nrelying on our novel capability feedback mechanism, MiddlePolice is able to\nenforce destination-driven traffic control so that it guarantees to deliver\nvictim-desired traffic regardless of the attacker strategies. We implement a\nprototype of MiddlePolice, and demonstrate its feasibility via extensive\nevaluations in the Internet, hardware testbed and large-scale simulations. \n\n"}
{"id": "1709.06002", "contents": "Title: NeuRoute: Predictive Dynamic Routing for Software-Defined Networks Abstract: This paper introduces NeuRoute, a dynamic routing framework for Software\nDefined Networks (SDN) entirely based on machine learning, specifically, Neural\nNetworks. Current SDN/OpenFlow controllers use a default routing based on\nDijkstra algorithm for shortest paths, and provide APIs to develop custom\nrouting applications. NeuRoute is a controller-agnostic dynamic routing\nframework that (i) predicts traffic matrix in real time, (ii) uses a neural\nnetwork to learn traffic characteristics and (iii) generates forwarding rules\naccordingly to optimize the network throughput. NeuRoute achieves the same\nresults as the most efficient dynamic routing heuristic but in much less\nexecution time. \n\n"}
{"id": "1709.06837", "contents": "Title: Towards Better Understanding of Bitcoin Unreachable Peers Abstract: The bitcoin peer-to-peer network has drawn significant attention from\nresearchers, but so far has mostly focused on publicly visible portions of the\nnetwork, i.e., publicly reachable peers. This mostly ignores the hidden parts\nof the network: unreachable Bitcoin peers behind NATs and firewalls. In this\npaper, we characterize Bitcoin peers that might be behind NATs or firewalls\nfrom different perspectives. Using a special-purpose measurement tool we\nconduct a large scale measurement study of the Bitcoin network, and discover\nseveral previously unreported usage patterns: a small number of peers are\ninvolved in the propagation of 89% of all bitcoin transactions, public cloud\nservices are being used for Bitcoin network probing and crawling, a large\namount of transactions are generated from only two mobile applications. We also\nempirically evaluate a method that uses timing information to re-identify the\npeer that created a transaction against unreachable peers. We find this method\nvery accurate for peers that use the latest version of the Bitcoin Core client. \n\n"}
{"id": "1709.07080", "contents": "Title: A Deep-Reinforcement Learning Approach for Software-Defined Networking\n  Routing Optimization Abstract: In this paper we design and evaluate a Deep-Reinforcement Learning agent that\noptimizes routing. Our agent adapts automatically to current traffic conditions\nand proposes tailored configurations that attempt to minimize the network\ndelay. Experiments show very promising performance. Moreover, this approach\nprovides important operational advantages with respect to traditional\noptimization algorithms. \n\n"}
{"id": "1709.07356", "contents": "Title: User Association and Bandwidth Allocation for Terrestrial and Aerial\n  Base Stations with Backhaul Considerations Abstract: Drone base stations (DBSs) can enhance network coverage and area capacity by\nmoving supply towards demand when required. This degree of freedom could be\nespecially useful for future applications with extreme demands, such as ultra\nreliable and low latency communications (uRLLC). However, deployment of DBSs\ncan face several challenges. One issue is finding the 3D placement of such BSs\nto satisfy dynamic requirements of the system. Second, the availability of\nreliable wireless backhaul links and the related resource allocation are\nprincipal issues that should be considered. Finally, association of the users\nwith BSs becomes an involved problem due to mobility of DBSs. In this paper, we\nconsider a macro-BS (MBS) and several DBSs that rely on the wireless links to\nthe MBS for backhauling. Considering regular and uRLLC users, we propose an\nalgorithm to find efficient 3D locations of DBSs in addition to the user-BS\nassociations and wireless backhaul bandwidth allocations to maximize the sum\nlogarithmic rate of the users. To this end, a decomposition method is employed\nto first find the user-BS association and bandwidth allocations. Then DBS\nlocations are updated using a heuristic particle swarm optimization algorithm.\nSimulation results show the effectiveness of the proposed method and provide\nuseful insights on the effects of traffic distributions and antenna beamwidth. \n\n"}
{"id": "1709.07974", "contents": "Title: Infrastructure Sharing for Mobile Network Operators: Analysis of\n  Trade-offs and Market Abstract: The conflicting problems of growing mobile service demand and\nunderutilization of dedicated spectrum has given rise to a paradigm where\nmobile network operators (MNOs) share their infrastructure among themselves in\norder to lower their operational costs, while at the same time increase the\nusage of their existing network resources. We model and analyze such an\ninfrastructure sharing system considering a single buyer MNO and multiple\nseller MNOs. Assuming that the locations of the BSs can be modeled as a\nhomogeneous Poisson point process, we find the downlink\nsignal-to-interference-plus-noise ratio (SINR) coverage probability for a user\nserved by the buyer MNO in an infrastructure sharing environment. We analyze\nthe trade-off between increasing the transmit power of a BS and the intensity\nof BSs owned by the buyer MNO required to achieve a given quality-of-service\n(QoS) in terms of the SINR coverage probability. Also, for a seller MNO, we\nanalyze the power consumption of the network per unit area (i.e., areal power\nconsumption) which is shown to be a piecewise continuous function of BS\nintensity, composed of a linear and a convex function. Accordingly, the BS\nintensity of the seller MNO can be optimized to minimize the areal power\nconsumption while achieving a minimum QoS for the buyer MNO. We then use these\nresults to formulate a single-buyer multiple-seller BS infrastructure market.\nThe buyer MNO is concerned with finding which seller MNO to purchase from and\nwhat fraction of BSs to purchase. On the sellers' side, the problem of pricing\nand determining the fraction of infrastructure to be sold is formulated as a\nCournot oligopoly market. We prove that the iterative update of each seller's\nbest response always converges to the Nash Equilibrium. \n\n"}
{"id": "1709.10128", "contents": "Title: Online Learning with Randomized Feedback Graphs for Optimal PUE Attacks\n  in Cognitive Radio Networks Abstract: In a cognitive radio network, a secondary user learns the spectrum\nenvironment and dynamically accesses the channel where the primary user is\ninactive. At the same time, a primary user emulation (PUE) attacker can send\nfalsified primary user signals and prevent the secondary user from utilizing\nthe available channel. The best attacking strategies that an attacker can apply\nhave not been well studied. In this paper, for the first time, we study optimal\nPUE attack strategies by formulating an online learning problem where the\nattacker needs to dynamically decide the attacking channel in each time slot\nbased on its attacking experience. The challenge in our problem is that since\nthe PUE attack happens in the spectrum sensing phase, the attacker cannot\nobserve the reward on the attacked channel. To address this challenge, we\nutilize the attacker's observation capability. We propose online learning-based\nattacking strategies based on the attacker's observation capabilities. Through\nour analysis, we show that with no observation within the attacking slot, the\nattacker loses on the regret order, and with the observation of at least one\nchannel, there is a significant improvement on the attacking performance.\nObservation of multiple channels does not give additional benefit to the\nattacker (only a constant scaling) though it gives insight on the number of\nobservations required to achieve the minimum constant factor. Our proposed\nalgorithms are optimal in the sense that their regret upper bounds match their\ncorresponding regret lower-bounds. We show consistency between simulation and\nanalytical results under various system parameters. \n\n"}
{"id": "1710.00395", "contents": "Title: Channel Hardening and Favorable Propagation in Cell-Free Massive MIMO\n  with Stochastic Geometry Abstract: Cell-Free (CF) Massive MIMO is an alternative topology for future wireless\nnetworks, where a large number of single-antenna access points (APs) are\ndistributed over the coverage area. There are no cells but all users are\njointly served by the APs using network MIMO methods. Prior works have claimed\nthat CF Massive MIMO inherits the basic properties of cellular Massive MIMO,\nnamely channel hardening and favorable propagation. In this paper, we evaluate\nif one can rely on these properties when having a realistic stochastic AP\ndeployment. Our results show that channel hardening only appears in special\ncases, for example, when the pathloss exponent is small. However, by using\n5--10 antennas per AP, instead of one, we can substantially improve the\nhardening. Only spatially well-separated users will exhibit favorable\npropagation, but when adding more antennas and/or reducing the pathloss\nexponent, it becomes more likely for favorable propagation to occur. The\nconclusion is that we cannot rely on channel hardening and favorable\npropagation when analyzing and designing CF Massive MIMO networks, but we need\nto use achievable rate expressions and resource allocation schemes that work\nwell also in the absence of these properties. Some options are reviewed in this\npaper. \n\n"}
{"id": "1710.01801", "contents": "Title: FOCAN: A Fog-supported Smart City Network Architecture for Management of\n  Applications in the Internet of Everything Environments Abstract: Smart city vision brings emerging heterogeneous communication technologies\nsuch as Fog Computing (FC) together to substantially reduce the latency and\nenergy consumption of Internet of Everything (IoE) devices running various\napplications. The key feature that distinguishes the FC paradigm for smart\ncities is that it spreads communication and computing resources over the\nwired/wireless access network (e.g., proximate access points and base stations)\nto provide resource augmentation (e.g., cyberforaging) for resource and\nenergy-limited wired/wireless (possibly mobile) things. Moreover, smart city\napplications are developed with the goal of improving the management of urban\nflows and allowing real-time responses to challenges that can arise in users'\ntransactional relationships. This article presents a Fog-supported smart city\nnetwork architecture called Fog Computing Architecture Network (FOCAN), a\nmulti-tier structure in which the applications running on things jointly\ncompute, route, and communicate with one another through the smart city\nenvironment to decrease latency and improve energy provisioning and the\nefficiency of services among things with different capabilities. An important\nconcern that arises with the introduction of FOCAN is the need to avoid\ntransferring data to/from distant things and instead to cover the nearest\nregion for an IoT application. We define three types of communications between\nFOCAN devices (e.g., interprimary, primary, and secondary communication) to\nmanage applications in a way that meets the quality of service standards for\nthe IoE. One of the main advantages of FOCAN is that the devices can provide\nthe services with low energy usage and in an efficient manner. Simulation\nresults for a selected case study demonstrate the tremendous impact of the\nFOCAN energy-efficient solution on the communication performance of various\ntypes of things in smart cities. \n\n"}
{"id": "1710.02459", "contents": "Title: Evaluation of the Performance of Adaptive HTTP Streaming Systems Abstract: Adaptive video streaming over HTTP is becoming omnipresent in our daily life.\nIn the past, dozens of research papers have proposed novel approaches to\naddress different aspects of adaptive streaming and a decent amount of player\nimplementations (commercial and open source) are available. However, state of\nthe art evaluations are sometimes superficial as many proposals only\ninvestigate a certain aspect of the problem or focus on a specific platform -\nplayer implementations used in actual services are rarely considered. HTML5 is\nnow available on many platforms and foster the deployment of adaptive media\nstreaming applications. We propose a common evaluation framework for adaptive\nHTML5 players and demonstrate its applicability by evaluating eight different\nplayers which are actually deployed in real-world services. \n\n"}
{"id": "1710.02611", "contents": "Title: Joint Energy Efficient and QoS-aware Path Allocation and VNF Placement\n  for Service Function Chaining Abstract: Service Function Chaining (SFC) allows the forwarding of a traffic flow along\na chain of Virtual Network Functions (VNFs, e.g., IDS, firewall, and NAT).\nSoftware Defined Networking (SDN) solutions can be used to support SFC reducing\nthe management complexity and the operational costs. One of the most critical\nissues for the service and network providers is the reduction of energy\nconsumption, which should be achieved without impact to the quality of\nservices. In this paper, we propose a novel resource (re)allocation\narchitecture which enables energy-aware SFC for SDN-based networks. To this\nend, we model the problems of VNF placement, allocation of VNFs to flows, and\nflow routing as optimization problems. Thereafter, heuristic algorithms are\nproposed for the different optimization problems, in order find near-optimal\nsolutions in acceptable times. The performance of the proposed algorithms are\nnumerically evaluated over a real-world topology and various network traffic\npatterns. The results confirm that the proposed heuristic algorithms provide\nnear optimal solutions while their execution time is applicable for real-life\nnetworks. \n\n"}
{"id": "1710.03473", "contents": "Title: Recent Advances in Information-Centric Networking based Internet of\n  Things (ICN-IoT) Abstract: Information-Centric Networking (ICN) is being realized as a promising\napproach to accomplish the shortcomings of current IP-address based networking.\nICN models are based on naming the content to get rid of address-space\nscarcity, accessing the content via name-based-routing, caching the content at\nintermediate nodes to provide reliable, efficient data delivery and\nself-certifying contents to ensure better security. Obvious benefits of ICN in\nterms of fast and efficient data delivery and improved reliability raises ICN\nas highly promising networking model for Internet of Things (IoTs) like\nenvironments. IoT aims to connect anyone and/or anything at any time by any\npath on any place. From last decade, IoTs attracts both industry and research\ncommunities. IoTs is an emerging research field and still in its infancy. Thus,\nthis paper presents the potential of ICN for IoTs by providing state-of-the-art\nliterature survey. We discuss briefly the feasibility of ICN features and their\nmodels (and architectures) in the context of IoT. Subsequently, we present a\ncomprehensive survey on ICN based caching, naming, security and mobility\napproaches for IoTs with appropriate classification. Furthermore, we present\noperating systems (OS) and simulation tools for ICNIoT. Finally, we provide\nimportant research challenges and issues faced by ICN for IoTs. \n\n"}
{"id": "1710.05616", "contents": "Title: Fast Deployment of UAV Networks for Optimal Wireless Coverage Abstract: Unmanned Aerial Vehicle (UAV) networks have emerged as a promising technique\nto rapidly provide wireless coverage to a geographical area, where a flying UAV\ncan be fast deployed to serve as cell site. Existing work on UAV-enabled\nwireless networks overlook the fast UAV deployment for wireless coverage, and\nsuch deployment problems have only been studied recently in sensor networks.\nUnlike sensors, UAVs should be deployed to the air and they are generally\ndifferent in flying speed, operating altitude and wireless coverage radius. By\nconsidering such UAV heterogeneity to cover the whole target area, this paper\nstudies two fast UAV deployment problems: one is to minimize the maximum\ndeployment delay among all UAVs (min-max) for fairness consideration, and the\nother is to minimize the total deployment delay (min-sum) for efficiency\nconsideration. We prove both min-max and min-sum problems are NP-complete in\ngeneral. When dispatching UAVs from the same location, we present an optimal\nalgorithm of low computational complexity $O(n^2)$ for the min-max problem.\nWhen UAVs are dispatched from different locations, we propose to preserve their\nlocation order during deployment and successfully design a fully polynomial\ntime approximation scheme (FPTAS) of computation complexity $O(n^2 \\log\n\\frac{1}{\\epsilon})$ to arbitrarily approach the global optimum with relative\nerror $\\epsilon$. The min-sum problem is more challenging. When UAVs are\ndispatched from the same initial location, we present an approximation\nalgorithm of linear time. As for the general case, we further reformulate it as\na dynamic program and propose a pseudo polynomial-time algorithm to solve it\noptimally. \n\n"}
{"id": "1710.06089", "contents": "Title: Hierarchical Fog-Cloud Computing for IoT Systems: A Computation\n  Offloading Game Abstract: Fog computing, which provides low-latency computing services at the network\nedge, is an enabler for the emerging Internet of Things (IoT) systems. In this\npaper, we study the allocation of fog computing resources to the IoT users in a\nhierarchical computing paradigm including fog and remote cloud computing\nservices. We formulate a computation offloading game to model the competition\nbetween IoT users and allocate the limited processing power of fog nodes\nefficiently. Each user aims to maximize its own quality of experience (QoE),\nwhich reflects its satisfaction of using computing services in terms of the\nreduction in computation energy and delay. Utilizing a potential game approach,\nwe prove the existence of a pure Nash equilibrium and provide an upper bound\nfor the price of anarchy. Since the time complexity to reach the equilibrium\nincreases exponentially in the number of users, we further propose a\nnear-optimal resource allocation mechanism and prove that in a system with $N$\nIoT users, it can achieve an $\\epsilon$-Nash equilibrium in $O(N/\\epsilon)$\ntime. Through numerical studies, we evaluate the users' QoE as well as the\nequilibrium efficiency. Our results reveal that by utilizing the proposed\nmechanism, more users benefit from computing services in comparison to an\nexisting offloading mechanism. We further show that our proposed mechanism\nsignificantly reduces the computation delay and enables low-latency fog\ncomputing services for delay-sensitive IoT applications. \n\n"}
{"id": "1710.07927", "contents": "Title: Coexistence Gaps in Space: Cross-Technology Interference-Nulling for\n  Improving LTE-U/WiFi Coexistence Abstract: To avoid the foreseeable spectrum crunch, LTE operators have started to\nexplore the option to directly use 5 GHz unlicensed spectrum band being used by\nIEEE 802.11 (WiFi). However, as LTE is not designed with shared spectrum access\nin mind, there is a major issue of coexistence with WiFi networks. Current\ncoexistence schemes to be deployed at the LTE-U BS create coexistence gaps only\nin one domain (e.g., time, frequency, or space) and can provide only\nincremental gains due to the lack of coordination among the coexisting WiFi and\nLTE-U networks. Therefore, we propose a coordinated coexistence scheme which\nrelies on cooperation between neighboring LTE-U and WiFi networks. Our proposal\nsuggests that LTE-U BSs equipped with multiple antennas can create coexistence\ngaps in space domain in addition to the time domain gaps by means of\ncross-technology interference nulling towards WiFi nodes in the interference\nrange. In return, LTE-U can increase its own airtime utilization while trading\noff slightly its antenna diversity. The cooperation offers benefits to both\nLTE-U and WiFi in terms of improved throughput and decreased channel access\ndelay. More specifically, system-level simulations reveal a throughput gain up\nto 221% for LTE-U network and 44% for WiFi network depending on the setting,\ne.g., the distance between the two cell, number of LTE antennas, and WiFi users\nin the LTE-U BS neighborhood. Our proposal provides significant benefits\nespecially for moderate separation distances between LTE-U/WiFi cells where\ninterference from a neighboring network might be severe due to the hidden\nnetwork problem. \n\n"}
{"id": "1710.08214", "contents": "Title: Parametric channel estimation for massive MIMO Abstract: Channel state information is crucial to achieving the capacity of\nmulti-antenna (MIMO) wireless communication systems. It requires estimating the\nchannel matrix. This estimation task is studied, considering a sparse channel\nmodel particularly suited to millimeter wave propagation, as well as a general\nmeasurement model taking into account hybrid architectures. The contribution is\ntwofold. First, the Cram{\\'e}r-Rao bound in this context is derived. Second,\ninterpretation of the Fisher Information Matrix structure allows to assess the\nrole of system parameters, as well as to propose asymptotically optimal and\ncomputationally efficient estimation algorithms. \n\n"}
{"id": "1710.08478", "contents": "Title: Key Technologies and System Trade-Offs for Detection and Localization of\n  Amateur Drones Abstract: The use of amateur drones (ADrs) is expected to significantly increase over\nthe upcoming years. However, regulations do not allow such drones to fly over\nall areas, in addition to typical altitude limitations. As a result, there is\nan urgent need for ADrs surveillance solutions. These solutions should include\nmeans of accurate detection, classification, and localization of the unwanted\ndrones in a no-fly zone. In this paper, we give an overview of promising\ntechniques for modulation classification and signal strength based localization\nof ADrs by using surveillance drones (SDrs). By introducing a generic altitude\ndependent propagation model, we show how detection and localization performance\ndepend on the altitude of SDrs. Particularly, our simulation results show a 25\ndB reduction in the minimum detectable power or 10 times coverage enhancement\nof an SDr by flying at the optimum altitude. Moreover, for a target no-fly\nzone, the location estimation error of an ADr can be remarkably reduced by\noptimizing the positions of the SDrs. Finally, we conclude the paper with a\ngeneral discussion about the future work and possible challenges of the aerial\nsurveillance systems. \n\n"}
{"id": "1710.08647", "contents": "Title: Approximate Reduction of Finite Automata for High-Speed Network\n  Intrusion Detection (Technical Report) Abstract: We consider the problem of approximate reduction of non-deterministic\nautomata that appear in hardware-accelerated network intrusion detection\nsystems (NIDSes). We define an error distance of a reduced automaton from the\noriginal one as the probability of packets being incorrectly classified by the\nreduced automaton (wrt the probabilistic distribution of packets in the network\ntraffic). We use this notion to design an approximate reduction procedure that\nachieves a great size reduction (much beyond the state-of-the-art\nlanguage-preserving techniques) with a controlled and small error. We have\nimplemented our approach and evaluated it on use cases from Snort, a popular\nNIDS. Our results provide experimental evidence that the method can be highly\nefficient in practice, allowing NIDSes to follow the rapid growth in the speed\nof networks. \n\n"}
{"id": "1710.09029", "contents": "Title: What is the Optimal Network Deployment for a Fixed Density of Antennas? Abstract: In this paper, we answer a fundamental question: when the total number of\nantennas per square kilometer is fixed, what is the optimal network deployment?\nA denser network with a less number of antennas per base station (BS) or the\nopposite case. To evaluate network performance, we consider a practical network\nscenario with a fixed antennas density and multiuser\nmultiple-input-multiple-output (MU-MIMO) operations for single-antenna users.\nThe number of antennas in each BS is calculated by dividing the antenna density\nby the BS density. With the consideration of several practical network models,\ni.e., pilot contamination, a limited user equipment (UE) density and\nprobabilistic line-of-sight (LoS)/non-line-of-sight (NLoS) path loss model, we\nevaluate the area spectral efficiency (ASE) performance. From our simulation\nresults, we conclude that there exists an optimal BS density for a certain UE\ndensity to maximize the ASE performance when the antenna density is fixed. The\nintuition is that (i) by densifying the network with more BSs, we can achieve a\nreceive power gain due to the smaller distance between the typical UE and its\nserving BS; (ii) by installing more antennas in each BS, we can achieve a\nbeamforming gain for UEs using MU-MIMO, although such beamforming gain is\ndegraded by pilot contamination; (iii) thus, a trade-off exists between the\nreceive power gain and the beamforming gain, if we fix the antenna density in\nthe network. \n\n"}
{"id": "1710.10033", "contents": "Title: Towards efficient coexistence of IEEE 802.15.4e TSCH and IEEE 802.11 Abstract: A major challenge in wide deployment of smart wireless devices, using\ndifferent technologies and sharing the same 2.4 GHz spectrum, is to achieve\ncoexistence across multiple technologies. The IEEE~802.11 (WLAN) and the IEEE\n802.15.4e TSCH (WSN) where designed with different goals in mind and both play\nimportant roles for respective applications. However, they cause mutual\ninterference and degraded performance while operating in the same space. To\nimprove this situation we propose an approach to enable a cooperative control\nwhich type of network is transmitting at given time, frequency and place.\n  We recognize that TSCH based sensor network is expected to occupy only small\nshare of time, and that the nodes are by design tightly synchronized. We\ndevelop mechanism enabling over-the-air synchronization of the Wi-Fi network to\nthe TSCH based sensor network. Finally, we show that Wi-Fi network can avoid\ntransmitting in the \"collision periods\". We provide full design and show\nprototype implementation based on the Commercial off-the-shelf (COTS) devices.\nOur solution does not require changes in any of the standards. \n\n"}
{"id": "1710.10356", "contents": "Title: Optimal Control of Wireless Computing Networks Abstract: Augmented information (AgI) services allow users to consume information that\nresults from the execution of a chain of service functions that process source\ninformation to create real-time augmented value. Applications include real-time\nanalysis of remote sensing data, real-time computer vision, personalized video\nstreaming, and augmented reality, among others. We consider the problem of\noptimal distribution of AgI services over a wireless computing network, in\nwhich nodes are equipped with both communication and computing resources. We\ncharacterize the wireless computing network capacity region and design a joint\nflow scheduling and resource allocation algorithm that stabilizes the\nunderlying queuing system while achieving a network cost arbitrarily close to\nthe minimum, with a tradeoff in network delay. Our solution captures the unique\nchaining and flow scaling aspects of AgI services, while exploiting the use of\nthe broadcast approach coding scheme over the wireless channel. \n\n"}
{"id": "1710.11404", "contents": "Title: Reshaping Cellular Networks for the Sky: Major Factors and Feasibility Abstract: This paper studies the feasibility of supporting drone operations using\nexistent cellular infrastructure. We propose an analytical framework that\nincludes the effects of base station (BS) height and antenna radiation pattern,\ndrone antenna directivity and various propagation environments. With this\nframework, we derive an exact expression for the coverage probability of ground\nand drone users through a practical cell association strategy. Our results show\nthat a carefully designed network can control the radiated interference that is\nreceived by the drones, and therefore guarantees a satisfactory quality of\nservice. Moreover, as the network density grows the increasing level of\ninterference can be partially managed by lowering the drone flying altitude.\nHowever, even at optimal conditions the drone coverage performance converges to\nzero considerably fast, suggesting that ultra-dense networks might be poor\ncandidates for serving aerial users. \n\n"}
{"id": "1710.11548", "contents": "Title: Complex Systems Science meets 5G and IoT Abstract: We propose a new paradigm for telecommunications, and develop a framework\ndrawing on concepts from information (i.e., different metrics of complexity)\nand computational (i.e., agent based modeling) theory, adapted from complex\nsystem science. We proceed in a systematic fashion by dividing network\ncomplexity understanding and analysis into different layers. Modelling layer\nforms the foundation of the proposed framework, supporting analysis and tuning\nlayers. The modelling layer aims at capturing the significant attributes of\nnetworks and the interactions that shape them, through the application of tools\nsuch as agent-based modelling and graph theoretical abstractions, to derive new\nmetrics that holistically describe a network. The analysis phase completes the\ncore functionality of the framework by linking our new metrics to the overall\nnetwork performance. The tuning layer augments this core with algorithms that\naim at automatically guiding networks toward desired conditions. In order to\nmaximize the impact of our ideas, the proposed approach is rooted in relevant,\nnear-future architectures and use cases in 5G networks, i.e., Internet of\nThings (IoT) and self-organizing cellular networks. \n\n"}
{"id": "1711.00339", "contents": "Title: On Spectral Analysis of the Internet Delay Space and Detecting Anomalous\n  Routing Paths Abstract: Latency is one of the most critical performance metrics for a wide range of\napplications. Therefore, it is important to understand the underlying\nmechanisms that give rise to the observed latency values and diagnose the ones\nthat are unexpectedly high. In this paper, we study the Internet delay space\nvia robust principal component analysis (RPCA). Using RPCA, we show that the\ndelay space, i.e. the matrix of measured round trip times between end hosts,\ncan be decomposed into two components - the expected latency between end hosts\nwith respect to the current state of the Internet and the inflation on the\npaths between the end hosts. Using this decomposition, first we study the\nwell-known low-dimensionality phenomena of the delay space and ask what\nproperties of the end hosts define the dimensions. Second, using the\ndecomposition, we develop a filtering method to detect the paths which\nexperience unexpected latencies and identify routing anomalies. We show that\nour filter successfully identifies an anomalous route even when its observed\nlatency is not obviously high in magnitude. \n\n"}
{"id": "1711.00973", "contents": "Title: Energy-Aware Virtual Machine Management in Inter-datacenter Networks\n  over Elastic Optical Infrastructure Abstract: Datacenters (DCs), deployed in a large scale to support the ever increasing\ndemand for data processing applications, consume tremendous energy. Powering\nDCs with renewable energy can effectively reduce the brown energy consumption.\nOwing to geographically distributed deployment of DCs, the renewable energy\ngeneration and the data processing demands usually vary in different DCs.\nMigrating virtual machines (VMs) among DCs according to the availability of\nrenewable energy helps match the energy demands and the renewable energy\ngeneration in DCs, and thus maximizes the utilization of renewable energy. We\nfirst elicit the renewable energy-aware inter-datacenter (inter-DC) VM\nmigration problem in an inter-DC network over the elastic optical\ninfrastructure, present it as a many-manycast communications problem, and then\nformulate it as an integer linear programming problem. The objective is to\nminimize the total cost of the brown energy consumption of DCs in such inter-DC\nnetwork via VM migration. We use CVX and Gurobi to solve this problem for small\nnetwork configurations, and we propose a few heuristic algorithms that\napproximate the optimal solution for large network configurations. Through\nextensive simulations, we show that the proposed algorithms, by migrating VM\namong DCs, can reduce up to 19.7% cost of the brown energy consumption. \n\n"}
{"id": "1711.01938", "contents": "Title: Single-Carrier Modulation versus OFDM for Millimeter-Wave Wireless MIMO Abstract: This paper presents results on the achievable spectral efficiency and on the\nenergy efficiency for a wireless multiple-input-multiple-output (MIMO) link\noperating at millimeter wave frequencies (mmWave) in a typical 5G scenario. Two\ndifferent single-carrier modem schemes are considered, i.e., a traditional\nmodulation scheme with linear equalization at the receiver, and a\nsingle-carrier modulation with cyclic prefix, frequency-domain equalization and\nFFT-based processing at the receiver; these two schemes are compared with a\nconventional MIMO-OFDM transceiver structure. Our analysis jointly takes into\naccount the peculiar characteristics of MIMO channels at mmWave frequencies,\nthe use of hybrid (analog-digital) pre-coding and post-coding beamformers, the\nfinite cardinality of the modulation structure, and the non-linear behavior of\nthe transmitter power amplifiers. Our results show that the best performance is\nachieved by single-carrier modulation with time-domain equalization, which\nexhibits the smallest loss due to the non-linear distortion, and whose\nperformance can be further improved by using advanced equalization schemes.\nResults also confirm that performance gets severely degraded when the link\nlength exceeds 90-100 meters and the transmit power falls below 0 dBW. \n\n"}
{"id": "1711.02805", "contents": "Title: The (thin) Bridges of AS Connectivity: Measuring Dependency using AS\n  Hegemony Abstract: Inter-domain routing is a crucial part of the Internet designed for arbitrary\npolicies, economical models, and topologies. This versatility translates into a\nsubstantially complex system that is hard to comprehend. Monitoring the\ninter-domain routing infrastructure is however essential for understanding the\ncurrent state of the Internet and improving it. In this paper we design a\nmethodology to answer two simple questions: Which are the common transit\nnetworks used to reach a certain AS? How much does this AS depends on these\ntransit networks? To answer these questions we digest AS paths advertised with\nthe Border Gateway Protocol (BGP) into AS graphs and measure node centrality,\nthat is the likelihood of an AS to lie on paths between two other ASes. Our\nproposal relies solely on the AS hegemony metric, a new way to quantify node\ncentrality while taking into account the bias towards the partial view offered\nby BGP. Our analysis using 14 years of BGP data refines our knowledge on\nInternet flattening but also exhibits the consolidated position of tier-1\nnetworks in today's IPv4 and IPv6 Internet. We also study the connectivity to\ntwo content providers (Google and Akamai) and investigate the AS dependency of\nnetworks hosting DNS root servers. These case studies emphasize the benefits of\nthe proposed method to assist ISPs in planning and assessing infrastructure\ndeployment. \n\n"}
{"id": "1711.02833", "contents": "Title: Traffic Prediction Based on Random Connectivity in Deep Learning with\n  Long Short-Term Memory Abstract: Traffic prediction plays an important role in evaluating the performance of\ntelecommunication networks and attracts intense research interests. A\nsignificant number of algorithms and models have been put forward to analyse\ntraffic data and make prediction. In the recent big data era, deep learning has\nbeen exploited to mine the profound information hidden in the data. In\nparticular, Long Short-Term Memory (LSTM), one kind of Recurrent Neural Network\n(RNN) schemes, has attracted a lot of attentions due to its capability of\nprocessing the long-range dependency embedded in the sequential traffic data.\nHowever, LSTM has considerable computational cost, which can not be tolerated\nin tasks with stringent latency requirement. In this paper, we propose a deep\nlearning model based on LSTM, called Random Connectivity LSTM (RCLSTM).\nCompared to the conventional LSTM, RCLSTM makes a notable breakthrough in the\nformation of neural network, which is that the neurons are connected in a\nstochastic manner rather than full connected. So, the RCLSTM, with certain\nintrinsic sparsity, have many neural connections absent (distinguished from the\nfull connectivity) and which leads to the reduction of the parameters to be\ntrained and the computational cost. We apply the RCLSTM to predict traffic and\nvalidate that the RCLSTM with even 35% neural connectivity still shows a\nsatisfactory performance. When we gradually add training samples, the\nperformance of RCLSTM becomes increasingly closer to the baseline LSTM.\nMoreover, for the input traffic sequences of enough length, the RCLSTM exhibits\neven superior prediction accuracy than the baseline LSTM. \n\n"}
{"id": "1711.03906", "contents": "Title: D-SLATS: Distributed Simultaneous Localization and Time Synchronization Abstract: Through the last decade, we have witnessed a surge of Internet of Things\n(IoT) devices, and with that a greater need to choreograph their actions across\nboth time and space. Although these two problems, namely time synchronization\nand localization, share many aspects in common, they are traditionally treated\nseparately or combined on centralized approaches that results in an ineffcient\nuse of resources, or in solutions that are not scalable in terms of the number\nof IoT devices. Therefore, we propose D-SLATS, a framework comprised of three\ndifferent and independent algorithms to jointly solve time synchronization and\nlocalization problems in a distributed fashion. The First two algorithms are\nbased mainly on the distributed Extended Kalman Filter (EKF) whereas the third\none uses optimization techniques. No fusion center is required, and the devices\nonly communicate with their neighbors. The proposed methods are evaluated on\ncustom Ultra-Wideband communication Testbed and a quadrotor, representing a\nnetwork of both static and mobile nodes. Our algorithms achieve up to three\nmicroseconds time synchronization accuracy and 30 cm localization error. \n\n"}
{"id": "1711.05456", "contents": "Title: Statistical Approaches for Initial Access in mmWave 5G Systems Abstract: mmWave communication systems overcome high attenuation by using multiple\nantennas at both the transmitter and the receiver to perform beamforming. Upon\nentrance of a user equipment (UE) into a cell a scanning procedure must be\nperformed by the base station in order to find the UE, in what is known as\ninitial access (IA) procedure. In this paper we start from the observation that\nUEs are more likely to enter from some directions than from others, as they\ntypically move along streets, while other movements are impossible due to the\npresence of obstacles. Moreover, users are entering with a given time\nstatistics, for example described by inter-arrival times. In this context we\npropose scanning strategies for IA that take into account the entrance\nstatistics. In particular, we propose two approaches: a memory-less random\nillumination (MLRI) algorithm and a statistic and memory-based illumination\n(SMBI) algorithm. The MLRI algorithm scans a random sector in each slot, based\non the statistics of sector entrance, without memory. The SMBI algorithm\ninstead scans sectors in a deterministic sequence selected according to the\nstatistics of sector entrance and time of entrance, and taking into account the\nfact that the user has not yet been discovered (thus including memory). We\nassess the performance of the proposed methods in terms of average discovery\ntime. \n\n"}
{"id": "1711.05855", "contents": "Title: Passive Crowd Speed Estimation in Adjacent Regions With Minimal WiFi\n  Sensing Abstract: In this paper, we propose a methodology for estimating the crowd speed using\nWiFi devices without relying on people to carry any device. Our approach not\nonly enables speed estimation in the region where WiFi links are, but also in\nthe adjacent possibly WiFi-free regions. More specifically, we use a pair of\nWiFi links in one region, whose RSSI measurements are then used to estimate the\ncrowd speed, not only in this region, but also in adjacent WiFi-free regions.\nWe first prove how the cross-correlation and the probability of crossing the\ntwo links implicitly carry key information about the pedestrian speeds and\ndevelop a mathematical model to relate them to pedestrian speeds. We then\nvalidate our approach with 108 experiments, in both indoor and outdoor, where\nup to 10 people walk in two adjacent areas, with variety of speeds per region,\nshowing that our framework can accurately estimate these speeds with only a\npair of WiFi links in one region. For instance, the NMSE over all experiments\nis 0.18. We also evaluate our framework in a museum-type setting and estimate\nthe popularity of different exhibits. We finally run experiments in an aisle in\nCostco, estimating key attributes of buyers' behaviors. \n\n"}
{"id": "1711.06154", "contents": "Title: Reliable Video Streaming over mmWave with Multi Connectivity and Network\n  Coding Abstract: The next generation of multimedia applications will require the\ntelecommunication networks to support a higher bitrate than today, in order to\ndeliver virtual reality and ultra-high quality video content to the users. Most\nof the video content will be accessed from mobile devices, prompting the\nprovision of very high data rates by next generation (5G) cellular networks. A\npossible enabler in this regard is communication at mmWave frequencies, given\nthe vast amount of available spectrum that can be allocated to mobile users;\nhowever, the harsh propagation environment at such high frequencies makes it\nhard to provide a reliable service. This paper presents a reliable video\nstreaming architecture for mmWave networks, based on multi connectivity and\nnetwork coding, and evaluates its performance using a novel combination of the\nns-3 mmWave module, real video traces and the network coding library Kodo. The\nresults show that it is indeed possible to reliably stream video over cellular\nmmWave links, while the combination of multi connectivity and network coding\ncan support high video quality with low latency. \n\n"}
{"id": "1711.08045", "contents": "Title: Standards for enabling heterogeneous IaaS cloud federations Abstract: Technology market is continuing a rapid growth phase where different resource\nproviders and Cloud Management Frameworks are positioning to provide ad-hoc\nsolutions -in terms of management interfaces, information discovery or billing-\ntrying to differentiate from competitors but that as a result remain\nincompatible between them when addressing more complex scenarios like federated\nclouds. Grasping interoperability problems present in current infrastructures\nis then a must-do, tackled by studying how existing and emerging standards\ncould enhance user experience in the cloud ecosystem. In this paper we will\nreview the current open challenges in Infrastructure as a Service cloud\ninteroperability and federation, as well as point to the potential standards\nthat should alleviate these problems. \n\n"}
{"id": "1711.08407", "contents": "Title: Multi-tier Drone Architecture for 5G/B5G Cellular Networks: Challenges,\n  Trends, and Prospects Abstract: Drones (or unmanned aerial vehicles [UAVs]) are expected to be an important\ncomponent of fifth generation (5G)/beyond 5G (B5G) cellular architectures that\ncan potentially facilitate wireless broadcast or point-to-multipoint\ntransmissions. The distinct features of various drones such as the maximum\noperational altitude, communication, coverage, computation, and endurance impel\nthe use of a multi-tier architecture for future drone-cell networks. In this\ncontext, this article focuses on investigating the feasibility of multi-tier\ndrone network architecture over traditional single-tier drone networks and\nidentifying the scenarios in which drone networks can potentially complement\nthe traditional RF-based terrestrial networks. We first identify the challenges\nassociated with multi-tier drone networks as well as drone-assisted cellular\nnetworks. We then review the existing state-of-the-art innovations in drone\nnetworks and drone-assisted cellular networks. We then investigate the\nperformance of a multi-tier drone network in terms of spectral efficiency of\ndownlink transmission while illustrating the optimal intensity and altitude of\ndrones in different tiers numerically. Our results demonstrate the specific\nnetwork load conditions (i.e., ratio of user intensity and base station\nintensity) where deployment of drones can be beneficial (in terms of spectral\nefficiency of downlink transmission) for conventional terrestrial cellular\nnetworks. \n\n"}
{"id": "1711.09012", "contents": "Title: Mobile Edge Computation Offloading Using Game Theory and Reinforcement\n  Learning Abstract: Due to the ever-increasing popularity of resource-hungry and\ndelay-constrained mobile applications, the computation and storage capabilities\nof remote cloud has partially migrated towards the mobile edge, giving rise to\nthe concept known as Mobile Edge Computing (MEC). While MEC servers enjoy the\nclose proximity to the end-users to provide services at reduced latency and\nlower energy costs, they suffer from limitations in computational and radio\nresources, which calls for fair efficient resource management in the MEC\nservers. The problem is however challenging due to the ultra-high density,\ndistributed nature, and intrinsic randomness of next generation wireless\nnetworks. In this article, we focus on the application of game theory and\nreinforcement learning for efficient distributed resource management in MEC, in\nparticular, for computation offloading. We briefly review the cutting-edge\nresearch and discuss future challenges. Furthermore, we develop a\ngame-theoretical model for energy-efficient distributed edge server activation\nand study several learning techniques. Numerical results are provided to\nillustrate the performance of these distributed learning techniques. Also, open\nresearch issues in the context of resource management in MEC servers are\ndiscussed. \n\n"}
{"id": "1711.09690", "contents": "Title: Real-Time Fair Resource Allocation in Distributed Software Defined\n  Networks Abstract: The performance of computer networks relies on how bandwidth is shared among\ndifferent flows. Fair resource allocation is a challenging problem particularly\nwhen the flows evolve over time.To address this issue, bandwidth sharing\ntechniques that quickly react to the traffic fluctuations are of interest,\nespecially in large scale settings with hundreds of nodes and thousands of\nflows. In this context, we propose a distributed algorithm that tackles the\nfair resource allocation problem in a distributed SDN control architecture. Our\nalgorithm continuously generates a sequence of resource allocation solutions\nconverging to the fair allocation while always remaining feasible, a property\nthat standard primal-dual decomposition methods often lack. Thanks to the\ndistribution of all computer intensive operations, we demonstrate that we can\nhandle large instances in real-time. \n\n"}
{"id": "1711.10102", "contents": "Title: A Game-theoretic Framework for Revenue Sharing in Edge-Cloud Computing\n  System Abstract: We introduce a game-theoretic framework to ex- plore revenue sharing in an\nEdge-Cloud computing system, in which computing service providers at the edge\nof the Internet (edge providers) and computing service providers at the cloud\n(cloud providers) co-exist and collectively provide computing resources to\nclients (e.g., end users or applications) at the edge. Different from\ntraditional cloud computing, the providers in an Edge-Cloud system are\nindependent and self-interested. To achieve high system-level efficiency, the\nmanager of the system adopts a task distribution mechanism to maximize the\ntotal revenue received from clients and also adopts a revenue sharing mechanism\nto split the received revenue among computing servers (and hence service\nproviders). Under those system-level mechanisms, service providers attempt to\ngame with the system in order to maximize their own utilities, by strategically\nallocating their resources (e.g., computing servers).\n  Our framework models the competition among the providers in an Edge-Cloud\nsystem as a non-cooperative game. Our simulations and experiments on an\nemulation system have shown the existence of Nash equilibrium in such a game.\nWe find that revenue sharing mechanisms have a significant impact on the\nsystem-level efficiency at Nash equilibria, and surprisingly the revenue\nsharing mechanism based directly on actual contributions can result in\nsignificantly worse system efficiency than Shapley value sharing mechanism and\nOrtmann proportional sharing mechanism. Our framework provides an effective\neconomics approach to understanding and designing efficient Edge-Cloud\ncomputing systems. \n\n"}
{"id": "1712.01905", "contents": "Title: Simulating Opportunistic Networks: Survey and Future Directions Abstract: Simulation is one of the most powerful tools we have for evaluating the\nperformance of Opportunistic Networks. In this survey, we focus on available\ntools and models, compare their performance and precision and experimentally\nshow the scalability of different simulators. We also perform a gap analysis of\nstate-of-the-art Opportunistic Network simulations and sketch out possible\nfurther development and lines of research. This survey is targeted at students\nstarting work and research in this area while also serving as a valuable source\nof information for experienced researchers. \n\n"}
{"id": "1712.01990", "contents": "Title: A Scalable Deep Neural Network Architecture for Multi-Building and\n  Multi-Floor Indoor Localization Based on Wi-Fi Fingerprinting Abstract: One of the key technologies for future large-scale location-aware services\ncovering a complex of multi-story buildings --- e.g., a big shopping mall and a\nuniversity campus --- is a scalable indoor localization technique. In this\npaper, we report the current status of our investigation on the use of deep\nneural networks (DNNs) for scalable building/floor classification and\nfloor-level position estimation based on Wi-Fi fingerprinting. Exploiting the\nhierarchical nature of the building/floor estimation and floor-level\ncoordinates estimation of a location, we propose a new DNN architecture\nconsisting of a stacked autoencoder for the reduction of feature space\ndimension and a feed-forward classifier for multi-label classification of\nbuilding/floor/location, on which the multi-building and multi-floor indoor\nlocalization system based on Wi-Fi fingerprinting is built. Experimental\nresults for the performance of building/floor estimation and floor-level\ncoordinates estimation of a given location demonstrate the feasibility of the\nproposed DNN-based indoor localization system, which can provide near\nstate-of-the-art performance using a single DNN, for the implementation with\nlower complexity and energy consumption at mobile devices. \n\n"}
{"id": "1712.02141", "contents": "Title: Selective Jamming of LoRaWAN using Commodity Hardware Abstract: Long range, low power networks are rapidly gaining acceptance in the Internet\nof Things (IoT) due to their ability to economically support long-range sensing\nand control applications while providing multi-year battery life. LoRa is a key\nexample of this new class of network and is being deployed at large scale in\nseveral countries worldwide. As these networks move out of the lab and into the\nreal world, they expose a large cyber-physical attack surface. Securing these\nnetworks is therefore both critical and urgent. This paper highlights security\nissues in LoRa and LoRaWAN that arise due to the choice of a robust but slow\nmodulation type in the protocol. We exploit these issues to develop a suite of\npractical attacks based around selective jamming. These attacks are conducted\nand evaluated using commodity hardware. The paper concludes by suggesting a\nrange of countermeasures that can be used to mitigate the attacks. \n\n"}
{"id": "1712.03038", "contents": "Title: Shrewd Selection Speeds Surfing: Use Smart EXP3! Abstract: In this paper, we explore the use of multi-armed bandit online learning\ntechniques to solve distributed resource selection problems. As an example, we\nfocus on the problem of network selection. Mobile devices often have several\nwireless networks at their disposal. While choosing the right network is vital\nfor good performance, a decentralized solution remains a challenge. The\nimpressive theoretical properties of multi-armed bandit algorithms, like EXP3,\nsuggest that it should work well for this type of problem. Yet, its real-word\nperformance lags far behind. The main reasons are the hidden cost of switching\nnetworks and its slow rate of convergence. We propose Smart EXP3, a novel\nbandit-style algorithm that (a) retains the good theoretical properties of\nEXP3, (b) bounds the number of switches, and (c) yields significantly better\nperformance in practice. We evaluate Smart EXP3 using simulations, controlled\nexperiments, and real-world experiments. Results show that it stabilizes at the\noptimal state, achieves fairness among devices and gracefully deals with\ntransient behaviors. In real world experiments, it can achieve 18% faster\ndownload over alternate strategies. We conclude that multi-armed bandit\nalgorithms can play an important role in distributed resource selection\nproblems, when practical concerns, such as switching costs and convergence\ntime, are addressed. \n\n"}
{"id": "1712.04201", "contents": "Title: On the Energy-Efficient Deployment for Ultra-Dense Heterogeneous\n  Networks with NLoS and LoS Transmissions Abstract: We investigate network performance of ultra-dense heterogeneous networks\n(HetNets) and study the maximum energy-efficient base station (BS) deployment\nincorporating probabilistic non-line-of-sight (NLoS) and line-of-sight (LoS)\ntransmissions. First, we develop an analytical framework with the maximum\ninstantaneous received power (MIRP) and the maximum average received power\n(MARP) association schemes to model the coverage probability and related\nperformance metrics, e.g., the potential throughput (PT) and the energy\nefficiency (EE). Second, we formulate two optimization problems to achieve the\nmaximum energy-efficient deployment solution with specific service criteria.\nSimulation results show that there are tradeoffs among the coverage\nprobability, the total power consumption, and the EE. To be specific, the\nmaximum coverage probability with ideal power consumption is superior to that\nwith practical power consumption when the total power constraint is small and\ninferior to that with practical power consumption when the total power\nconstraint becomes large. Moreover, the maximum EE is a decreasing function\nwith respect to the coverage probability constraint. \n\n"}
{"id": "1712.04301", "contents": "Title: Deep Learning for IoT Big Data and Streaming Analytics: A Survey Abstract: In the era of the Internet of Things (IoT), an enormous amount of sensing\ndevices collect and/or generate various sensory data over time for a wide range\nof fields and applications. Based on the nature of the application, these\ndevices will result in big or fast/real-time data streams. Applying analytics\nover such data streams to discover new information, predict future insights,\nand make control decisions is a crucial process that makes IoT a worthy\nparadigm for businesses and a quality-of-life improving technology. In this\npaper, we provide a thorough overview on using a class of advanced machine\nlearning techniques, namely Deep Learning (DL), to facilitate the analytics and\nlearning in the IoT domain. We start by articulating IoT data characteristics\nand identifying two major treatments for IoT data from a machine learning\nperspective, namely IoT big data analytics and IoT streaming data analytics. We\nalso discuss why DL is a promising approach to achieve the desired analytics in\nthese types of data and applications. The potential of using emerging DL\ntechniques for IoT data analytics are then discussed, and its promises and\nchallenges are introduced. We present a comprehensive background on different\nDL architectures and algorithms. We also analyze and summarize major reported\nresearch attempts that leveraged DL in the IoT domain. The smart IoT devices\nthat have incorporated DL in their intelligence background are also discussed.\nDL implementation approaches on the fog and cloud centers in support of IoT\napplications are also surveyed. Finally, we shed light on some challenges and\npotential directions for future research. At the end of each section, we\nhighlight the lessons learned based on our experiments and review of the recent\nliterature. \n\n"}
{"id": "1712.04687", "contents": "Title: Can Balloons Produce Li-Fi? A Disaster Management Perspective Abstract: Natural calamities and disasters disrupt the conventional communication\nsetups and the wireless bandwidth becomes constrained. A safe and\ncost-effective solution for communication and data access in such scenarios is\nlong needed. Light-Fidelity (Li-Fi) which promises wireless access to data at\nhigh speeds using visible light can be a good option. Visible light being safe\nto use for wireless access in such affected environments also provides\nillumination. Importantly, when a Li-Fi unit is attached to an air balloon and\na network of such Li-Fi balloons are coordinated to form a Li-Fi balloon\nnetwork, data can be accessed anytime and anywhere required and hence many\nlives can be tracked and saved. We propose this idea of a Li-Fi balloon and\ngive an overview of its design using the Philips Li-Fi hardware. Further, we\npropose the concept of a balloon network and coin it with an acronym, the\nLiBNet. We consider the balloons to be arranged as a homogeneous Poisson point\nprocess in the LiBNet and we derive the mean co-channel interference for such\nan arrangement. \n\n"}
{"id": "1712.04804", "contents": "Title: Ambient Backscatter Communications: A Contemporary Survey Abstract: Recently, ambient backscatter communications has been introduced as a\ncutting-edge technology which enables smart devices to communicate by utilizing\nambient radio frequency (RF) signals without requiring active RF transmission.\nThis technology is especially effective in addressing communication and energy\nefficiency problems for low-power communications systems such as sensor\nnetworks. It is expected to realize numerous Internet-of-Things (IoT)\napplications. Therefore, this paper aims to provide a contemporary and\ncomprehensive literature review on fundamentals, applications, challenges, and\nresearch efforts/progress of ambient backscatter communications. In particular,\nwe first present fundamentals of backscatter communications and briefly review\nbistatic backscatter communications systems. Then, the general architecture,\nadvantages, and solutions to address existing issues and limitations of ambient\nbackscatter communications systems are discussed. Additionally, emerging\napplications of ambient backscatter communications are highlighted. Finally, we\noutline some open issues and future research directions. \n\n"}
{"id": "1712.05004", "contents": "Title: Power Control in UAV-Supported Ultra Dense Networks: Communications,\n  Caching, and Energy Transfer Abstract: By means of network densification, ultra dense networks (UDNs) can\nefficiently broaden the network coverage and enhance the system throughput. In\nparallel, unmanned aerial vehicles (UAVs) communications and networking have\nattracted increasing attention recently due to their high agility and numerous\napplications. In this article, we present a vision of UAV-supported UDNs.\nFirstly, we present four representative scenarios to show the broad\napplications of UAV-supported UDNs in communications, caching and energy\ntransfer. Then, we highlight the efficient power control in UAV-supported UDNs\nby discussing the main design considerations and methods in a comprehensive\nmanner. Furthermore, we demonstrate the performance superiority of\nUAV-supported UDNs via case study simulations, compared to traditional fixed\ninfrastructure based networks. In addition, we discuss the dominating technical\nchallenges and open issues ahead. \n\n"}
{"id": "1712.05457", "contents": "Title: 60 GHz Blockage Study Using Phased Arrays Abstract: The millimeter wave (mmWave) frequencies offer the potential for enormous\ncapacity wireless links. However, designing robust communication systems at\nthese frequencies requires that we understand the channel dynamics over both\ntime and space: mmWave signals are extremely vulnerable to blocking and the\nchannel can thus rapidly appear and disappear with small movement of obstacles\nand reflectors. In rich scattering environments, different paths may experience\ndifferent blocking trajectories and understanding these multi-path blocking\ndynamics is essential for developing and assessing beamforming and\nbeam-tracking algorithms. This paper presents the design and experimental\nresults of a novel measurement system which uses phased arrays to perform\nmmWave dynamic channel measurements. Specifically, human blockage and its\neffects across multiple paths are investigated with only several microseconds\nbetween successive measurements. From these measurements we develop a modeling\ntechnique which uses low-rank tensor factorization to separate the available\npaths so that their joint statistics can be understood. \n\n"}
{"id": "1712.05677", "contents": "Title: Timely-Throughput Optimal Scheduling with Prediction Abstract: Motivated by the increasing importance of providing delay-guaranteed services\nin general computing and communication systems, and the recent wide adoption of\nlearning and prediction in network control, in this work, we consider a general\nstochastic single-server multi-user system and investigate the fundamental\nbenefit of predictive scheduling in improving timely-throughput, being the rate\nof packets that are delivered to destinations before their deadlines. By\nadopting an error rate-based prediction model, we first derive a Markov\ndecision process (MDP) solution to optimize the timely-throughput objective\nsubject to an average resource consumption constraint. Based on a packet-level\ndecomposition of the MDP, we explicitly characterize the optimal scheduling\npolicy and rigorously quantify the timely-throughput improvement due to\npredictive-service, which scales as\n$\\Theta(p\\left[C_{1}\\frac{(a-a_{\\max}q)}{p-q}\\rho^{\\tau}+C_{2}(1-\\frac{1}{p})\\right](1-\\rho^{D}))$,\nwhere $a, a_{\\max}, \\rho\\in(0, 1), C_1>0, C_2\\ge0$ are constants, $p$ is the\ntrue-positive rate in prediction, $q$ is the false-negative rate, $\\tau$ is the\npacket deadline and $D$ is the prediction window size. We also conduct\nextensive simulations to validate our theoretical findings. Our results provide\nnovel insights into how prediction and system parameters impact performance and\nprovide useful guidelines for designing predictive low-latency control\nalgorithms. \n\n"}
{"id": "1712.06634", "contents": "Title: Better Algorithms for Hybrid Circuit and Packet Switching in Data\n  Centers Abstract: Hybrid circuit and packet switching for data center networking (DCN) has\nreceived considerable research attention recently. A hybrid-switched DCN\nemploys a much faster circuit switch that is reconfigurable with a nontrivial\ncost, and a much slower packet switch that is reconfigurable with no cost, to\ninterconnect its racks of servers. The research problem is, given a traffic\ndemand matrix (between the racks), how to compute a good circuit switch\nconfiguration schedule so that the vast majority of the traffic demand is\nremoved by the circuit switch, leaving a remaining demand matrix that contains\nonly small elements for the packet switch to handle. In this paper, we propose\ntwo new hybrid switch scheduling algorithms under two different scheduling\nconstraints. Our first algorithm, called 2-hop Eclipse, strikes a much better\ntradeoff between the resulting performance (of the hybrid switch) and the\ncomputational complexity (of the algorithm) than the state of the art solution\nEclipse/Eclipse++. Our second algorithm, called BFF (best first fit), is the\nfirst hybrid switching solution that exploits the potential partial\nreconfiguration capability of the circuit switch for performance gains. \n\n"}
{"id": "1712.07021", "contents": "Title: Cache-Aided Private Information Retrieval with Partially Known Uncoded\n  Prefetching: Fundamental Limits Abstract: We consider the problem of private information retrieval (PIR) from $N$\nnon-colluding and replicated databases, when the user is equipped with a cache\nthat holds an uncoded fraction $r$ of the symbols from each of the $K$ stored\nmessages in the databases. This model operates in a two-phase scheme, namely,\nthe prefetching phase where the user acquires side information and the\nretrieval phase where the user privately downloads the desired message. In the\nprefetching phase, the user receives $\\frac{r}{N}$ uncoded fraction of each\nmessage from the $n$th database. This side information is known only to the\n$n$th database and unknown to the remaining databases, i.e., the user possesses\n\\emph{partially known} side information. We investigate the optimal normalized\ndownload cost $D^*(r)$ in the retrieval phase as a function of $K$, $N$, $r$.\nWe develop lower and upper bounds for the optimal download cost. The bounds\nmatch in general for the cases of very low caching ratio ($r \\leq\n\\frac{1}{N^{K-1}}$) and very high caching ratio ($r \\geq\n\\frac{K-2}{N^2-3N+KN}$). We fully characterize the optimal download cost\ncaching ratio tradeoff for $K=3$. For general $K$, $N$, and $r$, we show that\nthe largest gap between the achievability and the converse bounds is\n$\\frac{5}{32}$. \n\n"}
{"id": "1712.07740", "contents": "Title: Securing Edge Networks with Securebox Abstract: The number of mobile and IoT devices connected to home and enterprise\nnetworks is growing fast. These devices offer new services and experiences for\nthe users; however, they also present new classes of security threats\npertaining to data and device safety and user privacy. In this article, we\nfirst analyze the potential threats presented by these devices connected to\nedge networks. We then propose Securebox: a new cloud-driven, low cost\nSecurity-as-a-Service solution that applies Software-Defined Networking (SDN)\nto improve network monitoring, security and management. Securebox enables\nremote management of networks through a cloud security service (CSS) with\nminimal user intervention required. To reduce costs and improve the\nscalability, Securebox is based on virtualized middleboxes provided by CSS. Our\nproposal differs from the existing solutions by integrating the SDN and cloud\ninto a unified edge security solution, and by offering a collaborative\nprotection mechanism that enables rapid security policy dissemination across\nall connected networks in mitigating new threats or attacks detected by the\nsystem. We have implemented two Securebox prototypes, using a low-cost\nRaspberry-PI and off-the-shelf fanless PC. Our system evaluation has shown that\nSecurebox can achieve automatic network security and be deployed incrementally\nto the infrastructure with low management overhead. \n\n"}
{"id": "1712.08221", "contents": "Title: Tackling Contention Through Cooperation: A Distributed Federation in\n  LoRaWAN Space Abstract: Low-Power Wide Area Networks (LPWAN) play a key role in the IoT marketplace\nwherein LoRaWAN is considered a leading solution. Despite the traction of\nLoRaWAN, research shows that the current contention management mechanisms of\nLoRaWAN do not scale. This paper tackles contention on LoRaWAN by introducing\nFLIP, a fully distributed and open architecture for LoRaWAN that fundamentally\nrethinks how LoRa gateways should be managed and coordinated. FLIP transforms\nLoRa gateways into a federated network that provides inherent support for\nroaming while tackling contention using consensus-driven load balancing. FLIP\noffers identical security guarantees to LoRaWAN, is compatible with existing\ngateway hardware and requires no updates to end-device hardware or firmware.\nThese features ensure the practicality of FLIP and provide a path to its\nadoption. We evaluate the performance of FLIP in a large-scale real-world\ndeployment and demonstrate that FLIP delivers scalable roaming and improved\ncontention management in comparison to LoRaWAN. FLIP achieves these benefits\nwithin the resource constraints of conventional LoRa gateways and requires no\nserver hardware. \n\n"}
{"id": "1712.08768", "contents": "Title: Learning-Based Computation Offloading for IoT Devices with Energy\n  Harvesting Abstract: Internet of Things (IoT) devices can apply mobile-edge computing (MEC) and\nenergy harvesting (EH) to provide the satisfactory quality of experiences for\ncomputation intensive applications and prolong the battery lifetime. In this\narticle, we investigate the computation offloading for IoT devices with energy\nharvesting in wireless networks with multiple MEC devices such as base stations\nand access points, each with different computation resource and radio\ncommunication capability. We propose a reinforcement learning based computation\noffloading framework for an IoT device to choose the MEC device and determine\nthe offloading rate according to the current battery level, the previous radio\nbandwidth to each MEC device and the predicted amount of the harvested energy.\nA \"hotbooting\" Q-learning based computation offloading scheme is proposed for\nan IoT device to achieve the optimal offloading performance without being aware\nof the MEC model, the energy consumption and computation latency model. We also\npropose a fast deep Q-network (DQN) based offloading scheme, which combines the\ndeep learning and hotbooting techniques to accelerate the learning speed of\nQ-learning. We show that the proposed schemes can achieve the optimal\noffloading policy after sufficiently long learning time and provide their\nperformance bounds under two typical MEC scenarios. Simulations are performed\nfor IoT devices that use wireless power transfer to capture the ambient\nradio-frequency signals to charge the IoT batteries. Simulation results show\nthat the fast DQN-based offloading scheme reduces the energy consumption,\ndecreases the computation delay and the task drop ratio, and increases the\nutility of the IoT device in dynamic MEC, compared with the benchmark\nQ-learning based offloading. \n\n"}
{"id": "1712.09315", "contents": "Title: Who is Smarter? Intelligence Measure of Learning-based Cognitive Radios Abstract: Cognitive radio (CR) is considered as a key enabling technology for dynamic\nspectrum access to improve spectrum efficiency. Although the CR concept was\ninvented with the core idea of realizing cognition, the research on measuring\nCR cognitive capabilities and intelligence is largely open. Deriving the\nintelligence measure of CR not only can lead to the development of new CR\ntechnologies, but also makes it possible to better configure the networks by\nintegrating CRs with different cognitive capabilities. In this paper, for the\nfirst time, we propose a data-driven methodology to quantitatively measure the\nintelligence factors of the CR with learning capabilities. The basic idea of\nour methodology is to run various tests on the CR in different spectrum\nenvironments under different settings and obtain various performance data on\ndifferent metrics. Then we apply factor analysis on the performance data to\nidentify and quantize the intelligence factors and cognitive capabilities of\nthe CR. More specifically, we present a case study consisting of 144 different\ntypes of CRs. The CRs are different in terms of learning-based dynamic spectrum\naccess strategies, number of sensors, sensing accuracy, processing speed, and\nalgorithmic complexity. Five intelligence factors are identified for the CRs\nthrough our data analysis.We show that these factors comply well with the\nnature of the tested CRs, which validates the proposed intelligence measure\nmethodology. \n\n"}
{"id": "1801.00594", "contents": "Title: Dynamic Channel Bonding in Spatially Distributed High-Density WLANs Abstract: In this paper, we discuss the effects on throughput and fairness of dynamic\nchannel bonding (DCB) in spatially distributed high-density wireless local area\nnetworks (WLANs). First, we present an analytical framework based on\ncontinuous-time Markov networks (CTMNs) for depicting the behavior of different\nDCB policies in spatially distributed scenarios, where nodes are not required\nto be within the carrier sense range of each other. Then, we assess the\nperformance of DCB in high-density IEEE 802.11ac/ax WLANs by means of\nsimulations. We show that there may be critical interrelations among nodes in\nthe spatial domain - even if they are located outside the carrier sense range\nof each other - in a chain reaction manner. Results also reveal that, while\nalways selecting the widest available channel normally maximizes the individual\nlong-term throughput, it often generates unfair situations where other WLANs\nstarve. Moreover, we show that there are scenarios where DCB with stochastic\nchannel width selection improves the latter approach both in terms of\nindividual throughput and fairness. It follows that there is not a unique\noptimal DCB policy for every case. Instead, smarter bandwidth adaptation is\nrequired in the challenging scenarios of next-generation WLANs. \n\n"}
{"id": "1801.00831", "contents": "Title: Optimizing the Number of Fog Nodes for Cloud-Fog-Thing Networks Abstract: Going from theory to practice in fog networking raises the question of the\noptimum number of fog nodes that will be upgraded from the existing nodes. This\npaper finds the optimum number of fog nodes for a given total number of\nordinary nodes residing in the area of interest for different channel\nconditions. Determining the optimum number of fog nodes is quite beneficial,\nbecause it can strongly affect the SINR, and thus the average data rate and\ntransmission delay. The numerical results indicate that the average data rate\nincreases nearly an order of magnitude for an optimized number of fog nodes in\ncase of shadowing and fading. It is further shown that the optimum number of\nfog nodes does not increase in direct proportion to the increase in the total\nnumber of nodes. Furthermore, the optimum number of fog nodes decreases when\nchannels have high path loss exponents. These findings suggest that the fog\nnodes must be selected among those that have the highest computation capability\nfor densely deployed networks and high path loss exponents channels. \n\n"}
{"id": "1801.01108", "contents": "Title: Hybrid Scheduling in Heterogeneous Half- and Full-Duplex Wireless\n  Networks Abstract: Full-duplex (FD) wireless is an attractive communication paradigm with high\npotential for improving network capacity and reducing delay in wireless\nnetworks. Despite significant progress on the physical layer development, the\nchallenges associated with developing medium access control (MAC) protocols for\nheterogeneous networks composed of both legacy half-duplex (HD) and emerging FD\ndevices have not been fully addressed. Therefore, we focus on the design and\nperformance evaluation of scheduling algorithms for infrastructure-based\nheterogeneous HD-FD networks (composed of HD and FD users). We first show that\ncentralized Greedy Maximal Scheduling (GMS) is throughput-optimal in\nheterogeneous HD-FD networks. We propose the Hybrid-GMS (H-GMS) algorithm, a\ndistributed implementation of GMS that combines GMS and a queue-based\nrandom-access mechanism. We prove that H-GMS is throughput-optimal. Moreover,\nwe analyze the delay performance of H-GMS by deriving lower bounds on the\naverage queue length. We further demonstrate the benefits of upgrading HD nodes\nto FD nodes in terms of throughput gains for individual nodes and the whole\nnetwork. Finally, we evaluate the performance of H-GMS and its variants in\nterms of throughput, delay, and fairness between FD and HD users via extensive\nsimulations. We show that in heterogeneous HD-FD networks, H-GMS achieves\n16-30x better delay performance and improves fairness between HD and FD users\nby up to 50% compared with the fully decentralized Q-CSMA algorithm. \n\n"}
{"id": "1801.01516", "contents": "Title: Integrated NFV/SDN Architectures: A Systematic Literature Review Abstract: Network Functions Virtualization (NFV) and Software-Defined Networking (SDN)\nare new paradigms in the move towards open software and network hardware. While\nNFV aims to virtualize network functions and deploy them into general purpose\nhardware, SDN makes networks programmable by separating the control and data\nplanes. NFV and SDN are complementary technologies capable of providing one\nnetwork solution. SDN can provide connectivity between Virtual Network\nFunctions (VNFs) in a flexible and automated way, whereas NFV can use SDN as\npart of a service function chain. There are many studies designing NFV/SDN\narchitectures in different environments. Researchers have been trying to\naddress reliability, performance, and scalability problems using different\narchitectural designs. This Systematic Literature Review (SLR) focuses on\nintegrated NFV/SDN architectures, with the following goals: i) to investigate\nand provide an in-depth review of the state-of-the-art of NFV/SDN\narchitectures, ii) to synthesize their architectural designs, and iii) to\nidentify areas for further improvements. Broadly, this SLR will encourage\nresearchers to advance the current stage of development (i.e., the\nstate-of-the-practice) of integrated NFV/SDN architectures, and shed some light\non future research efforts and the challenges faced. \n\n"}
{"id": "1801.02344", "contents": "Title: Optimal Time Scheduling for Wireless-Powered Backscatter Communication\n  Networks Abstract: This letter introduces a novel wireless-powered backscatter communication\nsystem which allows sensors to utilize RF signals transmitted from a dedicated\nRF energy source to transmit data. In the proposed system, when the RF energy\nsource transmits RF signals, the sensors are able to backscatter the RF signals\nto transmit date to the gateway and/or harvest energy from the RF signals for\ntheir operations. By integrating backscattering and energy harvesting\ntechniques, we can optimize the network throughput of the system. In\nparticular, we first formulate the time scheduling problem for the system, and\nthen propose an optimal solution using convex optimization to maximize the\noverall network throughput. Numerical results show a significant throughput\ngain achieved by our proposed design over two other baseline schemes. \n\n"}
{"id": "1801.02609", "contents": "Title: Secure Beamforming in Full-Duplex SWIPT Systems With Loopback\n  Self-Interference Cancellation Abstract: Security is a critical issue in full duplex (FD) communication systems due to\nthe broadcast nature of wireless channels. In this paper, joint design of\ninformation and artificial noise beamforming vectors is proposed for the FD\nsimultaneous wireless information and power transferring (FD-SWIPT) systems\nwith loopback self-interference cancellation. To guarantee high security and\nenergy harvesting performance of the FD-SWIPT system, the proposed design is\nformulated as a secrecy rate maximization problem under energy transfer rate\nconstraints. Although the secrecy rate maximization problem is non-convex, we\nsolve it via semidefinite relaxation and a two-dimensional search. We prove the\noptimality of our proposed algorithm and demonstrate its performance via\nsimulations. \n\n"}
{"id": "1801.02741", "contents": "Title: Towards Stability Analysis of Data Transport Mechanisms: a Fluid Model\n  and an Application Abstract: The Transmission Control Protocol (TCP) utilizes congestion avoidance and\ncontrol mechanisms as a preventive measure against congestive collapse and as\nan adaptive measure in the presence of changing network conditions. The set of\navailable congestion control algorithms is diverse, and while many have been\nstudied from empirical and simulation perspectives, there is a notable lack of\nanalytical work for some variants. To gain more insight into the dynamics of\nthese algorithms, we: (1) propose a general modeling scheme consisting of a set\nof functional differential equations of retarded type (RFDEs) and of the\ncongestion window as a function of time; (2) apply this scheme to TCP Reno and\ndemonstrate its equivalence to a previous, well known model for TCP Reno; (3)\nshow an application of the new framework to the widely-deployed congestion\ncontrol algorithm TCP CUBIC, for which analytical models are few and limited;\nand (4) validate the model using simulations. Our modeling framework yields a\nfluid model for TCP CUBIC. From a theoretical analysis of this model, we\ndiscover that TCP CUBIC is locally uniformly asymptotically stable -- a\nproperty of the algorithm previously unknown. \n\n"}
{"id": "1801.04613", "contents": "Title: Software Defined Networks based Smart Grid Communication: A\n  Comprehensive Survey Abstract: The current power grid is no longer a feasible solution due to\never-increasing user demand of electricity, old infrastructure, and reliability\nissues and thus require transformation to a better grid a.k.a., smart grid\n(SG). The key features that distinguish SG from the conventional electrical\npower grid are its capability to perform two-way communication, demand side\nmanagement, and real time pricing. Despite all these advantages that SG will\nbring, there are certain issues which are specific to SG communication system.\nFor instance, network management of current SG systems is complex, time\nconsuming, and done manually. Moreover, SG communication (SGC) system is built\non different vendor specific devices and protocols. Therefore, the current SG\nsystems are not protocol independent, thus leading to interoperability issue.\nSoftware defined network (SDN) has been proposed to monitor and manage the\ncommunication networks globally. This article serves as a comprehensive survey\non SDN-based SGC. In this article, we first discuss taxonomy of advantages of\nSDNbased SGC.We then discuss SDN-based SGC architectures, along with case\nstudies. Our article provides an in-depth discussion on routing schemes for\nSDN-based SGC. We also provide detailed survey of security and privacy schemes\napplied to SDN-based SGC. We furthermore present challenges, open issues, and\nfuture research directions related to SDN-based SGC. \n\n"}
{"id": "1801.04964", "contents": "Title: The Future is Unlicensed: Coexistence in the Unlicensed Spectrum for 5G Abstract: 5G has to fulfill the requirements of ultra-dense, scalable, and customizable\nnetworks such as IoT while increasing spectrum and energy efficiency. Given the\ndiversity of envisaged applications and scenarios, one crucial property for 5G\nNew Radio (NR) is flexibility: flexible UL/DL allocation, bandwidths, or\nscalable transmission time interval, and most importantly operation at\ndifferent frequency bands. In particular, 5G should exploit the spectral\nopportunities in the unlicensed spectrum for expanding network capacity when\nand where needed. However, unlicensed bands pose the challenge of \"coexisting\nnetworks\", which mostly lack the means of communication for negotiation and\ncoordination. This deficiency is further exacerbated by the heterogeneity,\nmassive connectivity, and ubiquity of IoT systems and applications. Therefore,\n5G needs to provide mechanisms to coexist and even converge in the unlicensed\nbands. In that regard, WiFi, as the most prominent wireless technology in the\nunlicensed bands, is both a key enabler for boosting 5G capacity and competitor\nof 5G cellular networks for the shared unlicensed spectrum. In this work, we\ndescribe spectrum sharing in 5G and present key coexistence solutions, mostly\nin the context of WiFi. We also highlight the role of machine learning which is\nenvisaged to be critical for reaching coexistence and convergence goals by\nproviding the necessary intelligence and adaptation mechanisms. \n\n"}
{"id": "1801.05204", "contents": "Title: A Multi-Agent Neural Network for Dynamic Frequency Reuse in LTE Networks Abstract: Fractional Frequency Reuse techniques can be employed to address interference\nin mobile networks, improving throughput for edge users. There is a tradeoff\nbetween the coverage and overall throughput achievable, as interference\navoidance techniques lead to a loss in a cell's overall throughput, with\nspectrum efficiency decreasing with the fencing off of orthogonal resources. In\nthis paper we propose MANN, a dynamic multiagent frequency reuse scheme, where\nindividual agents in charge of cells control their configurations based on\ninput from neural networks. The agents' decisions are partially influenced by a\ncoordinator agent, which attempts to maximise a global metric of the network\n(e.g., cell-edge performance). Each agent uses a neural network to estimate the\nbest action (i.e., cell configuration) for its current environment setup, and\nattempts to maximise in turn a local metric, subject to the constraint imposed\nby the coordinator agent. Results show that our solution provides improved\nperformance for edge users, increasing the throughput of the bottom 5% of users\nby 22%, while retaining 95% of a network's overall throughput from the full\nfrequency reuse case. Furthermore, we show how our method improves on static\nfractional frequency reuse schemes. \n\n"}
{"id": "1801.05823", "contents": "Title: Device Caching for Network Offloading: Delay Minimization with Presence\n  of User Mobility Abstract: A delay-optimal caching problem (DOCP) in deviceto- device (D2D) networks\nwith moblity is modelled. The problem arises in the context of achieving\noffloading using device caching, and the offloading effect is represented by\nthe expected network load ratio (NLR) which is the percentage of data that has\nto be downloaded from the network. Compared with the related studies, this work\nconsiders minimizing delay with NLR guarantee in mobility scenarios. A lower\nbound of global optimum is derived, thus enabling performance benchmarking of\nany sub-optimal algorithm. For problem-solving, an effective search algorithm\n(ESA) is proposed based on the bound. Simulations are conducted to evaluate the\neffectiveness of the ESA algorithm. \n\n"}
{"id": "1801.06449", "contents": "Title: User Preference Learning Based Edge Caching for Fog Radio Access Network Abstract: In this paper, the edge caching problem in fog radio access network (F-RAN)\nis investigated. By maximizing the overall cache hit rate, the edge caching\noptimization problem is formulated to find the optimal policy. Content\npopularity in terms of time and space is considered from the perspective of\nregional users. We propose an online content popularity prediction algorithm by\nleveraging the content features and user preferences, and an offline user\npreference learning algorithm by using the {online gradient descent} (OGD)\nmethod and the {follow the (proximally) regularized leader} (FTRL-Proximal)\nmethod. Our proposed edge caching policy not only can promptly predict the\nfuture content popularity in an online fashion with low complexity, {but also}\ncan track the content popularity with spatial and temporal popularity dynamic\nin time without delay. Furthermore, we design two learning based edge caching\narchitectures. Moreover, we theoretically derive the upper bound of the\npopularity prediction error, the lower bound of the cache hit rate, and the\nregret bound of the overall cache hit rate of our proposed edge caching policy.\nSimulation results show that the overall cache hit rate of our proposed policy\nis superior to those of the traditional policies and asymptotically approaches\nthe optimal performance. \n\n"}
{"id": "1801.06619", "contents": "Title: Machine Learning Methods for User Positioning With Uplink RSS in\n  Distributed Massive MIMO Abstract: We consider a machine learning approach based on Gaussian process regression\n(GP) to position users in a distributed massive multiple-input multiple-output\n(MIMO) system with the uplink received signal strength (RSS) data. We focus on\nthe scenario where noise-free RSS is available for training, but only noisy RSS\nis available for testing purposes. To estimate the test user locations and\ntheir 2{\\sigma} error-bars, we adopt two state-of-the-art GP methods, namely,\nthe conventional GP (CGP) and the numerical approximation GP (NaGP) methods. We\nfind that the CGP method, which treats the noisy test RSS vectors as\nnoise-free, provides unrealistically small 2{\\sigma} error-bars on the\nestimated locations. To alleviate this concern, we derive the true predictive\ndistribution for the test user locations and then employ the NaGP method to\nnumerically approximate it as a Gaussian with the same first and second order\nmoments. We also derive a Bayesian Cramer-Rao lower bound (BCRLB) on the\nachievable root- mean-squared-error (RMSE) performance of the two GP methods.\nSimulation studies reveal that: (i) the NaGP method indeed provides realistic\n2{\\sigma} error-bars on the estimated locations, (ii) operation in massive MIMO\nregime improves the RMSE performance, and (iii) the achieved RMSE performances\nare very close to the derived BCRLB. \n\n"}
{"id": "1801.06623", "contents": "Title: Promises and Caveats of Uplink IoT Ultra-Dense Networks Abstract: In this paper, by means of simulations, we evaluate the uplink (UL)\nperformance of an Internet of Things (IoT) capable ultra-dense network (UDN) in\nterms of the coverage probability and the density of reliably working user\nequipments (UEs). From our study, we show the benefits and challenges that UL\nIoT UDNs will bring about in the future. In more detail, for a low-reliability\ncriterion, such as achieving a UL signal-to-interference-plus-noise ratio\n(SINR) above 0 dB, the density of reliably working UEs grows quickly with the\nnetwork densification, showing the potential of UL IoT UDNs. In contrast, for a\nhigh-reliability criterion, such as achieving a UL SINR above 10 dB, the\ndensity of reliably working UEs remains to be low in UDNs due to excessive\ninter-cell interference, which should be considered when operating UL IoT UDNs.\nMoreover, considering the existence of a non-zero antenna height difference\nbetween base stations (BSs) and UEs, the density of reliably working UEs could\neven decrease as we deploy more BSs. This calls for the usage of sophisticated\ninterference management schemes and/or beam steering/shaping technologies in UL\nIoT UDNs. \n\n"}
{"id": "1801.07472", "contents": "Title: Efficient 3D Aerial Base Station Placement Considering Users Mobility by\n  Reinforcement Learning Abstract: This paper considers an aerial base station (aerial-BS) assisted terrestrial\nnetwork where user mobility is taken into account. User movement changes the\nnetwork dynamically which may result in performance loss. To avoid this loss,\nguarantee a minimum quality-of-service (QoS) and possibly increase the QoS, we\nadd an aerial-BS to the network. For a fair comparison between the conventional\nterrestrial network and the aerial-BS assisted one, we keep the total number of\nBSs identical in both networks. Obtaining the best performance in such networks\nhighly depends on the optimal placement of the aerial-BS. To this end, an\nalgorithm which can rely on general and realistic assumptions and can decide\nwhere to go based on the past experiences is required. The proposed approach\nfor this goal is based on a discounted reward reinforcement learning which is\nknown as Q-learning. Simulation results show this method provides an effective\nplacement strategy which increases the QoS of wireless networks when it is\nneeded and promises to find the optimum position of the aerial-BS in discrete\nenvironments. \n\n"}
{"id": "1801.07614", "contents": "Title: Edge Computing Meets Millimeter-wave Enabled VR: Paving the Way to\n  Cutting the Cord Abstract: In this paper, a novel proactive computing and mmWave communication for\nultra-reliable and low latency wireless virtual reality (VR is proposed. By\nleveraging information about users' poses, proactive computing and caching are\nused to pre-compute and store users' HD video frames to minimize the computing\nlatency. Furthermore, multi-connectivity is exploited to ensure reliable mmWave\nlinks to deliver users' requested HD frames. The performance of the proposed\napproach is validated on a VR network serving an interactive gaming arcade,\nwhere dynamic and real-time rendering of HD video frames is needed and impulse\nactions of different players impact the content to be shown. Simulation results\nshow significant gains of up to $30\\%$ reduction in end-to-end delay and $50\\%$\nin the $90^{\\textrm{th}}$ percentile communication delay. \n\n"}
{"id": "1802.00521", "contents": "Title: Multipath Communication with Finite Sliding Window Network Coding for\n  Ultra-Reliability and Low Latency Abstract: We use random linear network coding (RLNC) based scheme for multipath\ncommunication in the presence of lossy links with different delay\ncharacteristics to obtain ultra-reliability and low latency. A sliding window\nversion of RLNC is proposed where the coded packets are generated using packets\nin a window size and are inserted among systematic packets in different paths.\nThe packets are scheduled in the paths in a round robin fashion proportional to\nthe data rates. We use finite encoding and decoding window size and do not rely\non feedback for closing the sliding window, unlike the previous work. Our\nimplementation of two paths with LTE and WiFi characteristics shows that the\nproposed sliding window scheme achieves better latency compared to the block\nRLNC code. It is also shown that the proposed scheme achieves low latency\ncommunication through multiple paths compared to the individual paths for\nbursty traffic by translating the throughput on both the paths into latency\ngain. \n\n"}
{"id": "1802.01471", "contents": "Title: Review of LiFi visible light communications : research and use cases Abstract: LiFi is a networked wireless communication technology transforming\nsolid-state indoor lighting into a backbone for information. The technology has\nreached maturity, with the first LiFi LED luminaire commercialized in 2016.\nReal life deployments with a variety of use cases, as well as staggering\nbandwidth improvements in the lab superior to 10 Gbps, hint to a luminous\nfuture for LiFi as a powerful complement or alternative to WiFi and 4G/5G. \n\n"}
{"id": "1802.03012", "contents": "Title: Resource Allocation in Heterogenous Full-duplex OFDMA Networks: Design\n  and Analysis Abstract: Recent studies indicate the feasibility of full-duplex (FD) bidirectional\nwireless communications. Due to its potential to increase the capacity,\nanalyzing the performance of a cellular network that contains full-duplex\ndevices is crucial. In this paper, we consider maximizing the weighted sum-rate\nof downlink and uplink of an FD heterogeneous OFDMA network where each cell\nconsists of an imperfect FD base-station (BS) and a mixture of half-duplex and\nimperfect full-duplex mobile users. To this end, first, the joint problem of\nsub-channel assignment and power allocation for a single cell network is\ninvestigated. Then, the proposed algorithms are extended for solving the\noptimization problem for an FD heterogeneous network in which intra-cell and\ninter-cell interferences are taken into account. Simulation results demonstrate\nthat in a single cell network, when all the users and the BSs are perfect FD\nnodes, the network throughput could be doubled. Otherwise, the performance\nimprovement is limited by the inter-cell interference, inter-node interference,\nand self-interference. We also investigate the effect of the percentage of FD\nusers on the network performance in both indoor and outdoor scenarios, and\nanalyze the effect of the self-interference cancellation capability of the FD\nnodes on the network performance. \n\n"}
{"id": "1802.04873", "contents": "Title: Random Linear Network Coding for 5G Mobile Video Delivery Abstract: An exponential increase in mobile video delivery will continue with the\ndemand for higher resolution, multi-view and large-scale multicast video\nservices. Novel fifth generation (5G) 3GPP New Radio (NR) standard will bring a\nnumber of new opportunities for optimizing video delivery across both 5G core\nand radio access networks. One of the promising approaches for video quality\nadaptation, throughput enhancement and erasure protection is the use of\npacket-level random linear network coding (RLNC). In this review paper, we\ndiscuss the integration of RLNC into the 5G NR standard, building upon the\nideas and opportunities identified in 4G LTE. We explicitly identify and\ndiscuss in detail novel 5G NR features that provide support for RLNC-based\nvideo delivery in 5G, thus pointing out to the promising avenues for future\nresearch. \n\n"}
{"id": "1802.07855", "contents": "Title: RT-DAP: A Real-Time Data Analytics Platform for Large-scale Industrial\n  Process Monitoring and Control Abstract: In most process control systems nowadays, process measurements are\nperiodically collected and archived in historians. Analytics applications\nprocess the data, and provide results offline or in a time period that is\nconsiderably slow in comparison to the performance of the manufacturing\nprocess. Along with the proliferation of Internet-of-Things (IoT) and the\nintroduction of \"pervasive sensors\" technology in process industries,\nincreasing number of sensors and actuators are installed in process plants for\npervasive sensing and control, and the volume of produced process data is\ngrowing exponentially. To digest these data and meet the ever-growing\nrequirements to increase production efficiency and improve product quality,\nthere needs to be a way to both improve the performance of the analytics system\nand scale the system to closely monitor a much larger set of plant resources.\nIn this paper, we present a real-time data analytics platform, called RT-DAP,\nto support large-scale continuous data analytics in process industries. RT-DAP\nis designed to be able to stream, store, process and visualize a large volume\nof realtime data flows collected from heterogeneous plant resources, and\nfeedback to the control system and operators in a realtime manner. A prototype\nof the platform is implemented on Microsoft Azure. Our extensive experiments\nvalidate the design methodologies of RT-DAP and demonstrate its efficiency in\nboth component and system levels. \n\n"}
{"id": "1802.08463", "contents": "Title: Multi-RATs Support to Improve V2X Communication Abstract: As the next generation of wireless system targets at providing a wider range\nof services with divergent QoS requirements, new applications will be enabled\nby the fifth generation (5G) network. Among the emerging applications,\nvehicle-to-everything (V2X) communication is an important use case targeted by\n5G to enable an improved traffic safety and traffic efficiency. Since the V2X\ncommunication requires a low end-to-end (E2E) latency and an ultra-high\nreliability, the legacy cellular networks can not meet the service requirement.\nIn this work, we inspect on the system performance of applying the LTE-Uu and\nPC5 interfaces to enable the V2X communication. With the LTE-Uu interface, one\nV2X data packet is transmitted through the cellular network infrastructure,\nwhile the PC5 interface facilitates the direct V2X communication without\ninvolving the network infrastructure in user-plane. In addition, due to the\nhigh reliability requirement, the application of a single V2X transmission\ntechnology can not meet the targets in some scenarios. Therefore, we also\npropose a multi-radio access technologies (multi-RATs) scheme where the data\npacket travels through both the LTE-Uu and PC5 interfaces to obtain a diversity\ngain. Last but not least, in order to derive the system performance, a system\nlevel simulator is implemented in this work. The numerical results provide us\ninsights on how the different technologies will perform in different scenarios\nand also validate the proposed multi-RATs scheme. \n\n"}
{"id": "1802.08776", "contents": "Title: Bandwidth Partitioning and Downlink Analysis in Millimeter Wave\n  Integrated Access and Backhaul for 5G Abstract: With the increasing network densification, it has become exceedingly\ndifficult to provide traditional fiber backhaul access to each cell site, which\nis especially true for small cell base stations (SBSs). The increasing maturity\nof millimeter wave (mm-wave) communication has opened up the possibility of\nproviding high-speed wireless backhaul to such cell sites. Since mm-wave is\nalso suitable for access links, the third generation partnership project (3GPP)\nis envisioning an integrated access and backhaul (IAB) architecture for the\nfifth generation (5G) cellular networks in which the same infrastructure and\nspectral resources will be used for both access and backhaul. In this paper, we\ndevelop an analytical framework for IAB-enabled cellular network using which\nits downlink rate coverage probability is accurately characterized. Using this\nframework, we study the performance of three backhaul bandwidth (BW) partition\nstrategies: 1) equal partition: when all SBSs obtain equal share of the\nbackhaul BW; 2) instantaneous load-based partition: when the backhaul BW share\nof an SBS is proportional to its instantaneous load; and 3) average load-based\npartition: when the backhaul BW share of an SBS is proportional to its average\nload. Our analysis shows that depending on the choice of the partition\nstrategy, there exists an optimal split of access and backhaul BW for which the\nrate coverage is maximized. Further, there exists a critical volume of\ncell-load (total number of users) beyond which the gains provided by the\nIAB-enabled network disappear and its performance converges to that of the\ntraditional macro-only network with no SBSs. \n\n"}
{"id": "1802.09815", "contents": "Title: Elmo: Source-Routed Multicast for Cloud Services Abstract: We present Elmo, a system that addresses the multicast scalability problem in\nmulti-tenant data centers. Modern cloud applications frequently exhibit\none-to-many communication patterns and, at the same time, require\nsub-millisecond latencies and high throughput. IP multicast can achieve these\nrequirements but has control- and data-plane scalability limitations that make\nit challenging to offer it as a service for hundreds of thousands of tenants,\ntypical of cloud environments. Tenants, therefore, must rely on unicast-based\napproaches (e.g., application-layer or overlay-based) to support multicast in\ntheir applications, imposing overhead on throughput and end host CPU\nutilization, with higher and unpredictable latencies.\n  Elmo scales network multicast by taking advantage of emerging programmable\nswitches and the unique characteristics of data-center networks; specifically,\nthe symmetric topology and short paths in a data center. Elmo encodes multicast\ngroup information inside packets themselves, reducing the need to store the\nsame information in network switches. In a three-tier data-center topology with\n27K hosts, Elmo supports a million multicast groups using a 325-byte packet\nheader, requiring as few as 1.1K multicast group-table entries on average in\nleaf switches, with a traffic overhead as low as 5% over ideal multicast. \n\n"}
{"id": "1802.10140", "contents": "Title: Towards a Socially Optimal Multi-Modal Routing Platform Abstract: The increasing rate of urbanization has added pressure on the already\nconstrained transportation networks in our communities. Ride-sharing platforms\nsuch as Uber and Lyft are becoming a more commonplace, particularly in urban\nenvironments. While such services may be deemed more convenient than riding\npublic transit due to their on-demand nature, reports show that they do not\nnecessarily decrease the congestion in major cities. One of the key problems is\nthat typically mobility decision support systems focus on individual utility\nand react only after congestion appears. In this paper, we propose socially\nconsiderate multi-modal routing algorithms that are proactive and consider, via\npredictions, the shared effect of riders on the overall efficacy of mobility\nservices. We have adapted the MATSim simulator framework to incorporate the\nproposed algorithms present a simulation analysis of a case study in Nashville,\nTennessee that assesses the effects of our routing models on the traffic\ncongestion for different levels of penetration and adoption of socially\nconsiderate routes. Our results indicate that even at a low penetration (social\nratio), we are able to achieve an improvement in system-level performance. \n\n"}
{"id": "1803.00683", "contents": "Title: Decentralized Computation Offloading and Resource Allocation in\n  Heterogeneous Networks with Mobile Edge Computing Abstract: We consider a heterogeneous network with mobile edge computing, where a user\ncan offload its computation to one among multiple servers. In particular, we\nminimize the system-wide computation overhead by jointly optimizing the\nindividual computation decisions, transmit power of the users, and computation\nresource at the servers. The crux of the problem lies in the combinatorial\nnature of multi-user offloading decisions, the complexity of the optimization\nobjective, and the existence of inter-cell interference. Then, we decompose the\nunderlying problem into two subproblems: i) the offloading decision, which\nincludes two phases of user association and subchannel assignment, and ii)\njoint resource allocation, which can be further decomposed into the problems of\ntransmit power and computation resource allocation. To enable distributed\ncomputation offloading, we sequentially apply a many-to-one matching game for\nuser association and a one-to-one matching game for subchannel assignment.\nMoreover, the transmit power of offloading users is found using a bisection\nmethod with approximate inter-cell interference, and the computation resources\nallocated to offloading users is achieved via the duality approach. The\nproposed algorithm is shown to converge and is stable. Finally, we provide\nsimulations to validate the performance of the proposed algorithm as well as\ncomparisons with the existing frameworks. \n\n"}
{"id": "1803.01528", "contents": "Title: Network Phenotyping for Network Traffic Classification and Anomaly\n  Detection Abstract: This paper proposes to develop a network phenotyping mechanism based on\nnetwork resource usage analysis and identify abnormal network traffic. The\nnetwork phenotyping may use different metrics in the cyber physical system\n(CPS), including resource and network usage monitoring, physical state\nestimation. The set of devices will collectively decide a holistic view of the\nentire system through advanced image processing and machine learning methods.\nIn this paper, we choose the network traffic pattern as a study case to\ndemonstrate the effectiveness of the proposed method, while the methodology may\nsimilarly apply to classification and anomaly detection based on other resource\nmetrics. We apply image processing and machine learning on the network resource\nusage to extract and recognize communication patterns. The phenotype method is\nexperimented on four real-world decentralized applications. With proper length\nof sampled continuous network resource usage, the overall recognition accuracy\nis about 99%. Additionally, the recognition error is used to detect the anomaly\nnetwork traffic. We simulate the anomaly network resource usage that equals to\n10%, 20% and 30% of the normal network resource usage. The experiment results\nshow the proposed anomaly detection method is efficient in detecting each\nintensity of anomaly network resource usage. \n\n"}
{"id": "1803.02261", "contents": "Title: User-Centric 5G Cellular Networks: Resource Allocation and Comparison\n  with the Cell-Free Massive MIMO Approach Abstract: Recently, the so-called cell-free (CF) Massive MIMO architecture has been\nintroduced, wherein a very large number of distributed access points (APs)\nsimultaneously and jointly serve a much smaller number of mobile stations\n(MSs). The paper extends the CF approach to the case in which both the APs and\nthe MSs are equipped with multiple antennas, proposing a beamfoming scheme\nthat, relying on the channel hardening effect, does not require channel\nestimation at the MSs. We contrast the CF massive MIMO approach with a\nuser-centric (UC) approach wherein each MS is served only by a limited number\nof APs. Since far APs experience a bad SINR, it turns out that they are quite\nunhelpful in serving far users, and so, the UC approach, while requiring less\nbackhaul overhead with respect to the CF approach, is shown here to achieve\nbetter performance results, in terms of achievable rate-per-user, for the vast\nmajority of the MSs in the network. Furthermore, in the paper we propose two\npower allocation strategy for the uplink and downlink, one aimed at maximizing\nthe overall data-rate and another aimed at maximizing system fairness. \n\n"}
{"id": "1803.02791", "contents": "Title: Facebook (A)Live? Are live social broadcasts really broadcasts? Abstract: The era of live-broadcast is back but with two major changes. First, unlike\ntraditional TV broadcasts, content is now streamed over the Internet enabling\nit to reach a wider audience. Second, due to various user-generated content\nplatforms it has become possible for anyone to get involved, streaming their\nown content to the world. This emerging trend of going live usually happens via\nsocial platforms, where users perform live social broadcasts predominantly from\ntheir mobile devices, allowing their friends (and the general public) to engage\nwith the stream in real-time. With the growing popularity of such platforms,\nthe burden on the current Internet infrastructure is therefore expected to\nmultiply. With this in mind, we explore one such prominent platform - Facebook\nLive. We gather 3TB of data, representing one month of global activity and\nexplore the characteristics of live social broadcast. From this, we derive\nsimple yet effective principles which can decrease the network burden. We then\ndissect global and hyper-local properties of the video while on-air, by\ncapturing the geography of the broadcasters or the users who produce the video\nand the viewers or the users who interact with it. Finally, we study the social\nengagement while the video is live and distinguish the key aspects when the\nsame video goes on-demand. A common theme throughout the paper is that, despite\nits name, many attributes of Facebook Live deviate from both the concepts of\nlive and broadcast. \n\n"}
{"id": "1803.02816", "contents": "Title: Shedding Light on the Dark Corners of the Internet: A Survey of Tor\n  Research Abstract: Anonymity services have seen high growth rates with increased usage in the\npast few years. Among various services, Tor is one of the most popular\npeer-to-peer anonymizing service. In this survey paper, we summarize, analyze,\nclassify and quantify 26 years of research on the Tor network. Our research\nshows that `security' and `anonymity' are the most frequent keywords associated\nwith Tor research studies. Quantitative analysis shows that the majority of\nresearch studies on Tor focus on `deanonymization' the design of a breaching\nstrategy. The second most frequent topic is analysis of path selection\nalgorithms to select more resilient paths. Analysis shows that the majority of\nexperimental studies derived their results by deploying private testbeds while\nothers performed simulations by developing custom simulators. No consistent\nparameters have been used for Tor performance analysis. The majority of authors\nperformed throughput and latency analysis. \n\n"}
{"id": "1803.03285", "contents": "Title: Massive UAV-to-Ground Communication and its Stable Movement Control: A\n  Mean-Field Approach Abstract: This paper proposes a real-time movement control algorithm for massive\nunmanned aerial vehicles (UAVs) that provide emergency cellular connections in\nan urban disaster site. While avoiding the inter-UAV collision under temporal\nwind dynamics, the proposed algorithm minimizes each UAV's energy consumption\nper unit downlink rate. By means of a mean-field game theoretic flocking\napproach, the velocity control of each UAV only requires its own location and\nchannel states. Numerical results validate the performance of the algorithm in\nterms of the number of collisions and energy consumption per data rate, under a\nrealistic 3GPP UAV channel model. \n\n"}
{"id": "1803.03622", "contents": "Title: Virtual Network Embedding Approximations: Leveraging Randomized Rounding Abstract: The Virtual Network Embedding Problem (VNEP) captures the essence of many\nresource allocation problems of today's infrastructure providers, which offer\ntheir physical computation and networking resources to customers. Customers\nrequest resources in the form of Virtual Networks, i.e. as a directed graph\nwhich specifies computational requirements at the nodes and communication\nrequirements on the edges. An embedding of a Virtual Network on the shared\nphysical infrastructure is the joint mapping of (virtual) nodes to physical\nservers together with the mapping of (virtual) edges onto paths in the physical\nnetwork connecting the respective servers.\n  This work initiates the study of approximation algorithms for the VNEP.\nConcretely, we study the offline setting with admission control: given multiple\nrequest graphs the task is to embed the most profitable subset while not\nexceeding resource capacities. Our approximation is based on the randomized\nrounding of Linear Programming (LP) solutions. Interestingly, we uncover that\nthe standard LP formulation for the VNEP exhibits an inherent structural\ndeficit when considering general virtual network topologies: its solutions\ncannot be decomposed into valid embeddings. In turn, focusing on the class of\ncactus request graphs, we devise a novel LP formulation, whose solutions can be\ndecomposed into convex combinations of valid embedding. Proving performance\nguarantees of our rounding scheme, we obtain the first approximation algorithm\nfor the VNEP in the resource augmentation model.\n  We propose two types of rounding heuristics and evaluate their performance in\nan extensive computational study. Our results indicate that randomized rounding\ncan yield good solutions (even without augmentations). Specifically, heuristic\nrounding achieves 73.8% of the baseline's profit, while not exceeding\ncapacities. \n\n"}
{"id": "1803.04166", "contents": "Title: Spatial networks with wireless applications Abstract: Many networks have nodes located in physical space, with links more common\nbetween closely spaced pairs of nodes. For example, the nodes could be wireless\ndevices and links communication channels in a wireless mesh network. We\ndescribe recent work involving such networks, considering effects due to the\ngeometry (convex,non-convex, and fractal), node distribution,\ndistance-dependent link probability, mobility, directivity and interference. \n\n"}
{"id": "1803.04452", "contents": "Title: (FPT-)Approximation Algorithms for the Virtual Network Embedding Problem Abstract: Many resource allocation problems in the cloud can be described as a basic\nVirtual Network Embedding Problem (VNEP): finding mappings of request graphs\n(describing the workloads) onto a substrate graph (describing the physical\ninfrastructure). In the offline setting, the two natural objectives are profit\nmaximization, i.e., embedding a maximal number of request graphs subject to the\nresource constraints, and cost minimization, i.e., embedding all requests at\nminimal overall cost. The VNEP can be seen as a generalization of classic\nrouting and call admission problems, in which requests are arbitrary graphs\nwhose communication endpoints are not fixed. Due to its applications, the\nproblem has been studied intensively in the networking community. However, the\nunderlying algorithmic problem is hardly understood.\n  This paper presents the first fixed-parameter tractable approximation\nalgorithms for the VNEP. Our algorithms are based on randomized rounding. Due\nto the flexible mapping options and the arbitrary request graph topologies, we\nshow that a novel linear program formulation is required. Only using this novel\nformulation the computation of convex combinations of valid mappings is\nenabled, as the formulation needs to account for the structure of the request\ngraphs. Accordingly, to capture the structure of request graphs, we introduce\nthe graph-theoretic notion of extraction orders and extraction width and show\nthat our algorithms have exponential runtime in the request graphs' maximal\nwidth. Hence, for request graphs of fixed extraction width, we obtain the first\npolynomial-time approximations.\n  Studying the new notion of extraction orders we show that (i) computing\nextraction orders of minimal width is NP-hard and (ii) that computing\ndecomposable LP solutions is in general NP-hard, even when restricting request\ngraphs to planar ones. \n\n"}
{"id": "1803.04675", "contents": "Title: Using Grouped Linear Prediction and Accelerated Reinforcement Learning\n  for Online Content Caching Abstract: Proactive caching is an effective way to alleviate peak-hour traffic\ncongestion by prefetching popular contents at the wireless network edge. To\nmaximize the caching efficiency requires the knowledge of content popularity\nprofile, which however is often unavailable in advance. In this paper, we first\npropose a new linear prediction model, named grouped linear model (GLM) to\nestimate the future content requests based on historical data. Unlike many\nexisting works that assumed the static content popularity profile, our model\ncan adapt to the temporal variation of the content popularity in practical\nsystems due to the arrival of new contents and dynamics of user preference.\nBased on the predicted content requests, we then propose a reinforcement\nlearning approach with model-free acceleration (RLMA) for online cache\nreplacement by taking into account both the cache hits and replacement cost.\nThis approach accelerates the learning process in non-stationary environment by\ngenerating imaginary samples for Q-value updates. Numerical results based on\nreal-world traces show that the proposed prediction and learning based online\ncaching policy outperform all considered existing schemes. \n\n"}
{"id": "1803.05364", "contents": "Title: Temporal Correlation of Interference in Vehicular Networks with\n  Shifted-Exponential Time Headways Abstract: We consider a one-dimensional vehicular network where the time headway (time\ndifference between successive vehicles as they pass a point on the roadway)\nfollows the shifted-exponential distribution. We show that neglecting the\nimpact of shift in the deployment model, which degenerates the distribution of\nvehicles to a Poisson Point Process, overestimates the temporal correlation of\ninterference at the origin. The estimation error becomes large at high traffic\nconditions and small time-lags. \n\n"}
{"id": "1803.06173", "contents": "Title: Energy Sustainable Mobile Networks via Energy Routing, Learning and\n  Foresighted Optimization Abstract: The design of self-sustainable base station (BS) deployments is addressed in\nthis paper: BSs have energy harvesting and storage capabilities, they can use\nambient energy to serve the local traffic or store it for later use. A\ndedicated power packet grid allows energy transfer across BSs, compensating for\nimbalance in the harvested energy or in the traffic load. Some BSs are offgrid,\ni.e., they can only use the locally harvested energy and that transferred from\nother BSs, whereas others are ongrid, i.e., they can also purchase energy from\nthe power grid. Within this setup, an optimization problem is formulated where:\nenergy harvested and traffic processes are estimated at the BSs through\nGaussian Processes (GPs), and a Model Predictive Control (MPC) framework is\ndevised for the computation of energy allocation and transfer schedules.\nNumerical results, obtained using real energy harvesting and traffic profiles,\nshow substantial improvements in terms of energy self-sustainability of the\nsystem, outage probability (zero in most cases), and in the amount of energy\npurchased from the power grid, which is of more than halved with respect to the\ncase where the optimization does not consider GP forecasting and MPC. \n\n"}
{"id": "1803.06596", "contents": "Title: Network Service Orchestration: A Survey Abstract: Business models of network service providers are undergoing an evolving\ntransformation fueled by vertical customer demands and technological advances\nsuch as 5G, Software Defined Networking~(SDN), and Network Function\nVirtualization~(NFV). Emerging scenarios call for agile network services\nconsuming network, storage, and compute resources across heterogeneous\ninfrastructures and administrative domains. Coordinating resource control and\nservice creation across interconnected domains and diverse technologies becomes\na grand challenge. Research and development efforts are being devoted to\nenabling orchestration processes to automate, coordinate, and manage the\ndeployment and operation of network services. In this survey, we delve into the\ntopic of Network Service Orchestration~(NSO) by reviewing the historical\nbackground, relevant research projects, enabling technologies, and\nstandardization activities. We define key concepts and propose a taxonomy of\nNSO approaches and solutions to pave the way towards a common understanding of\nthe various ongoing efforts around the realization of diverse NSO application\nscenarios. Based on the analysis of the state of affairs, we present a series\nof open challenges and research opportunities, altogether contributing to a\ntimely and comprehensive survey on the vibrant and strategic topic of network\nservice orchestration. \n\n"}
{"id": "1803.07588", "contents": "Title: A Push-Pull Gradient Method for Distributed Optimization in Networks Abstract: In this paper, we focus on solving a distributed convex optimization problem\nin a network, where each agent has its own convex cost function and the goal is\nto minimize the sum of the agents' cost functions while obeying the network\nconnectivity structure. In order to minimize the sum of the cost functions, we\nconsider a new distributed gradient-based method where each node maintains two\nestimates, namely, an estimate of the optimal decision variable and an estimate\nof the gradient for the average of the agents' objective functions. From the\nviewpoint of an agent, the information about the decision variable is pushed to\nthe neighbors, while the information about the gradients is pulled from the\nneighbors (hence giving the name \"push-pull gradient method\"). The method\nunifies the algorithms with different types of distributed architecture,\nincluding decentralized (peer-to-peer), centralized (master-slave), and\nsemi-centralized (leader-follower) architecture. We show that the algorithm\nconverges linearly for strongly convex and smooth objective functions over a\ndirected static network. In our numerical test, the algorithm performs well\neven for time-varying directed networks. \n\n"}
{"id": "1803.07649", "contents": "Title: An Online Algorithm for Power-proportional Data Centers with Switching\n  Cost Abstract: Recent studies have shown that power-proportional data centers can save\nenergy cost by dynamically \"right-sizing\" the data centers based on real-time\nworkload. More servers are activated when the workload increases while some\nservers can be put into the sleep mode during periods of low load. In this\npaper, we revisit the dynamic right-sizing problem for heterogeneous data\ncenters with various operational cost and switching cost. We propose a new\nonline algorithm based on a regularization technique, which achieves a better\ncompetitive ratio compared to the state-of-the-art greedy algorithm. We further\nintroduce a switching cost offset into the model and extend our algorithm to\nthis new setting. Simulations based on real workload and renewable energy\ntraces show that our algorithms outperform the greedy algorithm in both\nsettings. \n\n"}
{"id": "1803.07673", "contents": "Title: Ultra-Low Latency (ULL) Networks: The IEEE TSN and IETF DetNet Standards\n  and Related 5G ULL Research Abstract: Many network applications, e.g., industrial control, demand Ultra-Low Latency\n(ULL). However, traditional packet networks can only reduce the end-to-end\nlatencies to the order of tens of milliseconds. The IEEE 802.1 Time Sensitive\nNetworking (TSN) standard and related research studies have sought to provide\nlink layer support for ULL networking, while the emerging IETF Deterministic\nNetworking (DetNet) standards seek to provide the complementary network layer\nULL support. This article provides an up-to-date comprehensive survey of the\nIEEE TSN and IETF DetNet standards and the related research studies. The survey\nof these standards and research studies is organized according to the main\ncategories of flow concept, flow synchronization, flow management, flow\ncontrol, and flow integrity. ULL networking mechanisms play a critical role in\nthe emerging fifth generation (5G) network access chain from wireless devices\nvia access, backhaul, and core networks. We survey the studies that\nspecifically target the support of ULL in 5G networks, with the main categories\nof fronthaul, backhaul, and network management. Throughout, we identify the\npitfalls and limitations of the existing standards and research studies. This\nsurvey can thus serve as a basis for the development of standards enhancements\nand future ULL research studies that address the identified pitfalls and\nlimitations. \n\n"}
{"id": "1803.07976", "contents": "Title: An Overview on Application of Machine Learning Techniques in Optical\n  Networks Abstract: Today's telecommunication networks have become sources of enormous amounts of\nwidely heterogeneous data. This information can be retrieved from network\ntraffic traces, network alarms, signal quality indicators, users' behavioral\ndata, etc. Advanced mathematical tools are required to extract meaningful\ninformation from these data and take decisions pertaining to the proper\nfunctioning of the networks from the network-generated data. Among these\nmathematical tools, Machine Learning (ML) is regarded as one of the most\npromising methodological approaches to perform network-data analysis and enable\nautomated network self-configuration and fault management. The adoption of ML\ntechniques in the field of optical communication networks is motivated by the\nunprecedented growth of network complexity faced by optical networks in the\nlast few years. Such complexity increase is due to the introduction of a huge\nnumber of adjustable and interdependent system parameters (e.g., routing\nconfigurations, modulation format, symbol rate, coding schemes, etc.) that are\nenabled by the usage of coherent transmission/reception technologies, advanced\ndigital signal processing and compensation of nonlinear effects in optical\nfiber propagation. In this paper we provide an overview of the application of\nML to optical communications and networking. We classify and survey relevant\nliterature dealing with the topic, and we also provide an introductory tutorial\non ML for researchers and practitioners interested in this field. Although a\ngood number of research papers have recently appeared, the application of ML to\noptical networks is still in its infancy: to stimulate further work in this\narea, we conclude the paper proposing new possible research directions. \n\n"}
{"id": "1803.08153", "contents": "Title: Learning the Localization Function: Machine Learning Approach to\n  Fingerprinting Localization Abstract: Considered as a data-driven approach, Fingerprinting Localization Solutions\n(FPSs) enjoy huge popularity due to their good performance and minimal\nenvironment information requirement. This papers addresses applications of\nartificial intelligence to solve two problems in Received Signal Strength\nIndicator (RSSI) based FPS, first the cumbersome training database construction\nand second the extrapolation of fingerprinting algorithm for similar buildings\nwith slight environmental changes. After a concise overview of deep learning\ndesign techniques, two main techniques widely used in deep learning are\nexploited for the above mentioned issues namely data augmentation and transfer\nlearning. We train a multi-layer neural network that learns the mapping from\nthe observations to the locations. A data augmentation method is proposed to\nincrease the training database size based on the structure of RSSI measurements\nand hence reducing effectively the amount of training data. Then it is shown\nexperimentally how a model trained for a particular building can be transferred\nto a similar one by fine tuning with significantly smaller training numbers.\nThe paper implicitly discusses the new guidelines to consider about deep\nlearning designs when they are employed in a new application context. \n\n"}
{"id": "1803.08189", "contents": "Title: Can Decentralized Status Update Achieve Universally Near-Optimal\n  Age-of-Information in Wireless Multiaccess Channels? Abstract: In an Internet-of-Things system where status data are collected from sensors\nand actuators for time-critical applications, the freshness of data is vital\nand can be quantified by the recently proposed age-of-information (AoI) metric.\nIn this paper, we first consider a general scenario where multiple terminals\nshare a common channel to transmit or receive randomly generated status\npackets. The optimal scheduling problem to minimize AoI is formulated as a\nrestless multi-armed bandit problem. To solve the problem efficiently, we\nderive the Whittle's index in closed-form and establish the indexability\nthereof. Compared with existing work, we extend the index policy for AoI\noptimization to incorporate stochastic packet arrivals and optimal packet\nmanagement (buffering the latest packet). Inspired by the index policy which\nhas near-optimal performance but is centralized by nature, a decentralized\nstatus update scheme, i.e., the index-prioritized random access policy (IPRA),\nis further proposed, achieving universally near-optimal AoI performance and\noutperforming state-of-the-arts in the literature. \n\n"}
{"id": "1803.08433", "contents": "Title: Dyloc: Dynamic and Collaborative User-controlled AOA based Localizing\n  System with your laptops Abstract: Currently, accurate localization system based on commodity WiFi devices is\nnot broadly available yet. In the literature, the solutions are based on either\nnetwork infrastructure like WiFi router, which have at least three antennas, or\nsacrifice accuracy with coarse grained information like RSSI. In this work, we\ndesign a new localizing system which is accurate based on AOA estimation and\ninstantly deployable on users' devices.\n  Dyloc is designed to be dynamically constructed with user's devices as\nnetwork nodes without any network infrastructure. On the platform of laptops,\nour system achieve comparable localization accuracy with state-of-the-art work\ndespite of the limitation of less number and large separation of antennas. We\ndesign multi-stage signal processing to resolve the ambiguity issue arisen in\nthis scenario. To enable dynamic and collaborative construction, our system can\naccurately conduct self-localization and also eliminate the need of\ninfrastructure anchors, which is due to the dedicated two-layer algorithm\ndesign. \n\n"}
{"id": "1803.09112", "contents": "Title: To overlap or not to overlap: Enabling Channel Bonding in High-Density\n  WLANs Abstract: Wireless local area networks (WLANs) are the most popular kind of wireless\nInternet connection because of their simplicity of deployment and operation. As\na result, the number of devices accessing the Internet through WLANs such as\nlaptops, smartphones, or wearables, is increasing drastically at the same time\nthat applications' throughput requirements do. To cope with these challenges,\nchannel bonding (CB) techniques are used for enabling higher data rates by\ntransmitting in wider channels, thus increasing spectrum efficiency. However,\nimportant issues like higher potential co-channel and adjacent channel\ninterference arise when bonding channels. This may harm the performance of the\ncarrier sense multiple access (CSMA) protocol because of recurrent backoff\nfreezing while making nodes more sensitive to hidden node effects. In this\npaper, we address the following point at issue: is it convenient for\nhigh-density (HD) WLANs to use wider channels and potentially overlap in the\nspectrum? First, we highlight key aspects of DCB in toy scenarios through a\ncontinuous time Markov network (CTMN) model. Then, by means of extensive\nsimulations covering a wide range of traffic loads and access point (AP)\ndensities, we show that dynamic channel bonding (DCB) - which adapts the\nchannel bandwidth on a per-packet transmission - significantly outperforms\ntraditional single-channel on average. Nevertheless, results also corroborate\nthat DCB is more prone to generate unfair situations where WLANs may starve.\nContrary to most of the current thoughts pushing towards non-overlapping\nchannels in HD deployments, we highlight the benefits of allocating channels as\nwider as possible to WLANs altogether with implementing adaptive access\npolicies to cope with the unfairness situations that may appear. \n\n"}
{"id": "1803.10649", "contents": "Title: Advanced IEEE 802.11ax TCP aware scheduling under unreliable channels Abstract: In this paper we suggest advanced IEEE 802.11ax TCP-aware scheduling\nstrategies for optimizing the AP operation under transmission of unidirectional\nTCP traffic. Our scheduling strategies optimize the performance using the\ncapability for Multi User transmissions over the Uplink, first introduced in\nIEEE 802.11ax, together with Multi User transmissions over the Downlink. They\nare based on Transmission Opportunities (TXOP) and we suggest three scheduling\nstrategies determining the TXOP formation parameters. In one of the strategies\none can control the achieved Goodput vs. the delay. We also assume saturated\nWiFi transmission queues. We show that with minimal Goodput degradation one can\navoid considerable delays. \n\n"}
{"id": "1803.11512", "contents": "Title: Joint Communication, Computation, Caching, and Control in Big Data\n  Multi-access Edge Computing Abstract: The concept of multi-access edge computing (MEC) has been recently introduced\nto supplement cloud computing by deploying MEC servers to the network edge so\nas to reduce the network delay and alleviate the load on cloud data centers.\nHowever, compared to a resourceful cloud, an MEC server has limited resources.\nWhen each MEC server operates independently, it cannot handle all of the\ncomputational and big data demands stemming from the users devices.\nConsequently, the MEC server cannot provide significant gains in overhead\nreduction due to data exchange between users devices and remote cloud.\nTherefore, joint computing, caching, communication, and control (4C) at the\nedge with MEC server collaboration is strongly needed for big data\napplications. In order to address these challenges, in this paper, the problem\nof joint 4C in big data MEC is formulated as an optimization problem whose goal\nis to maximize the bandwidth saving while minimizing delay, subject to the\nlocal computation capability of user devices, computation deadline, and MEC\nresource constraints. However, the formulated problem is shown to be\nnon-convex. To make this problem convex, a proximal upper bound problem of the\noriginal formulated problem that guarantees descent to the original problem is\nproposed. To solve the proximal upper bound problem, a block successive upper\nbound minimization (BSUM) method is applied. Simulation results show that the\nproposed approach increases bandwidth-saving and minimizes delay while\nsatisfying the computation deadlines. \n\n"}
{"id": "1804.00739", "contents": "Title: Virtualized Application Function Chaining: Maximizing the Wearable\n  System Lifetime Abstract: The number of smart devices wear and carry by users is growing rapidly which\nis driven by innovative new smart wearables and interesting service o erings.\nThis has led to applications that utilize multiple devices around the body to\nprovide immersive environments such as mixed reality. These applications rely\non a number of di erent types of functions such as sensing, communication and\nvarious types of processing, that require considerable resources. Thus one of\nthe major challenges in supporting of these applications is dependent on the\nbattery lifetime of the devices that provide the necessary functionality. The\nbattery lifetime can be extended by either incorporating a battery with larger\ncapacity and/or by utilizing the available resources e ciently. However, the\nincreases in battery capacity are not keeping up with the demand and larger\nbatteries add to both the weight and size of the device. Thus, the focus of\nthis paper is to improve the battery e ciency through intelligent resources\nutilization. We show that, when the same resource is available on multiple\ndevices that form part of the wearable system, and or is in close proximity, it\nis possible consider them as a resource pool and further utilize them\nintelligently to improve the system lifetime. Speci cally, we formulate the\nfunction allocation algorithm as a Mixed Integer Linear Programming (MILP)\noptimization problem and propose an e cient heuristic solution. The\nexperimental data driven simulation results show that approximately 40-50%\nsystem battery life improvement can be achieved with proper function allocation\nand orchestration. \n\n"}
{"id": "1804.00811", "contents": "Title: Performance Analysis for Practical Unmanned Aerial Vehicle Networks with\n  LoS/NLoS Transmissions Abstract: In this paper, we provide a performance analysis for practical unmanned\naerial vehicle (UAV)-enabled networks. By considering both line-of-sight (LoS)\nand non-line-of-sight (NLoS) transmissions between aerial base stations (BSs)\nand ground users, the coverage probability and the area spectral efficiency\n(ASE) are derived. Considering that there is no consensus on the path loss\nmodel for studying UAVs in the literature, in this paper, three path loss\nmodels, i.e., high-altitude model, low-altitude model and ultra-low-altitude\nmodel, are investigated and compared. Moreover, the lower bound of the network\nperformance is obtained assuming that UAVs are hovering randomly according to\nhomogeneous Poisson point process (HPPP), while the upper bound is derived\nassuming that UAVs can instantaneously move to the positions directly overhead\nground users. From our analytical and simulation results for a practical UAV\nheight of 50 meters, we find that the network performance of the high-altitude\nmodel and the low-altitude model exhibit similar trends, while that of the\nultra-low-altitude model deviates significantly from the above two models. In\naddition, the optimal density of UAVs to maximize the coverage probability\nperformance has also been investigated. \n\n"}
{"id": "1804.01861", "contents": "Title: A Markov Model of Slice Admission Control Abstract: The emerging feature of network slicing in future Fifth Generation (5G)\nnetworks calls for efficient slice management. Recent studies have been\nfocusing on the mechanism of slice admission control, which functions in a\nmanner of state machine. This paper proposes a general state model for\nsynchronous slice admission control, and proves it to be Markovian under a set\nof weak constraints. An analytical approximation of the state transition matrix\nto reduce computational complexity in practical applications is also proposed\nand evaluated. \n\n"}
{"id": "1804.01895", "contents": "Title: Implicit Coordination of Caches in Small Cell Networks under Unknown\n  Popularity Profiles Abstract: We focus on a dense cellular network, in which a limited-size cache is\navailable at every Base Station (BS). In order to optimize the overall\nperformance of the system in such scenario, where a significant fraction of the\nusers is covered by several BSs, a tight coordination among nearby caches is\nneeded. To this end, this pape introduces a class of simple and fully\ndistributed caching policies, which require neither direct communication among\nBSs, nor a priori knowledge of content popularity. Furthermore, we propose a\nnovel approximate analytical methodology to assess the performance of\ninteracting caches under such policies. Our approach builds upon the well known\ncharacteristic time approximation and provides predictions that are\nsurprisingly accurate (hardly distinguishable from the simulations) in most of\nthe scenarios. Both synthetic and trace-driven results show that the our\ncaching policies achieve excellent performance (in some cases provably\noptimal). They outperform state-of-the-art dynamic policies for interacting\ncaches, and, in some cases, also the greedy content placement, which is known\nto be the best performing polynomial algorithm under static and perfectly-known\ncontent popularity profiles. \n\n"}
{"id": "1804.02994", "contents": "Title: Analysis of CSAT performance in Wi-Fi and LTE-U Coexistence Abstract: In this paper, we study energy-based Carrier Sense Adaptive Transmission\n(CSAT) for use with LTE-U and investigate the performance in Wi-Fi/LTE-U\ncoexistence using theoretical analysis and experimental verification using NI\nUSRPs. According to the LTE-U forum specification, if an LTE-U base station\n(BS) finds a vacant channel, it can transmit for up to 20 ms and turn OFF its\ntransmission for only 1 ms, resulting in a maximum duty cycle of 95%. In a\ndense deployment of LTE-U and Wi-Fi, it is very likely that a Wi-Fi access\npoint (AP) will wish to use the same channel. It will start transmission by\ntrying to transmit association packets (using carrier sense multiple access\nwith collision avoidance (CSMA/CA)) through the 1 ms LTE-U OFF duration. Since\nthis duration is very small, it leads to increased association packet drops and\nthus delays the Wi-Fi association process. Once LTE-U, using CSAT, detects\nWi-Fi, it should scale back the duty cycle to 50%. We demonstrate in this\npaper, using an experimental platform as well as theoretical analysis, that if\nLTE-U is using a 95% duty cycle, energy based CSAT will take a much longer time\nto scale back the duty cycle due to the beacon drops and delays in the\nreception. Hence, in order to maintain association fairness with Wi-Fi, we\npropose that a LTE-U BS should not transmit at maximum duty cycles (95%), even\nif the channel is sensed to be vacant. \n\n"}
{"id": "1804.03986", "contents": "Title: Dynamic Sensor Subset Selection for Centralized Tracking a Time-Varying\n  Stochastic Process Abstract: Motivated by the Internet-of-things and sensor networks for cyberphysical\nsystems, the problem of dynamic sensor activation for the centralized tracking\nof an i.i.d. time-varying process is examined. The tradeoff is between energy\nefficiency, which decreases with the number of active sensors, and fidelity,\nwhich increases with the number of active sensors. The problem of minimizing\nthe time-averaged mean-squared error over infinite horizon is examined under\nthe constraint of the mean number of active sensors. The proposed methods\nartfully combine Gibbs sampling and stochastic approximation for learning, in\norder to create a high performance, energy efficient tracking mechanisms with\nactive sensor selection. Centralized tracking of i.i.d. process with known\ndistribution as well as an unknown parametric distribution are considered. For\nan i.i.d. process with known distribution, convergence to the global optimal\nsolution with high probability is proved. The main challenge of the i.i.d. case\nis that the process has a distribution parameterized by a known or unknown\nparameter which must be learned; one key theoretical result proves that the\nproposed algorithm for tracking an i.i.d. process with unknown parametric\ndistribution converges to local optima. Numerical results show the efficacy of\nthe proposed algorithms and also suggest that global optimality is in fact\nachieved in some cases. \n\n"}
{"id": "1804.05057", "contents": "Title: 5G Wireless Network Slicing for eMBB, URLLC, and mMTC: A\n  Communication-Theoretic View Abstract: The grand objective of 5G wireless technology is to support three generic\nservices with vastly heterogeneous requirements: enhanced mobile broadband\n(eMBB), massive machine-type communications (mMTC), and ultra-reliable\nlow-latency communications (URLLC). Service heterogeneity can be accommodated\nby network slicing, through which each service is allocated resources to\nprovide performance guarantees and isolation from the other services. Slicing\nof the Radio Access Network (RAN) is typically done by means of orthogonal\nresource allocation among the services. This work studies the potential\nadvantages of allowing for non-orthogonal sharing of RAN resources in uplink\ncommunications from a set of eMBB, mMTC and URLLC devices to a common base\nstation. The approach is referred to as Heterogeneous Non-Orthogonal Multiple\nAccess (H-NOMA), in contrast to the conventional NOMA techniques that involve\nusers with homogeneous requirements and hence can be investigated through a\nstandard multiple access channel. The study devises a communication-theoretic\nmodel that accounts for the heterogeneous requirements and characteristics of\nthe three services. The concept of reliability diversity is introduced as a\ndesign principle that leverages the different reliability requirements across\nthe services in order to ensure performance guarantees with non-orthogonal RAN\nslicing. This study reveals that H-NOMA can lead, in some regimes, to\nsignificant gains in terms of performance trade-offs among the three generic\nservices as compared to orthogonal slicing. \n\n"}
{"id": "1804.05188", "contents": "Title: Area formation and content assignment for LTE broadcasting Abstract: Broadcasting and multicasting services in LTE networks are shaping up to be\nan effective way to provide popular content. A key requirement is that cells\nare aggregated into areas where a tight time synchronization among\ntransmissions is enforced, so as to broadcast the same radio resources. Our\npaper addresses a facet of LTE broadcasting that has so far received little\nattention: the creation of broadcasting areas and the assignment of content to\nthem in order to efficiently exploit radio resources and satisfy user requests.\nOur original clustering approach, named Single-Content Fusion, achieves these\ngoals by initially aggregating cells into single-content areas and maximizing\ncell similarity in content interests. Aggregated areas are then merged into\nmultiple-content areas by virtue of similar spatial coverage. We show the\nvalidity of our solution pointing out the advantages it provides in comparison\nto other approaches. We also discuss the impact of various system factors\n(e.g., number of served users, broadcast data rate, area size) and the\nscalability of our proposal in large, realistic scenarios with both static and\ntime-varying user interest. \n\n"}
{"id": "1804.05533", "contents": "Title: Resource-efficient Transmission of Vehicular Sensor Data Using\n  Context-aware Communication Abstract: Upcoming Intelligent Traffic Control Systems (ITSCs) will base their\noptimization processes on crowdsensing data obtained for cars that are used as\nmobile sensor nodes. In conclusion, public cellular networks will be confronted\nwith massive increases in Machine-Type Communication (MTC) and will require\nefficient communication schemes to minimize the interference of Internet of\nThings (IoT) data traffic with human communication. In this demonstration, we\npresent an Open Source framework for context-aware transmission of vehicular\nsensor data that exploits knowledge about the characteristics of the\ntransmission channel for leveraging connectivity hotspots, where data\ntransmissions can be performed with a high grade if resource efficiency. At the\nconference, we will present the measurement application for acquisition and\nlive-visualization of the required network quality indicators and show how the\ntransmission scheme performs in real-world vehicular scenarios based on\nmeasurement data obtained from field experiments. \n\n"}
{"id": "1804.05534", "contents": "Title: Combining Software Defined Networks and Machine Learning to enable Self\n  Organizing WLANs Abstract: Next generation of wireless local area networks (WLANs) will operate in\ndense, chaotic and highly dynamic scenarios that in a significant number of\ncases may result in a low user experience due to uncontrolled high interference\nlevels. Flexible network architectures, such as the software-defined networking\n(SDN) paradigm, will provide WLANs with new capabilities to deal with users'\ndemands, while achieving greater levels of efficiency and flexibility in those\ncomplex scenarios. On top of SDN, the use of machine learning (ML) techniques\nmay improve network resource usage and management by identifying feasible\nconfigurations through learning. ML techniques can drive WLANs to reach optimal\nworking points by means of parameter adjustment, in order to cope with\ndifferent network requirements and policies, as well as with the dynamic\nconditions. In this paper we overview the work done in SDN for WLANs, as well\nas the pioneering works considering ML for WLAN optimization. Finally, in order\nto demonstrate the potential of ML techniques in combination with SDN to\nimprove the network operation, we evaluate different use cases for\nintelligent-based spatial reuse and dynamic channel bonding operation in WLANs\nusing Multi-Armed Bandits. \n\n"}
{"id": "1804.06593", "contents": "Title: Coexistence of URLLC and eMBB services in the C-RAN Uplink: An\n  Information-Theoretic Study Abstract: The performance of orthogonal and non-orthogonal multiple access is studied\nfor the multiplexing of enhanced Mobile BroadBand (eMBB) and Ultra-Reliable\nLow-Latency Communications (URLLC) users in the uplink of a multi-cell Cloud\nRadio Access Network (C-RAN) architecture. While eMBB users can operate over\nlong codewords spread in time and frequency, URLLC users' transmissions are\nrandom and localized in time due to their low-latency requirements. These\nrequirements also call for decoding of their packets to be carried out at the\nedge nodes (ENs), whereas eMBB traffic can leverage the interference management\ncapabilities of centralized decoding at the cloud. Using information-theoretic\narguments, the performance trade-offs between eMBB and URLLC traffic types are\ninvestigated in terms of rate for the former, and rate, access latency, and\nreliability for the latter. The analysis includes non-orthogonal multiple\naccess (NOMA) with different decoding architectures, such as puncturing and\nsuccessive interference cancellation (SIC). The study sheds light into\neffective design choices as a function of inter-cell interference,\nsignal-to-noise ratio levels, and fronthaul capacity constraints. \n\n"}
{"id": "1804.07642", "contents": "Title: On the Effects of Subpacketization in Content-Centric Mobile Networks Abstract: A large-scale content-centric mobile ad hoc network employing\nsubpacketization is studied in which each mobile node having finite-size cache\nmoves according to the reshuffling mobility model and requests a content object\nfrom the library independently at random according to the Zipf popularity\ndistribution. Instead of assuming that one content object is transferred in a\nsingle time slot, we consider a more challenging scenario where the size of\neach content object is considerably large and thus only a subpacket of a file\ncan be delivered during one time slot, which is motivated by a fast mobility\nscenario. Under our mobility model, we consider a single-hop-based content\ndelivery and characterize the fundamental trade-offs between throughput and\ndelay. The order-optimal throughput-delay trade-off is analyzed by presenting\nthe following two content reception strategies: the sequential reception for\nuncoded caching and the random reception for maximum distance separable\n(MDS)-coded caching. We also perform numerical evaluation to validate our\nanalytical results. In particular, we conduct performance comparisons between\nthe uncoded caching and the MDS-coded caching strategies by identifying the\nregimes in which the performance difference between the two caching strategies\nbecomes prominent with respect to system parameters such as the Zipf exponent\nand the number of subpackets. In addition, we extend our study to the random\nwalk mobility scenario and show that our main results are essentially the same\nas those in the reshuffling mobility model. \n\n"}
{"id": "1804.07717", "contents": "Title: Target Wake Time: Scheduled access in IEEE 802.11ax WLANs Abstract: The increasing interest for ubiquitous networking, and the tremendous\npopularity gained by IEEE 802.11 Wireless Local Area Networks (WLANs) in recent\nyears, is leading to very dense deployments where high levels of channel\ncontention may prevent to meet the increasing users' demands. To mitigate the\nnegative effects of channel contention, the Target Wake Time (TWT) mechanism\nincluded in the IEEE 802.11ax amendment can have a significant role, as it\nprovides an extremely simple but effective mechanism to schedule transmissions\nin time. Moreover, in addition to reduce the contention between stations, the\nuse of TWT may also contribute to take full advantage of other novel mechanisms\nin the IEEE 802.11 universe, such as multiuser transmissions, multi-AP\ncooperation, spatial reuse and coexistence in high-density WLAN scenarios.\nOverall, we believe TWT may be a first step towards a practical collision-free\nand deterministic access in future WLANs. \n\n"}
{"id": "1804.08121", "contents": "Title: Cellular Connectivity for UAVs: Network Modeling, Performance Analysis\n  and Design Guidelines Abstract: The growing use of aerial user equipments (UEs) in various applications\nrequires ubiquitous and reliable connectivity for safe control and data\nexchange between these devices and ground stations. Key questions that need to\nbe addressed when planning the deployment of aerial UEs are whether the\ncellular network is a suitable candidate for enabling such connectivity, and\nhow the inclusion of aerial UEs might impact the overall network efficiency.\nThis paper provides an in-depth analysis of user and network level performance\nof a cellular network that serves both unmanned aerial vehicles (UAVs) and\nground users in the downlink. Our results show that the favorable propagation\nconditions that UAVs enjoy due to their height often backfire on them, as the\nincreased co-channel interference received from neighboring ground BSs is not\ncompensated by the improved signal strength. When compared with a ground user\nin an urban area, our analysis shows that a UAV flying at 100 meters can\nexperience a throughput decrease of a factor 10 and a coverage drop from 76% to\n30%. Motivated by these findings, we develop UAV and network based solutions to\nenable an adequate integration of UAVs into cellular networks. In particular,\nwe show that an optimal tilting of the UAV antenna can increase their coverage\nand throughput from 23% to 89% and from 3.5 b/s/Hz to 5.8 b/s/Hz, respectively,\noutperforming ground UEs. Furthermore, our findings reveal that depending on\nUAV altitude, the aerial user performance can scale with respect to the network\ndensity better than that of a ground user. Finally, our results show that\nnetwork densification and the use of micro cells limit UAV performance. While\nUAV usage has the potential to increase area spectral efficiency (ASE) of\ncellular networks with moderate number of cells, they might hamper the\ndevelopment of future ultra dense networks. \n\n"}
{"id": "1804.08333", "contents": "Title: Client Selection for Federated Learning with Heterogeneous Resources in\n  Mobile Edge Abstract: We envision a mobile edge computing (MEC) framework for machine learning (ML)\ntechnologies, which leverages distributed client data and computation resources\nfor training high-performance ML models while preserving client privacy. Toward\nthis future goal, this work aims to extend Federated Learning (FL), a\ndecentralized learning framework that enables privacy-preserving training of\nmodels, to work with heterogeneous clients in a practical cellular network. The\nFL protocol iteratively asks random clients to download a trainable model from\na server, update it with own data, and upload the updated model to the server,\nwhile asking the server to aggregate multiple client updates to further improve\nthe model. While clients in this protocol are free from disclosing own private\ndata, the overall training process can become inefficient when some clients are\nwith limited computational resources (i.e. requiring longer update time) or\nunder poor wireless channel conditions (longer upload time). Our new FL\nprotocol, which we refer to as FedCS, mitigates this problem and performs FL\nefficiently while actively managing clients based on their resource conditions.\nSpecifically, FedCS solves a client selection problem with resource\nconstraints, which allows the server to aggregate as many client updates as\npossible and to accelerate performance improvement in ML models. We conducted\nan experimental evaluation using publicly-available large-scale image datasets\nto train deep neural networks on MEC environment simulations. The experimental\nresults show that FedCS is able to complete its training process in a\nsignificantly shorter time compared to the original FL protocol. \n\n"}
{"id": "1804.08409", "contents": "Title: Stochastic Geometry Modeling of Cellular V2X Communication Over Shared\n  Channels Abstract: To overcome the limitations of DSRC with short range, non-supportability of\nhigh density networks, unreliable broadcast services, signal congestion and\nconnectivity disruptions, cellular vehicle-to-everything (C-V2X) communication\nnetworks, standardized in 3rd Generation Partnership Project (3GPP) Release 14,\nhave been recently introduced to cover broader vehicular communication\nscenarios including vehicle-to-vehicle (V2V), vehicle-to-pedestrian (V2P) and\nvehicle-to-infrastructure/network (V2I/N). In C-V2X, vehicles can directly\ncommunicate over PC5 based dedicated sidelinks called direct mode or V2V\ncommunication. However, high vehicle densities may require reuse of cellular\nspectrum for V2V. Moreover, infrastructure mode communication through V2I/N\nlinks can augment V2V communication by enhancing communication range and\nreliability for enhanced safety along with consistent performance under traffic\ncongestions. Motivated by the stringent connection reliability, spectral\nefficiency, and coverage requirements in C-V2X, this paper presents the first\ncomprehensive and tractable analytical framework for performance of C-V2X\nnetworks over shared V2V and cellular uplink channels, where the transmitting\nvehicles can deliver their information via infrastructure or direct mode, based\non their distances, propagation environments and the bias factor. By\npractically modeling the vehicles on the roads using the doubly stochastic Cox\nprocess and the base-stations, we derive new association probabilities, new\nsuccess probabilities of infrastructure and direct mode, and overall success\nprobability of the C-V2X communication over shared channels, which are\nvalidated by the simulations results. Our results reveal the benefits of our\nproposed model (possibility of selecting both direct and infrastructure modes\nover shared channels) compared to V2V network in terms of success probability. \n\n"}
{"id": "1804.08416", "contents": "Title: Learn and Pick Right Nodes to Offload Abstract: Task offloading is a promising technology to exploit the benefits of fog\ncomputing. An effective task offloading strategy is needed to utilize the\ncomputational resources efficiently. In this paper, we endeavor to seek an\nonline task offloading strategy to minimize the long-term latency. In\nparticular, we formulate a stochastic programming problem, where the\nexpectations of the system parameters change abruptly at unknown time instants.\nMeanwhile, we consider the fact that the queried nodes can only feed back the\nprocessing results after finishing the tasks. We then put forward an effective\nalgorithm to solve this challenging stochastic programming under the\nnon-stationary bandit model. We further prove that our proposed algorithm is\nasymptotically optimal in a non-stationary fog-enabled network. Numerical\nsimulations are carried out to corroborate our designs. \n\n"}
{"id": "1804.08787", "contents": "Title: Price and Performance of Cloud-hosted Virtual Network Functions:\n  Analysis and Future Challenges Abstract: The concept of Network Function Virtualization (NFV) has been introduced as a\nnew paradigm in the recent few years. NFV offers a number of benefits including\nsignificantly increased maintainability and reduced deployment overhead.\nSeveral works have been done to optimize deployment (also called embedding) of\nvirtual network functions (VNFs). However, no work to date has looked into\noptimizing the selection of cloud instances for a given VNF and its specific\nrequirements. In this paper, we evaluate the performance of VNFs when embedded\non different Amazon EC2 cloud instances. Specifically, we evaluate three VNFs\n(firewall, IDS, and NAT) in terms of arrival packet rate, resources\nutilization, and packet loss. Our results indicate that performance varies\nacross instance types, departing from the intuition of \"you get what you pay\nfor\" with cloud instances. We also find out that CPU is the critical resource\nfor the tested VNFs, although their peak packet processing capacities differ\nconsiderably from each other. Finally, based on the obtained results, we\nidentify key research challenges related to VNF instance selection and service\nchain provisioning. \n\n"}
{"id": "1804.08986", "contents": "Title: Feedback Control Goes Wireless: Guaranteed Stability over Low-power\n  Multi-hop Networks Abstract: Closing feedback loops fast and over long distances is key to emerging\napplications; for example, robot motion control and swarm coordination require\nupdate intervals of tens of milliseconds. Low-power wireless technology is\npreferred for its low cost, small form factor, and flexibility, especially if\nthe devices support multi-hop communication. So far, however, feedback control\nover wireless multi-hop networks has only been shown for update intervals on\nthe order of seconds. This paper presents a wireless embedded system that tames\nimperfections impairing control performance (e.g., jitter and message loss),\nand a control design that exploits the essential properties of this system to\nprovably guarantee closed-loop stability for physical processes with linear\ntime-invariant dynamics. Using experiments on a cyber-physical testbed with 20\nwireless nodes and multiple cart-pole systems, we are the first to demonstrate\nand evaluate feedback control and coordination over wireless multi-hop networks\nfor update intervals of 20 to 50 milliseconds. \n\n"}
{"id": "1804.10654", "contents": "Title: Resolving SINR Queries in a Dynamic Setting Abstract: We consider a set of transmitters broadcasting simultaneously on the same\nfrequency under the SINR model. Transmission power may vary from one\ntransmitter to another, and a transmitter's signal strength at a given point is\nmodeled by the transmitter's power divided by some constant power $\\alpha$ of\nthe distance it traveled. Roughly, a receiver at a given location can hear a\nspecific transmitter only if the transmitter's signal is stronger by a\nspecified ratio than the signals of all other transmitters combined. An SINR\nquery is to determine whether a receiver at a given location can hear any\ntransmitter, and if yes, which one.\n  An approximate answer to an SINR query is such that one gets a definite YES\nor definite NO, when the ratio between the strongest signal and all other\nsignals combined is well above or well below the reception threshold, while the\nanswer in the intermediate range is allowed to be either YES or NO.\n  We describe compact data structures that support approximate SINR queries in\nthe plane in a dynamic context, i.e., where transmitters may be inserted and\ndeleted over time. We distinguish between two main variants --- uniform power\nand non-uniform power. In both variants the preprocessing time is $O(n\n\\mathop{\\textrm{polylog}} n)$ and the amortized update time is\n$O(\\mathop{\\textrm{polylog}} n)$, while the query time is\n$O(\\mathop{\\textrm{polylog}} n)$ for uniform power, and randomized time\n$O(\\sqrt{n} \\mathop{\\textrm{polylog}} n)$ with high probability for non-uniform\npower.\n  Finally, we observe that in the static context the latter data structure can\nbe implemented differently, so that the query time is also\n$O(\\mathop{\\textrm{polylog}} n)$, thus significantly improving all previous\nresults for this problem. \n\n"}
{"id": "1804.10778", "contents": "Title: Hidden Vehicle Sensing via Asynchronous V2V Transmission: A\n  Multi-Path-Geometry Approach Abstract: Accurate vehicular sensing is a basic and important operation in autonomous\ndriving. Unfortunately, the existing techniques have their own limitations. For\ninstance, the communication-based approach (e.g., transmission of GPS\ninformation) has high latency and low reliability while the reflection-based\napproach (e.g., RADAR) is incapable of detecting hidden vehicles (HVs) without\nline-of-sight. This is arguably the reason behind some recent fatal accidents\ninvolving autonomous vehicles. To address this issue, this paper presents a\nnovel HV-sensing technology that exploits multi-path transmission from a HV to\na sensing vehicle (SV). The powerful technology enables the SV to detect\nmultiple HV-state parameters including position, orientation of driving\ndirection, and size. Its implementation does not even require\ntransmitter-receiver synchronization like conventional mobile positioning\ntechniques. Our design approach leverages estimated information on multi-path\n(AoA/AoD/ToA) and their geometric relations. As a result, a complex system of\nequations or optimization problems, where the desired HV-state parameters are\nvariables, can be formulated for different channel-noise conditions. The\ndevelopment of intelligent solution methods ranging from least-square estimator\nto disk/box minimization yields a set of practical HV-sensing techniques. We\nstudy their feasibility conditions in terms of the required number of paths.\nFurthermore, practical solutions, including sequential path combining and\nrandom directional beamforming, are proposed to enable HV-sensing given\ninsufficient paths. Last, realistic simulation of driving in both highway and\nrural scenarios demonstrates the effectiveness of the proposed techniques. In\nsummary, the proposed technique will enhance the capabilities of existing\nvehicular sensing technologies by enabling HV-sensing. \n\n"}
{"id": "1804.11341", "contents": "Title: Exploiting CSMA/ECA and Adaptive Sensitivity Control for Simultaneous\n  Transmit and Receive in IEEE 802.11 WLANs Abstract: Ever since the feasibility of in-band full-duplex (FD) at the Physical (PHY)\nlayer has been established, several studies have emerged investigating protocol\naspects of enabling FD operation in various legacy wireless technologies.\nRecently, the adoption of a simultaneous transmit and receive (STR) mode for\nnext generation wireless local area networks (WLANs) has received significant\nattention. Enabling STR mode (FD communication mode) in 802.11 WLANs creates\nbi-directional FD (BFD) and uni-directional FD (UFD) links. STR mode in 802.11\nWLANs must be enabled with minimal protocol modifications while accounting for\nthe co-existence and compatibility with legacy nodes and protocols. This paper\nprovides a novel solution, that can leverage carrier sense multiple access with\nenhanced collision avoidance (CSMA/ECA) and adaptive sensitivity control\nmechanisms, for enabling STR operation. The key aspects of the proposed\nsolution include co-existence with legacy nodes, identification of eligible\nnodes for UFD, optimization of secondary BFD and UFD transmissions, and\ncreation of UFD opportunities. Performance evaluation demonstrates that the\nproposed solution is effective in achieving the gains provided by STR\noperation. \n\n"}
{"id": "1805.00004", "contents": "Title: Maximum Likelihood Coordinate Systems for Wireless Sensor Networks: from\n  physical coordinates to topology coordinates Abstract: Many WSN protocols require the location coordinates of the sensor nodes, as\nit is useful to consider the data collected by the sensors in the context of\nthe location from which they were collected. Thus, one of the major challenges\nin WSNs is to determine the coordinates of sensors while minimizing the\nhardware cost. To address this, numerous localization algorithms have been\nproposed in the literature. However, outcomes of these algorithms are affected\nby noise, fading, and interference. As a result, their levels of accuracy may\nbecome unacceptable in complex environments that contain obstacles and\nreflecting surfaces. The alternative is to use topological maps based only on\nconnectivity information. Since they do not contain information about physical\ndistances, however, they are not faithful representatives of the physical\nlayout. Thus, the primary goal of this research is to discover a topology map\nthat provides more accurate information about physical layouts. In doing so,\nthis research has resulted in four main contributions. First, a novel concept\nMaximum-Likelihood Topology Map for RF WSNs is presented. This topology map\nprovides a more accurate physical representation, by using the probability of\npacket reception. The second contribution is Millimetre wave Topology Map\ncalculation, which is a novel topology mapping algorithm based on maximum\nlikelihood estimation for millimetre wave WSNs. The third contribution is a\ndistributed algorithm being proposed to calculate the topology coordinates of\nsensors by themselves as two algorithms above calculate centrally, which\nrequires time. Since a topology map contains significant non-linear\ndistortions, two WSN applications i.e. target searching and extremum seeking,\nwhich use a proposed topology map to localize the sensors and perform its\nspecified task are presented as the final contribution of this dissertation. \n\n"}
{"id": "1805.00041", "contents": "Title: LBP: Robust Rate Adaptation Algorithm for SVC Video Streaming Abstract: Video streaming today accounts for up to 55\\% of mobile traffic. In this\npaper, we explore streaming videos encoded using Scalable Video Coding scheme\n(SVC) over highly variable bandwidth conditions such as cellular networks.\nSVC's unique encoding scheme allows the quality of a video chunk to change\nincrementally, making it more flexible and adaptive to challenging network\nconditions compared to other encoding schemes. Our contribution is threefold.\nFirst, we formulate the quality decisions of video chunks constrained by the\navailable bandwidth, the playback buffer, and the chunk deadlines as an\noptimization problem. The objective is to optimize a novel QoE metric that\nmodels a combination of the three objectives of minimizing the stall/skip\nduration of the video, maximizing the playback quality of every chunk, and\nminimizing the number of quality switches. Second, we develop Layered Bin\nPacking (LBP) Adaptation Algorithm, a novel algorithm that solves the proposed\noptimization problem. Moreover, we show that LBP achieves the optimal solution\nof the proposed optimization problem with linear complexity in the number of\nvideo chunks. Third, we propose an online algorithm (online LBP) where several\nchallenges are addressed including handling bandwidth prediction errors, and\nshort prediction duration. Extensive simulations with real bandwidth traces of\npublic datasets reveal the robustness of our scheme and demonstrate its\nsignificant performance improvement as compared to the state-of-the-art SVC\nstreaming algorithms. The proposed algorithm is also implemented on a TCP/IP\nemulation test bed with real LTE bandwidth traces, and the emulation confirms\nthe simulation results and validates that the algorithm can be implemented and\ndeployed on today's mobile devices. \n\n"}
{"id": "1805.01449", "contents": "Title: Securing Downlink Non-Orthogonal Multiple Access Systems by Trusted\n  Relays Abstract: A downlink single-input single-output non-orthogonal multiple access system\nis considered in which a base station (BS) is communicating with two legitimate\nusers in the presence of an external eavesdropper. A group of trusted\ncooperative half-duplex relay nodes, powered by the BS, is employed to assist\nthe BS's transmission. The goal is to design relaying schemes such that the\nlegitimate users' secrecy rate region is maximized subject to a total power\nconstraint on the BS and the relays' transmissions. Three relaying schemes are\ninvestigated: cooperative jamming, decode-and-forward, and amplify-and-forward.\nDepending on the scheme, secure beamforming signals are carefully designed for\nthe relay nodes that either diminish the eavesdropper's rate without affecting\nthat of the legitimate users, or increase the legitimate users' rates without\nincreasing that of the eavesdropper. The results show that there is no relaying\nscheme that fits all conditions; the best relaying scheme depends on the system\nparameters, namely, the relays' and eavesdropper's distances from the BS, and\nthe number of relays. They also show that the relatively simple cooperative\njamming scheme outperforms other schemes when the relays are far from the BS\nand/or close to the eavesdropper. \n\n"}
{"id": "1805.01559", "contents": "Title: Computational Optimal Transport for 5G Massive C-RAN Device Association Abstract: The massive scale of future wireless networks will create computational\nbottlenecks in performance optimization. In this paper, we study the problem of\nconnecting mobile traffic to Cloud RAN (C-RAN) stations. To balance station\nload, we steer the traffic by designing device association rules. The baseline\nassociation rule connects each device to the station with the strongest signal,\nwhich does not account for interference or traffic hot spots, and leads to load\nimbalances and performance deterioration. Instead, we can formulate an\noptimization problem to decide centrally the best association rule at each time\ninstance. However, in practice this optimization has such high dimensions, that\neven linear programming solvers fail to solve. To address the challenge of\nmassive connectivity, we propose an approach based on the theory of optimal\ntransport, which studies the economical transfer of probability between two\ndistributions. Our proposed methodology can further inspire scalable algorithms\nfor massive optimization problems in wireless networks. \n\n"}
{"id": "1805.01715", "contents": "Title: 5G Island for Network Resilience and Autonomous Failsafe Operations Abstract: The resilience of 5G networks can be strongly challenged by central cloud\nvirtual network function (VNF) outages, which can be cause by server and\nbackhaul connection errors. This paper proposes a context-aware approach to\nmigrate VNF from central cloud to local edge cloud, in order to improve the\nnetwork resilience with minimized VNF migration cost. \n\n"}
{"id": "1805.02797", "contents": "Title: eBPF-based Content and Computation-aware Communication for Real-time\n  Edge Computing Abstract: By placing computation resources within a one-hop wireless topology, the\nrecent edge computing paradigm is a key enabler of real-time Internet of Things\n(IoT) applications. In the context of IoT scenarios where the same information\nfrom a sensor is used by multiple applications at different locations, the data\nstream needs to be replicated. However, the transportation of parallel streams\nmight not be feasible due to limitations in the capacity of the network\ntransporting the data. To address this issue, a content and computation-aware\ncommunication control framework is proposed based on the Software Defined\nNetwork (SDN) paradigm. The framework supports multi-streaming using the\nextended Berkeley Packet Filter (eBPF), where the traffic flow and packet\nreplication for each specific computation process is controlled by a program\nrunning inside an in-kernel Virtual Ma- chine (VM). The proposed framework is\ninstantiated to address a case-study scenario where video streams from multiple\ncameras are transmitted to the edge processor for real-time analysis. Numerical\nresults demonstrate the advantage of the proposed framework in terms of\nprogrammability, network bandwidth and system resource savings. \n\n"}
{"id": "1805.03111", "contents": "Title: Modeling and Analysis of MPTCP Proxy-based LTE-WLAN Path Aggregation Abstract: Long Term Evolution (LTE)-Wireless Local Area Network (WLAN) Path Aggregation\n(LWPA) based on Multi-path Transmission Control Protocol (MPTCP) has been under\nstandardization procedure as a promising and cost-efficient solution to boost\nDownlink (DL) data rate and handle the rapidly increasing data traffic. This\npaper aims at providing tractable analysis for the DL performance evaluation of\nlarge-scale LWPA networks with the help of tools from stochastic geometry. We\nconsider a simple yet practical model to determine under which conditions a\nnative WLAN Access Point (AP) will work under LWPA mode to help increasing the\nreceived data rate. Using stochastic spatial models for the distribution of\nWLAN APs and LTE Base Stations (BSs), we analyze the density of active\nLWPA-mode WiFi APs in the considered network model, which further leads to\nclosed-form expressions on the DL data rate and area spectral efficiency (ASE)\nimprovement. Our numerical results illustrate the impact of different network\nparameters on the performance of LWPA networks, which can be useful for further\nperformance optimization. \n\n"}
{"id": "1805.04268", "contents": "Title: Standalone and Non-Standalone Beam Management for 3GPP NR at mmWaves Abstract: The next generation of cellular networks will exploit mmWave frequencies to\ndramatically increase the network capacity. The communication at such high\nfrequencies, however, requires directionality to compensate the increase in\npropagation loss. Users and base stations need to align their beams during both\ninitial access and data transmissions, to ensure the maximum gain is reached.\nThe accuracy of the beam selection, and the delay in updating the beam pair or\nperforming initial access, impact the end-to-end performance and the quality of\nservice. In this paper we will present the beam management procedures that 3GPP\nhas included in the NR specifications, focusing on the different operations\nthat can be performed in Standalone (SA) and in Non-Standalone (NSA)\ndeployments. We will also provide a performance comparison among different\nschemes, along with design insights on the most important parameters related to\nbeam management frameworks. \n\n"}
{"id": "1805.05026", "contents": "Title: A Systematic Approach to Constructing Families of Incremental Topology\n  Control Algorithms Using Graph Transformation Abstract: In the communication systems domain, constructing and maintaining network\ntopologies via topology control (TC) algorithms is an important cross-cutting\nresearch area. Network topologies are usually modeled using attributed graphs\nwhose nodes and edges represent the network nodes and their interconnecting\nlinks. A key requirement of TC algorithms is to fulfill certain consistency and\noptimization properties to ensure a high quality of service. Still, few\nattempts have been made to constructively integrate these properties into the\ndevelopment process of TC algorithms. Furthermore, even though many TC\nalgorithms share substantial parts (such as structural patterns or tie-breaking\nstrategies), few works constructively leverage these commonalities and\ndifferences of TC algorithms systematically. In previous work, we addressed the\nconstructive integration of consistency properties into the development\nprocess. We outlined a constructive, model-driven methodology for designing\nindividual TC algorithms. Valid and high-quality topologies are characterized\nusing declarative graph constraints; TC algorithms are specified using\nprogrammed graph transformation. We applied a well-known static analysis\ntechnique to refine a given TC algorithm in a way that the resulting algorithm\npreserves the specified graph constraints.\n  In this paper, we extend our constructive methodology by generalizing it to\nsupport the specification of families of TC algorithms. To show the feasibility\nof our approach, we reneging six existing TC algorithms and develop e-kTC, a\nnovel energy-efficient variant of the TC algorithm kTC. Finally, we evaluate a\nsubset of the specified TC algorithms using a new tool integration of the graph\ntransformation tool eMoflon and the Simonstrator network simulation framework. \n\n"}
{"id": "1805.05138", "contents": "Title: Rogue Drone Detection: A Machine Learning Approach Abstract: The emerging, practical and observed issue of how to detect rogue drones that\ncarry terrestrial user equipment (UEs) on mobile networks is addressed in this\npaper. This issue has drawn much attention since the rogue drones may generate\nexcessive interference to mobile networks and may not be allowed by regulations\nin some regions. In this paper, we propose a novel machine learning approach to\nidentify the rogue drones in mobile networks based on radio measurements. We\napply two classification machine learning models, Logistic Regression, and\nDecision Tree, using features from radio measurements to identify the rogue\ndrones. We find that for high altitudes the proposed machine learning solutions\ncan yield high rogue drone detection rate while not mis-classifying regular\nground based UEs as rogue drone UEs. The detection accuracy however degrades at\nlow altitudes. \n\n"}
{"id": "1805.05923", "contents": "Title: Optimization and synchronization of programmable quantum communication\n  channels Abstract: Quantum applications transmit and receive data through quantum and classical\ncommunication channels. Channel capacity, the distance and the photon path\nbetween transmitting and receiving parties and the speed of the computation\nlinks play an essential role in timely synchronization and delivery of\ninformation using classical and quantum channels. In this study, we analyze and\noptimize the parameters of the communication channels needed for the quantum\napplication to successfully operate. We also develop algorithms for\nsynchronizing data delivery on classical and quantum channels. \n\n"}
{"id": "1805.06217", "contents": "Title: Artificial Intelligence Inspired Self-Deployment of Wireless Networks Abstract: In this paper, we propose a self-deployment approach for finding the optimal\nplacement of extenders in which both the wireless back-haul and front-haul\nthroughput of the extender are optimized. We present an artificial intelligence\n(AI) case based reasoning (CBR) framework that enables autonomous\nself-deployment in which the network can learn the environment by means of\nsensing and perception. New actions, i.e. extender positions, are created by\nproblem-specific optimization and semi-supervised learning algorithms that\nbalance exploration and exploitation of the search space. An IEEE 802.11\nstandard compliant simulations are performed to evaluate the framework on a\nlarge scale and compare its performance against existing conventional coverage\nmaximization approaches. Experimental evaluation is also performed in an\nenterprise environment to demonstrate the competence of the proposed\nAI-framework in perceiving such a dense scenario and reason the extender\ndeployment that achieves user quality of service (QoS). Throughput fairness and\nubiquitous QoS satisfaction are achieved which provide a leap to apply\nAI-driven self-deployment in wireless networks. \n\n"}
{"id": "1805.06637", "contents": "Title: How To Dimension Radio Resources When Users Are Distributed on Roads\n  Modeled by Poisson Line Process Abstract: Resources dimensioning aims at finding the number of radio resources required\nto carry a forecast data traffic at a target users Quality of Services (QoS).\nThe present paper attempts to provide a new approach of radio resources\ndimensioning considering the congestion probability, qualified as a relevant\nmetric for QoS evaluation. Users are assumed to be distributed according to a\nlinear Poisson Point Process (PPP) in a random system of roads modeled by\nPoisson Line Process (PLP) instead of the widely-used spatial PPP. We derive\nthe analytical expression of the congestion probability for analyzing its\nbehavior as a function of network parameters. Finally we show how to dimension\nradio resources by setting a value of the congestion probability, often\ntargeted by the operator, in order to find the relation between the necessary\nresources and the forecast data traffic expressed in terms of cell throughput.\nDifferent numerical results are presented to justify this dimensioning\napproach. \n\n"}
{"id": "1805.06670", "contents": "Title: Show me the Cache: Optimizing Cache-Friendly Recommendations for\n  Sequential Content Access Abstract: Caching has been successfully applied in wired networks, in the context of\nContent Distribution Networks (CDNs), and is quickly gaining ground for\nwireless systems. Storing popular content at the edge of the network (e.g. at\nsmall cells) is seen as a `win-win' for both the user (reduced access latency)\nand the operator (reduced load on the transport network and core servers).\nNevertheless, the much smaller size of such edge caches, and the volatility of\nuser preferences suggest that standard caching methods do not suffice in this\ncontext. What is more, simple popularity-based models commonly used (e.g. IRM)\nare becoming outdated, as users often consume multiple contents in sequence\n(e.g. YouTube, Spotify), and this consumption is driven by recommendation\nsystems. The latter presents a great opportunity to bias the recommender to\nminimize content access cost (e.g. maximizing cache hit rates). To this end, in\nthis paper we first propose a Markovian model for recommendation-driven user\nrequests. We then formulate the problem of biasing the recommendation algorithm\nto minimize access cost, while maintaining acceptable recommendation quality.\nWe show that the problem is non-convex, and propose an iterative ADMM-based\nalgorithm that outperforms existing schemes, and shows significant potential\nfor performance improvement on real content datasets. \n\n"}
{"id": "1805.06752", "contents": "Title: Scheduling Policies for Age Minimization in Wireless Networks with\n  Unknown Channel State Abstract: Age of information (AoI) is a recently proposed metric that measures the time\nelapsed since the generation of the last received information update. We\nconsider the problem of AoI minimization for a network under general\ninterference constraints, and time varying channel. We study the case where the\nchannel statistics are known, but the current channel state is unknown. We\npropose two scheduling policies, namely, the virtual queue based policy and\nage-based policy. In the virtual queue based policy, the scheduler schedules\nlinks with maximum weighted sum of the virtual queue lengths, while in the\nage-based policy, the scheduler schedules links with maximum weighted sum of a\nfunction of link AoI. We prove that the virtual queue based policy is peak age\noptimal, up to an additive constant, while the age-based policy is at most\nfactor 4 away from the optimal age. Numerical results suggest that both the\nproposed policies are, in fact, very close to the optimal. \n\n"}
{"id": "1805.06912", "contents": "Title: Fast reinforcement learning for decentralized MAC optimization Abstract: In this paper, we propose a novel decentralized framework for optimizing the\ntransmission strategy of Irregular Repetition Slotted ALOHA (IRSA) protocol in\nsensor networks. We consider a hierarchical communication framework that\nensures adaptivity to changing network conditions and does not require\ncentralized control. The proposed solution is inspired by the reinforcement\nlearning literature, and, in particular, Q-learning. To deal with sensor nodes'\nlimited lifetime and communication range, we allow them to decide how many\npacket replicas to transmit considering only their own buffer state. We show\nthat this information is sufficient and can help avoiding packets' collisions\nand improving the throughput significantly. We solve the problem using the\ndecentralized partially observable Markov Decision Process (Dec-POMDP)\nframework, where we allow each node to decide independently of the others how\nmany packet replicas to transmit. We enhance the proposed Q-learning based\nmethod with the concept of virtual experience, and we theoretically and\nexperimentally prove that convergence time is, thus, significantly reduced. The\nexperiments prove that our method leads to large throughput gains, in\nparticular when network traffic is heavy, and scales well with the size of the\nnetwork. To comprehend the effect of the problem's nature on the learning\ndynamics and vice versa, we investigate the waterfall effect, a severe\ndegradation in performance above a particular traffic load, typical for\ncodes-on-graphs and prove that our algorithm learns to alleviate it. \n\n"}
{"id": "1805.07743", "contents": "Title: Joint Path Selection and Rate Allocation Framework for 5G\n  Self-Backhauled mmWave Networks Abstract: Owing to severe path loss and unreliable transmission over a long distance at\nhigher frequency bands, we investigate the problem of path selection and rate\nallocation for multi-hop self-backhaul millimeter wave (mmWave) networks.\nEnabling multi-hop mmWave transmissions raises a potential issue of increased\nlatency, and thus, in this work we aim at addressing the fundamental questions:\nhow to select the best multi-hop paths and how to allocate rates over these\npaths subject to latency constraints? In this regard, we propose a new system\ndesign, which exploits multiple antenna diversity, mmWave bandwidth, and\ntraffic splitting techniques to improve the downlink transmission. The studied\nproblem is cast as a network utility maximization, subject to an upper delay\nbound constraint, network stability, and network dynamics. By leveraging\nstochastic optimization, the problem is decoupled into: path selection and rate\nallocation sub-problems, whereby a framework which selects the best paths is\nproposed using reinforcement learning techniques. Moreover, the rate allocation\nis a nonconvex program, which is converted into a convex one by using the\nsuccessive convex approximation method. Via mathematical analysis, we provide a\ncomprehensive performance analysis and convergence proofs for the proposed\nsolution. Numerical results show that our approach ensures reliable\ncommunication with a guaranteed probability of up to $99.9999\\%$, and reduces\nlatency by $50.64\\%$ and $92.9\\%$ as compared to baseline models. Furthermore,\nthe results showcase the key trade-off between latency and network arrival\nrate. \n\n"}
{"id": "1805.08429", "contents": "Title: Correctness and Fairness of Tendermint-core Blockchains Abstract: Tendermint-core blockchains (e.g. Cosmos) are considered today one of the\nmost viable alternatives for the highly energy consuming proof-of-work\nblockchains such as Bitcoin and Ethereum. Their particularity is that they aim\nat offering strong consistency (no forks) in an open system combining two\ningredients (i) a set of validators that generate blocks via a variant of\nPractical Byzantine Fault Tolerant (PBFT) consensus protocol and (ii) a\nselection strategy that dynamically selects nodes to be validators for the next\nblock via a proof-of-stake mechanism. However,the exact assumptions on the\nsystem model under which Tendermint underlying algorithms are correct and the\nexact properties Tendermint verifies have never been formally analyzed. The\ncontribution of this paper is two-fold. First, while formalizing Tendermint\nalgorithms we precisely characterize the system model and the exact problem\nsolved by Tendermint. We prove that in eventual synchronous systems a modified\nversion of Tendermint solves (i) under additional assumptions, a variant of\none-shot consensus for the validation of one single block and (ii) a variant of\nthe repeated consensus problem for multiple blocks. These results hold even if\nthe set of validators is hit by Byzantine failures, provided that for each\none-shot consensus instance less than one third of the validators is Byzantine.\nOur second contribution relates to the fairness of the rewarding mechanism. It\nis common knowledge that in permisionless blockchain systems the main threat is\nthe tragedy of commons that may yield the system to collapse if the rewarding\nmechanism is not adequate. Ad minimum the rewarding mechanism must be fair,\ni.e.distributing the rewards in proportion to the merit of participants. We\nprove, for the first time in blockchain systems, that in repeated-consensus\nbased blockchains there exists an (eventual) fair rewarding mechanism if and\nonly if the system is (eventual) synchronous. We also show that the original\nTendermint rewarding is not fair, however, a modification of the original\nprotocol makes it eventually fair. \n\n"}
{"id": "1805.09734", "contents": "Title: Johnson-Mehl Cell-based Analysis of UL Cellular Network with Coupled\n  User and BS Locations Abstract: In this work, we analyze the performance of the uplink (UL) of a cellular\nnetwork where the base station (BS) locations follow a homogeneous Poisson\npoint process (PPP), and the locations of users and BSs are spatially coupled.\nIn order to capture this coupling, we consider that users attached to a BS are\nlocated uniformly at random independently of each other in the Johnson-Mehl\n(JM) cell of that BS. For this system model, we derive analytical expressions\nfor the UL signal to interference ratio (SIR) coverage probability and average\nspectral efficiency (SE) of a typical user in the network. One of the key\nintermediate steps in our analysis is the approximate, but accurate,\ncharacterization of the area distribution of a typical JM cell. Another key\nintermediate step is the accurate statistical characterization of the point\nprocess formed by the interfering users that subsequently enables the coverage\nprobability analysis. We present coverage probability and SE results for a\ntypical user and study the interplay between different system parameters. \n\n"}
{"id": "1805.10783", "contents": "Title: ECD: An Edge Content Delivery and Update Framework in Mobile Edge\n  Computing Abstract: This article proposes an edge content delivery framework (ECD) based on\nmobile edge computing in the era of Internet of Things (IOT), to alleviate the\nload of the core network and improve the quality of experience (QoE) of mobile\nusers. Considering mobile devices become both the content consumers and\nproviders, and majority of the contents are unnecessary to be uploaded to the\ncloud datacenter, at the network edge, we deploy a content server to store the\nraw contents generated from the mobile users, and a cache pool to store the\ncontents that are frequently requested by mobile users in the ECD. The cache\npools are ranked and high ranked cache pools will store contents with higher\npopularity. Furthermore, we propose edge content delivery scheme and edge\ncontent update scheme, based on content popularity and cache pool ranking. The\ncontent delivery scheme is to efficiently deliver contents to mobile users,\nwhile the edge content update scheme is to mitigate the content generated by\nusers to appropriate cache pools based on its request frequently and cache poor\nranking. The edge content delivery is completely different from the content\ndelivery network and can further reduce the load on the core network. In\naddition, because the top ranking cache pools are prioritized for higher\npriority contents and the cache pools are prioritized for higher priority\ncontents and the cache pools are in proximity to the mobile users, the\nimmediately interactive response between mobile users and cache pools can be\nachieved. A representative case study of ECD is provided and open research\nissues are discussed. \n\n"}
{"id": "1805.11083", "contents": "Title: Potential and Pitfalls of Multi-Armed Bandits for Decentralized Spatial\n  Reuse in WLANs Abstract: Spatial Reuse (SR) has recently gained attention to maximize the performance\nof IEEE 802.11 Wireless Local Area Networks (WLANs). Decentralized mechanisms\nare expected to be key in the development of SR solutions for next-generation\nWLANs, since many deployments are characterized by being uncoordinated by\nnature. However, the potential of decentralized mechanisms is limited by the\nsignificant lack of knowledge with respect to the overall wireless environment.\nTo shed some light on this subject, we show the main considerations and\npossibilities of applying online learning to address the SR problem in\nuncoordinated WLANs. In particular, we provide a solution based on Multi-Armed\nBandits (MABs) whereby independent WLANs dynamically adjust their frequency\nchannel, transmit power and sensitivity threshold. To that purpose, we provide\ntwo different strategies, which refer to selfish and environment-aware\nlearning. While the former stands for pure individual behavior, the second one\nconsiders the performance experienced by surrounding networks, thus taking into\naccount the impact of individual actions on the environment. Through these two\nstrategies we delve into practical issues of applying MABs in wireless\nnetworks, such as convergence guarantees or adversarial effects. Our simulation\nresults illustrate the potential of the proposed solutions for enabling SR in\nfuture WLANs. We show that substantial improvements on network performance can\nbe achieved regarding throughput and fairness. \n\n"}
{"id": "1805.11308", "contents": "Title: In the IP of the Beholder: Strategies for Active IPv6 Topology Discovery Abstract: Existing methods for active topology discovery within the IPv6 Internet\nlargely mirror those of IPv4. In light of the large and sparsely populated\naddress space, in conjunction with aggressive ICMPv6 rate limiting by routers,\nthis work develops a different approach to Internet-wide IPv6 topology mapping.\nWe adopt randomized probing techniques in order to distribute probing load,\nminimize the effects of rate limiting, and probe at higher rates. Second, we\nextensively analyze the efficiency and efficacy of various IPv6 hitlists and\ntarget generation methods when used for topology discovery, and synthesize new\ntarget lists based on our empirical results to provide both breadth (coverage\nacross networks) and depth (to find potential subnetting). Employing our\nprobing strategy, we discover more than 1.3M IPv6 router interface addresses\nfrom a single vantage point. Finally, we share our prober implementation,\nsynthesized target lists, and discovered IPv6 topology results. \n\n"}
{"id": "1805.11506", "contents": "Title: A Long Way to the Top: Significance, Structure, and Stability of\n  Internet Top Lists Abstract: A broad range of research areas including Internet measurement, privacy, and\nnetwork security rely on lists of target domains to be analysed; researchers\nmake use of target lists for reasons of necessity or efficiency. The popular\nAlexa list of one million domains is a widely used example. Despite their\nprevalence in research papers, the soundness of top lists has seldom been\nquestioned by the community: little is known about the lists' creation,\nrepresentativity, potential biases, stability, or overlap between lists.\n  In this study we survey the extent, nature, and evolution of top lists used\nby research communities. We assess the structure and stability of these lists,\nand show that rank manipulation is possible for some lists. We also reproduce\nthe results of several scientific studies to assess the impact of using a top\nlist at all, which list specifically, and the date of list creation. We find\nthat (i) top lists generally overestimate results compared to the general\npopulation by a significant margin, often even an order of magnitude, and (ii)\nsome top lists have surprising change characteristics, causing high day-to-day\nfluctuation and leading to result instability. We conclude our paper with\nspecific recommendations on the use of top lists, and how to interpret results\nbased on top lists with caution. \n\n"}
{"id": "1805.11721", "contents": "Title: The Role of Caching in Future Communication Systems and Networks Abstract: This paper has the following ambitious goal: to convince the reader that\ncontent caching is an exciting research topic for the future communication\nsystems and networks. Caching has been studied for more than 40 years, and has\nrecently received increased attention from industry and academia. Novel caching\ntechniques promise to push the network performance to unprecedented limits, but\nalso pose significant technical challenges. This tutorial provides a brief\noverview of existing caching solutions, discusses seminal papers that open new\ndirections in caching, and presents the contributions of this Special Issue. We\nanalyze the challenges that caching needs to address today, considering also an\nindustry perspective, and identify bottleneck issues that must be resolved to\nunleash the full potential of this promising technique. \n\n"}
{"id": "1805.12090", "contents": "Title: Problem-Adapted Artificial Intelligence for Online Network Optimization Abstract: Future 5G wireless networks will rely on agile and automated network\nmanagement, where the usage of diverse resources must be jointly optimized with\nsurgical accuracy. A number of key wireless network functionalities (e.g.,\ntraffic steering, power control) give rise to hard optimization problems. What\nis more, high spatio-temporal traffic variability coupled with the need to\nsatisfy strict per slice/service SLAs in modern networks, suggest that these\nproblems must be constantly (re-)solved, to maintain close-to-optimal\nperformance. To this end, we propose the framework of Online Network\nOptimization (ONO), which seeks to maintain both agile and efficient control\nover time, using an arsenal of data-driven, online learning, and AI-based\ntechniques. Since the mathematical tools and the studied regimes vary widely\namong these methodologies, a theoretical comparison is often out of reach.\nTherefore, the important question `what is the right ONO technique?' remains\nopen to date. In this paper, we discuss the pros and cons of each technique and\npresent a direct quantitative comparison for a specific use case, using real\ndata. Our results suggest that carefully combining the insights of problem\nmodeling with state-of-the-art AI techniques provides significant advantages at\nreasonable complexity. \n\n"}
{"id": "1806.00276", "contents": "Title: Oblivious DNS: Practical Privacy for DNS Queries Abstract: Virtually every Internet communication typically involves a Domain Name\nSystem (DNS) lookup for the destination server that the client wants to\ncommunicate with. Operators of DNS recursive resolvers---the machines that\nreceive a client's query for a domain name and resolve it to a corresponding IP\naddress---can learn significant information about client activity. Past work,\nfor example, indicates that DNS queries reveal information ranging from web\nbrowsing activity to the types of devices that a user has in their home.\nRecognizing the privacy vulnerabilities associated with DNS queries, various\nthird parties have created alternate DNS services that obscure a user's DNS\nqueries from his or her Internet service provider. Yet, these systems merely\ntransfer trust to a different third party. We argue that no single party ought\nto be able to associate DNS queries with a client IP address that issues those\nqueries. To this end, we present Oblivious DNS (ODNS), which introduces an\nadditional layer of obfuscation between clients and their queries. To do so,\nODNS uses its own authoritative namespace; the authoritative servers for the\nODNS namespace act as recursive resolvers for the DNS queries that they\nreceive, but they never see the IP addresses for the clients that initiated\nthese queries. We present an initial deployment of ODNS; our experiments show\nthat ODNS introduces minimal performance overhead, both for individual queries\nand for web page loads. We design ODNS to be compatible with existing DNS\nprotocols and infrastructure, and we are actively working on an open standard\nwith the IETF. \n\n"}
{"id": "1806.00676", "contents": "Title: A Geometric Approach for Real-time Monitoring of Dynamic Large Scale\n  Graphs: AS-level graphs illustrated Abstract: The monitoring of large dynamic networks is a major chal- lenge for a wide\nrange of application. The complexity stems from properties of the underlying\ngraphs, in which slight local changes can lead to sizable variations of global\nprop- erties, e.g., under certain conditions, a single link cut that may be\noverlooked during monitoring can result in splitting the graph into two\ndisconnected components. Moreover, it is often difficult to determine whether a\nchange will propagate globally or remain local. Traditional graph theory\nmeasure such as the centrality or the assortativity of the graph are not\nsatisfying to characterize global properties of the graph. In this paper, we\ntackle the problem of real-time monitoring of dynamic large scale graphs by\ndeveloping a geometric approach that leverages notions of geometric curvature\nand recent development in graph embeddings using Ollivier-Ricci curvature [47].\nWe illustrate the use of our method by consid- ering the practical case of\nmonitoring dynamic variations of global Internet using topology changes\ninformation provided by combining several BGP feeds. In particular, we use our\nmethod to detect major events and changes via the geometry of the embedding of\nthe graph. \n\n"}
{"id": "1806.02088", "contents": "Title: Architectures and Key Technical Challenges for 5G Systems Incorporating\n  Satellites Abstract: Satellite Communication systems are a promising solution to extend and\ncomplement terrestrial networks in unserved or under-served areas. This aspect\nis reflected by recent commercial and standardisation endeavours. In\nparticular, 3GPP recently initiated a Study Item for New Radio-based, i.e., 5G,\nNon-Terrestrial Networks aimed at deploying satellite systems either as a\nstand-alone solution or as an integration to terrestrial networks in mobile\nbroadband and machine-type communication scenarios. However, typical satellite\nchannel impairments, as large path losses, delays, and Doppler shifts, pose\nsevere challenges to the realisation of a satellite-based NR network. In this\npaper, based on the architecture options currently being discussed in the\nstandardisation fora, we discuss and assess the impact of the satellite channel\ncharacteristics on the physical and Medium Access Control layers, both in terms\nof transmitted waveforms and procedures for enhanced Mobile BroadBand (eMBB)\nand NarrowBand-Internet of Things (NB-IoT) applications. The proposed analysis\nshows that the main technical challenges are related to the PHY/MAC procedures,\nin particular Random Access (RA), Timing Advance (TA), and Hybrid Automatic\nRepeat reQuest (HARQ) and, depending on the considered service and\narchitecture, different solutions are proposed. \n\n"}
{"id": "1806.03255", "contents": "Title: Automatically Generating a Large, Culture-Specific Blocklist for China Abstract: Internet censorship measurements rely on lists of websites to be tested, or\n\"block lists\" that are curated by third parties. Unfortunately, many of these\nlists are not public, and those that are tend to focus on a small group of\ntopics, leaving other types of sites and services untested. To increase and\ndiversify the set of sites on existing block lists, we use natural language\nprocessing and search engines to automatically discover a much wider range of\nwebsites that are censored in China. Using these techniques, we create a list\nof 1125 websites outside the Alexa Top 1,000 that cover Chinese politics,\nminority human rights organizations, oppressed religions, and more.\nImportantly, $\\textit{none of the sites we discover are present on the current\nlargest block list}$. The list that we develop not only vastly expands the set\nof sites that current Internet measurement tools can test, but it also deepens\nour understanding of the nature of content that is censored in China. We have\nreleased both this new block list and the code for generating it. \n\n"}
{"id": "1806.04193", "contents": "Title: Stochastic Geometric Coverage Analysis in mmWave Cellular Networks with\n  Realistic Channel and Antenna Radiation Models Abstract: Millimeter-wave (mmWave) bands will play an important role in 5G wireless\nsystems. The system performance can be assessed by using models from stochastic\ngeometry that cater for the directivity in the desired signal transmissions as\nwell as the interference, and by calculating the\nsignal-to-interference-plus-noise ratio (SINR) coverage. Nonetheless, the\ncorrectness of the existing coverage expressions derived through stochastic\ngeometry may be questioned, as it is not clear whether they capture the impact\nof the detailed mmWave channel and antenna features. In this study, we propose\nan SINR coverage analysis framework that includes realistic channel model (from\nNYU) and antenna element radiation patterns (with isotropic/directional\nradiation). We first introduce two parameters, aligned gain and misaligned\ngain, associated with the desired signal beam and the interfering signal beam,\nrespectively. We provide the distributions of the aligned and misaligned gains\nthrough curve fitting of system-simulation results. The distribution of these\ngains is used to determine the distribution of the SINR. We compare the\nobtained analytical SINR coverage with the corresponding SINR coverage\ncalculated via system-level simulations. The results show that both aligned and\nmisaligned gains can be modeled as exponential-logarithmically distributed\nrandom variables with the highest accuracy, and can further be approximated as\nexponentially distributed random variables with reasonable accuracy. These\napproximations are thus expected to be useful to evaluate the system\nperformance under ultra-reliable and low-latency communication (URLLC) and\nevolved mobile broadband (eMBB) scenarios, respectively. \n\n"}
{"id": "1806.04311", "contents": "Title: Opportunistic Edge Computing: Concepts, Opportunities and Research\n  Challenges Abstract: The growing need for low-latency access to computing resources has motivated\nthe introduction of edge computing, where resources are strategically placed at\nthe access networks. Unfortunately, edge computing infrastructures like fogs\nand cloudlets have limited scalability and may be prohibitively expensive to\ninstall given the vast edge of the Internet. In this paper, we present\nOpportunistic Edge Computing (OEC), a new computing paradigm that provides a\nframework to create scalable infrastructures at the edge using end-user\ncontributed resources. One of the goals of OEC is to place resources where\nthere is high demand for them by incentivizing people to share their resources.\nThis paper defines the OEC paradigm and the involved stakeholders and puts\nforward a management framework to build, manage and monitor scalable edge\ninfrastructures. It also highlights the key differences between the OEC\ncomputing models and the existing computing models and shed the light on early\nworks on the topic. The paper also presents preliminary experimental results\nthat highlight the benefits and the limitations of OEC compared to the regular\ncloud computing deployment and the Fog deployment. It finally summarizes key\nresearch directions pertaining to resource management in OEC environments. \n\n"}
{"id": "1806.04386", "contents": "Title: Rate Control under Finite Blocklength for Downlink Cellular Networks\n  with Reliability Constraints Abstract: Coming cellular systems are envisioned to open up to new services and\napplications with high reliability and low latency requirements. In this paper\nwe focus on the rate allocation problem in downlink cellular networks with\nRayleigh fading and stringent reliability constraints. We propose a rate\ncontrol strategy to cope with those requirements making use only of topological\ncharacteristics of the scenario, the reliability constraint and the number of\nantennas that are available at the receiver side. Numerical results show the\nfeasibility of the ultra-reliable operation when the number of antennas\nincreases, and also that our results remain valid even when operating at short\nblocklength as far as the amount of information to be transmitted is not too\nsmall. \n\n"}
{"id": "1806.04589", "contents": "Title: Computation Rate Maximization in UAV-Enabled Wireless Powered\n  Mobile-Edge Computing Systems Abstract: Mobile edge computing (MEC) and wireless power transfer (WPT) are two\npromising techniques to enhance the computation capability and to prolong the\noperational time of low-power wireless devices that are ubiquitous in Internet\nof Things. However, the computation performance and the harvested energy are\nsignificantly impacted by the severe propagation loss. In order to address this\nissue, an unmanned aerial vehicle (UAV)-enabled MEC wireless powered system is\nstudied in this paper. The computation rate maximization problems in a\nUAV-enabled MEC wireless powered system are investigated under both partial and\nbinary computation offloading modes, subject to the energy harvesting causal\nconstraint and the UAV's speed constraint. These problems are non-convex and\nchallenging to solve. A two-stage algorithm and a three-stage alternative\nalgorithm are respectively proposed for solving the formulated problems. The\nclosed-form expressions for the optimal central processing unit frequencies,\nuser offloading time, and user transmit power are derived. The optimal\nselection scheme on whether users choose to locally compute or offload\ncomputation tasks is proposed for the binary computation offloading mode.\nSimulation results show that our proposed resource allocation schemes\noutperforms other benchmark schemes. The results also demonstrate that the\nproposed schemes converge fast and have low computational complexity. \n\n"}
{"id": "1806.05026", "contents": "Title: An Analytical Model for Wireless Mesh Networks with Collision-Free TDMA\n  and Finite Queues Abstract: Wireless mesh networks are a promising technology for connecting sensors and\nactuators with high flexibility and low investment costs. In industrial\napplications, however, reliability is essential. Therefore, two time-slotted\nmedium access methods, DSME and TSCH, were added to the IEEE 802.15.4 standard.\nThey allow collision-free communication in multi-hop networks and provide\nchannel hopping for mitigating external interferences. The slot schedule used\nin these networks is of high importance for the network performance. This paper\nsupports the development of efficient schedules by providing an analytical\nmodel for the assessment of such schedules, focused on TSCH. A Markov chain\nmodel for the finite queue on every node is introduced that takes the slot\ndistribution into account. The models of all nodes are interconnected to\ncalculate network metrics such as packet delivery ratio, end-to-end delay and\nthroughput. An evaluation compares the model with a simulation of the Orchestra\nschedule. The model is applied to Orchestra as well as to two simple\ndistributed scheduling algorithms to demonstrate the importance of\ntraffic-awareness for achieving high throughput. \n\n"}
{"id": "1806.05265", "contents": "Title: A Hybrid RF-VLC System for Energy Efficient Wireless Access Abstract: In this paper, we propose a new paradigm in designing and realizing energy\nefficient wireless indoor access networks, namely, a hybrid system enabled by\ntraditional RF access, such as WiFi, as well as the emerging visible light\ncommunication (VLC). VLC facilitates the great advantage of being able to\njointly perform illumination and communications, and little extra power beyond\nillumination is required to empower communications, thus rendering wireless\naccess with almost zero power consumption. On the other hand, when illumination\nis not required from the light source, the energy consumed by VLC could be more\nthan that consumed by the RF. By capitalizing on the above properties, the\nproposed hybrid RF-VLC system is more energy efficient and more adaptive to the\nillumination conditions than the individual VLC or RF systems. To demonstrate\nthe viability of the proposed system, we first formulate the problem of\nminimizing the power consumption of the hybrid RF-VLC system while satisfying\nthe users requests and maintaining acceptable level of illumination, which is\nNP-complete. Therefore, we divide the problem into two subproblems. In the\nfirst subproblems, we determine the set of VLC access points (AP) that needs to\nbe turned on to satisfy the illumination requirements. Given this set, we turn\nour attention to satisfying the users' requests for real-time communications,\nand we propose a randomized online algorithm that, against an oblivious\nadversary, achieves a competitive ratio of $\\log(N)\\log(M)$ with probability of\nsuccess $1 - \\frac{1}{N}$, where $N$ is the number of users and $M$ is the\nnumber of VLC and RF APs. We also show that the best online algorithm to solve\nthis problem can achieve a competitive ratio of $\\log(M)$. Simulation results\nfurther demonstrate the advantages of the hybrid system. \n\n"}
{"id": "1806.05776", "contents": "Title: Tiny Codes for Guaranteeable Delay Abstract: Future 5G systems will need to support ultra-reliable low-latency\ncommunications scenarios. From a latency-reliability viewpoint, it is\ninefficient to rely on average utility-based system design. Therefore, we\nintroduce the notion of guaranteeable delay which is the average delay plus\nthree standard deviations of the mean. We investigate the trade-off between\nguaranteeable delay and throughput for point-to-point wireless erasure links\nwith unreliable and delayed feedback, by bringing together signal flow\ntechniques to the area of coding. We use tiny codes, i.e. sliding window by\ncoding with just 2 packets, and design three variations of selective-repeat ARQ\nprotocols, by building on the baseline scheme, i.e. uncoded ARQ, developed by\nAusavapattanakun and Nosratinia: (i) Hybrid ARQ with soft combining at the\nreceiver; (ii) cumulative feedback-based ARQ without rate adaptation; and (iii)\nCoded ARQ with rate adaptation based on the cumulative feedback. Contrasting\nthe performance of these protocols with uncoded ARQ, we demonstrate that HARQ\nperforms only slightly better, cumulative feedback-based ARQ does not provide\nsignificant throughput while it has better average delay, and Coded ARQ can\nprovide gains up to about 40% in terms of throughput. Coded ARQ also provides\ndelay guarantees, and is robust to various challenges such as imperfect and\ndelayed feedback, burst erasures, and round-trip time fluctuations. This\nfeature may be preferable for meeting the strict end-to-end latency and\nreliability requirements of future use cases of ultra-reliable low-latency\ncommunications in 5G, such as mission-critical communications and industrial\ncontrol for critical control messaging. \n\n"}
{"id": "1806.06125", "contents": "Title: Impact of Channel Models on the End-to-End Performance of mmWave\n  Cellular Networks Abstract: Communication at mmWave frequencies is one of the major innovations of the\nfifth generation of cellular networks, because of the potential multi-gigabit\ndata rate given by the large amounts of available bandwidth. The mmWave\nchannel, however, makes reliable communications particularly challenging, given\nthe harsh propagation environment and the sensitivity to blockage. Therefore,\nproper modeling of the mmWave channel is fundamental for accurate results in\nsystem simulations of mmWave cellular networks. Nonetheless, complex models,\nsuch as the 3GPP channel model for frequencies above 6 GHz, may introduce a\nsignificant overhead in terms of computational complexity. In this paper we\ninvestigate the trade offs related to the accuracy and the simplicity of the\nchannel model in end-to-end network simulations, and the impact on the\nperformance evaluation of transport protocols. \n\n"}
{"id": "1806.06185", "contents": "Title: EdgeChain: An Edge-IoT Framework and Prototype Based on Blockchain and\n  Smart Contracts Abstract: The emerging Internet of Things (IoT) is facing significant scalability and\nsecurity challenges. On the one hand, IoT devices are \"weak\" and need external\nassistance. Edge computing provides a promising direction addressing the\ndeficiency of centralized cloud computing in scaling massive number of devices.\nOn the other hand, IoT devices are also relatively \"vulnerable\" facing\nmalicious hackers due to resource constraints. The emerging blockchain and\nsmart contracts technologies bring a series of new security features for IoT\nand edge computing. In this paper, to address the challenges, we design and\nprototype an edge-IoT framework named \"EdgeChain\" based on blockchain and smart\ncontracts. The core idea is to integrate a permissioned blockchain and the\ninternal currency or \"coin\" system to link the edge cloud resource pool with\neach IoT device' account and resource usage, and hence behavior of the IoT\ndevices. EdgeChain uses a credit-based resource management system to control\nhow much resource IoT devices can obtain from edge servers, based on\npre-defined rules on priority, application types and past behaviors. Smart\ncontracts are used to enforce the rules and policies to regulate the IoT device\nbehavior in a non-deniable and automated manner. All the IoT activities and\ntransactions are recorded into blockchain for secure data logging and auditing.\nWe implement an EdgeChain prototype and conduct extensive experiments to\nevaluate the ideas. The results show that while gaining the security benefits\nof blockchain and smart contracts, the cost of integrating them into EdgeChain\nis within a reasonable and acceptable range. \n\n"}
{"id": "1806.06620", "contents": "Title: Machine Learning Based Uplink Transmission Power Prediction for LTE and\n  Upcoming 5G Networks using Passive Downlink Indicators Abstract: Energy-aware system design is an important optimization task for static and\nmobile Internet of Things (IoT)-based sensor nodes, especially for highly\nresource-constrained vehicles such as mobile robotic systems. For 4G/5G-based\ncellular communication systems, the effective transmission power of uplink data\ntransmissions is of crucial importance for the overall system power\nconsumption. Unfortunately, this information is usually hidden within\noff-the-shelf modems and mobile handsets and can therefore not be exploited for\nenabling green communication. Moreover, the dynamic transmission power control\nbehavior of the mobile device is not even explicitly modeled in most of the\nestablished simulation frameworks. In this paper, we present a novel machine\nlearning-based approach for forecasting the resulting uplink transmission power\nused for data transmissions based on the available passive network quality\nindicators and application-level information. The model is derived from\ncomprehensive field measurements of drive tests performed in a public cellular\nnetwork and can be parameterized for integrating all measurements a given\ntarget platform is able to provide into the prediction process. In a comparison\nof three different machine learning methods, Random-Forest models thoroughly\nperformed best with a mean average error of 3.166 dB. As the absolute sum of\nerrors converges towards zero and falls below 1 dB after 28 predictions in\naverage, the approach is well-suited for long-term power estimations. \n\n"}
{"id": "1806.07038", "contents": "Title: Few Throats to Choke: On the Current Structure of the Internet Abstract: The original design of the Internet was a resilient, distributed system, that\nmaybe able to route around (and therefore recover from) massive disruption ---\nup to and including nuclear war. However, network routing effects and business\ndecisions cause traffic to often be routed through a relatively small set of\nAutonomous Systems (ASes). This is not merely an academic issue; it has\npractical implications --- some of these frequently appearing ASes are hosted\nin censorious nations. Other than censoring their own citizens' network access,\nsuch ASes may inadvertently filter traffic for other foreign customer ASes.\n  In this paper, we examine the extent of routing centralization in the\nInternet; identify the major players who control the \"Internet backbone\"; and\npoint out how many of these are, in fact, under the jurisdiction of censorious\ncountries (specifically, Russia, China, and India). Further, we show that China\nand India are not only the two largest nations by number of Internet users, but\nthat many users in free and democratic countries are affected by collateral\ndamage caused due to censorship by such countries. \n\n"}
{"id": "1806.07302", "contents": "Title: Trust Anchors in Software Defined Networks Abstract: Advances in software virtualization and network processing lead to increasing\nnetwork softwarization. Software network elements running on commodity\nplatforms replace or complement hardware components in cloud and mobile network\ninfrastructure. However, such com- modity platforms have a large attack surface\nand often lack granular control and tight integration of the underlying\nhardware and software stack. Often, software network elements are either\nthemselves vulnerable to software attacks or can be compromised through the\nbloated trusted computing base. To address this, we protect the core security\nassets of network elements - authentication credentials and cryptographic\ncontext - by provisioning them to and maintaining them exclusively in isolated\nexecution environments. We complement this with a secure and scalable mechanism\nto enroll network elements into software defined networks. Our evaluation\nresults show a negligible impact on run-time performance and only a moderate\nperformance impact at the deployment stage. \n\n"}
{"id": "1806.07476", "contents": "Title: CommunityWatch: The Swiss-Army Knife of BGP Anomaly Detection Abstract: We present CommunityWatch, an open-source system that enables timely and\naccurate detection of BGP routing anomalies. CommunityWatch leverages meta-data\nencoded by AS operators on their advertised routes through the BGP Communities\nattribute. The BGP Communities values lack standardized semantics, offering the\nflexibility to attach a wide range of information, including AS relationships,\nlocation data, and route redistribution policies. Therefore, parsing and\ncorrelating Community values and their dynamics enables the detection and\ntracking of a variety of routing anomalies. We exhibit the efficacy of\nCommunityWatch through the detection of three different types of anomalies:\ninfrastructure outages, route leaks, and traffic blackholing. \n\n"}
{"id": "1806.07840", "contents": "Title: Edge Intelligence: On-Demand Deep Learning Model Co-Inference with\n  Device-Edge Synergy Abstract: As the backbone technology of machine learning, deep neural networks (DNNs)\nhave have quickly ascended to the spotlight. Running DNNs on\nresource-constrained mobile devices is, however, by no means trivial, since it\nincurs high performance and energy overhead. While offloading DNNs to the cloud\nfor execution suffers unpredictable performance, due to the uncontrolled long\nwide-area network latency. To address these challenges, in this paper, we\npropose Edgent, a collaborative and on-demand DNN co-inference framework with\ndevice-edge synergy. Edgent pursues two design knobs: (1) DNN partitioning that\nadaptively partitions DNN computation between device and edge, in order to\nleverage hybrid computation resources in proximity for real-time DNN inference.\n(2) DNN right-sizing that accelerates DNN inference through early-exit at a\nproper intermediate DNN layer to further reduce the computation latency. The\nprototype implementation and extensive evaluations based on Raspberry Pi\ndemonstrate Edgent's effectiveness in enabling on-demand low-latency edge\nintelligence. \n\n"}
{"id": "1806.09466", "contents": "Title: Optimized Video Streaming over Cloud: A Stall-Quality Trade-off Abstract: As video-streaming services have expanded and improved, cloud-based video has\nevolved into a necessary feature of any successful business for reaching\ninternal and external audiences. In this paper, video streaming over\ndistributed storage is considered where the video segments are encoded using an\nerasure code for better reliability. There are multiple parallel streams\nbetween each server and the edge router. For each client request, we need to\ndetermine the subset of servers to get the data, as well as one of the parallel\nstream from each chosen server. In order to have this scheduling, this paper\nproposes a two-stage probabilistic scheduling. The selection of video quality\nis also chosen with a certain probability distribution. With these parameters,\nthe playback time of video segments is determined by characterizing the\ndownload time of each coded chunk for each video segment. Using the playback\ntimes, a bound on the moment generating function of the stall duration is used\nto bound the mean stall duration. Based on this, we formulate an optimization\nproblem to jointly optimize the convex combination of mean stall duration and\naverage video quality for all requests, where the two-stage probabilistic\nscheduling, probabilistic video quality selection, bandwidth split among\nparallel streams, and auxiliary bound parameters can be chosen. This non-convex\nproblem is solved using an efficient iterative algorithm. Evaluation results\nshow significant improvement in QoE metrics for cloud-based video as compared\nto the considered baselines. \n\n"}
{"id": "1806.09582", "contents": "Title: Traffic Differentiation in Dense WLANs with CSMA/ECA-DR MAC Protocol Abstract: In today's WLANs, scheduling of packet transmissions solely relies on the\ncollision and success a station may experience. To better support traffic\ndifferentiation in dense WLANs, in this paper, we propose a distributed\nreservation mechanism for the Carrier Sense Multiple Access Extended Collision\nAvoidance (CSMA/ECA) MAC protocol, termed CSMA/ECA-DR, based on which stations\ncan collaboratively achieve higher network performance. In addition, proper\nContention Window (CW) will be chosen based on the instantaneously estimated\nnumber of active contenders in the network. Simulation results from dense\nscenarios with traffic differentiation demonstrate that CSMA/ECA-DR can greatly\nimprove the efficiency of WLANs for traffic differentiation even with large\nnumbers of contenders. \n\n"}
{"id": "1806.09980", "contents": "Title: Toward Performance Optimization in IoT-based Next-Gen Wireless Sensor\n  Networks Abstract: In this paper, we propose a novel framework for performance optimization in\nInternet of Things (IoT)-based next-generation wireless sensor networks. In\nparticular, a computationally-convenient system is presented to combat two\nmajor research problems in sensor networks. First is the conventionally-tackled\nresource optimization problem which triggers the drainage of battery at a\nfaster rate within a network. Such drainage promotes inefficient resource usage\nthereby causing sudden death of the network. The second main bottleneck for\nsuch networks is that of data degradation. This is because the nodes in such\nnetworks communicate via a wireless channel, where the inevitable presence of\nnoise corrupts the data making it unsuitable for practical applications.\nTherefore, we present a layer-adaptive method via 3-tier communication\nmechanism to ensure the efficient use of resources. This is supported with a\nmathematical coverage model that deals with the formation of coverage holes. We\nalso present a transform-domain based robust algorithm to effectively remove\nthe unwanted components from the data. Our proposed framework offers a handy\nalgorithm that enjoys desirable complexity for real-time applications as shown\nby the extensive simulation results. \n\n"}
{"id": "1806.10521", "contents": "Title: Reliable Wireless Multi-Hop Networks with Decentralized Slot Management:\n  An Analysis of IEEE 802.15.4 DSME Abstract: Wireless communication is a key element in the realization of the Industrial\nInternet of Things for flexible and cost-efficient monitoring and control of\nindustrial processes. Wireless mesh networks using IEEE 802.15.4 have a high\npotential for executing monitoring and control tasks with low energy\nconsumption and low costs for deployment and maintenance. However, conventional\nmedium access techniques based on carrier sensing cannot provide the required\nreliability for industrial applications. Therefore, the standard was extended\nwith techniques for time-slotted medium access on multiple channels. In this\npaper, we present openDSME, a comprehensive implementation of the Deterministic\nand Synchronous Multi-channel Extension (DSME) and propose a method for\ntraffic-aware and decentralized slot scheduling to enable scalable wireless\nindustrial networks. The performance of DSME and our implementation is\ndemonstrated in the OMNeT++ simulator and on a physically deployed wireless\nnetwork in the FIT/IoT-LAB. It is shown that in the given scenarios, twice as\nmuch traffic can be delivered reliably by using DSME instead of CSMA/CA and\nthat the energy consumption can be reduced significantly. The paper is\ncompleted by presenting important trade-offs for parameter selection and by\nuncovering open issues of the current specification that call for further\neffort in research and standardization. \n\n"}
{"id": "1807.00324", "contents": "Title: Joint Failure Recovery, Fault Prevention, and Energy-efficient Resource\n  Management for Real-time SFC in Fog-supported SDN Abstract: In this paper, we focus on the problems of traffic engineering, failure\nrecovery, fault prevention, and Service Function Chain (SFC) with reliability\nand energy consumption constraints in Software Defined Networks (SDN). These\ntypes of deployments use Fog computing as an emerging paradigm to manage the\ndistributed small-size traffic flows passing through the SDN-enabled switches\n(possibly Fog Nodes). The main aim of this integration is to support service\ndelivery in real-time, failure recovery, and fault-awareness in an SFC context.\nFirstly, we present an architecture for Failure Recovery and Fault Prevention\ncalled FRFP; this is a multi-tier structure in which the real-time traffic\nflows pass through SDN-enabled switches to jointly decrease the network\nside-effects of flow rerouting and energy consumption of the Fog Nodes. We then\nmathematically formulate an optimization problem called the Optimal\nFog-Supported Energy-Aware SFC rerouting algorithm (OFES) and propose a\nnear-optimal heuristic called Heuristic OFES (HFES) to solve the corresponding\nproblem in polynomial time. In this way, the energy consumption and the\nreliability of the selected paths are optimized, while the Quality of Service\nconstraints are met and the network congestion is minimized. In a reliability\ncontext, the focus of this work is on fault prevention; however, since we use a\nreallocation technique, the proposed scheme can be used as a failure recovery\nscheme. We compare the performance of HFES and OFES in terms of power\nconsumption, average path length, fault probability, network side-effects, link\nutilization, and Fog Node utilization. Additionally, we analyze the\ncomputational complexity of HFES. We use a real-world network topology to\nevaluate our algorithm. The simulation results show that the heuristic\nalgorithm is applicable to large-scale networks. \n\n"}
{"id": "1807.00464", "contents": "Title: Leveraging the Channel as a Sensor: Real-time Vehicle Classification\n  Using Multidimensional Radio-fingerprinting Abstract: Upcoming Intelligent Transportation Systems (ITSs) will transform roads from\nstatic resources to dynamic Cyber Physical Systems (CPSs) in order to satisfy\nthe requirements of future vehicular traffic in smart city environments.\nUp-to-date information serves as the basis for changing street directions as\nwell as guiding individual vehicles to a fitting parking slot. In this context,\nnot only abstract indicators like traffic flow and density are required, but\nalso data about mobility parameters and class information of individual\nvehicles. Consequently, accurate and reliable systems that are capable of\nproviding these kinds of information in real-time are highly demanded. In this\npaper, we present a system for classifying vehicles based on their\nradio-fingerprints which applies cutting-edge machine learning models and can\nbe non-intrusively installed into the existing road infrastructure in an ad-hoc\nmanner. In contrast to other approaches, it is able to provide accurate\nclassification results without causing privacy-violations or being vulnerable\nto challenging weather conditions. Moreover, it is a promising candidate for\nlarge-scale city deployments due to its cost-efficient installation and\nmaintenance properties. The proposed system is evaluated in a comprehensive\nfield evaluation campaign within an experimental live deployment on a German\nhighway, where it is able to achieve a binary classification success ratio of\nmore than 99% and an overall accuracy of 89.15% for a fine-grained\nclassification task with nine different classes. \n\n"}
{"id": "1807.01093", "contents": "Title: Hierarchical Capacity Provisioning for Fog Computing Abstract: The concept of fog computing is centered around providing computation\nresources at the edge of network, thereby reducing the latency and improving\nthe quality of service. However, it is still desirable to investigate how and\nwhere at the edge of the network the computation capacity should be\nprovisioned. To this end, we propose a hierarchical capacity provisioning\nscheme. In particular, we consider a two-tier network architecture consisting\nof shallow and deep cloudlets and explore the benefits of hierarchical capacity\nbased on queueing analysis. Moreover, we explore two different network\nscenarios in which the network delay between the two tiers is negligible as\nwell as the case that the deep cloudlet is located somewhere deeper in the\nnetwork and thus the delay is significant. More importantly, we model the first\nnetwork delay scenario with bufferless shallow cloudlets as well as the second\nscenario with finite-size buffer shallow cloudlets, and formulate an\noptimization problem for each model. We also use stochastic ordering to solve\nthe optimization problem formulated for the first model and an upper bound\nbased technique is proposed for the second model. The performance of the\nproposed scheme is evaluated via simulations in which we show the accuracy of\nthe proposed upper bound technique as well as the queue length estimation\napproach for both randomly generated input and real trace data. \n\n"}
{"id": "1807.01147", "contents": "Title: FastTrack: Minimizing Stalls for CDN-based Over-the-top Video Streaming\n  Systems Abstract: Traffic for internet video streaming has been rapidly increasing and is\nfurther expected to increase with the higher definition videos and IoT\napplications, such as 360 degree videos and augmented virtual reality\napplications. While efficient management of heterogeneous cloud resources to\noptimize the quality of experience is important, existing work in this problem\nspace often left out important factors. In this paper, we present a model for\ndescribing a today's representative system architecture for video streaming\napplications, typically composed of a centralized origin server and several CDN\nsites. Our model comprehensively considers the following factors: limited\ncaching spaces at the CDN sites, allocation of CDN for a video request, choice\nof different ports from the CDN, and the central storage and bandwidth\nallocation. With the model, we focus on minimizing a performance metric, stall\nduration tail probability (SDTP), and present a novel, yet efficient, algorithm\nto solve the formulated optimization problem. The theoretical bounds with\nrespect to the SDTP metric are also analyzed and presented. Our extensive\nsimulation results demonstrate that the proposed algorithms can significantly\nimprove the SDTP metric, compared to the baseline strategies. Small-scale video\nstreaming system implementation in a real cloud environment further validates\nour results. \n\n"}
{"id": "1807.01645", "contents": "Title: Fast Collision Simulation for Cyclic Wireless Protocols Abstract: With most modern smartphones supporting wireless protocols such as Bluetooth\nLow Energy (BLE) or ANT+, the number of networks are growing rapidly.\nTherefore, collisions among multiple networks need to be considered for\nchoosing the appropriate protocol parameters. With growing numbers of networks,\nsimulations for estimating the collision rate become computationally very\ncomplex and lengthy. The large simulation times therefore constitute a major\nlimitation in the analysis of complex cases. In this paper, we present a novel\nsimulation technique which can speed up collision simulations by one order of\nmagnitude in realistic situations. Whenever the transmission of a packet is\nsimulated, the cyclic nature of protocols like BLE is exploited to predict the\nnext packet that has a chance of colliding. All transmissions in between can be\nskipped without affecting the simulation results. Based on the transmission\nintervals of the networks, one can compute a certain shrinkage per cycle of the\ntime offset between their packets. Using this shrinkage and the current offset\nbetween the starting times of any two packets, our proposed simulation model\ncan accurately predict the next pair of packets that needs to be simulated.\nWhereas our proposed technique aims at the BLE protocol, the theory is generic\nand can be used for many other cyclic protocols such as ANT/ANT+ as well. \n\n"}
{"id": "1807.02567", "contents": "Title: Deep Learning for Launching and Mitigating Wireless Jamming Attacks Abstract: An adversarial machine learning approach is introduced to launch jamming\nattacks on wireless communications and a defense strategy is presented. A\ncognitive transmitter uses a pre-trained classifier to predict the current\nchannel status based on recent sensing results and decides whether to transmit\nor not, whereas a jammer collects channel status and ACKs to build a deep\nlearning classifier that reliably predicts the next successful transmissions\nand effectively jams them. This jamming approach is shown to reduce the\ntransmitter's performance much more severely compared with random or\nsensing-based jamming. The deep learning classification scores are used by the\njammer for power control subject to an average power constraint. Next, a\ngenerative adversarial network (GAN) is developed for the jammer to reduce the\ntime to collect the training dataset by augmenting it with synthetic samples.\nAs a defense scheme, the transmitter deliberately takes a small number of wrong\nactions in spectrum access (in form of a causative attack against the jammer)\nand therefore prevents the jammer from building a reliable classifier. The\ntransmitter systematically selects when to take wrong actions and adapts the\nlevel of defense to mislead the jammer into making prediction errors and\nconsequently increase its throughput. \n\n"}
{"id": "1807.03454", "contents": "Title: Using Complex Network Theory for Temporal Locality in Network Traffic\n  Flows Abstract: Monitoring the interaction behaviors of network traffic flows and detecting\nunwanted Internet applications and anomalous flows have become a challenging\nproblem, since many applications obfuscate their network traffic flow using\nunregistered port numbers or payload encryption. In this paper, the temporal\nlocality complex network model--TLCN is proposed as a way to monitor, analyze\nand visualize network traffic flows. TLCNs model the interaction behaviors of\nlarge-scale network traffic flows, where the nodes and the edges can be defined\nto represent different flow levels and flow interactions separately. Then, the\nstatistical characteristics and dynamic behaviors of the TLCNs are studied to\nrepresent TLCN's structure representing ability to the flow interactions.\nAccording to the analysis of TLCN statistical characteristics with different\nInternet applications, we found that the weak interaction flows prefer to form\nthe small-world TLCN and the strong interaction flows prefer to the scale-free\nTLCN. In the studies of anomaly behaviors of TLCNs, the network structure of\nattacked TLCNs can have a remarkable feature for three attack patterns, and the\nevolution of TLCNs exhibits a good consistency between TLCN structure and\nattack process. With the introduction of TLCNs, we are able to harness a wealth\nof tools and graph modeling techniques from a diverse set of disciplines. \n\n"}
{"id": "1807.03515", "contents": "Title: A Reinforcement Learning Approach to Jointly Adapt Vehicular\n  Communications and Planning for Optimized Driving Abstract: Our premise is that autonomous vehicles must optimize communications and\nmotion planning jointly. Specifically, a vehicle must adapt its motion plan\nstaying cognizant of communications rate related constraints and adapt the use\nof communications while being cognizant of motion planning related restrictions\nthat may be imposed by the on-road environment. To this end, we formulate a\nreinforcement learning problem wherein an autonomous vehicle jointly chooses\n(a) a motion planning action that executes on-road and (b) a communications\naction of querying sensed information from the infrastructure. The goal is to\noptimize the driving utility of the autonomous vehicle. We apply the Q-learning\nalgorithm to make the vehicle learn the optimal policy, which makes the optimal\nchoice of planning and communications actions at any given time. We demonstrate\nthe ability of the optimal policy to smartly adapt communications and planning\nactions, while achieving large driving utilities, using simulations. \n\n"}
{"id": "1807.03930", "contents": "Title: Robust Beamforming Design in a NOMA Cognitive Radio Network Relying on\n  SWIPT Abstract: This paper studies a multiple-input single-output non-orthogonal multiple\naccess cognitive radio network relying on simultaneous wireless information and\npower transfer. A realistic non-linear energy harvesting model is applied and a\npower splitting architecture is adopted at each secondary user (SU). Since it\nis difficult to obtain perfect channel state information (CSI) in practice,\ninstead either a bounded or gaussian CSI error model is considered. Our robust\nbeamforming and power splitting ratio are jointly designed for two problems\nwith different objectives, namely that of minimizing the transmission power of\nthe cognitive base station and that of maximizing the total harvested energy of\nthe SUs, respectively. The optimization problems are challenging to solve,\nmainly because of the non-linear structure of the energy harvesting and CSI\nerrors models. We converted them into convex forms by using semi-definite\nrelaxation. For the minimum transmission power problem, we obtain the rank-2\nsolution under the bounded CSI error model, while for the maximum energy\nharvesting problem, a two-loop procedure using a one-dimensional search is\nproposed. Our simulation results show that the proposed scheme significantly\noutperforms its traditional orthogonal multiple access counterpart.\nFurthermore, the performance using the gaussian CSI error model is generally\nbetter than that using the bounded CSI error model. \n\n"}
{"id": "1807.04449", "contents": "Title: Cross-Sender Bit-Mixing Coding Abstract: Scheduling to avoid packet collisions is a long-standing challenge in\nnetworking, and has become even trickier in wireless networks with multiple\nsenders and multiple receivers. In fact, researchers have proved that even {\\em\nperfect} scheduling can only achieve $\\mathbf{R} = O(\\frac{1}{\\ln N})$. Here\n$N$ is the number of nodes in the network, and $\\mathbf{R}$ is the {\\em medium\nutilization rate}. Ideally, one would hope to achieve $\\mathbf{R} = \\Theta(1)$,\nwhile avoiding all the complexities in scheduling. To this end, this paper\nproposes {\\em cross-sender bit-mixing coding} ({\\em BMC}), which does not rely\non scheduling. Instead, users transmit simultaneously on suitably-chosen slots,\nand the amount of overlap in different user's slots is controlled via coding.\nWe prove that in all possible network topologies, using BMC enables us to\nachieve $\\mathbf{R}=\\Theta(1)$. We also prove that the space and time\ncomplexities of BMC encoding/decoding are all low-order polynomials. \n\n"}
{"id": "1807.05061", "contents": "Title: Routing and Forwarding in nTorrent using ndnSIM Abstract: BitTorrent is a popular communication protocol for peer-to-peer file sharing.\nIt uses a data-centric approach, wherein the data is decentralized and peers\nrequest each other for pieces of the file(s). Aspects of this process is\nsimilar to the Named Data Networking (NDN) architecture, but is realized\ncompletely at the application level on top of TCP/IP networking. nTorrent is a\npeer-to-peer file sharing application that is based on NDN. The goal of this\nproject is to port the application onto ndnSIM and illustrate the effects of\nrouting and forwarding. \n\n"}
{"id": "1807.05220", "contents": "Title: Greedy Multi-Channel Neighbor Discovery Abstract: The accelerating penetration of physical environments by objects with\ninformation processing and wireless communication capabilities requires\napproaches to find potential communication partners and discover services. In\nthe present work, we focus on passive discovery approaches in multi-channel\nwireless networks based on overhearing periodic beacon transmissions of\nneighboring devices which are otherwise agnostic to the discovery process. We\npropose a family of low-complexity algorithms that generate listening schedules\nguaranteed to discover all neighbors. The presented approaches simultaneously\ndepending on the beacon periods optimize the worst case discovery time, the\nmean discovery time, and the mean number of neighbors discovered until any\narbitrary in time. The presented algorithms are fully compatible with\ntechnologies such as IEEE 802.11 and IEEE 802.15.4. Complementing the proposed\nlow-complexity algorithms, we formulate the problem of computing discovery\nschedules that minimize the mean discovery time for arbitrary beacon periods as\nan integer linear problem. We study the performance of the proposed approaches\nanalytically, by means of numerical experiments, and by extensively simulating\nthem under realistic conditions. We observe that the generated listening\nschedules significantly - by up to factor 4 for the mean discovery time, and by\nup to 300% for the mean number of neighbors discovered until each point in time\n- outperform the Passive Scan, a discovery approach defined in the IEEE\n802.15.4 standard. Based on the gained insights, we discuss how the selection\nof the beacon periods influences the efficiency of the discovery process, and\nprovide recommendations for the design of systems and protocols. \n\n"}
{"id": "1807.05523", "contents": "Title: Improving the Performance of WLANs by Reducing Unnecessary Active Scans Abstract: We consider the problem of excessive and unnecessary active scans in heavily\nutilized WLANs during which low rate probe requests and responses are\nbroadcast. These management frames severely impact the goodput. Our analysis of\ntwo production WLANs reveals that lesser number of non-overlapping channels in\n$2.4$ GHz makes it more prone to the effects of increased probe frames than $5$\nGHz. We find that not only up to $90$% of probe responses carry redundant\ninformation but the probe traffic can be as high as $60$\\% of the management\ntraffic. Furthermore, active scanning severely impacts real-time applications\nat a client as it increases the latency by $91$ times.\n  We present a detailed analysis of the impact of active scans on an individual\nclient and the whole network. We discuss three ways to control the probe\ntraffic in production WLANs -- access point configurations, network planning,\nand client modification. Our proposals for access point configuration are in\nline with current WLAN deployments, better network planning is device agnostic\nin nature, and client modification reduces the average number of probe requests\nper client by up to $50$% without hampering the ongoing WiFi connection. \n\n"}
{"id": "1807.07422", "contents": "Title: Delay and Communication Tradeoffs for Blockchain Systems with\n  Lightweight IoT Clients Abstract: The emerging blockchain protocols provide a decentralized architecture that\nis suitable of supporting Internet of Things (IoT) interactions. However,\nkeeping a local copy of the blockchain ledger is infeasible for low-power and\nmemory-constrained devices. For this reason, they are equipped with lightweight\nsoftware implementations that only download the useful data structures, e.g.\nstate of accounts, from the blockchain network, when they are updated. In this\npaper, we consider and analyze a novel scheme, implemented by the nodes of the\nblockchain network, which aggregates the blockchain data in periodic updates\nand further reduces the communication cost of the connected IoT devices. We\nshow that the aggregation period should be selected based on the channel\nquality, the offered rate, and the statistics of updates of the useful data\nstructures. The results, obtained for the Ethereum protocol, illustrate the\nbenefits of the aggregation scheme in terms of a reduced duty cycle of the\ndevice, particularly for low signal-to-noise ratios, and the overall reduction\nof the amount of information transmitted in downlink (e.g., from the wireless\nbase station to the IoT device). A potential application of the proposed scheme\nis to let the IoT device request more information than actually needed, hence\nincreasing its privacy, while keeping the communication cost constant. In\nconclusion, our work is the first to provide rigorous guidelines for the design\nof lightweight blockchain protocols with wireless connectivity. \n\n"}
{"id": "1807.07876", "contents": "Title: Power-Aware Virtual Network Function Placement and Routing using an\n  Abstraction Technique Abstract: The Network Function Virtualization (NFV) is very promising for efficient\nprovisioning of network services and is attracting a lot of attention. NFV can\nbe implemented in commercial off-the-shelf servers or Physical Machines (PMs),\nand many network services can be offered as a sequence of Virtual Network\nFunctions (VNFs), known as VNF chains. Furthermore, many existing network\ndevices (e.g., switches) and collocated PMs are underutilized or\nover-provisioned, resulting in low power-efficiency. In order to achieve more\nenergy efficient systems, this work aims at designing the placement of VNFs\nsuch that the total power consumption in network nodes and PMs is minimized,\nwhile meeting the delay and capacity requirements of the foreseen demands.\nBased on existing switch and PM power models, we propose a Integer Linear\nProgramming (ILP) formulation to find the optimal solution. We also propose a\nheuristic based on the concept of Blocking Islands (BI), and a baseline\nheuristic based on the Betweenness Centrality (BC) property of the graph. Both\nheuristics and the ILP solutions have been compared in terms of total power\nconsumption, delay, demands acceptance rate, and computation time. Our\nsimulation results suggest that BI-based heuristic is superior compared with\nthe BC-based heuristic, and very close to the optimal solution obtained from\nthe ILP in terms of total power consumption and demands acceptance rate.\nCompared to the ILP, the proposed BI-based heuristic is significantly faster\nand results in 22% lower end-to-end delay, with a penalty of consuming 6% more\npower in average. \n\n"}
{"id": "1807.08087", "contents": "Title: Capacity Analysis for Full Duplex Self-backhauled Small Cells Abstract: Full duplex (FD) communication enables simultaneous transmission and\nreception on the same frequency band. Though it has the potential of doubling\nthe throughput on isolated links, in reality, higher interference and\nasymmetric traffic demands in the uplink and downlink could significantly\nreduce the gains of FD operations. In this paper, we consider the application\nof FD operation in self-backhauled small cells, where multiple FD capable small\ncell base stations (SBS) are wirelessly backhauled by a FD capable macro-cell\nBS (MBS). To increase the capacity of the backhaul link, the MBS is equipped\nwith multiple antennas to enable space division multiple access (SDMA). A\nscheduling method using back-pressure algorithm and geometric programming is\nproposed for link selection and interference mitigation. Simulation results\nshow that with FD SDMA backhaul links, the proposed scheduler almost doubles\nthroughput under asymmetric traffic demand and various network conditions. \n\n"}
{"id": "1807.08088", "contents": "Title: Learning Optimal Resource Allocations in Wireless Systems Abstract: This paper considers the design of optimal resource allocation policies in\nwireless communication systems which are generically modeled as a functional\noptimization problem with stochastic constraints. These optimization problems\nhave the structure of a learning problem in which the statistical loss appears\nas a constraint, motivating the development of learning methodologies to\nattempt their solution. To handle stochastic constraints, training is\nundertaken in the dual domain. It is shown that this can be done with small\nloss of optimality when using near-universal learning parameterizations. In\nparticular, since deep neural networks (DNN) are near-universal their use is\nadvocated and explored. DNNs are trained here with a model-free primal-dual\nmethod that simultaneously learns a DNN parametrization of the resource\nallocation policy and optimizes the primal and dual variables. Numerical\nsimulations demonstrate the strong performance of the proposed approach on a\nnumber of common wireless resource allocation problems. \n\n"}
{"id": "1807.08315", "contents": "Title: Accelerated Structure-Aware Reinforcement Learning for Delay-Sensitive\n  Energy Harvesting Wireless Sensors Abstract: We investigate an energy-harvesting wireless sensor transmitting\nlatency-sensitive data over a fading channel. The sensor injects captured data\npackets into its transmission queue and relies on ambient energy harvested from\nthe environment to transmit them. We aim to find the optimal scheduling policy\nthat decides whether or not to transmit the queue's head-of-line packet at each\ntransmission opportunity such that the expected packet queuing delay is\nminimized given the available harvested energy. No prior knowledge of the\nstochastic processes that govern the channel, captured data, or harvested\nenergy dynamics are assumed, thereby necessitating the use of online learning\nto optimize the scheduling policy. We formulate this scheduling problem as a\nMarkov decision process (MDP) and analyze the structural properties of its\noptimal value function. In particular, we show that it is non-decreasing and\nhas increasing differences in the queue backlog and that it is non-increasing\nand has increasing differences in the battery state. We exploit this structure\nto formulate a novel accelerated reinforcement learning (RL) algorithm to solve\nthe scheduling problem online at a much faster learning rate, while limiting\nthe induced computational complexity. Our experiments demonstrate that the\nproposed algorithm closely approximates the performance of an optimal offline\nsolution that requires a priori knowledge of the channel, captured data, and\nharvested energy dynamics. Simultaneously, by leveraging the value function's\nstructure, our approach achieves competitive performance relative to a\nstate-of-the-art RL algorithm, at potentially orders of magnitude lower\ncomplexity. Finally, considerable performance gains are demonstrated over the\nwell-known and widely used Q-learning algorithm. \n\n"}
{"id": "1807.08615", "contents": "Title: Short-term and Long-term Cell Outage Compensation Using UAVs in 5G\n  Networks Abstract: The use of Unmanned Aerial Vehicles (UAVs) has gained interest in wireless\nnetworks for its many uses and advantages such as rapid deployment and\nmulti-purpose functionality. This is why wide deployment of UAVs has the\npotential to be integrated in the upcoming 5G standard. They can be used as\nflying base-stations, which can be deployed in case of ground Base-Stations\n(GBSs) failures. Such failures can be short-term or long-term. Based on the\ntype and duration of the failure, we propose a framework that uses drones or\nhelikites to mitigate GBS failures. Our proposed short-term and long-term cell\noutage compensation framework aims to mitigate the effect of the failure of any\nGBS in 5G networks. Within our framework, outage compensation is done with the\nassistance of sky BSs (UAVs). An optimization problem is formulated to jointly\nminimize communication power of the UAVs and maximize the minimum rates of the\nUsers' Equipment (UEs) affected by the failure. Also, the optimal placement of\nthe UAVs is determined. Simulation results show that the proposed framework\nguarantees the minimum quality of service for each UE in addition to minimizing\nthe UAVs' consumed energy. \n\n"}
{"id": "1807.09325", "contents": "Title: Controlling Packet Drops to Improve Freshness of information Abstract: Many systems require frequent and regular updates of a certain information.\nThese updates have to be transferred regularly from the source to the\ndestination. We consider scenarios in which an old packet becomes completely\nobsolete, in the presence of a new packet. In this context, if a new packet\narrives at the source while it is transferring a packet, one needs to decide\nthe packet to be dropped. New packet has recent information, but might require\nmore time to transfer. Thus it is not clear as to which packet to be dis-\ncarded, and this is the main focus of the paper. Recently introduced\nperformance metrics, called average age of information (AAoI) and peak age of\ninformation (PAoI) of the information available at the destination, are the\nrelevant performance measures. These type of systems do not require storage\nbuffers, of size more than one, at the source queue. We consider single source\n/ multiple sources regularly updating information to a single destination\npossibly over wireless channels to derive optimal drop policies that optimize\nthe AAoI. We showed that the state independent (static) policies like dropping\nalways the old packets or dropping always the new packets is optimal in many\nscenarios, among an appropriate set of stationary Markov policies. We consider\nrelevant games when multiple sources compete. In many scenarios, the\nnon-cooperative solution almost minimizes the social objective, the sum of\nAAoIs of all the sources. \n\n"}
{"id": "1807.09614", "contents": "Title: On the analysis of partially homogeneous nearest-neighbour random walks\n  in the quarter plane Abstract: This work deals with the stationary analysis of two-dimensional partially\nhomogeneous nearest-neighbour random walks. Such type of random walks in the\nquarter plane are characterized by the fact that the one-step transition\nprobabilities are functions of the state-space. We show that its stationary\nbehavior is investigated by solving a finite system of linear equations, and a\nfunctional equation with the aid of the theory of Riemann(-Hilbert) boundary\nvalue problems. This work is strongly motivated by emerging applications in\nmultiple access systems as well as in the study of a general class of queueing\nsystems with state dependent parameters. A simple numerical illustration\nproviding useful information about a queue-aware multiple access system is also\npresented. \n\n"}
{"id": "1807.10617", "contents": "Title: Temporal connectivity in finite networks with non-uniform measures Abstract: Soft Random Geometric Graphs (SRGGs) have been widely applied to various\nmodels including those of wireless sensor, communication, social and neural\nnetworks. SRGGs are constructed by randomly placing nodes in some space and\nmaking pairwise links probabilistically using a connection function that is\nsystem specific and usually decays with distance. In this paper we focus on the\napplication of SRGGs to wireless communication networks where information is\nrelayed in a multi hop fashion, although the analysis is more general and can\nbe applied elsewhere by using different distributions of nodes and/or\nconnection functions. We adopt a general non-uniform density which can model\nthe stationary distribution of different mobility models, with the interesting\ncase being when the density goes to zero along the boundaries. The global\nconnectivity properties of these non-uniform networks are likely to be\ndetermined by highly isolated nodes, where isolation can be caused by the\nspatial distribution or the local geometry (boundaries). We extend the analysis\nto temporal-spatial networks where we fix the underlying non-uniform\ndistribution of points and the dynamics are caused by the temporal variations\nin the link set, and explore the probability a node near the corner is isolated\nat time $T$. This work allows for insight into how non-uniformity (caused by\nmobility) and boundaries impact the connectivity features of temporal-spatial\nnetworks. We provide a simple method for approximating these probabilities for\na range of different connection functions and verify them against simulations.\nBoundary nodes are numerically shown to dominate the connectivity properties of\nthese finite networks with non-uniform measure. \n\n"}
{"id": "1807.10736", "contents": "Title: Dynamic Placement of VNF Chains for Proactive Caching in Mobile Edge\n  Networks Abstract: Notwithstanding the significant research effort Network Function\nVirtualization (NFV) architectures received over the last few years little\nattention has been placed on optimizing proactive caching when considering it\nas a service chain. Since caching of popular content is envisioned to be one of\nthe key technologies in emerging 5G networks to increase network efficiency and\noverall end user perceived quality of service we explicitly consider in this\npaper the interplay and subsequent optimization of caching based VNF service\nchains. To this end, we detail a novel mathematical programming framework\ntailored to VNF caching chains and detail also a scale-free heuristic to\nprovide competitive solutions for large network instances since the problem\nitself can be seen as a variant of the classical NP-hard Uncapacitated Facility\nLocation (UFL) problem. A wide set of numerical investigations are presented\nfor characterizing the attainable system performance of the proposed schemes. \n\n"}
{"id": "1807.11329", "contents": "Title: EIQIS: Toward an Event-Oriented Indexable and Queryable Intelligent\n  Surveillance System Abstract: Edge computing provides the ability to link distributor users for multimedia\ncontent, while retaining the power of significant data storage and access at a\ncentralized computer. Two requirements of significance include: what\ninformation show be processed at the edge and how the content should be stored.\nAnswers to these questions require a combination of query-based search, access,\nand response as well as indexed-based processing, storage, and distribution. A\nmeasure of intelligence is not what is known, but is recalled, hence, future\nedge intelligence must provide recalled information for dynamic response. In\nthis paper, a novel event-oriented indexable and queryable intelligent\nsurveillance (EIQIS) system is introduced leveraging the on-site edge devices\nto collect the information sensed in format of frames and extracts useful\nfeatures to enhance situation awareness. The design principles are discussed\nand a preliminary proof-of-concept prototype is built that validated the\nfeasibility of the proposed idea. \n\n"}
{"id": "1807.11915", "contents": "Title: Toward a Tactile Internet Reference Architecture: Vision and Progress of\n  the IEEE P1918.1 Standard Abstract: The term Tactile Internet broadly refers to a communication network which is\ncapable of delivering control, touch, and sensing/actuation information in\nreal-time. The Tactile Internet is currently a topic of interest for various\nstandardization bodies. The emerging IEEE P1918.1 standards working group is\nfocusing on defining a framework for the Tactile Internet. The main objective\nof this article is to present a reference architecture for the Tactile Internet\nbased on the latest developments within the IEEE P1918.1 standard. The article\nprovides an in-depth treatment of various architectural aspects including the\nkey entities, the interfaces, the functional capabilities and the protocol\nstack. A case study has been presented as a manifestation of the architecture.\nPerformance evaluation demonstrates the impact of functional capabilities and\nthe underlying enablers on user-level utility pertaining to a generic Tactile\nInternet application. \n\n"}
{"id": "1808.00058", "contents": "Title: A Unified Framework for Joint Mobility Prediction and Object Profiling\n  of Drones in UAV Networks Abstract: In recent years, using a network of autonomous and cooperative unmanned\naerial vehicles (UAVs) without command and communication from the ground\nstation has become more imperative, in particular in search-and-rescue\noperations, disaster management, and other applications where human\nintervention is limited. In such scenarios, UAVs can make more efficient\ndecisions if they acquire more information about the mobility, sensing and\nactuation capabilities of their neighbor nodes. In this paper, we develop an\nunsupervised online learning algorithm for joint mobility prediction and object\nprofiling of UAVs to facilitate control and communication protocols. The\nproposed method not only predicts the future locations of the surrounding\nflying objects, but also classifies them into different groups with similar\nlevels of maneuverability (e.g. rotatory, and fixed-wing UAVs) without prior\nknowledge about these classes. This method is flexible in admitting new object\ntypes with unknown mobility profiles, thereby applicable to emerging flying\nAd-hoc networks with heterogeneous nodes. \n\n"}
{"id": "1808.00203", "contents": "Title: Internet of Drones (IoD): Threats, Vulnerability, and Security\n  Perspectives Abstract: The development of the Internet of Drones (IoD) becomes vital because of a\nproliferation of drone-based civilian or military applications. The IoD based\ntechnological revolution upgrades the current Internet environment into a more\npervasive and ubiquitous world. IoD is capable of enhancing the\nstate-of-the-art for drones while leveraging services from the existing\ncellular networks. Irrespective to a vast domain and range of applications, IoD\nis vulnerable to malicious attacks over open-air radio space. Due to increasing\nthreats and attacks, there has been a lot of attention on deploying security\nmeasures for IoD networks. In this paper, critical threats and vulnerabilities\nof IoD are presented. Moreover, taxonomy is created to classify attacks based\non the threats and vulnerabilities associated with the networking of drone and\ntheir incorporation in the existing cellular setups. In addition, this article\nsummarizes the challenges and research directions to be followed for the\nsecurity of IoD. \n\n"}
{"id": "1808.00376", "contents": "Title: End-to-End Simulation of Integrated Access and Backhaul at mmWaves Abstract: Recently, the millimeter wave (mmWave) bands have been investigated as a\nmeans to support the foreseen extreme data rate demands of next-generation\ncellular networks (5G). However, in order to overcome the severe isotropic path\nloss and the harsh propagation experienced at such high frequencies, a dense\nbase station deployment is required, which may be infeasible because of the\nunavailability of fiber drops to provide wired backhauling. To address this\nchallenge, the 3GPP is investigating the concept of Integrated Access and\nBackhaul (IAB), i.e., the possibility of providing wireless backhaul to the\nmobile terminals. In this paper, we (i) extend the capabilities of the existing\nmmWave module for ns-3 to support advanced IAB functionalities, and (ii)\nevaluate the end-to-end performance of the IAB architecture through\nsystem-level full-stack simulations in terms of experienced throughput and\ncommunication latency. We finally provide guidelines on how to design optimal\nwireless backhaul solutions in the presence of resource-constrained and\ntraffic-congested mmWave scenarios. \n\n"}
{"id": "1808.00667", "contents": "Title: Deep Learning for Radio Resource Allocation in Multi-Cell Networks Abstract: Increased complexity and heterogeneity of emerging 5G and beyond 5G (B5G)\nwireless networks will require a paradigm shift from traditional resource\nallocation mechanisms. Deep learning (DL) is a powerful tool where a\nmulti-layer neural network can be trained to model a resource management\nalgorithm using network data.Therefore, resource allocation decisions can be\nobtained without intensive online computations which would be required\notherwise for the solution of resource allocation problems. In this context,\nthis article focuses on the application of DL to obtain solutions for the radio\nresource allocation problems in multi-cell networks. Starting with a brief\noverview of a deep neural network (DNN) as a DL model, relevant DNN\narchitectures and the data training procedure, we provide an overview of\nexisting state-of-the-art applying DL in the context of radio resource\nallocation. A qualitative comparison is provided in terms of their objectives,\ninputs/outputs, learning and data training methods. Then, we present a\nsupervised DL model to solve the sub-band and power allocation problem in a\nmulti-cell network. Using the data generated by a genetic algorithm, we first\ntrain the model and then test the accuracy of the proposed model in predicting\nthe resource allocation solutions. Simulation results show that the trained DL\nmodel is able to provide the desired optimal solution 86.3% of time. \n\n"}
{"id": "1808.02637", "contents": "Title: Social Community-Aware Content Placement in Wireless Device-to-Device\n  Communication Networks Abstract: In this paper, a novel framework for optimizing the caching of popular user\ncontent at the level of wireless user equipments (UEs) is proposed. The goal is\nto improve content offloading over wireless device-to-device (D2D)\ncommunication links. In the considered network, users belong to different\nsocial communities while their UEs form a single multi-hop D2D network. The\nproposed framework allows to exploit the multi-community social context of\nusers for improving the local offloading of cached content in a multihop D2D\nnetwork. To model the collaborative effect of a set of UEs on content\noffloading, a cooperative game between the UEs is formulated. For this game, it\nis shown that the Shapley value (SV) of each UE effectively captures the impact\nof this UE on the overall content offloading process. To capture the presence\nof multiple social communities that connect the UEs, a hypergraph model is\nproposed. Two line graphs, an influence-weighted graph, and a\nconnectivity-weighted graph, are developed for analyzing the proposed hypergaph\nmodel. Using the developed line graphs along with the SV of the cooperative\ngame, a precise offloading power metric is derived for each UE within a\nmulti-community, multi-hop D2D network. Then, UEs with high offloading power\nare chosen as the optimal locations for caching the popular content. Simulation\nresults show that, on the average, the proposed cache placement framework\nachieves 12%, 19%, and 21% improvements in terms of the number of UEs that\nreceived offloaded popular content compared to the schemes based on\nbetweenness, degree, and closeness centrality, respectively. \n\n"}
{"id": "1808.05283", "contents": "Title: All One Needs to Know about Fog Computing and Related Edge Computing\n  Paradigms: A Complete Survey Abstract: With the Internet of Things (IoT) becoming part of our daily life and our\nenvironment, we expect rapid growth in the number of connected devices. IoT is\nexpected to connect billions of devices and humans to bring promising\nadvantages for us. With this growth, fog computing, along with its related edge\ncomputing paradigms, such as multi-access edge computing (MEC) and cloudlet,\nare seen as promising solutions for handling the large volume of\nsecurity-critical and time-sensitive data that is being produced by the IoT. In\nthis paper, we first provide a tutorial on fog computing and its related\ncomputing paradigms, including their similarities and differences. Next, we\nprovide a taxonomy of research topics in fog computing, and through a\ncomprehensive survey, we summarize and categorize the efforts on fog computing\nand its related computing paradigms. Finally, we provide challenges and future\ndirections for research in fog computing. \n\n"}
{"id": "1808.06025", "contents": "Title: Optimization of LTE Radio Resource Block Allocation for Maritime\n  Channels Abstract: In this study, we describe the behavior of LTE over the sea and investigate\nthe problem of radio resource block allocation in such SINR limited maritime\nchannels. For simulations of such sea environment, we considered a network\nscenario of Bosphorus Strait in Istanbul, Turkey with different number of ships\nferrying between two ports at a given time. After exploiting the network\ncharacteristics, we formulated and solved the radio resource allocation problem\nby max-min integer linear programming method. The radio resource allocation\nfairness in terms of Jain's fairness index was computed and it was compared\nwith round robin and opportunistic methods. Results show that the max-min\noptimization method performs better than the opportunistic and round robin\nmethods. This result in turn reflects that the max-min optimization method\ngives us the high minimum best throughput as compared to other two methods\nconsidering different ship density scenarios in the sea. Also, it was observed\nthat as the number of ships begin to increase in the sea, the max-min method\nperforms significantly better with good fairness as compared to the other two\nmethods. \n\n"}
{"id": "1808.06453", "contents": "Title: Towards Fine Grained Network Flow Prediction Abstract: One main challenge for the design of networks is that traffic load is not\ngenerally known in advance. This makes it hard to adequately devote resources\nsuch as to best prevent or mitigate bottlenecks. While several authors have\nshown how to predict traffic in a coarse grained manner by aggregating flows,\nfine grained prediction of traffic at the level of individual flows, including\nbursty traffic, is widely considered to be impossible. This paper shows, to the\nbest of our knowledge, the first approach to fine grained per flow traffic\nprediction. In short, we introduce the Frequency-based Kernel Kalman Filter\n(FKKF), which predicts individual flows' behavior based on measurements. Our\nFKKF relies on the well known Kalman Filter in combination with a kernel to\nsupport the prediction of non linear functions. Furthermore we change the\noperating space from time to frequency space. In this space, into which we\ntransform the input data via a Short-Time Fourier Transform (STFT), the peak\nstructures of flows can be predicted after gleaning their key characteristics,\nwith a Principal Component Analysis (PCA), from past and ongoing flows that\nstem from the same socket-to-socket connection. We demonstrate the\neffectiveness of our approach on popular benchmark traces from a university\ndata center. Our approach predicts traffic on average across 17 out of 20\ngroups of flows with an average prediction error of 6.43% around 0.49 (average)\nseconds in advance, whilst existing coarse grained approaches exhibit\nprediction errors of 77% at best. \n\n"}
{"id": "1808.07864", "contents": "Title: Secure Relaying in Non-Orthogonal Multiple Access: Trusted and Untrusted\n  Scenarios Abstract: A downlink single-input single-output non-orthogonal multiple access setting\nis considered, in which a base station (BS) is communicating with two\nlegitimate users in two possible scenarios of unsecure environments: existence\nof an external eavesdropper and communicating through an untrusted relay. For\nthe first scenario, a number of trusted cooperative half-duplex relays is\nemployed to assist with the BS's transmission and secure its signals from the\nexternal eavesdropper. Various relaying schemes are proposed and analyzed for\nthat matter: cooperative jamming, decode-and-forward, and amplify-and-forward.\nFor each scheme, secure beamforming signals are devised at the relays to\nmaximize the achievable secrecy rate regions. For the second scenario, with the\nuntrusted relay, achievable secrecy rate regions are derived for two different\nrelaying schemes: compress-and-forward and amplify-and-forward, under two\ndifferent modes of operation. In the first mode, coined passive user mode, the\nusers receive signals from both the BS and the untrusted relay, and combine\nthem to decode their messages. In the second mode, coined active user mode, the\nusers transmit a cooperative jamming signal simultaneously with the BS's\ntransmission to further confuse the relay. Focusing on half-duplex nodes, the\nusers cannot receive the BS's signal while jamming the relay, i.e., while being\nactive, and rely only on the signals forwarded to them by the relay. It is\nshown that the best relaying scheme highly depends on the system parameters, in\nparticular distances between the nodes, and also on which part of the secrecy\nrate region the system is to operate at. \n\n"}
{"id": "1809.00659", "contents": "Title: Barriers in Seamless QoS for Mobile Applications Abstract: For seamless QoS, it is important that all the stakeholders, such as the\nhosts, applications, access networks, routers, and other middleboxes, follow a\nsingle protocol and they trust each other. In this article, we investigate the\nparticipation of these entities in providing QoS over wireless networks in\nlight of DiffServ QoS architecture. We initiate the study by investigating WiFi\nand Cellular network traces, which further motivates us a thorough\ninvestigation of these stakeholders with empirical measurements. Our findings\nare the followings. (i) Modern mobile VoIP applications request QoS to the\nnetwork. (ii) While the operating systems support basic APIs requesting QoS,\napplication developers either are not aware of such requirements or they misuse\nthe architecture for improved QoS. (iii) Wireless access networks rewrite the\nQoS requirements at the edge and enforce the rest of the routers or hops to\nprovide best effort service. (iv) QoS requests are also nullified by the secure\ntunnels. (v) Although the access networks may nullify the QoS requests, the\nperformance of the network still may differentiate traffic. We further\nemphasize that although the latest 5G network considers DiffServ QoS framework,\nit cannot deal with the challenges posed by the privacy related applications.\nNetwork neutrality is going to pose similar challenges. \n\n"}
{"id": "1809.02826", "contents": "Title: Delay-Constrained Input-Queued Switch Abstract: In this paper, we study the delay-constrained input-queued switch where each\npacket has a deadline and it will expire if it is not delivered before its\ndeadline. Such new scenario is motivated by the proliferation of real-time\napplications in multimedia communication systems, tactile Internet, networked\ncontrolled systems, and cyber-physical systems. The delay-constrained\ninput-queued switch is completely different from the well-understood\ndelay-unconstrained one and thus poses new challenges. We focus on three\nfundamental problems centering around the performance metric of timely\nthroughput: (i) how to characterize the capacity region? (ii) how to design a\nfeasibility/throughput-optimal scheduling policy? and (iii) how to design a\nnetwork-utility-maximization scheduling policy? We use three different\napproaches to solve these three fundamental problems. The first approach is\nbased on Markov Decision Process (MDP) theory, which can solve all three\nproblems. However, it suffers from the curse of dimensionality. The second\napproach breaks the curse of dimensionality by exploiting the combinatorial\nfeatures of the problem. It gives a new capacity region characterization with\nonly a polynomial number of linear constraints. The third approach is based on\nthe framework of Lyapunov optimization, where we design a polynomial-time\nmaximum-weight T-disjoint-matching scheduling policy which is proved to be\nfeasibility/throughput-optimal. Our three approaches apply to the\nframe-synchronized traffic pattern but our MDP-based approach can be extended\nto more general traffic patterns. \n\n"}
{"id": "1809.03953", "contents": "Title: 5G Massive MIMO Architectures: Self-Backhauled Small Cells versus Direct\n  Access Abstract: In this paper, we focus on one of the key technologies for the\nfifth-generation wireless communication networks, massive\nmultiple-input-multiple-output (mMIMO), by investigating two of its most\nrelevant architectures: 1) to provide in-band backhaul for the ultra-dense\nnetwork (UDN) of self-backhauled small cells (SCs), and 2) to provide direct\naccess (DA) to user equipments (UEs). Through comprehensive 3GPP-based\nsystem-level simulations and analytical formulations, we show the end-to-end UE\nrates achievable with these two architectures. Differently from the existing\nworks, we provide results for two strategies of self-backhauled SC deployments,\nnamely random and ad-hoc, where in the latter SCs are purposely positioned\nclose to UEs to achieve line-of-sight (LoS) access links. We also evaluate the\noptimal backhaul and access time resource partition due to the in-band\nself-backhauling (s-BH) operations. Our results show that the ad-hoc deployment\nof self-backhauled SCs closer to the UEs with optimal resource partition and\nwith directive antenna patterns, provides rate improvements for cell-edge UEs\nthat amount to 30% and tenfold gain, as compared to mMIMO DA architecture with\npilot reuse 3 and reuse 1, respectively. On the other hand, mMIMO s-BH\nunderperforms mMIMO DA above the median value of the UE rates when the effect\nof pilot contamination is less severe, and the LoS probability of the DA links\nimproves. \n\n"}
{"id": "1809.05088", "contents": "Title: High Throughput Cryptocurrency Routing in Payment Channel Networks Abstract: Despite growing adoption of cryptocurrencies, making fast payments at scale\nremains a challenge. Payment channel networks (PCNs) such as the Lightning\nNetwork have emerged as a viable scaling solution. However, completing payments\non PCNs is challenging: payments must be routed on paths with sufficient funds.\nAs payments flow over a single channel (link) in the same direction, the\nchannel eventually becomes depleted and cannot support further payments in that\ndirection; hence, naive routing schemes like shortest-path routing can deplete\nkey payment channels and paralyze the system. Today's PCNs also route payments\natomically, worsening the problem. In this paper, we present Spider, a routing\nsolution that \"packetizes\" transactions and uses a multi-path transport\nprotocol to achieve high-throughput routing in PCNs. Packetization allows\nSpider to complete even large transactions on low-capacity payment channels\nover time, while the multi-path congestion control protocol ensures balanced\nutilization of channels and fairness across flows. Extensive simulations\ncomparing Spider with state-of-the-art approaches shows that Spider requires\nless than 25% of the funds to successfully route over 95% of transactions on\nbalanced traffic demands, and offloads 4x more transactions onto the PCN on\nimbalanced demands. \n\n"}
{"id": "1809.06550", "contents": "Title: Joint User Association and Resource Allocation Optimization for Ultra\n  Reliable Low Latency HetNets Abstract: Ensuring ultra-reliable and low latency communications (URLLC) is necessary\nfor enabling delay critical applications in 5G HetNets. We propose a joint user\nto BS association and resource optimization method that is attractive for URLLC\nin HetNets with Cellular Base Stations (CBSs) and Small Cell Base Stations\n(SBSs), while also reducing energy and bandwidth consumption. In our scheme,\nCBSs share portions of the available spectrum with SBSs, and they in exchange,\nprovide data service to the users in their coverage area. We first show that\nthe CBSs optimal resource allocation (ORA) problem is NP-hard and\ncomputationally intractable for large number of users. Then, to reduce its time\ncomplexity, we propose a relaxed heuristic method (RHM) which breaks down the\noriginal ORA problem into a heuristic user association (HUA) algorithm and a\nconvex resource allocation (CRA) optimization problem. Simulation results show\nthat the proposed heuristic method decreases the time complexity of finding the\noptimal solution for CBS's significantly, thereby benefiting URLLC. It also\nhelps the CBSs to save energy by offloading users to SBSs. In our simulations,\nthe spectrum access delay for cellular users is reduced by 93\\% and the energy\nconsumption is reduced by 33\\%, while maintaining the full service rate. \n\n"}
{"id": "1809.06970", "contents": "Title: FastDeepIoT: Towards Understanding and Optimizing Neural Network\n  Execution Time on Mobile and Embedded Devices Abstract: Deep neural networks show great potential as solutions to many sensing\napplication problems, but their excessive resource demand slows down execution\ntime, pausing a serious impediment to deployment on low-end devices. To address\nthis challenge, recent literature focused on compressing neural network size to\nimprove performance. We show that changing neural network size does not\nproportionally affect performance attributes of interest, such as execution\ntime. Rather, extreme run-time nonlinearities exist over the network\nconfiguration space. Hence, we propose a novel framework, called FastDeepIoT,\nthat uncovers the non-linear relation between neural network structure and\nexecution time, then exploits that understanding to find network configurations\nthat significantly improve the trade-off between execution time and accuracy on\nmobile and embedded devices. FastDeepIoT makes two key contributions. First,\nFastDeepIoT automatically learns an accurate and highly interpretable execution\ntime model for deep neural networks on the target device. This is done without\nprior knowledge of either the hardware specifications or the detailed\nimplementation of the used deep learning library. Second, FastDeepIoT informs a\ncompression algorithm how to minimize execution time on the profiled device\nwithout impacting accuracy. We evaluate FastDeepIoT using three different\nsensing-related tasks on two mobile devices: Nexus 5 and Galaxy Nexus.\nFastDeepIoT further reduces the neural network execution time by $48\\%$ to\n$78\\%$ and energy consumption by $37\\%$ to $69\\%$ compared with the\nstate-of-the-art compression algorithms. \n\n"}
{"id": "1809.07665", "contents": "Title: Dynamic Power Control for Packets with Deadlines Abstract: Wireless devices need to adapt their transmission power according to the\nfluctuating wireless channel in order to meet constraints of delay sensitive\napplications. In this paper, we consider delay sensitivity in the form of\nstrict packet deadlines arriving in a transmission queue. Packets missing the\ndeadline while in the queue are dropped from the system. We aim at minimizing\nthe packet drop rate under average power constraints. We utilize tools from\nLyapunov optimization to find an approximate solution by selecting power\nallocation. We evaluate the performance of the proposed algorithm and show that\nit achieves the same performance in terms of packet drop rate with that of the\nEarliest Deadline First (EDF) when the available power is sufficient. However,\nour algorithm outperforms EDF regarding the trade-off between packet drop rate\nand average power consumption. \n\n"}
{"id": "1809.07681", "contents": "Title: Fundamentals on Base Stations in Cellular Networks: From the Perspective\n  of Algebraic Topology Abstract: In recent decades, the deployments of cellular networks have been going\nthrough an unprecedented expansion. In this regard, it is beneficial to acquire\nprofound knowledge of cellular networks from the view of topology so that\nprominent network performances can be achieved by means of appropriate\nplacements of base stations (BSs). In our researches, practical location data\nof BSs in eight representative cities are processed with classical algebraic\ngeometric instruments, including $ \\alpha $-Shapes, Betti numbers, and Euler\ncharacteristics. At first, the fractal nature is revealed in the BS topology\nfrom both perspectives of the Betti numbers and the Hurst coefficients.\nFurthermore, log-normal distribution is affirmed to provide the optimal fitness\nto the Euler characteristics of real BS deployments. \n\n"}
{"id": "1809.07857", "contents": "Title: In-Edge AI: Intelligentizing Mobile Edge Computing, Caching and\n  Communication by Federated Learning Abstract: Recently, along with the rapid development of mobile communication\ntechnology, edge computing theory and techniques have been attracting more and\nmore attentions from global researchers and engineers, which can significantly\nbridge the capacity of cloud and requirement of devices by the network edges,\nand thus can accelerate the content deliveries and improve the quality of\nmobile services. In order to bring more intelligence to the edge systems,\ncompared to traditional optimization methodology, and driven by the current\ndeep learning techniques, we propose to integrate the Deep Reinforcement\nLearning techniques and Federated Learning framework with the mobile edge\nsystems, for optimizing the mobile edge computing, caching and communication.\nAnd thus, we design the \"In-Edge AI\" framework in order to intelligently\nutilize the collaboration among devices and edge nodes to exchange the learning\nparameters for a better training and inference of the models, and thus to carry\nout dynamic system-level optimization and application-level enhancement while\nreducing the unnecessary system communication load. \"In-Edge AI\" is evaluated\nand proved to have near-optimal performance but relatively low overhead of\nlearning, while the system is cognitive and adaptive to the mobile\ncommunication systems. Finally, we discuss several related challenges and\nopportunities for unveiling a promising upcoming future of \"In-Edge AI\". \n\n"}
{"id": "1809.07864", "contents": "Title: Enabling Ultra-Low Delay Teleorchestras using Software Defined\n  Networking Abstract: Ultra-low delay sensitive applications can afford delay only at the level of\nmsec. An example of this application class are the Networked Music Performance\n(NMP) systems that describe a live music performance by geographically separate\nmusicians over the Internet. The present work proposes a novel architecture for\nNMP systems, where the key-innovation is the close collaboration between the\nnetwork and the application. Using SDN principles, the applications are enabled\nto adapt their internal audio signal processing, in order to cope with network\ndelay increase. Thus, affordable end-to-end delay is provided to NMP users,\neven under considerable network congestion. \n\n"}
{"id": "1809.08325", "contents": "Title: The Rise of Certificate Transparency and Its Implications on the\n  Internet Ecosystem Abstract: In this paper, we analyze the evolution of Certificate Transparency (CT) over\ntime and explore the implications of exposing certificate DNS names from the\nperspective of security and privacy. We find that certificates in CT logs have\nseen exponential growth. Website support for CT has also constantly increased,\nwith now 33% of established connections supporting CT. With the increasing\ndeployment of CT, there are also concerns of information leakage due to all\ncertificates being visible in CT logs. To understand this threat, we introduce\na CT honeypot and show that data from CT logs is being used to identify targets\nfor scanning campaigns only minutes after certificate issuance. We present and\nevaluate a methodology to learn and validate new subdomains from the vast\nnumber of domains extracted from CT logged certificates. \n\n"}
{"id": "1809.08514", "contents": "Title: Fundamental Limits of Invisible Flow Fingerprinting Abstract: Network flow fingerprinting can be used to de-anonymize communications on\nanonymity systems such as Tor by linking the ingress and egress segments of\nanonymized connections. Assume Alice and Bob have access to the input and the\noutput links of an anonymous network, respectively, and they wish to\ncollaboratively reveal the connections between the input and the output links\nwithout being detected by Willie who protects the network. Alice generates a\ncodebook of fingerprints, where each fingerprint corresponds to a unique\nsequence of inter-packet delays and shares it only with Bob. For each input\nflow, she selects a fingerprint from the codebook and embeds it in the flow,\ni.e., changes the packet timings of the flow to follow the packet timings\nsuggested by the fingerprint, and Bob extracts the fingerprints from the output\nflows. We model the network as parallel $M/M/1$ queues where each queue is\nshared by a flow from Alice to Bob and other flows independent of the flow from\nAlice to Bob. The timings of the flows are governed by independent Poisson\npoint processes. Assuming all input flows have equal rates and that Bob\nobserves only flows with fingerprints, we first present two scenarios: 1) Alice\nfingerprints all the flows; 2) Alice fingerprints a subset of the flows,\nunknown to Willie. Then, we extend the construction and analysis to the case\nwhere flow rates are arbitrary as well as the case where not all the flows that\nBob observes have a fingerprint. For each scenario, we derive the number of\nflows that Alice can fingerprint and Bob can trace by fingerprinting. \n\n"}
{"id": "1809.08748", "contents": "Title: A Survey of Conventional and Artificial Intelligence / Learning based\n  Resource Allocation and Interference Mitigation Schemes in D2D Enabled\n  Networks Abstract: 5th generation networks are envisioned to provide seamless and ubiquitous\nconnection to 1000-fold more devices and is believed to provide ultra-low\nlatency and higher data rates up to tens of Gbps. Different technologies\nenabling these requirements are being developed including mmWave\ncommunications, Massive MIMO and beamforming, Device to Device (D2D)\ncommunications and Heterogeneous Networks. D2D communication is a promising\ntechnology to enable applications requiring high bandwidth such as online\nstreaming and online gaming etc. It can also provide ultra- low latencies\nrequired for applications like vehicle to vehicle communication for autonomous\ndriving. D2D communication can provide higher data rates with high energy\nefficiency and spectral efficiency compared to conventional communication. The\nperformance benefits of D2D communication can be best achieved when D2D users\nreuses the spectrum being utilized by the conventional cellular users. This\nspectrum sharing in a multi-tier heterogeneous network will introduce complex\ninterference among D2D users and cellular users which needs to be resolved.\nMotivated by limited number of surveys for interference mitigation and resource\nallocation in D2D enabled heterogeneous networks, we have surveyed different\nconventional and artificial intelligence based interference mitigation and\nresource allocation schemes developed in recent years. Our contribution lies in\nthe analysis of conventional interference mitigation techniques and their\nshortcomings. Finally, the strengths of AI based techniques are determined and\nopen research challenges deduced from the recent research are presented. \n\n"}
{"id": "1809.09470", "contents": "Title: SS5G: Collision Resolution Protocol for Delay and Energy Efficient LoRa\n  Networks Abstract: Future 5G and Internet of Things (IoT) applications will heavily rely on\nlong-range communication technologies such as low-power wireless area networks\n(LPWANs). In particular, LoRaWAN built on LoRa physical layer is gathering\nincreasing interests, both from academia and industries, for enabling low-cost\nenergy efficient IoT wireless sensor networks for, e.g., environmental\nmonitoring over wide areas. While its communication range may go up to 20\nkilometers, the achievable bit rates in LoRaWAN are limited to a few kilobits\nper second. In the event of collisions, the perceived rate is further reduced\ndue to packet loss and retransmissions. Firstly, to alleviate the harmful\nimpacts of collisions, we propose a decoding algorithm that enables to resolve\nseveral superposed LoRa signals. Our proposed method exploits the slight\ndesynchronization of superposed signals and specific features of LoRa physical\nlayer. Secondly, we design a full MAC protocol enabling collision resolution.\nThe simulation results demonstrate that the proposed method outperforms\nconventional LoRaWAN jointly in terms of system throughput, energy efficiency\nas well as delay. These results show that our scheme is well suited for 5G and\nIoT systems, as one of their major goals is to provide the best trade-off among\nthese performance objectives. \n\n"}
{"id": "1809.09566", "contents": "Title: Security and Performance Considerations in ROS 2: A Balancing Act Abstract: Robot Operating System (ROS) 2 is a ground-up re-design of ROS 1 to support\nperformance critical cyber-physical systems (CPSs) using the Data Distribution\nService (DDS) middleware. Accordingly, the security of ROS 2 is highly reliant\non the security of its DDS communication protocol. However, finding a balance\nbetween the performance and security is non-trivial task. Inappropriate\nsecurity implementations may cause not only significant loss on performance of\nthe system, but also security failures in the system. In this paper, we provide\nan analysis of the DDS security protocol as well as an overview on how to find\nthe balance between performance and security. To accomplish this, we evaluate\nthe latency and throughput of the communication protocols of ROS 2 in both\nwired and wireless networks, and measure the efficiency loss caused by the\nenabling of security protocols such as Virtual Private Network (VPN) and DDS\nsecurity protocol in ROS 2 in both network setups. The result can be directly\nused by robotics developers to find the optimal and balanced settings of ROS 2\napplications. Additionally, we analyzed the security specification of DDS using\nexisting security standards and tested the implementation of the DDS protocol\nby performing static analysis. The results of this work can be used to enhance\nthe security of ROS 2. \n\n"}
{"id": "1809.09837", "contents": "Title: Analysis of Uplink Scheduling for Haptic Communications Abstract: While new mechanisms and configurations of the 5G radio are offering step\nforward in delivery of ultra-reliable low latency communication services in\ngeneral, and haptic communications in particular, they could inversely impact\nthe remainder of traffic services. In this paper, we investigate the uplink\naccess procedure, how different advances in this procedure enhance delivery of\nhaptic communication, and how it affects the remainder of traffic services in\nthe network. We model this impact as the remainder of service, using stochastic\nnetwork calculus. Our results show how best the tradeoff between faster or more\nresource efficient uplink access can be made depending on the rate of haptic\ndata, which is directly relevant to the application domain of haptic\ncommunication. \n\n"}
{"id": "1809.10537", "contents": "Title: Cross-Layer Effects on Training Neural Algorithms for Video Streaming Abstract: Nowadays Dynamic Adaptive Streaming over HTTP (DASH) is the most prevalent\nsolution on the Internet for multimedia streaming and responsible for the\nmajority of global traffic. DASH uses adaptive bit rate (ABR) algorithms, which\nselect the video quality considering performance metrics such as throughput and\nplayout buffer level. Pensieve is a system that allows to train ABR algorithms\nusing reinforcement learning within a simulated network environment and is\noutperforming existing approaches in terms of achieved performance. In this\npaper, we demonstrate that the performance of the trained ABR algorithms\ndepends on the implementation of the simulated environment used to train the\nneural network. We also show that the used congestion control algorithm impacts\nthe algorithms' performance due to cross-layer effects. \n\n"}
{"id": "1810.00349", "contents": "Title: IDMoB: IoT Data Marketplace on Blockchain Abstract: Today, Internet of Things (IoT) devices are the powerhouse of data generation\nwith their ever-increasing numbers and widespread penetration. Similarly,\nartificial intelligence (AI) and machine learning (ML) solutions are getting\nintegrated to all kinds of services, making products significantly more\n\"smarter\". The centerpiece of these technologies is \"data\". IoT device vendors\nshould be able keep up with the increased throughput and come up with new\nbusiness models. On the other hand, AI/ML solutions will produce better results\nif training data is diverse and plentiful.\n  In this paper, we propose a blockchain-based, decentralized and trustless\ndata marketplace where IoT device vendors and AI/ML solution providers may\ninteract and collaborate. By facilitating a transparent data exchange platform,\naccess to consented data will be democratized and the variety of services\ntargeting end-users will increase. Proposed data marketplace is implemented as\na smart contract on Ethereum blockchain and Swarm is used as the distributed\nstorage platform. \n\n"}
{"id": "1810.00827", "contents": "Title: Five Driving Forces of Multi-Access Edge Computing Abstract: The emergence of Multi-Access Edge Computing (MEC) technology aims at\nextending cloud computing capabilities to the edge of the wireless access\nnetworks. MEC provides real-time, high-bandwidth, low-latency access to radio\nnetwork resources, allowing operators to open their networks to a new ecosystem\nand value chain. Moreover, it will provide a new insight to the design of\nfuture 5th Generation (5G) wireless systems. This paper describes five key\ntechnologies, including Network Function Vitalization (NFV), Software Defined\nNetworking (SDN), Network Slicing, Information Centric Networking (ICN) and\nInternet of Things (IoT), that intensify the widespread of MEC and its\nadoption. Our goal is to provide the associativity between MEC and these five\ndriving technologies in 5G context while identifying the open challenges,\nfuture directions, and tangible integration paths. \n\n"}
{"id": "1810.00959", "contents": "Title: Performance of a Link in a Field of Vehicular Interferers with Hardcore\n  Headway Distance Abstract: The Poisson point process (PPP) is not always a realistic model for the\nlocations of vehicles along a road, because it does not account for the safety\ndistance a driver maintains from the vehicle ahead. In this paper, we model the\ninter-vehicle distance equal to the sum of a constant hardcore distance and a\nrandom distance following the exponential distribution. Unfortunately, the\nprobability generating functional of this point process is unknown. To\napproximate the Laplace transform of interference at the origin, we devise\nsimple approximations for the variance and skewness of interference, and we\nselect suitable probability functions to model the interference distribution.\nWhen the coefficient-of-variation and the skewness of interference distribution\nare high, the PPP (of equal intensity) approximation of the outage probability\nbecomes loose in the upper tail. Relevant scenarios are associated with urban\nmicrocells and highway macrocells with a low density of vehicles. The\npredictions of PPP deteriorate with a multi-antenna maximum ratio combining\nreceiver and temporal indicators related to the performance of retransmission\nschemes. Our approximations generate good predictions in all considered cases. \n\n"}
{"id": "1810.01291", "contents": "Title: An Exploration of Blockchain Enabled Decentralized Capability based\n  Access Control Strategy for Space Situation Awareness Abstract: Space situation awareness (SSA) includes tracking of active and inactive\nresident space objects (RSOs) and assessing the space environment through\nsensor data collection and processing. To enhance SSA, the dynamic data-driven\napplications systems (DDDAS) framework couples on-line data with off-line\nmodels to enhance system performance. Using feedback control, sensor\nmanagement, and communications reliability. For information management, there\nis a need for identity authentication and access control to ensure the\nintegrity of exchanged data as well as to grant authorized entities access\nright to data and services. Due to decentralization and heterogeneity of SSA\nsystems, it is challenging to build an efficient centralized access control\nsystem, which could either be a performance bottleneck or the single point of\nfailure. Inspired by the blockchain and smart contract technology, this paper\nintroduces BlendCAC, a decentralized authentication and capability-based access\ncontrol mechanism to enable effective protection for devices, services and\ninformation in SSA networks. To achieve secure identity authentication, the\nBlendCAC leverages the blockchain to create virtual trust zones and a robust\nidentity-based capability token management strategy is proposed. A\nproof-of-concept prototype has been implemented on both resources-constrained\ndevices and more powerful computing devices, and is tested on a private\nEthereum blockchain network. The experimental results demonstrate the\nfeasibility of the BlendCAC scheme to offer a decentralized, scalable,\nlightweight and fine-grained access control solution for space system towards\nSSA. \n\n"}
{"id": "1810.01548", "contents": "Title: Deep Learning Based Caching for Self-Driving Car in Multi-access Edge\n  Computing Abstract: Once self-driving car becomes a reality and passengers are no longer worry\nabout it, they will need to find new ways of entertainment. However, retrieving\nentertainment contents at the Data Center (DC) can hinder content delivery\nservice due to high delay of car-to-DC communication. To address these\nchallenges, we propose a deep learning based caching for self-driving car, by\nusing Deep Learning approaches deployed on the Multi-access Edge Computing\n(MEC) structure. First, at DC, Multi-Layer Perceptron (MLP) is used to predict\nthe probabilities of contents to be requested in specific areas. To reduce the\ncar-DC delay, MLP outputs are logged into MEC servers attached to roadside\nunits. Second, in order to cache entertainment contents stylized for car\npassengers' features such as age and gender, Convolutional Neural Network (CNN)\nis used to predict age and gender of passengers. Third, each car requests MLP\noutput from MEC server and compares its CNN and MLP outputs by using k-means\nand binary classification. Through this, the self-driving car can identify the\ncontents need to be downloaded from the MEC server and cached. Finally, we\nformulate deep learning based caching in the self-driving car that enhances\nentertainment services as an optimization problem whose goal is to minimize\ncontent downloading delay. To solve the formulated problem, a Block Successive\nMajorization-Minimization (BS-MM) technique is applied. The simulation results\nshow that the accuracy of our prediction for the contents need to be cached in\nthe areas of the self-driving car is achieved at 98.04% and our approach can\nminimize delay. \n\n"}
{"id": "1810.02276", "contents": "Title: Performance Analysis of NOMA for Ultra-Reliable and Low-Latency\n  Communications Abstract: Grant-free non-orthogonal multiple access (NOMA) has been regarded as a\nkey-enabler technology for ultra-reliable and low-latency communications\n(URLLC). In this paper, we analyse the performance of NOMA with short packet\ncommunications for URLLC. In this regard, the overall packet loss probability\nconsists of transmission error probability and queueing-delay violation\nprobability. Queueing-delay has been modelled using the effective bandwidth.\nDue to short transmission time, the infinite block-length has been replaced\nwith finite blocklength of the channel codes which rules out the application of\nShannon's formula. The achievable effective bandwidth of the system is derived,\nand then, the transmission error probability has been analysed. The derivations\nare validated through extensive simulations, which shows the variations of the\nsignal-to-noise ratio (SNR) requirements of the system for various\ntransmission-error probability, QoS exponent, and the transmission packet size. \n\n"}
{"id": "1810.03060", "contents": "Title: Eiffel: Efficient and Flexible Software Packet Scheduling Abstract: Packet scheduling determines the ordering of packets in a queuing data\nstructure with respect to some ranking function that is mandated by a\nscheduling policy. It is the core component in many recent innovations to\noptimize network performance and utilization. Our focus in this paper is on the\ndesign and deployment of packet scheduling in software. Software schedulers\nhave several advantages over hardware including shorter development cycle and\nflexibility in functionality and deployment location. We substantially improve\ncurrent software packet scheduling performance, while maintaining flexibility,\nby exploiting underlying features of packet ranking; namely, packet ranks are\nintegers and, at any point in time, fall within a limited range of values. We\nintroduce Eiffel, a novel programmable packet scheduling system. At the core of\nEiffel is an integer priority queue based on the Find First Set (FFS)\ninstruction and designed to support a wide range of policies and ranking\nfunctions efficiently. As an even more efficient alternative, we also propose a\nnew approximate priority queue that can outperform FFS-based queues for some\nscenarios. To support flexibility, Eiffel introduces novel programming\nabstractions to express scheduling policies that cannot be captured by current,\nstate-of-the-art scheduler programming models. We evaluate Eiffel in a variety\nof settings and in both kernel and userspace deployments. We show that it\noutperforms state of the art systems by 3-40x in terms of either number of\ncores utilized for network processing or number of flows given fixed processing\ncapacity. \n\n"}
{"id": "1810.03162", "contents": "Title: Competitive Online Virtual Cluster Embedding Algorithms Abstract: In the conventional cloud service model, computing resources are allocated\nfor tenants on a pay-per-use basis. However, the performance of applications\nthat communicate inside this network is unpredictable because network resources\nare not guaranteed. To mitigate this issue, the virtual cluster (VC) model has\nbeen developed in which network and compute units are guaranteed. Thereon, many\nalgorithms have been developed that are based on novel extensions of the VC\nmodel in order to solve the online virtual cluster embedding problem (VCE) with\nadditional parameters. In the online VCE, the resource footprint is greedily\nminimized per request which is connected with maximizing the profit for the\nprovider per request. However, this does not imply that a global maximization\nof the profit over the whole sequence of requests is guaranteed. In fact, these\nalgorithms do not even provide a worst case guarantee on a fraction of the\nmaximum achievable profit of a certain sequence of requests. Thus, these online\nalgorithms do not provide a competitive ratio on the profit.\n  In this thesis, two competitive online VCE algorithms and two heuristic\nalgorithms are presented. The competitive online VCE algorithms have different\ncompetitive ratios on the objective function and the capacity constraints\nwhereas the heuristic algorithms do not violate the capacity constraints. The\nworst case competitive ratios are analyzed. After that, the evaluation shows\nthe advantages and disadvantages of these algorithms in several scenarios with\ndifferent request patterns and profit metrics on the fat-tree and MDCube\ndatacenter topologies. The results show that for different scenarios, different\nalgorithms have the best performance with respect to certain metrics. \n\n"}
{"id": "1810.03259", "contents": "Title: Internet Congestion Control via Deep Reinforcement Learning Abstract: We present and investigate a novel and timely application domain for deep\nreinforcement learning (RL): Internet congestion control. Congestion control is\nthe core networking task of modulating traffic sources' data-transmission rates\nto efficiently utilize network capacity, and is the subject of extensive\nattention in light of the advent of Internet services such as live video,\nvirtual reality, Internet-of-Things, and more. We show that casting congestion\ncontrol as RL enables training deep network policies that capture intricate\npatterns in data traffic and network conditions, and leverage this to\noutperform the state-of-the-art. We also highlight significant challenges\nfacing real-world adoption of RL-based congestion control, including fairness,\nsafety, and generalization, which are not trivial to address within\nconventional RL formalism. To facilitate further research and reproducibility\nof our results, we present a test suite for RL-guided congestion control based\non the OpenAI Gym interface. \n\n"}
{"id": "1810.03298", "contents": "Title: Multi-Stream Opportunistic Network Decoupling: Relay Selection and\n  Interference Management Abstract: We study multi-stream transmission in the $K \\times N \\times K$ channel with\ninterfering relay nodes, consisting of $K$ multi-antenna source--destination\n(S--D) pairs and $N$ single-antenna half-duplex relay nodes between the S--D\npairs. We propose a new achievable scheme operating with partial effective\nchannel gain, termed multi-stream opportunistic network decoupling (MS-OND),\nwhich achieves the optimal degrees of freedom (DoF) under a certain relay\nscaling law. Our protocol is built upon the conventional OND that leads to\nvirtual full-duplex mode with one data stream transmission per S--D pair,\ngeneralizing the idea of OND to multi-stream scenarios by leveraging relay\nselection and interference management. Specifically, two subsets of relay nodes\nare opportunistically selected using alternate relaying in terms of producing\nor receiving the minimum total interference level. For interference management,\neach source node sends $S \\,(1 \\le S \\le M)$ data streams to selected relay\nnodes with random beamforming for the first hop, while each destination node\nreceives its desired $S$ streams from the selected relay nodes via\nopportunistic interference alignment for the second hop, where $M$ is the\nnumber of antennas at each source or destination node. Our analytical results\nare validated by numerical evaluation. \n\n"}
{"id": "1810.03476", "contents": "Title: On the Benefits of Network-Level Cooperation in Millimeter-Wave\n  Communications Abstract: Relaying techniques for millimeter-wave wireless networks represent a\npowerful solution for improving the transmission performance. In this work, we\nquantify the benefits in terms of delay and throughput for a random-access\nmulti-user millimeter-wave wireless network, assisted by a full-duplex network\ncooperative relay. The relay is equipped with a queue for which we analyze the\nperformance characteristics (e.g., arrival rate, service rate, average size,\nand stability condition). Moreover, we study two possible transmission schemes:\nfully directional and broadcast. In the former, the source nodes transmit a\npacket either to the relay or to the destination by using narrow beams,\nwhereas, in the latter, the nodes transmit to both the destination and the\nrelay in the same timeslot by using a wider beam, but with lower beamforming\ngain. In our analysis, we also take into account the beam alignment phase that\noccurs every time a transmitter node changes the destination node. We show how\nthe beam alignment duration, as well as position and number of transmitting\nnodes, significantly affect the network performance. Moreover, we illustrate\nthe optimal transmission scheme (i.e., broadcast or fully directional) for\nseveral system parameters and show that a fully directional transmission is not\nalways beneficial, but, in some scenarios, broadcasting and relaying can\nimprove the performance in terms of throughput and delay. \n\n"}
{"id": "1810.06930", "contents": "Title: Feedforward Neural Networks for Caching: Enough or Too Much? Abstract: We propose a caching policy that uses a feedforward neural network (FNN) to\npredict content popularity. Our scheme outperforms popular eviction policies\nlike LRU or ARC, but also a new policy relying on the more complex recurrent\nneural networks. At the same time, replacing the FNN predictor with a naive\nlinear estimator does not degrade caching performance significantly,\nquestioning then the role of neural networks for these applications. \n\n"}
{"id": "1810.06938", "contents": "Title: Wireless Access in Ultra-Reliable Low-Latency Communication (URLLC) Abstract: The future connectivity landscape and, notably, the 5G wireless systems will\nfeature Ultra-Reliable Low Latency Communication (URLLC). The coupling of high\nreliability and low latency requirements in URLLC use cases makes the wireless\naccess design very challenging, in terms of both the protocol design and of the\nassociated transmission techniques. This paper aims to provide a broad\nperspective on the fundamental tradeoffs in URLLC as well as the principles\nused in building access protocols. Two specific technologies are considered in\nthe context of URLLC: massive MIMO and multi-connectivity, also termed\ninterface diversity. The paper also touches upon the important question of the\nproper statistical methodology for designing and assessing extremely high\nreliability levels. \n\n"}
{"id": "1810.07730", "contents": "Title: Implementation and Analysis of QUIC for MQTT Abstract: Transport and security protocols are essential to ensure reliable and secure\ncommunication between two parties. For IoT applications, these protocols must\nbe lightweight, since IoT devices are usually resource constrained.\nUnfortunately, the existing transport and security protocols -- namely TCP/TLS\nand UDP/DTLS -- fall short in terms of connection overhead, latency, and\nconnection migration when used in IoT applications. In this paper, after\nstudying the root causes of these shortcomings, we show how utilizing QUIC in\nIoT scenarios results in a higher performance. Based on these observations, and\ngiven the popularity of MQTT as an IoT application layer protocol, we integrate\nMQTT with QUIC. By presenting the main APIs and functions developed, we explain\nhow connection establishment and message exchange functionalities work. We\nevaluate the performance of MQTTw/QUIC versus MQTTw/TCP using wired, wireless,\nand long-distance testbeds. Our results show that MQTTw/QUIC reduces connection\noverhead in terms of the number of packets exchanged with the broker by up to\n56%. In addition, by eliminating half-open connections, MQTTw/QUIC reduces\nprocessor and memory usage by up to 83% and 50%, respectively. Furthermore, by\nremoving the head-of-line blocking problem, delivery latency is reduced by up\nto 55%. We also show that the throughput drops experienced by MQTTw/QUIC when a\nconnection migration happens is considerably lower than that of MQTTw/TCP. \n\n"}
{"id": "1810.07795", "contents": "Title: Flow-based Network Traffic Generation using Generative Adversarial\n  Networks Abstract: Flow-based data sets are necessary for evaluating network-based intrusion\ndetection systems (NIDS). In this work, we propose a novel methodology for\ngenerating realistic flow-based network traffic. Our approach is based on\nGenerative Adversarial Networks (GANs) which achieve good results for image\ngeneration. A major challenge lies in the fact that GANs can only process\ncontinuous attributes. However, flow-based data inevitably contain categorical\nattributes such as IP addresses or port numbers. Therefore, we propose three\ndifferent preprocessing approaches for flow-based data in order to transform\nthem into continuous values. Further, we present a new method for evaluating\nthe generated flow-based network traffic which uses domain knowledge to define\nquality tests. We use the three approaches for generating flow-based network\ntraffic based on the CIDDS-001 data set. Experiments indicate that two of the\nthree approaches are able to generate high quality data. \n\n"}
{"id": "1810.07801", "contents": "Title: Integrating UAVs into Existing Wireless Networks: A Stochastic Geometry\n  Approach Abstract: The integration of unmanned aerial vehicles (UAVs) into wireless networks has\nopened a new horizon to meet the capacity and coverage requirements foreseen in\nfuture wireless networks. Harnessing UAVs as flying base stations (BSs) has\nhelped to achieve a cost-effective and on-the-go wireless network that may be\nused in several scenarios such as to support disaster response and in temporary\nhotspots. Despite the extensive research on the application side of UAVs, the\nintegration of UAVs as BSs into existing wireless networks remains an open\nchallenge. While UAV BSs can help to increase the area spectral efficiency, the\nadded network heterogeneity and BS densification may diminish the capacity\ngains due to increased handover rates. In this work, we shed some light on this\ntradeoff by studying a three tier network architecture consisting of macro,\nsmall, and UAV BSs and analyze its coverage and rate performance. In\nparticular, we consider joint control/data and split architectures and express\nthe rate performance for stationary and mobile users, using an analytical\napproach based on stochastic geometry. While both joint and split architectures\noffer similar performance for stationary users, the numerical results suggest\nthe splitting of control and data plane for mobile users. \n\n"}
{"id": "1810.07862", "contents": "Title: Applications of Deep Reinforcement Learning in Communications and\n  Networking: A Survey Abstract: This paper presents a comprehensive literature review on applications of deep\nreinforcement learning in communications and networking. Modern networks, e.g.,\nInternet of Things (IoT) and Unmanned Aerial Vehicle (UAV) networks, become\nmore decentralized and autonomous. In such networks, network entities need to\nmake decisions locally to maximize the network performance under uncertainty of\nnetwork environment. Reinforcement learning has been efficiently used to enable\nthe network entities to obtain the optimal policy including, e.g., decisions or\nactions, given their states when the state and action spaces are small.\nHowever, in complex and large-scale networks, the state and action spaces are\nusually large, and the reinforcement learning may not be able to find the\noptimal policy in reasonable time. Therefore, deep reinforcement learning, a\ncombination of reinforcement learning with deep learning, has been developed to\novercome the shortcomings. In this survey, we first give a tutorial of deep\nreinforcement learning from fundamental concepts to advanced models. Then, we\nreview deep reinforcement learning approaches proposed to address emerging\nissues in communications and networking. The issues include dynamic network\naccess, data rate control, wireless caching, data offloading, network security,\nand connectivity preservation which are all important to next generation\nnetworks such as 5G and beyond. Furthermore, we present applications of deep\nreinforcement learning for traffic routing, resource sharing, and data\ncollection. Finally, we highlight important challenges, open issues, and future\nresearch directions of applying deep reinforcement learning. \n\n"}
{"id": "1810.08111", "contents": "Title: Enabling Hard Service Guarantees in Software-Defined Smart Grid\n  Infrastructures Abstract: Information and Communication Technology (ICT) infrastructures play a key\nrole in the evolution from traditional power systems to Smart Grids.\nIncreasingly fluctuating power flows, sparked by the transition towards\nsustainable energy generation, become a major issue for power grid stability.\nTo deal with this challenge, future Smart Grids require precise monitoring and\ncontrol, which in turn demand for reliable, real-time capable and\ncost-efficient communications. For this purpose, we propose applying\nSoftware-Defined Networking (SDN) to handle the manifold requirements of Smart\nGrid communications. To achieve reliability, our approach encompasses fast\nrecovery after failures in the communication network and dynamic service-aware\nnetwork (re-)configuration. Network Calculus (NC) logic is embedded into our\nSDN controller for meeting latency requirements imposed by the standard IEC\n61850 of the International Electrotechnical Committee (IEC). Thus, routing\nprovides delay-optimal paths under consideration of existing cross traffic.\nAlso, continuous latency bound compliance is ensured by combining NC delay\nsupervision with means of flexible reconfiguration. For evaluation we consider\nthe well-known Nordic 32 test system, on which we map a corresponding\ncommunication network in both experiment and emulation. The described\nfunctionalities are validated, employing realistic IEC 61850 transmissions and\ndistributed control traffic. Our results show that hard service guarantees can\nbe ensured with the help of the proposed SDN solution. On this basis, we derive\nextremely time critical services, which must not be subjected to flexible\nreconfiguration. \n\n"}
{"id": "1810.09409", "contents": "Title: Event-triggered Natural Hazard Monitoring with Convolutional Neural\n  Networks on the Edge Abstract: In natural hazard warning systems fast decision making is vital to avoid\ncatastrophes. Decision making at the edge of a wireless sensor network promises\nfast response times but is limited by the availability of energy, data transfer\nspeed, processing and memory constraints. In this work we present a realization\nof a wireless sensor network for hazard monitoring based on an array of\nevent-triggered single-channel micro-seismic sensors with advanced signal\nprocessing and characterization capabilities based on a novel co-detection\ntechnique. On the one hand we leverage an ultra-low power, threshold-triggering\ncircuit paired with on-demand digital signal acquisition capable of extracting\nrelevant information exactly and efficiently at times when it matters most and\nconsequentially not wasting precious resources when nothing can be observed. On\nthe other hand we utilize machine-learning-based classification implemented on\nlow-power, off-the-shelf microcontrollers to avoid false positive warnings and\nto actively identify humans in hazard zones. The sensors' response time and\nmemory requirement is substantially improved by quantizing and pipelining the\ninference of a convolutional neural network. In this way, convolutional neural\nnetworks that would not run unmodified on a memory constrained device can be\nexecuted in real-time and at scale on low-power embedded devices. A field study\nwith our system is running on the rockfall scarp of the Matterhorn H\\\"ornligrat\nat 3500 m a.s.l. since 08/2018. \n\n"}
{"id": "1810.10139", "contents": "Title: Joint Transaction Transmission and Channel Selection in Cognitive Radio\n  Based Blockchain Networks: A Deep Reinforcement Learning Approach Abstract: To ensure that the data aggregation, data storage, and data processing are\nall performed in a decentralized but trusted manner, we propose to use the\nblockchain with the mining pool to support IoT services based on cognitive\nradio networks. As such, the secondary user can send its sensing data, i.e.,\ntransactions, to the mining pools. After being verified by miners, the\ntransactions are added to the blocks. However, under the dynamics of the\nprimary channel and the uncertainty of the mempool state of the mining pool, it\nis challenging for the secondary user to determine an optimal transaction\ntransmission policy. In this paper, we propose to use the deep reinforcement\nlearning algorithm to derive an optimal transaction transmission policy for the\nsecondary user. Specifically, we adopt a Double Deep-Q Network (DDQN) that\nallows the secondary user to learn the optimal policy. The simulation results\nclearly show that the proposed deep reinforcement learning algorithm\noutperforms the conventional Q-learning scheme in terms of reward and learning\nspeed. \n\n"}
{"id": "1810.11280", "contents": "Title: Virtual Network Embedding via Decomposable LP Formulations: Orientations\n  of Small Extraction Width and Beyond Abstract: The Virtual Network Embedding Problem (VNEP) considers the efficient\nallocation of resources distributed in a substrate network to a set of request\nnetworks. Many existing works discuss either heuristics or exact algorithms,\nresulting in a choice between quick runtimes and quality guarantees for the\nsolutions. Recently, the first fixed-parameter tractable (FPT) approximation\nalgorithm for the VNEP with arbitrary request and substrate topologies has been\npublished by Rost and Schmid. This algorithm is based on a LP formulation and\nis FPT in the newly introduced graph parameter extraction width (EW). It\ntherefore combines positive traits of heuristics and exact approaches: The\nruntime is polynomial for instances with bounded EW, and the algorithm returns\napproximate solutions with high probability.\n  We propose two extensions of this algorithm to optimize its runtime. Firstly,\nwe develop a new LP formulation related to tree decompositions. We show that\nthis LP formulation is always smaller, and that the resulting algorithm is FPT\nin the new parameter extraction label width (ELW). We improve on two important\nresults by Rost and Schmid: For centrally rooted half-wheel topologies, the EW\nscales linearly with request size, whereas the ELW is constant. Further, adding\nany number of paths parallel to an existing edge increases the EW by at most\nthe maximum degree of the request. By contrast, the ELW only increases by at\nmost one. Lastly, we show that finding the minimal ELW is NP-hard.\n  Secondly, we consider the approach of partitioning the request into subgraphs\nwhich are processed independently, yielding even smaller LP formulations. While\nthis algorithm may lead to higher ELW within the subgraphs, we show that this\nincrease is always smaller than the size of the inter-subgraph boundary. In\nparticular, the algorithm has zero additional cost when subgraphs are separated\nby a single node. \n\n"}
{"id": "1810.11729", "contents": "Title: Cooperative Deep Reinforcement Learning for Multiple-Group NB-IoT\n  Networks Optimization Abstract: NarrowBand-Internet of Things (NB-IoT) is an emerging cellular-based\ntechnology that offers a range of flexible configurations for massive IoT radio\naccess from groups of devices with heterogeneous requirements. A configuration\nspecifies the amount of radio resources allocated to each group of devices for\nrandom access and for data transmission. Assuming no knowledge of the traffic\nstatistics, the problem is to determine, in an online fashion at each\nTransmission Time Interval (TTI), the configurations that maximizes the\nlong-term average number of IoT devices that are able to both access and\ndeliver data. Given the complexity of optimal algorithms, a Cooperative\nMulti-Agent Deep Neural Network based Q-learning (CMA-DQN) approach is\ndeveloped, whereby each DQN agent independently control a configuration\nvariable for each group. The DQN agents are cooperatively trained in the same\nenvironment based on feedback regarding transmission outcomes. CMA-DQN is seen\nto considerably outperform conventional heuristic approaches based on load\nestimation. \n\n"}
{"id": "1810.12859", "contents": "Title: JavaScript Convolutional Neural Networks for Keyword Spotting in the\n  Browser: An Experimental Analysis Abstract: Used for simple commands recognition on devices from smart routers to mobile\nphones, keyword spotting systems are everywhere. Ubiquitous as well are web\napplications, which have grown in popularity and complexity over the last\ndecade with significant improvements in usability under cross-platform\nconditions. However, despite their obvious advantage in natural language\ninteraction, voice-enabled web applications are still far and few between. In\nthis work, we attempt to bridge this gap by bringing keyword spotting\ncapabilities directly into the browser. To our knowledge, we are the first to\ndemonstrate a fully-functional implementation of convolutional neural networks\nin pure JavaScript that runs in any standards-compliant browser. We also apply\nnetwork slimming, a model compression technique, to explore the\naccuracy-efficiency tradeoffs, reporting latency measurements on a range of\ndevices and software. Overall, our robust, cross-device implementation for\nkeyword spotting realizes a new paradigm for serving neural network\napplications, and one of our slim models reduces latency by 66% with a minimal\ndecrease in accuracy of 4% from 94% to 90%. \n\n"}
{"id": "1811.02330", "contents": "Title: Traversing Virtual Network Functions from the Edge to the Core: An\n  End-to-End Performance Analysis Abstract: Future mobile networks supporting Internet of Things are expected to provide\nboth high throughput and low latency to user-specific services. One way to\novercome this challenge is to adopt network function virtualization and\nMulti-access edge computing (MEC). In this paper, we analyze an end-to-end\ncommunication system that consists of both MEC servers and a server at the core\nnetwork hosting different types of virtual network functions. We develop a\nqueueing model for the performance analysis of the system consisting of both\nprocessing and transmission flows. The system is decomposed into subsystems\nwhich are independently analyzed in order to approximate the behaviour of the\noriginal system. We provide closed-form expressions of the performance metrics\nsuch as system drop rate and average number of tasks in the system. Simulation\nresults show that our approximation performs quite well. By evaluating the\nsystem under different scenarios, we provide insights for the decision making\non traffic flow control and its impact on critical performance metrics. \n\n"}
{"id": "1811.02638", "contents": "Title: Characterizing Task Completion Latencies in Fog Computing Abstract: Fog computing, which distributes computing resources to multiple locations\nbetween the Internet of Things (IoT) devices and the cloud, is attracting\nconsiderable attention from academia and industry. Yet, despite the excitement\nabout the potential of fog computing, few comprehensive quantitative\ncharacteristics of the properties of fog computing architectures have been\nconducted. In this paper we examine the properties of task completion latencies\nin fog computing. First, we present the results of our empirical\nbenchmarking-based study of task completion latencies. The study covered a\nrange of settings, and uniquely considered both traditional and serverless fog\ncomputing execution points. It demonstrated the range of execution point\ncharacteristics in different locations and the relative stability of latency\ncharacteristics for a given location. It also highlighted properties of\nserverless execution that are not incorporated in existing fog computing\nalgorithms. Second, we present a framework we developed for co-optimizing task\ncompletion quality and latency, which was inspired by the insights of our\nempirical study. We describe fog computing task assignment problems we\nformulated under this framework, and present the algorithms we developed for\nsolving them. \n\n"}
{"id": "1811.03353", "contents": "Title: ACP: An End-to-End Transport Protocol for Delivering Fresh Updates in\n  the Internet-of-Things Abstract: The next generation of networks must support billions of connected devices in\nthe Internet-of-Things (IoT). To support IoT applications, sources sense and\nsend their measurement updates over the Internet to a monitor (control station)\nfor real-time monitoring and actuation. Ideally, these updates would be\ndelivered at a high rate, only constrained by the sensing rate supported by the\nsources. However, given network constraints, such a rate may lead to delays in\ndelivery of updates at the monitor that make the freshest update at the monitor\nunacceptably old for the application.\n  We propose a novel transport layer protocol, namely the Age Control Protocol\n(ACP), that enables timely delivery of such updates to monitors, in a\nnetwork-transparent manner. ACP allows the source to adapt its rate of updates\nto dynamic network conditions such that the average age of the sensed\ninformation at the monitor is minimized. We detail the protocol and the\nproposed control algorithm. We demonstrate its efficacy using extensive\nsimulations and real-world experiments, which have a source send its updates\nover the Internet to a monitor on another continent. \n\n"}
{"id": "1811.03981", "contents": "Title: Ultra-Reliable Low-Latency Vehicular Networks: Taming the Age of\n  Information Tail Abstract: While the notion of age of information (AoI) has recently emerged as an\nimportant concept for analyzing ultra-reliable low-latency communications\n(URLLC), the majority of the existing works have focused on the average AoI\nmeasure. However, an average AoI based design falls short in properly\ncharacterizing the performance of URLLC systems as it cannot account for\nextreme events that occur with very low probabilities. In contrast, in this\npaper, the main objective is to go beyond the traditional notion of average AoI\nby characterizing and optimizing a URLLC system while capturing the AoI tail\ndistribution. In particular, the problem of vehicles' power minimization while\nensuring stringent latency and reliability constraints in terms of\nprobabilistic AoI is studied. To this end, a novel and efficient mapping\nbetween both AoI and queue length distributions is proposed. Subsequently,\nextreme value theory (EVT) and Lyapunov optimization techniques are adopted to\nformulate and solve the problem. Simulation results shows a nearly two-fold\nimprovement in terms of shortening the tail of the AoI distribution compared to\na baseline whose design is based on the maximum queue length among vehicles,\nwhen the number of vehicular user equipment (VUE) pairs is 80. The results also\nshow that this performance gain increases significantly as the number of VUE\npairs increases. \n\n"}
{"id": "1811.05308", "contents": "Title: On Distributed Routing in Underwater Optical Wireless Sensor Networks Abstract: Underwater optical wireless communication (UOWC) is becoming an attractive\ntechnology for underwater wireless sensor networks (UWSNs) since it offers\nhigh-speed communication links. Although UOWC overcomes the drawbacks of\nacoustic and radio frequency communication channels such as high latency and\nlow data rate, yet, it has its own limitations. One of the major limitations of\nUOWC is its limited transmission range which demands to develop a multi-hop\nnetwork with efficient routing protocols. Currently, the routing protocols for\nUOWSNs are centralized having high complexity and large end-to-end delay. In\nthis article, first, we present the existing routing protocols for UOWSNs.\nBased on the existing protocols, we then propose distributed routing protocols\nto address the problems of high complexity and large end-to-end delay.\nNumerical results have been provided to show that the proposed routing protocol\nis superior to the existing protocols in terms of complexity and end-to-end\ndelay. Finally, we have presented open research directions in UOWSNs. \n\n"}
{"id": "1811.05669", "contents": "Title: Massive MIMO channel estimation taking into account spherical waves Abstract: Together with millimiter waves (mmWaves), massive multiple-input\nmultiple-output (MIMO) systems are key technological components of fifth\ngeneration (5G) wireless communication systems. In such a context, geometric\nconsiderations show that the largely adopted plane wave model (PWM) of the\nchannel potentially loses its validity. An alternative is to consider the more\naccurate but more complex spherical wave model (SWM). This paper introduces an\nintermediate parabolic wave model (ParWM), more accurate than the PWM while\nless complex than the SWM. The validity domains of those three physical models\nare assessed in a novel way. Finally, estimation algorithms for the SWM and\nParWM are proposed and compared with classical algorithms, showing a promising\nperformance complexity trade-off. \n\n"}
{"id": "1811.05948", "contents": "Title: EdgeBench: Benchmarking Edge Computing Platforms Abstract: The emerging trend of edge computing has led several cloud providers to\nrelease their own platforms for performing computation at the 'edge' of the\nnetwork. We compare two such platforms, Amazon AWS Greengrass and Microsoft\nAzure IoT Edge, using a new benchmark comprising a suite of performance\nmetrics. We also compare the performance of the edge frameworks to cloud-only\nimplementations available in their respective cloud ecosystems. Amazon AWS\nGreengrass and Azure IoT Edge use different underlying technologies, edge\nLambda functions vs. containers, and so we also elaborate on platform features\navailable to developers. Our study shows that both of these edge platforms\nprovide comparable performance, which nevertheless differs in important ways\nfor key types of workloads used in edge applications. Finally, we discuss\nseveral current issues and challenges we faced in deploying these platforms. \n\n"}
{"id": "1811.06261", "contents": "Title: Efficient Edge Rewiring Strategies for Enhancement in Network Capacity Abstract: The structure of the network has great impact on its traffic dynamics. Most\nof the real world networks follow the heterogeneous structure and exhibit\nscale-free feature. In scale-free network, a new node prefers to connect with\nhub nodes and the network capacity is curtailed by smaller degree nodes.\nTherefore, we propose rewiring a fraction of links in the network, to improve\nthe network transport efficiency. In this paper, we discuss some efficient link\nrewiring strategies and perform simulations on scale-free networks, confirming\nthe effectiveness of these strategies. The rewiring strategies actually reduce\nthe centrality of the nodes having higher betweenness centrality. After the\nlink rewiring process, the degree distribution of the network remains the same.\nThis work will be beneficial for the enhancement of network performance. \n\n"}
{"id": "1811.06453", "contents": "Title: Minimizing the Age of Information from Sensors with Common Observations Abstract: We study the average Age of Information (AoI) in a system where physical\nsources produce independent discrete-time updates that are each observed by\nseveral sensors. We devise a model that is simple, but still capable to capture\nthe main tradeoffs. Two sensor scheduling policies are proposed to minimize the\nAoI of the sources; one in which the system parameters are assumed known, and\none in which they are learned. Both policies are able to exploit the common\nsensor information to reduce the AoI, resulting in large reductions in AoI\ncompared to common schedules. \n\n"}
{"id": "1811.06832", "contents": "Title: Spectrum graph coloring to improve Wi-Fi channel assignment in a\n  real-world scenario via edge contraction Abstract: The present work deals with the problem of efficiently assigning Wi-Fi\nchannels in a real-world scenario, the Polytechnic School of the University of\nAlcal\\'a. We first use proximity graphs to model the whole problem as an\ninstance of spectrum graph coloring, we further obtain a simplified model using\nedge contraction, and we finally use simulated annealing to look for a coloring\nwhich optimizes the network throughput. As the main result, we show that the\nsolutions we obtain outperform the de facto standard for Wi-Fi channel\nassignment, both in terms of network throughput and of computation time. \n\n"}
{"id": "1811.09221", "contents": "Title: The typical cell in anisotropic tessellations Abstract: The typical cell is a key concept for stochastic-geometry based modeling in\ncommunication networks, as it provides a rigorous framework for describing\nproperties of a serving zone associated with a component selected at random in\na large network. We consider a setting where network components are located on\na large street network. While earlier investigations were restricted to street\nsystems without preferred directions, in this paper we derive the distribution\nof the typical cell in Manhattan-type systems characterized by a pattern of\nhorizontal and vertical streets. We explain how the mathematical description\ncan be turned into a simulation algorithm and provide numerical results\nuncovering novel effects when compared to classical isotropic networks. \n\n"}
{"id": "1811.09731", "contents": "Title: In-network Congestion-aware Load Balancing at Transport Layer Abstract: Load balancing at transport layer is an important function in data centers,\ncontent delivery networks, and mobile networks, where per-connection\nconsistency (PCC) has to be met for optimal performance. Cloud-native L4 load\nbalancers are commonly deployed as virtual network functions (VNFs) and are a\ncritical forwarding element in modern cloud infrastructure. We identify load\nimbalance among service instances as the main cause of additional processing\ndelay caused by transport-layer load balancers. Existing transport-layer load\nbalancers rely on one of two methods: host-level traffic redirection, which may\nadd as much as 12.48% additional traffic to underlying networks, or connection\ntracking, which consumes a considerable amount of memory in load balancers.\nBoth of these methods result in inefficient usage of network resources. We\npropose the in-network congestion-aware load Balancer (INCAB) to achieve even\nload distribution among service instances and optimal network resources usage\nin addition to meeting the PCC requirement. We show that INCAB is capable of\nidentifying and monitoring each instance's most-utilized resource and can\nimprove the load distribution among all service instances. INCAB utilizes a\nBloom filter and an ultra-compact connection table for in-network flow\ndistribution. Furthermore, it does not rely on end hosts for traffic\nredirection. Our flow level simulations show that INCAB improves flows' average\ncompletion time by 31.97% compared to stateless solutions. \n\n"}
{"id": "1811.11247", "contents": "Title: Performance Analysis of Connectivity and Localization in Multi-Hop\n  Underwater Optical Wireless Sensor Networks Abstract: Underwater optical wireless links have limited range and intermittent\nconnectivity due to the hostile aquatic channel impairments and misalignment\nbetween the optical transceivers. Therefore, multi-hop communication can expand\nthe communication range, enhance network connectivity, and provide a more\nprecise network localization scheme. In this regard, this paper investigates\nthe connectivity of underwater optical wireless sensor networks (UOWSNs) and\nits impacts on the network localization performance. Firstly, we model UOWSNs\nas randomly scaled sector graphs where the connection between sensors is\nestablished by point-to-point directed links. Thereafter, the probability of\nnetwork connectivity is analytically derived as a function of network density,\ncommunication range, and optical transmitters' divergence angle. Secondly, the\nnetwork localization problem is formulated as an unconstrained optimization\nproblem and solved using the conjugate gradient technique. Numerical results\nshow that different network parameters such as the number of nodes, divergence\nangle, and transmission range significantly influence the probability of a\nconnected network. Furthermore, the performance of the proposed localization\ntechnique is compared to well-known network localization schemes and the\nresults show that the localization accuracy of the proposed technique\noutperforms the literature in terms of network connectivity, ranging error, and\nnumber of anchors. \n\n"}
{"id": "1811.11717", "contents": "Title: Wireless Data Center Networks: Advances, Challenges, and Opportunities Abstract: Data center networks (DCNs) are essential infrastructures to embrace the era\nof highly diversified massive amount of data generated by emerging\ntechnological applications. In order to store and process such a data deluge,\ntoday's DCNs have to deploy enormous length of wires to interconnect a plethora\nof servers and switches. Unfortunately, wired DCNs with uniform and inflexible\nlink capacities expose several drawbacks such as high cabling cost and\ncomplexity, low space utilization, and lack of bandwidth efficiency. Wireless\nDCNs (WDCNs) have emerged as a promising solution to reduce the time, effort,\nand cost spent on deploying and maintaining the wires. Thanks to its\nreconfigurability and flexibility, WDCNs can deliver higher throughputs by\nefficiently utilizing the bandwidth and mitigate the chronic DCN problems of\noversubscription and hotspots. Moreover, wireless links enhance the\nfault-tolerance and energy efficiency by eliminating the need for error-prone\npower-hungry switches. Accordingly, this paper first compares virtues and\ndrawbacks of millimeter wave (mmWave), terahertz (THz), and optical wireless\ncommunications as potential candidates. Thereafter, an in-depth discussion on\nadvances and challenges in WDCNs is provided including physical and virtual\ntopology design, quality of service (QoS) provisioning, flow classification,\ndata grooming, and load balancing. Finally, exciting research opportunities are\npresented to promote the prospects of WDCNs. \n\n"}
{"id": "1811.12924", "contents": "Title: Joint Information Freshness and Completion Time Optimization for\n  Vehicular Networks Abstract: The demand for real-time cloud applications has seen an unprecedented growth\nover the past decade. These applications require rapidly data transfer and fast\ncomputations. This paper considers a scenario where multiple IoT devices update\ninformation on the cloud, and request a computation from the cloud at certain\ntimes. The time required to complete the request for computation includes the\ntime to wait for computation to start on busy virtual machines, performing the\ncomputation, waiting and service in the networking stage for delivering the\noutput to the end user. In this context, the freshness of the information is an\nimportant concern and is different from the completion time. This paper\nproposes novel scheduling strategies for both computation and networking\nstages. Based on these strategies, the age-of-information (AoI) metric and the\ncompletion time are characterized. A convex combination of the two metrics is\noptimized over the scheduling parameters. The problem is shown to be convex and\nthus can be solved optimally. Moreover, based on the offline policy, an online\nalgorithm for job scheduling is developed. Numerical results demonstrate\nsignificant improvement as compared to the considered baselines. \n\n"}
{"id": "1812.00667", "contents": "Title: The TMB path loss model for 5 GHz indoor WiFi scenarios: On the\n  empirical relationship between RSSI, MCS, and spatial streams Abstract: The WiFi landscape is rapidly changing over the last years, responding to the\nnew needs of wireless communications. IEEE 802.11ax is the next\nfast-approaching standard, addressing some of today's biggest performance\nchallenges specifically for high-density public environments. It is designed to\noperate at 2.4 GHz and 5 GHz bands, the latter being rapidly adopted worldwide\nafter its inclusion in IEEE 802.11ac, and with expected growing demand in the\nnext 10 years.\n  This paper assesses empirically the suitability of the available IEEE\n802.11ax path loss models at 5 GHz on some real testbeds and proposes a new\nmodel with higher abstraction level; i.e., without requiring from a previous in\nsitu analysis of each considered receiver's location. The proposed TMB path\nloss model, used in combination with generated data sets, is able to obtain an\nestimation of RSSI, selected modulation and coding scheme (MCS), and number of\nspatial streams in function of the AP configuration and the AP-STA distance. We\naim to use the model to compare IEEE 802.11ac/ax performance simulation results\nwith experimental ones. \n\n"}
{"id": "1812.00724", "contents": "Title: Design and Provision of Traffic Grooming for Optical Wireless Data\n  Center Networks Abstract: Traditional wired data center networks (DCNs) suffer from cabling complexity,\nlack flexibility, and are limited by the speed of digital switches. In this\npaper, we alternatively develop a top-down traffic grooming (TG) approach to\nthe design and provisioning of mission-critical optical wireless DCNs. While\nswitches are modeled as hybrid optoelectronic cross-connects, links are modeled\nas wavelength division multiplexing (WDM) capable free-space optic (FSO)\nchannels. Using the standard TG terminology, we formulate the optimal\nmixed-integer TG problem considering the virtual topology, flow conversation,\nconnection topology, non-bifurcation, and capacity constraints. Thereafter, we\ndevelop a fast yet efficient sub-optimal solution which grooms mice flows (MFs)\nand mission-critical flows (CFs) and forward on predetermined rack-to-rack\n(R2R) lightpaths. On the other hand, elephant flows (EFs) are forwarded over\ndedicated server-to-server (S2S) express lightpaths whose routes and capacity\nare dynamically determined based on the availability of wavelength and\ncapacity. To prioritize the CFs, we consider low and high priority queues and\nanalyze the delay characteristics such as waiting times, maximum hop counts,\nand blocking probability. As a result of grooming the sub-wavelength traffic\nand adjusting the wavelength capacities, numerical results show that the\nproposed solutions can achieve significant performance enhancement by utilizing\nthe bandwidth more efficiently, completing the flows faster than delay\nsensitivity requirements, and avoiding the traffic congestion by treating EFs\nand MFs separately. \n\n"}
{"id": "1812.00896", "contents": "Title: A Coalition-Based Communication Framework for Task-Driven Flying Ad-Hoc\n  Networks Abstract: In this paper, we develop a task-driven networking framework for Flying\nAd-hoc Networks (FANETs), where a coalition-based model is outlined. Firstly,\nwe present a brief survey to show the state-of-the-art studies on the\nintra-communication of unmanned aerial vehicle (UAV) swarms. The features and\ndeficiencies of existing models are analyzed. To capture the task-driven\nrequirement of the flying multi-agent system, a coalition-based framework is\nproposed. We discuss the composition, networking mode and the classification of\ndata transmission. After that, the application scenario of UAV coalitions is\ngiven, where large-scale, distributed and highly dynamic characteristics\ngreatly increase the difficulty of resource optimization for UAVs. To tackle\nthe problem, we design an intelligence-based optimization architecture, which\nmainly includes the game model, machine learning and real-time decision. Under\nthe guidance of game theories and machine learning, UAVs can make comprehensive\ndecisions by combining the previous training results with their sensing,\ninformation interaction, and game strategies. Finally, a preliminary case and\npromising open issues of UAV coalitions are studied. \n\n"}
{"id": "1812.01126", "contents": "Title: Wideband Full-Duplex Wireless via Frequency-Domain Equalization: Design\n  and Experimentation Abstract: Full-duplex (FD) wireless can significantly enhance spectrum efficiency but\nrequires tremendous amount of self-interference (SI) cancellation. Recent\nadvances in the RFIC community enabled wideband RF SI cancellation (SIC) in\nintegrated circuits (ICs) via frequency-domain equalization (FDE), where RF\nfilters channelize the SI signal path. Unlike other FD implementations, that\nmostly rely on delay lines, FDE-based cancellers can be realized in\nsmall-form-factor devices. However, the fundamental limits and higher layer\nchallenges associated with these cancellers were not explored yet. Therefore,\nand in order to support the integration with a software-defined radio (SDR) and\nto facilitate experimentation in a testbed with several nodes, we design and\nimplement an FDE-based RF canceller on a printed circuit board (PCB). We derive\nand experimentally validate the PCB canceller model and present a canceller\nconfiguration scheme based on an optimization problem. We then extensively\nevaluate the performance of the FDE-based FD radio in the SDR testbed.\nExperiments show that it achieves 95dB overall SIC (52dB from RF SIC) across\n20MHz bandwidth, and an average link-level FD gain of 1.87x. We also conduct\nexperiments in: (i) uplink-downlink networks with inter-user interference, and\n(ii) heterogeneous networks with half-duplex and FD users. The experimental FD\ngains in the two types of networks confirm previous analytical results. They\ndepend on the users' SNR values and the number of FD users, and are 1.14x-1.25x\nand 1.25x-1.73x, respectively. Finally, we numerically evaluate and compare the\nRFIC and PCB implementations and study various design tradeoffs. \n\n"}
{"id": "1812.01830", "contents": "Title: Unified Analysis of HetNets using Poisson Cluster Process under\n  Max-Power Association Abstract: Owing to its flexibility in modeling real-world spatial configurations of\nusers and base stations (BSs), the Poisson cluster process (PCP) has recently\nemerged as an appealing way to model and analyze heterogeneous cellular\nnetworks (HetNets). Despite its undisputed relevance to HetNets -- corroborated\nby the models used in industry -- the PCP's use in performance analysis has\nbeen limited. This is primarily because of the lack of analytical tools to\ncharacterize performance metrics such as the coverage probability of a user\nconnected to the strongest BS. In this paper, we develop an analytical\nframework for the evaluation of the coverage probability, or equivalently the\ncomplementary cumulative density function (CCDF) of\nsignal-to-interference-and-noise-ratio (SINR), of a typical user in a K-tier\nHetNet under a max power-based association strategy, where the BS locations of\neach tier follow either a Poisson point process (PPP) or a PCP. The key\nenabling step involves conditioning on the parent PPPs of all the PCPs which\nallows us to express the coverage probability as a product of sum-product and\nprobability generating functionals (PGFLs) of the parent PPPs. In addition to\nseveral useful insights, our analysis provides a rigorous way to study the\nimpact of the cluster size on the SINR distribution, which was not possible\nusing existing PPP-based models. \n\n"}
{"id": "1812.02269", "contents": "Title: A Brief History on the Theoretical Analysis of Dense Small Cell Wireless\n  Networks Abstract: This article provides dives into the fundamentals of dense and ultra-dense\nsmall cell wireless networks, discussing the reasons why dense and ultra-dense\nsmall cell networks are fundamentally different from sparse ones, and why the\nwell-known linear scaling law of capacity with the base station (BS) density in\nthe latter does not apply to the former. In more detail, we review the impact\nof the following factors on ultradense networks (UDNs), (i) closed-access\noperations and line-of-sight conditions, (ii) the near-field effect, (iii) the\nantenna height difference between small cell BSs and user equipments (UEs), and\n(iv) the surplus of idle-mode-enabled small cell BSs with respect to UEs.\nCombining all these network characteristics and features, we present a more\nrealistic capacity scaling law for UDNs, which indicates (i) the existence of\nan optimum BS density to maximise the area spectral efficiency (ASE) for a\ngiven finite UE density, and (ii) the existence of an optimum density of UEs\nthat can be simultaneously scheduled across the network to maximise the ASE for\na given finite BS density. \n\n"}
{"id": "1812.02791", "contents": "Title: Multi-Hop Communication for nTorrent in a Wireless Ad Hoc Environment Abstract: nTorrent is a BitTorrent-like application that is based on NDN (Named Data\nNetworking). Ad hoc environments introduce additional challenges to the\ndissemination of files among peers. Some issues that we encounter are that not\nall peers in the neighborhood or environment run the nTorrent application or\ndesire the same torrent file. These issues cause nTorrent interests to be\nunable to be processed or prevent peers from downloading their desired torrent\nfiles. In order to solve this issue, I implemented pure forwarding nodes that\nrepresent peers that do not run the nTorrent application and also extended the\noriginal nTorrent application to be able to forward interests for torrent files\nother than their own desired torrent file. For this project, the solution is\nable to facilitate multi-hop communication through all nodes present in the\nenvironment whether or not they run nTorrent. \n\n"}
{"id": "1812.03421", "contents": "Title: Deep Learning in Downlink Coordinated Multipoint in New Radio\n  Heterogeneous Networks Abstract: We propose a method to improve the performance of the downlink coordinated\nmultipoint (DL CoMP) in heterogeneous fifth generation New Radio (NR) networks.\nThe standards-compliant method is based on the construction of a surrogate CoMP\ntrigger function using deep learning. The cooperating set is a single-tier of\nsub-6 GHz heterogeneous base stations operating in the frequency division\nduplex mode (i.e., no channel reciprocity). This surrogate function enhances\nthe downlink user throughput distribution through online learning of non-linear\ninteractions of features and lower bias learning models. In simulation, the\nproposed method outperforms industry standards in a realistic and scalable\nheterogeneous cellular environment. \n\n"}
{"id": "1812.03633", "contents": "Title: Efficient Training Management for Mobile Crowd-Machine Learning: A Deep\n  Reinforcement Learning Approach Abstract: In this letter, we consider the concept of Mobile Crowd-Machine Learning\n(MCML) for a federated learning model. The MCML enables mobile devices in a\nmobile network to collaboratively train neural network models required by a\nserver while keeping data on the mobile devices. The MCML thus addresses data\nprivacy issues of traditional machine learning. However, the mobile devices are\nconstrained by energy, CPU, and wireless bandwidth. Thus, to minimize the\nenergy consumption, training time and communication cost, the server needs to\ndetermine proper amounts of data and energy that the mobile devices use for\ntraining. However, under the dynamics and uncertainty of the mobile\nenvironment, it is challenging for the server to determine the optimal\ndecisions on mobile device resource management. In this letter, we propose to\nadopt a deep- Q learning algorithm that allows the server to learn and find\noptimal decisions without any a priori knowledge of network dynamics.\nSimulation results show that the proposed algorithm outperforms the static\nalgorithms in terms of energy consumption and training latency. \n\n"}
{"id": "1812.05032", "contents": "Title: Fission: A Provably Fast, Scalable, and Secure Permissionless Blockchain Abstract: We present Fission, a new permissionless blockchain that achieves scalability\nin both terms of system throughput and transaction confirmation time, while at\nthe same time, retaining blockchain's core values of equality and\ndecentralization. Fission overcomes the system throughput bottleneck by\nemploying a novel Eager-Lazy pipeling model that achieves very high system\nthroughputs via block pipelining, an adaptive partitioning mechanism that\nauto-scales to transaction volumes, and a provably secure energy-efficient\nconsensus protocol to ensure security and robustness. Fission applies a hybrid\nnetwork which consists of a relay network, and a peer-to-peer network. The goal\nof the relay network is to minimize the transaction confirmation time by\nminimizing the information propagation latency. To optimize the performance on\nthe relay network in the presence of churn, dynamic network topologies, and\nnetwork heterogeneity, we propose an ultra-fast game-theoretic relay selection\nalgorithm that achieves near-optimal performance in a fully distributed manner.\nFission's peer-to-peer network complements the relay network and provides a\nvery high data availability via enabling users to contribute their storage and\nbandwidth for information dissemination (with incentive). We propose a\ndistributed online data retrieval strategy that optimally offloads the relay\nnetwork without degrading the system performance. By re-innovating all the core\nelements of the blockchain technology - computation, networking, and storage -\nin a holistic manner, Fission aims to achieve the best balance among\nscalability, security and decentralization. \n\n"}
{"id": "1812.05534", "contents": "Title: Constraint programming for flexible Service Function Chaining deployment Abstract: Network Function Virtualization (NFV) and Software Defined Networking (SDN)\nare technologies that recently acquired a great momentum thanks to their\npromise of being a flexible and cost-effective solution for replacing\nhardware-based, vendor-dependent network middleboxes with software appliances\nrunning on general purpose hardware in the cloud. Delivering end-to-end\nnetworking services across multiple NFV/SDN network domains by implementing the\nso-called Service Function Chain (SFC) i.e., a sequence of Virtual Network\nFunctions (VNF) that composes the service, is a challenging task. In this paper\nwe address two crucial sub-problems of this task: i) the language to formalize\nthe request of a given SFC to the network and ii) the solution of the SFC\ndesign problem, once the request is received. As for i) in our solution the\nrequest is built upon the intent-based approach, with a syntax that focuses on\nasking the user \"what\" she needs and not \"how\" it should be implemented, in a\nsimple and high level language. Concerning ii) we define a formal model\ndescribing network architectures and VNF properties that is then used to solve\nthe SFC design problem by means of Constraint Programming (CP), a programming\nparadigm which is often used in Artificial Intelligence applications. We argue\nthat CP can be effectively used to address this kind of problems because it\nprovides very expressive and flexible modeling languages which come with\npowerful solvers, thus providing efficient and scalable performance. We\nsubstantiate this claim by validating our tool on some typical and non trivial\nSFC design problems. \n\n"}
{"id": "1812.05670", "contents": "Title: When to Preempt? Age of Information Minimization under Link Capacity\n  Constraint Abstract: In this paper, we consider a scenario where a source continuously monitors an\nobject and sends time-stamped status updates to a destination through a\nrate-limited link. We assume updates arrive randomly at the source according to\na Bernoulli process. Due to the link capacity constraint, it takes multiple\ntime slots for the source to complete the transmission of an update. Therefore,\nwhen a new update arrives at the source during the transmission of another\nupdate, the source needs to decide whether to skip the new arrival or to switch\nto it, in order to minimize the expected average age of information (AoI) at\nthe destination. We start with the setting where all updates are of the same\nsize, and prove that within a broadly defined class of online policies, the\noptimal policy should be a renewal policy, and has a sequential switching\nproperty. We then show that the optimal decision of the source in any time slot\nhas threshold structures, and only depends on the age of the update being\ntransmitted and the AoI at the destination. We then consider the setting where\nupdates are of different sizes, and show that the optimal Markovian policy also\nhas a multiple-threshold structure. For each of the settings, we explicitly\nidentify the thresholds by formulating the problem as a Markov Decision Process\n(MDP), and solve it through value iteration. Special structural properties of\nthe corresponding optimal policy are utilized to reduce the computational\ncomplexity of the value iteration algorithm. \n\n"}
{"id": "1812.06183", "contents": "Title: Iris: Deep Reinforcement Learning Driven Shared Spectrum Access\n  Architecture for Indoor Neutral-Host Small Cells Abstract: We consider indoor mobile access, a vital use case for current and future\nmobile networks. For this key use case, we outline a vision that combines a\nneutral-host based shared small-cell infrastructure with a common pool of\nspectrum for dynamic sharing as a way forward to proliferate indoor small-cell\ndeployments and open up the mobile operator ecosystem. Towards this vision, we\nfocus on the challenges pertaining to managing access to shared spectrum (e.g.,\n3.5GHz US CBRS spectrum). We propose Iris, a practical shared spectrum access\narchitecture for indoor neutral-host small-cells. At the core of Iris is a deep\nreinforcement learning based dynamic pricing mechanism that efficiently\nmediates access to shared spectrum for diverse operators in a way that provides\nincentives for operators and the neutral-host alike. We then present the Iris\nsystem architecture that embeds this dynamic pricing mechanism alongside\ncloud-RAN and RAN slicing design principles in a practical neutral-host design\ntailored for the indoor small-cell environment. Using a prototype\nimplementation of the Iris system, we present extensive experimental evaluation\nresults that not only offer insight into the Iris dynamic pricing process and\nits superiority over alternative approaches but also demonstrate its deployment\nfeasibility. \n\n"}
{"id": "1812.08148", "contents": "Title: Minimizing Age of Information with Soft Updates Abstract: We consider an information updating system where an information provider and\nan information receiver engage in an update process over time. Different from\nthe existing literature where updates are countable (hard) and take effect\neither immediately or after a delay, but $instantaneously$ in both cases, here\nupdates start taking effect right away but $gradually$ over time. We coin this\nsetting $soft$ $updates$. When the updating process starts, the age decreases\nuntil the soft update period ends. We constrain the number of times the\ninformation provider and the information receiver meet (number of update\nperiods) and the total duration of the update periods. We consider two models\nfor the decrease of age during an update period: In the first model, the rate\nof decrease of age is proportional to the current age, and in the second model,\nthe rate of decrease of age is constant. The first model results in an\nexponentially decaying age, and the second model results in a linearly decaying\nage. In both cases, we determine the optimum updating schemes, by determining\nthe optimum start times and optimum durations of the updates, subject to the\nconstraints on the number of update periods and the total update duration. \n\n"}
{"id": "1812.08265", "contents": "Title: Statistical learning of geometric characteristics of wireless networks Abstract: Motivated by the prediction of cell loads in cellular networks, we formulate\nthe following new, fundamental problem of statistical learning of geometric\nmarks of point processes: An unknown marking function, depending on the\ngeometry of point patterns, produces characteristics (marks) of the points. One\naims at learning this function from the examples of marked point patterns in\norder to predict the marks of new point patterns. To approximate (interpolate)\nthe marking function, in our baseline approach, we build a statistical\nregression model of the marks with respect some local point distance\nrepresentation. In a more advanced approach, we use a global data\nrepresentation via the scattering moments of random measures, which build\ninformative and stable to deformations data representation, already proven\nuseful in image analysis and related application domains. In this case, the\nregression of the scattering moments of the marked point patterns with respect\nto the non-marked ones is combined with the numerical solution of the inverse\nproblem, where the marks are recovered from the estimated scattering moments.\nConsidering some simple, generic marks, often appearing in the modeling of\nwireless networks, such as the shot-noise values, nearest neighbour distance,\nand some characteristics of the Voronoi cells, we show that the scattering\nmoments can capture similar geometry information as the baseline approach, and\ncan reach even better performance, especially for non-local marking functions.\nOur results motivate further development of statistical learning tools for\nstochastic geometry and analysis of wireless networks, in particular to predict\ncell loads in cellular networks from the locations of base stations and traffic\ndemand. \n\n"}
{"id": "1812.08286", "contents": "Title: On the Role of Age of Information in the Internet of Things Abstract: In this article, we provide an accessible introduction to the emerging idea\nof Age of Information (AoI) that quantifies freshness of information and\nexplore its possible role in the efficient design of freshness-aware Internet\nof Things (IoT). We start by summarizing the concept of AoI and its variants\nwith emphasis on the differences between AoI and other well-known performance\nmetrics in the literature, such as throughput and delay. Building on this, we\nexplore freshness-aware IoT design for a network in which IoT devices sense\npotentially different physical processes and are supposed to frequently update\nthe status of these processes at a destination node (such as a cellular base\nstation). Inspired by the recent interest, we also assume that these IoT\ndevices are powered by wireless energy transfer by the destination node. For\nthis setting, we investigate the optimal sampling policy that jointly optimizes\nwireless energy transfer and scheduling of update packet transmissions from IoT\ndevices with the goal of minimizing long-term weighted sum-AoI. Using this, we\ncharacterize the achievable AoI region. We also compare this AoI-optimal policy\nwith the one that maximizes average throughput (throughput-optimal policy), and\ndemonstrate the impact of system state on their structures. Several promising\ndirections for future research are also presented. \n\n"}
{"id": "1812.09201", "contents": "Title: Age of Information Performance of Multiaccess Strategies with Packet\n  Management Abstract: We consider a system consisting of $N$ source nodes communicating with a\ncommon receiver. Each source node has a buffer of infinite capacity to store\nincoming bursty traffic in the form of status updates transmitted in packets,\nwhich should maintain the status information at the receiver fresh. Packets\nwaiting for transmission can be discarded to avoid wasting network resources\nfor the transmission of stale information. We investigate the age of\ninformation (AoI) performance of the system under scheduled and random access.\nMoreover, we present analysis of the AoI with and without packet management at\nthe transmission queue of the source nodes, where as packet management we\nconsider the capability to replace unserved packets at the queue whenever newer\nones arrive. Finally, we provide simulation results that illustrate the impact\nof the network operating parameters on the age performance of the different\naccess protocols. \n\n"}
{"id": "1812.09761", "contents": "Title: How to Achieve High Classification Accuracy with Just a Few Labels: A\n  Semi-supervised Approach Using Sampled Packets Abstract: Network traffic classification, which has numerous applications from security\nto billing and network provisioning, has become a cornerstone of today's\ncomputer networks. Previous studies have developed traffic classification\ntechniques using classical machine learning algorithms and deep learning\nmethods when large quantities of labeled data are available. However, capturing\nlarge labeled datasets is a cumbersome and time-consuming process. In this\npaper, we propose a semi-supervised approach that obviates the need for large\nlabeled datasets. We first pre-train a model on a large unlabeled dataset where\nthe input is the time series features of a few sampled packets. Then the\nlearned weights are transferred to a new model that is re-trained on a small\nlabeled dataset. We show that our semi-supervised approach achieves almost the\nsame accuracy as a fully-supervised method with a large labeled dataset, though\nwe use only 20 samples per class. In tests based on a dataset generated from\nthe more challenging QUIC protocol, our approach yields 98% accuracy. To show\nits efficacy, we also test our approach on two public datasets. Moreover, we\nstudy three different sampling techniques and demonstrate that sampling packets\nfrom an arbitrary portion of a flow is sufficient for classification. \n\n"}
{"id": "1812.10015", "contents": "Title: Energy Efficient Massive MIMO through Distributed Precoder Design Abstract: This paper presents an energy-efficient downlink precoding scheme with the\nobjective of maximizing system energy efficiency in a multi-cell massive MIMO\nsystem. The proposed precoding design jointly considers the issues of power\ncontrol, interference management, antenna switching and user throughput in a\ncluster of base stations (BS). We demonstrate that the precoding design can be\nformulated into a general sparsity-inducing non-convex problem, which is\nNP-hard. We thus apply a smooth approximation of zero-norm in the antenna power\nmanagement to enable the application of the gradient-based algorithms. The\nnon-convexity of the problem may also cause slow convergence or even divergence\nif some classical gradient algorithms are directly applied. We thus develop an\nefficient alternative algorithm combining features from augmented multiplier\n(AM) and quadratic programming (QP) to guarantee the convergence. We\ntheoretically prove the convergence conditions for our algorithm both locally\nand globally under realistic assumptions. Our proposed algorithms further\nfacilitate a distributed implementation that reduces backhaul overhead by\noffloading data-intensive steps to local computation at each BS. Numerical\nresults confirm that our methods indeed achieve higher energy efficiency with\nsuperior convergence rate, compared to some well-known existing methods. \n\n"}
{"id": "1812.10455", "contents": "Title: Age of Information in Multihop Multicast Networks Abstract: We consider the age of information in a multihop multicast network where\nthere is a single source node sending time-sensitive updates to $n^L$ end\nnodes, and $L$ denotes the number of hops. In the first hop, the source node\nsends updates to $n$ first-hop receiver nodes, and in the second hop each\nfirst-hop receiver node relays the update packets that it has received to $n$\nfurther users that are connected to it. This network architecture continues in\nfurther hops such that each receiver node in hop $\\ell$ is connected to $n$\nfurther receiver nodes in hop $\\ell+1$. We study the age of information\nexperienced by the end nodes, and in particular, its scaling as a function of\n$n$. We show that, using an earliest $k$ transmission scheme in each hop, the\nage of information at the end nodes can be made a constant independent of $n$.\nIn particular, the source node transmits each update packet to the earliest\n$k_1$ of the $n$ first-hop nodes, and each first-hop node that receives the\nupdate relays it to the earliest $k_2$ out of $n$ second-hop nodes that are\nconnected to it and so on. We determine the optimum $k_\\ell$ stopping value for\neach hop $\\ell$ for arbitrary shifted exponential link delays. \n\n"}
{"id": "1812.11429", "contents": "Title: Modeling, Simulating and Configuring Programmable Wireless Environments\n  for Multi-User Multi-Objective Networking Abstract: Programmable wireless environments enable the software-defined propagation of\nwaves within them, yielding exceptional performance potential. Several\nbuilding-block technologies have been implemented and evaluated at the physical\nlayer. The present work contributes a network-layer scheme to configure such\nenvironments for multiple users and objectives, and for any physical-layer\ntechnology. Supported objectives include any combination of Quality of Service\nand power transfer optimization, eavesdropping and Doppler effect mitigation,\nin multi-cast or uni-cast settings. Additionally, a graph-based model of\nprogrammable environments is proposed, which incorporates core physical\nobservations and efficiently separates physical and networking concerns.\nEvaluation takes place in a specially developed, free simulation tool, and in a\nvariety of environments. Performance gains over regular propagation are\nhighlighted, reaching important insights on the user capacity of programmable\nenvironments. \n\n"}
{"id": "1812.11439", "contents": "Title: A Comprehensive Analysis of Swarming-based Live Streaming to Leverage\n  Client Heterogeneity Abstract: Due to missing IP multicast support on an Internet scale, over-the-top media\nstreams are delivered with the help of overlays as used by content delivery\nnetworks and their peer-to-peer (P2P) extensions. In this context,\nmesh/pull-based swarming plays an important role either as pure streaming\napproach or in combination with tree/push mechanisms. However, the impact of\nrealistic client populations with heterogeneous resources is not yet fully\nunderstood. In this technical report, we contribute to closing this gap by\nmathematically analysing the most basic scheduling mechanisms latest deadline\nfirst (LDF) and earliest deadline first (EDF) in a continuous time Markov chain\nframework and combining them into a simple, yet powerful, mixed strategy to\nleverage inherent differences in client resources. The main contributions are\ntwofold: (1) a mathematical framework for swarming on random graphs is proposed\nwith a focus on LDF and EDF strategies in heterogeneous scenarios; (2) a mixed\nstrategy, named SchedMix, is proposed that leverages peer heterogeneity. The\nproposed strategy, SchedMix is shown to outperform the other two strategies\nusing different abstractions: a mean-field theoretic analysis of buffer\nprobabilities, simulations of a stochastic model on random graphs, and a\nfull-stack implementation of a P2P streaming system. \n\n"}
{"id": "1901.00038", "contents": "Title: Poor Video Streaming Performance Explained (and Fixed) Abstract: HTTP-based video streaming is a key application on the Internet today,\ncomprising the majority of Internet traffic today. Yet customers remain\ndissatisfied with video quality, resulting in lost revenue for content\nproviders. Recent studies have blamed this on the adaptive bitrate selection\n(ABR) algorithm used by client players, claiming it interacts poorly with TCP\nwhen the video buffer is full, which causes it to underestimate available\nnetwork bandwidth.\n  We show that the root cause of the problem lies in the data plane, and that\neven a perfect control plane (ABR) algorithm is not enough to guarantee video\nflows their fair share of network bandwidth. Namely, it is the sequential\ndownload of (small) video segments that is at fault, as they disrupt the normal\ninteraction between TCP congestion control and router queue occupancy. We\nanalytically derive the throughput of a video flow as a function of download\nsize and network conditions, and use this to develop an adaptive algorithm for\nselecting the download size. Combined with pipelining, our approach achieves\nnear-optimal throughput and fast bitrate adaptation, regardless of the control\nplane algorithm. We implement our approach as a DASH video player called\nSprint, and evaluate it against state-of-the-art proposals from the literature\nas well as deployed players from Netflix, Youtube, Hulu, and Amazon. Sprint\nconsistently achieves above 90% of its fair-share throughput, while the\nprevious state-of-the-art exhibits high variability (e.g., from 31% to close to\nfair share depending on the network conditions). Industry players often achieve\nbelow 50% of their fair share. \n\n"}
{"id": "1901.00406", "contents": "Title: Delay and Power Tradeoff with Consideration of Caching Capabilities in\n  Dense Wireless Networks Abstract: Enabling caching capabilities in dense small cell networks (DSCNs) has a\ndirect impact on file delivery delay and power consumption. Most existing work\nstudied these two performance metrics separately in cache-enabled DSCNs.\nHowever, file delivery delay and power consumption are coupled with each other\nand cannot be minimized simultaneously. In this paper, we investigate the\noptimal tradoff between these two performance metrics. Firstly, we formulate\nthe joint file delivery delay and power consumption optimization (JDPO) problem\nwhere power control, user association and file placement are jointly\nconsidered. Then we convert it to a form that can be handled by Generalized\nBenders Decomposition (GDB). with GDB, we decompose the converted JDPO problem\ninto two smaller problems, i.e., primal problem related to power control and\nmaster problem related to user association and file placement. An iterative\nalgorithm is proposed and proved to be $\\epsilon$-optimal, in which the primal\nproblem and master problem are solved iteratively to approach the optimal\nsolution. To further reduce the complexity of the master problem, an\naccelerated algorithm based on semi-definite relaxation is proposed. Finally,\nthe simulation results demonstrate that the proposed algorithm can approach the\noptimal tradeoff between file delivery delay and power consumption. \n\n"}
{"id": "1901.00963", "contents": "Title: Integrating Sub-6 GHz and Millimeter Wave to Combat Blockage:\n  Delay-Optimal Scheduling Abstract: Millimeter wave (mmWave) technologies have the potential to achieve very high\ndata rates, but suffer from intermittent connectivity. In this paper, we\nprovision an architecture to integrate sub-6 GHz and mmWave technologies, where\nwe incorporate the sub-6 GHz interface as a fallback data transfer mechanism to\ncombat blockage and intermittent connectivity of the mmWave communications. To\nthis end, we investigate the problem of scheduling data packets across the\nmmWave and sub-6 GHz interfaces such that the average delay of system is\nminimized. This problem can be formulated as Markov Decision Process. We first\ninvestigate the problem of discounted delay minimization, and prove that the\noptimal policy is of the threshold-type, i.e., data packets should always be\nrouted to the mmWave interface as long as the number of packets in the system\nis smaller than a threshold. Then, we show that the results of the discounted\ndelay problem hold for the average delay problem as well. Through numerical\nresults, we demonstrate that under heavy traffic, integrating sub-6 GHz with\nmmWave can reduce the average delay by up to 70%. Further, our scheduling\npolicy substantially reduces the delay over the celebrated MaxWeight policy. \n\n"}
{"id": "1901.01863", "contents": "Title: Beyond socket options: making the Linux TCP stack truly extensible Abstract: The Transmission Control Protocol (TCP) is one of the most important\nprotocols in today's Internet. Its specification and implementations have been\nrefined for almost forty years. The Linux TCP stack is one of the most widely\nused TCP stacks given its utilisation on servers and Android smartphones and\ntablets. However, TCP and its implementations evolve very slowly. In this\npaper, we demonstrate how to leverage the eBPF virtual machine that is part of\nthe recent versions of the Linux kernel to make the TCP stack easier to extend.\n  We demonstrate a variety of use cases where the eBPF code is injected inside\na running kernel to update or tune the TCP implementation. We first implement\nthe TCP User Timeout Option. Then we propose a new option that enables a client\nto request a server to use a specific congestion control scheme. Our third\nextension is a TCP option that sets the initial congestion window. We then\ndemonstrate how eBPF code can be used to tune the acknowledgment strategy. \n\n"}
{"id": "1901.02306", "contents": "Title: Tutorial on UAV: A Blue Sky View on Wireless Communication Abstract: The growing use of Unmanned Aerial Vehicles (UAVs) for various applications\nrequires ubiquitous and reliable connectivity for safe control and data\nexchange between these devices and ground terminals. Depending on the\napplication, UAV-mounted wireless equipment can either be an aerial user\nequipment (AUE) that co-exists with the terrestrial users, or it can be a part\nof wireless infrastructure providing a range of services to the ground users.\nFor instance, AUE can be used for real-time search and rescue and Aerial Base\nStation (ABS) can enhance coverage, capacity and energy efficiency of wireless\nnetworks. In both cases, UAV-based solutions are scalable, mobile, fast to\ndeploy. However, several technical challenges have to be addressed. In this\nwork, we present a tutorial on wireless communication with UAVs, taking into\naccount a wide range of potential applications. The main goal of this work is\nto provide a complete overview of the main scenarios (AUE and ABS), channel and\nperformance models, compare them, and discuss open research points. This work\ngives a comprehensive overview of the research done until now and depicts a\ncomprehensive picture to foster new ideas and solutions while avoiding\nduplication of past work. We start by discussing the open challenges of\nwireless communication with UAVs. To give answers to the posed questions, we\nfocus on the UAV communication basics, mainly providing the necessary channel\nmodeling background and giving guidelines on how various channel models should\nbe used. Next, theoretical, simulation- and measurement-based approaches, to\naddress the key challenges for AUE usage, are presented. Moreover, in this\nwork, we aim to provide a comprehensive overview on how UAV-mounted equipment\ncan be used as a part of a communication network. Based on the theoretical\nanalysis, we show how various network parameters can be optimized. \n\n"}
{"id": "1901.02873", "contents": "Title: Waiting before Serving: A Companion to Packet Management in Status\n  Update Systems Abstract: In this paper, we explore the potential of server waiting before packet\ntransmission in improving the Age of Information (AoI) in status update\nsystems. We consider a non-preemptive queue with Poisson arrivals and\nindependent general service distribution and we incorporate waiting before\nserving in two packet management schemes: M/GI/1/1 and M/GI/1/$2^*$. In\nM/GI/1/1 scheme, the server waits for a deterministic time immediately after a\npacket enters the server. In M/GI/1/$2^*$ scheme, depending on idle or busy\nsystem state, the server waits for a deterministic time before starting service\nof the packet. In both cases, if a potential newer arrival is captured existing\npacket is discarded. Different from most existing works, we analyze AoI\nevolution by indexing the incoming packets, which is enabled by an alternative\nmethod of partitioning the area under the evolution of instantaneous AoI to\ncalculate its time average. We obtain expressions for average and average peak\nAoI for both queueing disciplines with waiting. Our numerical results\ndemonstrate that waiting before service can bring significant improvement in\naverage age, particularly, for heavy-tailed service distributions. This\nimprovement comes at the expense of an increase in average peak AoI. We\nhighlight the trade-off between average and average peak AoI generated by\nwaiting before serving. \n\n"}
{"id": "1901.03239", "contents": "Title: 6G: The Next Frontier Abstract: The current development of 5G networks represents a breakthrough in the\ndesign of communication networks, for its ability to provide a single platform\nenabling a variety of different services, from enhanced mobile broadband\ncommunications, automated driving, Internet-of-Things, with its huge number of\nconnected devices, etc. Nevertheless, looking at the current development of\ntechnologies and new services, it is already possible to envision the need to\nmove beyond 5G with a new architecture incorporating new services and\ntechnologies. The goal of this paper is to motivate the need to move to a sixth\ngeneration (6G) of mobile communication networks, starting from a gap analysis\nof 5G, and predicting a new synthesis of near future services, like hologram\ninterfaces, ambient sensing intelligence, a pervasive introduction of\nartificial intelligence and the incorporation of technologies, like TeraHertz\n(THz) or Visible Light Communications (VLC), 3-dimensional coverage. \n\n"}
{"id": "1901.03404", "contents": "Title: Handcrafted vs Deep Learning Classification for Scalable Video QoE\n  Modeling Abstract: Mobile video traffic is dominant in cellular and enterprise wireless\nnetworks. With the advent of diverse applications, network administrators face\nthe challenge to provide high QoE in the face of diverse wireless conditions\nand application contents. Yet, state-of-the-art networks lack analytics for\nQoE, as this requires support from the application or user feedback. While\nthere are existing techniques to map QoS to QoE by training machine learning\nmodels without requiring user feedback, these techniques are limited to only\nfew applications, due to insufficient QoE ground-truth annotation for ML. To\naddress these limitations, we focus on video telephony applications and model\nkey artefacts of spatial and temporal video QoE. Our key contribution is\ndesigning content- and device-independent metrics and training across diverse\nWiFi conditions. We show that our metrics achieve a median 90% accuracy by\ncomparing with mean-opinion-score from more than 200 users and 800 video\nsamples over three popular video telephony applications -- Skype, FaceTime and\nGoogle Hangouts. We further extend our metrics by using deep neural networks,\nmore specifically we use a combined CNN and LSTM model. We achieve a median\naccuracy of 95% by combining our QoE metrics with the deep learning model,\nwhich is a 38% improvement over the state-of-the-art well known techniques. \n\n"}
{"id": "1901.04167", "contents": "Title: Age-Delay Tradeoffs in Single Server Systems Abstract: Information freshness and low latency communication is important to many\nemerging applications. While Age of Information (AoI) serves as a metric of\ninformation freshness, packet delay is a traditional metric of communication\nlatency. We prove that there is a natural tradeoff between the AoI and packet\ndelay. We consider a single server system, in which at most one update packet\ncan be serviced at a time. The system designer controls the order in which the\npackets get serviced and the service time distribution, with a given service\nrate. We analyze two tradeoff problems that minimize packet delay and the\nvariance in packet delay, respectively, subject to an average age constraint.\nWe prove a strong age-delay and age-delay variance tradeoff, wherein, as the\naverage age approaches its minimum, the delay and its variance approach\ninfinity. We show that the service time distribution that mininizes average\nage, must necessarily have an unbounded-second moment. \n\n"}
{"id": "1901.04957", "contents": "Title: Improved Credit Bounds for the Credit-Based Shaper in Time-Sensitive\n  Networking Abstract: In Time-Sensitive Networking (TSN), it is important to formally prove per\nflow latency and backlog bounds. To this end, recent works apply network\ncalculus and obtain latency bounds from service curves. The latency component\nof such service curves is directly derived from upper bounds on the values of\nthe credit counters used by the Credit-Based Shaper (CBS), an essential\nbuilding-block of TSN. In this paper, we derive and formally prove credit upper\nbounds for CBS, which improve on existing bounds. \n\n"}
{"id": "1901.05096", "contents": "Title: Status from a Random Field: How Densely Should One Update? Abstract: In many applications, status information of a general spatial process, in\ncontrast to a point information source, is of interest. In this paper, we\nconsider a system where status information is drawn from a random field and\ntransmitted to a fusion center through a wireless multiaccess channel. The\noptimal density of spatial sampling points to minimize the remote status\nestimation error is investigated. Assuming a one-dimensional Gauss Markov\nrandom field and an exponential correlation function, closed-form expressions\nof remote estimation error are obtained for First-Come First-Served (FCFS) and\nLast-Come First-Served (LCFS) service disciplines. The optimal spatial sampling\ndensity for the LCFS case is given explicitly. Simulation results are presented\nwhich agree with our analysis. \n\n"}
{"id": "1901.06637", "contents": "Title: UAV Communications for 5G and Beyond: Recent Advances and Future Trends Abstract: Providing ubiquitous connectivity to diverse device types is the key\nchallenge for 5G and beyond 5G (B5G). Unmanned aerial vehicles (UAVs) are\nexpected to be an important component of the upcoming wireless networks that\ncan potentially facilitate wireless broadcast and support high rate\ntransmissions. Compared to the communications with fixed infrastructure, UAV\nhas salient attributes, such as flexible deployment, strong line-of-sight (LoS)\nconnection links, and additional design degrees of freedom with the controlled\nmobility. In this paper, a comprehensive survey on UAV communication towards\n5G/B5G wireless networks is presented. We first briefly introduce essential\nbackground and the space-air-ground integrated networks, as well as discuss\nrelated research challenges faced by the emerging integrated network\narchitecture. We then provide an exhaustive review of various 5G techniques\nbased on UAV platforms, which we categorize by different domains including\nphysical layer, network layer, and joint communication, computing and caching.\nIn addition, a great number of open research problems are outlined and\nidentified as possible future research directions. \n\n"}
{"id": "1901.07728", "contents": "Title: Broadcasting Real-Time Flows in Integrated Backhaul and Access 5G\n  Networks Abstract: This paper studies the problem of broadcasting real-time flows in multi-hop\nwireless networks. We consider that each packet has a stringent deadline, and\neach node in the network obtains some utility based on the number of packets\ndelivered to it on time for each flow. We propose a distributed protocol, the\ndelegated-set routing (DSR) protocol, that incurs virtually no overhead of\ncoordination among nodes. We also develop distributed algorithms that aim to\nmaximize the total system utility under DSR. The utility of our DSR protocol\nand distributed algorithms are demonstrated by both theoretical analysis and\nsimulation results, where we show that our algorithms achieve better\nperformance even when compared against centralized throughput optimal policies. \n\n"}
{"id": "1901.07768", "contents": "Title: Cooperation Speeds Surfing: Use Co-Bandit! Abstract: In this paper, we explore the benefit of cooperation in adversarial bandit\nsettings. As a motivating example, we consider the problem of wireless network\nselection. Mobile devices are often required to choose the right network to\nassociate with for optimal performance, which is non-trivial. The excellent\ntheoretical properties of EXP3, a leading multi-armed bandit algorithm, suggest\nthat it should work well for this type of problem. Yet, it performs poorly in\npractice. A major limitation is its slow rate of stabilization. Bandit-style\nalgorithms perform better when global knowledge is available, i.e., when\ndevices receive feedback about all networks after each selection. But,\nunfortunately, communicating full information to all devices is expensive.\nTherefore, we address the question of how much information is adequate to\nachieve better performance. We propose Co-Bandit, a novel cooperative bandit\napproach, that allows devices to occasionally share their observations and\nforward feedback received from neighbors; hence, feedback may be received with\na delay. Devices perform network selection based on their own observation and\nfeedback from neighbors. As such, they speed up each other's rate of learning.\nWe prove that Co-Bandit is regret-minimizing and retains the convergence\nproperty of multiplicative weight update algorithms with full information.\nThrough simulation, we show that a very small amount of information, even with\na delay, is adequate to nudge each other to select the right network and yield\nsignificantly faster stabilization at the optimal state (about 630x faster than\nEXP3). \n\n"}
{"id": "1901.08326", "contents": "Title: A stack-vector routing protocol for automatic tunneling Abstract: In a network, a tunnel is a part of a path where a protocol is encapsulated\nin another one. A tunnel starts with an encapsulation and ends with the\ncorresponding decapsulation. Several tunnels can be nested at some stage,\nforming a protocol stack. Tunneling is very important nowadays and it is\ninvolved in several tasks: IPv4/IPv6 transition, VPNs, security (IPsec, onion\nrouting), etc. However, tunnel establishment is mainly performed manually or by\nscript, which present obvious scalability issues. Some works attempt to\nautomate a part of the process (e.g., TSP, ISATAP, etc.). However, the\ndetermination of the tunnel(s) endpoints is not fully automated, especially in\nthe case of an arbitrary number of nested tunnels. The lack of routing\nprotocols performing automatic tunneling is due to the unavailability of path\ncomputation algorithms taking into account encapsulations and decapsulations.\nThere is a polynomial centralized algorithm to perform the task. However, to\nthe best of our knowledge, no fully distributed path computation algorithm is\nknown. Here, we propose the first fully distributed algorithm for path\ncomputation with automatic tunneling, i.e., taking into account encapsulation,\ndecapsulation and conversion of protocols. Our algorithm is a generalization of\nthe distributed Bellman-Ford algorithm, where the distance vector is replaced\nby a protocol stack vector. This allows to know how to route a packet with some\nprotocol stack. We prove that the messages size of our algorithm is polynomial,\neven if the shortest path can be of exponential length. We also prove that the\nalgorithm converges after a polynomial number of steps in a synchronized\nsetting. We adapt our algorithm into a proto-protocol for routing with\nautomatic tunneling and we show its efficiency through simulations. \n\n"}
{"id": "1901.08329", "contents": "Title: When Machine Learning Meets Big Data: A Wireless Communication\n  Perspective Abstract: We have witnessed an exponential growth in commercial data services, which\nhas lead to the 'big data era'. Machine learning, as one of the most promising\nartificial intelligence tools of analyzing the deluge of data, has been invoked\nin many research areas both in academia and industry. The aim of this article\nis twin-fold. Firstly, we briefly review big data analysis and machine\nlearning, along with their potential applications in next-generation wireless\nnetworks. The second goal is to invoke big data analysis to predict the\nrequirements of mobile users and to exploit it for improving the performance of\n\"social network-aware wireless\". More particularly, a unified big data aided\nmachine learning framework is proposed, which consists of feature extraction,\ndata modeling and prediction/online refinement. The main benefits of the\nproposed framework are that by relying on big data which reflects both the\nspectral and other challenging requirements of the users, we can refine the\nmotivation, problem formulations and methodology of powerful machine learning\nalgorithms in the context of wireless networks. In order to characterize the\nefficiency of the proposed framework, a pair of intelligent practical\napplications are provided as case studies: 1) To predict the positioning of\ndrone-mounted areal base stations (BSs) according to the specific tele-traffic\nrequirements by gleaning valuable data from social networks. 2) To predict the\ncontent caching requirements of BSs according to the users' preferences by\nmining data from social networks. Finally, open research opportunities are\nidentified for motivating future investigations. \n\n"}
{"id": "1901.08919", "contents": "Title: Wireless Broadcast with short labelling Abstract: In this paper, we study the broadcast problem in wireless networks when the\nbroadcast is helped by a labelling scheme. We focus on two variants of\nbroadcast: broadcast without acknowledgment (i.e. the initiator of the\nbroadcast is not notified at the end of broadcast) and broadcast with\nacknowledgment. Our contribution is threefold. First, we improve in terms of\nmemory complexity a recent labelling-based broadcast scheme with acknowledgment\ndesigned for arbitrary networks.Second, we propose label optimal broadcast\nalgorithms in Level Separable Networks (a class of networks issued from recent\nstudies in Wireless Body Area Networks). In this class of networks we propose\nan acknowledgment-free broadcast strategy using 1-bit labels and broadcast with\nacknowledgment using 2-bits labels. In the class of level-separable networks,\nour algorithms finish within 2D rounds, where D is the eccentricity of the\nbroadcast initiator. Interestingly, the time complexity of broadcast in the\ncase of level-separable networks does not depend on the size of the network but\nrather on the initiator eccentricity which makes this class of graphs\ninteresting for further investigation. Finally, we study the hardness of\ndetermining that a graph is level separable. Our study shows that even though\nchecking that a separation is a level separation can be done in polynomial\ntime, determining that a graph has the level separable property is NP-complete.\nThis result opens interesting independent research directions. \n\n"}
{"id": "1901.08946", "contents": "Title: Joint Service Placement and Request Routing in Multi-cell Mobile Edge\n  Computing Networks Abstract: The proliferation of innovative mobile services such as augmented reality,\nnetworked gaming, and autonomous driving has spurred a growing need for\nlow-latency access to computing resources that cannot be met solely by existing\ncentralized cloud systems. Mobile Edge Computing (MEC) is expected to be an\neffective solution to meet the demand for low-latency services by enabling the\nexecution of computing tasks at the network-periphery, in proximity to\nend-users. While a number of recent studies have addressed the problem of\ndetermining the execution of service tasks and the routing of user requests to\ncorresponding edge servers, the focus has primarily been on the efficient\nutilization of computing resources, neglecting the fact that non-trivial\namounts of data need to be stored to enable service execution, and that many\nemerging services exhibit asymmetric bandwidth requirements. To fill this gap,\nwe study the joint optimization of service placement and request routing in\nMEC-enabled multi-cell networks with multidimensional\n(storage-computation-communication) constraints. We show that this problem\ngeneralizes several problems in literature and propose an algorithm that\nachieves close-to-optimal performance using randomized rounding. Evaluation\nresults demonstrate that our approach can effectively utilize the available\nresources to maximize the number of requests served by low-latency edge cloud\nservers. \n\n"}
{"id": "1901.09129", "contents": "Title: Optimal $k$-Coverage Charging Problem Abstract: Wireless rechargeable sensor networks, consisting of sensor nodes with\nrechargeable batteries and mobile chargers to replenish their batteries, have\ngradually become a promising solution to the bottleneck of energy limitation\nthat hinders the wide deployment of wireless sensor networks (WSN). In this\npaper, we focus on the mobile charger scheduling and path optimization scenario\nin which the $k$-coverage ability of a network system needs to be maintained.\nWe formulate the optimal $k$-coverage charging problem of finding a feasible\npath for a mobile charger to charge a set of sensor nodes within their\nestimated charging deadlines under the constraint of maintaining the\n$k$-coverage ability of the network system, with an objective of minimizing the\nenergy consumption on traveling per tour. We show the hardness of the problem\nthat even finding a feasible path for the trivial case of the problem is an\nNP-complete one.\n  We model the problem and apply dynamic programming to design an algorithm\nthat finds an exact solution to the optimal $k$-coverage charging problem.\nHowever, the computational complexity is still prohibitive for large size\nnetworks. We then introduce Deep Q-learning, a reinforcement learning algorithm\nto tackle the problem. \n\n"}
{"id": "1901.09357", "contents": "Title: End-to-End Performance Analysis of Underwater Optical Wireless Relaying\n  and Routing Techniques Under Location Uncertainty Abstract: On the contrary of low speed and high delay acoustic systems, underwater\noptical wireless communication (UOWC) can deliver a high speed and low latency\nservice at the expense of short communication ranges. Therefore, multihop\ncommunication is of utmost importance to improve degree of connectivity and\noverall performance of underwater optical wireless networks (UOWNs). In this\nregard, this paper investigates relaying and routing techniques and provides\ntheir end-to-end (E2E) performance analysis under the location uncertainty. To\nachieve robust and reliable links, we first consider adaptive beamwidths and\nderive the divergence angles under the absence and presence of a\npointing-acquisitioning-and-tracking (PAT) mechanism. Thereafter, important E2E\nperformance metrics (e.g., data rate, bit error rate, transmission power,\namplifier gain, etc.) are obtained for two potential relaying techniques;\ndecode & forward (DF) and optical amplify & forward (AF). We develop\ncentralized routing schemes for both relaying techniques to optimize E2E rate,\nbit error rate, and power consumption. Alternatively, a distributed routing\nprotocol, namely Light Path Routing (LiPaR), is proposed by leveraging the\nrange-beamwidth tradeoff of UOWCs. LiPaR is especially shown to be favorable\nwhen there is no PAT mechanism and available network information. In order to\nshow the benefits of multihop communications, extensive simulations are\nconducted to compare different routing and relaying schemes under different\nnetwork parameters and underwater environments. \n\n"}
{"id": "1901.09389", "contents": "Title: Cloud-based Queuing Model for Tactile Internet in Next Generation of RAN Abstract: Ultra-low latency is the most important requirement of the Tactile Internet\n(TI), which is one of the proposed services for the next-generation wireless\nnetwork (NGWN), e.g., fifth generation (5G) network. In this paper, a new\nqueuing model for the TI is proposed for the cloud radio access network (CRAN)\narchitecture of the NGWN by applying power domain non-orthogonal multiple\naccess (PD-NOMA) technology. In this model, we consider both the radio remote\nhead (RRH) and baseband processing unit (BBU) queuing delays for each\nend-to-end (E2E) connection between a pair of tactile users. In our setup, to\nminimize the transmit power of users subject to guaranteeing an acceptable\ndelay of users, and fronthaul and access constraints, we formulate a resource\nallocation (RA) problem. Furthermore, we dynamically set the fronthaul and\naccess links to minimize the total transmit power. Given that the proposed RA\nproblem is highly non-convex, in order to solve it, we utilize diverse\ntransformation techniques such as successive convex approximation (SCA) and\ndifference of two convex functions (DC). Numerical results show that by dynamic\nadjustment of the access and fronthaul delays, transmit power reduces in\ncomparison with the fixed approach per each connection. Also, energy efficiency\nof orthogonal frequency division multiple access (OFDMA) and PD-NOMA are\ncompared for our setup. \n\n"}
{"id": "1901.09424", "contents": "Title: Identification of Smart Jammers: Learning based Approaches Using Wavelet\n  Representation Abstract: Smart jammer nodes can disrupt communication between a transmitter and a\nreceiver in a wireless network, and they leave traces that are undetectable to\nclassical jammer identification techniques, hidden in the time-frequency plane.\nThese traces cannot be effectively identified through the use of the classical\nFourier transform based time-frequency transformation (TFT) techniques with a\nfixed resolution. Inspired by the adaptive resolution property provided by the\nwavelet transforms, in this paper, we propose a jammer identification\nmethodology that includes a pre-processing step to obtain a multi-resolution\nimage, followed by the use of a classifier. Support vector machine (SVM) and\ndeep convolutional neural network (DCNN) architectures are investigated as\nclassifiers to automatically extract the features of the transformed signals\nand to classify them. Three different jamming attacks are considered, the\nbarrage jamming that targets the complete transmission bandwidth, the\nsynchronization signal jamming attack that targets synchronization signals and\nthe reference signal jamming attack that targets the reference signals in an\nLTE downlink transmission scenario. The performance of the proposed approach is\ncompared with the classical Fourier transform based TFT techniques,\ndemonstrating the efficacy of the proposed approach in the presence of smart\njammers. \n\n"}
{"id": "1901.10274", "contents": "Title: Multi-hop Backscatter Tag-to-Tag Networks Abstract: We characterize the performance of a backscatter tag-to-tag (T2T) multi-hop\nnetwork. For this, we developed a discrete component-based backscatter T2T\ntransceiver and a communication protocol suite. The protocol composed of a\nnovel (i) flooding-based link control tailored towards backscatter\ntransmission, and (ii) low-power listening MAC. The MAC design is based on the\nnew insight that backscatter reception is more energy costly than transmission.\nOur experiments show that multi-hopping extends the coverage of backscatter\nnetworks by enabling longer backward T2T links (tag far from the exciter\nsending to the tag close to the exciter). Four hops, for example, extend the\ncommunication range by a factor of two. Furthermore, we show that dead spots in\nmulti-hop T2T networks are far less significant than those in the single-hop\nT2T networks. \n\n"}
{"id": "cond-mat/0203227", "contents": "Title: Ising Model on Networks with an Arbitrary Distribution of Connections Abstract: We find the exact critical temperature $T_c$ of the nearest-neighbor\nferromagnetic Ising model on an `equilibrium' random graph with an arbitrary\ndegree distribution $P(k)$. We observe an anomalous behavior of the\nmagnetization, magnetic susceptibility and specific heat, when $P(k)$ is\nfat-tailed, or, loosely speaking, when the fourth moment of the distribution\ndiverges in infinite networks. When the second moment becomes divergent, $T_c$\napproaches infinity, the phase transition is of infinite order, and size effect\nis anomalously strong. \n\n"}
{"id": "cond-mat/0402143", "contents": "Title: Personal Email Networks: An Effective Anti-Spam Tool Abstract: We provide an automated graph theoretic method for identifying individual\nusers' trusted networks of friends in cyberspace. We routinely use our social\nnetworks to judge the trustworthiness of outsiders, i.e., to decide where to\nbuy our next car, or to find a good mechanic for it. In this work, we show that\nan email user may similarly use his email network, constructed solely from\nsender and recipient information available in the email headers, to distinguish\nbetween unsolicited commercial emails, commonly called \"spam\", and emails\nassociated with his circles of friends. We exploit the properties of social\nnetworks to construct an automated anti-spam tool which processes an individual\nuser's personal email network to simultaneously identify the user's core\ntrusted networks of friends, as well as subnetworks generated by spams. In our\nempirical studies of individual mail boxes, our algorithm classified\napproximately 53% of all emails as spam or non-spam, with 100% accuracy. Some\nof the emails are left unclassified by this network analysis tool. However, one\ncan exploit two of the following useful features. First, it requires no user\nintervention or supervised training; second, it results in no false negatives\ni.e., spam being misclassified as non-spam, or vice versa. We demonstrate that\nthese two features suggest that our algorithm may be used as a platform for a\ncomprehensive solution to the spam problem when used in concert with more\nsophisticated, but more cumbersome, content-based filters. \n\n"}
{"id": "cond-mat/0501169", "contents": "Title: Towards a Theory of Scale-Free Graphs: Definition, Properties, and\n  Implications (Extended Version) Abstract: Although the ``scale-free'' literature is large and growing, it gives neither\na precise definition of scale-free graphs nor rigorous proofs of many of their\nclaimed properties. In fact, it is easily shown that the existing theory has\nmany inherent contradictions and verifiably false claims. In this paper, we\npropose a new, mathematically precise, and structural definition of the extent\nto which a graph is scale-free, and prove a series of results that recover many\nof the claimed properties while suggesting the potential for a rich and\ninteresting theory. With this definition, scale-free (or its opposite,\nscale-rich) is closely related to other structural graph properties such as\nvarious notions of self-similarity (or respectively, self-dissimilarity).\nScale-free graphs are also shown to be the likely outcome of random\nconstruction processes, consistent with the heuristic definitions implicit in\nexisting random graph approaches. Our approach clarifies much of the confusion\nsurrounding the sensational qualitative claims in the scale-free literature,\nand offers rigorous and quantitative alternatives. \n\n"}
{"id": "cond-mat/0503087", "contents": "Title: On the Bias of Traceroute Sampling; or, Power-law Degree Distributions\n  in Regular Graphs Abstract: Understanding the structure of the Internet graph is a crucial step for\nbuilding accurate network models and designing efficient algorithms for\nInternet applications. Yet, obtaining its graph structure is a surprisingly\ndifficult task, as edges cannot be explicitly queried. Instead, empirical\nstudies rely on traceroutes to build what are essentially single-source,\nall-destinations, shortest-path trees. These trees only sample a fraction of\nthe network's edges, and a recent paper by Lakhina et al. found empirically\nthat the resuting sample is intrinsically biased. For instance, the observed\ndegree distribution under traceroute sampling exhibits a power law even when\nthe underlying degree distribution is Poisson.\n  In this paper, we study the bias of traceroute sampling systematically, and,\nfor a very general class of underlying degree distributions, calculate the\nlikely observed distributions explicitly. To do this, we use a continuous-time\nrealization of the process of exposing the BFS tree of a random graph with a\ngiven degree distribution, calculate the expected degree distribution of the\ntree, and show that it is sharply concentrated. As example applications of our\nmachinery, we show how traceroute sampling finds power-law degree distributions\nin both delta-regular and Poisson-distributed random graphs. Thus, our work\nputs the observations of Lakhina et al. on a rigorous footing, and extends them\nto nearly arbitrary degree distributions. \n\n"}
{"id": "cond-mat/0505193", "contents": "Title: Organization of complex networks without multiple connections Abstract: We find a new structural feature of equilibrium complex random networks\nwithout multiple and self-connections. We show that if the number of\nconnections is sufficiently high, these networks contain a core of highly\ninterconnected vertices. The number of vertices in this core varies in the\nrange between $const N^{1/2}$ and $const N^{2/3}$, where $N$ is the number of\nvertices in a network. At the birth point of the core, we obtain the\nsize-dependent cut-off of the distribution of the number of connections and\nfind that its position differs from earlier estimates. \n\n"}
{"id": "cond-mat/0506002", "contents": "Title: Correlations in interacting systems with a network topology Abstract: We study pair correlations in cooperative systems placed on complex networks.\nWe show that usually in these systems, the correlations between two interacting\nobjects (e.g., spins), separated by a distance $\\ell$, decay, on average,\nfaster than $1/(\\ell z_\\ell)$. Here $z_\\ell$ is the mean number of the\n$\\ell$-th nearest neighbors of a vertex in a network. This behavior, in\nparticular, leads to a dramatic weakening of correlations between second and\nmore distant neighbors on networks with fat-tailed degree distributions, which\nhave a divergent number $z_2$ in the infinite network limit. In this case, only\nthe pair correlations between the nearest neighbors are observable. We obtain\nthe pair correlation function of the Ising model on a complex network and also\nderive our results in the framework of a phenomenological approach. \n\n"}
{"id": "cond-mat/0509102", "contents": "Title: k-core organization of complex networks Abstract: We analytically describe the architecture of randomly damaged uncorrelated\nnetworks as a set of successively enclosed substructures -- k-cores. The k-core\nis the largest subgraph where vertices have at least k interconnections. We\nfind the structure of k-cores, their sizes, and their birth points -- the\nbootstrap percolation thresholds. We show that in networks with a finite mean\nnumber z_2 of the second-nearest neighbors, the emergence of a k-core is a\nhybrid phase transition. In contrast, if z_2 diverges, the networks contain an\ninfinite sequence of k-cores which are ultra-robust against random damage. \n\n"}
{"id": "cond-mat/0602351", "contents": "Title: Synchronization in Network Structures: Entangled Topology as Optimal\n  Architecture for Network Design Abstract: In these notes we study synchronizability of dynamical processes defined on\ncomplex networks as well as its interplay with network topology. Building from\na recent work by Barahona and Pecora [Phys. Rev. Lett. 89, 054101 (2002)], we\nuse a simulated annealing algorithm to construct optimally-synchronizable\nnetworks. The resulting structures, known as entangled networks, are\ncharacterized by an extremely homogeneous and interwoven topology: degree,\ndistance, and betweenness distributions are all very narrow, with short average\ndistances, large loops, and small modularity. Entangled networks exhibit an\nexcellent (almost optimal) performance with respect to other flow or\nconnectivity properties such as robustness, random walk minimal first-passage\ntimes, and good searchability. All this converts entangled networks in a\npowerful concept with optimal properties in many respects. \n\n"}
{"id": "cond-mat/0603861", "contents": "Title: Congestion-gradient driven transport on complex networks Abstract: We present a study of transport on complex networks with routing based on\nlocal information. Particles hop from one node of the network to another\naccording to a set of routing rules with different degrees of congestion\nawareness, ranging from random diffusion to rigid congestion-gradient driven\nflow. Each node can be either source or destination for particles and all nodes\nhave the same routing capacity, which are features of ad-hoc wireless networks.\nIt is shown that the transport capacity increases when a small amount of\ncongestion awareness is present in the routing rules, and that it then\ndecreases as the routing rules become too rigid when the flow becomes strictly\ncongestion-gradient driven. Therefore, an optimum value of the congestion\nawareness exists in the routing rules. It is also shown that, in the limit of a\nlarge number of nodes, networks using routing based on local information jam at\nany nonzero load. Finally, we study the correlation between congestion at node\nlevel and a betweenness centrality measure. \n\n"}
{"id": "cond-mat/0609098", "contents": "Title: Synchronization in Weighted Uncorrelated Complex Networks in a Noisy\n  Environment: Optimization and Connections with Transport Efficiency Abstract: Motivated by synchronization problems in noisy environments, we study the\nEdwards-Wilkinson process on weighted uncorrelated scale-free networks. We\nconsider a specific form of the weights, where the strength (and the associated\ncost) of a link is proportional to $(k_{i}k_{j})^{\\beta}$ with $k_{i}$ and\n$k_{j}$ being the degrees of the nodes connected by the link. Subject to the\nconstraint that the total network cost is fixed, we find that in the mean-field\napproximation on uncorrelated scale-free graphs, synchronization is optimal at\n$\\beta^{*}$$=$-1. Numerical results, based on exact numerical diagonalization\nof the corresponding network Laplacian, confirm the mean-field results, with\nsmall corrections to the optimal value of $\\beta^{*}$. Employing our recent\nconnections between the Edwards-Wilkinson process and resistor networks, and\nsome well-known connections between random walks and resistor networks, we also\npursue a naturally related problem of optimizing performance in queue-limited\ncommunication networks utilizing local weighted routing schemes. \n\n"}
{"id": "cond-mat/0701184", "contents": "Title: Transport optimization on complex networks Abstract: We present a comparative study of the application of a recently introduced\nheuristic algorithm to the optimization of transport on three major types of\ncomplex networks. The algorithm balances network traffic iteratively by\nminimizing the maximum node betweenness with as little path lengthening as\npossible. We show that by using this optimal routing, a network can sustain\nsignificantly higher traffic without jamming than in the case of shortest path\nrouting. A formula is proved that allows quick computation of the average\nnumber of hops along the path and of the average travel times once the\nbetweennesses of the nodes are computed. Using this formula, we show that\nrouting optimization preserves the small-world character exhibited by networks\nunder shortest path routing, and that it significantly reduces the average\ntravel time on congested networks with only a negligible increase in the\naverage travel time at low loads. Finally, we study the correlation between the\nweights of the links in the case of optimal routing and the betweennesses of\nthe nodes connected by them. \n\n"}
{"id": "cs/0107001", "contents": "Title: Analysis of Network Traffic in Switched Ethernet Systems Abstract: A 100 Mbps Ethernet link between a college campus and the outside world was\nmonitored with a dedicated PC and the measured data analysed for its\nstatistical properties. Similar measurements were taken at an internal node of\nthe network. The networks in both cases are a full-duplex switched Ethernet.\nInter-event interval histograms and power spectra of the throughput aggregated\nfor 10ms bins were used to analyse the measured traffic. For most investigated\ncases both methods reveal that the traffic behaves according to a power law.\nThe results will be used in later studies to parameterise models for network\ntraffic. \n\n"}
{"id": "cs/0202008", "contents": "Title: CUP: Controlled Update Propagation in Peer-to-Peer Networks Abstract: Recently the problem of indexing and locating content in peer-to-peer\nnetworks has received much attention. Previous work suggests caching index\nentries at intermediate nodes that lie on the paths taken by search queries,\nbut until now there has been little focus on how to maintain these intermediate\ncaches. This paper proposes CUP, a new comprehensive architecture for\nControlled Update Propagation in peer-to-peer networks. CUP asynchronously\nbuilds caches of index entries while answering search queries. It then\npropagates updates of index entries to maintain these caches. Under unfavorable\nconditions, when compared with standard caching based on expiration times, CUP\nreduces the average miss latency by as much as a factor of three. Under\nfavorable conditions, CUP can reduce the average miss latency by more than a\nfactor of ten.\n  CUP refreshes intermediate caches, reduces query latency, and reduces network\nload by coalescing bursts of queries for the same item. CUP controls and\nconfines propagation to updates whose cost is likely to be recovered by\nsubsequent queries. CUP gives peer-to-peer nodes the flexibility to use their\nown incentive-based policies to determine when to receive and when to propagate\nupdates. Finally, the small propagation overhead incurred by CUP is more than\ncompensated for by its savings in cache misses. \n\n"}
{"id": "cs/0206011", "contents": "Title: A Statistical Physics Perspective on Web Growth Abstract: Approaches from statistical physics are applied to investigate the structure\nof network models whose growth rules mimic aspects of the evolution of the\nworld-wide web. We first determine the degree distribution of a growing network\nin which nodes are introduced one at a time and attach to an earlier node of\ndegree k with rate A_ksim k^gamma. Very different behaviors arise for gamma<1,\ngamma=1, and gamma>1. We also analyze the degree distribution of a\nheterogeneous network, the joint age-degree distribution, the correlation\nbetween degrees of neighboring nodes, as well as global network properties. An\nextension to directed networks is then presented. By tuning model parameters to\nreasonable values, we obtain distinct power-law forms for the in-degree and\nout-degree distributions with exponents that are in good agreement with current\ndata for the web. Finally, a general growth process with independent\nintroduction of nodes and links is investigated. This leads to independently\ngrowing sub-networks that may coalesce with other sub-networks. General results\nfor both the size distribution of sub-networks and the degree distribution are\nobtained. \n\n"}
{"id": "cs/0302017", "contents": "Title: A Proposal to Separate Handles from Names on the Internet Abstract: Networked communications inherently depend on the ability of the sender of a\nmessage to indicate through some token how the message should be delivered to a\nparticular recipient. The tokens that refer messages to recipients are\nvariously known as routes, addresses,handles, and names} ordered by their\nrelative nearness to network topology vs. human meaning. All four sorts of\ntoken refer in some way to a recipient, but they are controlled by different\nauthorities and their meanings depend on different contextual parameters.\n  Today's global Internet employs dynamically determined routes, IP addresses,\nand domain names. Domain names combine the functions of handles and names. The\nhigh value of domain names as names leads to substantial social and legal\ndispute about their assignment, degrading their value as handles. The time has\ncome to provide a distinct open network handle system (ONHS), using handles\nthat are not meaningful in natural language and are therefore not subject to\nthe disputes surrounding the use of names.\n  A handle service may be deployed easily as a handle domain within the current\nDomain Name System. In order to minimize the administrative load, and maximize\ntheir own autonomy, netizens may use public-key cryptography to assign their\nown handles. \n\n"}
{"id": "cs/0307036", "contents": "Title: Small-World File-Sharing Communities Abstract: Web caches, content distribution networks, peer-to-peer file sharing\nnetworks, distributed file systems, and data grids all have in common that they\ninvolve a community of users who generate requests for shared data. In each\ncase, overall system performance can be improved significantly if we can first\nidentify and then exploit interesting structure within a community's access\npatterns. To this end, we propose a novel perspective on file sharing based on\nthe study of the relationships that form among users based on the files in\nwhich they are interested.\n  We propose a new structure that captures common user interests in data--the\ndata-sharing graph-- and justify its utility with studies on three\ndata-distribution systems: a high-energy physics collaboration, the Web, and\nthe Kazaa peer-to-peer network. We find small-world patterns in the\ndata-sharing graphs of all three communities. We analyze these graphs and\npropose some probable causes for these emergent small-world patterns. The\nsignificance of small-world patterns is twofold: it provides a rigorous support\nto intuition and, perhaps most importantly, it suggests ways to design\nmechanisms that exploit these naturally emerging patterns. \n\n"}
{"id": "cs/0308036", "contents": "Title: The Rich-Club Phenomenon In The Internet Topology Abstract: We show that the Internet topology at the Autonomous System (AS) level has a\nrich--club phenomenon. The rich nodes, which are a small number of nodes with\nlarge numbers of links, are very well connected to each other. The rich--club\nis a core tier that we measured using the rich--club connectivity and the\nnode--node link distribution. We obtained this core tier without any heuristic\nassumption between the ASes. The rich--club phenomenon is a simple qualitative\nway to differentiate between power law topologies and provides a criterion for\nnew network models. To show this, we compared the measured rich--club of the AS\ngraph with networks obtained using the Barab\\'asi--Albert (BA) scale--free\nnetwork model, the Fitness BA model and the Inet--3.0 model. \n\n"}
{"id": "cs/0405070", "contents": "Title: Traffic-driven model of the World Wide Web graph Abstract: We propose a model for the World Wide Web graph that couples the topological\ngrowth with the traffic's dynamical evolution. The model is based on a simple\ntraffic-driven dynamics and generates weighted directed graphs exhibiting the\nstatistical properties observed in the Web. In particular, the model yields a\nnon-trivial time evolution of vertices and heavy-tail distributions for the\ntopological and traffic properties. The generated graphs exhibit a complex\narchitecture with a hierarchy of cohesiveness levels similar to those observed\nin the analysis of real data. \n\n"}
{"id": "cs/0507072", "contents": "Title: Reliable Data Storage in Distributed Hash Tables Abstract: Distributed Hash Tables offer a resilient lookup service for unstable\ndistributed environments. Resilient data storage, however, requires additional\ndata replication and maintenance algorithms. These algorithms can have an\nimpact on both the performance and the scalability of the system. In this\npaper, we describe the goals and design space of these replication algorithms.\n  We examine an existing replication algorithm, and present a new analysis of\nits reliability. We then present a new dynamic replication algorithm which can\noperate in unstable environments. We give several possible replica placement\nstrategies for this algorithm, and show how they impact reliability and\nperformance.\n  Finally we compare all replication algorithms through simulation, showing\nquantitatively the difference between their bandwidth use, fault tolerance and\nperformance. \n\n"}
{"id": "cs/0511007", "contents": "Title: K-core decomposition of Internet graphs: hierarchies, self-similarity\n  and measurement biases Abstract: We consider the $k$-core decomposition of network models and Internet graphs\nat the autonomous system (AS) level. The $k$-core analysis allows to\ncharacterize networks beyond the degree distribution and uncover structural\nproperties and hierarchies due to the specific architecture of the system. We\ncompare the $k$-core structure obtained for AS graphs with those of several\nnetwork models and discuss the differences and similarities with the real\nInternet architecture. The presence of biases and the incompleteness of the\nreal maps are discussed and their effect on the $k$-core analysis is assessed\nwith numerical experiments simulating biased exploration on a wide range of\nnetwork models. We find that the $k$-core analysis provides an interesting\ncharacterization of the fluctuations and incompleteness of maps as well as\ninformation helping to discriminate the original underlying structure. \n\n"}
{"id": "cs/0511012", "contents": "Title: Parameters Affecting the Resilience of Scale-Free Networks to Random\n  Failures Abstract: It is commonly believed that scale-free networks are robust to massive\nnumbers of random node deletions. For example, Cohen et al. study scale-free\nnetworks including some which approximate the measured degree distribution of\nthe Internet. Their results suggest that if each node in this network failed\nindependently with probability 0.99, the remaining network would continue to\nhave a giant component. In this paper, we show that a large and important\nsubclass of scale-free networks are not robust to massive numbers of random\nnode deletions for practical purposes. In particular, we study finite\nscale-free networks which have minimum node degree of 1 and a power-law degree\ndistribution beginning with nodes of degree 1 (power-law networks). We show\nthat, in a power-law network approximating the Internet's reported\ndistribution, when the probability of deletion of each node is 0.5 only about\n25% of the surviving nodes in the network remain connected in a giant\ncomponent, and the giant component does not persist beyond a critical failure\nrate of 0.9. The new result is partially due to improved analytical\naccommodation of the large number of degree-0 nodes that result after node\ndeletions. Our results apply to finite power-law networks with a wide range of\npower-law exponents, including Internet-like networks. We give both analytical\nand empirical evidence that such networks are not generally robust to massive\nrandom node deletions. \n\n"}
{"id": "cs/0511101", "contents": "Title: Chinese Internet AS-level Topology Abstract: We present the first complete measurement of the Chinese Internet topology at\nthe autonomous systems (AS) level based on traceroute data probed from servers\nof major ISPs in mainland China. We show that both the Chinese Internet AS\ngraph and the global Internet AS graph can be accurately reproduced by the\nPositive-Feedback Preference (PFP) model with the same parameters. This result\nsuggests that the Chinese Internet preserves well the topological\ncharacteristics of the global Internet. This is the first demonstration of the\nInternet's topological fractality, or self-similarity, performed at the level\nof topology evolution modeling. \n\n"}
{"id": "cs/0512095", "contents": "Title: The Internet AS-Level Topology: Three Data Sources and One Definitive\n  Metric Abstract: We calculate an extensive set of characteristics for Internet AS topologies\nextracted from the three data sources most frequently used by the research\ncommunity: traceroutes, BGP, and WHOIS. We discover that traceroute and BGP\ntopologies are similar to one another but differ substantially from the WHOIS\ntopology. Among the widely considered metrics, we find that the joint degree\ndistribution appears to fundamentally characterize Internet AS topologies as\nwell as narrowly define values for other important metrics. We discuss the\ninterplay between the specifics of the three data collection mechanisms and the\nresulting topology views. In particular, we show how the data collection\npeculiarities explain differences in the resulting joint degree distributions\nof the respective topologies. Finally, we release to the community the input\ntopology datasets, along with the scripts and output of our calculations. This\nsupplement should enable researchers to validate their models against real data\nand to make more informed selection of topology data sources for their specific\nneeds. \n\n"}
{"id": "cs/0604017", "contents": "Title: AS Relationships: Inference and Validation Abstract: Research on performance, robustness, and evolution of the global Internet is\nfundamentally handicapped without accurate and thorough knowledge of the nature\nand structure of the contractual relationships between Autonomous Systems\n(ASs). In this work we introduce novel heuristics for inferring AS\nrelationships. Our heuristics improve upon previous works in several technical\naspects, which we outline in detail and demonstrate with several examples.\nSeeking to increase the value and reliability of our inference results, we then\nfocus on validation of inferred AS relationships. We perform a survey with ASs'\nnetwork administrators to collect information on the actual connectivity and\npolicies of the surveyed ASs. Based on the survey results, we find that our new\nAS relationship inference techniques achieve high levels of accuracy: we\ncorrectly infer 96.5% customer to provider (c2p), 82.8% peer to peer (p2p), and\n90.3% sibling to sibling (s2s) relationships. We then cross-compare the\nreported AS connectivity with the AS connectivity data contained in BGP tables.\nWe find that BGP tables miss up to 86.2% of the true adjacencies of the\nsurveyed ASs. The majority of the missing links are of the p2p type, which\nhighlights the limitations of present measuring techniques to capture links of\nthis type. Finally, to make our results easily accessible and practically\nuseful for the community, we open an AS relationship repository where we\narchive, on a weekly basis, and make publicly available the complete Internet\nAS-level topology annotated with AS relationship information for every pair of\nAS neighbors. \n\n"}
{"id": "cs/0607080", "contents": "Title: New Model of Internet Topology Using k-shell Decomposition Abstract: We introduce and use k-shell decomposition to investigate the topology of the\nInternet at the AS level. Our analysis separates the Internet into three\nsub-components: (a) a nucleus which is a small (~100 nodes) very well connected\nglobally distributed subgraph; (b) a fractal sub-component that is able to\nconnect the bulk of the Internet without congesting the nucleus, with self\nsimilar properties and critical exponents; and (c) dendrite-like structures,\nusually isolated nodes that are connected to the rest of the network through\nthe nucleus only. This unique decomposition is robust, and provides insight\ninto the underlying structure of the Internet and its functional consequences.\nOur approach is general and useful also when studying other complex networks. \n\n"}
{"id": "cs/0608088", "contents": "Title: Radial Structure of the Internet Abstract: The structure of the Internet at the Autonomous System (AS) level has been\nstudied by both the Physics and Computer Science communities. We extend this\nwork to include features of the core and the periphery, taking a radial\nperspective on AS network structure. New methods for plotting AS data are\ndescribed, and they are used to analyze data sets that have been extended to\ncontain edges missing from earlier collections. In particular, the average\ndistance from one vertex to the rest of the network is used as the baseline\nmetric for investigating radial structure. Common vertex-specific quantities\nare plotted against this metric to reveal distinctive characteristics of\ncentral and peripheral vertices. Two data sets are analyzed using these\nmeasures as well as two common generative models (Barabasi-Albert and Inet). We\nfind a clear distinction between the highly connected core and a sparse\nperiphery. We also find that the periphery has a more complex structure than\nthat predicted by degree distribution or the two generative models. \n\n"}
{"id": "cs/0609030", "contents": "Title: Space Division Multiple Access with a Sum Feedback Rate Constraint Abstract: On a multi-antenna broadcast channel, simultaneous transmission to multiple\nusers by joint beamforming and scheduling is capable of achieving high\nthroughput, which grows double logarithmically with the number of users. The\nsum rate for channel state information (CSI) feedback, however, increases\nlinearly with the number of users, reducing the effective uplink capacity. To\naddress this problem, a novel space division multiple access (SDMA) design is\nproposed, where the sum feedback rate is upper-bounded by a constant. This\ndesign consists of algorithms for CSI quantization, threshold based CSI\nfeedback, and joint beamforming and scheduling. The key feature of the proposed\napproach is the use of feedback thresholds to select feedback users with large\nchannel gains and small CSI quantization errors such that the sum feedback rate\nconstraint is satisfied. Despite this constraint, the proposed SDMA design is\nshown to achieve a sum capacity growth rate close to the optimal one. Moreover,\nthe feedback overflow probability for this design is found to decrease\nexponentially with the difference between the allowable and the average sum\nfeedback rates. Numerical results show that the proposed SDMA design is capable\nof attaining higher sum capacities than existing ones, even though the sum\nfeedback rate is bounded. \n\n"}
{"id": "cs/0611128", "contents": "Title: Scale-Free Overlay Topologies with Hard Cutoffs for Unstructured\n  Peer-to-Peer Networks Abstract: In unstructured peer-to-peer (P2P) networks, the overlay topology (or\nconnectivity graph) among peers is a crucial component in addition to the\npeer/data organization and search. Topological characteristics have profound\nimpact on the efficiency of search on such unstructured P2P networks as well as\nother networks. It has been well-known that search on small-world topologies of\nN nodes can be as efficient as O(ln N), while scale-free (power-law) topologies\noffer even better search efficiencies like as good as O(lnln N) for a range of\ndegree distribution exponents. However, generation and maintenance of such\nscale-free topologies are hard to realize in a distributed and potentially\nuncooperative environments as in the P2P networks. A key limitation of\nscale-free topologies is the high load (i.e. high degree) on very few number of\nhub nodes. In a typical unstructured P2P network, peers are not willing to\nmaintain high degrees/loads as they may not want to store large number of\nentries for construction of the overlay topology. So, to achieve fairness and\npracticality among all peers, hard cutoffs on the number of entries are imposed\nby the individual peers, which limits scale-freeness of the overall topology.\nThus, efficiency of the flooding search reduces as the size of the hard cutoff\ndoes. We investigate construction of scale-free topologies with hard cutoffs\n(i.e. there are not any major hubs) and effect of these hard cutoffs on the\nsearch efficiency. Interestingly, we observe that the efficiency of normalized\nflooding and random walk search algorithms increases as the hard cutoff\ndecreases. \n\n"}
{"id": "cs/0612040", "contents": "Title: The Workshop on Internet Topology (WIT) Report Abstract: Internet topology analysis has recently experienced a surge of interest in\ncomputer science, physics, and the mathematical sciences. However, researchers\nfrom these different disciplines tend to approach the same problem from\ndifferent angles. As a result, the field of Internet topology analysis and\nmodeling must untangle sets of inconsistent findings, conflicting claims, and\ncontradicting statements.\n  On May 10-12, 2006, CAIDA hosted the Workshop on Internet topology (WIT). By\nbringing together a group of researchers spanning the areas of computer\nscience, physics, and the mathematical sciences, the workshop aimed to improve\ncommunication across these scientific disciplines, enable interdisciplinary\ncrossfertilization, identify commonalities in the different approaches, promote\nsynergy where it exists, and utilize the richness that results from exploring\nsimilar problems from multiple perspectives.\n  This report describes the findings of the workshop, outlines a set of\nrelevant open research problems identified by participants, and concludes with\nrecommendations that can benefit all scientific communities interested in\nInternet topology research. \n\n"}
{"id": "cs/0702156", "contents": "Title: Analysis of Steiner subtrees of Random Trees for Traceroute Algorithms Abstract: We consider in this paper the problem of discovering, via a traceroute\nalgorithm, the topology of a network, whose graph is spanned by an infinite\nbranching process. A subset of nodes is selected according to some criterion.\nAs a measure of efficiency of the algorithm, the Steiner distance of the\nselected nodes, i.e. the size of the spanning sub-tree of these nodes, is\ninvestigated. For the selection of nodes, two criteria are considered: A node\nis randomly selected with a probability, which is either independent of the\ndepth of the node (uniform model) or else in the depth biased model, is\nexponentially decaying with respect to its depth. The limiting behavior the\nsize of the discovered subtree is investigated for both models. \n\n"}
{"id": "math/0510013", "contents": "Title: Network Kriging Abstract: Network service providers and customers are often concerned with aggregate\nperformance measures that span multiple network paths. Unfortunately, forming\nsuch network-wide measures can be difficult, due to the issues of scale\ninvolved. In particular, the number of paths grows too rapidly with the number\nof endpoints to make exhaustive measurement practical. As a result, it is of\ninterest to explore the feasibility of methods that dramatically reduce the\nnumber of paths measured in such situations while maintaining acceptable\naccuracy.\n  We cast the problem as one of statistical prediction--in the spirit of the\nso-called `kriging' problem in spatial statistics--and show that end-to-end\nnetwork properties may be accurately predicted in many cases using a\nsurprisingly small set of carefully chosen paths. More precisely, we formulate\na general framework for the prediction problem, propose a class of linear\npredictors for standard quantities of interest (e.g., averages, totals,\ndifferences) and show that linear algebraic methods of subset selection may be\nused to effectively choose which paths to measure. We characterize the\nperformance of the resulting methods, both analytically and numerically. The\nsuccess of our methods derives from the low effective rank of routing matrices\nas encountered in practice, which appears to be a new observation in its own\nright with potentially broad implications on network measurement generally. \n\n"}
{"id": "math/0604367", "contents": "Title: Network Delay Inference from Additive Metrics Abstract: We demonstrate the use of computational phylogenetic techniques to solve a\ncentral problem in inferential network monitoring. More precisely, we design a\nnovel algorithm for multicast-based delay inference, i.e. the problem of\nreconstructing the topology and delay characteristics of a network from\nend-to-end delay measurements on network paths. Our inference algorithm is\nbased on additive metric techniques widely used in phylogenetics. It runs in\npolynomial time and requires a sample of size only $\\poly(\\log n)$. \n\n"}
{"id": "physics/0504026", "contents": "Title: Let Your CyberAlter Ego Share Information and Manage Spam Abstract: Almost all of us have multiple cyberspace identities, and these {\\em\ncyber}alter egos are networked together to form a vast cyberspace social\nnetwork. This network is distinct from the world-wide-web (WWW), which is being\nqueried and mined to the tune of billions of dollars everyday, and until\nrecently, has gone largely unexplored. Empirically, the cyberspace social\nnetworks have been found to possess many of the same complex features that\ncharacterize its real counterparts, including scale-free degree distributions,\nlow diameter, and extensive connectivity. We show that these topological\nfeatures make the latent networks particularly suitable for explorations and\nmanagement via local-only messaging protocols. {\\em Cyber}alter egos can\ncommunicate via their direct links (i.e., using only their own address books)\nand set up a highly decentralized and scalable message passing network that can\nallow large-scale sharing of information and data. As one particular example of\nsuch collaborative systems, we provide a design of a spam filtering system, and\nour large-scale simulations show that the system achieves a spam detection rate\nclose to 100%, while the false positive rate is kept around zero. This system\nhas several advantages over other recent proposals (i) It uses an already\nexisting network, created by the same social dynamics that govern our daily\nlives, and no dedicated peer-to-peer (P2P) systems or centralized server-based\nsystems need be constructed; (ii) It utilizes a percolation search algorithm\nthat makes the query-generated traffic scalable; (iii) The network has a built\nin trust system (just as in social networks) that can be used to thwart\nmalicious attacks; iv) It can be implemented right now as a plugin to popular\nemail programs, such as MS Outlook, Eudora, and Sendmail. \n\n"}
