{"id": "0707.0895", "contents": "Title: Segmentation and Context of Literary and Musical Sequences Abstract: We test a segmentation algorithm, based on the calculation of the\nJensen-Shannon divergence between probability distributions, to two symbolic\nsequences of literary and musical origin. The first sequence represents the\nsuccessive appearance of characters in a theatrical play, and the second\nrepresents the succession of tones from the twelve-tone scale in a keyboard\nsonata. The algorithm divides the sequences into segments of maximal\ncompositional divergence between them. For the play, these segments are related\nto changes in the frequency of appearance of different characters and in the\ngeographical setting of the action. For the sonata, the segments correspond to\ntonal domains and reveal in detail the characteristic tonal progression of such\nkind of musical composition. \n\n"}
{"id": "0711.2270", "contents": "Title: Can a Computer Laugh ? Abstract: A computer model of \"a sense of humour\" suggested previously\n[arXiv:0711.2058,0711.2061], relating the humorous effect with a specific\nmalfunction in information processing, is given in somewhat different\nexposition. Psychological aspects of humour are elaborated more thoroughly. The\nmechanism of laughter is formulated on the more general level. Detailed\ndiscussion is presented for the higher levels of information processing, which\nare responsible for a perception of complex samples of humour. Development of a\nsense of humour in the process of evolution is discussed. \n\n"}
{"id": "0711.3197", "contents": "Title: How to realize \"a sense of humour\" in computers ? Abstract: Computer model of a \"sense of humour\" suggested previously [arXiv:0711.2058,\n0711.2061, 0711.2270] is raised to the level of a realistic algorithm. \n\n"}
{"id": "0802.4215", "contents": "Title: Equilibrium (Zipf) and Dynamic (Grasseberg-Procaccia) method based\n  analyses of human texts. A comparison of natural (english) and artificial\n  (esperanto) languages Abstract: A comparison of two english texts from Lewis Carroll, one (Alice in\nwonderland), also translated into esperanto, the other (Through a looking\nglass) are discussed in order to observe whether natural and artificial\nlanguages significantly differ from each other. One dimensional time series\nlike signals are constructed using only word frequencies (FTS) or word lengths\n(LTS). The data is studied through (i) a Zipf method for sorting out\ncorrelations in the FTS and (ii) a Grassberger-Procaccia (GP) technique based\nmethod for finding correlations in LTS. Features are compared : different power\nlaws are observed with characteristic exponents for the ranking properties, and\nthe {\\it phase space attractor dimensionality}. The Zipf exponent can take\nvalues much less than unity ($ca.$ 0.50 or 0.30) depending on how a sentence is\ndefined. This non-universality is conjectured to be a measure of the author\n$style$. Moreover the attractor dimension $r$ is a simple function of the so\ncalled phase space dimension $n$, i.e., $r = n^{\\lambda}$, with $\\lambda =\n0.79$. Such an exponent should also conjecture to be a measure of the author\n$creativity$. However, even though there are quantitative differences between\nthe original english text and its esperanto translation, the qualitative\ndifferences are very minutes, indicating in this case a translation relatively\nwell respecting, along our analysis lines, the content of the author writing. \n\n"}
{"id": "0901.4180", "contents": "Title: Google distance between words Abstract: Cilibrasi and Vitanyi have demonstrated that it is possible to extract the\nmeaning of words from the world-wide web. To achieve this, they rely on the\nnumber of webpages that are found through a Google search containing a given\nword and they associate the page count to the probability that the word appears\non a webpage. Thus, conditional probabilities allow them to correlate one word\nwith another word's meaning. Furthermore, they have developed a similarity\ndistance function that gauges how closely related a pair of words is. We\npresent a specific counterexample to the triangle inequality for this\nsimilarity distance function. \n\n"}
{"id": "1104.4426", "contents": "Title: Phylogeny and geometry of languages from normalized Levenshtein distance Abstract: The idea that the distance among pairs of languages can be evaluated from\nlexical differences seems to have its roots in the work of the French explorer\nDumont D'Urville. He collected comparative words lists of various languages\nduring his voyages aboard the Astrolabe from 1826 to 1829 and, in his work\nabout the geographical division of the Pacific, he proposed a method to measure\nthe degree of relation between languages.\n  The method used by the modern lexicostatistics, developed by Morris Swadesh\nin the 1950s, measures distances from the percentage of shared cognates, which\nare words with a common historical origin. The weak point of this method is\nthat subjective judgment plays a relevant role.\n  Recently, we have proposed a new automated method which is motivated by the\nanalogy with genetics. The new approach avoids any subjectivity and results can\nbe easily replicated by other scholars. The distance between two languages is\ndefined by considering a renormalized Levenshtein distance between pair of\nwords with the same meaning and averaging on the words contained in a list. The\nrenormalization, which takes into account the length of the words, plays a\ncrucial role, and no sensible results can be found without it.\n  In this paper we give a short review of our automated method and we\nillustrate it by considering the cluster of Malagasy dialects. We show that it\nsheds new light on their kinship relation and also that it furnishes a lot of\nnew information concerning the modalities of the settlement of Madagascar. \n\n"}
{"id": "1111.4343", "contents": "Title: Question Answering in a Natural Language Understanding System Based on\n  Object-Oriented Semantics Abstract: Algorithms of question answering in a computer system oriented on input and\nlogical processing of text information are presented. A knowledge domain under\nconsideration is social behavior of a person. A database of the system includes\nan internal representation of natural language sentences and supplemental\ninformation. The answer {\\it Yes} or {\\it No} is formed for a general question.\nA special question containing an interrogative word or group of interrogative\nwords permits to find a subject, object, place, time, cause, purpose and way of\naction or event. Answer generation is based on identification algorithms of\npersons, organizations, machines, things, places, and times. Proposed\nalgorithms of question answering can be realized in information systems closely\nconnected with text processing (criminology, operation of business, medicine,\ndocument systems). \n\n"}
{"id": "1301.3627", "contents": "Title: Two SVDs produce more focal deep learning representations Abstract: A key characteristic of work on deep learning and neural networks in general\nis that it relies on representations of the input that support generalization,\nrobust inference, domain adaptation and other desirable functionalities. Much\nrecent progress in the field has focused on efficient and effective methods for\ncomputing representations. In this paper, we propose an alternative method that\nis more efficient than prior work and produces representations that have a\nproperty we call focality -- a property we hypothesize to be important for\nneural network representations. The method consists of a simple application of\ntwo consecutive SVDs and is inspired by Anandkumar (2012). \n\n"}
{"id": "1304.0104", "contents": "Title: Meaning-focused and Quantum-inspired Information Retrieval Abstract: In recent years, quantum-based methods have promisingly integrated the\ntraditional procedures in information retrieval (IR) and natural language\nprocessing (NLP). Inspired by our research on the identification and\napplication of quantum structures in cognition, more specifically our work on\nthe representation of concepts and their combinations, we put forward a\n'quantum meaning based' framework for structured query retrieval in text\ncorpora and standardized testing corpora. This scheme for IR rests on\nconsidering as basic notions, (i) 'entities of meaning', e.g., concepts and\ntheir combinations and (ii) traces of such entities of meaning, which is how\ndocuments are considered in this approach. The meaning content of these\n'entities of meaning' is reconstructed by solving an 'inverse problem' in the\nquantum formalism, consisting of reconstructing the full states of the entities\nof meaning from their collapsed states identified as traces in relevant\ndocuments. The advantages with respect to traditional approaches, such as\nLatent Semantic Analysis (LSA), are discussed by means of concrete examples. \n\n"}
{"id": "1307.1662", "contents": "Title: Polyglot: Distributed Word Representations for Multilingual NLP Abstract: Distributed word representations (word embeddings) have recently contributed\nto competitive performance in language modeling and several NLP tasks. In this\nwork, we train word embeddings for more than 100 languages using their\ncorresponding Wikipedias. We quantitatively demonstrate the utility of our word\nembeddings by using them as the sole features for training a part of speech\ntagger for a subset of these languages. We find their performance to be\ncompetitive with near state-of-art methods in English, Danish and Swedish.\nMoreover, we investigate the semantic features captured by these embeddings\nthrough the proximity of word groupings. We will release these embeddings\npublicly to help researchers in the development and enhancement of multilingual\napplications. \n\n"}
{"id": "1307.3040", "contents": "Title: Between Sense and Sensibility: Declarative narrativisation of mental\n  models as a basis and benchmark for visuo-spatial cognition and computation\n  focussed collaborative cognitive systems Abstract: What lies between `\\emph{sensing}' and `\\emph{sensibility}'? In other words,\nwhat kind of cognitive processes mediate sensing capability, and the formation\nof sensible impressions ---e.g., abstractions, analogies, hypotheses and theory\nformation, beliefs and their revision, argument formation--- in domain-specific\nproblem solving, or in regular activities of everyday living, working and\nsimply going around in the environment? How can knowledge and reasoning about\nsuch capabilities, as exhibited by humans in particular problem contexts, be\nused as a model and benchmark for the development of collaborative cognitive\n(interaction) systems concerned with human assistance, assurance, and\nempowerment?\n  We pose these questions in the context of a range of assistive technologies\nconcerned with \\emph{visuo-spatial perception and cognition} tasks encompassing\naspects such as commonsense, creativity, and the application of specialist\ndomain knowledge and problem-solving thought processes. Assistive technologies\nbeing considered include: (a) human activity interpretation; (b) high-level\ncognitive rovotics; (c) people-centred creative design in domains such as\narchitecture & digital media creation, and (d) qualitative analyses geographic\ninformation systems. Computational narratives not only provide a rich cognitive\nbasis, but they also serve as a benchmark of functional performance in our\ndevelopment of computational cognitive assistance systems. We posit that\ncomputational narrativisation pertaining to space, actions, and change provides\na useful model of \\emph{visual} and \\emph{spatio-temporal thinking} within a\nwide-range of problem-solving tasks and application areas where collaborative\ncognitive systems could serve an assistive and empowering function. \n\n"}
{"id": "1308.1507", "contents": "Title: Logical analysis of natural language semantics to solve the problem of\n  computer understanding Abstract: An object--oriented approach to create a natural language understanding\nsystem is considered. The understanding program is a formal system built on the\nbase of predicative calculus. Horn's clauses are used as well--formed formulas.\nAn inference is based on the principle of resolution. Sentences of natural\nlanguage are represented in the view of typical predicate set. These predicates\ndescribe physical objects and processes, abstract objects, categories and\nsemantic relations between objects. Predicates for concrete assertions are\nsaved in a database. To describe the semantics of classes for physical objects,\nabstract concepts and processes, a knowledge base is applied. The proposed\nrepresentation of natural language sentences is a semantic net. Nodes of such\nnet are typical predicates. This approach is perspective as, firstly, such\ntypification of nodes facilitates essentially forming of processing algorithms\nand object descriptions, secondly, the effectiveness of algorithms is increased\n(particularly for the great number of nodes), thirdly, to describe the\nsemantics of words, encyclopedic knowledge is used, and this permits\nessentially to extend the class of solved problems. \n\n"}
{"id": "1309.4168", "contents": "Title: Exploiting Similarities among Languages for Machine Translation Abstract: Dictionaries and phrase tables are the basis of modern statistical machine\ntranslation systems. This paper develops a method that can automate the process\nof generating and extending dictionaries and phrase tables. Our method can\ntranslate missing word and phrase entries by learning language structures based\non large monolingual data and mapping between languages from small bilingual\ndata. It uses distributed representation of words and learns a linear mapping\nbetween vector spaces of languages. Despite its simplicity, our method is\nsurprisingly effective: we can achieve almost 90% precision@5 for translation\nof words between English and Spanish. This method makes little assumption about\nthe languages, so it can be used to extend and refine dictionaries and\ntranslation tables for any language pairs. \n\n"}
{"id": "1310.7782", "contents": "Title: Individual Biases, Cultural Evolution, and the Statistical Nature of\n  Language Universals: The Case of Colour Naming Systems Abstract: Language universals have long been attributed to an innate Universal Grammar.\nAn alternative explanation states that linguistic universals emerged\nindependently in every language in response to shared cognitive or perceptual\nbiases. A computational model has recently shown how this could be the case,\nfocusing on the paradigmatic example of the universal properties of colour\nnaming patterns, and producing results in quantitative agreement with the\nexperimental data. Here we investigate the role of an individual perceptual\nbias in the framework of the model. We study how, and to what extent, the\nstructure of the bias influences the corresponding linguistic universal\npatterns. We show that the cultural history of a group of speakers introduces\npopulation-specific constraints that act against the pressure for uniformity\narising from the individual bias, and we clarify the interplay between these\ntwo forces. \n\n"}
{"id": "1401.4994", "contents": "Title: A Review of Verbal and Non-Verbal Human-Robot Interactive Communication Abstract: In this paper, an overview of human-robot interactive communication is\npresented, covering verbal as well as non-verbal aspects of human-robot\ninteraction. Following a historical introduction, and motivation towards fluid\nhuman-robot communication, ten desiderata are proposed, which provide an\norganizational axis both of recent as well as of future research on human-robot\ncommunication. Then, the ten desiderata are examined in detail, culminating to\na unifying discussion, and a forward-looking conclusion. \n\n"}
{"id": "1402.3722", "contents": "Title: word2vec Explained: deriving Mikolov et al.'s negative-sampling\n  word-embedding method Abstract: The word2vec software of Tomas Mikolov and colleagues\n(https://code.google.com/p/word2vec/ ) has gained a lot of traction lately, and\nprovides state-of-the-art word embeddings. The learning models behind the\nsoftware are described in two research papers. We found the description of the\nmodels in these papers to be somewhat cryptic and hard to follow. While the\nmotivations and presentation may be obvious to the neural-networks\nlanguage-modeling crowd, we had to struggle quite a bit to figure out the\nrationale behind the equations.\n  This note is an attempt to explain equation (4) (negative sampling) in\n\"Distributed Representations of Words and Phrases and their Compositionality\"\nby Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean. \n\n"}
{"id": "1403.3668", "contents": "Title: Language Heedless of Logic - Philosophy Mindful of What? Failures of\n  Distributive and Absorption Laws Abstract: Much of philosophical logic and all of philosophy of language make empirical\nclaims about the vernacular natural language. They presume semantics under\nwhich `and' and `or' are related by the dually paired distributive and\nabsorption laws. However, at least one of each pair of laws fails in the\nvernacular. `Implicature'-based auxiliary theories associated with the\nprogramme of H.P. Grice do not prove remedial. Conceivable alternatives that\nmight replace the familiar logics as descriptive instruments are briefly noted:\n(i) substructural logics and (ii) meaning composition in linear algebras over\nthe reals, occasionally constrained by norms of classical logic. Alternative\n(ii) locates the problem in violations of one of the idempotent laws. Reasons\nfor a lack of curiosity about elementary and easily testable implications of\nthe received theory are considered. The concept of `reflective equilibrium' is\ncritically examined for its role in reconciling normative desiderata and\ndescriptive commitments. \n\n"}
{"id": "1403.4024", "contents": "Title: Measuring Global Similarity between Texts Abstract: We propose a new similarity measure between texts which, contrary to the\ncurrent state-of-the-art approaches, takes a global view of the texts to be\ncompared. We have implemented a tool to compute our textual distance and\nconducted experiments on several corpuses of texts. The experiments show that\nour methods can reliably identify different global types of texts. \n\n"}
{"id": "1404.1521", "contents": "Title: Exploring the power of GPU's for training Polyglot language models Abstract: One of the major research trends currently is the evolution of heterogeneous\nparallel computing. GP-GPU computing is being widely used and several\napplications have been designed to exploit the massive parallelism that\nGP-GPU's have to offer. While GPU's have always been widely used in areas of\ncomputer vision for image processing, little has been done to investigate\nwhether the massive parallelism provided by GP-GPU's can be utilized\neffectively for Natural Language Processing(NLP) tasks. In this work, we\ninvestigate and explore the power of GP-GPU's in the task of learning language\nmodels. More specifically, we investigate the performance of training Polyglot\nlanguage models using deep belief neural networks. We evaluate the performance\nof training the model on the GPU and present optimizations that boost the\nperformance on the GPU.One of the key optimizations, we propose increases the\nperformance of a function involved in calculating and updating the gradient by\napproximately 50 times on the GPU for sufficiently large batch sizes. We show\nthat with the above optimizations, the GP-GPU's performance on the task\nincreases by factor of approximately 3-4. The optimizations we made are generic\nTheano optimizations and hence potentially boost the performance of other\nmodels which rely on these operations.We also show that these optimizations\nresult in the GPU's performance at this task being now comparable to that on\nthe CPU. We conclude by presenting a thorough evaluation of the applicability\nof GP-GPU's for this task and highlight the factors limiting the performance of\ntraining a Polyglot model on the GPU. \n\n"}
{"id": "1404.4714", "contents": "Title: Radical-Enhanced Chinese Character Embedding Abstract: We present a method to leverage radical for learning Chinese character\nembedding. Radical is a semantic and phonetic component of Chinese character.\nIt plays an important role as characters with the same radical usually have\nsimilar semantic meaning and grammatical usage. However, existing Chinese\nprocessing algorithms typically regard word or character as the basic unit but\nignore the crucial radical information. In this paper, we fill this gap by\nleveraging radical for learning continuous representation of Chinese character.\nWe develop a dedicated neural architecture to effectively learn character\nembedding and apply it on Chinese character similarity judgement and Chinese\nword segmentation. Experiment results show that our radical-enhanced method\noutperforms existing embedding learning algorithms on both tasks. \n\n"}
{"id": "1404.7296", "contents": "Title: A Deep Architecture for Semantic Parsing Abstract: Many successful approaches to semantic parsing build on top of the syntactic\nanalysis of text, and make use of distributional representations or statistical\nmodels to match parses to ontology-specific queries. This paper presents a\nnovel deep learning architecture which provides a semantic parsing system\nthrough the union of two neural models of language semantics. It allows for the\ngeneration of ontology-specific queries from natural language statements and\nquestions without the need for parsing, which makes it especially suitable to\ngrammatically malformed or syntactically atypical text, such as tweets, as well\nas permitting the development of semantic parsers for resource-poor languages. \n\n"}
{"id": "1406.2963", "contents": "Title: A machine-compiled macroevolutionary history of Phanerozoic life Abstract: Many aspects of macroevolutionary theory and our understanding of biotic\nresponses to global environmental change derive from literature-based\ncompilations of palaeontological data. Existing manually assembled databases\nare, however, incomplete and difficult to assess and enhance. Here, we develop\nand validate the quality of a machine reading system, PaleoDeepDive, that\nautomatically locates and extracts data from heterogeneous text, tables, and\nfigures in publications. PaleoDeepDive performs comparably to humans in complex\ndata extraction and inference tasks and generates congruent synthetic\nmacroevolutionary results. Unlike traditional databases, PaleoDeepDive produces\na probabilistic database that systematically improves as information is added.\nWe also show that the system can readily accommodate sophisticated data types,\nsuch as morphological data in biological illustrations and associated textual\ndescriptions. Our machine reading approach to scientific data integration and\nsynthesis brings within reach many questions that are currently underdetermined\nand does so in ways that may stimulate entirely new modes of inquiry. \n\n"}
{"id": "1406.5679", "contents": "Title: Deep Fragment Embeddings for Bidirectional Image Sentence Mapping Abstract: We introduce a model for bidirectional retrieval of images and sentences\nthrough a multi-modal embedding of visual and natural language data. Unlike\nprevious models that directly map images or sentences into a common embedding\nspace, our model works on a finer level and embeds fragments of images\n(objects) and fragments of sentences (typed dependency tree relations) into a\ncommon space. In addition to a ranking objective seen in previous work, this\nallows us to add a new fragment alignment objective that learns to directly\nassociate these fragments across modalities. Extensive experimental evaluation\nshows that reasoning on both the global level of images and sentences and the\nfiner level of their respective fragments significantly improves performance on\nimage-sentence retrieval tasks. Additionally, our model provides interpretable\npredictions since the inferred inter-modal fragment alignment is explicit. \n\n"}
{"id": "1407.1640", "contents": "Title: WordRep: A Benchmark for Research on Learning Word Representations Abstract: WordRep is a benchmark collection for the research on learning distributed\nword representations (or word embeddings), released by Microsoft Research. In\nthis paper, we describe the details of the WordRep collection and show how to\nuse it in different types of machine learning research related to word\nembedding. Specifically, we describe how the evaluation tasks in WordRep are\nselected, how the data are sampled, and how the evaluation tool is built. We\nthen compare several state-of-the-art word representations on WordRep, report\ntheir evaluation performance, and make discussions on the results. After that,\nwe discuss new potential research topics that can be supported by WordRep, in\naddition to algorithm comparison. We hope that this paper can help people gain\ndeeper understanding of WordRep, and enable more interesting research on\nlearning distributed word representations and related topics. \n\n"}
{"id": "1407.1687", "contents": "Title: KNET: A General Framework for Learning Word Embedding using\n  Morphological Knowledge Abstract: Neural network techniques are widely applied to obtain high-quality\ndistributed representations of words, i.e., word embeddings, to address text\nmining, information retrieval, and natural language processing tasks. Recently,\nefficient methods have been proposed to learn word embeddings from context that\ncaptures both semantic and syntactic relationships between words. However, it\nis challenging to handle unseen words or rare words with insufficient context.\nIn this paper, inspired by the study on word recognition process in cognitive\npsychology, we propose to take advantage of seemingly less obvious but\nessentially important morphological knowledge to address these challenges. In\nparticular, we introduce a novel neural network architecture called KNET that\nleverages both contextual information and morphological word similarity built\nbased on morphological knowledge to learn word embeddings. Meanwhile, the\nlearning architecture is also able to refine the pre-defined morphological\nknowledge and obtain more accurate word similarity. Experiments on an\nanalogical reasoning task and a word similarity task both demonstrate that the\nproposed KNET framework can greatly enhance the effectiveness of word\nembeddings. \n\n"}
{"id": "1409.0473", "contents": "Title: Neural Machine Translation by Jointly Learning to Align and Translate Abstract: Neural machine translation is a recently proposed approach to machine\ntranslation. Unlike the traditional statistical machine translation, the neural\nmachine translation aims at building a single neural network that can be\njointly tuned to maximize the translation performance. The models proposed\nrecently for neural machine translation often belong to a family of\nencoder-decoders and consists of an encoder that encodes a source sentence into\na fixed-length vector from which a decoder generates a translation. In this\npaper, we conjecture that the use of a fixed-length vector is a bottleneck in\nimproving the performance of this basic encoder-decoder architecture, and\npropose to extend this by allowing a model to automatically (soft-)search for\nparts of a source sentence that are relevant to predicting a target word,\nwithout having to form these parts as a hard segment explicitly. With this new\napproach, we achieve a translation performance comparable to the existing\nstate-of-the-art phrase-based system on the task of English-to-French\ntranslation. Furthermore, qualitative analysis reveals that the\n(soft-)alignments found by the model agree well with our intuition. \n\n"}
{"id": "1409.1257", "contents": "Title: Overcoming the Curse of Sentence Length for Neural Machine Translation\n  using Automatic Segmentation Abstract: The authors of (Cho et al., 2014a) have shown that the recently introduced\nneural network translation systems suffer from a significant drop in\ntranslation quality when translating long sentences, unlike existing\nphrase-based translation systems. In this paper, we propose a way to address\nthis issue by automatically segmenting an input sentence into phrases that can\nbe easily translated by the neural network translation model. Once each segment\nhas been independently translated by the neural machine translation model, the\ntranslated clauses are concatenated to form a final translation. Empirical\nresults show a significant improvement in translation quality for long\nsentences. \n\n"}
{"id": "1409.2073", "contents": "Title: An NLP Assistant for Clide Abstract: This report describes an NLP assistant for the collaborative development\nenvironment Clide, that supports the development of NLP applications by\nproviding easy access to some common NLP data structures. The assistant\nvisualizes text fragments and their dependencies by displaying the semantic\ngraph of a sentence, the coreference chain of a paragraph and mined triples\nthat are extracted from a paragraph's semantic graphs and linked using its\ncoreference chain. Using this information and a logic programming library, we\ncreate an NLP database which is used by a series of queries to mine the\ntriples. The algorithm is tested by translating a natural language text\ndescribing a graph to an actual graph that is shown as an annotation in the\ntext editor. \n\n"}
{"id": "1410.1090", "contents": "Title: Explain Images with Multimodal Recurrent Neural Networks Abstract: In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model\nfor generating novel sentence descriptions to explain the content of images. It\ndirectly models the probability distribution of generating a word given\nprevious words and the image. Image descriptions are generated by sampling from\nthis distribution. The model consists of two sub-networks: a deep recurrent\nneural network for sentences and a deep convolutional network for images. These\ntwo sub-networks interact with each other in a multimodal layer to form the\nwhole m-RNN model. The effectiveness of our model is validated on three\nbenchmark datasets (IAPR TC-12, Flickr 8K, and Flickr 30K). Our model\noutperforms the state-of-the-art generative method. In addition, the m-RNN\nmodel can be applied to retrieval tasks for retrieving images or sentences, and\nachieves significant performance improvement over the state-of-the-art methods\nwhich directly optimize the ranking objective function for retrieval. \n\n"}
{"id": "1410.4445", "contents": "Title: Patterns in the English Language: Phonological Networks, Percolation and\n  Assembly Models Abstract: In this paper we provide a quantitative framework for the study of\nphonological networks (PNs) for the English language by carrying out principled\ncomparisons to null models, either based on site percolation, randomization\ntechniques, or network growth models. In contrast to previous work, we mainly\nfocus on null models that reproduce lower order characteristics of the\nempirical data. We find that artificial networks matching connectivity\nproperties of the English PN are exceedingly rare: this leads to the hypothesis\nthat the word repertoire might have been assembled over time by preferentially\nintroducing new words which are small modifications of old words. Our null\nmodels are able to explain the \"power-law-like\" part of the degree\ndistributions and generally retrieve qualitative features of the PN such as\nhigh clustering, high assortativity coefficient, and small-world\ncharacteristics. However, the detailed comparison to expectations from null\nmodels also points out significant differences, suggesting the presence of\nadditional constraints in word assembly. Key constraints we identify are the\navoidance of large degrees, the avoidance of triadic closure, and the avoidance\nof large non-percolating clusters. \n\n"}
{"id": "1410.4510", "contents": "Title: Graph-Sparse LDA: A Topic Model with Structured Sparsity Abstract: Originally designed to model text, topic modeling has become a powerful tool\nfor uncovering latent structure in domains including medicine, finance, and\nvision. The goals for the model vary depending on the application: in some\ncases, the discovered topics may be used for prediction or some other\ndownstream task. In other cases, the content of the topic itself may be of\nintrinsic scientific interest.\n  Unfortunately, even using modern sparse techniques, the discovered topics are\noften difficult to interpret due to the high dimensionality of the underlying\nspace. To improve topic interpretability, we introduce Graph-Sparse LDA, a\nhierarchical topic model that leverages knowledge of relationships between\nwords (e.g., as encoded by an ontology). In our model, topics are summarized by\na few latent concept-words from the underlying graph that explain the observed\nwords. Graph-Sparse LDA recovers sparse, interpretable summaries on two\nreal-world biomedical datasets while matching state-of-the-art prediction\nperformance. \n\n"}
{"id": "1410.8206", "contents": "Title: Addressing the Rare Word Problem in Neural Machine Translation Abstract: Neural Machine Translation (NMT) is a new approach to machine translation\nthat has shown promising results that are comparable to traditional approaches.\nA significant weakness in conventional NMT systems is their inability to\ncorrectly translate very rare words: end-to-end NMTs tend to have relatively\nsmall vocabularies with a single unk symbol that represents every possible\nout-of-vocabulary (OOV) word. In this paper, we propose and implement an\neffective technique to address this problem. We train an NMT system on data\nthat is augmented by the output of a word alignment algorithm, allowing the NMT\nsystem to emit, for each OOV word in the target sentence, the position of its\ncorresponding word in the source sentence. This information is later utilized\nin a post-processing step that translates every OOV word using a dictionary.\nOur experiments on the WMT14 English to French translation task show that this\nmethod provides a substantial improvement of up to 2.8 BLEU points over an\nequivalent NMT system that does not use this technique. With 37.5 BLEU points,\nour NMT system is the first to surpass the best result achieved on a WMT14\ncontest task. \n\n"}
{"id": "1411.1784", "contents": "Title: Conditional Generative Adversarial Nets Abstract: Generative Adversarial Nets [8] were recently introduced as a novel way to\ntrain generative models. In this work we introduce the conditional version of\ngenerative adversarial nets, which can be constructed by simply feeding the\ndata, y, we wish to condition on to both the generator and discriminator. We\nshow that this model can generate MNIST digits conditioned on class labels. We\nalso illustrate how this model could be used to learn a multi-modal model, and\nprovide preliminary examples of an application to image tagging in which we\ndemonstrate how this approach can generate descriptive tags which are not part\nof training labels. \n\n"}
{"id": "1411.3315", "contents": "Title: Statistically Significant Detection of Linguistic Change Abstract: We propose a new computational approach for tracking and detecting\nstatistically significant linguistic shifts in the meaning and usage of words.\nSuch linguistic shifts are especially prevalent on the Internet, where the\nrapid exchange of ideas can quickly change a word's meaning. Our meta-analysis\napproach constructs property time series of word usage, and then uses\nstatistically sound change point detection algorithms to identify significant\nlinguistic shifts.\n  We consider and analyze three approaches of increasing complexity to generate\nsuch linguistic property time series, the culmination of which uses\ndistributional characteristics inferred from word co-occurrences. Using\nrecently proposed deep neural language models, we first train vector\nrepresentations of words for each time period. Second, we warp the vector\nspaces into one unified coordinate system. Finally, we construct a\ndistance-based distributional time series for each word to track it's\nlinguistic displacement over time.\n  We demonstrate that our approach is scalable by tracking linguistic change\nacross years of micro-blogging using Twitter, a decade of product reviews using\na corpus of movie reviews from Amazon, and a century of written books using the\nGoogle Book-ngrams. Our analysis reveals interesting patterns of language usage\nchange commensurate with each medium. \n\n"}
{"id": "1411.4952", "contents": "Title: From Captions to Visual Concepts and Back Abstract: This paper presents a novel approach for automatically generating image\ndescriptions: visual detectors, language models, and multimodal similarity\nmodels learnt directly from a dataset of image captions. We use multiple\ninstance learning to train visual detectors for words that commonly occur in\ncaptions, including many different parts of speech such as nouns, verbs, and\nadjectives. The word detector outputs serve as conditional inputs to a\nmaximum-entropy language model. The language model learns from a set of over\n400,000 image descriptions to capture the statistics of word usage. We capture\nglobal semantics by re-ranking caption candidates using sentence-level features\nand a deep multimodal similarity model. Our system is state-of-the-art on the\nofficial Microsoft COCO benchmark, producing a BLEU-4 score of 29.1%. When\nhuman judges compare the system captions to ones written by other people on our\nheld-out test set, the system captions have equal or better quality 34% of the\ntime. \n\n"}
{"id": "1411.5726", "contents": "Title: CIDEr: Consensus-based Image Description Evaluation Abstract: Automatically describing an image with a sentence is a long-standing\nchallenge in computer vision and natural language processing. Due to recent\nprogress in object detection, attribute classification, action recognition,\netc., there is renewed interest in this area. However, evaluating the quality\nof descriptions has proven to be challenging. We propose a novel paradigm for\nevaluating image descriptions that uses human consensus. This paradigm consists\nof three main parts: a new triplet-based method of collecting human annotations\nto measure consensus, a new automated metric (CIDEr) that captures consensus,\nand two new datasets: PASCAL-50S and ABSTRACT-50S that contain 50 sentences\ndescribing each image. Our simple metric captures human judgment of consensus\nbetter than existing metrics across sentences generated by various sources. We\nalso evaluate five state-of-the-art image description approaches using this new\nprotocol and provide a benchmark for future comparisons. A version of CIDEr\nnamed CIDEr-D is available as a part of MS COCO evaluation server to enable\nsystematic evaluation and benchmarking. \n\n"}
{"id": "1411.6699", "contents": "Title: One Vector is Not Enough: Entity-Augmented Distributional Semantics for\n  Discourse Relations Abstract: Discourse relations bind smaller linguistic units into coherent texts.\nHowever, automatically identifying discourse relations is difficult, because it\nrequires understanding the semantics of the linked arguments. A more subtle\nchallenge is that it is not enough to represent the meaning of each argument of\na discourse relation, because the relation may depend on links between\nlower-level components, such as entity mentions. Our solution computes\ndistributional meaning representations by composition up the syntactic parse\ntree. A key difference from previous work on compositional distributional\nsemantics is that we also compute representations for entity mentions, using a\nnovel downward compositional pass. Discourse relations are predicted from the\ndistributional representations of the arguments, and also of their coreferent\nentity mentions. The resulting system obtains substantial improvements over the\nprevious state-of-the-art in predicting implicit discourse relations in the\nPenn Discourse Treebank. \n\n"}
{"id": "1412.1866", "contents": "Title: Integer-Programming Ensemble of Temporal-Relations Classifiers Abstract: The extraction and understanding of temporal events and their relations are\nmajor challenges in natural language processing. Processing text on a\nsentence-by-sentence or expression-by-expression basis often fails, in part due\nto the challenge of capturing the global consistency of the text. We present an\nensemble method, which reconciles the outputs of multiple classifiers of\ntemporal expressions across the text using integer programming. Computational\nexperiments show that the ensemble improves upon the best individual results\nfrom two recent challenges, SemEval-2013 TempEval-3 (Temporal Annotation) and\nSemEval-2016 Task 12 (Clinical TempEval). \n\n"}
{"id": "1412.2812", "contents": "Title: Unsupervised Induction of Semantic Roles within a Reconstruction-Error\n  Minimization Framework Abstract: We introduce a new approach to unsupervised estimation of feature-rich\nsemantic role labeling models. Our model consists of two components: (1) an\nencoding component: a semantic role labeling model which predicts roles given a\nrich set of syntactic and lexical features; (2) a reconstruction component: a\ntensor factorization model which relies on roles to predict argument fillers.\nWhen the components are estimated jointly to minimize errors in argument\nreconstruction, the induced roles largely correspond to roles defined in\nannotated resources. Our method performs on par with most accurate role\ninduction methods on English and German, even though, unlike these previous\napproaches, we do not incorporate any prior linguistic knowledge about the\nlanguages. \n\n"}
{"id": "1412.6568", "contents": "Title: Improving zero-shot learning by mitigating the hubness problem Abstract: The zero-shot paradigm exploits vector-based word representations extracted\nfrom text corpora with unsupervised methods to learn general mapping functions\nfrom other feature spaces onto word space, where the words associated to the\nnearest neighbours of the mapped vectors are used as their linguistic labels.\nWe show that the neighbourhoods of the mapped elements are strongly polluted by\nhubs, vectors that tend to be near a high proportion of items, pushing their\ncorrect labels down the neighbour list. After illustrating the problem\nempirically, we propose a simple method to correct it by taking the proximity\ndistribution of potential neighbours across many mapped vectors into account.\nWe show that this correction leads to consistent improvements in realistic\nzero-shot experiments in the cross-lingual, image labeling and image retrieval\ndomains. \n\n"}
{"id": "1412.7004", "contents": "Title: Tailoring Word Embeddings for Bilexical Predictions: An Experimental\n  Comparison Abstract: We investigate the problem of inducing word embeddings that are tailored for\na particular bilexical relation. Our learning algorithm takes an existing\nlexical vector space and compresses it such that the resulting word embeddings\nare good predictors for a target bilexical relation. In experiments we show\nthat task-specific embeddings can benefit both the quality and efficiency in\nlexical prediction tasks. \n\n"}
{"id": "1501.02598", "contents": "Title: Combining Language and Vision with a Multimodal Skip-gram Model Abstract: We extend the SKIP-GRAM model of Mikolov et al. (2013a) by taking visual\ninformation into account. Like SKIP-GRAM, our multimodal models (MMSKIP-GRAM)\nbuild vector-based word representations by learning to predict linguistic\ncontexts in text corpora. However, for a restricted set of words, the models\nare also exposed to visual representations of the objects they denote\n(extracted from natural images), and must predict linguistic and visual\nfeatures jointly. The MMSKIP-GRAM models achieve good performance on a variety\nof semantic benchmarks. Moreover, since they propagate visual information to\nall words, we use them to improve image labeling and retrieval in the zero-shot\nsetup, where the test concepts are never seen during model training. Finally,\nthe MMSKIP-GRAM models discover intriguing visual properties of abstract words,\npaving the way to realistic implementations of embodied theories of meaning. \n\n"}
{"id": "1502.03671", "contents": "Title: Phrase-based Image Captioning Abstract: Generating a novel textual description of an image is an interesting problem\nthat connects computer vision and natural language processing. In this paper,\nwe present a simple model that is able to generate descriptive sentences given\na sample image. This model has a strong focus on the syntax of the\ndescriptions. We train a purely bilinear model that learns a metric between an\nimage representation (generated from a previously trained Convolutional Neural\nNetwork) and phrases that are used to described them. The system is then able\nto infer phrases from a given image sample. Based on caption syntax statistics,\nwe propose a simple language model that can produce relevant descriptions for a\ngiven test image using the phrases inferred. Our approach, which is\nconsiderably simpler than state-of-the-art models, achieves comparable results\nin two popular datasets for the task: Flickr30k and the recently proposed\nMicrosoft COCO. \n\n"}
{"id": "1503.00168", "contents": "Title: The NLP Engine: A Universal Turing Machine for NLP Abstract: It is commonly accepted that machine translation is a more complex task than\npart of speech tagging. But how much more complex? In this paper we make an\nattempt to develop a general framework and methodology for computing the\ninformational and/or processing complexity of NLP applications and tasks. We\ndefine a universal framework akin to a Turning Machine that attempts to fit\n(most) NLP tasks into one paradigm. We calculate the complexities of various\nNLP tasks using measures of Shannon Entropy, and compare `simple' ones such as\npart of speech tagging to `complex' ones such as machine translation. This\npaper provides a first, though far from perfect, attempt to quantify NLP tasks\nunder a uniform paradigm. We point out current deficiencies and suggest some\navenues for fruitful research. \n\n"}
{"id": "1503.02335", "contents": "Title: An Unsupervised Method for Uncovering Morphological Chains Abstract: Most state-of-the-art systems today produce morphological analysis based only\non orthographic patterns. In contrast, we propose a model for unsupervised\nmorphological analysis that integrates orthographic and semantic views of\nwords. We model word formation in terms of morphological chains, from base\nwords to the observed words, breaking the chains into parent-child relations.\nWe use log-linear models with morpheme and word-level features to predict\npossible parents, including their modifications, for each word. The limited set\nof candidate parents for each word render contrastive estimation feasible. Our\nmodel consistently matches or outperforms five state-of-the-art systems on\nArabic, English and Turkish. \n\n"}
{"id": "1503.03244", "contents": "Title: Convolutional Neural Network Architectures for Matching Natural Language\n  Sentences Abstract: Semantic matching is of central importance to many natural language tasks\n\\cite{bordes2014semantic,RetrievalQA}. A successful matching algorithm needs to\nadequately model the internal structures of language objects and the\ninteraction between them. As a step toward this goal, we propose convolutional\nneural network models for matching two sentences, by adapting the convolutional\nstrategy in vision and speech. The proposed models not only nicely represent\nthe hierarchical structures of sentences with their layer-by-layer composition\nand pooling, but also capture the rich matching patterns at different levels.\nOur models are rather generic, requiring no prior knowledge on language, and\ncan hence be applied to matching tasks of different nature and in different\nlanguages. The empirical study on a variety of matching tasks demonstrates the\nefficacy of the proposed model on a variety of matching tasks and its\nsuperiority to competitor models. \n\n"}
{"id": "1503.04250", "contents": "Title: The YLI-MED Corpus: Characteristics, Procedures, and Plans Abstract: The YLI Multimedia Event Detection corpus is a public-domain index of videos\nwith annotations and computed features, specialized for research in multimedia\nevent detection (MED), i.e., automatically identifying what's happening in a\nvideo by analyzing the audio and visual content. The videos indexed in the\nYLI-MED corpus are a subset of the larger YLI feature corpus, which is being\ndeveloped by the International Computer Science Institute and Lawrence\nLivermore National Laboratory based on the Yahoo Flickr Creative Commons 100\nMillion (YFCC100M) dataset. The videos in YLI-MED are categorized as depicting\none of ten target events, or no target event, and are annotated for additional\nattributes like language spoken and whether the video has a musical score. The\nannotations also include degree of annotator agreement and average annotator\nconfidence scores for the event categorization of each video. Version 1.0 of\nYLI-MED includes 1823 \"positive\" videos that depict the target events and\n48,138 \"negative\" videos, as well as 177 supplementary videos that are similar\nto event videos but are not positive examples. Our goal in producing YLI-MED is\nto be as open about our data and procedures as possible. This report describes\nthe procedures used to collect the corpus; gives detailed descriptive\nstatistics about the corpus makeup (and how video attributes affected\nannotators' judgments); discusses possible biases in the corpus introduced by\nour procedural choices and compares it with the most similar existing dataset,\nTRECVID MED's HAVIC corpus; and gives an overview of our future plans for\nexpanding the annotation effort. \n\n"}
{"id": "1503.04723", "contents": "Title: Deep Feelings: A Massive Cross-Lingual Study on the Relation between\n  Emotions and Virality Abstract: This article provides a comprehensive investigation on the relations between\nvirality of news articles and the emotions they are found to evoke. Virality,\nin our view, is a phenomenon with many facets, i.e. under this generic term\nseveral different effects of persuasive communication are comprised. By\nexploiting a high-coverage and bilingual corpus of documents containing metrics\nof their spread on social networks as well as a massive affective annotation\nprovided by readers, we present a thorough analysis of the interplay between\nevoked emotions and viral facets. We highlight and discuss our findings in\nlight of a cross-lingual approach: while we discover differences in evoked\nemotions and corresponding viral effects, we provide preliminary evidence of a\ngeneralized explanatory model rooted in the deep structure of emotions: the\nValence-Arousal-Dominance (VAD) circumplex. We find that viral facets appear to\nbe consistently affected by particular VAD configurations, and these\nconfigurations indicate a clear connection with distinct phenomena underlying\npersuasive communication. \n\n"}
{"id": "1503.05615", "contents": "Title: Learning to Search for Dependencies Abstract: We demonstrate that a dependency parser can be built using a credit\nassignment compiler which removes the burden of worrying about low-level\nmachine learning details from the parser implementation. The result is a simple\nparser which robustly applies to many languages that provides similar\nstatistical and computational performance with best-to-date transition-based\nparsing approaches, while avoiding various downsides including randomization,\nextra feature requirements, and custom learning algorithms. \n\n"}
{"id": "1503.06733", "contents": "Title: Yara Parser: A Fast and Accurate Dependency Parser Abstract: Dependency parsers are among the most crucial tools in natural language\nprocessing as they have many important applications in downstream tasks such as\ninformation retrieval, machine translation and knowledge acquisition. We\nintroduce the Yara Parser, a fast and accurate open-source dependency parser\nbased on the arc-eager algorithm and beam search. It achieves an unlabeled\naccuracy of 93.32 on the standard WSJ test set which ranks it among the top\ndependency parsers. At its fastest, Yara can parse about 4000 sentences per\nsecond when in greedy mode (1 beam). When optimizing for accuracy (using 64\nbeams and Brown cluster features), Yara can parse 45 sentences per second. The\nparser can be trained on any syntactic dependency treebank and different\noptions are provided in order to make it more flexible and tunable for specific\ntasks. It is released with the Apache version 2.0 license and can be used for\nboth commercial and academic purposes. The parser can be found at\nhttps://github.com/yahoo/YaraParser. \n\n"}
{"id": "1504.01255", "contents": "Title: Semi-supervised Convolutional Neural Networks for Text Categorization\n  via Region Embedding Abstract: This paper presents a new semi-supervised framework with convolutional neural\nnetworks (CNNs) for text categorization. Unlike the previous approaches that\nrely on word embeddings, our method learns embeddings of small text regions\nfrom unlabeled data for integration into a supervised CNN. The proposed scheme\nfor embedding learning is based on the idea of two-view semi-supervised\nlearning, which is intended to be useful for the task of interest even though\nthe training is done on unlabeled data. Our models achieve better results than\nprevious approaches on sentiment classification and topic classification tasks. \n\n"}
{"id": "1504.01483", "contents": "Title: Transferring Knowledge from a RNN to a DNN Abstract: Deep Neural Network (DNN) acoustic models have yielded many state-of-the-art\nresults in Automatic Speech Recognition (ASR) tasks. More recently, Recurrent\nNeural Network (RNN) models have been shown to outperform DNNs counterparts.\nHowever, state-of-the-art DNN and RNN models tend to be impractical to deploy\non embedded systems with limited computational capacity. Traditionally, the\napproach for embedded platforms is to either train a small DNN directly, or to\ntrain a small DNN that learns the output distribution of a large DNN. In this\npaper, we utilize a state-of-the-art RNN to transfer knowledge to small DNN. We\nuse the RNN model to generate soft alignments and minimize the Kullback-Leibler\ndivergence against the small DNN. The small DNN trained on the soft RNN\nalignments achieved a 3.93 WER on the Wall Street Journal (WSJ) eval92 task\ncompared to a baseline 4.54 WER or more than 13% relative improvement. \n\n"}
{"id": "1504.01683", "contents": "Title: Jointly Embedding Relations and Mentions for Knowledge Population Abstract: This paper contributes a joint embedding model for predicting relations\nbetween a pair of entities in the scenario of relation inference. It differs\nfrom most stand-alone approaches which separately operate on either knowledge\nbases or free texts. The proposed model simultaneously learns low-dimensional\nvector representations for both triplets in knowledge repositories and the\nmentions of relations in free texts, so that we can leverage the evidence both\nresources to make more accurate predictions. We use NELL to evaluate the\nperformance of our approach, compared with cutting-edge methods. Results of\nextensive experiments show that our model achieves significant improvement on\nrelation extraction. \n\n"}
{"id": "1504.01684", "contents": "Title: Large Margin Nearest Neighbor Embedding for Knowledge Representation Abstract: Traditional way of storing facts in triplets ({\\it head\\_entity, relation,\ntail\\_entity}), abbreviated as ({\\it h, r, t}), makes the knowledge intuitively\ndisplayed and easily acquired by mankind, but hardly computed or even reasoned\nby AI machines. Inspired by the success in applying {\\it Distributed\nRepresentations} to AI-related fields, recent studies expect to represent each\nentity and relation with a unique low-dimensional embedding, which is different\nfrom the symbolic and atomic framework of displaying knowledge in triplets. In\nthis way, the knowledge computing and reasoning can be essentially facilitated\nby means of a simple {\\it vector calculation}, i.e. ${\\bf h} + {\\bf r} \\approx\n{\\bf t}$. We thus contribute an effective model to learn better embeddings\nsatisfying the formula by pulling the positive tail entities ${\\bf t^{+}}$ to\nget together and close to {\\bf h} + {\\bf r} ({\\it Nearest Neighbor}), and\nsimultaneously pushing the negatives ${\\bf t^{-}}$ away from the positives\n${\\bf t^{+}}$ via keeping a {\\it Large Margin}. We also design a corresponding\nlearning algorithm to efficiently find the optimal solution based on {\\it\nStochastic Gradient Descent} in iterative fashion. Quantitative experiments\nillustrate that our approach can achieve the state-of-the-art performance,\ncompared with several latest methods on some benchmark datasets for two\nclassical applications, i.e. {\\it Link prediction} and {\\it Triplet\nclassification}. Moreover, we analyze the parameter complexities among all the\nevaluated models, and analytical results indicate that our model needs fewer\ncomputational resources on outperforming the other methods. \n\n"}
{"id": "1504.04802", "contents": "Title: Gradual Classical Logic for Attributed Objects - Extended in\n  Re-Presentation Abstract: Our understanding about things is conceptual. By stating that we reason about\nobjects, it is in fact not the objects but concepts referring to them that we\nmanipulate. Now, so long just as we acknowledge infinitely extending notions\nsuch as space, time, size, colour, etc, - in short, any reasonable quality -\ninto which an object is subjected, it becomes infeasible to affirm atomicity in\nthe concept referring to the object. However, formal/symbolic logics typically\npresume atomic entities upon which other expressions are built. Can we reflect\nour intuition about the concept onto formal/symbolic logics at all? I assure\nthat we can, but the usual perspective about the atomicity needs inspected. In\nthis work, I present gradual logic which materialises the observation that we\ncannot tell apart whether a so-regarded atomic entity is atomic or is just\natomic enough not to be considered non-atomic. The motivation is to capture\ncertain phenomena that naturally occur around concepts with attributes,\nincluding presupposition and contraries. I present logical particulars of the\nlogic, which is then mapped onto formal semantics. Two linguistically\ninteresting semantics will be considered. Decidability is shown. \n\n"}
{"id": "1504.05319", "contents": "Title: Big Data Small Data, In Domain Out-of Domain, Known Word Unknown Word:\n  The Impact of Word Representation on Sequence Labelling Tasks Abstract: Word embeddings -- distributed word representations that can be learned from\nunlabelled data -- have been shown to have high utility in many natural\nlanguage processing applications. In this paper, we perform an extrinsic\nevaluation of five popular word embedding methods in the context of four\nsequence labelling tasks: POS-tagging, syntactic chunking, NER and MWE\nidentification. A particular focus of the paper is analysing the effects of\ntask-based updating of word representations. We show that when using word\nembeddings as features, as few as several hundred training instances are\nsufficient to achieve competitive results, and that word embeddings lead to\nimprovements over OOV words and out of domain. Perhaps more surprisingly, our\nresults indicate there is little difference between the different word\nembedding methods, and that simple Brown clusters are often competitive with\nword embeddings across all tasks we consider. \n\n"}
{"id": "1504.07225", "contents": "Title: Correlational Neural Networks Abstract: Common Representation Learning (CRL), wherein different descriptions (or\nviews) of the data are embedded in a common subspace, is receiving a lot of\nattention recently. Two popular paradigms here are Canonical Correlation\nAnalysis (CCA) based approaches and Autoencoder (AE) based approaches. CCA\nbased approaches learn a joint representation by maximizing correlation of the\nviews when projected to the common subspace. AE based methods learn a common\nrepresentation by minimizing the error of reconstructing the two views. Each of\nthese approaches has its own advantages and disadvantages. For example, while\nCCA based approaches outperform AE based approaches for the task of transfer\nlearning, they are not as scalable as the latter. In this work we propose an AE\nbased approach called Correlational Neural Network (CorrNet), that explicitly\nmaximizes correlation among the views when projected to the common subspace.\nThrough a series of experiments, we demonstrate that the proposed CorrNet is\nbetter than the above mentioned approaches with respect to its ability to learn\ncorrelated common representations. Further, we employ CorrNet for several cross\nlanguage tasks and show that the representations learned using CorrNet perform\nbetter than the ones learned using other state of the art approaches. \n\n"}
{"id": "1505.00468", "contents": "Title: VQA: Visual Question Answering Abstract: We propose the task of free-form and open-ended Visual Question Answering\n(VQA). Given an image and a natural language question about the image, the task\nis to provide an accurate natural language answer. Mirroring real-world\nscenarios, such as helping the visually impaired, both the questions and\nanswers are open-ended. Visual questions selectively target different areas of\nan image, including background details and underlying context. As a result, a\nsystem that succeeds at VQA typically needs a more detailed understanding of\nthe image and complex reasoning than a system producing generic image captions.\nMoreover, VQA is amenable to automatic evaluation, since many open-ended\nanswers contain only a few words or a closed set of answers that can be\nprovided in a multiple-choice format. We provide a dataset containing ~0.25M\nimages, ~0.76M questions, and ~10M answers (www.visualqa.org), and discuss the\ninformation it provides. Numerous baselines and methods for VQA are provided\nand compared with human performance. Our VQA demo is available on CloudCV\n(http://cloudcv.org/vqa). \n\n"}
{"id": "1505.01121", "contents": "Title: Ask Your Neurons: A Neural-based Approach to Answering Questions about\n  Images Abstract: We address a question answering task on real-world images that is set up as a\nVisual Turing Test. By combining latest advances in image representation and\nnatural language processing, we propose Neural-Image-QA, an end-to-end\nformulation to this problem for which all parts are trained jointly. In\ncontrast to previous efforts, we are facing a multi-modal problem where the\nlanguage output (answer) is conditioned on visual and natural language input\n(image and question). Our approach Neural-Image-QA doubles the performance of\nthe previous best approach on this problem. We provide additional insights into\nthe problem by analyzing how much information is contained only in the language\npart for which we provide a new human baseline. To study human consensus, which\nis related to the ambiguities inherent in this challenging task, we propose two\nnovel metrics and collect additional answers which extends the original DAQUAR\ndataset to DAQUAR-Consensus. \n\n"}
{"id": "1505.02074", "contents": "Title: Exploring Models and Data for Image Question Answering Abstract: This work aims to address the problem of image-based question-answering (QA)\nwith new models and datasets. In our work, we propose to use neural networks\nand visual semantic embeddings, without intermediate stages such as object\ndetection and image segmentation, to predict answers to simple questions about\nimages. Our model performs 1.8 times better than the only published results on\nan existing image QA dataset. We also present a question generation algorithm\nthat converts image descriptions, which are widely available, into QA form. We\nused this algorithm to produce an order-of-magnitude larger dataset, with more\nevenly distributed answers. A suite of baseline results on this new dataset are\nalso presented. \n\n"}
{"id": "1505.02419", "contents": "Title: Improved Relation Extraction with Feature-Rich Compositional Embedding\n  Models Abstract: Compositional embedding models build a representation (or embedding) for a\nlinguistic structure based on its component word embeddings. We propose a\nFeature-rich Compositional Embedding Model (FCM) for relation extraction that\nis expressive, generalizes to new domains, and is easy-to-implement. The key\nidea is to combine both (unlexicalized) hand-crafted features with learned word\nembeddings. The model is able to directly tackle the difficulties met by\ntraditional compositional embeddings models, such as handling arbitrary types\nof sentence annotations and utilizing global information for composition. We\ntest the proposed model on two relation extraction tasks, and demonstrate that\nour model outperforms both previous compositional models and traditional\nfeature rich models on the ACE 2005 relation extraction task, and the SemEval\n2010 relation classification task. The combination of our model and a\nlog-linear classifier with hand-crafted features gives state-of-the-art\nresults. \n\n"}
{"id": "1505.04342", "contents": "Title: Sifting Robotic from Organic Text: A Natural Language Approach for\n  Detecting Automation on Twitter Abstract: Twitter, a popular social media outlet, has evolved into a vast source of\nlinguistic data, rich with opinion, sentiment, and discussion. Due to the\nincreasing popularity of Twitter, its perceived potential for exerting social\ninfluence has led to the rise of a diverse community of automatons, commonly\nreferred to as bots. These inorganic and semi-organic Twitter entities can\nrange from the benevolent (e.g., weather-update bots, help-wanted-alert bots)\nto the malevolent (e.g., spamming messages, advertisements, or radical\nopinions). Existing detection algorithms typically leverage meta-data (time\nbetween tweets, number of followers, etc.) to identify robotic accounts. Here,\nwe present a powerful classification scheme that exclusively uses the natural\nlanguage text from organic users to provide a criterion for identifying\naccounts posting automated messages. Since the classifier operates on text\nalone, it is flexible and may be applied to any textual data beyond the\nTwitter-sphere. \n\n"}
{"id": "1505.04630", "contents": "Title: Recurrent Neural Network Training with Dark Knowledge Transfer Abstract: Recurrent neural networks (RNNs), particularly long short-term memory (LSTM),\nhave gained much attention in automatic speech recognition (ASR). Although some\nsuccessful stories have been reported, training RNNs remains highly\nchallenging, especially with limited training data. Recent research found that\na well-trained model can be used as a teacher to train other child models, by\nusing the predictions generated by the teacher model as supervision. This\nknowledge transfer learning has been employed to train simple neural nets with\na complex one, so that the final performance can reach a level that is\ninfeasible to obtain by regular training. In this paper, we employ the\nknowledge transfer learning approach to train RNNs (precisely LSTM) using a\ndeep neural network (DNN) model as the teacher. This is different from most of\nthe existing research on knowledge transfer learning, since the teacher (DNN)\nis assumed to be weaker than the child (RNN); however, our experiments on an\nASR task showed that it works fairly well: without applying any tricks on the\nlearning scheme, this approach can train RNNs successfully even with limited\ntraining data. \n\n"}
{"id": "1505.04771", "contents": "Title: DopeLearning: A Computational Approach to Rap Lyrics Generation Abstract: Writing rap lyrics requires both creativity to construct a meaningful,\ninteresting story and lyrical skills to produce complex rhyme patterns, which\nform the cornerstone of good flow. We present a rap lyrics generation method\nthat captures both of these aspects. First, we develop a prediction model to\nidentify the next line of existing lyrics from a set of candidate next lines.\nThis model is based on two machine-learning techniques: the RankSVM algorithm\nand a deep neural network model with a novel structure. Results show that the\nprediction model can identify the true next line among 299 randomly selected\nlines with an accuracy of 17%, i.e., over 50 times more likely than by random.\nSecond, we employ the prediction model to combine lines from existing songs,\nproducing lyrics with rhyme and a meaning. An evaluation of the produced lyrics\nshows that in terms of quantitative rhyme density, the method outperforms the\nbest human rappers by 21%. The rap lyrics generator has been deployed as an\nonline tool called DeepBeat, and the performance of the tool has been assessed\nby analyzing its usage logs. This analysis shows that machine-learned rankings\ncorrelate with user preferences. \n\n"}
{"id": "1505.04891", "contents": "Title: Learning Better Word Embedding by Asymmetric Low-Rank Projection of\n  Knowledge Graph Abstract: Word embedding, which refers to low-dimensional dense vector representations\nof natural words, has demonstrated its power in many natural language\nprocessing tasks. However, it may suffer from the inaccurate and incomplete\ninformation contained in the free text corpus as training data. To tackle this\nchallenge, there have been quite a few works that leverage knowledge graphs as\nan additional information source to improve the quality of word embedding.\nAlthough these works have achieved certain success, they have neglected some\nimportant facts about knowledge graphs: (i) many relationships in knowledge\ngraphs are \\emph{many-to-one}, \\emph{one-to-many} or even \\emph{many-to-many},\nrather than simply \\emph{one-to-one}; (ii) most head entities and tail entities\nin knowledge graphs come from very different semantic spaces. To address these\nissues, in this paper, we propose a new algorithm named ProjectNet. ProjecNet\nmodels the relationships between head and tail entities after transforming them\nwith different low-rank projection matrices. The low-rank projection can allow\nnon \\emph{one-to-one} relationships between entities, while different\nprojection matrices for head and tail entities allow them to originate in\ndifferent semantic spaces. The experimental results demonstrate that ProjectNet\nyields more accurate word embedding than previous works, thus leads to clear\nimprovements in various natural language processing tasks. \n\n"}
{"id": "1505.05667", "contents": "Title: A Re-ranking Model for Dependency Parser with Recursive Convolutional\n  Neural Network Abstract: In this work, we address the problem to model all the nodes (words or\nphrases) in a dependency tree with the dense representations. We propose a\nrecursive convolutional neural network (RCNN) architecture to capture syntactic\nand compositional-semantic representations of phrases and words in a dependency\ntree. Different with the original recursive neural network, we introduce the\nconvolution and pooling layers, which can model a variety of compositions by\nthe feature maps and choose the most informative compositions by the pooling\nlayers. Based on RCNN, we use a discriminative model to re-rank a $k$-best list\nof candidate dependency parsing trees. The experiments show that RCNN is very\neffective to improve the state-of-the-art dependency parsing on both English\nand Chinese datasets. \n\n"}
{"id": "1505.05899", "contents": "Title: The IBM 2015 English Conversational Telephone Speech Recognition System Abstract: We describe the latest improvements to the IBM English conversational\ntelephone speech recognition system. Some of the techniques that were found\nbeneficial are: maxout networks with annealed dropout rates; networks with a\nvery large number of outputs trained on 2000 hours of data; joint modeling of\npartially unfolded recurrent neural networks and convolutional nets by\ncombining the bottleneck and output layers and retraining the resulting model;\nand lastly, sophisticated language model rescoring with exponential and neural\nnetwork LMs. These techniques result in an 8.0% word error rate on the\nSwitchboard part of the Hub5-2000 evaluation test set which is 23% relative\nbetter than our previous best published result. \n\n"}
{"id": "1506.00578", "contents": "Title: On Quantum Generalizations of Information-Theoretic Measures and their\n  Contribution to Distributional Semantics Abstract: Information-theoretic measures such as relative entropy and correlation are\nextremely useful when modeling or analyzing the interaction of probabilistic\nsystems. We survey the quantum generalization of 5 such measures and point out\nsome of their commonalities and interpretations. In particular we find the\napplication of information theory to distributional semantics useful. By\nmodeling the distributional meaning of words as density operators rather than\nvectors, more of their semantic structure may be exploited. Furthermore,\nproperties of and interactions between words such as ambiguity, similarity and\nentailment can be simulated more richly and intuitively when using methods from\nquantum information theory. \n\n"}
{"id": "1506.01066", "contents": "Title: Visualizing and Understanding Neural Models in NLP Abstract: While neural networks have been successfully applied to many NLP tasks the\nresulting vector-based models are very difficult to interpret. For example it's\nnot clear how they achieve {\\em compositionality}, building sentence meaning\nfrom the meanings of words and phrases. In this paper we describe four\nstrategies for visualizing compositionality in neural models for NLP, inspired\nby similar work in computer vision. We first plot unit values to visualize\ncompositionality of negation, intensification, and concessive clauses, allow us\nto see well-known markedness asymmetries in negation. We then introduce three\nsimple and straightforward methods for visualizing a unit's {\\em salience}, the\namount it contributes to the final composed meaning: (1) gradient\nback-propagation, (2) the variance of a token from the average word node, (3)\nLSTM-style gates that measure information flow. We test our methods on\nsentiment using simple recurrent nets and LSTMs. Our general-purpose methods\nmay have wide applications for understanding compositionality and other\nsemantic properties of deep networks , and also shed light on why LSTMs\noutperform simple recurrent nets, \n\n"}
{"id": "1506.03694", "contents": "Title: Learning language through pictures Abstract: We propose Imaginet, a model of learning visually grounded representations of\nlanguage from coupled textual and visual input. The model consists of two Gated\nRecurrent Unit networks with shared word embeddings, and uses a multi-task\nobjective by receiving a textual description of a scene and trying to\nconcurrently predict its visual representation and the next word in the\nsentence. Mimicking an important aspect of human language learning, it acquires\nmeaning representations for individual words from descriptions of visual\nscenes. Moreover, it learns to effectively use sequential structure in semantic\ninterpretation of multi-word phrases. \n\n"}
{"id": "1506.05561", "contents": "Title: Comparing and evaluating extended Lambek calculi Abstract: Lambeks Syntactic Calculus, commonly referred to as the Lambek calculus, was\ninnovative in many ways, notably as a precursor of linear logic. But it also\nshowed that we could treat our grammatical framework as a logic (as opposed to\na logical theory). However, though it was successful in giving at least a basic\ntreatment of many linguistic phenomena, it was also clear that a slightly more\nexpressive logical calculus was needed for many other cases. Therefore, many\nextensions and variants of the Lambek calculus have been proposed, since the\neighties and up until the present day. As a result, there is now a large class\nof calculi, each with its own empirical successes and theoretical results, but\nalso each with its own logical primitives. This raises the question: how do we\ncompare and evaluate these different logical formalisms? To answer this\nquestion, I present two unifying frameworks for these extended Lambek calculi.\nBoth are proof net calculi with graph contraction criteria. The first calculus\nis a very general system: you specify the structure of your sequents and it\ngives you the connectives and contractions which correspond to it. The calculus\ncan be extended with structural rules, which translate directly into graph\nrewrite rules. The second calculus is first-order (multiplicative\nintuitionistic) linear logic, which turns out to have several other,\nindependently proposed extensions of the Lambek calculus as fragments. I will\nillustrate the use of each calculus in building bridges between analyses\nproposed in different frameworks, in highlighting differences and in helping to\nidentify problems. \n\n"}
{"id": "1506.06442", "contents": "Title: A Deep Memory-based Architecture for Sequence-to-Sequence Learning Abstract: We propose DEEPMEMORY, a novel deep architecture for sequence-to-sequence\nlearning, which performs the task through a series of nonlinear transformations\nfrom the representation of the input sequence (e.g., a Chinese sentence) to the\nfinal output sequence (e.g., translation to English). Inspired by the recently\nproposed Neural Turing Machine (Graves et al., 2014), we store the intermediate\nrepresentations in stacked layers of memories, and use read-write operations on\nthe memories to realize the nonlinear transformations between the\nrepresentations. The types of transformations are designed in advance but the\nparameters are learned from data. Through layer-by-layer transformations,\nDEEPMEMORY can model complicated relations between sequences necessary for\napplications such as machine translation between distant languages. The\narchitecture can be trained with normal back-propagation on sequenceto-sequence\ndata, and the learning can be easily scaled up to a large corpus. DEEPMEMORY is\nbroad enough to subsume the state-of-the-art neural translation model in\n(Bahdanau et al., 2015) as its special case, while significantly improving upon\nthe model with its deeper architecture. Remarkably, DEEPMEMORY, being purely\nneural network-based, can achieve performance comparable to the traditional\nphrase-based machine translation system Moses with a small vocabulary and a\nmodest parameter size. \n\n"}
{"id": "1506.06726", "contents": "Title: Skip-Thought Vectors Abstract: We describe an approach for unsupervised learning of a generic, distributed\nsentence encoder. Using the continuity of text from books, we train an\nencoder-decoder model that tries to reconstruct the surrounding sentences of an\nencoded passage. Sentences that share semantic and syntactic properties are\nthus mapped to similar vector representations. We next introduce a simple\nvocabulary expansion method to encode words that were not seen as part of\ntraining, allowing us to expand our vocabulary to a million words. After\ntraining our model, we extract and evaluate our vectors with linear models on 8\ntasks: semantic relatedness, paraphrase detection, image-sentence ranking,\nquestion-type classification and 4 benchmark sentiment and subjectivity\ndatasets. The end result is an off-the-shelf encoder that can produce highly\ngeneric sentence representations that are robust and perform well in practice.\nWe will make our encoder publicly available. \n\n"}
{"id": "1506.06833", "contents": "Title: A Survey of Current Datasets for Vision and Language Research Abstract: Integrating vision and language has long been a dream in work on artificial\nintelligence (AI). In the past two years, we have witnessed an explosion of\nwork that brings together vision and language from images to videos and beyond.\nThe available corpora have played a crucial role in advancing this area of\nresearch. In this paper, we propose a set of quality metrics for evaluating and\nanalyzing the vision & language datasets and categorize them accordingly. Our\nanalyses show that the most recent datasets have been using more complex\nlanguage and more abstract concepts, however, there are different strengths and\nweaknesses in each. \n\n"}
{"id": "1507.01526", "contents": "Title: Grid Long Short-Term Memory Abstract: This paper introduces Grid Long Short-Term Memory, a network of LSTM cells\narranged in a multidimensional grid that can be applied to vectors, sequences\nor higher dimensional data such as images. The network differs from existing\ndeep LSTM architectures in that the cells are connected between network layers\nas well as along the spatiotemporal dimensions of the data. The network\nprovides a unified way of using LSTM for both deep and sequential computation.\nWe apply the model to algorithmic tasks such as 15-digit integer addition and\nsequence memorization, where it is able to significantly outperform the\nstandard LSTM. We then give results for two empirical tasks. We find that 2D\nGrid LSTM achieves 1.47 bits per character on the Wikipedia character\nprediction benchmark, which is state-of-the-art among neural approaches. In\naddition, we use the Grid LSTM to define a novel two-dimensional translation\nmodel, the Reencoder, and show that it outperforms a phrase-based reference\nsystem on a Chinese-to-English translation task. \n\n"}
{"id": "1507.03641", "contents": "Title: Neural CRF Parsing Abstract: This paper describes a parsing model that combines the exact dynamic\nprogramming of CRF parsing with the rich nonlinear featurization of neural net\napproaches. Our model is structurally a CRF that factors over anchored rule\nproductions, but instead of linear potential functions based on sparse\nfeatures, we use nonlinear potentials computed via a feedforward neural\nnetwork. Because potentials are still local to anchored rules, structured\ninference (CKY) is unchanged from the sparse case. Computing gradients during\nlearning involves backpropagating an error signal formed from standard CRF\nsufficient statistics (expected rule counts). Using only dense features, our\nneural CRF already exceeds a strong baseline CRF model (Hall et al., 2014). In\ncombination with sparse features, our system achieves 91.1 F1 on section 23 of\nthe Penn Treebank, and more generally outperforms the best prior single parser\nresults on a range of languages. \n\n"}
{"id": "1507.04798", "contents": "Title: Exploratory topic modeling with distributional semantics Abstract: As we continue to collect and store textual data in a multitude of domains,\nwe are regularly confronted with material whose largely unknown thematic\nstructure we want to uncover. With unsupervised, exploratory analysis, no prior\nknowledge about the content is required and highly open-ended tasks can be\nsupported. In the past few years, probabilistic topic modeling has emerged as a\npopular approach to this problem. Nevertheless, the representation of the\nlatent topics as aggregations of semi-coherent terms limits their\ninterpretability and level of detail.\n  This paper presents an alternative approach to topic modeling that maps\ntopics as a network for exploration, based on distributional semantics using\nlearned word vectors. From the granular level of terms and their semantic\nsimilarity relations global topic structures emerge as clustered regions and\ngradients of concepts. Moreover, the paper discusses the visual interactive\nrepresentation of the topic map, which plays an important role in supporting\nits exploration. \n\n"}
{"id": "1508.00354", "contents": "Title: Significance of Maximum Spectral Amplitude in Sub-bands for Spectral\n  Envelope Estimation and Its Application to Statistical Parametric Speech\n  Synthesis Abstract: In this paper we propose a technique for spectral envelope estimation using\nmaximum values in the sub-bands of Fourier magnitude spectrum (MSASB). Most\nother methods in the literature parametrize spectral envelope in cepstral\ndomain such as Mel-generalized cepstrum etc. Such cepstral domain\nrepresentations, although compact, are not readily interpretable. This\ndifficulty is overcome by our method which parametrizes in the spectral domain\nitself. In our experiments, spectral envelope estimated using MSASB method was\nincorporated in the STRAIGHT vocoder. Both objective and subjective results of\nanalysis-by-synthesis indicate that the proposed method is comparable to\nSTRAIGHT. We also evaluate the effectiveness of the proposed parametrization in\na statistical parametric speech synthesis framework using deep neural networks. \n\n"}
{"id": "1508.01746", "contents": "Title: Using Deep Learning for Detecting Spoofing Attacks on Speech Signals Abstract: It is well known that speaker verification systems are subject to spoofing\nattacks. The Automatic Speaker Verification Spoofing and Countermeasures\nChallenge -- ASVSpoof2015 -- provides a standard spoofing database, containing\nattacks based on synthetic speech, along with a protocol for experiments. This\npaper describes CPqD's systems submitted to the ASVSpoof2015 Challenge, based\non deep neural networks, working both as a classifier and as a feature\nextraction module for a GMM and a SVM classifier. Results show the validity of\nthis approach, achieving less than 0.5\\% EER for known attacks. \n\n"}
{"id": "1508.01755", "contents": "Title: Stochastic Language Generation in Dialogue using Recurrent Neural\n  Networks with Convolutional Sentence Reranking Abstract: The natural language generation (NLG) component of a spoken dialogue system\n(SDS) usually needs a substantial amount of handcrafting or a well-labeled\ndataset to be trained on. These limitations add significantly to development\ncosts and make cross-domain, multi-lingual dialogue systems intractable.\nMoreover, human languages are context-aware. The most natural response should\nbe directly learned from data rather than depending on predefined syntaxes or\nrules. This paper presents a statistical language generator based on a joint\nrecurrent and convolutional neural network structure which can be trained on\ndialogue act-utterance pairs without any semantic alignments or predefined\ngrammar trees. Objective metrics suggest that this new model outperforms\nprevious methods under the same experimental conditions. Results of an\nevaluation by human judges indicate that it produces not only high quality but\nlinguistically varied utterances which are preferred compared to n-gram and\nrule-based systems. \n\n"}
{"id": "1508.03170", "contents": "Title: Generation of Multimedia Artifacts: An Extractive Summarization-based\n  Approach Abstract: We explore methods for content selection and address the issue of coherence\nin the context of the generation of multimedia artifacts. We use audio and\nvideo to present two case studies: generation of film tributes, and\nlecture-driven science talks. For content selection, we use centrality-based\nand diversity-based summarization, along with topic analysis. To establish\ncoherence, we use the emotional content of music, for film tributes, and ensure\ntopic similarity between lectures and documentaries, for science talks.\nComposition techniques for the production of multimedia artifacts are addressed\nas a means of organizing content, in order to improve coherence. We discuss our\nresults considering the above aspects. \n\n"}
{"id": "1508.04271", "contents": "Title: Probabilistic Modelling of Morphologically Rich Languages Abstract: This thesis investigates how the sub-structure of words can be accounted for\nin probabilistic models of language. Such models play an important role in\nnatural language processing tasks such as translation or speech recognition,\nbut often rely on the simplistic assumption that words are opaque symbols. This\nassumption does not fit morphologically complex language well, where words can\nhave rich internal structure and sub-word elements are shared across distinct\nword forms.\n  Our approach is to encode basic notions of morphology into the assumptions of\nthree different types of language models, with the intention that leveraging\nshared sub-word structure can improve model performance and help overcome data\nsparsity that arises from morphological processes.\n  In the context of n-gram language modelling, we formulate a new Bayesian\nmodel that relies on the decomposition of compound words to attain better\nsmoothing, and we develop a new distributed language model that learns vector\nrepresentations of morphemes and leverages them to link together\nmorphologically related words. In both cases, we show that accounting for word\nsub-structure improves the models' intrinsic performance and provides benefits\nwhen applied to other tasks, including machine translation.\n  We then shift the focus beyond the modelling of word sequences and consider\nmodels that automatically learn what the sub-word elements of a given language\nare, given an unannotated list of words. We formulate a novel model that can\nlearn discontiguous morphemes in addition to the more conventional contiguous\nmorphemes that most previous models are limited to. This approach is\ndemonstrated on Semitic languages, and we find that modelling discontiguous\nsub-word structures leads to improvements in the task of segmenting words into\ntheir contiguous morphemes. \n\n"}
{"id": "1508.05326", "contents": "Title: A large annotated corpus for learning natural language inference Abstract: Understanding entailment and contradiction is fundamental to understanding\nnatural language, and inference about entailment and contradiction is a\nvaluable testing ground for the development of semantic representations.\nHowever, machine learning research in this area has been dramatically limited\nby the lack of large-scale resources. To address this, we introduce the\nStanford Natural Language Inference corpus, a new, freely available collection\nof labeled sentence pairs, written by humans doing a novel grounded task based\non image captioning. At 570K pairs, it is two orders of magnitude larger than\nall other resources of its type. This increase in scale allows lexicalized\nclassifiers to outperform some sophisticated existing entailment models, and it\nallows a neural network-based model to perform competitively on natural\nlanguage inference benchmarks for the first time. \n\n"}
{"id": "1508.05508", "contents": "Title: Towards Neural Network-based Reasoning Abstract: We propose Neural Reasoner, a framework for neural network-based reasoning\nover natural language sentences. Given a question, Neural Reasoner can infer\nover multiple supporting facts and find an answer to the question in specific\nforms. Neural Reasoner has 1) a specific interaction-pooling mechanism,\nallowing it to examine multiple facts, and 2) a deep architecture, allowing it\nto model the complicated logical relations in reasoning tasks. Assuming no\nparticular structure exists in the question and facts, Neural Reasoner is able\nto accommodate different types of reasoning and different forms of language\nexpressions. Despite the model complexity, Neural Reasoner can still be trained\neffectively in an end-to-end manner. Our empirical studies show that Neural\nReasoner can outperform existing neural reasoning systems with remarkable\nmargins on two difficult artificial tasks (Positional Reasoning and Path\nFinding) proposed in [8]. For example, it improves the accuracy on Path\nFinding(10K) from 33.4% [6] to over 98%. \n\n"}
{"id": "1508.05565", "contents": "Title: Necessary and Sufficient Conditions and a Provably Efficient Algorithm\n  for Separable Topic Discovery Abstract: We develop necessary and sufficient conditions and a novel provably\nconsistent and efficient algorithm for discovering topics (latent factors) from\nobservations (documents) that are realized from a probabilistic mixture of\nshared latent factors that have certain properties. Our focus is on the class\nof topic models in which each shared latent factor contains a novel word that\nis unique to that factor, a property that has come to be known as separability.\nOur algorithm is based on the key insight that the novel words correspond to\nthe extreme points of the convex hull formed by the row-vectors of a suitably\nnormalized word co-occurrence matrix. We leverage this geometric insight to\nestablish polynomial computation and sample complexity bounds based on a few\nisotropic random projections of the rows of the normalized word co-occurrence\nmatrix. Our proposed random-projections-based algorithm is naturally amenable\nto an efficient distributed implementation and is attractive for modern\nweb-scale distributed data mining applications. \n\n"}
{"id": "1508.07909", "contents": "Title: Neural Machine Translation of Rare Words with Subword Units Abstract: Neural machine translation (NMT) models typically operate with a fixed\nvocabulary, but translation is an open-vocabulary problem. Previous work\naddresses the translation of out-of-vocabulary words by backing off to a\ndictionary. In this paper, we introduce a simpler and more effective approach,\nmaking the NMT model capable of open-vocabulary translation by encoding rare\nand unknown words as sequences of subword units. This is based on the intuition\nthat various word classes are translatable via smaller units than words, for\ninstance names (via character copying or transliteration), compounds (via\ncompositional translation), and cognates and loanwords (via phonological and\nmorphological transformations). We discuss the suitability of different word\nsegmentation techniques, including simple character n-gram models and a\nsegmentation based on the byte pair encoding compression algorithm, and\nempirically show that subword models improve over a back-off dictionary\nbaseline for the WMT 15 translation tasks English-German and English-Russian by\n1.1 and 1.3 BLEU, respectively. \n\n"}
{"id": "1509.01626", "contents": "Title: Character-level Convolutional Networks for Text Classification Abstract: This article offers an empirical exploration on the use of character-level\nconvolutional networks (ConvNets) for text classification. We constructed\nseveral large-scale datasets to show that character-level convolutional\nnetworks could achieve state-of-the-art or competitive results. Comparisons are\noffered against traditional models such as bag of words, n-grams and their\nTFIDF variants, and deep learning models such as word-based ConvNets and\nrecurrent neural networks. \n\n"}
{"id": "1509.06664", "contents": "Title: Reasoning about Entailment with Neural Attention Abstract: While most approaches to automatically recognizing entailment relations have\nused classifiers employing hand engineered features derived from complex\nnatural language processing pipelines, in practice their performance has been\nonly slightly better than bag-of-word pair classifiers using only lexical\nsimilarity. The only attempt so far to build an end-to-end differentiable\nneural network for entailment failed to outperform such a simple similarity\nclassifier. In this paper, we propose a neural model that reads two sentences\nto determine entailment using long short-term memory units. We extend this\nmodel with a word-by-word neural attention mechanism that encourages reasoning\nover entailments of pairs of words and phrases. Furthermore, we present a\nqualitative analysis of attention weights produced by this model, demonstrating\nsuch reasoning capabilities. On a large entailment dataset this model\noutperforms the previous best neural model and a classifier with engineered\nfeatures by a substantial margin. It is the first generic end-to-end\ndifferentiable system that achieves state-of-the-art accuracy on a textual\nentailment dataset. \n\n"}
{"id": "1510.00726", "contents": "Title: A Primer on Neural Network Models for Natural Language Processing Abstract: Over the past few years, neural networks have re-emerged as powerful\nmachine-learning models, yielding state-of-the-art results in fields such as\nimage recognition and speech processing. More recently, neural network models\nstarted to be applied also to textual natural language signals, again with very\npromising results. This tutorial surveys neural network models from the\nperspective of natural language processing research, in an attempt to bring\nnatural-language researchers up to speed with the neural techniques. The\ntutorial covers input encoding for natural language tasks, feed-forward\nnetworks, convolutional networks, recurrent networks and recursive networks, as\nwell as the computation graph abstraction for automatic gradient computation. \n\n"}
{"id": "1510.00726", "contents": "Title: A Primer on Neural Network Models for Natural Language Processing Abstract: Over the past few years, neural networks have re-emerged as powerful\nmachine-learning models, yielding state-of-the-art results in fields such as\nimage recognition and speech processing. More recently, neural network models\nstarted to be applied also to textual natural language signals, again with very\npromising results. This tutorial surveys neural network models from the\nperspective of natural language processing research, in an attempt to bring\nnatural-language researchers up to speed with the neural techniques. The\ntutorial covers input encoding for natural language tasks, feed-forward\nnetworks, convolutional networks, recurrent networks and recursive networks, as\nwell as the computation graph abstraction for automatic gradient computation. \n\n"}
{"id": "1510.03753", "contents": "Title: Improved Deep Learning Baselines for Ubuntu Corpus Dialogs Abstract: This paper presents results of our experiments for the next utterance ranking\non the Ubuntu Dialog Corpus -- the largest publicly available multi-turn dialog\ncorpus. First, we use an in-house implementation of previously reported models\nto do an independent evaluation using the same data. Second, we evaluate the\nperformances of various LSTMs, Bi-LSTMs and CNNs on the dataset. Third, we\ncreate an ensemble by averaging predictions of multiple models. The ensemble\nfurther improves the performance and it achieves a state-of-the-art result for\nthe next utterance ranking on this dataset. Finally, we discuss our future\nplans using this corpus. \n\n"}
{"id": "1510.07586", "contents": "Title: Parser for Abstract Meaning Representation using Learning to Search Abstract: We develop a novel technique to parse English sentences into Abstract Meaning\nRepresentation (AMR) using SEARN, a Learning to Search approach, by modeling\nthe concept and the relation learning in a unified framework. We evaluate our\nparser on multiple datasets from varied domains and show an absolute\nimprovement of 2% to 6% over the state-of-the-art. Additionally we show that\nusing the most frequent concept gives us a baseline that is stronger than the\nstate-of-the-art for concept prediction. We plan to release our parser for\npublic use. \n\n"}
{"id": "1511.02274", "contents": "Title: Stacked Attention Networks for Image Question Answering Abstract: This paper presents stacked attention networks (SANs) that learn to answer\nnatural language questions from images. SANs use semantic representation of a\nquestion as query to search for the regions in an image that are related to the\nanswer. We argue that image question answering (QA) often requires multiple\nsteps of reasoning. Thus, we develop a multiple-layer SAN in which we query an\nimage multiple times to infer the answer progressively. Experiments conducted\non four image QA data sets demonstrate that the proposed SANs significantly\noutperform previous state-of-the-art approaches. The visualization of the\nattention layers illustrates the progress that the SAN locates the relevant\nvisual clues that lead to the answer of the question layer-by-layer. \n\n"}
{"id": "1511.02301", "contents": "Title: The Goldilocks Principle: Reading Children's Books with Explicit Memory\n  Representations Abstract: We introduce a new test of how well language models capture meaning in\nchildren's books. Unlike standard language modelling benchmarks, it\ndistinguishes the task of predicting syntactic function words from that of\npredicting lower-frequency words, which carry greater semantic content. We\ncompare a range of state-of-the-art models, each with a different way of\nencoding what has been previously read. We show that models which store\nexplicit representations of long-term contexts outperform state-of-the-art\nneural language models at predicting semantic content words, although this\nadvantage is not observed for syntactic function words. Interestingly, we find\nthat the amount of text encoded in a single memory representation is highly\ninfluential to the performance: there is a sweet-spot, not too big and not too\nsmall, between single words and full sentences that allows the most meaningful\ninformation in a text to be effectively retained and recalled. Further, the\nattention over such window-based memories can be trained effectively through\nself-supervision. We then assess the generality of this principle by applying\nit to the CNN QA benchmark, which involves identifying named entities in\nparaphrased summaries of news articles, and achieve state-of-the-art\nperformance. \n\n"}
{"id": "1511.03745", "contents": "Title: Grounding of Textual Phrases in Images by Reconstruction Abstract: Grounding (i.e. localizing) arbitrary, free-form textual phrases in visual\ncontent is a challenging problem with many applications for human-computer\ninteraction and image-text reference resolution. Few datasets provide the\nground truth spatial localization of phrases, thus it is desirable to learn\nfrom data with no or little grounding supervision. We propose a novel approach\nwhich learns grounding by reconstructing a given phrase using an attention\nmechanism, which can be either latent or optimized directly. During training\nour approach encodes the phrase using a recurrent network language model and\nthen learns to attend to the relevant image region in order to reconstruct the\ninput phrase. At test time, the correct attention, i.e., the grounding, is\nevaluated. If grounding supervision is available it can be directly applied via\na loss over the attention mechanism. We demonstrate the effectiveness of our\napproach on the Flickr 30k Entities and ReferItGame datasets with different\nlevels of supervision, ranging from no supervision over partial supervision to\nfull supervision. Our supervised variant improves by a large margin over the\nstate-of-the-art on both datasets. \n\n"}
{"id": "1511.06018", "contents": "Title: Segmental Recurrent Neural Networks Abstract: We introduce segmental recurrent neural networks (SRNNs) which define, given\nan input sequence, a joint probability distribution over segmentations of the\ninput and labelings of the segments. Representations of the input segments\n(i.e., contiguous subsequences of the input) are computed by encoding their\nconstituent tokens using bidirectional recurrent neural nets, and these\n\"segment embeddings\" are used to define compatibility scores with output\nlabels. These local compatibility scores are integrated using a global\nsemi-Markov conditional random field. Both fully supervised training -- in\nwhich segment boundaries and labels are observed -- as well as partially\nsupervised training -- in which segment boundaries are latent -- are\nstraightforward. Experiments on handwriting recognition and joint Chinese word\nsegmentation/POS tagging show that, compared to models that do not explicitly\nrepresent segments such as BIO tagging schemes and connectionist temporal\nclassification (CTC), SRNNs obtain substantially higher accuracies. \n\n"}
{"id": "1511.06038", "contents": "Title: Neural Variational Inference for Text Processing Abstract: Recent advances in neural variational inference have spawned a renaissance in\ndeep latent variable models. In this paper we introduce a generic variational\ninference framework for generative and conditional models of text. While\ntraditional variational methods derive an analytic approximation for the\nintractable distributions over latent variables, here we construct an inference\nnetwork conditioned on the discrete text input to provide the variational\ndistribution. We validate this framework on two very different text modelling\napplications, generative document modelling and supervised question answering.\nOur neural variational document model combines a continuous stochastic document\nrepresentation with a bag-of-words generative model and achieves the lowest\nreported perplexities on two standard test corpora. The neural answer selection\nmodel employs a stochastic representation layer within an attention mechanism\nto extract the semantics between a question and answer pair. On two question\nanswering benchmarks this model exceeds all previous published benchmarks. \n\n"}
{"id": "1511.06066", "contents": "Title: Transfer Learning for Speech and Language Processing Abstract: Transfer learning is a vital technique that generalizes models trained for\none setting or task to other settings or tasks. For example in speech\nrecognition, an acoustic model trained for one language can be used to\nrecognize speech in another language, with little or no re-training data.\nTransfer learning is closely related to multi-task learning (cross-lingual vs.\nmultilingual), and is traditionally studied in the name of `model adaptation'.\nRecent advance in deep learning shows that transfer learning becomes much\neasier and more effective with high-level abstract features learned by deep\nmodels, and the `transfer' can be conducted not only between data distributions\nand data types, but also between model structures (e.g., shallow nets and deep\nnets) or even model types (e.g., Bayesian models and neural models). This\nreview paper summarizes some recent prominent research towards this direction,\nparticularly for speech and language processing. We also report some results\nfrom our group and highlight the potential of this very interesting research\nfield. \n\n"}
{"id": "1511.06219", "contents": "Title: Knowledge Base Population using Semantic Label Propagation Abstract: A crucial aspect of a knowledge base population system that extracts new\nfacts from text corpora, is the generation of training data for its relation\nextractors. In this paper, we present a method that maximizes the effectiveness\nof newly trained relation extractors at a minimal annotation cost. Manual\nlabeling can be significantly reduced by Distant Supervision, which is a method\nto construct training data automatically by aligning a large text corpus with\nan existing knowledge base of known facts. For example, all sentences\nmentioning both 'Barack Obama' and 'US' may serve as positive training\ninstances for the relation born_in(subject,object). However, distant\nsupervision typically results in a highly noisy training set: many training\nsentences do not really express the intended relation. We propose to combine\ndistant supervision with minimal manual supervision in a technique called\nfeature labeling, to eliminate noise from the large and noisy initial training\nset, resulting in a significant increase of precision. We further improve on\nthis approach by introducing the Semantic Label Propagation method, which uses\nthe similarity between low-dimensional representations of candidate training\ninstances, to extend the training set in order to increase recall while\nmaintaining high precision. Our proposed strategy for generating training data\nis studied and evaluated on an established test collection designed for\nknowledge base population tasks. The experimental results show that the\nSemantic Label Propagation strategy leads to substantial performance gains when\ncompared to existing approaches, while requiring an almost negligible manual\nannotation effort. \n\n"}
{"id": "1511.06379", "contents": "Title: Dynamic Adaptive Network Intelligence Abstract: Accurate representational learning of both the explicit and implicit\nrelationships within data is critical to the ability of machines to perform\nmore complex and abstract reasoning tasks. We describe the efficient weakly\nsupervised learning of such inferences by our Dynamic Adaptive Network\nIntelligence (DANI) model. We report state-of-the-art results for DANI over\nquestion answering tasks in the bAbI dataset that have proved difficult for\ncontemporary approaches to learning representation (Weston et al., 2015). \n\n"}
{"id": "1511.06909", "contents": "Title: BlackOut: Speeding up Recurrent Neural Network Language Models With Very\n  Large Vocabularies Abstract: We propose BlackOut, an approximation algorithm to efficiently train massive\nrecurrent neural network language models (RNNLMs) with million word\nvocabularies. BlackOut is motivated by using a discriminative loss, and we\ndescribe a new sampling strategy which significantly reduces computation while\nimproving stability, sample efficiency, and rate of convergence. One way to\nunderstand BlackOut is to view it as an extension of the DropOut strategy to\nthe output layer, wherein we use a discriminative training loss and a weighted\nsampling scheme. We also establish close connections between BlackOut,\nimportance sampling, and noise contrastive estimation (NCE). Our experiments,\non the recently released one billion word language modeling benchmark,\ndemonstrate scalability and accuracy of BlackOut; we outperform the\nstate-of-the art, and achieve the lowest perplexity scores on this dataset.\nMoreover, unlike other established methods which typically require GPUs or CPU\nclusters, we show that a carefully implemented version of BlackOut requires\nonly 1-10 days on a single machine to train a RNNLM with a million word\nvocabulary and billions of parameters on one billion words. Although we\ndescribe BlackOut in the context of RNNLM training, it can be used to any\nnetworks with large softmax output layers. \n\n"}
{"id": "1511.06931", "contents": "Title: Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems Abstract: A long-term goal of machine learning is to build intelligent conversational\nagents. One recent popular approach is to train end-to-end models on a large\namount of real dialog transcripts between humans (Sordoni et al., 2015; Vinyals\n& Le, 2015; Shang et al., 2015). However, this approach leaves many questions\nunanswered as an understanding of the precise successes and shortcomings of\neach model is hard to assess. A contrasting recent proposal are the bAbI tasks\n(Weston et al., 2015b) which are synthetic data that measure the ability of\nlearning machines at various reasoning tasks over toy language. Unfortunately,\nthose tests are very small and hence may encourage methods that do not scale.\nIn this work, we propose a suite of new tasks of a much larger scale that\nattempt to bridge the gap between the two regimes. Choosing the domain of\nmovies, we provide tasks that test the ability of models to answer factual\nquestions (utilizing OMDB), provide personalization (utilizing MovieLens),\ncarry short conversations about the two, and finally to perform on natural\ndialogs from Reddit. We provide a dataset covering 75k movie entities and with\n3.5M training examples. We present results of various models on these tasks,\nand evaluate their performance. \n\n"}
{"id": "1511.08130", "contents": "Title: A Roadmap towards Machine Intelligence Abstract: The development of intelligent machines is one of the biggest unsolved\nchallenges in computer science. In this paper, we propose some fundamental\nproperties these machines should have, focusing in particular on communication\nand learning. We discuss a simple environment that could be used to\nincrementally teach a machine the basics of natural-language-based\ncommunication, as a prerequisite to more complex interaction with human users.\nWe also present some conjectures on the sort of algorithms the machine should\nsupport in order to profitably learn from the environment. \n\n"}
{"id": "1511.08198", "contents": "Title: Towards Universal Paraphrastic Sentence Embeddings Abstract: We consider the problem of learning general-purpose, paraphrastic sentence\nembeddings based on supervision from the Paraphrase Database (Ganitkevitch et\nal., 2013). We compare six compositional architectures, evaluating them on\nannotated textual similarity datasets drawn both from the same distribution as\nthe training data and from a wide range of other domains. We find that the most\ncomplex architectures, such as long short-term memory (LSTM) recurrent neural\nnetworks, perform best on the in-domain data. However, in out-of-domain\nscenarios, simple architectures such as word averaging vastly outperform LSTMs.\nOur simplest averaging model is even competitive with systems tuned for the\nparticular tasks while also being extremely efficient and easy to use.\n  In order to better understand how these architectures compare, we conduct\nfurther experiments on three supervised NLP tasks: sentence similarity,\nentailment, and sentiment classification. We again find that the word averaging\nmodels perform well for sentence similarity and entailment, outperforming\nLSTMs. However, on sentiment classification, we find that the LSTM performs\nvery strongly-even recording new state-of-the-art performance on the Stanford\nSentiment Treebank.\n  We then demonstrate how to combine our pretrained sentence embeddings with\nthese supervised tasks, using them both as a prior and as a black box feature\nextractor. This leads to performance rivaling the state of the art on the SICK\nsimilarity and entailment tasks. We release all of our resources to the\nresearch community with the hope that they can serve as the new baseline for\nfurther work on universal sentence embeddings. \n\n"}
{"id": "1511.08277", "contents": "Title: A Deep Architecture for Semantic Matching with Multiple Positional\n  Sentence Representations Abstract: Matching natural language sentences is central for many applications such as\ninformation retrieval and question answering. Existing deep models rely on a\nsingle sentence representation or multiple granularity representations for\nmatching. However, such methods cannot well capture the contextualized local\ninformation in the matching process. To tackle this problem, we present a new\ndeep architecture to match two sentences with multiple positional sentence\nrepresentations. Specifically, each positional sentence representation is a\nsentence representation at this position, generated by a bidirectional long\nshort term memory (Bi-LSTM). The matching score is finally produced by\naggregating interactions between these different positional sentence\nrepresentations, through $k$-Max pooling and a multi-layer perceptron. Our\nmodel has several advantages: (1) By using Bi-LSTM, rich context of the whole\nsentence is leveraged to capture the contextualized local information in each\npositional sentence representation; (2) By matching with multiple positional\nsentence representations, it is flexible to aggregate different important\ncontextualized local information in a sentence to support the matching; (3)\nExperiments on different tasks such as question answering and sentence\ncompletion demonstrate the superiority of our model. \n\n"}
{"id": "1512.00818", "contents": "Title: Zero-Shot Event Detection by Multimodal Distributional Semantic\n  Embedding of Videos Abstract: We propose a new zero-shot Event Detection method by Multi-modal\nDistributional Semantic embedding of videos. Our model embeds object and action\nconcepts as well as other available modalities from videos into a\ndistributional semantic space. To our knowledge, this is the first Zero-Shot\nevent detection model that is built on top of distributional semantics and\nextends it in the following directions: (a) semantic embedding of multimodal\ninformation in videos (with focus on the visual modalities), (b) automatically\ndetermining relevance of concepts/attributes to a free text query, which could\nbe useful for other applications, and (c) retrieving videos by free text event\nquery (e.g., \"changing a vehicle tire\") based on their content. We embed videos\ninto a distributional semantic space and then measure the similarity between\nvideos and the event query in a free text form. We validated our method on the\nlarge TRECVID MED (Multimedia Event Detection) challenge. Using only the event\ntitle as a query, our method outperformed the state-of-the-art that uses big\ndescriptions from 12.6% to 13.5% with MAP metric and 0.73 to 0.83 with ROC-AUC\nmetric. It is also an order of magnitude faster. \n\n"}
{"id": "1512.03465", "contents": "Title: Mined Semantic Analysis: A New Concept Space Model for Semantic\n  Representation of Textual Data Abstract: Mined Semantic Analysis (MSA) is a novel concept space model which employs\nunsupervised learning to generate semantic representations of text. MSA\nrepresents textual structures (terms, phrases, documents) as a Bag of Concepts\n(BoC) where concepts are derived from concept rich encyclopedic corpora.\nTraditional concept space models exploit only target corpus content to\nconstruct the concept space. MSA, alternatively, uncovers implicit relations\nbetween concepts by mining for their associations (e.g., mining Wikipedia's\n\"See also\" link graph). We evaluate MSA's performance on benchmark datasets for\nmeasuring semantic relatedness of words and sentences. Empirical results show\ncompetitive performance of MSA compared to prior state-of-the-art methods.\nAdditionally, we introduce the first analytical study to examine statistical\nsignificance of results reported by different semantic relatedness methods. Our\nstudy shows that, the nuances of results across top performing methods could be\nstatistically insignificant. The study positions MSA as one of state-of-the-art\nmethods for measuring semantic relatedness, besides the inherent\ninterpretability and simplicity of the generated semantic representation. \n\n"}
{"id": "1512.04280", "contents": "Title: Small-footprint Deep Neural Networks with Highway Connections for Speech\n  Recognition Abstract: For speech recognition, deep neural networks (DNNs) have significantly\nimproved the recognition accuracy in most of benchmark datasets and application\ndomains. However, compared to the conventional Gaussian mixture models,\nDNN-based acoustic models usually have much larger number of model parameters,\nmaking it challenging for their applications in resource constrained platforms,\ne.g., mobile devices. In this paper, we study the application of the recently\nproposed highway network to train small-footprint DNNs, which are {\\it thinner}\nand {\\it deeper}, and have significantly smaller number of model parameters\ncompared to conventional DNNs. We investigated this approach on the AMI meeting\nspeech transcription corpus which has around 70 hours of audio data. The\nhighway neural networks constantly outperformed their plain DNN counterparts,\nand the number of model parameters can be reduced significantly without\nsacrificing the recognition accuracy. \n\n"}
{"id": "1512.04906", "contents": "Title: Strategies for Training Large Vocabulary Neural Language Models Abstract: Training neural network language models over large vocabularies is still\ncomputationally very costly compared to count-based models such as Kneser-Ney.\nAt the same time, neural language models are gaining popularity for many\napplications such as speech recognition and machine translation whose success\ndepends on scalability. We present a systematic comparison of strategies to\nrepresent and train large vocabularies, including softmax, hierarchical\nsoftmax, target sampling, noise contrastive estimation and self normalization.\nWe further extend self normalization to be a proper estimator of likelihood and\nintroduce an efficient variant of softmax. We evaluate each method on three\npopular benchmarks, examining performance on rare words, the speed/accuracy\ntrade-off and complementarity to Kneser-Ney. \n\n"}
{"id": "1512.05193", "contents": "Title: ABCNN: Attention-Based Convolutional Neural Network for Modeling\n  Sentence Pairs Abstract: How to model a pair of sentences is a critical issue in many NLP tasks such\nas answer selection (AS), paraphrase identification (PI) and textual entailment\n(TE). Most prior work (i) deals with one individual task by fine-tuning a\nspecific system; (ii) models each sentence's representation separately, rarely\nconsidering the impact of the other sentence; or (iii) relies fully on manually\ndesigned, task-specific linguistic features. This work presents a general\nAttention Based Convolutional Neural Network (ABCNN) for modeling a pair of\nsentences. We make three contributions. (i) ABCNN can be applied to a wide\nvariety of tasks that require modeling of sentence pairs. (ii) We propose three\nattention schemes that integrate mutual influence between sentences into CNN;\nthus, the representation of each sentence takes into consideration its\ncounterpart. These interdependent sentence pair representations are more\npowerful than isolated sentence representations. (iii) ABCNN achieves\nstate-of-the-art performance on AS, PI and TE tasks. \n\n"}
{"id": "1512.05742", "contents": "Title: A Survey of Available Corpora for Building Data-Driven Dialogue Systems Abstract: During the past decade, several areas of speech and language understanding\nhave witnessed substantial breakthroughs from the use of data-driven models. In\nthe area of dialogue systems, the trend is less obvious, and most practical\nsystems are still built through significant engineering and expert knowledge.\nNevertheless, several recent results suggest that data-driven approaches are\nfeasible and quite promising. To facilitate research in this area, we have\ncarried out a wide survey of publicly available datasets suitable for\ndata-driven learning of dialogue systems. We discuss important characteristics\nof these datasets, how they can be used to learn diverse dialogue strategies,\nand their other potential uses. We also examine methods for transfer learning\nbetween datasets and the use of external knowledge. Finally, we discuss\nappropriate choice of evaluation metrics for the learning objective. \n\n"}
{"id": "1512.08422", "contents": "Title: Natural Language Inference by Tree-Based Convolution and Heuristic\n  Matching Abstract: In this paper, we propose the TBCNN-pair model to recognize entailment and\ncontradiction between two sentences. In our model, a tree-based convolutional\nneural network (TBCNN) captures sentence-level semantics; then heuristic\nmatching layers like concatenation, element-wise product/difference combine the\ninformation in individual sentences. Experimental results show that our model\noutperforms existing sentence encoding-based approaches by a large margin. \n\n"}
{"id": "1601.00770", "contents": "Title: End-to-End Relation Extraction using LSTMs on Sequences and Tree\n  Structures Abstract: We present a novel end-to-end neural model to extract entities and relations\nbetween them. Our recurrent neural network based model captures both word\nsequence and dependency tree substructure information by stacking bidirectional\ntree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows\nour model to jointly represent both entities and relations with shared\nparameters in a single model. We further encourage detection of entities during\ntraining and use of entity information in relation extraction via entity\npretraining and scheduled sampling. Our model improves over the\nstate-of-the-art feature-based model on end-to-end relation extraction,\nachieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and\nACE2004, respectively. We also show that our LSTM-RNN based model compares\nfavorably to the state-of-the-art CNN based model (in F1-score) on nominal\nrelation classification (SemEval-2010 Task 8). Finally, we present an extensive\nablation analysis of several model components. \n\n"}
{"id": "1601.00893", "contents": "Title: The Role of Context Types and Dimensionality in Learning Word Embeddings Abstract: We provide the first extensive evaluation of how using different types of\ncontext to learn skip-gram word embeddings affects performance on a wide range\nof intrinsic and extrinsic NLP tasks. Our results suggest that while intrinsic\ntasks tend to exhibit a clear preference to particular types of contexts and\nhigher dimensionality, more careful tuning is required for finding the optimal\nsettings for most of the extrinsic tasks that we considered. Furthermore, for\nthese extrinsic tasks, we find that once the benefit from increasing the\nembedding dimensionality is mostly exhausted, simple concatenation of word\nembeddings, learned with different context types, can yield further performance\ngains. As an additional contribution, we propose a new variant of the skip-gram\nmodel that learns word embeddings from weighted contexts of substitute words. \n\n"}
{"id": "1601.00901", "contents": "Title: Joint learning of ontology and semantic parser from text Abstract: Semantic parsing methods are used for capturing and representing semantic\nmeaning of text. Meaning representation capturing all the concepts in the text\nmay not always be available or may not be sufficiently complete. Ontologies\nprovide a structured and reasoning-capable way to model the content of a\ncollection of texts. In this work, we present a novel approach to joint\nlearning of ontology and semantic parser from text. The method is based on\nsemi-automatic induction of a context-free grammar from semantically annotated\ntext. The grammar parses the text into semantic trees. Both, the grammar and\nthe semantic trees are used to learn the ontology on several levels -- classes,\ninstances, taxonomic and non-taxonomic relations. The approach was evaluated on\nthe first sentences of Wikipedia pages describing people. \n\n"}
{"id": "1601.02502", "contents": "Title: Trans-gram, Fast Cross-lingual Word-embeddings Abstract: We introduce Trans-gram, a simple and computationally-efficient method to\nsimultaneously learn and align wordembeddings for a variety of languages, using\nonly monolingual data and a smaller set of sentence-aligned data. We use our\nnew method to compute aligned wordembeddings for twenty-one languages using\nEnglish as a pivot language. We show that some linguistic features are aligned\nacross languages for which we do not have aligned data, even though those\nproperties do not exist in the pivot language. We also achieve state of the art\nresults on standard cross-lingual text classification and word translation\ntasks. \n\n"}
{"id": "1601.02828", "contents": "Title: Learning Hidden Unit Contributions for Unsupervised Acoustic Model\n  Adaptation Abstract: This work presents a broad study on the adaptation of neural network acoustic\nmodels by means of learning hidden unit contributions (LHUC) -- a method that\nlinearly re-combines hidden units in a speaker- or environment-dependent manner\nusing small amounts of unsupervised adaptation data. We also extend LHUC to a\nspeaker adaptive training (SAT) framework that leads to a more adaptable DNN\nacoustic model, working both in a speaker-dependent and a speaker-independent\nmanner, without the requirements to maintain auxiliary speaker-dependent\nfeature extractors or to introduce significant speaker-dependent changes to the\nDNN structure. Through a series of experiments on four different speech\nrecognition benchmarks (TED talks, Switchboard, AMI meetings, and Aurora4)\ncomprising 270 test speakers, we show that LHUC in both its test-only and SAT\nvariants results in consistent word error rate reductions ranging from 5% to\n23% relative depending on the task and the degree of mismatch between training\nand test data. In addition, we have investigated the effect of the amount of\nadaptation data per speaker, the quality of unsupervised adaptation targets,\nthe complementarity to other adaptation techniques, one-shot adaptation, and an\nextension to adapting DNNs trained in a sequence discriminative manner. \n\n"}
{"id": "1601.05936", "contents": "Title: Exploiting Low-dimensional Structures to Enhance DNN Based Acoustic\n  Modeling in Speech Recognition Abstract: We propose to model the acoustic space of deep neural network (DNN)\nclass-conditional posterior probabilities as a union of low-dimensional\nsubspaces. To that end, the training posteriors are used for dictionary\nlearning and sparse coding. Sparse representation of the test posteriors using\nthis dictionary enables projection to the space of training data. Relying on\nthe fact that the intrinsic dimensions of the posterior subspaces are indeed\nvery small and the matrix of all posteriors belonging to a class has a very low\nrank, we demonstrate how low-dimensional structures enable further enhancement\nof the posteriors and rectify the spurious errors due to mismatch conditions.\nThe enhanced acoustic modeling method leads to improvements in continuous\nspeech recognition task using hybrid DNN-HMM (hidden Markov model) framework in\nboth clean and noisy conditions, where upto 15.4% relative reduction in word\nerror rate (WER) is achieved. \n\n"}
{"id": "1601.06579", "contents": "Title: A Kernel Independence Test for Geographical Language Variation Abstract: Quantifying the degree of spatial dependence for linguistic variables is a\nkey task for analyzing dialectal variation. However, existing approaches have\nimportant drawbacks. First, they are based on parametric models of dependence,\nwhich limits their power in cases where the underlying parametric assumptions\nare violated. Second, they are not applicable to all types of linguistic data:\nsome approaches apply only to frequencies, others to boolean indicators of\nwhether a linguistic variable is present. We present a new method for measuring\ngeographical language variation, which solves both of these problems. Our\napproach builds on Reproducing Kernel Hilbert space (RKHS) representations for\nnonparametric statistics, and takes the form of a test statistic that is\ncomputed from pairs of individual geotagged observations without aggregation\ninto predefined geographical bins. We compare this test with prior work using\nsynthetic data as well as a diverse set of real datasets: a corpus of Dutch\ntweets, a Dutch syntactic atlas, and a dataset of letters to the editor in\nNorth American newspapers. Our proposed test is shown to support robust\ninferences across a broad range of scenarios and types of data. \n\n"}
{"id": "1601.06581", "contents": "Title: Character-Level Incremental Speech Recognition with Recurrent Neural\n  Networks Abstract: In real-time speech recognition applications, the latency is an important\nissue. We have developed a character-level incremental speech recognition (ISR)\nsystem that responds quickly even during the speech, where the hypotheses are\ngradually improved while the speaking proceeds. The algorithm employs a\nspeech-to-character unidirectional recurrent neural network (RNN), which is\nend-to-end trained with connectionist temporal classification (CTC), and an\nRNN-based character-level language model (LM). The output values of the\nCTC-trained RNN are character-level probabilities, which are processed by beam\nsearch decoding. The RNN LM augments the decoding by providing long-term\ndependency information. We propose tree-based online beam search with\nadditional depth-pruning, which enables the system to process infinitely long\ninput speech with low latency. This system not only responds quickly on speech\nbut also can dictate out-of-vocabulary (OOV) words according to pronunciation.\nThe proposed model achieves the word error rate (WER) of 8.90% on the Wall\nStreet Journal (WSJ) Nov'92 20K evaluation set when trained on the WSJ SI-284\ntraining set. \n\n"}
{"id": "1602.01137", "contents": "Title: A Dual Embedding Space Model for Document Ranking Abstract: A fundamental goal of search engines is to identify, given a query, documents\nthat have relevant text. This is intrinsically difficult because the query and\nthe document may use different vocabulary, or the document may contain query\nwords without being relevant. We investigate neural word embeddings as a source\nof evidence in document ranking. We train a word2vec embedding model on a large\nunlabelled query corpus, but in contrast to how the model is commonly used, we\nretain both the input and the output projections, allowing us to leverage both\nthe embedding spaces to derive richer distributional relationships. During\nranking we map the query words into the input space and the document words into\nthe output space, and compute a query-document relevance score by aggregating\nthe cosine similarities across all the query-document word pairs.\n  We postulate that the proposed Dual Embedding Space Model (DESM) captures\nevidence on whether a document is about a query term in addition to what is\nmodelled by traditional term-frequency based approaches. Our experiments show\nthat the DESM can re-rank top documents returned by a commercial Web search\nengine, like Bing, better than a term-matching based signal like TF-IDF.\nHowever, when ranking a larger set of candidate documents, we find the\nembeddings-based approach is prone to false positives, retrieving documents\nthat are only loosely related to the query. We demonstrate that this problem\ncan be solved effectively by ranking based on a linear mixture of the DESM and\nthe word counting features. \n\n"}
{"id": "1602.02215", "contents": "Title: Swivel: Improving Embeddings by Noticing What's Missing Abstract: We present Submatrix-wise Vector Embedding Learner (Swivel), a method for\ngenerating low-dimensional feature embeddings from a feature co-occurrence\nmatrix. Swivel performs approximate factorization of the point-wise mutual\ninformation matrix via stochastic gradient descent. It uses a piecewise loss\nwith special handling for unobserved co-occurrences, and thus makes use of all\nthe information in the matrix. While this requires computation proportional to\nthe size of the entire matrix, we make use of vectorized multiplication to\nprocess thousands of rows and columns at once to compute millions of predicted\nvalues. Furthermore, we partition the matrix into shards in order to\nparallelize the computation across many nodes. This approach results in more\naccurate embeddings than can be achieved with methods that consider only\nobserved co-occurrences, and can scale to much larger corpora than can be\nhandled with sampling methods. \n\n"}
{"id": "1602.03483", "contents": "Title: Learning Distributed Representations of Sentences from Unlabelled Data Abstract: Unsupervised methods for learning distributed representations of words are\nubiquitous in today's NLP research, but far less is known about the best ways\nto learn distributed phrase or sentence representations from unlabelled data.\nThis paper is a systematic comparison of models that learn such\nrepresentations. We find that the optimal approach depends critically on the\nintended application. Deeper, more complex models are preferable for\nrepresentations to be used in supervised systems, but shallow log-linear models\nwork best for building representation spaces that can be decoded with simple\nspatial distance metrics. We also propose two new unsupervised\nrepresentation-learning objectives designed to optimise the trade-off between\ntraining time, domain portability and performance. \n\n"}
{"id": "1602.03483", "contents": "Title: Learning Distributed Representations of Sentences from Unlabelled Data Abstract: Unsupervised methods for learning distributed representations of words are\nubiquitous in today's NLP research, but far less is known about the best ways\nto learn distributed phrase or sentence representations from unlabelled data.\nThis paper is a systematic comparison of models that learn such\nrepresentations. We find that the optimal approach depends critically on the\nintended application. Deeper, more complex models are preferable for\nrepresentations to be used in supervised systems, but shallow log-linear models\nwork best for building representation spaces that can be decoded with simple\nspatial distance metrics. We also propose two new unsupervised\nrepresentation-learning objectives designed to optimise the trade-off between\ntraining time, domain portability and performance. \n\n"}
{"id": "1602.04874", "contents": "Title: Bi-directional LSTM Recurrent Neural Network for Chinese Word\n  Segmentation Abstract: Recurrent neural network(RNN) has been broadly applied to natural language\nprocessing(NLP) problems. This kind of neural network is designed for modeling\nsequential data and has been testified to be quite efficient in sequential\ntagging tasks. In this paper, we propose to use bi-directional RNN with long\nshort-term memory(LSTM) units for Chinese word segmentation, which is a crucial\npreprocess task for modeling Chinese sentences and articles. Classical methods\nfocus on designing and combining hand-craft features from context, whereas\nbi-directional LSTM network(BLSTM) does not need any prior knowledge or\npre-designing, and it is expert in keeping the contextual information in both\ndirections. Experiment result shows that our approach gets state-of-the-art\nperformance in word segmentation on both traditional Chinese datasets and\nsimplified Chinese datasets. \n\n"}
{"id": "1602.06064", "contents": "Title: On Training Bi-directional Neural Network Language Model with Noise\n  Contrastive Estimation Abstract: We propose to train bi-directional neural network language model(NNLM) with\nnoise contrastive estimation(NCE). Experiments are conducted on a rescore task\non the PTB data set. It is shown that NCE-trained bi-directional NNLM\noutperformed the one trained by conventional maximum likelihood training. But\nstill(regretfully), it did not out-perform the baseline uni-directional NNLM. \n\n"}
{"id": "1602.06979", "contents": "Title: Empath: Understanding Topic Signals in Large-Scale Text Abstract: Human language is colored by a broad range of topics, but existing text\nanalysis tools only focus on a small number of them. We present Empath, a tool\nthat can generate and validate new lexical categories on demand from a small\nset of seed terms (like \"bleed\" and \"punch\" to generate the category violence).\nEmpath draws connotations between words and phrases by deep learning a neural\nembedding across more than 1.8 billion words of modern fiction. Given a small\nset of seed words that characterize a category, Empath uses its neural\nembedding to discover new related terms, then validates the category with a\ncrowd-powered filter. Empath also analyzes text across 200 built-in,\npre-validated categories we have generated from common topics in our web\ndataset, like neglect, government, and social media. We show that Empath's\ndata-driven, human validated categories are highly correlated (r=0.906) with\nsimilar categories in LIWC. \n\n"}
{"id": "1602.07776", "contents": "Title: Recurrent Neural Network Grammars Abstract: We introduce recurrent neural network grammars, probabilistic models of\nsentences with explicit phrase structure. We explain efficient inference\nprocedures that allow application to both parsing and language modeling.\nExperiments show that they provide better parsing in English than any single\npreviously published supervised generative model and better language modeling\nthan state-of-the-art sequential RNNs in English and Chinese. \n\n"}
{"id": "1603.00223", "contents": "Title: Segmental Recurrent Neural Networks for End-to-end Speech Recognition Abstract: We study the segmental recurrent neural network for end-to-end acoustic\nmodelling. This model connects the segmental conditional random field (CRF)\nwith a recurrent neural network (RNN) used for feature extraction. Compared to\nmost previous CRF-based acoustic models, it does not rely on an external system\nto provide features or segmentation boundaries. Instead, this model\nmarginalises out all the possible segmentations, and features are extracted\nfrom the RNN trained together with the segmental CRF. In essence, this model is\nself-contained and can be trained end-to-end. In this paper, we discuss\npractical training and decoding issues as well as the method to speed up the\ntraining in the context of speech recognition. We performed experiments on the\nTIMIT dataset. We achieved 17.3 phone error rate (PER) from the first-pass\ndecoding --- the best reported result using CRFs, despite the fact that we only\nused a zeroth-order CRF and without using any language model. \n\n"}
{"id": "1603.01354", "contents": "Title: End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF Abstract: State-of-the-art sequence labeling systems traditionally require large\namounts of task-specific knowledge in the form of hand-crafted features and\ndata pre-processing. In this paper, we introduce a novel neutral network\narchitecture that benefits from both word- and character-level representations\nautomatically, by using combination of bidirectional LSTM, CNN and CRF. Our\nsystem is truly end-to-end, requiring no feature engineering or data\npre-processing, thus making it applicable to a wide range of sequence labeling\ntasks. We evaluate our system on two data sets for two sequence labeling tasks\n--- Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003\ncorpus for named entity recognition (NER). We obtain state-of-the-art\nperformance on both the two data --- 97.55\\% accuracy for POS tagging and\n91.21\\% F1 for NER. \n\n"}
{"id": "1603.01360", "contents": "Title: Neural Architectures for Named Entity Recognition Abstract: State-of-the-art named entity recognition systems rely heavily on\nhand-crafted features and domain-specific knowledge in order to learn\neffectively from the small, supervised training corpora that are available. In\nthis paper, we introduce two new neural architectures---one based on\nbidirectional LSTMs and conditional random fields, and the other that\nconstructs and labels segments using a transition-based approach inspired by\nshift-reduce parsers. Our models rely on two sources of information about\nwords: character-based word representations learned from the supervised corpus\nand unsupervised word representations learned from unannotated corpora. Our\nmodels obtain state-of-the-art performance in NER in four languages without\nresorting to any language-specific knowledge or resources such as gazetteers. \n\n"}
{"id": "1603.01913", "contents": "Title: A Latent Variable Recurrent Neural Network for Discourse Relation\n  Language Models Abstract: This paper presents a novel latent variable recurrent neural network\narchitecture for jointly modeling sequences of words and (possibly latent)\ndiscourse relations between adjacent sentences. A recurrent neural network\ngenerates individual words, thus reaping the benefits of\ndiscriminatively-trained vector representations. The discourse relations are\nrepresented with a latent variable, which can be predicted or marginalized,\ndepending on the task. The resulting model can therefore employ a training\nobjective that includes not only discourse relation classification, but also\nword prediction. As a result, it outperforms state-of-the-art alternatives for\ntwo tasks: implicit discourse relation classification in the Penn Discourse\nTreebank, and dialog act classification in the Switchboard corpus. Furthermore,\nby marginalizing over latent discourse relations at test time, we obtain a\ndiscourse informed language model, which improves over a strong LSTM baseline. \n\n"}
{"id": "1603.03784", "contents": "Title: Towards using social media to identify individuals at risk for\n  preventable chronic illness Abstract: We describe a strategy for the acquisition of training data necessary to\nbuild a social-media-driven early detection system for individuals at risk for\n(preventable) type 2 diabetes mellitus (T2DM). The strategy uses a game-like\nquiz with data and questions acquired semi-automatically from Twitter. The\nquestions are designed to inspire participant engagement and collect relevant\ndata to train a public-health model applied to individuals. Prior systems\ndesigned to use social media such as Twitter to predict obesity (a risk factor\nfor T2DM) operate on entire communities such as states, counties, or cities,\nbased on statistics gathered by government agencies. Because there is\nconsiderable variation among individuals within these groups, training data on\nthe individual level would be more effective, but this data is difficult to\nacquire. The approach proposed here aims to address this issue. Our strategy\nhas two steps. First, we trained a random forest classifier on data gathered\nfrom (public) Twitter statuses and state-level statistics with state-of-the-art\naccuracy. We then converted this classifier into a 20-questions-style quiz and\nmade it available online. In doing so, we achieved high engagement with\nindividuals that took the quiz, while also building a training set of\nvoluntarily supplied individual-level data for future classification. \n\n"}
{"id": "1603.03827", "contents": "Title: Sequential Short-Text Classification with Recurrent and Convolutional\n  Neural Networks Abstract: Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for short-text classification. However, many short texts\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\nand most existing ANN-based systems do not leverage the preceding short texts\nwhen classifying a subsequent one. In this work, we present a model based on\nrecurrent neural networks and convolutional neural networks that incorporates\nthe preceding short texts. Our model achieves state-of-the-art results on three\ndifferent datasets for dialog act prediction. \n\n"}
{"id": "1603.03876", "contents": "Title: Variational Neural Discourse Relation Recognizer Abstract: Implicit discourse relation recognition is a crucial component for automatic\ndiscourselevel analysis and nature language understanding. Previous studies\nexploit discriminative models that are built on either powerful manual features\nor deep discourse representations. In this paper, instead, we explore\ngenerative models and propose a variational neural discourse relation\nrecognizer. We refer to this model as VarNDRR. VarNDRR establishes a directed\nprobabilistic model with a latent continuous variable that generates both a\ndiscourse and the relation between the two arguments of the discourse. In order\nto perform efficient inference and learning, we introduce neural discourse\nrelation models to approximate the prior and posterior distributions of the\nlatent variable, and employ these approximated distributions to optimize a\nreparameterized variational lower bound. This allows VarNDRR to be trained with\nstandard stochastic gradient methods. Experiments on the benchmark data set\nshow that VarNDRR can achieve comparable results against stateof- the-art\nbaselines without using any manual features. \n\n"}
{"id": "1603.05570", "contents": "Title: Predicate Gradual Logic and Linguistics Abstract: There are several major proposals for treating donkey anaphora such as\ndiscourse representation theory and the likes, or E-Type theories and the\nlikes. Every one of them works well for a set of specific examples that they\nuse to demonstrate validity of their approaches. As I show in this paper,\nhowever, they are not very generalisable and do not account for essentially the\nsame problem that they remedy when it manifests in other examples. I propose\nanother logical approach. I develoop logic that extends a recent, propositional\ngradual logic, and show that it can treat donkey anaphora generally. I also\nidentify and address a problem around the modern convention on existential\nimport. Furthermore, I show that Aristotle's syllogisms and conversion are\nrealisable in this logic. \n\n"}
{"id": "1603.05962", "contents": "Title: Document Neural Autoregressive Distribution Estimation Abstract: We present an approach based on feed-forward neural networks for learning the\ndistribution of textual documents. This approach is inspired by the Neural\nAutoregressive Distribution Estimator(NADE) model, which has been shown to be a\ngood estimator of the distribution of discrete-valued igh-dimensional vectors.\nIn this paper, we present how NADE can successfully be adapted to the case of\ntextual data, retaining from NADE the property that sampling or computing the\nprobability of observations can be done exactly and efficiently. The approach\ncan also be used to learn deep representations of documents that are\ncompetitive to those learned by the alternative topic modeling approaches.\nFinally, we describe how the approach can be combined with a regular neural\nnetwork N-gram model and substantially improve its performance, by making its\nlearned representation sensitive to the larger, document-specific context. \n\n"}
{"id": "1603.06270", "contents": "Title: Multi-Task Cross-Lingual Sequence Tagging from Scratch Abstract: We present a deep hierarchical recurrent neural network for sequence tagging.\nGiven a sequence of words, our model employs deep gated recurrent units on both\ncharacter and word levels to encode morphology and context information, and\napplies a conditional random field layer to predict the tags. Our model is task\nindependent, language independent, and feature engineering free. We further\nextend our model to multi-task and cross-lingual joint training by sharing the\narchitecture and parameters. Our model achieves state-of-the-art results in\nmultiple languages on several benchmark tasks including POS tagging, chunking,\nand NER. We also demonstrate that multi-task and cross-lingual joint training\ncan improve the performance in various cases. \n\n"}
{"id": "1603.06270", "contents": "Title: Multi-Task Cross-Lingual Sequence Tagging from Scratch Abstract: We present a deep hierarchical recurrent neural network for sequence tagging.\nGiven a sequence of words, our model employs deep gated recurrent units on both\ncharacter and word levels to encode morphology and context information, and\napplies a conditional random field layer to predict the tags. Our model is task\nindependent, language independent, and feature engineering free. We further\nextend our model to multi-task and cross-lingual joint training by sharing the\narchitecture and parameters. Our model achieves state-of-the-art results in\nmultiple languages on several benchmark tasks including POS tagging, chunking,\nand NER. We also demonstrate that multi-task and cross-lingual joint training\ncan improve the performance in various cases. \n\n"}
{"id": "1603.07603", "contents": "Title: Semantic Regularities in Document Representations Abstract: Recent work exhibited that distributed word representations are good at\ncapturing linguistic regularities in language. This allows vector-oriented\nreasoning based on simple linear algebra between words. Since many different\nmethods have been proposed for learning document representations, it is natural\nto ask whether there is also linear structure in these learned representations\nto allow similar reasoning at document level. To answer this question, we\ndesign a new document analogy task for testing the semantic regularities in\ndocument representations, and conduct empirical evaluations over several\nstate-of-the-art document representation models. The results reveal that neural\nembedding based document representations work better on this analogy task than\nconventional methods, and we provide some preliminary explanations over these\nobservations. \n\n"}
{"id": "1603.08042", "contents": "Title: On the Compression of Recurrent Neural Networks with an Application to\n  LVCSR acoustic modeling for Embedded Speech Recognition Abstract: We study the problem of compressing recurrent neural networks (RNNs). In\nparticular, we focus on the compression of RNN acoustic models, which are\nmotivated by the goal of building compact and accurate speech recognition\nsystems which can be run efficiently on mobile devices. In this work, we\npresent a technique for general recurrent model compression that jointly\ncompresses both recurrent and non-recurrent inter-layer weight matrices. We\nfind that the proposed technique allows us to reduce the size of our Long\nShort-Term Memory (LSTM) acoustic model to a third of its original size with\nnegligible loss in accuracy. \n\n"}
{"id": "1603.08148", "contents": "Title: Pointing the Unknown Words Abstract: The problem of rare and unknown words is an important issue that can\npotentially influence the performance of many NLP systems, including both the\ntraditional count-based and the deep learning models. We propose a novel way to\ndeal with the rare and unseen words for the neural network models using\nattention. Our model uses two softmax layers in order to predict the next word\nin conditional language models: one predicts the location of a word in the\nsource sentence, and the other predicts a word in the shortlist vocabulary. At\neach time-step, the decision of which softmax layer to use choose adaptively\nmade by an MLP which is conditioned on the context.~We motivate our work from a\npsychological evidence that humans naturally have a tendency to point towards\nobjects in the context or the environment when the name of an object is not\nknown.~We observe improvements on two tasks, neural machine translation on the\nEuroparl English to French parallel corpora and text summarization on the\nGigaword dataset using our proposed model. \n\n"}
{"id": "1603.09381", "contents": "Title: Clinical Information Extraction via Convolutional Neural Network Abstract: We report an implementation of a clinical information extraction tool that\nleverages deep neural network to annotate event spans and their attributes from\nraw clinical notes and pathology reports. Our approach uses context words and\ntheir part-of-speech tags and shape information as features. Then we hire\ntemporal (1D) convolutional neural network to learn hidden feature\nrepresentations. Finally, we use Multilayer Perceptron (MLP) to predict event\nspans. The empirical evaluation demonstrates that our approach significantly\noutperforms baselines. \n\n"}
{"id": "1603.09405", "contents": "Title: Enhancing Sentence Relation Modeling with Auxiliary Character-level\n  Embedding Abstract: Neural network based approaches for sentence relation modeling automatically\ngenerate hidden matching features from raw sentence pairs. However, the quality\nof matching feature representation may not be satisfied due to complex semantic\nrelations such as entailment or contradiction. To address this challenge, we\npropose a new deep neural network architecture that jointly leverage\npre-trained word embedding and auxiliary character embedding to learn sentence\nmeanings. The two kinds of word sequence representations as inputs into\nmulti-layer bidirectional LSTM to learn enhanced sentence representation. After\nthat, we construct matching features followed by another temporal CNN to learn\nhigh-level hidden matching feature representations. Experimental results\ndemonstrate that our approach consistently outperforms the existing methods on\nstandard evaluation datasets. \n\n"}
{"id": "1603.09509", "contents": "Title: Learning Multiscale Features Directly From Waveforms Abstract: Deep learning has dramatically improved the performance of speech recognition\nsystems through learning hierarchies of features optimized for the task at\nhand. However, true end-to-end learning, where features are learned directly\nfrom waveforms, has only recently reached the performance of hand-tailored\nrepresentations based on the Fourier transform. In this paper, we detail an\napproach to use convolutional filters to push past the inherent tradeoff of\ntemporal and frequency resolution that exists for spectral representations. At\nincreased computational cost, we show that increasing temporal resolution via\nreduced stride and increasing frequency resolution via additional filters\ndelivers significant performance improvements. Further, we find more efficient\nrepresentations by simultaneously learning at multiple scales, leading to an\noverall decrease in word error rate on a difficult internal speech test set by\n20.7% relative to networks with the same number of parameters trained on\nspectrograms. \n\n"}
{"id": "1603.09631", "contents": "Title: Data Collection for Interactive Learning through the Dialog Abstract: This paper presents a dataset collected from natural dialogs which enables to\ntest the ability of dialog systems to learn new facts from user utterances\nthroughout the dialog. This interactive learning will help with one of the most\nprevailing problems of open domain dialog system, which is the sparsity of\nfacts a dialog system can reason about. The proposed dataset, consisting of\n1900 collected dialogs, allows simulation of an interactive gaining of\ndenotations and questions explanations from users which can be used for the\ninteractive learning. \n\n"}
{"id": "1603.09643", "contents": "Title: Multi-task Recurrent Model for Speech and Speaker Recognition Abstract: Although highly correlated, speech and speaker recognition have been regarded\nas two independent tasks and studied by two communities. This is certainly not\nthe way that people behave: we decipher both speech content and speaker traits\nat the same time. This paper presents a unified model to perform speech and\nspeaker recognition simultaneously and altogether. The model is based on a\nunified neural network where the output of one task is fed to the input of the\nother, leading to a multi-task recurrent network. Experiments show that the\njoint model outperforms the task-specific models on both the two tasks. \n\n"}
{"id": "1603.09727", "contents": "Title: Neural Language Correction with Character-Based Attention Abstract: Natural language correction has the potential to help language learners\nimprove their writing skills. While approaches with separate classifiers for\ndifferent error types have high precision, they do not flexibly handle errors\nsuch as redundancy or non-idiomatic phrasing. On the other hand, word and\nphrase-based machine translation methods are not designed to cope with\northographic errors, and have recently been outpaced by neural models.\nMotivated by these issues, we present a neural network-based approach to\nlanguage correction. The core component of our method is an encoder-decoder\nrecurrent neural network with an attention mechanism. By operating at the\ncharacter level, the network avoids the problem of out-of-vocabulary words. We\nillustrate the flexibility of our approach on dataset of noisy, user-generated\ntext collected from an English learner forum. When combined with a language\nmodel, our method achieves a state-of-the-art $F_{0.5}$-score on the CoNLL 2014\nShared Task. We further demonstrate that training the network on additional\ndata with synthesized errors can improve performance. \n\n"}
{"id": "1604.01792", "contents": "Title: Advances in Very Deep Convolutional Neural Networks for LVCSR Abstract: Very deep CNNs with small 3x3 kernels have recently been shown to achieve\nvery strong performance as acoustic models in hybrid NN-HMM speech recognition\nsystems. In this paper we investigate how to efficiently scale these models to\nlarger datasets. Specifically, we address the design choice of pooling and\npadding along the time dimension which renders convolutional evaluation of\nsequences highly inefficient. We propose a new CNN design without timepadding\nand without timepooling, which is slightly suboptimal for accuracy, but has two\nsignificant advantages: it enables sequence training and deployment by allowing\nefficient convolutional evaluation of full utterances, and, it allows for batch\nnormalization to be straightforwardly adopted to CNNs on sequence data. Through\nbatch normalization, we recover the lost peformance from removing the\ntime-pooling, while keeping the benefit of efficient convolutional evaluation.\nWe demonstrate the performance of our models both on larger scale data than\nbefore, and after sequence training. Our very deep CNN model sequence trained\non the 2000h switchboard dataset obtains 9.4 word error rate on the Hub5\ntest-set, matching with a single model the performance of the 2015 IBM system\ncombination, which was the previous best published result. \n\n"}
{"id": "1604.01904", "contents": "Title: Neural Headline Generation with Sentence-wise Optimization Abstract: Recently, neural models have been proposed for headline generation by\nlearning to map documents to headlines with recurrent neural networks.\nNevertheless, as traditional neural network utilizes maximum likelihood\nestimation for parameter optimization, it essentially constrains the expected\ntraining objective within word level rather than sentence level. Moreover, the\nperformance of model prediction significantly relies on training data\ndistribution. To overcome these drawbacks, we employ minimum risk training\nstrategy in this paper, which directly optimizes model parameters in sentence\nlevel with respect to evaluation metrics and leads to significant improvements\nfor headline generation. Experiment results show that our models outperforms\nstate-of-the-art systems on both English and Chinese headline generation tasks. \n\n"}
{"id": "1604.02038", "contents": "Title: Sentence Level Recurrent Topic Model: Letting Topics Speak for\n  Themselves Abstract: We propose Sentence Level Recurrent Topic Model (SLRTM), a new topic model\nthat assumes the generation of each word within a sentence to depend on both\nthe topic of the sentence and the whole history of its preceding words in the\nsentence. Different from conventional topic models that largely ignore the\nsequential order of words or their topic coherence, SLRTM gives full\ncharacterization to them by using a Recurrent Neural Networks (RNN) based\nframework. Experimental results have shown that SLRTM outperforms several\nstrong baselines on various tasks. Furthermore, SLRTM can automatically\ngenerate sentences given a topic (i.e., topics to sentences), which is a key\ntechnology for real world applications such as personalized short text\nconversation. \n\n"}
{"id": "1604.02125", "contents": "Title: Resolving Language and Vision Ambiguities Together: Joint Segmentation &\n  Prepositional Attachment Resolution in Captioned Scenes Abstract: We present an approach to simultaneously perform semantic segmentation and\nprepositional phrase attachment resolution for captioned images. Some\nambiguities in language cannot be resolved without simultaneously reasoning\nabout an associated image. If we consider the sentence \"I shot an elephant in\nmy pajamas\", looking at language alone (and not using common sense), it is\nunclear if it is the person or the elephant wearing the pajamas or both. Our\napproach produces a diverse set of plausible hypotheses for both semantic\nsegmentation and prepositional phrase attachment resolution that are then\njointly reranked to select the most consistent pair. We show that our semantic\nsegmentation and prepositional phrase attachment resolution modules have\ncomplementary strengths, and that joint reasoning produces more accurate\nresults than any module operating in isolation. Multiple hypotheses are also\nshown to be crucial to improved multiple-module reasoning. Our vision and\nlanguage approach significantly outperforms the Stanford Parser (De Marneffe et\nal., 2006) by 17.91% (28.69% relative) and 12.83% (25.28% relative) in two\ndifferent experiments. We also make small improvements over DeepLab-CRF (Chen\net al., 2015). \n\n"}
{"id": "1604.03035", "contents": "Title: Learning Global Features for Coreference Resolution Abstract: There is compelling evidence that coreference prediction would benefit from\nmodeling global information about entity-clusters. Yet, state-of-the-art\nperformance can be achieved with systems treating each mention prediction\nindependently, which we attribute to the inherent difficulty of crafting\ninformative cluster-level features. We instead propose to use recurrent neural\nnetworks (RNNs) to learn latent, global representations of entity clusters\ndirectly from their mentions. We show that such representations are especially\nuseful for the prediction of pronominal mentions, and can be incorporated into\nan end-to-end coreference system that outperforms the state of the art without\nrequiring any additional search. \n\n"}
{"id": "1604.03390", "contents": "Title: Video Description using Bidirectional Recurrent Neural Networks Abstract: Although traditionally used in the machine translation field, the\nencoder-decoder framework has been recently applied for the generation of video\nand image descriptions. The combination of Convolutional and Recurrent Neural\nNetworks in these models has proven to outperform the previous state of the\nart, obtaining more accurate video descriptions. In this work we propose\npushing further this model by introducing two contributions into the encoding\nstage. First, producing richer image representations by combining object and\nlocation information from Convolutional Neural Networks and second, introducing\nBidirectional Recurrent Neural Networks for capturing both forward and backward\ntemporal relationships in the input frames. \n\n"}
{"id": "1604.04661", "contents": "Title: Parallelizing Word2Vec in Shared and Distributed Memory Abstract: Word2Vec is a widely used algorithm for extracting low-dimensional vector\nrepresentations of words. It generated considerable excitement in the machine\nlearning and natural language processing (NLP) communities recently due to its\nexceptional performance in many NLP applications such as named entity\nrecognition, sentiment analysis, machine translation and question answering.\nState-of-the-art algorithms including those by Mikolov et al. have been\nparallelized for multi-core CPU architectures but are based on vector-vector\noperations that are memory-bandwidth intensive and do not efficiently use\ncomputational resources. In this paper, we improve reuse of various data\nstructures in the algorithm through the use of minibatching, hence allowing us\nto express the problem using matrix multiply operations. We also explore\ndifferent techniques to distribute word2vec computation across nodes in a\ncompute cluster, and demonstrate good strong scalability up to 32 nodes. In\ncombination, these techniques allow us to scale up the computation near\nlinearly across cores and nodes, and process hundreds of millions of words per\nsecond, which is the fastest word2vec implementation to the best of our\nknowledge. \n\n"}
{"id": "1604.04835", "contents": "Title: SSP: Semantic Space Projection for Knowledge Graph Embedding with Text\n  Descriptions Abstract: Knowledge representation is an important, long-history topic in AI, and there\nhave been a large amount of work for knowledge graph embedding which projects\nsymbolic entities and relations into low-dimensional, real-valued vector space.\nHowever, most embedding methods merely concentrate on data fitting and ignore\nthe explicit semantic expression, leading to uninterpretable representations.\nThus, traditional embedding methods have limited potentials for many\napplications such as question answering, and entity classification. To this\nend, this paper proposes a semantic representation method for knowledge graph\n\\textbf{(KSR)}, which imposes a two-level hierarchical generative process that\nglobally extracts many aspects and then locally assigns a specific category in\neach aspect for every triple. Since both aspects and categories are\nsemantics-relevant, the collection of categories in each aspect is treated as\nthe semantic representation of this triple. Extensive experiments justify our\nmodel outperforms other state-of-the-art baselines substantially. \n\n"}
{"id": "1604.05525", "contents": "Title: An Attentive Neural Architecture for Fine-grained Entity Type\n  Classification Abstract: In this work we propose a novel attention-based neural network model for the\ntask of fine-grained entity type classification that unlike previously proposed\nmodels recursively composes representations of entity mention contexts. Our\nmodel achieves state-of-the-art performance with 74.94% loose micro F1-score on\nthe well-established FIGER dataset, a relative improvement of 2.59%. We also\ninvestigate the behavior of the attention mechanism of our model and observe\nthat it can learn contextual linguistic expressions that indicate the\nfine-grained category memberships of an entity. \n\n"}
{"id": "1604.06045", "contents": "Title: Dialog-based Language Learning Abstract: A long-term goal of machine learning research is to build an intelligent\ndialog agent. Most research in natural language understanding has focused on\nlearning from fixed training sets of labeled data, with supervision either at\nthe word level (tagging, parsing tasks) or sentence level (question answering,\nmachine translation). This kind of supervision is not realistic of how humans\nlearn, where language is both learned by, and used for, communication. In this\nwork, we study dialog-based language learning, where supervision is given\nnaturally and implicitly in the response of the dialog partner during the\nconversation. We study this setup in two domains: the bAbI dataset of (Weston\net al., 2015) and large-scale question answering from (Dodge et al., 2015). We\nevaluate a set of baseline learning strategies on these tasks, and show that a\nnovel model incorporating predictive lookahead is a promising approach for\nlearning from a teacher's response. In particular, a surprising result is that\nit can learn to answer questions correctly without any reward-based supervision\nat all. \n\n"}
{"id": "1604.06529", "contents": "Title: Dependency Parsing with LSTMs: An Empirical Evaluation Abstract: We propose a transition-based dependency parser using Recurrent Neural\nNetworks with Long Short-Term Memory (LSTM) units. This extends the feedforward\nneural network parser of Chen and Manning (2014) and enables modelling of\nentire sequences of shift/reduce transition decisions. On the Google Web\nTreebank, our LSTM parser is competitive with the best feedforward parser on\noverall accuracy and notably achieves more than 3% improvement for long-range\ndependencies, which has proved difficult for previous transition-based parsers\ndue to error propagation and limited context information. Our findings\nadditionally suggest that dropout regularisation on the embedding layer is\ncrucial to improve the LSTM's generalisation. \n\n"}
{"id": "1605.00942", "contents": "Title: TheanoLM - An Extensible Toolkit for Neural Network Language Modeling Abstract: We present a new tool for training neural network language models (NNLMs),\nscoring sentences, and generating text. The tool has been written using Python\nlibrary Theano, which allows researcher to easily extend it and tune any aspect\nof the training process. Regardless of the flexibility, Theano is able to\ngenerate extremely fast native code that can utilize a GPU or multiple CPU\ncores in order to parallelize the heavy numerical computations. The tool has\nbeen evaluated in difficult Finnish and English conversational speech\nrecognition tasks, and significant improvement was obtained over our best\nback-off n-gram models. The results that we obtained in the Finnish task were\ncompared to those from existing RNNLM and RWTHLM toolkits, and found to be as\ngood or better, while training times were an order of magnitude shorter. \n\n"}
{"id": "1605.01919", "contents": "Title: User Reviews and Language: How Language Influences Ratings Abstract: The number of user reviews of tourist attractions, restaurants, mobile apps,\netc. is increasing for all languages; yet, research is lacking on how reviews\nin multiple languages should be aggregated and displayed. Speakers of different\nlanguages may have consistently different experiences, e.g., different\ninformation available in different languages at tourist attractions or\ndifferent user experiences with software due to\ninternationalization/localization choices. This paper assesses the similarity\nin the ratings given by speakers of different languages to London tourist\nattractions on TripAdvisor. The correlations between different languages are\ngenerally high, but some language pairs are more correlated than others. The\nresults question the common practice of computing average ratings from reviews\nin many languages. \n\n"}
{"id": "1605.03835", "contents": "Title: Noisy Parallel Approximate Decoding for Conditional Recurrent Language\n  Model Abstract: Recent advances in conditional recurrent language modelling have mainly\nfocused on network architectures (e.g., attention mechanism), learning\nalgorithms (e.g., scheduled sampling and sequence-level training) and novel\napplications (e.g., image/video description generation, speech recognition,\netc.) On the other hand, we notice that decoding algorithms/strategies have not\nbeen investigated as much, and it has become standard to use greedy or beam\nsearch. In this paper, we propose a novel decoding strategy motivated by an\nearlier observation that nonlinear hidden layers of a deep neural network\nstretch the data manifold. The proposed strategy is embarrassingly\nparallelizable without any communication overhead, while improving an existing\ndecoding algorithm. We extensively evaluate it with attention-based neural\nmachine translation on the task of En->Cz translation. \n\n"}
{"id": "1605.03956", "contents": "Title: On the Convergent Properties of Word Embedding Methods Abstract: Do word embeddings converge to learn similar things over different\ninitializations? How repeatable are experiments with word embeddings? Are all\nword embedding techniques equally reliable? In this paper we propose evaluating\nmethods for learning word representations by their consistency across\ninitializations. We propose a measure to quantify the similarity of the learned\nword representations under this setting (where they are subject to different\nrandom initializations). Our preliminary results illustrate that our metric not\nonly measures a intrinsic property of word embedding methods but also\ncorrelates well with other evaluation metrics on downstream tasks. We believe\nour methods are is useful in characterizing robustness -- an important property\nto consider when developing new word embedding methods. \n\n"}
{"id": "1605.04481", "contents": "Title: Anchoring and Agreement in Syntactic Annotations Abstract: We present a study on two key characteristics of human syntactic annotations:\nanchoring and agreement. Anchoring is a well known cognitive bias in human\ndecision making, where judgments are drawn towards pre-existing values. We\nstudy the influence of anchoring on a standard approach to creation of\nsyntactic resources where syntactic annotations are obtained via human editing\nof tagger and parser output. Our experiments demonstrate a clear anchoring\neffect and reveal unwanted consequences, including overestimation of parsing\nperformance and lower quality of annotations in comparison with human-based\nannotations. Using sentences from the Penn Treebank WSJ, we also report\nsystematically obtained inter-annotator agreement estimates for English\ndependency parsing. Our agreement results control for parser bias, and are\nconsequential in that they are on par with state of the art parsing performance\nfor English newswire. We discuss the impact of our findings on strategies for\nfuture annotation efforts and parser evaluations. \n\n"}
{"id": "1605.04800", "contents": "Title: Log-linear Combinations of Monolingual and Bilingual Neural Machine\n  Translation Models for Automatic Post-Editing Abstract: This paper describes the submission of the AMU (Adam Mickiewicz University)\nteam to the Automatic Post-Editing (APE) task of WMT 2016. We explore the\napplication of neural translation models to the APE problem and achieve good\nresults by treating different models as components in a log-linear model,\nallowing for multiple inputs (the MT-output and the source) that are decoded to\nthe same target language (post-edited translations). A simple string-matching\npenalty integrated within the log-linear model is used to control for higher\nfaithfulness with regard to the raw machine translation output. To overcome the\nproblem of too little training data, we generate large amounts of artificial\ndata. Our submission improves over the uncorrected baseline on the unseen test\nset by -3.2\\% TER and +5.5\\% BLEU and outperforms any other system submitted to\nthe shared-task by a large margin. \n\n"}
{"id": "1605.06778", "contents": "Title: openXBOW - Introducing the Passau Open-Source Crossmodal Bag-of-Words\n  Toolkit Abstract: We introduce openXBOW, an open-source toolkit for the generation of\nbag-of-words (BoW) representations from multimodal input. In the BoW principle,\nword histograms were first used as features in document classification, but the\nidea was and can easily be adapted to, e.g., acoustic or visual low-level\ndescriptors, introducing a prior step of vector quantisation. The openXBOW\ntoolkit supports arbitrary numeric input features and text input and\nconcatenates computed subbags to a final bag. It provides a variety of\nextensions and options. To our knowledge, openXBOW is the first publicly\navailable toolkit for the generation of crossmodal bags-of-words. The\ncapabilities of the tool are exemplified in two sample scenarios:\ntime-continuous speech-based emotion recognition and sentiment analysis in\ntweets where improved results over other feature representation forms were\nobserved. \n\n"}
{"id": "1605.07427", "contents": "Title: Hierarchical Memory Networks Abstract: Memory networks are neural networks with an explicit memory component that\ncan be both read and written to by the network. The memory is often addressed\nin a soft way using a softmax function, making end-to-end training with\nbackpropagation possible. However, this is not computationally scalable for\napplications which require the network to read from extremely large memories.\nOn the other hand, it is well known that hard attention mechanisms based on\nreinforcement learning are challenging to train successfully. In this paper, we\nexplore a form of hierarchical memory network, which can be considered as a\nhybrid between hard and soft attention memory networks. The memory is organized\nin a hierarchical structure such that reading from it is done with less\ncomputation than soft attention over a flat memory, while also being easier to\ntrain than hard attention over a flat memory. Specifically, we propose to\nincorporate Maximum Inner Product Search (MIPS) in the training and inference\nprocedures for our hierarchical memory network. We explore the use of various\nstate-of-the art approximate MIPS techniques and report results on\nSimpleQuestions, a challenging large scale factoid question answering task. \n\n"}
{"id": "1605.07669", "contents": "Title: On-line Active Reward Learning for Policy Optimisation in Spoken\n  Dialogue Systems Abstract: The ability to compute an accurate reward function is essential for\noptimising a dialogue policy via reinforcement learning. In real-world\napplications, using explicit user feedback as the reward signal is often\nunreliable and costly to collect. This problem can be mitigated if the user's\nintent is known in advance or data is available to pre-train a task success\npredictor off-line. In practice neither of these apply for most real world\napplications. Here we propose an on-line learning framework whereby the\ndialogue policy is jointly trained alongside the reward model via active\nlearning with a Gaussian process model. This Gaussian process operates on a\ncontinuous space dialogue representation generated in an unsupervised fashion\nusing a recurrent neural network encoder-decoder. The experimental results\ndemonstrate that the proposed framework is able to significantly reduce data\nannotation costs and mitigate noisy user feedback in dialogue policy learning. \n\n"}
{"id": "1605.07852", "contents": "Title: SS4MCT: A Statistical Stemmer for Morphologically Complex Texts Abstract: There have been multiple attempts to resolve various inflection matching\nproblems in information retrieval. Stemming is a common approach to this end.\nAmong many techniques for stemming, statistical stemming has been shown to be\neffective in a number of languages, particularly highly inflected languages. In\nthis paper we propose a method for finding affixes in different positions of a\nword. Common statistical techniques heavily rely on string similarity in terms\nof prefix and suffix matching. Since infixes are common in irregular/informal\ninflections in morphologically complex texts, it is required to find infixes\nfor stemming. In this paper we propose a method whose aim is to find\nstatistical inflectional rules based on minimum edit distance table of word\npairs and the likelihoods of the rules in a language. These rules are used to\nstatistically stem words and can be used in different text mining tasks.\nExperimental results on CLEF 2008 and CLEF 2009 English-Persian CLIR tasks\nindicate that the proposed method significantly outperforms all the baselines\nin terms of MAP. \n\n"}
{"id": "1605.07918", "contents": "Title: Automatic Open Knowledge Acquisition via Long Short-Term Memory Networks\n  with Feedback Negative Sampling Abstract: Previous studies in Open Information Extraction (Open IE) are mainly based on\nextraction patterns. They manually define patterns or automatically learn them\nfrom a large corpus. However, these approaches are limited when grasping the\ncontext of a sentence, and they fail to capture implicit relations. In this\npaper, we address this problem with the following methods. First, we exploit\nlong short-term memory (LSTM) networks to extract higher-level features along\nthe shortest dependency paths, connecting headwords of relations and arguments.\nThe path-level features from LSTM networks provide useful clues regarding\ncontextual information and the validity of arguments. Second, we constructed\nsamples to train LSTM networks without the need for manual labeling. In\nparticular, feedback negative sampling picks highly negative samples among\nnon-positive samples through a model trained with positive samples. The\nexperimental results show that our approach produces more precise and abundant\nextractions than state-of-the-art open IE systems. To the best of our\nknowledge, this is the first work to apply deep learning to Open IE. \n\n"}
{"id": "1605.09186", "contents": "Title: Does Multimodality Help Human and Machine for Translation and Image\n  Captioning? Abstract: This paper presents the systems developed by LIUM and CVC for the WMT16\nMultimodal Machine Translation challenge. We explored various comparative\nmethods, namely phrase-based systems and attentional recurrent neural networks\nmodels trained using monomodal or multimodal data. We also performed a human\nevaluation in order to estimate the usefulness of multimodal data for human\nmachine translation and image description generation. Our systems obtained the\nbest results for both tasks according to the automatic evaluation metrics BLEU\nand METEOR. \n\n"}
{"id": "1605.09211", "contents": "Title: Going Deeper for Multilingual Visual Sentiment Detection Abstract: This technical report details several improvements to the visual concept\ndetector banks built on images from the Multilingual Visual Sentiment Ontology\n(MVSO). The detector banks are trained to detect a total of 9,918\nsentiment-biased visual concepts from six major languages: English, Spanish,\nItalian, French, German and Chinese. In the original MVSO release,\nadjective-noun pair (ANP) detectors were trained for the six languages using an\nAlexNet-styled architecture by fine-tuning from DeepSentiBank. Here, through a\nmore extensive set of experiments, parameter tuning, and training runs, we\ndetail and release higher accuracy models for detecting ANPs across six\nlanguages from the same image pool and setting as in the original release using\na more modern architecture, GoogLeNet, providing comparable or better\nperformance with reduced network parameter cost.\n  In addition, since the image pool in MVSO can be corrupted by user noise from\nsocial interactions, we partitioned out a sub-corpus of MVSO images based on\ntag-restricted queries for higher fidelity labels. We show that as a result of\nthese higher fidelity labels, higher performing AlexNet-styled ANP detectors\ncan be trained using the tag-restricted image subset as compared to the models\nin full corpus. We release all these newly trained models for public research\nuse along with the list of tag-restricted images from the MVSO dataset. \n\n"}
{"id": "1605.09553", "contents": "Title: Attention Correctness in Neural Image Captioning Abstract: Attention mechanisms have recently been introduced in deep learning for\nvarious tasks in natural language processing and computer vision. But despite\ntheir popularity, the \"correctness\" of the implicitly-learned attention maps\nhas only been assessed qualitatively by visualization of several examples. In\nthis paper we focus on evaluating and improving the correctness of attention in\nneural image captioning models. Specifically, we propose a quantitative\nevaluation metric for the consistency between the generated attention maps and\nhuman annotations, using recently released datasets with alignment between\nregions in images and entities in captions. We then propose novel models with\ndifferent levels of explicit supervision for learning attention maps during\ntraining. The supervision can be strong when alignment between regions and\ncaption entities are available, or weak when only object segments and\ncategories are provided. We show on the popular Flickr30k and COCO datasets\nthat introducing supervision of attention maps during training solidly improves\nboth attention correctness and caption quality, showing the promise of making\nmachine perception more human-like. \n\n"}
{"id": "1606.01161", "contents": "Title: Exploiting Multi-typed Treebanks for Parsing with Deep Multi-task\n  Learning Abstract: Various treebanks have been released for dependency parsing. Despite that\ntreebanks may belong to different languages or have different annotation\nschemes, they contain syntactic knowledge that is potential to benefit each\nother. This paper presents an universal framework for exploiting these\nmulti-typed treebanks to improve parsing with deep multi-task learning. We\nconsider two kinds of treebanks as source: the multilingual universal treebanks\nand the monolingual heterogeneous treebanks. Multiple treebanks are trained\njointly and interacted with multi-level parameter sharing. Experiments on\nseveral benchmark datasets in various languages demonstrate that our approach\ncan make effective use of arbitrary source treebanks to improve target parsing\nmodels. \n\n"}
{"id": "1606.01549", "contents": "Title: Gated-Attention Readers for Text Comprehension Abstract: In this paper we study the problem of answering cloze-style questions over\ndocuments. Our model, the Gated-Attention (GA) Reader, integrates a multi-hop\narchitecture with a novel attention mechanism, which is based on multiplicative\ninteractions between the query embedding and the intermediate states of a\nrecurrent neural network document reader. This enables the reader to build\nquery-specific representations of tokens in the document for accurate answer\nselection. The GA Reader obtains state-of-the-art results on three benchmarks\nfor this task--the CNN \\& Daily Mail news stories and the Who Did What dataset.\nThe effectiveness of multiplicative interaction is demonstrated by an ablation\nstudy, and by comparing to alternative compositional operators for implementing\nthe gated-attention. The code is available at\nhttps://github.com/bdhingra/ga-reader. \n\n"}
{"id": "1606.01614", "contents": "Title: Adversarial Deep Averaging Networks for Cross-Lingual Sentiment\n  Classification Abstract: In recent years great success has been achieved in sentiment classification\nfor English, thanks in part to the availability of copious annotated resources.\nUnfortunately, most languages do not enjoy such an abundance of labeled data.\nTo tackle the sentiment classification problem in low-resource languages\nwithout adequate annotated data, we propose an Adversarial Deep Averaging\nNetwork (ADAN) to transfer the knowledge learned from labeled data on a\nresource-rich source language to low-resource languages where only unlabeled\ndata exists. ADAN has two discriminative branches: a sentiment classifier and\nan adversarial language discriminator. Both branches take input from a shared\nfeature extractor to learn hidden representations that are simultaneously\nindicative for the classification task and invariant across languages.\nExperiments on Chinese and Arabic sentiment classification demonstrate that\nADAN significantly outperforms state-of-the-art systems. \n\n"}
{"id": "1606.02012", "contents": "Title: Can neural machine translation do simultaneous translation? Abstract: We investigate the potential of attention-based neural machine translation in\nsimultaneous translation. We introduce a novel decoding algorithm, called\nsimultaneous greedy decoding, that allows an existing neural machine\ntranslation model to begin translating before a full source sentence is\nreceived. This approach is unique from previous works on simultaneous\ntranslation in that segmentation and translation are done jointly to maximize\nthe translation quality and that translating each segment is strongly\nconditioned on all the previous segments. This paper presents a first step\ntoward building a full simultaneous translation system based on neural machine\ntranslation. \n\n"}
{"id": "1606.02555", "contents": "Title: Improving Recurrent Neural Networks For Sequence Labelling Abstract: In this paper we study different types of Recurrent Neural Networks (RNN) for\nsequence labeling tasks. We propose two new variants of RNNs integrating\nimprovements for sequence labeling, and we compare them to the more traditional\nElman and Jordan RNNs. We compare all models, either traditional or new, on\nfour distinct tasks of sequence labeling: two on Spoken Language Understanding\n(ATIS and MEDIA); and two of POS tagging for the French Treebank (FTB) and the\nPenn Treebank (PTB) corpora. The results show that our new variants of RNNs are\nalways more effective than the others. \n\n"}
{"id": "1606.02560", "contents": "Title: Towards End-to-End Learning for Dialog State Tracking and Management\n  using Deep Reinforcement Learning Abstract: This paper presents an end-to-end framework for task-oriented dialog systems\nusing a variant of Deep Recurrent Q-Networks (DRQN). The model is able to\ninterface with a relational database and jointly learn policies for both\nlanguage understanding and dialog strategy. Moreover, we propose a hybrid\nalgorithm that combines the strength of reinforcement learning and supervised\nlearning to achieve faster learning speed. We evaluated the proposed model on a\n20 Question Game conversational game simulator. Results show that the proposed\nmethod outperforms the modular-based baseline and learns a distributed\nrepresentation of the latent dialog state. \n\n"}
{"id": "1606.02689", "contents": "Title: Continuously Learning Neural Dialogue Management Abstract: We describe a two-step approach for dialogue management in task-oriented\nspoken dialogue systems. A unified neural network framework is proposed to\nenable the system to first learn by supervision from a set of dialogue data and\nthen continuously improve its behaviour via reinforcement learning, all using\ngradient-based algorithms on one single model. The experiments demonstrate the\nsupervised model's effectiveness in the corpus-based evaluation, with user\nsimulation, and with paid human subjects. The use of reinforcement learning\nfurther improves the model's performance in both interactive settings,\nespecially under higher-noise conditions. \n\n"}
{"id": "1606.03777", "contents": "Title: Neural Belief Tracker: Data-Driven Dialogue State Tracking Abstract: One of the core components of modern spoken dialogue systems is the belief\ntracker, which estimates the user's goal at every step of the dialogue.\nHowever, most current approaches have difficulty scaling to larger, more\ncomplex dialogue domains. This is due to their dependency on either: a) Spoken\nLanguage Understanding models that require large amounts of annotated training\ndata; or b) hand-crafted lexicons for capturing some of the linguistic\nvariation in users' language. We propose a novel Neural Belief Tracking (NBT)\nframework which overcomes these problems by building on recent advances in\nrepresentation learning. NBT models reason over pre-trained word vectors,\nlearning to compose them into distributed representations of user utterances\nand dialogue context. Our evaluation on two datasets shows that this approach\nsurpasses past limitations, matching the performance of state-of-the-art models\nwhich rely on hand-crafted semantic lexicons and outperforming them when such\nlexicons are not provided. \n\n"}
{"id": "1606.03821", "contents": "Title: Learning to Generate Compositional Color Descriptions Abstract: The production of color language is essential for grounded language\ngeneration. Color descriptions have many challenging properties: they can be\nvague, compositionally complex, and denotationally rich. We present an\neffective approach to generating color descriptions using recurrent neural\nnetworks and a Fourier-transformed color representation. Our model outperforms\nprevious work on a conditional language modeling task over a large corpus of\nnaturalistic color descriptions. In addition, probing the model's output\nreveals that it can accurately produce not only basic color terms but also\ndescriptors with non-convex denotations (\"greenish\"), bare modifiers (\"bright\",\n\"dull\"), and compositional phrases (\"faded teal\") not seen in training. \n\n"}
{"id": "1606.03864", "contents": "Title: Neural Associative Memory for Dual-Sequence Modeling Abstract: Many important NLP problems can be posed as dual-sequence or\nsequence-to-sequence modeling tasks. Recent advances in building end-to-end\nneural architectures have been highly successful in solving such tasks. In this\nwork we propose a new architecture for dual-sequence modeling that is based on\nassociative memory. We derive AM-RNNs, a recurrent associative memory (AM)\nwhich augments generic recurrent neural networks (RNN). This architecture is\nextended to the Dual AM-RNN which operates on two AMs at once. Our models\nachieve very competitive results on textual entailment. A qualitative analysis\ndemonstrates that long range dependencies between source and target-sequence\ncan be bridged effectively using Dual AM-RNNs. However, an initial experiment\non auto-encoding reveals that these benefits are not exploited by the system\nwhen learning to solve sequence-to-sequence tasks which indicates that\nadditional supervision or regularization is needed. \n\n"}
{"id": "1606.04199", "contents": "Title: Deep Recurrent Models with Fast-Forward Connections for Neural Machine\n  Translation Abstract: Neural machine translation (NMT) aims at solving machine translation (MT)\nproblems using neural networks and has exhibited promising results in recent\nyears. However, most of the existing NMT models are shallow and there is still\na performance gap between a single NMT model and the best conventional MT\nsystem. In this work, we introduce a new type of linear connections, named\nfast-forward connections, based on deep Long Short-Term Memory (LSTM) networks,\nand an interleaved bi-directional architecture for stacking the LSTM layers.\nFast-forward connections play an essential role in propagating the gradients\nand building a deep topology of depth 16. On the WMT'14 English-to-French task,\nwe achieve BLEU=37.7 with a single attention model, which outperforms the\ncorresponding single shallow model by 6.2 BLEU points. This is the first time\nthat a single NMT model achieves state-of-the-art performance and outperforms\nthe best conventional model by 0.7 BLEU points. We can still achieve BLEU=36.3\neven without using an attention mechanism. After special handling of unknown\nwords and model ensembling, we obtain the best score reported to date on this\ntask with BLEU=40.4. Our models are also validated on the more difficult WMT'14\nEnglish-to-German task. \n\n"}
{"id": "1606.04582", "contents": "Title: Query-Reduction Networks for Question Answering Abstract: In this paper, we study the problem of question answering when reasoning over\nmultiple facts is required. We propose Query-Reduction Network (QRN), a variant\nof Recurrent Neural Network (RNN) that effectively handles both short-term\n(local) and long-term (global) sequential dependencies to reason over multiple\nfacts. QRN considers the context sentences as a sequence of state-changing\ntriggers, and reduces the original query to a more informed query as it\nobserves each trigger (context sentence) through time. Our experiments show\nthat QRN produces the state-of-the-art results in bAbI QA and dialog tasks, and\nin a real goal-oriented dialog dataset. In addition, QRN formulation allows\nparallelization on RNN's time axis, saving an order of magnitude in time\ncomplexity for training and inference. \n\n"}
{"id": "1606.04963", "contents": "Title: The Edit Distance Transducer in Action: The University of Cambridge\n  English-German System at WMT16 Abstract: This paper presents the University of Cambridge submission to WMT16.\nMotivated by the complementary nature of syntactical machine translation and\nneural machine translation (NMT), we exploit the synergies of Hiero and NMT in\ndifferent combination schemes. Starting out with a simple neural lattice\nrescoring approach, we show that the Hiero lattices are often too narrow for\nNMT ensembles. Therefore, instead of a hard restriction of the NMT search space\nto the lattice, we propose to loosely couple NMT and Hiero by composition with\na modified version of the edit distance transducer. The loose combination\noutperforms lattice rescoring, especially when using multiple NMT systems in an\nensemble. \n\n"}
{"id": "1606.05491", "contents": "Title: Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax\n  Trees and Strings Abstract: We present a natural language generator based on the sequence-to-sequence\napproach that can be trained to produce natural language strings as well as\ndeep syntax dependency trees from input dialogue acts, and we use it to\ndirectly compare two-step generation with separate sentence planning and\nsurface realization stages to a joint, one-step approach. We were able to train\nboth setups successfully using very little training data. The joint setup\noffers better performance, surpassing state-of-the-art with regards to\nn-gram-based scores while providing more relevant outputs. \n\n"}
{"id": "1606.05699", "contents": "Title: Socially-Informed Timeline Generation for Complex Events Abstract: Existing timeline generation systems for complex events consider only\ninformation from traditional media, ignoring the rich social context provided\nby user-generated content that reveals representative public interests or\ninsightful opinions. We instead aim to generate socially-informed timelines\nthat contain both news article summaries and selected user comments. We present\nan optimization framework designed to balance topical cohesion between the\narticle and comment summaries along with their informativeness and coverage of\nthe event. Automatic evaluations on real-world datasets that cover four complex\nevents show that our system produces more informative timelines than\nstate-of-the-art systems. In human evaluation, the associated comment summaries\nare furthermore rated more insightful than editor's picks and comments ranked\nhighly by users. \n\n"}
{"id": "1606.05804", "contents": "Title: Generalizing to Unseen Entities and Entity Pairs with Row-less Universal\n  Schema Abstract: Universal schema predicts the types of entities and relations in a knowledge\nbase (KB) by jointly embedding the union of all available schema types---not\nonly types from multiple structured databases (such as Freebase or Wikipedia\ninfoboxes), but also types expressed as textual patterns from raw text. This\nprediction is typically modeled as a matrix completion problem, with one type\nper column, and either one or two entities per row (in the case of entity types\nor binary relation types, respectively). Factorizing this sparsely observed\nmatrix yields a learned vector embedding for each row and each column. In this\npaper we explore the problem of making predictions for entities or entity-pairs\nunseen at training time (and hence without a pre-learned row embedding). We\npropose an approach having no per-row parameters at all; rather we produce a\nrow vector on the fly using a learned aggregation function of the vectors of\nthe observed columns for that row. We experiment with various aggregation\nfunctions, including neural network attention models. Our approach can be\nunderstood as a natural language database, in that questions about KB entities\nare answered by attending to textual or database evidence. In experiments\npredicting both relations and entity types, we demonstrate that despite having\nan order of magnitude fewer parameters than traditional universal schema, we\ncan match the accuracy of the traditional model, and more importantly, we can\nnow make predictions about unseen rows with nearly the same accuracy as rows\navailable at training time. \n\n"}
{"id": "1606.06083", "contents": "Title: Product Classification in E-Commerce using Distributional Semantics Abstract: Product classification is the task of automatically predicting a taxonomy\npath for a product in a predefined taxonomy hierarchy given a textual product\ndescription or title. For efficient product classification we require a\nsuitable representation for a document (the textual description of a product)\nfeature vector and efficient and fast algorithms for prediction. To address the\nabove challenges, we propose a new distributional semantics representation for\ndocument vector formation. We also develop a new two-level ensemble approach\nutilizing (with respect to the taxonomy tree) a path-wise, node-wise and\ndepth-wise classifiers for error reduction in the final product classification.\nOur experiments show the effectiveness of the distributional representation and\nthe ensemble approach on data sets from a leading e-commerce platform and\nachieve better results on various evaluation metrics compared to earlier\napproaches. \n\n"}
{"id": "1606.06137", "contents": "Title: LSTM-Based Predictions for Proactive Information Retrieval Abstract: We describe a method for proactive information retrieval targeted at\nretrieving relevant information during a writing task. In our method, the\ncurrent task and the needs of the user are estimated, and the potential next\nsteps are unobtrusively predicted based on the user's past actions. We focus on\nthe task of writing, in which the user is coalescing previously collected\ninformation into a text. Our proactive system automatically recommends the user\nrelevant background information. The proposed system incorporates text input\nprediction using a long short-term memory (LSTM) network. We present\nsimulations, which show that the system is able to reach higher precision\nvalues in an exploratory search setting compared to both a baseline and a\ncomparison system. \n\n"}
{"id": "1606.06164", "contents": "Title: Pragmatic factors in image description: the case of negations Abstract: We provide a qualitative analysis of the descriptions containing negations\n(no, not, n't, nobody, etc) in the Flickr30K corpus, and a categorization of\nnegation uses. Based on this analysis, we provide a set of requirements that an\nimage description system should have in order to generate negation sentences.\nAs a pilot experiment, we used our categorization to manually annotate\nsentences containing negations in the Flickr30K corpus, with an agreement score\nof K=0.67. With this paper, we hope to open up a broader discussion of\nsubjective language in image descriptions. \n\n"}
{"id": "1606.06640", "contents": "Title: Neural Morphological Tagging from Characters for Morphologically Rich\n  Languages Abstract: This paper investigates neural character-based morphological tagging for\nlanguages with complex morphology and large tag sets. We systematically explore\na variety of neural architectures (DNN, CNN, CNNHighway, LSTM, BLSTM) to obtain\ncharacter-based word vectors combined with bidirectional LSTMs to model\nacross-word context in an end-to-end setting. We explore supplementary use of\nword-based vectors trained on large amounts of unlabeled data. Our experiments\nfor morphological tagging suggest that for \"simple\" model configurations, the\nchoice of the network architecture (CNN vs. CNNHighway vs. LSTM vs. BLSTM) or\nthe augmentation with pre-trained word embeddings can be important and clearly\nimpact the accuracy. Increasing the model capacity by adding depth, for\nexample, and carefully optimizing the neural networks can lead to substantial\nimprovements, and the differences in accuracy (but not training time) become\nmuch smaller or even negligible. Overall, our best morphological taggers for\nGerman and Czech outperform the best results reported in the literature by a\nlarge margin. \n\n"}
{"id": "1606.06710", "contents": "Title: Correlation-based Intrinsic Evaluation of Word Vector Representations Abstract: We introduce QVEC-CCA--an intrinsic evaluation metric for word vector\nrepresentations based on correlations of learned vectors with features\nextracted from linguistic resources. We show that QVEC-CCA scores are an\neffective proxy for a range of extrinsic semantic and syntactic tasks. We also\nshow that the proposed evaluation obtains higher and more consistent\ncorrelations with downstream tasks, compared to existing approaches to\nintrinsic evaluation of word vectors that are based on word similarity. \n\n"}
{"id": "1606.06737", "contents": "Title: Criticality in Formal Languages and Statistical Physics Abstract: We show that the mutual information between two symbols, as a function of the\nnumber of symbols between the two, decays exponentially in any probabilistic\nregular grammar, but can decay like a power law for a context-free grammar.\nThis result about formal languages is closely related to a well-known result in\nclassical statistical mechanics that there are no phase transitions in\ndimensions fewer than two. It is also related to the emergence of power-law\ncorrelations in turbulence and cosmological inflation through recursive\ngenerative processes. We elucidate these physics connections and comment on\npotential applications of our results to machine learning tasks like training\nartificial recurrent neural networks. Along the way, we introduce a useful\nquantity which we dub the rational mutual information and discuss\ngeneralizations of our claims involving more complicated Bayesian networks. \n\n"}
{"id": "1606.06864", "contents": "Title: A Curriculum Learning Method for Improved Noise Robustness in Automatic\n  Speech Recognition Abstract: The performance of automatic speech recognition systems under noisy\nenvironments still leaves room for improvement. Speech enhancement or feature\nenhancement techniques for increasing noise robustness of these systems usually\nadd components to the recognition system that need careful optimization. In\nthis work, we propose the use of a relatively simple curriculum training\nstrategy called accordion annealing (ACCAN). It uses a multi-stage training\nschedule where samples at signal-to-noise ratio (SNR) values as low as 0dB are\nfirst added and samples at increasing higher SNR values are gradually added up\nto an SNR value of 50dB. We also use a method called per-epoch noise mixing\n(PEM) that generates noisy training samples online during training and thus\nenables dynamically changing the SNR of our training data. Both the ACCAN and\nthe PEM methods are evaluated on a end-to-end speech recognition pipeline on\nthe Wall Street Journal corpus. ACCAN decreases the average word error rate\n(WER) on the 20dB to -10dB SNR range by up to 31.4% when compared to a\nconventional multi-condition training method. \n\n"}
{"id": "1606.06871", "contents": "Title: A Comprehensive Study of Deep Bidirectional LSTM RNNs for Acoustic\n  Modeling in Speech Recognition Abstract: We present a comprehensive study of deep bidirectional long short-term memory\n(LSTM) recurrent neural network (RNN) based acoustic models for automatic\nspeech recognition (ASR). We study the effect of size and depth and train\nmodels of up to 8 layers. We investigate the training aspect and study\ndifferent variants of optimization methods, batching, truncated\nbackpropagation, different regularization techniques such as dropout and $L_2$\nregularization, and different gradient clipping variants.\n  The major part of the experimental analysis was performed on the Quaero\ncorpus. Additional experiments also were performed on the Switchboard corpus.\nOur best LSTM model has a relative improvement in word error rate of over 14\\%\ncompared to our best feed-forward neural network (FFNN) baseline on the Quaero\ntask. On this task, we get our best result with an 8 layer bidirectional LSTM\nand we show that a pretraining scheme with layer-wise construction helps for\ndeep LSTMs.\n  Finally we compare the training calculation time of many of the presented\nexperiments in relation with recognition performance.\n  All the experiments were done with RETURNN, the RWTH extensible training\nframework for universal recurrent neural networks in combination with RASR, the\nRWTH ASR toolkit. \n\n"}
{"id": "1606.06950", "contents": "Title: A segmental framework for fully-unsupervised large-vocabulary speech\n  recognition Abstract: Zero-resource speech technology is a growing research area that aims to\ndevelop methods for speech processing in the absence of transcriptions,\nlexicons, or language modelling text. Early term discovery systems focused on\nidentifying isolated recurring patterns in a corpus, while more recent\nfull-coverage systems attempt to completely segment and cluster the audio into\nword-like units---effectively performing unsupervised speech recognition. This\narticle presents the first attempt we are aware of to apply such a system to\nlarge-vocabulary multi-speaker data. Our system uses a Bayesian modelling\nframework with segmental word representations: each word segment is represented\nas a fixed-dimensional acoustic embedding obtained by mapping the sequence of\nfeature frames to a single embedding vector. We compare our system on English\nand Xitsonga datasets to state-of-the-art baselines, using a variety of\nmeasures including word error rate (obtained by mapping the unsupervised output\nto ground truth transcriptions). Very high word error rates are reported---in\nthe order of 70--80% for speaker-dependent and 80--95% for speaker-independent\nsystems---highlighting the difficulty of this task. Nevertheless, in terms of\ncluster quality and word segmentation metrics, we show that by imposing a\nconsistent top-down segmentation while also using bottom-up knowledge from\ndetected syllable boundaries, both single-speaker and multi-speaker versions of\nour system outperform a purely bottom-up single-speaker syllable-based\napproach. We also show that the discovered clusters can be made less speaker-\nand gender-specific by using an unsupervised autoencoder-like feature extractor\nto learn better frame-level features (prior to embedding). Our system's\ndiscovered clusters are still less pure than those of unsupervised term\ndiscovery systems, but provide far greater coverage. \n\n"}
{"id": "1606.06996", "contents": "Title: The word entropy of natural languages Abstract: The average uncertainty associated with words is an information-theoretic\nconcept at the heart of quantitative and computational linguistics. The entropy\nhas been established as a measure of this average uncertainty - also called\naverage information content. We here use parallel texts of 21 languages to\nestablish the number of tokens at which word entropies converge to stable\nvalues. These convergence points are then used to select texts from a massively\nparallel corpus, and to estimate word entropies across more than 1000\nlanguages. Our results help to establish quantitative language comparisons, to\nunderstand the performance of multilingual translation systems, and to\nnormalize semantic similarity measures. \n\n"}
{"id": "1606.07189", "contents": "Title: Gender and Interest Targeting for Sponsored Post Advertising at Tumblr Abstract: As one of the leading platforms for creative content, Tumblr offers\nadvertisers a unique way of creating brand identity. Advertisers can tell their\nstory through images, animation, text, music, video, and more, and promote that\ncontent by sponsoring it to appear as an advertisement in the streams of Tumblr\nusers. In this paper we present a framework that enabled one of the key\ntargeted advertising components for Tumblr, specifically gender and interest\ntargeting. We describe the main challenges involved in development of the\nframework, which include creating the ground truth for training gender\nprediction models, as well as mapping Tumblr content to an interest taxonomy.\nFor purposes of inferring user interests we propose a novel semi-supervised\nneural language model for categorization of Tumblr content (i.e., post tags and\npost keywords). The model was trained on a large-scale data set consisting of\n6.8 billion user posts, with very limited amount of categorized keywords, and\nwas shown to have superior performance over the bag-of-words model. We\nsuccessfully deployed gender and interest targeting capability in Yahoo\nproduction systems, delivering inference for users that cover more than 90% of\ndaily activities at Tumblr. Online performance results indicate advantages of\nthe proposed approach, where we observed 20% lift in user engagement with\nsponsored posts as compared to untargeted campaigns. \n\n"}
{"id": "1606.07211", "contents": "Title: Toward a Deep Neural Approach for Knowledge-Based IR Abstract: This paper tackles the problem of the semantic gap between a document and a\nquery within an ad-hoc information retrieval task. In this context, knowledge\nbases (KBs) have already been acknowledged as valuable means since they allow\nthe representation of explicit relations between entities. However, they do not\nnecessarily represent implicit relations that could be hidden in a corpora.\nThis latter issue is tackled by recent works dealing with deep representation\nlearn ing of texts. With this in mind, we argue that embedding KBs within deep\nneural architectures supporting documentquery matching would give rise to\nfine-grained latent representations of both words and their semantic relations.\nIn this paper, we review the main approaches of neural-based document ranking\nas well as those approaches for latent representation of entities and relations\nvia KBs. We then propose some avenues to incorporate KBs in deep neural\napproaches for document ranking. More particularly, this paper advocates that\nKBs can be used either to support enhanced latent representations of queries\nand documents based on both distributional and relational semantics or to serve\nas a semantic translator between their latent distributional representations. \n\n"}
{"id": "1606.07493", "contents": "Title: Sort Story: Sorting Jumbled Images and Captions into Stories Abstract: Temporal common sense has applications in AI tasks such as QA, multi-document\nsummarization, and human-AI communication. We propose the task of sequencing --\ngiven a jumbled set of aligned image-caption pairs that belong to a story, the\ntask is to sort them such that the output sequence forms a coherent story. We\npresent multiple approaches, via unary (position) and pairwise (order)\npredictions, and their ensemble-based combinations, achieving strong results on\nthis task. We use both text-based and image-based features, which depict\ncomplementary improvements. Using qualitative examples, we demonstrate that our\nmodels have learnt interesting aspects of temporal common sense. \n\n"}
{"id": "1606.07545", "contents": "Title: Interactive Semantic Featuring for Text Classification Abstract: In text classification, dictionaries can be used to define\nhuman-comprehensible features. We propose an improvement to dictionary features\ncalled smoothed dictionary features. These features recognize document contexts\ninstead of n-grams. We describe a principled methodology to solicit dictionary\nfeatures from a teacher, and present results showing that models built using\nthese human-comprehensible features are competitive with models trained with\nBag of Words features. \n\n"}
{"id": "1606.07601", "contents": "Title: Evaluation method of word embedding by roots and affixes Abstract: Word embedding has been shown to be remarkably effective in a lot of Natural\nLanguage Processing tasks. However, existing models still have a couple of\nlimitations in interpreting the dimensions of word vector. In this paper, we\nprovide a new approach---roots and affixes model(RAAM)---to interpret it from\nthe intrinsic structures of natural language. Also it can be used as an\nevaluation measure of the quality of word embedding. We introduce the\ninformation entropy into our model and divide the dimensions into two\ncategories, just like roots and affixes in lexical semantics. Then considering\neach category as a whole rather than individually. We experimented with English\nWikipedia corpus. Our result show that there is a negative linear relation\nbetween the two attributes and a high positive correlation between our model\nand downstream semantic evaluation tasks. \n\n"}
{"id": "1606.07772", "contents": "Title: The emotional arcs of stories are dominated by six basic shapes Abstract: Advances in computing power, natural language processing, and digitization of\ntext now make it possible to study a culture's evolution through its texts\nusing a \"big data\" lens. Our ability to communicate relies in part upon a\nshared emotional experience, with stories often following distinct emotional\ntrajectories and forming patterns that are meaningful to us. Here, by\nclassifying the emotional arcs for a filtered subset of 1,327 stories from\nProject Gutenberg's fiction collection, we find a set of six core emotional\narcs which form the essential building blocks of complex emotional\ntrajectories. We strengthen our findings by separately applying Matrix\ndecomposition, supervised learning, and unsupervised learning. For each of\nthese six core emotional arcs, we examine the closest characteristic stories in\npublication today and find that particular emotional arcs enjoy greater\nsuccess, as measured by downloads. \n\n"}
{"id": "1606.07947", "contents": "Title: Sequence-Level Knowledge Distillation Abstract: Neural machine translation (NMT) offers a novel alternative formulation of\ntranslation that is potentially simpler than statistical approaches. However to\nreach competitive performance, NMT models need to be exceedingly large. In this\npaper we consider applying knowledge distillation approaches (Bucila et al.,\n2006; Hinton et al., 2015) that have proven successful for reducing the size of\nneural models in other domains to the problem of NMT. We demonstrate that\nstandard knowledge distillation applied to word-level prediction can be\neffective for NMT, and also introduce two novel sequence-level versions of\nknowledge distillation that further improve performance, and somewhat\nsurprisingly, seem to eliminate the need for beam search (even when applied on\nthe original teacher model). Our best student model runs 10 times faster than\nits state-of-the-art teacher with little loss in performance. It is also\nsignificantly better than a baseline model trained without knowledge\ndistillation: by 4.2/1.7 BLEU with greedy decoding/beam search. Applying weight\npruning on top of knowledge distillation results in a student model that has 13\ntimes fewer parameters than the original teacher model, with a decrease of 0.4\nBLEU. \n\n"}
{"id": "1606.07953", "contents": "Title: Bidirectional Recurrent Neural Networks for Medical Event Detection in\n  Electronic Health Records Abstract: Sequence labeling for extraction of medical events and their attributes from\nunstructured text in Electronic Health Record (EHR) notes is a key step towards\nsemantic understanding of EHRs. It has important applications in health\ninformatics including pharmacovigilance and drug surveillance. The state of the\nart supervised machine learning models in this domain are based on Conditional\nRandom Fields (CRFs) with features calculated from fixed context windows. In\nthis application, we explored various recurrent neural network frameworks and\nshow that they significantly outperformed the CRF models. \n\n"}
{"id": "1606.08425", "contents": "Title: Predicting the Relative Difficulty of Single Sentences With and Without\n  Surrounding Context Abstract: The problem of accurately predicting relative reading difficulty across a set\nof sentences arises in a number of important natural language applications,\nsuch as finding and curating effective usage examples for intelligent language\ntutoring systems. Yet while significant research has explored document- and\npassage-level reading difficulty, the special challenges involved in assessing\naspects of readability for single sentences have received much less attention,\nparticularly when considering the role of surrounding passages. We introduce\nand evaluate a novel approach for estimating the relative reading difficulty of\na set of sentences, with and without surrounding context. Using different sets\nof lexical and grammatical features, we explore models for predicting pairwise\nrelative difficulty using logistic regression, and examine rankings generated\nby aggregating pairwise difficulty labels using a Bayesian rating system to\nform a final ranking. We also compare rankings derived for sentences assessed\nwith and without context, and find that contextual features can help predict\ndifferences in relative difficulty judgments across these two conditions. \n\n"}
{"id": "1606.09370", "contents": "Title: Relation extraction from clinical texts using domain invariant\n  convolutional neural network Abstract: In recent years extracting relevant information from biomedical and clinical\ntexts such as research articles, discharge summaries, or electronic health\nrecords have been a subject of many research efforts and shared challenges.\nRelation extraction is the process of detecting and classifying the semantic\nrelation among entities in a given piece of texts. Existing models for this\ntask in biomedical domain use either manually engineered features or kernel\nmethods to create feature vector. These features are then fed to classifier for\nthe prediction of the correct class. It turns out that the results of these\nmethods are highly dependent on quality of user designed features and also\nsuffer from curse of dimensionality. In this work we focus on extracting\nrelations from clinical discharge summaries. Our main objective is to exploit\nthe power of convolution neural network (CNN) to learn features automatically\nand thus reduce the dependency on manual feature engineering. We evaluate\nperformance of the proposed model on i2b2-2010 clinical relation extraction\nchallenge dataset. Our results indicate that convolution neural network can be\na good model for relation exaction in clinical text without being dependent on\nexpert's knowledge on defining quality features. \n\n"}
{"id": "1606.09403", "contents": "Title: Learning Crosslingual Word Embeddings without Bilingual Corpora Abstract: Crosslingual word embeddings represent lexical items from different languages\nin the same vector space, enabling transfer of NLP tools. However, previous\nattempts had expensive resource requirements, difficulty incorporating\nmonolingual data or were unable to handle polysemy. We address these drawbacks\nin our method which takes advantage of a high coverage dictionary in an EM\nstyle training algorithm over monolingual corpora in two languages. Our model\nachieves state-of-the-art performance on bilingual lexicon induction task\nexceeding models using large bilingual corpora, and competitive results on the\nmonolingual word similarity and cross-lingual document classification task. \n\n"}
{"id": "1607.00198", "contents": "Title: Sharing Network Parameters for Crosslingual Named Entity Recognition Abstract: Most state of the art approaches for Named Entity Recognition rely on hand\ncrafted features and annotated corpora. Recently Neural network based models\nhave been proposed which do not require handcrafted features but still require\nannotated corpora. However, such annotated corpora may not be available for\nmany languages. In this paper, we propose a neural network based model which\nallows sharing the decoder as well as word and character level parameters\nbetween two languages thereby allowing a resource fortunate language to aid a\nresource deprived language. Specifically, we focus on the case when limited\nannotated corpora is available in one language ($L_1$) and abundant annotated\ncorpora is available in another language ($L_2$). Sharing the network\narchitecture and parameters between $L_1$ and $L_2$ leads to improved\nperformance in $L_1$. Further, our approach does not require any hand crafted\nfeatures but instead directly learns meaningful feature representations from\nthe training data itself. We experiment with 4 language pairs and show that\nindeed in a resource constrained setup (lesser annotated corpora), a model\njointly trained with data from another language performs better than a model\ntrained only on the limited corpora in one language. \n\n"}
{"id": "1607.01426", "contents": "Title: Chains of Reasoning over Entities, Relations, and Text using Recurrent\n  Neural Networks Abstract: Our goal is to combine the rich multistep inference of symbolic logical\nreasoning with the generalization capabilities of neural networks. We are\nparticularly interested in complex reasoning about entities and relations in\ntext and large-scale knowledge bases (KBs). Neelakantan et al. (2015) use RNNs\nto compose the distributed semantics of multi-hop paths in KBs; however for\nmultiple reasons, the approach lacks accuracy and practicality. This paper\nproposes three significant modeling advances: (1) we learn to jointly reason\nabout relations, entities, and entity-types; (2) we use neural attention\nmodeling to incorporate multiple paths; (3) we learn to share strength in a\nsingle RNN that represents logical composition across all relations. On a\nlargescale Freebase+ClueWeb prediction task, we achieve 25% error reduction,\nand a 53% error reduction on sparse relations due to shared strength. On chains\nof reasoning in WordNet we reduce error in mean quantile by 84% versus previous\nstate-of-the-art. The code and data are available at\nhttps://rajarshd.github.io/ChainsofReasoning \n\n"}
{"id": "1607.01856", "contents": "Title: Neural Name Translation Improves Neural Machine Translation Abstract: In order to control computational complexity, neural machine translation\n(NMT) systems convert all rare words outside the vocabulary into a single unk\nsymbol. Previous solution (Luong et al., 2015) resorts to use multiple numbered\nunks to learn the correspondence between source and target rare words. However,\ntesting words unseen in the training corpus cannot be handled by this method.\nAnd it also suffers from the noisy word alignment. In this paper, we focus on a\nmajor type of rare words -- named entity (NE), and propose to translate them\nwith character level sequence to sequence model. The NE translation model is\nfurther used to derive high quality NE alignment in the bilingual training\ncorpus. With the integration of NE translation and alignment modules, our NMT\nsystem is able to surpass the baseline system by 2.9 BLEU points on the Chinese\nto English task. \n\n"}
{"id": "1607.02250", "contents": "Title: Consensus Attention-based Neural Networks for Chinese Reading\n  Comprehension Abstract: Reading comprehension has embraced a booming in recent NLP research. Several\ninstitutes have released the Cloze-style reading comprehension data, and these\nhave greatly accelerated the research of machine comprehension. In this work,\nwe firstly present Chinese reading comprehension datasets, which consist of\nPeople Daily news dataset and Children's Fairy Tale (CFT) dataset. Also, we\npropose a consensus attention-based neural network architecture to tackle the\nCloze-style reading comprehension problem, which aims to induce a consensus\nattention over every words in the query. Experimental results show that the\nproposed neural network significantly outperforms the state-of-the-art\nbaselines in several public datasets. Furthermore, we setup a baseline for\nChinese reading comprehension task, and hopefully this would speed up the\nprocess for future research. \n\n"}
{"id": "1607.02310", "contents": "Title: Collaborative Training of Tensors for Compositional Distributional\n  Semantics Abstract: Type-based compositional distributional semantic models present an\ninteresting line of research into functional representations of linguistic\nmeaning. One of the drawbacks of such models, however, is the lack of training\ndata required to train each word-type combination. In this paper we address\nthis by introducing training methods that share parameters between similar\nwords. We show that these methods enable zero-shot learning for words that have\nno training data at all, as well as enabling construction of high-quality\ntensors from very few training examples per word. \n\n"}
{"id": "1607.02789", "contents": "Title: Charagram: Embedding Words and Sentences via Character n-grams Abstract: We present Charagram embeddings, a simple approach for learning\ncharacter-based compositional models to embed textual sequences. A word or\nsentence is represented using a character n-gram count vector, followed by a\nsingle nonlinear transformation to yield a low-dimensional embedding. We use\nthree tasks for evaluation: word similarity, sentence similarity, and\npart-of-speech tagging. We demonstrate that Charagram embeddings outperform\nmore complex architectures based on character-level recurrent and convolutional\nneural networks, achieving new state-of-the-art performance on several\nsimilarity tasks. \n\n"}
{"id": "1607.03780", "contents": "Title: A Vector Space for Distributional Semantics for Entailment Abstract: Distributional semantics creates vector-space representations that capture\nmany forms of semantic similarity, but their relation to semantic entailment\nhas been less clear. We propose a vector-space model which provides a formal\nfoundation for a distributional semantics of entailment. Using a mean-field\napproximation, we develop approximate inference procedures and entailment\noperators over vectors of probabilities of features being known (versus\nunknown). We use this framework to reinterpret an existing\ndistributional-semantic model (Word2Vec) as approximating an entailment-based\nmodel of the distributions of words in contexts, thereby predicting lexical\nentailment relations. In both unsupervised and semi-supervised experiments on\nhyponymy detection, we get substantial improvements over previous results. \n\n"}
{"id": "1607.04853", "contents": "Title: An Empirical Evaluation of various Deep Learning Architectures for\n  Bi-Sequence Classification Tasks Abstract: Several tasks in argumentation mining and debating, question-answering, and\nnatural language inference involve classifying a sequence in the context of\nanother sequence (referred as bi-sequence classification). For several single\nsequence classification tasks, the current state-of-the-art approaches are\nbased on recurrent and convolutional neural networks. On the other hand, for\nbi-sequence classification problems, there is not much understanding as to the\nbest deep learning architecture. In this paper, we attempt to get an\nunderstanding of this category of problems by extensive empirical evaluation of\n19 different deep learning architectures (specifically on different ways of\nhandling context) for various problems originating in natural language\nprocessing like debating, textual entailment and question-answering. Following\nthe empirical evaluation, we offer our insights and conclusions regarding the\narchitectures we have considered. We also establish the first deep learning\nbaselines for three argumentation mining tasks. \n\n"}
{"id": "1608.00466", "contents": "Title: Learning Semantically Coherent and Reusable Kernels in Convolution\n  Neural Nets for Sentence Classification Abstract: The state-of-the-art CNN models give good performance on sentence\nclassification tasks. The purpose of this work is to empirically study\ndesirable properties such as semantic coherence, attention mechanism and\nreusability of CNNs in these tasks. Semantically coherent kernels are\npreferable as they are a lot more interpretable for explaining the decision of\nthe learned CNN model. We observe that the learned kernels do not have semantic\ncoherence. Motivated by this observation, we propose to learn kernels with\nsemantic coherence using clustering scheme combined with Word2Vec\nrepresentation and domain knowledge such as SentiWordNet. We suggest a\ntechnique to visualize attention mechanism of CNNs for decision explanation\npurpose. Reusable property enables kernels learned on one problem to be used in\nanother problem. This helps in efficient learning as only a few additional\ndomain specific filters may have to be learned. We demonstrate the efficacy of\nour core ideas of learning semantically coherent kernels and leveraging\nreusable kernels for efficient learning on several benchmark datasets.\nExperimental results show the usefulness of our approach by achieving\nperformance close to the state-of-the-art methods but with semantic and\nreusable properties. \n\n"}
{"id": "1608.00869", "contents": "Title: SimVerb-3500: A Large-Scale Evaluation Set of Verb Similarity Abstract: Verbs play a critical role in the meaning of sentences, but these ubiquitous\nwords have received little attention in recent distributional semantics\nresearch. We introduce SimVerb-3500, an evaluation resource that provides human\nratings for the similarity of 3,500 verb pairs. SimVerb-3500 covers all normed\nverb types from the USF free-association database, providing at least three\nexamples for every VerbNet class. This broad coverage facilitates detailed\nanalyses of how syntactic and semantic phenomena together influence human\nunderstanding of verb meaning. Further, with significantly larger development\nand test sets than existing benchmarks, SimVerb-3500 enables more robust\nevaluation of representation learning architectures and promotes the\ndevelopment of methods tailored to verbs. We hope that SimVerb-3500 will enable\na richer understanding of the diversity and complexity of verb semantics and\nguide the development of systems that can effectively represent and interpret\nthis meaning. \n\n"}
{"id": "1608.01281", "contents": "Title: Learning Online Alignments with Continuous Rewards Policy Gradient Abstract: Sequence-to-sequence models with soft attention had significant success in\nmachine translation, speech recognition, and question answering. Though capable\nand easy to use, they require that the entirety of the input sequence is\navailable at the beginning of inference, an assumption that is not valid for\ninstantaneous translation and speech recognition. To address this problem, we\npresent a new method for solving sequence-to-sequence problems using hard\nonline alignments instead of soft offline alignments. The online alignments\nmodel is able to start producing outputs without the need to first process the\nentire input sequence. A highly accurate online sequence-to-sequence model is\nuseful because it can be used to build an accurate voice-based instantaneous\ntranslator. Our model uses hard binary stochastic decisions to select the\ntimesteps at which outputs will be produced. The model is trained to produce\nthese stochastic decisions using a standard policy gradient method. In our\nexperiments, we show that this model achieves encouraging performance on TIMIT\nand Wall Street Journal (WSJ) speech recognition datasets. \n\n"}
{"id": "1608.01561", "contents": "Title: UsingWord Embeddings for Query Translation for Hindi to English Cross\n  Language Information Retrieval Abstract: Cross-Language Information Retrieval (CLIR) has become an important problem\nto solve in the recent years due to the growth of content in multiple languages\nin the Web. One of the standard methods is to use query translation from source\nto target language. In this paper, we propose an approach based on word\nembeddings, a method that captures contextual clues for a particular word in\nthe source language and gives those words as translations that occur in a\nsimilar context in the target language. Once we obtain the word embeddings of\nthe source and target language pairs, we learn a projection from source to\ntarget word embeddings, making use of a dictionary with word translation\npairs.We then propose various methods of query translation and aggregation. The\nadvantage of this approach is that it does not require the corpora to be\naligned (which is difficult to obtain for resource-scarce languages), a\ndictionary with word translation pairs is enough to train the word vectors for\ntranslation. We experiment with Forum for Information Retrieval and Evaluation\n(FIRE) 2008 and 2012 datasets for Hindi to English CLIR. The proposed word\nembedding based approach outperforms the basic dictionary based approach by 70%\nand when the word embeddings are combined with the dictionary, the hybrid\napproach beats the baseline dictionary based method by 77%. It outperforms the\nEnglish monolingual baseline by 15%, when combined with the translations\nobtained from Google Translate and Dictionary. \n\n"}
{"id": "1608.02117", "contents": "Title: HyperLex: A Large-Scale Evaluation of Graded Lexical Entailment Abstract: We introduce HyperLex - a dataset and evaluation resource that quantifies the\nextent of of the semantic category membership, that is, type-of relation also\nknown as hyponymy-hypernymy or lexical entailment (LE) relation between 2,616\nconcept pairs. Cognitive psychology research has established that typicality\nand category/class membership are computed in human semantic memory as a\ngradual rather than binary relation. Nevertheless, most NLP research, and\nexisting large-scale invetories of concept category membership (WordNet,\nDBPedia, etc.) treat category membership and LE as binary. To address this, we\nasked hundreds of native English speakers to indicate typicality and strength\nof category membership between a diverse range of concept pairs on a\ncrowdsourcing platform. Our results confirm that category membership and LE are\nindeed more gradual than binary. We then compare these human judgements with\nthe predictions of automatic systems, which reveals a huge gap between human\nperformance and state-of-the-art LE, distributional and representation learning\nmodels, and substantial differences between the models themselves. We discuss a\npathway for improving semantic models to overcome this discrepancy, and\nindicate future application areas for improved graded LE systems. \n\n"}
{"id": "1608.02689", "contents": "Title: Multi-task Domain Adaptation for Sequence Tagging Abstract: Many domain adaptation approaches rely on learning cross domain shared\nrepresentations to transfer the knowledge learned in one domain to other\ndomains. Traditional domain adaptation only considers adapting for one task. In\nthis paper, we explore multi-task representation learning under the domain\nadaptation scenario. We propose a neural network framework that supports domain\nadaptation for multiple tasks simultaneously, and learns shared representations\nthat better generalize for domain adaptation. We apply the proposed framework\nto domain adaptation for sequence tagging problems considering two tasks:\nChinese word segmentation and named entity recognition. Experiments show that\nmulti-task domain adaptation works better than disjoint domain adaptation for\neach task, and achieves the state-of-the-art results for both tasks in the\nsocial media domain. \n\n"}
{"id": "1608.03030", "contents": "Title: Hierarchical Character-Word Models for Language Identification Abstract: Social media messages' brevity and unconventional spelling pose a challenge\nto language identification. We introduce a hierarchical model that learns\ncharacter and contextualized word-level representations for language\nidentification. Our method performs well against strong base- lines, and can\nalso reveal code-switching. \n\n"}
{"id": "1608.04207", "contents": "Title: Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction\n  Tasks Abstract: There is a lot of research interest in encoding variable length sentences\ninto fixed length vectors, in a way that preserves the sentence meanings. Two\ncommon methods include representations based on averaging word vectors, and\nrepresentations based on the hidden states of recurrent neural networks such as\nLSTMs. The sentence vectors are used as features for subsequent machine\nlearning tasks or for pre-training in the context of deep learning. However,\nnot much is known about the properties that are encoded in these sentence\nrepresentations and about the language information they capture. We propose a\nframework that facilitates better understanding of the encoded representations.\nWe define prediction tasks around isolated aspects of sentence structure\n(namely sentence length, word content, and word order), and score\nrepresentations by the ability to train a classifier to solve each prediction\ntask when using the representation as input. We demonstrate the potential\ncontribution of the approach by analyzing different sentence representation\nmechanisms. The analysis sheds light on the relative strengths of different\nsentence embedding methods with respect to these low level prediction tasks,\nand on the effect of the encoded vector's dimensionality on the resulting\nrepresentations. \n\n"}
{"id": "1608.05457", "contents": "Title: Who did What: A Large-Scale Person-Centered Cloze Dataset Abstract: We have constructed a new \"Who-did-What\" dataset of over 200,000\nfill-in-the-gap (cloze) multiple choice reading comprehension problems\nconstructed from the LDC English Gigaword newswire corpus. The WDW dataset has\na variety of novel features. First, in contrast with the CNN and Daily Mail\ndatasets (Hermann et al., 2015) we avoid using article summaries for question\nformation. Instead, each problem is formed from two independent articles --- an\narticle given as the passage to be read and a separate article on the same\nevents used to form the question. Second, we avoid anonymization --- each\nchoice is a person named entity. Third, the problems have been filtered to\nremove a fraction that are easily solved by simple baselines, while remaining\n84% solvable by humans. We report performance benchmarks of standard systems\nand propose the WDW dataset as a challenge task for the community. \n\n"}
{"id": "1608.05604", "contents": "Title: Modeling Human Reading with Neural Attention Abstract: When humans read text, they fixate some words and skip others. However, there\nhave been few attempts to explain skipping behavior with computational models,\nas most existing work has focused on predicting reading times (e.g.,~using\nsurprisal). In this paper, we propose a novel approach that models both\nskipping and reading, using an unsupervised architecture that combines a neural\nattention with autoencoding, trained on raw text using reinforcement learning.\nOur model explains human reading behavior as a tradeoff between precision of\nlanguage understanding (encoding the input accurately) and economy of attention\n(fixating as few words as possible). We evaluate the model on the Dundee\neye-tracking corpus, showing that it accurately predicts skipping behavior and\nreading times, is competitive with surprisal, and captures known qualitative\nfeatures of human reading. \n\n"}
{"id": "1608.07639", "contents": "Title: Learning to generalize to new compositions in image understanding Abstract: Recurrent neural networks have recently been used for learning to describe\nimages using natural language. However, it has been observed that these models\ngeneralize poorly to scenes that were not observed during training, possibly\ndepending too strongly on the statistics of the text in the training data. Here\nwe propose to describe images using short structured representations, aiming to\ncapture the crux of a description. These structured representations allow us to\ntease-out and evaluate separately two types of generalization: standard\ngeneralization to new images with similar scenes, and generalization to new\ncombinations of known entities. We compare two learning approaches on the\nMS-COCO dataset: a state-of-the-art recurrent network based on an LSTM (Show,\nAttend and Tell), and a simple structured prediction model on top of a deep\nnetwork. We find that the structured model generalizes to new compositions\nsubstantially better than the LSTM, ~7 times the accuracy of predicting\nstructured representations. By providing a concrete method to quantify\ngeneralization for unseen combinations, we argue that structured\nrepresentations and compositional splits are a useful benchmark for image\ncaptioning, and advocate compositional models that capture linguistic and\nvisual structure. \n\n"}
{"id": "1609.00070", "contents": "Title: How Much is 131 Million Dollars? Putting Numbers in Perspective with\n  Compositional Descriptions Abstract: How much is 131 million US dollars? To help readers put such numbers in\ncontext, we propose a new task of automatically generating short descriptions\nknown as perspectives, e.g. \"$131 million is about the cost to employ everyone\nin Texas over a lunch period\". First, we collect a dataset of numeric mentions\nin news articles, where each mention is labeled with a set of rated\nperspectives. We then propose a system to generate these descriptions\nconsisting of two steps: formula construction and description generation. In\nconstruction, we compose formulae from numeric facts in a knowledge base and\nrank the resulting formulas based on familiarity, numeric proximity and\nsemantic compatibility. In generation, we convert a formula into natural\nlanguage using a sequence-to-sequence recurrent neural network. Our system\nobtains a 15.2% F1 improvement over a non-compositional baseline at formula\nconstruction and a 12.5 BLEU point improvement over a baseline description\ngeneration. \n\n"}
{"id": "1609.00425", "contents": "Title: Identifying Dogmatism in Social Media: Signals and Models Abstract: We explore linguistic and behavioral features of dogmatism in social media\nand construct statistical models that can identify dogmatic comments. Our model\nis based on a corpus of Reddit posts, collected across a diverse set of\nconversational topics and annotated via paid crowdsourcing. We operationalize\nkey aspects of dogmatism described by existing psychology theories (such as\nover-confidence), finding they have predictive power. We also find evidence for\nnew signals of dogmatism, such as the tendency of dogmatic posts to refrain\nfrom signaling cognitive processes. When we use our predictive model to analyze\nmillions of other Reddit posts, we find evidence that suggests dogmatism is a\ndeeper personality trait, present for dogmatic users across many different\ndomains, and that users who engage on dogmatic comments tend to show increases\nin dogmatic posts themselves. \n\n"}
{"id": "1609.01454", "contents": "Title: Attention-Based Recurrent Neural Network Models for Joint Intent\n  Detection and Slot Filling Abstract: Attention-based encoder-decoder neural network models have recently shown\npromising results in machine translation and speech recognition. In this work,\nwe propose an attention-based neural network model for joint intent detection\nand slot filling, both of which are critical steps for many speech\nunderstanding and dialog systems. Unlike in machine translation and speech\nrecognition, alignment is explicit in slot filling. We explore different\nstrategies in incorporating this alignment information to the encoder-decoder\nframework. Learning from the attention mechanism in encoder-decoder model, we\nfurther propose introducing attention to the alignment-based RNN models. Such\nattentions provide additional information to the intent classification and slot\nlabel prediction. Our independent task models achieve state-of-the-art intent\ndetection error rate and slot filling F1 score on the benchmark ATIS task. Our\njoint training model further obtains 0.56% absolute (23.8% relative) error\nreduction on intent detection and 0.23% absolute gain on slot filling over the\nindependent task models. \n\n"}
{"id": "1609.02116", "contents": "Title: Ask the GRU: Multi-Task Learning for Deep Text Recommendations Abstract: In a variety of application domains the content to be recommended to users is\nassociated with text. This includes research papers, movies with associated\nplot summaries, news articles, blog posts, etc. Recommendation approaches based\non latent factor models can be extended naturally to leverage text by employing\nan explicit mapping from text to factors. This enables recommendations for new,\nunseen content, and may generalize better, since the factors for all items are\nproduced by a compactly-parametrized model. Previous work has used topic models\nor averages of word embeddings for this mapping. In this paper we present a\nmethod leveraging deep recurrent neural networks to encode the text sequence\ninto a latent vector, specifically gated recurrent units (GRUs) trained\nend-to-end on the collaborative filtering task. For the task of scientific\npaper recommendation, this yields models with significantly higher accuracy. In\ncold-start scenarios, we beat the previous state-of-the-art, all of which\nignore word order. Performance is further improved by multi-task learning,\nwhere the text encoder network is trained for a combination of content\nrecommendation and item metadata prediction. This regularizes the collaborative\nfiltering model, ameliorating the problem of sparsity of the observed rating\nmatrix. \n\n"}
{"id": "1609.02727", "contents": "Title: Detecting Singleton Review Spammers Using Semantic Similarity Abstract: Online reviews have increasingly become a very important resource for\nconsumers when making purchases. Though it is becoming more and more difficult\nfor people to make well-informed buying decisions without being deceived by\nfake reviews. Prior works on the opinion spam problem mostly considered\nclassifying fake reviews using behavioral user patterns. They focused on\nprolific users who write more than a couple of reviews, discarding one-time\nreviewers. The number of singleton reviewers however is expected to be high for\nmany review websites. While behavioral patterns are effective when dealing with\nelite users, for one-time reviewers, the review text needs to be exploited. In\nthis paper we tackle the problem of detecting fake reviews written by the same\nperson using multiple names, posting each review under a different name. We\npropose two methods to detect similar reviews and show the results generally\noutperform the vectorial similarity measures used in prior works. The first\nmethod extends the semantic similarity between words to the reviews level. The\nsecond method is based on topic modeling and exploits the similarity of the\nreviews topic distributions using two models: bag-of-words and\nbag-of-opinion-phrases. The experiments were conducted on reviews from three\ndifferent datasets: Yelp (57K reviews), Trustpilot (9K reviews) and Ott dataset\n(800 reviews). \n\n"}
{"id": "1609.02748", "contents": "Title: INSIGHT-1 at SemEval-2016 Task 5: Deep Learning for Multilingual\n  Aspect-based Sentiment Analysis Abstract: This paper describes our deep learning-based approach to multilingual\naspect-based sentiment analysis as part of SemEval 2016 Task 5. We use a\nconvolutional neural network (CNN) for both aspect extraction and aspect-based\nsentiment analysis. We cast aspect extraction as a multi-label classification\nproblem, outputting probabilities over aspects parameterized by a threshold. To\ndetermine the sentiment towards an aspect, we concatenate an aspect vector with\nevery word embedding and apply a convolution over it. Our constrained system\n(unconstrained for English) achieves competitive results across all languages\nand domains, placing first or second in 5 and 7 out of 11 language-domain pairs\nfor aspect category detection (slot 1) and sentiment polarity (slot 3)\nrespectively, thereby demonstrating the viability of a deep learning-based\napproach for multilingual aspect-based sentiment analysis. \n\n"}
{"id": "1609.04253", "contents": "Title: Neural Machine Transliteration: Preliminary Results Abstract: Machine transliteration is the process of automatically transforming the\nscript of a word from a source language to a target language, while preserving\npronunciation. Sequence to sequence learning has recently emerged as a new\nparadigm in supervised learning. In this paper a character-based\nencoder-decoder model has been proposed that consists of two Recurrent Neural\nNetworks. The encoder is a Bidirectional recurrent neural network that encodes\na sequence of symbols into a fixed-length vector representation, and the\ndecoder generates the target sequence using an attention-based recurrent neural\nnetwork. The encoder, the decoder and the attention mechanism are jointly\ntrained to maximize the conditional probability of a target sequence given a\nsource sequence. Our experiments on different datasets show that the proposed\nencoder-decoder model is able to achieve significantly higher transliteration\nquality over traditional statistical models. \n\n"}
{"id": "1609.04309", "contents": "Title: Efficient softmax approximation for GPUs Abstract: We propose an approximate strategy to efficiently train neural network based\nlanguage models over very large vocabularies. Our approach, called adaptive\nsoftmax, circumvents the linear dependency on the vocabulary size by exploiting\nthe unbalanced word distribution to form clusters that explicitly minimize the\nexpectation of computation time. Our approach further reduces the computational\ntime by exploiting the specificities of modern architectures and matrix-matrix\nvector operations, making it particularly suited for graphical processing\nunits. Our experiments carried out on standard benchmarks, such as EuroParl and\nOne Billion Word, show that our approach brings a large gain in efficiency over\nstandard approximations while achieving an accuracy close to that of the full\nsoftmax. The code of our method is available at\nhttps://github.com/facebookresearch/adaptive-softmax. \n\n"}
{"id": "1609.05600", "contents": "Title: Graph-Structured Representations for Visual Question Answering Abstract: This paper proposes to improve visual question answering (VQA) with\nstructured representations of both scene contents and questions. A key\nchallenge in VQA is to require joint reasoning over the visual and text\ndomains. The predominant CNN/LSTM-based approach to VQA is limited by\nmonolithic vector representations that largely ignore structure in the scene\nand in the form of the question. CNN feature vectors cannot effectively capture\nsituations as simple as multiple object instances, and LSTMs process questions\nas series of words, which does not reflect the true complexity of language\nstructure. We instead propose to build graphs over the scene objects and over\nthe question words, and we describe a deep neural network that exploits the\nstructure in these representations. This shows significant benefit over the\nsequential processing of LSTMs. The overall efficacy of our approach is\ndemonstrated by significant improvements over the state-of-the-art, from 71.2%\nto 74.4% in accuracy on the \"abstract scenes\" multiple-choice benchmark, and\nfrom 34.7% to 39.1% in accuracy over pairs of \"balanced\" scenes, i.e. images\nwith fine-grained differences and opposite yes/no answers to a same question. \n\n"}
{"id": "1609.06686", "contents": "Title: Character-level and Multi-channel Convolutional Neural Networks for\n  Large-scale Authorship Attribution Abstract: Convolutional neural networks (CNNs) have demonstrated superior capability\nfor extracting information from raw signals in computer vision. Recently,\ncharacter-level and multi-channel CNNs have exhibited excellent performance for\nsentence classification tasks. We apply CNNs to large-scale authorship\nattribution, which aims to determine an unknown text's author among many\ncandidate authors, motivated by their ability to process character-level\nsignals and to differentiate between a large number of classes, while making\nfast predictions in comparison to state-of-the-art approaches. We extensively\nevaluate CNN-based approaches that leverage word and character channels and\ncompare them against state-of-the-art methods for a large range of author\nnumbers, shedding new light on traditional approaches. We show that\ncharacter-level CNNs outperform the state-of-the-art on four out of five\ndatasets in different domains. Additionally, we present the first application\nof authorship attribution to reddit. \n\n"}
{"id": "1609.07317", "contents": "Title: Language as a Latent Variable: Discrete Generative Models for Sentence\n  Compression Abstract: In this work we explore deep generative models of text in which the latent\nrepresentation of a document is itself drawn from a discrete language model\ndistribution. We formulate a variational auto-encoder for inference in this\nmodel and apply it to the task of compressing sentences. In this application\nthe generative model first draws a latent summary sentence from a background\nlanguage model, and then subsequently draws the observed sentence conditioned\non this latent summary. In our empirical evaluation we show that generative\nformulations of both abstractive and extractive compression yield\nstate-of-the-art results when trained on a large amount of supervised data.\nFurther, we explore semi-supervised compression scenarios where we show that it\nis possible to achieve performance competitive with previously proposed\nsupervised models while training on a fraction of the supervised data. \n\n"}
{"id": "1609.07561", "contents": "Title: Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser Abstract: We introduce two first-order graph-based dependency parsers achieving a new\nstate of the art. The first is a consensus parser built from an ensemble of\nindependently trained greedy LSTM transition-based parsers with different\nrandom initializations. We cast this approach as minimum Bayes risk decoding\n(under the Hamming cost) and argue that weaker consensus within the ensemble is\na useful signal of difficulty or ambiguity. The second parser is a\n\"distillation\" of the ensemble into a single model. We train the distillation\nparser using a structured hinge loss objective with a novel cost that\nincorporates ensemble uncertainty estimates for each possible attachment,\nthereby avoiding the intractable cross-entropy computations required by\napplying standard distillation objectives to problems with structured outputs.\nThe first-order distillation parser matches or surpasses the state of the art\non English, Chinese, and German. \n\n"}
{"id": "1609.07756", "contents": "Title: A Factorized Model for Transitive Verbs in Compositional Distributional\n  Semantics Abstract: We present a factorized compositional distributional semantics model for the\nrepresentation of transitive verb constructions. Our model first produces\n(subject, verb) and (verb, object) vector representations based on the\nsimilarity of the nouns in the construction to each of the nouns in the\nvocabulary and the tendency of these nouns to take the subject and object roles\nof the verb. These vectors are then combined into a final (subject,verb,object)\nrepresentation through simple vector operations. On two established tasks for\nthe transitive verb construction our model outperforms recent previous work. \n\n"}
{"id": "1609.08337", "contents": "Title: Multi-task Recurrent Model for True Multilingual Speech Recognition Abstract: Research on multilingual speech recognition remains attractive yet\nchallenging. Recent studies focus on learning shared structures under the\nmulti-task paradigm, in particular a feature sharing structure. This approach\nhas been found effective to improve performance on each individual language.\nHowever, this approach is only useful when the deployed system supports just\none language. In a true multilingual scenario where multiple languages are\nallowed, performance will be significantly reduced due to the competition among\nlanguages in the decoding space. This paper presents a multi-task recurrent\nmodel that involves a multilingual speech recognition (ASR) component and a\nlanguage recognition (LR) component, and the ASR component is informed of the\nlanguage information by the LR component, leading to a language-aware\nrecognition. We tested the approach on an English-Chinese bilingual recognition\ntask. The results show that the proposed multi-task recurrent model can improve\nperformance of multilingual recognition systems. \n\n"}
{"id": "1609.08667", "contents": "Title: Deep Reinforcement Learning for Mention-Ranking Coreference Models Abstract: Coreference resolution systems are typically trained with heuristic loss\nfunctions that require careful tuning. In this paper we instead apply\nreinforcement learning to directly optimize a neural mention-ranking model for\ncoreference evaluation metrics. We experiment with two approaches: the\nREINFORCE policy gradient algorithm and a reward-rescaled max-margin objective.\nWe find the latter to be more effective, resulting in significant improvements\nover the current state-of-the-art on the English and Chinese portions of the\nCoNLL 2012 Shared Task. \n\n"}
{"id": "1609.08703", "contents": "Title: Optimizing Neural Network Hyperparameters with Gaussian Processes for\n  Dialog Act Classification Abstract: Systems based on artificial neural networks (ANNs) have achieved\nstate-of-the-art results in many natural language processing tasks. Although\nANNs do not require manually engineered features, ANNs have many\nhyperparameters to be optimized. The choice of hyperparameters significantly\nimpacts models' performances. However, the ANN hyperparameters are typically\nchosen by manual, grid, or random search, which either requires expert\nexperiences or is computationally expensive. Recent approaches based on\nBayesian optimization using Gaussian processes (GPs) is a more systematic way\nto automatically pinpoint optimal or near-optimal machine learning\nhyperparameters. Using a previously published ANN model yielding\nstate-of-the-art results for dialog act classification, we demonstrate that\noptimizing hyperparameters using GP further improves the results, and reduces\nthe computational time by a factor of 4 compared to a random search. Therefore\nit is a useful technique for tuning ANN models to yield the best performances\nfor natural language processing tasks. \n\n"}
{"id": "1609.09315", "contents": "Title: Semantic Parsing with Semi-Supervised Sequential Autoencoders Abstract: We present a novel semi-supervised approach for sequence transduction and\napply it to semantic parsing. The unsupervised component is based on a\ngenerative model in which latent sentences generate the unpaired logical forms.\nWe apply this method to a number of semantic parsing tasks focusing on domains\nwith limited access to labelled training data and extend those datasets with\nsynthetically generated logical forms. \n\n"}
{"id": "1610.00388", "contents": "Title: Learning to Translate in Real-time with Neural Machine Translation Abstract: Translating in real-time, a.k.a. simultaneous translation, outputs\ntranslation words before the input sentence ends, which is a challenging\nproblem for conventional machine translation methods. We propose a neural\nmachine translation (NMT) framework for simultaneous translation in which an\nagent learns to make decisions on when to translate from the interaction with a\npre-trained NMT environment. To trade off quality and delay, we extensively\nexplore various targets for delay and design a method for beam-search\napplicable in the simultaneous MT setting. Experiments against state-of-the-art\nbaselines on two language pairs demonstrate the efficacy of the proposed\nframework both quantitatively and qualitatively. \n\n"}
{"id": "1610.02003", "contents": "Title: Scalable Machine Translation in Memory Constrained Environments Abstract: Machine translation is the discipline concerned with developing automated\ntools for translating from one human language to another. Statistical machine\ntranslation (SMT) is the dominant paradigm in this field. In SMT, translations\nare generated by means of statistical models whose parameters are learned from\nbilingual data. Scalability is a key concern in SMT, as one would like to make\nuse of as much data as possible to train better translation systems.\n  In recent years, mobile devices with adequate computing power have become\nwidely available. Despite being very successful, mobile applications relying on\nNLP systems continue to follow a client-server architecture, which is of\nlimited use because access to internet is often limited and expensive. The goal\nof this dissertation is to show how to construct a scalable machine translation\nsystem that can operate with the limited resources available on a mobile\ndevice.\n  The main challenge for porting translation systems on mobile devices is\nmemory usage. The amount of memory available on a mobile device is far less\nthan what is typically available on the server side of a client-server\napplication. In this thesis, we investigate alternatives for the two components\nwhich prevent standard translation systems from working on mobile devices due\nto high memory usage. We show that once these standard components are replaced\nwith our proposed alternatives, we obtain a scalable translation system that\ncan work on a device with limited memory. \n\n"}
{"id": "1610.02692", "contents": "Title: Open-Ended Visual Question-Answering Abstract: This thesis report studies methods to solve Visual Question-Answering (VQA)\ntasks with a Deep Learning framework. As a preliminary step, we explore Long\nShort-Term Memory (LSTM) networks used in Natural Language Processing (NLP) to\ntackle Question-Answering (text based). We then modify the previous model to\naccept an image as an input in addition to the question. For this purpose, we\nexplore the VGG-16 and K-CNN convolutional neural networks to extract visual\nfeatures from the image. These are merged with the word embedding or with a\nsentence embedding of the question to predict the answer. This work was\nsuccessfully submitted to the Visual Question Answering Challenge 2016, where\nit achieved a 53,62% of accuracy in the test dataset. The developed software\nhas followed the best programming practices and Python code style, providing a\nconsistent baseline in Keras for different configurations. \n\n"}
{"id": "1610.02749", "contents": "Title: A Dynamic Window Neural Network for CCG Supertagging Abstract: Combinatory Category Grammar (CCG) supertagging is a task to assign lexical\ncategories to each word in a sentence. Almost all previous methods use fixed\ncontext window sizes as input features. However, it is obvious that different\ntags usually rely on different context window sizes. These motivate us to build\na supertagger with a dynamic window approach, which can be treated as an\nattention mechanism on the local contexts. Applying dropout on the dynamic\nfilters can be seen as drop on words directly, which is superior to the regular\ndropout on word embeddings. We use this approach to demonstrate the\nstate-of-the-art CCG supertagging performance on the standard test set. \n\n"}
{"id": "1610.02891", "contents": "Title: Personalizing a Dialogue System with Transfer Reinforcement Learning Abstract: It is difficult to train a personalized task-oriented dialogue system because\nthe data collected from each individual is often insufficient. Personalized\ndialogue systems trained on a small dataset can overfit and make it difficult\nto adapt to different user needs. One way to solve this problem is to consider\na collection of multiple users' data as a source domain and an individual\nuser's data as a target domain, and to perform a transfer learning from the\nsource to the target domain. By following this idea, we propose\n\"PETAL\"(PErsonalized Task-oriented diALogue), a transfer-learning framework\nbased on POMDP to learn a personalized dialogue system. The system first learns\ncommon dialogue knowledge from the source domain and then adapts this knowledge\nto the target user. This framework can avoid the negative transfer problem by\nconsidering differences between source and target users. The policy in the\npersonalized POMDP can learn to choose different actions appropriately for\ndifferent users. Experimental results on a real-world coffee-shopping data and\nsimulation data show that our personalized dialogue system can choose different\noptimal actions for different users, and thus effectively improve the dialogue\nquality under the personalized setting. \n\n"}
{"id": "1610.03017", "contents": "Title: Fully Character-Level Neural Machine Translation without Explicit\n  Segmentation Abstract: Most existing machine translation systems operate at the level of words,\nrelying on explicit segmentation to extract tokens. We introduce a neural\nmachine translation (NMT) model that maps a source character sequence to a\ntarget character sequence without any segmentation. We employ a character-level\nconvolutional network with max-pooling at the encoder to reduce the length of\nsource representation, allowing the model to be trained at a speed comparable\nto subword-level models while capturing local regularities. Our\ncharacter-to-character model outperforms a recently proposed baseline with a\nsubword-level encoder on WMT'15 DE-EN and CS-EN, and gives comparable\nperformance on FI-EN and RU-EN. We then demonstrate that it is possible to\nshare a single character-level encoder across multiple languages by training a\nmodel on a many-to-one translation task. In this multilingual setting, the\ncharacter-level encoder significantly outperforms the subword-level encoder on\nall the language pairs. We observe that on CS-EN, FI-EN and RU-EN, the quality\nof the multilingual character-level translation even surpasses the models\nspecifically trained on that language pair alone, both in terms of BLEU score\nand human judgment. \n\n"}
{"id": "1610.03946", "contents": "Title: A Neural Network for Coordination Boundary Prediction Abstract: We propose a neural-network based model for coordination boundary prediction.\nThe network is designed to incorporate two signals: the similarity between\nconjuncts and the observation that replacing the whole coordination phrase with\na conjunct tends to produce a coherent sentences. The modeling makes use of\nseveral LSTM networks. The model is trained solely on conjunction annotations\nin a Treebank, without using external resources. We show improvements on\npredicting coordination boundaries on the PTB compared to two state-of-the-art\nparsers; as well as improvement over previous coordination boundary prediction\nsystems on the Genia corpus. \n\n"}
{"id": "1610.05256", "contents": "Title: Achieving Human Parity in Conversational Speech Recognition Abstract: Conversational speech recognition has served as a flagship speech recognition\ntask since the release of the Switchboard corpus in the 1990s. In this paper,\nwe measure the human error rate on the widely used NIST 2000 test set, and find\nthat our latest automated system has reached human parity. The error rate of\nprofessional transcribers is 5.9% for the Switchboard portion of the data, in\nwhich newly acquainted pairs of people discuss an assigned topic, and 11.3% for\nthe CallHome portion where friends and family members have open-ended\nconversations. In both cases, our automated system establishes a new state of\nthe art, and edges past the human benchmark, achieving error rates of 5.8% and\n11.0%, respectively. The key to our system's performance is the use of various\nconvolutional and LSTM acoustic model architectures, combined with a novel\nspatial smoothing method and lattice-free MMI acoustic training, multiple\nrecurrent neural network language modeling approaches, and a systematic use of\nsystem combination. \n\n"}
{"id": "1610.05812", "contents": "Title: Small-footprint Highway Deep Neural Networks for Speech Recognition Abstract: State-of-the-art speech recognition systems typically employ neural network\nacoustic models. However, compared to Gaussian mixture models, deep neural\nnetwork (DNN) based acoustic models often have many more model parameters,\nmaking it challenging for them to be deployed on resource-constrained\nplatforms, such as mobile devices. In this paper, we study the application of\nthe recently proposed highway deep neural network (HDNN) for training\nsmall-footprint acoustic models. HDNNs are a depth-gated feedforward neural\nnetwork, which include two types of gate functions to facilitate the\ninformation flow through different layers. Our study demonstrates that HDNNs\nare more compact than regular DNNs for acoustic modeling, i.e., they can\nachieve comparable recognition accuracy with many fewer model parameters.\nFurthermore, HDNNs are more controllable than DNNs: the gate functions of an\nHDNN can control the behavior of the whole network using a very small number of\nmodel parameters. Finally, we show that HDNNs are more adaptable than DNNs. For\nexample, simply updating the gate functions using adaptation data can result in\nconsiderable gains in accuracy. We demonstrate these aspects by experiments\nusing the publicly available AMI corpus, which has around 80 hours of training\ndata. \n\n"}
{"id": "1610.05858", "contents": "Title: Bidirectional LSTM-CRF for Clinical Concept Extraction Abstract: Extraction of concepts present in patient clinical records is an essential\nstep in clinical research. The 2010 i2b2/VA Workshop on Natural Language\nProcessing Challenges for clinical records presented concept extraction (CE)\ntask, with aim to identify concepts (such as treatments, tests, problems) and\nclassify them into predefined categories. State-of-the-art CE approaches\nheavily rely on hand crafted features and domain specific resources which are\nhard to collect and tune. For this reason, this paper employs bidirectional\nLSTM with CRF decoding initialized with general purpose off-the-shelf word\nembeddings for CE. The experimental results achieved on 2010 i2b2/VA reference\nstandard corpora using bidirectional LSTM CRF ranks closely with top ranked\nsystems. \n\n"}
{"id": "1610.06053", "contents": "Title: Chinese Restaurant Process for cognate clustering: A threshold free\n  approach Abstract: In this paper, we introduce a threshold free approach, motivated from Chinese\nRestaurant Process, for the purpose of cognate clustering. We show that our\napproach yields similar results to a linguistically motivated cognate\nclustering system known as LexStat. Our Chinese Restaurant Process system is\nfast and does not require any threshold and can be applied to any language\nfamily of the world. \n\n"}
{"id": "1610.06540", "contents": "Title: Jointly Learning to Align and Convert Graphemes to Phonemes with Neural\n  Attention Models Abstract: We propose an attention-enabled encoder-decoder model for the problem of\ngrapheme-to-phoneme conversion. Most previous work has tackled the problem via\njoint sequence models that require explicit alignments for training. In\ncontrast, the attention-enabled encoder-decoder model allows for jointly\nlearning to align and convert characters to phonemes. We explore different\ntypes of attention models, including global and local attention, and our best\nmodels achieve state-of-the-art results on three standard data sets (CMUDict,\nPronlex, and NetTalk). \n\n"}
{"id": "1610.07149", "contents": "Title: Two are Better than One: An Ensemble of Retrieval- and Generation-Based\n  Dialog Systems Abstract: Open-domain human-computer conversation has attracted much attention in the\nfield of NLP. Contrary to rule- or template-based domain-specific dialog\nsystems, open-domain conversation usually requires data-driven approaches,\nwhich can be roughly divided into two categories: retrieval-based and\ngeneration-based systems. Retrieval systems search a user-issued utterance\n(called a query) in a large database, and return a reply that best matches the\nquery. Generative approaches, typically based on recurrent neural networks\n(RNNs), can synthesize new replies, but they suffer from the problem of\ngenerating short, meaningless utterances. In this paper, we propose a novel\nensemble of retrieval-based and generation-based dialog systems in the open\ndomain. In our approach, the retrieved candidate, in addition to the original\nquery, is fed to an RNN-based reply generator, so that the neural model is\naware of more information. The generated reply is then fed back as a new\ncandidate for post-reranking. Experimental results show that such ensemble\noutperforms each single part of it by a large margin. \n\n"}
{"id": "1610.07651", "contents": "Title: UTD-CRSS Systems for 2016 NIST Speaker Recognition Evaluation Abstract: This document briefly describes the systems submitted by the Center for\nRobust Speech Systems (CRSS) from The University of Texas at Dallas (UTD) to\nthe 2016 National Institute of Standards and Technology (NIST) Speaker\nRecognition Evaluation (SRE). We developed several UBM and DNN i-Vector based\nspeaker recognition systems with different data sets and feature\nrepresentations. Given that the emphasis of the NIST SRE 2016 is on language\nmismatch between training and enrollment/test data, so-called domain mismatch,\nin our system development we focused on: (1) using unlabeled in-domain data for\ncentralizing data to alleviate the domain mismatch problem, (2) finding the\nbest data set for training LDA/PLDA, (3) using newly proposed dimension\nreduction technique incorporating unlabeled in-domain data before PLDA\ntraining, (4) unsupervised speaker clustering of unlabeled data and using them\nalone or with previous SREs for PLDA training, (5) score calibration using only\nunlabeled data and combination of unlabeled and development (Dev) data as\nseparate experiments. \n\n"}
{"id": "1610.09158", "contents": "Title: Towards a continuous modeling of natural language domains Abstract: Humans continuously adapt their style and language to a variety of domains.\nHowever, a reliable definition of `domain' has eluded researchers thus far.\nAdditionally, the notion of discrete domains stands in contrast to the\nmultiplicity of heterogeneous domains that humans navigate, many of which\noverlap. In order to better understand the change and variation of human\nlanguage, we draw on research in domain adaptation and extend the notion of\ndiscrete domains to the continuous spectrum. We propose representation\nlearning-based models that can adapt to continuous domains and detail how these\ncan be used to investigate variation in language. To this end, we propose to\nuse dialogue modeling as a test bed due to its proximity to language modeling\nand its social component. \n\n"}
{"id": "1610.10099", "contents": "Title: Neural Machine Translation in Linear Time Abstract: We present a novel neural network for processing sequences. The ByteNet is a\none-dimensional convolutional neural network that is composed of two parts, one\nto encode the source sequence and the other to decode the target sequence. The\ntwo network parts are connected by stacking the decoder on top of the encoder\nand preserving the temporal resolution of the sequences. To address the\ndiffering lengths of the source and the target, we introduce an efficient\nmechanism by which the decoder is dynamically unfolded over the representation\nof the encoder. The ByteNet uses dilation in the convolutional layers to\nincrease its receptive field. The resulting network has two core properties: it\nruns in time that is linear in the length of the sequences and it sidesteps the\nneed for excessive memorization. The ByteNet decoder attains state-of-the-art\nperformance on character-level language modelling and outperforms the previous\nbest results obtained with recurrent networks. The ByteNet also achieves\nstate-of-the-art performance on character-to-character machine translation on\nthe English-to-German WMT translation task, surpassing comparable neural\ntranslation models that are based on recurrent networks with attentional\npooling and run in quadratic time. We find that the latent alignment structure\ncontained in the representations reflects the expected alignment between the\ntokens. \n\n"}
{"id": "1611.01186", "contents": "Title: Demystifying ResNet Abstract: The Residual Network (ResNet), proposed in He et al. (2015), utilized\nshortcut connections to significantly reduce the difficulty of training, which\nresulted in great performance boosts in terms of both training and\ngeneralization error.\n  It was empirically observed in He et al. (2015) that stacking more layers of\nresidual blocks with shortcut 2 results in smaller training error, while it is\nnot true for shortcut of length 1 or 3. We provide a theoretical explanation\nfor the uniqueness of shortcut 2.\n  We show that with or without nonlinearities, by adding shortcuts that have\ndepth two, the condition number of the Hessian of the loss function at the zero\ninitial point is depth-invariant, which makes training very deep models no more\ndifficult than shallow ones. Shortcuts of higher depth result in an extremely\nflat (high-order) stationary point initially, from which the optimization\nalgorithm is hard to escape. The shortcut 1, however, is essentially equivalent\nto no shortcuts, which has a condition number exploding to infinity as the\nnumber of layers grows. We further argue that as the number of layers tends to\ninfinity, it suffices to only look at the loss function at the zero initial\npoint.\n  Extensive experiments are provided accompanying our theoretical results. We\nshow that initializing the network to small weights with shortcut 2 achieves\nsignificantly better results than random Gaussian (Xavier) initialization,\northogonal initialization, and shortcuts of deeper depth, from various\nperspectives ranging from final loss, learning dynamics and stability, to the\nbehavior of the Hessian along the learning process. \n\n"}
{"id": "1611.01487", "contents": "Title: Morphological Inflection Generation with Hard Monotonic Attention Abstract: We present a neural model for morphological inflection generation which\nemploys a hard attention mechanism, inspired by the nearly-monotonic alignment\ncommonly found between the characters in a word and the characters in its\ninflection. We evaluate the model on three previously studied morphological\ninflection generation datasets and show that it provides state of the art\nresults in various setups compared to previous neural and non-neural\napproaches. Finally we present an analysis of the continuous representations\nlearned by both the hard and soft attention \\cite{bahdanauCB14} models for the\ntask, shedding some light on the features such models extract. \n\n"}
{"id": "1611.01547", "contents": "Title: Automated Generation of Multilingual Clusters for the Evaluation of\n  Distributed Representations Abstract: We propose a language-agnostic way of automatically generating sets of\nsemantically similar clusters of entities along with sets of \"outlier\"\nelements, which may then be used to perform an intrinsic evaluation of word\nembeddings in the outlier detection task. We used our methodology to create a\ngold-standard dataset, which we call WikiSem500, and evaluated multiple\nstate-of-the-art embeddings. The results show a correlation between performance\non this dataset and performance on sentiment analysis. \n\n"}
{"id": "1611.01576", "contents": "Title: Quasi-Recurrent Neural Networks Abstract: Recurrent neural networks are a powerful tool for modeling sequential data,\nbut the dependence of each timestep's computation on the previous timestep's\noutput limits parallelism and makes RNNs unwieldy for very long sequences. We\nintroduce quasi-recurrent neural networks (QRNNs), an approach to neural\nsequence modeling that alternates convolutional layers, which apply in parallel\nacross timesteps, and a minimalist recurrent pooling function that applies in\nparallel across channels. Despite lacking trainable recurrent layers, stacked\nQRNNs have better predictive accuracy than stacked LSTMs of the same hidden\nsize. Due to their increased parallelism, they are up to 16 times faster at\ntrain and test time. Experiments on language modeling, sentiment\nclassification, and character-level neural machine translation demonstrate\nthese advantages and underline the viability of QRNNs as a basic building block\nfor a variety of sequence tasks. \n\n"}
{"id": "1611.01587", "contents": "Title: A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks Abstract: Transfer and multi-task learning have traditionally focused on either a\nsingle source-target pair or very few, similar tasks. Ideally, the linguistic\nlevels of morphology, syntax and semantics would benefit each other by being\ntrained in a single model. We introduce a joint many-task model together with a\nstrategy for successively growing its depth to solve increasingly complex\ntasks. Higher layers include shortcut connections to lower-level task\npredictions to reflect linguistic hierarchies. We use a simple regularization\nterm to allow for optimizing all model weights to improve one task's loss\nwithout exhibiting catastrophic interference of the other tasks. Our single\nend-to-end model obtains state-of-the-art or competitive results on five\ndifferent tasks from tagging, parsing, relatedness, and entailment tasks. \n\n"}
{"id": "1611.01599", "contents": "Title: LipNet: End-to-End Sentence-level Lipreading Abstract: Lipreading is the task of decoding text from the movement of a speaker's\nmouth. Traditional approaches separated the problem into two stages: designing\nor learning visual features, and prediction. More recent deep lipreading\napproaches are end-to-end trainable (Wand et al., 2016; Chung & Zisserman,\n2016a). However, existing work on models trained end-to-end perform only word\nclassification, rather than sentence-level sequence prediction. Studies have\nshown that human lipreading performance increases for longer words (Easton &\nBasala, 1982), indicating the importance of features capturing temporal context\nin an ambiguous communication channel. Motivated by this observation, we\npresent LipNet, a model that maps a variable-length sequence of video frames to\ntext, making use of spatiotemporal convolutions, a recurrent network, and the\nconnectionist temporal classification loss, trained entirely end-to-end. To the\nbest of our knowledge, LipNet is the first end-to-end sentence-level lipreading\nmodel that simultaneously learns spatiotemporal visual features and a sequence\nmodel. On the GRID corpus, LipNet achieves 95.2% accuracy in sentence-level,\noverlapped speaker split task, outperforming experienced human lipreaders and\nthe previous 86.4% word-level state-of-the-art accuracy (Gergen et al., 2016). \n\n"}
{"id": "1611.02654", "contents": "Title: Sentence Ordering and Coherence Modeling using Recurrent Neural Networks Abstract: Modeling the structure of coherent texts is a key NLP problem. The task of\ncoherently organizing a given set of sentences has been commonly used to build\nand evaluate models that understand such structure. We propose an end-to-end\nunsupervised deep learning approach based on the set-to-sequence framework to\naddress this problem. Our model strongly outperforms prior methods in the order\ndiscrimination task and a novel task of ordering abstracts from scientific\narticles. Furthermore, our work shows that useful text representations can be\nobtained by learning to order sentences. Visualizing the learned sentence\nrepresentations shows that the model captures high-level logical structure in\nparagraphs. Our representations perform comparably to state-of-the-art\npre-training methods on sentence similarity and paraphrase detection tasks. \n\n"}
{"id": "1611.03218", "contents": "Title: Learning to Play Guess Who? and Inventing a Grounded Language as a\n  Consequence Abstract: Acquiring your first language is an incredible feat and not easily\nduplicated. Learning to communicate using nothing but a few pictureless books,\na corpus, would likely be impossible even for humans. Nevertheless, this is the\ndominating approach in most natural language processing today. As an\nalternative, we propose the use of situated interactions between agents as a\ndriving force for communication, and the framework of Deep Recurrent Q-Networks\nfor evolving a shared language grounded in the provided environment. We task\nthe agents with interactive image search in the form of the game Guess Who?.\nThe images from the game provide a non trivial environment for the agents to\ndiscuss and a natural grounding for the concepts they decide to encode in their\ncommunication. Our experiments show that the agents learn not only to encode\nphysical concepts in their words, i.e. grounding, but also that the agents\nlearn to hold a multi-step dialogue remembering the state of the dialogue from\nstep to step. \n\n"}
{"id": "1611.03596", "contents": "Title: Generalized Entropies and the Similarity of Texts Abstract: We show how generalized Gibbs-Shannon entropies can provide new insights on\nthe statistical properties of texts. The universal distribution of word\nfrequencies (Zipf's law) implies that the generalized entropies, computed at\nthe word level, are dominated by words in a specific range of frequencies. Here\nwe show that this is the case not only for the generalized entropies but also\nfor the generalized (Jensen-Shannon) divergences, used to compute the\nsimilarity between different texts. This finding allows us to identify the\ncontribution of specific words (and word frequencies) for the different\ngeneralized entropies and also to estimate the size of the databases needed to\nobtain a reliable estimation of the divergences. We test our results in large\ndatabases of books (from the Google n-gram database) and scientific papers\n(indexed by Web of Science). \n\n"}
{"id": "1611.04558", "contents": "Title: Google's Multilingual Neural Machine Translation System: Enabling\n  Zero-Shot Translation Abstract: We propose a simple solution to use a single Neural Machine Translation (NMT)\nmodel to translate between multiple languages. Our solution requires no change\nin the model architecture from our base system but instead introduces an\nartificial token at the beginning of the input sentence to specify the required\ntarget language. The rest of the model, which includes encoder, decoder and\nattention, remains unchanged and is shared across all languages. Using a shared\nwordpiece vocabulary, our approach enables Multilingual NMT using a single\nmodel without any increase in parameters, which is significantly simpler than\nprevious proposals for Multilingual NMT. Our method often improves the\ntranslation quality of all involved language pairs, even while keeping the\ntotal number of model parameters constant. On the WMT'14 benchmarks, a single\nmultilingual model achieves comparable performance for\nEnglish$\\rightarrow$French and surpasses state-of-the-art results for\nEnglish$\\rightarrow$German. Similarly, a single multilingual model surpasses\nstate-of-the-art results for French$\\rightarrow$English and\nGerman$\\rightarrow$English on WMT'14 and WMT'15 benchmarks respectively. On\nproduction corpora, multilingual models of up to twelve language pairs allow\nfor better translation of many individual pairs. In addition to improving the\ntranslation quality of language pairs that the model was trained with, our\nmodels can also learn to perform implicit bridging between language pairs never\nseen explicitly during training, showing that transfer learning and zero-shot\ntranslation is possible for neural translation. Finally, we show analyses that\nhints at a universal interlingua representation in our models and show some\ninteresting examples when mixing languages. \n\n"}
{"id": "1611.04741", "contents": "Title: A Neural Architecture Mimicking Humans End-to-End for Natural Language\n  Inference Abstract: In this work we use the recent advances in representation learning to propose\na neural architecture for the problem of natural language inference. Our\napproach is aligned to mimic how a human does the natural language inference\nprocess given two statements. The model uses variants of Long Short Term Memory\n(LSTM), attention mechanism and composable neural networks, to carry out the\ntask. Each part of our model can be mapped to a clear functionality humans do\nfor carrying out the overall task of natural language inference. The model is\nend-to-end differentiable enabling training by stochastic gradient descent. On\nStanford Natural Language Inference(SNLI) dataset, the proposed model achieves\nbetter accuracy numbers than all published models in literature. \n\n"}
{"id": "1611.04798", "contents": "Title: Toward Multilingual Neural Machine Translation with Universal Encoder\n  and Decoder Abstract: In this paper, we present our first attempts in building a multilingual\nNeural Machine Translation framework under a unified approach. We are then able\nto employ attention-based NMT for many-to-many multilingual translation tasks.\nOur approach does not require any special treatment on the network architecture\nand it allows us to learn minimal number of free parameters in a standard way\nof training. Our approach has shown its effectiveness in an under-resourced\ntranslation scenario with considerable improvements up to 2.6 BLEU points. In\naddition, the approach has achieved interesting and promising results when\napplied in the translation task that there is no direct parallel corpus between\nsource and target languages. \n\n"}
{"id": "1611.04928", "contents": "Title: Neural Machine Translation with Pivot Languages Abstract: While recent neural machine translation approaches have delivered\nstate-of-the-art performance for resource-rich language pairs, they suffer from\nthe data scarcity problem for resource-scarce language pairs. Although this\nproblem can be alleviated by exploiting a pivot language to bridge the source\nand target languages, the source-to-pivot and pivot-to-target translation\nmodels are usually independently trained. In this work, we introduce a joint\ntraining algorithm for pivot-based neural machine translation. We propose three\nmethods to connect the two models and enable them to interact with each other\nduring training. Experiments on Europarl and WMT corpora show that joint\ntraining of source-to-pivot and pivot-to-target models leads to significant\nimprovements over independent training across various languages. \n\n"}
{"id": "1611.05384", "contents": "Title: A Feature-Enriched Neural Model for Joint Chinese Word Segmentation and\n  Part-of-Speech Tagging Abstract: Recently, neural network models for natural language processing tasks have\nbeen increasingly focused on for their ability of alleviating the burden of\nmanual feature engineering. However, the previous neural models cannot extract\nthe complicated feature compositions as the traditional methods with discrete\nfeatures. In this work, we propose a feature-enriched neural model for joint\nChinese word segmentation and part-of-speech tagging task. Specifically, to\nsimulate the feature templates of traditional discrete feature based models, we\nuse different filters to model the complex compositional features with\nconvolutional and pooling layer, and then utilize long distance dependency\ninformation with recurrent layer. Experimental results on five different\ndatasets show the effectiveness of our proposed model. \n\n"}
{"id": "1611.06204", "contents": "Title: Visualizing and Understanding Curriculum Learning for Long Short-Term\n  Memory Networks Abstract: Curriculum Learning emphasizes the order of training instances in a\ncomputational learning setup. The core hypothesis is that simpler instances\nshould be learned early as building blocks to learn more complex ones. Despite\nits usefulness, it is still unknown how exactly the internal representation of\nmodels are affected by curriculum learning. In this paper, we study the effect\nof curriculum learning on Long Short-Term Memory (LSTM) networks, which have\nshown strong competency in many Natural Language Processing (NLP) problems. Our\nexperiments on sentiment analysis task and a synthetic task similar to sequence\nprediction tasks in NLP show that curriculum learning has a positive effect on\nthe LSTM's internal states by biasing the model towards building constructive\nrepresentations i.e. the internal representation at the previous timesteps are\nused as building blocks for the final prediction. We also find that smaller\nmodels significantly improves when they are trained with curriculum learning.\nLastly, we show that curriculum learning helps more when the amount of training\ndata is limited. \n\n"}
{"id": "1611.06722", "contents": "Title: False-Friend Detection and Entity Matching via Unsupervised\n  Transliteration Abstract: Transliterations play an important role in multilingual entity reference\nresolution, because proper names increasingly travel between languages in news\nand social media. Previous work associated with machine translation targets\ntransliteration only single between language pairs, focuses on specific classes\nof entities (such as cities and celebrities) and relies on manual curation,\nwhich limits the expression power of transliteration in multilingual\nenvironment.\n  By contrast, we present an unsupervised transliteration model covering 69\nmajor languages that can generate good transliterations for arbitrary strings\nbetween any language pair. Our model yields top-(1, 20, 100) averages of\n(32.85%, 60.44%, 83.20%) in matching gold standard transliteration compared to\nresults from a recently-published system of (26.71%, 50.27%, 72.79%). We also\nshow the quality of our model in detecting true and false friends from\nWikipedia high frequency lexicons. Our method indicates a strong signal of\npronunciation similarity and boosts the probability of finding true friends in\n68 out of 69 languages. \n\n"}
{"id": "1611.06986", "contents": "Title: Robust end-to-end deep audiovisual speech recognition Abstract: Speech is one of the most effective ways of communication among humans. Even\nthough audio is the most common way of transmitting speech, very important\ninformation can be found in other modalities, such as vision. Vision is\nparticularly useful when the acoustic signal is corrupted. Multi-modal speech\nrecognition however has not yet found wide-spread use, mostly because the\ntemporal alignment and fusion of the different information sources is\nchallenging.\n  This paper presents an end-to-end audiovisual speech recognizer (AVSR), based\non recurrent neural networks (RNN) with a connectionist temporal classification\n(CTC) loss function. CTC creates sparse \"peaky\" output activations, and we\nanalyze the differences in the alignments of output targets (phonemes or\nvisemes) between audio-only, video-only, and audio-visual feature\nrepresentations. We present the first such experiments on the large vocabulary\nIBM ViaVoice database, which outperform previously published approaches on\nphone accuracy in clean and noisy conditions. \n\n"}
{"id": "1611.08096", "contents": "Title: User Personalized Satisfaction Prediction via Multiple Instance Deep\n  Learning Abstract: Community based question answering services have arisen as a popular\nknowledge sharing pattern for netizens. With abundant interactions among users,\nindividuals are capable of obtaining satisfactory information. However, it is\nnot effective for users to attain answers within minutes. Users have to check\nthe progress over time until the satisfying answers submitted. We address this\nproblem as a user personalized satisfaction prediction task. Existing methods\nusually exploit manual feature selection. It is not desirable as it requires\ncareful design and is labor intensive. In this paper, we settle this issue by\ndeveloping a new multiple instance deep learning framework. Specifically, in\nour settings, each question follows a weakly supervised learning multiple\ninstance learning assumption, where its obtained answers can be regarded as\ninstance sets and we define the question resolved with at least one\nsatisfactory answer. We thus design an efficient framework exploiting multiple\ninstance learning property with deep learning to model the question answer\npairs. Extensive experiments on large scale datasets from Stack Exchange\ndemonstrate the feasibility of our proposed framework in predicting askers\npersonalized satisfaction. Our framework can be extended to numerous\napplications such as UI satisfaction Prediction, multi armed bandit problem,\nexpert finding and so on. \n\n"}
{"id": "1611.08562", "contents": "Title: A Simple, Fast Diverse Decoding Algorithm for Neural Generation Abstract: In this paper, we propose a simple, fast decoding algorithm that fosters\ndiversity in neural generation. The algorithm modifies the standard beam search\nalgorithm by adding an inter-sibling ranking penalty, favoring choosing\nhypotheses from diverse parents. We evaluate the proposed model on the tasks of\ndialogue response generation, abstractive summarization and machine\ntranslation. We find that diverse decoding helps across all tasks, especially\nthose for which reranking is needed.\n  We further propose a variation that is capable of automatically adjusting its\ndiversity decoding rates for different inputs using reinforcement learning\n(RL). We observe a further performance boost from this RL technique. This paper\nincludes material from the unpublished script \"Mutual Information and Diverse\nDecoding Improve Neural Machine Translation\" (Li and Jurafsky, 2016). \n\n"}
{"id": "1611.08656", "contents": "Title: Attention-based Memory Selection Recurrent Network for Language Modeling Abstract: Recurrent neural networks (RNNs) have achieved great success in language\nmodeling. However, since the RNNs have fixed size of memory, their memory\ncannot store all the information about the words it have seen before in the\nsentence, and thus the useful long-term information may be ignored when\npredicting the next words. In this paper, we propose Attention-based Memory\nSelection Recurrent Network (AMSRN), in which the model can review the\ninformation stored in the memory at each previous time step and select the\nrelevant information to help generate the outputs. In AMSRN, the attention\nmechanism finds the time steps storing the relevant information in the memory,\nand memory selection determines which dimensions of the memory are involved in\ncomputing the attention weights and from which the information is extracted.In\nthe experiments, AMSRN outperformed long short-term memory (LSTM) based\nlanguage models on both English and Chinese corpora. Moreover, we investigate\nusing entropy as a regularizer for attention weights and visualize how the\nattention mechanism helps language modeling. \n\n"}
{"id": "1611.08661", "contents": "Title: Knowledge Graph Representation with Jointly Structural and Textual\n  Encoding Abstract: The objective of knowledge graph embedding is to encode both entities and\nrelations of knowledge graphs into continuous low-dimensional vector spaces.\nPreviously, most works focused on symbolic representation of knowledge graph\nwith structure information, which can not handle new entities or entities with\nfew facts well. In this paper, we propose a novel deep architecture to utilize\nboth structural and textual information of entities. Specifically, we introduce\nthree neural models to encode the valuable information from text description of\nentity, among which an attentive model can select related information as\nneeded. Then, a gating mechanism is applied to integrate representations of\nstructure and text into a unified architecture. Experiments show that our\nmodels outperform baseline by margin on link prediction and triplet\nclassification tasks. Source codes of this paper will be available on Github. \n\n"}
{"id": "1611.09288", "contents": "Title: Dense Prediction on Sequences with Time-Dilated Convolutions for Speech\n  Recognition Abstract: In computer vision pixelwise dense prediction is the task of predicting a\nlabel for each pixel in the image. Convolutional neural networks achieve good\nperformance on this task, while being computationally efficient. In this paper\nwe carry these ideas over to the problem of assigning a sequence of labels to a\nset of speech frames, a task commonly known as framewise classification. We\nshow that dense prediction view of framewise classification offers several\nadvantages and insights, including computational efficiency and the ability to\napply batch normalization. When doing dense prediction we pay specific\nattention to strided pooling in time and introduce an asymmetric dilated\nconvolution, called time-dilated convolution, that allows for efficient and\nelegant implementation of pooling in time. We show results using time-dilated\nconvolutions in a very deep VGG-style CNN with batch normalization on the Hub5\nSwitchboard-2000 benchmark task. With a big n-gram language model, we achieve\n7.7% WER which is the best single model single-pass performance reported so\nfar. \n\n"}
{"id": "1611.09405", "contents": "Title: An End-to-End Architecture for Keyword Spotting and Voice Activity\n  Detection Abstract: We propose a single neural network architecture for two tasks: on-line\nkeyword spotting and voice activity detection. We develop novel inference\nalgorithms for an end-to-end Recurrent Neural Network trained with the\nConnectionist Temporal Classification loss function which allow our model to\nachieve high accuracy on both keyword spotting and voice activity detection\nwithout retraining. In contrast to prior voice activity detection models, our\narchitecture does not require aligned training data and uses the same\nparameters as the keyword spotting model. This allows us to deploy a high\nquality voice activity detector with no additional memory or maintenance\nrequirements. \n\n"}
{"id": "1612.00584", "contents": "Title: Alleviating Overfitting for Polysemous Words for Word Representation\n  Estimation Using Lexicons Abstract: Though there are some works on improving distributed word representations\nusing lexicons, the improper overfitting of the words that have multiple\nmeanings is a remaining issue deteriorating the learning when lexicons are\nused, which needs to be solved. An alternative method is to allocate a vector\nper sense instead of a vector per word. However, the word representations\nestimated in the former way are not as easy to use as the latter one. Our\nprevious work uses a probabilistic method to alleviate the overfitting, but it\nis not robust with a small corpus. In this paper, we propose a new neural\nnetwork to estimate distributed word representations using a lexicon and a\ncorpus. We add a lexicon layer in the continuous bag-of-words model and a\nthreshold node after the output of the lexicon layer. The threshold rejects the\nunreliable outputs of the lexicon layer that are less likely to be the same\nwith their inputs. In this way, it alleviates the overfitting of the polysemous\nwords. The proposed neural network can be trained using negative sampling,\nwhich maximizing the log probabilities of target words given the context words,\nby distinguishing the target words from random noises. We compare the proposed\nneural network with the continuous bag-of-words model, the other works\nimproving it, and the previous works estimating distributed word\nrepresentations using both a lexicon and a corpus. The experimental results\nshow that the proposed neural network is more efficient and balanced for both\nsemantic tasks and syntactic tasks than the previous works, and robust to the\nsize of the corpus. \n\n"}
{"id": "1612.00913", "contents": "Title: End-to-End Joint Learning of Natural Language Understanding and Dialogue\n  Manager Abstract: Natural language understanding and dialogue policy learning are both\nessential in conversational systems that predict the next system actions in\nresponse to a current user utterance. Conventional approaches aggregate\nseparate models of natural language understanding (NLU) and system action\nprediction (SAP) as a pipeline that is sensitive to noisy outputs of\nerror-prone NLU. To address the issues, we propose an end-to-end deep recurrent\nneural network with limited contextual dialogue memory by jointly training NLU\nand SAP on DSTC4 multi-domain human-human dialogues. Experiments show that our\nproposed model significantly outperforms the state-of-the-art pipeline models\nfor both NLU and SAP, which indicates that our joint model is capable of\nmitigating the affects of noisy NLU outputs, and NLU model can be refined by\nerror flows backpropagating from the extra supervised signals of system\nactions. \n\n"}
{"id": "1612.02695", "contents": "Title: Towards better decoding and language model integration in sequence to\n  sequence models Abstract: The recently proposed Sequence-to-Sequence (seq2seq) framework advocates\nreplacing complex data processing pipelines, such as an entire automatic speech\nrecognition system, with a single neural network trained in an end-to-end\nfashion. In this contribution, we analyse an attention-based seq2seq speech\nrecognition system that directly transcribes recordings into characters. We\nobserve two shortcomings: overconfidence in its predictions and a tendency to\nproduce incomplete transcriptions when language models are used. We propose\npractical solutions to both problems achieving competitive speaker independent\nword error rates on the Wall Street Journal dataset: without separate language\nmodels we reach 10.6% WER, while together with a trigram language model, we\nreach 6.7% WER. \n\n"}
{"id": "1612.02706", "contents": "Title: Entity Identification as Multitasking Abstract: Standard approaches in entity identification hard-code boundary detection and\ntype prediction into labels (e.g., John/B-PER Smith/I-PER) and then perform\nViterbi. This has two disadvantages: 1. the runtime complexity grows\nquadratically in the number of types, and 2. there is no natural segment-level\nrepresentation. In this paper, we propose a novel neural architecture that\naddresses these disadvantages. We frame the problem as multitasking, separating\nboundary detection and type prediction but optimizing them jointly. Despite its\nsimplicity, this architecture performs competitively with fully structured\nmodels such as BiLSTM-CRFs while scaling linearly in the number of types.\nFurthermore, by construction, the model induces type-disambiguating embeddings\nof predicted mentions. \n\n"}
{"id": "1612.03226", "contents": "Title: Active Learning for Speech Recognition: the Power of Gradients Abstract: In training speech recognition systems, labeling audio clips can be\nexpensive, and not all data is equally valuable. Active learning aims to label\nonly the most informative samples to reduce cost. For speech recognition,\nconfidence scores and other likelihood-based active learning methods have been\nshown to be effective. Gradient-based active learning methods, however, are\nstill not well-understood. This work investigates the Expected Gradient Length\n(EGL) approach in active learning for end-to-end speech recognition. We justify\nEGL from a variance reduction perspective, and observe that EGL's measure of\ninformativeness picks novel samples uncorrelated with confidence scores.\nExperimentally, we show that EGL can reduce word errors by 11\\%, or\nalternatively, reduce the number of samples to label by 50\\%, when compared to\nrandom sampling. \n\n"}
{"id": "1612.03551", "contents": "Title: Reading Comprehension using Entity-based Memory Network Abstract: This paper introduces a novel neural network model for question answering,\nthe \\emph{entity-based memory network}. It enhances neural networks' ability of\nrepresenting and calculating information over a long period by keeping records\nof entities contained in text. The core component is a memory pool which\ncomprises entities' states. These entities' states are continuously updated\naccording to the input text. Questions with regard to the input text are used\nto search the memory pool for related entities and answers are further\npredicted based on the states of retrieved entities. Compared with previous\nmemory network models, the proposed model is capable of handling fine-grained\ninformation and more sophisticated relations based on entities. We formulated\nseveral different tasks as question answering problems and tested the proposed\nmodel. Experiments reported satisfying results. \n\n"}
{"id": "1612.03929", "contents": "Title: Deep Active Learning for Dialogue Generation Abstract: We propose an online, end-to-end, neural generative conversational model for\nopen-domain dialogue. It is trained using a unique combination of offline\ntwo-phase supervised learning and online human-in-the-loop active learning.\nWhile most existing research proposes offline supervision or hand-crafted\nreward functions for online reinforcement, we devise a novel interactive\nlearning mechanism based on hamming-diverse beam search for response generation\nand one-character user-feedback at each step. Experiments show that our model\ninherently promotes the generation of semantically relevant and interesting\nresponses, and can be used to train agents with customized personas, moods and\nconversational styles. \n\n"}
{"id": "1612.04211", "contents": "Title: Multi-Perspective Context Matching for Machine Comprehension Abstract: Previous machine comprehension (MC) datasets are either too small to train\nend-to-end deep learning models, or not difficult enough to evaluate the\nability of current MC techniques. The newly released SQuAD dataset alleviates\nthese limitations, and gives us a chance to develop more realistic MC models.\nBased on this dataset, we propose a Multi-Perspective Context Matching (MPCM)\nmodel, which is an end-to-end system that directly predicts the answer\nbeginning and ending points in a passage. Our model first adjusts each\nword-embedding vector in the passage by multiplying a relevancy weight computed\nagainst the question. Then, we encode the question and weighted passage by\nusing bi-directional LSTMs. For each point in the passage, our model matches\nthe context of this point against the encoded question from multiple\nperspectives and produces a matching vector. Given those matched vectors, we\nemploy another bi-directional LSTM to aggregate all the information and predict\nthe beginning and ending points. Experimental result on the test set of SQuAD\nshows that our model achieves a competitive result on the leaderboard. \n\n"}
{"id": "1612.04342", "contents": "Title: Building Large Machine Reading-Comprehension Datasets using Paragraph\n  Vectors Abstract: We present a dual contribution to the task of machine reading-comprehension:\na technique for creating large-sized machine-comprehension (MC) datasets using\nparagraph-vector models; and a novel, hybrid neural-network architecture that\ncombines the representation power of recurrent neural networks with the\ndiscriminative power of fully-connected multi-layered networks. We use the\nMC-dataset generation technique to build a dataset of around 2 million\nexamples, for which we empirically determine the high-ceiling of human\nperformance (around 91% accuracy), as well as the performance of a variety of\ncomputer models. Among all the models we have experimented with, our hybrid\nneural-network architecture achieves the highest performance (83.2% accuracy).\nThe remaining gap to the human-performance ceiling provides enough room for\nfuture model improvements. \n\n"}
{"id": "1612.04936", "contents": "Title: Learning through Dialogue Interactions by Asking Questions Abstract: A good dialogue agent should have the ability to interact with users by both\nresponding to questions and by asking questions, and importantly to learn from\nboth types of interaction. In this work, we explore this direction by designing\na simulator and a set of synthetic tasks in the movie domain that allow such\ninteractions between a learner and a teacher. We investigate how a learner can\nbenefit from asking questions in both offline and online reinforcement learning\nsettings, and demonstrate that the learner improves when asking questions.\nFinally, real experiments with Mechanical Turk validate the approach. Our work\nrepresents a first step in developing such end-to-end learned interactive\ndialogue agents. \n\n"}
{"id": "1612.06027", "contents": "Title: Neural Multi-Source Morphological Reinflection Abstract: We explore the task of multi-source morphological reinflection, which\ngeneralizes the standard, single-source version. The input consists of (i) a\ntarget tag and (ii) multiple pairs of source form and source tag for a lemma.\nThe motivation is that it is beneficial to have access to more than one source\nform since different source forms can provide complementary information, e.g.,\ndifferent stems. We further present a novel extension to the encoder- decoder\nrecurrent neural architecture, consisting of multiple encoders, to better solve\nthe task. We show that our new architecture outperforms single-source\nreinflection models and publish our dataset for multi-source morphological\nreinflection to facilitate future research. \n\n"}
{"id": "1612.06897", "contents": "Title: Fast Domain Adaptation for Neural Machine Translation Abstract: Neural Machine Translation (NMT) is a new approach for automatic translation\nof text from one human language into another. The basic concept in NMT is to\ntrain a large Neural Network that maximizes the translation performance on a\ngiven parallel corpus. NMT is gaining popularity in the research community\nbecause it outperformed traditional SMT approaches in several translation tasks\nat WMT and other evaluation tasks/benchmarks at least for some language pairs.\nHowever, many of the enhancements in SMT over the years have not been\nincorporated into the NMT framework. In this paper, we focus on one such\nenhancement namely domain adaptation. We propose an approach for adapting a NMT\nsystem to a new domain. The main idea behind domain adaptation is that the\navailability of large out-of-domain training data and a small in-domain\ntraining data. We report significant gains with our proposed method in both\nautomatic metrics and a human subjective evaluation metric on two language\npairs. With our adaptation method, we show large improvement on the new domain\nwhile the performance of our general domain only degrades slightly. In\naddition, our approach is fast enough to adapt an already trained system to a\nnew domain within few hours without the need to retrain the NMT model on the\ncombined data which usually takes several days/weeks depending on the volume of\nthe data. \n\n"}
{"id": "1612.07486", "contents": "Title: Continuous multilinguality with language vectors Abstract: Most existing models for multilingual natural language processing (NLP) treat\nlanguage as a discrete category, and make predictions for either one language\nor the other. In contrast, we propose using continuous vector representations\nof language. We show that these can be learned efficiently with a\ncharacter-based neural language model, and used to improve inference about\nlanguage varieties not seen during training. In experiments with 1303 Bible\ntranslations into 990 different languages, we empirically explore the capacity\nof multilingual language models, and also show that the language vectors\ncapture genetic relationships between languages. \n\n"}
{"id": "1612.08354", "contents": "Title: Image-Text Multi-Modal Representation Learning by Adversarial\n  Backpropagation Abstract: We present novel method for image-text multi-modal representation learning.\nIn our knowledge, this work is the first approach of applying adversarial\nlearning concept to multi-modal learning and not exploiting image-text pair\ninformation to learn multi-modal feature. We only use category information in\ncontrast with most previous methods using image-text pair information for\nmulti-modal embedding. In this paper, we show that multi-modal feature can be\nachieved without image-text pair information and our method makes more similar\ndistribution with image and text in multi-modal feature space than other\nmethods which use image-text pair information. And we show our multi-modal\nfeature has universal semantic information, even though it was trained for\ncategory prediction. Our model is end-to-end backpropagation, intuitive and\neasily extended to other multi-modal learning work. \n\n"}
{"id": "1612.08994", "contents": "Title: Here's My Point: Joint Pointer Architecture for Argument Mining Abstract: One of the major goals in automated argumentation mining is to uncover the\nargument structure present in argumentative text. In order to determine this\nstructure, one must understand how different individual components of the\noverall argument are linked. General consensus in this field dictates that the\nargument components form a hierarchy of persuasion, which manifests itself in a\ntree structure. This work provides the first neural network-based approach to\nargumentation mining, focusing on the two tasks of extracting links between\nargument components, and classifying types of argument components. In order to\nsolve this problem, we propose to use a joint model that is based on a Pointer\nNetwork architecture. A Pointer Network is appealing for this task for the\nfollowing reasons: 1) It takes into account the sequential nature of argument\ncomponents; 2) By construction, it enforces certain properties of the tree\nstructure present in argument relations; 3) The hidden representations can be\napplied to auxiliary tasks. In order to extend the contribution of the original\nPointer Network model, we construct a joint model that simultaneously attempts\nto learn the type of argument component, as well as continuing to predict links\nbetween argument components. The proposed joint model achieves state-of-the-art\nresults on two separate evaluation corpora, achieving far superior performance\nthan a regular Pointer Network model. Our results show that optimizing for both\ntasks, and adding a fully-connected layer prior to recurrent neural network\ninput, is crucial for high performance. \n\n"}
{"id": "1612.09113", "contents": "Title: Deep Semi-Supervised Learning with Linguistically Motivated Sequence\n  Labeling Task Hierarchies Abstract: In this paper we present a novel Neural Network algorithm for conducting\nsemi-supervised learning for sequence labeling tasks arranged in a\nlinguistically motivated hierarchy. This relationship is exploited to\nregularise the representations of supervised tasks by backpropagating the error\nof the unsupervised task through the supervised tasks. We introduce a neural\nnetwork where lower layers are supervised by junior downstream tasks and the\nfinal layer task is an auxiliary unsupervised task. The architecture shows\nimprovements of up to two percentage points F1 for Chunking compared to a\nplausible baseline. \n\n"}
{"id": "1701.00874", "contents": "Title: Neural Probabilistic Model for Non-projective MST Parsing Abstract: In this paper, we propose a probabilistic parsing model, which defines a\nproper conditional probability distribution over non-projective dependency\ntrees for a given sentence, using neural representations as inputs. The neural\nnetwork architecture is based on bi-directional LSTM-CNNs which benefits from\nboth word- and character-level representations automatically, by using\ncombination of bidirectional LSTM and CNN. On top of the neural network, we\nintroduce a probabilistic structured layer, defining a conditional log-linear\nmodel over non-projective trees. We evaluate our model on 17 different\ndatasets, across 14 different languages. By exploiting Kirchhoff's Matrix-Tree\nTheorem (Tutte, 1984), the partition functions and marginals can be computed\nefficiently, leading to a straight-forward end-to-end model training procedure\nvia back-propagation. Our parser achieves state-of-the-art parsing performance\non nine datasets. \n\n"}
{"id": "1701.02593", "contents": "Title: A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based\n  Semantic Role Labeling Abstract: We introduce a simple and accurate neural model for dependency-based semantic\nrole labeling. Our model predicts predicate-argument dependencies relying on\nstates of a bidirectional LSTM encoder. The semantic role labeler achieves\ncompetitive performance on English, even without any kind of syntactic\ninformation and only using local inference. However, when automatically\npredicted part-of-speech tags are provided as input, it substantially\noutperforms all previous local models and approaches the best reported results\non the English CoNLL-2009 dataset. We also consider Chinese, Czech and Spanish\nwhere our approach also achieves competitive results. Syntactic parsers are\nunreliable on out-of-domain data, so standard (i.e., syntactically-informed)\nSRL models are hindered when tested in this setting. Our syntax-agnostic model\nappears more robust, resulting in the best reported results on standard\nout-of-domain test sets. \n\n"}
{"id": "1701.02901", "contents": "Title: A Multifaceted Evaluation of Neural versus Phrase-Based Machine\n  Translation for 9 Language Directions Abstract: We aim to shed light on the strengths and weaknesses of the newly introduced\nneural machine translation paradigm. To that end, we conduct a multifaceted\nevaluation in which we compare outputs produced by state-of-the-art neural\nmachine translation and phrase-based machine translation systems for 9 language\ndirections across a number of dimensions. Specifically, we measure the\nsimilarity of the outputs, their fluency and amount of reordering, the effect\nof sentence length and performance across different error categories. We find\nout that translations produced by neural machine translation systems are\nconsiderably different, more fluent and more accurate in terms of word order\ncompared to those produced by phrase-based systems. Neural machine translation\nsystems are also more accurate at producing inflected forms, but they perform\npoorly when translating very long sentences. \n\n"}
{"id": "1701.02962", "contents": "Title: Distinguishing Antonyms and Synonyms in a Pattern-based Neural Network Abstract: Distinguishing between antonyms and synonyms is a key task to achieve high\nperformance in NLP systems. While they are notoriously difficult to distinguish\nby distributional co-occurrence models, pattern-based methods have proven\neffective to differentiate between the relations. In this paper, we present a\nnovel neural network model AntSynNET that exploits lexico-syntactic patterns\nfrom syntactic parse trees. In addition to the lexical and syntactic\ninformation, we successfully integrate the distance between the related words\nalong the syntactic path as a new pattern feature. The results from\nclassification experiments show that AntSynNET improves the performance over\nprior pattern-based methods. \n\n"}
{"id": "1701.03578", "contents": "Title: Efficient Transfer Learning Schemes for Personalized Language Modeling\n  using Recurrent Neural Network Abstract: In this paper, we propose an efficient transfer leaning methods for training\na personalized language model using a recurrent neural network with long\nshort-term memory architecture. With our proposed fast transfer learning\nschemes, a general language model is updated to a personalized language model\nwith a small amount of user data and a limited computing resource. These\nmethods are especially useful for a mobile device environment while the data is\nprevented from transferring out of the device for privacy purposes. Through\nexperiments on dialogue data in a drama, it is verified that our transfer\nlearning methods have successfully generated the personalized language model,\nwhose output is more similar to the personal language style in both qualitative\nand quantitative aspects. \n\n"}
{"id": "1701.04056", "contents": "Title: Dialog Context Language Modeling with Recurrent Neural Networks Abstract: In this work, we propose contextual language models that incorporate dialog\nlevel discourse information into language modeling. Previous works on\ncontextual language model treat preceding utterances as a sequence of inputs,\nwithout considering dialog interactions. We design recurrent neural network\n(RNN) based contextual language models that specially track the interactions\nbetween speakers in a dialog. Experiment results on Switchboard Dialog Act\nCorpus show that the proposed model outperforms conventional single turn based\nRNN language model by 3.3% on perplexity. The proposed models also demonstrate\nadvantageous performance over other competitive contextual language models. \n\n"}
{"id": "1702.00887", "contents": "Title: Structured Attention Networks Abstract: Attention networks have proven to be an effective approach for embedding\ncategorical inference within a deep neural network. However, for many tasks we\nmay want to model richer structural dependencies without abandoning end-to-end\ntraining. In this work, we experiment with incorporating richer structural\ndistributions, encoded using graphical models, within deep networks. We show\nthat these structured attention networks are simple extensions of the basic\nattention procedure, and that they allow for extending attention beyond the\nstandard soft-selection approach, such as attending to partial segmentations or\nto subtrees. We experiment with two different classes of structured attention\nnetworks: a linear-chain conditional random field and a graph-based parsing\nmodel, and describe how these models can be practically implemented as neural\nnetwork layers. Experiments show that this approach is effective for\nincorporating structural biases, and structured attention networks outperform\nbaseline attention models on a variety of synthetic and real tasks: tree\ntransduction, neural machine translation, question answering, and natural\nlanguage inference. We further find that models trained in this way learn\ninteresting unsupervised hidden representations that generalize simple\nattention. \n\n"}
{"id": "1702.01101", "contents": "Title: Multilingual Multi-modal Embeddings for Natural Language Processing Abstract: We propose a novel discriminative model that learns embeddings from\nmultilingual and multi-modal data, meaning that our model can take advantage of\nimages and descriptions in multiple languages to improve embedding quality. To\nthat end, we introduce a modification of a pairwise contrastive estimation\noptimisation function as our training objective. We evaluate our embeddings on\nan image-sentence ranking (ISR), a semantic textual similarity (STS), and a\nneural machine translation (NMT) task. We find that the additional multilingual\nsignals lead to improvements on both the ISR and STS tasks, and the\ndiscriminative cost can also be used in re-ranking $n$-best lists produced by\nNMT models, yielding strong improvements. \n\n"}
{"id": "1702.01932", "contents": "Title: A Knowledge-Grounded Neural Conversation Model Abstract: Neural network models are capable of generating extremely natural sounding\nconversational interactions. Nevertheless, these models have yet to demonstrate\nthat they can incorporate content in the form of factual information or\nentity-grounded opinion that would enable them to serve in more task-oriented\nconversational applications. This paper presents a novel, fully data-driven,\nand knowledge-grounded neural conversation model aimed at producing more\ncontentful responses without slot filling. We generalize the widely-used\nSeq2Seq approach by conditioning responses on both conversation history and\nexternal \"facts\", allowing the model to be versatile and applicable in an\nopen-domain setting. Our approach yields significant improvements over a\ncompetitive Seq2Seq baseline. Human judges found that our outputs are\nsignificantly more informative. \n\n"}
{"id": "1702.02170", "contents": "Title: How to evaluate word embeddings? On importance of data efficiency and\n  simple supervised tasks Abstract: Maybe the single most important goal of representation learning is making\nsubsequent learning faster. Surprisingly, this fact is not well reflected in\nthe way embeddings are evaluated. In addition, recent practice in word\nembeddings points towards importance of learning specialized representations.\nWe argue that focus of word representation evaluation should reflect those\ntrends and shift towards evaluating what useful information is easily\naccessible. Specifically, we propose that evaluation should focus on data\nefficiency and simple supervised tasks, where the amount of available data is\nvaried and scores of a supervised model are reported for each subset (as\ncommonly done in transfer learning).\n  In order to illustrate significance of such analysis, a comprehensive\nevaluation of selected word embeddings is presented. Proposed approach yields a\nmore complete picture and brings new insight into performance characteristics,\nfor instance information about word similarity or analogy tends to be\nnon--linearly encoded in the embedding space, which questions the cosine-based,\nunsupervised, evaluation methods. All results and analysis scripts are\navailable online. \n\n"}
{"id": "1702.02171", "contents": "Title: Question Answering through Transfer Learning from Large Fine-grained\n  Supervision Data Abstract: We show that the task of question answering (QA) can significantly benefit\nfrom the transfer learning of models trained on a different large, fine-grained\nQA dataset. We achieve the state of the art in two well-studied QA datasets,\nWikiQA and SemEval-2016 (Task 3A), through a basic transfer learning technique\nfrom SQuAD. For WikiQA, our model outperforms the previous best model by more\nthan 8%. We demonstrate that finer supervision provides better guidance for\nlearning lexical and syntactic information than coarser supervision, through\nquantitative results and visual analysis. We also show that a similar transfer\nlearning procedure achieves the state of the art on an entailment task. \n\n"}
{"id": "1702.02363", "contents": "Title: Automatically Annotated Turkish Corpus for Named Entity Recognition and\n  Text Categorization using Large-Scale Gazetteers Abstract: Turkish Wikipedia Named-Entity Recognition and Text Categorization (TWNERTC)\ndataset is a collection of automatically categorized and annotated sentences\nobtained from Wikipedia. We constructed large-scale gazetteers by using a graph\ncrawler algorithm to extract relevant entity and domain information from a\nsemantic knowledge base, Freebase. The constructed gazetteers contains\napproximately 300K entities with thousands of fine-grained entity types under\n77 different domains. Since automated processes are prone to ambiguity, we also\nintroduce two new content specific noise reduction methodologies. Moreover, we\nmap fine-grained entity types to the equivalent four coarse-grained types:\nperson, loc, org, misc. Eventually, we construct six different dataset versions\nand evaluate the quality of annotations by comparing ground truths from human\nannotators. We make these datasets publicly available to support studies on\nTurkish named-entity recognition (NER) and text categorization (TC). \n\n"}
{"id": "1702.03118", "contents": "Title: Sigmoid-Weighted Linear Units for Neural Network Function Approximation\n  in Reinforcement Learning Abstract: In recent years, neural networks have enjoyed a renaissance as function\napproximators in reinforcement learning. Two decades after Tesauro's TD-Gammon\nachieved near top-level human performance in backgammon, the deep reinforcement\nlearning algorithm DQN achieved human-level performance in many Atari 2600\ngames. The purpose of this study is twofold. First, we propose two activation\nfunctions for neural network function approximation in reinforcement learning:\nthe sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU).\nThe activation of the SiLU is computed by the sigmoid function multiplied by\nits input. Second, we suggest that the more traditional approach of using\non-policy learning with eligibility traces, instead of experience replay, and\nsoftmax action selection with simple annealing can be competitive with DQN,\nwithout the need for a separate target network. We validate our proposed\napproach by, first, achieving new state-of-the-art results in both stochastic\nSZ-Tetris and Tetris with a small 10$\\times$10 board, using TD($\\lambda$)\nlearning and shallow dSiLU network agents, and, then, by outperforming DQN in\nthe Atari 2600 domain by using a deep Sarsa($\\lambda$) agent with SiLU and\ndSiLU hidden units. \n\n"}
{"id": "1702.03274", "contents": "Title: Hybrid Code Networks: practical and efficient end-to-end dialog control\n  with supervised and reinforcement learning Abstract: End-to-end learning of recurrent neural networks (RNNs) is an attractive\nsolution for dialog systems; however, current techniques are data-intensive and\nrequire thousands of dialogs to learn simple behaviors. We introduce Hybrid\nCode Networks (HCNs), which combine an RNN with domain-specific knowledge\nencoded as software and system action templates. Compared to existing\nend-to-end approaches, HCNs considerably reduce the amount of training data\nrequired, while retaining the key benefit of inferring a latent representation\nof dialog state. In addition, HCNs can be optimized with supervised learning,\nreinforcement learning, or a mixture of both. HCNs attain state-of-the-art\nperformance on the bAbI dialog dataset, and outperform two commercially\ndeployed customer-facing dialog systems. \n\n"}
{"id": "1702.03814", "contents": "Title: Bilateral Multi-Perspective Matching for Natural Language Sentences Abstract: Natural language sentence matching is a fundamental technology for a variety\nof tasks. Previous approaches either match sentences from a single direction or\nonly apply single granular (word-by-word or sentence-by-sentence) matching. In\nthis work, we propose a bilateral multi-perspective matching (BiMPM) model\nunder the \"matching-aggregation\" framework. Given two sentences $P$ and $Q$,\nour model first encodes them with a BiLSTM encoder. Next, we match the two\nencoded sentences in two directions $P \\rightarrow Q$ and $P \\leftarrow Q$. In\neach matching direction, each time step of one sentence is matched against all\ntime-steps of the other sentence from multiple perspectives. Then, another\nBiLSTM layer is utilized to aggregate the matching results into a fix-length\nmatching vector. Finally, based on the matching vector, the decision is made\nthrough a fully connected layer. We evaluate our model on three tasks:\nparaphrase identification, natural language inference and answer sentence\nselection. Experimental results on standard benchmark datasets show that our\nmodel achieves the state-of-the-art performance on all tasks. \n\n"}
{"id": "1702.04521", "contents": "Title: Frustratingly Short Attention Spans in Neural Language Modeling Abstract: Neural language models predict the next token using a latent representation\nof the immediate token history. Recently, various methods for augmenting neural\nlanguage models with an attention mechanism over a differentiable memory have\nbeen proposed. For predicting the next token, these models query information\nfrom a memory of the recent history which can facilitate learning mid- and\nlong-range dependencies. However, conventional attention mechanisms used in\nmemory-augmented neural language models produce a single output vector per time\nstep. This vector is used both for predicting the next token as well as for the\nkey and value of a differentiable memory of a token history. In this paper, we\npropose a neural language model with a key-value attention mechanism that\noutputs separate representations for the key and value of a differentiable\nmemory, as well as for encoding the next-word distribution. This model\noutperforms existing memory-augmented neural language models on two corpora.\nYet, we found that our method mainly utilizes a memory of the five most recent\noutput representations. This led to the unexpected main finding that a much\nsimpler model based only on the concatenation of recent output representations\nfrom previous time steps is on par with more sophisticated memory-augmented\nneural language models. \n\n"}
{"id": "1702.05270", "contents": "Title: Be Precise or Fuzzy: Learning the Meaning of Cardinals and Quantifiers\n  from Vision Abstract: People can refer to quantities in a visual scene by using either exact\ncardinals (e.g. one, two, three) or natural language quantifiers (e.g. few,\nmost, all). In humans, these two processes underlie fairly different cognitive\nand neural mechanisms. Inspired by this evidence, the present study proposes\ntwo models for learning the objective meaning of cardinals and quantifiers from\nvisual scenes containing multiple objects. We show that a model capitalizing on\na 'fuzzy' measure of similarity is effective for learning quantifiers, whereas\nthe learning of exact cardinals is better accomplished when information about\nnumber is provided. \n\n"}
{"id": "1702.06703", "contents": "Title: Data Distillation for Controlling Specificity in Dialogue Generation Abstract: People speak at different levels of specificity in different situations.\nDepending on their knowledge, interlocutors, mood, etc.} A conversational agent\nshould have this ability and know when to be specific and when to be general.\nWe propose an approach that gives a neural network--based conversational agent\nthis ability. Our approach involves alternating between \\emph{data\ndistillation} and model training : removing training examples that are closest\nto the responses most commonly produced by the model trained from the last\nround and then retrain the model on the remaining dataset. Dialogue generation\nmodels trained with different degrees of data distillation manifest different\nlevels of specificity.\n  We then train a reinforcement learning system for selecting among this pool\nof generation models, to choose the best level of specificity for a given\ninput. Compared to the original generative model trained without distillation,\nthe proposed system is capable of generating more interesting and\nhigher-quality responses, in addition to appropriately adjusting specificity\ndepending on the context.\n  Our research constitutes a specific case of a broader approach involving\ntraining multiple subsystems from a single dataset distinguished by differences\nin a specific property one wishes to model. We show that from such a set of\nsubsystems, one can use reinforcement learning to build a system that tailors\nits output to different input contexts at test time. \n\n"}
{"id": "1702.07983", "contents": "Title: Maximum-Likelihood Augmented Discrete Generative Adversarial Networks Abstract: Despite the successes in capturing continuous distributions, the application\nof generative adversarial networks (GANs) to discrete settings, like natural\nlanguage tasks, is rather restricted. The fundamental reason is the difficulty\nof back-propagation through discrete random variables combined with the\ninherent instability of the GAN training objective. To address these problems,\nwe propose Maximum-Likelihood Augmented Discrete Generative Adversarial\nNetworks. Instead of directly optimizing the GAN objective, we derive a novel\nand low-variance objective using the discriminator's output that follows\ncorresponds to the log-likelihood. Compared with the original, the new\nobjective is proved to be consistent in theory and beneficial in practice. The\nexperimental results on various discrete datasets demonstrate the effectiveness\nof the proposed approach. \n\n"}
{"id": "1703.00096", "contents": "Title: Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence\n  Labelling Abstract: Most existing sequence labelling models rely on a fixed decomposition of a\ntarget sequence into a sequence of basic units. These methods suffer from two\nmajor drawbacks: 1) the set of basic units is fixed, such as the set of words,\ncharacters or phonemes in speech recognition, and 2) the decomposition of\ntarget sequences is fixed. These drawbacks usually result in sub-optimal\nperformance of modeling sequences. In this pa- per, we extend the popular CTC\nloss criterion to alleviate these limitations, and propose a new loss function\ncalled Gram-CTC. While preserving the advantages of CTC, Gram-CTC automatically\nlearns the best set of basic units (grams), as well as the most suitable\ndecomposition of tar- get sequences. Unlike CTC, Gram-CTC allows the model to\noutput variable number of characters at each time step, which enables the model\nto capture longer term dependency and improves the computational efficiency. We\ndemonstrate that the proposed Gram-CTC improves CTC in terms of both\nperformance and efficiency on the large vocabulary speech recognition task at\nmultiple scales of data, and that with Gram-CTC we can outperform the\nstate-of-the-art on a standard speech benchmark. \n\n"}
{"id": "1703.00099", "contents": "Title: Learning Conversational Systems that Interleave Task and Non-Task\n  Content Abstract: Task-oriented dialog systems have been applied in various tasks, such as\nautomated personal assistants, customer service providers and tutors. These\nsystems work well when users have clear and explicit intentions that are\nwell-aligned to the systems' capabilities. However, they fail if users\nintentions are not explicit. To address this shortcoming, we propose a\nframework to interleave non-task content (i.e. everyday social conversation)\ninto task conversations. When the task content fails, the system can still keep\nthe user engaged with the non-task content. We trained a policy using\nreinforcement learning algorithms to promote long-turn conversation coherence\nand consistency, so that the system can have smooth transitions between task\nand non-task content. To test the effectiveness of the proposed framework, we\ndeveloped a movie promotion dialog system. Experiments with human users\nindicate that a system that interleaves social and task content achieves a\nbetter task success rate and is also rated as more engaging compared to a pure\ntask-oriented system. \n\n"}
{"id": "1703.00786", "contents": "Title: A Generic Online Parallel Learning Framework for Large Margin Models Abstract: To speed up the training process, many existing systems use parallel\ntechnology for online learning algorithms. However, most research mainly focus\non stochastic gradient descent (SGD) instead of other algorithms. We propose a\ngeneric online parallel learning framework for large margin models, and also\nanalyze our framework on popular large margin algorithms, including MIRA and\nStructured Perceptron. Our framework is lock-free and easy to implement on\nexisting systems. Experiments show that systems with our framework can gain\nnear linear speed up by increasing running threads, and with no loss in\naccuracy. \n\n"}
{"id": "1703.00993", "contents": "Title: A Comparative Study of Word Embeddings for Reading Comprehension Abstract: The focus of past machine learning research for Reading Comprehension tasks\nhas been primarily on the design of novel deep learning architectures. Here we\nshow that seemingly minor choices made on (1) the use of pre-trained word\nembeddings, and (2) the representation of out-of-vocabulary tokens at test\ntime, can turn out to have a larger impact than architectural choices on the\nfinal performance. We systematically explore several options for these choices,\nand provide recommendations to researchers working in this area. \n\n"}
{"id": "1703.01720", "contents": "Title: Sound-Word2Vec: Learning Word Representations Grounded in Sounds Abstract: To be able to interact better with humans, it is crucial for machines to\nunderstand sound - a primary modality of human perception. Previous works have\nused sound to learn embeddings for improved generic textual similarity\nassessment. In this work, we treat sound as a first-class citizen, studying\ndownstream textual tasks which require aural grounding. To this end, we propose\nsound-word2vec - a new embedding scheme that learns specialized word embeddings\ngrounded in sounds. For example, we learn that two seemingly (semantically)\nunrelated concepts, like leaves and paper are similar due to the similar\nrustling sounds they make. Our embeddings prove useful in textual tasks\nrequiring aural reasoning like text-based sound retrieval and discovering foley\nsound effects (used in movies). Moreover, our embedding space captures\ninteresting dependencies between words and onomatopoeia and outperforms prior\nwork on aurally-relevant word relatedness datasets such as AMEN and ASLex. \n\n"}
{"id": "1703.03130", "contents": "Title: A Structured Self-attentive Sentence Embedding Abstract: This paper proposes a new model for extracting an interpretable sentence\nembedding by introducing self-attention. Instead of using a vector, we use a\n2-D matrix to represent the embedding, with each row of the matrix attending on\na different part of the sentence. We also propose a self-attention mechanism\nand a special regularization term for the model. As a side effect, the\nembedding comes with an easy way of visualizing what specific parts of the\nsentence are encoded into the embedding. We evaluate our model on 3 different\ntasks: author profiling, sentiment classification, and textual entailment.\nResults show that our model yields a significant performance gain compared to\nother sentence embedding methods in all of the 3 tasks. \n\n"}
{"id": "1703.04247", "contents": "Title: DeepFM: A Factorization-Machine based Neural Network for CTR Prediction Abstract: Learning sophisticated feature interactions behind user behaviors is critical\nin maximizing CTR for recommender systems. Despite great progress, existing\nmethods seem to have a strong bias towards low- or high-order interactions, or\nrequire expertise feature engineering. In this paper, we show that it is\npossible to derive an end-to-end learning model that emphasizes both low- and\nhigh-order feature interactions. The proposed model, DeepFM, combines the power\nof factorization machines for recommendation and deep learning for feature\nlearning in a new neural network architecture. Compared to the latest Wide \\&\nDeep model from Google, DeepFM has a shared input to its \"wide\" and \"deep\"\nparts, with no need of feature engineering besides raw features. Comprehensive\nexperiments are conducted to demonstrate the effectiveness and efficiency of\nDeepFM over the existing models for CTR prediction, on both benchmark data and\ncommercial data. \n\n"}
{"id": "1703.04617", "contents": "Title: Exploring Question Understanding and Adaptation in Neural-Network-Based\n  Question Answering Abstract: The last several years have seen intensive interest in exploring\nneural-network-based models for machine comprehension (MC) and question\nanswering (QA). In this paper, we approach the problems by closely modelling\nquestions in a neural network framework. We first introduce syntactic\ninformation to help encode questions. We then view and model different types of\nquestions and the information shared among them as an adaptation task and\nproposed adaptation models for them. On the Stanford Question Answering Dataset\n(SQuAD), we show that these approaches can help attain better results over a\ncompetitive baseline. \n\n"}
{"id": "1703.04914", "contents": "Title: Ensemble of Neural Classifiers for Scoring Knowledge Base Triples Abstract: This paper describes our approach for the triple scoring task at the WSDM Cup\n2017. The task required participants to assign a relevance score for each pair\nof entities and their types in a knowledge base in order to enhance the ranking\nresults in entity retrieval tasks. We propose an approach wherein the outputs\nof multiple neural network classifiers are combined using a supervised machine\nlearning model. The experimental results showed that our proposed method\nachieved the best performance in one out of three measures (i.e., Kendall's\ntau), and performed competitively in the other two measures (i.e., accuracy and\naverage score difference). \n\n"}
{"id": "1703.06585", "contents": "Title: Learning Cooperative Visual Dialog Agents with Deep Reinforcement\n  Learning Abstract: We introduce the first goal-driven training for visual question answering and\ndialog agents. Specifically, we pose a cooperative 'image guessing' game\nbetween two agents -- Qbot and Abot -- who communicate in natural language\ndialog so that Qbot can select an unseen image from a lineup of images. We use\ndeep reinforcement learning (RL) to learn the policies of these agents\nend-to-end -- from pixels to multi-agent multi-round dialog to game reward.\n  We demonstrate two experimental results.\n  First, as a 'sanity check' demonstration of pure RL (from scratch), we show\nresults on a synthetic world, where the agents communicate in ungrounded\nvocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We find\nthat two bots invent their own communication protocol and start using certain\nsymbols to ask/answer about certain visual attributes (shape/color/style).\nThus, we demonstrate the emergence of grounded language and communication among\n'visual' dialog agents with no human supervision.\n  Second, we conduct large-scale real-image experiments on the VisDial dataset,\nwhere we pretrain with supervised dialog data and show that the RL 'fine-tuned'\nagents significantly outperform SL agents. Interestingly, the RL Qbot learns to\nask questions that Abot is good at, ultimately resulting in more informative\ndialog and a better team. \n\n"}
{"id": "1703.07588", "contents": "Title: Gate Activation Signal Analysis for Gated Recurrent Neural Networks and\n  Its Correlation with Phoneme Boundaries Abstract: In this paper we analyze the gate activation signals inside the gated\nrecurrent neural networks, and find the temporal structure of such signals is\nhighly correlated with the phoneme boundaries. This correlation is further\nverified by a set of experiments for phoneme segmentation, in which better\nresults compared to standard approaches were obtained. \n\n"}
{"id": "1703.08135", "contents": "Title: An embedded segmental K-means model for unsupervised segmentation and\n  clustering of speech Abstract: Unsupervised segmentation and clustering of unlabelled speech are core\nproblems in zero-resource speech processing. Most approaches lie at\nmethodological extremes: some use probabilistic Bayesian models with\nconvergence guarantees, while others opt for more efficient heuristic\ntechniques. Despite competitive performance in previous work, the full Bayesian\napproach is difficult to scale to large speech corpora. We introduce an\napproximation to a recent Bayesian model that still has a clear objective\nfunction but improves efficiency by using hard clustering and segmentation\nrather than full Bayesian inference. Like its Bayesian counterpart, this\nembedded segmental K-means model (ES-KMeans) represents arbitrary-length word\nsegments as fixed-dimensional acoustic word embeddings. We first compare\nES-KMeans to previous approaches on common English and Xitsonga data sets (5\nand 2.5 hours of speech): ES-KMeans outperforms a leading heuristic method in\nword segmentation, giving similar scores to the Bayesian model while being 5\ntimes faster with fewer hyperparameters. However, its clusters are less pure\nthan those of the other models. We then show that ES-KMeans scales to larger\ncorpora by applying it to the 5 languages of the Zero Resource Speech Challenge\n2017 (up to 45 hours), where it performs competitively compared to the\nchallenge baseline. \n\n"}
{"id": "1703.08314", "contents": "Title: Interacting Conceptual Spaces I : Grammatical Composition of Concepts Abstract: The categorical compositional approach to meaning has been successfully\napplied in natural language processing, outperforming other models in\nmainstream empirical language processing tasks. We show how this approach can\nbe generalized to conceptual space models of cognition. In order to do this,\nfirst we introduce the category of convex relations as a new setting for\ncategorical compositional semantics, emphasizing the convex structure important\nto conceptual space applications. We then show how to construct conceptual\nspaces for various types such as nouns, adjectives and verbs. Finally we show\nby means of examples how concepts can be systematically combined to establish\nthe meanings of composite phrases from the meanings of their constituent parts.\nThis provides the mathematical underpinnings of a new compositional approach to\ncognition. \n\n"}
{"id": "1703.09825", "contents": "Title: Semi-Supervised Affective Meaning Lexicon Expansion Using Semantic and\n  Distributed Word Representations Abstract: In this paper, we propose an extension to graph-based sentiment lexicon\ninduction methods by incorporating distributed and semantic word\nrepresentations in building the similarity graph to expand a three-dimensional\nsentiment lexicon. We also implemented and evaluated the label propagation\nusing four different word representations and similarity metrics. Our\ncomprehensive evaluation of the four approaches was performed on a single data\nset, demonstrating that all four methods can generate a significant number of\nnew sentiment assignments with high accuracy. The highest correlations\n(tau=0.51) and the lowest error (mean absolute error < 1.1%), obtained by\ncombining both the semantic and the distributional features, outperformed the\ndistributional-based and semantic-based label-propagation models and approached\na supervised algorithm. \n\n"}
{"id": "1703.10356", "contents": "Title: Simplified End-to-End MMI Training and Voting for ASR Abstract: A simplified speech recognition system that uses the maximum mutual\ninformation (MMI) criterion is considered. End-to-end training using gradient\ndescent is suggested, similarly to the training of connectionist temporal\nclassification (CTC). We use an MMI criterion with a simple language model in\nthe training stage, and a standard HMM decoder. Our method compares favorably\nto CTC in terms of performance, robustness, decoding time, disk footprint and\nquality of alignments. The good alignments enable the use of a straightforward\nensemble method, obtained by simply averaging the predictions of several neural\nnetwork models, that were trained separately end-to-end. The ensemble method\nyields a considerable reduction in the word error rate. \n\n"}
{"id": "1704.00939", "contents": "Title: Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring\n  Sentiment towards Brands from Financial News Headlines Abstract: In this paper, we describe a methodology to infer Bullish or Bearish\nsentiment towards companies/brands. More specifically, our approach leverages\naffective lexica and word embeddings in combination with convolutional neural\nnetworks to infer the sentiment of financial news headlines towards a target\ncompany. Such architecture was used and evaluated in the context of the SemEval\n2017 challenge (task 5, subtask 2), in which it obtained the best performance. \n\n"}
{"id": "1704.02156", "contents": "Title: The Meaning Factory at SemEval-2017 Task 9: Producing AMRs with Neural\n  Semantic Parsing Abstract: We evaluate a semantic parser based on a character-based sequence-to-sequence\nmodel in the context of the SemEval-2017 shared task on semantic parsing for\nAMRs. With data augmentation, super characters, and POS-tagging we gain major\nimprovements in performance compared to a baseline character-level model.\nAlthough we improve on previous character-based neural semantic parsing models,\nthe overall accuracy is still lower than a state-of-the-art AMR parser. An\nensemble combining our neural semantic parser with an existing, traditional\nparser, yields a small gain in performance. \n\n"}
{"id": "1704.02497", "contents": "Title: On the Linearity of Semantic Change: Investigating Meaning Variation via\n  Dynamic Graph Models Abstract: We consider two graph models of semantic change. The first is a time-series\nmodel that relates embedding vectors from one time period to embedding vectors\nof previous time periods. In the second, we construct one graph for each word:\nnodes in this graph correspond to time points and edge weights to the\nsimilarity of the word's meaning across two time points. We apply our two\nmodels to corpora across three different languages. We find that semantic\nchange is linear in two senses. Firstly, today's embedding vectors (= meaning)\nof words can be derived as linear combinations of embedding vectors of their\nneighbors in previous time periods. Secondly, self-similarity of words decays\nlinearly in time. We consider both findings as new laws/hypotheses of semantic\nchange. \n\n"}
{"id": "1704.02813", "contents": "Title: Character-Word LSTM Language Models Abstract: We present a Character-Word Long Short-Term Memory Language Model which both\nreduces the perplexity with respect to a baseline word-level language model and\nreduces the number of parameters of the model. Character information can reveal\nstructural (dis)similarities between words and can even be used when a word is\nout-of-vocabulary, thus improving the modeling of infrequent and unknown words.\nBy concatenating word and character embeddings, we achieve up to 2.77% relative\nimprovement on English compared to a baseline model with a similar amount of\nparameters and 4.57% on Dutch. Moreover, we also outperform baseline word-level\nmodels with a larger number of parameters. \n\n"}
{"id": "1704.03084", "contents": "Title: Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep\n  Reinforcement Learning Abstract: Building a dialogue agent to fulfill complex tasks, such as travel planning,\nis challenging because the agent has to learn to collectively complete multiple\nsubtasks. For example, the agent needs to reserve a hotel and book a flight so\nthat there leaves enough time for commute between arrival and hotel check-in.\nThis paper addresses this challenge by formulating the task in the mathematical\nframework of options over Markov Decision Processes (MDPs), and proposing a\nhierarchical deep reinforcement learning approach to learning a dialogue\nmanager that operates at different temporal scales. The dialogue manager\nconsists of: (1) a top-level dialogue policy that selects among subtasks or\noptions, (2) a low-level dialogue policy that selects primitive actions to\ncomplete the subtask given by the top-level policy, and (3) a global state\ntracker that helps ensure all cross-subtask constraints be satisfied.\nExperiments on a travel planning task with simulated and real users show that\nour approach leads to significant improvements over three baselines, two based\non handcrafted rules and the other based on flat deep reinforcement learning. \n\n"}
{"id": "1704.04856", "contents": "Title: A Neural Architecture for Generating Natural Language Descriptions from\n  Source Code Changes Abstract: We propose a model to automatically describe changes introduced in the source\ncode of a program using natural language. Our method receives as input a set of\ncode commits, which contains both the modifications and message introduced by\nan user. These two modalities are used to train an encoder-decoder\narchitecture. We evaluated our approach on twelve real world open source\nprojects from four different programming languages. Quantitative and\nqualitative results showed that the proposed approach can generate feasible and\nsemantically sound descriptions not only in standard in-project settings, but\nalso in a cross-project setting. \n\n"}
{"id": "1704.04920", "contents": "Title: Deep Joint Entity Disambiguation with Local Neural Attention Abstract: We propose a novel deep learning model for joint document-level entity\ndisambiguation, which leverages learned neural representations. Key components\nare entity embeddings, a neural attention mechanism over local context windows,\nand a differentiable joint inference stage for disambiguation. Our approach\nthereby combines benefits of deep learning with more traditional approaches\nsuch as graphical models and probabilistic mention-entity maps. Extensive\nexperiments show that we are able to obtain competitive or state-of-the-art\naccuracy at moderate computational costs. \n\n"}
{"id": "1704.05135", "contents": "Title: Does Neural Machine Translation Benefit from Larger Context? Abstract: We propose a neural machine translation architecture that models the\nsurrounding text in addition to the source sentence. These models lead to\nbetter performance, both in terms of general translation quality and pronoun\nprediction, when trained on small corpora, although this improvement largely\ndisappears when trained with a larger corpus. We also discover that\nattention-based neural machine translation is well suited for pronoun\nprediction and compares favorably with other approaches that were specifically\ndesigned for this task. \n\n"}
{"id": "1704.05415", "contents": "Title: An Empirical Analysis of NMT-Derived Interlingual Embeddings and their\n  Use in Parallel Sentence Identification Abstract: End-to-end neural machine translation has overtaken statistical machine\ntranslation in terms of translation quality for some language pairs, specially\nthose with large amounts of parallel data. Besides this palpable improvement,\nneural networks provide several new properties. A single system can be trained\nto translate between many languages at almost no additional cost other than\ntraining time. Furthermore, internal representations learned by the network\nserve as a new semantic representation of words -or sentences- which, unlike\nstandard word embeddings, are learned in an essentially bilingual or even\nmultilingual context. In view of these properties, the contribution of the\npresent work is two-fold. First, we systematically study the NMT context\nvectors, i.e. output of the encoder, and their power as an interlingua\nrepresentation of a sentence. We assess their quality and effectiveness by\nmeasuring similarities across translations, as well as semantically related and\nsemantically unrelated sentence pairs. Second, as extrinsic evaluation of the\nfirst point, we identify parallel sentences in comparable corpora, obtaining an\nF1=98.2% on data from a shared task when using only NMT context vectors. Using\ncontext vectors jointly with similarity measures F1 reaches 98.9%. \n\n"}
{"id": "1704.05907", "contents": "Title: End-to-End Multi-View Networks for Text Classification Abstract: We propose a multi-view network for text classification. Our method\nautomatically creates various views of its input text, each taking the form of\nsoft attention weights that distribute the classifier's focus among a set of\nbase features. For a bag-of-words representation, each view focuses on a\ndifferent subset of the text's words. Aggregating many such views results in a\nmore discriminative and robust representation. Through a novel architecture\nthat both stacks and concatenates views, we produce a network that emphasizes\nboth depth and width, allowing training to converge quickly. Using our\nmulti-view architecture, we establish new state-of-the-art accuracies on two\nbenchmark tasks. \n\n"}
{"id": "1704.05973", "contents": "Title: Call Attention to Rumors: Deep Attention Based Recurrent Neural Networks\n  for Early Rumor Detection Abstract: The proliferation of social media in communication and information\ndissemination has made it an ideal platform for spreading rumors. Automatically\ndebunking rumors at their stage of diffusion is known as \\textit{early rumor\ndetection}, which refers to dealing with sequential posts regarding disputed\nfactual claims with certain variations and highly textual duplication over\ntime. Thus, identifying trending rumors demands an efficient yet flexible model\nthat is able to capture long-range dependencies among postings and produce\ndistinct representations for the accurate early detection. However, it is a\nchallenging task to apply conventional classification algorithms to rumor\ndetection in earliness since they rely on hand-crafted features which require\nintensive manual efforts in the case of large amount of posts. This paper\npresents a deep attention model on the basis of recurrent neural networks (RNN)\nto learn \\textit{selectively} temporal hidden representations of sequential\nposts for identifying rumors. The proposed model delves soft-attention into the\nrecurrence to simultaneously pool out distinct features with particular focus\nand produce hidden representations that capture contextual variations of\nrelevant posts over time. Extensive experiments on real datasets collected from\nsocial media websites demonstrate that (1) the deep attention based RNN model\noutperforms state-of-the-arts that rely on hand-crafted features; (2) the\nintroduction of soft attention mechanism can effectively distill relevant parts\nto rumors from original posts in advance; (3) the proposed method detects\nrumors more quickly and accurately than competitors. \n\n"}
{"id": "1704.06194", "contents": "Title: Improved Neural Relation Detection for Knowledge Base Question Answering Abstract: Relation detection is a core component for many NLP applications including\nKnowledge Base Question Answering (KBQA). In this paper, we propose a\nhierarchical recurrent neural network enhanced by residual learning that\ndetects KB relations given an input question. Our method uses deep residual\nbidirectional LSTMs to compare questions and relation names via different\nhierarchies of abstraction. Additionally, we propose a simple KBQA system that\nintegrates entity linking and our proposed relation detector to enable one\nenhance another. Experimental results evidence that our approach achieves not\nonly outstanding relation detection performance, but more importantly, it helps\nour KBQA system to achieve state-of-the-art accuracy for both single-relation\n(SimpleQuestions) and multi-relation (WebQSP) QA benchmarks. \n\n"}
{"id": "1704.06217", "contents": "Title: Reinforcement Learning with External Knowledge and Two-Stage Q-functions\n  for Predicting Popular Reddit Threads Abstract: This paper addresses the problem of predicting popularity of comments in an\nonline discussion forum using reinforcement learning, particularly addressing\ntwo challenges that arise from having natural language state and action spaces.\nFirst, the state representation, which characterizes the history of comments\ntracked in a discussion at a particular point, is augmented to incorporate the\nglobal context represented by discussions on world events available in an\nexternal knowledge source. Second, a two-stage Q-learning framework is\nintroduced, making it feasible to search the combinatorial action space while\nalso accounting for redundancy among sub-actions. We experiment with five\nReddit communities, showing that the two methods improve over previous reported\nresults on this task. \n\n"}
{"id": "1704.06933", "contents": "Title: Adversarial Neural Machine Translation Abstract: In this paper, we study a new learning paradigm for Neural Machine\nTranslation (NMT). Instead of maximizing the likelihood of the human\ntranslation as in previous works, we minimize the distinction between human\ntranslation and the translation given by an NMT model. To achieve this goal,\ninspired by the recent success of generative adversarial networks (GANs), we\nemploy an adversarial training architecture and name it as Adversarial-NMT. In\nAdversarial-NMT, the training of the NMT model is assisted by an adversary,\nwhich is an elaborately designed Convolutional Neural Network (CNN). The goal\nof the adversary is to differentiate the translation result generated by the\nNMT model from that by human. The goal of the NMT model is to produce high\nquality translations so as to cheat the adversary. A policy gradient method is\nleveraged to co-train the NMT model and the adversary. Experimental results on\nEnglish$\\rightarrow$French and German$\\rightarrow$English translation tasks\nshow that Adversarial-NMT can achieve significantly better translation quality\nthan several strong baselines. \n\n"}
{"id": "1704.07047", "contents": "Title: Fast and Accurate Neural Word Segmentation for Chinese Abstract: Neural models with minimal feature engineering have achieved competitive\nperformance against traditional methods for the task of Chinese word\nsegmentation. However, both training and working procedures of the current\nneural models are computationally inefficient. This paper presents a greedy\nneural word segmenter with balanced word and character embedding inputs to\nalleviate the existing drawbacks. Our segmenter is truly end-to-end, capable of\nperforming segmentation much faster and even more accurate than\nstate-of-the-art neural models on Chinese benchmark datasets. \n\n"}
{"id": "1704.07092", "contents": "Title: Robust Incremental Neural Semantic Graph Parsing Abstract: Parsing sentences to linguistically-expressive semantic representations is a\nkey goal of Natural Language Processing. Yet statistical parsing has focused\nalmost exclusively on bilexical dependencies or domain-specific logical forms.\nWe propose a neural encoder-decoder transition-based parser which is the first\nfull-coverage semantic graph parser for Minimal Recursion Semantics (MRS). The\nmodel architecture uses stack-based embedding features, predicting graphs\njointly with unlexicalized predicates and their token alignments. Our parser is\nmore accurate than attention-based baselines on MRS, and on an additional\nAbstract Meaning Representation (AMR) benchmark, and GPU batch processing makes\nit an order of magnitude faster than a high-precision grammar-based parser.\nFurther, the 86.69% Smatch score of our MRS parser is higher than the\nupper-bound on AMR parsing, making MRS an attractive choice as a semantic\nrepresentation. \n\n"}
{"id": "1704.07156", "contents": "Title: Semi-supervised Multitask Learning for Sequence Labeling Abstract: We propose a sequence labeling framework with a secondary training objective,\nlearning to predict surrounding words for every word in the dataset. This\nlanguage modeling objective incentivises the system to learn general-purpose\npatterns of semantic and syntactic composition, which are also useful for\nimproving accuracy on different sequence labeling tasks. The architecture was\nevaluated on a range of datasets, covering the tasks of error detection in\nlearner texts, named entity recognition, chunking and POS-tagging. The novel\nlanguage modeling objective provided consistent performance improvements on\nevery benchmark, without requiring any additional annotated or unannotated\ndata. \n\n"}
{"id": "1704.07221", "contents": "Title: Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance\n  Classification with Branch-LSTM Abstract: This paper describes team Turing's submission to SemEval 2017 RumourEval:\nDetermining rumour veracity and support for rumours (SemEval 2017 Task 8,\nSubtask A). Subtask A addresses the challenge of rumour stance classification,\nwhich involves identifying the attitude of Twitter users towards the\ntruthfulness of the rumour they are discussing. Stance classification is\nconsidered to be an important step towards rumour verification, therefore\nperforming well in this task is expected to be useful in debunking false\nrumours. In this work we classify a set of Twitter posts discussing rumours\ninto either supporting, denying, questioning or commenting on the underlying\nrumours. We propose a LSTM-based sequential model that, through modelling the\nconversational structure of tweets, which achieves an accuracy of 0.784 on the\nRumourEval test set outperforming all other systems in Subtask A. \n\n"}
{"id": "1704.07329", "contents": "Title: A Trie-Structured Bayesian Model for Unsupervised Morphological\n  Segmentation Abstract: In this paper, we introduce a trie-structured Bayesian model for unsupervised\nmorphological segmentation. We adopt prior information from different sources\nin the model. We use neural word embeddings to discover words that are\nmorphologically derived from each other and thereby that are semantically\nsimilar. We use letter successor variety counts obtained from tries that are\nbuilt by neural word embeddings. Our results show that using different\ninformation sources such as neural word embeddings and letter successor variety\nas prior information improves morphological segmentation in a Bayesian model.\nOur model outperforms other unsupervised morphological segmentation models on\nTurkish and gives promising results on English and German for scarce resources. \n\n"}
{"id": "1704.07489", "contents": "Title: Multi-Task Video Captioning with Video and Entailment Generation Abstract: Video captioning, the task of describing the content of a video, has seen\nsome promising improvements in recent years with sequence-to-sequence models,\nbut accurately learning the temporal and logical dynamics involved in the task\nstill remains a challenge, especially given the lack of sufficient annotated\ndata. We improve video captioning by sharing knowledge with two related\ndirected-generation tasks: a temporally-directed unsupervised video prediction\ntask to learn richer context-aware video encoder representations, and a\nlogically-directed language entailment generation task to learn better\nvideo-entailed caption decoder representations. For this, we present a\nmany-to-many multi-task learning model that shares parameters across the\nencoders and decoders of the three tasks. We achieve significant improvements\nand the new state-of-the-art on several standard video captioning datasets\nusing diverse automatic and human evaluations. We also show mutual multi-task\nimprovements on the entailment generation task. \n\n"}
{"id": "1704.08243", "contents": "Title: C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0\n  Dataset Abstract: Visual Question Answering (VQA) has received a lot of attention over the past\ncouple of years. A number of deep learning models have been proposed for this\ntask. However, it has been shown that these models are heavily driven by\nsuperficial correlations in the training data and lack compositionality -- the\nability to answer questions about unseen compositions of seen concepts. This\ncompositionality is desirable and central to intelligence. In this paper, we\npropose a new setting for Visual Question Answering where the test\nquestion-answer pairs are compositionally novel compared to training\nquestion-answer pairs. To facilitate developing models under this setting, we\npresent a new compositional split of the VQA v1.0 dataset, which we call\nCompositional VQA (C-VQA). We analyze the distribution of questions and answers\nin the C-VQA splits. Finally, we evaluate several existing VQA models under\nthis new setting and show that the performances of these models degrade by a\nsignificant amount compared to the original VQA setting. \n\n"}
{"id": "1704.08424", "contents": "Title: Multimodal Word Distributions Abstract: Word embeddings provide point representations of words containing useful\nsemantic information. We introduce multimodal word distributions formed from\nGaussian mixtures, for multiple word meanings, entailment, and rich uncertainty\ninformation. To learn these distributions, we propose an energy-based\nmax-margin objective. We show that the resulting approach captures uniquely\nexpressive semantic information, and outperforms alternatives, such as word2vec\nskip-grams, and Gaussian embeddings, on benchmark datasets such as word\nsimilarity and entailment. \n\n"}
{"id": "1705.00335", "contents": "Title: Quantifying Mental Health from Social Media with Neural User Embeddings Abstract: Mental illnesses adversely affect a significant proportion of the population\nworldwide. However, the methods traditionally used for estimating and\ncharacterizing the prevalence of mental health conditions are time-consuming\nand expensive. Consequently, best-available estimates concerning the prevalence\nof mental health conditions are often years out of date. Automated approaches\nto supplement these survey methods with broad, aggregated information derived\nfrom social media content provides a potential means for near real-time\nestimates at scale. These may, in turn, provide grist for supporting,\nevaluating and iteratively improving upon public health programs and\ninterventions.\n  We propose a novel model for automated mental health status quantification\nthat incorporates user embeddings. This builds upon recent work exploring\nrepresentation learning methods that induce embeddings by leveraging social\nmedia post histories. Such embeddings capture latent characteristics of\nindividuals (e.g., political leanings) and encode a soft notion of homophily.\nIn this paper, we investigate whether user embeddings learned from twitter post\nhistories encode information that correlates with mental health statuses. To\nthis end, we estimated user embeddings for a set of users known to be affected\nby depression and post-traumatic stress disorder (PTSD), and for a set of\ndemographically matched `control' users. We then evaluated these embeddings\nwith respect to: (i) their ability to capture homophilic relations with respect\nto mental health status; and (ii) the performance of downstream mental health\nprediction models based on these features. Our experimental results demonstrate\nthat the user embeddings capture similarities between users with respect to\nmental conditions, and are predictive of mental health. \n\n"}
{"id": "1705.00464", "contents": "Title: Speech-Based Visual Question Answering Abstract: This paper introduces speech-based visual question answering (VQA), the task\nof generating an answer given an image and a spoken question. Two methods are\nstudied: an end-to-end, deep neural network that directly uses audio waveforms\nas input versus a pipelined approach that performs ASR (Automatic Speech\nRecognition) on the question, followed by text-based visual question answering.\nFurthermore, we investigate the robustness of both methods by injecting various\nlevels of noise into the spoken question and find both methods to be tolerate\nnoise at similar levels. \n\n"}
{"id": "1705.01991", "contents": "Title: Sharp Models on Dull Hardware: Fast and Accurate Neural Machine\n  Translation Decoding on the CPU Abstract: Attentional sequence-to-sequence models have become the new standard for\nmachine translation, but one challenge of such models is a significant increase\nin training and decoding cost compared to phrase-based systems. Here, we focus\non efficient decoding, with a goal of achieving accuracy close the\nstate-of-the-art in neural machine translation (NMT), while achieving CPU\ndecoding speed/throughput close to that of a phrasal decoder.\n  We approach this problem from two angles: First, we describe several\ntechniques for speeding up an NMT beam search decoder, which obtain a 4.4x\nspeedup over a very efficient baseline decoder without changing the decoder\noutput. Second, we propose a simple but powerful network architecture which\nuses an RNN (GRU/LSTM) layer at bottom, followed by a series of stacked\nfully-connected layers applied at every timestep. This architecture achieves\nsimilar accuracy to a deep recurrent model, at a small fraction of the training\nand decoding cost. By combining these techniques, our best system achieves a\nvery competitive accuracy of 38.3 BLEU on WMT English-French NewsTest2014,\nwhile decoding at 100 words/sec on single-threaded CPU. We believe this is the\nbest published accuracy/speed trade-off of an NMT system. \n\n"}
{"id": "1705.02364", "contents": "Title: Supervised Learning of Universal Sentence Representations from Natural\n  Language Inference Data Abstract: Many modern NLP systems rely on word embeddings, previously trained in an\nunsupervised manner on large corpora, as base features. Efforts to obtain\nembeddings for larger chunks of text, such as sentences, have however not been\nso successful. Several attempts at learning unsupervised representations of\nsentences have not reached satisfactory enough performance to be widely\nadopted. In this paper, we show how universal sentence representations trained\nusing the supervised data of the Stanford Natural Language Inference datasets\ncan consistently outperform unsupervised methods like SkipThought vectors on a\nwide range of transfer tasks. Much like how computer vision uses ImageNet to\nobtain features, which can then be transferred to other tasks, our work tends\nto indicate the suitability of natural language inference for transfer learning\nto other NLP tasks. Our encoder is publicly available. \n\n"}
{"id": "1705.02735", "contents": "Title: Combating Human Trafficking with Deep Multimodal Models Abstract: Human trafficking is a global epidemic affecting millions of people across\nthe planet. Sex trafficking, the dominant form of human trafficking, has seen a\nsignificant rise mostly due to the abundance of escort websites, where human\ntraffickers can openly advertise among at-will escort advertisements. In this\npaper, we take a major step in the automatic detection of advertisements\nsuspected to pertain to human trafficking. We present a novel dataset called\nTrafficking-10k, with more than 10,000 advertisements annotated for this task.\nThe dataset contains two sources of information per advertisement: text and\nimages. For the accurate detection of trafficking advertisements, we designed\nand trained a deep multimodal model called the Human Trafficking Deep Network\n(HTDN). \n\n"}
{"id": "1705.03557", "contents": "Title: DeepTingle Abstract: DeepTingle is a text prediction and classification system trained on the\ncollected works of the renowned fantastic gay erotica author Chuck Tingle.\nWhereas the writing assistance tools you use everyday (in the form of\npredictive text, translation, grammar checking and so on) are trained on\ngeneric, purportedly \"neutral\" datasets, DeepTingle is trained on a very\nspecific, internally consistent but externally arguably eccentric dataset. This\nallows us to foreground and confront the norms embedded in data-driven\ncreativity and productivity assistance tools. As such tools effectively\nfunction as extensions of our cognition into technology, it is important to\nidentify the norms they embed within themselves and, by extension, us.\nDeepTingle is realized as a web application based on LSTM networks and the\nGloVe word embedding, implemented in JavaScript with Keras-JS. \n\n"}
{"id": "1705.03670", "contents": "Title: Deep Speaker Feature Learning for Text-independent Speaker Verification Abstract: Recently deep neural networks (DNNs) have been used to learn speaker\nfeatures. However, the quality of the learned features is not sufficiently\ngood, so a complex back-end model, either neural or probabilistic, has to be\nused to address the residual uncertainty when applied to speaker verification,\njust as with raw features. This paper presents a convolutional time-delay deep\nneural network structure (CT-DNN) for speaker feature learning. Our\nexperimental results on the Fisher database demonstrated that this CT-DNN can\nproduce high-quality speaker features: even with a single feature (0.3 seconds\nincluding the context), the EER can be as low as 7.68%. This effectively\nconfirmed that the speaker trait is largely a deterministic short-time property\nrather than a long-time distributional pattern, and therefore can be extracted\nfrom just dozens of frames. \n\n"}
{"id": "1705.04146", "contents": "Title: Program Induction by Rationale Generation : Learning to Solve and\n  Explain Algebraic Word Problems Abstract: Solving algebraic word problems requires executing a series of arithmetic\noperations---a program---to obtain a final answer. However, since programs can\nbe arbitrarily complicated, inducing them directly from question-answer pairs\nis a formidable challenge. To make this task more feasible, we solve these\nproblems by generating answer rationales, sequences of natural language and\nhuman-readable mathematical expressions that derive the final answer through a\nseries of small steps. Although rationales do not explicitly specify programs,\nthey provide a scaffolding for their structure via intermediate milestones. To\nevaluate our approach, we have created a new 100,000-sample dataset of\nquestions, answers and rationales. Experimental results show that indirect\nsupervision of program learning via answer rationales is a promising strategy\nfor inducing arithmetic programs. \n\n"}
{"id": "1705.04400", "contents": "Title: Reducing Bias in Production Speech Models Abstract: Replacing hand-engineered pipelines with end-to-end deep learning systems has\nenabled strong results in applications like speech and object recognition.\nHowever, the causality and latency constraints of production systems put\nend-to-end speech models back into the underfitting regime and expose biases in\nthe model that we show cannot be overcome by \"scaling up\", i.e., training\nbigger models on more data. In this work we systematically identify and address\nsources of bias, reducing error rates by up to 20% while remaining practical\nfor deployment. We achieve this by utilizing improved neural architectures for\nstreaming inference, solving optimization issues, and employing strategies that\nincrease audio and label modelling versatility. \n\n"}
{"id": "1705.04434", "contents": "Title: Arc-swift: A Novel Transition System for Dependency Parsing Abstract: Transition-based dependency parsers often need sequences of local shift and\nreduce operations to produce certain attachments. Correct individual decisions\nhence require global information about the sentence context and mistakes cause\nerror propagation. This paper proposes a novel transition system, arc-swift,\nthat enables direct attachments between tokens farther apart with a single\ntransition. This allows the parser to leverage lexical information more\ndirectly in transition decisions. Hence, arc-swift can achieve significantly\nbetter performance with a very small beam size. Our parsers reduce error by\n3.7--7.6% relative to those using existing transition systems on the Penn\nTreebank dependency parsing task and English Universal Dependencies. \n\n"}
{"id": "1705.06273", "contents": "Title: Transfer Learning for Named-Entity Recognition with Neural Networks Abstract: Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for named-entity recognition (NER). In order to achieve high\nperformances, ANNs need to be trained on a large labeled dataset. However,\nlabels might be difficult to obtain for the dataset on which the user wants to\nperform NER: label scarcity is particularly pronounced for patient note\nde-identification, which is an instance of NER. In this work, we analyze to\nwhat extent transfer learning may address this issue. In particular, we\ndemonstrate that transferring an ANN model trained on a large labeled dataset\nto another dataset with a limited number of labels improves upon the\nstate-of-the-art results on two different datasets for patient note\nde-identification. \n\n"}
{"id": "1705.07136", "contents": "Title: Softmax Q-Distribution Estimation for Structured Prediction: A\n  Theoretical Interpretation for RAML Abstract: Reward augmented maximum likelihood (RAML), a simple and effective learning\nframework to directly optimize towards the reward function in structured\nprediction tasks, has led to a number of impressive empirical successes. RAML\nincorporates task-specific reward by performing maximum-likelihood updates on\ncandidate outputs sampled according to an exponentiated payoff distribution,\nwhich gives higher probabilities to candidates that are close to the reference\noutput. While RAML is notable for its simplicity, efficiency, and its\nimpressive empirical successes, the theoretical properties of RAML, especially\nthe behavior of the exponentiated payoff distribution, has not been examined\nthoroughly. In this work, we introduce softmax Q-distribution estimation, a\nnovel theoretical interpretation of RAML, which reveals the relation between\nRAML and Bayesian decision theory. The softmax Q-distribution can be regarded\nas a smooth approximation of the Bayes decision boundary, and the Bayes\ndecision rule is achieved by decoding with this Q-distribution. We further show\nthat RAML is equivalent to approximately estimating the softmax Q-distribution,\nwith the temperature $\\tau$ controlling approximation error. We perform two\nexperiments, one on synthetic data of multi-class classification and one on\nreal data of image captioning, to demonstrate the relationship between RAML and\nthe proposed softmax Q-distribution estimation method, verifying our\ntheoretical analysis. Additional experiments on three structured prediction\ntasks with rewards defined on sequential (named entity recognition), tree-based\n(dependency parsing) and irregular (machine translation) structures show\nnotable improvements over maximum likelihood baselines. \n\n"}
{"id": "1705.08091", "contents": "Title: Local Monotonic Attention Mechanism for End-to-End Speech and Language\n  Processing Abstract: Recently, encoder-decoder neural networks have shown impressive performance\non many sequence-related tasks. The architecture commonly uses an attentional\nmechanism which allows the model to learn alignments between the source and the\ntarget sequence. Most attentional mechanisms used today is based on a global\nattention property which requires a computation of a weighted summarization of\nthe whole input sequence generated by encoder states. However, it is\ncomputationally expensive and often produces misalignment on the longer input\nsequence. Furthermore, it does not fit with monotonous or left-to-right nature\nin several tasks, such as automatic speech recognition (ASR),\ngrapheme-to-phoneme (G2P), etc. In this paper, we propose a novel attention\nmechanism that has local and monotonic properties. Various ways to control\nthose properties are also explored. Experimental results on ASR, G2P and\nmachine translation between two languages with similar sentence structures,\ndemonstrate that the proposed encoder-decoder model with local monotonic\nattention could achieve significant performance improvements and reduce the\ncomputational complexity in comparison with the one that used the standard\nglobal attention architecture. \n\n"}
{"id": "1705.08142", "contents": "Title: Latent Multi-task Architecture Learning Abstract: Multi-task learning (MTL) allows deep neural networks to learn from related\ntasks by sharing parameters with other networks. In practice, however, MTL\ninvolves searching an enormous space of possible parameter sharing\narchitectures to find (a) the layers or subspaces that benefit from sharing,\n(b) the appropriate amount of sharing, and (c) the appropriate relative weights\nof the different task losses. Recent work has addressed each of the above\nproblems in isolation. In this work we present an approach that learns a latent\nmulti-task architecture that jointly addresses (a)--(c). We present experiments\non synthetic data and data from OntoNotes 5.0, including four different tasks\nand seven different domains. Our extension consistently outperforms previous\napproaches to learning latent architectures for multi-task problems and\nachieves up to 15% average error reductions over common approaches to MTL. \n\n"}
{"id": "1705.08557", "contents": "Title: Grounded Recurrent Neural Networks Abstract: In this work, we present the Grounded Recurrent Neural Network (GRNN), a\nrecurrent neural network architecture for multi-label prediction which\nexplicitly ties labels to specific dimensions of the recurrent hidden state (we\ncall this process \"grounding\"). The approach is particularly well-suited for\nextracting large numbers of concepts from text. We apply the new model to\naddress an important problem in healthcare of understanding what medical\nconcepts are discussed in clinical text. Using a publicly available dataset\nderived from Intensive Care Units, we learn to label a patient's diagnoses and\nprocedures from their discharge summary. Our evaluation shows a clear advantage\nto using our proposed architecture over a variety of strong baselines. \n\n"}
{"id": "1705.09037", "contents": "Title: Deriving Neural Architectures from Sequence and Graph Kernels Abstract: The design of neural architectures for structured objects is typically guided\nby experimental insights rather than a formal process. In this work, we appeal\nto kernels over combinatorial structures, such as sequences and graphs, to\nderive appropriate neural operations. We introduce a class of deep recurrent\nneural operations and formally characterize their associated kernel spaces. Our\nrecurrent modules compare the input to virtual reference objects (cf. filters\nin CNN) via the kernels. Similar to traditional neural operations, these\nreference objects are parameterized and directly optimized in end-to-end\ntraining. We empirically evaluate the proposed class of neural architectures on\nstandard applications such as language modeling and molecular graph regression,\nachieving state-of-the-art results across these applications. \n\n"}
{"id": "1705.09516", "contents": "Title: Biomedical Event Trigger Identification Using Bidirectional Recurrent\n  Neural Network Based Models Abstract: Biomedical events describe complex interactions between various biomedical\nentities. Event trigger is a word or a phrase which typically signifies the\noccurrence of an event. Event trigger identification is an important first step\nin all event extraction methods. However many of the current approaches either\nrely on complex hand-crafted features or consider features only within a\nwindow. In this paper we propose a method that takes the advantage of recurrent\nneural network (RNN) to extract higher level features present across the\nsentence. Thus hidden state representation of RNN along with word and entity\ntype embedding as features avoid relying on the complex hand-crafted features\ngenerated using various NLP toolkits. Our experiments have shown to achieve\nstate-of-art F1-score on Multi Level Event Extraction (MLEE) corpus. We have\nalso performed category-wise analysis of the result and discussed the\nimportance of various features in trigger identification task. \n\n"}
{"id": "1705.09980", "contents": "Title: Neural Semantic Parsing by Character-based Translation: Experiments with\n  Abstract Meaning Representations Abstract: We evaluate the character-level translation method for neural semantic\nparsing on a large corpus of sentences annotated with Abstract Meaning\nRepresentations (AMRs). Using a sequence-to-sequence model, and some trivial\npreprocessing and postprocessing of AMRs, we obtain a baseline accuracy of 53.1\n(F-score on AMR-triples). We examine five different approaches to improve this\nbaseline result: (i) reordering AMR branches to match the word order of the\ninput sentence increases performance to 58.3; (ii) adding part-of-speech tags\n(automatically produced) to the input shows improvement as well (57.2); (iii)\nSo does the introduction of super characters (conflating frequent sequences of\ncharacters to a single character), reaching 57.4; (iv) optimizing the training\nprocess by using pre-training and averaging a set of models increases\nperformance to 58.7; (v) adding silver-standard training data obtained by an\noff-the-shelf parser yields the biggest improvement, resulting in an F-score of\n64.0. Combining all five techniques leads to an F-score of 71.0 on holdout\ndata, which is state-of-the-art in AMR parsing. This is remarkable because of\nthe relative simplicity of the approach. \n\n"}
{"id": "1705.09993", "contents": "Title: Deep Learning for User Comment Moderation Abstract: Experimenting with a new dataset of 1.6M user comments from a Greek news\nportal and existing datasets of English Wikipedia comments, we show that an RNN\noutperforms the previous state of the art in moderation. A deep,\nclassification-specific attention mechanism improves further the overall\nperformance of the RNN. We also compare against a CNN and a word-list baseline,\nconsidering both fully automatic and semi-automatic moderation. \n\n"}
{"id": "1705.10415", "contents": "Title: On the \"Calligraphy\" of Books Abstract: Authorship attribution is a natural language processing task that has been\nwidely studied, often by considering small order statistics. In this paper, we\nexplore a complex network approach to assign the authorship of texts based on\ntheir mesoscopic representation, in an attempt to capture the flow of the\nnarrative. Indeed, as reported in this work, such an approach allowed the\nidentification of the dominant narrative structure of the studied authors. This\nhas been achieved due to the ability of the mesoscopic approach to take into\naccount relationships between different, not necessarily adjacent, parts of the\ntext, which is able to capture the story flow. The potential of the proposed\napproach has been illustrated through principal component analysis, a\ncomparison with the chance baseline method, and network visualization. Such\nvisualizations reveal individual characteristics of the authors, which can be\nunderstood as a kind of calligraphy. \n\n"}
{"id": "1705.10874", "contents": "Title: Deep Learning for Environmentally Robust Speech Recognition: An Overview\n  of Recent Developments Abstract: Eliminating the negative effect of non-stationary environmental noise is a\nlong-standing research topic for automatic speech recognition that stills\nremains an important challenge. Data-driven supervised approaches, including\nones based on deep neural networks, have recently emerged as potential\nalternatives to traditional unsupervised approaches and with sufficient\ntraining, can alleviate the shortcomings of the unsupervised methods in various\nreal-life acoustic environments. In this light, we review recently developed,\nrepresentative deep learning approaches for tackling non-stationary additive\nand convolutional degradation of speech with the aim of providing guidelines\nfor those involved in the development of environmentally robust speech\nrecognition systems. We separately discuss single- and multi-channel techniques\ndeveloped for the front-end and back-end of speech recognition systems, as well\nas joint front-end and back-end training frameworks. \n\n"}
{"id": "1705.11001", "contents": "Title: Adversarial Ranking for Language Generation Abstract: Generative adversarial networks (GANs) have great successes on synthesizing\ndata. However, the existing GANs restrict the discriminator to be a binary\nclassifier, and thus limit their learning capacity for tasks that need to\nsynthesize output with rich structures such as natural language descriptions.\nIn this paper, we propose a novel generative adversarial network, RankGAN, for\ngenerating high-quality language descriptions. Rather than training the\ndiscriminator to learn and assign absolute binary predicate for individual data\nsample, the proposed RankGAN is able to analyze and rank a collection of\nhuman-written and machine-written sentences by giving a reference group. By\nviewing a set of data samples collectively and evaluating their quality through\nrelative ranking scores, the discriminator is able to make better assessment\nwhich in turn helps to learn a better generator. The proposed RankGAN is\noptimized through the policy gradient technique. Experimental results on\nmultiple public datasets clearly demonstrate the effectiveness of the proposed\napproach. \n\n"}
{"id": "1706.00374", "contents": "Title: Semantic Specialisation of Distributional Word Vector Spaces using\n  Monolingual and Cross-Lingual Constraints Abstract: We present Attract-Repel, an algorithm for improving the semantic quality of\nword vectors by injecting constraints extracted from lexical resources.\nAttract-Repel facilitates the use of constraints from mono- and cross-lingual\nresources, yielding semantically specialised cross-lingual vector spaces. Our\nevaluation shows that the method can make use of existing cross-lingual\nlexicons to construct high-quality vector spaces for a plethora of different\nlanguages, facilitating semantic transfer from high- to lower-resource ones.\nThe effectiveness of our approach is demonstrated with state-of-the-art results\non semantic similarity datasets in six languages. We next show that\nAttract-Repel-specialised vectors boost performance in the downstream task of\ndialogue state tracking (DST) across multiple languages. Finally, we show that\ncross-lingual vector spaces produced by our algorithm facilitate the training\nof multilingual DST models, which brings further performance improvements. \n\n"}
{"id": "1706.00741", "contents": "Title: Prosodic Event Recognition using Convolutional Neural Networks with\n  Context Information Abstract: This paper demonstrates the potential of convolutional neural networks (CNN)\nfor detecting and classifying prosodic events on words, specifically pitch\naccents and phrase boundary tones, from frame-based acoustic features. Typical\napproaches use not only feature representations of the word in question but\nalso its surrounding context. We show that adding position features indicating\nthe current word benefits the CNN. In addition, this paper discusses the\ngeneralization from a speaker-dependent modelling approach to a\nspeaker-independent setup. The proposed method is simple and efficient and\nyields strong results not only in speaker-dependent but also\nspeaker-independent cases. \n\n"}
{"id": "1706.01399", "contents": "Title: Language Generation with Recurrent Generative Adversarial Networks\n  without Pre-training Abstract: Generative Adversarial Networks (GANs) have shown great promise recently in\nimage generation. Training GANs for language generation has proven to be more\ndifficult, because of the non-differentiable nature of generating text with\nrecurrent neural networks. Consequently, past work has either resorted to\npre-training with maximum-likelihood or used convolutional networks for\ngeneration. In this work, we show that recurrent neural networks can be trained\nto generate text with GANs from scratch using curriculum learning, by slowly\nteaching the model to generate sequences of increasing and variable length. We\nempirically show that our approach vastly improves the quality of generated\nsequences compared to a convolutional baseline. \n\n"}
{"id": "1706.01427", "contents": "Title: A simple neural network module for relational reasoning Abstract: Relational reasoning is a central component of generally intelligent\nbehavior, but has proven difficult for neural networks to learn. In this paper\nwe describe how to use Relation Networks (RNs) as a simple plug-and-play module\nto solve problems that fundamentally hinge on relational reasoning. We tested\nRN-augmented networks on three tasks: visual question answering using a\nchallenging dataset called CLEVR, on which we achieve state-of-the-art,\nsuper-human performance; text-based question answering using the bAbI suite of\ntasks; and complex reasoning about dynamic physical systems. Then, using a\ncurated dataset called Sort-of-CLEVR we show that powerful convolutional\nnetworks do not have a general capacity to solve relational questions, but can\ngain this capacity when augmented with RNs. Our work shows how a deep learning\narchitecture equipped with an RN module can implicitly discover and learn to\nreason about entities and their relations. \n\n"}
{"id": "1706.02141", "contents": "Title: How Important is Syntactic Parsing Accuracy? An Empirical Evaluation on\n  Rule-Based Sentiment Analysis Abstract: Syntactic parsing, the process of obtaining the internal structure of\nsentences in natural languages, is a crucial task for artificial intelligence\napplications that need to extract meaning from natural language text or speech.\nSentiment analysis is one example of application for which parsing has recently\nproven useful.\n  In recent years, there have been significant advances in the accuracy of\nparsing algorithms. In this article, we perform an empirical, task-oriented\nevaluation to determine how parsing accuracy influences the performance of a\nstate-of-the-art rule-based sentiment analysis system that determines the\npolarity of sentences from their parse trees. In particular, we evaluate the\nsystem using four well-known dependency parsers, including both current models\nwith state-of-the-art accuracy and more innacurate models which, however,\nrequire less computational resources.\n  The experiments show that all of the parsers produce similarly good results\nin the sentiment analysis task, without their accuracy having any relevant\ninfluence on the results. Since parsing is currently a task with a relatively\nhigh computational cost that varies strongly between algorithms, this suggests\nthat sentiment analysis researchers and users should prioritize speed over\naccuracy when choosing a parser; and parsing researchers should investigate\nmodels that improve speed further, even at some cost to accuracy. \n\n"}
{"id": "1706.02515", "contents": "Title: Self-Normalizing Neural Networks Abstract: Deep Learning has revolutionized vision via convolutional neural networks\n(CNNs) and natural language processing via recurrent neural networks (RNNs).\nHowever, success stories of Deep Learning with standard feed-forward neural\nnetworks (FNNs) are rare. FNNs that perform well are typically shallow and,\ntherefore cannot exploit many levels of abstract representations. We introduce\nself-normalizing neural networks (SNNs) to enable high-level abstract\nrepresentations. While batch normalization requires explicit normalization,\nneuron activations of SNNs automatically converge towards zero mean and unit\nvariance. The activation function of SNNs are \"scaled exponential linear units\"\n(SELUs), which induce self-normalizing properties. Using the Banach fixed-point\ntheorem, we prove that activations close to zero mean and unit variance that\nare propagated through many network layers will converge towards zero mean and\nunit variance -- even under the presence of noise and perturbations. This\nconvergence property of SNNs allows to (1) train deep networks with many\nlayers, (2) employ strong regularization, and (3) to make learning highly\nrobust. Furthermore, for activations not close to unit variance, we prove an\nupper and lower bound on the variance, thus, vanishing and exploding gradients\nare impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning\nrepository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with\nstandard FNNs and other machine learning methods such as random forests and\nsupport vector machines. SNNs significantly outperformed all competing FNN\nmethods at 121 UCI tasks, outperformed all competing methods at the Tox21\ndataset, and set a new record at an astronomy data set. The winning SNN\narchitectures are often very deep. Implementations are available at:\ngithub.com/bioinf-jku/SNNs. \n\n"}
{"id": "1706.02807", "contents": "Title: Learning to Embed Words in Context for Syntactic Tasks Abstract: We present models for embedding words in the context of surrounding words.\nSuch models, which we refer to as token embeddings, represent the\ncharacteristics of a word that are specific to a given context, such as word\nsense, syntactic category, and semantic role. We explore simple, efficient\ntoken embedding models based on standard neural network architectures. We learn\ntoken embeddings on a large amount of unannotated text and evaluate them as\nfeatures for part-of-speech taggers and dependency parsers trained on much\nsmaller amounts of annotated data. We find that predictors endowed with token\nembeddings consistently outperform baseline predictors across a range of\ncontext window and training set sizes. \n\n"}
{"id": "1706.02861", "contents": "Title: Assigning personality/identity to a chatting machine for coherent\n  conversation generation Abstract: Endowing a chatbot with personality or an identity is quite challenging but\ncritical to deliver more realistic and natural conversations. In this paper, we\naddress the issue of generating responses that are coherent to a pre-specified\nagent profile. We design a model consisting of three modules: a profile\ndetector to decide whether a post should be responded using the profile and\nwhich key should be addressed, a bidirectional decoder to generate responses\nforward and backward starting from a selected profile value, and a position\ndetector that predicts a word position from which decoding should start given a\nselected profile value. We show that general conversation data from social\nmedia can be used to generate profile-coherent responses. Manual and automatic\nevaluation shows that our model can deliver more coherent, natural, and\ndiversified responses. \n\n"}
{"id": "1706.03762", "contents": "Title: Attention Is All You Need Abstract: The dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks in an encoder-decoder configuration. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer, based\nsolely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to be\nsuperior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\nEnglish-to-German translation task, improving over the existing best results,\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\ntranslation task, our model establishes a new single-model state-of-the-art\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\nof the training costs of the best models from the literature. We show that the\nTransformer generalizes well to other tasks by applying it successfully to\nEnglish constituency parsing both with large and limited training data. \n\n"}
{"id": "1706.03850", "contents": "Title: Adversarial Feature Matching for Text Generation Abstract: The Generative Adversarial Network (GAN) has achieved great success in\ngenerating realistic (real-valued) synthetic data. However, convergence issues\nand difficulties dealing with discrete data hinder the applicability of GAN to\ntext. We propose a framework for generating realistic text via adversarial\ntraining. We employ a long short-term memory network as generator, and a\nconvolutional network as discriminator. Instead of using the standard objective\nof GAN, we propose matching the high-dimensional latent feature distributions\nof real and synthetic sentences, via a kernelized discrepancy metric. This\neases adversarial training by alleviating the mode-collapsing problem. Our\nexperiments show superior performance in quantitative evaluation, and\ndemonstrate that our model can generate realistic-looking sentences. \n\n"}
{"id": "1706.04902", "contents": "Title: A Survey Of Cross-lingual Word Embedding Models Abstract: Cross-lingual representations of words enable us to reason about word meaning\nin multilingual contexts and are a key facilitator of cross-lingual transfer\nwhen developing natural language processing models for low-resource languages.\nIn this survey, we provide a comprehensive typology of cross-lingual word\nembedding models. We compare their data requirements and objective functions.\nThe recurring theme of the survey is that many of the models presented in the\nliterature optimize for the same objectives, and that seemingly different\nmodels are often equivalent modulo optimization strategies, hyper-parameters,\nand such. We also discuss the different ways cross-lingual word embeddings are\nevaluated, as well as future challenges and research horizons. \n\n"}
{"id": "1706.04997", "contents": "Title: Extracting Formal Models from Normative Texts Abstract: We are concerned with the analysis of normative texts - documents based on\nthe deontic notions of obligation, permission, and prohibition. Our goal is to\nmake queries about these notions and verify that a text satisfies certain\nproperties concerning causality of actions and timing constraints. This\nrequires taking the original text and building a representation (model) of it\nin a formal language, in our case the C-O Diagram formalism. We present an\nexperimental, semi-automatic aid that helps to bridge the gap between a\nnormative text in natural language and its C-O Diagram representation. Our\napproach consists of using dependency structures obtained from the\nstate-of-the-art Stanford Parser, and applying our own rules and heuristics in\norder to extract the relevant components. The result is a tabular data\nstructure where each sentence is split into suitable fields, which can then be\nconverted into a C-O Diagram. The process is not fully automatic however, and\nsome post-editing is generally required of the user. We apply our tool and\nperform experiments on documents from different domains, and report an initial\nevaluation of the accuracy and feasibility of our approach. \n\n"}
{"id": "1706.05674", "contents": "Title: Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural\n  Network Approach Abstract: Knowledge base completion (KBC) aims to predict missing information in a\nknowledge base.In this paper, we address the out-of-knowledge-base (OOKB)\nentity problem in KBC:how to answer queries concerning test entities not\nobserved at training time. Existing embedding-based KBC models assume that all\ntest entities are available at training time, making it unclear how to obtain\nembeddings for new entities without costly retraining. To solve the OOKB entity\nproblem without retraining, we use graph neural networks (Graph-NNs) to compute\nthe embeddings of OOKB entities, exploiting the limited auxiliary knowledge\nprovided at test time.The experimental results show the effectiveness of our\nproposed model in the OOKB setting.Additionally, in the standard KBC setting in\nwhich OOKB entities are not involved, our model achieves state-of-the-art\nperformance on the WordNet dataset. The code and dataset are available at\nhttps://github.com/takuo-h/GNN-for-OOKB \n\n"}
{"id": "1706.06551", "contents": "Title: Grounded Language Learning in a Simulated 3D World Abstract: We are increasingly surrounded by artificially intelligent technology that\ntakes decisions and executes actions on our behalf. This creates a pressing\nneed for general means to communicate with, instruct and guide artificial\nagents, with human language the most compelling means for such communication.\nTo achieve this in a scalable fashion, agents must be able to relate language\nto the world and to actions; that is, their understanding of language must be\ngrounded and embodied. However, learning grounded language is a notoriously\nchallenging problem in artificial intelligence research. Here we present an\nagent that learns to interpret language in a simulated 3D environment where it\nis rewarded for the successful execution of written instructions. Trained via a\ncombination of reinforcement and unsupervised learning, and beginning with\nminimal prior knowledge, the agent learns to relate linguistic symbols to\nemergent perceptual representations of its physical surroundings and to\npertinent sequences of actions. The agent's comprehension of language extends\nbeyond its prior experience, enabling it to apply familiar language to\nunfamiliar situations and to interpret entirely novel instructions. Moreover,\nthe speed with which this agent learns new words increases as its semantic\nknowledge grows. This facility for generalising and bootstrapping semantic\nknowledge indicates the potential of the present approach for reconciling\nambiguous natural language with the complexity of the physical world. \n\n"}
{"id": "1706.07440", "contents": "Title: End-to-end Conversation Modeling Track in DSTC6 Abstract: End-to-end training of neural networks is a promising approach to automatic\nconstruction of dialog systems using a human-to-human dialog corpus. Recently,\nVinyals et al. tested neural conversation models using OpenSubtitles. Lowe et\nal. released the Ubuntu Dialogue Corpus for researching unstructured multi-turn\ndialogue systems. Furthermore, the approach has been extended to accomplish\ntask oriented dialogs to provide information properly with natural\nconversation. For example, Ghazvininejad et al. proposed a knowledge grounded\nneural conversation model [3], where the research is aiming at combining\nconversational dialogs with task-oriented knowledge using unstructured data\nsuch as Twitter data for conversation and Foursquare data for external\nknowledge.However, the task is still limited to a restaurant information\nservice, and has not yet been tested with a wide variety of dialog tasks. In\naddition, it is still unclear how to create intelligent dialog systems that can\nrespond like a human agent.\n  In consideration of these problems, we proposed a challenge track to the 6th\ndialog system technology challenges (DSTC6) using human-to-human dialog data to\nmimic human dialog behaviors. The focus of the challenge track is to train\nend-to-end conversation models from human-to-human conversation and accomplish\nend-to-end dialog tasks in various situations assuming a customer service, in\nwhich a system plays a role of human agent and generates natural and\ninformative sentences in response to user's questions or comments given dialog\ncontext. \n\n"}
{"id": "1706.07861", "contents": "Title: Cross-lingual Speaker Verification with Deep Feature Learning Abstract: Existing speaker verification (SV) systems often suffer from performance\ndegradation if there is any language mismatch between model training, speaker\nenrollment, and test. A major cause of this degradation is that most existing\nSV methods rely on a probabilistic model to infer the speaker factor, so any\nsignificant change on the distribution of the speech signal will impact the\ninference. Recently, we proposed a deep learning model that can learn how to\nextract the speaker factor by a deep neural network (DNN). By this feature\nlearning, an SV system can be constructed with a very simple back-end model. In\nthis paper, we investigate the robustness of the feature-based SV system in\nsituations with language mismatch. Our experiments were conducted on a complex\ncross-lingual scenario, where the model training was in English, and the\nenrollment and test were in Chinese or Uyghur. The experiments demonstrated\nthat the feature-based system outperformed the i-vector system with a large\nmargin, particularly with language mismatch between enrollment and test. \n\n"}
{"id": "1706.08476", "contents": "Title: Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog\n  Systems with Chatting Capability Abstract: Generative encoder-decoder models offer great promise in developing\ndomain-general dialog systems. However, they have mainly been applied to\nopen-domain conversations. This paper presents a practical and novel framework\nfor building task-oriented dialog systems based on encoder-decoder models. This\nframework enables encoder-decoder models to accomplish slot-value independent\ndecision-making and interact with external databases. Moreover, this paper\nshows the flexibility of the proposed method by interleaving chatting\ncapability with a slot-filling system for better out-of-domain recovery. The\nmodels were trained on both real-user data from a bus information system and\nhuman-human chat data. Results show that the proposed framework achieves good\nperformance in both offline evaluation metrics and in task success rate with\nhuman users. \n\n"}
{"id": "1706.09335", "contents": "Title: Generating Appealing Brand Names Abstract: Providing appealing brand names to newly launched products, newly formed\ncompanies or for renaming existing companies is highly important as it can play\na crucial role in deciding its success or failure. In this work, we propose a\ncomputational method to generate appealing brand names based on the description\nof such entities. We use quantitative scores for readability, pronounceability,\nmemorability and uniqueness of the generated names to rank order them. A set of\ndiverse appealing names is recommended to the user for the brand naming task.\nExperimental results show that the names generated by our approach are more\nappealing than names which prior approaches and recruited humans could come up. \n\n"}
{"id": "1706.09673", "contents": "Title: Improving Distributed Representations of Tweets - Present and Future Abstract: Unsupervised representation learning for tweets is an important research\nfield which helps in solving several business applications such as sentiment\nanalysis, hashtag prediction, paraphrase detection and microblog ranking. A\ngood tweet representation learning model must handle the idiosyncratic nature\nof tweets which poses several challenges such as short length, informal words,\nunusual grammar and misspellings. However, there is a lack of prior work which\nsurveys the representation learning models with a focus on tweets. In this\nwork, we organize the models based on its objective function which aids the\nunderstanding of the literature. We also provide interesting future directions,\nwhich we believe are fruitful in advancing this field by building high-quality\ntweet representation learning models. \n\n"}
{"id": "1707.00079", "contents": "Title: Synthetic Data for Neural Machine Translation of Spoken-Dialects Abstract: In this paper, we introduce a novel approach to generate synthetic data for\ntraining Neural Machine Translation systems. The proposed approach transforms a\ngiven parallel corpus between a written language and a target language to a\nparallel corpus between a spoken dialect variant and the target language. Our\napproach is language independent and can be used to generate data for any\nvariant of the source language such as slang or spoken dialect or even for a\ndifferent language that is closely related to the source language.\n  The proposed approach is based on local embedding projection of distributed\nrepresentations which utilizes monolingual embeddings to transform parallel\ndata across language variants. We report experimental results on Levantine to\nEnglish translation using Neural Machine Translation. We show that the\ngenerated data can improve a very large scale system by more than 2.8 Bleu\npoints using synthetic spoken data which shows that it can be used to provide a\nreliable translation system for a spoken dialect that does not have sufficient\nparallel data. \n\n"}
{"id": "1707.00110", "contents": "Title: Efficient Attention using a Fixed-Size Memory Representation Abstract: The standard content-based attention mechanism typically used in\nsequence-to-sequence models is computationally expensive as it requires the\ncomparison of large encoder and decoder states at each time step. In this work,\nwe propose an alternative attention mechanism based on a fixed size memory\nrepresentation that is more efficient. Our technique predicts a compact set of\nK attention contexts during encoding and lets the decoder compute an efficient\nlookup that does not need to consult the memory. We show that our approach\nperforms on-par with the standard attention mechanism while yielding inference\nspeedups of 20% for real-world translation tasks and more for tasks with longer\nsequences. By visualizing attention scores we demonstrate that our models learn\ndistinct, meaningful alignments. \n\n"}
{"id": "1707.00201", "contents": "Title: Rank-1 Constrained Multichannel Wiener Filter for Speech Recognition in\n  Noisy Environments Abstract: Multichannel linear filters, such as the Multichannel Wiener Filter (MWF) and\nthe Generalized Eigenvalue (GEV) beamformer are popular signal processing\ntechniques which can improve speech recognition performance. In this paper, we\npresent an experimental study on these linear filters in a specific speech\nrecognition task, namely the CHiME-4 challenge, which features real recordings\nin multiple noisy environments. Specifically, the rank-1 MWF is employed for\nnoise reduction and a new constant residual noise power constraint is derived\nwhich enhances the recognition performance. To fulfill the underlying rank-1\nassumption, the speech covariance matrix is reconstructed based on eigenvectors\nor generalized eigenvectors. Then the rank-1 constrained MWF is evaluated with\nalternative multichannel linear filters under the same framework, which\ninvolves a Bidirectional Long Short-Term Memory (BLSTM) network for mask\nestimation. The proposed filter outperforms alternative ones, leading to a 40%\nrelative Word Error Rate (WER) reduction compared with the baseline Weighted\nDelay and Sum (WDAS) beamformer on the real test set, and a 15% relative WER\nreduction compared with the GEV-BAN method. The results also suggest that the\nspeech recognition accuracy correlates more with the Mel-frequency cepstral\ncoefficients (MFCC) feature variance than with the noise reduction or the\nspeech distortion level. \n\n"}
{"id": "1707.00683", "contents": "Title: Modulating early visual processing by language Abstract: It is commonly assumed that language refers to high-level visual concepts\nwhile leaving low-level visual processing unaffected. This view dominates the\ncurrent literature in computational models for language-vision tasks, where\nvisual and linguistic input are mostly processed independently before being\nfused into a single representation. In this paper, we deviate from this classic\npipeline and propose to modulate the \\emph{entire visual processing} by\nlinguistic input. Specifically, we condition the batch normalization parameters\nof a pretrained residual network (ResNet) on a language embedding. This\napproach, which we call MOdulated RESnet (\\MRN), significantly improves strong\nbaselines on two visual question answering tasks. Our ablation study shows that\nmodulating from the early stages of the visual processing is beneficial. \n\n"}
{"id": "1707.01355", "contents": "Title: Align and Copy: UZH at SIGMORPHON 2017 Shared Task for Morphological\n  Reinflection Abstract: This paper presents the submissions by the University of Zurich to the\nSIGMORPHON 2017 shared task on morphological reinflection. The task is to\npredict the inflected form given a lemma and a set of morpho-syntactic\nfeatures. We focus on neural network approaches that can tackle the task in a\nlimited-resource setting. As the transduction of the lemma into the inflected\nform is dominated by copying over lemma characters, we propose two recurrent\nneural network architectures with hard monotonic attention that are strong at\ncopying and, yet, substantially different in how they achieve this. The first\napproach is an encoder-decoder model with a copy mechanism. The second approach\nis a neural state-transition system over a set of explicit edit actions,\nincluding a designated COPY action. We experiment with character alignment and\nfind that naive, greedy alignment consistently produces strong results for some\nlanguages. Our best system combination is the overall winner of the SIGMORPHON\n2017 Shared Task 1 without external resources. At a setting with 100 training\nsamples, both our approaches, as ensembles of models, outperform the next best\ncompetitor. \n\n"}
{"id": "1707.01450", "contents": "Title: The Complex Negotiation Dialogue Game Abstract: This position paper formalises an abstract model for complex negotiation\ndialogue. This model is to be used for the benchmark of optimisation algorithms\nranging from Reinforcement Learning to Stochastic Games, through Transfer\nLearning, One-Shot Learning or others. \n\n"}
{"id": "1707.01477", "contents": "Title: Like trainer, like bot? Inheritance of bias in algorithmic content\n  moderation Abstract: The internet has become a central medium through which `networked publics'\nexpress their opinions and engage in debate. Offensive comments and personal\nattacks can inhibit participation in these spaces. Automated content moderation\naims to overcome this problem using machine learning classifiers trained on\nlarge corpora of texts manually annotated for offence. While such systems could\nhelp encourage more civil debate, they must navigate inherently normatively\ncontestable boundaries, and are subject to the idiosyncratic norms of the human\nraters who provide the training data. An important objective for platforms\nimplementing such measures might be to ensure that they are not unduly biased\ntowards or against particular norms of offence. This paper provides some\nexploratory methods by which the normative biases of algorithmic content\nmoderation systems can be measured, by way of a case study using an existing\ndataset of comments labelled for offence. We train classifiers on comments\nlabelled by different demographic subsets (men and women) to understand how\ndifferences in conceptions of offence between these groups might affect the\nperformance of the resulting models on various test sets. We conclude by\ndiscussing some of the ethical choices facing the implementers of algorithmic\nmoderation systems, given various desired levels of diversity of viewpoints\namongst discussion participants. \n\n"}
{"id": "1707.01561", "contents": "Title: Automatic Generation of Natural Language Explanations Abstract: An important task for recommender system is to generate explanations\naccording to a user's preferences. Most of the current methods for explainable\nrecommendations use structured sentences to provide descriptions along with the\nrecommendations they produce. However, those methods have neglected the\nreview-oriented way of writing a text, even though it is known that these\nreviews have a strong influence over user's decision.\n  In this paper, we propose a method for the automatic generation of natural\nlanguage explanations, for predicting how a user would write about an item,\nbased on user ratings from different items' features. We design a\ncharacter-level recurrent neural network (RNN) model, which generates an item's\nreview explanations using long-short term memories (LSTM). The model generates\ntext reviews given a combination of the review and ratings score that express\nopinions about different factors or aspects of an item. Our network is trained\non a sub-sample from the large real-world dataset BeerAdvocate. Our empirical\nevaluation using natural language processing metrics shows the generated text's\nquality is close to a real user written review, identifying negation,\nmisspellings, and domain specific vocabulary. \n\n"}
{"id": "1707.02026", "contents": "Title: A Nested Attention Neural Hybrid Model for Grammatical Error Correction Abstract: Grammatical error correction (GEC) systems strive to correct both global\nerrors in word order and usage, and local errors in spelling and inflection.\nFurther developing upon recent work on neural machine translation, we propose a\nnew hybrid neural model with nested attention layers for GEC. Experiments show\nthat the new model can effectively correct errors of both types by\nincorporating word and character-level information,and that the model\nsignificantly outperforms previous neural models for GEC as measured on the\nstandard CoNLL-14 benchmark dataset. Further analysis also shows that the\nsuperiority of the proposed model can be largely attributed to the use of the\nnested attention mechanism, which has proven particularly effective in\ncorrecting local errors that involve small edits in orthography. \n\n"}
{"id": "1707.02268", "contents": "Title: Text Summarization Techniques: A Brief Survey Abstract: In recent years, there has been a explosion in the amount of text data from a\nvariety of sources. This volume of text is an invaluable source of information\nand knowledge which needs to be effectively summarized to be useful. In this\nreview, the main approaches to automatic text summarization are described. We\nreview the different processes for summarization and describe the effectiveness\nand shortcomings of the different methods. \n\n"}
{"id": "1707.02275", "contents": "Title: A parallel corpus of Python functions and documentation strings for\n  automated code documentation and code generation Abstract: Automated documentation of programming source code and automated code\ngeneration from natural language are challenging tasks of both practical and\nscientific interest. Progress in these areas has been limited by the low\navailability of parallel corpora of code and natural language descriptions,\nwhich tend to be small and constrained to specific domains.\n  In this work we introduce a large and diverse parallel corpus of a hundred\nthousands Python functions with their documentation strings (\"docstrings\")\ngenerated by scraping open source repositories on GitHub. We describe baseline\nresults for the code documentation and code generation tasks obtained by neural\nmachine translation. We also experiment with data augmentation techniques to\nfurther increase the amount of training data.\n  We release our datasets and processing scripts in order to stimulate research\nin these areas. \n\n"}
{"id": "1707.02377", "contents": "Title: Efficient Vector Representation for Documents through Corruption Abstract: We present an efficient document representation learning framework, Document\nVector through Corruption (Doc2VecC). Doc2VecC represents each document as a\nsimple average of word embeddings. It ensures a representation generated as\nsuch captures the semantic meanings of the document during learning. A\ncorruption model is included, which introduces a data-dependent regularization\nthat favors informative or rare words while forcing the embeddings of common\nand non-discriminative ones to be close to zero. Doc2VecC produces\nsignificantly better word embeddings than Word2Vec. We compare Doc2VecC with\nseveral state-of-the-art document representation learning algorithms. The\nsimple model architecture introduced by Doc2VecC matches or out-performs the\nstate-of-the-art in generating high-quality document representations for\nsentiment analysis, document classification as well as semantic relatedness\ntasks. The simplicity of the model enables training on billions of words per\nhour on a single machine. At the same time, the model is very efficient in\ngenerating representations of unseen documents at test time. \n\n"}
{"id": "1707.02483", "contents": "Title: Weakly Supervised Cross-Lingual Named Entity Recognition via Effective\n  Annotation and Representation Projection Abstract: The state-of-the-art named entity recognition (NER) systems are supervised\nmachine learning models that require large amounts of manually annotated data\nto achieve high accuracy. However, annotating NER data by human is expensive\nand time-consuming, and can be quite difficult for a new language. In this\npaper, we present two weakly supervised approaches for cross-lingual NER with\nno human annotation in a target language. The first approach is to create\nautomatically labeled NER data for a target language via annotation projection\non comparable corpora, where we develop a heuristic scheme that effectively\nselects good-quality projection-labeled data from noisy data. The second\napproach is to project distributed representations of words (word embeddings)\nfrom a target language to a source language, so that the source-language NER\nsystem can be applied to the target language without re-training. We also\ndesign two co-decoding schemes that effectively combine the outputs of the two\nprojection-based approaches. We evaluate the performance of the proposed\napproaches on both in-house and open NER data for several target languages. The\nresults show that the combined systems outperform three other weakly supervised\napproaches on the CoNLL data. \n\n"}
{"id": "1707.03172", "contents": "Title: Dataset for a Neural Natural Language Interface for Databases (NNLIDB) Abstract: Progress in natural language interfaces to databases (NLIDB) has been slow\nmainly due to linguistic issues (such as language ambiguity) and domain\nportability. Moreover, the lack of a large corpus to be used as a standard\nbenchmark has made data-driven approaches difficult to develop and compare. In\nthis paper, we revisit the problem of NLIDBs and recast it as a sequence\ntranslation problem. To this end, we introduce a large dataset extracted from\nthe Stack Exchange Data Explorer website, which can be used for training neural\nnatural language interfaces for databases. We also report encouraging baseline\nresults on a smaller manually annotated test corpus, obtained using an\nattention-based sequence-to-sequence neural network. \n\n"}
{"id": "1707.03569", "contents": "Title: Multitask Learning for Fine-Grained Twitter Sentiment Analysis Abstract: Traditional sentiment analysis approaches tackle problems like ternary\n(3-category) and fine-grained (5-category) classification by learning the tasks\nseparately. We argue that such classification tasks are correlated and we\npropose a multitask approach based on a recurrent neural network that benefits\nby jointly learning them. Our study demonstrates the potential of multitask\nmodels on this type of problems and improves the state-of-the-art results in\nthe fine-grained sentiment classification problem. \n\n"}
{"id": "1707.04227", "contents": "Title: Automatic Speech Recognition with Very Large Conversational Finnish and\n  Estonian Vocabularies Abstract: Today, the vocabulary size for language models in large vocabulary speech\nrecognition is typically several hundreds of thousands of words. While this is\nalready sufficient in some applications, the out-of-vocabulary words are still\nlimiting the usability in others. In agglutinative languages the vocabulary for\nconversational speech should include millions of word forms to cover the\nspelling variations due to colloquial pronunciations, in addition to the word\ncompounding and inflections. Very large vocabularies are also needed, for\nexample, when the recognition of rare proper names is important. \n\n"}
{"id": "1707.04244", "contents": "Title: Lithium NLP: A System for Rich Information Extraction from Noisy User\n  Generated Text on Social Media Abstract: In this paper, we describe the Lithium Natural Language Processing (NLP)\nsystem - a resource-constrained, high- throughput and language-agnostic system\nfor information extraction from noisy user generated text on social media.\nLithium NLP extracts a rich set of information including entities, topics,\nhashtags and sentiment from text. We discuss several real world applications of\nthe system currently incorporated in Lithium products. We also compare our\nsystem with existing commercial and academic NLP systems in terms of\nperformance, information extracted and languages supported. We show that\nLithium NLP is at par with and in some cases, outperforms state- of-the-art\ncommercial NLP systems. \n\n"}
{"id": "1707.04412", "contents": "Title: Evaluating Semantic Parsing against a Simple Web-based Question\n  Answering Model Abstract: Semantic parsing shines at analyzing complex natural language that involves\ncomposition and computation over multiple pieces of evidence. However, datasets\nfor semantic parsing contain many factoid questions that can be answered from a\nsingle web document. In this paper, we propose to evaluate semantic\nparsing-based question answering models by comparing them to a question\nanswering baseline that queries the web and extracts the answer only from web\nsnippets, without access to the target knowledge-base. We investigate this\napproach on COMPLEXQUESTIONS, a dataset designed to focus on compositional\nlanguage, and find that our model obtains reasonable performance (35 F1\ncompared to 41 F1 of state-of-the-art). We find in our analysis that our model\nperforms well on complex questions involving conjunctions, but struggles on\nquestions that involve relation composition and superlatives. \n\n"}
{"id": "1707.05227", "contents": "Title: Auxiliary Objectives for Neural Error Detection Models Abstract: We investigate the utility of different auxiliary objectives and training\nstrategies within a neural sequence labeling approach to error detection in\nlearner writing. Auxiliary costs provide the model with additional linguistic\ninformation, allowing it to learn general-purpose compositional features that\ncan then be exploited for other objectives. Our experiments show that a joint\nlearning approach trained with parallel labels on in-domain data improves\nperformance over the previous best error detection system. While the resulting\nmodel has the same number of parameters, the additional objectives allow it to\nbe optimised more efficiently and achieve better performance. \n\n"}
{"id": "1707.05236", "contents": "Title: Artificial Error Generation with Machine Translation and Syntactic\n  Patterns Abstract: Shortage of available training data is holding back progress in the area of\nautomated error detection. This paper investigates two alternative methods for\nartificially generating writing errors, in order to create additional\nresources. We propose treating error generation as a machine translation task,\nwhere grammatically correct text is translated to contain errors. In addition,\nwe explore a system for extracting textual patterns from an annotated corpus,\nwhich can then be used to insert errors into grammatically correct sentences.\nOur experiments show that the inclusion of artificially generated errors\nsignificantly improves error detection accuracy on both FCE and CoNLL 2014\ndatasets. \n\n"}
{"id": "1707.05501", "contents": "Title: Story Generation from Sequence of Independent Short Descriptions Abstract: Existing Natural Language Generation (NLG) systems are weak AI systems and\nexhibit limited capabilities when language generation tasks demand higher\nlevels of creativity, originality and brevity. Effective solutions or, at least\nevaluations of modern NLG paradigms for such creative tasks have been elusive,\nunfortunately. This paper introduces and addresses the task of coherent story\ngeneration from independent descriptions, describing a scene or an event.\nTowards this, we explore along two popular text-generation paradigms -- (1)\nStatistical Machine Translation (SMT), posing story generation as a translation\nproblem and (2) Deep Learning, posing story generation as a sequence to\nsequence learning problem. In SMT, we chose two popular methods such as phrase\nbased SMT (PB-SMT) and syntax based SMT (SYNTAX-SMT) to `translate' the\nincoherent input text into stories. We then implement a deep recurrent neural\nnetwork (RNN) architecture that encodes sequence of variable length input\ndescriptions to corresponding latent representations and decodes them to\nproduce well formed comprehensive story like summaries. The efficacy of the\nsuggested approaches is demonstrated on a publicly available dataset with the\nhelp of popular machine translation and summarization evaluation metrics. \n\n"}
{"id": "1707.05612", "contents": "Title: VSE++: Improving Visual-Semantic Embeddings with Hard Negatives Abstract: We present a new technique for learning visual-semantic embeddings for\ncross-modal retrieval. Inspired by hard negative mining, the use of hard\nnegatives in structured prediction, and ranking loss functions, we introduce a\nsimple change to common loss functions used for multi-modal embeddings. That,\ncombined with fine-tuning and use of augmented data, yields significant gains\nin retrieval performance. We showcase our approach, VSE++, on MS-COCO and\nFlickr30K datasets, using ablation studies and comparisons with existing\nmethods. On MS-COCO our approach outperforms state-of-the-art methods by 8.8%\nin caption retrieval and 11.3% in image retrieval (at R@1). \n\n"}
{"id": "1707.06130", "contents": "Title: Improving Language Modeling using Densely Connected Recurrent Neural\n  Networks Abstract: In this paper, we introduce the novel concept of densely connected layers\ninto recurrent neural networks. We evaluate our proposed architecture on the\nPenn Treebank language modeling task. We show that we can obtain similar\nperplexity scores with six times fewer parameters compared to a standard\nstacked 2-layer LSTM model trained with dropout (Zaremba et al. 2014). In\ncontrast with the current usage of skip connections, we show that densely\nconnecting only a few stacked layers with skip connections already yields\nsignificant perplexity reductions. \n\n"}
{"id": "1707.06265", "contents": "Title: Unsupervised Domain Adaptation for Robust Speech Recognition via\n  Variational Autoencoder-Based Data Augmentation Abstract: Domain mismatch between training and testing can lead to significant\ndegradation in performance in many machine learning scenarios. Unfortunately,\nthis is not a rare situation for automatic speech recognition deployments in\nreal-world applications. Research on robust speech recognition can be regarded\nas trying to overcome this domain mismatch issue. In this paper, we address the\nunsupervised domain adaptation problem for robust speech recognition, where\nboth source and target domain speech are presented, but word transcripts are\nonly available for the source domain speech. We present novel\naugmentation-based methods that transform speech in a way that does not change\nthe transcripts. Specifically, we first train a variational autoencoder on both\nsource and target domain data (without supervision) to learn a latent\nrepresentation of speech. We then transform nuisance attributes of speech that\nare irrelevant to recognition by modifying the latent representations, in order\nto augment labeled training data with additional data whose distribution is\nmore similar to the target domain. The proposed method is evaluated on the\nCHiME-4 dataset and reduces the absolute word error rate (WER) by as much as\n35% compared to the non-adapted baseline. \n\n"}
{"id": "1707.06527", "contents": "Title: Single-Channel Multi-talker Speech Recognition with Permutation\n  Invariant Training Abstract: Although great progresses have been made in automatic speech recognition\n(ASR), significant performance degradation is still observed when recognizing\nmulti-talker mixed speech. In this paper, we propose and evaluate several\narchitectures to address this problem under the assumption that only a single\nchannel of mixed signal is available. Our technique extends permutation\ninvariant training (PIT) by introducing the front-end feature separation module\nwith the minimum mean square error (MSE) criterion and the back-end recognition\nmodule with the minimum cross entropy (CE) criterion. More specifically, during\ntraining we compute the average MSE or CE over the whole utterance for each\npossible utterance-level output-target assignment, pick the one with the\nminimum MSE or CE, and optimize for that assignment. This strategy elegantly\nsolves the label permutation problem observed in the deep learning based\nmulti-talker mixed speech separation and recognition systems. The proposed\narchitectures are evaluated and compared on an artificially mixed AMI dataset\nwith both two- and three-talker mixed speech. The experimental results indicate\nthat our proposed architectures can cut the word error rate (WER) by 45.0% and\n25.0% relatively against the state-of-the-art single-talker speech recognition\nsystem across all speakers when their energies are comparable, for two- and\nthree-talker mixed speech, respectively. To our knowledge, this is the first\nwork on the multi-talker mixed speech recognition on the challenging\nspeaker-independent spontaneous large vocabulary continuous speech task. \n\n"}
{"id": "1707.06556", "contents": "Title: High-risk learning: acquiring new word vectors from tiny data Abstract: Distributional semantics models are known to struggle with small data. It is\ngenerally accepted that in order to learn 'a good vector' for a word, a model\nmust have sufficient examples of its usage. This contradicts the fact that\nhumans can guess the meaning of a word from a few occurrences only. In this\npaper, we show that a neural language model such as Word2Vec only necessitates\nminor modifications to its standard architecture to learn new terms from tiny\ndata, using background knowledge from a previously learnt semantic space. We\ntest our model on word definitions and on a nonce task involving 2-6 sentences'\nworth of context, showing a large increase in performance over state-of-the-art\nmodels on the definitional task. \n\n"}
{"id": "1707.06598", "contents": "Title: Toward Incorporation of Relevant Documents in word2vec Abstract: Recent advances in neural word embedding provide significant benefit to\nvarious information retrieval tasks. However as shown by recent studies,\nadapting the embedding models for the needs of IR tasks can bring considerable\nfurther improvements. The embedding models in general define the term\nrelatedness by exploiting the terms' co-occurrences in short-window contexts.\nAn alternative (and well-studied) approach in IR for related terms to a query\nis using local information i.e. a set of top-retrieved documents. In view of\nthese two methods of term relatedness, in this work, we report our study on\nincorporating the local information of the query in the word embeddings. One\nmain challenge in this direction is that the dense vectors of word embeddings\nand their estimation of term-to-term relatedness remain difficult to interpret\nand hard to analyze. As an alternative, explicit word representations propose\nvectors whose dimensions are easily interpretable, and recent methods show\ncompetitive performance to the dense vectors. We introduce a neural-based\nexplicit representation, rooted in the conceptual ideas of the word2vec\nSkip-Gram model. The method provides interpretable explicit vectors while\nkeeping the effectiveness of the Skip-Gram model. The evaluation of various\nexplicit representations on word association collections shows that the newly\nproposed method out- performs the state-of-the-art explicit representations\nwhen tasked with ranking highly similar terms. Based on the introduced ex-\nplicit representation, we discuss our approaches on integrating local documents\nin globally-trained embedding models and discuss the preliminary results. \n\n"}
{"id": "1707.06875", "contents": "Title: Why We Need New Evaluation Metrics for NLG Abstract: The majority of NLG evaluation relies on automatic metrics, such as BLEU . In\nthis paper, we motivate the need for novel, system- and data-independent\nautomatic evaluation methods: We investigate a wide range of metrics, including\nstate-of-the-art word-based and novel grammar-based ones, and demonstrate that\nthey only weakly reflect human judgements of system outputs as generated by\ndata-driven, end-to-end NLG. We also show that metric performance is data- and\nsystem-specific. Nevertheless, our results also suggest that automatic metrics\nperform reliably at system-level and can support system development by finding\ncases where a system performs poorly. \n\n"}
{"id": "1707.06939", "contents": "Title: Autocompletion interfaces make crowd workers slower, but their use\n  promotes response diversity Abstract: Creative tasks such as ideation or question proposal are powerful\napplications of crowdsourcing, yet the quantity of workers available for\naddressing practical problems is often insufficient. To enable scalable\ncrowdsourcing thus requires gaining all possible efficiency and information\nfrom available workers. One option for text-focused tasks is to allow assistive\ntechnology, such as an autocompletion user interface (AUI), to help workers\ninput text responses. But support for the efficacy of AUIs is mixed. Here we\ndesigned and conducted a randomized experiment where workers were asked to\nprovide short text responses to given questions. Our experimental goal was to\ndetermine if an AUI helps workers respond more quickly and with improved\nconsistency by mitigating typos and misspellings. Surprisingly, we found that\nneither occurred: workers assigned to the AUI treatment were slower than those\nassigned to the non-AUI control and their responses were more diverse, not\nless, than those of the control. Both the lexical and semantic diversities of\nresponses were higher, with the latter measured using word2vec. A crowdsourcer\ninterested in worker speed may want to avoid using an AUI, but using an AUI to\nboost response diversity may be valuable to crowdsourcers interested in\nreceiving as much novel information from workers as possible. \n\n"}
{"id": "1707.06961", "contents": "Title: Mimicking Word Embeddings using Subword RNNs Abstract: Word embeddings improve generalization over lexical features by placing each\nword in a lower-dimensional space, using distributional information obtained\nfrom unlabeled data. However, the effectiveness of word embeddings for\ndownstream NLP tasks is limited by out-of-vocabulary (OOV) words, for which\nembeddings do not exist. In this paper, we present MIMICK, an approach to\ngenerating OOV word embeddings compositionally, by learning a function from\nspellings to distributional embeddings. Unlike prior work, MIMICK does not\nrequire re-training on the original word embedding corpus; instead, learning is\nperformed at the type level. Intrinsic and extrinsic evaluations demonstrate\nthe power of this simple approach. On 23 languages, MIMICK improves performance\nover a word-based baseline for tagging part-of-speech and morphosyntactic\nattributes. It is competitive with (and complementary to) a supervised\ncharacter-based model in low-resource settings. \n\n"}
{"id": "1707.07250", "contents": "Title: Tensor Fusion Network for Multimodal Sentiment Analysis Abstract: Multimodal sentiment analysis is an increasingly popular research area, which\nextends the conventional language-based definition of sentiment analysis to a\nmultimodal setup where other relevant modalities accompany language. In this\npaper, we pose the problem of multimodal sentiment analysis as modeling\nintra-modality and inter-modality dynamics. We introduce a novel model, termed\nTensor Fusion Network, which learns both such dynamics end-to-end. The proposed\napproach is tailored for the volatile nature of spoken language in online\nvideos as well as accompanying gestures and voice. In the experiments, our\nmodel outperforms state-of-the-art approaches for both multimodal and unimodal\nsentiment analysis. \n\n"}
{"id": "1707.07273", "contents": "Title: Hierarchical Embeddings for Hypernymy Detection and Directionality Abstract: We present a novel neural model HyperVec to learn hierarchical embeddings for\nhypernymy detection and directionality. While previous embeddings have shown\nlimitations on prototypical hypernyms, HyperVec represents an unsupervised\nmeasure where embeddings are learned in a specific order and capture the\nhypernym$-$hyponym distributional hierarchy. Moreover, our model is able to\ngeneralize over unseen hypernymy pairs, when using only small sets of training\ndata, and by mapping to other languages. Results on benchmark datasets show\nthat HyperVec outperforms both state$-$of$-$the$-$art unsupervised measures and\nembedding models on hypernymy detection and directionality, and on predicting\ngraded lexical entailment. \n\n"}
{"id": "1707.07554", "contents": "Title: Learning Rare Word Representations using Semantic Bridging Abstract: We propose a methodology that adapts graph embedding techniques (DeepWalk\n(Perozzi et al., 2014) and node2vec (Grover and Leskovec, 2016)) as well as\ncross-lingual vector space mapping approaches (Least Squares and Canonical\nCorrelation Analysis) in order to merge the corpus and ontological sources of\nlexical knowledge. We also perform comparative analysis of the used algorithms\nin order to identify the best combination for the proposed system. We then\napply this to the task of enhancing the coverage of an existing word\nembedding's vocabulary with rare and unseen words. We show that our technique\ncan provide considerable extra coverage (over 99%), leading to consistent\nperformance gain (around 10% absolute gain is achieved with w2v-gn-500K cf.\\S\n3.3) on the Rare Word Similarity dataset. \n\n"}
{"id": "1707.07605", "contents": "Title: Share your Model instead of your Data: Privacy Preserving Mimic Learning\n  for Ranking Abstract: Deep neural networks have become a primary tool for solving problems in many\nfields. They are also used for addressing information retrieval problems and\nshow strong performance in several tasks. Training these models requires large,\nrepresentative datasets and for most IR tasks, such data contains sensitive\ninformation from users. Privacy and confidentiality concerns prevent many data\nowners from sharing the data, thus today the research community can only\nbenefit from research on large-scale datasets in a limited manner. In this\npaper, we discuss privacy preserving mimic learning, i.e., using predictions\nfrom a privacy preserving trained model instead of labels from the original\nsensitive training data as a supervision signal. We present the results of\npreliminary experiments in which we apply the idea of mimic learning and\nprivacy preserving mimic learning for the task of document re-ranking as one of\nthe core IR tasks. This research is a step toward laying the ground for\nenabling researchers from data-rich environments to share knowledge learned\nfrom actual users' data, which should facilitate research collaborations. \n\n"}
{"id": "1707.08081", "contents": "Title: Learning Word Relatedness over Time Abstract: Search systems are often focused on providing relevant results for the \"now\",\nassuming both corpora and user needs that focus on the present. However, many\ncorpora today reflect significant longitudinal collections ranging from 20\nyears of the Web to hundreds of years of digitized newspapers and books.\nUnderstanding the temporal intent of the user and retrieving the most relevant\nhistorical content has become a significant challenge. Common search features,\nsuch as query expansion, leverage the relationship between terms but cannot\nfunction well across all times when relationships vary temporally. In this\nwork, we introduce a temporal relationship model that is extracted from\nlongitudinal data collections. The model supports the task of identifying,\ngiven two words, when they relate to each other. We present an algorithmic\nframework for this task and show its application for the task of query\nexpansion, achieving high gain. \n\n"}
{"id": "1707.08139", "contents": "Title: Analogs of Linguistic Structure in Deep Representations Abstract: We investigate the compositional structure of message vectors computed by a\ndeep network trained on a communication game. By comparing truth-conditional\nrepresentations of encoder-produced message vectors to human-produced referring\nexpressions, we are able to identify aligned (vector, utterance) pairs with the\nsame meaning. We then search for structured relationships among these aligned\npairs to discover simple vector space transformations corresponding to\nnegation, conjunction, and disjunction. Our results suggest that neural\nrepresentations are capable of spontaneously developing a \"syntax\" with\nfunctional analogues to qualitative properties of natural language. \n\n"}
{"id": "1707.08214", "contents": "Title: Dual Rectified Linear Units (DReLUs): A Replacement for Tanh Activation\n  Functions in Quasi-Recurrent Neural Networks Abstract: In this paper, we introduce a novel type of Rectified Linear Unit (ReLU),\ncalled a Dual Rectified Linear Unit (DReLU). A DReLU, which comes with an\nunbounded positive and negative image, can be used as a drop-in replacement for\na tanh activation function in the recurrent step of Quasi-Recurrent Neural\nNetworks (QRNNs) (Bradbury et al. (2017)). Similar to ReLUs, DReLUs are less\nprone to the vanishing gradient problem, they are noise robust, and they induce\nsparse activations.\n  We independently reproduce the QRNN experiments of Bradbury et al. (2017) and\ncompare our DReLU-based QRNNs with the original tanh-based QRNNs and Long\nShort-Term Memory networks (LSTMs) on sentiment classification and word-level\nlanguage modeling. Additionally, we evaluate on character-level language\nmodeling, showing that we are able to stack up to eight QRNN layers with\nDReLUs, thus making it possible to improve the current state-of-the-art in\ncharacter-level language modeling over shallow architectures based on LSTMs. \n\n"}
{"id": "1707.08939", "contents": "Title: Strawman: an Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis Abstract: This paper describes a builder entry, named \"strawman\", to the sentence-level\nsentiment analysis task of the \"Build It, Break It\" shared task of the First\nWorkshop on Building Linguistically Generalizable NLP Systems. The goal of a\nbuilder is to provide an automated sentiment analyzer that would serve as a\ntarget for breakers whose goal is to find pairs of minimally-differing\nsentences that break the analyzer. \n\n"}
{"id": "1708.00077", "contents": "Title: Bayesian Sparsification of Recurrent Neural Networks Abstract: Recurrent neural networks show state-of-the-art results in many text analysis\ntasks but often require a lot of memory to store their weights. Recently\nproposed Sparse Variational Dropout eliminates the majority of the weights in a\nfeed-forward neural network without significant loss of quality. We apply this\ntechnique to sparsify recurrent neural networks. To account for recurrent\nspecifics we also rely on Binary Variational Dropout for RNN. We report 99.5%\nsparsity level on sentiment analysis task without a quality drop and up to 87%\nsparsity level on language modeling task with slight loss of accuracy. \n\n"}
{"id": "1708.00112", "contents": "Title: Retrofitting Distributional Embeddings to Knowledge Graphs with\n  Functional Relations Abstract: Knowledge graphs are a versatile framework to encode richly structured data\nrelationships, but it can be challenging to combine these graphs with\nunstructured data. Methods for retrofitting pre-trained entity representations\nto the structure of a knowledge graph typically assume that entities are\nembedded in a connected space and that relations imply similarity. However,\nuseful knowledge graphs often contain diverse entities and relations (with\npotentially disjoint underlying corpora) which do not accord with these\nassumptions. To overcome these limitations, we present Functional Retrofitting,\na framework that generalizes current retrofitting methods by explicitly\nmodeling pairwise relations. Our framework can directly incorporate a variety\nof pairwise penalty functions previously developed for knowledge graph\ncompletion. Further, it allows users to encode, learn, and extract information\nabout relation semantics. We present both linear and neural instantiations of\nthe framework. Functional Retrofitting significantly outperforms existing\nretrofitting methods on complex knowledge graphs and loses no accuracy on\nsimpler graphs (in which relations do imply similarity). Finally, we\ndemonstrate the utility of the framework by predicting new drug--disease\ntreatment pairs in a large, complex health knowledge graph. \n\n"}
{"id": "1708.00781", "contents": "Title: Dynamic Entity Representations in Neural Language Models Abstract: Understanding a long document requires tracking how entities are introduced\nand evolve over time. We present a new type of language model, EntityNLM, that\ncan explicitly model entities, dynamically update their representations, and\ncontextually generate their mentions. Our model is generative and flexible; it\ncan model an arbitrary number of entities in context while generating each\nentity mention at an arbitrary length. In addition, it can be used for several\ndifferent tasks such as language modeling, coreference resolution, and entity\nprediction. Experimental results with all these tasks demonstrate that our\nmodel consistently outperforms strong baselines and prior work. \n\n"}
{"id": "1708.02989", "contents": "Title: Identifying Reference Spans: Topic Modeling and Word Embeddings help IR Abstract: The CL-SciSumm 2016 shared task introduced an interesting problem: given a\ndocument D and a piece of text that cites D, how do we identify the text spans\nof D being referenced by the piece of text? The shared task provided the first\nannotated dataset for studying this problem. We present an analysis of our\ncontinued work in improving our system's performance on this task. We\ndemonstrate how topic models and word embeddings can be used to surpass the\npreviously best performing system. \n\n"}
{"id": "1708.03312", "contents": "Title: Radical-level Ideograph Encoder for RNN-based Sentiment Analysis of\n  Chinese and Japanese Abstract: The character vocabulary can be very large in non-alphabetic languages such\nas Chinese and Japanese, which makes neural network models huge to process such\nlanguages. We explored a model for sentiment classification that takes the\nembeddings of the radicals of the Chinese characters, i.e, hanzi of Chinese and\nkanji of Japanese. Our model is composed of a CNN word feature encoder and a\nbi-directional RNN document feature encoder. The results achieved are on par\nwith the character embedding-based models, and close to the state-of-the-art\nword embedding-based models, with 90% smaller vocabulary, and at least 13% and\n80% fewer parameters than the character embedding-based models and word\nembedding-based models respectively. The results suggest that the radical\nembedding-based approach is cost-effective for machine learning on Chinese and\nJapanese. \n\n"}
{"id": "1708.04439", "contents": "Title: Extractive Summarization using Deep Learning Abstract: This paper proposes a text summarization approach for factual reports using a\ndeep learning model. This approach consists of three phases: feature\nextraction, feature enhancement, and summary generation, which work together to\nassimilate core information and generate a coherent, understandable summary. We\nare exploring various features to improve the set of sentences selected for the\nsummary, and are using a Restricted Boltzmann Machine to enhance and abstract\nthose features to improve resultant accuracy without losing any important\ninformation. The sentences are scored based on those enhanced features and an\nextractive summary is constructed. Experimentation carried out on several\narticles demonstrates the effectiveness of the proposed approach. Source code\navailable at: https://github.com/vagisha-nidhi/TextSummarizer \n\n"}
{"id": "1708.04686", "contents": "Title: VQS: Linking Segmentations to Questions and Answers for Supervised\n  Attention in VQA and Question-Focused Semantic Segmentation Abstract: Rich and dense human labeled datasets are among the main enabling factors for\nthe recent advance on vision-language understanding. Many seemingly distant\nannotations (e.g., semantic segmentation and visual question answering (VQA))\nare inherently connected in that they reveal different levels and perspectives\nof human understandings about the same visual scenes --- and even the same set\nof images (e.g., of COCO). The popularity of COCO correlates those annotations\nand tasks. Explicitly linking them up may significantly benefit both individual\ntasks and the unified vision and language modeling. We present the preliminary\nwork of linking the instance segmentations provided by COCO to the questions\nand answers (QAs) in the VQA dataset, and name the collected links visual\nquestions and segmentation answers (VQS). They transfer human supervision\nbetween the previously separate tasks, offer more effective leverage to\nexisting problems, and also open the door for new research problems and models.\nWe study two applications of the VQS data in this paper: supervised attention\nfor VQA and a novel question-focused semantic segmentation task. For the\nformer, we obtain state-of-the-art results on the VQA real multiple-choice task\nby simply augmenting the multilayer perceptrons with some attention features\nthat are learned using the segmentation-QA links as explicit supervision. To\nput the latter in perspective, we study two plausible methods and compare them\nto an oracle method assuming that the instance segmentations are given at the\ntest stage. \n\n"}
{"id": "1708.04968", "contents": "Title: Fault in your stars: An Analysis of Android App Reviews Abstract: Mobile app distribution platforms such as Google Play Store allow users to\nshare their feedback about downloaded apps in the form of a review comment and\na corresponding star rating. Typically, the star rating ranges from one to five\nstars, with one star denoting a high sense of dissatisfaction with the app and\nfive stars denoting a high sense of satisfaction.\n  Unfortunately, due to a variety of reasons, often the star rating provided by\na user is inconsistent with the opinion expressed in the review. For example,\nconsider the following review for the Facebook App on Android; \"Awesome App\".\nOne would reasonably expect the rating for this review to be five stars, but\nthe actual rating is one star!\n  Such inconsistent ratings can lead to a deflated (or inflated) overall\naverage rating of an app which can affect user downloads, as typically users\nlook at the average star ratings while making a decision on downloading an app.\nAlso, the app developers receive a biased feedback about the application that\ndoes not represent ground reality. This is especially significant for small\napps with a few thousand downloads as even a small number of mismatched reviews\ncan bring down the average rating drastically.\n  In this paper, we conducted a study on this review-rating mismatch problem.\nWe manually examined 8600 reviews from 10 popular Android apps and found that\n20% of the ratings in our dataset were inconsistent with the review. Further,\nwe developed three systems; two of which were based on traditional machine\nlearning and one on deep learning to automatically identify reviews whose\nrating did not match with the opinion expressed in the review. Our deep\nlearning system performed the best and had an accuracy of 92% in identifying\nthe correct star rating to be associated with a given review. \n\n"}
{"id": "1708.05942", "contents": "Title: The Helsinki Neural Machine Translation System Abstract: We introduce the Helsinki Neural Machine Translation system (HNMT) and how it\nis applied in the news translation task at WMT 2017, where it ranked first in\nboth the human and automatic evaluations for English--Finnish. We discuss the\nsuccess of English--Finnish translations and the overall advantage of NMT over\na strong SMT baseline. We also discuss our submissions for English--Latvian,\nEnglish--Chinese and Chinese--English. \n\n"}
{"id": "1708.05997", "contents": "Title: A Batch Noise Contrastive Estimation Approach for Training Large\n  Vocabulary Language Models Abstract: Training large vocabulary Neural Network Language Models (NNLMs) is a\ndifficult task due to the explicit requirement of the output layer\nnormalization, which typically involves the evaluation of the full softmax\nfunction over the complete vocabulary. This paper proposes a Batch Noise\nContrastive Estimation (B-NCE) approach to alleviate this problem. This is\nachieved by reducing the vocabulary, at each time step, to the target words in\nthe batch and then replacing the softmax by the noise contrastive estimation\napproach, where these words play the role of targets and noise samples at the\nsame time. In doing so, the proposed approach can be fully formulated and\nimplemented using optimal dense matrix operations. Applying B-NCE to train\ndifferent NNLMs on the Large Text Compression Benchmark (LTCB) and the One\nBillion Word Benchmark (OBWB) shows a significant reduction of the training\ntime with no noticeable degradation of the models performance. This paper also\npresents a new baseline comparative study of different standard NNLMs on the\nlarge OBWB on a single Titan-X GPU. \n\n"}
{"id": "1708.06022", "contents": "Title: Learning to Paraphrase for Question Answering Abstract: Question answering (QA) systems are sensitive to the many different ways\nnatural language expresses the same information need. In this paper we turn to\nparaphrases as a means of capturing this knowledge and present a general\nframework which learns felicitous paraphrases for various QA tasks. Our method\nis trained end-to-end using question-answer pairs as a supervision signal. A\nquestion and its paraphrases serve as input to a neural scoring model which\nassigns higher weights to linguistic expressions most likely to yield correct\nanswers. We evaluate our approach on QA over Freebase and answer sentence\nselection. Experimental results on three datasets show that our framework\nconsistently improves performance, achieving competitive results despite the\nuse of simple QA models. \n\n"}
{"id": "1708.07149", "contents": "Title: Towards an Automatic Turing Test: Learning to Evaluate Dialogue\n  Responses Abstract: Automatically evaluating the quality of dialogue responses for unstructured\ndomains is a challenging problem. Unfortunately, existing automatic evaluation\nmetrics are biased and correlate very poorly with human judgements of response\nquality. Yet having an accurate automatic evaluation procedure is crucial for\ndialogue research, as it allows rapid prototyping and testing of new models\nwith fewer expensive human evaluations. In response to this challenge, we\nformulate automatic dialogue evaluation as a learning problem. We present an\nevaluation model (ADEM) that learns to predict human-like scores to input\nresponses, using a new dataset of human response scores. We show that the ADEM\nmodel's predictions correlate significantly, and at a level much higher than\nword-overlap metrics such as BLEU, with human judgements at both the utterance\nand system-level. We also show that ADEM can generalize to evaluating dialogue\nmodels unseen during training, an important step for automatic dialogue\nevaluation. \n\n"}
{"id": "1708.07950", "contents": "Title: Machine Translation in Indian Languages: Challenges and Resolution Abstract: English to Indian language machine translation poses the challenge of\nstructural and morphological divergence. This paper describes English to Indian\nlanguage statistical machine translation using pre-ordering and suffix\nseparation. The pre-ordering uses rules to transfer the structure of the source\nsentences prior to training and translation. This syntactic restructuring helps\nstatistical machine translation to tackle the structural divergence and hence\nbetter translation quality. The suffix separation is used to tackle the\nmorphological divergence between English and highly agglutinative Indian\nlanguages. We demonstrate that the use of pre-ordering and suffix separation\nhelps in improving the quality of English to Indian Language machine\ntranslation. \n\n"}
{"id": "1709.00149", "contents": "Title: Learning what to read: Focused machine reading Abstract: Recent efforts in bioinformatics have achieved tremendous progress in the\nmachine reading of biomedical literature, and the assembly of the extracted\nbiochemical interactions into large-scale models such as protein signaling\npathways. However, batch machine reading of literature at today's scale (PubMed\nalone indexes over 1 million papers per year) is unfeasible due to both cost\nand processing overhead. In this work, we introduce a focused reading approach\nto guide the machine reading of biomedical literature towards what literature\nshould be read to answer a biomedical query as efficiently as possible. We\nintroduce a family of algorithms for focused reading, including an intuitive,\nstrong baseline, and a second approach which uses a reinforcement learning (RL)\nframework that learns when to explore (widen the search) or exploit (narrow\nit). We demonstrate that the RL approach is capable of answering more queries\nthan the baseline, while being more efficient, i.e., reading fewer documents. \n\n"}
{"id": "1709.00354", "contents": "Title: Query-by-example Spoken Term Detection using Attention-based Multi-hop\n  Networks Abstract: Retrieving spoken content with spoken queries, or query-by- example spoken\nterm detection (STD), is attractive because it makes possible the matching of\nsignals directly on the acoustic level without transcribing them into text.\nHere, we propose an end-to-end query-by-example STD model based on an\nattention-based multi-hop network, whose input is a spoken query and an audio\nsegment containing several utterances; the output states whether the audio\nsegment includes the query. The model can be trained in either a supervised\nscenario using labeled data, or in an unsupervised fashion. In the supervised\nscenario, we find that the attention mechanism and multiple hops improve\nperformance, and that the attention weights indicate the time span of the\ndetected terms. In the unsupervised setting, the model mimics the behavior of\nthe existing query-by-example STD system, yielding performance comparable to\nthe existing system but with a lower search time complexity. \n\n"}
{"id": "1709.00387", "contents": "Title: MIT-QCRI Arabic Dialect Identification System for the 2017 Multi-Genre\n  Broadcast Challenge Abstract: In order to successfully annotate the Arabic speech con- tent found in\nopen-domain media broadcasts, it is essential to be able to process a diverse\nset of Arabic dialects. For the 2017 Multi-Genre Broadcast challenge (MGB-3)\nthere were two possible tasks: Arabic speech recognition, and Arabic Dialect\nIdentification (ADI). In this paper, we describe our efforts to create an ADI\nsystem for the MGB-3 challenge, with the goal of distinguishing amongst four\nmajor Arabic dialects, as well as Modern Standard Arabic. Our research fo-\ncused on dialect variability and domain mismatches between the training and\ntest domain. In order to achieve a robust ADI system, we explored both Siamese\nneural network models to learn similarity and dissimilarities among Arabic\ndialects, as well as i-vector post-processing to adapt domain mismatches. Both\nAcoustic and linguistic features were used for the final MGB-3 submissions,\nwith the best primary system achieving 75% accuracy on the official 10hr test\nset. \n\n"}
{"id": "1709.01888", "contents": "Title: Language Modeling by Clustering with Word Embeddings for Text\n  Readability Assessment Abstract: We present a clustering-based language model using word embeddings for text\nreadability prediction. Presumably, an Euclidean semantic space hypothesis\nholds true for word embeddings whose training is done by observing word\nco-occurrences. We argue that clustering with word embeddings in the metric\nspace should yield feature representations in a higher semantic space\nappropriate for text regression. Also, by representing features in terms of\nhistograms, our approach can naturally address documents of varying lengths. An\nempirical evaluation using the Common Core Standards corpus reveals that the\nfeatures formed on our clustering-based language model significantly improve\nthe previously known results for the same corpus in readability prediction. We\nalso evaluate the task of sentence matching based on semantic relatedness using\nthe Wiki-SimpleWiki corpus and find that our features lead to superior matching\nperformance. \n\n"}
{"id": "1709.01915", "contents": "Title: Towards Neural Machine Translation with Latent Tree Attention Abstract: Building models that take advantage of the hierarchical structure of language\nwithout a priori annotation is a longstanding goal in natural language\nprocessing. We introduce such a model for the task of machine translation,\npairing a recurrent neural network grammar encoder with a novel attentional\nRNNG decoder and applying policy gradient reinforcement learning to induce\nunsupervised tree structures on both the source and target. When trained on\ncharacter-level datasets with no explicit segmentation or parse annotation, the\nmodel learns a plausible segmentation and shallow parse, obtaining performance\nclose to an attentional baseline. \n\n"}
{"id": "1709.02828", "contents": "Title: Globally Normalized Reader Abstract: Rapid progress has been made towards question answering (QA) systems that can\nextract answers from text. Existing neural approaches make use of expensive\nbi-directional attention mechanisms or score all possible answer spans,\nlimiting scalability. We propose instead to cast extractive QA as an iterative\nsearch problem: select the answer's sentence, start word, and end word. This\nrepresentation reduces the space of each search step and allows computation to\nbe conditionally allocated to promising search paths. We show that globally\nnormalizing the decision process and back-propagating through beam search makes\nthis representation viable and learning efficient. We empirically demonstrate\nthe benefits of this approach using our model, Globally Normalized Reader\n(GNR), which achieves the second highest single model performance on the\nStanford Question Answering Dataset (68.4 EM, 76.21 F1 dev) and is 24.7x faster\nthan bi-attention-flow. We also introduce a data-augmentation method to produce\nsemantically valid examples by aligning named entities to a knowledge base and\nswapping them with new entities of the same type. This method improves the\nperformance of all models considered in this work and is of independent\ninterest for a variety of NLP tasks. \n\n"}
{"id": "1709.04109", "contents": "Title: Empower Sequence Labeling with Task-Aware Neural Language Model Abstract: Linguistic sequence labeling is a general modeling approach that encompasses\na variety of problems, such as part-of-speech tagging and named entity\nrecognition. Recent advances in neural networks (NNs) make it possible to build\nreliable models without handcrafted features. However, in many cases, it is\nhard to obtain sufficient annotations to train these models. In this study, we\ndevelop a novel neural framework to extract abundant knowledge hidden in raw\ntexts to empower the sequence labeling task. Besides word-level knowledge\ncontained in pre-trained word embeddings, character-aware neural language\nmodels are incorporated to extract character-level knowledge. Transfer learning\ntechniques are further adopted to mediate different components and guide the\nlanguage model towards the key knowledge. Comparing to previous methods, these\ntask-specific knowledge allows us to adopt a more concise model and conduct\nmore efficient training. Different from most transfer learning methods, the\nproposed framework does not rely on any additional supervision. It extracts\nknowledge from self-contained order information of training sequences.\nExtensive experiments on benchmark datasets demonstrate the effectiveness of\nleveraging character-level knowledge and the efficiency of co-training. For\nexample, on the CoNLL03 NER task, model training completes in about 6 hours on\na single GPU, reaching F1 score of 91.71$\\pm$0.10 without using any extra\nannotation. \n\n"}
{"id": "1709.06309", "contents": "Title: Aspect-Based Relational Sentiment Analysis Using a Stacked Neural\n  Network Architecture Abstract: Sentiment analysis can be regarded as a relation extraction problem in which\nthe sentiment of some opinion holder towards a certain aspect of a product,\ntheme or event needs to be extracted. We present a novel neural architecture\nfor sentiment analysis as a relation extraction problem that addresses this\nproblem by dividing it into three subtasks: i) identification of aspect and\nopinion terms, ii) labeling of opinion terms with a sentiment, and iii)\nextraction of relations between opinion terms and aspect terms. For each\nsubtask, we propose a neural network based component and combine all of them\ninto a complete system for relational sentiment analysis. The component for\naspect and opinion term extraction is a hybrid architecture consisting of a\nrecurrent neural network stacked on top of a convolutional neural network. This\napproach outperforms a standard convolutional deep neural architecture as well\nas a recurrent network architecture and performs competitively compared to\nother methods on two datasets of annotated customer reviews. To extract\nsentiments for individual opinion terms, we propose a recurrent architecture in\ncombination with word distance features and achieve promising results,\noutperforming a majority baseline by 18% accuracy and providing the first\nresults for the USAGE dataset. Our relation extraction component outperforms\nthe current state-of-the-art in aspect-opinion relation extraction by 15%\nF-Measure. \n\n"}
{"id": "1709.07758", "contents": "Title: Improving Language Modelling with Noise-contrastive estimation Abstract: Neural language models do not scale well when the vocabulary is large.\nNoise-contrastive estimation (NCE) is a sampling-based method that allows for\nfast learning with large vocabularies. Although NCE has shown promising\nperformance in neural machine translation, it was considered to be an\nunsuccessful approach for language modelling. A sufficient investigation of the\nhyperparameters in the NCE-based neural language models was also missing. In\nthis paper, we showed that NCE can be a successful approach in neural language\nmodelling when the hyperparameters of a neural network are tuned appropriately.\nWe introduced the 'search-then-converge' learning rate schedule for NCE and\ndesigned a heuristic that specifies how to use this schedule. The impact of the\nother important hyperparameters, such as the dropout rate and the weight\ninitialisation range, was also demonstrated. We showed that appropriate tuning\nof NCE-based neural language models outperforms the state-of-the-art\nsingle-model methods on a popular benchmark. \n\n"}
{"id": "1709.07858", "contents": "Title: Bootstrapping incremental dialogue systems from minimal data: the\n  generalisation power of dialogue grammars Abstract: We investigate an end-to-end method for automatically inducing task-based\ndialogue systems from small amounts of unannotated dialogue data. It combines\nan incremental semantic grammar - Dynamic Syntax and Type Theory with Records\n(DS-TTR) - with Reinforcement Learning (RL), where language generation and\ndialogue management are a joint decision problem. The systems thus produced are\nincremental: dialogues are processed word-by-word, shown previously to be\nessential in supporting natural, spontaneous dialogue. We hypothesised that the\nrich linguistic knowledge within the grammar should enable a combinatorially\nlarge number of dialogue variations to be processed, even when trained on very\nfew dialogues. Our experiments show that our model can process 74% of the\nFacebook AI bAbI dataset even when trained on only 0.13% of the data (5\ndialogues). It can in addition process 65% of bAbI+, a corpus we created by\nsystematically adding incremental dialogue phenomena such as restarts and\nself-corrections to bAbI. We compare our model with a state-of-the-art\nretrieval model, MemN2N. We find that, in terms of semantic accuracy, MemN2N\nshows very poor robustness to the bAbI+ transformations even when trained on\nthe full bAbI dataset. \n\n"}
{"id": "1709.08294", "contents": "Title: Learning Context-Sensitive Convolutional Filters for Text Processing Abstract: Convolutional neural networks (CNNs) have recently emerged as a popular\nbuilding block for natural language processing (NLP). Despite their success,\nmost existing CNN models employed in NLP share the same learned (and static)\nset of filters for all input sentences. In this paper, we consider an approach\nof using a small meta network to learn context-sensitive convolutional filters\nfor text processing. The role of meta network is to abstract the contextual\ninformation of a sentence or document into a set of input-aware filters. We\nfurther generalize this framework to model sentence pairs, where a\nbidirectional filter generation mechanism is introduced to encapsulate\nco-dependent sentence representations. In our benchmarks on four different\ntasks, including ontology classification, sentiment analysis, answer sentence\nselection, and paraphrase identification, our proposed model, a modified CNN\nwith context-sensitive filters, consistently outperforms the standard CNN and\nattention-based CNN baselines. By visualizing the learned context-sensitive\nfilters, we further validate and rationalize the effectiveness of proposed\nframework. \n\n"}
{"id": "1709.09220", "contents": "Title: Dataset Construction via Attention for Aspect Term Extraction with\n  Distant Supervision Abstract: Aspect Term Extraction (ATE) detects opinionated aspect terms in sentences or\ntext spans, with the end goal of performing aspect-based sentiment analysis.\nThe small amount of available datasets for supervised ATE and the fact that\nthey cover only a few domains raise the need for exploiting other data sources\nin new and creative ways. Publicly available review corpora contain a plethora\nof opinionated aspect terms and cover a larger domain spectrum. In this paper,\nwe first propose a method for using such review corpora for creating a new\ndataset for ATE. Our method relies on an attention mechanism to select\nsentences that have a high likelihood of containing actual opinionated aspects.\nWe thus improve the quality of the extracted aspects. We then use the\nconstructed dataset to train a model and perform ATE with distant supervision.\nBy evaluating on human annotated datasets, we prove that our method achieves a\nsignificantly improved performance over various unsupervised and supervised\nbaselines. Finally, we prove that sentence selection matters when it comes to\ncreating new datasets for ATE. Specifically, we show that, using a set of\nselected sentences leads to higher ATE performance compared to using the whole\nsentence set. \n\n"}
{"id": "1709.10381", "contents": "Title: Towards Universal Semantic Tagging Abstract: The paper proposes the task of universal semantic tagging---tagging word\ntokens with language-neutral, semantically informative tags. We argue that the\ntask, with its independent nature, contributes to better semantic analysis for\nwide-coverage multilingual text. We present the initial version of the semantic\ntagset and show that (a) the tags provide semantically fine-grained\ninformation, and (b) they are suitable for cross-lingual semantic parsing. An\napplication of the semantic tagging in the Parallel Meaning Bank supports both\nof these points as the tags contribute to formal lexical semantics and their\ncross-lingual projection. As a part of the application, we annotate a small\ncorpus with the semantic tags and present new baseline result for universal\nsemantic tagging. \n\n"}
{"id": "1710.02187", "contents": "Title: BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages Abstract: We present BPEmb, a collection of pre-trained subword unit embeddings in 275\nlanguages, based on Byte-Pair Encoding (BPE). In an evaluation using\nfine-grained entity typing as testbed, BPEmb performs competitively, and for\nsome languages bet- ter than alternative subword approaches, while requiring\nvastly fewer resources and no tokenization. BPEmb is available at\nhttps://github.com/bheinzerling/bpemb \n\n"}
{"id": "1710.02365", "contents": "Title: Czech Text Document Corpus v 2.0 Abstract: This paper introduces \"Czech Text Document Corpus v 2.0\", a collection of\ntext documents for automatic document classification in Czech language. It is\ncomposed of the text documents provided by the Czech News Agency and is freely\navailable for research purposes at http://ctdc.kiv.zcu.cz/. This corpus was\ncreated in order to facilitate a straightforward comparison of the document\nclassification approaches on Czech data. It is particularly dedicated to\nevaluation of multi-label document classification approaches, because one\ndocument is usually labelled with more than one label. Besides the information\nabout the document classes, the corpus is also annotated at the morphological\nlayer. This paper further shows the results of selected state-of-the-art\nmethods on this corpus to offer the possibility of an easy comparison with\nthese approaches. \n\n"}
{"id": "1710.04087", "contents": "Title: Word Translation Without Parallel Data Abstract: State-of-the-art methods for learning cross-lingual word embeddings have\nrelied on bilingual dictionaries or parallel corpora. Recent studies showed\nthat the need for parallel data supervision can be alleviated with\ncharacter-level information. While these methods showed encouraging results,\nthey are not on par with their supervised counterparts and are limited to pairs\nof languages sharing a common alphabet. In this work, we show that we can build\na bilingual dictionary between two languages without using any parallel\ncorpora, by aligning monolingual word embedding spaces in an unsupervised way.\nWithout using any character information, our model even outperforms existing\nsupervised methods on cross-lingual tasks for some language pairs. Our\nexperiments demonstrate that our method works very well also for distant\nlanguage pairs, like English-Russian or English-Chinese. We finally describe\nexperiments on the English-Esperanto low-resource language pair, on which there\nonly exists a limited amount of parallel data, to show the potential impact of\nour method in fully unsupervised machine translation. Our code, embeddings and\ndictionaries are publicly available. \n\n"}
{"id": "1710.05429", "contents": "Title: Semi-Supervised Approach to Monitoring Clinical Depressive Symptoms in\n  Social Media Abstract: With the rise of social media, millions of people are routinely expressing\ntheir moods, feelings, and daily struggles with mental health issues on social\nmedia platforms like Twitter. Unlike traditional observational cohort studies\nconducted through questionnaires and self-reported surveys, we explore the\nreliable detection of clinical depression from tweets obtained unobtrusively.\nBased on the analysis of tweets crawled from users with self-reported\ndepressive symptoms in their Twitter profiles, we demonstrate the potential for\ndetecting clinical depression symptoms which emulate the PHQ-9 questionnaire\nclinicians use today. Our study uses a semi-supervised statistical model to\nevaluate how the duration of these symptoms and their expression on Twitter (in\nterms of word usage patterns and topical preferences) align with the medical\nfindings reported via the PHQ-9. Our proactive and automatic screening tool is\nable to identify clinical depressive symptoms with an accuracy of 68% and\nprecision of 72%. \n\n"}
{"id": "1710.05941", "contents": "Title: Searching for Activation Functions Abstract: The choice of activation functions in deep networks has a significant effect\non the training dynamics and task performance. Currently, the most successful\nand widely-used activation function is the Rectified Linear Unit (ReLU).\nAlthough various hand-designed alternatives to ReLU have been proposed, none\nhave managed to replace it due to inconsistent gains. In this work, we propose\nto leverage automatic search techniques to discover new activation functions.\nUsing a combination of exhaustive and reinforcement learning-based search, we\ndiscover multiple novel activation functions. We verify the effectiveness of\nthe searches by conducting an empirical evaluation with the best discovered\nactivation function. Our experiments show that the best discovered activation\nfunction, $f(x) = x \\cdot \\text{sigmoid}(\\beta x)$, which we name Swish, tends\nto work better than ReLU on deeper models across a number of challenging\ndatasets. For example, simply replacing ReLUs with Swish units improves top-1\nclassification accuracy on ImageNet by 0.9\\% for Mobile NASNet-A and 0.6\\% for\nInception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it\neasy for practitioners to replace ReLUs with Swish units in any neural network. \n\n"}
{"id": "1710.06371", "contents": "Title: Specialising Word Vectors for Lexical Entailment Abstract: We present LEAR (Lexical Entailment Attract-Repel), a novel post-processing\nmethod that transforms any input word vector space to emphasise the asymmetric\nrelation of lexical entailment (LE), also known as the IS-A or\nhyponymy-hypernymy relation. By injecting external linguistic constraints\n(e.g., WordNet links) into the initial vector space, the LE specialisation\nprocedure brings true hyponymy-hypernymy pairs closer together in the\ntransformed Euclidean space. The proposed asymmetric distance measure adjusts\nthe norms of word vectors to reflect the actual WordNet-style hierarchy of\nconcepts. Simultaneously, a joint objective enforces semantic similarity using\nthe symmetric cosine distance, yielding a vector space specialised for both\nlexical relations at once. LEAR specialisation achieves state-of-the-art\nperformance in the tasks of hypernymy directionality, hypernymy detection, and\ngraded lexical entailment, demonstrating the effectiveness and robustness of\nthe proposed asymmetric specialisation model. \n\n"}
{"id": "1710.07032", "contents": "Title: SLING: A framework for frame semantic parsing Abstract: We describe SLING, a framework for parsing natural language into semantic\nframes. SLING supports general transition-based, neural-network parsing with\nbidirectional LSTM input encoding and a Transition Based Recurrent Unit (TBRU)\nfor output decoding. The parsing model is trained end-to-end using only the\ntext tokens as input. The transition system has been designed to output frame\ngraphs directly without any intervening symbolic representation. The SLING\nframework includes an efficient and scalable frame store implementation as well\nas a neural network JIT compiler for fast inference during parsing. SLING is\nimplemented in C++ and it is available for download on GitHub. \n\n"}
{"id": "1710.07654", "contents": "Title: Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence\n  Learning Abstract: We present Deep Voice 3, a fully-convolutional attention-based neural\ntext-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural\nspeech synthesis systems in naturalness while training ten times faster. We\nscale Deep Voice 3 to data set sizes unprecedented for TTS, training on more\nthan eight hundred hours of audio from over two thousand speakers. In addition,\nwe identify common error modes of attention-based speech synthesis networks,\ndemonstrate how to mitigate them, and compare several different waveform\nsynthesis methods. We also describe how to scale inference to ten million\nqueries per day on one single-GPU server. \n\n"}
{"id": "1710.07695", "contents": "Title: Verb Pattern: A Probabilistic Semantic Representation on Verbs Abstract: Verbs are important in semantic understanding of natural language.\nTraditional verb representations, such as FrameNet, PropBank, VerbNet, focus on\nverbs' roles. These roles are too coarse to represent verbs' semantics. In this\npaper, we introduce verb patterns to represent verbs' semantics, such that each\npattern corresponds to a single semantic of the verb. First we analyze the\nprinciples for verb patterns: generality and specificity. Then we propose a\nnonparametric model based on description length. Experimental results prove the\nhigh effectiveness of verb patterns. We further apply verb patterns to\ncontext-aware conceptualization, to show that verb patterns are helpful in\nsemantic-related tasks. \n\n"}
{"id": "1710.08634", "contents": "Title: Using Multi-Label Classification for Improved Question Answering Abstract: A plethora of diverse approaches for question answering over RDF data have\nbeen developed in recent years. While the accuracy of these systems has\nincreased significantly over time, most systems still focus on particular types\nof questions or particular challenges in question answering. What is a curse\nfor single systems is a blessing for the combination of these systems. We show\nin this paper how machine learning techniques can be applied to create a more\naccurate question answering metasystem by reusing existing systems. In\nparticular, we develop a multi-label classification-based metasystem for\nquestion answering over 6 existing systems using an innovative set of 14\nquestion features. The metasystem outperforms the best single system by 14%\nF-measure on the recent QALD-6 benchmark. Furthermore, we analyzed the\ninfluence and correlation of the underlying features on the metasystem quality. \n\n"}
{"id": "1710.08721", "contents": "Title: Clickbait Identification using Neural Networks Abstract: This paper presents the results of our participation in the Clickbait\nDetection Challenge 2017. The system relies on a fusion of neural networks,\nincorporating different types of available informations. It does not require\nany linguistic preprocessing, and hence generalizes more easily to new domains\nand languages. The final combined model achieves a mean squared error of\n0.0428, an accuracy of 0.826, and a F1 score of 0.564. According to the\nofficial evaluation metric the system ranked 6th of the 13 participating teams. \n\n"}
{"id": "1710.10280", "contents": "Title: One-shot and few-shot learning of word embeddings Abstract: Standard deep learning systems require thousands or millions of examples to\nlearn a concept, and cannot integrate new concepts easily. By contrast, humans\nhave an incredible ability to do one-shot or few-shot learning. For instance,\nfrom just hearing a word used in a sentence, humans can infer a great deal\nabout it, by leveraging what the syntax and semantics of the surrounding words\ntells us. Here, we draw inspiration from this to highlight a simple technique\nby which deep recurrent networks can similarly exploit their prior knowledge to\nlearn a useful representation for a new word from little data. This could make\nnatural language processing systems much more flexible, by allowing them to\nlearn continually from the new words they encounter. \n\n"}
{"id": "1710.10361", "contents": "Title: Deep Residual Learning for Small-Footprint Keyword Spotting Abstract: We explore the application of deep residual learning and dilated convolutions\nto the keyword spotting task, using the recently-released Google Speech\nCommands Dataset as our benchmark. Our best residual network (ResNet)\nimplementation significantly outperforms Google's previous convolutional neural\nnetworks in terms of accuracy. By varying model depth and width, we can achieve\ncompact models that also outperform previous small-footprint variants. To our\nknowledge, we are the first to examine these approaches for keyword spotting,\nand our results establish an open-source state-of-the-art reference to support\nthe development of future speech-based interfaces. \n\n"}
{"id": "1710.10453", "contents": "Title: Inducing Regular Grammars Using Recurrent Neural Networks Abstract: Grammar induction is the task of learning a grammar from a set of examples.\nRecently, neural networks have been shown to be powerful learning machines that\ncan identify patterns in streams of data. In this work we investigate their\neffectiveness in inducing a regular grammar from data, without any assumptions\nabout the grammar. We train a recurrent neural network to distinguish between\nstrings that are in or outside a regular language, and utilize an algorithm for\nextracting the learned finite-state automaton. We apply this method to several\nregular languages and find unexpected results regarding the connections between\nthe network's states that may be regarded as evidence for generalization. \n\n"}
{"id": "1710.10504", "contents": "Title: Phase Conductor on Multi-layered Attentions for Machine Comprehension Abstract: Attention models have been intensively studied to improve NLP tasks such as\nmachine comprehension via both question-aware passage attention model and\nself-matching attention model. Our research proposes phase conductor\n(PhaseCond) for attention models in two meaningful ways. First, PhaseCond, an\narchitecture of multi-layered attention models, consists of multiple phases\neach implementing a stack of attention layers producing passage representations\nand a stack of inner or outer fusion layers regulating the information flow.\nSecond, we extend and improve the dot-product attention function for PhaseCond\nby simultaneously encoding multiple question and passage embedding layers from\ndifferent perspectives. We demonstrate the effectiveness of our proposed model\nPhaseCond on the SQuAD dataset, showing that our model significantly\noutperforms both state-of-the-art single-layered and multiple-layered attention\nmodels. We deepen our results with new findings via both detailed qualitative\nanalysis and visualized examples showing the dynamic changes through\nmulti-layered attention models. \n\n"}
{"id": "1710.10609", "contents": "Title: Finding Dominant User Utterances And System Responses in Conversations Abstract: There are several dialog frameworks which allow manual specification of\nintents and rule based dialog flow. The rule based framework provides good\ncontrol to dialog designers at the expense of being more time consuming and\nlaborious. The job of a dialog designer can be reduced if we could identify\npairs of user intents and corresponding responses automatically from prior\nconversations between users and agents. In this paper we propose an approach to\nfind these frequent user utterances (which serve as examples for intents) and\ncorresponding agent responses. We propose a novel SimCluster algorithm that\nextends standard K-means algorithm to simultaneously cluster user utterances\nand agent utterances by taking their adjacency information into account. The\nmethod also aligns these clusters to provide pairs of intents and response\ngroups. We compare our results with those produced by using simple Kmeans\nclustering on a real dataset and observe upto 10% absolute improvement in\nF1-scores. Through our experiments on synthetic dataset, we show that our\nalgorithm gains more advantage over K-means algorithm when the data has large\nvariance. \n\n"}
{"id": "1710.10723", "contents": "Title: Simple and Effective Multi-Paragraph Reading Comprehension Abstract: We consider the problem of adapting neural paragraph-level question answering\nmodels to the case where entire documents are given as input. Our proposed\nsolution trains models to produce well calibrated confidence scores for their\nresults on individual paragraphs. We sample multiple paragraphs from the\ndocuments during training, and use a shared-normalization training objective\nthat encourages the model to produce globally correct output. We combine this\nmethod with a state-of-the-art pipeline for training models on document QA\ndata. Experiments demonstrate strong performance on several document QA\ndatasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion\nof TriviaQA, a large improvement from the 56.7 F1 of the previous best system. \n\n"}
{"id": "1710.10774", "contents": "Title: Sequence-to-Sequence ASR Optimization via Reinforcement Learning Abstract: Despite the success of sequence-to-sequence approaches in automatic speech\nrecognition (ASR) systems, the models still suffer from several problems,\nmainly due to the mismatch between the training and inference conditions. In\nthe sequence-to-sequence architecture, the model is trained to predict the\ngrapheme of the current time-step given the input of speech signal and the\nground-truth grapheme history of the previous time-steps. However, it remains\nunclear how well the model approximates real-world speech during inference.\nThus, generating the whole transcription from scratch based on previous\npredictions is complicated and errors can propagate over time. Furthermore, the\nmodel is optimized to maximize the likelihood of training data instead of error\nrate evaluation metrics that actually quantify recognition quality. This paper\npresents an alternative strategy for training sequence-to-sequence ASR models\nby adopting the idea of reinforcement learning (RL). Unlike the standard\ntraining scheme with maximum likelihood estimation, our proposed approach\nutilizes the policy gradient algorithm. We can (1) sample the whole\ntranscription based on the model's prediction in the training process and (2)\ndirectly optimize the model with negative Levenshtein distance as the reward.\nExperimental results demonstrate that we significantly improved the performance\ncompared to a model trained only with maximum likelihood estimation. \n\n"}
{"id": "1710.11041", "contents": "Title: Unsupervised Neural Machine Translation Abstract: In spite of the recent success of neural machine translation (NMT) in\nstandard benchmarks, the lack of large parallel corpora poses a major practical\nproblem for many language pairs. There have been several proposals to alleviate\nthis issue with, for instance, triangulation and semi-supervised learning\ntechniques, but they still require a strong cross-lingual signal. In this work,\nwe completely remove the need of parallel data and propose a novel method to\ntrain an NMT system in a completely unsupervised manner, relying on nothing but\nmonolingual corpora. Our model builds upon the recent work on unsupervised\nembedding mappings, and consists of a slightly modified attentional\nencoder-decoder model that can be trained on monolingual corpora alone using a\ncombination of denoising and backtranslation. Despite the simplicity of the\napproach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014\nFrench-to-English and German-to-English translation. The model can also profit\nfrom small parallel corpora, and attains 21.81 and 15.24 points when combined\nwith 100,000 parallel sentences, respectively. Our implementation is released\nas an open source project. \n\n"}
{"id": "1710.11475", "contents": "Title: A Neural-Symbolic Approach to Design of CAPTCHA Abstract: CAPTCHAs based on reading text are susceptible to machine-learning-based\nattacks due to recent significant advances in deep learning (DL). To address\nthis, this paper promotes image/visual captioning based CAPTCHAs, which is\nrobust against machine-learning-based attacks. To develop\nimage/visual-captioning-based CAPTCHAs, this paper proposes a new image\ncaptioning architecture by exploiting tensor product representations (TPR), a\nstructured neural-symbolic framework developed in cognitive science over the\npast 20 years, with the aim of integrating DL with explicit language structures\nand rules. We call it the Tensor Product Generation Network (TPGN). The key\nideas of TPGN are: 1) unsupervised learning of role-unbinding vectors of words\nvia a TPR-based deep neural network, and 2) integration of TPR with typical DL\narchitectures including Long Short-Term Memory (LSTM) models. The novelty of\nour approach lies in its ability to generate a sentence and extract partial\ngrammatical structure of the sentence by using role-unbinding vectors, which\nare obtained in an unsupervised manner. Experimental results demonstrate the\neffectiveness of the proposed approach. \n\n"}
{"id": "1711.00179", "contents": "Title: Keyword-based Query Comprehending via Multiple Optimized-Demand\n  Augmentation Abstract: In this paper, we consider the problem of machine reading task when the\nquestions are in the form of keywords, rather than natural language. In recent\nyears, researchers have achieved significant success on machine reading\ncomprehension tasks, such as SQuAD and TriviaQA. These datasets provide a\nnatural language question sentence and a pre-selected passage, and the goal is\nto answer the question according to the passage. However, in the situation of\ninteracting with machines by means of text, people are more likely to raise a\nquery in form of several keywords rather than a complete sentence. The\nkeyword-based query comprehension is a new challenge, because small variations\nto a question may completely change its semantical information, thus yield\ndifferent answers. In this paper, we propose a novel neural network system that\nconsists a Demand Optimization Model based on a passage-attention neural\nmachine translation and a Reader Model that can find the answer given the\noptimized question. The Demand Optimization Model optimizes the original query\nand output multiple reconstructed questions, then the Reader Model takes the\nnew questions as input and locate the answers from the passage. To make\npredictions robust, an evaluation mechanism will score the reconstructed\nquestions so the final answer strike a good balance between the quality of both\nthe Demand Optimization Model and the Reader Model. Experimental results on\nseveral datasets show that our framework significantly improves multiple strong\nbaselines on this challenging task. \n\n"}
{"id": "1711.00513", "contents": "Title: Evaluating Discourse Phenomena in Neural Machine Translation Abstract: For machine translation to tackle discourse phenomena, models must have\naccess to extra-sentential linguistic context. There has been recent interest\nin modelling context in neural machine translation (NMT), but models have been\nprincipally evaluated with standard automatic metrics, poorly adapted to\nevaluating discourse phenomena. In this article, we present hand-crafted,\ndiscourse test sets, designed to test the models' ability to exploit previous\nsource and target sentences. We investigate the performance of recently\nproposed multi-encoder NMT models trained on subtitles for English to French.\nWe also explore a novel way of exploiting context from the previous sentence.\nDespite gains using BLEU, multi-encoder models give limited improvement in the\nhandling of discourse phenomena: 50% accuracy on our coreference test set and\n53.5% for coherence/cohesion (compared to a non-contextual baseline of 50%). A\nsimple strategy of decoding the concatenation of the previous and current\nsentence leads to good performance, and our novel strategy of multi-encoding\nand decoding of two sentences leads to the best performance (72.5% for\ncoreference and 57% for coherence/cohesion), highlighting the importance of\ntarget-side context. \n\n"}
{"id": "1711.01068", "contents": "Title: Compressing Word Embeddings via Deep Compositional Code Learning Abstract: Natural language processing (NLP) models often require a massive number of\nparameters for word embeddings, resulting in a large storage or memory\nfootprint. Deploying neural NLP models to mobile devices requires compressing\nthe word embeddings without any significant sacrifices in performance. For this\npurpose, we propose to construct the embeddings with few basis vectors. For\neach word, the composition of basis vectors is determined by a hash code. To\nmaximize the compression rate, we adopt the multi-codebook quantization\napproach instead of binary coding scheme. Each code is composed of multiple\ndiscrete numbers, such as (3, 2, 1, 8), where the value of each component is\nlimited to a fixed range. We propose to directly learn the discrete codes in an\nend-to-end neural network by applying the Gumbel-softmax trick. Experiments\nshow the compression rate achieves 98% in a sentiment analysis task and 94% ~\n99% in machine translation tasks without performance loss. In both tasks, the\nproposed method can improve the model performance by slightly lowering the\ncompression rate. Compared to other approaches such as character-level\nsegmentation, the proposed method is language-independent and does not require\nmodifications to the network architecture. \n\n"}
{"id": "1711.01362", "contents": "Title: \"Attention\" for Detecting Unreliable News in the Information Age Abstract: An Unreliable news is any piece of information which is false or misleading,\ndeliberately spread to promote political, ideological and financial agendas.\nRecently the problem of unreliable news has got a lot of attention as the\nnumber instances of using news and social media outlets for propaganda have\nincreased rapidly. This poses a serious threat to society, which calls for\ntechnology to automatically and reliably identify unreliable news sources. This\npaper is an effort made in this direction to build systems for detecting\nunreliable news articles. In this paper, various NLP algorithms were built and\nevaluated on Unreliable News Data 2017 dataset. Variants of hierarchical\nattention networks (HAN) are presented for encoding and classifying news\narticles which achieve the best results of 0.944 ROC-AUC. Finally, Attention\nlayer weights are visualized to understand and give insight into the decisions\nmade by HANs. The results obtained are very promising and encouraging to deploy\nand use these systems in the real world to mitigate the problem of unreliable\nnews. \n\n"}
{"id": "1711.01416", "contents": "Title: Language as a matrix product state Abstract: We propose a statistical model for natural language that begins by\nconsidering language as a monoid, then representing it in complex matrices with\na compatible translation invariant probability measure. We interpret the\nprobability measure as arising via the Born rule from a translation invariant\nmatrix product state. \n\n"}
{"id": "1711.01567", "contents": "Title: Robust Speech Recognition Using Generative Adversarial Networks Abstract: This paper describes a general, scalable, end-to-end framework that uses the\ngenerative adversarial network (GAN) objective to enable robust speech\nrecognition. Encoders trained with the proposed approach enjoy improved\ninvariance by learning to map noisy audio to the same embedding space as that\nof clean audio. Unlike previous methods, the new framework does not rely on\ndomain expertise or simplifying assumptions as are often needed in signal\nprocessing, and directly encourages robustness in a data-driven way. We show\nthe new approach improves simulated far-field speech recognition of vanilla\nsequence-to-sequence models without specialized front-ends or preprocessing. \n\n"}
{"id": "1711.01921", "contents": "Title: $A^{4}NT$: Author Attribute Anonymity by Adversarial Training of Neural\n  Machine Translation Abstract: Text-based analysis methods allow to reveal privacy relevant author\nattributes such as gender, age and identify of the text's author. Such methods\ncan compromise the privacy of an anonymous author even when the author tries to\nremove privacy sensitive content. In this paper, we propose an automatic\nmethod, called Adversarial Author Attribute Anonymity Neural Translation\n($A^4NT$), to combat such text-based adversaries. We combine\nsequence-to-sequence language models used in machine translation and generative\nadversarial networks to obfuscate author attributes. Unlike machine translation\ntechniques which need paired data, our method can be trained on unpaired\ncorpora of text containing different authors. Importantly, we propose and\nevaluate techniques to impose constraints on our $A^4NT$ to preserve the\nsemantics of the input text. $A^4NT$ learns to make minimal changes to the\ninput text to successfully fool author attribute classifiers, while aiming to\nmaintain the meaning of the input. We show through experiments on two different\ndatasets and three settings that our proposed method is effective in fooling\nthe author attribute classifiers and thereby improving the anonymity of\nauthors. \n\n"}
{"id": "1711.02132", "contents": "Title: Weighted Transformer Network for Machine Translation Abstract: State-of-the-art results on neural machine translation often use attentional\nsequence-to-sequence models with some form of convolution or recursion. Vaswani\net al. (2017) propose a new architecture that avoids recurrence and convolution\ncompletely. Instead, it uses only self-attention and feed-forward layers. While\nthe proposed architecture achieves state-of-the-art results on several machine\ntranslation tasks, it requires a large number of parameters and training\niterations to converge. We propose Weighted Transformer, a Transformer with\nmodified attention layers, that not only outperforms the baseline network in\nBLEU score but also converges 15-40% faster. Specifically, we replace the\nmulti-head attention by multiple self-attention branches that the model learns\nto combine during the training process. Our model improves the state-of-the-art\nperformance by 0.5 BLEU points on the WMT 2014 English-to-German translation\ntask and by 0.4 on the English-to-French translation task. \n\n"}
{"id": "1711.02295", "contents": "Title: Quality-Efficiency Trade-offs in Machine Learning for Text Processing Abstract: Data mining, machine learning, and natural language processing are powerful\ntechniques that can be used together to extract information from large texts.\nDepending on the task or problem at hand, there are many different approaches\nthat can be used. The methods available are continuously being optimized, but\nnot all these methods have been tested and compared in a set of problems that\ncan be solved using supervised machine learning algorithms. The question is\nwhat happens to the quality of the methods if we increase the training data\nsize from, say, 100 MB to over 1 GB? Moreover, are quality gains worth it when\nthe rate of data processing diminishes? Can we trade quality for time\nefficiency and recover the quality loss by just being able to process more\ndata? We attempt to answer these questions in a general way for text processing\ntasks, considering the trade-offs involving training data size, learning time,\nand quality obtained. We propose a performance trade-off framework and apply it\nto three important text processing problems: Named Entity Recognition,\nSentiment Analysis and Document Classification. These problems were also chosen\nbecause they have different levels of object granularity: words, paragraphs,\nand documents. For each problem, we selected several supervised machine\nlearning algorithms and we evaluated the trade-offs of them on large publicly\navailable data sets (news, reviews, patents). To explore these trade-offs, we\nuse different data subsets of increasing size ranging from 50 MB to several GB.\nWe also consider the impact of the data set and the evaluation technique. We\nfind that the results do not change significantly and that most of the time the\nbest algorithms is the fastest. However, we also show that the results for\nsmall data (say less than 100 MB) are different from the results for big data\nand in those cases the best algorithm is much harder to determine. \n\n"}
{"id": "1711.02918", "contents": "Title: Improving Hypernymy Extraction with Distributional Semantic Classes Abstract: In this paper, we show how distributionally-induced semantic classes can be\nhelpful for extracting hypernyms. We present methods for inducing sense-aware\nsemantic classes using distributional semantics and using these induced\nsemantic classes for filtering noisy hypernymy relations. Denoising of\nhypernyms is performed by labeling each semantic class with its hypernyms. On\nthe one hand, this allows us to filter out wrong extractions using the global\nstructure of distributionally similar senses. On the other hand, we infer\nmissing hypernyms via label propagation to cluster terms. We conduct a\nlarge-scale crowdsourcing study showing that processing of automatically\nextracted hypernyms using our approach improves the quality of the hypernymy\nextraction in terms of both precision and recall. Furthermore, we show the\nutility of our method in the domain taxonomy induction task, achieving the\nstate-of-the-art results on a SemEval'16 task on taxonomy induction. \n\n"}
{"id": "1711.03697", "contents": "Title: Integrating User and Agent Models: A Deep Task-Oriented Dialogue System Abstract: Task-oriented dialogue systems can efficiently serve a large number of\ncustomers and relieve people from tedious works. However, existing\ntask-oriented dialogue systems depend on handcrafted actions and states or\nextra semantic labels, which sometimes degrades user experience despite the\nintensive human intervention. Moreover, current user simulators have limited\nexpressive ability so that deep reinforcement Seq2Seq models have to rely on\nselfplay and only work in some special cases. To address those problems, we\npropose a uSer and Agent Model IntegrAtion (SAMIA) framework inspired by an\nobservation that the roles of the user and agent models are asymmetric.\nFirstly, this SAMIA framework model the user model as a Seq2Seq learning\nproblem instead of ranking or designing rules. Then the built user model is\nused as a leverage to train the agent model by deep reinforcement learning. In\nthe test phase, the output of the agent model is filtered by the user model to\nenhance the stability and robustness. Experiments on a real-world coffee\nordering dataset verify the effectiveness of the proposed SAMIA framework. \n\n"}
{"id": "1711.03800", "contents": "Title: Object Referring in Visual Scene with Spoken Language Abstract: Object referring has important applications, especially for human-machine\ninteraction. While having received great attention, the task is mainly attacked\nwith written language (text) as input rather than spoken language (speech),\nwhich is more natural. This paper investigates Object Referring with Spoken\nLanguage (ORSpoken) by presenting two datasets and one novel approach. Objects\nare annotated with their locations in images, text descriptions and speech\ndescriptions. This makes the datasets ideal for multi-modality learning. The\napproach is developed by carefully taking down ORSpoken problem into three\nsub-problems and introducing task-specific vision-language interactions at the\ncorresponding levels. Experiments show that our method outperforms competing\nmethods consistently and significantly. The approach is also evaluated in the\npresence of audio noise, showing the efficacy of the proposed vision-language\ninteraction methods in counteracting background noise. \n\n"}
{"id": "1711.03953", "contents": "Title: Breaking the Softmax Bottleneck: A High-Rank RNN Language Model Abstract: We formulate language modeling as a matrix factorization problem, and show\nthat the expressiveness of Softmax-based models (including the majority of\nneural language models) is limited by a Softmax bottleneck. Given that natural\nlanguage is highly context-dependent, this further implies that in practice\nSoftmax with distributed word embeddings does not have enough capacity to model\nnatural language. We propose a simple and effective method to address this\nissue, and improve the state-of-the-art perplexities on Penn Treebank and\nWikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on\nthe large-scale 1B Word dataset, outperforming the baseline by over 5.6 points\nin perplexity. \n\n"}
{"id": "1711.04090", "contents": "Title: MojiTalk: Generating Emotional Responses at Scale Abstract: Generating emotional language is a key step towards building empathetic\nnatural language processing agents. However, a major challenge for this line of\nresearch is the lack of large-scale labeled training data, and previous studies\nare limited to only small sets of human annotated sentiment labels.\nAdditionally, explicitly controlling the emotion and sentiment of generated\ntext is also difficult. In this paper, we take a more radical approach: we\nexploit the idea of leveraging Twitter data that are naturally labeled with\nemojis. More specifically, we collect a large corpus of Twitter conversations\nthat include emojis in the response, and assume the emojis convey the\nunderlying emotions of the sentence. We then introduce a reinforced conditional\nvariational encoder approach to train a deep generative model on these\nconversations, which allows us to use emojis to control the emotion of the\ngenerated text. Experimentally, we show in our quantitative and qualitative\nanalyses that the proposed models can successfully generate high-quality\nabstractive conversation responses in accordance with designated emotions. \n\n"}
{"id": "1711.04154", "contents": "Title: Interpretable probabilistic embeddings: bridging the gap between topic\n  models and neural networks Abstract: We consider probabilistic topic models and more recent word embedding\ntechniques from a perspective of learning hidden semantic representations.\nInspired by a striking similarity of the two approaches, we merge them and\nlearn probabilistic embeddings with online EM-algorithm on word co-occurrence\ndata. The resulting embeddings perform on par with Skip-Gram Negative Sampling\n(SGNS) on word similarity tasks and benefit in the interpretability of the\ncomponents. Next, we learn probabilistic document embeddings that outperform\nparagraph2vec on a document similarity task and require less memory and time\nfor training. Finally, we employ multimodal Additive Regularization of Topic\nModels (ARTM) to obtain a high sparsity and learn embeddings for other\nmodalities, such as timestamps and categories. We observe further improvement\nof word similarity performance and meaningful inter-modality similarities. \n\n"}
{"id": "1711.04289", "contents": "Title: Neural Natural Language Inference Models Enhanced with External\n  Knowledge Abstract: Modeling natural language inference is a very challenging task. With the\navailability of large annotated data, it has recently become feasible to train\ncomplex models such as neural-network-based inference models, which have shown\nto achieve the state-of-the-art performance. Although there exist relatively\nlarge annotated data, can machines learn all knowledge needed to perform\nnatural language inference (NLI) from these data? If not, how can\nneural-network-based NLI models benefit from external knowledge and how to\nbuild NLI models to leverage it? In this paper, we enrich the state-of-the-art\nneural natural language inference models with external knowledge. We\ndemonstrate that the proposed models improve neural NLI models to achieve the\nstate-of-the-art performance on the SNLI and MultiNLI datasets. \n\n"}
{"id": "1711.04411", "contents": "Title: Convolutional Neural Network with Word Embeddings for Chinese Word\n  Segmentation Abstract: Character-based sequence labeling framework is flexible and efficient for\nChinese word segmentation (CWS). Recently, many character-based neural models\nhave been applied to CWS. While they obtain good performance, they have two\nobvious weaknesses. The first is that they heavily rely on manually designed\nbigram feature, i.e. they are not good at capturing n-gram features\nautomatically. The second is that they make no use of full word information.\nFor the first weakness, we propose a convolutional neural model, which is able\nto capture rich n-gram features without any feature engineering. For the second\none, we propose an effective approach to integrate the proposed model with word\nembeddings. We evaluate the model on two benchmark datasets: PKU and MSR.\nWithout any feature engineering, the model obtains competitive performance --\n95.7% on PKU and 97.3% on MSR. Armed with word embeddings, the model achieves\nstate-of-the-art performance on both datasets -- 96.5% on PKU and 98.0% on MSR,\nwithout using any external labeled resource. \n\n"}
{"id": "1711.04564", "contents": "Title: Phonemic and Graphemic Multilingual CTC Based Speech Recognition Abstract: Training automatic speech recognition (ASR) systems requires large amounts of\ndata in the target language in order to achieve good performance. Whereas large\ntraining corpora are readily available for languages like English, there exists\na long tail of languages which do suffer from a lack of resources. One method\nto handle data sparsity is to use data from additional source languages and\nbuild a multilingual system. Recently, ASR systems based on recurrent neural\nnetworks (RNNs) trained with connectionist temporal classification (CTC) have\ngained substantial research interest. In this work, we extended our previous\napproach towards training CTC-based systems multilingually. Our systems feature\na global phone set, based on the joint phone sets of each source language. We\nevaluated the use of different language combinations as well as the addition of\nLanguage Feature Vectors (LFVs). As contrastive experiment, we built systems\nbased on graphemes as well. Systems having a multilingual phone set are known\nto suffer in performance compared to their monolingual counterparts. With our\nproposed approach, we could reduce the gap between these mono- and multilingual\nsetups, using either graphemes or phonemes. \n\n"}
{"id": "1711.04964", "contents": "Title: Dynamic Fusion Networks for Machine Reading Comprehension Abstract: This paper presents a novel neural model - Dynamic Fusion Network (DFN), for\nmachine reading comprehension (MRC). DFNs differ from most state-of-the-art\nmodels in their use of a dynamic multi-strategy attention process, in which\npassages, questions and answer candidates are jointly fused into attention\nvectors, along with a dynamic multi-step reasoning module for generating\nanswers. With the use of reinforcement learning, for each input sample that\nconsists of a question, a passage and a list of candidate answers, an instance\nof DFN with a sample-specific network architecture can be dynamically\nconstructed by determining what attention strategy to apply and how many\nreasoning steps to take. Experiments show that DFNs achieve the best result\nreported on RACE, a challenging MRC dataset that contains real human reading\nquestions in a wide variety of types. A detailed empirical analysis also\ndemonstrates that DFNs can produce attention vectors that summarize information\nfrom questions, passages and answer candidates more effectively than other\npopular MRC models. \n\n"}
{"id": "1711.05066", "contents": "Title: Learning an Executable Neural Semantic Parser Abstract: This paper describes a neural semantic parser that maps natural language\nutterances onto logical forms which can be executed against a task-specific\nenvironment, such as a knowledge base or a database, to produce a response. The\nparser generates tree-structured logical forms with a transition-based approach\nwhich combines a generic tree-generation algorithm with domain-general\noperations defined by the logical language. The generation process is modeled\nby structured recurrent neural networks, which provide a rich encoding of the\nsentential context and generation history for making predictions. To tackle\nmismatches between natural language and logical form tokens, various attention\nmechanisms are explored. Finally, we consider different training settings for\nthe neural semantic parser, including a fully supervised training where\nannotated logical forms are given, weakly-supervised training where denotations\nare provided, and distant supervision where only unlabeled sentences and a\nknowledge base are available. Experiments across a wide range of datasets\ndemonstrate the effectiveness of our parser. \n\n"}
{"id": "1711.05116", "contents": "Title: Evidence Aggregation for Answer Re-Ranking in Open-Domain Question\n  Answering Abstract: A popular recent approach to answering open-domain questions is to first\nsearch for question-related passages and then apply reading comprehension\nmodels to extract answers. Existing methods usually extract answers from single\npassages independently. But some questions require a combination of evidence\nfrom across different sources to answer correctly. In this paper, we propose\ntwo models which make use of multiple passages to generate their answers. Both\nuse an answer-reranking approach which reorders the answer candidates generated\nby an existing state-of-the-art QA model. We propose two methods, namely,\nstrength-based re-ranking and coverage-based re-ranking, to make use of the\naggregated evidence from different passages to better determine the answer. Our\nmodels have achieved state-of-the-art results on three public open-domain QA\ndatasets: Quasar-T, SearchQA and the open-domain version of TriviaQA, with\nabout 8 percentage points of improvement over the former two datasets. \n\n"}
{"id": "1711.05350", "contents": "Title: A Deep Learning Approach for Expert Identification in Question Answering\n  Communities Abstract: In this paper, we describe an effective convolutional neural network\nframework for identifying the expert in question answering community. This\napproach uses the convolutional neural network and combines user feature\nrepresentations with question feature representations to compute scores that\nthe user who gets the highest score is the expert on this question. Unlike\nprior work, this method does not measure expert based on measure answer content\nquality to identify the expert but only require question sentence and user\nembedding feature to identify the expert. Remarkably, Our model can be applied\nto different languages and different domains. The proposed framework is trained\non two datasets, The first dataset is Stack Overflow and the second one is\nZhihu. The Top-1 accuracy results of our experiments show that our framework\noutperforms the best baseline framework for expert identification. \n\n"}
{"id": "1711.05443", "contents": "Title: Human and Machine Speaker Recognition Based on Short Trivial Events Abstract: Trivial events are ubiquitous in human to human conversations, e.g., cough,\nlaugh and sniff. Compared to regular speech, these trivial events are usually\nshort and unclear, thus generally regarded as not speaker discriminative and so\nare largely ignored by present speaker recognition research. However, these\ntrivial events are highly valuable in some particular circumstances such as\nforensic examination, as they are less subjected to intentional change, so can\nbe used to discover the genuine speaker from disguised speech. In this paper,\nwe collect a trivial event speech database that involves 75 speakers and 6\ntypes of events, and report preliminary speaker recognition results on this\ndatabase, by both human listeners and machines. Particularly, the deep feature\nlearning technique recently proposed by our group is utilized to analyze and\nrecognize the trivial events, which leads to acceptable equal error rates\n(EERs) despite the extremely short durations (0.2-0.5 seconds) of these events.\nComparing different types of events, 'hmm' seems more speaker discriminative. \n\n"}
{"id": "1711.05448", "contents": "Title: Lattice Rescoring Strategies for Long Short Term Memory Language Models\n  in Speech Recognition Abstract: Recurrent neural network (RNN) language models (LMs) and Long Short Term\nMemory (LSTM) LMs, a variant of RNN LMs, have been shown to outperform\ntraditional N-gram LMs on speech recognition tasks. However, these models are\ncomputationally more expensive than N-gram LMs for decoding, and thus,\nchallenging to integrate into speech recognizers. Recent research has proposed\nthe use of lattice-rescoring algorithms using RNNLMs and LSTMLMs as an\nefficient strategy to integrate these models into a speech recognition system.\nIn this paper, we evaluate existing lattice rescoring algorithms along with new\nvariants on a YouTube speech recognition task. Lattice rescoring using LSTMLMs\nreduces the word error rate (WER) for this task by 8\\% relative to the WER\nobtained using an N-gram LM. \n\n"}
{"id": "1711.05538", "contents": "Title: Detecting and assessing contextual change in diachronic text documents\n  using context volatility Abstract: Terms in diachronic text corpora may exhibit a high degree of semantic\ndynamics that is only partially captured by the common notion of semantic\nchange. The new measure of context volatility that we propose models the degree\nby which terms change context in a text collection over time. The computation\nof context volatility for a word relies on the significance-values of its\nco-occurrent terms and the corresponding co-occurrence ranks in sequential time\nspans. We define a baseline and present an efficient computational approach in\norder to overcome problems related to computational issues in the data\nstructure. Results are evaluated both, on synthetic documents that are used to\nsimulate contextual changes, and a real example based on British newspaper\ntexts. \n\n"}
{"id": "1711.06004", "contents": "Title: Remedies against the Vocabulary Gap in Information Retrieval Abstract: Search engines rely heavily on term-based approaches that represent queries\nand documents as bags of words. Text---a document or a query---is represented\nby a bag of its words that ignores grammar and word order, but retains word\nfrequency counts. When presented with a search query, the engine then ranks\ndocuments according to their relevance scores by computing, among other things,\nthe matching degrees between query and document terms. While term-based\napproaches are intuitive and effective in practice, they are based on the\nhypothesis that documents that exactly contain the query terms are highly\nrelevant regardless of query semantics. Inversely, term-based approaches assume\ndocuments that do not contain query terms as irrelevant. However, it is known\nthat a high matching degree at the term level does not necessarily mean high\nrelevance and, vice versa, documents that match null query terms may still be\nrelevant. Consequently, there exists a vocabulary gap between queries and\ndocuments that occurs when both use different words to describe the same\nconcepts. It is the alleviation of the effect brought forward by this\nvocabulary gap that is the topic of this dissertation. More specifically, we\npropose (1) methods to formulate an effective query from complex textual\nstructures and (2) latent vector space models that circumvent the vocabulary\ngap in information retrieval. \n\n"}
{"id": "1711.06141", "contents": "Title: ConvAMR: Abstract meaning representation parsing for legal document Abstract: Convolutional neural networks (CNN) have recently achieved remarkable\nperformance in a wide range of applications. In this research, we equip\nconvolutional sequence-to-sequence (seq2seq) model with an efficient graph\nlinearization technique for abstract meaning representation parsing. Our\nlinearization method is better than the prior method at signaling the turn of\ngraph traveling. Additionally, convolutional seq2seq model is more appropriate\nand considerably faster than the recurrent neural network models in this task.\nOur method outperforms previous methods by a large margin on both the standard\ndataset LDC2014T12. Our result indicates that future works still have a room\nfor improving parsing model using graph linearization approach. \n\n"}
{"id": "1711.06794", "contents": "Title: Co-attending Free-form Regions and Detections with Multi-modal\n  Multiplicative Feature Embedding for Visual Question Answering Abstract: Recently, the Visual Question Answering (VQA) task has gained increasing\nattention in artificial intelligence. Existing VQA methods mainly adopt the\nvisual attention mechanism to associate the input question with corresponding\nimage regions for effective question answering. The free-form region based and\nthe detection-based visual attention mechanisms are mostly investigated, with\nthe former ones attending free-form image regions and the latter ones attending\npre-specified detection-box regions. We argue that the two attention mechanisms\nare able to provide complementary information and should be effectively\nintegrated to better solve the VQA problem. In this paper, we propose a novel\ndeep neural network for VQA that integrates both attention mechanisms. Our\nproposed framework effectively fuses features from free-form image regions,\ndetection boxes, and question representations via a multi-modal multiplicative\nfeature embedding scheme to jointly attend question-related free-form image\nregions and detection boxes for more accurate question answering. The proposed\nmethod is extensively evaluated on two publicly available datasets, COCO-QA and\nVQA, and outperforms state-of-the-art approaches. Source code is available at\nhttps://github.com/lupantech/dual-mfa-vqa. \n\n"}
{"id": "1711.07128", "contents": "Title: Hello Edge: Keyword Spotting on Microcontrollers Abstract: Keyword spotting (KWS) is a critical component for enabling speech based user\ninteractions on smart devices. It requires real-time response and high accuracy\nfor good user experience. Recently, neural networks have become an attractive\nchoice for KWS architecture because of their superior accuracy compared to\ntraditional speech processing algorithms. Due to its always-on nature, KWS\napplication has highly constrained power budget and typically runs on tiny\nmicrocontrollers with limited memory and compute capability. The design of\nneural network architecture for KWS must consider these constraints. In this\nwork, we perform neural network architecture evaluation and exploration for\nrunning KWS on resource-constrained microcontrollers. We train various neural\nnetwork architectures for keyword spotting published in literature to compare\ntheir accuracy and memory/compute requirements. We show that it is possible to\noptimize these neural network architectures to fit within the memory and\ncompute constraints of microcontrollers without sacrificing accuracy. We\nfurther explore the depthwise separable convolutional neural network (DS-CNN)\nand compare it against other neural network architectures. DS-CNN achieves an\naccuracy of 95.4%, which is ~10% higher than the DNN model with similar number\nof parameters. \n\n"}
{"id": "1711.07646", "contents": "Title: Evaluating Machine Translation Performance on Chinese Idioms with a\n  Blacklist Method Abstract: Idiom translation is a challenging problem in machine translation because the\nmeaning of idioms is non-compositional, and a literal (word-by-word)\ntranslation is likely to be wrong. In this paper, we focus on evaluating the\nquality of idiom translation of MT systems. We introduce a new evaluation\nmethod based on an idiom-specific blacklist of literal translations, based on\nthe insight that the occurrence of any blacklisted words in the translation\noutput indicates a likely translation error. We introduce a dataset, CIBB\n(Chinese Idioms Blacklists Bank), and perform an evaluation of a\nstate-of-the-art Chinese-English neural MT system. Our evaluation confirms that\na sizable number of idioms in our test set are mistranslated (46.1%), that\nliteral translation error is a common error type, and that our blacklist method\nis effective at identifying literal translation errors. \n\n"}
{"id": "1711.08412", "contents": "Title: Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes Abstract: Word embeddings use vectors to represent words such that the geometry between\nvectors captures semantic relationship between the words. In this paper, we\ndevelop a framework to demonstrate how the temporal dynamics of the embedding\ncan be leveraged to quantify changes in stereotypes and attitudes toward women\nand ethnic minorities in the 20th and 21st centuries in the United States. We\nintegrate word embeddings trained on 100 years of text data with the U.S.\nCensus to show that changes in the embedding track closely with demographic and\noccupation shifts over time. The embedding captures global social shifts --\ne.g., the women's movement in the 1960s and Asian immigration into the U.S --\nand also illuminates how specific adjectives and occupations became more\nclosely associated with certain populations over time. Our framework for\ntemporal analysis of word embedding opens up a powerful new intersection\nbetween machine learning and quantitative social science. \n\n"}
{"id": "1711.09534", "contents": "Title: Neural Text Generation: A Practical Guide Abstract: Deep learning methods have recently achieved great empirical success on\nmachine translation, dialogue response generation, summarization, and other\ntext generation tasks. At a high level, the technique has been to train\nend-to-end neural network models consisting of an encoder model to produce a\nhidden representation of the source text, followed by a decoder model to\ngenerate the target. While such models have significantly fewer pieces than\nearlier systems, significant tuning is still required to achieve good\nperformance. For text generation models in particular, the decoder can behave\nin undesired ways, such as by generating truncated or repetitive outputs,\noutputting bland and generic responses, or in some cases producing\nungrammatical gibberish. This paper is intended as a practical guide for\nresolving such undesired behavior in text generation models, with the aim of\nhelping enable real-world applications. \n\n"}
{"id": "1711.09684", "contents": "Title: Production Ready Chatbots: Generate if not Retrieve Abstract: In this paper, we present a hybrid model that combines a neural\nconversational model and a rule-based graph dialogue system that assists users\nin scheduling reminders through a chat conversation. The graph based system has\nhigh precision and provides a grammatically accurate response but has a low\nrecall. The neural conversation model can cater to a variety of requests, as it\ngenerates the responses word by word as opposed to using canned responses. The\nhybrid system shows significant improvements over the existing baseline system\nof rule based approach and caters to complex queries with a domain-restricted\nneural model. Restricting the conversation topic and combination of graph based\nretrieval system with a neural generative model makes the final system robust\nenough for a real world application. \n\n"}
{"id": "1711.09873", "contents": "Title: Slim Embedding Layers for Recurrent Neural Language Models Abstract: Recurrent neural language models are the state-of-the-art models for language\nmodeling. When the vocabulary size is large, the space taken to store the model\nparameters becomes the bottleneck for the use of recurrent neural language\nmodels. In this paper, we introduce a simple space compression method that\nrandomly shares the structured parameters at both the input and output\nembedding layers of the recurrent neural language models to significantly\nreduce the size of model parameters, but still compactly represent the original\ninput and output embedding layers. The method is easy to implement and tune.\nExperiments on several data sets show that the new method can get similar\nperplexity and BLEU score results while only using a very tiny fraction of\nparameters. \n\n"}
{"id": "1711.10093", "contents": "Title: Surfacing contextual hate speech words within social media Abstract: Social media platforms have recently seen an increase in the occurrence of\nhate speech discourse which has led to calls for improved detection methods.\nMost of these rely on annotated data, keywords, and a classification technique.\nWhile this approach provides good coverage, it can fall short when dealing with\nnew terms produced by online extremist communities which act as original\nsources of words which have alternate hate speech meanings. These code words\n(which can be both created and adopted words) are designed to evade automatic\ndetection and often have benign meanings in regular discourse. As an example,\n\"skypes\", \"googles\", and \"yahoos\" are all instances of words which have an\nalternate meaning that can be used for hate speech. This overlap introduces\nadditional challenges when relying on keywords for both the collection of data\nthat is specific to hate speech, and downstream classification. In this work,\nwe develop a community detection approach for finding extremist hate speech\ncommunities and collecting data from their members. We also develop a word\nembedding model that learns the alternate hate speech meaning of words and\ndemonstrate the candidacy of our code words with several annotation\nexperiments, designed to determine if it is possible to recognize a word as\nbeing used for hate speech without knowing its alternate meaning. We report an\ninter-annotator agreement rate of K=0.871, and K=0.676 for data drawn from our\nextremist community and the keyword approach respectively, supporting our claim\nthat hate speech detection is a contextual task and does not depend on a fixed\nlist of keywords. Our goal is to advance the domain by providing a high quality\nhate speech dataset in addition to learned code words that can be fed into\nexisting classification approaches, thus improving the accuracy of automated\ndetection. \n\n"}
{"id": "1711.10122", "contents": "Title: End-to-end Adversarial Learning for Generative Conversational Agents Abstract: This paper presents a new adversarial learning method for generative\nconversational agents (GCA) besides a new model of GCA. Similar to previous\nworks on adversarial learning for dialogue generation, our method assumes the\nGCA as a generator that aims at fooling a discriminator that labels dialogues\nas human-generated or machine-generated; however, in our approach, the\ndiscriminator performs token-level classification, i.e. it indicates whether\nthe current token was generated by humans or machines. To do so, the\ndiscriminator also receives the context utterances (the dialogue history) and\nthe incomplete answer up to the current token as input. This new approach makes\npossible the end-to-end training by backpropagation. A self-conversation\nprocess enables to produce a set of generated data with more diversity for the\nadversarial training. This approach improves the performance on questions not\nrelated to the training data. Experimental results with human and adversarial\nevaluations show that the adversarial method yields significant performance\ngains over the usual teacher forcing training. \n\n"}
{"id": "1711.10327", "contents": "Title: Generative Interest Estimation for Document Recommendations Abstract: Learning distributed representations of documents has pushed the\nstate-of-the-art in several natural language processing tasks and was\nsuccessfully applied to the field of recommender systems recently. In this\npaper, we propose a novel content-based recommender system based on learned\nrepresentations and a generative model of user interest. Our method works as\nfollows: First, we learn representations on a corpus of text documents. Then,\nwe capture a user's interest as a generative model in the space of the document\nrepresentations. In particular, we model the distribution of interest for each\nuser as a Gaussian mixture model (GMM). Recommendations can be obtained\ndirectly by sampling from a user's generative model. Using Latent semantic\nanalysis (LSA) as comparison, we compute and explore document representations\non the Delicious bookmarks dataset, a standard benchmark for recommender\nsystems. We then perform density estimation in both spaces and show that\nlearned representations outperform LSA in terms of predictive performance. \n\n"}
{"id": "1711.11543", "contents": "Title: Embodied Question Answering Abstract: We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where\nan agent is spawned at a random location in a 3D environment and asked a\nquestion (\"What color is the car?\"). In order to answer, the agent must first\nintelligently navigate to explore the environment, gather information through\nfirst-person (egocentric) vision, and then answer the question (\"orange\").\n  This challenging task requires a range of AI skills -- active perception,\nlanguage understanding, goal-driven navigation, commonsense reasoning, and\ngrounding of language into actions. In this work, we develop the environments,\nend-to-end-trained reinforcement learning agents, and evaluation protocols for\nEmbodiedQA. \n\n"}
{"id": "1712.00377", "contents": "Title: Don't Just Assume; Look and Answer: Overcoming Priors for Visual\n  Question Answering Abstract: A number of studies have found that today's Visual Question Answering (VQA)\nmodels are heavily driven by superficial correlations in the training data and\nlack sufficient image grounding. To encourage development of models geared\ntowards the latter, we propose a new setting for VQA where for every question\ntype, train and test sets have different prior distributions of answers.\nSpecifically, we present new splits of the VQA v1 and VQA v2 datasets, which we\ncall Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2\nrespectively). First, we evaluate several existing VQA models under this new\nsetting and show that their performance degrades significantly compared to the\noriginal VQA setting. Second, we propose a novel Grounded Visual Question\nAnswering model (GVQA) that contains inductive biases and restrictions in the\narchitecture specifically designed to prevent the model from 'cheating' by\nprimarily relying on priors in the training data. Specifically, GVQA explicitly\ndisentangles the recognition of visual concepts present in the image from the\nidentification of plausible answer space for a given question, enabling the\nmodel to more robustly generalize across different distributions of answers.\nGVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).\nOur experiments demonstrate that GVQA significantly outperforms SAN on both\nVQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more\npowerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in\nseveral cases. GVQA offers strengths complementary to SAN when trained and\nevaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more\ntransparent and interpretable than existing VQA models. \n\n"}
{"id": "1712.01586", "contents": "Title: Deep Semantic Role Labeling with Self-Attention Abstract: Semantic Role Labeling (SRL) is believed to be a crucial step towards natural\nlanguage understanding and has been widely studied. Recent years, end-to-end\nSRL with recurrent neural networks (RNN) has gained increasing attention.\nHowever, it remains a major challenge for RNNs to handle structural information\nand long range dependencies. In this paper, we present a simple and effective\narchitecture for SRL which aims to address these problems. Our model is based\non self-attention which can directly capture the relationships between two\ntokens regardless of their distance. Our single model achieves F$_1=83.4$ on\nthe CoNLL-2005 shared task dataset and F$_1=82.7$ on the CoNLL-2012 shared task\ndataset, which outperforms the previous state-of-the-art results by $1.8$ and\n$1.0$ F$_1$ score respectively. Besides, our model is computationally\nefficient, and the parsing speed is 50K tokens per second on a single Titan X\nGPU. \n\n"}
{"id": "1712.01719", "contents": "Title: Phylogenetics of Indo-European Language families via an\n  Algebro-Geometric Analysis of their Syntactic Structures Abstract: Using Phylogenetic Algebraic Geometry, we analyze computationally the\nphylogenetic tree of subfamilies of the Indo-European language family, using\ndata of syntactic structures. The two main sources of syntactic data are the\nSSWL database and Longobardi's recent data of syntactic parameters. We compute\nphylogenetic invariants and likelihood functions for two sets of Germanic\nlanguages, a set of Romance languages, a set of Slavic languages and a set of\nearly Indo-European languages, and we compare the results with what is known\nthrough historical linguistics. \n\n"}
{"id": "1712.01807", "contents": "Title: Improving the Performance of Online Neural Transducer Models Abstract: Having a sequence-to-sequence model which can operate in an online fashion is\nimportant for streaming applications such as Voice Search. Neural transducer is\na streaming sequence-to-sequence model, but has shown a significant degradation\nin performance compared to non-streaming models such as Listen, Attend and\nSpell (LAS). In this paper, we present various improvements to NT.\nSpecifically, we look at increasing the window over which NT computes\nattention, mainly by looking backwards in time so the model still remains\nonline. In addition, we explore initializing a NT model from a LAS-trained\nmodel so that it is guided with a better alignment. Finally, we explore\nincluding stronger language models such as using wordpiece models, and applying\nan external LM during the beam search. On a Voice Search task, we find with\nthese improvements we can get NT to match the performance of LAS. \n\n"}
{"id": "1712.01813", "contents": "Title: Neural Cross-Lingual Entity Linking Abstract: A major challenge in Entity Linking (EL) is making effective use of\ncontextual information to disambiguate mentions to Wikipedia that might refer\nto different entities in different contexts. The problem exacerbates with\ncross-lingual EL which involves linking mentions written in non-English\ndocuments to entries in the English Wikipedia: to compare textual clues across\nlanguages we need to compute similarity between textual fragments across\nlanguages. In this paper, we propose a neural EL model that trains fine-grained\nsimilarities and dissimilarities between the query and candidate document from\nmultiple perspectives, combined with convolution and tensor networks. Further,\nwe show that this English-trained system can be applied, in zero-shot learning,\nto other languages by making surprisingly effective use of multi-lingual\nembeddings. The proposed system has strong empirical evidence yielding\nstate-of-the-art results in English as well as cross-lingual: Spanish and\nChinese TAC 2015 datasets. \n\n"}
{"id": "1712.01821", "contents": "Title: Neural Machine Translation by Generating Multiple Linguistic Factors Abstract: Factored neural machine translation (FNMT) is founded on the idea of using\nthe morphological and grammatical decomposition of the words (factors) at the\noutput side of the neural network. This architecture addresses two well-known\nproblems occurring in MT, namely the size of target language vocabulary and the\nnumber of unknown tokens produced in the translation. FNMT system is designed\nto manage larger vocabulary and reduce the training time (for systems with\nequivalent target language vocabulary size). Moreover, we can produce\ngrammatically correct words that are not part of the vocabulary. FNMT model is\nevaluated on IWSLT'15 English to French task and compared to the baseline\nword-based and BPE-based NMT systems. Promising qualitative and quantitative\nresults (in terms of BLEU and METEOR) are reported. \n\n"}
{"id": "1712.01996", "contents": "Title: An analysis of incorporating an external language model into a\n  sequence-to-sequence model Abstract: Attention-based sequence-to-sequence models for automatic speech recognition\njointly train an acoustic model, language model, and alignment mechanism. Thus,\nthe language model component is only trained on transcribed audio-text pairs.\nThis leads to the use of shallow fusion with an external language model at\ninference time. Shallow fusion refers to log-linear interpolation with a\nseparately trained language model at each step of the beam search. In this\nwork, we investigate the behavior of shallow fusion across a range of\nconditions: different types of language models, different decoding units, and\ndifferent tasks. On Google Voice Search, we demonstrate that the use of shallow\nfusion with a neural LM with wordpieces yields a 9.1% relative word error rate\nreduction (WERR) over our competitive attention-based sequence-to-sequence\nmodel, obviating the need for second-pass rescoring. \n\n"}
{"id": "1712.03449", "contents": "Title: Modulating and attending the source image during encoding improves\n  Multimodal Translation Abstract: We propose a new and fully end-to-end approach for multimodal translation\nwhere the source text encoder modulates the entire visual input processing\nusing conditional batch normalization, in order to compute the most informative\nimage features for our task. Additionally, we propose a new attention mechanism\nderived from this original idea, where the attention model for the visual input\nis conditioned on the source text encoder representations. In the paper, we\ndetail our models as well as the image analysis pipeline. Finally, we report\nexperimental results. They are, as far as we know, the new state of the art on\nthree different test sets. \n\n"}
{"id": "1712.04313", "contents": "Title: The Zero Resource Speech Challenge 2017 Abstract: We describe a new challenge aimed at discovering subword and word units from\nraw speech. This challenge is the followup to the Zero Resource Speech\nChallenge 2015. It aims at constructing systems that generalize across\nlanguages and adapt to new speakers. The design features and evaluation metrics\nof the challenge are presented and the results of seventeen models are\ndiscussed. \n\n"}
{"id": "1712.06682", "contents": "Title: Synthesizing Novel Pairs of Image and Text Abstract: Generating novel pairs of image and text is a problem that combines computer\nvision and natural language processing. In this paper, we present strategies\nfor generating novel image and caption pairs based on existing captioning\ndatasets. The model takes advantage of recent advances in generative\nadversarial networks and sequence-to-sequence modeling. We make generalizations\nto generate paired samples from multiple domains. Furthermore, we study cycles\n-- generating from image to text then back to image and vise versa, as well as\nits connection with autoencoders. \n\n"}
{"id": "1712.06751", "contents": "Title: HotFlip: White-Box Adversarial Examples for Text Classification Abstract: We propose an efficient method to generate white-box adversarial examples to\ntrick a character-level neural classifier. We find that only a few\nmanipulations are needed to greatly decrease the accuracy. Our method relies on\nan atomic flip operation, which swaps one token for another, based on the\ngradients of the one-hot input vectors. Due to efficiency of our method, we can\nperform adversarial training which makes the model more robust to attacks at\ntest time. With the use of a few semantics-preserving constraints, we\ndemonstrate that HotFlip can be adapted to attack a word-level classifier as\nwell. \n\n"}
{"id": "1712.07473", "contents": "Title: Differentially Private Distributed Learning for Language Modeling Tasks Abstract: One of the big challenges in machine learning applications is that training\ndata can be different from the real-world data faced by the algorithm. In\nlanguage modeling, users' language (e.g. in private messaging) could change in\na year and be completely different from what we observe in publicly available\ndata. At the same time, public data can be used for obtaining general knowledge\n(i.e. general model of English). We study approaches to distributed fine-tuning\nof a general model on user private data with the additional requirements of\nmaintaining the quality on the general data and minimization of communication\ncosts. We propose a novel technique that significantly improves prediction\nquality on users' language compared to a general model and outperforms gradient\ncompression methods in terms of communication efficiency. The proposed\nprocedure is fast and leads to an almost 70% perplexity reduction and 8.7\npercentage point improvement in keystroke saving rate on informal English\ntexts. We also show that the range of tasks our approach is applicable to is\nnot limited by language modeling only. Finally, we propose an experimental\nframework for evaluating differential privacy of distributed training of\nlanguage models and show that our approach has good privacy guarantees. \n\n"}
{"id": "1712.08291", "contents": "Title: TFW, DamnGina, Juvie, and Hotsie-Totsie: On the Linguistic and Social\n  Aspects of Internet Slang Abstract: Slang is ubiquitous on the Internet. The emergence of new social contexts\nlike micro-blogs, question-answering forums, and social networks has enabled\nslang and non-standard expressions to abound on the web. Despite this, slang\nhas been traditionally viewed as a form of non-standard language -- a form of\nlanguage that is not the focus of linguistic analysis and has largely been\nneglected. In this work, we use UrbanDictionary to conduct the first\nlarge-scale linguistic analysis of slang and its social aspects on the Internet\nto yield insights into this variety of language that is increasingly used all\nover the world online.\n  We begin by computationally analyzing the phonological, morphological and\nsyntactic properties of slang. We then study linguistic patterns in four\nspecific categories of slang namely alphabetisms, blends, clippings, and\nreduplicatives. Our analysis reveals that slang demonstrates extra-grammatical\nrules of phonological and morphological formation that markedly distinguish it\nfrom the standard form shedding insight into its generative patterns. Next, we\nanalyze the social aspects of slang by studying subject restriction and\nstereotyping in slang usage. Analyzing tens of thousands of such slang words\nreveals that the majority of slang on the Internet belongs to two major\ncategories: sex and drugs. We also noted that not only is slang usage not\nimmune to prevalent social biases and prejudices but also reflects such biases\nand stereotypes more intensely than the standard variety. \n\n"}
{"id": "1712.08793", "contents": "Title: Are words easier to learn from infant- than adult-directed speech? A\n  quantitative corpus-based investigation Abstract: We investigate whether infant-directed speech (IDS) could facilitate word\nform learning when compared to adult-directed speech (ADS). To study this, we\nexamine the distribution of word forms at two levels, acoustic and\nphonological, using a large database of spontaneous speech in Japanese. At the\nacoustic level we show that, as has been documented before for phonemes, the\nrealizations of words are more variable and less discriminable in IDS than in\nADS. At the phonological level, we find an effect in the opposite direction:\nthe IDS lexicon contains more distinctive words (such as onomatopoeias) than\nthe ADS counterpart. Combining the acoustic and phonological metrics together\nin a global discriminability score reveals that the bigger separation of\nlexical categories in the phonological space does not compensate for the\nopposite effect observed at the acoustic level. As a result, IDS word forms are\nstill globally less discriminable than ADS word forms, even though the effect\nis numerically small. We discuss the implication of these findings for the view\nthat the functional role of IDS is to improve language learnability. \n\n"}
{"id": "1801.00428", "contents": "Title: Sanskrit Sandhi Splitting using seq2(seq)^2 Abstract: In Sanskrit, small words (morphemes) are combined to form compound words\nthrough a process known as Sandhi. Sandhi splitting is the process of splitting\na given compound word into its constituent morphemes. Although rules governing\nword splitting exists in the language, it is highly challenging to identify the\nlocation of the splits in a compound word. Though existing Sandhi splitting\nsystems incorporate these pre-defined splitting rules, they have a low accuracy\nas the same compound word might be broken down in multiple ways to provide\nsyntactically correct splits.\n  In this research, we propose a novel deep learning architecture called Double\nDecoder RNN (DD-RNN), which (i) predicts the location of the split(s) with 95%\naccuracy, and (ii) predicts the constituent words (learning the Sandhi\nsplitting rules) with 79.5% accuracy, outperforming the state-of-art by 20%.\nAdditionally, we show the generalization capability of our deep learning model,\nby showing competitive results in the problem of Chinese word segmentation, as\nwell. \n\n"}
{"id": "1801.01825", "contents": "Title: Towards Understanding and Answering Multi-Sentence Recommendation\n  Questions on Tourism Abstract: We introduce the first system towards the novel task of answering complex\nmultisentence recommendation questions in the tourism domain. Our solution uses\na pipeline of two modules: question understanding and answering. For question\nunderstanding, we define an SQL-like query language that captures the semantic\nintent of a question; it supports operators like subset, negation, preference\nand similarity, which are often found in recommendation questions. We train and\ncompare traditional CRFs as well as bidirectional LSTM-based models for\nconverting a question to its semantic representation. We extend these models to\na semisupervised setting with partially labeled sequences gathered through\ncrowdsourcing. We find that our best model performs semi-supervised training of\nBiDiLSTM+CRF with hand-designed features and CCM(Chang et al., 2007)\nconstraints. Finally, in an end to end QA system, our answering component\nconverts our question representation into queries fired on underlying knowledge\nsources. Our experiments on two different answer corpora demonstrate that our\nsystem can significantly outperform baselines with up to 20 pt higher accuracy\nand 17 pt higher recall. \n\n"}
{"id": "1801.02916", "contents": "Title: Denotation Extraction for Interactive Learning in Dialogue Systems Abstract: This paper presents a novel task using real user data obtained in\nhuman-machine conversation. The task concerns with denotation extraction from\nanswer hints collected interactively in a dialogue. The task is motivated by\nthe need for large amounts of training data for question answering dialogue\nsystem development, where the data is often expensive and hard to collect.\nBeing able to collect denotation interactively and directly from users, one\ncould improve, for example, natural understanding components on-line and ease\nthe collection of the training data. This paper also presents introductory\nresults of evaluation of several denotation extraction models including\nattention-based neural network approaches. \n\n"}
{"id": "1801.04726", "contents": "Title: An Interpretable Reasoning Network for Multi-Relation Question Answering Abstract: Multi-relation Question Answering is a challenging task, due to the\nrequirement of elaborated analysis on questions and reasoning over multiple\nfact triples in knowledge base. In this paper, we present a novel model called\nInterpretable Reasoning Network that employs an interpretable, hop-by-hop\nreasoning process for question answering. The model dynamically decides which\npart of an input question should be analyzed at each hop; predicts a relation\nthat corresponds to the current parsed results; utilizes the predicted relation\nto update the question representation and the state of the reasoning process;\nand then drives the next-hop reasoning. Experiments show that our model yields\nstate-of-the-art results on two datasets. More interestingly, the model can\noffer traceable and observable intermediate predictions for reasoning analysis\nand failure diagnosis, thereby allowing manual manipulation in predicting the\nfinal answer. \n\n"}
{"id": "1801.04958", "contents": "Title: Topic Modeling on Health Journals with Regularized Variational Inference Abstract: Topic modeling enables exploration and compact representation of a corpus.\nThe CaringBridge (CB) dataset is a massive collection of journals written by\npatients and caregivers during a health crisis. Topic modeling on the CB\ndataset, however, is challenging due to the asynchronous nature of multiple\nauthors writing about their health journeys. To overcome this challenge we\nintroduce the Dynamic Author-Persona topic model (DAP), a probabilistic\ngraphical model designed for temporal corpora with multiple authors. The\nnovelty of the DAP model lies in its representation of authors by a persona ---\nwhere personas capture the propensity to write about certain topics over time.\nFurther, we present a regularized variational inference algorithm, which we use\nto encourage the DAP model's personas to be distinct. Our results show\nsignificant improvements over competing topic models --- particularly after\nregularization, and highlight the DAP model's unique ability to capture common\njourneys shared by different authors. \n\n"}
{"id": "1801.05147", "contents": "Title: Adversarial Learning for Chinese NER from Crowd Annotations Abstract: To quickly obtain new labeled data, we can choose crowdsourcing as an\nalternative way at lower cost in a short time. But as an exchange, crowd\nannotations from non-experts may be of lower quality than those from experts.\nIn this paper, we propose an approach to performing crowd annotation learning\nfor Chinese Named Entity Recognition (NER) to make full use of the noisy\nsequence labels from multiple annotators. Inspired by adversarial learning, our\napproach uses a common Bi-LSTM and a private Bi-LSTM for representing\nannotator-generic and -specific information. The annotator-generic information\nis the common knowledge for entities easily mastered by the crowd. Finally, we\nbuild our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we\ncreate two data sets for Chinese NER tasks from two domains. The experimental\nresults show that our system achieves better scores than strong baseline\nsystems. \n\n"}
{"id": "1801.05453", "contents": "Title: Beyond Word Importance: Contextual Decomposition to Extract Interactions\n  from LSTMs Abstract: The driving force behind the recent success of LSTMs has been their ability\nto learn complex and non-linear relationships. Consequently, our inability to\ndescribe these relationships has led to LSTMs being characterized as black\nboxes. To this end, we introduce contextual decomposition (CD), an\ninterpretation algorithm for analysing individual predictions made by standard\nLSTMs, without any changes to the underlying model. By decomposing the output\nof a LSTM, CD captures the contributions of combinations of words or variables\nto the final prediction of an LSTM. On the task of sentiment analysis with the\nYelp and SST data sets, we show that CD is able to reliably identify words and\nphrases of contrasting sentiment, and how they are combined to yield the LSTM's\nfinal prediction. Using the phrase-level labels in SST, we also demonstrate\nthat CD is able to successfully extract positive and negative negations from an\nLSTM, something which has not previously been done. \n\n"}
{"id": "1801.06176", "contents": "Title: Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy\n  Learning Abstract: Training a task-completion dialogue agent via reinforcement learning (RL) is\ncostly because it requires many interactions with real users. One common\nalternative is to use a user simulator. However, a user simulator usually lacks\nthe language complexity of human interlocutors and the biases in its design may\ntend to degrade the agent. To address these issues, we present Deep Dyna-Q,\nwhich to our knowledge is the first deep RL framework that integrates planning\nfor task-completion dialogue policy learning. We incorporate into the dialogue\nagent a model of the environment, referred to as the world model, to mimic real\nuser response and generate simulated experience. During dialogue policy\nlearning, the world model is constantly updated with real user experience to\napproach real user behavior, and in turn, the dialogue agent is optimized using\nboth real experience and simulated experience. The effectiveness of our\napproach is demonstrated on a movie-ticket booking task in both simulated and\nhuman-in-the-loop settings. \n\n"}
{"id": "1801.06287", "contents": "Title: What Does a TextCNN Learn? Abstract: TextCNN, the convolutional neural network for text, is a useful deep learning\nalgorithm for sentence classification tasks such as sentiment analysis and\nquestion classification. However, neural networks have long been known as black\nboxes because interpreting them is a challenging task. Researchers have\ndeveloped several tools to understand a CNN for image classification by deep\nvisualization, but research about deep TextCNNs is still insufficient. In this\npaper, we are trying to understand what a TextCNN learns on two classical NLP\ndatasets. Our work focuses on functions of different convolutional kernels and\ncorrelations between convolutional kernels. \n\n"}
{"id": "1801.06700", "contents": "Title: A Deep Reinforcement Learning Chatbot (Short Version) Abstract: We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including neural network and\ntemplate-based models. By applying reinforcement learning to crowdsourced data\nand real-world user interactions, the system has been trained to select an\nappropriate response from the models in its ensemble. The system has been\nevaluated through A/B testing with real-world users, where it performed\nsignificantly better than other systems. The results highlight the potential of\ncoupling ensemble systems with deep reinforcement learning as a fruitful path\nfor developing real-world, open-domain conversational agents. \n\n"}
{"id": "1801.06807", "contents": "Title: Embedding Learning Through Multilingual Concept Induction Abstract: We present a new method for estimating vector space representations of words:\nembedding learning by concept induction. We test this method on a highly\nparallel corpus and learn semantic representations of words in 1259 different\nlanguages in a single common space. An extensive experimental evaluation on\ncrosslingual word similarity and sentiment analysis indicates that\nconcept-based multilingual embedding learning performs better than previous\napproaches. \n\n"}
{"id": "1801.07779", "contents": "Title: The WiLI benchmark dataset for written language identification Abstract: This paper describes the WiLI-2018 benchmark dataset for monolingual written\nnatural language identification. WiLI-2018 is a publicly available, free of\ncharge dataset of short text extracts from Wikipedia. It contains 1000\nparagraphs of 235 languages, totaling in 23500 paragraphs. WiLI is a\nclassification dataset: Given an unknown paragraph written in one dominant\nlanguage, it has to be decided which language it is. \n\n"}
{"id": "1801.08186", "contents": "Title: MAttNet: Modular Attention Network for Referring Expression\n  Comprehension Abstract: In this paper, we address referring expression comprehension: localizing an\nimage region described by a natural language expression. While most recent work\ntreats expressions as a single unit, we propose to decompose them into three\nmodular components related to subject appearance, location, and relationship to\nother objects. This allows us to flexibly adapt to expressions containing\ndifferent types of information in an end-to-end framework. In our model, which\nwe call the Modular Attention Network (MAttNet), two types of attention are\nutilized: language-based attention that learns the module weights as well as\nthe word/phrase attention that each module should focus on; and visual\nattention that allows the subject and relationship modules to focus on relevant\nimage components. Module weights combine scores from all three modules\ndynamically to output an overall score. Experiments show that MAttNet\noutperforms previous state-of-art methods by a large margin on both\nbounding-box-level and pixel-level comprehension tasks. Demo and code are\nprovided. \n\n"}
{"id": "1801.09536", "contents": "Title: A Survey of Word Embeddings Evaluation Methods Abstract: Word embeddings are real-valued word representations able to capture lexical\nsemantics and trained on natural language corpora. Models proposing these\nrepresentations have gained popularity in the recent years, but the issue of\nthe most adequate evaluation method still remains open. This paper presents an\nextensive overview of the field of word embeddings evaluation, highlighting\nmain problems and proposing a typology of approaches to evaluation, summarizing\n16 intrinsic methods and 12 extrinsic methods. I describe both widely-used and\nexperimental methods, systematize information about evaluation datasets and\ndiscuss some key challenges. \n\n"}
{"id": "1801.09746", "contents": "Title: A Corpus for Modeling Word Importance in Spoken Dialogue Transcripts Abstract: Motivated by a project to create a system for people who are deaf or\nhard-of-hearing that would use automatic speech recognition (ASR) to produce\nreal-time text captions of spoken English during in-person meetings with\nhearing individuals, we have augmented a transcript of the Switchboard\nconversational dialogue corpus with an overlay of word-importance annotations,\nwith a numeric score for each word, to indicate its importance to the meaning\nof each dialogue turn. Further, we demonstrate the utility of this corpus by\ntraining an automatic word importance labeling model; our best performing model\nhas an F-score of 0.60 in an ordinal 6-class word-importance classification\ntask with an agreement (concordance correlation coefficient) of 0.839 with the\nhuman annotators (agreement score between annotators is 0.89). Finally, we\ndiscuss our intended future applications of this resource, particularly for the\ntask of evaluating ASR performance, i.e. creating metrics that predict\nASR-output caption text usability for DHH users better thanWord Error Rate\n(WER). \n\n"}
{"id": "1801.09866", "contents": "Title: Accelerating recurrent neural network language model based online speech\n  recognition system Abstract: This paper presents methods to accelerate recurrent neural network based\nlanguage models (RNNLMs) for online speech recognition systems. Firstly, a\nlossy compression of the past hidden layer outputs (history vector) with\ncaching is introduced in order to reduce the number of LM queries. Next, RNNLM\ncomputations are deployed in a CPU-GPU hybrid manner, which computes each layer\nof the model on a more advantageous platform. The added overhead by data\nexchanges between CPU and GPU is compensated through a frame-wise batching\nstrategy. The performance of the proposed methods evaluated on LibriSpeech test\nsets indicates that the reduction in history vector precision improves the\naverage recognition speed by 1.23 times with minimum degradation in accuracy.\nOn the other hand, the CPU-GPU hybrid parallelization enables RNNLM based\nreal-time recognition with a four times improvement in speed. \n\n"}
{"id": "1801.10293", "contents": "Title: Paraphrase-Supervised Models of Compositionality Abstract: Compositional vector space models of meaning promise new solutions to\nstubborn language understanding problems. This paper makes two contributions\ntoward this end: (i) it uses automatically-extracted paraphrase examples as a\nsource of supervision for training compositional models, replacing previous\nwork which relied on manual annotations used for the same purpose, and (ii)\ndevelops a context-aware model for scoring phrasal compositionality.\nExperimental results indicate that these multiple sources of information can be\nused to learn partial semantic supervision that matches previous techniques in\nintrinsic evaluation tasks. Our approaches are also evaluated for their impact\non a machine translation system where we show improvements in translation\nquality, demonstrating that compositionality in interpretation correlates with\ncompositionality in translation. \n\n"}
{"id": "1802.00889", "contents": "Title: Densely Connected Bidirectional LSTM with Applications to Sentence\n  Classification Abstract: Deep neural networks have recently been shown to achieve highly competitive\nperformance in many computer vision tasks due to their abilities of exploring\nin a much larger hypothesis space. However, since most deep architectures like\nstacked RNNs tend to suffer from the vanishing-gradient and overfitting\nproblems, their effects are still understudied in many NLP tasks. Inspired by\nthis, we propose a novel multi-layer RNN model called densely connected\nbidirectional long short-term memory (DC-Bi-LSTM) in this paper, which\nessentially represents each layer by the concatenation of its hidden state and\nall preceding layers' hidden states, followed by recursively passing each\nlayer's representation to all subsequent layers. We evaluate our proposed model\non five benchmark datasets of sentence classification. DC-Bi-LSTM with depth up\nto 20 can be successfully trained and obtain significant improvements over the\ntraditional Bi-LSTM with the same or even less parameters. Moreover, our model\nhas promising performance compared with the state-of-the-art approaches. \n\n"}
{"id": "1802.02607", "contents": "Title: Learning from Past Mistakes: Improving Automatic Speech Recognition\n  Output via Noisy-Clean Phrase Context Modeling Abstract: Automatic speech recognition (ASR) systems often make unrecoverable errors\ndue to subsystem pruning (acoustic, language and pronunciation models); for\nexample pruning words due to acoustics using short-term context, prior to\nrescoring with long-term context based on linguistics. In this work we model\nASR as a phrase-based noisy transformation channel and propose an error\ncorrection system that can learn from the aggregate errors of all the\nindependent modules constituting the ASR and attempt to invert those. The\nproposed system can exploit long-term context using a neural network language\nmodel and can better choose between existing ASR output possibilities as well\nas re-introduce previously pruned or unseen (out-of-vocabulary) phrases. It\nprovides corrections under poorly performing ASR conditions without degrading\nany accurate transcriptions; such corrections are greater on top of\nout-of-domain and mismatched data ASR. Our system consistently provides\nimprovements over the baseline ASR, even when baseline is further optimized\nthrough recurrent neural network language model rescoring. This demonstrates\nthat any ASR improvements can be exploited independently and that our proposed\nsystem can potentially still provide benefits on highly optimized ASR. Finally,\nwe present an extensive analysis of the type of errors corrected by our system. \n\n"}
{"id": "1802.03268", "contents": "Title: Efficient Neural Architecture Search via Parameter Sharing Abstract: We propose Efficient Neural Architecture Search (ENAS), a fast and\ninexpensive approach for automatic model design. In ENAS, a controller learns\nto discover neural network architectures by searching for an optimal subgraph\nwithin a large computational graph. The controller is trained with policy\ngradient to select a subgraph that maximizes the expected reward on the\nvalidation set. Meanwhile the model corresponding to the selected subgraph is\ntrained to minimize a canonical cross entropy loss. Thanks to parameter sharing\nbetween child models, ENAS is fast: it delivers strong empirical performances\nusing much fewer GPU-hours than all existing automatic model design approaches,\nand notably, 1000x less expensive than standard Neural Architecture Search. On\nthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves a\ntest perplexity of 55.8, establishing a new state-of-the-art among all methods\nwithout post-training processing. On the CIFAR-10 dataset, ENAS designs novel\narchitectures that achieve a test error of 2.89%, which is on par with NASNet\n(Zoph et al., 2018), whose test error is 2.65%. \n\n"}
{"id": "1802.03594", "contents": "Title: Online Learning for Effort Reduction in Interactive Neural Machine\n  Translation Abstract: Neural machine translation systems require large amounts of training data and\nresources. Even with this, the quality of the translations may be insufficient\nfor some users or domains. In such cases, the output of the system must be\nrevised by a human agent. This can be done in a post-editing stage or following\nan interactive machine translation protocol.\n  We explore the incremental update of neural machine translation systems\nduring the post-editing or interactive translation processes. Such\nmodifications aim to incorporate the new knowledge, from the edited sentences,\ninto the translation system. Updates to the model are performed on-the-fly, as\nsentences are corrected, via online learning techniques. In addition, we\nimplement a novel interactive, adaptive system, able to react to\nsingle-character interactions. This system greatly reduces the human effort\nrequired for obtaining high-quality translations.\n  In order to stress our proposals, we conduct exhaustive experiments varying\nthe amount and type of data available for training. Results show that online\nlearning effectively achieves the objective of reducing the human effort\nrequired during the post-editing or the interactive machine translation stages.\nMoreover, these adaptive systems also perform well in scenarios with scarce\nresources. We show that a neural machine translation system can be rapidly\nadapted to a specific domain, exclusively by means of online learning\ntechniques. \n\n"}
{"id": "1802.03881", "contents": "Title: Answerer in Questioner's Mind: Information Theoretic Approach to\n  Goal-Oriented Visual Dialog Abstract: Goal-oriented dialog has been given attention due to its numerous\napplications in artificial intelligence. Goal-oriented dialogue tasks occur\nwhen a questioner asks an action-oriented question and an answerer responds\nwith the intent of letting the questioner know a correct action to take. To ask\nthe adequate question, deep learning and reinforcement learning have been\nrecently applied. However, these approaches struggle to find a competent\nrecurrent neural questioner, owing to the complexity of learning a series of\nsentences. Motivated by theory of mind, we propose \"Answerer in Questioner's\nMind\" (AQM), a novel information theoretic algorithm for goal-oriented dialog.\nWith AQM, a questioner asks and infers based on an approximated probabilistic\nmodel of the answerer. The questioner figures out the answerer's intention via\nselecting a plausible question by explicitly calculating the information gain\nof the candidate intentions and possible answers to each question. We test our\nframework on two goal-oriented visual dialog tasks: \"MNIST Counting Dialog\" and\n\"GuessWhat?!\". In our experiments, AQM outperforms comparative algorithms by a\nlarge margin. \n\n"}
{"id": "1802.04223", "contents": "Title: SparseMAP: Differentiable Sparse Structured Inference Abstract: Structured prediction requires searching over a combinatorial number of\nstructures. To tackle it, we introduce SparseMAP: a new method for sparse\nstructured inference, and its natural loss function. SparseMAP automatically\nselects only a few global structures: it is situated between MAP inference,\nwhich picks a single structure, and marginal inference, which assigns\nprobability mass to all structures, including implausible ones. Importantly,\nSparseMAP can be computed using only calls to a MAP oracle, making it\napplicable to problems with intractable marginal inference, e.g., linear\nassignment. Sparsity makes gradient backpropagation efficient regardless of the\nstructure, enabling us to augment deep neural networks with generic and sparse\nstructured hidden layers. Experiments in dependency parsing and natural\nlanguage inference reveal competitive accuracy, improved interpretability, and\nthe ability to capture natural language ambiguities, which is attractive for\npipeline systems. \n\n"}
{"id": "1802.04335", "contents": "Title: Neural Program Search: Solving Programming Tasks from Description and\n  Examples Abstract: We present a Neural Program Search, an algorithm to generate programs from\nnatural language description and a small number of input/output examples. The\nalgorithm combines methods from Deep Learning and Program Synthesis fields by\ndesigning rich domain-specific language (DSL) and defining efficient search\nalgorithm guided by a Seq2Tree model on it. To evaluate the quality of the\napproach we also present a semi-synthetic dataset of descriptions with test\nexamples and corresponding programs. We show that our algorithm significantly\noutperforms a sequence-to-sequence model with attention baseline. \n\n"}
{"id": "1802.04358", "contents": "Title: A Unified Implicit Dialog Framework for Conversational Search Abstract: We propose a unified Implicit Dialog framework for goal-oriented, information\nseeking tasks of Conversational Search applications. It aims to enable dialog\ninteractions with domain data without replying on explicitly encoded the rules\nbut utilizing the underlying data representation to build the components\nrequired for dialog interaction, which we refer as Implicit Dialog in this\nwork. The proposed framework consists of a pipeline of End-to-End trainable\nmodules. A centralized knowledge representation is used to semantically ground\nmultiple dialog modules. An associated set of tools are integrated with the\nframework to gather end users' input for continuous improvement of the system.\nThe goal is to facilitate development of conversational systems by identifying\nthe components and the data that can be adapted and reused across many end-user\napplications. We demonstrate our approach by creating conversational agents for\nseveral independent domains. \n\n"}
{"id": "1802.04394", "contents": "Title: M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search Abstract: Learning to walk over a graph towards a target node for a given query and a\nsource node is an important problem in applications such as knowledge base\ncompletion (KBC). It can be formulated as a reinforcement learning (RL) problem\nwith a known state transition model. To overcome the challenge of sparse\nrewards, we develop a graph-walking agent called M-Walk, which consists of a\ndeep recurrent neural network (RNN) and Monte Carlo Tree Search (MCTS). The RNN\nencodes the state (i.e., history of the walked path) and maps it separately to\na policy and Q-values. In order to effectively train the agent from sparse\nrewards, we combine MCTS with the neural policy to generate trajectories\nyielding more positive rewards. From these trajectories, the network is\nimproved in an off-policy manner using Q-learning, which modifies the RNN\npolicy via parameter sharing. Our proposed RL algorithm repeatedly applies this\npolicy-improvement step to learn the model. At test time, MCTS is combined with\nthe neural policy to predict the target node. Experimental results on several\ngraph-walking benchmarks show that M-Walk is able to learn better policies than\nother RL-based methods, which are mainly based on policy gradients. M-Walk also\noutperforms traditional KBC baselines. \n\n"}
{"id": "1802.04675", "contents": "Title: Attention based Sentence Extraction from Scientific Articles using\n  Pseudo-Labeled data Abstract: In this work, we present a weakly supervised sentence extraction technique\nfor identifying important sentences in scientific papers that are worthy of\ninclusion in the abstract. We propose a new attention based deep learning\narchitecture that jointly learns to identify important content, as well as the\ncue phrases that are indicative of summary worthy sentences. We propose a new\ncontext embedding technique for determining the focus of a given paper using\ntopic models and use it jointly with an LSTM based sequence encoder to learn\nattention weights across the sentence words. We use a collection of articles\npublicly available through ACL anthology for our experiments. Our system\nachieves a performance that is better, in terms of several ROUGE metrics, as\ncompared to several state of art extractive techniques. It also generates more\ncoherent summaries and preserves the overall structure of the document. \n\n"}
{"id": "1802.05092", "contents": "Title: Linguistic unit discovery from multi-modal inputs in unwritten\n  languages: Summary of the \"Speaking Rosetta\" JSALT 2017 Workshop Abstract: We summarize the accomplishments of a multi-disciplinary workshop exploring\nthe computational and scientific issues surrounding the discovery of linguistic\nunits (subwords and words) in a language without orthography. We study the\nreplacement of orthographic transcriptions by images and/or translated text in\na well-resourced language to help unsupervised discovery from raw speech. \n\n"}
{"id": "1802.05365", "contents": "Title: Deep contextualized word representations Abstract: We introduce a new type of deep contextualized word representation that\nmodels both (1) complex characteristics of word use (e.g., syntax and\nsemantics), and (2) how these uses vary across linguistic contexts (i.e., to\nmodel polysemy). Our word vectors are learned functions of the internal states\nof a deep bidirectional language model (biLM), which is pre-trained on a large\ntext corpus. We show that these representations can be easily added to existing\nmodels and significantly improve the state of the art across six challenging\nNLP problems, including question answering, textual entailment and sentiment\nanalysis. We also present an analysis showing that exposing the deep internals\nof the pre-trained network is crucial, allowing downstream models to mix\ndifferent types of semi-supervision signals. \n\n"}
{"id": "1802.05368", "contents": "Title: Universal Neural Machine Translation for Extremely Low Resource\n  Languages Abstract: In this paper, we propose a new universal machine translation approach\nfocusing on languages with a limited amount of parallel data. Our proposed\napproach utilizes a transfer-learning approach to share lexical and sentence\nlevel representations across multiple source languages into one target\nlanguage. The lexical part is shared through a Universal Lexical Representation\nto support multilingual word-level sharing. The sentence-level sharing is\nrepresented by a model of experts from all source languages that share the\nsource encoders with all other languages. This enables the low-resource\nlanguage to utilize the lexical and sentence representations of the higher\nresource languages. Our approach is able to achieve 23 BLEU on Romanian-English\nWMT2016 using a tiny parallel corpus of 6k sentences, compared to the 18 BLEU\nof strong baseline system which uses multilingual training and\nback-translation. Furthermore, we show that the proposed approach can achieve\nalmost 20 BLEU on the same dataset through fine-tuning a pre-trained\nmulti-lingual system in a zero-shot setting. \n\n"}
{"id": "1802.05412", "contents": "Title: NtMalDetect: A Machine Learning Approach to Malware Detection Using\n  Native API System Calls Abstract: As computing systems become increasingly advanced and as users increasingly\nengage themselves in technology, security has never been a greater concern. In\nmalware detection, static analysis, the method of analyzing potentially\nmalicious files, has been the prominent approach. This approach, however,\nquickly falls short as malicious programs become more advanced and adopt the\ncapabilities of obfuscating its binaries to execute the same malicious\nfunctions, making static analysis extremely difficult for newer variants. The\napproach assessed in this paper is a novel dynamic malware analysis method,\nwhich may generalize better than static analysis to newer variants. Inspired by\nrecent successes in Natural Language Processing (NLP), widely used document\nclassification techniques were assessed in detecting malware by doing such\nanalysis on system calls, which contain useful information about the operation\nof a program as requests that the program makes of the kernel. Features\nconsidered are extracted from system call traces of benign and malicious\nprograms, and the task to classify these traces is treated as a binary document\nclassification task of system call traces. The system call traces were\nprocessed to remove the parameters to only leave the system call function\nnames. The features were grouped into various n-grams and weighted with Term\nFrequency-Inverse Document Frequency. This paper shows that Linear Support\nVector Machines (SVM) optimized by Stochastic Gradient Descent and the\ntraditional Coordinate Descent on the Wolfe Dual form of the SVM are effective\nin this approach, achieving a highest of 96% accuracy with 95% recall score.\nAdditional contributions include the identification of significant system call\nsequences that could be avenues for further research. \n\n"}
{"id": "1802.05630", "contents": "Title: CNN+LSTM Architecture for Speech Emotion Recognition with Data\n  Augmentation Abstract: In this work we design a neural network for recognizing emotions in speech,\nusing the IEMOCAP dataset. Following the latest advances in audio analysis, we\nuse an architecture involving both convolutional layers, for extracting\nhigh-level features from raw spectrograms, and recurrent ones for aggregating\nlong-term dependencies. We examine the techniques of data augmentation with\nvocal track length perturbation, layer-wise optimizer adjustment, batch\nnormalization of recurrent layers and obtain highly competitive results of\n64.5% for weighted accuracy and 61.7% for unweighted accuracy on four emotions. \n\n"}
{"id": "1802.05672", "contents": "Title: Event Nugget Detection with Forward-Backward Recurrent Neural Networks Abstract: Traditional event detection methods heavily rely on manually engineered rich\nfeatures. Recent deep learning approaches alleviate this problem by automatic\nfeature engineering. But such efforts, like tradition methods, have so far only\nfocused on single-token event mentions, whereas in practice events can also be\na phrase. We instead use forward-backward recurrent neural networks (FBRNNs) to\ndetect events that can be either words or phrases. To the best our knowledge,\nthis is one of the first efforts to handle multi-word events and also the first\nattempt to use RNNs for event detection. Experimental results demonstrate that\nFBRNN is competitive with the state-of-the-art methods on the ACE 2005 and the\nRich ERE 2015 event detection tasks. \n\n"}
{"id": "1802.06041", "contents": "Title: Fluency Over Adequacy: A Pilot Study in Measuring User Trust in\n  Imperfect MT Abstract: Although measuring intrinsic quality has been a key factor in the advancement\nof Machine Translation (MT), successfully deploying MT requires considering not\njust intrinsic quality but also the user experience, including aspects such as\ntrust. This work introduces a method of studying how users modulate their trust\nin an MT system after seeing errorful (disfluent or inadequate) output amidst\ngood (fluent and adequate) output. We conduct a survey to determine how users\nrespond to good translations compared to translations that are either adequate\nbut not fluent, or fluent but not adequate. In this pilot study, users\nresponded strongly to disfluent translations, but were, surprisingly, much less\nconcerned with adequacy. \n\n"}
{"id": "1802.07170", "contents": "Title: CytonMT: an Efficient Neural Machine Translation Open-source Toolkit\n  Implemented in C++ Abstract: This paper presents an open-source neural machine translation toolkit named\nCytonMT (https://github.com/arthurxlw/cytonMt). The toolkit is built from\nscratch only using C++ and NVIDIA's GPU-accelerated libraries. The toolkit\nfeatures training efficiency, code simplicity and translation quality.\nBenchmarks show that CytonMT accelerates the training speed by 64.5% to 110.8%\non neural networks of various sizes, and achieves competitive translation\nquality. \n\n"}
{"id": "1802.08949", "contents": "Title: OhioState at SemEval-2018 Task 7: Exploiting Data Augmentation for\n  Relation Classification in Scientific Papers using Piecewise Convolutional\n  Neural Networks Abstract: We describe our system for SemEval-2018 Shared Task on Semantic Relation\nExtraction and Classification in Scientific Papers where we focus on the\nClassification task. Our simple piecewise convolution neural encoder performs\ndecently in an end to end manner. A simple inter-task data augmentation\nsignifi- cantly boosts the performance of the model. Our best-performing\nsystems stood 8th out of 20 teams on the classification task on noisy data and\n12th out of 28 teams on the classification task on clean data. \n\n"}
{"id": "1802.09091", "contents": "Title: Revisiting the poverty of the stimulus: hierarchical generalization\n  without a hierarchical bias in recurrent neural networks Abstract: Syntactic rules in natural language typically need to make reference to\nhierarchical sentence structure. However, the simple examples that language\nlearners receive are often equally compatible with linear rules. Children\nconsistently ignore these linear explanations and settle instead on the correct\nhierarchical one. This fact has motivated the proposal that the learner's\nhypothesis space is constrained to include only hierarchical rules. We examine\nthis proposal using recurrent neural networks (RNNs), which are not constrained\nin such a way. We simulate the acquisition of question formation, a\nhierarchical transformation, in a fragment of English. We find that some RNN\narchitectures tend to learn the hierarchical rule, suggesting that hierarchical\ncues within the language, combined with the implicit architectural biases\ninherent in certain RNNs, may be sufficient to induce hierarchical\ngeneralizations. The likelihood of acquiring the hierarchical generalization\nincreased when the language included an additional cue to hierarchy in the form\nof subject-verb agreement, underscoring the role of cues to hierarchy in the\nlearner's input. \n\n"}
{"id": "1802.09194", "contents": "Title: Deep Feed-forward Sequential Memory Networks for Speech Synthesis Abstract: The Bidirectional LSTM (BLSTM) RNN based speech synthesis system is among the\nbest parametric Text-to-Speech (TTS) systems in terms of the naturalness of\ngenerated speech, especially the naturalness in prosody. However, the model\ncomplexity and inference cost of BLSTM prevents its usage in many runtime\napplications. Meanwhile, Deep Feed-forward Sequential Memory Networks (DFSMN)\nhas shown its consistent out-performance over BLSTM in both word error rate\n(WER) and the runtime computation cost in speech recognition tasks. Since\nspeech synthesis also requires to model long-term dependencies compared to\nspeech recognition, in this paper, we investigate the Deep-FSMN (DFSMN) in\nspeech synthesis. Both objective and subjective experiments show that, compared\nwith BLSTM TTS method, the DFSMN system can generate synthesized speech with\ncomparable speech quality while drastically reduce model complexity and speech\ngeneration time. \n\n"}
{"id": "1802.09375", "contents": "Title: From Phonology to Syntax: Unsupervised Linguistic Typology at Different\n  Levels with Language Embeddings Abstract: A core part of linguistic typology is the classification of languages\naccording to linguistic properties, such as those detailed in the World Atlas\nof Language Structure (WALS). Doing this manually is prohibitively\ntime-consuming, which is in part evidenced by the fact that only 100 out of\nover 7,000 languages spoken in the world are fully covered in WALS.\n  We learn distributed language representations, which can be used to predict\ntypological properties on a massively multilingual scale. Additionally,\nquantitative and qualitative analyses of these language embeddings can tell us\nhow language similarities are encoded in NLP models for tasks at different\ntypological levels. The representations are learned in an unsupervised manner\nalongside tasks at three typological levels: phonology (grapheme-to-phoneme\nprediction, and phoneme reconstruction), morphology (morphological inflection),\nand syntax (part-of-speech tagging).\n  We consider more than 800 languages and find significant differences in the\nlanguage representations encoded, depending on the target task. For instance,\nalthough Norwegian Bokm{\\aa}l and Danish are typologically close to one\nanother, they are phonologically distant, which is reflected in their language\nembeddings growing relatively distant in a phonological task. We are also able\nto predict typological features in WALS with high accuracies, even for unseen\nlanguage families. \n\n"}
{"id": "1802.09416", "contents": "Title: A Quality Type-aware Annotated Corpus and Lexicon for Harassment\n  Research Abstract: Having a quality annotated corpus is essential especially for applied\nresearch. Despite the recent focus of Web science community on researching\nabout cyberbullying, the community dose not still have standard benchmarks. In\nthis paper, we publish first, a quality annotated corpus and second, an\noffensive words lexicon capturing different types type of harassment as (i)\nsexual harassment, (ii) racial harassment, (iii) appearance-related harassment,\n(iv) intellectual harassment, and (v) political harassment.We crawled data from\nTwitter using our offensive lexicon. Then relied on the human judge to annotate\nthe collected tweets w.r.t. the contextual types because using offensive words\nis not sufficient to reliably detect harassment. Our corpus consists of 25,000\nannotated tweets in five contextual types. We are pleased to share this novel\nannotated corpus and the lexicon with the research community. The instruction\nto acquire the corpus has been published on the Git repository. \n\n"}
{"id": "1802.09944", "contents": "Title: The Development of Darwin's Origin of Species Abstract: From 1837, when he returned to England aboard the $\\textit{HMS Beagle}$, to\n1860, just after publication of $\\textit{The Origin of Species}$, Charles\nDarwin kept detailed notes of each book he read or wanted to read. His notes\nand manuscripts provide information about decades of individual scientific\npractice. Previously, we trained topic models on the full texts of each\nreading, and applied information-theoretic measures to detect that changes in\nhis reading patterns coincided with the boundaries of his three major\nintellectual projects in the period 1837-1860. In this new work we apply the\nreading model to five additional documents, four of them by Darwin: the first\nedition of $\\textit{The Origin of Species}$, two private essays stating\nintermediate forms of his theory in 1842 and 1844, a third essay of disputed\ndating, and Alfred Russel Wallace's essay, which Darwin received in 1858. We\naddress three historical inquiries, previously treated qualitatively: 1) the\nmythology of \"Darwin's Delay,\" that despite completing an extensive draft in\n1844, Darwin waited until 1859 to publish $\\textit{The Origin of Species}$ due\nto external pressures; 2) the relationship between Darwin and Wallace's\ncontemporaneous theories, especially in light of their joint presentation; and\n3) dating of the \"Outline and Draft\" which was rediscovered in 1975 and\npostulated first as an 1839 draft preceding the Sketch of 1842, then as an\ninterstitial draft between the 1842 and 1844 essays. \n\n"}
{"id": "1802.09957", "contents": "Title: Convolutional Neural Networks for Toxic Comment Classification Abstract: Flood of information is produced in a daily basis through the global Internet\nusage arising from the on-line interactive communications among users. While\nthis situation contributes significantly to the quality of human life,\nunfortunately it involves enormous dangers, since on-line texts with high\ntoxicity can cause personal attacks, on-line harassment and bullying behaviors.\nThis has triggered both industrial and research community in the last few years\nwhile there are several tries to identify an efficient model for on-line toxic\ncomment prediction. However, these steps are still in their infancy and new\napproaches and frameworks are required. On parallel, the data explosion that\nappears constantly, makes the construction of new machine learning\ncomputational tools for managing this information, an imperative need.\nThankfully advances in hardware, cloud computing and big data management allow\nthe development of Deep Learning approaches appearing very promising\nperformance so far. For text classification in particular the use of\nConvolutional Neural Networks (CNN) have recently been proposed approaching\ntext analytics in a modern manner emphasizing in the structure of words in a\ndocument. In this work, we employ this approach to discover toxic comments in a\nlarge pool of documents provided by a current Kaggle's competition regarding\nWikipedia's talk page edits. To justify this decision we choose to compare CNNs\nagainst the traditional bag-of-words approach for text analysis combined with a\nselection of algorithms proven to be very effective in text classification. The\nreported results provide enough evidence that CNN enhance toxic comment\nclassification reinforcing research interest towards this direction. \n\n"}
{"id": "1803.00179", "contents": "Title: Matching Natural Language Sentences with Hierarchical Sentence\n  Factorization Abstract: Semantic matching of natural language sentences or identifying the\nrelationship between two sentences is a core research problem underlying many\nnatural language tasks. Depending on whether training data is available, prior\nresearch has proposed both unsupervised distance-based schemes and supervised\ndeep learning schemes for sentence matching. However, previous approaches\neither omit or fail to fully utilize the ordered, hierarchical, and flexible\nstructures of language objects, as well as the interactions between them. In\nthis paper, we propose Hierarchical Sentence Factorization---a technique to\nfactorize a sentence into a hierarchical representation, with the components at\neach different scale reordered into a \"predicate-argument\" form. The proposed\nsentence factorization technique leads to the invention of: 1) a new\nunsupervised distance metric which calculates the semantic distance between a\npair of text snippets by solving a penalized optimal transport problem while\npreserving the logical relationship of words in the reordered sentences, and 2)\nnew multi-scale deep learning models for supervised semantic training, based on\nfactorized sentence hierarchies. We apply our techniques to text-pair\nsimilarity estimation and text-pair relationship classification tasks, based on\nmultiple datasets such as STSbenchmark, the Microsoft Research paraphrase\nidentification (MSRP) dataset, the SICK dataset, etc. Extensive experiments\nshow that the proposed hierarchical sentence factorization can be used to\nsignificantly improve the performance of existing unsupervised distance-based\nmetrics as well as multiple supervised deep learning models based on the\nconvolutional neural network (CNN) and long short-term memory (LSTM). \n\n"}
{"id": "1803.00353", "contents": "Title: Joint Training for Neural Machine Translation Models with Monolingual\n  Data Abstract: Monolingual data have been demonstrated to be helpful in improving\ntranslation quality of both statistical machine translation (SMT) systems and\nneural machine translation (NMT) systems, especially in resource-poor or domain\nadaptation tasks where parallel data are not rich enough. In this paper, we\npropose a novel approach to better leveraging monolingual data for neural\nmachine translation by jointly learning source-to-target and target-to-source\nNMT models for a language pair with a joint EM optimization method. The\ntraining process starts with two initial NMT models pre-trained on parallel\ndata for each direction, and these two models are iteratively updated by\nincrementally decreasing translation losses on training data. In each iteration\nstep, both NMT models are first used to translate monolingual data from one\nlanguage to the other, forming pseudo-training data of the other NMT model.\nThen two new NMT models are learnt from parallel data together with the pseudo\ntraining data. Both NMT models are expected to be improved and better\npseudo-training data can be generated in next step. Experiment results on\nChinese-English and English-German translation tasks show that our approach can\nsimultaneously improve translation quality of source-to-target and\ntarget-to-source models, significantly outperforming strong baseline systems\nwhich are enhanced with monolingual data for model training including\nback-translation. \n\n"}
{"id": "1803.00832", "contents": "Title: Towards a Question Answering System over the Semantic Web Abstract: Thanks to the development of the Semantic Web, a lot of new structured data\nhas become available on the Web in the form of knowledge bases (KBs). Making\nthis valuable data accessible and usable for end-users is one of the main goals\nof Question Answering (QA) over KBs. Most current QA systems query one KB, in\none language (namely English). The existing approaches are not designed to be\neasily adaptable to new KBs and languages. We first introduce a new approach\nfor translating natural language questions to SPARQL queries. It is able to\nquery several KBs simultaneously, in different languages, and can easily be\nported to other KBs and languages. In our evaluation, the impact of our\napproach is proven using 5 different well-known and large KBs: Wikidata,\nDBpedia, MusicBrainz, DBLP and Freebase as well as 5 different languages namely\nEnglish, German, French, Italian and Spanish. Second, we show how we integrated\nour approach, to make it easily accessible by the research community and by\nend-users. To summarize, we provided a conceptional solution for multilingual,\nKB-agnostic Question Answering over the Semantic Web. The provided first\napproximation validates this concept. \n\n"}
{"id": "1803.01465", "contents": "Title: Query and Output: Generating Words by Querying Distributed Word\n  Representations for Paraphrase Generation Abstract: Most recent approaches use the sequence-to-sequence model for paraphrase\ngeneration. The existing sequence-to-sequence model tends to memorize the words\nand the patterns in the training dataset instead of learning the meaning of the\nwords. Therefore, the generated sentences are often grammatically correct but\nsemantically improper. In this work, we introduce a novel model based on the\nencoder-decoder framework, called Word Embedding Attention Network (WEAN). Our\nproposed model generates the words by querying distributed word representations\n(i.e. neural word embeddings), hoping to capturing the meaning of the according\nwords. Following previous work, we evaluate our model on two\nparaphrase-oriented tasks, namely text simplification and short text\nabstractive summarization. Experimental results show that our model outperforms\nthe sequence-to-sequence baseline by the BLEU score of 6.3 and 5.5 on two\nEnglish text simplification datasets, and the ROUGE-2 F1 score of 5.7 on a\nChinese summarization dataset. Moreover, our model achieves state-of-the-art\nperformances on these three benchmark datasets. \n\n"}
{"id": "1803.02238", "contents": "Title: Precise but Natural Specification for Robot Tasks Abstract: We present Flipper, a natural language interface for describing high-level\ntask specifications for robots that are compiled into robot actions. Flipper\nstarts with a formal core language for task planning that allows expressing\nrich temporal specifications and uses a semantic parser to provide a natural\nlanguage interface. Flipper provides immediate visual feedback by executing an\nautomatically constructed plan of the task in a graphical user interface. This\nallows the user to resolve potentially ambiguous interpretations. Flipper\nextends itself via naturalization: its users can add definitions for\nutterances, from which Flipper induces new rules and adds them to the core\nlanguage, gradually growing a more and more natural task specification\nlanguage. Flipper improves the naturalization by generalizing the definition\nprovided by users. Unlike other task-specification systems, Flipper enables\nnatural language interactions while maintaining the expressive power and formal\nprecision of a programming language. We show through an initial user study that\nnatural language interactions and generalization can considerably ease the\ndescription of tasks. Moreover, over time, users employ more and more concepts\noutside of the initial core language. Such extensions are available to the\nFlipper community, and users can use concepts that others have defined. \n\n"}
{"id": "1803.02279", "contents": "Title: An End-to-End Goal-Oriented Dialog System with a Generative Natural\n  Language Response Generation Abstract: Recently advancements in deep learning allowed the development of end-to-end\ntrained goal-oriented dialog systems. Although these systems already achieve\ngood performance, some simplifications limit their usage in real-life\nscenarios.\n  In this work, we address two of these limitations: ignoring positional\ninformation and a fixed number of possible response candidates. We propose to\nuse positional encodings in the input to model the word order of the user\nutterances. Furthermore, by using a feedforward neural network, we are able to\ngenerate the output word by word and are no longer restricted to a fixed number\nof possible response candidates. Using the positional encoding, we were able to\nachieve better accuracies in the Dialog bAbI Tasks and using the feedforward\nneural network for generating the response, we were able to save computation\ntime and space consumption. \n\n"}
{"id": "1803.02400", "contents": "Title: Natural Language to Structured Query Generation via Meta-Learning Abstract: In conventional supervised training, a model is trained to fit all the\ntraining examples. However, having a monolithic model may not always be the\nbest strategy, as examples could vary widely. In this work, we explore a\ndifferent learning protocol that treats each example as a unique pseudo-task,\nby reducing the original learning problem to a few-shot meta-learning scenario\nwith the help of a domain-dependent relevance function. When evaluated on the\nWikiSQL dataset, our approach leads to faster convergence and achieves\n1.1%-5.4% absolute accuracy gains over the non-meta-learning counterparts. \n\n"}
{"id": "1803.03370", "contents": "Title: Expert Finding in Heterogeneous Bibliographic Networks with\n  Locally-trained Embeddings Abstract: Expert finding is an important task in both industry and academia. It is\nchallenging to rank candidates with appropriate expertise for various queries.\nIn addition, different types of objects interact with one another, which\nnaturally forms heterogeneous information networks. We study the task of expert\nfinding in heterogeneous bibliographical networks based on two aspects: textual\ncontent analysis and authority ranking. Regarding the textual content analysis,\nwe propose a new method for query expansion via locally-trained embedding\nlearning with concept hierarchy as guidance, which is particularly tailored for\nspecific queries with narrow semantic meanings. Compared with global embedding\nlearning, locally-trained embedding learning projects the terms into a latent\nsemantic space constrained on relevant topics, therefore it preserves more\nprecise and subtle information for specific queries. Considering the candidate\nranking, the heterogeneous information network structure, while being largely\nignored in the previous studies of expert finding, provides additional\ninformation. Specifically, different types of interactions among objects play\ndifferent roles. We propose a ranking algorithm to estimate the authority of\nobjects in the network, treating each strongly-typed edge type individually. To\ndemonstrate the effectiveness of the proposed framework, we apply the proposed\nmethod to a large-scale bibliographical dataset with over two million entries\nand one million researcher candidates. The experiment results show that the\nproposed framework outperforms existing methods for both general and specific\nqueries. \n\n"}
{"id": "1803.03476", "contents": "Title: An Unsupervised Model with Attention Autoencoders for Question Retrieval Abstract: Question retrieval is a crucial subtask for community question answering.\nPrevious research focus on supervised models which depend heavily on training\ndata and manual feature engineering. In this paper, we propose a novel\nunsupervised framework, namely reduced attentive matching network (RAMN), to\ncompute semantic matching between two questions. Our RAMN integrates together\nthe deep semantic representations, the shallow lexical mismatching information\nand the initial rank produced by an external search engine. For the first time,\nwe propose attention autoencoders to generate semantic representations of\nquestions. In addition, we employ lexical mismatching to capture surface\nmatching between two questions, which is derived from the importance of each\nword in a question. We conduct experiments on the open CQA datasets of\nSemEval-2016 and SemEval-2017. The experimental results show that our\nunsupervised model obtains comparable performance with the state-of-the-art\nsupervised methods in SemEval-2016 Task 3, and outperforms the best system in\nSemEval-2017 Task 3 by a wide margin. \n\n"}
{"id": "1803.03585", "contents": "Title: The Importance of Being Recurrent for Modeling Hierarchical Structure Abstract: Recent work has shown that recurrent neural networks (RNNs) can implicitly\ncapture and exploit hierarchical information when trained to solve common\nnatural language processing tasks such as language modeling (Linzen et al.,\n2016) and neural machine translation (Shi et al., 2016). In contrast, the\nability to model structured data with non-recurrent neural networks has\nreceived little attention despite their success in many NLP tasks (Gehring et\nal., 2017; Vaswani et al., 2017). In this work, we compare the two\narchitectures---recurrent versus non-recurrent---with respect to their ability\nto model hierarchical structure and find that recurrency is indeed important\nfor this purpose. \n\n"}
{"id": "1803.03859", "contents": "Title: Language Identification of Bengali-English Code-Mixed data using\n  Character & Phonetic based LSTM Models Abstract: Language identification of social media text still remains a challenging task\ndue to properties like code-mixing and inconsistent phonetic transliterations.\nIn this paper, we present a supervised learning approach for language\nidentification at the word level of low resource Bengali-English code-mixed\ndata taken from social media. We employ two methods of word encoding, namely\ncharacter based and root phone based to train our deep LSTM models. Utilizing\nthese two models we created two ensemble models using stacking and threshold\ntechnique which gave 91.78% and 92.35% accuracies respectively on our testing\ndata. \n\n"}
{"id": "1803.04715", "contents": "Title: Hierarchical Learning of Cross-Language Mappings through Distributed\n  Vector Representations for Code Abstract: Translating a program written in one programming language to another can be\nuseful for software development tasks that need functionality implementations\nin different languages. Although past studies have considered this problem,\nthey may be either specific to the language grammars, or specific to certain\nkinds of code elements (e.g., tokens, phrases, API uses). This paper proposes a\nnew approach to automatically learn cross-language representations for various\nkinds of structural code elements that may be used for program translation. Our\nkey idea is two folded: First, we normalize and enrich code token streams with\nadditional structural and semantic information, and train cross-language vector\nrepresentations for the tokens (a.k.a. shared embeddings based on word2vec, a\nneural-network-based technique for producing word embeddings; Second,\nhierarchically from bottom up, we construct shared embeddings for code elements\nof higher levels of granularity (e.g., expressions, statements, methods) from\nthe embeddings for their constituents, and then build mappings among code\nelements across languages based on similarities among embeddings.\n  Our preliminary evaluations on about 40,000 Java and C# source files from 9\nsoftware projects show that our approach can automatically learn shared\nembeddings for various code elements in different languages and identify their\ncross-language mappings with reasonable Mean Average Precision scores. When\ncompared with an existing tool for mapping library API methods, our approach\nidentifies many more mappings accurately. The mapping results and code can be\naccessed at\nhttps://github.com/bdqnghi/hierarchical-programming-language-mapping. We\nbelieve that our idea for learning cross-language vector representations with\ncode structural information can be a useful step towards automated program\ntranslation. \n\n"}
{"id": "1803.04884", "contents": "Title: IDEL: In-Database Entity Linking with Neural Embeddings Abstract: We present a novel architecture, In-Database Entity Linking (IDEL), in which\nwe integrate the analytics-optimized RDBMS MonetDB with neural text mining\nabilities. Our system design abstracts core tasks of most neural entity linking\nsystems for MonetDB. To the best of our knowledge, this is the first defacto\nimplemented system integrating entity-linking in a database. We leverage the\nability of MonetDB to support in-database-analytics with user defined functions\n(UDFs) implemented in Python. These functions call machine learning libraries\nfor neural text mining, such as TensorFlow. The system achieves zero cost for\ndata shipping and transformation by utilizing MonetDB's ability to embed Python\nprocesses in the database kernel and exchange data in NumPy arrays. IDEL\nrepresents text and relational data in a joint vector space with neural\nembeddings and can compensate errors with ambiguous entity representations. For\ndetecting matching entities, we propose a novel similarity function based on\njoint neural embeddings which are learned via minimizing pairwise contrastive\nranking loss. This function utilizes a high dimensional index structures for\nfast retrieval of matching entities. Our first implementation and experiments\nusing the WebNLG corpus show the effectiveness and the potentials of IDEL. \n\n"}
{"id": "1803.05655", "contents": "Title: HFL-RC System at SemEval-2018 Task 11: Hybrid Multi-Aspects Model for\n  Commonsense Reading Comprehension Abstract: This paper describes the system which got the state-of-the-art results at\nSemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge. In\nthis paper, we present a neural network called Hybrid Multi-Aspects (HMA)\nmodel, which mimic the human's intuitions on dealing with the multiple-choice\nreading comprehension. In this model, we aim to produce the predictions in\nmultiple aspects by calculating attention among the text, question and choices,\nand combine these results for final predictions. Experimental results show that\nour HMA model could give substantial improvements over the baseline system and\ngot the first place on the final test set leaderboard with the accuracy of\n84.13%. \n\n"}
{"id": "1803.06397", "contents": "Title: Deep learning for affective computing: text-based emotion recognition in\n  decision support Abstract: Emotions widely affect human decision-making. This fact is taken into account\nby affective computing with the goal of tailoring decision support to the\nemotional states of individuals. However, the accurate recognition of emotions\nwithin narrative documents presents a challenging undertaking due to the\ncomplexity and ambiguity of language. Performance improvements can be achieved\nthrough deep learning; yet, as demonstrated in this paper, the specific nature\nof this task requires the customization of recurrent neural networks with\nregard to bidirectional processing, dropout layers as a means of\nregularization, and weighted loss functions. In addition, we propose\nsent2affect, a tailored form of transfer learning for affective computing: here\nthe network is pre-trained for a different task (i.e. sentiment analysis),\nwhile the output layer is subsequently tuned to the task of emotion\nrecognition. The resulting performance is evaluated in a holistic setting\nacross 6 benchmark datasets, where we find that both recurrent neural networks\nand transfer learning consistently outperform traditional machine learning.\nAltogether, the findings have considerable implications for the use of\naffective computing. \n\n"}
{"id": "1803.06581", "contents": "Title: Variational Knowledge Graph Reasoning Abstract: Inferring missing links in knowledge graphs (KG) has attracted a lot of\nattention from the research community. In this paper, we tackle a practical\nquery answering task involving predicting the relation of a given entity pair.\nWe frame this prediction problem as an inference problem in a probabilistic\ngraphical model and aim at resolving it from a variational inference\nperspective. In order to model the relation between the query entity pair, we\nassume that there exists an underlying latent variable (paths connecting two\nnodes) in the KG, which carries the equivalent semantics of their relations.\nHowever, due to the intractability of connections in large KGs, we propose to\nuse variation inference to maximize the evidence lower bound. More\nspecifically, our framework (\\textsc{Diva}) is composed of three modules, i.e.\na posterior approximator, a prior (path finder), and a likelihood (path\nreasoner). By using variational inference, we are able to incorporate them\nclosely into a unified architecture and jointly optimize them to perform KG\nreasoning. With active interactions among these sub-modules, \\textsc{Diva} is\nbetter at handling noise and coping with more complex reasoning scenarios. In\norder to evaluate our method, we conduct the experiment of the link prediction\ntask on multiple datasets and achieve state-of-the-art performances on both\ndatasets. \n\n"}
{"id": "1803.06805", "contents": "Title: Acoustic feature learning using cross-domain articulatory measurements Abstract: Previous work has shown that it is possible to improve speech recognition by\nlearning acoustic features from paired acoustic-articulatory data, for example\nby using canonical correlation analysis (CCA) or its deep extensions. One\nlimitation of this prior work is that the learned feature models are difficult\nto port to new datasets or domains, and articulatory data is not available for\nmost speech corpora. In this work we study the problem of acoustic feature\nlearning in the setting where we have access to an external, domain-mismatched\ndataset of paired speech and articulatory measurements, either with or without\nlabels. We develop methods for acoustic feature learning in these settings,\nbased on deep variational CCA and extensions that use both source and target\ndomain data and labels. Using this approach, we improve phonetic recognition\naccuracies on both TIMIT and Wall Street Journal and analyze a number of design\nchoices. \n\n"}
{"id": "1803.08035", "contents": "Title: Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs Abstract: We consider the problem of zero-shot recognition: learning a visual\nclassifier for a category with zero training examples, just using the word\nembedding of the category and its relationship to other categories, which\nvisual data are provided. The key to dealing with the unfamiliar or novel\ncategory is to transfer knowledge obtained from familiar classes to describe\nthe unfamiliar class. In this paper, we build upon the recently introduced\nGraph Convolutional Network (GCN) and propose an approach that uses both\nsemantic embeddings and the categorical relationships to predict the\nclassifiers. Given a learned knowledge graph (KG), our approach takes as input\nsemantic embeddings for each node (representing visual category). After a\nseries of graph convolutions, we predict the visual classifier for each\ncategory. During training, the visual classifiers for a few categories are\ngiven to learn the GCN parameters. At test time, these filters are used to\npredict the visual classifiers of unseen categories. We show that our approach\nis robust to noise in the KG. More importantly, our approach provides\nsignificant improvement in performance compared to the current state-of-the-art\nresults (from 2 ~ 3% on some metrics to whopping 20% on a few). \n\n"}
{"id": "1803.09017", "contents": "Title: Style Tokens: Unsupervised Style Modeling, Control and Transfer in\n  End-to-End Speech Synthesis Abstract: In this work, we propose \"global style tokens\" (GSTs), a bank of embeddings\nthat are jointly trained within Tacotron, a state-of-the-art end-to-end speech\nsynthesis system. The embeddings are trained with no explicit labels, yet learn\nto model a large range of acoustic expressiveness. GSTs lead to a rich set of\nsignificant results. The soft interpretable \"labels\" they generate can be used\nto control synthesis in novel ways, such as varying speed and speaking style -\nindependently of the text content. They can also be used for style transfer,\nreplicating the speaking style of a single audio clip across an entire\nlong-form text corpus. When trained on noisy, unlabeled found data, GSTs learn\nto factorize noise and speaker identity, providing a path towards highly\nscalable but robust speech synthesis. \n\n"}
{"id": "1803.09091", "contents": "Title: Simple Large-scale Relation Extraction from Unstructured Text Abstract: Knowledge-based question answering relies on the availability of facts, the\nmajority of which cannot be found in structured sources (e.g. Wikipedia\ninfo-boxes, Wikidata). One of the major components of extracting facts from\nunstructured text is Relation Extraction (RE). In this paper we propose a novel\nmethod for creating distant (weak) supervision labels for training a\nlarge-scale RE system. We also provide new evidence about the effectiveness of\nneural network approaches by decoupling the model architecture from the feature\ndesign of a state-of-the-art neural network system. Surprisingly, a much\nsimpler classifier trained on similar features performs on par with the highly\ncomplex neural network system (at 75x reduction to the training time),\nsuggesting that the features are a bigger contributor to the final performance. \n\n"}
{"id": "1803.09816", "contents": "Title: Spectral feature mapping with mimic loss for robust speech recognition Abstract: For the task of speech enhancement, local learning objectives are agnostic to\nphonetic structures helpful for speech recognition. We propose to add a global\ncriterion to ensure de-noised speech is useful for downstream tasks like ASR.\nWe first train a spectral classifier on clean speech to predict senone labels.\nThen, the spectral classifier is joined with our speech enhancer as a noisy\nspeech recognizer. This model is taught to imitate the output of the spectral\nclassifier alone on clean speech. This \\textit{mimic loss} is combined with the\ntraditional local criterion to train the speech enhancer to produce de-noised\nspeech. Feeding the de-noised speech to an off-the-shelf Kaldi training recipe\nfor the CHiME-2 corpus shows significant improvements in WER. \n\n"}
{"id": "1803.10357", "contents": "Title: Deep Communicating Agents for Abstractive Summarization Abstract: We present deep communicating agents in an encoder-decoder architecture to\naddress the challenges of representing a long document for abstractive\nsummarization. With deep communicating agents, the task of encoding a long text\nis divided across multiple collaborating agents, each in charge of a subsection\nof the input text. These encoders are connected to a single decoder, trained\nend-to-end using reinforcement learning to generate a focused and coherent\nsummary. Empirical results demonstrate that multiple communicating encoders\nlead to a higher quality summary compared to several strong baselines,\nincluding those based on a single encoder or multiple non-communicating\nencoders. \n\n"}
{"id": "1803.10952", "contents": "Title: Towards Unsupervised Automatic Speech Recognition Trained by Unaligned\n  Speech and Text only Abstract: Automatic speech recognition (ASR) has been widely researched with supervised\napproaches, while many low-resourced languages lack audio-text aligned data,\nand supervised methods cannot be applied on them.\n  In this work, we propose a framework to achieve unsupervised ASR on a read\nEnglish speech dataset, where audio and text are unaligned. In the first stage,\neach word-level audio segment in the utterances is represented by a vector\nrepresentation extracted by a sequence-of-sequence autoencoder, in which\nphonetic information and speaker information are disentangled.\n  Secondly, semantic embeddings of audio segments are trained from the vector\nrepresentations using a skip-gram model. Last but not the least, an\nunsupervised method is utilized to transform semantic embeddings of audio\nsegments to text embedding space, and finally the transformed embeddings are\nmapped to words.\n  With the above framework, we are towards unsupervised ASR trained by\nunaligned text and speech only. \n\n"}
{"id": "1803.11070", "contents": "Title: Actor-Critic based Training Framework for Abstractive Summarization Abstract: We present a training framework for neural abstractive summarization based on\nactor-critic approaches from reinforcement learning. In the traditional neural\nnetwork based methods, the objective is only to maximize the likelihood of the\npredicted summaries, no other assessment constraints are considered, which may\ngenerate low-quality summaries or even incorrect sentences. To alleviate this\nproblem, we employ an actor-critic framework to enhance the training procedure.\nFor the actor, we employ the typical attention based sequence-to-sequence\n(seq2seq) framework as the policy network for summary generation. For the\ncritic, we combine the maximum likelihood estimator with a well designed global\nsummary quality estimator which is a neural network based binary classifier\naiming to make the generated summaries indistinguishable from the human-written\nones. Policy gradient method is used to conduct the parameter learning. An\nalternating training strategy is proposed to conduct the joint training of the\nactor and critic models. Extensive experiments on some benchmark datasets in\ndifferent languages show that our framework achieves improvements over the\nstate-of-the-art methods. \n\n"}
{"id": "1803.11138", "contents": "Title: Colorless green recurrent networks dream hierarchically Abstract: Recurrent neural networks (RNNs) have achieved impressive results in a\nvariety of linguistic processing tasks, suggesting that they can induce\nnon-trivial properties of language. We investigate here to what extent RNNs\nlearn to track abstract hierarchical syntactic structure. We test whether RNNs\ntrained with a generic language modeling objective in four languages (Italian,\nEnglish, Hebrew, Russian) can predict long-distance number agreement in various\nconstructions. We include in our evaluation nonsensical sentences where RNNs\ncannot rely on semantic or lexical cues (\"The colorless green ideas I ate with\nthe chair sleep furiously\"), and, for Italian, we compare model performance to\nhuman intuitions. Our language-model-trained RNNs make reliable predictions\nabout long-distance agreement, and do not lag much behind human performance. We\nthus bring support to the hypothesis that RNNs are not just shallow-pattern\nextractors, but they also acquire deeper grammatical competence. \n\n"}
{"id": "1803.11506", "contents": "Title: Automatically augmenting an emotion dataset improves classification\n  using audio Abstract: In this work, we tackle a problem of speech emotion classification. One of\nthe issues in the area of affective computation is that the amount of annotated\ndata is very limited. On the other hand, the number of ways that the same\nemotion can be expressed verbally is enormous due to variability between\nspeakers. This is one of the factors that limits performance and\ngeneralization. We propose a simple method that extracts audio samples from\nmovies using textual sentiment analysis. As a result, it is possible to\nautomatically construct a larger dataset of audio samples with positive,\nnegative emotional and neutral speech. We show that pretraining recurrent\nneural network on such a dataset yields better results on the challenging\nEmotiW corpus. This experiment shows a potential benefit of combining textual\nsentiment analysis with vocal information. \n\n"}
{"id": "1804.00247", "contents": "Title: Training Tips for the Transformer Model Abstract: This article describes our experiments in neural machine translation using\nthe recent Tensor2Tensor framework and the Transformer sequence-to-sequence\nmodel (Vaswani et al., 2017). We examine some of the critical parameters that\naffect the final translation quality, memory usage, training stability and\ntraining time, concluding each experiment with a set of recommendations for\nfellow researchers. In addition to confirming the general mantra \"more data and\nlarger models\", we address scaling to multiple GPUs and provide practical tips\nfor improved training regarding batch size, learning rate, warmup steps,\nmaximum sentence length and checkpoint averaging. We hope that our observations\nwill allow others to get better results given their particular hardware and\ndata constraints. \n\n"}
{"id": "1804.00320", "contents": "Title: Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition\n  Errors on Listening Comprehension Abstract: Reading comprehension has been widely studied. One of the most representative\nreading comprehension tasks is Stanford Question Answering Dataset (SQuAD), on\nwhich machine is already comparable with human. On the other hand, accessing\nlarge collections of multimedia or spoken content is much more difficult and\ntime-consuming than plain text content for humans. It's therefore highly\nattractive to develop machines which can automatically understand spoken\ncontent. In this paper, we propose a new listening comprehension task - Spoken\nSQuAD. On the new task, we found that speech recognition errors have\ncatastrophic impact on machine comprehension, and several approaches are\nproposed to mitigate the impact. \n\n"}
{"id": "1804.01189", "contents": "Title: Real-Time Prediction of the Duration of Distribution System Outages Abstract: This paper addresses the problem of predicting duration of unplanned power\noutages, using historical outage records to train a series of neural network\npredictors. The initial duration prediction is made based on environmental\nfactors, and it is updated based on incoming field reports using natural\nlanguage processing to automatically analyze the text. Experiments using 15\nyears of outage records show good initial results and improved performance\nleveraging text. Case studies show that the language processing identifies\nphrases that point to outage causes and repair steps. \n\n"}
{"id": "1804.01768", "contents": "Title: Chinese-Portuguese Machine Translation: A Study on Building Parallel\n  Corpora from Comparable Texts Abstract: Although there are increasing and significant ties between China and\nPortuguese-speaking countries, there is not much parallel corpora in the\nChinese-Portuguese language pair. Both languages are very populous, with 1.2\nbillion native Chinese speakers and 279 million native Portuguese speakers, the\nlanguage pair, however, could be considered as low-resource in terms of\navailable parallel corpora. In this paper, we describe our methods to curate\nChinese-Portuguese parallel corpora and evaluate their quality. We extracted\nbilingual data from Macao government websites and proposed a hierarchical\nstrategy to build a large parallel corpus. Experiments are conducted on\nexisting and our corpora using both Phrased-Based Machine Translation (PBMT)\nand the state-of-the-art Neural Machine Translation (NMT) models. The results\nof this work can be used as a benchmark for future Chinese-Portuguese MT\nsystems. The approach we used in this paper also shows a good example on how to\nboost performance of MT systems for low-resource language pairs. \n\n"}
{"id": "1804.02341", "contents": "Title: Compositional Obverter Communication Learning From Raw Visual Input Abstract: One of the distinguishing aspects of human language is its compositionality,\nwhich allows us to describe complex environments with limited vocabulary.\nPreviously, it has been shown that neural network agents can learn to\ncommunicate in a highly structured, possibly compositional language based on\ndisentangled input (e.g. hand- engineered features). Humans, however, do not\nlearn to communicate based on well-summarized features. In this work, we train\nneural agents to simultaneously develop visual perception from raw image\npixels, and learn to communicate with a sequence of discrete symbols. The\nagents play an image description game where the image contains factors such as\ncolors and shapes. We train the agents using the obverter technique where an\nagent introspects to generate messages that maximize its own understanding.\nThrough qualitative analysis, visualization and a zero-shot test, we show that\nthe agents can develop, out of raw image pixels, a language with compositional\nproperties, given a proper pressure from the environment. \n\n"}
{"id": "1804.02617", "contents": "Title: Language Modeling with Generative Adversarial Networks Abstract: Generative Adversarial Networks (GANs) have been promising in the field of\nimage generation, however, they have been hard to train for language\ngeneration. GANs were originally designed to output differentiable values, so\ndiscrete language generation is challenging for them which causes high levels\nof instability in training GANs. Consequently, past work has resorted to\npre-training with maximum-likelihood or training GANs without pre-training with\na WGAN objective with a gradient penalty. In this study, we present a\ncomparison of those approaches. Furthermore, we present the results of some\nexperiments that indicate better training and convergence of Wasserstein GANs\n(WGANs) when a weaker regularization term is enforcing the Lipschitz\nconstraint. \n\n"}
{"id": "1804.03240", "contents": "Title: Deep Attention Model for Triage of Emergency Department Patients Abstract: Optimization of patient throughput and wait time in emergency departments\n(ED) is an important task for hospital systems. For that reason, Emergency\nSeverity Index (ESI) system for patient triage was introduced to help guide\nmanual estimation of acuity levels, which is used by nurses to rank the\npatients and organize hospital resources. However, despite improvements that it\nbrought to managing medical resources, such triage system greatly depends on\nnurse's subjective judgment and is thus prone to human errors. Here, we propose\na novel deep model based on the word attention mechanism designed for\npredicting a number of resources an ED patient would need. Our approach\nincorporates routinely available continuous and nominal (structured) data with\nmedical text (unstructured) data, including patient's chief complaint, past\nmedical history, medication list, and nurse assessment collected for 338,500 ED\nvisits over three years in a large urban hospital. Using both structured and\nunstructured data, the proposed approach achieves the AUC of $\\sim 88\\%$ for\nthe task of identifying resource intensive patients (binary classification),\nand the accuracy of $\\sim 44\\%$ for predicting exact category of number of\nresources (multi-class classification task), giving an estimated lift over\nnurses' performance by 16\\% in accuracy. Furthermore, the attention mechanism\nof the proposed model provides interpretability by assigning attention scores\nfor nurses' notes which is crucial for decision making and implementation of\nsuch approaches in the real systems working on human health. \n\n"}
{"id": "1804.03396", "contents": "Title: QA4IE: A Question Answering based Framework for Information Extraction Abstract: Information Extraction (IE) refers to automatically extracting structured\nrelation tuples from unstructured texts. Common IE solutions, including\nRelation Extraction (RE) and open IE systems, can hardly handle cross-sentence\ntuples, and are severely restricted by limited relation types as well as\ninformal relation specifications (e.g., free-text based relation tuples). In\norder to overcome these weaknesses, we propose a novel IE framework named\nQA4IE, which leverages the flexible question answering (QA) approaches to\nproduce high quality relation triples across sentences. Based on the framework,\nwe develop a large IE benchmark with high quality human evaluation. This\nbenchmark contains 293K documents, 2M golden relation triples, and 636 relation\ntypes. We compare our system with some IE baselines on our benchmark and the\nresults show that our system achieves great improvements. \n\n"}
{"id": "1804.03799", "contents": "Title: Achieving Fluency and Coherency in Task-oriented Dialog Abstract: We consider real world task-oriented dialog settings, where agents need to\ngenerate both fluent natural language responses and correct external actions\nlike database queries and updates. We demonstrate that, when applied to\ncustomer support chat transcripts, Sequence to Sequence (Seq2Seq) models often\ngenerate short, incoherent and ungrammatical natural language responses that\nare dominated by words that occur with high frequency in the training data.\nThese phenomena do not arise in synthetic datasets such as bAbI, where we show\nSeq2Seq models are nearly perfect. We develop techniques to learn embeddings\nthat succinctly capture relevant information from the dialog history, and\ndemonstrate that nearest neighbor based approaches in this learned neural\nembedding space generate more fluent responses. However, we see that these\nmethods are not able to accurately predict when to execute an external action.\nWe show how to combine nearest neighbor and Seq2Seq methods in a hybrid model,\nwhere nearest neighbor is used to generate fluent responses and Seq2Seq type\nmodels ensure dialog coherency and generate accurate external actions. We show\nthat this approach is well suited for customer support scenarios, where agents'\nresponses are typically script-driven, and correct external actions are\ncritically important. The hybrid model on the customer support data achieves a\n78% relative improvement in fluency scores, and a 130% improvement in accuracy\nof external calls. \n\n"}
{"id": "1804.03824", "contents": "Title: Reference-less Measure of Faithfulness for Grammatical Error Correction Abstract: We propose USim, a semantic measure for Grammatical Error Correction (GEC)\nthat measures the semantic faithfulness of the output to the source, thereby\ncomplementing existing reference-less measures (RLMs) for measuring the\noutput's grammaticality. USim operates by comparing the semantic symbolic\nstructure of the source and the correction, without relying on manually-curated\nreferences. Our experiments establish the validity of USim, by showing that (1)\nsemantic annotation can be consistently applied to ungrammatical text; (2)\nvalid corrections obtain a high USim similarity score to the source; and (3)\ninvalid corrections obtain a lower score. \n\n"}
{"id": "1804.04212", "contents": "Title: Word2Vec applied to Recommendation: Hyperparameters Matter Abstract: Skip-gram with negative sampling, a popular variant of Word2vec originally\ndesigned and tuned to create word embeddings for Natural Language Processing,\nhas been used to create item embeddings with successful applications in\nrecommendation. While these fields do not share the same type of data, neither\nevaluate on the same tasks, recommendation applications tend to use the same\nalready tuned hyperparameters values, even if optimal hyperparameters values\nare often known to be data and task dependent. We thus investigate the marginal\nimportance of each hyperparameter in a recommendation setting through large\nhyperparameter grid searches on various datasets. Results reveal that\noptimizing neglected hyperparameters, namely negative sampling distribution,\nnumber of epochs, subsampling parameter and window-size, significantly improves\nperformance on a recommendation task, and can increase it by an order of\nmagnitude. Importantly, we find that optimal hyperparameters configurations for\nNatural Language Processing tasks and Recommendation tasks are noticeably\ndifferent. \n\n"}
{"id": "1804.05253", "contents": "Title: \"With 1 follower I must be AWESOME :P\". Exploring the role of irony\n  markers in irony recognition Abstract: Conversations in social media often contain the use of irony or sarcasm, when\nthe users say the opposite of what they really mean. Irony markers are the\nmeta-communicative clues that inform the reader that an utterance is ironic. We\npropose a thorough analysis of theoretically grounded irony markers in two\nsocial media platforms: $Twitter$ and $Reddit$. Classification and frequency\nanalysis show that for $Twitter$, typographic markers such as emoticons and\nemojis are the most discriminative markers to recognize ironic utterances,\nwhile for $Reddit$ the morphological markers (e.g., interjections, tag\nquestions) are the most discriminative. \n\n"}
{"id": "1804.05374", "contents": "Title: Twin Regularization for online speech recognition Abstract: Online speech recognition is crucial for developing natural human-machine\ninterfaces. This modality, however, is significantly more challenging than\noff-line ASR, since real-time/low-latency constraints inevitably hinder the use\nof future information, that is known to be very helpful to perform robust\npredictions. A popular solution to mitigate this issue consists of feeding\nneural acoustic models with context windows that gather some future frames.\nThis introduces a latency which depends on the number of employed look-ahead\nfeatures. This paper explores a different approach, based on estimating the\nfuture rather than waiting for it. Our technique encourages the hidden\nrepresentations of a unidirectional recurrent network to embed some useful\ninformation about the future. Inspired by a recently proposed technique called\nTwin Networks, we add a regularization term that forces forward hidden states\nto be as close as possible to cotemporal backward ones, computed by a \"twin\"\nneural network running backwards in time. The experiments, conducted on a\nnumber of datasets, recurrent architectures, input features, and acoustic\nconditions, have shown the effectiveness of this approach. One important\nadvantage is that our method does not introduce any additional computation at\ntest time if compared to standard unidirectional recurrent networks. \n\n"}
{"id": "1804.05416", "contents": "Title: Are Automatic Methods for Cognate Detection Good Enough for Phylogenetic\n  Reconstruction in Historical Linguistics? Abstract: We evaluate the performance of state-of-the-art algorithms for automatic\ncognate detection by comparing how useful automatically inferred cognates are\nfor the task of phylogenetic inference compared to classical manually annotated\ncognate sets. Our findings suggest that phylogenies inferred from automated\ncognate sets come close to phylogenies inferred from expert-annotated ones,\nalthough on average, the latter are still superior. We conclude that future\nwork on phylogenetic reconstruction can profit much from automatic cognate\ndetection. Especially where scholars are merely interested in exploring the\nbigger picture of a language family's phylogeny, algorithms for automatic\ncognate detection are a useful complement for current research on language\nphylogenies. \n\n"}
{"id": "1804.05868", "contents": "Title: Universal Dependency Parsing for Hindi-English Code-switching Abstract: Code-switching is a phenomenon of mixing grammatical structures of two or\nmore languages under varied social constraints. The code-switching data differ\nso radically from the benchmark corpora used in NLP community that the\napplication of standard technologies to these data degrades their performance\nsharply. Unlike standard corpora, these data often need to go through\nadditional processes such as language identification, normalization and/or\nback-transliteration for their efficient processing. In this paper, we\ninvestigate these indispensable processes and other problems associated with\nsyntactic parsing of code-switching data and propose methods to mitigate their\neffects. In particular, we study dependency parsing of code-switching data of\nHindi and English multilingual speakers from Twitter. We present a treebank of\nHindi-English code-switching tweets under Universal Dependencies scheme and\npropose a neural stacking model for parsing that efficiently leverages\npart-of-speech tag and syntactic tree annotations in the code-switching\ntreebank and the preexisting Hindi and English treebanks. We also present\nnormalization and back-transliteration models with a decoding process tailored\nfor code-switching data. Results show that our neural stacking parser is 1.5%\nLAS points better than the augmented parsing model and our decoding process\nimproves results by 3.8% LAS points over the first-best normalization and/or\nback-transliteration. \n\n"}
{"id": "1804.05990", "contents": "Title: Learning Joint Semantic Parsers from Disjoint Data Abstract: We present a new approach to learning semantic parsers from multiple\ndatasets, even when the target semantic formalisms are drastically different,\nand the underlying corpora do not overlap. We handle such \"disjoint\" data by\ntreating annotations for unobserved formalisms as latent structured variables.\nBuilding on state-of-the-art baselines, we show improvements both in\nframe-semantic parsing and semantic dependency parsing by modeling them\njointly. \n\n"}
{"id": "1804.06137", "contents": "Title: SeerNet at SemEval-2018 Task 1: Domain Adaptation for Affect in Tweets Abstract: The paper describes the best performing system for the SemEval-2018 Affect in\nTweets (English) sub-tasks. The system focuses on the ordinal classification\nand regression sub-tasks for valence and emotion. For ordinal classification\nvalence is classified into 7 different classes ranging from -3 to 3 whereas\nemotion is classified into 4 different classes 0 to 3 separately for each\nemotion namely anger, fear, joy and sadness. The regression sub-tasks estimate\nthe intensity of valence and each emotion. The system performs domain\nadaptation of 4 different models and creates an ensemble to give the final\nprediction. The proposed system achieved 1st position out of 75 teams which\nparticipated in the fore-mentioned sub-tasks. We outperform the baseline model\nby margins ranging from 49.2% to 76.4%, thus, pushing the state-of-the-art\nsignificantly. \n\n"}
{"id": "1804.06437", "contents": "Title: Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style\n  Transfer Abstract: We consider the task of text attribute transfer: transforming a sentence to\nalter a specific attribute (e.g., sentiment) while preserving its\nattribute-independent content (e.g., changing \"screen is just the right size\"\nto \"screen is too small\"). Our training data includes only sentences labeled\nwith their attribute (e.g., positive or negative), but not pairs of sentences\nthat differ only in their attributes, so we must learn to disentangle\nattributes from attribute-independent content in an unsupervised way. Previous\nwork using adversarial methods has struggled to produce high-quality outputs.\nIn this paper, we propose simpler methods motivated by the observation that\ntext attributes are often marked by distinctive phrases (e.g., \"too small\").\nOur strongest method extracts content words by deleting phrases associated with\nthe sentence's original attribute value, retrieves new phrases associated with\nthe target attribute, and uses a neural model to fluently combine these into a\nfinal output. On human evaluation, our best method generates grammatical and\nappropriate responses on 22% more inputs than the best previous system,\naveraged over three attribute transfer datasets: altering sentiment of reviews\non Yelp, altering sentiment of reviews on Amazon, and altering image captions\nto be more romantic or humorous. \n\n"}
{"id": "1804.06451", "contents": "Title: Multi-Reward Reinforced Summarization with Saliency and Entailment Abstract: Abstractive text summarization is the task of compressing and rewriting a\nlong document into a short summary while maintaining saliency, directed logical\nentailment, and non-redundancy. In this work, we address these three important\naspects of a good summary via a reinforcement learning approach with two novel\nreward functions: ROUGESal and Entail, on top of a coverage-based baseline. The\nROUGESal reward modifies the ROUGE metric by up-weighting the salient\nphrases/words detected via a keyphrase classifier. The Entail reward gives high\n(length-normalized) scores to logically-entailed summaries using an entailment\nclassifier. Further, we show superior performance improvement when these\nrewards are combined with traditional metric (ROUGE) based rewards, via our\nnovel and effective multi-reward approach of optimizing multiple rewards\nsimultaneously in alternate mini-batches. Our method achieves the new\nstate-of-the-art results (including human evaluation) on the CNN/Daily Mail\ndataset as well as strong improvements in a test-only transfer setup on\nDUC-2002. \n\n"}
{"id": "1804.06610", "contents": "Title: End-to-end Graph-based TAG Parsing with Neural Networks Abstract: We present a graph-based Tree Adjoining Grammar (TAG) parser that uses\nBiLSTMs, highway connections, and character-level CNNs. Our best end-to-end\nparser, which jointly performs supertagging, POS tagging, and parsing,\noutperforms the previously reported best results by more than 2.2 LAS and UAS\npoints. The graph-based parsing architecture allows for global inference and\nrich feature representations for TAG parsing, alleviating the fundamental\ntrade-off between transition-based and graph-based parsing systems. We also\ndemonstrate that the proposed parser achieves state-of-the-art performance in\nthe downstream tasks of Parsing Evaluation using Textual Entailments (PETE) and\nUnbounded Dependency Recovery. This provides further support for the claim that\nTAG is a viable formalism for problems that require rich structural analysis of\nsentences. \n\n"}
{"id": "1804.06987", "contents": "Title: Improving Distantly Supervised Relation Extraction using Word and Entity\n  Based Attention Abstract: Relation extraction is the problem of classifying the relationship between\ntwo entities in a given sentence. Distant Supervision (DS) is a popular\ntechnique for developing relation extractors starting with limited supervision.\nWe note that most of the sentences in the distant supervision relation\nextraction setting are very long and may benefit from word attention for better\nsentence representation. Our contributions in this paper are threefold.\nFirstly, we propose two novel word attention models for distantly- supervised\nrelation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based\nword attention model (BGWA), (2) an entity-centric attention model (EA), and\n(3) a combination model which combines multiple complementary models using\nweighted voting method for improved relation extraction. Secondly, we introduce\nGDS, a new distant supervision dataset for relation extraction. GDS removes\ntest data noise present in all previous distant- supervision benchmark\ndatasets, making credible automatic evaluation possible. Thirdly, through\nextensive experiments on multiple real-world datasets, we demonstrate the\neffectiveness of the proposed methods. \n\n"}
{"id": "1804.07726", "contents": "Title: Phrase-Indexed Question Answering: A New Challenge for Scalable Document\n  Comprehension Abstract: We formalize a new modular variant of current question answering tasks by\nenforcing complete independence of the document encoder from the question\nencoder. This formulation addresses a key challenge in machine comprehension by\nrequiring a standalone representation of the document discourse. It\nadditionally leads to a significant scalability advantage since the encoding of\nthe answer candidate phrases in the document can be pre-computed and indexed\noffline for efficient retrieval. We experiment with baseline models for the new\ntask, which achieve a reasonable accuracy but significantly underperform\nunconstrained QA models. We invite the QA research community to engage in\nPhrase-Indexed Question Answering (PIQA, pika) for closing the gap. The\nleaderboard is at: nlp.cs.washington.edu/piqa \n\n"}
{"id": "1804.07781", "contents": "Title: Pathologies of Neural Models Make Interpretations Difficult Abstract: One way to interpret neural model predictions is to highlight the most\nimportant input features---for example, a heatmap visualization over the words\nin an input sentence. In existing interpretation methods for NLP, a word's\nimportance is determined by either input perturbation---measuring the decrease\nin model confidence when that word is removed---or by the gradient with respect\nto that word. To understand the limitations of these methods, we use input\nreduction, which iteratively removes the least important word from the input.\nThis exposes pathological behaviors of neural models: the remaining words\nappear nonsensical to humans and are not the ones determined as important by\ninterpretation methods. As we confirm with human experiments, the reduced\nexamples lack information to support the prediction of any label, but models\nstill make the same predictions with high confidence. To explain these\ncounterintuitive results, we draw connections to adversarial examples and\nconfidence calibration: pathological behaviors reveal difficulties in\ninterpreting neural models trained with maximum likelihood. To mitigate their\ndeficiencies, we fine-tune the models by encouraging high entropy outputs on\nreduced examples. Fine-tuned models become more interpretable under input\nreduction without accuracy loss on regular examples. \n\n"}
{"id": "1804.07915", "contents": "Title: A Stable and Effective Learning Strategy for Trainable Greedy Decoding Abstract: Beam search is a widely used approximate search strategy for neural network\ndecoders, and it generally outperforms simple greedy decoding on tasks like\nmachine translation. However, this improvement comes at substantial\ncomputational cost. In this paper, we propose a flexible new method that allows\nus to reap nearly the full benefits of beam search with nearly no additional\ncomputational cost. The method revolves around a small neural network actor\nthat is trained to observe and manipulate the hidden state of a\npreviously-trained decoder. To train this actor network, we introduce the use\nof a pseudo-parallel corpus built using the output of beam search on a base\nmodel, ranked by a target quality metric like BLEU. Our method is inspired by\nearlier work on this problem, but requires no reinforcement learning, and can\nbe trained reliably on a range of models. Experiments on three parallel corpora\nand three architectures show that the method yields substantial improvements in\ntranslation quality and speed over each base system. \n\n"}
{"id": "1804.07944", "contents": "Title: Variational Inference In Pachinko Allocation Machines Abstract: The Pachinko Allocation Machine (PAM) is a deep topic model that allows\nrepresenting rich correlation structures among topics by a directed acyclic\ngraph over topics. Because of the flexibility of the model, however,\napproximate inference is very difficult. Perhaps for this reason, only a small\nnumber of potential PAM architectures have been explored in the literature. In\nthis paper we present an efficient and flexible amortized variational inference\nmethod for PAM, using a deep inference network to parameterize the approximate\nposterior distribution in a manner similar to the variational autoencoder. Our\ninference method produces more coherent topics than state-of-art inference\nmethods for PAM while being an order of magnitude faster, which allows\nexploration of a wider range of PAM architectures than have previously been\nstudied. \n\n"}
{"id": "1804.07976", "contents": "Title: Neural-Davidsonian Semantic Proto-role Labeling Abstract: We present a model for semantic proto-role labeling (SPRL) using an adapted\nbidirectional LSTM encoding strategy that we call \"Neural-Davidsonian\":\npredicate-argument structure is represented as pairs of hidden states\ncorresponding to predicate and argument head tokens of the input sequence. We\ndemonstrate: (1) state-of-the-art results in SPRL, and (2) that our network\nnaturally shares parameters between attributes, allowing for learning new\nattribute types with limited added supervision. \n\n"}
{"id": "1804.08077", "contents": "Title: Inducing and Embedding Senses with Scaled Gumbel Softmax Abstract: Methods for learning word sense embeddings represent a single word with\nmultiple sense-specific vectors. These methods should not only produce\ninterpretable sense embeddings, but should also learn how to select which sense\nto use in a given context. We propose an unsupervised model that learns sense\nembeddings using a modified Gumbel softmax function, which allows for\ndifferentiable discrete sense selection. Our model produces sense embeddings\nthat are competitive (and sometimes state of the art) on multiple similarity\nbased downstream evaluations. However, performance on these downstream\nevaluations tasks does not correlate with interpretability of sense embeddings,\nas we discover through an interpretability comparison with competing\nmulti-sense embeddings. While many previous approaches perform well on\ndownstream evaluations, they do not produce interpretable embeddings and learn\nduplicated sense groups; our method achieves the best of both worlds. \n\n"}
{"id": "1804.08477", "contents": "Title: ASR Performance Prediction on Unseen Broadcast Programs using\n  Convolutional Neural Networks Abstract: In this paper, we address a relatively new task: prediction of ASR\nperformance on unseen broadcast programs. We first propose an heterogenous\nFrench corpus dedicated to this task. Two prediction approaches are compared: a\nstate-of-the-art performance prediction based on regression (engineered\nfeatures) and a new strategy based on convolutional neural networks (learnt\nfeatures). We particularly focus on the combination of both textual (ASR\ntranscription) and signal inputs. While the joint use of textual and signal\nfeatures did not work for the regression baseline, the combination of inputs\nfor CNNs leads to the best WER prediction performance. We also show that our\nCNN prediction remarkably predicts the WER distribution on a collection of\nspeech recordings. \n\n"}
{"id": "1804.08875", "contents": "Title: Data-driven Summarization of Scientific Articles Abstract: Data-driven approaches to sequence-to-sequence modelling have been\nsuccessfully applied to short text summarization of news articles. Such models\nare typically trained on input-summary pairs consisting of only a single or a\nfew sentences, partially due to limited availability of multi-sentence training\ndata. Here, we propose to use scientific articles as a new milestone for text\nsummarization: large-scale training data come almost for free with two types of\nhigh-quality summaries at different levels - the title and the abstract. We\ngenerate two novel multi-sentence summarization datasets from scientific\narticles and test the suitability of a wide range of existing extractive and\nabstractive neural network-based summarization approaches. Our analysis\ndemonstrates that scientific papers are suitable for data-driven text\nsummarization. Our results could serve as valuable benchmarks for scaling\nsequence-to-sequence models to very long sequences. \n\n"}
{"id": "1804.09769", "contents": "Title: TypeSQL: Knowledge-based Type-Aware Neural Text-to-SQL Generation Abstract: Interacting with relational databases through natural language helps users of\nany background easily query and analyze a vast amount of data. This requires a\nsystem that understands users' questions and converts them to SQL queries\nautomatically. In this paper we present a novel approach, TypeSQL, which views\nthis problem as a slot filling task. Additionally, TypeSQL utilizes type\ninformation to better understand rare entities and numbers in natural language\nquestions. We test this idea on the WikiSQL dataset and outperform the prior\nstate-of-the-art by 5.5% in much less time. We also show that accessing the\ncontent of databases can significantly improve the performance when users'\nqueries are not well-formed. TypeSQL gets 82.6% accuracy, a 17.5% absolute\nimprovement compared to the previous content-sensitive model. \n\n"}
{"id": "1804.09779", "contents": "Title: On the Evaluation of Semantic Phenomena in Neural Machine Translation\n  Using Natural Language Inference Abstract: We propose a process for investigating the extent to which sentence\nrepresentations arising from neural machine translation (NMT) systems encode\ndistinct semantic phenomena. We use these representations as features to train\na natural language inference (NLI) classifier based on datasets recast from\nexisting semantic annotations. In applying this process to a representative NMT\nsystem, we find its encoder appears most suited to supporting inferences at the\nsyntax-semantics interface, as compared to anaphora resolution requiring\nworld-knowledge. We conclude with a discussion on the merits and potential\ndeficiencies of the existing process, and how it may be improved and extended\nas a broader framework for evaluating semantic coverage. \n\n"}
{"id": "1804.10184", "contents": "Title: Lessons from the Bible on Modern Topics: Low-Resource Multilingual Topic\n  Model Evaluation Abstract: Multilingual topic models enable document analysis across languages through\ncoherent multilingual summaries of the data. However, there is no standard and\neffective metric to evaluate the quality of multilingual topics. We introduce a\nnew intrinsic evaluation of multilingual topic models that correlates well with\nhuman judgments of multilingual topic coherence as well as performance in\ndownstream applications. Importantly, we also study evaluation for low-resource\nlanguages. Because standard metrics fail to accurately measure topic quality\nwhen robust external resources are unavailable, we propose an adaptation model\nthat improves the accuracy and reliability of these metrics in low-resource\nsettings. \n\n"}
{"id": "1804.10413", "contents": "Title: Extracting Parallel Paragraphs from Common Crawl Abstract: Most of the current methods for mining parallel texts from the web assume\nthat web pages of web sites share same structure across languages. We believe\nthat there still exists a non-negligible amount of parallel data spread across\nsources not satisfying this assumption. We propose an approach based on a\ncombination of bivec (a bilingual extension of word2vec) and locality-sensitive\nhashing which allows us to efficiently identify pairs of parallel segments\nlocated anywhere on pages of a given web domain, regardless their structure. We\nvalidate our method on realigning segments from a large parallel corpus.\nAnother experiment with real-world data provided by Common Crawl Foundation\nconfirms that our solution scales to hundreds of terabytes large set of\nweb-crawled data. \n\n"}
{"id": "1804.10615", "contents": "Title: Improving Coverage and Runtime Complexity for Exact Inference in\n  Non-Projective Transition-Based Dependency Parsers Abstract: We generalize Cohen, G\\'omez-Rodr\\'iguez, and Satta's (2011) parser to a\nfamily of non-projective transition-based dependency parsers allowing\npolynomial-time exact inference. This includes novel parsers with better\ncoverage than Cohen et al. (2011), and even a variant that reduces time\ncomplexity to $O(n^6)$, improving over the known bounds in exact inference for\nnon-projective transition-based parsing. We hope that this piece of theoretical\nwork inspires design of novel transition systems with better coverage and\nbetter run-time guarantees.\n  Code available at https://github.com/tzshi/nonproj-dp-variants-naacl2018 \n\n"}
{"id": "1804.10752", "contents": "Title: Syllable-Based Sequence-to-Sequence Speech Recognition with the\n  Transformer in Mandarin Chinese Abstract: Sequence-to-sequence attention-based models have recently shown very\npromising results on automatic speech recognition (ASR) tasks, which integrate\nan acoustic, pronunciation and language model into a single neural network. In\nthese models, the Transformer, a new sequence-to-sequence attention-based model\nrelying entirely on self-attention without using RNNs or convolutions, achieves\na new single-model state-of-the-art BLEU on neural machine translation (NMT)\ntasks. Since the outstanding performance of the Transformer, we extend it to\nspeech and concentrate on it as the basic architecture of sequence-to-sequence\nattention-based model on Mandarin Chinese ASR tasks. Furthermore, we\ninvestigate a comparison between syllable based model and context-independent\nphoneme (CI-phoneme) based model with the Transformer in Mandarin Chinese.\nAdditionally, a greedy cascading decoder with the Transformer is proposed for\nmapping CI-phoneme sequences and syllable sequences into word sequences.\nExperiments on HKUST datasets demonstrate that syllable based model with the\nTransformer performs better than CI-phoneme based counterpart, and achieves a\ncharacter error rate (CER) of \\emph{$28.77\\%$}, which is competitive to the\nstate-of-the-art CER of $28.0\\%$ by the joint CTC-attention based\nencoder-decoder network. \n\n"}
{"id": "1804.11067", "contents": "Title: Staircase Network: structural language identification via hierarchical\n  attentive units Abstract: Language recognition system is typically trained directly to optimize\nclassification error on the target language labels, without using the external,\nor meta-information in the estimation of the model parameters. However labels\nare not independent of each other, there is a dependency enforced by, for\nexample, the language family, which affects negatively on classification. The\nother external information sources (e.g. audio encoding, telephony or video\nspeech) can also decrease classification accuracy. In this paper, we attempt to\nsolve these issues by constructing a deep hierarchical neural network, where\ndifferent levels of meta-information are encapsulated by attentive prediction\nunits and also embedded into the training progress. The proposed method learns\nauxiliary tasks to obtain robust internal representation and to construct a\nvariant of attentive units within the hierarchical model. The final result is\nthe structural prediction of the target language and a closely related language\nfamily. The algorithm reflects a \"staircase\" way of learning in both its\narchitecture and training, advancing from the fundamental audio encoding to the\nlanguage family level and finally to the target language level. This process\nnot only improves generalization but also tackles the issues of imbalanced\nclass priors and channel variability in the deep neural network model. Our\nexperimental findings show that the proposed architecture outperforms the\nstate-of-the-art i-vector approaches on both small and big language corpora by\na significant margin. \n\n"}
{"id": "1804.11225", "contents": "Title: Automatic Metric Validation for Grammatical Error Correction Abstract: Metric validation in Grammatical Error Correction (GEC) is currently done by\nobserving the correlation between human and metric-induced rankings. However,\nsuch correlation studies are costly, methodologically troublesome, and suffer\nfrom low inter-rater agreement. We propose MAEGE, an automatic methodology for\nGEC metric validation, that overcomes many of the difficulties with existing\npractices. Experiments with \\maege\\ shed a new light on metric quality, showing\nfor example that the standard $M^2$ metric fares poorly on corpus-level\nranking. Moreover, we use MAEGE to perform a detailed analysis of metric\nbehavior, showing that correcting some types of errors is consistently\npenalized by existing metrics. \n\n"}
{"id": "1805.00097", "contents": "Title: Syntactic Patterns Improve Information Extraction for Medical Search Abstract: Medical professionals search the published literature by specifying the type\nof patients, the medical intervention(s) and the outcome measure(s) of\ninterest. In this paper we demonstrate how features encoding syntactic patterns\nimprove the performance of state-of-the-art sequence tagging models (both\nlinear and neural) for information extraction of these medically relevant\ncategories. We present an analysis of the type of patterns exploited, and the\nsemantic space induced for these, i.e., the distributed representations learned\nfor identified multi-token patterns. We show that these learned representations\ndiffer substantially from those of the constituent unigrams, suggesting that\nthe patterns capture contextual information that is otherwise lost. \n\n"}
{"id": "1805.00195", "contents": "Title: An Annotated Corpus for Machine Reading of Instructions in Wet Lab\n  Protocols Abstract: We describe an effort to annotate a corpus of natural language instructions\nconsisting of 622 wet lab protocols to facilitate automatic or semi-automatic\nconversion of protocols into a machine-readable format and benefit biological\nresearch. Experimental results demonstrate the utility of our corpus for\ndeveloping machine learning approaches to shallow semantic parsing of\ninstructional texts. We make our annotated Wet Lab Protocol Corpus available to\nthe research community. \n\n"}
{"id": "1805.00314", "contents": "Title: Object Counts! Bringing Explicit Detections Back into Image Captioning Abstract: The use of explicit object detectors as an intermediate step to image\ncaptioning - which used to constitute an essential stage in early work - is\noften bypassed in the currently dominant end-to-end approaches, where the\nlanguage model is conditioned directly on a mid-level image embedding. We argue\nthat explicit detections provide rich semantic information, and can thus be\nused as an interpretable representation to better understand why end-to-end\nimage captioning systems work well. We provide an in-depth analysis of\nend-to-end image captioning by exploring a variety of cues that can be derived\nfrom such object detections. Our study reveals that end-to-end image captioning\nsystems rely on matching image representations to generate captions, and that\nencoding the frequency, size and position of objects are complementary and all\nplay a role in forming a good image representation. It also reveals that\ndifferent object categories contribute in different ways towards image\ncaptioning. \n\n"}
{"id": "1805.00456", "contents": "Title: Multi-representation Ensembles and Delayed SGD Updates Improve\n  Syntax-based NMT Abstract: We explore strategies for incorporating target syntax into Neural Machine\nTranslation. We specifically focus on syntax in ensembles containing multiple\nsentence representations. We formulate beam search over such ensembles using\nWFSTs, and describe a delayed SGD update training procedure that is especially\neffective for long representations like linearized syntax. Our approach gives\nstate-of-the-art performance on a difficult Japanese-English task. \n\n"}
{"id": "1805.00604", "contents": "Title: Text-Independent Speaker Verification Using Long Short-Term Memory\n  Networks Abstract: In this paper, an architecture based on Long Short-Term Memory Networks has\nbeen proposed for the text-independent scenario which is aimed to capture the\ntemporal speaker-related information by operating over traditional speech\nfeatures. For speaker verification, at first, a background model must be\ncreated for speaker representation. Then, in enrollment stage, the speaker\nmodels will be created based on the enrollment utterances. For this work, the\nmodel will be trained in an end-to-end fashion to combine the first two stages.\nThe main goal of end-to-end training is the model being optimized to be\nconsistent with the speaker verification protocol. The end- to-end training\njointly learns the background and speaker models by creating the representation\nspace. The LSTM architecture is trained to create a discrimination space for\nvalidating the match and non-match pairs for speaker verification. The proposed\narchitecture demonstrate its superiority in the text-independent compared to\nother traditional methods. \n\n"}
{"id": "1805.00631", "contents": "Title: Accelerating Neural Transformer via an Average Attention Network Abstract: With parallelizable attention networks, the neural Transformer is very fast\nto train. However, due to the auto-regressive architecture and self-attention\nin the decoder, the decoding procedure becomes slow. To alleviate this issue,\nwe propose an average attention network as an alternative to the self-attention\nnetwork in the decoder of the neural Transformer. The average attention network\nconsists of two layers, with an average layer that models dependencies on\nprevious positions and a gating layer that is stacked over the average layer to\nenhance the expressiveness of the proposed attention network. We apply this\nnetwork on the decoder part of the neural Transformer to replace the original\ntarget-side self-attention model. With masking tricks and dynamic programming,\nour model enables the neural Transformer to decode sentences over four times\nfaster than its original version with almost no loss in training time and\ntranslation performance. We conduct a series of experiments on WMT17\ntranslation tasks, where on 6 different language pairs, we obtain robust and\nconsistent speed-ups in decoding. \n\n"}
{"id": "1805.01042", "contents": "Title: Hypothesis Only Baselines in Natural Language Inference Abstract: We propose a hypothesis only baseline for diagnosing Natural Language\nInference (NLI). Especially when an NLI dataset assumes inference is occurring\nbased purely on the relationship between a context and a hypothesis, it follows\nthat assessing entailment relations while ignoring the provided context is a\ndegenerate solution. Yet, through experiments on ten distinct NLI datasets, we\nfind that this approach, which we refer to as a hypothesis-only model, is able\nto significantly outperform a majority class baseline across a number of NLI\ndatasets. Our analysis suggests that statistical irregularities may allow a\nmodel to perform NLI in some datasets beyond what should be achievable without\naccess to the context. \n\n"}
{"id": "1805.01089", "contents": "Title: A Hierarchical End-to-End Model for Jointly Improving Text Summarization\n  and Sentiment Classification Abstract: Text summarization and sentiment classification both aim to capture the main\nideas of the text but at different levels. Text summarization is to describe\nthe text within a few sentences, while sentiment classification can be regarded\nas a special type of summarization which \"summarizes\" the text into a even more\nabstract fashion, i.e., a sentiment class. Based on this idea, we propose a\nhierarchical end-to-end model for joint learning of text summarization and\nsentiment classification, where the sentiment classification label is treated\nas the further \"summarization\" of the text summarization output. Hence, the\nsentiment classification layer is put upon the text summarization layer, and a\nhierarchical structure is derived. Experimental results on Amazon online\nreviews datasets show that our model achieves better performance than the\nstrong baseline systems on both abstractive summarization and sentiment\nclassification. \n\n"}
{"id": "1805.01416", "contents": "Title: Dimensional emotion recognition using visual and textual cues Abstract: This paper addresses the problem of automatic emotion recognition in the\nscope of the One-Minute Gradual-Emotional Behavior challenge (OMG-Emotion\nchallenge). The underlying objective of the challenge is the automatic\nestimation of emotion expressions in the two-dimensional emotion representation\nspace (i.e., arousal and valence). The adopted methodology is a weighted\nensemble of several models from both video and text modalities. For video-based\nrecognition, two different types of visual cues (i.e., face and facial\nlandmarks) were considered to feed a multi-input deep neural network. Regarding\nthe text modality, a sequential model based on a simple recurrent architecture\nwas implemented. In addition, we also introduce a model based on high-level\nfeatures in order to embed domain knowledge in the learning process.\nExperimental results on the OMG-Emotion validation set demonstrate the\neffectiveness of the implemented ensemble model as it clearly outperforms the\ncurrent baseline methods. \n\n"}
{"id": "1805.01676", "contents": "Title: Upping the Ante: Towards a Better Benchmark for Chinese-to-English\n  Machine Translation Abstract: There are many machine translation (MT) papers that propose novel approaches\nand show improvements over their self-defined baselines. The experimental\nsetting in each paper often differs from one another. As such, it is hard to\ndetermine if a proposed approach is really useful and advances the state of the\nart. Chinese-to-English translation is a common translation direction in MT\npapers, although there is not one widely accepted experimental setting in\nChinese-to-English MT. Our goal in this paper is to propose a benchmark in\nevaluation setup for Chinese-to-English machine translation, such that the\neffectiveness of a new proposed MT approach can be directly compared to\nprevious approaches. Towards this end, we also built a highly competitive\nstate-of-the-art MT system trained on a large-scale training set. Our system\noutperforms reported results on NIST OpenMT test sets in almost all papers\npublished in major conferences and journals in computational linguistics and\nartificial intelligence in the past 11 years. We argue that a standardized\nbenchmark on data and performance is important for meaningful comparison. \n\n"}
{"id": "1805.02094", "contents": "Title: Exploring Hyper-Parameter Optimization for Neural Machine Translation on\n  GPU Architectures Abstract: Neural machine translation (NMT) has been accelerated by deep learning neural\nnetworks over statistical-based approaches, due to the plethora and\nprogrammability of commodity heterogeneous computing architectures such as\nFPGAs and GPUs and the massive amount of training corpuses generated from news\noutlets, government agencies and social media. Training a learning classifier\nfor neural networks entails tuning hyper-parameters that would yield the best\nperformance. Unfortunately, the number of parameters for machine translation\ninclude discrete categories as well as continuous options, which makes for a\ncombinatorial explosive problem. This research explores optimizing\nhyper-parameters when training deep learning neural networks for machine\ntranslation. Specifically, our work investigates training a language model with\nMarian NMT. Results compare NMT under various hyper-parameter settings across a\nvariety of modern GPU architecture generations in single node and multi-node\nsettings, revealing insights on which hyper-parameters matter most in terms of\nperformance, such as words processed per second, convergence rates, and\ntranslation accuracy, and provides insights on how to best achieve\nhigh-performing NMT systems. \n\n"}
{"id": "1805.02214", "contents": "Title: Zero-shot Sequence Labeling: Transferring Knowledge from Sentences to\n  Tokens Abstract: Can attention- or gradient-based visualization techniques be used to infer\ntoken-level labels for binary sequence tagging problems, using networks trained\nonly on sentence-level labels? We construct a neural network architecture based\non soft attention, train it as a binary sentence classifier and evaluate\nagainst token-level annotation on four different datasets. Inferring token\nlabels from a network provides a method for quantitatively evaluating what the\nmodel is learning, along with generating useful feedback in assistance systems.\nOur results indicate that attention-based methods are able to predict\ntoken-level labels more accurately, compared to gradient-based methods,\nsometimes even rivaling the supervised oracle network. \n\n"}
{"id": "1805.02473", "contents": "Title: A Graph-to-Sequence Model for AMR-to-Text Generation Abstract: The problem of AMR-to-text generation is to recover a text representing the\nsame meaning as an input AMR graph. The current state-of-the-art method uses a\nsequence-to-sequence model, leveraging LSTM for encoding a linearized AMR\nstructure. Although being able to model non-local semantic information, a\nsequence LSTM can lose information from the AMR graph structure, and thus faces\nchallenges with large graphs, which result in long sequences. We introduce a\nneural graph-to-sequence model, using a novel LSTM structure for directly\nencoding graph-level semantics. On a standard benchmark, our model shows\nsuperior results to existing methods in the literature. \n\n"}
{"id": "1805.03162", "contents": "Title: Polite Dialogue Generation Without Parallel Data Abstract: Stylistic dialogue response generation, with valuable applications in\npersonality-based conversational agents, is a challenging task because the\nresponse needs to be fluent, contextually-relevant, as well as\nparalinguistically accurate. Moreover, parallel datasets for\nregular-to-stylistic pairs are usually unavailable. We present three\nweakly-supervised models that can generate diverse polite (or rude) dialogue\nresponses without parallel data. Our late fusion model (Fusion) merges the\ndecoder of an encoder-attention-decoder dialogue model with a language model\ntrained on stand-alone polite utterances. Our label-fine-tuning (LFT) model\nprepends to each source sequence a politeness-score scaled label (predicted by\nour state-of-the-art politeness classifier) during training, and at test time\nis able to generate polite, neutral, and rude responses by simply scaling the\nlabel embedding by the corresponding score. Our reinforcement learning model\n(Polite-RL) encourages politeness generation by assigning rewards proportional\nto the politeness classifier score of the sampled response. We also present two\nretrieval-based polite dialogue model baselines. Human evaluation validates\nthat while the Fusion and the retrieval-based models achieve politeness with\npoorer context-relevance, the LFT and Polite-RL models can produce\nsignificantly more polite responses without sacrificing dialogue quality. \n\n"}
{"id": "1805.03294", "contents": "Title: Improved training of end-to-end attention models for speech recognition Abstract: Sequence-to-sequence attention-based models on subword units allow simple\nopen-vocabulary end-to-end speech recognition. In this work, we show that such\nmodels can achieve competitive results on the Switchboard 300h and LibriSpeech\n1000h tasks. In particular, we report the state-of-the-art word error rates\n(WER) of 3.54% on the dev-clean and 3.82% on the test-clean evaluation subsets\nof LibriSpeech. We introduce a new pretraining scheme by starting with a high\ntime reduction factor and lowering it during training, which is crucial both\nfor convergence and final performance. In some experiments, we also use an\nauxiliary CTC loss function to help the convergence. In addition, we train long\nshort-term memory (LSTM) language models on subword units. By shallow fusion,\nwe report up to 27% relative improvements in WER over the attention baseline\nwithout a language model. \n\n"}
{"id": "1805.03801", "contents": "Title: Learning Domain-Sensitive and Sentiment-Aware Word Embeddings Abstract: Word embeddings have been widely used in sentiment classification because of\ntheir efficacy for semantic representations of words. Given reviews from\ndifferent domains, some existing methods for word embeddings exploit sentiment\ninformation, but they cannot produce domain-sensitive embeddings. On the other\nhand, some other existing methods can generate domain-sensitive word\nembeddings, but they cannot distinguish words with similar contexts but\nopposite sentiment polarity. We propose a new method for learning\ndomain-sensitive and sentiment-aware embeddings that simultaneously capture the\ninformation of sentiment semantics and domain sensitivity of individual words.\nOur method can automatically determine and produce domain-common embeddings and\ndomain-specific embeddings. The differentiation of domain-common and\ndomain-specific words enables the advantage of data augmentation of common\nsemantics from multiple domains and capture the varied semantics of specific\nwords from different domains at the same time. Experimental results show that\nour model provides an effective way to learn domain-sensitive and\nsentiment-aware word embeddings which benefit sentiment classification at both\nsentence level and lexicon term level. \n\n"}
{"id": "1805.04032", "contents": "Title: From Word to Sense Embeddings: A Survey on Vector Representations of\n  Meaning Abstract: Over the past years, distributed semantic representations have proved to be\neffective and flexible keepers of prior knowledge to be integrated into\ndownstream applications. This survey focuses on the representation of meaning.\nWe start from the theoretical background behind word vector space models and\nhighlight one of their major limitations: the meaning conflation deficiency,\nwhich arises from representing a word with all its possible meanings as a\nsingle vector. Then, we explain how this deficiency can be addressed through a\ntransition from the word level to the more fine-grained level of word senses\n(in its broader acceptation) as a method for modelling unambiguous lexical\nmeaning. We present a comprehensive overview of the wide range of techniques in\nthe two main branches of sense representation, i.e., unsupervised and\nknowledge-based. Finally, this survey covers the main evaluation procedures and\napplications for this type of representation, and provides an analysis of four\nof its important aspects: interpretability, sense granularity, adaptability to\ndifferent domains and compositionality. \n\n"}
{"id": "1805.04174", "contents": "Title: Joint Embedding of Words and Labels for Text Classification Abstract: Word embeddings are effective intermediate representations for capturing\nsemantic regularities between words, when learning the representations of text\nsequences. We propose to view text classification as a label-word joint\nembedding problem: each label is embedded in the same space with the word\nvectors. We introduce an attention framework that measures the compatibility of\nembeddings between text sequences and labels. The attention is learned on a\ntraining set of labeled samples to ensure that, given a text sequence, the\nrelevant words are weighted higher than the irrelevant ones. Our method\nmaintains the interpretability of word embeddings, and enjoys a built-in\nability to leverage alternative sources of information, in addition to input\ntext sequences. Extensive results on the several large text datasets show that\nthe proposed framework outperforms the state-of-the-art methods by a large\nmargin, in terms of both accuracy and speed. \n\n"}
{"id": "1805.04264", "contents": "Title: State Gradients for RNN Memory Analysis Abstract: We present a framework for analyzing what the state in RNNs remembers from\nits input embeddings. Our approach is inspired by backpropagation, in the sense\nthat we compute the gradients of the states with respect to the input\nembeddings. The gradient matrix is decomposed with Singular Value Decomposition\nto analyze which directions in the embedding space are best transferred to the\nhidden state space, characterized by the largest singular values. We apply our\napproach to LSTM language models and investigate to what extent and for how\nlong certain classes of words are remembered on average for a certain corpus.\nAdditionally, the extent to which a specific property or relationship is\nremembered by the RNN can be tracked by comparing a vector characterizing that\nproperty with the direction(s) in embedding space that are best preserved in\nhidden state space. \n\n"}
{"id": "1805.04988", "contents": "Title: Word learning and the acquisition of syntactic--semantic overhypotheses Abstract: Children learning their first language face multiple problems of induction:\nhow to learn the meanings of words, and how to build meaningful phrases from\nthose words according to syntactic rules. We consider how children might solve\nthese problems efficiently by solving them jointly, via a computational model\nthat learns the syntax and semantics of multi-word utterances in a grounded\nreference game. We select a well-studied empirical case in which children are\naware of patterns linking the syntactic and semantic properties of words ---\nthat the properties picked out by base nouns tend to be related to shape, while\nprenominal adjectives tend to refer to other properties such as color. We show\nthat children applying such inductive biases are accurately reflecting the\nstatistics of child-directed speech, and that inducing similar biases in our\ncomputational model captures children's behavior in a classic adjective\nlearning experiment. Our model incorporating such biases also demonstrates a\nclear data efficiency in learning, relative to a baseline model that learns\nwithout forming syntax-sensitive overhypotheses of word meaning. Thus solving a\nmore complex joint inference problem may make the full problem of language\nacquisition easier, not harder. \n\n"}
{"id": "1805.05377", "contents": "Title: Large-Scale QA-SRL Parsing Abstract: We present a new large-scale corpus of Question-Answer driven Semantic Role\nLabeling (QA-SRL) annotations, and the first high-quality QA-SRL parser. Our\ncorpus, QA-SRL Bank 2.0, consists of over 250,000 question-answer pairs for\nover 64,000 sentences across 3 domains and was gathered with a new\ncrowd-sourcing scheme that we show has high precision and good recall at modest\ncost. We also present neural models for two QA-SRL subtasks: detecting argument\nspans for a predicate and generating questions to label the semantic\nrelationship. The best models achieve question accuracy of 82.6% and span-level\naccuracy of 77.6% (under human evaluation) on the full pipelined QA-SRL\nprediction task. They can also, as we show, be used to gather additional\nannotations at low cost. \n\n"}
{"id": "1805.05492", "contents": "Title: Did the Model Understand the Question? Abstract: We analyze state-of-the-art deep learning models for three tasks: question\nanswering on (1) images, (2) tables, and (3) passages of text. Using the notion\nof \\emph{attribution} (word importance), we find that these deep networks often\nignore important question terms. Leveraging such behavior, we perturb questions\nto craft a variety of adversarial examples. Our strongest attacks drop the\naccuracy of a visual question answering model from $61.1\\%$ to $19\\%$, and that\nof a tabular question answering model from $33.5\\%$ to $3.3\\%$. Additionally,\nwe show how attributions can strengthen attacks proposed by Jia and Liang\n(2017) on paragraph comprehension models. Our results demonstrate that\nattributions can augment standard measures of accuracy and empower\ninvestigation of model performance. When a model is accurate but for the wrong\nreasons, attributions can surface erroneous logic in the model that indicates\ninadequacies in the test data. \n\n"}
{"id": "1805.05542", "contents": "Title: A Manually Annotated Chinese Corpus for Non-task-oriented Dialogue\n  Systems Abstract: This paper presents a large-scale corpus for non-task-oriented dialogue\nresponse selection, which contains over 27K distinct prompts more than 82K\nresponses collected from social media. To annotate this corpus, we define a\n5-grade rating scheme: bad, mediocre, acceptable, good, and excellent,\naccording to the relevance, coherence, informativeness, interestingness, and\nthe potential to move a conversation forward. To test the validity and\nusefulness of the produced corpus, we compare various unsupervised and\nsupervised models for response selection. Experimental results confirm that the\nproposed corpus is helpful in training response selection models. \n\n"}
{"id": "1805.05942", "contents": "Title: Harvesting Paragraph-Level Question-Answer Pairs from Wikipedia Abstract: We study the task of generating from Wikipedia articles question-answer pairs\nthat cover content beyond a single sentence. We propose a neural network\napproach that incorporates coreference knowledge via a novel gating mechanism.\nCompared to models that only take into account sentence-level information\n(Heilman and Smith, 2010; Du et al., 2017; Zhou et al., 2017), we find that the\nlinguistic knowledge introduced by the coreference representation aids question\ngeneration significantly, producing models that outperform the current\nstate-of-the-art. We apply our system (composed of an answer span extraction\nsystem and the passage-level QG system) to the 10,000 top-ranking Wikipedia\narticles and create a corpus of over one million question-answer pairs. We also\nprovide a qualitative analysis for this large-scale generated corpus from\nWikipedia. \n\n"}
{"id": "1805.06150", "contents": "Title: FollowNet: Robot Navigation by Following Natural Language Directions\n  with Deep Reinforcement Learning Abstract: Understanding and following directions provided by humans can enable robots\nto navigate effectively in unknown situations. We present FollowNet, an\nend-to-end differentiable neural architecture for learning multi-modal\nnavigation policies. FollowNet maps natural language instructions as well as\nvisual and depth inputs to locomotion primitives. FollowNet processes\ninstructions using an attention mechanism conditioned on its visual and depth\ninput to focus on the relevant parts of the command while performing the\nnavigation task. Deep reinforcement learning (RL) a sparse reward learns\nsimultaneously the state representation, the attention function, and control\npolicies. We evaluate our agent on a dataset of complex natural language\ndirections that guide the agent through a rich and realistic dataset of\nsimulated homes. We show that the FollowNet agent learns to execute previously\nunseen instructions described with a similar vocabulary, and successfully\nnavigates along paths not encountered during training. The agent shows 30%\nimprovement over a baseline model without the attention mechanism, with 52%\nsuccess rate at novel instructions. \n\n"}
{"id": "1805.06533", "contents": "Title: Modeling Naive Psychology of Characters in Simple Commonsense Stories Abstract: Understanding a narrative requires reading between the lines and reasoning\nabout the unspoken but obvious implications about events and people's mental\nstates - a capability that is trivial for humans but remarkably hard for\nmachines. To facilitate research addressing this challenge, we introduce a new\nannotation framework to explain naive psychology of story characters as\nfully-specified chains of mental states with respect to motivations and\nemotional reactions. Our work presents a new large-scale dataset with rich\nlow-level annotations and establishes baseline performance on several new\ntasks, suggesting avenues for future research. \n\n"}
{"id": "1805.06960", "contents": "Title: Ask No More: Deciding when to guess in referential visual dialogue Abstract: Our goal is to explore how the abilities brought in by a dialogue manager can\nbe included in end-to-end visually grounded conversational agents. We make\ninitial steps towards this general goal by augmenting a task-oriented visual\ndialogue model with a decision-making component that decides whether to ask a\nfollow-up question to identify a target referent in an image, or to stop the\nconversation to make a guess. Our analyses show that adding a decision making\ncomponent produces dialogues that are less repetitive and that include fewer\nunnecessary questions, thus potentially leading to more efficient and less\nunnatural interactions. \n\n"}
{"id": "1805.07513", "contents": "Title: Diverse Few-Shot Text Classification with Multiple Metrics Abstract: We study few-shot learning in natural language domains. Compared to many\nexisting works that apply either metric-based or optimization-based\nmeta-learning to image domain with low inter-task variance, we consider a more\nrealistic setting, where tasks are diverse. However, it imposes tremendous\ndifficulties to existing state-of-the-art metric-based algorithms since a\nsingle metric is insufficient to capture complex task variations in natural\nlanguage domain. To alleviate the problem, we propose an adaptive metric\nlearning approach that automatically determines the best weighted combination\nfrom a set of metrics obtained from meta-training tasks for a newly seen\nfew-shot task. Extensive quantitative evaluations on real-world sentiment\nanalysis and dialog intent classification datasets demonstrate that the\nproposed method performs favorably against state-of-the-art few shot learning\nalgorithms in terms of predictive accuracy. We make our code and data available\nfor further study. \n\n"}
{"id": "1805.07824", "contents": "Title: Validating WordNet Meronymy Relations using Adimen-SUMO Abstract: In this paper, we report on the practical application of a novel approach for\nvalidating the knowledge of WordNet using Adimen-SUMO. In particular, this\npaper focuses on cross-checking the WordNet meronymy relations against the\nknowledge encoded in Adimen-SUMO. Our validation approach tests a large set of\ncompetency questions (CQs), which are derived (semi)-automatically from the\nknowledge encoded in WordNet, SUMO and their mapping, by applying efficient\nfirst-order logic automated theorem provers. Unfortunately, despite of being\ncreated manually, these knowledge resources are not free of errors and\ndiscrepancies. In consequence, some of the resulting CQs are not plausible\naccording to the knowledge included in Adimen-SUMO. Thus, first we focus on\n(semi)-automatically improving the alignment between these knowledge resources,\nand second, we perform a minimal set of corrections in the ontology. Our aim is\nto minimize the manual effort required for an extensive validation process. We\nreport on the strategies followed, the changes made, the effort needed and its\nimpact when validating the WordNet meronymy relations using improved versions\nof the mapping and the ontology. Based on the new results, we discuss the\nimplications of the appropriate corrections and the need of future\nenhancements. \n\n"}
{"id": "1805.07932", "contents": "Title: Bilinear Attention Networks Abstract: Attention networks in multimodal learning provide an efficient way to utilize\ngiven visual information selectively. However, the computational cost to learn\nattention distributions for every pair of multimodal input channels is\nprohibitively expensive. To solve this problem, co-attention builds two\nseparate attention distributions for each modality neglecting the interaction\nbetween multimodal inputs. In this paper, we propose bilinear attention\nnetworks (BAN) that find bilinear attention distributions to utilize given\nvision-language information seamlessly. BAN considers bilinear interactions\namong two groups of input channels, while low-rank bilinear pooling extracts\nthe joint representations for each pair of channels. Furthermore, we propose a\nvariant of multimodal residual networks to exploit eight-attention maps of the\nBAN efficiently. We quantitatively and qualitatively evaluate our model on\nvisual question answering (VQA 2.0) and Flickr30k Entities datasets, showing\nthat BAN significantly outperforms previous methods and achieves new\nstate-of-the-arts on both datasets. \n\n"}
{"id": "1805.08182", "contents": "Title: Party Matters: Enhancing Legislative Embeddings with Author Attributes\n  for Vote Prediction Abstract: Predicting how Congressional legislators will vote is important for\nunderstanding their past and future behavior. However, previous work on\nroll-call prediction has been limited to single session settings, thus did not\nconsider generalization across sessions. In this paper, we show that metadata\nis crucial for modeling voting outcomes in new contexts, as changes between\nsessions lead to changes in the underlying data generation process. We show how\naugmenting bill text with the sponsors' ideologies in a neural network model\ncan achieve an average of a 4% boost in accuracy over the previous\nstate-of-the-art. \n\n"}
{"id": "1805.08329", "contents": "Title: Guided Feature Transformation (GFT): A Neural Language Grounding Module\n  for Embodied Agents Abstract: Recently there has been a rising interest in training agents, embodied in\nvirtual environments, to perform language-directed tasks by deep reinforcement\nlearning. In this paper, we propose a simple but effective neural language\ngrounding module for embodied agents that can be trained end to end from\nscratch taking raw pixels, unstructured linguistic commands, and sparse rewards\nas the inputs. We model the language grounding process as a language-guided\ntransformation of visual features, where latent sentence embeddings are used as\nthe transformation matrices. In several language-directed navigation tasks that\nfeature challenging partial observability and require simple reasoning, our\nmodule significantly outperforms the state of the art. We also release\nXWorld3D, an easy-to-customize 3D environment that can potentially be modified\nto evaluate a variety of embodied agents. \n\n"}
{"id": "1805.08455", "contents": "Title: Context-Aware Sequence-to-Sequence Models for Conversational Systems Abstract: This work proposes a novel approach based on sequence-to-sequence (seq2seq)\nmodels for context-aware conversational systems. Exist- ing seq2seq models have\nbeen shown to be good for generating natural responses in a data-driven\nconversational system. However, they still lack mechanisms to incorporate\nprevious conversation turns. We investigate RNN-based methods that efficiently\nintegrate previous turns as a context for generating responses. Overall, our\nexperimental results based on human judgment demonstrate the feasibility and\neffectiveness of the proposed approach. \n\n"}
{"id": "1805.08701", "contents": "Title: Normalization of Transliterated Words in Code-Mixed Data Using Seq2Seq\n  Model & Levenshtein Distance Abstract: Building tools for code-mixed data is rapidly gaining popularity in the NLP\nresearch community as such data is exponentially rising on social media.\nWorking with code-mixed data contains several challenges, especially due to\ngrammatical inconsistencies and spelling variations in addition to all the\nprevious known challenges for social media scenarios. In this article, we\npresent a novel architecture focusing on normalizing phonetic typing\nvariations, which is commonly seen in code-mixed data. One of the main features\nof our architecture is that in addition to normalizing, it can also be utilized\nfor back-transliteration and word identification in some cases. Our model\nachieved an accuracy of 90.27% on the test data. \n\n"}
{"id": "1805.09016", "contents": "Title: Bilingual Sentiment Embeddings: Joint Projection of Sentiment Across\n  Languages Abstract: Sentiment analysis in low-resource languages suffers from a lack of annotated\ncorpora to estimate high-performing models. Machine translation and bilingual\nword embeddings provide some relief through cross-lingual sentiment approaches.\nHowever, they either require large amounts of parallel data or do not\nsufficiently capture sentiment information. We introduce Bilingual Sentiment\nEmbeddings (BLSE), which jointly represent sentiment information in a source\nand target language. This model only requires a small bilingual lexicon, a\nsource-language corpus annotated for sentiment, and monolingual word embeddings\nfor each language. We perform experiments on three language combinations\n(Spanish, Catalan, Basque) for sentence-level cross-lingual sentiment\nclassification and find that our model significantly outperforms\nstate-of-the-art methods on four out of six experimental setups, as well as\ncapturing complementary information to machine translation. Our analysis of the\nresulting embedding space provides evidence that it represents sentiment\ninformation in the resource-poor target language without any annotated data in\nthat language. \n\n"}
{"id": "1805.09354", "contents": "Title: Working Memory Networks: Augmenting Memory Networks with a Relational\n  Reasoning Module Abstract: During the last years, there has been a lot of interest in achieving some\nkind of complex reasoning using deep neural networks. To do that, models like\nMemory Networks (MemNNs) have combined external memory storages and attention\nmechanisms. These architectures, however, lack of more complex reasoning\nmechanisms that could allow, for instance, relational reasoning. Relation\nNetworks (RNs), on the other hand, have shown outstanding results in relational\nreasoning tasks. Unfortunately, their computational cost grows quadratically\nwith the number of memories, something prohibitive for larger problems. To\nsolve these issues, we introduce the Working Memory Network, a MemNN\narchitecture with a novel working memory storage and reasoning module. Our\nmodel retains the relational reasoning abilities of the RN while reducing its\ncomputational complexity from quadratic to linear. We tested our model on the\ntext QA dataset bAbI and the visual QA dataset NLVR. In the jointly trained\nbAbI-10k, we set a new state-of-the-art, achieving a mean error of less than\n0.5%. Moreover, a simple ensemble of two of our models solves all 20 tasks in\nthe joint version of the benchmark. \n\n"}
{"id": "1805.09772", "contents": "Title: Auto-Detection of Safety Issues in Baby Products Abstract: Every year, thousands of people receive consumer product related injuries.\nResearch indicates that online customer reviews can be processed to\nautonomously identify product safety issues. Early identification of safety\nissues can lead to earlier recalls, and thus fewer injuries and deaths. A\ndataset of product reviews from Amazon.com was compiled, along with\n\\emph{SaferProducts.gov} complaints and recall descriptions from the Consumer\nProduct Safety Commission (CPSC) and European Commission Rapid Alert system. A\nsystem was built to clean the collected text and to extract relevant features.\nDimensionality reduction was performed by computing feature relevance through a\nRandom Forest and discarding features with low information gain. Various\nclassifiers were analyzed, including Logistic Regression, SVMs,\nNa{\\\"i}ve-Bayes, Random Forests, and an Ensemble classifier. Experimentation\nwith various features and classifier combinations resulted in a logistic\nregression model with 66\\% precision in the top 50 reviews surfaced. This\nclassifier outperforms all benchmarks set by related literature and consumer\nproduct safety professionals. \n\n"}
{"id": "1805.09927", "contents": "Title: Robust Distant Supervision Relation Extraction via Deep Reinforcement\n  Learning Abstract: Distant supervision has become the standard method for relation extraction.\nHowever, even though it is an efficient method, it does not come at no\ncost---The resulted distantly-supervised training samples are often very noisy.\nTo combat the noise, most of the recent state-of-the-art approaches focus on\nselecting one-best sentence or calculating soft attention weights over the set\nof the sentences of one specific entity pair. However, these methods are\nsuboptimal, and the false positive problem is still a key stumbling bottleneck\nfor the performance. We argue that those incorrectly-labeled candidate\nsentences must be treated with a hard decision, rather than being dealt with\nsoft attention weights. To do this, our paper describes a radical solution---We\nexplore a deep reinforcement learning strategy to generate the false-positive\nindicator, where we automatically recognize false positives for each relation\ntype without any supervised information. Unlike the removal operation in the\nprevious studies, we redistribute them into the negative examples. The\nexperimental results show that the proposed strategy significantly improves the\nperformance of distant supervision comparing to state-of-the-art systems. \n\n"}
{"id": "1805.10389", "contents": "Title: A Study of Question Effectiveness Using Reddit \"Ask Me Anything\" Threads Abstract: Asking effective questions is a powerful social skill. In this paper we seek\nto build computational models that learn to discriminate effective questions\nfrom ineffective ones. Armed with such a capability, future advanced systems\ncan evaluate the quality of questions and provide suggestions for effective\nquestion wording. We create a large-scale, real-world dataset that contains\nover 400,000 questions collected from Reddit \"Ask Me Anything\" threads. Each\nthread resembles an online press conference where questions compete with each\nother for attention from the host. This dataset enables the development of a\nclass of computational models for predicting whether a question will be\nanswered. We develop a new convolutional neural network architecture with\nvariable-length context and demonstrate the efficacy of the model by comparing\nit with state-of-the-art baselines and human judges. \n\n"}
{"id": "1805.10685", "contents": "Title: Legal Document Retrieval using Document Vector Embeddings and Deep\n  Learning Abstract: Domain specific information retrieval process has been a prominent and\nongoing research in the field of natural language processing. Many researchers\nhave incorporated different techniques to overcome the technical and domain\nspecificity and provide a mature model for various domains of interest. The\nmain bottleneck in these studies is the heavy coupling of domain experts, that\nmakes the entire process to be time consuming and cumbersome. In this study, we\nhave developed three novel models which are compared against a golden standard\ngenerated via the on line repositories provided, specifically for the legal\ndomain. The three different models incorporated vector space representations of\nthe legal domain, where document vector generation was done in two different\nmechanisms and as an ensemble of the above two. This study contains the\nresearch being carried out in the process of representing legal case documents\ninto different vector spaces, whilst incorporating semantic word measures and\nnatural language processing techniques. The ensemble model built in this study,\nshows a significantly higher accuracy level, which indeed proves the need for\nincorporation of domain specific semantic similarity measures into the\ninformation retrieval process. This study also shows, the impact of varying\ndistribution of the word similarity measures, against varying document vector\ndimensions, which can lead to improvements in the process of legal information\nretrieval. \n\n"}
{"id": "1805.10796", "contents": "Title: Convolutional neural network compression for natural language processing Abstract: Convolutional neural networks are modern models that are very efficient in\nmany classification tasks. They were originally created for image processing\npurposes. Then some trials were performed to use them in different domains like\nnatural language processing. The artificial intelligence systems (like humanoid\nrobots) are very often based on embedded systems with constraints on memory,\npower consumption etc. Therefore convolutional neural network because of its\nmemory capacity should be reduced to be mapped to given hardware. In this\npaper, results are presented of compressing the efficient convolutional neural\nnetworks for sentiment analysis. The main steps are quantization and pruning\nprocesses. The method responsible for mapping compressed network to FPGA and\nresults of this implementation are presented. The described simulations showed\nthat 5-bit width is enough to have no drop in accuracy from floating point\nversion of the network. Additionally, significant memory footprint reduction\nwas achieved (from 85% up to 93%). \n\n"}
{"id": "1805.10799", "contents": "Title: Interactive Text2Pickup Network for Natural Language based Human-Robot\n  Collaboration Abstract: In this paper, we propose the Interactive Text2Pickup (IT2P) network for\nhuman-robot collaboration which enables an effective interaction with a human\nuser despite the ambiguity in user's commands. We focus on the task where a\nrobot is expected to pick up an object instructed by a human, and to interact\nwith the human when the given instruction is vague. The proposed network\nunderstands the command from the human user and estimates the position of the\ndesired object first. To handle the inherent ambiguity in human language\ncommands, a suitable question which can resolve the ambiguity is generated. The\nuser's answer to the question is combined with the initial command and given\nback to the network, resulting in more accurate estimation. The experiment\nresults show that given unambiguous commands, the proposed method can estimate\nthe position of the requested object with an accuracy of 98.49% based on our\ntest dataset. Given ambiguous language commands, we show that the accuracy of\nthe pick up task increases by 1.94 times after incorporating the information\nobtained from the interaction. \n\n"}
{"id": "1805.11004", "contents": "Title: Soft Layer-Specific Multi-Task Summarization with Entailment and\n  Question Generation Abstract: An accurate abstractive summary of a document should contain all its salient\ninformation and should be logically entailed by the input document. We improve\nthese important aspects of abstractive summarization via multi-task learning\nwith the auxiliary tasks of question generation and entailment generation,\nwhere the former teaches the summarization model how to look for salient\nquestioning-worthy details, and the latter teaches the model how to rewrite a\nsummary which is a directed-logical subset of the input document. We also\npropose novel multi-task architectures with high-level (semantic)\nlayer-specific sharing across multiple encoder and decoder layers of the three\ntasks, as well as soft-sharing mechanisms (and show performance ablations and\nanalysis examples of each contribution). Overall, we achieve statistically\nsignificant improvements over the state-of-the-art on both the CNN/DailyMail\nand Gigaword datasets, as well as on the DUC-2002 transfer setup. We also\npresent several quantitative and qualitative analysis studies of our model's\nlearned saliency and entailment skills. \n\n"}
{"id": "1805.11267", "contents": "Title: Multi-hop Inference for Sentence-level TextGraphs: How Challenging is\n  Meaningfully Combining Information for Science Question Answering? Abstract: Question Answering for complex questions is often modeled as a graph\nconstruction or traversal task, where a solver must build or traverse a graph\nof facts that answer and explain a given question. This \"multi-hop\" inference\nhas been shown to be extremely challenging, with few models able to aggregate\nmore than two facts before being overwhelmed by \"semantic drift\", or the\ntendency for long chains of facts to quickly drift off topic. This is a major\nbarrier to current inference models, as even elementary science questions\nrequire an average of 4 to 6 facts to answer and explain. In this work we\nempirically characterize the difficulty of building or traversing a graph of\nsentences connected by lexical overlap, by evaluating chance sentence\naggregation quality through 9,784 manually-annotated judgments across knowledge\ngraphs built from three free-text corpora (including study guides and Simple\nWikipedia). We demonstrate semantic drift tends to be high and aggregation\nquality low, at between 0.04% and 3%, and highlight scenarios that maximize the\nlikelihood of meaningfully combining information. \n\n"}
{"id": "1805.11824", "contents": "Title: Anaphora and Coreference Resolution: A Review Abstract: Entity resolution aims at resolving repeated references to an entity in a\ndocument and forms a core component of natural language processing (NLP)\nresearch. This field possesses immense potential to improve the performance of\nother NLP fields like machine translation, sentiment analysis, paraphrase\ndetection, summarization, etc. The area of entity resolution in NLP has seen\nproliferation of research in two separate sub-areas namely: anaphora resolution\nand coreference resolution. Through this review article, we aim at clarifying\nthe scope of these two tasks in entity resolution. We also carry out a detailed\nanalysis of the datasets, evaluation metrics and research methods that have\nbeen adopted to tackle this NLP problem. This survey is motivated with the aim\nof providing the reader with a clear understanding of what constitutes this NLP\nproblem and the issues that require attention. \n\n"}
{"id": "1805.12096", "contents": "Title: Marian: Cost-effective High-Quality Neural Machine Translation in C++ Abstract: This paper describes the submissions of the \"Marian\" team to the WNMT 2018\nshared task. We investigate combinations of teacher-student training,\nlow-precision matrix products, auto-tuning and other methods to optimize the\nTransformer model on GPU and CPU. By further integrating these methods with the\nnew averaging attention networks, a recently introduced faster Transformer\nvariant, we create a number of high-quality, high-performance models on the GPU\nand CPU, dominating the Pareto frontier for this shared task. \n\n"}
{"id": "1805.12386", "contents": "Title: SemEval 2019 Shared Task: Cross-lingual Semantic Parsing with UCCA -\n  Call for Participation Abstract: We announce a shared task on UCCA parsing in English, German and French, and\ncall for participants to submit their systems. UCCA is a cross-linguistically\napplicable framework for semantic representation, which builds on extensive\ntypological work and supports rapid annotation. UCCA poses a challenge for\nexisting parsing techniques, as it exhibits reentrancy (resulting in DAG\nstructures), discontinuous structures and non-terminal nodes corresponding to\ncomplex semantic units. Given the success of recent semantic parsing shared\ntasks (on SDP and AMR), we expect the task to have a significant contribution\nto the advancement of UCCA parsing in particular, and semantic parsing in\ngeneral. Furthermore, existing applications for semantic evaluation that are\nbased on UCCA will greatly benefit from better automatic methods for UCCA\nparsing. The competition website is\nhttps://competitions.codalab.org/competitions/19160 \n\n"}
{"id": "1806.00258", "contents": "Title: A Survey of Domain Adaptation for Neural Machine Translation Abstract: Neural machine translation (NMT) is a deep learning based approach for\nmachine translation, which yields the state-of-the-art translation performance\nin scenarios where large-scale parallel corpora are available. Although the\nhigh-quality and domain-specific translation is crucial in the real world,\ndomain-specific corpora are usually scarce or nonexistent, and thus vanilla NMT\nperforms poorly in such scenarios. Domain adaptation that leverages both\nout-of-domain parallel corpora as well as monolingual corpora for in-domain\ntranslation, is very important for domain-specific translation. In this paper,\nwe give a comprehensive survey of the state-of-the-art domain adaptation\ntechniques for NMT. \n\n"}
{"id": "1806.00512", "contents": "Title: Structurally Sparsified Backward Propagation for Faster Long Short-Term\n  Memory Training Abstract: Exploiting sparsity enables hardware systems to run neural networks faster\nand more energy-efficiently. However, most prior sparsity-centric optimization\ntechniques only accelerate the forward pass of neural networks and usually\nrequire an even longer training process with iterative pruning and retraining.\nWe observe that artificially inducing sparsity in the gradients of the gates in\nan LSTM cell has little impact on the training quality. Further, we can enforce\nstructured sparsity in the gate gradients to make the LSTM backward pass up to\n45% faster than the state-of-the-art dense approach and 168% faster than the\nstate-of-the-art sparsifying method on modern GPUs. Though the structured\nsparsifying method can impact the accuracy of a model, this performance gap can\nbe eliminated by mixing our sparse training method and the standard dense\ntraining method. Experimental results show that the mixed method can achieve\ncomparable results in a shorter time span than using purely dense training. \n\n"}
{"id": "1806.00628", "contents": "Title: A Novel Framework for Recurrent Neural Networks with Enhancing\n  Information Processing and Transmission between Units Abstract: This paper proposes a novel framework for recurrent neural networks (RNNs)\ninspired by the human memory models in the field of cognitive neuroscience to\nenhance information processing and transmission between adjacent RNNs' units.\nThe proposed framework for RNNs consists of three stages that is working\nmemory, forget, and long-term store. The first stage includes taking input data\ninto sensory memory and transferring it to working memory for preliminary\ntreatment. And the second stage mainly focuses on proactively forgetting the\nsecondary information rather than the primary in the working memory. And\nfinally, we get the long-term store normally using some kind of RNN's unit. Our\nframework, which is generalized and simple, is evaluated on 6 datasets which\nfall into 3 different tasks, corresponding to text classification, image\nclassification and language modelling. Experiments reveal that our framework\ncan obviously improve the performance of traditional recurrent neural networks.\nAnd exploratory task shows the ability of our framework of correctly forgetting\nthe secondary information. \n\n"}
{"id": "1806.00807", "contents": "Title: Learning Semantic Sentence Embeddings using Sequential Pair-wise\n  Discriminator Abstract: In this paper, we propose a method for obtaining sentence-level embeddings.\nWhile the problem of securing word-level embeddings is very well studied, we\npropose a novel method for obtaining sentence-level embeddings. This is\nobtained by a simple method in the context of solving the paraphrase generation\ntask. If we use a sequential encoder-decoder model for generating paraphrase,\nwe would like the generated paraphrase to be semantically close to the original\nsentence. One way to ensure this is by adding constraints for true paraphrase\nembeddings to be close and unrelated paraphrase candidate sentence embeddings\nto be far. This is ensured by using a sequential pair-wise discriminator that\nshares weights with the encoder that is trained with a suitable loss function.\nOur loss function penalizes paraphrase sentence embedding distances from being\ntoo large. This loss is used in combination with a sequential encoder-decoder\nnetwork. We also validated our method by evaluating the obtained embeddings for\na sentiment analysis task. The proposed method results in semantic embeddings\nand outperforms the state-of-the-art on the paraphrase generation and sentiment\nanalysis task on standard datasets. These results are also shown to be\nstatistically significant. \n\n"}
{"id": "1806.01773", "contents": "Title: Contextual Slot Carryover for Disparate Schemas Abstract: In the slot-filling paradigm, where a user can refer back to slots in the\ncontext during a conversation, the goal of the contextual understanding system\nis to resolve the referring expressions to the appropriate slots in the\ncontext. In large-scale multi-domain systems, this presents two challenges -\nscaling to a very large and potentially unbounded set of slot values, and\ndealing with diverse schemas. We present a neural network architecture that\naddresses the slot value scalability challenge by reformulating the contextual\ninterpretation as a decision to carryover a slot from a set of possible\ncandidates. To deal with heterogenous schemas, we introduce a simple\ndata-driven method for trans- forming the candidate slots. Our experiments show\nthat our approach can scale to multiple domains and provides competitive\nresults over a strong baseline. \n\n"}
{"id": "1806.02253", "contents": "Title: The Limitations of Cross-language Word Embeddings Evaluation Abstract: The aim of this work is to explore the possible limitations of existing\nmethods of cross-language word embeddings evaluation, addressing the lack of\ncorrelation between intrinsic and extrinsic cross-language evaluation methods.\nTo prove this hypothesis, we construct English-Russian datasets for extrinsic\nand intrinsic evaluation tasks and compare performances of 5 different\ncross-language models on them. The results say that the scores even on\ndifferent intrinsic benchmarks do not correlate to each other. We can conclude\nthat the use of human references as ground truth for cross-language word\nembeddings is not proper unless one does not understand how do native speakers\nprocess semantics in their cognition. \n\n"}
{"id": "1806.02923", "contents": "Title: Multimodal Relational Tensor Network for Sentiment and Emotion\n  Classification Abstract: Understanding Affect from video segments has brought researchers from the\nlanguage, audio and video domains together. Most of the current multimodal\nresearch in this area deals with various techniques to fuse the modalities, and\nmostly treat the segments of a video independently. Motivated by the work of\n(Zadeh et al., 2017) and (Poria et al., 2017), we present our architecture,\nRelational Tensor Network, where we use the inter-modal interactions within a\nsegment (intra-segment) and also consider the sequence of segments in a video\nto model the inter-segment inter-modal interactions. We also generate rich\nrepresentations of text and audio modalities by leveraging richer audio and\nlinguistic context alongwith fusing fine-grained knowledge based polarity\nscores from text. We present the results of our model on CMU-MOSEI dataset and\nshow that our model outperforms many baselines and state of the art methods for\nsentiment classification and emotion recognition. \n\n"}
{"id": "1806.03537", "contents": "Title: Diachronic word embeddings and semantic shifts: a survey Abstract: Recent years have witnessed a surge of publications aimed at tracing temporal\nchanges in lexical semantics using distributional methods, particularly\nprediction-based word embedding models. However, this vein of research lacks\nthe cohesion, common terminology and shared practices of more established areas\nof natural language processing. In this paper, we survey the current state of\nacademic research related to diachronic word embeddings and semantic shifts\ndetection. We start with discussing the notion of semantic shifts, and then\ncontinue with an overview of the existing methods for tracing such time-related\nshifts with word embedding models. We propose several axes along which these\nmethods can be compared, and outline the main challenges before this emerging\nsubfield of NLP, as well as prospects and possible applications. \n\n"}
{"id": "1806.03692", "contents": "Title: Deconvolution-Based Global Decoding for Neural Machine Translation Abstract: A great proportion of sequence-to-sequence (Seq2Seq) models for Neural\nMachine Translation (NMT) adopt Recurrent Neural Network (RNN) to generate\ntranslation word by word following a sequential order. As the studies of\nlinguistics have proved that language is not linear word sequence but sequence\nof complex structure, translation at each step should be conditioned on the\nwhole target-side context. To tackle the problem, we propose a new NMT model\nthat decodes the sequence with the guidance of its structural prediction of the\ncontext of the target sequence. Our model generates translation based on the\nstructural prediction of the target-side context so that the translation can be\nfreed from the bind of sequential order. Experimental results demonstrate that\nour model is more competitive compared with the state-of-the-art methods, and\nthe analysis reflects that our model is also robust to translating sentences of\ndifferent lengths and it also reduces repetition with the instruction from the\ntarget-side context for decoding. \n\n"}
{"id": "1806.04092", "contents": "Title: WikiRef: Wikilinks as a route to recommending appropriate references for\n  scientific Wikipedia pages Abstract: The exponential increase in the usage of Wikipedia as a key source of\nscientific knowledge among the researchers is making it absolutely necessary to\nmetamorphose this knowledge repository into an integral and self-contained\nsource of information for direct utilization. Unfortunately, the references\nwhich support the content of each Wikipedia entity page, are far from complete.\nWhy are the reference section ill-formed for most Wikipedia pages? Is this\nsection edited as frequently as the other sections of a page? Can there be\nappropriate surrogates that can automatically enhance the reference section? In\nthis paper, we propose a novel two step approach -- WikiRef -- that (i)\nleverages the wikilinks present in a scientific Wikipedia target page and,\nthereby, (ii) recommends highly relevant references to be included in that\ntarget page appropriately and automatically borrowed from the reference section\nof the wikilinks. In the first step, we build a classifier to ascertain whether\na wikilink is a potential source of reference or not. In the following step, we\nrecommend references to the target page from the reference section of the\nwikilinks that are classified as potential sources of references in the first\nstep. We perform an extensive evaluation of our approach on datasets from two\ndifferent domains -- Computer Science and Physics. For Computer Science we\nachieve a notably good performance with a precision@1 of 0.44 for reference\nrecommendation as opposed to 0.38 obtained from the most competitive baseline.\nFor the Physics dataset, we obtain a similar performance boost of 10% with\nrespect to the most competitive baseline. \n\n"}
{"id": "1806.04466", "contents": "Title: Fusing Recency into Neural Machine Translation with an Inter-Sentence\n  Gate Model Abstract: Neural machine translation (NMT) systems are usually trained on a large\namount of bilingual sentence pairs and translate one sentence at a time,\nignoring inter-sentence information. This may make the translation of a\nsentence ambiguous or even inconsistent with the translations of neighboring\nsentences. In order to handle this issue, we propose an inter-sentence gate\nmodel that uses the same encoder to encode two adjacent sentences and controls\nthe amount of information flowing from the preceding sentence to the\ntranslation of the current sentence with an inter-sentence gate. In this way,\nour proposed model can capture the connection between sentences and fuse\nrecency from neighboring sentences into neural machine translation. On several\nNIST Chinese-English translation tasks, our experiments demonstrate that the\nproposed inter-sentence gate model achieves substantial improvements over the\nbaseline. \n\n"}
{"id": "1806.04822", "contents": "Title: SGM: Sequence Generation Model for Multi-label Classification Abstract: Multi-label classification is an important yet challenging task in natural\nlanguage processing. It is more complex than single-label classification in\nthat the labels tend to be correlated. Existing methods tend to ignore the\ncorrelations between labels. Besides, different parts of the text can\ncontribute differently for predicting different labels, which is not considered\nby existing models. In this paper, we propose to view the multi-label\nclassification task as a sequence generation problem, and apply a sequence\ngeneration model with a novel decoder structure to solve it. Extensive\nexperimental results show that our proposed methods outperform previous work by\na substantial margin. Further analysis of experimental results demonstrates\nthat the proposed methods not only capture the correlations between labels, but\nalso select the most informative words automatically when predicting different\nlabels. \n\n"}
{"id": "1806.04936", "contents": "Title: On Accurate Evaluation of GANs for Language Generation Abstract: Generative Adversarial Networks (GANs) are a promising approach to language\ngeneration. The latest works introducing novel GAN models for language\ngeneration use n-gram based metrics for evaluation and only report single\nscores of the best run. In this paper, we argue that this often misrepresents\nthe true picture and does not tell the full story, as GAN models can be\nextremely sensitive to the random initialization and small deviations from the\nbest hyperparameter choice. In particular, we demonstrate that the previously\nused BLEU score is not sensitive to semantic deterioration of generated texts\nand propose alternative metrics that better capture the quality and diversity\nof the generated samples. We also conduct a set of experiments comparing a\nnumber of GAN models for text with a conventional Language Model (LM) and find\nthat neither of the considered models performs convincingly better than the LM. \n\n"}
{"id": "1806.05130", "contents": "Title: Detecting Speech Act Types in Developer Question/Answer Conversations\n  During Bug Repair Abstract: This paper targets the problem of speech act detection in conversations about\nbug repair. We conduct a \"Wizard of Oz\" experiment with 30 professional\nprogrammers, in which the programmers fix bugs for two hours, and use a\nsimulated virtual assistant for help. Then, we use an open coding manual\nannotation procedure to identify the speech act types in the conversations.\nFinally, we train and evaluate a supervised learning algorithm to automatically\ndetect the speech act types in the conversations. In 30 two-hour conversations,\nwe made 2459 annotations and uncovered 26 speech act types. Our automated\ndetection achieved 69% precision and 50% recall. The key application of this\nwork is to advance the state of the art for virtual assistants in software\nengineering. Virtual assistant technology is growing rapidly, though\napplications in software engineering are behind those in other areas, largely\ndue to a lack of relevant data and experiments. This paper targets this problem\nin the area of developer Q/A conversations about bug repair. \n\n"}
{"id": "1806.05219", "contents": "Title: Bringing replication and reproduction together with generalisability in\n  NLP: Three reproduction studies for Target Dependent Sentiment Analysis Abstract: Lack of repeatability and generalisability are two significant threats to\ncontinuing scientific development in Natural Language Processing. Language\nmodels and learning methods are so complex that scientific conference papers no\nlonger contain enough space for the technical depth required for replication or\nreproduction. Taking Target Dependent Sentiment Analysis as a case study, we\nshow how recent work in the field has not consistently released code, or\ndescribed settings for learning methods in enough detail, and lacks\ncomparability and generalisability in train, test or validation data. To\ninvestigate generalisability and to enable state of the art comparative\nevaluations, we carry out the first reproduction studies of three groups of\ncomplementary methods and perform the first large-scale mass evaluation on six\ndifferent English datasets. Reflecting on our experiences, we recommend that\nfuture replication or reproduction experiments should always consider a variety\nof datasets alongside documenting and releasing their methods and published\ncode in order to minimise the barriers to both repeatability and\ngeneralisability. We have released our code with a model zoo on GitHub with\nJupyter Notebooks to aid understanding and full documentation, and we recommend\nthat others do the same with their papers at submission time through an\nanonymised GitHub account. \n\n"}
{"id": "1806.05258", "contents": "Title: SMHD: A Large-Scale Resource for Exploring Online Language Usage for\n  Multiple Mental Health Conditions Abstract: Mental health is a significant and growing public health concern. As language\nusage can be leveraged to obtain crucial insights into mental health\nconditions, there is a need for large-scale, labeled, mental health-related\ndatasets of users who have been diagnosed with one or more of such conditions.\nIn this paper, we investigate the creation of high-precision patterns to\nidentify self-reported diagnoses of nine different mental health conditions,\nand obtain high-quality labeled data without the need for manual labelling. We\nintroduce the SMHD (Self-reported Mental Health Diagnoses) dataset and make it\navailable. SMHD is a novel large dataset of social media posts from users with\none or multiple mental health conditions along with matched control users. We\nexamine distinctions in users' language, as measured by linguistic and\npsychological variables. We further explore text classification methods to\nidentify individuals with mental conditions through their language. \n\n"}
{"id": "1806.05461", "contents": "Title: Learning Cross-lingual Distributed Logical Representations for Semantic\n  Parsing Abstract: With the development of several multilingual datasets used for semantic\nparsing, recent research efforts have looked into the problem of learning\nsemantic parsers in a multilingual setup. However, how to improve the\nperformance of a monolingual semantic parser for a specific language by\nleveraging data annotated in different languages remains a research question\nthat is under-explored. In this work, we present a study to show how learning\ndistributed representations of the logical forms from data annotated in\ndifferent languages can be used for improving the performance of a monolingual\nsemantic parser. We extend two existing monolingual semantic parsers to\nincorporate such cross-lingual distributed logical representations as features.\nExperiments show that our proposed approach is able to yield improved semantic\nparsing results on the standard multilingual GeoQuery dataset. \n\n"}
{"id": "1806.05482", "contents": "Title: Morphological and Language-Agnostic Word Segmentation for NMT Abstract: The state of the art of handling rich morphology in neural machine\ntranslation (NMT) is to break word forms into subword units, so that the\noverall vocabulary size of these units fits the practical limits given by the\nNMT model and GPU memory capacity. In this paper, we compare two common but\nlinguistically uninformed methods of subword construction (BPE and STE, the\nmethod implemented in Tensor2Tensor toolkit) and two linguistically-motivated\nmethods: Morfessor and one novel method, based on a derivational dictionary.\nOur experiments with German-to-Czech translation, both morphologically rich,\ndocument that so far, the non-motivated methods perform better. Furthermore, we\niden- tify a critical difference between BPE and STE and show a simple pre-\nprocessing step for BPE that considerably increases translation quality as\nevaluated by automatic measures. \n\n"}
{"id": "1806.05559", "contents": "Title: Extracting Parallel Sentences with Bidirectional Recurrent Neural\n  Networks to Improve Machine Translation Abstract: Parallel sentence extraction is a task addressing the data sparsity problem\nfound in multilingual natural language processing applications. We propose a\nbidirectional recurrent neural network based approach to extract parallel\nsentences from collections of multilingual texts. Our experiments with noisy\nparallel corpora show that we can achieve promising results against a\ncompetitive baseline by removing the need of specific feature engineering or\nadditional external resources. To justify the utility of our approach, we\nextract sentence pairs from Wikipedia articles to train machine translation\nsystems and show significant improvements in translation performance. \n\n"}
{"id": "1806.05626", "contents": "Title: NCRF++: An Open-source Neural Sequence Labeling Toolkit Abstract: This paper describes NCRF++, a toolkit for neural sequence labeling. NCRF++\nis designed for quick implementation of different neural sequence labeling\nmodels with a CRF inference layer. It provides users with an inference for\nbuilding the custom model structure through configuration file with flexible\nneural feature design and utilization. Built on PyTorch, the core operations\nare calculated in batch, making the toolkit efficient with the acceleration of\nGPU. It also includes the implementations of most state-of-the-art neural\nsequence labeling models such as LSTM-CRF, facilitating reproducing and\nrefinement on those methods. \n\n"}
{"id": "1806.07169", "contents": "Title: Learning from Chunk-based Feedback in Neural Machine Translation Abstract: We empirically investigate learning from partial feedback in neural machine\ntranslation (NMT), when partial feedback is collected by asking users to\nhighlight a correct chunk of a translation. We propose a simple and effective\nway of utilizing such feedback in NMT training. We demonstrate how the common\nmachine translation problem of domain mismatch between training and deployment\ncan be reduced solely based on chunk-level user feedback. We conduct a series\nof simulation experiments to test the effectiveness of the proposed method. Our\nresults show that chunk-level feedback outperforms sentence based feedback by\nup to 2.61% BLEU absolute. \n\n"}
{"id": "1806.07687", "contents": "Title: Automated Fact Checking: Task formulations, methods and future\n  directions Abstract: The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking. \n\n"}
{"id": "1806.07978", "contents": "Title: The Corpus Replication Task Abstract: In the field of Natural Language Processing (NLP), we revisit the well-known\nword embedding algorithm word2vec. Word embeddings identify words by vectors\nsuch that the words' distributional similarity is captured. Unexpectedly,\nbesides semantic similarity even relational similarity has been shown to be\ncaptured in word embeddings generated by word2vec, whence two questions arise.\nFirstly, which kind of relations are representable in continuous space and\nsecondly, how are relations built. In order to tackle these questions we\npropose a bottom-up point of view. We call generating input text for which\nword2vec outputs target relations solving the Corpus Replication Task. Deeming\ngeneralizations of this approach to any set of relations possible, we expect\nsolving of the Corpus Replication Task to provide partial answers to the\nquestions. \n\n"}
{"id": "1806.08462", "contents": "Title: Stochastic Wasserstein Autoencoder for Probabilistic Sentence Generation Abstract: The variational autoencoder (VAE) imposes a probabilistic distribution\n(typically Gaussian) on the latent space and penalizes the Kullback--Leibler\n(KL) divergence between the posterior and prior. In NLP, VAEs are extremely\ndifficult to train due to the problem of KL collapsing to zero. One has to\nimplement various heuristics such as KL weight annealing and word dropout in a\ncarefully engineered manner to successfully train a VAE for text. In this\npaper, we propose to use the Wasserstein autoencoder (WAE) for probabilistic\nsentence generation, where the encoder could be either stochastic or\ndeterministic. We show theoretically and empirically that, in the original WAE,\nthe stochastically encoded Gaussian distribution tends to become a Dirac-delta\nfunction, and we propose a variant of WAE that encourages the stochasticity of\nthe encoder. Experimental results show that the latent space learned by WAE\nexhibits properties of continuity and smoothness as in VAEs, while\nsimultaneously achieving much higher BLEU scores for sentence reconstruction. \n\n"}
{"id": "1806.08727", "contents": "Title: Jack the Reader - A Machine Reading Framework Abstract: Many Machine Reading and Natural Language Understanding tasks require reading\nsupporting text in order to answer questions. For example, in Question\nAnswering, the supporting text can be newswire or Wikipedia articles; in\nNatural Language Inference, premises can be seen as the supporting text and\nhypotheses as questions. Providing a set of useful primitives operating in a\nsingle framework of related tasks would allow for expressive modelling, and\neasier model comparison and replication. To that end, we present Jack the\nReader (Jack), a framework for Machine Reading that allows for quick model\nprototyping by component reuse, evaluation of new models on existing datasets\nas well as integrating new datasets and applying them on a growing set of\nimplemented baseline models. Jack is currently supporting (but not limited to)\nthree tasks: Question Answering, Natural Language Inference, and Link\nPrediction. It is developed with the aim of increasing research efficiency and\ncode reuse. \n\n"}
{"id": "1806.09511", "contents": "Title: A Hierarchical Deep Learning Natural Language Parser for Fashion Abstract: This work presents a hierarchical deep learning natural language parser for\nfashion. Our proposal intends not only to recognize fashion-domain entities but\nalso to expose syntactic and morphologic insights. We leverage the usage of an\narchitecture of specialist models, each one for a different task (from parsing\nto entity recognition). Such architecture renders a hierarchical model able to\ncapture the nuances of the fashion language. The natural language parser is\nable to deal with textual ambiguities which are left unresolved by our\ncurrently existing solution. Our empirical results establish a robust baseline,\nwhich justifies the use of hierarchical architectures of deep learning models\nwhile opening new research avenues to explore. \n\n"}
{"id": "1806.10090", "contents": "Title: Conditional Generators of Words Definitions Abstract: We explore recently introduced definition modeling technique that provided\nthe tool for evaluation of different distributed vector representations of\nwords through modeling dictionary definitions of words. In this work, we study\nthe problem of word ambiguities in definition modeling and propose a possible\nsolution by employing latent variable modeling and soft attention mechanisms.\nOur quantitative and qualitative evaluation and analysis of the model shows\nthat taking into account words ambiguity and polysemy leads to performance\nimprovement. \n\n"}
{"id": "1806.10722", "contents": "Title: DeepTag: inferring all-cause diagnoses from clinical notes in\n  under-resourced medical domain Abstract: Large scale veterinary clinical records can become a powerful resource for\npatient care and research. However, clinicians lack the time and resource to\nannotate patient records with standard medical diagnostic codes and most\nveterinary visits are captured in free text notes. The lack of standard coding\nmakes it challenging to use the clinical data to improve patient care. It is\nalso a major impediment to cross-species translational research, which relies\non the ability to accurately identify patient cohorts with specific diagnostic\ncriteria in humans and animals. In order to reduce the coding burden for\nveterinary clinical practice and aid translational research, we have developed\na deep learning algorithm, DeepTag, which automatically infers diagnostic codes\nfrom veterinary free text notes. DeepTag is trained on a newly curated dataset\nof 112,558 veterinary notes manually annotated by experts. DeepTag extends\nmulti-task LSTM with an improved hierarchical objective that captures the\nsemantic structures between diseases. To foster human-machine collaboration,\nDeepTag also learns to abstain in examples when it is uncertain and defers them\nto human experts, resulting in improved performance. DeepTag accurately infers\ndisease codes from free text even in challenging cross-hospital settings where\nthe text comes from different clinical settings than the ones used for\ntraining. It enables automated disease annotation across a broad range of\nclinical diagnoses with minimal pre-processing. The technical framework in this\nwork can be applied in other medical domains that currently lack medical coding\nresources. \n\n"}
{"id": "1806.11183", "contents": "Title: Cross-Discourse and Multilingual Exploration of Textual Corpora with the\n  DualNeighbors Algorithm Abstract: Word choice is dependent on the cultural context of writers and their\nsubjects. Different words are used to describe similar actions, objects, and\nfeatures based on factors such as class, race, gender, geography and political\naffinity. Exploratory techniques based on locating and counting words may,\ntherefore, lead to conclusions that reinforce culturally inflected boundaries.\nWe offer a new method, the DualNeighbors algorithm, for linking thematically\nsimilar documents both within and across discursive and linguistic barriers to\nreveal cross-cultural connections. Qualitative and quantitative evaluations of\nthis technique are shown as applied to two cultural datasets of interest to\nresearchers across the humanities and social sciences. An open-source\nimplementation of the DualNeighbors algorithm is provided to assist in its\napplication. \n\n"}
{"id": "1807.00914", "contents": "Title: Modeling Language Variation and Universals: A Survey on Typological\n  Linguistics for Natural Language Processing Abstract: Linguistic typology aims to capture structural and semantic variation across\nthe world's languages. A large-scale typology could provide excellent guidance\nfor multilingual Natural Language Processing (NLP), particularly for languages\nthat suffer from the lack of human labeled resources. We present an extensive\nliterature survey on the use of typological information in the development of\nNLP techniques. Our survey demonstrates that to date, the use of information in\nexisting typological databases has resulted in consistent but modest\nimprovements in system performance. We show that this is due to both intrinsic\nlimitations of databases (in terms of coverage and feature granularity) and\nunder-employment of the typological features included in them. We advocate for\na new approach that adapts the broad and discrete nature of typological\ncategories to the contextual and continuous nature of machine learning\nalgorithms used in contemporary NLP. In particular, we suggest that such\napproach could be facilitated by recent developments in data-driven induction\nof typological knowledge. \n\n"}
{"id": "1807.00930", "contents": "Title: Neural Random Projections for Language Modelling Abstract: Neural network-based language models deal with data sparsity problems by\nmapping the large discrete space of words into a smaller continuous space of\nreal-valued vectors. By learning distributed vector representations for words,\neach training sample informs the neural network model about a combinatorial\nnumber of other patterns. In this paper, we exploit the sparsity in natural\nlanguage even further by encoding each unique input word using a fixed sparse\nrandom representation. These sparse codes are then projected onto a smaller\nembedding space which allows for the encoding of word occurrences from a\npossibly unknown vocabulary, along with the creation of more compact language\nmodels using a reduced number of parameters. We investigate the properties of\nour encoding mechanism empirically, by evaluating its performance on the widely\nused Penn Treebank corpus. We show that guaranteeing approximately equidistant\n(nearly orthogonal) vector representations for unique discrete inputs is enough\nto provide the neural network model with enough information to learn --and make\nuse-- of distributed representations for these inputs. \n\n"}
{"id": "1807.01395", "contents": "Title: Patient representation learning and interpretable evaluation using\n  clinical notes Abstract: We have three contributions in this work: 1. We explore the utility of a\nstacked denoising autoencoder and a paragraph vector model to learn\ntask-independent dense patient representations directly from clinical notes. To\nanalyze if these representations are transferable across tasks, we evaluate\nthem in multiple supervised setups to predict patient mortality, primary\ndiagnostic and procedural category, and gender. We compare their performance\nwith sparse representations obtained from a bag-of-words model. We observe that\nthe learned generalized representations significantly outperform the sparse\nrepresentations when we have few positive instances to learn from, and there is\nan absence of strong lexical features. 2. We compare the model performance of\nthe feature set constructed from a bag of words to that obtained from medical\nconcepts. In the latter case, concepts represent problems, treatments, and\ntests. We find that concept identification does not improve the classification\nperformance. 3. We propose novel techniques to facilitate model\ninterpretability. To understand and interpret the representations, we explore\nthe best encoded features within the patient representations obtained from the\nautoencoder model. Further, we calculate feature sensitivity across two\nnetworks to identify the most significant input features for different\nclassification tasks when we use these pretrained representations as the\nsupervised input. We successfully extract the most influential features for the\npipeline using this technique. \n\n"}
{"id": "1807.01763", "contents": "Title: Seq2RDF: An end-to-end application for deriving Triples from Natural\n  Language Text Abstract: We present an end-to-end approach that takes unstructured textual input and\ngenerates structured output compliant with a given vocabulary. Inspired by\nrecent successes in neural machine translation, we treat the triples within a\ngiven knowledge graph as an independent graph language and propose an\nencoder-decoder framework with an attention mechanism that leverages knowledge\ngraph embeddings. Our model learns the mapping from natural language text to\ntriple representation in the form of subject-predicate-object using the\nselected knowledge graph vocabulary. Experiments on three different data sets\nshow that we achieve competitive F1-Measures over the baselines using our\nsimple yet effective approach. A demo video is included. \n\n"}
{"id": "1807.01956", "contents": "Title: Neural Language Codes for Multilingual Acoustic Models Abstract: Multilingual Speech Recognition is one of the most costly AI problems,\nbecause each language (7,000+) and even different accents require their own\nacoustic models to obtain best recognition performance. Even though they all\nuse the same phoneme symbols, each language and accent imposes its own coloring\nor \"twang\". Many adaptive approaches have been proposed, but they require\nfurther training, additional data and generally are inferior to monolingually\ntrained models. In this paper, we propose a different approach that uses a\nlarge multilingual model that is \\emph{modulated} by the codes generated by an\nancillary network that learns to code useful differences between the \"twangs\"\nor human language.\n  We use Meta-Pi networks to have one network (the language code net) gate the\nactivity of neurons in another (the acoustic model nets). Our results show that\nduring recognition multilingual Meta-Pi networks quickly adapt to the proper\nlanguage coloring without retraining or new data, and perform better than\nmonolingually trained networks. The model was evaluated by training acoustic\nmodeling nets and modulating language code nets jointly and optimize them for\nbest recognition performance. \n\n"}
{"id": "1807.02658", "contents": "Title: Robust and Scalable Differentiable Neural Computer for Question\n  Answering Abstract: Deep learning models are often not easily adaptable to new tasks and require\ntask-specific adjustments. The differentiable neural computer (DNC), a\nmemory-augmented neural network, is designed as a general problem solver which\ncan be used in a wide range of tasks. But in reality, it is hard to apply this\nmodel to new tasks. We analyze the DNC and identify possible improvements\nwithin the application of question answering. This motivates a more robust and\nscalable DNC (rsDNC). The objective precondition is to keep the general\ncharacter of this model intact while making its application more reliable and\nspeeding up its required training time. The rsDNC is distinguished by a more\nrobust training, a slim memory unit and a bidirectional architecture. We not\nonly achieve new state-of-the-art performance on the bAbI task, but also\nminimize the performance variance between different initializations.\nFurthermore, we demonstrate the simplified applicability of the rsDNC to new\ntasks with passable results on the CNN RC task without adaptions. \n\n"}
{"id": "1807.03004", "contents": "Title: Towards Enhancing Lexical Resource and Using Sense-annotations of\n  OntoSenseNet for Sentiment Analysis Abstract: This paper illustrates the interface of the tool we developed for crowd\nsourcing and we explain the annotation procedure in detail. Our tool is named\nas 'Parupalli Padajaalam' which means web of words by Parupalli. The aim of\nthis tool is to populate the OntoSenseNet, sentiment polarity annotated Telugu\nresource. Recent works have shown the importance of word-level annotations on\nsentiment analysis. With this as basis, we aim to analyze the importance of\nsense-annotations obtained from OntoSenseNet in performing the task of\nsentiment analysis. We explain the fea- tures extracted from OntoSenseNet\n(Telugu). Furthermore we compute and explain the adverbial class distribution\nof verbs in OntoSenseNet. This task is known to aid in disambiguating\nword-senses which helps in enhancing the performance of word-sense\ndisambiguation (WSD) task(s). \n\n"}
{"id": "1807.03396", "contents": "Title: On Training Recurrent Networks with Truncated Backpropagation Through\n  Time in Speech Recognition Abstract: Recurrent neural networks have been the dominant models for many speech and\nlanguage processing tasks. However, we understand little about the behavior and\nthe class of functions recurrent networks can realize. Moreover, the heuristics\nused during training complicate the analyses. In this paper, we study recurrent\nnetworks' ability to learn long-term dependency in the context of speech\nrecognition. We consider two decoding approaches, online and batch decoding,\nand show the classes of functions to which the decoding approaches correspond.\nWe then draw a connection between batch decoding and a popular training\napproach for recurrent networks, truncated backpropagation through time.\nChanging the decoding approach restricts the amount of past history recurrent\nnetworks can use for prediction, allowing us to analyze their ability to\nremember. Empirically, we utilize long-term dependency in subphonetic states,\nphonemes, and words, and show how the design decisions, such as the decoding\napproach, lookahead, context frames, and consecutive prediction, characterize\nthe behavior of recurrent networks. Finally, we draw a connection between\nMarkov processes and vanishing gradients. These results have implications for\nstudying the long-term dependency in speech data and how these properties are\nlearned by recurrent networks. \n\n"}
{"id": "1807.04148", "contents": "Title: JeSemE: A Website for Exploring Diachronic Changes in Word Meaning and\n  Emotion Abstract: We here introduce a substantially extended version of JeSemE, an interactive\nwebsite for visually exploring computationally derived time-variant information\non word meanings and lexical emotions assembled from five large diachronic text\ncorpora. JeSemE is designed for scholars in the (digital) humanities as an\nalternative to consulting manually compiled, printed dictionaries for such\ninformation (if available at all). This tool uniquely combines state-of-the-art\ndistributional semantics with a nuanced model of human emotions, two\ninformation streams we deem beneficial for a data-driven interpretation of\ntexts in the humanities. \n\n"}
{"id": "1807.04172", "contents": "Title: Linear Transformations for Cross-lingual Semantic Textual Similarity Abstract: Cross-lingual semantic textual similarity systems estimate the degree of the\nmeaning similarity between two sentences, each in a different language.\nState-of-the-art algorithms usually employ machine translation and combine vast\namount of features, making the approach strongly supervised, resource rich, and\ndifficult to use for poorly-resourced languages.\n  In this paper, we study linear transformations, which project monolingual\nsemantic spaces into a shared space using bilingual dictionaries. We propose a\nnovel transformation, which builds on the best ideas from prior works. We\nexperiment with unsupervised techniques for sentence similarity based only on\nsemantic spaces and we show they can be significantly improved by the word\nweighting. Our transformation outperforms other methods and together with word\nweighting leads to very promising results on several datasets in different\nlanguages. \n\n"}
{"id": "1807.05154", "contents": "Title: Deep Enhanced Representation for Implicit Discourse Relation Recognition Abstract: Implicit discourse relation recognition is a challenging task as the relation\nprediction without explicit connectives in discourse parsing needs\nunderstanding of text spans and cannot be easily derived from surface features\nfrom the input sentence pairs. Thus, properly representing the text is very\ncrucial to this task. In this paper, we propose a model augmented with\ndifferent grained text representations, including character, subword, word,\nsentence, and sentence pair levels. The proposed deeper model is evaluated on\nthe benchmark treebank and achieves state-of-the-art accuracy with greater than\n48% in 11-way and $F_1$ score greater than 50% in 4-way classifications for the\nfirst time according to our best knowledge. \n\n"}
{"id": "1807.06270", "contents": "Title: Bench-Marking Information Extraction in Semi-Structured Historical\n  Handwritten Records Abstract: In this report, we present our findings from benchmarking experiments for\ninformation extraction on historical handwritten marriage records Esposalles\nfrom IEHHR - ICDAR 2017 robust reading competition. The information extraction\nis modeled as semantic labeling of the sequence across 2 set of labels. This\ncan be achieved by sequentially or jointly applying handwritten text\nrecognition (HTR) and named entity recognition (NER). We deploy a pipeline\napproach where first we use state-of-the-art HTR and use its output as input\nfor NER. We show that given low resource setup and simple structure of the\nrecords, high performance of HTR ensures overall high performance. We explore\nthe various configurations of conditional random fields and neural networks to\nbenchmark NER on given certain noisy input. The best model on 10-fold\ncross-validation as well as blind test data uses n-gram features with\nbidirectional long short-term memory. \n\n"}
{"id": "1807.06610", "contents": "Title: Learning Noise-Invariant Representations for Robust Speech Recognition Abstract: Despite rapid advances in speech recognition, current models remain brittle\nto superficial perturbations to their inputs. Small amounts of noise can\ndestroy the performance of an otherwise state-of-the-art model. To harden\nmodels against background noise, practitioners often perform data augmentation,\nadding artificially-noised examples to the training set, carrying over the\noriginal label. In this paper, we hypothesize that a clean example and its\nsuperficially perturbed counterparts shouldn't merely map to the same class ---\nthey should map to the same representation. We propose\ninvariant-representation-learning (IRL): At each training iteration, for each\ntraining example,we sample a noisy counterpart. We then apply a penalty term to\ncoerce matched representations at each layer (above some chosen layer). Our key\nresults, demonstrated on the Librispeech dataset are the following: (i) IRL\nsignificantly reduces character error rates (CER) on both 'clean' (3.3% vs\n6.5%) and 'other' (11.0% vs 18.1%) test sets; (ii) on several out-of-domain\nnoise settings (different from those seen during training), IRL's benefits are\neven more pronounced. Careful ablations confirm that our results are not simply\ndue to shrinking activations at the chosen layers. \n\n"}
{"id": "1807.06683", "contents": "Title: Improving Named Entity Recognition by Jointly Learning to Disambiguate\n  Morphological Tags Abstract: Previous studies have shown that linguistic features of a word such as\npossession, genitive or other grammatical cases can be employed in word\nrepresentations of a named entity recognition (NER) tagger to improve the\nperformance for morphologically rich languages. However, these taggers require\nexternal morphological disambiguation (MD) tools to function which are hard to\nobtain or non-existent for many languages. In this work, we propose a model\nwhich alleviates the need for such disambiguators by jointly learning NER and\nMD taggers in languages for which one can provide a list of candidate\nmorphological analyses. We show that this can be done independent of the\nmorphological annotation schemes, which differ among languages. Our experiments\nemploying three different model architectures that join these two tasks show\nthat joint learning improves NER performance. Furthermore, the morphological\ndisambiguator's performance is shown to be competitive. \n\n"}
{"id": "1807.07147", "contents": "Title: Guess who? Multilingual approach for the automated generation of\n  author-stylized poetry Abstract: This paper addresses the problem of stylized text generation in a\nmultilingual setup. A version of a language model based on a long short-term\nmemory (LSTM) artificial neural network with extended phonetic and semantic\nembeddings is used for stylized poetry generation. The quality of the resulting\npoems generated by the network is estimated through bilingual evaluation\nunderstudy (BLEU), a survey and a new cross-entropy based metric that is\nsuggested for the problems of such type. The experiments show that the proposed\nmodel consistently outperforms random sample and vanilla-LSTM baselines, humans\nalso tend to associate machine generated texts with the target author. \n\n"}
{"id": "1807.07828", "contents": "Title: Towards Functorial Language-Games Abstract: In categorical compositional semantics of natural language one studies\nfunctors from a category of grammatical derivations (such as a Lambek pregroup)\nto a semantic category (such as real vector spaces). We compositionally build\ngame-theoretic semantics of sentences by taking the semantic category to be the\ncategory whose morphisms are open games. This requires some modifications to\nthe grammar category to compensate for the failure of open games to form a\ncompact closed category. We illustrate the theory using simple examples of\nWittgenstein's language-games. \n\n"}
{"id": "1807.08204", "contents": "Title: Towards Neural Theorem Proving at Scale Abstract: Neural models combining representation learning and reasoning in an\nend-to-end trainable manner are receiving increasing interest. However, their\nuse is severely limited by their computational complexity, which renders them\nunusable on real world datasets. We focus on the Neural Theorem Prover (NTP)\nmodel proposed by Rockt{\\\"{a}}schel and Riedel (2017), a continuous relaxation\nof the Prolog backward chaining algorithm where unification between terms is\nreplaced by the similarity between their embedding representations. For\nanswering a given query, this model needs to consider all possible proof paths,\nand then aggregate results - this quickly becomes infeasible even for small\nKnowledge Bases (KBs). We observe that we can accurately approximate the\ninference process in this model by considering only proof paths associated with\nthe highest proof scores. This enables inference and learning on previously\nimpracticable KBs. \n\n"}
{"id": "1807.08587", "contents": "Title: Deep Dialog Act Recognition using Multiple Token, Segment, and Context\n  Information Representations Abstract: Dialog act (DA) recognition is a task that has been widely explored over the\nyears. Recently, most approaches to the task explored different DNN\narchitectures to combine the representations of the words in a segment and\ngenerate a segment representation that provides cues for intention. In this\nstudy, we explore means to generate more informative segment representations,\nnot only by exploring different network architectures, but also by considering\ndifferent token representations, not only at the word level, but also at the\ncharacter and functional levels. At the word level, in addition to the commonly\nused uncontextualized embeddings, we explore the use of contextualized\nrepresentations, which provide information concerning word sense and segment\nstructure. Character-level tokenization is important to capture\nintention-related morphological aspects that cannot be captured at the word\nlevel. Finally, the functional level provides an abstraction from words, which\nshifts the focus to the structure of the segment. We also explore approaches to\nenrich the segment representation with context information from the history of\nthe dialog, both in terms of the classifications of the surrounding segments\nand the turn-taking history. This kind of information has already been proved\nimportant for the disambiguation of DAs in previous studies. Nevertheless, we\nare able to capture additional information by considering a summary of the\ndialog history and a wider turn-taking context. By combining the best\napproaches at each step, we achieve results that surpass the previous\nstate-of-the-art on generic DA recognition on both SwDA and MRDA, two of the\nmost widely explored corpora for the task. Furthermore, by considering both\npast and future context, simulating annotation scenario, our approach achieves\na performance similar to that of a human annotator on SwDA and surpasses it on\nMRDA. \n\n"}
{"id": "1807.09639", "contents": "Title: Finding Better Subword Segmentation for Neural Machine Translation Abstract: For different language pairs, word-level neural machine translation (NMT)\nmodels with a fixed-size vocabulary suffer from the same problem of\nrepresenting out-of-vocabulary (OOV) words. The common practice usually\nreplaces all these rare or unknown words with a <UNK> token, which limits the\ntranslation performance to some extent. Most of recent work handled such a\nproblem by splitting words into characters or other specially extracted subword\nunits to enable open-vocabulary translation. Byte pair encoding (BPE) is one of\nthe successful attempts that has been shown extremely competitive by providing\neffective subword segmentation for NMT systems. In this paper, we extend the\nBPE style segmentation to a general unsupervised framework with three\nstatistical measures: frequency (FRQ), accessor variety (AV) and description\nlength gain (DLG). We test our approach on two translation tasks: German to\nEnglish and Chinese to English. The experimental results show that AV and DLG\nenhanced systems outperform the FRQ baseline in the frequency weighted schemes\nat different significant levels. \n\n"}
{"id": "1807.09875", "contents": "Title: Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a\n  Structured Variational Autoencoder Abstract: Human annotation for syntactic parsing is expensive, and large resources are\navailable only for a fraction of languages. A question we ask is whether one\ncan leverage abundant unlabeled texts to improve syntactic parsers, beyond just\nusing the texts to obtain more generalisable lexical features (i.e. beyond word\nembeddings). To this end, we propose a novel latent-variable generative model\nfor semi-supervised syntactic dependency parsing. As exact inference is\nintractable, we introduce a differentiable relaxation to obtain approximate\nsamples and compute gradients with respect to the parser parameters. Our method\n(Differentiable Perturb-and-Parse) relies on differentiable dynamic programming\nover stochastically perturbed edge scores. We demonstrate effectiveness of our\napproach with experiments on English, French and Swedish. \n\n"}
{"id": "1807.09950", "contents": "Title: Variational Memory Encoder-Decoder Abstract: Introducing variability while maintaining coherence is a core task in\nlearning to generate utterances in conversation. Standard neural\nencoder-decoder models and their extensions using conditional variational\nautoencoder often result in either trivial or digressive responses. To overcome\nthis, we explore a novel approach that injects variability into neural\nencoder-decoder via the use of external memory as a mixture model, namely\nVariational Memory Encoder-Decoder (VMED). By associating each memory read with\na mode in the latent mixture distribution at each timestep, our model can\ncapture the variability observed in sequential data such as natural\nconversations. We empirically compare the proposed model against other recent\napproaches on various conversational datasets. The results show that VMED\nconsistently achieves significant improvement over others in both metric-based\nand qualitative evaluations. \n\n"}
{"id": "1807.10661", "contents": "Title: Concept Tagging for Natural Language Understanding: Two Decadelong\n  Algorithm Development Abstract: Concept tagging is a type of structured learning needed for natural language\nunderstanding (NLU) systems. In this task, meaning labels from a domain\nontology are assigned to word sequences. In this paper, we review the\nalgorithms developed over the last twenty five years. We perform a comparative\nevaluation of generative, discriminative and deep learning methods on two\npublic datasets. We report on the statistical variability performance\nmeasurements. The third contribution is the release of a repository of the\nalgorithms, datasets and recipes for NLU evaluation. \n\n"}
{"id": "1807.10675", "contents": "Title: Resource-Size matters: Improving Neural Named Entity Recognition with\n  Optimized Large Corpora Abstract: This study improves the performance of neural named entity recognition by a\nmargin of up to 11% in F-score on the example of a low-resource language like\nGerman, thereby outperforming existing baselines and establishing a new\nstate-of-the-art on each single open-source dataset. Rather than designing\ndeeper and wider hybrid neural architectures, we gather all available resources\nand perform a detailed optimization and grammar-dependent morphological\nprocessing consisting of lemmatization and part-of-speech tagging prior to\nexposing the raw data to any training process. We test our approach in a\nthreefold monolingual experimental setup of a) single, b) joint, and c)\noptimized training and shed light on the dependency of downstream-tasks on the\nsize of corpora used to compute word embeddings. \n\n"}
{"id": "1807.10805", "contents": "Title: Improving Neural Sequence Labelling using Additional Linguistic\n  Information Abstract: Sequence labelling is the task of assigning categorical labels to a data\nsequence. In Natural Language Processing, sequence labelling can be applied to\nvarious fundamental problems, such as Part of Speech (POS) tagging, Named\nEntity Recognition (NER), and Chunking. In this study, we propose a method to\nadd various linguistic features to the neural sequence framework to improve\nsequence labelling. Besides word level knowledge, sense embeddings are added to\nprovide semantic information. Additionally, selective readings of character\nembeddings are added to capture contextual as well as morphological features\nfor each word in a sentence. Compared to previous methods, these added\nlinguistic features allow us to design a more concise model and perform more\nefficient training. Our proposed architecture achieves state of the art results\non the benchmark datasets of POS, NER, and chunking. Moreover, the convergence\nrate of our model is significantly better than the previous state of the art\nmodels. \n\n"}
{"id": "1807.10984", "contents": "Title: Domain Robust Feature Extraction for Rapid Low Resource ASR Development Abstract: Developing a practical speech recognizer for a low resource language is\nchallenging, not only because of the (potentially unknown) properties of the\nlanguage, but also because test data may not be from the same domain as the\navailable training data. In this paper, we focus on the latter challenge, i.e.\ndomain mismatch, for systems trained using a sequence-based criterion. We\ndemonstrate the effectiveness of using a pre-trained English recognizer, which\nis robust to such mismatched conditions, as a domain normalizing feature\nextractor on a low resource language. In our example, we use Turkish\nConversational Speech and Broadcast News data. This enables rapid development\nof speech recognizers for new languages which can easily adapt to any domain.\nTesting in various cross-domain scenarios, we achieve relative improvements of\naround 25% in phoneme error rate, with improvements being around 50% for some\ndomains. \n\n"}
{"id": "1807.11227", "contents": "Title: YouTube AV 50K: An Annotated Corpus for Comments in Autonomous Vehicles Abstract: With one billion monthly viewers, and millions of users discussing and\nsharing opinions, comments below YouTube videos are rich sources of data for\nopinion mining and sentiment analysis. We introduce the YouTube AV 50K dataset,\na freely-available collections of more than 50,000 YouTube comments and\nmetadata below autonomous vehicle (AV)-related videos. We describe its creation\nprocess, its content and data format, and discuss its possible usages.\nEspecially, we do a case study of the first self-driving car fatality to\nevaluate the dataset, and show how we can use this dataset to better understand\npublic attitudes toward self-driving cars and public reactions to the accident.\nFuture developments of the dataset are also discussed. \n\n"}
{"id": "1807.11535", "contents": "Title: News Article Teaser Tweets and How to Generate Them Abstract: In this work, we define the task of teaser generation and provide an\nevaluation benchmark and baseline systems for the process of generating\nteasers. A teaser is a short reading suggestion for an article that is\nillustrative and includes curiosity-arousing elements to entice potential\nreaders to read particular news items. Teasers are one of the main vehicles for\ntransmitting news to social media users. We compile a novel dataset of teasers\nby systematically accumulating tweets and selecting those that conform to the\nteaser definition. We have compared a number of neural abstractive\narchitectures on the task of teaser generation and the overall best performing\nsystem is See et al.(2017)'s seq2seq with pointer network. \n\n"}
{"id": "1807.11567", "contents": "Title: Neural Sentence Embedding using Only In-domain Sentences for\n  Out-of-domain Sentence Detection in Dialog Systems Abstract: To ensure satisfactory user experience, dialog systems must be able to\ndetermine whether an input sentence is in-domain (ID) or out-of-domain (OOD).\nWe assume that only ID sentences are available as training data because\ncollecting enough OOD sentences in an unbiased way is a laborious and\ntime-consuming job. This paper proposes a novel neural sentence embedding\nmethod that represents sentences in a low-dimensional continuous vector space\nthat emphasizes aspects that distinguish ID cases from OOD cases. We first used\na large set of unlabeled text to pre-train word representations that are used\nto initialize neural sentence embedding. Then we used domain-category analysis\nas an auxiliary task to train neural sentence embedding for OOD sentence\ndetection. After the sentence representations were learned, we used them to\ntrain an autoencoder aimed at OOD sentence detection. We evaluated our method\nby experimentally comparing it to the state-of-the-art methods in an\neight-domain dialog system; our proposed method achieved the highest accuracy\nin all tests. \n\n"}
{"id": "1807.11605", "contents": "Title: Doubly Attentive Transformer Machine Translation Abstract: In this paper a doubly attentive transformer machine translation model\n(DATNMT) is presented in which a doubly-attentive transformer decoder normally\njoins spatial visual features obtained via pretrained convolutional neural\nnetworks, conquering any gap between image captioning and translation. In this\nframework, the transformer decoder figures out how to take care of\nsource-language words and parts of an image freely by methods for two separate\nattention components in an Enhanced Multi-Head Attention Layer of doubly\nattentive transformer, as it generates words in the target language. We find\nthat the proposed model can effectively exploit not just the scarce multimodal\nmachine translation data, but also large general-domain text-only machine\ntranslation corpora, or image-text image captioning corpora. The experimental\nresults show that the proposed doubly-attentive transformer-decoder performs\nbetter than a single-decoder transformer model, and gives the state-of-the-art\nresults in the English-German multimodal machine translation task. \n\n"}
{"id": "1807.11679", "contents": "Title: Wasserstein GAN and Waveform Loss-based Acoustic Model Training for\n  Multi-speaker Text-to-Speech Synthesis Systems Using a WaveNet Vocoder Abstract: Recent neural networks such as WaveNet and sampleRNN that learn directly from\nspeech waveform samples have achieved very high-quality synthetic speech in\nterms of both naturalness and speaker similarity even in multi-speaker\ntext-to-speech synthesis systems. Such neural networks are being used as an\nalternative to vocoders and hence they are often called neural vocoders. The\nneural vocoder uses acoustic features as local condition parameters, and these\nparameters need to be accurately predicted by another acoustic model. However,\nit is not yet clear how to train this acoustic model, which is problematic\nbecause the final quality of synthetic speech is significantly affected by the\nperformance of the acoustic model. Significant degradation happens, especially\nwhen predicted acoustic features have mismatched characteristics compared to\nnatural ones. In order to reduce the mismatched characteristics between natural\nand generated acoustic features, we propose frameworks that incorporate either\na conditional generative adversarial network (GAN) or its variant, Wasserstein\nGAN with gradient penalty (WGAN-GP), into multi-speaker speech synthesis that\nuses the WaveNet vocoder. We also extend the GAN frameworks and use the\ndiscretized mixture logistic loss of a well-trained WaveNet in addition to mean\nsquared error and adversarial losses as parts of objective functions.\nExperimental results show that acoustic models trained using the WGAN-GP\nframework using back-propagated discretized-mixture-of-logistics (DML) loss\nachieves the highest subjective evaluation scores in terms of both quality and\nspeaker similarity. \n\n"}
{"id": "1808.00300", "contents": "Title: Learning Visual Question Answering by Bootstrapping Hard Attention Abstract: Attention mechanisms in biological perception are thought to select subsets\nof perceptual information for more sophisticated processing which would be\nprohibitive to perform on all sensory inputs. In computer vision, however,\nthere has been relatively little exploration of hard attention, where some\ninformation is selectively ignored, in spite of the success of soft attention,\nwhere information is re-weighted and aggregated, but never filtered out. Here,\nwe introduce a new approach for hard attention and find it achieves very\ncompetitive performance on a recently-released visual question answering\ndatasets, equalling and in some cases surpassing similar soft attention\narchitectures while entirely ignoring some features. Even though the hard\nattention mechanism is thought to be non-differentiable, we found that the\nfeature magnitudes correlate with semantic relevance, and provide a useful\nsignal for our mechanism's attentional selection criterion. Because hard\nattention selects important features of the input information, it can also be\nmore efficient than analogous soft attention mechanisms. This is especially\nimportant for recent approaches that use non-local pairwise operations, whereby\ncomputational and memory costs are quadratic in the size of the set of\nfeatures. \n\n"}
{"id": "1808.00957", "contents": "Title: SWDE : A Sub-Word And Document Embedding Based Engine for Clickbait\n  Detection Abstract: In order to expand their reach and increase website ad revenue, media outlets\nhave started using clickbait techniques to lure readers to click on articles on\ntheir digital platform. Having successfully enticed the user to open the\narticle, the article fails to satiate his curiosity serving only to boost\nclick-through rates. Initial methods for this task were dependent on feature\nengineering, which varies with each dataset. Industry systems have relied on an\nexhaustive set of rules to get the job done. Neural networks have barely been\nexplored to perform this task. We propose a novel approach considering\ndifferent textual embeddings of a news headline and the related article. We\ngenerate sub-word level embeddings of the title using Convolutional Neural\nNetworks and use them to train a bidirectional LSTM architecture. An attention\nlayer allows for calculation of significance of each term towards the nature of\nthe post. We also generate Doc2Vec embeddings of the title and article text and\nmodel how they interact, following which it is concatenated with the output of\nthe previous component. Finally, this representation is passed through a neural\nnetwork to obtain a score for the headline. We test our model over 2538 posts\n(having trained it on 17000 records) and achieve an accuracy of 83.49%\noutscoring previous state-of-the-art approaches. \n\n"}
{"id": "1808.01216", "contents": "Title: A Multi-task Ensemble Framework for Emotion, Sentiment and Intensity\n  Prediction Abstract: In this paper, through multi-task ensemble framework we address three\nproblems of emotion and sentiment analysis i.e. \"emotion classification &\nintensity\", \"valence, arousal & dominance for emotion\" and \"valence & arousal}\nfor sentiment\". The underlying problems cover two granularities (i.e.\ncoarse-grained and fine-grained) and a diverse range of domains (i.e. tweets,\nFacebook posts, news headlines, blogs, letters etc.). The ensemble model aims\nto leverage the learned representations of three deep learning models (i.e.\nCNN, LSTM and GRU) and a hand-crafted feature representation for the\npredictions. Experimental results on the benchmark datasets show the efficacy\nof our proposed multi-task ensemble frameworks. We obtain the performance\nimprovement of 2-3 points on an average over single-task systems for most of\nthe problems and domains. \n\n"}
{"id": "1808.01410", "contents": "Title: Predicting Expressive Speaking Style From Text In End-To-End Speech\n  Synthesis Abstract: Global Style Tokens (GSTs) are a recently-proposed method to learn latent\ndisentangled representations of high-dimensional data. GSTs can be used within\nTacotron, a state-of-the-art end-to-end text-to-speech synthesis system, to\nuncover expressive factors of variation in speaking style. In this work, we\nintroduce the Text-Predicted Global Style Token (TP-GST) architecture, which\ntreats GST combination weights or style embeddings as \"virtual\" speaking style\nlabels within Tacotron. TP-GST learns to predict stylistic renderings from text\nalone, requiring neither explicit labels during training nor auxiliary inputs\nfor inference. We show that, when trained on a dataset of expressive speech,\nour system generates audio with more pitch and energy variation than two\nstate-of-the-art baseline models. We further demonstrate that TP-GSTs can\nsynthesize speech with background noise removed, and corroborate these analyses\nwith positive results on human-rated listener preference audiobook tasks.\nFinally, we demonstrate that multi-speaker TP-GST models successfully factorize\nspeaker identity and speaking style. We provide a website with audio samples\nfor each of our findings. \n\n"}
{"id": "1808.02772", "contents": "Title: Effective Character-augmented Word Embedding for Machine Reading\n  Comprehension Abstract: Machine reading comprehension is a task to model relationship between passage\nand query. In terms of deep learning framework, most of state-of-the-art models\nsimply concatenate word and character level representations, which has been\nshown suboptimal for the concerned task. In this paper, we empirically explore\ndifferent integration strategies of word and character embeddings and propose a\ncharacter-augmented reader which attends character-level representation to\naugment word embedding with a short list to improve word representations,\nespecially for rare words. Experimental results show that the proposed approach\nhelps the baseline model significantly outperform state-of-the-art baselines on\nvarious public benchmarks. \n\n"}
{"id": "1808.03703", "contents": "Title: LemmaTag: Jointly Tagging and Lemmatizing for Morphologically-Rich\n  Languages with BRNNs Abstract: We present LemmaTag, a featureless neural network architecture that jointly\ngenerates part-of-speech tags and lemmas for sentences by using bidirectional\nRNNs with character-level and word-level embeddings. We demonstrate that both\ntasks benefit from sharing the encoding part of the network, predicting tag\nsubcategories, and using the tagger output as an input to the lemmatizer. We\nevaluate our model across several languages with complex morphology, which\nsurpasses state-of-the-art accuracy in both part-of-speech tagging and\nlemmatization in Czech, German, and Arabic. \n\n"}
{"id": "1808.03976", "contents": "Title: Text Classification using Capsules Abstract: This paper presents an empirical exploration of the use of capsule networks\nfor text classification. While it has been shown that capsule networks are\neffective for image classification, their validity in the domain of text has\nnot been explored. In this paper, we show that capsule networks indeed have the\npotential for text classification and that they have several advantages over\nconvolutional neural networks. We further suggest a simple routing method that\neffectively reduces the computational complexity of dynamic routing. We\nutilized seven benchmark datasets to demonstrate that capsule networks, along\nwith the proposed routing method provide comparable results. \n\n"}
{"id": "1808.04091", "contents": "Title: Live Video Comment Generation Based on Surrounding Frames and Live\n  Comments Abstract: In this paper, we propose the task of live comment generation. Live comments\nare a new form of comments on videos, which can be regarded as a mixture of\ncomments and chats. A high-quality live comment should be not only relevant to\nthe video, but also interactive with other users. In this work, we first\nconstruct a new dataset for live comment generation. Then, we propose a novel\nend-to-end model to generate the human-like live comments by referring to the\nvideo and the other users' comments. Finally, we evaluate our model on the\nconstructed dataset. Experimental results show that our method can\nsignificantly outperform the baselines. \n\n"}
{"id": "1808.04122", "contents": "Title: A Capsule Network-based Embedding Model for Knowledge Graph Completion\n  and Search Personalization Abstract: In this paper, we introduce an embedding model, named CapsE, exploring a\ncapsule network to model relationship triples (subject, relation, object). Our\nCapsE represents each triple as a 3-column matrix where each column vector\nrepresents the embedding of an element in the triple. This 3-column matrix is\nthen fed to a convolution layer where multiple filters are operated to generate\ndifferent feature maps. These feature maps are reconstructed into corresponding\ncapsules which are then routed to another capsule to produce a continuous\nvector. The length of this vector is used to measure the plausibility score of\nthe triple. Our proposed CapsE obtains better performance than previous\nstate-of-the-art embedding models for knowledge graph completion on two\nbenchmark datasets WN18RR and FB15k-237, and outperforms strong search\npersonalization baselines on SEARCH17. \n\n"}
{"id": "1808.04334", "contents": "Title: Angular-Based Word Meta-Embedding Learning Abstract: Ensembling word embeddings to improve distributed word representations has\nshown good success for natural language processing tasks in recent years. These\napproaches either carry out straightforward mathematical operations over a set\nof vectors or use unsupervised learning to find a lower-dimensional\nrepresentation. This work compares meta-embeddings trained for different\nlosses, namely loss functions that account for angular distance between the\nreconstructed embedding and the target and those that account normalized\ndistances based on the vector length. We argue that meta-embeddings are better\nto treat the ensemble set equally in unsupervised learning as the respective\nquality of each embedding is unknown for upstream tasks prior to\nmeta-embedding. We show that normalization methods that account for this such\nas cosine and KL-divergence objectives outperform meta-embedding trained on\nstandard $\\ell_1$ and $\\ell_2$ loss on \\textit{defacto} word similarity and\nrelatedness datasets and find it outperforms existing meta-learning strategies. \n\n"}
{"id": "1808.04339", "contents": "Title: Disentangled Representation Learning for Non-Parallel Text Style\n  Transfer Abstract: This paper tackles the problem of disentangling the latent variables of style\nand content in language models. We propose a simple yet effective approach,\nwhich incorporates auxiliary multi-task and adversarial objectives, for label\nprediction and bag-of-words prediction, respectively. We show, both\nqualitatively and quantitatively, that the style and content are indeed\ndisentangled in the latent space. This disentangled latent representation\nlearning method is applied to style transfer on non-parallel corpora. We\nachieve substantially better results in terms of transfer accuracy, content\npreservation and language fluency, in comparison to previous state-of-the-art\napproaches. \n\n"}
{"id": "1808.04364", "contents": "Title: D-PAGE: Diverse Paraphrase Generation Abstract: In this paper, we investigate the diversity aspect of paraphrase generation.\nPrior deep learning models employ either decoding methods or add random input\nnoise for varying outputs. We propose a simple method Diverse Paraphrase\nGeneration (D-PAGE), which extends neural machine translation (NMT) models to\nsupport the generation of diverse paraphrases with implicit rewriting patterns.\nOur experimental results on two real-world benchmark datasets demonstrate that\nour model generates at least one order of magnitude more diverse outputs than\nthe baselines in terms of a new evaluation metric Jeffrey's Divergence. We have\nalso conducted extensive experiments to understand various properties of our\nmodel with a focus on diversity. \n\n"}
{"id": "1808.04525", "contents": "Title: Discrete Structural Planning for Neural Machine Translation Abstract: Structural planning is important for producing long sentences, which is a\nmissing part in current language generation models. In this work, we add a\nplanning phase in neural machine translation to control the coarse structure of\noutput sentences. The model first generates some planner codes, then predicts\nreal output words conditioned on them. The codes are learned to capture the\ncoarse structure of the target sentence. In order to obtain the codes, we\ndesign an end-to-end neural network with a discretization bottleneck, which\npredicts the simplified part-of-speech tags of target sentences. Experiments\nshow that the translation performance are generally improved by planning ahead.\nWe also find that translations with different structures can be obtained by\nmanipulating the planner codes. \n\n"}
{"id": "1808.04865", "contents": "Title: Top-Down Tree Structured Text Generation Abstract: Text generation is a fundamental building block in natural language\nprocessing tasks. Existing sequential models performs autoregression directly\nover the text sequence and have difficulty generating long sentences of complex\nstructures. This paper advocates a simple approach that treats sentence\ngeneration as a tree-generation task. By explicitly modelling syntactic\nstructures in a constituent syntactic tree and performing top-down,\nbreadth-first tree generation, our model fixes dependencies appropriately and\nperforms implicit global planning. This is in contrast to transition-based\ndepth-first generation process, which has difficulty dealing with incomplete\ntexts when parsing and also does not incorporate future contexts in planning.\nOur preliminary results on two generation tasks and one parsing task\ndemonstrate that this is an effective strategy. \n\n"}
{"id": "1808.05505", "contents": "Title: Paraphrase Thought: Sentence Embedding Module Imitating Human Language\n  Recognition Abstract: Sentence embedding is an important research topic in natural language\nprocessing. It is essential to generate a good embedding vector that fully\nreflects the semantic meaning of a sentence in order to achieve an enhanced\nperformance for various natural language processing tasks, such as machine\ntranslation and document classification. Thus far, various sentence embedding\nmodels have been proposed, and their feasibility has been demonstrated through\ngood performances on tasks following embedding, such as sentiment analysis and\nsentence classification. However, because the performances of sentence\nclassification and sentiment analysis can be enhanced by using a simple\nsentence representation method, it is not sufficient to claim that these models\nfully reflect the meanings of sentences based on good performances for such\ntasks. In this paper, inspired by human language recognition, we propose the\nfollowing concept of semantic coherence, which should be satisfied for a good\nsentence embedding method: similar sentences should be located close to each\nother in the embedding space. Then, we propose the Paraphrase-Thought\n(P-thought) model to pursue semantic coherence as much as possible.\nExperimental results on two paraphrase identification datasets (MS COCO and STS\nbenchmark) show that the P-thought models outperform the benchmarked sentence\nembedding methods. \n\n"}
{"id": "1808.05700", "contents": "Title: Augmenting Statistical Machine Translation with Subword Translation of\n  Out-of-Vocabulary Words Abstract: Most statistical machine translation systems cannot translate words that are\nunseen in the training data. However, humans can translate many classes of\nout-of-vocabulary (OOV) words (e.g., novel morphological variants,\nmisspellings, and compounds) without context by using orthographic clues.\nFollowing this observation, we describe and evaluate several general methods\nfor OOV translation that use only subword information. We pose the OOV\ntranslation problem as a standalone task and intrinsically evaluate our\napproaches on fourteen typologically diverse languages across varying resource\nlevels. Adding OOV translators to a statistical machine translation system\nyields consistent BLEU gains (0.5 points on average, and up to 2.0) for all\nfourteen languages, especially in low-resource scenarios. \n\n"}
{"id": "1808.06161", "contents": "Title: Hierarchical Neural Networks for Sequential Sentence Classification in\n  Medical Scientific Abstracts Abstract: Prevalent models based on artificial neural network (ANN) for sentence\nclassification often classify sentences in isolation without considering the\ncontext in which sentences appear. This hampers the traditional sentence\nclassification approaches to the problem of sequential sentence classification,\nwhere structured prediction is needed for better overall classification\nperformance. In this work, we present a hierarchical sequential labeling\nnetwork to make use of the contextual information within surrounding sentences\nto help classify the current sentence. Our model outperforms the\nstate-of-the-art results by 2%-3% on two benchmarking datasets for sequential\nsentence classification in medical scientific abstracts. \n\n"}
{"id": "1808.06167", "contents": "Title: Source-Critical Reinforcement Learning for Transferring Spoken Language\n  Understanding to a New Language Abstract: To deploy a spoken language understanding (SLU) model to a new language,\nlanguage transferring is desired to avoid the trouble of acquiring and labeling\na new big SLU corpus. Translating the original SLU corpus into the target\nlanguage is an attractive strategy. However, SLU corpora consist of plenty of\nsemantic labels (slots), which general-purpose translators cannot handle well,\nnot to mention additional culture differences. This paper focuses on the\nlanguage transferring task given a tiny in-domain parallel SLU corpus. The\nin-domain parallel corpus can be used as the first adaptation on the general\ntranslator. But more importantly, we show how to use reinforcement learning\n(RL) to further finetune the adapted translator, where translated sentences\nwith more proper slot tags receive higher rewards. We evaluate our approach on\nChinese to English language transferring for SLU systems. The experimental\nresults show that the generated English SLU corpus via adaptation and\nreinforcement learning gives us over 97% in the slot F1 score and over 84%\naccuracy in domain classification. It demonstrates the effectiveness of the\nproposed language transferring method. Compared with naive translation, our\nproposed method improves domain classification accuracy by relatively 22%, and\nthe slot filling F1 score by relatively more than 71%. \n\n"}
{"id": "1808.06497", "contents": "Title: Goal-oriented Dialogue Policy Learning from Failures Abstract: Reinforcement learning methods have been used for learning dialogue policies.\nHowever, learning an effective dialogue policy frequently requires\nprohibitively many conversations. This is partly because of the sparse rewards\nin dialogues, and the very few successful dialogues in early learning phase.\nHindsight experience replay (HER) enables learning from failures, but the\nvanilla HER is inapplicable to dialogue learning due to the implicit goals. In\nthis work, we develop two complex HER methods providing different trade-offs\nbetween complexity and performance, and, for the first time, enabled HER-based\ndialogue policy learning. Experiments using a realistic user simulator show\nthat our HER methods perform better than existing experience replay methods (as\napplied to deep Q-networks) in learning rate. \n\n"}
{"id": "1808.06640", "contents": "Title: Adversarial Removal of Demographic Attributes from Text Data Abstract: Recent advances in Representation Learning and Adversarial Training seem to\nsucceed in removing unwanted features from the learned representation. We show\nthat demographic information of authors is encoded in -- and can be recovered\nfrom -- the intermediate representations learned by text-based neural\nclassifiers. The implication is that decisions of classifiers trained on\ntextual data are not agnostic to -- and likely condition on -- demographic\nattributes. When attempting to remove such demographic information using\nadversarial training, we find that while the adversarial component achieves\nchance-level development-set accuracy during training, a post-hoc classifier,\ntrained on the encoded sentences from the first part, still manages to reach\nsubstantially higher classification accuracies on the same data. This behavior\nis consistent across several tasks, demographic properties and datasets. We\nexplore several techniques to improve the effectiveness of the adversarial\ncomponent. Our main conclusion is a cautionary one: do not rely on the\nadversarial training to achieve invariant representation to sensitive features. \n\n"}
{"id": "1808.06810", "contents": "Title: The Influence of Down-Sampling Strategies on SVD Word Embedding\n  Stability Abstract: The stability of word embedding algorithms, i.e., the consistency of the word\nrepresentations they reveal when trained repeatedly on the same data set, has\nrecently raised concerns. We here compare word embedding algorithms on three\ncorpora of different sizes, and evaluate both their stability and accuracy. We\nfind strong evidence that down-sampling strategies (used as part of their\ntraining procedures) are particularly influential for the stability of\nSVDPPMI-type embeddings. This finding seems to explain diverging reports on\ntheir stability and lead us to a simple modification which provides superior\nstability as well as accuracy on par with skip-gram embeddings. \n\n"}
{"id": "1808.07016", "contents": "Title: Gaussian Word Embedding with a Wasserstein Distance Loss Abstract: Compared with word embedding based on point representation,\ndistribution-based word embedding shows more flexibility in expressing\nuncertainty and therefore embeds richer semantic information when representing\nwords. The Wasserstein distance provides a natural notion of dissimilarity with\nprobability measures and has a closed-form solution when measuring the distance\nbetween two Gaussian distributions. Therefore, with the aim of representing\nwords in a highly efficient way, we propose to operate a Gaussian word\nembedding model with a loss function based on the Wasserstein distance. Also,\nexternal information from ConceptNet will be used to semi-supervise the results\nof the Gaussian word embedding. Thirteen datasets from the word similarity\ntask, together with one from the word entailment task, and six datasets from\nthe downstream document classification task will be evaluated in this paper to\ntest our hypothesis. \n\n"}
{"id": "1808.07042", "contents": "Title: CoQA: A Conversational Question Answering Challenge Abstract: Humans gather information by engaging in conversations involving a series of\ninterconnected questions and answers. For machines to assist in information\ngathering, it is therefore essential to enable them to answer conversational\nquestions. We introduce CoQA, a novel dataset for building Conversational\nQuestion Answering systems. Our dataset contains 127k questions with answers,\nobtained from 8k conversations about text passages from seven diverse domains.\nThe questions are conversational, and the answers are free-form text with their\ncorresponding evidence highlighted in the passage. We analyze CoQA in depth and\nshow that conversational questions have challenging phenomena not present in\nexisting reading comprehension datasets, e.g., coreference and pragmatic\nreasoning. We evaluate strong conversational and reading comprehension models\non CoQA. The best system obtains an F1 score of 65.4%, which is 23.4 points\nbehind human performance (88.8%), indicating there is ample room for\nimprovement. We launch CoQA as a challenge to the community at\nhttp://stanfordnlp.github.io/coqa/ \n\n"}
{"id": "1808.07104", "contents": "Title: Aiming to Know You Better Perhaps Makes Me a More Engaging Dialogue\n  Partner Abstract: There have been several attempts to define a plausible motivation for a\nchit-chat dialogue agent that can lead to engaging conversations. In this work,\nwe explore a new direction where the agent specifically focuses on discovering\ninformation about its interlocutor. We formalize this approach by defining a\nquantitative metric. We propose an algorithm for the agent to maximize it. We\nvalidate the idea with human evaluation where our system outperforms various\nbaselines. We demonstrate that the metric indeed correlates with the human\njudgments of engagingness. \n\n"}
{"id": "1808.07599", "contents": "Title: Structured Interpretation of Temporal Relations Abstract: Temporal relations between events and time expressions in a document are\noften modeled in an unstructured manner where relations between individual\npairs of time expressions and events are considered in isolation. This often\nresults in inconsistent and incomplete annotation and computational modeling.\nWe propose a novel annotation approach where events and time expressions in a\ndocument form a dependency tree in which each dependency relation corresponds\nto an instance of temporal anaphora where the antecedent is the parent and the\nanaphor is the child. We annotate a corpus of 235 documents using this approach\nin the two genres of news and narratives, with 48 documents doubly annotated.\nWe report a stable and high inter-annotator agreement on the doubly annotated\nsubset, validating our approach, and perform a quantitative comparison between\nthe two genres of the entire corpus. We make this corpus publicly available. \n\n"}
{"id": "1808.07624", "contents": "Title: Exploiting Rich Syntactic Information for Semantic Parsing with\n  Graph-to-Sequence Model Abstract: Existing neural semantic parsers mainly utilize a sequence encoder, i.e., a\nsequential LSTM, to extract word order features while neglecting other valuable\nsyntactic information such as dependency graph or constituent trees. In this\npaper, we first propose to use the \\textit{syntactic graph} to represent three\ntypes of syntactic information, i.e., word order, dependency and constituency\nfeatures. We further employ a graph-to-sequence model to encode the syntactic\ngraph and decode a logical form. Experimental results on benchmark datasets\nshow that our model is comparable to the state-of-the-art on Jobs640, ATIS and\nGeo880. Experimental results on adversarial examples demonstrate the robustness\nof the model is also improved by encoding more syntactic information. \n\n"}
{"id": "1808.07982", "contents": "Title: Proximal Policy Optimization and its Dynamic Version for Sequence\n  Generation Abstract: In sequence generation task, many works use policy gradient for model\noptimization to tackle the intractable backpropagation issue when maximizing\nthe non-differentiable evaluation metrics or fooling the discriminator in\nadversarial learning. In this paper, we replace policy gradient with proximal\npolicy optimization (PPO), which is a proved more efficient reinforcement\nlearning algorithm, and propose a dynamic approach for PPO (PPO-dynamic). We\ndemonstrate the efficacy of PPO and PPO-dynamic on conditional sequence\ngeneration tasks including synthetic experiment and chit-chat chatbot. The\nresults show that PPO and PPO-dynamic can beat policy gradient by stability and\nperformance. \n\n"}
{"id": "1808.08270", "contents": "Title: Robust Text Classifier on Test-Time Budgets Abstract: We propose a generic and interpretable learning framework for building robust\ntext classification model that achieves accuracy comparable to full models\nunder test-time budget constraints. Our approach learns a selector to identify\nwords that are relevant to the prediction tasks and passes them to the\nclassifier for processing. The selector is trained jointly with the classifier\nand directly learns to incorporate with the classifier. We further propose a\ndata aggregation scheme to improve the robustness of the classifier. Our\nlearning framework is general and can be incorporated with any type of text\nclassification model. On real-world data, we show that the proposed approach\nimproves the performance of a given classifier and speeds up the model with a\nmere loss in accuracy performance. \n\n"}
{"id": "1808.08437", "contents": "Title: Meta-Learning for Low-Resource Neural Machine Translation Abstract: In this paper, we propose to extend the recently introduced model-agnostic\nmeta-learning algorithm (MAML) for low-resource neural machine translation\n(NMT). We frame low-resource translation as a meta-learning problem, and we\nlearn to adapt to low-resource languages based on multilingual high-resource\nlanguage tasks. We use the universal lexical\nrepresentation~\\citep{gu2018universal} to overcome the input-output mismatch\nacross different languages. We evaluate the proposed meta-learning strategy\nusing eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt,\nNl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro,\nLv, Fi, Tr and Ko) as target tasks. We show that the proposed approach\nsignificantly outperforms the multilingual, transfer learning based\napproach~\\citep{zoph2016transfer} and enables us to train a competitive NMT\nsystem with only a fraction of training examples. For instance, the proposed\napproach can achieve as high as 22.04 BLEU on Romanian-English WMT'16 by seeing\nonly 16,000 translated words (~600 parallel sentences). \n\n"}
{"id": "1808.08493", "contents": "Title: Contextual Parameter Generation for Universal Neural Machine Translation Abstract: We propose a simple modification to existing neural machine translation (NMT)\nmodels that enables using a single universal model to translate between\nmultiple languages while allowing for language specific parameterization, and\nthat can also be used for domain adaptation. Our approach requires no changes\nto the model architecture of a standard NMT system, but instead introduces a\nnew component, the contextual parameter generator (CPG), that generates the\nparameters of the system (e.g., weights in a neural network). This parameter\ngenerator accepts source and target language embeddings as input, and generates\nthe parameters for the encoder and the decoder, respectively. The rest of the\nmodel remains unchanged and is shared across all languages. We show how this\nsimple modification enables the system to use monolingual data for training and\nalso perform zero-shot translation. We further show it is able to surpass\nstate-of-the-art performance for both the IWSLT-15 and IWSLT-17 datasets and\nthat the learned language embeddings are able to uncover interesting\nrelationships between languages. \n\n"}
{"id": "1808.08762", "contents": "Title: Sentence Embeddings in NLI with Iterative Refinement Encoders Abstract: Sentence-level representations are necessary for various NLP tasks. Recurrent\nneural networks have proven to be very effective in learning distributed\nrepresentations and can be trained efficiently on natural language inference\ntasks. We build on top of one such model and propose a hierarchy of BiLSTM and\nmax pooling layers that implements an iterative refinement strategy and yields\nstate of the art results on the SciTail dataset as well as strong results for\nSNLI and MultiNLI. We can show that the sentence embeddings learned in this way\ncan be utilized in a wide variety of transfer learning tasks, outperforming\nInferSent on 7 out of 10 and SkipThought on 8 out of 9 SentEval sentence\nembedding evaluation tasks. Furthermore, our model beats the InferSent model in\n8 out of 10 recently published SentEval probing tasks designed to evaluate\nsentence embeddings' ability to capture some of the important linguistic\nproperties of sentences. \n\n"}
{"id": "1808.09006", "contents": "Title: Back-Translation Sampling by Targeting Difficult Words in Neural Machine\n  Translation Abstract: Neural Machine Translation has achieved state-of-the-art performance for\nseveral language pairs using a combination of parallel and synthetic data.\nSynthetic data is often generated by back-translating sentences randomly\nsampled from monolingual data using a reverse translation model. While\nback-translation has been shown to be very effective in many cases, it is not\nentirely clear why. In this work, we explore different aspects of\nback-translation, and show that words with high prediction loss during training\nbenefit most from the addition of synthetic data. We introduce several\nvariations of sampling strategies targeting difficult-to-predict words using\nprediction losses and frequencies of words. In addition, we also target the\ncontexts of difficult words and sample sentences that are similar in context.\nExperimental results for the WMT news translation task show that our method\nimproves translation quality by up to 1.7 and 1.2 Bleu points over\nback-translation using random sampling for German-English and English-German,\nrespectively. \n\n"}
{"id": "1808.09029", "contents": "Title: Pyramidal Recurrent Unit for Language Modeling Abstract: LSTMs are powerful tools for modeling contextual information, as evidenced by\ntheir success at the task of language modeling. However, modeling contexts in\nvery high dimensional space can lead to poor generalizability. We introduce the\nPyramidal Recurrent Unit (PRU), which enables learning representations in high\ndimensional space with more generalization power and fewer parameters. PRUs\nreplace the linear transformation in LSTMs with more sophisticated interactions\nincluding pyramidal and grouped linear transformations. This architecture gives\nstrong results on word-level language modeling while reducing the number of\nparameters significantly. In particular, PRU improves the perplexity of a\nrecent state-of-the-art language model Merity et al. (2018) by up to 1.3 points\nwhile learning 15-20% fewer parameters. For similar number of model parameters,\nPRU outperforms all previous RNN models that exploit different gating\nmechanisms and transformations. We provide a detailed examination of the PRU\nand its behavior on the language modeling tasks. Our code is open-source and\navailable at https://sacmehta.github.io/PRU/ \n\n"}
{"id": "1808.09037", "contents": "Title: Measuring the Volatility of the Political agenda in Public Opinion and\n  News Media Abstract: Recent election surprises, regime changes, and political shocks indicate that\npolitical agendas have become more fast-moving and volatile. The ability to\nmeasure the complex dynamics of agenda change and capture the nature and extent\nof volatility in political systems is therefore more crucial than ever before.\nThis study proposes a definition and operationalization of volatility that\ncombines insights from political science, communications, information theory,\nand computational techniques. The proposed measures of fractionalization and\nagenda change encompass the shifting salience of issues in the agenda as a\nwhole and allow the study of agendas across different domains. We evaluate\nthese metrics and compare them to other measures such as issue-level survival\nrates and the Pedersen Index, which uses public-opinion poll data to measure\npublic agendas, as well as traditional media content to measure media agendas\nin the UK and Germany. We show how these measures complement existing\napproaches and could be employed in future agenda-setting research. \n\n"}
{"id": "1808.09101", "contents": "Title: N-ary Relation Extraction using Graph State LSTM Abstract: Cross-sentence $n$-ary relation extraction detects relations among $n$\nentities across multiple sentences. Typical methods formulate an input as a\n\\textit{document graph}, integrating various intra-sentential and\ninter-sentential dependencies. The current state-of-the-art method splits the\ninput graph into two DAGs, adopting a DAG-structured LSTM for each. Though\nbeing able to model rich linguistic knowledge by leveraging graph edges,\nimportant information can be lost in the splitting procedure. We propose a\ngraph-state LSTM model, which uses a parallel state to model each word,\nrecurrently enriching state values via message passing. Compared with DAG\nLSTMs, our graph LSTM keeps the original graph structure, and speeds up\ncomputation by allowing more parallelization. On a standard benchmark, our\nmodel shows the best result in the literature. \n\n"}
{"id": "1808.09121", "contents": "Title: WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive\n  Meaning Representations Abstract: By design, word embeddings are unable to model the dynamic nature of words'\nsemantics, i.e., the property of words to correspond to potentially different\nmeanings. To address this limitation, dozens of specialized meaning\nrepresentation techniques such as sense or contextualized embeddings have been\nproposed. However, despite the popularity of research on this topic, very few\nevaluation benchmarks exist that specifically focus on the dynamic semantics of\nwords. In this paper we show that existing models have surpassed the\nperformance ceiling of the standard evaluation dataset for the purpose, i.e.,\nStanford Contextual Word Similarity, and highlight its shortcomings. To address\nthe lack of a suitable benchmark, we put forward a large-scale Word in Context\ndataset, called WiC, based on annotations curated by experts, for generic\nevaluation of context-sensitive representations. WiC is released in\nhttps://pilehvar.github.io/wic/. \n\n"}
{"id": "1808.09352", "contents": "Title: Evaluating Theory of Mind in Question Answering Abstract: We propose a new dataset for evaluating question answering models with\nrespect to their capacity to reason about beliefs. Our tasks are inspired by\ntheory-of-mind experiments that examine whether children are able to reason\nabout the beliefs of others, in particular when those beliefs differ from\nreality. We evaluate a number of recent neural models with memory augmentation.\nWe find that all fail on our tasks, which require keeping track of inconsistent\nstates of the world; moreover, the models' accuracy decreases notably when\nrandom sentences are introduced to the tasks at test. \n\n"}
{"id": "1808.09354", "contents": "Title: Universal Dependency Parsing with a General Transition-Based DAG Parser Abstract: This paper presents our experiments with applying TUPA to the CoNLL 2018 UD\nshared task. TUPA is a general neural transition-based DAG parser, which we use\nto present the first experiments on recovering enhanced dependencies as part of\nthe general parsing task. TUPA was designed for parsing UCCA, a\ncross-linguistic semantic annotation scheme, exhibiting reentrancy,\ndiscontinuity and non-terminal nodes. By converting UD trees and graphs to a\nUCCA-like DAG format, we train TUPA almost without modification on the UD\nparsing task. The generic nature of our approach lends itself naturally to\nmultitask learning. Our code is available at\nhttps://github.com/CoNLL-UD-2018/HUJI \n\n"}
{"id": "1808.09401", "contents": "Title: Temporal Information Extraction by Predicting Relative Time-lines Abstract: The current leading paradigm for temporal information extraction from text\nconsists of three phases: (1) recognition of events and temporal expressions,\n(2) recognition of temporal relations among them, and (3) time-line\nconstruction from the temporal relations. In contrast to the first two phases,\nthe last phase, time-line construction, received little attention and is the\nfocus of this work. In this paper, we propose a new method to construct a\nlinear time-line from a set of (extracted) temporal relations. But more\nimportantly, we propose a novel paradigm in which we directly predict start and\nend-points for events from the text, constituting a time-line without going\nthrough the intermediate step of prediction of temporal relations as in earlier\nwork. Within this paradigm, we propose two models that predict in linear\ncomplexity, and a new training loss using TimeML-style annotations, yielding\npromising results. \n\n"}
{"id": "1808.09492", "contents": "Title: Learning to Attend On Essential Terms: An Enhanced Retriever-Reader\n  Model for Open-domain Question Answering Abstract: Open-domain question answering remains a challenging task as it requires\nmodels that are capable of understanding questions and answers, collecting\nuseful information, and reasoning over evidence. Previous work typically\nformulates this task as a reading comprehension or entailment problem given\nevidence retrieved from search engines. However, existing techniques struggle\nto retrieve indirectly related evidence when no directly related evidence is\nprovided, especially for complex questions where it is hard to parse precisely\nwhat the question asks. In this paper we propose a retriever-reader model that\nlearns to attend on essential terms during the question answering process. We\nbuild (1) an essential term selector which first identifies the most important\nwords in a question, then reformulates the query and searches for related\nevidence; and (2) an enhanced reader that distinguishes between essential terms\nand distracting words to predict the answer. We evaluate our model on multiple\nopen-domain multiple-choice QA datasets, notably performing at the level of the\nstate-of-the-art on the AI2 Reasoning Challenge (ARC) dataset. \n\n"}
{"id": "1808.09582", "contents": "Title: Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and\n  Stopping Criteria for Neural Machine Translation Abstract: Beam search is widely used in neural machine translation, and usually\nimproves translation quality compared to greedy search. It has been widely\nobserved that, however, beam sizes larger than 5 hurt translation quality. We\nexplain why this happens, and propose several methods to address this problem.\nFurthermore, we discuss the optimal stopping criteria for these methods.\nResults show that our hyperparameter-free methods outperform the widely-used\nhyperparameter-free heuristic of length normalization by +2.0 BLEU, and achieve\nthe best results among all methods on Chinese-to-English translation. \n\n"}
{"id": "1808.09658", "contents": "Title: APRIL: Interactively Learning to Summarise by Combining Active\n  Preference Learning and Reinforcement Learning Abstract: We propose a method to perform automatic document summarisation without using\nreference summaries. Instead, our method interactively learns from users'\npreferences. The merit of preference-based interactive summarisation is that\npreferences are easier for users to provide than reference summaries. Existing\npreference-based interactive learning methods suffer from high sample\ncomplexity, i.e. they need to interact with the oracle for many rounds in order\nto converge. In this work, we propose a new objective function, which enables\nus to leverage active learning, preference learning and reinforcement learning\ntechniques in order to reduce the sample complexity. Both simulation and\nreal-user experiments suggest that our method significantly advances the state\nof the art. Our source code is freely available at\nhttps://github.com/UKPLab/emnlp2018-april. \n\n"}
{"id": "1808.10122", "contents": "Title: Learning Neural Templates for Text Generation Abstract: While neural, encoder-decoder models have had significant empirical success\nin text generation, there remain several unaddressed problems with this style\nof generation. Encoder-decoder models are largely (a) uninterpretable, and (b)\ndifficult to control in terms of their phrasing or content. This work proposes\na neural generation system using a hidden semi-markov model (HSMM) decoder,\nwhich learns latent, discrete templates jointly with learning to generate. We\nshow that this model learns useful templates, and that these templates make\ngeneration both more interpretable and controllable. Furthermore, we show that\nthis approach scales to real data sets and achieves strong performance nearing\nthat of encoder-decoder text generation models. \n\n"}
{"id": "1808.10432", "contents": "Title: Attaining the Unattainable? Reassessing Claims of Human Parity in Neural\n  Machine Translation Abstract: We reassess a recent study (Hassan et al., 2018) that claimed that machine\ntranslation (MT) has reached human parity for the translation of news from\nChinese into English, using pairwise ranking and considering three variables\nthat were not taken into account in that previous study: the language in which\nthe source side of the test set was originally written, the translation\nproficiency of the evaluators, and the provision of inter-sentential context.\nIf we consider only original source text (i.e. not translated from another\nlanguage, or translationese), then we find evidence showing that human parity\nhas not been achieved. We compare the judgments of professional translators\nagainst those of non-experts and discover that those of the experts result in\nhigher inter-annotator agreement and better discrimination between human and\nmachine translations. In addition, we analyse the human translations of the\ntest set and identify important translation issues. Finally, based on these\nfindings, we provide a set of recommendations for future human evaluations of\nMT. \n\n"}
{"id": "1808.10485", "contents": "Title: Syntactic Scaffolds for Semantic Structures Abstract: We introduce the syntactic scaffold, an approach to incorporating syntactic\ninformation into semantic tasks. Syntactic scaffolds avoid expensive syntactic\nprocessing at runtime, only making use of a treebank during training, through a\nmultitask objective. We improve over strong baselines on PropBank semantics,\nframe semantics, and coreference resolution, achieving competitive performance\non all three tasks. \n\n"}
{"id": "1808.10568", "contents": "Title: Multi-Hop Knowledge Graph Reasoning with Reward Shaping Abstract: Multi-hop reasoning is an effective approach for query answering (QA) over\nincomplete knowledge graphs (KGs). The problem can be formulated in a\nreinforcement learning (RL) setup, where a policy-based agent sequentially\nextends its inference path until it reaches a target. However, in an incomplete\nKG environment, the agent receives low-quality rewards corrupted by false\nnegatives in the training data, which harms generalization at test time.\nFurthermore, since no golden action sequence is used for training, the agent\ncan be misled by spurious search trajectories that incidentally lead to the\ncorrect answer. We propose two modeling advances to address both issues: (1) we\nreduce the impact of false negative supervision by adopting a pretrained\none-hop embedding model to estimate the reward of unobserved facts; (2) we\ncounter the sensitivity to spurious paths of on-policy RL by forcing the agent\nto explore a diverse set of paths using randomly generated edge masks. Our\napproach significantly improves over existing path-based KGQA models on several\nbenchmark datasets and is comparable or better than embedding-based models. \n\n"}
{"id": "1808.10584", "contents": "Title: Learning to Describe Differences Between Pairs of Similar Images Abstract: In this paper, we introduce the task of automatically generating text to\ndescribe the differences between two similar images. We collect a new dataset\nby crowd-sourcing difference descriptions for pairs of image frames extracted\nfrom video-surveillance footage. Annotators were asked to succinctly describe\nall the differences in a short paragraph. As a result, our novel dataset\nprovides an opportunity to explore models that align language and vision, and\ncapture visual salience. The dataset may also be a useful benchmark for\ncoherent multi-sentence generation. We perform a firstpass visual analysis that\nexposes clusters of differing pixels as a proxy for object-level differences.\nWe propose a model that captures visual salience by using a latent variable to\nalign clusters of differing pixels with output sentences. We find that, for\nboth single-sentence generation and as well as multi-sentence generation, the\nproposed model outperforms the models that use attention alone. \n\n"}
{"id": "1808.10701", "contents": "Title: Imitation Learning for Neural Morphological String Transduction Abstract: We employ imitation learning to train a neural transition-based string\ntransducer for morphological tasks such as inflection generation and\nlemmatization. Previous approaches to training this type of model either rely\non an external character aligner for the production of gold action sequences,\nwhich results in a suboptimal model due to the unwarranted dependence on a\nsingle gold action sequence despite spurious ambiguity, or require warm\nstarting with an MLE model. Our approach only requires a simple expert policy,\neliminating the need for a character aligner or warm start. It also addresses\nfamiliar MLE training biases and leads to strong and state-of-the-art\nperformance on several benchmarks. \n\n"}
{"id": "1808.10792", "contents": "Title: Bottom-Up Abstractive Summarization Abstract: Neural network-based methods for abstractive summarization produce outputs\nthat are more fluent than other techniques, but which can be poor at content\nselection. This work proposes a simple technique for addressing this issue: use\na data-efficient content selector to over-determine phrases in a source\ndocument that should be part of the summary. We use this selector as a\nbottom-up attention step to constrain the model to likely phrases. We show that\nthis approach improves the ability to compress text, while still generating\nfluent summaries. This two-step process is both simpler and higher performing\nthan other end-to-end content selection models, leading to significant\nimprovements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the\ncontent selector can be trained with as little as 1,000 sentences, making it\neasy to transfer a trained summarizer to a new domain. \n\n"}
{"id": "1809.00013", "contents": "Title: Gromov-Wasserstein Alignment of Word Embedding Spaces Abstract: Cross-lingual or cross-domain correspondences play key roles in tasks ranging\nfrom machine translation to transfer learning. Recently, purely unsupervised\nmethods operating on monolingual embeddings have become effective alignment\ntools. Current state-of-the-art methods, however, involve multiple steps,\nincluding heuristic post-hoc refinement strategies. In this paper, we cast the\ncorrespondence problem directly as an optimal transport (OT) problem, building\non the idea that word embeddings arise from metric recovery algorithms. Indeed,\nwe exploit the Gromov-Wasserstein distance that measures how similarities\nbetween pairs of words relate across languages. We show that our OT objective\ncan be estimated efficiently, requires little or no tuning, and results in\nperformance comparable with the state-of-the-art in various unsupervised word\ntranslation tasks. \n\n"}
{"id": "1809.00345", "contents": "Title: IntentsKB: A Knowledge Base of Entity-Oriented Search Intents Abstract: We address the problem of constructing a knowledge base of entity-oriented\nsearch intents. Search intents are defined on the level of entity types, each\ncomprising of a high-level intent category (property, website, service, or\nother), along with a cluster of query terms used to express that intent. These\nmachine-readable statements can be leveraged in various applications, e.g., for\ngenerating entity cards or query recommendations. By structuring\nservice-oriented search intents, we take one step towards making entities\nactionable. The main contribution of this paper is a pipeline of components we\ndevelop to construct a knowledge base of entity intents. We evaluate\nperformance both component-wise and end-to-end, and demonstrate that our\napproach is able to generate high-quality data. \n\n"}
{"id": "1809.00370", "contents": "Title: Neural Ranking Models for Temporal Dependency Structure Parsing Abstract: We design and build the first neural temporal dependency parser. It utilizes\na neural ranking model with minimal feature engineering, and parses time\nexpressions and events in a text into a temporal dependency tree structure. We\nevaluate our parser on two domains: news reports and narrative stories. In a\nparsing-only evaluation setup where gold time expressions and events are\nprovided, our parser reaches 0.81 and 0.70 f-score on unlabeled and labeled\nparsing respectively, a result that is very competitive against alternative\napproaches. In an end-to-end evaluation setup where time expressions and events\nare automatically recognized, our parser beats two strong baselines on both\ndata domains. Our experimental results and discussions shed light on the nature\nof temporal dependency structures in different domains and provide insights\nthat we believe will be valuable to future research in this area. \n\n"}
{"id": "1809.00388", "contents": "Title: MTNT: A Testbed for Machine Translation of Noisy Text Abstract: Noisy or non-standard input text can cause disastrous mistranslations in most\nmodern Machine Translation (MT) systems, and there has been growing research\ninterest in creating noise-robust MT systems. However, as of yet there are no\npublicly available parallel corpora of with naturally occurring noisy inputs\nand translations, and thus previous work has resorted to evaluating on\nsynthetically created datasets. In this paper, we propose a benchmark dataset\nfor Machine Translation of Noisy Text (MTNT), consisting of noisy comments on\nReddit (www.reddit.com) and professionally sourced translations. We\ncommissioned translations of English comments into French and Japanese, as well\nas French and Japanese comments into English, on the order of 7k-37k sentences\nper language pair. We qualitatively and quantitatively examine the types of\nnoise included in this dataset, then demonstrate that existing MT models fail\nbadly on a number of noise-related phenomena, even after performing adaptation\non a small training set of in-domain data. This indicates that this dataset can\nprovide an attractive testbed for methods tailored to handling noisy text in\nMT. The data is publicly available at www.cs.cmu.edu/~pmichel1/mtnt/. \n\n"}
{"id": "1809.00414", "contents": "Title: Hypernyms Through Intra-Article Organization in Wikipedia Abstract: We introduce a new measure for unsupervised hypernym detection and\ndirectionality. The motivation is to keep the measure computationally light and\nportatable across languages. We show that the relative physical location of\nwords in explanatory articles captures the directionality property. Further,\nthe phrases in section titles of articles about the word, capture the semantic\nsimilarity needed for hypernym detection task. We experimentally show that the\ncombination of features coming from these two simple measures suffices to\nproduce results comparable with the best unsupervised measures in terms of the\naverage precision. \n\n"}
{"id": "1809.00530", "contents": "Title: Adaptive Semi-supervised Learning for Cross-domain Sentiment\n  Classification Abstract: We consider the cross-domain sentiment classification problem, where a\nsentiment classifier is to be learned from a source domain and to be\ngeneralized to a target domain. Our approach explicitly minimizes the distance\nbetween the source and the target instances in an embedded feature space. With\nthe difference between source and target minimized, we then exploit additional\ninformation from the target domain by consolidating the idea of semi-supervised\nlearning, for which, we jointly employ two regularizations -- entropy\nminimization and self-ensemble bootstrapping -- to incorporate the unlabeled\ntarget data for classifier refinement. Our experimental results demonstrate\nthat the proposed approach can better leverage unlabeled data from the target\ndomain and achieve substantial improvements over baseline methods in various\nexperimental settings. \n\n"}
{"id": "1809.00640", "contents": "Title: Deep learning for language understanding of mental health concepts\n  derived from Cognitive Behavioural Therapy Abstract: In recent years, we have seen deep learning and distributed representations\nof words and sentences make impact on a number of natural language processing\ntasks, such as similarity, entailment and sentiment analysis. Here we introduce\na new task: understanding of mental health concepts derived from Cognitive\nBehavioural Therapy (CBT). We define a mental health ontology based on the CBT\nprinciples, annotate a large corpus where this phenomena is exhibited and\nperform understanding using deep learning and distributed representations. Our\nresults show that the performance of deep learning models combined with word\nembeddings or sentence embeddings significantly outperform non-deep-learning\nmodels in this difficult task. This understanding module will be an essential\ncomponent of a statistical dialogue system delivering therapy. \n\n"}
{"id": "1809.00653", "contents": "Title: Towards Dynamic Computation Graphs via Sparse Latent Structure Abstract: Deep NLP models benefit from underlying structures in the data---e.g., parse\ntrees---typically extracted using off-the-shelf parsers. Recent attempts to\njointly learn the latent structure encounter a tradeoff: either make\nfactorization assumptions that limit expressiveness, or sacrifice end-to-end\ndifferentiability. Using the recently proposed SparseMAP inference, which\nretrieves a sparse distribution over latent structures, we propose a novel\napproach for end-to-end learning of latent structure predictors jointly with a\ndownstream predictor. To the best of our knowledge, our method is the first to\nenable unrestricted dynamic computation graph construction from the global\nlatent structure, while maintaining differentiability. \n\n"}
{"id": "1809.00699", "contents": "Title: Multi-Level Structured Self-Attentions for Distantly Supervised Relation\n  Extraction Abstract: Attention mechanisms are often used in deep neural networks for distantly\nsupervised relation extraction (DS-RE) to distinguish valid from noisy\ninstances. However, traditional 1-D vector attention models are insufficient\nfor the learning of different contexts in the selection of valid instances to\npredict the relationship for an entity pair. To alleviate this issue, we\npropose a novel multi-level structured (2-D matrix) self-attention mechanism\nfor DS-RE in a multi-instance learning (MIL) framework using bidirectional\nrecurrent neural networks. In the proposed method, a structured word-level\nself-attention mechanism learns a 2-D matrix where each row vector represents a\nweight distribution for different aspects of an instance regarding two\nentities. Targeting the MIL issue, the structured sentence-level attention\nlearns a 2-D matrix where each row vector represents a weight distribution on\nselection of different valid in-stances. Experiments conducted on two publicly\navailable DS-RE datasets show that the proposed framework with a multi-level\nstructured self-attention mechanism significantly outperform state-of-the-art\nbaselines in terms of PR curves, P@N and F1 measures. \n\n"}
{"id": "1809.00934", "contents": "Title: A Deep Neural Network Sentence Level Classification Method with Context\n  Information Abstract: In the sentence classification task, context formed from sentences adjacent\nto the sentence being classified can provide important information for\nclassification. This context is, however, often ignored. Where methods do make\nuse of context, only small amounts are considered, making it difficult to\nscale. We present a new method for sentence classification, Context-LSTM-CNN,\nthat makes use of potentially large contexts. The method also utilizes\nlong-range dependencies within the sentence being classified, using an LSTM,\nand short-span features, using a stacked CNN. Our experiments demonstrate that\nthis approach consistently improves over previous methods on two different\ndatasets. \n\n"}
{"id": "1809.01452", "contents": "Title: Sentylic at IEST 2018: Gated Recurrent Neural Network and Capsule\n  Network Based Approach for Implicit Emotion Detection Abstract: In this paper, we present the system we have used for the Implicit WASSA 2018\nImplicit Emotion Shared Task. The task is to predict the emotion of a tweet of\nwhich the explicit mentions of emotion terms have been removed. The idea is to\ncome up with a model which has the ability to implicitly identify the emotion\nexpressed given the context words. We have used a Gated Recurrent Neural\nNetwork (GRU) and a Capsule Network based model for the task. Pre-trained word\nembeddings have been utilized to incorporate contextual knowledge about words\ninto the model. GRU layer learns latent representations using the input word\nembeddings. Subsequent Capsule Network layer learns high-level features from\nthat hidden representation. The proposed model managed to achieve a macro-F1\nscore of 0.692. \n\n"}
{"id": "1809.01477", "contents": "Title: A Supervised Learning Approach For Heading Detection Abstract: As the Portable Document Format (PDF) file format increases in popularity,\nresearch in analysing its structure for text extraction and analysis is\nnecessary. Detecting headings can be a crucial component of classifying and\nextracting meaningful data. This research involves training a supervised\nlearning model to detect headings with features carefully selected through\nrecursive feature elimination. The best performing classifier had an accuracy\nof 96.95%, sensitivity of 0.986 and a specificity of 0.953. This research into\nheading detection contributes to the field of PDF based text extraction and can\nbe applied to the automation of large scale PDF text analysis in a variety of\nprofessional and policy based contexts. \n\n"}
{"id": "1809.01478", "contents": "Title: Weakly-Supervised Neural Text Classification Abstract: Deep neural networks are gaining increasing popularity for the classic text\nclassification task, due to their strong expressive power and less requirement\nfor feature engineering. Despite such attractiveness, neural text\nclassification models suffer from the lack of training data in many real-world\napplications. Although many semi-supervised and weakly-supervised text\nclassification models exist, they cannot be easily applied to deep neural\nmodels and meanwhile support limited supervision types. In this paper, we\npropose a weakly-supervised method that addresses the lack of training data in\nneural text classification. Our method consists of two modules: (1) a\npseudo-document generator that leverages seed information to generate\npseudo-labeled documents for model pre-training, and (2) a self-training module\nthat bootstraps on real unlabeled data for model refinement. Our method has the\nflexibility to handle different types of weak supervision and can be easily\nintegrated into existing deep neural models for text classification. We have\nperformed extensive experiments on three real-world datasets from different\ndomains. The results demonstrate that our proposed method achieves inspiring\nperformance without requiring excessive training data and outperforms baseline\nmethods significantly. \n\n"}
{"id": "1809.01479", "contents": "Title: UKP-Athene: Multi-Sentence Textual Entailment for Claim Verification Abstract: The Fact Extraction and VERification (FEVER) shared task was launched to\nsupport the development of systems able to verify claims by extracting\nsupporting or refuting facts from raw text. The shared task organizers provide\na large-scale dataset for the consecutive steps involved in claim verification,\nin particular, document retrieval, fact extraction, and claim classification.\nIn this paper, we present our claim verification pipeline approach, which,\naccording to the preliminary results, scored third in the shared task, out of\n23 competing systems. For the document retrieval, we implemented a new entity\nlinking approach. In order to be able to rank candidate facts and classify a\nclaim on the basis of several selected facts, we introduce two extensions to\nthe Enhanced LSTM (ESIM). \n\n"}
{"id": "1809.01494", "contents": "Title: Interpretation of Natural Language Rules in Conversational Machine\n  Reading Abstract: Most work in machine reading focuses on question answering problems where the\nanswer is directly expressed in the text to read. However, many real-world\nquestion answering problems require the reading of text not because it contains\nthe literal answer, but because it contains a recipe to derive an answer\ntogether with the reader's background knowledge. One example is the task of\ninterpreting regulations to answer \"Can I...?\" or \"Do I have to...?\" questions\nsuch as \"I am working in Canada. Do I have to carry on paying UK National\nInsurance?\" after reading a UK government website about this topic. This task\nrequires both the interpretation of rules and the application of background\nknowledge. It is further complicated due to the fact that, in practice, most\nquestions are underspecified, and a human assistant will regularly have to ask\nclarification questions such as \"How long have you been working abroad?\" when\nthe answer cannot be directly derived from the question and text. In this\npaper, we formalise this task and develop a crowd-sourcing strategy to collect\n32k task instances based on real-world rules and crowd-generated questions and\nscenarios. We analyse the challenges of this task and assess its difficulty by\nevaluating the performance of rule-based and machine-learning baselines. We\nobserve promising results when no background knowledge is necessary, and\nsubstantial room for improvement whenever background knowledge is needed. \n\n"}
{"id": "1809.01495", "contents": "Title: A Reinforcement Learning-driven Translation Model for Search-Oriented\n  Conversational Systems Abstract: Search-oriented conversational systems rely on information needs expressed in\nnatural language (NL). We focus here on the understanding of NL expressions for\nbuilding keyword-based queries. We propose a reinforcement-learning-driven\ntranslation model framework able to 1) learn the translation from NL\nexpressions to queries in a supervised way, and, 2) to overcome the lack of\nlarge-scale dataset by framing the translation model as a word selection\napproach and injecting relevance feedback in the learning process. Experiments\nare carried out on two TREC datasets and outline the effectiveness of our\napproach. \n\n"}
{"id": "1809.01496", "contents": "Title: Learning Gender-Neutral Word Embeddings Abstract: Word embedding models have become a fundamental component in a wide range of\nNatural Language Processing (NLP) applications. However, embeddings trained on\nhuman-generated corpora have been demonstrated to inherit strong gender\nstereotypes that reflect social constructs. To address this concern, in this\npaper, we propose a novel training procedure for learning gender-neutral word\nembeddings. Our approach aims to preserve gender information in certain\ndimensions of word vectors while compelling other dimensions to be free of\ngender influence. Based on the proposed method, we generate a Gender-Neutral\nvariant of GloVe (GN-GloVe). Quantitative and qualitative experiments\ndemonstrate that GN-GloVe successfully isolates gender information without\nsacrificing the functionality of the embedding model. \n\n"}
{"id": "1809.01771", "contents": "Title: An Analysis of Hierarchical Text Classification Using Word Embeddings Abstract: Efficient distributed numerical word representation models (word embeddings)\ncombined with modern machine learning algorithms have recently yielded\nconsiderable improvement on automatic document classification tasks. However,\nthe effectiveness of such techniques has not been assessed for the hierarchical\ntext classification (HTC) yet. This study investigates the application of those\nmodels and algorithms on this specific problem by means of experimentation and\nanalysis. We trained classification models with prominent machine learning\nalgorithm implementations---fastText, XGBoost, SVM, and Keras' CNN---and\nnoticeable word embeddings generation methods---GloVe, word2vec, and\nfastText---with publicly available data and evaluated them with measures\nspecifically appropriate for the hierarchical context. FastText achieved an\n${}_{LCA}F_1$ of 0.893 on a single-labeled version of the RCV1 dataset. An\nanalysis indicates that using word embeddings and its flavors is a very\npromising approach for HTC. \n\n"}
{"id": "1809.01854", "contents": "Title: Top-down Tree Structured Decoding with Syntactic Connections for Neural\n  Machine Translation and Parsing Abstract: The addition of syntax-aware decoding in Neural Machine Translation (NMT)\nsystems requires an effective tree-structured neural network, a syntax-aware\nattention model and a language generation model that is sensitive to sentence\nstructure. We exploit a top-down tree-structured model called DRNN\n(Doubly-Recurrent Neural Networks) first proposed by Alvarez-Melis and Jaakola\n(2017) to create an NMT model called Seq2DRNN that combines a sequential\nencoder with tree-structured decoding augmented with a syntax-aware attention\nmodel. Unlike previous approaches to syntax-based NMT which use dependency\nparsing models our method uses constituency parsing which we argue provides\nuseful information for translation. In addition, we use the syntactic structure\nof the sentence to add new connections to the tree-structured decoder neural\nnetwork (Seq2DRNN+SynC). We compare our NMT model with sequential and state of\nthe art syntax-based NMT models and show that our model produces more fluent\ntranslations with better reordering. Since our model is capable of doing\ntranslation and constituency parsing at the same time we also compare our\nparsing accuracy against other neural parsing models. \n\n"}
{"id": "1809.01984", "contents": "Title: Training Millions of Personalized Dialogue Agents Abstract: Current dialogue systems are not very engaging for users, especially when\ntrained end-to-end without relying on proactive reengaging scripted strategies.\nZhang et al. (2018) showed that the engagement level of end-to-end dialogue\nmodels increases when conditioning them on text personas providing some\npersonalized back-story to the model. However, the dataset used in Zhang et al.\n(2018) is synthetic and of limited size as it contains around 1k different\npersonas. In this paper we introduce a new dataset providing 5 million personas\nand 700 million persona-based dialogues. Our experiments show that, at this\nscale, training using personas still improves the performance of end-to-end\nsystems. In addition, we show that other tasks benefit from the wide coverage\nof our dataset by fine-tuning our model on the data from Zhang et al. (2018)\nand achieving state-of-the-art results. \n\n"}
{"id": "1809.02223", "contents": "Title: Character-Aware Decoder for Translation into Morphologically Rich\n  Languages Abstract: Neural machine translation (NMT) systems operate primarily on words (or\nsub-words), ignoring lower-level patterns of morphology. We present a\ncharacter-aware decoder designed to capture such patterns when translating into\nmorphologically rich languages. We achieve character-awareness by augmenting\nboth the softmax and embedding layers of an attention-based encoder-decoder\nmodel with convolutional neural networks that operate on the spelling of a\nword. To investigate performance on a wide variety of morphological phenomena,\nwe translate English into 14 typologically diverse target languages using the\nTED multi-target dataset. In this low-resource setting, the character-aware\ndecoder provides consistent improvements with BLEU score gains of up to\n$+3.05$. In addition, we analyze the relationship between the gains obtained\nand properties of the target language and find evidence that our model does\nindeed exploit morphological patterns. \n\n"}
{"id": "1809.02253", "contents": "Title: Cycle-Consistent Speech Enhancement Abstract: Feature mapping using deep neural networks is an effective approach for\nsingle-channel speech enhancement. Noisy features are transformed to the\nenhanced ones through a mapping network and the mean square errors between the\nenhanced and clean features are minimized. In this paper, we propose a\ncycle-consistent speech enhancement (CSE) in which an additional inverse\nmapping network is introduced to reconstruct the noisy features from the\nenhanced ones. A cycle-consistent constraint is enforced to minimize the\nreconstruction loss. Similarly, a backward cycle of mappings is performed in\nthe opposite direction with the same networks and losses. With\ncycle-consistency, the speech structure is well preserved in the enhanced\nfeatures while noise is effectively reduced such that the feature-mapping\nnetwork generalizes better to unseen data. In cases where only unparalleled\nnoisy and clean data is available for training, two discriminator networks are\nused to distinguish the enhanced and noised features from the clean and noisy\nones. The discrimination losses are jointly optimized with reconstruction\nlosses through adversarial multi-task learning. Evaluated on the CHiME-3\ndataset, the proposed CSE achieves 19.60% and 6.69% relative word error rate\nimprovements respectively when using or without using parallel clean and noisy\nspeech data. \n\n"}
{"id": "1809.02306", "contents": "Title: Unsupervised Cross-lingual Word Embedding by Multilingual Neural\n  Language Models Abstract: We propose an unsupervised method to obtain cross-lingual embeddings without\nany parallel data or pre-trained word embeddings. The proposed model, which we\ncall multilingual neural language models, takes sentences of multiple languages\nas an input. The proposed model contains bidirectional LSTMs that perform as\nforward and backward language models, and these networks are shared among all\nthe languages. The other parameters, i.e. word embeddings and linear\ntransformation between hidden states and outputs, are specific to each\nlanguage. The shared LSTMs can capture the common sentence structure among all\nlanguages. Accordingly, word embeddings of each language are mapped into a\ncommon latent space, making it possible to measure the similarity of words\nacross multiple languages. We evaluate the quality of the cross-lingual word\nembeddings on a word alignment task. Our experiments demonstrate that our model\ncan obtain cross-lingual embeddings of much higher quality than existing\nunsupervised models when only a small amount of monolingual data (i.e. 50k\nsentences) are available, or the domains of monolingual data are different\nacross languages. \n\n"}
{"id": "1809.02649", "contents": "Title: A Transfer-Learnable Natural Language Interface for Databases Abstract: Relational database management systems (RDBMSs) are powerful because they are\nable to optimize and answer queries against any relational database. A natural\nlanguage interface (NLI) for a database, on the other hand, is tailored to\nsupport that specific database. In this work, we introduce a general purpose\ntransfer-learnable NLI with the goal of learning one model that can be used as\nNLI for any relational database. We adopt the data management principle of\nseparating data and its schema, but with the additional support for the\nidiosyncrasy and complexity of natural languages. Specifically, we introduce an\nautomatic annotation mechanism that separates the schema and the data, where\nthe schema also covers knowledge about natural language. Furthermore, we\npropose a customized sequence model that translates annotated natural language\nqueries to SQL statements. We show in experiments that our approach outperforms\nprevious NLI methods on the WikiSQL dataset and the model we learned can be\napplied to another benchmark dataset OVERNIGHT without retraining. \n\n"}
{"id": "1809.02731", "contents": "Title: Exploiting Invertible Decoders for Unsupervised Sentence Representation\n  Learning Abstract: The encoder-decoder models for unsupervised sentence representation learning\ntend to discard the decoder after being trained on a large unlabelled corpus,\nsince only the encoder is needed to map the input sentence into a vector\nrepresentation. However, parameters learnt in the decoder also contain useful\ninformation about language. In order to utilise the decoder after learning, we\npresent two types of decoding functions whose inverse can be easily derived\nwithout expensive inverse calculation. Therefore, the inverse of the decoding\nfunction serves as another encoder that produces sentence representations. We\nshow that, with careful design of the decoding functions, the model learns good\nsentence representations, and the ensemble of the representations produced from\nthe encoder and the inverse of the decoder demonstrate even better\ngeneralisation ability and solid transferability. \n\n"}
{"id": "1809.02836", "contents": "Title: Context-Free Transductions with Neural Stacks Abstract: This paper analyzes the behavior of stack-augmented recurrent neural network\n(RNN) models. Due to the architectural similarity between stack RNNs and\npushdown transducers, we train stack RNN models on a number of tasks, including\nstring reversal, context-free language modelling, and cumulative XOR\nevaluation. Examining the behavior of our networks, we show that\nstack-augmented RNNs can discover intuitive stack-based strategies for solving\nour tasks. However, stack RNNs are more difficult to train than classical\narchitectures such as LSTMs. Rather than employ stack-based strategies, more\ncomplex networks often find approximate solutions by using the stack as\nunstructured memory. \n\n"}
{"id": "1809.03044", "contents": "Title: How clever is the FiLM model, and how clever can it be? Abstract: The FiLM model achieves close-to-perfect performance on the diagnostic CLEVR\ndataset and is distinguished from other such models by having a comparatively\nsimple and easily transferable architecture. In this paper, we investigate in\nmore detail the ability of FiLM to learn various linguistic constructions. Our\nmain results show that (a) FiLM is not able to learn relational statements\nstraight away except for very simple instances, (b) training on a broader set\nof instances as well as pretraining on simpler instance types can help\nalleviate these learning difficulties, (c) mixing is less robust than\npretraining and very sensitive to the compositional structure of the dataset.\nOverall, our results suggest that the approach of big all-encompassing datasets\nand the paradigm of \"the effectiveness of data\" may have fundamental\nlimitations. \n\n"}
{"id": "1809.03056", "contents": "Title: SHOMA at Parseme Shared Task on Automatic Identification of VMWEs:\n  Neural Multiword Expression Tagging with High Generalisation Abstract: This paper presents a language-independent deep learning architecture adapted\nto the task of multiword expression (MWE) identification. We employ a neural\narchitecture comprising of convolutional and recurrent layers with the addition\nof an optional CRF layer at the top. This system participated in the open track\nof the Parseme shared task on automatic identification of verbal MWEs due to\nthe use of pre-trained wikipedia word embeddings. It outperformed all\nparticipating systems in both open and closed tracks with the overall\nmacro-average MWE-based F1 score of 58.09 averaged among all languages. A\nparticular strength of the system is its superior performance on unseen data\nentries. \n\n"}
{"id": "1809.03182", "contents": "Title: Towards one-shot learning for rare-word translation with external\n  experts Abstract: Neural machine translation (NMT) has significantly improved the quality of\nautomatic translation models. One of the main challenges in current systems is\nthe translation of rare words. We present a generic approach to address this\nweakness by having external models annotate the training data as Experts, and\ncontrol the model-expert interaction with a pointer network and reinforcement\nlearning. Our experiments using phrase-based models to simulate Experts to\ncomplement neural machine translation models show that the model can be trained\nto copy the annotations into the output consistently. We demonstrate the\nbenefit of our proposed framework in outof-domain translation scenarios with\nonly lexical resources, improving more than 1.0 BLEU point in both translation\ndirections English to Spanish and German to English \n\n"}
{"id": "1809.03202", "contents": "Title: Learning Sequence Encoders for Temporal Knowledge Graph Completion Abstract: Research on link prediction in knowledge graphs has mainly focused on static\nmulti-relational data. In this work we consider temporal knowledge graphs where\nrelations between entities may only hold for a time interval or a specific\npoint in time. In line with previous work on static knowledge graphs, we\npropose to address this problem by learning latent entity and relation type\nrepresentations. To incorporate temporal information, we utilize recurrent\nneural networks to learn time-aware representations of relation types which can\nbe used in conjunction with existing latent factorization methods. The proposed\napproach is shown to be robust to common challenges in real-world KGs: the\nsparsity and heterogeneity of temporal expressions. Experiments show the\nbenefits of our approach on four temporal KGs. The data sets are available\nunder a permissive BSD-3 license 1. \n\n"}
{"id": "1809.03391", "contents": "Title: Toward a Standardized and More Accurate Indonesian Part-of-Speech\n  Tagging Abstract: Previous work in Indonesian part-of-speech (POS) tagging are hard to compare\nas they are not evaluated on a common dataset. Furthermore, in spite of the\nsuccess of neural network models for English POS tagging, they are rarely\nexplored for Indonesian. In this paper, we explored various techniques for\nIndonesian POS tagging, including rule-based, CRF, and neural network-based\nmodels. We evaluated our models on the IDN Tagged Corpus. A new\nstate-of-the-art of 97.47 F1 score is achieved with a recurrent neural network.\nTo provide a standard for future work, we release the dataset split that we\nused publicly. \n\n"}
{"id": "1809.03416", "contents": "Title: Identifying Relationships Among Sentences in Court Case Transcripts\n  Using Discourse Relations Abstract: Case Law has a significant impact on the proceedings of legal cases.\nTherefore, the information that can be obtained from previous court cases is\nvaluable to lawyers and other legal officials when performing their duties.\nThis paper describes a methodology of applying discourse relations between\nsentences when processing text documents related to the legal domain. In this\nstudy, we developed a mechanism to classify the relationships that can be\nobserved among sentences in transcripts of United States court cases. First, we\ndefined relationship types that can be observed between sentences in court case\ntranscripts. Then we classified pairs of sentences according to the\nrelationship type by combining a machine learning model and a rule-based\napproach. The results obtained through our system were evaluated using human\njudges. To the best of our knowledge, this is the first study where discourse\nrelationships between sentences have been used to determine relationships among\nsentences in legal court case transcripts. \n\n"}
{"id": "1809.03633", "contents": "Title: Unsupervised Cross-lingual Transfer of Word Embedding Spaces Abstract: Cross-lingual transfer of word embeddings aims to establish the semantic\nmappings among words in different languages by learning the transformation\nfunctions over the corresponding word embedding spaces. Successfully solving\nthis problem would benefit many downstream tasks such as to translate text\nclassification models from resource-rich languages (e.g. English) to\nlow-resource languages. Supervised methods for this problem rely on the\navailability of cross-lingual supervision, either using parallel corpora or\nbilingual lexicons as the labeled data for training, which may not be available\nfor many low resource languages. This paper proposes an unsupervised learning\napproach that does not require any cross-lingual labeled data. Given two\nmonolingual word embedding spaces for any language pair, our algorithm\noptimizes the transformation functions in both directions simultaneously based\non distributional matching as well as minimizing the back-translation losses.\nWe use a neural network implementation to calculate the Sinkhorn distance, a\nwell-defined distributional similarity measure, and optimize our objective\nthrough back-propagation. Our evaluation on benchmark datasets for bilingual\nlexicon induction and cross-lingual word similarity prediction shows stronger\nor competitive performance of the proposed method compared to other\nstate-of-the-art supervised and unsupervised baseline methods over many\nlanguage pairs. \n\n"}
{"id": "1809.03999", "contents": "Title: Evaluating Semantic Rationality of a Sentence: A Sememe-Word-Matching\n  Neural Network based on HowNet Abstract: Automatic evaluation of semantic rationality is an important yet challenging\ntask, and current automatic techniques cannot well identify whether a sentence\nis semantically rational. The methods based on the language model do not\nmeasure the sentence by rationality but by commonness. The methods based on the\nsimilarity with human written sentences will fail if human-written references\nare not available. In this paper, we propose a novel model called\nSememe-Word-Matching Neural Network (SWM-NN) to tackle semantic rationality\nevaluation by taking advantage of sememe knowledge base HowNet. The advantage\nis that our model can utilize a proper combination of sememes to represent the\nfine-grained semantic meanings of a word within the specific contexts. We use\nthe fine-grained semantic representation to help the model learn the semantic\ndependency among words. To evaluate the effectiveness of the proposed model, we\nbuild a large-scale rationality evaluation dataset. Experimental results on\nthis dataset show that the proposed model outperforms the competitive baselines\nwith a 5.4\\% improvement in accuracy. \n\n"}
{"id": "1809.04271", "contents": "Title: Knowledge-Aware Conversational Semantic Parsing Over Web Tables Abstract: Conversational semantic parsing over tables requires knowledge acquiring and\nreasoning abilities, which have not been well explored by current\nstate-of-the-art approaches. Motivated by this fact, we propose a\nknowledge-aware semantic parser to improve parsing performance by integrating\nvarious types of knowledge. In this paper, we consider three types of\nknowledge, including grammar knowledge, expert knowledge, and external resource\nknowledge. First, grammar knowledge empowers the model to effectively replicate\npreviously generated logical form, which effectively handles the co-reference\nand ellipsis phenomena in conversation Second, based on expert knowledge, we\npropose a decomposable model, which is more controllable compared with\ntraditional end-to-end models that put all the burdens of learning on\ntrial-and-error in an end-to-end way. Third, external resource knowledge, i.e.,\nprovided by a pre-trained language model or an entity typing model, is used to\nimprove the representation of question and table for a better semantic\nunderstanding. We conduct experiments on the SequentialQA dataset. Results show\nthat our knowledge-aware model outperforms the state-of-the-art approaches.\nIncremental experimental results also prove the usefulness of various\nknowledge. Further analysis shows that our approach has the ability to derive\nthe meaning representation of a context-dependent utterance by leveraging\npreviously generated outcomes. \n\n"}
{"id": "1809.04560", "contents": "Title: Game-Based Video-Context Dialogue Abstract: Current dialogue systems focus more on textual and speech context knowledge\nand are usually based on two speakers. Some recent work has investigated static\nimage-based dialogue. However, several real-world human interactions also\ninvolve dynamic visual context (similar to videos) as well as dialogue\nexchanges among multiple speakers. To move closer towards such multimodal\nconversational skills and visually-situated applications, we introduce a new\nvideo-context, many-speaker dialogue dataset based on live-broadcast soccer\ngame videos and chats from Twitch.tv. This challenging testbed allows us to\ndevelop visually-grounded dialogue models that should generate relevant\ntemporal and spatial event language from the live video, while also being\nrelevant to the chat history. For strong baselines, we also present several\ndiscriminative and generative models, e.g., based on tridirectional attention\nflow (TriDAF). We evaluate these models via retrieval ranking-recall, automatic\nphrase-matching metrics, as well as human evaluation studies. We also present\ndataset analyses, model ablations, and visualizations to understand the\ncontribution of different modalities and model components. \n\n"}
{"id": "1809.04705", "contents": "Title: Distilled Wasserstein Learning for Word Embedding and Topic Modeling Abstract: We propose a novel Wasserstein method with a distillation mechanism, yielding\njoint learning of word embeddings and topics. The proposed method is based on\nthe fact that the Euclidean distance between word embeddings may be employed as\nthe underlying distance in the Wasserstein topic model. The word distributions\nof topics, their optimal transports to the word distributions of documents, and\nthe embeddings of words are learned in a unified framework. When learning the\ntopic model, we leverage a distilled underlying distance matrix to update the\ntopic distributions and smoothly calculate the corresponding optimal\ntransports. Such a strategy provides the updating of word embeddings with\nrobust guidance, improving the algorithmic convergence. As an application, we\nfocus on patient admission records, in which the proposed method embeds the\ncodes of diseases and procedures and learns the topics of admissions, obtaining\nsuperior performance on clinically-meaningful disease network construction,\nmortality prediction as a function of admission codes, and procedure\nrecommendation. \n\n"}
{"id": "1809.04938", "contents": "Title: LiveBot: Generating Live Video Comments Based on Visual and Textual\n  Contexts Abstract: We introduce the task of automatic live commenting. Live commenting, which is\nalso called `video barrage', is an emerging feature on online video sites that\nallows real-time comments from viewers to fly across the screen like bullets or\nroll at the right side of the screen. The live comments are a mixture of\nopinions for the video and the chit chats with other comments. Automatic live\ncommenting requires AI agents to comprehend the videos and interact with human\nviewers who also make the comments, so it is a good testbed of an AI agent's\nability of dealing with both dynamic vision and language. In this work, we\nconstruct a large-scale live comment dataset with 2,361 videos and 895,929 live\ncomments. Then, we introduce two neural models to generate live comments based\non the visual and textual contexts, which achieve better performance than\nprevious neural baselines such as the sequence-to-sequence model. Finally, we\nprovide a retrieval-based evaluation protocol for automatic live commenting\nwhere the model is asked to sort a set of candidate comments based on the\nlog-likelihood score, and evaluated on metrics such as mean-reciprocal-rank.\nPutting it all together, we demonstrate the first `LiveBot'. \n\n"}
{"id": "1809.05054", "contents": "Title: IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic\n  Oracles Abstract: We present a sequence-to-action parsing approach for the natural language to\nSQL task that incrementally fills the slots of a SQL query with feasible\nactions from a pre-defined inventory. To account for the fact that typically\nthere are multiple correct SQL queries with the same or very similar semantics,\nwe draw inspiration from syntactic parsing techniques and propose to train our\nsequence-to-action models with non-deterministic oracles. We evaluate our\nmodels on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the\ntest set, a 2.1% absolute improvement over the models trained with traditional\nstatic oracles assuming a single correct target SQL query. When further\ncombined with the execution-guided decoding strategy, our model sets a new\nstate-of-the-art performance at an execution accuracy of 87.1%. \n\n"}
{"id": "1809.05218", "contents": "Title: Freezing Subnetworks to Analyze Domain Adaptation in Neural Machine\n  Translation Abstract: To better understand the effectiveness of continued training, we analyze the\nmajor components of a neural machine translation system (the encoder, decoder,\nand each embedding space) and consider each component's contribution to, and\ncapacity for, domain adaptation. We find that freezing any single component\nduring continued training has minimal impact on performance, and that\nperformance is surprisingly good when a single component is adapted while\nholding the rest of the model fixed. We also find that continued training does\nnot move the model very far from the out-of-domain model, compared to a\nsensitivity analysis metric, suggesting that the out-of-domain model can\nprovide a good generic initialization for the new domain. \n\n"}
{"id": "1809.05296", "contents": "Title: Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory Abstract: For dialogue response generation, traditional generative models generate\nresponses solely from input queries. Such models rely on insufficient\ninformation for generating a specific response since a certain query could be\nanswered in multiple ways. Consequentially, those models tend to output generic\nand dull responses, impeding the generation of informative utterances.\nRecently, researchers have attempted to fill the information gap by exploiting\ninformation retrieval techniques. When generating a response for a current\nquery, similar dialogues retrieved from the entire training data are considered\nas an additional knowledge source. While this may harvest massive information,\nthe generative models could be overwhelmed, leading to undesirable performance.\nIn this paper, we propose a new framework which exploits retrieval results via\na skeleton-then-response paradigm. At first, a skeleton is generated by\nrevising the retrieved responses. Then, a novel generative model uses both the\ngenerated skeleton and the original query for response generation. Experimental\nresults show that our approaches significantly improve the diversity and\ninformativeness of the generated responses. \n\n"}
{"id": "1809.05726", "contents": "Title: Answering Science Exam Questions Using Query Rewriting with Background\n  Knowledge Abstract: Open-domain question answering (QA) is an important problem in AI and NLP\nthat is emerging as a bellwether for progress on the generalizability of AI\nmethods and techniques. Much of the progress in open-domain QA systems has been\nrealized through advances in information retrieval methods and corpus\nconstruction. In this paper, we focus on the recently introduced ARC Challenge\ndataset, which contains 2,590 multiple choice questions authored for\ngrade-school science exams. These questions are selected to be the most\nchallenging for current QA systems, and current state of the art performance is\nonly slightly better than random chance. We present a system that rewrites a\ngiven question into queries that are used to retrieve supporting text from a\nlarge corpus of science-related text. Our rewriter is able to incorporate\nbackground knowledge from ConceptNet and -- in tandem with a generic textual\nentailment system trained on SciTail that identifies support in the retrieved\nresults -- outperforms several strong baselines on the end-to-end QA task\ndespite only being trained to identify essential terms in the original source\nquestion. We use a generalizable decision methodology over the retrieved\nevidence and answer candidates to select the best answer. By combining query\nrewriting, background knowledge, and textual entailment our system is able to\noutperform several strong baselines on the ARC dataset. \n\n"}
{"id": "1809.05807", "contents": "Title: Dual Memory Network Model for Biased Product Review Classification Abstract: In sentiment analysis (SA) of product reviews, both user and product\ninformation are proven to be useful. Current tasks handle user profile and\nproduct information in a unified model which may not be able to learn salient\nfeatures of users and products effectively. In this work, we propose a dual\nuser and product memory network (DUPMN) model to learn user profiles and\nproduct reviews using separate memory networks. Then, the two representations\nare used jointly for sentiment prediction. The use of separate models aims to\ncapture user profiles and product information more effectively. Compared to\nstate-of-the-art unified prediction models, the evaluations on three benchmark\ndatasets, IMDB, Yelp13, and Yelp14, show that our dual learning model gives\nperformance gain of 0.6%, 1.2%, and 0.9%, respectively. The improvements are\nalso deemed very significant measured by p-values. \n\n"}
{"id": "1809.05886", "contents": "Title: Meta-Embedding as Auxiliary Task Regularization Abstract: Word embeddings have been shown to benefit from ensambling several word\nembedding sources, often carried out using straightforward mathematical\noperations over the set of word vectors. More recently, self-supervised\nlearning has been used to find a lower-dimensional representation, similar in\nsize to the individual word embeddings within the ensemble. However, these\nmethods do not use the available manually labeled datasets that are often used\nsolely for the purpose of evaluation. We propose to reconstruct an ensemble of\nword embeddings as an auxiliary task that regularises a main task while both\ntasks share the learned meta-embedding layer. We carry out intrinsic evaluation\n(6 word similarity datasets and 3 analogy datasets) and extrinsic evaluation (4\ndownstream tasks). For intrinsic task evaluation, supervision comes from\nvarious labeled word similarity datasets. Our experimental results show that\nthe performance is improved for all word similarity datasets when compared to\nself-supervised learning methods with a mean increase of $11.33$ in Spearman\ncorrelation. Specifically, the proposed method shows the best performance in 4\nout of 6 of word similarity datasets when using a cosine reconstruction loss\nand Brier's word similarity loss. Moreover, improvements are also made when\nperforming word meta-embedding reconstruction in sequence tagging and sentence\nmeta-embedding for sentence classification. \n\n"}
{"id": "1809.06214", "contents": "Title: Unsupervised Stylish Image Description Generation via Domain Layer Norm Abstract: Most of the existing works on image description focus on generating\nexpressive descriptions. The only few works that are dedicated to generating\nstylish (e.g., romantic, lyric, etc.) descriptions suffer from limited style\nvariation and content digression. To address these limitations, we propose a\ncontrollable stylish image description generation model. It can learn to\ngenerate stylish image descriptions that are more related to image content and\ncan be trained with the arbitrary monolingual corpus without collecting new\npaired image and stylish descriptions. Moreover, it enables users to generate\nvarious stylish descriptions by plugging in style-specific parameters to\ninclude new styles into the existing model. We achieve this capability via a\nnovel layer normalization layer design, which we will refer to as the Domain\nLayer Norm (DLN). Extensive experimental validation and user study on various\nstylish image description generation tasks are conducted to show the\ncompetitive advantages of the proposed model. \n\n"}
{"id": "1809.06309", "contents": "Title: Commonsense for Generative Multi-Hop Question Answering Tasks Abstract: Reading comprehension QA tasks have seen a recent surge in popularity, yet\nmost works have focused on fact-finding extractive QA. We instead focus on a\nmore challenging multi-hop generative task (NarrativeQA), which requires the\nmodel to reason, gather, and synthesize disjoint pieces of information within\nthe context to generate an answer. This type of multi-step reasoning also often\nrequires understanding implicit relations, which humans resolve via external,\nbackground commonsense knowledge. We first present a strong generative baseline\nthat uses a multi-attention mechanism to perform multiple hops of reasoning and\na pointer-generator decoder to synthesize the answer. This model performs\nsubstantially better than previous generative models, and is competitive with\ncurrent state-of-the-art span prediction models. We next introduce a novel\nsystem for selecting grounded multi-hop relational commonsense information from\nConceptNet via a pointwise mutual information and term-frequency based scoring\nfunction. Finally, we effectively use this extracted commonsense information to\nfill in gaps of reasoning between context hops, using a selectively-gated\nattention mechanism. This boosts the model's performance significantly (also\nverified via human evaluation), establishing a new state-of-the-art for the\ntask. We also show promising initial results of the generalizability of our\nbackground knowledge enhancements by demonstrating some improvement on\nQAngaroo-WikiHop, another multi-hop reasoning dataset. \n\n"}
{"id": "1809.06641", "contents": "Title: Talking to myself: self-dialogues as data for conversational agents Abstract: Conversational agents are gaining popularity with the increasing ubiquity of\nsmart devices. However, training agents in a data driven manner is challenging\ndue to a lack of suitable corpora. This paper presents a novel method for\ngathering topical, unstructured conversational data in an efficient way:\nself-dialogues through crowd-sourcing. Alongside this paper, we include a\ncorpus of 3.6 million words across 23 topics. We argue the utility of the\ncorpus by comparing self-dialogues with standard two-party conversations as\nwell as data from other corpora. \n\n"}
{"id": "1809.06858", "contents": "Title: FRAGE: Frequency-Agnostic Word Representation Abstract: Continuous word representation (aka word embedding) is a basic building block\nin many neural network-based models used in natural language processing tasks.\nAlthough it is widely accepted that words with similar semantics should be\nclose to each other in the embedding space, we find that word embeddings\nlearned in several tasks are biased towards word frequency: the embeddings of\nhigh-frequency and low-frequency words lie in different subregions of the\nembedding space, and the embedding of a rare word and a popular word can be far\nfrom each other even if they are semantically similar. This makes learned word\nembeddings ineffective, especially for rare words, and consequently limits the\nperformance of these neural network models. In this paper, we develop a neat,\nsimple yet effective way to learn \\emph{FRequency-AGnostic word Embedding}\n(FRAGE) using adversarial training. We conducted comprehensive studies on ten\ndatasets across four natural language processing tasks, including word\nsimilarity, language modeling, machine translation and text classification.\nResults show that with FRAGE, we achieve higher performance than the baselines\nin all tasks. \n\n"}
{"id": "1809.08711", "contents": "Title: Recognizing Film Entities in Podcasts Abstract: In this paper, we propose a Named Entity Recognition (NER) system to identify\nfilm titles in podcast audio. Taking inspiration from NER systems for noisy\ntext in social media, we implement a two-stage approach that is robust to\ncomputer transcription errors and does not require significant computational\nexpense to accommodate new film titles/releases. Evaluating on a diverse set of\npodcasts, we demonstrate more than a 20% increase in F1 score across three\nbaseline approaches when combining fuzzy-matching with a linear model aware of\nfilm-specific metadata. \n\n"}
{"id": "1809.08726", "contents": "Title: Context-Aware Attention for Understanding Twitter Abuse Abstract: The original goal of any social media platform is to facilitate users to\nindulge in healthy and meaningful conversations. But more often than not, it\nhas been found that it becomes an avenue for wanton attacks. We want to\nalleviate this issue and hence we try to provide a detailed analysis of how\nabusive behavior can be monitored in Twitter. The complexity of the natural\nlanguage constructs makes this task challenging. We show how applying\ncontextual attention to Long Short Term Memory networks help us give near state\nof art results on multiple benchmarks abuse detection data sets from Twitter. \n\n"}
{"id": "1809.08799", "contents": "Title: Chargrid: Towards Understanding 2D Documents Abstract: We introduce a novel type of text representation that preserves the 2D layout\nof a document. This is achieved by encoding each document page as a\ntwo-dimensional grid of characters. Based on this representation, we present a\ngeneric document understanding pipeline for structured documents. This pipeline\nmakes use of a fully convolutional encoder-decoder network that predicts a\nsegmentation mask and bounding boxes. We demonstrate its capabilities on an\ninformation extraction task from invoices and show that it significantly\noutperforms approaches based on sequential text or document images. \n\n"}
{"id": "1809.08962", "contents": "Title: WiRe57 : A Fine-Grained Benchmark for Open Information Extraction Abstract: We build a reference for the task of Open Information Extraction, on five\ndocuments. We tentatively resolve a number of issues that arise, including\ninference and granularity. We seek to better pinpoint the requirements for the\ntask. We produce our annotation guidelines specifying what is correct to\nextract and what is not. In turn, we use this reference to score existing Open\nIE systems. We address the non-trivial problem of evaluating the extractions\nproduced by systems against the reference tuples, and share our evaluation\nscript. Among seven compared extractors, we find the MinIE system to perform\nbest. \n\n"}
{"id": "1809.10040", "contents": "Title: Language Modeling Teaches You More Syntax than Translation Does: Lessons\n  Learned Through Auxiliary Task Analysis Abstract: Recent work using auxiliary prediction task classifiers to investigate the\nproperties of LSTM representations has begun to shed light on why pretrained\nrepresentations, like ELMo (Peters et al., 2018) and CoVe (McCann et al.,\n2017), are so beneficial for neural language understanding models. We still,\nthough, do not yet have a clear understanding of how the choice of pretraining\nobjective affects the type of linguistic information that models learn. With\nthis in mind, we compare four objectives---language modeling, translation,\nskip-thought, and autoencoding---on their ability to induce syntactic and\npart-of-speech information. We make a fair comparison between the tasks by\nholding constant the quantity and genre of the training data, as well as the\nLSTM architecture. We find that representations from language models\nconsistently perform best on our syntactic auxiliary prediction tasks, even\nwhen trained on relatively small amounts of data. These results suggest that\nlanguage modeling may be the best data-rich pretraining task for transfer\nlearning applications requiring syntactic information. We also find that the\nrepresentations from randomly-initialized, frozen LSTMs perform strikingly well\non our syntactic auxiliary tasks, but this effect disappears when the amount of\ntraining data for the auxiliary tasks is reduced. \n\n"}
{"id": "1809.10044", "contents": "Title: No One is Perfect: Analysing the Performance of Question Answering\n  Components over the DBpedia Knowledge Graph Abstract: Question answering (QA) over knowledge graphs has gained significant momentum\nover the past five years due to the increasing availability of large knowledge\ngraphs and the rising importance of question answering for user interaction.\nDBpedia has been the most prominently used knowledge graph in this setting and\nmost approaches currently use a pipeline of processing steps connecting a\nsequence of components. In this article, we analyse and micro evaluate the\nbehaviour of 29 available QA components for DBpedia knowledge graph that were\nreleased by the research community since 2010. As a result, we provide a\nperspective on collective failure cases, suggest characteristics of QA\ncomponents that prevent them from performing better and provide future\nchallenges and research directions for the field. \n\n"}
{"id": "1809.10282", "contents": "Title: Adaptive Pruning of Neural Language Models for Mobile Devices Abstract: Neural language models (NLMs) exist in an accuracy-efficiency tradeoff space\nwhere better perplexity typically comes at the cost of greater computation\ncomplexity. In a software keyboard application on mobile devices, this\ntranslates into higher power consumption and shorter battery life. This paper\nrepresents the first attempt, to our knowledge, in exploring\naccuracy-efficiency tradeoffs for NLMs. Building on quasi-recurrent neural\nnetworks (QRNNs), we apply pruning techniques to provide a \"knob\" to select\ndifferent operating points. In addition, we propose a simple technique to\nrecover some perplexity using a negligible amount of memory. Our empirical\nevaluations consider both perplexity as well as energy consumption on a\nRaspberry Pi, where we demonstrate which methods provide the best\nperplexity-power consumption operating point. At one operating point, one of\nthe techniques is able to provide energy savings of 40% over the state of the\nart with only a 17% relative increase in perplexity. \n\n"}
{"id": "1809.10617", "contents": "Title: Enabling FAIR Research in Earth Science through Research Objects Abstract: Data-intensive science communities are progressively adopting FAIR practices\nthat enhance the visibility of scientific breakthroughs and enable reuse. At\nthe core of this movement, research objects contain and describe scientific\ninformation and resources in a way compliant with the FAIR principles and\nsustain the development of key infrastructure and tools. This paper provides an\naccount of the challenges, experiences and solutions involved in the adoption\nof FAIR around research objects over several Earth Science disciplines. During\nthis journey, our work has been comprehensive, with outcomes including: an\nextended research object model adapted to the needs of earth scientists; the\nprovisioning of digital object identifiers (DOI) to enable persistent\nidentification and to give due credit to authors; the generation of\ncontent-based, semantically rich, research object metadata through natural\nlanguage processing, enhancing visibility and reuse through recommendation\nsystems and third-party search engines; and various types of checklists that\nprovide a compact representation of research object quality as a key enabler of\nscientific reuse. All these results have been integrated in ROHub, a platform\nthat provides research object management functionality to a wealth of\napplications and interfaces across different scientific communities. To monitor\nand quantify the community uptake of research objects, we have defined\nindicators and obtained measures via ROHub that are also discussed herein. \n\n"}
{"id": "1810.00438", "contents": "Title: Parameter-free Sentence Embedding via Orthogonal Basis Abstract: We propose a simple and robust non-parameterized approach for building\nsentence representations. Inspired by the Gram-Schmidt Process in geometric\ntheory, we build an orthogonal basis of the subspace spanned by a word and its\nsurrounding context in a sentence. We model the semantic meaning of a word in a\nsentence based on two aspects. One is its relatedness to the word vector\nsubspace already spanned by its contextual words. The other is the word's novel\nsemantic meaning which shall be introduced as a new basis vector perpendicular\nto this existing subspace. Following this motivation, we develop an innovative\nmethod based on orthogonal basis to combine pre-trained word embeddings into\nsentence representations. This approach requires zero parameters, along with\nefficient inference performance. We evaluate our approach on 11 downstream NLP\ntasks. Our model shows superior performance compared with non-parameterized\nalternatives and it is competitive to other approaches relying on either large\namounts of labelled data or prolonged training time. \n\n"}
{"id": "1810.00472", "contents": "Title: Automatic Evaluation of Neural Personality-based Chatbots Abstract: Stylistic variation is critical to render the utterances generated by\nconversational agents natural and engaging. In this paper, we focus on\nsequence-to-sequence models for open-domain dialogue response generation and\npropose a new method to evaluate the extent to which such models are able to\ngenerate responses that reflect different personality traits. \n\n"}
{"id": "1810.00660", "contents": "Title: Attention-based Encoder-Decoder Networks for Spelling and Grammatical\n  Error Correction Abstract: Automatic spelling and grammatical correction systems are one of the most\nwidely used tools within natural language applications. In this thesis, we\nassume the task of error correction as a type of monolingual machine\ntranslation where the source sentence is potentially erroneous and the target\nsentence should be the corrected form of the input. Our main focus in this\nproject is building neural network models for the task of error correction. In\nparticular, we investigate sequence-to-sequence and attention-based models\nwhich have recently shown a higher performance than the state-of-the-art of\nmany language processing problems. We demonstrate that neural machine\ntranslation models can be successfully applied to the task of error correction.\n  While the experiments of this research are performed on an Arabic corpus, our\nmethods in this thesis can be easily applied to any language. \n\n"}
{"id": "1810.00956", "contents": "Title: Challenges of Using Text Classifiers for Causal Inference Abstract: Causal understanding is essential for many kinds of decision-making, but\ncausal inference from observational data has typically only been applied to\nstructured, low-dimensional datasets. While text classifiers produce\nlow-dimensional outputs, their use in causal inference has not previously been\nstudied. To facilitate causal analyses based on language data, we consider the\nrole that text classifiers can play in causal inference through established\nmodeling mechanisms from the causality literature on missing data and\nmeasurement error. We demonstrate how to conduct causal analyses using text\nclassifiers on simulated and Yelp data, and discuss the opportunities and\nchallenges of future work that uses text data in causal inference. \n\n"}
{"id": "1810.01170", "contents": "Title: Findings of the E2E NLG Challenge Abstract: This paper summarises the experimental setup and results of the first shared\ntask on end-to-end (E2E) natural language generation (NLG) in spoken dialogue\nsystems. Recent end-to-end generation systems are promising since they reduce\nthe need for data annotation. However, they are currently limited to small,\ndelexicalised datasets. The E2E NLG shared task aims to assess whether these\nnovel approaches can generate better-quality output by learning from a dataset\ncontaining higher lexical richness, syntactic complexity and diverse discourse\nphenomena. We compare 62 systems submitted by 17 institutions, covering a wide\nrange of approaches, including machine learning architectures -- with the\nmajority implementing sequence-to-sequence models (seq2seq) -- as well as\nsystems based on grammatical rules and templates. \n\n"}
{"id": "1810.02338", "contents": "Title: Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language\n  Understanding Abstract: We marry two powerful ideas: deep representation learning for visual\nrecognition and language understanding, and symbolic program execution for\nreasoning. Our neural-symbolic visual question answering (NS-VQA) system first\nrecovers a structural scene representation from the image and a program trace\nfrom the question. It then executes the program on the scene representation to\nobtain an answer. Incorporating symbolic structure as prior knowledge offers\nthree unique advantages. First, executing programs on a symbolic space is more\nrobust to long program traces; our model can solve complex reasoning tasks\nbetter, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model\nis more data- and memory-efficient: it performs well after learning on a small\nnumber of training data; it can also encode an image into a compact\nrepresentation, requiring less storage than existing methods for offline\nquestion answering. Third, symbolic program execution offers full transparency\nto the reasoning process; we are thus able to interpret and diagnose each\nexecution step. \n\n"}
{"id": "1810.03459", "contents": "Title: Multilingual sequence-to-sequence speech recognition: architecture,\n  transfer learning, and language modeling Abstract: Sequence-to-sequence (seq2seq) approach for low-resource ASR is a relatively\nnew direction in speech research. The approach benefits by performing model\ntraining without using lexicon and alignments. However, this poses a new\nproblem of requiring more data compared to conventional DNN-HMM systems. In\nthis work, we attempt to use data from 10 BABEL languages to build a\nmulti-lingual seq2seq model as a prior model, and then port them towards 4\nother BABEL languages using transfer learning approach. We also explore\ndifferent architectures for improving the prior multilingual seq2seq model. The\npaper also discusses the effect of integrating a recurrent neural network\nlanguage model (RNNLM) with a seq2seq model during decoding. Experimental\nresults show that the transfer learning approach from the multilingual model\nshows substantial gains over monolingual models across all 4 BABEL languages.\nIncorporating an RNNLM also brings significant improvements in terms of %WER,\nand achieves recognition performance comparable to the models trained with\ntwice more training data. \n\n"}
{"id": "1810.03552", "contents": "Title: Multi-Source Cross-Lingual Model Transfer: Learning What to Share Abstract: Modern NLP applications have enjoyed a great boost utilizing neural networks\nmodels. Such deep neural models, however, are not applicable to most human\nlanguages due to the lack of annotated training data for various NLP tasks.\nCross-lingual transfer learning (CLTL) is a viable method for building NLP\nmodels for a low-resource target language by leveraging labeled data from other\n(source) languages. In this work, we focus on the multilingual transfer setting\nwhere training data in multiple source languages is leveraged to further boost\ntarget language performance.\n  Unlike most existing methods that rely only on language-invariant features\nfor CLTL, our approach coherently utilizes both language-invariant and\nlanguage-specific features at instance level. Our model leverages adversarial\nnetworks to learn language-invariant features, and mixture-of-experts models to\ndynamically exploit the similarity between the target language and each\nindividual source language. This enables our model to learn effectively what to\nshare between various languages in the multilingual setup. Moreover, when\ncoupled with unsupervised multilingual embeddings, our model can operate in a\nzero-resource setting where neither target language training data nor\ncross-lingual resources are available. Our model achieves significant\nperformance gains over prior art, as shown in an extensive set of experiments\nover multiple text classification and sequence tagging tasks including a\nlarge-scale industry dataset. \n\n"}
{"id": "1810.03947", "contents": "Title: textTOvec: Deep Contextualized Neural Autoregressive Topic Models of\n  Language with Distributed Compositional Prior Abstract: We address two challenges of probabilistic topic modelling in order to better\nestimate the probability of a word in a given context, i.e., P(word|context):\n(1) No Language Structure in Context: Probabilistic topic models ignore word\norder by summarizing a given context as a \"bag-of-word\" and consequently the\nsemantics of words in the context is lost. The LSTM-LM learns a vector-space\nrepresentation of each word by accounting for word order in local collocation\npatterns and models complex characteristics of language (e.g., syntax and\nsemantics), while the TM simultaneously learns a latent representation from the\nentire document and discovers the underlying thematic structure. We unite two\ncomplementary paradigms of learning the meaning of word occurrences by\ncombining a TM (e.g., DocNADE) and a LM in a unified probabilistic framework,\nnamed as ctx-DocNADE. (2) Limited Context and/or Smaller training corpus of\ndocuments: In settings with a small number of word occurrences (i.e., lack of\ncontext) in short text or data sparsity in a corpus of few documents, the\napplication of TMs is challenging. We address this challenge by incorporating\nexternal knowledge into neural autoregressive topic models via a language\nmodelling approach: we use word embeddings as input of a LSTM-LM with the aim\nto improve the word-topic mapping on a smaller and/or short-text corpus. The\nproposed DocNADE extension is named as ctx-DocNADEe.\n  We present novel neural autoregressive topic model variants coupled with\nneural LMs and embeddings priors that consistently outperform state-of-the-art\ngenerative TMs in terms of generalization (perplexity), interpretability (topic\ncoherence) and applicability (retrieval and classification) over 6 long-text\nand 8 short-text datasets from diverse domains. \n\n"}
{"id": "1810.04631", "contents": "Title: Extracting Arguments from Korean Question and Command: An Annotated\n  Corpus for Structured Paraphrasing Abstract: Intention identification is a core issue in dialog management. However, due\nto the non-canonicality of the spoken language, it is difficult to extract the\ncontent automatically from the conversation-style utterances. This is much more\nchallenging for languages like Korean and Japanese since the agglutination\nbetween morphemes make it difficult for the machines to parse the sentence and\nunderstand the intention. To suggest a guideline for this problem, and to merge\nthe issue flexibly with the neural paraphrasing systems introduced recently, we\npropose a structured annotation scheme for Korean question/commands and the\nresulting corpus which are widely applicable to the field of argument mining.\nThe scheme and dataset are expected to help machines understand the intention\nof natural language and grasp the core meaning of conversation-style\ninstructions. \n\n"}
{"id": "1810.04882", "contents": "Title: Towards Understanding Linear Word Analogies Abstract: A surprising property of word vectors is that word analogies can often be\nsolved with vector arithmetic. However, it is unclear why arithmetic operators\ncorrespond to non-linear embedding models such as skip-gram with negative\nsampling (SGNS). We provide a formal explanation of this phenomenon without\nmaking the strong assumptions that past theories have made about the vector\nspace and word distribution. Our theory has several implications. Past work has\nconjectured that linear substructures exist in vector spaces because relations\ncan be represented as ratios; we prove that this holds for SGNS. We provide\nnovel justification for the addition of SGNS word vectors by showing that it\nautomatically down-weights the more frequent word, as weighting schemes do ad\nhoc. Lastly, we offer an information theoretic interpretation of Euclidean\ndistance in vector spaces, justifying its use in capturing word dissimilarity. \n\n"}
{"id": "1810.05102", "contents": "Title: Neural Relation Extraction Within and Across Sentence Boundaries Abstract: Past work in relation extraction mostly focuses on binary relation between\nentity pairs within single sentence. Recently, the NLP community has gained\ninterest in relation extraction in entity pairs spanning multiple sentences. In\nthis paper, we propose a novel architecture for this task: inter-sentential\ndependency-based neural networks (iDepNN). iDepNN models the shortest and\naugmented dependency paths via recurrent and recursive neural networks to\nextract relationships within (intra-) and across (inter-) sentence boundaries.\nCompared to SVM and neural network baselines, iDepNN is more robust to false\npositives in relationships spanning sentences.\n  We evaluate our models on four datasets from newswire (MUC6) and medical\n(BioNLP shared task) domains that achieve state-of-the-art performance and show\na better balance in precision and recall for inter-sentential relationships. We\nperform better than 11 teams participating in the BioNLP shared task 2016 and\nachieve a gain of 5.2% (0.587 vs 0.558) in F1 over the winning team. We also\nrelease the crosssentence annotations for MUC6. \n\n"}
{"id": "1810.05237", "contents": "Title: SyntaxSQLNet: Syntax Tree Networks for Complex and\n  Cross-DomainText-to-SQL Task Abstract: Most existing studies in text-to-SQL tasks do not require generating complex\nSQL queries with multiple clauses or sub-queries, and generalizing to new,\nunseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network\nto address the complex and cross-domain text-to-SQL generation task.\nSyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL\ngeneration path history and table-aware column attention encoders. We evaluate\nSyntaxSQLNet on the Spider text-to-SQL task, which contains databases with\nmultiple tables and complex SQL queries with multiple SQL clauses and nested\nqueries. We use a database split setting where databases in the test set are\nunseen during training. Experimental results show that SyntaxSQLNet can handle\na significantly greater number of complex SQL examples than prior work,\noutperforming the previous state-of-the-art model by 7.3% in exact matching\naccuracy. We also show that SyntaxSQLNet can further improve the performance by\nan additional 7.5% using a cross-domain augmentation method, resulting in a\n14.8% improvement in total. To our knowledge, we are the first to study this\ncomplex and cross-domain text-to-SQL task. \n\n"}
{"id": "1810.05474", "contents": "Title: Pre-gen metrics: Predicting caption quality metrics without generating\n  captions Abstract: Image caption generation systems are typically evaluated against reference\noutputs. We show that it is possible to predict output quality without\ngenerating the captions, based on the probability assigned by the neural model\nto the reference captions. Such pre-gen metrics are strongly correlated to\nstandard evaluation metrics. \n\n"}
{"id": "1810.05867", "contents": "Title: An Empirical Study on Crosslingual Transfer in Probabilistic Topic\n  Models Abstract: Probabilistic topic modeling is a popular choice as the first step of\ncrosslingual tasks to enable knowledge transfer and extract multilingual\nfeatures. While many multilingual topic models have been developed, their\nassumptions on the training corpus are quite varied, and it is not clear how\nwell the models can be applied under various training conditions. In this\npaper, we systematically study the knowledge transfer mechanisms behind\ndifferent multilingual topic models, and through a broad set of experiments\nwith four models on ten languages, we provide empirical insights that can\ninform the selection and future development of multilingual topic models. \n\n"}
{"id": "1810.06351", "contents": "Title: (Self-Attentive) Autoencoder-based Universal Language Representation for\n  Machine Translation Abstract: Universal language representation is the holy grail in machine translation\n(MT). Thanks to the new neural MT approach, it seems that there are good\nperspectives towards this goal. In this paper, we propose a new architecture\nbased on combining variational autoencoders with encoder-decoders and\nintroducing an interlingual loss as an additional training objective. By adding\nand forcing this interlingual loss, we are able to train multiple encoders and\ndecoders for each language, sharing a common universal representation. Since\nthe final objective of this universal representation is producing close results\nfor similar input sentences (in any language), we propose to evaluate it by\nencoding the same sentence in two different languages, decoding both latent\nrepresentations into the same language and comparing both outputs. Preliminary\nresults on the WMT 2017 Turkish/English task shows that the proposed\narchitecture is capable of learning a universal language representation and\nsimultaneously training both translation directions with state-of-the-art\nresults. \n\n"}
{"id": "1810.06368", "contents": "Title: Neural Adaptation Layers for Cross-domain Named Entity Recognition Abstract: Recent research efforts have shown that neural architectures can be effective\nin conventional information extraction tasks such as named entity recognition,\nyielding state-of-the-art results on standard newswire datasets. However,\ndespite significant resources required for training such models, the\nperformance of a model trained on one domain typically degrades dramatically\nwhen applied to a different domain, yet extracting entities from new emerging\ndomains such as social media can be of significant interest. In this paper, we\nempirically investigate effective methods for conveniently adapting an\nexisting, well-trained neural NER model for a new domain. Unlike existing\napproaches, we propose lightweight yet effective methods for performing domain\nadaptation for neural models. Specifically, we introduce adaptation layers on\ntop of existing neural architectures, where no re-training using the source\ndomain data is required. We conduct extensive empirical studies and show that\nour approach significantly outperforms state-of-the-art methods. \n\n"}
{"id": "1810.06695", "contents": "Title: Exploring the Use of Attention within an Neural Machine Translation\n  Decoder States to Translate Idioms Abstract: Idioms pose problems to almost all Machine Translation systems. This type of\nlanguage is very frequent in day-to-day language use and cannot be simply\nignored. The recent interest in memory augmented models in the field of\nLanguage Modelling has aided the systems to achieve good results by bridging\nlong-distance dependencies. In this paper we explore the use of such techniques\ninto a Neural Machine Translation system to help in translation of idiomatic\nlanguage. \n\n"}
{"id": "1810.07125", "contents": "Title: The CoNLL--SIGMORPHON 2018 Shared Task: Universal Morphological\n  Reinflection Abstract: The CoNLL--SIGMORPHON 2018 shared task on supervised learning of\nmorphological generation featured data sets from 103 typologically diverse\nlanguages. Apart from extending the number of languages involved in earlier\nsupervised tasks of generating inflected forms, this year the shared task also\nfeatured a new second task which asked participants to inflect words in\nsentential context, similar to a cloze task. This second task featured seven\nlanguages. Task 1 received 27 submissions and task 2 received 6 submissions.\nBoth tasks featured a low, medium, and high data condition. Nearly all\nsubmissions featured a neural component and built on highly-ranked systems from\nthe earlier 2017 shared task. In the inflection task (task 1), 41 of the 52\nlanguages present in last year's inflection task showed improvement by the best\nsystems in the low-resource setting. The cloze task (task 2) proved to be\ndifficult, and few submissions managed to consistently improve upon both a\nsimple neural baseline system and a lemma-repeating baseline. \n\n"}
{"id": "1810.07320", "contents": "Title: Exploring Sentence Vector Spaces through Automatic Summarization Abstract: Given vector representations for individual words, it is necessary to compute\nvector representations of sentences for many applications in a compositional\nmanner, often using artificial neural networks.\n  Relatively little work has explored the internal structure and properties of\nsuch sentence vectors. In this paper, we explore the properties of sentence\nvectors in the context of automatic summarization. In particular, we show that\ncosine similarity between sentence vectors and document vectors is strongly\ncorrelated with sentence importance and that vector semantics can identify and\ncorrect gaps between the sentences chosen so far and the document. In addition,\nwe identify specific dimensions which are linked to effective summaries. To our\nknowledge, this is the first time specific dimensions of sentence embeddings\nhave been connected to sentence properties. We also compare the features of\ndifferent methods of sentence embeddings. Many of these insights have\napplications in uses of sentence embeddings far beyond summarization. \n\n"}
{"id": "1810.07942", "contents": "Title: Semantic Parsing for Task Oriented Dialog using Hierarchical\n  Representations Abstract: Task oriented dialog systems typically first parse user utterances to\nsemantic frames comprised of intents and slots. Previous work on task oriented\nintent and slot-filling work has been restricted to one intent per query and\none slot label per token, and thus cannot model complex compositional requests.\nAlternative semantic parsing systems have represented queries as logical forms,\nbut these are challenging to annotate and parse. We propose a hierarchical\nannotation scheme for semantic parsing that allows the representation of\ncompositional queries, and can be efficiently and accurately parsed by standard\nconstituency parsing models. We release a dataset of 44k annotated queries\n(fb.me/semanticparsingdialog), and show that parsing models outperform\nsequence-to-sequence approaches on this dataset. \n\n"}
{"id": "1810.08392", "contents": "Title: Impact of Corpora Quality on Neural Machine Translation Abstract: Large parallel corpora that are automatically obtained from the web,\ndocuments or elsewhere often exhibit many corrupted parts that are bound to\nnegatively affect the quality of the systems and models that learn from these\ncorpora. This paper describes frequent problems found in data and such data\naffects neural machine translation systems, as well as how to identify and deal\nwith them. The solutions are summarised in a set of scripts that remove\nproblematic sentences from input corpora. \n\n"}
{"id": "1810.08732", "contents": "Title: Named Entity Recognition on Twitter for Turkish using Semi-supervised\n  Learning with Word Embeddings Abstract: Recently, due to the increasing popularity of social media, the necessity for\nextracting information from informal text types, such as microblog texts, has\ngained significant attention. In this study, we focused on the Named Entity\nRecognition (NER) problem on informal text types for Turkish. We utilized a\nsemi-supervised learning approach based on neural networks. We applied a fast\nunsupervised method for learning continuous representations of words in vector\nspace. We made use of these obtained word embeddings, together with language\nindependent features that are engineered to work better on informal text types,\nfor generating a Turkish NER system on microblog texts. We evaluated our\nTurkish NER system on Twitter messages and achieved better F-score performances\nthan the published results of previously proposed NER systems on Turkish\ntweets. Since we did not employ any language dependent features, we believe\nthat our method can be easily adapted to microblog texts in other\nmorphologically rich languages. \n\n"}
{"id": "1810.08802", "contents": "Title: Hierarchical Text Generation using an Outline Abstract: Many challenges in natural language processing require generating text,\nincluding language translation, dialogue generation, and speech recognition.\nFor all of these problems, text generation becomes more difficult as the text\nbecomes longer. Current language models often struggle to keep track of\ncoherence for long pieces of text. Here, we attempt to have the model construct\nand use an outline of the text it generates to keep it focused. We find that\nthe usage of an outline improves perplexity. We do not find that using the\noutline improves human evaluation over a simpler baseline, revealing a\ndiscrepancy in perplexity and human perception. Similarly, hierarchical\ngeneration is not found to improve human evaluation scores. \n\n"}
{"id": "1810.08838", "contents": "Title: Abstractive Summarization Using Attentive Neural Techniques Abstract: In a world of proliferating data, the ability to rapidly summarize text is\ngrowing in importance. Automatic summarization of text can be thought of as a\nsequence to sequence problem. Another area of natural language processing that\nsolves a sequence to sequence problem is machine translation, which is rapidly\nevolving due to the development of attention-based encoder-decoder networks.\nThis work applies these modern techniques to abstractive summarization. We\nperform analysis on various attention mechanisms for summarization with the\ngoal of developing an approach and architecture aimed at improving the state of\nthe art. In particular, we modify and optimize a translation model with\nself-attention for generating abstractive sentence summaries. The effectiveness\nof this base model along with attention variants is compared and analyzed in\nthe context of standardized evaluation sets and test metrics. However, we show\nthat these metrics are limited in their ability to effectively score\nabstractive summaries, and propose a new approach based on the intuition that\nan abstractive model requires an abstractive evaluation. \n\n"}
{"id": "1810.10165", "contents": "Title: Resolving Referring Expressions in Images With Labeled Elements Abstract: Images may have elements containing text and a bounding box associated with\nthem, for example, text identified via optical character recognition on a\ncomputer screen image, or a natural image with labeled objects. We present an\nend-to-end trainable architecture to incorporate the information from these\nelements and the image to segment/identify the part of the image a natural\nlanguage expression is referring to. We calculate an embedding for each element\nand then project it onto the corresponding location (i.e., the associated\nbounding box) of the image feature map. We show that this architecture gives an\nimprovement in resolving referring expressions, over only using the image, and\nother methods that incorporate the element information. We demonstrate\nexperimental results on the referring expression datasets based on COCO, and on\na webpage image referring expression dataset that we developed. \n\n"}
{"id": "1810.10183", "contents": "Title: Multi-Head Attention with Disagreement Regularization Abstract: Multi-head attention is appealing for the ability to jointly attend to\ninformation from different representation subspaces at different positions. In\nthis work, we introduce a disagreement regularization to explicitly encourage\nthe diversity among multiple attention heads. Specifically, we propose three\ntypes of disagreement regularization, which respectively encourage the\nsubspace, the attended positions, and the output representation associated with\neach attention head to be different from other heads. Experimental results on\nwidely-used WMT14 English-German and WMT17 Chinese-English translation tasks\ndemonstrate the effectiveness and universality of the proposed approach. \n\n"}
{"id": "1810.10401", "contents": "Title: Image-based Natural Language Understanding Using 2D Convolutional Neural\n  Networks Abstract: We propose a new approach to natural language understanding in which we\nconsider the input text as an image and apply 2D Convolutional Neural Networks\nto learn the local and global semantics of the sentences from the variations\nofthe visual patterns of words. Our approach demonstrates that it is possible\nto get semantically meaningful features from images with text without using\noptical character recognition and sequential processing pipelines, techniques\nthat traditional Natural Language Understanding algorithms require. To validate\nour approach, we present results for two applications: text classification and\ndialog modeling. Using a 2D Convolutional Neural Network, we were able to\noutperform the state-of-art accuracy results of non-Latin alphabet-based text\nclassification and achieved promising results for eight text classification\ndatasets. Furthermore, our approach outperformed the memory networks when using\nout of vocabulary entities fromtask 4 of the bAbI dialog dataset. \n\n"}
{"id": "1810.10437", "contents": "Title: Variational Semi-supervised Aspect-term Sentiment Analysis via\n  Transformer Abstract: Aspect-term sentiment analysis (ATSA) is a longstanding challenge in natural\nlanguage understanding. It requires fine-grained semantical reasoning about a\ntarget entity appeared in the text. As manual annotation over the aspects is\nlaborious and time-consuming, the amount of labeled data is limited for\nsupervised learning. This paper proposes a semi-supervised method for the ATSA\nproblem by using the Variational Autoencoder based on Transformer (VAET), which\nmodels the latent distribution via variational inference. By disentangling the\nlatent representation into the aspect-specific sentiment and the lexical\ncontext, our method induces the underlying sentiment prediction for the\nunlabeled data, which then benefits the ATSA classifier. Our method is\nclassifier agnostic, i.e., the classifier is an independent module and various\nadvanced supervised models can be integrated. Experimental results are obtained\non the SemEval 2014 task 4 and show that our method is effective with four\nclassical classifiers. The proposed method outperforms two general\nsemisupervised methods and achieves state-of-the-art performance. \n\n"}
{"id": "1810.10665", "contents": "Title: Engaging Image Captioning Via Personality Abstract: Standard image captioning tasks such as COCO and Flickr30k are factual,\nneutral in tone and (to a human) state the obvious (e.g., \"a man playing a\nguitar\"). While such tasks are useful to verify that a machine understands the\ncontent of an image, they are not engaging to humans as captions. With this in\nmind we define a new task, Personality-Captions, where the goal is to be as\nengaging to humans as possible by incorporating controllable style and\npersonality traits. We collect and release a large dataset of 201,858 of such\ncaptions conditioned over 215 possible traits. We build models that combine\nexisting work from (i) sentence representations (Mazare et al., 2018) with\nTransformers trained on 1.7 billion dialogue examples; and (ii) image\nrepresentations (Mahajan et al., 2018) with ResNets trained on 3.5 billion\nsocial media images. We obtain state-of-the-art performance on Flickr30k and\nCOCO, and strong performance on our new task. Finally, online evaluations\nvalidate that our task and models are engaging to humans, with our best model\nclose to human performance. \n\n"}
{"id": "1810.10802", "contents": "Title: Tackling Sequence to Sequence Mapping Problems with Neural Networks Abstract: In Natural Language Processing (NLP), it is important to detect the\nrelationship between two sequences or to generate a sequence of tokens given\nanother observed sequence. We call the type of problems on modelling sequence\npairs as sequence to sequence (seq2seq) mapping problems. A lot of research has\nbeen devoted to finding ways of tackling these problems, with traditional\napproaches relying on a combination of hand-crafted features, alignment models,\nsegmentation heuristics, and external linguistic resources. Although great\nprogress has been made, these traditional approaches suffer from various\ndrawbacks, such as complicated pipeline, laborious feature engineering, and the\ndifficulty for domain adaptation. Recently, neural networks emerged as a\npromising solution to many problems in NLP, speech recognition, and computer\nvision. Neural models are powerful because they can be trained end to end,\ngeneralise well to unseen examples, and the same framework can be easily\nadapted to a new domain.\n  The aim of this thesis is to advance the state-of-the-art in seq2seq mapping\nproblems with neural networks. We explore solutions from three major aspects:\ninvestigating neural models for representing sequences, modelling interactions\nbetween sequences, and using unpaired data to boost the performance of neural\nmodels. For each aspect, we propose novel models and evaluate their efficacy on\nvarious tasks of seq2seq mapping. \n\n"}
{"id": "1810.11190", "contents": "Title: Magnitude: A Fast, Efficient Universal Vector Embedding Utility Package Abstract: Vector space embedding models like word2vec, GloVe, fastText, and ELMo are\nextremely popular representations in natural language processing (NLP)\napplications. We present Magnitude, a fast, lightweight tool for utilizing and\nprocessing embeddings. Magnitude is an open source Python package with a\ncompact vector storage file format that allows for efficient manipulation of\nhuge numbers of embeddings. Magnitude performs common operations up to 60 to\n6,000 times faster than Gensim. Magnitude introduces several novel features for\nimproved robustness like out-of-vocabulary lookups. \n\n"}
{"id": "1810.12366", "contents": "Title: Do Explanations make VQA Models more Predictable to a Human? Abstract: A rich line of research attempts to make deep neural networks more\ntransparent by generating human-interpretable 'explanations' of their decision\nprocess, especially for interactive tasks like Visual Question Answering (VQA).\nIn this work, we analyze if existing explanations indeed make a VQA model --\nits responses as well as failures -- more predictable to a human. Surprisingly,\nwe find that they do not. On the other hand, we find that human-in-the-loop\napproaches that treat the model as a black-box do. \n\n"}
{"id": "1810.12546", "contents": "Title: Simplifying Neural Machine Translation with Addition-Subtraction\n  Twin-Gated Recurrent Networks Abstract: In this paper, we propose an additionsubtraction twin-gated recurrent network\n(ATR) to simplify neural machine translation. The recurrent units of ATR are\nheavily simplified to have the smallest number of weight matrices among units\nof all existing gated RNNs. With the simple addition and subtraction operation,\nwe introduce a twin-gated mechanism to build input and forget gates which are\nhighly correlated. Despite this simplification, the essential non-linearities\nand capability of modeling long-distance dependencies are preserved.\nAdditionally, the proposed ATR is more transparent than LSTM/GRU due to the\nsimplification. Forward self-attention can be easily established in ATR, which\nmakes the proposed network interpretable. Experiments on WMT14 translation\ntasks demonstrate that ATR-based neural machine translation can yield\ncompetitive performance on English- German and English-French language pairs in\nterms of both translation quality and speed. Further experiments on NIST\nChinese-English translation, natural language inference and Chinese word\nsegmentation verify the generality and applicability of ATR on different\nnatural language processing tasks. \n\n"}
{"id": "1810.12703", "contents": "Title: Unsupervised Neural Machine Translation Initialized by Unsupervised\n  Statistical Machine Translation Abstract: Recent work achieved remarkable results in training neural machine\ntranslation (NMT) systems in a fully unsupervised way, with new and dedicated\narchitectures that rely on monolingual corpora only. In this work, we propose\nto define unsupervised NMT (UNMT) as NMT trained with the supervision of\nsynthetic bilingual data. Our approach straightforwardly enables the use of\nstate-of-the-art architectures proposed for supervised NMT by replacing\nhuman-made bilingual data with synthetic bilingual data for training. We\npropose to initialize the training of UNMT with synthetic bilingual data\ngenerated by unsupervised statistical machine translation (USMT). The UNMT\nsystem is then incrementally improved using back-translation. Our preliminary\nexperiments show that our approach achieves a new state-of-the-art for\nunsupervised machine translation on the WMT16 German--English news translation\ntask, for both translation directions. \n\n"}
{"id": "1810.12730", "contents": "Title: Audiovisual speaker conversion: jointly and simultaneously transforming\n  facial expression and acoustic characteristics Abstract: An audiovisual speaker conversion method is presented for simultaneously\ntransforming the facial expressions and voice of a source speaker into those of\na target speaker. Transforming the facial and acoustic features together makes\nit possible for the converted voice and facial expressions to be highly\ncorrelated and for the generated target speaker to appear and sound natural. It\nuses three neural networks: a conversion network that fuses and transforms the\nfacial and acoustic features, a waveform generation network that produces the\nwaveform from both the converted facial and acoustic features, and an image\nreconstruction network that outputs an RGB facial image also based on both the\nconverted features. The results of experiments using an emotional audiovisual\ndatabase showed that the proposed method achieved significantly higher\nnaturalness compared with one that separately transformed acoustic and facial\nfeatures. \n\n"}
{"id": "1810.12752", "contents": "Title: Long Short-Term Attention Abstract: Attention is an important cognition process of humans, which helps humans\nconcentrate on critical information during their perception and learning.\nHowever, although many machine learning models can remember information of\ndata, they have no the attention mechanism. For example, the long short-term\nmemory (LSTM) network is able to remember sequential information, but it cannot\npay special attention to part of the sequences. In this paper, we present a\nnovel model called long short-term attention (LSTA), which seamlessly\nintegrates the attention mechanism into the inner cell of LSTM. More than\nprocessing long short term dependencies, LSTA can focus on important\ninformation of the sequences with the attention mechanism. Extensive\nexperiments demonstrate that LSTA outperforms LSTM and related models on the\nsequence learning tasks. \n\n"}
{"id": "1810.13083", "contents": "Title: GraphIE: A Graph-Based Framework for Information Extraction Abstract: Most modern Information Extraction (IE) systems are implemented as sequential\ntaggers and only model local dependencies. Non-local and non-sequential context\nis, however, a valuable source of information to improve predictions. In this\npaper, we introduce GraphIE, a framework that operates over a graph\nrepresenting a broad set of dependencies between textual units (i.e. words or\nsentences). The algorithm propagates information between connected nodes\nthrough graph convolutions, generating a richer representation that can be\nexploited to improve word-level predictions. Evaluation on three different\ntasks --- namely textual, social media and visual information extraction ---\nshows that GraphIE consistently outperforms the state-of-the-art sequence\ntagging model by a significant margin. \n\n"}
{"id": "1810.13097", "contents": "Title: Attentive Neural Network for Named Entity Recognition in Vietnamese Abstract: We propose an attentive neural network for the task of named entity\nrecognition in Vietnamese. The proposed attentive neural model makes use of\ncharacter-based language models and word embeddings to encode words as vector\nrepresentations. A neural network architecture of encoder, attention, and\ndecoder layers is then utilized to encode knowledge of input sentences and to\nlabel entity tags. The experimental results show that the proposed attentive\nneural network achieves the state-of-the-art results on the benchmark named\nentity recognition datasets in Vietnamese in comparison to both hand-crafted\nfeatures based models and neural models. \n\n"}
{"id": "1810.13441", "contents": "Title: Improving Machine Reading Comprehension with General Reading Strategies Abstract: Reading strategies have been shown to improve comprehension levels,\nespecially for readers lacking adequate prior knowledge. Just as the process of\nknowledge accumulation is time-consuming for human readers, it is\nresource-demanding to impart rich general domain knowledge into a deep language\nmodel via pre-training. Inspired by reading strategies identified in cognitive\nscience, and given limited computational resources -- just a pre-trained model\nand a fixed number of training instances -- we propose three general strategies\naimed to improve non-extractive machine reading comprehension (MRC): (i) BACK\nAND FORTH READING that considers both the original and reverse order of an\ninput sequence, (ii) HIGHLIGHTING, which adds a trainable embedding to the text\nembedding of tokens that are relevant to the question and candidate answers,\nand (iii) SELF-ASSESSMENT that generates practice questions and candidate\nanswers directly from the text in an unsupervised manner.\n  By fine-tuning a pre-trained language model (Radford et al., 2018) with our\nproposed strategies on the largest general domain multiple-choice MRC dataset\nRACE, we obtain a 5.8% absolute increase in accuracy over the previous best\nresult achieved by the same pre-trained model fine-tuned on RACE without the\nuse of strategies. We further fine-tune the resulting model on a target MRC\ntask, leading to an absolute improvement of 6.2% in average accuracy over\nprevious state-of-the-art approaches on six representative non-extractive MRC\ndatasets from different domains (i.e., ARC, OpenBookQA, MCTest, SemEval-2018\nTask 11, ROCStories, and MultiRC). These results demonstrate the effectiveness\nof our proposed strategies and the versatility and general applicability of our\nfine-tuned models that incorporate these strategies. Core code is available at\nhttps://github.com/nlpdata/strategy/. \n\n"}
{"id": "1811.00147", "contents": "Title: DOLORES: Deep Contextualized Knowledge Graph Embeddings Abstract: We introduce a new method DOLORES for learning knowledge graph embeddings\nthat effectively captures contextual cues and dependencies among entities and\nrelations. First, we note that short paths on knowledge graphs comprising of\nchains of entities and relations can encode valuable information regarding\ntheir contextual usage. We operationalize this notion by representing knowledge\ngraphs not as a collection of triples but as a collection of entity-relation\nchains, and learn embeddings for entities and relations using deep neural\nmodels that capture such contextual usage. In particular, our model is based on\nBi-Directional LSTMs and learn deep representations of entities and relations\nfrom constructed entity-relation chains. We show that these representations can\nvery easily be incorporated into existing models to significantly advance the\nstate of the art on several knowledge graph prediction tasks like link\nprediction, triple classification, and missing relation type prediction (in\nsome cases by at least 9.5%). \n\n"}
{"id": "1811.00436", "contents": "Title: Unsupervised Dual-Cascade Learning with Pseudo-Feedback Distillation for\n  Query-based Extractive Summarization Abstract: We propose Dual-CES -- a novel unsupervised, query-focused, multi-document\nextractive summarizer. Dual-CES is designed to better handle the tradeoff\nbetween saliency and focus in summarization. To this end, Dual-CES employs a\ntwo-step dual-cascade optimization approach with saliency-based pseudo-feedback\ndistillation. Overall, Dual-CES significantly outperforms all other\nstate-of-the-art unsupervised alternatives. Dual-CES is even shown to be able\nto outperform strong supervised summarizers. \n\n"}
{"id": "1811.00491", "contents": "Title: A Corpus for Reasoning About Natural Language Grounded in Photographs Abstract: We introduce a new dataset for joint reasoning about natural language and\nimages, with a focus on semantic diversity, compositionality, and visual\nreasoning challenges. The data contains 107,292 examples of English sentences\npaired with web photographs. The task is to determine whether a natural\nlanguage caption is true about a pair of photographs. We crowdsource the data\nusing sets of visually rich images and a compare-and-contrast task to elicit\nlinguistically diverse language. Qualitative analysis shows the data requires\ncompositional joint reasoning, including about quantities, comparisons, and\nrelations. Evaluation using state-of-the-art visual reasoning methods shows the\ndata presents a strong challenge. \n\n"}
{"id": "1811.00570", "contents": "Title: On Difficulties of Cross-Lingual Transfer with Order Differences: A Case\n  Study on Dependency Parsing Abstract: Different languages might have different word orders. In this paper, we\ninvestigate cross-lingual transfer and posit that an order-agnostic model will\nperform better when transferring to distant foreign languages. To test our\nhypothesis, we train dependency parsers on an English corpus and evaluate their\ntransfer performance on 30 other languages. Specifically, we compare encoders\nand decoders based on Recurrent Neural Networks (RNNs) and modified\nself-attentive architectures. The former relies on sequential information while\nthe latter is more flexible at modeling word order. Rigorous experiments and\ndetailed analysis shows that RNN-based architectures transfer well to languages\nthat are close to English, while self-attentive models have better overall\ncross-lingual transferability and perform especially well on distant languages. \n\n"}
{"id": "1811.00625", "contents": "Title: Incorporating Structured Commonsense Knowledge in Story Completion Abstract: The ability to select an appropriate story ending is the first step towards\nperfect narrative comprehension. Story ending prediction requires not only the\nexplicit clues within the context, but also the implicit knowledge (such as\ncommonsense) to construct a reasonable and consistent story. However, most\nprevious approaches do not explicitly use background commonsense knowledge. We\npresent a neural story ending selection model that integrates three types of\ninformation: narrative sequence, sentiment evolution and commonsense knowledge.\nExperiments show that our model outperforms state-of-the-art approaches on a\npublic dataset, ROCStory Cloze Task , and the performance gain from adding the\nadditional commonsense knowledge is significant. \n\n"}
{"id": "1811.00707", "contents": "Title: Training Neural Speech Recognition Systems with Synthetic Speech\n  Augmentation Abstract: Building an accurate automatic speech recognition (ASR) system requires a\nlarge dataset that contains many hours of labeled speech samples produced by a\ndiverse set of speakers. The lack of such open free datasets is one of the main\nissues preventing advancements in ASR research. To address this problem, we\npropose to augment a natural speech dataset with synthetic speech. We train\nvery large end-to-end neural speech recognition models using the LibriSpeech\ndataset augmented with synthetic speech. These new models achieve state of the\nart Word Error Rate (WER) for character-level based models without an external\nlanguage model. \n\n"}
{"id": "1811.00728", "contents": "Title: Improving the Robustness of Speech Translation Abstract: Although neural machine translation (NMT) has achieved impressive progress\nrecently, it is usually trained on the clean parallel data set and hence cannot\nwork well when the input sentence is the production of the automatic speech\nrecognition (ASR) system due to the enormous errors in the source. To solve\nthis problem, we propose a simple but effective method to improve the\nrobustness of NMT in the case of speech translation. We simulate the noise\nexisting in the realistic output of the ASR system and inject them into the\nclean parallel data so that NMT can work under similar word distributions\nduring training and testing. Besides, we also incorporate the Chinese Pinyin\nfeature which is easy to get in speech translation to further improve the\ntranslation performance. Experiment results show that our method has a more\nstable performance and outperforms the baseline by an average of 3.12 BLEU on\nmultiple noisy test sets, even while achieves a generalization improvement on\nthe WMT'17 Chinese-English test set. \n\n"}
{"id": "1811.00845", "contents": "Title: Combining Long Short Term Memory and Convolutional Neural Network for\n  Cross-Sentence n-ary Relation Extraction Abstract: We propose in this paper a combined model of Long Short Term Memory and\nConvolutional Neural Networks (LSTM-CNN) that exploits word embeddings and\npositional embeddings for cross-sentence n-ary relation extraction. The\nproposed model brings together the properties of both LSTMs and CNNs, to\nsimultaneously exploit long-range sequential information and capture most\ninformative features, essential for cross-sentence n-ary relation extraction.\nThe LSTM-CNN model is evaluated on standard dataset on cross-sentence n-ary\nrelation extraction, where it significantly outperforms baselines such as CNNs,\nLSTMs and also a combined CNN-LSTM model. The paper also shows that the\nLSTM-CNN model outperforms the current state-of-the-art methods on\ncross-sentence n-ary relation extraction. \n\n"}
{"id": "1811.00998", "contents": "Title: Analysing Dropout and Compounding Errors in Neural Language Models Abstract: This paper carries out an empirical analysis of various dropout techniques\nfor language modelling, such as Bernoulli dropout, Gaussian dropout, Curriculum\nDropout, Variational Dropout and Concrete Dropout. Moreover, we propose an\nextension of variational dropout to concrete dropout and curriculum dropout\nwith varying schedules. We find these extensions to perform well when compared\nto standard dropout approaches, particularly variational curriculum dropout\nwith a linear schedule. Largest performance increases are made when applying\ndropout on the decoder layer. Lastly, we analyze where most of the errors occur\nat test time as a post-analysis step to determine if the well-known problem of\ncompounding errors is apparent and to what end do the proposed methods mitigate\nthis issue for each dataset. We report results on a 2-hidden layer LSTM, GRU\nand Highway network with embedding dropout, dropout on the gated hidden layers\nand the output projection layer for each model. We report our results on\nPenn-TreeBank and WikiText-2 word-level language modelling datasets, where the\nformer reduces the long-tail distribution through preprocessing and one which\npreserves rare words in the training and test set. \n\n"}
{"id": "1811.01088", "contents": "Title: Sentence Encoders on STILTs: Supplementary Training on Intermediate\n  Labeled-data Tasks Abstract: Pretraining sentence encoders with language modeling and related unsupervised\ntasks has recently been shown to be very effective for language understanding\ntasks. By supplementing language model-style pretraining with further training\non data-rich supervised tasks, such as natural language inference, we obtain\nadditional performance improvements on the GLUE benchmark. Applying\nsupplementary training on BERT (Devlin et al., 2018), we attain a GLUE score of\n81.8---the state of the art (as of 02/24/2019) and a 1.4 point improvement over\nBERT. We also observe reduced variance across random restarts in this setting.\nOur approach yields similar improvements when applied to ELMo (Peters et al.,\n2018a) and Radford et al. (2018)'s model. In addition, the benefits of\nsupplementary training are particularly pronounced in data-constrained regimes,\nas we show in experiments with artificially limited training data. \n\n"}
{"id": "1811.01090", "contents": "Title: Value-based Search in Execution Space for Mapping Instructions to\n  Programs Abstract: Training models to map natural language instructions to programs given target\nworld supervision only requires searching for good programs at training time.\nSearch is commonly done using beam search in the space of partial programs or\nprogram trees, but as the length of the instructions grows finding a good\nprogram becomes difficult. In this work, we propose a search algorithm that\nuses the target world state, known at training time, to train a critic network\nthat predicts the expected reward of every search state. We then score search\nstates on the beam by interpolating their expected reward with the likelihood\nof programs represented by the search state. Moreover, we search not in the\nspace of programs but in a more compressed state of program executions,\naugmented with recent entities and actions. On the SCONE dataset, we show that\nour algorithm dramatically improves performance on all three domains compared\nto standard beam search and other baselines. \n\n"}
{"id": "1811.01157", "contents": "Title: Identifying and Controlling Important Neurons in Neural Machine\n  Translation Abstract: Neural machine translation (NMT) models learn representations containing\nsubstantial linguistic information. However, it is not clear if such\ninformation is fully distributed or if some of it can be attributed to\nindividual neurons. We develop unsupervised methods for discovering important\nneurons in NMT models. Our methods rely on the intuition that different models\nlearn similar properties, and do not require any costly external supervision.\nWe show experimentally that translation quality depends on the discovered\nneurons, and find that many of them capture common linguistic phenomena.\nFinally, we show how to control NMT translations in predictable ways, by\nmodifying activations of individual neurons. \n\n"}
{"id": "1811.01910", "contents": "Title: Evolutionary Data Measures: Understanding the Difficulty of Text\n  Classification Tasks Abstract: Classification tasks are usually analysed and improved through new model\narchitectures or hyperparameter optimisation but the underlying properties of\ndatasets are discovered on an ad-hoc basis as errors occur. However,\nunderstanding the properties of the data is crucial in perfecting models. In\nthis paper we analyse exactly which characteristics of a dataset best determine\nhow difficult that dataset is for the task of text classification. We then\npropose an intuitive measure of difficulty for text classification datasets\nwhich is simple and fast to calculate. We show that this measure generalises to\nunseen data by comparing it to state-of-the-art datasets and results. This\nmeasure can be used to analyse the precise source of errors in a dataset and\nallows fast estimation of how difficult a dataset is to learn. We searched for\nthis measure by training 12 classical and neural network based models on 78\nreal-world datasets, then use a genetic algorithm to discover the best measure\nof difficulty. Our difficulty-calculating code ( https://github.com/Wluper/edm\n) and datasets ( http://data.wluper.com ) are publicly available. \n\n"}
{"id": "1811.02182", "contents": "Title: Unpaired Speech Enhancement by Acoustic and Adversarial Supervision for\n  Speech Recognition Abstract: Many speech enhancement methods try to learn the relationship between noisy\nand clean speech, obtained using an acoustic room simulator. We point out\nseveral limitations of enhancement methods relying on clean speech targets; the\ngoal of this work is proposing an alternative learning algorithm, called\nacoustic and adversarial supervision (AAS). AAS makes the enhanced output both\nmaximizing the likelihood of transcription on the pre-trained acoustic model\nand having general characteristics of clean speech, which improve\ngeneralization on unseen noisy speeches. We employ the connectionist temporal\nclassification and the unpaired conditional boundary equilibrium generative\nadversarial network as the loss function of AAS. AAS is tested on two datasets\nincluding additive noise without and with reverberation, Librispeech + DEMAND\nand CHiME-4. By visualizing the enhanced speech with different loss\ncombinations, we demonstrate the role of each supervision. AAS achieves a lower\nword error rate than other state-of-the-art methods using the clean speech\ntarget in both datasets. \n\n"}
{"id": "1811.02456", "contents": "Title: Semantic Term \"Blurring\" and Stochastic \"Barcoding\" for Improved\n  Unsupervised Text Classification Abstract: The abundance of text data being produced in the modern age makes it\nincreasingly important to intuitively group, categorize, or classify text data\nby theme for efficient retrieval and search. Yet, the high dimensionality and\nimprecision of text data, or more generally language as a whole, prove to be\nchallenging when attempting to perform unsupervised document clustering. In\nthis thesis, we present two novel methods for improving unsupervised document\nclustering/classification by theme. The first is to improve document\nrepresentations. We look to exploit \"term neighborhoods\" and \"blur\" semantic\nweight across neighboring terms. These neighborhoods are located in the\nsemantic space afforded by \"word embeddings.\" The second method is for cluster\nrevision, based on what we deem as \"stochastic barcoding\", or \"S- Barcode\"\npatterns. Text data is inherently high dimensional, yet clustering typically\ntakes place in a low dimensional representation space. Our method utilizes\nlower dimension clustering results as initial cluster configurations, and\niteratively revises the configuration in the high dimensional space. We show\nwith experimental results how both of the two methods improve the quality of\ndocument clustering. While this thesis elaborates on the two new conceptual\ncontributions, a joint thesis by David Yan details the feature transformation\nand software architecture we developed for unsupervised document\nclassification. \n\n"}
{"id": "1811.02641", "contents": "Title: Building Corpora for Single-Channel Speech Separation Across Multiple\n  Domains Abstract: To date, the bulk of research on single-channel speech separation has been\nconducted using clean, near-field, read speech, which is not representative of\nmany modern applications. In this work, we develop a procedure for constructing\nhigh-quality synthetic overlap datasets, necessary for most deep learning-based\nseparation frameworks. We produced datasets that are more representative of\nrealistic applications using the CHiME-5 and Mixer 6 corpora and evaluate\nstandard methods on this data to demonstrate the shortcomings of current\nsource-separation performance. We also demonstrate the value of a wide variety\nof data in training robust models that generalize well to multiple conditions. \n\n"}
{"id": "1811.02736", "contents": "Title: Learning acoustic word embeddings with phonetically associated triplet\n  network Abstract: Previous researches on acoustic word embeddings used in query-by-example\nspoken term detection have shown remarkable performance improvements when using\na triplet network. However, the triplet network is trained using only a limited\ninformation about acoustic similarity between words. In this paper, we propose\na novel architecture, phonetically associated triplet network (PATN), which\naims at increasing discriminative power of acoustic word embeddings by\nutilizing phonetic information as well as word identity. The proposed model is\nlearned to minimize a combined loss function that was made by introducing a\ncross entropy loss to the lower layer of LSTM-based triplet network. We\nobserved that the proposed method performs significantly better than the\nbaseline triplet network on a word discrimination task with the WSJ dataset\nresulting in over 20% relative improvement in recall rate at 1.0 false alarm\nper hour. Finally, we examined the generalization ability by conducting the\nout-of-domain test on the RM dataset. \n\n"}
{"id": "1811.02770", "contents": "Title: Promising Accurate Prefix Boosting for sequence-to-sequence ASR Abstract: In this paper, we present promising accurate prefix boosting (PAPB), a\ndiscriminative training technique for attention based sequence-to-sequence\n(seq2seq) ASR. PAPB is devised to unify the training and testing scheme in an\neffective manner. The training procedure involves maximizing the score of each\npartial correct sequence obtained during beam search compared to other\nhypotheses. The training objective also includes minimization of token\n(character) error rate. PAPB shows its efficacy by achieving 10.8\\% and 3.8\\%\nWER with and without RNNLM respectively on Wall Street Journal dataset. \n\n"}
{"id": "1811.03036", "contents": "Title: IMS at the PolEval 2018: A Bulky Ensemble Depedency Parser meets 12\n  Simple Rules for Predicting Enhanced Dependencies in Polish Abstract: This paper presents the IMS contribution to the PolEval 2018 Shared Task. We\nsubmitted systems for both of the Subtasks of Task 1. In Subtask (A), which was\nabout dependency parsing, we used our ensemble system from the CoNLL 2017 UD\nShared Task. The system first preprocesses the sentences with a CRF\nPOS/morphological tagger and predicts supertags with a neural tagger. Then, it\nemploys multiple instances of three different parsers and merges their outputs\nby applying blending. The system achieved the second place out of four\nparticipating teams. In this paper we show which components of the system were\nthe most responsible for its final performance.\n  The goal of Subtask (B) was to predict enhanced graphs. Our approach\nconsisted of two steps: parsing the sentences with our ensemble system from\nSubtask (A), and applying 12 simple rules to obtain the final dependency\ngraphs. The rules introduce additional enhanced arcs only for tokens with\n\"conj\" heads (conjuncts). They do not predict semantic relations at all. The\nsystem ranked first out of three participating teams. In this paper we show\nexamples of rules we designed and analyze the relation between the quality of\nautomatically parsed trees and the accuracy of the enhanced graphs. \n\n"}
{"id": "1811.03514", "contents": "Title: Deep Neural Networks for Query Expansion using Word Embeddings Abstract: Query expansion is a method for alleviating the vocabulary mismatch problem\npresent in information retrieval tasks. Previous works have shown that terms\nselected for query expansion by traditional methods such as pseudo-relevance\nfeedback are not always helpful to the retrieval process. In this paper, we\nshow that this is also true for more recently proposed embedding-based query\nexpansion methods. We then introduce an artificial neural network classifier to\npredict the usefulness of query expansion terms. This classifier uses term word\nembeddings as inputs. We perform experiments on four TREC newswire and web\ncollections show that using terms selected by the classifier for expansion\nsignificantly improves retrieval performance when compared to competitive\nbaselines. The results are also shown to be more robust than the baselines. \n\n"}
{"id": "1811.03604", "contents": "Title: Federated Learning for Mobile Keyboard Prediction Abstract: We train a recurrent neural network language model using a distributed,\non-device learning framework called federated learning for the purpose of\nnext-word prediction in a virtual keyboard for smartphones. Server-based\ntraining using stochastic gradient descent is compared with training on client\ndevices using the Federated Averaging algorithm. The federated algorithm, which\nenables training on a higher-quality dataset for this use case, is shown to\nachieve better prediction recall. This work demonstrates the feasibility and\nbenefit of training language models on client devices without exporting\nsensitive user data to servers. The federated learning environment gives users\ngreater control over the use of their data and simplifies the task of\nincorporating privacy by default with distributed training and aggregation\nacross a population of client devices. \n\n"}
{"id": "1811.03700", "contents": "Title: A Comparison of Lattice-free Discriminative Training Criteria for Purely\n  Sequence-Trained Neural Network Acoustic Models Abstract: In this work, three lattice-free (LF) discriminative training criteria for\npurely sequence-trained neural network acoustic models are compared on LVCSR\ntasks, namely maximum mutual information (MMI), boosted maximum mutual\ninformation (bMMI) and state-level minimum Bayes risk (sMBR). We demonstrate\nthat, analogous to LF-MMI, a neural network acoustic model can also be trained\nfrom scratch using LF-bMMI or LF-sMBR criteria respectively without the need of\ncross-entropy pre-training. Furthermore, experimental results on\nSwitchboard-300hrs and Switchboard+Fisher-2100hrs datasets show that models\ntrained with LF-bMMI consistently outperform those trained with plain LF-MMI\nand achieve a relative word error rate (WER) reduction of 5% over competitive\ntemporal convolution projected LSTM (TDNN-LSTMP) LF-MMI baselines. \n\n"}
{"id": "1811.04154", "contents": "Title: Zero-shot Neural Transfer for Cross-lingual Entity Linking Abstract: Cross-lingual entity linking maps an entity mention in a source language to\nits corresponding entry in a structured knowledge base that is in a different\n(target) language. While previous work relies heavily on bilingual lexical\nresources to bridge the gap between the source and the target languages, these\nresources are scarce or unavailable for many low-resource languages. To address\nthis problem, we investigate zero-shot cross-lingual entity linking, in which\nwe assume no bilingual lexical resources are available in the source\nlow-resource language. Specifically, we propose pivot-based entity linking,\nwhich leverages information from a high-resource \"pivot\" language to train\ncharacter-level neural entity linking models that are transferred to the source\nlow-resource language in a zero-shot manner. With experiments on 9 low-resource\nlanguages and transfer through a total of 54 languages, we show that our\nproposed pivot-based framework improves entity linking accuracy 17% (absolute)\non average over the baseline systems, for the zero-shot scenario. Further, we\nalso investigate the use of language-universal phonological representations\nwhich improves average accuracy (absolute) by 36% when transferring between\nlanguages that use different scripts. \n\n"}
{"id": "1811.04201", "contents": "Title: Adversarially-Trained Normalized Noisy-Feature Auto-Encoder for Text\n  Generation Abstract: This article proposes Adversarially-Trained Normalized Noisy-Feature\nAuto-Encoder (ATNNFAE) for byte-level text generation. An ATNNFAE consists of\nan auto-encoder where the internal code is normalized on the unit sphere and\ncorrupted by additive noise. Simultaneously, a replica of the decoder (sharing\nthe same parameters as the AE decoder) is used as the generator and fed with\nrandom latent vectors. An adversarial discriminator is trained to distinguish\ntraining samples reconstructed from the AE from samples produced through the\nrandom-input generator, making the entire generator-discriminator path\ndifferentiable for discrete data like text. The combined effect of noise\ninjection in the code and shared weights between the decoder and the generator\ncan prevent the mode collapsing phenomenon commonly observed in GANs. Since\nperplexity cannot be applied to non-sequential text generation, we propose a\nnew evaluation method using the total variance distance between frequencies of\nhash-coded byte-level n-grams (NGTVD). NGTVD is a single benchmark that can\ncharacterize both the quality and the diversity of the generated texts.\nExperiments are offered in 6 large-scale datasets in Arabic, Chinese and\nEnglish, with comparisons against n-gram baselines and recurrent neural\nnetworks (RNNs). Ablation study on both the noise level and the discriminator\nis performed. We find that RNNs have trouble competing with the n-gram\nbaselines, and the ATNNFAE results are generally competitive. \n\n"}
{"id": "1811.04531", "contents": "Title: Sequence-Level Knowledge Distillation for Model Compression of\n  Attention-based Sequence-to-Sequence Speech Recognition Abstract: We investigate the feasibility of sequence-level knowledge distillation of\nSequence-to-Sequence (Seq2Seq) models for Large Vocabulary Continuous Speech\nRecognition (LVSCR). We first use a pre-trained larger teacher model to\ngenerate multiple hypotheses per utterance with beam search. With the same\ninput, we then train the student model using these hypotheses generated from\nthe teacher as pseudo labels in place of the original ground truth labels. We\nevaluate our proposed method using Wall Street Journal (WSJ) corpus. It\nachieved up to $ 9.8 \\times$ parameter reduction with accuracy loss of up to\n7.0\\% word-error rate (WER) increase \n\n"}
{"id": "1811.04568", "contents": "Title: Vectorization of hypotheses and speech for faster beam search in encoder\n  decoder-based speech recognition Abstract: Attention-based encoder decoder network uses a left-to-right beam search\nalgorithm in the inference step. The current beam search expands hypotheses and\ntraverses the expanded hypotheses at the next time step. This traversal is\nimplemented using a for-loop program in general, and it leads to speed down of\nthe recognition process. In this paper, we propose a parallelism technique for\nbeam search, which accelerates the search process by vectorizing multiple\nhypotheses to eliminate the for-loop program. We also propose a technique to\nbatch multiple speech utterances for off-line recognition use, which reduces\nthe for-loop program with regard to the traverse of multiple utterances. This\nextension is not trivial during beam search unlike during training due to\nseveral pruning and thresholding techniques for efficient decoding. In\naddition, our method can combine scores of external modules, RNNLM and CTC, in\na batch as shallow fusion. We achieved 3.7 x speedup compared with the original\nbeam search algorithm by vectoring hypotheses, and achieved 10.5 x speedup by\nfurther changing processing unit to GPU. \n\n"}
{"id": "1811.04623", "contents": "Title: Fine-tuning of Language Models with Discriminator Abstract: Cross-entropy loss is a common choice when it comes to multiclass\nclassification tasks and language modeling in particular. Minimizing this loss\nresults in language models of very good quality. We show that it is possible to\nfine-tune these models and make them perform even better if they are fine-tuned\nwith sum of cross-entropy loss and reverse Kullback-Leibler divergence. The\nlatter is estimated using discriminator network that we train in advance.\nDuring fine-tuning probabilities of rare words that are usually underestimated\nby language models become bigger. The novel approach that we propose allows us\nto reach state-of-the-art quality on Penn Treebank: perplexity decreases from\n52.4 to 52.1. Our fine-tuning algorithm is rather fast, scales well to\ndifferent architectures and datasets and requires almost no hyperparameter\ntuning: the only hyperparameter that needs to be tuned is learning rate. \n\n"}
{"id": "1811.04655", "contents": "Title: Not Just Depressed: Bipolar Disorder Prediction on Reddit Abstract: Bipolar disorder, an illness characterized by manic and depressive episodes,\naffects more than 60 million people worldwide. We present a preliminary study\non bipolar disorder prediction from user-generated text on Reddit, which relies\non users' self-reported labels. Our benchmark classifiers for bipolar disorder\nprediction outperform the baselines and reach accuracy and F1-scores of above\n86%. Feature analysis shows interesting differences in language use between\nusers with bipolar disorders and the control group, including differences in\nthe use of emotion-expressive words. \n\n"}
{"id": "1811.04719", "contents": "Title: End-to-End Non-Autoregressive Neural Machine Translation with\n  Connectionist Temporal Classification Abstract: Autoregressive decoding is the only part of sequence-to-sequence models that\nprevents them from massive parallelization at inference time.\nNon-autoregressive models enable the decoder to generate all output symbols\nindependently in parallel. We present a novel non-autoregressive architecture\nbased on connectionist temporal classification and evaluate it on the task of\nneural machine translation. Unlike other non-autoregressive methods which\noperate in several steps, our model can be trained end-to-end. We conduct\nexperiments on the WMT English-Romanian and English-German datasets. Our models\nachieve a significant speedup over the autoregressive models, keeping the\ntranslation quality comparable to other non-autoregressive models. \n\n"}
{"id": "1811.05013", "contents": "Title: Blindfold Baselines for Embodied QA Abstract: We explore blindfold (question-only) baselines for Embodied Question\nAnswering. The EmbodiedQA task requires an agent to answer a question by\nintelligently navigating in a simulated environment, gathering necessary visual\ninformation only through first-person vision before finally answering.\nConsequently, a blindfold baseline which ignores the environment and visual\ninformation is a degenerate solution, yet we show through our experiments on\nthe EQAv1 dataset that a simple question-only baseline achieves\nstate-of-the-art results on the EmbodiedQA task in all cases except when the\nagent is spawned extremely close to the object. \n\n"}
{"id": "1811.05021", "contents": "Title: Improved Dynamic Memory Network for Dialogue Act Classification with\n  Adversarial Training Abstract: Dialogue Act (DA) classification is a challenging problem in dialogue\ninterpretation, which aims to attach semantic labels to utterances and\ncharacterize the speaker's intention. Currently, many existing approaches\nformulate the DA classification problem ranging from multi-classification to\nstructured prediction, which suffer from two limitations: a) these methods are\neither handcrafted feature-based or have limited memories. b) adversarial\nexamples can't be correctly classified by traditional training methods. To\naddress these issues, in this paper we first cast the problem into a question\nand answering problem and proposed an improved dynamic memory networks with\nhierarchical pyramidal utterance encoder. Moreover, we apply adversarial\ntraining to train our proposed model. We evaluate our model on two public\ndatasets, i.e., Switchboard dialogue act corpus and the MapTask corpus.\nExtensive experiments show that our proposed model is not only robust, but also\nachieves better performance when compared with some state-of-the-art baselines. \n\n"}
{"id": "1811.05145", "contents": "Title: Hate Speech Detection from Code-mixed Hindi-English Tweets Using Deep\n  Learning Models Abstract: This paper reports an increment to the state-of-the-art in hate speech\ndetection for English-Hindi code-mixed tweets. We compare three typical deep\nlearning models using domain-specific embeddings. On experimenting with a\nbenchmark dataset of English-Hindi code-mixed tweets, we observe that using\ndomain-specific embeddings results in an improved representation of target\ngroups, and an improved F-score. \n\n"}
{"id": "1811.05408", "contents": "Title: Multi-task learning for Joint Language Understanding and Dialogue State\n  Tracking Abstract: This paper presents a novel approach for multi-task learning of language\nunderstanding (LU) and dialogue state tracking (DST) in task-oriented dialogue\nsystems. Multi-task training enables the sharing of the neural network layers\nresponsible for encoding the user utterance for both LU and DST and improves\nperformance while reducing the number of network parameters. In our proposed\nframework, DST operates on a set of candidate values for each slot that has\nbeen mentioned so far. These candidate sets are generated using LU slot\nannotations for the current user utterance, dialogue acts corresponding to the\npreceding system utterance and the dialogue state estimated for the previous\nturn, enabling DST to handle slots with a large or unbounded set of possible\nvalues and deal with slot values not seen during training. Furthermore, to\nbridge the gap between training and inference, we investigate the use of\nscheduled sampling on LU output for the current user utterance as well as the\nDST output for the preceding turn. \n\n"}
{"id": "1811.05467", "contents": "Title: Towards Neural Machine Translation for African Languages Abstract: Given that South African education is in crisis, strategies for improvement\nand sustainability of high-quality, up-to-date education must be explored. In\nthe migration of education online, inclusion of machine translation for\nlow-resourced local languages becomes necessary. This paper aims to spur the\nuse of current neural machine translation (NMT) techniques for low-resourced\nlocal languages. The paper demonstrates state-of-the-art performance on\nEnglish-to-Setswana translation using the Autshumato dataset. The use of the\nTransformer architecture beat previous techniques by 5.33 BLEU points. This\ndemonstrates the promise of using current NMT techniques for African languages. \n\n"}
{"id": "1811.05949", "contents": "Title: Jointly Learning to Label Sentences and Tokens Abstract: Learning to construct text representations in end-to-end systems can be\ndifficult, as natural languages are highly compositional and task-specific\nannotated datasets are often limited in size. Methods for directly supervising\nlanguage composition can allow us to guide the models based on existing\nknowledge, regularizing them towards more robust and interpretable\nrepresentations. In this paper, we investigate how objectives at different\ngranularities can be used to learn better language representations and we\npropose an architecture for jointly learning to label sentences and tokens. The\npredictions at each level are combined together using an attention mechanism,\nwith token-level labels also acting as explicit supervision for composing\nsentence-level representations. Our experiments show that by learning to\nperform these tasks jointly on multiple levels, the model achieves substantial\nimprovements for both sentence classification and sequence labeling. \n\n"}
{"id": "1811.06203", "contents": "Title: Combining Axiom Injection and Knowledge Base Completion for Efficient\n  Natural Language Inference Abstract: In logic-based approaches to reasoning tasks such as Recognizing Textual\nEntailment (RTE), it is important for a system to have a large amount of\nknowledge data. However, there is a tradeoff between adding more knowledge data\nfor improved RTE performance and maintaining an efficient RTE system, as such a\nbig database is problematic in terms of the memory usage and computational\ncomplexity. In this work, we show the processing time of a state-of-the-art\nlogic-based RTE system can be significantly reduced by replacing its\nsearch-based axiom injection (abduction) mechanism by that based on Knowledge\nBase Completion (KBC). We integrate this mechanism in a Coq plugin that\nprovides a proof automation tactic for natural language inference.\nAdditionally, we show empirically that adding new knowledge data contributes to\nbetter RTE performance while not harming the processing speed in this\nframework. \n\n"}
{"id": "1811.06596", "contents": "Title: On Generality and Knowledge Transferability in Cross-Domain Duplicate\n  Question Detection for Heterogeneous Community Question Answering Abstract: Duplicate question detection is an ongoing challenge in community question\nanswering because semantically equivalent questions can have significantly\ndifferent words and structures. In addition, the identification of duplicate\nquestions can reduce the resources required for retrieval, when the same\nquestions are not repeated. This study compares the performance of deep neural\nnetworks and gradient tree boosting, and explores the possibility of domain\nadaptation with transfer learning to improve the under-performing target\ndomains for the text-pair duplicates classification task, using three\nheterogeneous datasets: general-purpose Quora, technical Ask Ubuntu, and\nacademic English Stack Exchange. Ultimately, our study exposes the alternative\nhypothesis that the meaning of a \"duplicate\" is not inherently general-purpose,\nbut rather is dependent on the domain of learning, hence reducing the chance of\ntransfer learning through adapting to the domain. \n\n"}
{"id": "1811.07021", "contents": "Title: Investigating the Effects of Word Substitution Errors on Sentence\n  Embeddings Abstract: A key initial step in several natural language processing (NLP) tasks\ninvolves embedding phrases of text to vectors of real numbers that preserve\nsemantic meaning. To that end, several methods have been recently proposed with\nimpressive results on semantic similarity tasks. However, all of these\napproaches assume that perfect transcripts are available when generating the\nembeddings. While this is a reasonable assumption for analysis of written text,\nit is limiting for analysis of transcribed text. In this paper we investigate\nthe effects of word substitution errors, such as those coming from automatic\nspeech recognition errors (ASR), on several state-of-the-art sentence embedding\nmethods. To do this, we propose a new simulator that allows the experimenter to\ninduce ASR-plausible word substitution errors in a corpus at a desired word\nerror rate. We use this simulator to evaluate the robustness of several\nsentence embedding methods. Our results show that pre-trained neural sentence\nencoders are both robust to ASR errors and perform well on textual similarity\ntasks after errors are introduced. Meanwhile, unweighted averages of word\nvectors perform well with perfect transcriptions, but their performance\ndegrades rapidly on textual similarity tasks for text with word substitution\nerrors. \n\n"}
{"id": "1811.07033", "contents": "Title: Analyzing Compositionality-Sensitivity of NLI Models Abstract: Success in natural language inference (NLI) should require a model to\nunderstand both lexical and compositional semantics. However, through\nadversarial evaluation, we find that several state-of-the-art models with\ndiverse architectures are over-relying on the former and fail to use the\nlatter. Further, this compositionality unawareness is not reflected via\nstandard evaluation on current datasets. We show that removing RNNs in existing\nmodels or shuffling input words during training does not induce large\nperformance loss despite the explicit removal of compositional information.\nTherefore, we propose a compositionality-sensitivity testing setup that\nanalyzes models on natural examples from existing datasets that cannot be\nsolved via lexical features alone (i.e., on which a bag-of-words model gives a\nhigh probability to one wrong label), hence revealing the models' actual\ncompositionality awareness. We show that this setup not only highlights the\nlimited compositional ability of current NLI models, but also differentiates\nmodel performance based on design, e.g., separating shallow bag-of-words models\nfrom deeper, linguistically-grounded tree-based models. Our evaluation setup is\nan important analysis tool: complementing currently existing adversarial and\nlinguistically driven diagnostic evaluations, and exposing opportunities for\nfuture work on evaluating models' compositional understanding. \n\n"}
{"id": "1811.07453", "contents": "Title: The PyTorch-Kaldi Speech Recognition Toolkit Abstract: The availability of open-source software is playing a remarkable role in the\npopularization of speech recognition and deep learning. Kaldi, for instance, is\nnowadays an established framework used to develop state-of-the-art speech\nrecognizers. PyTorch is used to build neural networks with the Python language\nand has recently spawn tremendous interest within the machine learning\ncommunity thanks to its simplicity and flexibility.\n  The PyTorch-Kaldi project aims to bridge the gap between these popular\ntoolkits, trying to inherit the efficiency of Kaldi and the flexibility of\nPyTorch. PyTorch-Kaldi is not only a simple interface between these software,\nbut it embeds several useful features for developing modern speech recognizers.\nFor instance, the code is specifically designed to naturally plug-in\nuser-defined acoustic models. As an alternative, users can exploit several\npre-implemented neural networks that can be customized using intuitive\nconfiguration files. PyTorch-Kaldi supports multiple feature and label streams\nas well as combinations of neural networks, enabling the use of complex neural\narchitectures. The toolkit is publicly-released along with a rich documentation\nand is designed to properly work locally or on HPC clusters.\n  Experiments, that are conducted on several datasets and tasks, show that\nPyTorch-Kaldi can effectively be used to develop modern state-of-the-art speech\nrecognizers. \n\n"}
{"id": "1811.07600", "contents": "Title: A Trustworthy, Responsible and Interpretable System to Handle Chit Chat\n  in Conversational Bots Abstract: Most often, chat-bots are built to solve the purpose of a search engine or a\nhuman assistant: Their primary goal is to provide information to the user or\nhelp them complete a task. However, these chat-bots are incapable of responding\nto unscripted queries like \"Hi, what's up\", \"What's your favourite food\". Human\nevaluation judgments show that 4 humans come to a consensus on the intent of a\ngiven query which is from chat domain only 77% of the time, thus making it\nevident how non-trivial this task is. In our work, we show why it is difficult\nto break the chitchat space into clearly defined intents. We propose a system\nto handle this task in chat-bots, keeping in mind scalability,\ninterpretability, appropriateness, trustworthiness, relevance and coverage. Our\nwork introduces a pipeline for query understanding in chitchat using\nhierarchical intents as well as a way to use seq-seq auto-generation models in\nprofessional bots. We explore an interpretable model for chat domain detection\nand also show how various components such as adult/offensive classification,\ngrammars/regex patterns, curated personality based responses, generic guided\nevasive responses and response generation models can be combined in a scalable\nway to solve this problem. \n\n"}
{"id": "1811.08008", "contents": "Title: End-to-End Retrieval in Continuous Space Abstract: Most text-based information retrieval (IR) systems index objects by words or\nphrases. These discrete systems have been augmented by models that use\nembeddings to measure similarity in continuous space. But continuous-space\nmodels are typically used just to re-rank the top candidates. We consider the\nproblem of end-to-end continuous retrieval, where standard approximate nearest\nneighbor (ANN) search replaces the usual discrete inverted index, and rely\nentirely on distances between learned embeddings. By training simple models\nspecifically for retrieval, with an appropriate model architecture, we improve\non a discrete baseline by 8% and 26% (MAP) on two similar-question retrieval\ntasks. We also discuss the problem of evaluation for retrieval systems, and\nshow how to modify existing pairwise similarity datasets for this purpose. \n\n"}
{"id": "1811.08541", "contents": "Title: Neural Machine Translation with Adequacy-Oriented Learning Abstract: Although Neural Machine Translation (NMT) models have advanced\nstate-of-the-art performance in machine translation, they face problems like\nthe inadequate translation. We attribute this to that the standard Maximum\nLikelihood Estimation (MLE) cannot judge the real translation quality due to\nits several limitations. In this work, we propose an adequacy-oriented learning\nmechanism for NMT by casting translation as a stochastic policy in\nReinforcement Learning (RL), where the reward is estimated by explicitly\nmeasuring translation adequacy. Benefiting from the sequence-level training of\nRL strategy and a more accurate reward designed specifically for translation,\nour model outperforms multiple strong baselines, including (1) standard and\ncoverage-augmented attention models with MLE-based training, and (2) advanced\nreinforcement and adversarial training strategies with rewards based on both\nword-level BLEU and character-level chrF3. Quantitative and qualitative\nanalyses on different language pairs and NMT architectures demonstrate the\neffectiveness and universality of the proposed approach. \n\n"}
{"id": "1811.08600", "contents": "Title: Contextualized Non-local Neural Networks for Sequence Learning Abstract: Recently, a large number of neural mechanisms and models have been proposed\nfor sequence learning, of which self-attention, as exemplified by the\nTransformer model, and graph neural networks (GNNs) have attracted much\nattention. In this paper, we propose an approach that combines and draws on the\ncomplementary strengths of these two methods. Specifically, we propose\ncontextualized non-local neural networks (CN$^{\\textbf{3}}$), which can both\ndynamically construct a task-specific structure of a sentence and leverage rich\nlocal dependencies within a particular neighborhood.\n  Experimental results on ten NLP tasks in text classification, semantic\nmatching, and sequence labeling show that our proposed model outperforms\ncompetitive baselines and discovers task-specific dependency structures, thus\nproviding better interpretability to users. \n\n"}
{"id": "1811.08705", "contents": "Title: Inline Detection of Domain Generation Algorithms with Context-Sensitive\n  Word Embeddings Abstract: Domain generation algorithms (DGAs) are frequently employed by malware to\ngenerate domains used for connecting to command-and-control (C2) servers.\nRecent work in DGA detection leveraged deep learning architectures like\nconvolutional neural networks (CNNs) and character-level long short-term memory\nnetworks (LSTMs) to classify domains. However, these classifiers perform poorly\nwith wordlist-based DGA families, which generate domains by pseudorandomly\nconcatenating dictionary words. We propose a novel approach that combines\ncontext-sensitive word embeddings with a simple fully-connected classifier to\nperform classification of domains based on word-level information. The word\nembeddings were pre-trained on a large unrelated corpus and left frozen during\nthe training on domain data. The resulting small number of trainable parameters\nenabled extremely short training durations, while the transfer of language\nknowledge stored in the representations allowed for high-performing models with\nsmall training datasets. We show that this architecture reliably outperformed\nexisting techniques on wordlist-based DGA families with just 30 DGA training\nexamples and achieved state-of-the-art performance with around 100 DGA training\nexamples, all while requiring an order of magnitude less time to train compared\nto current techniques. Of special note is the technique's performance on the\nmatsnu DGA: the classifier attained a 89.5% detection rate with a 1:1,000 false\npositive rate (FPR) after training on only 30 examples of the DGA domains, and\na 91.2% detection rate with a 1:10,000 FPR after 90 examples. Considering that\nsome of these DGAs have wordlists of several hundred words, our results\ndemonstrate that this technique does not rely on the classifier learning the\nDGA wordlists. Instead, the classifier is able to learn the semantic signatures\nof the wordlist-based DGA families. \n\n"}
{"id": "1811.08757", "contents": "Title: The Best of Both Worlds: Lexical Resources To Improve Low-Resource\n  Part-of-Speech Tagging Abstract: In natural language processing, the deep learning revolution has shifted the\nfocus from conventional hand-crafted symbolic representations to dense inputs,\nwhich are adequate representations learned automatically from corpora. However,\nparticularly when working with low-resource languages, small amounts of\nsymbolic lexical resources such as user-generated lexicons are often available\neven when gold-standard corpora are not. Such additional linguistic information\nis though often neglected, and recent neural approaches to cross-lingual\ntagging typically rely only on word and subword embeddings. While these\nrepresentations are effective, our recent work has shown clear benefits of\ncombining the best of both worlds: integrating conventional lexical information\nimproves neural cross-lingual part-of-speech (PoS) tagging. However, little is\nknown on how complementary such additional information is, and to what extent\nimprovements depend on the coverage and quality of these external resources.\nThis paper seeks to fill this gap by providing the first thorough analysis on\nthe contributions of lexical resources for cross-lingual PoS tagging in neural\ntimes. \n\n"}
{"id": "1811.09386", "contents": "Title: Explicit Interaction Model towards Text Classification Abstract: Text classification is one of the fundamental tasks in natural language\nprocessing. Recently, deep neural networks have achieved promising performance\nin the text classification task compared to shallow models. Despite of the\nsignificance of deep models, they ignore the fine-grained (matching signals\nbetween words and classes) classification clues since their classifications\nmainly rely on the text-level representations. To address this problem, we\nintroduce the interaction mechanism to incorporate word-level matching signals\ninto the text classification task. In particular, we design a novel framework,\nEXplicit interAction Model (dubbed as EXAM), equipped with the interaction\nmechanism. We justified the proposed approach on several benchmark datasets\nincluding both multi-label and multi-class text classification tasks. Extensive\nexperimental results demonstrate the superiority of the proposed method. As a\nbyproduct, we have released the codes and parameter settings to facilitate\nother researches. \n\n"}
{"id": "1811.09786", "contents": "Title: Recurrently Controlled Recurrent Networks Abstract: Recurrent neural networks (RNNs) such as long short-term memory and gated\nrecurrent units are pivotal building blocks across a broad spectrum of sequence\nmodeling problems. This paper proposes a recurrently controlled recurrent\nnetwork (RCRN) for expressive and powerful sequence encoding. More concretely,\nthe key idea behind our approach is to learn the recurrent gating functions\nusing recurrent networks. Our architecture is split into two components - a\ncontroller cell and a listener cell whereby the recurrent controller actively\ninfluences the compositionality of the listener cell. We conduct extensive\nexperiments on a myriad of tasks in the NLP domain such as sentiment analysis\n(SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment\nclassification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading\ncomprehension (NarrativeQA). Across all 26 datasets, our results demonstrate\nthat RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs,\nsuggesting that our controller architecture might be a suitable replacement for\nthe widely adopted stacked architecture. \n\n"}
{"id": "1811.10418", "contents": "Title: Combining neural and knowledge-based approaches to Named Entity\n  Recognition in Polish Abstract: Named entity recognition (NER) is one of the tasks in natural language\nprocessing that can greatly benefit from the use of external knowledge sources.\nWe propose a named entity recognition framework composed of knowledge-based\nfeature extractors and a deep learning model including contextual word\nembeddings, long short-term memory (LSTM) layers and conditional random fields\n(CRF) inference layer. We use an entity linking module to integrate our system\nwith Wikipedia. The combination of effective neural architecture and external\nresources allows us to obtain state-of-the-art results on recognition of Polish\nproper names. We evaluate our model on data from PolEval 2018 NER challenge on\nwhich it outperforms other methods, reducing the error rate by 22.4% compared\nto the winning solution. Our work shows that combining neural NER model and\nentity linking model with a knowledge base is more effective in recognizing\nnamed entities than using NER model alone. \n\n"}
{"id": "1811.10667", "contents": "Title: Embedding Uncertain Knowledge Graphs Abstract: Embedding models for deterministic Knowledge Graphs (KG) have been\nextensively studied, with the purpose of capturing latent semantic relations\nbetween entities and incorporating the structured knowledge into machine\nlearning. However, there are many KGs that model uncertain knowledge, which\ntypically model the inherent uncertainty of relations facts with a confidence\nscore, and embedding such uncertain knowledge represents an unresolved\nchallenge. The capturing of uncertain knowledge will benefit many\nknowledge-driven applications such as question answering and semantic search by\nproviding more natural characterization of the knowledge. In this paper, we\npropose a novel uncertain KG embedding model UKGE, which aims to preserve both\nstructural and uncertainty information of relation facts in the embedding\nspace. Unlike previous models that characterize relation facts with binary\nclassification techniques, UKGE learns embeddings according to the confidence\nscores of uncertain relation facts. To further enhance the precision of UKGE,\nwe also introduce probabilistic soft logic to infer confidence scores for\nunseen relation facts during training. We propose and evaluate two variants of\nUKGE based on different learning objectives. Experiments are conducted on three\nreal-world uncertain KGs via three tasks, i.e. confidence prediction, relation\nfact ranking, and relation fact classification. UKGE shows effectiveness in\ncapturing uncertain knowledge by achieving promising results on these tasks,\nand consistently outperforms baselines on these tasks. \n\n"}
{"id": "1811.10999", "contents": "Title: Exploiting Coarse-to-Fine Task Transfer for Aspect-level Sentiment\n  Classification Abstract: Aspect-level sentiment classification (ASC) aims at identifying sentiment\npolarities towards aspects in a sentence, where the aspect can behave as a\ngeneral Aspect Category (AC) or a specific Aspect Term (AT). However, due to\nthe especially expensive and labor-intensive labeling, existing public corpora\nin AT-level are all relatively small. Meanwhile, most of the previous methods\nrely on complicated structures with given scarce data, which largely limits the\nefficacy of the neural models. In this paper, we exploit a new direction named\ncoarse-to-fine task transfer, which aims to leverage knowledge learned from a\nrich-resource source domain of the coarse-grained AC task, which is more easily\naccessible, to improve the learning in a low-resource target domain of the\nfine-grained AT task. To resolve both the aspect granularity inconsistency and\nfeature mismatch between domains, we propose a Multi-Granularity Alignment\nNetwork (MGAN). In MGAN, a novel Coarse2Fine attention guided by an auxiliary\ntask can help the AC task modeling at the same fine-grained level with the AT\ntask. To alleviate the feature false alignment, a contrastive feature alignment\nmethod is adopted to align aspect-specific feature representations\nsemantically. In addition, a large-scale multi-domain dataset for the AC task\nis provided. Empirically, extensive experiments demonstrate the effectiveness\nof the MGAN. \n\n"}
{"id": "1811.12239", "contents": "Title: Counterfactual Learning from Human Proofreading Feedback for Semantic\n  Parsing Abstract: In semantic parsing for question-answering, it is often too expensive to\ncollect gold parses or even gold answers as supervision signals. We propose to\nconvert model outputs into a set of human-understandable statements which allow\nnon-expert users to act as proofreaders, providing error markings as learning\nsignals to the parser. Because model outputs were suggested by a historic\nsystem, we operate in a counterfactual, or off-policy, learning setup. We\nintroduce new estimators which can effectively leverage the given feedback and\nwhich avoid known degeneracies in counterfactual learning, while still being\napplicable to stochastic gradient optimization for neural semantic parsing.\nFurthermore, we discuss how our feedback collection method can be seamlessly\nintegrated into deployed virtual personal assistants that embed a semantic\nparser. Our work is the first to show that semantic parsers can be improved\nsignificantly by counterfactual learning from logged human feedback data. \n\n"}
{"id": "1811.12276", "contents": "Title: Improving Hospital Mortality Prediction with Medical Named Entities and\n  Multimodal Learning Abstract: Clinical text provides essential information to estimate the acuity of a\npatient during hospital stays in addition to structured clinical data. In this\nstudy, we explore how clinical text can complement a clinical predictive\nlearning task. We leverage an internal medical natural language processing\nservice to perform named entity extraction and negation detection on clinical\nnotes and compose selected entities into a new text corpus to train document\nrepresentations. We then propose a multimodal neural network to jointly train\ntime series signals and unstructured clinical text representations to predict\nthe in-hospital mortality risk for ICU patients. Our model outperforms the\nbenchmark by 2% AUC. \n\n"}
{"id": "1812.00271", "contents": "Title: Learning Speaker Representations with Mutual Information Abstract: Learning good representations is of crucial importance in deep learning.\nMutual Information (MI) or similar measures of statistical dependence are\npromising tools for learning these representations in an unsupervised way. Even\nthough the mutual information between two random variables is hard to measure\ndirectly in high dimensional spaces, some recent studies have shown that an\nimplicit optimization of MI can be achieved with an encoder-discriminator\narchitecture similar to that of Generative Adversarial Networks (GANs). In this\nwork, we learn representations that capture speaker identities by maximizing\nthe mutual information between the encoded representations of chunks of speech\nrandomly sampled from the same sentence. The proposed encoder relies on the\nSincNet architecture and transforms raw speech waveform into a compact feature\nvector. The discriminator is fed by either positive samples (of the joint\ndistribution of encoded chunks) or negative samples (from the product of the\nmarginals) and is trained to separate them. We report experiments showing that\nthis approach effectively learns useful speaker representations, leading to\npromising results on speaker identification and verification tasks. Our\nexperiments consider both unsupervised and semi-supervised settings and compare\nthe performance achieved with different objective functions. \n\n"}
{"id": "1812.00381", "contents": "Title: Towards Automatic Discovery of Cybercrime Supply Chains Abstract: Cybercrime forums enable modern criminal entrepreneurs to collaborate with\nother criminals into increasingly efficient and sophisticated criminal\nendeavors. Understanding the connections between different products and\nservices can often illuminate effective interventions. However, generating this\nunderstanding of supply chains currently requires time-consuming manual effort.\n  In this paper, we propose a language-agnostic method to automatically extract\nsupply chains from cybercrime forum posts and replies. Our supply chain\ndetection algorithm can identify 36% and 58% relevant chains within major\nEnglish and Russian forums, respectively, showing improvements over the\nbaselines of 13% and 36%, respectively. Our analysis of the automatically\ngenerated supply chains demonstrates underlying connections between products\nand services within these forums. For example, the extracted supply chain\nilluminated the connection between hack-for-hire services and the selling of\nrare and valuable `OG' accounts, which has only recently been reported. The\nunderstanding of connections between products and services exposes potentially\neffective intervention points. \n\n"}
{"id": "1812.00382", "contents": "Title: Improved and Robust Controversy Detection in General Web Pages Using\n  Semantic Approaches under Large Scale Conditions Abstract: Detecting controversy in general web pages is a daunting task, but\nincreasingly essential to efficiently moderate discussions and effectively\nfilter problematic content. Unfortunately, controversies occur across many\ntopics and domains, with great changes over time. This paper investigates\nneural classifiers as a more robust methodology for controversy detection in\ngeneral web pages. Current models have often cast controversy detection on\ngeneral web pages as Wikipedia linking, or exact lexical matching tasks. The\ndiverse and changing nature of controversies suggest that semantic approaches\nare better able to detect controversy. We train neural networks that can\ncapture semantic information from texts using weak signal data. By leveraging\nthe semantic properties of word embeddings we robustly improve on existing\ncontroversy detection methods. To evaluate model stability over time and to\nunseen topics, we asses model performance under varying training conditions to\ntest cross-temporal, cross-topic, cross-domain performance and annotator\ncongruence. In doing so, we demonstrate that weak-signal based neural\napproaches are closer to human estimates of controversy and are more robust to\nthe inherent variability of controversies. \n\n"}
{"id": "1812.00686", "contents": "Title: Building Sequential Inference Models for End-to-End Response Selection Abstract: This paper presents an end-to-end response selection model for Track 1 of the\n7th Dialogue System Technology Challenges (DSTC7). This task focuses on\nselecting the correct next utterance from a set of candidates given a partial\nconversation. We propose an end-to-end neural network based on enhanced\nsequential inference model (ESIM) for this task. Our proposed model differs\nfrom the original ESIM model in the following four aspects. First, a new word\nrepresentation method which combines the general pre-trained word embeddings\nwith those estimated on the task-specific training set is adopted in order to\naddress the challenge of out-of-vocabulary (OOV) words. Second, an attentive\nhierarchical recurrent encoder (AHRE) is designed which is capable to encode\nsentences hierarchically and generate more descriptive representations by\naggregation. Third, a new pooling method which combines multi-dimensional\npooling and last-state pooling is used instead of the simple combination of max\npooling and average pooling in the original ESIM. Last, a modification layer is\nadded before the softmax layer to emphasize the importance of the last\nutterance in the context for response selection. In the released evaluation\nresults of DSTC7, our proposed method ranked second on the Ubuntu dataset and\nthird on the Advising dataset in subtask 1 of Track 1. \n\n"}
{"id": "1812.01083", "contents": "Title: A System for Automated Image Editing from Natural Language Commands Abstract: This work presents the task of modifying images in an image editing program\nusing natural language written commands. We utilize a corpus of over 6000 image\nedit text requests to alter real world images collected via crowdsourcing. A\nnovel framework composed of actions and entities to map a user's natural\nlanguage request to executable commands in an image editing program is\ndescribed. We resolve previously labeled annotator disagreement through a\nvoting process and complete annotation of the corpus. We experimented with\ndifferent machine learning models and found that the LSTM, the SVM, and the\nbidirectional LSTM-CRF joint models are the best to detect image editing\nactions and associated entities in a given utterance. \n\n"}
{"id": "1812.01704", "contents": "Title: Impact of Sentiment Detection to Recognize Toxic and Subversive Online\n  Comments Abstract: The presence of toxic content has become a major problem for many online\ncommunities. Moderators try to limit this problem by implementing more and more\nrefined comment filters, but toxic users are constantly finding new ways to\ncircumvent them. Our hypothesis is that while modifying toxic content and\nkeywords to fool filters can be easy, hiding sentiment is harder. In this\npaper, we explore various aspects of sentiment detection and their correlation\nto toxicity, and use our results to implement a toxicity detection tool. We\nthen test how adding the sentiment information helps detect toxicity in three\ndifferent real-world datasets, and incorporate subversion to these datasets to\nsimulate a user trying to circumvent the system. Our results show sentiment\ninformation has a positive impact on toxicity detection against a subversive\nuser. \n\n"}
{"id": "1812.04081", "contents": "Title: Chat-crowd: A Dialog-based Platform for Visual Layout Composition Abstract: In this paper we introduce Chat-crowd, an interactive environment for visual\nlayout composition via conversational interactions. Chat-crowd supports\nmultiple agents with two conversational roles: agents who play the role of a\ndesigner are in charge of placing objects in an editable canvas according to\ninstructions or commands issued by agents with a director role. The system can\nbe integrated with crowdsourcing platforms for both synchronous and\nasynchronous data collection and is equipped with comprehensive quality\ncontrols on the performance of both types of agents. We expect that this system\nwill be useful to build multimodal goal-oriented dialog tasks that require\nspatial and geometric reasoning. \n\n"}
{"id": "1812.05271", "contents": "Title: TextBugger: Generating Adversarial Text Against Real-world Applications Abstract: Deep Learning-based Text Understanding (DLTU) is the backbone technique\nbehind various applications, including question answering, machine translation,\nand text classification. Despite its tremendous popularity, the security\nvulnerabilities of DLTU are still largely unknown, which is highly concerning\ngiven its increasing use in security-sensitive applications such as sentiment\nanalysis and toxic content detection. In this paper, we show that DLTU is\ninherently vulnerable to adversarial text attacks, in which maliciously crafted\ntexts trigger target DLTU systems and services to misbehave. Specifically, we\npresent TextBugger, a general attack framework for generating adversarial\ntexts. In contrast to prior works, TextBugger differs in significant ways: (i)\neffective -- it outperforms state-of-the-art attacks in terms of attack success\nrate; (ii) evasive -- it preserves the utility of benign text, with 94.9\\% of\nthe adversarial text correctly recognized by human readers; and (iii) efficient\n-- it generates adversarial text with computational complexity sub-linear to\nthe text length. We empirically evaluate TextBugger on a set of real-world DLTU\nsystems and services used for sentiment analysis and toxic content detection,\ndemonstrating its effectiveness, evasiveness, and efficiency. For instance,\nTextBugger achieves 100\\% success rate on the IMDB dataset based on Amazon AWS\nComprehend within 4.61 seconds and preserves 97\\% semantic similarity. We\nfurther discuss possible defense mechanisms to mitigate such attack and the\nadversary's potential countermeasures, which leads to promising directions for\nfurther research. \n\n"}
{"id": "1812.05288", "contents": "Title: Dynamic Transfer Learning for Named Entity Recognition Abstract: State-of-the-art named entity recognition (NER) systems have been improving\ncontinuously using neural architectures over the past several years. However,\nmany tasks including NER require large sets of annotated data to achieve such\nperformance. In particular, we focus on NER from clinical notes, which is one\nof the most fundamental and critical problems for medical text analysis. Our\nwork centers on effectively adapting these neural architectures towards\nlow-resource settings using parameter transfer methods. We complement a\nstandard hierarchical NER model with a general transfer learning framework\nconsisting of parameter sharing between the source and target tasks, and\nshowcase scores significantly above the baseline architecture. These sharing\nschemes require an exponential search over tied parameter sets to generate an\noptimal configuration. To mitigate the problem of exhaustively searching for\nmodel optimization, we propose the Dynamic Transfer Networks (DTN), a gated\narchitecture which learns the appropriate parameter sharing scheme between\nsource and target datasets. DTN achieves the improvements of the optimized\ntransfer learning framework with just a single training setting, effectively\nremoving the need for exponential search. \n\n"}
{"id": "1812.05407", "contents": "Title: Abstractive Text Summarization by Incorporating Reader Comments Abstract: In neural abstractive summarization field, conventional sequence-to-sequence\nbased models often suffer from summarizing the wrong aspect of the document\nwith respect to the main aspect. To tackle this problem, we propose the task of\nreader-aware abstractive summary generation, which utilizes the reader comments\nto help the model produce better summary about the main aspect. Unlike\ntraditional abstractive summarization task, reader-aware summarization\nconfronts two main challenges: (1) Comments are informal and noisy; (2) jointly\nmodeling the news document and the reader comments is challenging. To tackle\nthe above challenges, we design an adversarial learning model named\nreader-aware summary generator (RASG), which consists of four components: (1) a\nsequence-to-sequence based summary generator; (2) a reader attention module\ncapturing the reader focused aspects; (3) a supervisor modeling the semantic\ngap between the generated summary and reader focused aspects; (4) a goal\ntracker producing the goal for each generation step. The supervisor and the\ngoal tacker are used to guide the training of our framework in an adversarial\nmanner. Extensive experiments are conducted on our large-scale real-world text\nsummarization dataset, and the results show that RASG achieves the\nstate-of-the-art performance in terms of both automatic metrics and human\nevaluations. The experimental results also demonstrate the effectiveness of\neach module in our framework. We release our large-scale dataset for further\nresearch. \n\n"}
{"id": "1812.05710", "contents": "Title: FPETS : Fully Parallel End-to-End Text-to-Speech System Abstract: End-to-end Text-to-speech (TTS) system can greatly improve the quality of\nsynthesised speech. But it usually suffers form high time latency due to its\nauto-regressive structure. And the synthesised speech may also suffer from some\nerror modes, e.g. repeated words, mispronunciations, and skipped words. In this\npaper, we propose a novel non-autoregressive, fully parallel end-to-end TTS\nsystem (FPETS). It utilizes a new alignment model and the recently proposed\nU-shape convolutional structure, UFANS. Different from RNN, UFANS can capture\nlong term information in a fully parallel manner. Trainable position encoding\nand two-step training strategy are used for learning better alignments.\nExperimental results show FPETS utilizes the power of parallel computation and\nreaches a significant speed up of inference compared with state-of-the-art\nend-to-end TTS systems. More specifically, FPETS is 600X faster than Tacotron2,\n50X faster than DCTTS and 10X faster than Deep Voice3. And FPETS can generates\naudios with equal or better quality and fewer errors comparing with other\nsystem. As far as we know, FPETS is the first end-to-end TTS system which is\nfully parallel. \n\n"}
{"id": "1812.06158", "contents": "Title: Few-shot classification in Named Entity Recognition Task Abstract: For many natural language processing (NLP) tasks the amount of annotated data\nis limited. This urges a need to apply semi-supervised learning techniques,\nsuch as transfer learning or meta-learning. In this work we tackle Named Entity\nRecognition (NER) task using Prototypical Network - a metric learning\ntechnique. It learns intermediate representations of words which cluster well\ninto named entity classes. This property of the model allows classifying words\nwith extremely limited number of training examples, and can potentially be used\nas a zero-shot learning method. By coupling this technique with transfer\nlearning we achieve well-performing classifiers trained on only 20 instances of\na target class. \n\n"}
{"id": "1812.06401", "contents": "Title: What's to know? Uncertainty as a Guide to Asking Goal-oriented Questions Abstract: One of the core challenges in Visual Dialogue problems is asking the question\nthat will provide the most useful information towards achieving the required\nobjective. Encouraging an agent to ask the right questions is difficult because\nwe don't know a-priori what information the agent will need to achieve its\ntask, and we don't have an explicit model of what it knows already. We propose\na solution to this problem based on a Bayesian model of the uncertainty in the\nimplicit model maintained by the visual dialogue agent, and in the function\nused to select an appropriate output. By selecting the question that minimises\nthe predicted regret with respect to this implicit model the agent actively\nreduces ambiguity. The Bayesian model of uncertainty also enables a principled\nmethod for identifying when enough information has been acquired, and an action\nshould be selected. We evaluate our approach on two goal-oriented dialogue\ndatasets, one for visual-based collaboration task and the other for a\nnegotiation-based task. Our uncertainty-aware information-seeking model\noutperforms its counterparts in these two challenging problems. \n\n"}
{"id": "1812.07108", "contents": "Title: Learning Private Neural Language Modeling with Attentive Aggregation Abstract: Mobile keyboard suggestion is typically regarded as a word-level language\nmodeling problem. Centralized machine learning technique requires massive user\ndata collected to train on, which may impose privacy concerns for sensitive\npersonal typing data of users. Federated learning (FL) provides a promising\napproach to learning private language modeling for intelligent personalized\nkeyboard suggestion by training models in distributed clients rather than\ntraining in a central server. To obtain a global model for prediction, existing\nFL algorithms simply average the client models and ignore the importance of\neach client during model aggregation. Furthermore, there is no optimization for\nlearning a well-generalized global model on the central server. To solve these\nproblems, we propose a novel model aggregation with the attention mechanism\nconsidering the contribution of clients models to the global model, together\nwith an optimization technique during server aggregation. Our proposed\nattentive aggregation method minimizes the weighted distance between the server\nmodel and client models through iterative parameters updating while attends the\ndistance between the server model and client models. Through experiments on two\npopular language modeling datasets and a social media dataset, our proposed\nmethod outperforms its counterparts in terms of perplexity and communication\ncost in most settings of comparison. \n\n"}
{"id": "1812.09359", "contents": "Title: NeuroX: A Toolkit for Analyzing Individual Neurons in Neural Networks Abstract: We present a toolkit to facilitate the interpretation and understanding of\nneural network models. The toolkit provides several methods to identify salient\nneurons with respect to the model itself or an external task. A user can\nvisualize selected neurons, ablate them to measure their effect on the model\naccuracy, and manipulate them to control the behavior of the model at the test\ntime. Such an analysis has a potential to serve as a springboard in various\nresearch directions, such as understanding the model, better architectural\nchoices, model distillation and controlling data biases. \n\n"}
{"id": "1812.10061", "contents": "Title: Noise Flooding for Detecting Audio Adversarial Examples Against\n  Automatic Speech Recognition Abstract: Neural models enjoy widespread use across a variety of tasks and have grown\nto become crucial components of many industrial systems. Despite their\neffectiveness and extensive popularity, they are not without their exploitable\nflaws. Initially applied to computer vision systems, the generation of\nadversarial examples is a process in which seemingly imperceptible\nperturbations are made to an image, with the purpose of inducing a deep\nlearning based classifier to misclassify the image. Due to recent trends in\nspeech processing, this has become a noticeable issue in speech recognition\nmodels. In late 2017, an attack was shown to be quite effective against the\nSpeech Commands classification model. Limited-vocabulary speech classifiers,\nsuch as the Speech Commands model, are used quite frequently in a variety of\napplications, particularly in managing automated attendants in telephony\ncontexts. As such, adversarial examples produced by this attack could have\nreal-world consequences. While previous work in defending against these\nadversarial examples has investigated using audio preprocessing to reduce or\ndistort adversarial noise, this work explores the idea of flooding particular\nfrequency bands of an audio signal with random noise in order to detect\nadversarial examples. This technique of flooding, which does not require\nretraining or modifying the model, is inspired by work done in computer vision\nand builds on the idea that speech classifiers are relatively robust to natural\nnoise. A combined defense incorporating 5 different frequency bands for\nflooding the signal with noise outperformed other existing defenses in the\naudio space, detecting adversarial examples with 91.8% precision and 93.5%\nrecall. \n\n"}
{"id": "1812.10119", "contents": "Title: Sequence to Sequence Learning for Query Expansion Abstract: Using sequence to sequence algorithms for query expansion has not been\nexplored yet in Information Retrieval literature nor in Question-Answering's.\nWe tried to fill this gap in the literature with a custom Query Expansion\nengine trained and tested on open datasets. Starting from open datasets, we\nbuilt a Query Expansion training set using sentence-embeddings-based Keyword\nExtraction. We therefore assessed the ability of the Sequence to Sequence\nneural networks to capture expanding relations in the words embeddings' space. \n\n"}
{"id": "1812.10479", "contents": "Title: Multimodal deep learning for short-term stock volatility prediction Abstract: Stock market volatility forecasting is a task relevant to assessing market\nrisk. We investigate the interaction between news and prices for the\none-day-ahead volatility prediction using state-of-the-art deep learning\napproaches. The proposed models are trained either end-to-end or using sentence\nencoders transfered from other tasks. We evaluate a broad range of stock market\nsectors, namely Consumer Staples, Energy, Utilities, Heathcare, and Financials.\nOur experimental results show that adding news improves the volatility\nforecasting as compared to the mainstream models that rely only on price data.\nIn particular, our model outperforms the widely-recognized GARCH(1,1) model for\nall sectors in terms of coefficient of determination $R^2$, $MSE$ and $MAE$,\nachieving the best performance when training from both news and price data. \n\n"}
{"id": "1812.11158", "contents": "Title: MEETING BOT: Reinforcement Learning for Dialogue Based Meeting\n  Scheduling Abstract: In this paper we present Meeting Bot, a reinforcement learning based\nconversational system that interacts with multiple users to schedule meetings.\nThe system is able to interpret user utterences and map them to preferred time\nslots, which are then fed to a reinforcement learning (RL) system with the goal\nof converging on an agreeable time slot. The RL system is able to adapt to user\npreferences and environmental changes in meeting arrival rate while still\nscheduling effectively. Learning is performed via policy gradient with\nexploration, by utilizing an MLP as an approximator of the policy function.\nResults demonstrate that the system outperforms standard scheduling algorithms\nin terms of overall scheduling efficiency. Additionally, the system is able to\nadapt its strategy to situations when users consistently reject or accept\nmeetings in certain slots (such as Friday afternoon versus Thursday morning),\nor when the meeting is called by members who are at a more senior designation. \n\n"}
{"id": "1901.00066", "contents": "Title: Improving Tree-LSTM with Tree Attention Abstract: In Natural Language Processing (NLP), we often need to extract information\nfrom tree topology. Sentence structure can be represented via a dependency tree\nor a constituency tree structure. For this reason, a variant of LSTMs, named\nTree-LSTM, was proposed to work on tree topology. In this paper, we design a\ngeneralized attention framework for both dependency and constituency trees by\nencoding variants of decomposable attention inside a Tree-LSTM cell. We\nevaluated our models on a semantic relatedness task and achieved notable\nresults compared to Tree-LSTM based methods with no attention as well as other\nneural and non-neural methods and good results compared to Tree-LSTM based\nmethods with attention. \n\n"}
{"id": "1901.00439", "contents": "Title: Deep Representation Learning for Clustering of Health Tweets Abstract: Twitter has been a prominent social media platform for mining\npopulation-level health data and accurate clustering of health-related tweets\ninto topics is important for extracting relevant health insights. In this work,\nwe propose deep convolutional autoencoders for learning compact representations\nof health-related tweets, further to be employed in clustering. We compare our\nmethod to several conventional tweet representation methods including\nbag-of-words, term frequency-inverse document frequency, Latent Dirichlet\nAllocation and Non-negative Matrix Factorization with 3 different clustering\nalgorithms. Our results show that the clustering performance using proposed\nrepresentation learning scheme significantly outperforms that of conventional\nmethods for all experiments of different number of clusters. In addition, we\npropose a constraint on the learned representations during the neural network\ntraining in order to further enhance the clustering performance. All in all,\nthis study introduces utilization of deep neural network-based architectures,\ni.e., deep convolutional autoencoders, for learning informative representations\nof health-related tweets. \n\n"}
{"id": "1901.00519", "contents": "Title: Pull out all the stops: Textual analysis via punctuation sequences Abstract: Whether enjoying the lucid prose of a favorite author or slogging through\nsome other writer's cumbersome, heavy-set prattle (full of parentheses, em\ndashes, compound adjectives, and Oxford commas), readers will notice stylistic\nsignatures not only in word choice and grammar, but also in punctuation itself.\nIndeed, visual sequences of punctuation from different authors produce\nmarvelously different (and visually striking) sequences. Punctuation is a\nlargely overlooked stylistic feature in \"stylometry\", the quantitative analysis\nof written text. In this paper, we examine punctuation sequences in a corpus of\nliterary documents and ask the following questions: Are the properties of such\nsequences a distinctive feature of different authors? Is it possible to\ndistinguish literary genres based on their punctuation sequences? Do the\npunctuation styles of authors evolve over time? Are we on to something\ninteresting in trying to do stylometry without words, or are we full of sound\nand fury (signifying nothing)? \n\n"}
{"id": "1901.01183", "contents": "Title: Aspect Category Detection via Topic-Attention Network Abstract: The e-commerce has started a new trend in natural language processing through\nsentiment analysis of user-generated reviews. Different consumers have\ndifferent concerns about various aspects of a specific product or service.\nAspect category detection, as a subtask of aspect-based sentiment analysis,\ntackles the problem of categorizing a given review sentence into a set of\npre-defined aspect categories. In recent years, deep learning approaches have\nbrought revolutionary advances in multiple branches of natural language\nprocessing including sentiment analysis. In this paper, we propose a deep\nneural network method based on attention mechanism to identify different aspect\ncategories of a given review sentence. Our model utilizes several attentions\nwith different topic contexts, enabling it to attend to different parts of a\nreview sentence based on different topics. Experimental results on two datasets\nin the restaurant domain released by SemEval workshop demonstrates that our\napproach outperforms existing methods on both datasets. Visualization of the\ntopic attention weights shows the effectiveness of our model in identifying\nwords related to different topics. \n\n"}
{"id": "1901.01239", "contents": "Title: Speaker Adaptation for End-to-End CTC Models Abstract: We propose two approaches for speaker adaptation in end-to-end (E2E)\nautomatic speech recognition systems. One is Kullback-Leibler divergence (KLD)\nregularization and the other is multi-task learning (MTL). Both approaches aim\nto address the data sparsity especially output target sparsity issue of speaker\nadaptation in E2E systems. The KLD regularization adapts a model by forcing the\noutput distribution from the adapted model to be close to the unadapted one.\nThe MTL utilizes a jointly trained auxiliary task to improve the performance of\nthe main task. We investigated our approaches on E2E connectionist temporal\nclassification (CTC) models with three different types of output units.\nExperiments on the Microsoft short message dictation task demonstrated that MTL\noutperforms KLD regularization. In particular, the MTL adaptation obtained\n8.8\\% and 4.0\\% relative word error rate reductions (WERRs) for supervised and\nunsupervised adaptations for the word CTC model, and 9.6% and 3.8% relative\nWERRs for the mix-unit CTC model, respectively. \n\n"}
{"id": "1901.01590", "contents": "Title: Improving Unsupervised Word-by-Word Translation with Language Model and\n  Denoising Autoencoder Abstract: Unsupervised learning of cross-lingual word embedding offers elegant matching\nof words across languages, but has fundamental limitations in translating\nsentences. In this paper, we propose simple yet effective methods to improve\nword-by-word translation of cross-lingual embeddings, using only monolingual\ncorpora but without any back-translation. We integrate a language model for\ncontext-aware search, and use a novel denoising autoencoder to handle\nreordering. Our system surpasses state-of-the-art unsupervised neural\ntranslation systems without costly iterative training. We also analyze the\neffect of vocabulary size and denoising type on the translation performance,\nwhich provides better understanding of learning the cross-lingual word\nembedding and its usage in translation. \n\n"}
{"id": "1901.01695", "contents": "Title: Vector representations of text data in deep learning Abstract: In this dissertation we report results of our research on dense distributed\nrepresentations of text data. We propose two novel neural models for learning\nsuch representations. The first model learns representations at the document\nlevel, while the second model learns word-level representations.\n  For document-level representations we propose Binary Paragraph Vector: a\nneural network models for learning binary representations of text documents,\nwhich can be used for fast document retrieval. We provide a thorough evaluation\nof these models and demonstrate that they outperform the seminal method in the\nfield in the information retrieval task. We also report strong results in\ntransfer learning settings, where our models are trained on a generic text\ncorpus and then used to infer codes for documents from a domain-specific\ndataset. In contrast to previously proposed approaches, Binary Paragraph Vector\nmodels learn embeddings directly from raw text data.\n  For word-level representations we propose Disambiguated Skip-gram: a neural\nnetwork model for learning multi-sense word embeddings. Representations learned\nby this model can be used in downstream tasks, like part-of-speech tagging or\nidentification of semantic relations. In the word sense induction task\nDisambiguated Skip-gram outperforms state-of-the-art models on three out of\nfour benchmarks datasets. Our model has an elegant probabilistic\ninterpretation. Furthermore, unlike previous models of this kind, it is\ndifferentiable with respect to all its parameters and can be trained with\nbackpropagation. In addition to quantitative results, we present qualitative\nevaluation of Disambiguated Skip-gram, including two-dimensional visualisations\nof selected word-sense embeddings. \n\n"}
{"id": "1901.02081", "contents": "Title: Team EP at TAC 2018: Automating data extraction in systematic reviews of\n  environmental agents Abstract: We describe our entry for the Systematic Review Information Extraction track\nof the 2018 Text Analysis Conference. Our solution is an end-to-end, deep\nlearning, sequence tagging model based on the BI-LSTM-CRF architecture.\nHowever, we use interleaved, alternating LSTM layers with highway connections\ninstead of the more traditional approach, where last hidden states of both\ndirections are concatenated to create an input to the next layer. We also make\nextensive use of pre-trained word embeddings, namely GloVe and ELMo. Thanks to\na number of regularization techniques, we were able to achieve relatively large\ncapacity of the model (31.3M+ of trainable parameters) for the size of training\nset (100 documents, less than 200K tokens). The system's official score was\n60.9% (micro-F1) and it ranked first for the Task 1. Additionally, after\nrectifying an obvious mistake in the submission format, the system scored\n67.35%. \n\n"}
{"id": "1901.02348", "contents": "Title: Improving noise robustness of automatic speech recognition via parallel\n  data and teacher-student learning Abstract: For real-world speech recognition applications, noise robustness is still a\nchallenge. In this work, we adopt the teacher-student (T/S) learning technique\nusing a parallel clean and noisy corpus for improving automatic speech\nrecognition (ASR) performance under multimedia noise. On top of that, we apply\na logits selection method which only preserves the k highest values to prevent\nwrong emphasis of knowledge from the teacher and to reduce bandwidth needed for\ntransferring data. We incorporate up to 8000 hours of untranscribed data for\ntraining and present our results on sequence trained models apart from cross\nentropy trained ones. The best sequence trained student model yields relative\nword error rate (WER) reductions of approximately 10.1%, 28.7% and 19.6% on our\nclean, simulated noisy and real test sets respectively comparing to a sequence\ntrained teacher. \n\n"}
{"id": "1901.02539", "contents": "Title: Supervised Transfer Learning for Product Information Question Answering Abstract: Popular e-commerce websites such as Amazon offer community question answering\nsystems for users to pose product related questions and experienced customers\nmay provide answers voluntarily. In this paper, we show that the large volume\nof existing community question answering data can be beneficial when building a\nsystem for answering questions related to product facts and specifications. Our\nexperimental results demonstrate that the performance of a model for answering\nquestions related to products listed in the Home Depot website can be improved\nby a large margin via a simple transfer learning technique from an existing\nlarge-scale Amazon community question answering dataset. Transfer learning can\nresult in an increase of about 10% in accuracy in the experimental setting\nwhere we restrict the size of the data of the target task used for training. As\nan application of this work, we integrate the best performing model trained in\nthis work into a mobile-based shopping assistant and show its usefulness. \n\n"}
{"id": "1901.02671", "contents": "Title: Is it Time to Swish? Comparing Deep Learning Activation Functions Across\n  NLP tasks Abstract: Activation functions play a crucial role in neural networks because they are\nthe nonlinearities which have been attributed to the success story of deep\nlearning. One of the currently most popular activation functions is ReLU, but\nseveral competitors have recently been proposed or 'discovered', including\nLReLU functions and swish. While most works compare newly proposed activation\nfunctions on few tasks (usually from image classification) and against few\ncompetitors (usually ReLU), we perform the first large-scale comparison of 21\nactivation functions across eight different NLP tasks. We find that a largely\nunknown activation function performs most stably across all tasks, the\nso-called penalized tanh function. We also show that it can successfully\nreplace the sigmoid and tanh gates in LSTM cells, leading to a 2 percentage\npoint (pp) improvement over the standard choices on a challenging NLP task. \n\n"}
{"id": "1901.02860", "contents": "Title: Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context Abstract: Transformers have a potential of learning longer-term dependency, but are\nlimited by a fixed-length context in the setting of language modeling. We\npropose a novel neural architecture Transformer-XL that enables learning\ndependency beyond a fixed length without disrupting temporal coherence. It\nconsists of a segment-level recurrence mechanism and a novel positional\nencoding scheme. Our method not only enables capturing longer-term dependency,\nbut also resolves the context fragmentation problem. As a result,\nTransformer-XL learns dependency that is 80% longer than RNNs and 450% longer\nthan vanilla Transformers, achieves better performance on both short and long\nsequences, and is up to 1,800+ times faster than vanilla Transformers during\nevaluation. Notably, we improve the state-of-the-art results of bpc/perplexity\nto 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion\nWord, and 54.5 on Penn Treebank (without finetuning). When trained only on\nWikiText-103, Transformer-XL manages to generate reasonably coherent, novel\ntext articles with thousands of tokens. Our code, pretrained models, and\nhyperparameters are available in both Tensorflow and PyTorch. \n\n"}
{"id": "1901.03735", "contents": "Title: EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in\n  Natural Language Inference Abstract: Quantitative reasoning is a higher-order reasoning skill that any intelligent\nnatural language understanding system can reasonably be expected to handle. We\npresent EQUATE (Evaluating Quantitative Understanding Aptitude in Textual\nEntailment), a new framework for quantitative reasoning in textual entailment.\nWe benchmark the performance of 9 published NLI models on EQUATE, and find that\non average, state-of-the-art methods do not achieve an absolute improvement\nover a majority-class baseline, suggesting that they do not implicitly learn to\nreason with quantities. We establish a new baseline Q-REAS that manipulates\nquantities symbolically. In comparison to the best performing NLI model, it\nachieves success on numerical reasoning tests (+24.2%), but has limited verbal\nreasoning capabilities (-8.1%). We hope our evaluation framework will support\nthe development of models of quantitative reasoning in language understanding. \n\n"}
{"id": "1901.04787", "contents": "Title: A Tweet Dataset Annotated for Named Entity Recognition and Stance\n  Detection Abstract: Annotated datasets in different domains are critical for many supervised\nlearning-based solutions to related problems and for the evaluation of the\nproposed solutions. Topics in natural language processing (NLP) similarly\nrequire annotated datasets to be used for such purposes. In this paper, we\ntarget at two NLP problems, named entity recognition and stance detection, and\npresent the details of a tweet dataset in Turkish annotated for named entity\nand stance information. Within the course of the current study, both the named\nentity and stance annotations of the included tweets are made publicly\navailable, although previously the dataset has been publicly shared with stance\nannotations only. We believe that this dataset will be useful for uncovering\nthe possible relationships between named entity recognition and stance\ndetection in tweets. \n\n"}
{"id": "1901.06595", "contents": "Title: Evaluating Text-to-Image Matching using Binary Image Selection (BISON) Abstract: Providing systems the ability to relate linguistic and visual content is one\nof the hallmarks of computer vision. Tasks such as text-based image retrieval\nand image captioning were designed to test this ability but come with\nevaluation measures that have a high variance or are difficult to interpret. We\nstudy an alternative task for systems that match text and images: given a text\nquery, the system is asked to select the image that best matches the query from\na pair of semantically similar images. The system's accuracy on this Binary\nImage SelectiON (BISON) task is interpretable, eliminates the reliability\nproblems of retrieval evaluations, and focuses on the system's ability to\nunderstand fine-grained visual structure. We gather a BISON dataset that\ncomplements the COCO dataset and use it to evaluate modern text-based image\nretrieval and image captioning systems. Our results provide novel insights into\nthe performance of these systems. The COCO-BISON dataset and corresponding\nevaluation code are publicly available from \\url{http://hexianghu.com/bison/}. \n\n"}
{"id": "1901.07744", "contents": "Title: Automated Essay Scoring based on Two-Stage Learning Abstract: Current state-of-art feature-engineered and end-to-end Automated Essay Score\n(AES) methods are proven to be unable to detect adversarial samples, e.g. the\nessays composed of permuted sentences and the prompt-irrelevant essays.\nFocusing on the problem, we develop a Two-Stage Learning Framework (TSLF) which\nintegrates the advantages of both feature-engineered and end-to-end AES models.\nIn experiments, we compare TSLF against a number of strong baselines, and the\nresults demonstrate the effectiveness and robustness of our models. TSLF\nsurpasses all the baselines on five-eighths of prompts and achieves new\nstate-of-the-art average performance when without negative samples. After\nadding some adversarial essays to the original datasets, TSLF outperforms the\nfeature-engineered and end-to-end baselines to a great extent, and shows great\nrobustness. \n\n"}
{"id": "1901.07910", "contents": "Title: NLSC: Unrestricted Natural Language-based Service Composition through\n  Sentence Embeddings Abstract: Current approaches for service composition (assemblies of atomic services)\nrequire developers to use: (a) domain-specific semantics to formalize services\nthat restrict the vocabulary for their descriptions, and (b) translation\nmechanisms for service retrieval to convert unstructured user requests to\nstrongly-typed semantic representations. In our work, we argue that effort to\ndeveloping service descriptions, request translations, and matching mechanisms\ncould be reduced using unrestricted natural language; allowing both: (1)\nend-users to intuitively express their needs using natural language, and (2)\nservice developers to develop services without relying on syntactic/semantic\ndescription languages. Although there are some natural language-based service\ncomposition approaches, they restrict service retrieval to syntactic/semantic\nmatching. With recent developments in Machine learning and Natural Language\nProcessing, we motivate the use of Sentence Embeddings by leveraging richer\nsemantic representations of sentences for service description, matching and\nretrieval. Experimental results show that service composition development\neffort may be reduced by more than 44\\% while keeping a high precision/recall\nwhen matching high-level user requests with low-level service method\ninvocations. \n\n"}
{"id": "1901.08149", "contents": "Title: TransferTransfo: A Transfer Learning Approach for Neural Network Based\n  Conversational Agents Abstract: We introduce a new approach to generative data-driven dialogue systems (e.g.\nchatbots) called TransferTransfo which is a combination of a Transfer learning\nbased training scheme and a high-capacity Transformer model. Fine-tuning is\nperformed by using a multi-task objective which combines several unsupervised\nprediction tasks. The resulting fine-tuned model shows strong improvements over\nthe current state-of-the-art end-to-end conversational models like memory\naugmented seq2seq and information-retrieval models. On the privately held\nPERSONA-CHAT dataset of the Conversational Intelligence Challenge 2, this\napproach obtains a new state-of-the-art, with respective perplexity, Hits@1 and\nF1 metrics of 16.28 (45 % absolute improvement), 80.7 (46 % absolute\nimprovement) and 19.5 (20 % absolute improvement). \n\n"}
{"id": "1901.08746", "contents": "Title: BioBERT: a pre-trained biomedical language representation model for\n  biomedical text mining Abstract: Biomedical text mining is becoming increasingly important as the number of\nbiomedical documents rapidly grows. With the progress in natural language\nprocessing (NLP), extracting valuable information from biomedical literature\nhas gained popularity among researchers, and deep learning has boosted the\ndevelopment of effective biomedical text mining models. However, directly\napplying the advancements in NLP to biomedical text mining often yields\nunsatisfactory results due to a word distribution shift from general domain\ncorpora to biomedical corpora. In this article, we investigate how the recently\nintroduced pre-trained language model BERT can be adapted for biomedical\ncorpora. We introduce BioBERT (Bidirectional Encoder Representations from\nTransformers for Biomedical Text Mining), which is a domain-specific language\nrepresentation model pre-trained on large-scale biomedical corpora. With almost\nthe same architecture across tasks, BioBERT largely outperforms BERT and\nprevious state-of-the-art models in a variety of biomedical text mining tasks\nwhen pre-trained on biomedical corpora. While BERT obtains performance\ncomparable to that of previous state-of-the-art models, BioBERT significantly\noutperforms them on the following three representative biomedical text mining\ntasks: biomedical named entity recognition (0.62% F1 score improvement),\nbiomedical relation extraction (2.80% F1 score improvement) and biomedical\nquestion answering (12.24% MRR improvement). Our analysis results show that\npre-training BERT on biomedical corpora helps it to understand complex\nbiomedical texts. We make the pre-trained weights of BioBERT freely available\nat https://github.com/naver/biobert-pretrained, and the source code for\nfine-tuning BioBERT available at https://github.com/dmis-lab/biobert. \n\n"}
{"id": "1901.09492", "contents": "Title: Neural Related Work Summarization with a Joint Context-driven Attention\n  Mechanism Abstract: Conventional solutions to automatic related work summarization rely heavily\non human-engineered features. In this paper, we develop a neural data-driven\nsummarizer by leveraging the seq2seq paradigm, in which a joint context-driven\nattention mechanism is proposed to measure the contextual relevance within full\ntexts and a heterogeneous bibliography graph simultaneously. Our motivation is\nto maintain the topic coherency between a related work section and its target\ndocument, where both the textual and graphic contexts play a big role in\ncharacterizing the relationship among scientific publications accurately.\nExperimental results on a large dataset show that our approach achieves a\nconsiderable improvement over a typical seq2seq summarizer and five classical\nsummarization baselines. \n\n"}
{"id": "1901.09813", "contents": "Title: Analogies Explained: Towards Understanding Word Embeddings Abstract: Word embeddings generated by neural network methods such as word2vec (W2V)\nare well known to exhibit seemingly linear behaviour, e.g. the embeddings of\nanalogy \"woman is to queen as man is to king\" approximately describe a\nparallelogram. This property is particularly intriguing since the embeddings\nare not trained to achieve it. Several explanations have been proposed, but\neach introduces assumptions that do not hold in practice. We derive a\nprobabilistically grounded definition of paraphrasing that we re-interpret as\nword transformation, a mathematical description of \"$w_x$ is to $w_y$\". From\nthese concepts we prove existence of linear relationships between W2V-type\nembeddings that underlie the analogical phenomenon, identifying explicit error\nterms. \n\n"}
{"id": "1901.10263", "contents": "Title: TiFi: Taxonomy Induction for Fictional Domains [Extended version] Abstract: Taxonomies are important building blocks of structured knowledge bases, and\ntheir construction from text sources and Wikipedia has received much attention.\nIn this paper we focus on the construction of taxonomies for fictional domains,\nusing noisy category systems from fan wikis or text extraction as input. Such\nfictional domains are archetypes of entity universes that are poorly covered by\nWikipedia, such as also enterprise-specific knowledge bases or highly\nspecialized verticals. Our fiction-targeted approach, called TiFi, consists of\nthree phases: (i) category cleaning, by identifying candidate categories that\ntruly represent classes in the domain of interest, (ii) edge cleaning, by\nselecting subcategory relationships that correspond to class subsumption, and\n(iii) top-level construction, by mapping classes onto a subset of high-level\nWordNet categories. A comprehensive evaluation shows that TiFi is able to\nconstruct taxonomies for a diverse range of fictional domains such as Lord of\nthe Rings, The Simpsons or Greek Mythology with very high precision and that it\noutperforms state-of-the-art baselines for taxonomy induction by a substantial\nmargin. \n\n"}
{"id": "1901.10265", "contents": "Title: Implicit Diversity in Image Summarization Abstract: Studies have shown that the people depicted in image search results tend to\nbe of majority groups with respect to socially salient attributes. This skew\ngoes beyond that which already exists in the world - e.g., Kay et al. showed\nthat although 28% of CEOs in US are women, only 10% of the top 100 results for\nCEO in Google Image Search are women. Most existing approaches to correct for\nthis kind of bias assume that the images of people include socially salient\nattribute labels. However, such labels are often unknown. Further, using\nautomated techniques to infer these labels may often not be possible within\nacceptable accuracy ranges, and may not be desirable due to the additional\nbiases this process could incur. We develop a novel approach that takes as\ninput a visibly diverse control set of images and uses this set to select a set\nof images of people in response to a query. The goal is to have a resulting set\nthat is more visibly diverse in a manner that emulates the diversity depicted\nin the control set. Importantly, this approach does not require images to be\nlabelled at any point; effectively, it gives a way to implicitly diversify the\nset of images selected. We provide two variants of our approach: the first is a\nmodification of the MMR algorithm to incorporate the diversity scores, and\nsecond is a more efficient variant that does not consider within-list\nredundancy. We evaluate these approaches empirically on two datasets 1) a new\ndataset containing top Google image results for 96 occupations, for which we\nevaluate gender and skin-tone diversity with respect to occupations and 2) the\nCelebA dataset for which we evaluate gender diversity with respect to facial\nfeatures. Our approaches produce image sets that significantly improve the\nvisible diversity of the results, compared to current Google search and other\ndiverse image summarization algorithms, at a minimal cost to accuracy. \n\n"}
{"id": "1901.10723", "contents": "Title: Compositionality for Recursive Neural Networks Abstract: Modelling compositionality has been a longstanding area of research in the\nfield of vector space semantics. The categorical approach to compositionality\nmaps grammar onto vector spaces in a principled way, but comes under fire for\nrequiring the formation of very high-dimensional matrices and tensors, and\ntherefore being computationally infeasible. In this paper I show how a linear\nsimplification of recursive neural tensor network models can be mapped directly\nonto the categorical approach, giving a way of computing the required matrices\nand tensors. This mapping suggests a number of lines of research for both\ncategorical compositional vector space models of meaning and for recursive\nneural network models of compositionality. \n\n"}
{"id": "1901.10787", "contents": "Title: Tensorized Embedding Layers for Efficient Model Compression Abstract: The embedding layers transforming input words into real vectors are the key\ncomponents of deep neural networks used in natural language processing.\nHowever, when the vocabulary is large, the corresponding weight matrices can be\nenormous, which precludes their deployment in a limited resource setting. We\nintroduce a novel way of parametrizing embedding layers based on the Tensor\nTrain (TT) decomposition, which allows compressing the model significantly at\nthe cost of a negligible drop or even a slight gain in performance. We evaluate\nour method on a wide range of benchmarks in natural language processing and\nanalyze the trade-off between performance and compression ratios for a wide\nrange of architectures, from MLPs to LSTMs and Transformers. \n\n"}
{"id": "1901.10826", "contents": "Title: Additive Margin SincNet for Speaker Recognition Abstract: Speaker Recognition is a challenging task with essential applications such as\nauthentication, automation, and security. The SincNet is a new deep learning\nbased model which has produced promising results to tackle the mentioned task.\nTo train deep learning systems, the loss function is essential to the network\nperformance. The Softmax loss function is a widely used function in deep\nlearning methods, but it is not the best choice for all kind of problems. For\ndistance-based problems, one new Softmax based loss function called Additive\nMargin Softmax (AM-Softmax) is proving to be a better choice than the\ntraditional Softmax. The AM-Softmax introduces a margin of separation between\nthe classes that forces the samples from the same class to be closer to each\nother and also maximizes the distance between classes. In this paper, we\npropose a new approach for speaker recognition systems called AM-SincNet, which\nis based on the SincNet but uses an improved AM-Softmax layer. The proposed\nmethod is evaluated in the TIMIT dataset and obtained an improvement of\napproximately 40% in the Frame Error Rate compared to SincNet. \n\n"}
{"id": "1901.11333", "contents": "Title: IMaT: Unsupervised Text Attribute Transfer via Iterative Matching and\n  Translation Abstract: Text attribute transfer aims to automatically rewrite sentences such that\nthey possess certain linguistic attributes, while simultaneously preserving\ntheir semantic content. This task remains challenging due to a lack of\nsupervised parallel data. Existing approaches try to explicitly disentangle\ncontent and attribute information, but this is difficult and often results in\npoor content-preservation and ungrammaticality. In contrast, we propose a\nsimpler approach, Iterative Matching and Translation (IMaT), which: (1)\nconstructs a pseudo-parallel corpus by aligning a subset of semantically\nsimilar sentences from the source and the target corpora; (2) applies a\nstandard sequence-to-sequence model to learn the attribute transfer; (3)\niteratively improves the learned transfer function by refining imperfections in\nthe alignment. In sentiment modification and formality transfer tasks, our\nmethod outperforms complex state-of-the-art systems by a large margin. As an\nauxiliary contribution, we produce a publicly-available test set with\nhuman-generated transfer references. \n\n"}
{"id": "cmp-lg/9509001", "contents": "Title: How much is enough?: Data requirements for statistical NLP Abstract: In this paper I explore a number of issues in the analysis of data\nrequirements for statistical NLP systems. A preliminary framework for viewing\nsuch systems is proposed and a sample of existing works are compared within\nthis framework. The first steps toward a theory of data requirements are made\nby establishing some results relevant to bounding the expected error rate of a\nclass of simplified statistical language learners as a function of the volume\nof training data. \n\n"}
{"id": "cmp-lg/9610004", "contents": "Title: A Faster Structured-Tag Word-Classification Method Abstract: Several methods have been proposed for processing a corpus to induce a tagset\nfor the sub-language represented by the corpus. This paper examines a\nstructured-tag word classification method introduced by McMahon (1994) and\ndiscussed further by McMahon & Smith (1995) in cmp-lg/9503011 . Two major\nvariations, (1) non-random initial assignment of words to classes and (2)\nmoving multiple words in parallel, together provide robust non-random results\nwith a speed increase of 200% to 450%, at the cost of slightly lower quality\nthan McMahon's method's average quality. Two further variations, (3) retaining\ninformation from less- frequent words and (4) avoiding reclustering closed\nclasses, are proposed for further study.\n  Note: The speed increases quoted above are relative to my implementation of\nmy understanding of McMahon's algorithm; this takes time measured in hours and\ndays on a home PC. A revised version of the McMahon & Smith (1995) paper has\nappeared (June 1996) in Computational Linguistics 22(2):217- 247; this refers\nto a time of \"several weeks\" to cluster 569 words on a Sparc-IPC. \n\n"}
{"id": "cmp-lg/9707006", "contents": "Title: Finite State Transducers Approximating Hidden Markov Models Abstract: This paper describes the conversion of a Hidden Markov Model into a\nsequential transducer that closely approximates the behavior of the stochastic\nmodel. This transformation is especially advantageous for part-of-speech\ntagging because the resulting transducer can be composed with other transducers\nthat encode correction rules for the most frequent tagging errors. The speed of\ntagging is also improved. The described methods have been implemented and\nsuccessfully tested on six languages. \n\n"}
{"id": "cmp-lg/9804001", "contents": "Title: Graph Interpolation Grammars: a Rule-based Approach to the Incremental\n  Parsing of Natural Languages Abstract: Graph Interpolation Grammars are a declarative formalism with an operational\nsemantics. Their goal is to emulate salient features of the human parser, and\nnotably incrementality. The parsing process defined by GIGs incrementally\nbuilds a syntactic representation of a sentence as each successive lexeme is\nread. A GIG rule specifies a set of parse configurations that trigger its\napplication and an operation to perform on a matching configuration. Rules are\npartly context-sensitive; furthermore, they are reversible, meaning that their\noperations can be undone, which allows the parsing process to be\nnondeterministic. These two factors confer enough expressive power to the\nformalism for parsing natural languages. \n\n"}
{"id": "cmp-lg/9805007", "contents": "Title: Parsing Inside-Out Abstract: The inside-outside probabilities are typically used for reestimating\nProbabilistic Context Free Grammars (PCFGs), just as the forward-backward\nprobabilities are typically used for reestimating HMMs. I show several novel\nuses, including improving parser accuracy by matching parsing algorithms to\nevaluation criteria; speeding up DOP parsing by 500 times; and 30 times faster\nPCFG thresholding at a given accuracy level. I also give an elegant,\nstate-of-the-art grammar formalism, which can be used to compute inside-outside\nprobabilities; and a parser description formalism, which makes it easy to\nderive inside-outside formulas and many others. \n\n"}
{"id": "cs/0007023", "contents": "Title: Towards a query language for annotation graphs Abstract: The multidimensional, heterogeneous, and temporal nature of speech databases\nraises interesting challenges for representation and query. Recently,\nannotation graphs have been proposed as a general-purpose representational\nframework for speech databases. Typical queries on annotation graphs require\npath expressions similar to those used in semistructured query languages.\nHowever, the underlying model is rather different from the customary graph\nmodels for semistructured data: the graph is acyclic and unrooted, and both\ntemporal and inclusion relationships are important. We develop a query language\nand describe optimization techniques for an underlying relational\nrepresentation. \n\n"}
{"id": "cs/0204020", "contents": "Title: Seven Dimensions of Portability for Language Documentation and\n  Description Abstract: The process of documenting and describing the world's languages is undergoing\nradical transformation with the rapid uptake of new digital technologies for\ncapture, storage, annotation and dissemination. However, uncritical adoption of\nnew tools and technologies is leading to resources that are difficult to reuse\nand which are less portable than the conventional printed resources they\nreplace. We begin by reviewing current uses of software tools and digital\ntechnologies for language documentation and description. This sheds light on\nhow digital language documentation and description are created and managed,\nleading to an analysis of seven portability problems under the following\nheadings: content, format, discovery, access, citation, preservation and\nrights. After characterizing each problem we provide a series of value\nstatements, and this provides the framework for a broad range of best practice\nrecommendations. \n\n"}
{"id": "cs/0205028", "contents": "Title: NLTK: The Natural Language Toolkit Abstract: NLTK, the Natural Language Toolkit, is a suite of open source program\nmodules, tutorials and problem sets, providing ready-to-use computational\nlinguistics courseware. NLTK covers symbolic and statistical natural language\nprocessing, and is interfaced to annotated corpora. Students augment and\nreplace existing components, learn structured programming by example, and\nmanipulate sophisticated models from the outset. \n\n"}
{"id": "cs/0208020", "contents": "Title: Using the DIFF Command for Natural Language Processing Abstract: Diff is a software program that detects differences between two data sets and\nis useful in natural language processing. This paper shows several examples of\nthe application of diff. They include the detection of differences between two\ndifferent datasets, extraction of rewriting rules, merging of two different\ndatasets, and the optimal matching of two different data sets. Since diff comes\nwith any standard UNIX system, it is readily available and very easy to use.\nOur studies showed that diff is a practical tool for research into natural\nlanguage processing. \n\n"}
{"id": "cs/0412098", "contents": "Title: The Google Similarity Distance Abstract: Words and phrases acquire meaning from the way they are used in society, from\ntheir relative semantics to other words and phrases. For computers the\nequivalent of `society' is `database,' and the equivalent of `use' is `way to\nsearch the database.' We present a new theory of similarity between words and\nphrases based on information distance and Kolmogorov complexity. To fix\nthoughts we use the world-wide-web as database, and Google as search engine.\nThe method is also applicable to other search engines and databases. This\ntheory is then applied to construct a method to automatically extract\nsimilarity, the Google similarity distance, of words and phrases from the\nworld-wide-web using Google page counts. The world-wide-web is the largest\ndatabase on earth, and the context information entered by millions of\nindependent users averages out to provide automatic semantics of useful\nquality. We give applications in hierarchical clustering, classification, and\nlanguage translation. We give examples to distinguish between colors and\nnumbers, cluster names of paintings by 17th century Dutch masters and names of\nbooks by English novelists, the ability to understand emergencies, and primes,\nand we demonstrate the ability to do a simple automatic English-Spanish\ntranslation. Finally, we use the WordNet database as an objective baseline\nagainst which to judge the performance of our method. We conduct a massive\nrandomized trial in binary classification using support vector machines to\nlearn categories based on our Google distance, resulting in an a mean agreement\nof 87% with the expert crafted WordNet categories. \n\n"}
{"id": "cs/9906006", "contents": "Title: Learning Efficient Disambiguation Abstract: This dissertation analyses the computational properties of current\nperformance-models of natural language parsing, in particular Data Oriented\nParsing (DOP), points out some of their major shortcomings and suggests\nsuitable solutions. It provides proofs that various problems of probabilistic\ndisambiguation are NP-Complete under instances of these performance-models, and\nit argues that none of these models accounts for attractive efficiency\nproperties of human language processing in limited domains, e.g. that frequent\ninputs are usually processed faster than infrequent ones. The central\nhypothesis of this dissertation is that these shortcomings can be eliminated by\nspecializing the performance-models to the limited domains. The dissertation\naddresses \"grammar and model specialization\" and presents a new framework, the\nAmbiguity-Reduction Specialization (ARS) framework, that formulates the\nnecessary and sufficient conditions for successful specialization. The\nframework is instantiated into specialization algorithms and applied to\nspecializing DOP. Novelties of these learning algorithms are 1) they limit the\nhypotheses-space to include only \"safe\" models, 2) are expressed as constrained\noptimization formulae that minimize the entropy of the training tree-bank given\nthe specialized grammar, under the constraint that the size of the specialized\nmodel does not exceed a predefined maximum, and 3) they enable integrating the\nspecialized model with the original one in a complementary manner. The\ndissertation provides experiments with initial implementations and compares the\nresulting Specialized DOP (SDOP) models to the original DOP models with\nencouraging results. \n\n"}
