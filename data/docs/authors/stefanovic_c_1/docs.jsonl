{"id": "0705.3995", "contents": "Title: On Undetected Error Probability of Binary Matrix Ensembles Abstract: In this paper, an analysis of the undetected error probability of ensembles\nof binary matrices is presented. The ensemble called the Bernoulli ensemble\nwhose members are considered as matrices generated from i.i.d. Bernoulli source\nis mainly considered here. The main contributions of this work are (i)\nderivation of the error exponent of the average undetected error probability\nand (ii) closed form expressions for the variance of the undetected error\nprobability. It is shown that the behavior of the exponent for a sparse\nensemble is somewhat different from that for a dense ensemble. Furthermore, as\na byproduct of the proof of the variance formula, simple covariance formula of\nthe weight distribution is derived. \n\n"}
{"id": "0707.1099", "contents": "Title: Worst-Case Interactive Communication and Enhancing Sensor Network\n  Lifetime Abstract: We are concerned with the problem of maximizing the worst-case lifetime of a\ndata-gathering wireless sensor network consisting of a set of sensor nodes\ndirectly communicating with a base-station.We propose to solve this problem by\nmodeling sensor node and base-station communication as the interactive\ncommunication between multiple correlated informants (sensor nodes) and a\nrecipient (base-station). We provide practical and scalable interactive\ncommunication protocols for data gathering in sensor networks and demonstrate\ntheir efficiency compared to traditional approaches.\n  In this paper, we first develop a formalism to address the problem of\nworst-case interactive communication between a set of multiple correlated\ninformants and a recipient. We realize that there can be different objectives\nto achieve in such a communication scenario and compute the optimal number of\nmessages and bits exchanged to realize these objectives. Then, we propose to\nadapt these results in the context of single-hop data-gathering sensor\nnetworks. Finally, based on this proposed formalism, we propose a clustering\nbased communication protocol for large sensor networks and demonstrate its\nsuperiority over a traditional clustering protocol. \n\n"}
{"id": "0708.0271", "contents": "Title: Capacity Region of the Finite-State Multiple Access Channel with and\n  without Feedback Abstract: The capacity region of the Finite-State Multiple Access Channel (FS-MAC) with\nfeedback that may be an arbitrary time-invariant function of the channel output\nsamples is considered. We characterize both an inner and an outer bound for\nthis region, using Masseys's directed information. These bounds are shown to\ncoincide, and hence yield the capacity region, of FS-MACs where the state\nprocess is stationary and ergodic and not affected by the inputs.\n  Though `multi-letter' in general, our results yield explicit conclusions when\napplied to specific scenarios of interest. E.g., our results allow us to:\n  - Identify a large class of FS-MACs, that includes the additive mod-2 noise\nMAC where the noise may have memory, for which feedback does not enlarge the\ncapacity region.\n  - Deduce that, for a general FS-MAC with states that are not affected by the\ninput, if the capacity (region) without feedback is zero, then so is the\ncapacity (region) with feedback.\n  - Deduce that the capacity region of a MAC that can be decomposed into a\n`multiplexer' concatenated by a point-to-point channel (with, without, or with\npartial feedback), the capacity region is given by $\\sum_{m} R_m \\leq C$, where\nC is the capacity of the point to point channel and m indexes the encoders.\nMoreover, we show that for this family of channels source-channel coding\nseparation holds. \n\n"}
{"id": "0708.1859", "contents": "Title: Multiple-Description Coding by Dithered Delta-Sigma Quantization Abstract: We address the connection between the multiple-description (MD) problem and\nDelta-Sigma quantization. The inherent redundancy due to oversampling in\nDelta-Sigma quantization, and the simple linear-additive noise model resulting\nfrom dithered lattice quantization, allow us to construct a symmetric and\ntime-invariant MD coding scheme. We show that the use of a noise shaping filter\nmakes it possible to trade off central distortion for side distortion.\nAsymptotically as the dimension of the lattice vector quantizer and order of\nthe noise shaping filter approach infinity, the entropy rate of the dithered\nDelta-Sigma quantization scheme approaches the symmetric two-channel MD\nrate-distortion function for a memoryless Gaussian source and MSE fidelity\ncriterion, at any side-to-central distortion ratio and any resolution. In the\noptimal scheme, the infinite-order noise shaping filter must be minimum phase\nand have a piece-wise flat power spectrum with a single jump discontinuity. An\nimportant advantage of the proposed design is that it is symmetric in rate and\ndistortion by construction, so the coding rates of the descriptions are\nidentical and there is therefore no need for source splitting. \n\n"}
{"id": "0708.3699", "contents": "Title: Convolutional Entanglement Distillation Abstract: We develop a theory of entanglement distillation that exploits a\nconvolutional coding structure. We provide a method for converting an arbitrary\nclassical binary or quaternary convolutional code into a convolutional\nentanglement distillation protocol. The imported classical convolutional code\ndoes not have to be dual-containing or self-orthogonal. The yield and\nerror-correcting properties of such a protocol depend respectively on the rate\nand error-correcting properties of the imported classical convolutional code. A\nconvolutional entanglement distillation protocol has several other benefits.\nTwo parties sharing noisy ebits can distill noiseless ebits ``online'' as they\nacquire more noisy ebits. Distillation yield is high and decoding complexity is\nsimple for a convolutional entanglement distillation protocol. Our theory of\nconvolutional entanglement distillation reduces the problem of finding a good\nconvolutional entanglement distillation protocol to the well-established\nproblem of finding a good classical convolutional code. \n\n"}
{"id": "0708.4214", "contents": "Title: High Rate Single-Symbol Decodable Precoded DSTBCs for Cooperative\n  Networks Abstract: Distributed Orthogonal Space-Time Block Codes (DOSTBCs) achieving full\ndiversity order and single-symbol ML decodability have been introduced recently\nfor cooperative networks and an upper-bound on the maximal rate of such codes\nalong with code constructions has been presented. In this report, we introduce\na new class of Distributed STBCs called Semi-orthogonal Precoded Distributed\nSingle-Symbol Decodable STBCs (S-PDSSDC) wherein, the source performs\nco-ordinate interleaving of information symbols appropriately before\ntransmitting it to all the relays. It is shown that DOSTBCs are a special case\nof S-PDSSDCs. A special class of S-PDSSDCs having diagonal covariance matrix at\nthe destination is studied and an upper bound on the maximal rate of such codes\nis derived. The bounds obtained are approximately twice larger than that of the\nDOSTBCs. A systematic construction of S-PDSSDCs is presented when the number of\nrelays $K \\geq 4$. The constructed codes are shown to achieve the upper-bound\non the rate when $K$ is of the form 0 modulo 4 or 3 modulo 4. For the rest of\nthe values of $K$, the constructed codes are shown to have rates higher than\nthat of DOSTBCs. It is also shown that S-PDSSDCs cannot be constructed with any\nform of linear processing at the relays when the source doesn't perform\nco-ordinate interleaving of the information symbols. \n\n"}
{"id": "0709.2833", "contents": "Title: Distributed Space Time Codes with Low Decoding Complexity for\n  Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time code (DSTC) structure that admit its application in the\nproposed transmission scheme are identified and it is pointed out that the\nrecently proposed full diversity four group decodable DSTCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time codes applicable in this new transmission scheme for\npower of two number of relays are also provided. \n\n"}
{"id": "0709.3921", "contents": "Title: Geographic Gossip: Efficient Averaging for Sensor Networks Abstract: Gossip algorithms for distributed computation are attractive due to their\nsimplicity, distributed nature, and robustness in noisy and uncertain\nenvironments. However, using standard gossip algorithms can lead to a\nsignificant waste in energy by repeatedly recirculating redundant information.\nFor realistic sensor network model topologies like grids and random geometric\ngraphs, the inefficiency of gossip schemes is related to the slow mixing times\nof random walks on the communication graph. We propose and analyze an\nalternative gossiping scheme that exploits geographic information. By utilizing\ngeographic routing combined with a simple resampling method, we demonstrate\nsubstantial gains over previously proposed gossip protocols. For regular graphs\nsuch as the ring or grid, our algorithm improves standard gossip by factors of\n$n$ and $\\sqrt{n}$ respectively. For the more challenging case of random\ngeometric graphs, our algorithm computes the true average to accuracy\n$\\epsilon$ using $O(\\frac{n^{1.5}}{\\sqrt{\\log n}} \\log \\epsilon^{-1})$ radio\ntransmissions, which yields a $\\sqrt{\\frac{n}{\\log n}}$ factor improvement over\nstandard gossip algorithms. We illustrate these theoretical results with\nexperimental comparisons between our algorithm and standard methods as applied\nto various classes of random fields. \n\n"}
{"id": "0710.5161", "contents": "Title: Decomposable Subspaces, Linear Sections of Grassmann Varieties, and\n  Higher Weights of Grassmann Codes Abstract: Given a homogeneous component of an exterior algebra, we characterize those\nsubspaces in which every nonzero element is decomposable. In geometric terms,\nthis corresponds to characterizing the projective linear subvarieties of the\nGrassmann variety with its Plucker embedding. When the base field is finite, we\nconsider the more general question of determining the maximum number of points\non sections of Grassmannians by linear subvarieties of a fixed (co)dimension.\nThis corresponds to a known open problem of determining the complete weight\nhierarchy of linear error correcting codes associated to Grassmann varieties.\nWe recover most of the known results as well as prove some new results. In the\nprocess we obtain, and utilize, a simple generalization of the Griesmer-Wei\nbound for arbitrary linear codes. \n\n"}
{"id": "0711.0237", "contents": "Title: Zero-rate feedback can achieve the empirical capacity Abstract: The utility of limited feedback for coding over an individual sequence of\nDMCs is investigated. This study complements recent results showing how limited\nor noisy feedback can boost the reliability of communication. A strategy with\nfixed input distribution $P$ is given that asymptotically achieves rates\narbitrarily close to the mutual information induced by $P$ and the\nstate-averaged channel. When the capacity achieving input distribution is the\nsame over all channel states, this achieves rates at least as large as the\ncapacity of the state averaged channel, sometimes called the empirical\ncapacity. \n\n"}
{"id": "0803.2262", "contents": "Title: Constant-Rank Codes and Their Connection to Constant-Dimension Codes Abstract: Constant-dimension codes have recently received attention due to their\nsignificance to error control in noncoherent random linear network coding. What\nthe maximal cardinality of any constant-dimension code with finite dimension\nand minimum distance is and how to construct the optimal constant-dimension\ncode (or codes) that achieves the maximal cardinality both remain open research\nproblems. In this paper, we introduce a new approach to solving these two\nproblems. We first establish a connection between constant-rank codes and\nconstant-dimension codes. Via this connection, we show that optimal\nconstant-dimension codes correspond to optimal constant-rank codes over\nmatrices with sufficiently many rows. As such, the two aforementioned problems\nare equivalent to determining the maximum cardinality of constant-rank codes\nand to constructing optimal constant-rank codes, respectively. To this end, we\nthen derive bounds on the maximum cardinality of a constant-rank code with a\ngiven minimum rank distance, propose explicit constructions of optimal or\nasymptotically optimal constant-rank codes, and establish asymptotic bounds on\nthe maximum rate of a constant-rank code. \n\n"}
{"id": "0804.0611", "contents": "Title: Channel State Feedback Schemes for Multiuser MIMO-OFDM Downlink Abstract: Channel state feedback schemes for the MIMO broadcast downlink have been\nwidely studied in the frequency-flat case. This work focuses on the more\nrelevant frequency selective case, where some important new aspects emerge. We\nconsider a MIMO-OFDM broadcast channel and compare achievable ergodic rates\nunder three channel state feedback schemes: analog feedback, direction\nquantized feedback and \"time-domain\" channel quantized feedback. The first two\nschemes are direct extensions of previously proposed schemes. The third scheme\nis novel, and it is directly inspired by rate-distortion theory of Gaussian\ncorrelated sources. For each scheme we derive the conditions under which the\nsystem achieves full multiplexing gain. The key difference with respect to the\nwidely treated frequency-flat case is that in MIMO-OFDM the frequency-domain\nchannel transfer function is a Gaussian correlated source. The new time-domain\nquantization scheme takes advantage of the channel frequency correlation\nstructure and outperforms the other schemes. Furthermore, it is by far simpler\nto implement than complicated spherical vector quantization. In particular, we\nobserve that no structured codebook design and vector quantization is actually\nneeded for efficient channel state information feedback. \n\n"}
{"id": "0804.0980", "contents": "Title: Large MIMO Detection: A Low-Complexity Detector at High Spectral\n  Efficiencies Abstract: We consider large MIMO systems, where by `{\\em large}' we mean number of\ntransmit and receive antennas of the order of tens to hundreds. Such large MIMO\nsystems will be of immense interest because of the very high spectral\nefficiencies possible in such systems. We present a low-complexity detector\nwhich achieves uncoded near-exponential diversity performance for hundreds of\nantennas (i.e., achieves near SISO AWGN performance in a large MIMO fading\nenvironment) with an average per-bit complexity of just $O(N_tN_r)$, where\n$N_t$ and $N_r$ denote the number of transmit and receive antennas,\nrespectively. With an outer turbo code, the proposed detector achieves good\ncoded bit error performance as well. For example, in a 600 transmit and 600\nreceive antennas V-BLAST system with a high spectral efficiency of 200 bps/Hz\n(using BPSK and rate-1/3 turbo code), our simulation results show that the\nproposed detector performs close to within about 4.6 dB from theoretical\ncapacity. We also adopt the proposed detector for the low-complexity decoding\nof high-rate non-orthogonal space-time block codes (STBC) from division\nalgebras (DA). For example, we have decoded the $16\\times 16$ full-rate\nnon-orthogonal STBC from DA using the proposed detector and show that it\nperforms close to within about 5.5 dB of the capacity using 4-QAM and rate-3/4\nturbo code at a spectral efficiency of 24 bps/Hz. The practical feasibility of\nthe proposed high-performance low-complexity detector could potentially trigger\nwide interest in the implementation of large MIMO systems. In large MC-CDMA\nsystems with hundreds of users, the proposed detector is shown to achieve near\nsingle-user performance at an average per-bit complexity linear in number of\nusers, which is quite appealing for its use in practical CDMA systems. \n\n"}
{"id": "0805.1209", "contents": "Title: Scaling Laws for Overlaid Wireless Networks: A Cognitive Radio Network\n  vs. a Primary Network Abstract: We study the scaling laws for the throughputs and delays of two coexisting\nwireless networks that operate in the same geographic region. The primary\nnetwork consists of Poisson distributed legacy users of density n, and the\nsecondary network consists of Poisson distributed cognitive users of density m,\nwith m>n. The primary users have a higher priority to access the spectrum\nwithout particular considerations for the secondary users, while the secondary\nusers have to act conservatively in order to limit the interference to the\nprimary users. With a practical assumption that the secondary users only know\nthe locations of the primary transmitters (not the primary receivers), we first\nshow that both networks can achieve the same throughput scaling law as what\nGupta and Kumar [1] established for a stand-alone wireless network if proper\ntransmission schemes are deployed, where a certain throughput is achievable for\neach individual secondary user (i.e., zero outage) with high probability. By\nusing a fluid model, we also show that both networks can achieve the same\ndelay-throughput tradeoff as the optimal one established by El Gamal et al. [2]\nfor a stand-alone wireless network. \n\n"}
{"id": "0805.1857", "contents": "Title: The Gaussian Many-Help-One Distributed Source Coding Problem Abstract: Jointly Gaussian memoryless sources are observed at N distinct terminals. The\ngoal is to efficiently encode the observations in a distributed fashion so as\nto enable reconstruction of any one of the observations, say the first one, at\nthe decoder subject to a quadratic fidelity criterion. Our main result is a\nprecise characterization of the rate-distortion region when the covariance\nmatrix of the sources satisfies a \"tree-structure\" condition. In this\nsituation, a natural analog-digital separation scheme optimally trades off the\ndistributed quantization rate tuples and the distortion in the reconstruction:\neach encoder consists of a point-to-point Gaussian vector quantizer followed by\na Slepian-Wolf binning encoder. We also provide a partial converse that\nsuggests that the tree structure condition is fundamental. \n\n"}
{"id": "0806.3650", "contents": "Title: Recursive Code Construction for Random Networks Abstract: A modification of Koetter-Kschischang codes for random networks is presented\n(these codes were also studied by Wang et al. in the context of authentication\nproblems). The new codes have higher information rate, while maintaining the\nsame error-correcting capabilities. An efficient error-correcting algorithm is\nproposed for these codes. \n\n"}
{"id": "0806.4200", "contents": "Title: The Secrecy Rate Region of the Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers, while a wire-tapper\nalso receives the transmitted signal. This model is motivated by wireless\ncommunications, where individual secure messages are broadcast over open media\nand can be received by any illegitimate receiver. The secrecy level is measured\nby equivocation rate at the eavesdropper. We first study the general\n(non-degraded) broadcast channel with confidential messages. We present an\ninner bound on the secrecy capacity region for this model. The inner bound\ncoding scheme is based on a combination of random binning and the\nGelfand-Pinsker bining. This scheme matches the Marton's inner bound on the\nbroadcast channel without confidentiality constraint. We further study the\nsituation where the channels are degraded. For the degraded broadcast channel\nwith confidential messages, we present the secrecy capacity region. Our\nachievable coding scheme is based on Cover's superposition scheme and random\nbinning. We refer to this scheme as Secret Superposition Scheme. In this\nscheme, we show that randomization in the first layer increases the secrecy\nrate of the second layer. This capacity region matches the capacity region of\nthe degraded broadcast channel without security constraint. It also matches the\nsecrecy capacity for the conventional wire-tap channel. Our converse proof is\nbased on a combination of the converse proof of the conventional degraded\nbroadcast channel and Csiszar lemma. Finally, we assume that the channels are\nAdditive White Gaussian Noise (AWGN) and show that secret superposition scheme\nwith Gaussian codebook is optimal. The converse proof is based on the\ngeneralized entropy power inequality. \n\n"}
{"id": "0807.2440", "contents": "Title: Construction of Error-Correcting Codes for Random Network Coding Abstract: In this work we present error-correcting codes for random network coding\nbased on rank- metric codes, Ferrers diagrams, and puncturing. For most\nparameters, the constructed codes are larger than all previously known codes. \n\n"}
{"id": "0808.0234", "contents": "Title: DMT of Multi-hop Cooperative Networks - Part I: Basic Results Abstract: In this two-part paper, the DMT of cooperative multi-hop networks is\nexamined. The focus is on single-source single-sink (ss-ss) multi-hop relay\nnetworks having slow-fading links and relays that potentially possess multiple\nantennas. The present paper examines the two end-points of the DMT of\nfull-duplex networks. In particular, the maximum achievable diversity of\narbitrary multi-terminal wireless networks is shown to be equal to the min-cut.\nThe maximum multiplexing gain of arbitrary full-duplex ss-ss networks is shown\nto be equal to the min-cut rank, using a new connection to a deterministic\nnetwork. We also prove some basic results including a proof that the colored\nnoise encountered in AF protocols for cooperative networks can be treated as\nwhite noise for DMT computations. The DMT of a parallel channel with\nindependent MIMO links is also computed here. As an application of these basic\nresults, we prove that a linear tradeoff between maximum diversity and maximum\nmultiplexing gain is achievable for full-duplex networks with single antenna\nnodes. All protocols in this paper are explicit and rely only upon\namplify-and-forward (AF) relaying. Half duplex networks are studied, and\nexplicit codes for all protocols proposed in both parts, are provided in the\ncompanion paper. \n\n"}
{"id": "0808.0948", "contents": "Title: Capacity of a Class of Diamond Channels Abstract: We study a special class of diamond channels which was introduced by Schein\nin 2001. In this special class, each diamond channel consists of a transmitter,\na noisy relay, a noiseless relay and a receiver. We prove the capacity of this\nclass of diamond channels by providing an achievable scheme and a converse. The\ncapacity we show is strictly smaller than the cut-set bound. Our result also\nshows the optimality of a combination of decode-and-forward (DAF) and\ncompress-and-forward (CAF) at the noisy relay node. This is the first example\nwhere a combination of DAF and CAF is shown to be capacity achieving. Finally,\nwe note that there exists a duality between this diamond channel coding problem\nand the Kaspi-Berger source coding problem. \n\n"}
{"id": "0809.0009", "contents": "Title: Distributed Parameter Estimation in Sensor Networks: Nonlinear\n  Observation Models and Imperfect Communication Abstract: The paper studies distributed static parameter (vector) estimation in sensor\nnetworks with nonlinear observation models and noisy inter-sensor\ncommunication. It introduces \\emph{separably estimable} observation models that\ngeneralize the observability condition in linear centralized estimation to\nnonlinear distributed estimation. It studies two distributed estimation\nalgorithms in separably estimable models, the $\\mathcal{NU}$ (with its linear\ncounterpart $\\mathcal{LU}$) and the $\\mathcal{NLU}$. Their update rule combines\na \\emph{consensus} step (where each sensor updates the state by weight\naveraging it with its neighbors' states) and an \\emph{innovation} step (where\neach sensor processes its local current observation.) This makes the three\nalgorithms of the \\textit{consensus + innovations} type, very different from\ntraditional consensus. The paper proves consistency (all sensors reach\nconsensus almost surely and converge to the true parameter value,) efficiency,\nand asymptotic unbiasedness. For $\\mathcal{LU}$ and $\\mathcal{NU}$, it proves\nasymptotic normality and provides convergence rate guarantees. The three\nalgorithms are characterized by appropriately chosen decaying weight sequences.\nAlgorithms $\\mathcal{LU}$ and $\\mathcal{NU}$ are analyzed in the framework of\nstochastic approximation theory; algorithm $\\mathcal{NLU}$ exhibits mixed\ntime-scale behavior and biased perturbations, and its analysis requires a\ndifferent approach that is developed in the paper. \n\n"}
{"id": "0809.1366", "contents": "Title: Network Coding Security: Attacks and Countermeasures Abstract: By allowing intermediate nodes to perform non-trivial operations on packets,\nsuch as mixing data from multiple streams, network coding breaks with the\nruling store and forward networking paradigm and opens a myriad of challenging\nsecurity questions. Following a brief overview of emerging network coding\nprotocols, we provide a taxonomy of their security vulnerabilities, which\nhighlights the differences between attack scenarios in which network coding is\nparticularly vulnerable and other relevant cases in which the intrinsic\nproperties of network coding allow for stronger and more efficient security\nsolutions than classical routing. Furthermore, we give practical examples where\nnetwork coding can be combined with classical cryptography both for secure\ncommunication and secret key distribution. Throughout the paper we identify a\nnumber of research challenges deemed relevant towards the applicability of\nsecure network coding in practical networks. \n\n"}
{"id": "0809.3540", "contents": "Title: A Note on the Equivalence of Gibbs Free Energy and Information Theoretic\n  Capacity Abstract: The minimization of Gibbs free energy is based on the changes in work and\nfree energy that occur in a physical or chemical system. The maximization of\nmutual information, the capacity, of a noisy channel is determined based on the\nmarginal probabilities and conditional entropies associated with a\ncommunications system. As different as the procedures might first appear,\nthrough the exploration of a simple, \"dual use\" Ising model, it is seen that\nthe two concepts are in fact the same. In particular, the case of a binary\nsymmetric channel is calculated in detail. \n\n"}
{"id": "0809.4086", "contents": "Title: Learning Hidden Markov Models using Non-Negative Matrix Factorization Abstract: The Baum-Welsh algorithm together with its derivatives and variations has\nbeen the main technique for learning Hidden Markov Models (HMM) from\nobservational data. We present an HMM learning algorithm based on the\nnon-negative matrix factorization (NMF) of higher order Markovian statistics\nthat is structurally different from the Baum-Welsh and its associated\napproaches. The described algorithm supports estimation of the number of\nrecurrent states of an HMM and iterates the non-negative matrix factorization\n(NMF) algorithm to improve the learned HMM parameters. Numerical examples are\nprovided as well. \n\n"}
{"id": "0810.1808", "contents": "Title: A Central Limit Theorem for the SINR at the LMMSE Estimator Output for\n  Large Dimensional Signals Abstract: This paper is devoted to the performance study of the Linear Minimum Mean\nSquared Error estimator for multidimensional signals in the large dimension\nregime. Such an estimator is frequently encountered in wireless communications\nand in array processing, and the Signal to Interference and Noise Ratio (SINR)\nat its output is a popular performance index. The SINR can be modeled as a\nrandom quadratic form which can be studied with the help of large random matrix\ntheory, if one assumes that the dimension of the received and transmitted\nsignals go to infinity at the same pace. This paper considers the asymptotic\nbehavior of the SINR for a wide class of multidimensional signal models that\nincludes general multi-antenna as well as spread spectrum transmission models.\n  The expression of the deterministic approximation of the SINR in the large\ndimension regime is recalled and the SINR fluctuations around this\ndeterministic approximation are studied. These fluctuations are shown to\nconverge in distribution to the Gaussian law in the large dimension regime, and\ntheir variance is shown to decrease as the inverse of the signal dimension. \n\n"}
{"id": "0810.4658", "contents": "Title: Indexability of Restless Bandit Problems and Optimality of Whittle's\n  Index for Dynamic Multichannel Access Abstract: We consider a class of restless multi-armed bandit problems (RMBP) that\narises in dynamic multichannel access, user/server scheduling, and optimal\nactivation in multi-agent systems. For this class of RMBP, we establish the\nindexability and obtain Whittle's index in closed-form for both discounted and\naverage reward criteria. These results lead to a direct implementation of\nWhittle's index policy with remarkably low complexity. When these Markov chains\nare stochastically identical, we show that Whittle's index policy is optimal\nunder certain conditions. Furthermore, it has a semi-universal structure that\nobviates the need to know the Markov transition probabilities. The optimality\nand the semi-universal structure result from the equivalency between Whittle's\nindex policy and the myopic policy established in this work. For non-identical\nchannels, we develop efficient algorithms for computing a performance upper\nbound given by Lagrangian relaxation. The tightness of the upper bound and the\nnear-optimal performance of Whittle's index policy are illustrated with\nsimulation examples. \n\n"}
{"id": "0811.0196", "contents": "Title: Reduced-Complexity Reed--Solomon Decoders Based on Cyclotomic FFTs Abstract: In this paper, we reduce the computational complexities of partial and dual\npartial cyclotomic FFTs (CFFTs), which are discrete Fourier transforms where\nspectral and temporal components are constrained, based on their properties as\nwell as a common subexpression elimination algorithm. Our partial CFFTs achieve\nsmaller computational complexities than previously proposed partial CFFTs.\nUtilizing our CFFTs in both transform- and time-domain Reed--Solomon decoders,\nwe achieve significant complexity reductions. \n\n"}
{"id": "0811.4773", "contents": "Title: Two-way source coding with a helper Abstract: Consider the two-way rate-distortion problem in which a helper sends a common\nlimited-rate message to both users based on side information at its disposal.\nWe characterize the region of achievable rates and distortions where a Markov\nform (Helper)-(User 1)-(User 2) holds. The main insight of the result is that\nin order to achieve the optimal rate, the helper may use a binning scheme, as\nin Wyner-Ziv, where the side information at the decoder is the \"further\" user,\nnamely, User 2. We derive these regions explicitly for the Gaussian sources\nwith square error distortion, analyze a trade-off between the rate from the\nhelper and the rate from the source, and examine a special case where the\nhelper has the freedom to send different messages, at different rates, to the\nencoder and the decoder. \n\n"}
{"id": "0812.0319", "contents": "Title: Secrecy Capacity of a Class of Broadcast Channels with an Eavesdropper Abstract: We study the security of communication between a single transmitter and\nmultiple receivers in a broadcast channel in the presence of an eavesdropper.\nWe consider several special classes of channels. As the first model, we\nconsider the degraded multi-receiver wiretap channel where the legitimate\nreceivers exhibit a degradedness order while the eavesdropper is more noisy\nwith respect to all legitimate receivers. We establish the secrecy capacity\nregion of this channel model. Secondly, we consider the parallel multi-receiver\nwiretap channel with a less noisiness order in each sub-channel, where this\norder is not necessarily the same for all sub-channels. We establish the common\nmessage secrecy capacity and sum secrecy capacity of this channel. Thirdly, we\nstudy a special class of degraded parallel multi-receiver wiretap channels and\nprovide a stronger result. In particular, we study the case with two\nsub-channels two users and one eavesdropper, where there is a degradedness\norder in each sub-channel such that in the first (resp. second) sub-channel the\nsecond (resp. first) receiver is degraded with respect to the first (resp.\nsecond) receiver, while the eavesdropper is degraded with respect to both\nlegitimate receivers in both sub-channels. We determine the secrecy capacity\nregion of this channel. Finally, we focus on a variant of this previous channel\nmodel where the transmitter can use only one of the sub-channels at any time.\nWe characterize the secrecy capacity region of this channel as well. \n\n"}
{"id": "0812.1629", "contents": "Title: An application of the O'Nan-Scott theorem to the group generated by the\n  round functions of an AES-like cipher Abstract: In a previous paper, we had proved that the permutation group generated by\nthe round functions of an AES-like cipher is primitive. Here we apply the O'Nan\nScott classification of primitive groups to prove that this group is the\nalternating group. \n\n"}
{"id": "0812.5104", "contents": "Title: On Quantum and Classical Error Control Codes: Constructions and\n  Applications Abstract: It is conjectured that quantum computers are able to solve certain problems\nmore quickly than any deterministic or probabilistic computer. A quantum\ncomputer exploits the rules of quantum mechanics to speed up computations.\nHowever, it is a formidable task to build a quantum computer, since the quantum\nmechanical systems storing the information unavoidably interact with their\nenvironment. Therefore, one has to mitigate the resulting noise and decoherence\neffects to avoid computational errors.\n  In this work, I study various aspects of quantum error control codes -- the\nkey component of fault-tolerant quantum information processing. I present the\nfundamental theory and necessary background of quantum codes and construct many\nfamilies of quantum block and convolutional codes over finite fields, in\naddition to families of subsystem codes over symmetric and asymmetric channels.\n  Particularly, many families of quantum BCH, RS, duadic, and convolutional\ncodes are constructed over finite fields. Families of subsystem codes and a\nclass of optimal MDS subsystem codes are derived over asymmetric and symmetric\nquantum channels. In addition, propagation rules and tables of upper bounds on\nsubsystem code parameters are established. Classes of quantum and classical\nLDPC codes based on finite geometries and Latin squares are constructed. \n\n"}
{"id": "0901.1869", "contents": "Title: Low-Complexity Near-ML Decoding of Large Non-Orthogonal STBCs Using PDA Abstract: Non-orthogonal space-time block codes (STBC) from cyclic division algebras\n(CDA) having large dimensions are attractive because they can simultaneously\nachieve both high spectral efficiencies (same spectral efficiency as in V-BLAST\nfor a given number of transmit antennas) {\\em as well as} full transmit\ndiversity. Decoding of non-orthogonal STBCs with hundreds of dimensions has\nbeen a challenge. In this paper, we present a probabilistic data association\n(PDA) based algorithm for decoding non-orthogonal STBCs with large dimensions.\nOur simulation results show that the proposed PDA-based algorithm achieves near\nSISO AWGN uncoded BER as well as near-capacity coded BER (within about 5 dB of\nthe theoretical capacity) for large non-orthogonal STBCs from CDA. We study the\neffect of spatial correlation on the BER, and show that the performance loss\ndue to spatial correlation can be alleviated by providing more receive spatial\ndimensions. We report good BER performance when a training-based iterative\ndecoding/channel estimation is used (instead of assuming perfect channel\nknowledge) in channels with large coherence times. A comparison of the\nperformances of the PDA algorithm and the likelihood ascent search (LAS)\nalgorithm (reported in our recent work) is also presented. \n\n"}
{"id": "0901.1936", "contents": "Title: A Lower Bound on the Capacity of Wireless Erasure Networks with Random\n  Node Locations Abstract: In this paper, a lower bound on the capacity of wireless ad hoc erasure\nnetworks is derived in closed form in the canonical case where $n$ nodes are\nuniformly and independently distributed in the unit area square. The bound\nholds almost surely and is asymptotically tight. We assume all nodes have fixed\ntransmit power and hence two nodes should be within a specified distance $r_n$\nof each other to overcome noise. In this context, interference determines\noutages, so we model each transmitter-receiver pair as an erasure channel with\na broadcast constraint, i.e. each node can transmit only one signal across all\nits outgoing links. A lower bound of $\\Theta(n r_n)$ for the capacity of this\nclass of networks is derived. If the broadcast constraint is relaxed and each\nnode can send distinct signals on distinct outgoing links, we show that the\ngain is a function of $r_n$ and the link erasure probabilities, and is at most\na constant if the link erasure probabilities grow sufficiently large with $n$.\nFinally, the case where the erasure probabilities are themselves random\nvariables, for example due to randomness in geometry or channels, is analyzed.\nWe prove somewhat surprisingly that in this setting, variability in erasure\nprobabilities increases network capacity. \n\n"}
{"id": "0902.2141", "contents": "Title: Extracting the Kolmogorov Complexity of Strings and Sequences from\n  Sources with Limited Independence Abstract: An infinite binary sequence has randomness rate at least $\\sigma$ if, for\nalmost every $n$, the Kolmogorov complexity of its prefix of length $n$ is at\nleast $\\sigma n$. It is known that for every rational $\\sigma \\in (0,1)$, on\none hand, there exists sequences with randomness rate $\\sigma$ that can not be\neffectively transformed into a sequence with randomness rate higher than\n$\\sigma$ and, on the other hand, any two independent sequences with randomness\nrate $\\sigma$ can be transformed into a sequence with randomness rate higher\nthan $\\sigma$. We show that the latter result holds even if the two input\nsequences have linear dependency (which, informally speaking, means that all\nprefixes of length $n$ of the two sequences have in common a constant fraction\nof their information). The similar problem is studied for finite strings. It is\nshown that from any two strings with sufficiently large Kolmogorov complexity\nand sufficiently small dependence, one can effectively construct a string that\nis random even conditioned by any one of the input strings. \n\n"}
{"id": "0902.2260", "contents": "Title: Network Coding with Two-Way Relaying: Achievable Rate Regions and\n  Diversity-Multiplexing Tradeoffs Abstract: This paper addresses the fundamental characteristics of information exchange\nvia multihop network coding over two-way relaying in a wireless ad hoc network.\nThe end-to-end rate regions achieved by time-division multihop (TDMH),\nMAC-layer network coding (MLNC) and PHY-layer network coding (PLNC) are first\ncharacterized. It is shown that MLNC does not always achieve better rates than\nTDMH, time sharing between TDMH and MLNC is able to achieve a larger rate\nregion, and PLNC dominates the rate regions achieved by TDMH and MLNC. An\nopportunistic scheduling algorithm for MLNC and PLNC is then proposed to\nstabilize the two-way relaying system for Poisson arrivals whenever the rate\npair is within the Shannon rate regions of MLNC and PLNC. To understand the\ntwo-way transmission limits of multihop network coding, the sum-rate\noptimization with or without certain traffic pattern and the end-to-end\ndiversity-multiplexing tradeoffs (DMTs) of two-way transmission over multiple\nrelay nodes are also analyzed. \n\n"}
{"id": "0903.3261", "contents": "Title: The Secrecy Capacity Region of the Gaussian MIMO Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers via a Gaussian MIMO\nbroadcast channel. A wire-tapper also receives the transmitted signal via\nanother MIMO channel. First we assumed that the channels are degraded and the\nwire-tapper has the worst channel. We establish the capacity region of this\nscenario. Our achievability scheme is a combination of the superposition of\nGaussian codes and randomization within the layers which we will refer to as\nSecret Superposition Coding. For the outerbound, we use the notion of enhanced\nchannel to show that the secret superposition of Gaussian codes is optimal. We\nshow that we only need to enhance the channels of the legitimate receivers, and\nthe channel of the eavesdropper remains unchanged. Then we extend the result of\nthe degraded case to non-degraded case. We show that the secret superposition\nof Gaussian codes along with successive decoding cannot work when the channels\nare not degraded. we develop a Secret Dirty Paper Coding (SDPC) scheme and show\nthat SDPC is optimal for this channel. Finally, we investigate practical\ncharacterizations for the specific scenario in which the transmitter and the\neavesdropper have multiple antennas, while both intended receivers have a\nsingle antenna. We characterize the secrecy capacity region in terms of\ngeneralized eigenvalues of the receivers channel and the eavesdropper channel.\nWe refer to this configuration as the MISOME case. In high SNR we show that the\ncapacity region is a convex closure of two rectangular regions. \n\n"}
{"id": "0905.3407", "contents": "Title: Throughput and Delay Scaling in Supportive Two-Tier Networks Abstract: Consider a wireless network that has two tiers with different priorities: a\nprimary tier vs. a secondary tier, which is an emerging network scenario with\nthe advancement of cognitive radio technologies. The primary tier consists of\nrandomly distributed legacy nodes of density $n$, which have an absolute\npriority to access the spectrum. The secondary tier consists of randomly\ndistributed cognitive nodes of density $m=n^\\beta$ with $\\beta\\geq 2$, which\ncan only access the spectrum opportunistically to limit the interference to the\nprimary tier. Based on the assumption that the secondary tier is allowed to\nroute the packets for the primary tier, we investigate the throughput and delay\nscaling laws of the two tiers in the following two scenarios: i) the primary\nand secondary nodes are all static; ii) the primary nodes are static while the\nsecondary nodes are mobile. With the proposed protocols for the two tiers, we\nshow that the primary tier can achieve a per-node throughput scaling of\n$\\lambda_p(n)=\\Theta(1/\\log n)$ in the above two scenarios. In the associated\ndelay analysis for the first scenario, we show that the primary tier can\nachieve a delay scaling of $D_p(n)=\\Theta(\\sqrt{n^\\beta\\log n}\\lambda_p(n))$\nwith $\\lambda_p(n)=O(1/\\log n)$. In the second scenario, with two mobility\nmodels considered for the secondary nodes: an i.i.d. mobility model and a\nrandom walk model, we show that the primary tier can achieve delay scaling laws\nof $\\Theta(1)$ and $\\Theta(1/S)$, respectively, where $S$ is the random walk\nstep size. The throughput and delay scaling laws for the secondary tier are\nalso established, which are the same as those for a stand-alone network. \n\n"}
{"id": "0905.4023", "contents": "Title: DMT Optimality of LR-Aided Linear Decoders for a General Class of\n  Channels, Lattice Designs, and System Models Abstract: The work identifies the first general, explicit, and non-random MIMO\nencoder-decoder structures that guarantee optimality with respect to the\ndiversity-multiplexing tradeoff (DMT), without employing a computationally\nexpensive maximum-likelihood (ML) receiver. Specifically, the work establishes\nthe DMT optimality of a class of regularized lattice decoders, and more\nimportantly the DMT optimality of their lattice-reduction (LR)-aided linear\ncounterparts. The results hold for all channel statistics, for all channel\ndimensions, and most interestingly, irrespective of the particular lattice-code\napplied. As a special case, it is established that the LLL-based LR-aided\nlinear implementation of the MMSE-GDFE lattice decoder facilitates DMT optimal\ndecoding of any lattice code at a worst-case complexity that grows at most\nlinearly in the data rate. This represents a fundamental reduction in the\ndecoding complexity when compared to ML decoding whose complexity is generally\nexponential in rate.\n  The results' generality lends them applicable to a plethora of pertinent\ncommunication scenarios such as quasi-static MIMO, MIMO-OFDM, ISI,\ncooperative-relaying, and MIMO-ARQ channels, in all of which the DMT optimality\nof the LR-aided linear decoder is guaranteed. The adopted approach yields\ninsight, and motivates further study, into joint transceiver designs with an\nimproved SNR gap to ML decoding. \n\n"}
{"id": "0906.3200", "contents": "Title: On the Compound MIMO Broadcast Channels with Confidential Messages Abstract: We study the compound multi-input multi-output (MIMO) broadcast channel with\nconfidential messages (BCC), where one transmitter sends a common message to\ntwo receivers and two confidential messages respectively to each receiver. The\nchannel state may take one of a finite set of states, and the transmitter knows\nthe state set but does not know the realization of the state. We study\nachievable rates with perfect secrecy in the high SNR regime by characterizing\nan achievable secrecy degree of freedom (s.d.o.f.) region for two models, the\nGaussian MIMO-BCC and the ergodic fading multi-input single-output (MISO)-BCC\nwithout a common message. We show that by exploiting an additional temporal\ndimension due to state variation in the ergodic fading model, the achievable\ns.d.o.f. region can be significantly improved compared to the Gaussian model\nwith a constant state, although at the price of a larger delay. \n\n"}
{"id": "0906.3499", "contents": "Title: Convergence of fixed-point continuation algorithms for matrix rank\n  minimization Abstract: The matrix rank minimization problem has applications in many fields such as\nsystem identification, optimal control, low-dimensional embedding, etc. As this\nproblem is NP-hard in general, its convex relaxation, the nuclear norm\nminimization problem, is often solved instead. Recently, Ma, Goldfarb and Chen\nproposed a fixed-point continuation algorithm for solving the nuclear norm\nminimization problem. By incorporating an approximate singular value\ndecomposition technique in this algorithm, the solution to the matrix rank\nminimization problem is usually obtained. In this paper, we study the\nconvergence/recoverability properties of the fixed-point continuation algorithm\nand its variants for matrix rank minimization. Heuristics for determining the\nrank of the matrix when its true rank is not known are also proposed. Some of\nthese algorithms are closely related to greedy algorithms in compressed\nsensing. Numerical results for these algorithms for solving affinely\nconstrained matrix rank minimization problems are reported. \n\n"}
{"id": "0906.3682", "contents": "Title: Large System Analysis of Linear Precoding in Correlated MISO Broadcast\n  Channels under Limited Feedback Abstract: In this paper, we study the sum rate performance of zero-forcing (ZF) and\nregularized ZF (RZF) precoding in large MISO broadcast systems under the\nassumptions of imperfect channel state information at the transmitter and\nper-user channel transmit correlation. Our analysis assumes that the number of\ntransmit antennas $M$ and the number of single-antenna users $K$ are large\nwhile their ratio remains bounded. We derive deterministic approximations of\nthe empirical signal-to-interference plus noise ratio (SINR) at the receivers,\nwhich are tight as $M,K\\to\\infty$. In the course of this derivation, the\nper-user channel correlation model requires the development of a novel\ndeterministic equivalent of the empirical Stieltjes transform of large\ndimensional random matrices with generalized variance profile. The\ndeterministic SINR approximations enable us to solve various practical\noptimization problems. Under sum rate maximization, we derive (i) for RZF the\noptimal regularization parameter, (ii) for ZF the optimal number of users,\n(iii) for ZF and RZF the optimal power allocation scheme and (iv) the optimal\namount of feedback in large FDD/TDD multi-user systems. Numerical simulations\nsuggest that the deterministic approximations are accurate even for small\n$M,K$. \n\n"}
{"id": "0907.0505", "contents": "Title: Multi-User MISO Interference Channels with Single-User Detection:\n  Optimality of Beamforming and the Achievable Rate Region Abstract: For a multi-user interference channel with multi-antenna transmitters and\nsingle-antenna receivers, by restricting each transmitter to Gaussian input and\neach receiver to a single-user detector, computing the largest achievable rate\nregion amounts to solving a family of non-convex optimization problems.\nRecognizing the intrinsic connection between the signal power at the intended\nreceiver and the interference power at the unintended receiver, the original\nfamily of non-convex optimization problems is converted into a new family of\nconvex optimization problems. It is shown that, for such interference channels\nwith each receiver implementing single-user detection, transmitter beamforming\ncan achieve all boundary points of the achievable rate region. \n\n"}
{"id": "0907.1888", "contents": "Title: Compressive Sensing for Feedback Reduction in MIMO Broadcast Channels Abstract: We propose a generalized feedback model and compressive sensing based\nopportunistic feedback schemes for feedback resource reduction in MIMO\nBroadcast Channels under the assumption that both uplink and downlink channels\nundergo block Rayleigh fading. Feedback resources are shared and are\nopportunistically accessed by users who are strong, i.e. users whose channel\nquality information is above a certain fixed threshold. Strong users send same\nfeedback information on all shared channels. They are identified by the base\nstation via compressive sensing. Both analog and digital feedbacks are\nconsidered. The proposed analog & digital opportunistic feedback schemes are\nshown to achieve the same sum-rate throughput as that achieved by dedicated\nfeedback schemes, but with feedback channels growing only logarithmically with\nnumber of users. Moreover, there is also a reduction in the feedback load. In\nthe analog feedback case, we show that the propose scheme reduces the feedback\nnoise which eventually results in better throughput, whereas in the digital\nfeedback case the proposed scheme in a noisy scenario achieves almost the\nthroughput obtained in a noiseless dedicated feedback scenario. We also show\nthat for a fixed given budget of feedback bits, there exist a trade-off between\nthe number of shared channels and thresholds accuracy of the feedback SINR. \n\n"}
{"id": "0908.1071", "contents": "Title: Optimal Joint Target Detection and Parameter Estimation By MIMO Radar Abstract: We consider multiple-input multiple-output (MIMO) radar systems with\nwidely-spaced antennas. Such antenna configuration facilitates capturing the\ninherent diversity gain due to independent signal dispersion by the target\nscatterers. We consider a new MIMO radar framework for detecting a target that\nlies in an unknown location. This is in contrast with conventional MIMO radars\nwhich break the space into small cells and aim at detecting the presence of a\ntarget in a specified cell. We treat this problem through offering a novel\ncomposite hypothesis testing framework for target detection when (i) one or\nmore parameters of the target are unknown and we are interested in estimating\nthem, and (ii) only a finite number of observations are available. The test\noffered optimizes a metric which accounts for both detection and estimation\naccuracies. In this paper as the parameter of interest we focus on the vector\nof time-delays that the waveforms undergo from being emitted by the transmit\nantennas until being observed by the receive antennas. The analytical and\nempirical results establish that for the proposed joint target detection and\ntime-delay estimation framework, MIMO radars exhibit significant gains over\nphased-array radars for extended targets which consist of multiple independent\nscatterers. For point targets modeled as single scatterers, however, the\ndetection/estimation accuracies of MIMO and phased-array radars for this\nspecific setup (joint target detection and time-delay estimation) are\ncomparable. \n\n"}
{"id": "0908.1948", "contents": "Title: Interference Mitigation Through Limited Receiver Cooperation: Symmetric\n  Case Abstract: Interference is a major issue that limits the performance in wireless\nnetworks, and cooperation among receivers can help mitigate interference by\nforming distributed MIMO systems. The rate at which receivers cooperate,\nhowever, is limited in most scenarios. How much interference can one bit of\nreceiver cooperation mitigate? In this paper, we study the two-user Gaussian\ninterference channel with conferencing decoders to answer this question in a\nsimple setting. We characterize the fundamental gain from cooperation: at high\nSNR, when INR is below 50% of SNR in dB scale, one-bit cooperation per\ndirection buys roughly one-bit gain per user until full receiver cooperation\nperformance is reached, while when INR is between 67% and 200% of SNR in dB\nscale, one-bit cooperation per direction buys roughly half-bit gain per user.\nThe conclusion is drawn based on the approximate characterization of the\nsymmetric capacity in the symmetric set-up. We propose strategies achieving the\nsymmetric capacity universally to within 3 bits. The strategy consists of two\nparts: (1) the transmission scheme, where superposition encoding with a simple\npower split is employed, and (2) the cooperative protocol, where\nquantize-binning is used for relaying. \n\n"}
{"id": "0908.2494", "contents": "Title: A Channel Coding Perspective of Collaborative Filtering Abstract: We consider the problem of collaborative filtering from a channel coding\nperspective. We model the underlying rating matrix as a finite alphabet matrix\nwith block constant structure. The observations are obtained from this\nunderlying matrix through a discrete memoryless channel with a noisy part\nrepresenting noisy user behavior and an erasure part representing missing data.\nMoreover, the clusters over which the underlying matrix is constant are {\\it\nunknown}. We establish a sharp threshold result for this model: if the largest\ncluster size is smaller than $C_1 \\log(mn)$ (where the rating matrix is of size\n$m \\times n$), then the underlying matrix cannot be recovered with any\nestimator, but if the smallest cluster size is larger than $C_2 \\log(mn)$, then\nwe show a polynomial time estimator with diminishing probability of error. In\nthe case of uniform cluster size, not only the order of the threshold, but also\nthe constant is identified. \n\n"}
{"id": "0908.3562", "contents": "Title: Another Look at the Physics of Large Deviations With Application to\n  Rate-Distortion Theory Abstract: We revisit and extend the physical interpretation recently given to a certain\nidentity between large--deviations rate--functions (as well as applications of\nthis identity to Information Theory), as an instance of thermal equilibrium\nbetween several physical systems that are brought into contact. Our new\ninterpretation, of mechanical equilibrium between these systems, is shown to\nhave several advantages relative to that of thermal equilibrium. This physical\npoint of view also provides a trigger to the development of certain alternative\nrepresentations of the rate--distortion function and channel capacity, which\nare new to the best knowledge of the author. \n\n"}
{"id": "0909.1344", "contents": "Title: Multiuser MISO Transmitter Optimization for Inter-Cell Interference\n  Mitigation Abstract: The transmitter optimization (i.e., steering vectors and power allocation)\nfor a MISO Broadcast Channel (MISO-BC) subject to general linear constraints is\nconsidered. Such constraints include, as special cases, the sum power, the\nper-antenna or per-group-of-antennas power, and \"forbidden interference\ndirection\" constraints. We consider both the optimal dirty-paper coding and the\nsimple suboptimal linear zero-forcing beamforming strategies, and provide\nnumerically efficient algorithms that solve the problem in its most general\nform. As an application, we consider a multi-cell scenario with partial cell\ncooperation, where each cell optimizes its precoder by taking into account\ninterference constraints on specific users in adjacent cells. The effectiveness\nof the proposed methods is evaluated in a simple system scenario including two\nadjacent cells, under different fairness criteria that emphasize the bottleneck\nrole of users near the cell \"boundary\". Our results show that \"active\"\nInter-Cell Interference (ICI) mitigation outperforms the conventional \"static\"\nICI mitigation based on fractional frequency reuse. \n\n"}
{"id": "0909.4484", "contents": "Title: Error exponents for Neyman-Pearson detection of a continuous-time\n  Gaussian Markov process from noisy irregular samples Abstract: This paper addresses the detection of a stochastic process in noise from\nirregular samples. We consider two hypotheses. The \\emph{noise only} hypothesis\namounts to model the observations as a sample of a i.i.d. Gaussian random\nvariables (noise only). The \\emph{signal plus noise} hypothesis models the\nobservations as the samples of a continuous time stationary Gaussian process\n(the signal) taken at known but random time-instants corrupted with an additive\nnoise. Two binary tests are considered, depending on which assumptions is\nretained as the null hypothesis. Assuming that the signal is a linear\ncombination of the solution of a multidimensional stochastic differential\nequation (SDE), it is shown that the minimum Type II error probability\ndecreases exponentially in the number of samples when the False Alarm\nprobability is fixed. This behavior is described by \\emph{error exponents} that\nare completely characterized. It turns out that they are related with the\nasymptotic behavior of the Kalman Filter in random stationary environment,\nwhich is studied in this paper. Finally, numerical illustrations of our claims\nare provided in the context of sensor networks. \n\n"}
{"id": "0909.5006", "contents": "Title: On the Degrees of Freedom of the Compound MIMO Broadcast Channels with\n  Finite States Abstract: Multiple-antenna broadcast channels with $M$ transmit antennas and $K$\nsingle-antenna receivers is considered, where the channel of receiver $r$ takes\none of the $J_r$ finite values. It is assumed that the channel states of each\nreceiver are randomly selected from $\\mathds{R}^{M\\times 1}$ (or from\n$\\mathds{C}^{M\\times 1}$). It is shown that no matter what $J_r$ is, the\ndegrees of freedom (DoF) of $\\frac{MK}{M+K-1}$ is achievable. The achievable\nscheme relies on the idea of interference alignment at receivers, without\nexploiting the possibility of cooperation among transmit antennas. It is proven\nthat if $J_r \\geq M$, $r=1,...,K$, this scheme achieves the optimal DoF. This\nresults implies that when the uncertainty of the base station about the channel\nrealization is considerable, the system loses the gain of cooperation. However,\nit still benefits from the gain of interference alignment. In fact, in this\ncase, the compound broadcast channel is treated as a compound X channel.\n  Moreover, it is shown that when the base station knows the channel states of\nsome of the receivers, a combination of transmit cooperation and interference\nalignment would achieve the optimal DoF.\n  Like time-invariant $K$-user interference channels, the naive vector-space\napproaches of interference management seem insufficient to achieve the optimal\nDoF of this channel. In this paper, we use the Number-Theory approach of\nalignment, recently developed by Motahari et al.[1]. We extend the approach of\n[1] to complex channels as well, therefore all the results that we present are\nvalid for both real and complex channels. \n\n"}
{"id": "0910.0641", "contents": "Title: Optimal Testing of Reed-Muller Codes Abstract: We consider the problem of testing if a given function f : F_2^n -> F_2 is\nclose to any degree d polynomial in n variables, also known as the Reed-Muller\ntesting problem. The Gowers norm is based on a natural 2^{d+1}-query test for\nthis property. Alon et al. [AKKLR05] rediscovered this test and showed that it\naccepts every degree d polynomial with probability 1, while it rejects\nfunctions that are Omega(1)-far with probability Omega(1/(d 2^{d})). We give an\nasymptotically optimal analysis of this test, and show that it rejects\nfunctions that are (even only) Omega(2^{-d})-far with Omega(1)-probability (so\nthe rejection probability is a universal constant independent of d and n). This\nimplies a tight relationship between the (d+1)st Gowers norm of a function and\nits maximal correlation with degree d polynomials, when the correlation is\nclose to 1. Our proof works by induction on n and yields a new analysis of even\nthe classical Blum-Luby-Rubinfeld [BLR93] linearity test, for the setting of\nfunctions mapping F_2^n to F_2. The optimality follows from a tighter analysis\nof counterexamples to the \"inverse conjecture for the Gowers norm\" constructed\nby [GT09,LMS08]. Our result has several implications. First, it shows that the\nGowers norm test is tolerant, in that it also accepts close codewords. Second,\nit improves the parameters of an XOR lemma for polynomials given by Viola and\nWigderson [VW07]. Third, it implies a \"query hierarchy\" result for property\ntesting of affine-invariant properties. That is, for every function q(n), it\ngives an affine-invariant property that is testable with O(q(n))-queries, but\nnot with o(q(n))-queries, complementing an analogous result of [GKNR09] for\ngraph properties. \n\n"}
{"id": "0910.1407", "contents": "Title: 3-Receiver Broadcast Channels with Common and Confidential Messages Abstract: This paper establishes inner bounds on the secrecy capacity regions for the\ngeneral 3-receiver broadcast channel with one common and one confidential\nmessage sets. We consider two setups. The first is when the confidential\nmessage is to be sent to two receivers and kept secret from the third receiver.\nAchievability is established using indirect decoding, Wyner wiretap channel\ncoding, and the new idea of generating secrecy from a publicly available\nsuperposition codebook. The inner bound is shown to be tight for a class of\nreversely degraded broadcast channels and when both legitimate receivers are\nless noisy than the third receiver. The second setup investigated in this paper\nis when the confidential message is to be sent to one receiver and kept secret\nfrom the other two receivers. Achievability in this case follows from Wyner\nwiretap channel coding and indirect decoding. This inner bound is also shown to\nbe tight for several special cases. \n\n"}
{"id": "0911.2053", "contents": "Title: Interference Mitigation Through Limited Receiver Cooperation Abstract: Interference is a major issue limiting the performance in wireless networks.\nCooperation among receivers can help mitigate interference by forming\ndistributed MIMO systems. The rate at which receivers cooperate, however, is\nlimited in most scenarios. How much interference can one bit of receiver\ncooperation mitigate? In this paper, we study the two-user Gaussian\ninterference channel with conferencing decoders to answer this question in a\nsimple setting. We identify two regions regarding the gain from receiver\ncooperation: linear and saturation regions. In the linear region receiver\ncooperation is efficient and provides a degrees-of-freedom gain, which is\neither one cooperation bit buys one more bit or two cooperation bits buy one\nmore bit until saturation. In the saturation region receiver cooperation is\ninefficient and provides a power gain, which is at most a constant regardless\nof the rate at which receivers cooperate. The conclusion is drawn from the\ncharacterization of capacity region to within two bits. The proposed strategy\nconsists of two parts: (1) the transmission scheme, where superposition\nencoding with a simple power split is employed, and (2) the cooperative\nprotocol, where one receiver quantize-bin-and-forwards its received signal, and\nthe other after receiving the side information decode-bin-and-forwards its\nreceived signal. \n\n"}
{"id": "0911.4207", "contents": "Title: An information theoretic approach to statistical dependence: copula\n  information Abstract: We discuss the connection between information and copula theories by showing\nthat a copula can be employed to decompose the information content of a\nmultivariate distribution into marginal and dependence components, with the\nlatter quantified by the mutual information. We define the information excess\nas a measure of deviation from a maximum entropy distribution. The idea of\nmarginal invariant dependence measures is also discussed and used to show that\nempirical linear correlation underestimates the amplitude of the actual\ncorrelation in the case of non-Gaussian marginals. The mutual information is\nshown to provide an upper bound for the asymptotic empirical log-likelihood of\na copula. An analytical expression for the information excess of T-copulas is\nprovided, allowing for simple model identification within this family. We\nillustrate the framework in a financial data set. \n\n"}
{"id": "0911.4222", "contents": "Title: Message Passing Algorithms for Compressed Sensing: II. Analysis and\n  Validation Abstract: In a recent paper, the authors proposed a new class of low-complexity\niterative thresholding algorithms for reconstructing sparse signals from a\nsmall set of linear measurements \\cite{DMM}. The new algorithms are broadly\nreferred to as AMP, for approximate message passing. This is the second of two\nconference papers describing the derivation of these algorithms, connection\nwith related literature, extensions of original framework, and new empirical\nevidence.\n  This paper describes the state evolution formalism for analyzing these\nalgorithms, and some of the conclusions that can be drawn from this formalism.\nWe carried out extensive numerical simulations to confirm these predictions. We\npresent here a few representative results. \n\n"}
{"id": "0911.4530", "contents": "Title: MIMO Z-Interference Channels: Capacity Under Strong and Noisy\n  Interference Abstract: The capacity regions of multiple-input multiple-output Gaussian\nZ-interference channels are established for the very strong interference and\naligned strong interference cases. The sum-rate capacity of such channels is\nestablished under noisy interference. These results generalize known results\nfor scalar Gaussian Z-interference channels. \n\n"}
{"id": "0911.5300", "contents": "Title: Improving zero-error classical communication with entanglement Abstract: Given one or more uses of a classical channel, only a certain number of\nmessages can be transmitted with zero probability of error. The study of this\nnumber and its asymptotic behaviour constitutes the field of classical\nzero-error information theory, the quantum generalisation of which has started\nto develop recently. We show that, given a single use of certain classical\nchannels, entangled states of a system shared by the sender and receiver can be\nused to increase the number of (classical) messages which can be sent with no\nchance of error. In particular, we show how to construct such a channel based\non any proof of the Bell-Kochen-Specker theorem. This is a new example of the\nuse of quantum effects to improve the performance of a classical task. We\ninvestigate the connection between this phenomenon and that of\n``pseudo-telepathy'' games. The use of generalised non-signalling correlations\nto assist in this task is also considered. In this case, a particularly elegant\ntheory results and, remarkably, it is sometimes possible to transmit\ninformation with zero-error using a channel with no unassisted zero-error\ncapacity. \n\n"}
{"id": "0911.5515", "contents": "Title: Finite Dimensional Statistical Inference Abstract: In this paper, we derive the explicit series expansion of the eigenvalue\ndistribution of various models, namely the case of non-central Wishart\ndistributions, as well as correlated zero mean Wishart distributions. The tools\nused extend those of the free probability framework, which have been quite\nsuccessful for high dimensional statistical inference (when the size of the\nmatrices tends to infinity), also known as free deconvolution. This\ncontribution focuses on the finite Gaussian case and proposes algorithmic\nmethods to compute the moments. Cases where asymptotic results fail to apply\nare also discussed. \n\n"}
{"id": "0912.1628", "contents": "Title: KF-CS: Compressive Sensing on Kalman Filtered Residual Abstract: We consider the problem of recursively reconstructing time sequences of\nsparse signals (with unknown and time-varying sparsity patterns) from a limited\nnumber of linear incoherent measurements with additive noise. The idea of our\nproposed solution, KF CS-residual (KF-CS) is to replace compressed sensing (CS)\non the observation by CS on the Kalman filtered (KF) observation residual\ncomputed using the previous estimate of the support. KF-CS error stability over\ntime is studied. Simulation comparisons with CS and LS-CS are shown. \n\n"}
{"id": "0912.3029", "contents": "Title: Interference Alignment and a Noisy Interference Regime for Many-to-One\n  Interference Channels Abstract: We study the capacity of discrete memoryless many-to-one interference\nchannels, i.e., K user interference channels where only one receiver faces\ninterference. For a class of many-to-one interference channels, we identify a\nnoisy interference regime, i.e., a regime where random coding and treating\ninterference as noise achieves sum-capacity. Specializing our results to the\nGaussian MIMO many-to-one interference channel, which is a special case of the\nclass of channels considered, we obtain new capacity results. Firstly, we\nextend the noisy interference regime, previously studied for (many-to-one)\ninterference channels with average power constraints on the inputs, to a more\ngeneral class of inputs. This more general class includes the practical\nscenario of inputs being restricted to fixed finite-size constellations such as\nPSK or QAM. Secondly, we extend noisy interference results previously studied\nin SISO interference channels with full channel state information (CSI) at all\nnodes, to MIMO and parallel Gaussian many-to-one interference channels, and to\nfading Gaussian many-to-one interference channels without CSI at the\ntransmitters. While the many-to-one interference channel requires interference\nalignment, which in turn requires structured codes in general, we argue that in\nthe noisy interference regime, interference is implicitly aligned by random\ncoding irrespective of the input distribution. As a byproduct of our study, we\nidentify a second class of many-to-one interference channels (albeit\ndeterministic) where random coding is optimal (though interference is not\ntreated as noise). The optimality of random coding in this second class of\nchannels is due to an interference resolvability condition which precludes\ninterference alignment and hence obviates the need of structured codes. \n\n"}
{"id": "0912.3264", "contents": "Title: Random Access: An Information-Theoretic Perspective Abstract: This paper considers a random access system where each sender can be in two\nmodes of operation, active or not active, and where the set of active users is\navailable to a common receiver only. Active transmitters encode data into\nindependent streams of information, a subset of which are decoded by the\nreceiver, depending on the value of the collective interference. The main\ncontribution is to present an information-theoretic formulation of the problem\nwhich allows us to characterize, with a guaranteed gap to optimality, the rates\nthat can be achieved by different data streams.\n  Our results are articulated as follows. First, we exactly characterize the\ncapacity region of a two-user system assuming a binary-expansion deterministic\nchannel model. Second, we extend this result to a two-user additive white\nGaussian noise channel, providing an approximate characterization within\n$\\sqrt{3}/2$ bit of the actual capacity. Third, we focus on the symmetric\nscenario in which users are active with the same probability and subject to the\nsame received power constraint, and study the maximum achievable expected\nsum-rate, or throughput, for any number of users. In this case, for the\nsymmetric binary expansion deterministic channel (which is related to the\npacket collision model used in the networking literature), we show that a\nsimple coding scheme which does not employ superposition coding achieves the\nsystem throughput. This result also shows that the performance of slotted ALOHA\nsystems can be improved by allowing encoding rate adaptation at the\ntransmitters. For the symmetric additive white Gaussian noise channel, we\npropose a scheme that is within one bit of the system throughput for any value\nof the underlying parameters. \n\n"}
{"id": "0912.5537", "contents": "Title: Quantum Reverse Shannon Theorem Abstract: Dual to the usual noisy channel coding problem, where a noisy (classical or\nquantum) channel is used to simulate a noiseless one, reverse Shannon theorems\nconcern the use of noiseless channels to simulate noisy ones, and more\ngenerally the use of one noisy channel to simulate another. For channels of\nnonzero capacity, this simulation is always possible, but for it to be\nefficient, auxiliary resources of the proper kind and amount are generally\nrequired. In the classical case, shared randomness between sender and receiver\nis a sufficient auxiliary resource, regardless of the nature of the source, but\nin the quantum case the requisite auxiliary resources for efficient simulation\ndepend on both the channel being simulated, and the source from which the\nchannel inputs are coming. For tensor power sources (the quantum generalization\nof classical IID sources), entanglement in the form of standard ebits\n(maximally entangled pairs of qubits) is sufficient, but for general sources,\nwhich may be arbitrarily correlated or entangled across channel inputs,\nadditional resources, such as entanglement-embezzling states or backward\ncommunication, are generally needed. Combining existing and new results, we\nestablish the amounts of communication and auxiliary resources needed in both\nthe classical and quantum cases, the tradeoffs among them, and the loss of\nsimulation efficiency when auxiliary resources are absent or insufficient. In\nparticular we find a new single-letter expression for the excess forward\ncommunication cost of coherent feedback simulations of quantum channels (i.e.\nsimulations in which the sender retains what would escape into the environment\nin an ordinary simulation), on non-tensor-power sources in the presence of\nunlimited ebits but no other auxiliary resource. Our results on tensor power\nsources establish a strong converse to the entanglement-assisted capacity\ntheorem. \n\n"}
{"id": "1001.0723", "contents": "Title: MacWilliams Identities for Terminated Convolutional Codes Abstract: Shearer and McEliece [1977] showed that there is no MacWilliams identity for\nthe free distance spectra of orthogonal linear convolutional codes. We show\nthat on the other hand there does exist a MacWilliams identity between the\ngenerating functions of the weight distributions per unit time of a linear\nconvolutional code C and its orthogonal code C^\\perp, and that this\ndistribution is as useful as the free distance spectrum for estimating code\nperformance. These observations are similar to those made recently by\nBocharova, Hug, Johannesson and Kudryashov; however, we focus on terminating by\ntail-biting rather than by truncation. \n\n"}
{"id": "1001.1705", "contents": "Title: On the Pseudocodeword Redundancy Abstract: We define the AWGNC, BSC, and max-fractional pseudocodeword redundancy of a\ncode as the smallest number of rows in a parity-check matrix such that the\ncorresponding minimum pseudoweight is equal to the minimum Hamming distance. We\nshow that most codes do not have a finite pseudocodeword redundancy. We also\nprovide bounds on the pseudocodeword redundancy for some families of codes,\nincluding codes based on designs. \n\n"}
{"id": "1001.2198", "contents": "Title: Performance of Interference Alignment in Clustered Wireless Ad Hoc\n  Networks Abstract: Spatial interference alignment among a finite number of users is proposed as\na technique to increase the probability of successful transmission in an\ninterference limited clustered wireless ad hoc network. Using techniques from\nstochastic geometry, we build on the work of Ganti and Haenggi dealing with\nPoisson cluster processes with a fixed number of cluster points and provide a\nnumerically integrable expression for the outage probability using an\nintra-cluster interference alignment strategy with multiplexing gain one. For a\nspecial network setting we derive a closed-form upper bound. We demonstrate\nsignificant performance gains compared to single-antenna systems without local\ncooperation. \n\n"}
{"id": "1001.2283", "contents": "Title: Mutual Information of IID Complex Gaussian Signals on Block\n  Rayleigh-faded Channels Abstract: We present a method to compute, quickly and efficiently, the mutual\ninformation achieved by an IID (independent identically distributed) complex\nGaussian input on a block Rayleigh-faded channel without side information at\nthe receiver. The method accommodates both scalar and MIMO (multiple-input\nmultiple-output) settings. Operationally, the mutual information thus computed\nrepresents the highest spectral efficiency that can be attained using standard\nGaussian codebooks. Examples are provided that illustrate the loss in spectral\nefficiency caused by fast fading and how that loss is amplified by the use of\nmultiple transmit antennas. These examples are further enriched by comparisons\nwith the channel capacity under perfect channel-state information at the\nreceiver, and with the spectral efficiency attained by pilot-based\ntransmission. \n\n"}
{"id": "1001.4137", "contents": "Title: On the solvability of 3-source 3-terminal sum-networks Abstract: We consider a directed acyclic network with three sources and three terminals\nsuch that each source independently generates one symbol from a given field $F$\nand each terminal wants to receive the sum (over $F$) of the source symbols.\nEach link in the network is considered to be error-free and delay-free and can\ncarry one symbol from the field in each use. We call such a network a 3-source\n3-terminal {\\it $(3s/3t)$ sum-network}. In this paper, we give a necessary and\nsufficient condition for a $3s/3t$ sum-network to allow all the terminals to\nreceive the sum of the source symbols over \\textit{any} field. Some lemmas\nprovide interesting simpler sufficient conditions for the same. We show that\nlinear codes are sufficient for this problem for $3s/3t$ though they are known\nto be insufficient for arbitrary number of sources and terminals. We further\nshow that in most cases, such networks are solvable by simple XOR coding. We\nalso prove a recent conjecture that if fractional coding is allowed, then the\ncoding capacity of a $3s/3t$ sum-network is either $0,2/3$ or $\\geq 1$. \n\n"}
{"id": "1002.0110", "contents": "Title: On Unbiased Estimation of Sparse Vectors Corrupted by Gaussian Noise Abstract: We consider the estimation of a sparse parameter vector from measurements\ncorrupted by white Gaussian noise. Our focus is on unbiased estimation as a\nsetting under which the difficulty of the problem can be quantified\nanalytically. We show that there are infinitely many unbiased estimators but\nnone of them has uniformly minimum mean-squared error. We then provide lower\nand upper bounds on the Barankin bound, which describes the performance\nachievable by unbiased estimators. These bounds are used to predict the\nthreshold region of practical estimators. \n\n"}
{"id": "1002.2813", "contents": "Title: Distributed Rate Allocation for Wireless Networks Abstract: This paper develops a distributed algorithm for rate allocation in wireless\nnetworks that achieves the same throughput region as optimal centralized\nalgorithms. This cross-layer algorithm jointly performs medium access control\n(MAC) and physical-layer rate adaptation. The paper establishes that this\nalgorithm is throughput-optimal for general rate regions. In contrast to on-off\nscheduling, rate allocation enables optimal utilization of physical-layer\nschemes by scheduling multiple rate levels. The algorithm is based on local\nqueue-length information, and thus the algorithm is of significant practical\nvalue. The algorithm requires that each link can determine the global\nfeasibility of increasing its current data-rate. In many classes of networks,\nany one link's data-rate primarily impacts its neighbors and this impact decays\nwith distance. Hence, local exchanges can provide the information needed to\ndetermine feasibility. Along these lines, the paper discusses the potential use\nof existing physical-layer control messages to determine feasibility. This can\nbe considered as a technique analogous to carrier sensing in CSMA (Carrier\nSense Multiple Access) networks. An important application of this algorithm is\nin multiple-band multiple-radio throughput-optimal distributed scheduling for\nwhite-space networks. \n\n"}
{"id": "1002.3312", "contents": "Title: Multiuser Scheduling in a Markov-modeled Downlink using Randomly Delayed\n  ARQ Feedback Abstract: We focus on the downlink of a cellular system, which corresponds to the bulk\nof the data transfer in such wireless systems. We address the problem of\nopportunistic multiuser scheduling under imperfect channel state information,\nby exploiting the memory inherent in the channel. In our setting, the channel\nbetween the base station and each user is modeled by a two-state Markov chain\nand the scheduled user sends back an ARQ feedback signal that arrives at the\nscheduler with a random delay that is i.i.d across users and time. The\nscheduler indirectly estimates the channel via accumulated delayed-ARQ feedback\nand uses this information to make scheduling decisions. We formulate a\nthroughput maximization problem as a partially observable Markov decision\nprocess (POMDP). For the case of two users in the system, we show that a greedy\npolicy is sum throughput optimal for any distribution on the ARQ feedback\ndelay. For the case of more than two users, we prove that the greedy policy is\nsuboptimal and demonstrate, via numerical studies, that it has near optimal\nperformance. We show that the greedy policy can be implemented by a simple\nalgorithm that does not require the statistics of the underlying Markov channel\nor the ARQ feedback delay, thus making it robust against errors in system\nparameter estimation. Establishing an equivalence between the two-user system\nand a genie-aided system, we obtain a simple closed form expression for the sum\ncapacity of the Markov-modeled downlink. We further derive inner and outer\nbounds on the capacity region of the Markov-modeled downlink and tighten these\nbounds for special cases of the system parameters. \n\n"}
{"id": "1002.4935", "contents": "Title: Multiarray Signal Processing: Tensor decomposition meets compressed\n  sensing Abstract: We discuss how recently discovered techniques and tools from compressed\nsensing can be used in tensor decompositions, with a view towards modeling\nsignals from multiple arrays of multiple sensors. We show that with appropriate\nbounds on a measure of separation between radiating sources called coherence,\none could always guarantee the existence and uniqueness of a best rank-r\napproximation of the tensor representing the signal. We also deduce a\ncomputationally feasible variant of Kruskal's uniqueness condition, where the\ncoherence appears as a proxy for k-rank. Problems of sparsest recovery with an\ninfinite continuous dictionary, lowest-rank tensor representation, and blind\nsource separation are treated in a uniform fashion. The decomposition of the\nmeasurement tensor leads to simultaneous localization and extraction of\nradiating sources, in an entirely deterministic manner. \n\n"}
{"id": "1003.2606", "contents": "Title: Asymptotically-Optimal, Fast-Decodable, Full-Diversity STBCs Abstract: For a family/sequence of STBCs $\\mathcal{C}_1,\\mathcal{C}_2,\\dots$, with\nincreasing number of transmit antennas $N_i$, with rates $R_i$ complex symbols\nper channel use (cspcu), the asymptotic normalized rate is defined as $\\lim_{i\n\\to \\infty}{\\frac{R_i}{N_i}}$. A family of STBCs is said to be\nasymptotically-good if the asymptotic normalized rate is non-zero, i.e., when\nthe rate scales as a non-zero fraction of the number of transmit antennas, and\nthe family of STBCs is said to be asymptotically-optimal if the asymptotic\nnormalized rate is 1, which is the maximum possible value. In this paper, we\nconstruct a new class of full-diversity STBCs that have the least ML decoding\ncomplexity among all known codes for any number of transmit antennas $N>1$ and\nrates $R>1$ cspcu. For a large set of $\\left(R,N\\right)$ pairs, the new codes\nhave lower ML decoding complexity than the codes already available in the\nliterature. Among the new codes, the class of full-rate codes ($R=N$) are\nasymptotically-optimal and fast-decodable, and for $N>5$ have lower ML decoding\ncomplexity than all other families of asymptotically-optimal, fast-decodable,\nfull-diversity STBCs available in the literature. The construction of the new\nSTBCs is facilitated by the following further contributions of this paper:(i)\nFor $g > 1$, we construct $g$-group ML-decodable codes with rates greater than\none cspcu. These codes are asymptotically-good too. For $g>2$, these are the\nfirst instances of $g$-group ML-decodable codes with rates greater than $1$\ncspcu presented in the literature. (ii) We construct a new class of\nfast-group-decodable codes for all even number of transmit antennas and rates\n$1 < R \\leq 5/4$.(iii) Given a design with full-rank linear dispersion\nmatrices, we show that a full-diversity STBC can be constructed from this\ndesign by encoding the real symbols independently using only regular PAM\nconstellations. \n\n"}
{"id": "1003.2822", "contents": "Title: Innovation Rate Sampling of Pulse Streams with Application to Ultrasound\n  Imaging Abstract: Signals comprised of a stream of short pulses appear in many applications\nincluding bio-imaging and radar. The recent finite rate of innovation\nframework, has paved the way to low rate sampling of such pulses by noticing\nthat only a small number of parameters per unit time are needed to fully\ndescribe these signals. Unfortunately, for high rates of innovation, existing\nsampling schemes are numerically unstable. In this paper we propose a general\nsampling approach which leads to stable recovery even in the presence of many\npulses. We begin by deriving a condition on the sampling kernel which allows\nperfect reconstruction of periodic streams from the minimal number of samples.\nWe then design a compactly supported class of filters, satisfying this\ncondition. The periodic solution is extended to finite and infinite streams,\nand is shown to be numerically stable even for a large number of pulses. High\nnoise robustness is also demonstrated when the delays are sufficiently\nseparated. Finally, we process ultrasound imaging data using our techniques,\nand show that substantial rate reduction with respect to traditional ultrasound\nsampling schemes can be achieved. \n\n"}
{"id": "1004.5132", "contents": "Title: The Two-User Deterministic Interference Channel with Rate-Limited\n  Feedback Abstract: In this paper we study the effect of rate-limited feedback on the sum-rate\ncapacity of the deterministic interference channel. We characterize the\nsum-rate capacity of this channel in the symmetric case and show that having\nfeedback links can increase the sum-rate capacity by at most the rate of the\navailable feedback. Our proof includes a novel upper-bound on the sum-rate\ncapacity and a set of new achievability strategies. \n\n"}
{"id": "1005.0624", "contents": "Title: The Gaussian Many-to-1 Interference Channel with Confidential Messages Abstract: The many-to-one interference channel has received interest by virtue of\nembodying the essence of an interference network while being more tractable\nthan the general K-user interference channel. In this paper, we introduce\ninformation theoretic secrecy to this model and consider the many-to-one\ninterference channel with confidential messages, in which each receiver, in\nparticular, the one subject to interference, is also one from which the\ninterfering users' messages need to be kept secret from. We derive the\nachievable secrecy sum rate for this channel using nested lattice codes, as\nwell as an upper bound on the secrecy sum rate for all possible channel gain\nconfigurations. We identify several nontrivial cases where the gap between the\nupper bound and the achieved secrecy sum rate is only a function of the number\nof the users K, and is uniform over all possible channel gain configurations in\neach case. In addition, we identify the secure degree of freedom for this\nchannel and show it to be equivalent to its degree of freedom, i.e., the\nsecrecy in high SNR comes for free. \n\n"}
{"id": "1005.3093", "contents": "Title: A remark about orthogonal matching pursuit algorithm Abstract: In this note, we investigate the theoretical properties of Orthogonal\nMatching Pursuit (OMP), a class of decoder to recover sparse signal in\ncompressed sensing. In particular, we show that the OMP decoder can give\n$(p,q)$ instance optimality for a large class of encoders with $1\\leq p\\leq q\n\\leq 2$ and $(p,q)\\neq (2,2)$. We also show that, if the encoding matrix is\ndrawn from an appropriate distribution, then the OMP decoder is $(2,2)$\ninstance optimal in probability. \n\n"}
{"id": "1005.4769", "contents": "Title: A Network Coding Approach to Loss Tomography Abstract: Network tomography aims at inferring internal network characteristics based\non measurements at the edge of the network. In loss tomography, in particular,\nthe characteristic of interest is the loss rate of individual links and\nmulticast and/or unicast end-to-end probes are typically used. Independently,\nrecent advances in network coding have shown that there are advantages from\nallowing intermediate nodes to process and combine, in addition to just\nforward, packets. In this paper, we study the problem of loss tomography in\nnetworks with network coding capabilities. We design a framework for estimating\nlink loss rates, which leverages network coding capabilities, and we show that\nit improves several aspects of tomography including the identifiability of\nlinks, the trade-off between estimation accuracy and bandwidth efficiency, and\nthe complexity of probe path selection. We discuss the cases of inferring link\nloss rates in a tree topology and in a general topology. In the latter case,\nthe benefits of our approach are even more pronounced compared to standard\ntechniques, but we also face novel challenges, such as dealing with cycles and\nmultiple paths between sources and receivers. Overall, this work makes the\nconnection between active network tomography and network coding. \n\n"}
{"id": "1006.0355", "contents": "Title: An algebraic approach to information theory Abstract: This work proposes an algebraic model for classical information theory. We\nfirst give an algebraic model of probability theory. Information theoretic\nconstructs are based on this model. In addition to theoretical insights\nprovided by our model one obtains new computational and analytical tools.\nSeveral important theorems of classical probability and information theory are\npresented in the algebraic framework. \n\n"}
{"id": "1006.1667", "contents": "Title: Interference Channel with Generalized Feedback (a.k.a. with source\n  cooperation). Part I: Achievable Region Abstract: An Interference Channel with Generalized Feedback (IFC-GF) is a model for a\nwireless network where several source-destination pairs compete for the same\nchannel resources, and where the sources have the ability to sense the current\nchannel activity. The signal overheard from the channel provides information\nabout the activity of the other users, and thus furnishes the basis for\ncooperation. In this two-part paper we study achievable strategies and outer\nbounds for a general IFC-GF with two source-destination pairs. We then evaluate\nthe proposed regions for the Gaussian channel. Part I: achievable region. We\npropose that the generalized feedback is used to gain knowledge about the\nmessage sent by other user and then exploited in two ways: (a) to {\\em relay}\nthe messages that can be decoded at both destinations--thus realizing the gains\nof beam-forming of a distributed multi-antenna system--and (b) to {\\em hide}\nthe messages that can not be decoded at the non-intended destination--thus\nleveraging the interference \"pre-cancellation\" property of dirty-paper-type\ncoding. We show that our achievable region generalizes several known achievable\nregions for IFC-GF and that it reduces to known achievable regions for some of\nthe channels subsumed by the IFC-GF model. \n\n"}
{"id": "1006.3385", "contents": "Title: A Fixed Precoding Approach to Achieve the Degrees of Freedom in X\n  channel Abstract: This paper aims to provide a fixed precoding scheme to achieve the Degrees of\nFreedom DoF of the generalized ergodic X channel. This is achieved through\nusing the notion of ergodic interference alignment technique. Accordingly, in\nthe proposed method the transmitters do not require to know the full channel\nstate information, while this assumption is the integral part of existing\nmethods. Instead, a finite-rate feed-back channel is adequate to achieve the\nDoF. In other words, it is demonstrated that quantized versions of channel\ngains are adequate to achieve theDOF. To get an insight regarding the\nfunctionality of the proposed method, first we rely on finite field channel\nmodels, and then extend the terminology to more realistic cases, including\ndispersive fading channels in the presence of quantizer. Accordingly, in a\nRayliegh fading environment, it is shown a feedback rate of\n2log(p)+Theta(log(log(p))) can provide the DoF, where $p$ is the total transmit\npower. \n\n"}
{"id": "1006.4046", "contents": "Title: Online Identification and Tracking of Subspaces from Highly Incomplete\n  Information Abstract: This work presents GROUSE (Grassmanian Rank-One Update Subspace Estimation),\nan efficient online algorithm for tracking subspaces from highly incomplete\nobservations. GROUSE requires only basic linear algebraic manipulations at each\niteration, and each subspace update can be performed in linear time in the\ndimension of the subspace. The algorithm is derived by analyzing incremental\ngradient descent on the Grassmannian manifold of subspaces. With a slight\nmodification, GROUSE can also be used as an online incremental algorithm for\nthe matrix completion problem of imputing missing entries of a low-rank matrix.\nGROUSE performs exceptionally well in practice both in tracking subspaces and\nas an online algorithm for matrix completion. \n\n"}
{"id": "1007.0404", "contents": "Title: Quasi-Cyclic Asymptotically Regular LDPC Codes Abstract: Families of \"asymptotically regular\" LDPC block code ensembles can be formed\nby terminating (J,K)-regular protograph-based LDPC convolutional codes. By\nvarying the termination length, we obtain a large selection of LDPC block code\nensembles with varying code rates, minimum distance that grows linearly with\nblock length, and capacity approaching iterative decoding thresholds, despite\nthe fact that the terminated ensembles are almost regular. In this paper, we\ninvestigate the properties of the quasi-cyclic (QC) members of such an\nensemble. We show that an upper bound on the minimum Hamming distance of\nmembers of the QC sub-ensemble can be improved by careful choice of the\ncomponent protographs used in the code construction. Further, we show that the\nupper bound on the minimum distance can be improved by using arrays of\ncirculants in a graph cover of the protograph. \n\n"}
{"id": "1007.0528", "contents": "Title: Binary Independent Component Analysis with OR Mixtures Abstract: Independent component analysis (ICA) is a computational method for separating\na multivariate signal into subcomponents assuming the mutual statistical\nindependence of the non-Gaussian source signals. The classical Independent\nComponents Analysis (ICA) framework usually assumes linear combinations of\nindependent sources over the field of realvalued numbers R. In this paper, we\ninvestigate binary ICA for OR mixtures (bICA), which can find applications in\nmany domains including medical diagnosis, multi-cluster assignment, Internet\ntomography and network resource management. We prove that bICA is uniquely\nidentifiable under the disjunctive generation model, and propose a\ndeterministic iterative algorithm to determine the distribution of the latent\nrandom variables and the mixing matrix. The inverse problem concerning\ninferring the values of latent variables are also considered along with noisy\nmeasurements. We conduct an extensive simulation study to verify the\neffectiveness of the propose algorithm and present examples of real-world\napplications where bICA can be applied. \n\n"}
{"id": "1007.1243", "contents": "Title: New Results on the Capacity of the Gaussian Cognitive Interference\n  Channel Abstract: The capacity of the two-user Gaussian cognitive interference channel, a\nvariation of the classical interference channel where one of the transmitters\nhas knowledge of both messages, is known in several parameter regimes but\nremains unknown in general. In this paper, we consider the following achievable\nscheme: the cognitive transmitter pre-codes its message against the\ninterference created at its intended receiver by the primary user, and the\ncognitive receiver only decodes its intended message, similar to the optimal\nscheme for \"weak interference\"; the primary decoder decodes both messages,\nsimilar to the optimal scheme for \"very strong interference\". Although the\ncognitive message is pre-coded against the primary message, by decoding it, the\nprimary receiver obtains information about its own message, thereby improving\nits rate. We show: (1) that this proposed scheme achieves capacity in what we\nterm the \"primary decodes cognitive\" regime, i.e., a subset of the \"strong\ninterference\" regime that is not included in the \"very strong interference\"\nregime for which capacity was known; (2) that this scheme is within one\nbit/s/Hz, or a factor two, of capacity for a much larger set of parameters,\nthus improving the best known constant gap result; (3) we provide insights into\nthe trade-off between interference pre-coding at the cognitive encoder and\ninterference decoding at the primary receiver based on the analysis of the\napproximate capacity results. \n\n"}
{"id": "1007.3661", "contents": "Title: Non-Binary Polar Codes using Reed-Solomon Codes and Algebraic Geometry\n  Codes Abstract: Polar codes, introduced by Arikan, achieve symmetric capacity of any discrete\nmemoryless channels under low encoding and decoding complexity. Recently,\nnon-binary polar codes have been investigated. In this paper, we calculate\nerror probability of non-binary polar codes constructed on the basis of\nReed-Solomon matrices by numerical simulations. It is confirmed that 4-ary\npolar codes have significantly better performance than binary polar codes on\nbinary-input AWGN channel. We also discuss an interpretation of polar codes in\nterms of algebraic geometry codes, and further show that polar codes using\nHermitian codes have asymptotically good performance. \n\n"}
{"id": "1007.3706", "contents": "Title: Cooperative Convex Optimization in Networked Systems: Augmented\n  Lagrangian Algorithms with Directed Gossip Communication Abstract: We study distributed optimization in networked systems, where nodes cooperate\nto find the optimal quantity of common interest, x=x^\\star. The objective\nfunction of the corresponding optimization problem is the sum of private (known\nonly by a node,) convex, nodes' objectives and each node imposes a private\nconvex constraint on the allowed values of x. We solve this problem for generic\nconnected network topologies with asymmetric random link failures with a novel\ndistributed, decentralized algorithm. We refer to this algorithm as AL-G\n(augmented Lagrangian gossiping,) and to its variants as AL-MG (augmented\nLagrangian multi neighbor gossiping) and AL-BG (augmented Lagrangian broadcast\ngossiping.) The AL-G algorithm is based on the augmented Lagrangian dual\nfunction. Dual variables are updated by the standard method of multipliers, at\na slow time scale. To update the primal variables, we propose a novel,\nGauss-Seidel type, randomized algorithm, at a fast time scale. AL-G uses\nunidirectional gossip communication, only between immediate neighbors in the\nnetwork and is resilient to random link failures. For networks with reliable\ncommunication (i.e., no failures,) the simplified, AL-BG (augmented Lagrangian\nbroadcast gossiping) algorithm reduces communication, computation and data\nstorage cost. We prove convergence for all proposed algorithms and demonstrate\nby simulations the effectiveness on two applications: l_1-regularized logistic\nregression for classification and cooperative spectrum sensing for cognitive\nradio networks. \n\n"}
{"id": "1008.0420", "contents": "Title: Modeling Network Coded TCP Throughput: A Simple Model and its Validation Abstract: We analyze the performance of TCP and TCP with network coding (TCP/NC) in\nlossy wireless networks. We build upon the simple framework introduced by\nPadhye et al. and characterize the throughput behavior of classical TCP as well\nas TCP/NC as a function of erasure rate, round-trip time, maximum window size,\nand duration of the connection. Our analytical results show that network coding\nmasks erasures and losses from TCP, thus preventing TCP's performance\ndegradation in lossy networks, such as wireless networks. It is further seen\nthat TCP/NC has significant throughput gains over TCP. In addition, we simulate\nTCP and TCP/NC to verify our analysis of the average throughput and the window\nevolution. Our analysis and simulation results show very close concordance and\nsupport that TCP/NC is robust against erasures. TCP/NC is not only able to\nincrease its window size faster but also to maintain a large window size\ndespite losses within the network, whereas TCP experiences window closing\nessentially because losses are mistakenly attributed to congestion. \n\n"}
{"id": "1008.0919", "contents": "Title: Compressive Sensing over Graphs Abstract: In this paper, motivated by network inference and tomography applications, we\nstudy the problem of compressive sensing for sparse signal vectors over graphs.\nIn particular, we are interested in recovering sparse vectors representing the\nproperties of the edges from a graph. Unlike existing compressive sensing\nresults, the collective additive measurements we are allowed to take must\nfollow connected paths over the underlying graph. For a sufficiently connected\ngraph with $n$ nodes, it is shown that, using $O(k \\log(n))$ path measurements,\nwe are able to recover any $k$-sparse link vector (with no more than $k$\nnonzero elements), even though the measurements have to follow the graph path\nconstraints. We further show that the computationally efficient $\\ell_1$\nminimization can provide theoretical guarantees for inferring such $k$-sparse\nvectors with $O(k \\log(n))$ path measurements from the graph. \n\n"}
{"id": "1008.1387", "contents": "Title: Codes over Matrix Rings for Space-Time Coded Modulations Abstract: It is known that, for transmission over quasi-static MIMO fading channels\nwith n transmit antennas, diversity can be obtained by using an inner fully\ndiverse space-time block code while coding gain, derived from the determinant\ncriterion, comes from an appropriate outer code. When the inner code has a\ncyclic algebra structure over a number field, as for perfect space-time codes,\nan outer code can be designed via coset coding. More precisely, we take the\nquotient of the algebra by a two-sided ideal which leads to a finite alphabet\nfor the outer code, with a cyclic algebra structure over a finite field or a\nfinite ring. We show that the determinant criterion induces various metrics on\nthe outer code, such as the Hamming and Bachoc distances. When n=2,\npartitioning the 2x2 Golden code by using an ideal above the prime 2 leads to\nconsider codes over either M2(F_2) or M2(F_2[i]), both being non-commutative\nalphabets. Matrix rings of higher dimension, suitable for 3x3 and 4x4 perfect\ncodes, give rise to more complex examples. \n\n"}
{"id": "1008.2581", "contents": "Title: The LASSO risk for gaussian matrices Abstract: We consider the problem of learning a coefficient vector x_0\\in R^N from\nnoisy linear observation y=Ax_0+w \\in R^n. In many contexts (ranging from model\nselection to image processing) it is desirable to construct a sparse estimator\nx'. In this case, a popular approach consists in solving an L1-penalized least\nsquares problem known as the LASSO or Basis Pursuit DeNoising (BPDN).\n  For sequences of matrices A of increasing dimensions, with independent\ngaussian entries, we prove that the normalized risk of the LASSO converges to a\nlimit, and we obtain an explicit expression for this limit. Our result is the\nfirst rigorous derivation of an explicit formula for the asymptotic mean square\nerror of the LASSO for random instances. The proof technique is based on the\nanalysis of AMP, a recently developed efficient algorithm, that is inspired\nfrom graphical models ideas.\n  Simulations on real data matrices suggest that our results can be relevant in\na broad array of practical applications. \n\n"}
{"id": "1008.3295", "contents": "Title: Optimal relay location and power allocation for low SNR broadcast relay\n  channels Abstract: We consider the broadcast relay channel (BRC), where a single source\ntransmits to multiple destinations with the help of a relay, in the limit of a\nlarge bandwidth. We address the problem of optimal relay positioning and power\nallocations at source and relay, to maximize the multicast rate from source to\nall destinations. To solve such a network planning problem, we develop a\nthree-faceted approach based on an underlying information theoretic model,\ncomputational geometric aspects, and network optimization tools. Firstly,\nassuming superposition coding and frequency division between the source and the\nrelay, the information theoretic framework yields a hypergraph model of the\nwideband BRC, which captures the dependency of achievable rate-tuples on the\nnetwork topology. As the relay position varies, so does the set of hyperarcs\nconstituting the hypergraph, rendering the combinatorial nature of optimization\nproblem. We show that the convex hull C of all nodes in the 2-D plane can be\ndivided into disjoint regions corresponding to distinct hyperarcs sets. These\nsets are obtained by superimposing all k-th order Voronoi tessellation of C. We\npropose an easy and efficient algorithm to compute all hyperarc sets, and prove\nthey are polynomially bounded. Using the switched hypergraph approach, we model\nthe original problem as a continuous yet non-convex network optimization\nprogram. Ultimately, availing on the techniques of geometric programming and\n$p$-norm surrogate approximation, we derive a good convex approximation. We\nprovide a detailed characterization of the problem for collinearly located\ndestinations, and then give a generalization for arbitrarily located\ndestinations. Finally, we show strong gains for the optimal relay positioning\ncompared to seemingly interesting positions. \n\n"}
{"id": "1008.3813", "contents": "Title: The Approximate Capacity of the Gaussian N-Relay Diamond Network Abstract: We consider the Gaussian \"diamond\" or parallel relay network, in which a\nsource node transmits a message to a destination node with the help of N\nrelays. Even for the symmetric setting, in which the channel gains to the\nrelays are identical and the channel gains from the relays are identical, the\ncapacity of this channel is unknown in general. The best known capacity\napproximation is up to an additive gap of order N bits and up to a\nmultiplicative gap of order N^2, with both gaps independent of the channel\ngains.\n  In this paper, we approximate the capacity of the symmetric Gaussian N-relay\ndiamond network up to an additive gap of 1.8 bits and up to a multiplicative\ngap of a factor 14. Both gaps are independent of the channel gains and, unlike\nthe best previously known result, are also independent of the number of relays\nN in the network. Achievability is based on bursty amplify-and-forward, showing\nthat this simple scheme is uniformly approximately optimal, both in the\nlow-rate as well as in the high-rate regimes. The upper bound on capacity is\nbased on a careful evaluation of the cut-set bound. We also present\napproximation results for the asymmetric Gaussian N-relay diamond network. In\nparticular, we show that bursty amplify-and-forward combined with optimal relay\nselection achieves a rate within a factor O(log^4(N)) of capacity with\npre-constant in the order notation independent of the channel gains. \n\n"}
{"id": "1009.1128", "contents": "Title: Distributed Basis Pursuit Abstract: We propose a distributed algorithm for solving the optimization problem Basis\nPursuit (BP). BP finds the least L1-norm solution of the underdetermined linear\nsystem Ax = b and is used, for example, in compressed sensing for\nreconstruction. Our algorithm solves BP on a distributed platform such as a\nsensor network, and is designed to minimize the communication between nodes.\nThe algorithm only requires the network to be connected, has no notion of a\ncentral processing node, and no node has access to the entire matrix A at any\ntime. We consider two scenarios in which either the columns or the rows of A\nare distributed among the compute nodes. Our algorithm, named D-ADMM, is a\ndecentralized implementation of the alternating direction method of\nmultipliers. We show through numerical simulation that our algorithm requires\nconsiderably less communications between the nodes than the state-of-the-art\nalgorithms. \n\n"}
{"id": "1009.2528", "contents": "Title: Is Witsenhausen's counterexample a relevant toy? Abstract: This paper answers a question raised by Doyle on the relevance of the\nWitsenhausen counterexample as a toy decentralized control problem. The\nquestion has two sides, the first of which focuses on the lack of an external\nchannel in the counterexample. Using existing results, we argue that the core\ndifficulty in the counterexample is retained even in the presence of such a\nchannel. The second side questions the LQG formulation of the counterexample.\nWe consider alternative formulations and show that the understanding developed\nfor the LQG case guides the investigation for these other cases as well.\nSpecifically, we consider 1) a variation on the original counterexample with\ngeneral, but bounded, noise distributions, and 2) an adversarial extension with\nbounded disturbance and quadratic costs. For each of these formulations, we\nshow that quantization-based nonlinear strategies outperform linear strategies\nby an arbitrarily large factor. Further, these nonlinear strategies also\nperform within a constant factor of the optimal, uniformly over all possible\nparameter choices (for fixed noise distributions in the Bayesian case).\n  Fortuitously, the assumption of bounded noise results in a significant\nsimplification of proofs as compared to those for the LQG formulation.\nTherefore, the results in this paper are also of pedagogical interest. \n\n"}
{"id": "1009.3130", "contents": "Title: Strong Secrecy on the Binary Erasure Wiretap Channel Using Large-Girth\n  LDPC Codes Abstract: For an arbitrary degree distribution pair (DDP), we construct a sequence of\nlow-density parity-check (LDPC) code ensembles with girth growing\nlogarithmically in block-length using Ramanujan graphs. When the DDP has\nminimum left degree at least three, we show using density evolution analysis\nthat the expected bit-error probability of these ensembles, when passed through\na binary erasure channel with erasure probability $\\epsilon$, decays as\n$\\mathcal{O}(\\exp(-c_1 n^{c_2}))$ with the block-length $n$ for positive\nconstants $c_1$ and $c_2$, as long as $\\epsilon$ is lesser than the erasure\nthreshold $\\epsilon_\\mathrm{th}$ of the DDP. This guarantees that the coset\ncoding scheme using the dual sequence provides strong secrecy over the binary\nerasure wiretap channel for erasure probabilities greater than $1 -\n\\epsilon_\\mathrm{th}$. \n\n"}
{"id": "1009.3916", "contents": "Title: Finite-SNR Diversity-Multiplexing Tradeoff via Asymptotic Analysis of\n  Large MIMO Systems Abstract: Diversity-multiplexing tradeoff (DMT) was characterized asymptotically (SNR->\ninfinity) for i.i.d. Rayleigh fading channel by Zheng and Tse [1]. The\nSNR-asymptotic DMT overestimates the finite-SNR one [2]. This paper outlines a\nnumber of additional limitations and difficulties of the DMT framework and\ndiscusses their implications. Using the recent results on the size-asymptotic\n(in the number of antennas) outage capacity distribution, the finite-SNR,\nsize-asymptotic DMT is derived for a broad class of fading distributions. The\nSNR range over which the finite-SNR DMT is accurately approximated by the\nSNR-asymptotic one is characterized. The multiplexing gain definition is shown\nto affect critically this range and thus should be carefully selected, so that\nthe SNR-asymptotic DMT is an accurate approximation at realistic SNR values and\nthus has operational significance to be used as a design criteria. The finite\nSNR diversity gain is shown to decrease with correlation and power imbalance in\na broad class of fading channels, and such an effect is described in a compact,\nclosed form. Complete characterization of the outage probability (or outage\ncapacity) requires not only the finite-SNR DMT, but also the SNR offset, which\nis introduced and investigated as well. This offset, which is not accounted for\nin the DMT framework, is shown to have a significant impact on the outage\nprobability for a broad class of fading channels, especially when the\nmultiplexing gain is small. The analytical results and conclusions are\nvalidated via extensive Monte-Carlo simulations. Overall, the size-asymptotic\nDMT represents a valuable alternative to the SNR-asymptotic one. \n\n"}
{"id": "1009.4128", "contents": "Title: Asymptotic Spectral Efficiency of Multi-antenna Links in Wireless\n  Networks with Limited Tx CSI Abstract: An asymptotic technique is presented for finding the spectral efficiency of\nmulti-antenna links in wireless networks where transmitters have\nChannel-State-Information (CSI) corresponding to their target receiver.\nTransmitters are assumed to transmit independent data streams on a limited\nnumber of channel modes which limits the rank of transmit covariance matrices.\nThis technique is applied to spatially distributed networks to derive an\napproximation for the asymptotic spectral efficiency in the\ninterference-limited regime as a function of link-length, interferer density,\nnumber of antennas per receiver and transmitter, number of transmit streams and\npath-loss exponent. It is found that targeted-receiver CSI, which can be\nacquired with low overhead in duplex systems with reciprocity, can increase\nspectral efficiency several fold, particularly when link lengths are large,\nnode density is high or both. Additionally, the per-link spectral efficiency is\nfound to be a function of the ratio of node density to the number of receiver\nantennas, and that it can often be improved if nodes transmit using fewer\nstreams. These results are validated for finite-sized systems by Monte-Carlo\nsimulation and are asymptotic in the regime where the number of users and\nantennas per receiver approach infinity. \n\n"}
{"id": "1009.6057", "contents": "Title: Network Flows for Functions Abstract: We consider in-network computation of an arbitrary function over an arbitrary\ncommunication network. A network with capacity constraints on the links is\ngiven. Some nodes in the network generate data, e.g., like sensor nodes in a\nsensor network. An arbitrary function of this distributed data is to be\nobtained at a terminal node. The structure of the function is described by a\ngiven computation schema, which in turn is represented by a directed tree. We\ndesign computing and communicating schemes to obtain the function at the\nterminal at the maximum rate. For this, we formulate linear programs to\ndetermine network flows that maximize the computation rate. We then develop\nfast combinatorial primal-dual algorithm to obtain $\\epsilon$-approximate\nsolutions to these linear programs. We then briefly describe extensions of our\ntechniques to the cases of multiple terminals wanting different functions,\nmultiple computation schemas for a function, computation with a given desired\nprecision, and to networks with energy constraints at nodes. \n\n"}
{"id": "1010.0781", "contents": "Title: Transmission Capacity of Spectrum Sharing Ad-hoc Networks with Multiple\n  Antennas Abstract: Two coexisting ad-hoc networks, primary and secondary, are considered, where\neach node of the primary network has a single antenna, while each node of the\nsecondary network is equipped with multiple antennas. Using multiple antennas,\neach secondary transmitter uses some of its spatial transmit degrees of freedom\n(STDOF) to null its interference towards the primary receivers, while each\nsecondary receiver employs interference cancelation using some of its spatial\nreceive degrees of freedom (SRDOF). This paper derives the optimal STDOF for\nnulling and SRDOF for interference cancelation that maximize the scaling of the\ntransmission capacity of the secondary network with respect to the number of\nantennas, when the secondary network operates under an outage constraint at the\nprimary receivers. With a single receive antenna, using a fraction of the total\nSTDOF for nulling at each secondary transmitter maximizes the transmission\ncapacity. With multiple transmit and receive antennas and fixing all but one\nSTDOF for nulling, using a fraction of the total SRDOF to cancel the nearest\ninterferers maximizes the transmission capacity of the secondary network. \n\n"}
{"id": "1010.0933", "contents": "Title: Interference Alignment with Limited Feedback on Two-cell Interfering\n  Two-User MIMO-MAC Abstract: In this paper, we consider a two-cell interfering two-user multiple-input\nmultiple-output multiple access channel (MIMO-MAC) with limited feedback. We\nfirst investigate the multiplexing gain of such channel when users have perfect\nchannel state information at transmitter (CSIT) by exploiting an interference\nalignment scheme. In addition, we propose a feedback framework for the\ninterference alignment in the limited feedback system. On the basis of the\nproposed feedback framework, we analyze the rate gap loss and it is shown that\nin order to keep the same multiplexing gain with the case of perfect CSIT, the\nnumber of feedback bits per receiver scales as $B \\geq\n(M\\!-1\\!)\\!\\log_{2}(\\textsf{SNR})+C$, where $M$ and $C$ denote the number of\ntransmit antennas and a constant, respectively. Throughout the simulation\nresults, it is shown that the sum-rate performance coincides with the derived\nresults. \n\n"}
{"id": "1010.1322", "contents": "Title: A New Upper Bound on the Average Error Exponent for Multiple-Access\n  Channels Abstract: A new lower bound for the average probability or error for a two-user\ndiscrete memoryless (DM) multiple-access channel (MAC) is derived. This bound\nhas a structure very similar to the well-known sphere packing packing bound\nderived by Haroutunian. However, since explicitly imposes independence of the\nusers' input distributions (conditioned on the time-sharing auxiliary variable)\nresults in a tighter sphere-packing exponent in comparison to Haroutunian's.\nAlso, the relationship between average and maximal error probabilities is\nstudied. Finally, by using a known sphere packing bound on the maximal\nprobability of error, a lower bound on the average error probability is\nderived. \n\n"}
{"id": "1010.1973", "contents": "Title: For the Grid and Through the Grid: The Role of Power Line Communications\n  in the Smart Grid Abstract: Is Power Line Communications (PLC) a good candidate for Smart Grid\napplications? The objective of this paper is to address this important\nquestion. To do so we provide an overview of what PLC can deliver today by\nsurveying its history and describing the most recent technological advances in\nthe area. We then address Smart Grid applications as instances of sensor\nnetworking and network control problems and discuss the main conclusion one can\ndraw from the literature on these subjects. The application scenario of PLC\nwithin the Smart Grid is then analyzed in detail. Since a necessary ingredient\nof network planning is modeling, we also discuss two aspects of engineering\nmodeling that relate to our question. The first aspect is modeling the PLC\nchannel through fading models. The second aspect we review is the Smart Grid\ncontrol and traffic modeling problem which allows us to achieve a better\nunderstanding of the communications requirements. Finally, this paper reports\nrecent studies on the electrical and topological properties of a sample power\ndistribution network. Power grid topological studies are very important for PLC\nnetworking as the power grid is not only the information source \\textit{but\nalso} the information delivery system - a unique feature when PLC is used for\nthe Smart Grid. \n\n"}
{"id": "1010.1985", "contents": "Title: Relay Strategies Based on Cross-Determinism for the Broadcast Relay\n  Channel Abstract: We consider a two-user Gaussian multiple-input multiple-output (MIMO)\nbroadcast channel with a common multiple-antenna relay, and a shared digital\n(noiseless) link between the relay and the two destinations. For this channel,\nthis paper introduces an asymptotically sum-capacity-achieving\nquantize-and-forward (QF) relay strategy. Our technique to design an\nasymptotically optimal relay quantizer is based on identifying a\ncross-deterministic relation between the relay observation, the source signal,\nand the destination observation. In a relay channel, an approximate cross\ndeterministic relation corresponds to an approximately deterministic relation,\nwhere the relay observation is to some extent a deterministic function of the\nsource and destination signals. We show that cross determinism can serve as a\nmeasure for quantization penalty. By identifying an analogy between a\ndeterministic broadcast relay channel and a Gaussian MIMO relay channel, we\npropose a three-stage dirty paper coding strategy, along with receiver\nbeamforming and quantization at the relay, to asymptotically achieve an\nextended achievable rate region for the MIMO broadcast channel with a common\nmultiple-antenna relay. \n\n"}
{"id": "1010.2285", "contents": "Title: Information-based complexity, feedback and dynamics in convex\n  programming Abstract: We study the intrinsic limitations of sequential convex optimization through\nthe lens of feedback information theory. In the oracle model of optimization,\nan algorithm queries an {\\em oracle} for noisy information about the unknown\nobjective function, and the goal is to (approximately) minimize every function\nin a given class using as few queries as possible. We show that, in order for a\nfunction to be optimized, the algorithm must be able to accumulate enough\ninformation about the objective. This, in turn, puts limits on the speed of\noptimization under specific assumptions on the oracle and the type of feedback.\nOur techniques are akin to the ones used in statistical literature to obtain\nminimax lower bounds on the risks of estimation procedures; the notable\ndifference is that, unlike in the case of i.i.d. data, a sequential\noptimization algorithm can gather observations in a {\\em controlled} manner, so\nthat the amount of information at each step is allowed to change in time. In\nparticular, we show that optimization algorithms often obey the law of\ndiminishing returns: the signal-to-noise ratio drops as the optimization\nalgorithm approaches the optimum. To underscore the generality of the tools, we\nuse our approach to derive fundamental lower bounds for a certain active\nlearning problem. Overall, the present work connects the intuitive notions of\ninformation in optimization, experimental design, estimation, and active\nlearning to the quantitative notion of Shannon information. \n\n"}
{"id": "1010.2667", "contents": "Title: Virtual Full-Duplex Wireless Communication via Rapid On-Off-Division\n  Duplex Abstract: This paper introduces a novel paradigm for design- ing the physical and\nmedium access control (MAC) layers of mobile ad hoc or peer-to-peer networks\nformed by half-duplex radios. A node equipped with such a radio cannot\nsimultaneously transmit and receive useful signals at the same frequency.\nUnlike in conventional designs, where a node's transmission frames are\nscheduled away from its reception, each node transmits its signal through a\nrandomly generated on-off duplex mask (or signature) over every frame interval,\nand receive a signal through each of its own off-slots. This is called rapid\non-off- division duplex (RODD). Over the period of a single frame, every node\ncan transmit a message to some or all of its peers, and may simultaneously\nreceive a message from each peer. Thus RODD achieves virtual full-duplex\ncommunication using half-duplex radios and can simplify the design of higher\nlayers of a network protocol stack significantly. The throughput of RODD is\nevaluated under some general settings, which is significantly larger than that\nof ALOHA. RODD is especially efficient in case the dominant traffic is\nsimultaneous broadcast from nodes to their one-hop peers, such as in\nspontaneous wireless social networks, emergency situations or on battlefield.\nImportant design issues of peer discovery, distribution of on-off signatures,\nsynchronization and error-control coding are also addressed. \n\n"}
{"id": "1010.2731", "contents": "Title: A Unified Framework for High-Dimensional Analysis of M-Estimators with\n  Decomposable Regularizers Abstract: High-dimensional statistical inference deals with models in which the the\nnumber of parameters p is comparable to or larger than the sample size n. Since\nit is usually impossible to obtain consistent procedures unless\n$p/n\\rightarrow0$, a line of recent work has studied models with various types\nof low-dimensional structure, including sparse vectors, sparse and structured\nmatrices, low-rank matrices and combinations thereof. In such settings, a\ngeneral approach to estimation is to solve a regularized optimization problem,\nwhich combines a loss function measuring how well the model fits the data with\nsome regularization function that encourages the assumed structure. This paper\nprovides a unified framework for establishing consistency and convergence rates\nfor such regularized M-estimators under high-dimensional scaling. We state one\nmain theorem and show how it can be used to re-derive some existing results,\nand also to obtain a number of new results on consistency and convergence\nrates, in both $\\ell_2$-error and related norms. Our analysis also identifies\ntwo key properties of loss and regularization functions, referred to as\nrestricted strong convexity and decomposability, that ensure corresponding\nregularized M-estimators have fast convergence rates and which are optimal in\nmany well-studied cases. \n\n"}
{"id": "1010.2741", "contents": "Title: MIMO Interference Alignment Over Correlated Channels with Imperfect CSI Abstract: Interference alignment (IA), given uncorrelated channel components and\nperfect channel state information, obtains the maximum degrees of freedom in an\ninterference channel. Little is known, however, about how the sum rate of IA\nbehaves at finite transmit power, with imperfect channel state information, or\nantenna correlation. This paper provides an approximate closed-form\nsignal-to-interference-plus-noise-ratio (SINR) expression for IA over\nmultiple-input-multiple-output (MIMO) channels with imperfect channel state\ninformation and transmit antenna correlation. Assuming linear processing at the\ntransmitters and zero-forcing receivers, random matrix theory tools are\nutilized to derive an approximation for the post-processing SINR distribution\nof each stream for each user. Perfect channel knowledge and i.i.d. channel\ncoefficients constitute special cases. This SINR distribution not only allows\neasy calculation of useful performance metrics like sum rate and symbol error\nrate, but also permits a realistic comparison of IA with other transmission\ntechniques. More specifically, IA is compared with spatial multiplexing and\nbeamforming and it is shown that IA may not be optimal for some performance\ncriteria. \n\n"}
{"id": "1010.4548", "contents": "Title: Windowed Decoding of Protograph-based LDPC Convolutional Codes over\n  Erasure Channels Abstract: We consider a windowed decoding scheme for LDPC convolutional codes that is\nbased on the belief-propagation (BP) algorithm. We discuss the advantages of\nthis decoding scheme and identify certain characteristics of LDPC convolutional\ncode ensembles that exhibit good performance with the windowed decoder. We will\nconsider the performance of these ensembles and codes over erasure channels\nwith and without memory. We show that the structure of LDPC convolutional code\nensembles is suitable to obtain performance close to the theoretical limits\nover the memoryless erasure channel, both for the BP decoder and windowed\ndecoding. However, the same structure imposes limitations on the performance\nover erasure channels with memory. \n\n"}
{"id": "1010.4612", "contents": "Title: Recovering Compressively Sampled Signals Using Partial Support\n  Information Abstract: In this paper we study recovery conditions of weighted $\\ell_1$ minimization\nfor signal reconstruction from compressed sensing measurements when partial\nsupport information is available. We show that if at least 50% of the (partial)\nsupport information is accurate, then weighted $\\ell_1$ minimization is stable\nand robust under weaker conditions than the analogous conditions for standard\n$\\ell_1$ minimization. Moreover, weighted $\\ell_1$ minimization provides better\nbounds on the reconstruction error in terms of the measurement noise and the\ncompressibility of the signal to be recovered. We illustrate our results with\nextensive numerical experiments on synthetic data and real audio and video\nsignals. \n\n"}
{"id": "1010.4854", "contents": "Title: Implicit and explicit communication in decentralized control Abstract: There has been substantial progress recently in understanding toy problems of\npurely implicit signaling. These are problems where the source and the channel\nare implicit -- the message is generated endogenously by the system, and the\nplant itself is used as a channel. In this paper, we explore how implicit and\nexplicit communication can be used synergistically to reduce control costs. The\nsetting is an extension of Witsenhausen's counterexample where a rate-limited\nexternal channel connects the two controllers. Using a semi-deterministic\nversion of the problem, we arrive at a binning-based strategy that can\noutperform the best known strategies by an arbitrarily large factor. We also\nshow that our binning-based strategy attains within a constant factor of the\noptimal cost for an asymptotically infinite-length version of the problem\nuniformly over all problem parameters and all rates on the external channel.\nFor the scalar case, although our results yield approximate optimality for each\nfixed rate, we are unable to prove approximately-optimality uniformly over all\nrates. \n\n"}
{"id": "1010.5806", "contents": "Title: Inner and Outer Bounds for the Gaussian Cognitive Interference Channel\n  and New Capacity Results Abstract: The capacity of the Gaussian cognitive interference channel, a variation of\nthe classical two-user interference channel where one of the transmitters\n(referred to as cognitive) has knowledge of both messages, is known in several\nparameter regimes but remains unknown in general. In this paper we provide a\ncomparative overview of this channel model as we proceed through our\ncontributions: we present a new outer bound based on the idea of a broadcast\nchannel with degraded message sets, and another series of outer bounds obtained\nby transforming the cognitive channel into channels with known capacity. We\nspecialize the largest known inner bound derived for the discrete memoryless\nchannel to the Gaussian noise channel and present several simplified schemes\nevaluated for Gaussian inputs in closed form which we use to prove a number of\nresults. These include a new set of capacity results for the a) \"primary\ndecodes cognitive\" regime, a subset of the \"strong interference\" regime that is\nnot included in the \"very strong interference\" regime for which capacity was\nknown, and for the b) \"S-channel\" in which the primary transmitter does not\ninterfere with the cognitive receiver. Next, for a general Gaussian cognitive\ninterference channel, we determine the capacity to within one bit/s/Hz and to\nwithin a factor two regardless of channel parameters, thus establishing rate\nperformance guarantees at high and low SNR, respectively. We also show how\ndifferent simplified transmission schemes achieve a constant gap between inner\nand outer bound for specific channels. Finally, we numerically evaluate and\ncompare the various simplified achievable rate regions and outer bounds in\nparameter regimes where capacity is unknown, leading to further insight on the\ncapacity region of the Gaussian cognitive interference channel. \n\n"}
{"id": "1011.1377", "contents": "Title: Construction of Network Error Correction Codes in Packet Networks Abstract: Recently, network error correction coding (NEC) has been studied extensively.\nSeveral bounds in classical coding theory have been extended to network error\ncorrection coding, especially the Singleton bound. In this paper, following the\nresearch line using the extended global encoding kernels proposed in\n\\cite{zhang-correction}, the refined Singleton bound of NEC can be proved more\nexplicitly. Moreover, we give a constructive proof of the attainability of this\nbound and indicate that the required field size for the existence of network\nmaximum distance separable (MDS) codes can become smaller further. By this\nproof, an algorithm is proposed to construct general linear network error\ncorrection codes including the linear network error correction MDS codes.\nFinally, we study the error correction capability of random linear network\nerror correction coding. Motivated partly by the performance analysis of random\nlinear network coding \\cite{Ho-etc-random}, we evaluate the different failure\nprobabilities defined in this paper in order to analyze the performance of\nrandom linear network error correction coding. Several upper bounds on these\nprobabilities are obtained and they show that these probabilities will approach\nto zero as the size of the base field goes to infinity. Using these upper\nbounds, we slightly improve on the probability mass function of the minimum\ndistance of random linear network error correction codes in\n\\cite{zhang-random}, as well as the upper bound on the field size required for\nthe existence of linear network error correction codes with degradation at most\n$d$. \n\n"}
{"id": "1011.2115", "contents": "Title: Secure Communication over Parallel Relay Channel Abstract: We investigate the problem of secure communication over parallel relay\nchannel in the presence of a passive eavesdropper. We consider a four terminal\nrelay-eavesdropper channel which consists of multiple relay-eavesdropper\nchannels as subchannels. For the discrete memoryless model, we establish outer\nand inner bounds on the rate-equivocation region. The inner bound allows mode\nselection at the relay. For each subchannel, secure transmission is obtained\nthrough one of two coding schemes at the relay: decoding-and-forwarding the\nsource message or confusing the eavesdropper through noise injection. For the\nGaussian memoryless channel, we establish lower and upper bounds on the perfect\nsecrecy rate. Furthermore, we study a special case in which the relay does not\nhear the source and show that under certain conditions the lower and upper\nbounds coincide. The results established for the parallel Gaussian\nrelay-eavesdropper channel are then applied to study the fading\nrelay-eavesdropper channel. Analytical results are illustrated through some\nnumerical examples. \n\n"}
{"id": "1011.2797", "contents": "Title: When are microcircuits well-modeled by maximum entropy methods? Abstract: Describing the collective activity of neural populations is a daunting task:\nthe number of possible patterns grows exponentially with the number of cells,\nresulting in practically unlimited complexity. Recent empirical studies,\nhowever, suggest a vast simplification in how multi-neuron spiking occurs: the\nactivity patterns of some circuits are nearly completely captured by pairwise\ninteractions among neurons. Why are such pairwise models so successful in some\ninstances, but insufficient in others? Here, we study the emergence of\nhigher-order interactions in simple circuits with different architectures and\ninputs. We quantify the impact of higher-order interactions by comparing the\nresponses of mechanistic circuit models vs. \"null\" descriptions in which all\nhigher-than-pairwise correlations have been accounted for by lower order\nstatistics, known as pairwise maximum entropy models.\n  We find that bimodal input signals produce larger deviations from pairwise\npredictions than unimodal inputs for circuits with local and global\nconnectivity. Moreover, recurrent coupling can accentuate these deviations, if\ncoupling strengths are neither too weak nor too strong. A circuit model based\non intracellular recordings from ON parasol retinal ganglion cells shows that a\nbroad range of light signals induce unimodal inputs to spike generators, and\nthat coupling strengths produce weak effects on higher-order interactions. This\nprovides a novel explanation for the success of pairwise models in this system.\nOverall, our findings identify circuit-level mechanisms that produce and fail\nto produce higher-order spiking statistics in neural ensembles. \n\n"}
{"id": "1011.3074", "contents": "Title: Distributed Detection over Gaussian Multiple Access Channels with\n  Constant Modulus Signaling Abstract: A distributed detection scheme where the sensors transmit with constant\nmodulus signals over a Gaussian multiple access channel is considered. The\ndeflection coefficient of the proposed scheme is shown to depend on the\ncharacteristic function of the sensing noise and the error exponent for the\nsystem is derived using large deviation theory. Optimization of the deflection\ncoefficient and error exponent are considered with respect to a transmission\nphase parameter for a variety of sensing noise distributions including\nimpulsive ones. The proposed scheme is also favorably compared with existing\namplify-and-forward and detect-and-forward schemes. The effect of fading is\nshown to be detrimental to the detection performance through a reduction in the\ndeflection coefficient depending on the fading statistics. Simulations\ncorroborate that the deflection coefficient and error exponent can be\neffectively used to optimize the error probability for a wide variety of\nsensing noise distributions. \n\n"}
{"id": "1011.3588", "contents": "Title: Distributed Interference Cancellation in Multiple Access Channels Abstract: In this paper, we consider a Gaussian multiple access channel with multiple\nindependent additive white Gaussian interferences. Each interference is known\nto exactly one transmitter non-causally. The capacity region is characterized\nto within a constant gap regardless of channel parameters. These results are\nbased on a layered modulo-lattice scheme which realizes distributed\ninterference cancellation. \n\n"}
{"id": "1011.6218", "contents": "Title: Coordinated Transmissions to Direct and Relayed Users in Wireless\n  Cellular Systems Abstract: The ideas of wireless network coding at the physical layer promise high\nthroughput gains in wireless systems with relays and multi-way traffic flows.\nThis gain can be ascribed to two principles: (1) joint transmission of multiple\ncommunication flows and (2) usage of \\emph{a priori} information to cancel the\ninterference. In this paper we use these principles to devise new transmission\nschemes in wireless cellular systems that feature both users served directly by\nthe base stations (direct users) and users served through relays (relayed\nusers). We present four different schemes for \\emph{coordinated transmission}\nof uplink and downlink traffic in which one direct and one relayed user are\nserved. These schemes are then used as building blocks in multi-user scenarios,\nwhere we present several schemes for scheduling pairs of users for coordinated\ntransmissions. The optimal scheme involves exhaustive search of the best user\npair in terms of overall rate. We propose several suboptimal scheduling\nschemes, which perform closely to the optimal scheme. The numerical results\nshow a substantial increase in the system--level rate with respect to the\nsystems with non--coordinated transmissions. \n\n"}
{"id": "1101.0764", "contents": "Title: Binary Polar Code Kernels from Code Decompositions Abstract: Code decompositions (a.k.a code nestings) are used to design good binary\npolar code kernels. The proposed kernels are in general non-linear and show a\nbetter rate of polarization under successive cancelation decoding, than the\nones suggested by Korada et al., for the same kernel dimensions. In particular,\nkernels of sizes 14, 15 and 16 are constructed and shown to provide\npolarization rates better than any binary kernel of such sizes. \n\n"}
{"id": "1101.2937", "contents": "Title: A Deterministic Polynomial--Time Algorithm for Constructing a Multicast\n  Coding Scheme for Linear Deterministic Relay Networks Abstract: We propose a new way to construct a multicast coding scheme for linear\ndeterministic relay networks. Our construction can be regarded as a\ngeneralization of the well-known multicast network coding scheme of Jaggi et\nal. to linear deterministic relay networks and is based on the notion of flow\nfor a unicast session that was introduced by the authors in earlier work. We\npresent randomized and deterministic polynomial--time versions of our algorithm\nand show that for a network with $g$ destinations, our deterministic algorithm\ncan achieve the capacity in $\\left\\lceil \\log(g+1)\\right\\rceil $ uses of the\nnetwork. \n\n"}
{"id": "1101.3098", "contents": "Title: Quantum Convex Support Abstract: Convex support, the mean values of a set of random variables, is central in\ninformation theory and statistics. Equally central in quantum information\ntheory are mean values of a set of observables in a finite-dimensional\nC*-algebra A, which we call (quantum) convex support. The convex support can be\nviewed as a projection of the state space of A and it is a projection of a\nspectrahedron.\n  Spectrahedra are increasingly investigated at least since the 1990's boom in\nsemidefinite programming. We recall the geometry of the positive semi-definite\ncone and of the state space. We write a convex duality for general self-dual\nconvex cones. This restricts to projections of state spaces and connects them\nto results on spectrahedra.\n  Really new in this article is an analysis of the face lattice of convex\nsupport by mapping this lattice to a lattice of orthogonal projections, using\nnatural isomorphisms. The result encodes the face lattice of the convex support\ninto a set of projections in A and enables the integration of convex geometry\nwith matrix calculus or algebraic techniques. \n\n"}
{"id": "1101.3285", "contents": "Title: A note on the multiple unicast capacity of directed acyclic networks Abstract: We consider the multiple unicast problem under network coding over directed\nacyclic networks with unit capacity edges. There is a set of n source-terminal\n(s_i - t_i) pairs that wish to communicate at unit rate over this network. The\nconnectivity between the s_i - t_i pairs is quantified by means of a\nconnectivity level vector, [k_1 k_2 ... k_n] such that there exist k_i\nedge-disjoint paths between s_i and t_i. Our main aim is to characterize the\nfeasibility of achieving this for different values of n and [k_1 ... k_n]. For\n3 unicast connections (n = 3), we characterize several achievable and\nunachievable values of the connectivity 3-tuple. In addition, in this work, we\nhave found certain network topologies, and capacity characterizations that are\nuseful in understanding the case of general n. \n\n"}
{"id": "1101.5809", "contents": "Title: The Degrees of Freedom Region and Interference Alignment for the MIMO\n  Interference Channel with Delayed CSI Abstract: The degrees of freedom (DoF) region of the 2-user multiple-antenna or MIMO\n(multiple-input, multiple-output) interference channel (IC) is studied under\nfast fading and the assumption of {\\em delayed} channel state information (CSI)\nwherein all terminals know all (or certain) channel matrices perfectly, but\nwith a delay, and each receiver in addition knows its own incoming channels\ninstantaneously. The general MIMO IC is considered with an arbitrary number of\nantennas at each of the four terminals. Dividing it into several classes\ndepending on the relation between the numbers of antennas at the four\nterminals, the fundamental DoF regions are characterized under the delayed CSI\nassumption for {\\em all} possible values of number of antennas at the four\nterminals. In particular, an outer bound on the DoF region of the general MIMO\nIC is derived. This bound is then shown to be tight for all MIMO ICs by\ndeveloping interference alignment based achievability schemes for each class. A\ncomparison of these DoF regions under the delayed CSI assumption is made with\nthose of the idealistic `perfect CSI' assumption where perfect and\ninstantaneous CSI is available at all terminals on the one hand and with the\nDoF regions of the conservative `no CSI' assumption on the other, where CSI is\navailable at the receivers but not at all at the transmitters. \n\n"}
{"id": "1101.6033", "contents": "Title: Some More Functions That Are Not APN Infinitely Often. The Case of\n  Kasami exponents Abstract: We prove a necessary condition for some polynomials of Kasami degree to be\nAPN over F_{q^n} for large n. \n\n"}
{"id": "1102.1115", "contents": "Title: Adaptive Resource Allocation in Jamming Teams Using Game Theory Abstract: In this work, we study the problem of power allocation and adaptive\nmodulation in teams of decision makers. We consider the special case of two\nteams with each team consisting of two mobile agents. Agents belonging to the\nsame team communicate over wireless ad hoc networks, and they try to split\ntheir available power between the tasks of communication and jamming the nodes\nof the other team. The agents have constraints on their total energy and\ninstantaneous power usage. The cost function adopted is the difference between\nthe rates of erroneously transmitted bits of each team. We model the adaptive\nmodulation problem as a zero-sum matrix game which in turn gives rise to a a\ncontinuous kernel game to handle power control. Based on the communications\nmodel, we present sufficient conditions on the physical parameters of the\nagents for the existence of a pure strategy saddle-point equilibrium (PSSPE). \n\n"}
{"id": "1102.3289", "contents": "Title: Belief propagation for joint sparse recovery Abstract: Compressed sensing (CS) demonstrates that sparse signals can be recovered\nfrom underdetermined linear measurements. We focus on the joint sparse recovery\nproblem where multiple signals share the same common sparse support sets, and\nthey are measured through the same sensing matrix. Leveraging a recent\ninformation theoretic characterization of single signal CS, we formulate the\noptimal minimum mean square error (MMSE) estimation problem, and derive a\nbelief propagation algorithm, its relaxed version, for the joint sparse\nrecovery problem and an approximate message passing algorithm. In addition,\nusing density evolution, we provide a sufficient condition for exact recovery. \n\n"}
{"id": "1102.3289", "contents": "Title: Belief propagation for joint sparse recovery Abstract: Compressed sensing (CS) demonstrates that sparse signals can be recovered\nfrom underdetermined linear measurements. We focus on the joint sparse recovery\nproblem where multiple signals share the same common sparse support sets, and\nthey are measured through the same sensing matrix. Leveraging a recent\ninformation theoretic characterization of single signal CS, we formulate the\noptimal minimum mean square error (MMSE) estimation problem, and derive a\nbelief propagation algorithm, its relaxed version, for the joint sparse\nrecovery problem and an approximate message passing algorithm. In addition,\nusing density evolution, we provide a sufficient condition for exact recovery. \n\n"}
{"id": "1102.3833", "contents": "Title: Aligned Interference Neutralization and the Degrees of Freedom of the 2\n  User Interference Channel with Instantaneous Relay Abstract: It is well known that the classical 2 user Gaussian interference channel has\nonly 1 degree of freedom (DoF), which can be achieved by orthogonal time\ndivision among the 2 users. It is also known that the use of conventional\nrelays, which introduce a processing delay of at least one symbol duration\nrelative to the direct paths between sources and destinations, does not\nincrease the DoF of the 2 user interference channel. The use of instantaneous\nrelays (relays-without-delay) has been explored for the single user\npoint-to-point setting and it is known that such a relay, even with memoryless\nforwarding at the relay, can achieve a higher capacity than conventional\nrelays. In this work, we show that the 2 user interference channel with an\ninstantaneous relay, achieves 3/2 DoF. Thus, an instantaneous relay increases\nnot only the capacity but also the DoF of the 2 user interference channel. The\nachievable scheme is inspired by the aligned interference neutralization scheme\nrecently proposed for the 2X2X2 interference channel. Remarkably the DoF gain\nis achieved with memoryless relays, i.e., with relays that have no memory of\npast received symbols. \n\n"}
{"id": "1102.5138", "contents": "Title: Low-Complexity Near-Optimal Codes for Gaussian Relay Networks Abstract: We consider the problem of information flow over Gaussian relay networks.\nSimilar to the recent work by Avestimehr \\emph{et al.} [1], we propose network\ncodes that achieve up to a constant gap from the capacity of such networks.\nHowever, our proposed codes are also computationally tractable. Our main\ntechnique is to use the codes of Avestimehr \\emph{et al.} as inner codes in a\nconcatenated coding scheme. \n\n"}
{"id": "1103.1178", "contents": "Title: A Simplified Approach to Recovery Conditions for Low Rank Matrices Abstract: Recovering sparse vectors and low-rank matrices from noisy linear\nmeasurements has been the focus of much recent research. Various reconstruction\nalgorithms have been studied, including $\\ell_1$ and nuclear norm minimization\nas well as $\\ell_p$ minimization with $p<1$. These algorithms are known to\nsucceed if certain conditions on the measurement map are satisfied. Proofs of\nrobust recovery for matrices have so far been much more involved than in the\nvector case.\n  In this paper, we show how several robust classes of recovery conditions can\nbe extended from vectors to matrices in a simple and transparent way, leading\nto the best known restricted isometry and nullspace conditions for matrix\nrecovery. Our results rely on the ability to \"vectorize\" matrices through the\nuse of a key singular value inequality. \n\n"}
{"id": "1103.2046", "contents": "Title: Wireless Network Simplification: the Gaussian N-Relay Diamond Network Abstract: We consider the Gaussian N-relay diamond network, where a source wants to\ncommunicate to a destination node through a layer of N-relay nodes. We\ninvestigate the following question: what fraction of the capacity can we\nmaintain by using only k out of the N available relays? We show that\nindependent of the channel configurations and the operating SNR, we can always\nfind a subset of k relays which alone provide a rate (kC/(k+1))-G, where C is\nthe information theoretic cutset upper bound on the capacity of the whole\nnetwork and G is a constant that depends only on N and k (logarithmic in N and\nlinear in k). In particular, for k = 1, this means that half of the capacity of\nany N-relay diamond network can be approximately achieved by routing\ninformation over a single relay. We also show that this fraction is tight:\nthere are configurations of the N-relay diamond network where every subset of k\nrelays alone can at most provide approximately a fraction k/(k+1) of the total\ncapacity. These high-capacity k-relay subnetworks can be also discovered\nefficiently. We propose an algorithm that computes a constant gap approximation\nto the capacity of the Gaussian N-relay diamond network in O(N log N) running\ntime and discovers a high-capacity k-relay subnetwork in O(kN) running time.\n  This result also provides a new approximation to the capacity of the Gaussian\nN-relay diamond network which is hybrid in nature: it has both multiplicative\nand additive gaps. In the intermediate SNR regime, this hybrid approximation is\ntighter than existing purely additive or purely multiplicative approximations\nto the capacity of this network. \n\n"}
{"id": "1103.2289", "contents": "Title: A Token Based Algorithm to Distributed Computation in Sensor Networks Abstract: We consider distributed algorithms for data aggregation and function\ncomputation in sensor networks. The algorithms perform pairwise computations\nalong edges of an underlying communication graph. A token is associated with\neach sensor node, which acts as a transmission permit. Nodes with active tokens\nhave transmission permits; they generate messages at a constant rate and send\neach message to a randomly selected neighbor. By using different strategies to\ncontrol the transmission permits we can obtain tradeoffs between message and\ntime complexity. Gossip corresponds to the case when all nodes have permits all\nthe time. We study algorithms where permits are revoked after transmission and\nrestored upon reception. Examples of such algorithms include Simple-Random\nWalk(SRW), Coalescent-Random-Walk(CRW) and Controlled Flooding(CFLD) and their\nhybrid variants. SRW has a single node permit, which is passed on in the\nnetwork. CRW, initially initially has a permit for each node but these permits\nare revoked gradually. The final result for SRW and CRW resides at a single(or\nfew) random node(s) making a direct comparison with GOSSIP difficult. A hybrid\ntwo-phase algorithm switching from CRW to CFLD at a suitable pre-determined\ntime can be employed to achieve consensus. We show that such hybrid variants\nachieve significant gains in both message and time complexity. The per-node\nmessage complexity for n-node graphs, such as 2D mesh, torii, and Random\ngeometric graphs, scales as $O(polylog(n))$ and the corresponding time\ncomplexity scales as O(n). The reduced per-node message complexity leads to\nreduced energy utilization in sensor networks. \n\n"}
{"id": "1103.4335", "contents": "Title: Diviseurs de la forme 2D-G sans sections et rang de la multiplication\n  dans les corps finis (Divisors of the form 2D-G without sections and bilinear\n  complexity of multiplication in finite fields) Abstract: Let X be an algebraic curve, defined over a perfect field, and G a divisor on\nX. If X has sufficiently many points, we show how to construct a divisor D on X\nsuch that l(2D-G)=0, of essentially any degree such that this is compatible the\nRiemann-Roch theorem. We also generalize this construction to the case of a\nfinite number of constraints, l(k_i.D-G_i)=0, where |k_i|\\leq 2.\n  Such a result was previously claimed by Shparlinski-Tsfasman-Vladut, in\nrelation with the Chudnovsky-Chudnovsky method for estimating the bilinear\ncomplexity of the multiplication in finite fields based on interpolation on\ncurves; unfortunately, as noted by Cascudo et al., their proof was flawed. So\nour work fixes the proof of Shparlinski-Tsfasman-Vladut and shows that their\nestimate m_q\\leq 2(1+1/(A(q)-1)) holds, at least when A(q)\\geq 5. We also fix a\nstatement of Ballet that suffers from the same problem, and then we point out a\nfew other possible applications. \n\n"}
{"id": "1104.0954", "contents": "Title: Multiple Unicast Capacity of 2-Source 2-Sink Networks Abstract: We study the sum capacity of multiple unicasts in wired and wireless multihop\nnetworks. With 2 source nodes and 2 sink nodes, there are a total of 4\nindependent unicast sessions (messages), one from each source to each sink node\n(this setting is also known as an X network). For wired networks with arbitrary\nconnectivity, the sum capacity is achieved simply by routing. For wireless\nnetworks, we explore the degrees of freedom (DoF) of multihop X networks with a\nlayered structure, allowing arbitrary number of hops, and arbitrary\nconnectivity within each hop. For the case when there are no more than two\nrelay nodes in each layer, the DoF can only take values 1, 4/3, 3/2 or 2, based\non the connectivity of the network, for almost all values of channel\ncoefficients. When there are arbitrary number of relays in each layer, the DoF\ncan also take the value 5/3 . Achievability schemes incorporate linear\nforwarding, interference alignment and aligned interference neutralization\nprinciples. Information theoretic converse arguments specialized for the\nconnectivity of the network are constructed based on the intuition from linear\ndimension counting arguments. \n\n"}
{"id": "1104.5456", "contents": "Title: Interference Alignment at Finite SNR for Time-Invariant Channels Abstract: An achievable rate region, based on lattice interference alignment, is\nderived for a class of time-invariant Gaussian interference channels with more\nthan two users. The result is established via a new coding theorem for the\ntwo-user Gaussian multiple-access channel where both users use a single linear\ncode. The class of interference channels treated is such that all interference\nchannel gains are rational. For this class of interference channels, beyond\nrecovering the known results on the degrees of freedom, an explicit rate region\nis derived for finite signal-to-noise ratios, shedding light on the nature of\npreviously established asymptotic results. \n\n"}
{"id": "1105.2283", "contents": "Title: The Deterministic Sum Capacity of a Multiple Access Channel Interfering\n  with a Point to Point Link Abstract: In this paper, we use the linear deterministic approximation model to study a\ntwo user multiple access channel mutually interfering with a point to point\nlink, which represents a basic setup of a cellular system. We derive outer\nbounds on the achievable sum rate and construct coding schemes achieving the\nouter bounds. For a large parameter range, the sum capacity is identical to the\nsum capacity of the interference channel obtained by silencing the weaker user\nin the multiple access channel. For other interference configurations, the sum\nrate can be increased using interference alignment, which exploits the channel\ngain difference of the users in the multiple access channel. From these\nresults, lower bounds on the generalized degrees of freedom for the Gaussian\ncounterpart are derived. \n\n"}
{"id": "1105.3879", "contents": "Title: Non-Malleable Codes from the Wire-Tap Channel Abstract: Recently, Dziembowski et al. introduced the notion of non-malleable codes\n(NMC), inspired from the notion of non-malleability in cryptography and the\nwork of Gennaro et al. in 2004 on tamper proof security. Informally, when using\nNMC, if an attacker modifies a codeword, decoding this modified codeword will\nreturn either the original message or a completely unrelated value.\n  The definition of NMC is related to a family of modifications authorized to\nthe attacker. In their paper, Dziembowski et al. propose a construction valid\nfor the family of all bit-wise independent functions.\n  In this article, we study the link between the second version of the Wire-Tap\n(WT) Channel, introduced by Ozarow and Wyner in 1984, and NMC. Using\ncoset-coding, we describe a new construction for NMC w.r.t. a subset of the\nfamily of bit-wise independent functions. Our scheme is easier to build and\nmore efficient than the one proposed by Dziembowski et al. \n\n"}
{"id": "1105.5306", "contents": "Title: On the Generalized Degrees of Freedom of the K-user Symmetric MIMO\n  Gaussian Interference Channel Abstract: The K-user symmetric multiple input multiple output (MIMO) Gaussian\ninterference channel (IC) where each transmitter has M antennas and each\nreceiver has N antennas is studied from a generalized degrees of freedom (GDOF)\nperspective. An inner bound on the GDOF is derived using a combination of\ntechniques such as treating interference as noise, zero forcing (ZF) at the\nreceivers, interference alignment (IA), and extending the Han-Kobayashi (HK)\nscheme to K users, as a function of the number of antennas and the log (INR) /\nlog (SNR) level. Three outer bounds are derived, under different assumptions of\ncooperation and providing side information to receivers. The novelty in the\nderivation lies in the careful selection of side information, which results in\nthe cancellation of the negative differential entropy terms containing signal\ncomponents, leading to a tractable outer bound. The overall outer bound is\nobtained by taking the minimum of the three outer bounds. The derived bounds\nare simplified for the MIMO Gaussian symmetric IC to obtain outer bounds on the\ngeneralized degrees of freedom (GDOF). Several interesting conclusions are\ndrawn from the derived bounds. For example, when K > N/M + 1, a combination of\nthe HK and IA schemes performs the best among the schemes considered. When N/M\n< K <= N/M + 1, the HK-scheme outperforms other schemes and is shown to be GDOF\noptimal. In addition, when the SNR and INR are at the same level, ZF-receiving\nand the HK-scheme have the same GDOF performance. It is also shown that many of\nthe existing results on the GDOF of the Gaussian IC can be obtained as special\ncases of the bounds, e.g., by setting K=2 or the number of antennas at each\nuser to 1. \n\n"}
{"id": "1105.6368", "contents": "Title: Message-Passing Estimation from Quantized Samples Abstract: Estimation of a vector from quantized linear measurements is a common problem\nfor which simple linear techniques are suboptimal -- sometimes greatly so. This\npaper develops generalized approximate message passing (GAMP) algorithms for\nminimum mean-squared error estimation of a random vector from quantized linear\nmeasurements, notably allowing the linear expansion to be overcomplete or\nundercomplete and the scalar quantization to be regular or non-regular. GAMP is\na recently-developed class of algorithms that uses Gaussian approximations in\nbelief propagation and allows arbitrary separable input and output channels.\nScalar quantization of measurements is incorporated into the output channel\nformalism, leading to the first tractable and effective method for\nhigh-dimensional estimation problems involving non-regular scalar quantization.\nNon-regular quantization is empirically demonstrated to greatly improve\nrate-distortion performance in some problems with oversampling or with\nundersampling combined with a sparsity-inducing prior. Under the assumption of\na Gaussian measurement matrix with i.i.d. entries, the asymptotic error\nperformance of GAMP can be accurately predicted and tracked through the state\nevolution formalism. We additionally use state evolution to design MSE-optimal\nscalar quantizers for GAMP signal reconstruction and empirically demonstrate\nthe superior error performance of the resulting quantizers. \n\n"}
{"id": "1106.1474", "contents": "Title: Simple Bounds for Recovering Low-complexity Models Abstract: This note presents a unified analysis of the recovery of simple objects from\nrandom linear measurements. When the linear functionals are Gaussian, we show\nthat an s-sparse vector in R^n can be efficiently recovered from 2s log n\nmeasurements with high probability and a rank r, n by n matrix can be\nefficiently recovered from r(6n-5r) with high probability. For sparse vectors,\nthis is within an additive factor of the best known nonasymptotic bounds. For\nlow-rank matrices, this matches the best known bounds. We present a parallel\nanalysis for block sparse vectors obtaining similarly tight bounds. In the case\nof sparse and block sparse signals, we additionally demonstrate that our bounds\nare only slightly weakened when the measurement map is a random sign matrix.\nOur results are based on analyzing a particular dual point which certifies\noptimality conditions of the respective convex programming problem. Our\ncalculations rely only on standard large deviation inequalities and our\nanalysis is self-contained. \n\n"}
{"id": "1106.3373", "contents": "Title: Perturbation Analysis of Orthogonal Matching Pursuit Abstract: Orthogonal Matching Pursuit (OMP) is a canonical greedy pursuit algorithm for\nsparse approximation. Previous studies of OMP have mainly considered the exact\nrecovery of a sparse signal $\\bm x$ through $\\bm \\Phi$ and $\\bm y=\\bm \\Phi \\bm\nx$, where $\\bm \\Phi$ is a matrix with more columns than rows. In this paper,\nbased on Restricted Isometry Property (RIP), the performance of OMP is analyzed\nunder general perturbations, which means both $\\bm y$ and $\\bm \\Phi$ are\nperturbed. Though exact recovery of an almost sparse signal $\\bm x$ is no\nlonger feasible, the main contribution reveals that the exact recovery of the\nlocations of $k$ largest magnitude entries of $\\bm x$ can be guaranteed under\nreasonable conditions. The error between $\\bm x$ and solution of OMP is also\nestimated. It is also demonstrated that the sufficient condition is rather\ntight by constructing an example. When $\\bm x$ is strong-decaying, it is proved\nthat the sufficient conditions can be relaxed, and the locations can even be\nrecovered in the order of the entries' magnitude. \n\n"}
{"id": "1106.5648", "contents": "Title: Joint LDPC and Physical-layer Network Coding for Asynchronous\n  Bi-directional Relaying Abstract: In practical asynchronous bi-directional relaying, symbols transmitted by two\nsources cannot arrive at the relay with perfect frame and symbol alignments and\nthe asynchronous multiple-access channel (MAC) should be seriously considered.\nRecently, Lu et al. proposed a Tanner-graph representation of the\nsymbol-asynchronous MAC with rectangular-pulse shaping and further developed\nthe message-passing algorithm for optimal decoding of the symbol-asynchronous\nphysical-layer network coding. In this paper, we present a general channel\nmodel for the asynchronous MAC with arbitrary pulse-shaping. Then, the Bahl,\nCocke, Jelinek, and Raviv (BCJR) algorithm is developed for optimal decoding of\nthe asynchronous MAC channel. For Low-Density Parity-Check (LDPC)-coded BPSK\nsignalling over the symbol-asynchronous MAC, we present a formal log-domain\ngeneralized sum-product-algorithm (Log-G-SPA) for efficient decoding.\nFurthermore, we propose to use cyclic codes for combating the\nframe-asynchronism and the resolution of the relative delay inherent in this\napproach can be achieved by employing the simple cyclic-redundancy-check (CRC)\ncoding technique. Simulation results demonstrate the effectiveness of the\nproposed approach. \n\n"}
{"id": "1106.5742", "contents": "Title: Wireless Network Coding with Local Network Views: Coded Layer Scheduling Abstract: One of the fundamental challenges in the design of distributed wireless\nnetworks is the large dynamic range of network state. Since continuous tracking\nof global network state at all nodes is practically impossible, nodes can only\nacquire limited local views of the whole network to design their transmission\nstrategies. In this paper, we study multi-layer wireless networks and assume\nthat each node has only a limited knowledge, namely 1-local view, where each\nS-D pair has enough information to perform optimally when other pairs do not\ninterfere, along with connectivity information for rest of the network. We\ninvestigate the information-theoretic limits of communication with such limited\nknowledge at the nodes. We develop a novel transmission strategy, namely Coded\nLayer Scheduling, that solely relies on 1-local view at the nodes and\nincorporates three different techniques: (1) per layer interference avoidance,\n(2) repetition coding to allow overhearing of the interference, and (3) network\ncoding to allow interference neutralization. We show that our proposed scheme\ncan provide a significant throughput gain compared with the conventional\ninterference avoidance strategies. Furthermore, we show that our strategy\nmaximizes the achievable normalized sum-rate for some classes of networks,\nhence, characterizing the normalized sum-capacity of those networks with\n1-local view. \n\n"}
{"id": "1106.6323", "contents": "Title: The Diversity Multiplexing Tradeoff of the MIMO Half-Duplex Relay\n  Channel Abstract: The fundamental diversity-multiplexing tradeoff of the three-node,\nmulti-input, multi-output (MIMO), quasi-static, Rayleigh faded, half-duplex\nrelay channel is characterized for an arbitrary number of antennas at each node\nand in which opportunistic scheduling (or dynamic operation) of the relay is\nallowed, i.e., the relay can switch between receive and transmit modes at a\nchannel dependent time. In this most general case, the diversity-multiplexing\ntradeoff is characterized as a solution to a simple, two-variable optimization\nproblem. This problem is then solved in closed form for special classes of\nchannels defined by certain restrictions on the numbers of antennas at the\nthree nodes. The key mathematical tool developed here that enables the explicit\ncharacterization of the diversity-multiplexing tradeoff is the joint eigenvalue\ndistribution of three mutually correlated random Wishart matrices. Previously,\nwithout actually characterizing the diversity-multiplexing tradeoff, the\noptimality in this tradeoff metric of the dynamic compress-and-forward (DCF)\nprotocol based on the classical compress-and-forward scheme of Cover and El\nGamal was shown by Yuksel and Erkip. However, this scheme requires global\nchannel state information (CSI) at the relay. In this work, the so-called\nquantize-map and forward (QMF) coding scheme due to Avestimehr {\\em et} {\\em\nal} is adopted as the achievability scheme with the added benefit that it\nachieves optimal tradeoff with only the knowledge of the (channel dependent)\nswitching time at the relay node. Moreover, in special classes of the MIMO\nhalf-duplex relay channel, the optimal tradeoff is shown to be attainable even\nwithout this knowledge. Such a result was previously known only for the\nhalf-duplex relay channel with a single antenna at each node, also via the QMF\nscheme. \n\n"}
{"id": "1107.2499", "contents": "Title: Improving Energy Efficiency Through Multimode Transmission in the\n  Downlink MIMO Systems Abstract: Adaptively adjusting system parameters including bandwidth, transmit power\nand mode to maximize the \"Bits per-Joule\" energy efficiency (BPJ-EE) in the\ndownlink MIMO systems with imperfect channel state information at the\ntransmitter (CSIT) is considered in this paper. By mode we refer to choice of\ntransmission schemes i.e. singular value decomposition (SVD) or block\ndiagonalization (BD), active transmit/receive antenna number and active user\nnumber. We derive optimal bandwidth and transmit power for each dedicated mode\nat first. During the derivation, accurate capacity estimation strategies are\nproposed to cope with the imperfect CSIT caused capacity prediction problem.\nThen, an ergodic capacity based mode switching strategy is proposed to further\nimprove the BPJ-EE, which provides insights on the preferred mode under given\nscenarios. Mode switching compromises different power parts, exploits the\ntradeoff between the multiplexing gain and the imperfect CSIT caused inter-user\ninterference, improves the BPJ-EE significantly. \n\n"}
{"id": "1107.4142", "contents": "Title: Asymptotics of the Invariant Measure in Mean Field Models with Jumps Abstract: We consider the asymptotics of the invariant measure for the process of the\nempirical spatial distribution of $N$ coupled Markov chains in the limit of a\nlarge number of chains. Each chain reflects the stochastic evolution of one\nparticle. The chains are coupled through the dependence of the transition rates\non this spatial distribution of particles in the various states. Our model is a\ncaricature for medium access interactions in wireless local area networks. It\nis also applicable to the study of spread of epidemics in a network. The\nlimiting process satisfies a deterministic ordinary differential equation\ncalled the McKean-Vlasov equation. When this differential equation has a unique\nglobally asymptotically stable equilibrium, the spatial distribution\nasymptotically concentrates on this equilibrium. More generally, its limit\npoints are supported on a subset of the $\\omega$-limit sets of the\nMcKean-Vlasov equation. Using a control-theoretic approach, we examine the\nquestion of large deviations of the invariant measure from this limit. \n\n"}
{"id": "1107.4600", "contents": "Title: On the Capacity of the Interference Channel with a Cognitive Relay Abstract: The InterFerence Channel with a Cognitive Relay (IFC-CR) consists of the\nclassical interference channel with two independent source-destination pairs\nwhose communication is aided by an additional node, referred to as the\ncognitive relay, that has a priori knowledge of both sources' messages. This a\npriori message knowledge is termed cognition and idealizes the relay learning\nthe messages of the two sources from their transmissions over a wireless\nchannel. This paper presents new inner and outer bounds for the capacity region\nof the general memoryless IFC-CR that are shown to be tight for a certain class\nof channels. The new outer bound follows from arguments originally devised for\nbroadcast channels among which Sato's observation that the capacity region of\nchannels with non-cooperative receivers only depends on the channel output\nconditional marginal distributions. The new inner bound is shown to include all\npreviously proposed coding schemes and it is thus the largest known achievable\nrate region to date. The new inner and outer bounds coincide for a subset of\nchannel satisfying a strong interference condition. For these channels there is\nno loss in optimality if both destinations decode both messages. This result\nparallels analogous results for the classical IFC and for the cognitive IFC and\nis the first known capacity result for the general IFC-CR. Numerical\nevaluations of the proposed inner and outer bounds are presented for the\nGaussian noise case. \n\n"}
{"id": "1107.4705", "contents": "Title: A unified graphical approach to random coding for multi-terminal\n  networks Abstract: A unified approach to the derivation of rate regions for single-hop\nmemoryless networks is presented. A general transmission scheme for any\nmemoryless, single-hop, k-user channel with or without common information, is\ndefined through two steps. The first step is user virtualization: each user is\ndivided into multiple virtual sub-users according to a chosen rate-splitting\nstrategy which preserves the rates of the original messages. This results in an\nenhanced channel with a possibly larger number of users for which more coding\npossibilities are available. Moreover, user virtualization provides a simple\nmechanism to encode common messages to any subset of users. Following user\nvirtualization, the message of each user in the enhanced model is coded using a\nchosen combination of coded time-sharing, superposition coding and joint\nbinning. A graph is used to represent the chosen coding strategies: nodes in\nthe graph represent codewords while edges represent coding operations. This\ngraph is used to construct a graphical Markov model which illustrates the\nstatistical dependency among codewords that can be introduced by the\nsuperposition coding or joint binning. Using this statistical representation of\nthe overall codebook distribution, the error probability of the code is shown\nto vanish via a unified analysis. The rate bounds that define the achievable\nrate region are obtained by linking the error analysis to the properties of the\ngraphical Markov model. This proposed framework makes it possible to\nnumerically obtain an achievable rate region by specifying a user\nvirtualization strategy and describing a set of coding operations. The largest\nachievable rate region can be obtained by considering all the possible\nrate-splitting strategies and taking the union over all the possible ways to\nsuperimpose or bin codewords. \n\n"}
{"id": "1108.3883", "contents": "Title: Exact Regenerating Codes for Byzantine Fault Tolerance in Distributed\n  Storage Abstract: Due to the use of commodity software and hardware, crash-stop and Byzantine\nfailures are likely to be more prevalent in today's large-scale distributed\nstorage systems. Regenerating codes have been shown to be a more efficient way\nto disperse information across multiple nodes and recover crash-stop failures\nin the literature. In this paper, we present the design of regeneration codes\nin conjunction with integrity check that allows exact regeneration of failed\nnodes and data reconstruction in presence of Byzantine failures. A progressive\ndecoding mechanism is incorporated in both procedures to leverage computation\nperformed thus far. The fault-tolerance and security properties of the schemes\nare also analyzed. \n\n"}
{"id": "1108.4257", "contents": "Title: Capacity Analysis of Linear Operator Channels over Finite Fields Abstract: Motivated by communication through a network employing linear network coding,\ncapacities of linear operator channels (LOCs) with arbitrarily distributed\ntransfer matrices over finite fields are studied. Both the Shannon capacity $C$\nand the subspace coding capacity $C_{\\text{SS}}$ are analyzed. By establishing\nand comparing lower bounds on $C$ and upper bounds on $C_{\\text{SS}}$, various\nnecessary conditions and sufficient conditions such that $C=C_{\\text{SS}}$ are\nobtained. A new class of LOCs such that $C=C_{\\text{SS}}$ is identified, which\nincludes LOCs with uniform-given-rank transfer matrices as special cases. It is\nalso demonstrated that $C_{\\text{SS}}$ is strictly less than $C$ for a broad\nclass of LOCs. In general, an optimal subspace coding scheme is difficult to\nfind because it requires to solve the maximization of a non-concave function.\nHowever, for a LOC with a unique subspace degradation, $C_{\\text{SS}}$ can be\nobtained by solving a convex optimization problem over rank distribution.\nClasses of LOCs with a unique subspace degradation are characterized. Since\nLOCs with uniform-given-rank transfer matrices have unique subspace\ndegradations, some existing results on LOCs with uniform-given-rank transfer\nmatrices are explained from a more general way. \n\n"}
{"id": "1108.4753", "contents": "Title: Differential properties of functions x -> x^{2^t-1} -- extended version Abstract: We provide an extensive study of the differential properties of the functions\n$x\\mapsto x^{2^t-1}$ over $\\F$, for $2 \\leq t \\leq n-1$. We notably show that\nthe differential spectra of these functions are determined by the number of\nroots of the linear polynomials $x^{2^t}+bx^2+(b+1)x$ where $b$ varies in\n$\\F$.We prove a strong relationship between the differential spectra of\n$x\\mapsto x^{2^t-1}$ and $x\\mapsto x^{2^{s}-1}$ for $s= n-t+1$. As a direct\nconsequence, this result enlightens a connection between the differential\nproperties of the cube function and of the inverse function. We also determine\nthe complete differential spectra of $x \\mapsto x^7$ by means of the value of\nsome Kloosterman sums, and of $x \\mapsto x^{2^t-1}$ for $t \\in \\{\\lfloor\nn/2\\rfloor, \\lceil n/2\\rceil+1, n-2\\}$. \n\n"}
{"id": "1109.0318", "contents": "Title: Compressive Matched-Field Processing Abstract: Source localization by matched-field processing (MFP) generally involves\nsolving a number of computationally intensive partial differential equations.\nThis paper introduces a technique that mitigates this computational workload by\n\"compressing\" these computations. Drawing on key concepts from the recently\ndeveloped field of compressed sensing, it shows how a low-dimensional proxy for\nthe Green's function can be constructed by backpropagating a small set of\nrandom receiver vectors. Then, the source can be located by performing a number\nof \"short\" correlations between this proxy and the projection of the recorded\nacoustic data in the compressed space. Numerical experiments in a Pekeris ocean\nwaveguide are presented which demonstrate that this compressed version of MFP\nis as effective as traditional MFP even when the compression is significant.\nThe results are particularly promising in the broadband regime where using as\nfew as two random backpropagations per frequency performs almost as well as the\ntraditional broadband MFP, but with the added benefit of generic applicability.\nThat is, the computationally intensive backpropagations may be computed offline\nindependently from the received signals, and may be reused to locate any source\nwithin the search grid area. \n\n"}
{"id": "1109.5373", "contents": "Title: Degrees of Freedom Region of the MIMO Interference Channel with Output\n  Feedback and Delayed CSIT Abstract: The two-user multiple-input multiple-output (MIMO) interference channel (IC)\nwith arbitrary number of antennas at each terminal is considered and the\ndegrees of freedom (DoF) region is characterized in the presence of noiseless\nchannel output feedback from each receiver to its respective transmitter and\navailability of delayed channel state information at the transmitters (CSIT).\nIt is shown that having output feedback and delayed CSIT can strictly enlarge\nthe DoF region of the MIMO IC when compared to the case in which only delayed\nCSIT is present. The proposed coding schemes that achieve the corresponding DoF\nregion with feedback and delayed CSIT utilize both resources, i.e., feedback\nand delayed CSIT in a non-trivial manner. It is also shown that the DoF region\nwith local feedback and delayed CSIT is equal to the DoF region with global\nfeedback and delayed CSIT, i.e., local feedback and delayed CSIT is equivalent\nto global feedback and delayed CSIT from the perspective of the degrees of\nfreedom region. The converse is proved for a stronger setting in which the\nchannels to the two receivers need not be statistically equivalent. \n\n"}
{"id": "1109.6269", "contents": "Title: Precoder Design for Physical Layer Multicasting Abstract: This paper studies the instantaneous rate maximization and the weighted sum\ndelay minimization problems over a K-user multicast channel, where multiple\nantennas are available at the transmitter as well as at all the receivers.\nMotivated by the degree of freedom optimality and the simplicity offered by\nlinear precoding schemes, we consider the design of linear precoders using the\naforementioned two criteria. We first consider the scenario wherein the linear\nprecoder can be any complex-valued matrix subject to rank and power\nconstraints. We propose cyclic alternating ascent based precoder design\nalgorithms and establish their convergence to respective stationary points.\nSimulation results reveal that our proposed algorithms considerably outperform\nknown competing solutions. We then consider a scenario in which the linear\nprecoder can be formed by selecting and concatenating precoders from a given\nfinite codebook of precoding matrices, subject to rank and power constraints.\nWe show that under this scenario, the instantaneous rate maximization problem\nis equivalent to a robust submodular maximization problem which is strongly NP\nhard. We propose a deterministic approximation algorithm and show that it\nyields a bicriteria approximation. For the weighted sum delay minimization\nproblem we propose a simple deterministic greedy algorithm, which at each step\nentails approximately maximizing a submodular set function subject to multiple\nknapsack constraints, and establish its performance guarantee. \n\n"}
{"id": "1110.5176", "contents": "Title: Demodulating Subsampled Direct Sequence Spread Spectrum Signals using\n  Compressive Signal Processing Abstract: We show that to lower the sampling rate in a spread spectrum communication\nsystem using Direct Sequence Spread Spectrum (DSSS), compressive signal\nprocessing can be applied to demodulate the received signal. This may lead to a\ndecrease in the power consumption or the manufacturing price of wireless\nreceivers using spread spectrum technology. The main novelty of this paper is\nthe discovery that in spread spectrum systems it is possible to apply\ncompressive sensing with a much simpler hardware architecture than in other\nsystems, making the implementation both simpler and more energy efficient. Our\ntheoretical work is exemplified with a numerical experiment using the IEEE\n802.15.4 standard's 2.4 GHz band specification. The numerical results support\nour theoretical findings and indicate that compressive sensing may be used\nsuccessfully in spread spectrum communication systems. The results obtained\nhere may also be applicable in other spread spectrum technologies, such as Code\nDivision Multiple Access (CDMA) systems. \n\n"}
{"id": "1110.6591", "contents": "Title: On some quasigroup cryptographical primitives Abstract: We propose modifications of known quasigroup based stream ciphers. Systems of\northogonal n-ary groupoids are used. \n\n"}
{"id": "1111.0084", "contents": "Title: Lattice codes for the Gaussian relay channel: Decode-and-Forward and\n  Compress-and-Forward Abstract: Lattice codes are known to achieve capacity in the Gaussian point-to-point\nchannel, achieving the same rates as independent, identically distributed\n(i.i.d.) random Gaussian codebooks. Lattice codes are also known to outperform\nrandom codes for certain channel models that are able to exploit their\nlinearity. In this work, we show that lattice codes may be used to achieve the\nsame performance as known i.i.d. Gaussian random coding techniques for the\nGaussian relay channel, and show several examples of how this may be combined\nwith the linearity of lattices codes in multi-source relay networks. In\nparticular, we present a nested lattice list decoding technique, by which,\nlattice codes are shown to achieve the Decode-and-Forward (DF) rate of single\nsource, single destination Gaussian relay channels with one or more relays. We\nnext present two examples of how this DF scheme may be combined with the\nlinearity of lattice codes to achieve new rate regions which for some channel\nconditions outperform analogous known Gaussian random coding techniques in\nmulti-source relay channels. That is, we derive a new achievable rate region\nfor the two-way relay channel with direct links and compare it to existing\nschemes, and derive another achievable rate region for the multiple access\nrelay channel. We furthermore present a lattice Compress-and-Forward (CF)\nscheme for the Gaussian relay channel which exploits a lattice Wyner-Ziv\nbinning scheme and achieves the same rate as the Cover-El Gamal CF rate\nevaluated for Gaussian random codes. These results suggest that\nstructured/lattice codes may be used to mimic, and sometimes outperform, random\nGaussian codes in general Gaussian networks. \n\n"}
{"id": "1111.1788", "contents": "Title: Robust PCA as Bilinear Decomposition with Outlier-Sparsity\n  Regularization Abstract: Principal component analysis (PCA) is widely used for dimensionality\nreduction, with well-documented merits in various applications involving\nhigh-dimensional data, including computer vision, preference measurement, and\nbioinformatics. In this context, the fresh look advocated here permeates\nbenefits from variable selection and compressive sampling, to robustify PCA\nagainst outliers. A least-trimmed squares estimator of a low-rank bilinear\nfactor analysis model is shown closely related to that obtained from an\n$\\ell_0$-(pseudo)norm-regularized criterion encouraging sparsity in a matrix\nexplicitly modeling the outliers. This connection suggests robust PCA schemes\nbased on convex relaxation, which lead naturally to a family of robust\nestimators encompassing Huber's optimal M-class as a special case. Outliers are\nidentified by tuning a regularization parameter, which amounts to controlling\nsparsity of the outlier matrix along the whole robustification path of (group)\nleast-absolute shrinkage and selection operator (Lasso) solutions. Beyond its\nneat ties to robust statistics, the developed outlier-aware PCA framework is\nversatile to accommodate novel and scalable algorithms to: i) track the\nlow-rank signal subspace robustly, as new data are acquired in real time; and\nii) determine principal components robustly in (possibly) infinite-dimensional\nfeature spaces. Synthetic and real data tests corroborate the effectiveness of\nthe proposed robust PCA schemes, when used to identify aberrant responses in\npersonality assessment surveys, as well as unveil communities in social\nnetworks, and intruders from video surveillance data. \n\n"}
{"id": "1111.4575", "contents": "Title: Information Theoretic Exemplification of the Impact of\n  Transmitter-Receiver Cognition on the Channel Capacity Abstract: In this paper, we study, information theoretically, the impact of transmitter\nand or receiver cognition on the channel capacity. The cognition can be\ndescribed by state information, dependent on the channel noise and or input.\nSpecifically, as a new idea, we consider the receiver cognition as a state\ninformation dependent on the noise and we derive a capacity theorem based on\nthe Gaussian version of the Cover-Chiang capacity theorem for two-sided state\ninformation channel. As intuitively expected, the receiver cognition increases\nthe channel capacity and our theorem shows this increase quantitatively. Also,\nour capacity theorem includes the famous Costa theorem as its special cases. \n\n"}
{"id": "1111.5241", "contents": "Title: Refinement of Gini-Means Inequalities and Connections with Divergence\n  Measures Abstract: In 1938, Gini studied a mean having two parameters. Later, many authors\nstudied properties of this mean. It contains as particular cases the famous\nmeans such as harmonic, geometric, arithmetic, etc. Also it contains, the power\nmean of order r and Lehmer mean as particular cases. In this paper we have\nconsidered inequalities arising due to Gini-Mean and Heron's mean, and improved\nthem based on the results recently studied by the author (Taneja, 2011). \n\n"}
{"id": "1111.5900", "contents": "Title: Cubature formulas and discrete fourier transform on compact manifolds Abstract: The goal of the paper is to describe essentially optimal cubature formulas on\ncompact Riemannian manifolds which are exact on spaces of band- limited\nfunctions. \n\n"}
{"id": "1112.0674", "contents": "Title: Analytical Evaluation of Fractional Frequency Reuse for Heterogeneous\n  Cellular Networks Abstract: Interference management techniques are critical to the performance of\nheterogeneous cellular networks, which will have dense and overlapping coverage\nareas, and experience high levels of interference. Fractional frequency reuse\n(FFR) is an attractive interference management technique due to its low\ncomplexity and overhead, and significant coverage improvement for\nlow-percentile (cell-edge) users. Instead of relying on system simulations\nbased on deterministic access point locations, this paper instead proposes an\nanalytical model for evaluating Strict FFR and Soft Frequency Reuse (SFR)\ndeployments based on the spatial Poisson point process. Our results both\ncapture the non-uniformity of heterogeneous deployments and produce tractable\nexpressions which can be used for system design with Strict FFR and SFR. We\nobserve that the use of Strict FFR bands reserved for the users of each tier\nwith the lowest average SINR provides the highest gains in terms of coverage\nand rate, while the use of SFR allows for more efficient use of shared spectrum\nbetween the tiers, while still mitigating much of the interference.\nAdditionally, in the context of multi-tier networks with closed access in some\ntiers, the proposed framework shows the impact of cross-tier interference on\nclosed access FFR, and informs the selection of key FFR parameters in open\naccess. \n\n"}
{"id": "1112.1770", "contents": "Title: Polar codes for the m-user multiple access channels Abstract: Polar codes are constructed for m-user multiple access channels (MAC) whose\ninput alphabet size is a prime number. The block error probability under\nsuccessive cancelation decoding decays exponentially with the square root of\nthe block length. Although the sum capacity is achieved by this coding scheme,\nsome points in the symmetric capacity region may not be achieved. In the case\nwhere the channel is a combination of linear channels, we provide a necessary\nand sufficient condition characterizing the channels whose symmetric capacity\nregion is preserved upon the polarization process. We also provide a sufficient\ncondition for having a total loss in the dominant face. \n\n"}
{"id": "1112.2493", "contents": "Title: Symbolic transfer entropy rate is equal to transfer entropy rate for\n  bivariate finite-alphabet stationary ergodic Markov processes Abstract: Transfer entropy is a measure of the magnitude and the direction of\ninformation flow between jointly distributed stochastic processes. In recent\nyears, its permutation analogues are considered in the literature to estimate\nthe transfer entropy by counting the number of occurrences of orderings of\nvalues, not the values themselves. It has been suggested that the method of\npermutation is easy to implement, computationally low cost and robust to noise\nwhen applying to real world time series data. In this paper, we initiate a\ntheoretical treatment of the corresponding rates. In particular, we consider\nthe transfer entropy rate and its permutation analogue, the symbolic transfer\nentropy rate, and show that they are equal for any bivariate finite-alphabet\nstationary ergodic Markov process. This result is an illustration of the\nduality method introduced in [T. Haruna and K. Nakajima, Physica D 240, 1370\n(2011)]. We also discuss the relationship among the transfer entropy rate, the\ntime-delayed mutual information rate and their permutation analogues. \n\n"}
{"id": "1112.2690", "contents": "Title: Multilevel Coding Schemes for Compute-and-Forward with Flexible Decoding Abstract: We consider the design of coding schemes for the wireless two-way relaying\nchannel when there is no channel state information at the transmitter. In the\nspirit of the compute and forward paradigm, we present a multilevel coding\nscheme that permits computation (or, decoding) of a class of functions at the\nrelay. The function to be computed (or, decoded) is then chosen depending on\nthe channel realization. We define such a class of functions which can be\ndecoded at the relay using the proposed coding scheme and derive rates that are\nuniversally achievable over a set of channel gains when this class of functions\nis used at the relay. We develop our framework with general modulation formats\nin mind, but numerical results are presented for the case where each node\ntransmits using the QPSK constellation. Numerical results with QPSK show that\nthe flexibility afforded by our proposed scheme results in substantially higher\nrates than those achievable by always using a fixed function or by adapting the\nfunction at the relay but coding over GF(4). \n\n"}
{"id": "1112.3471", "contents": "Title: A Nonstochastic Information Theory for Communication and State\n  Estimation Abstract: In communications, unknown variables are usually modelled as random\nvariables, and concepts such as independence, entropy and information are\ndefined in terms of the underlying probability distributions. In contrast,\ncontrol theory often treats uncertainties and disturbances as bounded unknowns\nhaving no statistical structure. The area of networked control combines both\nfields, raising the question of whether it is possible to construct meaningful\nanalogues of stochastic concepts such as independence, Markovness, entropy and\ninformation without assuming a probability space. This paper introduces a\nframework for doing so, leading to the construction of a maximin information\nfunctional for nonstochastic variables. It is shown that the largest maximin\ninformation rate through a memoryless, error-prone channel in this framework\ncoincides with the block-coding zero-error capacity of the channel. Maximin\ninformation is then used to derive tight conditions for uniformly estimating\nthe state of a linear time-invariant system over such a channel, paralleling\nrecent results of Matveev and Savkin. \n\n"}
{"id": "1112.4167", "contents": "Title: Iterative Deterministic Equivalents for the Performance Analysis of\n  Communication Systems Abstract: In this article, we introduce iterative deterministic equivalents as a novel\ntechnique for the performance analysis of communication systems whose channels\nare modeled by complex combinations of independent random matrices. This\ntechnique extends the deterministic equivalent approach for the study of\nfunctionals of large random matrices to a broader class of random matrix models\nwhich naturally arise as channel models in wireless communications. We present\ntwo specific applications: First, we consider a multi-hop amplify-and-forward\n(AF) MIMO relay channel with noise at each stage and derive deterministic\napproximations of the mutual information after the Kth hop. Second, we study a\nMIMO multiple access channel (MAC) where the channel between each transmitter\nand the receiver is represented by the double-scattering channel model. We\nprovide deterministic approximations of the mutual information, the\nsignal-to-interference-plus-noise ratio (SINR) and sum-rate with\nminimum-mean-square-error (MMSE) detection and derive the asymptotically\noptimal precoding matrices. In both scenarios, the approximations can be\ncomputed by simple and provably converging fixed-point algorithms and are shown\nto be almost surely tight in the limit when the number of antennas at each node\ngrows infinitely large. Simulations suggest that the approximations are\naccurate for realistic system dimensions. The technique of iterative\ndeterministic equivalents can be easily extended to other channel models of\ninterest and is, therefore, also a new contribution to the field of random\nmatrix theory. \n\n"}
{"id": "1201.0830", "contents": "Title: Wireless Network-Coded Accumulate-Compute and Forward Two-Way Relaying Abstract: The design of modulation schemes for the physical layer network-coded two way\nwireless relaying scenario is considered. It was observed by Koike-Akino et al.\nfor the two way relaying scenario, that adaptively changing the network coding\nmap used at the relay according to the channel conditions greatly reduces the\nimpact of multiple access interference which occurs at the relay during the MA\nPhase and all these network coding maps should satisfy a requirement called\nexclusive law. We extend this approach to an Accumulate-Compute and Forward\nprotocol which employs two phases: Multiple Access (MA) phase consisting of two\nchannel uses with independent messages in each channel use, and Broadcast (BC)\nphase having one channel use. Assuming that the two users transmit points from\nthe same 4-PSK constellation, every such network coding map that satisfies the\nexclusive law can be represented by a Latin Square with side 16, and\nconversely, this relationship can be used to get the network coding maps\nsatisfying the exclusive law. Two methods of obtaining this network coding map\nto be used at the relay are discussed. Using the structural properties of the\nLatin Squares for a given set of parameters, the problem of finding all the\nrequired maps is reduced to finding a small set of maps. Having obtained all\nthe Latin Squares, the set of all possible channel realizations is quantized,\ndepending on which one of the Latin Squares obtained optimizes the performance.\nThe quantization thus obtained, is shown to be the same as the one obtained in\n[7] for the 2-stage bidirectional relaying. \n\n"}
{"id": "1201.2868", "contents": "Title: On Ergodic Secrecy Capacity of Multiple Input Wiretap Channel with\n  Statistical CSIT Abstract: We consider the secure transmission in ergodic fast-Rayleigh fading\nmultiple-input single-output single-antennaeavesdropper (MISOSE) wiretap\nchannels. We assume that the statistics of both the legitimate and eavesdropper\nchannels is the only available channel state information at the transmitter\n(CSIT). By introducing a new secrecy capacity upper bound, we prove that the\nsecrecy capacity is achieved by Gaussian input without prefixing. To attain\nthis, we form another MISOSE channel for upper-bounding, and tighten the bound\nby finding the worst correlations between the legitimate and eavesdropper\nchannel coefficients. The resulting upper bound is tighter than the others in\nthe literature which are based on modifying the correlation between the noises\nat the legitimate receiver and eavesdropper. Next, we fully characterize the\nergodic secrecy capacity by showing that the optimal channel input covariance\nmatrix is a scaled identity matrix, with the transmit power allocated uniformly\namong the antennas. The key to solve such a complicated stochastic optimization\nproblem is by exploiting the completely monotone property of the ergodic\nsecrecy capacity to use the stochastic ordering theory. Finally, our simulation\nresults show that for the considered channel setting, the secrecy capacity is\nbounded in both the high signal-to-noise ratio and large number of transmit\nantenna regimes. \n\n"}
{"id": "1201.3088", "contents": "Title: An Adaptive Modulation Scheme for Two-user Fading MAC with Quantized\n  Fade State Feedback Abstract: With no CSI at the users, transmission over the two-user Gaussian Multiple\nAccess Channel with fading and finite constellation at the input, is not\nefficient because error rates will be high when the channel conditions are\npoor. However, perfect CSI at the users is an unrealistic assumption in the\nwireless scenario, as it would involve massive feedback overheads. In this\npaper we propose a scheme which uses only quantized knowledge of CSI at the\ntransmitters with the overhead being nominal. The users rotate their\nconstellation without varying their transmit power to adapt to the existing\nchannel conditions, in order to meet certain pre-determined minimum Euclidean\ndistance requirement in the equivalent constellation at the destination. The\noptimal modulation scheme has been described for the case when both the users\nuse symmetric M-PSK constellations at the input, where $ M=2^\\lambda $, $\n\\lambda $ being a positive integer. The strategy has been illustrated by\nconsidering examples where both users use QPSK or 8-PSK signal sets at the\ninput. It is shown that the proposed scheme has better throughput and error\nperformance compared to the conventional non-adaptive scheme, at the cost of a\nfeedback overhead of just $\\lceil \\log_2(\\frac{M^2}{8}-\\frac{M}{4}+2)\\rceil + 1\n$ bits, for the M-PSK case. \n\n"}
{"id": "1201.4615", "contents": "Title: Augmented L1 and Nuclear-Norm Models with a Globally Linearly Convergent\n  Algorithm Abstract: This paper studies the long-existing idea of adding a nice smooth function to\n\"smooth\" a non-differentiable objective function in the context of sparse\noptimization, in particular, the minimization of\n$||x||_1+1/(2\\alpha)||x||_2^2$, where $x$ is a vector, as well as the\nminimization of $||X||_*+1/(2\\alpha)||X||_F^2$, where $X$ is a matrix and\n$||X||_*$ and $||X||_F$ are the nuclear and Frobenius norms of $X$,\nrespectively. We show that they can efficiently recover sparse vectors and\nlow-rank matrices. In particular, they enjoy exact and stable recovery\nguarantees similar to those known for minimizing $||x||_1$ and $||X||_*$ under\nthe conditions on the sensing operator such as its null-space property,\nrestricted isometry property, spherical section property, or RIPless property.\nTo recover a (nearly) sparse vector $x^0$, minimizing\n$||x||_1+1/(2\\alpha)||x||_2^2$ returns (nearly) the same solution as minimizing\n$||x||_1$ almost whenever $\\alpha\\ge 10||x^0||_\\infty$. The same relation also\nholds between minimizing $||X||_*+1/(2\\alpha)||X||_F^2$ and minimizing\n$||X||_*$ for recovering a (nearly) low-rank matrix $X^0$, if $\\alpha\\ge\n10||X^0||_2$. Furthermore, we show that the linearized Bregman algorithm for\nminimizing $||x||_1+1/(2\\alpha)||x||_2^2$ subject to $Ax=b$ enjoys global\nlinear convergence as long as a nonzero solution exists, and we give an\nexplicit rate of convergence. The convergence property does not require a\nsolution solution or any properties on $A$. To our knowledge, this is the best\nknown global convergence result for first-order sparse optimization algorithms. \n\n"}
{"id": "1201.6548", "contents": "Title: Orthogonal Multiple Access with Correlated Sources: Feasible Region and\n  Pragmatic Schemes Abstract: In this paper, we consider orthogonal multiple access coding schemes, where\ncorrelated sources are encoded in a distributed fashion and transmitted,\nthrough additive white Gaussian noise (AWGN) channels, to an access point (AP).\nAt the AP, component decoders, associated with the source encoders, iteratively\nexchange soft information by taking into account the source correlation. The\nfirst goal of this paper is to investigate the ultimate achievable performance\nlimits in terms of a multi-dimensional feasible region in the space of channel\nparameters, deriving insights on the impact of the number of sources. The\nsecond goal is the design of pragmatic schemes, where the sources use\n\"off-the-shelf\" channel codes. In order to analyze the performance of given\ncoding schemes, we propose an extrinsic information transfer (EXIT)-based\napproach, which allows to determine the corresponding multi-dimensional\nfeasible regions. On the basis of the proposed analytical framework, the\nperformance of pragmatic coded schemes, based on serially concatenated\nconvolutional codes (SCCCs), is discussed. \n\n"}
{"id": "1202.0168", "contents": "Title: On the Capacity of Large-MIMO Block-Fading Channels Abstract: We characterize the capacity of Rayleigh block-fading multiple-input\nmultiple-output (MIMO) channels in the noncoherent setting where transmitter\nand receiver have no a priori knowledge of the realizations of the fading\nchannel. We prove that unitary space-time modulation (USTM) is not\ncapacity-achieving in the high signal-to-noise ratio (SNR) regime when the\ntotal number of antennas exceeds the coherence time of the fading channel\n(expressed in multiples of the symbol duration), a situation that is relevant\nfor MIMO systems with large antenna arrays (large-MIMO systems). This result\nsettles a conjecture by Zheng & Tse (2002) in the affirmative. The\ncapacity-achieving input signal, which we refer to as Beta-variate space-time\nmodulation (BSTM), turns out to be the product of a unitary isotropically\ndistributed random matrix, and a diagonal matrix whose nonzero entries are\ndistributed as the square-root of the eigenvalues of a Beta-distributed random\nmatrix of appropriate size. Numerical results illustrate that using BSTM\ninstead of USTM in large-MIMO systems yields a rate gain as large as 13% for\nSNR values of practical interest. \n\n"}
{"id": "1202.0204", "contents": "Title: On the Capacity of Interference Channel with Causal and Non-causal\n  Generalized Feedback at the Cognitive Transmitter Abstract: In this paper, taking into account the effect of link delays, we investigate\nthe capacity region of the Cognitive Interference Channel (C-IFC), where\ncognition can be obtained from either causal or non-causal generalized\nfeedback. For this purpose, we introduce the Causal Cognitive Interference\nChannel With Delay (CC-IFC-WD) in which the cognitive user's transmission can\ndepend on $L$ future received symbols as well as the past ones. We show that\nthe CC-IFC-WD model is equivalent to a classical Causal C-IFC (CC-IFC) with\nlink delays. Moreover, CC-IFC-WD extends both genie-aided and causal cognitive\nradio channels and bridges the gap between them. First, we derive an outer\nbound on the capacity region for the arbitrary value of $L$ and specialize this\ngeneral outer bound to the strong interference case. Then, under strong\ninterference conditions, we tighten the outer bound. To derive the achievable\nrate regions, we concentrate on three special cases: 1) Classical CC-IFC (L=0),\n2) CC-IFC without delay (L=1), and 3) CC-IFC with unlimited look-ahead in which\nthe cognitive user non-causally knows its entire received sequence. In each\ncase, we obtain a new inner bound on the capacity region. Moreover, we show\nthat the coding strategy which we use to derive an achievable rate region for\nthe classical CC-IFC achieves the capacity for the classes of degraded and\nsemi-deterministic classical CC-IFC under strong interference conditions.\nFurthermore, we extend our achievable rate regions to the Gaussian case.\nProviding some numerical examples for Gaussian CC-IFC-WD, we compare the\nperformances of the different strategies and investigate the rate gain of the\ncognitive link for different delay values. \n\n"}
{"id": "1202.0343", "contents": "Title: How Fast Can Dense Codes Achieve the Min-Cut Capacity of Line Networks? Abstract: In this paper, we study the coding delay and the average coding delay of\nrandom linear network codes (dense codes) over line networks with deterministic\nregular and Poisson transmission schedules. We consider both lossless networks\nand networks with Bernoulli losses. The upper bounds derived in this paper,\nwhich are in some cases more general, and in some other cases tighter, than the\nexisting bounds, provide a more clear picture of the speed of convergence of\ndense codes to the min-cut capacity of line networks. \n\n"}
{"id": "1202.0864", "contents": "Title: Nested Lattice Codes for Arbitrary Continuous Sources and Channels Abstract: In this paper, we show that nested lattice codes achieve the capacity of\narbitrary channels with or without non-casual state information at the\ntransmitter. We also show that nested lattice codes are optimal for source\ncoding with or without non-causal side information at the receiver for\narbitrary continuous sources. \n\n"}
{"id": "1202.0866", "contents": "Title: List-decoding of Subspace Codes and Rank-Metric Codes up to Singleton\n  Bound Abstract: Subspace codes and rank-metric codes can be used to correct errors and\nerasures in network, with linear network coding. Subspace codes were introduced\nby Koetter and Kschischang to correct errors and erasures in networks where\ntopology is unknown (the noncoherent case). In a previous work, we have\ndeveloped a family of subspace codes, based upon the Koetter-Kschichang\nconstruction, which are efficiently list decodable. Using these codes, we\nachieved a better decoding radius than Koetter-Kschischiang codes at low rates.\nHerein, we introduce a new family of subspace codes based upon a different\napproach which leads to a linear-algebraic list-decoding algorithm. The\nresulting error correction radius can be expressed as follows: for any integer\n$s$, our list-decoder using $s+1$-interpolation polynomials guarantees\nsuccessful recovery of the message subspace provided the normalized dimension\nof errors is at most $s(1-sR)$. The same list-decoding algorithm can be used to\ncorrect erasures as well as errors. The size of output list is at most\n$Q^{s-1}$, where $Q$ is the size of the field that message symbols are chosen\nfrom. Rank-metric codes are suitable for error correction in the case where the\nnetwork topology and the underlying network code are known (the coherent case).\nGabidulin codes are a well-known class of algebraic rank-metric codes that meet\nthe Singleton bound on the minimum rank metric of a code. In this paper, we\nintroduce a folded version of Gabidulin codes analogous to the folded\nReed-Solomon codes of Guruswami and Rudra along with a list-decoding algorithm\nfor such codes. Our list-decoding algorithm makes it possible to recover the\nmessage provided that the normalized rank of error is at most $1-R-\\epsilon$,\nfor any $\\epsilon > 0$. Notably this achieves the information theoretic bound\non the decoding radius of a rank-metric code. \n\n"}
{"id": "1202.1572", "contents": "Title: Expansion coding: Achieving the capacity of an AEN channel Abstract: A general method of coding over expansions is proposed, which allows one to\nreduce the highly non-trivial problem of coding over continuous channels to a\nmuch simpler discrete ones. More specifically, the focus is on the additive\nexponential noise (AEN) channel, for which the (binary) expansion of the\n(exponential) noise random variable is considered. It is shown that each of the\nrandom variables in the expansion corresponds to independent Bernoulli random\nvariables. Thus, each of the expansion levels (of the underlying channel)\ncorresponds to a binary symmetric channel (BSC), and the coding problem is\nreduced to coding over these parallel channels while satisfying the channel\ninput constraint. This optimization formulation is stated as the achievable\nrate result, for which a specific choice of input distribution is shown to\nachieve a rate which is arbitrarily close to the channel capacity in the high\nSNR regime. Remarkably, the scheme allows for low-complexity capacity-achieving\ncodes for AEN channels, using the codes that are originally designed for BSCs.\nExtensions to different channel models and applications to other coding\nproblems are discussed. \n\n"}
{"id": "1202.2167", "contents": "Title: Abstract Representations and Frequent Pattern Discovery Abstract: We discuss the frequent pattern mining problem in a general setting. From an\nanalysis of abstract representations, summarization and frequent pattern\nmining, we arrive at a generalization of the problem. Then, we show how the\nproblem can be cast into the powerful language of algorithmic information\ntheory. This allows us to formulate a simple algorithm to mine for all frequent\npatterns. \n\n"}
{"id": "1202.4034", "contents": "Title: PAR-Aware Large-Scale Multi-User MIMO-OFDM Downlink Abstract: We investigate an orthogonal frequency-division multiplexing (OFDM)-based\ndownlink transmission scheme for large-scale multi-user (MU) multiple-input\nmultiple-output (MIMO) wireless systems. The use of OFDM causes a high\npeak-to-average (power) ratio (PAR), which necessitates expensive and\npower-inefficient radio-frequency (RF) components at the base station. In this\npaper, we present a novel downlink transmission scheme, which exploits the\nmassive degrees-of-freedom available in large-scale MU-MIMO-OFDM systems to\nachieve low PAR. Specifically, we propose to jointly perform MU precoding, OFDM\nmodulation, and PAR reduction by solving a convex optimization problem. We\ndevelop a corresponding fast iterative truncation algorithm (FITRA) and show\nnumerical results to demonstrate tremendous PAR-reduction capabilities. The\nsignificantly reduced linearity requirements eventually enable the use of\nlow-cost RF components for the large-scale MU-MIMO-OFDM downlink. \n\n"}
{"id": "1202.4425", "contents": "Title: Relay Channel with Orthogonal Components and Structured Interference\n  Known at the Source Abstract: A relay channel with orthogonal components that is affected by an\ninterference signal that is noncausally available only at the source is\nstudied. The interference signal has structure in that it is produced by\nanother transmitter communicating with its own destination. Moreover, the\ninterferer is not willing to adjust its communication strategy to minimize the\ninterference. Knowledge of the interferer's signal may be acquired by the\nsource, for instance, by exploiting HARQ retransmissions on the interferer's\nlink. The source can then utilize the relay not only for communicating its own\nmessage, but also for cooperative interference mitigation at the destination by\ninforming the relay about the interference signal. Proposed transmission\nstrategies are based on partial decode-and-forward (PDF) relaying and leverage\nthe interference structure. Achievable schemes are derived for discrete\nmemoryless models, Gaussian and Ricean fading channels. Furthermore, optimal\nstrategies are identified in some special cases. Finally, numerical results\nbring insight into the advantages of utilizing the interference structure at\nthe source, relay or destination. \n\n"}
{"id": "1202.6555", "contents": "Title: Adaptive sensing using deterministic partial Hadamard matrices Abstract: This paper investigates the construction of deterministic matrices preserving\nthe entropy of random vectors with a given probability distribution. In\nparticular, it is shown that for random vectors having i.i.d. discrete\ncomponents, this is achieved by selecting a subset of rows of a Hadamard matrix\nsuch that (i) the selection is deterministic (ii) the fraction of selected rows\nis vanishing. In contrast, it is shown that for random vectors with i.i.d.\ncontinuous components, no partial Hadamard matrix of reduced dimension allows\nto preserve the entropy. These results are in agreement with the results of\nWu-Verdu on almost lossless analog compression. This paper is however motivated\nby the complexity attribute of Hadamard matrices, which allows the use of\nefficient and stable reconstruction algorithms. The proof technique is based on\na polar code martingale argument and on a new entropy power inequality for\ninteger-valued random variables. \n\n"}
{"id": "1203.1304", "contents": "Title: Analytical Modeling of Uplink Cellular Networks Abstract: Cellular uplink analysis has typically been undertaken by either a simple\napproach that lumps all interference into a single deterministic or random\nparameter in a Wyner-type model, or via complex system level simulations that\noften do not provide insight into why various trends are observed. This paper\nproposes a novel middle way using point processes that is both accurate and\nalso results in easy-to-evaluate integral expressions based on the Laplace\ntransform of the interference. We assume mobiles and base stations are randomly\nplaced in the network with each mobile pairing up to its closest base station.\nCompared to related recent work on downlink analysis, the proposed uplink model\ndiffers in two key features. First, dependence is considered between user and\nbase station point processes to make sure each base station serves a single\nmobile in the given resource block. Second, per-mobile power control is\nincluded, which further couples the transmission of mobiles due to\nlocation-dependent channel inversion. Nevertheless, we succeed in deriving the\ncoverage (equivalently outage) probability of a typical link in the network.\nThis model can be used to address a wide variety of system design questions in\nthe future. In this paper we focus on the implications for power control and\nsee that partial channel inversion should be used at low\nsignal-to-interference-plus-noise ratio (SINR), while full power transmission\nis optimal at higher SINR. \n\n"}
{"id": "1203.1376", "contents": "Title: MIMO Multiple Access Channel with an Arbitrarily Varying Eavesdropper Abstract: A two-transmitter Gaussian multiple access wiretap channel with multiple\nantennas at each of the nodes is investigated. The channel matrices at the\nlegitimate terminals are fixed and revealed to all the terminals, whereas the\nchannel matrix of the eavesdropper is arbitrarily varying and only known to the\neavesdropper. The secrecy degrees of freedom (s.d.o.f.) region under a strong\nsecrecy constraint is characterized. A transmission scheme that orthogonalizes\nthe transmit signals of the two users at the intended receiver and uses a\nsingle-user wiretap code is shown to be sufficient to achieve the s.d.o.f.\nregion. The converse involves establishing an upper bound on a\nweighted-sum-rate expression. This is accomplished by using induction, where at\neach step one combines the secrecy and multiple-access constraints associated\nwith an adversary eavesdropping a carefully selected group of sub-channels. \n\n"}
{"id": "1203.1570", "contents": "Title: In-network Sparsity-regularized Rank Minimization: Algorithms and\n  Applications Abstract: Given a limited number of entries from the superposition of a low-rank matrix\nplus the product of a known fat compression matrix times a sparse matrix,\nrecovery of the low-rank and sparse components is a fundamental task subsuming\ncompressed sensing, matrix completion, and principal components pursuit. This\npaper develops algorithms for distributed sparsity-regularized rank\nminimization over networks, when the nuclear- and $\\ell_1$-norm are used as\nsurrogates to the rank and nonzero entry counts of the sought matrices,\nrespectively. While nuclear-norm minimization has well-documented merits when\ncentralized processing is viable, non-separability of the singular-value sum\nchallenges its distributed minimization. To overcome this limitation, an\nalternative characterization of the nuclear norm is adopted which leads to a\nseparable, yet non-convex cost minimized via the alternating-direction method\nof multipliers. The novel distributed iterations entail reduced-complexity\nper-node tasks, and affordable message passing among single-hop neighbors.\nInterestingly, upon convergence the distributed (non-convex) estimator provably\nattains the global optimum of its centralized counterpart, regardless of\ninitialization. Several application domains are outlined to highlight the\ngenerality and impact of the proposed framework. These include unveiling\ntraffic anomalies in backbone networks, predicting networkwide path latencies,\nand mapping the RF ambiance using wireless cognitive radios. Simulations with\nsynthetic and real network data corroborate the convergence of the novel\ndistributed algorithm, and its centralized performance guarantees. \n\n"}
{"id": "1203.2316", "contents": "Title: Near-optimal quantization and linear network coding for relay networks Abstract: We introduce a discrete network corresponding to any Gaussian wireless\nnetwork that is obtained by simply quantizing the received signals and\nrestricting the transmitted signals to a finite precision. Since signals in the\ndiscrete network are obtained from those of a Gaussian network, the Gaussian\nnetwork can be operated on the quantization-based digital interface defined by\nthe discrete network. We prove that this digital interface is near-optimal for\nGaussian relay networks and the capacities of the Gaussian and the discrete\nnetworks are within a bounded gap of O(M^2) bits, where M is the number of\nnodes.\n  We prove that any near-optimal coding strategy for the discrete network can\nbe naturally transformed into a near-optimal coding strategy for the Gaussian\nnetwork merely by quantization. We exploit this by designing a linear coding\nstrategy for the case of layered discrete relay networks. The linear coding\nstrategy is near-optimal for Gaussian and discrete networks and achieves rates\nwithin O(M^2) bits of the capacity, independent of channel gains or SNR. The\nlinear code is robust and the relays need not know the channel gains. The\ntransmit and receive signals at all relays are simply quantized to binary\ntuples of the same length $n$ . The linear network code requires all the relay\nnodes to collect the received binary tuples into a long binary vector and apply\na linear transformation on the long vector. The resulting binary vector is\nsplit into smaller binary tuples for transmission by the relays. The\nquantization requirements of the linear network code are completely defined by\nthe parameter $n$, which also determines the resolution of the\nanalog-to-digital and digital-to-analog convertors for operating the network\nwithin a bounded gap of the network's capacity. The linear network code\nexplicitly connects network coding for wireline networks with codes for\nGaussian networks. \n\n"}
{"id": "1203.3115", "contents": "Title: Codes on Graphs: Observability, Controllability and Local Reducibility Abstract: This paper investigates properties of realizations of linear or group codes\non general graphs that lead to local reducibility.\n  Trimness and properness are dual properties of constraint codes. A linear or\ngroup realization with a constraint code that is not both trim and proper is\nlocally reducible. A linear or group realization on a finite cycle-free graph\nis minimal if and only if every local constraint code is trim and proper.\n  A realization is called observable if there is a one-to-one correspondence\nbetween codewords and configurations, and controllable if it has independent\nconstraints. A linear or group realization is observable if and only if its\ndual is controllable. A simple counting test for controllability is given. An\nunobservable or uncontrollable realization is locally reducible. Parity-check\nrealizations are controllable if and only if they have independent parity\nchecks. In an uncontrollable tail-biting trellis realization, the behavior\npartitions into disconnected subbehaviors, but this property does not hold for\nnon-trellis realizations. On a general graph, the support of an unobservable\nconfiguration is a generalized cycle. \n\n"}
{"id": "1203.3322", "contents": "Title: A note on Shannon entropy Abstract: We present a somewhat different way of looking on Shannon entropy. This leads\nto an axiomatisation of Shannon entropy that is essentially equivalent to that\nof Fadeev. In particular we give a new proof of Fadeev theorem. \n\n"}
{"id": "1203.3659", "contents": "Title: Cognitive Wyner Networks with Clustered Decoding Abstract: We study an interference network where equally-numbered transmitters and\nreceivers lie on two parallel lines, each transmitter opposite its intended\nreceiver. We consider two short-range interference models: the \"asymmetric\nnetwork,\" where the signal sent by each transmitter is interfered only by the\nsignal sent by its left neighbor (if present), and a \"symmetric network,\" where\nit is interfered by both its left and its right neighbors. Each transmitter is\ncognizant of its own message, the messages of the $t_\\ell$ transmitters to its\nleft, and the messages of the $t_r$ transmitters to its right. Each receiver\ndecodes its message based on the signals received at its own antenna, at the\n$r_\\ell$ receive antennas to its left, and the $r_r$ receive antennas to its\nright. For such networks we provide upper and lower bounds on the multiplexing\ngain, i.e., on the high-SNR asymptotic logarithmic growth of the sum-rate\ncapacity. In some cases our bounds meet, e.g., for the asymmetric network. Our\nresults exhibit an equivalence between the transmitter side-information\nparameters $t_\\ell, t_r$ and the receiver side-information parameters $r_\\ell,\nr_r$ in the sense that increasing/decreasing $t_\\ell$ or $t_r$ by a positive\ninteger $\\delta$ has the same effect on the multiplexing gain as\nincreasing/decreasing $r_\\ell$ or $r_r$ by $\\delta$. Moreover---even in\nasymmetric networks---there is an equivalence between the left side-information\nparameters $t_\\ell, r_\\ell$ and the right side-information parameters $t_r,\nr_r$. \n\n"}
{"id": "1203.4583", "contents": "Title: Multi-Antenna System Design with Bright Transmitters and Blind Receivers Abstract: This paper considers a scenario for multi-input multi-output (MIMO)\ncommunication systems when perfect channel state information at the transmitter\n(CSIT) is given while the equivalent channel state information at the receiver\n(CSIR) is not available. Such an assumption is valid for the downlink\nmulti-user MIMO systems with linear precoders that depend on channels to all\nreceivers. We propose a concept called dual systems with zero-forcing designs\nbased on the duality principle, originally proposed to relate Gaussian\nmulti-access channels (MACs) and Gaussian broadcast channels (BCs). For the\ntwo-user N*2 MIMO BC with N antennas at the transmitter and two antennas at\neach of the receivers, we design a downlink interference cancellation (IC)\ntransmission scheme using the dual of uplink MAC systems employing IC methods.\nThe transmitter simultaneously sends two precoded Alamouti codes, one for each\nuser. Each receiver can zero-force the unintended user's Alamouti codes and\ndecouple its own data streams using two simple linear operations independent of\nCSIR. Analysis shows that the proposed scheme achieves a diversity gain of\n2(N-1) for equal energy constellations with short-term power and rate\nconstraints. Power allocation between two users can also be performed, and it\nimproves the array gain but not the diversity gain. Numerical results\ndemonstrate that the bit error rate of the downlink IC scheme has a substantial\ngain compared to the block diagonalization method, which requires global\nchannel information at each node. \n\n"}
{"id": "1203.5362", "contents": "Title: Throughput Optimal Scheduling with Dynamic Channel Feedback Abstract: It is well known that opportunistic scheduling algorithms are throughput\noptimal under full knowledge of channel and network conditions. However, these\nalgorithms achieve a hypothetical achievable rate region which does not take\ninto account the overhead associated with channel probing and feedback required\nto obtain the full channel state information at every slot. We adopt a channel\nprobing model where $\\beta$ fraction of time slot is consumed for acquiring the\nchannel state information (CSI) of a single channel. In this work, we design a\njoint scheduling and channel probing algorithm named SDF by considering the\noverhead of obtaining the channel state information. We first analytically\nprove SDF algorithm can support $1+\\epsilon$ fraction of of the full rate\nregion achieved when all users are probed where $\\epsilon$ depends on the\nexpected number of users which are not probed. Then, for homogenous channel, we\nshow that when the number of users in the network is greater than 3, $\\epsilon\n> 0$, i.e., we guarantee to expand the rate region. In addition, for\nheterogenous channels, we prove the conditions under which SDF guarantees to\nincrease the rate region. We also demonstrate numerically in a realistic\nsimulation setting that this rate region can be achieved by probing only less\nthan 50% of all channels in a CDMA based cellular network utilizing high data\nrate protocol under normal channel conditions. \n\n"}
{"id": "1204.0590", "contents": "Title: Linear System Identification via Atomic Norm Regularization Abstract: This paper proposes a new algorithm for linear system identification from\nnoisy measurements. The proposed algorithm balances a data fidelity term with a\nnorm induced by the set of single pole filters. We pose a convex optimization\nproblem that approximately solves the atomic norm minimization problem and\nidentifies the unknown system from noisy linear measurements. This problem can\nbe solved efficiently with standard, freely available software. We provide\nrigorous statistical guarantees that explicitly bound the estimation error (in\nthe H_2-norm) in terms of the stability radius, the Hankel singular values of\nthe true system and the number of measurements. These results in turn yield\ncomplexity bounds and asymptotic consistency. We provide numerical experiments\ndemonstrating the efficacy of our method for estimating linear systems from a\nvariety of linear measurements. \n\n"}
{"id": "1204.0867", "contents": "Title: Optimal Index Codes for a Class of Multicast Networks with Receiver Side\n  Information Abstract: This paper studies a special class of multicast index coding problems where a\nsender transmits messages to multiple receivers, each with some side\ninformation. Here, each receiver knows a unique message a priori, and there is\nno restriction on how many messages each receiver requests from the sender. For\nthis class of multicast index coding problems, we obtain the optimal index\ncode, which has the shortest codelength for which the sender needs to send in\norder for all receivers to obtain their (respective) requested messages. This\nis the first class of index coding problems where the optimal index codes are\nfound. In addition, linear index codes are shown to be optimal for this class\nof index coding problems. \n\n"}
{"id": "1204.1595", "contents": "Title: Femtocaching and Device-to-Device Collaboration: A New Architecture for\n  Wireless Video Distribution Abstract: We present a new architecture to handle the ongoing explosive increase in the\ndemand for video content in wireless networks. It is based on distributed\ncaching of the content in femto-basestations with small or non-existing\nbackhaul capacity but with considerable storage space, called helper nodes. We\nalso consider using the mobile terminals themselves as caching helpers, which\ncan distribute video through device-to-device communications. This approach\nallows an improvement in the video throughput without deployment of any\nadditional infrastructure. The new architecture can improve video throughput by\none to two orders-of-magnitude. \n\n"}
{"id": "1204.4840", "contents": "Title: Energy-Delay Tradeoff and Dynamic Sleep Switching for Bluetooth-Like\n  Body-Area Sensor Networks Abstract: Wireless technology enables novel approaches to healthcare, in particular the\nremote monitoring of vital signs and other parameters indicative of people's\nhealth. This paper considers a system scenario relevant to such applications,\nwhere a smart-phone acts as a data-collecting hub, gathering data from a number\nof wireless-capable body sensors, and relaying them to a healthcare provider\nhost through standard existing cellular networks. Delay of critical data and\nsensors' energy efficiency are both relevant and conflicting issues. Therefore,\nit is important to operate the wireless body-area sensor network at some\ndesired point close to the optimal energy-delay tradeoff curve. This tradeoff\ncurve is a function of the employed physical-layer protocol: in particular, it\ndepends on the multiple-access scheme and on the coding and modulation schemes\navailable. In this work, we consider a protocol closely inspired by the\nwidely-used Bluetooth standard. First, we consider the calculation of the\nminimum energy function, i.e., the minimum sum energy per symbol that\nguarantees the stability of all transmission queues in the network. Then, we\napply the general theory developed by Neely to develop a dynamic scheduling\npolicy that approaches the optimal energy-delay tradeoff for the network at\nhand. Finally, we examine the queue dynamics and propose a novel policy that\nadaptively switches between connected and disconnected (sleeping) modes. We\ndemonstrate that the proposed policy can achieve significant gains in the\nrealistic case where the control \"NULL\" packets necessary to maintain the\nconnection alive, have a non-zero energy cost, and the data arrival statistics\ncorresponding to the sensed physical process are bursty. \n\n"}
{"id": "1204.5226", "contents": "Title: An Optimal and Distributed Method for Voltage Regulation in Power\n  Distribution Systems Abstract: This paper addresses the problem of voltage regulation in power distribution\nnetworks with deep-penetration of distributed energy resources, e.g.,\nrenewable-based generation, and storage-capable loads such as plug-in hybrid\nelectric vehicles. We cast the problem as an optimization program, where the\nobjective is to minimize the losses in the network subject to constraints on\nbus voltage magnitudes, limits on active and reactive power injections,\ntransmission line thermal limits and losses. We provide sufficient conditions\nunder which the optimization problem can be solved via its convex relaxation.\nUsing data from existing networks, we show that these sufficient conditions are\nexpected to be satisfied by most networks. We also provide an efficient\ndistributed algorithm to solve the problem. The algorithm adheres to a\ncommunication topology described by a graph that is the same as the graph that\ndescribes the electrical network topology. We illustrate the operation of the\nalgorithm, including its robustness against communication link failures,\nthrough several case studies involving 5-, 34-, and 123-bus power distribution\nsystems. \n\n"}
{"id": "1204.5317", "contents": "Title: Correction Trees as an Alternative to Turbo Codes and Low Density Parity\n  Check Codes Abstract: The rapidly improving performance of modern hardware renders convolutional\ncodes obsolete, and allows for the practical implementation of more\nsophisticated correction codes such as low density parity check (LDPC) and\nturbo codes (TC). Both are decoded by iterative algorithms, which require a\ndisproportional computational effort for low channel noise. They are also\nunable to correct higher noise levels, still below the Shannon theoretical\nlimit. In this paper, we discuss an enhanced version of a convolutional-like\ndecoding paradigm which adopts very large spaces of possible system states, of\nthe order of $2^{64}$. Under such conditions, the traditional convolution\noperation is rendered useless and needs to be replaced by a carefully designed\nstate transition procedure. The size of the system state space completely\nchanges the correction philosophy, as state collisions are virtually impossible\nand the decoding procedure becomes a correction tree. The proposed decoding\nalgorithm is practically cost-free for low channel noise. As the channel noise\napproaches the Shannon limit, it is still possible to perform correction,\nalthough its cost increases to infinity. In many applications, the implemented\ndecoder can essentially outperform both LDPC and TC. This paper describes the\nproposed correction paradigm and theoretically analyzes the asymptotic\ncorrection performance. The considered encoder and decoder were verified\nexperimentally for the binary symmetric channel. The correction process remains\npractically cost-free for channel error rates below 0.05 and 0.13 for the 1/2\nand 1/4 rate codes, respectively. For the considered resource limit, the output\nbit error rates reach the order of $10^{-3}$ for channel error rates 0.08 and\n0.18. The proposed correction paradigm can be easily extended to other\ncommunication channels; the appropriate generalizations are also discussed in\nthis study. \n\n"}
{"id": "1204.5467", "contents": "Title: A new upper bound on the query complexity for testing generalized\n  Reed-Muller codes Abstract: Over a finite field $\\F_q$ the $(n,d,q)$-Reed-Muller code is the code given\nby evaluations of $n$-variate polynomials of total degree at most $d$ on all\npoints (of $\\F_q^n$). The task of testing if a function $f:\\F_q^n \\to \\F_q$ is\nclose to a codeword of an $(n,d,q)$-Reed-Muller code has been of central\ninterest in complexity theory and property testing. The query complexity of\nthis task is the minimal number of queries that a tester can make (minimum over\nall testers of the maximum number of queries over all random choices) while\naccepting all Reed-Muller codewords and rejecting words that are $\\delta$-far\nfrom the code with probability $\\Omega(\\delta)$. (In this work we allow the\nconstant in the $\\Omega$ to depend on $d$.) In this work we give a new upper\nbound of $(c q)^{(d+1)/q}$ on the query complexity, where $c$ is a universal\nconstant. In the process we also give new upper bounds on the \"spanning weight\"\nof the dual of the Reed-Muller code (which is also a Reed-Muller code). The\nspanning weight of a code is the smallest integer $w$ such that codewords of\nHamming weight at most $w$ span the code. \n\n"}
{"id": "1205.4266", "contents": "Title: Chernoff Bounds for Analysis of Rate-Compatible Sphere-Packing with\n  Numerous Transmissions Abstract: Recent results by Chen et al. and Polyanskiy et al. explore using feedback to\napproach capacity with short blocklengths. This paper explores Chernoff\nbounding techniques to extend the rate-compatible sphere-packing (RCSP)\nanalysis proposed by Chen et al. to scenarios involving numerous\nretransmissions and different step sizes in each incremental retransmission.\nWilliamson et al. employ exact RCSP computations for up to six transmissions.\nHowever, exact RCSP computation with more than six retransmissions becomes\nunwieldy because of joint error probabilities involving numerous chi-squared\ndistributions. This paper explores Chernoff approaches for upper and lower\nbounds to provide support for computations involving more than six\ntransmissions.\n  We present two versions of upper and lower bounds for the two-transmission\ncase. One of the versions is extended to the general case of $m$ transmissions\nwhere $m \\geq 1$. Computing the general bounds requires minimization of\nexponential functions with the auxiliary parameters, but is less complex and\nmore stable than multiple rounds of numerical integration. These bounds also\nprovide a good estimate of the expected throughput and expected latency, which\nare useful for optimization purposes. \n\n"}
{"id": "1205.4781", "contents": "Title: An Achievable Rate Region for Three-Pair Interference Channels with\n  Noise Abstract: An achievable rate region for certain noisy three-user-pair interference\nchannels is proposed. The channel class under consideration generalizes the\nthree-pair deterministic interference channel (3-DIC) in the same way as the\nTelatar-Tse noisy two-pair interference channel generalizes the El Gamal-Costa\ninjective channel. Specifically, arbitrary noise is introduced that acts on the\ncombined interference signal before it affects the desired signal. This class\nof channels includes the Gaussian case.\n  The rate region includes the best-known inner bound on the 3-DIC capacity\nregion, dominates treating interference as noise, and subsumes the\nHan-Kobayashi region for the two-pair case. \n\n"}
{"id": "1205.4856", "contents": "Title: Bounds on Minimum Number of Anchors for Iterative Localization and its\n  Connections to Bootstrap Percolation Abstract: Iterated localization is considered where each node of a network needs to get\nlocalized (find its location on 2-D plane), when initially only a subset of\nnodes have their location information. The iterated localization process\nproceeds as follows. Starting with a subset of nodes that have their location\ninformation, possibly using global positioning system (GPS) devices, any other\nnode gets localized if it has three or more localized nodes in its radio range.\nThe newly localized nodes are included in the subset of nodes that have their\nlocation information for the next iteration. This process is allowed to\ncontinue, until no new node can be localized. The problem is to find the\nminimum size of the initially localized subset to start with so that the whole\nnetwork is localized with high probability. There are intimate connections\nbetween iterated localization and bootstrap percolation, that is well studied\nin statistical physics. Using results known in bootstrap percolation, we find a\nsufficient condition on the size of the initially localized subset that\nguarantees the localization of all nodes in the network with high probability. \n\n"}
{"id": "1205.4988", "contents": "Title: Capacity of Diffusion-based Molecular Communication with Ligand\n  Receptors Abstract: A diffusion-based molecular communication system has two major components:\nthe diffusion in the medium, and the ligand-reception. Information bits,\nencoded in the time variations of the concentration of molecules, are conveyed\nto the receiver front through the molecular diffusion in the medium. The\nreceiver, in turn, measures the concentration of the molecules in its vicinity\nin order to retrieve the information. This is done via ligand-reception\nprocess. In this paper, we develop models to study the constraints imposed by\nthe concentration sensing at the receiver side and derive the maximum rate by\nwhich a ligand-receiver can receive information. Therefore, the overall\ncapacity of the diffusion channel with the ligand receptors can be obtained by\ncombining the results presented in this paper with our previous work on the\nachievable information rate of molecular communication over the diffusion\nchannel. \n\n"}
{"id": "1205.5004", "contents": "Title: Systematic DFT Frames: Principle and Eigenvalues Structure Abstract: Motivated by a host of recent applications requiring some amount of\nredundancy, frames are becoming a standard tool in the signal processing\ntoolbox. In this paper, we study a specific class of frames, known as discrete\nFourier transform (DFT) codes, and introduce the notion of systematic frames\nfor this class. This is encouraged by application of systematic DFT codes in\ndistributed source coding using DFT codes, a new application for frames.\nStudying their extreme eigenvalues, we show that, unlike DFT frames, systematic\nDFT frames are not necessarily tight. Then, we come up with conditions for\nwhich these frames can be tight. In either case, the best and worst systematic\nframes are established from reconstruction error point of view. Eigenvalues of\nDFT frames, and their subframes, play a pivotal role in this work. \n\n"}
{"id": "1205.5073", "contents": "Title: Secure estimation and control for cyber-physical systems under\n  adversarial attacks Abstract: The vast majority of today's critical infrastructure is supported by numerous\nfeedback control loops and an attack on these control loops can have disastrous\nconsequences. This is a major concern since modern control systems are becoming\nlarge and decentralized and thus more vulnerable to attacks. This paper is\nconcerned with the estimation and control of linear systems when some of the\nsensors or actuators are corrupted by an attacker. In the first part we look at\nthe estimation problem where we characterize the resilience of a system to\nattacks and study the possibility of increasing its resilience by a change of\nparameters. We then propose an efficient algorithm to estimate the state\ndespite the attacks and we characterize its performance. Our approach is\ninspired from the areas of error-correction over the reals and compressed\nsensing. In the second part we consider the problem of designing\noutput-feedback controllers that stabilize the system despite attacks. We show\nthat a principle of separation between estimation and control holds and that\nthe design of resilient output feedback controllers can be reduced to the\ndesign of resilient state estimators. \n\n"}
{"id": "1205.5465", "contents": "Title: Isometry and Automorphisms of Constant Dimension Codes Abstract: We define linear and semilinear isometry for general subspace codes, used for\nrandom network coding. Furthermore, some results on isometry classes and\nautomorphism groups of known constant dimension code constructions are derived. \n\n"}
{"id": "1206.0937", "contents": "Title: Detecting Activations over Graphs using Spanning Tree Wavelet Bases Abstract: We consider the detection of activations over graphs under Gaussian noise,\nwhere signals are piece-wise constant over the graph. Despite the wide\napplicability of such a detection algorithm, there has been little success in\nthe development of computationally feasible methods with proveable theoretical\nguarantees for general graph topologies. We cast this as a hypothesis testing\nproblem, and first provide a universal necessary condition for asymptotic\ndistinguishability of the null and alternative hypotheses. We then introduce\nthe spanning tree wavelet basis over graphs, a localized basis that reflects\nthe topology of the graph, and prove that for any spanning tree, this approach\ncan distinguish null from alternative in a low signal-to-noise regime. Lastly,\nwe improve on this result and show that using the uniform spanning tree in the\nbasis construction yields a randomized test with stronger theoretical\nguarantees that in many cases matches our necessary conditions. Specifically,\nwe obtain near-optimal performance in edge transitive graphs, $k$-nearest\nneighbor graphs, and $\\epsilon$-graphs. \n\n"}
{"id": "1206.3953", "contents": "Title: Probabilistic Reconstruction in Compressed Sensing: Algorithms, Phase\n  Diagrams, and Threshold Achieving Matrices Abstract: Compressed sensing is a signal processing method that acquires data directly\nin a compressed form. This allows one to make less measurements than what was\nconsidered necessary to record a signal, enabling faster or more precise\nmeasurement protocols in a wide range of applications. Using an\ninterdisciplinary approach, we have recently proposed in [arXiv:1109.4424] a\nstrategy that allows compressed sensing to be performed at acquisition rates\napproaching to the theoretical optimal limits. In this paper, we give a more\nthorough presentation of our approach, and introduce many new results. We\npresent the probabilistic approach to reconstruction and discuss its optimality\nand robustness. We detail the derivation of the message passing algorithm for\nreconstruction and expectation max- imization learning of signal-model\nparameters. We further develop the asymptotic analysis of the corresponding\nphase diagrams with and without measurement noise, for different distribution\nof signals, and discuss the best possible reconstruction performances\nregardless of the algorithm. We also present new efficient seeding matrices,\ntest them on synthetic data and analyze their performance asymptotically. \n\n"}
{"id": "1206.4226", "contents": "Title: Three-User Cognitive Interference Channel: Capacity Region with Strong\n  Interference Abstract: This study investigates the capacity region of a three-user cognitive radio\nnetwork with two primary users and one cognitive user. A three-user Cognitive\nInterference Channel (C-IFC) is proposed by considering a three-user\nInterference Channel (IFC) where one of the transmitters has cognitive\ncapabilities and knows the messages of the other two transmitters in a\nnon-causal manner. First, two inner bounds on the capacity region of the\nthree-user C-IFC are obtained based on using the schemes which allow all\nreceivers to decode all messages with two different orders. Next, two sets of\nconditions are derived, under which the capacity region of the proposed model\ncoincides with the capacity region of a three-user C-IFC in which all three\nmessages are required at all receivers. Under these conditions, referred to as\nstrong interference conditions, the capacity regions for the proposed\nthree-user C-IFC are characterized. Moreover, the Gaussian three-user C-IFC is\nconsidered and the capacity results are derived for the Gaussian case. Some\nnumerical examples are also provided. \n\n"}
{"id": "1206.4389", "contents": "Title: Improving Two-Way Selective Decode-and-forward Wireless Relaying with\n  Energy-Efficient One-bit Soft Forwarding Abstract: Motivated by applications such as battery-operated wireless sensor networks\n(WSN), we propose an easy-to-implement energy-efficient two-way relaying\nscheme. In particular, we address the challenge of improving the standard\ntwo-way selective decode-and-forward protocol (TW-SDF) in terms of\nblock-error-rate (BLER) with minor additional complexity and energy\nconsumption. By following the principle of soft relaying, our solution is the\ntwo-way one-bit soft forwarding (TW-1bSF) protocol in which the relay forwards\nthe one-bit quantization of a posterior information metric about the\ntransmitted bits, associated with an appropriately designed reliability\nparameter.\n  In WSN-related standards (such as IEEE802.15.6 and Bluetooth), block codes\nare adopted instead of convolutional and other sophisticated codes, due to\ntheir efficient decoder hardware implementation. As the second main\ncontribution, we derive tight upper bounds on the BLER performance for both\nTW-SDF and TW-1bSF, when the two-way relaying network employs block codes and\nhard decoding. The error probability analysis confirms the superiority of\nTW-1bSF. Moreover, we derive the asymptotic performance gain of TW-1bSF over\nTW-SDF, which further suggests that the proposed protocol is a good choice,\nespecially when long block codes are used. \n\n"}
{"id": "1206.6145", "contents": "Title: Two-way Networks: when Adaptation is Useless Abstract: In two-way networks, nodes act as both sources and destinations of messages.\nThis allows for \"adaptation\" at or \"interaction\" between the nodes - a node's\nchannel inputs may be functions of its message(s) and previously received\nsignals. How to best adapt is key to two-way communication, rendering it\nchallenging. However, examples exist of point-to-point channels where\nadaptation is not beneficial from a capacity perspective. We ask whether\nanalogous examples exist for multi-user two-way networks.\n  We first consider deterministic two-way channel models: the binary modulo-2\naddition channel and a generalization thereof, and the linear deterministic\nchannel. For these deterministic models we obtain the capacity region for the\ntwo-way multiple access/broadcast channel, the two-way Z channel and the\ntwo-way interference channel (IC). In all cases we permit all nodes to adapt\nchannel inputs to past outputs (except for portions of the linear deterministic\ntwo-way IC where we only permit 2 of the 4 nodes to fully adapt). However, we\nshow that this adaptation is useless from a capacity region perspective and\ncapacity is achieved by strategies where the channel inputs at each use do not\nadapt to previous inputs. Finally, we consider the Gaussian two-way IC, and\nshow that partial adaptation is useless when the interference is very strong.\nIn the strong and weak interference regimes, we show that the non-adaptive Han\nand Kobayashi scheme utilized in parallel in both directions achieves to within\na constant gap for the symmetric rate of the fully (some regimes) or partially\n(remaining regimes) adaptive models.\n  The central technical contribution is the derivation of new, computable outer\nbounds which allow for adaptation. Inner bounds follow from non-adaptive\nachievability schemes of the corresponding one-way channel models. \n\n"}
{"id": "1207.0273", "contents": "Title: Performance Analysis for Heterogeneous Cellular Systems with Range\n  Expansion Abstract: Recently heterogeneous base station structure has been adopted in cellular\nsystems to enhance system throughput and coverage. In this paper, the uplink\ncoverage probability for the heterogeneous cellular systems is analyzed and\nderived in closed-form. The randomness on the locations and number of mobile\nusers is taken into account in the analysis. Based on the analytical results,\nthe impacts of various system parameters on the uplink performance are\ninvestigated in detail. The correctness of the analytical results is also\nverified by simulation results. These analytical results can thus serve as a\nguidance for system design without the need of time consuming simulations. \n\n"}
{"id": "1207.1517", "contents": "Title: On the Feasibility of Linear Interference Alignment for MIMO\n  Interference Broadcast Channels with Constant Coefficients Abstract: In this paper, we analyze the feasibility of linear interference alignment\n(IA) for multi-input-multi-output (MIMO) interference broadcast channel\n(MIMO-IBC) with constant coefficients. We pose and prove the necessary\nconditions of linear IA feasibility for general MIMO-IBC. Except for the proper\ncondition, we find another necessary condition to ensure a kind of irreducible\ninterference to be eliminated. We then prove the necessary and sufficient\nconditions for a special class of MIMO-IBC, where the numbers of antennas are\ndivisible by the number of data streams per user. Since finding an invertible\nJacobian matrix is crucial for the sufficiency proof, we first analyze the\nimpact of sparse structure and repeated structure of the Jacobian matrix.\nConsidering that for the MIMO-IBC the sub-matrices of the Jacobian matrix\ncorresponding to the transmit and receive matrices have different repeated\nstructure, we find an invertible Jacobian matrix by constructing the two\nsub-matrices separately. We show that for the MIMO-IBC where each user has one\ndesired data stream, a proper system is feasible. For symmetric MIMO-IBC, we\nprovide proper but infeasible region of antenna configurations by analyzing the\ndifference between the necessary conditions and the sufficient conditions of\nlinear IA feasibility. \n\n"}
{"id": "1207.1563", "contents": "Title: Achievable Sum-Rates in Gaussian Multiple-Access Channels with\n  MIMO-AF-Relay and Direct Links Abstract: We consider a single-antenna Gaussian multiple-access channel (MAC) with a\nmultiple-antenna amplify-and-forward (AF) relay, where, contrary to many\nprevious works, also the direct links between transmitters and receiver are\ntaken into account. For this channel, we investigate two transmit schemes:\nSending and relaying all signals jointly or using a time-division\nmultiple-access (TDMA) structure, where only one transmitter uses the channel\nat a time. While the optimal relaying matrices and time slot durations are\nfound for the latter scheme, we provide upper and lower bounds on the\nachievable sum-rate for the former one. These bounds are evaluated by Monte\nCarlo simulations, where it turns out that they are very close to each other.\nMoreover, these bounds are compared to the sum-rates achieved by the TDMA\nscheme. For the asymptotic case of high available transmit power at the relay,\nan analytic expression is given, which allows to determine the superior scheme. \n\n"}
{"id": "1207.2094", "contents": "Title: The Capacity of More Capable Cognitive Interference Channels Abstract: We establish the capacity region for a class of discrete memoryless cognitive\ninterference channel (DM-CIC) called cognitive-more-capable channel, and we\nshow that superposition coding is the optimal encoding technique. This is the\nlargest capacity region for the DM-CIC to date, as the existing capacity\nresults are explicitly shown to be its subsets. \n\n"}
{"id": "1207.2103", "contents": "Title: Precoding Methods for MISO Broadcast Channel with Delayed CSIT Abstract: Recent information theoretic results suggest that precoding on the multi-user\ndownlink MIMO channel with delayed channel state information at the transmitter\n(CSIT) could lead to data rates much beyond the ones obtained without any CSIT,\neven in extreme situations when the delayed channel feedback is made totally\nobsolete by a feedback delay exceeding the channel coherence time. This\nsurprising result is based on the ideas of interference repetition and\nalignment which allow the receivers to reconstruct information symbols which\ncanceling out the interference completely, making it an optimal scheme in the\ninfinite SNR regime. In this paper, we formulate a similar problem, yet at\nfinite SNR. We propose a first construction for the precoder which matches the\nprevious results at infinite SNR yet reaches a useful trade-off between\ninterference alignment and signal enhancement at finite SNR, allowing for\nsignificant performance improvements in practical settings. We present two\ngeneral precoding methods with arbitrary number of users by means of virtual\nMMSE and mutual information optimization, achieving good compromise between\nsignal enhancement and interference alignment. Simulation results show\nsubstantial improvement due to the compromise between those two aspects. \n\n"}
{"id": "1207.2829", "contents": "Title: Sparse Recovery with Graph Constraints Abstract: Sparse recovery can recover sparse signals from a set of underdetermined\nlinear measurements. Motivated by the need to monitor large-scale networks from\na limited number of measurements, this paper addresses the problem of\nrecovering sparse signals in the presence of network topological constraints.\nUnlike conventional sparse recovery where a measurement can contain any subset\nof the unknown variables, we use a graph to characterize the topological\nconstraints and allow an additive measurement over nodes (unknown variables)\nonly if they induce a connected subgraph. We provide explicit measurement\nconstructions for several special graphs, and the number of measurements by our\nconstruction is less than that needed by existing random constructions.\nMoreover, our construction for a line network is provably optimal in the sense\nthat it requires the minimum number of measurements. A measurement construction\nalgorithm for general graphs is also proposed and evaluated. For any given\ngraph $G$ with $n$ nodes, we derive bounds of the minimum number of\nmeasurements needed to recover any $k$-sparse vector over $G$ ($M^G_{k,n}$).\nUsing the Erd\\H{o}s-R\\'enyi random graph as an example, we characterize the\ndependence of $M^G_{k,n}$ on the graph structure. \n\n"}
{"id": "1207.4707", "contents": "Title: Correction to \"A Note on Gallager's Capacity Theorem for Waveform\n  Channels\" Abstract: We correct an alleged contradiction to Gallager's capacity theorem for\nwaveform channels as presented in a poster at the 2012 IEEE International\nSymposium on Information Theory. \n\n"}
{"id": "1207.6706", "contents": "Title: Wireless MIMO Switching: Weighted Sum Mean Square Error and Sum Rate\n  Optimization Abstract: This paper addresses joint transceiver and relay design for a wireless\nmultiple-input-multiple-output (MIMO) switching scheme that enables data\nexchange among multiple users. Here, a multi-antenna relay linearly precodes\nthe received (uplink) signals from multiple users before forwarding the signal\nin the downlink, where the purpose of precoding is to let each user receive its\ndesired signal with interference from other users suppressed. The problem of\noptimizing the precoder based on various design criteria is typically\nnon-convex and difficult to solve. The main contribution of this paper is a\nunified approach to solve the weighted sum mean square error (MSE) minimization\nand weighted sum rate maximization problems in MIMO switching. Specifically, an\niterative algorithm is proposed for jointly optimizing the relay's precoder and\nthe users' receive filters to minimize the weighted sum MSE. It is also shown\nthat the weighted sum rate maximization problem can be reformulated as an\niterated weighted sum MSE minimization problem and can therefore be solved\nsimilarly to the case of weighted sum MSE minimization. With properly chosen\ninitial values, the proposed iterative algorithms are asymptotically optimal in\nboth high and low signal-to-noise ratio (SNR) regimes for MIMO switching,\neither with or without self-interference cancellation (a.k.a., physical-layer\nnetwork coding). Numerical results show that the optimized MIMO switching\nscheme based on the proposed algorithms significantly outperforms existing\napproaches in the literature. \n\n"}
{"id": "1208.1977", "contents": "Title: Offloading in Heterogeneous Networks: Modeling, Analysis, and Design\n  Insights Abstract: Pushing data traffic from cellular to WiFi is an example of inter radio\naccess technology (RAT) offloading. While this clearly alleviates congestion on\nthe over-loaded cellular network, the ultimate potential of such offloading and\nits effect on overall system performance is not well understood. To address\nthis, we develop a general and tractable model that consists of $M$ different\nRATs, each deploying up to $K$ different tiers of access points (APs), where\neach tier differs in transmit power, path loss exponent, deployment density and\nbandwidth. Each class of APs is modeled as an independent Poisson point process\n(PPP), with mobile user locations modeled as another independent PPP, all\nchannels further consisting of i.i.d. Rayleigh fading. The distribution of rate\nover the entire network is then derived for a weighted association strategy,\nwhere such weights can be tuned to optimize a particular objective. We show\nthat the optimum fraction of traffic offloaded to maximize $\\SINR$ coverage is\nnot in general the same as the one that maximizes rate coverage, defined as the\nfraction of users achieving a given rate. \n\n"}
{"id": "1208.2387", "contents": "Title: Instantly Decodable versus Random Linear Network Coding: A Comparative\n  Framework for Throughput and Decoding Delay Performance Abstract: This paper studies the tension between throughput and decoding delay\nperformance of two widely-used network coding schemes: random linear network\ncoding (RLNC) and instantly decodable network coding (IDNC). A single-hop\nbroadcasting system model is considered that aims to deliver a block of packets\nto all receivers in the presence of packet erasures. For a fair and\nanalytically tractable comparison between the two coding schemes, the\ntransmission comprises two phases: a systematic transmission phase and a\nnetwork coded transmission phase which is further divided into rounds. After\nthe systematic transmission phase and given the same packet reception state,\nthree quantitative metrics are proposed and derived in each scheme: 1) the\nabsolute minimum number of transmissions in the first coded transmission round\n(assuming no erasures), 2) probability distribution of extra coded\ntransmissions in a subsequent round (due to erasures), and 3) average packet\ndecoding delay. This comparative study enables application-aware adaptive\nselection between IDNC and RLNC after systematic transmission phase.\n  One contribution of this paper is to provide a deep and systematic\nunderstanding of the IDNC scheme, to propose the notion of packet diversity and\nan optimal IDNC encoding scheme for minimizing metric 1. This is generally\nNP-hard, but nevertheless required for characterizing and deriving all the\nthree metrics. Analytical and numerical results show that there is no clear\nwinner between RLNC and IDNC if one is concerned with both throughput and\ndecoding delay performance. IDNC is more preferable than RLNC when the number\nof receivers is smaller than packet block size, and the case reverses when the\nnumber of receivers is much greater than the packet block size. In the middle\nregime, the choice can depend on the application and a specific instance of the\nproblem. \n\n"}
{"id": "1208.3806", "contents": "Title: Dynamic Rate Adaptation for Improved Throughput and Delay in Wireless\n  Network Coded Broadcast Abstract: In this paper we provide theoretical and simulation-based study of the\ndelivery delay performance of a number of existing throughput optimal coding\nschemes and use the results to design a new dynamic rate adaptation scheme that\nachieves improved overall throughput-delay performance.\n  Under a baseline rate control scheme, the receivers' delay performance is\nexamined. Based on their Markov states, the knowledge difference between the\nsender and receiver, three distinct methods for packet delivery are identified:\nzero state, leader state and coefficient-based delivery. We provide analyses of\neach of these and show that, in many cases, zero state delivery alone presents\na tractable approximation of the expected packet delivery behaviour.\nInterestingly, while coefficient-based delivery has so far been treated as a\nsecondary effect in the literature, we find that the choice of coefficients is\nextremely important in determining the delay, and a well chosen encoding scheme\ncan, in fact, contribute a significant improvement to the delivery delay.\n  Based on our delivery delay model, we develop a dynamic rate adaptation\nscheme which uses performance prediction models to determine the sender\ntransmission rate. Surprisingly, taking this approach leads us to the simple\nconclusion that the sender should regulate its addition rate based on the total\nnumber of undelivered packets stored at the receivers. We show that despite its\nsimplicity, our proposed dynamic rate adaptation scheme results in noticeably\nimproved throughput-delay performance over existing schemes in the literature. \n\n"}
{"id": "1208.6125", "contents": "Title: Bounded-Contention Coding for Wireless Networks in the High SNR Regime Abstract: Efficient communication in wireless networks is typically challenged by the\npossibility of interference among several transmitting nodes. Much important\nresearch has been invested in decreasing the number of collisions in order to\nobtain faster algorithms for communication in such networks.\n  This paper proposes a novel approach for wireless communication, which\nembraces collisions rather than avoiding them, over an additive channel. It\nintroduces a coding technique called Bounded-Contention Coding (BCC) that\nallows collisions to be successfully decoded by the receiving nodes into the\noriginal transmissions and whose complexity depends on a bound on the\ncontention among the transmitters.\n  BCC enables deterministic local broadcast in a network with n nodes and at\nmost a transmitters with information of l bits each within O(a log n + al) bits\nof communication with full-duplex radios, and O((a log n + al)(log n)) bits,\nwith high probability, with half-duplex radios. When combined with random\nlinear network coding, BCC gives global broadcast within O((D + a + log n)(a\nlog n + l)) bits, with high probability. This also holds in dynamic networks\nthat can change arbitrarily over time by a worst-case adversary. When no bound\non the contention is given, it is shown how to probabilistically estimate it\nand obtain global broadcast that is adaptive to the true contention in the\nnetwork. \n\n"}
{"id": "1209.0245", "contents": "Title: Diffusion maps for changing data Abstract: Graph Laplacians and related nonlinear mappings into low dimensional spaces\nhave been shown to be powerful tools for organizing high dimensional data. Here\nwe consider a data set X in which the graph associated with it changes\ndepending on some set of parameters. We analyze this type of data in terms of\nthe diffusion distance and the corresponding diffusion map. As the data changes\nover the parameter space, the low dimensional embedding changes as well. We\ngive a way to go between these embeddings, and furthermore, map them all into a\ncommon space, allowing one to track the evolution of X in its intrinsic\ngeometry. A global diffusion distance is also defined, which gives a measure of\nthe global behavior of the data over the parameter space. Approximation\ntheorems in terms of randomly sampled data are presented, as are potential\napplications. \n\n"}
{"id": "1209.1380", "contents": "Title: The Sample Complexity of Search over Multiple Populations Abstract: This paper studies the sample complexity of searching over multiple\npopulations. We consider a large number of populations, each corresponding to\neither distribution P0 or P1. The goal of the search problem studied here is to\nfind one population corresponding to distribution P1 with as few samples as\npossible. The main contribution is to quantify the number of samples needed to\ncorrectly find one such population. We consider two general approaches:\nnon-adaptive sampling methods, which sample each population a predetermined\nnumber of times until a population following P1 is found, and adaptive sampling\nmethods, which employ sequential sampling schemes for each population. We first\nderive a lower bound on the number of samples required by any sampling scheme.\nWe then consider an adaptive procedure consisting of a series of sequential\nprobability ratio tests, and show it comes within a constant factor of the\nlower bound. We give explicit expressions for this constant when samples of the\npopulations follow Gaussian and Bernoulli distributions. An alternative\nadaptive scheme is discussed which does not require full knowledge of P1, and\ncomes within a constant factor of the optimal scheme. For comparison, a lower\nbound on the sampling requirements of any non-adaptive scheme is presented. \n\n"}
{"id": "1209.1402", "contents": "Title: Joint Spatial Division and Multiplexing Abstract: We propose Joint Spatial Division and Multiplexing (JSDM), an approach to\nmultiuser MIMO downlink that exploits the structure of the correlation of the\nchannel vectors in order to allow for a large number of antennas at the base\nstation while requiring reduced-dimensional Channel State Information at the\nTransmitter (CSIT). This allows for significant savings both in the downlink\ntraining and in the CSIT feedback from the user terminals to the base station,\nthus making the use of a large number of base station antennas potentially\nsuitable also for Frequency Division Duplexing (FDD) systems, for which\nuplink/downlink channel reciprocity cannot be exploited. JSDM forms the\nmultiuser MIMO downlink precoder by concatenating a pre-beamforming matrix,\nwhich depends only on the channel second-order statistics, with a classical\nmultiuser precoder, based on the instantaneous knowledge of the resulting\nreduced dimensional effective channels. We prove a simple condition under which\nJSDM incurs no loss of optimality with respect to the full CSIT case. For\nlinear uniformly spaced arrays, we show that such condition is closely\napproached when the number of antennas is large. For this case, we use Szego\nasymptotic theory of large Toeplitz matrices to design a DFT-based\npre-beamforming scheme requiring only coarse information about the users angles\nof arrival and angular spread. Finally, we extend these ideas to the case of a\ntwo-dimensional base station antenna array, with 3-dimensional beamforming,\nincluding multiple beams in the elevation angle direction. We provide\nguidelines for the pre-beamforming optimization and calculate the system\nspectral efficiency under proportional fairness and maxmin fairness criteria,\nshowing extremely attractive performance. Our numerical results are obtained\nvia an asymptotic random matrix theory tool known as deterministic equivalent\napproximation. \n\n"}
{"id": "1209.2138", "contents": "Title: Optimality Properties, Distributed Strategies, and Measurement-Based\n  Evaluation of Coordinated Multicell OFDMA Transmission Abstract: The throughput of multicell systems is inherently limited by interference and\nthe available communication resources. Coordinated resource allocation is the\nkey to efficient performance, but the demand on backhaul signaling and\ncomputational resources grows rapidly with number of cells, terminals, and\nsubcarriers. To handle this, we propose a novel multicell framework with\ndynamic cooperation clusters where each terminal is jointly served by a small\nset of base stations. Each base station coordinates interference to neighboring\nterminals only, thus limiting backhaul signalling and making the framework\nscalable. This framework can describe anything from interference channels to\nideal joint multicell transmission.\n  The resource allocation (i.e., precoding and scheduling) is formulated as an\noptimization problem (P1) with performance described by arbitrary monotonic\nfunctions of the signal-to-interference-and-noise ratios (SINRs) and arbitrary\nlinear power constraints. Although (P1) is non-convex and difficult to solve\noptimally, we are able to prove: 1) Optimality of single-stream beamforming; 2)\nConditions for full power usage; and 3) A precoding parametrization based on a\nfew parameters between zero and one. These optimality properties are used to\npropose low-complexity strategies: both a centralized scheme and a distributed\nversion that only requires local channel knowledge and processing. We evaluate\nthe performance on measured multicell channels and observe that the proposed\nstrategies achieve close-to-optimal performance among centralized and\ndistributed solutions, respectively. In addition, we show that multicell\ninterference coordination can give substantial improvements in sum performance,\nbut that joint transmission is very sensitive to synchronization errors and\nthat some terminals can experience performance degradations. \n\n"}
{"id": "1209.3366", "contents": "Title: Implement Blind Interference Alignment over Homogeneous 3-user 2x1\n  Broadcast Channel Abstract: This paper first studies the homogeneous 3-user 2x1 broadcast channel (BC)\nwith no CSIT. We show a sufficient condition for it to achieve the optimal 3/2\ndegrees of freedom (DoF) by using Blind Interference Alignment (BIA). BIA\nrefers to the interference alignment method without the need of CSIT. It\nfurther studies the 2x1 broadcast network in which there are K>=3 homogeneous\nsingle-antenna users, and their coherence time offsets are independently and\nuniformly distributed. We show that, if K>=11, the two-antenna transmitter can\nfind, with more than 95% certainty, three users to form a BIA-feasible 3-user\nBC and achieve the optimal 3/2 DoF. \n\n"}
{"id": "1209.3505", "contents": "Title: Cognitive Energy Harvesting and Transmission from a Network Perspective Abstract: Wireless networks can be self-sustaining by harvesting energy from\nradio-frequency (RF) signals. Building on classic cognitive radio networks, we\npropose a novel method for network coexisting where mobiles from a secondary\nnetwork, called secondary transmitters (STs), either harvest energy from\ntransmissions by nearby transmitters from a primary network, called primary\ntransmitters (PTs), or transmit information if PTs are sufficiently far away;\nSTs store harvested energy in rechargeable batteries with finite capacity and\nuse all available energy for subsequent transmission when batteries are fully\ncharged. In this model, each PT is centered at a guard zone and a harvesting\nzone that are disks with given radiuses; a ST harvests energy if it lies in\nsome harvesting zone, transmits fixed-power signals if it is outside all guard\nzones or else idles. Based on this model, the spatial throughput of the\nsecondary network is maximized using a stochastic-geometry model where PTs and\nSTs are modeled as independent homogeneous Poisson point processes (HPPPs),\nunder the outage constraints for coexisting networks and obtained in a simple\nclosed-form. It is observed from the result that the maximum secondary\nthroughput decreases linearly with the growing PT density, and the optimal ST\ndensity is inversely proportional to the derived transmission probability for\nSTs. \n\n"}
{"id": "1209.4414", "contents": "Title: On Cyclic DNA Codes Abstract: This paper considers cyclic DNA codes of arbitrary length over the ring\n$R=\\F_2[u]/u^4-1$. A mapping is given between the elements of $R$ and the\nalphabet $\\{A,C,G,T\\}$ which allows the additive stem distance to be extended\nto this ring. Cyclic codes over $R$ are designed such that their images under\nthe mapping are also cyclic or quasi-cyclic of index 2. The additive distance\nand hybridization energy are functions of the neighborhood energy. \n\n"}
{"id": "1209.5259", "contents": "Title: Entropy Bounds for Discrete Random Variables via Maximal Coupling Abstract: This paper derives new bounds on the difference of the entropies of two\ndiscrete random variables in terms of the local and total variation distances\nbetween their probability mass functions. The derivation of the bounds relies\non maximal coupling, and they apply to discrete random variables which are\ndefined over finite or countably infinite alphabets. Loosened versions of these\nbounds are demonstrated to reproduce some previously reported results. The use\nof the new bounds is exemplified for the Poisson approximation, where bounds on\nthe local and total variation distances follow from Stein's method. \n\n"}
{"id": "1209.5656", "contents": "Title: Learning Price-Elasticity of Smart Consumers in Power Distribution\n  Systems Abstract: Demand Response is an emerging technology which will transform the power grid\nof tomorrow. It is revolutionary, not only because it will enable peak load\nshaving and will add resources to manage large distribution systems, but mainly\nbecause it will tap into an almost unexplored and extremely powerful pool of\nresources comprised of many small individual consumers on distribution grids.\nHowever, to utilize these resources effectively, the methods used to engage\nthese resources must yield accurate and reliable control. A diversity of\nmethods have been proposed to engage these new resources. As opposed to direct\nload control, many methods rely on consumers and/or loads responding to\nexogenous signals, typically in the form of energy pricing, originating from\nthe utility or system operator. Here, we propose an open loop\ncommunication-lite method for estimating the price elasticity of many customers\ncomprising a distribution system. We utilize a sparse linear regression method\nthat relies on operator-controlled, inhomogeneous minor price variations, which\nwill be fair to all the consumers. Our numerical experiments show that reliable\nestimation of individual and thus aggregated instantaneous elasticities is\npossible. We describe the limits of the reliable reconstruction as functions of\nthe three key parameters of the system: (i) ratio of the number of\ncommunication slots (time units) per number of engaged consumers; (ii) level of\nsparsity (in consumer response); and (iii) signal-to-noise ratio. \n\n"}
{"id": "1209.6412", "contents": "Title: Integer-Forcing MIMO Linear Receivers Based on Lattice Reduction Abstract: A new architecture called integer-forcing (IF) linear receiver has been\nrecently proposed for multiple-input multiple-output (MIMO) fading channels,\nwherein an appropriate integer linear combination of the received symbols has\nto be computed as a part of the decoding process. In this paper, we propose a\nmethod based on Hermite-Korkine-Zolotareff (HKZ) and Minkowski lattice basis\nreduction algorithms to obtain the integer coefficients for the IF receiver. We\nshow that the proposed method provides a lower bound on the ergodic rate, and\nachieves the full receive diversity. Suitability of complex\nLenstra-Lenstra-Lovasz (LLL) lattice reduction algorithm (CLLL) to solve the\nproblem is also investigated. Furthermore, we establish the connection between\nthe proposed IF linear receivers and lattice reduction-aided MIMO detectors\n(with equivalent complexity), and point out the advantages of the former class\nof receivers over the latter. For the $2 \\times 2$ and $4\\times 4$ MIMO\nchannels, we compare the coded-block error rate and bit error rate of the\nproposed approach with that of other linear receivers. Simulation results show\nthat the proposed approach outperforms the zero-forcing (ZF) receiver, minimum\nmean square error (MMSE) receiver, and the lattice reduction-aided MIMO\ndetectors. \n\n"}
{"id": "1210.2019", "contents": "Title: On the relation of nonanticipative rate distortion function and\n  filtering theory Abstract: In this paper the relation between nonanticipative rate distortion function\n(RDF) and Bayesian filtering theory is investigated using the topology of weak\nconvergence of probability measures on Polish spaces. The relation is\nestablished via an optimization on the space of conditional distributions of\nthe so-called directed information subject to fidelity constraints. Existence\nof the optimal reproduction distribution of the nonanticipative RDF is shown,\nwhile the optimal nonanticipative reproduction conditional distribution for\nstationary processes is derived in closed form. The realization procedure of\nnonanticipative RDF which is equivalent to joint-source channel matching for\nsymbol-by-symbol transmission is described, while an example is introduced to\nillustrate the concepts. \n\n"}
{"id": "1210.2182", "contents": "Title: Approximate Ergodic Capacity of a Class of Fading 2-user 2-hop Networks Abstract: We consider a fading AWGN 2-user 2-hop network where the channel coefficients\nare independent and identically distributed (i.i.d.) drawn from a continuous\ndistribution and vary over time. For a broad class of channel distributions, we\ncharacterize the ergodic sum capacity to within a constant number of\nbits/sec/Hz, independent of signal-to-noise ratio. The achievability follows\nfrom the analysis of an interference neutralization scheme where the relays are\npartitioned into $M$ pairs, and interference is neutralized separately by each\npair of relays. When $M=1$, the proposed ergodic interference neutralization\ncharacterizes the ergodic sum capacity to within $4$ bits/sec/Hz for i.i.d.\nuniform phase fading and approximately $4.7$ bits/sec/Hz for i.i.d. Rayleigh\nfading. We further show that this gap can be tightened to $4\\log \\pi-4$\nbits/sec/Hz (approximately $2.6$) for i.i.d. uniform phase fading and $4-4\\log(\n\\frac{3\\pi}{8})$ bits/sec/Hz (approximately $3.1$) for i.i.d. Rayleigh fading\nin the limit of large $M$. \n\n"}
{"id": "1210.3667", "contents": "Title: A New Analysis of the DS-CDMA Cellular Downlink Under Spatial\n  Constraints Abstract: The direct-sequence code-division multiple access (DS-CDMA) cellular downlink\nis modeled by a constrained random spatial model involving a fixed number of\nbase stations placed over a finite area with a minimum separation. The analysis\nis driven by a new closed-form expression for the conditional outage\nprobability at each mobile, where the conditioning is with respect to the\nnetwork realization. The analysis features a flexible channel model, accounting\nfor path loss, Nakagami fading, and shadowing. By generating many random\nnetworks and applying a given resource allocation policy, the distribution of\nthe rates provided to each user is obtained. In addition to determining the\naverage rate, the analysis can determine the transmission capacity of the\nnetwork and can characterize fairness in terms of the fraction of users that\nachieve a specified rate. The analysis is used to compare a rate-control policy\nagainst a power-control policy and investigate the influence of the minimum\nbase-station separation. \n\n"}
{"id": "1210.5424", "contents": "Title: Implementation of Distributed Time Exchange Based Cooperative Forwarding Abstract: In this paper, we design and implement time exchange (TE) based cooperative\nforwarding where nodes use transmission time slots as incentives for relaying.\nWe focus on distributed joint time slot exchange and relay selection in the sum\ngoodput maximization of the overall network. We formulate the design objective\nas a mixed integer nonlinear programming (MINLP) problem and provide a\npolynomial time distributed solution of the MINLP. We implement the designed\nalgorithm in the software defined radio enabled USRP nodes of the ORBIT indoor\nwireless testbed. The ORBIT grid is used as a global control plane for exchange\nof control information between the USRP nodes. Experimental results suggest\nthat TE can significantly increase the sum goodput of the network. We also\ndemonstrate the performance of a goodput optimization algorithm that is\nproportionally fair. \n\n"}
{"id": "1210.5470", "contents": "Title: The DoF of Network MIMO with Backhaul Delays Abstract: We consider the problem of downlink precoding for Network (multi-cell) MIMO\nnetworks where Transmitters (TXs) are provided with imperfect Channel State\nInformation (CSI). Specifically, each TX receives a delayed channel estimate\nwith the delay being specific to each channel component. This model is\nparticularly adapted to the scenarios where a user feeds back its CSI to its\nserving base only as it is envisioned in future LTE networks. We analyze the\nimpact of the delay during the backhaul-based CSI exchange on the rate\nperformance achieved by Network MIMO. We highlight how delay can dramatically\ndegrade system performance if existing precoding methods are to be used. We\npropose an alternative robust beamforming strategy which achieves the maximal\nperformance, in DoF sense. We verify by simulations that the theoretical DoF\nimprovement translates into a performance increase at finite Signal-to-Noise\nRatio (SNR) as well. \n\n"}
{"id": "1210.5991", "contents": "Title: Online Recovery Guarantees and Analytical Results for OMP Abstract: Orthogonal Matching Pursuit (OMP) is a simple, yet empirically competitive\nalgorithm for sparse recovery. Recent developments have shown that OMP\nguarantees exact recovery of K-sparse signals with K or more than K iterations\nif the observation matrix satisfies the restricted isometry property (RIP) with\nsome conditions. We develop RIP-based online guarantees for recovery of a\nK-sparse signal with more than K OMP iterations. Though these guarantees cannot\nbe generalized to all sparse signals a priori, we show that they can still hold\nonline when the state-of-the-art K-step recovery guarantees fail. In addition,\nwe present bounds on the number of correct and false indices in the support\nestimate for the derived condition to be less restrictive than the K-step\nguarantees. Under these bounds, this condition guarantees exact recovery of a\nK-sparse signal within 3K/2 iterations, which is much less than the number of\nsteps required for the state-of-the-art exact recovery guarantees with more\nthan K steps. Moreover, we present phase transitions of OMP in comparison to\nbasis pursuit and subspace pursuit, which are obtained after extensive recovery\nsimulations involving different sparse signal types. Finally, we empirically\nanalyse the number of false indices in the support estimate, which indicates\nthat these do not violate the developed upper bound in practice. \n\n"}
{"id": "1210.6673", "contents": "Title: Semantically Secure Lattice Codes for the Gaussian Wiretap Channel Abstract: We propose a new scheme of wiretap lattice coding that achieves semantic\nsecurity and strong secrecy over the Gaussian wiretap channel. The key tool in\nour security proof is the flatness factor which characterizes the convergence\nof the conditional output distributions corresponding to different messages and\nleads to an upper bound on the information leakage. We not only introduce the\nnotion of secrecy-good lattices, but also propose the {flatness factor} as a\ndesign criterion of such lattices. Both the modulo-lattice Gaussian channel and\nthe genuine Gaussian channel are considered. In the latter case, we propose a\nnovel secrecy coding scheme based on the discrete Gaussian distribution over a\nlattice, which achieves the secrecy capacity to within a half nat under mild\nconditions. No \\textit{a priori} distribution of the message is assumed, and no\ndither is used in our proposed schemes. \n\n"}
{"id": "1210.8253", "contents": "Title: Ranks of propelinear perfect binary codes Abstract: It is proven that for any numbers n=2^m-1, m >= 4 and r, such that n -\nlog(n+1)<= r <= n excluding n = r = 63, n = 127, r in {126,127} and n = r =\n2047 there exists a propelinear perfect binary code of length n and rank r. \n\n"}
{"id": "1211.0985", "contents": "Title: Interactive Interference Alignment Abstract: We study interference channels (IFC) where interaction among sources and\ndestinations is enabled, e.g., both sources and destinations can talk to each\nother using full-duplex radios. The interaction can come in two ways: 1) {\\em\nIn-band interaction:} sources and destinations can transmit and listen in the\nsame channel simultaneously, enabling interaction. 2) {\\em out-of-band\ninteraction:} destinations talk back to the sources on an out-of-band channel,\npossible from white-space channels. The flexibility afforded by interaction\namong sources and destinations allows for the derivation of interference\nalignment (IA) strategies that have desirable \"engineering properties\":\ninsensitivity to the rationality or irrationality of channel parameters, small\nblock lengths and finite SNR operations. We show that for several classes of\ninterference channels the interactive interference alignment scheme can achieve\nthe optimal degrees of freedom. In particular, we show the {\\em first simple\nscheme} (having finite block length, for channels having no diversity) for\n$K=3,4$ that can achieve the optimal degrees of freedom of $\\frac{K}{2}$ even\nafter accounting for the cost of interaction. We also give simulation results\non the finite SNR performance of interactive alignment under some settings.\n  On the technical side, we show using a Gr\\\"{o}bner basis argument that in a\ngeneral network potentially utilizing cooperation and feedback, the optimal\ndegrees of freedom under linear schemes of a fixed block length is the same for\nchannel coefficients with probability 1. Furthermore, a numerical method to\nestimate this value is also presented. These tools have potentially wider\nutility in studying other wireless networks as well. \n\n"}
{"id": "1211.3322", "contents": "Title: The Degrees of Freedom Region of Temporally-Correlated MIMO Networks\n  with Delayed CSIT Abstract: We consider the temporally-correlated Multiple-Input Multiple-Output (MIMO)\nbroadcast channels (BC) and interference channels (IC) where the transmitter(s)\nhas/have (i) delayed channel state information (CSI) obtained from a\nlatency-prone feedback channel as well as (ii) imperfect current CSIT,\nobtained, e.g., from prediction on the basis of these past channel samples\nbased on the temporal correlation. The degrees of freedom (DoF) regions for the\ntwo-user broadcast and interference MIMO networks with general antenna\nconfiguration under such conditions are fully characterized, as a function of\nthe prediction quality indicator. Specifically, a simple unified framework is\nproposed, allowing to attain optimal DoF region for the general antenna\nconfigurations and current CSIT qualities. Such a framework builds upon\nblock-Markov encoding with interference quantization, optimally combining the\nuse of both outdated and instantaneous CSIT. A striking feature of our work is\nthat, by varying the power allocation, every point in the DoF region can be\nachieved with one single scheme. As a result, instead of checking the\nachievability of every corner point of the outer bound region, as typically\ndone in the literature, we propose a new systematic way to prove the\nachievability. \n\n"}
{"id": "1211.4198", "contents": "Title: Degrees of Freedom of the 3-User Rank-Deficient MIMO Interference\n  Channel Abstract: We provide the degrees of freedom (DoF) characterization for the $3$-user\n$M_T\\times M_R$ multiple-input multiple-output (MIMO) interference channel (IC)\nwith \\emph{rank-deficient} channel matrices, where each transmitter is equipped\nwith $M_T$ antennas and each receiver with $M_R$ antennas, and the interfering\nchannel matrices from each transmitter to the other two receivers are of ranks\n$D_1$ and $D_2$, respectively. One important intermediate step for both the\nconverse and achievability arguments is to convert the fully-connected\nrank-deficient channel into an equivalent partially-connected full-rank MIMO-IC\nby invertible linear transformations. As such, existing techniques developed\nfor full-rank MIMO-IC can be incorporated to derive the DoF outer and inner\nbounds for the rank-deficient case. Our result shows that when the interfering\nlinks are weak in terms of the channel ranks, i.e., $D_1+D_2\\leq \\min(M_T,\nM_R)$, zero forcing is sufficient to achieve the optimal DoF. On the other\nhand, when $D_1+D_2> \\min(M_T, M_R)$, a combination of zero forcing and\ninterference alignment is in general required for DoF optimality. The DoF\ncharacterization obtained in this paper unifies several existing results in the\nliterature. \n\n"}
{"id": "1211.4392", "contents": "Title: Cost Efficient High Capacity Indoor Wireless Access: Denser Wi-Fi or\n  Coordinated Pico-cellular? Abstract: Rapidly increasing traffic demand has forced indoor operators to deploy more\nand more Wi-Fi access points (APs). As AP density increases, inter-AP\ninterference rises and may limit the capacity. Alternatively, cellular\ntechnologies using centralized interference coordination can provide the same\ncapacity with the fewer number of APs at the price of more expensive equipment\nand installation cost. It is still not obvious at what demand level more\nsophisticated coordination pays off in terms of total system cost. To make this\ncomparison, we assess the required AP density of three candidate systems for a\ngiven average demand: a Wi-Fi network, a conventional pico-cellular network\nwith frequency planning, and an advanced system employing multi-cell joint\nprocessing. Numerical results show that dense Wi-Fi is the cheapest solution at\na relatively low demand level. However, the AP density grows quickly at a\ncritical demand level regardless of propagation conditions. Beyond this Wi-Fi\nnetwork limit, the conventional pico-cellular network works and is cheaper than\nthe joint processing in obstructed environments, e.g., furnished offices with\nwalls. In line of sight condition such as stadiums, the joint processing\nbecomes the most viable solution. The drawback is that extremely accurate\nchannel state information at transmitters is needed. \n\n"}
{"id": "1211.5884", "contents": "Title: Low complexity sum rate maximization for single and multiple stream MIMO\n  AF relay networks Abstract: A multiple-antenna amplify-and-forward two-hop interference network with\nmultiple links and multiple relays is considered. We optimize transmit\nprecoders, receive decoders and relay AF matrices to maximize the achievable\nsum rate. Under per user and total relay sum power constraints, we propose an\nefficient algorithm to maximize the total signal to total interference plus\nnoise ratio (TSTINR). Computational complexity analysis shows that our proposed\nalgorithm for TSTINR has lower complexity than the existing weighted minimum\nmean square error (WMMSE) algorithm. We analyze and confirm by simulations that\nthe TSTINR, WMMSE and the total leakage interference plus noise (TLIN)\nminimization models with per user and total relay sum power constraints can\nonly transmit a single data stream for each user. Thus we propose a novel\nmultiple stream TSTINR model with requirement of orthogonal columns for\nprecoders, in order to support multiple data streams and thus utilize higher\nDegrees of Freedom. Multiple data streams and larger multiplexing gains are\nguaranteed. Simulation results show that for single stream models, our TSTINR\nalgorithm outperforms the TLIN algorithm generally and outperforms WMMSE in\nmedium to high Signal-to-Noise-Ratio scenarios; the system sum rate\nsignificantly benefits from multiple data streams in medium to high SNR\nscenarios. \n\n"}
{"id": "1211.5914", "contents": "Title: A survey of uncertainty principles and some signal processing\n  applications Abstract: The goal of this paper is to review the main trends in the domain of\nuncertainty principles and localization, emphasize their mutual connections and\ninvestigate practical consequences. The discussion is strongly oriented\ntowards, and motivated by signal processing problems, from which significant\nadvances have been made recently. Relations with sparse approximation and\ncoding problems are emphasized. \n\n"}
{"id": "1212.0877", "contents": "Title: Toeplitz Matrix Based Sparse Error Correction in System Identification:\n  Outliers and Random Noises Abstract: In this paper, we consider robust system identification under sparse outliers\nand random noises. In our problem, system parameters are observed through a\nToeplitz matrix. All observations are subject to random noises and a few are\ncorrupted with outliers. We reduce this problem of system identification to a\nsparse error correcting problem using a Toeplitz structured real-numbered\ncoding matrix. We prove the performance guarantee of Toeplitz structured matrix\nin sparse error correction. Thresholds on the percentage of correctable errors\nfor Toeplitz structured matrices are also established. When both outliers and\nobservation noise are present, we have shown that the estimation error goes to\n0 asymptotically as long as the probability density function for observation\nnoise is not \"vanishing\" around 0. \n\n"}
{"id": "1212.2537", "contents": "Title: Polar codes for private and quantum communication over arbitrary\n  channels Abstract: We construct new polar coding schemes for the transmission of quantum or\nprivate classical information over arbitrary quantum channels. In the former\ncase, our coding scheme achieves the symmetric coherent information and in the\nlatter the symmetric private information. Both schemes are built from a polar\ncoding construction capable of transmitting classical information over a\nquantum channel [Wilde and Guha, IEEE Transactions on Information Theory, in\npress]. Appropriately merging two such classical-quantum schemes, one for\ntransmitting \"amplitude\" information and the other for transmitting \"phase,\"\nleads to the new private and quantum coding schemes, similar to the\nconstruction for Pauli and erasure channels in [Renes, Dupuis, and Renner,\nPhysical Review Letters 109, 050504 (2012)]. The encoding is entirely similar\nto the classical case, and thus efficient. The decoding can also be performed\nby successive cancellation, as in the classical case, but no efficient\nsuccessive cancellation scheme is yet known for arbitrary quantum channels. An\nefficient code construction is unfortunately still unknown. Generally, our two\ncoding schemes require entanglement or secret-key assistance, respectively, but\nwe extend two known conditions under which the needed assistance rate vanishes.\nFinally, although our results are formulated for qubit channels, we show how\nthe scheme can be extended to multiple qubits. This then demonstrates a\nnear-explicit coding method for realizing one of the most striking phenomena in\nquantum information theory: the superactivation effect, whereby two quantum\nchannels which individually have zero quantum capacity can have a non-zero\nquantum capacity when used together. \n\n"}
{"id": "1212.3170", "contents": "Title: Improving Macrocell - Small Cell Coexistence through Adaptive\n  Interference Draining Abstract: The deployment of underlay small base stations (SBSs) is expected to\nsignificantly boost the spectrum efficiency and the coverage of next-generation\ncellular networks. However, the coexistence of SBSs underlaid to an existing\nmacro-cellular network faces important challenges, notably in terms of spectrum\nsharing and interference management. In this paper, we propose a novel\ngame-theoretic model that enables the SBSs to optimize their transmission rates\nby making decisions on the resource occupation jointly in the frequency and\nspatial domains. This procedure, known as interference draining, is performed\namong cooperative SBSs and allows to drastically reduce the interference\nexperienced by both macro- and small cell users. At the macrocell side, we\nconsider a modified water-filling policy for the power allocation that allows\neach macrocell user (MUE) to focus the transmissions on the degrees of freedom\nover which the MUE experiences the best channel and interference conditions.\nThis approach not only represents an effective way to decrease the received\ninterference at the MUEs but also grants the SBSs tier additional transmission\nopportunities and allows for a more agile interference management. Simulation\nresults show that the proposed approach yields significant gains at both\nmacrocell and small cell tiers, in terms of average achievable rate per user,\nreaching up to 37%, relative to the non-cooperative case, for a network with\n150 MUEs and 200 SBSs. \n\n"}
{"id": "1212.6009", "contents": "Title: Distributed Sparse Signal Recovery For Sensor Networks Abstract: We propose a distributed algorithm for sparse signal recovery in sensor\nnetworks based on Iterative Hard Thresholding (IHT). Every agent has a set of\nmeasurements of a signal x, and the objective is for the agents to recover x\nfrom their collective measurements at a minimal communication cost and with low\ncomputational complexity. A naive distributed implementation of IHT would\nrequire global communication of every agent's full state in each iteration. We\nfind that we can dramatically reduce this communication cost by leveraging\nsolutions to the distributed top-K problem in the database literature.\nEvaluations show that our algorithm requires up to three orders of magnitude\nless total bandwidth than the best-known distributed basis pursuit method. \n\n"}
{"id": "1301.1760", "contents": "Title: Carrier phase and amplitude estimation for phase shift keying using\n  pilots and data Abstract: We consider least squares estimators of carrier phase and amplitude from a\nnoisy communications signal that contains both pilot signals, known to the\nreceiver, and data signals, unknown to the receiver. We focus on signaling\nconstellations that have symbols evenly distributed on the complex unit circle,\ni.e., M-ary phase shift keying. We show, under reasonably mild conditions on\nthe distribution of the noise, that the least squares estimator of carrier\nphase is strongly consistent and asymptotically normally distributed. However,\nthe amplitude estimator is not consistent, but converges to a positive real\nnumber that is a function of the true carrier amplitude, the noise distribution\nand the size of the constellation. Our theoretical results can also be applied\nto the case where no pilot symbols exist, i.e., noncoherent detection. The\nresults of Monte Carlo simulations are provided and these agree with the\ntheoretical results. \n\n"}
{"id": "1301.3106", "contents": "Title: Topological Interference Management through Index Coding Abstract: This work studies linear interference networks, both wired and wireless, with\nno channel state information at the transmitters (CSIT) except a coarse\nknowledge of the end-to-end one-hop topology of the network that only allows a\ndistinction between weak (zero) and significant (non-zero) channels and no\nfurther knowledge of the channel coefficients' realizations. The network\ncapacity (wired) and DoF (wireless) are found to be bounded above by the\ncapacity of an index coding problem for which the antidote graph is the\ncomplement of the given interference graph. The problems are shown to be\nequivalent under linear solutions. An interference alignment perspective is\nthen used to translate the existing index coding solutions into the wired\nnetwork capacity and wireless network DoF solutions, as well as to find new and\nunified solutions to different classes of all three problems. \n\n"}
{"id": "1301.3991", "contents": "Title: Generic Regular Decompositions for Parametric Polynomial Systems Abstract: This paper presents a generalization of our earlier work in [19]. In this\npaper, the two concepts, generic regular decomposition (GRD) and\nregular-decomposition-unstable (RDU) variety introduced in [19] for generic\nzero-dimensional systems, are extended to the case where the parametric systems\nare not necessarily zero-dimensional. An algorithm is provided to compute GRDs\nand the associated RDU varieties of parametric systems simultaneously on the\nbasis of the algorithm for generic zero-dimensional systems proposed in [19].\nThen the solutions of any parametric system can be represented by the solutions\nof finitely many regular systems and the decomposition is stable at any\nparameter value in the complement of the associated RDU variety of the\nparameter space. The related definitions and the results presented in [19] are\nalso generalized and a further discussion on RDU varieties is given from an\nexperimental point of view. The new algorithm has been implemented on the basis\nof DISCOVERER with Maple 16 and experimented with a number of benchmarks from\nthe literature. \n\n"}
{"id": "1301.5044", "contents": "Title: Performance Analysis of Heterogeneous Feedback Design in an OFDMA\n  Downlink with Partial and Imperfect Feedback Abstract: Current OFDMA systems group resource blocks into subband to form the basic\nfeedback unit. Homogeneous feedback design with a common subband size is not\naware of the heterogeneous channel statistics among users. Under a general\ncorrelated channel model, we demonstrate the gain of matching the subband size\nto the underlying channel statistics motivating heterogeneous feedback design\nwith different subband sizes and feedback resources across clusters of users.\nEmploying the best-M partial feedback strategy, users with smaller subband size\nwould convey more partial feedback to match the frequency selectivity. In order\nto develop an analytical framework to investigate the impact of partial\nfeedback and potential imperfections, we leverage the multi-cluster subband\nfading model. The perfect feedback scenario is thoroughly analyzed, and the\nclosed form expression for the average sum rate is derived for the\nheterogeneous partial feedback system. We proceed to examine the effect of\nimperfections due to channel estimation error and feedback delay, which leads\nto additional consideration of system outage. Two transmission strategies: the\nfix rate and the variable rate, are considered for the outage analysis. We also\ninvestigate how to adapt to the imperfections in order to maximize the average\ngoodput under heterogeneous partial feedback. \n\n"}
{"id": "1301.5848", "contents": "Title: Decentralized Coded Caching Attains Order-Optimal Memory-Rate Tradeoff Abstract: Replicating or caching popular content in memories distributed across the\nnetwork is a technique to reduce peak network loads. Conventionally, the main\nperformance gain of this caching was thought to result from making part of the\nrequested data available closer to end users. Instead, we recently showed that\na much more significant gain can be achieved by using caches to create\ncoded-multicasting opportunities, even for users with different demands,\nthrough coding across data streams. These coded-multicasting opportunities are\nenabled by careful content overlap at the various caches in the network,\ncreated by a central coordinating server.\n  In many scenarios, such a central coordinating server may not be available,\nraising the question if this multicasting gain can still be achieved in a more\ndecentralized setting. In this paper, we propose an efficient caching scheme,\nin which the content placement is performed in a decentralized manner. In other\nwords, no coordination is required for the content placement. Despite this lack\nof coordination, the proposed scheme is nevertheless able to create\ncoded-multicasting opportunities and achieves a rate close to the optimal\ncentralized scheme. \n\n"}
{"id": "1301.5973", "contents": "Title: Non-Adaptive Distributed Compression in Networks Abstract: In this paper, we discuss non-adaptive distributed compression of inter-node\ncorrelated real-valued messages. To do so, we discuss the performance of\nconventional packet forwarding via routing, in terms of the total network load\nversus the resulting quality of service (distortion level). As a better\nalternative for packet forwarding, we briefly describe our previously proposed\none-step Quantized Network Coding (QNC), and make motivating arguments on its\nadvantage when the appropriate marginal rates for distributed source coding are\nnot available at the encoder source nodes. We also derive analytic guarantees\non the resulting distortion of our one-step QNC scenario. Finally, we conclude\nthe paper by providing a mathematical comparison between the total network\nloads of one-step QNC and conventional packet forwarding, showing a significant\nreduction in the case of one-step QNC. \n\n"}
{"id": "1301.6199", "contents": "Title: Sample Complexity of Bayesian Optimal Dictionary Learning Abstract: We consider a learning problem of identifying a dictionary matrix D (M times\nN dimension) from a sample set of M dimensional vectors Y = N^{-1/2} DX, where\nX is a sparse matrix (N times P dimension) in which the density of non-zero\nentries is 0<rho< 1. In particular, we focus on the minimum sample size P_c\n(sample complexity) necessary for perfectly identifying D of the optimal\nlearning scheme when D and X are independently generated from certain\ndistributions. By using the replica method of statistical mechanics, we show\nthat P_c=O(N) holds as long as alpha = M/N >rho is satisfied in the limit of N\nto infinity. Our analysis also implies that the posterior distribution given Y\nis condensed only at the correct dictionary D when the compression rate alpha\nis greater than a certain critical value alpha_M(rho). This suggests that\nbelief propagation may allow us to learn D with a low computational complexity\nusing O(N) samples. \n\n"}
{"id": "1301.6209", "contents": "Title: On the achievable region for interference networks with point-to-point\n  codes Abstract: This paper studies evaluation of the capacity region for interference\nnetworks with point-to-point (p2p) capacity-achieving codes. Such capacity\nregion has recently been characterized as union of several sub-regions each of\nwhich has distinctive operational characteristics. Detailed evaluation of this\nregion, therefore, can be accomplished in a very simple manner by acknowledging\nsuch characteristics, which, in turn, provides an insight for a simple\nimplementation scenario. Completely generalized message assignment which is\nalso practically relevant is considered in this paper, and it is shown to\nprovide strictly larger achievable rates than what traditional message\nassignment does when a receiver with joint decoding capability is used. \n\n"}
{"id": "1301.6295", "contents": "Title: Fixed Points of Generalized Approximate Message Passing with Arbitrary\n  Matrices Abstract: The estimation of a random vector with independent components passed through\na linear transform followed by a componentwise (possibly nonlinear) output map\narises in a range of applications. Approximate message passing (AMP) methods,\nbased on Gaussian approximations of loopy belief propagation, have recently\nattracted considerable attention for such problems. For large random\ntransforms, these methods exhibit fast convergence and admit precise analytic\ncharacterizations with testable conditions for optimality, even for certain\nnon-convex problem instances. However, the behavior of AMP under general\ntransforms is not fully understood. In this paper, we consider the generalized\nAMP (GAMP) algorithm and relate the method to more common optimization\ntechniques. This analysis enables a precise characterization of the GAMP\nalgorithm fixed-points that applies to arbitrary transforms. In particular, we\nshow that the fixed points of the so-called max-sum GAMP algorithm for MAP\nestimation are critical points of a constrained maximization of the posterior\ndensity. The fixed-points of the sum-product GAMP algorithm for estimation of\nthe posterior marginals can be interpreted as critical points of a certain free\nenergy. \n\n"}
{"id": "1301.6397", "contents": "Title: Scalar Quantize-and-Forward for Symmetric Half-duplex Two-Way Relay\n  Channels Abstract: Scalar Quantize & Forward (QF) schemes are studied for the Two-Way Relay\nChannel. Different QF approaches are compared in terms of rates as well as\nrelay and decoder complexity. A coding scheme not requiring Slepian-Wolf coding\nat the relay is proposed and properties of the corresponding sum-rate\noptimization problem are presented. A numerical scheme similar to the\nBlahut-Arimoto algorithm is derived that guides optimized quantizer design. The\nresults are supported by simulations. \n\n"}
{"id": "1301.6599", "contents": "Title: An Upper Bound on the Capacity of non-Binary Deletion Channels Abstract: We derive an upper bound on the capacity of non-binary deletion channels.\nAlthough binary deletion channels have received significant attention over the\nyears, and many upper and lower bounds on their capacity have been derived,\nsuch studies for the non-binary case are largely missing. The state of the art\nis the following: as a trivial upper bound, capacity of an erasure channel with\nthe same input alphabet as the deletion channel can be used, and as a lower\nbound the results by Diggavi and Grossglauser are available. In this paper, we\nderive the first non-trivial non-binary deletion channel capacity upper bound\nand reduce the gap with the existing achievable rates. To derive the results we\nfirst prove an inequality between the capacity of a 2K-ary deletion channel\nwith deletion probability $d$, denoted by $C_{2K}(d)$, and the capacity of the\nbinary deletion channel with the same deletion probability, $C_2(d)$, that is,\n$C_{2K}(d)\\leq C_2(d)+(1-d)\\log(K)$. Then by employing some existing upper\nbounds on the capacity of the binary deletion channel, we obtain upper bounds\non the capacity of the 2K-ary deletion channel. We illustrate via examples the\nuse of the new bounds and discuss their asymptotic behavior as $d \\rightarrow\n0$. \n\n"}
{"id": "1302.0581", "contents": "Title: SMML estimators for exponential families with continuous sufficient\n  statistics Abstract: The minimum message length principle is an information theoretic criterion\nthat links data compression with statistical inference. This paper studies the\nstrict minimum message length (SMML) estimator for $d$-dimensional exponential\nfamilies with continuous sufficient statistics, for all $d \\ge 1$. The\npartition of an SMML estimator is shown to consist of convex polytopes (i.e.\nconvex polygons when $d=2$) which can be described explicitly in terms of the\nassertions and coding probabilities. While this result is known, we give a new\nproof based on the calculus of variations, and this approach gives some\ninteresting new inequalities for SMML estimators. We also use this result to\nconstruct an SMML estimator for a $2$-dimensional normal random variable with\nknown variance and a normal prior on its mean. \n\n"}
{"id": "1302.5449", "contents": "Title: Nonparametric Basis Pursuit via Sparse Kernel-based Learning Abstract: Signal processing tasks as fundamental as sampling, reconstruction, minimum\nmean-square error interpolation and prediction can be viewed under the prism of\nreproducing kernel Hilbert spaces. Endowing this vantage point with\ncontemporary advances in sparsity-aware modeling and processing, promotes the\nnonparametric basis pursuit advocated in this paper as the overarching\nframework for the confluence of kernel-based learning (KBL) approaches\nleveraging sparse linear regression, nuclear-norm regularization, and\ndictionary learning. The novel sparse KBL toolbox goes beyond translating\nsparse parametric approaches to their nonparametric counterparts, to\nincorporate new possibilities such as multi-kernel selection and matrix\nsmoothing. The impact of sparse KBL to signal processing applications is\nillustrated through test cases from cognitive radio sensing, microarray data\nimputation, and network traffic prediction. \n\n"}
{"id": "1302.5945", "contents": "Title: Queue-Based Random-Access Algorithms: Fluid Limits and Stability Issues Abstract: We use fluid limits to explore the (in)stability properties of wireless\nnetworks with queue-based random-access algorithms. Queue-based random-access\nschemes are simple and inherently distributed in nature, yet provide the\ncapability to match the optimal throughput performance of centralized\nscheduling mechanisms in a wide range of scenarios. Unfortunately, the type of\nactivation rules for which throughput optimality has been established, may\nresult in excessive queue lengths and delays. The use of more\naggressive/persistent access schemes can improve the delay performance, but\ndoes not offer any universal maximum-stability guarantees. In order to gain\nqualitative insight and investigate the (in)stability properties of more\naggressive/persistent activation rules, we examine fluid limits where the\ndynamics are scaled in space and time. In some situations, the fluid limits\nhave smooth deterministic features and maximum stability is maintained, while\nin other scenarios they exhibit random oscillatory characteristics, giving rise\nto major technical challenges. In the latter regime, more aggressive access\nschemes continue to provide maximum stability in some networks, but may cause\ninstability in others. Simulation experiments are conducted to illustrate and\nvalidate the analytical results. \n\n"}
{"id": "1303.1038", "contents": "Title: Anytime Reliable LDPC Convolutional Codes for Networked Control over\n  Wireless Channel Abstract: This paper deals with the problem of stabilizing an unstable system through\nnetworked control over the wireless medium. In such a situation a remote sensor\ncommunicates the measurements to the system controller through a noisy channel.\nIn particular, in the AWGN scenario, we show that protograph-based LDPC\nconvolutional codes achieve anytime reliability and we also derive a lower\nbound to the signal-to-noise ratio required to stabilize the system. Moreover,\non the Rayleigh-fading channel, we show by simulations that resorting to\nmultiple sensors allows to achieve a diversity gain. \n\n"}
{"id": "1303.2087", "contents": "Title: Capacity Bounds and Sum Rate Capacities of a CLass of Discrete\n  Memoryless Interference Channels Abstract: This paper studies the capacity of a class of discrete memoryless\ninterference channels where interference is defined analogous to that of\nGaussian interference channel with one-sided weak interference. The sum-rate\ncapacity of this class of channels is determined. As with the Gaussian case,\nthe sum-rate capacity is achieved by letting the transceiver pair subject to\ninterference communicate at a rate such that its message can be decoded at the\nunintended receiver using single user detection. It is also established that\nthis class of discrete memoryless interference channels is equivalent in\ncapacity region to certain degraded interference channels. This allows the\nconstruction of capacity outer-bounds using the capacity regions of associated\ndegraded broadcast channels. The same technique is then used to determine the\nsum-rate capacity of discrete memoryless interference channels with mixed\ninterference as defined in the paper. The obtained capacity bounds and sum-rate\ncapacities are used to resolve the capacities of several new discrete\nmemoryless interference channels. \n\n"}
{"id": "1303.2636", "contents": "Title: Energy Cooperation in Energy Harvesting Communications Abstract: In energy harvesting communications, users transmit messages using energy\nharvested from nature during the course of communication. With an optimum\ntransmit policy, the performance of the system depends only on the energy\narrival profiles. In this paper, we introduce the concept of energy\ncooperation, where a user wirelessly transmits a portion of its energy to\nanother energy harvesting user. This enables shaping and optimization of the\nenergy arrivals at the energy-receiving node, and improves the overall system\nperformance, despite the loss incurred in energy transfer. We consider several\nbasic multi-user network structures with energy harvesting and wireless energy\ntransfer capabilities: relay channel, two-way channel and multiple access\nchannel. We determine energy management policies that maximize the system\nthroughput within a given duration using a Lagrangian formulation and the\nresulting KKT optimality conditions. We develop a two-dimensional directional\nwater-filling algorithm which optimally controls the flow of harvested energy\nin two dimensions: in time (from past to future) and among users (from\nenergy-transferring to energy-receiving) and show that a generalized version of\nthis algorithm achieves the boundary of the capacity region of the two-way\nchannel. \n\n"}
{"id": "1303.3049", "contents": "Title: On Optimal Jamming Over an Additive Noise Channel Abstract: This paper considers the problem of optimal zero-delay jamming over an\nadditive noise channel. Early work had already solved this problem for a\nGaussian source and channel. Building on a sequence of recent results on\nconditions for linearity of optimal estimation, and of optimal mappings in\nsource-channel coding, we derive the saddle-point solution to the jamming\nproblem for general sources and channels, without recourse to Gaussian\nassumptions. We show that linearity conditions play a pivotal role in jamming,\nin the sense that the optimal jamming strategy is to effectively force both\ntransmitter and receiver to default to linear mappings, i.e., the jammer\nensures, whenever possible, that the transmitter and receiver cannot benefit\nfrom non-linear strategies. This result is shown to subsume the known result\nfor Gaussian source and channel. We analyze conditions and general settings\nwhere such unbeatable strategy can indeed be achieved by the jammer. Moreover,\nwe provide the procedure to approximate optimal jamming in the remaining\n(source-channel) cases where the jammer cannot impose linearity on the\ntransmitter and the receiver. \n\n"}
{"id": "1303.4348", "contents": "Title: Near Minimax Line Spectral Estimation Abstract: This paper establishes a nearly optimal algorithm for estimating the\nfrequencies and amplitudes of a mixture of sinusoids from noisy equispaced\nsamples. We derive our algorithm by viewing line spectral estimation as a\nsparse recovery problem with a continuous, infinite dictionary. We show how to\ncompute the estimator via semidefinite programming and provide guarantees on\nits mean-square error rate. We derive a complementary minimax lower bound on\nthis estimation rate, demonstrating that our approach nearly achieves the best\npossible estimation error. Furthermore, we establish bounds on how well our\nestimator localizes the frequencies in the signal, showing that the\nlocalization error tends to zero as the number of samples grows. We verify our\ntheoretical results in an array of numerical experiments, demonstrating that\nthe semidefinite programming approach outperforms two classical spectral\nestimation techniques. \n\n"}
{"id": "1303.5097", "contents": "Title: On the optimality of a L1/L1 solver for sparse signal recovery from\n  sparsely corrupted compressive measurements Abstract: This short note proves the $\\ell_2-\\ell_1$ instance optimality of a\n$\\ell_1/\\ell_1$ solver, i.e a variant of \\emph{basis pursuit denoising} with a\n$\\ell_1$ fidelity constraint, when applied to the estimation of sparse (or\ncompressible) signals observed by sparsely corrupted compressive measurements.\nThe approach simply combines two known results due to Y. Plan, R. Vershynin and\nE. Cand\\`es. \n\n"}
{"id": "1303.6387", "contents": "Title: Message Passing Algorithm for Distributed Downlink Regularized\n  Zero-forcing Beamforming with Cooperative Base Stations Abstract: Base station (BS) cooperation can turn unwanted interference to useful signal\nenergy for enhancing system performance. In the cooperative downlink,\nzero-forcing beamforming (ZFBF) with a simple scheduler is well known to obtain\nnearly the performance of the capacity-achieving dirty-paper coding. However,\nthe centralized ZFBF approach is prohibitively complex as the network size\ngrows. In this paper, we devise message passing algorithms for realizing the\nregularized ZFBF (RZFBF) in a distributed manner using belief propagation. In\nthe proposed methods, the overall computational cost is decomposed into many\nsmaller computation tasks carried out by groups of neighboring BSs and\ncommunications is only required between neighboring BSs. More importantly, some\nexchanged messages can be computed based on channel statistics rather than\ninstantaneous channel state information, leading to significant reduction in\ncomputational complexity. Simulation results demonstrate that the proposed\nalgorithms converge quickly to the exact RZFBF and much faster compared to\nconventional methods. \n\n"}
{"id": "1303.6672", "contents": "Title: Living on the edge: Phase transitions in convex programs with random\n  data Abstract: Recent research indicates that many convex optimization problems with random\nconstraints exhibit a phase transition as the number of constraints increases.\nFor example, this phenomenon emerges in the $\\ell_1$ minimization method for\nidentifying a sparse vector from random linear measurements. Indeed, the\n$\\ell_1$ approach succeeds with high probability when the number of\nmeasurements exceeds a threshold that depends on the sparsity level; otherwise,\nit fails with high probability.\n  This paper provides the first rigorous analysis that explains why phase\ntransitions are ubiquitous in random convex optimization problems. It also\ndescribes tools for making reliable predictions about the quantitative aspects\nof the transition, including the location and the width of the transition\nregion. These techniques apply to regularized linear inverse problems with\nrandom measurements, to demixing problems under a random incoherence model, and\nalso to cone programs with random affine constraints.\n  The applied results depend on foundational research in conic geometry. This\npaper introduces a summary parameter, called the statistical dimension, that\ncanonically extends the dimension of a linear subspace to the class of convex\ncones. The main technical result demonstrates that the sequence of intrinsic\nvolumes of a convex cone concentrates sharply around the statistical dimension.\nThis fact leads to accurate bounds on the probability that a randomly rotated\ncone shares a ray with a fixed cone. \n\n"}
{"id": "1303.7291", "contents": "Title: A framework to characterize performance of LASSO algorithms Abstract: In this paper we consider solving \\emph{noisy} under-determined systems of\nlinear equations with sparse solutions. A noiseless equivalent attracted\nenormous attention in recent years, above all, due to work of\n\\cite{CRT,CanRomTao06,DonohoPol} where it was shown in a statistical and large\ndimensional context that a sparse unknown vector (of sparsity proportional to\nthe length of the vector) can be recovered from an under-determined system via\na simple polynomial $\\ell_1$-optimization algorithm. \\cite{CanRomTao06} further\nestablished that even when the equations are \\emph{noisy}, one can, through an\nSOCP noisy equivalent of $\\ell_1$, obtain an approximate solution that is (in\nan $\\ell_2$-norm sense) no further than a constant times the noise from the\nsparse unknown vector. In our recent works\n\\cite{StojnicCSetam09,StojnicUpper10}, we created a powerful mechanism that\nhelped us characterize exactly the performance of $\\ell_1$ optimization in the\nnoiseless case (as shown in \\cite{StojnicEquiv10} and as it must be if the\naxioms of mathematics are well set, the results of\n\\cite{StojnicCSetam09,StojnicUpper10} are in an absolute agreement with the\ncorresponding exact ones from \\cite{DonohoPol}). In this paper we design a\nmechanism, as powerful as those from \\cite{StojnicCSetam09,StojnicUpper10},\nthat can handle the analysis of a LASSO type of algorithm (and many others)\nthat can be (or typically are) used for \"solving\" noisy under-determined\nsystems. Using the mechanism we then, in a statistical context, compute the\nexact worst-case $\\ell_2$ norm distance between the unknown sparse vector and\nthe approximate one obtained through such a LASSO. The obtained results match\nthe corresponding exact ones obtained in \\cite{BayMon10,DonMalMon10}. Moreover,\nas a by-product of our analysis framework we recognize existence of an SOCP\ntype of algorithm that achieves the same performance. \n\n"}
{"id": "1304.0036", "contents": "Title: Tight bound on relative entropy by entropy difference Abstract: We prove a lower bound on the relative entropy between two finite-dimensional\nstates in terms of their entropy difference and the dimension of the underlying\nspace. The inequality is tight in the sense that equality can be attained for\nany prescribed value of the entropy difference, both for quantum and classical\nsystems. We outline implications for information theory and thermodynamics,\nsuch as a necessary condition for a process to be close to thermodynamic\nreversibility, or an easily computable lower bound on the classical channel\ncapacity. Furthermore, we derive a tight upper bound, uniform for all states of\na given dimension, on the variance of the surprisal, whose thermodynamic\nmeaning is that of heat capacity. \n\n"}
{"id": "1304.0110", "contents": "Title: A Signal Constellation for Pilotless Communications Over Wiener Phase\n  Noise Channels Abstract: Many satellite communication systems operating today employ low cost\nupconverters or downconverters which create phase noise. This noise can\nseverely limit the information rate of the system and pose a serious challenge\nfor the detection systems. Moreover, simple solutions for phase noise tracking\nsuch as PLL either require low phase noise or otherwise require many pilot\nsymbols which reduce the effective data rate. In order to increase the\neffective information rate, we propose a signal constellation which does not\nrequire pilots, at all, in order to converge in the decoding process. In this\ncontribution, we will present a signal constellation which does not require\npilot sequences, but we require a signal that does not present rotational\nsymmetry. For example a simple MPSK cannot be used.Moreover, we will provide a\nmethod to analyze the proposed constellations and provide a figure of merit for\ntheir performance when iterative decoding algorithms are used. \n\n"}
{"id": "1304.3179", "contents": "Title: Joint Precoding and Multivariate Backhaul Compression for the Downlink\n  of Cloud Radio Access Networks Abstract: This work studies the joint design of precoding and backhaul compression\nstrategies for the downlink of cloud radio access networks. In these systems, a\ncentral encoder is connected to multiple multi-antenna base stations (BSs) via\nfinite-capacity backhaul links. At the central encoder, precoding is followed\nby compression in order to produce the rate-limited bit streams delivered to\neach BS over the corresponding backhaul link. In current state-of-the-art\napproaches, the signals intended for different BSs are compressed\nindependently. In contrast, this work proposes to leverage joint compression,\nalso referred to as multivariate compression, of the signals of different BSs\nin order to better control the effect of the additive quantization noises at\nthe mobile stations (MSs). The problem of maximizing the weighted sum-rate with\nrespect to both the precoding matrix and the joint correlation matrix of the\nquantization noises is formulated subject to power and backhaul capacity\nconstraints. An iterative algorithm is proposed that achieves a stationary\npoint of the problem. Moreover, in order to enable the practical implementation\nof multivariate compression across BSs, a novel architecture is proposed based\non successive steps of minimum mean-squared error (MMSE) estimation and per-BS\ncompression. Robust design with respect to imperfect channel state information\nis also discussed. From numerical results, it is confirmed that the proposed\njoint precoding and compression strategy outperforms conventional approaches\nbased on the separate design of precoding and compression or independent\ncompression across the BSs. \n\n"}
{"id": "1304.3826", "contents": "Title: Multi-Layer Transmission and Hybrid Relaying for Relay Channels with\n  Multiple Out-of-Band Relays Abstract: In this work, a relay channel is studied in which a source encoder\ncommunicates with a destination decoder through a number of out-of-band relays\nthat are connected to the decoder through capacity-constrained digital backhaul\nlinks. This model is motivated by the uplink of cloud radio access networks. In\nthis scenario, a novel transmission and relaying strategies are proposed in\nwhich multi-layer transmission is used, on the one hand, to adaptively leverage\nthe different decoding capabilities of the relays and, on the other hand, to\nenable hybrid decode-and-forward (DF) and compress-and-forward (CF) relaying.\nThe hybrid relaying strategy allows each relay to forward part of the decoded\nmessages and a compressed version of the received signal to the decoder. The\nproblem of optimizing the power allocation across the layers and the\ncompression test channels is formulated. Albeit non-convex, the derived problem\nis found to belong to the class of so called complementary geometric programs\n(CGPs). Using this observation, an iterative algorithm based on the homotopy\nmethod is proposed that achieves a stationary point of the original problem by\nsolving a sequence of geometric programming (GP), and thus convex, problems.\nNumerical results are provided that show the effectiveness of the proposed\nmulti-layer hybrid scheme in achieving performance close to a theoretical\n(cutset) upper bound. \n\n"}
{"id": "1304.6133", "contents": "Title: On Maximal Correlation, Hypercontractivity, and the Data Processing\n  Inequality studied by Erkip and Cover Abstract: In this paper we provide a new geometric characterization of the\nHirschfeld-Gebelein-R\\'{e}nyi maximal correlation of a pair of random $(X,Y)$,\nas well as of the chordal slope of the nontrivial boundary of the\nhypercontractivity ribbon of $(X,Y)$ at infinity. The new characterizations\nlead to simple proofs for some of the known facts about these quantities. We\nalso provide a counterexample to a data processing inequality claimed by Erkip\nand Cover, and find the correct tight constant for this kind of inequality. \n\n"}
{"id": "1304.7344", "contents": "Title: On feedback in Gaussian multi-hop networks Abstract: The study of feedback has been mostly limited to single-hop communication\nsettings. In this paper, we consider Gaussian networks where sources and\ndestinations can communicate with the help of intermediate relays over multiple\nhops. We assume that links in the network can be bidirected providing\nopportunities for feedback. We ask the following question: can the information\ntransfer in both directions of a link be critical to maximizing the end-to-end\ncommunication rates in the network? Equivalently, could one of the directions\nin each bidirected link (and more generally at least one of the links forming a\ncycle) be shut down and the capacity of the network still be approximately\nmaintained? We show that in any arbitrary Gaussian network with bidirected\nedges and cycles and unicast traffic, we can always identify a directed acyclic\nsubnetwork that approximately maintains the capacity of the original network.\nFor Gaussian networks with multiple-access and broadcast traffic, an acyclic\nsubnetwork is sufficient to achieve every rate point in the capacity region of\nthe original network, however, there may not be a single acyclic subnetwork\nthat maintains the whole capacity region. For networks with multicast and\nmultiple unicast traffic, on the other hand, bidirected information flow across\ncertain links can be critically needed to maximize the end-to-end capacity\nregion. These results can be regarded as generalizations of the conclusions\nregarding the usefulness of feedback in various single-hop Gaussian settings\nand can provide opportunities for simplifying operation in Gaussian multi-hop\nnetworks. \n\n"}
{"id": "1304.7886", "contents": "Title: Throughput Maximization in Wireless Powered Communication Networks Abstract: This paper studies the newly emerging wireless powered communication network\n(WPCN) in which one hybrid access point (H-AP) with constant power supply\ncoordinates the wireless energy/information transmissions to/from distributed\nusers that do not have energy sources. A \"harvest-then-transmit\" protocol is\nproposed where all users first harvest the wireless energy broadcast by the\nH-AP in the downlink (DL) and then send their independent information to the\nH-AP in the uplink (UL) by time-division-multiple-access (TDMA). First, we\nstudy the sum-throughput maximization of all users by jointly optimizing the\ntime allocation for the DL wireless power transfer versus the users' UL\ninformation transmissions given a total time constraint based on the users' DL\nand UL channels as well as their average harvested energy values. By applying\nconvex optimization techniques, we obtain the closed-form expressions for the\noptimal time allocations to maximize the sum-throughput. Our solution reveals\n\"doubly near-far\" phenomenon due to both the DL and UL distance-dependent\nsignal attenuation, where a far user from the H-AP, which receives less\nwireless energy than a nearer user in the DL, has to transmit with more power\nin the UL for reliable information transmission. Consequently, the maximum\nsum-throughput is achieved by allocating substantially more time to the near\nusers than the far users, thus resulting in unfair rate allocation among\ndifferent users. To overcome this problem, we furthermore propose a new\nperformance metric so-called common-throughput with the additional constraint\nthat all users should be allocated with an equal rate regardless of their\ndistances to the H-AP. We present an efficient algorithm to solve the\ncommon-throughput maximization problem. Simulation results demonstrate the\neffectiveness of the common-throughput approach for solving the new doubly\nnear-far problem in WPCNs. \n\n"}
{"id": "1304.8126", "contents": "Title: Robust Spectral Compressed Sensing via Structured Matrix Completion Abstract: The paper explores the problem of \\emph{spectral compressed sensing}, which\naims to recover a spectrally sparse signal from a small random subset of its\n$n$ time domain samples. The signal of interest is assumed to be a\nsuperposition of $r$ multi-dimensional complex sinusoids, while the underlying\nfrequencies can assume any \\emph{continuous} values in the normalized frequency\ndomain. Conventional compressed sensing paradigms suffer from the basis\nmismatch issue when imposing a discrete dictionary on the Fourier\nrepresentation. To address this issue, we develop a novel algorithm, called\n\\emph{Enhanced Matrix Completion (EMaC)}, based on structured matrix completion\nthat does not require prior knowledge of the model order. The algorithm starts\nby arranging the data into a low-rank enhanced form exhibiting multi-fold\nHankel structure, and then attempts recovery via nuclear norm minimization.\nUnder mild incoherence conditions, EMaC allows perfect recovery as soon as the\nnumber of samples exceeds the order of $r\\log^{4}n$, and is stable against\nbounded noise. Even if a constant portion of samples are corrupted with\narbitrary magnitude, EMaC still allows exact recovery, provided that the sample\ncomplexity exceeds the order of $r^{2}\\log^{3}n$. Along the way, our results\ndemonstrate the power of convex relaxation in completing a low-rank multi-fold\nHankel or Toeplitz matrix from minimal observed entries. The performance of our\nalgorithm and its applicability to super resolution are further validated by\nnumerical experiments. \n\n"}
{"id": "1305.3358", "contents": "Title: Symmetry in Distributed Storage Systems Abstract: The max-flow outer bound is achievable by regenerating codes for functional\nrepair distributed storage system. However, the capacity of exact repair\ndistributed storage system is an open problem. In this paper, the linear\nprogramming bound for exact repair distributed storage systems is formulated. A\nnotion of symmetrical sets for a set of random variables is given and\nequalities of joint entropies for certain subsets of random variables in a\nsymmetrical set is established. Concatenation coding scheme for exact repair\ndistributed storage systems is proposed and it is shown that concatenation\ncoding scheme is sufficient to achieve any admissible rate for any exact repair\ndistributed storage system. Equalities of certain joint entropies of random\nvariables induced by concatenation scheme is shown. These equalities of joint\nentropies are new tools to simplify the linear programming bound and to obtain\nstronger converse results for exact repair distributed storage systems. \n\n"}
{"id": "1305.3537", "contents": "Title: Cooperative Relaying in a Poisson Field of Interferers: A Diversity\n  Order Analysis Abstract: This work analyzes the gains of cooperative relaying in interference-limited\nnetworks, in which outages can be due to interference and fading. A stochastic\nmodel based on point process theory is used to capture the spatial randomness\npresent in contemporary wireless networks. Using a modification of the\ndiversity order metric, the reliability gain of selection decode-and-forward is\nstudied for several cases. The main results are as follows: the achievable\n\\emph{spatial-contention} diversity order (SC-DO) is equal to one irrespective\nof the type of channel which is due to the ineffectiveness of the relay in the\nMAC-phase (transmit diversity). In the BC-phase (receive diversity), the SC-DO\ndepends on the amount of fading and spatial interference correlation. In the\nabsence of fading, there is a hard transition between SC-DO of either one or\ntwo, depending on the system parameters. \n\n"}
{"id": "1305.5278", "contents": "Title: The second laws of quantum thermodynamics Abstract: The second law of thermodynamics tells us which state transformations are so\nstatistically unlikely that they are effectively forbidden. Its original\nformulation, due to Clausius, states that \"Heat can never pass from a colder to\na warmer body without some other change, connected therewith, occurring at the\nsame time\". The second law applies to systems composed of many particles\ninteracting; however, we are seeing that one can make sense of thermodynamics\nin the regime where we only have a small number of particles interacting with a\nheat bath. Is there a second law of thermodynamics in this regime? Here, we\nfind that for processes which are cyclic or very close to cyclic, the second\nlaw for microscopic systems takes on a very different form than it does at the\nmacroscopic scale, imposing not just one constraint on what state\ntransformations are possible, but an entire family of constraints. In\nparticular, we find a family of free energies which generalise the traditional\none, and show that they can never increase. We further find that there are\nthree regimes which determine which family of second laws govern state\ntransitions, depending on how cyclic the process is. In one regime one can\ncause an apparent violation of the usual second law, through a process of\nembezzling work from a large system which remains arbitrarily close to its\noriginal state. These second laws are not only relevant for small systems, but\nalso apply to individual macroscopic systems interacting via long-range\ninteractions, which only satisfy the ordinary second law on average. By making\nprecise the definition of thermal operations, the laws of thermodynamics take\non a simple form with the first law defining the class of thermal operations,\nthe zeroeth law emerging as a unique condition ensuring the theory is\nnontrivial, and the remaining laws being a monotonicity property of our\ngeneralised free energies. \n\n"}
{"id": "1305.5530", "contents": "Title: Optimal Scheduling for Energy Harvesting Transmitters with Hybrid Energy\n  Storage Abstract: We consider data transmission with an energy harvesting transmitter which has\na hybrid energy storage unit composed of a perfectly efficient super-capacitor\n(SC) and an inefficient battery. The SC has finite space for energy storage\nwhile the battery has unlimited space. The transmitter can choose to store the\nharvested energy in the SC or in the battery. The energy is drained from the SC\nand the battery simultaneously. In this setting, we consider the offline\nthroughput maximization problem by a deadline over a point-to-point channel. In\ncontrast to previous works, the hybrid energy storage model with finite and\nunlimited storage capacities imposes a generalized set of constraints on the\ntransmission policy. As such, we show that the solution generalizes that for a\nsingle battery and is obtained by applying directional water-filling algorithm\nmultiple times. \n\n"}
{"id": "1306.2109", "contents": "Title: Distributed Decision-Making over Adaptive Networks Abstract: In distributed processing, agents generally collect data generated by the\nsame underlying unknown model (represented by a vector of parameters) and then\nsolve an estimation or inference task cooperatively. In this paper, we consider\nthe situation in which the data observed by the agents may have risen from two\ndifferent models. Agents do not know beforehand which model accounts for their\ndata and the data of their neighbors. The objective for the network is for all\nagents to reach agreement on which model to track and to estimate this model\ncooperatively. In these situations, where agents are subject to data from\nunknown different sources, conventional distributed estimation strategies would\nlead to biased estimates relative to any of the underlying models. We first\nshow how to modify existing strategies to guarantee unbiasedness. We then\ndevelop a classification scheme for the agents to identify the models that\ngenerated the data, and propose a procedure by which the entire network can be\nmade to converge towards the same model through a collaborative decision-making\nprocess. The resulting algorithm is applied to model fish foraging behavior in\nthe presence of two food sources. \n\n"}
{"id": "1306.3478", "contents": "Title: Symplectic spreads, planar functions and mutually unbiased bases Abstract: In this paper we give explicit descriptions of complete sets of mutually\nunbiased bases (MUBs) and orthogonal decompositions of special Lie algebras\n$sl_n(\\mathbb{C})$ obtained from commutative and symplectic semifields, and\nfrom some other non-semifield symplectic spreads. Relations between various\nconstructions are also studied. We show that the automorphism group of a\ncomplete set of MUBs is isomorphic to the automorphism group of the\ncorresponding orthogonal decomposition of the Lie algebra $sl_n(\\mathbb{C})$.\nIn the case of symplectic spreads this automorphism group is determined by the\nautomorphism group of the spread. By using the new notion of pseudo-planar\nfunctions over fields of characteristic two we give new explicit constructions\nof complete sets of MUBs. \n\n"}
{"id": "1306.3610", "contents": "Title: Thresholds of Spatially Coupled Systems via Lyapunov's Method Abstract: The threshold, or saturation phenomenon of spatially coupled systems is\nrevisited in the light of Lyapunov's theory of dynamical systems. It is shown\nthat an application of Lyapunov's direct method can be used to quantitatively\ndescribe the threshold phenomenon, prove convergence, and compute threshold\nvalues. This provides a general proof methodology for the various systems\nrecently studied. Examples of spatially coupled systems are given and their\nthresholds are computed. \n\n"}
{"id": "1306.3774", "contents": "Title: Under-determined linear systems and $\\ell_q$-optimization thresholds Abstract: Recent studies of under-determined linear systems of equations with sparse\nsolutions showed a great practical and theoretical efficiency of a particular\ntechnique called $\\ell_1$-optimization. Seminal works \\cite{CRT,DOnoho06CS}\nrigorously confirmed it for the first time. Namely, \\cite{CRT,DOnoho06CS}\nshowed, in a statistical context, that $\\ell_1$ technique can recover sparse\nsolutions of under-determined systems even when the sparsity is linearly\nproportional to the dimension of the system. A followup \\cite{DonohoPol} then\nprecisely characterized such a linearity through a geometric approach and a\nseries of work\\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} reaffirmed\nstatements of \\cite{DonohoPol} through a purely probabilistic approach. A\ntheoretically interesting alternative to $\\ell_1$ is a more general version\ncalled $\\ell_q$ (with an essentially arbitrary $q$). While $\\ell_1$ is\ntypically considered as a first available convex relaxation of sparsity norm\n$\\ell_0$, $\\ell_q,0\\leq q\\leq 1$, albeit non-convex, should technically be a\ntighter relaxation of $\\ell_0$. Even though developing polynomial (or close to\nbe polynomial) algorithms for non-convex problems is still in its initial\nphases one may wonder what would be the limits of an $\\ell_q,0\\leq q\\leq 1$,\nrelaxation even if at some point one can develop algorithms that could handle\nits non-convexity. A collection of answers to this and a few realted questions\nis precisely what we present in this paper. \n\n"}
{"id": "1306.3778", "contents": "Title: Upper-bounding $\\ell_1$-optimization sectional thresholds Abstract: In this paper we look at a particular problem related to under-determined\nlinear systems of equations with sparse solutions. $\\ell_1$-minimization is a\nfairly successful polynomial technique that can in certain statistical\nscenarios find sparse enough solutions of such systems. Barriers of $\\ell_1$\nperformance are typically referred to as its thresholds. Depending if one is\ninterested in a typical or worst case behavior one then distinguishes between\nthe \\emph{weak} thresholds that relate to a typical behavior on one side and\nthe \\emph{sectional} and \\emph{strong} thresholds that relate to the worst case\nbehavior on the other side. Starting with seminal works\n\\cite{CRT,DonohoPol,DOnoho06CS} a substantial progress has been achieved in\ntheoretical characterization of $\\ell_1$-minimization statistical thresholds.\nMore precisely, \\cite{CRT,DOnoho06CS} presented for the first time linear lower\nbounds on all of these thresholds. Donoho's work \\cite{DonohoPol} (and our own\n\\cite{StojnicCSetam09,StojnicUpper10}) went a bit further and essentially\nsettled the $\\ell_1$'s \\emph{weak} thresholds. At the same time they also\nprovided fairly good lower bounds on the values on the \\emph{sectional} and\n\\emph{strong} thresholds. In this paper, we revisit the \\emph{sectional}\nthresholds and present a simple mechanism that can be used to create solid\nupper bounds as well. The method we present relies on a seemingly simple but\nsubstantial progress we made in studying Hopfield models in\n\\cite{StojnicHopBnds10}. \n\n"}
{"id": "1306.4748", "contents": "Title: New Analysis of Manifold Embeddings and Signal Recovery from Compressive\n  Measurements Abstract: Compressive Sensing (CS) exploits the surprising fact that the information\ncontained in a sparse signal can be preserved in a small number of compressive,\noften random linear measurements of that signal. Strong theoretical guarantees\nhave been established concerning the embedding of a sparse signal family under\na random measurement operator and on the accuracy to which sparse signals can\nbe recovered from noisy compressive measurements. In this paper, we address\nsimilar questions in the context of a different modeling framework. Instead of\nsparse models, we focus on the broad class of manifold models, which can arise\nin both parametric and non-parametric signal families. Using tools from the\ntheory of empirical processes, we improve upon previous results concerning the\nembedding of low-dimensional manifolds under random measurement operators. We\nalso establish both deterministic and probabilistic instance-optimal bounds in\n$\\ell_2$ for manifold-based signal recovery and parameter estimation from noisy\ncompressive measurements. In line with analogous results for sparsity-based CS,\nwe conclude that much stronger bounds are possible in the probabilistic\nsetting. Our work supports the growing evidence that manifold-based models can\nbe used with high accuracy in compressive signal processing. \n\n"}
{"id": "1307.1101", "contents": "Title: Mixed-Timescale Precoding and Cache Control in Cached MIMO Interference\n  Network Abstract: Consider media streaming in MIMO interference networks whereby multiple base\nstations (BS) simultaneously deliver media to their associated users using\nfixed data rates. The performance is fundamentally limited by the cross-link\ninterference. We propose a cache-induced opportunistic cooperative MIMO (CoMP)\nfor interference mitigation. By caching a portion of the media files, the BSs\nopportunistically employ CoMP to transform the cross-link interference into\nspatial multiplexing gain. We study a mixed-timescale optimization of MIMO\nprecoding and cache control to minimize the transmit power under the rate\nconstraint. The cache control is to create more CoMP opportunities and is\nadaptive to the long-term popularity of the media files. The precoding is to\nguarantee the rate requirement and is adaptive to the channel state information\nand cache state at the BSs. The joint stochastic optimization problem is\ndecomposed into a short-term precoding and a long-term cache control problem.\nWe propose a precoding algorithm which converges to a stationary point of the\nshort-term problem. Based on this, we exploit the hidden convexity of the\nlong-term problem and propose a low complexity and robust solution using\nstochastic subgradient. The solution has significant gains over various\nbaselines and does not require explicit knowledge of the media popularity. \n\n"}
{"id": "1307.1770", "contents": "Title: Improving A*OMP: Theoretical and Empirical Analyses With a Novel Dynamic\n  Cost Model Abstract: Best-first search has been recently utilized for compressed sensing (CS) by\nthe A* orthogonal matching pursuit (A*OMP) algorithm. In this work, we\nconcentrate on theoretical and empirical analyses of A*OMP. We present a\nrestricted isometry property (RIP) based general condition for exact recovery\nof sparse signals via A*OMP. In addition, we develop online guarantees which\npromise improved recovery performance with the residue-based termination\ninstead of the sparsity-based one. We demonstrate the recovery capabilities of\nA*OMP with extensive recovery simulations using the adaptive-multiplicative\n(AMul) cost model, which effectively compensates for the path length\ndifferences in the search tree. The presented results, involving phase\ntransitions for different nonzero element distributions as well as recovery\nrates and average error, reveal not only the superior recovery accuracy of\nA*OMP, but also the improvements with the residue-based termination and the\nAMul cost model. Comparison of the run times indicate the speed up by the AMul\ncost model. We also demonstrate a hybrid of OMP and A?OMP to accelerate the\nsearch further. Finally, we run A*OMP on a sparse image to illustrate its\nrecovery performance for more realistic coefcient distributions. \n\n"}
{"id": "1307.2430", "contents": "Title: On The Fast Fading Multiple-Antenna Gaussian Broadcast Channel with\n  Confidential Messages and Partial CSIT Abstract: In wiretap channels the eavesdropper's channel state information (CSI) is\ncommonly assumed to be known at transmitter, fully or partially. However, under\nperfect secrecy constraint the eavesdropper may not be motivated to feedback\nany correct CSI. In this paper we consider a more feasible problem for the\ntransmitter to have eavesdropper's CSI. That is, the fast fading\nmultiple-antenna Gaussian broadcast channels (FMGBC-CM) with confidential\nmessages, where both receivers are legitimate users such that they both are\nwilling to feedback accurate CSI to maintain their secure transmission, and not\nto be eavesdropped by the other. We assume that only the statistics of the\nchannel state information are known by the transmitter. We first show the\nnecessary condition for the FMGBC-CM not to be degraded to the common wiretap\nchannels. Then we derive the achievable rate region for the FMGBC-CM where the\nchannel input covariance matrices and the inflation factor are left unknown and\nto be solved. After that we provide an analytical solution to the channel input\ncovariance matrices. We also propose an iterative algorithm to solve the\nchannel input covariance matrices and the inflation factor. Due to the\ncomplicated rate region formulae in normal SNR, we resort to low SNR analysis\nto investigate the characteristics of the channel. Finally, numerical examples\nshow that under perfect secrecy constraint both users can achieve positive\nrates simultaneously, which verifies our derived necessary condition. Numerical\nresults also elucidate the effectiveness of the analytic solution and proposed\nalgorithm of solving the channel input covariance matrices and the inflation\nfactor under different conditions. \n\n"}
{"id": "1307.4502", "contents": "Title: Universally Elevating the Phase Transition Performance of Compressed\n  Sensing: Non-Isometric Matrices are Not Necessarily Bad Matrices Abstract: In compressed sensing problems, $\\ell_1$ minimization or Basis Pursuit was\nknown to have the best provable phase transition performance of recoverable\nsparsity among polynomial-time algorithms. It is of great theoretical and\npractical interest to find alternative polynomial-time algorithms which perform\nbetter than $\\ell_1$ minimization. \\cite{Icassp reweighted l_1}, \\cite{Isit\nreweighted l_1}, \\cite{XuScaingLaw} and \\cite{iterativereweightedjournal} have\nshown that a two-stage re-weighted $\\ell_1$ minimization algorithm can boost\nthe phase transition performance for signals whose nonzero elements follow an\namplitude probability density function (pdf) $f(\\cdot)$ whose $t$-th derivative\n$f^{t}(0) \\neq 0$ for some integer $t \\geq 0$. However, for signals whose\nnonzero elements are strictly suspended from zero in distribution (for example,\nconstant-modulus, only taking values `$+d$' or `$-d$' for some nonzero real\nnumber $d$), no polynomial-time signal recovery algorithms were known to\nprovide better phase transition performance than plain $\\ell_1$ minimization,\nespecially for dense sensing matrices. In this paper, we show that a\npolynomial-time algorithm can universally elevate the phase-transition\nperformance of compressed sensing, compared with $\\ell_1$ minimization, even\nfor signals with constant-modulus nonzero elements. Contrary to conventional\nwisdoms that compressed sensing matrices are desired to be isometric, we show\nthat non-isometric matrices are not necessarily bad sensing matrices. In this\npaper, we also provide a framework for recovering sparse signals when sensing\nmatrices are not isometric. \n\n"}
{"id": "1307.7211", "contents": "Title: Physical Layer Security in Downlink Multi-Antenna Cellular Networks Abstract: In this paper, we study physical layer security for the downlink of cellular\nnetworks, where the confidential messages transmitted to each mobile user can\nbe eavesdropped by both (i) the other users in the same cell and (ii) the users\nin the other cells. The locations of base stations and mobile users are modeled\nas two independent two-dimensional Poisson point processes. Using the proposed\nmodel, we analyze the secrecy rates achievable by regularized channel inversion\n(RCI) precoding by performing a large-system analysis that combines tools from\nstochastic geometry and random matrix theory. We obtain approximations for the\nprobability of secrecy outage and the mean secrecy rate, and characterize\nregimes where RCI precoding achieves a nonzero secrecy rate. We find that\nunlike isolated cells, the secrecy rate in a cellular network does not grow\nmonotonically with the transmit power, and the network tends to be in secrecy\noutage if the transmit power grows unbounded. Furthermore, we show that there\nis an optimal value for the base station deployment density that maximizes the\nsecrecy rate, and this value is a decreasing function of the signal-to-noise\nratio. \n\n"}
{"id": "1308.3310", "contents": "Title: On the Capacity and Degrees of Freedom Regions of MIMO Interference\n  Channels with Limited Receiver Cooperation Abstract: This paper gives the approximate capacity region of a two-user MIMO\ninterference channel with limited receiver cooperation, where the gap between\nthe inner and outer bounds is in terms of the total number of receive antennas\nat the two receivers and is independent of the actual channel values. The\napproximate capacity region is then used to find the degrees of freedom region.\nFor the special case of symmetric interference channels, we also find the\namount of receiver cooperation in terms of the backhaul capacity beyond which\nthe degrees of freedom do not improve. Further, the generalized degrees of\nfreedom are found for MIMO interference channels with equal number of antennas\nat all nodes. It is shown that the generalized degrees of freedom improve\ngradually from a \"W\" curve to a \"V\" curve with increase in cooperation in terms\nof the backhaul capacity. \n\n"}
{"id": "1308.4499", "contents": "Title: On a question of Babadi and Tarokh II Abstract: In this paper we continue to study a question proposed by Babadi and Tarokh\n\\cite{ba2} on the mysterious randomness of Gold sequences. Upon improving their\nresult, we establish the randomness of product of pseudorandom matrices formed\nfrom two linear block codes with respect to the empirical spectral\ndistribution, if the dual distance of both codes is at least 5, hence providing\nan affirmative answer to the question. \n\n"}
{"id": "1308.6007", "contents": "Title: Tree Codes and a Conjecture on Exponential Sums Abstract: We propose a new conjecture on some exponential sums. These particular sums\nhave not apparently been considered in the literature. Subject to the\nconjecture we obtain the first effective construction of asymptotically good\ntree codes. The available numerical evidence is consistent with the conjecture\nand is sufficient to certify codes for significant-length communications. \n\n"}
{"id": "1309.0482", "contents": "Title: Law of Log Determinant of Sample Covariance Matrix and Optimal\n  Estimation of Differential Entropy for High-Dimensional Gaussian\n  Distributions Abstract: Differential entropy and log determinant of the covariance matrix of a\nmultivariate Gaussian distribution have many applications in coding,\ncommunications, signal processing and statistical inference. In this paper we\nconsider in the high dimensional setting optimal estimation of the differential\nentropy and the log-determinant of the covariance matrix. We first establish a\ncentral limit theorem for the log determinant of the sample covariance matrix\nin the high dimensional setting where the dimension $p(n)$ can grow with the\nsample size $n$. An estimator of the differential entropy and the log\ndeterminant is then considered. Optimal rate of convergence is obtained. It is\nshown that in the case $p(n)/n \\rightarrow 0$ the estimator is asymptotically\nsharp minimax. The ultra-high dimensional setting where $p(n) > n$ is also\ndiscussed. \n\n"}
{"id": "1309.0799", "contents": "Title: Linear Degrees of Freedom of the X-Channel with Delayed CSIT Abstract: We establish the degrees of freedom of the two-user X-channel with delayed\nchannel knowledge at transmitters (i.e., delayed CSIT), assuming linear coding\nstrategies at the transmitters. We derive a new upper bound and characterize\nthe linear degrees of freedom of this network to be 6/5. The converse builds\nupon our development of a general lemma that shows that, if two distributed\ntransmitters employ linear strategies, the ratio of the dimensions of received\nlinear subspaces at the two receivers cannot exceed 3/2, due to delayed CSIT.\nAs a byproduct, we also apply this general lemma to the three-user interference\nchannel with delayed CSIT, thereby deriving a new upper bound of 9/7 on its\nlinear degrees of freedom. This is the first bound that captures the impact of\ndelayed CSIT on the degrees of freedom of this network, under the assumption of\nlinear encoding strategies. \n\n"}
{"id": "1309.0898", "contents": "Title: Two-Hop Interference Channels: Impact of Linear Schemes Abstract: We consider the two-hop interference channel (IC), which consists of two\nsource-destination pairs communicating with each other via two relays. We\nanalyze the degrees of freedom (DoF) of this network when the relays are\nrestricted to perform linear schemes, and the channel gains are constant (i.e.,\nslow fading). We show that, somewhat surprisingly, by using vector-linear\nstrategies at the relays, it is possible to achieve 4/3 sum-DoF when the\nchannel gains are real. The key achievability idea is to alternate relaying\ncoefficients across time, to create different end-to-end interference\nstructures (or topologies) at different times. Although each of these\ntopologies has only 1 sum-DoF, we manage to achieve 4/3 by coding across them.\nFurthermore, we develop a novel outer bound that matches our achievability,\nhence characterizing the sum-DoF of two-hop interference channels with linear\nschemes. As for the case of complex channel gains, we characterize the sum-DoF\nwith linear schemes to be 5/3. We also generalize the results to the\nmulti-antenna setting, characterizing the sum-DoF with linear schemes to be\n2M-1/3 (for complex channel gains), where M is the number of antennas at each\nnode. \n\n"}
{"id": "1309.1585", "contents": "Title: Network-Level Cooperation in Energy Harvesting Wireless Networks Abstract: We consider a two-hop communication network consisted of a source node, a\nrelay and a destination node in which the source and the relay node have\nexternal traffic arrivals. The relay forwards a fraction of the source node's\ntraffic to the destination and the cooperation is performed at the network\nlevel. In addition, both source and relay nodes have energy harvesting\ncapabilities and an unlimited battery to store the harvested energy. We study\nthe impact of the energy constraints on the stability region. Specifically, we\nprovide inner and outer bounds on the stability region of the two-hop network\nwith energy harvesting source and relay. \n\n"}
{"id": "1309.3511", "contents": "Title: Event-Triggered State Observers for Sparse Sensor Noise/Attacks Abstract: This paper describes two algorithms for state reconstruction from sensor\nmeasurements that are corrupted with sparse, but otherwise arbitrary, \"noise\".\nThese results are motivated by the need to secure cyber-physical systems\nagainst a malicious adversary that can arbitrarily corrupt sensor measurements.\nThe first algorithm reconstructs the state from a batch of sensor measurements\nwhile the second algorithm is able to incorporate new measurements as they\nbecome available, in the spirit of a Luenberger observer. A distinguishing\npoint of these algorithms is the use of event-triggered techniques to improve\nthe computational performance of the proposed algorithms. \n\n"}
{"id": "1309.3792", "contents": "Title: Exact Complexity: The Spectral Decomposition of Intrinsic Computation Abstract: We give exact formulae for a wide family of complexity measures that capture\nthe organization of hidden nonlinear processes. The spectral decomposition of\noperator-valued functions leads to closed-form expressions involving the full\neigenvalue spectrum of the mixed-state presentation of a process's\nepsilon-machine causal-state dynamic. Measures include correlation functions,\npower spectra, past-future mutual information, transient and synchronization\ninformations, and many others. As a result, a direct and complete analysis of\nintrinsic computation is now available for the temporal organization of\nfinitary hidden Markov models and nonlinear dynamical systems with generating\npartitions and for the spatial organization in one-dimensional systems,\nincluding spin systems, cellular automata, and complex materials via chaotic\ncrystallography. \n\n"}
{"id": "1309.7540", "contents": "Title: Joint Power and Antenna Selection Optimization in Large Cloud Radio\n  Access Networks Abstract: Large multiple-input multiple-output (MIMO) networks promise high energy\nefficiency, i.e., much less power is required to achieve the same capacity\ncompared to the conventional MIMO networks if perfect channel state information\n(CSI) is available at the transmitter. However, in such networks, huge overhead\nis required to obtain full CSI especially for Frequency-Division Duplex (FDD)\nsystems. To reduce overhead, we propose a downlink antenna selection scheme,\nwhich selects S antennas from M>S transmit antennas based on the large scale\nfading to serve K\\leq S users in large distributed MIMO networks employing\nregularized zero-forcing (RZF) precoding. In particular, we study the joint\noptimization of antenna selection, regularization factor, and power allocation\nto maximize the average weighted sum-rate. This is a mixed combinatorial and\nnon-convex problem whose objective and constraints have no closed-form\nexpressions. We apply random matrix theory to derive asymptotically accurate\nexpressions for the objective and constraints. As such, the joint optimization\nproblem is decomposed into subproblems, each of which is solved by an efficient\nalgorithm. In addition, we derive structural solutions for some special cases\nand show that the capacity of very large distributed MIMO networks scales as\nO\\left(K\\textrm{log}M\\right) when M\\rightarrow\\infty with K,S fixed.\nSimulations show that the proposed scheme achieves significant performance gain\nover various baselines. \n\n"}
{"id": "1309.7841", "contents": "Title: Asynchronous Gossip for Averaging and Spectral Ranking Abstract: We consider two variants of the classical gossip algorithm. The first variant\nis a version of asynchronous stochastic approximation. We highlight a\nfundamental difficulty associated with the classical asynchronous gossip\nscheme, viz., that it may not converge to a desired average, and suggest an\nalternative scheme based on reinforcement learning that has guaranteed\nconvergence to the desired average. We then discuss a potential application to\na wireless network setting with simultaneous link activation constraints. The\nsecond variant is a gossip algorithm for distributed computation of the\nPerron-Frobenius eigenvector of a nonnegative matrix. While the first variant\ndraws upon a reinforcement learning algorithm for an average cost controlled\nMarkov decision problem, the second variant draws upon a reinforcement learning\nalgorithm for risk-sensitive control. We then discuss potential applications of\nthe second variant to ranking schemes, reputation networks, and principal\ncomponent analysis. \n\n"}
{"id": "1309.7964", "contents": "Title: A General Formula for the Mismatch Capacity Abstract: The fundamental limits of channels with mismatched decoding are addressed. A\ngeneral formula is established for the mismatch capacity of a general channel,\ndefined as a sequence of conditional distributions with a general decoding\nmetrics sequence. We deduce an identity between the Verd\\'{u}-Han general\nchannel capacity formula, and the mismatch capacity formula applied to Maximum\nLikelihood decoding metric. Further, several upper bounds on the capacity are\nprovided, and a simpler expression for a lower bound is derived for the case of\na non-negative decoding metric. The general formula is specialized to the case\nof finite input and output alphabet channels with a type-dependent metric. The\nclosely related problem of threshold mismatched decoding is also studied, and a\ngeneral expression for the threshold mismatch capacity is obtained. As an\nexample of threshold mismatch capacity, we state a general expression for the\nerasures-only capacity of the finite input and output alphabet channel. We\nobserve that for every channel there exists a (matched) threshold decoder which\nis capacity achieving. Additionally, necessary and sufficient conditions are\nstated for a channel to have a strong converse. Csisz\\'{a}r and Narayan's\nconjecture is proved for bounded metrics, providing a positive answer to the\nopen problem introduced in [1], i.e., that the \"product-space\" improvement of\nthe lower random coding bound, $C_q^{(\\infty)}(W)$, is indeed the mismatch\ncapacity of the discrete memoryless channel $W$. We conclude by presenting an\nidentity between the threshold capacity and $C_q^{(\\infty)}(W)$ in the DMC\ncase. \n\n"}
{"id": "1310.1635", "contents": "Title: Constellation Optimization in the Presence of Strong Phase Noise Abstract: In this paper, we address the problem of optimizing signal constellations for\nstrong phase noise. The problem is investigated by considering three\noptimization formulations, which provide an analytical framework for\nconstellation design. In the first formulation, we seek to design\nconstellations that minimize the symbol error probability (SEP) for an\napproximate ML detector in the presence of phase noise. In the second\nformulation, we optimize constellations in terms of mutual information (MI) for\nthe effective discrete channel consisting of phase noise, additive white\nGaussian noise, and the approximate ML detector. To this end, we derive the MI\nof this discrete channel. Finally, we optimize constellations in terms of the\nMI for the phase noise channel. We give two analytical characterizations of the\nMI of this channel, which are shown to be accurate for a wide range of\nsignal-to-noise ratios and phase noise variances. For each formulation, we\npresent a detailed analysis of the optimal constellations and their performance\nin the presence of strong phase noise. We show that the optimal constellations\nsignificantly outperform conventional constellations and those proposed in the\nliterature in terms of SEP, error floors, and MI. \n\n"}
{"id": "1310.3085", "contents": "Title: Source-Channel Matching for Sources with Memory Abstract: In this paper we analyze the probabilistic matching of sources with memory to\nchannels with memory so that symbol-by-symbol code with memory without\nanticipation are optimal, with respect to an average distortion and excess\ndistortion probability. We show achievability of such a symbolby- symbol code\nwith memory without anticipation, and we show matching for the Binary Symmetric\nMarkov source (BSMS(p)) over a first-order symmetric channel with a cost\nconstraint. \n\n"}
{"id": "1310.3724", "contents": "Title: Spatially Coupled Sparse Codes on Graphs - Theory and Practice Abstract: Since the discovery of turbo codes 20 years ago and the subsequent\nre-discovery of low-density parity-check codes a few years later, the field of\nchannel coding has experienced a number of major advances. Up until that time,\ncode designers were usually happy with performance that came within a few\ndecibels of the Shannon Limit, primarily due to implementation complexity\nconstraints, whereas the new coding techniques now allow performance within a\nsmall fraction of a decibel of capacity with modest encoding and decoding\ncomplexity. Due to these significant improvements, coding standards in\napplications as varied as wireless mobile transmission, satellite TV, and deep\nspace communication are being updated to incorporate the new techniques. In\nthis paper, we review a particularly exciting new class of low-density\nparity-check codes, called spatially-coupled codes, which promise excellent\nperformance over a broad range of channel conditions and decoded error rate\nrequirements. \n\n"}
{"id": "1310.4761", "contents": "Title: Towards Energy Neutrality in Energy Harvesting Wireless Sensor Networks:\n  A Case for Distributed Compressive Sensing? Abstract: This paper advocates the use of the emerging distributed compressive sensing\n(DCS) paradigm in order to deploy energy harvesting (EH) wireless sensor\nnetworks (WSN) with practical network lifetime and data gathering rates that\nare substantially higher than the state-of-the-art. In particular, we argue\nthat there are two fundamental mechanisms in an EH WSN: i) the energy diversity\nassociated with the EH process that entails that the harvested energy can vary\nfrom sensor node to sensor node, and ii) the sensing diversity associated with\nthe DCS process that entails that the energy consumption can also vary across\nthe sensor nodes without compromising data recovery. We also argue that such\nmechanisms offer the means to match closely the energy demand to the energy\nsupply in order to unlock the possibility for energy-neutral WSNs that leverage\nEH capability. A number of analytic and simulation results are presented in\norder to illustrate the potential of the approach. \n\n"}
{"id": "1310.5684", "contents": "Title: Linear tree codes and the problem of explicit constructions Abstract: We reduce the problem of constructing asymptotically good tree codes to the\nconstruction of triangular totally nonsingular matrices over fields with\npolynomially many elements. We show a connection of this problem to Birkhoff\ninterpolation in finite fields. \n\n"}
{"id": "1310.8135", "contents": "Title: Large-Scale Sensor Network Localization via Rigid Subnetwork\n  Registration Abstract: In this paper, we describe an algorithm for sensor network localization (SNL)\nthat proceeds by dividing the whole network into smaller subnetworks, then\nlocalizes them in parallel using some fast and accurate algorithm, and finally\nregisters the localized subnetworks in a global coordinate system. We\ndemonstrate that this divide-and-conquer algorithm can be used to leverage\nexisting high-precision SNL algorithms to large-scale networks, which could\notherwise only be applied to small-to-medium sized networks. The main\ncontribution of this paper concerns the final registration phase. In\nparticular, we consider a least-squares formulation of the registration problem\n(both with and without anchor constraints) and demonstrate how this otherwise\nnon-convex problem can be relaxed into a tractable convex program. We provide\nsome preliminary simulation results for large-scale SNL demonstrating that the\nproposed registration algorithm (together with an accurate localization scheme)\noffers a good tradeoff between run time and accuracy. \n\n"}
{"id": "1311.3045", "contents": "Title: Joint Power and Admission Control: Non-Convex $L_q$ Approximation and An\n  Effective Polynomial Time Deflation Approach Abstract: In an interference limited network, joint power and admission control (JPAC)\naims at supporting a maximum number of links at their specified signal to\ninterference plus noise ratio (SINR) targets while using a minimum total\ntransmission power. Various convex approximation deflation approaches have been\ndeveloped for the JPAC problem. In this paper, we propose an effective\npolynomial time non-convex approximation deflation approach for solving the\nproblem. The approach is based on the non-convex $\\ell_q$-minimization\napproximation of an equivalent sparse $\\ell_0$-minimization reformulation of\nthe JPAC problem where $q\\in(0,1).$ We show that, for any instance of the JPAC\nproblem, there exists a $\\bar q\\in(0,1)$ such that it can be exactly solved by\nsolving its $\\ell_q$-minimization approximation problem with any $q\\in(0, \\bar\nq]$. We also show that finding the global solution of the $\\ell_q$\napproximation problem is NP-hard. Then, we propose a potential reduction\ninterior-point algorithm, which can return an $\\epsilon$-KKT solution of the\nNP-hard $\\ell_q$-minimization approximation problem in polynomial time. The\nreturned solution can be used to check the simultaneous supportability of all\nlinks in the network and to guide an iterative link removal procedure,\nresulting in the polynomial time non-convex approximation deflation approach\nfor the JPAC problem. Numerical simulations show that the proposed approach\noutperforms the existing convex approximation approaches in terms of the number\nof supported links and the total transmission power, particularly exhibiting a\nquite good performance in selecting which subset of links to support. \n\n"}
{"id": "1311.4310", "contents": "Title: Achievable Rate Region of the Bidirectional Buffer-Aided Relay Channel\n  with Block Fading Abstract: The bidirectional relay channel, in which two users communicate with each\nother through a relay node, is a simple but fundamental and practical network\narchitecture. In this paper, we consider the block fading bidirectional relay\nchannel and propose efficient transmission strategies that exploit the block\nfading property of the channel. Thereby, we consider a decode-and-forward relay\nand assume that a direct link between the two users is not present. Our aim is\nto characterize the long-term achievable rate region and to develop protocols\nwhich achieve all points of the obtained rate region. Specifically, in the\nbidirectional relay channel, there exist six possible transmission modes: four\npoint-to-point modes (user 1-to-relay, user 2-to-relay, relay-to-user 1,\nrelay-to-user 2), a multiple-access mode (both users to the relay), and a\nbroadcast mode (the relay to both users). Most existing protocols assume a\nfixed schedule for using a subset of the aforementioned transmission modes.\nMotivated by this limitation, we develop protocols which are not restricted to\nadhere to a predefined schedule for using the transmission modes. In fact,\nbased on the instantaneous channel state information (CSI) of the involved\nlinks, the proposed protocol selects the optimal transmission mode in each time\nslot to maximize the long-term achievable rate region. Thereby, we consider two\ndifferent types of transmit power constraints: 1) a joint long-term power\nconstraint for all nodes, and 2) a fixed transmit power for each node.\nFurthermore, to enable the use of a non-predefined schedule for transmission\nmode selection, the relay has to be equipped with two buffers for storage of\nthe information received from both users. As data buffering increases the\nend-to-end delay, we consider both delay-unconstrained and delay-constrained\ntransmission in the paper. \n\n"}
{"id": "1311.4809", "contents": "Title: Uplink Performance of Large Optimum-Combining Antenna Arrays in\n  Poisson-Cell Networks Abstract: The uplink of a wireless network with base stations distributed according to\na Poisson Point Process (PPP) is analyzed. The base stations are assumed to\nhave a large number of antennas and use linear minimum-mean-square-error (MMSE)\nspatial processing for multiple access. The number of active mobiles per cell\nis limited to permit channel estimation using pilot sequences that are\northogonal in each cell. The cumulative distribution function (CDF) of a\nrandomly located link in a typical cell of such a system is derived when\naccurate channel estimation is available. A simple bound is provided for the\nspectral efficiency when channel estimates suffer from pilot contamination. The\nresults provide insight into the performance of so-called massive\nMultiple-Input-Multiple-Output (MIMO) systems in spatially distributed cellular\nnetworks. \n\n"}
{"id": "1311.4947", "contents": "Title: A Framework of Constructions of Minimal Storage Regenerating Codes with\n  the Optimal Access/Update Property Abstract: In this paper, we present a generic framework for constructing systematic\nminimum storage regenerating codes with two parity nodes based on the invariant\nsubspace technique. Codes constructed in our framework not only contain some\nbest known codes as special cases, but also include some new codes with key\nproperties such as the optimal access property and the optimal update property.\nIn particular, for a given storage capacity of an individual node, one of the\nnew codes has the largest number of systematic nodes and two of the new codes\nhave the largest number of systematic nodes with the optimal update property. \n\n"}
{"id": "1311.7237", "contents": "Title: Beamforming for MISO Interference Channels with QoS and RF Energy\n  Transfer Abstract: We consider a multiuser multiple-input single-output interference channel\nwhere the receivers are characterized by both quality-of-service (QoS) and\nradio-frequency (RF) energy harvesting (EH) constraints. We consider the power\nsplitting RF-EH technique where each receiver divides the received signal into\ntwo parts a) for information decoding and b) for battery charging. The minimum\nrequired power that supports both the QoS and the RF-EH constraints is\nformulated as an optimization problem that incorporates the transmitted power\nand the beamforming design at each transmitter as well as the power splitting\nratio at each receiver. We consider both the cases of fixed beamforming and\nwhen the beamforming design is incorporated into the optimization problem. For\nfixed beamforming we study three standard beamforming schemes, the zero-forcing\n(ZF), the regularized zero-forcing (RZF) and the maximum ratio transmission\n(MRT); a hybrid scheme, MRT-ZF, comprised of a linear combination of MRT and ZF\nbeamforming is also examined. The optimal solution for ZF beamforming is\nderived in closed-form, while optimization algorithms based on second-order\ncone programming are developed for MRT, RZF and MRT-ZF beamforming to solve the\nproblem. In addition, the joint-optimization of beamforming and power\nallocation is studied using semidefinite programming (SDP) with the aid of rank\nrelaxation. \n\n"}
{"id": "1312.0914", "contents": "Title: Characterizing the Rate Region of the (4,3,3) Exact-Repair Regenerating\n  Codes Abstract: Exact-repair regenerating codes are considered for the case (n,k,d)=(4,3,3),\nfor which a complete characterization of the rate region is provided. This\ncharacterization answers in the affirmative the open question whether there\nexists a non-vanishing gap between the optimal bandwidth-storage tradeoff of\nthe functional-repair regenerating codes (i.e., the cut-set bound) and that of\nthe exact-repair regenerating codes. To obtain an explicit information\ntheoretic converse, a computer-aided proof (CAP) approach based on primal and\ndual relation is developed. This CAP approach extends Yeung's linear\nprogramming (LP) method, which was previously only used on information\ntheoretic problems with a few random variables due to the exponential growth of\nthe number of variables in the corresponding LP problem. The symmetry in the\nexact-repair regenerating code problem allows an effective reduction of the\nnumber of variables, and together with several other problem-specific\nreductions, the LP problem is reduced to a manageable scale. For the\nachievability, only one non-trivial corner point of the rate region needs to be\naddressed in this case, for which an explicit binary code construction is\ngiven. \n\n"}
{"id": "1312.0972", "contents": "Title: Rank-Modulation Rewrite Coding for Flash Memories Abstract: The current flash memory technology focuses on the cost minimization of its\nstatic storage capacity. However, the resulting approach supports a relatively\nsmall number of program-erase cycles. This technology is effective for consumer\ndevices (e.g., smartphones and cameras) where the number of program-erase\ncycles is small. However, it is not economical for enterprise storage systems\nthat require a large number of lifetime writes. The proposed approach in this\npaper for alleviating this problem consists of the efficient integration of two\nkey ideas: (i) improving reliability and endurance by representing the\ninformation using relative values via the rank modulation scheme and (ii)\nincreasing the overall (lifetime) capacity of the flash device via rewriting\ncodes, namely, performing multiple writes per cell before erasure. This paper\npresents a new coding scheme that combines rank modulation with rewriting. The\nkey benefits of the new scheme include: (i) the ability to store close to 2\nbits per cell on each write with minimal impact on the lifetime of the memory,\nand (ii) efficient encoding and decoding algorithms that make use of\ncapacity-achieving write-once-memory (WOM) codes that were proposed recently. \n\n"}
{"id": "1312.2045", "contents": "Title: Joint Spatial Division and Multiplexing for mm-Wave Channels Abstract: Massive MIMO systems are well-suited for mm-Wave communications, as large\narrays can be built with reasonable form factors, and the high array gains\nenable reasonable coverage even for outdoor communications. One of the main\nobstacles for using such systems in frequency-division duplex mode, namely the\nhigh overhead for the feedback of channel state information (CSI) to the\ntransmitter, can be mitigated by the recently proposed JSDM (Joint Spatial\nDivision and Multiplexing) algorithm. In this paper we analyze the performance\nof this algorithm in some realistic propagation channels that take into account\nthe partial overlap of the angular spectra from different users, as well as the\nsparsity of mm-Wave channels. We formulate the problem of user grouping for two\ndifferent objectives, namely maximizing spatial multiplexing, and maximizing\ntotal received power, in a graph-theoretic framework. As the resulting problems\nare numerically difficult, we proposed (sub optimum) greedy algorithms as\nefficient solution methods. Numerical examples show that the different\nalgorithms may be superior in different settings.We furthermore develop a new,\n\"degenerate\" version of JSDM that only requires average CSI at the transmitter,\nand thus greatly reduces the computational burden. Evaluations in propagation\nchannels obtained from ray tracing results, as well as in measured outdoor\nchannels show that this low-complexity version performs surprisingly well in\nmm-Wave channels. \n\n"}
{"id": "1312.4716", "contents": "Title: More Classes of Complete Permutation Polynomials over $\\F_q$ Abstract: In this paper, by using a powerful criterion for permutation polynomials\ngiven by Zieve, we give several classes of complete permutation monomials over\n$\\F_{q^r}$. In addition, we present a class of complete permutation\nmultinomials, which is a generalization of recent work. \n\n"}
{"id": "1312.5486", "contents": "Title: Molecular communication networks with general molecular circuit\n  receivers Abstract: In a molecular communication network, transmitters may encode information in\nconcentration or frequency of signalling molecules. When the signalling\nmolecules reach the receivers, they react, via a set of chemical reactions or a\nmolecular circuit, to produce output molecules. The counts of output molecules\nover time is the output signal of the receiver. The aim of this paper is to\ninvestigate the impact of different reaction types on the information\ntransmission capacity of molecular communication networks. We realise this aim\nby using a general molecular circuit model. We derive general expressions of\nmean receiver output, and signal and noise spectra. We use these expressions to\ninvestigate the information transmission capacities of a number of molecular\ncircuits. \n\n"}
{"id": "1312.7135", "contents": "Title: Multihop Backhaul Compression for the Uplink of Cloud Radio Access\n  Networks Abstract: In cloud radio access networks (C-RANs), the baseband processing of the radio\nunits (RUs) is migrated to remote control units (CUs). This is made possible by\na network of backhaul links that connects RUs and CUs and that carries\ncompressed baseband signals. While prior work has focused mostly on single-hop\nbackhaul networks, this paper investigates efficient backhaul compression\nstrategies for the uplink of C-RANs with a general multihop backhaul topology.\nA baseline multiplex-and-forward (MF) scheme is first studied in which each RU\nforwards the bit streams received from the connected RUs without any\nprocessing. It is observed that this strategy may cause significant performance\ndegradation in the presence of a dense deployment of RUs with a well connected\nbackhaul network. To obviate this problem, a scheme is proposed in which each\nRU decompresses the received bit streams and performs linear in-network\nprocessing of the decompressed signals. For both the MF and the\ndecompress-process-and-recompress (DPR) backhaul schemes, the optimal design is\naddressed with the aim of maximizing the sum-rate under the backhaul capacity\nconstraints. Recognizing the significant demands of the optimal solution of the\nDPR scheme in terms of channel state information (CSI) at the RUs,\ndecentralized optimization algorithms are proposed under the assumption of\nlimited CSI at the RUs. Numerical results are provided to compare the\nperformance of the MF and DPR schemes, highlighting the potential advantage of\nin-network processing and the impact of CSI limitations. \n\n"}
{"id": "1312.7695", "contents": "Title: A discretization-free sparse and parametric approach for linear array\n  signal processing Abstract: Direction of arrival (DOA) estimation in array processing using\nuniform/sparse linear arrays is concerned in this paper. While sparse methods\nvia approximate parameter discretization have been popular in the past decade,\nthe discretization may cause problems, e.g., modeling error and increased\ncomputations due to dense sampling. In this paper, an exact discretization-free\nmethod, named as sparse and parametric approach (SPA), is proposed for uniform\nand sparse linear arrays. SPA carries out parameter estimation in the\ncontinuous range based on well-established covariance fitting criteria and\nconvex optimization. It guarantees to produce a sparse parameter estimate\nwithout discretization required by existing sparse methods. Theoretical\nanalysis shows that the SPA parameter estimator is a large-snapshot realization\nof the maximum likelihood estimator and is statistically consistent (in the\nnumber of snapshots) under uncorrelated sources. Other merits of SPA include\nimproved resolution, applicability to arbitrary number of snapshots, robustness\nto correlation of the sources and no requirement of user-parameters. Numerical\nsimulations are carried out to verify our analysis and demonstrate advantages\nof SPA compared to existing methods. \n\n"}
{"id": "1401.0061", "contents": "Title: On dually flat general $(\\alpha,\\beta)$-metrics Abstract: In this work, the dual flatness, which is connected with Statistics and\nInformation geometry, of general $(\\alpha,\\beta)$-metrics (a new class of\nFinsler metrics) is studied. A nice characterization for such metrics to be\ndually flat under some suitable conditions is provided and all the solutions\nare completely determined. By using an original kind of metrical deformations,\nmany non-trivial explicit examples are constructed. Moreover, the relationship\nof dual flatness and projective flatness of such metrics is shown. \n\n"}
{"id": "1401.1106", "contents": "Title: Structured random measurements in signal processing Abstract: Compressed sensing and its extensions have recently triggered interest in\nrandomized signal acquisition. A key finding is that random measurements\nprovide sparse signal reconstruction guarantees for efficient and stable\nalgorithms with a minimal number of samples. While this was first shown for\n(unstructured) Gaussian random measurement matrices, applications require\ncertain structure of the measurements leading to structured random measurement\nmatrices. Near optimal recovery guarantees for such structured measurements\nhave been developed over the past years in a variety of contexts. This article\nsurveys the theory in three scenarios: compressed sensing (sparse recovery),\nlow rank matrix recovery, and phaseless estimation. The random measurement\nmatrices to be considered include random partial Fourier matrices, partial\nrandom circulant matrices (subsampled convolutions), matrix completion, and\nphase estimation from magnitudes of Fourier type measurements. The article\nconcludes with a brief discussion of the mathematical techniques for the\nanalysis of such structured random measurements. \n\n"}
{"id": "1401.1467", "contents": "Title: The sum $2^{\\mathit{KA}(x)-\\mathit{KP}(x)}$ over all prefixes $x$ of\n  some binary sequence can be infinite Abstract: We consider two quantities that measure complexity of binary strings:\n$\\mathit{KA}(x)$ is defined as the minus logarithm of continuous a priori\nprobability on the binary tree, and $\\mathit{KP}(x)$ denotes prefix complexity\nof a binary string $x$. In this paper we answer a question posed by Joseph\nMiller and prove that there exists an infinite binary sequence $\\omega$ such\nthat the sum of $2^{\\mathit{KA}(x)-\\mathit{KP}(x)}$ over all prefixes $x$ of\n$\\omega$ is infinite. Such a sequence can be chosen among characteristic\nsequences of computably enumerable sets. \n\n"}
{"id": "1401.1480", "contents": "Title: Lower Bounds and Approximations for the Information Rate of the ISI\n  Channel Abstract: We consider the discrete-time intersymbol interference (ISI) channel model,\nwith additive Gaussian noise and fixed i.i.d. inputs. In this setting, we\ninvestigate the expression put forth by Shamai and Laroia as a conjectured\nlower bound for the input-output mutual information after application of a\nMMSE-DFE receiver. A low-SNR expansion is used to prove that the conjectured\nbound does not hold under general conditions, and to characterize inputs for\nwhich it is particularly ill-suited. One such input is used to construct a\ncounterexample, indicating that the Shamai-Laroia expression does not always\nbound even the achievable rate of the channel, thus excluding a natural\nrelaxation of the original conjectured bound. However, this relaxed bound is\nthen shown to hold for any finite entropy input and ISI channel, when the SNR\nis sufficiently high. Finally, new simple bounds for the achievable rate are\nproven, and compared to other known bounds. Information-Estimation relations\nand estimation-theoretic bounds play a key role in establishing our results. \n\n"}
{"id": "1401.1711", "contents": "Title: Energy-Efficient Communication over the Unsynchronized Gaussian Diamond\n  Network Abstract: Communication networks are often designed and analyzed assuming tight\nsynchronization among nodes. However, in applications that require\ncommunication in the energy-efficient regime of low signal-to-noise ratios,\nestablishing tight synchronization among nodes in the network can result in a\nsignificant energy overhead. Motivated by a recent result showing that\nnear-optimal energy efficiency can be achieved over the AWGN channel without\nrequiring tight synchronization, we consider the question of whether the\npotential gains of cooperative communication can be achieved in the absence of\nsynchronization. We focus on the symmetric Gaussian diamond network and\nestablish that cooperative-communication gains are indeed feasible even with\nunsynchronized nodes. More precisely, we show that the capacity per unit energy\nof the unsynchronized symmetric Gaussian diamond network is within a constant\nfactor of the capacity per unit energy of the corresponding synchronized\nnetwork. To this end, we propose a distributed relaying scheme that does not\nrequire tight synchronization but nevertheless achieves most of the energy\ngains of coherent combining. \n\n"}
{"id": "1401.2220", "contents": "Title: Analog Network Coding for Multi-User Spread-Spectrum Communication\n  Systems Abstract: This work presents another look at an analog network coding scheme for\nmulti-user spread-spectrum communication systems. Our proposed system combines\ncoding and cooperation between a relay and users to boost the throughput and to\nexploit interference. To this end, each pair of users, $\\mathcal{A}$ and\n$\\mathcal{B}$, that communicate with each other via a relay $\\mathcal{R}$\nshares the same spreading code. The relay has two roles, it synchronizes\nnetwork transmissions and it broadcasts the combined signals received from\nusers. From user $\\mathcal{B}$'s point of view, the signal is decoded, and\nthen, the data transmitted by user $\\mathcal{A}$ is recovered by subtracting\nuser $\\mathcal{B}$'s own data. We derive the analytical performance of this\nsystem for an additive white Gaussian noise channel with the presence of\nmulti-user interference, and we confirm its accuracy by simulation. \n\n"}
{"id": "1401.2228", "contents": "Title: Multistage Compute-and-Forward with Multilevel Lattice Codes Based on\n  Product Constructions Abstract: A novel construction of lattices is proposed. This construction can be\nthought of as Construction A with codes that can be represented as the\nCartesian product of $L$ linear codes over\n$\\mathbb{F}_{p_1},\\ldots,\\mathbb{F}_{p_L}$, respectively; hence, is referred to\nas the product construction. The existence of a sequence of such lattices that\nare good for quantization and Poltyrev-good under multistage decoding is shown.\nThis family of lattices is then used to generate a sequence of nested lattice\ncodes which allows one to achieve the same computation rate of Nazer and\nGastpar for compute-and-forward under multistage decoding, which is referred to\nas lattice-based multistage compute-and-forward.\n  Motivated by the proposed lattice codes, two families of signal\nconstellations are then proposed for the separation-based compute-and-forward\nframework proposed by Tunali \\textit{et al.} together with a multilevel\ncoding/multistage decoding scheme tailored specifically for these\nconstellations. This scheme is termed separation-based multistage\ncompute-and-forward and is shown having a complexity of the channel coding\ndominated by the greatest common divisor of the constellation size (may not be\na prime number) instead of the constellation size itself. \n\n"}
{"id": "1401.3174", "contents": "Title: Comments on \"Optimal Utilization of a Cognitive Shared Channel with a\n  Rechargeable Primary Source Node\" Abstract: In a recent paper [1], the authors investigated the maximum stable throughput\nregion of a network composed of a rechargeable primary user and a secondary\nuser plugged to a reliable power supply. The authors studied the cases of an\ninfinite and a finite energy queue at the primary transmitter. However, the\nresults of the finite case are incorrect. We show that under the proposed\nenergy queue model (a decoupled ${\\rm M/D/1}$ queueing system with Bernoulli\narrivals and the consumption of one energy packet per time slot), the energy\nqueue capacity does not affect the stability region of the network. \n\n"}
{"id": "1401.3682", "contents": "Title: Broadcast Classical-Quantum Capacity Region of Two-Phase Bidirectional\n  Relaying Channel Abstract: We study a three-node quantum network which enables bidirectional\ncommunication between two nodes with a half-duplex relay node. A\ndecode-and-forward protocol is used to perform the communication in two phases.\nIn the first phase, the messages of two nodes are transmitted to the relay\nnode. In the second phase, the relay node broadcasts a re-encoded composition\nto the two nodes. We determine the capacity region of the broadcast phase. \n\n"}
{"id": "1401.3814", "contents": "Title: Information Geometry Approach to Parameter Estimation in Markov Chains Abstract: We consider the parameter estimation of Markov chain when the unknown\ntransition matrix belongs to an exponential family of transition matrices.\nThen, we show that the sample mean of the generator of the exponential family\nis an asymptotically efficient estimator. Further, we also define a curved\nexponential family of transition matrices. Using a transition matrix version of\nthe Pythagorean theorem, we give an asymptotically efficient estimator for a\ncurved exponential family. \n\n"}
{"id": "1401.3922", "contents": "Title: Discrete Convexity and Stochastic Approximation for Cross-layer On-off\n  Transmission Control Abstract: This paper considers the discrete convexity of a cross-layer on-off\ntransmission control problem in wireless communications. In this system, a\nscheduler decides whether or not to transmit in order to optimize the long-term\nquality of service (QoS) incurred by the queueing effects in the data link\nlayer and the transmission power consumption in the physical (PHY) layer\nsimultaneously. Using a Markov decision process (MDP) formulation, we show that\nthe optimal policy can be determined by solving a minimization problem over a\nset of queue thresholds if the dynamic programming (DP) is submodular. We prove\nthat this minimization problem is discrete convex. In order to search the\nminimizer, we consider two discrete stochastic approximation (DSA) algorithms:\ndiscrete simultaneous perturbation stochastic approximation (DSPSA) and\nL-natural-convex stochastic approximation (L-natural-convex SA). Through\nnumerical studies, we show that the two DSA algorithms converge significantly\nfaster than the existing continuous simultaneous perturbation stochastic\napproximation (CSPSA) algorithm in multi-user systems. Finally, we compare the\nconvergence results and complexity of two DSA and CSPSA algorithms where we\nshow that DSPSA achieves the best trade-off between complexity and accuracy in\nmulti-user systems. \n\n"}
{"id": "1401.5742", "contents": "Title: Diffusion-Based Adaptive Distributed Detection: Steady-State Performance\n  in the Slow Adaptation Regime Abstract: This work examines the close interplay between cooperation and adaptation for\ndistributed detection schemes over fully decentralized networks. The combined\nattributes of cooperation and adaptation are necessary to enable networks of\ndetectors to continually learn from streaming data and to continually track\ndrifts in the state of nature when deciding in favor of one hypothesis or\nanother. The results in the paper establish a fundamental scaling law for the\nsteady-state probabilities of miss-detection and false-alarm in the slow\nadaptation regime, when the agents interact with each other according to\ndistributed strategies that employ small constant step-sizes. The latter are\ncritical to enable continuous adaptation and learning. The work establishes\nthree key results. First, it is shown that the output of the collaborative\nprocess at each agent has a steady-state distribution. Second, it is shown that\nthis distribution is asymptotically Gaussian in the slow adaptation regime of\nsmall step-sizes. And third, by carrying out a detailed large deviations\nanalysis, closed-form expressions are derived for the decaying rates of the\nfalse-alarm and miss-detection probabilities. Interesting insights are gained.\nIn particular, it is verified that as the step-size $\\mu$ decreases, the error\nprobabilities are driven to zero exponentially fast as functions of $1/\\mu$,\nand that the error exponents increase linearly in the number of agents. It is\nalso verified that the scaling laws governing errors of detection and errors of\nestimation over networks behave very differently, with the former having an\nexponential decay proportional to $1/\\mu$, while the latter scales linearly\nwith decay proportional to $\\mu$. It is shown that the cooperative strategy\nallows each agent to reach the same detection performance, in terms of\ndetection error exponents, of a centralized stochastic-gradient solution. \n\n"}
{"id": "1401.6039", "contents": "Title: Constant Compositions in the Sphere Packing Bound for Classical-Quantum\n  Channels Abstract: The sphere packing bound, in the form given by Shannon, Gallager and\nBerlekamp, was recently extended to classical-quantum channels, and it was\nshown that this creates a natural setting for combining probabilistic\napproaches with some combinatorial ones such as the Lov\\'asz theta function. In\nthis paper, we extend the study to the case of constant composition codes. We\nfirst extend the sphere packing bound for classical-quantum channels to this\ncase, and we then show that the obtained result is related to a variation of\nthe Lov\\'asz theta function studied by Marton. We then propose a further\nextension to the case of varying channels and codewords with a constant\nconditional composition given a particular sequence. This extension is then\napplied to auxiliary channels to deduce a bound which can be interpreted as an\nextension of the Elias bound. \n\n"}
{"id": "1401.6145", "contents": "Title: On Stochastic Geometry Modeling of Cellular Uplink Transmission with\n  Truncated Channel Inversion Power Control Abstract: Using stochastic geometry, we develop a tractable uplink modeling paradigm\nfor outage probability and spectral efficiency in both single and multi-tier\ncellular wireless networks. The analysis accounts for per user equipment (UE)\npower control as well as the maximum power limitations for UEs. More\nspecifically, for interference mitigation and robust uplink communication, each\nUE is required to control its transmit power such that the average received\nsignal power at its serving base station (BS) is equal to a certain threshold\n$\\rho_o$. Due to the limited transmit power, the UEs employ a truncated channel\ninversion power control policy with a cutoff threshold of $\\rho_o$. We show\nthat there exists a transfer point in the uplink system performance that\ndepends on the tuple: BS intensity ($\\lambda$), maximum transmit power of UEs\n($P_u$), and $\\rho_o$. That is, when $P_u$ is a tight operational constraint\nwith respect to [w.r.t.] $\\lambda$ and $\\rho_o$, the uplink outage probability\nand spectral efficiency highly depend on the values of $\\lambda$ and $\\rho_o$.\nIn this case, there exists an optimal cutoff threshold $\\rho^*_o$, which\ndepends on the system parameters, that minimizes the outage probability. On the\nother hand, when $P_u$ is not a binding operational constraint w.r.t. $\\lambda$\nand $\\rho_o$, the uplink outage probability and spectral efficiency become\nindependent of $\\lambda$ and $\\rho_o$. We obtain approximate yet accurate\nsimple expressions for outage probability and spectral efficiency which reduce\nto closed-forms in some special cases. \n\n"}
{"id": "1401.7074", "contents": "Title: Phase Precoded Compute-and-Forward with Partial Feedback Abstract: In this work, we propose phase precoding for the compute-and-forward (CoF)\nprotocol. We derive the phase precoded computation rate and show that it is\ngreater than the original computation rate of CoF protocol without precoder. To\nmaximize the phase precoded computation rate, we need to 'jointly' find the\noptimum phase precoding matrix and the corresponding network equation\ncoefficients. This is a mixed integer programming problem where the optimum\nprecoders should be obtained at the transmitters and the network equation\ncoefficients have to be computed at the relays. To solve this problem, we\nintroduce phase precoded CoF with partial feedback. It is a quantized precoding\nsystem where the relay jointly computes both a quasi-optimal precoder from a\nfinite codebook and the corresponding network equations. The index of the\nobtained phase precoder within the codebook will then be fedback to the\ntransmitters. A \"deep hole phase precoder\" is presented as an example of such a\nscheme. We further simulate our scheme with a lattice code carved out of the\nGosset lattice and show that significant coding gains can be obtained in terms\nof equation error performance. \n\n"}
{"id": "1401.8022", "contents": "Title: Synchronizing Rankings via Interactive Communication Abstract: We consider the problem of exact synchronization of two rankings at remote\nlocations connected by a two-way channel. Such synchronization problems arise\nwhen items in the data are distinguishable, as is the case for playlists,\ntasklists, crowdvotes and recommender systems rankings. Our model accounts for\ndifferent constraints on the communication throughput of the forward and\nfeedback links, resulting in different anchoring, syndrome and checksum\ncomputation strategies. Information editing is assumed of the form of\ndeletions, insertions, block deletions/insertions, translocations and\ntranspositions. The protocols developed under the given model are order-optimal\nwith respect to genie aided lower bounds. \n\n"}
{"id": "1402.0197", "contents": "Title: Measuring the Complexity of Self-organizing Traffic Lights Abstract: We apply measures of complexity, emergence and self-organization to an\nabstract city traffic model for comparing a traditional traffic coordination\nmethod with a self-organizing method in two scenarios: cyclic boundaries and\nnon-orientable boundaries. We show that the measures are useful to identify and\ncharacterize different dynamical phases. It becomes clear that different\noperation regimes are required for different traffic demands. Thus, not only\ntraffic is a non-stationary problem, which requires controllers to adapt\nconstantly. Controllers must also change drastically the complexity of their\nbehavior depending on the demand. Based on our measures, we can say that the\nself-organizing method achieves an adaptability level comparable to a living\nsystem. \n\n"}
{"id": "1402.0729", "contents": "Title: Stability and Performance Issues of a Relay Assisted Multiple Access\n  Scheme with MPR Capabilities Abstract: In this work, we study the impact of a relay node to a network with a finite\nnumber of users-sources and a destination node. We assume that the users have\nsaturated queues and the relay node does not have packets of its own; we have\nrandom access of the medium and the time is slotted. The relay node stores a\nsource packet that it receives successfully in its queue when the transmission\nto the destination node has failed. The relay and the destination nodes have\nmulti-packet reception capabilities. We obtain analytical equations for the\ncharacteristics of the relay's queue such as average queue length, stability\nconditions etc. We also study the throughput per user and the aggregate\nthroughput for the network. \n\n"}
{"id": "1402.2011", "contents": "Title: Locality and Availability in Distributed Storage Abstract: This paper studies the problem of code symbol availability: a code symbol is\nsaid to have $(r, t)$-availability if it can be reconstructed from $t$ disjoint\ngroups of other symbols, each of size at most $r$. For example, $3$-replication\nsupports $(1, 2)$-availability as each symbol can be read from its $t= 2$ other\n(disjoint) replicas, i.e., $r=1$. However, the rate of replication must vanish\nlike $\\frac{1}{t+1}$ as the availability increases.\n  This paper shows that it is possible to construct codes that can support a\nscaling number of parallel reads while keeping the rate to be an arbitrarily\nhigh constant. It further shows that this is possible with the minimum distance\narbitrarily close to the Singleton bound. This paper also presents a bound\ndemonstrating a trade-off between minimum distance, availability and locality.\nOur codes match the aforementioned bound and their construction relies on\ncombinatorial objects called resolvable designs.\n  From a practical standpoint, our codes seem useful for distributed storage\napplications involving hot data, i.e., the information which is frequently\naccessed by multiple processes in parallel. \n\n"}
{"id": "1402.3215", "contents": "Title: Analysis of Compressed Sensing with Spatially-Coupled Orthogonal\n  Matrices Abstract: Recent development in compressed sensing (CS) has revealed that the use of a\nspecial design of measurement matrix, namely the spatially-coupled matrix, can\nachieve the information-theoretic limit of CS. In this paper, we consider the\nmeasurement matrix which consists of the spatially-coupled \\emph{orthogonal}\nmatrices. One example of such matrices are the randomly selected discrete\nFourier transform (DFT) matrices. Such selection enjoys a less memory\ncomplexity and a faster multiplication procedure. Our contributions are the\nreplica calculations to find the mean-square-error (MSE) of the Bayes-optimal\nreconstruction for such setup. We illustrate that the reconstruction thresholds\nunder the spatially-coupled orthogonal and Gaussian ensembles are quite\ndifferent especially in the noisy cases. In particular, the spatially coupled\northogonal matrices achieve the faster convergence rate, the lower measurement\nrate, and the reduced MSE. \n\n"}
{"id": "1402.4238", "contents": "Title: Downlink and Uplink Energy Minimization Through User Association and\n  Beamforming in Cloud RAN Abstract: The cloud radio access network (C-RAN) concept, in which densely deployed\naccess points (APs) are empowered by cloud computing to cooperatively support\nmobile users (MUs), to improve mobile data rates, has been recently proposed.\nHowever, the high density of active (\"on\") APs results in severe interference\nand also inefficient energy consumption. Moreover, the growing popularity of\nhighly interactive applications with stringent uplink (UL) requirements, e.g.\nnetwork gaming and real-time broadcasting by wireless users, means that the UL\ntransmission is becoming more crucial and requires special attention. Therefore\nin this paper, we propose a joint downlink (DL) and UL MU-AP association and\nbeamforming design to coordinate interference in the C-RAN for energy\nminimization, a problem which is shown to be NP hard. Due to the new\nconsideration of UL transmission, it is shown that the two state-of-the-art\napproaches for finding computationally efficient solutions of joint MU-AP\nassociation and beamforming considering only the DL, i.e., group-sparse\noptimization and relaxed-integer programming, cannot be modified in a\nstraightforward way to solve our problem. Leveraging on the celebrated UL-DL\nduality result, we show that by establishing a virtual DL transmission for the\noriginal UL transmission, the joint DL and UL optimization problem can be\nconverted to an equivalent DL problem in C-RAN with two inter-related\nsubproblems for the original and virtual DL transmissions, respectively. Based\non this transformation, two efficient algorithms for joint DL and UL MU-AP\nassociation and beamforming design are proposed, whose performances are\nevaluated and compared with other benchmarking schemes through extensive\nsimulations. \n\n"}
{"id": "1402.4746", "contents": "Title: Near-optimal-sample estimators for spherical Gaussian mixtures Abstract: Statistical and machine-learning algorithms are frequently applied to\nhigh-dimensional data. In many of these applications data is scarce, and often\nmuch more costly than computation time. We provide the first sample-efficient\npolynomial-time estimator for high-dimensional spherical Gaussian mixtures.\n  For mixtures of any $k$ $d$-dimensional spherical Gaussians, we derive an\nintuitive spectral-estimator that uses\n$\\mathcal{O}_k\\bigl(\\frac{d\\log^2d}{\\epsilon^4}\\bigr)$ samples and runs in time\n$\\mathcal{O}_{k,\\epsilon}(d^3\\log^5 d)$, both significantly lower than\npreviously known. The constant factor $\\mathcal{O}_k$ is polynomial for sample\ncomplexity and is exponential for the time complexity, again much smaller than\nwhat was previously known. We also show that\n$\\Omega_k\\bigl(\\frac{d}{\\epsilon^2}\\bigr)$ samples are needed for any\nalgorithm. Hence the sample complexity is near-optimal in the number of\ndimensions.\n  We also derive a simple estimator for one-dimensional mixtures that uses\n$\\mathcal{O}\\bigl(\\frac{k \\log \\frac{k}{\\epsilon} }{\\epsilon^2} \\bigr)$ samples\nand runs in time\n$\\widetilde{\\mathcal{O}}\\left(\\bigl(\\frac{k}{\\epsilon}\\bigr)^{3k+1}\\right)$.\nOur other technical contributions include a faster algorithm for choosing a\ndensity estimate from a set of distributions, that minimizes the $\\ell_1$\ndistance to an unknown underlying distribution. \n\n"}
{"id": "1402.5073", "contents": "Title: Exploiting Two-Dimensional Group Sparsity in 1-Bit Compressive Sensing Abstract: We propose a new approach, {\\it two-dimensional fused binary compressive\nsensing} (2DFBCS) to recover 2D sparse piece-wise signals from 1-bit\nmeasurements, exploiting 2D group sparsity for 1-bit compressive sensing\nrecovery. The proposed method is a modified 2D version of the previous {\\it\nbinary iterative hard thresholding} (2DBIHT) algorithm, where the objective\nfunction includes a 2D one-sided $\\ell_1$ (or $\\ell_2$) penalty function\nencouraging agreement with the observed data, an indicator function of\n$K$-sparsity, and a total variation (TV) or modified TV (MTV) constraint. The\nsubgradient of the 2D one-sided $\\ell_1$ (or $\\ell_2$) penalty and the\nprojection onto the $K$-sparsity and TV or MTV constraint can be computed\nefficiently, allowing the appliaction of algorithms of the {\\it\nforward-backward splitting} (a.k.a. {\\it iterative shrinkage-thresholding})\nfamily. Experiments on the recovery of 2D sparse piece-wise smooth signals show\nthat the proposed approach is able to take advantage of the piece-wise\nsmoothness of the original signal, achieving more accurate recovery than\n2DBIHT. More specifically, 2DFBCS with the MTV and the $\\ell_2$ penalty\nperforms best amongst the algorithms tested. \n\n"}
{"id": "1403.1757", "contents": "Title: Hilberg Exponents: New Measures of Long Memory in the Process Abstract: The paper concerns the rates of power-law growth of mutual information\ncomputed for a stationary measure or for a universal code. The rates are called\nHilberg exponents and four such quantities are defined for each measure and\neach code: two random exponents and two expected exponents. A particularly\ninteresting case arises for conditional algorithmic mutual information. In this\ncase, the random Hilberg exponents are almost surely constant on ergodic\nsources and are bounded by the expected Hilberg exponents. This property is a\n\"second-order\" analogue of the Shannon-McMillan-Breiman theorem, proved without\ninvoking the ergodic theorem. It carries over to Hilberg exponents for the\nunderlying probability measure via Shannon-Fano coding and Barron inequality.\nMoreover, the expected Hilberg exponents can be linked for different universal\ncodes. Namely, if one code dominates another, the expected Hilberg exponents\nare greater for the former than for the latter. The paper is concluded by an\nevaluation of Hilberg exponents for certain sources such as the mixture\nBernoulli process and the Santa Fe processes. \n\n"}
{"id": "1403.4333", "contents": "Title: Increasing Flash Memory Lifetime by Dynamic Voltage Allocation for\n  Constant Mutual Information Abstract: The read channel in Flash memory systems degrades over time because the\nFowler-Nordheim tunneling used to apply charge to the floating gate eventually\ncompromises the integrity of the cell because of tunnel oxide degradation.\nWhile degradation is commonly measured in the number of program/erase cycles\nexperienced by a cell, the degradation is proportional to the number of\nelectrons forced into the floating gate and later released by the erasing\nprocess. By managing the amount of charge written to the floating gate to\nmaintain a constant read-channel mutual information, Flash lifetime can be\nextended. This paper proposes an overall system approach based on information\ntheory to extend the lifetime of a flash memory device. Using the instantaneous\nstorage capacity of a noisy flash memory channel, our approach allocates the\nread voltage of flash cell dynamically as it wears out gradually over time. A\npractical estimation of the instantaneous capacity is also proposed based on\nsoft information via multiple reads of the memory cells. \n\n"}
{"id": "1403.7012", "contents": "Title: On the Degrees of freedom of the K-user MISO Interference Channel with\n  imperfect delayed CSIT Abstract: This work investigates the degrees of freedom (DoF) of the K-user\nmultiple-input single-output (MISO) interference channel (IC) with imperfect\ndelayed channel state information at the transmitters (dCSIT). For this\nsetting, new DoF inner bonds are provided, and benchmarked with\ncooperation-based outer bounds. The achievability result is based on a\nprecoding scheme that aligns the interfering received signals through time,\nexploiting the concept of Retrospective Interference Alignment (RIA). The\nproposed approach outperforms all previous known schemes. Furthermore, we study\nthe proposed scheme under channel estimation errors (CEE) on the reported\ndCSIT, and derive a closed-form expression for the achievable DoF with\nimperfect dCSIT. \n\n"}
{"id": "1404.1443", "contents": "Title: Upper-Bounding the Capacity of Relay Communications - Part II Abstract: This paper focuses on the capacity of peer-to-peer relay communications\nwherein the transmitter are assisted by an arbitrary number of parallel relays,\ni.e. there is no link and cooperation between the relays themselves. We detail\nthe mathematical model of different relaying strategies including cutset and\namplify and forward strategies. The cutset upper bound capacity is presented as\na reference to compare another realistic strategy. We present its outer region\ncapacity which is lower than that in the existing literature. We show that a\nmultiple parallel relayed network achieves its maximum capacity by virtue of\nonly one relay or by virtue of all relays together. Adding a relay may even\ndecrease the overall capacity or may do not change it. We exemplify various\nouter region capacities of the addressed strategies with two different case\nstudies. The results exhibit that in low signal-to-noise ratio (SNR)\nenvironments the cutset outperforms the amplify and forward strategy and this\nis contrary in high SNR environments. \n\n"}
{"id": "1404.1547", "contents": "Title: Asymptotic Behavior of Ultra-Dense Cellular Networks and Its Economic\n  Impact Abstract: This paper investigates the relationship between base station (BS) density\nand average spectral efficiency (SE) in the downlink of a cellular network.\nThis relationship has been well known for sparse deployment, i.e. when the\nnumber of BSs is small compared to the number of users. In this case the SE is\nindependent of BS density. As BS density grows, on the other hand, it has\npreviously been shown that increasing the BS density increases the SE, but no\ntractable form for the SE-BS density relationship has yet been derived. In this\npaper we derive such a closed-form result that reveals the SE is asymptotically\na logarithmic function of BS density as the density grows. Further, we study\nthe impact of this result on the network operator's profit when user demand\nvaries, and derive the profit maximizing BS density and the optimal amount of\nspectrum to be utilized in closed forms. In addition, we provide deployment\nplanning guidelines that will aid the operator in his decision if he should\ninvest in densifying his network or in acquiring more spectrum. \n\n"}
{"id": "1404.2006", "contents": "Title: K\\\"ahlerian information geometry for signal processing Abstract: We prove the correspondence between the information geometry of a signal\nfilter and a K\\\"ahler manifold. The information geometry of a minimum-phase\nlinear system with a finite complex cepstrum norm is a K\\\"ahler manifold. The\nsquare of the complex cepstrum norm of the signal filter corresponds to the\nK\\\"ahler potential. The Hermitian structure of the K\\\"ahler manifold is\nexplicitly emergent if and only if the impulse response function of the highest\ndegree in $z$ is constant in model parameters. The K\\\"ahlerian information\ngeometry takes advantage of more efficient calculation steps for the metric\ntensor and the Ricci tensor. Moreover, $\\alpha$-generalization on the geometric\ntensors is linear in $\\alpha$. It is also robust to find Bayesian predictive\npriors, such as superharmonic priors, because Laplace-Beltrami operators on\nK\\\"ahler manifolds are in much simpler forms than those of the non-K\\\"ahler\nmanifolds. Several time series models are studied in the K\\\"ahlerian\ninformation geometry. \n\n"}
{"id": "1404.2081", "contents": "Title: Simultaneous Diagonalization: On the DoF Region of the K-user MIMO\n  Multi-way Relay Channel Abstract: The K-user MIMO Y-channel consisting of K users which want to exchange\nmessages among each other via a common relay node is studied in this paper. A\ntransmission strategy based on channel diagonalization using zero-forcing\nbeam-forming is proposed. This strategy is then combined with signal-space\nalignment for network-coding, and the achievable degrees-of-freedom region is\nderived. A new degrees-of-freedom outer bound is also derived and it is shown\nthat the proposed strategy achieves this outer bound if the users have more\nantennas than the relay. \n\n"}
{"id": "1404.2796", "contents": "Title: Linear Batch Codes Abstract: In an application, where a client wants to obtain many elements from a large\ndatabase, it is often desirable to have some load balancing. Batch codes\n(introduced by Ishai et al. in STOC 2004) make it possible to do exactly that:\nthe large database is divided between many servers, so that the client has to\nonly make a small number of queries to every server to obtain sufficient\ninformation to reconstruct all desired elements. Other important parameters of\nthe batch codes are total storage and the number of servers. Batch codes also\nhave applications in cryptography (namely, in the construction of multi-query\ncomputationally-private information retrieval protocols).\n  In this work, we initiate the study of linear batch codes. These codes, in\nparticular, are of potential use in distributed storage systems. We show that a\ngenerator matrix of a binary linear batch code is also a generator matrix of\nclassical binary linear error-correcting code. This immediately yields that a\nvariety of upper bounds, which were developed for error-correcting codes, are\napplicable also to binary linear batch codes. We also propose new methods to\nconstruct large linear batch codes from the smaller ones. \n\n"}
{"id": "1404.3010", "contents": "Title: On the Energy-Spectral Efficiency Trade-off of the MRC Receiver in\n  Massive MIMO Systems with Transceiver Power Consumption Abstract: We consider the uplink of a multiuser massive MIMO system wherein a base\nstation (BS) having $M$ antennas communicates coherently with $K$ single\nantenna user terminals (UTs). We study the energy efficiency of this system\nwhile taking the transceiver power consumption at the UTs and the BS into\nconsideration. For a given spectral efficiency $R$ and fixed transceiver power\nconsumption parameters, we propose and analyze the problem of maximizing the\nenergy efficiency as a function of $(M,K)$. For the maximum ratio combining\n(MRC) detector at the BS we show that with increasing $R$, $(M,K)$ can be\nadaptively increased in such a way that the energy efficiency converges to a\npositive constant as $R \\rightarrow \\infty$ ($(M,K)$ is increased in such a way\nthat a constant per-user spectral efficiency $R/K$ is maintained). This is in\ncontrast to the fixed $(M,K)$ scenario where the energy efficiency is known to\nconverge to zero as $R \\rightarrow \\infty$. We also observe that for large $R$,\nthe optimal $(M,K)$ maximizing the energy efficiency is such that, the total\npower consumed by the power amplifiers (PA) in all the $K$ UTs is a small\nfraction of the total system power consumption. \n\n"}
{"id": "1404.3637", "contents": "Title: A Game-Theoretic Framework for Decentralized Cooperative Data Exchange\n  using Network Coding Abstract: In this paper, we introduce a game theoretic framework for studying the\nproblem of minimizing the delay of instantly decodable network coding (IDNC)\nfor cooperative data exchange (CDE) in decentralized wireless network. In this\nconfiguration, clients cooperate with each other to recover the erased packets\nwithout a central controller. Game theory is employed herein as a tool for\nimproving the distributed solution by overcoming the need for a central\ncontroller or additional signaling in the system. We model the session by\nself-interested players in a non-cooperative potential game. The utility\nfunctions are designed such that increasing individual payoff results in a\ncollective behavior achieving both a desirable system performance in a shared\nnetwork environment and the Nash bargaining solution. Three games are\ndeveloped: the first aims to reduce the completion time, the second to reduce\nthe maximum decoding delay and the third the sum decoding delay. We improve\nthese formulations to include punishment policy upon collision occurrence and\nachieve the Nash bargaining solution. Through extensive simulations, our\nframework is tested against the best performance that could be found in the\nconventional point-to-multipoint (PMP) recovery process in numerous cases:\nfirst we simulate the problem with complete information. We, then, simulate\nwith incomplete information and finally we test it in lossy feedback scenario.\nNumerical results show that our formulation with complete information largely\noutperforms the conventional PMP scheme in most situations and achieves a lower\ndelay. They also show that the completion time formulation with incomplete\ninformation also outperforms the conventional PMP. \n\n"}
{"id": "1404.5012", "contents": "Title: On the MacWilliams Identity for Classical and Quantum Convolutional\n  Codes Abstract: The weight generating functions associated with convolutional codes (CCs) are\nbased on state space realizations or the weight adjacency matrices (WAMs). The\nMacWilliams identity for CCs on the WAMs was first established by Gluesing-\nLuerssen and Schneider in the case of minimal encoders, and generalized by\nForney. We consider this problem in the viewpoint of constraint codes and\nobtain a simple and direct proof of this MacWilliams identity in the case of\nminimal encoders. For our purpose, we choose a different representation for the\nexact weight generating function (EWGF) of a block code, by defining it as a\nlinear combination of orthonormal vectors in Dirac bra-ket notation. This\nrepresentation provides great flexibility so that general split weight\ngenerating functions and their MacWilliams identities can be easily obtained\nfrom the MacWilliams identity for EWGFs. As a result, we also obtain the\nMacWilliams identity for the input-parity weight adjacency matrices of a\nsystematic convolutional code and its dual. Finally, paralleling the\ndevelopment of the classical case, we establish the MacWilliams identity for\nquantum convolutional codes. \n\n"}
{"id": "1404.5940", "contents": "Title: A strong converse for the quantum state merging protocol Abstract: The Polyanskiy-Verd\\'{u} paradigm provides an elegant way of using\ngeneralized-divergences to obtain strong converses and thus far has remained\nconfined to protocols involving channels (classical or quantum). In this paper,\ndrawing inspirations from it, we provide strong converses for protocols\ninvolving LOCC (local operations and classical communication). The key quantity\nthat we work with is the R\\'{e}nyi relative entropy of entanglement. We provide\na strong converse for the quantum state merging protocol that gives an\nexponential decay of the fidelity of the protocol for rates below the optimum\nwith the number of copies of the state and are provided both for entanglement\nrate with LOCC as well as for classical communication with one-way LOCC. As an\naside, the developments also yield short strong converses for the\nentanglement-concentration of pure states and the Schumacher compression. \n\n"}
{"id": "1404.6320", "contents": "Title: Demystifying the Scaling Laws of Dense Wireless Networks: No Linear\n  Scaling in Practice Abstract: We optimize the hierarchical cooperation protocol of Ozgur, Leveque and Tse,\nwhich is supposed to yield almost linear scaling of the capacity of a dense\nwireless network with the number of users $n$. Exploiting recent results on the\noptimality of \"treating interference as noise\" in Gaussian interference\nchannels, we are able to optimize the achievable average per-link rate and not\njust its scaling law. Our optimized hierarchical cooperation protocol\nsignificantly outperforms the originally proposed scheme. On the negative side,\nwe show that even for very large $n$, the rate scaling is far from linear, and\nthe optimal number of stages $t$ is less than 4, instead of $t \\rightarrow\n\\infty$ as required for almost linear scaling. Combining our results and the\nfact that, beyond a certain user density, the network capacity is fundamentally\nlimited by Maxwell laws, as shown by Francheschetti, Migliore and Minero, we\nargue that there is indeed no intermediate regime of linear scaling for dense\nnetworks in practice. \n\n"}
{"id": "1404.6512", "contents": "Title: Cellular Interference Alignment: Omni-Directional Antennas and\n  Asymmetric Configurations Abstract: Although interference alignment (IA) can theoretically achieve the optimal\ndegrees of freedom (DoFs) in the $K$-user Gaussian interference channel, its\ndirect application comes at the prohibitive cost of precoding over\nexponentially-many signaling dimensions. On the other hand, it is known that\npractical \"one-shot\" IA precoding (i.e., linear schemes without symbol\nexpansion) provides a vanishing DoFs gain in large fully-connected networks\nwith generic channel coefficients. In our previous work, we introduced the\nconcept of \"Cellular IA\" for a network topology induced by hexagonal cells with\nsectors and nearest-neighbor interference. Assuming that neighboring sectors\ncan exchange decoded messages (and not received signal samples) in the uplink,\nwe showed that linear one-shot IA precoding over $M$ transmit/receive antennas\ncan achieve the optimal $M/2$ DoFs per user. In this paper we extend this\nframework to networks with omni-directional (non-sectorized) cells and consider\nthe practical scenario where users have $2$ antennas, and base-stations have\n$2$, $3$ or $4$ antennas. In particular, we provide linear one-shot IA schemes\nfor the $2\\times 2$, $2\\times3$ and $2\\times 4$ cases, and show the\nachievability of $3/4$, $1$ and $7/6$ DoFs per user, respectively. DoFs\nconverses for one-shot schemes require the solution of a discrete optimization\nproblem over a number of variables that grows with the network size. We develop\na new approach to transform such challenging optimization problem into a\ntractable linear program (LP) with significantly fewer variables. This approach\nis used to show that the achievable $3/4$ DoFs per user are indeed optimal for\na large (extended) cellular network with $2\\times 2$ links. \n\n"}
{"id": "1404.7374", "contents": "Title: Explicit and almost sure conditions for K/2 degrees of freedom Abstract: It is well known that in K-user constant single-antenna interference channels\nK/2 degrees of freedom (DoF) can be achieved for almost all channel matrices.\nExplicit conditions on the channel matrix to admit K/2 DoF are, however, not\navailable. The purpose of this paper is to identify such explicit conditions,\nwhich are satisfied for almost all channel matrices. We also provide a\nconstruction of corresponding asymptotically DoF-optimal input distributions.\nThe main technical tool used is a recent breakthrough result by Hochman in\nfractal geometry. \n\n"}
{"id": "1404.7736", "contents": "Title: Massive MIMO with 1-bit ADC Abstract: We investigate massive multiple-input-multiple output (MIMO) uplink systems\nwith 1-bit analog-to-digital converters (ADCs) on each receiver antenna.\nReceivers that rely on 1-bit ADC do not need energy-consuming interfaces such\nas automatic gain control (AGC). This decreases both ADC building and\noperational costs. Our design is based on maximal ratio combining (MRC),\nzero-forcing (ZF), and least squares (LS) detection, taking into account the\neffects of the 1-bit ADC on channel estimation. Through numerical results, we\nshow good performance of the system in terms of mutual information and symbol\nerror rate (SER). Furthermore, we provide an analytical approach to calculate\nthe mutual information and SER of the MRC receiver. The analytical approach\nreduces complexity in the sense that a symbol and channel noise vectors Monte\nCarlo simulation is avoided. \n\n"}
{"id": "1405.0521", "contents": "Title: Blind MIMOME Wiretap Channel with Delayed CSIT Abstract: We study the Gaussian MIMOME wiretap channel where a transmitter wishes to\ncommunicate a confidential message to a legitimate receiver in the presence of\neavesdroppers, while the eavesdroppers should not be able to decode the\nconfidential message. Each node in the network is equipped with arbitrary\nnumber of antennas. Furthermore, channels are time varying, and there is no\nchannel state information available at the transmitter (CSIT) with respect to\neavesdroppers' channels; and transmitter only has access to delayed CSIT of the\nchannel to the legitimate receiver. The secure degrees of freedom (SDoF) for\nsuch network has only been characterized for special cases, and is unknown in\ngeneral. We completely characterize the SDoF of this network for all antenna\nconfigurations. In particular, we strictly improve the state-of-the-art\nachievable scheme for this network by proposing more efficient artificial noise\nalignment at the receivers. Furthermore, we develop a tight upper bound by\nutilizing 4 important inequalities that provide lower bounds on the received\nsignal dimensions at receivers which supply delayed CSIT or no CSIT, or at a\ncollection of receivers where some supply no CSIT. These inequalities together\nallow for analysis of signal dimensions in networks with asymmetric CSIT; and\nas a result, we present a converse proof that leads to characterization of SDoF\nfor all possible antenna configurations. \n\n"}
{"id": "1405.0894", "contents": "Title: Interactive Function Computation via Polar Coding Abstract: In a series of papers N. Ma and P. Ishwar (2011-13) considered a range of\ndistributed source coding problems that arise in the context of iterative\ncomputation of functions, characterizing the region of achievable communication\nrates. We consider the problems of interactive computation of functions by two\nterminals and interactive computation in a collocated network, showing that the\nrate regions for both these problems can be achieved using several rounds of\npolar-coded transmissions. \n\n"}
{"id": "1405.1593", "contents": "Title: Information Nonanticipative Rate Distortion Function and Its\n  Applications Abstract: This paper investigates applications of nonanticipative Rate Distortion\nFunction (RDF) in a) zero-delay Joint Source-Channel Coding (JSCC) design based\non average and excess distortion probability, b) in bounding the Optimal\nPerformance Theoretically Attainable (OPTA) by noncausal and causal codes, and\ncomputing the Rate Loss (RL) of zero-delay and causal codes with respect to\nnoncausal codes. These applications are described using two running examples,\nthe Binary Symmetric Markov Source with parameter p, (BSMS(p)) and the\nmultidimensional partially observed Gaussian-Markov source. For the\nmultidimensional Gaussian-Markov source with square error distortion, the\nsolution of the nonanticipative RDF is derived, its operational meaning using\nJSCC design via a noisy coding theorem is shown by providing the optimal\nencoding-decoding scheme over a vector Gaussian channel, and the RL of causal\nand zero-delay codes with respect to noncausal codes is computed.\n  For the BSMS(p) with Hamming distortion, the solution of the nonanticipative\nRDF is derived, the RL of causal codes with respect to noncausal codes is\ncomputed, and an uncoded noisy coding theorem based on excess distortion\nprobability is shown. The information nonanticipative RDF is shown to be\nequivalent to the nonanticipatory epsilon-entropy, which corresponds to the\nclassical RDF with an additional causality or nonanticipative condition imposed\non the optimal reproduction conditional distribution. \n\n"}
{"id": "1405.1665", "contents": "Title: On Communication Cost of Distributed Statistical Estimation and\n  Dimensionality Abstract: We explore the connection between dimensionality and communication cost in\ndistributed learning problems. Specifically we study the problem of estimating\nthe mean $\\vec{\\theta}$ of an unknown $d$ dimensional gaussian distribution in\nthe distributed setting. In this problem, the samples from the unknown\ndistribution are distributed among $m$ different machines. The goal is to\nestimate the mean $\\vec{\\theta}$ at the optimal minimax rate while\ncommunicating as few bits as possible. We show that in this setting, the\ncommunication cost scales linearly in the number of dimensions i.e. one needs\nto deal with different dimensions individually. Applying this result to\nprevious lower bounds for one dimension in the interactive setting\n\\cite{ZDJW13} and to our improved bounds for the simultaneous setting, we prove\nnew lower bounds of $\\Omega(md/\\log(m))$ and $\\Omega(md)$ for the bits of\ncommunication needed to achieve the minimax squared loss, in the interactive\nand simultaneous settings respectively. To complement, we also demonstrate an\ninteractive protocol achieving the minimax squared loss with $O(md)$ bits of\ncommunication, which improves upon the simple simultaneous protocol by a\nlogarithmic factor. Given the strong lower bounds in the general setting, we\ninitiate the study of the distributed parameter estimation problems with\nstructured parameters. Specifically, when the parameter is promised to be\n$s$-sparse, we show a simple thresholding based protocol that achieves the same\nsquared loss while saving a $d/s$ factor of communication. We conjecture that\nthe tradeoff between communication and squared loss demonstrated by this\nprotocol is essentially optimal up to logarithmic factor. \n\n"}
{"id": "1405.1782", "contents": "Title: When are dynamic relaying strategies necessary in half-duplex wireless\n  networks? Abstract: We study a simple question: when are dynamic relaying strategies essential in\noptimizing the diversity-multiplexing tradeoff (DMT) in half-duplex wireless\nrelay networks? This is motivated by apparently two contrasting results even\nfor a simple 3 node network, with a single half-duplex relay. When all channels\nare assumed to be i.i.d. fading, a static schedule where the relay listens half\nthe time and transmits half the time combined with quantize-map-forward (QMF)\nrelaying is known to achieve the full-duplex performance. However, when there\nis no direct link between source and destination, a dynamic-decode-forward\n(DDF) strategy is needed to achieve the optimal tradeoff. In this case, a\nstatic schedule is strictly suboptimal and the optimal tradeoff is\nsignificantly worse than the full-duplex performance. In this paper we study\nthe general case when the direct link is neither as strong as the other links\nnor fully non-existent, and identify regimes where dynamic schedules are\nnecessary and those where static schedules are enough. We identify 4\nqualitatively different regimes for the single relay channel where the tradeoff\nbetween diversity and multiplexing is significantly different. We show that in\nall these regimes one of the above two strategies is sufficient to achieve the\noptimal tradeoff by developing a new upper bound on the best achievable\ntradeoff under channel state information available only at the receivers. A\nnatural next question is whether these two strategies are sufficient to achieve\nthe DMT of more general half-duplex wireless networks. We propose a\ngeneralization of the two existing schemes through a dynamic QMF (DQMF)\nstrategy, where the relay listens for a fraction of time depending on received\nCSI but not long enough to be able to decode. We show that such a DQMF strategy\nis needed to achieve the optimal DMT in a parallel channel with two relays. \n\n"}
{"id": "1405.2562", "contents": "Title: $\\alpha$-divergence derived as the generalized rate function in a\n  power-law system Abstract: The generalized binomial distribution in Tsallis statistics (power-law\nsystem) is explicitly formulated from the precise $q$-Stirling's formula. The\n$\\alpha $-divergence (or $q$-divergence) is uniquely derived from the\ngeneralized binomial distribution in the sense that when $\\alpha\\rightarrow-1$\n(i.e., $q\\rightarrow1$) it recovers KL divergence obtained from the standard\nbinomial distribution. Based on these combinatorial considerations, it is shown\nthat $\\alpha$-divergence (or $q$-divergence) is appeared as the generalized\nrate function in the large deviation estimate in Tsallis statistics. \n\n"}
{"id": "1405.2820", "contents": "Title: A weight-distribution bound for entropy extractors using linear binary\n  codes Abstract: We consider a bound on the bias reduction of a random number generator by\nprocessing based on binary linear codes. We introduce a new bound on the total\nvariation distance of the processed output based on the weight distribution of\nthe code generated by the chosen binary matrix. Starting from this result we\nshow a lower bound for the entropy rate of the output of linear binary\nextractors. \n\n"}
{"id": "1405.2984", "contents": "Title: Multicell Coordinated Beamforming with Rate Outage Constraint--Part II:\n  Efficient Approximation Algorithms Abstract: This paper studies the coordinated beamforming (CoBF) design for the\nmultiple-input single-output interference channel, provided that only channel\ndistribution information is known to the transmitters. The problem under\nconsideration is a probabilistically constrained optimization problem which\nmaximizes a predefined system utility subject to constraints on rate outage\nprobability and power budget of each transmitter. Our recent analysis has shown\nthat the outage-constrained CoBF problem is intricately difficult, e.g.,\nNP-hard. Therefore, the focus of this paper is on suboptimal but\ncomputationally efficient algorithms. Specifically, by leveraging on the block\nsuccessive upper bound minimization (BSUM) method in optimization, we propose a\nGauss-Seidel type algorithm, called distributed BSUM algorithm, which can\nhandle differentiable, monotone and concave system utilities. By exploiting a\nweighted minimum mean-square error (WMMSE) reformulation, we further propose a\nJocobi-type algorithm, called distributed WMMSE algorithm, which can optimize\nthe weighted sum rate utility in a fully parallel manner. To provide a\nperformance benchmark, a relaxed approximation method based on polyblock outer\napproximation is also proposed. Simulation results show that the proposed\nalgorithms are significantly superior to the existing successive convex\napproximation method in both performance and computational efficiency, and can\nyield promising approximation performance. \n\n"}
{"id": "1405.4623", "contents": "Title: Training-Based SWIPT: Optimal Power Splitting at the Receiver Abstract: We consider a point-to-point system with simultaneous wireless information\nand power transfer (SWIPT) over a block fading channel. Each transmission block\nconsists of a training phase and a data transmission phase. Pilot symbols are\ntransmitted during the training phase for channel estimation at the receiver.\nTo enable SWIPT, the receiver adopts a power-splitting design, such that a\nportion of the received signal is used for channel estimation or data\ndetection, while the remaining is used for energy harvesting. We optimally\ndesign the power-splitting ratios for both training and data phases to achieve\nthe best ergodic capacity performance while maintaining a required energy\nharvesting rate. Our result shows how a power-splitting receiver can make the\nbest use of the received pilot and data signals to obtain the optimal SWIPT\nperformance. \n\n"}
{"id": "1405.5618", "contents": "Title: Compressive Phase Retrieval via Generalized Approximate Message Passing Abstract: In phase retrieval, the goal is to recover a signal\n$\\mathbf{x}\\in\\mathbb{C}^N$ from the magnitudes of linear measurements\n$\\mathbf{Ax}\\in\\mathbb{C}^M$. While recent theory has established that\n$M\\approx 4N$ intensity measurements are necessary and sufficient to recover\ngeneric $\\mathbf{x}$, there is great interest in reducing the number of\nmeasurements through the exploitation of sparse $\\mathbf{x}$, which is known as\ncompressive phase retrieval. In this work, we detail a novel, probabilistic\napproach to compressive phase retrieval based on the generalized approximate\nmessage passing (GAMP) algorithm. We then present a numerical study of the\nproposed PR-GAMP algorithm, demonstrating its excellent phase-transition\nbehavior, robustness to noise, and runtime. Our experiments suggest that\napproximately $M\\geq 2K\\log_2(N/K)$ intensity measurements suffice to recover\n$K$-sparse Bernoulli-Gaussian signals for $\\mathbf{A}$ with i.i.d Gaussian\nentries and $K\\ll N$. Meanwhile, when recovering a 6k-sparse 65k-pixel\ngrayscale image from 32k randomly masked and blurred Fourier intensity\nmeasurements at 30~dB measurement SNR, PR-GAMP achieved an output SNR of no\nless than 28~dB in all of 100 random trials, with a median runtime of only 7.3\nseconds. Compared to the recently proposed CPRL, sparse-Fienup, and GESPAR\nalgorithms, our experiments suggest that PR-GAMP has a superior phase\ntransition and orders-of-magnitude faster runtimes as the sparsity and problem\ndimensions increase. \n\n"}
{"id": "1405.5974", "contents": "Title: Living on the Edge: The Role of Proactive Caching in 5G Wireless\n  Networks Abstract: This article explores one of the key enablers of beyond $4$G wireless\nnetworks leveraging small cell network deployments, namely proactive caching.\nEndowed with predictive capabilities and harnessing recent developments in\nstorage, context-awareness and social networks, peak traffic demands can be\nsubstantially reduced by proactively serving predictable user demands, via\ncaching at base stations and users' devices. In order to show the effectiveness\nof proactive caching, we examine two case studies which exploit the spatial and\nsocial structure of the network, where proactive caching plays a crucial role.\nFirstly, in order to alleviate backhaul congestion, we propose a mechanism\nwhereby files are proactively cached during off-peak demands based on file\npopularity and correlations among users and files patterns. Secondly,\nleveraging social networks and device-to-device (D2D) communications, we\npropose a procedure that exploits the social structure of the network by\npredicting the set of influential users to (proactively) cache strategic\ncontents and disseminate them to their social ties via D2D communications.\nExploiting this proactive caching paradigm, numerical results show that\nimportant gains can be obtained for each case study, with backhaul savings and\na higher ratio of satisfied users of up to $22\\%$ and $26\\%$, respectively.\nHigher gains can be further obtained by increasing the storage capability at\nthe network edge. \n\n"}
{"id": "1405.7147", "contents": "Title: New extremal binary self-dual codes from F_4 + uF_4-lifts of quadratic\n  double circulant codes over F_4 Abstract: In this work, quadratic double and quadratic bordered double circulant\nconstructions are applied to F_4 + uF_4 as well as F_4, as a result of which\nextremal binary self-dual codes of length 56 and 64 are obtained. The binary\nextension theorems as well as the ring extension version are used to obtain 7\nextremal self-dual binary codes of length 58, 24 extremal self-dual binary\ncodes of length 66 and 29 extremal self-dual binary codes of length 68, all\nwith new weight enumerators, updating the list of all the known extremal\nself-dual codes in the literature. \n\n"}
{"id": "1406.1055", "contents": "Title: Lattice Codes for the Binary Deletion Channel Abstract: The construction of deletion codes for the Levenshtein metric is reduced to\nthe construction of codes over the integers for the Manhattan metric by run\nlength coding. The latter codes are constructed by expurgation of translates of\nlattices. These lattices, in turn, are obtained from Construction~A applied to\nbinary codes and $\\Z_4-$codes. A lower bound on the size of our codes for the\nManhattan distance are obtained through generalized theta series of the\ncorresponding lattices. \n\n"}
{"id": "1406.2255", "contents": "Title: Energy-Efficient Cooperative Cognitive Relaying Schemes for Cognitive\n  Radio Networks Abstract: We investigate a cognitive radio network in which a primary user (PU) may\ncooperate with a cognitive radio user (i.e., a secondary user (SU)) for\ntransmissions of its data packets. The PU is assumed to be a buffered node\noperating in a time-slotted fashion where the time is partitioned into\nequal-length slots. We develop two schemes which involve cooperation between\nprimary and secondary users. To satisfy certain quality of service (QoS)\nrequirements, users share time slot duration and channel frequency bandwidth.\nMoreover, the SU may leverage the primary feedback message to further increase\nboth its data rate and satisfy the PU QoS requirements. The proposed\ncooperative schemes are designed such that the SU data rate is maximized under\nthe constraint that the PU average queueing delay is maintained less than the\naverage queueing delay in case of non-cooperative PU. In addition, the proposed\nschemes guarantee the stability of the PU queue and maintain the average energy\nemitted by the SU below a certain value. The proposed schemes also provide more\nrobust and potentially continuous service for SUs compared to the conventional\npractice in cognitive networks where SUs transmit in the spectrum holes and\nsilence sessions of the PUs. We include primary source burstiness, sensing\nerrors, and feedback decoding errors to the analysis of our proposed\ncooperative schemes. The optimization problems are solved offline and require a\nsimple 2-dimensional grid-based search over the optimization variables.\nNumerical results show the beneficial gains of the cooperative schemes in terms\nof SU data rate and PU throughput, average PU queueing delay, and average PU\nenergy savings. \n\n"}
{"id": "1406.2738", "contents": "Title: Wireless Backhaul Networks: Capacity Bound, Scalability Analysis and\n  Design Guidelines Abstract: This paper studies the scalability of a wireless backhaul network modeled as\na random extended network with multi-antenna base stations (BSs), where the\nnumber of antennas per BS is allowed to scale as a function of the network\nsize. The antenna scaling is justified by the current trend towards the use of\nhigher carrier frequencies, which allows to pack large number of antennas in\nsmall form factors. The main goal is to study the per-BS antenna requirement\nthat ensures scalability of this network, i.e., its ability to deliver\nnon-vanishing rate to each source-destination pair. We first derive an\ninformation theoretic upper bound on the capacity of this network under a\ngeneral propagation model, which provides a lower bound on the per-BS antenna\nrequirement. Then, we characterize the scalability requirements for two\ncompeting strategies of interest: (i) long hop: each source-destination pair\nminimizes the number of hops by sacrificing multiplexing gain while achieving\nfull beamforming (power) gain over each hop, and (ii) short hop: each\nsource-destination pair communicates through a series of short hops, each\nachieving full multiplexing gain. While long hop may seem more intuitive in the\ncontext of massive multiple-input multiple-output (MIMO) transmission, we show\nthat the short hop strategy is significantly more efficient in terms of per-BS\nantenna requirement for throughput scalability. As a part of the proof, we\nconstruct a scalable short hop strategy and show that it does not violate any\nfundamental limits on the spatial degrees of freedom (DoFs). \n\n"}
{"id": "1406.3368", "contents": "Title: Lattices from Codes for Harnessing Interference: An Overview and\n  Generalizations Abstract: In this paper, using compute-and-forward as an example, we provide an\noverview of constructions of lattices from codes that possess the right\nalgebraic structures for harnessing interference. This includes Construction A,\nConstruction D, and Construction $\\pi_A$ (previously called product\nconstruction) recently proposed by the authors. We then discuss two\ngeneralizations where the first one is a general construction of lattices named\nConstruction $\\pi_D$ subsuming the above three constructions as special cases\nand the second one is to go beyond principal ideal domains and build lattices\nover algebraic integers. \n\n"}
{"id": "1406.4775", "contents": "Title: Non-negative Principal Component Analysis: Message Passing Algorithms\n  and Sharp Asymptotics Abstract: Principal component analysis (PCA) aims at estimating the direction of\nmaximal variability of a high-dimensional dataset. A natural question is: does\nthis task become easier, and estimation more accurate, when we exploit\nadditional knowledge on the principal vector? We study the case in which the\nprincipal vector is known to lie in the positive orthant. Similar constraints\narise in a number of applications, ranging from analysis of gene expression\ndata to spike sorting in neural signal processing.\n  In the unconstrained case, the estimation performances of PCA has been\nprecisely characterized using random matrix theory, under a statistical model\nknown as the `spiked model.' It is known that the estimation error undergoes a\nphase transition as the signal-to-noise ratio crosses a certain threshold.\nUnfortunately, tools from random matrix theory have no bearing on the\nconstrained problem. Despite this challenge, we develop an analogous\ncharacterization in the constrained case, within a one-spike model.\n  In particular: $(i)$~We prove that the estimation error undergoes a similar\nphase transition, albeit at a different threshold in signal-to-noise ratio that\nwe determine exactly; $(ii)$~We prove that --unlike in the unconstrained case--\nestimation error depends on the spike vector, and characterize the least\nfavorable vectors; $(iii)$~We show that a non-negative principal component can\nbe approximately computed --under the spiked model-- in nearly linear time.\nThis despite the fact that the problem is non-convex and, in general, NP-hard\nto solve exactly. \n\n"}
{"id": "1406.4928", "contents": "Title: Diversity Multiplexing Tradeoff of the Half-duplex Slow Fading Multiple\n  Access Channel based on Generalized Quantize-and-Forward Scheme Abstract: This paper investigates the Diversity Multiplexing Tradeoff (DMT) of the\ngeneralized quantize-and-forward (GQF) relaying scheme over the slow fading\nhalf-duplex multiple-access relay channel (HD-MARC). The compress-and-forward\n(CF) scheme has been shown to achieve the optimal DMT when the channel state\ninformation (CSI) of the relay-destination link is available at the relay.\nHowever, having the CSI of relay-destination link at relay is not always\npossible due to the practical considerations of the wireless system. In\ncontrast, in this work, the DMT of the GQF scheme is derived without\nrelay-destination link CSI at the relay. It is shown that even without\nknowledge of relay-destination CSI, the GQF scheme achieves the same DMT,\nachievable by CF scheme with full knowledge of CSI. \n\n"}
{"id": "1406.5582", "contents": "Title: Optimal Offline Packet Scheduling in Energy Harvesting 2-user Multiple\n  Access Channel with Common Data Abstract: The lifetime and the sustainability of the wireless sensor networks (WSNs)\ncan be increased with energy harvesting transmitters utilizing optimum packet\nscheduling. On the other hand, WSNs are observed to collect spatially or\ntemporally correlated data which should be taken into account for the optimum\npacket scheduling in an energy harvesting system. However, the solutions\navailable for 2-user multiple-access channel (MAC) systems with energy\nharvesting transmitters do not consider the common data or the correlation\namong the data. In this paper, optimal packet scheduling for energy harvesting\n2-user Gaussian MAC with common data is achieved by assuming deterministic\nknowledge of the data and energy packets, i.e., offline solution. The optimum\ndeparture region is found by using Karush- Kuhn-Tucker (KKT) conditions\ngeneralizing the solutions obtained for the MAC without common data. An\nefficient iterative backward water-filling algorithm is defined. The optimum\nsolution is numerically compared with the case of no scheduling, uniform power\nscheduling and the previous solutions defined for the MAC without common data\nby showing the improvement obtained with the optimization. \n\n"}
{"id": "1406.6514", "contents": "Title: SURE Information Criteria for Large Covariance Matrix Estimation and\n  Their Asymptotic Properties Abstract: Consider $n$ independent and identically distributed $p$-dimensional Gaussian\nrandom vectors with covariance matrix $\\Sigma.$ The problem of estimating\n$\\Sigma$ when $p$ is much larger than $n$ has received a lot of attention in\nrecent years. Yet little is known about the information criterion for\ncovariance matrix estimation. How to properly define such a criterion and what\nare the statistical properties? We attempt to answer these questions in the\npresent paper by focusing on the estimation of bandable covariance matrices\nwhen $p>n$ but $\\log(p)=o(n)$. Motivated by the deep connection between Stein's\nunbiased risk estimation (SURE) and AIC in regression models, we propose a\nfamily of generalized SURE ($\\text{SURE}_c$) indexed by $c$ for covariance\nmatrix estimation, where $c$ is some constant. When $c$ is 2, $\\text{SURE}_2$\nprovides an unbiased estimator of the Frobenious risk of the covariance matrix\nestimator. Furthermore, we show that by minimizing $\\text{SURE}_2$ over all\npossible banding covariance matrix estimators we attain the minimax optimal\nrate of convergence and the resulting estimator behaves like the covariance\nmatrix estimator obtained by the so-called oracle tuning. On the other hand, we\nalso show that $\\text{SURE}_2$ is selection inconsistent when the true\ncovariance matrix is exactly banded. To fix the selection inconsistency, we\nconsider using SURE with $c=\\log(n)$ and prove that by minimizing\n$\\text{SURE}_{\\log(n)}$ we select the true bandwith with probability tending to\none. Therefore, our analysis indicates that $\\text{SURE}_2$ and\n$\\text{SURE}_{\\log(n)}$ can be regarded as the AIC and BIC for large covariance\nmatrix estimation, respectively. \n\n"}
{"id": "1406.7264", "contents": "Title: Repairable Block Failure Resilient Codes Abstract: In large scale distributed storage systems (DSS) deployed in cloud computing,\ncorrelated failures resulting in simultaneous failure (or, unavailability) of\nblocks of nodes are common. In such scenarios, the stored data or a content of\na failed node can only be reconstructed from the available live nodes belonging\nto available blocks. To analyze the resilience of the system against such block\nfailures, this work introduces the framework of Block Failure Resilient (BFR)\ncodes, wherein the data (e.g., file in DSS) can be decoded by reading out from\na same number of codeword symbols (nodes) from each available blocks of the\nunderlying codeword. Further, repairable BFR codes are introduced, wherein any\ncodeword symbol in a failed block can be repaired by contacting to remaining\nblocks in the system. Motivated from regenerating codes, file size bounds for\nrepairable BFR codes are derived, trade-off between per node storage and repair\nbandwidth is analyzed, and BFR-MSR and BFR-MBR points are derived. Explicit\ncodes achieving these two operating points for a wide set of parameters are\nconstructed by utilizing combinatorial designs, wherein the codewords of the\nunderlying outer codes are distributed to BFR codeword symbols according to\nprojective planes. \n\n"}
{"id": "1407.1424", "contents": "Title: Cross Layer Provision of Future Cellular Networks Abstract: To cope with the growing demand for wireless data and to extend service\ncoverage, future 5G networks will increasingly rely on the use of low powered\nnodes to support massive connectivity in diverse set of applications and\nservices [1]. To this end, virtualized and mass-scale cloud architectures are\nproposed as promising technologies for 5G in which all the nodes are connected\nvia a backhaul network and managed centrally by such cloud centers. The\nsignificant computing power made available by the cloud technologies has\nenabled the implementation of sophisticated signal processing algorithms,\nespecially by way of parallel processing, for both interference management and\nnetwork provision. The latter two are among the major signal processing tasks\nfor 5G due to increased level of frequency sharing, node density, interference\nand network congestion. This article outlines several theoretical and practical\naspects of joint interference management and network provisioning for future 5G\nnetworks. A cross-layer optimization framework is proposed for joint user\nadmission, user-base station association, power control, user grouping,\ntransceiver design as well as routing and flow control. We show that many of\nthese cross-layer tasks can be treated in a unified way and implemented in a\nparallel manner using an efficient algorithmic framework called WMMSE (Weighted\nMMSE). Some recent developments in this area are highlighted and future\nresearch directions are identified. \n\n"}
{"id": "1407.3257", "contents": "Title: Demystifying the Information Reconciliation Protocol Cascade Abstract: Cascade is an information reconciliation protocol proposed in the context of\nsecret key agreement in quantum cryptography. This protocol allows removing\ndiscrepancies in two partially correlated sequences that belong to distant\nparties, connected through a public noiseless channel. It is highly\ninteractive, thus requiring a large number of channel communications between\nthe parties to proceed and, although its efficiency is not optimal, it has\nbecome the de-facto standard for practical implementations of information\nreconciliation in quantum key distribution. The aim of this work is to analyze\nthe performance of Cascade, to discuss its strengths, weaknesses and\noptimization possibilities, comparing with some of the modified versions that\nhave been proposed in the literature. When looking at all design trade-offs, a\nnew view emerges that allows to put forward a number of guidelines and propose\nnear optimal parameters for the practical implementation of Cascade improving\nperformance significantly in comparison with all previous proposals. \n\n"}
{"id": "1407.4177", "contents": "Title: Power Control for Sum Rate Maximization on Interference Channels Under\n  Sum Power Constraint Abstract: In this paper, we consider the problem of power control for sum rate\nmaximization on multiple interfering links (TX-RX pairs)under sum power\nconstraint. We consider a single frequency network, where all pairs are\noperating in same frequency band,thereby creating interference for each other.\nWe study the power allocation problem for sum rate maximization with and\nwithout QoS requirements on individual links. When the objective is only sum\nrate maximization without QoS guarantees, we develop an analytic solution to\ndecide optimal power allocation for two TX-RX pair problem. We also develop a\nlow complexity iterative algorithm for three TX-RX pair problem. For a generic\nN>3 TX-RX pair problem, we develop two low-complexity sub-optimal power\nallocation algorithms. The first algorithm is based on the idea of making\nclusters of two or three TX-RX pairs and then leverage the power allocation\nresults obtained for two and three TX-RX pair problems. The second algorithm is\ndeveloped by using a high SINR approximation and this algorithm can also be\nimplemented in a distributed manner by individual TXs. We then consider the\nsame problem but with additional QoS guarantees for individual links. We again\ndevelop an analytic solution for two TX-RX pair problem, and a distributed\nalgorithm for N>2 TX-RX pairs. \n\n"}
{"id": "1407.5144", "contents": "Title: Lower Bounds on the Oracle Complexity of Nonsmooth Convex Optimization\n  via Information Theory Abstract: We present an information-theoretic approach to lower bound the oracle\ncomplexity of nonsmooth black box convex optimization, unifying previous lower\nbounding techniques by identifying a combinatorial problem, namely string\nguessing, as a single source of hardness. As a measure of complexity we use\ndistributional oracle complexity, which subsumes randomized oracle complexity\nas well as worst-case oracle complexity. We obtain strong lower bounds on\ndistributional oracle complexity for the box $[-1,1]^n$, as well as for the\n$L^p$-ball for $p \\geq 1$ (for both low-scale and large-scale regimes),\nmatching worst-case upper bounds, and hence we close the gap between\ndistributional complexity, and in particular, randomized complexity, and\nworst-case complexity. Furthermore, the bounds remain essentially the same for\nhigh-probability and bounded-error oracle complexity, and even for combination\nof the two, i.e., bounded-error high-probability oracle complexity. This\nconsiderably extends the applicability of known bounds. \n\n"}
{"id": "1407.6288", "contents": "Title: Subspace Learning From Bits Abstract: Networked sensing, where the goal is to perform complex inference using a\nlarge number of inexpensive and decentralized sensors, has become an\nincreasingly attractive research topic due to its applications in wireless\nsensor networks and internet-of-things. To reduce the communication, sensing\nand storage complexity, this paper proposes a simple sensing and estimation\nframework to faithfully recover the principal subspace of high-dimensional data\nstreams using a collection of binary measurements from distributed sensors,\nwithout transmitting the whole data. The binary measurements are designed to\nindicate comparison outcomes of aggregated energy projections of the data\nsamples over pairs of randomly selected directions. When the covariance matrix\nis a low-rank matrix, we propose a spectral estimator that recovers the\nprincipal subspace of the covariance matrix as the subspace spanned by the top\neigenvectors of a properly designed surrogate matrix, which is provably\naccurate as soon as the number of binary measurements is sufficiently large. An\nadaptive rank selection strategy based on soft thresholding is also presented.\nFurthermore, we propose a tailored spectral estimator when the covariance\nmatrix is additionally Toeplitz, and show reliable estimation can be obtained\nfrom a substantially smaller number of binary measurements. Our results hold\neven when a constant fraction of the binary measurements is randomly flipped.\nFinally, we develop a low-complexity online algorithm to track the principal\nsubspace when new measurements arrive sequentially. Numerical examples are\nprovided to validate the proposed approach. \n\n"}
{"id": "1407.7267", "contents": "Title: On Spectrum Sharing Between Energy Harvesting Cognitive Radio Users and\n  Primary Users Abstract: This paper investigates the maximum secondary throughput for a rechargeable\nsecondary user (SU) sharing the spectrum with a primary user (PU) plugged to a\nreliable power supply. The SU maintains a finite energy queue and harvests\nenergy from natural resources and primary radio frequency (RF) transmissions.\nWe propose a power allocation policy at the PU and analyze its effect on the\nthroughput of both the PU and SU. Furthermore, we study the impact of the\nbursty arrivals at the PU on the energy harvested by the SU from RF\ntransmissions. Moreover, we investigate the impact of the rate of energy\nharvesting from natural resources on the SU throughput. We assume fading\nchannels and compute exact closed-form expressions for the energy harvested by\nthe SU under fading. Results reveal that the proposed power allocation policy\nalong with the implemented RF energy harvesting at the SU enhance the\nthroughput of both primary and secondary links. \n\n"}
{"id": "1407.8246", "contents": "Title: Exponential decay of reconstruction error from binary measurements of\n  sparse signals Abstract: Binary measurements arise naturally in a variety of statistical and\nengineering applications. They may be inherent to the problem---e.g., in\ndetermining the relationship between genetics and the presence or absence of a\ndisease---or they may be a result of extreme quantization. In one-bit\ncompressed sensing it has recently been shown that the number of one-bit\nmeasurements required for signal estimation mirrors that of unquantized\ncompressed sensing. Indeed, $s$-sparse signals in $\\mathbb{R}^n$ can be\nestimated (up to normalization) from $\\Omega(s \\log (n/s))$ one-bit\nmeasurements. Nevertheless, controlling the precise accuracy of the error\nestimate remains an open challenge. In this paper, we focus on optimizing the\ndecay of the error as a function of the oversampling factor $\\lambda := m/(s\n\\log(n/s))$, where $m$ is the number of measurements. It is known that the\nerror in reconstructing sparse signals from standard one-bit measurements is\nbounded below by $\\Omega(\\lambda^{-1})$. Without adjusting the measurement\nprocedure, reducing this polynomial error decay rate is impossible. However, we\nshow that an adaptive choice of the thresholds used for quantization may lower\nthe error rate to $e^{-\\Omega(\\lambda)}$. This improves upon guarantees for\nother methods of adaptive thresholding as proposed in Sigma-Delta quantization.\nWe develop a general recursive strategy to achieve this exponential decay and\ntwo specific polynomial-time algorithms which fall into this framework, one\nbased on convex programming and one on hard thresholding. This work is inspired\nby the one-bit compressed sensing model, in which the engineer controls the\nmeasurement procedure. Nevertheless, the principle is extendable to signal\nreconstruction problems in a variety of binary statistical models as well as\nstatistical estimation problems like logistic regression. \n\n"}
{"id": "1407.8409", "contents": "Title: Joint Network and Gelfand-Pinsker Coding for 3-Receiver Gaussian\n  Broadcast Channels with Receiver Message Side Information Abstract: The problem of characterizing the capacity region for Gaussian broadcast\nchannels with receiver message side information appears difficult and remains\nopen for N >= 3 receivers. This paper proposes a joint network and\nGelfand-Pinsker coding method for 3-receiver cases. Using the method, we\nestablish a unified inner bound on the capacity region of 3-receiver Gaussian\nbroadcast channels under general message side information configuration. The\nachievability proof of the inner bound uses an idea of joint interference\ncancelation, where interference is canceled by using both dirty-paper coding at\nthe encoder and successive decoding at some of the decoders. We show that the\ninner bound is larger than that achieved by state of the art coding schemes. An\nouter bound is also established and shown to be tight in 46 out of all 64\npossible cases. \n\n"}
{"id": "1408.0377", "contents": "Title: Layered, Exact-Repair Regenerating Codes Via Embedded Error Correction\n  and Block Designs Abstract: A new class of exact-repair regenerating codes is constructed by stitching\ntogether shorter erasure correction codes, where the stitching pattern can be\nviewed as block designs. The proposed codes have the \"help-by-transfer\"\nproperty where the helper nodes simply transfer part of the stored data\ndirectly, without performing any computation. This embedded error correction\nstructure makes the decoding process straightforward, and in some cases the\ncomplexity is very low. We show that this construction is able to achieve\nperformance better than space-sharing between the minimum storage regenerating\ncodes and the minimum repair-bandwidth regenerating codes, and it is the first\nclass of codes to achieve this performance. In fact, it is shown that the\nproposed construction can achieve a non-trivial point on the optimal\nfunctional-repair tradeoff, and it is asymptotically optimal at high rate,\ni.e., it asymptotically approaches the minimum storage and the minimum\nrepair-bandwidth simultaneously. \n\n"}
{"id": "1408.1165", "contents": "Title: Noncommutative Uncertainty Principles Abstract: The classical uncertainty principles deal with functions on abelian groups.\nIn this paper, we discuss the uncertainty principles for finite index\nsubfactors which include the cases for finite groups and finite dimensional Kac\nalgebras. We prove the Hausdorff-Young inequality, Young's inequality, the\nHirschman-Beckner uncertainty principle, the Donoho-Stark uncertainty\nprinciple. We characterize the minimizers of the uncertainty principles. We\nalso prove that the minimizer is uniquely determined by the supports of itself\nand its Fourier transform. The proofs take the advantage of the analytic and\nthe categorial perspectives of subfactor planar algebras. Our method to prove\nthe uncertainty principles also works for more general cases, such as Popa's\n$\\lambda$-lattices, modular tensor categories etc. \n\n"}
{"id": "1408.2335", "contents": "Title: Wireless Powered Communication: Opportunities and Challenges Abstract: The performance of wireless communication is fundamentally constrained by the\nlimited battery life of wireless devices, whose operations are frequently\ndisrupted due to the need of manual battery replacement/recharging. The recent\nadvance in radio frequency (RF) enabled wireless energy transfer (WET)\ntechnology provides an attractive solution named wireless powered communication\n(WPC), where the wireless devices are powered by dedicated wireless power\ntransmitters to provide continuous and stable microwave energy over the air. As\na key enabling technology for truly perpetual communications, WPC opens up the\npotential to build a network with larger throughput, higher robustness, and\nincreased flexibility compared to its battery-powered counterpart. However, the\ncombination of wireless energy and information transmissions also raises many\nnew research problems and implementation issues to be addressed. In this\narticle, we provide an overview of state-of-the-art RF-enabled WET technologies\nand their applications to wireless communications, with highlights on the key\ndesign challenges, solutions, and opportunities ahead. \n\n"}
{"id": "1408.3757", "contents": "Title: Tier Association Probability and Spectrum Partitioning for Maximum Rate\n  Coverage in Multi-tier Heterogeneous Networks Abstract: For a wireless multi-tier heterogeneous network with orthogonal spectrum\nallocation across tiers, we optimize the association probability and the\nfraction of spectrum allocated to each tier so as to maximize rate coverage. In\npractice, the association probability can be controlled using a biased received\nsignal power. The optimization problem is non-convex and we are forced to\nexplore locally optimal solutions. We make two contributions in this paper:\nfirst, we show that there exists a relation between the first derivatives of\nthe objective function with respect to each of the optimization variables. This\ncan be used to simplify numerical solutions to the optimization problem.\nSecond, we explore the optimality of the intuitive solution that the fraction\nof spectrum allocated to each tier should be equal to the tier association\nprobability. We show that, in this case, a closed-form solution exists.\nImportantly, our numerical results show that there is essentially zero\nperformance loss. The results also illustrate the significant gains possible by\njointly optimizing the user association and the resource allocation. \n\n"}
{"id": "1408.5468", "contents": "Title: A Sytematic Piggybacking Design for Minimum Storage Regenerating Codes Abstract: Piggybacking is an efficient method to decrease the repair bandwidth of\nMaximum Distance Separable (MDS) codes or Minimum Storage Regenerating (MSR)\ncodes. In this paper, for minimizing the repair bandwidth of parity nodes of\nthe known MSR codes with high rate, which is usually the whole size of the\noriginal data, i.e., the maximal, a new systematic piggybacking design is\nproposed through an in-depth analysis of the design of piggybacking. As a\nresult, new MSR codes are obtained with almost optimal repair bandwidth of\nparity nodes while retaining the optimal repair bandwidth of systematic nodes.\nFurthermore, MSR codes with balanced download during node repair process are\npresented based on the new piggybacking design. \n\n"}
{"id": "1408.6385", "contents": "Title: Long term Throughput and Approximate Capacity of Transmitter-Receiver\n  Energy Harvesting Channel with Fading Abstract: We first consider an energy harvesting channel with fading, where only the\ntransmitter harvests energy from natural sources. We bound the optimal long\nterm throughput by a constant for a class of energy arrival distributions. The\nproposed method also gives a constant approximation to the capacity of the\nenergy harvesting channel with fading. Next, we consider a more general system\nwhere both the transmitter and the receiver employ energy harvesting to power\nthemselves. In this case, we show that finding an approximation to the optimal\nlong term throughput is far more difficult, and identify a special case of unit\nbattery capacity at both the transmitter and the receiver for which we obtain a\nuniversal bound on the ratio of the upper and lower bound on the long term\nthroughput. \n\n"}
{"id": "1409.1122", "contents": "Title: On $\\ell_p$-norm Computation over Multiple-Access Channels Abstract: This paper addresses some aspects of the general problem of information\ntransfer and distributed function computation in wireless networks. Many\napplications of wireless technology foresee networks of autonomous devices\nexecuting tasks that can be posed as distributed function computation. In\ntoday's wireless networks, the tasks of communication and (distributed)\ncomputation are performed separately, although an efficient network operation\ncalls for approaches in which the information transfer is dynamically adapted\nto time-varying computation objectives. Thus, wireless communications and\nfunction computation must be tightly coupled and it is shown in this paper that\ninformation theory may play a crucial role in the design of efficient\ncomputation-aware wireless communication and networking strategies. This is\nexplained in more detail by considering the problem of computing $\\ell_p$-norms\nover multiple access channels. \n\n"}
{"id": "1409.1184", "contents": "Title: Spectral Efficiency of the Cellular Two-Way Relaying with Large Antenna\n  Arrays Abstract: This paper considers a multiuser cellular two-way relay network (cTWRN) where\nmultiple users exchange information with a base station (BS) via a relay\nstation (RS). Each user is equipped with a single antenna, while both the BS\nand the RS are equipped with a very large antenna array. We investigate the\nperformance of the cTWRN with amplify-and-forward (AF) based physical-layer\nnetwork coding, and derive closed-form expression for the asymptotic spectral\nefficiency when both the number of antennas at the BS and the RS grow large. It\nis shown that the noise propagation of the non-regenerative relaying protocol\ncan be greatly suppressed, and the AF relaying scheme can approach the cut-set\nbound under certain conditions. We also investigate the performance of the AF\nrelaying scheme under two power-scaling cases, and show that the transmit power\nof the BS and each user can be made inversely proportional to the number of\nrelay antennas while maintaining a given quality-of-service. Numerical results\nare presented to verify the analytical results. \n\n"}
{"id": "1409.1606", "contents": "Title: Power Optimal Non-contiguous Spectrum Access in Multi Front End Radio\n  Enabled Point-to-Point Link Abstract: Non-contiguous spectrum chunks allow wireless links to flexibly access a wide\namount of bandwidth. Multi- Channel Multi-Radio (MC-MR) and Non-Contiguous\nOrthogonal Frequency Division Multiplexing (NC-OFDM) are the two commercially\nviable strategies to access non-contiguous spectrum chunks. MC-MR accesses\nmultiple non-contiguous chunks by activating multiple front ends which, in\nturn, increases the circuit power consumption of each of the activated front\nends. NC-OFDM accesses non-contiguous spectrum chunks with a single front end\nby nulling remaining subchannels but increases spectrum span which, in turn,\nincreases the power consumption of ADC and DAC. This work focuses on a\npoint-to-point link where transmitter and receiver have multiple front ends and\ncan employ NC-OFDM technology. We investigate optimal spectrum fragmentation in\neach front end from a system power (summation of transmit power and circuit\npower) perspective. We formulate a mixed integer non-linear program (MINLP) to\nperform power control and scheduling, and minimize system power by providing a\ngreedy algorithm (O(M^3 I)) where M and I denote the number of channels and\nradio front ends respectively. \n\n"}
{"id": "1409.2177", "contents": "Title: The Large Margin Mechanism for Differentially Private Maximization Abstract: A basic problem in the design of privacy-preserving algorithms is the private\nmaximization problem: the goal is to pick an item from a universe that\n(approximately) maximizes a data-dependent function, all under the constraint\nof differential privacy. This problem has been used as a sub-routine in many\nprivacy-preserving algorithms for statistics and machine-learning.\n  Previous algorithms for this problem are either range-dependent---i.e., their\nutility diminishes with the size of the universe---or only apply to very\nrestricted function classes. This work provides the first general-purpose,\nrange-independent algorithm for private maximization that guarantees\napproximate differential privacy. Its applicability is demonstrated on two\nfundamental tasks in data mining and machine learning. \n\n"}
{"id": "1409.3246", "contents": "Title: Wideband Sensing and Optimization for Cognitive Radio Networks with\n  Noise Variance Uncertainty Abstract: This paper considers wide-band spectrum sensing and optimization for\ncognitive radio (CR) networks with noise variance uncertainty. It is assumed\nthat the considered wide-band contains one or more white sub-bands. Under this\nassumption, we consider throughput maximization of the CR network while\nappropriately protecting the primary network. We address this problem as\nfollows. First, we propose novel ratio based test statistics for detecting the\nedges of each sub-band. Second, we employ simple energy comparison approach to\nchoose one reference white sub-band. Third, we propose novel generalized energy\ndetector (GED) for examining each of the remaining sub-bands by exploiting the\nnoise information of the reference white sub-band. Finally, we optimize the\nsensing time ($T_o$) to maximize the CR network throughput using the detection\nand false alarm probabilities of the GED. The proposed GED does not suffer from\nsignal to noise ratio (SNR) wall and outperforms the existing signal detectors.\nMoreover, the relationship between the proposed GED and conventional energy\ndetector (CED) is quantified analytically. We show that the optimal $T_o$\ndepends on the noise variance information. In particular, with $10$TV bands,\nSNR=$-20$dB and $2$s frame duration, we found that the optimal $T_o$ is\n$28.5$ms ($50.6$ms) with perfect (imperfect) noise variance scenario. \n\n"}
{"id": "1409.3665", "contents": "Title: Monotone Measures for Non-Local Correlations Abstract: Non-locality is the phenomenon of observing strong correlations among the\noutcomes of local measurements of a multipartite physical system. No-signaling\nboxes are the abstract objects for studying non-locality, and wirings are local\noperations on the space of no-signaling boxes. This means that, no matter how\nnon-local the nature is, the set of physical non-local correlations must be\nclosed under wirings. Then, one approach to identify the non-locality of nature\nis to characterize closed sets of non-local correlations. Although non-trivial\nexamples of wirings of no-signaling boxes are known, there is no systematic way\nto study wirings. In particular, given a set of no-signaling boxes, we do not\nknow a general method to prove that it is closed under wirings. In this paper,\nwe propose the first general method to construct such closed sets of non-local\ncorrelations. We show that a well-known measure of correlation, called maximal\ncorrelation, when appropriately defined for non-local correlations, is\nmonotonically decreasing under wirings.\n  This establishes a conjecture about the impossibility of simulating isotropic\nboxes from each other, implying the existence of a continuum of closed sets of\nnon-local boxes under wirings. To prove our main result, we introduce some\nmathematical tools that may be of independent interest: we define a notion of\nmaximal correlation ribbon as a generalization of maximal correlation, and\nprovide a connection between it and a known object called hypercontractivity\nribbon; we show that these two ribbons are monotone under wirings too. \n\n"}
{"id": "1409.3836", "contents": "Title: Hardness of parameter estimation in graphical models Abstract: We consider the problem of learning the canonical parameters specifying an\nundirected graphical model (Markov random field) from the mean parameters. For\ngraphical models representing a minimal exponential family, the canonical\nparameters are uniquely determined by the mean parameters, so the problem is\nfeasible in principle. The goal of this paper is to investigate the\ncomputational feasibility of this statistical task. Our main result shows that\nparameter estimation is in general intractable: no algorithm can learn the\ncanonical parameters of a generic pair-wise binary graphical model from the\nmean parameters in time bounded by a polynomial in the number of variables\n(unless RP = NP). Indeed, such a result has been believed to be true (see the\nmonograph by Wainwright and Jordan (2008)) but no proof was known.\n  Our proof gives a polynomial time reduction from approximating the partition\nfunction of the hard-core model, known to be hard, to learning approximate\nparameters. Our reduction entails showing that the marginal polytope boundary\nhas an inherent repulsive property, which validates an optimization procedure\nover the polytope that does not use any knowledge of its structure (as required\nby the ellipsoid method and others). \n\n"}
{"id": "1409.5531", "contents": "Title: A mathematical theory of resources Abstract: In many different fields of science, it is useful to characterize physical\nstates and processes as resources. Chemistry, thermodynamics, Shannon's theory\nof communication channels, and the theory of quantum entanglement are prominent\nexamples. Questions addressed by a theory of resources include: Which resources\ncan be converted into which other ones? What is the rate at which arbitrarily\nmany copies of one resource can be converted into arbitrarily many copies of\nanother? Can a catalyst help in making an impossible transformation possible?\nHow does one quantify the resource? Here, we propose a general mathematical\ndefinition of what constitutes a resource theory. We prove some general\ntheorems about how resource theories can be constructed from theories of\nprocesses wherein there is a special class of processes that are implementable\nat no cost and which define the means by which the costly states and processes\ncan be interconverted one to another. We outline how various existing resource\ntheories fit into our framework. Our abstract characterization of resource\ntheories is a first step in a larger project of identifying universal features\nand principles of resource theories. In this vein, we identify a few general\nresults concerning resource convertibility. \n\n"}
{"id": "1410.0952", "contents": "Title: Robust Binary Hypothesis Testing Under Contaminated Likelihoods Abstract: In hypothesis testing, the phenomenon of label noise, in which hypothesis\nlabels are switched at random, contaminates the likelihood functions. In this\npaper, we develop a new method to determine the decision rule when we do not\nhave knowledge of the uncontaminated likelihoods and contamination\nprobabilities, but only have knowledge of the contaminated likelihoods. In\nparticular we pose a minimax optimization problem that finds a decision rule\nrobust against this lack of knowledge. The method simplifies by application of\nlinear programming theory. Motivation for this investigation is provided by\nproblems encountered in workforce analytics. \n\n"}
{"id": "1410.2861", "contents": "Title: Multiuser Joint Energy-Bandwidth Allocation with Energy Harvesting -\n  Part I: Optimum Algorithm & Multiple Point-to-Point Channels Abstract: In this paper, we develop optimal energy-bandwidth allocation algorithms in\nfading channels for multiple energy harvesting transmitters, each may\ncommunicate with multiple receivers via orthogonal channels. We first assume\nthat the side information of both the channel states and the energy harvesting\nstates is known for $K$ time slots {\\em a priori}, and the battery capacity and\nthe maximum transmission power in each time slot are bounded. The objective is\nto maximize the weighted sum-rate of all transmitters over the $K$ time slots\nby assigning the transmission power and bandwidth for each transmitter in each\nslot. The problem is formulated as a convex optimization problem with ${\\cal\nO}(MK)$ constraints, where $M$ is the number of the receivers, making it hard\nto solve with a generic convex solver. An iterative algorithm is proposed that\nalternatively solves two subproblems in each iteration. The convergence and the\noptimality of this algorithm are also shown. We then consider the special case\nthat each transmitter only communicates with one receiver and the objective is\nto maximize the total throughput. We develop efficient algorithms for solving\nthe two subproblems and the optimal energy-bandwidth allocation can be obtained\nwith an overall complexity of ${\\cal O}(MK^2)$. Moreover, a heuristic algorithm\nis also proposed for energy-bandwidth allocation based on causal information of\nchannel and energy harvesting states. \n\n"}
{"id": "1410.4986", "contents": "Title: Code Construction and Decoding Algorithms for Semi-Quantitative Group\n  Testing with Nonuniform Thresholds Abstract: We analyze a new group testing scheme, termed semi-quantitative group\ntesting, which may be viewed as a concatenation of an adder channel and a\ndiscrete quantizer. Our focus is on non-uniform quantizers with arbitrary\nthresholds. For the most general semi-quantitative group testing model, we\ndefine three new families of sequences capturing the constraints on the code\ndesign imposed by the choice of the thresholds. The sequences represent\nextensions and generalizations of Bh and certain types of super-increasing and\nlexicographically ordered sequences, and they lead to code structures amenable\nfor efficient recursive decoding. We describe the decoding methods and provide\nan accompanying computational complexity and performance analysis. \n\n"}
{"id": "1410.5373", "contents": "Title: Poisson Group Testing: A Probabilistic Model for Boolean Compressed\n  Sensing Abstract: We introduce a novel probabilistic group testing framework, termed Poisson\ngroup testing, in which the number of defectives follows a right-truncated\nPoisson distribution. The Poisson model has a number of new applications,\nincluding dynamic testing with diminishing relative rates of defectives. We\nconsider both nonadaptive and semi-adaptive identification methods. For\nnonadaptive methods, we derive a lower bound on the number of tests required to\nidentify the defectives with a probability of error that asymptotically\nconverges to zero; in addition, we propose test matrix constructions for which\nthe number of tests closely matches the lower bound. For semi-adaptive methods,\nwe describe a lower bound on the expected number of tests required to identify\nthe defectives with zero error probability. In addition, we propose a\nstage-wise reconstruction algorithm for which the expected number of tests is\nonly a constant factor away from the lower bound. The methods rely only on an\nestimate of the average number of defectives, rather than on the individual\nprobabilities of subjects being defective. \n\n"}
{"id": "1410.6339", "contents": "Title: Constructions and Properties of Linear Locally Repairable Codes Abstract: In this paper, locally repairable codes with all-symbol locality are studied.\nMethods to modify already existing codes are presented. Also, it is shown that\nwith high probability, a random matrix with a few extra columns guaranteeing\nthe locality property, is a generator matrix for a locally repairable code with\na good minimum distance. The proof of this also gives a constructive method to\nfind locally repairable codes. Constructions are given of three infinite\nclasses of optimal vector-linear locally repairable codes over an alphabet of\nsmall size, not depending on the size of the code. \n\n"}
{"id": "1410.6913", "contents": "Title: Low rank matrix recovery from rank one measurements Abstract: We study the recovery of Hermitian low rank matrices $X \\in \\mathbb{C}^{n\n\\times n}$ from undersampled measurements via nuclear norm minimization. We\nconsider the particular scenario where the measurements are Frobenius inner\nproducts with random rank-one matrices of the form $a_j a_j^*$ for some\nmeasurement vectors $a_1,...,a_m$, i.e., the measurements are given by $y_j =\n\\mathrm{tr}(X a_j a_j^*)$. The case where the matrix $X=x x^*$ to be recovered\nis of rank one reduces to the problem of phaseless estimation (from\nmeasurements, $y_j = |\\langle x,a_j\\rangle|^2$ via the PhaseLift approach,\nwhich has been introduced recently. We derive bounds for the number $m$ of\nmeasurements that guarantee successful uniform recovery of Hermitian rank $r$\nmatrices, either for the vectors $a_j$, $j=1,...,m$, being chosen independently\nat random according to a standard Gaussian distribution, or $a_j$ being sampled\nindependently from an (approximate) complex projective $t$-design with $t=4$.\nIn the Gaussian case, we require $m \\geq C r n$ measurements, while in the case\nof $4$-designs we need $m \\geq Cr n \\log(n)$. Our results are uniform in the\nsense that one random choice of the measurement vectors $a_j$ guarantees\nrecovery of all rank $r$-matrices simultaneously with high probability.\nMoreover, we prove robustness of recovery under perturbation of the\nmeasurements by noise. The result for approximate $4$-designs generalizes and\nimproves a recent bound on phase retrieval due to Gross, Kueng and Krahmer. In\naddition, it has applications in quantum state tomography. Our proofs employ\nthe so-called bowling scheme which is based on recent ideas by Mendelson and\nKoltchinskii. \n\n"}
{"id": "1410.7270", "contents": "Title: Capacity Analysis of Decoupled Downlink and Uplink Access in 5G\n  Heterogeneous Systems Abstract: Our traditional notion of a cell is changing dramatically given the\nincreasing degree of heterogeneity in 4G and emerging 5G systems. Rather than\nbelonging to a specific cell, a device would choose the most suitable\nconnection from the plethora of connections available. In such a setting, given\nthe transmission powers differ significantly between downlink (DL) and uplink\n(UL), a wireless device that sees multiple Base Stations (BSs) may access the\ninfrastructure in a way that it receives the downlink (DL) traffic from one BS\nand sends uplink (UL) traffic through another BS. This situation is referred to\nas Downlink and Uplink Decoupling (DUDe). In this paper, the capacity and\nthroughput gains brought by decoupling are rigorously derived using stochastic\ngeometry. Theoretical findings are then corroborated by means of simulation\nresults. A further constituent of this paper is the verification of the\ntheoretically derived results by means of a real-world system simulation\nplatform. Despite theoretical assumptions differing from the very complete\nsystem simulator, the trends in the association probabilities and capacity\ngains are similar. Based on the promising results, we then outline\narchitectural changes needed to facilitate the decoupling of DL and UL. \n\n"}
{"id": "1411.0114", "contents": "Title: On the Transmit Beamforming for MIMO Wiretap Channels: Large-System\n  Analysis Abstract: With the growth of wireless networks, security has become a fundamental issue\nin wireless communications due to the broadcast nature of these networks. In\nthis work, we consider MIMO wiretap channels in a fast fading environment, for\nwhich the overall performance is characterized by the ergodic MIMO secrecy\nrate. Unfortunately, the direct solution to finding ergodic secrecy rates is\nprohibitive due to the expectations in the rates expressions in this setting.\nTo overcome this difficulty, we invoke the large-system assumption, which\nallows a deterministic approximation to the ergodic mutual information.\nLeveraging results from random matrix theory, we are able to characterize the\nachievable ergodic secrecy rates. Based on this characterization, we address\nthe problem of covariance optimization at the transmitter. Our numerical\nresults demonstrate a good match between the large-system approximation and the\nactual simulated secrecy rates, as well as some interesting features of the\nprecoder optimization. \n\n"}
{"id": "1411.0435", "contents": "Title: Sparse Signal Processing Concepts for Efficient 5G System Design Abstract: As it becomes increasingly apparent that 4G will not be able to meet the\nemerging demands of future mobile communication systems, the question what\ncould make up a 5G system, what are the crucial challenges and what are the key\ndrivers is part of intensive, ongoing discussions. Partly due to the advent of\ncompressive sensing, methods that can optimally exploit sparsity in signals\nhave received tremendous attention in recent years. In this paper we will\ndescribe a variety of scenarios in which signal sparsity arises naturally in 5G\nwireless systems. Signal sparsity and the associated rich collection of tools\nand algorithms will thus be a viable source for innovation in 5G wireless\nsystem design. We will discribe applications of this sparse signal processing\nparadigm in MIMO random access, cloud radio access networks, compressive\nchannel-source network coding, and embedded security. We will also emphasize\nimportant open problem that may arise in 5G system design, for which sparsity\nwill potentially play a key role in their solution. \n\n"}
{"id": "1411.1801", "contents": "Title: Space-Time Encoded MISO Broadcast Channel with Outdated CSIT: An Error\n  Rate and Diversity Performance Analysis Abstract: Studies of the MISO Broadcast Channel (BC) with delayed Channel State\nInformation at the Transmitter (CSIT) have so far focused on the sum-rate and\nDegrees-of-Freedom (DoF) region analysis. In this paper, we investigate for the\nfirst time the error rate performance at finite SNR and the\ndiversity-multiplexing tradeoff (DMT) at infinite SNR of a space-time encoded\ntransmission over a two-user MISO BC with delayed CSIT. We consider the\nso-called MAT protocol obtained by Maddah-Ali and Tse, which was shown to\nprovide 33% DoF enhancement over TDMA. While the asymptotic DMT analysis shows\nthat MAT is always preferable to TDMA, the Pairwise Error Probability analysis\nat finite SNR shows that MAT is in fact not always a better alternative to\nTDMA. Benefits can be obtained over TDMA only at very high rate or once\nconcatenated with a full-rate full-diversity space-time code. The analysis is\nalso extended to spatially correlated channels and the influence of transmit\ncorrelation matrices and user pairing strategies on the performance are\ndiscussed. Relying on statistical CSIT, signal constellations are further\noptimized to improve the error rate performance of MAT and make it insensitive\nto user orthogonality. Finally, other transmission strategies relying on\ndelayed CSIT are discussed. \n\n"}
{"id": "1411.2417", "contents": "Title: Capacity Results for Multicasting Nested Message Sets over Combination\n  Networks Abstract: The problem of multicasting two nested messages is studied over a class of\nnetworks known as combination networks. A source multicasts two messages, a\ncommon and a private message, to several receivers. A subset of the receivers\n(called the public receivers) only demand the common message and the rest of\nthe receivers (called the private receivers) demand both the common and the\nprivate message. Three encoding schemes are discussed that employ linear\nsuperposition coding and their optimality is proved in special cases. The\nstandard linear superposition scheme is shown to be optimal for networks with\ntwo public receivers and any number of private receivers. When the number of\npublic receivers increases, this scheme stops being optimal. Two improvements\nare discussed: one using pre-encoding at the source, and one using a block\nMarkov encoding scheme. The rate-regions that are achieved by the two schemes\nare characterized in terms of feasibility problems. Both inner-bounds are shown\nto be the capacity region for networks with three (or fewer) public and any\nnumber of private receivers. Although the inner bounds are not comparable in\ngeneral, it is shown through an example that the region achieved by the block\nMarkov encoding scheme may strictly include the region achieved by the\npre-encoding/linear superposition scheme. Optimality results are founded on the\ngeneral framework of Balister and Bollob\\'as (2012) for sub-modularity of the\nentropy function. An equivalent graphical representation is introduced and a\nlemma is proved that might be of independent interest.\n  Motivated by the connections between combination networks and broadcast\nchannels, a new block Markov encoding scheme is proposed for broadcast channels\nwith two nested messages. The rate-region that is obtained includes the\npreviously known rate-regions. It remains open whether this inclusion is\nstrict. \n\n"}
{"id": "1411.4226", "contents": "Title: Roy's largest root under rank-one alternatives:The complex valued case\n  and applications Abstract: The largest eigenvalue of a Wishart matrix, known as Roy's largest root\n(RLR), plays an important role in a variety of applications. Most works to date\nderived approximations to its distribution under various asymptotic regimes,\nsuch as degrees of freedom, dimension, or both tending to infinity. However,\nseveral applications involve finite and relative small parameters, for which\nthe above approximations may be inaccurate. Recently, via a small noise\nperturbation approach with fixed dimension and degrees of freedom, Johnstone\nand Nadler derived simple yet accurate stochastic approximations to the\ndistribution of Roy's largest root in the real valued case, under a rank-one\nalternative. In this paper, we extend their results to the complex valued case.\nFurthermore, we analyze the behavior of the leading eigenvector by developing\nnew stochastic approximations. Specifically, we derive simple stochastic\napproximations to the distribution of the largest eigenvalue under five common\ncomplex single-matrix and double-matrix scenarios. We then apply these results\nto investigate several problems in signal detection and communications. In\nparticular, we analyze the performance of RLR detector in cognitive radio\nspectrum sensing and constant modulus signal detection in the high\nsignal-to-noise ratio (SNR) regime. Moreover, we address the problem of\ndetermining the optimal transmit-receive antenna configuration (here optimality\nis in the sense of outage minimization) for rank-one multiple-input\nmultiple-output Rician Fading channels at high SNR. \n\n"}
{"id": "1411.4253", "contents": "Title: Energy-efficient Decoders for Compressive Sensing: Fundamental Limits\n  and Implementations Abstract: The fundamental problem considered in this paper is \"What is the\n\\textit{energy} consumed for the implementation of a \\emph{compressive sensing}\ndecoding algorithm on a circuit?\". Using the \"information-friction\" framework,\nwe examine the smallest amount of \\textit{bit-meters} as a measure for the\nenergy consumed by a circuit. We derive a fundamental lower bound for the\nimplementation of compressive sensing decoding algorithms on a circuit. In the\nsetting where the number of measurements scales linearly with the sparsity and\nthe sparsity is sub-linear with the length of the signal, we show that the\n\\textit{bit-meters} consumption for these algorithms is order-tight, i.e., it\nmatches the lower bound asymptotically up to a constant factor. Our\nimplementations yield interesting insights into design of energy-efficient\ncircuits that are not captured by the notion of computational efficiency alone. \n\n"}
{"id": "1411.5326", "contents": "Title: Compress and Control Abstract: This paper describes a new information-theoretic policy evaluation technique\nfor reinforcement learning. This technique converts any compression or density\nmodel into a corresponding estimate of value. Under appropriate stationarity\nand ergodicity conditions, we show that the use of a sufficiently powerful\nmodel gives rise to a consistent value function estimator. We also study the\nbehavior of this technique when applied to various Atari 2600 video games,\nwhere the use of suboptimal modeling techniques is unavoidable. We consider\nthree fundamentally different models, all too limited to perfectly model the\ndynamics of the system. Remarkably, we find that our technique provides\nsufficiently accurate value estimates for effective on-policy control. We\nconclude with a suggestive study highlighting the potential of our technique to\nscale to large problems. \n\n"}
{"id": "1411.6137", "contents": "Title: Enhanced Multi-Parameter Cognitive Architecture for Future Wireless\n  Communications Abstract: The very original concept of cognitive radio (CR) raised by Mitola targets at\nall the environment parameters, including those in physical layer, MAC layer,\napplication layer as well as the information extracted from reasoning. Hence\nthe first CR is also referred to as \"full cognitive radio\". However, due to its\ndifficult implementation, FCC and Simon Haykin separately proposed a much more\nsimplified definition, in which CR mainly detects one single parameter, i.e.,\nspectrum occupancy, and is also called as \"spectrum sensing cognitive radio\".\nWith the rapid development of wireless communication, the infrastructure of a\nwireless system becomes much more complicated while the functionality at every\nnode is desired to be as intelligent as possible, say the self-organized\ncapability in the approaching 5G cellular networks. It is then interesting to\nre-look into Mitola's definition and think whether one could, besides obtaining\nthe \"on/off\" status of the licensed user only, achieve more parameters in a\ncognitive way. In this article, we propose a new cognitive architecture\ntargeting at multiple parameters in future cellular networks, which is a one\nstep further towards the \"full cognition\" compared to the most existing CR\nresearch. The new architecture is elaborated in detailed stages, and three\nrepresentative examples are provided based on the recent research progress to\nillustrate the feasibility as well as the validity of the proposed\narchitecture. \n\n"}
{"id": "1411.7632", "contents": "Title: Semidefinite Programming Approach to Gaussian Sequential Rate-Distortion\n  Trade-offs Abstract: Sequential rate-distortion (SRD) theory provides a framework for studying the\nfundamental trade-off between data-rate and data-quality in real-time\ncommunication systems. In this paper, we consider the SRD problem for\nmulti-dimensional time-varying Gauss-Markov processes under mean-square\ndistortion criteria. We first revisit the sensor-estimator separation\nprinciple, which asserts that considered SRD problem is equivalent to a joint\nsensor and estimator design problem in which data-rate of the sensor output is\nminimized while the estimator's performance satisfies the distortion criteria.\nWe then show that the optimal joint design can be performed by semidefinite\nprogramming. A semidefinite representation of the corresponding SRD function is\nobtained. Implications of the obtained result in the context of zero-delay\nsource coding theory and applications to networked control theory are also\ndiscussed. \n\n"}
{"id": "1412.1538", "contents": "Title: Krylov Subspace Methods in Dynamical Sampling Abstract: Let $B$ be an unknown linear evolution process on $\\mathbb C^d\\simeq\nl^2(\\mathbb Z_d)$ driving an unknown initial state $x$ and producing the states\n$\\{B^\\ell x, \\ell = 0,1,\\ldots\\}$ at different time levels. The problem under\nconsideration in this paper is to find as much information as possible about\n$B$ and $x$ from the measurements $Y=\\{x(i)$, $Bx(i)$, $\\dots$,\n$B^{\\ell_i}x(i): i \\in \\Omega\\subset \\mathbb Z^d\\}$. If $B$ is a \"low-pass\"\nconvolution operator, we show that we can recover both $B$ and $x$, almost\nsurely, as long as we double the amount of temporal samples needed in\n\\cite{ADK13} to recover the signal propagated by a known operator $B$. For a\ngeneral operator $B$, we can recover parts or even all of its spectrum from\n$Y$. As a special case of our method, we derive the centuries old Prony's\nmethod \\cite{BDVMC08, P795, PP13} which recovers a vector with an $s$-sparse\nFourier transform from $2s$ of its consecutive components. \n\n"}
{"id": "1412.1898", "contents": "Title: Joint Rate and SINR Coverage Analysis for Decoupled Uplink-Downlink\n  Biased Cell Associations in HetNets Abstract: Load balancing by proactively offloading users onto small and otherwise\nlightly-loaded cells is critical for tapping the potential of dense\nheterogeneous cellular networks (HCNs). Offloading has mostly been studied for\nthe downlink, where it is generally assumed that a user offloaded to a small\ncell will communicate with it on the uplink as well. The impact of coupled\ndownlink-uplink offloading is not well understood. Uplink power control and\nspatial interference correlation further complicate the mathematical analysis\nas compared to the downlink. We propose an accurate and tractable model to\ncharacterize the uplink SINR and rate distribution in a multi-tier HCN as a\nfunction of the association rules and power control parameters. Joint\nuplink-downlink rate coverage is also characterized. Using the developed\nanalysis, it is shown that the optimal degree of channel inversion (for uplink\npower control) increases with load imbalance in the network. In sharp contrast\nto the downlink, minimum path loss association is shown to be optimal for\nuplink rate. Moreover, with minimum path loss association and full channel\ninversion, uplink SIR is shown to be invariant of infrastructure density. It is\nfurther shown that a decoupled association---employing differing association\nstrategies for uplink and downlink---leads to significant improvement in joint\nuplink-downlink rate coverage over the standard coupled association in HCNs. \n\n"}
{"id": "1412.2192", "contents": "Title: Optimal algorithms for universal random number generation from finite\n  memory sources Abstract: We study random number generators (RNGs), both in the fixed to\nvariable-length (FVR) and the variable to fixed-length (VFR) regimes, in a\nuniversal setting in which the input is a finite memory source of arbitrary\norder and unknown parameters, with arbitrary input and output (finite) alphabet\nsizes. Applying the method of types, we characterize essentially unique optimal\nuniversal RNGs that maximize the expected output (respectively, minimize the\nexpected input) length in the FVR (respectively, VFR) case. For the FVR case,\nthe RNG studied is a generalization of Elias's scheme, while in the VFR case\nthe general scheme is new. We precisely characterize, up to an additive\nconstant, the corresponding expected lengths, which include second-order terms\nsimilar to those encountered in universal data compression and universal\nsimulation. Furthermore, in the FVR case, we consider also a \"twice-universal\"\nsetting, in which the Markov order k of the input source is also unknown. \n\n"}
{"id": "1412.2669", "contents": "Title: Two step recovery of jointly sparse and low-rank matrices: theoretical\n  guarantees Abstract: We introduce a two step algorithm with theoretical guarantees to recover a\njointly sparse and low-rank matrix from undersampled measurements of its\ncolumns. The algorithm first estimates the row subspace of the matrix using a\nset of common measurements of the columns. In the second step, the subspace\naware recovery of the matrix is solved using a simple least square algorithm.\nThe results are verified in the context of recovering CINE data from\nundersampled measurements; we obtain good recovery when the sampling conditions\nare satisfied. \n\n"}
{"id": "1412.4324", "contents": "Title: Secure State Estimation For Cyber Physical Systems Under Sensor Attacks:\n  A Satisfiability Modulo Theory Approach Abstract: We address the problem of detecting and mitigating the effect of malicious\nattacks to the sensors of a linear dynamical system. We develop a novel,\nefficient algorithm that uses a Satisfiability-Modulo-Theory approach to\nisolate the compromised sensors and estimate the system state despite the\npresence of the attack, thus harnessing the intrinsic combinatorial complexity\nof the problem. By leveraging results from formal methods over real numbers, we\nprovide guarantees on the soundness and completeness of our algorithm. We then\nreport simulation results to compare its runtime performance with alternative\ntechniques. Finally, we demonstrate its application to the problem of\ncontrolling an unmanned ground vehicle. \n\n"}
{"id": "1412.4813", "contents": "Title: Opportunistic Relaying without CSI: Optimizing Variable-Rate HARQ Abstract: We analyze the opportunistic relaying based on HARQ transmission over the\nblock-fading channel with absence of channel state information (CSI) at the\ntransmitter nodes. We assume that both the source and the relay are allowed to\nvary their transmission rate between the HARQ transmission rounds. We solve the\nproblem of throughput maximization with respect to the transmission rates using\ndouble-recursive Dynamic Programming. Simplifications are also proposed to\ndiminish the complexity of the optimization. The numerical results confirm that\nthe variable-rate HARQ can increase the throughput significantly comparing to\nits fixed-rate counterpart. \n\n"}
{"id": "1412.5551", "contents": "Title: Statistical Modeling and Performance Characterization of an Ultrafast\n  Digital Lightwave Communication System Using a Power-Cubic Optical Nonlinear\n  Preprocessor (Extended Version) Abstract: In this paper, we present an analytical approach in obtaining the probability\ndensity function (pdf) of the random decision variable Y, formed at the output\nof power-cubic all-optical nonlinear preprocessor followed by the\nphotodetector. Our approach can be used to accurately evaluate the performance\nof ultrafast pulse detection in the presence of Gaussian noise. Through\nrigorous Monte-Carlo simulation, the accuracy of widely used Gaussian\napproximation of decision variable Y is refuted. However, in this paper we show\nthat the so called Log-Pearson type-3 probability density function (LP3 pdf) is\nan excellent representation for the decision variable Y . Three distinguishable\nparameters of the LP3 pdf are obtained through analytical derivation of three\nmoments of the decision variable Y . Furthermore, toward a more realistic\nmodel, in addition to ASE Gaussian noise, the effects of shot and thermal\nnoises are also included. Finally, using the presented analytical approach, it\nis shown that power-cubic preprocessor outperforms its quadratic counterparts,\ni.e., Second Harmonic Generation (SHG) and Two Photon Absorption (TPA) devices,\nin high power regime where shot and thermal noises can be neglected. \n\n"}
{"id": "1412.6135", "contents": "Title: Multi-Scale Stochastic Simulation for Diffusive Molecular Communication Abstract: Recently, hybrid models have emerged that combine microscopic and mesoscopic\nregimes in a single stochastic reaction-diffusion simulation. Microscopic\nsimulations track every individual molecule and are generally more accurate.\nMesoscopic simulations partition the environment into subvolumes, track when\nmolecules move between adjacent subvolumes, and are generally more\ncomputationally efficient. In this paper, we present the foundation of a\nmulti-scale stochastic simulator from the perspective of molecular\ncommunication, for both mesoscopic and hybrid models, where we emphasize\nsimulation accuracy at the receiver and efficiency in regions that are far from\nthe communication link. Our multi-scale models use subvolumes of different\nsizes, between which we derive the diffusion event transition rate. Simulation\nresults compare the accuracy and efficiency of traditional approaches with that\nof a regular hybrid method and with those of our proposed multi-scale methods. \n\n"}
{"id": "1412.6946", "contents": "Title: Probability Estimates for Fading and Wiretap Channels from Ideal Class\n  Zeta Functions Abstract: In this paper, new probability estimates are derived for ideal lattice codes\nfrom totally real number fields using ideal class Dedekind zeta functions. In\ncontrast to previous work on the subject, it is not assumed that the ideal in\nquestion is principal. In particular, it is shown that the corresponding\ninverse norm sum depends not only on the regulator and discriminant of the\nnumber field, but also on the values of the ideal class Dedekind zeta\nfunctions. Along the way, we derive an estimate of the number of elements in a\ngiven ideal with a certain algebraic norm within a finite hypercube. We provide\nseveral examples which measure the accuracy and predictive ability of our\ntheorems. \n\n"}
{"id": "1501.00035", "contents": "Title: Massive MIMO testbed - Implementation and Initial Results in System\n  Model Validation Abstract: This paper presents the design and implementation of a novel SDR based\nmassive MIMO testbed with up to 70 nodes built at Tennessee Technological\nUniversity. The deployment can reach a $30 \\times 30$ antenna MIMO scheme. With\nthis testbed, we are able to measure the channel matrix and compute the\nachievable rate of the massive MIMO system using experimental data. The\nmeasured channel capacity is linearly increasing with the number of antennas of\nthe base station. We also demonstrate the channel reciprocity including the\ncircuits impact from the transmitter and receiver. We show that the Vandermonde\nchannel model is more realistic to describe the massive MIMO architecture than\nthe widely used Gaussian channel model, in terms of capacity. By adjusting the\nrange for angle of arrival $\\alpha$ and the base station antenna distance $d$\nduring the simulation, we find out the Vandermonde model agrees with our\nmeasured capacity at a certain $\\alpha$ for each selected $d$ and the $\\alpha$\nis very close to that of the experiment deployment. It is the first time that\nthe feasibility of Vandermonde channel model is demonstrated by the experiment\nfor massive MIMO. \n\n"}
{"id": "1501.01742", "contents": "Title: LDPC Coded Modulation with Probabilistic Shaping for Optical Fiber\n  Systems Abstract: An LDPC coded modulation scheme with probabilistic shaping, optimized\ninterleavers and noniterative demapping is proposed. Full-field simulations\nshow an increase in transmission distance by 8% compared to uniformly\ndistributed input. \n\n"}
{"id": "1501.02046", "contents": "Title: Multiuser MIMO Wireless Energy Transfer With Coexisting Opportunistic\n  Communication Abstract: This letter considers spectrum sharing between a primary multiuser\nmultiple-input multiple-output (MIMO) wireless energy transfer (WET) system and\na coexisting secondary point-to-point MIMO wireless information transmission\n(WIT) system, where WET generates interference to WIT and degrades its\nthroughput performance. We show that due to the interference, the WIT system\nsuffers from a loss of the degrees of freedom (DoF) proportional to the number\nof energy beams sent by the energy transmitter (ET), which, in general, needs\nto be larger than one in order to optimize the multiuser WET with user fairness\nconsideration. To minimize the DoF loss in WIT, we further propose a new\nsingle-beam energy transmission scheme based on the principle of time sharing,\nwhere the ET transmits one of the optimal energy beams at each time. This new\nscheme achieves the same optimal performance for the WET system, and minimizes\nthe impact of its interference to the WIT system. \n\n"}
{"id": "1501.02419", "contents": "Title: Delay Minimizing User Association in Cellular Networks via\n  Hierarchically Well-Separated Trees Abstract: We study downlink delay minimization within the context of cellular user\nassociation policies that map mobile users to base stations. We note the delay\nminimum user association problem fits within a broader class of network utility\nmaximization and can be posed as a non-convex quadratic program. This\nnon-convexity motivates a split quadratic objective function that captures the\noriginal problem's inherent tradeoff: association with a station that provides\nthe highest signal-to-interference-plus-noise ratio (SINR) vs. a station that\nis least congested. We find the split-term formulation is amenable to\nlinearization by embedding the base stations in a hierarchically well-separated\ntree (HST), which offers a linear approximation with constant distortion. We\nprovide a numerical comparison of several problem formulations and find that\nwith appropriate optimization parameter selection, the quadratic reformulation\nproduces association policies with sum delays that are close to that of the\noriginal network utility maximization. We also comment on the more difficult\nproblem when idle base stations (those without associated users) are\ndeactivated. \n\n"}
{"id": "1501.02473", "contents": "Title: A Comparative Study of Polar Code Constructions for the AWGN Channel Abstract: We present a comparative study of the performance of various polar code\nconstructions in an additive white Gaussian noise (AWGN) channel. A polar code\nconstruction is any algorithm that selects $K$ best among $N$ possible polar\nbit-channels at the design signal-to-noise-ratio (design-SNR) in terms of bit\nerror rate (BER). Optimal polar code construction is hard and therefore many\nsuboptimal polar code constructions have been proposed at different\ncomputational complexities. Polar codes are also non-universal meaning the code\nchanges significantly with the design-SNR. However, it is not known which\nconstruction algorithm at what design-SNR constructs the best polar codes. We\nfirst present a comprehensive survey of all the well-known polar code\nconstructions along with their full implementations. We then propose a\nheuristic algorithm to find the best design-SNR for constructing best possible\npolar codes from a given construction algorithm. The proposed algorithm\ninvolves a search among several possible design-SNRs. We finally use our\nalgorithm to perform a comparison of different construction algorithms using\nextensive simulations. We find that all polar code construction algorithms\ngenerate equally good polar codes in an AWGN channel, if the design-SNR is\noptimized. \n\n"}
{"id": "1501.03407", "contents": "Title: User Association in Massive MIMO HetNets Abstract: Massive MIMO and small cell are both recognized as the key technologies for\nthe future 5G wireless systems. In this paper, we investigate the problem of\nuser association in a heterogeneous network (HetNet) with massive MIMO and\nsmall cells, where the macro base station (BS) is equipped with a massive MIMO\nand the picocell BS's are equipped with regular MIMOs. We first develop\ncentralized user association algorithms with proven optimality, considering\nvarious objectives such as rate maximization, proportional fairness, and joint\nuser association and resource allocation. We then model the massive MIMO HetNet\nas a repeated game, which leads to distributed user association algorithms with\nproven convergence to the Nash Equilibrium (NE). We demonstrate the efficacy of\nthese optimal schemes by comparison with several greedy algorithms through\nsimulations. \n\n"}
{"id": "1501.04721", "contents": "Title: Two-Stage Subspace Constrained Precoding in Massive MIMO Cellular\n  Systems Abstract: We propose a subspace constrained precoding scheme that exploits the spatial\nchannel correlation structure in massive MIMO cellular systems to fully unleash\nthe tremendous gain provided by massive antenna array with reduced channel\nstate information (CSI) signaling overhead. The MIMO precoder at each base\nstation (BS) is partitioned into an inner precoder and a Transmit (Tx) subspace\ncontrol matrix. The inner precoder is adaptive to the local CSI at each BS for\nspatial multiplexing gain. The Tx subspace control is adaptive to the channel\nstatistics for inter-cell interference mitigation and Quality of Service (QoS)\noptimization. Specifically, the Tx subspace control is formulated as a QoS\noptimization problem which involves an SINR chance constraint where the\nprobability of each user's SINR not satisfying a service requirement must not\nexceed a given outage probability. Such chance constraint cannot be handled by\nthe existing methods due to the two stage precoding structure. To tackle this,\nwe propose a bi-convex approximation approach, which consists of three key\ningredients: random matrix theory, chance constrained optimization and\nsemidefinite relaxation. Then we propose an efficient algorithm to find the\noptimal solution of the resulting bi-convex approximation problem. Simulations\nshow that the proposed design has significant gain over various baselines. \n\n"}
{"id": "1501.04775", "contents": "Title: Interference Aligned Space-Time Transmission with Diversity for the $2\n  \\times 2$ X-Network Abstract: The sum degrees of freedom (DoF) of the two-transmitter, two-receiver\nmultiple-input multiple-output (MIMO) X-Network ($2 \\times 2$ MIMO X-Network)\nwith $M$ antennas at each node is known to be $\\frac{4M}{3}$. Transmission\nschemes which couple local channel-state-information-at-the-transmitter (CSIT)\nbased precoding with space-time block coding to achieve the sum-DoF of this\nnetwork are known specifically for $M=2,4$. These schemes have been proven to\nguarantee a diversity gain of $M$ when a finite-sized input constellation is\nemployed. In this paper, an explicit transmission scheme that achieves the\n$\\frac{4M}{3}$ sum-DoF of the $2 \\times 2$ X-Network for arbitrary $M$ is\npresented. The proposed scheme needs only local CSIT unlike the Jafar-Shamai\nscheme which requires the availability of global CSIT in order to achieve the\n$\\frac{4M}{3}$ sum-DoF. Further, it is shown analytically that the proposed\nscheme guarantees a diversity gain of $M+1$ when finite-sized input\nconstellations are employed. \n\n"}
{"id": "1501.05683", "contents": "Title: Polar Lattices for Lossy Compression Abstract: Polar lattices, which are constructed from polar codes, have recently been\nproved to be able to achieve the capacity of the additive white Gaussian noise\n(AWGN) channel. In this work, we propose a new construction of polar lattices\nto solve the dual problem, i.e., achieving the rate-distortion bound of a\nmemoryless Gaussian source, which means that polar lattices can also be good\nfor the lossy compression of continuous sources. The structure of the proposed\npolar lattices enables us to integrate the post-entropy coding process into the\nlattice quantizer, which simplifies the quantization process. The overall\ncomplexity of encoding and decoding complexity is $O(N \\log^2 N)$ for a\nsub-exponentially decaying excess distortion. Moreover, the nesting structure\nof polar lattices further provides solutions for some multi-terminal coding\nproblems. The Wyner-Ziv coding problem for a Gaussian source can be solved by\nan AWGN capacity-achieving polar lattice nested in a rate-distortion bound\nachieving one, and the Gelfand-Pinsker problem can be solved in a reversed\nmanner. \n\n"}
{"id": "1501.06076", "contents": "Title: Fourier Analysis of MAC Polarization Abstract: One problem with MAC polar codes that are based on MAC polarization is that\nthey may not achieve the entire capacity region. The reason behind this problem\nis that MAC polarization sometimes induces a loss in the capacity region. This\npaper provides a single letter necessary and sufficient condition which\ncharacterizes all the MACs that do not lose any part of their capacity region\nby polarization. \n\n"}
{"id": "1501.06683", "contents": "Title: Codes With Hierarchical Locality Abstract: In this paper, we study the notion of {\\em codes with hierarchical locality}\nthat is identified as another approach to local recovery from multiple\nerasures. The well-known class of {\\em codes with locality} is said to possess\nhierarchical locality with a single level. In a {\\em code with two-level\nhierarchical locality}, every symbol is protected by an inner-most local code,\nand another middle-level code of larger dimension containing the local code. We\nfirst consider codes with two levels of hierarchical locality, derive an upper\nbound on the minimum distance, and provide optimal code constructions of low\nfield-size under certain parameter sets. Subsequently, we generalize both the\nbound and the constructions to hierarchical locality of arbitrary levels. \n\n"}
{"id": "1501.06851", "contents": "Title: Distributed Power Allocations in Heterogeneous Networks with Dual\n  Connectivity using Backhaul State Information Abstract: LTE release 12 proposes the use of dual connectivity in heterogeneous\ncellular networks, where a user equipment (UE) maintains parallel connections\nto a macro-cell node (base station) and to a low-tier node (pico base station\nor relay). In this paper, we propose a distributed multi-objective power\ncontrol scheme where each UE independently adapts its transmit power on its\ndual connections, possibly of unequal bandwidth, with non-ideal backhaul links.\nIn the proposed scheme, the UEs can dynamically switch their objectives between\ndata rate maximization and transmit power minimization as the backhaul load\nvaries. Given the coupling between interference and the backhaul load, we\npropose a low-overhead convergence mechanism which does not require explicit\ncoordination between autonomous nodes and also derive a closed-form expression\nof the transmit power levels at equilibrium. We illustrate a higher aggregate\nend-to-end data rate and significant power saving for our scheme over when the\noptimization is implemented through a greedy algorithm or when UEs only perform\nwaterfilling. \n\n"}
{"id": "1502.00714", "contents": "Title: Exploiting the Preferred Domain of FDD Massive MIMO Systems with Uniform\n  Planar Arrays Abstract: Massive multiple-input multiple-output (MIMO) systems hold the potential to\nbe an enabling technology for 5G cellular. Uniform planar array (UPA) antenna\nstructures are a focus of much commercial discussion because of their ability\nto enable a large number of antennas in a relatively small area. With UPA\nantenna structures, the base station can control the beam direction in both the\nhorizontal and vertical domains simultaneously. However, channel conditions may\ndictate that one dimension requires higher channel state information (CSI)\naccuracy than the other. We propose the use of an additional one bit of\nfeedback information sent from the user to the base station to indicate the\npreferred domain on top of the feedback overhead of CSI quantization in\nfrequency division duplexing (FDD) massive MIMO systems. Combined with\nvariable-rate CSI quantization schemes, the numerical studies show that the\nadditional one bit of feedback can increase the quality of CSI significantly\nfor UPA antenna structures. \n\n"}
{"id": "1502.02925", "contents": "Title: On the Finite Length Scaling of Ternary Polar Codes Abstract: The polarization process of polar codes over a ternary alphabet is studied.\nRecently it has been shown that the scaling of the blocklength of polar codes\nwith prime alphabet size scales polynomially with respect to the inverse of the\ngap between code rate and channel capacity. However, except for the binary\ncase, the degree of the polynomial in the bound is extremely large. In this\nwork, it is shown that a much lower degree polynomial can be computed\nnumerically for the ternary case. Similar results are conjectured for the\ngeneral case of prime alphabet size. \n\n"}
{"id": "1502.02973", "contents": "Title: A Distributed Tracking Algorithm for Reconstruction of Graph Signals Abstract: The rapid development of signal processing on graphs provides a new\nperspective for processing large-scale data associated with irregular domains.\nIn many practical applications, it is necessary to handle massive data sets\nthrough complex networks, in which most nodes have limited computing power.\nDesigning efficient distributed algorithms is critical for this task. This\npaper focuses on the distributed reconstruction of a time-varying bandlimited\ngraph signal based on observations sampled at a subset of selected nodes. A\ndistributed least square reconstruction (DLSR) algorithm is proposed to recover\nthe unknown signal iteratively, by allowing neighboring nodes to communicate\nwith one another and make fast updates. DLSR uses a decay scheme to annihilate\nthe out-of-band energy occurring in the reconstruction process, which is\ninevitably caused by the transmission delay in distributed systems. Proof of\nconvergence and error bounds for DLSR are provided in this paper, suggesting\nthat the algorithm is able to track time-varying graph signals and perfectly\nreconstruct time-invariant signals. The DLSR algorithm is numerically\nexperimented with synthetic data and real-world sensor network data, which\nverifies its ability in tracking slowly time-varying graph signals. \n\n"}
{"id": "1502.03124", "contents": "Title: Order-Optimal Rate of Caching and Coded Multicasting with Random Demands Abstract: We consider the canonical {\\em shared link network} formed by a source node,\nhosting a library of $m$ information messages (files), connected via a\nnoiseless common link to $n$ destination nodes (users), each with a cache of\nsize M files. Users request files at random and independently, according to a\ngiven a-priori demand distribution $\\qv$. A coding scheme for this network\nconsists of a caching placement (i.e., a mapping of the library files into the\nuser caches) and delivery scheme (i.e., a mapping for the library files and\nuser demands into a common multicast codeword) such that, after the codeword\ntransmission, all users can retrieve their requested file. The rate of the\nscheme is defined as the {\\em average} codeword length normalized with respect\nto the length of one file, where expectation is taken over the random user\ndemands. For the same shared link network, in the case of deterministic\ndemands, the optimal min-max rate has been characterized within a uniform\nbound, independent of the network parameters. In particular, fractional caching\n(i.e., storing file segments) and using linear network coding has been shown to\nprovide a min-max rate reduction proportional to 1/M with respect to standard\nschemes such as unicasting or \"naive\" uncoded multicasting. The case of random\ndemands was previously considered by applying the same order-optimal min-max\nscheme separately within groups of files requested with similar probability.\nHowever, no order-optimal guarantee was provided for random demands under the\naverage rate performance criterion. In this paper, we consider the random\ndemand setting and provide general achievability and converse results. In\nparticular, we consider a family of schemes that combine random fractional\ncaching according to a probability distribution $\\pv$ that depends on the\ndemand distribution $\\qv$, with a linear coded delivery scheme based on ... \n\n"}
{"id": "1502.04169", "contents": "Title: Computationally Tractable Algorithms for Finding a Subset of\n  Non-defective Items from a Large Population Abstract: In the classical non-adaptive group testing setup, pools of items are tested\ntogether, and the main goal of a recovery algorithm is to identify the\n\"complete defective set\" given the outcomes of different group tests. In\ncontrast, the main goal of a \"non-defective subset recovery\" algorithm is to\nidentify a \"subset\" of non-defective items given the test outcomes. In this\npaper, we present a suite of computationally efficient and analytically\ntractable non-defective subset recovery algorithms. By analyzing the\nprobability of error of the algorithms, we obtain bounds on the number of tests\nrequired for non-defective subset recovery with arbitrarily small probability\nof error. Our analysis accounts for the impact of both the additive noise\n(false positives) and dilution noise (false negatives). By comparing with the\ninformation theoretic lower bounds, we show that the upper bounds on the number\nof tests are order-wise tight up to a $\\log^2K$ factor, where $K$ is the number\nof defective items. We also provide simulation results that compare the\nrelative performance of the different algorithms and provide further insights\ninto their practical utility. The proposed algorithms significantly outperform\nthe straightforward approaches of testing items one-by-one, and of first\nidentifying the defective set and then choosing the non-defective items from\nthe complement set, in terms of the number of measurements required to ensure a\ngiven success rate. \n\n"}
{"id": "1502.04262", "contents": "Title: Information flow through a model of the C. elegans klinotaxis circuit Abstract: Understanding how information about external stimuli is transformed into\nbehavior is one of the central goals of neuroscience. Here we characterize the\ninformation flow through a complete sensorimotor circuit: from stimulus, to\nsensory neurons, to interneurons, to motor neurons, to muscles, to motion.\nSpecifically, we apply a recently developed framework for quantifying\ninformation flow to a previously published ensemble of models of salt\nklinotaxis in the nematode worm C. elegans. The models are grounded in the\nneuroanatomy and currently known neurophysiology of the worm. The unknown model\nparameters were optimized to reproduce the worm's behavior. Information flow\nanalysis reveals several key principles underlying how the models operate: (1)\nInterneuron class AIY is responsible for integrating information about positive\nand negative changes in concentration, and exhibits a strong left/right\ninformation asymmetry. (2) Gap junctions play a crucial role in the transfer of\ninformation responsible for the information symmetry observed in interneuron\nclass AIZ. (3) Neck motor neuron class SMB implements an information gating\nmechanism that underlies the circuit's state-dependent response. (4) The neck\ncarries non-uniform distribution about changes in concentration. Thus, not all\ndirections of movement are equally informative. Each of these findings\ncorresponds to an experimental prediction that could be tested in the worm to\ngreatly refine our understanding of the neural circuit underlying klinotaxis.\nInformation flow analysis also allows us to explore how information flow\nrelates to underlying electrophysiology. Despite large variations in the neural\nparameters of individual circuits, the overall information flow architecture\ncircuit is remarkably consistent across the ensemble, suggesting that\ninformation flow analysis captures general principles of operation for the\nklinotaxis circuit. \n\n"}
{"id": "1502.04806", "contents": "Title: On the Noisy Feedback Capacity of Gaussian Broadcast Channels Abstract: It is well known that, in general, feedback may enlarge the capacity region\nof Gaussian broadcast channels. This has been demonstrated even when the\nfeedback is noisy (or partial-but-perfect) and only from one of the receivers.\nThe only case known where feedback has been shown not to enlarge the capacity\nregion is when the channel is physically degraded (El Gamal 1978, 1981). In\nthis paper, we show that for a class of two-user Gaussian broadcast channels\n(not necessarily physically degraded), passively feeding back the stronger\nuser's signal over a link corrupted by Gaussian noise does not enlarge the\ncapacity region if the variance of feedback noise is above a certain threshold. \n\n"}
{"id": "1502.05789", "contents": "Title: Location Identification of Power Line Outages Using PMU Measurements\n  with Bad Data Abstract: The use of phasor angle measurements provided by phasor measurement units\n(PMUs) in fault detection is regarded as a promising method in identifying\nlocations of power line outages. However, communication errors or system\nmalfunctions may introduce errors to the measurements and thus yield bad data.\nMost of the existing methods on line outage identification fail to consider\nsuch error. This paper develops a framework for identifying multiple power line\noutages based on the PMUs' measurements in the presence of bad data. In\nparticular, we design an algorithm to identify locations of line outage and\nrecover the faulty measurements simultaneously. The proposed algorithm does not\nrequire any prior information on the number of line outages and the noise\nvariance. Case studies carried out on test systems of different sizes validate\nthe effectiveness and efficiency of the proposed approach. \n\n"}
{"id": "1502.06491", "contents": "Title: Unique Factorization and Controllability of Tail-Biting Trellis\n  Realizations via Controller Granule Decompositions Abstract: The Conti-Boston factorization theorem (CBFT) for linear tail-biting trellis\nrealizations is extended to group realizations with a new and simpler proof,\nbased on a controller granule decomposition of the behavior and known\ncontrollability results for group realizations. Further controllability results\nare given; e.g., a trellis realization is controllable if and only if its top\n(controllability) granule is trivial. \n\n"}
{"id": "1502.06601", "contents": "Title: Optimization-Based Linear Network Coding for General Connections of\n  Continuous Flows Abstract: For general connections, the problem of finding network codes and optimizing\nresources for those codes is intrinsically difficult and little is known about\nits complexity. Most of the existing solutions rely on very restricted classes\nof network codes in terms of the number of flows allowed to be coded together,\nand are not entirely distributed. In this paper, we consider a new method for\nconstructing linear network codes for general connections of continuous flows\nto minimize the total cost of edge use based on mixing. We first formulate the\nminimumcost network coding design problem. To solve the optimization problem,\nwe propose two equivalent alternative formulations with discrete mixing and\ncontinuous mixing, respectively, and develop distributed algorithms to solve\nthem. Our approach allows fairly general coding across flows and guarantees no\ngreater cost than any solution without network coding. \n\n"}
{"id": "1502.06899", "contents": "Title: Towards a Tractable Analysis of Localization Fundamentals in Cellular\n  Networks Abstract: When dedicated positioning systems, such as GPS, are unavailable, a mobile\ndevice has no choice but to fall back on its cellular network for localization.\nDue to random variations in the channel conditions to its surrounding base\nstations (BS), the mobile device is likely to face a mix of both favorable and\nunfavorable geometries for localization. Analytical studies of localization\nperformance (e.g., using the Cram\\'{e}r-Rao lower bound) usually require that\none fix the BS geometry, and favorable geometries have always been the\npreferred choice in the literature. However, not only are the resulting\nanalytical results constrained to the selected geometry, this practice is\nlikely to lead to overly-optimistic expectations of typical localization\nperformance. Ideally, localization performance should be studied across all\npossible geometric setups, thereby also removing any selection bias. This,\nhowever, is known to be hard and has been carried out only in simulation. In\nthis paper, we develop a new tractable approach where we endow the BS locations\nwith a distribution by modeling them as a Poisson point process (PPP), and use\ntools from stochastic geometry to obtain easy-to-use expressions for key\nperformance metrics. In particular, we focus on the probability of detecting\nsome minimum number of BSs, which is shown to be closely coupled with a network\noperator's ability to obtain satisfactory localization performance (e.g., meet\nFCC E911 requirements). This metric is indifferent to the localization\ntechnique (e.g., TOA, TDOA, AOA, or hybrids thereof), though different\ntechniques will presumably lead to different BS hearability requirements. In\norder to mitigate excessive interference due to the presence of dominant\ninterferers in the form of other BSs, we incorporate both BS coordination and\nfrequency reuse in the proposed framework and quantify the resulting\nperformance gains analytically. \n\n"}
{"id": "1502.06945", "contents": "Title: New extremal binary self-dual codes of lengths 66 and 68 from codes over\n  r_k,m Abstract: In this work, four circulant and quadratic double circulant (QDC)\nconstructions are applied to the family of the rings R_k,m. Self-dual binary\ncodes are obtained as the Gray images of self-dual QDC codes over R_k,m.\nExtremal binary self-dual codes of length 64 are obtained as Gray images of\n?-four circulant codes over R_2,1 and R_2,2. Extremal binary self-dual codes of\nlengths 66 and 68 are constructed by applying extension theorems to the F_2 and\nR_2,1 images of these codes. More precisely, 11 new codes of length 66 and 39\nnew codes of length 68 are discovered. The codes with these weight enumerators\nare constructed for the first time in literature. The results are tabulated. \n\n"}
{"id": "1502.07966", "contents": "Title: Delay-Aware Uplink Fronthaul Allocation in Cloud Radio Access Networks Abstract: In cloud radio access networks (C-RANs), the baseband units and radio units\nof base stations are separated, which requires high-capacity fronthaul links\nconnecting both parts. In this paper, we consider the delay-aware fronthaul\nallocation problem for C-RANs. The stochastic optimization problem is\nformulated as an infinite horizon average cost Markov decision process. To deal\nwith the curse of dimensionality, we derive a closed-form approximate priority\nfunction and the associated error bound using perturbation analysis. Based on\nthe closed-form approximate priority function, we propose a low-complexity\ndelay-aware fronthaul allocation algorithm solving the per-stage optimization\nproblem. The proposed solution is further shown to be asymptotically optimal\nfor sufficiently small cross link path gains. Finally, the proposed fronthaul\nallocation algorithm is compared with various baselines through simulations,\nand it is shown that significant performance gain can be achieved. \n\n"}
{"id": "1503.00267", "contents": "Title: Distributed Cloud Association in Downlink Multicloud Radio Access\n  Networks Abstract: This paper considers a multicloud radio access network (M-CRAN), wherein each\ncloud serves a cluster of base-stations (BS's) which are connected to the\nclouds through high capacity digital links. The network comprises several\nremote users, where each user can be connected to one (and only one) cloud.\nThis paper studies the user-to-cloud-assignment problem by maximizing a\nnetwork-wide utility subject to practical cloud connectivity constraints. The\npaper solves the problem by using an auction-based iterative algorithm, which\ncan be implemented in a distributed fashion through a reasonable exchange of\ninformation between the clouds. The paper further proposes a centralized\nheuristic algorithm, with low computational complexity. Simulations results\nshow that the proposed algorithms provide appreciable performance improvements\nas compared to the conventional cloud-less assignment solutions. \n\n"}
{"id": "1503.00877", "contents": "Title: Modeling and Analysis of Wireless Channels via the Mixture of Gaussian\n  Distribution Abstract: Considerable efforts have been devoted to statistical modeling and the\ncharacterization of channels in a range of statistical models for fading\nchannels. In this paper, we consider a unified approach to model wireless\nchannels by the mixture of Gaussian (MoG) distribution. Simulations provided\nhave shown the new probability density function to accurately characterize\nmultipath fading as well as composite fading channels. We utilize the well\nknown expectation-maximization algorithm to estimate the parameters of the MoG\nmodel and further utilize the Kullback-Leibler divergence and the mean square\nerror criteria to demonstrate that our model provides both high accuracy and\nlow computational complexity, in comparison with existing results.\nAdditionally, we provide closed form expressions for several performance\nmetrics used in wireless communication systems, including the moment generating\nfunction, the raw moments, the amount of fading, the outage probability, the\naverage channel capacity, and the probability of energy detection for cognitive\nradio. Numerical Analysis and Monte-Carlo simulations are presented to\ncorroborate the analytical results and to provide detailed performance\ncomparisons with the other models in the literature. \n\n"}
{"id": "1503.01570", "contents": "Title: A proof of the Shepp-Olkin entropy concavity conjecture Abstract: We prove the Shepp--Olkin conjecture, which states that the entropy of the\nsum of independent Bernoulli random variables is concave in the parameters of\nthe individual random variables. Our proof is a refinement of an argument\npreviously presented by the same authors, which resolved the conjecture in the\nmonotonic case (where all the parameters are simultaneously increasing). In\nfact, we show that the monotonic case is the worst case, using a careful\nanalysis of concavity properties of the derivatives of the probability mass\nfunction. We propose a generalization of Shepp and Olkin's original conjecture,\nto consider Renyi and Tsallis entropies. \n\n"}
{"id": "1503.02339", "contents": "Title: Multiple and single snapshot compressive beamforming Abstract: For a sound field observed on a sensor array, compressive sensing (CS)\nreconstructs the direction-of-arrival (DOA) of multiple sources using a\nsparsity constraint. The DOA estimation is posed as an underdetermined problem\nby expressing the acoustic pressure at each sensor as a phase-lagged\nsuperposition of source amplitudes at all hypothetical DOAs. Regularizing with\nan $\\ell_1$-norm constraint renders the problem solvable with convex\noptimization, and promoting sparsity gives high-resolution DOA maps. Here, the\nsparse source distribution is derived using maximum a posteriori (MAP)\nestimates for both single and multiple snapshots. CS does not require inversion\nof the data covariance matrix and thus works well even for a single snapshot\nwhere it gives higher resolution than conventional beamforming. For multiple\nsnapshots, CS outperforms conventional high-resolution methods, even with\ncoherent arrivals and at low signal-to-noise ratio. The superior resolution of\nCS is demonstrated with vertical array data from the SWellEx96 experiment for\ncoherent multi-paths. \n\n"}
{"id": "1503.04604", "contents": "Title: Multi-Antenna Wireless Energy Transfer for Backscatter Communication\n  Systems Abstract: We study RF-enabled wireless energy transfer (WET) via energy beamforming,\nfrom a multi-antenna energy transmitter (ET) to multiple energy receivers (ERs)\nin a backscatter communication system, such as RFID, where each ER (or RFID\ntag) reflects back a portion of the incident signal to the ET (or RFID reader).\nFor such a system, the acquisition of the forward-channel (i.e., ET-to-ER)\nstate information (F-CSI) at the ET is challenging, since the ERs are typically\ntoo energy-and-hardware-constrained to estimate or feed back the F-CSI. The ET\nleverages its observed backscatter signals to estimate the backscatter-channel\n(i.e., ET-to-ER-to-ET) state information (BS-CSI) directly. We first analyze\nthe harvested energy obtained by using the estimated BS-CSI. Furthermore, we\noptimize the channel-training energy and the energy allocation weights for\ndifferent energy beams, for weighted-sum-energy (WSE) maximization and\nproportional-fair-energy (PFE) maximization. For WET to single ER, we obtain\nthe optimal channel-training energy in a semi-closed form. For WET to multiple\nERs, the optimal WET scheme for WSE maximization is shown to use only one\nenergy beam. For PFE maximization, we show it is a biconvex problem, and\npropose a block-coordinate-descent based algorithm to find the close-to-optimal\nsolution. Numerical results show that with the optimized solutions, the\nharvested energy suffers slight reduction of less than 10%, compared to that\nobtained by using the perfect F-CSI. Hence, energy beamforming by using the\nestimated BS-CSI is promising, as the complexity and energy requirement is\nshifted from the ERs to the ET. \n\n"}
{"id": "1503.05113", "contents": "Title: Quantifying Morphological Computation based on an Information\n  Decomposition of the Sensorimotor Loop Abstract: The question how an agent is affected by its embodiment has attracted growing\nattention in recent years. A new field of artificial intelligence has emerged,\nwhich is based on the idea that intelligence cannot be understood without\ntaking into account embodiment. We believe that a formal approach to\nquantifying the embodiment's effect on the agent's behaviour is beneficial to\nthe fields of artificial life and artificial intelligence. The contribution of\nan agent's body and environment to its behaviour is also known as morphological\ncomputation. Therefore, in this work, we propose a quantification of\nmorphological computation, which is based on an information decomposition of\nthe sensorimotor loop into shared, unique and synergistic information. In\nnumerical simulation based on a formal representation of the sensorimotor loop,\nwe show that the unique information of the body and environment is a good\nmeasure for morphological computation. The results are compared to our\npreviously derived quantification of morphological computation. \n\n"}
{"id": "1503.05365", "contents": "Title: Caching at the Edge: a Green Perspective for 5G Networks Abstract: Endowed with context-awareness and proactive capabilities, caching users'\ncontent locally at the edge of the network is able to cope with increasing data\ntraffic demand in 5G wireless networks. In this work, we focus on the energy\nconsumption aspects of cache-enabled wireless cellular networks, specifically\nin terms of area power consumption (APC) and energy efficiency (EE). We assume\nthat both base stations (BSs) and mobile users are distributed according to\nhomogeneous Poisson point processes (PPPs) and we introduce a detailed power\nmodel that takes into account caching. We study the conditions under which the\narea power consumption is minimized with respect to BS transmit power, while\nensuring a certain quality of service (QoS) in terms of coverage probability.\nFurthermore, we provide the optimal BS transmit power that maximizes the area\nspectral efficiency per unit total power spent. The main takeaway of this paper\nis that caching seems to be an energy efficient solution. \n\n"}
{"id": "1503.05448", "contents": "Title: A Transfer Learning Approach for Cache-Enabled Wireless Networks Abstract: Locally caching contents at the network edge constitutes one of the most\ndisruptive approaches in $5$G wireless networks. Reaping the benefits of edge\ncaching hinges on solving a myriad of challenges such as how, what and when to\nstrategically cache contents subject to storage constraints, traffic load,\nunknown spatio-temporal traffic demands and data sparsity. Motivated by this,\nwe propose a novel transfer learning-based caching procedure carried out at\neach small cell base station. This is done by exploiting the rich contextual\ninformation (i.e., users' content viewing history, social ties, etc.) extracted\nfrom device-to-device (D2D) interactions, referred to as source domain. This\nprior information is incorporated in the so-called target domain where the goal\nis to optimally cache strategic contents at the small cells as a function of\nstorage, estimated content popularity, traffic load and backhaul capacity. It\nis shown that the proposed approach overcomes the notorious data sparsity and\ncold-start problems, yielding significant gains in terms of users'\nquality-of-experience (QoE) and backhaul offloading, with gains reaching up to\n$22\\%$ in a setting consisting of four small cell base stations. \n\n"}
{"id": "1503.06675", "contents": "Title: The Fourier Decomposition Method for nonlinear and nonstationary time\n  series analysis Abstract: Since many decades, there is a general perception in literature that the\nFourier methods are not suitable for the analysis of nonlinear and\nnonstationary data. In this paper, we propose a Fourier Decomposition Method\n(FDM) and demonstrate its efficacy for the analysis of nonlinear (i.e. data\ngenerated by nonlinear systems) and nonstationary time series. The proposed FDM\ndecomposes any data into a small number of `Fourier intrinsic band functions'\n(FIBFs). The FDM presents a generalized Fourier expansion with variable\namplitudes and frequencies of a time series by the Fourier method itself. We\npropose an idea of zero-phase filter bank based multivariate FDM (MFDM)\nalgorithm, for the analysis of multivariate nonlinear and nonstationary time\nseries, from the FDM. We also present an algorithm to obtain cutoff frequencies\nfor MFDM. The MFDM algorithm is generating finite number of band limited\nmultivariate FIBFs (MFIBFs). The MFDM preserves some intrinsic physical\nproperties of the multivariate data, such as scale alignment, trend and\ninstantaneous frequency. The proposed methods produce the results in a\ntime-frequency-energy distribution that reveal the intrinsic structures of a\ndata. Simulations have been carried out and comparison is made with the\nEmpirical Mode Decomposition (EMD) methods in the analysis of various simulated\nas well as real life time series, and results show that the proposed methods\nare powerful tools for analyzing and obtaining the time-frequency-energy\nrepresentation of any data. \n\n"}
{"id": "1503.07455", "contents": "Title: Sum Secrecy Rate in MISO Full-Duplex Wiretap Channel with Imperfect CSI Abstract: In this paper, we consider the achievable sum secrecy rate in MISO\n(multiple-input-single-output) {\\em full-duplex} wiretap channel in the\npresence of a passive eavesdropper and imperfect channel state information\n(CSI). We assume that the users participating in full-duplex communication have\nmultiple transmit antennas, and that the users and the eavesdropper have single\nreceive antenna each. The users have individual transmit power constraints.\nThey also transmit jamming signals to improve the secrecy rates. We obtain the\nachievable perfect secrecy rate region by maximizing the worst case sum secrecy\nrate. We also obtain the corresponding transmit covariance matrices associated\nwith the message signals and the jamming signals. Numerical results that show\nthe impact of imperfect CSI on the achievable secrecy rate region are\npresented. \n\n"}
{"id": "1503.08782", "contents": "Title: Robust Recovery of Positive Stream of Pulses Abstract: The problem of estimating the delays and amplitudes of a positive stream of\npulses appears in many applications, such as single-molecule microscopy. This\npaper suggests estimating the delays and amplitudes using a convex program,\nwhich is robust in the presence of noise (or model mismatch). Particularly, the\nrecovery error is proportional to the noise level. We further show that the\nerror grows exponentially with the density of the delays and also depends on\nthe localization properties of the pulse. \n\n"}
{"id": "1504.02530", "contents": "Title: Classifying Unrooted Gaussian Trees under Privacy Constraints Abstract: In this work, our objective is to find out how topological and algebraic\nproperties of unrooted Gaussian tree models determine their security\nrobustness, which is measured by our proposed max-min information (MaMI)\nmetric. Such metric quantifies the amount of common randomness extractable\nthrough public discussion between two legitimate nodes under an eavesdropper\nattack. We show some general topological properties that the desired max-min\nsolutions shall satisfy. Under such properties, we develop conditions under\nwhich comparable trees are put together to form partially ordered sets\n(posets). Each poset contains the most favorable structure as the poset leader,\nand the least favorable structure. Then, we compute the Tutte-like polynomial\nfor each tree in a poset in order to assign a polynomial to any tree in a\nposet. Moreover, we propose a novel method, based on restricted integer\npartitions, to effectively enumerate all poset leaders. The results not only\nhelp us understand the security strength of different Gaussian trees, which is\ncritical when we evaluate the information leakage issues for various jointly\nGaussian distributed measurements in networks, but also provide us both an\nalgebraic and a topological perspective in grasping some fundamental properties\nof such models. \n\n"}
{"id": "1504.03024", "contents": "Title: Almost Lossless Analog Compression without Phase Information Abstract: We propose an information-theoretic framework for phase retrieval.\nSpecifically, we consider the problem of recovering an unknown n-dimensional\nvector x up to an overall sign factor from m=Rn phaseless measurements with\ncompression rate R and derive a general achievability bound for R.\nSurprisingly, it turns out that this bound on the compression rate is the same\nas the one for almost lossless analog compression obtained by Wu and Verd\\'u\n(2010): Phaseless linear measurements are as good as linear measurements with\nfull phase information in the sense that ignoring the sign of m measurements\nonly leaves us with an ambiguity with respect to an overall sign factor of x. \n\n"}
{"id": "1504.03048", "contents": "Title: The weight distributions of two classes of p ary cyclic codes with few\n  weights Abstract: Cyclic codes have attracted a lot of research interest for decades as they\nhave efficient encoding and decoding algorithms.\n  In this paper, for an odd prime $p$, the weight distributions of two classes\nof $p$-ary cyclic codes are completely determined. We show that both codes have\nat most five nonzero weights. \n\n"}
{"id": "1504.04113", "contents": "Title: On the Performance of the Relay-ARQ Networks Abstract: This paper investigates the performance of relay networks in the presence of\nhybrid automatic repeat request (ARQ) feedback and adaptive power allocation.\nThe throughput and the outage probability of different hybrid ARQ protocols are\nstudied for independent and spatially-correlated fading channels. The results\nare obtained for the cases where there is a sum power constraint on the source\nand the relay or when each of the source and the relay are power-limited\nindividually. With adaptive power allocation, the results demonstrate the\nefficiency of relay-ARQ techniques in different conditions. \n\n"}
{"id": "1504.04419", "contents": "Title: Wasserstein continuity of entropy and outer bounds for interference\n  channels Abstract: It is shown that under suitable regularity conditions, differential entropy\nis a Lipschitz functional on the space of distributions on $n$-dimensional\nEuclidean space with respect to the quadratic Wasserstein distance. Under\nsimilar conditions, (discrete) Shannon entropy is shown to be Lipschitz\ncontinuous in distributions over the product space with respect to Ornstein's\n$\\bar d$-distance (Wasserstein distance corresponding to the Hamming distance).\nThese results together with Talagrand's and Marton's transportation-information\ninequalities allow one to replace the unknown multi-user interference with its\ni.i.d. approximations. As an application, a new outer bound for the two-user\nGaussian interference channel is proved, which, in particular, settles the\n\"missing corner point\" problem of Costa (1985). \n\n"}
{"id": "1504.05318", "contents": "Title: Compressive Random Access Using A Common Overloaded Control Channel Abstract: We introduce a \"one shot\" random access procedure where users can send a\nmessage without a priori synchronizing with the network. In this procedure a\ncommon overloaded control channel is used to jointly detect sparse user\nactivity and sparse channel profiles. The detected information is subsequently\nused to demodulate the data in dedicated frequency slots. We analyze the system\ntheoretically and provide a link between achievable rates and standard\ncompressing sensing estimates in terms of explicit expressions and scaling\nlaws. Finally, we support our findings with simulations in an LTE-A-like\nsetting allowing \"one shot\" sparse random access of 100 users in 1ms. \n\n"}
{"id": "1504.05566", "contents": "Title: Secure State Estimation: Optimal Guarantees against Sensor Attacks in\n  the Presence of Noise Abstract: Motivated by the need to secure cyber-physical systems against attacks, we\nconsider the problem of estimating the state of a noisy linear dynamical system\nwhen a subset of sensors is arbitrarily corrupted by an adversary. We propose a\nsecure state estimation algorithm and derive (optimal) bounds on the achievable\nstate estimation error. In addition, as a result of independent interest, we\ngive a coding theoretic interpretation for prior work on secure state\nestimation against sensor attacks in a noiseless dynamical system. \n\n"}
{"id": "1504.06247", "contents": "Title: TC: Throughput Centric Successive Cancellation Decoder Hardware\n  Implementation for Polar Codes Abstract: This paper presents a hardware architecture of fast simplified successive\ncancellation (fast-SSC) algorithm for polar codes, which significantly reduces\nthe decoding latency and dramatically increases the throughput.\nAlgorithmically, fast-SSC algorithm suffers from the fact that its decoder\nscheduling and the consequent architecture depends on the code rate; this is a\nchallenge for rate-compatible system. However, by exploiting the\nhomogeneousness between the decoding processes of fast constituent polar codes\nand regular polar codes, the presented design is compatible with any rate. The\nscheduling plan and the intendedly designed process core are also described.\nResults show that, compared with the state-of-art decoder, proposed design can\nachieve at least 60% latency reduction for the codes with length N = 1024. By\nusing Nangate FreePDK 45nm process, proposed design can reach throughput up to\n5.81 Gbps and 2.01 Gbps for (1024, 870) and (1024, 512) polar code,\nrespectively. \n\n"}
{"id": "1504.06316", "contents": "Title: Interactive Communication with Unknown Noise Rate Abstract: Alice and Bob want to run a protocol over a noisy channel, where a certain\nnumber of bits are flipped adversarially. Several results take a protocol\nrequiring $L$ bits of noise-free communication and make it robust over such a\nchannel. In a recent breakthrough result, Haeupler described an algorithm that\nsends a number of bits that is conjectured to be near optimal in such a model.\nHowever, his algorithm critically requires $a \\ priori$ knowledge of the number\nof bits that will be flipped by the adversary.\n  We describe an algorithm requiring no such knowledge. If an adversary flips\n$T$ bits, our algorithm sends $L + O\\left(\\sqrt{L(T+1)\\log L} + T\\right)$ bits\nin expectation and succeeds with high probability in $L$. It does so without\nany $a \\ priori$ knowledge of $T$. Assuming a conjectured lower bound by\nHaeupler, our result is optimal up to logarithmic factors.\n  Our algorithm critically relies on the assumption of a private channel. We\nshow that privacy is necessary when the amount of noise is unknown. \n\n"}
{"id": "1505.00769", "contents": "Title: On Non-Interactive Simulation of Joint Distributions Abstract: We consider the following non-interactive simulation problem: Alice and Bob\nobserve sequences $X^n$ and $Y^n$ respectively where $\\{(X_i, Y_i)\\}_{i=1}^n$\nare drawn i.i.d. from $P(x,y),$ and they output $U$ and $V$ respectively which\nis required to have a joint law that is close in total variation to a specified\n$Q(u,v).$ It is known that the maximal correlation of $U$ and $V$ must\nnecessarily be no bigger than that of $X$ and $Y$ if this is to be possible.\nOur main contribution is to bring hypercontractivity to bear as a tool on this\nproblem. In particular, we show that if $P(x,y)$ is the doubly symmetric binary\nsource, then hypercontractivity provides stronger impossibility results than\nmaximal correlation. Finally, we extend these tools to provide impossibility\nresults for the $k$-agent version of this problem. \n\n"}
{"id": "1505.00810", "contents": "Title: Optimizing Data Aggregation for Uplink Machine-to-Machine Communication\n  Networks Abstract: Machine-to-machine (M2M) communication's severe power limitations challenge\nthe interconnectivity, access management, and reliable communication of data.\nIn densely deployed M2M networks, controlling and aggregating the generated\ndata is critical. We propose an energy efficient data aggregation scheme for a\nhierarchical M2M network. We develop a coverage probability-based optimal data\naggregation scheme for M2M devices to minimize the average total energy\nexpenditure per unit area per unit time or simply the {\\em energy density} of\nan M2M communication network. Our analysis exposes the key tradeoffs between\nthe energy density of the M2M network and the coverage characteristics for\nsuccessive and parallel transmission schemes that can be either half-duplex or\nfull-duplex. Comparing the rate and energy performances of the transmission\nmodels, we observe that successive mode and half-duplex parallel mode have\nbetter coverage characteristics compared to full-duplex parallel scheme.\nSimulation results show that the uplink coverage characteristics dominate the\ntrend of the energy consumption for both successive and parallel schemes. \n\n"}
{"id": "1505.01137", "contents": "Title: On the Reliability Function of Variable-Rate Slepian-Wolf Coding Abstract: The reliability function of variable-rate Slepian-Wolf coding is linked to\nthe reliability function of channel coding with constant composition codes,\nthrough which computable lower and upper bounds are derived. The bounds\ncoincide at rates close to the Slepian-Wolf limit, yielding a complete\ncharacterization of the reliability function in that rate regime. It is shown\nthat variable-rate Slepian-Wolf codes can significantly outperform fixed-rate\nSlepian-Wolf codes in terms of rate-error tradeoff. The reliability function of\nvariable-rate Slepian-Wolf coding with rate below the Slepian-Wolf limit is\ndetermined. In sharp contrast with fixed-rate Slepian-Wolf codes for which the\ncorrect decoding probability decays to zero exponentially fast if the rate is\nbelow the Slepian-Wolf limit, the correct decoding probability of variable-rate\nSlepian-Wolf codes can be bounded away from zero. \n\n"}
{"id": "1505.01619", "contents": "Title: Compressed sensing with structured sparsity and structured acquisition Abstract: Compressed Sensing (CS) is an appealing framework for applications such as\nMagnetic Resonance Imaging (MRI). However, up-to-date, the sensing schemes\nsuggested by CS theories are made of random isolated measurements, which are\nusually incompatible with the physics of acquisition. To reflect the physical\nconstraints of the imaging device, we introduce the notion of blocks of\nmeasurements: the sensing scheme is not a set of isolated measurements anymore,\nbut a set of groups of measurements which may represent any arbitrary shape\n(parallel or radial lines for instance). Structured acquisition with blocks of\nmeasurements are easy to implement, and provide good reconstruction results in\npractice. However, very few results exist on the theoretical guarantees of CS\nreconstructions in this setting. In this paper, we derive new CS results for\nstructured acquisitions and signals satisfying a prior structured sparsity. The\nobtained results provide a recovery probability of sparse vectors that\nexplicitly depends on their support. Our results are thus support-dependent and\noffer the possibility for flexible assumptions on the sparsity structure.\nMoreover, the results are drawing-dependent, since we highlight an explicit\ndependency between the probability of reconstructing a sparse vector and the\nway of choosing the blocks of measurements. Numerical simulations show that the\nproposed theory is faithful to experimental observations. \n\n"}
{"id": "1505.01753", "contents": "Title: Weighted Gaussian entropy and determinant inequalities Abstract: We produce a series of results extending information-theoretical inequalities\n(discussed by Dembo--Cover--Thomas in 1989-1991) to a weighted version of\nentropy. The resulting inequalities involve the Gaussian weighted entropy; they\nimply a number of new relations for determinants of positive-definite matrices. \n\n"}
{"id": "1505.03257", "contents": "Title: Optimal linear estimation under unknown nonlinear transform Abstract: Linear regression studies the problem of estimating a model parameter\n$\\beta^* \\in \\mathbb{R}^p$, from $n$ observations\n$\\{(y_i,\\mathbf{x}_i)\\}_{i=1}^n$ from linear model $y_i = \\langle\n\\mathbf{x}_i,\\beta^* \\rangle + \\epsilon_i$. We consider a significant\ngeneralization in which the relationship between $\\langle \\mathbf{x}_i,\\beta^*\n\\rangle$ and $y_i$ is noisy, quantized to a single bit, potentially nonlinear,\nnoninvertible, as well as unknown. This model is known as the single-index\nmodel in statistics, and, among other things, it represents a significant\ngeneralization of one-bit compressed sensing. We propose a novel spectral-based\nestimation procedure and show that we can recover $\\beta^*$ in settings (i.e.,\nclasses of link function $f$) where previous algorithms fail. In general, our\nalgorithm requires only very mild restrictions on the (unknown) functional\nrelationship between $y_i$ and $\\langle \\mathbf{x}_i,\\beta^* \\rangle$. We also\nconsider the high dimensional setting where $\\beta^*$ is sparse ,and introduce\na two-stage nonconvex framework that addresses estimation challenges in high\ndimensional regimes where $p \\gg n$. For a broad class of link functions\nbetween $\\langle \\mathbf{x}_i,\\beta^* \\rangle$ and $y_i$, we establish minimax\nlower bounds that demonstrate the optimality of our estimators in both the\nclassical and high dimensional regimes. \n\n"}
{"id": "1505.07283", "contents": "Title: Index Codes for the Gaussian Broadcast Channel using Quadrature\n  Amplitude Modulation Abstract: We propose index codes, based on multidimensional QAM constellations, for the\nGaussian broadcast channel, where every receiver demands all the messages from\nthe source. The efficiency with which an index code exploits receiver side\ninformation in this broadcast channel is characterised by a code design metric\ncalled \"side information gain\". The known index codes for this broadcast\nchannel enjoy large side information gains, but do not encode all the source\nmessages at the same rate, and do not admit message sizes that are powers of\ntwo. The index codes proposed in this letter, which are based on linear codes\nover integer rings, overcome both these drawbacks and yet provide large values\nof side information gain. With the aid of a computer search, we obtain QAM\nindex codes for encoding up to 5 messages with message sizes 2^m, m <= 6. We\nalso present the simulated performance of a new 16-QAM index code, concatenated\nwith an off-the-shelf LDPC code, which is observed to operate within 4.3 dB of\nthe broadcast channel capacity. \n\n"}
{"id": "1505.07717", "contents": "Title: Exploring multimodal data fusion through joint decompositions with\n  flexible couplings Abstract: A Bayesian framework is proposed to define flexible coupling models for joint\ntensor decompositions of multiple data sets. Under this framework, a natural\nformulation of the data fusion problem is to cast it in terms of a joint\nmaximum a posteriori (MAP) estimator. Data driven scenarios of joint posterior\ndistributions are provided, including general Gaussian priors and non Gaussian\ncoupling priors. We present and discuss implementation issues of algorithms\nused to obtain the joint MAP estimator. We also show how this framework can be\nadapted to tackle the problem of joint decompositions of large datasets. In the\ncase of a conditional Gaussian coupling with a linear transformation, we give\ntheoretical bounds on the data fusion performance using the Bayesian Cramer-Rao\nbound. Simulations are reported for hybrid coupling models ranging from simple\nadditive Gaussian models, to Gamma-type models with positive variables and to\nthe coupling of data sets which are inherently of different size due to\ndifferent resolution of the measurement devices. \n\n"}
{"id": "1506.00154", "contents": "Title: Resolvability in E{\\gamma} with Applications to Lossy Compression and\n  Wiretap Channels Abstract: We study the amount of randomness needed for an input process to approximate\na given output distribution of a channel in the $E_{\\gamma}$ distance. A\ngeneral one-shot achievability bound for the precision of such an approximation\nis developed. In the i.i.d.~setting where $\\gamma=\\exp(nE)$, a (nonnegative)\nrandomness rate above $\\inf_{Q_{\\sf U}: D(Q_{\\sf X}||\\pi_{\\sf X})\\le E}\n\\{D(Q_{\\sf X}||\\pi_{\\sf X})+I(Q_{\\sf U},Q_{\\sf X|U})-E\\}$ is necessary and\nsufficient to asymptotically approximate the output distribution $\\pi_{\\sf\nX}^{\\otimes n}$ using the channel $Q_{\\sf X|U}^{\\otimes n}$, where $Q_{\\sf\nU}\\to Q_{\\sf X|U}\\to Q_{\\sf X}$. The new resolvability result is then used to\nderive a one-shot upper bound on the error probability in the rate distortion\nproblem, and a lower bound on the size of the eavesdropper list to include the\nactual message in the wiretap channel problem. Both bounds are asymptotically\ntight in i.i.d.~settings. \n\n"}
{"id": "1506.00740", "contents": "Title: Asymmetric Lee Distance Codes for DNA-Based Storage Abstract: We consider a new family of codes, termed asymmetric Lee distance codes, that\narise in the design and implementation of DNA-based storage systems and systems\nwith parallel string transmission protocols. The codewords are defined over a\nquaternary alphabet, although the results carry over to other alphabet sizes;\nfurthermore, symbol confusability is dictated by their underlying binary\nrepresentation. Our contributions are two-fold. First, we demonstrate that the\nnew distance represents a linear combination of the Lee and Hamming distance\nand derive upper bounds on the size of the codes under this metric based on\nlinear programming techniques. Second, we propose a number of code\nconstructions which imply lower bounds. \n\n"}
{"id": "1506.02693", "contents": "Title: Approximate Message Passing Algorithm with Universal Denoising and\n  Gaussian Mixture Learning Abstract: We study compressed sensing (CS) signal reconstruction problems where an\ninput signal is measured via matrix multiplication under additive white\nGaussian noise. Our signals are assumed to be stationary and ergodic, but the\ninput statistics are unknown; the goal is to provide reconstruction algorithms\nthat are universal to the input statistics. We present a novel algorithmic\nframework that combines: (i) the approximate message passing (AMP) CS\nreconstruction framework, which solves the matrix channel recovery problem by\niterative scalar channel denoising; (ii) a universal denoising scheme based on\ncontext quantization, which partitions the stationary ergodic signal denoising\ninto independent and identically distributed (i.i.d.) subsequence denoising;\nand (iii) a density estimation approach that approximates the probability\ndistribution of an i.i.d. sequence by fitting a Gaussian mixture (GM) model. In\naddition to the algorithmic framework, we provide three contributions: (i)\nnumerical results showing that state evolution holds for non-separable Bayesian\nsliding-window denoisers; (ii) an i.i.d. denoiser based on a modified GM\nlearning algorithm; and (iii) a universal denoiser that does not need\ninformation about the range where the input takes values from or require the\ninput signal to be bounded. We provide two implementations of our universal CS\nrecovery algorithm with one being faster and the other being more accurate. The\ntwo implementations compare favorably with existing universal reconstruction\nalgorithms in terms of both reconstruction quality and runtime. \n\n"}
{"id": "1506.03236", "contents": "Title: Fundamental Limits of Communication with Low Probability of Detection Abstract: This paper considers the problem of communication over a discrete memoryless\nchannel (DMC) or an additive white Gaussian noise (AWGN) channel subject to the\nconstraint that the probability that an adversary who observes the channel\noutputs can detect the communication is low. Specifically, the relative entropy\nbetween the output distributions when a codeword is transmitted and when no\ninput is provided to the channel must be sufficiently small. For a DMC whose\noutput distribution induced by the \"off\" input symbol is not a mixture of the\noutput distributions induced by other input symbols, it is shown that the\nmaximum amount of information that can be transmitted under this criterion\nscales like the square root of the blocklength. The same is true for the AWGN\nchannel. Exact expressions for the scaling constant are also derived. \n\n"}
{"id": "1506.04822", "contents": "Title: Some Improvements on Locally Repairable Codes Abstract: The locally repairable codes (LRCs) were introduced to correct erasures\nefficiently in distributed storage systems. LRCs are extensively studied\nrecently.\n  In this paper, we first deal with the open case remained in \\cite{q} and\nderive an improved upper bound for the minimum distances of LRCs. We also give\nan explicit construction for LRCs attaining this bound. Secondly, we consider\nthe constructions of LRCs with any locality and availability which have high\ncode rate and minimum distance as large as possible. We give a graphical model\nfor LRCs. By using the deep results from graph theory, we construct a family of\nLRCs with any locality $r$ and availability $2$ with code rate\n$\\frac{r-1}{r+1}$ and optimal minimum distance $O(\\log n)$ where $n$ is the\nlength of the code. \n\n"}
{"id": "1506.06199", "contents": "Title: Non-parametric Quickest Change Detection for Large Scale Random Matrices Abstract: The problem of quickest detection of a change in the distribution of a\n$n\\times p$ random matrix based on a sequence of observations having a single\nunknown change point is considered. The forms of the pre- and post-change\ndistributions of the rows of the matrices are assumed to belong to the family\nof elliptically contoured densities with sparse dispersion matrices but are\notherwise unknown. We propose a non-parametric stopping rule that is based on a\nnovel summary statistic related to k-nearest neighbor correlation between\ncolumns of each observed random matrix. In the large scale regime of\n$p\\rightarrow \\infty$ and $n$ fixed we show that, among all functions of the\nproposed summary statistic, the proposed stopping rule is asymptotically\noptimal under a minimax quickest change detection (QCD) model. \n\n"}
{"id": "1506.06296", "contents": "Title: On Modeling Heterogeneous Wireless Networks Using Non-Poisson Point\n  Processes Abstract: Future wireless networks are required to support 1000 times higher data rate,\nthan the current LTE standard. In order to meet the ever increasing demand, it\nis inevitable that, future wireless networks will have to develop seamless\ninterconnection between multiple technologies. A manifestation of this idea is\nthe collaboration among different types of network tiers such as macro and\nsmall cells, leading to the so-called heterogeneous networks (HetNets).\nResearchers have used stochastic geometry to analyze such networks and\nunderstand their real potential. Unsurprisingly, it has been revealed that\ninterference has a detrimental effect on performance, especially if not modeled\nproperly. Interference can be correlated in space and/or time, which has been\noverlooked in the past. For instance, it is normally assumed that the nodes are\nlocated completely independent of each other and follow a homogeneous Poisson\npoint process (PPP), which is not necessarily true in real networks since the\nnode locations are spatially dependent. In addition, the interference\ncorrelation created by correlated stochastic processes has mostly been ignored.\nTo this end, we take a different approach in modeling the interference where we\nuse non-PPP, as well as we study the impact of spatial and temporal correlation\non the performance of HetNets. To illustrate the impact of correlation on\nperformance, we consider three case studies from real-life scenarios.\nSpecifically, we use massive multiple-input multiple-output (MIMO) to\nunderstand the impact of spatial correlation; we use the random medium access\nprotocol to examine the temporal correlation; and we use cooperative relay\nnetworks to illustrate the spatial-temporal correlation. We present several\nnumerical examples through which we demonstrate the impact of various\ncorrelation types on the performance of HetNets. \n\n"}
{"id": "1506.06484", "contents": "Title: Cross-layer estimation and control for Cognitive Radio: Exploiting\n  Sparse Network Dynamics Abstract: In this paper, a cross-layer framework to jointly optimize spectrum sensing\nand scheduling in resource constrained agile wireless networks is presented. A\nnetwork of secondary users (SUs) accesses portions of the spectrum left unused\nby a network of licensed primary users (PUs). A central controller (CC)\nschedules the traffic of the SUs, based on distributed compressed measurements\ncollected by the SUs. Sensing and scheduling are jointly controlled to maximize\nthe SU throughput, with constraints on PU throughput degradation and SU cost.\nThe sparsity in the spectrum dynamics is exploited: leveraging a prior spectrum\noccupancy estimate, the CC needs to estimate only a residual uncertainty vector\nvia sparse recovery techniques. The high complexity entailed by the POMDP\nformulation is reduced by a low-dimensional belief representation via\nminimization of the Kullback-Leibler divergence. It is proved that the\noptimization of sensing and scheduling can be decoupled. A partially myopic\nscheduling strategy is proposed for which structural properties can be proved\nshowing that the myopic scheme allocates SU traffic to likely idle spectral\nbands. Simulation results show that this framework balances optimally the\nresources between spectrum sensing and data transmission. This framework\ndefines sensing-scheduling schemes most informative for network control,\nyielding energy efficient resource utilization. \n\n"}
{"id": "1506.07571", "contents": "Title: Indoor Location Estimation with Optical-based OFDM Communications Abstract: Visible Light Communication (VLC) using light emitting diodes (LEDs) has been\ngaining increasing attention in recent years as it is appealing for a wide\nrange of applications such as indoor positioning. Orthogonal frequency division\nmultiplexing (OFDM) has been applied to indoor wireless optical communications\nin order to mitigate the effect of multipath distortion of the optical channel\nas well as increasing data rate. In this paper, a novel OFDM VLC system is\nproposed which can be utilized for both communications and indoor positioning.\nA positioning algorithm based on power attenuation is used to estimate the\nreceiver coordinates. We further calculate the positioning errors in all the\nlocations of a room and compare them with those using single carrier modulation\nscheme, i.e., on-off keying (OOK) modulation. We demonstrate that OFDM\npositioning system outperforms its conventional counterpart. Finally, we\ninvestigate the impact of different system parameters on the positioning\naccuracy of the proposed OFDM VLC system. \n\n"}
{"id": "1506.08269", "contents": "Title: Construction $\\pi_A$ and $\\pi_D$ Lattices: Construction, Goodness, and\n  Decoding Algorithms Abstract: A novel construction of lattices is proposed. This construction can be\nthought of as a special class of Construction A from codes over finite rings\nthat can be represented as the Cartesian product of $L$ linear codes over\n$\\mathbb{F}_{p_1},\\ldots,\\mathbb{F}_{p_L}$, respectively, and hence is referred\nto as Construction $\\pi_A$. The existence of a sequence of such lattices that\nis good for channel coding (i.e., Poltyrev-limit achieving) under multistage\ndecoding is shown. A new family of multilevel nested lattice codes based on\nConstruction $\\pi_A$ lattices is proposed and its achievable rate for the\nadditive white Gaussian channel is analyzed. A generalization named\nConstruction $\\pi_D$ is also investigated which subsumes Construction A with\ncodes over prime fields, Construction D, and Construction $\\pi_A$ as special\ncases. \n\n"}
{"id": "1506.08291", "contents": "Title: Generalized Space and Frequency Index Modulation Abstract: Unlike in conventional modulation where information bits are conveyed only\nthrough symbols from modulation alphabets defined in the complex plane (e.g.,\nquadrature amplitude modulation (QAM), phase shift keying (PSK)), in index\nmodulation (IM), additional information bits are conveyed through indices of\ncertain transmit entities that get involved in the transmission. Transmit\nantennas in multi-antenna systems and subcarriers in multi-carrier systems are\nexamples of such transmit entities that can be used to convey additional\ninformation bits through indexing. In this paper, we introduce {\\em generalized\nspace and frequency index modulation}, where the indices of active transmit\nantennas and subcarriers convey information bits. We first introduce index\nmodulation in the spatial domain, referred to as generalized spatial index\nmodulation (GSIM). For GSIM, where bits are indexed only in the spatial domain,\nwe derive the expression for achievable rate as well as easy-to-compute upper\nand lower bounds on this rate. We show that the achievable rate in GSIM can be\nmore than that in spatial multiplexing, and analytically establish the\ncondition under which this can happen. It is noted that GSIM achieves this\nhigher rate using fewer transmit radio frequency (RF) chains compared to\nspatial multiplexing. We also propose a Gibbs sampling based detection\nalgorithm for GSIM and show that GSIM can achieve better bit error rate (BER)\nperformance than spatial multiplexing. For generalized space-frequency index\nmodulation (GSFIM), where bits are encoded through indexing in both active\nantennas as well as subcarriers, we derive the achievable rate expression.\nNumerical results show that GSFIM can achieve higher rates compared to\nconventional MIMO-OFDM. Also, BER results show the potential for GSFIM\nperforming better than MIMO-OFDM. \n\n"}
{"id": "1507.00071", "contents": "Title: Optimal time sharing in underlay cognitive radio systems with RF energy\n  harvesting Abstract: Due to the fundamental tradeoffs, achieving spectrum efficiency and energy\nefficiency are two contending design challenges for the future wireless\nnetworks. However, applying radio-frequency (RF) energy harvesting (EH) in a\ncognitive radio system could potentially circumvent this tradeoff, resulting in\na secondary system with limitless power supply and meaningful achievable\ninformation rates. This paper proposes an online solution for the optimal time\nallocation (time sharing) between the EH phase and the information transmission\n(IT) phase in an underlay cognitive radio system, which harvests the RF energy\noriginating from the primary system. The proposed online solution maximizes the\naverage achievable rate of the cognitive radio system, subject to the\n$\\varepsilon$-percentile protection criteria for the primary system. The\noptimal time sharing achieves significant gains compared to equal time\nallocation between the EH and IT phases. \n\n"}
{"id": "1507.00182", "contents": "Title: Modeling and Analysis of Content Caching in Wireless Small Cell Networks Abstract: Network densification with small cell base stations is a promising solution\nto satisfy future data traffic demands. However, increasing small cell base\nstation density alone does not ensure better users quality-of-experience and\nincurs high operational expenditures. Therefore, content caching on different\nnetwork elements has been proposed as a mean of offloading he backhaul by\ncaching strategic contents at the network edge, thereby reducing latency. In\nthis paper, we investigate cache-enabled small cells in which we model and\ncharacterize the outage probability, defined as the probability of not\nsatisfying users requests over a given coverage area. We analytically derive a\nclosed form expression of the outage probability as a function of\nsignal-to-interference ratio, cache size, small cell base station density and\nthreshold distance. By assuming the distribution of base stations as a Poisson\npoint process, we derive the probability of finding a specific content within a\nthreshold distance and the optimal small cell base station density that\nachieves a given target cache hit probability. Furthermore, simulation results\nare performed to validate the analytical model. \n\n"}
{"id": "1507.02444", "contents": "Title: Non-Asymptotic Achievable Rates for Energy-Harvesting Channels using\n  Save-and-Transmit Abstract: This paper investigates the information-theoretic limits of energy-harvesting\n(EH) channels in the finite blocklength regime. The EH process is characterized\nby a sequence of i.i.d. random variables with finite variances. We use the\nsave-and-transmit strategy proposed by Ozel and Ulukus (2012) together with\nShannon's non-asymptotic achievability bound to obtain lower bounds on the\nachievable rates for both additive white Gaussian noise channels and discrete\nmemoryless channels under EH constraints. The first-order terms of the lower\nbounds of the achievable rates are equal to $C$ and the second-order (backoff\nfrom capacity) terms are proportional to $-\\sqrt{ \\frac{\\log n}{n}}$, where $n$\ndenotes the blocklength and $C$ denotes the capacity of the EH channel, which\nis the same as the capacity without the EH constraints. The constant of\nproportionality of the backoff term is found and qualitative interpretations\nare provided. \n\n"}
{"id": "1507.02874", "contents": "Title: On the Public Communication Needed to Achieve SK Capacity in the\n  Multiterminal Source Model Abstract: The focus of this paper is on the public communication required for\ngenerating a maximal-rate secret key (SK) within the multiterminal source model\nof Csisz{\\'a}r and Narayan. Building on the prior work of Tyagi for the\ntwo-terminal scenario, we derive a lower bound on the communication complexity,\n$R_{\\text{SK}}$, defined to be the minimum rate of public communication needed\nto generate a maximal-rate SK. It is well known that the minimum rate of\ncommunication for omniscience, denoted by $R_{\\text{CO}}$, is an upper bound on\n$R_{\\text{SK}}$. For the class of pairwise independent network (PIN) models\ndefined on uniform hypergraphs, we show that a certain \"Type $\\mathcal{S}$\"\ncondition, which is verifiable in polynomial time, guarantees that our lower\nbound on $R_{\\text{SK}}$ meets the $R_{\\text{CO}}$ upper bound. Thus, PIN\nmodels satisfying our condition are $R_{\\text{SK}}$-maximal, meaning that the\nupper bound $R_{\\text{SK}} \\le R_{\\text{CO}}$ holds with equality. This allows\nus to explicitly evaluate $R_{\\text{SK}}$ for such PIN models. We also give\nseveral examples of PIN models that satisfy our Type $\\mathcal S$ condition.\nFinally, we prove that for an arbitrary multiterminal source model, a stricter\nversion of our Type $\\mathcal S$ condition implies that communication from\n\\emph{all} terminals (\"omnivocality\") is needed for establishing a SK of\nmaximum rate. For three-terminal source models, the converse is also true:\nomnivocality is needed for generating a maximal-rate SK only if the strict Type\n$\\mathcal S$ condition is satisfied. Counterexamples exist that show that the\nconverse is not true in general for source models with four or more terminals. \n\n"}
{"id": "1507.03955", "contents": "Title: Robust Estimation of Self-Exciting Generalized Linear Models with\n  Application to Neuronal Modeling Abstract: We consider the problem of estimating self-exciting generalized linear models\nfrom limited binary observations, where the history of the process serves as\nthe covariate. We analyze the performance of two classes of estimators, namely\nthe $\\ell_1$-regularized maximum likelihood and greedy estimators, for a\ncanonical self-exciting process and characterize the sampling tradeoffs\nrequired for stable recovery in the non-asymptotic regime. Our results extend\nthose of compressed sensing for linear and generalized linear models with\ni.i.d. covariates to those with highly inter-dependent covariates. We further\nprovide simulation studies as well as application to real spiking data from the\nmouse's lateral geniculate nucleus and the ferret's retinal ganglion cells\nwhich agree with our theoretical predictions. \n\n"}
{"id": "1507.05371", "contents": "Title: Regret Guarantees for Item-Item Collaborative Filtering Abstract: There is much empirical evidence that item-item collaborative filtering works\nwell in practice. Motivated to understand this, we provide a framework to\ndesign and analyze various recommendation algorithms. The setup amounts to\nonline binary matrix completion, where at each time a random user requests a\nrecommendation and the algorithm chooses an entry to reveal in the user's row.\nThe goal is to minimize regret, or equivalently to maximize the number of +1\nentries revealed at any time. We analyze an item-item collaborative filtering\nalgorithm that can achieve fundamentally better performance compared to\nuser-user collaborative filtering. The algorithm achieves good \"cold-start\"\nperformance (appropriately defined) by quickly making good recommendations to\nnew users about whom there is little information. \n\n"}
{"id": "1507.05506", "contents": "Title: Cyclic codes from the second class two-prime Whiteman's generalized\n  cyclotomic sequence with order 6 Abstract: Let $n_1=ef+1$ and $n_2=ef'+1$ be two distinct odd primes with positive\nintegers $e,\\ f,\\ f'.$ In this paper, the two-prime Whiteman's generalized\ncyclotomic sequence of order $e=6$ is employed to construct several classes of\ncyclic codes over $\\mathrm{GF}(q)$ with length $n_1n_2$. The lower bounds on\nthe minimum distance of these cyclic codes are obtained. \n\n"}
{"id": "1507.05924", "contents": "Title: Multiuser Communication through Power Talk in DC MicroGrids Abstract: Power talk is a novel concept for communication among control units in\nMicroGrids (MGs), carried out without a dedicated modem, but by using power\nelectronics that interface the common bus. The information is transmitted by\nmodulating the parameters of the primary control, incurring subtle power\ndeviations that can be detected by other units. In this paper, we develop power\ntalk communication strategies for DC MG systems with arbitrary number of\ncontrol units that carry out all-to-all communication. We investigate two\nmultiple access strategies: 1) TDMA, where only one unit transmits at a time,\nand 2) full duplex, where all units transmit and receive simultaneously. We\nintroduce the notions of signaling space, where the power talk symbol\nconstellations are constructed, and detection space, where the demodulation of\nthe symbols is performed. The proposed communication technique is challenged by\nthe random changes of the bus parameters due to load variations in the system.\nTo this end, we employ a solution based on training sequences, which\nre-establishes the signaling and detection spaces and thus enables reliable\ninformation exchange. The presented results show that power talk is an\neffective solution for reliable communication among units in DC MG systems. \n\n"}
{"id": "1507.06737", "contents": "Title: The Degrees of Freedom of the Interference Channel with a Cognitive\n  Relay under Delayed Feedback Abstract: This paper studies the interference channel with a cognitive relay (ICCR)\nunder delayed feedback. Three types of delayed feedback are studied: delayed\nchannel state information at the transmitter (CSIT), delayed output feedback,\nand delayed Shannon feedback. Outer bounds are derived for the DoF region of\nthe two-user multiple-input multiple-output (MIMO) ICCR with delayed feedback\nas well as without feedback. For the single-input single-output (SISO)\nscenario, optimal schemes are proposed based on retrospective interference\nalignment. It is shown that while a cognitive relay without feedback cannot\nextend the sum-DoF beyond $1$ in the two-user SISO interference channel,\ndelayed feedback in the same scenario can extend the sum-DoF to $4/3$. For the\nMIMO case, achievable schemes are obtained via extensions of retrospective\ninterference alignment, leading to DoF regions that meet the respective upper\nbounds. \n\n"}
{"id": "1507.08979", "contents": "Title: Tractable Resource Management with Uplink Decoupled Millimeter-Wave\n  Overlay in Ultra-Dense Cellular Networks Abstract: The forthcoming 5G cellular network is expected to overlay millimeter-wave\n(mmW) transmissions with the incumbent micro-wave ({\\mu}W) architecture. The\noverall mm-{\\mu}W resource management should therefore harmonize with each\nother. This paper aims at maximizing the overall downlink (DL) rate with a\nminimum uplink (UL) rate constraint, and concludes: mmW tends to focus more on\nDL transmissions while {\\mu}W has high priority for complementing UL, under\ntime-division duplex (TDD) mmW operations. Such UL dedication of {\\mu}W results\nfrom the limited use of mmW UL bandwidth due to excessive power consumption\nand/or high peak-to-average power ratio (PAPR) at mobile users. To further\nrelieve this UL bottleneck, we propose mmW UL decoupling that allows each\nlegacy {\\mu}W base station (BS) to receive mmW signals. Its impact on mm-{\\mu}W\nresource management is provided in a tractable way by virtue of a novel\nclosed-form mm-{\\mu}W spectral efficiency (SE) derivation. In an ultra-dense\ncellular network (UDN), our derivation verifies mmW (or {\\mu}W) SE is a\nlogarithmic function of BS-to-user density ratio. This strikingly simple yet\npractically valid analysis is enabled by exploiting stochastic geometry in\nconjunction with real three dimensional (3D) building blockage statistics in\nSeoul, Korea. \n\n"}
{"id": "1508.00168", "contents": "Title: Completion Time in Two-user Channels: An Information-Theoretic\n  Perspective Abstract: In a two-user channel, completion time refers to the number of channel uses\nspent by each user to transmit a bit pool with some given size. In this paper,\nthe information-theoretic formulation of completion time is based on the\nconcept of constrained rates, where users are allowed to employ different\nnumbers of channel uses for transmission as opposed to the equal channel use of\nthe standard information-theoretic formulation. Analogous to the capacity\nregion, the completion time region characterizes all possible trade-offs among\nusers' completion times. For a multi-access channel, it is shown that the\ncompletion time region is achieved by operating the channel in two independent\nphases: a multi-access phase when both users are transmitting, and a\npoint-to-point phase when one user has finished and the other is still\ntransmitting. Using a similar two-phase approach, the completion time region\n(or inner and outer bounds) is established for a Gaussian broadcast channel and\na Gaussian interference channel. It is observed that although consisting of two\nconvex subregions, the completion time region may not be convex in general.\nFinally an optimization problem of minimizing the weighted sum completion time\nfor a Gaussian multi-access channel and a Gaussian broadcast channel is solved,\ndemonstrating the utility of the completion time approach. \n\n"}
{"id": "1508.00522", "contents": "Title: Explicit Frames for Deterministic Phase Retrieval via PhaseLift Abstract: We explicitly give a frame of cardinality $5n-6$ such that every signal in\n$\\mathbb{C}^n$ can be recovered up to a phase from its associated intensity\nmeasurements via the PhaseLift approach. Furthermore, we give explicit linear\nmeasurements with $4r(n-r)+n-2r$ outcomes that enable the recovery of every\npositive semidefinite $n\\times n$ matrix of rank at most $r$. \n\n"}
{"id": "1508.01161", "contents": "Title: Pushing towards the Limit of Sampling Rate: Adaptive Chasing Sampling Abstract: Measurement samples are often taken in various monitoring applications. To\nreduce the sensing cost, it is desirable to achieve better sensing quality\nwhile using fewer samples. Compressive Sensing (CS) technique finds its role\nwhen the signal to be sampled meets certain sparsity requirements. In this\npaper we investigate the possibility and basic techniques that could further\nreduce the number of samples involved in conventional CS theory by exploiting\nlearning-based non-uniform adaptive sampling.\n  Based on a typical signal sensing application, we illustrate and evaluate the\nperformance of two of our algorithms, Individual Chasing and Centroid Chasing,\nfor signals of different distribution features. Our proposed learning-based\nadaptive sampling schemes complement existing efforts in CS fields and do not\ndepend on any specific signal reconstruction technique. Compared to\nconventional sparse sampling methods, the simulation results demonstrate that\nour algorithms allow $46\\%$ less number of samples for accurate signal\nreconstruction and achieve up to $57\\%$ smaller signal reconstruction error\nunder the same noise condition. \n\n"}
{"id": "1508.01842", "contents": "Title: New Guarantees for Blind Compressed Sensing Abstract: Blind Compressed Sensing (BCS) is an extension of Compressed Sensing (CS)\nwhere the optimal sparsifying dictionary is assumed to be unknown and subject\nto estimation (in addition to the CS sparse coefficients). Since the emergence\nof BCS, dictionary learning, a.k.a. sparse coding, has been studied as a matrix\nfactorization problem where its sample complexity, uniqueness and\nidentifiability have been addressed thoroughly. However, in spite of the strong\nconnections between BCS and sparse coding, recent results from the sparse\ncoding problem area have not been exploited within the context of BCS. In\nparticular, prior BCS efforts have focused on learning constrained and complete\ndictionaries that limit the scope and utility of these efforts. In this paper,\nwe develop new theoretical bounds for perfect recovery for the general\nunconstrained BCS problem. These unconstrained BCS bounds cover the case of\novercomplete dictionaries, and hence, they go well beyond the existing BCS\ntheory. Our perfect recovery results integrate the combinatorial theories of\nsparse coding with some of the recent results from low-rank matrix recovery. In\nparticular, we propose an efficient CS measurement scheme that results in\npractical recovery bounds for BCS. Moreover, we discuss the performance of BCS\nunder polynomial-time sparse coding algorithms. \n\n"}
{"id": "1508.02015", "contents": "Title: On cyclic DNA codes over the Ring $\\Z_4 + u \\Z_4$ Abstract: In this paper, we study the theory for constructing DNA cyclic codes of odd\nlength over $\\Z_4[u]/\\langle u^2 \\rangle$ which play an important role in DNA\ncomputing. Cyclic codes of odd length over $\\Z_4 + u \\Z_4$ satisfy the reverse\nconstraint and the reverse-complement constraint are studied in this paper. The\nstructure and existence of such codes are also studied. The paper concludes\nwith some DNA example obtained via the family of cyclic codes. \n\n"}
{"id": "1508.02556", "contents": "Title: Assessment of LTE Wireless Access for Monitoring of Energy Distribution\n  in the Smart Grid Abstract: While LTE is becoming widely rolled out for human-type services, it is also a\npromising solution for cost-efficient connectivity of the smart grid monitoring\nequipment. This is a type of machine-to-machine (M2M) traffic that consists\nmainly of sporadic uplink transmissions. In such a setting, the amount of\ntraffic that can be served in a cell is not constrained by the data capacity,\nbut rather by the signaling constraints in the random access channel and\ncontrol channel. In this paper we explore these limitations using a detailed\nsimulation of the LTE access reservation protocol (ARP). We find that 1)\nassigning more random access opportunities may actually worsen performance; and\n2) the additional signaling that follows the ARP has very large impact on the\ncapacity in terms of the number of supported devices; we observed a reduction\nin the capacity by almost a factor of 3. This suggests that a lightweight\naccess method, with a reduced number of signaling messages, needs to be\nconsidered in standardization for M2M applications. Additionally we propose a\ntractable analytical model to calculate the outage that can be rapidly\nimplemented and evaluated. The model accounts for the features of the random\naccess, control channel and uplink and downlink data channels, as well as\nretransmissions. \n\n"}
{"id": "1508.02820", "contents": "Title: STFT Phase Retrieval: Uniqueness Guarantees and Recovery Algorithms Abstract: The problem of recovering a signal from its Fourier magnitude is of paramount\nimportance in various fields of engineering and applied physics. Due to the\nabsence of Fourier phase information, some form of additional information is\nrequired in order to be able to uniquely, efficiently and robustly identify the\nunderlying signal. Inspired by practical methods in optical imaging, we\nconsider the problem of signal reconstruction from the Short-Time Fourier\nTransform (STFT) magnitude. We first develop conditions under which the STFT\nmagnitude is an almost surely unique signal representation. We then consider a\nsemidefinite relaxation-based algorithm (STliFT) and provide recovery\nguarantees. Numerical simulations complement our theoretical analysis and\nprovide directions for future work. \n\n"}
{"id": "1508.04030", "contents": "Title: Performance Characterization of Relay-Assisted Wireless Optical CDMA\n  Networks in Turbulent Underwater Channel Abstract: In this paper, we characterize the performance of relay-assisted underwater\nwireless optical code division multiple access (OCDMA) networks over turbulent\nchannels. In addition to scattering and absorption effects of underwater\nchannels, we also consider optical turbulence as a log-normal fading\ncoefficient in our analysis. To simultaneously and asynchronously share medium\namong many users, we assign a unique optical orthogonal code (OOC) to each user\nin order to actualize OCDMA-based underwater network. The most significant\nchallenge in underwater optical communication is in the ability to extend the\nshort range of its coverage. In order to expand the viable communication range,\nwe consider multi-hop transmission to the destination. Moreover, we evaluate\nthe performance of a relay-assisted point-to-point UWOC system as a special\ncase of the proposed relay-assisted OCDMA network. Our numerical results\nindicate significant performance improvement by employing intermediate relays,\ne.g., one can achieve $32$ {dB} improvement in the bit error rate (BER) of\n$10^{-6}$ using only a dual-hop transmission in a $90$ {m} point-to-point clear\nocean link. \n\n"}
{"id": "1508.04726", "contents": "Title: A Lower Bound on the per Soliton Capacity of the Nonlinear Optical Fibre\n  Channel Abstract: A closed-form expression for a lower bound on the per soliton capacity of the\nnonlinear optical fibre channel in the presence of (optical) amplifier\nspontaneous emission (ASE) noise is derived. This bound is based on a\nnon-Gaussian conditional probability density function for the soliton amplitude\njitter induced by the ASE noise and is proven to grow logarithmically as the\nsignal-to-noise ratio increases. \n\n"}
{"id": "1508.06381", "contents": "Title: Joint Transceiver Design Algorithms for Multiuser MISO Relay Systems\n  with Energy Harvesting Abstract: In this paper, we investigate a multiuser relay system with simultaneous\nwireless information and power transfer. Assuming that both base station (BS)\nand relay station (RS) are equipped with multiple antennas, this work studies\nthe joint transceiver design problem for the BS beamforming vectors, the RS\namplify-and-forward transformation matrix and the power splitting (PS) ratios\nat the single-antenna receivers. Firstly, an iterative algorithm based on\nalternating optimization (AO) and with guaranteed convergence is proposed to\nsuccessively optimize the transceiver coefficients. Secondly, a novel design\nscheme based on switched relaying (SR) is proposed that can significantly\nreduce the computational complexity and overhead of the AO based designs while\nmaintaining a similar performance. In the proposed SR scheme, the RS is\nequipped with a codebook of permutation matrices. For each permutation matrix,\na latent transceiver is designed which consists of BS beamforming vectors,\noptimally scaled RS permutation matrix and receiver PS ratios. For the given\nCSI, the optimal transceiver with the lowest total power consumption is\nselected for transmission. We propose a concave-convex procedure based and\nsubgradient-type iterative algorithms for the non-robust and robust latent\ntransceiver designs. Simulation results are presented to validate the\neffectiveness of all the proposed algorithms. \n\n"}
{"id": "1508.07590", "contents": "Title: New Classes of Permutation Binomials and Permutation Trinomials over\n  Finite Fields Abstract: Permutation polynomials over finite fields play important roles in finite\nfields theory. They also have wide applications in many areas of science and\nengineering such as coding theory, cryptography, combinatorial design,\ncommunication theory and so on. Permutation binomials and trinomials attract\npeople's interest due to their simple algebraic form and additional\nextraordinary properties. In this paper, several new classes of permutation\nbinomials and permutation trinomials are constructed. Some of these permutation\npolynomials are generalizations of known ones. \n\n"}
{"id": "1509.00453", "contents": "Title: PLC-to-DSL Interference: Statistical Model and Impact on DSL Abstract: Newly available standards for broadband access using Digital Subscriber Lines\n(DSL) have a high degree of spectrum overlap with home networking technologies\nusing broadband Power Line Communications (BB-PLC) and this overlap leads to\nElectromagnetic Compatibility issues that may cause performance degradation in\nDSL systems. This paper studies the characteristics of measured PLC-to-DSL\ninterference and presents novel results on its statistical characterization.\nThe frequency-dependent couplings between power line cables and twisted-pairs\nare estimated from measurements and a statistical model based on a mixture of\ntwo truncated Gaussian distributions is set forth. The proposed statistical\nmodel allows the accurate evaluation of the impact of BB-PLC interference on\nvarious DSL technologies, in terms of both average and worst-case impacts on\ndata rate. This paper further provides an extensive assessment of the impact of\nPLC-to-DSL interference at various loop lengths and for multiple profiles of\nVery-high rate Digital Subscriber Lines (VDSL2), Vectored VDSL2 (V-VDSL2), and\nG.fast. The results of this paper confirm that the impact of PLC interference\nvaries with loop length and whether vectoring is used or not. Furthermore, the\naverage impact is found to be generally small but worst-case couplings can lead\nto substantial degradation of DSL. \n\n"}
{"id": "1509.00777", "contents": "Title: A Note on the Convexity of $\\log \\det ( I + KX^{-1} )$ and its\n  Constrained Optimization Representation Abstract: This note provides another proof for the {\\em convexity} ({\\em strict\nconvexity}) of $\\log \\det ( I + KX^{-1} )$ over the positive definite cone for\nany given positive semidefinite matrix $K \\succeq 0$ (positive definite matrix\n$K \\succ 0$) and the {\\em strictly convexity} of $\\log \\det (K + X^{-1})$ over\nthe positive definite cone for any given $K \\succeq 0$. Equivalent optimization\nrepresentation with linear matrix inequalities (LMIs) for the functions $\\log\n\\det ( I + KX^{-1} )$ and $\\log \\det (K + X^{-1})$ are presented. Their\noptimization representations with LMI constraints can be particularly useful\nfor some related synthetic design problems. \n\n"}
{"id": "1509.01047", "contents": "Title: A Theory of Super-Resolution from Short-Time Fourier Transform\n  Measurements Abstract: While spike trains are obviously not band-limited, the theory of\nsuper-resolution tells us that perfect recovery of unknown spike locations and\nweights from low-pass Fourier transform measurements is possible provided that\nthe minimum spacing, $\\Delta$, between spikes is not too small. Specifically,\nfor a measurement cutoff frequency of $f_c$, Donoho [2] showed that exact\nrecovery is possible if the spikes (on $\\mathbb{R}$) lie on a lattice and\n$\\Delta > 1/f_c$, but does not specify a corresponding recovery method.\nCand$\\text{\\`e}$s and Fernandez-Granda [3, 4] provide a convex programming\nmethod for the recovery of periodic spike trains (i.e., spike trains on the\ntorus $\\mathbb{T}$), which succeeds provably if $\\Delta > 2/f_c$ and $f_c \\geq\n128$ or if $\\Delta > 1.26/f_c$ and $f_c \\geq 10^3$, and does not need the\nspikes within the fundamental period to lie on a lattice. In this paper, we\ndevelop a theory of super-resolution from short-time Fourier transform (STFT)\nmeasurements. Specifically, we present a recovery method similar in spirit to\nthe one in [3] for pure Fourier measurements. For a STFT Gaussian window\nfunction of width $\\sigma = 1/(4f_c)$ this method succeeds provably if $\\Delta\n> 1/f_c$, without restrictions on $f_c$. Our theory is based on a\nmeasure-theoretic formulation of the recovery problem, which leads to\nconsiderable generality in the sense of the results being grid-free and\napplying to spike trains on both $\\mathbb{R}$ and $\\mathbb{T}$. The case of\nspike trains on $\\mathbb{R}$ comes with significant technical challenges. For\nrecovery of spike trains on $\\mathbb{T}$ we prove that the correct solution can\nbe approximated---in weak-* topology---by solving a sequence of\nfinite-dimensional convex programming problems. \n\n"}
{"id": "1509.01187", "contents": "Title: Unmanned Aerial Vehicle with Underlaid Device-to-Device Communications:\n  Performance and Tradeoffs Abstract: In this paper, the deployment of an unmanned aerial vehicle (UAV) as a flying\nbase station used to provide on the fly wireless communications to a given\ngeographical area is analyzed. In particular, the co-existence between the UAV,\nthat is transmitting data in the downlink, and an underlaid device-todevice\n(D2D) communication network is considered. For this model, a tractable\nanalytical framework for the coverage and rate analysis is derived. Two\nscenarios are considered: a static UAV and a mobile UAV. In the first scenario,\nthe average coverage probability and the system sum-rate for the users in the\narea are derived as a function of the UAV altitude and the number of D2D users.\nIn the second scenario, using the disk covering problem, the minimum number of\nstop points that the UAV needs to visit in order to completely cover the area\nis computed. Furthermore, considering multiple retransmissions for the UAV and\nD2D users, the overall outage probability of the D2D users is derived.\nSimulation and analytical results show that, depending on the density of D2D\nusers, optimal values for the UAV altitude exist for which the system sum-rate\nand the coverage probability are maximized. Moreover, our results also show\nthat, by enabling the UAV to intelligently move over the target area, the total\nrequired transmit power of UAV while covering the entire area, is minimized.\nFinally, in order to provide a full coverage for the area of interest, the\ntradeoff between the coverage and delay, in terms of the number of stop points,\nis discussed. \n\n"}
{"id": "1509.01371", "contents": "Title: Complete Weight Enumerators of a Family of Three-Weight Linear Codes Abstract: Linear codes have been an interesting topic in both theory and practice for\nmany years. In this paper, for an odd prime $p$, we present the explicit\ncomplete weight enumerator of a family of $p$-ary linear codes constructed with\ndefining set. The weight enumerator is an mmediate result of the complete\nweight enumerator, which shows that the codes proposed in this paper are\nthree-weight linear codes. Additionally, all nonzero codewords are minimal and\nthus they are suitable for secret sharing. \n\n"}
{"id": "1509.01377", "contents": "Title: Generalized Multicast Multibeam Precoding for Satellite Communications Abstract: This paper deals with the problem of precoding in multibeam satellite\nsystems. In contrast to general multiuser multiple-input-multiple-output (MIMO)\ncellular schemes, multibeam satellite architectures suffer from different\nchallenges. First, satellite communications standards embed more than one user\nin each frame in order to increase the channel coding gain. This leads to the\ndifferent so-called multigroup multicast model, whose optimization requires\ncomputationally complex operations. Second, when the data traffic is generated\nby several Earth stations (gateways), the precoding matrix must be\ndistributively computed and attain additional payload restrictions. Third,\nsince the feedback channel is adverse (large delay and quantization errors),\nthe precoding must be able to deal with such uncertainties. In order to solve\nthe aforementioned problems, we propose a two-stage precoding design in order\nto both limit the multibeam interference and to enhance the intra-beam minimum\nuser signal power (i.e. the one that dictates the rate allocation per beam). A\nrobust version of the proposed precoder based on a first perturbation model is\npresented. This mechanism behaves well when the channel state information is\ncorrupted. Furthermore, we propose a per beam user grouping mechanism together\nwith its robust version in order to increase the precoding gain. Finally, a\nmethod for dealing with the multiple gateway architecture is presented, which\noffers high throughputs with a low inter-gateway communication. The conceived\ndesigns are evaluated in a close-to-real beam pattern and the latest broadband\ncommunication standard for satellite communications. \n\n"}
{"id": "1509.03262", "contents": "Title: A Satisfiability Modulo Theory Approach to Secure State Reconstruction\n  in Differentially Flat Systems Under Sensor Attacks Abstract: We address the problem of estimating the state of a differentially flat\nsystem from measurements that may be corrupted by an adversarial attack. In\ncyber-physical systems, malicious attacks can directly compromise the system's\nsensors or manipulate the communication between sensors and controllers. We\nconsider attacks that only corrupt a subset of sensor measurements. We show\nthat the possibility of reconstructing the state under such attacks is\ncharacterized by a suitable generalization of the notion of s-sparse\nobservability, previously introduced by some of the authors in the linear case.\nWe also extend our previous work on the use of Satisfiability Modulo Theory\nsolvers to estimate the state under sensor attacks to the context of\ndifferentially flat systems. The effectiveness of our approach is illustrated\non the problem of controlling a quadrotor under sensor attacks. \n\n"}
{"id": "1509.03411", "contents": "Title: Receiver Algorithm based on Differential Signaling for SIMO Phase Noise\n  Channels with Common and Separate Oscillator Configurations Abstract: In this paper, a receiver algorithm consisting of differential transmission\nand a two-stage detection for a single-input multiple-output (SIMO) phase-noise\nchannels is studied. Specifically, the phases of the QAM modulated data symbols\nare manipulated before transmission in order to make them more immune to the\nrandom rotational effects of phase noise. At the receiver, a two-stage detector\nis implemented, which first detects the amplitude of the transmitted symbols\nfrom a nonlinear combination of the received signal amplitudes. Then in the\nsecond stage, the detector performs phase detection. The studied signaling\nmethod does not require transmission of any known symbols that act as pilots.\nFurthermore, no phase noise estimator (or a tracker) is needed at the receiver\nto compensate the effect of phase noise. This considerably reduces the\ncomplexity of the receiver structure. Moreover, it is observed that the studied\nalgorithm can be used for the setups where a common local oscillator or\nseparate independent oscillators drive the radio-frequency circuitries\nconnected to each antenna. Due to the differential encoding/decoding of the\nphase, weighted averaging can be employed at a multi-antenna receiver, allowing\nfor phase noise suppression to leverage the large number of antennas. Hence, we\nobserve that the performance improves by increasing the number of antennas,\nespecially in the separate oscillator case. Further increasing the number of\nreceive antennas results in a performance error floor, which is a function of\nthe quality of the oscillator at the transmitter. \n\n"}
{"id": "1509.04303", "contents": "Title: Downlink Performance of Massive MIMO under General Channel Aging\n  Conditions Abstract: Massive multiple-input multiple-output (MIMO) is a promising technology\naiming at achieving high spectral efficiency by deploying a large number of\nbase station (BS) antennas using coherent combining. Channel aging due to user\nmobility is a significant degrading factor of such systems. In addition, cost\nefficiency of massive MIMO is a prerecuisite for their deployment, that leads\nto low cost antenna elements inducing high phase noise. Since phase is\ntime-dependent, it contributes to channel aging. For this reason, we present a\nnovel joint channel-phase noise model, that enables us to study the downlink of\nmassive MIMO with maximum ratio transmission (MRT) precoder under these\nconditions by means of the deterministic equivalent of the achievable sum-rate.\nAmong the noteworthy outcomes is that the degradation due to user mobility\ndominates over the effect of phase noise. Nevertheless, we demonstrate that the\njoint effects of phase noise and user mobility do not degrade the power scaling\nlaw $1/\\sqrt{M}$ ($M$ is the number of BS antennas), as has been established in\nmassive MIMO systems with imperfect channel state information. \n\n"}
{"id": "1509.04491", "contents": "Title: Sparse Multinomial Logistic Regression via Approximate Message Passing Abstract: For the problem of multi-class linear classification and feature selection,\nwe propose approximate message passing approaches to sparse multinomial\nlogistic regression (MLR). First, we propose two algorithms based on the Hybrid\nGeneralized Approximate Message Passing (HyGAMP) framework: one finds the\nmaximum a posteriori (MAP) linear classifier and the other finds an\napproximation of the test-error-rate minimizing linear classifier. Then we\ndesign computationally simplified variants of these two algorithms. Next, we\ndetail methods to tune the hyperparameters of their assumed statistical models\nusing Stein's unbiased risk estimate (SURE) and expectation-maximization (EM),\nrespectively. Finally, using both synthetic and real-world datasets, we\ndemonstrate improved error-rate and runtime performance relative to existing\nstate-of-the-art approaches to sparse MLR. \n\n"}
{"id": "1509.06611", "contents": "Title: Stochastic Content-Centric Multicast Scheduling for Cache-Enabled\n  Heterogeneous Cellular Networks Abstract: Caching at small base stations (SBSs) has demonstrated significant benefits\nin alleviating the backhaul requirement in heterogeneous cellular networks\n(HetNets). While many existing works focus on what contents to cache at each\nSBS, an equally important problem is what contents to deliver so as to satisfy\ndynamic user demands given the cache status. In this paper, we study optimal\ncontent delivery in cache-enabled HetNets by taking into account the inherent\nmulticast capability of wireless medium. We consider stochastic content\nmulticast scheduling to jointly minimize the average network delay and power\ncosts under a multiple access constraint. We establish a content-centric\nrequest queue model and formulate this stochastic optimization problem as an\ninfinite horizon average cost Markov decision process (MDP). By using\n\\emph{relative value iteration} and special properties of the request queue\ndynamics, we characterize some properties of the value function of the MDP.\nBased on these properties, we show that the optimal multicast scheduling policy\nis of threshold type. Then, we propose a structure-aware optimal algorithm to\nobtain the optimal policy. We also propose a low-complexity suboptimal policy,\nwhich possesses similar structural properties to the optimal policy, and\ndevelop a low-complexity algorithm to obtain this policy. \n\n"}
{"id": "1509.07223", "contents": "Title: Secure Transmission for Relay Wiretap Channels in the Presence of\n  Spatially Random Eavesdroppers Abstract: We propose a secure transmission scheme for a relay wiretap channel, where a\nsource communicates with a destination via a decode-and-forward relay in the\npresence of spatially random-distributed eavesdroppers. We assume that the\nsource is equipped with multiple antennas, whereas the relay, the destination,\nand the eavesdroppers are equipped with a single antenna each. In the proposed\nscheme, in addition to information signals, the source transmits artificial\nnoise signals in order to confuse the eavesdroppers. With the target of\nmaximizing the secrecy throughput of the relay wiretap channel, we derive a\nclosed-form expression for the transmission outage probability and an\neasy-to-compute expression for the secrecy outage probability. Using these\nexpressions, we determine the optimal power allocation factor and wiretap code\nrates that guarantee the maximum secrecy throughput, while satisfying a secrecy\noutage probability constraint. Furthermore, we examine the impact of source\nantenna number on the secrecy throughput, showing that adding extra transmit\nantennas at the source brings about a significant increase in the secrecy\nthroughput. \n\n"}
{"id": "1509.08667", "contents": "Title: LINOEP vectors, spiral of Theodorus, and nonlinear time-invariant system\n  models of mode decomposition Abstract: In this paper, we propose a general method to obtain a set of Linearly\nIndependent Non-Orthogonal yet Energy (square of the norm) Preserving (LINOEP)\nvectors using iterative filtering operation and we refer it as Filter Mode\nDecomposition (FDM). We show that the general energy preserving theorem (EPT),\nwhich is valid for both linearly independent (orthogonal and nonorthogonal) and\nlinearly dependent set of vectors, proposed by Singh P. et al. is a\ngeneralization of the discrete spiral of Theodorus (or square root spiral or\nEinstein spiral or Pythagorean spiral). From the EPT, we obtain the (2D)\ndiscrete spiral of Theodorus and show that the multidimensional discrete\nspirals (e.g. a 3D spiral) can be easily generated using a set of\nmultidimensional energy preserving unit vectors. We also establish that the\nrecently proposed methods (e.g. Empirical Mode Decomposition (EMD),\nSynchrosqueezed Wavelet Transforms (SSWT), Variational Mode Decomposition\n(VMD), Eigenvalue Decomposition (EVD), Fourier Decomposition Method (FDM),\netc.), for nonlinear and nonstationary time series analysis, are nonlinear\ntime-invariant (NTI) system models of filtering. Simulation and numerical\nresults demonstrate the efficacy of LINOEP vectors. \n\n"}
{"id": "1509.09222", "contents": "Title: On Jamming Against Wireless Networks Abstract: In this paper, we study jamming attacks against wireless networks.\nSpecifically, we consider a network of base stations (BS) or access points (AP)\nand investigate the impact of a fixed number of jammers that are randomly\ndeployed according to a Binomial point process. We shed light on the network\nperformance in terms of a) the outage probability and b) the error probability\nof a victim receiver in the downlink of this wireless network. We derive\nanalytical expressions for both these metrics and discuss in detail how the\njammer network must adapt to the various wireless network parameters in order\nto effectively attack the victim receivers. For instance, we will show that\nwith only 1 jammer per BS/AP a) the outage probability of the wireless network\ncan be increased from 1% (as seen in the non-jamming case) to 80% and b) when\nretransmissions are used, the jammers cause the effective network activity\nfactor (and hence the interference among the BSs) to be doubled. Furthermore,\nwe show that the behavior of the jammer network as a function of the BS/AP\ndensity is not obvious. In particular, an interesting concave-type behavior is\nseen which indicates that the number of jammers required to attack the wireless\nnetwork must scale with the BS density only until a certain value beyond which\nit decreases. In the context of error probability of the victim receiver, we\nstudy whether or not some recent results related to jamming in the\npoint-to-point link scenario can be extended to the case of jamming against\nwireless networks. Numerical results are presented to validate the theoretical\ninferences presented. \n\n"}
{"id": "1510.00059", "contents": "Title: On Remote Estimation with Multiple Communication Channels Abstract: This paper considers a sequential estimation and sensor scheduling problem in\nthe presence of multiple communication channels. As opposed to the classical\nremote estimation problem that involves one perfect (noiseless) channel and one\nextremely noisy channel (which corresponds to not transmitting the observed\nstate), a more realistic additive noise channel with fixed power constraint\nalong with a more costly perfect channel is considered. It is shown, via a\ncounter-example, that the common folklore of applying symmetric threshold\npolicy, which is well known to be optimal (for unimodal state densities) in the\nclassical two-channel remote estimation problem, can be suboptimal for the\nsetting considered. Next, in order to make the problem tractable, a side\nchannel which signals the sign of the underlying state is considered. It is\nshown that, under some technical assumptions, threshold-in-threshold\ncommunication scheduling is optimal for this setting. The impact of the\npresence of a noisy channel is analyzed numerically based on dynamic\nprogramming. This numerical analysis uncovers some rather surprising results\ninheriting known properties from the noisy and noiseless settings. \n\n"}
{"id": "1510.00297", "contents": "Title: Efficient Sampling Set Selection for Bandlimited Graph Signals Using\n  Graph Spectral Proxies Abstract: We study the problem of selecting the best sampling set for bandlimited\nreconstruction of signals on graphs. A frequency domain representation for\ngraph signals can be defined using the eigenvectors and eigenvalues of\nvariation operators that take into account the underlying graph connectivity.\nSmoothly varying signals defined on the nodes are of particular interest in\nvarious applications, and tend to be approximately bandlimited in the frequency\nbasis. Sampling theory for graph signals deals with the problem of choosing the\nbest subset of nodes for reconstructing a bandlimited signal from its samples.\nMost approaches to this problem require a computation of the frequency basis\n(i.e., the eigenvectors of the variation operator), followed by a search\nprocedure using the basis elements. This can be impractical, in terms of\nstorage and time complexity, for real datasets involving very large graphs. We\ncircumvent this issue in our formulation by introducing quantities called graph\nspectral proxies, defined using the powers of the variation operator, in order\nto approximate the spectral content of graph signals. This allows us to\nformulate a direct sampling set selection approach that does not require the\ncomputation and storage of the basis elements. We show that our approach also\nprovides stable reconstruction when the samples are noisy or when the original\nsignal is only approximately bandlimited. Furthermore, the proposed approach is\nvalid for any choice of the variation operator, thereby covering a wide range\nof graphs and applications. We demonstrate its effectiveness through various\nnumerical experiments. \n\n"}
{"id": "1510.02462", "contents": "Title: Secure State Estimation against Sensor Attacks in the Presence of Noise Abstract: We consider the problem of estimating the state of a noisy linear dynamical\nsystem when an unknown subset of sensors is arbitrarily corrupted by an\nadversary. We propose a secure state estimation algorithm, and derive (optimal)\nbounds on the achievable state estimation error given an upper bound on the\nnumber of attacked sensors. The proposed state estimator involves Kalman\nfilters operating over subsets of sensors to search for a sensor subset which\nis reliable for state estimation. To further improve the subset search time, we\npropose Satisfiability Modulo Theory based techniques to exploit the\ncombinatorial nature of searching over sensor subsets. Finally, as a result of\nindependent interest, we give a coding theoretic view of attack detection and\nstate estimation against sensor attacks in a noiseless dynamical system. \n\n"}
{"id": "1510.02956", "contents": "Title: On The Number of Optimal Linear Index Codes For Unicast Index Coding\n  Problems Abstract: An index coding problem arises when there is a single source with a number of\nmessages and multiple receivers each wanting a subset of messages and knowing a\ndifferent set of messages a priori. The noiseless Index Coding Problem is to\nidentify the minimum number of transmissions (optimal length) to be made by the\nsource through noiseless channels so that all receivers can decode their wanted\nmessages using the transmitted symbols and their respective prior information.\nRecently, it is shown that different optimal length codes perform differently\nin a noisy channel. Towards identifying the best optimal length index code one\nneeds to know the number of optimal length index codes. In this paper we\npresent results on the number of optimal length index codes making use of the\nrepresentation of an index coding problem by an equivalent network code. Our\nformulation results in matrices of smaller sizes compared to the approach of\nKotter and Medard. Our formulation leads to a lower bound on the minimum number\nof optimal length codes possible for all unicast index coding problems which is\nmet with equality for several special cases of the unicast index coding\nproblem. A method to identify the optimal length codes which lead to\nminimum-maximum probability of error is also presented. \n\n"}
{"id": "1510.03947", "contents": "Title: Distributed Linear Network Operators using Graph Filters Abstract: We study the design of graph filters to implement arbitrary linear\ntransformations between graph signals. Graph filters can be represented by\nmatrix polynomials of the graph-shift operator, which captures the structure of\nthe graph and is assumed to be given. Thus, graph-filter design consists in\nchoosing the coefficients of these polynomials (known as filter coefficients)\nto resemble desired linear transformations. Due to the local structure of the\ngraph-shift operator, graph filters can be implemented distributedly across\nnodes, making them suitable for networked settings. We determine spectral\nconditions under which a specific linear transformation can be implemented\nperfectly using graph filters. Furthermore, for the cases where perfect\nimplementation is infeasible, the design of optimal approximations for\ndifferent error metrics is analyzed. We introduce the notion of a node-variant\ngraph filter, which allows the simultaneous implementation of multiple\n(regular) graph filters in different nodes of the graph. This additional\nflexibility enables the design of more general operators without undermining\nthe locality in implementation. Perfect and approximate implementation of\nnetwork operators is also studied for node-variant graph filters. We\ndemonstrate the practical relevance of the developed framework by studying in\ndetail the application of graph filters to the problems of finite-time\nconsensus and analog network coding. Finally, we present additional numerical\nexperiments comparing the performance of node-invariant and node-variant\nfilters when approximating arbitrary linear network operators. \n\n"}
{"id": "1510.04214", "contents": "Title: LQG Control with Minimum Directed Information: Semidefinite Programming\n  Approach Abstract: We consider a discrete-time Linear-Quadratic-Gaussian (LQG) control problem\nin which Massey's directed information from the observed output of the plant to\nthe control input is minimized while required control performance is\nattainable. This problem arises in several different contexts, including joint\nencoder and controller design for data-rate minimization in networked control\nsystems. We show that the optimal control law is a Linear-Gaussian randomized\npolicy. We also identify the state space realization of the optimal policy,\nwhich can be synthesized by an efficient algorithm based on semidefinite\nprogramming. Our structural result indicates that the filter-controller\nseparation principle from the LQG control theory, and the sensor-filter\nseparation principle from the zero-delay rate-distortion theory for\nGauss-Markov sources hold simultaneously in the considered problem. A\nconnection to the data-rate theorem for mean-square stability by Nair and Evans\nis also established. \n\n"}
{"id": "1510.04467", "contents": "Title: From Microscopic Heterogeneity to Macroscopic Complexity in the\n  Contrarian Voter Model Abstract: An analytical treatment of a simple opinion model with contrarian behavior is\npresented. The focus is on the stationary dynamics of the model and in\nparticular on the effect of inhomogeneities in the interaction topology on the\nstationary behavior. We start from a micro-level Markov chain description of\nthe model. Markov chain aggregation is then used to derive a macro chain for\nthe complete graph as well as a meso-level description for the two-community\ngraph composed of two (weakly) coupled sub-communities. In both cases, a\ndetailed understanding of the model behavior is possible using Markov chain\ntools. More importantly, however, this setting provides an analytical scenario\nto study the discrepancy between the homogeneous mixing case and the model on a\nslightly more complex topology. We show that memory effects are introduced at\nthe macro level when we aggregate over agent attributes without sensitivity to\nthe microscopic details and quantify these effects using concepts from\ninformation theory. In this way, the method facilitates the analysis of the\nrelation between microscopic processes and a their aggregation to a macroscopic\nlevel of description and informs about the complexity of a system introduced by\nheterogeneous interaction relations. \n\n"}
{"id": "1510.05205", "contents": "Title: Asymptotic Scaling Laws of Wireless Adhoc Network with Physical Layer\n  Caching Abstract: We propose a physical layer (PHY) caching scheme for wireless adhoc networks.\nThe PHY caching exploits cache-assisted multihop gain and cache-induced\ndual-layer CoMP gain, which substantially improves the throughput of wireless\nadhoc networks. In particular, the PHY caching scheme contains a novel PHY\ntransmission mode called the cache-induced dual-layer CoMP which can support\nhomogeneous opportunistic CoMP in the wireless adhoc network. Compared with\ntraditional per-node throughput scaling results of\n\\Theta\\left(1/\\sqrt{N}\\right), we can achieve O(1) per node throughput for a\ncached wireless adhoc network with N nodes. Moreover, we analyze the throughput\nof the PHY caching scheme for regular wireless adhoc networks and study the\nimpact of various system parameters on the PHY caching gain. \n\n"}
{"id": "1510.05938", "contents": "Title: Ultra Dense Networks: The New Wireless Frontier for Enabling 5G Access Abstract: The extreme traffic load that future wireless networks are expected to\naccommodate requires a re-thinking of the system design. Initial estimations\nindicate that, different from the evolutionary path of previous cellular\ngenerations that was based on spectral efficiency improvements, the most\nsubstantial amount of future system performance gains will be obtained by means\nof network infrastructure densification. By increasing the density of\noperator-deployed infrastructure elements, along with incorporation of\nuser-deployed access nodes and mobile user devices acting as \"infrastructure\nprosumers\", it is expected that having one or more access nodes exclusively\ndedicated to each user will become feasible, introducing the ultra dense\nnetwork (UDN) paradigm. Although it is clear that UDNs are able to take\nadvantage of the significant benefits provided by proximal transmissions and\nincreased spatial reuse of system resources, at the same time, large node\ndensity and irregular deployment introduce new challenges, mainly due to the\ninterference environment characteristics that are vastly different from\nprevious cellular deployments. This article attempts to provide insights on\nfundamental issues related to UDN deployment, such as determining the\ninfrastructure density required to support given traffic load requirements and\nthe benefits of network-wise coordination, demonstrating the potential of UDNs\nfor 5G wireless networks. \n\n"}
{"id": "1510.07176", "contents": "Title: On the Effect of Fronthaul Latency on ARQ in C-RAN Systems Abstract: In the Cloud Radio Access Network (C-RAN) architecture, a Control Unit (CU)\nimplements the baseband processing functionalities of a cluster of Base\nStations (BSs), which are connected to it through a fronthaul network. This\narchitecture enables centralized processing at the CU, and hence the\nimplementation of enhanced interference mitigation strategies, but it also\nentails an increased decoding latency due to the transport on the fronthaul\nnetwork. The fronthaul latency may offset the benefits of centralized\nprocessing when considering the performance of protocols at layer 2 and above.\nThis letter studies the impact of fronthaul latency on the performance of\nstandard Automatic Retransmission reQuest (ARQ) protocols, namely Stop and\nWait, Go-Back-N and Selective Repeat. The performance of the C-RAN architecture\nin terms of throughput and efficiency is compared to the that of a conventional\ncellular system with local processing, as well as with that of a proposed\nhybrid C-RAN system in which BSs can perform decoding. The dynamics of the\nsystem are modeled as a multi-dimensional Markov process that includes\nsub-chains to capture the temporal correlation of interference and channel\ngains. Numerical results yield insights into the impact of system parameters\nsuch as fronthaul latency and signal-to-interference ratio on different ARQ\nprotocols. \n\n"}
{"id": "1510.07865", "contents": "Title: Optimal Caching Placement for D2D Assisted Wireless Caching Networks Abstract: In this paper, we devise the optimal caching placement to maximize the\noffloading probability for a two-tier wireless caching system, where the\nhelpers and a part of users have caching ability. The offloading comes from the\nlocal caching, D2D sharing and the helper transmission. In particular, to\nmaximize the offloading probability we reformulate the caching placement\nproblem for users and helpers into a difference of convex (DC) problem which\ncan be effectively solved by DC programming. Moreover, we analyze the two\nextreme cases where there is only help-tier caching network and only user-tier.\nSpecifically, the placement problem for the helper-tier caching network is\nreduced to a convex problem, and can be effectively solved by the classical\nwater-filling method. We notice that users and helpers prefer to cache popular\ncontents under low node density and prefer to cache different contents evenly\nunder high node density. Simulation results indicate a great performance gain\nof the proposed caching placement over existing approaches. \n\n"}
{"id": "1510.08202", "contents": "Title: Oblivious Fronthaul-Constrained Relay for a Gaussian Channel Abstract: We consider systems in which the transmitter conveys messages to the receiver\nthrough a capacity-limited relay station. The channel between the transmitter\nand the relay-station is assumed to be a frequency selective additive Gaussian\nnoise channel. It is assumed that the transmitter can shape the spectrum and\nadapt the coding technique so as to optimize performance. The relay operation\nis oblivious (nomadic transmitters), that is, the specific codebooks used are\nunknown. We find the reliable information rate that can be achieved with\nGaussian signaling in this setting, and to that end, employ Gaussian bottleneck\nresults combined with Shannon's incremental frequency approach. We also prove\nthat, unlike classical water-pouring, the allocated spectrum (power and\nbit-rate) of the optimal solution could frequently be discontinuous. These\nresults can be applied to a MIMO transmission scheme. We also investigate the\ncase of an entropy limited relay. We present lower and upper bounds on the\noptimal performance (in terms of mutual information), and derive an analytical\napproximation. \n\n"}
{"id": "1511.01017", "contents": "Title: Consistent Parameter Estimation for LASSO and Approximate Message\n  Passing Abstract: We consider the problem of recovering a vector $\\beta_o \\in \\mathbb{R}^p$\nfrom $n$ random and noisy linear observations $y= X\\beta_o + w$, where $X$ is\nthe measurement matrix and $w$ is noise. The LASSO estimate is given by the\nsolution to the optimization problem $\\hat{\\beta}_{\\lambda} = \\arg \\min_{\\beta}\n\\frac{1}{2} \\|y-X\\beta\\|_2^2 + \\lambda \\| \\beta \\|_1$. Among the iterative\nalgorithms that have been proposed for solving this optimization problem,\napproximate message passing (AMP) has attracted attention for its fast\nconvergence. Despite significant progress in the theoretical analysis of the\nestimates of LASSO and AMP, little is known about their behavior as a function\nof the regularization parameter $\\lambda$, or the thereshold parameters\n$\\tau^t$. For instance the following basic questions have not yet been studied\nin the literature: (i) How does the size of the active set\n$\\|\\hat{\\beta}^\\lambda\\|_0/p$ behave as a function of $\\lambda$? (ii) How does\nthe mean square error $\\|\\hat{\\beta}_{\\lambda} - \\beta_o\\|_2^2/p$ behave as a\nfunction of $\\lambda$? (iii) How does $\\|\\beta^t - \\beta_o \\|_2^2/p$ behave as\na function of $\\tau^1, \\ldots, \\tau^{t-1}$? Answering these questions will help\nin addressing practical challenges regarding the optimal tuning of $\\lambda$ or\n$\\tau^1, \\tau^2, \\ldots$. This paper answers these questions in the asymptotic\nsetting and shows how these results can be employed in deriving simple and\ntheoretically optimal approaches for tuning the parameters $\\tau^1, \\ldots,\n\\tau^t$ for AMP or $\\lambda$ for LASSO. It also explores the connection between\nthe optimal tuning of the parameters of AMP and the optimal tuning of LASSO. \n\n"}
{"id": "1511.01705", "contents": "Title: Partial Spread and Vectorial Generalized Bent Functions Abstract: In this paper we generalize the partial spread class and completely describe\nit for generalized Boolean functions from $\\F_2^n$ to $\\mathbb{Z}_{2^t}$.\nExplicitly, we describe gbent functions from $\\F_2^n$ to $\\mathbb{Z}_{2^t}$,\nwhich can be seen as a gbent version of Dillon's $PS_{ap}$ class. For the first\ntime, we also introduce the concept of a vectorial gbent function from $\\F_2^n$\nto $\\Z_q^m$, and determine the maximal value which $m$ can attain for the case\n$q=2^t$. Finally we point to a relation between vectorial gbent functions and\nrelative difference sets. \n\n"}
{"id": "1511.02128", "contents": "Title: Hierarchical Codebook Design for Beamforming Training in Millimeter-Wave\n  Communication Abstract: In millimeter-wave communication, large antenna arrays are required to\nachieve high power gain by steering towards each other with narrow beams, which\nposes the problem to efficiently search the best beam direction in the angle\ndomain at both Tx and Rx sides. As the exhaustive search is time consuming,\nhierarchical search has been widely accepted to reduce the complexity, and its\nperformance is highly dependent on the codebook design. In this paper, we\npropose two basic criteria for the hierarchical codebook design, and devise an\nefficient hierarchical codebook by jointly exploiting sub-array and\ndeactivation (turning-off) antenna processing techniques, where closed-form\nexpressions are provided to generate the codebook. Performance evaluations are\nconducted under different system and channel models. Results show superiority\nof the proposed codebook over the existing alternatives. \n\n"}
{"id": "1511.03937", "contents": "Title: DNA Cyclic Codes Over The Ring $ \\F_2[u,v]/\\langle u^2-1,v^3-v,uv-vu\n  \\rangle$ Abstract: In this paper, we mainly study the some structure of cyclic DNA codes of odd\nlength over the ring $R = \\F_2[u,v]/\\langle u^2-1,v^3-v,uv-vu \\rangle$ which\nplay an important role in DNA computing. We established a direct link between\nthe element of ring $R$ and 64 codons by introducing a Gray map from $R$ to\n$R_1 = F_2 + uF_2, u^2 = 1$ where $R_1$ is the ring of four elements. The\nreverse constrain and the reverse-complement constraint codes over $R$ and\n$R_1$ are studied in this paper. Binary image of the cyclic codes over R also\nstudy. The paper concludes with some example on DNA codes obtained via gray\nmap. \n\n"}
{"id": "1511.06198", "contents": "Title: Spherical Cap Packing Asymptotics and Rank-Extreme Detection Abstract: We study the spherical cap packing problem with a probabilistic approach.\nSuch probabilistic considerations result in an asymptotic sharp universal\nuniform bound on the maximal inner product between any set of unit vectors and\na stochastically independent uniformly distributed unit vector. When the set of\nunit vectors are themselves independently uniformly distributed, we further\ndevelop the extreme value distribution limit of the maximal inner product,\nwhich characterizes its uncertainty around the bound.\n  As applications of the above asymptotic results, we derive (1) an asymptotic\nsharp universal uniform bound on the maximal spurious correlation, as well as\nits uniform convergence in distribution when the explanatory variables are\nindependently Gaussian distributed; and (2) an asymptotic sharp universal bound\non the maximum norm of a low-rank elliptically distributed vector, as well as\nrelated limiting distributions. With these results, we develop a fast detection\nmethod for a low-rank structure in high-dimensional Gaussian data without using\nthe spectrum information. \n\n"}
{"id": "1511.06960", "contents": "Title: Binary Linear Locally Repairable Codes Abstract: Locally repairable codes (LRCs) are a class of codes designed for the local\ncorrection of erasures. They have received considerable attention in recent\nyears due to their applications in distributed storage. Most existing results\non LRCs do not explicitly take into consideration the field size $q$, i.e., the\nsize of the code alphabet. In particular, for the binary case, only a few\nresults are known.\n  In this work, we present an upper bound on the minimum distance $d$ of linear\nLRCs with availability, based on the work of Cadambe and Mazumdar. The bound\ntakes into account the code length $n$, dimension $k$, locality $r$,\navailability $t$, and field size $q$. Then, we study binary linear LRCs in\nthree aspects. First, we focus on analyzing the locality of some classical\ncodes, i.e., cyclic codes and Reed-Muller codes, and their modified versions,\nwhich are obtained by applying the operations of extend, shorten, expurgate,\naugment, and lengthen. Next, we construct LRCs using phantom parity-check\nsymbols and multi-level tensor product structure, respectively. Compared to\nother previous constructions of binary LRCs with fixed locality or minimum\ndistance, our construction is much more flexible in terms of code parameters,\nand gives various families of high-rate LRCs, some of which are shown to be\noptimal with respect to their minimum distance. Finally, availability of LRCs\nis studied. We investigate the locality and availability properties of several\nclasses of one-step majority-logic decodable codes, including cyclic simplex\ncodes, cyclic difference-set codes, and $4$-cycle free regular low-density\nparity-check (LDPC) codes. We also show the construction of a long LRC with\navailability from a short one-step majority-logic decodable code. \n\n"}
{"id": "1511.07539", "contents": "Title: An Efficient Multiple-Groupcast Coded Multicasting Scheme for Finite\n  Fractional Caching Abstract: Coded multicasting has been shown to improve the caching performance of\ncontent delivery networks with multiple caches downstream of a common multicast\nlink. However, the schemes that have been shown to achieve order-optimal\nperfor- mance require content items to be partitioned into a number of packets\nthat grows exponentially with the number of users [1]. In this paper, we first\nextend the analysis of the achievable scheme in [2] to the case of\nheterogeneous cache sizes and demand distribu- tions, providing an achievable\nscheme and an upper bound on the limiting average performance when the number\nof packets goes to infinity while the remaining system parameters are kept\nconstant. We then show how the scheme achieving this upper bound can very\nquickly loose its multiplicative caching gain for finite content packetization.\nTo overcome this limitation, we design a novel polynomial-time algorithm based\non greedy local graph-coloring that, while keeping the same content\npacketization, recovers a significant part of the multiplicative caching gain.\nOur results show that the achievable schemes proposed to date to quantify the\nlimiting performance, must be properly designed for practical finite system\nparameters. \n\n"}
{"id": "1511.08746", "contents": "Title: Compressed Sensing for Wireless Communications : Useful Tips and Tricks Abstract: As a paradigm to recover the sparse signal from a small set of linear\nmeasurements, compressed sensing (CS) has stimulated a great deal of interest\nin recent years. In order to apply the CS techniques to wireless communication\nsystems, there are a number of things to know and also several issues to be\nconsidered. However, it is not easy to come up with simple and easy answers to\nthe issues raised while carrying out research on CS. The main purpose of this\npaper is to provide essential knowledge and useful tips that wireless\ncommunication researchers need to know when designing CS-based wireless\nsystems. First, we present an overview of the CS technique, including basic\nsetup, sparse recovery algorithm, and performance guarantee. Then, we describe\nthree distinct subproblems of CS, viz., sparse estimation, support\nidentification, and sparse detection, with various wireless communication\napplications. We also address main issues encountered in the design of CS-based\nwireless communication systems. These include potentials and limitations of CS\ntechniques, useful tips that one should be aware of, subtle points that one\nshould pay attention to, and some prior knowledge to achieve better\nperformance. Our hope is that this article will be a useful guide for wireless\ncommunication researchers and even non-experts to grasp the gist of CS\ntechniques. \n\n"}
{"id": "1511.08957", "contents": "Title: A Novel Molecular Communication System Using Acids, Bases and Hydrogen\n  Ions Abstract: Concentration modulation, whereby information is encoded in the concentration\nlevel of chemicals, is considered. One of the main challenges with such systems\nis the limited control the transmitter has on the concentration level at the\nreceiver. For example, concentration cannot be directly decreased by the\ntransmitter, and the decrease in concentration over time occurs solely due to\ntransport mechanisms such as diffusion. This can result in inter-symbol\ninterference (ISI), which can have degrading effects on performance. In this\nwork, a new and novel scheme is proposed that uses the transmission of acids,\nbases, and the concentration of hydrogen ions for carrying information. By\nemploying this technique, the concentration of hydrogen ions at the receiver\ncan be both increased and decreased through the sender's transmissions. This\nenables novel ISI mitigation schemes as well as the possibility to form a wider\narray of signal patterns at the receiver. \n\n"}
{"id": "1512.00213", "contents": "Title: A Multi-Service Oriented Multiple-Access Scheme for Next-Generation\n  Mobile Networks Abstract: One of the key requirements for fifth-generation (5G) cellular networks is\ntheir ability to handle densely connected devices with different quality of\nservice (QoS) requirements. In this article, we present multi-service oriented\nmultiple access (MOMA), an integrated access scheme for massive connections\nwith diverse QoS profiles and/or traffic patterns originating from both\nhandheld devices and machine-to-machine (M2M) transmissions. MOMA is based on\na) stablishing separate classes of users based on relevant criteria that go\nbeyond the simple handheld/M2M split, b) class dependent hierarchical spreading\nof the data signal and c) a mix of multiuser and single-user detection schemes\nat the receiver. Practical implementations of the MOMA principle are provided\nfor base stations (BSs) that are equipped with a large number of antenna\nelements. Finally, it is shown that such a\nmassive-multiple-input-multiple-output (MIMO) scenario enables the achievement\nof all the benefits of MOMA even with a simple receiver structure that allows\nto concentrate the receiver complexity where effectively needed. \n\n"}
{"id": "1512.08309", "contents": "Title: Identifying Seizure Onset Zone from the Causal Connectivity Inferred\n  Using Directed Information Abstract: In this paper, we developed a model-based and a data-driven estimator for\ndirected information (DI) to infer the causal connectivity graph between\nelectrocorticographic (ECoG) signals recorded from brain and to identify the\nseizure onset zone (SOZ) in epileptic patients. Directed information, an\ninformation theoretic quantity, is a general metric to infer causal\nconnectivity between time-series and is not restricted to a particular class of\nmodels unlike the popular metrics based on Granger causality or transfer\nentropy. The proposed estimators are shown to be almost surely convergent.\nCausal connectivity between ECoG electrodes in five epileptic patients is\ninferred using the proposed DI estimators, after validating their performance\non simulated data. We then proposed a model-based and a data-driven SOZ\nidentification algorithm to identify SOZ from the causal connectivity inferred\nusing model-based and data-driven DI estimators respectively. The data-driven\nSOZ identification outperforms the model-based SOZ identification algorithm\nwhen benchmarked against visual analysis by neurologist, the current clinical\ngold standard. The causal connectivity analysis presented here is the first\nstep towards developing novel non-surgical treatments for epilepsy. \n\n"}
{"id": "1512.08562", "contents": "Title: Taming the Noise in Reinforcement Learning via Soft Updates Abstract: Model-free reinforcement learning algorithms, such as Q-learning, perform\npoorly in the early stages of learning in noisy environments, because much\neffort is spent unlearning biased estimates of the state-action value function.\nThe bias results from selecting, among several noisy estimates, the apparent\noptimum, which may actually be suboptimal. We propose G-learning, a new\noff-policy learning algorithm that regularizes the value estimates by\npenalizing deterministic policies in the beginning of the learning process. We\nshow that this method reduces the bias of the value-function estimation,\nleading to faster convergence to the optimal value and the optimal policy.\nMoreover, G-learning enables the natural incorporation of prior domain\nknowledge, when available. The stochastic nature of G-learning also makes it\navoid some exploration costs, a property usually attributed only to on-policy\nalgorithms. We illustrate these ideas in several examples, where G-learning\nresults in significant improvements of the convergence rate and the cost of the\nlearning process. \n\n"}
{"id": "1512.08852", "contents": "Title: Randomness: quantum versus classical Abstract: Recent tremendous development of quantum information theory led to a number\nof quantum technological projects, e.g., quantum random generators. This\ndevelopment stimulates a new wave of interest in quantum foundations. One of\nthe most intriguing problems of quantum foundations is elaboration of a\nconsistent and commonly accepted interpretation of quantum state. Closely\nrelated problem is clarification of the notion of quantum randomness and its\ninterrelation with classical randomness. In this short review we shall discuss\nbasics of classical theory of randomness (which by itself is very complex and\ncharacterized by diversity of approaches) and compare it with irreducible\nquantum randomness. The second part of this review is devoted to the\ninformation interpretation of quantum mechanics (QM) in the spirit of Zeilinger\nand Brukner (and QBism of Fuchs et al.) and physics in general (e.g., Wheeler's\n\"it from bit\") as well as digital philosophy of Chaitin (with historical\ncoupling to ideas of Leibnitz). Finally, we continue discussion on\ninterrelation of quantum and classical randomness and information\ninterpretation of QM. \n\n"}
{"id": "1601.00608", "contents": "Title: Scheduling and Power Allocation to Optimize Service and Queue-Waiting\n  Times in Cognitive Radio Uplinks Abstract: In this report, we study the packet delay as a QoS metric in CR systems. The\npacket delay includes the queue waiting time and the service time. In this\nwork, we study the effect of both the scheduling and the power allocation\nalgorithms on the delay performance of the SUs.\n  To study the delay due to the service time we study a multichannel system\nwhere the channels are sensed sequentially, we study the tradeoff between\nthroughput and delay. The problem is formulated as an optimal stopping rule\nproblem where there is a tradeoff between the service time and the throughput.\nThis tradeoff results from skipping low-quality channels to seek the\npossibility of finding high-quality ones in the future at the expense of a\nhigher probability of being blocked from transmission since these future\nchannels might be busy.\n  On the other hand, the queue waiting time is studied by considering a\nmulti-user single channel system. Specifically, we study the effect of\nscheduling and power allocation on the delay performance of all SUs in the\nsystem. We propose a delay optimal algorithm that protects the PUs from harmful\ninterference and provides the required delay guarantees to users. Conventional\nscheduling algorithms do not provide such guarantees if the interference\nchannels are heterogeneous. This is because they are developed for conventional\nnon-CR wireless systems that neglect interference since channels are\northogonal.\n  Finally, we present two potential extensions to these studied problems. \n\n"}
{"id": "1601.02284", "contents": "Title: Update or Wait: How to Keep Your Data Fresh Abstract: In this work, we study how to optimally manage the freshness of information\nupdates sent from a source node to a destination via a channel. A proper metric\nfor data freshness at the destination is the age-of-information, or simply age,\nwhich is defined as how old the freshest received update is since the moment\nthat this update was generated at the source node (e.g., a sensor). A\nreasonable update policy is the zero-wait policy, i.e., the source node submits\na fresh update once the previous update is delivered and the channel becomes\nfree, which achieves the maximum throughput and the minimum delay.\nSurprisingly, this zero-wait policy does not always minimize the age. This\ncounter-intuitive phenomenon motivates us to study how to optimally control\ninformation updates to keep the data fresh and to understand when the zero-wait\npolicy is optimal. We introduce a general age penalty function to characterize\nthe level of dissatisfaction on data staleness and formulate the average age\npenalty minimization problem as a constrained semi-Markov decision problem\n(SMDP) with an uncountable state space. We develop efficient algorithms to find\nthe optimal update policy among all causal policies, and establish sufficient\nand necessary conditions for the optimality of the zero-wait policy. Our\ninvestigation shows that the zero-wait policy is far from the optimum if (i)\nthe age penalty function grows quickly with respect to the age, (ii) the packet\ntransmission times over the channel are positively correlated over time, or\n(iii) the packet transmission times are highly random (e.g., following a\nheavy-tail distribution). \n\n"}
{"id": "1601.02864", "contents": "Title: Tables of subspace codes Abstract: One of the main problems of subspace coding asks for the maximum possible\ncardinality of a subspace code with minimum distance at least $d$ over\n$\\mathbb{F}_q^n$, where the dimensions of the codewords, which are vector\nspaces, are contained in $K\\subseteq\\{0,1,\\dots,n\\}$. In the special case of\n$K=\\{k\\}$ one speaks of constant dimension codes. Since this (still) emerging\nfield is very prosperous on the one hand side and there are a lot of\nconnections to classical objects from Galois geometry it is a bit difficult to\nkeep or to obtain an overview about the current state of knowledge. To this end\nwe have implemented an on-line database of the (at least to us) known results\nat \\url{subspacecodes.uni-bayreuth.de}. The aim of this recurrently updated\ntechnical report is to provide a user guide how this technical tool can be used\nin research projects and to describe the so far implemented theoretic and\nalgorithmic knowledge. \n\n"}
{"id": "1601.03790", "contents": "Title: Optimal Trade-offs in Multi-Processor Approximate Message Passing Abstract: We consider large-scale linear inverse problems in Bayesian settings. We\nfollow a recent line of work that applies the approximate message passing (AMP)\nframework to multi-processor (MP) computational systems, where each processor\nnode stores and processes a subset of rows of the measurement matrix along with\ncorresponding measurements. In each MP-AMP iteration, nodes of the MP system\nand its fusion center exchange lossily compressed messages pertaining to their\nestimates of the input. In this setup, we derive the optimal per-iteration\ncoding rates using dynamic programming. We analyze the excess mean squared\nerror (EMSE) beyond the minimum mean squared error (MMSE), and prove that, in\nthe limit of low EMSE, the optimal coding rates increase approximately linearly\nper iteration. Additionally, we obtain that the combined cost of computation\nand communication scales with the desired estimation quality according to\n$O(\\log^2(1/\\text{EMSE}))$. Finally, we study trade-offs between the physical\ncosts of the estimation process including computation time, communication\nloads, and the estimation quality as a multi-objective optimization problem,\nand characterize the properties of the Pareto optimal surfaces. \n\n"}
{"id": "1601.04453", "contents": "Title: Some results of linear codes over the ring\n  $\\mathbb{Z}_4+u\\mathbb{Z}_4+v\\mathbb{Z}_4+uv\\mathbb{Z}_4$ Abstract: In this paper, we mainly study the theory of linear codes over the ring $R\n=\\mathbb{Z}_4+u\\mathbb{Z}_4+v\\mathbb{Z}_4+uv\\mathbb{Z}_4$. By the Chinese\nRemainder Theorem, we have $R$ is isomorphic to the direct sum of four rings\n$\\mathbb{Z}_4$. We define a Gray map $\\Phi$ from $R^{n}$ to\n$\\mathbb{Z}_4^{4n}$, which is a distance preserving map. The Gray image of a\ncyclic code over $R^{n}$ is a linear code over $\\mathbb{Z}_4$. Furthermore, we\nstudy the MacWilliams identities of linear codes over $R$ and give the the\ngenerator polynomials of cyclic codes over $R$. Finally, we discuss some\nproperties of MDS codes over $R$. \n\n"}
{"id": "1601.05661", "contents": "Title: Distortion Bounds for Source Broadcast Problems Abstract: This paper investigates the joint source-channel coding problem of sending a\nmemoryless source over a memoryless broadcast channel. An inner bound and\nseveral outer bounds on the admissible distortion region are derived, which\nrespectively generalize and unify several existing bounds. As a consequence, we\nalso obtain an inner bound and an outer bound for the degraded broadcast\nchannel case. When specialized to the Gaussian or binary source broadcast, the\ninner bound and outer bound not only recover the best known inner bound and\nouter bound in the literature, but also generate some new results. Besides, we\nalso extend the inner bound and outer bounds to the Wyner-Ziv source broadcast\nproblem, i.e., source broadcast with side information available at decoders.\nSome new bounds are obtained when specialized to the Wyner-Ziv Gaussian and\nWyner-Ziv binary cases. \n\n"}
{"id": "1601.05690", "contents": "Title: A New Converse Bound for Coded Caching Abstract: An information-theoretic lower bound is developed for the caching system\nstudied by Maddah-Ali and Niesen. By comparing the proposed lower bound with\nthe decentralized coded caching scheme of Maddah-Ali and Niesen, the optimal\nmemory--rate tradeoff is characterized to within a multiplicative gap of $4.7$\nfor the worst case, improving the previous analytical gap of $12$. Furthermore,\nfor the case when users' requests follow the uniform distribution, the\nmultiplicative gap is tightened to $4.7$, improving the previous analytical gap\nof $72$. As an independent result of interest, for the single-user average case\nin which the user requests multiple files, it is proved that caching the most\nrequested files is optimal. \n\n"}
{"id": "1601.05793", "contents": "Title: Shift-Invariant and Sampling Spaces Associated with the Special Affine\n  Fourier Transform Abstract: The Special Affine Fourier Transformation or the SAFT generalizes a number of\nwell known unitary transformations as well as signal processing and optics\nrelated mathematical operations. Shift-invariant spaces also play an important\nrole in sampling theory, multiresolution analysis, and many other areas of\nsignal and image processing. Shannon's sampling theorem, which is at the heart\nof modern digital communications, is a special case of sampling in\nshift-invariant spaces. Furthermore, it is well known that the Poisson\nsummation formula is equivalent to the sampling theorem and that the Zak\ntransform is closely connected to the sampling theorem and the Poisson\nsummation formula. These results have been known to hold in the Fourier\ntransform domain for decades and were recently shown to hold in the Fractional\nFourier transform domain by A. Bhandari and A. Zayed.\n  The main goal of this article is to show that these results also hold true in\nthe SAFT domain. We provide a short, self-contained proof of Shannon's theorem\nfor functions bandlimited in the SAFT domain and then show that sampling in the\nSAFT domain is equivalent to orthogonal projection of functions onto a subspace\nof bandlimited basis associated with the SAFT domain. This interpretation of\nsampling leads to least-squares optimal sampling theorem. Furthermore, we show\nthat this approximation procedure is linked with convolution and semi-discrete\nconvolution operators that are associated with the SAFT domain. We conclude the\narticle with an application of fractional delay filtering of SAFT bandlimited\nfunctions. \n\n"}
{"id": "1601.06312", "contents": "Title: Channels with Synchronization/Substitution Errors and Computation of\n  Error Control Codes Abstract: We introduce the concept of an \\ff-maximal error-detecting block code, for\nsome parameter \\ff{} between 0 and 1, in order to formalize the situation where\na block code is close to maximal with respect to being error-detecting. Our\nmotivation for this is that constructing a maximal error-detecting code is a\ncomputationally hard problem. We present a randomized algorithm that takes as\ninput two positive integers $N,\\ell$, a probability value \\ff, and a\nspecification of the errors permitted in some application, and generates an\nerror-detecting, or error-correcting, block code having up to $N$ codewords of\nlength $\\ell$. If the algorithm finds less than $N$ codewords, then those\ncodewords constitute a code that is \\ff-maximal with high probability. The\nerror specification (also called channel) is modelled as a transducer, which\nallows one to model any rational combination of substitution and\nsynchronization errors. We also present some elements of our implementation of\nvarious error-detecting properties and their associated methods. Then, we show\nseveral tests of the implemented randomized algorithm on various channels. A\nmethodological contribution is the presentation of how various desirable error\ncombinations can be expressed formally and processed algorithmically. \n\n"}
{"id": "1601.06383", "contents": "Title: On Caching with More Users than Files Abstract: Caching appears to be an efficient way to reduce peak hour network traffic\ncongestion by storing some content at the user's cache without knowledge of\nlater demands. Recently, Maddah-Ali and Niesen proposed a two-phase, placement\nand delivery phase, coded caching strategy for centralized systems (where\ncoordination among users is possible in the placement phase), and for\ndecentralized systems. This paper investigates the same setup under the further\nassumption that the number of users is larger than the number of files. By\nusing the same uncoded placement strategy of Maddah-Ali and Niesen, a novel\ncoded delivery strategy is proposed to profit from the multicasting\nopportunities that arise because a file may be demanded by multiple users. The\nproposed delivery method is proved to be optimal under the constraint of\nuncoded placement for centralized systems with two files, moreover it is shown\nto outperform known caching strategies for both centralized and decentralized\nsystems. \n\n"}
{"id": "1601.06689", "contents": "Title: A class of index coding problems with rate 1/3 Abstract: An index coding problem with $n$ messages has symmetric rate $R$ if all $n$\nmessages can be conveyed at rate $R$. In a recent work, a class of index coding\nproblems for which symmetric rate $\\frac{1}{3}$ is achievable was characterised\nusing special properties of the side-information available at the receivers. In\nthis paper, we show a larger class of index coding problems (which includes the\nprevious class of problems) for which symmetric rate $\\frac{1}{3}$ is\nachievable. In the process, we also obtain a stricter necessary condition for\nrate $\\frac{1}{3}$ feasibility than what is known in literature. \n\n"}
{"id": "1601.06814", "contents": "Title: Hybrid Digital and Analog Beamforming Design for Large-Scale Antenna\n  Arrays Abstract: The potential of using of millimeter wave (mmWave) frequency for future\nwireless cellular communication systems has motivated the study of large-scale\nantenna arrays for achieving highly directional beamforming. However, the\nconventional fully digital beamforming methods which require one radio\nfrequency (RF) chain per antenna element is not viable for large-scale antenna\narrays due to the high cost and high power consumption of RF chain components\nin high frequencies. To address the challenge of this hardware limitation, this\npaper considers a hybrid beamforming architecture in which the overall\nbeamformer consists of a low-dimensional digital beamformer followed by an RF\nbeamformer implemented using analog phase shifters. Our aim is to show that\nsuch an architecture can approach the performance of a fully digital scheme\nwith much fewer number of RF chains. Specifically, this paper establishes that\nif the number of RF chains is twice the total number of data streams, the\nhybrid beamforming structure can realize any fully digital beamformer exactly,\nregardless of the number of antenna elements. For cases with fewer number of RF\nchains, this paper further considers the hybrid beamforming design problem for\nboth the transmission scenario of a point-to-point multipleinput\nmultiple-output (MIMO) system and a downlink multiuser multiple-input\nsingle-output (MU-MISO) system. For each scenario, we propose a heuristic\nhybrid beamforming design that achieves a performance close to the performance\nof the fully digital beamforming baseline. Finally, the proposed algorithms are\nmodified for the more practical setting in which only finite resolution phase\nshifters are available. Numerical simulations show that the proposed schemes\nare effective even when phase shifters with very low resolution are used. \n\n"}
{"id": "1601.07322", "contents": "Title: On Optimal Geographical Caching in Heterogeneous Cellular Networks Abstract: In this work we investigate optimal geographical caching in heterogeneous\ncellular networks where different types of base stations (BSs) have different\ncache capacities. Users request files from a content library according to a\nknown probability distribution. The performance metric is the total hit\nprobability, which is the probability that a user at an arbitrary location in\nthe plane will find the content that it requires in one of the BSs that it is\ncovered by.\n  We consider the problem of optimally placing content in all BSs jointly. As\nthis problem is not convex, we provide a heuristic scheme by finding the\noptimal placement policy for one type of base station conditioned on the\nplacement in all other types. We demonstrate that these individual optimization\nproblems are convex and we provide an analytical solution. As an illustration,\nwe find the optimal placement policy of the small base stations (SBSs)\ndepending on the placement policy of the macro base stations (MBSs). We show\nhow the hit probability evolves as the deployment density of the SBSs varies.\nWe show that the heuristic of placing the most popular content in the MBSs is\nalmost optimal after deploying the SBSs with optimal placement policies. Also,\nfor the SBSs no such heuristic can be used; the optimal placement is\nsignificantly better than storing the most popular content. Finally, we show\nthat solving the individual problems to find the optimal placement policies for\ndifferent types of BSs iteratively, namely repeatedly updating the placement\npolicies, does not improve the performance. \n\n"}
{"id": "1601.07976", "contents": "Title: Distributed Algorithms for Complete and Partial Information Games on\n  Interference Channels Abstract: We consider a Gaussian interference channel with independent direct and cross\nlink channel gains, each of which is independent and identically distributed\nacross time. Each transmitter-receiver user pair aims to maximize its long-term\naverage transmission rate subject to an average power constraint. We formulate\na stochastic game for this system in three different scenarios. First, we\nassume that each user knows all direct and cross link channel gains. Later, we\nassume that each user knows channel gains of only the links that are incident\non its receiver. Lastly, we assume that each user knows only its own direct\nlink channel gain. In all cases, we formulate the problem of finding a Nash\nequilibrium (NE) as a variational inequality (VI) problem. We present a novel\nheuristic for solving a VI. We use this heuristic to solve for a NE of power\nallocation games with partial information. We also present a lower bound on the\nutility for each user at any NE in the case of the games with partial\ninformation. We obtain this lower bound using a water-filling like power\nallocation that requires only knowledge of the distribution of a user's own\nchannel gains and average power constraints of all the users. We also provide a\ndistributed algorithm to compute Pareto optimal solutions for the proposed\ngames. Finally, we use Bayesian learning to obtain an algorithm that converges\nto an $\\epsilon$-Nash equilibrium for the incomplete information game with\ndirect link channel gain knowledge only without requiring the knowledge of the\npower policies of the other users. \n\n"}
{"id": "1602.00173", "contents": "Title: Wireless Caching: Technical Misconceptions and Business Barriers Abstract: Caching is a hot research topic and poised to develop into a key technology\nfor the upcoming 5G wireless networks. The successful implementation of caching\ntechniques however, crucially depends on joint research developments in\ndifferent scientific domains such as networking, information theory, machine\nlearning, and wireless communications. Moreover, there exist business barriers\nrelated to the complex interactions between the involved stakeholders, the\nusers, the cellular operators, and the Internet content providers. In this\narticle we discuss several technical misconceptions with the aim to uncover\nenabling research directions for caching in wireless systems. Ultimately we\nmake a speculative stakeholder analysis for wireless caching in 5G. \n\n"}
{"id": "1602.00721", "contents": "Title: Concentration of measure without independence: a unified approach via\n  the martingale method Abstract: The concentration of measure phenomenon may be summarized as follows: a\nfunction of many weakly dependent random variables that is not too sensitive to\nany of its individual arguments will tend to take values very close to its\nexpectation. This phenomenon is most completely understood when the arguments\nare mutually independent random variables, and there exist several powerful\ncomplementary methods for proving concentration inequalities, such as the\nmartingale method, the entropy method, and the method of transportation\ninequalities. The setting of dependent arguments is much less well understood.\nThis chapter focuses on the martingale method for deriving concentration\ninequalities without independence assumptions. In particular, we use the\nmachinery of so-called Wasserstein matrices to show that the Azuma-Hoeffding\nconcentration inequality for martingales with almost surely bounded\ndifferences, when applied in a sufficiently abstract setting, is powerful\nenough to recover and sharpen several known concentration results for\nnonproduct measures. Wasserstein matrices provide a natural formalism for\ncapturing the interplay between the metric and the probabilistic structures,\nwhich is fundamental to the concentration phenomenon. \n\n"}
{"id": "1602.01139", "contents": "Title: Throughput Analysis of Massive MIMO Uplink with Low-Resolution ADCs Abstract: We investigate the uplink throughput achievable by a multiple-user (MU)\nmassive multiple-input multiple-output (MIMO) system in which the base station\nis equipped with a large number of low-resolution analog-to-digital converters\n(ADCs). Our focus is on the case where neither the transmitter nor the receiver\nhave any a priori channel state information. This implies that the fading\nrealizations have to be learned through pilot transmission followed by channel\nestimation at the receiver, based on coarsely quantized observations. We\npropose a novel channel estimator, based on Bussgang's decomposition, and a\nnovel approximation to the rate achievable with finite-resolution ADCs, both\nfor the case of finite-cardinality constellations and of Gaussian inputs, that\nis accurate for a broad range of system parameters. Through numerical results,\nwe illustrate that, for the 1-bit quantized case, pilot-based channel\nestimation together with maximal-ratio combing or zero-forcing detection\nenables reliable multi-user communication with high-order constellations in\nspite of the severe nonlinearity introduced by the ADCs. Furthermore, we show\nthat the rate achievable in the infinite-resolution (no quantization) case can\nbe approached using ADCs with only a few bits of resolution. We finally\ninvestigate the robustness of low-ADC-resolution MU-MIMO uplink against receive\npower imbalances between the different users, caused for example by imperfect\npower control. \n\n"}
{"id": "1602.01409", "contents": "Title: Optimal De-Anonymization in Random Graphs with Community Structure Abstract: Anonymized social network graphs published for academic or advertisement\npurposes are subject to de-anonymization attacks by leveraging side information\nin the form of a second, public social network graph correlated with the\nanonymized graph. This is because the two are from the same underlying graph of\ntrue social relationships. In this paper, we (i) characterize the maximum a\nposteriori (MAP) estimates of user identities for the anonymized graph and (ii)\nprovide sufficient conditions for successful de-anonymization for underlying\ngraphs with community structure. Our results generalize prior work that assumed\nunderlying graphs of Erd\\H{o}s-R\\'enyi type, in addition to proving the\noptimality of the attack strategy adopted in the prior work. \n\n"}
{"id": "1602.01532", "contents": "Title: Optimal Transport Theory for Power-Efficient Deployment of Unmanned\n  Aerial Vehicles Abstract: In this paper, the optimal deployment of multiple unmanned aerial vehicles\n(UAVs) acting as flying base stations is investigated. Considering the downlink\nscenario, the goal is to minimize the total required transmit power of UAVs\nwhile satisfying the users' rate requirements. To this end, the optimal\nlocations of UAVs as well as the cell boundaries of their coverage areas are\ndetermined. To find those optimal parameters, the problem is divided into two\nsub-problems that are solved iteratively. In the first sub-problem, given the\ncell boundaries corresponding to each UAV, the optimal locations of the UAVs\nare derived using the facility location framework. In the second sub-problem,\nthe locations of UAVs are assumed to be fixed, and the optimal cell boundaries\nare obtained using tools from optimal transport theory. The analytical results\nshow that the total required transmit power is significantly reduced by\ndetermining the optimal coverage areas for UAVs. These results also show that,\nmoving the UAVs based on users' distribution, and adjusting their altitudes can\nlead to a minimum power consumption. Finally, it is shown that the proposed\ndeployment approach, can improve the system's power efficiency by a factor of\n20 compared to the classical Voronoi cell association technique with fixed UAVs\nlocations. \n\n"}
{"id": "1602.02201", "contents": "Title: The Rate-Distortion Risk in Estimation from Compressed Data Abstract: Consider the problem of estimating a latent signal from a lossy compressed\nversion of the data when the compressor is agnostic to the relation between the\nsignal and the data. This situation arises in a host of modern applications\nwhen data is transmitted or stored prior to determining the downstream\ninference task. Given a bitrate constraint and a distortion measure between the\ndata and its compressed version, let us consider the joint distribution\nachieving Shannon's rate-distortion (RD) function. Given an estimator and a\nloss function associated with the downstream inference task, define the\nrate-distortion risk as the expected loss under the RD-achieving distribution.\nWe provide general conditions under which the operational risk in estimating\nfrom the compressed data is asymptotically equivalent to the RD risk. The main\ntheoretical tools to prove this equivalence are transportation-cost\ninequalities in conjunction with properties of compression codes achieving\nShannon's RD function. Whenever such equivalence holds, a recipe for designing\nestimators from datasets undergoing lossy compression without specifying the\nactual compression technique emerges: design the estimator to minimize the RD\nrisk. Our conditions simplified in the special cases of discrete memoryless or\nmultivariate normal data. For these scenarios, we derive explicit expressions\nfor the RD risk of several estimators and compare them to the optimal source\ncoding performance associated with full knowledge of the relation between the\nlatent signal and the data. \n\n"}
{"id": "1602.03115", "contents": "Title: Towards Robustness in Residue Number Systems Abstract: The problem of robustly reconstructing a large number from its erroneous\nremainders with respect to several moduli, namely the robust remaindering\nproblem, may occur in many applications including phase unwrapping, frequency\ndetection from several undersampled waveforms, wireless sensor networks, etc.\nAssuming that the dynamic range of the large number is the maximal possible\none, i.e., the least common multiple (lcm) of all the moduli, a method called\nrobust Chinese remainder theorem (CRT) for solving the robust remaindering\nproblem has been recently proposed. In this paper, by relaxing the assumption\nthat the dynamic range is fixed to be the lcm of all the moduli, a trade-off\nbetween the dynamic range and the robustness bound for two-modular systems is\nstudied. It basically says that a decrease in the dynamic range may lead to an\nincrease of the robustness bound. We first obtain a general condition on the\nremainder errors and derive the exact dynamic range with a closed-form formula\nfor the robustness to hold. We then propose simple closed-form reconstruction\nalgorithms. Furthermore, the newly obtained two-modular results are applied to\nthe robust reconstruction for multi-modular systems and generalized to real\nnumbers. Finally, some simulations are carried out to verify our proposed\ntheoretical results. \n\n"}
{"id": "1602.03768", "contents": "Title: MISO Networks with Imperfect CSIT: A Topological Rate-Splitting Approach Abstract: Recently, the Degrees-of-Freedom (DoF) region of multiple-input-single-output\n(MISO) networks with imperfect channel state information at the transmitter\n(CSIT) has attracted significant attentions. An achievable scheme is known as\nrate-splitting (RS) that integrates common-message-multicasting and\nprivate-message-unicasting. In this paper, focusing on the general $K$-cell\nMISO IC where the CSIT of each interference link has an arbitrary quality of\nimperfectness, we firstly identify the DoF region achieved by RS. Secondly, we\nintroduce a novel scheme, so called Topological RS (TRS), whose novelties\ncompared to RS lie in a multi-layer structure and transmitting multiple common\nmessages to be decoded by groups of users rather than all users. The design of\nTRS is motivated by a novel interpretation of the $K$-cell IC with imperfect\nCSIT as a weighted-sum of a series of partially connected networks. We show\nthat the DoF region achieved by TRS covers that achieved by RS. Also, we find\nthe maximal sum DoF achieved by TRS via hypergraph fractional packing, which\nyields the best sum DoF so far. Lastly, for a realistic scenario where each\nuser is connected to three dominant transmitters, we identify the sufficient\ncondition where TRS strictly outperforms conventional schemes. \n\n"}
{"id": "1602.03954", "contents": "Title: Linear Degrees of Freedom for $K $-user MISO Interference Channels with\n  Blind Interference Alignment Abstract: In this paper, we characterize the degrees of freedom (DoF) for $K $-user $M\n\\times 1 $ multiple-input single-output interference channels with\nreconfigurable antennas which have multiple preset modes at the receivers,\nassuming linear coding strategies in the absence of channel state information\nat the transmitters, i.e., blind interference alignment. Our linear DoF\nconverse builds on the lemma that if a set of transmit symbols is aligned at\ntheir common unintended receivers, those symbols must have independent signal\nsubspace at their corresponding receivers. This lemma arises from the inherent\nfeature that channel state's changing patterns of the links towards the same\nreceiver are always identical, assuming that the coherence time of the channel\nis long enough. We derive an upper bound for the linear sum DoF, and propose an\nachievable scheme that exactly achieves the linear sum DoF upper-bound when\nboth of the $\\frac{n^{*}}{M}=R_{1} $ and $\\frac{MK}{n^{*}}=R_{2} $ are\nintegers. For the other cases, where either $R_1 $ or $R_2 $ is not an integer,\nwe only give some guidelines how the interfering signals are aligned at the\nreceivers to achieve the upper-bound. As an extension, we also show the linear\nsum DoF upper-bound for downlink/uplink cellular networks. \n\n"}
{"id": "1602.04034", "contents": "Title: On Scaling Rules for Energy of VLSI Polar Encoders and Decoders Abstract: It is shown that all polar encoding schemes of rate $R>\\frac{1}{2}$ of block\nlength $N$ implemented according to the Thompson VLSI model must take energy\n$E\\ge\\Omega\\left(N^{3/2}\\right)$. This lower bound is achievable up to\npolylogarithmic factors using a mesh network topology defined by Thompson and\nthe encoding algorithm defined by Arikan. A general class of circuits that\ncompute successive cancellation decoding adapted from Arikan's butterfly\nnetwork algorithm is defined. It is shown that such decoders implemented on a\nrectangle grid for codes of rate $R>2/3$ must take energy\n$E\\ge\\Omega(N^{3/2})$, and this can also be reached up to polylogarithmic\nfactors using a mesh network. Capacity approaching sequences of energy optimal\npolar encoders and decoders, as a function of reciprocal gap to capacity $\\chi\n= (1-R/C)^{-1}$, have energy that scales as $\\Omega\\left(\\chi^{5.325}\\right)\\le\nE \\le O\\left(\\chi^{7.05}\\log^{4}\\left(\\chi\\right)\\right)$. \n\n"}
{"id": "1602.04260", "contents": "Title: Adaptivity provably helps: information-theoretic limits on $l_0$ cost of\n  non-adaptive sensing Abstract: The advantages of adaptivity and feedback are of immense interest in signal\nprocessing and communication with many positive and negative results. Although\nit is established that adaptivity does not offer substantial reductions in\nminimax mean square error for a fixed number of measurements, existing results\nhave shown several advantages of adaptivity in complexity of reconstruction,\naccuracy of support detection, and gain in signal-to-noise ratio, under\nconstraints on sensing energy. Sensing energy has often been measured in terms\nof the Frobenius Norm of the sensing matrix. This paper uses a different metric\nthat we call the $l_0$ cost of a sensing matrix-- to quantify the complexity of\nsensing. Thus sparse sensing matrices have a lower cost. We derive\ninformation-theoretic lower bounds on the $l_0$ cost that hold for any\nnon-adaptive sensing strategy. We establish that any non-adaptive sensing\nstrategy must incur an $l_0$ cost of $\\Theta\\left( N \\log_2(N)\\right) $ to\nreconstruct an $N$-dimensional, one--sparse signal when the number of\nmeasurements are limited to $\\Theta\\left(\\log_2 (N)\\right)$. In comparison,\nbisection-type adaptive strategies only require an $l_0$ cost of at most\n$\\mathcal{O}(N)$ for an equal number of measurements. The problem has an\ninteresting interpretation as a sphere packing problem in a multidimensional\nspace, such that all the sphere centres have minimum non-zero co-ordinates. We\nalso discuss the variation in $l_0$ cost as the number of measurements increase\nfrom $\\Theta\\left(\\log_2 (N)\\right)$ to $\\Theta\\left(N\\right)$. \n\n"}
{"id": "1602.06509", "contents": "Title: Orthogonal AMP Abstract: Approximate message passing (AMP) is a low-cost iterative signal recovery\nalgorithm for linear system models. When the system transform matrix has\nindependent identically distributed (IID) Gaussian entries, the performance of\nAMP can be asymptotically characterized by a simple scalar recursion called\nstate evolution (SE). However, SE may become unreliable for other matrix\nensembles, especially for ill-conditioned ones. This imposes limits on the\napplications of AMP.\n  In this paper, we propose an orthogonal AMP (OAMP) algorithm based on\nde-correlated linear estimation (LE) and divergence-free non-linear estimation\n(NLE). The Onsager term in standard AMP vanishes as a result of the\ndivergence-free constraint on NLE. We develop an SE procedure for OAMP and show\nnumerically that the SE for OAMP is accurate for general unitarily-invariant\nmatrices, including IID Gaussian matrices and partial orthogonal matrices. We\nfurther derive optimized options for OAMP and show that the corresponding SE\nfixed point coincides with the optimal performance obtained via the replica\nmethod. Our numerical results demonstrate that OAMP can be advantageous over\nAMP, especially for ill-conditioned matrices \n\n"}
{"id": "1602.06664", "contents": "Title: A Geometric Analysis of Phase Retrieval Abstract: Can we recover a complex signal from its Fourier magnitudes? More generally,\ngiven a set of $m$ measurements, $y_k = |\\mathbf a_k^* \\mathbf x|$ for $k = 1,\n\\dots, m$, is it possible to recover $\\mathbf x \\in \\mathbb{C}^n$ (i.e.,\nlength-$n$ complex vector)? This **generalized phase retrieval** (GPR) problem\nis a fundamental task in various disciplines, and has been the subject of much\nrecent investigation. Natural nonconvex heuristics often work remarkably well\nfor GPR in practice, but lack clear theoretical explanations. In this paper, we\ntake a step towards bridging this gap. We prove that when the measurement\nvectors $\\mathbf a_k$'s are generic (i.i.d. complex Gaussian) and the number of\nmeasurements is large enough ($m \\ge C n \\log^3 n$), with high probability, a\nnatural least-squares formulation for GPR has the following benign geometric\nstructure: (1) there are no spurious local minimizers, and all global\nminimizers are equal to the target signal $\\mathbf x$, up to a global phase;\nand (2) the objective function has a negative curvature around each saddle\npoint. This structure allows a number of iterative optimization methods to\nefficiently find a global minimizer, without special initialization. To\ncorroborate the claim, we describe and analyze a second-order trust-region\nalgorithm. \n\n"}
{"id": "1602.07533", "contents": "Title: 5G 3GPP-like Channel Models for Outdoor Urban Microcellular and\n  Macrocellular Environments Abstract: For the development of new 5G systems to operate in bands up to 100 GHz,\nthere is a need for accurate radio propagation models at these bands that\ncurrently are not addressed by existing channel models developed for bands\nbelow 6 GHz. This document presents a preliminary overview of 5G channel models\nfor bands up to 100 GHz. These have been derived based on extensive measurement\nand ray tracing results across a multitude of frequencies from 6 GHz to 100\nGHz, and this document describes an initial 3D channel model which includes: 1)\ntypical deployment scenarios for urban microcells (UMi) and urban macrocells\n(UMa), and 2) a baseline model for incorporating path loss, shadow fading, line\nof sight probability, penetration and blockage models for the typical\nscenarios. Various processing methodologies such as clustering and antenna\ndecoupling algorithms are also presented. \n\n"}
{"id": "1602.08710", "contents": "Title: Dynamic Channel Access Scheme for Interference Mitigation in\n  Relay-assisted Intra-WBANs Abstract: This work addresses problems related to interference mitigation in a single\nwireless body area network (WBAN). In this paper, We propose a distributed\n\\textit{C}ombined carrier sense multiple access with collision avoidance\n(CSMA/CA) with \\textit{F}lexible time division multiple access (\\textit{T}DMA)\nscheme for \\textit{I}nterference \\textit{M}itigation in relay-assisted\nintra-WBAN, namely, CFTIM. In CFTIM scheme, non interfering sources\n(transmitters) use CSMA/CA to communicate with relays. Whilst, high interfering\nsources and best relays use flexible TDMA to communicate with coordinator (C)\nthrough using stable channels. Simulation results of the proposed scheme are\ncompared to other schemes and consequently CFTIM scheme outperforms in all\ncases. These results prove that the proposed scheme mitigates interference,\nextends WBAN energy lifetime and improves the throughput. To further reduce the\ninterference level, we analytically show that the outage probability can be\neffectively reduced to the minimal. \n\n"}
{"id": "1603.00644", "contents": "Title: A Novel Interleaving Scheme for Polar Codes Abstract: It's known that the bit errors of polar codes with successive cancellation\n(SC) decoding are coupled. We call the coupled information bits the correlated\nbits. In this paper, concatenation schemes are studied for polar codes (as\ninner codes) and LDPC codes (as outer codes). In a conventional concatenation\nscheme, to achieve a better BER performance, one can divide all $N_l$ bits in a\nLDPC block into $N_l$ polar blocks to completely de-correlate the possible\ncoupled errors. In this paper, we propose a novel interleaving scheme between a\nLDPC code and a polar code which breaks the correlation of the errors among the\ncorrelated bits. This interleaving scheme still keeps the simple SC decoding of\npolar codes while achieves a comparable BER performance at a much smaller delay\ncompared with a $N_l$-block delay scheme. \n\n"}
{"id": "1603.01566", "contents": "Title: Identifiability of an X-rank decomposition of polynomial maps Abstract: In this paper, we study a polynomial decomposition model that arises in\nproblems of system identification, signal processing and machine learning. We\nshow that this decomposition is a special case of the X-rank decomposition ---\na powerful novel concept in algebraic geometry that generalizes the tensor CP\ndecomposition. We prove new results on generic/maximal rank and on\nidentifiability of a particular polynomial decomposition model. In the paper,\nwe try to make results and basic tools accessible for general audience\n(assuming no knowledge of algebraic geometry or its prerequisites). \n\n"}
{"id": "1603.01921", "contents": "Title: Optimal Geographic Caching in Finite Wireless Networks Abstract: Cache-enabled device-to-device (D2D) networks turn memory of the devices at\nthe network edge, such as smart phones and tablets, into bandwidth by enabling\nasynchronous content sharing directly between proximate devices. Limited\nstorage capacity of the mobile devices necessitates the determination of\noptimal set of contents to be cached on each device. In order to study the\nproblem of optimal cache placement, we model the locations of devices in a\nfinite region (e.g., coffee shop, sports bar, library) as a uniform binomial\npoint process (BPP). For this setup, we first develop a generic framework to\nanalyze the coverage probability of the target receiver (target-Rx) when the\nrequested content is available at the $k^{th}$ closest device to it. Using this\ncoverage probability result, we evaluate optimal caching probability of the\npopular content to maximize the total hit probability. Our analysis concretely\ndemonstrates that optimal caching probability strongly depends on the number of\nsimultaneously active devices in the network. \n\n"}
{"id": "1603.05368", "contents": "Title: A Survey on High-Speed Railway Communications: A Radio Resource\n  Management Perspective Abstract: High-speed railway (HSR) communications will become a key feature supported\nby intelligent transportation communication systems. The increasing demand for\nHSR communications leads to significant attention on the study of radio\nresource management (RRM), which enables efficient resource utilization and\nimproved system performance. RRM design is a challenging problem due to\nheterogenous quality of service (QoS) requirements and dynamic characteristics\nof HSR wireless communications. The objective of this paper is to provide an\noverview on the key issues that arise in the RRM design for HSR wireless\ncommunications. A detailed description of HSR communication systems is first\npresented, followed by an introduction on HSR channel models and\ncharacteristics, which are vital to the cross-layer RRM design. Then we provide\na literature survey on state-of-the-art RRM schemes for HSR wireless\ncommunications, with an in-depth discussion on various RRM aspects including\nadmission control, mobility management, power control and resource allocation.\nFinally, this paper outlines the current challenges and open issues in the area\nof RRM design for HSR wireless communications. \n\n"}
{"id": "1603.06286", "contents": "Title: A Generalized LDPC Framework for Robust and Sublinear Compressive\n  Sensing Abstract: Compressive sensing aims to recover a high-dimensional sparse signal from a\nrelatively small number of measurements. In this paper, a novel design of the\nmeasurement matrix is proposed. The design is inspired by the construction of\ngeneralized low-density parity-check codes, where the capacity-achieving\npoint-to-point codes serve as subcodes to robustly estimate the signal support.\nIn the case that each entry of the $n$-dimensional $k$-sparse signal lies in a\nknown discrete alphabet, the proposed scheme requires only $O(k \\log n)$\nmeasurements and arithmetic operations. In the case of arbitrary, possibly\ncontinuous alphabet, an error propagation graph is proposed to characterize the\nresidual estimation error. With $O(k \\log^2 n)$ measurements and computational\ncomplexity, the reconstruction error can be made arbitrarily small with high\nprobability. \n\n"}
{"id": "1603.08113", "contents": "Title: Reconstructing undirected graphs from eigenspaces Abstract: In this paper, we aim at recovering an undirected weighted graph of $N$\nvertices from the knowledge of a perturbed version of the eigenspaces of its\nadjacency matrix $W$. For instance, this situation arises for stationary\nsignals on graphs or for Markov chains observed at random times. Our approach\nis based on minimizing a cost function given by the Frobenius norm of the\ncommutator $\\mathsf{A} \\mathsf{B}-\\mathsf{B} \\mathsf{A}$ between symmetric\nmatrices $\\mathsf{A}$ and $\\mathsf{B}$.\n  In the Erd\\H{o}s-R\\'enyi model with no self-loops, we show that\nidentifiability (i.e., the ability to reconstruct $W$ from the knowledge of its\neigenspaces) follows a sharp phase transition on the expected number of edges\nwith threshold function $N\\log N/2$.\n  Given an estimation of the eigenspaces based on a $n$-sample, we provide\nsupport selection procedures from theoretical and practical point of views. In\nparticular, when deleting an edge from the active support, our study unveils\nthat our test statistic is the order of $\\mathcal O(1/n)$ when we overestimate\nthe true support and lower bounded by a positive constant when the estimated\nsupport is smaller than the true support. This feature leads to a powerful\npractical support estimation procedure. Simulated and real life numerical\nexperiments assert our new methodology. \n\n"}
{"id": "1603.08236", "contents": "Title: Improving the Performance of Nested Lattice Codes Using Concatenation Abstract: A fundamental problem in coding theory is the design of an efficient coding\nscheme that achieves the capacity of the additive white Gaussian (AWGN)\nchannel. The main objective of this short note is to point out that by\nconcatenating a capacity-achieving nested lattice code with a suitable\nhigh-rate linear code over an appropriate finite field, we can achieve the\ncapacity of the AWGN channel with polynomial encoding and decoding complexity.\nSpecifically, we show that using inner Construction-A lattice codes and outer\nReed-Solomon codes, we can obtain capacity-achieving codes whose encoding and\ndecoding complexities grow as $O(N^2)$, while the probability of error decays\nexponentially in $N$, where $N$ denotes the blocklength. Replacing the outer\nReed-Solomon code by an expander code helps us further reduce the decoding\ncomplexity to $O(N\\log^2N)$. This also gives us a recipe for converting a\nhigh-complexity nested lattice code for a Gaussian channel to a low-complexity\nconcatenated code without any loss in the asymptotic rate. As examples, we\ndescribe polynomial-time coding schemes for the wiretap channel, and the\ncompute-and-forward scheme for computing integer linear combinations of\nmessages. \n\n"}
{"id": "1603.08387", "contents": "Title: Post-processing procedure for industrial quantum key distribution\n  systems Abstract: We present algorithmic solutions aimed on post-processing for industrial\nquantum key distribution systems with hardware sifting. The main steps of the\nprocedure are error correction, parameter estimation, and privacy\namplification. Authentication of a classical public communication channel is\nalso considered. \n\n"}
{"id": "1603.08578", "contents": "Title: Analysis of k-Nearest Neighbor Distances with Application to Entropy\n  Estimation Abstract: Estimating entropy and mutual information consistently is important for many\nmachine learning applications. The Kozachenko-Leonenko (KL) estimator\n(Kozachenko & Leonenko, 1987) is a widely used nonparametric estimator for the\nentropy of multivariate continuous random variables, as well as the basis of\nthe mutual information estimator of Kraskov et al. (2004), perhaps the most\nwidely used estimator of mutual information in this setting. Despite the\npractical importance of these estimators, major theoretical questions regarding\ntheir finite-sample behavior remain open. This paper proves finite-sample\nbounds on the bias and variance of the KL estimator, showing that it achieves\nthe minimax convergence rate for certain classes of smooth functions. In\nproving these bounds, we analyze finite-sample behavior of k-nearest neighbors\n(k-NN) distance statistics (on which the KL estimator is based). We derive\nconcentration inequalities for k-NN distances and a general expectation bound\nfor statistics of k-NN distances, which may be useful for other analyses of\nk-NN methods. \n\n"}
{"id": "1603.08817", "contents": "Title: Compressive Sensing Based Design of Sparse Tripole Arrays Abstract: This paper considers the problem of designing sparse linear tripole arrays.\nIn such arrays at each antenna location there are three orthogonal dipoles,\nallowing full measurement of both the horizontal and vertical components of the\nreceived waveform. We formulate this problem from the viewpoint of Compressive\nSensing (CS). However, unlike for isotropic array elements (single antenna), we\nnow have three complex valued weight coefficients associated with each\npotential location (due to the three dipoles), which have to be simultaneously\nminimised. If this is not done, we may only set the weight coefficients of\nindividual dipoles to be zero valued, rather than complete tripoles, meaning\nsome dipoles may remain at each location. Therefore, the contributions of this\npaper are to formulate the design of sparse tripole arrays as an optimisation\nproblem, and then we obtain a solution based on the minimisation of a modified\nl1 norm or a series of iteratively solved reweighted minimisations, which\nensure a truly sparse solution. Design examples are provided to verify the\neffectiveness of the proposed methods and show that a good approximation of a\nreference pattern can be achieved using fewer tripoles than a Uniform Linear\nArray (ULA) of equivalent length. \n\n"}
{"id": "1604.00565", "contents": "Title: A Statistical Block Fading Channel Model for Multiuser Massive MIMO\n  System Abstract: This paper presents a statistical block fading channel model for multiuser\nmassive MIMO system. The proposed channel model is evolved from correlation\nbased stochastic channel model (CBSCM) but in addition to the properties of\nCBSCM, it has capability of capturing channel variations along time or\nfrequency and along space simultaneously. It has a simplified analytical\nexpression, still being able to simulate underlying physical phenomena which\notherwise need a complex geometry based stochastic channel model (GBSCM). The\nchannel model is verified with reported measurement data of channel for massive\nMIMO. Spatial determinism in channel, the basic cause of unfavorable\npropagation, is modeled into controlling parameters of channel model. Channel\nmodel uses only three controlling parameters; one parameter describes variation\nin channel along resource block (along time or frequency) and remaining two\nparameters describe spatial variation in channel. Modeling of simultaneous\nvariation along time and space belongs to a very common scenario where mobility\nof mobile terminal and angular power distribution at base station receiver, are\nkey parameters. Additionally, simulation results reveal the hidden advantages\nof spatial determinism in channel for multiuser massive MIMO. \n\n"}
{"id": "1604.00635", "contents": "Title: Quantum-inspired secure wireless communication protocol under spatial\n  and local Gaussian noise assumptions Abstract: Inspired from quantum key distribution, we consider wireless communication\nbetween Alice and Bob when the intermediate space between Alice and Bob is\ncontrolled by Eve. That is, our model divides the channel noise into two parts,\nthe noise generated during the transmission and the noise generated in the\ndetector. Eve is allowed to control the former, but is not allowed to do the\nlatter. While the latter is assumed to be a Gaussian random variable, the\nformer is not assumed to be a Gaussian random variable. In this situation,\nusing backward reconciliation and the random sampling, we propose a protocol to\ngenerate secure keys between Alice and Bob under the assumption that Eve's\ndetector has a Gaussian noise and Eve is out of Alice's neighborhood. In our\nprotocol, the security criteria are quantitatively guaranteed even with finite\nblock-length code based on the evaluation of error of the estimation of\nchannel. \n\n"}
{"id": "1604.00700", "contents": "Title: From compressed sensing to compressed bit-streams: practical encoders,\n  tractable decoders Abstract: Compressed sensing is now established as an effective method for dimension\nreduction when the underlying signals are sparse or compressible with respect\nto some suitable basis or frame. One important, yet under-addressed problem\nregarding the compressive acquisition of analog signals is how to perform\nquantization. This is directly related to the important issues of how\n\"compressed\" compressed sensing is (in terms of the total number of bits one\nends up using after acquiring the signal) and ultimately whether compressed\nsensing can be used to obtain compressed representations of suitable signals.\nBuilding on our recent work, we propose a concrete and practicable method for\nperforming \"analog-to-information conversion\". Following a compressive signal\nacquisition stage, the proposed method consists of a quantization stage, based\non $\\Sigma\\Delta$ (sigma-delta) quantization, and a subsequent encoding\n(compression) stage that fits within the framework of compressed sensing\nseamlessly. We prove that, using this method, we can convert analog compressive\nsamples to compressed digital bitstreams and decode using tractable algorithms\nbased on convex optimization. We prove that the proposed AIC provides a nearly\noptimal encoding of sparse and compressible signals. Finally, we present\nnumerical experiments illustrating the effectiveness of the proposed\nanalog-to-information converter. \n\n"}
{"id": "1604.02333", "contents": "Title: Information Theoretic Caching: The Multi-User Case Abstract: In this paper, we consider a cache aided network in which each user is\nassumed to have individual caches, while upon users' requests, an update\nmessage is sent though a common link to all users. First, we formulate a\ngeneral information theoretic setting that represents the database as a\ndiscrete memoryless source, and the users' requests as side information that is\navailable everywhere except at the cache encoder. The decoders' objective is to\nrecover a function of the source and the side information. By viewing cache\naided networks in terms of a general distributed source coding problem and\nthrough information theoretic arguments, we present inner and outer bounds on\nthe fundamental tradeoff of cache memory size and update rate. Then, we\nspecialize our general inner and outer bounds to a specific model of content\ndelivery networks: File selection networks, in which the database is a\ncollection of independent equal-size files and each user requests one of the\nfiles independently. For file selection networks, we provide an outer bound and\ntwo inner bounds (for centralized and decentralized caching strategies). For\nthe case when the user request information is uniformly distributed, we\ncharacterize the rate vs. cache size tradeoff to within a multiplicative gap of\n4. By further extending our arguments to the framework of Maddah-Ali and\nNiesen, we also establish a new outer bound and two new inner bounds in which\nit is shown to recover the centralized and decentralized strategies, previously\nestablished by Maddah-Ali and Niesen. Finally, in terms of rate vs. cache size\ntradeoff, we improve the previous multiplicative gap of 72 to 4.7 for the\naverage case with uniform requests. \n\n"}
{"id": "1604.02380", "contents": "Title: Group secret key agreement over state-dependent wireless broadcast\n  channels Abstract: We consider a group of $m$ trusted and authenticated nodes that aim to create\na shared secret key $K$ over a wireless channel in the presence of an\neavesdropper Eve. We assume that there exists a state dependent wireless\nbroadcast channel from one of the honest nodes to the rest of them including\nEve. All of the trusted nodes can also discuss over a cost-free, noiseless and\nunlimited rate public channel which is also overheard by Eve. For this setup,\nwe develop an information-theoretically secure secret key agreement protocol.\nWe show the optimality of this protocol for \"linear deterministic\" wireless\nbroadcast channels. This model generalizes the packet erasure model studied in\nliterature for wireless broadcast channels. For \"state-dependent Gaussian\"\nwireless broadcast channels, we propose an achievability scheme based on a\nmulti-layer wiretap code. Finding the best achievable secret key generation\nrate leads to solving a non-convex power allocation problem. We show that using\na dynamic programming algorithm, one can obtain the best power allocation for\nthis problem. Moreover, we prove the optimality of the proposed achievability\nscheme for the regime of high-SNR and large-dynamic range over the channel\nstates in the (generalized) degrees of freedom sense. \n\n"}
{"id": "1604.03089", "contents": "Title: Different quantum f-divergences and the reversibility of quantum\n  operations Abstract: The concept of classical $f$-divergences gives a unified framework to\nconstruct and study measures of dissimilarity of probability distributions;\nspecial cases include the relative entropy and the R\\'enyi divergences. Various\nquantum versions of this concept, and more narrowly, the concept of R\\'enyi\ndivergences, have been introduced in the literature with applications in\nquantum information theory; most notably Petz' quasi-entropies (standard\n$f$-divergences), Matsumoto's maximal $f$-divergences, measured\n$f$-divergences, and sandwiched and $\\alpha$-$z$-R\\'enyi divergences.\n  In this paper we give a systematic overview of the various concepts of\nquantum $f$-divergences with a main focus on their monotonicity under quantum\noperations, and the implications of the preservation of a quantum\n$f$-divergence by a quantum operation. In particular, we compare the standard\nand the maximal $f$-divergences regarding their ability to detect the\nreversibility of quantum operations. We also show that these two quantum\n$f$-divergences are strictly different for non-commuting operators unless $f$\nis a polynomial, and obtain some analogous partial results for the relation\nbetween the measured and the standard $f$-divergences.\n  We also study the monotonicity of the $\\alpha$-$z$-R\\'enyi divergences under\nthe special class of bistochastic maps that leave one of the arguments of the\nR\\'enyi divergence invariant, and determine domains of the parameters\n$\\alpha,z$ where monotonicity holds, and where the preservation of the\n$\\alpha$-$z$-R\\'enyi divergence implies the reversibility of the quantum\noperation. \n\n"}
{"id": "1604.03204", "contents": "Title: Distributed Index Coding Abstract: In this paper, we study the capacity region of the general distributed index\ncoding. In contrast to the traditional centralized index coding where a single\nserver contains all $n$ messages requested by the receivers, in the distributed\nindex coding there are $2^n-1$ servers, each containing a unique non-empty\nsubset $J$ of the messages and each is connected to all receivers via a\nnoiseless independent broadcast link with an arbitrary capacity $C_J \\ge 0$.\nFirst, we generalize the existing polymatroidal outer bound on the capacity\nregion of the centralized problem to the distributed case. Next, building upon\nthe existing centralized composite coding scheme, we propose three distributed\ncomposite coding schemes and derive the corresponding inner bounds on the\ncapacity region. We present a number of interesting numerical examples, which\nhighlight the subtleties and challenges of dealing with the distributed index\ncoding, even for very small problem sizes of $n=3$ and $n=4$. \n\n"}
{"id": "1604.03888", "contents": "Title: Fundamental Limits of Coded Caching: Improved Delivery Rate-Cache\n  Capacity Trade-off Abstract: A centralized coded caching system, consisting of a server delivering N\npopular files, each of size F bits, to K users through an error-free shared\nlink, is considered. It is assumed that each user is equipped with a local\ncache memory with capacity MF bits, and contents can be proactively cached into\nthese caches over a low traffic period; however, without the knowledge of the\nuser demands. During the peak traffic period each user requests a single file\nfrom the server. The goal is to minimize the number of bits delivered by the\nserver over the shared link, known as the delivery rate, over all user demand\ncombinations. A novel coded caching scheme for the cache capacity of M= (N-1)/K\nis proposed. It is shown that the proposed scheme achieves a smaller delivery\nrate than the existing coded caching schemes in the literature when K > N >= 3.\nFurthermore, we argue that the delivery rate of the proposed scheme is within a\nconstant multiplicative factor of 2 of the optimal delivery rate for cache\ncapacities 1/K <= M <= (N-1)/K, when K > N >= 3. \n\n"}
{"id": "1604.04826", "contents": "Title: On the Non-existence of certain classes of generalized bent functions Abstract: We obtain new non-existence results of generalized bent functions from\n\\ZZ^n_q to \\ZZ_q (called type [n,q]). The first case is a class of types where\nq=2p_1^{r_1}p_2^{r_2}. The second case contains two types [1 <= n <= 3, 2 *\n31^e]$ and [1 <= n <= 7,2 * 151^e]. \n\n"}
{"id": "1604.05622", "contents": "Title: Understanding Noise and Interference Regimes in 5G Millimeter-Wave\n  Cellular Networks Abstract: With the severe spectrum shortage in conventional cellular bands,\nmillimeter-wave (mmWave) frequencies have been attracting growing attention for\nnext-generation micro- and picocellular wireless networks. A fundamental and\nopen question is whether mmWave cellular networks are likely to be noise- or\ninterference-limited. Identifying in which regime a network is operating is\ncritical for the design of MAC and physical-layer procedures and to provide\ninsights on how transmissions across cells should be coordinated to cope with\ninterference. This work uses the latest measurement-based statistical channel\nmodels to accurately assess the Interference-to-Noise Ratio (INR) in a wide\nrange of deployment scenarios. In addition to cell density, we also study\nantenna array size and antenna patterns, whose effects are critical in the\nmmWave regime. The channel models also account for blockage, line-of-sight and\nnon-line-of-sight regimes as well as local scattering, that significantly\naffect the level of spatial isolation. \n\n"}
{"id": "1604.06553", "contents": "Title: Density Evolution for Deterministic Generalized Product Codes with\n  Higher-Order Modulation Abstract: Generalized product codes (GPCs) are extensions of product codes (PCs) where\ncoded bits are protected by two component codes but not necessarily arranged in\na rectangular array. It has recently been shown that there exists a large class\nof deterministic GPCs (including, e.g., irregular PCs, half-product codes,\nstaircase codes, and certain braided codes) for which the asymptotic\nperformance under iterative bounded-distance decoding over the binary erasure\nchannel (BEC) can be rigorously characterized in terms of a density evolution\nanalysis. In this paper, the analysis is extended to the case where\ntransmission takes place over parallel BECs with different erasure\nprobabilities. We use this model to predict the code performance in a coded\nmodulation setup with higher-order signal constellations. We also discuss the\ndesign of the bit mapper that determines the allocation of the coded bits to\nthe modulation bits of the signal constellation. \n\n"}
{"id": "1604.07918", "contents": "Title: Fundamental Green Tradeoffs: Progresses, Challenges, and Impacts on 5G\n  Networks Abstract: With years of tremendous traffic and energy consumption growth, green radio\nhas been valued not only for theoretical research interests but also for the\noperational expenditure reduction and the sustainable development of wireless\ncommunications. Fundamental green tradeoffs, served as an important framework\nfor analysis, include four basic relationships: spectrum efficiency (SE) versus\nenergy efficiency (EE), deployment efficiency (DE) versus energy efficiency\n(EE), delay (DL) versus power (PW), and bandwidth (BW) versus power (PW). In\nthis paper, we first provide a comprehensive overview on the extensive on-going\nresearch efforts and categorize them based on the fundamental green tradeoffs.\nWe will then focus on research progresses of 4G and 5G communications, such as\northogonal frequency division multiplexing (OFDM) and non-orthogonal\naggregation (NOA), multiple input multiple output (MIMO), and heterogeneous\nnetworks (HetNets). We will also discuss potential challenges and impacts of\nfundamental green tradeoffs, to shed some light on the energy efficient\nresearch and design for future wireless networks. \n\n"}
{"id": "1604.07974", "contents": "Title: Non-convexity of private capacity and classical environment-assisted\n  capacity of a quantum channel Abstract: The capacity of classical channels is convex. This is not the case for the\nquantum capacity of a channel: the capacity of a mixture of different quantum\nchannels exceeds the mixture of the individual capacities and thus is\nnon-convex. Here we show that this effect goes beyond the quantum capacity and\nholds for the private and classical environment-assisted capacities of quantum\nchannels. \n\n"}
{"id": "1605.00322", "contents": "Title: Adaptive Modulation in Network-coded Two-way Relay Channel: A\n  Supermodular Game Approach Abstract: We study the adaptive modulation (AM) problem in a network-coded two-way\nrelay channel (NC-TWRC), where each of the two users controls its own bit rate\nin the $m$-ary quadrature amplitude modulation ($m$-QAM) to minimize the\ntransmission error rate and enhance the spectral efficiency. We show that there\nexists a strategic complementarity, one user tends to transmit while the other\ndecides to do so in order to enhance the overall spectral efficiency, which is\nbeyond the scope of the conventional single-agent AM scheduling method. We\npropose a two-player game model parameterized by the signal-to-noise ratios\n(SNRs) of two user-to-user channels and prove that it is a supermodular game\nwhere there always exist the extremal pure strategy Nash equilibria (PSNEs),\nthe largest and smallest PSNEs. We show by simulation results that the extremal\nPSNEs incur a similar bit error rate (BER) as the conventional single-agent AM\nscheme, but significantly improve the spectral efficiency in the NC-TWRC\nsystem. The study also reveals the Pareto order of the extremal PSNEs: The\nlargest and smallest PSNEs are Pareto worst and best PSNEs, respectively.\nFinally, we derive the sufficient conditions for the extremal PSNEs to be\nsymmetric and monotonic in channel SNRs. We also discuss how to utilize the\nsymmetry and monotonicity to relieve the complexity in the PSNE learning\nprocess. \n\n"}
{"id": "1605.01211", "contents": "Title: An Upper Bound for the Capacity of Amplitude-Constrained Scalar AWGN\n  Channel Abstract: This paper slightly improves the upper bound in Thangaraj et al. for the\ncapacity of the amplitude-constrained scalar AWGN channel. This improvement\nmakes the upper bound within 0.002 bits of the capacity for\n$\\frac{E_b}{N_0}\\leq 2.5$ dB. \n\n"}
{"id": "1605.01690", "contents": "Title: Fog-Aided Wireless Networks for Content Delivery: Fundamental Latency\n  Trade-Offs Abstract: A fog-aided wireless network architecture is studied in which edge-nodes\n(ENs), such as base stations, are connected to a cloud processor via dedicated\nfronthaul links, while also being endowed with caches. Cloud processing enables\nthe centralized implementation of cooperative transmission strategies at the\nENs, albeit at the cost of an increased latency due to fronthaul transfer. In\ncontrast, the proactive caching of popular content at the ENs allows for the\nlow-latency delivery of the cached files, but with generally limited\nopportunities for cooperative transmission among the ENs. The interplay between\ncloud processing and edge caching is addressed from an information-theoretic\nviewpoint by investigating the fundamental limits of a high\nSignal-to-Noise-Ratio (SNR) metric, termed normalized delivery time (NDT),\nwhich captures the worst-case coding latency for delivering any requested\ncontent to the users. The NDT is defined under the assumptions of either serial\nor pipelined fronthaul-edge transmission, and is studied as a function of\nfronthaul and cache capacity constraints. Placement and delivery strategies\nacross both fronthaul and wireless, or edge, segments are proposed with the aim\nof minimizing the NDT. Information-theoretic lower bounds on the NDT are also\nderived. Achievability arguments and lower bounds are leveraged to characterize\nthe minimal NDT in a number of important special cases, including systems with\nno caching capabilities, as well as to prove that the proposed schemes achieve\noptimality within a constant multiplicative factor of 2 for all values of the\nproblem parameters. \n\n"}
{"id": "1605.01930", "contents": "Title: Context Information Based Initial Cell Search for Millimeter Wave 5G\n  Cellular Networks Abstract: Millimeter wave (mmWave) communication is envisioned as a cornerstone to\nfulfill the data rate requirements for fifth generation (5G) cellular networks.\nIn mmWave communication, beamforming is considered as a key technology to\ncombat the high path-loss, and unlike in conventional microwave communication,\nbeamforming may be necessary even during initial access/cell search. Among the\nproposed beamforming schemes for initial cell search, analog beamforming is a\npower efficient approach but suffers from its inherent search delay during\ninitial access. In this work, we argue that analog beamforming can still be a\nviable choice when context information about mmWave base stations (BS) is\navailable at the mobile station (MS). We then study how the performance of\nanalog beamforming degrades in case of angular errors in the available context\ninformation. Finally, we present an analog beamforming receiver architecture\nthat uses multiple arrays of Phase Shifters and a single RF chain to combat the\neffect of angular errors, showing that it can achieve the same performance as\nhybrid beamforming. \n\n"}
{"id": "1605.02175", "contents": "Title: Asymptotics of Input-Constrained Erasure Channel Capacity Abstract: In this paper, we examine an input-constrained erasure channel and we\ncharacterize the asymptotics of its capacity when the erasure rate is low. More\nspecifically, for a general memoryless erasure channel with its input supported\non an irreducible finite-type constraint, we derive partial asymptotics of its\ncapacity, using some series expansion type formulas of its mutual information\nrate; and for a binary erasure channel with its first-order Markovian input\nsupported on the $(1, \\infty)$-RLL constraint, based on the concavity of its\nmutual information rate with respect to some parameterization of the input, we\nnumerically evaluate its first-order Markov capacity and further derive its\nfull asymptotics. The asymptotics obtained in this paper, when compared with\nthe recently derived feedback capacity for a binary erasure channel with the\nsame input constraint, enable us to draw the conclusion that feedback may\nincrease the capacity of an input-constrained channel, even if the channel is\nmemoryless. \n\n"}
{"id": "1605.02238", "contents": "Title: Latency Analysis of Systems with Multiple Interfaces for Ultra-Reliable\n  M2M Communication Abstract: One of the ways to satisfy the requirements of ultra-reliable low latency\ncommunication for mission critical Machine-type Communications (MTC)\napplications is to integrate multiple communication interfaces. In order to\nestimate the performance in terms of latency and reliability of such an\nintegrated communication system, we propose an analysis framework that combines\ntraditional reliability models with technology-specific latency probability\ndistributions. In our proposed model we demonstrate how failure correlation\nbetween technologies can be taken into account. We show for the considered\nscenario with fiber and different cellular technologies how up to 5-nines\nreliability can be achieved and how packet splitting can be used to reduce\nlatency substantially while keeping 4-nines reliability. The model has been\nvalidated through simulation. \n\n"}
{"id": "1605.02894", "contents": "Title: Sharp Sufficient Conditions for Stable Recovery of Block Sparse Signals\n  by Block Orthogonal Matching Pursuit Abstract: In this paper, we use the block orthogonal matching pursuit (BOMP) algorithm\nto recover block sparse signals $\\x$ from measurements $\\y=\\A\\x+\\v$, where $\\v$\nis an $\\ell_2$-bounded noise vector (i.e., $\\|\\v\\|_2\\leq \\epsilon$ for some\nconstant $\\epsilon$). We investigate some sufficient conditions based on the\nblock restricted isometry property (block-RIP) for exact (when $\\v=\\0$) and\nstable (when $\\v\\neq\\0$) recovery of block sparse signals $\\x$. First, on the\none hand, we show that if $\\A$ satisfies the block-RIP with\n$\\delta_{K+1}<1/\\sqrt{K+1}$, then every block $K$-sparse signal $\\x$ can be\nexactly or stably recovered by BOMP in $K$ iterations. On the other hand, we\nshow that, for any $K\\geq 1$ and $1/\\sqrt{K+1}\\leq \\delta<1$, there exists a\nmatrix $\\A$ satisfying the block-RIP with $\\delta_{K+1}=\\delta$ and a block\n$K$-sparse signal $\\x$ such that BOMP may fail to recover $\\x$ in $K$\niterations. Then, we study some sufficient conditions for recovering block\n$\\alpha$-strongly-decaying $K$-sparse signals. We show that if $\\A$ satisfies\nthe block-RIP with $\\delta_{K+1}<\\sqrt{2}/2$, then every\n$\\alpha$-strongly-decaying block $K$-sparse signal can be exactly or stably\nrecovered by BOMP in $K$ iterations under some conditions on $\\alpha$. Our\nnewly found sufficient condition on the block-RIP of $\\A$ is less restrictive\nthan that for $\\ell_1$ minimization for this special class of sparse signals.\nFurthermore, for any $K\\geq 1$, $\\alpha>1$ and $\\sqrt{2}/2\\leq \\delta<1$, the\nrecovery of $\\x$ may fail in $K$ iterations for a sensing matrix $\\A$ which\nsatisfies the block-RIP with $\\delta_{K+1}=\\delta$. Finally, we study some\nsufficient conditions for partial recovery of block sparse signals.\nSpecifically, if $\\A$ satisfies the block-RIP with $\\delta_{K+1}<\\sqrt{2}/2$,\nthen BOMP is guaranteed to recover some blocks of $\\x$ if these blocks satisfy\na sufficient condition. \n\n"}
{"id": "1605.02928", "contents": "Title: Achievable Degrees of Freedom of the K-user MISO Broadcast Channel with\n  Alternating CSIT via Interference Creation-Resurrection Abstract: Channel state information at the transmitter affects the degrees of freedom\nof the wireless networks. In this paper, we analyze the DoF for the K-user\nmultiple-input single-output (MISO) broadcast channel (BC) with synergistic\nalternating channel state information at the transmitter (CSIT). Specifically,\nthe CSIT of each user alternates between three states, namely, perfect CSIT\n(P), delayed CSIT (D) and no CSIT (N) among different time slots. For the\nK-user MISO BC, we show that the total achievable degrees of freedom (DoF) are\ngiven by $\\frac{K^{2}}{2K-1}$ through utilizing the synergistic benefits of\nCSIT patterns. We compare the achievable DoF with results reported previously\nin the literature in the case of delayed CSIT and hybrid CSIT models. \n\n"}
{"id": "1605.05862", "contents": "Title: Coded Pilot Access: A Random Access Solution for Massive MIMO Systems Abstract: We present a novel access protocol for crowd scenarios in massive MIMO\n(Multiple-input multiple-output) systems. Crowd scenarios are characterized by\na large number of users with intermittent access behavior, whereby orthogonal\nscheduling is infeasible. In such scenarios, random access is a natural choice.\nThe proposed access protocol relies on two essential properties of a massive\nMIMO system, namely asymptotic orthogonality between user channels and\nasymptotic invariance of channel powers. Signal processing techniques that take\nadvantage of these properties allow us to view a set of contaminated pilot\nsignals as a graph code on which iterative belief propagation can be performed.\nThis makes it possible to decontaminate pilot signals and increase the\nthroughput of the system. Numerical evaluations show that the proposed access\nprotocol increases the throughput with 36%, when having 400 antennas at the\nbase station, compared to the conventional method of slotted ALOHA. With 1024\nantennas, the throughput is increased by 85%. \n\n"}
{"id": "1605.06096", "contents": "Title: Consensus+Innovations Distributed Kalman Filter with Optimized Gains Abstract: In this paper, we address the distributed filtering and prediction of\ntime-varying random fields represented by linear time-invariant (LTI) dynamical\nsystems. The field is observed by a sparsely connected network of\nagents/sensors collaborating among themselves. We develop a Kalman filter type\nconsensus+innovations distributed linear estimator of the dynamic field termed\nas Consensus+Innovations Kalman Filter. We analyze the convergence properties\nof this distributed estimator. We prove that the mean-squared error of the\nestimator asymptotically converges if the degree of instability of the field\ndynamics is within a pre-specified threshold defined as tracking capacity of\nthe estimator. The tracking capacity is a function of the local observation\nmodels and the agent communication network. We design the optimal consensus and\ninnovation gain matrices yielding distributed estimates with minimized\nmean-squared error. Through numerical evaluations, we show that, the\ndistributed estimator with optimal gains converges faster and with\napproximately 3dB better mean-squared error performance than previous\ndistributed estimators. \n\n"}
{"id": "1605.08513", "contents": "Title: Stochastic Online Control for Energy-Harvesting Wireless Networks with\n  Battery Imperfections Abstract: In energy harvesting (EH) network, the energy storage devices (i.e.,\nbatteries) are usually not perfect. In this paper, we consider a practical\nbattery model with finite battery capacity, energy (dis-)charging loss, and\nenergy dissipation. Taking into account such battery imperfections, we rely on\nthe Lyapunov optimization technique to develop a stochastic online control\nscheme that aims to maximize the utility of data rates for EH multi-hop\nwireless networks. It is established that the proposed algorithm can provide a\nfeasible and efficient data admission, power allocation, routing and scheduling\nsolution, without requiring any statistical knowledge of the stochastic\nchannel, data-traffic, and EH processes. Numerical results demonstrate the\nmerit of the proposed scheme. \n\n"}
{"id": "1605.09013", "contents": "Title: Flexible constrained de Finetti reductions and applications Abstract: De Finetti theorems show how sufficiently exchangeable states are\nwell-approximated by convex combinations of i.i.d. states. Recently, it was\nshown that in many quantum information applications a more relaxed de Finetti\nreduction (i.e. only a matrix inequality between the symmetric state and one of\nde Finetti form) is enough, and that it leads to more concise and elegant\narguments. Here we show several uses and general flexible applicability of a\nconstrained de Finetti reduction in quantum information theory, which was\nrecently discovered by Duan, Severini and Winter. In particular we show that\nthe technique can accommodate other symmetries commuting with the permutation\naction, and permutation-invariant linear constraints. We then demonstrate that,\nin some cases, it is also fruitful with convex constraints, in particular\nseparability in a bipartite setting. This is a constraint particularly\ninteresting in the context of the complexity class $\\mathrm{QMA}(2)$ of\ninteractive quantum Merlin-Arthur games with unentangled provers, and our\nresults relate to the soundness gap amplification of $\\mathrm{QMA}(2)$\nprotocols by parallel repetition. It is also relevant for the regularization of\ncertain entropic channel parameters. Finally, we explore an extension to\ninfinite-dimensional systems, which usually pose inherent problems to de\nFinetti techniques in the quantum case. \n\n"}
{"id": "1605.09124", "contents": "Title: Minimax Rate-Optimal Estimation of Divergences between Discrete\n  Distributions Abstract: We study the minimax estimation of $\\alpha$-divergences between discrete\ndistributions for integer $\\alpha\\ge 1$, which include the Kullback--Leibler\ndivergence and the $\\chi^2$-divergences as special examples. Dropping the usual\ntheoretical tricks to acquire independence, we construct the first minimax\nrate-optimal estimator which does not require any Poissonization, sample\nsplitting, or explicit construction of approximating polynomials. The estimator\nuses a hybrid approach which solves a problem-independent linear program based\non moment matching in the non-smooth regime, and applies a problem-dependent\nbias-corrected plug-in estimator in the smooth regime, with a soft decision\nboundary between these regimes. \n\n"}
{"id": "1605.09493", "contents": "Title: A Multiway Relay Channel with Balanced Sources Abstract: We consider a joint source-channel coding problem on a finite-field multiway\nrelay channel, and we give closed-form lower and upper bounds on the optimal\nsource-channel rate. These bounds are shown to be tight for all discrete\nmemoryless sources in a certain class $\\mathcal{P}^*$, and we demonstrate that\nstrict source-channel separation is optimal within this class. We show how to\ntest whether a given source belongs to $\\mathcal{P}^*$, we give a\nbalanced-information regularity condition for $\\mathcal{P}^*$, and we express\n$\\mathcal{P}^*$ in terms of conditional multiple-mutual informations. Finally,\nwe show that $\\mathcal{P}^*$ is useful for a centralised storage problem. \n\n"}
{"id": "1606.00160", "contents": "Title: The Mathematical Intelligencer flunks the Olympics Abstract: The Mathematical Intelligencer recently published a note by Y. Sergeyev that\nchallenges both mathematics and intelligence. We examine Sergeyev's claims\nconcerning his purported Infinity computer. We compare his grossone system with\nthe classical Levi-Civita fields and with the hyperreal framework of A.\nRobinson, and analyze the related algorithmic issues inevitably arising in any\ngenuine computer implementation. We show that Sergeyev's grossone system is\nunnecessary and vague, and that whatever consistent subsystem could be salvaged\nis subsumed entirely within a stronger and clearer system (IST). Lou Kauffman,\nwho published an article on a grossone, places it squarely outside the\nhistorical panorama of ideas dealing with infinity and infinitesimals. \n\n"}
{"id": "1606.00963", "contents": "Title: Optimal quantization for a probability measure on a nonuniform stretched\n  Sierpi\\'{n}ski triangle Abstract: Quantization for a Borel probability measure refers to the idea of estimating\na given probability by a discrete probability with support containing a finite\nnumber of elements. In this paper, we have considered a Borel probability\nmeasure $P$ on $\\mathbb R^2$, which has support a nonuniform stretched\nSierpi\\'{n}ski triangle generated by a set of three contractive similarity\nmappings on $\\mathbb R^2$. For this probability measure, we investigate the\noptimal sets of $n$-means and the $n$th quantization errors for all positive\nintegers $n$. \n\n"}
{"id": "1606.01505", "contents": "Title: Basis entropy: A useful physical quantity about projective measurement Abstract: Projective measurement can increase the entropy of a state $\\rho$, the\nincreased entropy is not only up to the basis of projective measurement, but\nalso has something to do with the properties of the state itself. In this paper\nwe define this increased entropy as basis entropy. And then we discuss the\nusefulness of this new concept by showing its application in deciding whether a\nstate is pure or not and detecting the existence of quantum discord. And as\nshown in the paper, this new concept can also be used to describe decoherence. \n\n"}
{"id": "1606.04202", "contents": "Title: Improved Approximation of Storage-Rate Tradeoff for Caching with\n  Multiple Demands Abstract: Caching at the network edge has emerged as a viable solution for alleviating\nthe severe capacity crunch in modern content centric wireless networks by\nleveraging network load-balancing in the form of localized content storage and\ndelivery. In this work, we consider a cache-aided network where the cache\nstorage phase is assisted by a central server and users can demand multiple\nfiles at each transmission interval. To service these demands, we consider two\ndelivery models - $(1)$ centralized content delivery where user demands at each\ntransmission interval are serviced by the central server via multicast\ntransmissions; and $(2)$ device-to-device (D2D) assisted distributed delivery\nwhere users multicast to each other in order to service file demands. For such\ncache-aided networks, we present new results on the fundamental cache storage\nvs. transmission rate tradeoff. Specifically, we develop a new technique for\ncharacterizing information theoretic lower bounds on the storage-rate tradeoff\nand show that the new lower bounds are strictly tighter than cut-set bounds\nfrom literature. Furthermore, using the new lower bounds, we establish the\noptimal storage-rate tradeoff to within a constant multiplicative gap. We show\nthat, for multiple demands per user, achievable schemes based on repetition of\nschemes for single demands are order-optimal under both delivery models. \n\n"}
{"id": "1606.04203", "contents": "Title: Order-2 Asymptotic Optimality of the Fully Distributed Sequential\n  Hypothesis Test Abstract: This work analyzes the asymptotic performances of fully distributed\nsequential hypothesis testing procedures as the type-I and type-II error rates\napproach zero, in the context of a sensor network without a fusion center. In\nparticular, the sensor network is defined by an undirected graph, where each\nsensor can observe samples over time, access the information from the adjacent\nsensors, and perform the sequential test based on its own decision statistic.\nDifferent from most literature, the sampling process and the information\nexchange process in our framework take place simultaneously (or, at least in\ncomparable time-scales), thus cannot be decoupled from one another. Two\nmessage-passing schemes are considered, based on which the distributed\nsequential probability ratio test (DSPRT) is carried out respectively. The\nfirst scheme features the dissemination of the raw samples. Although the sample\npropagation based DSPRT is shown to yield the asymptotically optimal\nperformance at each sensor, it incurs excessive inter-sensor communication\noverhead due to the exchange of raw samples with index information. The second\nscheme adopts the consensus algorithm, where the local decision statistic is\nexchanged between sensors instead of the raw samples, thus significantly\nlowering the communication requirement compared to the first scheme. In\nparticular, the decision statistic for DSPRT at each sensor is updated by the\nweighted average of the decision statistics in the neighbourhood at every\nmessage-passing step. We show that, under certain regularity conditions, the\nconsensus algorithm based DSPRT also yields the order-2 asymptotically optimal\nperformance at all sensors. \n\n"}
{"id": "1606.04760", "contents": "Title: Adapting to unknown noise level in sparse deconvolution Abstract: In this paper, we study sparse spike deconvolution over the space of\ncomplex-valued measures when the input measure is a finite sum of Dirac masses.\nWe introduce a modified version of the Beurling Lasso (BLasso), a semi-definite\nprogram that we refer to as the Concomitant Beurling Lasso (CBLasso). This new\nprocedure estimates the target measure and the unknown noise level\nsimultaneously. Contrary to previous estimators in the literature, theory holds\nfor a tuning parameter that depends only on the sample size, so that it can be\nused for unknown noise level problems. Consistent noise level estimation is\nstandardly proved. As for Radon measure estimation, theoretical guarantees\nmatch the previous state-of-the-art results in Super-Resolution regarding\nminimax prediction and localization. The proofs are based on a bound on the\nnoise level given by a new tail estimate of the supremum of a stationary\nnon-Gaussian process through the Rice method. \n\n"}
{"id": "1606.04791", "contents": "Title: 2D Time-frequency interference modelling using stochastic geometry for\n  performance evaluation in Low-Power Wide-Area Networks Abstract: In wireless networks, interferences between trans- missions are modelled\neither in time or frequency domain. In this article, we jointly analyze\ninterferences in the time- frequency domain using a stochastic geometry model\nassuming the total time-frequency resources to be a two-dimensional plane and\ntransmissions from Internet of Things (IoT) devices time- frequency patterns on\nthis plane. To evaluate the interference, we quantify the overlap between the\ninformation packets: provided that the overlap is not too strong, the packets\nare not necessarily lost due to capture effect. This flexible model can be used\nfor multiple medium access scenarios and is especially adapted to the random\ntime-frequency access schemes used in Low-Power Wide-Area Networks (LPWANs). By\ncharacterizing the outage probability and throughput, our approach permits to\nevaluate the performance of two representative LPWA technologies\nSigfox{\\textsuperscript \\textregistered} and LoRaWA{\\textsuperscript\n\\textregistered}. \n\n"}
{"id": "1606.05673", "contents": "Title: User-Centric Mobility Management in Ultra-Dense Cellular Networks under\n  Spatio-Temporal Dynamics Abstract: This article investigates the mobility management of an ultra dense cellular\nnetwork (UDN) from an energy-efficiency (EE) point of view. Many dormant base\nstations (BSs) in a UDN do not transmit signals, and thus a received power\nbased handover (HO) approach as in traditional cellular networks is hardly\napplicable. In addition, the limited front/backhaul capacity compared to a huge\nnumber of BSs makes it difficult to implement a centralized HO and power\ncontrol. For these reasons, a novel user-centric association rule is proposed,\nwhich jointly optimizes HO and power control for maximizing EE. The proposed\nmobility management is able to cope not only with the spatial randomness of\nuser movement but also with temporally correlated wireless channels. The\nproposed approach is implemented over a HO time window and tractable power\ncontrol policy by exploiting mean-field game (MFG) and stochastic geometry\n(SG). Compared to a baseline with a fixed HO interval and transmit power, the\nproposed approach achieves the 1.2 times higher long-term average EE at a\ntypical active BS. \n\n"}
{"id": "1606.06099", "contents": "Title: Information Bounds and Flatness Factor Approximation for Fading Wiretap\n  MIMO Channels Abstract: In this article, the design of secure lattice coset codes for general\nwireless channels with fading and Gaussian noise is studied. Recalling the\neavesdropper's probability and information bounds, a variant of the latter is\ngiven from which it is explicitly seen that both quantities are upper bounded\nby (increasing functions of) the expected flatness factor of the faded lattice\nrelated to the eavesdropper.\n  By making use of a recently developed approximation of the theta series of a\nlattice, it is further shown how the average flatness factor can be\napproximated numerically. In particular, based on the numerical computations,\nthe average flatness factor not only bounds but also orders correctly the\nperformance of different lattices. \n\n"}
{"id": "1606.06794", "contents": "Title: A Delay-Optimal Packet Scheduler for M2M Uplink Abstract: In this paper, we present a delay-optimal packet scheduler for processing the\nM2M uplink traffic at the M2M application server (AS). Due to the\ndelay-heterogeneity in uplink traffic, we classify it broadly into\ndelay-tolerant and delay-sensitive traffic. We then map the diverse delay\nrequirements of each class to sigmoidal functions of packet delay and formulate\na utility-maximization problem that results in a proportionally fair\ndelay-optimal scheduler. We note that solving this optimization problem is\nequivalent to solving for the optimal fraction of time each class is served\nwith (preemptive) priority such that it maximizes the system utility. Using\nMonte-Carlo simulations for the queuing process at AS, we verify the\ncorrectness of the analytical result for optimal scheduler and show that it\noutperforms other state-of-the-art packet schedulers such as weighted round\nrobin, max-weight scheduler, fair scheduler and priority scheduling. We also\nnote that at higher traffic arrival rate, the proposed scheduler results in a\nnear-minimal delay variance for the delay-sensitive traffic which is highly\ndesirable. This comes at the expense of somewhat higher delay variance for\ndelay-tolerant traffic which is usually acceptable due to its delay-tolerant\nnature. \n\n"}
{"id": "1606.08545", "contents": "Title: A H-ARQ scheme for polar codes Abstract: We consider the problem of supporting H-ARQ with polar codes. For supporting\nH-ARQ, we propose to create redundancy versions based on different, but\nequivalent, subsets of a polar code. The equivalent subsets are created from an\ninitial subset of a polar code using an inherent symmetry in polar code\nconstruction. A greedy construction is used to create the initial subset of a\npolar code. We demonstrate performance of proposed constructions via\nsimulations for binary input AWGN channel. We demonstrate that a (4096, 1024)\npolar code can be divided into two disjoint (2048, 1024) subset polar codes,\nwhich when decoded individually are within 0.2 dB (at $1 \\%$ BLER) of a (2048,\n1024) polar code, and achieve performance of a (4096, 1024) polar code when\ndecoded jointly. \n\n"}
{"id": "1606.08587", "contents": "Title: Coordination and Antenna Domain Formation in Cloud-RAN systems Abstract: We study here the problem of Antenna Domain Formation (ADF) in cloud RAN\nsystems, whereby multiple remote radio-heads (RRHs) are each to be assigned to\na set of antenna domains (ADs), such that the total interference between the\nADs is minimized. We formulate the corresponding optimization problem, by\nintroducing the concept of \\emph{interference coupling coefficients} among\npairs of radio-heads. We then propose a low-overhead algorithm that allows the\nproblem to be solved in a distributed fashion, among the aggregation nodes\n(ANs), and establish basic convergence results. Moreover, we also propose a\nsimple relaxation to the problem, thus enabling us to characterize its maximum\nperformance. We follow a layered coordination structure: after the ADs are\nformed, radio-heads are clustered to perform coordinated beamforming using the\nwell known Weighted-MMSE algorithm. Finally, our simulations show that using\nthe proposed ADF mechanism would significantly increase the sum-rate of the\nsystem (with respect to random assignment of radio-heads). \n\n"}
{"id": "1606.08950", "contents": "Title: Cross-layer design for downlink multi-hop cloud radio access networks\n  with network coding Abstract: There are two fundamentally different fronthaul techniques in the downlink\ncommunication of cloud radio access network (C-RAN): the data-sharing strategy\nand the compression-based strategy. Under the former strategy, each user's\nmessage is multicast from the central processor (CP) to all the serving remote\nradio heads (RRHs) over the fronthaul network, which then cooperatively serve\nthe users through joint beamforming; while under the latter strategy, the user\nmessages are first beamformed then quantized at the CP, and the compressed\nsignal is unicast to the corresponding RRH, which then decompresses its\nreceived signal for wireless transmission. Previous works show that in general\nthe compression-based strategy outperforms the data-sharing strategy. This\npaper, on the other hand, point s out that in a C-RAN model where the RRHs are\nconnected to the CP via multi-hop routers, data-sharing can be superior to\ncompression if the network coding technique is adopted for multicasting user\nmessages to the cooperating RRHs, and the RRH's beamforming vectors, the\nuser-RRH association, and the network coding design over the fronthaul network\nare jointly optimized based on the techniques of sparse optimization an d\nsuccessive convex approximation. This is in comparison to the compression-based\nstrategy, where information is unicast over the fronthaul network by simple\nrouting, and the RRH's compression noise covariance and beamforming vectors, as\nwell as the routing strategy over the fronthaul network are jointly optimized\nbased on the successive convex approximation technique. The observed gain in\noverall network throughput is due to that information multicast is more\nefficient than information unicast over the multi-hop fronthaul of a C-RAN. \n\n"}
{"id": "1607.00500", "contents": "Title: Spatio-Temporal Network Dynamics Framework for Energy-Efficient\n  Ultra-Dense Cellular Networks Abstract: This article investigates the performance of an ultra-dense network (UDN)\nfrom an energy-efficiency (EE) standpoint leveraging the interplay between\nstochastic geometry (SG) and mean-field game (MFG) theory. In this setting,\nbase stations (BSs) (resp. users) are uniformly distributed over a\ntwo-dimensional plane as two independent homogeneous Poisson point processes\n(PPPs), where users associate to their nearest BSs. The goal of every BS is to\nmaximize its own energy efficiency subject to channel uncertainty, random BS\nlocation, and interference levels. Due to the coupling in interference, the\nproblem is solved in the mean-field (MF) regime where each BS interacts with\nthe whole BS population via time-varying MF interference. As a main\ncontribution, the asymptotic convergence of MF interference to zero is\nrigorously proved in a UDN with multiple transmit antennas. It allows us to\nderive a closed-form EE representation, yielding a tractable EE optimal power\ncontrol policy. This proposed power control achieves more than 1.5 times higher\nEE compared to a fixed power baseline. \n\n"}
{"id": "1607.01827", "contents": "Title: Compressive Spectral Estimation with Single-Snapshot ESPRIT: Stability\n  and Resolution Abstract: In this paper Estimation of Signal Parameters via Rotational Invariance\nTechniques (ESPRIT) is developed for spectral estimation with single-snapshot\nmeasurement. Stability and resolution analysis with performance guarantee for\nSingle-Snapshot ESPRIT (SS-ESPRIT) is the main focus. In the noise-free case,\nexact reconstruction is guaranteed for any arbitrary set of frequencies as long\nas the number of measurement data is at least twice the number of distinct\nfrequencies to be recovered. In the presence of noise and under the assumption\nthat the true frequencies are separated by at least two times Rayleigh's\nResolution Length, an explicit error bound for frequency reconstruction is\ngiven in terms of the dynamic range and the separation of the frequencies. The\nseparation and sparsity constraint compares favorably with those of the leading\napproaches to compressed sensing in the continuum. \n\n"}
{"id": "1607.02259", "contents": "Title: Maximum Entropy and Sufficiency Abstract: The notion of Bregman divergence and sufficiency will be defined on general\nconvex state spaces. It is demonstrated that only spectral sets can have a\nBregman divergence that satisfies a sufficiency condition. Positive elements\nwith trace 1 in a Jordan algebra are examples of spectral sets, and the most\nimportant example is the set of density matrices with complex entries. It is\nconjectured that information theoretic considerations lead directly to the\nnotion of Jordan algebra under some regularity conditions. \n\n"}
{"id": "1607.02385", "contents": "Title: Finite Length Performance of Random Slotted ALOHA Strategies Abstract: Multiple connected devices sharing common wireless resources might create\ninterference if they access the channel simultaneously. Medium access control\n(MAC) protocols gener- ally regulate the access of the devices to the shared\nchannel to limit signal interference. In particular, irregular repetition\nslotted ALOHA (IRSA) techniques can achieve high-throughput performance when\ninterference cancellation methods are adopted to recover from collisions. In\nthis work, we study the finite length performance for IRSA schemes by building\non the analogy between successive interference cancellation and iterative\nbelief- propagation on erasure channels. We use a novel combinatorial\nderivation based on the matrix-occupancy theory to compute the error\nprobability and we validate our method with simulation results. \n\n"}
{"id": "1607.02649", "contents": "Title: Linear signal recovery from $b$-bit-quantized linear measurements:\n  precise analysis of the trade-off between bit depth and number of\n  measurements Abstract: We consider the problem of recovering a high-dimensional structured signal\nfrom independent Gaussian linear measurements each of which is quantized to $b$\nbits. Our interest is in linear approaches to signal recovery, where \"linear\"\nmeans that non-linearity resulting from quantization is ignored and the\nobservations are treated as if they arose from a linear measurement model.\nSpecifically, the focus is on a generalization of a method for one-bit\nobservations due to Plan and Vershynin [\\emph{IEEE~Trans. Inform. Theory,\n\\textbf{59} (2013), 482--494}]. At the heart of the present paper is a precise\ncharacterization of the optimal trade-off between the number of measurements\n$m$ and the bit depth per measurement $b$ given a total budget of $B = m \\cdot\nb$ bits when the goal is to minimize the $\\ell_2$-error in estimating the\nsignal. It turns out that the choice $b = 1$ is optimal for estimating the unit\nvector (direction) corresponding to the signal for any level of additive\nGaussian noise before quantization as well as for a specific model of\nadversarial noise, while the choice $b = 2$ is optimal for estimating the\ndirection and the norm (scale) of the signal. Moreover, Lloyd-Max quantization\nis shown to be an optimal quantization scheme w.r.t. $\\ell_2$-estimation error.\nOur analysis is corroborated by numerical experiments showing nearly perfect\nagreement with our theoretical predictions. The paper is complemented by an\nempirical comparison to alternative methods of signal recovery taking the\nnon-linearity resulting from quantization into account. The results of that\ncomparison point to a regime change depending on the noise level: in a\nlow-noise setting, linear signal recovery falls short of more sophisticated\ncompetitors while being competitive in moderate- and high-noise settings. \n\n"}
{"id": "1607.02699", "contents": "Title: At Every Corner: Determining Corner Points of Two-User Gaussian\n  Interference Channels Abstract: The corner points of the capacity region of the two-user Gaussian\ninterference channel under strong or weak interference are determined using the\nnotions of almost Gaussian random vectors, almost lossless addition of random\nvectors, and almost linearly dependent random vectors. In particular, the\n\"missing\" corner point problem is solved in a manner that differs from previous\nworks in that it avoids the use of integration over a continuum of SNR values\nor of Monge-Kantorovitch transportation problems. \n\n"}
{"id": "1607.02817", "contents": "Title: Binary Codes with Locality for Four Erasures Abstract: In this paper, codes with locality for four erasures are considered. An upper\nbound on the rate of codes with locality with sequential recovery from four\nerasures is derived. The rate bound derived here is field independent. An\noptimal construction for binary codes meeting this rate bound is also provided.\nThe construction is based on regular graphs of girth $6$ and employs the\nsequential approach of locally recovering from multiple erasures. An extension\nof this construction that generates codes which can sequentially recover from\nfive erasures is also presented. \n\n"}
{"id": "1607.03581", "contents": "Title: Encoding and Indexing of Lattice Codes Abstract: Encoding and indexing of lattice codes is generalized from self-similar\nlattice codes to a broader class of lattices. If coding lattice\n$\\Lambda_{\\textrm{c}}$ and shaping lattice $\\Lambda_{\\textrm{s}}$ satisfy\n$\\Lambda_{\\textrm{s}} \\subseteq \\Lambda_{\\textrm{c}}$, then\n$\\Lambda_{\\textrm{c}} / \\Lambda_{\\textrm{s}}$ is a quotient group that can be\nused to form a (nested) lattice code $\\mathcal{C}$. Conway and Sloane's method\nof encoding and indexing does not apply when the lattices are not self-similar.\nResults are provided for two classes of lattices. (1) If $\\Lambda_{\\textrm{c}}$\nand $\\Lambda_{\\textrm{s}}$ both have generator matrices in triangular form,\nthen encoding is always possible. (2) When $\\Lambda_{\\textrm{c}}$ and\n$\\Lambda_{\\textrm{s}}$ are described by full generator matrices, if a solution\nto a linear diophantine equation exists, then encoding is possible. In\naddition, special cases where $\\mathcal{C}$ is a cyclic code are also\nconsidered. A condition for the existence of a group homomorphism between the\ninformation and $\\mathcal{C}$ is given. The results are applicable to a variety\nof coding lattices, including Construction A, Construction D and LDLCs. The\n$D_4$, $E_8$ and convolutional code lattices are shown to be good choices for\nthe shaping lattice. Thus, a lattice code $\\mathcal{C}$ can be designed by\nselecting $\\Lambda_{\\textrm{c}}$ and $\\Lambda_{\\textrm{s}}$ separately,\navoiding competing design requirements of self-similar lattice codes. \n\n"}
{"id": "1607.03671", "contents": "Title: On The Use of Conjugate Teager-Kaiser Energy Operators with Matched\n  Filters Abstract: This work presents the proof of concept of using energy operator theory based\non the conjugate Teager-Kaiser energy operators in matched filters for signal\ndetection in multipath fading channels. To do so, we consider signals in the\nspace $\\mathcal{S}(\\mathbb{R})$ a subspace of the Schwartz space\n$\\mathbf{S}^-(\\mathbb{R})$ in order to approximate the received signal. These\nfunctions obey to some specific properties as shown in this work. It allows to\ndecompose the received signals into subchannels with their own\nSignal-to-Noise-Ratio. \n\n"}
{"id": "1607.04525", "contents": "Title: Secure Analog Network Coding in Layered Networks Abstract: We consider a class of Gaussian layered networks where a source communicates\nwith a destination through $L$ intermediate relay layers with $N$ nodes in each\nlayer in the presence of a single eavesdropper which can overhear the\ntransmissions of the nodes in any one layer. The problem of maximum secrecy\nrate achievable with analog network coding for a unicast communication over\nsuch layered wireless relay networks with directed links is considered. A relay\nnode performing analog network coding scales and forwards the signals received\nat its input. The key contribution of this work is a lemma that provides the\nglobally optimal set of scaling factors for the nodes that maximizes the\nend-to-end secrecy rate for a class of layered networks. We also show that in\nthe high-SNR regime, ANC achieves secrecy rates within a constant gap of the\ncutset upper bound on the secrecy capacity. To the best of our knowledge, this\nwork offers the first characterization of the performance of secure ANC in\nmulti-layered networks in the presence of an eavesdropper. \n\n"}
{"id": "1607.06313", "contents": "Title: On Optimal Heterogeneous Regenerating Codes Abstract: Heterogeneous Distributed Storage Systems (DSSs) are close to the real world\napplications for data storage. Each node of the considered DSS, may store\ndifferent number of packets and each having different repair bandwidth with\nuniform repair traffic. For such heterogeneous DSS, a failed node can be\nrepaired with the help of some specific nodes. In this work, a family of codes\nbased on graph theory, is constructed which achieves the fundamental bound on\nfile size for the particular heterogeneous DSS. \n\n"}
{"id": "1607.07484", "contents": "Title: Phase Retrieval by Linear Algebra Abstract: The null vector method, based on a simple linear algebraic concept, is\nproposed as a solution to the phase retrieval problem.\n  In the case with complex Gaussian random measurement matrices, a\nnon-asymptotic error bound is derived, yielding an asymptotic regime of\naccurate approximation comparable to that for the spectral vector method. \n\n"}
{"id": "1607.07942", "contents": "Title: Multiple scan data association by convex variational inference Abstract: Data association, the reasoning over correspondence between targets and\nmeasurements, is a problem of fundamental importance in target tracking.\nRecently, belief propagation (BP) has emerged as a promising method for\nestimating the marginal probabilities of measurement to target association,\nproviding fast, accurate estimates. The excellent performance of BP in the\nparticular formulation used may be attributed to the convexity of the\nunderlying free energy which it implicitly optimises. This paper studies\nmultiple scan data association problems, i.e., problems that reason over\ncorrespondence between targets and several sets of measurements, which may\ncorrespond to different sensors or different time steps. We find that the\nmultiple scan extension of the single scan BP formulation is non-convex and\ndemonstrate the undesirable behaviour that can result. A convex free energy is\nconstructed using the recently proposed fractional free energy (FFE). A\nconvergent, BP-like algorithm is provided for the single scan FFE, and employed\nin optimising the multiple scan free energy using primal-dual coordinate\nascent. Finally, based on a variational interpretation of joint probabilistic\ndata association (JPDA), we develop a sequential variant of the algorithm that\nis similar to JPDA, but retains consistency constraints from prior scans. The\nperformance of the proposed methods is demonstrated on a bearings only target\nlocalisation problem. \n\n"}
{"id": "1608.00352", "contents": "Title: Spectral Efficiency of Mixed-ADC Receivers for Massive MIMO Systems Abstract: This paper investigated the uplink of multi-user massive multi-input\nmulti-output (MIMO) systems with a mixed analog-to-digital converter (ADC)\nreceiver architecture, in which some antennas are equipped with costly\nfull-resolution ADCs and others with less expensive low-resolution ADCs. A\nclosed-form approximation of the achievable spectral efficiency (SE) with the\nmaximum-ratio combining (MRC) detector is derived. Based on this approximated\nresult, the effects of the number of base station antennas, the transmit power,\nthe proportion of full-resolution ADCs in the mixed-ADC structure, and the\nnumber of quantization bits of the low-resolution ADCs are revealed. Results\nshowcase that the achievable SE increases with the number of BS antennas and\nquantization bits, and it converges to a saturated value in the high user power\nregime or the full ADC resolution case. Most important, this work efficiency\nverifies that for massive MIMO, the mixed-ADC receiver with a small fraction of\nfull-resolution ADCs can have comparable SE performance with the receiver with\nall full-resolution ADCs but at a considerably lower hardware cost. \n\n"}
{"id": "1608.01432", "contents": "Title: Decision Error Probability in a Two-stage Communication Network for\n  Smart Grids with Imperfect Data Links Abstract: This paper analyzes a scenario where the distribution system operator needs\nto estimate whether the average power demand in a given period is above a\npredetermined threshold using an 1-bit memoryless scheme. Specifically,\nindividual smart-meters periodically monitor the average power demand of their\nrespective households to inform the system operator if it is above a\npredetermined level using only a 1-bit signal. The communication link between\nthe meters and the operator occurs in two hops and is modeled as binary\nsymmetric channels. The first hop connects individual smart meters to their\ncorresponding aggregator, while the second connects different aggregators to\nthe system operator. A decision about the power demand also happens in two\nstages based on the received information bit. We consider here three decision\nrules: AND, OR and MAJORITY. Our analytical results indicate the circumstances\n(i.e. how frequent the meters experience the consumption above the defined\nthreshold) and the design setting (i.e. decision rules) that a low error\nprobability can be attained. We illustrate our approach with numerical results\nfrom actual daily consumption from 12 households and 3 aggregators. \n\n"}
{"id": "1608.02866", "contents": "Title: Optimal Relay Selection for the Parallel Hybrid RF/FSO Relay Channel:\n  Non-Buffer-Aided and Buffer-Aided Designs Abstract: Hybrid radio frequency (RF)/free space optical (FSO) systems are among the\ncandidate enabling technologies for the next generation of wireless networks\nsince they benefit from both the high data rates of the FSO subsystem and the\nhigh reliability of the RF subsystem. In this paper, we focus on the problem of\nthroughput maximization in the parallel hybrid RF/FSO relay channel. In the\nparallel hybrid RF/FSO relay channel, a source node sends its data to a\ndestination node with the help of multiple relay nodes. Thereby, for a given\nrelay, the source-relay and the relay-destination FSO links are orthogonal with\nrespect to each other due to the narrow beam employed for FSO transmission,\nwhereas, due to the broadcast nature of the RF channel, half-duplex operation\nis required for the RF links if self-interference is to be avoided. Moreover,\nwe consider the two cases where the relays are and are not equipped with\nbuffers. For both cases, we derive the optimal relay selection policies for the\nRF and FSO links and the optimal time allocation policy for transmission and\nreception for the RF links. The proposed optimal protocols provide important\ninsights for optimal system design. Since the optimal buffer-aided (BA) policy\nintroduces an unbounded end-to-end delay, we also propose a suboptimal BA\npolicy which ensures certain target average delays. Moreover, we present\ndistributed implementations for both proposed optimal protocols. Simulation\nresults demonstrate that a considerable gain can be achieved by the proposed\nadaptive protocols in comparison with benchmark schemes from the literature. \n\n"}
{"id": "1608.03825", "contents": "Title: Coded Network Function Virtualization: Fault Tolerance via In-Network\n  Coding Abstract: Network Function Virtualization (NFV) prescribes the instantiation of network\nfunctions on general-purpose network devices, such as servers and switches.\nWhile yielding a more flexible and cost-effective network architecture, NFV is\npotentially limited by the fact that commercial off-the-shelf hardware is less\nreliable than the dedicated network elements used in conventional cellular\ndeployments. The typical solution for this problem is to duplicate network\nfunctions across geographically distributed hardware in order to ensure\ndiversity. In contrast, this letter proposes to leverage channel coding in\norder to enhance the robustness on NFV to hardware failure. The proposed\napproach targets the network function of uplink channel decoding, and builds on\nthe algebraic structure of the encoded data frames in order to perform\nin-network coding on the signals to be processed at different servers. The key\nprinciples underlying the proposed coded NFV approach are presented for a\nsimple embodiment and extensions are discussed. Numerical results demonstrate\nthe potential gains obtained with the proposed scheme as compared to the\nconventional diversity-based fault-tolerant scheme in terms of error\nprobability. \n\n"}
{"id": "1608.03989", "contents": "Title: Centralized coded caching schemes: A hypergraph theoretical approach Abstract: The centralized coded caching scheme is a technique proposed by Maddah-Ali\nand Niesen as a solution to reduce the network burden in peak times in a\nwireless system. Later Yan et al. reformulated the problem as designing a\ncorresponding placement delivery array, and proposed two new schemes from this\nperspective. These schemes above significantly reduce the transmission rate\n$R$, compared with the uncoded caching scheme. However, to implement the new\nschemes, each file should be cut into $F$ pieces, where $F$ increases\nexponentially with the number of users $K$. Such constraint is obviously\ninfeasible in the practical setting, especially when $K$ is large. Thus it is\ndesirable to design caching schemes with constant rate $R$ (independent of $K$)\nas well as small $F$.\n  In this paper we view the centralized coded caching problem in a hypergraph\nperspective and show that designing a feasible placement delivery array is\nequivalent to constructing a linear and (6, 3)-free 3-uniform 3-partite\nhypergraph. Several new results and constructions arise from our novel point of\nview. First, by using the famous (6, 3)-theorem in extremal combinatorics, we\nshow that constant rate caching schemes with $F$ growing linearly with $K$ do\nnot exist. Second, we present two infinite classes of centralized coded caching\nschemes, which include the schemes of Ali-Niesen and Yan et al. as special\ncases, respectively. Moreover, our constructions show that constant rate\ncaching schemes with $F$ growing sub-exponentially with $K$ do exist. \n\n"}
{"id": "1608.04460", "contents": "Title: Microcanonical thermodynamics in general physical theories Abstract: Microcanonical thermodynamics studies the operations that can be performed on\nsystems with well-defined energy. So far, this approach has been applied to\nclassical and quantum systems. Here we extend it to arbitrary physical\ntheories, proposing two requirements for the development of a general\nmicrocanonical framework. We then formulate three resource theories,\ncorresponding to three different sets of basic operations: i) random reversible\noperations, resulting from reversible dynamics with fluctuating parameters, ii)\nnoisy operations, generated by the interaction with ancillas in the\nmicrocanonical state, and iii) unital operations, defined as the operations\nthat preserve the microcanonical state. We focus our attention on a class of\nphysical theories, called sharp theories with purification, where these three\nsets of operations exhibit remarkable properties. Firstly, each set is\ncontained into the next. Secondly, the convertibility of states by unital\noperations is completely characterised by a majorisation criterion. Thirdly,\nthe three sets are equivalent in terms of state convertibility if and only if\nthe dynamics allowed by theory satisfy a suitable condition, which we call\nunrestricted reversibility. Under this condition, we derive a duality between\nthe resource theory of microcanonical thermodynamics and the resource theory of\npure bipartite entanglement. \n\n"}
{"id": "1608.05317", "contents": "Title: R\\'enyi divergences as weighted non-commutative vector valued\n  $L_p$-spaces Abstract: We show that Araki and Masuda's weighted non-commutative vector valued\n$L_p$-spaces [Araki \\& Masuda, Publ. Res. Inst. Math. Sci., 18:339 (1982)]\ncorrespond to an algebraic generalization of the sandwiched R\\'enyi divergences\nwith parameter $\\alpha = \\frac{p}{2}$. Using complex interpolation theory, we\nprove various fundamental properties of these divergences in the setup of von\nNeumann algebras, including a data-processing inequality and monotonicity in\n$\\alpha$. We thereby also give new proofs for the corresponding\nfinite-dimensional properties. We discuss the limiting cases $\\alpha\\to\n\\{\\frac{1}{2},1,\\infty\\}$ leading to minus the logarithm of Uhlmann's fidelity,\nUmegaki's relative entropy, and the max-relative entropy, respectively. As a\ncontribution that might be of independent interest, we derive a Riesz-Thorin\ntheorem for Araki-Masuda $L_p$-spaces and an Araki-Lieb-Thirring inequality for\nstates on von Neumann algebras. \n\n"}
{"id": "1608.06117", "contents": "Title: Phase Retrieval From the Magnitudes of Affine Linear Measurements Abstract: In this paper, we consider the phase retrieval problem in which one aims to\nrecover a signal from the magnitudes of affine measurements. Let $\\{{\\mathbf\na}_j\\}_{j=1}^m \\subset {\\mathbb H}^d$ and ${\\mathbf b}=(b_1, \\ldots,\nb_m)^\\top\\in{\\mathbb H}^m$, where ${\\mathbb H}={\\mathbb R}$ or ${\\mathbb C}$.\nWe say $\\{{\\mathbf a}_j\\}_{j=1}^m$ and $\\mathbf b$ are affine phase retrievable\nfor ${\\mathbb H}^d$ if any ${\\mathbf x}\\in{\\mathbb H}^d$ can be recovered from\nthe magnitudes of the affine measurements $\\{|<{\\mathbf a}_j,{\\mathbf\nx}>+b_j|,\\, 1\\leq j\\leq m\\}$. We develop general framework for affine phase\nretrieval and prove necessary and sufficient conditions for $\\{{\\mathbf\na}_j\\}_{j=1}^m$ and $\\mathbf b$ to be affine phase retrievable. We establish\nresults on minimal measurements and generic measurements for affine phase\nretrieval as well as on sparse affine phase retrieval. In particular, we also\nhighlight some notable differences between affine phase retrieval and the\nstandard phase retrieval in which one aims to recover a signal $\\mathbf x$ from\nthe magnitudes of its linear measurements. In standard phase retrieval, one can\nonly recover $\\mathbf x$ up to a unimodular constant, while affine phase\nretrieval removes this ambiguity. We prove that unlike standard phase\nretrieval, the affine phase retrievable measurements $\\{{\\mathbf\na}_j\\}_{j=1}^m$ and $\\mathbf b$ do not form an open set in ${\\mathbb\nH}^{m\\times d}\\times {\\mathbb H}^m$. Also in the complex setting, the standard\nphase retrieval requires $4d-O(\\log_2d)$ measurements, while the affine phase\nretrieval only needs $m=3d$ measurements. \n\n"}
{"id": "1608.06991", "contents": "Title: Gaussian hypothesis testing and quantum illumination Abstract: Quantum hypothesis testing is one of the most basic tasks in quantum\ninformation theory and has fundamental links with quantum communication and\nestimation theory. In this paper, we establish a formula that characterizes the\ndecay rate of the minimal Type-II error probability in a quantum hypothesis\ntest of two Gaussian states given a fixed constraint on the Type-I error\nprobability. This formula is a direct function of the mean vectors and\ncovariance matrices of the quantum Gaussian states in question. We give an\napplication to quantum illumination, which is the task of determining whether\nthere is a low-reflectivity object embedded in a target region with a bright\nthermal-noise bath. For the asymmetric-error setting, we find that a quantum\nillumination transmitter can achieve an error probability exponent stronger\nthan a coherent-state transmitter of the same mean photon number, and\nfurthermore, that it requires far fewer trials to do so. This occurs when the\nbackground thermal noise is either low or bright, which means that a quantum\nadvantage is even easier to witness than in the symmetric-error setting because\nit occurs for a larger range of parameters. Going forward from here, we expect\nour formula to have applications in settings well beyond those considered in\nthis paper, especially to quantum communication tasks involving quantum\nGaussian channels. \n\n"}
{"id": "1608.07799", "contents": "Title: SUMMeR: Sub-Nyquist MIMO Radar Abstract: Multiple input multiple output (MIMO) radar exhibits several advantages with\nrespect to traditional radar array systems in terms of flexibility and\nperformance. However, MIMO radar poses new challenges for both hardware design\nand digital processing. In particular, achieving high azimuth resolution\nrequires a large number of transmit and receive antennas. In addition, the\ndigital processing is performed on samples of the received signal, from each\ntransmitter to each receiver, at its Nyquist rate, which can be prohibitively\nlarge when high resolution is needed. Overcoming the rate bottleneck,\nsub-Nyquist sampling methods have been proposed that break the link between\nradar signal bandwidth and sampling rate. In this work, we extend these methods\nto MIMO configurations and propose a sub-Nyquist MIMO radar (SUMMeR) system\nthat performs both time and spatial compression. We present a\nrange-azimuth-Doppler recovery algorithm from sub-Nyquist samples obtained from\na reduced number of transmitters and receivers, that exploits the sparsity of\nthe recovered targets' parameters. This allows us to achieve reduction in the\nnumber of deployed antennas and the number of samples per receiver, without\ndegrading the time and spatial resolutions. Simulations illustrate the\ndetection performance of SUMMeR for different compression levels and shows that\nboth time and spatial resolution are preserved, with respect to classic Nyquist\nMIMO configurations. We also examine the impact of design parameters, such as\nantennas' locations and carrier frequencies, on the detection performance, and\nprovide guidelines for their choice. \n\n"}
{"id": "1608.08454", "contents": "Title: Improving the Correlation Lower Bound for Simultaneous Orthogonal\n  Matching Pursuit Abstract: The simultaneous orthogonal matching pursuit (SOMP) algorithm aims to find\nthe joint support of a set of sparse signals acquired under a multiple\nmeasurement vector model. Critically, the analysis of SOMP depends on the\nmaximal inner product of any atom of a suitable dictionary and the current\nsignal residual, which is formed by the subtraction of previously selected\natoms. This inner product, or correlation, is a key metric to determine the\nbest atom to pick at each iteration. This paper provides, for each iteration of\nSOMP, a novel lower bound of the aforementioned metric for the atoms belonging\nto the correct and common joint support of the multiple signals. Although the\nbound is obtained for the noiseless case, its main purpose is to intervene in\nnoisy analyses of SOMP. Finally, it is shown for specific signal patterns that\nthe proposed bound outperforms state-of-the-art results for SOMP, and\northogonal matching pursuit (OMP) as a special case. \n\n"}
{"id": "1609.00951", "contents": "Title: A Unified Convergence Analysis of the Multiplicative Update Algorithm\n  for Regularized Nonnegative Matrix Factorization Abstract: The multiplicative update (MU) algorithm has been extensively used to\nestimate the basis and coefficient matrices in nonnegative matrix factorization\n(NMF) problems under a wide range of divergences and regularizers. However,\ntheoretical convergence guarantees have only been derived for a few special\ndivergences without regularization. In this work, we provide a conceptually\nsimple, self-contained, and unified proof for the convergence of the MU\nalgorithm applied on NMF with a wide range of divergences and regularizers. Our\nmain result shows the sequence of iterates (i.e., pairs of basis and\ncoefficient matrices) produced by the MU algorithm converges to the set of\nstationary points of the non-convex NMF optimization problem. Our proof\nstrategy has the potential to open up new avenues for analyzing similar\nproblems in machine learning and signal processing. \n\n"}
{"id": "1609.01053", "contents": "Title: Multi-Cell Massive MIMO Performance with Double Scattering Channels Abstract: This paper investigates the spectral efficiency (SE) of multi-cell Massive\nMulti-Input Multi-Output (MIMO) using different channel models. Prior works\nhave derived closed-form SE bounds and approximations for Gaussian distributed\nchannels, while we consider the double scattering model-a prime example of a\nnon-Gaussian channel for which it is intractable to obtain closed form SE\nexpressions. The channels are estimated using limited resources, which gives\nrise to pilot contamination, and the estimates are used for linear detection\nand to compute the SE numerically. Analytical and numerical examples are used\nto describe the key behaviors of the double scattering models, which differ\nfrom conventional Massive MIMO models. Finally, we provide multi-cell\nsimulation results that compare the double scattering model with uncorrelated\nRayleigh fading and explain under what conditions we can expect to achieve\nsimilar SEs. \n\n"}
{"id": "1609.02519", "contents": "Title: Not All Fluctuations are Created Equal: Spontaneous Variations in\n  Thermodynamic Function Abstract: Almost all processes -- highly correlated, weakly correlated, or correlated\nnot at all---exhibit statistical fluctuations. Often physical laws, such as the\nSecond Law of Thermodynamics, address only typical realizations -- as\nhighlighted by Shannon's asymptotic equipartition property and as entailed by\ntaking the thermodynamic limit of an infinite number of degrees of freedom.\nIndeed, our interpretations of the functioning of macroscopic thermodynamic\ncycles are so focused. Using a recently derived Second Law for information\nprocessing, we show that different subsets of fluctuations lead to distinct\nthermodynamic functioning in Maxwellian Demons. For example, while typical\nrealizations may operate as an engine -- converting thermal fluctuations to\nuseful work -- even \"nearby\" fluctuations (nontypical, but probable\nrealizations) behave differently, as Landauer erasers -- converting available\nstored energy to dissipate stored information. One concludes that ascribing a\nsingle, unique functional modality to a thermodynamic system, especially one on\nthe nanoscale, is at best misleading, likely masking an array of simultaneous,\nparallel thermodynamic transformations. This alters how we conceive of cellular\nprocesses, engineering design, and evolutionary adaptation. \n\n"}
{"id": "1609.02968", "contents": "Title: Real-time Cooperative Communication for Automation over Wireless Abstract: High-performance industrial automation systems rely on tens of simultaneously\nactive sensors and actuators and have stringent communication latency and\nreliability requirements. Current wireless technologies like WiFi, Bluetooth,\nand LTE are unable to meet these requirements, forcing the use of wired\ncommunication in industrial control systems. This paper introduces a wireless\ncommunication protocol that capitalizes on multiuser diversity and cooperative\ncommunication to achieve the ultra-reliability with a low-latency constraint.\n  Our protocol is analyzed using the communication-theoretic\ndelay-limited-capacity framework and compared to baseline schemes that\nprimarily exploit frequency diversity. For a scenario inspired by an industrial\nprinting application with thirty nodes in the control loop, 20B messages\ntransmitted between pairs of nodes and a cycle time of $2$ ms, an idealized\nprotocol can achieve a cycle failure probability (probability that any packet\nin a cycle is not successfully delivered) lower than $10^{-9}$ with nominal SNR\nbelow 5 dB in a 20MHz wide channel. \n\n"}
{"id": "1609.03363", "contents": "Title: CONDENSE: A Reconfigurable Knowledge Acquisition Architecture for Future\n  5G IoT Abstract: In forthcoming years, the Internet of Things (IoT) will connect billions of\nsmart devices generating and uploading a deluge of data to the cloud. If\nsuccessfully extracted, the knowledge buried in the data can significantly\nimprove the quality of life and foster economic growth. However, a critical\nbottleneck for realising the efficient IoT is the pressure it puts on the\nexisting communication infrastructures, requiring transfer of enormous data\nvolumes. Aiming at addressing this problem, we propose a novel architecture\ndubbed Condense, which integrates the IoT-communication infrastructure into\ndata analysis. This is achieved via the generic concept of network function\ncomputation: Instead of merely transferring data from the IoT sources to the\ncloud, the communication infrastructure should actively participate in the data\nanalysis by carefully designed en-route processing. We define the Condense\narchitecture, its basic layers, and the interactions among its constituent\nmodules. Further, from the implementation side, we describe how Condense can be\nintegrated into the 3rd Generation Partnership Project (3GPP) Machine Type\nCommunications (MTC) architecture, as well as the prospects of making it a\npractically viable technology in a short time frame, relying on Network\nFunction Virtualization (NFV) and Software Defined Networking (SDN). Finally,\nfrom the theoretical side, we survey the relevant literature on computing\n\"atomic\" functions in both analog and digital domains, as well as on function\ndecomposition over networks, highlighting challenges, insights, and future\ndirections for exploiting these techniques within practical 3GPP MTC\narchitecture. \n\n"}
{"id": "1609.04602", "contents": "Title: New MDS or near MDS self-dual codes over finite fields Abstract: The study of MDS self-dual codes has attracted lots of attention in recent\nyears.\n  There are many papers on determining existence of $q-$ary MDS self-dual codes\nfor various lengths.\n  There are not existence of $q-$ary MDS self-dual codes of some lengths, even\nthese lengths $< q$.\n  We generalize MDS Euclidean self-dual codes to near MDS Euclidean self-dual\ncodes and near MDS isodual codes.\n  And we obtain many new near MDS isodual codes from extended negacyclic duadic\ncodes and we obtain many new MDS Euclidean self-dual codes from MDS Euclidean\nself-dual codes.\n  We generalize MDS Hermitian self-dual codes to near MDS Hermitian self-dual\ncodes.\n  We obtain near MDS Hermitian self-dual codes from extended negacyclic duadic\ncodes and from MDS Hermitian self-dual codes. \n\n"}
{"id": "1609.05384", "contents": "Title: Spatiotemporal Stochastic Modeling of IoT Enabled Cellular Networks:\n  Scalability and Stability Analysis Abstract: The Internet of Things (IoT) is large-scale by nature, which is manifested by\nthe massive number of connected devices as well as their vast spatial\nexistence. Cellular networks, which provide ubiquitous, reliable, and efficient\nwireless access, are natural candidates to provide the first-mile access for\nthe data tsunami to be generated by the IoT. However, cellular networks may\nhave scalability problems to provide uplink connectivity to massive numbers of\nconnected things. To characterize the scalability of cellular uplink in the\ncontext of IoT networks, this paper develops a traffic-aware spatiotemporal\nmathematical model for IoT devices supported by cellular uplink connectivity.\nThe developed model is based on stochastic geometry and queueing theory to\naccount for the traffic requirement per IoT device, the different transmission\nstrategies, and the mutual interference between the IoT devices. To this end,\nthe developed model is utilized to characterize the extent to which cellular\nnetworks can accommodate IoT traffic as well as to assess and compare three\ndifferent transmission strategies that incorporate a combination of\ntransmission persistency, backoff, and power-ramping. The analysis and the\nresults clearly illustrate the scalability problem imposed by IoT on cellular\nnetwork and offer insights into effective scenarios for each transmission\nstrategy. \n\n"}
{"id": "1609.05490", "contents": "Title: Efficient Integer Coefficient Search for Compute-and-Forward Abstract: Integer coefficient selection is an important decoding step in the\nimplementation of compute-and-forward (C-F) relaying scheme. Choosing the\noptimal integer coefficients in C-F has been shown to be a shortest vector\nproblem (SVP) which is known to be NP hard in its general form. Exhaustive\nsearch of the integer coefficients is only feasible in complexity for small\nnumber of users while approximation algorithms such as Lenstra-Lenstra-Lovasz\n(LLL) lattice reduction algorithm only find a vector within an exponential\nfactor of the shortest vector. An optimal deterministic algorithm was proposed\nfor C-F by Sahraei and Gastpar specifically for the real valued channel case.\nIn this paper, we adapt their idea to the complex valued channel and propose an\nefficient search algorithm to find the optimal integer coefficient vectors over\nthe ring of Gaussian integers and the ring of Eisenstein integers. A second\nalgorithm is then proposed that generalises our search algorithm to the\nInteger-Forcing MIMO C-F receiver. Performance and efficiency of the proposed\nalgorithms are evaluated through simulations and theoretical analysis. \n\n"}
{"id": "1609.09594", "contents": "Title: The value of timing information in event-triggered control Abstract: We study event-triggered control for stabilization of unstable linear plants\nover rate-limited communication channels subject to unknown, bounded delay. On\none hand, the timing of event triggering carries implicit information about the\nstate of the plant. On the other hand, the delay in the communication channel\ncauses information loss, as it makes the state information available at the\ncontroller out of date. Combining these two effects, we show a phase transition\nbehavior in the transmission rate required for stabilization using a given\nevent-triggering strategy. For small values of the delay, the timing\ninformation carried by the triggering events is substantial, and the system can\nbe stabilized with any positive rate. When the delay exceeds a critical\nthreshold, the timing information alone is not enough to achieve stabilization\nand the required rate grows. When the loss of information due to the\ncommunication delay perfectly compensates the implicit information carried by\nthe triggering events, the delay equals the inverse of the entropy rate of the\nplant, and we obtain the same rate requirement prescribed by the data-rate\ntheorem. When the delay is larger than this threshold, the required rate\nbecomes larger than that required by the data-rate theorem. We also provide an\nexplicit construction yielding a sufficient rate for stabilization, and\ngeneralize our results to vector systems. The results do not rely on any a\npriori probabilistic model of the delay or the initial conditions. \n\n"}
{"id": "1610.00381", "contents": "Title: Covert Communications on Poisson Packet Channels Abstract: Consider a channel where authorized transmitter Jack sends packets to\nauthorized receiver Steve according to a Poisson process with rate $\\lambda$\npackets per second for a time period $T$. Suppose that covert transmitter Alice\nwishes to communicate information to covert receiver Bob on the same channel\nwithout being detected by a watchful adversary Willie. We consider two\nscenarios. In the first scenario, we assume that warden Willie cannot look at\npacket contents but rather can only observe packet timings, and Alice must send\ninformation by inserting her own packets into the channel. We show that the\nnumber of packets that Alice can covertly transmit to Bob is on the order of\nthe square root of the number of packets that Jack transmits to Steve;\nconversely, if Alice transmits more than that, she will be detected by Willie\nwith high probability. In the second scenario, we assume that Willie can look\nat packet contents but that Alice can communicate across an $M/M/1$ queue to\nBob by altering the timings of the packets going from Jack to Steve. First,\nAlice builds a codebook, with each codeword consisting of a sequence of packet\ntimings to be employed for conveying the information associated with that\ncodeword. However, to successfully employ this codebook, Alice must always have\na packet to send at the appropriate time. Hence, leveraging our result from the\nfirst scenario, we propose a construction where Alice covertly slows down the\npacket stream so as to buffer packets to use during a succeeding codeword\ntransmission phase. Using this approach, Alice can covertly and reliably\ntransmit $\\mathcal{O}(\\lambda T)$ covert bits to Bob in time period $T$ over an\n$M/M/1$ queue with service rate $\\mu > \\lambda$. \n\n"}
{"id": "1610.04924", "contents": "Title: An interleaver design for polar codes over slow fading channels Abstract: We consider the problem of using polar codes over slow fading wireless\nchannels. For design, we focus on a parallel slow fading channel with 2 blocks,\nand polar codes with rate <= 1/2. Motivated by Arikan's systematic polar code\nconstruction, we propose an interleaver design for a general polar code. The\ninterleaver comprises of using the bit reversal of the order of polarized bit\nchannels. This interleaver is called a diversity interleaver. In addition to\nthe diversity interleaver, a diversity polar code is proposed to further\nincrease the diversity gain.\n  The proposed designs are evaluated via link simulations for AWGN and fading\nchannels. The simulation results show a performance close to the outage\nprobability (within 2 dB) and significant gains over using a random\ninterleaver. \n\n"}
{"id": "1610.05961", "contents": "Title: Proximity-Aware Balanced Allocations in Cache Networks Abstract: We consider load balancing in a network of caching servers delivering\ncontents to end users. Randomized load balancing via the so-called power of two\nchoices is a well-known approach in parallel and distributed systems that\nreduces network imbalance. In this paper, we propose a randomized load\nbalancing scheme which simultaneously considers cache size limitation and\nproximity in the server redirection process.\n  Since the memory limitation and the proximity constraint cause correlation in\nthe server selection process, we may not benefit from the power of two choices\nin general. However, we prove that in certain regimes, in terms of memory\nlimitation and proximity constraint, our scheme results in the maximum load of\norder $\\Theta(\\log\\log n)$ (here $n$ is the number of servers and requests),\nand at the same time, leads to a low communication cost. This is an exponential\nimprovement in the maximum load compared to the scheme which assigns each\nrequest to the nearest available replica. Finally, we investigate our scheme\nperformance by extensive simulations. \n\n"}
{"id": "1610.06050", "contents": "Title: A 9.52 dB NCG FEC scheme and 164 bits/cycle low-complexity product\n  decoder architecture Abstract: Powerful Forward Error Correction (FEC) schemes are used in optical\ncommunications to achieve bit-error rates below $10^{-15}$. These FECs follow\none of two approaches: concatenation of simpler hard-decision codes or usage of\ninherently powerful soft-decision codes. The first approach yields lower Net\nCoding Gains (NCGs), but can usually work at higher code rates and have lower\ncomplexity decoders. In this work, we propose a novel FEC scheme based on a\nproduct code and a post-processing technique. It can achieve an NCG of 9.52~dB\nat a BER of $10^{-15}$ and 9.96~dB at a BER of $10^{-18}$, an error-correction\nperformance that sits between that of current hard-decision and soft-decision\nFECs. A decoder architecture is designed, tested on FPGA and synthesized in 65\nnm CMOS technology: its 164 bits/cycle worst-case information throughput can\nreach 100 Gb/s at the achieved frequency of 609~MHz. Its complexity is shown to\nbe lower than that of hard-decision decoders in literature, and an order of\nmagnitude lower than the estimated complexity of soft-decision decoders. \n\n"}
{"id": "1610.06995", "contents": "Title: Modeling and Analysis of Uplink Non-Orthogonal Multiple Access (NOMA) in\n  Large-Scale Cellular Networks Using Poisson Cluster Processes Abstract: Non-orthogonal multiple access (NOMA) serves multiple users by superposing\ntheir distinct message signals. The desired message signal is decoded at the\nreceiver by applying successive interference cancellation (SIC). Using the\ntheory of Poisson cluster process (PCP), we provide a framework to analyze\nmulti-cell uplink NOMA systems. Specifically, we characterize the rate coverage\nprobability of a NOMA user who is at rank $m$ (in terms of the distance from\nits serving BS) among all users in a cell and the mean rate coverage\nprobability of all users in a cell. Since the signal-to-interference-plus-noise\nratio (SINR) of $m$-th user relies on efficient SIC, we consider three\nscenarios, i.e., perfect SIC (in which the signals of $m-1$ interferers who are\nstronger than $m$-th user are decoded successfully), imperfect SIC (in which\nthe signals of of $m-1$ interferers who are stronger than $m$-th user may or\nmay not be decoded successfully), and imperfect worst case SIC (in which the\ndecoding of the signal of $m$-th user is always unsuccessful whenever the\ndecoding of its relative $m-1$ stronger users is unsuccessful). The derived\nexpressions are customized to capture the performance of a user at rank $m$ in\nan equivalent orthogonal multiple access (OMA) system. Finally, numerical\nresults are presented to validate the derived expressions. \n\n"}
{"id": "1610.07240", "contents": "Title: Are mmWave Low-Complexity Beamforming Structures Energy-Efficient?\n  Analysis of the Downlink MU-MIMO Abstract: Future cellular systems based on the use of above-6 GHz frequencies, the\nso-called millimeter wave (mmWave) bandwidths, will heavily rely on the use of\nantenna arrays both at the transmitter and at the receiver, possibly with a\nlarge number of elements. For complexity reasons, fully digital precoding and\npostcoding structures may turn out to be unfeasible, and thus suboptimal\nstructures, making use of simplified hardware and a limited number of RF\nchains, have been investigated. This paper considers and makes a comparative\nassessment, both from a spectral efficiency and energy efficiency point of\nview, of several suboptimal precoding and postcoding beamforming structures for\nthe downlink of a cellular multiuser MIMO (MU-MIMO) system. Based on the most\nrecently available data for the energy consumption of phase shifters and\nswitches, we show that there are cases where fully-digital beamformers may\nachieve a larger energy efficiency than lower-complexity solutions, as well as\nthat structures based on the exclusive use of switches achieve quite\nunsatisfactory performance in realistic scenarios. \n\n"}
{"id": "1610.07736", "contents": "Title: Construction of MDS self-dual codes from orthogonal matrices Abstract: In this paper, we give algorithms and methods of construction of self-dual\ncodes over finite fields using orthogonal matrices. Randomization in the\northogonal group, and code extension are the main tools. Some optimal, almost\nMDS, and MDS self-dual codes over both small and large prime fields are\nconstructed. \n\n"}
{"id": "1610.07740", "contents": "Title: MIMO Multiway Distributed-Relay Channel with Full Data Exchange: An\n  Achievable Rate Perspective Abstract: We consider efficient communications over the multiple-input multiple-output\n(MIMO) multiway distributed relay channel (MDRC) with full data exchange, where\neach user, equipped with multiple antennas, broadcasts its message to all the\nother users via the help of a number of distributive relays. We propose a\nphysical-layer network coding (PNC) based scheme involving linear precoding for\nchannel alignment nested lattice coding for PNC, and lattice-based precoding\nfor interference mitigation, We show that, with the proposed scheme,\ndistributed relaying achieves the same sum-rate as cooperative relaying in the\nhigh SNR regime. We also show that the proposed scheme achieve the asymptotic\nsum capacity of the MIMO MDRC within a constant gap at high SNR. Numerical\nresults demonstrate that the proposed scheme considerably outperforms the\nexisting schemes including decode-and-forward and amplify-and-forward. \n\n"}
{"id": "1610.08026", "contents": "Title: Improved Upper Bounds on Systematic-Length for Linear Minimum Storage\n  Regenerating Codes Abstract: In this paper, we revisit the problem of finding the longest\nsystematic-length $k$ for a linear minimum storage regenerating (MSR) code with\noptimal repair of only systematic part, for a given per-node storage capacity\n$l$ and an arbitrary number of parity nodes $r$. We study the problem by\nfollowing a geometric analysis of linear subspaces and operators. First, a\nsimple quadratic bound is given, which implies that $k=r+2$ is the largest\nnumber of systematic nodes in the \\emph{scalar} scenario. Second, an\n$r$-based-log bound is derived, which is superior to the upper bound on\nlog-base $2$ in the prior work. Finally, an explicit upper bound depending on\nthe value of $\\frac{r^2}{l}$ is introduced, which further extends the\ncorresponding result in the literature. \n\n"}
{"id": "1610.09453", "contents": "Title: Degrees of Freedom in Wireless Interference Networks with Cooperative\n  Transmission and Backhaul Load Constraints Abstract: Degrees of freedom (DoF) gains are studied in wireless networks with\ncooperative transmission under a backhaul load constraint that limits the\naverage number of messages that can be delivered from a centralized controller\nto base station transmitters. The backhaul load is defined as the sum of all\nthe messages available at all the transmitters per channel use, normalized by\nthe number of users. For Wyner's linear interference network, where each\ntransmitter is connected to the receiver having the same index as well as one\nsucceeding receiver, the per user DoF is characterized and the optimal scheme\nis presented. Furthermore, it is shown that the optimal assignment of messages\nto transmitters is asymmetric and satisfies a local cooperation constraint, and\nthat the optimal coding scheme relies only on one-shot cooperative zero-forcing\ntransmit beamforming. Using insights from the analysis of Wyner's linear\ninterference network, the results are extended to the more practical hexagonal\nsectored cellular network, and coding schemes based on cooperative zero-forcing\nare shown to deliver significant DoF gains. It is established that by allowing\nfor cooperative transmission and a flexible message assignment that is\nconstrained only by an average backhaul load, one can deliver the rate gains\npromised by information-theoretic upper bounds with practical one-shot schemes\nthat incur little or no additional load on the backhaul. Finally, useful upper\nbounds on the per user DoF for schemes based on cooperative zero-forcing are\npresented for lower values of the average backhaul load constraint, and an\noptimization framework is formulated for the general converse problem. \n\n"}
{"id": "1611.00297", "contents": "Title: Generalized Entropy Concentration for Counts Abstract: The phenomenon of entropy concentration provides strong support for the\nmaximum entropy method, MaxEnt, for inferring a probability vector from\ninformation in the form of constraints. Here we extend this phenomenon, in a\ndiscrete setting, to non-negative integral vectors not necessarily summing to\n1. We show that linear constraints that simply bound the allowable sums suffice\nfor concentration to occur even in this setting. This requires a new,\n`generalized' entropy measure in which the sum of the vector plays a role. We\nmeasure the concentration in terms of deviation from the maximum generalized\nentropy value, or in terms of the distance from the maximum generalized entropy\nvector. We provide non-asymptotic bounds on the concentration in terms of\nvarious parameters, including a tolerance on the constraints which ensures that\nthey are always satisfied by an integral vector. Generalized entropy\nmaximization is not only compatible with ordinary MaxEnt, but can also be\nconsidered an extension of it, as it allows us to address problems that cannot\nbe formulated as MaxEnt problems. \n\n"}
{"id": "1611.01042", "contents": "Title: Multi-Way Massive MIMO with Maximum-Ratio Processing and Imperfect CSI Abstract: This paper considers a multi-way massive multiple-input multiple-output\nrelaying system, where single-antenna users exchange their information-bearing\nsignals with the help of one relay station equipped with unconventionally many\nantennas. The relay first estimates the channels to all users through the pilot\nsignals transmitted from them. Then, the relay uses maximum-ratio processing\n(i.e. maximum-ratio combining in the multiple-access phase and maximum-ratio\ntransmission in the broadcast phase) to process the signals. A rigorous\nclosed-form expression for the spectral efficiency is derived. The effects of\nthe channel estimation error, the channel estimation overhead, the length of\nthe training duration, and the randomness of the user locations are analyzed.\nWe show that by deploying massive antenna arrays at the relay and simple\nmaximum-ratio processing, we can serve many users in the same time-frequency\nresource, while maintaining a given quality-of-service for each user. \n\n"}
{"id": "1611.01704", "contents": "Title: End-to-end Optimized Image Compression Abstract: We describe an image compression method, consisting of a nonlinear analysis\ntransformation, a uniform quantizer, and a nonlinear synthesis transformation.\nThe transforms are constructed in three successive stages of convolutional\nlinear filters and nonlinear activation functions. Unlike most convolutional\nneural networks, the joint nonlinearity is chosen to implement a form of local\ngain control, inspired by those used to model biological neurons. Using a\nvariant of stochastic gradient descent, we jointly optimize the entire model\nfor rate-distortion performance over a database of training images, introducing\na continuous proxy for the discontinuous loss function arising from the\nquantizer. Under certain conditions, the relaxed loss function may be\ninterpreted as the log likelihood of a generative model, as implemented by a\nvariational autoencoder. Unlike these models, however, the compression model\nmust operate at any given point along the rate-distortion curve, as specified\nby a trade-off parameter. Across an independent set of test images, we find\nthat the optimized method generally exhibits better rate-distortion performance\nthan the standard JPEG and JPEG 2000 compression methods. More importantly, we\nobserve a dramatic improvement in visual quality for all images at all bit\nrates, which is supported by objective quality estimates using MS-SSIM. \n\n"}
{"id": "1611.02733", "contents": "Title: Minimum node degree in inhomogeneous random key graphs with unreliable\n  links Abstract: We consider wireless sensor networks under a heterogeneous random key\npredistribution scheme and an on-off channel model. The heterogeneous key\npredistribution scheme has recently been introduced by Ya\\u{g}an - as an\nextension to the Eschenauer and Gligor scheme - for the cases when the network\nconsists of sensor nodes with varying level of resources and/or connectivity\nrequirements, e.g., regular nodes vs. cluster heads. The network is modeled by\nthe intersection of the inhomogeneous random key graph (induced by the\nheterogeneous scheme) with an Erd\\H{o}s-R\\'enyi graph (induced by the on/off\nchannel model). We present conditions (in the form of zero-one laws) on how to\nscale the parameters of the intersection model so that with high probability\nall of its nodes are connected to at least $k$ other nodes; i.e., the minimum\nnode degree of the graph is no less than $k$. We also present numerical results\nto support our results in the finite-node regime. The numerical results suggest\nthat the conditions that ensure $k$-connectivity coincide with those ensuring\nthe minimum node degree being no less than $k$. \n\n"}
{"id": "1611.03046", "contents": "Title: Channel Estimation for Hybrid Architecture Based Wideband Millimeter\n  Wave Systems Abstract: Hybrid analog and digital precoding allows millimeter wave (mmWave) systems\nto achieve both array and multiplexing gain. The design of the hybrid precoders\nand combiners, though, is usually based on knowledge of the channel. Prior work\non mmWave channel estimation with hybrid architectures focused on narrowband\nchannels. Since mmWave systems will be wideband with frequency selectivity, it\nis vital to develop channel estimation solutions for hybrid architectures based\nwideband mmWave systems. In this paper, we develop a sparse formulation and\ncompressed sensing based solutions for the wideband mmWave channel estimation\nproblem for hybrid architectures. First, we leverage the sparse structure of\nthe frequency selective mmWave channels and formulate the channel estimation\nproblem as a sparse recovery in both time and frequency domains. Then, we\npropose explicit channel estimation techniques for purely time or frequency\ndomains and for combined time/frequency domains. Our solutions are suitable for\nboth SC-FDE and OFDM systems. Simulation results show that the proposed\nsolutions achieve good channel estimation quality, while requiring small\ntraining overhead. Leveraging the hybrid architecture at the transceivers gives\nfurther improvement in estimation error performance and achievable rates. \n\n"}
{"id": "1611.04212", "contents": "Title: Millimeter Wave Beam Alignment: Large Deviations Analysis and Design\n  Insights Abstract: In millimeter wave cellular communication, fast and reliable beam alignment\nvia beam training is crucial to harvest sufficient beamforming gain for the\nsubsequent data transmission. In this paper, we establish fundamental limits in\nbeam-alignment performance under both the exhaustive search and the\nhierarchical search that adopts multi-resolution beamforming codebooks,\naccounting for time-domain training overhead. Specifically, we derive lower and\nupper bounds on the probability of misalignment for an arbitrary level in the\nhierarchical search, based on a single-path channel model. Using the method of\nlarge deviations, we characterize the decay rate functions of both bounds and\nshow that the bounds coincide as the training sequence length goes large. We go\non to characterize the asymptotic misalignment probability of both the\nhierarchical and exhaustive search, and show that the latter asymptotically\noutperforms the former, subject to the same training overhead and codebook\nresolution. We show via numerical results that this relative performance\nbehavior holds in the non-asymptotic regime. Moreover, the exhaustive search is\nshown to achieve significantly higher worst-case spectrum efficiency than the\nhierarchical search, when the pre-beamforming signal-to-noise ratio (SNR) is\nrelatively low. This study hence implies that the exhaustive search is more\neffective for users situated further from base stations, as they tend to have\nlow SNR. \n\n"}
{"id": "1611.08267", "contents": "Title: Finite-Length Analysis of Spatially-Coupled Regular LDPC Ensembles on\n  Burst-Erasure Channels Abstract: Regular spatially-Coupled LDPC (SC-LDPC) ensembles have gained significant\ninterest since they were shown to universally achieve the capacity of binary\nmemoryless channels under low-complexity belief-propagation decoding. In this\nwork, we focus primarily on the performance of these ensembles over binary\nchannels affected by bursts of erasures. We first develop an analysis of the\nfinite length performance for a single burst per codeword and no errors\notherwise. We first assume that the burst erases a complete spatial position,\nmodeling for instance node failures in distributed storage. We provide new\ntight lower bounds for the block erasure probability ($P_{\\mathrm{B}}$) at\nfinite block length and bounds on the coupling parameter for being\nasymptotically able to recover the burst. We further show that expurgating the\nensemble can improve the block erasure probability by several orders of\nmagnitude. Later we extend our methodology to more general channel models. In a\nfirst extension, we consider bursts that can start at a random position in the\ncodeword and span across multiple spatial positions. Besides the finite length\nanalysis, we determine by means of density evolution the maximnum correctable\nburst length. In a second extension, we consider the case where in addition to\na single burst, random bit erasures may occur. Finally, we consider a block\nerasure channel model which erases each spatial position independently with\nsome probability $p$, potentially introducing multiple bursts simultaneously.\nAll results are verified using Monte-Carlo simulations. \n\n"}
{"id": "1611.09914", "contents": "Title: Batch and PIR Codes and Their Connections to Locally Repairable Codes Abstract: In this survey, two related families of codes are discussed: batch codes and\ncodes for private information retrieval. These two families can be viewed as\nnatural generalizations of locally repairable codes, which were extensively\nstudied in the context of coding for fault tolerance in distributed data\nstorage systems. Bounds on the parameters of the codes, as well as basic\nconstructions, are presented. Connections between different code families are\ndiscussed. \n\n"}
{"id": "1612.00130", "contents": "Title: Secure Polar Coding for the Two-Way Wiretap Channel Abstract: We consider the problem of polar coding for secure communications over the\ntwo-way wiretap channel, where two legitimate users communicate with each other\nsimultaneously while a passive eavesdropper overhears a combination of their\nexchanged signals. The legitimate users wish to design a cooperative jamming\ncode such that the interference between their codewords can jam the\neavesdropper. In this paper, we design a polar coded cooperative jamming scheme\nthat achieves the whole secrecy rate region of the general two-way wiretap\nchannel under the strong secrecy criterion. The chaining method is used to make\nproper alignment of polar indices. The randomness required to be shared between\ntwo legitimate users is treated as a limited resource and we show that its rate\ncan be made negligible by increasing the blocklength and the number of chained\nblocks. For the special case when the eavesdropper channel is degraded with\nrespect to the legitimate ones, a simplified scheme is proposed which can\nsimultaneously ensure reliability and weak secrecy within a single transmission\nblock. An example of the binary erasure channel case is given to demonstrate\nthe performance of our scheme. \n\n"}
{"id": "1612.01361", "contents": "Title: Repairing Reed-Solomon Codes With Multiple Erasures Abstract: Despite their exceptional error-correcting properties, Reed-Solomon codes\nhave been overlooked in distributed storage applications due to the common\nbelief that they have poor repair bandwidth: A naive repair approach would\nrequire the whole file to be reconstructed in order to recover a single erased\ncodeword symbol. In a recent work, Guruswami and Wootters (STOC'16) proposed a\nsingle-erasure repair method for Reed-Solomon codes that achieves the optimal\nrepair bandwidth amongst all linear encoding schemes. Their key idea is to\nrecover the erased symbol by collecting a sufficiently large number of its\ntraces, each of which can be constructed from a number of traces of other\nsymbols. We extend the trace collection technique to cope with two and three\nerasures. \n\n"}
{"id": "1612.03164", "contents": "Title: Square Hellinger Subadditivity for Bayesian Networks and its\n  Applications to Identity Testing Abstract: We show that the square Hellinger distance between two Bayesian networks on\nthe same directed graph, $G$, is subadditive with respect to the neighborhoods\nof $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two\nBayesian networks on the same DAG, our inequality states that the square\nHellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the\nsum, $\\sum_v H^2(P_{\\{v\\} \\cup \\Pi_v}, Q_{\\{v\\} \\cup \\Pi_v})$, of the square\nHellinger distances between the marginals of $P$ and $Q$ on every node $v$ and\nits parents $\\Pi_v$ in the DAG. Importantly, our bound does not involve the\nconditionals but the marginals of $P$ and $Q$. We derive a similar inequality\nfor more general Markov Random Fields.\n  As an application of our inequality, we show that distinguishing whether two\nBayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy\n$P=Q$ vs $d_{\\rm TV}(P,Q)>\\epsilon$ can be performed from\n$\\tilde{O}(|\\Sigma|^{3/4(d+1)} \\cdot n/\\epsilon^2)$ samples, where $d$ is the\nmaximum in-degree of the DAG and $\\Sigma$ the domain of each variable of the\nBayesian networks. If $P$ and $Q$ are defined on potentially different and\npotentially unknown trees, the sample complexity becomes\n$\\tilde{O}(|\\Sigma|^{4.5} n/\\epsilon^2)$, whose dependence on $n, \\epsilon$ is\noptimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product\ndistributions over $\\{0,1\\}^n$ and $Q$ is known, the sample complexity becomes\n$O(\\sqrt{n}/\\epsilon^2)$, which is optimal up to constant factors. \n\n"}
{"id": "1612.04703", "contents": "Title: Lexicodes over Finite Principal Left Ideal Rings Abstract: Let R be a finite principal left ideal ring. Via a total ordering of the ring\nelements and an ordered basis a lexicographic ordering of the module R^n is\nproduced. This is used to set up a greedy algorithm that selects vectors for\nwhich all linear combination with the previously selected vectors satisfy a\npre-specified selection property and updates the to-be-constructed code to the\nlinear hull of the vectors selected so far. The output is called a lexicode.\nThis process was discussed earlier in the literature for fields and chain\nrings. In this paper we investigate the properties of such lexicodes over\nfinite principal left ideal rings and show that the total ordering of the ring\nelements has to respect containment of ideals in order for the algorithm to\nproduce meaningful results. Only then it is guaranteed that the algorithm is\nexhaustive and thus produces codes that are maximal with respect to inclusion.\nIt is further illustrated that the output of the algorithm heavily depends on\nthe total ordering and chosen basis. \n\n"}
{"id": "1612.05523", "contents": "Title: Two-weight codes from trace codes over $R_k$ Abstract: We construct a family of two-Lee-weight codes over the ring $R_k,$ which is\ndefined as trace codes with algebraic structure of abelian codes. The Lee\nweight distribution of the two-weight codes is given. Taking the Gray map, we\nobtain optimal abelian binary two-weight codes by using the Griesmer bound. An\napplication to secret sharing schemes is also given. \n\n"}
{"id": "1612.06339", "contents": "Title: Randomized Learning of the Second-Moment Matrix of a Smooth Function Abstract: Consider an open set $\\mathbb{D}\\subseteq\\mathbb{R}^n$, equipped with a\nprobability measure $\\mu$. An important characteristic of a smooth function\n$f:\\mathbb{D}\\rightarrow\\mathbb{R}$ is its \\emph{second-moment matrix}\n$\\Sigma_{\\mu}:=\\int \\nabla f(x) \\nabla f(x)^* \\mu(dx) \\in\\mathbb{R}^{n\\times\nn}$, where $\\nabla f(x)\\in\\mathbb{R}^n$ is the gradient of $f(\\cdot)$ at\n$x\\in\\mathbb{D}$ and $*$ stands for transpose. For instance, the span of the\nleading $r$ eigenvectors of $\\Sigma_{\\mu}$ forms an \\emph{active subspace} of\n$f(\\cdot)$, which contains the directions along which $f(\\cdot)$ changes the\nmost and is of particular interest in \\emph{ridge approximation}. In this work,\nwe propose a simple algorithm for estimating $\\Sigma_{\\mu}$ from random point\nevaluations of $f(\\cdot)$ \\emph{without} imposing any structural assumptions on\n$\\Sigma_{\\mu}$. Theoretical guarantees for this algorithm are established with\nthe aid of the same technical tools that have proved valuable in the context of\ncovariance matrix estimation from partial measurements. \n\n"}
{"id": "1612.08459", "contents": "Title: Thermodynamics of Random Number Generation Abstract: We analyze the thermodynamic costs of the three main approaches to generating\nrandom numbers via the recently introduced Information Processing Second Law.\nGiven access to a specified source of randomness, a random number generator\n(RNG) produces samples from a desired target probability distribution. This\ndiffers from pseudorandom number generators (PRNG) that use wholly\ndeterministic algorithms and from true random number generators (TRNG) in which\nthe randomness source is a physical system. For each class, we analyze the\nthermodynamics of generators based on algorithms implemented as finite-state\nmachines, as these allow for direct bounds on the required physical resources.\nThis establishes bounds on heat dissipation and work consumption during the\noperation of three main classes of RNG algorithms---including those of von\nNeumann, Knuth and Yao, and Roche and Hoshi---and for PRNG methods. We\nintroduce a general TRNG and determine its thermodynamic costs exactly for\narbitrary target distributions. The results highlight the significant\ndifferences between the three main approaches to random number generation: One\nis work producing, one is work consuming, and the other is potentially\ndissipation neutral. Notably, TRNGs can both generate random numbers and\nconvert thermal energy to stored work. These thermodynamic costs on information\ncreation complement Landauer's limit on the irreducible costs of information\ndestruction. \n\n"}
{"id": "1612.09027", "contents": "Title: On Covert Communication with Noise Uncertainty Abstract: Prior studies on covert communication with noise uncertainty adopted a\nworst-case approach from the warden's perspective. That is, the worst-case\ndetection performance of the warden is used to assess covertness, which is\noverly optimistic. Instead of simply considering the worst limit, in this work,\nwe take the distribution of noise uncertainty into account to evaluate the\noverall covertness in a statistical sense. Specifically, we define new metrics\nfor measuring the covertness, which are then adopted to analyze the maximum\nachievable rate for a given covertness requirement under both bounded and\nunbounded noise uncertainty models. \n\n"}
{"id": "1701.00365", "contents": "Title: Beam-On-Graph: Simultaneous Channel Estimation for mmWave MIMO Systems\n  with Multiple Users Abstract: This paper is concerned with the channel estimation problem in multi-user\nmillimeter wave (mmWave) wireless systems with large antenna arrays. We develop\na novel simultaneous-estimation with iterative fountain training (SWIFT)\nframework, in which multiple users estimate their channels at the same time and\nthe required number of channel measurements is adapted to various channel\nconditions of different users. To achieve this, we represent the beam direction\nestimation process by a graph, referred to as the beam-on-graph, and associate\nthe channel estimation process with a code-on-graph decoding problem.\nSpecifically, the base station (BS) and each user measure the channel with a\nseries of random combinations of transmit/receive beamforming vectors until the\nchannel estimate converges. As the proposed SWIFT does not adapt the BS's beams\nto any single user, we are able to estimate all user channels simultaneously.\nSimulation results show that SWIFT can significantly outperform the existing\nrandom beamforming-based approaches, which use a predetermined number of\nmeasurements, over a wide range of signal-to-noise ratios and channel coherence\ntime. Furthermore, by utilizing the users' order in terms of completing their\nchannel estimation, our SWIFT framework can infer the sequence of users'\nchannel quality and perform effective user scheduling to achieve superior\nperformance. \n\n"}
{"id": "1701.00858", "contents": "Title: Constrained Low-rank Matrix Estimation: Phase Transitions, Approximate\n  Message Passing and Applications Abstract: This article is an extended version of previous work of the authors [40, 41]\non low-rank matrix estimation in the presence of constraints on the factors\ninto which the matrix is factorized. Low-rank matrix factorization is one of\nthe basic methods used in data analysis for unsupervised learning of relevant\nfeatures and other types of dimensionality reduction. We present a framework to\nstudy the constrained low-rank matrix estimation for a general prior on the\nfactors, and a general output channel through which the matrix is observed. We\ndraw a paralel with the study of vector-spin glass models - presenting a\nunifying way to study a number of problems considered previously in separate\nstatistical physics works. We present a number of applications for the problem\nin data analysis. We derive in detail a general form of the low-rank\napproximate message passing (Low- RAMP) algorithm, that is known in statistical\nphysics as the TAP equations. We thus unify the derivation of the TAP equations\nfor models as different as the Sherrington-Kirkpatrick model, the restricted\nBoltzmann machine, the Hopfield model or vector (xy, Heisenberg and other) spin\nglasses. The state evolution of the Low-RAMP algorithm is also derived, and is\nequivalent to the replica symmetric solution for the large class of vector-spin\nglass models. In the section devoted to result we study in detail phase\ndiagrams and phase transitions for the Bayes-optimal inference in low-rank\nmatrix estimation. We present a typology of phase transitions and their\nrelation to performance of algorithms such as the Low-RAMP or commonly used\nspectral methods. \n\n"}
{"id": "1701.01981", "contents": "Title: Guessing Attacks on Distributed-Storage Systems Abstract: The secrecy of a distributed-storage system for passwords is studied. The\nencoder, Alice, observes a length-n password and describes it using two hints,\nwhich she stores in different locations. The legitimate receiver, Bob, observes\nboth hints. In one scenario the requirement is that the expected number of\nguesses it takes Bob to guess the password approach one as n tends to infinity,\nand in the other that the expected size of the shortest list that Bob must form\nto guarantee that it contain the password approach one. The eavesdropper, Eve,\nsees only one of the hints. Assuming that Alice cannot control which hints Eve\nobserves, the largest normalized (by n) exponent that can be guaranteed for the\nexpected number of guesses it takes Eve to guess the password is characterized\nfor each scenario. Key to the proof are new results on Arikan's guessing and\nBunte and Lapidoth's task-encoding problem; in particular, the paper\nestablishes a close relation between the two problems. A rate-distortion\nversion of the model is also discussed, as is a generalization that allows for\nAlice to produce {\\delta} (not necessarily two) hints, for Bob to observe {\\nu}\n(not necessarily two) of the hints, and for Eve to observe {\\eta} (not\nnecessarily one) of the hints. The generalized model is robust against {\\delta}\n- {\\nu} disk failures. \n\n"}
{"id": "1701.02054", "contents": "Title: Unitary Reconstruction of Secret for Stabilizer Based Quantum Secret\n  Sharing Abstract: We propose a unitary procedure to reconstruct quantum secret for a quantum\nsecret sharing scheme constructed from stabilizer quantum error-correcting\ncodes. Erasure correcting procedures for stabilizer codes need to add missing\nshares for reconstruction of quantum secret while unitary reconstruction\nprocedures for certain class of quantum secret sharing are known to work\nwithout adding missing shares. The proposed procedure also works without adding\nmissing shares. \n\n"}
{"id": "1701.02345", "contents": "Title: Sliding-Window Superposition Coding:Two-User Interference Channels Abstract: A low-complexity coding scheme is developed to achieve the rate region of\nmaximum likelihood decoding for interference channels. As in the classical\nrate-splitting multiple access scheme by Grant, Rimoldi, Urbanke, and Whiting,\nthe proposed coding scheme uses superposition of multiple codewords with\nsuccessive cancellation decoding, which can be implemented using standard\npoint-to-point encoders and decoders. Unlike rate-splitting multiple access,\nwhich is not rate-optimal for multiple receivers, the proposed coding scheme\ntransmits codewords over multiple blocks in a staggered manner and recovers\nthem successively over sliding decoding windows, achieving the single-stream\noptimal rate region as well as the more general Han--Kobayashi inner bound for\nthe two-user interference channel. The feasibility of this scheme in practice\nis verified by implementing it using commercial channel codes over the two-user\nGaussian interference channel. \n\n"}
{"id": "1701.02831", "contents": "Title: On the Uniqueness of FROG Methods Abstract: The problem of recovering a signal from its power spectrum, called phase\nretrieval, arises in many scientific fields. One of many examples is\nultra-short laser pulse characterization in which the electromagnetic field is\noscillating with ~10^15 Hz and phase information cannot be measured directly\ndue to limitations of the electronic sensors. Phase retrieval is ill-posed in\nmost cases as there are many different signals with the same Fourier transform\nmagnitude. To overcome this fundamental ill-posedness, several measurement\ntechniques are used in practice. One of the most popular methods for complete\ncharacterization of ultra-short laser pulses is the Frequency-Resolved Optical\nGating (FROG). In FROG, the acquired data is the power spectrum of the product\nof the unknown pulse with its delayed replica. Therefore the measured signal is\na quartic function of the unknown pulse. A generalized version of FROG, where\nthe delayed replica is replaced by a second unknown pulse, is called blind\nFROG. In this case, the measured signal is quadratic with respect to both\npulses. In this letter we introduce and formulate FROG-type techniques. We then\nshow that almost all band-limited signals are determined uniquely, up to\ntrivial ambiguities, by blind FROG measurements (and thus also by FROG), if in\naddition we have access to the signals power spectrum. \n\n"}
{"id": "1701.02979", "contents": "Title: Multi-Antenna Coded Caching Abstract: In this paper we consider a single-cell downlink scenario where a\nmultiple-antenna base station delivers contents to multiple cache-enabled user\nterminals. Based on the multicasting opportunities provided by the so-called\nCoded Caching technique, we investigate three delivery approaches. Our baseline\nscheme employs the coded caching technique on top of max-min fair multicasting.\nThe second one consists of a joint design of Zero-Forcing (ZF) and coded\ncaching, where the coded chunks are formed in the signal domain (complex\nfield). The third scheme is similar to the second one with the difference that\nthe coded chunks are formed in the data domain (finite field). We derive\nclosed-form rate expressions where our results suggest that the latter two\nschemes surpass the first one in terms of Degrees of Freedom (DoF). However, at\nthe intermediate SNR regime forming coded chunks in the signal domain results\nin power loss, and will deteriorate throughput of the second scheme. The main\nmessage of our paper is that the schemes performing well in terms of DoF may\nnot be directly appropriate for intermediate SNR regimes, and modified schemes\nshould be employed. \n\n"}
{"id": "1701.03023", "contents": "Title: On the Tradeoff Region of Secure Exact-Repair Regenerating Codes Abstract: We consider the $(n,k,d,\\ell)$ secure exact-repair regenerating code problem,\nwhich generalizes the $(n,k,d)$ exact-repair regenerating code problem with the\nadditional constraint that the stored file needs to be kept\ninformation-theoretically secure against an eavesdropper, who can access the\ndata transmitted to regenerate a total of $\\ell$ different failed nodes. For\nall known results on this problem, the achievable tradeoff regions between the\nnormalized storage capacity and repair bandwidth have a single corner point,\nachieved by a scheme proposed by Shah, Rashmi and Kumar (the SRK point). Since\nthe achievable tradeoff regions of the exact-repair regenerating code problem\nwithout any secrecy constraints are known to have multiple corner points in\ngeneral, these existing results suggest a phase-change-like behavior, i.e.,\nenforcing a secrecy constraint ($\\ell\\geq 1$) immediately reduces the tradeoff\nregion to one with a single corner point. In this work, we first show that when\nthe secrecy parameter $\\ell$ is sufficiently large, the SRK point is indeed the\nonly corner point of the tradeoff region. However, when $\\ell$ is small, we\nshow that the tradeoff region can in fact have multiple corner points. In\nparticular, we establish a precise characterization of the tradeoff region for\nthe $(7,6,6,1)$ problem, which has exactly two corner points. Thus, a smooth\ntransition, instead of a phase-change-type of transition, should be expected as\nthe secrecy constraint is gradually strengthened. \n\n"}
{"id": "1701.03135", "contents": "Title: Guaranteed recovery of quantum processes from few measurements Abstract: Quantum process tomography is the task of reconstructing unknown quantum\nchannels from measured data. In this work, we introduce compressed\nsensing-based methods that facilitate the reconstruction of quantum channels of\nlow Kraus rank. Our main contribution is the analysis of a natural measurement\nmodel for this task: We assume that data is obtained by sending pure states\ninto the channel and measuring expectation values on the output. Neither\nancillary systems nor coherent operations across multiple channel uses are\nrequired. Most previous results on compressed process reconstruction reduce the\nproblem to quantum state tomography on the channel's Choi matrix. While this\nansatz yields recovery guarantees from an essentially minimal number of\nmeasurements, physical implementations of such schemes would typically involve\nancillary systems. A priori, it is unclear whether a measurement model tailored\ndirectly to quantum process tomography might require more measurements. We\nestablish that this is not the case. Technically, we prove recovery guarantees\nfor three different reconstruction algorithms. The reconstructions are based on\na trace, diamond, and $\\ell_2$-norm minimization, respectively. Our recovery\nguarantees are uniform in the sense that with one random choice of measurement\nsettings all quantum channels can be recovered equally well. Moreover,\nstability against arbitrary measurement noise and robustness against violations\nof the low-rank assumption is guaranteed. Numerical studies demonstrate the\nfeasibility of the approach. \n\n"}
{"id": "1701.03195", "contents": "Title: Moderate Deviation Analysis for Classical-Quantum Channels and Quantum\n  Hypothesis Testing Abstract: In this work, we study the tradeoffs between the error probabilities of\nclassical-quantum channels and the blocklength $n$ when the transmission rates\napproach the channel capacity at a rate slower than $1/\\sqrt{n}$, a research\ntopic known as moderate deviation analysis. We show that the optimal error\nprobability vanishes under this rate convergence. Our main technical\ncontributions are a tight quantum sphere-packing bound, obtained via Chaganty\nand Sethuraman's concentration inequality in strong large deviation theory, and\nasymptotic expansions of error-exponent functions. Moderate deviation analysis\nfor quantum hypothesis testing is also established. The converse directly\nfollows from our channel coding result, while the achievability relies on a\nmartingale inequality. \n\n"}
{"id": "1701.03247", "contents": "Title: Scalable Spectrum Allocation and User Association in Networks with Many\n  Small Cells Abstract: A scalable framework is developed to allocate radio resources across a large\nnumber of densely deployed small cells with given traffic statistics on a slow\ntimescale. Joint user association and spectrum allocation is first formulated\nas a convex optimization problem by dividing the spectrum among all possible\ntransmission patterns of active access points (APs). To improve scalability\nwith the number of APs, the problem is reformulated using local patterns of\ninterfering APs. To maintain global consistency among local patterns,\ninter-cluster interaction is characterized as hyper-edges in a hyper-graph with\nnodes corresponding to neighborhoods of APs. A scalable solution is obtained by\niteratively solving a convex optimization problem for bandwidth allocation with\nreduced complexity and constructing a global spectrum allocation using\nhyper-graph coloring. Numerical results demonstrate the proposed solution for a\nnetwork with 100 APs and several hundred user equipments. For a given quality\nof service (QoS), the proposed scheme can increase the network capacity several\nfold compared to assigning each user to the strongest AP with full-spectrum\nreuse. \n\n"}
{"id": "1701.03403", "contents": "Title: K-means Algorithm over Compressed Binary Data Abstract: We consider a network of binary-valued sensors with a fusion center. The\nfusion center has to perform K-means clustering on the binary data transmitted\nby the sensors. In order to reduce the amount of data transmitted within the\nnetwork, the sensors compress their data with a source coding scheme based on\nbinary sparse matrices. We propose to apply the K-means algorithm directly over\nthe compressed data without reconstructing the original sensors measurements,\nin order to avoid potentially complex decoding operations. We provide\napproximated expressions of the error probabilities of the K-means steps in the\ncompressed domain. From these expressions, we show that applying the K-means\nalgorithm in the compressed domain enables to recover the clusters of the\noriginal domain. Monte Carlo simulations illustrate the accuracy of the\nobtained approximated error probabilities, and show that the coding rate needed\nto perform K-means clustering in the compressed domain is lower than the rate\nneeded to reconstruct all the measurements. \n\n"}
{"id": "1701.04187", "contents": "Title: Control Capacity Abstract: Feedback control actively dissipates uncertainty from a dynamical system by\nmeans of actuation. We develop a notion of \"control capacity\" that gives a\nfundamental limit (in bits) on the rate at which a controller can dissipate the\nuncertainty from a system, i.e. stabilize to a known fixed point. We give a\ncomputable single-letter characterization of control capacity for memoryless\nstationary scalar multiplicative actuation channels. Control capacity allows us\nto answer questions of stabilizability for scalar linear systems: a system with\nactuation uncertainty is stabilizable if and only if the control capacity is\nlarger than the log of the unstable open-loop eigenvalue.\n  For second-moment senses of stability, we recover the classic uncertainty\nthreshold principle result. However, our definition of control capacity can\nquantify the stabilizability limits for any moment of stability. Our\nformulation parallels the notion of Shannon's communication capacity, and thus\nyields both a strong converse and a way to compute the value of\nside-information in control. The results in our paper are motivated by\nbit-level models for control that build on the deterministic models that are\nwidely used to understand information flows in wireless network information\ntheory. \n\n"}
{"id": "1701.04466", "contents": "Title: Continuity of Channel Parameters and Operations under Various DMC\n  Topologies Abstract: We study the continuity of many channel parameters and operations under\nvarious topologies on the space of equivalent discrete memoryless channels\n(DMC). We show that mutual information, channel capacity, Bhattacharyya\nparameter, probability of error of a fixed code, and optimal probability of\nerror for a given code rate and blocklength, are continuous under various DMC\ntopologies. We also show that channel operations such as sums, products,\ninterpolations, and Ar{\\i}kan-style transformations are continuous. \n\n"}
{"id": "1701.04901", "contents": "Title: Multi-channel Sensing And Resource Allocation in Energy Constrained\n  Cognitive Radio Networks Abstract: We consider a cognitive radio network in a multi-channel licensed\nenvironment. Secondary user transmits in a channel if the channel is sensed to\nbe vacant. This results in a tradeoff between sensing time and transmission\ntime. When secondary users are energy constrained, energy available for\ntransmission is less if more energy is used in sensing. This gives rise to an\nenergy tradeoff. For multiple primary channels, secondary users must decide\nappropriate sensing time and transmission power in each channel to maximize\naverage aggregate-bit throughput in each frame duration while ensuring\nquality-of-service of primary users. Considering time and energy as limited\nresources, we formulate this problem as a resource allocation problem.\nInitially a single secondary user scenario is considered and solution is\nobtained using decomposition and alternating optimization techniques. Later we\nextend the analysis for the case of multiple secondary users. Simulation\nresults are presented to study effect of channel occupancy, fading and energy\navailability on performance of proposed method. \n\n"}
{"id": "1701.06303", "contents": "Title: Delivery Latency Trade-Offs of Heterogeneous Contents in Fog Radio\n  Access Networks Abstract: A Fog Radio Access Network (F-RAN) is a cellular wireless system that enables\ncontent delivery via the caching of popular content at edge nodes (ENs) and\ncloud processing. The existing information-theoretic analyses of F-RAN systems,\nand special cases thereof, make the assumption that all requests should be\nguaranteed the same delivery latency, which results in identical latency for\nall files in the content library. In practice, however, contents may have\nheterogeneous timeliness requirements depending on the applications that\noperate on them. Given per-EN cache capacity constraint, there exists a\nfundamental trade-off among the delivery latencies of different users'\nrequests, since contents that are allocated more cache space generally enjoy\nlower delivery latencies. For the case with two ENs and two users, the optimal\nlatency trade-off is characterized in the high-SNR regime in terms of the\nNormalized Delivery Time (NDT) metric. The main results are illustrated by\nnumerical examples. \n\n"}
{"id": "1701.06338", "contents": "Title: SCW Codes for Optimal CSI-Free Detection in Diffusive Molecular\n  Communications Abstract: Instantaneous or statistical channel state information (CSI) is needed for\nmost detection schemes developed in the molecular communication (MC)\nliterature. Since the MC channel changes, e.g., due to variations in the\nvelocity of flow, the temperature, or the distance between transmitter and\nreceiver, CSI acquisition has to be conducted repeatedly to keep track of CSI\nvariations. Frequent CSI acquisition may entail a large overhead whereas\ninfrequent CSI acquisition may result in a low CSI estimation quality. To cope\nwith these issues, we design codes which facilitate maximum likelihood sequence\ndetection at the receiver without instantaneous or statistical CSI. In\nparticular, assuming concentration shift keying modulation, we show that a\nclass of codes, referred to as strongly constant-weight (SCW) codes, enables\noptimal CSI-free sequence detection at the cost of decreasing the data rate.\nFor the proposed SCW codes, we analyze the code rate and the error rate.\nSimulation results verify our analytical derivations and reveal that the\nproposed CSI-free detector for SCW codes outperforms the baseline coherent and\nnon-coherent detectors for uncoded transmission. \n\n"}
{"id": "1701.06342", "contents": "Title: Bayesian definition of random sequences with respect to conditional\n  probabilities Abstract: We study Martin-L\\\"{o}f random (ML-random) points on computable probability\nmeasures on sample and parameter spaces (Bayes models). We consider variants of\nconditional randomness defined by ML-randomness on Bayes models and those of\nconditional blind randomness. We show that variants of conditional blind\nrandomness are ill-defined from the Bayes statistical point of view. We prove\nthat if the sets of random sequences of uniformly computable parametric models\nare pairwise disjoint then there is a consistent estimator for the model.\nFinally, we present an algorithmic solution to a classical problem in Bayes\nstatistics, i.e., the posterior distributions converge weakly to almost all\nparameters if and only if the posterior distributions converge weakly to all\nML-random parameters. \n\n"}
{"id": "1701.06814", "contents": "Title: Rate $\\frac{1}{3}$ Index Coding: Forbidden and Feasible Configurations Abstract: Linear index coding can be formulated as an interference alignment problem,\nin which precoding vectors of the minimum possible length are to be assigned to\nthe messages in such a way that the precoding vector of a demand (at some\nreceiver) is independent of the space of the interference (non\nside-information) precoding vectors. An index code has rate $\\frac{1}{l}$ if\nthe assigned vectors are of length $l$. In this paper, we introduce the notion\nof strictly rate $\\frac{1}{L}$ message subsets which must necessarily be\nallocated precoding vectors from a strictly $L$-dimensional space ($L=1,2,3$)\nin any rate $\\frac{1}{3}$ code. We develop a general necessary condition for\nrate $\\frac{1}{3}$ feasibility using intersections of strictly rate\n$\\frac{1}{L}$ message subsets. We apply the necessary condition to show that\nthe presence of certain interference configurations makes the index coding\nproblem rate $\\frac{1}{3}$ infeasible. We also obtain a class of index coding\nproblems, containing certain interference configurations, which are rate\n$\\frac{1}{3}$ feasible based on the idea of \\textit{contractions} of an index\ncoding problem. Our necessary conditions for rate $\\frac{1}{3}$ feasibility and\nthe class of rate $\\frac{1}{3}$ feasible problems obtained subsume all such\nknown results for rate $\\frac{1}{3}$ index coding. \n\n"}
{"id": "1701.06969", "contents": "Title: Error correction based on partial information Abstract: We consider the decoding of linear and array codes from errors when we are\nonly allowed to download a part of the codeword. More specifically, suppose\nthat we have encoded $k$ data symbols using an $(n,k)$ code with code length\n$n$ and dimension $k.$ During storage, some of the codeword coordinates might\nbe corrupted by errors. We aim to recover the original data by reading the\ncorrupted codeword with a limit on the transmitting bandwidth, namely, we can\nonly download an $\\alpha$ proportion of the corrupted codeword. For a given\n$\\alpha,$ our objective is to design a code and a decoding scheme such that we\ncan recover the original data from the largest possible number of errors. A\nnaive scheme is to read $\\alpha n$ coordinates of the codeword. This method\nused in conjunction with MDS codes guarantees recovery from any $\\lfloor(\\alpha\nn-k)/2\\rfloor$ errors. In this paper we show that we can instead read an\n$\\alpha$ proportion from each of the codeword's coordinates. For a\nwell-designed MDS code, this method can guarantee recovery from $\\lfloor\n(n-k/\\alpha)/2 \\rfloor$ errors, which is $1/\\alpha$ times more than the naive\nmethod, and is also the maximum number of errors that an $(n,k)$ code can\ncorrect by downloading only an $\\alpha$ proportion of the codeword. We present\ntwo families of such optimal constructions and decoding schemes. One is a\nReed-Solomon code with evaluation points in a subfield and the other is based\non Folded Reed-Solomon codes. We further show that both code constructions\nattain asymptotically optimal list decoding radius when downloading only a part\nof the corrupted codeword. We also construct an ensemble of random codes that\nwith high probability approaches the upper bound on the number of correctable\nerrors when the decoder downloads an $\\alpha$ proportion of the corrupted\ncodeword. \n\n"}
{"id": "1701.07153", "contents": "Title: Throughput Maximization for Wireless Powered Communications Harvesting\n  from Non-dedicated Sources Abstract: We consider the wireless powered communications where users harvest energy\nfrom non-dedicated sources. The user follows a harvest-then-transmit protocol:\nin first phase of a slot time the source node harvests energy from a nearby\nconventional Access Point, then transmit information to its destination node or\nrelay node in the second phase. We obtain the optimal\\textit{ harvesting ratio}\nto maximize the expected throughput for direct transmission (DT )and decode\nforward (DF) relay under outage constraint, respectively. Our results reveal\nthat the optimal harvest ratio for DT is dominated by the outage constraint\nwhile for DF relay, by the data causality . \n\n"}
{"id": "1701.07262", "contents": "Title: On the Error Probability of Short Concatenated Polar and Cyclic Codes\n  with Interleaving Abstract: In this paper, the analysis of the performance of the concatenation of a\nshort polar code with an outer binary linear block code is addressed from a\ndistance spectrum viewpoint. The analysis targets the case where an outer\ncyclic code is employed together with an inner systematic polar code. A\nconcatenated code ensemble is introduced placing an interleaver at the input of\nthe polar encoder. The introduced ensemble allows deriving bounds on the\nachievable error rates under maximum likelihood decoding, by applying the union\nbound to the (expurgated) average weight enumerators. The analysis suggests the\nneed of careful optimization of the outer code, to attain low error floors. \n\n"}
{"id": "1701.07371", "contents": "Title: Divergence Scaling of Fixed-Length, Binary-Output, One-to-One\n  Distribution Matching Abstract: Distribution matching is the process of invertibly mapping a uniformly\ndistributed input sequence onto sequences that approximate the output of a\ndesired discrete memoryless source. The special case of a binary output\nalphabet and one-to-one mapping is studied. A fixed-length distribution matcher\nis proposed that is optimal in the sense of minimizing the unnormalized\ninformational divergence between its output distribution and a binary\nmemoryless target distribution. Upper and lower bounds on the unnormalized\ndivergence are computed that increase logarithmically in the output block\nlength $n$. It follows that a recently proposed constant composition\ndistribution matcher performs within a constant gap of the minimal achievable\ninformational divergence. \n\n"}
{"id": "1701.07730", "contents": "Title: Alpha Fair Coded Caching Abstract: The performance of existing \\emph{coded caching} schemes is sensitive to\nworst channel quality, a problem which is exacerbated when communicating over\nfading channels. In this paper we address this limitation in the following\nmanner: \\emph{in short-term}, we allow transmissions to subsets of users with\ngood channel quality, avoiding users with fades, while \\emph{in long-term} we\nensure fairness across the different users.Our online scheme combines (i) joint\nscheduling and power control for the broadcast channel with fading, and (ii)\ncongestion control for ensuring the optimal long-term average performance. We\nrestrict the caching operations to the decentralized scheme of\n\\cite{maddah2013decentralized}, and subject to this restriction we prove that\nour scheme has near-optimal overall performance with respect to the convex\nalpha-fairness coded caching optimization. By tuning the coefficient alpha, the\noperator can differentiate user performance with respect to video delivery\nrates achievable by coded caching.\n  We demonstrate via simulations our scheme's superiority over legacy coded\ncaching and unicast opportunistic scheduling, which are identified as special\ncases of our general framework. \n\n"}
{"id": "1701.07964", "contents": "Title: On the Performance of Practical Ultra-Dense Networks: The Major and\n  Minor Factors Abstract: In this paper, we conduct performance evaluation for Ultra-Dense Networks\n(UDNs), and identify which modelling factors play major roles and minor roles.\nFrom our study, we draw the following conclusions. First, there are 3\nfactors/models that have a major impact on the performance of UDNs, and they\nshould be considered when performing theoretical analyses: i) a multi-piece\npath loss model with line-of-sight (LoS) and non-lineof- sight (NLoS)\ntransmissions; ii) a non-zero antenna height difference between base stations\n(BSs) and user equipments (UEs); iii) a finite BS/UE density. Second, there are\n4 factors/models that have a minor impact on the performance of UDNs, i.e.,\nchanging the results quantitatively but not qualitatively, and thus their\nincorporation into theoretical analyses is less urgent: i) a general multi-path\nfading model based on Rician fading; ii) a correlated shadow fading model; iii)\na BS density dependent transmission power; iv) a deterministic BS/user density.\nFinally, there are 5 factors/models for future study: i) a BS vertical antenna\npattern; ii) multi-antenna and/or multi-BS joint transmissions; iii) a\nproportional fair BS scheduler; iv) a non-uniform distribution of BSs; v) a\ndynamic time division duplex (TDD) or full duplex (FD) network. Our conclusions\ncan guide researchers to downselect the assumptions in their theoretical\nanalyses, so as to avoid unnecessarily complicated results, while still\ncapturing the fundamentals of UDNs in a meaningful way. \n\n"}
{"id": "1702.00942", "contents": "Title: Quantum Optimal Multiple Assignment Scheme for Realizing General Access\n  Structure of Secret Sharing Abstract: The multiple assignment scheme is to assign one or more shares to single\nparticipant so that any kind of access structure can be realized by classical\nsecret sharing schemes. We propose its quantum version including ramp secret\nsharing schemes. Then we propose an integer optimization approach to minimize\nthe average share size. \n\n"}
{"id": "1702.01241", "contents": "Title: Generalized piggybacking codes for distributed storage systems Abstract: This paper generalizes the piggybacking constructions for distributed storage\nsystems by considering various protected instances and piggybacked instances.\nAnalysis demonstrates that the proportion of protected instances determines the\naverage repair bandwidth for a systematic node. By optimizing the proportion of\nprotected instances, the repair ratio of generalized piggybacking codes\napproaches zero instead of 50% as the number of parity check nodes tends to\ninfinity. Furthermore, the computational complexity for repairing a single\nsystematic node cost by generalized piggybacking codes is less than that of the\nexisting piggybacking designs. \n\n"}
{"id": "1702.01672", "contents": "Title: On Coded Caching in the Overloaded MISO Broadcast Channel Abstract: This work investigates the interplay of coded caching and spatial\nmultiplexing in an overloaded Multiple-Input-Single-Output (MISO) Broadcast\nChannel (BC), i.e. a system where the number of users is greater than the\nnumber of transmitting antennas. On one hand, coded caching uses the aggregate\nglobal cache memory of the users to create multicasting opportunities. On the\nother hand, multiple antennas at the transmitter leverage the available CSIT to\ntransmit multiple streams simultaneously. In this paper, we introduce a novel\nscheme which combines both the gain derived from coded-caching and spatial\nmultiplexing and outperforms existing schemes in terms of delivery time and\nCSIT requirement. \n\n"}
{"id": "1702.02497", "contents": "Title: Two-Dimensional AoD and AoA Acquisition for Wideband mmWave Systems with\n  Cross-Polarized MIMO Abstract: In this paper, a novel two-dimensional super-resolution angle-of-departure\n(AoD) and angle-of-arrival (AoA) estimation technique is proposed for wideband\nmillimeter-wave multiple-input multiple-output systems with cross-polarized\nantenna elements. The key ingredient of the proposed method is to form custom\ndesigned beam pairs, and devise an invertible function of the AoD/AoA to be\nestimated from the corresponding beam pairs. Further, a new multi-layer\nreference signal structure is developed for the proposed method to facilitate\nangle estimation for wideband channels with cross-polarized antenna elements.\nTo facilitate feedback in closed-loop frequency division duplexing systems, a\nnovel differential feedback strategy is proposed aiming at feedback reduction\nfor the two-dimensional angle estimation. Numerical results demonstrate that by\nusing the proposed method, good azimuth/elevation AoD and AoA estimation\nperformance can be achieved under different levels of signal-to-noise ratio,\nchannel conditions, and antenna array configurations. \n\n"}
{"id": "1702.03589", "contents": "Title: Subspace-Aware Index Codes Abstract: In this paper, we generalize the well-known index coding problem to exploit\nthe structure in the source-data to improve system throughput. In many\napplications, the data to be transmitted may lie (or can be well approximated)\nin a low-dimensional subspace. We exploit this low-dimensional structure of the\ndata using an algebraic framework to solve the index coding problem (referred\nto as subspace-aware index coding) as opposed to the traditional index coding\nproblem which is subspace-unaware. Also, we propose an efficient algorithm\nbased on the alternating minimization approach to obtain near optimal index\ncodes for both subspace-aware and -unaware cases. Our simulations indicate that\nunder certain conditions, a significant throughput gain (about 90%) can be\nachieved by subspace-aware index codes over conventional subspace-unaware index\ncodes. \n\n"}
{"id": "1702.03656", "contents": "Title: Information and estimation in Fokker-Planck channels Abstract: We study the relationship between information- and estimation-theoretic\nquantities in time-evolving systems. We focus on the Fokker-Planck channel\ndefined by a general stochastic differential equation, and show that the time\nderivatives of entropy, KL divergence, and mutual information are characterized\nby estimation-theoretic quantities involving an appropriate generalization of\nthe Fisher information. Our results vastly extend De Bruijn's identity and the\nclassical I-MMSE relation. \n\n"}
{"id": "1702.04834", "contents": "Title: Improved Converses and Gap Results for Coded Caching Abstract: Improved lower bounds on the average and the worst-case rate-memory tradeoffs\nfor the Maddah-Ali&Niesen coded caching scenario are presented. For any number\nof users and files and for arbitrary cache sizes, the multiplicative gap\nbetween the exact rate-memory tradeoff and the new lower bound is less than\n2.315 in the worst-case scenario and less than 2.507 in the average-case\nscenario. \n\n"}
{"id": "1702.05309", "contents": "Title: Mobile Edge Computing: A Survey on Architecture and Computation\n  Offloading Abstract: Technological evolution of mobile user equipments (UEs), such as smartphones\nor laptops, goes hand-in-hand with evolution of new mobile applications.\nHowever, running computationally demanding applications at the UEs is\nconstrained by limited battery capacity and energy consumption of the UEs.\nSuitable solution extending the battery life-time of the UEs is to offload the\napplications demanding huge processing to a conventional centralized cloud\n(CC). Nevertheless, this option introduces significant execution delay\nconsisting in delivery of the offloaded applications to the cloud and back plus\ntime of the computation at the cloud. Such delay is inconvenient and make the\noffloading unsuitable for real-time applications. To cope with the delay\nproblem, a new emerging concept, known as mobile edge computing (MEC), has been\nintroduced. The MEC brings computation and storage resources to the edge of\nmobile network enabling to run the highly demanding applications at the UE\nwhile meeting strict delay requirements. The MEC computing resources can be\nexploited also by operators and third parties for specific purposes. In this\npaper, we first describe major use cases and reference scenarios where the MEC\nis applicable. After that we survey existing concepts integrating MEC\nfunctionalities to the mobile networks and discuss current advancement in\nstandardization of the MEC. The core of this survey is, then, focused on\nuser-oriented use case in the MEC, i.e., computation offloading. In this\nregard, we divide the research on computation offloading to three key areas: i)\ndecision on computation offloading, ii) allocation of computing resource within\nthe MEC, and iii) mobility management. Finally, we highlight lessons learned in\narea of the MEC and we discuss open research challenges yet to be addressed in\norder to fully enjoy potentials offered by the MEC. \n\n"}
{"id": "1702.06878", "contents": "Title: $M$-QAM Precoder Design for MIMO Directional Modulation Transceivers Abstract: Spectrally efficient multi-antenna wireless communication systems are a key\nchallenge as service demands continue to increase. At the same time, powering\nup radio access networks is facing environmental and regulation limitations. In\norder to achieve more power efficiency, we design a directional modulation\nprecoder by considering an $M$-QAM constellation, particularly with\n$M=4,8,16,32$. First, extended detection regions are defined for desired\nconstellations using analytical geometry. Then, constellation points are placed\nin the optimal positions of these regions while the minimum Euclidean distance\nto adjacent constellation points and detection region boundaries is kept as in\nthe conventional $M$-QAM modulation. For further power efficiency and symbol\nerror rate similar to that of fixed design in high SNR, relaxed detection\nregions are modeled for inner points of $M=16,32$ constellations. The modeled\nextended and relaxed detection regions as well as the modulation\ncharacteristics are utilized to formulate symbol-level precoder design problems\nfor directional modulation to minimize the transmission power while preserving\nthe minimum required SNR at the destination. In addition, the extended and\nrelaxed detection regions are used for precoder design to minimize the output\nof each power amplifier. We transform the design problems into convex ones and\ndevise an interior point path-following iterative algorithm to solve the\nmentioned problems and provide details on finding the initial values of the\nparameters and the starting point. Results show that compared to the benchmark\nschemes, the proposed method performs better in terms of power and peak power\nreduction as well as symbol error rate reduction for a wide range of SNRs. \n\n"}
{"id": "1702.07302", "contents": "Title: Two-Moment Inequalities for R\\'enyi Entropy and Mutual Information Abstract: This paper explores some applications of a two-moment inequality for the\nintegral of the $r$-th power of a function, where $0 < r< 1$. The first\ncontribution is an upper bound on the R\\'{e}nyi entropy of a random vector in\nterms of the two different moments. When one of the moments is the zeroth\nmoment, these bounds recover previous results based on maximum entropy\ndistributions under a single moment constraint. More generally, evaluation of\nthe bound with two carefully chosen nonzero moments can lead to significant\nimprovements with a modest increase in complexity. The second contribution is a\nmethod for upper bounding mutual information in terms of certain integrals with\nrespect to the variance of the conditional density. The bounds have a number of\nuseful properties arising from the connection with variance decompositions. \n\n"}
{"id": "1702.07737", "contents": "Title: Decoding Generalized Reed-Solomon Codes and Its Application to RLCE\n  Encryption Schemes Abstract: This paper compares the efficiency of various algorithms for implementing\nquantum resistant public key encryption scheme RLCE on 64-bit CPUs. By\noptimizing various algorithms for polynomial and matrix operations over finite\nfields, we obtained several interesting (or even surprising) results. For\nexample, it is well known (e.g., Moenck 1976 \\cite{moenck1976practical}) that\nKaratsuba's algorithm outperforms classical polynomial multiplication algorithm\nfrom the degree 15 and above (practically, Karatsuba's algorithm only\noutperforms classical polynomial multiplication algorithm from the degree 35\nand above ). Our experiments show that 64-bit optimized Karatsuba's algorithm\nwill only outperform 64-bit optimized classical polynomial multiplication\nalgorithm for polynomials of degree 115 and above over finite field\n$GF(2^{10})$. The second interesting (surprising) result shows that 64-bit\noptimized Chien's search algorithm ourperforms all other 64-bit optimized\npolynomial root finding algorithms such as BTA and FFT for polynomials of all\ndegrees over finite field $GF(2^{10})$. The third interesting (surprising)\nresult shows that 64-bit optimized Strassen matrix multiplication algorithm\nonly outperforms 64-bit optimized classical matrix multiplication algorithm for\nmatrices of dimension 750 and above over finite field $GF(2^{10})$. It should\nbe noted that existing literatures and practices recommend Strassen matrix\nmultiplication algorithm for matrices of dimension 40 and above. All our\nexperiments are done on a 64-bit MacBook Pro with i7 CPU and single thread C\ncodes. It should be noted that the reported results should be appliable to 64\nor larger bits CPU architectures. For 32 or smaller bits CPUs, these results\nmay not be applicable. The source code and library for the algorithms covered\nin this paper are available at http://quantumca.org/. \n\n"}
{"id": "1702.07881", "contents": "Title: On the Performance of Wireless Powered Communication With Non-linear\n  Energy Harvesting Abstract: In this paper, we analyze the performance of a time-slotted multi-antenna\nwireless powered communication (WPC) system, where a wireless device first\nharvests radio frequency (RF) energy from a power station (PS) in the downlink\nto facilitate information transfer to an information receiving station (IRS) in\nthe uplink. The main goal of this paper is to provide insights and guidelines\nfor the design of practical WPC systems. To this end, we adopt a recently\nproposed parametric non-linear RF energy harvesting (EH) model, which has been\nshown to accurately model the end-to-end non-linearity of practical RF EH\ncircuits. In order to enhance the RF power transfer efficiency, maximum ratio\ntransmission is adopted at the PS to focus the energy signals on the wireless\ndevice. Furthermore, at the IRS, maximum ratio combining is used. We analyze\nthe outage probability and the average throughput of information transfer,\nassuming Nakagami-$m$ fading uplink and downlink channels. Moreover, we study\nthe system performance as a function of the number of PS transmit antennas, the\nnumber of IRS receive antennas, the transmit power of the PS, the fading\nseverity, the transmission rate of the wireless device, and the EH time\nduration. In addition, we obtain a fixed point equation for the optimal\ntransmission rate and the optimal EH time duration that maximize the asymptotic\nthroughput for high PS transmit powers. All analytical results are corroborated\nby simulations. \n\n"}
{"id": "1702.08052", "contents": "Title: Delay-Optimal Probabilistic Scheduling with Arbitrary Arrival and\n  Adaptive Transmission Abstract: In this paper, we aim to obtain the optimal delay-power tradeoff and the\ncorresponding optimal scheduling policy for an arbitrary i.i.d. arrival process\nand adaptive transmissions. The number of backlogged packets at the transmitter\nis known to a scheduler, who has to determine how many backlogged packets to\ntransmit during each time slot. The power consumption is assumed to be convex\nin transmission rates. Hence, if the scheduler transmits faster, the delay will\nbe reduced but with higher power consumption. To obtain the optimal delay-power\ntradeoff and the corresponding optimal policy, we model the problem as a\nConstrained Markov Decision Process (CMDP), where we minimize the average delay\ngiven an average power constraint. By steady-state analysis and Lagrangian\nrelaxation, we can show that the optimal tradeoff curve is decreasing, convex,\nand piecewise linear, and the optimal policy is threshold-based. Based on the\nrevealed properties of the optimal policy, we develop an algorithm to\nefficiently obtain the optimal tradeoff curve and the optimal policy with full\ninformation of the system. The complexity of our proposed algorithm is much\nlower than a general algorithm based on Linear Programming. However, usually\nthe distribution of the arrival process is unknown to the scheduler, therefore\nwe proposed a reinforcement learning algorithm to efficiently obtain the\noptimal policy under this circumstance. We also analyse in details about how\nthe system parameters affect the optimal policy and the system performance. In\nthe final, we use simulations to validate the derived results and the proposed\nalgorithms. \n\n"}
{"id": "1702.08130", "contents": "Title: Multiuser Precoding and Channel Estimation for Hybrid Millimeter Wave\n  MIMO Systems Abstract: In this paper, we develop a low-complexity channel estimation for hybrid\nmillimeter wave (mmWave) systems, where the number of radio frequency (RF)\nchains is much less than the number of antennas equipped at each transceiver.\nThe proposed channel estimation algorithm aims to estimate the strongest\nangle-of-arrivals (AoAs) at both the base station (BS) and the users. Then all\nthe users transmit orthogonal pilot symbols to the BS via these estimated\nstrongest AoAs to facilitate the channel estimation. The algorithm does not\nrequire any explicit channel state information (CSI) feedback from the users\nand the associated signalling overhead of the algorithm is only proportional to\nthe number of users, which is significantly less compared to various existing\nschemes. Besides, the proposed algorithm is applicable to both non-sparse and\nsparse mmWave channel environments. Based on the estimated CSI, zero-forcing\n(ZF) precoding is adopted for multiuser downlink transmission. In addition, we\nderive a tight achievable rate upper bound of the system. Our analytical and\nsimulation results show that the proposed scheme offer a considerable\nachievable rate gain compared to fully digital systems, where the number of RF\nchains equipped at each transceiver is equal to the number of antennas.\nFurthermore, the achievable rate performance gap between the considered hybrid\nmmWave systems and the fully digital system is characterized, which provides\nuseful system design insights. \n\n"}
{"id": "1702.08565", "contents": "Title: Nearly Maximally Predictive Features and Their Dimensions Abstract: Scientific explanation often requires inferring maximally predictive features\nfrom a given data set. Unfortunately, the collection of minimal maximally\npredictive features for most stochastic processes is uncountably infinite. In\nsuch cases, one compromises and instead seeks nearly maximally predictive\nfeatures. Here, we derive upper-bounds on the rates at which the number and the\ncoding cost of nearly maximally predictive features scales with desired\npredictive power. The rates are determined by the fractal dimensions of a\nprocess' mixed-state distribution. These results, in turn, show how widely-used\nfinite-order Markov models can fail as predictors and that mixed-state\npredictive features offer a substantial improvement. \n\n"}
{"id": "1703.00178", "contents": "Title: 5G Mobile Cellular Networks: Enabling Distributed State Estimation for\n  Smart Grids Abstract: With transition towards 5G, mobile cellular networks are evolving into a\npowerful platform for ubiquitous large-scale information acquisition,\ncommunication, storage and processing. 5G will provide suitable services for\nmission-critical and real-time applications such as the ones envisioned in\nfuture Smart Grids. In this work, we show how emerging 5G mobile cellular\nnetwork, with its evolution of Machine-Type Communications and the concept of\nMobile Edge Computing, provides an adequate environment for distributed\nmonitoring and control tasks in Smart Grids. In particular, we present in\ndetail how Smart Grids could benefit from advanced distributed State Estimation\nmethods placed within 5G environment. We present an overview of emerging\ndistributed State Estimation solutions, focusing on those based on distributed\noptimization and probabilistic graphical models, and investigate their\nintegration as part of the future 5G Smart Grid services. \n\n"}
{"id": "1703.00641", "contents": "Title: Learning Mixtures of Sparse Linear Regressions Using Sparse Graph Codes Abstract: In this paper, we consider the mixture of sparse linear regressions model.\nLet ${\\beta}^{(1)},\\ldots,{\\beta}^{(L)}\\in\\mathbb{C}^n$ be $ L $ unknown sparse\nparameter vectors with a total of $ K $ non-zero coefficients. Noisy linear\nmeasurements are obtained in the form $y_i={x}_i^H {\\beta}^{(\\ell_i)} + w_i$,\neach of which is generated randomly from one of the sparse vectors with the\nlabel $ \\ell_i $ unknown. The goal is to estimate the parameter vectors\nefficiently with low sample and computational costs. This problem presents\nsignificant challenges as one needs to simultaneously solve the demixing\nproblem of recovering the labels $ \\ell_i $ as well as the estimation problem\nof recovering the sparse vectors $ {\\beta}^{(\\ell)} $.\n  Our solution to the problem leverages the connection between modern coding\ntheory and statistical inference. We introduce a new algorithm, Mixed-Coloring,\nwhich samples the mixture strategically using query vectors $ {x}_i $\nconstructed based on ideas from sparse graph codes. Our novel code design\nallows for both efficient demixing and parameter estimation. In the noiseless\nsetting, for a constant number of sparse parameter vectors, our algorithm\nachieves the order-optimal sample and time complexities of $\\Theta(K)$. In the\npresence of Gaussian noise, for the problem with two parameter vectors (i.e.,\n$L=2$), we show that the Robust Mixed-Coloring algorithm achieves near-optimal\n$\\Theta(K polylog(n))$ sample and time complexities. When $K=O(n^{\\alpha})$ for\nsome constant $\\alpha\\in(0,1)$ (i.e., $K$ is sublinear in $n$), we can achieve\nsample and time complexities both sublinear in the ambient dimension. In one of\nour experiments, to recover a mixture of two regressions with dimension $n=500$\nand sparsity $K=50$, our algorithm is more than $300$ times faster than EM\nalgorithm, with about one third of its sample cost. \n\n"}
{"id": "1703.01092", "contents": "Title: Zero-Delay Source-Channel Coding with a One-Bit ADC Front End and\n  Correlated Side Information at the Receiver Abstract: Zero-delay transmission of a Gaussian source over an additive white Gaussian\nnoise (AWGN) channel is considered with a one-bit analog-to-digital converter\n(ADC) front end and a correlated side information at the receiver. The design\nof the optimal encoder and decoder is studied for two performance criteria,\nnamely, the mean squared error (MSE) distortion and the distortion outage\nprobability (DOP), under an average power constraint on the channel input. For\nboth criteria, necessary optimality conditions for the encoder and the decoder\nare derived. Using these conditions, it is observed that the numerically\noptimized encoder (NOE) under the MSE distortion criterion is periodic, and its\nperiod increases with the correlation between the source and the receiver side\ninformation. For the DOP, it is instead seen that the NOE mappings periodically\nacquire positive and negative values, which decay to zero with increasing\nsource magnitude, and the interval over which the mapping takes non-zero\nvalues, becomes wider with the correlation between the source and the side\ninformation. \n\n"}
{"id": "1703.01208", "contents": "Title: Preserving Confidentiality in The Gaussian Broadcast Channel Using\n  Compute-and-Forward Abstract: We study the transmission of confidential messages across a wireless\nbroadcast channel with K>2 receivers and K helpers. The goal is to transmit all\nmessages reliably to their intended receivers while keeping them confidential\nfrom the unintended receivers. We design a codebook based on nested lattice\nstructure, cooperative jamming, lattice alignment, and i.i.d. coding. Moreover,\nwe exploit the asymmetric compute-and-forward decoding strategy to handle\nfinite SNR regimes. Unlike previous alignment schemes, our achievable rates are\nattainable at any finite SNR value. Also, we show that our scheme achieves the\noptimal sum secure degrees of freedom of 1 for the K-receiver Gaussian\nbroadcast channel with K confidential messages and K helpers. \n\n"}
{"id": "1703.01441", "contents": "Title: Algebraic geometry codes with complementary duals exceed the asymptotic\n  Gilbert-Varshamov bound Abstract: It was shown by Massey that linear complementary dual (LCD for short) codes\nare asymptotically good. In 2004, Sendrier proved that LCD codes meet the\nasymptotic Gilbert-Varshamov (GV for short) bound. Until now, the GV bound\nstill remains to be the best asymptotical lower bound for LCD codes. In this\npaper, we show that an algebraic geometry code over a finite field of even\ncharacteristic is equivalent to an LCD code and consequently there exists a\nfamily of LCD codes that are equivalent to algebraic geometry codes and exceed\nthe asymptotical GV bound. \n\n"}
{"id": "1703.04209", "contents": "Title: Virtual Reality over Wireless Networks: Quality-of-Service Model and\n  Learning-Based Resource Management Abstract: In this paper, the problem of resource management is studied for a network of\nwireless virtual reality (VR) users communicating over small cell networks\n(SCNs). In order to capture the VR users' quality-of-service (QoS) in SCNs, a\nnovel VR model, based on multi-attribute utility theory, is proposed. This\nmodel jointly accounts for VR metrics such as tracking accuracy, processing\ndelay, and transmission delay. In this model, the small base stations (SBSs)\nact as the VR control centers that collect the tracking information from VR\nusers over the cellular uplink. Once this information is collected, the SBSs\nwill then send the three dimensional images and accompanying surround stereo\naudio to the VR users over the downlink. Therefore, the resource allocation\nproblem in VR wireless networks must jointly consider both the uplink and\ndownlink. This problem is then formulated as a noncooperative game and a\ndistributed algorithm based on the machine learning framework of echo state\nnetworks (ESNs) is proposed to find the solution of this game. The use of the\nproposed ESN algorithm enables the SBSs to predict the VR QoS of each SBS and\nguarantees the convergence to a mixed-strategy Nash equilibrium. The analytical\nresult shows that each user's VR QoS jointly depends on both VR tracking\naccuracy and wireless resource allocation. Simulation results show that the\nproposed algorithm yields significant gains, in terms of total utility value of\nVR QoS, that reach up to 22.2% and 37.5%, respectively, compared to Q-learning\nand a baseline proportional fair algorithm. The results also show that the\nproposed algorithm has a faster convergence time than Q-learning and can\nguarantee low delays for VR services. \n\n"}
{"id": "1703.04925", "contents": "Title: Heralded Channel Holevo Superadditivity Bounds from Entanglement\n  Monogamy Abstract: We show that for a particular class of quantum channels, which we call\nheralded channels, monogamy of squashed entanglement limits the superadditivity\nof Holevo capacity. Heralded channels provide a means to understand the quantum\nerasure channel composed with an arbitrary other quantum channel, as well as\ncommon situations in experimental quantum information that involve frequent\nloss of qubits or failure of trials. We also show how entanglement monogamy\napplies to non-classicality in quantum games, and we consider how faithful,\nmonogamous entanglement measures may bound other entanglement-dependent\nquantities in many-party scenarios. \n\n"}
{"id": "1703.05024", "contents": "Title: Tail asymptotics of signal-to-interference ratio distribution in spatial\n  cellular network models Abstract: We consider a spatial stochastic model of wireless cellular networks, where\nthe base stations (BSs) are deployed according to a simple and stationary point\nprocess on $\\mathbb{R}^d$, $d\\ge2$. In this model, we investigate tail\nasymptotics of the distribution of signal-to-interference ratio (SIR), which is\na key quantity in wireless communications. In the case where the path-loss\nfunction representing signal attenuation is unbounded at the origin, we derive\nthe exact tail asymptotics of the SIR distribution under an appropriate\nsufficient condition. While we show that widely-used models based on a Poisson\npoint process and on a determinantal point process meet the sufficient\ncondition, we also give a counterexample violating it. In the case of bounded\npath-loss functions, we derive a logarithmically asymptotic upper bound on the\nSIR tail distribution for the Poisson-based and $\\alpha$-Ginibre-based models.\nA logarithmically asymptotic lower bound with the same order as the upper bound\nis also obtained for the Poisson-based model. \n\n"}
{"id": "1703.05536", "contents": "Title: A Compressive Method for Centralized PSD Map Construction with Imperfect\n  Reporting Channel Abstract: Spectrum resources management of growing demands is a challenging problem and\nCognitive Radio (CR) known to be capable of improving the spectrum utilization.\nRecently, Power Spectral Density (PSD) map is defined to enable the CR to reuse\nthe frequency resources regarding to the area. For this reason, the sensed PSDs\nare collected by the distributed sensors in the area and fused by a Fusion\nCenter (FC). But, for a given zone, the sensed PSDs by neighbor CR sensors may\ncontain a shared common component for a while. This component can be exploited\nin the theory of the Distributed Source Coding (DSC) to make the sensors\ntransmission data more compressed. However, uncertain channel fading and random\nshadowing would lead to varying signal strength at different CRs, even placed\nclose to each other. Hence, existence of some perturbations in the transmission\nprocedure yields to some imperfection in the reporting channel and as a result\nit degrades the performance remarkably. The main focus of this paper is to be\nable to reconstruct the PSDs of sensors \\textit{robustly} based on the\nDistributed Compressive Sensing (DCS) when the data transmission is slightly\nimperfect. Simulation results verify the robustness of the proposed scheme. \n\n"}
{"id": "1703.07474", "contents": "Title: Achieving Dalenius' Goal of Data Privacy with Practical Assumptions Abstract: Recent studies show that differential privacy is vulnerable when different\nindividuals' data in the dataset are correlated, and that there are many cases\nwhere differential privacy implies poor utility. In order to treat the two\nweaknesses, we traced the origin of differential privacy to Dalenius' goal, a\nmore rigorous privacy measure. We formalized Dalenius' goal by using Shannon's\nperfect secrecy and tried to achieve Dalenius' goal with better utility. Our\nfirst result is that, if the independence assumption is true, then differential\nprivacy is equivalent to Dalenius' goal, where the independence assumption\nassumes that each adversary has no knowledge of the correlation among different\nindividuals' data in the dataset. This implies that the security of\ndifferential privacy is based on the independence assumption. Since the\nindependence assumption is impractical, we introduced a new practical\nassumption, which assumes that each adversary is unknown to some data of the\ndataset if the dataset is large enough. Based on the assumption, we can achieve\nDalenius' goal with better utility. Furthermore, we proved a useful result\nwhich can transplant results or approaches of information theory into data\nprivacy protection. We then proved that several basic privacy\nmechanisms/channels satisfy Dalenuis' goal, such as the random response, the\nexponential, and the Gaussian privacy channels, which are respective\ncounterparts of the random response, the exponential, and the Gaussian\nmechanisms of differential privacy. Moreover, the group and the composition\nproperties were also proved. Finally, by using Yao's computational information\ntheory, we extend our model to the computational-bounded case. \n\n"}
{"id": "1703.09204", "contents": "Title: On period polynomials of degree $2^m$ and weight distributions of\n  certain irreducible cyclic codes Abstract: We explicitly determine the values of reduced cyclotomic periods of order\n$2^m$, $m\\ge 4$, for finite fields of characteristic $p\\equiv 3$ or\n$5\\pmod{8}$. These evaluations are applied to obtain explicit factorizations of\nthe corresponding reduced period polynomials. As another application, the\nweight distributions of certain irreducible cyclic codes are described. \n\n"}
{"id": "1703.10329", "contents": "Title: Hybrid Precoding for Multi-Group Physical Layer Multicasting Abstract: Next generation of wireless networks will likely rely on large-scale antenna\nsystems, either in the form of massive multi-input-multi-output (MIMO) or\nmillimeter wave (mmWave) systems. Therefore, the conventional fully-digital\nprecoders are not suitable for physical layer multicasting as they require a\ndedicated radio frequency chain per antenna element. In this paper, we show\nthat in a multi-group multicasting system with an arbitrary number of transmit\nantennas, $G$ multicasting groups, and an arbitrary number of users in each\ngroup, one can achieve the performance of any fully-digital precoder with just\n$G$ radio frequency chains using the proposed hybrid multi-group multicasting\nstructure. \n\n"}
{"id": "1703.10744", "contents": "Title: Time-triggering versus event-triggering control over communication\n  channels Abstract: Time-triggered and event-triggered control strategies for stabilization of an\nunstable plant over a rate-limited communication channel subject to unknown,\nbounded delay are studied and compared. Event triggering carries implicit\ninformation, revealing the state of the plant. However, the delay in the\ncommunication channel causes information loss, as it makes the state\ninformation out of date. There is a critical delay value, when the loss of\ninformation due to the communication delay perfectly compensates the implicit\ninformation carried by the triggering events. This occurs when the maximum\ndelay equals the inverse of the entropy rate of the plant. In this context,\nextensions of our previous results for event triggering strategies are\npresented for vector systems and are compared with the data-rate theorem for\ntime-triggered control, that is extended here to a setting with unknown delay. \n\n"}
{"id": "1704.01244", "contents": "Title: Dynamic Base Station Repositioning to Improve Spectral Efficiency of\n  Drone Small Cells Abstract: With recent advancements in drone technology, researchers are now considering\nthe possibility of deploying small cells served by base stations mounted on\nflying drones. A major advantage of such drone small cells is that the\noperators can quickly provide cellular services in areas of urgent demand\nwithout having to pre-install any infrastructure. Since the base station is\nattached to the drone, technically it is feasible for the base station to\ndynamic reposition itself in response to the changing locations of users for\nreducing the communication distance, decreasing the probability of signal\nblocking, and ultimately increasing the spectral efficiency. In this paper, we\nfirst propose distributed algorithms for autonomous control of drone movements,\nand then model and analyse the spectral efficiency performance of a drone small\ncell to shed new light on the fundamental benefits of dynamic repositioning. We\nshow that, with dynamic repositioning, the spectral efficiency of drone small\ncells can be increased by nearly 100\\% for realistic drone speed, height, and\nuser traffic model and without incurring any major increase in drone energy\nconsumption. \n\n"}
{"id": "1704.01799", "contents": "Title: Prototyping and Experimentation of a Closed-Loop Wireless Power\n  Transmission with Channel Acquisition and Waveform Optimization Abstract: A systematic design of adaptive waveform for Wireless Power Transfer (WPT)\nhas recently been proposed and shown through simulations to lead to significant\nperformance benefits compared to traditional non-adaptive and heuristic\nwaveforms. In this study, we design the first prototype of a closed-loop\nwireless power transfer system with adaptive waveform optimization based on\nChannel State Information acquisition. The prototype consists of three\nimportant blocks, namely the channel estimator, the waveform optimizer, and the\nenergy harvester. Software Defined Radio (SDR) prototyping tools are used to\nimplement a wireless power transmitter and a channel estimator, and a voltage\ndoubler rectenna is designed to work as an energy harvester. A channel adaptive\nwaveform with 8 sinewaves is shown through experiments to improve the average\nharvested DC power at the rectenna output by 9.8% to 36.8% over a non-adaptive\ndesign with the same number of sinewaves. \n\n"}
{"id": "1704.02262", "contents": "Title: A Converse Bound on Wyner-Ahlswede-K\\\"orner Network via Gray-Wyner\n  Network Abstract: We show a reduction method to construct a code for the Gray-Wyner (GW)\nnetwork from a given code for the Wyner-Ahlswede-K\\\"orner (WAK) network. By\ncombining this reduction with a converse bound on the GW network, we derive a\nconverse bound on the WAK network. The derived bound gives an alternative proof\nof the strong converse theorem for the WAK network. \n\n"}
{"id": "1704.03234", "contents": "Title: Error Bounds for Uplink and Downlink 3D Localization in 5G mmWave\n  Systems Abstract: Location-aware communication systems are expected to play a pivotal part in\nthe next generation of mobile communication networks. Therefore, there is a\nneed to understand the localization limits in these networks, particularly,\nusing millimeter-wave technology (mmWave). Towards that, we address the uplink\nand downlink localization limits in terms of 3D position and orientation error\nbounds for mmWave multipath channels. We also carry out a detailed analysis of\nthe dependence of the bounds of different systems parameters. Our key findings\nindicate that the uplink and downlink behave differently in two distinct ways.\nFirst of all, the error bounds have different scaling factors with respect to\nthe number of antennas in the uplink and downlink. Secondly, uplink\nlocalization is sensitive to the orientation angle of the user equipment (UE),\nwhereas downlink is not. Moreover, in the considered outdoor scenarios, the\nnon-line-of-sight paths generally improve localization when a line-of-sight\npath exists. Finally, our numerical results show that mmWave systems are\ncapable of localizing a UE with sub-meter position error, and sub-degree\norientation error. \n\n"}
{"id": "1704.03611", "contents": "Title: Hybrid Beamforming via the Kronecker Decomposition for the\n  Millimeter-Wave Massive MIMO Systems Abstract: Despite its promising performance gain, the realization of mmWave massive\nMIMO still faces several practical challenges. In particular, implementing\nmassive MIMO in the digital domain requires hundreds of RF chains matching the\nnumber of antennas. Furthermore, designing these components to operate at the\nmmWave frequencies is challenging and costly. These motivated the recent\ndevelopment of hybrid-beamforming where MIMO processing is divided for separate\nimplementation in the analog and digital domains, called the analog and digital\nbeamforming, respectively. Analog beamforming using a phase array introduces\nuni-modulus constraints on the beamforming coefficients, rendering the\nconventional MIMO techniques unsuitable and call for new designs. In this\npaper, we present a systematic design framework for hybrid beamforming for\nmulti-cell multiuser massive MIMO systems over mmWave channels characterized by\nsparse propagation paths. The framework relies on the decomposition of analog\nbeamforming vectors and path observation vectors into Kronecker products of\nfactors being uni-modulus vectors. Exploiting properties of Kronecker mixed\nproducts, different factors of the analog beamformer are designed for either\nnulling interference paths or coherently combining data paths. Furthermore, a\nchannel estimation scheme is designed for enabling the proposed hybrid\nbeamforming. The scheme estimates the AoA of data and interference paths by\nanalog beam scanning and data-path gains by analog beam steering. The\nperformance of the channel estimation scheme is analyzed. In particular, the\nAoA spectrum resulting from beam scanning, which displays the magnitude\ndistribution of paths over the AoA range, is derived in closed-form. It is\nshown that the inter-cell interference level diminishes inversely with the\narray size, the square root of pilot sequence length and the spatial separation\nbetween paths. \n\n"}
{"id": "1704.03816", "contents": "Title: Dynamic Signaling Games with Quadratic Criteria under Nash and\n  Stackelberg Equilibria Abstract: This paper considers dynamic (multi-stage) signaling games involving an\nencoder and a decoder who have subjective models on the cost functions. We\nconsider both Nash (simultaneous-move) and Stackelberg (leader-follower)\nequilibria of dynamic signaling games under quadratic criteria. For the\nmulti-stage scalar cheap talk, we show that the final stage equilibrium is\nalways quantized and under further conditions the equilibria for all time\nstages must be quantized. In contrast, the Stackelberg equilibria are always\nfully revealing. In the multi-stage signaling game where the transmission of a\nGauss-Markov source over a memoryless Gaussian channel is considered, affine\npolicies constitute an invariant subspace under best response maps for Nash\nequilibria; whereas the Stackelberg equilibria always admit linear policies for\nscalar sources but such policies may be non-linear for multi-dimensional\nsources. We obtain an explicit recursion for optimal linear encoding policies\nfor multi-dimensional sources, and derive conditions under which Stackelberg\nequilibria are informative. \n\n"}
{"id": "1704.04709", "contents": "Title: Quantization Design and Channel Estimation for Massive MIMO Systems with\n  One-Bit ADCs Abstract: We consider the problem of channel estimation for uplink multiuser massive\nMIMO systems, where, in order to significantly reduce the hardware cost and\npower consumption, one-bit analog-to-digital converters (ADCs) are used at the\nbase station (BS) to quantize the received signal. Channel estimation for\none-bit massive MIMO systems is challenging due to the severe distortion caused\nby the coarse quantization. It was shown in previous studies that an extremely\nlong training sequence is required to attain an acceptable performance. In this\npaper, we study the problem of optimal one-bit quantization design for channel\nestimation in one-bit massive MIMO systems. Our analysis reveals that, if the\nquantization thresholds are optimally devised, using one-bit ADCs can achieve\nan estimation error close to (with an increase by a factor of $\\pi/2$) that of\nan ideal estimator which has access to the unquantized data. The optimal\nquantization thresholds, however, are dependent on the unknown channel\nparameters. To cope with this difficulty, we propose an adaptive quantization\n(AQ) approach in which the thresholds are adaptively adjusted in a way such\nthat the thresholds converge to the optimal thresholds, and a random\nquantization (RQ) scheme which randomly generate a set of nonidentical\nthresholds based on some statistical prior knowledge of the channel. Simulation\nresults show that, our proposed AQ and RQ schemes, owing to their wisely\ndevised thresholds, present a significant performance improvement over the\nconventional fixed quantization scheme that uses a fixed (typically zero)\nthreshold, and meanwhile achieve a substantial training overhead reduction for\nchannel estimation. In particular, even with a moderate number of pilot symbols\n(about 5 times the number of users), the AQ scheme can provide an achievable\nrate close to that of the perfect channel state information (CSI) case. \n\n"}
{"id": "1704.05186", "contents": "Title: Capacity of Cellular Wireless Network Abstract: Earlier definitions of capacity for wireless networks, e.g., transport or\ntransmission capacity, for which exact theoretical results are known, are well\nsuited for ad hoc networks but are not directly applicable for cellular\nwireless networks, where large-scale basestation (BS) coordination is not\npossible, and retransmissions/ARQ under the SINR model is a universal feature.\n  In this paper, cellular wireless networks, where both BS locations and mobile\nuser (MU) locations are distributed as independent Poisson point processes are\nconsidered, and each MU connects to its nearest BS. With ARQ, under the SINR\nmodel, the effective downlink rate of packet transmission is the reciprocal of\nthe expected delay (number of retransmissions needed till success), which we\nuse as our network capacity definition after scaling it with the BS density.\n  Exact characterization of this natural capacity metric for cellular wireless\nnetworks is derived. The capacity is shown to first increase polynomially with\nthe BS density in the low BS density regime and then scale inverse\nexponentially with the increasing BS density. Two distinct upper bounds are\nderived that are relevant for the low and the high BS density regimes. A single\npower control strategy is shown to achieve the upper bounds in both the\nregimes. This result is fundamentally different from the well known capacity\nresults for ad hoc networks, such as transport and transmission capacity that\nscale as the square root of the (high) BS density. Our results show that the\nstrong temporal correlations of SINRs with PPP distributed BS locations is\nlimiting, and the realizable capacity in cellular wireless networks in high-BS\ndensity regime is much smaller than previously thought. A byproduct of our\nanalysis shows that the capacity of the ALOHA strategy with retransmissions is\nzero. \n\n"}
{"id": "1704.06426", "contents": "Title: Massive MIMO Downlink 1-Bit Precoding with Linear Programming for PSK\n  Signaling Abstract: Quantized massive multiple-input-multiple-output (MIMO) systems are gaining\nmore interest due to their power efficiency. We present a new precoding\ntechnique to mitigate the multi-user interference and the quantization\ndistortions in a downlink multi-user (MU) multiple-input-single-output (MISO)\nsystem with 1-bit quantization at the transmitter. This work is restricted to\nPSK modulation schemes. The transmit signal vector is optimized for every\ndesired received vector taking into account the 1-bit quantization. The\noptimization is based on maximizing the safety margin to the decision\nthresholds of the PSK modulation. Simulation results show a significant gain in\nterms of the uncoded bit-error-ratio (BER) compared to the existing linear\nprecoding techniques. \n\n"}
{"id": "1704.06785", "contents": "Title: A general private information retrieval scheme for MDS coded databases\n  with colluding servers Abstract: The problem of private information retrieval gets renewed attentions in\nrecent years due to its information-theoretic reformulation and applications in\ndistributed storage systems. PIR capacity is the maximal number of bits\nprivately retrieved per one bit of downloaded bit. The capacity has been fully\nsolved for some degenerating cases. For a general case where the database is\nboth coded and colluded, the exact capacity remains unknown. We build a general\nprivate information retrieval scheme for MDS coded databases with colluding\nservers. Our scheme achieves the rate $(1+R+R^2+\\cdots+R^{M-1})$, where\n$R=1-\\frac{{{N-T}\\choose K}}{{N\\choose K}}$. Compared to existing PIR schemes,\nour scheme performs better for a certain range of parameters and is suitable\nfor any underlying MDS code used in the distributed storage system. \n\n"}
{"id": "1704.07037", "contents": "Title: Energy Efficient User Association and Power Allocation in Millimeter\n  Wave Based Ultra Dense Networks with Energy Harvesting Base Stations Abstract: Millimeter wave (mmWave) communication technologies have recently emerged as\nan attractive solution to meet the exponentially increasing demand on mobile\ndata traffic. Moreover, ultra dense networks (UDNs) combined with mmWave\ntechnology are expected to increase both energy efficiency and spectral\nefficiency. In this paper, user association and power allocation in mmWave\nbased UDNs is considered with attention to load balance constraints, energy\nharvesting by base stations, user quality of service requirements, energy\nefficiency, and cross-tier interference limits. The joint user association and\npower optimization problem is modeled as a mixed-integer programming problem,\nwhich is then transformed into a convex optimization problem by relaxing the\nuser association indicator and solved by Lagrangian dual decomposition. An\niterative gradient user association and power allocation algorithm is proposed\nand shown to converge rapidly to an optimal point. The complexity of the\nproposed algorithm is analyzed and the effectiveness of the proposed scheme\ncompared with existing methods is verified by simulations. \n\n"}
{"id": "1704.07461", "contents": "Title: Denoising Linear Models with Permuted Data Abstract: The multivariate linear regression model with shuffled data and additive\nGaussian noise arises in various correspondence estimation and matching\nproblems. Focusing on the denoising aspect of this problem, we provide a\ncharacterization the minimax error rate that is sharp up to logarithmic\nfactors. We also analyze the performance of two versions of a computationally\nefficient estimator, and establish their consistency for a large range of input\nparameters. Finally, we provide an exact algorithm for the noiseless problem\nand demonstrate its performance on an image point-cloud matching task. Our\nanalysis also extends to datasets with outliers. \n\n"}
{"id": "1704.08572", "contents": "Title: Frequency-domain Compressive Channel Estimation for Frequency-Selective\n  Hybrid mmWave MIMO Systems Abstract: Channel estimation is useful in millimeter wave (mmWave) MIMO communication\nsystems. Channel state information allows optimized designs of precoders and\ncombiners under different metrics such as mutual information or\nsignal-to-interference-noise (SINR) ratio. At mmWave, MIMO precoders and\ncombiners are usually hybrid, since this architecture provides a means to\ntrade-off power consumption and achievable rate. Channel estimation is\nchallenging when using these architectures, however, since there is no direct\naccess to the outputs of the different antenna elements in the array. The MIMO\nchannel can only be observed through the analog combining network, which acts\nas a compression stage of the received signal. Most of prior work on channel\nestimation for hybrid architectures assumes a frequency-flat mmWave channel\nmodel. In this paper, we consider a frequency-selective mmWave channel and\npropose compressed-sensing-based strategies to estimate the channel in the\nfrequency domain. We evaluate different algorithms and compute their complexity\nto expose trade-offs in complexity-overhead-performance as compared to those of\nprevious approaches. \n\n"}
{"id": "1704.08931", "contents": "Title: A Framework for Rate Efficient Control of Distributed Discrete Systems Abstract: A key issue in the control of distributed discrete systems modeled as Markov\ndecisions processes, is that often the state of the system is not directly\nobservable at any single location in the system. The participants in the\ncontrol scheme must share information with one another regarding the state of\nthe system in order to collectively make informed control decisions, but this\ninformation sharing can be costly. Harnessing recent results from information\ntheory regarding distributed function computation, in this paper we derive, for\nseveral information sharing model structures, the minimum amount of control\ninformation that must be exchanged to enable local participants to derive the\nsame control decisions as an imaginary omniscient controller having full\nknowledge of the global state. Incorporating consideration for this amount of\ninformation that must be exchanged into the reward enables one to trade the\ncompeting objectives of minimizing this control information exchange and\nmaximizing the performance of the controller. An alternating optimization\nframework is then provided to help find the efficient controllers and messaging\nschemes. A series of running examples from wireless resource allocation\nillustrate the ideas and design tradeoffs. \n\n"}
{"id": "1705.01235", "contents": "Title: Non-Orthogonal Random Access (NORA) for 5G Networks Abstract: The massive amounts of machine-type user equipments (UEs) will be supported\nin the future fifth generation (5G) networks. However, the potential large\nrandom access (RA) delay calls for a new RA scheme and for a detailed\nassessment of its performance. Motivated by the key idea of non-orthogonal\nmultiple access, the non-orthogonal random access (NORA) scheme based on\nsuccessive interference cancellation (SIC) is proposed in this paper to\nalleviate the access congestion problem. Specifically, NORA utilizes the\ndifference of time of arrival to identify multiple UEs with the identical\npreamble, and enables power domain multiplexing of collided UEs in the\nfollowing access process, while the base station performs SIC based on the\nchannel conditions obtained through preamble detection. Our analysis show that\nthe performance of NORA is superior to the conventional orthogonal random\naccess (ORA) scheme in terms of the preamble collision probability, access\nsuccess probability and throughput of random access. Simulation results verify\nour analysis and further show that our NORA scheme can improve the number of\nthe supported UEs by more than 30%. Moreover, the number of preamble\ntransmissions and the access delay for successfully accessed UEs are also\nreduced significantly by using the proposed random access scheme. \n\n"}
{"id": "1705.01733", "contents": "Title: On the Design of Matched Filters for Molecule Counting Receivers Abstract: In this paper, we design matched filters for diffusive molecular\ncommunication systems taking into account the following impairments:\nsignal-dependent diffusion noise, inter-symbol interference (ISI), and external\ninterfering molecules. The receiver counts the number of observed molecules\nseveral times within one symbol interval and employs linear filtering to detect\nthe transmitted data. We derive the optimal matched filter by maximizing the\nexpected signal-to-interference-plus-noise ratio of the decision variable.\nMoreover, we show that for the special case of an ISI-free channel, the matched\nfilter reduces to a simple sum detector and a correlator for the channel\nimpulse response for the diffusion noise-limited and (external)\ninterference-limited regimes, respectively. Our simulation results reveal that\nthe proposed matched filter considerably outperforms the benchmark schemes\navailable in literature, especially when ISI is severe. \n\n"}
{"id": "1705.02877", "contents": "Title: Ultra Reliable UAV Communication Using Altitude and Cooperation\n  Diversity Abstract: The use of unmanned aerial vehicles (UAVs) that serve as aerial base stations\nis expected to become predominant in the next decade. However, in order for\nthis technology to unfold its full potential it is necessary to develop a\nfundamental understanding of the distinctive features of air-to-ground (A2G)\nlinks. As a contribution in this direction, this paper proposes a generic\nframework for the analysis and optimization of the A2G systems. In contrast to\nthe existing literature, this framework incorporates both height-dependent path\nloss exponent and small-scale fading, and unifies a widely used\nground-to-ground channel model with that of A2G for analysis of large-scale\nwireless networks. We derive analytical expressions for the optimal UAV height\nthat minimizes the outage probability of a given A2G link. Moreover, our\nframework allows us to derive a height-dependent closed-form expression and a\ntight lower bound for the outage probability of an \\textit{A2G cooperative\ncommunication} network. Our results suggest that the optimal location of the\nUAVs with respect to the ground nodes does not change by the inclusion of\nground relays. This enables interesting insights in the deployment of future\nA2G networks, as the system reliability could be adjusted dynamically by adding\nrelaying nodes without requiring changes in the position of the corresponding\nUAVs. \n\n"}
{"id": "1705.02882", "contents": "Title: End-to-End Simulation of 5G mmWave Networks Abstract: Due to its potential for multi-gigabit and low latency wireless links,\nmillimeter wave (mmWave) technology is expected to play a central role in 5th\ngeneration cellular systems. While there has been considerable progress in\nunderstanding the mmWave physical layer, innovations will be required at all\nlayers of the protocol stack, in both the access and the core network.\nDiscrete-event network simulation is essential for end-to-end, cross-layer\nresearch and development. This paper provides a tutorial on a recently\ndeveloped full-stack mmWave module integrated into the widely used open-source\nns--3 simulator. The module includes a number of detailed statistical channel\nmodels as well as the ability to incorporate real measurements or ray-tracing\ndata. The Physical (PHY) and Medium Access Control (MAC) layers are modular and\nhighly customizable, making it easy to integrate algorithms or compare\nOrthogonal Frequency Division Multiplexing (OFDM) numerologies, for example.\nThe module is interfaced with the core network of the ns--3 Long Term Evolution\n(LTE) module for full-stack simulations of end-to-end connectivity, and\nadvanced architectural features, such as dual-connectivity, are also available.\nTo facilitate the understanding of the module, and verify its correct\nfunctioning, we provide several examples that show the performance of the\ncustom mmWave stack as well as custom congestion control algorithms designed\nspecifically for efficient utilization of the mmWave channel. \n\n"}
{"id": "1705.03064", "contents": "Title: Optimal User Scheduling and Power Allocation for Millimeter Wave NOMA\n  Systems Abstract: This paper investigates the application of non-orthogonal multiple access\n(NOMA) in millimeter wave (mmWave) communications by exploiting beamforming,\nuser scheduling and power allocation. Random beamforming is invoked for\nreducing the feedback overhead of considered systems. A nonconvex optimization\nproblem for maximizing the sum rate is formulated, which is proved to be\nNP-hard. The branch and bound (BB) approach is invoked to obtain the optimal\npower allocation policy, which is proved to converge to a global optimal\nsolution. To elaborate further, low complexity suboptimal approach is developed\nfor striking a good computational complexity-optimality tradeoff, where\nmatching theory and successive convex approximation (SCA) techniques are\ninvoked for tackling the user scheduling and power allocation problems,\nrespectively. Simulation results reveal that: i) the proposed low complexity\nsolution achieves a near-optimal performance; and ii) the proposed mmWave NOMA\nsystems is capable of outperforming conventional mmWave orthogonal multiple\naccess (OMA) systems in terms of sum rate and the number of served users. \n\n"}
{"id": "1705.04070", "contents": "Title: Coded Multicast Fronthauling and Edge Caching for Multi-Connectivity\n  Transmission in Fog Radio Access Networks Abstract: This work studies the advantages of coded multicasting for the downlink of a\nFog Radio Access Network (F-RAN) system equipped with a multicast fronthaul\nlink. In this system, a control unit (CU) in the baseband processing unit (BBU)\npool is connected to distributed edge nodes (ENs) through a multicast fronthaul\nlink of finite capacity, and the ENs have baseband processing and caching\ncapabilities. Each user equipment (UE) requests a file in a content library\nwhich is available at the CU, and the requested files are served by the closest\nENs based on the cached contents and on the information received on the\nmulticast fronthaul link. The performance of coded multicast fronthauling is\ninvestigated in terms of the delivery latency of the requested contents under\nthe assumption of pipelined transmission on the fronthaul and edge links and of\nsingle-user encoding and decoding strategies based on the hard transfer of\nfiles on the fronthaul links. Extensive numerical results are provided to\nvalidate the advantages of the coded multicasting scheme compared to uncoded\nunicast and multicast strategies. \n\n"}
{"id": "1705.04560", "contents": "Title: Construction of Sidon spaces with applications to coding Abstract: A subspace of a finite extension field is called a Sidon space if the product\nof any two of its elements is unique up to a scalar multiplier from the base\nfield. Sidon spaces were recently introduced by Bachoc et al. as a means to\ncharacterize multiplicative properties of subspaces, and yet no explicit\nconstructions were given. In this paper, several constructions of Sidon spaces\nare provided. In particular, in some of the constructions the relation between\n$k$, the dimension of the Sidon space, and $n$, the dimension of the ambient\nextension field, is optimal.\n  These constructions are shown to provide cyclic subspace codes, which are\nuseful tools in network coding schemes. To the best of the authors' knowledge,\nthis constitutes the first set of constructions of non-trivial cyclic subspace\ncodes in which the relation between $k$ and $n$ is polynomial, and in\nparticular, linear. As a result, a conjecture by Trautmann et al. regarding the\nexistence of non-trivial cyclic subspace codes is resolved for most parameters,\nand multi-orbit cyclic subspace codes are attained, whose cardinality is within\na constant factor (close to $1/2$) from the sphere-packing bound for subspace\ncodes. \n\n"}
{"id": "1705.06315", "contents": "Title: Direct Ensemble Estimation of Density Functionals Abstract: Estimating density functionals of analog sources is an important problem in\nstatistical signal processing and information theory. Traditionally, estimating\nthese quantities requires either making parametric assumptions about the\nunderlying distributions or using non-parametric density estimation followed by\nintegration. In this paper we introduce a direct nonparametric approach which\nbypasses the need for density estimation by using the error rates of k-NN\nclassifiers asdata-driven basis functions that can be combined to estimate a\nrange of density functionals. However, this method is subject to a non-trivial\nbias that dramatically slows the rate of convergence in higher dimensions. To\novercome this limitation, we develop an ensemble method for estimating the\nvalue of the basis function which, under some minor constraints on the\nsmoothness of the underlying distributions, achieves the parametric rate of\nconvergence regardless of data dimension. \n\n"}
{"id": "1705.06860", "contents": "Title: Beyond Massive-MIMO: The Potential of Positioning with Large Intelligent\n  Surfaces Abstract: We consider the potential for positioning with a system where antenna arrays\nare deployed as a large intelligent surface (LIS), which is a newly proposed\nconcept beyond massive-MIMO where future man-made structures are electronically\nactive with integrated electronics and wireless communication making the entire\nenvironment \\lq\\lq{}intelligent\\rq\\rq{}. In a first step, we derive\nFisher-information and Cram\\'{e}r-Rao lower bounds (CRLBs) in closed-form for\npositioning a terminal located perpendicular to the center of the LIS, whose\nlocation we refer to as being on the central perpendicular line (CPL) of the\nLIS. For a terminal that is not on the CPL, closed-form expressions of the\nFisher-information and CRLB seem out of reach, and we alternatively find\napproximations of them which are shown to be accurate. Under mild conditions,\nwe show that the CRLB for all three Cartesian dimensions ($x$, $y$ and $z$)\ndecreases quadratically in the surface-area of the LIS, except for a terminal\nexactly on the CPL where the CRLB for the $z$-dimension (distance from the LIS)\ndecreases linearly in the same. In a second step, we analyze the CRLB for\npositioning when there is an unknown phase $\\varphi$ presented in the analog\ncircuits of the LIS. We then show that the CRLBs are dramatically increased for\nall three dimensions but decrease in the third-order of the surface-area.\nMoreover, with an infinitely large LIS the CRLB for the $z$-dimension with an\nunknown $\\varphi$ is 6 dB higher than the case without phase uncertainty, and\nthe CRLB for estimating $\\varphi$ converges to a constant that is independent\nof the wavelength $\\lambda$. At last, we extensively discuss the impact of\ncentralized and distributed deployments of LIS, and show that a distributed\ndeployment of LIS can enlarge the coverage for terminal-positioning and improve\nthe overall positioning performance. \n\n"}
{"id": "1705.08572", "contents": "Title: Joint Rate Control and Power Allocation for Non-Orthogonal Multiple\n  Access Systems Abstract: This paper investigates the optimal resource allocation of a downlink\nnon-orthogonal multiple access (NOMA) system consisting of one base station and\nmultiple users. Unlike existing short-term NOMA designs that focused on the\nresource allocation for only the current transmission timeslot, we aim to\nmaximize a long-term network utility by jointly optimizing the data rate\ncontrol at the network layer and the power allocation among multiple users at\nthe physical layer, subject to practical constraints on both the short-term and\nlong-term power consumptions. To solve this problem, we leverage the\nrecently-developed Lyapunov optimization framework to convert the original\nlong-term optimization problem into a series of online rate control and power\nallocation problems in each timeslot. The power allocation problem, however, is\nshown to be non-convex in nature and thus cannot be solved with a standard\nmethod. However, we explore two structures of the optimal solution and develop\na dynamic programming based power allocation algorithm, which can derive a\nglobally optimal solution, with a polynomial computational complexity.\nExtensive simulation results are provided to evaluate the performance of the\nproposed joint rate control and power allocation framework for NOMA systems,\nwhich demonstrate that the proposed NOMA design can significantly outperform\nmultiple benchmark schemes, including orthogonal multiple access (OMA) schemes\nwith optimal power allocation and NOMA schemes with non-optimal power\nallocation, in terms of average throughput and data delay. \n\n"}
{"id": "1705.09076", "contents": "Title: Wireless Powered Communications with Finite Battery and Finite\n  Blocklength Abstract: We analyze a wireless communication system with finite block length and\nfinite battery energy, under quasi-static Nakagami-m fading. Wireless energy\ntransfer is carried out in the downlink while information transfer occurs in\nthe uplink. Transmission strategies for scenarios with/without energy\naccumulation between transmission rounds are characterized in terms of error\nprobability and energy consumption. A power control protocol for the energy\naccumulation scenario is proposed and results show the enormous impact on\nimproving the system performance, in terms of error probability and energy\nconsumption. The numerical results corroborate the existence and uniqueness of\nan optimum target error probability, while showing that a relatively small\nbattery could be a limiting factor for some setups, specially when using the\nenergy accumulation strategy. \n\n"}
{"id": "1705.09258", "contents": "Title: Quantum-secured blockchain Abstract: Blockchain is a distributed database which is cryptographically protected\nagainst malicious modifications. While promising for a wide range of\napplications, current blockchain platforms rely on digital signatures, which\nare vulnerable to attacks by means of quantum computers. The same, albeit to a\nlesser extent, applies to cryptographic hash functions that are used in\npreparing new blocks, so parties with access to quantum computation would have\nunfair advantage in procuring mining rewards. Here we propose a possible\nsolution to the quantum era blockchain challenge and report an experimental\nrealization of a quantum-safe blockchain platform that utilizes quantum key\ndistribution across an urban fiber network for information-theoretically secure\nauthentication. These results address important questions about realizability\nand scalability of quantum-safe blockchains for commercial and governmental\napplications. \n\n"}
{"id": "1705.09391", "contents": "Title: Discovering Reliable Approximate Functional Dependencies Abstract: Given a database and a target attribute of interest, how can we tell whether\nthere exists a functional, or approximately functional dependence of the target\non any set of other attributes in the data? How can we reliably, without bias\nto sample size or dimensionality, measure the strength of such a dependence?\nAnd, how can we efficiently discover the optimal or $\\alpha$-approximate\ntop-$k$ dependencies? These are exactly the questions we answer in this paper.\n  As we want to be agnostic on the form of the dependence, we adopt an\ninformation-theoretic approach, and construct a reliable, bias correcting score\nthat can be efficiently computed. Moreover, we give an effective optimistic\nestimator of this score, by which for the first time we can mine the\napproximate functional dependencies from data with guarantees of optimality.\nEmpirical evaluation shows that the derived score achieves a good bias for\nvariance trade-off, can be used within an efficient discovery algorithm, and\nindeed discovers meaningful dependencies. Most important, it remains reliable\nin the face of data sparsity. \n\n"}
{"id": "1705.09769", "contents": "Title: Efficient 3D Placement of a UAV Using Particle Swarm Optimization Abstract: Unmanned aerial vehicles (UAVs) can be used as aerial wireless base stations\nwhen cellular networks go down. Prior studies on UAV-based wireless coverage\ntypically consider an Air-to-Ground path loss model, which assumes that the\nusers are outdoor and they are located on a 2D plane. In this paper, we propose\nusing a single UAV to provide wireless coverage for indoor users inside a\nhigh-rise building under disaster situations (such as earthquakes or floods),\nwhen cellular networks are down. We assume that the locations of indoor users\nare uniformly distributed in each floor and we propose a particle swarm\noptimization algorithm to find an efficient 3D placement of a UAV that\nminimizes the total transmit power required to cover the indoor users. \n\n"}
{"id": "1706.00307", "contents": "Title: Energy Harvesting Networks with General Utility Functions: Near Optimal\n  Online Policies Abstract: We consider online scheduling policies for single-user energy harvesting\ncommunication systems, where the goal is to characterize online policies that\nmaximize the long term average utility, for some general concave and\nmonotonically increasing utility function. In our setting, the transmitter\nrelies on energy harvested from nature to send its messages to the receiver,\nand is equipped with a finite-sized battery to store its energy. Energy packets\nare independent and identically distributed (i.i.d.) over time slots, and are\nrevealed causally to the transmitter. Only the average arrival rate is known a\npriori. We first characterize the optimal solution for the case of Bernoulli\narrivals. Then, for general i.i.d. arrivals, we first show that fixed fraction\npolicies [Shaviv-Ozgur] are within a constant multiplicative gap from the\noptimal solution for all energy arrivals and battery sizes. We then derive a\nset of sufficient conditions on the utility function to guarantee that fixed\nfraction policies are within a constant additive gap as well from the optimal\nsolution. \n\n"}
{"id": "1706.00399", "contents": "Title: Benchmark problems for phase retrieval Abstract: In recent years, the mathematical and algorithmic aspects of the phase\nretrieval problem have received considerable attention. Many papers in this\narea mention crystallography as a principal application. In crystallography,\nthe signal to be recovered is periodic and comprised of atomic distributions\narranged homogeneously in the unit cell of the crystal. The crystallographic\nproblem is both the leading application and one of the hardest forms of phase\nretrieval. We have constructed a graded set of benchmark problems for\nevaluating algorithms that perform this type of phase retrieval. The data,\npublicly available online, is provided in an easily interpretable format. We\nalso propose a simple and unambiguous success/failure criterion based on the\nactual needs in crystallography. Baseline runtimes were obtained with an\niterative algorithm that is similar but more transparent than those used in\ncrystallography. Empirically, the runtimes grow exponentially with respect to a\nnew hardness parameter: the sparsity of the signal autocorrelation. We also\nreview the algorithms used by the leading software packages. This set of\nbenchmark problems, we hope, will encourage the development of new algorithms\nfor the phase retrieval problem in general, and crystallography in particular. \n\n"}
{"id": "1706.00668", "contents": "Title: The role of asymptotic functions in network optimization and feasibility\n  studies Abstract: Solutions to network optimization problems have greatly benefited from\ndevelopments in nonlinear analysis, and, in particular, from developments in\nconvex optimization. A key concept that has made convex and nonconvex analysis\nan important tool in science and engineering is the notion of asymptotic\nfunction, which is often hidden in many influential studies on nonlinear\nanalysis and related fields. Therefore, we can also expect that asymptotic\nfunctions are deeply connected to many results in the wireless domain, even\nthough they are rarely mentioned in the wireless literature. In this study, we\nshow connections of this type. By doing so, we explain many properties of\ncentralized and distributed solutions to wireless resource allocation problems\nwithin a unified framework, and we also generalize and unify existing\napproaches to feasibility analysis of network designs. In particular, we show\nsufficient and necessary conditions for mappings widely used in wireless\ncommunication problems (more precisely, the class of standard interference\nmappings) to have a fixed point. Furthermore, we derive fundamental bounds on\nthe utility and the energy efficiency that can be achieved by solving a large\nfamily of max-min utility optimization problems in wireless networks. \n\n"}
{"id": "1706.00862", "contents": "Title: Efficient Textual Representation of Structure Abstract: This paper attempts a more formal approach to the legibility of text based\nprogramming languages, presenting, with proof, minimum possible ways of\nrepresenting structure in text interleaved with information. This presumes that\na minimalist approach is best for purposes of human readability, data storage\nand transmission, and machine evaluation.\n  Several proposals are given for improving the expression of interleaved\nhierarchical structure. For instance, a single colon can replace a pair of\nbrackets, and bracket types do not need to be repeated in both opening and\nclosing symbols or words. Historic and customary uses of punctuation symbols\nguided the chosen form and nature of the improvements. \n\n"}
{"id": "1706.01628", "contents": "Title: Optimal Attack against Cyber-Physical Control Systems with Reactive\n  Attack Mitigation Abstract: This paper studies the performance and resilience of a cyber-physical control\nsystem (CPCS) with attack detection and reactive attack mitigation. It\naddresses the problem of deriving an optimal sequence of false data injection\nattacks that maximizes the state estimation error of the system. The results\nprovide basic understanding about the limit of the attack impact. The design of\nthe optimal attack is based on a Markov decision process (MDP) formulation,\nwhich is solved efficiently using the value iteration method. Using the\nproposed framework, we quantify the effect of false positives and\nmis-detections on the system performance, which can help the joint design of\nthe attack detection and mitigation. To demonstrate the use of the proposed\nframework in a real-world CPCS, we consider the voltage control system of power\ngrids, and run extensive simulations using PowerWorld, a high-fidelity power\nsystem simulator, to validate our analysis. The results show that by carefully\ndesigning the attack sequence using our proposed approach, the attacker can\ncause a large deviation of the bus voltages from the desired setpoint. Further,\nthe results verify the optimality of the derived attack sequence and show that,\nto cause maximum impact, the attacker must carefully craft his attack to strike\na balance between the attack magnitude and stealthiness, due to the\nsimultaneous presence of attack detection and mitigation. \n\n"}
{"id": "1706.02731", "contents": "Title: Capacity Comparison between MIMO-NOMA and MIMO-OMA with Multiple Users\n  in a Cluster Abstract: In this paper, the performance of multiple-input multiple-output\nnon-orthogonal multiple access (MIMO-NOMA) is investigated when multiple users\nare grouped into a cluster. The superiority of MIMO-NOMA over MIMO orthogonal\nmultiple access (MIMO-OMA) in terms of both sum channel capacity and ergodic\nsum capacity is proved analytically. Furthermore, it is demonstrated that the\nmore users are admitted to a cluster, the lower is the achieved sum rate, which\nillustrates the tradeoff between the sum rate and maximum number of admitted\nusers. On this basis, a user admission scheme is proposed, which is optimal in\nterms of both sum rate and number of admitted users when the\nsignal-to-interference-plus-noise ratio thresholds of the users are equal. When\nthese thresholds are different, the proposed scheme still achieves good\nperformance in balancing both criteria. Moreover, under certain conditions,it\nmaximizes the number of admitted users. In addition, the complexity of the\nproposed scheme is linear to the number of users per cluster. Simulation\nresults verify the superiority of MIMO-NOMA over MIMO-OMA in terms of both sum\nrate and user fairness, as well as the effectiveness of the proposed user\nadmission scheme. \n\n"}
{"id": "1706.05347", "contents": "Title: A Survey on Non-Orthogonal Multiple Access for 5G Networks: Research\n  Challenges and Future Trends Abstract: Non-orthogonal multiple access (NOMA) is an essential enabling technology for\nthe fifth generation (5G) wireless networks to meet the heterogeneous demands\non low latency, high reliability, massive connectivity, improved fairness, and\nhigh throughput. The key idea behind NOMA is to serve multiple users in the\nsame resource block, such as a time slot, subcarrier, or spreading code. The\nNOMA principle is a general framework, and several recently proposed 5G\nmultiple access schemes can be viewed as special cases. This survey provides an\noverview of the latest NOMA research and innovations as well as their\napplications. Thereby, the papers published in this special issue are put into\nthe content of the existing literature. Future research challenges regarding\nNOMA in 5G and beyond are also discussed. \n\n"}
{"id": "1706.06451", "contents": "Title: Control-Data Separation with Decentralized Edge Control in Fog-Assisted\n  Uplink Communications Abstract: Fog-aided network architectures for 5G systems encompass wireless edge nodes,\nreferred to as remote radio systems (RRSs), as well as remote cloud center\n(RCC) processors, which are connected to the RRSs via a fronthaul access\nnetwork. RRSs and RCC are operated via Network Functions Virtualization (NFV),\nenabling a flexible split of network functionalities that adapts to network\nparameters such as fronthaul latency and capacity. This work focuses on uplink\ncommunications and investigates the cloud-edge allocation of two important\nnetwork functions, namely the control functionality of rate selection and the\ndata-plane function of decoding. Three functional splits are considered: (i)\nDistributed Radio Access Network (D-RAN), in which both functions are\nimplemented in a decentralized way at the RRSs, (ii) Cloud RAN (C-RAN), in\nwhich instead both functions are carried out centrally at the RCC, and (iii) a\nnew functional split, referred to as Fog RAN (F-RAN), with separate\ndecentralized edge control and centralized cloud data processing. The model\nunder study consists of a time-varying uplink channel in which the RCC has\nglobal but delayed channel state information (CSI) due to fronthaul latency,\nwhile the RRSs have local but more timely CSI. Using the adaptive sum-rate as\nthe performance criterion, it is concluded that the F-RAN architecture can\nprovide significant gains in the presence of user mobility. \n\n"}
{"id": "1706.09918", "contents": "Title: User Activity Detection in Massive Random Access: Compressed Sensing vs.\n  Coded Slotted ALOHA Abstract: Machine-type communication services in mobile cel- lular systems are\ncurrently evolving with an aim to efficiently address a massive-scale user\naccess to the system. One of the key problems in this respect is to efficiently\nidentify active users in order to allocate them resources for the subsequent\ntransmissions. In this paper, we examine two recently suggested approaches for\nuser activity detection: compressed-sensing (CS) and coded slotted ALOHA (CSA),\nand provide their comparison in terms of performance vs resource utilization.\nOur preliminary results show that CS-based approach is able to provide the\ntarget user activity detection performance with less overall system resource\nutilization. However, this comes at a price of lower energy- efficiency per\nuser, as compared to CSA-based approach. \n\n"}
{"id": "1707.00808", "contents": "Title: Deconvolution of Point Sources: A Sampling Theorem and Robustness\n  Guarantees Abstract: In this work we analyze a convex-programming method for estimating\nsuperpositions of point sources or spikes from nonuniform samples of their\nconvolution with a known kernel. We consider a one-dimensional model where the\nkernel is either a Gaussian function or a Ricker wavelet, inspired by\napplications in geophysics and imaging. Our analysis establishes that\nminimizing a continuous counterpart of the $\\ell_1$ norm achieves exact\nrecovery of the original spikes as long as (1) the signal support satisfies a\nminimum-separation condition and (2) there are at least two samples close to\nevery spike. In addition, we derive theoretical guarantees on the robustness of\nthe approach to both dense and sparse additive noise. \n\n"}
{"id": "1707.01203", "contents": "Title: Estimating the Fundamental Limits is Easier than Achieving the\n  Fundamental Limits Abstract: We show through case studies that it is easier to estimate the fundamental\nlimits of data processing than to construct explicit algorithms to achieve\nthose limits. Focusing on binary classification, data compression, and\nprediction under logarithmic loss, we show that in the finite space setting,\nwhen it is possible to construct an estimator of the limits with vanishing\nerror with $n$ samples, it may require at least $n\\ln n$ samples to construct\nan explicit algorithm to achieve the limits. \n\n"}
{"id": "1707.04875", "contents": "Title: Coding sets with asymmetric information Abstract: We study the following one-way asymmetric transmission problem, also a\nvariant of model-based compressed sensing: a resource-limited encoder has to\nreport a small set $S$ from a universe of $N$ items to a more powerful decoder\n(server). The distinguishing feature is asymmetric information: the subset $S$\nis comprised of i.i.d. samples from a prior distribution $\\mu$, and $\\mu$ is\nonly known to the decoder. The goal for the encoder is to encode $S$\nobliviously, while achieving the information-theoretic bound of $|S| \\cdot\nH(\\mu)$, i.e., the Shannon entropy bound.\n  We first show that any such compression scheme must be {\\em randomized}, if\nit gains non-trivially from the prior $\\mu$. This stands in contrast to the\nsymmetric case (when both the encoder and decoder know $\\mu$), where the\nHuffman code provides a near-optimal deterministic solution. On the other hand,\na rather simple argument shows that, when $|S|=k$, a random linear code\nachieves near-optimal communication rate of about $k\\cdot H(\\mu)$ bits. Alas,\nthe resulting scheme has prohibitive decoding time: about ${N\\choose k} \\approx\n(N/k)^k$.\n  Our main result is a computationally efficient and linear coding scheme,\nwhich achieves an $O(\\lg\\lg N)$-competitive communication ratio compared to the\noptimal benchmark, and runs in $\\text{poly}(N,k)$ time. Our \"multi-level\"\ncoding scheme uses a combination of hashing and syndrome-decoding of\nReed-Solomon codes, and relies on viewing the (unknown) prior $\\mu$ as a rather\nsmall convex combination of uniform (\"flat\") distributions. \n\n"}
{"id": "1707.05869", "contents": "Title: The Benefit of Encoder Cooperation in the Presence of State Information Abstract: In many communication networks, the availability of channel state information\nat various nodes provides an opportunity for network nodes to work together, or\n\"cooperate.\" This work studies the benefit of cooperation in the multiple\naccess channel with a cooperation facilitator, distributed state information at\nthe encoders, and full state information available at the decoder. Under\nvarious causality constraints, sufficient conditions are obtained such that\nencoder cooperation through the facilitator results in a gain in sum-capacity\nthat has infinite slope in the information rate shared with the encoders. This\nresult extends the prior work of the authors on cooperation in networks where\nnone of the nodes have access to state information. \n\n"}
{"id": "1707.06350", "contents": "Title: On Optimal Power Allocation for Downlink Non-Orthogonal Multiple Access\n  Systems Abstract: Non-orthogonal multiple access (NOMA) enables power-domain multiplexing via\nsuccessive interference cancellation (SIC) and has been viewed as a promising\ntechnology for 5G communication. The full benefit of NOMA depends on resource\nallocation, including power allocation and channel assignment, for all users,\nwhich, however, leads to mixed integer programs. In the literature, the optimal\npower allocation has only been found in some special cases, while the joint\noptimization of power allocation and channel assignment generally requires\nexhaustive search. In this paper, we investigate resource allocation in\ndownlink NOMA systems. As the main contribution, we analytically characterize\nthe optimal power allocation with given channel assignment over multiple\nchannels under different performance criteria. Specifically, we consider the\nmaximin fairness, weighted sum rate maximization, sum rate maximization with\nquality of service (QoS) constraints, energy efficiency maximization with\nweights or QoS constraints in NOMA systems. We also take explicitly into\naccount the order constraints on the powers of the users on each channel, which\nare often ignored in theexisting works, and show that they have a significant\nimpact on SIC in NOMA systems. Then, we provide the optimal power allocation\nfor the considered criteria in closed or semi-closed form. We also propose a\nlow-complexity efficient method to jointly optimize channel assignment and\npower allocation in NOMA systems by incorporating the matching algorithm with\nthe optimal power allocation. Simulation results show that the joint resource\noptimization using our optimal power allocation yields better performance than\nthe existing schemes. \n\n"}
{"id": "1707.08926", "contents": "Title: Non-Coherent Detection for Diffusive Molecular Communications Abstract: We study non-coherent detection schemes for molecular communication (MC)\nsystems that do not require knowledge of the channel state information (CSI).\nIn particular, we first derive the optimal maximum likelihood (ML)\nmultiple-symbol (MS) detector for MC systems. As a special case of the optimal\nMS detector, we show that the optimal ML symbol-by-symbol (SS) detector can be\nequivalently written in the form of a threshold-based detector, where the\noptimal decision threshold is constant and depends only on the statistics of\nthe MC channel. The main challenge of the MS detector is the complexity\nassociated with the calculation of the optimal detection metric. To overcome\nthis issue, we propose an approximate MS detection metric which can be\nexpressed in closed form. To reduce complexity even further, we develop a\nnon-coherent decision-feedback (DF) detector and a suboptimal blind detector.\nFinally, we derive analytical expressions for the bit error rate (BER) of the\noptimal SS detector, as well as upper and lower bounds for the BER of the\noptimal MS detector. Simulation results confirm the analysis and reveal the\neffectiveness of the proposed optimal and suboptimal detection schemes compared\nto a benchmark scheme that assumes perfect CSI knowledge, particularly when the\nnumber of observations used for detection is sufficiently large. \n\n"}
{"id": "1707.09334", "contents": "Title: Compressive Sensing with Cross-Validation and Stop-Sampling for Sparse\n  Polynomial Chaos Expansions Abstract: Compressive sensing is a powerful technique for recovering sparse solutions\nof underdetermined linear systems, which is often encountered in uncertainty\nquantification analysis of expensive and high-dimensional physical models. We\nperform numerical investigations employing several compressive sensing solvers\nthat target the unconstrained LASSO formulation, with a focus on linear systems\nthat arise in the construction of polynomial chaos expansions. With core\nsolvers of l1_ls, SpaRSA, CGIST, FPC_AS, and ADMM, we develop techniques to\nmitigate overfitting through an automated selection of regularization constant\nbased on cross-validation, and a heuristic strategy to guide the stop-sampling\ndecision. Practical recommendations on parameter settings for these techniques\nare provided and discussed. The overall method is applied to a series of\nnumerical examples of increasing complexity, including large eddy simulations\nof supersonic turbulent jet-in-crossflow involving a 24-dimensional input.\nThrough empirical phase-transition diagrams and convergence plots, we\nillustrate sparse recovery performance under structures induced by polynomial\nchaos, accuracy and computational tradeoffs between polynomial bases of\ndifferent degrees, and practicability of conducting compressive sensing for a\nrealistic, high-dimensional physical application. Across test cases studied in\nthis paper, we find ADMM to have demonstrated empirical advantages through\nconsistent lower errors and faster computational times. \n\n"}
{"id": "1707.09441", "contents": "Title: A compressive channel estimation technique robust to synchronization\n  impairments Abstract: Initial access at millimeter wave frequencies is a challenging problem due to\nhardware non-idealities and low SNR measurements prior to beamforming. Prior\nwork has exploited the observation that mmWave MIMO channels are sparse in the\nspatial angle domain and has used compressed sensing based algorithms for\nchannel estimation. Most of them, however, ignore hardware impairments like\ncarrier frequency offset and phase noise, and fail to perform well when such\nimpairments are considered. In this paper, we develop a compressive channel\nestimation algorithm for narrowband mmWave systems, which is robust to such non\nidealities. We address this problem by constructing a tensor that models both\nthe mmWave channel and CFO, and estimate the tensor while still exploiting the\nsparsity of the mmWave channel. Simulation results show that under the same\nsettings, our method performs better than comparable algorithms that are robust\nto phase errors. \n\n"}
{"id": "1708.00617", "contents": "Title: Stabilizer codes from modified symplectic form Abstract: Stabilizer codes form an important class of quantum error correcting codes\nwhich have an elegant theory, efficient error detection, and many known\nexamples. Constructing stabilizer codes of length $n$ is equivalent to\nconstructing subspaces of $\\mathbb{F}_p^n \\times \\mathbb{F}_p^n$ which are\n\"isotropic\" under the symplectic bilinear form defined by $\\left\\langle\n(\\mathbf{a},\\mathbf{b}),(\\mathbf{c},\\mathbf{d}) \\right\\rangle =\n\\mathbf{a}^{\\mathrm{T}} \\mathbf{d} - \\mathbf{b}^{\\mathrm{T}} \\mathbf{c}$. As a\nresult, many, but not all, ideas from the theory of classical error correction\ncan be translated to quantum error correction. One of the main theoretical\ncontribution of this article is to study stabilizer codes starting with a\ndifferent symplectic form.\n  In this paper, we concentrate on cyclic codes. Modifying the symplectic form\nallows us to generalize the previous known construction for linear cyclic\nstabilizer codes, and in the process, circumvent some of the Galois theoretic\nno-go results proved there. More importantly, this tweak in the symplectic form\nallows us to make use of well known error correcting algorithms for cyclic\ncodes to give efficient quantum error correcting algorithms. Cyclicity of error\ncorrecting codes is a \"basis dependent\" property. Our codes are no more\n\"cyclic\" when they are derived using the standard symplectic forms (if we\nignore the error correcting properties like distance, all such symplectic forms\ncan be converted to each other via a basis transformation). Hence this change\nof perspective is crucial from the point of view of designing efficient\ndecoding algorithm for these family of codes. In this context, recall that for\ngeneral codes, efficient decoding algorithms do not exist if some widely\nbelieved complexity theoretic assumptions are true. \n\n"}
{"id": "1708.00905", "contents": "Title: Covert Communication Achieved by A Greedy Relay in Wireless Networks Abstract: Covert communication aims to hide the very existence of wireless\ntransmissions in order to guarantee a strong security in wireless networks. In\nthis work, we examine the possibility and achievable performance of covert\ncommunication in one-way relay networks. Specifically, the relay is greedy and\nopportunistically transmits its own information to the destination covertly on\ntop of forwarding the source's message, while the source tries to detect this\ncovert transmission to discover the illegitimate usage of the resource (e.g.,\npower, spectrum) allocated only for the purpose of forwarding source's\ninformation. We propose two strategies for the relay to transmit its covert\ninformation, namely fixed-rate and fixed-power transmission schemes, for which\nthe source's detection limits are analysed in terms of the false alarm and miss\ndetection rates and the achievable effective covert rates from the relay to\ndestination are derived. Our examination determines the conditions under which\nthe fixed-rate transmission scheme outperforms the fixed-power transmission\nscheme, and vice versa, which enables the relay to achieve the maximum\neffective covert rate. Our analysis indicates that the relay has to forward the\nsource's message to shield its covert transmission and the effective covert\nrate increases with its forwarding ability (e.g., its maximum transmit power). \n\n"}
{"id": "1708.03066", "contents": "Title: Design and Optimization of VoD schemes with Client Caching in Wireless\n  Multicast Networks Abstract: Due to the explosive growth in multimedia traffic, the scalability of\nvideo-on-demand (VoD) services becomes increasingly important. By exploiting\nthe potential cache ability at the client side, the performance of VoD\nmulticast delivery can be improved through video segment pre-caching. In this\npaper, we address the performance limits of client caching enabled VoD schemes\nin wireless multicast networks with asynchronous requests. Both reactive and\nproactive systems are investigated. Specifically, for the reactive system where\nvideos are transmitted on demand, we propose a joint cache allocation and\nmulticast delivery scheme to minimize the average bandwidth consumption under\nthe zero-delay constraint. For the proactive system where videos are\nperiodically broadcasted, a joint design of the cache-bandwidth allocation\nalgorithm and the delivery mechanism is developed to minimize the average\nwaiting time under the total bandwidth constraint. In addition to the full\naccess pattern where clients view videos in their entirety, we further consider\nthe access patterns with random endpoints, fixed-size intervals and downloading\ndemand, respectively. The impacts of different access patterns on the\nresource-allocation algorithm and the delivery mechanism are elaborated.\nSimulation results validate the accuracy of the analytical results and also\nprovide useful insights in designing VoD networks with client caching. \n\n"}
{"id": "1708.04283", "contents": "Title: Key and Message Semantic-Security over State-Dependent Channels Abstract: We study the trade-off between secret message (SM) and secret key (SK) rates,\nsimultaneously achievable over a state-dependent (SD) wiretap channel (WTC)\nwith non-causal channel state information (CSI) at the encoder. This model\nsubsumes other instances of CSI availability as special cases, and calls for\nefficient utilization of the state sequence for both reliability and security\npurposes. An inner bound on the semantic-security (SS) SM-SK capacity region is\nderived based on a superposition coding scheme inspired by a past work of the\nauthors. The region is shown to attain capacity for a certain class of SD-WTCs.\nSS is established by virtue of two versions of the strong soft-covering lemma.\nThe derived region yields an improvement upon the previously best known SM-SK\ntrade-off result reported by Prabhakaran et al., and, to the best of our\nknowledge, upon all other existing lower bounds for either SM or SK for this\nsetup, even if the semantic security requirement is relaxed to weak secrecy. It\nis demonstrated that our region can be strictly larger than those reported in\nthe preceding works. \n\n"}
{"id": "1708.06012", "contents": "Title: Product Matrix Minimum Storage Regenerating Codes with Flexible Number\n  of Helpers Abstract: In coding for distributed storage systems, efficient data reconstruction and\nrepair through accessing a predefined number of arbitrarily chosen storage\nnodes is guaranteed by regenerating codes. Traditionally, code parameters,\nspecially the number of helper nodes participating in a repair process, are\npredetermined. However, depending on the state of the system and network\ntraffic, it is desirable to adapt such parameters accordingly in order to\nminimize the cost of repair. In this work a class of regenerating codes with\nminimum storage is introduced that can simultaneously operate at the optimal\nrepair bandwidth, for a wide range of exact repair mechanisms, based on\ndifferent number of helper nodes. \n\n"}
{"id": "1709.00132", "contents": "Title: A Secure Approach for Caching Contents in Wireless Ad Hoc Networks Abstract: Caching aims to store data locally in some nodes within the network to be\nable to retrieve the contents in shorter time periods. However, caching in the\nnetwork did not always consider secure storage (due to the compromise between\ntime performance and security). In this paper, a novel decentralized secure\ncoded caching approach is proposed. In this solution, nodes only transmit coded\nfiles to avoid eavesdropper wiretapping and protect the user contents. In this\ntechnique random vectors are used to combine the contents using XOR operation.\nWe modeled the proposed coded caching scheme by a Shannon cipher system to show\nthat coded caching achieves asymptotic perfect secrecy. The proposed coded\ncaching scheme significantly simplifies the routing protocol in cached networks\nwhile it reduces over-caching and achieves a higher throughput capacity\ncompared to uncoded caching in reactive routing. It is shown that with the\nproposed coded caching scheme any content can be retrieved by selecting a\nrandom path while achieving asymptotic optimum solution. We have also studied\nthe cache hit probability and shown that the coded cache hit probability is\nsignificantly higher than uncoded caching. A secure caching update algorithm is\nalso presented. \n\n"}
{"id": "1709.01746", "contents": "Title: Information-theoretic analysis of the directional influence between\n  cellular processes Abstract: Inferring the directionality of interactions between cellular processes is a\nmajor challenge in systems biology. Time-lagged correlations allow to\ndiscriminate between alternative models, but they still rely on assumed\nunderlying interactions. Here, we use the transfer entropy (TE), an\ninformation-theoretic quantity that quantifies the directional influence\nbetween fluctuating variables in a model-free way. We present a theoretical\napproach to compute the transfer entropy, even when the noise has an extrinsic\ncomponent or in the presence of feedback. We re-analyze the experimental data\nfrom Kiviet et al. (2014) where fluctuations in gene expression of metabolic\nenzymes and growth rate have been measured in single cells of E. coli. We\nconfirm the formerly detected modes between growth and gene expression, while\nprescribing more stringent conditions on the structure of noise sources. We\nfurthermore point out practical requirements in terms of length of time series\nand sampling time which must be satisfied in order to infer optimally transfer\nentropy from times series of fluctuations. \n\n"}
{"id": "1709.02917", "contents": "Title: Sublinear-Time Algorithms for Compressive Phase Retrieval Abstract: In the compressive phase retrieval problem, or phaseless compressed sensing,\nor compressed sensing from intensity only measurements, the goal is to\nreconstruct a sparse or approximately $k$-sparse vector $x \\in \\mathbb{R}^n$\ngiven access to $y= |\\Phi x|$, where $|v|$ denotes the vector obtained from\ntaking the absolute value of $v\\in\\mathbb{R}^n$ coordinate-wise. In this paper\nwe present sublinear-time algorithms for different variants of the compressive\nphase retrieval problem which are akin to the variants considered for the\nclassical compressive sensing problem in theoretical computer science. Our\nalgorithms use pure combinatorial techniques and near-optimal number of\nmeasurements. \n\n"}
{"id": "1709.05733", "contents": "Title: The Stochastic Geometry Analyses of Cellular Networks with\n  {\\alpha}-Stable Self-Similarity Abstract: To understand the spatial deployment of base stations (BSs) is the first step\nto analyze the performance of cellular networks and further design efficient\nnetworking protocols. Poisson point process (PPP), which has been widely\nadopted to characterize the deployment of BSs and established the reputation to\ngive tractable results in the stochastic geometry analyses, usually assumes a\nstatic BS deployment density in homogeneous PPP (HPPP) models or delicately\ndesigned location-dependent density functions in in-homogeneous PPP (IPPP)\nmodels. However, the simultaneous existence of attractiveness and repulsiveness\namong BSs practically deployed in a large-scale area defies such an assumption,\nand the $\\alpha$-stable distribution, one kind of heavy-tailed distributions,\nhas recently demonstrated superior accuracy to statistically model the varying\nBS density in different areas. In this paper, we start with these new findings\nand investigate the intrinsic feature (i.e., the spatial self-similarity)\nembedded in the BSs. Afterwards, we refer to a generalized PPP setup with\n$\\alpha$-stable distributed density and theoretically derive the related\ncoverage probability. In particular, we give an upper bound of the derived\ncoverage probability for high signal-to-interference-plus-noise ratio (SINR)\nthresholds and show the monotonically decreasing property of this bound with\nrespect to the variance of BS density. Besides, we prove that our model could\nreduce to the single-tier HPPP for some special cases, and demonstrate the\nsuperior accuracy of the $\\alpha$-stable model to approach the real\nenvironment. \n\n"}
{"id": "1709.08577", "contents": "Title: Coverage Analysis of a Vehicular Network Modeled as Cox Process Driven\n  by Poisson Line Process Abstract: In this paper, we consider a vehicular network in which the wireless nodes\nare located on a system of roads. We model the roadways, which are\npredominantly straight and randomly oriented, by a Poisson line process (PLP)\nand the locations of nodes on each road as a homogeneous 1D Poisson point\nprocess (PPP). Assuming that each node transmits independently, the locations\nof transmitting and receiving nodes are given by two Cox processes driven by\nthe same PLP. For this setup, we derive the coverage probability of a typical\nreceiver, which is an arbitrarily chosen receiving node, assuming independent\nNakagami-$m$ fading over all wireless channels. Assuming that the typical\nreceiver connects to its closest transmitting node in the network, we first\nderive the distribution of the distance between the typical receiver and the\nserving node to characterize the desired signal power. We then characterize\ncoverage probability for this setup, which involves two key technical\nchallenges. First, we need to handle several cases as the serving node can\npossibly be located on any line in the network and the corresponding\ninterference experienced at the typical receiver is different in each case.\nSecond, conditioning on the serving node imposes constraints on the spatial\nconfiguration of lines, which require careful analysis of the conditional\ndistribution of the lines. We address these challenges in order to accurately\ncharacterize the interference experienced at the typical receiver. We then\nderive an exact expression for coverage probability in terms of the derivative\nof Laplace transform of interference power distribution. We analyze the trends\nin coverage probability as a function of the network parameters: line density\nand node density. We also study the asymptotic behavior of this model and\ncompare the coverage performance with that of a homogeneous 2D PPP model with\nthe same node density. \n\n"}
{"id": "1709.09279", "contents": "Title: From Blind deconvolution to Blind Super-Resolution through convex\n  programming Abstract: This paper discusses the recovery of an unknown signal $x\\in \\mathbb{R}^L$\nthrough the result of its convolution with an unknown filter $h \\in\n\\mathbb{R}^L$. This problem, also known as blind deconvolution, has been\nstudied extensively by the signal processing and applied mathematics\ncommunities, leading to a diversity of proofs and algorithms based on various\nassumptions on the filter and its input. Sparsity of this filter, or in\ncontrast, non vanishing of its Fourier transform are instances of such\nassumptions. The main result of this paper shows that blind deconvolution can\nbe solved through nuclear norm relaxation in the case of a fully unknown\nchannel, as soon as this channel is probed through a few $N \\gtrsim \\mu^2_m\nK^{1/2}$ input signals $x_n = C_n m_n$, $n=1,\\ldots,N,$ that are living in\nknown $K$-dimensional subspaces $C_n$ of $\\mathbb{R}^L$. This result holds with\nhigh probability on the genericity of the subspaces $C_n$ as soon as $L\\gtrsim\nK^{3/2}$ and $N\\gtrsim K^{1/2}$ up to log factors. Our proof system relies on\nthe construction of a certificate of optimality for the underlying convex\nprogram. This certificate expands as a Neumann series and is shown to satisfy\nthe conditions for the recovery of the matrix encoding the unknowns by\ncontrolling the terms in this series. An incidental consequence of the result\nof this paper, following from the lack of assumptions on the filter, is that\nnuclear norm relaxation can be extended from blind deconvolution to blind\nsuper-resolution, as soon as the unknown ideal low pass filter has a\nsufficiently large support compared to the ambient dimension $L$. Numerical\nexperiments supporting the theory as well as its application to blind\nsuper-resolution are provided. \n\n"}
{"id": "1709.09765", "contents": "Title: State Estimation in Smart Distribution System With Low-Precision\n  Measurements Abstract: Efficient and accurate state estimation is essential for the optimal\nmanagement of the future smart grid. However, to meet the requirements of\ndeploying the future grid at a large scale, the state estimation algorithm must\nbe able to accomplish two major tasks: (1) combining measurement data with\ndifferent qualities to attain an optimal state estimate and (2) dealing with\nthe large number of measurement data rendered by meter devices. To address\nthese two tasks, we first propose a practical solution using a very short word\nlength to represent a partial measurement of the system state in the meter\ndevice to reduce the amount of data. We then develop a unified probabilistic\nframework based on a Bayesian belief inference to incorporate measurements of\ndifferent qualities to obtain an optimal state estimate. Simulation results\ndemonstrate that the proposed scheme significantly outperforms other linear\nestimators in different test scenarios. These findings indicate that the\nproposed scheme not only has the ability to integrate data with different\nqualities but can also decrease the amount of data that needs to be transmitted\nand processed. \n\n"}
{"id": "1709.10119", "contents": "Title: Distributed Join-the-Idle-Queue for Low Latency Cloud Services Abstract: Low latency is highly desirable for cloud services. To achieve low response\ntime, stringent timing requirements are needed for task scheduling in a\nlarge-scale server farm spanning thousands of servers. In this paper, we\nconduct an in-depth analysis for distributed Join-the-Idle-Queue (JIQ), a\npromising new approximation of an idealized task-scheduling algorithm. In\nparticular, we derive semi-closed form expressions for the delay performance of\ndistributed JIQ, and we propose a new variant of distributed JIQ that offers\nclear advantages over alternative algorithms for large systems. \n\n"}
{"id": "1709.10371", "contents": "Title: Multi-Kernel Polar Codes: Proof of Polarization and Error Exponents Abstract: In this paper, we investigate a novel family of polar codes based on\nmulti-kernel constructions, proving that this construction actually polarizes.\nTo this end, we derive a new and more general proof of polarization, which\ngives sufficient conditions for kernels to polarize. Finally, we derive the\nconvergence rate of the multi-kernel construction and relate it to the\nconvergence rate of each of the constituent kernels. \n\n"}
{"id": "1710.00784", "contents": "Title: Cache Placement in Fog-RANs: From Centralized to Distributed Algorithms Abstract: To deal with the rapid growth of high-speed and/or ultra-low latency data\ntraffic for massive mobile users, fog radio access networks (Fog-RANs) have\nemerged as a promising architecture for next-generation wireless networks. In\nFog-RANs, the edge nodes and user terminals possess storage, computation and\ncommunication functionalities to various degrees, which provides high\nflexibility for network operation, i.e., from fully centralized to fully\ndistributed operation. In this paper, we study the cache placement problem in\nFog-RANs, by taking into account flexible physical-layer transmission schemes\nand diverse content preferences of different users. We develop both centralized\nand distributed transmission aware cache placement strategies to minimize\nusers' average download delay subject to the storage capacity constraints. In\nthe centralized mode, the cache placement problem is transformed into a matroid\nconstrained submodular maximization problem, and an approximation algorithm is\nproposed to find a solution within a constant factor to the optimum. In the\ndistributed mode, a belief propagation based distributed algorithm is proposed\nto provide a suboptimal solution, with iterative updates at each BS based on\nlocally collected information. Simulation results show that by exploiting\ncaching and cooperation gains, the proposed transmission aware caching\nalgorithms can greatly reduce the users' average download delay. \n\n"}
{"id": "1710.01381", "contents": "Title: Generalized Colonel Blotto Game Abstract: Competitive resource allocation between adversarial decision makers arises in\na wide spectrum of real-world applications such as in communication systems,\ncyber-physical systems security, as well as financial, political, and electoral\ncompetition. As such, developing analytical tools to model and analyze\ncompetitive resource allocation is crucial for devising optimal allocation\nstrategies and anticipating the potential outcomes of the competition. To this\nend, the Colonel Blotto game is one of the most popular game-theoretic\nframeworks for modeling and analyzing such competitive resource allocation\nproblems. However, in many real-world competitive situations, the Colonel\nBlotto game does not admit solutions in deterministic strategies and, hence,\none must rely on analytically complex mixed-strategies with their associated\ntractability, applicability, and practicality challenges. In this paper, a\ngeneralization of the Colonel Blotto game which enables the derivation of\ndeterministic, practical, and implementable equilibrium strategies is proposed\nwhile accounting for the heterogeneity of the battlefields. In addition, the\nproposed generalized game enables accounting for the consumed resources in each\nbattlefield, a feature that is not considered in the classical Blotto game. For\nthe generalized game, the existence of a Nash equilibrium in pure-strategies is\nshown. Then, closed-form analytical expressions of the equilibrium strategies,\nare derived and the outcome of the game is characterized; based on the number\nof resources of each player as well as the valuation of each battlefield. The\ngenerated results provide invaluable insights on the outcome of the\ncompetition. For example, the results show that, when both players are fully\nrational, the more resourceful player can achieve a better total payoff at the\nNash equilibrium, a result that is not mimicked in the classical Blotto game. \n\n"}
{"id": "1710.03109", "contents": "Title: Skew and linearized Reed-Solomon codes and maximum sum rank distance\n  codes over any division ring Abstract: Reed-Solomon codes and Gabidulin codes have maximum Hamming distance and\nmaximum rank distance, respectively. A general construction using skew\npolynomials, called skew Reed-Solomon codes, has already been introduced in the\nliterature. In this work, we introduce a linearized version of such codes,\ncalled linearized Reed-Solomon codes. We prove that they have maximum sum-rank\ndistance. Such distance is of interest in multishot network coding or in\nsingleshot multi-network coding. To prove our result, we introduce new metrics\ndefined by skew polynomials, which we call skew metrics, we prove that skew\nReed-Solomon codes have maximum skew distance, and then we translate this\nscenario to linearized Reed-Solomon codes and the sum-rank metric. The theories\nof Reed-Solomon codes and Gabidulin codes are particular cases of our theory,\nand the sum-rank metric extends both the Hamming and rank metrics. We develop\nour theory over any division ring (commutative or non-commutative field). We\nalso consider non-zero derivations, which give new maximum rank distance codes\nover infinite fields not considered before. \n\n"}
{"id": "1710.03287", "contents": "Title: One-bit compressed sensing with partial Gaussian circulant matrices Abstract: In this paper we consider memoryless one-bit compressed sensing with randomly\nsubsampled Gaussian circulant matrices. We show that in a small sparsity regime\nand for small enough accuracy $\\delta$, $m\\sim \\delta^{-4} s\\log(N/s\\delta)$\nmeasurements suffice to reconstruct the direction of any $s$-sparse vector up\nto accuracy $\\delta$ via an efficient program. We derive this result by proving\nthat partial Gaussian circulant matrices satisfy an $\\ell_1/\\ell_2$\nRIP-property. Under a slightly worse dependence on $\\delta$, we establish\nstability with respect to approximate sparsity, as well as full vector recovery\nresults. \n\n"}
{"id": "1710.04971", "contents": "Title: Average Age of Information with Hybrid ARQ under a Resource Constraint Abstract: Scheduling of the transmission of status updates over an error-prone\ncommunication channel is studied in order to minimize the long-term average age\nof information (AoI) at the destination, under an average resource constraint\nat the source node, which limits the average number of transmissions. After\neach transmission, the source receives an instantaneous ACK/NACK feedback, and\ndecides on the next update, without a priori knowledge on the success of the\nfuture transmissions. The optimal scheduling policy is studied under different\nfeedback mechanisms; in particular, standard automatic repeat request (ARQ) and\nhybrid ARQ (HARQ) protocols are considered. Average-cost reinforcement learning\nalgorithms are proposed when the error probabilities for the HARQ system are\nunknown. \n\n"}
{"id": "1710.05063", "contents": "Title: A Distributed Auction Policy for User Association in Device-to-Device\n  Caching Networks Abstract: We propose a distributed bidding-aided Matern carrier sense multiple access\n(CSMA) policy for device-to-device (D2D) content distribution. The network is\ncomposed of D2D receivers and potential D2D transmitters, i.e., transmitters\nare turned on or off by the scheduling algorithm. Each D2D receiver determines\nthe value of its request, by bidding on the set of potential transmitters in\nits communication range. Given a medium access probability, a fraction of the\npotential transmitters are jointly scheduled, i.e., turned on, determined\njointly by the auction policy and the power control scheme. The bidding-aided\nscheduling algorithm exploits (i) the local demand distribution, (ii) spatial\ndistribution of D2D node locations, and (iii) the cache configurations of the\npotential transmitters. We contrast the performance of the bidding-aided CSMA\npolicy with other well-known CSMA schemes that do not take into account\n(i)-(iii), demonstrate that our algorithm achieves a higher spectral efficiency\nin terms of the number of bits transmitted per unit time per unit bandwidth per\nuser. The gain becomes even more visible under randomized configurations and\nrequests rather than more skewed placement configurations and deterministic\ndemand distributions. \n\n"}
{"id": "1710.07153", "contents": "Title: Generalized Water-filling for Source-aware Energy-efficient SRAMs Abstract: Conventional low-power static random access memories (SRAMs) reduce read\nenergy by decreasing the bit-line voltage swings uniformly across the bit-line\ncolumns. This is because the read energy is proportional to the bit-line\nswings. On the other hand, bit-line swings are limited by the need to avoid\ndecision errors especially in the most significant bits. We propose an\ninformation-theoretic approach to determine optimal non-uniform bit-line swings\nby formulating convex optimization problems. For a given constraint on mean\nsquared error of retrieved words, we consider criteria to minimize energy (for\nlow-power SRAMs), maximize speed (for high-speed SRAMs), and minimize\nenergy-delay product. These optimization problems can be interpreted as\nclassical water-filling, ground-flattening and water-filling, and sand-pouring\nand water-filling, respectively. By leveraging these interpretations, we also\npropose greedy algorithms to obtain optimized discrete swings. Numerical\nresults show that energy-optimal swing assignment reduces energy consumption by\nhalf at a peak signal-to-noise ratio of 30dB for an 8-bit accessed word. The\nenergy savings increase to four times for a 16-bit accessed word. \n\n"}
{"id": "1710.07319", "contents": "Title: Atypicality for Heart Rate Variability Using a Pattern-Tree Weighting\n  Method Abstract: Heart rate variability (HRV) is a vital measure of the autonomic nervous\nsystem functionality and a key indicator of cardiovascular condition. This\npaper proposes a novel method, called pattern tree which is an extension of\nWillem's context tree to real-valued data, to investigate HRV via an\natypicality framework. In a previous paper atypicality was developed as method\nfor mining and discovery in \"Big Data,\" which requires a universal approach.\nUsing the proposed pattern tree as a universal source coder in this framework\nled to discovery of arrhythmias and unknown patterns in HRV Holter Monitoring. \n\n"}
{"id": "1710.07617", "contents": "Title: Asymptotically Optimal Resource Block Allocation With Limited Feedback Abstract: Consider a channel allocation problem over a frequency-selective\nchannel.There are K channels (frequency bands) and N users such that K=bN for\nsome positive integer b. We want to allocate b channels (or resource blocks) to\neach user. Due to the nature of the frequency-selective channel, each user\nconsiders some channels to be better than others. The optimal solution to this\nresource allocation problem can be computed using the Hungarian algorithm.\nHowever, this requires knowledge of the numerical value of all the channel\ngains, which makes this approach impractical for large networks. We suggest a\nsuboptimal approach, that only requires knowing what the M-best channels of\neach user are. We find the minimal value of M such that there exists an\nallocation where all the b channels each user gets are among his M-best. This\nleads to feedback of significantly less than one bit per user per channel. For\na large class of fading distributions, including Rayleigh, Rician, m-Nakagami\nand others, this suboptimal approach leads to both an asymptotically (in K)\noptimal sum-rate and an asymptotically optimal minimal rate. Our\nnon-opportunistic approach achieves (asymptotically) full multiuser diversity\nas well as optimal fairness, by contrast to all other limited feedback\nalgorithms. \n\n"}
{"id": "1710.08214", "contents": "Title: Parametric channel estimation for massive MIMO Abstract: Channel state information is crucial to achieving the capacity of\nmulti-antenna (MIMO) wireless communication systems. It requires estimating the\nchannel matrix. This estimation task is studied, considering a sparse channel\nmodel particularly suited to millimeter wave propagation, as well as a general\nmeasurement model taking into account hybrid architectures. The contribution is\ntwofold. First, the Cram{\\'e}r-Rao bound in this context is derived. Second,\ninterpretation of the Fisher Information Matrix structure allows to assess the\nrole of system parameters, as well as to propose asymptotically optimal and\ncomputationally efficient estimation algorithms. \n\n"}
{"id": "1710.08671", "contents": "Title: Linear State Estimation via 5G C-RAN Cellular Networks using Gaussian\n  Belief Propagation Abstract: Machine-type communications and large-scale information processing\narchitectures are among key (r)evolutionary enhancements of emerging\nfifth-generation (5G) mobile cellular networks. Massive data acquisition and\nprocessing will make 5G network an ideal platform for large-scale system\nmonitoring and control with applications in future smart transportation,\nconnected industry, power grids, etc. In this work, we investigate a capability\nof such a 5G network architecture to provide the state estimate of an\nunderlying linear system from the input obtained via large-scale deployment of\nmeasurement devices. Assuming that the measurements are communicated via\ndensely deployed cloud radio access network (C-RAN), we formulate and solve the\nproblem of estimating the system state from the set of signals collected at\nC-RAN base stations. Our solution, based on the Gaussian Belief-Propagation\n(GBP) framework, allows for large-scale and distributed deployment within the\nemerging 5G information processing architectures. The presented numerical study\ndemonstrates the accuracy, convergence behavior and scalability of the proposed\nGBP-based solution to the large-scale state estimation problem. \n\n"}
{"id": "1710.09916", "contents": "Title: Low-Complexity Equalization for Orthogonal Time and Frequency Signaling\n  (OTFS) Abstract: Recently, a new precoding technique called orthogonal time-frequency\nsignaling (OTFS) has been proposed for time- and frequency-selective\ncommunication channels. OTFS precodes a data frame with a complete set of\nspreading sequences and transmits the results via orthogonal frequency division\nmultiplexing (OFDM). OTFS uses two dimensional (2D) linear spreading sequences\nin time and frequency which are the basis functions of a symplectic Fourier\ntransform. OTFS allows the utilization of time- and frequency-diversity but\nrequires maximum likelihood decoding to achieve full diversity. In this paper\nwe show performance results of a low-complexity equalizer using soft-symbol\nfeedback for interference cancellation after an initial minimum-mean square\nerror equalization step. Performance results for an implementation in the\ndelay-Doppler domain and in the time-frequency domain are compared. With our\nequalizer, OTFS achieves a gain of 5dB compared to OFDM for a bit error rate of\n$10^{-4}$ and a velocity of $200\\,\\text{km/h}$. \n\n"}
{"id": "1710.10255", "contents": "Title: Sequential Empirical Coordination Under an Output Entropy Constraint Abstract: This paper considers the problem of sequential empirical coordination, where\nthe objective is to achieve a given value of the expected uniform deviation\nbetween state-action empirical averages and statistical expectations under a\ngiven strategic probability measure, with respect to a given universal\nGlivenko-Cantelli class of test functions. A communication constraint is\nimposed on the Shannon entropy of the resulting action sequence. It is shown\nthat the fundamental limit on the output entropy is given by the minimum of the\nmutual information between the state and the action processes under all\nstrategic measures that have the same marginal state process as the target\nmeasure and approximate the target measure to desired accuracy with respect to\nthe underlying Glivenko--Cantelli seminorm. The fundamental limit is shown to\nbe asymptotically achievable by tree-structured codes. \n\n"}
{"id": "1710.10378", "contents": "Title: Distributed Change Detection via Average Consensus over Networks Abstract: Distributed change-point detection has been a fundamental problem when\nperforming real-time monitoring using sensor-networks. We propose a distributed\ndetection algorithm, where each sensor only exchanges CUSUM statistic with\ntheir neighbors based on the average consensus scheme, and an alarm is raised\nwhen local consensus statistic exceeds a pre-specified global threshold. We\nprovide theoretical performance bounds showing that the performance of the\nfully distributed scheme can match the centralized algorithms under some mild\nconditions. Numerical experiments demonstrate the good performance of the\nalgorithm especially in detecting asynchronous changes. \n\n"}
{"id": "1711.01110", "contents": "Title: A Rudimentary Model for Low-Latency Anonymous Communication Systems Abstract: In this paper we present a rudimentary model for low-latency anonymous\ncommunication systems. Specifically, we study distributed OR algorithm as an\nabstract of the system. Based on our model, we give several satisfactory lower\nbounds of anonymity leakage of a deterministic OR algorithm. Some of them\nreveal a trade-off between anonymity and communication complexity. For the\nrandomized OR algorithm, we only give a relatively trivial but possibly tight\nlower bound when leaving out communication complexity. And we find the\nrelationship between our model and some open case in the study of secret\nsharing scheme, if considering communication complexity. \n\n"}
{"id": "1711.02056", "contents": "Title: Throughput Maximization for Delay-Sensitive Random Access Communication Abstract: Future 5G cellular networks supporting ultra-reliable, low-latency\ncommunications (URLLC) could employ random access communication to reduce the\noverhead compared to scheduled access techniques used in 4G networks. We\nconsider a wireless communication system where multiple devices transmit\npayloads of a given fixed size in a random access fashion over shared radio\nresources to a common receiver. We allow retransmissions and assume Chase\ncombining at the receiver. The radio resources are partitioned in the time and\nfrequency dimensions, and we determine the optimal partition granularity to\nmaximize throughput, subject to given constraints on latency and outage. In the\nregime of high and low signal-to-noise ratio (SNR), we derive explicit\nexpressions for the granularity and throughput, first using a Shannon capacity\napproximation and then using finite block length analysis. Numerical results\nshow that the throughput scaling results are applicable over a range of SNRs.\nThe proposed analytical framework can provide insights for resource allocation\nstrategies in general random access systems and in specific 5G use cases for\nmassive URLLC uplink access. \n\n"}
{"id": "1711.03310", "contents": "Title: Weak Flip Codes and their Optimality on the Binary Erasure Channel Abstract: This paper investigates fundamental properties of nonlinear binary codes by\nlooking at the codebook matrix not row-wise (codewords), but column-wise. The\nfamily of weak flip codes is presented and shown to contain many beautiful\nproperties. In particular the subfamily fair weak flip codes, which goes back\nto Berlekamp, Gallager, and Shannon and which was shown to achieve the error\nexponent with a fixed number of codewords $M$, can be seen as a generalization\nof linear codes to an arbitrary number of codewords. Based on the column-wise\napproach, the $r$-wise Hamming distance is introduced as a generalization to\nthe widely used (pairwise) Hamming distance. It is shown that the minimum\n$r$-wise Hamming distance satisfies a generalized $r$-wise Plotkin bound. The\n$r$-wise Hamming distance structure of the nonlinear fair weak flip codes is\nanalyzed and shown to be superior to many codes. In particular, it is proven\nthat the fair weak flip codes achieve the $r$-wise Plotkin bound with equality\nfor all $r$. In the second part of the paper, these insights are applied to a\nbinary erasure channel (BEC) with an arbitrary erasure probability. An exact\nformula for the average error probability of an arbitrary code using maximum\nlikelihood decoding is derived and shown to be expressible using only the\n$r$-wise Hamming distance structure of the code. For a number of codewords\n$M\\leq4$ and an arbitrary blocklength $n$, the globally optimal codes (in the\nsense of minimizing the average error probability) are found. For $M=5,6$ and\nan arbitrary blocklength $n$, the optimal codes are conjectured. For larger\n$M$, observations regarding the optimal design are presented, e.g., that good\ncodes have a large $r$-wise Hamming distance structure for all $r$. Numerical\nresults validate our code design criteria and show the superiority of our best\nfound nonlinear weak flip codes compared to the best linear codes. \n\n"}
{"id": "1711.04819", "contents": "Title: Uncertainty quantification for radio interferometric imaging: II. MAP\n  estimation Abstract: Uncertainty quantification is a critical missing component in radio\ninterferometric imaging that will only become increasingly important as the\nbig-data era of radio interferometry emerges. Statistical sampling approaches\nto perform Bayesian inference, like Markov Chain Monte Carlo (MCMC) sampling,\ncan in principle recover the full posterior distribution of the image, from\nwhich uncertainties can then be quantified. However, for massive data sizes,\nlike those anticipated from the Square Kilometre Array (SKA), it will be\ndifficult if not impossible to apply any MCMC technique due to its inherent\ncomputational cost. We formulate Bayesian inference problems with\nsparsity-promoting priors (motivated by compressive sensing), for which we\nrecover maximum a posteriori (MAP) point estimators of radio interferometric\nimages by convex optimisation. Exploiting recent developments in the theory of\nprobability concentration, we quantify uncertainties by post-processing the\nrecovered MAP estimate. Three strategies to quantify uncertainties are\ndeveloped: (i) highest posterior density credible regions; (ii) local credible\nintervals (cf. error bars) for individual pixels and superpixels; and (iii)\nhypothesis testing of image structure. These forms of uncertainty\nquantification provide rich information for analysing radio interferometric\nobservations in a statistically robust manner. Our MAP-based methods are\napproximately $10^5$ times faster computationally than state-of-the-art MCMC\nmethods and, in addition, support highly distributed and parallelised\nalgorithmic structures. For the first time, our MAP-based techniques provide a\nmeans of quantifying uncertainties for radio interferometric imaging for\nrealistic data volumes and practical use, and scale to the emerging big-data\nera of radio astronomy. \n\n"}
{"id": "1711.07457", "contents": "Title: Unimodality-Constrained Matrix Factorization for Non-Parametric Source\n  Localization Abstract: Herein, the problem of simultaneous localization of multiple sources given a\nnumber of energy samples at different locations is examined. The strategies do\nnot require knowledge of the signal propagation models, nor do they exploit the\nspatial signatures of the source. A non-parametric source localization\nframework based on a matrix observation model is developed. It is shown that\nthe source location can be estimated by localizing the peaks of a pair of\nlocation signature vectors extracted from the incomplete energy observation\nmatrix. A robust peak localization algorithm is developed and shown to decrease\nthe source localization mean squared error (MSE) faster than O(1/M^1.5) with M\nsamples, when there is no measurement noise. To extract the source signature\nvectors from a matrix with mixed energy from multiple sources, a\nunimodality-constrained matrix factorization (UMF) problem is formulated, and\ntwo rotation techniques are developed to solve the UMF efficiently. Our\nnumerical experiments demonstrate that the proposed scheme achieves similar\nperformance as the kernel regression baseline using only 1/5 energy measurement\nsamples in detecting a single source, and the performance gain is more\nsignificant in the cases of detecting multiple sources. \n\n"}
{"id": "1711.07805", "contents": "Title: Approaching Miscorrection-free Performance of Product and Generalized\n  Product Codes Abstract: Product codes (PCs) protect a two-dimensional array of bits using short\ncomponent codes. Assuming transmission over the binary symmetric channel, the\ndecoding is commonly performed by iteratively applying bounded-distance\ndecoding to the component codes. For this coding scheme, undetected errors in\nthe component decoding-also known as miscorrections-significantly degrade the\nperformance. In this paper, we propose a novel iterative decoding algorithm for\nPCs which can detect and avoid most miscorrections. The algorithm can also be\nused to decode many recently proposed classes of generalized PCs such as\nstaircase, braided, and half-product codes. Depending on the component code\nparameters, our algorithm significantly outperforms the conventional iterative\ndecoding method. As an example, for double-error-correcting\nBose-Chaudhuri-Hocquenghem component codes, the net coding gain can be\nincreased by up to 0.4 dB. Moreover, the error floor can be lowered by orders\nof magnitude, up to the point where the decoder performs virtually identical to\na genie-aided decoder that avoids all miscorrections. We also discuss\npost-processing techniques that can be used to reduce the error floor even\nfurther. \n\n"}
{"id": "1711.09888", "contents": "Title: Distributed Convergence Verification for Gaussian Belief Propagation Abstract: Gaussian belief propagation (BP) is a computationally efficient method to\napproximate the marginal distribution and has been widely used for inference\nwith high dimensional data as well as distributed estimation in large-scale\nnetworks. However, the convergence of Gaussian BP is still an open issue.\nThough sufficient convergence conditions have been studied in the literature,\nverifying these conditions requires gathering all the information over the\nwhole network, which defeats the main advantage of distributed computing by\nusing Gaussian BP. In this paper, we propose a novel sufficient convergence\ncondition for Gaussian BP that applies to both the pairwise linear Gaussian\nmodel and to Gaussian Markov random fields. We show analytically that this\nsufficient convergence condition can be easily verified in a distributed way\nthat satisfies the network topology constraint. \n\n"}
{"id": "1711.10538", "contents": "Title: Power Control and Scheduling In Low SNR Region In The Uplink of Two Cell\n  Networks Abstract: In this paper we investigate the sub-channel assignment and power control to\nmaximize the total sum rate in the uplink of two-cell network. It is assumed\nthat there are some sub-channels in each cell which should be allocated among\nsome users. Also, each user is subjected to a power constraint. The underlying\nproblem is a non-convex mixed integer non-linear optimization problem which\ndoes not have a trivial solution. To solve the problem, having fixed the\nconsumed power of each user, and assuming low co-channel interference region,\nthe sub-channel allocation problem is reformulate into a more mathematically\ntractable problem which is shown can be tackled through the so-called Hungarian\nalgorithm. Then, the consumed power of each user is reformulated as a quadratic\nfractional problem which can be numerically derived. Numerical results\ndemonstrate the superiority of the proposed method in low SNR region as\ncompared to existing works addressed in the literature \n\n"}
{"id": "1712.00703", "contents": "Title: Diffusion Adaptation Framework for Compressive Sensing Reconstruction Abstract: Compressive sensing(CS) has drawn much attention in recent years due to its\nlow sampling rate as well as high recovery accuracy. As an important procedure,\nreconstructing a sparse signal from few measurement data has been intensively\nstudied. Many reconstruction algorithms have been proposed and shown good\nreconstruction performance. However, when dealing with large-scale sparse\nsignal reconstruction problem, the storage requirement will be high, and many\nalgorithms also suffer from high computational cost. In this paper, we propose\na novel diffusion adaptation framework for CS reconstruction, where the\nreconstruction is performed in a distributed network. The data of measurement\nmatrix are partitioned into small parts and are stored in each node, which\nassigns the storage load in a decentralized manner. The local information\ninteraction provides the reconstruction ability. Then, a simple and efficient\ngradient-descend based diffusion algorithm has been proposed to collaboratively\nrecover the sparse signal over network. The convergence of the proposed\nalgorithm is analyzed. To further increase the convergence speed, a mini-batch\nbased diffusion algorithm is also proposed. Simulation results show that the\nproposed algorithms can achieve good reconstruction accuracy as well as fast\nconvergence speed. \n\n"}
{"id": "1712.02235", "contents": "Title: Stochastic Geometry Analysis of Ultra-Dense Networks: Impact of Antenna\n  Height and Performance Limits Abstract: The concept of Ultra Dense Networks (UDN) is often seen as a key enabler of\nthe next generation mobile networks. However, existing analysis of UDNs,\nincluding Stochastic Geometry, has not been able to fully determine the\npotential gains and limits of densification. In this paper we study performance\nof UDNs in downlink and provide new insights on the impact of antenna height\nand careful site selection on the network performance. We focus our\ninvestigation on the probability of coverage, average cell rate and average\narea spectral efficiency for networks with regular and random BS deployments.\nWe show that under a path-loss model which considers antenna height there\nexists an upper limit on network performance which is dependent on the\npath-loss model parameters. Our analysis shows an interesting finding that even\nfor over-densified networks a non-negligible system performance can be\nachieved. \n\n"}
{"id": "1712.02466", "contents": "Title: On Sub-Packetization and Access Number of Capacity-Achieving PIR Schemes\n  for MDS Coded Non-Colluding Servers Abstract: Consider the problem of private information retrieval (PIR) over a\ndistributed storage system where $M$ records are stored across $N$ servers by\nusing an $[N,K]$ MDS code. For simplicity, this problem is usually referred as\nthe coded PIR problem. In 2016, Banawan and Ulukus designed the first\ncapacity-achieving coded PIR scheme with sub-packetization $KN^{M}$ and access\nnumber $MKN^{M}$, where capacity characterizes the minimal download size for\nretrieving per unit of data, and sub-packetization and access number are two\nmetrics closely related to implementation complexity. In this paper, we focus\non minimizing the sub-packetization and the access number for linear\ncapacity-achieving coded PIR schemes. We first determine the lower bounds on\nsub-packetization and access number, which are $Kn^{M-1}$ and $MKn^{M-1}$,\nrespectively, in the nontrivial cases (i.e. $N\\!>\\!K\\!\\geq\\!1$ and $M\\!>\\!1$),\nwhere $n\\!=\\!N/{\\rm gcd}(N,K)$. We then design a general linear\ncapacity-achieving coded PIR scheme to simultaneously attain these two bounds,\nimplying tightness of both bounds. \n\n"}
{"id": "1712.03310", "contents": "Title: Maximum entropy low-rank matrix recovery Abstract: We propose in this paper a novel, information-theoretic method, called\nMaxEnt, for efficient data acquisition for low-rank matrix recovery. This\nproposed method has important applications to a wide range of problems,\nincluding image processing and text document indexing. Fundamental to our\ndesign approach is the so-called maximum entropy principle, which states that\nthe measurement masks which maximize the entropy of observations, also maximize\nthe information gain on the unknown matrix $\\mathbf{X}$. Coupled with a\nlow-rank stochastic model for $\\mathbf{X}$, such a principle (i) reveals novel\nconnections between information-theoretic sampling and subspace packings, and\n(ii) yields efficient mask construction algorithms for matrix recovery, which\nsignificantly outperforms random measurements. We illustrate the effectiveness\nof MaxEnt in simulation experiments, and demonstrate its usefulness in two\nreal-world applications on image recovery and text document indexing. \n\n"}
{"id": "1712.03314", "contents": "Title: Efficient Data Collection Over Multiple Access Wireless Sensors Network Abstract: Data collection in Wireless Sensor Networks (WSN) draws significant\nattention, due to emerging interest in technologies raging from Internet of\nThings (IoT) networks to simple \"Presence\" applications, which identify the\nstatus of the devices (active or inactive). Numerous Medium Access Control\n(MAC) protocols for WSN, which can address the challenge of data collection in\ndense networks, were suggested over the years. Most of these protocols utilize\nthe traditional layering approach, in which the MAC layer is unaware of the\nencapsulated packet payload, and therefore there is no connection between the\ndata collected, the physical layer and the signaling mechanisms. Nonetheless,\nin many of the applications that intend to utilize such protocols, nodes may\nneed to exchange very little information, and do so only sporadically, that is,\nwhile the number of devices in the network can be very large, only a subset\nwishes to transmit at any given time. Thus, a tailored protocol, which matches\nthe signaling, physical layer and access control to traffic patterns is\nrequired.\n  In this work, we design and analyze a data collection protocol based on\ninformation theoretic principles. In the suggested protocol, the sink collects\nmessages from up to K sensors simultaneously, out of a large population of\nsensors, without knowing in advance which sensors will transmit, and without\nrequiring any synchronization, coordination or management overhead. In other\nwords, neither the sink nor the other sensors need to know who are the actively\ntransmitting sensors, and this data is decoded directly from the channel\noutput. We provide a simple codebook construction with very simple encoding and\ndecoding procedures. We further design a secure version of the protocol. \n\n"}
{"id": "1712.03433", "contents": "Title: Caching and Coded Delivery over Gaussian Broadcast Channels for Energy\n  Efficiency Abstract: A cache-aided $K$-user Gaussian broadcast channel (BC) is considered. The\ntransmitter has a library of $N$ equal-rate files, from which each user demands\none. The impact of the equal-capacity receiver cache memories on the minimum\nrequired transmit power to satisfy all user demands is studied. Considering\nuniformly random demands across the library, both the minimum average power\n(averaged over all demand combinations) and the minimum peak power (minimum\npower required to satisfy all demand combinations) are studied. Upper bounds\nare presented on the minimum required average and peak transmit power as a\nfunction of the cache capacity considering both centralized and decentralized\ncaching. The lower bounds on the minimum required average and peak power values\nare also derived assuming uncoded cache placement. The bounds for both the peak\nand average power values are shown to be tight in the centralized scenario\nthrough numerical simulations. The results in this paper show that proactive\ncaching and coded delivery can provide significant energy savings in wireless\nnetworks. \n\n"}
{"id": "1712.04462", "contents": "Title: Online radio interferometric imaging: assimilating and discarding\n  visibilities on arrival Abstract: The emerging generation of radio interferometric (RI) telescopes, such as the\nSquare Kilometre Array (SKA), will acquire massive volumes of data and\ntransition radio astronomy to a big-data era. The ill-posed inverse problem of\nimaging the raw visibilities acquired by RI telescopes will become\nsignificantly more computationally challenging, particularly in terms of data\nstorage and computational cost. Current RI imaging methods, such as CLEAN, its\nvariants, and compressive sensing approaches (sparse regularisation), have\nyielded excellent reconstruction fidelity. However, scaling these methods to\nbig-data remains difficult if not impossible in some cases. All\nstate-of-the-art methods in RI imaging lack the ability to process data streams\nas they are acquired during the data observation stage. Such approaches are\nreferred to as online processing methods. We present an online sparse\nregularisation methodology for RI imaging. Image reconstruction is performed\nsimultaneously with data acquisition, where observed visibilities are\nassimilated into the reconstructed image as they arrive and then discarded.\nSince visibilities are processed online, good reconstructions are recovered\nmuch faster than standard (offline) methods which cannot start until the data\nacquisition stage completes. Moreover, the online method provides additional\ncomputational savings and, most importantly, dramatically reduces data storage\nrequirements. Theoretically, the reconstructed images are of the same fidelity\nas those recovered by the equivalent offline approach and, in practice, very\nsimilar reconstruction fidelity is achieved. We anticipate online imaging\ntechniques, as proposed here, will be critical in scaling RI imaging to the\nemerging big-data era of radio astronomy. \n\n"}
{"id": "1712.06745", "contents": "Title: Efficient Algorithms for Searching the Minimum Information Partition in\n  Integrated Information Theory Abstract: The ability to integrate information in the brain is considered to be an\nessential property for cognition and consciousness. Integrated Information\nTheory (IIT) hypothesizes that the amount of integrated information ($\\Phi$) in\nthe brain is related to the level of consciousness. IIT proposes that to\nquantify information integration in a system as a whole, integrated information\nshould be measured across the partition of the system at which information loss\ncaused by partitioning is minimized, called the Minimum Information Partition\n(MIP). The computational cost for exhaustively searching for the MIP grows\nexponentially with system size, making it difficult to apply IIT to real neural\ndata. It has been previously shown that if a measure of $\\Phi$ satisfies a\nmathematical property, submodularity, the MIP can be found in a polynomial\norder by an optimization algorithm. However, although the first version of\n$\\Phi$ is submodular, the later versions are not. In this study, we empirically\nexplore to what extent the algorithm can be applied to the non-submodular\nmeasures of $\\Phi$ by evaluating the accuracy of the algorithm in simulated\ndata and real neural data. We find that the algorithm identifies the MIP in a\nnearly perfect manner even for the non-submodular measures. Our results show\nthat the algorithm allows us to measure $\\Phi$ in large systems within a\npractical amount of time. \n\n"}
{"id": "1712.06866", "contents": "Title: The Error Probability of Sparse Superposition Codes with Approximate\n  Message Passing Decoding Abstract: Sparse superposition codes, or sparse regression codes (SPARCs), are a recent\nclass of codes for reliable communication over the AWGN channel at rates\napproaching the channel capacity. Approximate message passing (AMP) decoding, a\ncomputationally efficient technique for decoding SPARCs, has been proven to be\nasymptotically capacity-achieving for the AWGN channel. In this paper, we\nrefine the asymptotic result by deriving a large deviations bound on the\nprobability of AMP decoding error. This bound gives insight into the error\nperformance of the AMP decoder for large but finite problem sizes, giving an\nerror exponent as well as guidance on how the code parameters should be chosen\nat finite block lengths. For an appropriate choice of code parameters, we show\nthat for any fixed rate less than the channel capacity, the decoding error\nprobability decays exponentially in $n/(\\log n)^{2T}$, where $T$, the number of\nAMP iterations required for successful decoding, is bounded in terms of the gap\nfrom capacity. \n\n"}
{"id": "1712.07062", "contents": "Title: Covert Wireless Communication with a Poisson Field of Interferers Abstract: In this paper, we study covert communication in wireless networks consisting\nof a transmitter, Alice, an intended receiver, Bob, a warden, Willie, and a\nPoisson field of interferers. Bob and Willie are subject to uncertain shot\nnoise due to the ambient signals from interferers in the network. With the aid\nof stochastic geometry, we analyze the throughput of the covert communication\nbetween Alice and Bob subject to given requirements on the covertness against\nWillie and the reliability of decoding at Bob. We consider non-fading and\nfading channels. We analytically obtain interesting findings on the impacts of\nthe density and the transmit power of the concurrent interferers on the covert\nthroughput. That is, the density and the transmit power of the interferers have\nno impact on the covert throughput as long as the network stays in the\ninterference-limited regime, for both the non-fading and the fading cases. When\nthe interference is sufficiently small and comparable with the receiver noise,\nthe covert throughput increases as the density or the transmit power of the\nconcurrent interferers increases. \n\n"}
{"id": "1712.07863", "contents": "Title: On the Information Dimension of Multivariate Gaussian Processes Abstract: The authors have recently defined the R\\'enyi information dimension rate\n$d(\\{X_t\\})$ of a stationary stochastic process $\\{X_t,\\,t\\in\\mathbb{Z}\\}$ as\nthe entropy rate of the uniformly-quantized process divided by minus the\nlogarithm of the quantizer step size $1/m$ in the limit as $m\\to\\infty$ (B.\nGeiger and T. Koch, \"On the information dimension rate of stochastic\nprocesses,\" in Proc. IEEE Int. Symp. Inf. Theory (ISIT), Aachen, Germany, June\n2017). For Gaussian processes with a given spectral distribution function\n$F_X$, they showed that the information dimension rate equals the Lebesgue\nmeasure of the set of harmonics where the derivative of $F_X$ is positive. This\npaper extends this result to multivariate Gaussian processes with a given\nmatrix-valued spectral distribution function $F_{\\mathbf{X}}$. It is\ndemonstrated that the information dimension rate equals the average rank of the\nderivative of $F_{\\mathbf{X}}$. As a side result, it is shown that the scale\nand translation invariance of information dimension carries over from random\nvariables to stochastic processes. \n\n"}
{"id": "1801.00222", "contents": "Title: Limitation of SDMA in Ultra-Dense Small Cell Networks Abstract: Benefitting from multi-user gain brought by multi-antenna techniques, space\ndivision multiple access (SDMA) is capable of significantly enhancing spatial\nthroughput (ST) in wireless networks. Nevertheless, we show in this letter\nthat, even when SDMA is applied, ST would diminish to be zero in ultra-dense\nnetworks (UDN), where small cell base stations (BSs) are fully densified. More\nimportantly, we compare the performance of SDMA, single-user beamforming\n(SU-BF) (one user is served in each cell) and full SDMA (the number of served\nusers equals the number of equipped antennas). Surprisingly, it is shown that\nSU-BF achieves the highest ST and critical density, beyond which ST starts to\ndegrade, in UDN. The results in this work could shed light on the fundamental\nlimitation of SDMA in UDN. \n\n"}
{"id": "1801.00406", "contents": "Title: Reduced Dimensional Optimal Vector Linear Index Codes for Index Coding\n  Problems with Symmetric Neighboring and Consecutive Side-information Abstract: A single unicast index coding problem (SUICP) with symmetric neighboring and\nconsecutive side-information (SNCS) has $K$ messages and $K$ receivers, the\n$k$th receiver $R_k$ wanting the $k$th message $x_k$ and having the\nside-information $\\mathcal{K}_k=\\{x_{k-U},\\dots,x_{k-2},x_{k-1}\\}\\cup\\{x_{k+1},\nx_{k+2},\\dots,x_{k+D}\\}$. The single unicast index coding problem with\nsymmetric neighboring and consecutive side-information, SUICP(SNCS), is\nmotivated by topological interference management problems in wireless\ncommunication networks. Maleki, Cadambe and Jafar obtained the symmetric\ncapacity of this SUICP(SNCS) and proposed optimal length codes by using\nVandermonde matrices. In our earlier work, we gave optimal length\n$(U+1)$-dimensional vector linear index codes for SUICP(SNCS) satisfying some\nconditions on $K,D$ and $U$ \\cite{VaR1}. In this paper, for SUICP(SNCS) with\narbitrary $K,D$ and $U$, we construct optimal length\n$\\frac{U+1}{\\text{gcd}(K,D-U,U+1)}$-dimensional vector linear index codes. We\nprove that the constructed vector linear index code is of minimal dimension if\n$\\text{gcd}(K-D+U,U+1)$ is equal to $\\text{gcd}(K,D-U,U+1)$. The proposed\nconstruction gives optimal length scalar linear index codes for the SUICP(SNCS)\nif $(U+1)$ divides both $K$ and $D-U$. The proposed construction is independent\nof field size and works over every field. We give a low-complexity decoding for\nthe SUICP(SNCS). By using the proposed decoding method, every receiver is able\nto decode its wanted message symbol by simply adding some index code symbols\n(broadcast symbols). \n\n"}
{"id": "1801.02020", "contents": "Title: Decentralized Base-Graph Routing for the Quantum Internet Abstract: Quantum repeater networks are a fundamental of any future quantum Internet\nand long-distance quantum communications. The entangled quantum nodes can\ncommunicate through several different levels of entanglement, leading to a\nheterogeneous, multi-level network structure. The level of entanglement between\nthe quantum nodes determines the hop distance and the probability of the\nexistence of an entangled link in the network. Here, we define a decentralized\nrouting for entangled quantum networks. The proposed method allows an efficient\nrouting to find the shortest paths in entangled quantum networks by using only\nlocal knowledge of the quantum nodes. We give bounds on the maximum value of\nthe total number of entangled links of a path. The proposed scheme can be\ndirectly applied in practical quantum communications and quantum networking\nscenarios. \n\n"}
{"id": "1801.02987", "contents": "Title: Multiplexing Analysis of Millimeter-Wave Massive MIMO Systems Abstract: This paper is concerned with spatial multiplexing analysis for\nmillimeter-wave (mmWave) massive MIMO systems. For a single-user mmWave system\nemploying distributed antenna subarray architecture in which the transmitter\nand receiver consist of Kt and Kr subarrays, respectively, an asymptotic\nmultiplexing gain formula is firstly derived when the numbers of antennas at\nsubarrays go to infinity. Specifically, assuming that all subchannels have the\nsame average number of propagation paths L, the formula implies that by\nemploying such a distributed antenna-subarray architecture, an exact average\nmaximum multiplexing gain of KrKtL can be achieved. This result means that\ncompared to the co-located antenna architecture, using the distributed\nantenna-subarray architecture can scale up the maximum multiplexing gain\nproportionally to KrKt. In order to further reveal the relation between\ndiversity gain and multiplexing gain, a simple characterization of the\ndiversity-multiplexing tradeoff is also given. The multiplexing gain analysis\nis then extended to the multiuser scenario. Moreover, simulation results\nobtained with the hybrid analog/digital processing corroborate the analysis\nresults. \n\n"}
{"id": "1801.03655", "contents": "Title: Can Negligible Cooperation Increase Network Capacity? The Average-Error\n  Case Abstract: In communication networks, cooperative strategies are coding schemes where\nnetwork nodes work together to improve network performance metrics such as\nsum-rate. This work studies encoder cooperation in the setting of a discrete\nmultiple access channel with two encoders and a single decoder. A node in the\nnetwork that is connected to both encoders via rate-limited links, referred to\nas the cooperation facilitator (CF), enables the cooperation strategy.\nPreviously, the authors presented a class of multiple access channels where the\naverage-error sum-capacity has an infinite derivative in the limit where CF\noutput link capacities approach zero. The authors also demonstrated that for\nsome channels, the maximal-error sum-capacity is not continuous at the point\nwhere the output link capacities of the CF equal zero. This work shows that the\nthe average-error sum-capacity is continuous when CF output link capacities\nconverge to zero; that is, the infinite derivative of the average-error\nsum-capacity is not a result of its discontinuity as in the maximal-error case. \n\n"}
{"id": "1801.04803", "contents": "Title: New LMRD bounds for constant dimension codes and improved constructions Abstract: We generalize upper bounds for constant dimension codes containing a lifted\nmaximum rank distance code first studied by Etzion and Silberstein. The proof\nallows to construct several improved codes. \n\n"}
{"id": "1801.04920", "contents": "Title: Secrecy Amplification for Distributed Encrypted Sources with Correlated\n  Keys using Affine Encoders Abstract: This paper proposed the application of post-encryption-compression (PEC) to\nstrengthen the secrecy in the case of distributed encryption where the\nencryption keys are correlated to each other. We derive the universal code\nconstruction for the compression and the rate region where codes with\nachievability and secrecy are obtainable. Our main technique is to use affine\nencoders which are constructed from certain linear encoders to encode the\nciphertexts before sending them to public communication channels. We show that\nif the rates of linear codes are within a certain rate region:(1) information\nleakage on the original sources from the encoded ciphertexts without the keys\nis negligible, while (2) one who has legitimate keys is able to retrieve the\noriginal source data with negligible error probability. \n\n"}
{"id": "1801.05089", "contents": "Title: Reed-Muller Sequences for 5G Grant-free Massive Access Abstract: We propose to use second order Reed-Muller (RM) sequence for user\nidentification in 5G grant-free access. The benefits of RM sequences mainly lie\nin two folds, (i) support of much larger user space, hence lower collision\nprobability and (ii) lower detection complexity. These two features are\nessential to meet the massive connectivity ($10^7$ links/km$^2$),\nultra-reliable and low-latency requirements in 5G, e.g., one-shot transmission\n($\\leq 1$ms) with $\\leq 10^{-4}$ packet error rate. However, the\nnon-orthogonality introduced during sequence space expansion leads to worse\ndetection performance. In this paper, we propose a noise-resilient detection\nalgorithm along with a layered sequence construction to meet the harsh\nrequirements. Link-level simulations in both narrow-band and OFDM-based\nscenarios show that RM sequences are suitable for 5G. \n\n"}
{"id": "1801.05112", "contents": "Title: Exact Error and Erasure Exponents for the Asymmetric Broadcast Channel Abstract: Consider the asymmetric broadcast channel with a random superposition\ncodebook, which may be comprised of constant composition or \\iid codewords. By\napplying Forney's optimal decoder for individual messages and the message pair\nfor the receiver that decodes both messages, exact (ensemble-tight) error and\nerasure exponents are derived. It is shown that the optimal decoder designed to\ndecode the pair of messages achieves the optimal trade-off between the total\nand undetected exponents associated with the optimal decoder for the private\nmessage. Convex optimization-based procedures to evaluate the exponents\nefficiently are proposed. Finally, numerical examples are presented to\nillustrate the results. \n\n"}
{"id": "1801.05522", "contents": "Title: Coded Computing for Distributed Graph Analytics Abstract: Performance of distributed graph processing systems significantly suffers\nfrom 'communication bottleneck' as a large number of messages are exchanged\namong servers at each step of the computation. Motivated by graph based\nMapReduce, we propose a coded computing framework that leverages computation\nredundancy to alleviate the communication bottleneck in distributed graph\nprocessing. We develop a novel 'coding' scheme that systematically injects\nstructured redundancy in computation phase to enable 'coded' multicasting\nopportunities during message exchange between servers, reducing communication\nload substantially in large-scale graph processing. For theoretical analysis,\nwe consider random graph models, and prove that our proposed scheme enables an\n(asymptotically) inverse-linear trade-off between 'computation load' and\n'average communication load' for two popular random graph models -- Erdos-Renyi\nmodel, and power law model. Particularly, for a given computation load r, (i.e.\nwhen each graph vertex is carefully stored at r servers), the proposed scheme\nslashes the average communication load by (nearly) a multiplicative factor of\nr. For the Erdos-Renyi model, our proposed scheme is optimal asymptotically as\nthe graph size increases by providing an information-theoretic converse. To\nillustrate the benefits of our scheme in practice, we implement PageRank over\nAmazon EC2, using artificial as well as real-world datasets, demonstrating\nsignificant gains over conventional PageRank. We also specialize our scheme and\nextend our theoretical results to two other random graph models -- random\nbi-partite model, and stochastic block model. They asymptotically enable\ninverse-linear trade-offs between computation and communication loads in\ndistributed graph processing for these popular random graph models as well. We\ncomplement the achievability results with converse bounds for both of these\nmodels. \n\n"}
{"id": "1801.06609", "contents": "Title: A Precise Analysis of PhaseMax in Phase Retrieval Abstract: Recovering an unknown complex signal from the magnitude of linear\ncombinations of the signal is referred to as phase retrieval. We present an\nexact performance analysis of a recently proposed\nconvex-optimization-formulation for this problem, known as PhaseMax. Standard\nconvex-relaxation-based methods in phase retrieval resort to the idea of\n\"lifting\" which makes them computationally inefficient, since the number of\nunknowns is effectively squared. In contrast, PhaseMax is a novel convex\nrelaxation that does not increase the number of unknowns. Instead it relies on\nan initial estimate of the true signal which must be externally provided. In\nthis paper, we investigate the required number of measurements for exact\nrecovery of the signal in the large system limit and when the linear\nmeasurement matrix is random with iid standard normal entries. If $n$ denotes\nthe dimension of the unknown complex signal and $m$ the number of phaseless\nmeasurements, then in the large system limit, $\\frac{m}{n} >\n\\frac{4}{\\cos^2(\\theta)}$ measurements is necessary and sufficient to recover\nthe signal with high probability, where $\\theta$ is the angle between the\ninitial estimate and the true signal. Our result indicates a sharp phase\ntransition in the asymptotic regime which matches the empirical result in\nnumerical simulations. \n\n"}
{"id": "1801.06623", "contents": "Title: Promises and Caveats of Uplink IoT Ultra-Dense Networks Abstract: In this paper, by means of simulations, we evaluate the uplink (UL)\nperformance of an Internet of Things (IoT) capable ultra-dense network (UDN) in\nterms of the coverage probability and the density of reliably working user\nequipments (UEs). From our study, we show the benefits and challenges that UL\nIoT UDNs will bring about in the future. In more detail, for a low-reliability\ncriterion, such as achieving a UL signal-to-interference-plus-noise ratio\n(SINR) above 0 dB, the density of reliably working UEs grows quickly with the\nnetwork densification, showing the potential of UL IoT UDNs. In contrast, for a\nhigh-reliability criterion, such as achieving a UL SINR above 10 dB, the\ndensity of reliably working UEs remains to be low in UDNs due to excessive\ninter-cell interference, which should be considered when operating UL IoT UDNs.\nMoreover, considering the existence of a non-zero antenna height difference\nbetween base stations (BSs) and UEs, the density of reliably working UEs could\neven decrease as we deploy more BSs. This calls for the usage of sophisticated\ninterference management schemes and/or beam steering/shaping technologies in UL\nIoT UDNs. \n\n"}
{"id": "1801.06718", "contents": "Title: Analog-to-Digital Compression: A New Paradigm for Converting Signals to\n  Bits Abstract: Processing, storing and communicating information that originates as an\nanalog signal involves conversion of this information to bits. This conversion\ncan be described by the combined effect of sampling and quantization, as\nillustrated in Fig. 1. The digital representation is achieved by first sampling\nthe analog signal so as to represent it by a set of discrete-time samples and\nthen quantizing these samples to a finite number of bits. Traditionally, these\ntwo operations are considered separately. The sampler is designed to minimize\ninformation loss due to sampling based on characteristics of the\ncontinuous-time input. The quantizer is designed to represent the samples as\naccurately as possible, subject to a constraint on the number of bits that can\nbe used in the representation. The goal of this article is to revisit this\nparadigm by illuminating the dependency between these two operations. In\nparticular, we explore the requirements on the sampling system subject to\nconstraints on the available number of bits for storing, communicating or\nprocessing the analog information. \n\n"}
{"id": "1801.07188", "contents": "Title: Resource Allocation for Solar Powered UAV Communication Systems Abstract: In this paper, we investigate the resource allocation design for multicarrier\n(MC) systems employing a solar powered unmanned aerial vehicle (UAV) for\nproviding communication services to multiple downlink users. We study the joint\ndesign of the three-dimensional positioning of the UAV and the power and\nsubcarrier allocation for maximization of the system sum throughput. The\nalgorithm design is formulated as a mixed-integer non-convex optimization\nproblem, which requires a prohibitive computational complexity for obtaining\nthe globally optimal solution. Therefore, a low-complexity suboptimal iterative\nsolution based on successive convex approximation is proposed. Simulation\nresults confirm that the proposed suboptimal algorithm achieves a substantially\nhigher system sum throughput compared to several baseline schemes. \n\n"}
{"id": "1801.08206", "contents": "Title: Sparse Representation for Wireless Communications: A Compressive Sensing\n  Approach Abstract: Sparse representation can efficiently model signals in different applications\nto facilitate processing. In this article, we will discuss various applications\nof sparse representation in wireless communications, with focus on the most\nrecent compressive sensing (CS) enabled approaches. With the help of the\nsparsity property, CS is able to enhance the spectrum efficiency and energy\nefficiency for the fifth generation (5G) networks and Internet of Things (IoT)\nnetworks. This article starts from a comprehensive overview of CS principles\nand different sparse domains potentially used in 5G and IoT networks. Then\nrecent research progress on applying CS to address the major opportunities and\nchallenges in 5G and IoT networks is introduced, including wideband spectrum\nsensing in cognitive radio networks, data collection in IoT networks, and\nchannel estimation and feedback in massive MIMO systems. Moreover, other\npotential applications and research challenges on sparse representation for 5G\nand IoT networks are identified. This article will provide readers a clear\npicture of how to exploit the sparsity properties to process wireless signals\nin different applications. \n\n"}
{"id": "1801.08704", "contents": "Title: Event-triggered stabilization of disturbed linear systems over digital\n  channels Abstract: We present an event-triggered control strategy for stabilizing a scalar,\ncontinuous-time, time-invariant, linear system over a digital communication\nchannel having bounded delay, and in the presence of bounded system\ndisturbance. We propose an encoding-decoding scheme, and determine lower bounds\non the packet size and on the information transmission rate which are\nsufficient for stabilization. We show that for small values of the delay, the\ntiming information implicit in the triggering events is enough to stabilize the\nsystem with any positive rate. In contrast, when the delay increases beyond a\ncritical threshold, the timing information alone is not enough to stabilize the\nsystem and the transmission rate begins to increase. Finally, large values of\nthe delay require transmission rates higher than what prescribed by the classic\ndata-rate theorem. The results are numerically validated using a linearized\nmodel of an inverted pendulum. \n\n"}
{"id": "1801.09109", "contents": "Title: Spectral and Energy Efficient Wireless Powered IoT Networks: NOMA or\n  TDMA? Abstract: Wireless powered communication networks (WPCNs), where multiple\nenergy-limited devices first harvest energy in the downlink and then transmit\ninformation in the uplink, have been envisioned as a promising solution for the\nfuture Internet-of-Things (IoT). Meanwhile, non-orthogonal multiple access\n(NOMA) has been proposed to improve the system spectral efficiency (SE) of the\nfifth-generation (5G) networks by allowing concurrent transmissions of multiple\nusers in the same spectrum. As such, NOMA has been recently considered for the\nuplink of WPCNs based IoT networks with a massive number of devices. However,\nsimultaneous transmissions in NOMA may also incur more transmit energy\nconsumption as well as circuit energy consumption in practice which is critical\nfor energy constrained IoT devices. As a result, compared to orthogonal\nmultiple access schemes such as time-division multiple access (TDMA), whether\nthe SE can be improved and/or the total energy consumption can be reduced with\nNOMA in such a scenario still remains unknown. To answer this question, we\nfirst derive the optimal time allocations for maximizing the SE of a TDMA-based\nWPCN (T-WPCN) and a NOMA-based WPCN (N-WPCN), respectively. Subsequently, we\nanalyze the total energy consumption as well as the maximum SE achieved by\nthese two networks. Surprisingly, it is found that N-WPCN not only consumes\nmore energy, but also is less spectral efficient than T-WPCN. Simulation\nresults verify our theoretical findings and unveil the fundamental performance\nbottleneck, i.e., \"worst user bottleneck problem\", in multiuser NOMA systems. \n\n"}
{"id": "1801.10282", "contents": "Title: Stochastic Optimization and Control Framework for 5G Network Slicing\n  with Effective Isolation Abstract: Network slicing is an emerging technique for providing resources to diverse\nwireless services with heterogeneous quality-of-service needs. However, beyond\nsatisfying end-to-end requirements of network users, network slicing needs to\nalso provide isolation between slices so as to prevent one slice's faults and\ncongestion from affecting other slices. In this paper, the problem of network\nslicing is studied in the context of a wireless system having a time-varying\nnumber of users that require two types of slices: reliable low latency (RLL)\nand self-managed (capacity limited) slices. To address this problem, a novel\ncontrol framework for stochastic optimization is proposed based on the Lyapunov\ndrift-plus-penalty method. This new framework enables the system to minimize\npower, maintain slice isolation, and provide reliable and low latency\nend-to-end communication for RLL slices. Simulation results show that the\nproposed approach can maintain the system's reliability while providing\neffective slice isolation in the event of sudden changes in the network\nenvironment. \n\n"}
{"id": "1802.01049", "contents": "Title: Blind Joint MIMO Channel Estimation and Decoding Abstract: We propose a method for MIMO decoding when channel state information (CSI) is\nunknown to both the transmitter and receiver. The proposed method requires some\nstructure in the transmitted signal for the decoding to be effective, in\nparticular that the underlying sources are drawn from a hypercubic space. Our\nproposed technique fits a minimum volume parallelepiped to the received\nsamples. This problem can be expressed as a non-convex optimization problem\nthat can be solved with high probability by gradient descent. Our blind\ndecoding algorithm can be used when communicating over unknown MIMO wireless\nchannels using either BPSK or MPAM modulation. We apply our technique to\njointly estimate MIMO channel gain matrices and decode the underlying\ntransmissions with only knowledge of the transmitted constellation and without\nthe use of pilot symbols. Our results provide theoretical guarantees that the\nproposed algorithm is correct when applied to small MIMO systems. Empirical\nresults show small sample size requirements, making this algorithm suitable for\nblock-fading channels with coherence times typically seen in practice. Our\napproach has a loss of less than 3dB compared to zero-forcing with perfect CSI,\nimposing a similar performance penalty as space-time coding techniques without\nthe loss of rate incurred by those techniques. \n\n"}
{"id": "1802.03837", "contents": "Title: Integrated Millimeter Wave and Sub-6 GHz Wireless Networks: A Roadmap\n  for Joint Mobile Broadband and Ultra-Reliable Low-Latency Communications Abstract: Next-generation wireless networks must enable emerging technologies such as\naugmented reality and connected autonomous vehicles via wide range of wireless\nservices that span enhanced mobile broadband (eMBB), as well as ultra-reliable\nlow-latency communication (URLLC). Existing wireless systems that solely rely\non the scarce sub-6 GHz, microwave ($\\mu$W) frequency bands will be unable to\nmeet such stringent and mixed service requirements for future wireless services\ndue to spectrum scarcity. Meanwhile, operating at high-frequency millimeter\nwave (mmWave) bands is seen as an attractive solution, primarily due to the\nbandwidth availability and possibility of large-scale multi-antenna\ncommunication. However, mmWave communication is inherently unreliable due to\nits susceptibility to blockage, high path loss, and channel uncertainty. Hence,\nto provide URLLC and high-speed wireless access, it is desirable to seamlessly\nintegrate the reliability of $\\mu$W networks with the high capacity of mmWave\nnetworks. To this end, in this paper, the first comprehensive tutorial for\n\\emph{integrated mmWave-$\\mu$W} communications is introduced. This envisioned\nintegrated design will enable wireless networks to achieve URLLC along with\neMBB by leveraging the best of two worlds: reliable, long-range communications\nat the $\\mu$W bands and directional high-speed communications at the mmWave\nfrequencies. To achieve this goal, key solution concepts are discussed that\ninclude new architectures for the radio interface, URLLC-aware frame structure\nand resource allocation methods along with mobility management, to realize the\npotential of integrated mmWave-$\\mu$W communications. The opportunities and\nchallenges of each proposed scheme are discussed and key results are presented\nto show the merits of the developed integrated mmWave-$\\mu$W framework. \n\n"}
{"id": "1802.04769", "contents": "Title: Edge Caching in Delay-Constrained Virtualized Cellular Networks:\n  Analysis and Market Abstract: Caching of popular contents at cellular base stations, i.e., edge caching, in\norder to eliminate duplicate transmission through the backhaul can reduce the\nlatency of data delivery in $5$G networks. However, since caching can only\nreduce the backhaul delay, techniques such as base station densification will\nalso need to be used to reduce the fronthaul delay. In this paper, using\nresults from stochastic geometry, we first model the effects of base station\ndensification and cache size on the latency of the system. We then derive a\ntight approximation for the cache hit probability. To optimize the network cost\ndue to the deployment of base station (BS) and cache storage, a minimization\nproblem for the product of the BS intensity and cache size is formulated under\nprobabilistic delay constraint, which is converted into a geometric program and\nsolved analytically. The results are then used to analyze the economics of a\ncache-enabled virtualized cellular network where the network infrastructure,\ni.e., BSs and cache storage, owned by an infrastructure provider (InP) is\nshared among multiple mobile network operators (MNOs). For the pricing between\nthe InP and the MNOs, we formulate a Stackelberg game with the InP as the\nleader and multiple MNOs as the followers. In this virtualized scenario, the\ncommon cost of renting the infrastructure is shared in a fair manner among the\nMNOs by using the Shapely value. An efficient algorithm is provided to divide\nthe rent among MNOs. \n\n"}
{"id": "1802.04923", "contents": "Title: Beamforming with Multiple One-Bit Wireless Transceivers Abstract: Classical beamforming techniques rely on highly linear transmitters and\nreceivers to allow phase-coherent combining at the transmitter and receiver.\nThe transmitter uses beamforming to steer signal power towards the receiver,\nand the receiver uses beamforming to gather and coherently combine the signals\nfrom multiple receiver antennas. When the transmitters and receivers are\ninstead constrained for power and cost reasons to be non-linear one-bit\ndevices, the potential advantages and performance metrics associated with\nbeamforming are not as well understood. We define beamforming at the\ntransmitter as a codebook design problem to maximize the minimum distance\nbetween codewords. We define beamforming at the receiver as the maximum\nlikelihood detector of the transmitted codeword. We show that beamforming with\none-bit transceivers is a constellation design problem, and that we can come\nwithin a few dB SNR of the capacity attained by linear transceivers. \n\n"}
{"id": "1802.05209", "contents": "Title: Sum Secrecy Rate Maximization in a Multi-Carrier MIMO Wiretap Channel\n  with Full-Duplex Jamming Abstract: In this paper we address a sum secrecy rate maximization problem for a\nmulti-carrier and MIMO communication system. We consider the case that the\nreceiver is capable of full-duplex (FD) operation and simultaneously sends\njamming signal to a potential eavesdropper. In particular, we simultaneously\ntake advantage of the spatial and frequency diversity in the system in order to\nobtain a higher level of security in the physical layer. Due to the non-convex\nnature of the resulting mathematical problem, we propose an iterative solution\nwith a guaranteed convergence, based on block coordinate descent method, by\nre-structuring our problem as a separately convex program. Moreover, for the\nspecial case that the transmitter is equipped with a single antenna, an optimal\ntransmit power allocation strategy is obtained analytically, assuming a known\njamming strategy. We also study a FD bidirectional secure communication system,\nwhere the jamming power can be reused to enhance the sum secrecy rate. The\nperformance of the proposed design is then numerically evaluated compared to\nthe other design strategies, and under different system assumptions. \n\n"}
{"id": "1802.06670", "contents": "Title: Frequency-Selective Hybrid Beamforming Based on Implicit CSI for\n  Millimeter Wave Systems Abstract: Hybrid beamforming is a promising concept to achieve high data rate\ntransmission at millimeter waves. To implement it in a transceiver, many\nreferences optimally adapt to a high-dimensional multi-antenna channel but more\nor less ignore the complexity of the channel estimation. Realizing that\nreceived coupling coefficients of the channel and pairs of possible analog\nbeamforming vectors can be used for analog beam selection, we further propose a\nlow-complexity scheme that exploits the coupling coefficients to implement\nhybrid beamforming. Essentially, the coupling coefficients can be regarded as\nimplicit channel state information (CSI), and the estimates of these coupling\ncoefficients yield alternatives of effective channel matrices of much lower\ndimension. After calculating the Frobenius norm of these effective channel\nmatrices, it turns out that the effective channel having the largest value of\nthe Frobenius norm provides the solution to hybrid beamforming problem. \n\n"}
{"id": "1802.06910", "contents": "Title: Single or Multiple Frames Content Delivery for Next-Generation Networks? Abstract: This paper addresses the four enabling technologies, namely multi-user sparse\ncode multiple access (SCMA), content caching, energy harvesting, and physical\nlayer security for proposing an energy and spectral efficient resource\nallocation algorithm for the access and backhaul links in heterogeneous\ncellular networks. Although each of the above mentioned issues could be a topic\nof research, in a real situation, we would face a complicated scenario where\nthey should be considered jointly, and hence, our target is to consider these\ntechnologies jointly in a unified framework. Moreover, we propose two novel\ncontent delivery scenarios: 1) single frame content delivery (SFCD), and 2)\nmultiple frames content delivery (MFCD), where the time duration of serving\nuser requests is divided into several frames. In the first scenario, the\nrequested content by each user is served over one frame. However, in the second\nscenario, the requested content by each user can be delivered over several\nframes. We formulate the resource allocation for the proposed scenarios as\noptimization problems where our main aim is to maximize the energy efficiency\nof access links subject to the transmit power and rate constraints of access\nand backhaul links, caching and energy harvesting constraints, and SCMA\ncodebook allocation limitations. Due to the practical limitations, we assume\nthat the channel state information values between eavesdroppers and base\nstations are uncertain and design the network for the worst case scenario.\nSince the corresponding optimization problems are mixed integer non-linear and\nnonconvex programming, NP-hard, and intractable, we propose an iterative\nalgorithm based on the well-known alternate and successive convex approximation\nmethods. \n\n"}
{"id": "1802.07458", "contents": "Title: Non-Asymptotic Bounds and a General Formula for the Rate-Distortion\n  Region of the Successive Refinement Problem Abstract: In the successive refinement problem, a fixed-length sequence emitted from an\ninformation source is encoded into two codewords by two encoders in order to\ngive two reconstructions of the sequence. One of two reconstructions is\nobtained by one of two codewords, and the other reconstruction is obtained by\nall two codewords. For this coding problem, we give non-asymptotic inner and\nouter bounds on pairs of numbers of codewords of two encoders such that each\nprobability that a distortion exceeds a given distortion level is less than a\ngiven probability level. We also give a general formula for the rate-distortion\nregion for general sources, where the rate-distortion region is the set of rate\npairs of two encoders such that each maximum value of possible distortions is\nless than a given distortion level. \n\n"}
{"id": "1802.08276", "contents": "Title: Quantum entropy and polarization measurements of the two-photon system Abstract: We consider the bipartite state of a two-photon polarization system and\nobtain the exact analytical expression for the von Neumann entropy in the\nparticular case of a 5-parameter polarization density matrix. We investigate\nand graphically illustrate the dependence of the entropy on these five\nparameters, in particular, the existence of exotic, transition from exotic to\nnon-exotic, and non-exotic states, where the quantum conditional entropy is\nnegative, both positive and negative, and positive, respectively. We study the\n\"cooling\" or \"heating\" effect that follows from the reduced density of photon 2\nwhen a measurement is performed on photon 1. \n\n"}
{"id": "1802.08464", "contents": "Title: The geometry of off-the-grid compressed sensing Abstract: This paper presents a sharp geometric analysis of the recovery performance of\nsparse regularization. More specifically, we analyze the BLASSO method which\nestimates a sparse measure (sum of Dirac masses) from randomized sub-sampled\nmeasurements. This is a \"continuous\", often called off-the-grid, extension of\nthe compressed sensing problem, where the $\\ell^1$ norm is replaced by the\ntotal variation of measures. This extension is appealing from a numerical\nperspective because it avoids to discretize the the space by some grid. But\nmore importantly, it makes explicit the geometry of the problem since the\npositions of the Diracs can now freely move over the parameter space. On a\nmethodological level, our contribution is to propose the Fisher geodesic\ndistance on this parameter space as the canonical metric to analyze\nsuper-resolution in a way which is invariant to reparameterization of this\nspace. Switching to the Fisher metric allows us to take into account\nmeasurement operators which are not translation invariant, which is crucial for\napplications such as Laplace inversion in imaging, Gaussian mixtures estimation\nand training of multilayer perceptrons with one hidden layer. On a theoretical\nlevel, our main contribution shows that if the Fisher distance between spikes\nis larger than a Rayleigh separation constant, then the BLASSO recovers in a\nstable way a stream of Diracs, provided that the number of measurements is\nproportional (up to log factors) to the number of Diracs. We measure the\nstability using an optimal transport distance constructed on top of the Fisher\ngeodesic distance. Our result is (up to log factor) sharp and does not require\nany randomness assumption on the amplitudes of the underlying measure. Our\nproof technique relies on an infinite-dimensional extension of the so-called\n\"golfing scheme\" which operates over the space of measures and is of general\ninterest. \n\n"}
{"id": "1803.00884", "contents": "Title: Physical Layer Security for RF Satellite Channels in the Finite-length\n  Regime Abstract: Secure communications is becoming increasingly relevant in the development of\nspace technology. Well established cryptographic technology is already in place\nand is expected to continue to be so. On the other hand, information\ntheoretical security emerges as a post-quantum versatile candidate to\ncomplement overall security strength. In order to prove such potential,\nperformance analysis methods are needed that consider realistic legitimate and\neavesdropper system assumptions and non-asymptotic coding lengths. In this\npaper we propose the design of secure radio frequency (RF) satellite links with\nrealistic system assumptions. Our contribution is three-fold. First, we propose\na wiretap channel model for the finite-length regime. The model includes an\nstochastic wiretap encoding method using existing practical linear error\ncorrecting codes and hash codes. Secrecy is provided with privacy\namplification, for which the finite-length secrecy metric is given that upper\nbounds semantic secrecy. Second, we derive a novel RF (broadcast) satellite\nwiretap channel model that parameterizes the stochastic degraded channel around\nthe legitimate channel, a necessary condition to enable secure communication.\nFinally, we show the design of a secure satellite physical layer and\nfinite-length performance evaluation. In doing so, we define as sacrifice rate\nthe fixed fraction of the overall coding rate budget for reliability that needs\nto be allocated to secrecy. Our methodology does not make use of channel side\ninformation of the eavesdropper, only assumes worst case system assumptions. We\nillustrate our proposed design method with numerical results using practical\nerror correcting codes in current standards of satellite communication. \n\n"}
{"id": "1803.00983", "contents": "Title: Power Control and Channel Allocation for D2D Underlaid Cellular Networks Abstract: Device-to-Device (D2D) communications underlaying cellular networks is a\nviable network technology that can potentially increase spectral utilization\nand improve power efficiency for proximitybased wireless applications and\nservices. However, a major challenge in such deployment scenarios is the\ninterference caused by D2D links when sharing the same resources with cellular\nusers. In this work, we propose a channel allocation (CA) scheme together with\na set of three power control (PC) schemes to mitigate interference in a D2D\nunderlaid cellular system modeled as a random network using the mathematical\ntool of stochastic geometry. The novel aspect of the proposed CA scheme is that\nit enables D2D links to share resources with multiple cellular users as opposed\nto one as previously considered in the literature. Moreover, the accompanying\ndistributed PC schemes further manage interference during link establishment\nand maintenance. The first two PC schemes compensate for large-scale path-loss\neffects and maximize the D2D sum rate by employing distance-dependent pathloss\nparameters of the D2D link and the base station, including an error estimation\nmargin. The third scheme is an adaptive PC scheme based on a variable target\nsignal-to-interference-plus-noise ratio, which limits the interference caused\nby D2D users and provides sufficient coverage probability for cellular users.\nClosed-form expressions for the coverage probability of cellular links, D2D\nlinks, and sum rate of D2D links are derived in terms of the allocated power,\ndensity of D2D links, and path-loss exponent. The impact of these key system\nparameters on network performance is analyzed and compared with previous work.\nSimulation results demonstrate an enhancement in cellular and D2D coverage\nprobabilities, and an increase in spectral and power efficiency. \n\n"}
{"id": "1803.03733", "contents": "Title: Mobile Edge Computing for Cellular-Connected UAV: Computation Offloading\n  and Trajectory Optimization Abstract: This paper studies a new mobile edge computing (MEC) setup where an unmanned\naerial vehicle (UAV) is served by cellular ground base stations (GBSs) for\ncomputation offloading. The UAV flies between a give pair of initial and final\nlocations, during which it needs to accomplish certain computation tasks by\noffloading them to some selected GBSs along its trajectory for parallel\nexecution. Under this setup, we aim to minimize the UAV's mission completion\ntime by optimizing its trajectory jointly with the computation offloading\nscheduling, subject to the maximum speed constraint of the UAV, and the\ncomputation capacity constraints at GBSs. The joint UAV trajectory and\ncomputation offloading optimization problem is, however, non-convex and thus\ndifficult to be solved optimally. To tackle this problem, we propose an\nefficient algorithm to obtain a high-quality suboptimal solution. Numerical\nresults show that the proposed design significantly reduces the UAV's mission\ncompletion time, as compared to benchmark schemes. \n\n"}
{"id": "1803.03752", "contents": "Title: Optimum Linear Codes with Support Constraints over Small Fields Abstract: We consider the problem of designing optimal linear codes (in terms of having\nthe largest minimum distance) subject to a support constraint on the generator\nmatrix. We show that the largest minimum distance can be achieved by a subcode\nof a Reed-Solomon code of small field size. As a by-product of this result, we\nsettle the GM-MDS conjecture of Dau et. al. in the affirmative. \n\n"}
{"id": "1803.07505", "contents": "Title: Non-Asymptotic Classical Data Compression with Quantum Side Information Abstract: In this paper, we analyze classical data compression with quantum side\ninformation (also known as the classical-quantum Slepian-Wolf protocol) in the\nso-called large and moderate deviation regimes. In the non-asymptotic setting,\nthe protocol involves compressing classical sequences of finite length $n$ and\ndecoding them with the assistance of quantum side information. In the large\ndeviation regime, the compression rate is fixed, and we obtain bounds on the\nerror exponent function, which characterizes the minimal probability of error\nas a function of the rate. Devetak and Winter showed that the asymptotic data\ncompression limit for this protocol is given by a conditional entropy. For any\nprotocol with a rate below this quantity, the probability of error converges to\none asymptotically and its speed of convergence is given by the strong converse\nexponent function. We obtain finite blocklength bounds on this function, and\ndetermine exactly its asymptotic value. In the moderate deviation regime for\nthe compression rate, the latter is no longer considered to be fixed. It is\nallowed to depend on the blocklength $n$, but assumed to decay slowly to the\nasymptotic data compression limit. Starting from a rate above this limit, we\ndetermine the speed of convergence of the error probability to zero and show\nthat it is given in terms of the conditional information variance. Our results\ncomplement earlier results obtained by Tomamichel and Hayashi, in which they\nanalyzed the so-called small deviation regime of this protocol. \n\n"}
{"id": "1803.07993", "contents": "Title: Age of Information in a Network of Preemptive Servers Abstract: A source submits status updates to a network for delivery to a destination\nmonitor. Updates follow a route through a series of network nodes. Each node is\na last-come-first-served queue supporting preemption in service. We\ncharacterize the average age of information at the input and output of each\nnode in the route induced by the updates passing through. For Poisson arrivals\nto a line network of preemptive memoryless servers, we show that average age\naccumulates through successive network nodes. \n\n"}
{"id": "1803.08178", "contents": "Title: Boosted Density Estimation Remastered Abstract: There has recently been a steady increase in the number iterative approaches\nto density estimation. However, an accompanying burst of formal convergence\nguarantees has not followed; all results pay the price of heavy assumptions\nwhich are often unrealistic or hard to check. The Generative Adversarial\nNetwork (GAN) literature --- seemingly orthogonal to the aforementioned pursuit\n--- has had the side effect of a renewed interest in variational divergence\nminimisation (notably $f$-GAN). We show that by introducing a weak learning\nassumption (in the sense of the classical boosting framework) we are able to\nimport some recent results from the GAN literature to develop an iterative\nboosted density estimation algorithm, including formal convergence results with\nrates, that does not suffer the shortcomings other approaches. We show that the\ndensity fit is an exponential family, and as part of our analysis obtain an\nimproved variational characterisation of $f$-GAN. \n\n"}
{"id": "1803.08189", "contents": "Title: Can Decentralized Status Update Achieve Universally Near-Optimal\n  Age-of-Information in Wireless Multiaccess Channels? Abstract: In an Internet-of-Things system where status data are collected from sensors\nand actuators for time-critical applications, the freshness of data is vital\nand can be quantified by the recently proposed age-of-information (AoI) metric.\nIn this paper, we first consider a general scenario where multiple terminals\nshare a common channel to transmit or receive randomly generated status\npackets. The optimal scheduling problem to minimize AoI is formulated as a\nrestless multi-armed bandit problem. To solve the problem efficiently, we\nderive the Whittle's index in closed-form and establish the indexability\nthereof. Compared with existing work, we extend the index policy for AoI\noptimization to incorporate stochastic packet arrivals and optimal packet\nmanagement (buffering the latest packet). Inspired by the index policy which\nhas near-optimal performance but is centralized by nature, a decentralized\nstatus update scheme, i.e., the index-prioritized random access policy (IPRA),\nis further proposed, achieving universally near-optimal AoI performance and\noutperforming state-of-the-arts in the literature. \n\n"}
{"id": "1803.08686", "contents": "Title: Uplink Achievable Rate in One-bit Quantized Massive MIMO with\n  Superimposed Pilots Abstract: In this work, we consider a 1-bit quantized massive MIMO channel with\nsuperimposed pilot (SP) scheme, dubbed QSP. With linear minimum mean square\nerror (LMMSE) channel estimator and maximum ratio combining (MRC) receiver at\nthe BS, we derive an approximate lower bound on the achievable rate. When\noptimizing pilot and data powers, the optimal power allocation maximizing the\ndata rate is obtained in a closed-form solution. Although there is a\nperformance gap between the quantized and unquantized systems, it is shown that\nthis gap diminishes as the number of BS antennas is asymptotically large.\nMoreover, we show that pilot removal from the received signal by using the\nchannel estimate doesn't result in a significant increase in information,\nespecially in the cases of low signal-to-noise ratio (SNR) and a large number\nof users. We present some numerical results to corroborate our analytical\nfindings and insights are provided for further exploration of the quantized\nsystems with SP. \n\n"}
{"id": "1803.09012", "contents": "Title: Message passing-based joint CFO and channel estimation in millimeter\n  wave systems with one-bit ADCs Abstract: Channel estimation at millimeter wave (mmWave) is challenging when large\nantenna arrays are used. Prior work has leveraged the sparse nature of mmWave\nchannels via compressed sensing based algorithms for channel estimation. Most\nof these algorithms, though, assume perfect synchronization and are vulnerable\nto phase errors that arise due to carrier frequency offset (CFO) and phase\nnoise. Recently sparsity-aware, non-coherent beamforming algorithms that are\nrobust to phase errors were proposed for narrowband phased array systems with\nfull resolution analog-to-digital converters (ADCs). Such energy based\nalgorithms, however, are not robust to heavy quantization at the receiver. In\nthis paper, we develop a joint CFO and wideband channel estimation algorithm\nthat is scalable across different mmWave architectures. Our method exploits the\nsparsity of mmWave MIMO channel in the angle-delay domain, in addition to\ncompressibility of the phase error vector. We formulate the joint estimation as\na sparse bilinear optimization problem and then use message passing for\nrecovery. We also give an efficient implementation of a generalized bilinear\nmessage passing algorithm for the joint estimation in mmWave systems with\none-bit ADCs. Simulation results show that our method is able to recover the\nCFO and the channel compressively, even in the presence of phase noise. \n\n"}
{"id": "1803.10623", "contents": "Title: Stability and Dynamic Control of Underlay Mobile Edge Networks Abstract: This paper studies the stability and dynamic control of underlay mobile edge\nnetworks. First, the stability region for a multiuser edge network is obtained\nunder the assumption of full channel state information. This result provides a\nbenchmark figure for comparing performance of the proposed algorithms. Second,\na centralized joint flow control and scheduling algorithm is proposed to\nstabilize the queues of edge devices while respecting the average and\ninstantaneous interference power constraints at the core access point. This\nalgorithm is proven to converge to a utility point arbitrarily close to the\nmaximum achievable utility within the stability region. Finally, more practical\nimplementation issues such as distributed scheduling are examined by designing\nefficient scheduling algorithms taking advantage of communications diversity.\nThe proposed distributed solutions utilize mini slots for contention resolution\nand achieve a certain fraction of the utility optimal point. The performance\nlower bounds for distributed algorithms are determined analytically. The\ndetailed simulation study is performed to pinpoint the cost of distributed\ncontrol for mobile edge networks with respect to centralized control. \n\n"}
{"id": "1803.11335", "contents": "Title: On the classification of linear complementary dual codes Abstract: We give a complete classification of binary linear complementary dual codes\nof lengths up to $13$ and ternary linear complementary dual codes of lengths up\nto $10$. \n\n"}
{"id": "1803.11451", "contents": "Title: Minimax Estimation of Quadratic Fourier Functionals Abstract: We study estimation of (semi-)inner products between two nonparametric\nprobability distributions, given IID samples from each distribution. These\nproducts include relatively well-studied classical $\\mathcal{L}^2$ and Sobolev\ninner products, as well as those induced by translation-invariant reproducing\nkernels, for which we believe our results are the first. We first propose\nestimators for these quantities, and the induced (semi)norms and\n(pseudo)metrics. We then prove non-asymptotic upper bounds on their mean\nsquared error, in terms of weights both of the inner product and of the two\ndistributions, in the Fourier basis. Finally, we prove minimax lower bounds\nthat imply rate-optimality of the proposed estimators over Fourier ellipsoids. \n\n"}
{"id": "1804.00351", "contents": "Title: Stabilizing a linear system using phone calls: when time is information Abstract: We consider the problem of stabilizing an undisturbed, scalar, linear system\nover a \"timing\" channel, namely a channel where information is communicated\nthrough the timestamps of the transmitted symbols. Each symbol transmitted from\na sensor to a controller in a closed-loop system is received subject to some to\nrandom delay. The sensor can encode messages in the waiting times between\nsuccessive transmissions and the controller must decode them from the\ninter-reception times of successive symbols. This set-up is analogous to a\ntelephone system where a transmitter signals a phone call to a receiver through\na \"ring\" and, after the random delay required to establish the connection; the\nreceiver is aware of the \"ring\" being received. Since there is no data payload\nexchange between the sensor and the controller, this set-up provides an\nabstraction for performing event-triggering control with zero-payload rate. We\nshow the following requirement for stabilization: for the state of the system\nto converge to zero in probability, the timing capacity of the channel should\nbe, essentially, at least as large as the entropy rate of the system.\nConversely, in the case the symbol delays are exponentially distributed, we\nshow an \"almost\" tight sufficient condition using a coding strategy that\nrefines the estimate of the decoded message every time a new symbol is\nreceived. Our results generalize previous zero-payload event-triggering control\nstrategies, revealing a fundamental limit in using timing information for\nstabilization, independent of any transmission strategy. \n\n"}
{"id": "1804.00807", "contents": "Title: Full Characterization of Optimal Uncoded Placement for the Structured\n  Clique Cover Delivery of Nonuniform Demands Abstract: We investigate the problem of coded caching for nonuniform demands when the\nstructured clique cover algorithm proposed by Maddah-Ali and Niesen for\ndecentralized caching is used for delivery. We apply this algorithm to all user\ndemands regardless of their request probabilities. This allows for coding among\nthe files that have different request probabilities but makes the allocation of\nmemory to different files challenging during the content placement phase. As\nour main contribution, we analytically characterize the optimal placement\nstrategy that minimizes the expected delivery rate under a storage capacity\nconstraint. It is shown that the optimal placement follows either a two or a\nthree group strategy, where a set of less popular files are not cached at all\nand the files within each of the other sets are allocated identical amounts of\nstorage as if they had the same request probabilities. We show that for a\nfinite set of storage capacities, that we call the base-cases of the problem,\nthe two group strategy is always optimal. For other storage capacities, optimal\nplacement is achieved by memory sharing between certain base-cases and the\nresulting placement either follows a two or a three group strategy depending on\nthe corresponding base-cases used. We derive a polynomial time algorithm that\ndetermines the base-cases of the problem given the number of caches and\npopularity distribution of files. Given the base-cases of the problem, the\noptimal memory allocation parameters for any storage capacity are derived\nanalytically. \n\n"}
{"id": "1804.03665", "contents": "Title: An information-theoretic, all-scales approach to comparing networks Abstract: As network research becomes more sophisticated, it is more common than ever\nfor researchers to find themselves not studying a single network but needing to\nanalyze sets of networks. An important task when working with sets of networks\nis network comparison, developing a similarity or distance measure between\nnetworks so that meaningful comparisons can be drawn. The best means to\naccomplish this task remains an open area of research. Here we introduce a new\nmeasure to compare networks, the Network Portrait Divergence, that is\nmathematically principled, incorporates the topological characteristics of\nnetworks at all structural scales, and is general-purpose and applicable to all\ntypes of networks. An important feature of our measure that enables many of its\nuseful properties is that it is based on a graph invariant, the network\nportrait. We test our measure on both synthetic graphs and real world networks\ntaken from protein interaction data, neuroscience, and computational social\nscience applications. The Network Portrait Divergence reveals important\ncharacteristics of multilayer and temporal networks extracted from data. \n\n"}
{"id": "1804.06002", "contents": "Title: Joint Quantizer Optimization based on Neural Quantizer for Sum-Product\n  Decoder Abstract: A low-precision analog-to-digital converter (ADC) is required to implement a\nfrontend device of wideband digital communication systems in order to reduce\nits power consumption. The goal of this paper is to present a novel joint\nquantizer optimization method for minimizing lower-precision quantizers matched\nto the sum-product algorithms. The principal idea is to introduce a quantizer\nthat includes a feed-forward neural network and the soft staircase function.\nSince the soft staircase function is differentiable and has non-zero gradient\nvalues everywhere, we can exploit backpropagation and a stochastic gradient\ndescent method to train the feed-forward neural network in the quantizer. The\nexpected loss regarding the channel input and the decoder output is minimized\nin a supervised training phase. The experimental results indicate that the\njoint quantizer optimization method successfully provides an 8-level quantizer\nfor a low-density parity-check (LDPC) code that achieves only a 0.1-dB\nperformance loss compared to the unquantized system. \n\n"}
{"id": "1804.07394", "contents": "Title: QoS Provisioning in Large Wireless Networks Abstract: Quality of service (QoS) provisioning in next-generation mobile\ncommunications systems entails a deep understanding of the delay performance.\nThe delay in wireless networks is strongly affected by the traffic arrival\nprocess and the service process, which in turn depends on the medium access\nprotocol and the signal-to-interference-plus-noise ratio (SINR) distribution.\nIn this work, we characterize the conditional distribution of the service\nprocess given the point process in Poisson bipolar networks. We then provide an\nupper bound on the delay violation probability combining tools from stochastic\nnetwork calculus and stochastic geometry. Furthermore, we analyze the delay\nperformance under statistical queueing constraints using the effective capacity\nformulation. The impact of QoS requirements, network geometry and link distance\non the delay performance is identified. Our results provide useful insights for\nguaranteeing stringent delay requirements in large wireless networks. \n\n"}
{"id": "1804.07642", "contents": "Title: On the Effects of Subpacketization in Content-Centric Mobile Networks Abstract: A large-scale content-centric mobile ad hoc network employing\nsubpacketization is studied in which each mobile node having finite-size cache\nmoves according to the reshuffling mobility model and requests a content object\nfrom the library independently at random according to the Zipf popularity\ndistribution. Instead of assuming that one content object is transferred in a\nsingle time slot, we consider a more challenging scenario where the size of\neach content object is considerably large and thus only a subpacket of a file\ncan be delivered during one time slot, which is motivated by a fast mobility\nscenario. Under our mobility model, we consider a single-hop-based content\ndelivery and characterize the fundamental trade-offs between throughput and\ndelay. The order-optimal throughput-delay trade-off is analyzed by presenting\nthe following two content reception strategies: the sequential reception for\nuncoded caching and the random reception for maximum distance separable\n(MDS)-coded caching. We also perform numerical evaluation to validate our\nanalytical results. In particular, we conduct performance comparisons between\nthe uncoded caching and the MDS-coded caching strategies by identifying the\nregimes in which the performance difference between the two caching strategies\nbecomes prominent with respect to system parameters such as the Zipf exponent\nand the number of subpackets. In addition, we extend our study to the random\nwalk mobility scenario and show that our main results are essentially the same\nas those in the reshuffling mobility model. \n\n"}
{"id": "1804.07756", "contents": "Title: Mobile Edge Computing-Enabled Heterogeneous Networks Abstract: The mobile edge computing (MEC) has been introduced for providing computing\ncapabilities at the edge of networks to improve the latency performance of\nwireless networks. In this paper, we provide the novel framework for\nMEC-enabled heterogeneous networks (HetNets), composed of the multi-tier\nnetworks with access points (APs) (i.e., MEC servers), which have different\ntransmission power and different computing capabilities. In this framework, we\nalso consider multiple-type mobile users with different sizes of computation\ntasks, and they offload the tasks to a MEC server, and receive the computation\nresulting data from the server. We derive the successful edge computing\nprobability (SECP), defined as the probability that a user offloads and\nfinishes its computation task at the MEC server within the target latency. We\nprovide a closed-form expression of the approximated SECP for general case, and\nclosed-form expressions of the exact SECP for special cases. This paper then\nprovides the design insights for the optimal configuration of MEC-enabled\nHetNets by analyzing the effects of network parameters and bias factors, used\nin MEC server association, on the SECP. Specifically, it shows how the optimal\nbias factors in terms of SECP can be changed according to the numbers of user\ntypes and tiers of MEC servers, and how they are different to the conventional\nones that did not consider the computing capabilities and task sizes. \n\n"}
{"id": "1804.10298", "contents": "Title: Success Probability and Area Spectral Efficiency of a VANET Modeled as a\n  Cox Process Abstract: This paper analyzes the performance of a vehicular ad hoc network (VANET)\nmodeled as a Cox process, where the spatial layout of the roads is modeled by a\nPoisson line process (PLP) and the locations of nodes on each line are modeled\nas a 1D Poisson point process (PPP). For this setup, we characterize the\nsuccess probability of a typical link and the area spectral efficiency (ASE) of\nthe network assuming slotted ALOHA as the channel access scheme. We then\nconcretely establish that the success probability of a typical link in a VANET\nmodeled using a Cox process converges to that of a 1D and 2D PPP for some\nextreme values of the line and node densities. We also study the trends in\nsuccess probability as a function of the system parameters and show that the\noptimum transmission probability that maximizes the ASE for this Cox process\nmodel differs significantly from those of the relatively-simpler 1D and 2D PPP\nmodels used commonly in the literature to model vehicular networks. \n\n"}
{"id": "1804.10856", "contents": "Title: Efficient Calculation of Meta Distributions and the Performance of User\n  Percentiles Abstract: Meta distributions (MDs) are refined performance metrics in wireless networks\nmodeled using point processes. While there is no known method to directly\ncalculate MDs, the moments of the underlying conditional distributions (given\nthe point process) can often be expressed in exact analytical form. The problem\nof finding the MD given the moments has several solutions, but the standard\napproaches are inefficient and sensitive to the choices of a number of\nparameters. Here we propose and explore the use of a method based on binomial\nmixtures, which has several key advantages over other methods, since it is\nbased on a simple linear transform of the moments. \n\n"}
{"id": "1804.11136", "contents": "Title: Proof of spending in block-chain systems Abstract: We introduce proof of spending in a block-chain system. In this system the\nprobability for a node to create a legal block is proportional to the total\namount of coins it has spent in history. \n\n"}
{"id": "1805.00706", "contents": "Title: On the Structure of Interlinked Cycle Structures with Interlocked Outer\n  Cycles Abstract: For index coding problems with special structure on the side-information\ngraphs called Interlinked Cycle (IC) structures index codes have been proposed\nin the literature (C. Thapa, L. Ong, and S. Johnson, \"Interlinked Cycles for\nIndex Coding: Generalizing Cycles and Cliques\", in IEEE Trans. Inf. Theory,\nvol. 63, no. 6, Jun. 2017, with a correction in \"Interlinked Cycles for Index\nCoding: Generalizing Cycles and Cliques\", in arxiv (arxiv:1603.00092v2 [cs.IT]\n25 Feb 2018)). Recently (S. Sasi and B.S. Rajan, \"On Optimal Index Codes for\nInterlinked Cycle Structures with Outer Cycles,\" in arxiv (arXiv:1804.09120v1\n[cs.IT]), 24 Apr 2018) for a generalization of IC structures called IC\nstructures with interlocked outer cycles optimal length index codes have been\nreported and it is shown that the optimal length depends on the maximum number\nof disjoint outer cycles. In this paper we discuss certain structural\nproperties of IC structures with interlocked outer cycles and provide a simple\nalgorithm to find the maximum number of disjoint outer cycles. \n\n"}
{"id": "1805.00743", "contents": "Title: Group Secret-Key Generation using Algebraic Rings in Wireless Networks Abstract: It is well known that physical-layer Group Secret-Key (GSK) generation\ntechniques allow multiple nodes of a wireless network to synthesize a common\nsecret-key, which can be subsequently used to keep their group messages\nconfidential. As one of its salient features, the wireless nodes involved in\nphysical-layer GSK generation extract randomness from a subset of their\nwireless channels, referred as the common source of randomness (CSR). Unlike\ntwo-user key generation, in GSK generation, some nodes must act as facilitators\nby broadcasting quantized versions of the linear combinations of the channel\nrealizations, so as to assist all the nodes to observe a CSR. However, we note\nthat broadcasting linear combination of channel realizations incurs non-zero\nleakage of the CSR to an eavesdropper, and moreover, quantizing the linear\ncombination also reduces the overall key-rate. Identifying these issues, we\npropose a practical GSK generation protocol, referred to as Algebraic\nSymmetrically Quantized GSK (A-SQGSK) protocol, in a network of three nodes,\nwherein due to quantization of symbols at the facilitator, the other two nodes\nalso quantize their channel realizations, and use them appropriately over\nalgebraic rings to generate the keys. First, we prove that the A-SQGSK protocol\nincurs zero leakage to an eavesdropper. Subsequently, on the CSR provided by\nthe A-SQGSK protocol, we propose a consensus algorithm among the three nodes,\ncalled the Entropy-Maximization Error-Minimization (EM-EM) algorithm, which\nmaximizes the entropy of the secret-key subject to an upper-bound on the\nmismatch-rate. We use extensive analysis and simulation results to lay out\nguidelines to jointly choose the parameters of the A-SQGSK protocol and the\nEM-EM algorithm. \n\n"}
{"id": "1805.01498", "contents": "Title: Improved decoding of Folded Reed-Solomon and Multiplicity Codes Abstract: In this work, we show new and improved error-correcting properties of folded\nReed-Solomon codes and multiplicity codes. Both of these families of codes are\nbased on polynomials over finite fields, and both have been the sources of\nrecent advances in coding theory. Folded Reed-Solomon codes were the first\nexplicit constructions of codes known to achieve list-decoding capacity;\nmultivariate multiplicity codes were the first constructions of high-rate\nlocally correctable codes; and univariate multiplicity codes are also known to\nachieve list-decoding capacity.\n  However, previous analyses of the error-correction properties of these codes\ndid not yield optimal results. In particular, in the list-decoding setting, the\nguarantees on the list-sizes were polynomial in the block length, rather than\nconstant; and for multivariate multiplicity codes, local list-decoding\nalgorithms could not go beyond the Johnson bound.\n  In this paper, we show that Folded Reed-Solomon codes and multiplicity codes\nare in fact better than previously known in the context of list-decoding and\nlocal list-decoding. More precisely, we first show that Folded RS codes achieve\nlist-decoding capacity with constant list sizes, independent of the block\nlength; and that high-rate univariate multiplicity codes can also be\nlist-recovered with constant list sizes. Using our result on univariate\nmultiplicity codes, we show that multivariate multiplicity codes are high-rate,\nlocally list-recoverable codes. Finally, we show how to combine the above\nresults with standard tools to obtain capacity achieving locally list decodable\ncodes with query complexity significantly lower than was known before. \n\n"}
{"id": "1805.01808", "contents": "Title: Stochastic Geometry-based Uplink Analysis of Massive MIMO Systems with\n  Fractional Pilot Reuse Abstract: In this work, we analyze the performance of the uplink (UL) of a massive MIMO\nnetwork considering an asymptotically large number of antennas at base stations\n(BSs). We model the locations of BSs as a homogeneous Poisson point process\n(PPP) and assume that their service regions are limited to their respective\nPoisson-Voronoi cells (PVCs). Further, for each PVC, based on a threshold\nradius, we model the cell center (CC) region as the Johnson-Mehl (JM) cell of\nits BS while rest of the PVC is deemed as the cell edge (CE) region. The CC and\nCE users are located uniformly at random independently of each other in the JM\ncell and CE region, respectively. In addition, we consider a fractional pilot\nreuse (FPR) scheme where two different sets of pilot sequences are used for CC\nand CE users with the objective of reducing the interference due to pilot\ncontamination for CE users. Based on the above system model, we derive\nanalytical expressions for the UL signal-to-interference-and-noise ratio (SINR)\ncoverage probability and average spectral efficiency (SE) for randomly selected\nCC and CE users. In addition, we present an approximate expression for the\naverage cell SE. One of the key intermediate results in our analysis is the\napproximate but accurate characterization of the distributions of the CC and CE\nareas of a typical cell. Another key intermediate step is the accurate\ncharacterization of the pair correlation functions of the point processes\nformed by the interfering CC and CE users that subsequently enables the\ncoverage probability analysis. From our system analysis, we present a\npartitioning rule for the number of pilot sequences to be used for CC and CE\nusers as a function of threshold radius that improves the average CE user SE\nwhile achieving similar CC user SE with respect to unity pilot reuse. \n\n"}
{"id": "1805.03785", "contents": "Title: Deep Learning of Geometric Constellation Shaping including Fiber\n  Nonlinearities Abstract: A new geometric shaping method is proposed, leveraging unsupervised machine\nlearning to optimize the constellation design. The learned constellation\nmitigates nonlinear effects with gains up to 0.13 bit/4D when trained with a\nsimplified fiber channel model. \n\n"}
{"id": "1805.07013", "contents": "Title: Blind Receive Beamforming for Autonomous Grant-Free High-Overloading\n  Multiple Access Abstract: Massive number of internet of things (IoT) devices are expected to\nsimultaneously connect to the mMTC and beyond future generations of wireless\nnetwork, posing severe challenge to aspects such as RACH procedure, user\nequipment detection and channel estimation. Although spatial combining has\nprovided significant gains in conventional grant-based transmission, this\ntechnique is stuck in dilemma when it comes to autonomous grant-free\ntransmission tailored for IoT use cases. To address this, blind spatial\ncombining and its incorporation in the data-only MUD are elaborated in this\npaper answering to both the academic and industry's concern in the overloading\npotential of autonomous grant-free (AGF) transmission. Blind spatial combining\ncould be interpreted as blind receive beamforming heuristically. Simulation\nresults show that the blind spatial combining enhanced data-only MUD\nperformance for AGF transmission is rather impressive. \n\n"}
{"id": "1805.07027", "contents": "Title: Efficient Downlink Channel Reconstruction for FDD Multi-Antenna Systems Abstract: In this paper, we propose an efficient downlink channel reconstruction scheme\nfor a frequency-division-duplex multi-antenna system by utilizing uplink\nchannel state information combined with limited feedback. Based on the spatial\nreciprocity in a wireless channel, the downlink channel is reconstructed by\nusing frequency-independent parameters. We first estimate the gains, delays,\nand angles during uplink sounding. The gains are then refined through downlink\ntraining and sent back to the base station (BS). With limited overhead, the\nrefinement can substantially improve the accuracy of the downlink channel\nreconstruction. The BS can then reconstruct the downlink channel with the\nuplink-estimated delays and angles and the downlink-refined gains. We also\nintroduce and extend the Newtonized orthogonal matching pursuit (NOMP)\nalgorithm to detect the delays and gains in a multi-antenna multi-subcarrier\ncondition. The results of our analysis show that the extended NOMP algorithm\nachieves high estimation accuracy. Simulations and over-the-air tests are\nperformed to assess the performance of the efficient downlink channel\nreconstruction scheme. The results show that the reconstructed channel is close\nto the practical channel and that the accuracy is enhanced when the number of\nBS antennas increases, thereby highlighting that the promising application of\nthe proposed scheme in large-scale antenna array systems. \n\n"}
{"id": "1805.07182", "contents": "Title: Cellular-Enabled UAV Communication: A Connectivity-Constrained\n  Trajectory Optimization Perspective Abstract: Integrating the unmanned aerial vehicles (UAVs) into the cellular network is\nenvisioned to be a promising technology to significantly enhance the\ncommunication performance of both UAVs and existing terrestrial users. In this\npaper, we first provide an overview on the two main paradigms in cellular UAV\ncommunications, i.e., cellular-enabled UAV communication with UAVs as new\naerial users served by the ground base stations (GBSs), and UAV-assisted\ncellular communication with UAVs as new aerial communication platforms serving\nthe terrestrial users. Then, we focus on the former paradigm and study a new\nUAV trajectory design problem subject to practical communication connectivity\nconstraints with the GBSs. Specifically, we consider a cellular-connected UAV\nin the mission of flying from an initial location to a final location, during\nwhich it needs to maintain reliable communication with the cellular network by\nassociating with one GBS at each time instant. We aim to minimize the UAV's\nmission completion time by optimizing its trajectory, subject to a\nquality-of-connectivity constraint of the GBS-UAV link specified by a minimum\nreceive signal-to-noise ratio target. To tackle this challenging non-convex\nproblem, we first propose a graph connectivity based method to verify its\nfeasibility. Next, by examining the GBS-UAV association sequence over time, we\nobtain useful structural results on the optimal UAV trajectory, based on which\ntwo efficient methods are proposed to find high-quality approximate trajectory\nsolutions by leveraging graph theory and convex optimization techniques. The\nproposed methods are analytically shown to be capable of achieving a flexible\ntrade-off between complexity and performance, and yielding a solution that is\narbitrarily close to the optimal solution in polynomial time. Finally, we make\nconcluding remarks and point out some promising directions for future work. \n\n"}
{"id": "1805.07784", "contents": "Title: Adaptive Recovery of Dictionary-sparse Signals using Binary Measurements Abstract: One-bit compressive sensing (CS) is an advanced version of sparse recovery in\nwhich the sparse signal of interest can be recovered from extremely quantized\nmeasurements. Namely, only the sign of each measurement is available to us. In\nmany applications, the ground-truth signal is not sparse itself, but can be\nrepresented in a redundant dictionary. A strong line of research has addressed\nconventional CS in this signal model including its extension to one-bit\nmeasurements. However, one-bit CS suffers from the extremely large number of\nrequired measurements to achieve a predefined reconstruction error level. A\ncommon alternative to resolve this issue is to exploit adaptive schemes.\nAdaptive sampling acts on the acquired samples to trace the signal in an\nefficient way. In this work, we utilize an adaptive sampling strategy to\nrecover dictionary-sparse signals from binary measurements. For this task, a\nmulti-dimensional threshold is proposed to incorporate the previous signal\nestimates into the current sampling procedure. This strategy substantially\nreduces the required number of measurements for exact recovery. Our proof\napproach is based on the recent tools in high dimensional geometry in\nparticular random hyperplane tessellation and Gaussian width. We show through\nrigorous and numerical analysis that the proposed algorithm considerably\noutperforms state of the art approaches. Further, our algorithm reaches an\nexponential error decay in terms of the number of quantized measurements. \n\n"}
{"id": "1805.08635", "contents": "Title: Joint Configuration of Transmission Direction and Altitude in UAV-based\n  Two-Way Communication Abstract: When considering unidirectional communication for unmanned aerial vehicles\n(UAVs) as flying Base Stations (BSs), either uplink or downlink, the system is\nlimited through the co-channel interference that takes place over line-of-sight\n(LoS) links. This paper considers two-way communication and takes advantage of\nthe fact that the interference among the ground devices takes place through\nnon-line-of-sight (NLoS) links. UAVs can be deployed at the high altitudes to\nhave larger coverage, while the two-way communication allows to configure the\ntransmission direction. Using these two levers, we show how the system\nthroughput can be maximized for a given deployment of the ground devices. \n\n"}
{"id": "1805.08955", "contents": "Title: Coded Caching via Line Graphs of Bipartite Graphs Abstract: We present a coded caching framework using line graphs of bipartite graphs. A\nclique cover of the line graph describes the uncached subfiles at users. A\nclique cover of the complement of the square of the line graph gives a\ntransmission scheme that satisfies user demands. We then define a specific\nclass of such caching line graphs, for which the subpacketization, rate, and\nuncached fraction of the coded caching problem can be captured via its graph\ntheoretic parameters. We present a construction of such caching line graphs\nusing projective geometry. The presented scheme has a rate bounded from above\nby a constant with subpacketization level $q^{O((log_qK)^2)}$ and uncached\nfraction $\\Theta(\\frac{1}{\\sqrt{K}})$, where $K$ is the number of users and $q$\nis a prime power. We also present a subpacketization-dependent lower bound on\nthe rate of coded caching schemes for a given broadcast setup. \n\n"}
{"id": "1805.09066", "contents": "Title: Asymptotic Performance Analysis of GSVD-NOMA Systems with a Large-Scale\n  Antenna Array Abstract: This paper considers a multiple-input multiple-output (MIMO) downlink\ncommunication scenario with one base station and two users, where each user is\nequipped with m antennas and the base station is equipped with n antennas. To\nefficiently exploit the spectrum resources, we propose a transmission protocol\nwhich combines generalized singular value decomposition (GSVD) and\nnon-orthogonal multiple access (NOMA). The average data rates achieved by the\ntwo users are adopted as performance metrics for evaluation of the proposed\nGSVD-NOMA scheme. In particular, we first characterize the limiting\ndistribution of the squared generalized singular values of the two users'\nchannel matrices for the asymptotic case where the numbers of transmit and\nreceive antennas approach infinity. Then, we calculate the normalized average\nindividual rates of the users in the considered asymptotic regime. Furthermore,\nwe extend the proposed GSVD-NOMA scheme to the MIMO downlink communication\nscenario with more than two users by using a hybrid multiple access (MA)\napproach, where the base station first divides the users into different groups,\nthen the proposed GSVD-NOMA scheme is implemented within each group, and\ndifferent groups are allocated with orthogonal bandwidth resources. Finally,\nnumerical results are provided to validate the effectiveness of the proposed\nGSVD-NOMA protocol, and the accuracy of the developed analytical results. \n\n"}
{"id": "1805.09785", "contents": "Title: Entropy and mutual information in models of deep neural networks Abstract: We examine a class of deep learning models with a tractable method to compute\ninformation-theoretic quantities. Our contributions are three-fold: (i) We show\nhow entropies and mutual informations can be derived from heuristic statistical\nphysics methods, under the assumption that weight matrices are independent and\northogonally-invariant. (ii) We extend particular cases in which this result is\nknown to be rigorously exact by providing a proof for two-layers networks with\nGaussian random weights, using the recently introduced adaptive interpolation\nmethod. (iii) We propose an experiment framework with generative models of\nsynthetic datasets, on which we train deep neural networks with a weight\nconstraint designed so that the assumption in (i) is verified during learning.\nWe study the behavior of entropies and mutual informations throughout learning\nand conclude that, in the proposed setting, the relationship between\ncompression and generalization remains elusive. \n\n"}
{"id": "1805.11720", "contents": "Title: The Age of Updates in a Simple Relay Network Abstract: In this paper, we examine a system where status updates are generated by a\nsource and are forwarded in a First-Come-First-Served (FCFS) manner to the\nmonitor. We consider the case where the server has other tasks to fulfill, a\nsimple example being relaying the packets of another stream. Due to the\nserver's necessity to go on vacations, the age process of the stream of\ninterest becomes complicated to evaluate. By leveraging specific queuing theory\ntools, we provide a closed form of the average age for both streams which\nenables us to optimize the generation rate of packets belonging to each stream\nto achieve the minimum possible average age. The tools used can be further\nadopted to provide insights on more general multi-hop scenarios. Numerical\nresults are provided to corroborate the theoretical findings and highlight the\ninteraction between the two streams. \n\n"}
{"id": "1805.12097", "contents": "Title: Social Signals in the Ethereum Trading Network Abstract: Blockchain technology, which has been known by mostly small technological\ncircles up until recently, is bursting throughout the globe, with a potential\neconomic and social impact that could fundamentally alter traditional financial\nand social structures. Issuing cryptocurrencies on top of the Blockchain system\nby startups and private sector companies is becoming a ubiquitous phenomenon,\ninducing the trading of these crypto-coins among their holders using dedicated\nexchanges.\n  Apart from being a trading ledger for tokens, Blockchain can also be observed\nas a social network. Analyzing and modeling the dynamics of the \"social\nsignals\" of this network can contribute to our understanding of this ecosystem\nand the forces acting within in.\n  This work is the first analysis of the network properties of the ERC20\nprotocol compliant crypto-coins' trading data. Considering all trading wallets\nas a network's nodes, and constructing its edges using buy--sell trades, we can\nanalyze the network properties of the ERC20 network. Examining several periods\nof time, and several data aggregation variants, we demonstrate that the network\ndisplays strong power-law properties. These results coincide with current\nnetwork theory expectations, however nonetheless, are the first scientific\nvalidation of it, for the ERC20 trading data.\n  The data we examined is composed of over 30 million ERC20 tokens trades,\nperformed by over 6.8 million unique wallets, lapsing over a two years period\nbetween February 2016 and February 2018. \n\n"}
{"id": "1806.00990", "contents": "Title: Time-Fractional User Association in Millimeter Wave MIMO Networks Abstract: User association determines which base stations a user connects to, hence\naffecting the amount of network interference and consequently the network\nthroughput. Conventional user association schemes, however, assume that user\ninstantaneous rates are independent of user association. In this paper, we\nintroduce a new load-aware user association scheme for millimeter wave (mmWave)\nMIMO networks which takes into account the dependency of network interference\non user association. This consideration is well suited for mmWave\ncommunications, where the links are highly directional and vulnerable to small\nchannel variations. We formulate our user association problem as a mixed\ninteger nonlinear programming (MINLP) and solve it using the genetic algorithm.\nWe show that the proposed method can improve network performance by moving the\ntraffic of congested base stations to lightly-loaded base stations and\nadjusting the interference accordingly. Our simulations confirm that our scheme\nresults in a higher network throughput compared to conventional user\nassociation techniques. \n\n"}
{"id": "1806.01799", "contents": "Title: Survey and Taxonomy of Lossless Graph Compression and Space-Efficient\n  Graph Representations Abstract: Various graphs such as web or social networks may contain up to trillions of\nedges. Compressing such datasets can accelerate graph processing by reducing\nthe amount of I/O accesses and the pressure on the memory subsystem. Yet,\nselecting a proper compression method is challenging as there exist a plethora\nof techniques, algorithms, domains, and approaches in compressing graphs. To\nfacilitate this, we present a survey and taxonomy on lossless graph compression\nthat is the first, to the best of our knowledge, to exhaustively analyze this\ndomain. Moreover, our survey does not only categorize existing schemes, but\nalso explains key ideas, discusses formal underpinning in selected works, and\ndescribes the space of the existing compression schemes using three dimensions:\nareas of research (e.g., compressing web graphs), techniques (e.g., gap\nencoding), and features (e.g., whether or not a given scheme targets dynamic\ngraphs). Our survey can be used as a guide to select the best lossless\ncompression scheme in a given setting. \n\n"}
{"id": "1806.01991", "contents": "Title: The stabilizer for $n$-qubit symmetric states Abstract: The stabilizer group for an $n$-qubit state $\\ket{\\phi}$ is the set of all\ninvertible local operators (ILO) $g=g_1\\otimes g_2\\otimes \\cdots\\otimes g_n,$ $\ng_i\\in \\mathcal{GL}(2,\\mathbb{C})$ such that $\\ket{\\phi}=g\\ket{\\phi}.$\nRecently, G. Gour $et$ $al.$ \\cite{GKW} presented that almost all $n$-qubit\nstate $\\ket{\\psi}$ own a trivial stabilizer group when $n\\ge 5.$ In this\narticle, we consider the case when the stabilizer group of an $n$-qubit\nsymmetric pure state $\\ket{\\psi}$ is trivial. First we show that the stabilizer\ngroup for an n-qubit symmetric pure state $\\ket{\\phi}$ is nontrivial when $n\\le\n4$. Then we present a class of $n$-qubit symmetric states $\\ket{\\phi}$ with the\ntrivial stabilizer group. At last, we prove that an $n$-qubit symmetric pure\nstate owns a trivial stabilizer group when its diversity number is bigger than\n5, which confirms the main result of \\cite{GKW} partly. \n\n"}
{"id": "1806.04589", "contents": "Title: Computation Rate Maximization in UAV-Enabled Wireless Powered\n  Mobile-Edge Computing Systems Abstract: Mobile edge computing (MEC) and wireless power transfer (WPT) are two\npromising techniques to enhance the computation capability and to prolong the\noperational time of low-power wireless devices that are ubiquitous in Internet\nof Things. However, the computation performance and the harvested energy are\nsignificantly impacted by the severe propagation loss. In order to address this\nissue, an unmanned aerial vehicle (UAV)-enabled MEC wireless powered system is\nstudied in this paper. The computation rate maximization problems in a\nUAV-enabled MEC wireless powered system are investigated under both partial and\nbinary computation offloading modes, subject to the energy harvesting causal\nconstraint and the UAV's speed constraint. These problems are non-convex and\nchallenging to solve. A two-stage algorithm and a three-stage alternative\nalgorithm are respectively proposed for solving the formulated problems. The\nclosed-form expressions for the optimal central processing unit frequencies,\nuser offloading time, and user transmit power are derived. The optimal\nselection scheme on whether users choose to locally compute or offload\ncomputation tasks is proposed for the binary computation offloading mode.\nSimulation results show that our proposed resource allocation schemes\noutperforms other benchmark schemes. The results also demonstrate that the\nproposed schemes converge fast and have low computational complexity. \n\n"}
{"id": "1806.05005", "contents": "Title: Proactive Resource Allocation with Predictable Channel Statistics Abstract: The behavior of users in relatively predictable, both in terms of the data\nthey request and the wireless channels they observe. In this paper, we consider\nthe statistics of such predictable patterns of the demand and channel jointly\nacross multiple users, and develop a novel predictive resource allocation\nmethod. This method is shown to provide performance benefits over a reactive\napproach, which ignores these patterns and instead aims to satisfy the\ninstantaneous demands, irrespective of cost to the system. In particular, we\nshow that our proposed method is able to attain a novel fundamental bound on\nthe achievable cost, as the service window grows. Through numerical evaluation,\nwe gain insights into how different uncertainty sources affect the decisions\nand the cost. \n\n"}
{"id": "1806.05533", "contents": "Title: Distributed Hypothesis Testing based on Unequal-Error Protection Codes Abstract: Coding and testing schemes for binary hypothesis testing over noisy networks\nare proposed and their corresponding type-II error exponents are derived. When\ncommunication is over a discrete memoryless channel (DMC), our scheme combines\nShimokawa-Han-Amari's hypothesis testing scheme with Borade's unequal error\nprotection (UEP) for channel coding. A separate source channel coding\narchitecture is employed. The resulting exponent is optimal for the newly\nintroduced class of \\emph{generalized testing against conditional\nindependence}. When communication is over a MAC or a BC, our scheme combines\nhybrid coding with UEP. The resulting error exponent over the MAC is optimal in\nthe case of generalized testing against conditional independence with\nindependent observations at the two sensors, when the MAC decomposes into two\nindividual DMCs. In this case, separate source-channel coding is sufficient;\nthis same conclusion holds also under arbitrarily correlated sensor\nobservations when testing is against independence. For the BC, the error\nexponents region of hybrid coding with UEP exhibits a tradeoff between the\nexponents attained at the two decision centers. When both receivers aim at\nmaximizing the error exponents under different hypotheses and the marginal\ndistributions of the sensors' observations are different under these\nhypotheses, then this tradeoff can be mitigated with the following strategy.\nThe sensor makes a tentative guess on the hypothesis, submits this guess, and\napplies our coding and testing scheme for the DMC only for the decision center\nthat is not interested in maximizing the exponent under the guessed hypothesis. \n\n"}
{"id": "1806.06790", "contents": "Title: Towards Distributed Energy Services: Decentralizing Optimal Power Flow\n  with Machine Learning Abstract: The implementation of optimal power flow (OPF) methods to perform voltage and\npower flow regulation in electric networks is generally believed to require\nextensive communication. We consider distribution systems with multiple\ncontrollable Distributed Energy Resources (DERs) and present a data-driven\napproach to learn control policies for each DER to reconstruct and mimic the\nsolution to a centralized OPF problem from solely locally available\ninformation. Collectively, all local controllers closely match the centralized\nOPF solution, providing near optimal performance and satisfaction of system\nconstraints. A rate distortion framework enables the analysis of how well the\nresulting fully decentralized control policies are able to reconstruct the OPF\nsolution. The methodology provides a natural extension to decide what nodes a\nDER should communicate with to improve the reconstruction of its individual\npolicy. The method is applied on both single- and three-phase test feeder\nnetworks using data from real loads and distributed generators, focusing on\nDERs that do not exhibit inter-temporal dependencies. It provides a framework\nfor Distribution System Operators to efficiently plan and operate the\ncontributions of DERs to achieve Distributed Energy Services in distribution\nnetworks. \n\n"}
{"id": "1806.07800", "contents": "Title: Full Coded Caching Gains for Cache-less Users Abstract: Within the context of coded caching, the work reveals the interesting\nconnection between having multiple transmitters and having heterogeneity in the\ncache sizes of the receivers. Our work effectively shows that having multiple\ntransmit antennas -- while providing full multiplexing gains -- can also\nsimultaneously completely remove the performance penalties that are typically\nassociated to cache-size unevenness. Focusing on the multiple-input\nsingle-output Broadcast Channel, the work first identifies the performance\nlimits of the extreme case where cache-aided users coincide with users that do\nnot have caches, and then expands the analysis to the case where both user\ngroups are cache-aided but with heterogeneous cache-sizes. In the first case,\nthe main contribution is a new algorithm that employs perfect matchings on a\nbipartite graph to offer full multiplexing as well as full coded-caching gains\nto both cache-aided as well as cache-less users. An interesting conclusion is\nthat, starting from a single-stream centralized coded caching setting with\nnormalized cache size $\\gamma$, then adding $L$ antennas allows for the\naddition of {up to} approximately $L/\\gamma$ extra cache-less users, at no\nadded delay costs. Similarly surprising is the finding that, {beginning} with a\nsingle-antenna hybrid system (with both cache-less and cache-aided users), then\nadding {$L-1$} antennas to the transmitter, as well as endowing the cache-less\nusers with a cumulative normalized cache size $\\Gamma_2$, increases the Degrees\nof Freedom by a \\emph{multiplicative} factor of up to $\\Gamma_{2}+L$. \n\n"}
{"id": "1806.08690", "contents": "Title: Is the 1-norm the best convex sparse regularization? Abstract: The 1-norm is a good convex regularization for the recovery of sparse vectors\nfrom under-determined linear measurements. No other convex regularization seems\nto surpass its sparse recovery performance. How can this be explained? To\nanswer this question, we define several notions of \"best\" (convex)\nregulariza-tion in the context of general low-dimensional recovery and show\nthat indeed the 1-norm is an optimal convex sparse regularization within this\nframework. \n\n"}
{"id": "1806.08698", "contents": "Title: To Skip or to Switch? Minimizing Age of Information under Link Capacity\n  Constraint Abstract: Consider a scenario where a source continuously monitors an object and sends\ntime-stamped status updates to a destination through a rate-limited link. In\norder to measure the \"freshness\" of the status information available at the\ndestination, we adopt the metric called Age of Information (AoI). We assume all\nupdates are of the same size, and arrive randomly at the source according to a\nBernoulli process. Due to the link capacity constraint, it takes $d$ ($d\\geq\n2$) time slots for the source to complete the transmission of an update.\nTherefore, when a new update when arrives at the source and it is transmitting\nanother update, the source needs to decide whether to skip the new arrival or\nto switch to it, in order to minimize the expected average AoI at the\ndestination. We prove that within a broadly defined class of online policies,\nthe optimal policy should be a renewal policy, and has a sequential switching\nproperty. We then show that the optimal decision the source should take in any\ntime slot has a multiple-threshold structure, and only depends on the age of\nthe update being transmitted and the AoI in the system. The thresholds are then\nnumerically identified by formulating the problem as a Markov Decision Process\n(MDP). \n\n"}
{"id": "1806.10583", "contents": "Title: On the Error in Phase Transition Computations for Compressed Sensing Abstract: Evaluating the statistical dimension is a common tool to determine the\nasymptotic phase transition in compressed sensing problems with Gaussian\nensemble. Unfortunately, the exact evaluation of the statistical dimension is\nvery difficult and it has become standard to replace it with an upper-bound. To\nensure that this technique is suitable, [1] has introduced an upper-bound on\nthe gap between the statistical dimension and its approximation. In this work,\nwe first show that the error bound in [1] in some low-dimensional models such\nas total variation and $\\ell_1$ analysis minimization becomes poorly large.\nNext, we develop a new error bound which significantly improves the estimation\ngap compared to [1]. In particular, unlike the bound in [1] that is not\napplicable to settings with overcomplete dictionaries, our bound exhibits a\ndecaying behavior in such cases. \n\n"}
{"id": "1807.00655", "contents": "Title: On the Tradeoff Between Accuracy and Complexity in Blind Detection of\n  Polar Codes Abstract: Polar codes are a recent family of error-correcting codes with a number of\ndesirable characteristics. Their disruptive nature is illustrated by their\nrapid adoption in the $5^{th}$-generation mobile-communication standard, where\nthey are used to protect control messages. In this work, we describe a\ntwo-stage system tasked with identifying the location of control messages that\nconsists of a detection and selection stage followed by a decoding one. The\nfirst stage spurs the need for polar-code detection algorithms with variable\neffort to balance complexity between the two stages. We illustrate this idea of\nvariable effort for multiple detection algorithms aimed at the first stage. We\npropose three novel blind detection methods based on belief-propagation\ndecoding inspired by early-stopping criteria. Then we show how their\nreliability improves with the number of decoding iterations to highlight the\npossible tradeoffs between accuracy and complexity. Additionally, we show\nsimilar tradeoffs for a detection method from previous work. In a setup where\nonly one block encoded with the polar code of interest is present among many\nother blocks, our results notably show that, depending on the complexity\nbudget, a variable number of undesirable blocks can be dismissed while\nachieving a missed-detection rate in line with the block-error rate of a\ncomplex decoding algorithm. \n\n"}
{"id": "1807.00682", "contents": "Title: Dynamic Power Allocation and User Scheduling for Power-Efficient and\n  Low-Latency Communications Abstract: In this paper, we propose a joint dynamic power control and user pairing\nalgorithm for power-efficient and low-latency hybrid multiple access systems.\nIn a hybrid multiple access system, user pairing determines whether the\ntransmitter should serve a certain user by orthogonal multiple access (OMA) or\nnon-orthogonal multiple access (NOMA). The proposed optimization framework\nminimizes the long-term time-average transmit power expenditure while reducing\nthe queueing delay and satisfying time-average data rate requirements. The\nproposed technique observes channel and queue state information and adjusts\nqueue backlogs to avoid an excessive queueing delay by appropriate user pairing\nand power allocation. Further, user scheduling for determining the activation\nof a given user link as well as flexible use of resources are captured in the\nproposed algorithm. Data-intensive simulation results show that the proposed\nscheme guarantees an end-to-end delay smaller than 1 ms with high\npower-efficiency and high reliability, based on the short frame structure\ndesigned for ultra-reliable low-latency communications (URLLC). \n\n"}
{"id": "1807.00738", "contents": "Title: Treating Interference as Noise in Cellular Networks: A Stochastic\n  Geometry Approach Abstract: The interference management technique that treats interference as noise (TIN)\nis optimal when the interference is sufficiently low. Scheduling algorithms\nbased on the TIN optimality condition have recently been proposed, e.g., for\napplication to device-to-device communications. TIN, however, has never been\napplied to cellular networks. In this work, we propose a scheduling algorithm\nfor application to cellular networks that is based on the TIN optimality\ncondition. In the proposed scheduling algorithm, each base station (BS) first\nrandomly selects a user equipment (UE) in its coverage region, and then checks\nthe TIN optimality conditions. If the latter conditions are not fulfilled, the\nBS is turned off. In order to assess the performance of TIN applied to cellular\nnetworks, we introduce an analytical framework with the aid of stochastic\ngeometry theory. We develop, in particular, tractable expressions of the\nsignal-to-interference-and-noise ratio (SINR) coverage probability and average\nrate of cellular networks. In addition, we carry out asymptotic analysis to\nfind the optimal system parameters that maximize the SINR coverage probability.\nBy using the optimized system parameters, it is shown that TIN applied to\ncellular networks yields significant gains in terms of SINR coverage\nprobability and average rate. Specifically, the numerical results show that\naverage rate gains of the order of $21\\%$ over conventional scheduling\nalgorithms are obtained. \n\n"}
{"id": "1807.01246", "contents": "Title: The Concatenated Structure of Quasi-Abelian Codes Abstract: The decomposition of a quasi-abelian code into shorter linear codes over\nlarger alphabets was given in (Jitman, Ling, (2015)), extending the analogous\nChinese remainder decomposition of quasi-cyclic codes (Ling, Sol\\'e, (2001)).\nWe give a concatenated decomposition of quasi-abelian codes and show, as in the\nquasi-cyclic case, that the two decompositions are equivalent. The concatenated\ndecomposition allows us to give a general minimum distance bound for\nquasi-abelian codes and to construct some optimal codes. Moreover, we show by\nexamples that the minimum distance bound is sharp in some cases. In addition,\nexamples of large strictly quasi-abelian codes of about a half rate are given.\nThe concatenated structure also enables us to conclude that strictly\nquasi-abelian linear complementary dual codes over any finite field are\nasymptotically good. \n\n"}
{"id": "1807.01251", "contents": "Title: Training behavior of deep neural network in frequency domain Abstract: Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization. \n\n"}
{"id": "1807.02494", "contents": "Title: Joint Channel-Estimation/Decoding with Frequency-Selective Channels and\n  Few-Bit ADCs Abstract: We propose a fast and near-optimal approach to joint channel-estimation,\nequalization, and decoding of coded single-carrier (SC) transmissions over\nfrequency-selective channels with few-bit analog-to-digital converters (ADCs).\nOur approach leverages parametric bilinear generalized approximate message\npassing (PBiGAMP) to reduce the implementation complexity of joint channel\nestimation and (soft) symbol decoding to that of a few fast Fourier transforms\n(FFTs). Furthermore, it learns and exploits sparsity in the channel impulse\nresponse. Our work is motivated by millimeter-wave systems with bandwidths on\nthe order of Gsamples/sec, where few-bit ADCs, SC transmissions, and fast\nprocessing all lead to significant reductions in power consumption and\nimplementation cost. We numerically demonstrate our approach using signals and\nchannels generated according to the IEEE 802.11ad wireless local area network\n(LAN) standard, in the case that the receiver uses analog beamforming and a\nsingle ADC. \n\n"}
{"id": "1807.05718", "contents": "Title: Task Replication for Vehicular Edge Computing: A Combinatorial\n  Multi-Armed Bandit based Approach Abstract: In vehicular edge computing (VEC) system, some vehicles with surplus\ncomputing resources can provide computation task offloading opportunities for\nother vehicles or pedestrians. However, vehicular network is highly dynamic,\nwith fast varying channel states and computation loads. These dynamics are\ndifficult to model or to predict, but they have major impact on the quality of\nservice (QoS) of task offloading, including delay performance and service\nreliability. Meanwhile, the computing resources in VEC are often redundant due\nto the high density of vehicles. To improve the QoS of VEC and exploit the\nabundant computing resources on vehicles, we propose a learning-based task\nreplication algorithm (LTRA) based on combinatorial multi-armed bandit (CMAB)\ntheory, in order to minimize the average offloading delay. LTRA enables\nmultiple vehicles to process the replicas of the same task simultaneously, and\nvehicles that require computing services can learn the delay performance of\nother vehicles while offloading tasks. We take the occurrence time of vehicles\ninto consideration, and redesign the utility function of existing CMAB\nalgorithm, so that LTRA can adapt to the time varying network topology of VEC.\nWe use a realistic highway scenario to evaluate the delay performance and\nservice reliability of LTRA through simulations, and show that compared with\nsingle task offloading, LTRA can improve the task completion ratio with\ndeadline 0.6s from 80% to 98%. \n\n"}
{"id": "1807.06143", "contents": "Title: Quickest Detection of Dynamic Events in Networks Abstract: The problem of quickest detection of dynamic events in networks is studied.\nAt some unknown time, an event occurs, and a number of nodes in the network are\naffected by the event, in that they undergo a change in the statistics of their\nobservations. It is assumed that the event is dynamic, in that it can propagate\nalong the edges in the network, and affect more and more nodes with time. The\nevent propagation dynamics is assumed to be unknown. The goal is to design a\nsequential algorithm that can detect a \"significant\" event, i.e., when the\nevent has affected no fewer than $\\eta$ nodes, as quickly as possible, while\ncontrolling the false alarm rate. Fully connected networks are studied first,\nand the results are then extended to arbitrarily connected networks. The\ndesigned algorithms are shown to be adaptive to the unknown propagation\ndynamics, and their first-order asymptotic optimality is demonstrated as the\nfalse alarm rate goes to zero. The algorithms can be implemented with linear\ncomputational complexity in the network size at each time step, which is\ncritical for online implementation. Numerical simulations are provided to\nvalidate the theoretical results. \n\n"}
{"id": "1807.11190", "contents": "Title: Distributed Stochastic Optimization in Networks with Low Informational\n  Exchange Abstract: We consider a distributed stochastic optimization problem in networks with\nfinite number of nodes. Each node adjusts its action to optimize the global\nutility of the network, which is defined as the sum of local utilities of all\nnodes. Gradient descent method is a common technique to solve the optimization\nproblem, while the computation of the gradient may require much information\nexchange. In this paper, we consider that each node can only have a noisy\nnumerical observation of its local utility, of which the closed-form expression\nis not available. This assumption is quite realistic, especially when the\nsystem is too complicated or constantly changing. Nodes may exchange the\nobservation of their local utilities to estimate the global utility at each\ntimeslot. We propose stochastic perturbation based distributed algorithms under\nthe assumptions whether each node has collected local utilities of all or only\npart of the other nodes. We use tools from stochastic approximation to prove\nthat both algorithms converge to the optimum. The convergence rate of the\nalgorithms is also derived. Although the proposed algorithms can be applied to\ngeneral optimization problems, we perform simulations considering power control\nin wireless networks and present numerical results to corroborate our claim. \n\n"}
{"id": "1807.11250", "contents": "Title: Fast Analog Transmission for High-Mobility Wireless Data Acquisition in\n  Edge Learning Abstract: By implementing machine learning at the network edge, edge learning trains\nmodels by leveraging rich data distributed at edge devices (e.g., smartphones\nand sensors) and in return endow on them capabilities of seeing, listening, and\nreasoning. In edge learning, the need of high-mobility wireless data\nacquisition arises in scenarios where edge devices (or even servers) are\nmounted on the ground or aerial vehicles. In this paper, we present a novel\nsolution, called fast analog transmission (FAT), for high- mobility data\nacquisition in edge-learning systems, which has several key features. First,\nFAT incurs low-latency. Specifically, FAT requires no source-and-channel coding\nand no channel training via the proposed technique of Grassmann analog encoding\n(GAE) that encodes data samples into subspace matrices. Second, FAT supports\nspatial multiplexing by directly transmitting analog vector data over an\nantenna array. Third, FAT can be seamlessly integrated with edge learning\n(i.e., training of a classifier model in this work). In particular, by applying\na Grassmannian-classification algorithm from computer vision, the received GAE\nencoded data can be directly applied to training the model without decoding and\nconversion. This design is found by simulation to outperform conventional\nschemes in learning accuracy due to its robustness against data distortion\ninduced by fast fading. \n\n"}
{"id": "1808.00189", "contents": "Title: Multi-Beam UAV Communication in Cellular Uplink: Cooperative\n  Interference Cancellation and Sum-Rate Maximization Abstract: Integrating unmanned aerial vehicles (UAVs) into the cellular network as new\naerial users is a promising solution to meet their ever-increasing\ncommunication demands in a plethora of applications. Due to the high UAV\naltitude, the channels between UAVs and the ground base stations (GBSs) are\ndominated by the strong line-of-sight (LoS) links, thus severe interference may\nbe generated to/from the GBSs in the uplink/downlink, which renders the\ninterference management with coexisting terrestrial and aerial users a more\nchallenging problem to solve. In this paper, we study the uplink communication\nfrom a multi-antenna UAV to a set of GBSs in its signal coverage region. Among\nthese GBSs, we denote available GBSs as the ones that do not serve any\nterrestrial users at the assigned resource block (RB) of the UAV, and occupied\nGBSs as the rest that are serving their respectively associated terrestrial\nusers in the same RB. We propose a new cooperative interference cancellation\nstrategy for the multi-beam UAV uplink communication, which aims to eliminate\nthe co-channel interference at each of the occupied GBSs and in the meanwhile\nmaximize the sum-rate to the available GBSs. Specifically, the multi-antenna\nUAV sends multiple data streams to selected available GBSs, which in turn\nforward their decoded data streams to their backhaul-connected occupied GBSs\nfor interference cancellation. To draw useful insights, the maximum\ndegrees-of-freedom (DoF) achievable by the multi-beam UAV communication for\nsum-rate maximization in the high signal-to-noise ratio (SNR) regime is first\ncharacterized, subject to the stringent constraint that all the occupied GBSs\ndo not suffer from any interference in the UAV's uplink transmission. Then,\nbased on the DoF-optimal design, the achievable sum-rate at finite SNR is\nmaximized, subject to given maximum allowable interference power constraints at\neach occupied GBS. \n\n"}
{"id": "1808.00519", "contents": "Title: Orthogonal Time Frequency Space Modulation Abstract: This paper introduces a new two-dimensional modulation technique called\nOrthogonal Time Frequency Space (OTFS) modulation. OTFS has the novel and\nimportant feature of being designed in the delay-Doppler domain. When coupled\nwith a suitable equalizer, OTFS modulation is able to exploit the full channel\ndiversity over both time and frequency. Moreover, it converts the fading,\ntime-varying wireless channel experienced by modulated signals such as OFDM\ninto a time-independent channel with a complex channel gain that is essentially\nconstant for all symbols.\n  This design obviates the need for transmitter adaptation, and greatly\nsimplifies system operation. The paper describes the basic operating principles\nof OTFS as well as a possible implementation as an overlay to current or\nanticipated standardized systems. OTFS is shown to provide significant\nperformance improvement in systems with high Doppler, short packets, and/or\nlarge antenna array. In particular, simulation results indicate at least\nseveral dB of block error rate performance improvement for OTFS over OFDM in\nall of these settings. \n\n"}
{"id": "1808.00591", "contents": "Title: Impact of Beam Misalignment on Hybrid Beamforming NOMA for mmWave\n  Communications Abstract: This paper studies hybrid beamforming (HB)-based non-orthogonal multiple\naccess (NOMA) in multiuser millimeter wave (mmWave) communications. HB offers\npower-efficient and low-complexity precoding for downlink multiuser mmWave\nsystems which increases multiplexing gain and spectral efficiency of the\nsystem. Applying NOMA to HB-based systems, called HB-NOMA, can scale the number\nof users while offering a high spectral efficiency. However, an imperfect\ncorrelation between the effective channels of users in each NOMA cluster\nseriously degrades the achievable rate of HB-NOMA. In this paper, first a\nsum-rate maximization problem is formulated for HB-NOMA, and an algorithm is\nproposed to solve it effectively. It is then shown that the relationship\nbetween the effective channels of the users in each NOMA cluster can be\napproximated by a correlation factor. Next, the effect of imperfect correlation\nis analyzed, and a lower bound on the achievable rate of the users is derived\nfor both perfect and imperfect correlation. Finally, the rate gap resulting\nfrom an imperfect correlation is evaluated and a tight upper bound is derived\nfor that. Simulation results show that low correlation degrades the achievable\nrate of users. The lower bounds are tight in the large dimensional regime and\nin single-path channels. \n\n"}
{"id": "1808.03880", "contents": "Title: Parallelization does not Accelerate Convex Optimization: Adaptivity\n  Lower Bounds for Non-smooth Convex Minimization Abstract: In this paper we study the limitations of parallelization in convex\noptimization. A convenient approach to study parallelization is through the\nprism of \\emph{adaptivity} which is an information theoretic measure of the\nparallel runtime of an algorithm [BS18]. Informally, adaptivity is the number\nof sequential rounds an algorithm needs to make when it can execute\npolynomially-many queries in parallel at every round. For combinatorial\noptimization with black-box oracle access, the study of adaptivity has recently\nled to exponential accelerations in parallel runtime and the natural question\nis whether dramatic accelerations are achievable for convex optimization.\n  For the problem of minimizing a non-smooth convex function $f:[0,1]^n\\to\n\\mathbb{R}$ over the unit Euclidean ball, we give a tight lower bound that\nshows that even when $\\texttt{poly}(n)$ queries can be executed in parallel,\nthere is no randomized algorithm with $\\tilde{o}(n^{1/3})$ rounds of adaptivity\nthat has convergence rate that is better than those achievable with a\none-query-per-round algorithm. A similar lower bound was obtained by Nemirovski\n[Nem94], however that result holds for the $\\ell_{\\infty}$-setting instead of\n$\\ell_2$. In addition, we also show a tight lower bound that holds for\nLipschitz and strongly convex functions.\n  At the time of writing this manuscript we were not aware of Nemirovski's\nresult. The construction we use is similar to the one in [Nem94], though our\nanalysis is different. Due to the close relationship between this work and\n[Nem94], we view the research contribution of this manuscript limited and it\nshould serve as an instructful approach to understanding lower bounds for\nparallel optimization. \n\n"}
{"id": "1808.04618", "contents": "Title: On Robustness of Massive MIMO Systems Against Passive Eavesdropping\n  under Antenna Selection Abstract: In massive MIMO wiretap settings, the base station can significantly suppress\neavesdroppers by narrow beamforming toward legitimate terminals. Numerical\ninvestigations show that by this approach, secrecy is obtained at no\nsignificant cost. We call this property of massive MIMO systems `secrecy for\nfree' and show that it not only holds when all the transmit antennas at the\nbase station are employed, but also when only a single antenna is set active.\nUsing linear precoding, the information leakage to the eavesdroppers can be\nsufficiently diminished, when the total number of available transmit antennas\nat the base station grows large, even when only a fixed number of them are\nselected. This result indicates that passive eavesdropping has no significant\nimpact on massive MIMO systems, regardless of the number of active transmit\nantennas. \n\n"}
{"id": "1808.05678", "contents": "Title: Optimization of MIMO Device-to-Device Networks via Matrix Fractional\n  Programming: A Minorization-Maximization Approach Abstract: Interference management is a fundamental issue in device-to-device (D2D)\ncommunications whenever the transmitter-and-receiver pairs are located in close\nproximity and frequencies are fully reused, so active links may severely\ninterfere with each other. This paper devises an optimization strategy named\nFPLinQ to coordinate the link scheduling decisions among the interfering links,\nalong with power control and beamforming. The key enabler is a novel\noptimization method called matrix fractional programming (FP) that generalizes\nprevious scalar and vector forms of FP in allowing multiple data streams per\nlink. From a theoretical perspective, this paper provides a deeper\nunderstanding of FP by showing a connection to the minorization-maximization\n(MM) algorithm. From an application perspective, this paper shows that as\ncompared to the existing methods for coordinating scheduling in the D2D\nnetwork, such as FlashLinQ, ITLinQ, and ITLinQ+, the proposed FPLinQ approach\nis more general in allowing multiple antennas at both the transmitters and the\nreceivers, and further in allowing arbitrary and multiple possible associations\nbetween the devices via matching. Numerical results show that FPLinQ\nsignificantly outperforms the previous state-of-the-art in a typical D2D\ncommunication environment. \n\n"}
{"id": "1808.06148", "contents": "Title: Generalized Bregman and Jensen divergences which include some\n  f-divergences Abstract: In this paper, we introduce new classes of divergences by extending the\ndefinitions of the Bregman divergence and the skew Jensen divergence. These new\ndivergence classes (g-Bregman divergence and skew g-Jensen divergence) satisfy\nsome properties similar to the Bregman or skew Jensen divergence. We show these\ng-divergences include divergences which belong to a class of f-divergence (the\nHellinger distance, the chi-square divergence and the alpha-divergence in\naddition to the Kullback-Leibler divergence). Moreover, we derive an inequality\nbetween the g-Bregman divergence and the skew g-Jensen divergence and show this\ninequality is a generalization of Lin's inequality. \n\n"}
{"id": "1808.07732", "contents": "Title: An Exact Upper Bound on the $L^p$ Lebesgue Constant and The\n  $\\infty$-R\\'enyi Entropy Power Inequality for Integer Valued Random Variables Abstract: In this paper, we proved an exact asymptotically sharp upper bound of the\n$L^p$ Lebesgue Constant (i.e. the $L^p$ norm of Dirichlet kernel) for $p\\ge 2$.\nAs an application, we also verified the implication of a new $\\infty $-R\\'enyi\nentropy power inequality for integer valued random variables. \n\n"}
{"id": "1808.08926", "contents": "Title: Opportunistic Treating Interference as Noise Abstract: We consider a $K$-user interference network with $M$ states, where each\ntransmitter has $M$ messages and over State $m$, Receiver $k$ wishes to decode\nthe first $\\pi_k(m) \\in \\{1,2,\\cdots,M\\}$ messages from its desired\ntransmitter. This problem of channel with states models opportunistic\ncommunications, where more messages are sent for better channel states. The\nfirst message from each transmitter has the highest priority as it is required\nto be decoded regardless of the state of the receiver; the second message is\nopportunistically decoded if the state allows a receiver to decode 2 messages;\nand the $M$-th message has the lowest priority as it is decoded if and only if\nthe receiver wishes to decode all $M$ messages. For this interference network\nwith states, we show that if any possible combination of the channel states\nsatisfies a condition under which power control and treating interference as\nnoise (TIN) are sufficient to achieve the entire generalized degrees of freedom\n(GDoF) region of this channel state by itself, then a simple layered\nsuperposition encoding scheme with power control and a successive decoding\nscheme with TIN achieves the entire GDoF region of the network with $M$ states\nfor all $KM$ messages. \n\n"}
{"id": "1809.00008", "contents": "Title: On $Z_pZ_{p^k}$-additive codes and their duality Abstract: In this paper, two different Gray-like maps from $Z_p^\\alpha\\times\nZ_{p^k}^\\beta$, where $p$ is prime, to $Z_p^n$, $n={\\alpha+\\beta p^{k-1}}$,\ndenoted by $\\phi$ and $\\Phi$, respectively, are presented. We have determined\nthe connection between the weight enumerators among the image codes under these\ntwo mappings. We show that if $C$ is a $Z_p Z_{p^k}$-additive code, and\n$C^\\bot$ is its dual, then the weight enumerators of the image $p$-ary codes\n$\\phi(C)$ and $\\Phi(C^\\bot)$ are formally dual. This is a partial\ngeneralization of [On $Z_{2^k}$-dual binary codes, arXiv:math/0509325], and the\nresult is generalized to odd characteristic $p$ and mixed alphabet.\nAdditionally, a construction of $1$-perfect additive codes in the mixed $Z_p\nZ_{p^2} ... Z_{p^k}$ alphabet is given. \n\n"}
{"id": "1809.03988", "contents": "Title: The $\\epsilon$-error Capacity of Symmetric PIR with Byzantine\n  Adversaries Abstract: The capacity of symmetric private information retrieval with $K$ messages,\n$N$ servers (out of which any $T$ may collude), and an omniscient Byzantine\nadversary (who can corrupt any $B$ answers) is shown to be $1 - \\frac{T+2B}{N}$\n[1], under the requirement of zero probability of error. In this work, we show\nthat by weakening the adversary slightly (either providing secret low rate\nchannels between the servers and the user, or limiting the observation of the\nadversary), and allowing vanishing probability of error, the capacity increases\nto $1 - \\frac{T+B}{N}$. \n\n"}
{"id": "1809.04380", "contents": "Title: Binary MDS Array Codes with Optimal Repair Abstract: Consider a binary maximum distance separable (MDS) array code composed of an\n$m\\times (k+r)$ array of bits with $k$ information columns and $r$ parity\ncolumns, such that any $k$ out of $k+r$ columns suffice to reconstruct the $k$\ninformation columns. Our goal is to provide {\\em optimal repair access} for\nbinary MDS array codes, meaning that the bandwidth triggered to repair any\nsingle failed information or parity column is minimized. In this paper, we\npropose a generic transformation framework for binary MDS array codes, using\nEVENODD codes as a motivating example, to support optimal repair access for\n$k+1\\le d \\le k+r-1$, where $d$ denotes the number of non-failed columns that\nare connected for repair; note that when $d<k+r-1$, some of the chosen $d$\ncolumns in repairing a failed column are specific. In addition, we show how our\ntransformation framework applies to an example of binary MDS array codes with\nasymptotically optimal repair access of any single information column and\nenables asymptotically or exactly optimal repair access for any column.\nFurthermore, we present a new transformation for EVENODD codes with two parity\ncolumns such that the existing efficient repair property of any information\ncolumn is preserved and the repair access of parity column is optimal. \n\n"}
{"id": "1809.05515", "contents": "Title: A Statistical Learning Approach to Ultra-Reliable Low Latency\n  Communication Abstract: Mission-critical applications require Ultra-Reliable Low Latency (URLLC)\nwireless connections, where the packet error rate (PER) goes down to $10^{-9}$.\nFulfillment of the bold reliability figures becomes meaningful only if it can\nbe related to a statistical model in which the URLLC system operates. However,\nthis model is generally not known and needs to be learned by sampling the\nwireless environment. In this paper we treat this fundamental problem in the\nsimplest possible communication-theoretic setting: selecting a transmission\nrate over a dynamic wireless channel in order to guarantee high transmission\nreliability. We introduce a novel statistical framework for design and\nassessment of URLLC systems, consisting of three key components: (i) channel\nmodel selection; (ii) learning the model using training; (3) selecting the\ntransmission rate to satisfy the required reliability. As it is insufficient to\nspecify the URLLC requirements only through PER, two types of statistical\nconstraints are introduced, Averaged Reliability (AR) and Probably Correct\nReliability (PCR). The analysis and the evaluations show that adequate model\nselection and learning are indispensable for designing consistent physical\nlayer that asymptotically behaves as if the channel was known perfectly, while\nmaintaining the reliability requirements in URLLC systems. \n\n"}
{"id": "1809.07104", "contents": "Title: One-shot Capacity bounds on the Simultaneous Transmission of Classical\n  and Quantum Information Abstract: We study the communication capabilities of a quantum channel under the most\ngeneral channel model known as the one-shot model. Unlike classical channels\nthat can only be used to transmit classical information (bits), a quantum\nchannel can be used for transmission of classical information, quantum\ninformation (qubits) and simultaneous transmission of classical and quantum\ninformation. In this work, we investigate the one-shot capabilities of a\nquantum channel for simultaneously transmitting of bits and qubits. This\nproblem was studied in the asymptotic regime for a memoryless channel and a\nregularized characterization of the capacity region was reported. It is known\nthat the transmission of private classical information is closely related to\nthe problem of quantum information transmission. We resort to this idea and\nfind achievable and converse bounds on the simultaneous transmission of the\npublic and private classical information. then by shifting the classical\nprivate rate to the quantum information rate, the obtained rate regions will be\ntranslated into rate regions of thThis in turn, leads to a rate region for\nsimulttaneous transmission of classical and quantum information. In the case of\nasymptotic i.i.d. setting, our one-shot result is evaluated to the known\nresults in the literature. Our main tools used in the achievability proofs are\nposition-based decoding and convex-split lemma. \n\n"}
{"id": "1809.08365", "contents": "Title: A Unified Framework for the Tractable Analysis of Multi-Antenna Wireless\n  Networks Abstract: Densifying networks and deploying more antennas at each access point are two\nprincipal ways to boost the capacity of wireless networks. However, the\ncomplicated distributions of the signal power and the accumulated interference\npower, largely induced by various space-time processing techniques, make it\nhighly challenging to quantitatively characterize the performance of\nmulti-antenna networks. In this paper, using tools from stochastic geometry, a\nunified framework is developed for the analysis of such networks. The major\nresults are two innovative representations of the coverage probability, which\nmake the analysis of multi-antenna networks almost as tractable as the\nsingle-antenna case. One is expressed as an $\\ell_1$-induced norm of a Toeplitz\nmatrix, and the other is given in a finite sum form. With a compact\nrepresentation, the former incorporates many existing analytical results on\nsingle- and multi-antenna networks as special cases, and leads to tractable\nexpressions for evaluating the coverage probability in both ad hoc and cellular\nnetworks. While the latter is more complicated for numerical evaluation, it\nhelps analytically gain key design insights. In particular, it helps prove that\nthe coverage probability of ad hoc networks is a monotonically decreasing\nconvex function of the transmitter density and that there exists a peak value\nof the coverage improvement when increasing the number of transmit antennas. On\nthe other hand, in multi-antenna cellular networks, it is shown that the\ncoverage probability is independent of the transmitter density and that the\noutage probability decreases exponentially as the number of transmit antennas\nincreases. \n\n"}
{"id": "1809.08438", "contents": "Title: Trusted Multi-Party Computation and Verifiable Simulations: A Scalable\n  Blockchain Approach Abstract: Large-scale computational experiments, often running over weeks and over\nlarge datasets, are used extensively in fields such as epidemiology,\nmeteorology, computational biology, and healthcare to understand phenomena, and\ndesign high-stakes policies affecting everyday health and economy. For\ninstance, the OpenMalaria framework is a computationally-intensive simulation\nused by various non-governmental and governmental agencies to understand\nmalarial disease spread and effectiveness of intervention strategies, and\nsubsequently design healthcare policies. Given that such shared results form\nthe basis of inferences drawn, technological solutions designed, and day-to-day\npolicies drafted, it is essential that the computations are validated and\ntrusted. In particular, in a multi-agent environment involving several\nindependent computing agents, a notion of trust in results generated by peers\nis critical in facilitating transparency, accountability, and collaboration.\nUsing a novel combination of distributed validation of atomic computation\nblocks and a blockchain-based immutable audits mechanism, this work proposes a\nuniversal framework for distributed trust in computations. In particular we\naddress the scalaibility problem by reducing the storage and communication\ncosts using a lossy compression scheme. This framework guarantees not only\nverifiability of final results, but also the validity of local computations,\nand its cost-benefit tradeoffs are studied using a synthetic example of\ntraining a neural network. \n\n"}
{"id": "1809.09231", "contents": "Title: Tunable Measures for Information Leakage and Applications to\n  Privacy-Utility Tradeoffs Abstract: We introduce a tunable measure for information leakage called maximal\nalpha-leakage. This measure quantifies the maximal gain of an adversary in\ninferring any (potentially random) function of a dataset from a release of the\ndata. The inferential capability of the adversary is, in turn, quantified by a\nclass of adversarial loss functions that we introduce as $\\alpha$-loss,\n$\\alpha\\in[1,\\infty]$. The choice of $\\alpha$ determines the specific\nadversarial action and ranges from refining a belief (about any function of the\ndata) for $\\alpha=1$ to guessing the most likely value for $\\alpha=\\infty$\nwhile refining the $\\alpha^{th}$ moment of the belief for $\\alpha$ in between.\nMaximal alpha-leakage then quantifies the adversarial gain under $\\alpha$-loss\nover all possible functions of the data. In particular, for the extremal values\nof $\\alpha=1$ and $\\alpha=\\infty$, maximal alpha-leakage simplifies to mutual\ninformation and maximal leakage, respectively. For $\\alpha\\in(1,\\infty)$ this\nmeasure is shown to be the Arimoto channel capacity of order $\\alpha$. We show\nthat maximal alpha-leakage satisfies data processing inequalities and a\nsub-additivity property thereby allowing for a weak composition result.\nBuilding upon these properties, we use maximal alpha-leakage as the privacy\nmeasure and study the problem of data publishing with privacy guarantees,\nwherein the utility of the released data is ensured via a hard distortion\nconstraint. Unlike average distortion, hard distortion provides a deterministic\nguarantee of fidelity. We show that under a hard distortion constraint, for\n$\\alpha>1$ the optimal mechanism is independent of $\\alpha$, and therefore, the\nresulting optimal tradeoff is the same for all values of $\\alpha>1$. Finally,\nthe tunability of maximal alpha-leakage as a privacy measure is also\nillustrated for binary data with average Hamming distortion as the utility\nmeasure. \n\n"}
{"id": "1809.09237", "contents": "Title: Nonconvex Robust Low-rank Matrix Recovery Abstract: In this paper we study the problem of recovering a low-rank matrix from a\nnumber of random linear measurements that are corrupted by outliers taking\narbitrary values. We consider a nonsmooth nonconvex formulation of the problem,\nin which we explicitly enforce the low-rank property of the solution by using a\nfactored representation of the matrix variable and employ an $\\ell_1$-loss\nfunction to robustify the solution against outliers. We show that even when a\nconstant fraction (which can be up to almost half) of the measurements are\narbitrarily corrupted, as long as certain measurement operators arising from\nthe measurement model satisfy the so-called $\\ell_1/\\ell_2$-restricted isometry\nproperty, the ground-truth matrix can be exactly recovered from any global\nminimum of the resulting optimization problem. Furthermore, we show that the\nobjective function of the optimization problem is sharp and weakly convex.\nConsequently, a subgradient Method (SubGM) with geometrically diminishing step\nsizes will converge linearly to the ground-truth matrix when suitably\ninitialized. We demonstrate the efficacy of the SubGM for the nonconvex robust\nlow-rank matrix recovery problem with various numerical experiments. \n\n"}
{"id": "1809.09748", "contents": "Title: Tight Limits on Nonlocality from Nontrivial Communication Complexity;\n  a.k.a. Reliable Computation with Asymmetric Gate Noise Abstract: It has long been known that the existence of certain superquantum nonlocal\ncorrelations would cause communication complexity to collapse. The absurdity of\na world in which any nonlocal binary function could be evaluated with a\nconstant amount of communication in turn provides a tantalizing way to\ndistinguish quantum mechanics from incorrect theories of physics; the statement\n\"communication complexity is nontrivial\" has even been conjectured to be a\nconcise information-theoretic axiom for characterizing quantum mechanics. We\ndirectly address the viability of that perspective with two results. First, we\nexhibit a nonlocal game such that communication complexity collapses in any\nphysical theory whose maximal winning probability exceeds the quantum value.\nSecond, we consider the venerable CHSH game that initiated this line of\ninquiry. In that case, the quantum value is about 0.85 but it is known that a\nwinning probability of approximately 0.91 would collapse communication\ncomplexity. We provide evidence that the 0.91 result is the best possible using\na large class of proof strategies, suggesting that the communication complexity\naxiom is insufficient for characterizing CHSH correlations. Both results build\non new insights about reliable classical computation. The first exploits our\nformalization of an equivalence between amplification and reliable computation,\nwhile the second follows from an upper bound on the threshold for reliable\ncomputation with formulas of noisy XOR and AND gates. \n\n"}
{"id": "1810.00276", "contents": "Title: Wireless Powered Cooperative Relaying using NOMA with Imperfect CSI Abstract: The impact of imperfect channel state (CSI) information in an energy\nharvesting (EH) cooperative non-orthogonal multiple access (NOMA) network,\nconsisting of a source, two users, and an EH relay is investigated in this\npaper. The relay is not equipped with a fixed power source and acts as a\nwireless powered node to help signal transmission to the users. Closed-form\nexpressions for the outage probability of both users are derived under\nimperfect CSI for two different power allocation strategies namely fixed and\ndynamic power allocation. Monte Carlo simulations are used to numerically\nevaluate the effect of imperfect CSI. These results confirm the theoretical\noutage analysis and show that NOMA can outperform orthogonal multiple access\neven with imperfect CSI. \n\n"}
{"id": "1810.00295", "contents": "Title: On Exact and $\\infty$-R\\'enyi Common Informations Abstract: Recently, two extensions of Wyner's common information\\textemdash exact and\nR\\'enyi common informations\\textemdash were introduced respectively by Kumar,\nLi, and El Gamal (KLE), and the present authors. The class of common\ninformation problems involves determining the minimum rate of the common input\nto two independent processors needed to exactly or approximately generate a\ntarget joint distribution. For the exact common information problem, exact\ngeneration of the target distribution is required, while for Wyner's and\n$\\alpha$-R\\'enyi common informations, the relative entropy and R\\'enyi\ndivergence with order $\\alpha$ were respectively used to quantify the\ndiscrepancy between the synthesized and target distributions. The exact common\ninformation is larger than or equal to Wyner's common information. However, it\nwas hitherto unknown whether the former is strictly larger than the latter for\nsome joint distributions. In this paper, we first establish the equivalence\nbetween the exact and $\\infty$-R\\'enyi common informations, and then provide\nsingle-letter upper and lower bounds for these two quantities. For doubly\nsymmetric binary sources, we show that the upper and lower bounds coincide,\nwhich implies that for such sources, the exact and $\\infty$-R\\'enyi common\ninformations are completely characterized. Interestingly, we observe that for\nsuch sources, these two common informations are strictly larger than Wyner's.\nThis answers an open problem posed by KLE. Furthermore, we extend Wyner's,\n$\\infty$-R\\'enyi, and exact common informations to sources with countably\ninfinite or continuous alphabets, including Gaussian sources. \n\n"}
{"id": "1810.00298", "contents": "Title: Zero-Delay Rate Distortion via Filtering for Vector-Valued Gaussian\n  Sources Abstract: We deal with zero-delay source coding of a vector-valued Gauss-Markov source\nsubject to a mean-squared error (MSE) fidelity criterion characterized by the\noperational zero-delay vector-valued Gaussian rate distortion function (RDF).\nWe address this problem by considering the nonanticipative RDF (NRDF) which is\na lower bound to the causal optimal performance theoretically attainable (OPTA)\nfunction and operational zero-delay RDF. We recall the realization that\ncorresponds to the optimal \"test-channel\" of the Gaussian NRDF, when\nconsidering a vector Gauss-Markov source subject to a MSE distortion in the\nfinite time horizon. Then, we introduce sufficient conditions to show existence\nof solution for this problem in the infinite time horizon. For the asymptotic\nregime, we use the asymptotic characterization of the Gaussian NRDF to provide\na new equivalent realization scheme with feedback which is characterized by a\nresource allocation (reverse-waterfilling) problem across the dimension of the\nvector source. We leverage the new realization to derive a predictive coding\nscheme via lattice quantization with subtractive dither and joint memoryless\nentropy coding. This coding scheme offers an upper bound to the operational\nzero-delay vector-valued Gaussian RDF. When we use scalar quantization, then\nfor \"r\" active dimensions of the vector Gauss-Markov source the gap between the\nobtained lower and theoretical upper bounds is less than or equal to 0.254r + 1\nbits/vector. We further show that it is possible when we use vector\nquantization, and assume infinite dimensional Gauss-Markov sources to make the\nprevious gap to be negligible, i.e., Gaussian NRDF approximates the operational\nzero-delay Gaussian RDF. We also extend our results to vector-valued Gaussian\nsources of any finite memory under mild conditions. Our theoretical framework\nis demonstrated with illustrative numerical experiments. \n\n"}
{"id": "1810.00774", "contents": "Title: Geometric Constellation Shaping for Fiber Optic Communication Systems\n  via End-to-end Learning Abstract: In this paper, an unsupervised machine learning method for geometric\nconstellation shaping is investigated. By embedding a differentiable fiber\nchannel model within two neural networks, the learning algorithm is optimizing\nfor a geometric constellation shape. The learned constellations yield improved\nperformance to state-of-the-art geometrically shaped constellations, and\ninclude an implicit trade-off between amplification noise and nonlinear\neffects. Further, the method allows joint optimization of system parameters,\nsuch as the optimal launch power, simultaneously with the constellation shape.\nAn experimental demonstration validates the findings. Improved performances are\nreported, up to 0.13 bit/4D in simulation and experimentally up to 0.12 bit/4D. \n\n"}
{"id": "1810.03427", "contents": "Title: Distributed Hypothesis Testing with Collaborative Detection Abstract: A detection system with a single sensor and two detectors is considered,\nwhere each of the terminals observes a memoryless source sequence, the sensor\nsends a message to both detectors and the first detector sends a message to the\nsecond detector. Communication of these messages is assumed to be error-free\nbut rate-limited. The joint probability mass function (pmf) of the source\nsequences observed at the three terminals depends on an $\\mathsf{M}$-ary\nhypothesis $(\\mathsf{M} \\geq 2)$, and the goal of the communication is that\neach detector can guess the underlying hypothesis. Detector $k$, $k=1,2$, aims\nto maximize the error exponent \\textit{under hypothesis} $i_k$, $i_k \\in\n\\{1,\\ldots,\\mathsf{M}\\}$, while ensuring a small probability of error under all\nother hypotheses. We study this problem in the case in which the detectors aim\nto maximize their error exponents under the \\textit{same} hypothesis (i.e.,\n$i_1=i_2$) and in the case in which they aim to maximize their error exponents\nunder \\textit{distinct} hypotheses (i.e., $i_1 \\neq i_2$). For the setting in\nwhich $i_1=i_2$, we present an achievable exponents region for the case of\npositive communication rates, and show that it is optimal for a specific case\nof testing against independence. We also characterize the optimal exponents\nregion in the case of zero communication rates. For the setting in which $i_1\n\\neq i_2$, we characterize the optimal exponents region in the case of zero\ncommunication rates. \n\n"}
{"id": "1810.06938", "contents": "Title: Wireless Access in Ultra-Reliable Low-Latency Communication (URLLC) Abstract: The future connectivity landscape and, notably, the 5G wireless systems will\nfeature Ultra-Reliable Low Latency Communication (URLLC). The coupling of high\nreliability and low latency requirements in URLLC use cases makes the wireless\naccess design very challenging, in terms of both the protocol design and of the\nassociated transmission techniques. This paper aims to provide a broad\nperspective on the fundamental tradeoffs in URLLC as well as the principles\nused in building access protocols. Two specific technologies are considered in\nthe context of URLLC: massive MIMO and multi-connectivity, also termed\ninterface diversity. The paper also touches upon the important question of the\nproper statistical methodology for designing and assessing extremely high\nreliability levels. \n\n"}
{"id": "1810.07014", "contents": "Title: Bregman Divergence Bounds and Universality Properties of the Logarithmic\n  Loss Abstract: A loss function measures the discrepancy between the true values and their\nestimated fits, for a given instance of data. In classification problems, a\nloss function is said to be proper if a minimizer of the expected loss is the\ntrue underlying probability. We show that for binary classification, the\ndivergence associated with smooth, proper, and convex loss functions is upper\nbounded by the Kullback-Leibler (KL) divergence, to within a normalization\nconstant. This implies that by minimizing the logarithmic loss associated with\nthe KL divergence, we minimize an upper bound to any choice of loss from this\nset. As such the logarithmic loss is universal in the sense of providing\nperformance guarantees with respect to a broad class of accuracy measures.\nImportantly, this notion of universality is not problem-specific, enabling its\nuse in diverse applications, including predictive modeling, data clustering and\nsample complexity analysis. Generalizations to arbitrary finite alphabets are\nalso developed. The derived inequalities extend several well-known\n$f$-divergence results. \n\n"}
{"id": "1810.08718", "contents": "Title: Testing Randomness in Quantum Mechanics Abstract: Pseudo-random number generators are widely used in many branches of science,\nmainly in applications related to Monte Carlo methods, although they are\ndeterministic in design and, therefore, unsuitable for tackling fundamental\nproblems in security and cryptography. The natural laws of the microscopic\nrealm provide a fairly simple method to generate non-deterministic sequences of\nrandom numbers, based on measurements of quantum states. In practice, however,\nthe experimental devices on which quantum random number generators are based\nare often unable to pass some tests of randomness. In this review, we briefly\ndiscuss two such tests, point out the challenges that we have encountered and\nfinally present a fairly simple method that successfully generates\nnon-deterministic maximally random sequences. \n\n"}
{"id": "1810.11831", "contents": "Title: Latency-Reliability Tradeoffs for State Estimation Abstract: The emerging interest in low-latency high-reliability applications, such as\nconnected vehicles, necessitates a new abstraction between communication and\ncontrol. Thanks to advances in cyber-physical systems over the past decades, we\nunderstand this interface for classical bit-rate models of channels as well as\npacket-loss-type channels. This work proposes a new abstraction characterized\nas a tradeoff curve between latency, reliability and rate. Our aim is to\nunderstand: Do we (control engineers) prefer faster but less reliable\ncommunications (with shorter codes), or slower but more reliable communications\n(with longer codes)? In this paper we examine the tradeoffs between latency and\nreliability for the problem of estimating dynamical systems over communication\nchannels. Employing different latency-reliability curves derived from practical\ncoding schemes, we develop a co-design methodology, i.e., select the code\nlength depending on the system dynamics to optimize system performance. \n\n"}
{"id": "1810.12983", "contents": "Title: Sleeping Multi-Armed Bandit Learning for Fast Uplink Grant Allocation in\n  Machine Type Communications Abstract: Scheduling fast uplink grant transmissions for machine type communications\n(MTCs) is one of the main challenges of future wireless systems. In this paper,\na novel fast uplink grant scheduling method based on the theory of multi-armed\nbandits (MABs) is proposed. First, a single quality-of-service metric is\ndefined as a combination of the value of data packets, maximum tolerable access\ndelay, and data rate. Since full knowledge of these metrics for all machine\ntype devices (MTDs) cannot be known in advance at the base station (BS) and the\nset of active MTDs changes over time, the problem is modeled as a sleeping MAB\nwith stochastic availability and a stochastic reward function. In particular,\ngiven that, at each time step, the knowledge on the set of active MTDs is\nprobabilistic, a novel probabilistic sleeping MAB algorithm is proposed to\nmaximize the defined metric. Analysis of the regret is presented and the effect\nof the prediction error of the source traffic prediction algorithm on the\nperformance of the proposed sleeping MAB algorithm is investigated. Moreover,\nto enable fast uplink allocation for multiple MTDs at each time, a novel method\nis proposed based on the concept of best arms ordering in the MAB setting.\nSimulation results show that the proposed framework yields a three-fold\nreduction in latency compared to a random scheduling policy since it\nprioritises the scheduling of MTDs that have stricter latency requirements.\nMoreover, by properly balancing the exploration versus exploitation tradeoff,\nthe proposed algorithm can provide system fairness by allowing the most\nimportant MTDs to be scheduled more often while also allowing the less\nimportant MTDs to be selected enough times to ensure the accuracy of estimation\nof their importance. \n\n"}
{"id": "1811.03918", "contents": "Title: On Conditional Correlations Abstract: The Pearson correlation, correlation ratio, and maximal correlation have been\nwell-studied in the literature. In this paper, we study the conditional\nversions of these quantities. We extend the most important properties of the\nunconditional versions to the conditional versions, and also derive some new\nproperties. Based on the conditional maximal correlation, we define an\ninformation-correlation function of two arbitrary random variables, and use it\nto derive an impossibility result for the problem of the non-interactive\nsimulation of random variables. \n\n"}
{"id": "1811.03946", "contents": "Title: Broadcasting on Random Directed Acyclic Graphs Abstract: We study a generalization of the well-known model of broadcasting on trees.\nConsider a directed acyclic graph (DAG) with a unique source vertex $X$, and\nsuppose all other vertices have indegree $d\\geq 2$. Let the vertices at\ndistance $k$ from $X$ be called layer $k$. At layer $0$, $X$ is given a random\nbit. At layer $k\\geq 1$, each vertex receives $d$ bits from its parents in\nlayer $k-1$, which are transmitted along independent binary symmetric channel\nedges, and combines them using a $d$-ary Boolean processing function. The goal\nis to reconstruct $X$ with probability of error bounded away from $1/2$ using\nthe values of all vertices at an arbitrarily deep layer. This question is\nclosely related to models of reliable computation and storage, and information\nflow in biological networks.\n  In this paper, we analyze randomly constructed DAGs, for which we show that\nbroadcasting is only possible if the noise level is below a certain degree and\nfunction dependent critical threshold. For $d\\geq 3$, and random DAGs with\nlayer sizes $\\Omega(\\log k)$ and majority processing functions, we identify the\ncritical threshold. For $d=2$, we establish a similar result for NAND\nprocessing functions. We also prove a partial converse for odd $d\\geq 3$\nillustrating that the identified thresholds are impossible to improve by\nselecting different processing functions if the decoder is restricted to using\na single vertex.\n  Finally, for any noise level, we construct explicit DAGs (using expander\ngraphs) with bounded degree and layer sizes $\\Theta(\\log k)$ admitting\nreconstruction. In particular, we show that such DAGs can be generated in\ndeterministic quasi-polynomial time or randomized polylogarithmic time in the\ndepth. These results portray a doubly-exponential advantage for storing a bit\nin DAGs compared to trees, where $d=1$ but layer sizes must grow exponentially\nwith depth in order to enable broadcasting. \n\n"}
{"id": "1811.04218", "contents": "Title: Properties of Noncommutative Renyi and Augustin Information Abstract: R\\'enyi and Augustin information are generalizations of mutual information\ndefined via the R\\'enyi divergence, playing a significant role in evaluating\nthe performance of information processing tasks by virtue of its connection to\nthe error exponent analysis. In quantum information theory, there are three\ngeneralizations of the classical R\\'enyi divergence -- the Petz's, sandwiched,\nand log-Euclidean versions, that possess meaningful operational interpretation.\nHowever, the associated quantum R\\'enyi and Augustin information are much less\nexplored compared with their classical counterpart, and lacking crucial\nproperties hinders applications of these quantities to error exponent analysis\nin the quantum regime. The goal of this paper is to analyze fundamental\nproperties of the R\\'enyi and Augustin information from a noncommutative\nmeasure-theoretic perspective. Firstly, we prove the uniform equicontinuity for\nall three quantum versions of R\\'enyi and Augustin information, and it hence\nyields the joint continuity of these quantities in order and prior input\ndistributions. Secondly, we establish the concavity of the scaled R\\'enyi and\nAugustin information in the region of $s\\in(-1,0)$ for both Petz's and the\nsandwiched versions. This completes the open questions raised by Holevo [IEEE\nTrans.~Inf.~Theory, 46(6):2256--2261, 2000], and Mosonyi and Ogawa\n[Commun.~Math.~Phys., 355(1):373--426, 2017]. For the applications, we show\nthat the strong converse exponent in classical-quantum channel coding satisfies\na minimax identity, which means that the strong converse exponent can be\nattained by the best constant composition code. The established concavity is\nfurther employed to prove an entropic duality between classical data\ncompression with quantum side information and classical-quantum channel coding,\nand a Fenchel duality in joint source-channel coding with quantum side\ninformation. \n\n"}
{"id": "1811.09652", "contents": "Title: Generalised Entropies and Metric-Invariant Optimal Countermeasures for\n  Information Leakage under Symmetric Constraints Abstract: We introduce a novel generalization of entropy and conditional entropy from\nwhich most definitions from the literature can be derived as particular cases.\nWithin this general framework, we investigate the problem of designing\ncountermeasures for information leakage. In particular, we seek\nmetric-invariant solutions, i.e., they are robust against the choice of entropy\nfor quantifying the leakage. The problem can be modelled as an information\nchannel from the system to an adversary, and the countermeasures can be seen as\nmodifying this channel in order to minimise the amount of information that the\noutputs reveal about the inputs. Our main result is to fully solve the problem\nunder the highly symmetrical design constraint that the number of inputs that\ncan produce the same output is capped. Our proof is constructive and the\noptimal channels and the minimum leakage are derived in closed form. \n\n"}
{"id": "1811.09695", "contents": "Title: Multilevel-Coded Pulse-Position Modulation for Covert Communications\n  over Binary-Input Discrete Memoryless Channels Abstract: We develop a low-complexity coding scheme to achieve covert communications\nover binary-input discrete memoryless channels (BI-DMCs). We circumvent the\nimpossibility of covert communication with linear codes by introducing\nnon-linearity through the use of pulse position modulation (PPM) and multilevel\ncoding (MLC). We show that the MLC-PPM scheme exhibits many appealing\nproperties; in particular, the channel at a given index level remains\nstationary as the number of level increases, which allows one to use families\nof channel capacity- and channel resolvability-achieving codes to concretely\ninstantiate the covert communication scheme. \n\n"}
{"id": "1811.09923", "contents": "Title: Average-Case Information Complexity of Learning Abstract: How many bits of information are revealed by a learning algorithm for a\nconcept class of VC-dimension $d$? Previous works have shown that even for\n$d=1$ the amount of information may be unbounded (tend to $\\infty$ with the\nuniverse size). Can it be that all concepts in the class require leaking a\nlarge amount of information? We show that typically concepts do not require\nleakage. There exists a proper learning algorithm that reveals $O(d)$ bits of\ninformation for most concepts in the class. This result is a special case of a\nmore general phenomenon we explore. If there is a low information learner when\nthe algorithm {\\em knows} the underlying distribution on inputs, then there is\na learner that reveals little information on an average concept {\\em without\nknowing} the distribution on inputs. \n\n"}
{"id": "1811.10315", "contents": "Title: Investigation of Nonlinear Communication Channel with Small Dispersion\n  via Stochastic Correlator Approach Abstract: We consider the optical fiber channel modelled by the nonlinear\nSchr\\\"{o}dinger equation with additive white Gaussian noise and with large\nsignal-to-noise ratio. For the small dispersion case we present the approach to\nanalyze the stochastic nonlinear Schr\\\"{o}dinger equation. Taking into account\nthe averaging procedure (frequency filtering) of the output signal detector we\nfind the first corrections in small dispersion parameter to the correlators of\nthe input signal recovered by the backward propagation. These correlators are\nthe important ingredients for the calculation of the channel capacity and the\noptimal input signal distribution. We assert that the information channel\ncharacteristics essentially depend on the procedures of the output signal\nfiltering and the recovery of the transmitted signal. \n\n"}
{"id": "1811.12606", "contents": "Title: Millimeter Wave Systems for Wireless Cellular Communications Abstract: This thesis considers channel estimation and multiuser (MU) data transmission\nfor massive MIMO systems with fully digital/hybrid structures in mmWave\nchannels. It contains three main contributions. In this thesis, we first\npropose a tone-based linear search algorithm to facilitate the estimation of\nangle-of-arrivals of the strongest components as well as scattering components\nof the users at the base station (BS) with fully digital structure. Our results\nshow that the proposed maximum-ratio transmission (MRT) based on the strongest\ncomponents can achieve a higher data rate than that of the conventional MRT,\nunder the same mean squared errors (MSE). Second, we develop a low-complexity\nchannel estimation and beamformer/precoder design scheme for hybrid mmWave\nsystems. In addition, the proposed scheme applies to both non-sparse and sparse\nmmWave channel environments. We then leverage the proposed scheme to\ninvestigate the downlink achievable rate performance. The results show that the\nproposed scheme obtains a considerable achievable rate of fully digital\nsystems. Taking into account the effect of various types of errors, we\ninvestigate the achievable rate performance degradation of the considered\nscheme. Third, we extend our proposed scheme to a multi-cell MU mmWave MIMO\nnetwork. We derive the closed-form approximation of the normalized MSE of\nchannel estimation under pilot contamination over Rician fading channels.\nFurthermore, we derive a tight closed-form approximation and the scaling law of\nthe average achievable rate. Our results unveil that channel estimation errors,\nthe intra-cell interference, and the inter-cell interference caused by pilot\ncontamination over Rician fading channels can be efficiently mitigated by\nsimply increasing the number of antennas equipped at the desired BS. \n\n"}
{"id": "1812.00752", "contents": "Title: Sharma-Mittal Quantum Discord Abstract: We demonstrate a generalization of quantum discord using a generalized\ndefinition of von-Neumann entropy, which is Sharma-Mittal entropy; and the new\ndefinition of discord is called Sharma-Mittal quantum discord. Its analytic\nexpressions are worked out for two qubit quantum states as well as Werner,\nisotropic, and pointer states as special cases. The R{\\'e}nyi, Tsallis, and\nvon-Neumann entropy based quantum discords can be expressed as limiting cases\nfor of Sharma-Mittal quantum discord. We also numerically compare all these\ndiscords and entanglement negativity. \n\n"}
{"id": "1812.00819", "contents": "Title: Fast and Reliable Initial Access with Random Beamforming for mmWave\n  Networks Abstract: Millimeter-wave (mmWave) communications rely on directional transmissions to\novercome severe path loss. Nevertheless, the use of narrow beams complicates\nthe initial access procedure and increase the latency as the transmitter and\nreceiver beams should be aligned for a proper link establishment. In this\npaper, we investigate the feasibility of random beamforming for the cell-search\nphase of initial access. We develop a stochastic geometry framework to analyze\nthe performance in terms of detection failure probability and expected latency\nof initial access as well as total data transmission. Meanwhile, we compare our\nscheme with the widely used exhaustive search and iterative search schemes, in\nboth control plane and data plane. Our numerical results show that, compared to\nthe other two schemes, random beamforming can substantially reduce the latency\nof initial access with comparable failure probability in dense networks. We\nshow that the gain of the random beamforming is more prominent in light\ntraffics and low-latency services. Our work demonstrates that developing\ncomplex cell-discovery algorithms may be unnecessary in dense mmWave networks\nand thus shed new lights on mmWave network design. \n\n"}
{"id": "1812.02936", "contents": "Title: Coding over Sets for DNA Storage Abstract: In this paper we study error-correcting codes for the storage of data in\nsynthetic deoxyribonucleic acid (DNA). We investigate a storage model where a\ndata set is represented by an unordered set of $M$ sequences, each of length\n$L$. Errors within that model are a loss of whole sequences and point errors\ninside the sequences, such as insertions, deletions and substitutions. We\nderive Gilbert-Varshamov lower bounds and sphere packing upper bounds on\nachievable cardinalities of error-correcting codes within this storage model.\nWe further propose explicit code constructions than can correct errors in such\na storage system that can be encoded and decoded efficiently. Comparing the\nsizes of these codes to the upper bounds, we show that many of the\nconstructions are close to optimal. \n\n"}
{"id": "1812.06411", "contents": "Title: Coded Elastic Computing Abstract: Cloud providers have recently introduced new offerings whereby spare\ncomputing resources are accessible at discounts compared to on-demand\ncomputing. Exploiting such opportunity is challenging inasmuch as such\nresources are accessed with low-priority and therefore can elastically leave\n(through preemption) and join the computation at any time. In this paper, we\ndesign a new technique called coded elastic computing, enabling distributed\ncomputations over elastic resources. The proposed technique allows machines to\nleave the computation without sacrificing the algorithm-level performance, and,\nat the same time, adaptively reduce the workload at existing machines when new\nones join the computation. Leveraging coded redundancy, our approach can\nachieve similar computational cost as the original (noiseless) method when all\nmachines are present; the cost gracefully increases when machines are preempted\nand reduces when machines join. The performance of the proposed technique is\nevaluated on matrix-vector multiplication and linear regression tasks. In\nexperimental validations, it can achieve exactly the same numerical result as\nthe noiseless computation, while reducing the computation time by 46% when\ncompared to non-adaptive coding schemes. \n\n"}
{"id": "1812.06885", "contents": "Title: Optimizing Throughput Performance in Distributed MIMO Wi-Fi Networks\n  using Deep Reinforcement Learning Abstract: This paper explores the feasibility of leveraging concepts from deep\nreinforcement learning (DRL) to enable dynamic resource management in Wi-Fi\nnetworks implementing distributed multi-user MIMO (D-MIMO). D-MIMO is a\ntechnique by which a set of wireless access points are synchronized and grouped\ntogether to jointly serve multiple users simultaneously. This paper addresses\ntwo dynamic resource management problems pertaining to D-MIMO Wi-Fi networks:\n(i) channel assignment of D-MIMO groups, and (ii) deciding how to cluster\naccess points to form D-MIMO groups, in order to maximize user throughput\nperformance. These problems are known to be NP-Hard and only heuristic\nsolutions exist in literature. We construct a DRL framework through which a\nlearning agent interacts with a D-MIMO Wi-Fi network, learns about the network\nenvironment, and is successful in converging to policies which address the\naforementioned problems. Through extensive simulations and on-line training\nbased on D-MIMO Wi-Fi networks, this paper demonstrates the efficacy of DRL in\nachieving an improvement of 20% in user throughput performance compared to\nheuristic solutions, particularly when network conditions are dynamic. This\nwork also showcases the effectiveness of DRL in meeting multiple network\nobjectives simultaneously, for instance, maximizing throughput of users as well\nas fairness of throughput among them. \n\n"}
{"id": "1812.11942", "contents": "Title: On Optimal Locally Repairable Codes with Super-Linear Length Abstract: Locally repairable codes which are optimal with respect to the bound\npresented by Prakash et al. are considered. New upper bounds on the length of\nsuch optimal codes are derived. The new bounds both improve and generalize\npreviously known bounds. Optimal codes are constructed, whose length is\norder-optimal when compared with the new upper bounds. The length of the codes\nis super-linear in the alphabet size. \n\n"}
{"id": "1901.00798", "contents": "Title: Scalable Information-Flow Analysis of Secure Three-Party Affine\n  Computations Abstract: Elaborate protocols in Secure Multi-party Computation enable several\nparticipants to compute a public function of their own private inputs while\nensuring that no undesired information leaks about the private inputs, and\nwithout resorting to any trusted third party. However, the public output of the\ncomputation inevitably leaks some information about the private inputs. Recent\nworks have introduced a framework and proposed some techniques for quantifying\nsuch information flow. Yet, owing to their complexity, those methods do not\nscale to practical situations that may involve large input spaces. The main\ncontribution of the work reported here is to formally investigate the\ninformation flow captured by the min-entropy in the particular case of secure\nthree-party computations of affine functions in order to make its\nquantification scalable to realistic scenarios. To this end, we mathematically\nderive an explicit formula for this entropy under uniform prior beliefs about\nthe inputs. We show that this closed-form expression can be computed in time\nconstant in the inputs sizes and logarithmic in the coefficients of the affine\nfunction. Finally, we formulate some theoretical bounds for this privacy leak\nin the presence of non-uniform prior beliefs. \n\n"}
{"id": "1901.00963", "contents": "Title: Integrating Sub-6 GHz and Millimeter Wave to Combat Blockage:\n  Delay-Optimal Scheduling Abstract: Millimeter wave (mmWave) technologies have the potential to achieve very high\ndata rates, but suffer from intermittent connectivity. In this paper, we\nprovision an architecture to integrate sub-6 GHz and mmWave technologies, where\nwe incorporate the sub-6 GHz interface as a fallback data transfer mechanism to\ncombat blockage and intermittent connectivity of the mmWave communications. To\nthis end, we investigate the problem of scheduling data packets across the\nmmWave and sub-6 GHz interfaces such that the average delay of system is\nminimized. This problem can be formulated as Markov Decision Process. We first\ninvestigate the problem of discounted delay minimization, and prove that the\noptimal policy is of the threshold-type, i.e., data packets should always be\nrouted to the mmWave interface as long as the number of packets in the system\nis smaller than a threshold. Then, we show that the results of the discounted\ndelay problem hold for the average delay problem as well. Through numerical\nresults, we demonstrate that under heavy traffic, integrating sub-6 GHz with\nmmWave can reduce the average delay by up to 70%. Further, our scheduling\npolicy substantially reduces the delay over the celebrated MaxWeight policy. \n\n"}
{"id": "1901.05096", "contents": "Title: Status from a Random Field: How Densely Should One Update? Abstract: In many applications, status information of a general spatial process, in\ncontrast to a point information source, is of interest. In this paper, we\nconsider a system where status information is drawn from a random field and\ntransmitted to a fusion center through a wireless multiaccess channel. The\noptimal density of spatial sampling points to minimize the remote status\nestimation error is investigated. Assuming a one-dimensional Gauss Markov\nrandom field and an exponential correlation function, closed-form expressions\nof remote estimation error are obtained for First-Come First-Served (FCFS) and\nLast-Come First-Served (LCFS) service disciplines. The optimal spatial sampling\ndensity for the LCFS case is given explicitly. Simulation results are presented\nwhich agree with our analysis. \n\n"}
{"id": "1901.05428", "contents": "Title: Relative Age of Information: A New Metric for Status Update Systems Abstract: In this paper, we introduce a new data freshness metric, relative Age of\nInformation (rAoI), and examine it in a single server system with various\npacket management schemes. The (classical) AoI metric was introduced to measure\nthe staleness of status updates at the receiving end with respect to their\ngeneration at the source. This metric addresses systems where the timings of\nupdate generation at the source are absolute and can be designed separately or\njointly with the transmission schedules. In many decentralized applications,\ntransmission schedules are blind to update generation timing, and the\ntransmitter can know the timing of an update packet only after it arrives. As\nsuch, an update becomes stale after a new one arrives. The rAoI metric measures\nhow fresh the data is at the receiver with respect to the data at the\ntransmitter. It introduces a particularly explicit dependence on the arrival\nprocess in the evaluation of age. We investigate several queuing disciplines\nand provide closed form expressions for rAoI and numerical comparisons. \n\n"}
{"id": "1901.05732", "contents": "Title: On Coded Caching with Correlated Files Abstract: This paper studies the fundamental limits of the shared-link coded caching\nproblem with correlated files, where a server with a library of $N$ files\ncommunicates with $K$ users who can locally cache $M$ files. Given an integer\n$r \\in [N]$, correlation is modeled as follows: each r-subset of files contains\na unique common block. The tradeoff between the cache size and the average\ntransmitted load is considered. First, a converse bound under the constraint of\nuncoded cache placement (i.e., each user directly stores a subset of the\nlibrary bits) is derived. Then, a caching scheme for the case where every user\ndemands a distinct file (possible for $N \\geq K$) is shown to be optimal under\nthe constraint of uncoded cache placement. This caching scheme is further\nproved to be decodable and optimal under the constraint of uncoded cache\nplacement when (i) $KrM \\leq 2N$ or $KrM \\geq (K - 1)N $or $r \\in \\{1,2,N-\n1,N\\}$ for every demand type (i.e., when the demanded file are not necessarily\ndistinct), and (ii) when the number of distinct demanded files is no larger\nthan four. Finally, a two-phase delivery scheme based on interference alignment\nis shown to be optimal to within a factor of 2 under the constraint of uncoded\ncache placement for every possible demands. As a by-product, the proposed\ninterference alignment scheme is shown to reduce the (worst-case or average)\nload of state-of-the-art schemes for the coded caching problem where the users\ncan request multiple files. \n\n"}
{"id": "1901.05778", "contents": "Title: Joint Source-Channel Coding for the Multiple-Access Channel with\n  Correlated Sources Abstract: This paper studies the random-coding exponent of joint source-channel coding\nfor the multiple-access channel with correlated sources. For each user, by\ndefining a threshold, the messages of each source are partitioned into two\nclasses. The achievable exponent for correlated sources with two\nmessage-dependent input distributions for each user is determined and shown to\nbe larger than that achieved using only one input distribution for each user. A\nsystem of equations is presented to determine the optimal thresholds maximizing\nthe achievable exponent. The obtained exponent is compared with the one derived\nfor the MAC with independent sources. \n\n"}
{"id": "1901.06010", "contents": "Title: Degrees of Freedom Region of the $(M,N_1,N_2)$ MIMO Broadcast Channel\n  with Partial CSIT: An Application of Sum-set Inequalities Based on Aligned\n  Image Sets Abstract: The degrees of freedom (DoF) region is characterized for the $2$-user\nmultiple input multiple output (MIMO) broadcast channel (BC), where the\ntransmitter is equipped with $M$ antennas, the two receivers are equipped with\n$N_1$ and $N_2$ antennas, and the levels of channel state information at the\ntransmitter (CSIT) for the two users are parameterized by $\\beta_1, \\beta_2$,\nrespectively. The achievability of the DoF region was established by Hao,\nRassouli and Clerckx, but no proof of optimality was heretofore available. The\nproof of optimality is provided in this work with the aid of sum-set\ninequalities based on the aligned image sets (AIS) approach. \n\n"}
{"id": "1901.06878", "contents": "Title: Polarization-ring-switching for nonlinearity-tolerant\n  geometrically-shaped four-dimensional formats maximizing generalized mutual\n  information Abstract: In this paper, a new four-dimensional 64-ary polarization ring switching\n(4D-64PRS) modulation format with a spectral efficiency of 6 bit/4D-sym is\nintroduced. The format is designed by maximizing the generalized mutual\ninformation (GMI) and by imposing a constant-modulus on the 4D structure. The\nproposed format yields an improved performance with respect to state-of-the-art\ngeometrically shaped modulation formats for bit-interleaved coded modulation\nsystems at the same spectral efficiency. Unlike previously published results,\nthe coordinates of the constellation points and the binary labeling of the\nconstellation are jointly optimized. When compared with\npolarization-multiplexed 8-ary quadrature-amplitude modulation (PM-8QAM), gains\nof up to 0.7 dB in signal-to-noise ratio are observed in the additive white\nGaussian noise (AWGN) channel. For a long-haul nonlinear optical fiber system\nof 8,000 km, gains of up to 0.27 bit/4D-sym (5.5% data capacity increase) are\nobserved. These gains translate into a reach increase of approximately 16%\n(1,100 km). The proposed modulation format is also shown to be more tolerant to\nnonlinearities than PM-8QAM. Results with LDPC codes are also presented, which\nconfirm the gains predicted by the GMI. \n\n"}
{"id": "1901.07013", "contents": "Title: Achievable Rates of Attack Detection Strategies in Echo-Assisted\n  Communication Abstract: We consider an echo-assisted communication model wherein block-coded\nmessages, when transmitted across several frames, reach the destination as\nmultiple noisy copies. We address adversarial attacks on such models wherein a\nsubset of the noisy copies are vulnerable to manipulation by an adversary.\nParticularly, we study a non-persistent attack model with the adversary\nattacking 50% of the frames on the vulnerable copies in an i.i.d. fashion. We\nshow that this adversarial model drives the destination to detect the attack\nlocally within every frame, thereby resulting in degraded performance due to\nfalse-positives and miss-detection. Our main objective is to characterize the\nmutual information of this adversarial echo-assisted channel by incorporating\nthe performance of attack-detection strategies. With the use of an imperfect\ndetector, we show that the compound channel comprising the adversarial\necho-assisted channel and the attack detector exhibits memory-property, and as\na result, obtaining closed-form expressions on mutual information is\nintractable. To circumvent this problem, we present a new framework to\napproximate the mutual information by deriving sufficient conditions on the\nchannel parameters and also the performance of the attack detectors. Finally,\nwe propose two attack-detectors, which are inspired by traditional as well as\nneural-network ideas, and show that the mutual information offered by these\ndetectors is close to that of the Genie detector for short frame-lengths. \n\n"}
{"id": "1901.07069", "contents": "Title: Minimum Age of Information in the Internet of Things with Non-uniform\n  Status Packet Sizes Abstract: In this paper, a real-time Internet of Things (IoT) monitoring system is\nconsidered in which the IoT devices are scheduled to sample underlying physical\nprocesses and send the status updates to a common destination. In a real-world\nIoT, due to the possibly different dynamics of each physical process, the sizes\nof the status updates for different devices are often different and each status\nupdate typically requires multiple transmission slots. By taking into account\nsuch multi-time slot transmissions with non-uniform sizes of the status updates\nunder noisy channels, the problem of joint device scheduling and status\nsampling is studied in order to minimize the average age of information (AoI)\nat the destination. This stochastic problem is formulated as an infinite\nhorizon average cost Markov decision process (MDP). The monotonicity of the\nvalue function of the MDP is characterized and then used to show that the\noptimal scheduling and sampling policy is threshold-based with respect to the\nAoI at each device. To overcome the curse of dimensionality, a low-complexity\nsuboptimal policy is proposed through a semi-randomized base policy and linear\napproximated value functions. The proposed suboptimal policy is shown to\nexhibit a similar structure to the optimal policy, which provides a structural\nbase for its effective performance. A structure-aware algorithm is then\ndeveloped to obtain the suboptimal policy. The analytical results are further\nextended to the IoT monitoring system with random status update arrivals, for\nwhich, the optimal scheduling and sampling policy is also shown to be\nthreshold-based with the AoI at each device. Simulation results illustrate the\nstructures of the optimal policy and show a near-optimal AoI performance\nresulting from the proposed suboptimal solution approach. \n\n"}
{"id": "1901.07303", "contents": "Title: Hybrid Precoder Design for Cache-enabled Millimeter Wave Radio Access\n  Networks Abstract: In this paper, we study the design of a hybrid precoder, consisting of an\nanalog and a digital precoder, for the delivery phase of downlink cache-enabled\nmillimeter wave (mmWave) radio access networks (CeMm-RANs). In CeMm-RANs,\nenhanced remote radio heads (eRRHs), which are equipped with local cache and\nbaseband signal processing capabilities in addition to the basic\nfunctionalities of conventional RRHs, are connected to the baseband processing\nunit via fronthaul links. Two different fronthaul information transfer\nstrategies are considered, namely, hard fronthaul information transfer, where\nhard information of uncached requested files is transmitted via the fronthaul\nlinks to a subset of eRRHs, and soft fronthaul information transfer, where the\nfronthaul links are used to transmit quantized baseband signals of uncached\nrequested files. The hybrid precoder is optimized for maximization of the\nminimum user rate under a fronthaul capacity constraint, an eRRH transmit power\nconstraint, and a constant-modulus constraint on the analog precoder. The\nresulting optimization problem is non-convex, and hence the global optimal\nsolution is difficult to obtain. Therefore, convex approximation methods are\nemployed to tackle the non-convexity of the achievable user rate, the fronthaul\ncapacity constraint, and the constant modulus constraint on the analog\nprecoder. Then, an effective algorithm with provable convergence is developed\nto solve the approximated optimization problem. Simulation results are provided\nto evaluate the performance of the proposed algorithms, where fully digital\nprecoding is used as benchmark. The results reveal that except for the case of\na large fronthaul link capacity, soft fronthaul information transfer is\npreferable for CeMm-RANs. \n\n"}
{"id": "1901.07769", "contents": "Title: Bit Flipping Moment Balancing Schemes for Insertion, Deletion and\n  Substitution Error Correction Abstract: In this paper, two moment balancing schemes, namely a variable index scheme\nand a fixed index scheme, for either single insertion/deletion error correction\nor multiple substitution error correction are introduced for coded sequences\noriginally developed for correcting substitution errors only. By judiciously\nflipping bits of the original substitution error correcting code word, the\nresulting word is able to correct either a reduced number of substitution\nerrors or a single insertion/deletion error. The number of flips introduced by\nthe two schemes can be kept small compared to the code length. It shows a\npractical value of applying the schemes to a long substitution error correcting\ncode for a severe channel where substitution errors dominate but\ninsertion/deletion errors can occur with a low probability. The new schemes can\nbe more easily implemented in an existing coding system than any previously\npublished moment balancing templates since no additional parity bits are\nrequired which also means the code rate remains same and the existing\nsubstitution error correcting decoder requires no changes. Moreover, the work\nextends the class of Levenshtein codes capable of correcting either single\nsubstitution or single insertion/deletion errors to codes capable of correcting\neither multiple substitution errors or single insertion/deletion error. \n\n"}
{"id": "1901.09308", "contents": "Title: Energy-Efficient Resource Allocation for Secure UAV Communication\n  Systems Abstract: In this paper, we study the resource allocation and trajectory design for\nenergy-efficient secure unmanned aerial vehicle (UAV) communication systems\nwhere a UAV base station serves multiple legitimate ground users in the\nexistence of a potential eavesdropper. We aim to maximize the energy efficiency\nof the UAV by jointly optimizing its transmit power, user scheduling,\ntrajectory, and velocity. The design is formulated as a non-convex optimization\nproblem taking into account the maximum tolerable signal-to-noise ratio (SNR)\nleakage, the minimum data rate requirement of each user, and the location\nuncertainty of the eavesdropper. An iterative algorithm is proposed to obtain\nan efficient suboptimal solution. Simulation results demonstrate that the\nproposed algorithm can achieve a significant improvement of the system energy\nefficiency while satisfying communication security constraint, compared to some\nsimple scheme adopting straight flight trajectory with a constant speed. \n\n"}
{"id": "1901.09339", "contents": "Title: Heterogeneity-aware Gradient Coding for Straggler Tolerance Abstract: Gradient descent algorithms are widely used in machine learning. In order to\ndeal with huge volume of data, we consider the implementation of gradient\ndescent algorithms in a distributed computing setting where multiple workers\ncompute the gradient over some partial data and the master node aggregates\ntheir results to obtain the gradient over the whole data. However, its\nperformance can be severely affected by straggler workers. Recently, some\ncoding-based approaches are introduced to mitigate the straggler problem, but\nthey are efficient only when the workers are homogeneous, i.e., having the same\ncomputation capabilities. In this paper, we consider that the workers are\nheterogeneous which are common in modern distributed systems. We propose a\nnovel heterogeneity-aware gradient coding scheme which can not only tolerate a\npredetermined number of stragglers but also fully utilize the computation\ncapabilities of heterogeneous workers. We show that this scheme is optimal when\nthe computation capabilities of workers are estimated accurately. A variant of\nthis scheme is further proposed to improve the performance when the estimations\nof the computation capabilities are not so accurate. We conduct our schemes for\ngradient descent based image classification on QingCloud clusters. Evaluation\nresults show that our schemes can reduce the whole computation time by up to\n$3\\times$ compared with a state-of-the-art coding scheme. \n\n"}
{"id": "1901.09738", "contents": "Title: Bandwidth Gain from Mobile Edge Computing and Caching in Wireless\n  Multicast Systems Abstract: In this paper, we present a novel mobile edge computing (MEC) model where the\nMEC server has the input and output data of all computation tasks and\ncommunicates with multiple caching-and-computing-enabled mobile devices via a\nshared wireless link. Each task request can be served from local output\ncaching, local computing with input caching, local computing or MEC computing,\neach of which incurs a unique bandwidth requirement of the multicast link.\nAiming to minimize the transmission bandwidth, we design and optimize the local\ncaching and computing policy at mobile devices subject to latency, caching,\nenergy and multicast transmission constraints. The joint policy optimization\nproblem is shown to be NP-hard. When the output data size is smaller than the\ninput data size, we reformulate the problem as minimization of a monotone\nsubmodular function over matroid constraints and obtain the optimal solution\nvia a strongly polynomial algorithm of Schrijver. On the other hand, when the\noutput data size is larger than the input data size, by leveraging sample\napproximation and concave convex procedure together with the alternating\ndirection method of multipliers, we propose a low-complexity high-performance\nalgorithm and prove it converges to a stationary point. Furthermore, we\ntheoretically reveal how much bandwidth gain can be achieved from computing and\ncaching resources at mobile devices or the multicast transmission for symmetric\ncase. Our results indicate that exploiting the computing and caching resources\nat mobile devices as well as multicast transmission can provide significant\nbandwidth savings. \n\n"}
{"id": "1901.09901", "contents": "Title: Asymptotic Performance Analysis of Generalized User Selection for\n  Interference-Limited Multiuser Secondary Networks Abstract: We analyze the asymptotic performance of a generalized multiuser diversity\nscheme for an interference-limited secondary multiuser network of underlay\ncognitive radio systems. Assuming a large number of secondary users and that\nthe noise at each secondary user's receiver is negligible compared to the\ninterference from the primary transmitter, the secondary transmitter transmits\ninformation to the $k$-th best secondary user, namely, the one with the $k$-th\nhighest signal-to-interference ratio (SIR). We use extreme value theory to show\nthat the $k$-th highest SIR converges uniformly in distribution to an inverse\ngamma random variable for a fixed $k$ and large number of secondary users. We\nuse this result to derive asymptotic expressions for the average throughput,\neffective throughput, average bit error rate and outage probability of the\n$k$-th best secondary user under continuous power adaptation at the secondary\ntransmitter, which ensures satisfaction of the instantaneous interference\nconstraint at the primary receiver caused by the secondary transmitter.\nNumerical simulations show that our derived asymptotic expressions are accurate\nfor different values of system parameters. \n\n"}
{"id": "cond-mat/0701218", "contents": "Title: Generalized Statistics Framework for Rate Distortion Theory with Bregman\n  Divergences Abstract: A variational principle for the rate distortion (RD) theory with Bregman\ndivergences is formulated within the ambit of the generalized (nonextensive)\nstatistics of Tsallis. The Tsallis-Bregman RD lower bound is established.\nAlternate minimization schemes for the generalized Bregman RD (GBRD) theory are\nderived. A computational strategy to implement the GBRD model is presented. The\nefficacy of the GBRD model is exemplified with the aid of numerical\nsimulations. \n\n"}
{"id": "cs/0503064", "contents": "Title: Minimum-Cost Multicast over Coded Packet Networks Abstract: We consider the problem of establishing minimum-cost multicast connections\nover coded packet networks, i.e. packet networks where the contents of outgoing\npackets are arbitrary, causal functions of the contents of received packets. We\nconsider both wireline and wireless packet networks as well as both static\nmulticast (where membership of the multicast group remains constant for the\nduration of the connection) and dynamic multicast (where membership of the\nmulticast group changes in time, with nodes joining and leaving the group).\n  For static multicast, we reduce the problem to a polynomial-time solvable\noptimization problem, and we present decentralized algorithms for solving it.\nThese algorithms, when coupled with existing decentralized schemes for\nconstructing network codes, yield a fully decentralized approach for achieving\nminimum-cost multicast. By contrast, establishing minimum-cost static multicast\nconnections over routed packet networks is a very difficult problem even using\ncentralized computation, except in the special cases of unicast and broadcast\nconnections.\n  For dynamic multicast, we reduce the problem to a dynamic programming problem\nand apply the theory of dynamic programming to suggest how it may be solved. \n\n"}
{"id": "cs/0503089", "contents": "Title: Second order asymptotics in fixed-length source coding and intrinsic\n  randomness Abstract: Second order asymptotics of fixed-length source coding and intrinsic\nrandomness is discussed with a constant error constraint. There was a\ndifference between optimal rates of fixed-length source coding and intrinsic\nrandomness, which never occurred in the first order asymptotics. In addition,\nthe relation between uniform distribution and compressed data is discussed\nbased on this fact. These results are valid for general information sources as\nwell as independent and identical distributions. A universal code attaining the\nsecond order optimal rate is also constructed. \n\n"}
{"id": "cs/0605067", "contents": "Title: Efficient Operation of Coded Packet Networks Abstract: A fundamental problem faced in the design of almost all packet networks is\nthat of efficient operation--of reliably communicating given messages among\nnodes at minimum cost in resource usage. We present a solution to the efficient\noperation problem for coded packet networks, i.e., packet networks where the\ncontents of outgoing packets are arbitrary, causal functions of the contents of\nreceived packets. Such networks are in contrast to conventional, routed packet\nnetworks, where outgoing packets are restricted to being copies of received\npackets and where reliability is provided by the use of retransmissions.\n  This thesis introduces four considerations to coded packet networks: 1.\nefficiency, 2. the lack of synchronization in packet networks, 3. the\npossibility of broadcast links, and 4. packet loss. We take these\nconsiderations and give a prescription for operation that is novel and general,\nyet simple, useful, and extensible. \n\n"}
{"id": "cs/0607099", "contents": "Title: Degrees of Freedom Region for the MIMO X Channel Abstract: We provide achievability as well as converse results for the degrees of\nfreedom region of a MIMO $X$ channel, i.e., a system with two transmitters, two\nreceivers, each equipped with multiple antennas, where independent messages\nneed to be conveyed over fixed channels from each transmitter to each receiver.\nWith M=1 antennas at each node, we find that the total (sum rate) degrees of\nfreedom are bounded above and below as $1 \\leq\\eta_X^\\star \\leq {4/3}$. If\n$M>1$ and channel matrices are non-degenerate then the precise degrees of\nfreedom $\\eta_X^\\star = {4/3}M$. Simple zero forcing without dirty paper\nencoding or successive decoding, suffices to achieve the ${4/3}M$ degrees of\nfreedom. With equal number of antennas at all nodes, we explore the increase in\ndegrees of freedom when some of the messages are made available to a\ntransmitter or receiver in the manner of cognitive radio. With a cognitive\ntransmitter we show that the number of degrees of freedom $\\eta = {3/2}M$ (for\n$M>1$) on the MIMO $X$ channel. The same degrees of freedom are obtained on the\nMIMO $X$ channel with a cognitive receiver as well. In contrast to the $X$\nchannel result, we show that for the MIMO \\emph{interference} channel, the\ndegrees of freedom are not increased even if both the transmitter and the\nreceiver of one user know the other user's message. However, the interference\nchannel can achieve the full $2M$ degrees of freedom if \\emph{each} user has\neither a cognitive transmitter or a cognitive receiver. Lastly, if the channels\nvary with time/frequency then the $X$ channel with single antennas $(M=1)$ at\nall nodes has exactly 4/3 degrees of freedom with no shared messages and\nexactly 3/2 degrees of freedom with a cognitive transmitter or a cognitive\nreceiver. \n\n"}
{"id": "cs/0608018", "contents": "Title: The single-serving channel capacity Abstract: In this paper we provide the answer to the following question: Given a noisy\nchannel and epsilon>0, how many bits can be transmitted with an error of at\nmost epsilon by a single use of the channel? \n\n"}
{"id": "cs/0610021", "contents": "Title: On the Fading Paper Achievable Region of the Fading MIMO Broadcast\n  Channel Abstract: We consider transmission over the ergodic fading multi-antenna broadcast\n(MIMO-BC) channel with partial channel state information at the transmitter and\nfull information at the receiver. Over the equivalent {\\it non}-fading channel,\ncapacity has recently been shown to be achievable using transmission schemes\nthat were designed for the ``dirty paper'' channel. We focus on a similar\n``fading paper'' model. The evaluation of the fading paper capacity is\ndifficult to obtain. We confine ourselves to the {\\it linear-assignment}\ncapacity, which we define, and use convex analysis methods to prove that its\nmaximizing distribution is Gaussian. We compare our fading-paper transmission\nto an application of dirty paper coding that ignores the partial state\ninformation and assumes the channel is fixed at the average fade. We show that\na gain is easily achieved by appropriately exploiting the information. We also\nconsider a cooperative upper bound on the sum-rate capacity as suggested by\nSato. We present a numeric example that indicates that our scheme is capable of\nrealizing much of this upper bound. \n\n"}
{"id": "cs/0610047", "contents": "Title: Capacity of the Trapdoor Channel with Feedback Abstract: We establish that the feedback capacity of the trapdoor channel is the\nlogarithm of the golden ratio and provide a simple communication scheme that\nachieves capacity. As part of the analysis, we formulate a class of dynamic\nprograms that characterize capacities of unifilar finite-state channels. The\ntrapdoor channel is an instance that admits a simple analytic solution. \n\n"}
{"id": "cs/0610160", "contents": "Title: A Non-Orthogonal Distributed Space-Time Coded Protocol Part II-Code\n  Construction and DM-G Tradeoff Abstract: This is the second part of a two-part series of papers. In this paper, for\nthe generalized non-orthogonal amplify and forward (GNAF) protocol presented in\nPart-I, a construction of a new family of distributed space-time codes based on\nCo-ordinate Interleaved Orthogonal Designs (CIOD) which result in reduced\nMaximum Likelihood (ML) decoding complexity at the destination is proposed.\nFurther, it is established that the recently proposed Toeplitz space-time codes\nas well as space-time block codes (STBCs) from cyclic division algebras can be\nused in GNAF protocol. Finally, a lower bound on the optimal\nDiversity-Multiplexing Gain (DM-G) tradeoff for the GNAF protocol is\nestablished and it is shown that this bound approaches the transmit diversity\nbound asymptotically as the number of relays and the number of channels uses\nincreases. \n\n"}
{"id": "cs/0701120", "contents": "Title: Algorithmic Complexity Bounds on Future Prediction Errors Abstract: We bound the future loss when predicting any (computably) stochastic sequence\nonline. Solomonoff finitely bounded the total deviation of his universal\npredictor $M$ from the true distribution $mu$ by the algorithmic complexity of\n$mu$. Here we assume we are at a time $t>1$ and already observed $x=x_1...x_t$.\nWe bound the future prediction performance on $x_{t+1}x_{t+2}...$ by a new\nvariant of algorithmic complexity of $mu$ given $x$, plus the complexity of the\nrandomness deficiency of $x$. The new complexity is monotone in its condition\nin the sense that this complexity can only decrease if the condition is\nprolonged. We also briefly discuss potential generalizations to Bayesian model\nclasses and to classification problems. \n\n"}
{"id": "cs/0701123", "contents": "Title: Feasible Depth Abstract: This paper introduces two complexity-theoretic formulations of Bennett's\nlogical depth: finite-state depth and polynomial-time depth. It is shown that\nfor both formulations, trivial and random infinite sequences are shallow, and a\nslow growth law holds, implying that deep sequences cannot be created easily\nfrom shallow sequences. Furthermore, the E analogue of the halting language is\nshown to be polynomial-time deep, by proving a more general result: every\nlanguage to which a nonnegligible subset of E can be reduced in uniform\nexponential time is polynomial-time deep. \n\n"}
{"id": "cs/0702059", "contents": "Title: Redundancy-Related Bounds on Generalized Huffman Codes Abstract: This paper presents new lower and upper bounds for the compression rate of\nbinary prefix codes optimized over memoryless sources according to various\nnonlinear codeword length objectives. Like the most well-known redundancy\nbounds for minimum average redundancy coding - Huffman coding - these are in\nterms of a form of entropy and/or the probability of an input symbol, often the\nmost probable one. The bounds here, some of which are tight, improve on known\nbounds of the form L in [H,H+1), where H is some form of entropy in bits (or,\nin the case of redundancy objectives, 0) and L is the length objective, also in\nbits. The objectives explored here include exponential-average length, maximum\npointwise redundancy, and exponential-average pointwise redundancy (also called\ndth exponential redundancy). The first of these relates to various problems\ninvolving queueing, uncertainty, and lossless communications; the second\nrelates to problems involving Shannon coding and universal modeling. For these\ntwo objectives we also explore the related problem of the necessary and\nsufficient conditions for the shortest codeword of a code being a specific\nlength. \n\n"}
{"id": "cs/0702130", "contents": "Title: Syndrome Decoding of Reed-Solomon Codes Beyond Half the Minimum Distance\n  based on Shift-Register Synthesis Abstract: In this paper, a new approach for decoding low-rate Reed-Solomon codes beyond\nhalf the minimum distance is considered and analyzed. Unlike the Sudan\nalgorithm published in 1997, this new approach is based on multi-sequence\nshift-register synthesis, which makes it easy to understand and simple to\nimplement. The computational complexity of this shift-register based algorithm\nis of the same order as the complexity of the well-known Berlekamp-Massey\nalgorithm. Moreover, the error correcting radius coincides with the error\ncorrecting radius of the original Sudan algorithm, and the practical decoding\nperformance observed on a q-ary symmetric channel (QSC) is virtually identical\nto the decoding performance of the Sudan algorithm. Bounds for the failure and\nerror probability as well as for the QSC decoding performance of the new\nalgorithm are derived, and the performance is illustrated by means of examples. \n\n"}
{"id": "math/0401045", "contents": "Title: Unitary Space Time Constellation Analysis: An Upper Bound for the\n  Diversity Abstract: The diversity product and the diversity sum are two very important parameters\nfor a good-performing unitary space time constellation. A basic question is\nwhat the maximal diversity product (or sum) is. In this paper we are going to\nderive general upper bounds on the diversity sum and the diversity product for\nunitary constellations of any dimension $n$ and any size $m$ using packing\ntechniques on the compact Lie group U(n). \n\n"}
{"id": "math/0509325", "contents": "Title: On $Z_{2^k}$-Dual Binary Codes Abstract: A new generalization of the Gray map is introduced. The new generalization\n$\\Phi: Z_{2^k}^n \\to Z_{2}^{2^{k-1}n}$ is connected with the known generalized\nGray map $\\phi$ in the following way: if we take two dual linear\n$Z_{2^k}$-codes and construct binary codes from them using the generalizations\n$\\phi$ and $\\Phi$ of the Gray map, then the weight enumerators of the binary\ncodes obtained will satisfy the MacWilliams identity. The classes of\n$Z_{2^k}$-linear Hadamard codes and co-$Z_{2^k}$-linear extended 1-perfect\ncodes are described, where co-$Z_{2^k}$-linearity means that the code can be\nobtained from a linear $Z_{2^k}$-code with the help of the new generalized Gray\nmap. Keywords: Gray map, Hadamard codes, MacWilliams identity, perfect codes,\n$Z_{2^k}$-linearity \n\n"}
