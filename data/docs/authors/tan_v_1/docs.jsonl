{"id": "0706.3752", "contents": "Title: Secure Nested Codes for Type II Wiretap Channels Abstract: This paper considers the problem of secure coding design for a type II\nwiretap channel, where the main channel is noiseless and the eavesdropper\nchannel is a general binary-input symmetric-output memoryless channel. The\nproposed secure error-correcting code has a nested code structure. Two secure\nnested coding schemes are studied for a type II Gaussian wiretap channel. The\nnesting is based on cosets of a good code sequence for the first scheme and on\ncosets of the dual of a good code sequence for the second scheme. In each case,\nthe corresponding achievable rate-equivocation pair is derived based on the\nthreshold behavior of good code sequences. The two secure coding schemes\ntogether establish an achievable rate-equivocation region, which almost covers\nthe secrecy capacity-equivocation region in this case study. The proposed\nsecure coding scheme is extended to a type II binary symmetric wiretap channel.\nA new achievable perfect secrecy rate, which improves upon the previously\nreported result by Thangaraj et al., is derived for this channel. \n\n"}
{"id": "0707.1489", "contents": "Title: Is there an eta-3He quasi--bound state ? Abstract: The observed variation of the total cross section for the dp -> 3He eta\nreaction near threshold means that the magnitude of the s--wave amplitude falls\nvery rapidly with the eta centre--of--mass momentum. It is shown here that\nrecent measurements of the momentum dependence of the angular distribution\nimply a strong variation also in the phase of this amplitude. Such a behaviour\nis that expected from a quasi--bound or virtual eta-3He state. The\ninterpretation can be investigated further through measurements of the deuteron\nor proton analysing powers and/or spin--correlations. \n\n"}
{"id": "0708.1076", "contents": "Title: Early evolution of transversally thermalized partons Abstract: The idea that the parton system created in relativistic heavy-ion collisions\n(i) emerges in a state with transverse momenta close to thermodynamic\nequilibrium and (ii) its evolution at early times is dominated by the\n2-dimensional (transverse) hydrodynamics of the ideal fluid is investigated. It\nis argued that this mechanism may help to solve the problem of early\nequilibration. \n\n"}
{"id": "0708.1859", "contents": "Title: Multiple-Description Coding by Dithered Delta-Sigma Quantization Abstract: We address the connection between the multiple-description (MD) problem and\nDelta-Sigma quantization. The inherent redundancy due to oversampling in\nDelta-Sigma quantization, and the simple linear-additive noise model resulting\nfrom dithered lattice quantization, allow us to construct a symmetric and\ntime-invariant MD coding scheme. We show that the use of a noise shaping filter\nmakes it possible to trade off central distortion for side distortion.\nAsymptotically as the dimension of the lattice vector quantizer and order of\nthe noise shaping filter approach infinity, the entropy rate of the dithered\nDelta-Sigma quantization scheme approaches the symmetric two-channel MD\nrate-distortion function for a memoryless Gaussian source and MSE fidelity\ncriterion, at any side-to-central distortion ratio and any resolution. In the\noptimal scheme, the infinite-order noise shaping filter must be minimum phase\nand have a piece-wise flat power spectrum with a single jump discontinuity. An\nimportant advantage of the proposed design is that it is symmetric in rate and\ndistortion by construction, so the coding rates of the descriptions are\nidentical and there is therefore no need for source splitting. \n\n"}
{"id": "0708.3699", "contents": "Title: Convolutional Entanglement Distillation Abstract: We develop a theory of entanglement distillation that exploits a\nconvolutional coding structure. We provide a method for converting an arbitrary\nclassical binary or quaternary convolutional code into a convolutional\nentanglement distillation protocol. The imported classical convolutional code\ndoes not have to be dual-containing or self-orthogonal. The yield and\nerror-correcting properties of such a protocol depend respectively on the rate\nand error-correcting properties of the imported classical convolutional code. A\nconvolutional entanglement distillation protocol has several other benefits.\nTwo parties sharing noisy ebits can distill noiseless ebits ``online'' as they\nacquire more noisy ebits. Distillation yield is high and decoding complexity is\nsimple for a convolutional entanglement distillation protocol. Our theory of\nconvolutional entanglement distillation reduces the problem of finding a good\nconvolutional entanglement distillation protocol to the well-established\nproblem of finding a good classical convolutional code. \n\n"}
{"id": "0709.2833", "contents": "Title: Distributed Space Time Codes with Low Decoding Complexity for\n  Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time code (DSTC) structure that admit its application in the\nproposed transmission scheme are identified and it is pointed out that the\nrecently proposed full diversity four group decodable DSTCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time codes applicable in this new transmission scheme for\npower of two number of relays are also provided. \n\n"}
{"id": "0710.0118", "contents": "Title: Pion and kaon production in central Pb+Pb collisions at 20A and 30A GeV:\n  Evidence for the onset of deconfinement Abstract: Results on charged pion and kaon production in central Pb+Pb collisions at\n20A and 30A GeV are presented and compared to data at lower and higher\nenergies. A rapid change of the energy dependence is observed around 30A GeV\nfor the yields of pions and kaons as well as for the shape of the transverse\nmass spectra. The change is compatible with the prediction that the threshold\nfor production of a state of deconfined matter at the early stage of the\ncollisions is located at low SPS energies. \n\n"}
{"id": "0710.2705", "contents": "Title: Fingerprinting with Minimum Distance Decoding Abstract: This work adopts an information theoretic framework for the design of\ncollusion-resistant coding/decoding schemes for digital fingerprinting. More\nspecifically, the minimum distance decision rule is used to identify 1 out of t\npirates. Achievable rates, under this detection rule, are characterized in two\ndistinct scenarios. First, we consider the averaging attack where a random\ncoding argument is used to show that the rate 1/2 is achievable with t=2\npirates. Our study is then extended to the general case of arbitrary $t$\nhighlighting the underlying complexity-performance tradeoff. Overall, these\nresults establish the significant performance gains offered by minimum distance\ndecoding as compared to other approaches based on orthogonal codes and\ncorrelation detectors. In the second scenario, we characterize the achievable\nrates, with minimum distance decoding, under any collusion attack that\nsatisfies the marking assumption. For t=2 pirates, we show that the rate\n$1-H(0.25)\\approx 0.188$ is achievable using an ensemble of random linear\ncodes. For $t\\geq 3$, the existence of a non-resolvable collusion attack, with\nminimum distance decoding, for any non-zero rate is established. Inspired by\nour theoretical analysis, we then construct coding/decoding schemes for\nfingerprinting based on the celebrated Belief-Propagation framework. Using an\nexplicit repeat-accumulate code, we obtain a vanishingly small probability of\nmisidentification at rate 1/3 under averaging attack with t=2. For collusion\nattacks which satisfy the marking assumption, we use a more sophisticated\naccumulate repeat accumulate code to obtain a vanishingly small\nmisidentification probability at rate 1/9 with t=2. These results represent a\nmarked improvement over the best available designs in the literature. \n\n"}
{"id": "0710.5161", "contents": "Title: Decomposable Subspaces, Linear Sections of Grassmann Varieties, and\n  Higher Weights of Grassmann Codes Abstract: Given a homogeneous component of an exterior algebra, we characterize those\nsubspaces in which every nonzero element is decomposable. In geometric terms,\nthis corresponds to characterizing the projective linear subvarieties of the\nGrassmann variety with its Plucker embedding. When the base field is finite, we\nconsider the more general question of determining the maximum number of points\non sections of Grassmannians by linear subvarieties of a fixed (co)dimension.\nThis corresponds to a known open problem of determining the complete weight\nhierarchy of linear error correcting codes associated to Grassmann varieties.\nWe recover most of the known results as well as prove some new results. In the\nprocess we obtain, and utilize, a simple generalization of the Griesmer-Wei\nbound for arbitrary linear codes. \n\n"}
{"id": "0712.3216", "contents": "Title: Energy Dependence of Multiplicity Fluctuations in Heavy Ion Collisions\n  at the CERN SPS Abstract: Multiplicity fluctuations of positively, negatively and all charged hadrons\nin the forward hemisphere were studied in central Pb+Pb collisions at 20A, 30A,\n40A, 80A and 158A GeV. The multiplicity distributions and their scaled\nvariances are presented in dependence of collision energy as well as of\nrapidity and transverse momentum. The distributions have bell-like shape and\ntheir scaled variances are in the range from 0.8 to 1.2 without any significant\nstructure in their energy dependence. No indication of the critical point in\nfluctuations are observed. The string-hadronic model UrQMD significantly\noverpredicts the mean, but approximately reproduces the scaled variance of the\nmultiplicity distributions. The predictions of the statistical hadron-resonance\ngas model obtained within the grand-canonical and canonical ensembles disagree\nwith the measured scaled variances. The narrower than Poissonian multiplicity\nfluctuations measured in numerous cases may be explained by the impact of\nconservation laws on fluctuations in relativistic systems. \n\n"}
{"id": "0801.0061", "contents": "Title: Security for Wiretap Networks via Rank-Metric Codes Abstract: The problem of securing a network coding communication system against a\nwiretapper adversary is considered. The network implements linear network\ncoding to deliver $n$ packets from source to each receiver, and the wiretapper\ncan eavesdrop on $\\mu$ arbitrarily chosen links. A coding scheme is proposed\nthat can achieve the maximum possible rate of $k=n-\\mu$ packets that are\ninformation-theoretically secure from the adversary. A distinctive feature of\nour scheme is that it is universal: it can be applied on top of any\ncommunication network without requiring knowledge of or any modifications on\nthe underlying network code. In fact, even a randomized network code can be\nused. Our approach is based on Rouayheb-Soljanin's formulation of a wiretap\nnetwork as a generalization of the Ozarow-Wyner wiretap channel of type II.\nEssentially, the linear MDS code in Ozarow-Wyner's coset coding scheme is\nreplaced by a maximum-rank-distance code over an extension of the field in\nwhich linear network coding operations are performed. \n\n"}
{"id": "0801.2242", "contents": "Title: Information Spectrum Approach to Second-Order Coding Rate in Channel\n  Coding Abstract: Second-order coding rate of channel coding is discussed for general sequence\nof channels. The optimum second-order transmission rate with a constant error\nconstraint $\\epsilon$ is obtained by using the information spectrum method. We\napply this result to the discrete memoryless case, the discrete memoryless case\nwith a cost constraint, the additive Markovian case, and the Gaussian channel\ncase with an energy constraint. We also clarify that the Gallager bound does\nnot give the optimum evaluation in the second-order coding rate. \n\n"}
{"id": "0802.0554", "contents": "Title: Message-Passing Decoding of Lattices Using Gaussian Mixtures Abstract: A lattice decoder which represents messages explicitly as a mixture of\nGaussians functions is given. In order to prevent the number of functions in a\nmixture from growing as the decoder iterations progress, a method for replacing\nN Gaussian functions with M Gaussian functions, with M < N, is given. A squared\ndistance metric is used to select functions for combining. A pair of selected\nGaussians is replaced by a single Gaussian with the same first and second\nmoments. The metric can be computed efficiently, and at the same time, the\nproposed algorithm empirically gives good results, for example, a dimension 100\nlattice has a loss of 0.2 dB in signal-to-noise ratio at a probability of\nsymbol error of 10^{-5}. \n\n"}
{"id": "0802.3419", "contents": "Title: Randomized Frameproof Codes: Fingerprinting Plus Validation Minus\n  Tracing Abstract: We propose randomized frameproof codes for content protection, which arise by\nstudying a variation of the Boneh-Shaw fingerprinting problem. In the modified\nsystem, whenever a user tries to access his fingerprinted copy, the fingerprint\nis submitted to a validation algorithm to verify that it is indeed permissible\nbefore the content can be executed. We show an improvement in the achievable\nrates compared to deterministic frameproof codes and traditional fingerprinting\ncodes.\n  For coalitions of an arbitrary fixed size, we construct randomized frameproof\ncodes which have an $O(n^2)$ complexity validation algorithm and probability of\nerror $\\exp(-\\Omega(n)),$ where $n$ denotes the length of the fingerprints.\nFinally, we present a connection between linear frameproof codes and minimal\nvectors for size-2 coalitions. \n\n"}
{"id": "0804.0611", "contents": "Title: Channel State Feedback Schemes for Multiuser MIMO-OFDM Downlink Abstract: Channel state feedback schemes for the MIMO broadcast downlink have been\nwidely studied in the frequency-flat case. This work focuses on the more\nrelevant frequency selective case, where some important new aspects emerge. We\nconsider a MIMO-OFDM broadcast channel and compare achievable ergodic rates\nunder three channel state feedback schemes: analog feedback, direction\nquantized feedback and \"time-domain\" channel quantized feedback. The first two\nschemes are direct extensions of previously proposed schemes. The third scheme\nis novel, and it is directly inspired by rate-distortion theory of Gaussian\ncorrelated sources. For each scheme we derive the conditions under which the\nsystem achieves full multiplexing gain. The key difference with respect to the\nwidely treated frequency-flat case is that in MIMO-OFDM the frequency-domain\nchannel transfer function is a Gaussian correlated source. The new time-domain\nquantization scheme takes advantage of the channel frequency correlation\nstructure and outperforms the other schemes. Furthermore, it is by far simpler\nto implement than complicated spherical vector quantization. In particular, we\nobserve that no structured codebook design and vector quantization is actually\nneeded for efficient channel state information feedback. \n\n"}
{"id": "0804.0980", "contents": "Title: Large MIMO Detection: A Low-Complexity Detector at High Spectral\n  Efficiencies Abstract: We consider large MIMO systems, where by `{\\em large}' we mean number of\ntransmit and receive antennas of the order of tens to hundreds. Such large MIMO\nsystems will be of immense interest because of the very high spectral\nefficiencies possible in such systems. We present a low-complexity detector\nwhich achieves uncoded near-exponential diversity performance for hundreds of\nantennas (i.e., achieves near SISO AWGN performance in a large MIMO fading\nenvironment) with an average per-bit complexity of just $O(N_tN_r)$, where\n$N_t$ and $N_r$ denote the number of transmit and receive antennas,\nrespectively. With an outer turbo code, the proposed detector achieves good\ncoded bit error performance as well. For example, in a 600 transmit and 600\nreceive antennas V-BLAST system with a high spectral efficiency of 200 bps/Hz\n(using BPSK and rate-1/3 turbo code), our simulation results show that the\nproposed detector performs close to within about 4.6 dB from theoretical\ncapacity. We also adopt the proposed detector for the low-complexity decoding\nof high-rate non-orthogonal space-time block codes (STBC) from division\nalgebras (DA). For example, we have decoded the $16\\times 16$ full-rate\nnon-orthogonal STBC from DA using the proposed detector and show that it\nperforms close to within about 5.5 dB of the capacity using 4-QAM and rate-3/4\nturbo code at a spectral efficiency of 24 bps/Hz. The practical feasibility of\nthe proposed high-performance low-complexity detector could potentially trigger\nwide interest in the implementation of large MIMO systems. In large MC-CDMA\nsystems with hundreds of users, the proposed detector is shown to achieve near\nsingle-user performance at an average per-bit complexity linear in number of\nusers, which is quite appealing for its use in practical CDMA systems. \n\n"}
{"id": "0804.2940", "contents": "Title: Secret Key Agreement by Soft-decision of Signals in Gaussian Maurer's\n  Model Abstract: We consider the problem of secret key agreement in Gaussian Maurer's Model.\nIn Gaussian Maurer's model, legitimate receivers, Alice and Bob, and a\nwire-tapper, Eve, receive signals randomly generated by a satellite through\nthree independent memoryless Gaussian channels respectively. Then Alice and Bob\ngenerate a common secret key from their received signals. In this model, we\npropose a protocol for generating a common secret key by using the result of\nsoft-decision of Alice and Bob's received signals. Then, we calculate a lower\nbound on the secret key rate in our proposed protocol. As a result of\ncomparison with the protocol that only uses hard-decision, we found that the\nhigher rate is obtained by using our protocol. \n\n"}
{"id": "0805.0213", "contents": "Title: The polarizability of the pion: no conflict between dispersion theory\n  and chiral perturbation theory Abstract: Recent attempts to determine the pion polarizability by dispersion relations\nyield values that disagree with the predictions of chiral perturbation theory.\nThese dispersion relations are based on specific forms for the absorptive part\nof the Compton amplitudes. The analytic properties of these forms are examined,\nand the strong enhancement of intermediate-meson contributions is shown to be\nconnected with spurious singularities. If the basic requirements of dispersion\nrelations are taken into account, the results of dispersion theory and\neffective field theory are not inconsistent. \n\n"}
{"id": "0806.0079", "contents": "Title: Overview of charm production at RHIC Abstract: We present an overview of the recent abundant measurements for charm\nproduction at RHIC. The significant information of charm cross sections in\ndifferent collision system at 200 GeV and charmed hadron freeze-out and flow\nproperties extracted from these measurements are presented. The heavy flavor\nenergy loss in the medium and heavy flavor related azimuthal correlations in\nheavy ion collisions are also discussed. \n\n"}
{"id": "0806.0353", "contents": "Title: $J/\\psi$ and $\\Upsilon$ measurements in STAR Abstract: Heavy-quarkonium states are expected to evidenciate the deconfinement of the\nnuclear matter into a Quark-Gluon Plasma in heavy-ion collisions. To strive\nconclusive information from quarkonium production modification in A+A\ncollisions, systematic measurements of the $J/\\psi$ and $\\Upsilon$ states in\np+p, d+Au and Au+Au collisions are necessary. To accomplish this mission the\nSTAR experiment has a Quarkonium program based on the development of specific\ntrigger setups that take advantage of the large STAR acceptance. In this work\nwe present the preliminary results of the $J/\\psi$ and $\\Upsilon$ measurement\nin 200 GeV p+p and the first measurements of $\\Upsilon$ in 200 GeV heavy ion\ncollisions. \n\n"}
{"id": "0806.0358", "contents": "Title: Universal upper bound on the energy of a parton escaping from the\n  strongly coupled quark-gluon matter Abstract: It has been shown through the AdS/CFT correspondence that the energy loss of\na fast quark in a strongly coupled ${\\cal N}=4$ SUSY Yang--Mills matter in the\nlarge N limit is given by the classical Lienard formula. I demonstrate that\nunder quite natural assumptions about the dynamics of heavy ion collisions this\nleads to a universal (i.e. independent of the initial parton energy, but\ndependent on flavor and centrality) upper bound on the energy of the partons\nescaping from the plasma. This bound is a Yang--Mills analog of the Pomeranchuk\nbound in classical electrodynamics, where it is a consequence of radiation in a\nstrong external field acting on a relativistic charge. Since as a result the\nmassive constituent partons are slowed down to a velocity v < c, the angular\ndistribution of the emitted radiation exhibits a broad \"dead cone\". If the\nproperties of conformal and QCD matter at strong coupling are qualitatively\nsimilar, the existence of this universal upper bound would have dramatic\nimplications for heavy ion experiments. \n\n"}
{"id": "0806.3650", "contents": "Title: Recursive Code Construction for Random Networks Abstract: A modification of Koetter-Kschischang codes for random networks is presented\n(these codes were also studied by Wang et al. in the context of authentication\nproblems). The new codes have higher information rate, while maintaining the\nsame error-correcting capabilities. An efficient error-correcting algorithm is\nproposed for these codes. \n\n"}
{"id": "0806.4200", "contents": "Title: The Secrecy Rate Region of the Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers, while a wire-tapper\nalso receives the transmitted signal. This model is motivated by wireless\ncommunications, where individual secure messages are broadcast over open media\nand can be received by any illegitimate receiver. The secrecy level is measured\nby equivocation rate at the eavesdropper. We first study the general\n(non-degraded) broadcast channel with confidential messages. We present an\ninner bound on the secrecy capacity region for this model. The inner bound\ncoding scheme is based on a combination of random binning and the\nGelfand-Pinsker bining. This scheme matches the Marton's inner bound on the\nbroadcast channel without confidentiality constraint. We further study the\nsituation where the channels are degraded. For the degraded broadcast channel\nwith confidential messages, we present the secrecy capacity region. Our\nachievable coding scheme is based on Cover's superposition scheme and random\nbinning. We refer to this scheme as Secret Superposition Scheme. In this\nscheme, we show that randomization in the first layer increases the secrecy\nrate of the second layer. This capacity region matches the capacity region of\nthe degraded broadcast channel without security constraint. It also matches the\nsecrecy capacity for the conventional wire-tap channel. Our converse proof is\nbased on a combination of the converse proof of the conventional degraded\nbroadcast channel and Csiszar lemma. Finally, we assume that the channels are\nAdditive White Gaussian Noise (AWGN) and show that secret superposition scheme\nwith Gaussian codebook is optimal. The converse proof is based on the\ngeneralized entropy power inequality. \n\n"}
{"id": "0808.0234", "contents": "Title: DMT of Multi-hop Cooperative Networks - Part I: Basic Results Abstract: In this two-part paper, the DMT of cooperative multi-hop networks is\nexamined. The focus is on single-source single-sink (ss-ss) multi-hop relay\nnetworks having slow-fading links and relays that potentially possess multiple\nantennas. The present paper examines the two end-points of the DMT of\nfull-duplex networks. In particular, the maximum achievable diversity of\narbitrary multi-terminal wireless networks is shown to be equal to the min-cut.\nThe maximum multiplexing gain of arbitrary full-duplex ss-ss networks is shown\nto be equal to the min-cut rank, using a new connection to a deterministic\nnetwork. We also prove some basic results including a proof that the colored\nnoise encountered in AF protocols for cooperative networks can be treated as\nwhite noise for DMT computations. The DMT of a parallel channel with\nindependent MIMO links is also computed here. As an application of these basic\nresults, we prove that a linear tradeoff between maximum diversity and maximum\nmultiplexing gain is achievable for full-duplex networks with single antenna\nnodes. All protocols in this paper are explicit and rely only upon\namplify-and-forward (AF) relaying. Half duplex networks are studied, and\nexplicit codes for all protocols proposed in both parts, are provided in the\ncompanion paper. \n\n"}
{"id": "0808.0948", "contents": "Title: Capacity of a Class of Diamond Channels Abstract: We study a special class of diamond channels which was introduced by Schein\nin 2001. In this special class, each diamond channel consists of a transmitter,\na noisy relay, a noiseless relay and a receiver. We prove the capacity of this\nclass of diamond channels by providing an achievable scheme and a converse. The\ncapacity we show is strictly smaller than the cut-set bound. Our result also\nshows the optimality of a combination of decode-and-forward (DAF) and\ncompress-and-forward (CAF) at the noisy relay node. This is the first example\nwhere a combination of DAF and CAF is shown to be capacity achieving. Finally,\nwe note that there exists a duality between this diamond channel coding problem\nand the Kaspi-Berger source coding problem. \n\n"}
{"id": "0809.2049", "contents": "Title: Particle-Number Restoration within the Energy Density Functional\n  formalism: Nonviability of terms depending on noninteger powers of the\n  density matrices Abstract: We discuss the origin of pathological behaviors that have been recently\nidentified in particle-number-restoration calculations performed within the\nnuclear energy density functional framework. A regularization method that\nremoves the problematic terms from the multi-reference energy density\nfunctional and which applies (i) to any symmetry restoration- and/or\ngenerator-coordinate-method-based configuration mixing calculation and (ii) to\nenergy density functionals depending only on integer powers of the density\nmatrices, was proposed in [D. Lacroix, T. Duguet, M. Bender, arXiv:0809.2041]\nand implemented for particle-number restoration calculations in [M. Bender, T.\nDuguet, D. Lacroix, arXiv:0809.2045]. In the present paper, we address the\nviability of non-integer powers of the density matrices in the nuclear energy\ndensity functional. Our discussion builds upon the analysis already carried out\nin [J. Dobaczewski \\emph{et al.}, Phys. Rev. C \\textbf{76}, 054315 (2007)].\nFirst, we propose to reduce the pathological nature of terms depending on a\nnon-integer power of the density matrices by regularizing the fraction that\nrelates to the integer part of the exponent using the method proposed in [D.\nLacroix, T. Duguet, M. Bender, arXiv:0809.2041]. Then, we discuss the spurious\nfeatures brought about by the remaining fractional power. Finally, we conclude\nthat non-integer powers of the density matrices are not viable and should be\navoided in the first place when constructing nuclear energy density functionals\nthat are eventually meant to be used in multi-reference calculations. \n\n"}
{"id": "0809.3540", "contents": "Title: A Note on the Equivalence of Gibbs Free Energy and Information Theoretic\n  Capacity Abstract: The minimization of Gibbs free energy is based on the changes in work and\nfree energy that occur in a physical or chemical system. The maximization of\nmutual information, the capacity, of a noisy channel is determined based on the\nmarginal probabilities and conditional entropies associated with a\ncommunications system. As different as the procedures might first appear,\nthrough the exploration of a simple, \"dual use\" Ising model, it is seen that\nthe two concepts are in fact the same. In particular, the case of a binary\nsymmetric channel is calculated in detail. \n\n"}
{"id": "0809.3546", "contents": "Title: Universal Secure Network Coding via Rank-Metric Codes Abstract: The problem of securing a network coding communication system against an\neavesdropper adversary is considered. The network implements linear network\ncoding to deliver n packets from source to each receiver, and the adversary can\neavesdrop on \\mu arbitrarily chosen links. The objective is to provide reliable\ncommunication to all receivers, while guaranteeing that the source information\nremains information-theoretically secure from the adversary. A coding scheme is\nproposed that can achieve the maximum possible rate of n-\\mu packets. The\nscheme, which is based on rank-metric codes, has the distinctive property of\nbeing universal: it can be applied on top of any communication network without\nrequiring knowledge of or any modifications on the underlying network code. The\nonly requirement of the scheme is that the packet length be at least n, which\nis shown to be strictly necessary for universal communication at the maximum\nrate. A further scenario is considered where the adversary is allowed not only\nto eavesdrop but also to inject up to t erroneous packets into the network, and\nthe network may suffer from a rank deficiency of at most \\rho. In this case,\nthe proposed scheme can be extended to achieve the rate of n-\\rho-2t-\\mu\npackets. This rate is shown to be optimal under the assumption of zero-error\ncommunication. \n\n"}
{"id": "0809.5269", "contents": "Title: The 3He(alpha,gamma)7Be S-factor at solar energies: the prompt gamma\n  experiment at LUNA Abstract: The 3He(alpha,gamma)7Be process is a key reaction in both Big-Bang\nnucleosynthesis and p-p chain of Hydrogen Burning in Stars. A new measurement\nof the 3He(alpha,gamma)7Be cross section has been performed at the INFN Gran\nSasso underground laboratory by both the activation and the prompt gamma\ndetection methods. The present work reports full details of the prompt gamma\ndetection experiment, focusing on the determination of the systematic\nuncertainty. The final data, including activation measurements at LUNA, are\ncompared with the results of the last generation experiments and two different\ntheoretical models are used to obtain the S-factor at solar energies. \n\n"}
{"id": "0810.1808", "contents": "Title: A Central Limit Theorem for the SINR at the LMMSE Estimator Output for\n  Large Dimensional Signals Abstract: This paper is devoted to the performance study of the Linear Minimum Mean\nSquared Error estimator for multidimensional signals in the large dimension\nregime. Such an estimator is frequently encountered in wireless communications\nand in array processing, and the Signal to Interference and Noise Ratio (SINR)\nat its output is a popular performance index. The SINR can be modeled as a\nrandom quadratic form which can be studied with the help of large random matrix\ntheory, if one assumes that the dimension of the received and transmitted\nsignals go to infinity at the same pace. This paper considers the asymptotic\nbehavior of the SINR for a wide class of multidimensional signal models that\nincludes general multi-antenna as well as spread spectrum transmission models.\n  The expression of the deterministic approximation of the SINR in the large\ndimension regime is recalled and the SINR fluctuations around this\ndeterministic approximation are studied. These fluctuations are shown to\nconverge in distribution to the Gaussian law in the large dimension regime, and\ntheir variance is shown to decrease as the inverse of the signal dimension. \n\n"}
{"id": "0810.4225", "contents": "Title: Nonnegative Factorization and The Maximum Edge Biclique Problem Abstract: Nonnegative Matrix Factorization (NMF) is a data analysis technique which\nallows compression and interpretation of nonnegative data. NMF became widely\nstudied after the publication of the seminal paper by Lee and Seung (Learning\nthe Parts of Objects by Nonnegative Matrix Factorization, Nature, 1999, vol.\n401, pp. 788--791), which introduced an algorithm based on Multiplicative\nUpdates (MU). More recently, another class of methods called Hierarchical\nAlternating Least Squares (HALS) was introduced that seems to be much more\nefficient in practice.\n  In this paper, we consider the problem of approximating a not necessarily\nnonnegative matrix with the product of two nonnegative matrices, which we refer\nto as Nonnegative Factorization (NF); this is the subproblem that HALS methods\nimplicitly try to solve at each iteration. We prove that NF is NP-hard for any\nfixed factorization rank, using a reduction to the maximum edge biclique\nproblem.\n  We also generalize the multiplicative updates to NF, which allows us to shed\nsome light on the differences between the MU and HALS algorithms for NMF and\ngive an explanation for the better performance of HALS. Finally, we link\nstationary points of NF with feasible solutions of the biclique problem to\nobtain a new type of biclique finding algorithm (based on MU) whose iterations\nhave an algorithmic complexity proportional to the number of edges in the\ngraph, and show that it performs better than comparable existing methods. \n\n"}
{"id": "0810.4658", "contents": "Title: Indexability of Restless Bandit Problems and Optimality of Whittle's\n  Index for Dynamic Multichannel Access Abstract: We consider a class of restless multi-armed bandit problems (RMBP) that\narises in dynamic multichannel access, user/server scheduling, and optimal\nactivation in multi-agent systems. For this class of RMBP, we establish the\nindexability and obtain Whittle's index in closed-form for both discounted and\naverage reward criteria. These results lead to a direct implementation of\nWhittle's index policy with remarkably low complexity. When these Markov chains\nare stochastically identical, we show that Whittle's index policy is optimal\nunder certain conditions. Furthermore, it has a semi-universal structure that\nobviates the need to know the Markov transition probabilities. The optimality\nand the semi-universal structure result from the equivalency between Whittle's\nindex policy and the myopic policy established in this work. For non-identical\nchannels, we develop efficient algorithms for computing a performance upper\nbound given by Lagrangian relaxation. The tightness of the upper bound and the\nnear-optimal performance of Whittle's index policy are illustrated with\nsimulation examples. \n\n"}
{"id": "0811.0196", "contents": "Title: Reduced-Complexity Reed--Solomon Decoders Based on Cyclotomic FFTs Abstract: In this paper, we reduce the computational complexities of partial and dual\npartial cyclotomic FFTs (CFFTs), which are discrete Fourier transforms where\nspectral and temporal components are constrained, based on their properties as\nwell as a common subexpression elimination algorithm. Our partial CFFTs achieve\nsmaller computational complexities than previously proposed partial CFFTs.\nUtilizing our CFFTs in both transform- and time-domain Reed--Solomon decoders,\nwe achieve significant complexity reductions. \n\n"}
{"id": "0812.0319", "contents": "Title: Secrecy Capacity of a Class of Broadcast Channels with an Eavesdropper Abstract: We study the security of communication between a single transmitter and\nmultiple receivers in a broadcast channel in the presence of an eavesdropper.\nWe consider several special classes of channels. As the first model, we\nconsider the degraded multi-receiver wiretap channel where the legitimate\nreceivers exhibit a degradedness order while the eavesdropper is more noisy\nwith respect to all legitimate receivers. We establish the secrecy capacity\nregion of this channel model. Secondly, we consider the parallel multi-receiver\nwiretap channel with a less noisiness order in each sub-channel, where this\norder is not necessarily the same for all sub-channels. We establish the common\nmessage secrecy capacity and sum secrecy capacity of this channel. Thirdly, we\nstudy a special class of degraded parallel multi-receiver wiretap channels and\nprovide a stronger result. In particular, we study the case with two\nsub-channels two users and one eavesdropper, where there is a degradedness\norder in each sub-channel such that in the first (resp. second) sub-channel the\nsecond (resp. first) receiver is degraded with respect to the first (resp.\nsecond) receiver, while the eavesdropper is degraded with respect to both\nlegitimate receivers in both sub-channels. We determine the secrecy capacity\nregion of this channel. Finally, we focus on a variant of this previous channel\nmodel where the transmitter can use only one of the sub-channels at any time.\nWe characterize the secrecy capacity region of this channel as well. \n\n"}
{"id": "0901.1732", "contents": "Title: Feedback Communication over Individual Channels Abstract: We consider the problem of communicating over a channel for which no\nmathematical model is specified. We present achievable rates as a function of\nthe channel input and output sequences known a-posteriori for discrete and\ncontinuous channels. Furthermore we present a rate-adaptive scheme employing\nfeedback which achieves these rates asymptotically without prior knowledge of\nthe channel behavior. \n\n"}
{"id": "0901.1898", "contents": "Title: Efficient and Guaranteed Rank Minimization by Atomic Decomposition Abstract: Recht, Fazel, and Parrilo provided an analogy between rank minimization and\n$\\ell_0$-norm minimization. Subject to the rank-restricted isometry property,\nnuclear norm minimization is a guaranteed algorithm for rank minimization. The\nresulting semidefinite formulation is a convex problem but in practice the\nalgorithms for it do not scale well to large instances. Instead, we explore\nmissing terms in the analogy and propose a new algorithm which is\ncomputationally efficient and also has a performance guarantee. The algorithm\nis based on the atomic decomposition of the matrix variable and extends the\nidea in the CoSaMP algorithm for $\\ell_0$-norm minimization. Combined with the\nrecent fast low rank approximation of matrices based on randomization, the\nproposed algorithm can efficiently handle large scale rank minimization\nproblems. \n\n"}
{"id": "0902.1377", "contents": "Title: Fundamental Symmetries and Conservation Laws Abstract: I discuss recent progress in low-energy tests of symmetries and conservation\nlaws, including parity nonconservation in atoms and nuclei, electric dipole\nmoment tests of time-reversal invariance, beta-decay correlation studies, and\ndecays violating separate (family) and total lepton number. \n\n"}
{"id": "0903.3261", "contents": "Title: The Secrecy Capacity Region of the Gaussian MIMO Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers via a Gaussian MIMO\nbroadcast channel. A wire-tapper also receives the transmitted signal via\nanother MIMO channel. First we assumed that the channels are degraded and the\nwire-tapper has the worst channel. We establish the capacity region of this\nscenario. Our achievability scheme is a combination of the superposition of\nGaussian codes and randomization within the layers which we will refer to as\nSecret Superposition Coding. For the outerbound, we use the notion of enhanced\nchannel to show that the secret superposition of Gaussian codes is optimal. We\nshow that we only need to enhance the channels of the legitimate receivers, and\nthe channel of the eavesdropper remains unchanged. Then we extend the result of\nthe degraded case to non-degraded case. We show that the secret superposition\nof Gaussian codes along with successive decoding cannot work when the channels\nare not degraded. we develop a Secret Dirty Paper Coding (SDPC) scheme and show\nthat SDPC is optimal for this channel. Finally, we investigate practical\ncharacterizations for the specific scenario in which the transmitter and the\neavesdropper have multiple antennas, while both intended receivers have a\nsingle antenna. We characterize the secrecy capacity region in terms of\ngeneralized eigenvalues of the receivers channel and the eavesdropper channel.\nWe refer to this configuration as the MISOME case. In high SNR we show that the\ncapacity region is a convex closure of two rectangular regions. \n\n"}
{"id": "0903.4014", "contents": "Title: Construction of Codes for Wiretap Channel and Secret Key Agreement from\n  Correlated Source Outputs by Using Sparse Matrices Abstract: The aim of this paper is to prove coding theorems for the wiretap channel\ncoding problem and secret key agreement problem based on the the notion of a\nhash property for an ensemble of functions. These theorems imply that codes\nusing sparse matrices can achieve the optimal rate. Furthermore, fixed-rate\nuniversal coding theorems for a wiretap channel and a secret key agreement are\nalso proved. \n\n"}
{"id": "0905.0440", "contents": "Title: Tandem Coding and Cryptography on Wiretap Channels: EXIT Chart Analysis Abstract: Traditional cryptography assumes an eavesdropper receives an error-free copy\nof the transmitted ciphertext. Wyner's wiretap channel model recognizes that at\nthe physical layer both the intended receiver and the passive eavesdropper\ninevitably receive an error-prone version of the transmitted message which must\nbe corrected prior to decryption. This paper considers the implications of\nusing both channel and cryptographic codes under the wiretap channel model in a\nway that enhances the \\emph{information-theoretic} security for the friendly\nparties by keeping the information transfer to the eavesdropper small. We\nconsider a secret-key cryptographic system with a linear feedback shift\nregister (LFSR)-based keystream generator and observe the mutual information\nbetween an LFSR-generated sequence and the received noise-corrupted ciphertext\nsequence under a known-plaintext scenario. The effectiveness of a noniterative\nfast correlation attack, which reduces the search time in a brute-force attack,\nis shown to be correlated with this mutual information. For an iterative fast\ncorrelation attack on this cryptographic system, it is shown that an EXIT chart\nand mutual information are very good predictors of decoding success and failure\nby a passive eavesdropper. \n\n"}
{"id": "0905.3407", "contents": "Title: Throughput and Delay Scaling in Supportive Two-Tier Networks Abstract: Consider a wireless network that has two tiers with different priorities: a\nprimary tier vs. a secondary tier, which is an emerging network scenario with\nthe advancement of cognitive radio technologies. The primary tier consists of\nrandomly distributed legacy nodes of density $n$, which have an absolute\npriority to access the spectrum. The secondary tier consists of randomly\ndistributed cognitive nodes of density $m=n^\\beta$ with $\\beta\\geq 2$, which\ncan only access the spectrum opportunistically to limit the interference to the\nprimary tier. Based on the assumption that the secondary tier is allowed to\nroute the packets for the primary tier, we investigate the throughput and delay\nscaling laws of the two tiers in the following two scenarios: i) the primary\nand secondary nodes are all static; ii) the primary nodes are static while the\nsecondary nodes are mobile. With the proposed protocols for the two tiers, we\nshow that the primary tier can achieve a per-node throughput scaling of\n$\\lambda_p(n)=\\Theta(1/\\log n)$ in the above two scenarios. In the associated\ndelay analysis for the first scenario, we show that the primary tier can\nachieve a delay scaling of $D_p(n)=\\Theta(\\sqrt{n^\\beta\\log n}\\lambda_p(n))$\nwith $\\lambda_p(n)=O(1/\\log n)$. In the second scenario, with two mobility\nmodels considered for the secondary nodes: an i.i.d. mobility model and a\nrandom walk model, we show that the primary tier can achieve delay scaling laws\nof $\\Theta(1)$ and $\\Theta(1/S)$, respectively, where $S$ is the random walk\nstep size. The throughput and delay scaling laws for the secondary tier are\nalso established, which are the same as those for a stand-alone network. \n\n"}
{"id": "0905.4023", "contents": "Title: DMT Optimality of LR-Aided Linear Decoders for a General Class of\n  Channels, Lattice Designs, and System Models Abstract: The work identifies the first general, explicit, and non-random MIMO\nencoder-decoder structures that guarantee optimality with respect to the\ndiversity-multiplexing tradeoff (DMT), without employing a computationally\nexpensive maximum-likelihood (ML) receiver. Specifically, the work establishes\nthe DMT optimality of a class of regularized lattice decoders, and more\nimportantly the DMT optimality of their lattice-reduction (LR)-aided linear\ncounterparts. The results hold for all channel statistics, for all channel\ndimensions, and most interestingly, irrespective of the particular lattice-code\napplied. As a special case, it is established that the LLL-based LR-aided\nlinear implementation of the MMSE-GDFE lattice decoder facilitates DMT optimal\ndecoding of any lattice code at a worst-case complexity that grows at most\nlinearly in the data rate. This represents a fundamental reduction in the\ndecoding complexity when compared to ML decoding whose complexity is generally\nexponential in rate.\n  The results' generality lends them applicable to a plethora of pertinent\ncommunication scenarios such as quasi-static MIMO, MIMO-OFDM, ISI,\ncooperative-relaying, and MIMO-ARQ channels, in all of which the DMT optimality\nof the LR-aided linear decoder is guaranteed. The adopted approach yields\ninsight, and motivates further study, into joint transceiver designs with an\nimproved SNR gap to ML decoding. \n\n"}
{"id": "0906.1835", "contents": "Title: Secret-Key Generation using Correlated Sources and Channels Abstract: We study the problem of generating a shared secret key between two terminals\nin a joint source-channel setup -- the sender communicates to the receiver over\na discrete memoryless wiretap channel and additionally the terminals have\naccess to correlated discrete memoryless source sequences. We establish lower\nand upper bounds on the secret-key capacity. These bounds coincide,\nestablishing the capacity, when the underlying channel consists of independent,\nparallel and reversely degraded wiretap channels. In the lower bound, the\nequivocation terms of the source and channel components are functionally\nadditive. The secret-key rate is maximized by optimally balancing the the\nsource and channel contributions. This tradeoff is illustrated in detail for\nthe Gaussian case where it is also shown that Gaussian codebooks achieve the\ncapacity. When the eavesdropper also observes a source sequence, the secret-key\ncapacity is established when the sources and channels of the eavesdropper are a\ndegraded version of the legitimate receiver. Finally the case when the\nterminals also have access to a public discussion channel is studied. We\npropose generating separate keys from the source and channel components and\nestablish the optimality of this approach when the when the channel outputs of\nthe receiver and the eavesdropper are conditionally independent given the\ninput. \n\n"}
{"id": "0906.3200", "contents": "Title: On the Compound MIMO Broadcast Channels with Confidential Messages Abstract: We study the compound multi-input multi-output (MIMO) broadcast channel with\nconfidential messages (BCC), where one transmitter sends a common message to\ntwo receivers and two confidential messages respectively to each receiver. The\nchannel state may take one of a finite set of states, and the transmitter knows\nthe state set but does not know the realization of the state. We study\nachievable rates with perfect secrecy in the high SNR regime by characterizing\nan achievable secrecy degree of freedom (s.d.o.f.) region for two models, the\nGaussian MIMO-BCC and the ergodic fading multi-input single-output (MISO)-BCC\nwithout a common message. We show that by exploiting an additional temporal\ndimension due to state variation in the ergodic fading model, the achievable\ns.d.o.f. region can be significantly improved compared to the Gaussian model\nwith a constant state, although at the price of a larger delay. \n\n"}
{"id": "0907.0505", "contents": "Title: Multi-User MISO Interference Channels with Single-User Detection:\n  Optimality of Beamforming and the Achievable Rate Region Abstract: For a multi-user interference channel with multi-antenna transmitters and\nsingle-antenna receivers, by restricting each transmitter to Gaussian input and\neach receiver to a single-user detector, computing the largest achievable rate\nregion amounts to solving a family of non-convex optimization problems.\nRecognizing the intrinsic connection between the signal power at the intended\nreceiver and the interference power at the unintended receiver, the original\nfamily of non-convex optimization problems is converted into a new family of\nconvex optimization problems. It is shown that, for such interference channels\nwith each receiver implementing single-user detection, transmitter beamforming\ncan achieve all boundary points of the achievable rate region. \n\n"}
{"id": "0907.3119", "contents": "Title: Physics with the ALICE Electromagnetic Calorimeter Abstract: I will present physics measurements which are achievable in the ALICE\nexperiment at the LHC through the inclusion of a new electromagnetic\ncalorimeter. I will focus on jet measurements in proton proton and heavy ion\ncollisions. Detailed simulations have been performed on jet reconstruction, jet\ntriggering, heavy flavor jet reconstruction through electron identification,\ngamma-jet reconstruction and the measurements of identified hadrons and\nresonances in jets. I will show the physics capabilities which are made\npossible through the combination of calorimeter information with the other\ndetector components in ALICE. \n\n"}
{"id": "0907.4696", "contents": "Title: Quarkonia measurement in p+p and d+Au collisions at sqrt(s)=200 GeV by\n  PHENIX Detector Abstract: We report new quarkonia measurements necessary to understand production\nmechanisms and cold nuclear matter effects in the yields observed at RHIC\nenergy. Results obtained in p+p collisions collected during the 2006 RHIC Run\ninclude J/psi, Psi' and Upsilon differential cross sections as well as J/psi\npolarization. Revisited interpretations of the published J/psi nuclear\nmodification factors and statistically improved observations in d+Au collisions\ntaken in the 2008 Run are also discussed in the view of the recent\nunderstanding of the initial state effects and breakup cross section. \n\n"}
{"id": "0908.0898", "contents": "Title: On Secrecy Capacity Scaling in Wireless Networks Abstract: This work studies the achievable secure rate per source-destination pair in\nwireless networks. First, a path loss model is considered, where the legitimate\nand eavesdropper nodes are assumed to be placed according to Poisson point\nprocesses with intensities $\\lambda$ and $\\lambda_e$, respectively. It is shown\nthat, as long as $\\lambda_e/\\lambda=o((\\log n)^{-2})$, almost all of the nodes\nachieve a perfectly secure rate of $\\Omega(\\frac{1}{\\sqrt{n}})$ for the\nextended and dense network models. Therefore, under these assumptions, securing\nthe network does not entail a loss in the per-node throughput. The\nachievability argument is based on a novel multi-hop forwarding scheme where\nrandomization is added in every hop to ensure maximal ambiguity at the\neavesdropper(s). Secondly, an ergodic fading model with $n$ source-destination\npairs and $n_e$ eavesdroppers is considered. Employing the ergodic interference\nalignment scheme with an appropriate secrecy pre-coding, each user is shown to\nachieve a constant positive secret rate for sufficiently large $n$. Remarkably,\nthe scheme does not require eavesdropper CSI (only the statistical knowledge is\nassumed) and the secure throughput per node increases as we add more legitimate\nusers to the network in this setting. Finally, the effect of eavesdropper\ncollusion on the performance of the proposed schemes is characterized. \n\n"}
{"id": "0908.2042", "contents": "Title: Problems in application of LDPC codes to information reconciliation in\n  quantum key distribution protocols Abstract: The information reconciliation in a quantum key distribution protocol can be\nstudied separately from other steps in the protocol. The problem of information\nreconciliation can be reduced to that of distributed source coding. Its\nsolution by LDPC codes is reviewed. We list some obstacles preventing the\nLDPC-based distributed source coding from becoming a more favorable alternative\nto the Cascade protocol for information reconciliation in quantum key\ndistribution protocols. This exposition does not require knowledge of the\nquantum theory. \n\n"}
{"id": "0908.2494", "contents": "Title: A Channel Coding Perspective of Collaborative Filtering Abstract: We consider the problem of collaborative filtering from a channel coding\nperspective. We model the underlying rating matrix as a finite alphabet matrix\nwith block constant structure. The observations are obtained from this\nunderlying matrix through a discrete memoryless channel with a noisy part\nrepresenting noisy user behavior and an erasure part representing missing data.\nMoreover, the clusters over which the underlying matrix is constant are {\\it\nunknown}. We establish a sharp threshold result for this model: if the largest\ncluster size is smaller than $C_1 \\log(mn)$ (where the rating matrix is of size\n$m \\times n$), then the underlying matrix cannot be recovered with any\nestimator, but if the smallest cluster size is larger than $C_2 \\log(mn)$, then\nwe show a polynomial time estimator with diminishing probability of error. In\nthe case of uniform cluster size, not only the order of the threshold, but also\nthe constant is identified. \n\n"}
{"id": "0908.3562", "contents": "Title: Another Look at the Physics of Large Deviations With Application to\n  Rate-Distortion Theory Abstract: We revisit and extend the physical interpretation recently given to a certain\nidentity between large--deviations rate--functions (as well as applications of\nthis identity to Information Theory), as an instance of thermal equilibrium\nbetween several physical systems that are brought into contact. Our new\ninterpretation, of mechanical equilibrium between these systems, is shown to\nhave several advantages relative to that of thermal equilibrium. This physical\npoint of view also provides a trigger to the development of certain alternative\nrepresentations of the rate--distortion function and channel capacity, which\nare new to the best knowledge of the author. \n\n"}
{"id": "0909.0485", "contents": "Title: Search for the QCD critical point at SPS energies Abstract: Lattice QCD calculations locate the QCD critical point at energies accessible\nat the CERN Super Proton Synchrotron (SPS). We present average transverse\nmomentum and multiplicity fluctuations, as well as baryon and anti-baryon\ntransverse mass spectra which are expected to be sensitive to effects of the\ncritical point. The future CP search strategy of the NA61/SHINE experiment at\nthe SPS is also discussed. \n\n"}
{"id": "0909.1344", "contents": "Title: Multiuser MISO Transmitter Optimization for Inter-Cell Interference\n  Mitigation Abstract: The transmitter optimization (i.e., steering vectors and power allocation)\nfor a MISO Broadcast Channel (MISO-BC) subject to general linear constraints is\nconsidered. Such constraints include, as special cases, the sum power, the\nper-antenna or per-group-of-antennas power, and \"forbidden interference\ndirection\" constraints. We consider both the optimal dirty-paper coding and the\nsimple suboptimal linear zero-forcing beamforming strategies, and provide\nnumerically efficient algorithms that solve the problem in its most general\nform. As an application, we consider a multi-cell scenario with partial cell\ncooperation, where each cell optimizes its precoder by taking into account\ninterference constraints on specific users in adjacent cells. The effectiveness\nof the proposed methods is evaluated in a simple system scenario including two\nadjacent cells, under different fairness criteria that emphasize the bottleneck\nrole of users near the cell \"boundary\". Our results show that \"active\"\nInter-Cell Interference (ICI) mitigation outperforms the conventional \"static\"\nICI mitigation based on fractional frequency reuse. \n\n"}
{"id": "0909.2349", "contents": "Title: Electroexcitation of nucleon resonances from CLAS data on single pion\n  electroproduction Abstract: We present results on the electroexcitation of the low mass resonances\nDelta(1232)P33, N(1440)P11, N(1520)D13, and N(1535)S11 in a wide range of Q2.\nThe results were obtained in the comprehensive analysis of JLab-CLAS data on\ndifferential cross sections, longitudinally polarized beam asymmetries, and\nlongitudinal target and beam-target asymmetries for pion electroproduction off\nthe proton. The data were analysed using two conceptually different approaches,\nfixed-t dispersion relations and a unitary isobar model, allowing us to draw\nconclusions on the model sensitivity of the obtained electrocoupling\namplitudes. The amplitudes for the Delta(1232)P33} show the importance of a\nmeson-cloud contribution to quantitatively explain the magnetic dipole\nstrength, as well as the electric and scalar quadrupole transitions. They do\nnot show any tendency of approaching the pQCD regime for Q2<6 GeV2. For the\nRoper resonance, N(1440)P11, the data provide strong evidence for this state as\na predominantly radial excitation of a 3-quark ground state. Measured in pion\nelectroproduction, the transverse helicity amplitude for the N(1535)S11 allowed\nus to obtain the branching ratios of this state to the piN and etaN channels\nvia comparison to the results extracted from eta electroproduction. The\nextensive CLAS data also enabled the extraction of the gamma*p -> N(1520)D13\nand N(1535)S11 longitudinal helicity amplitudes with good precision. \n\n"}
{"id": "0909.5216", "contents": "Title: Learning Gaussian Tree Models: Analysis of Error Exponents and Extremal\n  Structures Abstract: The problem of learning tree-structured Gaussian graphical models from\nindependent and identically distributed (i.i.d.) samples is considered. The\ninfluence of the tree structure and the parameters of the Gaussian distribution\non the learning rate as the number of samples increases is discussed.\nSpecifically, the error exponent corresponding to the event that the estimated\ntree structure differs from the actual unknown tree structure of the\ndistribution is analyzed. Finding the error exponent reduces to a least-squares\nproblem in the very noisy learning regime. In this regime, it is shown that the\nextremal tree structure that minimizes the error exponent is the star for any\nfixed set of correlation coefficients on the edges of the tree. If the\nmagnitudes of all the correlation coefficients are less than 0.63, it is also\nshown that the tree structure that maximizes the error exponent is the Markov\nchain. In other words, the star and the chain graphs represent the hardest and\nthe easiest structures to learn in the class of tree-structured Gaussian\ngraphical models. This result can also be intuitively explained by correlation\ndecay: pairs of nodes which are far apart, in terms of graph distance, are\nunlikely to be mistaken as edges by the maximum-likelihood estimator in the\nasymptotic regime. \n\n"}
{"id": "0910.1300", "contents": "Title: D-MG Tradeoff of DF and AF Relaying Protocols over Asynchronous PAM\n  Cooperative Networks Abstract: The diversity multiplexing tradeoff of a general two-hop asynchronous\ncooperative network is examined for various relaying protocols such as\nnon-orthogonal selection decode-and-forward (NSDF), orthogonal selection\ndecode-and-forward (OSDF), non-orthogonal amplify-and-forward (NAF), and\northogonal amplify-and-forward (OAF). The transmitter nodes are assumed to send\npulse amplitude modulation (PAM) signals asynchronously, in which information\nsymbols are linearly modulated by a shaping waveform to be sent to the\ndestination. We consider two different cases with respect to the length of the\nshaping waveforms in the time domain. In the theoretical case where the shaping\nwaveforms with infinite time support are used, it is shown that asynchronism\ndoes not affect the DMT performance of the system and the same DMT as that of\nthe corresponding synchronous network is obtained for all the aforementioned\nprotocols. In the practical case where finite length shaping waveforms are\nused, it is shown that better diversity gains can be achieved at the expense of\nbandwidth expansion. In the decode-and-forward (DF) type protocols, the\nasynchronous network provides better diversity gains than those of the\ncorresponding synchronous network throughout the range of the multiplexing\ngain. In the amplify-and-forward (AF) type protocols, the asynchronous network\nprovides the same DMT as that of the corresponding synchronous counterpart\nunder the OAF protocol; however, a better diversity gain is achieved under the\nNAF protocol throughout the range of the multiplexing gain. In particular, in\nthe single relay asynchronous network, the NAF protocol provides the same DMT\nas that of the 2 {\\times} 1 multiple-input single-output (MISO) channel. \n\n"}
{"id": "0911.2346", "contents": "Title: Asymmetric Multilevel Diversity Coding and Asymmetric Gaussian Multiple\n  Descriptions Abstract: We consider the asymmetric multilevel diversity (A-MLD) coding problem, where\na set of $2^K-1$ information sources, ordered in a decreasing level of\nimportance, is encoded into $K$ messages (or descriptions). There are $2^K-1$\ndecoders, each of which has access to a non-empty subset of the encoded\nmessages. Each decoder is required to reproduce the information sources up to a\ncertain importance level depending on the combination of descriptions available\nto it. We obtain a single letter characterization of the achievable rate region\nfor the 3-description problem. In contrast to symmetric multilevel diversity\ncoding, source-separation coding is not sufficient in the asymmetric case, and\nideas akin to network coding need to be used strategically. Based on the\nintuitions gained in treating the A-MLD problem, we derive inner and outer\nbounds for the rate region of the asymmetric Gaussian multiple description (MD)\nproblem with three descriptions. Both the inner and outer bounds have a similar\ngeometric structure to the rate region template of the A-MLD coding problem,\nand moreover, we show that the gap between them is small, which results in an\napproximate characterization of the asymmetric Gaussian three description rate\nregion. \n\n"}
{"id": "0911.4222", "contents": "Title: Message Passing Algorithms for Compressed Sensing: II. Analysis and\n  Validation Abstract: In a recent paper, the authors proposed a new class of low-complexity\niterative thresholding algorithms for reconstructing sparse signals from a\nsmall set of linear measurements \\cite{DMM}. The new algorithms are broadly\nreferred to as AMP, for approximate message passing. This is the second of two\nconference papers describing the derivation of these algorithms, connection\nwith related literature, extensions of original framework, and new empirical\nevidence.\n  This paper describes the state evolution formalism for analyzing these\nalgorithms, and some of the conclusions that can be drawn from this formalism.\nWe carried out extensive numerical simulations to confirm these predictions. We\npresent here a few representative results. \n\n"}
{"id": "0911.4507", "contents": "Title: On Feasibility of Interference Alignment in MIMO Interference Networks Abstract: We explore the feasibility of interference alignment in signal vector space\n-- based only on beamforming -- for K-user MIMO interference channels. Our main\ncontribution is to relate the feasibility issue to the problem of determining\nthe solvability of a multivariate polynomial system, considered extensively in\nalgebraic geometry. It is well known, e.g. from Bezout's theorem, that generic\npolynomial systems are solvable if and only if the number of equations does not\nexceed the number of variables. Following this intuition, we classify signal\nspace interference alignment problems as either proper or improper based on the\nnumber of equations and variables. Rigorous connections between feasible and\nproper systems are made through Bernshtein's theorem for the case where each\ntransmitter uses only one beamforming vector. The multi-beam case introduces\ndependencies among the coefficients of a polynomial system so that the system\nis no longer generic in the sense required by both theorems. In this case, we\nshow that the connection between feasible and proper systems can be further\nstrengthened (since the equivalency between feasible and proper systems does\nnot always hold) by including standard information theoretic outer bounds in\nthe feasibility analysis. \n\n"}
{"id": "0911.4880", "contents": "Title: An Estimation Theoretic Approach for Sparsity Pattern Recovery in the\n  Noisy Setting Abstract: Compressed sensing deals with the reconstruction of sparse signals using a\nsmall number of linear measurements. One of the main challenges in compressed\nsensing is to find the support of a sparse signal. In the literature, several\nbounds on the scaling law of the number of measurements for successful support\nrecovery have been derived where the main focus is on random Gaussian\nmeasurement matrices. In this paper, we investigate the noisy support recovery\nproblem from an estimation theoretic point of view, where no specific\nassumption is made on the underlying measurement matrix. The linear\nmeasurements are perturbed by additive white Gaussian noise. We define the\noutput of a support estimator to be a set of position values in increasing\norder. We set the error between the true and estimated supports as the\n$\\ell_2$-norm of their difference. On the one hand, this choice allows us to\nuse the machinery behind the $\\ell_2$-norm error metric and on the other hand,\nconverts the support recovery into a more intuitive and geometrical problem.\nFirst, by using the Hammersley-Chapman-Robbins (HCR) bound, we derive a\nfundamental lower bound on the performance of any \\emph{unbiased} estimator of\nthe support set. This lower bound provides us with necessary conditions on the\nnumber of measurements for reliable $\\ell_2$-norm support recovery, which we\nspecifically evaluate for uniform Gaussian measurement matrices. Then, we\nanalyze the maximum likelihood estimator and derive conditions under which the\nHCR bound is achievable. This leads us to the number of measurements for the\noptimum decoder which is sufficient for reliable $\\ell_2$-norm support\nrecovery. Using this framework, we specifically evaluate sufficient conditions\nfor uniform Gaussian measurement matrices. \n\n"}
{"id": "0912.1987", "contents": "Title: Training and Feedback Optimization for Multiuser MIMO Downlink Abstract: We consider a MIMO fading broadcast channel where the fading channel\ncoefficients are constant over time-frequency blocks that span a coherent time\n$\\times$ a coherence bandwidth. In closed-loop systems, channel state\ninformation at transmitter (CSIT) is acquired by the downlink training sent by\nthe base station and an explicit feedback from each user terminal. In open-loop\nsystems, CSIT is obtained by exploiting uplink training and channel\nreciprocity. We use a tight closed-form lower bound on the ergodic achievable\nrate in the presence of CSIT errors in order to optimize the overall system\nthroughput, by taking explicitly into account the overhead due to channel\nestimation and channel state feedback. Based on three time-frequency block\nmodels inspired by actual systems, we provide some useful guidelines for the\noverall system optimization. In particular, digital (quantized) feedback is\nfound to offer a substantial advantage over analog (unquantized) feedback. \n\n"}
{"id": "0912.3264", "contents": "Title: Random Access: An Information-Theoretic Perspective Abstract: This paper considers a random access system where each sender can be in two\nmodes of operation, active or not active, and where the set of active users is\navailable to a common receiver only. Active transmitters encode data into\nindependent streams of information, a subset of which are decoded by the\nreceiver, depending on the value of the collective interference. The main\ncontribution is to present an information-theoretic formulation of the problem\nwhich allows us to characterize, with a guaranteed gap to optimality, the rates\nthat can be achieved by different data streams.\n  Our results are articulated as follows. First, we exactly characterize the\ncapacity region of a two-user system assuming a binary-expansion deterministic\nchannel model. Second, we extend this result to a two-user additive white\nGaussian noise channel, providing an approximate characterization within\n$\\sqrt{3}/2$ bit of the actual capacity. Third, we focus on the symmetric\nscenario in which users are active with the same probability and subject to the\nsame received power constraint, and study the maximum achievable expected\nsum-rate, or throughput, for any number of users. In this case, for the\nsymmetric binary expansion deterministic channel (which is related to the\npacket collision model used in the networking literature), we show that a\nsimple coding scheme which does not employ superposition coding achieves the\nsystem throughput. This result also shows that the performance of slotted ALOHA\nsystems can be improved by allowing encoding rate adaptation at the\ntransmitters. For the symmetric additive white Gaussian noise channel, we\npropose a scheme that is within one bit of the system throughput for any value\nof the underlying parameters. \n\n"}
{"id": "1001.0107", "contents": "Title: Exact Regeneration Codes for Distributed Storage Repair Using\n  Interference Alignment Abstract: The high repair cost of (n,k) Maximum Distance Separable (MDS) erasure codes\nhas recently motivated a new class of codes, called Regenerating Codes, that\noptimally trade off storage cost for repair bandwidth. On one end of this\nspectrum of Regenerating Codes are Minimum Storage Regenerating (MSR) codes\nthat can match the minimum storage cost of MDS codes while also significantly\nreducing repair bandwidth. In this paper, we describe Exact-MSR codes which\nallow for any failed nodes (whether they are systematic or parity nodes) to be\nregenerated exactly rather than only functionally or information-equivalently.\nWe show that Exact-MSR codes come with no loss of optimality with respect to\nrandom-network-coding based MSR codes (matching the cutset-based lower bound on\nrepair bandwidth) for the cases of: (a) k/n <= 1/2; and (b) k <= 3. Our\nconstructive approach is based on interference alignment techniques, and,\nunlike the previous class of random-network-coding based approaches, we provide\nexplicit and deterministic coding schemes that require a finite-field size of\nat most 2(n-k). \n\n"}
{"id": "1001.0210", "contents": "Title: Achieving the Secrecy Capacity of Wiretap Channels Using Polar Codes Abstract: Suppose Alice wishes to send messages to Bob through a communication channel\nC_1, but her transmissions also reach an eavesdropper Eve through another\nchannel C_2. The goal is to design a coding scheme that makes it possible for\nAlice to communicate both reliably and securely. Reliability is measured in\nterms of Bob's probability of error in recovering the message, while security\nis measured in terms of Eve's equivocation ratio. Wyner showed that the\nsituation is characterized by a single constant C_s, called the secrecy\ncapacity, which has the following meaning: for all $\\epsilon > 0$, there exist\ncoding schemes of rate $R \\ge C_s - \\epsilon$ that asymptotically achieve both\nthe reliability and the security objectives. However, his proof of this result\nis based upon a nonconstructive random-coding argument. To date, despite a\nconsiderable research effort, the only case where we know how to construct\ncoding schemes that achieve secrecy capacity is when Eve's channel C_2 is an\nerasure channel, or a combinatorial variation thereof.\n  Polar codes were recently invented by Arikan; they approach the capacity of\nsymmetric binary-input discrete memoryless channels with low encoding and\ndecoding complexity. Herein, we use polar codes to construct a coding scheme\nthat achieves the secrecy capacity for a wide range of wiretap channels. Our\nconstruction works for any instantiation of the wiretap channel model, as long\nas both C_1 and C_2 are symmetric and binary-input, and C_2 is degraded with\nrespect to C_1. Moreover, we show how to modify our construction in order to\nprovide strong security, in the sense defined by Maurer, while still operating\nat a rate that approaches the secrecy capacity. In this case, we cannot\nguarantee that the reliability condition will be satisfied unless the main\nchannel C_1 is noiseless, although we believe it can be always satisfied in\npractice. \n\n"}
{"id": "1001.1026", "contents": "Title: On Network-Error Correcting Convolutional Codes under the BSC Edge Error\n  Model Abstract: Convolutional network-error correcting codes (CNECCs) are known to provide\nerror correcting capability in acyclic instantaneous networks within the\nnetwork coding paradigm under small field size conditions. In this work, we\ninvestigate the performance of CNECCs under the error model of the network\nwhere the edges are assumed to be statistically independent binary symmetric\nchannels, each with the same probability of error $p_e$($0\\leq p_e<0.5$). We\nobtain bounds on the performance of such CNECCs based on a modified generating\nfunction (the transfer function) of the CNECCs. For a given network, we derive\na mathematical condition on how small $p_e$ should be so that only single edge\nnetwork-errors need to be accounted for, thus reducing the complexity of\nevaluating the probability of error of any CNECC. Simulations indicate that\nconvolutional codes are required to possess different properties to achieve\ngood performance in low $p_e$ and high $p_e$ regimes. For the low $p_e$ regime,\nconvolutional codes with good distance properties show good performance. For\nthe high $p_e$ regime, convolutional codes that have a good \\textit{slope} (the\nminimum normalized cycle weight) are seen to be good. We derive a lower bound\non the slope of any rate $b/c$ convolutional code with a certain degree. \n\n"}
{"id": "1001.2284", "contents": "Title: An Efficient Approach Toward the Asymptotic Analysis of Node-Based\n  Recovery Algorithms in Compressed Sensing Abstract: In this paper, we propose a general framework for the asymptotic analysis of\nnode-based verification-based algorithms. In our analysis we tend the signal\nlength $n$ to infinity. We also let the number of non-zero elements of the\nsignal $k$ scale linearly with $n$. Using the proposed framework, we study the\nasymptotic behavior of the recovery algorithms over random sparse matrices\n(graphs) in the context of compressive sensing. Our analysis shows that there\nexists a success threshold on the density ratio $k/n$, before which the\nrecovery algorithms are successful, and beyond which they fail. This threshold\nis a function of both the graph and the recovery algorithm. We also demonstrate\nthat there is a good agreement between the asymptotic behavior of recovery\nalgorithms and finite length simulations for moderately large values of $n$. \n\n"}
{"id": "1001.2307", "contents": "Title: Tranceiver Design using Linear Precoding in a Multiuser MIMO System with\n  Limited Feedback Abstract: We investigate quantization and feedback of channel state information in a\nmultiuser (MU) multiple input multiple output (MIMO) system. Each user may\nreceive multiple data streams. Our design minimizes the sum mean squared error\n(SMSE) while accounting for the imperfections in channel state information\n(CSI) at the transmitter. This paper makes three contributions: first, we\nprovide an end-to-end SMSE transceiver design that incorporates receiver\ncombining, feedback policy and transmit precoder design with channel\nuncertainty. This enables the proposed transceiver to outperform the previously\nderived limited feedback MU linear transceivers. Second, we remove\ndimensionality constraints on the MIMO system, for the scenario with multiple\ndata streams per user, using a combination of maximum expected signal combining\n(MESC) and minimum MSE receiver. This makes the feedback of each user\nindependent of the others and the resulting feedback overhead scales linearly\nwith the number of data streams instead of the number of receiving antennas.\nFinally, we analyze SMSE of the proposed algorithm at high signal-to-noise\nratio (SNR) and large number of transmit antennas. As an aside, we show\nanalytically why the bit error rate, in the high SNR regime, increases if\nquantization error is ignored. \n\n"}
{"id": "1002.0182", "contents": "Title: Sobolev Duals for Random Frames and Sigma-Delta Quantization of\n  Compressed Sensing Measurements Abstract: Quantization of compressed sensing measurements is typically justified by the\nrobust recovery results of Cand\\`es, Romberg and Tao, and of Donoho. These\nresults guarantee that if a uniform quantizer of step size $\\delta$ is used to\nquantize $m$ measurements $y = \\Phi x$ of a $k$-sparse signal $x \\in \\R^N$,\nwhere $\\Phi$ satisfies the restricted isometry property, then the approximate\nrecovery $x^#$ via $\\ell_1$-minimization is within $O(\\delta)$ of $x$. The\nsimplest and commonly assumed approach is to quantize each measurement\nindependently. In this paper, we show that if instead an $r$th order\n$\\Sigma\\Delta$ quantization scheme with the same output alphabet is used to\nquantize $y$, then there is an alternative recovery method via Sobolev dual\nframes which guarantees a reduction of the approximation error by a factor of\n$(m/k)^{(r-1/2)\\alpha}$ for any $0 < \\alpha < 1$, if $m \\gtrsim_r k (\\log\nN)^{1/(1-\\alpha)}$. The result holds with high probability on the initial draw\nof the measurement matrix $\\Phi$ from the Gaussian distribution, and uniformly\nfor all $k$-sparse signals $x$ that satisfy a mild size condition on their\nsupports. \n\n"}
{"id": "1002.1313", "contents": "Title: Half-Duplex Active Eavesdropping in Fast Fading Channels: A Block-Markov\n  Wyner Secrecy Encoding Scheme Abstract: In this paper we study the problem of half-duplex active eavesdropping in\nfast fading channels. The active eavesdropper is a more powerful adversary than\nthe classical eavesdropper. It can choose between two functional modes:\neavesdropping the transmission between the legitimate parties (Ex mode), and\njamming it (Jx mode) -- the active eavesdropper cannot function in full duplex\nmode. We consider a conservative scenario, when the active eavesdropper can\nchoose its strategy based on the legitimate transmitter-receiver pair's\nstrategy -- and thus the transmitter and legitimate receiver have to plan for\nthe worst. We show that conventional physical-layer secrecy approaches perform\npoorly (if at all), and we introduce a novel encoding scheme, based on very\nlimited and unsecured feedback -- the Block-Markov Wyner (BMW) encoding scheme\n-- which outperforms any schemes currently available. \n\n"}
{"id": "1002.1738", "contents": "Title: The Isospin Dependence Of The Nuclear Equation Of State Near The\n  Critical Point Abstract: We discuss experimental evidence for a nuclear phase transition driven by the\ndifferent concentration of neutrons to protons. Different ratios of the neutron\nto proton concentrations lead to different critical points for the phase\ntransition. This is analogous to the phase transitions occurring in 4He-3He\nliquid mixtures. We present experimental results which reveal the N/A (or Z/A)\ndependence of the phase transition and discuss possible implications of these\nobservations in terms of the Landau Free Energy description of critical\nphenomena. \n\n"}
{"id": "1002.4548", "contents": "Title: Interference Alignment for the Multi-Antenna Compound Wiretap Channel Abstract: We study a wiretap channel model where the sender has $M$ transmit antennas\nand there are two groups consisting of $J_1$ and $J_2$ receivers respectively.\nEach receiver has a single antenna. We consider two scenarios. First we\nconsider the compound wiretap model -- group 1 constitutes the set of\nlegitimate receivers, all interested in a common message, whereas group 2 is\nthe set of eavesdroppers. We establish new lower and upper bounds on the secure\ndegrees of freedom. Our lower bound is based on the recently proposed\n\\emph{real interference alignment} scheme. The upper bound provides the first\nknown example which illustrates that the \\emph{pairwise upper bound} used in\nearlier works is not tight.\n  The second scenario we study is the compound private broadcast channel. Each\ngroup is interested in a message that must be protected from the other group.\nUpper and lower bounds on the degrees of freedom are developed by extending the\nresults on the compound wiretap channel. \n\n"}
{"id": "1002.5026", "contents": "Title: Capacity Region of Gaussian MIMO Broadcast Channels with Common and\n  Confidential Messages Abstract: We study the two-user Gaussian multiple-input multiple-output (MIMO)\nbroadcast channel with common and confidential messages. In this channel, the\ntransmitter sends a common message to both users, and a confidential message to\neach user which needs to be kept perfectly secret from the other user. We\nobtain the entire capacity region of this channel. We also explore the\nconnections between the capacity region we obtain for the Gaussian MIMO\nbroadcast channel with common and confidential messages and the capacity region\nof its non-confidential counterpart, i.e., the Gaussian MIMO broadcast channel\nwith common and private messages, which is not known completely. \n\n"}
{"id": "1003.0064", "contents": "Title: Decoding by Sampling: A Randomized Lattice Algorithm for Bounded\n  Distance Decoding Abstract: Despite its reduced complexity, lattice reduction-aided decoding exhibits a\nwidening gap to maximum-likelihood (ML) performance as the dimension increases.\nTo improve its performance, this paper presents randomized lattice decoding\nbased on Klein's sampling technique, which is a randomized version of Babai's\nnearest plane algorithm (i.e., successive interference cancelation (SIC)). To\nfind the closest lattice point, Klein's algorithm is used to sample some\nlattice points and the closest among those samples is chosen. Lattice reduction\nincreases the probability of finding the closest lattice point, and only needs\nto be run once during pre-processing. Further, the sampling can operate very\nefficiently in parallel. The technical contribution of this paper is two-fold:\nwe analyze and optimize the decoding radius of sampling decoding resulting in\nbetter error performance than Klein's original algorithm, and propose a very\nefficient implementation of random rounding. Of particular interest is that a\nfixed gain in the decoding radius compared to Babai's decoding can be achieved\nat polynomial complexity. The proposed decoder is useful for moderate\ndimensions where sphere decoding becomes computationally intensive, while\nlattice reduction-aided decoding starts to suffer considerable loss. Simulation\nresults demonstrate near-ML performance is achieved by a moderate number of\nsamples, even if the dimension is as high as 32. \n\n"}
{"id": "1003.0488", "contents": "Title: On Secure Distributed Data Storage Under Repair Dynamics Abstract: We address the problem of securing distributed storage systems against\npassive eavesdroppers that can observe a limited number of storage nodes. An\nimportant aspect of these systems is node failures over time, which demand a\nrepair mechanism aimed at maintaining a targeted high level of system\nreliability. If an eavesdropper observes a node that is added to the system to\nreplace a failed node, it will have access to all the data downloaded during\nrepair, which can potentially compromise the entire information in the system.\nWe are interested in determining the secrecy capacity of distributed storage\nsystems under repair dynamics, i.e., the maximum amount of data that can be\nsecurely stored and made available to a legitimate user without revealing any\ninformation to any eavesdropper. We derive a general upper bound on the secrecy\ncapacity and show that this bound is tight for the bandwidth-limited regime\nwhich is of importance in scenarios such as peer-to-peer distributed storage\nsystems. We also provide a simple explicit code construction that achieves the\ncapacity for this regime. \n\n"}
{"id": "1004.4075", "contents": "Title: Secrecy Gain: a Wiretap Lattice Code Design Abstract: We propose the notion of secrecy gain as a code design criterion for wiretap\nlattice codes to be used over an additive white Gaussian noise channel. Our\nanalysis relies on the error probabilites of both the legitimate user and the\neavesdropper. We focus on geometrical properties of lattices, described by\ntheir theta series, to characterize good wiretap codes. \n\n"}
{"id": "1004.5189", "contents": "Title: Rate-distortion function via minimum mean square error estimation Abstract: We derive a simple general parametric representation of the rate-distortion\nfunction of a memoryless source, where both the rate and the distortion are\ngiven by integrals whose integrands include the minimum mean square error\n(MMSE) of the distortion $\\Delta=d(X,Y)$ based on the source symbol $X$, with\nrespect to a certain joint distribution of these two random variables. At first\nglance, these relations may seem somewhat similar to the I-MMSE relations due\nto Guo, Shamai and Verd\\'u, but they are, in fact, quite different. The new\nrelations among rate, distortion, and MMSE are discussed from several aspects,\nand more importantly, it is demonstrated that they can sometimes be rather\nuseful for obtaining non-trivial upper and lower bounds on the rate-distortion\nfunction, as well as for determining the exact asymptotic behavior for very low\nand for very large distortion. Analogous MMSE relations hold for channel\ncapacity as well. \n\n"}
{"id": "1005.2710", "contents": "Title: Capacity of a Class of Multicast Tree Networks Abstract: In this paper, we characterize the capacity of a new class of single-source\nmulticast discrete memoryless relay networks having a tree topology in which\nthe root node is the source and each parent node in the graph has at most one\nnoisy child node and any number of noiseless child nodes. This class of\nmulticast tree networks includes the class of diamond networks studied by Kang\nand Ulukus as a special case, where they showed that the capacity can be\nstrictly lower than the cut-set bound. For achievablity, a novel coding scheme\nis constructed where each noisy relay employs a combination of\ndecode-and-forward (DF) and compress-and-forward (CF) and each noiseless relay\nperforms a random binning such that codebook constructions and relay operations\nare independent for each node and do not depend on the network topology. For\nconverse, a new technique of iteratively manipulating inequalities exploiting\nthe tree topology is used. \n\n"}
{"id": "1005.3486", "contents": "Title: Exploration of AWGNC and BSC Pseudocodeword Redundancy Abstract: The AWGNC, BSC, and max-fractional pseudocodeword redundancy of a code is\ndefined as the smallest number of rows in a parity-check matrix such that the\ncorresponding minimum pseudoweight is equal to the minimum Hamming distance of\nthe code. This paper provides new results on the AWGNC, BSC, and max-fractional\npseudocodeword redundancies of codes. The pseudocodeword redundancies for all\ncodes of small length (at most 9) are computed. Also, comprehensive results are\nprovided on the cases of cyclic codes of length at most 250 for which the\neigenvalue bound of Vontobel and Koetter is sharp. \n\n"}
{"id": "1006.0619", "contents": "Title: Spectrum Sharing in Cognitive Radio with Quantized Channel Information Abstract: We consider a wideband spectrum sharing system where a secondary user can\nshare a number of orthogonal frequency bands where each band is licensed to an\nindividual primary user. We address the problem of optimum secondary transmit\npower allocation for its ergodic capacity maximization subject to an average\nsum (across the bands) transmit power constraint and individual average\ninterference constraints on the primary users. The major contribution of our\nwork lies in considering quantized channel state information (CSI)(for the\nvector channel space consisting of all secondary-to-secondary and\nsecondary-to-primary channels) at the secondary transmitter. It is assumed that\na band manager or a cognitive radio service provider has access to the full CSI\ninformation from the secondary and primary receivers and designs (offline) an\noptimal power codebook based on the statistical information (channel\ndistributions) of the channels and feeds back the index of the codebook to the\nsecondary transmitter for every channel realization in real-time, via a\ndelay-free noiseless limited feedback channel. A modified Generalized\nLloyds-type algorithm (GLA) is designed for deriving the optimal power\ncodebook. An approximate quantized power allocation (AQPA) algorithm is also\npresented, that performs very close to its GLA based counterpart for large\nnumber of feedback bits and is significantly faster. We also present an\nextension of the modified GLA based quantized power codebook design algorithm\nfor the case when the feedback channel is noisy. Numerical studies illustrate\nthat with only 3-4 bits of feedback, the modified GLA based algorithms provide\nsecondary ergodic capacity very close to that achieved by full CSI and with\nonly as little as 4 bits of feedback, AQPA provides a comparable performance,\nthus making it an attractive choice for practical implementation. \n\n"}
{"id": "1006.4255", "contents": "Title: Polar codes for the two-user multiple-access channel Abstract: Arikan's polar coding method is extended to two-user multiple-access\nchannels. It is shown that if the two users of the channel use the Arikan\nconstruction, the resulting channels will polarize to one of five possible\nextremals, on each of which uncoded transmission is optimal. The sum rate\nachieved by this coding technique is the one that correponds to uniform input\ndistributions. The encoding and decoding complexities and the error performance\nof these codes are as in the single-user case: $O(n\\log n)$ for encoding and\ndecoding, and $o(\\exp(-n^{1/2-\\epsilon}))$ for block error probability, where\n$n$ is the block length. \n\n"}
{"id": "1007.0563", "contents": "Title: Graphical Models as Block-Tree Graphs Abstract: We introduce block-tree graphs as a framework for deriving efficient\nalgorithms on graphical models. We define block-tree graphs as a\ntree-structured graph where each node is a cluster of nodes such that the\nclusters in the graph are disjoint. This differs from junction-trees, where two\nclusters connected by an edge always have at least one common node. When\ncompared to junction-trees, we show that constructing block-tree graphs is\nfaster, and finding optimal block-tree graphs has a much smaller search space.\nApplying our block-tree graph framework to graphical models, we show that, for\nsome graphs, e.g., grid graphs, using block-tree graphs for inference is\ncomputationally more efficient than using junction-trees. For graphical models\nwith boundary conditions, the block-tree graph framework transforms the\nboundary valued problem into an initial value problem. For Gaussian graphical\nmodels, the block-tree graph framework leads to a linear state-space\nrepresentation. Since exact inference in graphical models can be\ncomputationally intractable, we propose to use spanning block-trees to derive\napproximate inference algorithms. Experimental results show the improved\nperformance in using spanning block-trees versus using spanning trees for\napproximate estimation over Gaussian graphical models. \n\n"}
{"id": "1007.1697", "contents": "Title: Quantum Cyclic Code Abstract: In this paper, we define and study \\emph{quantum cyclic codes}, a\ngeneralisation of cyclic codes to the quantum setting. Previously studied\nexamples of quantum cyclic codes were all quantum codes obtained from classical\ncyclic codes via the CSS construction. However, the codes that we study are\nmuch more general. In particular, we construct cyclic stabiliser codes with\nparameters $[[5,1,3]]$, $[[17,1,7]]$ and $[[17,9,3]]$, all of which are\n\\emph{not} CSS. The $[[5,1,3]]$ code is the well known Laflamme code and to the\nbest of our knowledge the other two are new examples. Our definition of\ncyclicity applies to non-stabiliser codes as well; in fact we show that the\n$((5,6,2))$ nonstabiliser first constructed by Rains\\etal~\ncite{rains97nonadditive} and latter by Arvind\n\\etal~\\cite{arvind:2004:nonstabilizer} is cyclic. We also study stabiliser\ncodes of length $4^m +1$ over $\\mathbb{F}_2$ for which we define a notation of\nBCH distance. Much like the Berlekamp decoding algorithm for classical BCH\ncodes, we give efficient quantum algorithms to correct up to\n$\\floor{\\frac{d-1}{2}}$ errors when the BCH distance is $d$. \n\n"}
{"id": "1007.3027", "contents": "Title: Impact of Neutron Decay Experiments on non-Standard Model Physics Abstract: This paper gives a brief overview of the present and expected future limits\non physics beyond the Standard Model (SM) from neutron beta decay, which is\ndescribed by two parameters only within the SM. Since more than two observables\nare accessible, the problem is over-determined. Thus, precise measurements of\ncorrelations in neutron decay can be used to study the SM as well to search for\nevidence of possible extensions to it. Of particular interest in this context\nare the search for right-handed currents or for scalar and tensor interactions.\nPrecision measurements of neutron decay observables address important open\nquestions of particle physics and cosmology, and are generally complementary to\ndirect searches for new physics beyond the SM in high-energy physics. Free\nneutron decay is therefore a very active field, with a number of new\nmeasurements underway worldwide. We present the impact of recent developments. \n\n"}
{"id": "1007.3808", "contents": "Title: Characterization of Graph-cover Pseudocodewords of Codes over $F_3$ Abstract: Linear-programming pseudocodewords play a pivotal role in our understanding\nof the linear-programming decoding algorithms. These pseudocodewords are known\nto be equivalent to the graph-cover pseudocodewords. The latter\npseudocodewords, when viewed as points in the multidimensional Euclidean space,\nlie inside a fundamental cone. This fundamental cone depends on the choice of a\nparity-check matrix of a code, rather than on the choice of the code itself.\nThe cone does not depend on the channel, over which the code is employed. The\nknowledge of the boundaries of the fundamental cone could help in studying\nvarious properties of the pseudocodewords, such as their minimum pseudoweight,\npseudoredundancy of the codes, etc. For the binary codes, the full\ncharacterization of the fundamental cone was derived by Koetter et al. However,\nif the underlying alphabet is large, such characterization becom is more\ninvolved. In this work, a characterization of the fundamental cone for codes\nover $F_3$ is discussed. \n\n"}
{"id": "1007.4112", "contents": "Title: Interference Alignment for Clustered Multicell Joint Decoding Abstract: Multicell joint processing has been proven to be very efficient in overcoming\nthe interference-limited nature of the cellular paradigm. However, for reasons\nof practical implementation global multicell joint decoding is not feasible and\nthus clusters of cooperating Base Stations have to be considered. In this\ncontext, intercluster interference has to be mitigated in order to harvest the\nfull potential of multicell joint processing. In this paper, four scenarios of\nintercluster interference are investigated, namely a) global multicell joint\nprocessing, b) interference alignment, c) resource division multiple access and\nd) cochannel interference allowance. Each scenario is modelled and analyzed\nusing the per-cell ergodic sum-rate capacity as a figure of merit. In this\nprocess, a number of theorems are derived for analytically expressing the\nasymptotic eigenvalue distributions of the channel covariance matrices. The\nanalysis is based on principles from Free Probability theory and especially\nproperties in the R and Stieltjes transform domain. \n\n"}
{"id": "1007.5456", "contents": "Title: One-Shot Classical-Quantum Capacity and Hypothesis Testing Abstract: The one-shot classical capacity of a quantum channel quantifies the amount of\nclassical information that can be transmitted through a single use of the\nchannel such that the error probability is below a certain threshold. In this\nwork, we show that this capacity is well approximated by a\nrelative-entropy-type measure defined via hypothesis testing. Combined with a\nquantum version of Stein's lemma, our results give a conceptually simple proof\nof the well-known Holevo-Schumacher-Westmoreland theorem for the capacity of\nmemoryless channels. More generally, we obtain tight capacity formulas for\narbitrary (not necessarily memoryless) channels. \n\n"}
{"id": "1008.2526", "contents": "Title: Low ML Decoding Complexity STBCs via Codes over GF(4) Abstract: In this paper, we give a new framework for constructing low ML decoding\ncomplexity Space-Time Block Codes (STBCs) using codes over the finite field\n$\\mathbb{F}_4$. Almost all known low ML decoding complexity STBCs can be\nobtained via this approach. New full-diversity STBCs with low ML decoding\ncomplexity and cubic shaping property are constructed, via codes over\n$\\mathbb{F}_4$, for number of transmit antennas \\mbox{$N=2^m$}, \\mbox{$m \\geq\n1$}, and rates \\mbox{$R>1$} complex symbols per channel use. When \\mbox{$R=N$},\nthe new STBCs are information-lossless as well. The new class of STBCs have the\nleast known ML decoding complexity among all the codes available in the\nliterature for a large set of \\mbox{$(N,R)$} pairs. \n\n"}
{"id": "1009.2722", "contents": "Title: Learning Latent Tree Graphical Models Abstract: We study the problem of learning a latent tree graphical model where samples\nare available only from a subset of variables. We propose two consistent and\ncomputationally efficient algorithms for learning minimal latent trees, that\nis, trees without any redundant hidden nodes. Unlike many existing methods, the\nobserved nodes (or variables) are not constrained to be leaf nodes. Our first\nalgorithm, recursive grouping, builds the latent tree recursively by\nidentifying sibling groups using so-called information distances. One of the\nmain contributions of this work is our second algorithm, which we refer to as\nCLGrouping. CLGrouping starts with a pre-processing procedure in which a tree\nover the observed variables is constructed. This global step groups the\nobserved nodes that are likely to be close to each other in the true latent\ntree, thereby guiding subsequent recursive grouping (or equivalent procedures)\non much smaller subsets of variables. This results in more accurate and\nefficient learning of latent trees. We also present regularized versions of our\nalgorithms that learn latent tree approximations of arbitrary distributions. We\ncompare the proposed algorithms to other methods by performing extensive\nnumerical experiments on various latent tree graphical models such as hidden\nMarkov models and star graphs. In addition, we demonstrate the applicability of\nour methods on real-world datasets by modeling the dependency structure of\nmonthly stock returns in the S&P index and of the words in the 20 newsgroups\ndataset. \n\n"}
{"id": "1009.3041", "contents": "Title: Secret Sharing LDPC Codes for the BPSK-constrained Gaussian Wiretap\n  Channel Abstract: The problem of secret sharing over the Gaussian wiretap channel is\nconsidered. A source and a destination intend to share secret information over\na Gaussian channel in the presence of a wiretapper who observes the\ntransmission through another Gaussian channel. Two constraints are imposed on\nthe source-to-destination channel; namely, the source can transmit only binary\nphase shift keyed (BPSK) symbols, and symbol-by-symbol hard-decision\nquantization is applied to the received symbols of the destination. An\nerror-free public channel is also available for the source and destination to\nexchange messages in order to help the secret sharing process. The wiretapper\ncan perfectly observe all messages in the public channel. It is shown that a\nsecret sharing scheme that employs a random ensemble of regular low density\nparity check (LDPC) codes can achieve the key capacity of the BPSK-constrained\nGaussian wiretap channel asymptotically with increasing block length. To\naccommodate practical constraints of finite block length and limited decoding\ncomplexity, fixed irregular LDPC codes are also designed to replace the regular\nLDPC code ensemble in the proposed secret sharing scheme. \n\n"}
{"id": "1009.3387", "contents": "Title: Distributed STBCs with Full-diversity Partial Interference Cancellation\n  Decoding Abstract: Recently, Guo and Xia introduced low complexity decoders called Partial\nInterference Cancellation (PIC) and PIC with Successive Interference\nCancellation (PIC-SIC), which include the Zero Forcing (ZF) and ZF-SIC\nreceivers as special cases, for point-to-point MIMO channels. In this paper, we\nshow that PIC and PIC-SIC decoders are capable of achieving the full\ncooperative diversity available in wireless relay networks. We give sufficient\nconditions for a Distributed Space-Time Block Code (DSTBC) to achieve full\ndiversity with PIC and PIC-SIC decoders and construct a new class of DSTBCs\nwith low complexity full-diversity PIC-SIC decoding using complex orthogonal\ndesigns. The new class of codes includes a number of known full-diversity\nPIC/PIC-SIC decodable Space-Time Block Codes (STBCs) constructed for\npoint-to-point channels as special cases. The proposed DSTBCs achieve higher\nrates (in complex symbols per channel use) than the multigroup ML decodable\nDSTBCs available in the literature. Simulation results show that the proposed\ncodes have better bit error rate performance than the best known low\ncomplexity, full-diversity DSTBCs. \n\n"}
{"id": "1009.4352", "contents": "Title: An Iterative Joint Linear-Programming Decoding of LDPC Codes and\n  Finite-State Channels Abstract: In this paper, we introduce an efficient iterative solver for the joint\nlinear-programming (LP) decoding of low-density parity-check (LDPC) codes and\nfinite-state channels (FSCs). In particular, we extend the approach of\niterative approximate LP decoding, proposed by Vontobel and Koetter and\nexplored by Burshtein, to this problem. By taking advantage of the dual-domain\nstructure of the joint decoding LP, we obtain a convergent iterative algorithm\nfor joint LP decoding whose structure is similar to BCJR-based turbo\nequalization (TE). The result is a joint iterative decoder whose complexity is\nsimilar to TE but whose performance is similar to joint LP decoding. The main\nadvantage of this decoder is that it appears to provide the predictability of\njoint LP decoding and superior performance with the computational complexity of\nTE. \n\n"}
{"id": "1009.6057", "contents": "Title: Network Flows for Functions Abstract: We consider in-network computation of an arbitrary function over an arbitrary\ncommunication network. A network with capacity constraints on the links is\ngiven. Some nodes in the network generate data, e.g., like sensor nodes in a\nsensor network. An arbitrary function of this distributed data is to be\nobtained at a terminal node. The structure of the function is described by a\ngiven computation schema, which in turn is represented by a directed tree. We\ndesign computing and communicating schemes to obtain the function at the\nterminal at the maximum rate. For this, we formulate linear programs to\ndetermine network flows that maximize the computation rate. We then develop\nfast combinatorial primal-dual algorithm to obtain $\\epsilon$-approximate\nsolutions to these linear programs. We then briefly describe extensions of our\ntechniques to the cases of multiple terminals wanting different functions,\nmultiple computation schemas for a function, computation with a given desired\nprecision, and to networks with energy constraints at nodes. \n\n"}
{"id": "1010.1016", "contents": "Title: Multilevel Coding Schemes for Compute-and-Forward Abstract: We investigate techniques for designing modulation/coding schemes for the\nwireless two-way relaying channel. The relay is assumed to have perfect channel\nstate information, but the transmitters are assumed to have no channel state\ninformation. We consider physical layer network coding based on multilevel\ncoding techniques. Our multilevel coding framework is inspired by the\ncompute-and-forward relaying protocol. Indeed, we show that the framework\ndeveloped here naturally facilitates decoding of linear combinations of\ncodewords for forwarding by the relay node. We develop our framework with\ngeneral modulation formats in mind, but numerical results are presented for the\ncase where each node transmits using the QPSK constellation with gray labeling.\nWe focus our discussion on the rates at which the relay may reliably decode\nlinear combinations of codewords transmitted from the end nodes. \n\n"}
{"id": "1010.1358", "contents": "Title: Tight exponential analysis of universally composable privacy\n  amplification and its applications Abstract: Motivated by the desirability of universal composability, we analyze in terms\nof L_1 distinguishability the task of secret key generation from a joint random\nvariable. Under this secrecy criterion, using the Renyi entropy of order 1+s\nfor s in [0,1, we derive a new upper bound of Eve's distinguishability under\nthe application of the universal2 hash functions. It is also shown that this\nbound gives the tight exponential rate of decrease in the case of independent\nand identical distributions. The result is applied to the wire-tap channel\nmodel and to secret key generation (distillation) by public discussion. \n\n"}
{"id": "1010.6057", "contents": "Title: Ergodic Secret Alignment Abstract: In this paper, we introduce two new achievable schemes for the fading\nmultiple access wiretap channel (MAC-WT). In the model that we consider, we\nassume that perfect knowledge of the state of all channels is available at all\nthe nodes in a causal fashion. Our schemes use this knowledge together with the\ntime varying nature of the channel model to align the interference from\ndifferent users at the eavesdropper perfectly in a one-dimensional space while\ncreating a higher dimensionality space for the interfering signals at the\nlegitimate receiver hence allowing for better chance of recovery. While we\nachieve this alignment through signal scaling at the transmitters in our first\nscheme (scaling based alignment (SBA)), we let nature provide this alignment\nthrough the ergodicity of the channel coefficients in the second scheme\n(ergodic secret alignment (ESA)). For each scheme, we obtain the resulting\nachievable secrecy rate region. We show that the secrecy rates achieved by both\nschemes scale with SNR as 1/2log(SNR). Hence, we show the sub-optimality of the\ni.i.d. Gaussian signaling based schemes with and without cooperative jamming by\nshowing that the secrecy rates achieved using i.i.d. Gaussian signaling with\ncooperative jamming do not scale with SNR. In addition, we introduce an\nimproved version of our ESA scheme where we incorporate cooperative jamming to\nachieve higher secrecy rates. Moreover, we derive the necessary optimality\nconditions for the power control policy that maximizes the secrecy sum rate\nachievable by our ESA scheme when used solely and with cooperative jamming. \n\n"}
{"id": "1010.6280", "contents": "Title: Optimum Transmission Policies for Battery Limited Energy Harvesting\n  Nodes Abstract: Wireless networks with energy harvesting battery powered nodes are quickly\nemerging as a viable option for future wireless networks with extended\nlifetime. Equally important to their counterpart in the design of energy\nharvesting radios are the design principles that this new networking paradigm\ncalls for. In particular, unlike wireless networks considered up to date, the\nenergy replenishment process and the storage constraints of the rechargeable\nbatteries need to be taken into account in designing efficient transmission\nstrategies. In this work, we consider such transmission policies for\nrechargeable nodes, and identify the optimum solution for two related problems.\nSpecifically, the transmission policy that maximizes the short term throughput,\ni.e., the amount of data transmitted in a finite time horizon is found. In\naddition, we show the relation of this optimization problem to another, namely,\nthe minimization of the transmission completion time for a given amount of\ndata, and solve that as well. The transmission policies are identified under\nthe constraints on energy causality, i.e., energy replenishment process, as\nwell as the energy storage, i.e., battery capacity. The power-rate relationship\nfor this problem is assumed to be an increasing concave function, as dictated\nby information theory. For battery replenishment, a model with discrete packets\nof energy arrivals is considered. We derive the necessary conditions that the\nthroughput-optimal allocation satisfies, and then provide the algorithm that\nfinds the optimal transmission policy with respect to the short-term throughput\nand the minimum transmission completion time. Numerical results are presented\nto confirm the analytical findings. \n\n"}
{"id": "1011.0786", "contents": "Title: Gaussian Process Techniques for Wireless Communications Abstract: Bayesian filtering is a general framework for recursively estimating the\nstate of a dynamical system. Classical solutions such that Kalman filter and\nParticle filter are introduced in this report. Gaussian processes have been\nintroduced as a non-parametric technique for system estimation from supervision\nlearning. For the thesis project, we intend to propose a new, general\nmethodology for inference and learning in non-linear state-space models\nprobabilistically incorporating with the Gaussian process model estimation. \n\n"}
{"id": "1011.1261", "contents": "Title: On the Saddle-point Solution and the Large-Coalition Asymptotics of\n  Fingerprinting Games Abstract: We study a fingerprinting game in which the number of colluders and the\ncollusion channel are unknown. The encoder embeds fingerprints into a host\nsequence and provides the decoder with the capability to trace back pirated\ncopies to the colluders.\n  Fingerprinting capacity has recently been derived as the limit value of a\nsequence of maximin games with mutual information as their payoff functions.\nHowever, these games generally do not admit saddle-point solutions and are very\nhard to solve numerically. Here under the so-called Boneh-Shaw marking\nassumption, we reformulate the capacity as the value of a single two-person\nzero-sum game, and show that it is achieved by a saddle-point solution.\n  If the maximal coalition size is k and the fingerprinting alphabet is binary,\nwe show that capacity decays quadratically with k. Furthermore, we prove\nrigorously that the asymptotic capacity is 1/(k^2 2ln2) and we confirm our\nearlier conjecture that Tardos' choice of the arcsine distribution\nasymptotically maximizes the mutual information payoff function while the\ninterleaving attack minimizes it. Along with the asymptotic behavior, numerical\nsolutions to the game for small k are also presented. \n\n"}
{"id": "1011.1677", "contents": "Title: Convergence Rate Analysis of Distributed Gossip (Linear Parameter)\n  Estimation: Fundamental Limits and Tradeoffs Abstract: The paper considers gossip distributed estimation of a (static) distributed\nrandom field (a.k.a., large scale unknown parameter vector) observed by\nsparsely interconnected sensors, each of which only observes a small fraction\nof the field. We consider linear distributed estimators whose structure\ncombines the information \\emph{flow} among sensors (the \\emph{consensus} term\nresulting from the local gossiping exchange among sensors when they are able to\ncommunicate) and the information \\emph{gathering} measured by the sensors (the\n\\emph{sensing} or \\emph{innovations} term.) This leads to mixed time scale\nalgorithms--one time scale associated with the consensus and the other with the\ninnovations. The paper establishes a distributed observability condition\n(global observability plus mean connectedness) under which the distributed\nestimates are consistent and asymptotically normal. We introduce the\ndistributed notion equivalent to the (centralized) Fisher information rate,\nwhich is a bound on the mean square error reduction rate of any distributed\nestimator; we show that under the appropriate modeling and structural network\ncommunication conditions (gossip protocol) the distributed gossip estimator\nattains this distributed Fisher information rate, asymptotically achieving the\nperformance of the optimal centralized estimator. Finally, we study the\nbehavior of the distributed gossip estimator when the measurements fade (noise\nvariance grows) with time; in particular, we consider the maximum rate at which\nthe noise variance can grow and still the distributed estimator being\nconsistent, by showing that, as long as the centralized estimator is\nconsistent, the distributed estimator remains consistent. \n\n"}
{"id": "1011.2644", "contents": "Title: Do AES encryptions act randomly? Abstract: The Advanced Encryption Standard (AES) is widely recognized as the most\nimportant block cipher in common use nowadays. This high assurance in AES is\ngiven by its resistance to ten years of extensive cryptanalysis, that has shown\nno weakness, not even any deviation from the statistical behaviour expected\nfrom a random permutation. Only reduced versions of the ciphers have been\nbroken, but they are not usually implemented. In this paper we build a\ndistinguishing attack on the AES, exploiting the properties of a novel cipher\nembedding. With our attack we give some statistical evidence that the set of\nAES-$128$ encryptions acts on the message space in a way significantly\ndifferent than that of the set of random permutations acting on the same space.\nWhile we feel that more computational experiments by independent third parties\nare needed in order to validate our statistical results, we show that the\nnon-random behaviour is the same as we would predict using the property of our\nembedding. Indeed, the embedding lowers the nonlinearity of the AES rounds and\ntherefore the AES encryptions tend, on average, to keep low the rank of\nlow-rank matrices constructed in the large space. Our attack needs $2^{23}$\nplaintext-ciphertext pairs and costs the equivalent of $2^{48}$ encryptions.\n  We expect our attack to work also for AES-$192$ and AES-$256$, as confirmed\nby preliminary experiments. \n\n"}
{"id": "1011.2797", "contents": "Title: When are microcircuits well-modeled by maximum entropy methods? Abstract: Describing the collective activity of neural populations is a daunting task:\nthe number of possible patterns grows exponentially with the number of cells,\nresulting in practically unlimited complexity. Recent empirical studies,\nhowever, suggest a vast simplification in how multi-neuron spiking occurs: the\nactivity patterns of some circuits are nearly completely captured by pairwise\ninteractions among neurons. Why are such pairwise models so successful in some\ninstances, but insufficient in others? Here, we study the emergence of\nhigher-order interactions in simple circuits with different architectures and\ninputs. We quantify the impact of higher-order interactions by comparing the\nresponses of mechanistic circuit models vs. \"null\" descriptions in which all\nhigher-than-pairwise correlations have been accounted for by lower order\nstatistics, known as pairwise maximum entropy models.\n  We find that bimodal input signals produce larger deviations from pairwise\npredictions than unimodal inputs for circuits with local and global\nconnectivity. Moreover, recurrent coupling can accentuate these deviations, if\ncoupling strengths are neither too weak nor too strong. A circuit model based\non intracellular recordings from ON parasol retinal ganglion cells shows that a\nbroad range of light signals induce unimodal inputs to spike generators, and\nthat coupling strengths produce weak effects on higher-order interactions. This\nprovides a novel explanation for the success of pairwise models in this system.\nOverall, our findings identify circuit-level mechanisms that produce and fail\nto produce higher-order spiking statistics in neural ensembles. \n\n"}
{"id": "1011.6326", "contents": "Title: New Null Space Results and Recovery Thresholds for Matrix Rank\n  Minimization Abstract: Nuclear norm minimization (NNM) has recently gained significant attention for\nits use in rank minimization problems. Similar to compressed sensing, using\nnull space characterizations, recovery thresholds for NNM have been studied in\n\\cite{arxiv,Recht_Xu_Hassibi}. However simulations show that the thresholds are\nfar from optimal, especially in the low rank region. In this paper we apply the\nrecent analysis of Stojnic for compressed sensing \\cite{mihailo} to the null\nspace conditions of NNM. The resulting thresholds are significantly better and\nin particular our weak threshold appears to match with simulation results.\nFurther our curves suggest for any rank growing linearly with matrix size $n$\nwe need only three times of oversampling (the model complexity) for weak\nrecovery. Similar to \\cite{arxiv} we analyze the conditions for weak, sectional\nand strong thresholds. Additionally a separate analysis is given for special\ncase of positive semidefinite matrices. We conclude by discussing simulation\nresults and future research directions. \n\n"}
{"id": "1011.6592", "contents": "Title: Axial and Vector Structure Functions for Electron- and Neutrino- Nucleon\n  Scattering Cross Sections at all $Q^2$ using Effective Leading order Parton\n  Distribution Functions Abstract: We construct a model for inelastic neutrino- and electron-nucleon scattering\ncross sections using effective leading order parton distribution functions with\na new scaling variable $\\xi_w$. Non-perturbative effects are well described\nusing the $\\xi_w$ scaling variable, in combination with multiplicative $K$\nfactors at low $Q^2$.Our model describes all inelastic charged lepton-nucleon\nscattering (including resonance) data (HERA/NMC/BCDMS/SLAC/JLab) ranging from\nvery high $Q^2$ to very low $Q^2$ and down to the photo-production region. The\nmodel describes existing inelastic neutrino-nucleon scattering measurements,\nand has been developed to be used in analysis of neutrino oscillation\nexperiments in the few GeV region. \n\n"}
{"id": "1012.0898", "contents": "Title: Classification of quaternary Hermitian self-dual codes of length 20 Abstract: A classification of quaternary Hermitian self-dual codes of length 20 is\ngiven. Using this classification, a classification of extremal quaternary\nHermitian self-dual codes of length 22 is also given. \n\n"}
{"id": "1101.4036", "contents": "Title: Secure Multiplex Coding with a Common Message Abstract: We determine the capacity region of the secure multiplex coding with a common\nmessage, and evaluate the mutual information and the equivocation rate of a\ncollection of secret messages to the second receiver (eavesdropper), which were\nnot evaluated by Yamamoto et al. \n\n"}
{"id": "1101.5809", "contents": "Title: The Degrees of Freedom Region and Interference Alignment for the MIMO\n  Interference Channel with Delayed CSI Abstract: The degrees of freedom (DoF) region of the 2-user multiple-antenna or MIMO\n(multiple-input, multiple-output) interference channel (IC) is studied under\nfast fading and the assumption of {\\em delayed} channel state information (CSI)\nwherein all terminals know all (or certain) channel matrices perfectly, but\nwith a delay, and each receiver in addition knows its own incoming channels\ninstantaneously. The general MIMO IC is considered with an arbitrary number of\nantennas at each of the four terminals. Dividing it into several classes\ndepending on the relation between the numbers of antennas at the four\nterminals, the fundamental DoF regions are characterized under the delayed CSI\nassumption for {\\em all} possible values of number of antennas at the four\nterminals. In particular, an outer bound on the DoF region of the general MIMO\nIC is derived. This bound is then shown to be tight for all MIMO ICs by\ndeveloping interference alignment based achievability schemes for each class. A\ncomparison of these DoF regions under the delayed CSI assumption is made with\nthose of the idealistic `perfect CSI' assumption where perfect and\ninstantaneous CSI is available at all terminals on the one hand and with the\nDoF regions of the conservative `no CSI' assumption on the other, where CSI is\navailable at the receivers but not at all at the transmitters. \n\n"}
{"id": "1102.0250", "contents": "Title: Information-Theoretic Viewpoints on Optimal Causal Coding-Decoding\n  Problems Abstract: In this paper we consider an interacting two-agent sequential decision-making\nproblem consisting of a Markov source process, a causal encoder with feedback,\nand a causal decoder. Motivated by a desire to foster links between control and\ninformation theory, we augment the standard formulation by considering general\nalphabets and a cost function operating on current and previous symbols. Using\ndynamic programming, we provide a structural result whereby an optimal scheme\nexists that operates on appropriate sufficient statistics. We emphasize an\nexample where the decoder alphabet lies in a space of beliefs on the source\nalphabet, and the additive cost function is a log likelihood ratio pertaining\nto sequential information gain. We also consider the inverse optimal control\nproblem, where a fixed encoder/decoder pair satisfying statistical conditions\nis shown to be optimal for some cost function, using probabilistic matching. We\nprovide examples of the applicability of this framework to communication with\nfeedback, hidden Markov models and the nonlinear filter, decentralized control,\nbrain-machine interfaces, and queuing theory. \n\n"}
{"id": "1102.0365", "contents": "Title: Limit Theorems in Hidden Markov Models Abstract: In this paper, under mild assumptions, we derive a law of large numbers, a\ncentral limit theorem with an error estimate, an almost sure invariance\nprinciple and a variant of Chernoff bound in finite-state hidden Markov models.\nThese limit theorems are of interest in certain ares in statistics and\ninformation theory. Particularly, we apply the limit theorems to derive the\nrate of convergence of the maximum likelihood estimator in finite-state hidden\nMarkov models. \n\n"}
{"id": "1102.2254", "contents": "Title: Matrix completion with column manipulation: Near-optimal\n  sample-robustness-rank tradeoffs Abstract: This paper considers the problem of matrix completion when some number of the\ncolumns are completely and arbitrarily corrupted, potentially by a malicious\nadversary. It is well-known that standard algorithms for matrix completion can\nreturn arbitrarily poor results, if even a single column is corrupted. One\ndirect application comes from robust collaborative filtering. Here, some number\nof users are so-called manipulators who try to skew the predictions of the\nalgorithm by calibrating their inputs to the system. In this paper, we develop\nan efficient algorithm for this problem based on a combination of a trimming\nprocedure and a convex program that minimizes the nuclear norm and the\n$\\ell_{1,2}$ norm. Our theoretical results show that given a vanishing fraction\nof observed entries, it is nevertheless possible to complete the underlying\nmatrix even when the number of corrupted columns grows. Significantly, our\nresults hold without any assumptions on the locations or values of the observed\nentries of the manipulated columns. Moreover, we show by an\ninformation-theoretic argument that our guarantees are nearly optimal in terms\nof the fraction of sampled entries on the authentic columns, the fraction of\ncorrupted columns, and the rank of the underlying matrix. Our results therefore\nsharply characterize the tradeoffs between sample, robustness and rank in\nmatrix completion. \n\n"}
{"id": "1102.3819", "contents": "Title: Enhancement of flow anisotropies due to magnetic field in relativistic\n  heavy-ion collisions Abstract: It is known that the presence of background magnetic field in cosmic plasma\ndistorts the acoustic peaks in CMBR. This primarily results from different\ntypes of waves in the plasma with velocities depending on the angle between the\nmagnetic field and the wave vector. We consider the consequences of these\neffects in relativistic heavy-ion collisions where very strong magnetic fields\narise during early stages of the plasma evolution. We show that flow\ncoefficients can be significantly affected by these effects when the magnetic\nfield remains strong during early stages due to strong induced fields in the\nconducting plasma. In particular, the presence of magnetic field can lead to\nenhancement in the elliptic flow coefficient $v_2$. \n\n"}
{"id": "1103.0270", "contents": "Title: Interference Alignment and Degrees of Freedom Region of Cellular Sigma\n  Channel Abstract: We investigate the Degrees of Freedom (DoF) Region of a cellular network,\nwhere the cells can have overlapping areas. Within an overlapping area, the\nmobile users can access multiple base stations. We consider a case where there\nare two base stations both equipped with multiple antennas. The mobile stations\nare all equipped with single antenna and each mobile station can belong to\neither a single cell or both cells. We completely characterize the DoF region\nfor the uplink channel assuming that global channel state information is\navailable at the transmitters. The achievability scheme is based on\ninterference alignment at the base stations. \n\n"}
{"id": "1104.3911", "contents": "Title: Information Exchange Limits in Cooperative MIMO Networks Abstract: Concurrent presence of inter-cell and intra-cell interferences constitutes a\nmajor impediment to reliable downlink transmission in multi-cell multiuser\nnetworks. Harnessing such interferences largely hinges on two levels of\ninformation exchange in the network: one from the users to the base-stations\n(feedback) and the other one among the base-stations (cooperation). We\ndemonstrate that exchanging a finite number of bits across the network, in the\nform of feedback and cooperation, is adequate for achieving the optimal\ncapacity scaling. We also show that the average level of information exchange\nis independent of the number of users in the network. This level of information\nexchange is considerably less than that required by the existing coordination\nstrategies which necessitate exchanging infinite bits across the network for\nachieving the optimal sum-rate capacity scaling. The results provided rely on a\nconstructive proof. \n\n"}
{"id": "1104.4824", "contents": "Title: Fast global convergence of gradient methods for high-dimensional\n  statistical recovery Abstract: Many statistical $M$-estimators are based on convex optimization problems\nformed by the combination of a data-dependent loss function with a norm-based\nregularizer. We analyze the convergence rates of projected gradient and\ncomposite gradient methods for solving such problems, working within a\nhigh-dimensional framework that allows the data dimension $\\pdim$ to grow with\n(and possibly exceed) the sample size $\\numobs$. This high-dimensional\nstructure precludes the usual global assumptions---namely, strong convexity and\nsmoothness conditions---that underlie much of classical optimization analysis.\nWe define appropriately restricted versions of these conditions, and show that\nthey are satisfied with high probability for various statistical models. Under\nthese conditions, our theory guarantees that projected gradient descent has a\nglobally geometric rate of convergence up to the \\emph{statistical precision}\nof the model, meaning the typical distance between the true unknown parameter\n$\\theta^*$ and an optimal solution $\\hat{\\theta}$. This result is substantially\nsharper than previous convergence results, which yielded sublinear convergence,\nor linear convergence only up to the noise level. Our analysis applies to a\nwide range of $M$-estimators and statistical models, including sparse linear\nregression using Lasso ($\\ell_1$-regularized regression); group Lasso for block\nsparsity; log-linear models with regularization; low-rank matrix recovery using\nnuclear norm regularization; and matrix decomposition. Overall, our analysis\nreveals interesting connections between statistical precision and computational\nefficiency in high-dimensional estimation. \n\n"}
{"id": "1105.0060", "contents": "Title: Signal Processing in Large Systems: a New Paradigm Abstract: For a long time, detection and parameter estimation methods for signal\nprocessing have relied on asymptotic statistics as the number $n$ of\nobservations of a population grows large comparatively to the population size\n$N$, i.e. $n/N\\to \\infty$. Modern technological and societal advances now\ndemand the study of sometimes extremely large populations and simultaneously\nrequire fast signal processing due to accelerated system dynamics. This results\nin not-so-large practical ratios $n/N$, sometimes even smaller than one. A\ndisruptive change in classical signal processing methods has therefore been\ninitiated in the past ten years, mostly spurred by the field of large\ndimensional random matrix theory. The early works in random matrix theory for\nsignal processing applications are however scarce and highly technical. This\ntutorial provides an accessible methodological introduction to the modern tools\nof random matrix theory and to the signal processing methods derived from them,\nwith an emphasis on simple illustrative examples. \n\n"}
{"id": "1105.1080", "contents": "Title: Number of Collisions in the Glauber Model and Beyond Abstract: The so called number of hadron-nucleus collisions n_coll(b) at impact\nparameter b, and its integral value N_coll, which are used to normalize the\nmeasured fractional cross section of a hard process, are calculated within the\nGlauber-Gribov theory including the effects of nucleon short-range\ncorrelations. The Gribov inelastic shadowing corrections are summed to all\norders by employing the dipole representation. Numerical calculations are\nperformed at the energies of the BNL Relativistic Heavy Ion Collider (RHIC) and\nCERN Large Hadron Collider (LHC). We found that whereas the Gribov corrections\ngenerally increase the value of N_coll, the inclusion of nucleon correlations,\nacting in the opposite directions, decreases it by a comparable amount. The\ninterplay of the two effects varies with the value of the impact parameter. \n\n"}
{"id": "1105.1144", "contents": "Title: Investigations of three, four, and five-particle exit channels of levels\n  in light nuclei created using a 9C beam Abstract: The interactions of a E/A=70-MeV 9C beam with a Be target was used to\npopulate levels in Be, B, and C isotopes which undergo decay into many-particle\nexit channels. The decay products were detected in the HiRA array and the level\nenergies were identified from their invariant mass. Correlations between the\ndecay products were examined to deduce the nature of the decays, specifically\nto what extent all the fragments were created in one prompt step or whether the\ndisintegration proceeded in a sequential fashion through long-lived\nintermediate states. In the latter case, information on the spin of the level\nwas also obtained. Of particular interest is the 5-body decay of the 8C ground\nstate which was found to disintegrate in two steps of two-proton decay passing\nthrough the 6Beg.s. intermediate state. The isobaric analog of 8Cg.s. in 8B was\nalso found to undergo two-proton decay to the isobaric analog of 6Beg.s. in\n6Li. A 9.69-MeV state in 10C was found to undergo prompt 4-body decay to the\n2p+2alpha exit channel. The two protons were found to have a strong\nenhancementin the diproton region and the relative energies of all four p-alpha\npairs were consistent with the 5Lig.s. resonance. \n\n"}
{"id": "1105.2281", "contents": "Title: Upper limits for a narrow resonance in the reaction p + p -> K^+ +\n  (Lambda p) Abstract: The reaction pp -> K^+ + (Lambda p) has been measured at T_p = 1.953 GeV and\n\\Theta = 0 deg with a high missing mass resolution in order to study the Lambda\np final state interaction. Narrow S = -1 resonances predicted by bag model\ncalculations are not visible in the missing mass spectrum. Small structures\nobserved in a previous experiment are not confirmed. Upper limits for the\nproduction cross section of a narrow resonance are deduced for missing masses\nbetween 2058 and 2105 MeV/c^2. \n\n"}
{"id": "1105.5419", "contents": "Title: Strong Secrecy from Channel Resolvability Abstract: We analyze physical-layer security based on the premise that the coding\nmechanism for secrecy over noisy channels is tied to the notion of channel\nresolvability. Instead of considering capacity-based constructions, which\nassociate to each message a sub-code that operates just below the capacity of\nthe eavesdropper's channel, we consider channel-resolvability-based\nconstructions, which associate to each message a sub-code that operates just\nabove the resolvability of the eavesdropper's channel. Building upon the work\nof Csiszar and Hayashi, we provide further evidence that channel resolvability\nis a powerful and versatile coding mechanism for secrecy by developing results\nthat hold for strong secrecy metrics and arbitrary channels.\n  Specifically, we show that at least for symmetric wiretap channels, random\ncapacity-based constructions fail to achieve the strong secrecy capacity while\nchannel-resolvability-based constructions achieve it. We then leverage channel\nresolvability to establish the secrecy-capacity region of arbitrary broadcast\nchannels with confidential messages and a cost constraint for strong secrecy\nmetrics. Finally, we specialize our results to study the secrecy capacity of\nwireless channels with perfect channel state information, mixed channels and\ncompound channels with receiver Channel State Information (CSI), as well as the\nsecret-key capacity of source models for secret-key agreement. By tying secrecy\nto channel resolvability, we obtain achievable rates for strong secrecy metrics\nwith simple proofs. \n\n"}
{"id": "1105.5438", "contents": "Title: The capacity region of classes of product broadcast channels Abstract: We establish a new outer bound for the capacity region of product broadcast\nchannels. This outer bound matches Marton's inner bound for a variety of\nclasses of product broadcast channels whose capacity regions were previously\nunknown. These classes include product of reversely semi-deterministic and\nproduct of reversely more-capable channels. A significant consequence of this\nnew outer bound is that it establishes, via an example, that the previously\nbest known outer-bound is strictly suboptimal for the general broadcast\nchannel. Our example is comprised of a product broadcast channel with two\nsemi-deterministic components in reverse orientation. \n\n"}
{"id": "1105.5476", "contents": "Title: Feedback-Topology Designs for Interference Alignment in MIMO\n  Interference Channels Abstract: Interference alignment (IA) is a joint-transmission technique that achieves\nthe capacity of the interference channel for high signal-to-noise ratios\n(SNRs). Most prior work on IA is based on the impractical assumption that\nperfect and global channel-state information(CSI) is available at all\ntransmitters. To implement IA, each receiver has to feed back CSI to all\ninterferers, resulting in overwhelming feedback overhead. In particular, the\nsum feedback rate of each receiver scales quadratically with the number of\nusers even if the quantized CSI is fed back. To substantially suppress feedback\noverhead, this paper focuses on designing efficient arrangements of feedback\nlinks, called feedback topologies, under the IA constraint. For the\nmultiple-input-multiple-output (MIMO) K-user interference channel, we propose\nthe feedback topology that supports sequential CSI exchange (feedback and\nfeedforward) between transmitters and receivers so as to achieve IA\nprogressively. This feedback topology is shown to reduce the network feedback\noverhead from a cubic function of K to a linear one. To reduce the delay in the\nsequential CSI exchange, an alternative feedback topology is designed for\nsupporting two-hop feedback via a control station, which also achieves the\nlinear feedback scaling with K. Next, given the proposed feedback topologies,\nthe feedback-bit allocation algorithm is designed for allocating feedback bits\nby each receiver to different feedback links so as to regulate the residual\ninterference caused by the finite-rate feedback. Simulation results demonstrate\nthat the proposed bit allocation leads to significant throughput gains\nespecially in strong interference environments. \n\n"}
{"id": "1105.6163", "contents": "Title: Assisted Common Information: Further Results Abstract: We presented assisted common information as a generalization of\nG\\'acs-K\\\"orner (GK) common information at ISIT 2010. The motivation for our\nformulation was to improve upperbounds on the efficiency of protocols for\nsecure two-party sampling (which is a form of secure multi-party computation).\nOur upperbound was based on a monotonicity property of a rate-region (called\nthe assisted residual information region) associated with the assisted common\ninformation formulation. In this note we present further results. We explore\nthe connection of assisted common information with the Gray-Wyner system. We\nshow that the assisted residual information region and the Gray-Wyner region\nare connected by a simple relationship: the assisted residual information\nregion is the increasing hull of the Gray-Wyner region under an affine map.\nSeveral known relationships between GK common information and Gray-Wyner system\nfall out as consequences of this. Quantities which arise in other source coding\ncontexts acquire new interpretations. In previous work we showed that assisted\ncommon information can be used to derive upperbounds on the rate at which a\npair of parties can {\\em securely sample} correlated random variables, given\ncorrelated random variables from another distribution. Here we present an\nexample where the bound derived using assisted common information is much\nbetter than previously known bounds, and in fact is tight. This example\nconsiders correlated random variables defined in terms of standard variants of\noblivious transfer, and is interesting on its own as it answers a natural\nquestion about these cryptographic primitives. \n\n"}
{"id": "1106.6174", "contents": "Title: Pairwise Check Decoding for LDPC Coded Two-Way Relay Block Fading\n  Channels Abstract: Partial decoding has the potential to achieve a larger capacity region than\nfull decoding in two-way relay (TWR) channels. Existing partial decoding\nrealizations are however designed for Gaussian channels and with a static\nphysical layer network coding (PLNC). In this paper, we propose a new solution\nfor joint network coding and channel decoding at the relay, called pairwise\ncheck decoding (PCD), for low-density parity-check (LDPC) coded TWR system over\nblock fading channels. The main idea is to form a check relationship table\n(check-relation-tab) for the superimposed LDPC coded packet pair in the\nmultiple access (MA) phase in conjunction with an adaptive PLNC mapping in the\nbroadcast (BC) phase. Using PCD, we then present a partial decoding method,\ntwo-stage closest-neighbor clustering with PCD (TS-CNC-PCD), with the aim of\nminimizing the worst pairwise error probability. Moreover, we propose the\nminimum correlation optimization (MCO) for selecting the better\ncheck-relation-tabs. Simulation results confirm that the proposed TS-CNC-PCD\noffers a sizable gain over the conventional XOR with belief propagation (BP) in\nfading channels. \n\n"}
{"id": "1106.6224", "contents": "Title: Structured Compressed Sensing: From Theory to Applications Abstract: Compressed sensing (CS) is an emerging field that has attracted considerable\nresearch interest over the past few years. Previous review articles in CS limit\ntheir scope to standard discrete-to-discrete measurement architectures using\nmatrices of randomized nature and signal models based on standard sparsity. In\nrecent years, CS has worked its way into several new application areas. This,\nin turn, necessitates a fresh look on many of the basics of CS. The random\nmatrix measurement operator must be replaced by more structured sensing\narchitectures that correspond to the characteristics of feasible acquisition\nhardware. The standard sparsity prior has to be extended to include a much\nricher class of signals and to encode broader data models, including\ncontinuous-time signals. In our overview, the theme is exploiting signal and\nmeasurement structure in compressive sensing. The prime focus is bridging\ntheory and practice; that is, to pinpoint the potential of structured CS\nstrategies to emerge from the math to the hardware. Our summary highlights new\ndirections as well as relations to more traditional CS, with the hope of\nserving both as a review to practitioners wanting to join this emerging field,\nand as a reference for researchers that attempts to put some of the existing\nideas in perspective of practical applications. \n\n"}
{"id": "1107.2335", "contents": "Title: A proposed search for a fourth neutrino with a PBq antineutrino source Abstract: Several observed anomalies in neutrino oscillation data can be explained by a\nhypothetical fourth neutrino separated from the three standard neutrinos by a\nsquared mass difference of a few eV^2. We show that this hypothesis can be\ntested with a PBq (ten kilocurie scale) 144Ce or 106Ru antineutrino beta-source\ndeployed at the center of a large low background liquid scintillator detector.\nIn particular, the compact size of such a source could yield an\nenergy-dependent oscillating pattern in event spatial distribution that would\nunabiguously determine neutrino mass differences and mixing angles. \n\n"}
{"id": "1107.3602", "contents": "Title: Heterogeneous Cellular Networks with Flexible Cell Association: A\n  Comprehensive Downlink SINR Analysis Abstract: In this paper we develop a tractable framework for SINR analysis in downlink\nheterogeneous cellular networks (HCNs) with flexible cell association policies.\nThe HCN is modeled as a multi-tier cellular network where each tier's base\nstations (BSs) are randomly located and have a particular transmit power, path\nloss exponent, spatial density, and bias towards admitting mobile users. For\nexample, as compared to macrocells, picocells would usually have lower transmit\npower, higher path loss exponent (lower antennas), higher spatial density (many\npicocells per macrocell), and a positive bias so that macrocell users are\nactively encouraged to use the more lightly loaded picocells. In the present\npaper we implicitly assume all base stations have full queues; future work\nshould relax this. For this model, we derive the outage probability of a\ntypical user in the whole network or a certain tier, which is equivalently the\ndownlink SINR cumulative distribution function. The results are accurate for\nall SINRs, and their expressions admit quite simple closed-forms in some\nplausible special cases. We also derive the \\emph{average ergodic rate} of the\ntypical user, and the \\emph{minimum average user throughput} -- the smallest\nvalue among the average user throughputs supported by one cell in each tier. We\nobserve that neither the number of BSs or tiers changes the outage probability\nor average ergodic rate in an interference-limited full-loaded HCN with\nunbiased cell association (no biasing), and observe how biasing alters the\nvarious metrics. \n\n"}
{"id": "1107.4148", "contents": "Title: The Sender-Excited Secret Key Agreement Model: Capacity, Reliability and\n  Secrecy Exponents Abstract: We consider the secret key generation problem when sources are randomly\nexcited by the sender and there is a noiseless public discussion channel. Our\nsetting is thus similar to recent works on channels with action-dependent\nstates where the channel state may be influenced by some of the parties\ninvolved. We derive single-letter expressions for the secret key capacity\nthrough a type of source emulation analysis. We also derive lower bounds on the\nachievable reliability and secrecy exponents, i.e., the exponential rates of\ndecay of the probability of decoding error and of the information leakage.\nThese exponents allow us to determine a set of strongly-achievable secret key\nrates. For degraded eavesdroppers the maximum strongly-achievable rate equals\nthe secret key capacity; our exponents can also be specialized to previously\nknown results.\n  In deriving our strong achievability results we introduce a coding scheme\nthat combines wiretap coding (to excite the channel) and key extraction (to\ndistill keys from residual randomness). The secret key capacity is naturally\nseen to be a combination of both source- and channel-type randomness. Through\nexamples we illustrate a fundamental interplay between the portion of the\nsecret key rate due to each type of randomness. We also illustrate inherent\ntradeoffs between the achievable reliability and secrecy exponents. Our new\nscheme also naturally accommodates rate limits on the public discussion. We\nshow that under rate constraints we are able to achieve larger rates than those\nthat can be attained through a pure source emulation strategy. \n\n"}
{"id": "1108.1766", "contents": "Title: Activized Learning: Transforming Passive to Active with Improved Label\n  Complexity Abstract: We study the theoretical advantages of active learning over passive learning.\nSpecifically, we prove that, in noise-free classifier learning for VC classes,\nany passive learning algorithm can be transformed into an active learning\nalgorithm with asymptotically strictly superior label complexity for all\nnontrivial target functions and distributions. We further provide a general\ncharacterization of the magnitudes of these improvements in terms of a novel\ngeneralization of the disagreement coefficient. We also extend these results to\nactive learning in the presence of label noise, and find that even under broad\nclasses of noise distributions, we can typically guarantee strict improvements\nover the known results for passive learning. \n\n"}
{"id": "1108.3047", "contents": "Title: BESIII: \"charming\" physics at an e$^+$e$^-$ collider machine Abstract: Despite the successes of the standard model, the non-perturbative dynamics of\nthe strong interaction are not fully understood yet. Charmonium spectroscopy\nserves as an ideal tool to shed light on the dynamics of the strong interaction\nsuch as quark confinement and the generation of hadron masses. The BESIII\ncollaboration studies extensively the strong interaction and various aspects\nthat could shed light on physics beyond the standard model via copious\ne$^+$e$^-$ collisions at the BESIII/BEPCII facility in Beijing, China, in the\ncharmonium mass regime. We present a few of the recent results with the\nemphasis on charmonium spectroscopy studies using 106$\\times10^6$ $\\psi^\\prime$\nevents. \n\n"}
{"id": "1108.4940", "contents": "Title: Quantum rate distortion, reverse Shannon theorems, and source-channel\n  separation Abstract: We derive quantum counterparts of two key theorems of classical information\ntheory, namely, the rate distortion theorem and the source-channel separation\ntheorem. The rate-distortion theorem gives the ultimate limits on lossy data\ncompression, and the source-channel separation theorem implies that a two-stage\nprotocol consisting of compression and channel coding is optimal for\ntransmitting a memoryless source over a memoryless channel. In spite of their\nimportance in the classical domain, there has been surprisingly little work in\nthese areas for quantum information theory. In the present paper, we prove that\nthe quantum rate distortion function is given in terms of the regularized\nentanglement of purification. We also determine a single-letter expression for\nthe entanglement-assisted quantum rate distortion function, and we prove that\nit serves as a lower bound on the unassisted quantum rate distortion function.\nThis implies that the unassisted quantum rate distortion function is\nnon-negative and generally not equal to the coherent information between the\nsource and distorted output (in spite of Barnum's conjecture that the coherent\ninformation would be relevant here). Moreover, we prove several quantum\nsource-channel separation theorems. The strongest of these are in the\nentanglement-assisted setting, in which we establish a necessary and sufficient\ncodition for transmitting a memoryless source over a memoryless quantum channel\nup to a given distortion. \n\n"}
{"id": "1109.0593", "contents": "Title: Error Estimation for Moments Analysis in Heavy-Ion Collision Experiments Abstract: Fluctuations of conserved quantities are predicted to be sensitive to the\ncorrelation length and connected to the thermodynamic susceptibility. Thus,\nmoments of net-baryon, net-charge and net-strangeness have been extensively\nstudied theoretically and experimentally to explore phase structure and bulk\nproperties of QCD matters created in heavy ion collision experiment. As the\nmoments analysis is statistics hungry study, the error estimation is crucial to\nextract physics information from the limited experimental data. In this paper,\nwe will derive the limit distributions and error formula based on Delta theorem\nin statistics for various order moments used in the experimental data analysis.\nThe Monte Carlo simulation is also applied to test the error formula. \n\n"}
{"id": "1109.0760", "contents": "Title: Measuring Parton Energy Loss at RHIC compared to LHC Abstract: The method of measuring $\\hat{x}_h=\\hat{p}_{Ta}/\\hat{p}_{Tt}$, the ratio of\nthe away-parton transverse momentum, $\\hat{p}_{T_a}$, to the trigger-parton\ntransverse momentum, $\\hat{p}_{T_t}$, using two-particle correlations at RHIC,\nwill be reviewed. This measurement is simply related to the two new variables\nintroduced at LHC for the di-jet fractional transverse momentum imbalance:\nATLAS $A_J=(\\hat{p}_{Tt}-\\hat{p}_{Ta})/(\\hat{p}_{Tt}+\\hat{p}_{Ta})=\n(1-\\hat{x}_h)/(1+\\hat{x}_h)$; and CMS\n$\\mean{(\\hat{p}_{Tt}-\\hat{p}_{Ta})/\\hat{p}_{Tt}}= \\mean{1-\\hat{x}_h}$. Results\nfrom two-particle correlations at RHIC for $\\hat{x}_h$ in p-p and A+A\ncollisions will be reviewed and new results will be presented and compared to\nLHC results. The importance of comparing any effect in A+A collisions to the\nsame effect effect in p-p collisions will be illustrated and emphasized. \n\n"}
{"id": "1109.6437", "contents": "Title: An Error Probability Approach to MIMO Wiretap Channels Abstract: We consider MIMO (Multiple Input Multiple Output) wiretap channels, where a\nlegitimate transmitter Alice is communicating with a legitimate receiver Bob in\nthe presence of an eavesdropper Eve, and communication is done via MIMO\nchannels. We suppose that Alice's strategy is to use a codebook which has a\nlattice structure, which then allows her to perform coset encoding. We analyze\nEve's probability of correctly decoding the message Alice meant to Bob, and\nfrom minimizing this probability, we derive a code design criterion for MIMO\nlattice wiretap codes. The case of block fading channels is treated similarly,\nand fast fading channels are derived as a particular case. The Alamouti code is\ncarefully studied as an illustration of the analysis provided. \n\n"}
{"id": "1110.1237", "contents": "Title: Free Deterministic Equivalents, Rectangular Random Matrix Models, and\n  Operator-Valued Free Probability Theory Abstract: Motivated by the asymptotic collective behavior of random and deterministic\nmatrices, we propose an approximation (called \"free deterministic equivalent\")\nto quite general random matrix models, by replacing the matrices with operators\nsatisfying certain freeness relations. We comment on the relation between our\nfree deterministic equivalent and deterministic equivalents considered in the\nengineering literature. We do not only consider the case of square matrices,\nbut also show how rectangular matrices can be treated. Furthermore, we\nemphasize how operator-valued free probability techniques can be used to solve\nour free deterministic equivalents.\n  As an illustration of our methods we consider a random matrix model studied\nfirst by R. Couillet, J. Hoydis, and M. Debbah. We show how its free\ndeterministic equivalent can be treated and we thus recover in a conceptual way\ntheir result.\n  On a technical level, we generalize a result from scalar valued free\nprobability, by showing that randomly rotated deterministic matrices of\ndifferent sizes are asymptotically free from deterministic rectangular\nmatrices, with amalgamation over a certain algebra of projections.\n  In the Appendix, we show how estimates for differences between Cauchy\ntransforms can be extended from a neighborhood of infinity to a region close to\nthe real axis. This is of some relevance if one wants to compare the original\nrandom matrix problem with its free deterministic equivalent. \n\n"}
{"id": "1110.2436", "contents": "Title: An MDL framework for sparse coding and dictionary learning Abstract: The power of sparse signal modeling with learned over-complete dictionaries\nhas been demonstrated in a variety of applications and fields, from signal\nprocessing to statistical inference and machine learning. However, the\nstatistical properties of these models, such as under-fitting or over-fitting\ngiven sets of data, are still not well characterized in the literature. As a\nresult, the success of sparse modeling depends on hand-tuning critical\nparameters for each data and application. This work aims at addressing this by\nproviding a practical and objective characterization of sparse models by means\nof the Minimum Description Length (MDL) principle -- a well established\ninformation-theoretic approach to model selection in statistical inference. The\nresulting framework derives a family of efficient sparse coding and dictionary\nlearning algorithms which, by virtue of the MDL principle, are completely\nparameter free. Furthermore, such framework allows to incorporate additional\nprior information to existing models, such as Markovian dependencies, or to\ndefine completely new problem formulations, including in the matrix analysis\narea, in a natural way. These virtues will be demonstrated with parameter-free\nalgorithms for the classic image denoising and classification problems, and for\nlow-rank matrix recovery in video applications. \n\n"}
{"id": "1110.3341", "contents": "Title: The Nuclear Matter Symmetry Energy at $0.03\\leq \\rho/\\rho_0\\leq 0.2$ Abstract: Measurements of the density dependence of the free symmetry energy in low\ndensity clustered matter have been extended using the NIMROD multi-detector at\nTexas A&M University. Thermal coalescence models were employed to extract\ndensities, $\\rho$, and temperatures, $T$, for evolving systems formed in\ncollisions of 47 $A$ MeV $^{40}$Ar + $^{112}$Sn,$^{124}$Sn and $^{64}$Zn +\n$^{112}$Sn, $^{124}$Sn. Densities of $0.03 \\leq \\rho/\\rho_0 \\leq 0.2$ and\ntemperatures in the range 5 to 10 MeV have been sampled. The free symmetry\nenergy coefficients are found to be in good agreement with values calculated\nusing a quantum statistical model. Values of the corresponding symmetry energy\ncoefficient are derived from the data using entropies derived from the model. \n\n"}
{"id": "1110.5944", "contents": "Title: Communication cost of classically simulating a quantum channel with\n  subsequent rank-1 projective measurement Abstract: A process of preparation, transmission and subsequent projective measurement\nof a qubit can be simulated by a classical model with only two bits of\ncommunication and some amount of shared randomness. However no model for n\nqubits with a finite amount of classical communication is known at present. A\nlower bound for the communication cost can provide useful hints for a\ngeneralization. It is known for example that the amount of communication must\nbe greater than c 2^n, where c~0.01. The proof uses a quite elaborate theorem\nof communication complexity. Using a mathematical conjecture known as the\n\"double cap conjecture\", we strengthen this result by presenting a geometrical\nand extremely simple derivation of the lower bound 2^n-1. Only rank-1\nprojective measurements are involved in the derivation. \n\n"}
{"id": "1111.0084", "contents": "Title: Lattice codes for the Gaussian relay channel: Decode-and-Forward and\n  Compress-and-Forward Abstract: Lattice codes are known to achieve capacity in the Gaussian point-to-point\nchannel, achieving the same rates as independent, identically distributed\n(i.i.d.) random Gaussian codebooks. Lattice codes are also known to outperform\nrandom codes for certain channel models that are able to exploit their\nlinearity. In this work, we show that lattice codes may be used to achieve the\nsame performance as known i.i.d. Gaussian random coding techniques for the\nGaussian relay channel, and show several examples of how this may be combined\nwith the linearity of lattices codes in multi-source relay networks. In\nparticular, we present a nested lattice list decoding technique, by which,\nlattice codes are shown to achieve the Decode-and-Forward (DF) rate of single\nsource, single destination Gaussian relay channels with one or more relays. We\nnext present two examples of how this DF scheme may be combined with the\nlinearity of lattice codes to achieve new rate regions which for some channel\nconditions outperform analogous known Gaussian random coding techniques in\nmulti-source relay channels. That is, we derive a new achievable rate region\nfor the two-way relay channel with direct links and compare it to existing\nschemes, and derive another achievable rate region for the multiple access\nrelay channel. We furthermore present a lattice Compress-and-Forward (CF)\nscheme for the Gaussian relay channel which exploits a lattice Wyner-Ziv\nbinning scheme and achieves the same rate as the Cover-El Gamal CF rate\nevaluated for Gaussian random codes. These results suggest that\nstructured/lattice codes may be used to mimic, and sometimes outperform, random\nGaussian codes in general Gaussian networks. \n\n"}
{"id": "1111.0493", "contents": "Title: LPM effect as the origin of the jet fragmentation scaling in heavy ion\n  collisions Abstract: We address a recent puzzling result from the LHC: the jet fragmentation\nfunctions measured in $PbPb$ and $pp$ collisions appear very similar in spite\nof a large medium-induced energy loss (we will call this \"jet fragmentation\nscaling\", JFS). To model the real-time non-perturbative effects in the\npropagation of a high energy jet through the strongly coupled QCD matter, we\nadopt an effective dimensionally reduced description in terms of the $(1+1)$\nquasi-Abelian Schwinger theory. This theory is exactly soluble at any value of\nthe coupling and shares with QCD the properties of dynamical generation of\n\"mesons\" with a finite mass and the screening of \"quark\" charge that are\ncrucial for describing the transition of the jet into hadrons. We find that\nthis approach describes quite well the vacuum jet fragmentation in $e^+e^-$\nannihilation at $z\\geq0.2$ at jet energies in the range of the LHC heavy ion\nmeasurements ($z$ is the ratio of hadron and jet momenta). In QCD medium, we\nfind that the JFS is reproduced if the mean free path $\\lambda$ of the jet is\nshort, $\\lambda \\leq 0.3$ fm, which is in accord with the small shear viscosity\ninferred from the measurements of the collective flow. The JFS holds since at\nshort mean free path the quantum interference (analogous to the\nLandau-Pomeranchuk-Migdal effect in QED) causes the produced mesons to have low\nmomenta $p \\sim m$, where $m \\simeq 0.6$ GeV is the typical meson mass.\nMeanwhile the induced jet energy loss at short mean free path is much larger\nthan naively expected in string models. \n\n"}
{"id": "1111.1892", "contents": "Title: Jet studies with STAR at RHIC: jet algorithms, jet shapes, jets in AA Abstract: Hard scattered partons are predicted to be well calibrated probes of the hot\nand dense medium produced in heavy ion collisions. Interactions of these\npartons with the medium w ill result in modifications of internal jet structure\nin Au+Au events compared to that observed in the p+p/d+Au reference. Full jet\nreconstruction is a promising tool to measu re these effects without the\nsignificant biases present in measurements with high-$\\pT$ hadrons.\n  One of the most significant challenges for jet reconstruction in the heavy\nion environment comes from the correct characterization of the background\nfluctuations. The jet mome ntum irresolution due to background fluctuations has\nto be understood in order to recover the correct jet spectrum. Recent progress\nin jet reconstruction methodology is discu ssed, as well as recent measurements\nfrom p+p, d+Au and Au+Au collisions at $\\sqrt{s_\\mathrm{NN}}=200 \\gev$. \n\n"}
{"id": "1111.1995", "contents": "Title: Moderate Deviations Analysis of Binary Hypothesis Testing Abstract: This paper is focused on the moderate-deviations analysis of binary\nhypothesis testing. The analysis relies on a concentration inequality for\ndiscrete-parameter martingales with bounded jumps, where this inequality forms\na refinement to the Azuma-Hoeffding inequality. Relations of the analysis to\nthe moderate deviations principle for i.i.d. random variables and to the\nrelative entropy are considered. \n\n"}
{"id": "1111.6664", "contents": "Title: Generalized Orthogonal Matching Pursuit Abstract: As a greedy algorithm to recover sparse signals from compressed measurements,\northogonal matching pursuit (OMP) algorithm has received much attention in\nrecent years. In this paper, we introduce an extension of the OMP for pursuing\nefficiency in reconstructing sparse signals. Our approach, henceforth referred\nto as generalized OMP (gOMP), is literally a generalization of the OMP in the\nsense that multiple $N$ indices are identified per iteration. Owing to the\nselection of multiple ''correct'' indices, the gOMP algorithm is finished with\nmuch smaller number of iterations when compared to the OMP. We show that the\ngOMP can perfectly reconstruct any $K$-sparse signals ($K > 1$), provided that\nthe sensing matrix satisfies the RIP with $\\delta_{NK} <\n\\frac{\\sqrt{N}}{\\sqrt{K} + 3 \\sqrt{N}}$. We also demonstrate by empirical\nsimulations that the gOMP has excellent recovery performance comparable to\n$\\ell_1$-minimization technique with fast processing speed and competitive\ncomputational complexity. \n\n"}
{"id": "1112.0915", "contents": "Title: Collective flow in p-Pb and d-Pb collisions at TeV energies Abstract: We apply the hydrodynamic model for the dynamics of matter created in p-Pb\ncollisions at 4.4TeV and d-Pb collisions at 3.11TeV. The fluctuating initial\nconditions are calculated in the Glauber Monte-Carlo model for several\ncentrality classes. The expansion is performed event by event in\n3+1-dimensional viscous hydrodynamics. Noticeable elliptic and triangular flows\nappear in the distributions of produced particles. \n\n"}
{"id": "1112.2212", "contents": "Title: Nucleon and Roper electromagnetic elastic and transition form factors Abstract: We compute nucleon and Roper e.m. elastic and transition form factors using a\nsymmetry-preserving treatment of a contact-interaction. Obtained thereby, the\ne.m. interactions of baryons are typically described by hard form factors. In\ncontrasting this behaviour with that produced by a momentum-dependent\ninteraction, one achieves comparisons which highlight that elastic scattering\nand resonance electroproduction experiments probe the infrared evolution of\nQCD's running masses; e.g., the existence, and location if so, of a zero in the\nratio of nucleon Sachs form factors are strongly influenced by the running of\nthe dressed-quark mass. In our description of baryons, diquark correlations are\nimportant. These correlations are instrumental in producing a zero in the Dirac\nform factor of the proton's d-quark; and in determining d_v/u_v(x=1), as we\nshow via a formula that expresses d_v/u_v(x=1) in terms of the nucleon's\ndiquark content. The contact interaction produces a first excitation of the\nnucleon that is constituted predominantly from axial-vector diquark\ncorrelations. This impacts greatly on the gamma*p->P_{11}(1440) form factors.\nNotably, our quark core contribution to F_2*(Q^2) exhibits a zero at\nQ^2~0.5mN^2. Faddeev equation treatments of a hadron's quark core usually\nunderestimate its magnetic properties, hence we consider the effect produced by\na dressed-quark anomalous e.m. moment. Its inclusion much improves agreement\nwith experiment. On the domain 0<Q^2<2GeV^2, meson-cloud effects are important\nin making a realistic comparison between experiment and hadron structure\ncalculations. Our computed helicity amplitudes are similar to the bare\namplitudes in coupled-channels analyses of the electroproduction process. Thus\nsupports a view that extant structure calculations should directly be compared\nwith the bare-couplings, etc., determined via coupled-channels analyses. \n\n"}
{"id": "1112.2972", "contents": "Title: Fast Distributed Gradient Methods Abstract: We study distributed optimization problems when $N$ nodes minimize the sum of\ntheir individual costs subject to a common vector variable. The costs are\nconvex, have Lipschitz continuous gradient (with constant $L$), and bounded\ngradient. We propose two fast distributed gradient algorithms based on the\ncentralized Nesterov gradient algorithm and establish their convergence rates\nin terms of the per-node communications $\\mathcal{K}$ and the per-node gradient\nevaluations $k$. Our first method, Distributed Nesterov Gradient, achieves\nrates $O\\left({\\log \\mathcal{K}}/{\\mathcal{K}}\\right)$ and $O\\left({\\log\nk}/{k}\\right)$. Our second method, Distributed Nesterov gradient with Consensus\niterations, assumes at all nodes knowledge of $L$ and $\\mu(W)$ -- the second\nlargest singular value of the $N \\times N$ doubly stochastic weight matrix $W$.\nIt achieves rates $O\\left({1}/{\\mathcal{K}^{2-\\xi}}\\right)$ and\n$O\\left({1}/{k^2}\\right)$ ($\\xi>0$ arbitrarily small). Further, we give with\nboth methods explicit dependence of the convergence constants on $N$ and $W$.\nSimulation examples illustrate our findings. \n\n"}
{"id": "1112.6320", "contents": "Title: Threshold Saturation in Spatially Coupled Constraint Satisfaction\n  Problems Abstract: We consider chains of random constraint satisfaction models that are\nspatially coupled across a finite window along the chain direction. We\ninvestigate their phase diagram at zero temperature using the survey\npropagation formalism and the interpolation method. We prove that the SAT-UNSAT\nphase transition threshold of an infinite chain is identical to the one of the\nindividual standard model, and is therefore not affected by spatial coupling.\nWe compute the survey propagation complexity using population dynamics as well\nas large degree approximations, and determine the survey propagation threshold.\nWe find that a clustering phase survives coupling. However, as one increases\nthe range of the coupling window, the survey propagation threshold increases\nand saturates towards the phase transition threshold. We also briefly discuss\nother aspects of the problem. Namely, the condensation threshold is not\naffected by coupling, but the dynamic threshold displays saturation towards the\ncondensation one. All these features may provide a new avenue for obtaining\nbetter provable algorithmic lower bounds on phase transition thresholds of the\nindividual standard model. \n\n"}
{"id": "1201.2205", "contents": "Title: A Cryptographic Treatment of the Wiretap Channel Abstract: The wiretap channel is a setting where one aims to provide\ninformation-theoretic privacy of communicated data based solely on the\nassumption that the channel from sender to adversary is \"noisier\" than the\nchannel from sender to receiver. It has been the subject of decades of work in\nthe information and coding (I&C) community. This paper bridges the gap between\nthis body of work and modern cryptography with contributions along two fronts,\nnamely metrics (definitions) of security, and schemes. We explain that the\nmetric currently in use is weak and insufficient to guarantee security of\napplications and propose two replacements. One, that we call mis-security, is a\nmutual-information based metric in the I&C style. The other, semantic security,\nadapts to this setting a cryptographic metric that, in the cryptography\ncommunity, has been vetted by decades of evaluation and endorsed as the target\nfor standards and implementations. We show that they are equivalent (any scheme\nsecure under one is secure under the other), thereby connecting two\nfundamentally different ways of defining security and providing a strong,\nunified and well-founded target for designs. Moving on to schemes, results from\nthe wiretap community are mostly non-constructive, proving the existence of\nschemes without necessarily yielding ones that are explicit, let alone\nefficient, and only meeting their weak notion of security. We apply\ncryptographic methods based on extractors to produce explicit, polynomial-time\nand even practical encryption schemes that meet our new and stronger security\ntarget. \n\n"}
{"id": "1201.3160", "contents": "Title: Polynomial-Time, Semantically-Secure Encryption Achieving the Secrecy\n  Capacity Abstract: In the wiretap channel setting, one aims to get information-theoretic privacy\nof communicated data based only on the assumption that the channel from sender\nto receiver is noisier than the one from sender to adversary. The secrecy\ncapacity is the optimal (highest possible) rate of a secure scheme, and the\nexistence of schemes achieving it has been shown. For thirty years the ultimate\nand unreached goal has been to achieve this optimal rate with a scheme that is\npolynomial-time. (This means both encryption and decryption are proven\npolynomial time algorithms.) This paper finally delivers such a scheme. In fact\nit does more. Our scheme not only meets the classical notion of security from\nthe wiretap literature, called MIS-R (mutual information security for random\nmessages) but achieves the strictly stronger notion of semantic security, thus\ndelivering more in terms of security without loss of rate. \n\n"}
{"id": "1201.5411", "contents": "Title: Lower bounds on the Probability of Error for Classical and\n  Classical-Quantum Channels Abstract: In this paper, lower bounds on error probability in coding for discrete\nclassical and classical-quantum channels are studied. The contribution of the\npaper goes in two main directions: i) extending classical bounds of Shannon,\nGallager and Berlekamp to classical-quantum channels, and ii) proposing a new\nframework for lower bounding the probability of error of channels with a\nzero-error capacity in the low rate region. The relation between these two\nproblems is revealed by showing that Lov\\'asz' bound on zero-error capacity\nemerges as a natural consequence of the sphere packing bound once we move to\nthe more general context of classical-quantum channels. A variation of\nLov\\'asz' bound is then derived to lower bound the probability of error in the\nlow rate region by means of auxiliary channels. As a result of this study,\nconnections between the Lov\\'asz theta function, the expurgated bound of\nGallager, the cutoff rate of a classical channel and the sphere packing bound\nfor classical-quantum channels are established. \n\n"}
{"id": "1202.0186", "contents": "Title: A Feasibility Test for Linear Interference Alignment in MIMO Channels\n  with Constant Coefficients Abstract: In this paper, we consider the feasibility of linear interference alignment\n(IA) for multiple-input multiple-output (MIMO) channels with constant\ncoefficients for any number of users, antennas and streams per user; and\npropose a polynomial-time test for this problem. Combining algebraic geometry\ntechniques with differential topology ones, we first prove a result that\ngeneralizes those previously published on this topic. Specifically, we consider\nthe input set (complex projective space of MIMO interference channels), the\noutput set (precoder and decoder Grassmannians) and the solution set (channels,\ndecoders and precoders satisfying the IA polynomial equations), not only as\nalgebraic sets but also as smooth compact manifolds. Using this mathematical\nframework, we prove that the linear alignment problem is feasible when the\nalgebraic dimension of the solution variety is larger than or equal to the\ndimension of the input space and the linear mapping between the tangent spaces\nof both smooth manifolds given by the first projection is generically\nsurjective. If that mapping is not surjective, then the solution variety\nprojects into the input space in a singular way and the projection is a\nzero-measure set. This result naturally yields a simple feasibility test, which\namounts to checking the rank of a matrix. We also provide an exact arithmetic\nversion of the test, which proves that testing the feasibility of IA for\ngeneric MIMO channels belongs to the bounded-error probabilistic polynomial\n(BPP) complexity class. \n\n"}
{"id": "1202.0325", "contents": "Title: Quantum wiretap channel with non-uniform random number and its exponent\n  and equivocation rate of leaked information Abstract: A usual code for quantum wiretap channel requires an auxiliary random\nvariable subject to the perfect uniform distribution. However, it is difficult\nto prepare such an auxiliary random variable. We propose a code that requires\nonly an auxiliary random variable subject to a non-uniform distribution instead\nof the perfect uniform distribution. Further, we evaluate the exponential\ndecreasing rate of leaked information and derive its equivocation rate. For\npractical constructions, we also discuss the security when our code consists of\na linear error correcting code. \n\n"}
{"id": "1202.0690", "contents": "Title: Minimization of Transmission Duration of Data Packets over an Energy\n  Harvesting Fading Channel Abstract: The offline problem of transmission completion time minimization for an\nenergy harvesting transmitter under fading is extended to allow packet arrivals\nduring transmission. A method for computing an optimal power and rate\nallocation (i.e., an optimal offline schedule) is developed and studied. \n\n"}
{"id": "1202.2113", "contents": "Title: Decentralized Delay Optimal Control for Interference Networks with\n  Limited Renewable Energy Storage Abstract: In this paper, we consider delay minimization for interference networks with\nrenewable energy source, where the transmission power of a node comes from both\nthe conventional utility power (AC power) and the renewable energy source. We\nassume the transmission power of each node is a function of the local channel\nstate, local data queue state and local energy queue state only. In turn, we\nconsider two delay optimization formulations, namely the decentralized\npartially observable Markov decision process (DEC-POMDP) and Non-cooperative\npartially observable stochastic game (POSG). In DEC-POMDP formulation, we\nderive a decentralized online learning algorithm to determine the control\nactions and Lagrangian multipliers (LMs) simultaneously, based on the policy\ngradient approach. Under some mild technical conditions, the proposed\ndecentralized policy gradient algorithm converges almost surely to a local\noptimal solution. On the other hand, in the non-cooperative POSG formulation,\nthe transmitter nodes are non-cooperative. We extend the decentralized policy\ngradient solution and establish the technical proof for almost-sure convergence\nof the learning algorithms. In both cases, the solutions are very robust to\nmodel variations. Finally, the delay performance of the proposed solutions are\ncompared with conventional baseline schemes for interference networks and it is\nillustrated that substantial delay performance gain and energy savings can be\nachieved. \n\n"}
{"id": "1202.2239", "contents": "Title: Charmed and strange baryon resonances with heavy-quark spin symmetry Abstract: We study charmed and strange baryon resonances that are generated dynamically\nby a unitary baryon-meson coupled-channel model which incorporates heavy-quark\nspin symmetry. This is accomplished by extending the SU(3) Weinberg-Tomozawa\nchiral Lagrangian to SU(8) spin-flavor symmetry plus a suitable symmetry\nbreaking. The model produces resonances with negative parity from s-wave\ninteraction of pseudoscalar and vector mesons with $1/2^+$ and $3/2^+$ baryons.\nResonances in all the isospin, spin, and strange sectors with one, two, and\nthree charm units are studied. Our results are compared with experimental data\nfrom several facilities, such as the CLEO, Belle or BaBar Collaborations, as\nwell as with other theoretical models. Some of our dynamically generated states\ncan be readily assigned to resonances found experimentally, while others do not\nhave a straightforward identification and require the compilation of more data\nand also a refinement of the model. In particular, we identify the\n$\\Xi_c(2790)$ and $\\Xi_c(2815)$ resonances as possible candidates for a\nheavy-quark spin symmetry doublet. \n\n"}
{"id": "1202.4591", "contents": "Title: Additive Entropies of Partitions Abstract: We provide, under minimal continuity assumptions, a description of\n\\textsl{additive partition entropies}. They are real functions $I$ on the set\nof finite partitions that are additive on stochastically independent partitions\nin a given probability space. \n\n"}
{"id": "1202.5413", "contents": "Title: On the Joint Error-and-Erasure Decoding for Irreducible Polynomial\n  Remainder Codes Abstract: A general class of polynomial remainder codes is considered. Such codes are\nvery flexible in rate and length and include Reed-Solomon codes as a special\ncase.\n  As an extension of previous work, two joint error-and-erasure decoding\napproaches are proposed. In particular, both the decoding approaches by means\nof a fixed transform are treated in a way compatible with the error-only\ndecoding. In the end, a collection of gcd-based decoding algorithm is obtained,\nsome of which appear to be new even when specialized to Reed-Solomon codes. \n\n"}
{"id": "1202.5474", "contents": "Title: Pareto Boundary of the Rate Region for Single-Stream MIMO Interference\n  Channels: Linear Transceiver Design Abstract: We consider a multiple-input multiple-output (MIMO) interference channel\n(IC), where a single data stream per user is transmitted and each receiver\ntreats interference as noise. The paper focuses on the open problem of\ncomputing the outermost boundary (so-called Pareto boundary-PB) of the\nachievable rate region under linear transceiver design. The Pareto boundary\nconsists of the strict PB and non-strict PB. For the two user case, we compute\nthe non-strict PB and the two ending points of the strict PB exactly. For the\nstrict PB, we formulate the problem to maximize one rate while the other rate\nis fixed such that a strict PB point is reached. To solve this non-convex\noptimization problem which results from the hard-coupled two transmit\nbeamformers, we propose an alternating optimization algorithm. Furthermore, we\nextend the algorithm to the multi-user scenario and show convergence. Numerical\nsimulations illustrate that the proposed algorithm computes a sequence of\nwell-distributed operating points that serve as a reasonable and complete inner\nbound of the strict PB compared with existing methods. \n\n"}
{"id": "1203.0731", "contents": "Title: Coordination via a relay Abstract: In this paper, we study the problem of coordinating two nodes which can only\nexchange information via a relay at limited rates. The nodes are allowed to do\na two-round interactive two-way communication with the relay, after which they\nshould be able to generate i.i.d. copies of two random variables with a given\njoint distribution within a vanishing total variation distance. We prove inner\nand outer bounds on the coordination capacity region for this problem. Our\ninner bound is proved using the technique of \"output statistics of random\nbinning\" that has recently been developed by Yassaee, et al. \n\n"}
{"id": "1203.2468", "contents": "Title: Diversity, Coding, and Multiplexing Trade-Off of Network-Coded\n  Cooperative Wireless Networks Abstract: In this paper, we study the performance of network-coded cooperative\ndiversity systems with practical communication constraints. More specifically,\nwe investigate the interplay between diversity, coding, and multiplexing gain\nwhen the relay nodes do not act as dedicated repeaters, which only forward data\npackets transmitted by the sources, but they attempt to pursue their own\ninterest by forwarding packets which contain a network-coded version of\nreceived and their own data. We provide a very accurate analysis of the Average\nBit Error Probability (ABEP) for two network topologies with three and four\nnodes, when practical communication constraints, i.e., erroneous decoding at\nthe relays and fading over all the wireless links, are taken into account.\nFurthermore, diversity and coding gain are studied, and advantages and\ndisadvantages of cooperation and binary Network Coding (NC) are highlighted.\nOur results show that the throughput increase introduced by NC is offset by a\nloss of diversity and coding gain. It is shown that there is neither a coding\nnor a diversity gain for the source node when the relays forward a\nnetwork-coded version of received and their own data. Compared to other results\navailable in the literature, the conclusion is that binary NC seems to be more\nuseful when the relay nodes act only on behalf of the source nodes, and do not\nmix their own packets to the received ones. Analytical derivation and findings\nare substantiated through extensive Monte Carlo simulations. \n\n"}
{"id": "1203.3002", "contents": "Title: A Proximal-Gradient Homotopy Method for the Sparse Least-Squares Problem Abstract: We consider solving the $\\ell_1$-regularized least-squares ($\\ell_1$-LS)\nproblem in the context of sparse recovery, for applications such as compressed\nsensing. The standard proximal gradient method, also known as iterative\nsoft-thresholding when applied to this problem, has low computational cost per\niteration but a rather slow convergence rate. Nevertheless, when the solution\nis sparse, it often exhibits fast linear convergence in the final stage. We\nexploit the local linear convergence using a homotopy continuation strategy,\ni.e., we solve the $\\ell_1$-LS problem for a sequence of decreasing values of\nthe regularization parameter, and use an approximate solution at the end of\neach stage to warm start the next stage. Although similar strategies have been\nstudied in the literature, there have been no theoretical analysis of their\nglobal iteration complexity. This paper shows that under suitable assumptions\nfor sparse recovery, the proposed homotopy strategy ensures that all iterates\nalong the homotopy solution path are sparse. Therefore the objective function\nis effectively strongly convex along the solution path, and geometric\nconvergence at each stage can be established. As a result, the overall\niteration complexity of our method is $O(\\log(1/\\epsilon))$ for finding an\n$\\epsilon$-optimal solution, which can be interpreted as global geometric rate\nof convergence. We also present empirical results to support our theoretical\nanalysis. \n\n"}
{"id": "1203.5915", "contents": "Title: On the Feasibility of Network Alignment for Three-Source\n  Three-Destination Multiple Unicast Networks with Delays Abstract: A transform approach to network coding was introduced by Bavirisetti et al.\n(arXiv:1103.3882v3 [cs.IT]) as a tool to view wireline networks with delays as\n$k$-instantaneous networks (for some large $k$). When the local encoding\nkernels (LEKs) of the network are varied with every time block of length $k >\n1$, the network is said to use block time varying LEKs. In this work, we\npropose a Precoding Based Network Alignment (PBNA) scheme based on transform\napproach and block time varying LEKs for three-source three-destination\nmultiple unicast network with delays (3-S 3-D MUN-D). In a recent work, Meng et\nal. (arXiv:1202.3405v1 [cs.IT]) reduced the infinite set of sufficient\nconditions for feasibility of PBNA in a three-source three-destination\ninstantaneous multiple unicast network as given by Das et al.\n(arXiv:1008.0235v1 [cs.IT]) to a finite set and also showed that the conditions\nare necessary. We show that the conditions of Meng et al. are also necessary\nand sufficient conditions for feasibility of PBNA based on transform approach\nand block time varying LEKs for 3-S 3-D MUN-D. \n\n"}
{"id": "1203.6233", "contents": "Title: Information Theory of DNA Shotgun Sequencing Abstract: DNA sequencing is the basic workhorse of modern day biology and medicine.\nShotgun sequencing is the dominant technique used: many randomly located short\nfragments called reads are extracted from the DNA sequence, and these reads are\nassembled to reconstruct the original sequence. A basic question is: given a\nsequencing technology and the statistics of the DNA sequence, what is the\nminimum number of reads required for reliable reconstruction? This number\nprovides a fundamental limit to the performance of {\\em any} assembly\nalgorithm. For a simple statistical model of the DNA sequence and the read\nprocess, we show that the answer admits a critical phenomena in the asymptotic\nlimit of long DNA sequences: if the read length is below a threshold,\nreconstruction is impossible no matter how many reads are observed, and if the\nread length is above the threshold, having enough reads to cover the DNA\nsequence is sufficient to reconstruct. The threshold is computed in terms of\nthe Renyi entropy rate of the DNA sequence. We also study the impact of noise\nin the read process on the performance. \n\n"}
{"id": "1204.0556", "contents": "Title: Decomposition Methods for Large Scale LP Decoding Abstract: When binary linear error-correcting codes are used over symmetric channels, a\nrelaxed version of the maximum likelihood decoding problem can be stated as a\nlinear program (LP). This LP decoder can be used to decode error-correcting\ncodes at bit-error-rates comparable to state-of-the-art belief propagation (BP)\ndecoders, but with significantly stronger theoretical guarantees. However, LP\ndecoding when implemented with standard LP solvers does not easily scale to the\nblock lengths of modern error correcting codes. In this paper we draw on\ndecomposition methods from optimization theory, specifically the Alternating\nDirections Method of Multipliers (ADMM), to develop efficient distributed\nalgorithms for LP decoding.\n  The key enabling technical result is a \"two-slice\" characterization of the\ngeometry of the parity polytope, which is the convex hull of all codewords of a\nsingle parity check code. This new characterization simplifies the\nrepresentation of points in the polytope. Using this simplification, we develop\nan efficient algorithm for Euclidean norm projection onto the parity polytope.\nThis projection is required by ADMM and allows us to use LP decoding, with all\nits theoretical guarantees, to decode large-scale error correcting codes\nefficiently.\n  We present numerical results for LDPC codes of lengths more than 1000. The\nwaterfall region of LP decoding is seen to initiate at a slightly higher\nsignal-to-noise ratio than for sum-product BP, however an error floor is not\nobserved for LP decoding, which is not the case for BP. Our implementation of\nLP decoding using ADMM executes as fast as our baseline sum-product BP decoder,\nis fully parallelizable, and can be seen to implement a type of message-passing\nwith a particularly simple schedule. \n\n"}
{"id": "1204.0839", "contents": "Title: A Constrained Random Demodulator for Sub-Nyquist Sampling Abstract: This paper presents a significant modification to the Random Demodulator (RD)\nof Tropp et al. for sub-Nyquist sampling of frequency-sparse signals. The\nmodification, termed constrained random demodulator, involves replacing the\nrandom waveform, essential to the operation of the RD, with a constrained\nrandom waveform that has limits on its switching rate because fast switching\nwaveforms may be hard to generate cleanly. The result is a relaxation on the\nhardware requirements with a slight, but manageable, decrease in the recovery\nguarantees. The paper also establishes the importance of properly choosing the\nstatistics of the constrained random waveform. If the power spectrum of the\nrandom waveform matches the distribution on the tones of the input signal\n(i.e., the distribution is proportional to the power spectrum), then recovery\nof the input signal tones is improved. The theoretical guarantees provided in\nthe paper are validated through extensive numerical simulations and phase\ntransition plots. \n\n"}
{"id": "1205.4983", "contents": "Title: Collective Sensing-Capacity of Bacteria Populations Abstract: The design of biological networks using bacteria as the basic elements of the\nnetwork is initially motivated by a phenomenon called quorum sensing. Through\nquorum sensing, each bacterium performs sensing the medium and communicating it\nto others via molecular communication. As a result, bacteria can orchestrate\nand act collectively and perform tasks impossible otherwise. In this paper, we\nconsider a population of bacteria as a single node in a network. In our version\nof biological communication networks, such a node would communicate with one\nanother via molecular signals. As a first step toward such networks, this paper\nfocuses on the study of the transfer of information to the population (i.e.,\nthe node) by stimulating it with a concentration of special type of a molecules\nsignal. These molecules trigger a chain of processes inside each bacteria that\nresults in a final output in the form of light or fluorescence. Each stage in\nthe process adds noise to the signal carried to the next stage. Our objective\nis to measure (compute) the maximum amount of information that we can transfer\nto the node. This can be viewed as the collective sensing capacity of the node.\nThe molecular concentration, which carries the information, is the input to the\nnode, which should be estimated by observing the produced light as the output\nof the node (i.e., the entire population of bacteria forming the node). We\nfocus on the noise caused by the random process of trapping molecules at the\nreceptors as well as the variation of outputs of different bacteria in the\nnode. The capacity variation with the number of bacteria in the node and the\nnumber of receptors per bacteria is obtained. Finally, we investigated the\ncollective sensing capability of the node when a specific form of molecular\nsignaling concentration is used. \n\n"}
{"id": "1206.0937", "contents": "Title: Detecting Activations over Graphs using Spanning Tree Wavelet Bases Abstract: We consider the detection of activations over graphs under Gaussian noise,\nwhere signals are piece-wise constant over the graph. Despite the wide\napplicability of such a detection algorithm, there has been little success in\nthe development of computationally feasible methods with proveable theoretical\nguarantees for general graph topologies. We cast this as a hypothesis testing\nproblem, and first provide a universal necessary condition for asymptotic\ndistinguishability of the null and alternative hypotheses. We then introduce\nthe spanning tree wavelet basis over graphs, a localized basis that reflects\nthe topology of the graph, and prove that for any spanning tree, this approach\ncan distinguish null from alternative in a low signal-to-noise regime. Lastly,\nwe improve on this result and show that using the uniform spanning tree in the\nbasis construction yields a randomized test with stronger theoretical\nguarantees that in many cases matches our necessary conditions. Specifically,\nwe obtain near-optimal performance in edge transitive graphs, $k$-nearest\nneighbor graphs, and $\\epsilon$-graphs. \n\n"}
{"id": "1206.3381", "contents": "Title: On the Cover-Hart Inequality: What's a Sample of Size One Worth? Abstract: Bob predicts a future observation based on a sample of size one. Alice can\ndraw a sample of any size before issuing her prediction. How much better can\nshe do than Bob? Perhaps surprisingly, under a large class of loss functions,\nwhich we refer to as the Cover-Hart family, the best Alice can do is to halve\nBob's risk. In this sense, half the information in an infinite sample is\ncontained in a sample of size one. The Cover-Hart family is a convex cone that\nincludes metrics and negative definite functions, subject to slight regularity\nconditions. These results may help explain the small relative differences in\nempirical performance measures in applied classification and forecasting\nproblems, as well as the success of reasoning and learning by analogy in\ngeneral, and nearest neighbor techniques in particular. \n\n"}
{"id": "1206.4755", "contents": "Title: The Practical Challenges of Interference Alignment Abstract: Interference alignment (IA) is a revolutionary wireless transmission strategy\nthat reduces the impact of interference. The idea of interference alignment is\nto coordinate multiple transmitters so that their mutual interference aligns at\nthe receivers, facilitating simple interference cancellation techniques. Since\nIA's inception, researchers have investigated its performance and proposed\nimprovements, verifying IA's ability to achieve the maximum degrees of freedom\n(an approximation of sum capacity) in a variety of settings, developing\nalgorithms for determining alignment solutions, and generalizing transmission\nstrategies that relax the need for perfect alignment but yield better\nperformance. This article provides an overview of the concept of interference\nalignment as well as an assessment of practical issues including performance in\nrealistic propagation environments, the role of channel state information at\nthe transmitter, and the practicality of interference alignment in large\nnetworks. \n\n"}
{"id": "1206.6145", "contents": "Title: Two-way Networks: when Adaptation is Useless Abstract: In two-way networks, nodes act as both sources and destinations of messages.\nThis allows for \"adaptation\" at or \"interaction\" between the nodes - a node's\nchannel inputs may be functions of its message(s) and previously received\nsignals. How to best adapt is key to two-way communication, rendering it\nchallenging. However, examples exist of point-to-point channels where\nadaptation is not beneficial from a capacity perspective. We ask whether\nanalogous examples exist for multi-user two-way networks.\n  We first consider deterministic two-way channel models: the binary modulo-2\naddition channel and a generalization thereof, and the linear deterministic\nchannel. For these deterministic models we obtain the capacity region for the\ntwo-way multiple access/broadcast channel, the two-way Z channel and the\ntwo-way interference channel (IC). In all cases we permit all nodes to adapt\nchannel inputs to past outputs (except for portions of the linear deterministic\ntwo-way IC where we only permit 2 of the 4 nodes to fully adapt). However, we\nshow that this adaptation is useless from a capacity region perspective and\ncapacity is achieved by strategies where the channel inputs at each use do not\nadapt to previous inputs. Finally, we consider the Gaussian two-way IC, and\nshow that partial adaptation is useless when the interference is very strong.\nIn the strong and weak interference regimes, we show that the non-adaptive Han\nand Kobayashi scheme utilized in parallel in both directions achieves to within\na constant gap for the symmetric rate of the fully (some regimes) or partially\n(remaining regimes) adaptive models.\n  The central technical contribution is the derivation of new, computable outer\nbounds which allow for adaptation. Inner bounds follow from non-adaptive\nachievability schemes of the corresponding one-way channel models. \n\n"}
{"id": "1207.0782", "contents": "Title: Polar write once memory codes Abstract: A coding scheme for write once memory (WOM) using polar codes is presented.\nIt is shown that the scheme achieves the capacity region of noiseless WOMs when\nan arbitrary number of multiple writes is permitted. The encoding and decoding\ncomplexities scale as O(N log N) where N is the blocklength. For N sufficiently\nlarge, the error probability decreases sub-exponentially in N. The results can\nbe generalized from binary to generalized WOMs, described by an arbitrary\ndirected acyclic graph, using nonbinary polar codes. In the derivation we also\nobtain results on the typical distortion of polar codes for lossy source\ncoding. Some simulation results with finite length codes are presented. \n\n"}
{"id": "1207.1986", "contents": "Title: On the Capacity Region of Two-User Linear Deterministic Interference\n  Channel and Its Application to Multi-Session Network Coding Abstract: In this paper, we study the capacity of the two-user multiple-input\nmultiple-output (MIMO) linear deterministic interference channel (IC), with\npossible correlations within/between the channel matrices. The capacity region\nis characterized in terms of the rank of the channel matrices. It is shown that\n\\emph{linear precoding} with Han-Kobayashi type of rate-splitting, i.e.,\nsplitting the information-bearing symbols of each user into common and private\nparts, is sufficient to achieve all the rate pairs in the derived capacity\nregion. The capacity result is applied to obtain an achievable rate region for\nthe double-unicast networks with random network coding at the intermediate\nnodes, which can be modeled by the two-user MIMO linear deterministic IC\nstudied. It is shown that the newly proposed achievable region is strictly\nlarger than the existing regions in the literature. \n\n"}
{"id": "1207.4763", "contents": "Title: Buffer-Aided Relaying with Adaptive Link Selection - Fixed and Mixed\n  Rate Transmission Abstract: We consider a simple network consisting of a source, a half-duplex DF relay\nwith a buffer, and a destination. We assume that the direct source-destination\nlink is not available and all links undergo fading. We propose two new\nbuffer-aided relaying schemes. In the first scheme, neither the source nor the\nrelay have CSIT, and consequently, both nodes are forced to transmit with fixed\nrates. In contrast, in the second scheme, the source does not have CSIT and\ntransmits with fixed rate but the relay has CSIT and adapts its transmission\nrate accordingly. In the absence of delay constraints, for both fixed rate and\nmixed rate transmission, we derive the throughput-optimal buffer-aided relaying\nprotocols which select either the source or the relay for transmission based on\nthe instantaneous SNRs of the source-relay and the relay-destination links. In\naddition, for the delay constrained case, we develop buffer-aided relaying\nprotocols that achieve a predefined average delay. Compared to conventional\nrelaying protocols, which select the transmitting node according to a\npredefined schedule independent of the link instantaneous SNRs, the proposed\nbuffer-aided protocols with adaptive link selection achieve large performance\ngains. In particular, for fixed rate transmission, we show that the proposed\nprotocol achieves a diversity gain of two as long as an average delay of more\nthan three time slots can be afforded. Furthermore, for mixed rate transmission\nwith an average delay of $E{T}$ time slots, a multiplexing gain of\n$r=1-1/(2E{T})$ is achieved. Hence, for mixed rate transmission, for\nsufficiently large average delays, buffer-aided half-duplex relaying with and\nwithout adaptive link selection does not suffer from a multiplexing gain loss\ncompared to full-duplex relaying. \n\n"}
{"id": "1207.6380", "contents": "Title: About the Linear Complexity of Ding-Hellesth Generalized Cyclotomic\n  Binary Sequences of Any Period Abstract: We defined sufficient conditions for designing Ding-Helleseth sequences with\narbitrary period and high linear complexity for generalized cyclotomies. Also\nwe discuss the method of computing the linear complexity of Ding-Helleseth\nsequences in the general case. \n\n"}
{"id": "1207.6902", "contents": "Title: Interference Alignment with Quantized Grassmannian Feedback in the\n  K-user Constant MIMO Interference Channel Abstract: A simple channel state information (CSI) feedback scheme is proposed for\ninterference alignment (IA) over the K-user constant\nMultiple-Input-Multiple-Output Interference Channel (MIMO IC). The proposed\ntechnique relies on the identification of invariants in the IA equations, which\nenables the reformulation of the CSI quantization problem as a single\nquantization on the Grassmann manifold at each receiver. The scaling of the\nnumber of feedback bits with the transmit power sufficient to preserve the\nmultiplexing gain that can be achieved under perfect CSI is established. We\nshow that the CSI feedback requirements of the proposed technique are better\n(lower) than what is required when using previously published methods, for\nsystem dimensions (number of users and antennas) of practical interest.\nFurthermore, we show through simulations that this advantage persists at low\nSNR, in the sense that the proposed technique yields a higher sum-rate\nperformance for a given number of feedback bits. Finally, to complement our\nanalysis, we introduce a statistical model that faithfully captures the\nproperties of the quantization error obtained for random vector quantization\n(RVQ) on the Grassmann manifold for large codebooks; this enables the numerical\n(Monte-Carlo) analysis of general Grassmannian RVQ schemes for codebook sizes\nthat would be impractically large to simulate. \n\n"}
{"id": "1208.1400", "contents": "Title: Second-order asymptotics for quantum hypothesis testing Abstract: In the asymptotic theory of quantum hypothesis testing, the minimal error\nprobability of the first kind jumps sharply from zero to one when the error\nexponent of the second kind passes by the point of the relative entropy of the\ntwo states in an increasing way. This is well known as the direct part and\nstrong converse of quantum Stein's lemma. Here we look into the behavior of\nthis sudden change and have make it clear how the error of first kind grows\nsmoothly according to a lower order of the error exponent of the second kind,\nand hence we obtain the second-order asymptotics for quantum hypothesis\ntesting. This actually implies quantum Stein's lemma as a special case.\nMeanwhile, our analysis also yields tight bounds for the case of finite sample\nsize. These results have potential applications in quantum information theory.\nOur method is elementary, based on basic linear algebra and probability theory.\nIt deals with the achievability part and the optimality part in a unified\nfashion. \n\n"}
{"id": "1208.2043", "contents": "Title: High-Dimensional Screening Using Multiple Grouping of Variables Abstract: Screening is the problem of finding a superset of the set of non-zero entries\nin an unknown p-dimensional vector \\beta* given n noisy observations.\nNaturally, we want this superset to be as small as possible. We propose a novel\nframework for screening, which we refer to as Multiple Grouping (MuG), that\ngroups variables, performs variable selection over the groups, and repeats this\nprocess multiple number of times to estimate a sequence of sets that contains\nthe non-zero entries in \\beta*. Screening is done by taking an intersection of\nall these estimated sets. The MuG framework can be used in conjunction with any\ngroup based variable selection algorithm. In the high-dimensional setting,\nwhere p >> n, we show that when MuG is used with the group Lasso estimator,\nscreening can be consistently performed without using any tuning parameter. Our\nnumerical simulations clearly show the merits of using the MuG framework in\npractice. \n\n"}
{"id": "1208.3029", "contents": "Title: Fast Adaptive S-ALOHA Scheme for Event-driven M2M Communications\n  (Journal version) Abstract: Supporting massive device transmission is challenging in Machine-to-Machine\n(M2M) communications. Particularly, in event-driven M2M communications, a large\nnumber of devices activate within a short period of time, which in turn causes\nhigh radio congestions and severe access delay. To address this issue, we\npropose a Fast Adaptive S-ALOHA (FASA) scheme for random access control of M2M\ncommunication systems with bursty traffic. Instead of the observation in a\nsingle slot, the statistics of consecutive idle and collision slots are used in\nFASA to accelerate the tracking process of network status which is critical for\noptimizing S-ALOHA systems. Using drift analysis, we design the FASA scheme\nsuch that the estimate of the backlogged devices converges fast to the true\nvalue. Furthermore, by examining the $T$-slot drifts, we prove that the\nproposed FASA scheme is stable as long as the average arrival rate is smaller\nthan $e^{-1}$, in the sense that the Markov Chain derived from the scheme is\ngeometrically ergodic. Simulation results demonstrate that the proposed FASA\nscheme outperforms traditional additive schemes such as PB-ALOHA and achieves\nnear-optimal performance in reducing access delay. Moreover, compared to\nmultiplicative schemes, FASA shows its robustness under heavy traffic load in\naddition to better delay performance. \n\n"}
{"id": "1208.4423", "contents": "Title: Estimation in Phase-Shift and Forward Wireless Sensor Networks Abstract: We consider a network of single-antenna sensors that observe an unknown\ndeterministic parameter. Each sensor applies a phase shift to the observation\nand the sensors simultaneously transmit the result to a multi-antenna fusion\ncenter (FC). Based on its knowledge of the wireless channel to the sensors, the\nFC calculates values for the phase factors that minimize the variance of the\nparameter estimate, and feeds this information back to the sensors. The use of\na phase-shift-only transmission scheme provides a simplified analog\nimplementation at the sensor, and also leads to a simpler algorithm design and\nperformance analysis. We propose two algorithms for this problem, a numerical\nsolution based on a relaxed semidefinite programming problem, and a closed-form\nsolution based on the analytic constant modulus algorithm. Both approaches are\nshown to provide performance close to the theoretical bound. We derive\nasymptotic performance analyses for cases involving large numbers of sensors or\nlarge numbers of FC antennas, and we also study the impact of phase errors at\nthe sensor transmitters. Finally, we consider the sensor selection problem, in\nwhich only a subset of the sensors is chosen to send their observations to the\nFC. \n\n"}
{"id": "1208.4651", "contents": "Title: Throughput Maximization for an Energy Harvesting Communication System\n  with Processing Cost Abstract: In wireless networks, energy consumed for communication includes both the\ntransmission and the processing energy. In this paper, point-to-point\ncommunication over a fading channel with an energy harvesting transmitter is\nstudied considering jointly the energy costs of transmission and processing.\nUnder the assumption of known energy arrival and fading profiles, optimal\ntransmission policy for throughput maximization is investigated. Assuming that\nthe transmitter has sufficient amount of data in its buffer at the beginning of\nthe transmission period, the average throughput by a given deadline is\nmaximized. Furthermore, a \"directional glue pouring algorithm\" that computes\nthe optimal transmission policy is described. \n\n"}
{"id": "1209.2192", "contents": "Title: Power Allocation for Conventional and Buffer-Aided Link Adaptive\n  Relaying Systems with Energy Harvesting Nodes Abstract: Energy harvesting (EH) nodes can play an important role in cooperative\ncommunication systems which do not have a continuous power supply. In this\npaper, we consider the optimization of conventional and buffer-aided link\nadaptive EH relaying systems, where an EH source communicates with the\ndestination via an EH decode-and-forward relay. In conventional relaying,\nsource and relay transmit signals in consecutive time slots whereas in\nbuffer-aided link adaptive relaying, the state of the source-relay and\nrelay-destination channels determines whether the source or the relay is\nselected for transmission. Our objective is to maximize the system throughput\nover a finite number of transmission time slots for both relaying protocols. In\ncase of conventional relaying, we propose an offline and several online joint\nsource and relay transmit power allocation schemes. For offline power\nallocation, we formulate an optimization problem which can be solved optimally.\nFor the online case, we propose a dynamic programming (DP) approach to compute\nthe optimal online transmit power. To alleviate the complexity inherent to DP,\nwe also propose several suboptimal online power allocation schemes. For\nbuffer-aided link adaptive relaying, we show that the joint offline\noptimization of the source and relay transmit powers along with the link\nselection results in a mixed integer non-linear program which we solve\noptimally using the spatial branch-and-bound method. We also propose an\nefficient online power allocation scheme and a naive online power allocation\nscheme for buffer-aided link adaptive relaying. Our results show that link\nadaptive relaying provides performance improvement over conventional relaying\nat the expense of a higher computational complexity. \n\n"}
{"id": "1209.4145", "contents": "Title: Network Massive MIMO for Cell-Boundary Users: From a Precoding\n  Normalization Perspective Abstract: In this paper, we propose network massive multiple- input multiple-output\n(MIMO) systems, where three radio units (RUs) connected via one digital unit\n(DU) support multiple user equipments (UEs) at a cell-boundary through the same\nradio resource, i.e., the same frequency/time band. For precoding designs,\nzero-forcing (ZF) and matched filter (MF) with vector or matrix normalization\nare considered. We also derive the formulae of the lower and upper bounds of\nthe achievable sum rate for each precoding. Based on our analytical results, we\nobserve that vector normalization is better for ZF while matrix normalization\nis better for MF. Given antenna configurations, we also derive the optimal\nswitching point as a function of the number of active users in a network.\nNumerical simulations confirm our analytical \n\n"}
{"id": "1209.4729", "contents": "Title: Minimum Bias Measurements with ALICE at the LHC Abstract: ALICE (A Large Ion Collider Experiment) is one of the seven experiments at\nthe the Large Hadron Collider (LHC) at CERN, Geneva, Switzerland. ALICE is\nespecially designed for heavy-ion collisions but it also operates a rich\nproton-proton (pp) program. ALICE has collected pp collision data at\n$\\sqrt{s}=$ 0.9, 2.36, 2.76, and 7 TeV and lead-lead (Pb--Pb) collision data at\n$\\sqrt{s_{\\mathrm{NN}}}=$2.76 TeV. Here, we report minimum bias measurements\nobtained until the end of 2010: the results include measurements of\ncharged-particle pseudorapidity, multiplicity and transverse momentum\ndistributions. Also, the two-pion Bose-Einstein correlation and the measurement\nof antiproton-to-proton ratio will be discussed. Furthermore, results on the\nproduction of identified particles including strange particles will be shown as\nwell as first results from the first Pb--Pb run at the LHC. \n\n"}
{"id": "1209.5370", "contents": "Title: Secure Degrees of Freedom of One-hop Wireless Networks Abstract: We study the secure degrees of freedom (d.o.f.) of one-hop wireless networks\nby considering four fundamental Gaussian network structures: wiretap channel,\nbroadcast channel with confidential messages, interference channel with\nconfidential messages, and multiple access wiretap channel. The secure d.o.f.\nof the canonical Gaussian wiretap channel with no helpers is zero. It has been\nknown that a strictly positive secure d.o.f. can be obtained in the Gaussian\nwiretap channel by using a helper which sends structured cooperative signals.\nWe show that the exact secure d.o.f. of the Gaussian wiretap channel with a\nhelper is 1/2. Our achievable scheme is based on real interference alignment\nand cooperative jamming, which renders the message signal and the cooperative\njamming signal separable at the legitimate receiver, but aligns them perfectly\nat the eavesdropper preventing any reliable decoding of the message signal. Our\nconverse is based on two key lemmas. The first lemma quantifies the secrecy\npenalty by showing that the net effect of an eavesdropper on the system is that\nit eliminates one of the independent channel inputs. The second lemma\nquantifies the role of a helper by developing a direct relationship between the\ncooperative jamming signal of a helper and the message rate. We extend this\nresult to the case of M helpers, and show that the exact secure d.o.f. in this\ncase is M/(M+1). We then generalize this approach to more general network\nstructures with multiple messages. We show that the sum secure d.o.f. of the\nGaussian broadcast channel with confidential messages and M helpers is 1, the\nsum secure d.o.f. of the two-user interference channel with confidential\nmessages is 2/3, the sum secure d.o.f. of the two-user interference channel\nwith confidential messages and M helpers is 1, and the sum secure d.o.f. of the\nK-user multiple access wiretap channel is K(K-1)/(K(K-1)+1). \n\n"}
{"id": "1209.6030", "contents": "Title: Nuclear modification of high transverse momentum particle production in\n  p+A collisions at RHIC and LHC Abstract: We present results and predictions for the nuclear modification of the\ndifferential cross sections for inclusive light hadron and prompt photon\nproduction in minimum bias d+Au collisions at $\\sqrt{s} = 200$ GeV and minimum\nbias p+Pb collisions at $\\sqrt{s} = 5$ TeV at RHIC and LHC, respectively. Our\ncalculations combine the leading order perturbative QCD formalism with cold\nnuclear matter effects that arise from the elastic, inelastic and coherent\nmultiple scattering of partons in large nuclei. We find that a theoretical\napproach that includes the isospin effect, Cronin effect, cold nuclear matter\nenergy loss and dynamical shadowing can describe the RHIC d+Au data rather\nwell. The LHC p+Pb predictions will soon be confronted by new experimental\nresults to help clarify the magnitude and origin of cold nuclear matter effects\nand facilitate precision dense QCD matter tomography. \n\n"}
{"id": "1210.2484", "contents": "Title: Semi-Quantitative Group Testing: A Unifying Framework for Group Testing\n  with Applications in Genotyping Abstract: We propose a novel group testing method, termed semi-quantitative group\ntesting, motivated by a class of problems arising in genome screening\nexperiments. Semi-quantitative group testing (SQGT) is a (possibly) non-binary\npooling scheme that may be viewed as a concatenation of an adder channel and an\ninteger-valued quantizer. In its full generality, SQGT may be viewed as a\nunifying framework for group testing, in the sense that most group testing\nmodels are special instances of SQGT. For the new testing scheme, we define the\nnotion of SQ-disjunct and SQ-separable codes, representing generalizations of\nclassical disjunct and separable codes. We describe several combinatorial and\nprobabilistic constructions for such codes. While for most of these\nconstructions we assume that the number of defectives is much smaller than\ntotal number of test subjects, we also consider the case in which there is no\nrestriction on the number of defectives and they may be as large as the total\nnumber of subjects. For the codes constructed in this paper, we describe a\nnumber of efficient decoding algorithms. In addition, we describe a belief\npropagation decoder for sparse SQGT codes for which no other efficient decoder\nis currently known. Finally, we define the notion of capacity of SQGT and\nevaluate it for some special choices of parameters using information theoretic\nmethods. \n\n"}
{"id": "1210.2772", "contents": "Title: Measurements of the electron-positron continuum in ALICE Abstract: The status of the analysis of electron-positron pairs measured by ALICE in pp\ncollisions at $\\sqrt{s} = 7$ TeV and central Pb-Pb collisions at\n$\\sqrt{s_\\mathrm{NN}}=2.76$ TeV is presented. Key questions and the main\nchallenges of the analysis are discussed on the basis of first raw invariant\nmass spectra for both collision systems. \n\n"}
{"id": "1210.5217", "contents": "Title: Dijet production, collision centrality and backgrounds in high-energy\n  p-p collisions Abstract: Two aspects of high-energy \\pp collisions share common phenomenological\nelements: (a) A correlation between jet production and \\pp centrality is\nsuggested by the transverse partonic structure of hadrons inferred from\ndeep-inelastic scattering data. (b) The {\\em underlying event} (UE) is defined\nas the final-state particles complementary to a triggered high-energy dijet. An\nobservable common to both topics is variation of so-called {\\em transverse\nmultiplicity} $N_\\perp$ with a $p_{t,trig}$ dijet trigger. We test assumptions\nassociated with \\pp collision centrality and the UE. We determine the nature of\nthe UE and explore the relation between jet production and \\pp centrality. We\nuse the {\\em two-component model} (TCM) of spectra and correlations derived\nfrom 200 GeV \\pp collisions to construct a simulated particle distribution on\n$(p_t,n_{ch})$ to predict the $N_\\perp$ response to $p_{t,trig}$. The $p_t$\nspectrum TCM combined in this analysis with measured minimum-bias \\pp angular\ncorrelations suggests that the UE includes a substantial contribution from the\ntriggered dijet in addition to the contribution from projectile fragmentation\n(beam-beam remnants). The jet contribution to $N_\\perp$ may represent a\nuniversal large-angle base common to all dijets that extends across $2\\pi$\nazimuth. The analysis further suggests that \\pp centrality is not controlled\nsignificantly by $p_{t,trig}$ but may be correlated to some extent with an\nimposed $n_{ch}$ condition, depending on the role of fluctuations. Future\ncorrelation studies may better determine the role of \\pp centrality. These\nresults may have implications for ongoing RHIC analysis and LHC searches for\nphysics beyond the standard model. \n\n"}
{"id": "1210.6730", "contents": "Title: Measure What Should be Measured: Progress and Challenges in Compressive\n  Sensing Abstract: Is compressive sensing overrated? Or can it live up to our expectations? What\nwill come after compressive sensing and sparsity? And what has Galileo Galilei\ngot to do with it? Compressive sensing has taken the signal processing\ncommunity by storm. A large corpus of research devoted to the theory and\nnumerics of compressive sensing has been published in the last few years.\nMoreover, compressive sensing has inspired and initiated intriguing new\nresearch directions, such as matrix completion. Potential new applications\nemerge at a dazzling rate. Yet some important theoretical questions remain\nopen, and seemingly obvious applications keep escaping the grip of compressive\nsensing. In this paper I discuss some of the recent progress in compressive\nsensing and point out key challenges and opportunities as the area of\ncompressive sensing and sparse representations keeps evolving. I also attempt\nto assess the long-term impact of compressive sensing. \n\n"}
{"id": "1211.0905", "contents": "Title: Heavy Flavor, Quarkonia, and Electroweak Probes at Quark Matter 2012 Abstract: We summarize and discuss some of the experimental and theoretical results on\nheavy flavor, quarkonia, and electro-weak probes presented at Quark Matter\n2012. \n\n"}
{"id": "1211.1932", "contents": "Title: Codes with Local Regeneration Abstract: Regenerating codes and codes with locality are two schemes that have recently\nbeen proposed to ensure data collection and reliability in a distributed\nstorage network. In a situation where one is attempting to repair a failed\nnode, regenerating codes seek to minimize the amount of data downloaded for\nnode repair, while codes with locality attempt to minimize the number of helper\nnodes accessed. In this paper, we provide several constructions for a class of\nvector codes with locality in which the local codes are regenerating codes,\nthat enjoy both advantages. We derive an upper bound on the minimum distance of\nthis class of codes and show that the proposed constructions achieve this\nbound. The constructions include both the cases where the local regenerating\ncodes correspond to the MSR as well as the MBR point on the\nstorage-repair-bandwidth tradeoff curve of regenerating codes. Also included is\na performance comparison of various code constructions for fixed block length\nand minimum distance. \n\n"}
{"id": "1211.2578", "contents": "Title: J/Psi and Psi(2S) production in Pb-Pb collisions with the ALICE Muon\n  Spectrometer at the LHC Abstract: Charmonium states are considered important signatures of the strongly\ninteracting medium created in heavy-ion collisions. In the ALICE experiment,\nthese probes can be investigated in the mu^+mu^- decay channel, in the forward\nrapidity region (2.5<y<4) down to zero transverse momentum. Results on\ncharmonia production in Pb-Pb collisions at sqrt(s_NN)=2.76 TeV are presented.\nThe centrality and transverse momentum dependence of the inclusive J/Psi\nnuclear modification factor are shown and compared with theoretical models.\nFinally, first ALICE results on the Psi(2S) production in Pb-Pb collisions are\nalso discussed. \n\n"}
{"id": "1211.4381", "contents": "Title: Degrees-of-Freedom Region of Time Correlated MISO Broadcast Channel with\n  Perfect Delayed CSIT and Asymmetric Partial Current CSIT Abstract: The impact of imperfect CSIT on the degrees of freedom (DoF) of a time\ncorrelated MISO Broadcast Channel has drawn a lot of attention recently.\nMaddah-Ali and Tse have shown that the completely stale CSIT still benefit the\nDoF. In very recent works, Yang et al. have extended the results by integrating\nthe partial current CSIT for a two-user MISO broadcast channel. However, those\nresearches so far focused on a symmetric case. In this contribution, we\ninvestigate a more general case where the transmitter has knowledge of current\nCSI of both users with unequal qualities. The essential ingredient in our work\nlies in the way to multicast the overheard interference to boost the DoF. The\noptimal DoF region is simply proved and its achievability is shown using a\nnovel transmission scheme assuming an infinite number of channel uses. \n\n"}
{"id": "1211.4657", "contents": "Title: Forest Sparsity for Multi-channel Compressive Sensing Abstract: In this paper, we investigate a new compressive sensing model for\nmulti-channel sparse data where each channel can be represented as a\nhierarchical tree and different channels are highly correlated. Therefore, the\nfull data could follow the forest structure and we call this property as\n\\emph{forest sparsity}. It exploits both intra- and inter- channel correlations\nand enriches the family of existing model-based compressive sensing theories.\nThe proposed theory indicates that only $\\mathcal{O}(Tk+\\log(N/k))$\nmeasurements are required for multi-channel data with forest sparsity, where\n$T$ is the number of channels, $N$ and $k$ are the length and sparsity number\nof each channel respectively. This result is much better than\n$\\mathcal{O}(Tk+T\\log(N/k))$ of tree sparsity, $\\mathcal{O}(Tk+k\\log(N/k))$ of\njoint sparsity, and far better than $\\mathcal{O}(Tk+Tk\\log(N/k))$ of standard\nsparsity. In addition, we extend the forest sparsity theory to the multiple\nmeasurement vectors problem, where the measurement matrix is a block-diagonal\nmatrix. The result shows that the required measurement bound can be the same as\nthat for dense random measurement matrix, when the data shares equal energy in\neach channel. A new algorithm is developed and applied on four example\napplications to validate the benefit of the proposed model. Extensive\nexperiments demonstrate the effectiveness and efficiency of the proposed theory\nand algorithm. \n\n"}
{"id": "1211.5252", "contents": "Title: Non-Asymptotic Analysis of Privacy Amplification via Renyi Entropy and\n  Inf-Spectral Entropy Abstract: This paper investigates the privacy amplification problem, and compares the\nexisting two bounds: the exponential bound derived by one of the authors and\nthe min-entropy bound derived by Renner. It turns out that the exponential\nbound is better than the min-entropy bound when a security parameter is rather\nsmall for a block length, and that the min-entropy bound is better than the\nexponential bound when a security parameter is rather large for a block length.\nFurthermore, we present another bound that interpolates the exponential bound\nand the min-entropy bound by a hybrid use of the Renyi entropy and the\ninf-spectral entropy. \n\n"}
{"id": "1211.7298", "contents": "Title: Strange and Multi-Strange Particle Production in ALICE Abstract: The production of strange and multi-strange hadrons in proton-proton (pp) and\nlead-lead (Pb-Pb) collisions is studied with the ALICE experiment at the CERN\nLHC. These particles are reconstructed via their weak decay topologies,\nexploiting the tracking and particle identification capabilities of ALICE.\nMeasurements of central rapidity yields of $\\Lambda$, $\\Xi^{-}$ and\n$\\Omega^{-}$ baryons, their antiparticles and ${\\mathrm K}^{0}_{S}$ mesons are\npresented as a function of transverse momentum for Pb-Pb collisions at\n$\\sqrt{s_{NN}}=2.76$ TeV. They are compared to those observed in pp collisions\nas well as to results from lower energy nucleus-nucleus measurements. \n\n"}
{"id": "1212.0494", "contents": "Title: Identification Via Quantum Channels Abstract: We review the development of the quantum version of Ahlswede and Dueck's\ntheory of identification via channels. As is often the case in quantum\nprobability, there is not just one but several quantizations: we know at least\ntwo different concepts of identification of classical information via quantum\nchannels, and three different identification capacities for quantum\ninformation. In the present summary overview we concentrate on conceptual\npoints and open problems, referring the reader to the small set of original\narticles for details. \n\n"}
{"id": "1212.1195", "contents": "Title: Long-Range Rapidity Correlations in Heavy-Light Ion Collisions Abstract: We study two-particle long-range rapidity correlations arising in the early\nstages of heavy ion collisions in the saturation/Color Glass Condensate\nframework, assuming for simplicity that one colliding nucleus is much larger\nthan the other. We calculate the two-gluon production cross section while\nincluding all-order saturation effects in the heavy nucleus with the\nlowest-order rescattering in the lighter nucleus. We find four types of\ncorrelations in the two-gluon production cross section: (i) geometric\ncorrelations, (ii) HBT correlations accompanied by a back-to-back maximum,\n(iii) away-side correlations, and (iv) near-side azimuthal correlations which\nare long-range in rapidity. The geometric correlations (i) are due to the fact\nthat nucleons are correlated by simply being confined within the same nucleus\nand may lead to long-range rapidity correlations for the produced particles\nwithout strong azimuthal angle dependence. Somewhat surprisingly, long-range\nrapidity correlations (iii) and (iv) have exactly the same amplitudes along\nwith azimuthal and rapidity shapes: one centered around \\Delta \\phi =\\pi\\ with\nthe other one centered around \\Delta \\phi =0 (here \\Delta \\phi\\ is the\nazimuthal angle between the two produced gluons). We thus observe that the\nearly-time CGC dynamics in nucleus-nucleus collisions generates azimuthal\nnon-flow correlations which are qualitatively different from jet correlations\nby being long-range in rapidity. If strong enough, they have the potential of\nmimicking the elliptic (and higher-order even-harmonic) flow in the di-hadron\ncorrelators: one may need to take them into account in the experimental\ndetermination of the flow observables. \n\n"}
{"id": "1212.3376", "contents": "Title: Linearly Reconfigurable Kalman Filtering for a Vector Process Abstract: In this paper, we consider a dynamic linear system in state-space form where\nthe observation equation depends linearly on a set of parameters. We address\nthe problem of how to dynamically calculate these parameters in order to\nminimize the mean-squared error (MSE) of the state estimate achieved by a\nKalman filter. We formulate and solve two kinds of problems under a quadratic\nconstraint on the observation parameters: minimizing the sum MSE (Min-Sum-MSE)\nor minimizing the maximum MSE (Min-Max-MSE). In each case, the optimization\nproblem is divided into two sub-problems for which optimal solutions can be\nfound: a semidefinite programming (SDP) problem followed by a constrained\nleast-squares minimization. A more direct solution is shown to exist for the\nspecial case of a scalar observation; in particular, the Min-Sum-MSE solution\ncan be found directly using a generalized eigendecomposition, and is optimally\nsolved utilizing Rayleigh quotient, and the Min-Max-MSE problem reduces to an\nSDP feasibility test that can be solved via the bisection method. \n\n"}
{"id": "1212.3621", "contents": "Title: Local Irreducibility of Tail-Biting Trellises Abstract: This paper investigates tail-biting trellis realizations for linear block\ncodes. Intrinsic trellis properties are used to characterize irreducibility on\ngiven intervals of the time axis. It proves beneficial to always consider the\ntrellis and its dual simultaneously. A major role is played by trellis\nproperties that amount to observability and controllability for fragments of\nthe trellis of various lengths. For fragments of length less than the minimum\nspan length of the code it is shown that fragment observability and fragment\ncontrollability are equivalent to irreducibility. For reducible trellises, a\nconstructive reduction procedure is presented. The considerations also lead to\na characterization for when the dual of a trellis allows a product\nfactorization into elementary (\"atomic\") trellises. \n\n"}
{"id": "1212.3631", "contents": "Title: Learning efficient sparse and low rank models Abstract: Parsimony, including sparsity and low rank, has been shown to successfully\nmodel data in numerous machine learning and signal processing tasks.\nTraditionally, such modeling approaches rely on an iterative algorithm that\nminimizes an objective function with parsimony-promoting terms. The inherently\nsequential structure and data-dependent complexity and latency of iterative\noptimization constitute a major limitation in many applications requiring\nreal-time performance or involving large-scale data. Another limitation\nencountered by these modeling techniques is the difficulty of their inclusion\nin discriminative learning scenarios. In this work, we propose to move the\nemphasis from the model to the pursuit algorithm, and develop a process-centric\nview of parsimonious modeling, in which a learned deterministic\nfixed-complexity pursuit process is used in lieu of iterative optimization. We\nshow a principled way to construct learnable pursuit process architectures for\nstructured sparse and robust low rank models, derived from the iteration of\nproximal descent algorithms. These architectures learn to approximate the exact\nparsimonious representation at a fraction of the complexity of the standard\noptimization methods. We also show that appropriate training regimes allow to\nnaturally extend parsimonious models to discriminative settings.\nState-of-the-art results are demonstrated on several challenging problems in\nimage and audio processing with several orders of magnitude speedup compared to\nthe exact optimization algorithms. \n\n"}
{"id": "1212.4663", "contents": "Title: Concentration of Measure Inequalities in Information Theory,\n  Communications and Coding (Second Edition) Abstract: During the last two decades, concentration inequalities have been the subject\nof exciting developments in various areas, including convex geometry,\nfunctional analysis, statistical physics, high-dimensional statistics, pure and\napplied probability theory, information theory, theoretical computer science,\nand learning theory. This monograph focuses on some of the key modern\nmathematical tools that are used for the derivation of concentration\ninequalities, on their links to information theory, and on their various\napplications to communications and coding. In addition to being a survey, this\nmonograph also includes various new recent results derived by the authors. The\nfirst part of the monograph introduces classical concentration inequalities for\nmartingales, as well as some recent refinements and extensions. The power and\nversatility of the martingale approach is exemplified in the context of codes\ndefined on graphs and iterative decoding algorithms, as well as codes for\nwireless communication. The second part of the monograph introduces the entropy\nmethod, an information-theoretic technique for deriving concentration\ninequalities. The basic ingredients of the entropy method are discussed first\nin the context of logarithmic Sobolev inequalities, which underlie the\nso-called functional approach to concentration of measure, and then from a\ncomplementary information-theoretic viewpoint based on transportation-cost\ninequalities and probability in metric spaces. Some representative results on\nconcentration for dependent random variables are briefly summarized, with\nemphasis on their connections to the entropy method. Finally, we discuss\nseveral applications of the entropy method to problems in communications and\ncoding, including strong converses, empirical distributions of good channel\ncodes, and an information-theoretic converse for concentration of measure. \n\n"}
{"id": "1212.5701", "contents": "Title: ADADELTA: An Adaptive Learning Rate Method Abstract: We present a novel per-dimension learning rate method for gradient descent\ncalled ADADELTA. The method dynamically adapts over time using only first order\ninformation and has minimal computational overhead beyond vanilla stochastic\ngradient descent. The method requires no manual tuning of a learning rate and\nappears robust to noisy gradient information, different model architecture\nchoices, various data modalities and selection of hyperparameters. We show\npromising results compared to other methods on the MNIST digit classification\ntask using a single machine and on a large scale voice dataset in a distributed\ncluster environment. \n\n"}
{"id": "1301.0504", "contents": "Title: MuLan Measurement of the Positive Muon Lifetime and Determination of the\n  Fermi Constant Abstract: We report results from the MuLan measurement of the positive muon lifetime.\nThe experiment was conducted at the Paul Scherrer Institute using a\ntime-structured surface muon beam and a segmented plastic scintillator array.\nTwo different in-vacuum muon stopping targets were used: a ferromagnetic foil\nwith a large internal magnetic field and a quartz crystal in a moderate\nexternal magnetic field. From a total of 1.6 x 10^{12} decays, we obtained the\nmuon lifetime tau_mu = 2196980.3(2.2) ps (1.0 ppm) and Fermi constant G_F =\n1.1663787(6) x 10^{-5} GeV^{-2} (0.5 ppm). \n\n"}
{"id": "1301.6312", "contents": "Title: Rooting out the Rumor Culprit from Suspects Abstract: Suppose that a rumor originating from a single source among a set of suspects\nspreads in a network, how to root out this rumor source? With the a priori\nknowledge of suspect nodes and an observation of infected nodes, we construct a\nmaximum a posteriori (MAP) estimator to identify the rumor source using the\nsusceptible-infected (SI) model. The a priori suspect set and its associated\nconnectivity bring about new ingredients to the problem, and thus we propose to\nuse local rumor center, a generalized concept based on rumor centrality, to\nidentify the source from suspects. For regular tree-type networks of node\ndegree {\\delta}, we characterize Pc(n), the correct detection probability of\nthe estimator upon observing n infected nodes, in both the finite and\nasymptotic regimes. First, when every infected node is a suspect, Pc(n)\nasymptotically grows from 0.25 to 0.307 with {\\delta} from 3 to infinity, a\nresult first established in Shah and Zaman (2011, 2012) via a different\napproach; and it monotonically decreases with n and increases with {\\delta}.\nSecond, when the suspects form a connected subgraph of the network, Pc(n)\nasymptotically significantly exceeds the a priori probability if {\\delta}>2,\nand reliable detection is achieved as {\\delta} becomes large; furthermore, it\nmonotonically decreases with n and increases with {\\delta}. Third, when there\nare only two suspects, Pc(n) is asymptotically at least 0.75 if {\\delta}>2; and\nit increases with the distance between the two suspects. Fourth, when there are\nmultiple suspects, among all possible connection patterns, that they form a\nconnected subgraph of the network achieves the smallest detection probability.\nOur analysis leverages ideas from the Polya's urn model in probability theory\nand sheds insight into the behavior of the rumor spreading process not only in\nthe asymptotic regime but also for the general finite-n regime. \n\n"}
{"id": "1302.0019", "contents": "Title: Fixed-to-Variable Length Distribution Matching Abstract: Fixed-to-variable length (f2v) matchers are used to reversibly transform an\ninput sequence of independent and uniformly distributed bits into an output\nsequence of bits that are (approximately) independent and distributed according\nto a target distribution. The degree of approximation is measured by the\ninformational divergence between the output distribution and the target\ndistribution. An algorithm is developed that efficiently finds optimal f2v\ncodes. It is shown that by encoding the input bits blockwise, the informational\ndivergence per bit approaches zero as the block length approaches infinity. A\nrelation to data compression by Tunstall coding is established. \n\n"}
{"id": "1302.0082", "contents": "Title: Distribution-Free Distribution Regression Abstract: `Distribution regression' refers to the situation where a response Y depends\non a covariate P where P is a probability distribution. The model is Y=f(P) +\nmu where f is an unknown regression function and mu is a random error.\nTypically, we do not observe P directly, but rather, we observe a sample from\nP. In this paper we develop theory and methods for distribution-free versions\nof distribution regression. This means that we do not make distributional\nassumptions about the error term mu and covariate P. We prove that when the\neffective dimension is small enough (as measured by the doubling dimension),\nthen the excess prediction risk converges to zero with a polynomial rate. \n\n"}
{"id": "1302.0561", "contents": "Title: Breaking the coherence barrier: A new theory for compressed sensing Abstract: This paper provides an extension of compressed sensing which bridges a\nsubstantial gap between existing theory and its current use in real-world\napplications. It introduces a mathematical framework that generalizes the three\nstandard pillars of compressed sensing - namely, sparsity, incoherence and\nuniform random subsampling - to three new concepts: asymptotic sparsity,\nasymptotic incoherence and multilevel random sampling. The new theorems show\nthat compressed sensing is also possible, and reveals several advantages, under\nthese substantially relaxed conditions. The importance of this is threefold.\nFirst, inverse problems to which compressed sensing is currently applied are\ntypically coherent. The new theory provides the first comprehensive\nmathematical explanation for a range of empirical usages of compressed sensing\nin real-world applications, such as medical imaging, microscopy, spectroscopy\nand others. Second, in showing that compressed sensing does not require\nincoherence, but instead that asymptotic incoherence is sufficient, the new\ntheory offers markedly greater flexibility in the design of sensing mechanisms.\nThird, by using asymptotic incoherence and multi-level sampling to exploit not\njust sparsity, but also structure, i.e. asymptotic sparsity, the new theory\nshows that substantially improved reconstructions can be obtained from fewer\nmeasurements. \n\n"}
{"id": "1302.3492", "contents": "Title: Outer Bounds for Multiterminal Source Coding via a Strong Data\n  Processing Inequality Abstract: An intuitive outer bound for the multiterminal source coding problem is\ngiven. The proposed bound explicitly couples the rate distortion functions for\neach source and correlation measures which derive from a \"strong\" data\nprocessing inequality. Unlike many standard outer bounds, the proposed bound is\nnot parameterized by a continuous family of auxiliary random variables, but\ninstead only requires maximizing two ratios of divergences which do not depend\non the distortion functions under consideration. \n\n"}
{"id": "1302.5453", "contents": "Title: The Quantum Entropy Cone of Stabiliser States Abstract: We investigate the universal linear inequalities that hold for the von\nNeumann entropies in a multi-party system, prepared in a stabiliser state. We\ndemonstrate here that entropy vectors for stabiliser states satisfy, in\naddition to the classic inequalities, a type of linear rank inequalities\nassociated with the combinatorial structure of normal subgroups of certain\nmatrix groups.\n  In the 4-party case, there is only one such inequality, the so-called\nIngleton inequality. For these systems we show that strong subadditivity, weak\nmonotonicity and Ingleton inequality exactly characterize the entropy cone for\nstabiliser states. \n\n"}
{"id": "1302.6570", "contents": "Title: Secure Degrees of Freedom of the Gaussian Wiretap Channel with Helpers\n  and No Eavesdropper CSI: Blind Cooperative Jamming Abstract: We consider the Gaussian wiretap channel with M helpers, where no\neavesdropper channel state information (CSI) is available at the legitimate\nentities. The exact secure d.o.f. of the Gaussian wiretap channel with M\nhelpers with perfect CSI at the transmitters was found in [1], [2] to be\nM/(M+1). One of the key ingredients of the optimal achievable scheme in [1],\n[2] is to align cooperative jamming signals with the information symbols at the\neavesdropper to limit the information leakage rate. This required perfect\neavesdropper CSI at the transmitters. Motivated by the recent result in [3], we\npropose a new achievable scheme in which cooperative jamming signals span the\nentire space of the eavesdropper, but are not exactly aligned with the\ninformation symbols. We show that this scheme achieves the same secure d.o.f.\nof M/(M+1) in [1], [2] but does not require any eavesdropper CSI; the\ntransmitters blindly cooperative jam the eavesdropper. \n\n"}
{"id": "1303.0088", "contents": "Title: Half-Duplex or Full-Duplex Relaying: A Capacity Analysis under\n  Self-Interference Abstract: In this paper multi-antenna half-duplex and full-duplex relaying are compared\nfrom the perspective of achievable rates. Full-duplexing operation requires\nadditional resources at the relay such as antennas and RF chains for\nself-interference cancellation. Using a practical model for the residual\nself-interference, full-duplex achievable rates and degrees of freedom are\ncomputed for the cases for which the relay has the same number of antennas or\nthe same number of RF chains as in the half-duplex case, and compared with\ntheir half-duplex counterparts. It is shown that power scaling at the relay is\nnecessary to maximize the the degrees of freedom in the full-duplex mode. \n\n"}
{"id": "1303.0341", "contents": "Title: Matrix Completion via Max-Norm Constrained Optimization Abstract: Matrix completion has been well studied under the uniform sampling model and\nthe trace-norm regularized methods perform well both theoretically and\nnumerically in such a setting. However, the uniform sampling model is\nunrealistic for a range of applications and the standard trace-norm relaxation\ncan behave very poorly when the underlying sampling scheme is non-uniform.\n  In this paper we propose and analyze a max-norm constrained empirical risk\nminimization method for noisy matrix completion under a general sampling model.\nThe optimal rate of convergence is established under the Frobenius norm loss in\nthe context of approximately low-rank matrix reconstruction. It is shown that\nthe max-norm constrained method is minimax rate-optimal and yields a unified\nand robust approximate recovery guarantee, with respect to the sampling\ndistributions. The computational effectiveness of this method is also\ndiscussed, based on first-order algorithms for solving convex optimizations\ninvolving max-norm regularization. \n\n"}
{"id": "1303.0707", "contents": "Title: On the Achievable Error Region of Physical Layer Authentication\n  Techniques over Rayleigh Fading Channels Abstract: For a physical layer message authentication procedure based on the comparison\nof channel estimates obtained from the received messages, we focus on an outer\nbound on the type I/II error probability region. Channel estimates are modelled\nas multivariate Gaussian vectors, and we assume that the attacker has only some\nside information on the channel estimate, which he does not know directly. We\nderive the attacking strategy that provides the tightest bound on the error\nregion, given the statistics of the side information. This turns out to be a\nzero mean, circularly symmetric Gaussian density whose correlation matrices may\nbe obtained by solving a constrained optimization problem. We propose an\niterative algorithm for its solution: Starting from the closed form solution of\na relaxed problem, we obtain, by projection, an initial feasible solution;\nthen, by an iterative procedure, we look for the fixed point solution of the\nproblem. Numerical results show that for cases of interest the iterative\napproach converges, and perturbation analysis shows that the found solution is\na local minimum. \n\n"}
{"id": "1303.0901", "contents": "Title: Measurement of Charge Multiplicity Asymmetry Correlations in High Energy\n  Nucleus-Nucleus Collisions at 200 GeV Abstract: A study is reported of the same- and opposite-sign charge-dependent azimuthal\ncorrelations with respect to the event plane in Au+Au collisions at 200 GeV.\nThe charge multiplicity asymmetries between the up/down and left/right\nhemispheres relative to the event plane are utilized. The contributions from\nstatistical fluctuations and detector effects were subtracted from the\n(co-)variance of the observed charge multiplicity asymmetries. In the mid- to\nmost-central collisions, the same- (opposite-) sign pairs are preferentially\nemitted in back-to-back (aligned on the same-side) directions. The charge\nseparation across the event plane, measured by the difference, $\\Delta$,\nbetween the like- and unlike-sign up/down $-$ left/right correlations, is\nlargest near the event plane. The difference is found to be proportional to the\nevent-by-event final-state particle ellipticity (via the observed second-order\nharmonic $v^{\\rm obs}_{2}$), where $\\Delta=(1.3\\pm1.4({\\rm\nstat})^{+4.0}_{-1.0}({\\rm syst}))\\times10^{-5}+(3.2\\pm0.2({\\rm\nstat})^{+0.4}_{-0.3}({\\rm syst}))\\times10^{-3}v^{\\rm obs}_{2}$ for 20-40% Au+Au\ncollisions. The implications for the proposed chiral magnetic effect are\ndiscussed. \n\n"}
{"id": "1303.1312", "contents": "Title: A Fast Iterative Bayesian Inference Algorithm for Sparse Channel\n  Estimation Abstract: In this paper, we present a Bayesian channel estimation algorithm for\nmulticarrier receivers based on pilot symbol observations. The inherent sparse\nnature of wireless multipath channels is exploited by modeling the prior\ndistribution of multipath components' gains with a hierarchical representation\nof the Bessel K probability density function; a highly efficient, fast\niterative Bayesian inference method is then applied to the proposed model. The\nresulting estimator outperforms other state-of-the-art Bayesian and\nnon-Bayesian estimators, either by yielding lower mean squared estimation error\nor by attaining the same accuracy with improved convergence rate, as shown in\nour numerical evaluation. \n\n"}
{"id": "1303.1609", "contents": "Title: Physical Layer Security in Cellular Networks: A Stochastic Geometry\n  Approach Abstract: This paper studies the information-theoretic secrecy performance in\nlarge-scale cellular networks based on a stochastic geometry framework. The\nlocations of both base stations and mobile users are modeled as independent\ntwo-dimensional Poisson point processes. We consider two important features of\ncellular networks, namely, information exchange between base stations and cell\nassociation, to characterize their impact on the achievable secrecy rate of an\narbitrary downlink transmission with a certain portion of the mobile users\nacting as potential eavesdroppers. In particular, tractable results are\npresented under diverse assumptions on the availability of eavesdroppers'\nlocation information at the serving base station, which captures the benefit\nfrom the exchange of the location information between base stations. \n\n"}
{"id": "1303.2545", "contents": "Title: Optimization of the parity-check matrix density in QC-LDPC code-based\n  McEliece cryptosystems Abstract: Low-density parity-check (LDPC) codes are one of the most promising families\nof codes to replace the Goppa codes originally used in the McEliece\ncryptosystem. In fact, it has been shown that by using quasi-cyclic low-density\nparity-check (QC-LDPC) codes in this system, drastic reductions in the public\nkey size can be achieved, while maintaining fixed security levels. Recently,\nsome proposals have appeared in the literature using codes with denser\nparity-check matrices, named moderate-density parity-check (MDPC) codes.\nHowever, the density of the parity-check matrices to be used in QC-LDPC\ncode-based variants of the McEliece cryptosystem has never been optimized. This\npaper aims at filling such gap, by proposing a procedure for selecting the\ndensity of the private parity-check matrix, based on the security level and the\ndecryption complexity. We provide some examples of the system parameters\nobtained through the proposed technique. \n\n"}
{"id": "1303.4080", "contents": "Title: Performances of a large mass ZnSe bolometer to search for rare events Abstract: Scintillating bolometers of ZnSe are the baseline choice of the LUCIFER\nexperiment, whose aim is to observe the neutrinoless double beta decay of 82Se.\nThe independent read-out of the heat and scintillation signals allows to\nidentify and reject alpha particle interactions, the dominant background source\nfor bolometric detectors. In this paper we report the performances of a ZnSe\ncrystal operated within the LUCIFER R&D. We measured the scintillation yield,\nthe energy resolution and the background in the energy region where the signal\nfrom neutrinoless double beta decay of 82Se is expected with an exposure of 9.4\nkg x days. With a newly developed analysis algorithm we improved the rejection\nof alpha events, and we estimated the increase in energy resolution obtained by\nthe combination of the heat and light signals. For the first time we measured\nthe light emitted by nuclear recoils, and found it to be compatible with zero.\nWe conclude that the discrimination of nuclear recoils from beta/gamma\ninteractions in the WIMPs energy region is possible, but low-noise light\ndetectors are needed. \n\n"}
{"id": "1303.4326", "contents": "Title: Unambiguous Identification of the Second 2+ State in 12C and the\n  Structure of the Hoyle State Abstract: The second 2+ state of 12C, predicted over fifty years ago as an excitation\nof the Hoyle state, has been unambiguously identified using the 12C(g,a_0)8Be\nreaction. The alpha particles produced by the photodisintegration of 12C were\ndetected using an Optical Time Projection Chamber (O-TPC). Data were collected\nat beam energies between 9.1 and 10.7 MeV using the intense nearly\nmono-energetic gamma-ray beams at the HIgS facility. The measured angular\ndistributions determine the cross section and the E1-E2 relative phases as a\nfunction of energy leading to an unambiguous identification of the second 2+\nstate in 12C at 10.03(11) MeV, with a total width of 800(130) keV and a ground\nstate gamma-decay width of 60(10) meV; B(E2: 2+ ---> gs) = 0.73(13) e2fm4 [or\n0.45(8) W.u.]. The Hoyle state and its rotational 2+ state that are more\nextended than the ground state of 12C presents a challenge and constraints for\nmodels attempting to reveal the nature of three alpha particle states in 12C.\nSpecifically it challenges the ab-initio Lattice Effective Field Theory (L-EFT)\ncalculations that predict similar r.m.s. radii for the ground state and the\nHoyle state. \n\n"}
{"id": "1303.4683", "contents": "Title: Alternating Rate Profile Optimization in Single Stream MIMO Interference\n  Channels Abstract: The multiple-input multiple-output interference channel is considered with\nperfect channel information at the transmitters and single-user decoding\nreceivers. With all transmissions restricted to single stream beamforming, we\nconsider the problem of finding all Pareto optimal rate-tuples in the\nachievable rate region. The problem is cast as a rate profile optimization\nproblem. Due to its nonconvexity, we resort to an alternating approach: For\nfixed receivers, optimal transmission is known. For fixed transmitters, we show\nthat optimal receive beamforming is a solution to an inverse field of values\nproblem. We prove the solution's stationarity and compare it with existing\napproaches. \n\n"}
{"id": "1303.5522", "contents": "Title: The Weak Neutral Current Abstract: This is a review of electroweak precision physics with particular emphasis on\nlow-energy precision measurements in the neutral current sector of the\nelectroweak theory and includes future experimental prospects and the\ntheoretical challenges one faces to interpret these observables. Within the\nminimal Standard Model they serve as determinations of the weak mixing angle\nwhich are competitive with and complementary to those obtained near the\nZ-resonance. In the context of new physics beyond the Standard Model these\nmeasurements are crucial to discriminate between models and to reduce the\nallowed parameter space within a given model. We illustrate this for the\nminimal supersymmetric Standard Model with or without R-parity. \n\n"}
{"id": "1303.6388", "contents": "Title: Phase Transition Analysis of Sparse Support Detection from Noisy\n  Measurements Abstract: This paper investigates the problem of sparse support detection (SSD) via a\ndetection-oriented algorithm named Bayesian hypothesis test via belief\npropagation (BHT-BP). Our main focus is to compare BHT-BP to an\nestimation-based algorithm, called CS-BP, and show its superiority in the SSD\nproblem. For this investigation, we perform a phase transition (PT) analysis\nover the plain of the noise level and signal magnitude on the signal support.\nThis PT analysis sharply specifies the required signal magnitude for the\ndetection under a certain noise level. In addition, we provide an experimental\nvalidation to assure the PT analysis. Our analytical and experimental results\nshow the fact that BHT-BP detects the signal support against additive noise\nmore robustly than CS-BP does. \n\n"}
{"id": "1304.0001", "contents": "Title: Optimality of $\\ell_2/\\ell_1$-optimization block-length dependent\n  thresholds Abstract: The recent work of \\cite{CRT,DonohoPol} rigorously proved (in a large\ndimensional and statistical context) that if the number of equations\n(measurements in the compressed sensing terminology) in the system is\nproportional to the length of the unknown vector then there is a sparsity\n(number of non-zero elements of the unknown vector) also proportional to the\nlength of the unknown vector such that $\\ell_1$-optimization algorithm succeeds\nin solving the system. In more recent papers\n\\cite{StojnicCSetamBlock09,StojnicICASSP09block,StojnicJSTSP09} we considered\nunder-determined systems with the so-called \\textbf{block}-sparse solutions. In\na large dimensional and statistical context in \\cite{StojnicCSetamBlock09} we\ndetermined lower bounds on the values of allowable sparsity for any given\nnumber (proportional to the length of the unknown vector) of equations such\nthat an $\\ell_2/\\ell_1$-optimization algorithm succeeds in solving the system.\nThese lower bounds happened to be in a solid numerical agreement with what one\ncan observe through numerical experiments. Here we derive the corresponding\nupper bounds. Moreover, the upper bounds that we obtain in this paper match the\nlower bounds from \\cite{StojnicCSetamBlock09} and ultimately make them optimal. \n\n"}
{"id": "1304.0480", "contents": "Title: A problem dependent analysis of SOCP algorithms in noisy compressed\n  sensing Abstract: Under-determined systems of linear equations with sparse solutions have been\nthe subject of an extensive research in last several years above all due to\nresults of \\cite{CRT,CanRomTao06,DonohoPol}. In this paper we will consider\n\\emph{noisy} under-determined linear systems. In a breakthrough\n\\cite{CanRomTao06} it was established that in \\emph{noisy} systems for any\nlinear level of under-determinedness there is a linear sparsity that can be\n\\emph{approximately} recovered through an SOCP (second order cone programming)\noptimization algorithm so that the approximate solution vector is (in an\n$\\ell_2$-norm sense) guaranteed to be no further from the sparse unknown vector\nthan a constant times the noise. In our recent work \\cite{StojnicGenSocp10} we\nestablished an alternative framework that can be used for statistical\nperformance analysis of the SOCP algorithms. To demonstrate how the framework\nworks we then showed in \\cite{StojnicGenSocp10} how one can use it to precisely\ncharacterize the \\emph{generic} (worst-case) performance of the SOCP. In this\npaper we present a different set of results that can be obtained through the\nframework of \\cite{StojnicGenSocp10}. The results will relate to \\emph{problem\ndependent} performance analysis of SOCP's. We will consider specific types of\nunknown sparse vectors and characterize the SOCP performance when used for\nrecovery of such vectors. We will also show that our theoretical predictions\nare in a solid agreement with the results one can get through numerical\nsimulations. \n\n"}
{"id": "1304.0604", "contents": "Title: On the Gaussian Interference Channel with Half-Duplex Causal Cognition Abstract: This paper studies the two-user Gaussian interference channel with\nhalf-duplex causal cognition. This channel model consists of two\nsource-destination pairs sharing a common wireless channel. One of the sources,\nreferred to as the cognitive, overhears the other source, referred to as the\nprimary, through a noisy link and can therefore assist in sending the primary's\ndata. Due to practical constraints, the cognitive source is assumed to work in\nhalf-duplex mode, that is, it cannot simultaneously transmit and receive. This\nmodel is more relevant for practical cognitive radio systems than the classical\ninformation theoretic cognitive channel model, where the cognitive source is\nassumed to have a non-causal knowledge of the primary's message. Different\nnetwork topologies are considered, corresponding to different interference\nscenarios: (i) the interference-symmetric scenario, where both destinations are\nin the coverage area of the two sources and hence experience interference, and\n(ii) the interference-asymmetric scenario, where one destination does not\nsuffer from interference. For each topology the sum-rate performance is studied\nby first deriving the generalized Degrees of Freedom (gDoF), or \"sum-capacity\npre-log\" in the high-SNR regime, and then showing relatively simple coding\nschemes that achieve a sum-rate upper bound to within a constant number of bits\nfor any SNR. Finally, the gDoF of the channel is compared to that of the\nnon-cooperative interference channel and to that of the non-causal cognitive\nchannel to identify the parameter regimes where half-duplex causal cognition is\nuseless in practice or attains its ideal ultimate limit, respectively. \n\n"}
{"id": "1304.2876", "contents": "Title: Detailed HBT measurements with respect to the event plane and collision\n  energy in Au+Au collisions at PHENIX Abstract: The azimuthal dependence of 3D HBT radii relative to the event plane gives us\ninformation about the source shape at freeze-out. It also provides information\non the system's evolution by comparing it to the initial source shape. In\nrecent studies, higher harmonic event planes and flow have been measured at\nRHIC and the LHC, which result primarily from spatial fluctuations of the\ninitial density across the collision area. If the shape caused by initial\nfluctuations still exists at freeze-out, the HBT measurement relative to higher\norder event plane may show these features.\n  We present recent results of azimuthal HBT measurements relative to $2^{nd}$-\nand $3^{rd}$-order event planes in Au+Au 200 GeV collisions with the PHENIX\nexperiment. Recent HBT measurements at lower energies will be also shown and\ncompared with the 200 GeV result. \n\n"}
{"id": "1304.3634", "contents": "Title: Towards the Little Bang Standard Model Abstract: I review recent progress in developing a complete dynamical model for the\nevolution of the Little Bang fireballs created in relativistic heavy-ion\ncollisions, and using the model to extract the transport properties and initial\ndensity fluctuations of the liquid quark-gluon plasma state of matter of which\nmakes up these Little Bangs during the first half of their lives. \n\n"}
{"id": "1304.3658", "contents": "Title: Efficient One-Way Secret-Key Agreement and Private Channel Coding via\n  Polarization Abstract: We introduce explicit schemes based on the polarization phenomenon for the\ntasks of one-way secret key agreement from common randomness and private\nchannel coding. For the former task, we show how to use common randomness and\ninsecure one-way communication to obtain a strongly secure key such that the\nkey construction has a complexity essentially linear in the blocklength and the\nrate at which the key is produced is optimal, i.e., equal to the one-way\nsecret-key rate. For the latter task, we present a private channel coding\nscheme that achieves the secrecy capacity using the condition of strong secrecy\nand whose encoding and decoding complexity are again essentially linear in the\nblocklength. \n\n"}
{"id": "1304.4764", "contents": "Title: Lifshitz and Excited State Quantum Phase Transitions in Microwave Dirac\n  Billiards Abstract: We present experimental results for the density of states (DOS) of a\nsuperconducting microwave Dirac billiard which serves as an idealized model for\nthe electronic properties of graphene. The DOS exhibits two sharp peaks which\nevolve into van Hove singularities with increasing system size. They divide the\nband structure into regions governed by the \\emph{relativistic} Dirac equation\nand by the \\emph{non-relativistic} Schr\\\"odinger equation, respectively. We\ndemonstrate that in the thermodynamic limit a topological transition appears as\na neck-disrupting Lifshitz transition in the number susceptibility and as an\nexcited state transition in the electronic excitations. Furthermore, we recover\nthe finite-size scaling typical for excited state quantum phase transitions\ninvolving logarithmic divergences and identify a quasi-order parameter. \n\n"}
{"id": "1304.5357", "contents": "Title: Exact-Regenerating Codes between MBR and MSR Points Abstract: In this paper we study distributed storage systems with exact repair. We give\na construction for regenerating codes between the minimum storage regenerating\n(MSR) and the minimum bandwidth regenerating (MBR) points and show that in the\ncase that the parameters n, k, and d are close to each other our constructions\nare close to optimal when comparing to the known capacity when only functional\nrepair is required. We do this by showing that when the distances of the\nparameters n, k, and d are fixed but the actual values approach to infinity,\nthe fraction of the performance of our codes with exact repair and the known\ncapacity of codes with functional repair approaches to one. \n\n"}
{"id": "1304.6599", "contents": "Title: Robust error correction for real-valued signals via message-passing\n  decoding and spatial coupling Abstract: We revisit the error correction scheme of real-valued signals when the\ncodeword is corrupted by gross errors on a fraction of entries and a small\nnoise on all the entries. Combining the recent developments of approximate\nmessage passing and the spatially-coupled measurement matrix in compressed\nsensing we show that the error correction and its robustness towards noise can\nbe enhanced considerably. We discuss the performance in the large signal limit\nusing previous results on state evolution, as well as for finite size signals\nthrough numerical simulations. Even for relatively small sizes, the approach\nproposed here outperforms convex-relaxation-based decoders. \n\n"}
{"id": "1304.8087", "contents": "Title: Uniqueness of Tensor Decompositions with Applications to Polynomial\n  Identifiability Abstract: We give a robust version of the celebrated result of Kruskal on the\nuniqueness of tensor decompositions: we prove that given a tensor whose\ndecomposition satisfies a robust form of Kruskal's rank condition, it is\npossible to approximately recover the decomposition if the tensor is known up\nto a sufficiently small (inverse polynomial) error.\n  Kruskal's theorem has found many applications in proving the identifiability\nof parameters for various latent variable models and mixture models such as\nHidden Markov models, topic models etc. Our robust version immediately implies\nidentifiability using only polynomially many samples in many of these settings.\nThis polynomial identifiability is an essential first step towards efficient\nlearning algorithms for these models.\n  Recently, algorithms based on tensor decompositions have been used to\nestimate the parameters of various hidden variable models efficiently in\nspecial cases as long as they satisfy certain \"non-degeneracy\" properties. Our\nmethods give a way to go beyond this non-degeneracy barrier, and establish\npolynomial identifiability of the parameters under much milder conditions.\nGiven the importance of Kruskal's theorem in the tensor literature, we expect\nthat this robust version will have several applications beyond the settings we\nexplore in this work. \n\n"}
{"id": "1305.0664", "contents": "Title: Practical Implementation of Spatial Modulation Abstract: In this work we seek to characterise the performance of spatial modulation\n(SM) and spatial multiplexing (SMX) with an experimental test bed. Two National\nInstruments (NI)-PXIe devices are used for the system testing, one for the\ntransmitter and one for the receiver. The digital signal processing that\nformats the information data in preparation of transmission is described along\nwith the digital signal processing that recovers the information data. In\naddition, the hardware limitations of the system are also analysed. The average\nbit error ratio (ABER) of the system is validated through both theoretical\nanalysis and simulation results for SM and SMX under line of sight (LoS)\nchannel conditions. \n\n"}
{"id": "1305.2789", "contents": "Title: Phaseless Signal Recovery in Infinite Dimensional Spaces using\n  Structured Modulations Abstract: This paper considers the recovery of continuous signals in infinite\ndimensional spaces from the magnitude of their frequency samples. It proposes a\nsampling scheme which involves a combination of oversampling and modulations\nwith complex exponentials. Sufficient conditions are given such that almost\nevery signal with compact support can be reconstructed up to a unimodular\nconstant using only its magnitude samples in the frequency domain. Finally it\nis shown that an average sampling rate of four times the Nyquist rate is enough\nto reconstruct almost every time-limited signal. \n\n"}
{"id": "1305.4008", "contents": "Title: Exact Recovery Conditions for Sparse Representations with Partial\n  Support Information Abstract: We address the exact recovery of a k-sparse vector in the noiseless setting\nwhen some partial information on the support is available. This partial\ninformation takes the form of either a subset of the true support or an\napproximate subset including wrong atoms as well. We derive a new sufficient\nand worst-case necessary (in some sense) condition for the success of some\nprocedures based on lp-relaxation, Orthogonal Matching Pursuit (OMP) and\nOrthogonal Least Squares (OLS). Our result is based on the coherence \"mu\" of\nthe dictionary and relaxes the well-known condition mu<1/(2k-1) ensuring the\nrecovery of any k-sparse vector in the non-informed setup. It reads\nmu<1/(2k-g+b-1) when the informed support is composed of g good atoms and b\nwrong atoms. We emphasize that our condition is complementary to some\nrestricted-isometry based conditions by showing that none of them implies the\nother.\n  Because this mutual coherence condition is common to all procedures, we carry\nout a finer analysis based on the Null Space Property (NSP) and the Exact\nRecovery Condition (ERC). Connections are established regarding the\ncharacterization of lp-relaxation procedures and OMP in the informed setup.\nFirst, we emphasize that the truncated NSP enjoys an ordering property when p\nis decreased. Second, the partial ERC for OMP (ERC-OMP) implies in turn the\ntruncated NSP for the informed l1 problem, and the truncated NSP for p<1. \n\n"}
{"id": "1305.5082", "contents": "Title: Performance of Joint Channel and Physical Network Coding Based on\n  Alamouti STBC Abstract: This work considers the protograph-coded physical network coding (PNC) based\non Alamouti space-time block coding (STBC) over Nakagami-fading two-way relay\nchannels, in which both the two sources and relay possess two antennas. We\nfirst propose a novel precoding scheme at the two sources so as to implement\nthe iterative decoder efficiently at the relay. We further address a simplified\nupdating rule of the log-likelihood-ratio (LLR) in such a decoder. Based on the\nsimplified LLR-updating rule and Gaussian approximation, we analyze the\ntheoretical bit-error-rate (BER) of the system, which is shown to be consistent\nwith the decoding thresholds and simulated results. Moreover, the theoretical\nanalysis has lower computational complexity than the protograph extrinsic\ninformation transfer (PEXIT) algorithm. Consequently, the analysis not only\nprovides a simple way to evaluate the error performance but also facilitates\nthe design of the joint channel-and-PNC (JCNC) in wireless communication\nscenarios. \n\n"}
{"id": "1305.7214", "contents": "Title: Secure Degrees of Freedom of K-User Gaussian Interference Channels: A\n  Unified View Abstract: We determine the exact sum secure degrees of freedom (d.o.f.) of the K-user\nGaussian interference channel. We consider three different secrecy constraints:\n1) K-user interference channel with one external eavesdropper (IC-EE), 2)\nK-user interference channel with confidential messages (IC-CM), and 3) K-user\ninterference channel with confidential messages and one external eavesdropper\n(IC-CM-EE). We show that for all of these three cases, the exact sum secure\nd.o.f. is K(K-1)/(2K-1). We show converses for IC-EE and IC-CM, which imply a\nconverse for IC-CM-EE. We show achievability for IC-CM-EE, which implies\nachievability for IC-EE and IC-CM. We develop the converses by relating the\nchannel inputs of interfering users to the reliable rates of the interfered\nusers, and by quantifying the secrecy penalty in terms of the eavesdroppers'\nobservations. Our achievability uses structured signaling, structured\ncooperative jamming, channel prefixing, and asymptotic real interference\nalignment. While the traditional interference alignment provides some amount of\nsecrecy by mixing unintended signals in a smaller sub-space at every receiver,\nin order to attain the optimum sum secure d.o.f., we incorporate structured\ncooperative jamming into the achievable scheme, and intricately design the\nstructure of all of the transmitted signals jointly. \n\n"}
{"id": "1305.7327", "contents": "Title: Moments of net-charge multiplicity distribution in Au+Au collisions\n  measured by the PHENIX experiment at RHIC Abstract: Beam Energy Scan (BES) program at RHIC is important to search for the\nexistence of the critical point in the QCD phase diagram. Lattice QCD have\nshown that the predictions of the susceptibility of the medium formed in\nheavy-ion collisions can be sensitive to the various moments (mean ($\\mu$)\n=${<x>}$, variance ($\\sigma^2$) = ${<(x-\\mu)^2>}$, skewness (S) =\n$\\frac{<(x-\\mu)^3>}{\\sigma^3}$ and kurtosis ($\\kappa$)\n=$\\frac{<(x-\\mu)^4>}{\\sigma^4} -3$) of conserved quantities like net-baryon\nnumber ($\\Delta$B), net-electric charge ($\\Delta$Q) and net-strangeness\n($\\Delta$S).\n  Any non-monotonic behavior of the higher moments would confirm the existence\nof the QCD critical point. The recent results of the higher moments of\nnet-charge multiplicity distributions for Au+Au collisions at $\\sqrt{s}_{NN}$\nvarying from 7.7 GeV to 200 GeV from the PHENIX experiment at RHIC are\npresented. The energy and centrality dependence of the higher moments and their\nproducts (S$\\sigma$ and $\\kappa\\sigma^{2}$) are shown for the net-charge\nmultiplicity distributions. Furthermore, the results are compared with the\nvalues obtained from the heavy-ion collision models, where there is no QCD\nphase transition and critical point. \n\n"}
{"id": "1306.1310", "contents": "Title: Electromagnetic Lens-focusing Antenna Enabled Massive MIMO Abstract: Massive multiple-input multiple-output (MIMO) techniques have been recently\nadvanced to tremendously improve the performance of wireless networks. However,\nthe use of very large antenna arrays brings new issues, such as the\nsignificantly increased hardware cost and signal processing cost and\ncomplexity. In order to reap the enormous gain of massive MIMO and yet reduce\nits cost to an affordable level, this paper proposes a novel system design by\nintegrating an electromagnetic (EM) lens with the large antenna array, termed\n\\emph{electromagnetic lens antenna} (ELA). An ELA has the capability of\nfocusing the power of any incident plane wave passing through the EM lens to a\nsmall subset of the antenna array, while the location of focal area is\ndependent on the angle of arrival (AoA) of the wave. As compared to\nconventional antenna arrays without the EM lens, the proposed system can\nsubstantially reduce the number of required radio frequency (RF) chains at the\nreceiver and hence, the implementation costs. In this paper, we investigate the\nproposed system under a simplified single-user uplink transmission setup, by\ncharacterizing the power distribution of the ELA as well as the resulting\nchannel model. Furthermore, by assuming antenna selection used at the receiver,\nwe show the throughput gains of the proposed system over conventional antenna\narrays given the same number of selected antennas. \n\n"}
{"id": "1306.2035", "contents": "Title: Minimax Theory for High-dimensional Gaussian Mixtures with Sparse Mean\n  Separation Abstract: While several papers have investigated computationally and statistically\nefficient methods for learning Gaussian mixtures, precise minimax bounds for\ntheir statistical performance as well as fundamental limits in high-dimensional\nsettings are not well-understood. In this paper, we provide precise information\ntheoretic bounds on the clustering accuracy and sample complexity of learning a\nmixture of two isotropic Gaussians in high dimensions under small mean\nseparation. If there is a sparse subset of relevant dimensions that determine\nthe mean separation, then the sample complexity only depends on the number of\nrelevant dimensions and mean separation, and can be achieved by a simple\ncomputationally efficient procedure. Our results provide the first step of a\ntheoretical basis for recent methods that combine feature selection and\nclustering. \n\n"}
{"id": "1306.2550", "contents": "Title: Fixed-to-Variable Length Resolution Coding for Target Distributions Abstract: The number of random bits required to approximate a target distribution in\nterms of un-normalized informational divergence is considered. It is shown that\nfor a variable-to-variable length encoder, this number is lower bounded by the\nentropy of the target distribution. A fixed-to-variable length encoder is\nconstructed using M-type quantization and Tunstall coding. It is shown that the\nencoder achieves in the limit an un-normalized informational divergence of zero\nwith the number of random bits per generated symbol equal to the entropy of the\ntarget distribution. Numerical results show that the proposed encoder\nsignificantly outperforms the optimal block-to-block encoder in the finite\nlength regime. \n\n"}
{"id": "1306.3142", "contents": "Title: On quantum Renyi entropies: a new generalization and some properties Abstract: The Renyi entropies constitute a family of information measures that\ngeneralizes the well-known Shannon entropy, inheriting many of its properties.\nThey appear in the form of unconditional and conditional entropies, relative\nentropies or mutual information, and have found many applications in\ninformation theory and beyond. Various generalizations of Renyi entropies to\nthe quantum setting have been proposed, most notably Petz's quasi-entropies and\nRenner's conditional min-, max- and collision entropy. Here, we argue that\nprevious quantum extensions are incompatible and thus unsatisfactory.\n  We propose a new quantum generalization of the family of Renyi entropies that\ncontains the von Neumann entropy, min-entropy, collision entropy and the\nmax-entropy as special cases, thus encompassing most quantum entropies in use\ntoday. We show several natural properties for this definition, including\ndata-processing inequalities, a duality relation, and an entropic uncertainty\nrelation. \n\n"}
{"id": "1306.3791", "contents": "Title: A gambling interpretation of some quantum information-theoretic\n  quantities Abstract: It is known that repeated gambling over the outcomes of independent and\nidentically distributed (i.i.d.) random variables gives rise to alternate\noperational meaning of entropies in the classical case in terms of the doubling\nrates. We give a quantum extension of this approach for gambling over the\nmeasurement outcomes of tensor product states. Under certain parameters of the\ngambling setup, one can give operational meaning of von Neumann entropies. We\ndiscuss two variants of gambling when a helper is available and it is shown\nthat the difference in their doubling rates is the quantum discord. Lastly, a\nquantum extension of Kelly's gambling setup in the classical case gives a\ndoubling rate that is upper bounded by the Holevo information. \n\n"}
{"id": "1306.5350", "contents": "Title: Error Correction for NOR Memory Devices with Exponentially Distributed\n  Read Noise Abstract: The scaling of high density NOR Flash memory devices with multi level cell\n(MLC) hits the reliability break wall because of relatively high intrinsic bit\nerror rate (IBER). The chip maker companies offer two solutions to meet the\noutput bit error rate (OBER) specification: either partial coverage with error\ncorrection code (ECC) or data storage in single level cell (SLC) with\nsignificant increase of the die cost. The NOR flash memory allows to write\ninformation in small portions, therefore the full error protection becomes\ncostly due to high required redundancy, e.g. $\\sim$50%. This is very different\nfrom the NAND flash memory writing at once large chunks of information; NAND\nECC requires just $\\sim$10% redundancy. This paper gives an analysis of a novel\nerror protection scheme applicable to NOR storage of one byte. The method does\nnot require any redundant cells, but assumes 5th program level. The information\nis mapped to states in the 4-dimensional space separated by the minimal\nManhattan distance equal 2. This code preserves the information capacity: one\nbyte occupies four memory cells. We demonstrate the OBER $\\sim$ IBER$^{3/2}$\nscaling law, where IBER is calculated for the 4-level MLC memory. As an\nexample, the 4-level MLC with IBER $\\sim10^{-9}$, which is unacceptable for\nhigh density products, can be converted to OBER $\\sim10^{-12}$. We assume that\nthe IBER is determined by the exponentially distributed read noise. This is the\ncase for NOR Flash memory devices, since the exponential tails are typical for\nthe random telegraph signal (RTS) noise and for most of the charge loss, charge\ngain, and charge sharing data losses. \n\n"}
{"id": "1306.6264", "contents": "Title: Codes on Graphs: Fundamentals Abstract: This paper develops a fundamental theory of realizations of linear and group\ncodes on general graphs using elementary group theory, including basic group\nduality theory. Principal new and extended results include: normal realization\nduality; analysis of systems-theoretic properties of fragments of realizations\nand their connections; \"minimal = trim and proper\" theorem for cycle-free\ncodes; results showing that all constraint codes except interface nodes may be\nassumed to be trim and proper, and that the interesting part of a cyclic\nrealization is its \"2-core;\" notions of observability and controllability for\nfragments, and related tests; relations between state-trimness and\ncontrollability, and dual state-trimness and observability. \n\n"}
{"id": "1307.2430", "contents": "Title: On The Fast Fading Multiple-Antenna Gaussian Broadcast Channel with\n  Confidential Messages and Partial CSIT Abstract: In wiretap channels the eavesdropper's channel state information (CSI) is\ncommonly assumed to be known at transmitter, fully or partially. However, under\nperfect secrecy constraint the eavesdropper may not be motivated to feedback\nany correct CSI. In this paper we consider a more feasible problem for the\ntransmitter to have eavesdropper's CSI. That is, the fast fading\nmultiple-antenna Gaussian broadcast channels (FMGBC-CM) with confidential\nmessages, where both receivers are legitimate users such that they both are\nwilling to feedback accurate CSI to maintain their secure transmission, and not\nto be eavesdropped by the other. We assume that only the statistics of the\nchannel state information are known by the transmitter. We first show the\nnecessary condition for the FMGBC-CM not to be degraded to the common wiretap\nchannels. Then we derive the achievable rate region for the FMGBC-CM where the\nchannel input covariance matrices and the inflation factor are left unknown and\nto be solved. After that we provide an analytical solution to the channel input\ncovariance matrices. We also propose an iterative algorithm to solve the\nchannel input covariance matrices and the inflation factor. Due to the\ncomplicated rate region formulae in normal SNR, we resort to low SNR analysis\nto investigate the characteristics of the channel. Finally, numerical examples\nshow that under perfect secrecy constraint both users can achieve positive\nrates simultaneously, which verifies our derived necessary condition. Numerical\nresults also elucidate the effectiveness of the analytic solution and proposed\nalgorithm of solving the channel input covariance matrices and the inflation\nfactor under different conditions. \n\n"}
{"id": "1307.2584", "contents": "Title: Massive MIMO Systems with Non-Ideal Hardware: Energy Efficiency,\n  Estimation, and Capacity Limits Abstract: The use of large-scale antenna arrays can bring substantial improvements in\nenergy and/or spectral efficiency to wireless systems due to the greatly\nimproved spatial resolution and array gain. Recent works in the field of\nmassive multiple-input multiple-output (MIMO) show that the user channels\ndecorrelate when the number of antennas at the base stations (BSs) increases,\nthus strong signal gains are achievable with little inter-user interference.\nSince these results rely on asymptotics, it is important to investigate whether\nthe conventional system models are reasonable in this asymptotic regime. This\npaper considers a new system model that incorporates general transceiver\nhardware impairments at both the BSs (equipped with large antenna arrays) and\nthe single-antenna user equipments (UEs). As opposed to the conventional case\nof ideal hardware, we show that hardware impairments create finite ceilings on\nthe channel estimation accuracy and on the downlink/uplink capacity of each UE.\nSurprisingly, the capacity is mainly limited by the hardware at the UE, while\nthe impact of impairments in the large-scale arrays vanishes asymptotically and\ninter-user interference (in particular, pilot contamination) becomes\nnegligible. Furthermore, we prove that the huge degrees of freedom offered by\nmassive MIMO can be used to reduce the transmit power and/or to tolerate larger\nhardware impairments, which allows for the use of inexpensive and\nenergy-efficient antenna elements. \n\n"}
{"id": "1307.2747", "contents": "Title: Impossibility of Local State Transformation via Hypercontractivity Abstract: Local state transformation is the problem of transforming an arbitrary number\nof copies of a bipartite resource state to a bipartite target state under local\noperations. That is, given two bipartite states, is it possible to transform an\narbitrary number of copies of one of them to one copy of the other state under\nlocal operations only? This problem is a hard one in general since we assume\nthat the number of copies of the resource state is arbitrarily large. In this\npaper we prove some bounds on this problem using the hypercontractivity\nproperties of some super-operators corresponding to bipartite states. We\nmeasure hypercontractivity in terms of both the usual super-operator norms as\nwell as completely bounded norms. \n\n"}
{"id": "1307.3290", "contents": "Title: Concatenated Coding Using Linear Schemes for Gaussian Broadcast Channels\n  with Noisy Channel Output Feedback Abstract: Linear coding schemes have been the main choice of coding for the additive\nwhite Gaussian noise broadcast channel (AWGN-BC) with noiseless feedback in the\nliterature. The achievable rate regions of these schemes go well beyond the\ncapacity region of the AWGN-BC without feedback. In this paper, a concatenating\ncoding design for the $K$-user AWGN-BC with noisy feedback is proposed that\nrelies on linear feedback schemes to achieve rate tuples outside the\nno-feedback capacity region. Specifically, a linear feedback code for the\nAWGN-BC with noisy feedback is used as an inner code that creates an effective\nsingle-user channel from the transmitter to each of the receivers, and then\nopen-loop coding is used for coding over these single-user channels. An\nachievable rate region of linear feedback schemes for noiseless feedback is\nshown to be achievable by the concatenated coding scheme for sufficiently small\nfeedback noise level. Then, a linear feedback coding scheme for the $K$-user\nsymmetric AWGN-BC with noisy feedback is presented and optimized for use in the\nconcatenated coding scheme. Lastly, we apply the concatenated coding design to\nthe two-user AWGN-BC with a single noisy feedback link from one of the\nreceivers. \n\n"}
{"id": "1307.4339", "contents": "Title: Computing Similarity Distances Between Rankings Abstract: We address the problem of computing distances between rankings that take into\naccount similarities between candidates. The need for evaluating such distances\nis governed by applications as diverse as rank aggregation, bioinformatics,\nsocial sciences and data storage. The problem may be summarized as follows:\nGiven two rankings and a positive cost function on transpositions that depends\non the similarity of the candidates involved, find a smallest cost sequence of\ntranspositions that converts one ranking into another. Our focus is on costs\nthat may be described via special metric-tree structures and on complete\nrankings modeled as permutations. The presented results include a\nquadratic-time algorithm for finding a minimum cost decomposition for simple\ncycles, and a quadratic-time, $4/3$-approximation algorithm for permutations\nthat contain multiple cycles. The proposed methods rely on investigating a\nnewly introduced balancing property of cycles embedded in trees, cycle-merging\nmethods, and shortest path optimization techniques. \n\n"}
{"id": "1307.4815", "contents": "Title: Linear Precoder Design for MIMO Interference Channels with\n  Finite-Alphabet Signaling Abstract: This paper investigates the linear precoder design for $K$-user interference\nchannels of multiple-input multiple-output (MIMO) transceivers under finite\nalphabet inputs. We first obtain general explicit expressions of the achievable\nrate for users in the MIMO interference channel systems. We study optimal\ntransmission strategies in both low and high signal-to-noise ratio (SNR)\nregions. Given finite alphabet inputs, we show that a simple power allocation\ndesign achieves optimal performance at high SNR whereas the well-known\ninterference alignment technique for Gaussian inputs only utilizes a partial\ninterference-free signal space for transmission and leads to a constant rate\nloss when applied naively to finite-alphabet inputs. Moreover, we establish\nnecessary conditions for the linear precoder design to achieve weighted\nsum-rate maximization. We also present an efficient iterative algorithm for\ndetermining precoding matrices of all the users. Our numerical results\ndemonstrate that the proposed iterative algorithm achieves considerably higher\nsum-rate under practical QAM inputs than other known methods. \n\n"}
{"id": "1307.5827", "contents": "Title: Cooperative Energy Harvesting Networks with Spatially Random Users Abstract: This paper considers a cooperative network with multiple source-destination\npairs and one energy harvesting relay. The outage probability experienced by\nusers in this network is characterized by taking the spatial randomness of user\nlocations into consideration. In addition, the cooperation among users is\nmodeled as a canonical coalitional game and the grand coalition is shown to be\nstable in the addressed scenario. Simulation results are provided to\ndemonstrate the accuracy of the developed analytical results. \n\n"}
{"id": "1308.1438", "contents": "Title: Profiling hot and dense nuclear medium with high transverse momentum\n  hadrons produced in d+Au and Au+Au collisions by the PHENIX experiment at\n  RHIC Abstract: PHENIX measurements of high transverse momentum ($p_T$) identified hadrons in\n$d$+Au and Au+Au collisions are presented. The nuclear modification factors\n($R_{d{\\rm A}}$ and $R_{\\rm AA}$) for $\\pi^0$ and $\\eta$ are found to be very\nconsistent in both collision systems, respectively. Using large amount of $p+p$\nand Au+Au datasets, the fractional momentum loss ($S_{\\rm loss}$) and the\npath-length dependent yield of $\\pi^0$ in Au+Au collisions are obtained. The\nhadron spectra in the most central $d$+Au and the most peripheral Au+Au\ncollisions are studied. The spectra shapes are found to be similar in both\nsystems, but the yield is suppressed in the most peripheral Au+Au collisions. \n\n"}
{"id": "1308.2454", "contents": "Title: Understanding the Benefits of Open Access in Femtocell Networks:\n  Stochastic Geometric Analysis in the Uplink Abstract: We introduce a comprehensive analytical framework to compare between open\naccess and closed access in two-tier femtocell networks, with regard to uplink\ninterference and outage. Interference at both the macrocell and femtocell\nlevels is considered. A stochastic geometric approach is employed as the basis\nfor our analysis. We further derive sufficient conditions for open access and\nclosed access to outperform each other in terms of the outage probability,\nleading to closed-form expressions to upper and lower bound the difference in\nthe targeted received power between the two access modes. Simulations are\nconducted to validate the accuracy of the analytical model and the correctness\nof the bounds. \n\n"}
{"id": "1308.4123", "contents": "Title: A Likelihood Ratio Approach for Probabilistic Inequalities Abstract: We propose a new approach for deriving probabilistic inequalities based on\nbounding likelihood ratios. We demonstrate that this approach is more general\nand powerful than the classical method frequently used for deriving\nconcentration inequalities such as Chernoff bounds. We discover that the\nproposed approach is inherently related to statistical concepts such as\nmonotone likelihood ratio, maximum likelihood, and the method of moments for\nparameter estimation. A connection between the proposed approach and the large\ndeviation theory is also established. We show that, without using moment\ngenerating functions, tightest possible concentration inequalities may be\nreadily derived by the proposed approach. We have derived new concentration\ninequalities using the proposed approach, which cannot be obtained by the\nclassical approach based on moment generating functions. \n\n"}
{"id": "1308.6175", "contents": "Title: Connections Between Construction D and Related Constructions of Lattices Abstract: Most practical constructions of lattice codes with high coding gains are\nmultilevel constructions where each level corresponds to an underlying code\ncomponent. Construction D, Construction D$'$, and Forney's code formula are\nclassical constructions that produce such lattices explicitly from a family of\nnested binary linear codes. In this paper, we investigate these three closely\nrelated constructions along with the recently developed Construction A$'$ of\nlattices from codes over the polynomial ring $\\mathbb{F}_2[u]/u^a$. We show\nthat Construction by Code Formula produces a lattice packing if and only if the\nnested codes being used are closed under Schur product, thus proving the\nsimilarity of Construction D and Construction by Code Formula when applied to\nReed-Muller codes. In addition, we relate Construction by Code Formula to\nConstruction A$'$ by finding a correspondence between nested binary codes and\ncodes over $\\mathbb{F}_2[u]/u^a$. This proves that any lattice constructible\nusing Construction by Code Formula is also constructible using Construction\nA$'$. Finally, we show that Construction A$'$ produces a lattice if and only if\nthe corresponding code over $\\mathbb{F}_2[u]/u^a$ is closed under shifted Schur\nproduct. \n\n"}
{"id": "1308.6503", "contents": "Title: Second-Order Asymptotics for the Classical Capacity of Image-Additive\n  Quantum Channels Abstract: We study non-asymptotic fundamental limits for transmitting classical\ninformation over memoryless quantum channels, i.e. we investigate the amount of\nclassical information that can be transmitted when a quantum channel is used a\nfinite number of times and a fixed, non-vanishing average error is permissible.\nWe consider the classical capacity of quantum channels that are image-additive,\nincluding all classical to quantum channels, as well as the product state\ncapacity of arbitrary quantum channels. In both cases we show that the\nnon-asymptotic fundamental limit admits a second-order approximation that\nillustrates the speed at which the rate of optimal codes converges to the\nHolevo capacity as the blocklength tends to infinity. The behavior is governed\nby a new channel parameter, called channel dispersion, for which we provide a\ngeometrical interpretation. \n\n"}
{"id": "1309.1323", "contents": "Title: From Instantly Decodable to Random Linear Network Coding Abstract: Our primary goal in this paper is to traverse the performance gap between two\nlinear network coding schemes: random linear network coding (RLNC) and\ninstantly decodable network coding (IDNC) in terms of throughput and decoding\ndelay. We first redefine the concept of packet generation and use it to\npartition a block of partially-received data packets in a novel way, based on\nthe coding sets in an IDNC solution. By varying the generation size, we obtain\na general coding framework which consists of a series of coding schemes, with\nRLNC and IDNC identified as two extreme cases. We then prove that the\nthroughput and decoding delay performance of all coding schemes in this coding\nframework are bounded between the performance of RLNC and IDNC and hence\nthroughput-delay tradeoff becomes possible. We also propose implementations of\nthis coding framework to further improve its throughput and decoding delay\nperformance, to manage feedback frequency and coding complexity, or to achieve\nin-block performance adaption. Extensive simulations are then provided to\nverify the performance of the proposed coding schemes and their\nimplementations. \n\n"}
{"id": "1309.1541", "contents": "Title: Projection onto the probability simplex: An efficient algorithm with a\n  simple proof, and an application Abstract: We provide an elementary proof of a simple, efficient algorithm for computing\nthe Euclidean projection of a point onto the probability simplex. We also show\nan application in Laplacian K-modes clustering. \n\n"}
{"id": "1309.3139", "contents": "Title: Exploiting Interference for Efficient Distributed Computation in\n  Cluster-based Wireless Sensor Networks Abstract: This invited paper presents some novel ideas on how to enhance the\nperformance of consensus algorithms in distributed wireless sensor networks,\nwhen communication costs are considered. Of particular interest are consensus\nalgorithms that exploit the broadcast property of the wireless channel to boost\nthe performance in terms of convergence speeds. To this end, we propose a novel\nclustering based consensus algorithm that exploits interference for\ncomputation, while reducing the energy consumption in the network. The\nresulting optimization problem is a semidefinite program, which can be solved\noffline prior to system startup. \n\n"}
{"id": "1309.3228", "contents": "Title: Quantum hypothesis testing and the operational interpretation of the\n  quantum Renyi relative entropies Abstract: We show that the new quantum extension of Renyi's \\alpha-relative entropies,\nintroduced recently by Muller-Lennert, Dupuis, Szehr, Fehr and Tomamichel, J.\nMath. Phys. 54, 122203, (2013), and Wilde, Winter, Yang, Commun. Math. Phys.\n331, (2014), have an operational interpretation in the strong converse problem\nof quantum hypothesis testing. Together with related results for the direct\npart of quantum hypothesis testing, known as the quantum Hoeffding bound, our\nresult suggests that the operationally relevant definition of the quantum Renyi\nrelative entropies depends on the parameter \\alpha: for \\alpha<1, the right\nchoice seems to be the traditional definition, whereas for \\alpha>1 the right\nchoice is the newly introduced version.\n  As a sideresult, we show that the new Renyi \\alpha-relative entropies are\nasymptotically attainable by measurements for \\alpha>1, and give a new simple\nproof for their monotonicity under completely positive trace-preserving maps. \n\n"}
{"id": "1309.4111", "contents": "Title: Regularized Spectral Clustering under the Degree-Corrected Stochastic\n  Blockmodel Abstract: Spectral clustering is a fast and popular algorithm for finding clusters in\nnetworks. Recently, Chaudhuri et al. (2012) and Amini et al.(2012) proposed\ninspired variations on the algorithm that artificially inflate the node degrees\nfor improved statistical performance. The current paper extends the previous\nstatistical estimation results to the more canonical spectral clustering\nalgorithm in a way that removes any assumption on the minimum degree and\nprovides guidance on the choice of the tuning parameter. Moreover, our results\nshow how the \"star shape\" in the eigenvectors--a common feature of empirical\nnetworks--can be explained by the Degree-Corrected Stochastic Blockmodel and\nthe Extended Planted Partition model, two statistical models that allow for\nhighly heterogeneous degrees. Throughout, the paper characterizes and justifies\nseveral of the variations of the spectral clustering algorithm in terms of\nthese models. \n\n"}
{"id": "1309.5979", "contents": "Title: Asymptotic Analysis of LASSOs Solution Path with Implications for\n  Approximate Message Passing Abstract: This paper concerns the performance of the LASSO (also knows as basis pursuit\ndenoising) for recovering sparse signals from undersampled, randomized, noisy\nmeasurements. We consider the recovery of the signal $x_o \\in \\mathbb{R}^N$\nfrom $n$ random and noisy linear observations $y= Ax_o + w$, where $A$ is the\nmeasurement matrix and $w$ is the noise. The LASSO estimate is given by the\nsolution to the optimization problem $x_o$ with $\\hat{x}_{\\lambda} = \\arg\n\\min_x \\frac{1}{2} \\|y-Ax\\|_2^2 + \\lambda \\|x\\|_1$. Despite major progress in\nthe theoretical analysis of the LASSO solution, little is known about its\nbehavior as a function of the regularization parameter $\\lambda$. In this paper\nwe study two questions in the asymptotic setting (i.e., where $N \\rightarrow\n\\infty$, $n \\rightarrow \\infty$ while the ratio $n/N$ converges to a fixed\nnumber in $(0,1)$): (i) How does the size of the active set\n$\\|\\hat{x}_\\lambda\\|_0/N$ behave as a function of $\\lambda$, and (ii) How does\nthe mean square error $\\|\\hat{x}_{\\lambda} - x_o\\|_2^2/N$ behave as a function\nof $\\lambda$? We then employ these results in a new, reliable algorithm for\nsolving LASSO based on approximate message passing (AMP). \n\n"}
{"id": "1309.7528", "contents": "Title: Finite-Length Analyses for Source and Channel Coding on Markov Chains Abstract: We study finite-length bounds for source coding with side information for\nMarkov sources and channel coding for channels with conditional Markovian\nadditive noise. For this purpose, we propose two criteria for finite-length\nbounds. One is the asymptotic optimality and the other is the efficient\ncomputability of the bound. Then, we derive finite-length upper and lower\nbounds for coding length in both settings so that their computational\ncomplexity is efficient. To discuss the first criterion, we derive the large\ndeviation bounds, the moderate deviation bounds, and second order bounds for\nthese two topics, and show that these finite-length bounds achieves the\nasymptotic optimality in these senses. For this discussion, we introduce\nseveral kinds of information measure for transition matrices. \n\n"}
{"id": "1309.7583", "contents": "Title: Optimized Bit Mappings for Spatially Coupled LDPC Codes over Parallel\n  Binary Erasure Channels Abstract: In many practical communication systems, one binary encoder/decoder pair is\nused to communicate over a set of parallel channels. Examples of this setup\ninclude multi-carrier transmission, rate-compatible puncturing of turbo-like\ncodes, and bit-interleaved coded modulation (BICM). A bit mapper is commonly\nemployed to determine how the coded bits are allocated to the channels. In this\npaper, we study spatially coupled low-density parity check codes over parallel\nchannels and optimize the bit mapper using BICM as the driving example. For\nsimplicity, the parallel bit channels that arise in BICM are replaced by\nindependent binary erasure channels (BECs). For two parallel BECs modeled\naccording to a 4-PAM constellation labeled by the binary reflected Gray code,\nthe optimization results show that the decoding threshold can be improved over\na uniform random bit mapper, or, alternatively, the spatial chain length of the\ncode can be reduced for a given gap to capacity. It is also shown that for\nrate-loss free, circular (tail-biting) ensembles, a decoding wave effect can be\ninitiated using only an optimized bit mapper. \n\n"}
{"id": "1309.7734", "contents": "Title: Some New Results on the Cross Correlation of $m$-sequences Abstract: The determination of the cross correlation between an $m$-sequence and its\ndecimated sequence has been a long-standing research problem. Considering a\nternary $m$-sequence of period $3^{3r}-1$, we determine the cross correlation\ndistribution for decimations $d=3^{r}+2$ and $d=3^{2r}+2$, where $\\gcd(r,3)=1$.\nMeanwhile, for a binary $m$-sequence of period $2^{2lm}-1$, we make an initial\ninvestigation for the decimation $d=\\frac{2^{2lm}-1}{2^{m}+1}+2^{s}$, where $l\n\\ge 2$ is even and $0 \\le s \\le 2m-1$. It is shown that the cross correlation\ntakes at least four values. Furthermore, we confirm the validity of two famous\nconjectures due to Sarwate et al. and Helleseth in this case. \n\n"}
{"id": "1309.7804", "contents": "Title: On statistics, computation and scalability Abstract: How should statistical procedures be designed so as to be scalable\ncomputationally to the massive datasets that are increasingly the norm? When\ncoupled with the requirement that an answer to an inferential question be\ndelivered within a certain time budget, this question has significant\nrepercussions for the field of statistics. With the goal of identifying\n\"time-data tradeoffs,\" we investigate some of the statistical consequences of\ncomputational perspectives on scability, in particular divide-and-conquer\nmethodology and hierarchies of convex relaxations. \n\n"}
{"id": "1309.7824", "contents": "Title: Linear Regression from Strategic Data Sources Abstract: Linear regression is a fundamental building block of statistical data\nanalysis. It amounts to estimating the parameters of a linear model that maps\ninput features to corresponding outputs. In the classical setting where the\nprecision of each data point is fixed, the famous Aitken/Gauss-Markov theorem\nin statistics states that generalized least squares (GLS) is a so-called \"Best\nLinear Unbiased Estimator\" (BLUE). In modern data science, however, one often\nfaces strategic data sources, namely, individuals who incur a cost for\nproviding high-precision data.\n  In this paper, we study a setting in which features are public but\nindividuals choose the precision of the outputs they reveal to an analyst. We\nassume that the analyst performs linear regression on this dataset, and\nindividuals benefit from the outcome of this estimation. We model this scenario\nas a game where individuals minimize a cost comprising two components: (a) an\n(agent-specific) disclosure cost for providing high-precision data; and (b) a\n(global) estimation cost representing the inaccuracy in the linear model\nestimate. In this game, the linear model estimate is a public good that\nbenefits all individuals. We establish that this game has a unique non-trivial\nNash equilibrium. We study the efficiency of this equilibrium and we prove\ntight bounds on the price of stability for a large class of disclosure and\nestimation costs. Finally, we study the estimator accuracy achieved at\nequilibrium. We show that, in general, Aitken's theorem does not hold under\nstrategic data sources, though it does hold if individuals have identical\ndisclosure costs (up to a multiplicative factor). When individuals have\nnon-identical costs, we derive a bound on the improvement of the equilibrium\nestimation cost that can be achieved by deviating from GLS, under mild\nassumptions on the disclosure cost functions. \n\n"}
{"id": "1310.1890", "contents": "Title: Investigation of collective radial expansion and stopping in heavy ion\n  collisions at Fermi energies Abstract: We present an analysis of multifragmentation events observed in central Xe+Sn\nreactions at Fermi energies. Performing a comparison between the predictions of\nthe Stochastic Mean Field (SMF) transport model and experimental data, we\ninvestigate the impact of the compression-expansion dynamics on the properties\nof the final reaction products. We show that the amount of radial collective\nexpansion, which characterizes the dynamical stage of the reaction, influences\ndirectly the onset of multifragmentation and the kinematic properties of\nmultifragmentation events. For the same set of events we also undertake a shape\nanalysis in momentum space, looking at the degree of stopping reached in the\ncollision, as proposed in recent experimental studies. We show that full\nstopping is achieved for the most central collisions at Fermi energies.\nHowever, considering the same central event selection as in the experimental\ndata, we observe a similar behavior of the stopping power with the beam energy,\nwhich can be associated with a change of the fragmentation mechanism, from\nstatistical to prompt fragment emission. \n\n"}
{"id": "1310.2121", "contents": "Title: Dynamics and termination cost of spatially coupled mean-field models Abstract: This work is motivated by recent progress in information theory and signal\nprocessing where the so-called `spatially coupled' design of systems leads to\nconsiderably better performance. We address relevant open questions about\nspatially coupled systems through the study of a simple Ising model. In\nparticular, we consider a chain of Curie-Weiss models that are coupled by\ninteractions up to a certain range. Indeed, it is well known that the pure\n(uncoupled) Curie-Weiss model undergoes a first order phase transition driven\nby the magnetic field, and furthermore, in the spinodal region such systems are\nunable to reach equilibrium in sub-exponential time if initialized in the\nmetastable state. By contrast, the spatially coupled system is, instead, able\nto reach the equilibrium even when initialized to the metastable state. The\nequilibrium phase propagates along the chain in the form of a travelling wave.\nHere we study the speed of the wave-front and the so-called `termination\ncost'--- \\textit{i.e.}, the conditions necessary for the propagation to occur.\nWe reach several interesting conclusions about optimization of the speed and\nthe cost. \n\n"}
{"id": "1310.2806", "contents": "Title: An Empirical-Bayes Approach to Recovering Linearly Constrained\n  Non-Negative Sparse Signals Abstract: We propose two novel approaches to the recovery of an (approximately) sparse\nsignal from noisy linear measurements in the case that the signal is a priori\nknown to be non-negative and obey given linear equality constraints, such as\nsimplex signals. This problem arises in, e.g., hyperspectral imaging, portfolio\noptimization, density estimation, and certain cases of compressive imaging. Our\nfirst approach solves a linearly constrained non-negative version of LASSO\nusing the max-sum version of the generalized approximate message passing (GAMP)\nalgorithm, where we consider both quadratic and absolute loss, and where we\npropose a novel approach to tuning the LASSO regularization parameter via the\nexpectation maximization (EM) algorithm. Our second approach is based on the\nsum-product version of the GAMP algorithm, where we propose the use of a\nBernoulli non-negative Gaussian-mixture signal prior and a Laplacian\nlikelihood, and propose an EM-based approach to learning the underlying\nstatistical parameters. In both approaches, the linear equality constraints are\nenforced by augmenting GAMP's generalized-linear observation model with\nnoiseless pseudo-measurements. Extensive numerical experiments demonstrate the\nstate-of-the-art performance of our proposed approaches. \n\n"}
{"id": "1310.5930", "contents": "Title: A Unifying Model for External Noise Sources and ISI in Diffusive\n  Molecular Communication Abstract: This paper considers the impact of external noise sources, including\ninterfering transmitters, on a diffusive molecular communication system, where\nthe impact is measured as the number of noise molecules expected to be observed\nat a passive receiver. A unifying model for noise, multiuser interference, and\nintersymbol interference is presented, where, under certain circumstances,\ninterference can be approximated as a noise source that is emitting\ncontinuously. The model includes the presence of advection and molecule\ndegradation. The time-varying and asymptotic impact is derived for a series of\nspecial cases, some of which facilitate closed-form solutions. Simulation\nresults show the accuracy of the expressions derived for the impact of a\ncontinuously-emitting noise source, and show how approximating intersymbol\ninterference as a noise source can simplify the calculation of the expected bit\nerror probability of a weighted sum detector. \n\n"}
{"id": "1310.7669", "contents": "Title: Further Studies of Transverse Enhancement in Quasielastic Electron\n  Scattering Abstract: In a previous communication we reported on a parametrization of the observed\nenhancement in the transverse electron quasielastic (QE) response function for\nnucleons bound in carbon as a function of the square of the four momentum\ntransfer ($Q^2$) in terms of a correction to the magnetic form factors of bound\nnucleons. That parametrization was used to predict the overall magnitude and\n$Q^2$ dependence of the cross section for neutrino quasielastic scattering on\nnuclear targets. In this paper, we extend the study to include parametrizations\nof both the $Q^2$ as well as the energy transfer ($\\nu$) dependence of the\ntransverse enhancement. These parametrization can be used to give a more\ncomplete two dimensional description of the neutrino quasielastic scattering\nprocess on nuclear targets, which is essential for precision studies of mass\nsplitings and mixing angles in neutrino oscillation experiments. \n\n"}
{"id": "1311.0100", "contents": "Title: An Efficient Feedback Coding Scheme with Low Error Probability for\n  Discrete Memoryless Channels Abstract: Existing fixed-length feedback communication schemes are either specialized\nto particular channels (Schalkwijk--Kailath, Horstein), or apply to general\nchannels but either have high coding complexity (block feedback schemes) or are\ndifficult to analyze (posterior matching). This paper introduces a new\nfixed-length feedback coding scheme which achieves the capacity for all\ndiscrete memoryless channels, has an error exponent that approaches the sphere\npacking bound as the rate approaches the capacity, and has $O(n\\log n)$ coding\ncomplexity. These benefits are achieved by judiciously combining features from\nprevious schemes with new randomization technique and encoding/decoding rule.\nThese new features make the analysis of the error probability for the new\nscheme easier than for posterior matching. \n\n"}
{"id": "1311.0121", "contents": "Title: Subspace Thresholding Pursuit: A Reconstruction Algorithm for Compressed\n  Sensing Abstract: We propose a new iterative greedy algorithm for reconstructions of sparse\nsignals with or without noisy perturbations in compressed sensing. The proposed\nalgorithm, called \\emph{subspace thresholding pursuit} (STP) in this paper, is\na simple combination of subspace pursuit and iterative hard thresholding.\nFirstly, STP has the theoretical guarantee comparable to that of $\\ell_1$\nminimization in terms of restricted isometry property. Secondly, with a tuned\nparameter, on the one hand, when reconstructing Gaussian signals, it can\noutperform other state-of-the-art reconstruction algorithms greatly; on the\nother hand, when reconstructing constant amplitude signals with random signs,\nit can outperform other state-of-the-art iterative greedy algorithms and even\noutperform $\\ell_1$ minimization if the undersampling ratio is not very large.\nIn addition, we propose a simple but effective method to improve the empirical\nperformance further if the undersampling ratio is large. Finally, it is showed\nthat other iterative greedy algorithms can improve their empirical performance\nby borrowing the idea of STP. \n\n"}
{"id": "1311.2234", "contents": "Title: FuSSO: Functional Shrinkage and Selection Operator Abstract: We present the FuSSO, a functional analogue to the LASSO, that efficiently\nfinds a sparse set of functional input covariates to regress a real-valued\nresponse against. The FuSSO does so in a semi-parametric fashion, making no\nparametric assumptions about the nature of input functional covariates and\nassuming a linear form to the mapping of functional covariates to the response.\nWe provide a statistical backing for use of the FuSSO via proof of asymptotic\nsparsistency under various conditions. Furthermore, we observe good results on\nboth synthetic and real-world data. \n\n"}
{"id": "1311.2651", "contents": "Title: MIMO Broadcast Channel with an Unknown Eavesdropper: Secrecy Degrees of\n  Freedom Abstract: We study a multi-antenna broadcast channel with two legitimate receivers and\nan external eavesdropper. We assume that the channel matrix of the eavesdropper\nis unknown to the legitimate terminals but satisfies a maximum rank constraint.\nAs our main result we characterize the associated secrecy degrees of freedom\nfor the broadcast channel with common and private messages. We show that a\ndirect extension of the single-user wiretap codebook does not achieve the\nsecrecy degrees of freedom. Our proposed optimal scheme involves decomposing\nthe signal space into a common subspace, which can be observed by both\nreceivers, and private subspaces which can be observed by only one of the\nreceivers, and carefully transmitting a subset of messages in each subspace. We\nalso consider the case when each user's private message must additionally\nremain confidential from the other legitimate receiver and characterize the\ns.d.o.f.\\ region in this case. \n\n"}
{"id": "1311.3995", "contents": "Title: Compressed Sensing for Energy-Efficient Wireless Telemonitoring:\n  Challenges and Opportunities Abstract: As a lossy compression framework, compressed sensing has drawn much attention\nin wireless telemonitoring of biosignals due to its ability to reduce energy\nconsumption and make possible the design of low-power devices. However, the\nnon-sparseness of biosignals presents a major challenge to compressed sensing.\nThis study proposes and evaluates a spatio-temporal sparse Bayesian learning\nalgorithm, which has the desired ability to recover such non-sparse biosignals.\nIt exploits both temporal correlation in each individual biosignal and\ninter-channel correlation among biosignals from different channels. The\nproposed algorithm was used for compressed sensing of multichannel\nelectroencephalographic (EEG) signals for estimating vehicle drivers'\ndrowsiness. Results showed that the drowsiness estimation was almost unaffected\neven if raw EEG signals (containing various artifacts) were compressed by 90%. \n\n"}
{"id": "1311.4679", "contents": "Title: Potential of the neutron Lloyd's mirror interferometer for the search\n  for new interactions Abstract: We discuss the potential of the neutron Lloyd's mirror interferometer in a\nsearch for new interactions at small scales. We consider three hypothetical\ninteractions that may be tested using the interferometer.\n  The chameleon scalar field proposed to solve the enigma of accelerating\nexpansion of the Universe produces interaction between particles and matter.\nThe axion-like spin-dependent coupling between neutron and nuclei or/and\nelectrons may cause P- and T-non-invariant interaction with matter.\nHypothetical non-Newtonian gravitational interactions mediates additional\nshort-range potential between neutrons and bulk matter. These interactions\nbetween the neutron and the mirror of the Lloyd's type neutron interferometer\ncause phase shift of neutron waves.\n  We estimate the sensitivity and systematic effects of possible experiments. \n\n"}
{"id": "1311.4861", "contents": "Title: On Multiplicative Matrix Channels over Finite Chain Rings Abstract: Motivated by physical-layer network coding, this paper considers\ncommunication in multiplicative matrix channels over finite chain rings. Such\nchannels are defined by the law $Y =A X$, where $X$ and $Y$ are the input and\noutput matrices, respectively, and $A$ is called the transfer matrix. It is\nassumed a coherent scenario in which the instances of the transfer matrix are\nunknown to the transmitter, but available to the receiver. It is also assumed\nthat $A$ and $X$ are independent. Besides that, no restrictions on the\nstatistics of $A$ are imposed. As contributions, a closed-form expression for\nthe channel capacity is obtained, and a coding scheme for the channel is\nproposed. It is then shown that the scheme can achieve the capacity with\npolynomial time complexity and can provide correcting guarantees under a\nworst-case channel model. The results in the paper extend the corresponding\nones for finite fields. \n\n"}
{"id": "1311.6635", "contents": "Title: Multiuser Random Coding Techniques for Mismatched Decoding Abstract: This paper studies multiuser random coding techniques for channel coding with\na given (possibly suboptimal) decoding rule. For the mismatched discrete\nmemoryless multiple-access channel, an error exponent is obtained that is tight\nwith respect to the ensemble average, and positive within the interior of\nLapidoth's achievable rate region. This exponent proves the ensemble tightness\nof the exponent of Liu and Hughes in the case of maximum-likelihood decoding.\nAn equivalent dual form of Lapidoth's achievable rate region is given, and the\nlatter is shown to extend immediately to channels with infinite and continuous\nalphabets. In the setting of single-user mismatched decoding, similar analysis\ntechniques are applied to a refined version of superposition coding, which is\nshown to achieve rates at least as high as standard superposition coding for\nany set of random-coding parameters. \n\n"}
{"id": "1312.0894", "contents": "Title: Search for new resonant states in 10C and 11C and their impact on the\n  cosmological lithium problem Abstract: The observed primordial 7Li abundance in metal-poor halo stars is found to be\nlower than its Big-Bang nucleosynthesis (BBN) calculated value by a factor of\napproximately three. Some recent works suggested the possibility that this\ndiscrepancy originates from missing resonant reactions which would destroy the\n7Be, parent of 7Li. The most promising candidate resonances which were found\ninclude a possibly missed 1- or 2- narrow state around 15 MeV in the compound\nnucleus 10C formed by 7Be+3He and a state close to 7.8 MeV in the compound\nnucleus 11C formed by 7Be+4He. In this work, we studied the high excitation\nenergy region of 10C and the low excitation energy region in 11C via the\nreactions 10B(3He,t)10C and 11B(3He,t)11C, respectively, at the incident energy\nof 35 MeV. Our results for 10C do not support 7Be+3He as a possible solution\nfor the 7Li problem. Concerning 11C results, the data show no new resonances in\nthe excitation energy region of interest and this excludes 7Be+4He reaction\nchannel as an explanation for the 7Li deficit. \n\n"}
{"id": "1312.1666", "contents": "Title: Semi-Stochastic Gradient Descent Methods Abstract: In this paper we study the problem of minimizing the average of a large\nnumber ($n$) of smooth convex loss functions. We propose a new method, S2GD\n(Semi-Stochastic Gradient Descent), which runs for one or several epochs in\neach of which a single full gradient and a random number of stochastic\ngradients is computed, following a geometric law. The total work needed for the\nmethod to output an $\\varepsilon$-accurate solution in expectation, measured in\nthe number of passes over data, or equivalently, in units equivalent to the\ncomputation of a single gradient of the loss, is\n$O((\\kappa/n)\\log(1/\\varepsilon))$, where $\\kappa$ is the condition number.\nThis is achieved by running the method for $O(\\log(1/\\varepsilon))$ epochs,\nwith a single gradient evaluation and $O(\\kappa)$ stochastic gradient\nevaluations in each. The SVRG method of Johnson and Zhang arises as a special\ncase. If our method is limited to a single epoch only, it needs to evaluate at\nmost $O((\\kappa/\\varepsilon)\\log(1/\\varepsilon))$ stochastic gradients. In\ncontrast, SVRG requires $O(\\kappa/\\varepsilon^2)$ stochastic gradients. To\nillustrate our theoretical results, S2GD only needs the workload equivalent to\nabout 2.1 full gradient evaluations to find an $10^{-6}$-accurate solution for\na problem with $n=10^9$ and $\\kappa=10^3$. \n\n"}
{"id": "1312.3194", "contents": "Title: Error-Correcting Regenerating and Locally Repairable Codes via\n  Rank-Metric Codes Abstract: This paper presents and analyzes a novel concatenated coding scheme for\nenabling error resilience in two distributed storage settings: one being\nstorage using existing regenerating codes and the second being storage using\nlocally repairable codes. The concatenated coding scheme brings together a\nmaximum rank distance (MRD) code as an outer code and either a globally\nregenerating or a locally repairable code as an inner code. Also, error\nresilience for combination of locally repairable codes with regenerating codes\nis considered. This concatenated coding system is designed to handle two\ndifferent types of adversarial errors: the first type includes an adversary\nthat can replace the content of an affected node only once; while the second\ntype studies an adversary that is capable of polluting data an unbounded number\nof times. The paper establishes an upper bound on the resilience capacity for a\nlocally repairable code and proves that this concatenated coding coding scheme\nattains the upper bound on resilience capacity for the first type of adversary.\nFurther, the paper presents mechanisms that combine the presented concatenated\ncoding scheme with subspace signatures to achieve error resilience for the\nsecond type of errors. \n\n"}
{"id": "1312.3200", "contents": "Title: Constrained Colluding Eavesdroppers: An Information-Theoretic Model Abstract: We study the secrecy capacity in the vicinity of colluding eavesdroppers.\nContrary to the perfect collusion assumption in previous works, our new\ninformation-theoretic model considers constraints in collusion. We derive the\nachievable secure rates (lower bounds on the perfect secrecy capacity), both\nfor the discrete memoryless and Gaussian channels. We also compare the proposed\nrates to the non-colluding and perfect colluding cases. \n\n"}
{"id": "1401.0615", "contents": "Title: Message Encoding for Spread and Orbit Codes Abstract: Spread codes and orbit codes are special families of constant dimension\nsubspace codes. These codes have been well-studied for their error correction\ncapability and transmission rate, but the question of how to encode messages\nhas not been investigated. In this work we show how the message space can be\nchosen for a given code and how message en- and decoding can be done. \n\n"}
{"id": "1401.0872", "contents": "Title: Binary Linear Classification and Feature Selection via Generalized\n  Approximate Message Passing Abstract: For the problem of binary linear classification and feature selection, we\npropose algorithmic approaches to classifier design based on the generalized\napproximate message passing (GAMP) algorithm, recently proposed in the context\nof compressive sensing. We are particularly motivated by problems where the\nnumber of features greatly exceeds the number of training examples, but where\nonly a few features suffice for accurate classification. We show that\nsum-product GAMP can be used to (approximately) minimize the classification\nerror rate and max-sum GAMP can be used to minimize a wide variety of\nregularized loss functions. Furthermore, we describe an\nexpectation-maximization (EM)-based scheme to learn the associated model\nparameters online, as an alternative to cross-validation, and we show that\nGAMP's state-evolution framework can be used to accurately predict the\nmisclassification rate. Finally, we present a detailed numerical study to\nconfirm the accuracy, speed, and flexibility afforded by our GAMP-based\napproaches to binary linear classification and feature selection. \n\n"}
{"id": "1401.2592", "contents": "Title: On the Optimality of Treating Interference as Noise: General Message\n  Sets Abstract: In a K-user Gaussian interference channel, it has been shown that if for each\nuser the desired signal strength is no less than the sum of the strengths of\nthe strongest interference from this user and the strongest interference to\nthis user (all values in dB scale), then treating interference as noise (TIN)\nis optimal from the perspective of generalized degrees-of-freedom (GDoF) and\nachieves the entire channel capacity region to within a constant gap. In this\nwork, we show that for such TIN-optimal interference channels, even if the\nmessage set is expanded to include an independent message from each transmitter\nto each receiver, operating the new channel as the original interference\nchannel and treating interference as noise is still optimal for the sum\ncapacity up to a constant gap. Furthermore, we extend the result to the\nsum-GDoF optimality of TIN in the general setting of X channels with arbitrary\nnumbers of transmitters and receivers. \n\n"}
{"id": "1401.3146", "contents": "Title: The Blackwell relation defines no lattice Abstract: Blackwell's theorem shows the equivalence of two preorders on the set of\ninformation channels. Here, we restate, and slightly generalize, his result in\nterms of random variables. Furthermore, we prove that the corresponding partial\norder is not a lattice; that is, least upper bounds and greatest lower bounds\ndo not exist. \n\n"}
{"id": "1401.3682", "contents": "Title: Broadcast Classical-Quantum Capacity Region of Two-Phase Bidirectional\n  Relaying Channel Abstract: We study a three-node quantum network which enables bidirectional\ncommunication between two nodes with a half-duplex relay node. A\ndecode-and-forward protocol is used to perform the communication in two phases.\nIn the first phase, the messages of two nodes are transmitted to the relay\nnode. In the second phase, the relay node broadcasts a re-encoded composition\nto the two nodes. We determine the capacity region of the broadcast phase. \n\n"}
{"id": "1401.4451", "contents": "Title: Reliable, Deniable, and Hidable Communication over Multipath Networks Abstract: We consider the scenario wherein Alice wants to (potentially) communicate to\nthe intended receiver Bob over a network consisting of multiple parallel links\nin the presence of a passive eavesdropper Willie, who observes an unknown\nsubset of links. A primary goal of our communication protocol is to make the\ncommunication \"deniable\", {\\it i.e.}, Willie should not be able to {\\it\nreliably} estimate whether or not Alice is transmitting any {\\it covert}\ninformation to Bob. Moreover, if Alice is indeed actively communicating, her\ncovert messages should be information-theoretically \"hidable\" in the sense that\nWillie's observations should not {\\it leak any information} about Alice's\n(potential) message to Bob -- our notion of hidability is slightly stronger\nthan the notion of information-theoretic strong secrecy well-studied in the\nliterature, and may be of independent interest. It can be shown that\ndeniability does not imply either hidability or (weak or strong)\ninformation-theoretic secrecy; nor does any form of information-theoretic\nsecrecy imply deniability. We present matching inner and outer bounds on the\ncapacity for deniable and hidable communication over {\\it multipath networks}. \n\n"}
{"id": "1401.6063", "contents": "Title: Resource cost results for one-way entanglement distillation and state\n  merging of compound and arbitrarily varying quantum sources Abstract: We consider one-way quantum state merging and entanglement distillation under\ncompound and arbitrarily varying source models. Regarding quantum compound\nsources, where the source is memoryless, but the source state an unknown member\nof a certain set of density matrices, we continue investigations begun in the\nwork of Bjelakovi\\'c et. al. [Universal quantum state merging, J. Math. Phys.\n54, 032204 (2013)] and determine the classical as well as entanglement cost of\nstate merging. We further investigate quantum state merging and entanglement\ndistillation protocols for arbitrarily varying quantum sources (AVQS). In the\nAVQS model, the source state is assumed to vary in an arbitrary manner for each\nsource output due to environmental fluctuations or adversarial manipulation. We\ndetermine the one-way entanglement distillation capacity for AVQS, where we\ninvoke the famous robustification and elimination techniques introduced by R.\nAhlswede. Regarding quantum state merging for AVQS we show by example, that the\nrobustification and elimination based approach generally leads to suboptimal\nentanglement as well as classical communication rates. \n\n"}
{"id": "1401.6853", "contents": "Title: Computing the Kullback-Leibler Divergence between two Generalized Gamma\n  Distributions Abstract: We derive a closed form solution for the Kullback-Leibler divergence between\ntwo generalized gamma distributions. These notes are meant as a reference and\nprovide a guided tour towards a result of practical interest that is rarely\nexplicated in the literature. \n\n"}
{"id": "1401.7485", "contents": "Title: Superimposed Codes and Threshold Group Testing Abstract: We will discuss superimposed codes and non-adaptive group testing designs\narising from the potentialities of compressed genotyping models in molecular\nbiology. The given paper was motivated by the 30th anniversary of\nD'yachkov-Rykov recurrent upper bound on the rate of superimposed codes\npublished in 1982. We were also inspired by recent results obtained for\nnon-adaptive threshold group testing which develop the theory of superimposed\ncodes \n\n"}
{"id": "1402.0375", "contents": "Title: Highly symmetric POVMs and their informational power Abstract: We discuss the dependence of the Shannon entropy of normalized finite rank-1\nPOVMs on the choice of the input state, looking for the states that minimize\nthis quantity. To distinguish the class of measurements where the problem can\nbe solved analytically, we introduce the notion of highly symmetric POVMs and\nclassify them in dimension two (for qubits). In this case we prove that the\nentropy is minimal, and hence the relative entropy (informational power) is\nmaximal, if and only if the input state is orthogonal to one of the states\nconstituting a POVM. The method used in the proof, employing the Michel theory\nof critical points for group action, the Hermite interpolation and the\nstructure of invariant polynomials for unitary-antiunitary groups, can also be\napplied in higher dimensions and for other entropy-like functions. The links\nbetween entropy minimization and entropic uncertainty relations, the Wehrl\nentropy and the quantum dynamical entropy are described. \n\n"}
{"id": "1402.0614", "contents": "Title: Vector Bin-and-Cancel for MIMO Distributed Full-Duplex Abstract: In a multi-input multi-output (MIMO) full-duplex network, where an in-band\nfull-duplex infrastruc- ture node communicates with two half-duplex mobiles\nsupporting simultaneous up- and downlink flows, the inter-mobile interference\nbetween the up- and downlink mobiles limits the system performance. We study\nthe impact of leveraging an out-of-band side-channel between mobiles in such\nnetwork under different channel models. For time-invariant channels, we aim to\ncharacterize the generalized degrees- of-freedom (GDoF) of the side-channel\nassisted MIMO full-duplex network. For slow-fading channels, we focus on the\ndiversity-multiplexing tradeoff (DMT) of the system with various assumptions as\nto the availability of channel state information at the transmitter (CSIT). The\nkey to the optimal performance is a vector bin-and-cancel strategy leveraging\nHan-Kobayashi message splitting, which is shown to achieve the system capacity\nregion to within a constant bit. We quantify how the side-channel improve the\nGDoF and DMT compared to a system without the extra orthogonal spectrum. The\ninsights gained from our analysis reveal: i) the tradeoff between spatial\nresources from multiple antennas at different nodes and spectral resources of\nthe side-channel, and ii) the interplay between the channel uncertainty at the\ntransmitter and use of the side-channel. \n\n"}
{"id": "1402.1473", "contents": "Title: Near-Optimal Joint Object Matching via Convex Relaxation Abstract: Joint matching over a collection of objects aims at aggregating information\nfrom a large collection of similar instances (e.g. images, graphs, shapes) to\nimprove maps between pairs of them. Given multiple matches computed between a\nfew object pairs in isolation, the goal is to recover an entire collection of\nmaps that are (1) globally consistent, and (2) close to the provided maps ---\nand under certain conditions provably the ground-truth maps. Despite recent\nadvances on this problem, the best-known recovery guarantees are limited to a\nsmall constant barrier --- none of the existing methods find theoretical\nsupport when more than $50\\%$ of input correspondences are corrupted. Moreover,\nprior approaches focus mostly on fully similar objects, while it is practically\nmore demanding to match instances that are only partially similar to each\nother.\n  In this paper, we develop an algorithm to jointly match multiple objects that\nexhibit only partial similarities, given a few pairwise matches that are\ndensely corrupted. Specifically, we propose to recover the ground-truth maps\nvia a parameter-free convex program called MatchLift, following a spectral\nmethod that pre-estimates the total number of distinct elements to be matched.\nEncouragingly, MatchLift exhibits near-optimal error-correction ability, i.e.\nin the asymptotic regime it is guaranteed to work even when a dominant fraction\n$1-\\Theta\\left(\\frac{\\log^{2}n}{\\sqrt{n}}\\right)$ of the input maps behave like\nrandom outliers. Furthermore, MatchLift succeeds with minimal input complexity,\nnamely, perfect matching can be achieved as soon as the provided maps form a\nconnected map graph. We evaluate the proposed algorithm on various benchmark\ndata sets including synthetic examples and real-world examples, all of which\nconfirm the practical applicability of MatchLift. \n\n"}
{"id": "1402.2044", "contents": "Title: A Second-order Bound with Excess Losses Abstract: We study online aggregation of the predictions of experts, and first show new\nsecond-order regret bounds in the standard setting, which are obtained via a\nversion of the Prod algorithm (and also a version of the polynomially weighted\naverage algorithm) with multiple learning rates. These bounds are in terms of\nexcess losses, the differences between the instantaneous losses suffered by the\nalgorithm and the ones of a given expert. We then demonstrate the interest of\nthese bounds in the context of experts that report their confidences as a\nnumber in the interval [0,1] using a generic reduction to the standard setting.\nWe conclude by two other applications in the standard setting, which improve\nthe known bounds in case of small excess losses and show a bounded regret\nagainst i.i.d. sequences of losses. \n\n"}
{"id": "1402.7028", "contents": "Title: Hall A Annual Report 2013 Abstract: Report over the experimental activities in Hall A at Thomas Jefferson\nNational Accelerator Facility during 2013. \n\n"}
{"id": "1403.0515", "contents": "Title: A Primal Dual Active Set with Continuation Algorithm for the\n  \\ell^0-Regularized Optimization Problem Abstract: We develop a primal dual active set with continuation algorithm for solving\nthe \\ell^0-regularized least-squares problem that frequently arises in\ncompressed sensing. The algorithm couples the the primal dual active set method\nwith a continuation strategy on the regularization parameter. At each inner\niteration, it first identifies the active set from both primal and dual\nvariables, and then updates the primal variable by solving a (typically small)\nleast-squares problem defined on the active set, from which the dual variable\ncan be updated explicitly. Under certain conditions on the sensing matrix,\ni.e., mutual incoherence property or restricted isometry property, and the\nnoise level, the finite step global convergence of the algorithm is\nestablished. Extensive numerical examples are presented to illustrate the\nefficiency and accuracy of the algorithm and the convergence analysis. \n\n"}
{"id": "1403.1738", "contents": "Title: A Fast Active Set Block Coordinate Descent Algorithm for\n  $\\ell_1$-regularized least squares Abstract: The problem of finding sparse solutions to underdetermined systems of linear\nequations arises in several applications (e.g. signal and image processing,\ncompressive sensing, statistical inference). A standard tool for dealing with\nsparse recovery is the $\\ell_1$-regularized least-squares approach that has\nbeen recently attracting the attention of many researchers. In this paper, we\ndescribe an active set estimate (i.e. an estimate of the indices of the zero\nvariables in the optimal solution) for the considered problem that tries to\nquickly identify as many active variables as possible at a given point, while\nguaranteeing that some approximate optimality conditions are satisfied. A\nrelevant feature of the estimate is that it gives a significant reduction of\nthe objective function when setting to zero all those variables estimated\nactive. This enables to easily embed it into a given globally converging\nalgorithmic framework. In particular, we include our estimate into a block\ncoordinate descent algorithm for $\\ell_1$-regularized least squares, analyze\nthe convergence properties of this new active set method, and prove that its\nbasic version converges with linear rate. Finally, we report some numerical\nresults showing the effectiveness of the approach. \n\n"}
{"id": "1403.2543", "contents": "Title: Second-order asymptotics for source coding, dense coding and pure-state\n  entanglement conversions Abstract: We introduce two variants of the information spectrum relative entropy\ndefined by Tomamichel and Hayashi which have the particular advantage of\nsatisfying the data-processing inequality, i.e. monotonicity under quantum\noperations. This property allows us to obtain one-shot bounds for various\ninformation-processing tasks in terms of these quantities. Moreover, these\nrelative entropies have a second order asymptotic expansion, which in turn\nyields tight second order asymptotics for optimal rates of these tasks in the\ni.i.d. setting. The tasks studied in this paper are fixed-length quantum source\ncoding, noisy dense coding, entanglement concentration, pure-state entanglement\ndilution, and transmission of information through a classical-quantum channel.\nIn the latter case, we retrieve the second order asymptotics obtained by\nTomamichel and Tan. Our results also yield the known second order asymptotics\nof fixed-length classical source coding derived by Hayashi. The second order\nasymptotics of entanglement concentration and dilution provide a refinement of\nthe inefficiency of these protocols - a quantity which, in the case of\nentanglement dilution, was studied by Harrow and Lo. We prove how the\ndiscrepancy between the optimal rates of these two processes in the second\norder implies the irreversibility of entanglement concentration established by\nKumagai and Hayashi. In addition, the spectral divergence rates of the\nInformation Spectrum Approach (ISA) can be retrieved from our relative\nentropies in the asymptotic limit. This enables us to directly obtain the more\ngeneral results of the ISA from our one-shot bounds. \n\n"}
{"id": "1403.2580", "contents": "Title: Optimal Resource Allocation in Full-Duplex Wireless-Powered\n  Communication Network Abstract: This paper studies optimal resource allocation in the wireless-powered\ncommunication network (WPCN), where one hybrid access-point (H-AP) operating in\nfull-duplex (FD) broadcasts wireless energy to a set of distributed users in\nthe downlink (DL) and at the same time receives independent information from\nthe users via time-division-multiple-access (TDMA) in the uplink (UL). We\ndesign an efficient protocol to support simultaneous wireless energy transfer\n(WET) in the DL and wireless information transmission (WIT) in the UL for the\nproposed FD-WPCN. We jointly optimize the time allocations to the H-AP for DL\nWET and different users for UL WIT as well as the transmit power allocations\nover time at the H-AP to maximize the users' weighted sum-rate of UL\ninformation transmission with harvested energy. We consider both the cases with\nperfect and imperfect self-interference cancellation (SIC) at the H-AP, for\nwhich we obtain optimal and suboptimal time and power allocation solutions,\nrespectively. Furthermore, we consider the half-duplex (HD) WPCN as a baseline\nscheme and derive its optimal resource allocation solution. Simulation results\nshow that the FD-WPCN outperforms HD-WPCN when effective SIC can be implemented\nand more stringent peak power constraint is applied at the H-AP. \n\n"}
{"id": "1403.2779", "contents": "Title: Erasure codes with simplex locality Abstract: We focus on erasure codes for distributed storage. The distributed storage\nsetting imposes locality requirements because of easy repair demands on the\ndecoder. We first establish the characterization of various locality properties\nin terms of the generator matrix of the code. These lead to bounds on locality\nand notions of optimality. We then examine the locality properties of a family\nof non-binary codes with simplex structure. We investigate their optimality and\ndesign several easy repair decoding methods. In particular, we show that any\ncorrectable erasure pattern can be solved by easy repair. \n\n"}
{"id": "1403.3438", "contents": "Title: Neighborhood Selection for Thresholding-based Subspace Clustering Abstract: Subspace clustering refers to the problem of clustering high-dimensional data\npoints into a union of low-dimensional linear subspaces, where the number of\nsubspaces, their dimensions and orientations are all unknown. In this paper, we\npropose a variation of the recently introduced thresholding-based subspace\nclustering (TSC) algorithm, which applies spectral clustering to an adjacency\nmatrix constructed from the nearest neighbors of each data point with respect\nto the spherical distance measure. The new element resides in an individual and\ndata-driven choice of the number of nearest neighbors. Previous performance\nresults for TSC, as well as for other subspace clustering algorithms based on\nspectral clustering, come in terms of an intermediate performance measure,\nwhich does not address the clustering error directly. Our main analytical\ncontribution is a performance analysis of the modified TSC algorithm (as well\nas the original TSC algorithm) in terms of the clustering error directly. \n\n"}
{"id": "1403.4583", "contents": "Title: An Achievable rate region for the $3-$user interference channel based on\n  coset codes Abstract: We consider the problem of communication over a three user discrete\nmemoryless interference channel ($3-$IC). The current known coding techniques\nfor communicating over an arbitrary $3-$IC are based on message splitting,\nsuperposition coding and binning using independent and identically distributed\n(iid) random codebooks. In this work, we propose a new ensemble of codes -\npartitioned coset codes (PCC) - that possess an appropriate mix of empirical\nand algebraic closure properties. We develop coding techniques that exploit\nalgebraic closure property of PCC to enable efficient communication over\n$3-$IC. We analyze the performance of the proposed coding technique to derive\nan achievable rate region for the general discrete $3-$IC. Additive and\nnon-additive examples are identified for which the derived achievable rate\nregion is the capacity, and moreover, strictly larger than current known\nlargest achievable rate regions based on iid random codebooks. \n\n"}
{"id": "1403.5315", "contents": "Title: A Deterministic Annealing Optimization Approach for Witsenhausen's and\n  Related Decentralized Control Settings Abstract: This paper studies the problem of mapping optimization in decentralized\ncontrol problems. A global optimization algorithm is proposed based on the\nideas of ``deterministic annealing\" - a powerful non-convex optimization\nframework derived from information theoretic principles with analogies to\nstatistical physics. The key idea is to randomize the mappings and control the\nShannon entropy of the system during optimization. The entropy constraint is\ngradually relaxed in a deterministic annealing process while tracking the\nminimum, to obtain the ultimate deterministic mappings. Deterministic annealing\nhas been successfully employed in several problems including clustering, vector\nquantization, regression, as well as the Witsenhausen's counterexample in our\nrecent work[1]. We extend our method to a more involved setting, a variation of\nWitsenhausen's counterexample, where there is a side channel between the two\ncontrollers. The problem can be viewed as a two stage cancellation problem. We\ndemonstrate that there exist complex strategies that can exploit the side\nchannel efficiently, obtaining significant gains over the best affine and known\nnon-linear strategies. \n\n"}
{"id": "1403.5711", "contents": "Title: Large-Scale MIMO Detection for 3GPP LTE: Algorithms and FPGA\n  Implementations Abstract: Large-scale (or massive) multiple-input multiple-output (MIMO) is expected to\nbe one of the key technologies in next-generation multi-user cellular systems,\nbased on the upcoming 3GPP LTE Release 12 standard, for example. In this work,\nwe propose - to the best of our knowledge - the first VLSI design enabling\nhigh-throughput data detection in single-carrier frequency-division multiple\naccess (SC-FDMA)-based large-scale MIMO systems. We propose a new approximate\nmatrix inversion algorithm relying on a Neumann series expansion, which\nsubstantially reduces the complexity of linear data detection. We analyze the\nassociated error, and we compare its performance and complexity to those of an\nexact linear detector. We present corresponding VLSI architectures, which\nperform exact and approximate soft-output detection for large-scale MIMO\nsystems with various antenna/user configurations. Reference implementation\nresults for a Xilinx Virtex-7 XC7VX980T FPGA show that our designs are able to\nachieve more than 600 Mb/s for a 128 antenna, 8 user 3GPP LTE-based large-scale\nMIMO system. We finally provide a performance/complexity trade-off comparison\nusing the presented FPGA designs, which reveals that the detector circuit of\nchoice is determined by the ratio between BS antennas and users, as well as the\ndesired error-rate performance. \n\n"}
{"id": "1404.2796", "contents": "Title: Linear Batch Codes Abstract: In an application, where a client wants to obtain many elements from a large\ndatabase, it is often desirable to have some load balancing. Batch codes\n(introduced by Ishai et al. in STOC 2004) make it possible to do exactly that:\nthe large database is divided between many servers, so that the client has to\nonly make a small number of queries to every server to obtain sufficient\ninformation to reconstruct all desired elements. Other important parameters of\nthe batch codes are total storage and the number of servers. Batch codes also\nhave applications in cryptography (namely, in the construction of multi-query\ncomputationally-private information retrieval protocols).\n  In this work, we initiate the study of linear batch codes. These codes, in\nparticular, are of potential use in distributed storage systems. We show that a\ngenerator matrix of a binary linear batch code is also a generator matrix of\nclassical binary linear error-correcting code. This immediately yields that a\nvariety of upper bounds, which were developed for error-correcting codes, are\napplicable also to binary linear batch codes. We also propose new methods to\nconstruct large linear batch codes from the smaller ones. \n\n"}
{"id": "1404.2825", "contents": "Title: Asymptotics of Fingerprinting and Group Testing: Capacity-Achieving\n  Log-Likelihood Decoders Abstract: We study the large-coalition asymptotics of fingerprinting and group testing,\nand derive explicit decoders that provably achieve capacity for many of the\nconsidered models. We do this both for simple decoders (fast but suboptimal)\nand for joint decoders (slow but optimal), and both for informed and uninformed\nsettings.\n  For fingerprinting, we show that if the pirate strategy is known, the\nNeyman-Pearson-based log-likelihood decoders provably achieve capacity,\nregardless of the strategy. The decoder built against the interleaving attack\nis further shown to be a universal decoder, able to deal with arbitrary attacks\nand achieving the uninformed capacity. This universal decoder is shown to be\nclosely related to the Lagrange-optimized decoder of Oosterwijk et al. and the\nempirical mutual information decoder of Moulin. Joint decoders are also\nproposed, and we conjecture that these also achieve the corresponding joint\ncapacities.\n  For group testing, the simple decoder for the classical model is shown to be\nmore efficient than the one of Chan et al. and it provably achieves the simple\ngroup testing capacity. For generalizations of this model such as noisy group\ntesting, the resulting simple decoders also achieve the corresponding simple\ncapacities. \n\n"}
{"id": "1404.2904", "contents": "Title: Construction A of Lattices over Number Fields and Block Fading Wiretap\n  Coding Abstract: We propose a lattice construction from totally real and CM fields, which\nnaturally generalizes the Construction A of lattices from $p$-ary codes\nobtained from the cyclotomic field $\\mathbb{Q}(\\zeta_p)$, $p$ a prime, which in\nturn contains the so-called Construction A of lattices from binary codes as a\nparticular case. We focus on the maximal totally real subfield\n$\\mathbb{Q}(\\zeta_{p^r}+\\zeta_{p}^{-r})$ of the cyclotomic field\n$\\mathbb{Q}(\\zeta_{p^r})$, $r\\geq 1$. Our construction has applications to\ncoset encoding of algebraic lattice codes, and we detail the case of coset\nencoding of block fading wiretap codes. \n\n"}
{"id": "1404.4761", "contents": "Title: Using Network Coding to Achieve the Capacity of Deterministic Relay\n  Networks with Relay Messages Abstract: In this paper, we derive the capacity of the deterministic relay networks\nwith relay messages. We consider a network which consists of five nodes, four\nof which can only communicate via the fifth one. However, the fifth node is not\nmerely a relay as it may exchange private messages with the other network\nnodes. First, we develop an upper bound on the capacity region based on the\nnotion of a single sided genie. In the course of the achievability proof, we\nalso derive the deterministic capacity of a 4-user relay network (without\nprivate messages at the relay). The capacity achieving schemes use a\ncombination of two network coding techniques: the Simple Ordering Scheme (SOS)\nand Detour Schemes (DS). In the SOS, we order the transmitted bits at each user\nsuch that the bi-directional messages will be received at the same channel\nlevel at the relay, while the basic idea behind the DS is that some parts of\nthe message follow an indirect path to their respective destinations. This\npaper, therefore, serves to show that user cooperation and network coding can\nenhance throughput, even when the users are not directly connected to each\nother. \n\n"}
{"id": "1404.4927", "contents": "Title: On the Number of Iterations for Convergence of CoSaMP and Subspace\n  Pursuit Algorithms Abstract: In compressive sensing, one important parameter that characterizes the\nvarious greedy recovery algorithms is the iteration bound which provides the\nmaximum number of iterations by which the algorithm is guaranteed to converge.\nIn this letter, we present a new iteration bound for CoSaMP by certain\nmathematical manipulations including formulation of appropriate sufficient\nconditions that ensure passage of a chosen support through the two selection\nstages of CoSaMP, Augment and Update. Subsequently, we extend the treatment to\nthe subspace pursuit (SP) algorithm. The proposed iteration bounds for both\nCoSaMP and SP algorithms are seen to be improvements over their existing\ncounterparts, revealing that both CoSaMP and SP algorithms converge in fewer\niterations than suggested by results available in literature. \n\n"}
{"id": "1404.5683", "contents": "Title: The Likelihood Encoder for Lossy Source Compression Abstract: In this work, a likelihood encoder is studied in the context of lossy source\ncompression. The analysis of the likelihood encoder is based on a soft-covering\nlemma. It is demonstrated that the use of a likelihood encoder together with\nthe soft-covering lemma gives alternative achievability proofs for classical\nsource coding problems. The case of the rate-distortion function with side\ninformation at the decoder (i.e. the Wyner-Ziv problem) is carefully examined\nand an application of the likelihood encoder to the multi-terminal source\ncoding inner bound (i.e. the Berger-Tung region) is outlined. \n\n"}
{"id": "1404.6185", "contents": "Title: Observation of $D^0$ meson nuclear modifications in Au+Au collisions at\n  $\\sqrt{s_{_{\\mathrm{NN}}}}$ = 200 GeV Abstract: We report the first measurement of charmed-hadron ($D^0$) production via the\nhadronic decay channel ($D^0\\rightarrow K^- + \\pi^+$) in Au+Au collisions at\n$\\sqrt{s_{_{\\mathrm{NN}}}}$ = 200\\,GeV with the STAR experiment. The charm\nproduction cross-section per nucleon-nucleon collision at mid-rapidity scales\nwith the number of binary collisions, $N_{bin}$, from $p$+$p$ to central Au+Au\ncollisions. The $D^0$ meson yields in central Au+Au collisions are strongly\nsuppressed compared to those in $p$+$p$ scaled by $N_{bin}$, for transverse\nmomenta $p_{T}>3$ GeV/$c$, demonstrating significant energy loss of charm\nquarks in the hot and dense medium. An enhancement at intermediate $p_{T}$ is\nalso observed. Model calculations including strong charm-medium interactions\nand coalescence hadronization describe our measurements. \n\n"}
{"id": "1404.6563", "contents": "Title: Coded Caching for Multi-level Popularity and Access Abstract: To address the exponentially rising demand for wireless content, use of\ncaching is emerging as a potential solution. It has been recently established\nthat joint design of content delivery and storage (coded caching) can\nsignificantly improve performance over conventional caching. Coded caching is\nwell suited to emerging heterogeneous wireless architectures which consist of a\ndense deployment of local-coverage wireless access points (APs) with high data\nrates, along with sparsely-distributed, large-coverage macro-cell base stations\n(BS). This enables design of coded caching-and-delivery schemes that equip APs\nwith storage, and place content in them in a way that creates coded-multicast\nopportunities for combining with macro-cell broadcast to satisfy users even\nwith different demands. Such coded-caching schemes have been shown to be\norder-optimal with respect to the BS transmission rate, for a system with\nsingle-level content, i.e., one where all content is uniformly popular. In this\nwork, we consider a system with non-uniform popularity content which is divided\ninto multiple levels, based on varying degrees of popularity. The main\ncontribution of this work is the derivation of an order-optimal scheme which\njudiciously shares cache memory among files with different popularities. To\nshow order-optimality we derive new information-theoretic lower bounds, which\nuse a sliding-window entropy inequality, effectively creating a non-cutset\nbound. We also extend the ideas to when users can access multiple caches along\nwith the broadcast. Finally we consider two extreme cases of user distribution\nacross caches for the multi-level popularity model: a single user per cache\n(single-user setup) versus a large number of users per cache (multi-user\nsetup), and demonstrate a dichotomy in the order-optimal strategies for these\ntwo extreme cases. \n\n"}
{"id": "1404.7041", "contents": "Title: Super-resolution Line Spectrum Estimation with Block Priors Abstract: We address the problem of super-resolution line spectrum estimation of an\nundersampled signal with block prior information. The component frequencies of\nthe signal are assumed to take arbitrary continuous values in known frequency\nblocks. We formulate a general semidefinite program to recover these\ncontinuous-valued frequencies using theories of positive trigonometric\npolynomials. The proposed semidefinite program achieves super-resolution\nfrequency recovery by taking advantage of known structures of frequency blocks.\nNumerical experiments show great performance enhancements using our method. \n\n"}
{"id": "1404.7399", "contents": "Title: Testing the Ge detectors for the MAJORANA DEMONSTRATOR Abstract: High purity germanium (HPGe) crystals will be used for the MAJORANA\nDEMONSTRATOR, where they serve as both the source and the detector for\nneutrinoless double beta decay. It is crucial for the experiment to understand\nthe performance of the HPGe crystals. A variety of crystal properties are being\ninvestigated, including basic properties such as energy resolution, efficiency,\nuniformity, capacitance, leakage current and crystal axis orientation, as well\nas more sophisticated properties, e.g. pulse shapes and dead layer and\ntransition layer distributions. In this paper, we will present our measurements\nthat characterize the HPGe crystals. We will also discuss our simulation\npackage for the detector characterization setup, and show that additional\ninformation can be extracted from data-simulation comparisons. \n\n"}
{"id": "1404.7478", "contents": "Title: Secure Degrees of Freedom Regions of Multiple Access and Interference\n  Channels: The Polytope Structure Abstract: The sum secure degrees of freedom (s.d.o.f.) of two fundamental multi-user\nnetwork structures, the K-user Gaussian multiple access (MAC) wiretap channel\nand the K-user interference channel (IC) with secrecy constraints, have been\ndetermined recently as K(K-1)/(K(K-1)+1) [1,2] and K(K-1)/(2K-1) [3,4],\nrespectively. In this paper, we determine the entire s.d.o.f. regions of these\ntwo channel models. The converse for the MAC follows from a middle step in the\nconverse of [1,2]. The converse for the IC includes constraints both due to\nsecrecy as well as due to interference. Although the portion of the region\nclose to the optimum sum s.d.o.f. point is governed by the upper bounds due to\nsecrecy constraints, the other portions of the region are governed by the upper\nbounds due to interference constraints. Different from the existing literature,\nin order to fully understand the characterization of the s.d.o.f. region of the\nIC, one has to study the 4-user case, i.e., the 2 or 3-user cases do not\nillustrate the generality of the problem. In order to prove the achievability,\nwe use the polytope structure of the converse region. In both MAC and IC cases,\nwe develop explicit schemes that achieve the extreme points of the polytope\nregion given by the converse. Specifically, the extreme points of the MAC\nregion are achieved by an m-user MAC wiretap channel with (K-m) helpers, i.e.,\nby setting (K-m) users' secure rates to zero and utilizing them as pure\n(structured) cooperative jammers. The extreme points of the IC region are\nachieved by a (K-m)-user IC with confidential messages, m helpers, and N\nexternal eavesdroppers, for m>=1 and a finite N. A byproduct of our results in\nthis paper is that the sum s.d.o.f. is achieved only at one extreme point of\nthe s.d.o.f. region, which is the symmetric-rate extreme point, for both MAC\nand IC channel models. \n\n"}
{"id": "1405.0086", "contents": "Title: Medically Relevant Criteria used in EEG Compression for Improved\n  Post-Compression Seizure Detection Abstract: Biomedical signals aid in the diagnosis of different disorders and\nabnormalities. When targeting lossy compression of such signals, the medically\nrelevant information that lies within the data should maintain its accuracy and\nthus its reliability. In fact, signal models that are inspired by the\nbio-physical properties of the signals at hand allow for a compression that\npreserves more naturally the clinically significant features of these signals.\nIn this paper, we illustrate this through the example of EEG signals; more\nspecifically, we analyze three specific lossy EEG compression schemes. These\nschemes are based on signal models that have different degrees of reliance on\nsignal production and physiological characteristics of EEG. The resilience of\nthese schemes is illustrated through the performance of seizure detection post\ncompression. \n\n"}
{"id": "1405.1004", "contents": "Title: Model Consistency of Partly Smooth Regularizers Abstract: This paper studies least-square regression penalized with partly smooth\nconvex regularizers. This class of functions is very large and versatile\nallowing to promote solutions conforming to some notion of low-complexity.\nIndeed, they force solutions of variational problems to belong to a\nlow-dimensional manifold (the so-called model) which is stable under small\nperturbations of the function. This property is crucial to make the underlying\nlow-complexity model robust to small noise. We show that a generalized\n\"irrepresentable condition\" implies stable model selection under small noise\nperturbations in the observations and the design matrix, when the\nregularization parameter is tuned proportionally to the noise level. This\ncondition is shown to be almost a necessary condition. We then show that this\ncondition implies model consistency of the regularized estimator. That is, with\na probability tending to one as the number of measurements increases, the\nregularized estimator belongs to the correct low-dimensional model manifold.\nThis work unifies and generalizes several previous ones, where model\nconsistency is known to hold for sparse, group sparse, total variation and\nlow-rank regularizations. \n\n"}
{"id": "1405.1194", "contents": "Title: Quantization and Compressive Sensing Abstract: Quantization is an essential step in digitizing signals, and, therefore, an\nindispensable component of any modern acquisition system. This book chapter\nexplores the interaction of quantization and compressive sensing and examines\npractical quantization strategies for compressive acquisition systems.\nSpecifically, we first provide a brief overview of quantization and examine\nfundamental performance bounds applicable to any quantization approach. Next,\nwe consider several forms of scalar quantizers, namely uniform, non-uniform,\nand 1-bit. We provide performance bounds and fundamental analysis, as well as\npractical quantizer designs and reconstruction algorithms that account for\nquantization. Furthermore, we provide an overview of Sigma-Delta\n($\\Sigma\\Delta$) quantization in the compressed sensing context, and also\ndiscuss implementation issues, recovery algorithms and performance bounds. As\nwe demonstrate, proper accounting for quantization and careful quantizer design\nhas significant impact in the performance of a compressive acquisition system. \n\n"}
{"id": "1405.1797", "contents": "Title: On the Second-Order Asymptotics for Entanglement-Assisted Communication Abstract: The entanglement-assisted classical capacity of a quantum channel is known to\nprovide the formal quantum generalization of Shannon's classical channel\ncapacity theorem, in the sense that it admits a single-letter characterization\nin terms of the quantum mutual information and does not increase in the\npresence of a noiseless quantum feedback channel from receiver to sender. In\nthis work, we investigate second-order asymptotics of the entanglement-assisted\nclassical communication task. That is, we consider how quickly the rates of\nentanglement-assisted codes converge to the entanglement-assisted classical\ncapacity of a channel as a function of the number of channel uses and the error\ntolerance. We define a quantum generalization of the mutual information\nvariance of a channel in the entanglement-assisted setting. For covariant\nchannels, we show that this quantity is equal to the channel dispersion, and\nthus completely characterize the convergence towards the entanglement-assisted\nclassical capacity when the number of channel uses increases. Our results also\napply to entanglement-assisted quantum communication, due to the equivalence\nbetween entanglement-assisted classical and quantum communication established\nby the teleportation and super-dense coding protocols. \n\n"}
{"id": "1405.2113", "contents": "Title: Empirical Bayes and Full Bayes for Signal Estimation Abstract: We consider signals that follow a parametric distribution where the parameter\nvalues are unknown. To estimate such signals from noisy measurements in scalar\nchannels, we study the empirical performance of an empirical Bayes (EB)\napproach and a full Bayes (FB) approach. We then apply EB and FB to solve\ncompressed sensing (CS) signal estimation problems by successively denoising a\nscalar Gaussian channel within an approximate message passing (AMP) framework.\nOur numerical results show that FB achieves better performance than EB in\nscalar channel denoising problems when the signal dimension is small. In the CS\nsetting, the signal dimension must be large enough for AMP to work well; for\nlarge signal dimensions, AMP has similar performance with FB and EB. \n\n"}
{"id": "1405.2524", "contents": "Title: Spatial Coupling of Generator Matrix: A General Approach to Design of\n  Good Codes at a Target BER Abstract: For any given short code (referred to as the basic code), block Markov\nsuperposition transmission (BMST) provides a simple way to obtain predictable\nextra coding gain by spatial coupling the generator matrix of the basic code.\nThis paper presents a systematic design methodology for BMST systems to\napproach the channel capacity at any given target bit-error-rate (BER) of\ninterest. To simplify the design, we choose the basic code as the Cartesian\nproduct of a short block code. The encoding memory is then inferred from the\ngenie-aided lower bound according to the performance gap of the short block\ncode to the corresponding Shannon limit at the target BER. In addition to the\nsliding-window decoding algorithm, we propose to perform one more phase\ndecoding to remove residual (rare) errors. A new technique that assumes a noisy\ngenie is proposed to upper bound the performance. Under some mild assumptions,\nthese genie-aided bounds can be used to predict the performance of the proposed\ntwo-phase decoding algorithm in the extremely low BER region. Using the\nCartesian product of a repetition code as the basic code, we construct a BMST\nsystem with an encoding memory 30 whose performance at the BER of $10^{-15}$\ncan be predicted within one dB away from the Shannon limit over the\nbinary-input additive white Gaussian noise channel (BI-AWGNC). \n\n"}
{"id": "1405.2668", "contents": "Title: Charge separation with fluctuating domains in relativistic heavy-ion\n  collisions Abstract: Charge separation induced by the chiral magnetic effect suggested that some\n${\\cal P}$- or ${\\cal CP}$-odd metastable domains could be produced in a QCD\nvacuum in the early stage of relativistic heavy-ion collisions. Based on a\nmulti-phase transport model, our results suggest that a domain-based scenario\nwith final state interactions can describe the solenoidal tracker at RHIC\ndetector (STAR) measurements of both same- and opposite-charge azimuthal angle\ncorrelations, $<\\cos(\\phi_{\\alpha}+\\phi_{\\beta})>$, in Au+Au collisions at\n$\\sqrt{s_{_{\\rm NN}}}=200$ GeV. The occupancy factor of the total volume of\ndomains over the fireball volume is small, which indicates that the size and\nnumber of metastable domains should be relatively small in the early stage of a\nquark-gluon plasma. \n\n"}
{"id": "1405.3263", "contents": "Title: Scalable sparse covariance estimation via self-concordance Abstract: We consider the class of convex minimization problems, composed of a\nself-concordant function, such as the $\\log\\det$ metric, a convex data fidelity\nterm $h(\\cdot)$ and, a regularizing -- possibly non-smooth -- function\n$g(\\cdot)$. This type of problems have recently attracted a great deal of\ninterest, mainly due to their omnipresence in top-notch applications. Under\nthis \\emph{locally} Lipschitz continuous gradient setting, we analyze the\nconvergence behavior of proximal Newton schemes with the added twist of a\nprobable presence of inexact evaluations. We prove attractive convergence rate\nguarantees and enhance state-of-the-art optimization schemes to accommodate\nsuch developments. Experimental results on sparse covariance estimation show\nthe merits of our algorithm, both in terms of recovery efficiency and\ncomplexity. \n\n"}
{"id": "1405.4345", "contents": "Title: Wiener Filters in Gaussian Mixture Signal Estimation with Infinity-Norm\n  Error Abstract: Consider the estimation of a signal ${\\bf x}\\in\\mathbb{R}^N$ from noisy\nobservations ${\\bf r=x+z}$, where the input~${\\bf x}$ is generated by an\nindependent and identically distributed (i.i.d.) Gaussian mixture source, and\n${\\bf z}$ is additive white Gaussian noise (AWGN) in parallel Gaussian\nchannels. Typically, the $\\ell_2$-norm error (squared error) is used to\nquantify the performance of the estimation process. In contrast, we consider\nthe $\\ell_\\infty$-norm error (worst case error). For this error metric, we\nprove that, in an asymptotic setting where the signal dimension $N\\to\\infty$,\nthe $\\ell_\\infty$-norm error always comes from the Gaussian component that has\nthe largest variance, and the Wiener filter asymptotically achieves the optimal\nexpected $\\ell_\\infty$-norm error. The i.i.d. Gaussian mixture case is easily\napplicable to i.i.d. Bernoulli-Gaussian distributions, which are often used to\nmodel sparse signals. Finally, our results can be extended to linear mixing\nsystems with i.i.d. Gaussian mixture inputs, in settings where a linear mixing\nsystem can be decoupled to parallel Gaussian channels. \n\n"}
{"id": "1405.4395", "contents": "Title: User-Centric Intercell Interference Nulling for Downlink Small Cell\n  Networks Abstract: Small cell networks are regarded as a promising candidate to meet the\nexponential growth of mobile data traffic in cellular networks. With a dense\ndeployment of access points, spatial reuse will be improved, and uniform\ncoverage can be provided. However, such performance gains cannot be achieved\nwithout effective intercell interference management. In this paper, a novel\ninterference coordination strategy, called user-centric intercell interference\nnulling, is proposed for small cell networks. A main merit of the proposed\nstrategy is its ability to effectively identify and mitigate the dominant\ninterference for each user. Different from existing works, each user selects\nthe coordinating base stations (BSs) based on the relative distance between the\nhome BS and the interfering BSs, called the interference nulling (IN) range,\nand thus interference nulling adapts to each user's own interference situation.\nBy adopting a random spatial network model, we derive an approximate expression\nof the successful transmission probability to the typical user, which is then\nused to determine the optimal IN range. Simulation results shall confirm the\ntightness of the approximation, and demonstrate significant performance gains\n(about 35%-40%) of the proposed coordination strategy, compared with the\nnon-coordination case. Moreover, it is shown that the proposed strategy\noutperforms other interference nulling methods. Finally, the effect of\nimperfect channel state information (CSI) is investigated, where CSI is assumed\nto be obtained via limited feedback. It is shown that the proposed coordination\nstrategy still provides significant performance gains even with a moderate\nnumber of feedback bits. \n\n"}
{"id": "1405.5059", "contents": "Title: Sivers Effect in Dihadron Semi-Inclusive Deep Inelastic Scattering Abstract: The Sivers effect describes the correlation of the unpolarized parton's\ntransverse momentum with the transverse spin of the nucleon. It manifests as a\nsine modulation of the cross section for single hadron semi-inclusive deep\ninelastic scattering (SIDIS) on a transversely polarized nucleon with the\nazimuthal angle between the produced hadron's transverse momentum and the\nnucleon spin ($\\varphi_h$ and $\\varphi_S$, respectively). It has been recently\nsuggested that the Sivers effect can also be measured in two hadron SIDIS\nprocess as sine modulations involving the azimuthal angles $\\varphi_T$ and\n$\\varphi_R$ of both the total and the relative transverse momenta of the hadron\npair. Here we present the detailed derivation of the two hadron SIDIS cross\nsection using simple parton-model inspired functional forms for both the parton\ndistribution and the fragmentation functions. We show explicitly that the terms\ncorresponding to the $\\sin(\\varphi_R-\\varphi_S)$ and\n$\\sin(\\varphi_T-\\varphi_S)$ modulations are non-zero. Further, we derive the\ncross section expressions for single hadron production in the two hadron\nsample. Finally, we employ a modified version of the $\\tt{LEPTO}$ Monte Carlo\nevent generator that includes the Sivers effect to estimate the size of single\nspin asymmetries corresponding to these modulations independent of the\nformalism developed. \n\n"}
{"id": "1406.1055", "contents": "Title: Lattice Codes for the Binary Deletion Channel Abstract: The construction of deletion codes for the Levenshtein metric is reduced to\nthe construction of codes over the integers for the Manhattan metric by run\nlength coding. The latter codes are constructed by expurgation of translates of\nlattices. These lattices, in turn, are obtained from Construction~A applied to\nbinary codes and $\\Z_4-$codes. A lower bound on the size of our codes for the\nManhattan distance are obtained through generalized theta series of the\ncorresponding lattices. \n\n"}
{"id": "1406.1725", "contents": "Title: Bi-level Protected Compressive Sampling Abstract: Some pioneering works have investigated embedding cryptographic properties in\ncompressive sampling (CS) in a way similar to one-time pad symmetric cipher.\nThis paper tackles the problem of constructing a CS-based symmetric cipher\nunder the key reuse circumstance, i.e., the cipher is resistant to common\nattacks even a fixed measurement matrix is used multiple times. To this end, we\nsuggest a bi-level protected CS (BLP-CS) model which makes use of the advantage\nof the non-RIP measurement matrix construction. Specifically, two kinds of\nartificial basis mismatch techniques are investigated to construct key-related\nsparsifying bases. It is demonstrated that the encoding process of BLP-CS is\nsimply a random linear projection, which is the same as the basic CS model.\nHowever, decoding the linear measurements requires knowledge of both the\nkey-dependent sensing matrix and its sparsifying basis. The proposed model is\nexemplified by sampling images as a joint data acquisition and protection layer\nfor resource-limited wireless sensors. Simulation results and numerical\nanalyses have justified that the new model can be applied in circumstances\nwhere the measurement matrix can be re-used. \n\n"}
{"id": "1406.1867", "contents": "Title: Energy Efficiency of Cross-Tier Base Station Cooperation in\n  Heterogeneous Cellular Networks Abstract: Heterogeneous cellular networks (HetNets) are to be deployed for future\nwireless communication to meet the ever-increasing mobile traffic demand.\nHowever, the dense and random deployment of small cells and their uncoordinated\noperation raise important concerns about energy efficiency. Base station (BS)\ncooperation is set to play a key role in managing interference in the HetNets.\nIn this paper, we consider BS cooperation in the downlink HetNets where BSs\nfrom different tiers within the respective cooperative clusters jointly\ntransmit the same data to a typical user, and further optimize the energy\nefficiency performance. First, based on the proposed clustering model, we\nderive the spatial average rate using tools from stochastic geometry.\nFurthermore, we formulate a power minimization problem with a minimum spatial\naverage rate constraint and derive an approximate result of the optimal\nreceived signal strength (RSS) thresholds. Building upon these results, we\neffectively address the problem of how to design appropriate RSS thresholds,\ntaking into account the trade-off between spatial average rate and energy\nefficiency. Simulations show that our proposed clustering model is more\nenergy-saving than the geometric clustering model, and under our proposed\nclustering model, deploying a two-tier HetNet is significantly more\nenergy-saving compared to a macro-only network. \n\n"}
{"id": "1406.2721", "contents": "Title: Learning Latent Variable Gaussian Graphical Models Abstract: Gaussian graphical models (GGM) have been widely used in many\nhigh-dimensional applications ranging from biological and financial data to\nrecommender systems. Sparsity in GGM plays a central role both statistically\nand computationally. Unfortunately, real-world data often does not fit well to\nsparse graphical models. In this paper, we focus on a family of latent variable\nGaussian graphical models (LVGGM), where the model is conditionally sparse\ngiven latent variables, but marginally non-sparse. In LVGGM, the inverse\ncovariance matrix has a low-rank plus sparse structure, and can be learned in a\nregularized maximum likelihood framework. We derive novel parameter estimation\nerror bounds for LVGGM under mild conditions in the high-dimensional setting.\nThese results complement the existing theory on the structural learning, and\nopen up new possibilities of using LVGGM for statistical inference. \n\n"}
{"id": "1406.6956", "contents": "Title: Minimax Estimation of Functionals of Discrete Distributions Abstract: We propose a general methodology for the construction and analysis of minimax\nestimators for a wide class of functionals of finite dimensional parameters,\nand elaborate on the case of discrete distributions, where the alphabet size\n$S$ is unknown and may be comparable with the number of observations $n$. We\ntreat the respective regions where the functional is \"nonsmooth\" and \"smooth\"\nseparately. In the \"nonsmooth\" regime, we apply an unbiased estimator for the\nbest polynomial approximation of the functional whereas, in the \"smooth\"\nregime, we apply a bias-corrected Maximum Likelihood Estimator (MLE). We\nillustrate the merit of this approach by thoroughly analyzing two important\ncases: the entropy $H(P) = \\sum_{i = 1}^S -p_i \\ln p_i$ and $F_\\alpha(P) =\n\\sum_{i = 1}^S p_i^\\alpha,\\alpha>0$. We obtain the minimax $L_2$ rates for\nestimating these functionals. In particular, we demonstrate that our estimator\nachieves the optimal sample complexity $n \\asymp S/\\ln S$ for entropy\nestimation. We also show that the sample complexity for estimating\n$F_\\alpha(P),0<\\alpha<1$ is $n\\asymp S^{1/\\alpha}/ \\ln S$, which can be\nachieved by our estimator but not the MLE. For $1<\\alpha<3/2$, we show the\nminimax $L_2$ rate for estimating $F_\\alpha(P)$ is $(n\\ln n)^{-2(\\alpha-1)}$\nregardless of the alphabet size, while the $L_2$ rate for the MLE is\n$n^{-2(\\alpha-1)}$. For all the above cases, the behavior of the minimax\nrate-optimal estimators with $n$ samples is essentially that of the MLE with\n$n\\ln n$ samples. We highlight the practical advantages of our schemes for\nentropy and mutual information estimation. We demonstrate that our approach\nreduces running time and boosts the accuracy compared to existing various\napproaches. Moreover, we show that the mutual information estimator induced by\nour methodology leads to significant performance boosts over the Chow--Liu\nalgorithm in learning graphical models. \n\n"}
{"id": "1407.0474", "contents": "Title: Recent Advances in Joint Wireless Energy and Information Transfer Abstract: In this paper, we provide an overview of the recent advances in\nmicrowave-enabled wireless energy transfer (WET) technologies and their\napplications in wireless communications. Specifically, we divide our\ndiscussions into three parts. First, we introduce the state-of-the-art WET\ntechnologies and the signal processing techniques to maximize the energy\ntransfer efficiency. Then, we discuss an interesting paradigm named\nsimultaneous wireless information and power transfer (SWIPT), where energy and\ninformation are jointly transmitted using the same radio waveform. At last, we\nreview the recent progress in wireless powered communication networks (WPCN),\nwhere wireless devices communicate using the power harvested by means of WET.\nExtensions and future directions are also discussed in each of these areas. \n\n"}
{"id": "1407.1424", "contents": "Title: Cross Layer Provision of Future Cellular Networks Abstract: To cope with the growing demand for wireless data and to extend service\ncoverage, future 5G networks will increasingly rely on the use of low powered\nnodes to support massive connectivity in diverse set of applications and\nservices [1]. To this end, virtualized and mass-scale cloud architectures are\nproposed as promising technologies for 5G in which all the nodes are connected\nvia a backhaul network and managed centrally by such cloud centers. The\nsignificant computing power made available by the cloud technologies has\nenabled the implementation of sophisticated signal processing algorithms,\nespecially by way of parallel processing, for both interference management and\nnetwork provision. The latter two are among the major signal processing tasks\nfor 5G due to increased level of frequency sharing, node density, interference\nand network congestion. This article outlines several theoretical and practical\naspects of joint interference management and network provisioning for future 5G\nnetworks. A cross-layer optimization framework is proposed for joint user\nadmission, user-base station association, power control, user grouping,\ntransceiver design as well as routing and flow control. We show that many of\nthese cross-layer tasks can be treated in a unified way and implemented in a\nparallel manner using an efficient algorithmic framework called WMMSE (Weighted\nMMSE). Some recent developments in this area are highlighted and future\nresearch directions are identified. \n\n"}
{"id": "1407.1487", "contents": "Title: Precoder Index Modulation Abstract: Index modulation, where information bits are conveyed through antenna indices\n(spatial modulation) and subcarrier indices (subcarrier index modulation) in\naddition to information bits conveyed through conventional modulation symbols,\nis getting increased research attention. In this paper, we introduce {\\em\nprecoder index modulation}, where information bits are conveyed through the\nchoice of a precoder matrix at the transmitter from a set of pre-determined\npseudo-random phase precoder (PRPP) matrices. Combining precoder index\nmodulation (PIM) and spatial modulation (SM), we introduce a PIM-SM scheme\nwhich conveys information bits through both antenna index as well as precoder\nindex. Spectral efficiency (in bits per channel use) and bit error performance\nof these index modulation schemes are presented. \n\n"}
{"id": "1407.1556", "contents": "Title: Energy Efficiency and Spectral Efficiency Tradeoff in Device-to-Device\n  (D2D) Communications Abstract: In this letter, we investigate the tradeoff between energy efficiency (EE)\nand spectral efficiency (SE) in device-to-device (D2D) communications\nunderlaying cellular networks with uplink channel reuse. The resource\nallocation problem is modeled as a noncooperative game, in which each user\nequipment (UE) is self-interested and wants to maximize its own EE. Given the\nSE requirement and maximum transmission power constraints, a distributed\nenergy-efficient resource allocation algorithm is proposed by exploiting the\nproperties of the nonlinear fractional programming. The relationships between\nthe EE and SE tradeoff of the proposed algorithm and system parameters are\nanalyzed and verified through computer simulations. \n\n"}
{"id": "1407.3567", "contents": "Title: Two approaches to obtain the strong converse exponent of quantum\n  hypothesis testing for general sequences of quantum states Abstract: We present two general approaches to obtain the strong converse rate of\nquantum hypothesis testing for correlated quantum states. One approach requires\nthat the states satisfy a certain factorization property; typical examples of\nsuch states are the temperature states of translation-invariant finite-range\ninteractions on a spin chain. The other approach requires the differentiability\nof a regularized R\\'enyi $\\alpha$-divergence in the parameter $\\alpha$; typical\nexamples of such states include temperature states of non-interacting fermionic\nlattice systems, and classical irreducible Markov chains. In all cases, we get\nthat the strong converse exponent is equal to the Hoeffding anti-divergence,\nwhich in turn is obtained from the regularized R\\'enyi divergences of the two\nstates. \n\n"}
{"id": "1407.5158", "contents": "Title: Tight convex relaxations for sparse matrix factorization Abstract: Based on a new atomic norm, we propose a new convex formulation for sparse\nmatrix factorization problems in which the number of nonzero elements of the\nfactors is assumed fixed and known. The formulation counts sparse PCA with\nmultiple factors, subspace clustering and low-rank sparse bilinear regression\nas potential applications. We compute slow rates and an upper bound on the\nstatistical dimension of the suggested norm for rank 1 matrices, showing that\nits statistical dimension is an order of magnitude smaller than the usual\n$\\ell\\_1$-norm, trace norm and their combinations. Even though our convex\nformulation is in theory hard and does not lead to provably polynomial time\nalgorithmic schemes, we propose an active set algorithm leveraging the\nstructure of the convex problem to solve it and show promising numerical\nresults. \n\n"}
{"id": "1407.5305", "contents": "Title: The dynamics of the leverage cycle Abstract: We present a simple agent-based model of a financial system composed of\nleveraged investors such as banks that invest in stocks and manage their risk\nusing a Value-at-Risk constraint, based on historical observations of asset\nprices. The Value-at-Risk constraint implies that when perceived risk is low,\nleverage is high and vice versa, a phenomenon that has been dubbed pro-cyclical\nleverage. We show that this leads to endogenous irregular oscillations, in\nwhich gradual increases in stock prices and leverage are followed by drastic\nmarket collapses, i.e. a leverage cycle. This phenomenon is studied using\nsimplified models that give a deeper understanding of the dynamics and the\nnature of the feedback loops and instabilities underlying the leverage cycle.\nWe introduce a flexible leverage regulation policy in which it is possible to\ncontinuously tune from pro-cyclical to countercyclical leverage. When the\npolicy is sufficiently countercyclical and bank risk is sufficiently low the\nendogenous oscillation disappears and prices go to a fixed point. While there\nis always a leverage ceiling above which the dynamics are unstable,\ncountercyclical leverage can be used to raise the ceiling. We also study the\nimpact on leverage cycles of direct, temporal control of the bank's riskiness\nvia the bank's required Value-at-Risk quantile. Under such a rule the regulator\nrelaxes the Value-at-Risk quantile following a negative stock price shock and\ntightens it following a positive shock. While such a policy rule can reduce the\namplitude of leverage cycles, its effectiveness is highly dependent on the\nchoice of parameters. Finally, we investigate fixed limits on leverage and show\nhow they can control the leverage cycle. \n\n"}
{"id": "1407.6288", "contents": "Title: Subspace Learning From Bits Abstract: Networked sensing, where the goal is to perform complex inference using a\nlarge number of inexpensive and decentralized sensors, has become an\nincreasingly attractive research topic due to its applications in wireless\nsensor networks and internet-of-things. To reduce the communication, sensing\nand storage complexity, this paper proposes a simple sensing and estimation\nframework to faithfully recover the principal subspace of high-dimensional data\nstreams using a collection of binary measurements from distributed sensors,\nwithout transmitting the whole data. The binary measurements are designed to\nindicate comparison outcomes of aggregated energy projections of the data\nsamples over pairs of randomly selected directions. When the covariance matrix\nis a low-rank matrix, we propose a spectral estimator that recovers the\nprincipal subspace of the covariance matrix as the subspace spanned by the top\neigenvectors of a properly designed surrogate matrix, which is provably\naccurate as soon as the number of binary measurements is sufficiently large. An\nadaptive rank selection strategy based on soft thresholding is also presented.\nFurthermore, we propose a tailored spectral estimator when the covariance\nmatrix is additionally Toeplitz, and show reliable estimation can be obtained\nfrom a substantially smaller number of binary measurements. Our results hold\neven when a constant fraction of the binary measurements is randomly flipped.\nFinally, we develop a low-complexity online algorithm to track the principal\nsubspace when new measurements arrive sequentially. Numerical examples are\nprovided to validate the proposed approach. \n\n"}
{"id": "1407.6481", "contents": "Title: Interference Management in 5G Reverse TDD HetNets with Wireless\n  Backhaul: A Large System Analysis Abstract: This work analyzes a heterogeneous network (HetNet), which comprises a macro\nbase station (BS) equipped with a large number of antennas and an overlaid\ndense tier of small cell access points (SCAs) using a wireless backhaul for\ndata traffic. The static and low mobility user equipment terminals (UEs) are\nassociated with the SCAs while those with medium-to-high mobility are served by\nthe macro BS. A reverse time division duplexing (TDD) protocol is used by the\ntwo tiers, which allows the BS to locally estimate both the intra-tier and\ninter-tier channels. This knowledge is then used at the BS either in the uplink\n(UL) or in the downlink (DL) to simultaneously serve the macro UEs (MUEs) and\nto provide the wireless backhaul to SCAs. A geographical separation of\nco-channel SCAs is proposed to limit the interference coming from the UL\nsignals of MUEs. A concatenated linear precoding technique employing either\nzero-forcing (ZF) or regularized ZF is used at the BS to simultaneously serve\nMUEs and SCAs in DL while nulling interference toward those SCAs in UL. We\nevaluate and characterize the performance of the system through the power\nconsumption of UL and DL transmissions under the assumption that target rates\nmust be satisfied and imperfect channel state information is available for\nMUEs. The analysis is conducted in the asymptotic regime where the number of BS\nantennas and the network size (MUEs and SCAs) grow large with fixed ratios.\nResults from large system analysis are used to provide concise formulae for the\nasymptotic UL and DL transmit powers and precoding vectors under the above\nassumptions. Numerical results are used to validate the analysis in different\nsettings and to make comparisons with alternative network architectures. \n\n"}
{"id": "1407.6616", "contents": "Title: Second order asymptotics of visible mixed quantum source coding via\n  universal codes Abstract: The simplest example of a quantum information source with memory is a mixed\nsource which emits signals entirely from one of two memoryless quantum sources\nwith given a priori probabilities. Considering a mixed source consisting of a\ngeneral one-parameter family of memoryless sources, we derive the second order\nasymptotic rate for fixed-length visible source coding. Furthermore, we\nspecialize our main result to a mixed source consisting of two memoryless\nsources. Our results provide the first example of second order asymptotics for\na quantum information-processing task employing a resource with memory. For the\ncase of a classical mixed source (using a finite alphabet), our results reduce\nto those obtained by Nomura and Han [IEEE Trans. on Inf. Th. 59.1 (2013), pp.\n1-16]. To prove the achievability part of our main result, we introduce\nuniversal quantum source codes achieving second order asymptotic rates. These\nare obtained by an extension of Hayashi's construction [IEEE Trans. on Inf. Th.\n54.10 (2008), pp. 4619-4637] of their classical counterparts. \n\n"}
{"id": "1407.7169", "contents": "Title: Principles and Parameters: a coding theory perspective Abstract: We propose an approach to Longobardi's parametric comparison method (PCM) via\nthe theory of error-correcting codes. One associates to a collection of\nlanguages to be analyzed with the PCM a binary (or ternary) code with one code\nwords for each language in the family and each word consisting of the binary\nvalues of the syntactic parameters of the language, with the ternary case\nallowing for an additional parameter state that takes into account phenomena of\nentailment of parameters. The code parameters of the resulting code can be\ncompared with some classical bounds in coding theory: the asymptotic bound, the\nGilbert-Varshamov bound, etc. The position of the code parameters with respect\nto some of these bounds provides quantitative information on the variability of\nsyntactic parameters within and across historical-linguistic families. While\ncomputations carried out for languages belonging to the same family yield codes\nbelow the GV curve, comparisons across different historical families can give\nexamples of isolated codes lying above the asymptotic bound. \n\n"}
{"id": "1408.0180", "contents": "Title: Linear Locally Repairable Codes with Random Matrices Abstract: In this paper, locally repairable codes with all-symbol locality are studied.\nMethods to modify already existing codes are presented. Also, it is shown that\nwith high probability, a random matrix with a few extra columns guaranteeing\nthe locality property, is a generator matrix for a locally repairable code with\na good minimum distance. The proof of this gives also a constructive method to\nfind locally repairable codes. \n\n"}
{"id": "1408.2765", "contents": "Title: Neutral meson production in pp and Pb-Pb collisions measured by ALICE at\n  the LHC Abstract: The midrapidity $\\pi^0$ nuclear modification factor, $R_{\\rm{AA}}$, at\n$\\sqrt{s_\\mathrm{NN}} =$ 2.76 TeV in 6 centrality classes as well as the\ncorresponding $\\pi^0$ invariant yields in Pb-Pb and in pp collisions are\npresented. The transverse momentum range covered is 0.6 (0.4) GeV/$c$ $<\np_{\\mathrm{T}} <$ 12 (10) GeV/$c$ for Pb-Pb (pp) collisions. A suppression of\nneutral pions increasing with centrality is observed. The yield of charged\nparticles associated with a high $p_{\\mathrm{T}}$ neutral pion trigger (8\nGeV/$c$ $< p_{\\mathrm{T}} <$ 16 GeV/$c$) is measured in pp and Pb-Pb collisions\nat $\\sqrt{s_\\mathrm{NN}} =$ 2.76 TeV. The conditional per-trigger yield\nmodification factor in the near and away side is in agreement with the measured\none for charged particles. \n\n"}
{"id": "1408.3502", "contents": "Title: L\\\"uders' and quantum Jeffrey's rules as entropic projections Abstract: We prove that the standard quantum mechanical description of a quantum state\nchange due to measurement, given by Lueders' rules, is a special case of the\nconstrained maximisation of a quantum relative entropy functional. This result\nis a quantum analogue of the derivation of the Bayes--Laplace rule as a special\ncase of the constrained maximisation of relative entropy. The proof is provided\nfor the Umegaki relative entropy of density operators over a Hilbert space as\nwell as for the Araki relative entropy of normal states over a W*-algebra. We\nalso introduce a quantum analogue of Jeffrey's rule, derive it in the same way\nas above, and discuss the meaning of these results for quantum bayesianism. \n\n"}
{"id": "1408.4045", "contents": "Title: Relax, no need to round: integrality of clustering formulations Abstract: We study exact recovery conditions for convex relaxations of point cloud\nclustering problems, focusing on two of the most common optimization problems\nfor unsupervised clustering: $k$-means and $k$-median clustering. Motivations\nfor focusing on convex relaxations are: (a) they come with a certificate of\noptimality, and (b) they are generic tools which are relatively parameter-free,\nnot tailored to specific assumptions over the input. More precisely, we\nconsider the distributional setting where there are $k$ clusters in\n$\\mathbb{R}^m$ and data from each cluster consists of $n$ points sampled from a\nsymmetric distribution within a ball of unit radius. We ask: what is the\nminimal separation distance between cluster centers needed for convex\nrelaxations to exactly recover these $k$ clusters as the optimal integral\nsolution? For the $k$-median linear programming relaxation we show a tight\nbound: exact recovery is obtained given arbitrarily small pairwise separation\n$\\epsilon > 0$ between the balls. In other words, the pairwise center\nseparation is $\\Delta > 2+\\epsilon$. Under the same distributional model, the\n$k$-means LP relaxation fails to recover such clusters at separation as large\nas $\\Delta = 4$. Yet, if we enforce PSD constraints on the $k$-means LP, we get\nexact cluster recovery at center separation $\\Delta > 2\\sqrt2(1+\\sqrt{1/m})$.\nIn contrast, common heuristics such as Lloyd's algorithm (a.k.a. the $k$-means\nalgorithm) can fail to recover clusters in this setting; even with arbitrarily\nlarge cluster separation, k-means++ with overseeding by any constant factor\nfails with high probability at exact cluster recovery. To complement the\ntheoretical analysis, we provide an experimental study of the recovery\nguarantees for these various methods, and discuss several open problems which\nthese experiments suggest. \n\n"}
{"id": "1408.4841", "contents": "Title: Wireless-Powered Cooperative Communications via a Hybrid Relay Abstract: In this paper, we consider a wireless-powered cooperative communication\nnetwork, which consists of a hybrid access-point (AP), a hybrid relay, and an\ninformation source. In contrast to the conventional cooperative networks, the\nsource in the considered network is assumed to have no embedded energy supply.\nThus, it first needs to harvest energy from the signals broadcast by the AP\nand/or relay, which have constant power supply, in the downlink (DL) before\ntransmitting the information to the AP in the uplink (UL). The hybrid relay can\nnot only help to forward information in the UL but also charge the source with\nwireless energy transfer in the DL. Considering different possible operations\nof the hybrid relay, we propose two cooperative protocols for the considered\nnetwork. We jointly optimize the time and power allocation for DL energy\ntransfer and UL information transmission to maximize the system throughput of\nthe proposed protocols. Numerical results are presented to compare the\nperformance of the proposed protocols and illustrate the impacts of system\nparameters. \n\n"}
{"id": "1408.5781", "contents": "Title: GSPBOX: A toolbox for signal processing on graphs Abstract: This document introduces the Graph Signal Processing Toolbox (GSPBox) a\nframework that can be used to tackle graph related problems with a signal\nprocessing approach. It explains the structure and the organization of this\nsoftware. It also contains a general description of the important modules. \n\n"}
{"id": "1408.6894", "contents": "Title: Correlation Detection and an Operational Interpretation of the Renyi\n  Mutual Information Abstract: A variety of new measures of quantum Renyi mutual information and quantum\nRenyi conditional entropy have recently been proposed, and some of their\nmathematical properties explored. Here, we show that the Renyi mutual\ninformation attains operational meaning in the context of composite hypothesis\ntesting, when the null hypothesis is a fixed bipartite state and the alternate\nhypothesis consists of all product states that share one marginal with the null\nhypothesis. This hypothesis testing problem occurs naturally in channel coding,\nwhere it corresponds to testing whether a state is the output of a given\nquantum channel or of a 'useless' channel whose output is decoupled from the\nenvironment. Similarly, we establish an operational interpretation of Renyi\nconditional entropy by choosing an alternative hypothesis that consists of\nproduct states that are maximally mixed on one system. Specialized to classical\nprobability distributions, our results also establish an operational\ninterpretation of Renyi mutual information and Renyi conditional entropy. \n\n"}
{"id": "1408.6897", "contents": "Title: Investigating Properties of a Family of Quantum Renyi Divergences Abstract: Audenaert and Datta recently introduced a two-parameter family of relative\nR\\'{e}nyi entropies, known as the $\\alpha$-$z$-relative R\\'{e}nyi entropies.\nThe definition of the $\\alpha$-$z$-relative R\\'{e}nyi entropy unifies all\npreviously proposed definitions of the quantum R\\'{e}nyi divergence of order\n$\\alpha$ under a common framework. Here we will prove that the\n$\\alpha$-$z$-relative R\\'{e}nyi entropies are a proper generalization of the\nquantum relative entropy by computing the limit of the $\\alpha$-$z$ divergence\nas $\\alpha$ approaches one and $z$ is an arbitrary function of $\\alpha$. We\nalso show that certain operationally relevant families of R\\'enyi divergences\nare differentiable at $\\alpha = 1$. Finally, our analysis reveals that the\nderivative at $\\alpha = 1$ evaluates to half the relative entropy variance, a\nquantity that has attained operational significance in second-order quantum\nhypothesis testing. \n\n"}
{"id": "1409.2536", "contents": "Title: Coding Theorem and Strong Converse for Quantum Channels Abstract: In this correspondence we present a new proof of Holevo's coding theorem for\ntransmitting classical information through quantum channels, and its strong\nconverse. The technique is largely inspired by Wolfowitz's combinatorial\napproach using types of sequences. As a by-product of our approach which is\nindependent of previous ones, both in the coding theorem and the converse, we\ncan give a new proof of Holevo's information bound. \n\n"}
{"id": "1409.3246", "contents": "Title: Wideband Sensing and Optimization for Cognitive Radio Networks with\n  Noise Variance Uncertainty Abstract: This paper considers wide-band spectrum sensing and optimization for\ncognitive radio (CR) networks with noise variance uncertainty. It is assumed\nthat the considered wide-band contains one or more white sub-bands. Under this\nassumption, we consider throughput maximization of the CR network while\nappropriately protecting the primary network. We address this problem as\nfollows. First, we propose novel ratio based test statistics for detecting the\nedges of each sub-band. Second, we employ simple energy comparison approach to\nchoose one reference white sub-band. Third, we propose novel generalized energy\ndetector (GED) for examining each of the remaining sub-bands by exploiting the\nnoise information of the reference white sub-band. Finally, we optimize the\nsensing time ($T_o$) to maximize the CR network throughput using the detection\nand false alarm probabilities of the GED. The proposed GED does not suffer from\nsignal to noise ratio (SNR) wall and outperforms the existing signal detectors.\nMoreover, the relationship between the proposed GED and conventional energy\ndetector (CED) is quantified analytically. We show that the optimal $T_o$\ndepends on the noise variance information. In particular, with $10$TV bands,\nSNR=$-20$dB and $2$s frame duration, we found that the optimal $T_o$ is\n$28.5$ms ($50.6$ms) with perfect (imperfect) noise variance scenario. \n\n"}
{"id": "1409.3562", "contents": "Title: Strong converse exponent for classical-quantum channel coding Abstract: We determine the exact strong converse exponent of classical-quantum channel\ncoding, for every rate above the Holevo capacity. Our form of the exponent is\nan exact analogue of Arimoto's, given as a transform of the Renyi capacities\nwith parameters alpha>1. It is important to note that, unlike in the classical\ncase, there are many inequivalent ways to define the Renyi divergence of\nstates, and hence the R\\'enyi capacities of channels. Our exponent is in terms\nof the Renyi capacities corresponding to a version of the Renyi divergences\nthat has been introduced recently in [M\\\"uller-Lennert, Dupuis, Szehr, Fehr and\nTomamichel, J. Math. Phys. 54, 122203, (2013)], and [Wilde, Winter, Yang,\nCommun. Math. Phys. 331, (2014)]. Our result adds to the growing body of\nevidence that this new version is the natural definition for the purposes of\nstrong converse problems. \n\n"}
{"id": "1409.4320", "contents": "Title: Self-Dictionary Sparse Regression for Hyperspectral Unmixing: Greedy\n  Pursuit and Pure Pixel Search are Related Abstract: This paper considers a recently emerged hyperspectral unmixing formulation\nbased on sparse regression of a self-dictionary multiple measurement vector\n(SD-MMV) model, wherein the measured hyperspectral pixels are used as the\ndictionary. Operating under the pure pixel assumption, this SD-MMV formalism is\nspecial in that it allows simultaneous identification of the endmember spectral\nsignatures and the number of endmembers. Previous SD-MMV studies mainly focus\non convex relaxations. In this study, we explore the alternative of greedy\npursuit, which generally provides efficient and simple algorithms. In\nparticular, we design a greedy SD-MMV algorithm using simultaneous orthogonal\nmatching pursuit. Intriguingly, the proposed greedy algorithm is shown to be\nclosely related to some existing pure pixel search algorithms, especially, the\nsuccessive projection algorithm (SPA). Thus, a link between SD-MMV and pure\npixel search is revealed. We then perform exact recovery analyses, and prove\nthat the proposed greedy algorithm is robust to noise---including its\nidentification of the (unknown) number of endmembers---under a sufficiently low\nnoise level. The identification performance of the proposed greedy algorithm is\ndemonstrated through both synthetic and real-data experiments. \n\n"}
{"id": "1409.5276", "contents": "Title: Sidon Sets, Difference Sets, and Codes in $ A_n $ Lattices Abstract: This chapter investigates the properties of (linear) codes in $ A_n $\nlattices, the practical motivation for which is found in several communication\nscenarios, such as asymmetric channels, sticky-insertion channels, bit-shift\nchannels, and permutation channels. In particular, a connection between these\ncodes and notions of difference sets and Sidon sets in Abelian groups is\ndemonstrated. It is shown that the $ A_n $ lattice admits a linear perfect code\nof radius $ 1 $ if and only if there exists an Abelian planar difference set of\ncardinality $ n + 1 $. Similarly, a direct link is given between linear codes\nof radius $ r $ in the $ A_n $ lattice and Sidon sets of order $ 2r $ and\ncardinality $ n + 1 $. Sidon sets of order $ 2r-1 $ are also represented\ngeometrically in a similar way. Apart from providing geometric intuition about\nSidon sets, this interpretation enables simple derivations of bounds on their\nparameters, which are either equivalent to, or improve upon the known bounds.\nIn connection to the above, more general (non-planar) Abelian difference sets\nand perfect codes of radius $ r $ are also discussed. \n\n"}
{"id": "1410.1443", "contents": "Title: R\\'enyi squashed entanglement, discord, and relative entropy differences Abstract: In [Berta et al., J. Math. Phys. 56, 022205 (2015)], we recently proposed\nRenyi generalizations of the conditional quantum mutual information of a\ntripartite state on $ABC$ (with $C$ being the conditioning system), which were\nshown to satisfy some properties that hold for the original quantity, such as\nnon-negativity, duality, and monotonicity with respect to local operations on\nthe system $B$ (with it being left open to show that the Renyi quantity is\nmonotone with respect to local operations on system $A$). Here we define a\nRenyi squashed entanglement and a Renyi quantum discord based on a Renyi\nconditional quantum mutual information and investigate these quantities in\ndetail. Taking as a conjecture that the Renyi conditional quantum mutual\ninformation is monotone with respect to local operations on both systems $A$\nand $B$, we prove that the Renyi squashed entanglement and the Renyi quantum\ndiscord satisfy many of the properties of the respective original von Neumann\nentropy based quantities. In our prior work [Berta et al., Phys. Rev. A 91,\n022333 (2015)], we also detailed a procedure to obtain Renyi generalizations of\nany quantum information measure that is equal to a linear combination of von\nNeumann entropies with coefficients chosen from the set $\\{-1,0,1\\}$. Here, we\nextend this procedure to include differences of relative entropies. Using the\nextended procedure and a conjectured monotonicity of the Renyi generalizations\nin the Renyi parameter, we discuss potential remainder terms for well known\ninequalities such as monotonicity of the relative entropy, joint convexity of\nthe relative entropy, and the Holevo bound. \n\n"}
{"id": "1410.3812", "contents": "Title: Polar Coding for the General Wiretap Channel Abstract: Information-theoretic work for wiretap channels is mostly based on random\ncoding schemes. Designing practical coding schemes to achieve\ninformation-theoretic security is an important problem. By applying the two\nrecently developed techniques for polar codes, we propose a polar coding scheme\nto achieve the secrecy capacity of the general wiretap channel. \n\n"}
{"id": "1410.5009", "contents": "Title: Secure Degrees of Freedom of Wireless X Networks Using Artificial Noise\n  Alignment Abstract: The problem of transmitting confidential messages in $M \\times K$ wireless X\nnetworks is considered, in which each transmitter intends to send one\nconfidential message to every receiver. In particular, the secure degrees of\nfreedom (SDOF) of the considered network are studied based on an artificial\nnoise alignment (ANA) approach, which integrates interference alignment and\nartificial noise transmission. At first, an SDOF upper bound is derived for the\n$M \\times K$ X network with confidential messages (XNCM) to be\n$\\frac{K(M-1)}{K+M-2}$. By proposing an ANA approach, it is shown that the SDOF\nupper bound is tight when $K=2$ for the considered XNCM with time/frequency\nvarying channels. For $K \\geq 3$, it is shown that SDOF of\n$\\frac{K(M-1)}{K+M-1}$ can be achieved, even when an external eavesdropper is\npresent. The key idea of the proposed scheme is to inject artificial noise into\nthe network, which can be aligned in the interference space at receivers for\nconfidentiality. Moreover, for the network with no channel state information at\ntransmitters, a blind ANA scheme is proposed to achieve SDOF of\n$\\frac{K(M-1)}{K+M-1}$ for $K,M \\geq 2$, with reconfigurable antennas at\nreceivers. The proposed method provides a linear approach to secrecy coding and\ninterference alignment. \n\n"}
{"id": "1410.5085", "contents": "Title: On the Capacity Regions of Two-Way Diamond Channels Abstract: In this paper, we study the capacity regions of two-way diamond channels. We\nshow that for a linear deterministic model the capacity of the diamond channel\nin each direction can be simultaneously achieved for all values of channel\nparameters, where the forward and backward channel parameters are not\nnecessarily the same. We divide the achievability scheme into three cases,\ndepending on the forward and backward channel parameters. For the first case,\nwe use a reverse amplify-and-forward strategy in the relays. For the second\ncase, we use four relay strategies based on the reverse amplify-and-forward\nwith some modifications in terms of replacement and repetition of some stream\nlevels. For the third case, we use two relay strategies based on performing two\nrounds of repetitions in a relay. The proposed schemes for deterministic\nchannels are used to find the capacity regions within constant gaps for two\nspecial cases of the Gaussian two-way diamond channel. First, for the general\nGaussian two-way relay channel with a simple coding scheme the smallest gap is\nachieved compared to the prior works. Then, a special symmetric Gaussian\ntwo-way diamond model is considered and the capacity region is achieved within\nfour bits. \n\n"}
{"id": "1410.6289", "contents": "Title: Signal inference with unknown response: Calibration-uncertainty\n  renormalized estimator Abstract: The calibration of a measurement device is crucial for every scientific\nexperiment, where a signal has to be inferred from data. We present CURE, the\ncalibration uncertainty renormalized estimator, to reconstruct a signal and\nsimultaneously the instrument's calibration from the same data without knowing\nthe exact calibration, but its covariance structure. The idea of CURE,\ndeveloped in the framework of information field theory, is starting with an\nassumed calibration to successively include more and more portions of\ncalibration uncertainty into the signal inference equations and to absorb the\nresulting corrections into renormalized signal (and calibration) solutions.\nThereby, the signal inference and calibration problem turns into solving a\nsingle system of ordinary differential equations and can be identified with\ncommon resummation techniques used in field theories. We verify CURE by\napplying it to a simplistic toy example and compare it against existent\nself-calibration schemes, Wiener filter solutions, and Markov Chain Monte Carlo\nsampling. We conclude that the method is able to keep up in accuracy with the\nbest self-calibration methods and serves as a non-iterative alternative to it. \n\n"}
{"id": "1411.0282", "contents": "Title: Noisy Matrix Completion under Sparse Factor Models Abstract: This paper examines a general class of noisy matrix completion tasks where\nthe goal is to estimate a matrix from observations obtained at a subset of its\nentries, each of which is subject to random noise or corruption. Our specific\nfocus is on settings where the matrix to be estimated is well-approximated by a\nproduct of two (a priori unknown) matrices, one of which is sparse. Such\nstructural models - referred to here as \"sparse factor models\" - have been\nwidely used, for example, in subspace clustering applications, as well as in\ncontemporary sparse modeling and dictionary learning tasks. Our main\ntheoretical contributions are estimation error bounds for sparsity-regularized\nmaximum likelihood estimators for problems of this form, which are applicable\nto a number of different observation noise or corruption models. Several\nspecific implications are examined, including scenarios where observations are\ncorrupted by additive Gaussian noise or additive heavier-tailed (Laplace)\nnoise, Poisson-distributed observations, and highly-quantized (e.g., one-bit)\nobservations. We also propose a simple algorithmic approach based on the\nalternating direction method of multipliers for these tasks, and provide\nexperimental evidence to support our error analyses. \n\n"}
{"id": "1411.0446", "contents": "Title: Multiple Access Gaussian Channels with Arbitrary Inputs: Optimal\n  Precoding and Power Allocation Abstract: In this paper, we derive new closed-form expressions for the gradient of the\nmutual information with respect to arbitrary parameters of the two-user\nmultiple access channel (MAC). The derived relations generalize the fundamental\nrelation between the derivative of the mutual information and the minimum mean\nsquared error (MMSE) to multiuser setups. We prove that the derivative of the\nmutual information with respect to the signal to noise ratio (SNR) is equal to\nthe MMSE plus a covariance induced due to the interference, quantified by a\nterm with respect to the cross correlation of the multiuser input estimates,\nthe channels and the precoding matrices. We also derive new relations for the\ngradient of the conditional and non-conditional mutual information with respect\nto the MMSE. Capitalizing on the new fundamental relations, we investigate the\nlinear precoding and power allocation policies that maximize the mutual\ninformation for the two-user MAC Gaussian channels with arbitrary input\ndistributions. We show that the optimal design of linear precoders may satisfy\na fixed-point equation as a function of the channel and the input constellation\nunder specific setups. We show also that the non-mutual interference in a\nmultiuser setup introduces a term to the gradient of the mutual information\nwhich plays a fundamental role in the design of optimal transmission\nstrategies, particularly the optimal precoding and power allocation, and\nexplains the losses in the data rates. Therefore, we provide a novel\ninterpretation of the interference with respect to the channel, power, and\ninput estimates of the main user and the interferer. \n\n"}
{"id": "1411.3603", "contents": "Title: Communication with Imperfectly Shared Randomness Abstract: The communication complexity of many fundamental problems reduces greatly\nwhen the communicating parties share randomness that is independent of the\ninputs to the communication task. Natural communication processes (say between\nhumans) however often involve large amounts of shared correlations among the\ncommunicating players, but rarely allow for perfect sharing of randomness. Can\nthe communication complexity benefit from shared correlations as well as it\ndoes from shared randomness? This question was considered mainly in the context\nof simultaneous communication by Bavarian et al. (ICALP 2014). In this work we\nstudy this problem in the standard interactive setting and give some general\nresults. In particular, we show that every problem with communication\ncomplexity of $k$ bits with perfectly shared randomness has a protocol using\nimperfectly shared randomness with complexity $\\exp(k)$ bits. We also show that\nthis is best possible by exhibiting a promise problem with complexity $k$ bits\nwith perfectly shared randomness which requires $\\exp(k)$ bits when the\nrandomness is imperfectly shared. Along the way we also highlight some other\nbasic problems such as compression, and agreement distillation, where shared\nrandomness plays a central role and analyze the complexity of these problems in\nthe imperfectly shared randomness model.\n  The technical highlight of this work is the lower bound that goes into the\nresult showing the tightness of our general connection. This result builds on\nthe intuition that communication with imperfectly shared randomness needs to be\nless sensitive to its random inputs than communication with perfectly shared\nrandomness. The formal proof invokes results about the small-set expansion of\nthe noisy hypercube and an invariance principle to convert this intuition to a\nproof, thus giving a new application domain for these fundamental results. \n\n"}
{"id": "1411.4732", "contents": "Title: Quantifying Redundant Information in Predicting a Target Random Variable Abstract: This paper considers the problem of defining a measure of redundant\ninformation that quantifies how much common information two or more random\nvariables specify about a target random variable. We discussed desired\nproperties of such a measure, and propose new measures with some desirable\nproperties. \n\n"}
{"id": "1411.5350", "contents": "Title: Identifying Coupling Structure in Complex Systems through the Optimal\n  Causation Entropy Principle Abstract: Inferring the coupling structure of complex systems from time series data in\ngeneral by means of statistical and information-theoretic techniques is a\nchallenging problem in applied science. The reliability of statistical\ninferences requires the construction of suitable information-theoretic measures\nthat take into account both direct and indirect influences, manifest in the\nform of information flows, between the components within the system. In this\nwork, we present an application of the optimal causation entropy (oCSE)\nprinciple to identify the coupling structure of a synthetic biological system,\nthe repressilator. Specifically, when the system reaches an equilibrium state,\nwe use a stochastic perturbation approach to extract time series data that\napproximate a linear stochastic process. Then, we present and jointly apply the\naggregative discovery and progressive removal algorithms based on the oCSE\nprinciple to infer the coupling structure of the system from the measured data.\nFinally, we show that the success rate of our coupling inferences not only\nimproves with the amount of available data, but it also increases with a higher\nfrequency of sampling and is especially immune to false positives. \n\n"}
{"id": "1411.6469", "contents": "Title: Resource Allocation for Energy-Efficient 3-Way Relay Channels Abstract: Throughput and energy efficiency in 3-way relay channels are studied in this\npaper. Unlike previous contributions, we consider a circular message exchange.\nFirst, an outer bound and achievable sum rate expressions for different\nrelaying protocols are derived for 3-way relay channels. The sum capacity is\ncharacterized for certain SNR regimes. Next, leveraging the derived achievable\nsum rate expressions, cooperative and competitive maximization of the energy\nefficiency are considered. For the cooperative case, both low-complexity and\nglobally optimal algorithms for joint power allocation at the users and at the\nrelay are designed so as to maximize the system global energy efficiency. For\nthe competitive case, a game theoretic approach is taken, and it is shown that\nthe best response dynamics is guaranteed to converge to a Nash equilibrium. A\npower consumption model for mmWave board-to-board communications is developed,\nand numerical results are provided to corroborate and provide insight on the\ntheoretical findings. \n\n"}
{"id": "1411.6792", "contents": "Title: Conditional probability calculations for the nonlinear Schr\\\"odinger\n  equation with additive noise Abstract: The method for computation of conditional probability density function for\nthe nonlinear Schr\\\"odinger equation with additive noise is developed. We\npresent in a constructive form the conditional probability density function in\nthe limit of a small noise and analytically derive it in a weakly nonlinear\ncase. The general theory results are illustrated using fibre-optic\ncommunications as a particular, albeit practically very important, example. \n\n"}
{"id": "1412.0616", "contents": "Title: Logical Entropy for Quantum States Abstract: The novel concept of quantum logical entropy is presented and analyzed. We\nprove several basic properties of this entropy with regard to density matrices.\nWe hereby motivate a different approach for the assignment of quantum entropy\nto density matrices. \n\n"}
{"id": "1412.0980", "contents": "Title: Approximate Degradable Quantum Channels Abstract: Degradable quantum channels are an important class of completely positive\ntrace-preserving maps. Among other properties, they offer a single-letter\nformula for the quantum and the private classical capacity and are\ncharacterized by the fact that a complementary channel can be obtained from the\nchannel by applying a degrading channel. In this work we introduce the concept\nof approximate degradable channels, which satisfy this condition up to some\nfinite $\\varepsilon\\geq0$. That is, there exists a degrading channel which upon\ncomposition with the channel is $\\varepsilon$-close in the diamond norm to the\ncomplementary channel. We show that for any fixed channel the smallest such\n$\\varepsilon$ can be efficiently determined via a semidefinite program.\nMoreover, these approximate degradable channels also approximately inherit all\nother properties of degradable channels. As an application, we derive improved\nupper bounds to the quantum and private classical capacity for certain channels\nof interest in quantum communication. \n\n"}
{"id": "1412.3098", "contents": "Title: On the number of active links in random wireless networks Abstract: This paper presents results on the typical number of simultaneous\npoint-to-point transmissions above a minimum rate that can be sustained in a\nnetwork with $n$ transmitter-receiver node pairs when all transmitting nodes\ncan potentially interfere with all receivers. In particular we obtain a scaling\nlaw when the fading gains are independent Rayleigh distributed random variables\nand the transmitters over different realizations are located at the points of a\nstationary Poisson field in the plane. We show that asymptotically with\nprobability approaching 1, the number of simultaneous transmissions (links that\ncan transmit at greater than a minimum rate) is of the order of\n$O(n^{\\frac{1}{4}})$. These asymptotic results are confirmed from simulations. \n\n"}
{"id": "1412.3448", "contents": "Title: MIMO Beamforming Design towards Maximizing Mutual Information in\n  Wireless Sensor Network Abstract: This paper considers joint beamformer design towards maximizing the mutual\ninformation in a coherent wireless sensor network with noisy observation and\nmultiple antennae. Leveraging the weighted minimum mean square error and block\ncoordinate ascent (BCA) framework, we propose two new and efficient methods:\nbatch-mode BCA and cyclic multi-block BCA. The existing batch-mode approaches\nrequire stringent conditions such as diagonal channel matrices and positive\ndefinite second-order matrices, and are therefore inapplicable to our problem.\nOur match-mode BCA overcomes the previous limitations via a general\nsecond-order cone programming formation, and exhibits a strong convergence\nproperty which we have rigorously proven. The existing multi-block approaches\nrely on numerical solvers to handle the subproblems and some render good\nperformance only at high signal-to-noise ratios. Exploiting the convexity of\nthe trust-region subproblem for the convex case, our multi-block BCA\nsignificantly reduces the complexity and enhances the previous results by\nproviding an analytical expression for the energy-preserving optimal solution.\nAnalysis and simulations confirm the advantages of the proposed methods. \n\n"}
{"id": "1412.4444", "contents": "Title: Asymptotics and Non-asymptotics for Universal Fixed-to-Variable Source\n  Coding Abstract: Universal fixed-to-variable lossless source coding for memoryless sources is\nstudied in the finite blocklength and higher-order asymptotics regimes. Optimal\nthird-order coding rates are derived for general fixed-to-variable codes and\nfor prefix codes. It is shown that the non-prefix Type Size code, in which\ncodeword lengths are chosen in ascending order of type class size, achieves the\noptimal third-order rate and outperforms classical Two-Stage codes. Converse\nresults are proved making use of a result on the distribution of the empirical\nentropy and Laplace's approximation. Finally, the fixed-to-variable coding\nproblem without a prefix constraint is shown to be essentially the same as the\nuniversal guessing problem. \n\n"}
{"id": "1412.5065", "contents": "Title: A Stochastic Geometry Framework for LOS/NLOS Propagation in Dense Small\n  Cell Networks Abstract: The need to carry out analytical studies of wireless systems often motivates\nthe usage of simplified models which, despite their tractability, can easily\nlead to an overestimation of the achievable performance. In the case of dense\nsmall cells networks, the standard single slope path-loss model has been shown\nto provide interesting, but supposedly too optimistic, properties such as the\ninvariance of the outage/coverage probability and of the spectral efficiency to\nthe base station density. This paper seeks to explore the performance of dense\nsmall cells networks when a more accurate path-loss model is taken into\naccount. We first propose a stochastic geometry based framework for small cell\nnetworks where the signal propagation accounts for both the Line-of-Sight (LOS)\nand Non-Line-Of-Sight (NLOS) components, such as the model provided by the 3GPP\nfor evaluation of pico-cells in Heterogeneous Networks. We then study the\nperformance of these networks and we show the dependency of some metrics such\nas the outage/coverage probability, the spectral efficiency and Area Spectral\nEfficiency (ASE) on the base station density and on the LOS likelihood of the\npropagation environment. Specifically, we show that, with LOS/NLOS propagation,\ndense networks still achieve large ASE gain but, at the same time, suffer from\nhigh outage probability. \n\n"}
{"id": "1412.7065", "contents": "Title: Asymptotic entropic uncertainty relations Abstract: We analyze entropic uncertainty relations for two orthogonal measurements on\na $N$-dimensional Hilbert space, performed in two generic bases. It is assumed\nthat the unitary matrix $U$ relating both bases is distributed according to the\nHaar measure on the unitary group. We provide lower bounds on the average\nShannon entropy of probability distributions related to both measurements. The\nbounds are stronger than these obtained with use of the entropic uncertainty\nrelation by Maassen and Uffink, and they are optimal up to additive constants.\nWe also analyze the case of a large number of measurements and obtain strong\nentropic uncertainty relations which hold with high probability with respect to\nthe random choice of bases. The lower bounds we obtain are optimal up to\nadditive constants and allow us to establish the conjecture by Wehner and\nWinter on the asymptotic behavior of constants in entropic uncertainty\nrelations as the dimension tends to infinity. As a tool we develop estimates on\nthe maximum operator norm of a submatrix of a fixed size of a random unitary\nmatrix distributed according to the Haar measure, which are of an independent\ninterest. \n\n"}
{"id": "1412.8097", "contents": "Title: The Adversarial Noise Threshold for Distributed Protocols Abstract: We consider the problem of implementing distributed protocols, despite\nadversarial channel errors, on synchronous-messaging networks with arbitrary\ntopology.\n  In our first result we show that any $n$-party $T$-round protocol on an\nundirected communication network $G$ can be compiled into a robust simulation\nprotocol on a sparse ($\\mathcal{O}(n)$ edges) subnetwork so that the simulation\ntolerates an adversarial error rate of $\\Omega\\left(\\frac{1}{n}\\right)$; the\nsimulation has a round complexity of $\\mathcal{O}\\left(\\frac{m \\log n}{n}\nT\\right)$, where $m$ is the number of edges in $G$. (So the simulation is\nwork-preserving up to a $\\log$ factor.) The adversary's error rate is within a\nconstant factor of optimal. Given the error rate, the round complexity blowup\nis within a factor of $\\mathcal{O}(k \\log n)$ of optimal, where $k$ is the edge\nconnectivity of $G$. We also determine that the maximum tolerable error rate on\ndirected communication networks is $\\Theta(1/s)$ where $s$ is the number of\nedges in a minimum equivalent digraph.\n  Next we investigate adversarial per-edge error rates, where the adversary is\ngiven an error budget on each edge of the network. We determine the exact limit\nfor tolerable per-edge error rates on an arbitrary directed graph. However, the\nconstruction that approaches this limit has exponential round complexity, so we\ngive another compiler, which transforms $T$-round protocols into\n$\\mathcal{O}(mT)$-round simulations, and prove that for polynomial-query black\nbox compilers, the per-edge error rate tolerated by this last compiler is\nwithin a constant factor of optimal. \n\n"}
{"id": "1501.01825", "contents": "Title: Unified Convex Optimization Approach to Super-Resolution Based on\n  Localized Kernels Abstract: The problem of resolving the fine details of a signal from its coarse scale\nmeasurements or, as it is commonly referred to in the literature, the\nsuper-resolution problem arises naturally in engineering and physics in a\nvariety of settings. We suggest a unified convex optimization approach for\nsuper-resolution. The key is the construction of an interpolating polynomial\nbased on localized kernels. We also show that the localized kernels act as the\nconnecting thread to another wide-spread problem of stream of pulses. \n\n"}
{"id": "1501.02444", "contents": "Title: Unified Scaling of Polar Codes: Error Exponent, Scaling Exponent,\n  Moderate Deviations, and Error Floors Abstract: Consider the transmission of a polar code of block length $N$ and rate $R$\nover a binary memoryless symmetric channel $W$ and let $P_e$ be the block error\nprobability under successive cancellation decoding. In this paper, we develop\nnew bounds that characterize the relationship of the parameters $R$, $N$,\n$P_e$, and the quality of the channel $W$ quantified by its capacity $I(W)$ and\nits Bhattacharyya parameter $Z(W)$.\n  In previous work, two main regimes were studied. In the error exponent\nregime, the channel $W$ and the rate $R<I(W)$ are fixed, and it was proved that\nthe error probability $P_e$ scales roughly as $2^{-\\sqrt{N}}$. In the scaling\nexponent approach, the channel $W$ and the error probability $P_e$ are fixed\nand it was proved that the gap to capacity $I(W)-R$ scales as $N^{-1/\\mu}$.\nHere, $\\mu$ is called scaling exponent and this scaling exponent depends on the\nchannel $W$. A heuristic computation for the binary erasure channel (BEC) gives\n$\\mu=3.627$ and it was shown that, for any channel $W$, $3.579 \\le \\mu \\le\n5.702$.\n  Our contributions are as follows. First, we provide the tighter upper bound\n$\\mu \\le 4.714$ valid for any $W$. With the same technique, we obtain $\\mu \\le\n3.639$ for the case of the BEC, which approaches very closely its heuristically\nderived value. Second, we develop a trade-off between the gap to capacity\n$I(W)-R$ and the error probability $P_e$ as functions of the block length $N$.\nIn other words, we consider a moderate deviations regime in which we study how\nfast both quantities, as functions of the block length $N$, simultaneously go\nto $0$. Third, we prove that polar codes are not affected by error floors. To\ndo so, we fix a polar code of block length $N$ and rate $R$. Then, we vary the\nchannel $W$ and we show that the error probability $P_e$ scales as the\nBhattacharyya parameter $Z(W)$ raised to a power that scales roughly like\n$\\sqrt{N}$. \n\n"}
{"id": "1501.05781", "contents": "Title: Unprecedented studies of the low-energy negatively charged kaons\n  interactions in nuclear matter by AMADEUS Abstract: The AMADEUS experiment aims to provide unique quality data of $K^-$ hadronic\ninteractions in light nuclear targets, in order to solve fundamental open\nquestions in the non-perturbative strangeness QCD sector, like the\ncontroversial nature of the $\\Lambda(1405)$ state, the yield of hyperon\nformation below threshold, the yield and shape of multi-nucleon $K^-$\nabsorption, processes which are intimately connected to the possible existence\nof exotic antikaon multi-nucleon clusters. AMADEUS takes advantage of the\nDA$\\Phi$NE collider, which provides a unique source of monochromatic\nlow-momentum kaons and exploits the KLOE detector as an active target, in order\nto obtain excellent acceptance and resolution data for $K^-$ nuclear capture on\nH, ${}^4$He, ${}^{9}$Be and ${}^{12}$C, both at-rest and in-flight. During the\nsecond half of 2012 a successful data taking was performed with a dedicated\npure carbon target implemented in the central region of KLOE, providing a high\nstatistic sample of pure at-rest $K^-$ nuclear interactions. For the future\ndedicated setups involving cryogenic gaseous targets are under preparation. \n\n"}
{"id": "1501.05892", "contents": "Title: Capacity-achieving Sparse Superposition Codes via Approximate Message\n  Passing Decoding Abstract: Sparse superposition codes were recently introduced by Barron and Joseph for\nreliable communication over the AWGN channel at rates approaching the channel\ncapacity. The codebook is defined in terms of a Gaussian design matrix, and\ncodewords are sparse linear combinations of columns of the matrix. In this\npaper, we propose an approximate message passing decoder for sparse\nsuperposition codes, whose decoding complexity scales linearly with the size of\nthe design matrix. The performance of the decoder is rigorously analyzed and it\nis shown to asymptotically achieve the AWGN capacity with an appropriate power\nallocation. Simulation results are provided to demonstrate the performance of\nthe decoder at finite blocklengths. We introduce a power allocation scheme to\nimprove the empirical performance, and demonstrate how the decoding complexity\ncan be significantly reduced by using Hadamard design matrices. \n\n"}
{"id": "1501.06264", "contents": "Title: Feasibility Studies of Exclusive Diffractive Bremsstrahlung Measurement\n  at RHIC Energies Abstract: Feasibility studies of an observation of the exclusive diffractive\nbremsstrahlung at RHIC at $\\sqrt{s} = 200$~GeV and at $\\sqrt{s} = 500$~GeV are\nreported. A simplified approach to the photon and the scattered proton energy\nreconstruction is used. Influence of possible backgrounds is discussed. \n\n"}
{"id": "1501.06279", "contents": "Title: Fast Inverse Nonlinear Fourier Transform For Generating Multi-Solitons\n  In Optical Fiber Abstract: The achievable data rates of current fiber-optic\nwavelength-division-multiplexing (WDM) systems are limited by nonlinear\ninteractions between different subchannels. Recently, it was thus proposed to\nreplace the conventional Fourier transform in WDM systems with an appropriately\ndefined nonlinear Fourier transform (NFT). The computational complexity of NFTs\nis a topic of current research. In this paper, a fast inverse NFT algorithm for\nthe important special case of multi-solitonic signals is presented. The\nalgorithm requires only $\\mathcal{O}(D\\log^{2}D)$ floating point operations to\ncompute $D$ samples of a multi-soliton. To the best of our knowledge, this is\nthe first algorithm for this problem with $\\log^{2}$-linear complexity. The\npaper also includes a many samples analysis of the generated nonlinear Fourier\nspectra. \n\n"}
{"id": "1501.06477", "contents": "Title: Exploring the properties of the phases of QCD matter - research\n  opportunities and priorities for the next decade Abstract: This document provides a summary of the discussions during the recent joint\nQCD Town Meeting at Temple University of the status of and future plans for the\nresearch program of the relativistic heavy-ion community. A list of compelling\nquestions is formulated, and a number of recommendations outlining the greatest\nresearch opportunities and detailing the research priorities of the heavy-ion\ncommunity, voted on and unanimously approved at the Town Meeting, are\npresented. They are supported by a broad discussion of the underlying physics\nand its relation to other subfields. Areas of overlapping interests with the\n\"QCD and Hadron Structure\" (\"cold QCD\") subcommunity, in particular the\nrecommendation for the future construction of an Electron-Ion Collider, are\nemphasized. The agenda of activities of the \"hot QCD\" subcommunity at the Town\nMeeting is attached. \n\n"}
{"id": "1501.07723", "contents": "Title: A hybrid TIM-NOMA scheme for the SISO Broadcast Channel Abstract: Future mobile communication networks will require enhanced network efficiency\nand reduced system overhead due to their user density and high data rate\ndemanding applications of the mobile devices. Research on Blind Interference\nAlignment (BIA) and Topological Interference Management (TIM) has shown that\noptimal Degrees of Freedom (DoF) can be achieved, in the absence of Channel\nState Information (CSI) at the transmitters, reducing the network's overhead.\nMoreover, the recently emerged Non-Orthogonal Multiple Access (NOMA) scheme\nsuggests a different multiple access approach, compared to the current\northogonal methods employed in 4G networks, resulting in high capacity gains.\nOur contribution is a hybrid TIM-NOMA scheme in Single-Input-Single-Output\n(SISO) K-user cells, in which users are divided into T groups, and 1/T DoF is\nachieved for each user. By superimposing users in the power domain, we\nintroduce a two-stage decoding process, managing 'inter-group' interference\nbased on the TIM principles, and 'intra-group' interference based on Successful\nInterference Cancellation (SIC), as proposed by NOMA. We show that for high SNR\nvalues the hybrid scheme can improve the sum rate by at least 100% when\ncompared to Time Division Multiple Access (TDMA). \n\n"}
{"id": "1502.02647", "contents": "Title: Secure Degrees of Freedom Region of the Two-User MISO Broadcast Channel\n  with Alternating CSIT Abstract: The two user multiple-input single-output (MISO) broadcast channel with\nconfidential messages (BCCM) is studied in which the nature of channel state\ninformation at the transmitter (CSIT) from each user can be of the form\n$I_{i}$, $i=1,2$ where $I_{1}, I_{2}\\in \\{\\mathsf{P}, \\mathsf{D},\n\\mathsf{N}\\}$, and the forms $\\mathsf{P}$, $\\mathsf{D}$ and $\\mathsf{N}$\ncorrespond to perfect and instantaneous, completely delayed, and no CSIT,\nrespectively. Thus, the overall CSIT can alternate between $9$ possible states\ncorresponding to all possible values of $I_{1}I_{2}$, with each state occurring\nfor $\\lambda_{I_{1}I_{2}}$ fraction of the total duration. The main\ncontribution of this paper is to establish the secure degrees of freedom\n(s.d.o.f.) region of the MISO BCCM with alternating CSIT with the symmetry\nassumption, where $\\lambda_{I_{1} I_{2}}=\\lambda_{I_{2}I_{1}}$.\n  The main technical contributions include developing a) novel achievable\nschemes for MISO BCCM with alternating CSIT with security constraints which\nalso highlight the synergistic benefits of inter-state coding for secrecy, b)\nnew converse proofs via local statistical equivalence and channel enhancement;\nand c) showing the interplay between various aspects of channel knowledge and\ntheir impact on s.d.o.f. \n\n"}
{"id": "1502.02733", "contents": "Title: Bandwidth Efficient and Rate-Matched Low-Density Parity-Check Coded\n  Modulation Abstract: A new coded modulation scheme is proposed. At the transmitter, the\nconcatenation of a distribution matcher and a systematic binary encoder\nperforms probabilistic signal shaping and channel coding. At the receiver, the\noutput of a bitwise demapper is fed to a binary decoder. No iterative demapping\nis performed. Rate adaption is achieved by adjusting the input distribution and\nthe transmission power. The scheme is applied to bipolar amplitude shift keying\n(ASK) constellations with equidistant signal points and it is directly\napplicable to two-dimensional quadrature amplitude modulation (QAM). The scheme\nis implemented by using the DVB-S2 low-density parity-check (LDPC) codes. At a\nframe error rate of 1e-3, the new scheme operates within less than 1 dB of the\nAWGN capacity 0.5log2(1+SNR) at any spectral efficiency between 1 and 5\nbits/s/Hz by using only 5 modes, i.e., 4-ASK with code rate 2/3, 8-ASK with\n3/4, 16-ASK and 32-ASK with 5/6 and 64-ASK with 9/10. \n\n"}
{"id": "1502.03903", "contents": "Title: Coding for Network-Coded Slotted ALOHA Abstract: Slotted ALOHA can benefit from physical-layer network coding (PNC) by\ndecoding one or multiple linear combinations of the packets simultaneously\ntransmitted in a timeslot, forming a system of linear equations. Different\nsystems of linear equations are recovered in different timeslots. A message\ndecoder then recovers the original packets of all the users by jointly solving\nmultiple systems of linear equations obtained over different timeslots. We\npropose the batched BP decoding algorithm that combines belief propagation (BP)\nand local Gaussian elimination. Compared with pure Gaussian elimination\ndecoding, our algorithm reduces the decoding complexity from cubic to linear\nfunction of the number of users. Compared with the ordinary BP decoding\nalgorithm for low-density generator-matrix codes, our algorithm has better\nperformance and the same order of computational complexity. We analyze the\nperformance of the batched BP decoding algorithm by generalizing the tree-based\napproach and provide an approach to optimize the system performance. \n\n"}
{"id": "1502.06134", "contents": "Title: Learning with Square Loss: Localization through Offset Rademacher\n  Complexity Abstract: We consider regression with square loss and general classes of functions\nwithout the boundedness assumption. We introduce a notion of offset Rademacher\ncomplexity that provides a transparent way to study localization both in\nexpectation and in high probability. For any (possibly non-convex) class, the\nexcess loss of a two-step estimator is shown to be upper bounded by this offset\ncomplexity through a novel geometric inequality. In the convex case, the\nestimator reduces to an empirical risk minimizer. The method recovers the\nresults of \\citep{RakSriTsy15} for the bounded case while also providing\nguarantees without the boundedness assumption. \n\n"}
{"id": "1502.06644", "contents": "Title: On The Identifiability of Mixture Models from Grouped Samples Abstract: Finite mixture models are statistical models which appear in many problems in\nstatistics and machine learning. In such models it is assumed that data are\ndrawn from random probability measures, called mixture components, which are\nthemselves drawn from a probability measure P over probability measures. When\nestimating mixture models, it is common to make assumptions on the mixture\ncomponents, such as parametric assumptions. In this paper, we make no\nassumption on the mixture components, and instead assume that observations from\nthe mixture model are grouped, such that observations in the same group are\nknown to be drawn from the same component. We show that any mixture of m\nprobability measures can be uniquely identified provided there are 2m-1\nobservations per group. Moreover we show that, for any m, there exists a\nmixture of m probability measures that cannot be uniquely identified when\ngroups have 2m-2 observations. Our results hold for any sample space with more\nthan one element. \n\n"}
{"id": "1502.07281", "contents": "Title: On the Lower Bound of the Divisibility of Exponential Sums in Binomial\n  Case Abstract: Francis Castro, et al [2] computed the exact divisibility of families of\nexponential sums associated to binomials $F(X) = aX^{d_1} + bX^{d_2}$ over\n$\\mathbb{F}_p$, and a conjecture is presented for related work. Here we study\nthis question. \n\n"}
{"id": "1502.07523", "contents": "Title: Cramer-Rao Bound for Sparse Signals Fitting the Low-Rank Model with\n  Small Number of Parameters Abstract: In this paper, we consider signals with a low-rank covariance matrix which\nreside in a low-dimensional subspace and can be written in terms of a finite\n(small) number of parameters. Although such signals do not necessarily have a\nsparse representation in a finite basis, they possess a sparse structure which\nmakes it possible to recover the signal from compressed measurements. We study\nthe statistical performance bound for parameter estimation in the low-rank\nsignal model from compressed measurements. Specifically, we derive the\nCramer-Rao bound (CRB) for a generic low-rank model and we show that the number\nof compressed samples needs to be larger than the number of sources for the\nexistence of an unbiased estimator with finite estimation variance. We further\nconsider the applications to direction-of-arrival (DOA) and spectral estimation\nwhich fit into the low-rank signal model. We also investigate the effect of\ncompression on the CRB by considering numerical examples of the DOA estimation\nscenario, and show how the CRB increases by increasing the compression or\nequivalently reducing the number of compressed samples. \n\n"}
{"id": "1503.01205", "contents": "Title: A Markovian Approach to the Optimal Demodulation of Diffusion-based\n  Molecular Communication Networks Abstract: In a diffusion-based molecular communication network, transmitters and\nreceivers communicate by using signalling molecules (or ligands) in a fluid\nmedium. This paper assumes that the transmitter uses different chemical\nreactions to generate different emission patterns of signalling molecules to\nrepresent different transmission symbols, and the receiver consists of\nreceptors. When the signalling molecules arrive at the receiver, they may react\nwith the receptors to form ligand-receptor complexes. Our goal is to study the\ndemodulation in this setup assuming that the transmitter and receiver are\nsynchronised. We derive an optimal demodulator using the continuous history of\nthe number of complexes at the receiver as the input to the demodulator. We do\nthat by first deriving a communication model which includes the chemical\nreactions in the transmitter, diffusion in the transmission medium and the\nligand-receptor process in the receiver. This model, which takes the form of a\ncontinuous-time Markov process, captures the noise in the receiver signal due\nto the stochastic nature of chemical reactions and diffusion. We then adopt a\nmaximum a posterior framework and use Bayesian filtering to derive the optimal\ndemodulator. We use numerical examples to illustrate the properties of this\noptimal demodulator. \n\n"}
{"id": "1503.01245", "contents": "Title: Large Dimensional Analysis of Robust M-Estimators of Covariance with\n  Outliers Abstract: A large dimensional characterization of robust M-estimators of covariance (or\nscatter) is provided under the assumption that the dataset comprises\nindependent (essentially Gaussian) legitimate samples as well as arbitrary\ndeterministic samples, referred to as outliers. Building upon recent random\nmatrix advances in the area of robust statistics, we specifically show that the\nso-called Maronna M-estimator of scatter asymptotically behaves similar to\nwell-known random matrices when the population and sample sizes grow together\nto infinity. The introduction of outliers leads the robust estimator to behave\nasymptotically as the weighted sum of the sample outer products, with a\nconstant weight for all legitimate samples and different weights for the\noutliers. A fine analysis of this structure reveals importantly that the\npropensity of the M-estimator to attenuate (or enhance) the impact of outliers\nis mostly dictated by the alignment of the outliers with the inverse population\ncovariance matrix of the legitimate samples. Thus, robust M-estimators can\nbring substantial benefits over more simplistic estimators such as the\nper-sample normalized version of the sample covariance matrix, which is not\ncapable of differentiating the outlying samples. The analysis shows that,\nwithin the class of Maronna's estimators of scatter, the Huber estimator is\nmost favorable for rejecting outliers. On the contrary, estimators more similar\nto Tyler's scale invariant estimator (often preferred in the literature) run\nthe risk of inadvertently enhancing some outliers. \n\n"}
{"id": "1503.02045", "contents": "Title: Estimation after Parameter Selection: Performance Analysis and\n  Estimation Methods Abstract: In many practical parameter estimation problems, prescreening and parameter\nselection are performed prior to estimation. In this paper, we consider the\nproblem of estimating a preselected unknown deterministic parameter chosen from\na parameter set based on observations according to a predetermined selection\nrule, $\\Psi$. The data-based parameter selection process may impact the\nsubsequent estimation by introducing a selection bias and creating coupling\nbetween decoupled parameters. This paper introduces a post-selection mean\nsquared error (PSMSE) criterion as a performance measure. A corresponding\nCram\\'er-Rao-type bound on the PSMSE of any $\\Psi$-unbiased estimator is\nderived, where the $\\Psi$-unbiasedness is in the Lehmann-unbiasedness sense.\nThe post-selection maximum-likelihood (PSML) estimator is presented .It is\nproved that if there exists an $\\Psi$-unbiased estimator that achieves the\n$\\Psi$-Cram\\'er-Rao bound (CRB), i.e. an $\\Psi$-efficient estimator, then it is\nproduced by the PSML estimator. In addition, iterative methods are developed\nfor the practical implementation of the PSML estimator. Finally, the proposed\n$\\Psi$-CRB and PSML estimator are examined in estimation after parameter\nselection with different distributions. \n\n"}
{"id": "1503.02120", "contents": "Title: Identifying missing dictionary entries with frequency-conserving context\n  models Abstract: In an effort to better understand meaning from natural language texts, we\nexplore methods aimed at organizing lexical objects into contexts. A number of\nthese methods for organization fall into a family defined by word ordering.\nUnlike demographic or spatial partitions of data, these collocation models are\nof special importance for their universal applicability. While we are\ninterested here in text and have framed our treatment appropriately, our work\nis potentially applicable to other areas of research (e.g., speech, genomics,\nand mobility patterns) where one has ordered categorical data, (e.g., sounds,\ngenes, and locations). Our approach focuses on the phrase (whether word or\nlarger) as the primary meaning-bearing lexical unit and object of study. To do\nso, we employ our previously developed framework for generating word-conserving\nphrase-frequency data. Upon training our model with the Wiktionary---an\nextensive, online, collaborative, and open-source dictionary that contains over\n100,000 phrasal-definitions---we develop highly effective filters for the\nidentification of meaningful, missing phrase-entries. With our predictions we\nthen engage the editorial community of the Wiktionary and propose short lists\nof potential missing entries for definition, developing a breakthrough, lexical\nextraction technique, and expanding our knowledge of the defined English\nlexicon of phrases. \n\n"}
{"id": "1503.03525", "contents": "Title: Online Matrix Completion and Online Robust PCA Abstract: This work studies two interrelated problems - online robust PCA (RPCA) and\nonline low-rank matrix completion (MC). In recent work by Cand\\`{e}s et al.,\nRPCA has been defined as a problem of separating a low-rank matrix (true data),\n$L:=[\\ell_1, \\ell_2, \\dots \\ell_{t}, \\dots , \\ell_{t_{\\max}}]$ and a sparse\nmatrix (outliers), $S:=[x_1, x_2, \\dots x_{t}, \\dots, x_{t_{\\max}}]$ from their\nsum, $M:=L+S$. Our work uses this definition of RPCA. An important application\nwhere both these problems occur is in video analytics in trying to separate\nsparse foregrounds (e.g., moving objects) and slowly changing backgrounds.\n  While there has been a large amount of recent work on both developing and\nanalyzing batch RPCA and batch MC algorithms, the online problem is largely\nopen. In this work, we develop a practical modification of our recently\nproposed algorithm to solve both the online RPCA and online MC problems. The\nmain contribution of this work is that we obtain correctness results for the\nproposed algorithms under mild assumptions. The assumptions that we need are:\n(a) a good estimate of the initial subspace is available (easy to obtain using\na short sequence of background-only frames in video surveillance); (b) the\n$\\ell_t$'s obey a `slow subspace change' assumption; (c) the basis vectors for\nthe subspace from which $\\ell_t$ is generated are dense (non-sparse); (d) the\nsupport of $x_t$ changes by at least a certain amount at least every so often;\nand (e) algorithm parameters are appropriately set \n\n"}
{"id": "1503.04244", "contents": "Title: Security in Locally Repairable Storage Abstract: In this paper we extend the notion of {\\em locally repairable} codes to {\\em\nsecret sharing} schemes. The main problem that we consider is to find optimal\nways to distribute shares of a secret among a set of storage-nodes\n(participants) such that the content of each node (share) can be recovered by\nusing contents of only few other nodes, and at the same time the secret can be\nreconstructed by only some allowable subsets of nodes. As a special case, an\neavesdropper observing some set of specific nodes (such as less than certain\nnumber of nodes) does not get any information. In other words, we propose to\nstudy a locally repairable distributed storage system that is secure against a\n{\\em passive eavesdropper} that can observe some subsets of nodes.\n  We provide a number of results related to such systems including upper-bounds\nand achievability results on the number of bits that can be securely stored\nwith these constraints. \n\n"}
{"id": "1503.07455", "contents": "Title: Sum Secrecy Rate in MISO Full-Duplex Wiretap Channel with Imperfect CSI Abstract: In this paper, we consider the achievable sum secrecy rate in MISO\n(multiple-input-single-output) {\\em full-duplex} wiretap channel in the\npresence of a passive eavesdropper and imperfect channel state information\n(CSI). We assume that the users participating in full-duplex communication have\nmultiple transmit antennas, and that the users and the eavesdropper have single\nreceive antenna each. The users have individual transmit power constraints.\nThey also transmit jamming signals to improve the secrecy rates. We obtain the\nachievable perfect secrecy rate region by maximizing the worst case sum secrecy\nrate. We also obtain the corresponding transmit covariance matrices associated\nwith the message signals and the jamming signals. Numerical results that show\nthe impact of imperfect CSI on the achievable secrecy rate region are\npresented. \n\n"}
{"id": "1503.08196", "contents": "Title: Performance analysis of spatial smoothing schemes in the context of\n  large arrays Abstract: This paper adresses the statistical behaviour of spatial smoothing subspace\nDoA estimation schemes using a sensor array in the case where the number of\nobservations $N$ is significantly smaller than the number of sensors $M$, and\nthat the smoothing parameter $L$ is such that $M$ and $NL$ are of the same\norder of magnitude. This context is modelled by an asymptotic regime in which\n$NL$ and $M$ both converge towards $\\infty$ at the same rate. As in recent\nworks devoted to the study of (unsmoothed) subspace methods in the case where\n$M$ and $N$ are of the same order of magnitude, it is shown that it is still\npossible to derive improved DoA estimators termed as Generalized-MUSIC with\nspatial smoothing (G-MUSIC SS). The key ingredient of this work is a technical\nresult showing that the largest singular values and corresponding singular\nvectors of low rank deterministic perturbation of certain Gaussian block-Hankel\nlarge random matrices behave as if the entries of the latter random matrices\nwere independent identically distributed. This allows to conclude that when the\nnumber of sources and their DoA do not scale with $M,N,L,$ a situation\nmodelling widely spaced DoA scenarios, then both traditional and Generalized\nspatial smoothing subspace methods provide consistent DoA estimators whose\nconvergence speed is faster than $\\frac{1}{M}$. The case of DoA that are spaced\nof the order of a beamwidth, which models closely spaced sources, is also\nconsidered. It is shown that the convergence speed of G-MUSIC SS estimates is\nunchanged, but that it is no longer the case for MUSIC SS ones. \n\n"}
{"id": "1503.08453", "contents": "Title: Quantum walk, entanglement and thermodynamic laws Abstract: We consider an special dynamics of a quantum walk (QW) on a line. Initially,\nthe walker localized at the origin of the line with arbitrary chirality,\nevolves to an asymptotic stationary state. In this stationary state a\nmeasurement is performed and the state resulting from this measurement is used\nto start a second QW evolution to achieve a second asymptotic stationary state.\nIn previous works, we developed the thermodynamics associated with the\nentanglement between the coin and position degrees of freedom in the QW. Here\nwe study the application of the first and second laws of thermodynamics to the\nprocess between the two stationary states mentioned above. We show that: i) the\nentropy change has upper and lower bounds that are obtained analytically as a\nfunction of the initial conditions. ii) the energy change is associated to a\nheat-transfer process. \n\n"}
{"id": "1503.09039", "contents": "Title: Operational Region of D2D Communications for Enhancing Cellular Network\n  Performance Abstract: An important enabler towards the successful deployment of any new\nelement/feature to the cellular network is the investigation and\ncharacterization of the operational conditions where its introduction will\nenhance performance. Even though there has been significant research activity\non the potential of device-to-device (D2D) communications, there are currently\nno clear indications of whether D2D communications are actually able to provide\nbenefits for a wide range of operational conditions, thus justifying their\nintroduction to the system. This paper attempts to fill this gap by taking a\nstochastic geometry approach on characterizing the set (region) of operational\nconditions for which D2D communications enhance performance in terms of average\nuser rate. For the practically interesting case of a heavy loaded network, the\noperational region is provided in closed form as a function of a variety of\nparameters such as maximum D2D link distances and user densities, reflecting a\nwide range of operational conditions (points). It is shown that under the\nappropriate deployment scheme, D2D communications can indeed be beneficial not\nonly for the usually considered regime of \"proximal communications\" but to a\nwide range of operational conditions that include D2D link distances comparable\nto the distance to the cellular access point and considerably large user\ndensities. \n\n"}
{"id": "1504.02293", "contents": "Title: Spatial Domain Simultaneous Information and Power Transfer for MIMO\n  Channels Abstract: In this paper, we theoretically investigate a new technique for simultaneous\ninformation and power transfer (SWIPT) in multiple-input multiple-output (MIMO)\npoint-to-point with radio frequency energy harvesting capabilities. The\nproposed technique exploits the spatial decomposition of the MIMO channel and\nuses the eigenchannels either to convey information or to transfer energy. In\norder to generalize our study, we consider channel estimation error in the\ndecomposition process and the interference between the eigenchannels. An\noptimization problem that minimizes the total transmitted power subject to\nmaximum power per eigenchannel, information and energy constraints is\nformulated as a mixed-integer nonlinear program and solved to optimality using\nmixed-integer second-order cone programming. A near-optimal mixed-integer\nlinear programming solution is also developed with robust computational\nperformance. A polynomial complexity algorithm is further proposed for the\noptimal solution of the problem when no maximum power per eigenchannel\nconstraints are imposed. In addition, a low polynomial complexity algorithm is\ndeveloped for the power allocation problem with a given eigenchannel\nassignment, as well as a low-complexity heuristic for solving the eigenchannel\nassignment problem. \n\n"}
{"id": "1504.04244", "contents": "Title: Throughput Maximization in Multi-Hop Wireless Networks under Secrecy\n  Constraint Abstract: This paper analyzes the throughput of industrial communication networks under\na secrecy constraint. The proposed scenario is composed by sensors that measure\nsome relevant information of the plant that is first processed by aggregator\nnode and then sent to the control unit. The sensor measurements, their\ncommunication with the aggregetor and the information processing are all\nassumed perfect. To reach the control unit, the message may travel through\nrelay nodes, forming a multi-hop, wireless link. At every hop, eavesdropper\nnodes attempt to acquire the messages transmitted through the legitimate link.\nThe communication design problem posed here is how to maximize the multi-hop\nthroughput from the aggregator to the control unit by finding the best\ncombination of relay positions (i.e. hop length: short or long) and coding\nrates (i.e. high or low spectral efficiency) so that the secrecy constraint is\nsatisfied. Using a stochastic-geometry approach, we show that the optimal\nchoice of coding rate depends only on the path- loss exponent and is normally\nhigh while greater number of shorter hops are preferable to smaller number of\nlonger hops. For the scenarios of interest, we prove that the optimal\nthroughput subject to the secrecy constraint achieves the unconstrained optimal\nperformance if a feasible solution exists. \n\n"}
{"id": "1504.04617", "contents": "Title: Quantum Coding with Finite Resources Abstract: The quantum capacity of a memoryless channel is often used as a single figure\nof merit to characterize its ability to transmit quantum information\ncoherently. The capacity determines the maximal rate at which we can code\nreliably over asymptotically many uses of the channel. We argue that this\nasymptotic treatment is insufficient to the point of being irrelevant in the\nquantum setting where decoherence severely limits our ability to manipulate\nlarge quantum systems in the encoder and decoder. For all practical purposes we\nshould instead focus on the trade-off between three parameters: the rate of the\ncode, the number of coherent uses of the channel, and the fidelity of the\ntransmission. The aim is then to specify the region determined by allowed\ncombinations of these parameters. Towards this goal, we find approximate and\nexact characterizations of the region of allowed triplets for the qubit\ndephasing channel and for the erasure channel with classical post-processing\nassistance. In each case the region is parametrized by a second channel\nparameter, the quantum channel dispersion. In the process we also develop\nseveral general inner (achievable) and outer (converse) bounds on the coding\nregion that are valid for all finite-dimensional quantum channels and can be\ncomputed efficiently. Applied to the depolarizing channel, this allows us to\ndetermine a lower bound on the number of coherent uses of the channel necessary\nto witness super-additivity of the coherent information. \n\n"}
{"id": "1504.05110", "contents": "Title: Iteratively Reweighted $\\ell_1$ Approaches to Sparse Composite\n  Regularization Abstract: Motivated by the observation that a given signal $\\boldsymbol{x}$ admits\nsparse representations in multiple dictionaries $\\boldsymbol{\\Psi}_d$ but with\nvarying levels of sparsity across dictionaries, we propose two new algorithms\nfor the reconstruction of (approximately) sparse signals from noisy linear\nmeasurements. Our first algorithm, Co-L1, extends the well-known lasso\nalgorithm from the L1 regularizer $\\|\\boldsymbol{\\Psi x}\\|_1$ to composite\nregularizers of the form $\\sum_d \\lambda_d \\|\\boldsymbol{\\Psi}_d\n\\boldsymbol{x}\\|_1$ while self-adjusting the regularization weights\n$\\lambda_d$. Our second algorithm, Co-IRW-L1, extends the well-known\niteratively reweighted L1 algorithm to the same family of composite\nregularizers. We provide several interpretations of both algorithms: i)\nmajorization-minimization (MM) applied to a non-convex log-sum-type penalty,\nii) MM applied to an approximate $\\ell_0$-type penalty, iii) MM applied to\nBayesian MAP inference under a particular hierarchical prior, and iv)\nvariational expectation-maximization (VEM) under a particular prior with\ndeterministic unknown parameters. A detailed numerical study suggests that our\nproposed algorithms yield significantly improved recovery SNR when compared to\ntheir non-composite L1 and IRW-L1 counterparts. \n\n"}
{"id": "1504.05318", "contents": "Title: Compressive Random Access Using A Common Overloaded Control Channel Abstract: We introduce a \"one shot\" random access procedure where users can send a\nmessage without a priori synchronizing with the network. In this procedure a\ncommon overloaded control channel is used to jointly detect sparse user\nactivity and sparse channel profiles. The detected information is subsequently\nused to demodulate the data in dedicated frequency slots. We analyze the system\ntheoretically and provide a link between achievable rates and standard\ncompressing sensing estimates in terms of explicit expressions and scaling\nlaws. Finally, we support our findings with simulations in an LTE-A-like\nsetting allowing \"one shot\" sparse random access of 100 users in 1ms. \n\n"}
{"id": "1504.05616", "contents": "Title: Lossy Compression with Privacy Constraints: Optimality of Polar Codes Abstract: A lossy source coding problem with privacy constraint is studied in which two\ncorrelated discrete sources $X$ and $Y$ are compressed into a reconstruction\n$\\hat{X}$ with some prescribed distortion $D$. In addition, a privacy\nconstraint is specified as the equivocation between the lossy reconstruction\n$\\hat{X}$ and $Y$. This models the situation where a certain amount of source\ninformation from one user is provided as utility (given by the fidelity of its\nreconstruction) to another user or the public, while some other correlated part\nof the source information $Y$ must be kept private. In this work, we show that\npolar codes are able, possibly with the aid of time sharing, to achieve any\npoint in the optimal rate-distortion-equivocation region identified by\nYamamoto, thus providing a constructive scheme that obtains the optimal\ntradeoff between utility and privacy in this framework. \n\n"}
{"id": "1504.05756", "contents": "Title: A Large Deviations Approach to Secure Lossy Compression Abstract: We consider a Shannon cipher system for memoryless sources, in which\ndistortion is allowed at the legitimate decoder. The source is compressed using\na rate distortion code secured by a shared key, which satisfies a constraint on\nthe compression rate, as well as a constraint on the exponential rate of the\nexcess-distortion probability at the legitimate decoder. Secrecy is measured by\nthe exponential rate of the exiguous-distortion probability at the\neavesdropper, rather than by the traditional measure of equivocation. We define\nthe perfect secrecy exponent as the maximal exiguous-distortion exponent\nachievable when the key rate is unlimited. Under limited key rate, we prove\nthat the maximal achievable exiguous-distortion exponent is equal to the\nminimum between the average key rate and the perfect secrecy exponent, for a\nfairly general class of variable key rate codes. \n\n"}
{"id": "1504.05837", "contents": "Title: New Perspectives on Multiple Source Localization in Wireless Sensor\n  Networks Abstract: In this paper we address the challenging problem of multiple source\nlocalization in Wireless Sensor Networks (WSN). We develop an efficient\nstatistical algorithm, based on the novel application of Sequential Monte Carlo\n(SMC) sampler methodology, that is able to deal with an unknown number of\nsources given quantized data obtained at the fusion center from different\nsensors with imperfect wireless channels. We also derive the Posterior\nCram\\'er-Rao Bound (PCRB) of the source location estimate. The PCRB is used to\nanalyze the accuracy of the proposed SMC sampler algorithm and the impact that\nquantization has on the accuracy of location estimates of the sources.\nExtensive experiments show that the benefits of the proposed scheme in terms of\nthe accuracy of the estimation method that are required for model selection\n(i.e., the number of sources) and the estimation of the source characteristics\ncompared to the classical importance sampling method. \n\n"}
{"id": "1505.00273", "contents": "Title: A Survey of Stochastic Simulation and Optimization Methods in Signal\n  Processing Abstract: Modern signal processing (SP) methods rely very heavily on probability and\nstatistics to solve challenging SP problems. SP methods are now expected to\ndeal with ever more complex models, requiring ever more sophisticated\ncomputational inference techniques. This has driven the development of\nstatistical SP methods based on stochastic simulation and optimization.\nStochastic simulation and optimization algorithms are computationally intensive\ntools for performing statistical inference in models that are analytically\nintractable and beyond the scope of deterministic inference methods. They have\nbeen recently successfully applied to many difficult problems involving complex\nstatistical models and sophisticated (often Bayesian) statistical inference\ntechniques. This survey paper offers an introduction to stochastic simulation\nand optimization methods in signal and image processing. The paper addresses a\nvariety of high-dimensional Markov chain Monte Carlo (MCMC) methods as well as\ndeterministic surrogate methods, such as variational Bayes, the Bethe approach,\nbelief and expectation propagation and approximate message passing algorithms.\nIt also discusses a range of optimization methods that have been adopted to\nsolve stochastic problems, as well as stochastic methods for deterministic\noptimization. Subsequently, areas of overlap between simulation and\noptimization, in particular optimization-within-MCMC and MCMC-driven\noptimization are discussed. \n\n"}
{"id": "1505.01029", "contents": "Title: Can a many-nucleon structure be visible in bremsstrahlung emission\n  during $\\alpha$ decay? Abstract: We analyze if the nucleon structure of the $\\alpha$ decaying nucleus can be\nvisible in the experimental bremsstrahlung spectra of the emitted photons which\naccompany such a decay. We develop a new formalism of the bremsstrahlung model\ntaking into account distribution of nucleons in the $\\alpha$ decaying nuclear\nsystem. We conclude the following: (1) After inclusion of the nucleon structure\ninto the model the calculated bremsstrahlung spectrum is changed very slowly\nfor a majority of the $\\alpha$ decaying nuclei. However, we have observed that\nvisible changes really exist for the $^{106}{\\rm Te}$ nucleus\n($Q_{\\alpha}=4.29$ MeV, $T_{1/2}$=70 mks) even for the energy of the emitted\nphotons up to 1 MeV. This nucleus is a good candidate for future experimental\nstudy of this task. (2) Inclusion of the nucleon structure into the model\nincreases the bremsstrahlung probability of the emitted photons. (3) We find\nthe following tendencies for obtaining the nuclei, which have bremsstrahlung\nspectra more sensitive to the nucleon structure: (a) direction to nuclei with\nsmaller $Z$, (b) direction to nuclei with larger $Q_{\\alpha}$-values. \n\n"}
{"id": "1505.01110", "contents": "Title: Zero Error Coordination Abstract: In this paper, we consider a zero error coordination problem wherein the\nnodes of a network exchange messages to be able to perfectly coordinate their\nactions with the individual observations of each other. While previous works on\ncoordination commonly assume an asymptotically vanishing error, we assume\nexact, zero error coordination. Furthermore, unlike previous works that employ\nthe empirical or strong notions of coordination, we define and use a notion of\nset coordination. This notion of coordination bears similarities with the\nempirical notion of coordination. We observe that set coordination, in its\nspecial case of two nodes with a one-way communication link is equivalent with\nthe \"Hide and Seek\" source coding problem of McEliece and Posner. The Hide and\nSeek problem has known intimate connections with graph entropy, rate distortion\ntheory, Renyi mutual information and even error exponents. Other special cases\nof the set coordination problem relate to Witsenhausen's zero error rate and\nthe distributed computation problem. These connections motivate a better\nunderstanding of set coordination, its connections with empirical coordination,\nand its study in more general setups. This paper takes a first step in this\ndirection by proving new results for two node networks. \n\n"}
{"id": "1505.01462", "contents": "Title: Estimation from Pairwise Comparisons: Sharp Minimax Bounds with Topology\n  Dependence Abstract: Data in the form of pairwise comparisons arises in many domains, including\npreference elicitation, sporting competitions, and peer grading among others.\nWe consider parametric ordinal models for such pairwise comparison data\ninvolving a latent vector $w^* \\in \\mathbb{R}^d$ that represents the\n\"qualities\" of the $d$ items being compared; this class of models includes the\ntwo most widely used parametric models--the Bradley-Terry-Luce (BTL) and the\nThurstone models. Working within a standard minimax framework, we provide tight\nupper and lower bounds on the optimal error in estimating the quality score\nvector $w^*$ under this class of models. The bounds depend on the topology of\nthe comparison graph induced by the subset of pairs being compared via its\nLaplacian spectrum. Thus, in settings where the subset of pairs may be chosen,\nour results provide principled guidelines for making this choice. Finally, we\ncompare these error rates to those under cardinal measurement models and show\nthat the error rates in the ordinal and cardinal settings have identical\nscalings apart from constant pre-factors. \n\n"}
{"id": "1505.01858", "contents": "Title: Energy Efficiency and Sum Rate when Massive MIMO meets Device-to-Device\n  Communication Abstract: This paper considers a scenario of short-range communication, known as\ndevice-to-device (D2D) communication, where D2D users reuse the downlink\nresources of a cellular network to transmit directly to their corresponding\nreceivers. In addition, multiple antennas at the base station (BS) are used in\norder to simultaneously support multiple cellular users using multiuser or\nmassive MIMO. The network model considers a fixed number of cellular users and\nthat D2D users are distributed according to a homogeneous Poisson point process\n(PPP). Two metrics are studied, namely, average sum rate (ASR) and energy\nefficiency (EE). We derive tractable expressions and study the tradeoffs\nbetween the ASR and EE as functions of the number of BS antennas and density of\nD2D users for a given coverage area. \n\n"}
{"id": "1505.02776", "contents": "Title: Area law for fixed points of rapidly mixing dissipative quantum systems Abstract: We prove an area law with a logarithmic correction for the mutual information\nfor fixed points of local dissipative quantum system satisfying a rapid mixing\ncondition, under either of the following assumptions: the fixed point is pure,\nor the system is frustration free. \n\n"}
{"id": "1505.03257", "contents": "Title: Optimal linear estimation under unknown nonlinear transform Abstract: Linear regression studies the problem of estimating a model parameter\n$\\beta^* \\in \\mathbb{R}^p$, from $n$ observations\n$\\{(y_i,\\mathbf{x}_i)\\}_{i=1}^n$ from linear model $y_i = \\langle\n\\mathbf{x}_i,\\beta^* \\rangle + \\epsilon_i$. We consider a significant\ngeneralization in which the relationship between $\\langle \\mathbf{x}_i,\\beta^*\n\\rangle$ and $y_i$ is noisy, quantized to a single bit, potentially nonlinear,\nnoninvertible, as well as unknown. This model is known as the single-index\nmodel in statistics, and, among other things, it represents a significant\ngeneralization of one-bit compressed sensing. We propose a novel spectral-based\nestimation procedure and show that we can recover $\\beta^*$ in settings (i.e.,\nclasses of link function $f$) where previous algorithms fail. In general, our\nalgorithm requires only very mild restrictions on the (unknown) functional\nrelationship between $y_i$ and $\\langle \\mathbf{x}_i,\\beta^* \\rangle$. We also\nconsider the high dimensional setting where $\\beta^*$ is sparse ,and introduce\na two-stage nonconvex framework that addresses estimation challenges in high\ndimensional regimes where $p \\gg n$. For a broad class of link functions\nbetween $\\langle \\mathbf{x}_i,\\beta^* \\rangle$ and $y_i$, we establish minimax\nlower bounds that demonstrate the optimality of our estimators in both the\nclassical and high dimensional regimes. \n\n"}
{"id": "1505.03399", "contents": "Title: Identifiability in Blind Deconvolution with Subspace or Sparsity\n  Constraints Abstract: Blind deconvolution (BD), the resolution of a signal and a filter given their\nconvolution, arises in many applications. Without further constraints, BD is\nill-posed. In practice, subspace or sparsity constraints have been imposed to\nreduce the search space, and have shown some empirical success. However,\nexisting theoretical analysis on uniqueness in BD is rather limited. As an\neffort to address the still mysterious question, we derive sufficient\nconditions under which two vectors can be uniquely identified from their\ncircular convolution, subject to subspace or sparsity constraints. These\nsufficient conditions provide the first algebraic sample complexities for BD.\nWe first derive a sufficient condition that applies to almost all bases or\nframes. For blind deconvolution of vectors in $\\mathbb{C}^n$, with two subspace\nconstraints of dimensions $m_1$ and $m_2$, the required sample complexity is\n$n\\geq m_1m_2$. Then we impose a sub-band structure on one basis, and derive a\nsufficient condition that involves a relaxed sample complexity $n\\geq\nm_1+m_2-1$, which we show to be optimal. We present the extensions of these\nresults to BD with sparsity constraints or mixed constraints, with the sparsity\nlevel replacing the subspace dimension. The cost for the unknown support in\nthis case is an extra factor of 2 in the sample complexity. \n\n"}
{"id": "1505.05481", "contents": "Title: Expansion Coding for Channel and Source Coding Abstract: A general method of coding over expansion is proposed,which allows one to\nreduce the highly non-trivial problems of coding over analog channels and\ncompressing analog sources to a set of much simpler subproblems, coding over\ndiscrete channels and compressing discrete sources. More specifically, the\nfocus of this paper is on the additive exponential noise (AEN) channel, and\nlossy compression of exponential sources. Taking advantage of the essential\ndecomposable property of these channels (sources), the proposed expansion\nmethod allows for mapping of these problems to coding over parallel channels\n(respectively, sources), where each level is modeled as an independent coding\nproblem over discrete alphabets. Any feasible solution to the resulting\noptimization problem after expansion corresponds to an achievable scheme of the\noriginal problem. Utilizing this mapping, even for the cases where the optimal\nsolutions are difficult to characterize, it is shown that the expansion coding\nscheme still performs well with appropriate choices of parameters. More\nspecifically, theoretical analysis and numerical results reveal that expansion\ncoding achieves the capacity of AEN channel in the high SNR regime. It is also\nshown that for lossy compression, the achievable rate distortion pair by\nexpansion coding approaches to the Shannon limit in the low distortion region.\nRemarkably, by using capacity-achieving codes with low encoding and decoding\ncomplexity that are originally designed for discrete alphabets, for instance\npolar codes, the proposed expansion coding scheme allows for designing\nlow-complexity analog channel and source codes. \n\n"}
{"id": "1505.07515", "contents": "Title: Communication Efficient Secret Sharing Abstract: A secret sharing scheme is a method to store information securely and\nreliably. Particularly, in a threshold secret sharing scheme, a secret is\nencoded into $n$ shares, such that any set of at least $t_1$ shares suffice to\ndecode the secret, and any set of at most $t_2 < t_1$ shares reveal no\ninformation about the secret. Assuming that each party holds a share and a user\nwishes to decode the secret by receiving information from a set of parties; the\nquestion we study is how to minimize the amount of communication between the\nuser and the parties. We show that the necessary amount of communication,\ntermed \"decoding bandwidth\", decreases as the number of parties that\nparticipate in decoding increases. We prove a tight lower bound on the decoding\nbandwidth, and construct secret sharing schemes achieving the bound.\nParticularly, we design a scheme that achieves the optimal decoding bandwidth\nwhen $d$ parties participate in decoding, universally for all $t_1 \\le d \\le\nn$. The scheme is based on Shamir's secret sharing scheme and preserves its\nsimplicity and efficiency. In addition, we consider secure distributed storage\nwhere the proposed communication efficient secret sharing schemes further\nimprove disk access complexity during decoding. \n\n"}
{"id": "1506.00557", "contents": "Title: From CELSIUS to COSY: on the observation of a dibaryon resonance Abstract: Using the high-quality beam of storage rings in combination with a pellet\ntarget and the hermetic WASA detector covering practically the full solid angle\nthe two-pion production in nucleon-nucleon collisions has been systematically\nstudied by exclusive and kinematically complete measurements -- first at\nCELSIUS and subsequently at COSY. These measurements resulted in a detailed\nunderstanding of the two-pion production mechanism by $t$-channel meson\nexchange. The investigation of the ABC effect in double-pionic fusion reactions\nlead the trace to the observation of a narrow dibaryon resonance with $I(J^P) =\n0(3^+)$ about 80 MeV below the nominal mass of the conventional $\\Delta\\Delta$\nsystem. New neutron-proton scattering data, taken with polarized beam at COSY,\nproduce a pole in the coupled $^3D_3$ - $^3G_3$ partial waves at\n($2380\\pm10~-~i~40\\pm5$) MeV establishing thus the first observation of a\ngenuine $s$-channel dibaryon resonance. \n\n"}
{"id": "1506.02557", "contents": "Title: Variational Dropout and the Local Reparameterization Trick Abstract: We investigate a local reparameterizaton technique for greatly reducing the\nvariance of stochastic gradients for variational Bayesian inference (SGVB) of a\nposterior over model parameters, while retaining parallelizability. This local\nreparameterization translates uncertainty about global parameters into local\nnoise that is independent across datapoints in the minibatch. Such\nparameterizations can be trivially parallelized and have variance that is\ninversely proportional to the minibatch size, generally leading to much faster\nconvergence. Additionally, we explore a connection with dropout: Gaussian\ndropout objectives correspond to SGVB with local reparameterization, a\nscale-invariant prior and proportionally fixed posterior variance. Our method\nallows inference of more flexibly parameterized posteriors; specifically, we\npropose variational dropout, a generalization of Gaussian dropout where the\ndropout rates are learned, often leading to better models. The method is\ndemonstrated through several experiments. \n\n"}
{"id": "1506.02751", "contents": "Title: Guaranteed Blind Sparse Spikes Deconvolution via Lifting and Convex\n  Optimization Abstract: Neural recordings, returns from radars and sonars, images in astronomy and\nsingle-molecule microscopy can be modeled as a linear superposition of a small\nnumber of scaled and delayed copies of a band-limited or diffraction-limited\npoint spread function, which is either determined by the nature or designed by\nthe users; in other words, we observe the convolution between a point spread\nfunction and a sparse spike signal with unknown amplitudes and delays. While it\nis of great interest to accurately resolve the spike signal from as few samples\nas possible, however, when the point spread function is not known a priori,\nthis problem is terribly ill-posed. This paper proposes a convex optimization\nframework to simultaneously estimate the point spread function as well as the\nspike signal, by mildly constraining the point spread function to lie in a\nknown low-dimensional subspace. By applying the lifting trick, we obtain an\nunderdetermined linear system of an ensemble of signals with joint spectral\nsparsity, to which atomic norm minimization is applied. Under mild randomness\nassumptions of the low-dimensional subspace as well as a separation condition\nof the spike signal, we prove the proposed algorithm, dubbed as AtomicLift, is\nguaranteed to recover the spike signal up to a scaling factor as soon as the\nnumber of samples is large enough. The extension of AtomicLift to handle noisy\nmeasurements is also discussed. Numerical examples are provided to validate the\neffectiveness of the proposed approaches. \n\n"}
{"id": "1506.03394", "contents": "Title: Spatial Self-Interference Isolation for In-Band Full-Duplex Wireless: A\n  Degrees-of-Freedom Analysis Abstract: The challenge to in-band full-duplex wireless communication is managing\nself-interference. Many designs have employed spatial isolation mechanisms,\nsuch as shielding or multi-antenna beamforming, to isolate the\nself-interference wave from the receiver. Such spatial isolation methods are\neffective, but by confining the transmit and receive signals to a subset of the\navailable space, the full spatial resources of the channel be under-utilized,\nexpending a cost that may nullify the net benefit of operating in full-duplex\nmode. In this paper we leverage an antenna-theory-based channel model to\nanalyze the spatial degrees of freedom available to a full-duplex capable base\nstation, and observe that whether or not spatial isolation out-performs\ntime-division (i.e. half-duplex) depends heavily on the geometric distribution\nof scatterers. Unless the angular spread of the objects that scatter to the\nintended users is overlapped by the spread of objects that backscatter to the\nbase station, then spatial isolation outperforms time division, otherwise time\ndivision may be optimal. \n\n"}
{"id": "1506.04283", "contents": "Title: Series Representation of Modified Bessel Functions and Its Application\n  in AF Cooperative systems Abstract: Using fractional-calculus mathematics, a novel approach is introduced to\nrewrite modified Bessel functions in series form using simple elementary\nfunctions. Then, a statistical characterization of the total receive-SNR at the\ndestination, corresponding to the source-relay-destination and the\nsource-destination link SNR, is provided for a general relaying scenario, in\nwhich the destination exploits a maximum ratio combining (MRC) receiver. Using\nthe novel statistical model for the total receive SNR at the destination,\naccurate and simple analytical expressions for the outage probability, the bit\nerror probability and the ergodic capacity are obtained. \n\n"}
{"id": "1506.05547", "contents": "Title: Quantum Gaussian Channels with Weak Measurements Abstract: In this paper we perform a novel analysis of quantum Gaussian channels in the\ncontext of weak measurements. Suppose Alice sends classical information to Bob\nusing a quantum channel. Suppose Bob is allowed to use only weak measurements,\nwhat would be the channel capacity? We formulate weak measurement theory in\nthese terms and discuss the above question. \n\n"}
{"id": "1506.06114", "contents": "Title: Secure Degrees of Freedom of One-hop Wireless Networks with No\n  Eavesdropper CSIT Abstract: We consider three channel models: the wiretap channel with $M$ helpers, the\n$K$-user multiple access wiretap channel, and the $K$-user interference channel\nwith an external eavesdropper, when no eavesdropper's channel state information\n(CSI) is available at the transmitters. In each case, we establish the optimal\nsum secure degrees of freedom (s.d.o.f.) by providing achievable schemes and\nmatching converses. We show that the unavailability of the eavesdropper's CSIT\ndoes not reduce the s.d.o.f. of the wiretap channel with helpers. However,\nthere is loss in s.d.o.f. for both the multiple access wiretap channel and the\ninterference channel with an external eavesdropper. In particular, we show that\nin the absence of eavesdropper's CSIT, the $K$-user multiple access wiretap\nchannel reduces to a wiretap channel with $(K-1)$ helpers from a sum s.d.o.f.\nperspective, and the optimal sum s.d.o.f. reduces from\n$\\frac{K(K-1)}{K(K-1)+1}$ to $\\frac{K-1}{K}$. For the interference channel with\nan external eavesdropper, the optimal sum s.d.o.f. decreases from\n$\\frac{K(K-1)}{2K-1}$ to $\\frac{K-1}{2}$ in the absence of the eavesdropper's\nCSIT. Our results show that the lack of eavesdropper's CSIT does not have a\nsignificant impact on the optimal s.d.o.f. for any of the three channel models,\nespecially when the number of users is large. This implies that physical layer\nsecurity can be made robust to the unavailability of eavesdropper CSIT at high\nsignal to noise ratio (SNR) regimes by careful modification of the achievable\nschemes as demonstrated in this paper. \n\n"}
{"id": "1506.06801", "contents": "Title: Matrix Poincar\\'e, \\Phi-Sobolev inequalities, and quantum ensembles Abstract: Sobolev-type inequalities have been extensively studied in the frameworks of\nreal-valued functions and non-commutative $\\mathbb{L}_p$ spaces, and have\nproven useful in bounding the time evolution of classical/quantum Markov\nprocesses, among many other applications. In this paper, we consider yet\nanother fundamental setting - matrix-valued functions - and prove new\nSobolev-type inequalities for them. Our technical contributions are two-fold:\n(i) we establish a series of matrix Poincar\\'e inequalities for separably\nconvex functions and general functions with Gaussian unitary ensembles inputs;\nand (ii) we derive $\\Phi$-Sobolev inequalities for matrix-valued functions\ndefined on Boolean hypercubes and for those with Gaussian distributions. Our\nresults recover the corresponding classical inequalities (i.e.~real-valued\nfunctions) when the matrix has one dimension. Finally, as an application of our\ntechnical outcomes, we derive the upper bounds for a fundamental entropic\nquantity - the Holevo quantity - in quantum information science since\nclassical-quantum channels are a special instance of matrix-valued functions.\nThis is obtained through the equivalence between the constants in the strong\ndata processing inequality and the $\\Phi$-Sobolev inequality. \n\n"}
{"id": "1506.07902", "contents": "Title: Minimax Structured Normal Means Inference Abstract: We provide a unified treatment of a broad class of noisy structure recovery\nproblems, known as structured normal means problems. In this setting, the goal\nis to identify, from a finite collection of Gaussian distributions with\ndifferent means, the distribution that produced some observed data. Recent work\nhas studied several special cases including sparse vectors, biclusters, and\ngraph-based structures. We establish nearly matching upper and lower bounds on\nthe minimax probability of error for any structured normal means problem, and\nwe derive an optimality certificate for the maximum likelihood estimator, which\ncan be applied to many instantiations. We also consider an experimental design\nsetting, where we generalize our minimax bounds and derive an algorithm for\ncomputing a design strategy with a certain optimality property. We show that\nour results give tight minimax bounds for many structure recovery problems and\nconsider some consequences for interactive sampling. \n\n"}
{"id": "1506.08159", "contents": "Title: Near-Optimal Estimation of Simultaneously Sparse and Low-Rank Matrices\n  from Nested Linear Measurements Abstract: In this paper we consider the problem of estimating simultaneously low-rank\nand row-wise sparse matrices from nested linear measurements where the linear\noperator consists of the product of a linear operator $\\mathcal{W}$ and a\nmatrix $\\mathbf{\\varPsi}$. Leveraging the nested structure of the measurement\noperator, we propose a computationally efficient two-stage algorithm for\nestimating the simultaneously structured target matrix. Assuming that\n$\\mathcal{W}$ is a restricted isometry for low-rank matrices and\n$\\mathbf{\\varPsi}$ is a restricted isometry for row-wise sparse matrices, we\nestablish an accuracy guarantee that holds uniformly for all sufficiently\nlow-rank and row-wise sparse matrices with high probability. Furthermore, using\nstandard tools from information theory, we establish a minimax lower bound for\nestimation of simultaneously low-rank and row-wise sparse matrices from linear\nmeasurements that need not be nested. The accuracy bounds established for the\nalgorithm, that also serve as a minimax upper bound, differ from the derived\nminimax lower bound merely by a polylogarithmic factor of the dimensions.\nTherefore, the proposed algorithm is nearly minimax optimal. We also discuss\nsome applications of the proposed observation model and evaluate our algorithm\nthrough numerical simulation. \n\n"}
{"id": "1506.09080", "contents": "Title: Multihadron production dynamics exploring the energy balance in hadronic\n  and nuclear collisions Abstract: The multihadron production in nucleus-nucleus collisions and its\ninterrelation with that in (anti)proton-proton interactions are studied by\nexploring the charged particle mean multiplicity collision-energy and\ncentrality dependencies in the measurements to date. The study is performed in\nthe framework of the recently proposed effective-energy approach which, under\nthe proper scaling of the collision energy, combines the constituent quark\npicture with Landau relativistic hydrodynamics counting for the\ncentrality-defined effective energy of participants and relating different\ntypes of collisions. Within this approach, the multiplicity energy dependence\nand the pseudorapidity spectra from the most central nuclear collisions are\nwell reproduced. The study of the multiplicity centrality dependence reveals a\nnew scaling between the measured pseudorapidity spectra and the calculations.\nBy means of this scaling, called the energy balanced limiting fragmentation\nscaling, one reproduces the pseudorapidity spectra for all centralities. The\nscaling elucidates some differences in the multiplicity and midrapidity density\ncentrality dependence obtained at RHIC and LHC. These findings reveal an\ninherent similarity in the multiplicity energy dependence from the most central\ncollisions and centrality data. A new regime in heavy-ion collisions to occur\nat about a TeV energy is indicated, similar to that observed in the earlier\nstudies of the midrapidity densities. Predictions are made for the mean\nmultiplicities to be measured in proton-proton and heavy-ion collisions at the\nLHC. \n\n"}
{"id": "1507.00903", "contents": "Title: Constrained Quantum Tomography of Semi-Algebraic Sets with Applications\n  to Low-Rank Matrix Recovery Abstract: We analyze quantum state tomography in scenarios where measurements and\nstates are both constrained. States are assumed to live in a semi-algebraic\nsubset of state space and measurements are supposed to be rank-one POVMs,\npossibly with additional constraints. Specifically, we consider sets of von\nNeumann measurements and sets of local observables. We provide upper bounds on\nthe minimal number of measurement settings or outcomes that are required for\ndiscriminating all states within the given set. The bounds exploit tools from\nreal algebraic geometry and lead to generic results that do not only show the\nexistence of good measurements but guarantee that almost all measurements with\nthe same dimension characteristic perform equally well.\n  In particular, we show that on an $n$-dimensional Hilbert space any two\nstates of a semi-algebraic subset can be discriminated by $k$ generic von\nNeumann measurements if $k(n-1)$ is larger than twice the dimension of the\nsubset. In case the subset is given by states of rank at most $r$, we show that\n$k$ generic von Neumann measurements suffice to discriminate any two states\nprovided that $k(n-1)>4r(n-r)-2$. We obtain corresponding results for low-rank\nmatrix recovery of hermitian matrices in the scenario where the linear\nmeasurement mapping is induced by tight frames. \n\n"}
{"id": "1507.01255", "contents": "Title: Universal Decoding for Source-Channel Coding with Side Information Abstract: We consider a setting of Slepian--Wolf coding, where the random bin of the\nsource vector undergoes channel coding, and then decoded at the receiver, based\non additional side information, correlated to the source. For a given\ndistribution of the randomly selected channel codewords, we propose a universal\ndecoder that depends on the statistics of neither the correlated sources nor\nthe channel, assuming first that they are both memoryless. Exact analysis of\nthe random-binning/random-coding error exponent of this universal decoder shows\nthat it is the same as the one achieved by the optimal maximum a-posteriori\n(MAP) decoder. Previously known results on universal Slepian-Wolf source\ndecoding, universal channel decoding, and universal source-channel decoding,\nare all obtained as special cases of this result. Subsequently, we further\ngeneralize the results in several directions, including: (i) finite-state\nsources and finite-state channels, along with a universal decoding metric that\nis based on Lempel-Ziv parsing, (ii) arbitrary sources and channels, where the\nuniversal decoding is with respect to a given class of decoding metrics, and\n(iii) full (symmetric) Slepian-Wolf coding, where both source streams are\nseparately fed into random-binning source encoders, followed by random channel\nencoders, which are then jointly decoded by a universal decoder. \n\n"}
{"id": "1507.01307", "contents": "Title: Subspace-Sparse Representation Abstract: Given an overcomplete dictionary $A$ and a signal $b$ that is a linear\ncombination of a few linearly independent columns of $A$, classical sparse\nrecovery theory deals with the problem of recovering the unique sparse\nrepresentation $x$ such that $b = A x$. It is known that under certain\nconditions on $A$, $x$ can be recovered by the Basis Pursuit (BP) and the\nOrthogonal Matching Pursuit (OMP) algorithms. In this work, we consider the\nmore general case where $b$ lies in a low-dimensional subspace spanned by some\ncolumns of $A$, which are possibly linearly dependent. In this case, the\nsparsest solution $x$ is generally not unique, and we study the problem that\nthe representation $x$ identifies the subspace, i.e. the nonzero entries of $x$\ncorrespond to dictionary atoms that are in the subspace. Such a representation\n$x$ is called subspace-sparse. We present sufficient conditions for\nguaranteeing subspace-sparse recovery, which have clear geometric\ninterpretations and explain properties of subspace-sparse recovery. We also\nshow that the sufficient conditions can be satisfied under a randomized model.\nOur results are applicable to the traditional sparse recovery problem and we\nget conditions for sparse recovery that are less restrictive than the canonical\nmutual coherent condition. We also use the results to analyze the sparse\nrepresentation based classification (SRC) method, for which we get conditions\nto show its correctness. \n\n"}
{"id": "1507.01728", "contents": "Title: Equidistant subspace codes Abstract: In this paper we study equidistant subspace codes, i.e. subspace codes with\nthe property that each two distinct codewords have the same distance. We\nprovide an almost complete classification of such codes under the assumption\nthat the cardinality of the ground field is large enough. More precisely, we\nprove that for most values of the parameters, an equidistant code of maximum\ncardinality is either a sunflower or the orthogonal of a sunflower. We also\nstudy equidistant codes with extremal parameters, and establish general\nproperties of equidistant codes that are not sunflowers. Finally, we propose a\nsystematic construction of equidistant codes based on our previous construction\nof partial spread codes, and provide an efficient decoding algorithm. \n\n"}
{"id": "1507.02826", "contents": "Title: Comments On \"Multipath Matching Pursuit\" by Kwon, Wang and Shim Abstract: Straightforward combination of tree search with matching pursuits, which was\nsuggested in 2001 by Cotter and Rao, and then later developed by some other\nauthors, has been revisited recently as multipath matching pursuit (MMP). In\nthis comment, we would like to point out some major issues regarding this\npublication. First, the idea behind MMP is not novel, and the related\nliterature has not been properly referenced. MMP has not been compared to\nclosely related algorithms such as A* orthogonal matching pursuit (A*OMP). The\ntheoretical analyses do ignore the pruning strategies applied by the authors in\npractice. All these issues have the potential to mislead the reader and lead to\nmisinterpretation of the results. With this short paper, we intend to clarify\nthe relation of MMP to existing literature in the area and compare its\nperformance with A*OMP. \n\n"}
{"id": "1507.03769", "contents": "Title: Moments of $\\phi$ meson spectral functions in vacuum and nuclear matter Abstract: Moments of the $\\phi$ meson spectral function in vacuum and in nuclear matter\nare analyzed, combining a model based on chiral SU(3) effective field theory\n(with kaonic degrees of freedom) and finite-energy QCD sum rules. For the\nvacuum we show that the spectral density is strongly constrained by a recent\naccurate measurement of the $e^+ e^- \\to K^+ K^-$ cross section. In nuclear\nmatter the $\\phi$ spectrum is modified by interactions of the decay kaons with\nthe surrounding nuclear medium, leading to a significant broadening and an\nasymmetric deformation of the $\\phi$ meson peak. We demonstrate that both in\nvacuum and nuclear matter, the first two moments of the spectral function are\ncompatible with finite-energy QCD sum rules. A brief discussion of the\nnext-higher spectral moment involving strange four-quark condensates is also\npresented. \n\n"}
{"id": "1507.03843", "contents": "Title: Minimum Energy to Send $k$ Bits Over Multiple-Antenna Fading Channels Abstract: This paper investigates the minimum energy required to transmit $k$\ninformation bits with a given reliability over a multiple-antenna Rayleigh\nblock-fading channel, with and without channel state information (CSI) at the\nreceiver. No feedback is assumed. It is well known that the ratio between the\nminimum energy per bit and the noise level converges to $-1.59$ dB as $k$ goes\nto infinity, regardless of whether CSI is available at the receiver or not.\nThis paper shows that lack of CSI at the receiver causes a slowdown in the\nspeed of convergence to $-1.59$ dB as $k\\to\\infty$ compared to the case of\nperfect receiver CSI. Specifically, we show that, in the no-CSI case, the gap\nto $-1.59$ dB is proportional to $((\\log k) /k)^{1/3}$, whereas when perfect\nCSI is available at the receiver, this gap is proportional to $1/\\sqrt{k}$. In\nboth cases, the gap to $-1.59$ dB is independent of the number of transmit\nantennas and of the channel's coherence time. Numerically, we observe that,\nwhen the receiver is equipped with a single antenna, to achieve an energy per\nbit of $ - 1.5$ dB in the no-CSI case, one needs to transmit at least $7\\times\n10^7$ information bits, whereas $6\\times 10^4$ bits suffice for the case of\nperfect CSI at the receiver. \n\n"}
{"id": "1507.03951", "contents": "Title: Bottomonia suppression in 2.76 TeV Pb-Pb collisions Abstract: We compute the QGP suppression of Upsilon(1s), Upsilon(2s), Upsilon(3s),\nchi_b1, and chi_b2 states in sqrt(s_NN)=2.76 TeV Pb-Pb collisions. Using the\nsuppression of each of these states, we estimate the inclusive R_AA for the\nUpsilon(1s) and Upsilon(2s) states as a function of N_part, y, and p_T\nincluding the effect of excited state feed down. We find that our model\nprovides a reasonable description of preliminary CMS results for the N_part-,\ny-, and p_T-dependence of R_AA for both the Upsilon(1s) and Upsilon(2s).\nComparing to our previous model predictions, we find a flatter rapidity\ndependence, thereby reducing some of the tension between our model and ALICE\nforward-rapidity results for Upsilon(1s) suppression. \n\n"}
{"id": "1507.04136", "contents": "Title: Taming the Basel Leverage Cycle Abstract: Effective risk control must make a tradeoff between the microprudential risk\nof exogenous shocks to individual institutions and the macroprudential risks\ncaused by their systemic interactions. We investigate a simple dynamical model\nfor understanding this tradeoff, consisting of a bank with a leverage target\nand an unleveraged fundamental investor subject to exogenous noise with\nclustered volatility. The parameter space has three regions: (i) a stable\nregion, where the system always reaches a fixed point equilibrium; (ii) a\nlocally unstable region, characterized by cycles and chaotic behavior; and\n(iii) a globally unstable region. A crude calibration of parameters to data\nputs the model in region (ii). In this region there is a slowly building price\nbubble, resembling a \"Great Moderation\", followed by a crash, with a period of\napproximately 10-15 years, which we dub the \"Basel leverage cycle\". We propose\na criterion for rating macroprudential policies based on their ability to\nminimize risk for a given average leverage. We construct a one parameter family\nof leverage policies that allows us to vary from the procyclical policies of\nBasel II or III, in which leverage decreases when volatility increases, to\ncountercyclical policies in which leverage increases when volatility increases.\nWe find the best policy depends critically on three parameters: The average\nleverage used by the bank; the relative size of the bank and the\nfundamentalist, and the amplitude of the exogenous noise. Basel II is optimal\nwhen the exogenous noise is high, the bank is small and leverage is low; in the\nopposite limit where the bank is large or leverage is high the optimal policy\nis closer to constant leverage. We also find that systemic risk can be\ndramatically decreased by lowering the leverage target adjustment speed of the\nbanks. \n\n"}
{"id": "1507.05488", "contents": "Title: The study of the thermal neutron flux in the deep underground laboratory\n  DULB-4900 Abstract: We report on the study of thermal neutron flux using monitors based on\nmixture of ZnS(Ag) and LiF enriched with a lithium-6 isotope at the deep\nunderground laboratory DULB-4900 at the Baksan Neutrino Observatory. An annual\nmodulation of thermal neutron flux in DULB-4900 is observed. Experimental\nevidences were obtained of correlation between the long-term thermal neutron\nflux variations and the absolute humidity of the air in laboratory. The\namplitude of the modulation exceed 5\\% of total neutron flux. \n\n"}
{"id": "1507.05533", "contents": "Title: Secure Partial Repair in Wireless Caching Networks with Broadcast\n  Channels Abstract: We study security in partial repair in wireless caching networks where parts\nof the stored packets in the caching nodes are susceptible to be erased. Let us\ndenote a caching node that has lost parts of its stored packets as a sick\ncaching node and a caching node that has not lost any packet as a healthy\ncaching node. In partial repair, a set of caching nodes (among sick and healthy\ncaching nodes) broadcast information to other sick caching nodes to recover the\nerased packets. The broadcast information from a caching node is assumed to be\nreceived without any error by all other caching nodes. All the sick caching\nnodes then are able to recover their erased packets, while using the broadcast\ninformation and the nonerased packets in their storage as side information. In\nthis setting, if an eavesdropper overhears the broadcast channels, it might\nobtain some information about the stored file. We thus study secure partial\nrepair in the senses of information-theoretically strong and weak security. In\nboth senses, we investigate the secrecy caching capacity, namely, the maximum\namount of information which can be stored in the caching network such that\nthere is no leakage of information during a partial repair process. We then\ndeduce the strong and weak secrecy caching capacities, and also derive the\nsufficient finite field sizes for achieving the capacities. Finally, we propose\noptimal secure codes for exact partial repair, in which the recovered packets\nare exactly the same as erased packets. \n\n"}
{"id": "1507.05994", "contents": "Title: Massive MIMO in Real Propagation Environments: Do All Antennas\n  Contribute Equally? Abstract: Massive MIMO can greatly increase both spectral and transmit-energy\nefficiency. This is achieved by allowing the number of antennas and RF chains\nto grow very large. However, the challenges include high system complexity and\nhardware energy consumption. Here we investigate the possibilities to reduce\nthe required number of RF chains, by performing antenna selection. While this\napproach is not a very effective strategy for theoretical independent Rayleigh\nfading channels, a substantial reduction in the number of RF chains can be\nachieved for real massive MIMO channels, without significant performance loss.\nWe evaluate antenna selection performance on measured channels at 2.6 GHz,\nusing a linear and a cylindrical array, both having 128 elements. Sum-rate\nmaximization is used as the criterion for antenna selection. A selection scheme\nbased on convex optimization is nearly optimal and used as a benchmark. The\nachieved sum-rate is compared with that of a very simple scheme that selects\nthe antennas with the highest received power. The power-based scheme gives\nperformance close to the convex optimization scheme, for the measured channels.\nThis observation indicates a potential for significant reductions of massive\nMIMO implementation complexity, by reducing the number of RF chains and\nperforming antenna selection using simple algorithms. \n\n"}
{"id": "1507.07395", "contents": "Title: Almost universal codes achieving ergodic MIMO capacity within a constant\n  gap Abstract: This work addresses the question of achieving capacity with lattice codes in\nmulti-antenna block fading channels when the number of fading blocks tends to\ninfinity. A design criterion based on the normalized minimum determinant is\nproposed for division algebra multiblock space-time codes over fading channels;\nthis plays a similar role to the Hermite invariant for Gaussian channels. It is\nshown that this criterion is sufficient to guarantee transmission rates within\na constant gap from capacity both for slow fading channels and ergodic fading\nchannels. This performance is achieved both under maximum likelihood decoding\nand naive lattice decoding. In the case of independent identically distributed\nRayleigh fading, it is also shown that the error probability vanishes\nexponentially fast. In contrast to the standard approach in the literature\nwhich employs random lattice ensembles, the existence results in this paper are\nderived from number theory. First the gap to capacity is shown to depend on the\ndiscriminant of the chosen division algebra; then class field theory is applied\nto build families of algebras with small discriminants. The key element in the\nconstruction is the choice of a sequence of division algebras whose centers are\nnumber fields with small root discriminants. \n\n"}
{"id": "1507.07628", "contents": "Title: LP-decodable multipermutation codes Abstract: In this paper, we introduce a new way of constructing and decoding\nmultipermutation codes. Multipermutations are permutations of a multiset that\ngenerally consist of duplicate entries. We first introduce a class of binary\nmatrices called multipermutation matrices, each of which corresponds to a\nunique and distinct multipermutation. By enforcing a set of linear constraints\non these matrices, we define a new class of codes that we term LP-decodable\nmultipermutation codes. In order to decode these codes using a linear program\n(LP), thereby enabling soft decoding, we characterize the convex hull of\nmultipermutation matrices. This characterization allows us to relax the coding\nconstraints to a polytope and to derive two LP decoding problems. These two\nproblems are respectively formulated by relaxing the maximum likelihood\ndecoding problem and the minimum Chebyshev distance decoding problem.\n  Because these codes are non-linear, we also study efficient encoding and\ndecoding algorithms. We first describe an algorithm that maps consecutive\nintegers, one by one, to an ordered list of multipermutations. Based on this\nalgorithm, we develop an encoding algorithm for a code proposed by Shieh and\nTsai, a code that falls into our class of LP-decodable multipermutation codes.\nRegarding decoding algorithms, we propose an efficient distributed decoding\nalgorithm based on the alternating direction method of multipliers (ADMM).\nFinally, we observe from simulation results that the soft decoding techniques\nwe introduce can significantly outperform hard decoding techniques that are\nbased on quantized channel outputs. \n\n"}
{"id": "1507.08015", "contents": "Title: On Massive MIMO Physical Layer Cryptosystem Abstract: In this paper, we present a zero-forcing (ZF) attack on the physical layer\ncryptography scheme based on massive multiple-input multiple-output (MIMO). The\nscheme uses singular value decomposition (SVD) precoder. We show that the\neavesdropper can decrypt/decode the information data under the same condition\nas the legitimate receiver. We then study the advantage for decoding by the\nlegitimate user over the eavesdropper in a generalized scheme using an\narbitrary precoder at the transmitter. On the negative side, we show that if\nthe eavesdropper uses a number of receive antennas much larger than the number\nof legitimate user antennas, then there is no advantage, independent of the\nprecoding scheme employed at the transmitter. On the positive side, for the\ncase where the adversary is limited to have the same number of antennas as\nlegitimate users, we give an $\\mathcal{O}\\left(n^2\\right)$ upper bound on the\nadvantage and show that this bound can be approached using an inverse precoder. \n\n"}
{"id": "1508.00256", "contents": "Title: Volume of Metric Balls in High-Dimensional Complex Grassmann Manifolds Abstract: Volume of metric balls relates to rate-distortion theory and packing bounds\non codes. In this paper, the volume of balls in complex Grassmann manifolds is\nevaluated for an arbitrary radius. The ball is defined as a set of hyperplanes\nof a fixed dimension with reference to a center of possibly different\ndimension, and a generalized chordal distance for unequal dimensional subspaces\nis used. First, the volume is reduced to one-dimensional integral\nrepresentation. The overall problem boils down to evaluating a determinant of a\nmatrix of the same size as the subspace dimensionality. Interpreting this\ndeterminant as a characteristic function of the Jacobi ensemble, an asymptotic\nanalysis is carried out. The obtained asymptotic volume is moreover refined\nusing moment-matching techniques to provide a tighter approximation in\nfinite-size regimes. Lastly, the pertinence of the derived results is shown by\nrate-distortion analysis of source coding on Grassmann manifolds. \n\n"}
{"id": "1508.00536", "contents": "Title: Estimating Mutual Information by Local Gaussian Approximation Abstract: Estimating mutual information (MI) from samples is a fundamental problem in\nstatistics, machine learning, and data analysis. Recently it was shown that a\npopular class of non-parametric MI estimators perform very poorly for strongly\ndependent variables and have sample complexity that scales exponentially with\nthe true MI. This undesired behavior was attributed to the reliance of those\nestimators on local uniformity of the underlying (and unknown) probability\ndensity function. Here we present a novel semi-parametric estimator of mutual\ninformation, where at each sample point, densities are {\\em locally}\napproximated by a Gaussians distribution. We demonstrate that the estimator is\nasymptotically unbiased. We also show that the proposed estimator has a\nsuperior performance compared to several baselines, and is able to accurately\nmeasure relationship strengths over many orders of magnitude. \n\n"}
{"id": "1508.03311", "contents": "Title: Memoryless Thermodynamics? A Reply Abstract: We reply to arXiv:1508.00203 `Comment on \"Identifying Functional\nThermodynamics in Autonomous Maxwellian Ratchets\" (arXiv:1507.01537v2)'. \n\n"}
{"id": "1508.03787", "contents": "Title: Information-theoretically Secure Erasure Codes for Distributed Storage Abstract: Repair operations in distributed storage systems potentially expose the data\nto malicious acts of passive eavesdroppers or active adversaries, which can be\ndetrimental to the security of the system. This paper presents erasure codes\nand repair algorithms that ensure security of the data in the presence of\npassive eavesdroppers and active adversaries, while maintaining high\navailability, reliability and efficiency in the system. Our codes are optimal\nin that they meet previously proposed lower bounds on the storage,\nnetwork-bandwidth, and reliability requirements for a wide range of system\nparameters. Our results thus establish the capacity of such systems. Our codes\nfor security from active adversaries provide an additional appealing feature of\n`on-demand security' where the desired level of security can be chosen\nseparately for each instance of repair, and our algorithms remain optimal\nsimultaneously for all possible levels. The paper also provides necessary and\nsufficient conditions governing the transformation of any (non-secure) code\ninto one providing on-demand security. \n\n"}
{"id": "1508.04372", "contents": "Title: A Fast and Efficient Algorithm for Reconstructing MR images From Partial\n  Fourier Samples Abstract: In this paper, the problem of Magnetic Resonance (MR) image reconstruction\nfrom partial Fourier samples has been considered. To this aim, we leverage the\nevidence that MR images are sparser than their zero-filled reconstructed ones\nfrom incomplete Fourier samples. This information can be used to define an\noptimization problem which searches for the sparsest possible image conforming\nwith the available Fourier samples. We solve the resulting problem using the\nwell-known Alternating Direction Method of Multipliers (ADMM). Unlike most\nexisting methods that work with small over-lapping image patches, the proposed\nalgorithm considers the whole image without dividing it into small blocks.\nExperimental results prominently confirm its promising performance and\nadvantages over the existing methods. \n\n"}
{"id": "1508.05040", "contents": "Title: Exploring sd-shell nuclei from two- and three-nucleon interactions with\n  realistic saturation properties Abstract: We study ground- and excited-state properties of all sd-shell nuclei with\nneutron and proton numbers 8 <= N,Z <= 20, based on a set of low-resolution\ntwo- and three-nucleon interactions that predict realistic saturation\nproperties of nuclear matter. We focus on estimating the theoretical\nuncertainties due to variation of the resolution scale, the low-energy\ncouplings, as well as from the many-body method. The experimental two-neutron\nand two-proton separation energies are reasonably well reproduced, with an\nuncertainty range of about 5 MeV. The first excited 2+ energies also show\noverall agreement, with a more narrow uncertainty range of about 500 keV. In\nmost cases, this range is dominated by the uncertainties in the Hamiltonian. \n\n"}
{"id": "1508.06025", "contents": "Title: Strong data-processing inequalities for channels and Bayesian networks Abstract: The data-processing inequality, that is, $I(U;Y) \\le I(U;X)$ for a Markov\nchain $U \\to X \\to Y$, has been the method of choice for proving impossibility\n(converse) results in information theory and many other disciplines. Various\nchannel-dependent improvements (called strong data-processing inequalities, or\nSDPIs) of this inequality have been proposed both classically and more\nrecently. In this note we first survey known results relating various notions\nof contraction for a single channel. Then we consider the basic extension:\ngiven SDPI for each constituent channel in a Bayesian network, how to produce\nan end-to-end SDPI?\n  Our approach is based on the (extract of the) Evans-Schulman method, which is\ndemonstrated for three different kinds of SDPIs, namely, the usual\nAhslwede-G\\'acs type contraction coefficients (mutual information), Dobrushin's\ncontraction coefficients (total variation), and finally the $F_I$-curve (the\nbest possible non-linear SDPI for a given channel). Resulting bounds on the\ncontraction coefficients are interpreted as probability of site percolation. As\nan example, we demonstrate how to obtain SDPI for an $n$-letter memoryless\nchannel with feedback given an SDPI for $n=1$.\n  Finally, we discuss a simple observation on the equivalence of a linear SDPI\nand comparison to an erasure channel (in the sense of \"less noisy\" order). This\nleads to a simple proof of a curious inequality of Samorodnitsky (2015), and\nsheds light on how information spreads in the subsets of inputs of a memoryless\nchannel. \n\n"}
{"id": "1508.06624", "contents": "Title: Discriminating quantum states: the multiple Chernoff distance Abstract: We consider the problem of testing multiple quantum hypotheses\n$\\{\\rho_1^{\\otimes n},\\ldots,\\rho_r^{\\otimes n}\\}$, where an arbitrary prior\ndistribution is given and each of the $r$ hypotheses is $n$ copies of a quantum\nstate. It is known that the average error probability $P_e$ decays\nexponentially to zero, that is, $P_e=\\exp\\{-\\xi n+o(n)\\}$. However, this error\nexponent $\\xi$ is generally unknown, except for the case that $r=2$.\n  In this paper, we solve the long-standing open problem of identifying the\nabove error exponent, by proving Nussbaum and Szko\\l a's conjecture that\n$\\xi=\\min_{i\\neq j}C(\\rho_i,\\rho_j)$. The right-hand side of this equality is\ncalled the multiple quantum Chernoff distance, and\n$C(\\rho_i,\\rho_j):=\\max_{0\\leq s\\leq\n1}\\{-\\log\\operatorname{Tr}\\rho_i^s\\rho_j^{1-s}\\}$ has been previously\nidentified as the optimal error exponent for testing two hypotheses,\n$\\rho_i^{\\otimes n}$ versus $\\rho_j^{\\otimes n}$.\n  The main ingredient of our proof is a new upper bound for the average error\nprobability, for testing an ensemble of finite-dimensional, but otherwise\ngeneral, quantum states. This upper bound, up to a states-dependent factor,\nmatches the multiple-state generalization of Nussbaum and Szko\\l a's lower\nbound. Specialized to the case $r=2$, we give an alternative proof to the\nachievability of the binary-hypothesis Chernoff distance, which was originally\nproved by Audenaert et al. \n\n"}
{"id": "1509.00114", "contents": "Title: Multi-Sensor Slope Change Detection Abstract: We develop a mixture procedure for multi-sensor systems to monitor data\nstreams for a change-point that causes a gradual degradation to a subset of the\nstreams. Observations are assumed to be initially normal random variables with\nknown constant means and variances. After the change-point, observations in the\nsubset will have increasing or decreasing means. The subset and the\nrate-of-changes are unknown. Our procedure uses a mixture statistics, which\nassumes that each sensor is affected by the change-point with probability\n$p_0$. Analytic expressions are obtained for the average run length (ARL) and\nthe expected detection delay (EDD) of the mixture procedure, which are\ndemonstrated to be quite accurate numerically. We establish the asymptotic\noptimality of the mixture procedure. Numerical examples demonstrate the good\nperformance of the proposed procedure. We also discuss an adaptive mixture\nprocedure using empirical Bayes. This paper extends our earlier work on\ndetecting an abrupt change-point that causes a mean-shift, by tackling the\nchallenges posed by the non-stationarity of the slope-change problem. \n\n"}
{"id": "1509.02626", "contents": "Title: Lattice Index Codes from Algebraic Number Fields Abstract: Broadcasting $K$ independent messages to multiple users where each user\ndemands all the messages and has a subset of the messages as side information\nis studied. Recently, Natarajan, Hong, and Viterbo proposed a novel\nbroadcasting strategy called lattice index coding which uses lattices\nconstructed over some principal ideal domains (PIDs) for transmission and\nshowed that this scheme provides uniform side information gains. In this paper,\nwe generalize this strategy to general rings of algebraic integers of number\nfields which may not be PIDs. Upper and lower bounds on the side information\ngains for the proposed scheme constructed over some interesting classes of\nnumber fields are provided and are shown to coincide asymptotically in message\nrates. This generalization substantially enlarges the design space and\npartially includes the scheme by Natarajan, Hong, and Viterbo as a special\ncase. Perhaps more importantly, in addition to side information gains, the\nproposed lattice index codes benefit from diversity gains inherent in\nconstellations carved from number fields when used over Rayleigh fading\nchannel. Some interesting examples are also provided for which the proposed\nscheme allows all the messages to be from the same field. \n\n"}
{"id": "1509.03281", "contents": "Title: Density Evolution in the Degree-correlated Stochastic Block Model Abstract: There is a recent surge of interest in identifying the sharp recovery\nthresholds for cluster recovery under the stochastic block model. In this\npaper, we address the more refined question of how many vertices that will be\nmisclassified on average. We consider the binary form of the stochastic block\nmodel, where $n$ vertices are partitioned into two clusters with edge\nprobability $a/n$ within the first cluster, $c/n$ within the second cluster,\nand $b/n$ across clusters. Suppose that as $n \\to \\infty$, $a= b+ \\mu \\sqrt{ b}\n$, $c=b+ \\nu \\sqrt{ b} $ for two fixed constants $\\mu, \\nu$, and $b \\to \\infty$\nwith $b=n^{o(1)}$. When the cluster sizes are balanced and $\\mu \\neq \\nu$, we\nshow that the minimum fraction of misclassified vertices on average is given by\n$Q(\\sqrt{v^*})$, where $Q(x)$ is the Q-function for standard normal, $v^*$ is\nthe unique fixed point of $v= \\frac{(\\mu-\\nu)^2}{16} + \\frac{ (\\mu+\\nu)^2 }{16}\n\\mathbb{E}[ \\tanh(v+ \\sqrt{v} Z)],$ and $Z$ is standard normal. Moreover, the\nminimum misclassified fraction on average is attained by a local algorithm,\nnamely belief propagation, in time linear in the number of edges. Our proof\ntechniques are based on connecting the cluster recovery problem to tree\nreconstruction problems, and analyzing the density evolution of belief\npropagation on trees with Gaussian approximations. \n\n"}
{"id": "1509.04073", "contents": "Title: Electromagnetic fields and anomalous transports in heavy-ion collisions\n  --- A pedagogical review Abstract: The hot and dense matter generated in heavy-ion collisions may contain\ndomains which are not invariant under P and CP transformations. Moreover,\nheavy-ion collisions can generate extremely strong magnetic fields as well as\nelectric fields. The interplay between the electromagnetic field and triangle\nanomaly leads to a number of macroscopic quantum phenomena in these P- and\nCP-odd domains known as the anomalous transports. The purpose of the article is\nto give a pedagogical review of various properties of the electromagnetic\nfields, the anomalous transports phenomena, and their experimental signatures\nin heavy-ion collisions. \n\n"}
{"id": "1509.04491", "contents": "Title: Sparse Multinomial Logistic Regression via Approximate Message Passing Abstract: For the problem of multi-class linear classification and feature selection,\nwe propose approximate message passing approaches to sparse multinomial\nlogistic regression (MLR). First, we propose two algorithms based on the Hybrid\nGeneralized Approximate Message Passing (HyGAMP) framework: one finds the\nmaximum a posteriori (MAP) linear classifier and the other finds an\napproximation of the test-error-rate minimizing linear classifier. Then we\ndesign computationally simplified variants of these two algorithms. Next, we\ndetail methods to tune the hyperparameters of their assumed statistical models\nusing Stein's unbiased risk estimate (SURE) and expectation-maximization (EM),\nrespectively. Finally, using both synthetic and real-world datasets, we\ndemonstrate improved error-rate and runtime performance relative to existing\nstate-of-the-art approaches to sparse MLR. \n\n"}
{"id": "1509.04671", "contents": "Title: Unravelling Medium Effects in Heavy Ion Collisions with Zeal Abstract: We propose a new observable, called zeal, to analyze events with jets in\nheavy ion collisions. The observable measures how a thermal medium affects the\nmultiplicity and distribution of energetic particles in a jet. Using few known\nmodels for energy loss and jet quenching, we demonstrate its capability to\ndistinguish the physics of these models. \n\n"}
{"id": "1509.04747", "contents": "Title: Fundamentals of Cluster-Centric Content Placement in Cache-Enabled\n  Device-to-Device Networks Abstract: This paper develops a comprehensive analytical framework with foundations in\nstochastic geometry to characterize the performance of cluster-centric content\nplacement in a cache-enabled device-to-device (D2D) network. Different from\ndevice-centric content placement, cluster-centric placement focuses on placing\ncontent in each cluster such that the collective performance of all the devices\nin each cluster is optimized. Modeling the locations of the devices by a\nPoisson cluster process, we define and analyze the performance for three\ngeneral cases: (i)$k$-Tx case: receiver of interest is chosen uniformly at\nrandom in a cluster and its content of interest is available at the $k^{th}$\nclosest device to the cluster center, (ii) $\\ell$-Rx case: receiver of interest\nis the $\\ell^{th}$ closest device to the cluster center and its content of\ninterest is available at a device chosen uniformly at random from the same\ncluster, and (iii) baseline case: the receiver of interest is chosen uniformly\nat random in a cluster and its content of interest is available at a device\nchosen independently and uniformly at random from the same cluster. Easy-to-use\nexpressions for the key performance metrics, such as coverage probability and\narea spectral efficiency (ASE) of the whole network, are derived for all three\ncases. Our analysis concretely demonstrates significant improvement in the\nnetwork performance when the device on which content is cached or device\nrequesting content from cache is biased to lie closer to the cluster center\ncompared to baseline case. Based on this insight, we develop and analyze a new\ngenerative model for cluster-centric D2D networks that allows to study the\neffect of intra-cluster interfering devices that are more likely to lie closer\nto the cluster center. \n\n"}
{"id": "1509.05383", "contents": "Title: Blast wave fits with resonances to $p_t$ spectra from nuclear collisions\n  at the LHC Abstract: We report our results for the freeze-out temperature and transverse flow\nprofile obtained from fits to hadronic spectra measured by the ALICE\ncollaboration. The influence of resonance decays is important and cannot be\nsimply accounted for without the inclusion of their decays into the fits. \n\n"}
{"id": "1509.07250", "contents": "Title: Optimal Rate-Diverse Wireless Network Coding Abstract: This paper proposes an encoding/decoding framework for achieving the optimal\nchannel capacities of the two-user broadcast channel where each user (receiver)\nhas the message targeted for the other user (receiver) as side information.\nSince the link qualities of the channels from the base station to the two users\nare different, their respective single-user non-broadcast channel capacities\nare also different. A goal is to simultaneously achieve/approach the\nsingle-user non-broadcast channel capacities of the two users with a single\nbroadcast transmission by applying network coding. This is referred to as the\n\\emph{rate-diverse wireless network coding} problem. For this problem, this\npaper presents a capacity-achieving framework based on linear- structured\nnested lattice codes. The significance of the proposed framework, besides its\ntheoretical optimality, is that it suggests a general design principle for\nlinear rate-diverse wireless network coding going beyond the use of lattice\ncodes. We refer to this design principle as the \\emph{principle of virtual\nsingle-user channels}. Guided by this design principle, we propose two\nimplementations of our encoding/decoding framework using practical linear codes\namenable to decoding with affordable complexities: the first implementation is\nbased on Low Density Lattice Codes (LDLC) and the second implementation is\nbased on Bit-interleaved Coded Modulation (BICM). These two implementations\ndemonstrate the validity and performance advantage of our framework. \n\n"}
{"id": "1509.07939", "contents": "Title: Novel Collective Phenomena in High-Energy Proton-Proton and\n  Proton-Nucleus Collisions Abstract: The observation of long-range collective correlations for particles emitted\nin high-multiplicity pp and pPb collisions has opened up new opportunities of\ninvestigating novel high-density QCD phenomena in small colliding systems. We\nreview experimental results related to the studies of collective phenomena in\nsmall systems from RHIC and the LHC over the past several years. Latest\ndevelopment in theoretical interpretations motivated by different frameworks\nare also reviewed, and confronted with the experimental data. Perspectives on\npossible future directions are discussed, with the aim of further exploring the\nrich emergent QCD phenomena. \n\n"}
{"id": "1509.08305", "contents": "Title: Random Access for Massive MIMO Systems with Intra-Cell Pilot\n  Contamination Abstract: Massive MIMO systems, where the base stations are equipped with hundreds of\nantenna elements, are an attractive way to attain unprecedented spectral\nefficiency in future wireless networks. In the \"classical\" massive MIMO\nsetting, the terminals are assumed fully loaded and a main impairment to the\nperformance comes from the inter-cell pilot contamination, i.e., interference\nfrom terminals in neighboring cells using the same pilots as in the home cell.\nHowever, when the terminals are active intermittently, it is viable to avoid\ninter-cell contamination by pre-allocation of pilots, while same-cell terminals\nuse random access to select the allocated pilot sequences. This leads to the\nproblem of intra-cell pilot contamination. We propose a framework for random\naccess in massive MIMO networks and derive new uplink sum rate expressions that\ntake intra-cell pilot collisions, intermittent terminal activity, and\ninterference into account. We use these expressions to optimize the terminal\nactivation probability and pilot length. \n\n"}
{"id": "1509.08734", "contents": "Title: Pseudorapidity and transverse-momentum distributions of charged\n  particles in proton-proton collisions at $\\mathbf{\\sqrt{\\textit s}}$ = 13 TeV Abstract: The pseudorapidity ($\\eta$) and transverse-momentum ($p_{\\rm T}$)\ndistributions of charged particles produced in proton-proton collisions are\nmeasured at the centre-of-mass energy $\\sqrt{s}$ = 13 TeV. The pseudorapidity\ndistribution in $|\\eta|<$ 1.8 is reported for inelastic events and for events\nwith at least one charged particle in $|\\eta|<$ 1. The pseudorapidity density\nof charged particles produced in the pseudorapidity region $|\\eta|<$ 0.5 is\n5.31 $\\pm$ 0.18 and 6.46 $\\pm$ 0.19 for the two event classes, respectively.\nThe transverse-momentum distribution of charged particles is measured in the\nrange 0.15 $<$ $p_{\\rm T}$ $<$ 20 GeV/c and $|\\eta|<$ 0.8 for events with at\nleast one charged particle in $|\\eta|<$ 1. The correlation between transverse\nmomentum and particle multiplicity is also investigated by studying the\nevolution of the spectra with event multiplicity. The results are compared with\ncalculations from PYTHIA and EPOS Monte Carlo generators. \n\n"}
{"id": "1510.00504", "contents": "Title: Stable recovery of low-dimensional cones in Hilbert spaces: One RIP to\n  rule them all Abstract: Many inverse problems in signal processing deal with the robust estimation of\nunknown data from underdetermined linear observations. Low dimensional models,\nwhen combined with appropriate regularizers, have been shown to be efficient at\nperforming this task. Sparse models with the 1-norm or low rank models with the\nnuclear norm are examples of such successful combinations. Stable recovery\nguarantees in these settings have been established using a common tool adapted\nto each case: the notion of restricted isometry property (RIP). In this paper,\nwe establish generic RIP-based guarantees for the stable recovery of cones\n(positively homogeneous model sets) with arbitrary regularizers. These\nguarantees are illustrated on selected examples. For block structured sparsity\nin the infinite dimensional setting, we use the guarantees for a family of\nregularizers which efficiency in terms of RIP constant can be controlled,\nleading to stronger and sharper guarantees than the state of the art. \n\n"}
{"id": "1510.01031", "contents": "Title: Linear Codes With Two or Three Weights From Some Functions With Low\n  Walsh Spectrum in Odd Characteristic Abstract: Linear codes with few weights have applications in authentication codes,\nsecrete sharing schemes, association schemes, consumer electronics and data\nstorage system. In this paper, several classes of linear codes with two or\nthree weights are obtained from some functions with low Walsh spectrum in odd\ncharacteristic. Numerical results show that some of the linear codes obtained\nare optimal or almost optimal in the sense that they meet certain bounds on\nlinear codes. \n\n"}
{"id": "1510.04747", "contents": "Title: Tensor vs Matrix Methods: Robust Tensor Decomposition under Block Sparse\n  Perturbations Abstract: Robust tensor CP decomposition involves decomposing a tensor into low rank\nand sparse components. We propose a novel non-convex iterative algorithm with\nguaranteed recovery. It alternates between low-rank CP decomposition through\ngradient ascent (a variant of the tensor power method), and hard thresholding\nof the residual. We prove convergence to the globally optimal solution under\nnatural incoherence conditions on the low rank component, and bounded level of\nsparse perturbations. We compare our method with natural baselines which apply\nrobust matrix PCA either to the {\\em flattened} tensor, or to the matrix slices\nof the tensor. Our method can provably handle a far greater level of\nperturbation when the sparse tensor is block-structured. This naturally occurs\nin many applications such as the activity detection task in videos. Our\nexperiments validate these findings. Thus, we establish that tensor methods can\ntolerate a higher level of gross corruptions compared to matrix methods. \n\n"}
{"id": "1510.06454", "contents": "Title: Many Access for Small Packets Based on Precoding and Sparsity-aware\n  Recovery Abstract: Modern mobile terminals produce massive small data packets. For these\nshort-length packets, it is inefficient to follow the current multiple access\nschemes to allocate transmission resources due to heavy signaling overhead. We\npropose a non-orthogonal many-access scheme that is well suited for the future\ncommunication systems equipped with many receive antennas. The system is\nmodeled as having a block-sparsity pattern with unknown sparsity level (i.e.,\nunknown number of transmitted messages). Block precoding is employed at each\nsingle-antenna transmitter to enable the simultaneous transmissions of many\nusers. The number of simultaneously served active users is allowed to be even\nmore than the number of receive antennas. Sparsity-aware recovery is designed\nat the receiver for joint user detection and symbol demodulation. To reduce the\neffects of channel fading on signal recovery, normalized block orthogonal\nmatching pursuit (BOMP) algorithm is introduced, and based on its approximate\nperformance analysis, we develop interference cancellation based BOMP (ICBOMP)\nalgorithm. The ICBOMP performs error correction and detection in each iteration\nof the normalized BOMP. Simulation results demonstrate the effectiveness of the\nproposed scheme in small packet services, as well as the advantages of ICBOMP\nin improving signal recovery accuracy and reducing computational cost. \n\n"}
{"id": "1510.06828", "contents": "Title: Construction of Near-Capacity Protograph LDPC Code Sequences with\n  Block-Error Thresholds Abstract: Density evolution for protograph Low-Density Parity-Check (LDPC) codes is\nconsidered, and it is shown that the message-error rate falls\ndouble-exponentially with iterations whenever the degree-2 subgraph of the\nprotograph is cycle-free and noise level is below threshold. Conditions for\nstability of protograph density evolution are established and related to the\nstructure of the protograph. Using large-girth graphs, sequences of protograph\nLDPC codes with block-error threshold equal to bit-error threshold and\nblock-error rate falling near-exponentially with blocklength are constructed\ndeterministically. Small-sized protographs are optimized to obtain thresholds\nnear capacity for binary erasure and binary-input Gaussian channels. \n\n"}
{"id": "1510.07930", "contents": "Title: Interplay Between Delayed CSIT and Network Topology for Secure MISO BC Abstract: We study the problem of secure transmission over a Gaussian two-user\nmulti-input single-output (MISO) broadcast channel under the assumption that\nlinks connecting the transmitter to the two receivers may have unequal strength\nstatistically. In addition to this, the state of the channel to each receiver\nis conveyed in a strictly causal manner to the transmitter. We focus on a two\nstate topological setting of strong v.s. weak links. Under these assumptions,\nwe first consider the MISO wiretap channel and establish bounds on generalized\nsecure degrees of freedom (GSDoF). Next, we extend this model to the two-user\nMISO broadcast channel and establish inner and outer bounds on GSDoF region\nwith different topology states. The encoding scheme sheds light on the usage of\nboth resources, i.e., topology of the model and strictly causal channel state\ninformation at the transmitter (CSIT); and, allows digitization and\nmulti-casting of overheard side information, while transmitting confidential\nmessage over the stronger link. Furthermore, for a special class of channels,\nwe show that the established bounds agree and so we characterize the sum GSDoF. \n\n"}
{"id": "1510.08000", "contents": "Title: Baryon spectroscopy with polarization observables from CLAS Abstract: Meson photoproduction is an important tool in the study of baryon resonances.\nThe spectrum of broad and overlapping nucleon excitations can be greatly\nclarified by use of polarization observables. The N* program at Jefferson Lab\nwith the CEBAF Large Acceptance Spectrometer (CLAS) includes experimental\nstudies with linearly and circularly polarized tagged photon beams,\nlongitudinally and transversely polarized nucleon targets, and recoil\npolarizations. An overview of these experimental studies and recent results\nwill be given. \n\n"}
{"id": "1510.08213", "contents": "Title: Optimal Point-to-Point Codes in Interference Channels: An Incremental\n  I-MMSE approach Abstract: A recent result of the authors shows a so-called I-MMSE-like relationship\nthat, for the two-user Gaussian interference channel, an I-MMSE relationship\nholds in the limit, as n $\\to \\infty$, between the interference and the\ninterfered-with receiver, assuming that the interfered-with transmission is an\noptimal point-to-point sequence (achieves the point-to-point capacity). This\nresult was further used to provide a proof of the \"missing corner points\" of\nthe two-user Gaussian interference channel. This paper provides an information\ntheoretic proof of the above-mentioned I-MMSE-like relationship which follows\nthe incremental channel approach, an approach which was used by Guo, Shamai and\nVerd\\'u to provide an insightful proof of the original I-MMSE relationship for\npoint-to-point channels. Finally, some additional applications of this result\nare shown for other multi-user settings: the Gaussian multiple-access channel\nwith interference and specific K-user Gaussian Z-interference channel settings. \n\n"}
{"id": "1511.01212", "contents": "Title: Hierarchical Polar Coding for Achieving Secrecy over Fading Wiretap\n  Channels without any Instantaneous CSI Abstract: This paper presents a polar coding scheme to achieve secrecy in block fading\nbinary symmetric wiretap channels without the knowledge of instantaneous\nchannel state information (CSI) at the transmitter. For this model, a coding\nscheme that hierarchically utilizes polar codes is presented. In particular, on\npolarization of different binary symmetric channels over different fading\nblocks, each channel use is modeled as an appropriate binary erasure channel\nover fading blocks. Polar codes are constructed for both coding over channel\nuses for each fading block and coding over fading blocks for certain channel\nuses. In order to guarantee security, random bits are introduced at appropriate\nplaces to exhaust the observations of the eavesdropper. It is shown that this\ncoding scheme, without instantaneous CSI at the transmitter, is secrecy\ncapacity achieving for the simultaneous fading scenario. For the independent\nfading case, the capacity is achieved when the fading realizations for the\neavesdropper channel is always degraded with respect to the receiver. For the\nremaining cases, the gap is analyzed by comparing lower and upper bounds.\nRemarkably, for the scenarios where the secrecy capacity is achieved, the\nresults imply that instantaneous CSI does not increase the secrecy capacity. \n\n"}
{"id": "1511.04066", "contents": "Title: Properly Learning Poisson Binomial Distributions in Almost Polynomial\n  Time Abstract: We give an algorithm for properly learning Poisson binomial distributions. A\nPoisson binomial distribution (PBD) of order $n$ is the discrete probability\ndistribution of the sum of $n$ mutually independent Bernoulli random variables.\nGiven $\\widetilde{O}(1/\\epsilon^2)$ samples from an unknown PBD $\\mathbf{p}$,\nour algorithm runs in time $(1/\\epsilon)^{O(\\log \\log (1/\\epsilon))}$, and\noutputs a hypothesis PBD that is $\\epsilon$-close to $\\mathbf{p}$ in total\nvariation distance. The previously best known running time for properly\nlearning PBDs was $(1/\\epsilon)^{O(\\log(1/\\epsilon))}$.\n  As one of our main contributions, we provide a novel structural\ncharacterization of PBDs. We prove that, for all $\\epsilon >0,$ there exists an\nexplicit collection $\\cal{M}$ of $(1/\\epsilon)^{O(\\log \\log (1/\\epsilon))}$\nvectors of multiplicities, such that for any PBD $\\mathbf{p}$ there exists a\nPBD $\\mathbf{q}$ with $O(\\log(1/\\epsilon))$ distinct parameters whose\nmultiplicities are given by some element of ${\\cal M}$, such that $\\mathbf{q}$\nis $\\epsilon$-close to $\\mathbf{p}$. Our proof combines tools from Fourier\nanalysis and algebraic geometry.\n  Our approach to the proper learning problem is as follows: Starting with an\naccurate non-proper hypothesis, we fit a PBD to this hypothesis. More\nspecifically, we essentially start with the hypothesis computed by the\ncomputationally efficient non-proper learning algorithm in our recent\nwork~\\cite{DKS15}. Our aforementioned structural characterization allows us to\nreduce the corresponding fitting problem to a collection of\n$(1/\\epsilon)^{O(\\log \\log(1/\\epsilon))}$ systems of low-degree polynomial\ninequalities. We show that each such system can be solved in time\n$(1/\\epsilon)^{O(\\log \\log(1/\\epsilon))}$, which yields the overall running\ntime of our algorithm. \n\n"}
{"id": "1511.08327", "contents": "Title: Random Forests for Big Data Abstract: Big Data is one of the major challenges of statistical science and has\nnumerous consequences from algorithmic and theoretical viewpoints. Big Data\nalways involve massive data but they also often include online data and data\nheterogeneity. Recently some statistical methods have been adapted to process\nBig Data, like linear regression models, clustering methods and bootstrapping\nschemes. Based on decision trees combined with aggregation and bootstrap ideas,\nrandom forests were introduced by Breiman in 2001. They are a powerful\nnonparametric statistical method allowing to consider in a single and versatile\nframework regression problems, as well as two-class and multi-class\nclassification problems. Focusing on classification problems, this paper\nproposes a selective review of available proposals that deal with scaling\nrandom forests to Big Data problems. These proposals rely on parallel\nenvironments or on online adaptations of random forests. We also describe how\nrelated quantities -- such as out-of-bag error and variable importance -- are\naddressed in these methods. Then, we formulate various remarks for random\nforests in the Big Data context. Finally, we experiment five variants on two\nmassive datasets (15 and 120 millions of observations), a simulated one as well\nas real world data. One variant relies on subsampling while three others are\nrelated to parallel implementations of random forests and involve either\nvarious adaptations of bootstrap to Big Data or to \"divide-and-conquer\"\napproaches. The fifth variant relates on online learning of random forests.\nThese numerical experiments lead to highlight the relative performance of the\ndifferent variants, as well as some of their limitations. \n\n"}
{"id": "1512.00213", "contents": "Title: A Multi-Service Oriented Multiple-Access Scheme for Next-Generation\n  Mobile Networks Abstract: One of the key requirements for fifth-generation (5G) cellular networks is\ntheir ability to handle densely connected devices with different quality of\nservice (QoS) requirements. In this article, we present multi-service oriented\nmultiple access (MOMA), an integrated access scheme for massive connections\nwith diverse QoS profiles and/or traffic patterns originating from both\nhandheld devices and machine-to-machine (M2M) transmissions. MOMA is based on\na) stablishing separate classes of users based on relevant criteria that go\nbeyond the simple handheld/M2M split, b) class dependent hierarchical spreading\nof the data signal and c) a mix of multiuser and single-user detection schemes\nat the receiver. Practical implementations of the MOMA principle are provided\nfor base stations (BSs) that are equipped with a large number of antenna\nelements. Finally, it is shown that such a\nmassive-multiple-input-multiple-output (MIMO) scenario enables the achievement\nof all the benefits of MOMA even with a simple receiver structure that allows\nto concentrate the receiver complexity where effectively needed. \n\n"}
{"id": "1512.00907", "contents": "Title: Innovation Pursuit: A New Approach to Subspace Clustering Abstract: In subspace clustering, a group of data points belonging to a union of\nsubspaces are assigned membership to their respective subspaces. This paper\npresents a new approach dubbed Innovation Pursuit (iPursuit) to the problem of\nsubspace clustering using a new geometrical idea whereby subspaces are\nidentified based on their relative novelties. We present two frameworks in\nwhich the idea of innovation pursuit is used to distinguish the subspaces.\nUnderlying the first framework is an iterative method that finds the subspaces\nconsecutively by solving a series of simple linear optimization problems, each\nsearching for a direction of innovation in the span of the data potentially\northogonal to all subspaces except for the one to be identified in one step of\nthe algorithm. A detailed mathematical analysis is provided establishing\nsufficient conditions for iPursuit to correctly cluster the data. The proposed\napproach can provably yield exact clustering even when the subspaces have\nsignificant intersections. It is shown that the complexity of the iterative\napproach scales only linearly in the number of data points and subspaces, and\nquadratically in the dimension of the subspaces. The second framework\nintegrates iPursuit with spectral clustering to yield a new variant of\nspectral-clustering-based algorithms. The numerical simulations with both real\nand synthetic data demonstrate that iPursuit can often outperform the\nstate-of-the-art subspace clustering algorithms, more so for subspaces with\nsignificant intersections, and that it significantly improves the\nstate-of-the-art result for subspace-segmentation-based face clustering. \n\n"}
{"id": "1512.01907", "contents": "Title: An algorithm to compute CVTs for finitely generated Cantor distributions Abstract: Centroidal Voronoi tessellations (CVTs) are Voronoi tessellations of a region\nsuch that the generating points of the tessellations are also the centroids of\nthe corresponding Voronoi regions with respect to a given probability measure.\nCVT is a fundamental notion that has a wide spectrum of applications in\ncomputational science and engineering. In this paper, an algorithm is given to\nobtain the CVTs with $n$-generators to level $m$, for any positive integers $m$\nand $n$, of any Cantor set generated by a pair of self-similar mappings given\nby $S_1(x)=r_1x$ and $S_2(x)=r_2x+(1-r_2)$ for $x\\in \\mathbb R$, where $r_1,\nr_2>0$ and $r_1+r_2<1$, with respect to any probability distribution $P$ such\nthat $P=p_1 P\\circ S_1^{-1}+p_2 P\\circ S_2^{-1}$, where $p_1, p_2>0$ and\n$p_1+p_2=1$. \n\n"}
{"id": "1512.03605", "contents": "Title: LHCb results from proton ion collisions Abstract: Proton-lead and lead-proton data taking during 2013 has allowed LHCb to\nexpand its physics program to heavy ion physics. Results include the first\nforward measurement of Z production in proton-lead collisions as well as a\nmeasurement of the nuclear modification factor and forward-backward production\nof prompt and displaced J/$\\psi$, $\\psi$(2S) and $\\Upsilon$. Angular particle\ncorrelations have also been measured for events of varying charged particle\nactivity. \n\n"}
{"id": "1512.06161", "contents": "Title: On Locally Recoverable (LRC) Codes Abstract: We present simple constructions of optimal erasure-correcting LRC codes by\nexhibiting their parity-check matrices. When the number of local parities in a\nparity group plus the number of global parities is smaller than the size of the\nparity group, the constructed codes are optimal with a field of size at least\nthe length of the code. We can reduce the size of the field to at least the\nsize of the parity groups when the number of global parities equals the number\nof local parities in a parity group plus one. \n\n"}
{"id": "1512.06298", "contents": "Title: Streaming Data Transmission in the Moderate Deviations and Central Limit\n  Regimes Abstract: We consider streaming data transmission over a discrete memoryless channel. A\nnew message is given to the encoder at the beginning of each block and the\ndecoder decodes each message sequentially, after a delay of $T$ blocks. In this\nstreaming setup, we study the fundamental interplay between the rate and error\nprobability in the central limit and moderate deviations regimes and show that\ni) in the moderate deviations regime, the moderate deviations constant improves\nover the block coding or non-streaming setup by a factor of $T$ and ii) in the\ncentral limit regime, the second-order coding rate improves by a factor of\napproximately $\\sqrt{T}$ for a wide range of channel parameters. For both\nregimes, we propose coding techniques that incorporate a joint encoding of\nfresh and previous messages. In particular, for the central limit regime, we\npropose a coding technique with truncated memory to ensure that a summation of\nconstants, which arises as a result of applications of the central limit\ntheorem, does not diverge in the error analysis.\n  Furthermore, we explore interesting variants of the basic streaming setup in\nthe moderate deviations regime. We first consider a scenario with an erasure\noption at the decoder and show that both the exponents of the total error and\nthe undetected error probabilities improve by factors of $T$. Next, by\nutilizing the erasure option, we show that the exponent of the total error\nprobability can be improved to that of the undetected error probability (in the\norder sense) at the expense of a variable decoding delay. Finally, we also\nextend our results to the case where the message rate is not fixed but\nalternates between two values. \n\n"}
{"id": "1512.06298", "contents": "Title: Streaming Data Transmission in the Moderate Deviations and Central Limit\n  Regimes Abstract: We consider streaming data transmission over a discrete memoryless channel. A\nnew message is given to the encoder at the beginning of each block and the\ndecoder decodes each message sequentially, after a delay of $T$ blocks. In this\nstreaming setup, we study the fundamental interplay between the rate and error\nprobability in the central limit and moderate deviations regimes and show that\ni) in the moderate deviations regime, the moderate deviations constant improves\nover the block coding or non-streaming setup by a factor of $T$ and ii) in the\ncentral limit regime, the second-order coding rate improves by a factor of\napproximately $\\sqrt{T}$ for a wide range of channel parameters. For both\nregimes, we propose coding techniques that incorporate a joint encoding of\nfresh and previous messages. In particular, for the central limit regime, we\npropose a coding technique with truncated memory to ensure that a summation of\nconstants, which arises as a result of applications of the central limit\ntheorem, does not diverge in the error analysis.\n  Furthermore, we explore interesting variants of the basic streaming setup in\nthe moderate deviations regime. We first consider a scenario with an erasure\noption at the decoder and show that both the exponents of the total error and\nthe undetected error probabilities improve by factors of $T$. Next, by\nutilizing the erasure option, we show that the exponent of the total error\nprobability can be improved to that of the undetected error probability (in the\norder sense) at the expense of a variable decoding delay. Finally, we also\nextend our results to the case where the message rate is not fixed but\nalternates between two values. \n\n"}
{"id": "1512.06352", "contents": "Title: Vector Network Coding Based on Subspace Codes Outperforms Scalar Linear\n  Network Coding Abstract: This paper considers vector network coding solutions based on rank-metric\ncodes and subspace codes. The main result of this paper is that vector\nsolutions can significantly reduce the required alphabet size compared to the\noptimal scalar linear solution for the same multicast network. The multicast\nnetworks considered in this paper have one source with $h$ messages, and the\nvector solution is over a field of size $q$ with vectors of length~$t$. For a\ngiven network, let the smallest field size for which the network has a scalar\nlinear solution be $q_s$, then the gap in the alphabet size between the vector\nsolution and the scalar linear solution is defined to be $q_s-q^t$. In this\ncontribution, the achieved gap is $q^{(h-2)t^2/h + o(t)}$ for any $q \\geq 2$\nand any even $h \\geq 4$. If $h \\geq 5$ is odd, then the achieved gap of the\nalphabet size is $q^{(h-3)t^2/(h-1) + o(t)}$. Previously, only a gap of size\nsize one had been shown for networks with a very large number of messages.\nThese results imply the same gap of the alphabet size between the optimal\nscalar linear and some scalar nonlinear network coding solution for multicast\nnetworks. For three messages, we also show an advantage of vector network\ncoding, while for two messages the problem remains open. Several networks are\nconsidered, all of them are generalizations and modifications of the well-known\ncombination networks. The vector network codes that are used as solutions for\nthose networks are based on subspace codes, particularly subspace codes\nobtained from rank-metric codes. Some of these codes form a new family of\nsubspace codes, which poses a new research problem. \n\n"}
{"id": "1512.06835", "contents": "Title: Cosmogenic Backgrounds to 0{\\nu}{\\beta}{\\beta} in EXO-200 Abstract: As neutrinoless double-beta decay experiments become more sensitive and\nintrinsic radioactivity in detector materials is reduced, previously minor\ncontributions to the background must be understood and eliminated. With this in\nmind, cosmogenic backgrounds have been studied with the EXO-200 experiment.\nUsing the EXO-200 TPC, the muon flux (through a flat horizontal surface)\nunderground at the Waste Isolation Pilot Plant (WIPP) has been measured to be\n{\\Phi} = 4.07 $\\pm$ 0.14 (sys) $\\pm$ 0.03 (stat) $\\times$ $10^{-7}$cm$^{-2}$\ns$^{-1}$, with a vertical intensity of $I_{v}$ = 2.97$^{+0.14}_{-0.13}$ (sys)\n$\\pm$ 0.02 (stat) $\\times$ $10^{-7}$cm$^{-2}$ s$^{-1}$ sr$^{-1}$. Simulations\nof muon-induced backgrounds identified several potential cosmogenic\nradionuclides, though only 137Xe is a significant background for the 136Xe\n0{\\nu}{\\beta}{\\beta} search with EXO-200. Muon-induced neutron backgrounds were\nmeasured using {\\gamma}-rays from neutron capture on the detector materials.\nThis provided a measurement of 137Xe yield, and a test of the accuracy of the\nneutron production and transport simulations. The independently measured rates\nof 136Xe neutron capture and of 137Xe decay agree within uncertainties. Geant4\nand FLUKA simulations were performed to estimate neutron capture rates, and\nthese estimates agreed to within ~40% or better with measurements. The ability\nto identify 136Xe(n,{\\gamma}) events will allow for rejection of 137Xe\nbackgrounds in future 0{\\nu}{\\beta}{\\beta} analyses. \n\n"}
{"id": "1512.07856", "contents": "Title: Cache Aided Wireless Networks: Tradeoffs between Storage and Latency Abstract: We investigate the fundamental information theoretic limits of cache-aided\nwireless networks, in which edge nodes (or transmitters) are endowed with\ncaches that can store popular content, such as multimedia files. This\narchitecture aims to localize popular multimedia content by proactively pushing\nit closer to the edge of the wireless network, thereby alleviating backhaul\nload. An information theoretic model of such networks is presented, that\nincludes the introduction of a new metric, namely normalized delivery time\n(NDT), which captures the worst case time to deliver any requested content to\nthe users. We present new results on the trade-off between latency, measured\nvia the NDT, and the cache storage capacity of the edge nodes. In particular, a\nnovel information theoretic lower bound on NDT is presented for cache aided\nnetworks. The optimality of this bound is shown for several system parameters. \n\n"}
{"id": "1512.08214", "contents": "Title: Isoscalar dipole transition as a probe for asymmetric clustering Abstract: Background: The sharp $1^-$ resonances with enhanced isoscalar dipole\ntransition strengths are observed in many light nuclei at relatively small\nexcitation energies, but their nature was unclear. Purpose: We show those\nresonances can be attributed to the cluster states with asymmetric\nconfigurations such as $\\alpha$+$^{16}{\\rm O}$. We explain why asymmetric\ncluster states are strongly excited by the isoscalar dipole transition. We also\nprovide a theoretical prediction of the isoscalar dipole transitions in\n$^{20}{\\rm Ne}$ and $^{44}{\\rm Ti}$. Method: The transition matrix is\nanalytically derived to clarify the excitation mechanism. The nuclear model\ncalculations by Brink-Bloch wave function and antisymmetrized molecular\ndynamics are also performed to provide a theoretical prediction for $^{20}{\\rm\nNe}$ and $^{44}{\\rm Ti}$. Results: It is shown that the transition matrix is as\nlarge as the Weisskopf estimate even though the ground state is an ideal shell\nmodel state. Furthermore, it is considerably amplified if the ground state has\ncluster correlation. The nuclear model calculations predict large transition\nmatrix to the $\\alpha$+$^{16}{\\rm O}$ and $\\alpha$+$^{40}{\\rm Ca}$ cluster\nstates comparable with or larger than the Weisskopf estimate.\n  Conclusion: We conclude that the asymmetric cluster states are strongly\nexcited by the isoscalar dipole transition. Combined with the isoscalar\nmonopole transition that populates the $0^+$ cluster states, the isoscalar\ntransitions are promising probe for asymmetric clusters. \n\n"}
{"id": "1512.08269", "contents": "Title: Statistical and Computational Guarantees for the Baum-Welch Algorithm Abstract: The Hidden Markov Model (HMM) is one of the mainstays of statistical modeling\nof discrete time series, with applications including speech recognition,\ncomputational biology, computer vision and econometrics. Estimating an HMM from\nits observation process is often addressed via the Baum-Welch algorithm, which\nis known to be susceptible to local optima. In this paper, we first give a\ngeneral characterization of the basin of attraction associated with any global\noptimum of the population likelihood. By exploiting this characterization, we\nprovide non-asymptotic finite sample guarantees on the Baum-Welch updates,\nguaranteeing geometric convergence to a small ball of radius on the order of\nthe minimax rate around a global optimum. As a concrete example, we prove a\nlinear rate of convergence for a hidden Markov mixture of two isotropic\nGaussians given a suitable mean separation and an initialization within a ball\nof large radius around (one of) the true parameters. To our knowledge, these\nare the first rigorous local convergence guarantees to global optima for the\nBaum-Welch algorithm in a setting where the likelihood function is nonconvex.\nWe complement our theoretical results with thorough numerical simulations\nstudying the convergence of the Baum-Welch algorithm and illustrating the\naccuracy of our predictions. \n\n"}
{"id": "1601.00743", "contents": "Title: Measurement of D-meson azimuthal anisotropy in Au+Au 200 GeV collisions\n  at RHIC Abstract: Heavy quarks are produced through initial hard scatterings and they are\naffected by the hot and dense medium created in heavy-ion collisions throughout\nits whole evolution. Due to their heavy mass, charm quarks are expected to\nthermalize much more slowly than light flavor quarks. The charm quark flow is a\nunique tool to study the extent of thermalization of the bulk medium dominated\nby light quarks and gluons. At high $p_T$, D meson azimuthal anisotropy is\nsensitive to the path length dependence of charm quark energy loss in the\nmedium, which offers new insights into heavy quark energy loss mechanisms -\ngluon radiation vs. collisional processes. We present the STAR measurement of\nelliptic flow ($v_2$) of $D^0$ and $D^{\\pm}$ mesons in Au+Au collisions at\n$\\sqrt{s_{NN}}$ = 200 GeV, for a wide transverse momentum range. These results\nare obtained from the data taken in the first year of physics running of the\nnew STAR Heavy Flavor Tracker detector, which greatly improves open heavy\nflavor hadron measurements by the topological reconstruction of secondary decay\nvertices. The D meson $v_2$ is finite for $p_T > 2 \\text{ GeV/c}^2$ and\nsystematically below the measurement of light particle species at the same\nenergy. Comparison to a series of model calculations favors scenarios where\ncharm flows with the medium and is used to infer a range for the charm\ndiffusion coefficient $2\\pi T D_s$. \n\n"}
{"id": "1601.02320", "contents": "Title: A Class of Three-Weight Linear Codes and Their Complete Weight\n  Enumerators Abstract: Recently, linear codes constructed from defining sets have been investigated\nextensively and they have many applications. In this paper, for an odd prime\n$p$, we propose a class of $p$-ary linear codes by choosing a proper defining\nset. Their weight enumerators and complete weight enumerators are presented\nexplicitly. The results show that they are linear codes with three weights and\nsuitable for the constructions of authentication codes and secret sharing\nschemes. \n\n"}
{"id": "1601.02391", "contents": "Title: Almost universal codes for fading wiretap channels Abstract: We consider a fading wiretap channel model where the transmitter has only\nstatistical channel state information, and the legitimate receiver and\neavesdropper have perfect channel state information. We propose a sequence of\nnon-random lattice codes which achieve strong secrecy and semantic security\nover ergodic fading channels. The construction is almost universal in the sense\nthat it achieves the same constant gap to secrecy capacity over Gaussian and\nergodic fading models. \n\n"}
{"id": "1601.03793", "contents": "Title: Stochastic Geometry Analysis of Multi-Antenna Two-Tier Cellular Networks Abstract: In this paper, we study the key properties of multi-antenna two-tier networks\nunder different system configurations. Based on stochastic geometry, we derive\nthe expressions and approximations for the users' average data rate. Through\nthe more tractable approximations, the theoretical analysis can be greatly\nsimplified. We find that the differences in density and transmit power between\ntwo tiers, together with range expansion bias significantly affect the users'\ndata rate. Besides, for the purpose of area spectral efficiency (ASE)\nmaximization, we find that the optimal number of active users for each tier is\napproximately fixed portion of the sum of the number of antennas plus one.\nInterestingly, the optimal settings are insensitive to different configurations\nbetween two tiers. Last but not the least, if the number of antennas of macro\nbase stations (MBSs) is sufficiently larger than that of small cell base\nstations (SBSs), we find that range expansion will improve ASE. \n\n"}
{"id": "1601.04396", "contents": "Title: Source-Channel Secrecy for Shannon Cipher System Abstract: Recently, a secrecy measure based on list-reconstruction has been proposed\n[2], in which a wiretapper is allowed to produce a list of $2^{mR_{L}}$\nreconstruction sequences and the secrecy is measured by the minimum distortion\nover the entire list. In this paper, we show that this list secrecy problem is\nequivalent to the one with secrecy measured by a new quantity\n\\emph{lossy-equivocation}, which is proven to be the minimum optimistic\n1-achievable source coding rate (the minimum coding rate needed to reconstruct\nthe source within target distortion with positive probability for\n\\emph{infinitely many blocklengths}) of the source with the wiretapped signal\nas two-sided information, and also can be seen as a lossy extension of\nconventional equivocation. Upon this (or list) secrecy measure, we study\nsource-channel secrecy problem in the discrete memoryless Shannon cipher system\nwith \\emph{noisy} wiretap channel. Two inner bounds and an outer bound on the\nachievable region of secret key rate, list rate, wiretapper distortion, and\ndistortion of legitimate user are given. The inner bounds are derived by using\nuncoded scheme and (operationally) separate scheme, respectively. Thanks to the\nequivalence between lossy-equivocation secrecy and list secrecy, information\nspectrum method is leveraged to prove the outer bound. As special cases, the\nadmissible region for the case of degraded wiretap channel or lossless\ncommunication for legitimate user has been characterized completely. For both\nthese two cases, separate scheme is proven to be optimal. Interestingly,\nhowever, separation indeed suffers performance loss for other certain cases.\nBesides, we also extend our results to characterize the achievable region for\nGaussian communication case. As a side product optimistic lossy source coding\nhas also been addressed. \n\n"}
{"id": "1601.04485", "contents": "Title: TDOA Matrices: Algebraic Properties and their Application to Robust\n  Denoising with Missing Data Abstract: Measuring the Time delay of Arrival (TDOA) between a set of sensors is the\nbasic setup for many applications, such as localization or signal beamforming.\nThis paper presents the set of TDOA matrices, which are built from noise-free\nTDOA measurements, not requiring knowledge of the sensor array geometry. We\nprove that TDOA matrices are rank-two and have a special SVD decomposition that\nleads to a compact linear parametric representation. Properties of TDOA\nmatrices are applied in this paper to perform denoising, by finding the TDOA\nmatrix closest to the matrix composed with noisy measurements. The paper shows\nthat this problem admits a closed-form solution for TDOA measurements\ncontaminated with Gaussian noise which extends to the case of having missing\ndata. The paper also proposes a novel robust denoising method resistant to\noutliers, missing data and inspired in recent advances in robust low-rank\nestimation. Experiments in synthetic and real datasets show TDOA-based\nlocalization, both in terms of TDOA accuracy estimation and localization error. \n\n"}
{"id": "1601.04500", "contents": "Title: Second-Order and Moderate Deviation Asymptotics for Successive\n  Refinement Abstract: We derive the optimal second-order coding region and moderate deviations\nconstant for successive refinement source coding with a joint excess-distortion\nprobability constraint. We consider two scenarios: (i) a discrete memoryless\nsource (DMS) and arbitrary distortion measures at the decoders and (ii) a\nGaussian memoryless source (GMS) and quadratic distortion measures at the\ndecoders. For a DMS with arbitrary distortion measures, we prove an achievable\nsecond-order coding region, using type covering lemmas by Kanlis and Narayan\nand by No, Ingber and Weissman. We prove the converse using the perturbation\napproach by Gu and Effros. When the DMS is successively refinable, the\nexpressions for the second-order coding region and the moderate deviations\nconstant are simplified and easily computable. For this case, we also obtain\nnew insights on the second-order behavior compared to the scenario where\nseparate excess-distortion proabilities are considered. For example, we\ndescribe a DMS, for which the optimal second-order region transitions from\nbeing characterizable by a bivariate Gaussian to a univariate Gaussian, as the\ndistortion levels are varied. We then consider a GMS with quadratic distortion\nmeasures. To prove the direct part, we make use of the sphere covering theorem\nby Verger-Gaugry, together with appropriately-defined Gaussian type classes. To\nprove the converse, we generalize Kostina and Verd\\'u's one-shot converse bound\nfor point-to-point lossy source coding. We remark that this proof is applicable\nto general successively refinable sources. In the proofs of the moderate\ndeviations results for both scenarios, we follow a strategy similar to that for\nthe second-order asymptotics and use the moderate deviations principle. \n\n"}
{"id": "1601.05793", "contents": "Title: Shift-Invariant and Sampling Spaces Associated with the Special Affine\n  Fourier Transform Abstract: The Special Affine Fourier Transformation or the SAFT generalizes a number of\nwell known unitary transformations as well as signal processing and optics\nrelated mathematical operations. Shift-invariant spaces also play an important\nrole in sampling theory, multiresolution analysis, and many other areas of\nsignal and image processing. Shannon's sampling theorem, which is at the heart\nof modern digital communications, is a special case of sampling in\nshift-invariant spaces. Furthermore, it is well known that the Poisson\nsummation formula is equivalent to the sampling theorem and that the Zak\ntransform is closely connected to the sampling theorem and the Poisson\nsummation formula. These results have been known to hold in the Fourier\ntransform domain for decades and were recently shown to hold in the Fractional\nFourier transform domain by A. Bhandari and A. Zayed.\n  The main goal of this article is to show that these results also hold true in\nthe SAFT domain. We provide a short, self-contained proof of Shannon's theorem\nfor functions bandlimited in the SAFT domain and then show that sampling in the\nSAFT domain is equivalent to orthogonal projection of functions onto a subspace\nof bandlimited basis associated with the SAFT domain. This interpretation of\nsampling leads to least-squares optimal sampling theorem. Furthermore, we show\nthat this approximation procedure is linked with convolution and semi-discrete\nconvolution operators that are associated with the SAFT domain. We conclude the\narticle with an application of fractional delay filtering of SAFT bandlimited\nfunctions. \n\n"}
{"id": "1601.05839", "contents": "Title: The Impact of Unlicensed Access on Small-Cell Resource Allocation Abstract: Small cells deployed in licensed spectrum and unlicensed access via WiFi\nprovide different ways of expanding wireless services to low mobility users.\nThat reduces the demand for conventional macro-cellular networks, which are\nbetter suited for wide-area mobile coverage. The mix of these technologies seen\nin practice depends in part on the decisions made by wireless service providers\nthat seek to maximize revenue, and allocations of licensed and unlicensed\nspectrum by regulators. To understand these interactions we present a model in\nwhich a service provider allocates available licensed spectrum across two\nseparate bands, one for macro- and one for small-cells, in order to serve two\ntypes of users: mobile and fixed. We assume a service model in which the\nproviders can charge a (different) price per unit rate for each type of service\n(macro- or small-cell); unlicensed access is free. With this setup we study how\nthe addition of unlicensed spectrum affects prices and the optimal allocation\nof bandwidth across macro-/small-cells. We also characterize the optimal\nfraction of unlicensed spectrum when new bandwidth becomes available. \n\n"}
{"id": "1601.05921", "contents": "Title: Edge Agreement of Second-order Multi-agent System with Dynamic\n  Quantization via Directed Edge Laplacian Abstract: This work explores the edge agreement problem of second-order multi-agent\nsystem with dynamic quantization under directed communication. To begin with,\nby virtue of the directed edge laplacian, we derive a model reduction\nrepresentation of the closed-loop multi-agent system depended on the spanning\ntree subgraph. Considering the limitations of the finite bandwidth channels,\nthe quantization effects of second-order multi-agent system under directed\ngraph are considered. Motivated by the observation that the static quantizer\nalways lead to the practical stability rather than the asymptotic stability,\nthe dynamic quantized communication strategy referring to the rooming\nin-rooming out scheme is employed. Based on the reduced model associated with\nthe essential edge Laplacian, the asymptotic stability of second-order\nmulti-agent system under dynamic quantized effects with only finite\nquantization level can be guaranteed. Finally, simulation results are provided\nto verify the theoretical analysis. \n\n"}
{"id": "1601.06113", "contents": "Title: The Unbounded Benefit of Encoder Cooperation for the $k$-user MAC Abstract: Cooperation strategies allow communication devices to work together to\nimprove network capacity. Consider a network consisting of a $k$-user multiple\naccess channel (MAC) and a node that is connected to all $k$ encoders via\nrate-limited bidirectional links, referred to as the \"cooperation facilitator\"\n(CF). Define the cooperation benefit as the sum-capacity gain resulting from\nthe communication between the encoders and the CF and the cooperation rate as\nthe total rate the CF shares with the encoders. This work demonstrates the\nexistence of a class of $k$-user MACs where the ratio of the cooperation\nbenefit to cooperation rate tends to infinity as the cooperation rate tends to\nzero. Examples of channels in this class include the binary erasure MAC for\n$k=2$ and the $k$-user Gaussian MAC for any $k\\geq 2$. \n\n"}
{"id": "1601.06224", "contents": "Title: Rate Distortion for Lossy In-network Function Computation: Information\n  Dissipation and Sequential Reverse Water-Filling Abstract: We consider the problem of distributed lossy linear function computation in a\ntree network. We examine two cases: (i) data aggregation (only one sink node\ncomputes) and (ii) consensus (all nodes compute the same function). By\nquantifying the accumulation of information loss in distributed computing, we\nobtain fundamental limits on network computation rate as a function of\nincremental distortions (and hence incremental loss of information) along the\nedges of the network. The above characterization, based on quantifying\ndistortion accumulation, offers an improvement over classical cut-set type\ntechniques which are based on overall distortions instead of incremental\ndistortions. This quantification of information loss qualitatively resembles\ninformation dissipation in cascaded channels [1]. Surprisingly, this\naccumulation effect of distortion happens even at infinite blocklength.\nCombining this observation with an inequality on the dominance of mean-square\nquantities over relative-entropy quantities, we obtain outer bounds on the rate\ndistortion function that are tighter than classical cut-set bounds by a\ndifference which can be arbitrarily large in both data aggregation and\nconsensus. We also obtain inner bounds on the optimal rate using random\nGaussian coding, which differ from the outer bounds by $\\mathcal{O}(\\sqrt{D})$,\nwhere $D$ is the overall distortion. The obtained inner and outer bounds can\nprovide insights on rate (bit) allocations for both the data aggregation\nproblem and the consensus problem. We show that for tree networks, the rate\nallocation results have a mathematical structure similar to classical reverse\nwater-filling for parallel Gaussian sources. \n\n"}
{"id": "1601.06239", "contents": "Title: Divide and Conquer Local Average Regression Abstract: The divide and conquer strategy, which breaks a massive data set into a se-\nries of manageable data blocks, and then combines the independent results of\ndata blocks to obtain a final decision, has been recognized as a\nstate-of-the-art method to overcome challenges of massive data analysis. In\nthis paper, we merge the divide and conquer strategy with local average\nregression methods to infer the regressive relationship of input-output pairs\nfrom a massive data set. After theoretically analyzing the pros and cons, we\nfind that although the divide and conquer local average regression can reach\nthe optimal learning rate, the restric- tion to the number of data blocks is a\nbit strong, which makes it only feasible for small number of data blocks. We\nthen propose two variants to lessen (or remove) this restriction. Our results\nshow that these variants can achieve the optimal learning rate with much milder\nrestriction (or without such restriction). Extensive experimental studies are\ncarried out to verify our theoretical assertions. \n\n"}
{"id": "1601.06410", "contents": "Title: Finite Blocklength Achievable Rates for Energy Harvesting AWGN Channels\n  with Infinite Buffer Abstract: We consider an additive White Gaussian channel where the transmitter is\npowered by an energy harvesting source. For such a system, we provide a lower\nbound on the maximal code book at finite code lengths that improves upon\npreviously known bounds. \n\n"}
{"id": "1601.06676", "contents": "Title: Plausible Deniability over Broadcast Channels Abstract: In this paper, we introduce the notion of Plausible Deniability in an\ninformation theoretic framework. We consider a scenario where an entity that\neavesdrops through a broadcast channel summons one of the parties in a\ncommunication protocol to reveal their message (or signal vector). It is\ndesirable that the summoned party have enough freedom to produce a fake output\nthat is likely plausible given the eavesdropper's observation. We examine three\nvariants of this problem -- Message Deniability, Transmitter Deniability, and\nReceiver Deniability. In the first setting, the message sender is summoned to\nproduce the sent message. Similarly, in the second and third settings, the\ntransmitter and the receiver are required to produce the transmitted codeword,\nand the received vector respectively. For each of these settings, we examine\nthe maximum communication rate that allows a given minimum rate of plausible\nfake outputs. For the Message and Transmitter Deniability problems, we fully\ncharacterise the capacity region for general broadcast channels, while for the\nReceiver Deniability problem, we give an achievable rate region for physically\ndegraded broadcast channels. \n\n"}
{"id": "1601.06847", "contents": "Title: Battery-Powered Devices in WPCNs Abstract: Wireless powered communication networks are becoming an effective solution\nfor improving self sustainability of mobile devices. In this context, a hybrid\naccess point transfers energy to a group of nodes, which use the harvested\nenergy to perform computation or transmission tasks. While the availability of\nthe wireless energy transfer mechanism opens up new frontiers, an appropriate\nchoice of the network parameters (e.g., transmission powers, transmission\nduration, amount of transferred energy, etc.) is required in order to achieve\nhigh performance. In this work, we study the throughput optimization problem in\na system composed of an access point which recharges the batteries of two\ndevices at different distances. In the literature, the main focus so far has\nbeen on slot-oriented optimization, in which all the harvested energy is used\nin the same slot in which it is harvested. However, this approach is strongly\nsub-optimal because it does not exploit the possibility to store the energy and\nuse it at a later time. Thus, instead of considering the slot-oriented case, we\naddress the long-term maximization. This assumption greatly increases the\noptimization complexity, requiring to consider, e.g., the channel state\nrealizations, its statistics and the batteries evolution. Our objective is to\nfind the best scheduling scheme, both for the energy transferred by the access\npoint and for the data sent by the two nodes. We discuss how to perform the\nmaximization with optimal as well as approximate techniques and show that the\nslot-oriented policies proposed so far are strongly sub-optimal in the long\nrun. \n\n"}
{"id": "1601.06899", "contents": "Title: Coded Compressive Sensing: A Compute-and-Recover Approach Abstract: In this paper, we propose \\textit{coded compressive sensing} that recovers an\n$n$-dimensional integer sparse signal vector from a noisy and quantized\nmeasurement vector whose dimension $m$ is far-fewer than $n$. The core idea of\ncoded compressive sensing is to construct a linear sensing matrix whose columns\nconsist of lattice codes. We present a two-stage decoding method named\n\\textit{compute-and-recover} to detect the sparse signal from the noisy and\nquantized measurements. In the first stage, we transform such measurements into\nnoiseless finite-field measurements using the linearity of lattice codewords.\nIn the second stage, syndrome decoding is applied over the finite-field to\nreconstruct the sparse signal vector. A sufficient condition of a perfect\nrecovery is derived. Our theoretical result demonstrates an interplay among the\nquantization level $p$, the sparsity level $k$, the signal dimension $n$, and\nthe number of measurements $m$ for the perfect recovery. Considering 1-bit\ncompressive sensing as a special case, we show that the proposed algorithm\nempirically outperforms an existing greedy recovery algorithm. \n\n"}
{"id": "1601.07024", "contents": "Title: Asymptotic analysis of downlink MIMO systems over Rician fading channels Abstract: In this work, we focus on the ergodic sum rate in the downlink of a\nsingle-cell large-scale multi-user MIMO system in which the base station\nemploys N antennas to communicate with $K$ single-antenna user equipments. A\nregularized zero-forcing (RZF) scheme is used for precoding under the\nassumption that each link forms a spatially correlated MIMO Rician fading\nchannel. The analysis is conducted assuming $N$ and $K$ grow large with a non\ntrivial ratio and perfect channel state information is available at the base\nstation. Recent results from random matrix theory and large system analysis are\nused to compute an asymptotic expression of the signal-to-interference-\nplus-noise ratio as a function of the system parameters, the spatial\ncorrelation matrix and the Rician factor. Numerical results are used to\nevaluate the performance gap in the finite system regime under different\noperating conditions. \n\n"}
{"id": "1601.07985", "contents": "Title: Online (and Offline) Robust PCA: Novel Algorithms and Performance\n  Guarantees Abstract: In this work, we study the online robust principal components' analysis\n(RPCA) problem. In recent work, RPCA has been defined as a problem of\nseparating a low-rank matrix (true data), $L$, and a sparse matrix (outliers),\n$S$, from their sum, $M:=L + S$. A more general version of this problem is to\nrecover $L$ and $S$ from $M:=L + S + W$ where $W$ is the matrix of unstructured\nsmall noise/corruptions. An important application where this problem occurs is\nin video analytics in trying to separate sparse foregrounds (e.g., moving\nobjects) from slowly changing backgrounds. While there has been a large amount\nof recent work on solutions and guarantees for the batch RPCA problem, the\nonline problem is largely open.\"Online\" RPCA is the problem of doing the above\non-the-fly with the extra assumptions that the initial subspace is accurately\nknown and that the subspace from which $l_t$ is generated changes slowly over\ntime. We develop and study a novel \"online\" RPCA algorithm based on the\nrecently introduced Recursive Projected Compressive Sensing (ReProCS)\nframework. Our algorithm improves upon the original ReProCS algorithm and it\nalso returns even more accurate offline estimates. The key contribution of this\nwork is a correctness result (complete performance guarantee) for this\nalgorithm under reasonably mild assumptions. By using extra assumptions --\naccurate initial subspace knowledge, slow subspace change, and clustered\neigenvalues -- we are able to remove one important limitation of batch RPCA\nresults and two key limitations of a recent result for ReProCS for online RPCA.\nTo our knowledge, this work is among the first few correctness results for\nonline RPCA. Most earlier results were only partial results, i.e., they\nrequired an assumption on intermediate algorithm estimates. \n\n"}
{"id": "1602.00223", "contents": "Title: A Proximal Stochastic Quasi-Newton Algorithm Abstract: In this paper, we discuss the problem of minimizing the sum of two convex\nfunctions: a smooth function plus a non-smooth function. Further, the smooth\npart can be expressed by the average of a large number of smooth component\nfunctions, and the non-smooth part is equipped with a simple proximal mapping.\nWe propose a proximal stochastic second-order method, which is efficient and\nscalable. It incorporates the Hessian in the smooth part of the function and\nexploits multistage scheme to reduce the variance of the stochastic gradient.\nWe prove that our method can achieve linear rate of convergence. \n\n"}
{"id": "1602.01132", "contents": "Title: Interactive algorithms: from pool to stream Abstract: We consider interactive algorithms in the pool-based setting, and in the\nstream-based setting. Interactive algorithms observe suggested elements\n(representing actions or queries), and interactively select some of them and\nreceive responses. Pool-based algorithms can select elements at any order,\nwhile stream-based algorithms observe elements in sequence, and can only select\nelements immediately after observing them. We assume that the suggested\nelements are generated independently from some source distribution, and ask\nwhat is the stream size required for emulating a pool algorithm with a given\npool size. We provide algorithms and matching lower bounds for general pool\nalgorithms, and for utility-based pool algorithms. We further show that a\nmaximal gap between the two settings exists also in the special case of active\nlearning for binary classification. \n\n"}
{"id": "1602.02201", "contents": "Title: The Rate-Distortion Risk in Estimation from Compressed Data Abstract: Consider the problem of estimating a latent signal from a lossy compressed\nversion of the data when the compressor is agnostic to the relation between the\nsignal and the data. This situation arises in a host of modern applications\nwhen data is transmitted or stored prior to determining the downstream\ninference task. Given a bitrate constraint and a distortion measure between the\ndata and its compressed version, let us consider the joint distribution\nachieving Shannon's rate-distortion (RD) function. Given an estimator and a\nloss function associated with the downstream inference task, define the\nrate-distortion risk as the expected loss under the RD-achieving distribution.\nWe provide general conditions under which the operational risk in estimating\nfrom the compressed data is asymptotically equivalent to the RD risk. The main\ntheoretical tools to prove this equivalence are transportation-cost\ninequalities in conjunction with properties of compression codes achieving\nShannon's RD function. Whenever such equivalence holds, a recipe for designing\nestimators from datasets undergoing lossy compression without specifying the\nactual compression technique emerges: design the estimator to minimize the RD\nrisk. Our conditions simplified in the special cases of discrete memoryless or\nmultivariate normal data. For these scenarios, we derive explicit expressions\nfor the RD risk of several estimators and compare them to the optimal source\ncoding performance associated with full knowledge of the relation between the\nlatent signal and the data. \n\n"}
{"id": "1602.02612", "contents": "Title: Sign-Compute-Resolve for Tree Splitting Random Access Abstract: We present a framework for random access that is based on three elements:\nphysical-layer network coding (PLNC), signature codes and tree splitting. In\npresence of a collision, physical-layer network coding enables the receiver to\ndecode, i.e. compute, the sum of the packets that were transmitted by the\nindividual users. For each user, the packet consists of the user's signature,\nas well as the data that the user wants to communicate. As long as no more than\nK users collide, their identities can be recovered from the sum of their\nsignatures. This framework for creating and transmitting packets can be used as\na fundamental building block in random access algorithms, since it helps to\ndeal efficiently with the uncertainty of the set of contending terminals. In\nthis paper we show how to apply the framework in conjunction with a\ntree-splitting algorithm, which is required to deal with the case that more\nthan K users collide. We demonstrate that our approach achieves throughput that\ntends to 1 rapidly as K increases. We also present results on net data-rate of\nthe system, showing the impact of the overheads of the constituent elements of\nthe proposed protocol. We compare the performance of our scheme with an upper\nbound that is obtained under the assumption that the active users are a priori\nknown. Also, we consider an upper bound on the net data-rate for any PLNC based\nstrategy in which one linear equation per slot is decoded. We show that already\nat modest packet lengths, the net data-rate of our scheme becomes close to the\nsecond upper bound, i.e. the overhead of the contention resolution algorithm\nand the signature codes vanishes. \n\n"}
{"id": "1602.02944", "contents": "Title: Fast phase retrieval for high dimensions: A block-based approach Abstract: This paper addresses fundamental scaling issues that hinder phase retrieval\n(PR) in high dimensions. We show that, if the measurement matrix can be put\ninto a generalized block-diagonal form, a large PR problem can be solved on\nseparate blocks, at the cost of a few extra global measurements to merge the\npartial results. We illustrate this principle using two distinct PR methods,\nand discuss different design trade-offs. Experimental results indicate that\nthis block-based PR framework can reduce computational cost and memory\nrequirements by several orders of magnitude. \n\n"}
{"id": "1602.03906", "contents": "Title: How to group wireless nodes together? Abstract: This report presents a survey on how to group together in a static way planar\nnodes, that may belong to a wireless network (ad hoc or cellular). The aim is\nto identify appropriate methods that could also be applied for Point Processes.\nSpecifically matching pairs and algorithms are initially discussed. Next,\nspecifically for Point Processes, the Nearest Neighbour and Lilypond models are\npresented. Properties and results for the two models are stated. Original\nbounds are given for the value of the so-called generation number, which is\nrelated to the size of the nearest neighbour cluster. Finally, a variation of\nthe nearest neighbour grouping is proposed and an original metric is\nintroduced, named here the ancestor number. This is used to facilitate the\nanalysis of the distribution of cluster size. Based on this certain related\nbounds are derived. The report and the analysis included show clearly the\ndifficulty of working in point processes with static clusters of size greater\nthan two, when these are defined by proximity criteria. \n\n"}
{"id": "1602.04435", "contents": "Title: Random Forest Based Approach for Concept Drift Handling Abstract: Concept drift has potential in smart grid analysis because the socio-economic\nbehaviour of consumers is not governed by the laws of physics. Likewise there\nare also applications in wind power forecasting. In this paper we present\ndecision tree ensemble classification method based on the Random Forest\nalgorithm for concept drift. The weighted majority voting ensemble aggregation\nrule is employed based on the ideas of Accuracy Weighted Ensemble (AWE) method.\nBase learner weight in our case is computed for each sample evaluation using\nbase learners accuracy and intrinsic proximity measure of Random Forest. Our\nalgorithm exploits both temporal weighting of samples and ensemble pruning as a\nforgetting strategy. We present results of empirical comparison of our method\nwith original random forest with incorporated \"replace-the-looser\" forgetting\nandother state-of-the-art concept-drfit classifiers like AWE2. \n\n"}
{"id": "1602.04567", "contents": "Title: Adversarial Top-$K$ Ranking Abstract: We study the top-$K$ ranking problem where the goal is to recover the set of\ntop-$K$ ranked items out of a large collection of items based on partially\nrevealed preferences. We consider an adversarial crowdsourced setting where\nthere are two population sets, and pairwise comparison samples drawn from one\nof the populations follow the standard Bradley-Terry-Luce model (i.e., the\nchance of item $i$ beating item $j$ is proportional to the relative score of\nitem $i$ to item $j$), while in the other population, the corresponding chance\nis inversely proportional to the relative score. When the relative size of the\ntwo populations is known, we characterize the minimax limit on the sample size\nrequired (up to a constant) for reliably identifying the top-$K$ items, and\ndemonstrate how it scales with the relative size. Moreover, by leveraging a\ntensor decomposition method for disambiguating mixture distributions, we extend\nour result to the more realistic scenario in which the relative population size\nis unknown, thus establishing an upper bound on the fundamental limit of the\nsample size for recovering the top-$K$ set. \n\n"}
{"id": "1602.07795", "contents": "Title: Expectation Consistent Approximate Inference: Generalizations and\n  Convergence Abstract: Approximations of loopy belief propagation, including expectation propagation\nand approximate message passing, have attracted considerable attention for\nprobabilistic inference problems. This paper proposes and analyzes a\ngeneralization of Opper and Winther's expectation consistent (EC) approximate\ninference method. The proposed method, called Generalized Expectation\nConsistency (GEC), can be applied to both maximum a posteriori (MAP) and\nminimum mean squared error (MMSE) estimation. Here we characterize its fixed\npoints, convergence, and performance relative to the replica prediction of\noptimality. \n\n"}
{"id": "1602.08290", "contents": "Title: Explicit back-off rates for achieving target throughputs in CSMA/CA\n  networks Abstract: CSMA/CA networks have often been analyzed using a stylized model that is\nfully characterized by a vector of back-off rates and a conflict graph.\nFurther, for any achievable throughput vector $\\vec \\theta$ the existence of a\nunique vector $\\vec \\nu(\\vec \\theta)$ of back-off rates that achieves this\nthroughput vector was proven. Although this unique vector can in principle be\ncomputed iteratively, the required time complexity grows exponentially in the\nnetwork size, making this only feasible for small networks.\n  In this paper, we present an explicit formula for the unique vector of\nback-off rates $\\vec \\nu(\\vec \\theta)$ needed to achieve any achievable\nthroughput vector $\\vec \\theta$ provided that the network has a chordal\nconflict graph. This class of networks contains a number of special cases of\ninterest such as (inhomogeneous) line networks and networks with an acyclic\nconflict graph. Moreover, these back-off rates are such that the back-off rate\nof a node only depends on its own target throughput and the target throughput\nof its neighbors and can be determined in a distributed manner.\n  We further indicate that back-off rates of this form cannot be obtained in\ngeneral for networks with non-chordal conflict graphs. For general conflict\ngraphs we nevertheless show how to adapt the back-off rates when a node is\nadded to the network when its interfering nodes form a clique in the conflict\ngraph. Finally, we introduce a distributed chordal approximation algorithm for\ngeneral conflict graphs which is shown (using numerical examples) to be more\naccurate than the Bethe approximation. \n\n"}
{"id": "1602.08898", "contents": "Title: Converse bounds for private communication over quantum channels Abstract: This paper establishes several converse bounds on the private transmission\ncapabilities of a quantum channel. The main conceptual development builds\nfirmly on the notion of a private state, which is a powerful, uniquely quantum\nmethod for simplifying the tripartite picture of privacy involving local\noperations and public classical communication to a bipartite picture of quantum\nprivacy involving local operations and classical communication. This approach\nhas previously led to some of the strongest upper bounds on secret key rates,\nincluding the squashed entanglement and the relative entropy of entanglement.\nHere we use this approach along with a \"privacy test\" to establish a general\nmeta-converse bound for private communication, which has a number of\napplications. The meta-converse allows for proving that any quantum channel's\nrelative entropy of entanglement is a strong converse rate for private\ncommunication. For covariant channels, the meta-converse also leads to\nsecond-order expansions of relative entropy of entanglement bounds for private\ncommunication rates. For such channels, the bounds also apply to the private\ncommunication setting in which the sender and receiver are assisted by\nunlimited public classical communication, and as such, they are relevant for\nestablishing various converse bounds for quantum key distribution protocols\nconducted over these channels. We find precise characterizations for several\nchannels of interest and apply the methods to establish several converse bounds\non the private transmission capabilities of all phase-insensitive bosonic\nchannels. \n\n"}
{"id": "1602.09140", "contents": "Title: Information Reconciliation for Continuous-Variable Quantum Key\n  Distribution using Non-Binary Low-Density Parity-Check Codes Abstract: An information reconciliation method for continuous-variable quantum key\ndistribution with Gaussian modulation that is based on non-binary low-density\nparity-check (LDPC) codes is presented. Sets of regular and irregular LDPC\ncodes with different code rates over the Galois fields $GF(8)$, $GF(16)$,\n$GF(32)$, and $GF(64)$ have been constructed. We have performed simulations to\nanalyze the efficiency and the frame error rate using the sum-product\nalgorithm. The proposed method achieves an efficiency between $0.94$ and $0.98$\nif the signal-to-noise ratio is between $4$ dB and $24$ dB. \n\n"}
{"id": "1603.01592", "contents": "Title: Phase Retrieval of Real-Valued Signals in a Shift-Invariant Space Abstract: Phase retrieval arises in various fields of science and engineering and it is\nwell studied in a finite-dimensional setting. In this paper, we consider an\ninfinite-dimensional phase retrieval problem to reconstruct real-valued signals\nliving in a shift-invariant space from its phaseless samples taken either on\nthe whole line or on a set with finite sampling rate. We find the equivalence\nbetween nonseparability of signals in a linear space and its phase\nretrievability with phaseless samples taken on the whole line. For a spline\nsignal of order $N$, we show that it can be well approximated, up to a sign,\nfrom its noisy phaseless samples taken on a set with sampling rate $2N-1$. We\npropose an algorithm to reconstruct nonseparable signals in a shift-invariant\nspace generated by a compactly supported continuous function. The proposed\nalgorithm is robust against bounded sampling noise and it could be implemented\nin a distributed manner. \n\n"}
{"id": "1603.01675", "contents": "Title: Capacity of Systems with Queue-Length Dependent Service Quality Abstract: We study the information-theoretic limit of reliable information processing\nby a server with queue-length dependent quality of service. We define the\ncapacity for such a system as the number of bits reliably processed per unit\ntime, and characterize it in terms of queuing system parameters. We also\ncharacterize the distributions of the arrival and service processes that\nmaximize and minimize the capacity of such systems in a discrete-time setting.\nFor arrival processes with at most one arrival per time slot, we observed a\nminimum around the memoryless distribution. We also studied the case of\nmultiple arrivals per time slot, and observed that burstiness in arrival has\nadverse effects on the system. The problem is theoretically motivated by an\neffort to incorporate the notion of reliability in queueing systems, and is\napplicable in the contexts of crowdsourcing, multimedia communication, and\nstream computing. \n\n"}
{"id": "1603.05576", "contents": "Title: Extracting Wyner's Common Information Using Polar Codes and Polar\n  Lattices Abstract: Explicit constructions of polar codes and polar lattices for both lossless\nand lossy Gray-Wyner problems are studied. Polar codes are employed to extract\nWyner's common information of doubly symmetric binary source; polar lattices\nare then extended to extract that of a pair of Gaussian sources or multiple\nGaussian sources. With regard to the discrete sources, the entire best-known\nregion of the lossless Gray-Wyner problem are achieved by specifying the test\nchannels to construct polar codes without time-sharing. As a result, we are\nable to give an interpretation that the Wyner's common information remains the\nsame to the lossy case when the distortion is small [1]. Finally, the entire\nbest-known lossy Gray-Wyner region for discrete sources can also be achieved\nusing polar codes. With regard to the Gaussian sources, the best-known lossy\nGray-Wyner region for bivariate Gaussian sources with a specific covariance\nmatrix [1] can be achieved by using polar lattices. Moreover, we prove that\nextracting Wyner's common information of a pair of Gaussian sources is\nequivalent to implementing the lossy compression for a single Gaussian source,\nwhich implies that the common information can be extracted by a polar lattice\nfor quantization. Furthermore, we extend this result to the case of multiple\nGaussian sources. \n\n"}
{"id": "1603.05823", "contents": "Title: Optimal Throughput for Covert Communication Over a Classical-Quantum\n  Channel Abstract: This paper considers the problem of communication over a memoryless\nclassical-quantum wiretap channel subject to the constraint that the\neavesdropper on the channel should not be able to learn whether the legitimate\nparties are using the channel to communicate or not. Specifically, the relative\nentropy between the output quantum states at the eavesdropper when a codeword\nis transmitted and when no input is provided must be sufficiently small.\nExtending earlier works, this paper proves the \"square-root law\" for a broad\nclass of classical-quantum channels: the maximum amount of information that can\nbe reliably and covertly transmitted over $n$ uses of such a channel scales\nlike $\\sqrt{n}$. The scaling constant is also determined. \n\n"}
{"id": "1603.05953", "contents": "Title: Katyusha: The First Direct Acceleration of Stochastic Gradient Methods Abstract: Nesterov's momentum trick is famously known for accelerating gradient\ndescent, and has been proven useful in building fast iterative algorithms.\nHowever, in the stochastic setting, counterexamples exist and prevent\nNesterov's momentum from providing similar acceleration, even if the underlying\nproblem is convex and finite-sum.\n  We introduce $\\mathtt{Katyusha}$, a direct, primal-only stochastic gradient\nmethod to fix this issue. In convex finite-sum stochastic optimization,\n$\\mathtt{Katyusha}$ has an optimal accelerated convergence rate, and enjoys an\noptimal parallel linear speedup in the mini-batch setting.\n  The main ingredient is $\\textit{Katyusha momentum}$, a novel \"negative\nmomentum\" on top of Nesterov's momentum. It can be incorporated into a\nvariance-reduction based algorithm and speed it up, both in terms of\n$\\textit{sequential and parallel}$ performance. Since variance reduction has\nbeen successfully applied to a growing list of practical problems, our paper\nsuggests that in each of such cases, one could potentially try to give Katyusha\na hug. \n\n"}
{"id": "1603.06286", "contents": "Title: A Generalized LDPC Framework for Robust and Sublinear Compressive\n  Sensing Abstract: Compressive sensing aims to recover a high-dimensional sparse signal from a\nrelatively small number of measurements. In this paper, a novel design of the\nmeasurement matrix is proposed. The design is inspired by the construction of\ngeneralized low-density parity-check codes, where the capacity-achieving\npoint-to-point codes serve as subcodes to robustly estimate the signal support.\nIn the case that each entry of the $n$-dimensional $k$-sparse signal lies in a\nknown discrete alphabet, the proposed scheme requires only $O(k \\log n)$\nmeasurements and arithmetic operations. In the case of arbitrary, possibly\ncontinuous alphabet, an error propagation graph is proposed to characterize the\nresidual estimation error. With $O(k \\log^2 n)$ measurements and computational\ncomplexity, the reconstruction error can be made arbitrarily small with high\nprobability. \n\n"}
{"id": "1603.06607", "contents": "Title: Consequences of high-$x$ proton size fluctuations in small collision\n  systems at RHIC Abstract: Recent measurements of jet production rates at large transverse momentum\n($p_T$) in the collisions of small projectiles with large nuclei at RHIC and\nthe LHC indicate that they have an unexpected relationship with estimates of\nthe collision centrality. One compelling interpretation of the data is that it\ncaptures an $x_p$-dependent decrease in the average interaction strength of the\nnucleon in the projectile undergoing a hard scattering. A weakly interacting or\n\"shrinking\" nucleon in the projectile strikes fewer nucleons in the nucleus,\nresulting in a particular pattern of centrality-dependent modifications to\nhigh-$p_T$ processes. We describe a simple one-parameter geometric\nimplementation of this picture within a modified Monte Carlo Glauber model\ntuned to $d$$+$Au jet data, and explore two of its major consequences. First,\nthe model predicts a particular projectile-species dependence to the centrality\ndependence at high-$x_p$, opposite to that expected from an energy loss effect.\nSecond, we find that some of the large centrality dependence observed for\nforward di-hadron production in $d$$+$Au collisions at RHIC may arise from the\nphysics of the \"shrinking\" projectile nucleon, in addition to impact\nparameter-dependent shadowing or saturation effects at low nuclear-$x$. We\nconclude that analogous measurements in recently collected $p$$+$Au and\n$^3$He$+$Au collision data at RHIC can provide a unique test of these\npredictions. \n\n"}
{"id": "1603.07327", "contents": "Title: Constellation Shaping for WDM systems using 256QAM/1024QAM with\n  Probabilistic Optimization Abstract: In this paper, probabilistic shaping is numerically and experimentally\ninvestigated for increasing the transmission reach of wavelength division\nmultiplexed (WDM) optical communication system employing quadrature amplitude\nmodulation (QAM). An optimized probability mass function (PMF) of the QAM\nsymbols is first found from a modified Blahut-Arimoto algorithm for the optical\nchannel. A turbo coded bit interleaved coded modulation system is then applied,\nwhich relies on many-to-one labeling to achieve the desired PMF, thereby\nachieving shaping gain. Pilot symbols at rate at most 2% are used for\nsynchronization and equalization, making it possible to receive input\nconstellations as large as 1024QAM. The system is evaluated experimentally on a\n10 GBaud, 5 channels WDM setup. The maximum system reach is increased w.r.t.\nstandard 1024QAM by 20% at input data rate of 4.65 bits/symbol and up to 75% at\n5.46 bits/symbol. It is shown that rate adaptation does not require changing of\nthe modulation format. The performance of the proposed 1024QAM shaped system is\nvalidated on all 5 channels of the WDM signal for selected distances and rates.\nFinally, it was shown via EXIT charts and BER analysis that iterative\ndemapping, while generally beneficial to the system, is not a requirement for\nachieving the shaping gain. \n\n"}
{"id": "1603.09707", "contents": "Title: Capacity of Remotely Powered Communication Abstract: Motivated by recent developments in wireless power transfer, we study\ncommunication with a remotely powered transmitter. We propose an\ninformation-theoretic model where a charger can dynamically decide on how much\npower to transfer to the transmitter based on its side information regarding\nthe communication, while the transmitter needs to dynamically adapt its coding\nstrategy to its instantaneous energy state, which in turn depends on the\nactions previously taken by the charger. We characterize the capacity as an\n$n$-letter mutual information rate under various levels of side information\navailable at the charger. When the charger is finely tunable to different\nenergy levels, referred to as a \"precision charger\", we show that these\nexpressions reduce to single-letter form and there is a simple and intuitive\njoint charging and coding scheme achieving capacity. The precision charger\nscenario is motivated by the observation that in practice the transferred\nenergy can be controlled by simply changing the amplitude of the beamformed\nsignal. When the charger does not have sufficient precision, for example when\nit is restricted to use a few discrete energy levels, we show that the\ncomputation of the $n$-letter capacity can be cast as a Markov decision process\nif the channel is noiseless. This allows us to numerically compute the capacity\nfor specific cases and obtain insights on the corresponding optimal policy, or\neven to obtain closed form analytical solutions by solving the corresponding\nBellman equations, as we demonstrate through examples. Our findings provide\nsome surprising insights on how side information at the charger can be used to\nincrease the overall capacity of the system. \n\n"}
{"id": "1604.01566", "contents": "Title: Achievable Rates for Gaussian Degraded Relay Channels with Non-Vanishing\n  Error Probabilities Abstract: This paper revisits the Gaussian degraded relay channel, where the link that\ncarries information from the source to the destination is a physically degraded\nversion of the link that carries information from the source to the relay. The\nsource and the relay are subject to expected power constraints. The\n$\\varepsilon$-capacity of the channel is characterized and it is strictly\nlarger than the capacity for $\\varepsilon>0$, which implies that the channel\ndoes not possess the strong converse property. The proof of the achievability\npart is based on several key ideas: block Markov coding which is used in the\nclassical decode-forward strategy, power control for Gaussian channels under\nexpected power constraints, and a careful scaling between the block size and\nthe total number of block uses. The converse part is proved by first\nestablishing two non-asymptotic lower bounds on the error probability, which\nare derived from the type-II errors of some binary hypothesis tests.\nSubsequently, each lower bound is simplified by conditioning on an event\nrelated to the power of some linear combination of the codewords transmitted by\nthe source and the relay. Lower and upper bounds on the second-order term of\nthe optimal coding rate in terms of blocklength and error probability are also\nobtained. \n\n"}
{"id": "1604.01653", "contents": "Title: Optimal DoF of the K-User Broadcast Channel with Delayed and Imperfect\n  Current CSIT Abstract: This work studies the optimal Degrees-of-Freedom (DoF) of the $K$-User MISO\nBroadcast Channel (BC) with delayed Channel-State Information at the\nTransmitter (CSIT) and with additional current noisy CSIT where the current\nchannel estimation error scales in~$P^{-\\alpha}$ for $\\alpha\\in[0,1]$. This\npapers establishes for the first time the optimal DoF in this setting thanks to\na new transmission scheme which achieves the elusive DoF-optimal combining of\nthe Maddah-Ali and Tse scheme (MAT) introduced in their seminal work in $2010$\nwith Zero-Forcing (ZF) for an arbitrary number of users. The derived sum DoF\ntakes the surprisingly simple form $(1-\\alpha) K/H_K+\\alpha K$ where\n$H_K\\triangleq \\sum_{k=1}^K \\frac{1}{k}$ is the sum-DoF achieved using solely\nMAT. \n\n"}
{"id": "1604.02058", "contents": "Title: Sufficient Conditions for Existence of $J_{\\alpha}(X +\n  \\sqrt[\\alpha]{\\eta}N)$ Abstract: In his technical report~\\cite[sec. 6]{barrontech}, Barron states that the de\nBruijn's identity for Gaussian perturbations holds for any RV having a finite\nvariance. In this report, we follow Barron's steps as we prove the existence of\n$J_{\\alpha}\\left(X + \\sqrt[\\alpha]{\\eta}N\\right)$, $\\eta > 0$ for any Radom\nVariable (RV) $X \\in \\mathcal{L}$ where \\begin{equation*} \\mathcal{L} = \\left\\{\n\\text{RVs} \\,\\,U: \\int \\ln\\left(1 + |U|\\right)\\,dF_{U}(u) \\text{ is finite }\n\\right\\}, \\end{equation*} and where $N \\sim \\mathcal{S}(\\alpha;1)$ is\nindependent of $X$, $0< \\alpha <2$. \n\n"}
{"id": "1604.02390", "contents": "Title: Minimax Optimal Procedures for Locally Private Estimation Abstract: Working under a model of privacy in which data remains private even from the\nstatistician, we study the tradeoff between privacy guarantees and the risk of\nthe resulting statistical estimators. We develop private versions of classical\ninformation-theoretic bounds, in particular those due to Le Cam, Fano, and\nAssouad. These inequalities allow for a precise characterization of statistical\nrates under local privacy constraints and the development of provably (minimax)\noptimal estimation procedures. We provide a treatment of several canonical\nfamilies of problems: mean estimation and median estimation, generalized linear\nmodels, and nonparametric density estimation. For all of these families, we\nprovide lower and upper bounds that match up to constant factors, and exhibit\nnew (optimal) privacy-preserving mechanisms and computationally efficient\nestimators that achieve the bounds. Additionally, we present a variety of\nexperimental results for estimation problems involving sensitive data,\nincluding salaries, censored blog posts and articles, and drug abuse; these\nexperiments demonstrate the importance of deriving optimal procedures. \n\n"}
{"id": "1604.02517", "contents": "Title: Throughput Maximization for Mobile Relaying Systems Abstract: Relaying is an effective technique to achieve reliable wireless connectivity\nin harsh communication environment. However, most of the existing relaying\nschemes are based on relays with fixed locations, or \\emph{static relaying}. In\nthis paper, we consider a novel \\emph{mobile relaying} technique, where the\nrelay nodes are assumed to be capable of moving at high speed. Compared to\nstatic relaying, mobile relaying offers a new degree of freedom for performance\nenhancement via careful relay trajectory design. We study the throughput\nmaximization problem in mobile relaying systems by optimizing the source/relay\ntransmit power along with the relay trajectory, subject to practical mobility\nconstraints (on the relay speed and initial/final relay locations), as well as\nthe \\emph{information-causality constraint} at the relay owing to its\ndecode-store-and-forward (DSF) strategy. It is shown that for fixed relay\ntrajectory, the throughput-optimal source/relay power allocations over time\nfollow a \"staircase\" water filling (WF) structure, with \\emph{non-increasing}\nand \\emph{non-decreasing} water levels at the source and relay, respectively.\nOn the other hand, with given power allocations, the throughput can be further\nimproved by optimizing the relay trajectory via successive convex optimization.\nAn iterative algorithm is thus proposed to optimize the power allocations and\nrelay trajectory alternately. Furthermore, for the special case with free\ninitial and final relay locations, the jointly optimal power allocation and\nrelay trajectory are derived. Numerical results show that by optimizing the\ntrajectory of the relay and power allocations adaptive to its induced channel\nvariation, mobile relaying is able to achieve significant throughput gains over\nthe conventional static relaying. \n\n"}
{"id": "1604.04033", "contents": "Title: From dripline to dripline: Nuclear astrophysics in the laboratory Abstract: For the better part of a century the field of nuclear astrophysics has aimed\nto answer fundamental questions about nature, such as the origin of the\nelements and the behavior of high-density, low-temperature matter. Sustained\nand concerted efforts in nuclear experiment have been key to achieving progress\nin these areas and will continue to be so. Here I will briefly review recent\naccomplishments and open questions in experimental nuclear astrophysics. \n\n"}
{"id": "1604.04351", "contents": "Title: Construction of de Bruijn Sequences from Product of Two Irreducible\n  Polynomials Abstract: We study a class of Linear Feedback Shift Registers (LFSRs) with\ncharacteristic polynomial $f(x)=p(x)q(x)$ where $p(x)$ and $q(x)$ are distinct\nirreducible polynomials in $\\F_2[x]$. Important properties of the LFSRs, such\nas the cycle structure and the adjacency graph, are derived. A method to\ndetermine a state belonging to each cycle and a generic algorithm to find all\nconjugate pairs shared by any pair of cycles are given. The process explicitly\ndetermines the edges and their labels in the adjacency graph. The results are\nthen combined with the cycle joining method to efficiently construct a new\nclass of de Bruijn sequences. An estimate of the number of resulting sequences\nis given. In some cases, using cyclotomic numbers, we can determine the number\nexactly. \n\n"}
{"id": "1604.04888", "contents": "Title: Structured low-rank recovery of piecewise constant signals with\n  performance guarantees Abstract: We derive theoretical guarantees for the exact recovery of piecewise constant\ntwo-dimensional images from a minimal number of non-uniform Fourier samples\nusing a convex matrix completion algorithm. We assume the discontinuities of\nthe image are localized to the zero level-set of a bandlimited function, which\ninduces certain linear dependencies in Fourier domain, such that a multifold\nToeplitz matrix built from the Fourier data is known to be low-rank. The\nrecovery algorithm arranges the known Fourier samples into the structured\nmatrix then attempts recovery of the missing Fourier data by minimizing the\nnuclear norm subject to structure and data constraints. This work adapts\nresults by Chen and Chi on the recovery of isolated Diracs via nuclear norm\nminimization of a similar multifold Hankel structure. We show that exact\nrecovery is possible with high probability when the bandlimited function\ndescribing the edge set satisfies an incoherency property. Finally, we\ndemonstrate the algorithm on the recovery of undersampled MRI data. \n\n"}
{"id": "1604.05332", "contents": "Title: Correction methods for finite-acceptance effects in two-particle\n  correlation analyses Abstract: Two-particle angular correlations have been widely used as a tool to explore\nparticle production mechanisms in heavy-ion collisions. The mixed-event\ntechnique is generally used as a standard method to correct for\nfinite-acceptance effects. We demonstrate that event mixing only provides an\napproximate acceptance correction, and propose new methods for\nfinite-acceptance corrections. Starting from discussions about 2-dimensional\ncorrection procedures, new methods are derived for specific assumptions on the\nproperties of the signal, such as uniform signal distribution or\n$\\delta$-function-like trigger particle distribution, and suitable for\ntwo-particle correlation analyses from particles at mid-rapidity and jet-hadron\nor high $p_{\\text{T}}$-triggered hadron-hadron correlations. Per-trigger\nassociated particle yields from the mixed-event method and the new methods are\ncompared through Monte Carlo simulations containing well-defined correlation\nsignals. Significant differences are observed at large pseudorapidity\ndifferences in general and especially for asymmetric particle distribution like\nthat produced in proton--nucleus collisions. The applicability and validity of\nthe new methods are discussed in detail. \n\n"}
{"id": "1604.05991", "contents": "Title: Bounding the optimal rate of the ICSI and ICCSI problem Abstract: In this work we study both the index coding with side information (ICSI)\nproblem introduced by Birk and Kol in 1998 and the more general problem of\nindex coding with coded side information (ICCSI), described by Shum et al in\n2012. We estimate the optimal rate of an instance of the index coding problem.\nIn the ICSI problem case, we characterize those digraphs having min-rank one\nless than their order and we give an upper bound on the min-rank of a\nhypergraph whose incidence matrix can be associated with that of a 2-design.\nSecurity aspects are discussed in the particular case when the design is a\nprojective plane. For the coded side information case, we extend the graph\ntheoretic upper bounds given by Shanmugam et al in 2014 on the optimal rate of\nindex code. \n\n"}
{"id": "1604.07143", "contents": "Title: Neural Random Forests Abstract: Given an ensemble of randomized regression trees, it is possible to\nrestructure them as a collection of multilayered neural networks with\nparticular connection weights. Following this principle, we reformulate the\nrandom forest method of Breiman (2001) into a neural network setting, and in\nturn propose two new hybrid procedures that we call neural random forests. Both\npredictors exploit prior knowledge of regression trees for their architecture,\nhave less parameters to tune than standard networks, and less restrictions on\nthe geometry of the decision boundaries than trees. Consistency results are\nproved, and substantial numerical evidence is provided on both synthetic and\nreal data sets to assess the excellent performance of our methods in a large\nvariety of prediction problems. \n\n"}
{"id": "1604.07281", "contents": "Title: Phase Retrieval Without Small-Ball Probability Assumptions Abstract: In the context of the phase retrieval problem, it is known that certain\nnatural classes of measurements, such as Fourier measurements and random\nBernoulli measurements, do not lead to the unique reconstruction of all\npossible signals, even in combination with certain practically feasible random\nmasks. To avoid this difficulty, the analysis is often restricted to\nmeasurement ensembles (or masks) that satisfy a small-ball probability\ncondition, in order to ensure that the reconstruction is unique.\n  This paper shows a complementary result: for random Bernoulli measurements,\nthere is still a large class of signals that can be reconstructed uniquely,\nnamely those signals that are \"non-peaky.\" In fact, this result is much more\ngeneral: it holds for random measurements sampled from any subgaussian\ndistribution D, without any small-ball conditions. This is demonstrated in two\nways: first, a proof of stability and uniqueness, and second, a uniform\nrecovery guarantee for the PhaseLift algorithm. In all of these cases, the\nnumber of measurements m approaches the information-theoretic lower bound.\n  Finally, for random Bernoulli measurements with erasures, it is shown that\nPhaseLift achieves uniform recovery of all signals (including peaky ones). \n\n"}
{"id": "1605.01033", "contents": "Title: Universal Multiparty Data Exchange and Secret Key Agreement Abstract: Multiple parties observing correlated data seek to recover each other's data\nand attain omniscience. To that end, they communicate interactively over a\nnoiseless broadcast channel - each bit transmitted over this channel is\nreceived by all the parties. We give a universal interactive communication\nprotocol, termed the recursive data exchange protocol (RDE), which attains\nomniscience for any sequence of data observed by the parties and provide an\nindividual sequence guarantee of performance. As a by-product, for observations\nof length $n$, we show the universal rate optimality of RDE up to an\n$\\mathcal{O}\\left(n^{-\\frac 12}\\sqrt{\\log n}\\right)$ term in a generative\nsetting where the data sequence is independent and identically distributed (in\ntime). Furthermore, drawing on the duality between omniscience and secret key\nagreement due to Csiszar and Narayan, we obtain a universal protocol for\ngenerating a multiparty secret key of rate at most $\\mathcal{O}\\left(n^{-\\frac\n12}\\sqrt{\\log n}\\right)$ less than the maximum rate possible. A key feature of\nRDE is its recursive structure whereby when a subset $A$ of parties recover\neach-other's data, the rates appear as if the parties have been executing the\nprotocol in an alternative model where the parties in $A$ are collocated. \n\n"}
{"id": "1605.01473", "contents": "Title: Topological Interference Management with Reconfigurable Antennas Abstract: We study the symmetric degrees-of-freedom (DoF) of partially connected\ninterference networks under linear coding strategies at transmitters without\nchannel state information beyond topology. We assume that the receivers are\nequipped with reconfigurable antennas that can switch among their preset modes.\nIn such a network setting, we characterize the class of network topologies in\nwhich half linear symmetric DoF is achievable. Moreover, we derive a general\nupper bound on the linear symmetric DoF for arbitrary network topologies. We\nalso show that this upper bound is tight if the transmitters have at most two\nco-interferers. \n\n"}
{"id": "1605.01880", "contents": "Title: Privacy-Constrained Remote Source Coding Abstract: We consider the problem of revealing/sharing data in an efficient and secure\nway via a compact representation. The representation should ensure reliable\nreconstruction of the desired features/attributes while still preserve privacy\nof the secret parts of the data. The problem is formulated as a remote lossy\nsource coding with a privacy constraint where the remote source consists of\npublic and secret parts. Inner and outer bounds for the optimal tradeoff region\nof compression rate, distortion, and privacy leakage rate are given and shown\nto coincide for some special cases. When specializing the distortion measure to\na logarithmic loss function, the resulting rate-distortion-leakage tradeoff for\nthe case of identical side information forms an optimization problem which\ncorresponds to the \"secure\" version of the so-called information bottleneck. \n\n"}
{"id": "1605.01993", "contents": "Title: Coded Caching for a Large Number Of Users Abstract: Information theoretic analysis of a coded caching system is considered, in\nwhich a server with a database of N equal-size files, each F bits long, serves\nK users. Each user is assumed to have a local cache that can store M files,\ni.e., capacity of MF bits. Proactive caching to user terminals is considered,\nin which the caches are filled by the server in advance during the placement\nphase, without knowing the user requests. Each user requests a single file, and\nall the requests are satisfied simultaneously through a shared error-free link\nduring the delivery phase.\n  First, centralized coded caching is studied assuming both the number and the\nidentity of the active users in the delivery phase are known by the server\nduring the placement phase. A novel group-based centralized coded caching (GBC)\nscheme is proposed for a cache capacity of M = N/K. It is shown that this\nscheme achieves a smaller delivery rate than all the known schemes in the\nliterature. The improvement is then extended to a wider range of cache\ncapacities through memory-sharing between the proposed scheme and other known\nschemes in the literature. Next, the proposed centralized coded caching idea is\nexploited in the decentralized setting, in which the identities of the users\nthat participate in the delivery phase are assumed to be unknown during the\nplacement phase. It is shown that the proposed decentralized caching scheme\nalso achieves a delivery rate smaller than the state-of-the-art. Numerical\nsimulations are also presented to corroborate our theoretical results. \n\n"}
{"id": "1605.02693", "contents": "Title: Inference of High-dimensional Autoregressive Generalized Linear Models Abstract: Vector autoregressive models characterize a variety of time series in which\nlinear combinations of current and past observations can be used to accurately\npredict future observations. For instance, each element of an observation\nvector could correspond to a different node in a network, and the parameters of\nan autoregressive model would correspond to the impact of the network structure\non the time series evolution. Often these models are used successfully in\npractice to learn the structure of social, epidemiological, financial, or\nbiological neural networks. However, little is known about statistical\nguarantees on estimates of such models in non-Gaussian settings. This paper\naddresses the inference of the autoregressive parameters and associated network\nstructure within a generalized linear model framework that includes Poisson and\nBernoulli autoregressive processes. At the heart of this analysis is a\nsparsity-regularized maximum likelihood estimator. While\nsparsity-regularization is well-studied in the statistics and machine learning\ncommunities, those analysis methods cannot be applied to autoregressive\ngeneralized linear models because of the correlations and potential\nheteroscedasticity inherent in the observations. Sample complexity bounds are\nderived using a combination of martingale concentration inequalities and modern\nempirical process techniques for dependent random variables. These bounds,\nwhich are supported by several simulation studies, characterize the impact of\nvarious network parameters on estimator performance. \n\n"}
{"id": "1605.02701", "contents": "Title: Lower Bounds on Time-Space Trade-Offs for Approximate Near Neighbors Abstract: We show tight lower bounds for the entire trade-off between space and query\ntime for the Approximate Near Neighbor search problem. Our lower bounds hold in\na restricted model of computation, which captures all hashing-based approaches.\nIn articular, our lower bound matches the upper bound recently shown in\n[Laarhoven 2015] for the random instance on a Euclidean sphere (which we show\nin fact extends to the entire space $\\mathbb{R}^d$ using the techniques from\n[Andoni, Razenshteyn 2015]).\n  We also show tight, unconditional cell-probe lower bounds for one and two\nprobes, improving upon the best known bounds from [Panigrahy, Talwar, Wieder\n2010]. In particular, this is the first space lower bound (for any static data\nstructure) for two probes which is not polynomially smaller than for one probe.\nTo show the result for two probes, we establish and exploit a connection to\nlocally-decodable codes. \n\n"}
{"id": "1605.02928", "contents": "Title: Achievable Degrees of Freedom of the K-user MISO Broadcast Channel with\n  Alternating CSIT via Interference Creation-Resurrection Abstract: Channel state information at the transmitter affects the degrees of freedom\nof the wireless networks. In this paper, we analyze the DoF for the K-user\nmultiple-input single-output (MISO) broadcast channel (BC) with synergistic\nalternating channel state information at the transmitter (CSIT). Specifically,\nthe CSIT of each user alternates between three states, namely, perfect CSIT\n(P), delayed CSIT (D) and no CSIT (N) among different time slots. For the\nK-user MISO BC, we show that the total achievable degrees of freedom (DoF) are\ngiven by $\\frac{K^{2}}{2K-1}$ through utilizing the synergistic benefits of\nCSIT patterns. We compare the achievable DoF with results reported previously\nin the literature in the case of delayed CSIT and hybrid CSIT models. \n\n"}
{"id": "1605.05776", "contents": "Title: The Quality of the Covariance Selection Through Detection Problem and\n  AUC Bounds Abstract: We consider the problem of quantifying the quality of a model selection\nproblem for a graphical model. We discuss this by formulating the problem as a\ndetection problem. Model selection problems usually minimize a distance between\nthe original distribution and the model distribution. For the special case of\nGaussian distributions, the model selection problem simplifies to the\ncovariance selection problem which is widely discussed in literature by\nDempster [2] where the likelihood criterion is maximized or equivalently the\nKullback-Leibler (KL) divergence is minimized to compute the model covariance\nmatrix. While this solution is optimal for Gaussian distributions in the sense\nof the KL divergence, it is not optimal when compared with other information\ndivergences and criteria such as Area Under the Curve (AUC).\n  In this paper, we analytically compute upper and lower bounds for the AUC and\ndiscuss the quality of model selection problem using the AUC and its bounds as\nan accuracy measure in detection problem. We define the correlation\napproximation matrix (CAM) and show that analytical computation of the KL\ndivergence, the AUC and its bounds only depend on the eigenvalues of CAM. We\nalso show the relationship between the AUC, the KL divergence and the ROC curve\nby optimizing with respect to the ROC curve. In the examples provided, we pick\ntree structures as the simplest graphical models. We perform simulations on\nfully-connected graphs and compute the tree structured models by applying the\nwidely used Chow-Liu algorithm [3]. Examples show that the quality of tree\napproximation models are not good in general based on information divergences,\nthe AUC and its bounds when the number of nodes in the graphical model is\nlarge. We show both analytically and by simulations that the 1-AUC for the tree\napproximation model decays exponentially as the dimension of graphical model\nincreases. \n\n"}
{"id": "1605.06290", "contents": "Title: Constant Envelope Precoding for MIMO Systems Abstract: Constant envelope (CE) precoding is an appealing transmission technique,\nwhich enables highly efficient power amplification, and is realizable with a\nsingle radio frequency (RF) chain at the multi-antenna transmitter. In this\npaper, we study the transceiver design for a point-to-point multiple-input\nmultiple-output (MIMO) system with CE precoding. Both single-stream\ntransmission (i.e., beamforming) and multi-stream transmission (i.e., spatial\nmultiplexing) are considered. For single-stream transmission, we optimize the\nreceive beamforming vector to minimize the symbol error rate (SER) for any\ngiven channel realization and desired constellation at the combiner output. By\nreformulating the problem as an equivalent quadratically constrained quadratic\nprogram (QCQP), we propose an efficient semi-definite relaxation (SDR) based\nalgorithm to find an approximate solution. Next, for multi-stream transmission,\nwe propose a new scheme based on antenna grouping at the transmitter and\nminimum mean squared error (MMSE) or zero-forcing (ZF) based beamforming at the\nreceiver. The transmit antenna grouping and receive beamforming vectors are\nthen jointly designed to minimize the maximum SER over all data streams.\nFinally, the error-rate performance of single- versus multi-stream transmission\nis compared via simulations under different setups. \n\n"}
{"id": "1605.08201", "contents": "Title: Towards optimal nonlinearities for sparse recovery using higher-order\n  statistics Abstract: We consider machine learning techniques to develop low-latency approximate\nsolutions to a class of inverse problems. More precisely, we use a\nprobabilistic approach for the problem of recovering sparse stochastic signals\nthat are members of the $\\ell_p$-balls. In this context, we analyze the\nBayesian mean-square-error (MSE) for two types of estimators: (i) a linear\nestimator and (ii) a structured estimator composed of a linear operator\nfollowed by a Cartesian product of univariate nonlinear mappings. By\nconstruction, the complexity of the proposed nonlinear estimator is comparable\nto that of its linear counterpart since the nonlinear mapping can be\nimplemented efficiently in hardware by means of look-up tables (LUTs). The\nproposed structure lends itself to neural networks and iterative\nshrinkage/thresholding-type algorithms restricted to a single iterate (e.g. due\nto imposed hardware or latency constraints). By resorting to an alternating\nminimization technique, we obtain a sequence of optimized linear operators and\nnonlinear mappings that converge in the MSE objective. The result is attractive\nfor real-time applications where general iterative and convex optimization\nmethods are infeasible. \n\n"}
{"id": "1605.08285", "contents": "Title: Solving Systems of Random Quadratic Equations via Truncated Amplitude\n  Flow Abstract: This paper presents a new algorithm, termed \\emph{truncated amplitude flow}\n(TAF), to recover an unknown vector $\\bm{x}$ from a system of quadratic\nequations of the form $y_i=|\\langle\\bm{a}_i,\\bm{x}\\rangle|^2$, where\n$\\bm{a}_i$'s are given random measurement vectors. This problem is known to be\n\\emph{NP-hard} in general. We prove that as soon as the number of equations is\non the order of the number of unknowns, TAF recovers the solution exactly (up\nto a global unimodular constant) with high probability and complexity growing\nlinearly with both the number of unknowns and the number of equations. Our TAF\napproach adopts the \\emph{amplitude-based} empirical loss function, and\nproceeds in two stages. In the first stage, we introduce an\n\\emph{orthogonality-promoting} initialization that can be obtained with a few\npower iterations. Stage two refines the initial estimate by successive updates\nof scalable \\emph{truncated generalized gradient iterations}, which are able to\nhandle the rather challenging nonconvex and nonsmooth amplitude-based objective\nfunction. In particular, when vectors $\\bm{x}$ and $\\bm{a}_i$'s are\nreal-valued, our gradient truncation rule provably eliminates erroneously\nestimated signs with high probability to markedly improve upon its untruncated\nversion. Numerical tests using synthetic data and real images demonstrate that\nour initialization returns more accurate and robust estimates relative to\nspectral initializations. Furthermore, even under the same initialization, the\nproposed amplitude-based refinement outperforms existing Wirtinger flow\nvariants, corroborating the superior performance of TAF over state-of-the-art\nalgorithms. \n\n"}
{"id": "1605.09124", "contents": "Title: Minimax Rate-Optimal Estimation of Divergences between Discrete\n  Distributions Abstract: We study the minimax estimation of $\\alpha$-divergences between discrete\ndistributions for integer $\\alpha\\ge 1$, which include the Kullback--Leibler\ndivergence and the $\\chi^2$-divergences as special examples. Dropping the usual\ntheoretical tricks to acquire independence, we construct the first minimax\nrate-optimal estimator which does not require any Poissonization, sample\nsplitting, or explicit construction of approximating polynomials. The estimator\nuses a hybrid approach which solves a problem-independent linear program based\non moment matching in the non-smooth regime, and applies a problem-dependent\nbias-corrected plug-in estimator in the smooth regime, with a soft decision\nboundary between these regimes. \n\n"}
{"id": "1605.09333", "contents": "Title: Minimum distance of Line Orthogonal Grassmann Codes in even\n  characteristic Abstract: In this paper we determine the minimum distance of orthogonal line-Grassmann\ncodes for $q$ even. The case $q$ odd was solved in \"I. Cardinali, L. Giuzzi, K.\nKaipa, A. Pasini, Line Polar Grassmann Codes of Orthogonal Type, J. Pure\nApplied Algebra.\"\n  We also show that for $q$ even all minimum weight codewords are equivalent\nand that symplectic line-Grassmann codes are proper subcodes of codimension\n$2n$ of the orthogonal ones. \n\n"}
{"id": "1605.09551", "contents": "Title: Analysis of Remaining Uncertainties and Exponents under Various\n  Conditional R\\'{e}nyi Entropies Abstract: In this paper, we analyze the asymptotics of the normalized remaining\nuncertainty of a source when a compressed or hashed version of it and\ncorrelated side-information is observed. For this system, commonly known as\nSlepian-Wolf source coding, we establish the optimal (minimum) rate of\ncompression of the source to ensure that the remaining uncertainties vanish. We\nalso study the exponential rate of decay of the remaining uncertainty to zero\nwhen the rate is above the optimal rate of compression. In our study, we\nconsider various classes of random universal hash functions. Instead of\nmeasuring remaining uncertainties using traditional Shannon information\nmeasures, we do so using two forms of the conditional R\\'{e}nyi entropy. Among\nother techniques, we employ new one-shot bounds and the moments of type class\nenumerator method for these evaluations. We show that these asymptotic results\nare generalizations of the strong converse exponent and the error exponent of\nthe Slepian-Wolf problem under maximum \\emph{a posteriori} (MAP) decoding. \n\n"}
{"id": "1605.09551", "contents": "Title: Analysis of Remaining Uncertainties and Exponents under Various\n  Conditional R\\'{e}nyi Entropies Abstract: In this paper, we analyze the asymptotics of the normalized remaining\nuncertainty of a source when a compressed or hashed version of it and\ncorrelated side-information is observed. For this system, commonly known as\nSlepian-Wolf source coding, we establish the optimal (minimum) rate of\ncompression of the source to ensure that the remaining uncertainties vanish. We\nalso study the exponential rate of decay of the remaining uncertainty to zero\nwhen the rate is above the optimal rate of compression. In our study, we\nconsider various classes of random universal hash functions. Instead of\nmeasuring remaining uncertainties using traditional Shannon information\nmeasures, we do so using two forms of the conditional R\\'{e}nyi entropy. Among\nother techniques, we employ new one-shot bounds and the moments of type class\nenumerator method for these evaluations. We show that these asymptotic results\nare generalizations of the strong converse exponent and the error exponent of\nthe Slepian-Wolf problem under maximum \\emph{a posteriori} (MAP) decoding. \n\n"}
{"id": "1606.02307", "contents": "Title: Sifting Common Information from Many Variables Abstract: Measuring the relationship between any pair of variables is a rich and active\narea of research that is central to scientific practice. In contrast,\ncharacterizing the common information among any group of variables is typically\na theoretical exercise with few practical methods for high-dimensional data. A\npromising solution would be a multivariate generalization of the famous Wyner\ncommon information, but this approach relies on solving an apparently\nintractable optimization problem. We leverage the recently introduced\ninformation sieve decomposition to formulate an incremental version of the\ncommon information problem that admits a simple fixed point solution, fast\nconvergence, and complexity that is linear in the number of variables. This\nscalable approach allows us to demonstrate the usefulness of common information\nin high-dimensional learning problems. The sieve outperforms standard methods\non dimensionality reduction tasks, solves a blind source separation problem\nthat cannot be solved with ICA, and accurately recovers structure in brain\nimaging data. \n\n"}
{"id": "1606.03668", "contents": "Title: Spatial and Social Paradigms for Interference and Coverage Analysis in\n  Underlay D2D Network Abstract: The homogeneous Poisson point process (PPP) is widely used to model spatial\ndistribution of base stations and mobile terminals. The same process can be\nused to model underlay device-to-device (D2D) network, however, neglecting\nhomophilic relation for D2D pairing presents underestimated system insights. In\nthis paper, we model both spatial and social distributions of interfering D2D\nnodes as proximity based independently marked homogeneous Poisson point\nprocess. The proximity considers physical distance between D2D nodes whereas\nsocial relationship is modeled as Zipf based marks. We apply these two\nparadigms to analyze the effect of interference on coverage probability of\ndistance-proportional power-controlled cellular user. Effectively, we apply two\ntype of functional mappings (physical distance, social marks) to Laplace\nfunctional of PPP. The resulting coverage probability has no closed-form\nexpression, however for a subset of social marks, the mark summation converges\nto digamma and polygamma functions. This subset constitutes the upper and lower\nbounds on coverage probability. We present numerical evaluation of these bounds\non coverage probability by varying number of different parameters. The results\nshow that by imparting simple power control on cellular user, ultra-dense\nunderlay D2D network can be realized without compromising the coverage\nprobability of cellular user. \n\n"}
{"id": "1606.04991", "contents": "Title: A Class of Parallel Doubly Stochastic Algorithms for Large-Scale\n  Learning Abstract: We consider learning problems over training sets in which both, the number of\ntraining examples and the dimension of the feature vectors, are large. To solve\nthese problems we propose the random parallel stochastic algorithm (RAPSA). We\ncall the algorithm random parallel because it utilizes multiple parallel\nprocessors to operate on a randomly chosen subset of blocks of the feature\nvector. We call the algorithm stochastic because processors choose training\nsubsets uniformly at random. Algorithms that are parallel in either of these\ndimensions exist, but RAPSA is the first attempt at a methodology that is\nparallel in both the selection of blocks and the selection of elements of the\ntraining set. In RAPSA, processors utilize the randomly chosen functions to\ncompute the stochastic gradient component associated with a randomly chosen\nblock. The technical contribution of this paper is to show that this minimally\ncoordinated algorithm converges to the optimal classifier when the training\nobjective is convex. Moreover, we present an accelerated version of RAPSA\n(ARAPSA) that incorporates the objective function curvature information by\npremultiplying the descent direction by a Hessian approximation matrix. We\nfurther extend the results for asynchronous settings and show that if the\nprocessors perform their updates without any coordination the algorithms are\nstill convergent to the optimal argument. RAPSA and its extensions are then\nnumerically evaluated on a linear estimation problem and a binary image\nclassification task using the MNIST handwritten digit dataset. \n\n"}
{"id": "1606.06642", "contents": "Title: Particle production and equilibrium properties within a new hadron\n  transport approach for heavy-ion collisions Abstract: The microscopic description of heavy-ion reactions at low beam energies is\nachieved within hadronic transport approaches. In this article a new approach\nSMASH (Simulating Many Accelerated Strongly-interacting Hadrons) is introduced\nand applied to study the production of non-strange particles in heavy-ion\nreactions at $E_{\\rm kin}=0.4-2A$ GeV. First, the model is described including\ndetails about the collision criterion, the initial conditions and the resonance\nformation and decays. To validate the approach, equilibrium properties such as\ndetailed balance are presented and the results are compared to experimental\ndata for elementary cross sections. Finally results for pion and proton\nproduction in C+C and Au+Au collisions is confronted with HADES and FOPI data.\nPredictions for particle production in $\\pi+A$ collisions are made. \n\n"}
{"id": "1606.07384", "contents": "Title: Robust Learning of Fixed-Structure Bayesian Networks Abstract: We investigate the problem of learning Bayesian networks in a robust model\nwhere an $\\epsilon$-fraction of the samples are adversarially corrupted. In\nthis work, we study the fully observable discrete case where the structure of\nthe network is given. Even in this basic setting, previous learning algorithms\neither run in exponential time or lose dimension-dependent factors in their\nerror guarantees. We provide the first computationally efficient robust\nlearning algorithm for this problem with dimension-independent error\nguarantees. Our algorithm has near-optimal sample complexity, runs in\npolynomial time, and achieves error that scales nearly-linearly with the\nfraction of adversarially corrupted samples. Finally, we show on both synthetic\nand semi-synthetic data that our algorithm performs well in practice. \n\n"}
{"id": "1606.09157", "contents": "Title: Spectroscopy of the neutron-rich hypernucleus $^{7}_{\\Lambda}$He from\n  electron scattering Abstract: The missing mass spectroscopy of the $^{7}_{\\Lambda}$He hypernucleus was\nperformed, using the $^{7}$Li$(e,e^{\\prime}K^{+})^{7}_{\\Lambda}$He reaction at\nthe Thomas Jefferson National Accelerator Facility Hall C. The $\\Lambda$\nbinding energy of the ground state (1/2$^{+}$) was determined with a smaller\nerror than that of the previous measurement, being $B_{\\Lambda}$ = 5.55 $\\pm$\n0.10(stat.) $\\pm$ 0.11(sys.) MeV. The experiment also provided new insight into\ncharge symmetry breaking in p-shell hypernuclear systems. Finally, a peak at\n$B_{\\Lambda}$ = 3.65 $\\pm$ 0.20(stat.) $\\pm$ 0.11(sys.) MeV was observed and\nassigned as a mixture of 3/2$^{+}$ and 5/2$^{+}$ states, confirming the\n\"gluelike\" behavior of $\\Lambda$, which makes an unstable state in $^{6}$He\nstable against neutron emission. \n\n"}
{"id": "1607.01461", "contents": "Title: On the Minimum Mean $p$-th Error in Gaussian Noise Channels and its\n  Applications Abstract: The problem of estimating an arbitrary random vector from its observation\ncorrupted by additive white Gaussian noise, where the cost function is taken to\nbe the Minimum Mean $p$-th Error (MMPE), is considered. The classical Minimum\nMean Square Error (MMSE) is a special case of the MMPE. Several bounds,\nproperties and applications of the MMPE are derived and discussed. The optimal\nMMPE estimator is found for Gaussian and binary input distributions. Properties\nof the MMPE as a function of the input distribution, SNR and order $p$ are\nderived. In particular, it is shown that the MMPE is a continuous function of\n$p$ and SNR. These results are possible in view of interpolation and change of\nmeasure bounds on the MMPE. The `Single-Crossing-Point Property' (SCPP) that\nbounds the MMSE for all SNR values {\\it above} a certain value, at which the\nMMSE is known, together with the I-MMSE relationship is a powerful tool in\nderiving converse proofs in information theory. By studying the notion of\nconditional MMPE, a unifying proof (i.e., for any $p$) of the SCPP is shown. A\ncomplementary bound to the SCPP is then shown, which bounds the MMPE for all\nSNR values {\\it below} a certain value, at which the MMPE is known. As a first\napplication of the MMPE, a bound on the conditional differential entropy in\nterms of the MMPE is provided, which then yields a generalization of the\nOzarow-Wyner lower bound on the mutual information achieved by a discrete input\non a Gaussian noise channel. As a second application, the MMPE is shown to\nimprove on previous characterizations of the phase transition phenomenon that\nmanifests, in the limit as the length of the capacity achieving code goes to\ninfinity, as a discontinuity of the MMSE as a function of SNR. As a final\napplication, the MMPE is used to show bounds on the second derivative of mutual\ninformation, that tighten previously known bounds. \n\n"}
{"id": "1607.02298", "contents": "Title: On Channel Resolvability in Presence of Feedback Abstract: We study the problem of generating an approximately i.i.d. string at the\noutput of a discrete memoryless channel using a limited amount of randomness at\nits input in presence of causal noiseless feedback. Feedback does not decrease\nthe channel resolution, the minimum entropy rate required to achieve an\naccurate approximation of an i.i.d. output string. However, we show that, at\nleast over a binary symmetric channel, a significantly larger resolvability\nexponent (the exponential decay rate of the divergence between the output\ndistribution and product measure), compared to the best known achievable\nresolvability exponent in a system without feedback, is possible. We show that\nby employing a variable-length resolvability scheme and using an average number\nof coin-flips per channel use, the average divergence between the distribution\nof the output sequence and product measure decays exponentially fast in the\naverage length of output sequence with an exponent equal to $[R-I(U;V)]^+$\nwhere $I(U;V)$ is the mutual information developed across the channel. \n\n"}
{"id": "1607.03165", "contents": "Title: Deuteron charge radius and Rydberg constant from spectroscopy data in\n  atomic deuterium Abstract: We give a pedagogical description of the method to extract the charge radii\nand Rydberg constant from laser spectroscopy in regular hydrogen (H) and\ndeuterium (D) atoms, that is part of the CODATA least-squares adjustment (LSA)\nof the fundamental physical constants. We give a deuteron charge radius Rd from\nD spectroscopy alone of 2.1415(45) fm. This value is independent of the\nmeasurements that lead to the proton charge radius, and five times more\naccurate than the value found in the CODATA Adjustment 10. The improvement is\ndue to the use of a value for the 1S->2S transition in atomic deuterium which\ncan be inferred from published data or found in a PhD thesis. \n\n"}
{"id": "1607.03854", "contents": "Title: The Partially Observable Hidden Markov Model and its Application to\n  Keystroke Dynamics Abstract: The partially observable hidden Markov model is an extension of the hidden\nMarkov Model in which the hidden state is conditioned on an independent Markov\nchain. This structure is motivated by the presence of discrete metadata, such\nas an event type, that may partially reveal the hidden state but itself\nemanates from a separate process. Such a scenario is encountered in keystroke\ndynamics whereby a user's typing behavior is dependent on the text that is\ntyped. Under the assumption that the user can be in either an active or passive\nstate of typing, the keyboard key names are event types that partially reveal\nthe hidden state due to the presence of relatively longer time intervals\nbetween words and sentences than between letters of a word. Using five public\ndatasets, the proposed model is shown to consistently outperform other anomaly\ndetectors, including the standard HMM, in biometric identification and\nverification tasks and is generally preferred over the HMM in a Monte Carlo\ngoodness of fit test. \n\n"}
{"id": "1607.04849", "contents": "Title: Secure Group Testing Abstract: The principal goal of Group Testing (GT) is to identify a small subset of\n\"defective\" items from a large population, by grouping items into as few test\npools as possible. The test outcome of a pool is positive if it contains at\nleast one defective item, and is negative otherwise. GT algorithms are utilized\nin numerous applications, and in many of them maintaining the privacy of the\ntested items, namely, keeping secret whether they are defective or not, is\ncritical.\n  In this paper, we consider a scenario where there is an eavesdropper (Eve)\nwho is able to observe a subset of the GT outcomes (pools). We propose a new\nnon-adaptive Secure Group Testing (SGT) scheme based on information-theoretic\nprinciples. The new proposed test design keeps the eavesdropper ignorant\nregarding the items' status. Specifically, when the fraction of tests observed\nby Eve is $0 \\leq \\delta <1$, we prove that with the naive Maximum Likelihood\n(ML) decoding algorithm the number of tests required for both correct\nreconstruction at the legitimate user (with high probability) and negligible\ninformation leakage to Eve is $\\frac{1}{1-\\delta}$ times the number of tests\nrequired with no secrecy constraint for the fixed $K$ regime. By a matching\nconverse, we completely characterize the Secure GT capacity. Moreover, we\nconsider the Definitely Non-Defective (DND) computationally efficient decoding\nalgorithm, proposed in the literature for non-secure GT. We prove that with the\nnew secure test design, for $\\delta < 1/2$, the number of tests required,\nwithout any constraint on $K$, is at most $\\frac{1}{1/2-\\delta}$ times the\nnumber of tests required with no secrecy constraint. \n\n"}
{"id": "1607.05264", "contents": "Title: The Aerogel Cherenkov Detector for the SHMS magnetic spectrometer in\n  Hall C at Jefferson Lab Abstract: Hadronic reactions producing strange quarks such as exclusive or\nsemi-inclusive kaon production, play an important role in studies of hadron\nstructure and the dynamics that bind the most basic elements of nuclear\nphysics. The small-angle capability of the new Super High Momentum Spectrometer\n(SHMS) in Hall C, coupled with its high momentum reach - up to the anticipated\n11-GeV beam energy in Hall C - and coincidence capability with the\nwell-understood High Momentum Spectrometer, will allow for probes of such\nhadron structure involving strangeness down to the smallest distance scales to\ndate. To cleanly select the kaons, a threshold aerogel Cerenkov detector has\nbeen constructed for the SHMS. The detector consists of an aerogel tray\nfollowed by a diffusion box. Four trays for aerogel of nominal refractive\nindices of n=1.030, 1.020, 1.015 and 1.011 were constructed. The tray\ncombination will allow for identification of kaons from 1 GeV/c up to 7.2\nGeV/c, reaching 10^-2 proton and 10^-3 pion rejection, with kaon detection\nefficiency better than 95%. The diffusion box of the detector is equipped with\n14 five-inch diameter photomultiplier tubes. Its interior walls are covered\nwith Gore diffusive reflector, which is superior to the commonly used Millipore\npaper and improved the detector performance by 35%. The inner surface of the\ntwo aerogel trays with higher refractive index is covered with Millipore paper,\nhowever, those two trays with lower aerogel refractive index are again covered\nwith Gore diffusive reflector for higher performance. The measured mean number\nof photoelectrons in saturation is ~12 for n=1.030, ~sim8 for n=1.020, ~10 for\nn=1.015, and ~5.5 for n=1.011. The design details, the results of component\ncharacterization, and initial performance tests and optimization of the\ndetector are presented. \n\n"}
{"id": "1607.05459", "contents": "Title: Dynamic Joint Uplink and Downlink Optimization for Uplink and Downlink\n  Decoupling-Enabled 5G Heterogeneous Networks Abstract: The concept of user-centric and personalized service in the fifth generation\n(5G) mobile networks encourages technical solutions such as dynamic asymmetric\nuplink/downlink resource allocation and elastic association of cells to users\nwith decoupled uplink and downlink (DeUD) access. In this paper we develop a\njoint uplink and downlink optimization algorithm for DeUD-enabled wireless\nnetworks for adaptive joint uplink and downlink bandwidth allocation and power\ncontrol, under different link association policies. Based on a general model of\ninter-cell interference, we propose a three-step optimization algorithm to\njointly optimize the uplink and downlink bandwidth allocation and power\ncontrol, using the fixed point approach for nonlinear operators with or without\nmonotonicity, to maximize the minimum level of quality of service satisfaction\nper link, subjected to a general class of resource (power and bandwidth)\nconstraints. We present numerical results illustrating the theoretical findings\nfor network simulator in a real-world setting, and show the advantage of our\nsolution compared to the conventional proportional fairness resource allocation\nschemes in both the coupled uplink and downlink (CoUD) access and the novel\nlink association schemes in DeUD. \n\n"}
{"id": "1607.06833", "contents": "Title: Explicit Polyhedral Bounds on Network Coding Rate Regions via Entropy\n  Function Region: Algorithms, Symmetry, and Computation Abstract: Automating the solutions of multiple network information theory problems,\nstretching from fundamental concerns such as determining all information\ninequalities and the limitations of linear codes, to applied ones such as\ndesigning coded networks, distributed storage systems, and caching systems, can\nbe posed as polyhedral projections. These problems are demonstrated to exhibit\nmultiple types of polyhedral symmetries. It is shown how these symmetries can\nbe exploited to reduce the complexity of solving these problems through\npolyhedral projection. \n\n"}
{"id": "1607.07815", "contents": "Title: Strong Secrecy on a Class of Degraded Broadcast Channels Using Polar\n  Codes Abstract: Different polar coding schemes are proposed for the memoryless degraded\nbroadcast channel under different reliability and secrecy requirements: layered\ndecoding and/or layered secrecy. In this setting, the transmitter wishes to\nsend multiple messages to a set of legitimate receivers keeping them masked\nfrom a set of eavesdroppers. The layered decoding structure requires receivers\nwith better channel quality to reliably decode more messages, while the layered\nsecrecy structure requires eavesdroppers with worse channel quality to be kept\nignorant of more messages. The implementation of the proposed polar coding\nschemes is discussed and their performance is evaluated by simulations for the\nsymmetric degraded broadcast channel. \n\n"}
{"id": "1608.00075", "contents": "Title: Online Nonnegative Matrix Factorization with General Divergences Abstract: We develop a unified and systematic framework for performing online\nnonnegative matrix factorization under a wide variety of important divergences.\nThe online nature of our algorithm makes it particularly amenable to\nlarge-scale data. We prove that the sequence of learned dictionaries converges\nalmost surely to the set of critical points of the expected loss function. We\ndo so by leveraging the theory of stochastic approximations and projected\ndynamical systems. This result substantially generalizes the previous results\nobtained only for the squared-$\\ell_2$ loss. Moreover, the novel techniques\ninvolved in our analysis open new avenues for analyzing similar matrix\nfactorization problems. The computational efficiency and the quality of the\nlearned dictionary of our algorithm are verified empirically on both synthetic\nand real datasets. In particular, on the tasks of topic learning, shadow\nremoval and image denoising, our algorithm achieves superior trade-offs between\nthe quality of learned dictionary and running time over the batch and other\nonline NMF algorithms. \n\n"}
{"id": "1608.00075", "contents": "Title: Online Nonnegative Matrix Factorization with General Divergences Abstract: We develop a unified and systematic framework for performing online\nnonnegative matrix factorization under a wide variety of important divergences.\nThe online nature of our algorithm makes it particularly amenable to\nlarge-scale data. We prove that the sequence of learned dictionaries converges\nalmost surely to the set of critical points of the expected loss function. We\ndo so by leveraging the theory of stochastic approximations and projected\ndynamical systems. This result substantially generalizes the previous results\nobtained only for the squared-$\\ell_2$ loss. Moreover, the novel techniques\ninvolved in our analysis open new avenues for analyzing similar matrix\nfactorization problems. The computational efficiency and the quality of the\nlearned dictionary of our algorithm are verified empirically on both synthetic\nand real datasets. In particular, on the tasks of topic learning, shadow\nremoval and image denoising, our algorithm achieves superior trade-offs between\nthe quality of learned dictionary and running time over the batch and other\nonline NMF algorithms. \n\n"}
{"id": "1608.01805", "contents": "Title: R\\'enyi divergence and the central limit theorem Abstract: We explore properties of the $\\chi^2$ and more general R\\'enyi (Tsallis)\ndistances to the normal law. In particular we provide necessary and sufficient\nconditions for the convergence to the normal law in the central limit theorem\nusing these distances. Moreover, we derive exact rates of convergence in these\ndistances with respect to an increasing number of summands. \n\n"}
{"id": "1608.02554", "contents": "Title: Sparse recovery via Orthogonal Least-Squares under presence of Noise Abstract: We consider the Orthogonal Least-Squares (OLS) algorithm for the recovery of\na $m$-dimensional $k$-sparse signal from a low number of noisy linear\nmeasurements. The Exact Recovery Condition (ERC) in bounded noisy scenario is\nestablished for OLS under certain condition on nonzero elements of the signal.\nThe new result also improves the existing guarantees for Orthogonal Matching\nPursuit (OMP) algorithm. In addition, This framework is employed to provide\nprobabilistic guarantees for the case that the coefficient matrix is drawn at\nrandom according to Gaussian or Bernoulli distribution where we exploit some\nconcentration properties. It is shown that under certain conditions, OLS\nrecovers the true support in $k$ iterations with high probability. This in turn\ndemonstrates that ${\\cal O}\\left(k\\log m\\right)$ measurements is sufficient for\nexact recovery of sparse signals via OLS. \n\n"}
{"id": "1608.02902", "contents": "Title: Linear Regression with an Unknown Permutation: Statistical and\n  Computational Limits Abstract: Consider a noisy linear observation model with an unknown permutation, based\non observing $y = \\Pi^* A x^* + w$, where $x^* \\in \\mathbb{R}^d$ is an unknown\nvector, $\\Pi^*$ is an unknown $n \\times n$ permutation matrix, and $w \\in\n\\mathbb{R}^n$ is additive Gaussian noise. We analyze the problem of permutation\nrecovery in a random design setting in which the entries of the matrix $A$ are\ndrawn i.i.d. from a standard Gaussian distribution, and establish sharp\nconditions on the SNR, sample size $n$, and dimension $d$ under which $\\Pi^*$\nis exactly and approximately recoverable. On the computational front, we show\nthat the maximum likelihood estimate of $\\Pi^*$ is NP-hard to compute, while\nalso providing a polynomial time algorithm when $d =1$. \n\n"}
{"id": "1608.05094", "contents": "Title: Tolerant Compressed Sensing With Partially Coherent Sensing Matrices Abstract: Most of compressed sensing (CS) theory to date is focused on incoherent\nsensing, that is, columns from the sensing matrix are highly uncorrelated.\nHowever, sensing systems with naturally occurring correlations arise in many\napplications, such as signal detection, motion detection and radar. Moreover,\nin these applications it is often not necessary to know the support of the\nsignal exactly, but instead small errors in the support and signal are\ntolerable.\n  Despite the abundance of work utilizing incoherent sensing matrices, for this\ntype of tolerant recovery we suggest that coherence is actually beneficial. We\npromote the use of coherent sampling when tolerant support recovery is\nacceptable, and demonstrate its advantages empirically. In addition, we provide\na first step towards theoretical analysis by considering a specific\nreconstruction method for selected signal classes. \n\n"}
{"id": "1608.07632", "contents": "Title: Resource Allocation for Machine-to-Machine Communications with Unmanned\n  Aerial Vehicles Abstract: In this paper, a novel framework for power-efficient, cluster-based\nmachine-to-machine (M2M) communications is proposed. In the studied model, a\nnumber of unmanned aerial vehicles (UAVs) are used as aerial base stations to\ncollect data from the cluster heads (CHs) of a set of M2M clusters. To minimize\nthe CHs' transmit power while satisfying the rate requirements of M2M devices,\nan optimal scheduling and resource allocation mechanism for CH-UAV\ncommunications is proposed. First, using the queue rate stability concept, the\nminimum number of UAVs as well as the dwelling time that each UAV must spend\nfor servicing the CHs are computed. Next, the optimal resource allocation for\nthe CH-UAV communication links is determined such that M2M devices rate\nrequirements are satisfied with a minimum transmit power. Simulation results\nshow that, as the packet transmission probability of machines increases, the\nminimum number of UAVs required to guarantee the queue rate stability of CHs\nwill also significantly increase. Our results also show that, compared to a\ncase with pre-deployed terrestrial base stations, the average transmit power of\nCHs will decrease by 68% when UAVs are used. \n\n"}
{"id": "1608.07900", "contents": "Title: $X(4140)$, $X(4270)$, $X(4500)$ and $X(4700)$ and their\n  $cs\\bar{c}\\bar{s}$ tetraquark partners Abstract: In the simple color-magnetic interaction model, we investigate possible\nground $cs\\bar{c}\\bar{s}$ tetraquark states in the diquark-antidiquark basis.\nWe use several methods to estimate the mass spectrum and discuss possible\nassignment for the $X$ states observed in the $J/\\psi\\phi$ channel. We find\nthat assigning the Belle $X(4350)$ as a $0^{++}$ tetraquark is consistent with\nthe tetraquark interpretation for the $X(4140)$ and $X(4270)$ while the\ninterpretation of the $X(4500)$ and $X(4700)$ needs orbital or radial\nexcitation. There probably exist several tetraquarks around 4.3 GeV that decay\ninto $J/\\psi\\phi$ or $\\eta_c\\phi$. \n\n"}
{"id": "1608.08852", "contents": "Title: A Mathematical Framework for Feature Selection from Real-World Data with\n  Non-Linear Observations Abstract: In this paper, we study the challenge of feature selection based on a\nrelatively small collection of sample pairs $\\{(x_i, y_i)\\}_{1 \\leq i \\leq m}$.\nThe observations $y_i \\in \\mathbb{R}$ are thereby supposed to follow a noisy\nsingle-index model, depending on a certain set of signal variables. A major\ndifficulty is that these variables usually cannot be observed directly, but\nrather arise as hidden factors in the actual data vectors $x_i \\in\n\\mathbb{R}^d$ (feature variables). We will prove that a successful variable\nselection is still possible in this setup, even when the applied estimator does\nnot have any knowledge of the underlying model parameters and only takes the\n'raw' samples $\\{(x_i, y_i)\\}_{1 \\leq i \\leq m}$ as input. The model\nassumptions of our results will be fairly general, allowing for non-linear\nobservations, arbitrary convex signal structures as well as strictly convex\nloss functions. This is particularly appealing for practical purposes, since in\nmany applications, already standard methods, e.g., the Lasso or logistic\nregression, yield surprisingly good outcomes. Apart from a general discussion\nof the practical scope of our theoretical findings, we will also derive a\nrigorous guarantee for a specific real-world problem, namely sparse feature\nextraction from (proteomics-based) mass spectrometry data. \n\n"}
{"id": "1609.00594", "contents": "Title: On Gaussian MACs with Variable-Length Feedback and Non-Vanishing\n  Error~Probabilities Abstract: We characterize the fundamental limits of transmission of information over a\nGaussian multiple access channel (MAC) with the use of variable-length feedback\ncodes and under a non-vanishing error probability formalism. We develop new\nachievability and converse techniques to handle the continuous nature of the\nchannel and the presence of expected power constraints. We establish the\n$\\varepsilon$-capacity regions and bounds on the second-order asymptotics of\nthe Gaussian MAC with variable-length feedback with termination (VLFT) codes\nand stop-feedback codes. We show that the former outperforms the latter\nsignificantly. Due to the multi-terminal nature of the channel model, we\nleverage tools from renewal theory developed by Lai and Siegmund to bound the\nasymptotic behavior of the maximum of a finite number of stopping times. \n\n"}
{"id": "1609.00832", "contents": "Title: Information Measures, Inequalities and Performance Bounds for Parameter\n  Estimation in Impulsive Noise Environments Abstract: Recent studies found that many channels are affected by additive noise that\nis impulsive in nature and is best explained by heavy-tailed symmetric\nalpha-stable distributions. Dealing with impulsive noise environments comes\nwith an added complexity with respect to the standard Gaussian environment: the\nalpha-stable probability density functions have an infinite second moment and\nthe \"nice\" Hilbert space structure of the space of random variables having a\nfinite second moment is lost along with its tools and methodologies. This is\nindeed the case in estimation theory where classical tools to quantify\nperformance of an estimator are tightly related to the assumption of finite\nvariance variables. In alpha-stable environments, expressions such as the mean\nsquare error and the Cramer-Rao bound are hence problematic. In this work, we\ntackle the parameter estimation problem in impulsive noise environments and\ndevelop novel tools that are tailored to the alpha-stable and heavy-tailed\nnoise environments, tools that coincide with the standard ones adopted in the\nGaussian setup, namely a generalized \"power\" measure and a generalized Fisher\ninformation. We generalize known information inequalities commonly used in the\nGaussian context: the de Bruijn's identity, the data processing inequality, the\nFisher information inequality, the isoperimetric inequality for entropies and\nthe Cramer-Rao bound. Additionally, we derive upper bounds on the differential\nentropy of independent sums having a stable component. Finally, the new \"power\"\nmeasure is used to shed some light on the additive alpha-stable noise channel\ncapacity in a setup that generalizes the linear average power constrained AWGN\nchannel. Our theoretical findings are paralleled with numerical evaluations of\nvarious quantities and bounds using developed {\\em Matlab} packages. \n\n"}
{"id": "1609.03258", "contents": "Title: Joint Power and Subcarrier Allocation for Multicarrier Full-Duplex\n  Systems Abstract: In this paper, we investigate resource allocation for multicarrier\ncommunication systems employing a full-duplex base station for serving multiple\nhalf-duplex downlink and uplink users simultaneously. We study the joint power\nand subcarrier allocation design for the maximization of the weighted sum\nthroughput of the system. The algorithm design is formulated as a mixed\ncombinatorial non-convex optimization problem and obtaining the globally\noptimal solution may require prohibitively high computational complexity.\nTherefore, a low computational complexity suboptimal iterative algorithm\nexploiting successive convex approximation is proposed to obtain a locally\noptimal solution. Simulation results confirm that the proposed suboptimal\nalgorithm obtains a substantial improvement in system throughput compared to\nvarious existing baseline schemes. \n\n"}
{"id": "1609.03547", "contents": "Title: Bounds on Separating Redundancy of Linear Codes and Rates of X-Codes Abstract: An error-erasure channel is a simple noise model that introduces both errors\nand erasures. While the two types of errors can be corrected simultaneously\nwith error-correcting codes, it is also known that any linear code allows for\nfirst correcting errors and then erasures in two-step decoding. In particular,\na carefully designed parity-check matrix not only allows for separating\nerasures from errors but also makes it possible to efficiently correct\nerasures. The separating redundancy of a linear code is the number of\nparity-check equations in a smallest parity-check matrix that has the required\nproperty for this error-erasure separation. In a sense, it is a parameter of a\nlinear code that represents the minimum overhead for efficiently separating\nerasures from errors. While several bounds on separating redundancy are known,\nthere still remains a wide gap between upper and lower bounds except for a few\nlimited cases. In this paper, using probabilistic combinatorics and design\ntheory, we improve both upper and lower bounds on separating redundancy. We\nalso show a relation between parity-check matrices for error-erasure separation\nand special matrices, called X-codes, for data compaction circuits in VLSI\ntesting. This leads to an exponentially improved bound on the size of an\noptimal X-code. \n\n"}
{"id": "1609.05160", "contents": "Title: Energy-Efficient Resource Allocation for SWIPT in Multiple Access\n  Channels Abstract: In this paper, we study optimal resource allocation strategies for\nsimultaneous information and power transfer (SWIPT) focusing on the system\nenergy efficiency. We consider two-user multiple access channels in which\nenergy harvesting (EH) and information decoding (ID) nodes are spatially\nseparated. We formulate optimization problems that maximize system energy\nefficiency while taking harvested energy constraints into account. These are\nconcave-linear fractional problems, and hence Karush-Kuhn-Tucker (KKT)\nconditions are necessary and sufficient to obtain globally optimal solution.\nSolving these optimization problems, we provide analytical expressions for\noptimal transmit power allocation among the source nodes, and identify the\ncorresponding energy efficiency. We confirm the theoretical analysis via\nnumerical results. Furthermore, we also characterize the effect of circuit\npower consumption on the system's efficiency as the harvested energy demand\nvaries. \n\n"}
{"id": "1609.06432", "contents": "Title: Polar Coding for Empirical Coordination of Signals and Actions over\n  Noisy Channels Abstract: -We develop a polar coding scheme for empirical coordination in a two-node\nnetwork with a noisy link in which the input and output signals have to be\ncoordinated with the source and the reconstruction. In the case of non-causal\nencoding and decoding, we show that polar codes achieve the best known inner\nbound for the empirical coordination region, provided that a vanishing rate of\ncommon randomness is available. This scheme provides a constructive alternative\nto random binning and coding proofs. \n\n"}
{"id": "1609.07027", "contents": "Title: PIR schemes with small download complexity and low storage requirements Abstract: In the classical model for (information theoretically secure) Private\nInformation Retrieval (PIR), a user wishes to retrieve one bit of a database\nthat is stored on a set of $n$ servers, in such a way that no individual server\ngains information about which bit the user is interested in. The aim is to\ndesign schemes that minimise communication between the user and the servers.\nMore recently, there have been moves to consider more realistic models where\nthe total storage of the set of servers, or the per server storage, should be\nminimised (possibly using techniques from distributed storage), and where the\ndatabase is divided into $R$-bit records with $R>1$, and the user wishes to\nretrieve one record rather than one bit. When $R$ is large, downloads from the\nservers to the user dominate the communication complexity and so the aim is to\nminimise the total number of downloaded bits. Shah, Rashmi and Ramchandran show\nthat at least $R+1$ bits must be downloaded from servers in the worst case, and\nprovide PIR schemes meeting this bound. Sun and Jafar determine the best\nasymptotic download cost of a PIR scheme (as $R\\rightarrow\\infty$), where this\ncost is defined as the ratio of the message length $R$ and the total number of\nbits downloaded.\n  This paper provides various bounds on the download complexity of a PIR\nscheme, generalising those of Shah et al. to the case when the number $n$ of\nservers is bounded, and providing links with classical techniques due to Chor\net al. The paper also provides a range of constructions for PIR schemes that\nare either simpler or perform better than previously known schemes, including\nexplicit schemes that achieve the best asymptotic download complexity of Sun\nand Jafar with significantly lower upload complexity, and general techniques\nfor constructing a scheme with good worst case download complexity from a\nscheme with good download complexity on average. \n\n"}
{"id": "1609.08137", "contents": "Title: Nearest-Neighbor and Contact Distance Distributions for Thomas Cluster\n  Process Abstract: We characterize the statistics of nearest-neighbor and contact distance\ndistributions for Thomas cluster process (TCP), which is a special case of\nPoisson cluster process. In particular, we derive the cumulative distribution\nfunction (CDF) of the distance to the nearest point of TCP from a reference\npoint for three different cases: (i) reference point is not a part of the point\nprocess, (ii) it is chosen uniformly at random from the TCP, and (iii) it is a\nrandomly chosen point from a cluster chosen uniformly at random from the TCP.\nWhile the first corresponds to the contact distance distribution, the other two\nprovide two different viewpoints for the nearest-neighbor distance\ndistribution. \n\n"}
{"id": "1609.09358", "contents": "Title: Combining Belief Propagation and Successive Cancellation List Decoding\n  of Polar Codes on a GPU Platform Abstract: The decoding performance of polar codes strongly depends on the decoding\nalgorithm used, while also the decoder throughput and its latency mainly depend\non the decoding algorithm. In this work, we implement the powerful successive\ncancellation list (SCL) decoder on a GPU and identify the bottlenecks of this\nalgorithm with respect to parallel computing and its difficulties. The inherent\nserial decoding property of the SCL algorithm naturally limits the achievable\nspeed-up gains on GPUs when compared to CPU implementations. In order to\nincrease the decoding throughput, we use a hybrid decoding scheme based on the\nbelief propagation (BP) decoder, which can be intra and inter-frame\nparallelized. The proposed scheme combines excellent decoding performance and\nhigh throughput within the signal-to-noise ratio (SNR) region of interest. \n\n"}
{"id": "1610.00732", "contents": "Title: Sequential Low-Rank Change Detection Abstract: Detecting emergence of a low-rank signal from high-dimensional data is an\nimportant problem arising from many applications such as camera surveillance\nand swarm monitoring using sensors. We consider a procedure based on the\nlargest eigenvalue of the sample covariance matrix over a sliding window to\ndetect the change. To achieve dimensionality reduction, we present a\nsketching-based approach for rank change detection using the low-dimensional\nlinear sketches of the original high-dimensional observations. The premise is\nthat when the sketching matrix is a random Gaussian matrix, and the dimension\nof the sketching vector is sufficiently large, the rank of sample covariance\nmatrix for these sketches equals the rank of the original sample covariance\nmatrix with high probability. Hence, we may be able to detect the low-rank\nchange using sample covariance matrices of the sketches without having to\nrecover the original covariance matrix. We character the performance of the\nlargest eigenvalue statistic in terms of the false-alarm-rate and the expected\ndetection delay, and present an efficient online implementation via subspace\ntracking. \n\n"}
{"id": "1610.02419", "contents": "Title: Charged-particle multiplicity and transverse-energy distribution using\n  the Weibull-Glauber approach in heavy-ion collisions Abstract: The charged-particle multiplicity distribution and the transverse-energy\ndistribution measured in heavy-ion collisions at top RHIC and LHC energies are\ndescribed using the two-component model approach based on a convolution of the\nMonte Carlo Glauber model with the Weibull model for particle production. The\nmodel successfully describes the multiplicity and transverse-energy\ndistribution of minimum-bias collision data for a wide range of energies. The\nWeibull-Glauber model can be used to determine the centrality classes in\nheavy-ion collisions as an alternative to the conventional negative binomial\ndistribution (NBD)-Glauber approach. \n\n"}
{"id": "1610.03475", "contents": "Title: Secrecy in MIMO Networks with No Eavesdropper CSIT Abstract: We consider two fundamental multi-user channel models: the multiple-input\nmultiple-output (MIMO) wiretap channel with one helper (WTH) and the MIMO\nmultiple access wiretap channel (MAC-WT). In each case, the eavesdropper has\n$K$ antennas while the remaining terminals have $N$ antennas each. We consider\na fast fading channel where the channel state information (CSI) of the\nlegitimate receiver is available at the transmitters but no channel state\ninformation at the transmitters (CSIT) is available for the eavesdropper's\nchannel. We determine the optimal sum secure degrees of freedom (s.d.o.f.) for\neach channel model for the regime $K\\leq N$, and show that in this regime, the\nMAC-WT channel reduces to the WTH in the absence of eavesdropper CSIT. For the\nregime $N\\leq K\\leq 2N$, we obtain the optimal linear s.d.o.f., and show that\nthe MAC-WT channel and the WTH have the same optimal s.d.o.f. when restricted\nto linear encoding strategies. In the absence of any such restrictions, we\nprovide an upper bound for the sum s.d.o.f. of the MAC-WT chanel in the regime\n$N\\leq K\\leq 2N$. Our results show that unlike in the single-input\nsingle-output (SISO) case, there is loss of s.d.o.f. for even the WTH due to\nlack of eavesdropper CSIT when $K\\geq N$. \n\n"}
{"id": "1610.04215", "contents": "Title: Partial Strong Converse for the Non-Degraded Wiretap Channel Abstract: We prove the partial strong converse property for the discrete memoryless\n\\emph{non-degraded} wiretap channel, for which we require the leakage to the\neavesdropper to vanish but allow an asymptotic error probability $\\epsilon \\in\n[0,1)$ to the legitimate receiver. We show that when the transmission rate is\nabove the secrecy capacity, the probability of correct decoding at the\nlegitimate receiver decays to zero exponentially. Therefore, the maximum\ntransmission rate is the same for $\\epsilon \\in [0,1)$, and the partial strong\nconverse property holds. Our work is inspired by a recently developed technique\nbased on information spectrum method and Chernoff-Cramer bound for evaluating\nthe exponent of the probability of correct decoding. \n\n"}
{"id": "1610.04218", "contents": "Title: Super-Resolution Delay-Doppler Estimation for OFDM Passive Radar Abstract: In this paper, we consider the problem of joint delay-Doppler estimation of\nmoving targets in a passive radar that makes use of orthogonal\nfrequency-division multiplexing (OFDM) communication signals. A compressed\nsensing algorithm is proposed to achieve supper-resolution and better accuracy,\nusing both the atomic norm and the $\\ell_1$-norm. The atomic norm is used to\nmanifest the signal sparsity in the continuous domain. Unlike previous works\nwhich assume the demodulation to be error free, we explicitly introduce the\ndemodulation error signal whose sparsity is imposed by the $\\ell_1$-norm. On\nthis basis, the delays and Doppler frequencies are estimated by solving a\nsemidefinite program (SDP) which is convex. We also develop an iterative method\nfor solving this SDP via the alternating direction method of multipliers (ADMM)\nwhere each iteration involves closed-form computation. Simulation results are\npresented to illustrate the high performance of the proposed algorithm. \n\n"}
{"id": "1610.06994", "contents": "Title: Production of charmed baryon $\\Lambda_c(2940)$ by kaon-induced reaction\n  on a proton target Abstract: We investigate the possibility to study the charmed baryon $\\Lambda_c(2940)$\nby kaon-induced reaction on a proton target. By assuming the $\\Lambda_c(2940)$\nas a $pD^{*0}$ molecular state with spin-parity $J^{p}=1/2^{\\pm}$, an effective\nLagrangian approach was adopted to calculate the cross section, the $D^0p$\ninvariant mass spectrum and Dalitz plot of the $\\Lambda(2940)$ production. The\ntotal cross section of the $K^{-}p\\to\\Lambda_c(2940)D_s^{-}$ reaction is found\nat an order of magnitude about 10 $\\mu$b. By considering the sub sequential\ndecay $\\Lambda_c(2940)\\to{}D^0p$ with contributions from the $\\Lambda_c(2286)$\nand the $\\Sigma_c(2455)$ as background, the $K^{-}p\\to{}D_{s}^{-}D^{0}p$\nreaction are studied. It is found that the $\\Lambda_c(2940)$ is produced mainly\nat forward angles. The $\\Lambda_c(2940)$ signal is predicted to be significant\nin the $D^0p$ invariant mass spectrum and the Dalitz plot of the\n$K^{-}p\\to{}D_{s}^{-}D^{0}p$ reaction. The results suggest that it is promising\nto study the $\\Lambda_c(2940)$ with high-energy kaon beam on a proton target in\nexperiment. \n\n"}
{"id": "1610.07252", "contents": "Title: Information-theoretic Physical Layer Security for Satellite Channels Abstract: Shannon introduced the classic model of a cryptosystem in 1949, where Eve has\naccess to an identical copy of the cyphertext that Alice sends to Bob. Shannon\ndefined perfect secrecy to be the case when the mutual information between the\nplaintext and the cyphertext is zero. Perfect secrecy is motivated by\nerror-free transmission and requires that Bob and Alice share a secret key.\nWyner in 1975 and later I.~Csisz\\'ar and J.~K\\\"orner in 1978 modified the\nShannon model assuming that the channels are noisy and proved that secrecy can\nbe achieved without sharing a secret key. This model is called wiretap channel\nmodel and secrecy capacity is known when Eve's channel is noisier than Bob's\nchannel.\n  In this paper we review the concept of wiretap coding from the satellite\nchannel viewpoint. We also review subsequently introduced stronger secrecy\nlevels which can be numerically quantified and are keyless unconditionally\nsecure under certain assumptions. We introduce the general construction of\nwiretap coding and analyse its applicability for a typical satellite channel.\nFrom our analysis we discuss the potential of keyless information theoretic\nphysical layer security for satellite channels based on wiretap coding. We also\nidentify system design implications for enabling simultaneous operation with\nadditional information theoretic security protocols. \n\n"}
{"id": "1610.07531", "contents": "Title: PhaseMax: Convex Phase Retrieval via Basis Pursuit Abstract: We consider the recovery of a (real- or complex-valued) signal from\nmagnitude-only measurements, known as phase retrieval. We formulate phase\nretrieval as a convex optimization problem, which we call PhaseMax. Unlike\nother convex methods that use semidefinite relaxation and lift the phase\nretrieval problem to a higher dimension, PhaseMax is a \"non-lifting\" relaxation\nthat operates in the original signal dimension. We show that the dual problem\nto PhaseMax is Basis Pursuit, which implies that phase retrieval can be\nperformed using algorithms initially designed for sparse signal recovery. We\ndevelop sharp lower bounds on the success probability of PhaseMax for a broad\nrange of random measurement ensembles, and we analyze the impact of measurement\nnoise on the solution accuracy. We use numerical results to demonstrate the\naccuracy of our recovery guarantees, and we showcase the efficacy and limits of\nPhaseMax in practice. \n\n"}
{"id": "1610.07740", "contents": "Title: MIMO Multiway Distributed-Relay Channel with Full Data Exchange: An\n  Achievable Rate Perspective Abstract: We consider efficient communications over the multiple-input multiple-output\n(MIMO) multiway distributed relay channel (MDRC) with full data exchange, where\neach user, equipped with multiple antennas, broadcasts its message to all the\nother users via the help of a number of distributive relays. We propose a\nphysical-layer network coding (PNC) based scheme involving linear precoding for\nchannel alignment nested lattice coding for PNC, and lattice-based precoding\nfor interference mitigation, We show that, with the proposed scheme,\ndistributed relaying achieves the same sum-rate as cooperative relaying in the\nhigh SNR regime. We also show that the proposed scheme achieve the asymptotic\nsum capacity of the MIMO MDRC within a constant gap at high SNR. Numerical\nresults demonstrate that the proposed scheme considerably outperforms the\nexisting schemes including decode-and-forward and amplify-and-forward. \n\n"}
{"id": "1610.08076", "contents": "Title: Optimal Power Allocation and Active Interference Mitigation for Spatial\n  Multiplexed MIMO Cognitive Systems Abstract: In this paper, the performance of an underlay multiple-input multiple-output\n(MIMO) cognitive radio system is analytically studied. In particular, the\nsecondary transmitter operates in a spatial multiplexing transmission mode,\nwhile a zero-forcing (ZF) detector is employed at the secondary receiver.\nAdditionally, the secondary system is interfered by multiple randomly\ndistributed single-antenna primary users (PUs). To enhance the performance of\nsecondary transmission, optimal power allocation is performed at the secondary\ntransmitter with a constraint on the interference temperature (IT) specified by\nthe PUs. The outage probability of the secondary receiver is explicitly derived\nin an exact closed-form expression. Also, some special cases of practical\ninterest, including co-located PUs and massive MIMO, are discussed. Further, to\nmitigate instantaneous excessive interference onto PUs caused by the\ntime-average IT, an iterative antenna reduction algorithm is developed for the\nsecondary transmitter and, accordingly, the average number of transmit antennas\nis analytically computed. Extensive numerical and simulation results\ncorroborate the effectiveness of our analysis. \n\n"}
{"id": "1610.08535", "contents": "Title: On Multihop Weibull-Fading Communications: Performance Analysis\n  Framework and Applications Abstract: The paper presents a comprehensive closed-form performance analysis framework\nfor multihop communications over Weibull fading channels. The analyzed scheme\nconsists basically of multiple regenerative relays with generalized high-order\nquadrature amplitude modulation (M-QAM) transmissions. To take into\nconsideration the channel fading in the mmWave range, we adopt the advocated\nWeibull model for its flexible ability to cover different channel conditions.\nThe end-to-end performance is evaluated in terms of outage probability, bit\nerror probability (BER), symbol error probability (SER), block error rate\n(BLER), ergodic capacity, and energy efficiency (EE). For all the metrics, we\npresent exact closed-form expressions along with their asymptotic behavior,\nsome in terms of generalized hypergeometric functions. Based on the obtained\nanalytical results, we also present a practical application, we derive two BER-\nand EE-optimal transmit power allocation strategies, and we discuss the\nresulting performance gains. The exactness of our analysis is illustrated by\nnumerical examples, and assessed via Monte-Carlo simulations for different\nsystem and channel parameters. Finally, as a secondary contribution, noting the\nincreasing popularity of Fox's H and bivariate H functions, we provide new and\ngeneralized codes for computing these functions which are of practical utility\nin different contexts. \n\n"}
{"id": "1610.08870", "contents": "Title: Uniform continuity bounds for information characteristics of quantum\n  channels depending on input dimension and on input energy Abstract: We obtain continuity bounds for basic information characteristics of quantum\nchannels depending on their input dimension (if it is finite) and on the input\nenergy bound (if the input dimension is infinite). We pay a special attention\nto the case of a multi-mode quantum oscillator as an input system.\n  First we prove continuity bounds for the output conditional mutual\ninformation for a single channel and for $n$ copies of a channel.\n  Then we obtain estimates for variation of the output Holevo quantity with\nrespect to simultaneous variations of a channel and of an input ensemble.\n  As a result tight and close-to-tight continuity bounds for basic capacities\nof quantum channels depending on the input dimension are obtained. They\ncomplement the Leung-Smith continuity bounds depending on the output dimension.\n  Finally, we obtain tight and close-to-tight continuity bounds for basic\ncapacities of infinite-dimensional energy-constrained channels with respect to\nthe energy-constrained Bures distance generating the strong convergence of\nquantum channels. \n\n"}
{"id": "1610.09289", "contents": "Title: Generalized Common Informations: Measuring Commonness by the Conditional\n  Maximal Correlation Abstract: In literature, different common informations were defined by G\\'acs and\nK\\\"orner, by Wyner, and by Kumar, Li, and Gamal, respectively. In this paper,\nwe define two generalized versions of common informations, named approximate\nand exact information-correlation functions, by exploiting the conditional\nmaximal correlation as a commonness or privacy measure. These two generalized\ncommon informations encompass the notions of G\\'acs-K\\\"orner's, Wyner's, and\nKumar-Li-Gamal's common informations as special cases. Furthermore, to give\noperational characterizations of these two generalized common informations, we\nalso study the problems of private sources synthesis and common information\nextraction, and show that the information-correlation functions are equal to\nthe minimum rates of commonness needed to ensure that some conditional maximal\ncorrelation constraints are satisfied for the centralized setting versions of\nthese problems. As a byproduct, the conditional maximal correlation has been\nstudied as well. \n\n"}
{"id": "1611.01179", "contents": "Title: Adaptive Geometric Multiscale Approximations for Intrinsically\n  Low-dimensional Data Abstract: We consider the problem of efficiently approximating and encoding\nhigh-dimensional data sampled from a probability distribution $\\rho$ in\n$\\mathbb{R}^D$, that is nearly supported on a $d$-dimensional set $\\mathcal{M}$\n- for example supported on a $d$-dimensional Riemannian manifold. Geometric\nMulti-Resolution Analysis (GMRA) provides a robust and computationally\nefficient procedure to construct low-dimensional geometric approximations of\n$\\mathcal{M}$ at varying resolutions. We introduce a thresholding algorithm on\nthe geometric wavelet coefficients, leading to what we call adaptive GMRA\napproximations. We show that these data-driven, empirical approximations\nperform well, when the threshold is chosen as a suitable universal function of\nthe number of samples $n$, on a wide variety of measures $\\rho$, that are\nallowed to exhibit different regularity at different scales and locations,\nthereby efficiently encoding data from more complex measures than those\nsupported on manifolds. These approximations yield a data-driven dictionary,\ntogether with a fast transform mapping data to coefficients, and an inverse of\nsuch a map. The algorithms for both the dictionary construction and the\ntransforms have complexity $C n \\log n$ with the constant linear in $D$ and\nexponential in $d$. Our work therefore establishes adaptive GMRA as a fast\ndictionary learning algorithm with approximation guarantees. We include several\nnumerical experiments on both synthetic and real data, confirming our\ntheoretical results and demonstrating the effectiveness of adaptive GMRA. \n\n"}
{"id": "1611.01278", "contents": "Title: Topological Interference Management: Linear Cooperation is not useful\n  for Wyner's Networks Abstract: In this work, we study the value of cooperative transmission in wireless\nnetworks if no channel state information is available at the transmitters (no\nCSIT). Our focus is on large locally connected networks, where each transmitter\nis connected to the receiver that has the same index as well as L succeeding\nreceivers. The cases of L=1 and L=2 represent Wyner's asymmetric and symmetric\nnetwork models, respectively. The considered rate criterion is the per user\nDegrees of Freedom (puDoF) as the number of transmitter-receiver pairs goes to\ninfinity. For the case when L=1, it was shown in previous work that linear\ncooperation schemes do not increases the puDoF value, and that the optimal\nscheme relies on assigning each message to a single transmitter and using\northogonal access (TDMA). Here, we extend this conclusion to the case where\nL=2, by proving optimality of TDMA in this case as well. We conclude by\ndiscussing whether increasing the value of L can create a value for linear\ncooperation schemes from a DoF perspective. \n\n"}
{"id": "1611.01510", "contents": "Title: Suppression of Upsilon(1S), Upsilon(2S), and Upsilon(3S) production in\n  PbPb collisions at sqrt(s[NN]) = 2.76 TeV Abstract: The production yields of Upsilon(1S), Upsilon(2S), and Upsilon(3S) quarkonium\nstates are measured through their decays into muon pairs in the CMS detector,\nin PbPb and pp collisions at the centre-of-mass energy per nucleon pair of 2.76\nTeV. The data correspond to integrated luminosities of 166 inverse microbarns\nand 5.4 inverse picobarns for PbPb and pp collisions, respectively.\nDifferential production cross sections are reported as functions of Upsilon\nrapidity y up to 2.4, and transverse momentum pT up to 20 GeV/c. A strong\ncentrality-dependent suppression is observed in PbPb relative to pp collisions,\nby factors of up to approximately 2 and 8, for the Upsilon(1S) and Upsilon(2S)\nstates, respectively. No significant dependence of this suppression is observed\nas a function of y or pT. The Upsilon(3S) state is not observed in PbPb\ncollisions, which corresponds to a suppression for the centrality-integrated\ndata by at least a factor of approximately 7 at a 95% confidence level. The\nobserved suppression is in agreement with theoretical scenarios modeling the\nsequential melting of quarkonium states in a quark gluon plasma. \n\n"}
{"id": "1611.01704", "contents": "Title: End-to-end Optimized Image Compression Abstract: We describe an image compression method, consisting of a nonlinear analysis\ntransformation, a uniform quantizer, and a nonlinear synthesis transformation.\nThe transforms are constructed in three successive stages of convolutional\nlinear filters and nonlinear activation functions. Unlike most convolutional\nneural networks, the joint nonlinearity is chosen to implement a form of local\ngain control, inspired by those used to model biological neurons. Using a\nvariant of stochastic gradient descent, we jointly optimize the entire model\nfor rate-distortion performance over a database of training images, introducing\na continuous proxy for the discontinuous loss function arising from the\nquantizer. Under certain conditions, the relaxed loss function may be\ninterpreted as the log likelihood of a generative model, as implemented by a\nvariational autoencoder. Unlike these models, however, the compression model\nmust operate at any given point along the rate-distortion curve, as specified\nby a trade-off parameter. Across an independent set of test images, we find\nthat the optimized method generally exhibits better rate-distortion performance\nthan the standard JPEG and JPEG 2000 compression methods. More importantly, we\nobserve a dramatic improvement in visual quality for all images at all bit\nrates, which is supported by objective quality estimates using MS-SSIM. \n\n"}
{"id": "1611.02010", "contents": "Title: Convergence Analysis of Distributed Inference with Vector-Valued\n  Gaussian Belief Propagation Abstract: This paper considers inference over distributed linear Gaussian models using\nfactor graphs and Gaussian belief propagation (BP). The distributed inference\nalgorithm involves only local computation of the information matrix and of the\nmean vector, and message passing between neighbors. Under broad conditions, it\nis shown that the message information matrix converges to a unique positive\ndefinite limit matrix for arbitrary positive semidefinite initialization, and\nit approaches an arbitrarily small neighborhood of this limit matrix at a\ndoubly exponential rate. A necessary and sufficient convergence condition for\nthe belief mean vector to converge to the optimal centralized estimator is\nprovided under the assumption that the message information matrix is\ninitialized as a positive semidefinite matrix. Further, it is shown that\nGaussian BP always converges when the underlying factor graph is given by the\nunion of a forest and a single loop. The proposed convergence condition in the\nsetup of distributed linear Gaussian models is shown to be strictly weaker than\nother existing convergence conditions and requirements, including the Gaussian\nMarkov random field based walk-summability condition, and applicable to a large\nclass of scenarios. \n\n"}
{"id": "1611.02136", "contents": "Title: Production and interaction of the eta meson with nucleons and nuclei Abstract: We report on the status of the search for eta-mesic nuclei and the studies of\nthe interaction of the eta meson with nucleons. Recently we have completed the\nanalysis of the new WASA-at-COSY data on the production of the eta meson with\npolarized proton beam. New results on the analyzing power for the pp->ppeta\nreaction with more than an order of magnitude improved precision shed a new\nlight on the production mechanism of the eta meson in nucleon-nucleon\ncollisions. Also, the latest results of the search for eta-mesic nuclei are\ndiscussed. \n\n"}
{"id": "1611.04645", "contents": "Title: An Overview on Resource Allocation Techniques for Multi-User MIMO\n  Systems Abstract: Remarkable research activities and major advances have been occurred over the\npast decade in multiuser multiple-input multiple-output (MU-MIMO) systems.\nSeveral transmission technologies and precoding techniques have been developed\nin order to exploit the spatial dimension so that simultaneous transmission of\nindependent data streams reuse the same radio resources. The achievable\nperformance of such techniques heavily depends on the channel characteristics\nof the selected users, the amount of channel knowledge, and how efficiently\ninterference is mitigated. In systems where the total number of receivers is\nlarger than the number of total transmit antennas, user selection becomes a key\napproach to benefit from multiuser diversity and achieve full multiplexing\ngain. The overall performance of MU-MIMO systems is a complex joint\nmulti-objective optimization problem since many variables and parameters have\nto be optimized, including the number of users, the number of antennas, spatial\nsignaling, rate and power allocation, and transmission technique. The objective\nof this literature survey is to provide a comprehensive overview of the various\nmethodologies used to approach the aforementioned joint optimization task in\nthe downlink of MU-MIMO communication systems. \n\n"}
{"id": "1611.05391", "contents": "Title: From gluon topology to chiral anomaly: Emergent phenomena in quark-gluon\n  plasma Abstract: Heavy-ion collision experiments at RHIC and the LHC have found a new emergent\nphase of QCD, a strongly coupled quark-gluon plasma (sQGP) that is\ndistinctively different from either the low temperature hadron phase or the\nvery high temperature weakly coupled plasma phase. Highly nontrivial emergent\nphenomena occur in such sQGP and two examples will be discussed in this\ncontribution: the magnetic component of sQGP that stems from topologically\nnontrivial configurations in the gluon sector; and the anomalous chiral\ntransport that arises as macroscopic manifestation of microscopic chiral\nanomaly in the quark sector. For both examples, their important roles in\nexplaining pertinent heavy-ion data will be emphasized. \n\n"}
{"id": "1611.06150", "contents": "Title: Optimal Key Consensus in Presence of Noise Abstract: In this work, we abstract some key ingredients in previous LWE- and\nRLWE-based key exchange protocols, by introducing and formalizing the building\ntool, referred to as key consensus (KC) and its asymmetric variant AKC. KC and\nAKC allow two communicating parties to reach consensus from close values\nobtained by some secure information exchange. We then discover upper bounds on\nparameters for any KC and AKC. KC and AKC are fundamental to lattice based\ncryptography, in the sense that a list of cryptographic primitives based on\nLWR, LWE and RLWE (including key exchange, public-key encryption, and more) can\nbe modularly constructed from them. As a conceptual contribution, this much\nsimplifies the design and analysis of these cryptosystems in the future.\n  We then design and analyze both general and highly practical KC and AKC\nschemes, which are referred to as OKCN and AKCN respectively for presentation\nsimplicity. Based on KC and AKC, we present generic constructions of key\nexchange (KE) from LWR, LWE and RLWE. The generic construction allows versatile\ninstantiations with our OKCN and AKCN schemes, for which we elaborate on\nevaluating and choosing the concrete parameters in order to achieve an\noptimally-balanced performance among security, computational cost, bandwidth\nefficiency, error rate, and operation simplicity. \n\n"}
{"id": "1611.07164", "contents": "Title: Distance verification for classical and quantum LDPC codes Abstract: The techniques of distance verification known for general linear codes are\nre-applied to quantum stabilizer codes. Then distance verification is addressed\nfor classical and quantum LDPC codes. New complexity bounds for distance\nverification with provable performance are derived using the average weight\nspectra of the ensembles of LDPC codes. These bounds are expressed in terms of\nthe erasure-correcting capacity of the corresponding ensemble. We also present\na new irreducible-cluster technique that can be applied to any LDPC code and\ntakes advantage of parity-checks' sparsity for both classical and quantum LDPC\ncodes. This technique reduces complexity exponents of all existing\ndeterministic techniques designed for generic stabilizer codes with small\nrelative distances, which also include all known families of quantum LDPC\ncodes. \n\n"}
{"id": "1611.09914", "contents": "Title: Batch and PIR Codes and Their Connections to Locally Repairable Codes Abstract: In this survey, two related families of codes are discussed: batch codes and\ncodes for private information retrieval. These two families can be viewed as\nnatural generalizations of locally repairable codes, which were extensively\nstudied in the context of coding for fault tolerance in distributed data\nstorage systems. Bounds on the parameters of the codes, as well as basic\nconstructions, are presented. Connections between different code families are\ndiscussed. \n\n"}
{"id": "1612.01980", "contents": "Title: Statistical Mechanics of MAP Estimation: General Replica Ansatz Abstract: The large-system performance of MAP estimation is studied considering a\ngeneral distortion function when the observation vector is received through a\nlinear system with additive white Gaussian noise. The analysis considers the\nsystem matrix to be chosen from the large class of rotationally invariant\nrandom matrices. We take a statistical mechanical approach by introducing a\nspin glass corresponding to the estimator, and employing the replica method for\nthe large-system analysis. In contrast to earlier replica based studies, our\nanalysis evaluates the general replica ansatz of the corresponding spin glass\nand determines the asymptotic distortion of the estimator for any structure of\nthe replica correlation matrix. Consequently, the replica symmetric as well as\nthe Replica Symmetry (RS) breaking ansatz with $b$ steps of breaking is deduced\nfrom the given general replica ansatz. The generality of our distortion\nfunction lets us derive a more general form of the MAP decoupling principle.\nBased on the general replica ansatz, we show that for any structure of the\nreplica correlation matrix, the vector-valued system decouples into a bank of\nequivalent decoupled linear systems followed by MAP estimators. The structure\nof the decoupled linear system is further studied under both the RS and the\nReplica Symmetry Breaking (RSB) assumptions. For $b$ steps of RSB, the\ndecoupled system is found to be an additive system with a noise term given as\nthe sum of an independent Gaussian random variable with $b$ correlated\nimpairment terms. As an application of our study, we investigate large\ncompressive sensing systems by considering the $\\ell_p$ minimization recovery\nschemes. Our numerical investigations show that the replica symmetric ansatz\nfor $\\ell_0$ norm recovery fails to give an accurate approximation of the mean\nsquare error as the compression rate grows, and therefore, the RSB ans\\\"atze\nare needed. \n\n"}
{"id": "1612.02320", "contents": "Title: An Energy Efficiency Perspective on Massive MIMO Quantization Abstract: One of the basic aspects of Massive MIMO (MaMi) that is in the focus of\ncurrent investigations is its potential of using low-cost and energy-efficient\nhardware. It is often claimed that MaMi will allow for using analog-to-digital\nconverters (ADCs) with very low resolutions and that this will result in\noverall improvement of energy efficiency. In this contribution, we perform a\nparametric energy efficiency analysis of MaMi uplink for the entire base\nstation receiver system with varying ADC resolutions. The analysis shows that,\nfor a wide variety of system parameters, ADCs with intermediate bit resolutions\n(4 - 10 bits) are optimal in energy efficiency sense, and that using very low\nbit resolutions results in degradation of energy efficiency. \n\n"}
{"id": "1612.03363", "contents": "Title: Quantum dynamical entropy, chaotic unitaries and complex Hadamard\n  matrices Abstract: We introduce two information-theoretical invariants for the projective\nunitary group acting on a finite-dimensional complex Hilbert space: PVM- and\nPOVM-dynamical (quantum) entropies. They quantify the randomness of the\nsuccessive quantum measurement results in the case where the evolution of the\nsystem between each two consecutive measurements is described by a given\nunitary operator. We study the class of chaotic unitaries, i.e., the ones of\nmaximal entropy or, equivalently, such that they can be represented by suitably\nrescaled complex Hadamard matrices in some orthonormal bases. We provide\nnecessary conditions for a unitary operator to be chaotic, which become also\nsufficient for qubits and qutrits. These conditions are expressed in terms of\nthe relation between the trace and the determinant of the operator. We also\ncompute the volume of the set of chaotic unitaries in dimensions two and three,\nand the average PVM-dynamical entropy over the unitary group in dimension two.\nWe prove that this mean value behaves as the logarithm of the dimension of the\nHilbert space, which implies that the probability that the dynamical entropy of\na unitary is almost as large as possible approaches unity as the dimension\ntends to infinity. \n\n"}
{"id": "1612.05743", "contents": "Title: Improper Signaling in Two-Path Relay Channels Abstract: Inter-relay interference (IRI) challenges the operation of two-path relaying\nsystems. Furthermore, the unavailability of the channel state information (CSI)\nat the source and the limited detection capabilities at the relays prevent\nneither eliminating the interference nor adopting joint detection at the relays\nnodes. Improper signaling is a powerful signaling scheme that has the\ncapability to reduce the interference impact at the receiver side and improves\nthe achievable rate performance. Therefore, improper signaling is adopted at\nboth relays, which have access to the global CSI. Then, improper signal\ncharacteristics are designed to maximize the total end-to-end achievable rate\nat the relays. To this end, both the power and the circularity coefficient, a\nmeasure of the impropriety degree of the signal, are optimized at the relays.\nAlthough the optimization problem is not convex, optimal power allocation for\nboth relays for a fixed circularity coefficient is obtained. Moreover, the\ncircularity coefficient is tuned to maximize the rate for a given power\nallocation. Finally, a joint solution of the optimization problem is proposed\nusing a coordinate descent method based on alternate optimization. The\nsimulation results show that employing improper signaling improves the\nachievable rate at medium and high IRI. \n\n"}
{"id": "1612.08459", "contents": "Title: Thermodynamics of Random Number Generation Abstract: We analyze the thermodynamic costs of the three main approaches to generating\nrandom numbers via the recently introduced Information Processing Second Law.\nGiven access to a specified source of randomness, a random number generator\n(RNG) produces samples from a desired target probability distribution. This\ndiffers from pseudorandom number generators (PRNG) that use wholly\ndeterministic algorithms and from true random number generators (TRNG) in which\nthe randomness source is a physical system. For each class, we analyze the\nthermodynamics of generators based on algorithms implemented as finite-state\nmachines, as these allow for direct bounds on the required physical resources.\nThis establishes bounds on heat dissipation and work consumption during the\noperation of three main classes of RNG algorithms---including those of von\nNeumann, Knuth and Yao, and Roche and Hoshi---and for PRNG methods. We\nintroduce a general TRNG and determine its thermodynamic costs exactly for\narbitrary target distributions. The results highlight the significant\ndifferences between the three main approaches to random number generation: One\nis work producing, one is work consuming, and the other is potentially\ndissipation neutral. Notably, TRNGs can both generate random numbers and\nconvert thermal energy to stored work. These thermodynamic costs on information\ncreation complement Landauer's limit on the irreducible costs of information\ndestruction. \n\n"}
{"id": "1612.08516", "contents": "Title: Fully bilinear generic and lifted random processes comparisons Abstract: In our companion paper \\cite{Stojnicgscomp16} we introduce a collection of\nfairly powerful statistical comparison results. They relate to a general\ncomparison concept and its an upgrade that we call lifting procedure. Here we\nprovide a different generic principle (which we call fully bilinear) that in\ncertain cases turns out to be stronger than the corresponding one from\n\\cite{Stojnicgscomp16}. Moreover, we also show how the principle that we\nintroduce here can also be pushed through the lifting machinery of\n\\cite{Stojnicgscomp16}. Finally, as was the case in \\cite{Stojnicgscomp16},\nhere we also show how the well known Slepian's max and Gordon's minmax\ncomparison principles can be obtained as special cases of the mechanisms that\nwe present here. We also create their lifted upgrades which happen to be\nstronger than the corresponding ones in \\cite{Stojnicgscomp16}. A fairly large\ncollection of results obtained through numerical experiments is also provided.\nIt is observed that these results are in an excellent agreement with what the\ntheory predicts. \n\n"}
{"id": "1612.09234", "contents": "Title: Logarithmic coherence: Operational interpretation of $\\ell_1$-norm\n  coherence Abstract: We show that the distillable coherence---which is equal to the relative\nentropy of coherence---is, up to a constant factor, always bounded by the\n$\\ell_1$-norm measure of coherence (defined as the sum of absolute values of\noff diagonals). Thus the latter plays a similar role as logarithmic negativity\nplays in entanglement theory and this is the best operational interpretation\nfrom a resource-theoretic viewpoint. Consequently the two measures are\nintimately connected to another operational measure, the robustness of\ncoherence. We find also relationships between these measures, which are tight\nfor general states, and the tightest possible for pure and qubit states. For a\ngiven robustness, we construct a state having minimum distillable coherence. \n\n"}
{"id": "1612.09555", "contents": "Title: Semirelativistic approximation to the $\\gamma^\\ast N \\to N(1520)$ and\n  $\\gamma^\\ast N \\to N(1535)$ transition form factors Abstract: The representation of the wave functions of the nucleon resonances within a\nrelativistic framework is a complex task. In a nonrelativistic framework the\northogonality between states can be imposed naturally. In a relativistic\ngeneralization, however, the derivation of the orthogonality condition between\nstates can be problematic, particularly when the states have different masses.\nIn this work we study the $N(1520)$ and $N(1535)$ states using a relativistic\nframework. We considered wave functions derived in previous works, but impose\nthe orthogonality between the nucleon and resonance states using the properties\nof the nucleon, ignoring the difference of masses between the states\n(semirelativistic approximation). The $N(1520)$ and $N(1535)$ wave functions\nare then defined without any adjustable parameters and are used to make\npredictions for the valence quark contributions to the transition form factors.\nThe predictions compare well with the data particularly for high momentum\ntransfer, where the dominance of the quark degrees of freedom is expected. \n\n"}
{"id": "1701.01207", "contents": "Title: Learning Semidefinite Regularizers Abstract: Regularization techniques are widely employed in optimization-based\napproaches for solving ill-posed inverse problems in data analysis and\nscientific computing. These methods are based on augmenting the objective with\na penalty function, which is specified based on prior domain-specific expertise\nto induce a desired structure in the solution. We consider the problem of\nlearning suitable regularization functions from data in settings in which\nprecise domain knowledge is not directly available. Previous work under the\ntitle of `dictionary learning' or `sparse coding' may be viewed as learning a\nregularization function that can be computed via linear programming. We\ndescribe generalizations of these methods to learn regularizers that can be\ncomputed and optimized via semidefinite programming. Our framework for learning\nsuch semidefinite regularizers is based on obtaining structured factorizations\nof data matrices, and our algorithmic approach for computing these\nfactorizations combines recent techniques for rank minimization problems along\nwith an operator analog of Sinkhorn scaling. Under suitable conditions on the\ninput data, our algorithm provides a locally linearly convergent method for\nidentifying the correct regularizer that promotes the type of structure\ncontained in the data. Our analysis is based on the stability properties of\nOperator Sinkhorn scaling and their relation to geometric aspects of\ndeterminantal varieties (in particular tangent spaces with respect to these\nvarieties). The regularizers obtained using our framework can be employed\neffectively in semidefinite programming relaxations for solving inverse\nproblems. \n\n"}
{"id": "1701.01800", "contents": "Title: Variable-Length Lossy Compression Allowing Positive Overflow and Excess\n  Distortion Probabilities Abstract: This paper investigates the problem of variable-length lossy source coding\nallowing a positive excess distortion probability and an overflow probability\nof codeword lengths. Novel one-shot achievability and converse bounds of the\noptimal rate are established by a new quantity based on the smooth max entropy\n(the smooth R\\'enyi entropy of order zero). To derive the achievability bounds,\nwe give an explicit code construction based on a distortion ball instead of\nusing the random coding argument. The basic idea of the code construction is\nsimilar to the optimal code construction in the variable-length lossless source\ncoding. Our achievability bounds are slightly different, depending on whether\nthe encoder is stochastic or deterministic. One-shot results yield a general\nformula of the optimal rate for blocklength $n$. In addition, our general\nformula is applied to asymptotic analysis for a stationary memoryless source.\nAs a result, we derive a single-letter characterization of the optimal rate by\nusing the rate-distortion and rate-dispersion functions. \n\n"}
{"id": "1701.02578", "contents": "Title: Multiprocessor Approximate Message Passing with Column-Wise Partitioning Abstract: Solving a large-scale regularized linear inverse problem using multiple\nprocessors is important in various real-world applications due to the\nlimitations of individual processors and constraints on data sharing policies.\nThis paper focuses on the setting where the matrix is partitioned column-wise.\nWe extend the algorithmic framework and the theoretical analysis of approximate\nmessage passing (AMP), an iterative algorithm for solving linear inverse\nproblems, whose asymptotic dynamics are characterized by state evolution (SE).\nIn particular, we show that column-wise multiprocessor AMP (C-MP-AMP) obeys an\nSE under the same assumptions when the SE for AMP holds. The SE results imply\nthat (i) the SE of C-MP-AMP converges to a state that is no worse than that of\nAMP and (ii) the asymptotic dynamics of C-MP-AMP and AMP can be identical.\nMoreover, for a setting that is not covered by SE, numerical results show that\ndamping can improve the convergence performance of C-MP-AMP. \n\n"}
{"id": "1701.03195", "contents": "Title: Moderate Deviation Analysis for Classical-Quantum Channels and Quantum\n  Hypothesis Testing Abstract: In this work, we study the tradeoffs between the error probabilities of\nclassical-quantum channels and the blocklength $n$ when the transmission rates\napproach the channel capacity at a rate slower than $1/\\sqrt{n}$, a research\ntopic known as moderate deviation analysis. We show that the optimal error\nprobability vanishes under this rate convergence. Our main technical\ncontributions are a tight quantum sphere-packing bound, obtained via Chaganty\nand Sethuraman's concentration inequality in strong large deviation theory, and\nasymptotic expansions of error-exponent functions. Moderate deviation analysis\nfor quantum hypothesis testing is also established. The converse directly\nfollows from our channel coding result, while the achievability relies on a\nmartingale inequality. \n\n"}
{"id": "1701.03515", "contents": "Title: Multiple Illumination Phaseless Super-Resolution (MIPS) with\n  Applications To Phaseless DOA Estimation and Diffraction Imaging Abstract: Phaseless super-resolution is the problem of recovering an unknown signal\nfrom measurements of the magnitudes of the low frequency Fourier transform of\nthe signal. This problem arises in applications where measuring the phase, and\nmaking high-frequency measurements, are either too costly or altogether\ninfeasible. The problem is especially challenging because it combines the\ndifficult problems of phase retrieval and classical super-resolution \n\n"}
{"id": "1701.03904", "contents": "Title: The Passive Eavesdropper Affects my Channel: Secret-Key Rates under\n  Real-World Conditions (Extended Version) Abstract: Channel-reciprocity based key generation (CRKG) has gained significant\nimportance as it has recently been proposed as a potential lightweight security\nsolution for IoT devices. However, the impact of the attacker's position in\nclose range has only rarely been evaluated in practice, posing an open research\nproblem about the security of real-world realizations. Furthermore, this would\nfurther bridge the gap between theoretical channel models and their\npractice-oriented realizations. For security metrics, we utilize\ncross-correlation, mutual information, and a lower bound on secret-key\ncapacity. We design a practical setup of three parties such that the channel\nstatistics, although based on joint randomness, are always reproducible. We run\nexperiments to obtain channel states and evaluate the aforementioned metrics\nfor the impact of an attacker depending on his position. It turns out the\nattacker himself affects the outcome, which has not been adequately regarded\nyet in standard channel models. \n\n"}
{"id": "1701.05284", "contents": "Title: Rigorous Dynamics of Expectation-Propagation-Based Signal Recovery from\n  Unitarily Invariant Measurements Abstract: Signal recovery from unitarily invariant measurements is investigated in this\npaper. A message-passing algorithm is formulated on the basis of expectation\npropagation (EP). A rigorous analysis is presented for the dynamics of the\nalgorithm in the large system limit, where both input and output dimensions\ntend to infinity while the compression rate is kept constant. The main result\nis the justification of state evolution (SE) equations conjectured by Ma and\nPing. This result implies that the EP-based algorithm achieves the\nBayes-optimal performance that was originally derived via a non-rigorous tool\nin statistical physics and proved partially in a recent paper, when the\ncompression rate is larger than a threshold. The proof is based on an extension\nof a conventional conditioning technique for the standard Gaussian matrix to\nthe case of the Haar matrix. \n\n"}
{"id": "1701.05989", "contents": "Title: Bounds and Constructions for Linear Locally Repairable Codes over Binary\n  Fields Abstract: For binary $[n,k,d]$ linear locally repairable codes (LRCs), two new upper\nbounds on $k$ are derived. The first one applies to LRCs with disjoint local\nrepair groups, for general values of $n,d$ and locality $r$, containing some\npreviously known bounds as special cases. The second one is based on solving an\noptimization problem and applies to LRCs with arbitrary structure of local\nrepair groups. Particularly, an explicit bound is derived from the second bound\nwhen $d\\geq 5$. A specific comparison shows this explicit bound outperforms the\nCadambe-Mazumdar bound for $5\\leq d\\leq 8$ and large values of $n$. Moreover, a\nconstruction of binary linear LRCs with $d\\geq6$ attaining our second bound is\nprovided. \n\n"}
{"id": "1701.06290", "contents": "Title: A Practical Approach for Successive Omniscience Abstract: The system that we study in this paper contains a set of users that observe a\ndiscrete memoryless multiple source and communicate via noise-free channels\nwith the aim of attaining omniscience, the state that all users recover the\nentire multiple source. We adopt the concept of successive omniscience (SO),\ni.e., letting the local omniscience in some user subset be attained before the\nglobal omniscience in the entire system, and consider the problem of how to\nefficiently attain omniscience in a successive manner. Based on the existing\nresults on SO, we propose a CompSetSO algorithm for determining a complimentary\nset, a user subset in which the local omniscience can be attained first without\nincreasing the sum-rate, the total number of communications, for the global\nomniscience. We also derive a sufficient condition for a user subset to be\ncomplimentary so that running the CompSetSO algorithm only requires a lower\nbound, instead of the exact value, of the minimum sum-rate for attaining global\nomniscience. The CompSetSO algorithm returns a complimentary user subset in\npolynomial time. We show by example how to recursively apply the CompSetSO\nalgorithm so that the global omniscience can be attained by multi-stages of SO. \n\n"}
{"id": "1701.06969", "contents": "Title: Error correction based on partial information Abstract: We consider the decoding of linear and array codes from errors when we are\nonly allowed to download a part of the codeword. More specifically, suppose\nthat we have encoded $k$ data symbols using an $(n,k)$ code with code length\n$n$ and dimension $k.$ During storage, some of the codeword coordinates might\nbe corrupted by errors. We aim to recover the original data by reading the\ncorrupted codeword with a limit on the transmitting bandwidth, namely, we can\nonly download an $\\alpha$ proportion of the corrupted codeword. For a given\n$\\alpha,$ our objective is to design a code and a decoding scheme such that we\ncan recover the original data from the largest possible number of errors. A\nnaive scheme is to read $\\alpha n$ coordinates of the codeword. This method\nused in conjunction with MDS codes guarantees recovery from any $\\lfloor(\\alpha\nn-k)/2\\rfloor$ errors. In this paper we show that we can instead read an\n$\\alpha$ proportion from each of the codeword's coordinates. For a\nwell-designed MDS code, this method can guarantee recovery from $\\lfloor\n(n-k/\\alpha)/2 \\rfloor$ errors, which is $1/\\alpha$ times more than the naive\nmethod, and is also the maximum number of errors that an $(n,k)$ code can\ncorrect by downloading only an $\\alpha$ proportion of the codeword. We present\ntwo families of such optimal constructions and decoding schemes. One is a\nReed-Solomon code with evaluation points in a subfield and the other is based\non Folded Reed-Solomon codes. We further show that both code constructions\nattain asymptotically optimal list decoding radius when downloading only a part\nof the corrupted codeword. We also construct an ensemble of random codes that\nwith high probability approaches the upper bound on the number of correctable\nerrors when the decoder downloads an $\\alpha$ proportion of the corrupted\ncodeword. \n\n"}
{"id": "1701.07371", "contents": "Title: Divergence Scaling of Fixed-Length, Binary-Output, One-to-One\n  Distribution Matching Abstract: Distribution matching is the process of invertibly mapping a uniformly\ndistributed input sequence onto sequences that approximate the output of a\ndesired discrete memoryless source. The special case of a binary output\nalphabet and one-to-one mapping is studied. A fixed-length distribution matcher\nis proposed that is optimal in the sense of minimizing the unnormalized\ninformational divergence between its output distribution and a binary\nmemoryless target distribution. Upper and lower bounds on the unnormalized\ndivergence are computed that increase logarithmically in the output block\nlength $n$. It follows that a recently proposed constant composition\ndistribution matcher performs within a constant gap of the minimal achievable\ninformational divergence. \n\n"}
{"id": "1701.07805", "contents": "Title: On extractable shared information Abstract: We consider the problem of quantifying the information shared by a pair of\nrandom variables $X_{1},X_{2}$ about another variable $S$. We propose a new\nmeasure of shared information, called extractable shared information, that is\nleft monotonic; that is, the information shared about $S$ is bounded from below\nby the information shared about $f(S)$ for any function $f$. We show that our\nmeasure leads to a new nonnegative decomposition of the mutual information\n$I(S;X_1X_2)$ into shared, complementary and unique components. We study\nproperties of this decomposition and show that a left monotonic shared\ninformation is not compatible with a Blackwell interpretation of unique\ninformation. We also discuss whether it is possible to have a decomposition in\nwhich both shared and unique information are left monotonic. \n\n"}
{"id": "1702.00153", "contents": "Title: Structure and Performance of Generalized Quasi-Cyclic Codes Abstract: Generalized quasi-cyclic (GQC) codes form a natural generalization of\nquasi-cyclic (QC) codes. They are viewed here as mixed alphabet codes over a\nfamily of ring alphabets. Decomposing these rings into local rings by the\nChinese Remainder Theorem yields a decomposition of GQC codes into a sum of\nconcatenated codes. This decomposition leads to a trace formula, a minimum\ndistance bound, and to a criteria for the GQC code to be self-dual or to be\nlinear complementary dual (LCD). Explicit long GQC codes that are LCD, but not\nQC, are exhibited. \n\n"}
{"id": "1702.00709", "contents": "Title: IQN: An Incremental Quasi-Newton Method with Local Superlinear\n  Convergence Rate Abstract: The problem of minimizing an objective that can be written as the sum of a\nset of $n$ smooth and strongly convex functions is considered. The Incremental\nQuasi-Newton (IQN) method proposed here belongs to the family of stochastic and\nincremental methods that have a cost per iteration independent of $n$. IQN\niterations are a stochastic version of BFGS iterations that use memory to\nreduce the variance of stochastic approximations. The convergence properties of\nIQN bridge a gap between deterministic and stochastic quasi-Newton methods.\nDeterministic quasi-Newton methods exploit the possibility of approximating the\nNewton step using objective gradient differences. They are appealing because\nthey have a smaller computational cost per iteration relative to Newton's\nmethod and achieve a superlinear convergence rate under customary regularity\nassumptions. Stochastic quasi-Newton methods utilize stochastic gradient\ndifferences in lieu of actual gradient differences. This makes their\ncomputational cost per iteration independent of the number of objective\nfunctions $n$. However, existing stochastic quasi-Newton methods have sublinear\nor linear convergence at best. IQN is the first stochastic quasi-Newton method\nproven to converge superlinearly in a local neighborhood of the optimal\nsolution. IQN differs from state-of-the-art incremental quasi-Newton methods in\nthree aspects: (i) The use of aggregated information of variables, gradients,\nand quasi-Newton Hessian approximation matrices to reduce the noise of gradient\nand Hessian approximations. (ii) The approximation of each individual function\nby its Taylor's expansion in which the linear and quadratic terms are evaluated\nwith respect to the same iterate. (iii) The use of a cyclic scheme to update\nthe functions in lieu of a random selection routine. We use these fundamental\nproperties of IQN to establish its local superlinear convergence rate. \n\n"}
{"id": "1702.01672", "contents": "Title: On Coded Caching in the Overloaded MISO Broadcast Channel Abstract: This work investigates the interplay of coded caching and spatial\nmultiplexing in an overloaded Multiple-Input-Single-Output (MISO) Broadcast\nChannel (BC), i.e. a system where the number of users is greater than the\nnumber of transmitting antennas. On one hand, coded caching uses the aggregate\nglobal cache memory of the users to create multicasting opportunities. On the\nother hand, multiple antennas at the transmitter leverage the available CSIT to\ntransmit multiple streams simultaneously. In this paper, we introduce a novel\nscheme which combines both the gain derived from coded-caching and spatial\nmultiplexing and outperforms existing schemes in terms of delivery time and\nCSIT requirement. \n\n"}
{"id": "1702.04834", "contents": "Title: Improved Converses and Gap Results for Coded Caching Abstract: Improved lower bounds on the average and the worst-case rate-memory tradeoffs\nfor the Maddah-Ali&Niesen coded caching scenario are presented. For any number\nof users and files and for arbitrary cache sizes, the multiplicative gap\nbetween the exact rate-memory tradeoff and the new lower bound is less than\n2.315 in the worst-case scenario and less than 2.507 in the average-case\nscenario. \n\n"}
{"id": "1702.05018", "contents": "Title: Cross-Mode Interference Characterization in Cellular Networks with\n  Voronoi Guard Regions Abstract: Advances in cellular networks such as device-to-device communications and\nfull-duplex radios, as well as the inherent elimination of intra-cell\ninterference achieved by network-controlled multiple access schemes, motivates\nthe investigation of the cross-mode interference properties under a guard\nregion corresponding to the Voronoi cell of an access point (AP). By modeling\nthe positions of interfering APs and user equipments (UEs) as Poisson\ndistributed, analytical expressions for the statistics of the cross-mode\ninterference generated by either APs or UEs are obtained based on appropriately\ndefined density functions. The considered system model and analysis are general\nenough to capture many operational scenarios of practical interest, including\nconventional downlink/uplink transmissions with nearest AP association, as well\nas transmissions where not both communicating nodes lie within the same cell.\nAnalysis provides insights on the level of protection offered by a Voronoi\nguard region and its dependence on type of interference and receiver position.\nNumerical examples demonstrate the validity/accuracy of the analysis in\nobtaining the system coverage probability for operational scenarios of\npractical interest. \n\n"}
{"id": "1702.05197", "contents": "Title: Throughput-Optimal Broadcast in Wireless Networks with\n  Point-to-Multipoint Transmissions Abstract: We consider the problem of efficient packet dissemination in wireless\nnetworks with point-to-multi-point wireless broadcast channels. We propose a\ndynamic policy, which achieves the broadcast capacity of the network. This\npolicy is obtained by first transforming the original multi-hop network into a\nprecedence-relaxed virtual single-hop network and then finding an optimal\nbroadcast policy for the relaxed network. The resulting policy is shown to be\nthroughput-optimal for the original wireless network using a sample-path\nargument. We also prove the NP-completeness of the finite-horizon broadcast\nproblem, which is in contrast with the polynomial time solvability of the\nproblem with point-to-point channels. Illustrative simulation results\ndemonstrate the efficacy of the proposed broadcast policy in achieving the full\nbroadcast capacity with low delay. \n\n"}
{"id": "1702.06293", "contents": "Title: Measurement of the exclusive ${\\pi}^0$ muoproduction cross section at\n  COMPASS Abstract: At COMPASS DVCS and DVMP processes are studied in order to probe the partonic\nstructure of the nucleon by constraining GPD models. Extending beyond\nsemi-inclusive deep inelastic scattering, the measurement of lepton-induced\nexclusive reactions enables the study of GPDs, which ultimately reveal the\nthree dimensional picture of the nucleon and the decomposition of its total\nangular momentum. Exploiting the flavour filtering character of DVMP\nmeasurements, the COMPASS experiment is able to access different combinations\nof quark and gluon GPDs by determining the cross sections for various mesons.\nWe report on the first extraction of the exclusive ${\\pi}^0$ muoproduction\ncross section in the intermediate $x_{Bj}$ domain ranging from 0.01 to 0.15. \n\n"}
{"id": "1702.06435", "contents": "Title: Phase Transitions of Spectral Initialization for High-Dimensional\n  Nonconvex Estimation Abstract: We study a spectral initialization method that serves a key role in recent\nwork on estimating signals in nonconvex settings. Previous analysis of this\nmethod focuses on the phase retrieval problem and provides only performance\nbounds. In this paper, we consider arbitrary generalized linear sensing models\nand present a precise asymptotic characterization of the performance of the\nmethod in the high-dimensional limit. Our analysis also reveals a phase\ntransition phenomenon that depends on the ratio between the number of samples\nand the signal dimension. When the ratio is below a minimum threshold, the\nestimates given by the spectral method are no better than random guesses drawn\nfrom a uniform distribution on the hypersphere, thus carrying no information;\nabove a maximum threshold, the estimates become increasingly aligned with the\ntarget signal. The computational complexity of the method, as measured by the\nspectral gap, is also markedly different in the two phases. Worked examples and\nnumerical results are provided to illustrate and verify the analytical\npredictions. In particular, simulations show that our asymptotic formulas\nprovide accurate predictions for the actual performance of the spectral method\neven at moderate signal dimensions. \n\n"}
{"id": "1702.06772", "contents": "Title: Efficient CSMA using Regional Free Energy Approximations Abstract: CSMA (Carrier Sense Multiple Access) algorithms based on Gibbs sampling can\nachieve throughput optimality if certain parameters called the fugacities are\nappropriately chosen. However, the problem of computing these fugacities is\nNP-hard. In this work, we derive estimates of the fugacities by using a\nframework called the regional free energy approximations. In particular, we\nderive explicit expressions for approximate fugacities corresponding to any\nfeasible service rate vector. We further prove that our approximate fugacities\nare exact for the class of chordal graphs. A distinguishing feature of our work\nis that the regional approximations that we propose are tailored to conflict\ngraphs with small cycles, which is a typical characteristic of wireless\nnetworks. Numerical results indicate that the fugacities obtained by the\nproposed method are quite accurate and significantly outperform the existing\nBethe approximation based techniques. \n\n"}
{"id": "1702.07302", "contents": "Title: Two-Moment Inequalities for R\\'enyi Entropy and Mutual Information Abstract: This paper explores some applications of a two-moment inequality for the\nintegral of the $r$-th power of a function, where $0 < r< 1$. The first\ncontribution is an upper bound on the R\\'{e}nyi entropy of a random vector in\nterms of the two different moments. When one of the moments is the zeroth\nmoment, these bounds recover previous results based on maximum entropy\ndistributions under a single moment constraint. More generally, evaluation of\nthe bound with two carefully chosen nonzero moments can lead to significant\nimprovements with a modest increase in complexity. The second contribution is a\nmethod for upper bounding mutual information in terms of certain integrals with\nrespect to the variance of the conditional density. The bounds have a number of\nuseful properties arising from the connection with variance decompositions. \n\n"}
{"id": "1702.07737", "contents": "Title: Decoding Generalized Reed-Solomon Codes and Its Application to RLCE\n  Encryption Schemes Abstract: This paper compares the efficiency of various algorithms for implementing\nquantum resistant public key encryption scheme RLCE on 64-bit CPUs. By\noptimizing various algorithms for polynomial and matrix operations over finite\nfields, we obtained several interesting (or even surprising) results. For\nexample, it is well known (e.g., Moenck 1976 \\cite{moenck1976practical}) that\nKaratsuba's algorithm outperforms classical polynomial multiplication algorithm\nfrom the degree 15 and above (practically, Karatsuba's algorithm only\noutperforms classical polynomial multiplication algorithm from the degree 35\nand above ). Our experiments show that 64-bit optimized Karatsuba's algorithm\nwill only outperform 64-bit optimized classical polynomial multiplication\nalgorithm for polynomials of degree 115 and above over finite field\n$GF(2^{10})$. The second interesting (surprising) result shows that 64-bit\noptimized Chien's search algorithm ourperforms all other 64-bit optimized\npolynomial root finding algorithms such as BTA and FFT for polynomials of all\ndegrees over finite field $GF(2^{10})$. The third interesting (surprising)\nresult shows that 64-bit optimized Strassen matrix multiplication algorithm\nonly outperforms 64-bit optimized classical matrix multiplication algorithm for\nmatrices of dimension 750 and above over finite field $GF(2^{10})$. It should\nbe noted that existing literatures and practices recommend Strassen matrix\nmultiplication algorithm for matrices of dimension 40 and above. All our\nexperiments are done on a 64-bit MacBook Pro with i7 CPU and single thread C\ncodes. It should be noted that the reported results should be appliable to 64\nor larger bits CPU architectures. For 32 or smaller bits CPUs, these results\nmay not be applicable. The source code and library for the algorithms covered\nin this paper are available at http://quantumca.org/. \n\n"}
{"id": "1702.08033", "contents": "Title: Euclidean and Hermitian LCD MDS codes Abstract: Linear codes with complementary duals (abbreviated LCD) are linear codes\nwhose intersection with their dual is trivial. When they are binary, they play\nan important role in armoring implementations against side-channel attacks and\nfault injection attacks. Non-binary LCD codes in characteristic 2 can be\ntransformed into binary LCD codes by expansion. On the other hand, being\noptimal codes, maximum distance separable codes (abbreviated MDS) have been of\nmuch interest from many researchers due to their theoretical significant and\npractical implications. However, little work has been done on LCD MDS codes. In\nparticular, determining the existence of $q$-ary $[n,k]$ LCD MDS codes for\nvarious lengths $n$ and dimensions $k$ is a basic and interesting problem. In\nthis paper, we firstly study the problem of the existence of $q$-ary $[n,k]$\nLCD MDS codes and completely solve it for the Euclidean case. More\nspecifically, we show that for $q>3$ there exists a $q$-ary $[n,k]$ Euclidean\nLCD MDS code, where $0\\le k \\le n\\le q+1$, or, $q=2^{m}$, $n=q+2$ and $k= 3\n\\text{or} q-1$. Secondly, we investigate several constructions of new Euclidean\nand Hermitian LCD MDS codes. Our main techniques in constructing Euclidean and\nHermitian LCD MDS codes use some linear codes with small dimension or\ncodimension, self-orthogonal codes and generalized Reed-Solomon codes. \n\n"}
{"id": "1702.08044", "contents": "Title: Benefits of Cache Assignment on Degraded Broadcast Channels Abstract: Degraded K-user broadcast channels (BC) are studied when receivers are\nfacilitated with cache memories. Lower and upper bounds are derived on the\ncapacity-memory tradeoff, i.e., on the largest rate of reliable communication\nover the BC as a function of the receivers' cache sizes, and the bounds are\nshown to match for some special cases. The lower bounds are achieved by two new\ncoding schemes that benefit from non-uniform cache assignment. Lower and upper\nbounds are also established on the global capacity-memory tradeoff, i.e., on\nthe largest capacity-memory tradeoff that can be attained by optimizing the\nreceivers' cache sizes subject to a total cache memory budget. The bounds\ncoincide when the total cache memory budget is sufficiently small or\nsufficiently large, characterized in terms of the BC statistics. For small\ncache memories, it is optimal to assign all the cache memory to the weakest\nreceiver. In this regime, the global capacity-memory tradeoff grows as the\ntotal cache memory budget divided by the number of files in the system. In\nother words, a perfect global caching gain is achievable in this regime and the\nperformance corresponds to a system where all cache contents in the network are\navailable to all receivers. For large cache memories, it is optimal to assign a\npositive cache memory to every receiver such that the weaker receivers are\nassigned larger cache memories compared to the stronger receivers. In this\nregime, the growth rate of the global capacity-memory tradeoff is further\ndivided by the number of users, which corresponds to a local caching gain.\nNumerical indicate suggest that a uniform cache-assignment of the total cache\nmemory is suboptimal in all regimes unless the BC is completely symmetric. For\nerasure BCs, this claim is proved analytically in the regime of small\ncache-sizes. \n\n"}
{"id": "1702.08211", "contents": "Title: Algorithmic Chaining and the Role of Partial Feedback in Online\n  Nonparametric Learning Abstract: We investigate contextual online learning with nonparametric (Lipschitz)\ncomparison classes under different assumptions on losses and feedback\ninformation. For full information feedback and Lipschitz losses, we design the\nfirst explicit algorithm achieving the minimax regret rate (up to log factors).\nIn a partial feedback model motivated by second-price auctions, we obtain\nalgorithms for Lipschitz and semi-Lipschitz losses with regret bounds improving\non the known bounds for standard bandit feedback. Our analysis combines novel\nresults for contextual second-price auctions with a novel algorithmic approach\nbased on chaining. When the context space is Euclidean, our chaining approach\nis efficient and delivers an even better regret bound. \n\n"}
{"id": "1703.01362", "contents": "Title: First and Second Order Asymptotics in Covert Communication Abstract: We study the first- and second-order asymptotics of covert communication over\nbinary-input DMC for three different covertness metrics and under maximum\nprobability of error constraint. When covertness is measured in terms of the\nrelative entropy between the channel output distributions induced with and\nwithout communication, we characterize the exact first- and second-order\nasymptotics of the number of bits that can be reliably transmitted with a\nmaximum probability of error less than $\\epsilon$ and a relative entropy less\nthan $\\delta$. When covertness is measured in terms of the variational distance\nbetween the channel output distributions or in terms of the probability of\nmissed detection for fixed probability of false alarm, we establish the exact\nfirst-order asymptotics and bound the second-order asymptotics. PPM achieves\nthe optimal first-order asymptotics for all three metrics, as well as the\noptimal second-order asymptotics for relative entropy. The main conceptual\ncontribution of this paper is to clarify how the choice of a covertness metric\nimpacts the information-theoretic limits of covert communications. The main\ntechnical contribution underlying our results is a detailed expurgation\nargument to show the existence of a code satisfying the reliability and\ncovertness criteria. \n\n"}
{"id": "1703.03596", "contents": "Title: High SNR Consistent Compressive Sensing Abstract: High signal to noise ratio (SNR) consistency of model selection criteria in\nlinear regression models has attracted a lot of attention recently. However,\nmost of the existing literature on high SNR consistency deals with model order\nselection. Further, the limited literature available on the high SNR\nconsistency of subset selection procedures (SSPs) is applicable to linear\nregression with full rank measurement matrices only. Hence, the performance of\nSSPs used in underdetermined linear models (a.k.a compressive sensing (CS)\nalgorithms) at high SNR is largely unknown. This paper fills this gap by\nderiving necessary and sufficient conditions for the high SNR consistency of\npopular CS algorithms like $l_0$-minimization, basis pursuit de-noising or\nLASSO, orthogonal matching pursuit and Dantzig selector. Necessary conditions\nanalytically establish the high SNR inconsistency of CS algorithms when used\nwith the tuning parameters discussed in literature. Novel tuning parameters\nwith SNR adaptations are developed using the sufficient conditions and the\nchoice of SNR adaptations are discussed analytically using convergence rate\nanalysis. CS algorithms with the proposed tuning parameters are numerically\nshown to be high SNR consistent and outperform existing tuning parameters in\nthe moderate to high SNR regime. \n\n"}
{"id": "1703.04072", "contents": "Title: Resource Allocation for a Full-Duplex Base Station Aided OFDMA System Abstract: Exploiting full-duplex (FD) technology on base stations (BSs) is a promising\nsolution to enhancing the system performance. Motivated by this, we revisit a\nfull-duplex base station (FD-BS) aided OFDMA system, which consists of one BS,\nseveral uplink/downlink users and multiple subcarriers. A joint 3-dimensional\n(3D) mapping scheme among subcarriers, down-link users (DUEs), uplink users\n(UUEs) is considered as well as an associated power allocation optimization. In\ndetail, we first decompose the complex 3D mapping problem into three\n2-dimensional sub ones and solve them by using the iterative Hungarian method,\nrespectively. Then based on the Lagrange dual method, we sequentially solve the\npower allocation and 3- dimensional mapping problem by fixing a dual point.\nFinally, the optimal solution can be obtained by utilizing the sub-gradient\nmethod. Unlike existing work that only solves either 3D mapping or power\nallocation problem but with a high computation complexity, we tackle both of\nthem and have successfully reduced computation complexity from exponential to\npolynomial order. Numerical simulations are conducted to verify the proposed\nscheme. \n\n"}
{"id": "1703.05080", "contents": "Title: Tuning Free Orthogonal Matching Pursuit Abstract: Orthogonal matching pursuit (OMP) is a widely used compressive sensing (CS)\nalgorithm for recovering sparse signals in noisy linear regression models. The\nperformance of OMP depends on its stopping criteria (SC). SC for OMP discussed\nin literature typically assumes knowledge of either the sparsity of the signal\nto be estimated $k_0$ or noise variance $\\sigma^2$, both of which are\nunavailable in many practical applications. In this article we develop a\nmodified version of OMP called tuning free OMP or TF-OMP which does not require\na SC. TF-OMP is proved to accomplish successful sparse recovery under the usual\nassumptions on restricted isometry constants (RIC) and mutual coherence of\ndesign matrix. TF-OMP is numerically shown to deliver a highly competitive\nperformance in comparison with OMP having \\textit{a priori} knowledge of $k_0$\nor $\\sigma^2$. Greedy algorithm for robust de-noising (GARD) is an OMP like\nalgorithm proposed for efficient estimation in classical overdetermined linear\nregression models corrupted by sparse outliers. However, GARD requires the\nknowledge of inlier noise variance which is difficult to estimate. We also\nproduce a tuning free algorithm (TF-GARD) for efficient estimation in the\npresence of sparse outliers by extending the operating principle of TF-OMP to\nGARD. TF-GARD is numerically shown to achieve a performance comparable to that\nof the existing implementation of GARD. \n\n"}
{"id": "1703.05671", "contents": "Title: Upper bounds for the Holevo quantity and their use Abstract: We present a family of easily computable upper bounds for the Holevo quantity\nof ensemble of quantum states depending on a reference state as a free\nparameter. These upper bounds are obtained by combining probabilistic and\nmetric characteristics of the ensemble. We show that appropriate choice of the\nreference state gives tight upper bounds for the Holevo quantity which in many\ncases improve existing estimates in the literature.\n  We also present upper bound for the Holevo quantity of a generalized ensemble\nof quantum states with finite average energy depending on metric divergence of\nthe ensemble. The specification of this upper bound for the multi-mode quantum\noscillator is tight for large energy.\n  The above results are used to obtain tight upper bounds for the Holevo\ncapacity of finite-dimensional and infinite-dimensional energy-constrained\nquantum channels depending on metric characteristics of the channel output. \n\n"}
{"id": "1703.07442", "contents": "Title: Comment on the Equality Condition for the I-MMSE Proof of Entropy Power\n  Inequality Abstract: The paper establishes the equality condition in the I-MMSE proof of the\nentropy power inequality (EPI). This is done by establishing an exact\nexpression for the deficit between the two sides of the EPI. Interestingly, a\nnecessary condition for the equality is established by making a connection to\nthe famous Cauchy functional equation. \n\n"}
{"id": "1703.08900", "contents": "Title: Some new bounds of placement delivery arrays Abstract: Coded caching scheme is a technique which reduce the load during peak traffic\ntimes in a wireless network system. Placement delivery array (PDA in short) was\nfirst introduced by Yan et al.. It can be used to design coded caching scheme.\nIn this paper, we prove some lower bounds of PDA on the element and some lower\nbounds of PDA on the column. We also give some constructions for optimal PDA. \n\n"}
{"id": "1703.10556", "contents": "Title: Sparse Signal Recovery via Generalized Entropy Functions Minimization Abstract: Compressive sensing relies on the sparse prior imposed on the signal of\ninterest to solve the ill-posed recovery problem in an under-determined linear\nsystem. The objective function used to enforce the sparse prior information\nshould be both effective and easily optimizable. Motivated by the entropy\nconcept from information theory, in this paper we propose the generalized\nShannon entropy function and R\\'{e}nyi entropy function of the signal as the\nsparsity promoting regularizers. Both entropy functions are nonconvex,\nnon-separable. Their local minimums only occur on the boundaries of the\northants in the Euclidean space. Compared to other popular objective functions,\nminimizing the generalized entropy functions adaptively promotes multiple\nhigh-energy coefficients while suppressing the rest low-energy coefficients.\nThe corresponding optimization problems can be recasted into a series of\nreweighted $l_1$-norm minimization problems and then solved efficiently by\nadapting the FISTA. Sparse signal recovery experiments on both the simulated\nand real data show the proposed entropy functions minimization approaches\nperform better than other popular approaches and achieve state-of-the-art\nperformances. \n\n"}
{"id": "1704.00367", "contents": "Title: Provable Inductive Robust PCA via Iterative Hard Thresholding Abstract: The robust PCA problem, wherein, given an input data matrix that is the\nsuperposition of a low-rank matrix and a sparse matrix, we aim to separate out\nthe low-rank and sparse components, is a well-studied problem in machine\nlearning. One natural question that arises is that, as in the inductive\nsetting, if features are provided as input as well, can we hope to do better?\nAnswering this in the affirmative, the main goal of this paper is to study the\nrobust PCA problem while incorporating feature information. In contrast to\nprevious works in which recovery guarantees are based on the convex relaxation\nof the problem, we propose a simple iterative algorithm based on\nhard-thresholding of appropriate residuals. Under weaker assumptions than\nprevious works, we prove the global convergence of our iterative procedure;\nmoreover, it admits a much faster convergence rate and lesser computational\ncomplexity per iteration. In practice, through systematic synthetic and real\ndata simulations, we confirm our theoretical findings regarding improvements\nobtained by using feature information. \n\n"}
{"id": "1704.01312", "contents": "Title: On Generalization and Regularization in Deep Learning Abstract: Why do large neural network generalize so well on complex tasks such as image\nclassification or speech recognition? What exactly is the role regularization\nfor them? These are arguably among the most important open questions in machine\nlearning today. In a recent and thought provoking paper [C. Zhang et al.]\nseveral authors performed a number of numerical experiments that hint at the\nneed for novel theoretical concepts to account for this phenomenon. The paper\nstirred quit a lot of excitement among the machine learning community but at\nthe same time it created some confusion as discussions on OpenReview.net\ntestifies. The aim of this pedagogical paper is to make this debate accessible\nto a wider audience of data scientists without advanced theoretical knowledge\nin statistical learning. The focus here is on explicit mathematical definitions\nand on a discussion of relevant concepts, not on proofs for which we provide\nreferences. \n\n"}
{"id": "1704.01535", "contents": "Title: Distributed Hypothesis Testing Over Noisy Channels Abstract: A distributed binary hypothesis testing problem, in which multiple observers\ntransmit their observations to a detector over noisy channels, is studied.\nGiven its own side information, the goal of the detector is to decide between\ntwo hypotheses for the joint distribution of the data. Single-letter upper and\nlower bounds on the optimal type 2 error exponent (T2-EE), when the type 1\nerror probability vanishes with the block-length are obtained. These bounds\ncoincide and characterize the optimal T2-EE when only a single helper is\ninvolved. Our result shows that the optimal T2-EE depends on the marginal\ndistributions of the data and the channels rather than their joint\ndistribution. However, an operational separation between HT and channel coding\ndoes not hold, and the optimal T2-EE is achieved by generating channel inputs\ncorrelated with observed data. \n\n"}
{"id": "1704.02275", "contents": "Title: Mitigating Interference in Content Delivery Networks by Spatial Signal\n  Alignment: The Approach of Shot-Noise Ratio Abstract: Multimedia content especially videos is expected to dominate data traffic in\nnext-generation mobile networks. Caching popular content at the network edge\nhas emerged to be a solution for low-latency content delivery. Compared with\nthe traditional wireless communication, content delivery has a key\ncharacteristic that many signals coexisting in the air carry identical popular\ncontent. They, however, can interfere with each other at a receiver if their\nmodulation-and-coding (MAC) schemes are adapted to individual channels\nfollowing the classic approach. To address this issue, we present a novel idea\nof content adaptive MAC (CAMAC) where adapting MAC schemes to content ensures\nthat all signals carry identical content are encoded using an identical MAC\nscheme, achieving spatial MAC alignment. Consequently, interference can be\nharnessed as signals, to improve the reliability of wireless delivery. In the\nremaining part of the paper, we focus on quantifying the gain CAMAC can bring\nto a content-delivery network using a stochastic-geometry model. Specifically,\ncontent helpers are distributed as a Poisson point process, each of which\ntransmits a file from a content database based on a given popularity\ndistribution. It is discovered that the successful content-delivery probability\nis closely related to the distribution of the ratio of two independent shot\nnoise processes, named a shot-noise ratio. The distribution itself is an open\nmathematical problem that we tackle in this work. Using stable-distribution\ntheory and tools from stochastic geometry, the distribution function is derived\nin closed form. Extending the result in the context of content-delivery\nnetworks with CAMAC yields the content-delivery probability in different closed\nforms. In addition, the gain in the probability due to CAMAC is shown to grow\nwith the level of skewness in the content popularity distribution. \n\n"}
{"id": "1704.03387", "contents": "Title: Enhancement of Physical Layer Security Using Destination Artificial\n  Noise Based on Outage Probability Abstract: In this paper, we study using Destination Artificial Noise (DAN) besides\nSource Artificial Noise (SAN) to enhance physical layer secrecy with an outage\nprobability based approach. It is assumed that all nodes in the network (i.e.\nsource, destination and eavesdropper) are equipped with multiple antennas. In\naddition, the eavesdropper is passive and its channel state and location are\nunknown at the source and destination. In our proposed scheme, by optimized\nallocation of power to the SAN, DAN and data signal, a minimum value for the\noutage probability is guaranteed at the eavesdropper, and at the same time a\ncertain level of signal to noise ratio (SNR) at the destination is ensured. Our\nsimulation results show that using DAN along with SAN brings a significant\nenhancement in power consumption compared to methods that merely adopt SAN to\nachieve the same outage probability at the eavesdropper. \n\n"}
{"id": "1704.05443", "contents": "Title: Approximations from Anywhere and General Rough Sets Abstract: Not all approximations arise from information systems. The problem of fitting\napproximations, subjected to some rules (and related data), to information\nsystems in a rough scheme of things is known as the \\emph{inverse problem}. The\ninverse problem is more general than the duality (or abstract representation)\nproblems and was introduced by the present author in her earlier papers. From\nthe practical perspective, a few (as opposed to one) theoretical frameworks may\nbe suitable for formulating the problem itself. \\emph{Granular operator spaces}\nhave been recently introduced and investigated by the present author in her\nrecent work in the context of antichain based and dialectical semantics for\ngeneral rough sets. The nature of the inverse problem is examined from\nnumber-theoretic and combinatorial perspectives in a higher order variant of\ngranular operator spaces and some necessary conditions are proved. The results\nand the novel approach would be useful in a number of unsupervised and semi\nsupervised learning contexts and algorithms. \n\n"}
{"id": "1704.06531", "contents": "Title: Asymptotic Performance Analysis of Spatially Reconfigurable Antenna\n  Arrays Abstract: A spatially reconfigurable antenna arrays consists of an antenna array of\nfinite length and fixed geometry which is displaced within a given area. Using\nthese reconfigurable components, the performance of MIMO systems is remarkably\nimproved by effectively positioning the array in its displacement area. This\npaper studies the large-system performance of MIMO setups with spatially\nreconfigurable antenna arrays when the displacement area is large. Considering\nfading channels, the distribution of the input-output mutual information is\nderived, and the asymptotic hardening property is demonstrated to hold. As the\nsize of the displacement area grows large, the mutual information is shown to\nconverge in distribution to a type-one Gumbel random variable whose mean grows\nlarge proportional to the displacement size, and whose variance tends to zero.\nOur numerical investigations depict that the type-one Gumbel approximation\nclosely tracks the empirical distribution even for a finite displacement size. \n\n"}
{"id": "1704.07461", "contents": "Title: Denoising Linear Models with Permuted Data Abstract: The multivariate linear regression model with shuffled data and additive\nGaussian noise arises in various correspondence estimation and matching\nproblems. Focusing on the denoising aspect of this problem, we provide a\ncharacterization the minimax error rate that is sharp up to logarithmic\nfactors. We also analyze the performance of two versions of a computationally\nefficient estimator, and establish their consistency for a large range of input\nparameters. Finally, we provide an exact algorithm for the noiseless problem\nand demonstrate its performance on an image point-cloud matching task. Our\nanalysis also extends to datasets with outliers. \n\n"}
{"id": "1704.07611", "contents": "Title: A Survey on MIMO Transmission with Discrete Input Signals: Technical\n  Challenges, Advances, and Future Trends Abstract: Multiple antennas have been exploited for spatial multiplexing and diversity\ntransmission in a wide range of communication applications. However, most of\nthe advances in the design of high speed wireless multiple-input multiple\noutput (MIMO) systems are based on information-theoretic principles that\ndemonstrate how to efficiently transmit signals conforming to Gaussian\ndistribution. Although the Gaussian signal is capacity-achieving, signals\nconforming to discrete constellations are transmitted in practical\ncommunication systems. As a result, this paper is motivated to provide a\ncomprehensive overview on MIMO transmission design with discrete input signals.\nWe first summarize the existing fundamental results for MIMO systems with\ndiscrete input signals. Then, focusing on the basic point-to-point MIMO\nsystems, we examine transmission schemes based on three most important criteria\nfor communication systems: the mutual information driven designs, the mean\nsquare error driven designs, and the diversity driven designs. Particularly, a\nunified framework which designs low complexity transmission schemes applicable\nto massive MIMO systems in upcoming 5G wireless networks is provided in the\nfirst time. Moreover, adaptive transmission designs which switch among these\ncriteria based on the channel conditions to formulate the best transmission\nstrategy are discussed. Then, we provide a survey of the transmission designs\nwith discrete input signals for multiuser MIMO scenarios, including MIMO uplink\ntransmission, MIMO downlink transmission, MIMO interference channel, and MIMO\nwiretap channel. Additionally, we discuss the transmission designs with\ndiscrete input signals for other systems using MIMO technology. Finally,\ntechnical challenges which remain unresolved at the time of writing are\nsummarized and the future trends of transmission designs with discrete input\nsignals are addressed. \n\n"}
{"id": "1704.08920", "contents": "Title: Interference Exploitation for Radar and Cellular Coexistence: The\n  Power-Efficient Approach Abstract: We propose a novel approach to enable the coexistence between\nMulti-Input-Multi-Output (MIMO) radar and downlink multi-user\nMulti-Input-Single-Output (MU-MISO) communication system. By exploiting the\nconstructive multi-user interference (MUI), the proposed approach trades-off\nuseful MUI power for reducing the transmit power, to obtain a power efficient\ntransmission. This paper focuses on two optimization problems: a) Transmit\npower minimization at the base station (BS) while guaranteeing the receive\nsignal-to-interference-plus-noise ratio (SINR) level of downlink users and the\ninterference-to-noise ratio (INR) level to radar; b) Minimization of the\ninterference from BS to radar for a given requirement of downlink SINR and\ntransmit power budget. To reduce the computational overhead of the proposed\nscheme in practice, an algorithm based on gradient projection is designed to\nsolve the power minimization problem. In addition, we investigate the trade-off\nbetween the performance of radar and communication, and analytically derive the\nkey metrics for MIMO radar in the presence of the interference from the BS.\nFinally, a robust power minimization problem is formulated to ensure the\neffectiveness of the proposed method in the case of imperfect Channel State\nInformation (CSI). Numerical results show that the proposed method achieves a\nsignificant power saving compared to conventional approaches, while obtaining a\nfavorable performance-complexity trade-off. \n\n"}
{"id": "1705.01473", "contents": "Title: Randomness cost of symmetric twirling Abstract: We study random unitary channels which reproduce the action of the twirling\nchannel corresponding to the representation of the symmetric groupon an n-fold\ntensor product. We derive upper andlower bounds on the randomness cost of\nimplementing such a map which depend exponentially on the number of systems.\nConsequently, symmetrictwirling can be regarded as a reasonable Shannon\ntheoretic protocol. On the other hand, such protocols are disqualified by their\nresource-inefficiency in situations where randomness is a costly resource. \n\n"}
{"id": "1705.01733", "contents": "Title: On the Design of Matched Filters for Molecule Counting Receivers Abstract: In this paper, we design matched filters for diffusive molecular\ncommunication systems taking into account the following impairments:\nsignal-dependent diffusion noise, inter-symbol interference (ISI), and external\ninterfering molecules. The receiver counts the number of observed molecules\nseveral times within one symbol interval and employs linear filtering to detect\nthe transmitted data. We derive the optimal matched filter by maximizing the\nexpected signal-to-interference-plus-noise ratio of the decision variable.\nMoreover, we show that for the special case of an ISI-free channel, the matched\nfilter reduces to a simple sum detector and a correlator for the channel\nimpulse response for the diffusion noise-limited and (external)\ninterference-limited regimes, respectively. Our simulation results reveal that\nthe proposed matched filter considerably outperforms the benchmark schemes\navailable in literature, especially when ISI is severe. \n\n"}
{"id": "1705.02753", "contents": "Title: Optimizing Pilot Overhead for Ultra-Reliable Short-Packet Transmission Abstract: In this paper we optimize the pilot overhead for ultra-reliable short-packet\ntransmission and investigate the dependence of this overhead on packet size and\nerror probability. In particular, we consider a point-to-point communication in\nwhich one sensor sends messages to a central node, or base-station, over AWGN\nwith Rayleigh fading channel. We formalize the optimization in terms of\napproximate achievable rates at a given block length, pilot length, and error\nprobability. This leads to more accurate pilot overhead optimization.\nSimulation results show that it is important to take into account the packet\nsize and the error probability when optimizing the pilot overhead. \n\n"}
{"id": "1705.03439", "contents": "Title: Frequentist Consistency of Variational Bayes Abstract: A key challenge for modern Bayesian statistics is how to perform scalable\ninference of posterior distributions. To address this challenge, variational\nBayes (VB) methods have emerged as a popular alternative to the classical\nMarkov chain Monte Carlo (MCMC) methods. VB methods tend to be faster while\nachieving comparable predictive performance. However, there are few theoretical\nresults around VB. In this paper, we establish frequentist consistency and\nasymptotic normality of VB methods. Specifically, we connect VB methods to\npoint estimates based on variational approximations, called frequentist\nvariational approximations, and we use the connection to prove a variational\nBernstein-von Mises theorem. The theorem leverages the theoretical\ncharacterizations of frequentist variational approximations to understand\nasymptotic properties of VB. In summary, we prove that (1) the VB posterior\nconverges to the Kullback-Leibler (KL) minimizer of a normal distribution,\ncentered at the truth and (2) the corresponding variational expectation of the\nparameter is consistent and asymptotically normal. As applications of the\ntheorem, we derive asymptotic properties of VB posteriors in Bayesian mixture\nmodels, Bayesian generalized linear mixed models, and Bayesian stochastic block\nmodels. We conduct a simulation study to illustrate these theoretical results. \n\n"}
{"id": "1705.04051", "contents": "Title: Nash Region of the Linear Deterministic Interference Channel with Noisy\n  Output Feedback Abstract: In this paper, the $\\eta$-Nash equilibrium ($\\eta$-NE) region of the two-user\nlinear deterministic interference channel (IC) with noisy channel-output\nfeedback is characterized for all $\\eta > 0$. The $\\eta$-NE region, a subset of\nthe capacity region, contains the set of all achievable information rate pairs\nthat are stable in the sense of an $\\eta$-NE. More specifically, given an\n$\\eta$-NE coding scheme, there does not exist an alternative coding scheme for\neither transmitter-receiver pair that increases the individual rate by more\nthan $\\eta$ bits per channel use. Existing results such as the $\\eta$-NE region\nof the linear deterministic IC without feedback and with perfect output\nfeedback are obtained as particular cases of the result presented in this\npaper. \n\n"}
{"id": "1705.06558", "contents": "Title: Robust Chance-Constrained Optimization for Power-Efficient and Secure\n  SWIPT Systems Abstract: In this paper, we propose beamforming schemes to simultaneously transmit data\nsecurely to multiple information receivers (IRs) while transferring power\nwirelessly to multiple energy-harvesting receivers (ERs). Taking into account\nthe imperfection of the instantaneous channel state information (CSI), we\nintroduce a chance-constrained optimization problem to minimize the total\ntransmit power while guaranteeing data transmission reliability, data\ntransmission security, and power transfer reliability. As the proposed\noptimization problem is non-convex due to the chance constraints, we propose\ntwo robust reformulations of the original problem based on\nsafe-convex-approximation techniques. Subsequently, applying semidefinite\nprogramming relaxation (SDR), the derived robust reformulations can be\neffectively solved by standard convex optimization packages. We show that the\nadopted SDR is tight and thus the globally optimal solutions of the\nreformulated problems can be recovered. Simulation results confirm the\nsuperiority of the proposed methods in guaranteeing transmission security\ncompared to a baseline scheme. Furthermore, the performance of proposed methods\ncan closely follow that of a benchmark scheme where perfect CSI is available\nfor resource allocation. \n\n"}
{"id": "1705.06799", "contents": "Title: Joint Uplink and Downlink Coverage Analysis of Cellular-based RF-powered\n  IoT Network Abstract: Ambient radio frequency (RF) energy harvesting has emerged as a promising\nsolution for powering small devices and sensors in massive Internet of Things\n(IoT) ecosystem due to its ubiquity and cost efficiency. In this paper, we\nstudy joint uplink and downlink coverage of cellular-based ambient RF energy\nharvesting IoT where the cellular network is assumed to be the only source of\nRF energy. We consider a time division-based approach for power and information\ntransmission where each time-slot is partitioned into three sub-slots: (i)\ncharging sub-slot during which the cellular base stations (BSs) act as RF\nchargers for the IoT devices, which then use the energy harvested in this\nsub-slot for information transmission and/or reception during the remaining two\nsub-slots, (ii) downlink sub-slot during which the IoT device receives\ninformation from the associated BS, and (iii) uplink sub-slot during which the\nIoT device transmits information to the associated BS. For this setup, we\ncharacterize the joint coverage probability, which is the joint probability of\nthe events that the typical device harvests sufficient energy in the given time\nslot and is under both uplink and downlink signal-to-interference-plus-noise\nratio (SINR) coverage with respect to its associated BS. This metric\nsignificantly generalizes the prior art on energy harvesting communications,\nwhich usually focused on downlink or uplink coverage separately. The key\ntechnical challenge is in handling the correlation between the amount of energy\nharvested in the charging sub-slot and the information signal quality (SINR) in\nthe downlink and uplink sub-slots. Dominant BS-based approach is developed to\nderive tight approximation for this joint coverage probability. Several system\ndesign insights including comparison with regularly powered IoT network and\nthroughput-optimal slot partitioning are also provided. \n\n"}
{"id": "1705.07349", "contents": "Title: $\\left( \\beta, \\varpi \\right)$-stability for cross-validation and the\n  choice of the number of folds Abstract: In this paper, we introduce a new concept of stability for cross-validation,\ncalled the $\\left( \\beta, \\varpi \\right)$-stability, and use it as a new\nperspective to build the general theory for cross-validation. The $\\left(\n\\beta, \\varpi \\right)$-stability mathematically connects the generalization\nability and the stability of the cross-validated model via the Rademacher\ncomplexity. Our result reveals mathematically the effect of cross-validation\nfrom two sides: on one hand, cross-validation picks the model with the best\nempirical generalization ability by validating all the alternatives on test\nsets; on the other hand, cross-validation may compromise the stability of the\nmodel selection by causing subsampling error. Moreover, the difference between\ntraining and test errors in q\\textsuperscript{th} round, sometimes referred to\nas the generalization error, might be autocorrelated on q. Guided by the ideas\nabove, the $\\left( \\beta, \\varpi \\right)$-stability help us derivd a new class\nof Rademacher bounds, referred to as the one-round/convoluted Rademacher\nbounds, for the stability of cross-validation in both the i.i.d.\\ and\nnon-i.i.d.\\ cases. For both light-tail and heavy-tail losses, the new bounds\nquantify the stability of the one-round/average test error of the\ncross-validated model in terms of its one-round/average training error, the\nsample sizes $n$, number of folds $K$, the tail property of the loss (encoded\nas Orlicz-$\\Psi_\\nu$ norms) and the Rademacher complexity of the model class\n$\\Lambda$. The new class of bounds not only quantitatively reveals the\nstability of the generalization ability of the cross-validated model, it also\nshows empirically the optimal choice for number of folds $K$, at which the\nupper bound of the one-round/average test error is lowest, or, to put it in\nanother way, where the test error is most stable. \n\n"}
{"id": "1705.07533", "contents": "Title: A Note on the Information-Theoretic-(in)Security of Fading Generated\n  Secret Keys Abstract: In this work we explore the security of secret keys generated via the\nelectromagnetic reciprocity of the wireless fading channel. Identifying a new\nsophisticated colluding attack, we explore the information-theoretic-security\nfor such keys in the presence of an all-powerful adversary constrained only by\nthe laws of quantum mechanics. Specifically, we calculate the reduction in the\nconditional mutual information between transmitter and receiver that can occur\nwhen an adversary with unlimited computational and communication resources\nplaces directional antenna interceptors at chosen locations. Such locations, in\nprincipal, can be arbitrarily far from the intended receiver yet still\ninfluence the secret key rate. \n\n"}
{"id": "1705.08572", "contents": "Title: Joint Rate Control and Power Allocation for Non-Orthogonal Multiple\n  Access Systems Abstract: This paper investigates the optimal resource allocation of a downlink\nnon-orthogonal multiple access (NOMA) system consisting of one base station and\nmultiple users. Unlike existing short-term NOMA designs that focused on the\nresource allocation for only the current transmission timeslot, we aim to\nmaximize a long-term network utility by jointly optimizing the data rate\ncontrol at the network layer and the power allocation among multiple users at\nthe physical layer, subject to practical constraints on both the short-term and\nlong-term power consumptions. To solve this problem, we leverage the\nrecently-developed Lyapunov optimization framework to convert the original\nlong-term optimization problem into a series of online rate control and power\nallocation problems in each timeslot. The power allocation problem, however, is\nshown to be non-convex in nature and thus cannot be solved with a standard\nmethod. However, we explore two structures of the optimal solution and develop\na dynamic programming based power allocation algorithm, which can derive a\nglobally optimal solution, with a polynomial computational complexity.\nExtensive simulation results are provided to evaluate the performance of the\nproposed joint rate control and power allocation framework for NOMA systems,\nwhich demonstrate that the proposed NOMA design can significantly outperform\nmultiple benchmark schemes, including orthogonal multiple access (OMA) schemes\nwith optimal power allocation and NOMA schemes with non-optimal power\nallocation, in terms of average throughput and data delay. \n\n"}
{"id": "1705.09391", "contents": "Title: Discovering Reliable Approximate Functional Dependencies Abstract: Given a database and a target attribute of interest, how can we tell whether\nthere exists a functional, or approximately functional dependence of the target\non any set of other attributes in the data? How can we reliably, without bias\nto sample size or dimensionality, measure the strength of such a dependence?\nAnd, how can we efficiently discover the optimal or $\\alpha$-approximate\ntop-$k$ dependencies? These are exactly the questions we answer in this paper.\n  As we want to be agnostic on the form of the dependence, we adopt an\ninformation-theoretic approach, and construct a reliable, bias correcting score\nthat can be efficiently computed. Moreover, we give an effective optimistic\nestimator of this score, by which for the first time we can mine the\napproximate functional dependencies from data with guarantees of optimality.\nEmpirical evaluation shows that the derived score achieves a good bias for\nvariance trade-off, can be used within an efficient discovery algorithm, and\nindeed discovers meaningful dependencies. Most important, it remains reliable\nin the face of data sparsity. \n\n"}
{"id": "1705.09949", "contents": "Title: Measurement uncertainty relations for position and momentum: Relative\n  entropy formulation Abstract: Heisenberg's uncertainty principle has recently led to general measurement\nuncertainty relations for quantum systems: incompatible observables can be\nmeasured jointly or in sequence only with some unavoidable approximation, which\ncan be quantified in various ways. The relative entropy is the natural\ntheoretical quantifier of the information loss when a `true' probability\ndistribution is replaced by an approximating one. In this paper, we provide a\nlower bound for the amount of information that is lost by replacing the\ndistributions of the sharp position and momentum observables, as they could be\nobtained with two separate experiments, by the marginals of any smeared joint\nmeasurement. The bound is obtained by introducing an entropic error function,\nand optimizing it over a suitable class of covariant approximate joint\nmeasurements. We fully exploit two cases of target observables: (1)\n$n$-dimensional position and momentum vectors; (2) two components of position\nand momentum along different directions. In (1), we connect the quantum bound\nto the dimension $n$; in (2), going from parallel to orthogonal directions, we\nshow the transition from highly incompatible observables to compatible ones.\nFor simplicity, we develop the theory only for Gaussian states and\nmeasurements. \n\n"}
{"id": "1705.10198", "contents": "Title: Energy-Efficient Transponder Configuration for FMF-based Elastic Optical\n  Networks Abstract: We propose an energy-efficient procedure for transponder configuration in\nFMF-based elastic optical networks in which quality of service and physical\nconstraints are guaranteed and joint optimization of transmit optical power,\ntemporal, spatial and spectral variables are addressed. We use geometric\nconvexification techniques to provide convex representations for quality of\nservice, transponder power consumption and transponder configuration problem.\nSimulation results show that our convex formulation is considerably faster than\nits mixed-integer nonlinear counterpart and its ability to optimize transmit\noptical power reduces total transponder power consumption up to 32%. We also\nanalyze the effect of mode coupling and number of available modes on power\nconsumption of different network elements. \n\n"}
{"id": "1705.10407", "contents": "Title: Solving Almost all Systems of Random Quadratic Equations Abstract: This paper deals with finding an $n$-dimensional solution $x$ to a system of\nquadratic equations of the form $y_i=|\\langle{a}_i,x\\rangle|^2$ for $1\\le i \\le\nm$, which is also known as phase retrieval and is NP-hard in general. We put\nforth a novel procedure for minimizing the amplitude-based least-squares\nempirical loss, that starts with a weighted maximal correlation initialization\nobtainable with a few power or Lanczos iterations, followed by successive\nrefinements based upon a sequence of iteratively reweighted (generalized)\ngradient iterations. The two (both the initialization and gradient flow) stages\ndistinguish themselves from prior contributions by the inclusion of a fresh\n(re)weighting regularization technique. The overall algorithm is conceptually\nsimple, numerically scalable, and easy-to-implement. For certain random\nmeasurement models, the novel procedure is shown capable of finding the true\nsolution $x$ in time proportional to reading the data $\\{(a_i;y_i)\\}_{1\\le i\n\\le m}$. This holds with high probability and without extra assumption on the\nsignal $x$ to be recovered, provided that the number $m$ of equations is some\nconstant $c>0$ times the number $n$ of unknowns in the signal vector, namely,\n$m>cn$. Empirically, the upshots of this contribution are: i) (almost) $100\\%$\nperfect signal recovery in the high-dimensional (say e.g., $n\\ge 2,000$) regime\ngiven only an information-theoretic limit number of noiseless equations,\nnamely, $m=2n-1$ in the real-valued Gaussian case; and, ii) (nearly) optimal\nstatistical accuracy in the presence of additive noise of bounded support.\nFinally, substantial numerical tests using both synthetic data and real images\ncorroborate markedly improved signal recovery performance and computational\nefficiency of our novel procedure relative to state-of-the-art approaches. \n\n"}
{"id": "1706.00061", "contents": "Title: The Sample Complexity of Online One-Class Collaborative Filtering Abstract: We consider the online one-class collaborative filtering (CF) problem that\nconsists of recommending items to users over time in an online fashion based on\npositive ratings only. This problem arises when users respond only occasionally\nto a recommendation with a positive rating, and never with a negative one. We\nstudy the impact of the probability of a user responding to a recommendation,\np_f, on the sample complexity, i.e., the number of ratings required to make\n`good' recommendations, and ask whether receiving positive and negative\nratings, instead of positive ratings only, improves the sample complexity. Both\nquestions arise in the design of recommender systems. We introduce a simple\nprobabilistic user model, and analyze the performance of an online user-based\nCF algorithm. We prove that after an initial cold start phase, where\nrecommendations are invested in exploring the user's preferences, this\nalgorithm makes---up to a fraction of the recommendations required for updating\nthe user's preferences---perfect recommendations. The number of ratings\nrequired for the cold start phase is nearly proportional to 1/p_f, and that for\nupdating the user's preferences is essentially independent of p_f. As a\nconsequence we find that, receiving positive and negative ratings instead of\nonly positive ones improves the number of ratings required for initial\nexploration by a factor of 1/p_f, which can be significant. \n\n"}
{"id": "1706.00440", "contents": "Title: The conditional Entropy Power Inequality for bosonic quantum systems Abstract: We prove the conditional Entropy Power Inequality for Gaussian quantum\nsystems. This fundamental inequality determines the minimum quantum conditional\nvon Neumann entropy of the output of the beam-splitter or of the squeezing\namong all the input states where the two inputs are conditionally independent\ngiven the memory and have given quantum conditional entropies. We also prove\nthat, for any couple of values of the quantum conditional entropies of the two\ninputs, the minimum of the quantum conditional entropy of the output given by\nthe conditional Entropy Power Inequality is asymptotically achieved by a\nsuitable sequence of quantum Gaussian input states. Our proof of the\nconditional Entropy Power Inequality is based on a new Stam inequality for the\nquantum conditional Fisher information and on the determination of the\nuniversal asymptotic behaviour of the quantum conditional entropy under the\nheat semigroup evolution. The beam-splitter and the squeezing are the central\nelements of quantum optics, and can model the attenuation, the amplification\nand the noise of electromagnetic signals. This conditional Entropy Power\nInequality will have a strong impact in quantum information and quantum\ncryptography. Among its many possible applications there is the proof of a new\nuncertainty relation for the conditional Wehrl entropy. \n\n"}
{"id": "1706.02461", "contents": "Title: On neutrino production of a charmed meson Abstract: We calculate in the framework of the collinear QCD approach the amplitude for\nexclusive neutrino-production of a pseudoscalar charmed $D$ meson. This process\nallows to access gluon and both chiral-odd and chiral-even quark generalized\nparton distributions (GPDs), which contribute in specific ways to the amplitude\nfor different polarization states of the $W$ boson. The energy dependence of\nthe cross section allows to separate different contributions and the\nmeasurement of the azimuthal dependence helps to single out the transversity\nchiral-odd GPDs contributions. The flavor dependence, and in particular the\ndifference between $D^+$ and $D^0$ production rates, allows to test the\nimportance of gluonic contributions. The behaviour of the proton and neutron\ntarget cross sections enables to separate the $u$ and $d$ quark contributions.\nPlanned medium and high energy neutrino facilities will thus allow some\nimportant progress in the realm of hadronic physics. \n\n"}
{"id": "1706.03342", "contents": "Title: Explicit Lower Bounds on the Outage Probability of Integer Forcing over\n  Nrx2 Channels Abstract: The performance of integer-forcing equalization for communication over the\ncompound multiple-input multipleoutput channel is investigated. An upper bound\non the resulting outage probability as a function of the gap to capacity has\nbeen derived previously, assuming a random precoding matrix drawn from the\ncircular unitary ensemble is applied prior to transmission. In the present work\na simple and explicit lower bound on the worst-case outage probability is\nderived for the case of a system with two transmit antennas and two or more\nreceive antennas, leveraging the properties of the Jacobi ensemble. The derived\nlower bound is also extended to random space-time precoding, and may serve as a\nuseful benchmark for assessing the relative merits of various algebraic\nspace-time precoding schemes. We further show that the lower bound may be\nadapted to the case of a $1 \\times N_t$ system. As an application of this, we\nderive closed-form bounds for the symmetric-rate capacity of the Rayleigh\nfading multiple-access channel where all terminals are equipped with a single\nantenna. Lastly, we demonstrate that the integer-forcing equalization coupled\nwith distributed space-time coding is able to approach these bounds. \n\n"}
{"id": "1706.04295", "contents": "Title: Compressed Secret Key Agreement: Maximizing Multivariate Mutual\n  Information Per Bit Abstract: The multiterminal secret key agreement problem by public discussion is\nformulated with an additional source compression step where, prior to the\npublic discussion phase, users independently compress their private sources to\nfilter out strongly correlated components for generating a common secret key.\nThe objective is to maximize the achievable key rate as a function of the joint\nentropy of the compressed sources. Since the maximum achievable key rate\ncaptures the total amount of information mutual to the compressed sources, an\noptimal compression scheme essentially maximizes the multivariate mutual\ninformation per bit of randomness of the private sources, and can therefore be\nviewed more generally as a dimension reduction technique. Single-letter lower\nand upper bounds on the maximum achievable key rate are derived for the general\nsource model, and an explicit polynomial-time computable formula is obtained\nfor the pairwise independent network model. In particular, the converse results\nand the upper bounds are obtained from those of the related secret key\nagreement problem with rate-limited discussion. A precise duality is shown for\nthe two-user case with one-way discussion, and such duality is extended to\nobtain the desired converse results in the multi-user case. In addition to\nposing new challenges in information processing and dimension reduction, the\ncompressed secret key agreement problem helps shed new light on resolving the\ndifficult problem of secret key agreement with rate-limited discussion, by\noffering a more structured achieving scheme and some simpler conjectures to\nprove. \n\n"}
{"id": "1706.04635", "contents": "Title: Information Potential Auto-Encoders Abstract: In this paper, we suggest a framework to make use of mutual information as a\nregularization criterion to train Auto-Encoders (AEs). In the proposed\nframework, AEs are regularized by minimization of the mutual information\nbetween input and encoding variables of AEs during the training phase. In order\nto estimate the entropy of the encoding variables and the mutual information,\nwe propose a non-parametric method. We also give an information theoretic view\nof Variational AEs (VAEs), which suggests that VAEs can be considered as\nparametric methods that estimate entropy. Experimental results show that the\nproposed non-parametric models have more degree of freedom in terms of\nrepresentation learning of features drawn from complex distributions such as\nMixture of Gaussians, compared to methods which estimate entropy using\nparametric approaches, such as Variational AEs. \n\n"}
{"id": "1706.06549", "contents": "Title: Inference in Deep Networks in High Dimensions Abstract: Deep generative networks provide a powerful tool for modeling complex data in\na wide range of applications. In inverse problems that use these networks as\ngenerative priors on data, one must often perform inference of the inputs of\nthe networks from the outputs. Inference is also required for sampling during\nstochastic training on these generative models. This paper considers inference\nin a deep stochastic neural network where the parameters (e.g., weights, biases\nand activation functions) are known and the problem is to estimate the values\nof the input and hidden units from the output. While several approximate\nalgorithms have been proposed for this task, there are few analytic tools that\ncan provide rigorous guarantees in the reconstruction error. This work presents\na novel and computationally tractable output-to-input inference method called\nMulti-Layer Vector Approximate Message Passing (ML-VAMP). The proposed\nalgorithm, derived from expectation propagation, extends earlier AMP methods\nthat are known to achieve the replica predictions for optimality in simple\nlinear inverse problems. Our main contribution shows that the mean-squared\nerror (MSE) of ML-VAMP can be exactly predicted in a certain large system limit\n(LSL) where the numbers of layers is fixed and weight matrices are random and\northogonally-invariant with dimensions that grow to infinity. ML-VAMP is thus a\nprincipled method for output-to-input inference in deep networks with a\nrigorous and precise performance achievability result in high dimensions. \n\n"}
{"id": "1706.07582", "contents": "Title: Fundamental Limits of Universal Variable-to-Fixed Length Coding of\n  Parametric Sources Abstract: Universal variable-to-fixed (V-F) length coding of $d$-dimensional\nexponential family of distributions is considered. We propose an achievable\nscheme consisting of a dictionary, used to parse the source output stream,\nmaking use of the previously-introduced notion of quantized types. The\nquantized type class of a sequence is based on partitioning the space of\nminimal sufficient statistics into cuboids. Our proposed dictionary consists of\nsequences in the boundaries of transition from low to high quantized type class\nsize. We derive the asymptotics of the $\\epsilon$-coding rate of our coding\nscheme for large enough dictionaries. In particular, we show that the\nthird-order coding rate of our scheme is $H\\frac{d}{2}\\frac{\\log\\log M}{\\log\nM}$, where $H$ is the entropy of the source and $M$ is the dictionary size. We\nfurther provide a converse, showing that this rate is optimal up to the\nthird-order term. \n\n"}
{"id": "1706.10198", "contents": "Title: Modern Random Access for Satellite Communications Abstract: The present PhD dissertation focuses on modern random access (RA) techniques.\nIn the first part an slot- and frame-asynchronous RA scheme adopting replicas,\nsuccessive interference cancellation and combining techniques is presented and\nits performance analysed. The comparison of both slot-synchronous and\nasynchronous RA at higher layer, follows. Next, the optimization procedure, for\nslot-synchronous RA with irregular repetitions, is extended to the Rayleigh\nblock fading channel. Finally, random access with multiple receivers is\nconsidered. \n\n"}
{"id": "1707.00324", "contents": "Title: Efficient Spectrum Availability Information Recovery for Wideband DSA\n  Networks: A Weighted Compressive Sampling Approach Abstract: Compressive sampling has great potential for making wideband spectrum sensing\npossible at sub-Nyquist sampling rates. As a result, there have recently been\nresearch efforts that leverage compressive sampling to enable efficient\nwideband spectrum sensing. These efforts consider homogenous wideband spectrum,\nwhere all bands are assumed to have similar PU traffic characteristics. In\npractice, however, wideband spectrum is not homogeneous, in that different\nspectrum bands could present different PU occupancy patterns. In fact, the\nnature of spectrum assignment, in which applications of similar types are often\nassigned bands within the same block, dictates that wideband spectrum is indeed\nheterogeneous. In this paper, we consider heterogeneous wideband spectrum, and\nexploit its inherent, block-like structure to design efficient compressive\nspectrum sensing techniques that are well suited for heterogeneous wideband\nspectrum. We propose a weighted $\\ell_1-$minimization sensing information\nrecovery algorithm that achieves more stable recovery than that achieved by\nexisting approaches while accounting for the variations of spectrum occupancy\nacross both the time and frequency dimensions. In addition, we show that our\nproposed algorithm requires a lesser number of sensing measurements when\ncompared to the state-of-the-art approaches. \n\n"}
{"id": "1707.00475", "contents": "Title: Reconstruction Error Bounds for Compressed Sensing under Poisson or\n  Poisson-Gaussian Noise Using Variance Stabilization Transforms Abstract: Most existing bounds for signal reconstruction from compressive measurements\nmake the assumption of additive signal-independent noise. However in many\ncompressive imaging systems, the noise statistics are more accurately\nrepresented by Poisson or Poisson-Gaussian noise models. In this paper, we\nderive upper bounds for signal reconstruction error from compressive\nmeasurements which are corrupted by Poisson or Poisson-Gaussian noise. The\nfeatures of our bounds are as follows: (1) The bounds are derived for a\nprobabilistically motivated, computationally tractable convex estimator with\nprincipled parameter selection. The estimator penalizes signal sparsity subject\nto a constraint that imposes an upper bound on a term based on variance\nstabilization transforms to approximate the Poisson or Poisson-Gaussian\nnegative log-likelihoods. (2) They are applicable to signals that are sparse as\nwell as compressible in any orthonormal basis, and are derived for compressive\nsystems obeying realistic constraints such as non-negativity and\nflux-preservation. We present extensive numerical results for signal\nreconstruction under varying number of measurements and varying signal\nintensity levels. \n\n"}
{"id": "1707.00810", "contents": "Title: R\\'enyi Resolvability and Its Applications to the Wiretap Channel Abstract: The conventional channel resolvability problem refers to the determination of\nthe minimum rate required for an input process so that the output distribution\napproximates a target distribution in either the total variation distance or\nthe relative entropy. In contrast to previous works, in this paper, we use the\n(normalized or unnormalized) R\\'enyi divergence (with the R\\'enyi parameter in\n$[0,2]\\cup\\{\\infty\\}$) to measure the level of approximation. We also provide\nasymptotic expressions for normalized R\\'enyi divergence when the R\\'enyi\nparameter is larger than or equal to $1$ as well as (lower and upper) bounds\nfor the case when the same parameter is smaller than $1$. We characterize the\nR\\'enyi resolvability, which is defined as the minimum rate required to ensure\nthat the R\\'enyi divergence vanishes asymptotically. The R\\'enyi\nresolvabilities are the same for both the normalized and unnormalized\ndivergence cases. In addition, when the R\\'enyi parameter smaller than~$1$,\nconsistent with the traditional case where the R\\'enyi parameter is equal\nto~$1$, the R\\'enyi resolvability equals the minimum mutual information over\nall input distributions that induce the target output distribution. When the\nR\\'enyi parameter is larger than $1$ the R\\'enyi resolvability is, in general,\nlarger than the mutual information. The optimal R\\'enyi divergence is proven to\nvanish at least exponentially fast for both of these two cases, as long as the\ncode rate is larger than the R\\'enyi resolvability. The optimal exponential\nrate of decay for i.i.d.\\ random codes is also characterized exactly. We apply\nthese results to the wiretap channel, and completely characterize the optimal\ntradeoff between the rates of the secret and non-secret messages when the\nleakage measure is given by the (unnormalized) R\\'enyi divergence. \n\n"}
{"id": "1707.02409", "contents": "Title: Estimation Efficiency Under Privacy Constraints Abstract: We investigate the problem of estimating a random variable $Y\\in \\mathcal{Y}$\nunder a privacy constraint dictated by another random variable $X\\in\n\\mathcal{X}$, where estimation efficiency and privacy are assessed in terms of\ntwo different loss functions. In the discrete case, we use the Hamming loss\nfunction and express the corresponding utility-privacy tradeoff in terms of the\nprivacy-constrained guessing probability $h(P_{XY}, \\epsilon)$, the maximum\nprobability $\\mathsf{P}_\\mathsf{c}(Y|Z)$ of correctly guessing $Y$ given an\nauxiliary random variable $Z\\in \\mathcal{Z}$, where the maximization is taken\nover all $P_{Z|Y}$ ensuring that $\\mathsf{P}_\\mathsf{c}(X|Z)\\leq \\epsilon$ for\na given privacy threshold $\\epsilon \\geq 0$. We prove that $h(P_{XY}, \\cdot)$\nis concave and piecewise linear, which allows us to derive its expression in\nclosed form for any $\\epsilon$ when $X$ and $Y$ are binary. In the non-binary\ncase, we derive $h(P_{XY}, \\epsilon)$ in the high utility regime (i.e., for\nsufficiently large values of $\\epsilon$) under the assumption that $Z$ takes\nvalues in $\\mathcal{Y}$. We also analyze the privacy-constrained guessing\nprobability for two binary vector scenarios. When $X$ and $Y$ are continuous\nrandom variables, we use the squared-error loss function and express the\ncorresponding utility-privacy tradeoff in terms of $\\mathsf{sENSR}(P_{XY},\n\\epsilon)$, which is the smallest normalized minimum mean squared-error (mmse)\nincurred in estimating $Y$ from its Gaussian perturbation $Z$, such that the\nmmse of $f(X)$ given $Z$ is within $\\epsilon$ of the variance of $f(X)$ for any\nnon-constant real-valued function $f$. We derive tight upper and lower bounds\nfor $\\mathsf{sENSR}$ when $Y$ is Gaussian. We also obtain a tight lower bound\nfor $\\mathsf{sENSR}(P_{XY}, \\epsilon)$ for general absolutely continuous random\nvariables when $\\epsilon$ is sufficiently small. \n\n"}
{"id": "1707.03384", "contents": "Title: Deep Learning-Based Communication Over the Air Abstract: End-to-end learning of communications systems is a fascinating novel concept\nthat has so far only been validated by simulations for block-based\ntransmissions. It allows learning of transmitter and receiver implementations\nas deep neural networks (NNs) that are optimized for an arbitrary\ndifferentiable end-to-end performance metric, e.g., block error rate (BLER). In\nthis paper, we demonstrate that over-the-air transmissions are possible: We\nbuild, train, and run a complete communications system solely composed of NNs\nusing unsynchronized off-the-shelf software-defined radios (SDRs) and\nopen-source deep learning (DL) software libraries. We extend the existing ideas\ntowards continuous data transmission which eases their current restriction to\nshort block lengths but also entails the issue of receiver synchronization. We\novercome this problem by introducing a frame synchronization module based on\nanother NN. A comparison of the BLER performance of the \"learned\" system with\nthat of a practical baseline shows competitive performance close to 1 dB, even\nwithout extensive hyperparameter tuning. We identify several practical\nchallenges of training such a system over actual channels, in particular the\nmissing channel gradient, and propose a two-step learning procedure based on\nthe idea of transfer learning that circumvents this issue. \n\n"}
{"id": "1707.03495", "contents": "Title: Lengthening and Extending Binary Private Information Retrieval Codes Abstract: It was recently shown by Fazeli et al. that the storage overhead of a\ntraditional $t$-server private information retrieval (PIR) protocol can be\nsignificantly reduced using the concept of a $t$-server PIR code. In this work,\nwe show that a family of $t$-server PIR codes (with increasing dimensions and\nblocklengths) can be constructed from an existing $t$-server PIR code through\nlengthening by a single information symbol and code extension by at most\n$\\bigl\\lceil t/2\\bigr\\rceil$ code symbols. Furthermore, by extending a code\nconstruction notion from Steiner systems by Fazeli et al., we obtain a specific\nfamily of $t$-server PIR codes. Based on a code construction technique that\nlengthens and extends a $t$-server PIR code simultaneously, a basic algorithm\nto find good (i.e., small blocklength) $t$-server PIR codes is proposed. For\nthe special case of $t=5$, we find provably optimal PIR codes for code\ndimensions $k\\leq 6$, while for all $7\\leq k\\leq 32$ we find codes of smaller\nblocklength than the best known codes from the literature. Furthermore, in the\ncase of $t = 8$, we also find better codes for $k = 5, 6, 11, 12$. Numerical\nresults show that most of the best found $5$-server PIR codes can be\nconstructed from the proposed family of codes connected to Steiner systems. \n\n"}
{"id": "1707.03858", "contents": "Title: Gradient Coding from Cyclic MDS Codes and Expander Graphs Abstract: Gradient coding is a technique for straggler mitigation in distributed\nlearning. In this paper we design novel gradient codes using tools from\nclassical coding theory, namely, cyclic MDS codes, which compare favorably with\nexisting solutions, both in the applicable range of parameters and in the\ncomplexity of the involved algorithms. Second, we introduce an approximate\nvariant of the gradient coding problem, in which we settle for approximate\ngradient computation instead of the exact one. This approach enables graceful\ndegradation, i.e., the $\\ell_2$ error of the approximate gradient is a\ndecreasing function of the number of stragglers. Our main result is that\nnormalized adjacency matrices of expander graphs yield excellent approximate\ngradient codes, which enable significantly less computation compared to exact\ngradient coding, and guarantee faster convergence than trivial solutions under\nstandard assumptions. We experimentally test our approach on Amazon EC2, and\nshow that the generalization error of approximate gradient coding is very close\nto the full gradient while requiring significantly less computation from the\nworkers. \n\n"}
{"id": "1707.05697", "contents": "Title: An Iterative BP-CNN Architecture for Channel Decoding Abstract: Inspired by recent advances in deep learning, we propose a novel iterative\nBP-CNN architecture for channel decoding under correlated noise. This\narchitecture concatenates a trained convolutional neural network (CNN) with a\nstandard belief-propagation (BP) decoder. The standard BP decoder is used to\nestimate the coded bits, followed by a CNN to remove the estimation errors of\nthe BP decoder and obtain a more accurate estimation of the channel noise.\nIterating between BP and CNN will gradually improve the decoding SNR and hence\nresult in better decoding performance. To train a well-behaved CNN model, we\ndefine a new loss function which involves not only the accuracy of the noise\nestimation but also the normality test for the estimation errors, i.e., to\nmeasure how likely the estimation errors follow a Gaussian distribution. The\nintroduction of the normality test to the CNN training shapes the residual\nnoise distribution and further reduces the BER of the iterative decoding,\ncompared to using the standard quadratic loss function. We carry out extensive\nexperiments to analyze and verify the proposed framework. The iterative BP-CNN\ndecoder has better BER performance with lower complexity, is suitable for\nparallel implementation, does not rely on any specific channel model or\nencoding method, and is robust against training mismatches. All of these\nfeatures make it a good candidate for decoding modern channel codes. \n\n"}
{"id": "1707.05920", "contents": "Title: Elastic $\\alpha$-$^{12}$C scattering at low energies with the bound\n  states of $^{16}$O in effective field theory Abstract: The elastic $\\alpha$-$^{12}$C scattering for $l=0,1,2,3$ channels at low\nenergies is studied, including the energies of excited bound states of\n$^{16}$O, in effective field theory. We introduce a new renormalization method\ndue to the large suppression factor produced by the Coulomb interaction when\nfitting the effective range parameters to the phase sift data. After fitting\nthe parameters, we calculate asymptotic normalization constants of the $0_2^+$,\n$1_1^-$, $2_1^+$, $3_1^-$ states of $^{16}$O. We also discuss the uncertainties\nof the present study when the amplitudes are interpolated to the stellar energy\nregion of the $^{12}$C($\\alpha$,$\\gamma$)$^{16}$O reaction. \n\n"}
{"id": "1707.07234", "contents": "Title: A Covert Queueing Channel in FCFS Schedulers Abstract: We study covert queueing channels (CQCs), which are a kind of covert timing\nchannel that may be exploited in shared queues across supposedly isolated\nusers. In our system model, a user sends messages to another user via his\npattern of access to the shared resource, which serves the users according to a\nfirst come first served (FCFS) policy. One example of such a channel is the\ncross-virtual network covert channel in data center networks, resulting from\nthe queueing effects of the shared resource. First, we study a system\ncomprising a transmitter and a receiver that share a deterministic and\nwork-conserving FCFS scheduler, and we compute the capacity of this channel. We\nalso consider the effect of the presence of other users on the information\ntransmission rate of this channel. The achievable information transmission\nrates obtained in this study demonstrate the possibility of significant\ninformation leakage and great privacy threats brought by CQCs in FCFS\nschedulers. \n\n"}
{"id": "1707.09613", "contents": "Title: Sparse Vector Recovery: Bernoulli-Gaussian Message Passing Abstract: Low-cost message passing (MP) algorithm has been recognized as a promising\ntechnique for sparse vector recovery. However, the existing MP algorithms\neither focus on mean square error (MSE) of the value recovery while ignoring\nthe sparsity requirement, or support error rate (SER) of the sparse support\n(non-zero position) recovery while ignoring its value. A novel low-complexity\nBernoulli-Gaussian MP (BGMP) is proposed to perform the value recovery as well\nas the support recovery. Particularly, in the proposed BGMP, support-related\nBernoulli messages and value-related Gaussian messages are jointly processed\nand assist each other. In addition, a strict lower bound is developed for the\nMSE of BGMP via the genie-aided minimum mean-square-error (GA-MMSE) method. The\nGA-MMSE lower bound is shown to be tight in high signal-to-noise ratio.\nNumerical results are provided to verify the advantage of BGMP in terms of\nfinal MSE, SER and convergence speed. \n\n"}
{"id": "1708.03355", "contents": "Title: Fundamental Limits of PhaseMax for Phase Retrieval: A Replica Analysis Abstract: We consider a recently proposed convex formulation, known as the PhaseMax\nmethod, for solving the phase retrieval problem. Using the replica method from\nstatistical mechanics, we analyze the performance of PhaseMax in the\nhigh-dimensional limit. Our analysis predicts the \\emph{exact} asymptotic\nperformance of PhaseMax. In particular, we show that a sharp phase transition\nphenomenon takes place, with a simple analytical formula characterizing the\nphase transition boundary. This result shows that the oversampling ratio\nrequired by existing performance bounds in the literature can be significantly\nreduced. Numerical results confirm the validity of our replica analysis,\nshowing that the theoretical predictions are in excellent agreement with the\nactual performance of the algorithm, even for moderate signal dimensions. \n\n"}
{"id": "1708.05198", "contents": "Title: Hypothesis Testing Over the Two-hop Relay Network Abstract: Coding and testing schemes and the corresponding achievable type-II error\nexponents are presented for binary hypothesis testing over two-hop relay\nnetworks. The schemes are based on cascade source coding techniques and\n{unanimous decision-forwarding}, the latter meaning that a terminal decides on\nthe null hypothesis only if all previous terminals have decided on the null\nhypothesis. If the observations at the transmitter, the relay, and the receiver\nform a Markov chain in this order, then, without loss in performance, the\nproposed cascade source code can be replaced by two independent point-to-point\nsource codes, one for each hop. The decoupled scheme (combined with\ndecision-forwarding) is shown to attain the optimal type-II error exponents for\nvarious instances of \"testing against conditional independence.\" The same\ndecoupling is shown to be optimal also for some instances of \"testing against\nindependence,\" when the observations at the transmitter, the receiver, and the\nrelay form a Markov chain in this order, and when the relay-to-receiver link is\nof sufficiently high rate. For completeness, the paper also presents an\nanalysis of the Shimokawa-Han-Amari binning scheme for the point-to-point\nhypothesis testing setup. \n\n"}
{"id": "1708.05474", "contents": "Title: The Storage vs Repair Bandwidth Trade-off for Multiple Failures in\n  Clustered Storage Networks Abstract: We study the trade-off between storage overhead and inter-cluster repair\nbandwidth in clustered storage systems, while recovering from multiple node\nfailures within a cluster. A cluster is a collection of $m$ nodes, and there\nare $n$ clusters. For data collection, we download the entire content from any\n$k$ clusters. For repair of $t \\geq 2$ nodes within a cluster, we take help\nfrom $\\ell$ local nodes, as well as $d$ helper clusters. We characterize the\noptimal trade-off under functional repair, and also under exact repair for the\nminimum storage and minimum inter-cluster bandwidth (MBR) operating points. Our\nbounds show the following interesting facts: $1)$ When $t|(m-\\ell)$ the\ntrade-off is the same as that under $t=1$, and thus there is no advantage in\njointly repairing multiple nodes, $2)$ When $t \\nmid (m-\\ell)$, the optimal\nfile-size at the MBR point under exact repair can be strictly less than that\nunder functional repair. $3)$ Unlike the case of $t=1$, increasing the number\nof local helper nodes does not necessarily increase the system capacity under\nfunctional repair. \n\n"}
{"id": "1708.05496", "contents": "Title: Non-Asymptotic Converse Bounds and Refined Asymptotics for Two Lossy\n  Source Coding Problems Abstract: In this paper, we revisit two multi-terminal lossy source coding problems:\nthe lossy source coding problem with side information available at the encoder\nand one of the two decoders, which we term as the Kaspi problem (Kaspi, 1994),\nand the multiple description coding problem with one semi-deterministic\ndistortion measure, which we refer to as the Fu-Yeung problem (Fu and Yeung,\n2002). For the Kaspi problem, we first present the properties of optimal test\nchannels. Subsequently, we generalize the notion of the distortion-tilted\ninformation density for the lossy source coding problem to the Kaspi problem\nand prove a non-asymptotic converse bound using the properties of optimal test\nchannels and the well-defined distortion-tilted information density. Finally,\nfor discrete memoryless sources, we derive refined asymptotics which includes\nthe second-order, large and moderate deviations asymptotics. In the converse\nproof of second-order asymptotics, we apply the Berry-Esseen theorem to the\nderived non-asymptotic converse bound. The achievability proof follows by first\nproving a type-covering lemma tailored to the Kaspi problem, then properly\nTaylor expanding the well-defined distortion-tilted information densities and\nfinally applying the Berry-Esseen theorem. We then generalize the methods used\nin the Kaspi problem to the Fu-Yeung problem. As a result, we obtain the\nproperties of optimal test channels for the minimum sum-rate function, a\nnon-asymptotic converse bound and refined asymptotics for discrete memoryless\nsources. Since the successive refinement problem is a special case of the\nFu-Yeung problem, as a by-product, we obtain a non-asymptotic converse bound\nfor the successive refinement problem, which is a strict generalization of the\nnon-asymptotic converse bound for successively refinable sources (Zhou, Tan and\nMotani, 2017). \n\n"}
{"id": "1708.05932", "contents": "Title: Fundamental Limits of Weak Recovery with Applications to Phase Retrieval Abstract: In phase retrieval we want to recover an unknown signal $\\boldsymbol\nx\\in\\mathbb C^d$ from $n$ quadratic measurements of the form $y_i =\n|\\langle{\\boldsymbol a}_i,{\\boldsymbol x}\\rangle|^2+w_i$ where $\\boldsymbol\na_i\\in \\mathbb C^d$ are known sensing vectors and $w_i$ is measurement noise.\nWe ask the following weak recovery question: what is the minimum number of\nmeasurements $n$ needed to produce an estimator $\\hat{\\boldsymbol\nx}(\\boldsymbol y)$ that is positively correlated with the signal $\\boldsymbol\nx$? We consider the case of Gaussian vectors $\\boldsymbol a_i$. We prove that -\nin the high-dimensional limit - a sharp phase transition takes place, and we\nlocate the threshold in the regime of vanishingly small noise. For $n\\le\nd-o(d)$ no estimator can do significantly better than random and achieve a\nstrictly positive correlation. For $n\\ge d+o(d)$ a simple spectral estimator\nachieves a positive correlation. Surprisingly, numerical simulations with the\nsame spectral estimator demonstrate promising performance with realistic\nsensing matrices. Spectral methods are used to initialize non-convex\noptimization algorithms in phase retrieval, and our approach can boost the\nperformance in this setting as well.\n  Our impossibility result is based on classical information-theory arguments.\nThe spectral algorithm computes the leading eigenvector of a weighted empirical\ncovariance matrix. We obtain a sharp characterization of the spectral\nproperties of this random matrix using tools from free probability and\ngeneralizing a recent result by Lu and Li. Both the upper and lower bound\ngeneralize beyond phase retrieval to measurements $y_i$ produced according to a\ngeneralized linear model. As a byproduct of our analysis, we compare the\nthreshold of the proposed spectral method with that of a message passing\nalgorithm. \n\n"}
{"id": "1708.06513", "contents": "Title: Simplified Cooperative Detection for Multi-Receiver Molecular\n  Communication Abstract: Diffusion-based molecular communication (MC) systems experience significant\nreliability losses. To boost the reliability, an MC scheme where multiple\nreceivers (RXs) work cooperatively to decide the signal of a transmitter (TX)\nby sending the same type of molecules to a fusion center (FC) is proposed in\nthis paper. The FC observes the total number of molecules received and compares\nthis number with a threshold to determine the TX's signal. The proposed scheme\nis more bio-realistic and requires relatively low computational complexity\ncompared to existing cooperative schemes where the RXs send and the FC\nrecognizes different types of molecules. Asymmetric and symmetric topologies\nare considered, and closed-form expressions are derived for the global error\nprobability for both topologies. Results show that the trade-off for simplified\ncomputations leads to a slight reduction in error performance, compared to the\nexisting cooperative schemes. \n\n"}
{"id": "1708.06959", "contents": "Title: Adaptive Linear Programming Decoding of Nonbinary Linear Codes Over\n  Prime Fields Abstract: In this work, we consider adaptive linear programming (ALP) decoding of\nlinear codes over the finite field $\\mathbb{F}_p$ of size $p$ where $p$ is a\nprime. In particular, we provide a general construction of valid inequalities\nfor the codeword polytope of the so-called constant-weight embedding of a\nsingle parity-check (SPC) code over any prime field. The construction is based\non classes of building blocks that are assembled to form the left-hand side of\nan inequality according to several rules. In the case of almost\ndoubly-symmetric valid classes we prove that the resulting inequalities are all\nfacet-defining, while we conjecture this to be true if and only if the class is\nvalid and symmetric. For $p=3$, there is only a single valid symmetric class\nand we prove that the resulting inequalities together with the so-called\nsimplex constraints give a completely and irredundant description of the\ncodeword polytope of the embedded SPC code. For $p>5$, we show that there are\nadditional facets beyond those from the proposed construction. We use these\ninequalities to develop an efficient (relaxed) ALP decoder for general\n(non-SPC) linear codes over prime fields. The key ingredient is an efficient\nseparation algorithm based on the principle of dynamic programming.\nFurthermore, we construct a decoder for linear codes over arbitrary fields\n$\\mathbb{F}_q$ with $q=p^m$ and $m>1$ by a factor graph representation that\nreduces to several instances of the case $m=1$, which results, in general, in a\nrelaxation of the original decoding polytope. Finally, we present an efficient\ncut-generating algorithm to search for redundant parity-checks to further\nimprove the performance towards maximum-likelihood decoding for short-to-medium\nblock lengths. Numerical experiments confirm that our new decoder is very\nefficient compared to a static LP decoder for various field sizes, check-node\ndegrees, and block lengths. \n\n"}
{"id": "1708.07132", "contents": "Title: Beam-Energy Dependence of Directed Flow of $\\Lambda$, $\\bar{\\Lambda}$,\n  $K^\\pm$, $K^0_s$ and $\\phi$ in Au+Au Collisions Abstract: Rapidity-odd directed flow measurements at midrapidity are presented for\n$\\Lambda$, $\\bar{\\Lambda}$, $K^\\pm$, $K^0_s$ and $\\phi$ at $\\sqrt{s_{NN}} =$\n7.7, 11.5, 14.5, 19.6, 27, 39, 62.4 and 200 GeV in Au+Au collisions recorded by\nthe STAR detector at the Relativistic Heavy Ion Collider. These measurements\ngreatly expand the scope of data available to constrain models with differing\nprescriptions for the equation of state of quantum chromodynamics. Results show\ngood sensitivity for testing a picture where flow is assumed to be imposed\nbefore hadron formation and the observed particles are assumed to form via\ncoalescence of constituent quarks. The pattern of departure from a\ncoalescence-inspired sum-rule can be a valuable new tool for probing the\ncollision dynamics. \n\n"}
{"id": "1708.08157", "contents": "Title: Characteristic and Universal Tensor Product Kernels Abstract: Maximum mean discrepancy (MMD), also called energy distance or N-distance in\nstatistics and Hilbert-Schmidt independence criterion (HSIC), specifically\ndistance covariance in statistics, are among the most popular and successful\napproaches to quantify the difference and independence of random variables,\nrespectively. Thanks to their kernel-based foundations, MMD and HSIC are\napplicable on a wide variety of domains. Despite their tremendous success,\nquite little is known about when HSIC characterizes independence and when MMD\nwith tensor product kernel can discriminate probability distributions. In this\npaper, we answer these questions by studying various notions of characteristic\nproperty of the tensor product kernel. \n\n"}
{"id": "1708.09117", "contents": "Title: Cache-Aided Interference Management in Partially Connected Linear\n  Networks Abstract: This paper studies caching in (K+L-1) x K partially connected wireless linear\nnetworks, where each of the K receivers locally communicates with L out of the\nK+L-1 transmitters, and caches are at all nodes. The goal is to design caching\nand delivery schemes to reduce the transmission latency, by using normalized\ndelivery time (NDT) as the performance metric. For small transmitter cache size\n(any L transmitters can collectively store the database just once), we propose\na cyclic caching strategy so that each of every L consecutive transmitters\ncaches a distinct part of each file; the delivery strategy exploits coded\nmulticasting and interference alignment by introducing virtual receivers. The\nobtained NDT is within a multiplicative gap of 2 to the optimum in the entire\ncache size region, and optimal in certain region. For large transmitter cache\nsize (any L transmitters can collectively store the database for multiple\ncopies), we propose a modified caching strategy so that every bit is repeatedly\ncached at consecutive transmitters; the delivery strategy exploits\nself-interference cancellation and interference neutralization. By combining\nthese schemes, the NDT is optimal in a larger region. We also extend our\nresults to linear networks with heterogeneous receiver connectivity and\npartially connected circular networks. \n\n"}
{"id": "1708.09574", "contents": "Title: Differential cross section and photon beam asymmetry for the gamma p ->\n  pi+ n reaction at forward pi+ angles at Egamma=1.5-2.95 GeV Abstract: Differential cross sections and photon beam asymmetries for the gamma p ->\npi+ n reaction have been measured for 0.6<cos(theta)<1 and Egamma=1.5-2.95 GeV\nat SPring-8/LEPS. The cross sections monotonically decrease as the photon beam\nenergy increases for 0.6<cos(theta)<0.9. However, the energy dependence of the\ncross sections for 0.9<cos(theta)<1 and Egamma=1.5-2.2 GeV (W=1.9-2.2 GeV) is\ndifferent, which may be due to a nucleon or Delta resonance. The present cross\nsections agree well with the previous cross sections measured by other groups\nand show forward peaking, suggesting significant t-channel contributions in\nthis kinematical region. The asymmetries are found to be positive, which can be\nexplained by rho-exchange in the t-channel. Large positive asymmetries in the\nsmall |t| region, where the rho-exchange contribution becomes small, could be\nexplained by introducing pi-exchange interference with the s-channel. \n\n"}
{"id": "1709.00112", "contents": "Title: Private Information Retrieval with Side Information Abstract: We study the problem of Private Information Retrieval (PIR) in the presence\nof prior side information. The problem setup includes a database of $K$\nindependent messages possibly replicated on several servers, and a user that\nneeds to retrieve one of these messages. In addition, the user has some prior\nside information in the form of a subset of $M$ messages, not containing the\ndesired message and unknown to the servers. This problem is motivated by\npractical settings in which the user can obtain side information\nopportunistically from other users or has previously downloaded some messages\nusing classical PIR schemes. The objective of the user is to retrieve the\nrequired message without revealing its identity while minimizing the amount of\ndata downloaded from the servers.\n  We focus on achieving information-theoretic privacy in two scenarios: (i) the\nuser wants to protect jointly its demand and side information; (ii) the user\nwants to protect only the information about its demand, but not the side\ninformation. To highlight the role of side information, we focus first on the\ncase of a single server (single database). In the first scenario, we prove that\nthe minimum download cost is $K-M$ messages, and in the second scenario it is\n$\\lceil \\frac{K}{M+1}\\rceil$ messages, which should be compared to $K$\nmessages, the minimum download cost in the case of no side information. Then,\nwe extend some of our results to the case of the database replicated on\nmultiple servers. Our proof techniques relate PIR with side information to the\nindex coding problem. We leverage this connection to prove converse results, as\nwell as to design achievability schemes. \n\n"}
{"id": "1709.00664", "contents": "Title: Analysis and Optimization of Probabilistic Caching in Multi-Antenna\n  Small-Cell Networks Abstract: Previous works on cache-enabled small-cell networks (SCNs) with probabilistic\ncaching often assume that each user is connected to the nearest small base\nstation (SBS) among all that have cached its desired content. The user may,\nhowever, suffer strong interference from other SBSs which do not cache the\ndesired content but are geographically closer. In this work, we investigate\nthis issue by deploying multiple antennas at each SBS. We first propose a\nuser-centric SBS clustering model where each user chooses its serving SBS only\nfrom a cluster of $K$ nearest SBSs with $K$ being a fixed cluster size. Two\nbeamforming schemes are considered. One is coordinated beamforming, where each\nSBS uses zero-forcing (ZF) beamformer to null out the interference within the\ncoordination cluster. The other is uncoordinated beamforming, where each SBS\nsimply applies matched-filter (MF) beamformer. Using tools from stochastic\ngeometry, we obtain tractable expressions for the successful transmission\nprobability (STP) of a typical user for both cases in the high signal-to-noise\nratio (SNR) region. Tight approximations in closed-form expressions are also\nobtained. We then formulate and solve the optimal probabilistic caching problem\nto maximize the STP. Numerical results reveal interesting insights on the\nchoices of ZF and MF beamforming in multi-antenna cache-enabled SCNs. \n\n"}
{"id": "1709.00779", "contents": "Title: Directional Cell Search Delay Analysis for Cellular Networks with Static\n  Users Abstract: Cell search is the process for a user to detect its neighboring base stations\n(BSs) and make a cell selection decision. Due to the importance of beamforming\ngain in millimeter wave (mmWave) and massive MIMO cellular networks, the\ndirectional cell search delay performance is investigated. A cellular network\nwith fixed BS and user locations is considered, so that strong temporal\ncorrelations exist for the SINR experienced at each BS and user. For Poisson\ncellular networks with Rayleigh fading channels, a closed-form expression for\nthe spatially averaged mean cell search delay of all users is derived. This\nmean cell search delay for a noise-limited network (e.g., mmWave network) is\nproved to be infinite whenever the non-line-of-sight (NLOS) path loss exponent\nis larger than 2. For interference-limited networks, a phase transition for the\nmean cell search delay is shown to exist in terms of the number of BS\nantennas/beams $M$: the mean cell search delay is infinite when $M$ is smaller\nthan a threshold and finite otherwise. Beam-sweeping is also demonstrated to be\neffective in decreasing the cell search delay, especially for the cell edge\nusers. \n\n"}
{"id": "1709.01447", "contents": "Title: Conditional independence testing based on a nearest-neighbor estimator\n  of conditional mutual information Abstract: Conditional independence testing is a fundamental problem underlying causal\ndiscovery and a particularly challenging task in the presence of nonlinear and\nhigh-dimensional dependencies. Here a fully non-parametric test for continuous\ndata based on conditional mutual information combined with a local permutation\nscheme is presented. Through a nearest neighbor approach, the test efficiently\nadapts also to non-smooth distributions due to strongly nonlinear dependencies.\nNumerical experiments demonstrate that the test reliably simulates the null\ndistribution even for small sample sizes and with high-dimensional conditioning\nsets. The test is better calibrated than kernel-based tests utilizing an\nanalytical approximation of the null distribution, especially for non-smooth\ndensities, and reaches the same or higher power levels. Combining the local\npermutation scheme with the kernel tests leads to better calibration, but\nsuffers in power. For smaller sample sizes and lower dimensions, the test is\nfaster than random fourier feature-based kernel tests if the permutation scheme\nis (embarrassingly) parallelized, but the runtime increases more sharply with\nsample size and dimensionality. Thus, more theoretical research to analytically\napproximate the null distribution and speed up the estimation for larger sample\nsizes is desirable. \n\n"}
{"id": "1709.02168", "contents": "Title: Wyner's Common Information under R\\'enyi Divergence Measures Abstract: We study a generalized version of Wyner's common information problem (also\ncoined the distributed source simulation problem). The original common\ninformation problem consists in understanding the minimum rate of the common\ninput to independent processors to generate an approximation of a joint\ndistribution when the distance measure used to quantify the discrepancy between\nthe synthesized and target distributions is the normalized relative entropy.\nOur generalization involves changing the distance measure to the unnormalized\nand normalized R\\'enyi divergences of order $\\alpha=1+s\\in[0,2]$. We show that\nthe minimum rate needed to ensure the R\\'enyi divergences between the\ndistribution induced by a code and the target distribution vanishes remains the\nsame as the one in Wyner's setting, except when the order $\\alpha=1+s=0$. This\nimplies that Wyner's common information is rather robust to the choice of\ndistance measure employed. As a byproduct of the proofs used to the establish\nthe above results, the exponential strong converse for the common information\nproblem under the total variation distance measure is established. \n\n"}
{"id": "1709.02497", "contents": "Title: Optimal-Dimensionality Sampling on the Sphere: Improvements and\n  Variations Abstract: For the accurate representation and reconstruction of band-limited signals on\nthe sphere, an optimal-dimensionality sampling scheme has been recently\nproposed which requires the optimal number of samples equal to the number of\ndegrees of freedom of the signal in the spectral (harmonic) domain. The\ncomputation of the spherical harmonic transform (SHT) associated with the\noptimal-dimensionality sampling requires the inversion of a series of linear\nsystems in an iterative manner. The stability of the inversion depends on the\nplacement of iso-latitude rings of samples along co-latitude. In this work, we\nhave developed a method to place these iso-latitude rings of samples with the\nobjective of improving the well-conditioning of the linear systems involved in\nthe computation of the SHT. We also propose a multi-pass SHT algorithm to\niteratively improve the accuracy of the SHT of band-limited signals.\nFurthermore, we review the changes in the computational complexity and\nimprovement in accuracy of the SHT with the embedding of the proposed methods.\nThrough numerical experiments, we illustrate that the proposed variations and\nimprovements in the SHT algorithm corresponding to the optimal-dimensionality\nsampling scheme significantly enhance the accuracy of the SHT. \n\n"}
{"id": "1709.02625", "contents": "Title: Decentralized Robust Transceiver Designs for MISO SWIPT Interference\n  Channel Abstract: This paper considers a $K$-user multiple-input single-output (MISO)\ninterference channels for simultaneous wireless information and power transfer\n(SWIPT), where each multi-antenna transmitter serves a single-antenna receiver\nper user pair. All receivers perform simultaneously information processing and\nenergy harvesting (EH) based on the receive power-splitting (PS) architectures.\nAssuming imperfect channel state information (CSI) at the transmitters, we\ndevelop an optimal robust transceiver design scheme that minimizes the total\ntransmission power under the worst-case signal-to-interference-plus-noise ratio\n(SINR) and energy harvesting (EH) constraints at the receivers, by jointly\noptimizing transmit beamforming and receive PS ratio per receiver. When the CSI\nuncertainties are bounded by ellipsoidal regions, it is shown that the\nworst-case SINR and EH constraints per receiver can be recast into quadratic\nmatrix inequality forms. Leveraging semidefinite relaxation technique, the\nintended robust beamforming and PS (BFPS) problem can be relaxed as a tractable\n(centralized) semidefinite program (SDP). More importantly, relying on the\nstate-of-the-art alternating direction method of multipliers (ADMM) in convex\noptimization, we propose a {\\em decentralized} algorithm capable of computing\nthe optimal robust BFPS scheme with local CSI and limited information exchange\namong the transmitters. It is shown the proposed decentralized algorithm is\nguaranteed to converge to the optimal centralized solution. Numerical results\nare provided to demonstrate the merits of the proposed approaches. \n\n"}
{"id": "1709.02840", "contents": "Title: A Brief Introduction to Machine Learning for Engineers Abstract: This monograph aims at providing an introduction to key concepts, algorithms,\nand theoretical results in machine learning. The treatment concentrates on\nprobabilistic models for supervised and unsupervised learning problems. It\nintroduces fundamental concepts and algorithms by building on first principles,\nwhile also exposing the reader to more advanced topics with extensive pointers\nto the literature, within a unified notation and mathematical framework. The\nmaterial is organized according to clearly defined categories, such as\ndiscriminative and generative models, frequentist and Bayesian approaches,\nexact and approximate inference, as well as directed and undirected models.\nThis monograph is meant as an entry point for researchers with a background in\nprobability and linear algebra. \n\n"}
{"id": "1709.03271", "contents": "Title: Beyond Empirical Models: Pattern Formation Driven Placement of UAV Base\n  Stations Abstract: This work considers the placement of unmanned aerial vehicle base stations\n(UAV-BSs) with criterion of minimum UAV-recall-frequency (UAV-RF), indicating\nthe energy efficiency of mobile UAVs networks. Several different power\nconsumptions, including signal transmit power, on-board circuit power and the\npower for UAVs mobility, and the ground user density are taken into account.\nInstead of conventional empirical stochastic models, this paper utilizes a\npattern formation system to track the instable and non-ergodic time-varying\nnature of user density. We show that for a single time-slot, the optimal\nplacement is achieved when the transmit power of UAV-BSs equals their on-board\ncircuit power. Then, for multiple time-slot duration, we prove that the optimal\nplacement updating problem is a nonlinear dynamic programming coupled with an\ninteger linear programming. Since the original problem is NP-hard and can not\nbe solved with conventional recursive methods, we propose a\nsequential-Markov-greedy-decision method to achieve near minimal UAV-RF in\npolynomial time. Further, we prove that the increment of UAV-RF caused by\ninaccurate predicted user density is proportional to the generalization error\nof learned patterns. Here, in regions with large area, high-rise buildings or\nlow user density, large sample sets are required for effective pattern\nformation. \n\n"}
{"id": "1709.08114", "contents": "Title: Nonconvex Low-Rank Matrix Recovery with Arbitrary Outliers via\n  Median-Truncated Gradient Descent Abstract: Recent work has demonstrated the effectiveness of gradient descent for\ndirectly recovering the factors of low-rank matrices from random linear\nmeasurements in a globally convergent manner when initialized properly.\nHowever, the performance of existing algorithms is highly sensitive in the\npresence of outliers that may take arbitrary values. In this paper, we propose\na truncated gradient descent algorithm to improve the robustness against\noutliers, where the truncation is performed to rule out the contributions of\nsamples that deviate significantly from the {\\em sample median} of measurement\nresiduals adaptively in each iteration. We demonstrate that, when initialized\nin a basin of attraction close to the ground truth, the proposed algorithm\nconverges to the ground truth at a linear rate for the Gaussian measurement\nmodel with a near-optimal number of measurements, even when a constant fraction\nof the measurements are arbitrarily corrupted. In addition, we propose a new\ntruncated spectral method that ensures an initialization in the basin of\nattraction at slightly higher requirements. We finally provide numerical\nexperiments to validate the superior performance of the proposed approach. \n\n"}
{"id": "1709.08692", "contents": "Title: The interplay of short-range correlations and nuclear symmetry energy in\n  hard photon productions from heavy-ion reactions at Fermi energies Abstract: Within an isospin- and momentum-dependent transport model for nuclear\nreactions at intermediate energies, we investigate the interplay of the\nnucleon-nucleon short-range correlations (SRC) and nuclear symmetry energy\n$E_{sym}(\\rho)$ on hard photon spectra in collisions of several Ca isotopes on\n$^{112}$Sn and $^{124}$Sn targets at a beam energy of 45 MeV/nucleon. It is\nfound that over the whole spectra of hard photons studied, effects of the SRC\noverwhelm those due to the $E_{sym}(\\rho)$. The energetic photons come mostly\nfrom the high-momentum tails (HMT) of single-nucleon momentum distributions in\nthe target and projectile. Within the neutron-proton dominance model of SRC\nbased on the consideration that the tensor force acts mostly in the isosinglet\nand spin-triplet nucleon-nucleon interaction channel, there are equal numbers\nof neutrons and protons, thus a zero isospin-asymmetry in the HMTs. Therefore,\nexperimental measurements of the energetic photons from heavy-ion collisions at\nFermi energies have the great potential to help us better understand the nature\nof SRC without any appreciable influence by the uncertain $E_{sym}(\\rho)$.\nThese measurements will be complementary to but also have some advantages over\nthe ongoing and planned experiments using hadronic messengers from reactions\ninduced by high-energy electrons or protons. Since the underlying physics of\nSRC and $E_{sym}(\\rho)$ are closely correlated, a better understanding of the\nSRC will in turn help constrain the nuclear symmetry energy more precisely in a\nbroad density range. \n\n"}
{"id": "1709.09803", "contents": "Title: Quantization for Low-Rank Matrix Recovery Abstract: We study Sigma-Delta quantization methods coupled with appropriate\nreconstruction algorithms for digitizing randomly sampled low-rank matrices. We\nshow that the reconstruction error associated with our methods decays\npolynomially with the oversampling factor, and we leverage our results to\nobtain root-exponential accuracy by optimizing over the choice of quantization\nscheme. Additionally, we show that a random encoding scheme, applied to the\nquantized measurements, yields a near-optimal exponential bit-rate. As an added\nbenefit, our schemes are robust both to noise and to deviations from the\nlow-rank assumption. In short, we provide a full generalization of analogous\nresults, obtained in the classical setup of bandlimited function acquisition,\nand more recently, in the finite frame and compressed sensing setups to the\ncase of low-rank matrices sampled with sub-Gaussian linear operators. Finally,\nwe believe our techniques for generalizing results from the compressed sensing\nsetup to the analogous low-rank matrix setup is applicable to other\nquantization schemes. \n\n"}
{"id": "1710.00197", "contents": "Title: Matching Anonymized and Obfuscated Time Series to Users' Profiles Abstract: Many popular applications use traces of user data to offer various services\nto their users. However, even if user data is anonymized and obfuscated, a\nuser's privacy can be compromised through the use of statistical matching\ntechniques that match a user trace to prior user behavior. In this work, we\nderive the theoretical bounds on the privacy of users in such a scenario. We\nbuild on our recent study in the area of location privacy, in which we\nintroduced formal notions of location privacy for anonymization-based location\nprivacy-protection mechanisms. Here we derive the fundamental limits of user\nprivacy when both anonymization and obfuscation-based protection mechanisms are\napplied to users' time series of data. We investigate the impact of such\nmechanisms on the trade-off between privacy protection and user utility. We\nfirst study achievability results for the case where the time-series of users\nare governed by an i.i.d. process. The converse results are proved both for the\ni.i.d. case as well as the more general Markov chain model. We demonstrate that\nas the number of users in the network grows, the obfuscation-anonymization\nplane can be divided into two regions: in the first region, all users have\nperfect privacy; and, in the second region, no user has privacy. \n\n"}
{"id": "1710.00809", "contents": "Title: The Capacity of Private Information Retrieval with Partially Known\n  Private Side Information Abstract: We consider the problem of private information retrieval (PIR) of a single\nmessage out of $K$ messages from $N$ replicated and non-colluding databases\nwhere a cache-enabled user (retriever) of cache-size $M$ possesses side\ninformation in the form of full messages that are partially known to the\ndatabases. In this model, the user and the databases engage in a two-phase\nscheme, namely, the prefetching phase where the user acquires side information\nand the retrieval phase where the user downloads desired information. In the\nprefetching phase, the user receives $m_n$ full messages from the $n$th\ndatabase, under the cache memory size constraint $\\sum_{n=1}^N m_n \\leq M$. In\nthe retrieval phase, the user wishes to retrieve a message such that no\nindividual database learns anything about the identity of the desired message.\nIn addition, the identities of the side information messages that the user did\nnot prefetch from a database must remain private against that database. Since\nthe side information provided by each database in the prefetching phase is\nknown by the providing database and the side information must be kept private\nagainst the remaining databases, we coin this model as \\textit{partially known\nprivate side information}. We characterize the capacity of the PIR with\npartially known private side information to be\n$C=\\left(1+\\frac{1}{N}+\\cdots+\\frac{1}{N^{K-M-1}}\\right)^{-1}=\\frac{1-\\frac{1}{N}}{1-(\\frac{1}{N})^{K-M}}$.\nInterestingly, this result is the same if none of the databases knows any of\nthe prefetched side information, i.e., when the side information is obtained\nexternally, a problem posed by Kadhe et al. and settled by Chen-Wang-Jafar\nrecently. Thus, our result implies that there is no loss in using the same\ndatabases for both prefetching and retrieval phases. \n\n"}
{"id": "1710.01203", "contents": "Title: Event patterns extracted from anisotropic spectra of charged particles\n  produced in Pb-Pb collisions at 2.76 TeV Abstract: Event patterns extracted from anisotropic spectra of charged particles\nproduced in lead-lead collisions at 2.76 TeV are investigated. We use an\ninverse power-law resulted from the QCD calculus to describe the transverse\nmomentum spectrum in the hard scattering process, and a revised Erlang\ndistribution resulted from a multisource thermal model to describe the\ntransverse momentum spectrum and anisotropic flow in the soft excitation\nprocess. The pseudorapidity distribution is described by a three-Gaussian\nfunction which is a revision of the Landau hydrodynamic model. Thus, the event\npatterns at the kinetic freeze-out are displayed by the scatter plots of the\nconsidered particles in the three-dimensional velocity, momentum, and rapidity\nspaces. \n\n"}
{"id": "1710.04389", "contents": "Title: Securing UAV Communications Via Trajectory Optimization Abstract: Unmanned aerial vehicle (UAV) communications has drawn significant interest\nrecently due to many advantages such as low cost, high mobility, and on-demand\ndeployment. This paper addresses the issue of physical-layer security in a UAV\ncommunication system, where a UAV sends confidential information to a\nlegitimate receiver in the presence of a potential eavesdropper which are both\non the ground. We aim to maximize the secrecy rate of the system by jointly\noptimizing the UAV's trajectory and transmit power over a finite horizon. In\ncontrast to the existing literature on wireless security with static nodes, we\nexploit the mobility of the UAV in this paper to enhance the secrecy rate via a\nnew trajectory design. Although the formulated problem is non-convex and\nchallenging to solve, we propose an iterative algorithm to solve the problem\nefficiently, based on the block coordinate descent and successive convex\noptimization methods. Specifically, the UAV's transmit power and trajectory are\neach optimized with the other fixed in an alternating manner until convergence.\nNumerical results show that the proposed algorithm significantly improves the\nsecrecy rate of the UAV communication system, as compared to benchmark schemes\nwithout transmit power control or trajectory optimization. \n\n"}
{"id": "1710.05209", "contents": "Title: Near-optimal Sample Complexity Bounds for Robust Learning of Gaussians\n  Mixtures via Compression Schemes Abstract: We prove that $\\tilde{\\Theta}(k d^2 / \\varepsilon^2)$ samples are necessary\nand sufficient for learning a mixture of $k$ Gaussians in $\\mathbb{R}^d$, up to\nerror $\\varepsilon$ in total variation distance. This improves both the known\nupper bounds and lower bounds for this problem. For mixtures of axis-aligned\nGaussians, we show that $\\tilde{O}(k d / \\varepsilon^2)$ samples suffice,\nmatching a known lower bound. Moreover, these results hold in the\nagnostic-learning/robust-estimation setting as well, where the target\ndistribution is only approximately a mixture of Gaussians.\n  The upper bound is shown using a novel technique for distribution learning\nbased on a notion of `compression.' Any class of distributions that allows such\na compression scheme can also be learned with few samples. Moreover, if a class\nof distributions has such a compression scheme, then so do the classes of\nproducts and mixtures of those distributions. The core of our main result is\nshowing that the class of Gaussians in $\\mathbb{R}^d$ admits a small-sized\ncompression scheme. \n\n"}
{"id": "1710.05312", "contents": "Title: Deep Learning for Wireless Physical Layer: Opportunities and Challenges Abstract: Machine learning (ML) has been widely applied to the upper layers of wireless\ncommunication systems for various purposes, such as deployment of cognitive\nradio and communication network. However, its application to the physical layer\nis hampered by sophisticated channel environments and limited learning ability\nof conventional ML algorithms. Deep learning (DL) has been recently applied for\nmany fields, such as computer vision and natural language processing, given its\nexpressive capacity and convenient optimization capability. The potential\napplication of DL to the physical layer has also been increasingly recognized\nbecause of the new features for future communications, such as complex\nscenarios with unknown channel models, high speed and accurate processing\nrequirements; these features challenge conventional communication theories.\nThis paper presents a comprehensive overview of the emerging studies on\nDL-based physical layer processing, including leveraging DL to redesign a\nmodule of the conventional communication system (for modulation recognition,\nchannel decoding, and detection) and replace the communication system with a\nradically new architecture based on an autoencoder. These DL-based methods show\npromising performance improvements but have certain limitations, such as lack\nof solid analytical tools and use of architectures that are specifically\ndesigned for communication and implementation research, thereby motivating\nfuture research in this field. \n\n"}
{"id": "1710.06753", "contents": "Title: Universally Weakly Secure Coset Coding Schemes for Minimum Storage\n  Regenerating (MSR) Codes Abstract: We consider the problem of designing codes for distributed storage that\nprotect user data against eavesdroppers that can gain access to network links\nas well as individual nodes. Our goal is to achieve weak security (also known\nas block security) that requires that the eavesdroppers would not be able to\ndecode individual files or combinations of a small number of files. The\nstandard approach for achieving block security is to use a joint design scheme\nthat consists of (inner) storage code and the (outer) coset code. However,\njointly designing the codes requires that the user, who pre-processes and\nstores the files, should know the underlying storage code in order to design\nthe (outer) linear transformation for achieving weak security. In many\npractical scenarios, such as storing the files on the third party cloud storage\nsystem, it may not be possible for the user to know the underlying storage\ncode.\n  In this work, we present universal schemes that separate the outer code\ndesign from the storage code design for minimum storage regenerating codes\n(MSR). Our schemes allow the independent design of the storage code and the\nouter code. Our schemes use small field size and can be used in a broad range\nof practical settings. \n\n"}
{"id": "1710.09429", "contents": "Title: DPCA: Dimensionality Reduction for Discriminative Analytics of Multiple\n  Large-Scale Datasets Abstract: Principal component analysis (PCA) has well-documented merits for data\nextraction and dimensionality reduction. PCA deals with a single dataset at a\ntime, and it is challenged when it comes to analyzing multiple datasets. Yet in\ncertain setups, one wishes to extract the most significant information of one\ndataset relative to other datasets. Specifically, the interest may be on\nidentifying, namely extracting features that are specific to a single target\ndataset but not the others. This paper develops a novel approach for such\nso-termed discriminative data analysis, and establishes its optimality in the\nleast-squares (LS) sense under suitable data modeling assumptions. The\ncriterion reveals linear combinations of variables by maximizing the ratio of\nthe variance of the target data to that of the remainders. The novel approach\nsolves a generalized eigenvalue problem by performing SVD just once. Numerical\ntests using synthetic and real datasets showcase the merits of the proposed\napproach relative to its competing alternatives. \n\n"}
{"id": "1710.09859", "contents": "Title: Kernel k-Groups via Hartigan's Method Abstract: Energy statistics was proposed by Sz\\' ekely in the 80's inspired by Newton's\ngravitational potential in classical mechanics and it provides a model-free\nhypothesis test for equality of distributions. In its original form, energy\nstatistics was formulated in Euclidean spaces. More recently, it was\ngeneralized to metric spaces of negative type. In this paper, we consider a\nformulation for the clustering problem using a weighted version of energy\nstatistics in spaces of negative type. We show that this approach leads to a\nquadratically constrained quadratic program in the associated kernel space,\nestablishing connections with graph partitioning problems and kernel methods in\nmachine learning. To find local solutions of such an optimization problem, we\npropose kernel k-groups, which is an extension of Hartigan's method to kernel\nspaces. Kernel k-groups is cheaper than spectral clustering and has the same\ncomputational cost as kernel k-means (which is based on Lloyd's heuristic) but\nour numerical results show an improved performance, especially in higher\ndimensions. Moreover, we verify the efficiency of kernel k-groups in community\ndetection in sparse stochastic block models which has fascinating applications\nin several areas of science. \n\n"}
{"id": "1710.10388", "contents": "Title: Minimax Rates and Efficient Algorithms for Noisy Sorting Abstract: There has been a recent surge of interest in studying permutation-based\nmodels for ranking from pairwise comparison data. Despite being structurally\nricher and more robust than parametric ranking models, permutation-based models\nare less well understood statistically and generally lack efficient learning\nalgorithms. In this work, we study a prototype of permutation-based ranking\nmodels, namely, the noisy sorting model. We establish the optimal rates of\nlearning the model under two sampling procedures. Furthermore, we provide a\nfast algorithm to achieve near-optimal rates if the observations are sampled\nindependently. Along the way, we discover properties of the symmetric group\nwhich are of theoretical interest. \n\n"}
{"id": "1710.11315", "contents": "Title: Rate-optimal Meta Learning of Classification Error Abstract: Meta learning of optimal classifier error rates allows an experimenter to\nempirically estimate the intrinsic ability of any estimator to discriminate\nbetween two populations, circumventing the difficult problem of estimating the\noptimal Bayes classifier. To this end we propose a weighted nearest neighbor\n(WNN) graph estimator for a tight bound on the Bayes classification error; the\nHenze-Penrose (HP) divergence. Similar to recently proposed HP estimators\n[berisha2016], the proposed estimator is non-parametric and does not require\ndensity estimation. However, unlike previous approaches the proposed estimator\nis rate-optimal, i.e., its mean squared estimation error (MSEE) decays to zero\nat the fastest possible rate of $O(1/M+1/N)$ where $M,N$ are the sample sizes\nof the respective populations. We illustrate the proposed WNN meta estimator\nfor several simulated and real data sets. \n\n"}
{"id": "1710.11404", "contents": "Title: Reshaping Cellular Networks for the Sky: Major Factors and Feasibility Abstract: This paper studies the feasibility of supporting drone operations using\nexistent cellular infrastructure. We propose an analytical framework that\nincludes the effects of base station (BS) height and antenna radiation pattern,\ndrone antenna directivity and various propagation environments. With this\nframework, we derive an exact expression for the coverage probability of ground\nand drone users through a practical cell association strategy. Our results show\nthat a carefully designed network can control the radiated interference that is\nreceived by the drones, and therefore guarantees a satisfactory quality of\nservice. Moreover, as the network density grows the increasing level of\ninterference can be partially managed by lowering the drone flying altitude.\nHowever, even at optimal conditions the drone coverage performance converges to\nzero considerably fast, suggesting that ultra-dense networks might be poor\ncandidates for serving aerial users. \n\n"}
{"id": "1710.11420", "contents": "Title: Joint Cooperative Computation and Interactive Communication for\n  Relay-Assisted Mobile Edge Computing Abstract: To realize cooperative computation and communication in a relay mobile edge\ncomputing system, we develop a hybrid relay forward protocol, where we seek to\nbalance the execution delay and network energy consumption. The problem is\nformulated as a nondifferentible optimization problem which is nonconvex with\nhighly coupled constraints. By exploiting the problem structure, we propose a\nlightweight algorithm based on inexact block coordinate descent method. Our\nresults show that the proposed algorithm exhibits much faster convergence as\ncompared with the popular concave-convex procedure based algorithm, while\nachieving good performance. \n\n"}
{"id": "1711.00379", "contents": "Title: Non-Linear Digital Self-Interference Cancellation for In-Band\n  Full-Duplex Radios Using Neural Networks Abstract: Full-duplex systems require very strong self-interference cancellation in\norder to operate correctly and a significant part of the self-interference\nsignal is due to non-linear effects created by various transceiver impairments.\nAs such, linear cancellation alone is usually not sufficient and sophisticated\nnon-linear cancellation algorithms have been proposed in the literature. In\nthis work, we investigate the use of a neural network as an alternative to the\ntraditional non-linear cancellation method that is based on polynomial basis\nfunctions. Measurement results from a full-duplex testbed demonstrate that a\nsmall and simple feed-forward neural network canceler works exceptionally well,\nas it can match the performance of the polynomial non-linear canceler with\nsignificantly lower computational complexity. \n\n"}
{"id": "1711.00657", "contents": "Title: Semi-Robust Communications over a Broadcast Channel Abstract: We establish the deterministic-code capacity region of a network with one\ntransmitter and two receivers: an \"ordinary receiver\" and a \"robust receiver.\"\nThe channel to the ordinary receiver is a given (known) discrete memoryless\nchannel (DMC), whereas the channel to the robust receiver is an arbitrarily\nvarying channel (AVC). Both receivers are required to decode the \"common\nmessage,\" whereas only the ordinary receiver is required to decode the \"private\nmessage.\" \n\n"}
{"id": "1711.02408", "contents": "Title: Probing the hadronic phase with resonances of different lifetimes in\n  Pb-Pb collisions with ALICE Abstract: The ALICE experiment has measured the production of a rich set of hadronic\nresonances, such as $\\rho(770)^{0}$, ${\\rm K}^{\\ast}(892)^{0}$, $\\phi$(1020),\n$\\Sigma^{\\pm}$(1385), $\\Lambda(1520)$ and $\\Xi^{\\ast 0}$ in pp, p-Pb and Pb-Pb\ncollisions at various energies at the LHC. A comprehensive overview and the\nlatest results are presented in this paper. Special focus is given to the role\nof hadronic resonances for the study of final-state effects in high-energy\ncollisions. In particular, the measurement of resonance production in heavy-ion\ncollisions has the capability to provide insight into the existence of a\nprolonged hadronic phase after hadronisation. The observation of the\nsuppression of the production of $\\Lambda(1520)$ resonance in central Pb-Pb\ncollisions at $\\sqrt{s_{\\rm NN}}$ = 2.76 TeV adds further support to the\nexistence of such a dense hadronic phase, as already evidenced by the ratios\n${\\rm K}^{\\ast}(892)^{0}$/${\\rm K}$ and $\\rho(770)^{0}$/$\\pi$. \n\n"}
{"id": "1711.02989", "contents": "Title: Variational Gaussian Dropout is not Bayesian Abstract: Gaussian multiplicative noise is commonly used as a stochastic regularisation\ntechnique in training of deterministic neural networks. A recent paper\nreinterpreted the technique as a specific algorithm for approximate inference\nin Bayesian neural networks; several extensions ensued. We show that the\nlog-uniform prior used in all the above publications does not generally induce\na proper posterior, and thus Bayesian inference in such models is ill-posed.\nIndependent of the log-uniform prior, the correlated weight noise approximation\nhas further issues leading to either infinite objective or high risk of\noverfitting. The above implies that the reported sparsity of obtained solutions\ncannot be explained by Bayesian or the related minimum description length\narguments. We thus study the objective from a non-Bayesian perspective, provide\nits previously unknown analytical form which allows exact gradient evaluation,\nand show that the later proposed additive reparametrisation introduces minima\nnot present in the original multiplicative parametrisation. Implications and\nfuture research directions are discussed. \n\n"}
{"id": "1711.03512", "contents": "Title: Fast Meta-Learning for Adaptive Hierarchical Classifier Design Abstract: We propose a new splitting criterion for a meta-learning approach to\nmulticlass classifier design that adaptively merges the classes into a\ntree-structured hierarchy of increasingly difficult binary classification\nproblems. The classification tree is constructed from empirical estimates of\nthe Henze-Penrose bounds on the pairwise Bayes misclassification rates that\nrank the binary subproblems in terms of difficulty of classification. The\nproposed empirical estimates of the Bayes error rate are computed from the\nminimal spanning tree (MST) of the samples from each pair of classes. Moreover,\na meta-learning technique is presented for quantifying the one-vs-rest Bayes\nerror rate for each individual class from a single MST on the entire dataset.\nExtensive simulations on benchmark datasets show that the proposed hierarchical\nmethod can often be learned much faster than competing methods, while achieving\ncompetitive accuracy. \n\n"}
{"id": "1711.04387", "contents": "Title: Capacity of UAV-Enabled Multicast Channel: Joint Trajectory Design and\n  Power Allocation Abstract: This paper studies an unmanned aerial vehicle (UAV)-enabled multicast\nchannel, in which a UAV serves as a mobile transmitter to deliver common\ninformation to a set of $K$ ground users. We aim to characterize the capacity\nof this channel over a finite UAV communication period, subject to its maximum\nspeed constraint and an average transmit power constraint. To achieve the\ncapacity, the UAV should use a sufficiently long code that spans over its whole\ncommunication period. Accordingly, the multicast channel capacity is achieved\nvia maximizing the minimum achievable time-averaged rates of the $K$ users, by\njointly optimizing the UAV's trajectory and transmit power allocation over\ntime. However, this problem is non-convex and difficult to be solved optimally.\nTo tackle this problem, we first consider a relaxed problem by ignoring the\nmaximum UAV speed constraint, and obtain its globally optimal solution via the\nLagrange dual method. The optimal solution reveals that the UAV should hover\nabove a finite number of ground locations, with the optimal hovering duration\nand transmit power at each location. Next, based on such a\nmulti-location-hovering solution, we present a successive hover-and-fly\ntrajectory design and obtain the corresponding optimal transmit power\nallocation for the case with the maximum UAV speed constraint. Numerical\nresults show that our proposed joint UAV trajectory and transmit power\noptimization significantly improves the achievable rate of the UAV-enabled\nmulticast channel, and also greatly outperforms the conventional multicast\nchannel with a fixed-location transmitter. \n\n"}
{"id": "1711.04677", "contents": "Title: Private Function Retrieval Abstract: The widespread use of cloud computing services raises the question of how one\ncan delegate the processing tasks to the untrusted distributed parties without\nbreeching the privacy of its data and algorithms. Motivated by the algorithm\nprivacy concerns in a distributed computing system, in this paper, we introduce\nthe private function retrieval (PFR) problem, where a user wishes to\nefficiently retrieve a linear function of $K$ messages from $N$\nnon-communicating replicated servers while keeping the function hidden from\neach individual server. The goal is to find a scheme with minimum communication\ncost. To characterize the fundamental limits of the communication cost, we\ndefine the capacity of PFR problem as the size of the message that can be\nprivately retrieved (which is the size of one file) normalized to the required\ndownloaded information bits. We first show that for the PFR problem with $K$\nmessages, $N=2$ servers and a linear function with binary coefficients the\ncapacity is $C=\\frac{1}{2}\\Big(1-\\frac{1}{2^K}\\Big)^{-1}$. Interestingly, this\nis the capacity of retrieving one of $K$ messages from $N=2$ servers while\nkeeping the index of the requested message hidden from each individual server,\nthe problem known as private information retrieval (PIR). Then, we extend the\nproposed achievable scheme to the case of arbitrary number of servers and\ncoefficients in the field $GF(q)$ with arbitrary $q$ and obtain\n$R=\\Big(1-\\frac{1}{N}\\Big)\\Big(1+\\frac{\\frac{1}{N-1}}{(\\frac{q^K-1}{q-1})^{N-1}}\\Big)$. \n\n"}
{"id": "1711.07956", "contents": "Title: Time-Limited Toeplitz Operators on Abelian Groups: Applications in\n  Information Theory and Subspace Approximation Abstract: Toeplitz operators are fundamental and ubiquitous in signal processing and\ninformation theory as models for linear, time-invariant (LTI) systems. Due to\nthe fact that any practical system can access only signals of finite duration,\ntime-limited restrictions of Toeplitz operators are naturally of interest. To\nprovide a unifying treatment of such systems working on different signal\ndomains, we consider time-limited Toeplitz operators on locally compact abelian\ngroups with the aid of the Fourier transform on these groups. In particular, we\nsurvey existing results concerning the relationship between the spectrum of a\ntime-limited Toeplitz operator and the spectrum of the corresponding\nnon-time-limited Toeplitz operator. We also develop new results specifically\nconcerning the eigenvalues of time-frequency limiting operators on locally\ncompact abelian groups. Applications of our unifying treatment are discussed in\nrelation to channel capacity and in relation to representation and\napproximation of signals. \n\n"}
{"id": "1711.10299", "contents": "Title: Expurgated Bounds for the Asymmetric Broadcast Channel Abstract: This work contains two main contributions concerning the expurgation of\nhierarchical ensembles for the asymmetric broadcast channel. The first is an\nanalysis of the optimal maximum likelihood (ML) decoders for the weak and\nstrong user. Two different methods of code expurgation will be used, that will\nprovide two competing error exponents. The second is the derivation of\nexpurgated exponents under the generalized stochastic likelihood decoder (GLD).\nWe prove that the GLD exponents are at least as tight as the maximum between\nthe random coding error exponents derived in an earlier work by Averbuch and\nMerhav (2017) and one of our ML-based expurgated exponents. By that, we\nactually prove the existence of hierarchical codebooks that achieve the best of\nthe random coding exponent and the expurgated exponent simultaneously for both\nusers. \n\n"}
{"id": "1711.10783", "contents": "Title: Partial Consensus and Conservative Fusion of Gaussian Mixtures for\n  Distributed PHD Fusion Abstract: We propose a novel consensus notion, called \"partial consensus\", for\ndistributed GM-PHD (Gaussian mixture probability hypothesis density) fusion\nbased on a peer-to-peer (P2P) sensor network, in which only highly-weighted\nposterior Gaussian components (GCs) are disseminated in the P2P communication\nfor fusion while the insignificant GCs are not involved. The partial consensus\ndoes not only enjoy high efficiency in both network communication and local\nfusion computation, but also significantly reduces the affect of potential\nfalse data (clutter) to the filter, leading to increased signal-to-noise ratio\nat local sensors. Two \"conservative\" mixture reduction schemes are advocated\nfor fusing the shared GCs in a fully distributed manner. One is given by\npairwise averaging GCs between sensors based on Hungarian assignment and the\nother is merging close GCs based a new GM merging scheme. The proposed\napproaches have a close connection to the conservative fusion approaches known\nas covariance union and arithmetic mean density. In parallel, average consensus\nis sought on the cardinality distribution (namely the GM weight sum) among\nsensors. Simulations for tracking either a single target or multiple targets\nthat simultaneously appear are presented based on a sensor network where each\nsensor operates a GM-PHD filter, in order to compare our approaches with the\nbenchmark generalized covariance intersection approach. The results demonstrate\nthat the partial, arithmetic average, consensus outperforms the complete,\ngeometric average, consensus. \n\n"}
{"id": "1711.10954", "contents": "Title: A Robust Time-Domain Beam Alignment Scheme for Multi-User Wideband\n  mmWave Systems Abstract: Millimeter wave (mmWave) communication with large array gains is a key\ningredient of next generation (5G) wireless networks. Effective communication\nin mmWaves usually depends on the knowledge of the channel. We refer to the\nproblem of finding a narrow beam pair at the transmitter and at the receiver,\nyielding high Signal to Noise Ratio (SNR) as Beam Alignment (BA). Prior BA\nschemes typically considered deterministic channels, where the instantaneous\nchannel coefficients are assumed to stay constant for a long time. In this\npaper, in contrast, we propose a time-domain BA scheme for wideband mmWave\nsystems, where the channel is characterized by multi-path components, different\ndelays, Angle-of-Arrivals/Angle-of-Departures (AoAs/AoDs), and Doppler shifts.\nIn our proposed scheme, the Base Station (BS) probes the channel in the\ndownlink by some sequences with good autocorrelation property (e.g.,\nPseudo-Noise (PN) sequences), letting each user estimate its best AoA-AoD that\nconnects the user to the BS with two-sided high beamforming gain. We leverage\nthe sparse nature of mmWaves in the AoA-AoD-time domain, and formulate the BA\nproblem as a Compressed Sensing (CS) of a non-negative sparse vector. We use\nthe recently developed Non-Negative Least Squares (NNLS) technique to\nefficiently find the strongest path connecting the BS and each user. Simulation\nresults show that the proposed scheme outperforms its counterpart in terms of\nthe training overhead and robustness to fast channel variations. \n\n"}
{"id": "1712.00702", "contents": "Title: Efficient Beam Alignment in Millimeter Wave Systems Using Contextual\n  Bandits Abstract: In this paper, we investigate the problem of beam alignment in millimeter\nwave (mmWave) systems, and design an optimal algorithm to reduce the overhead.\nSpecifically, due to directional communications, the transmitter and receiver\nbeams need to be aligned, which incurs high delay overhead since without a\npriori knowledge of the transmitter/receiver location, the search space spans\nthe entire angular domain. This is further exacerbated under dynamic conditions\n(e.g., moving vehicles) where the access to the base station (access point) is\nhighly dynamic with intermittent on-off periods, requiring more frequent beam\nalignment and signal training. To mitigate this issue, we consider an online\nstochastic optimization formulation where the goal is to maximize the\ndirectivity gain (i.e., received energy) of the beam alignment policy within a\ntime period. We exploit the inherent correlation and unimodality properties of\nthe model, and demonstrate that contextual information improves the\nperformance. To this end, we propose an equivalent structured Multi-Armed\nBandit model to optimally exploit the exploration-exploitation tradeoff. In\ncontrast to the classical MAB models, the contextual information makes the\nlower bound on regret (i.e., performance loss compared with an oracle policy)\nindependent of the number of beams. This is a crucial property since the number\nof all combinations of beam patterns can be large in transceiver antenna\narrays, especially in massive MIMO systems. We further provide an\nasymptotically optimal beam alignment algorithm, and investigate its\nperformance via simulations. \n\n"}
{"id": "1712.00708", "contents": "Title: Study of the Sparse Superposition Codes and the Generalized Approximate\n  Message Passing Decoder for the Communication over Binary Symmetric and Z\n  Channels Abstract: In this project, the behavior of Generalized Approximate Message-Passing\nDecoder for BSC and Z Channel is studied using i.i.d matrices for constructing\nthe codewords. The performance of GAMP in AWGN Channel is already evaluated in\nthe previous scientific work of Jean Barbier, therefore, this project mainly\nfocuses on the performance of GAMP decoder for BSC and Z Channel. We evaluate\nthe performance of the GAMP decoder for sparse superposition codes at various\nsettings and compare the performance of decoder for different channels and\nparameters. \n\n"}
{"id": "1712.01158", "contents": "Title: Statistical Inference for Incomplete Ranking Data: The Case of\n  Rank-Dependent Coarsening Abstract: We consider the problem of statistical inference for ranking data,\nspecifically rank aggregation, under the assumption that samples are incomplete\nin the sense of not comprising all choice alternatives. In contrast to most\nexisting methods, we explicitly model the process of turning a full ranking\ninto an incomplete one, which we call the coarsening process. To this end, we\npropose the concept of rank-dependent coarsening, which assumes that incomplete\nrankings are produced by projecting a full ranking to a random subset of ranks.\nFor a concrete instantiation of our model, in which full rankings are drawn\nfrom a Plackett-Luce distribution and observations take the form of pairwise\npreferences, we study the performance of various rank aggregation methods. In\naddition to predictive accuracy in the finite sample setting, we address the\ntheoretical question of consistency, by which we mean the ability to recover a\ntarget ranking when the sample size goes to infinity, despite a potential bias\nin the observations caused by the (unknown) coarsening. \n\n"}
{"id": "1712.04086", "contents": "Title: PacGAN: The power of two samples in generative adversarial networks Abstract: Generative adversarial networks (GANs) are innovative techniques for learning\ngenerative models of complex data distributions from samples. Despite\nremarkable recent improvements in generating realistic images, one of their\nmajor shortcomings is the fact that in practice, they tend to produce samples\nwith little diversity, even when trained on diverse datasets. This phenomenon,\nknown as mode collapse, has been the main focus of several recent advances in\nGANs. Yet there is little understanding of why mode collapse happens and why\nexisting approaches are able to mitigate mode collapse. We propose a principled\napproach to handling mode collapse, which we call packing. The main idea is to\nmodify the discriminator to make decisions based on multiple samples from the\nsame class, either real or artificially generated. We borrow analysis tools\nfrom binary hypothesis testing---in particular the seminal result of Blackwell\n[Bla53]---to prove a fundamental connection between packing and mode collapse.\nWe show that packing naturally penalizes generators with mode collapse, thereby\nfavoring generator distributions with less mode collapse during the training\nprocess. Numerical experiments on benchmark datasets suggests that packing\nprovides significant improvements in practice as well. \n\n"}
{"id": "1712.04462", "contents": "Title: Online radio interferometric imaging: assimilating and discarding\n  visibilities on arrival Abstract: The emerging generation of radio interferometric (RI) telescopes, such as the\nSquare Kilometre Array (SKA), will acquire massive volumes of data and\ntransition radio astronomy to a big-data era. The ill-posed inverse problem of\nimaging the raw visibilities acquired by RI telescopes will become\nsignificantly more computationally challenging, particularly in terms of data\nstorage and computational cost. Current RI imaging methods, such as CLEAN, its\nvariants, and compressive sensing approaches (sparse regularisation), have\nyielded excellent reconstruction fidelity. However, scaling these methods to\nbig-data remains difficult if not impossible in some cases. All\nstate-of-the-art methods in RI imaging lack the ability to process data streams\nas they are acquired during the data observation stage. Such approaches are\nreferred to as online processing methods. We present an online sparse\nregularisation methodology for RI imaging. Image reconstruction is performed\nsimultaneously with data acquisition, where observed visibilities are\nassimilated into the reconstructed image as they arrive and then discarded.\nSince visibilities are processed online, good reconstructions are recovered\nmuch faster than standard (offline) methods which cannot start until the data\nacquisition stage completes. Moreover, the online method provides additional\ncomputational savings and, most importantly, dramatically reduces data storage\nrequirements. Theoretically, the reconstructed images are of the same fidelity\nas those recovered by the equivalent offline approach and, in practice, very\nsimilar reconstruction fidelity is achieved. We anticipate online imaging\ntechniques, as proposed here, will be critical in scaling RI imaging to the\nemerging big-data era of radio astronomy. \n\n"}
{"id": "1712.04613", "contents": "Title: ROAST: Rapid Orthogonal Approximate Slepian Transform Abstract: In this paper, we provide a Rapid Orthogonal Approximate Slepian Transform\n(ROAST) for the discrete vector that one obtains when collecting a finite set\nof uniform samples from a baseband analog signal. The ROAST offers an\northogonal projection which is an approximation to the orthogonal projection\nonto the leading discrete prolate spheroidal sequence (DPSS) vectors (also\nknown as Slepian basis vectors). As such, the ROAST is guaranteed to accurately\nand compactly represent not only oversampled bandlimited signals but also the\nleading DPSS vectors themselves. Moreover, the subspace angle between the ROAST\nsubspace and the corresponding DPSS subspace can be made arbitrarily small. The\ncomplexity of computing the representation of a signal using the ROAST is\ncomparable to the FFT, which is much less than the complexity of using the DPSS\nbasis vectors. We also give non-asymptotic results to guarantee that the\nproposed basis not only provides a very high degree of approximation accuracy\nin a mean squared error sense for bandlimited sample vectors, but also that it\ncan provide high-quality approximations of all sampled sinusoids within the\nband of interest. \n\n"}
{"id": "1712.05728", "contents": "Title: Low SNR Asymptotic Rates of Vector Channels with One-Bit Outputs Abstract: We analyze the performance of multiple-input multiple-output (MIMO) links\nwith one-bit output quantization in terms of achievable rates and characterize\ntheir performance loss compared to unquantized systems for general channel\nstatistical models and general channel state information (CSI) at the receiver.\nOne-bit ADCs are particularly suitable for large-scale millimeter wave MIMO\nCommunications (massive MIMO) to reduce the hardware complexity. In such\napplications, the signal-to-noise ratio per antenna is rather low due to the\npropagation loss. Thus, it is crucial to analyze the performance of MIMO\nsystems in this regime by means of information theoretical methods. Since an\nexact and general information-theoretic analysis is not possible, we resort to\nthe derivation of a general asymptotic expression for the mutual information in\nterms of a second order expansion around zero SNR. We show that up to second\norder in the SNR, the mutual information of a system with two-level (sign)\noutput signals incorporates only a power penalty factor of pi/2 (1.96 dB)\ncompared to system with infinite resolution for all channels of practical\ninterest with perfect or statistical CSI. An essential aspect of the derivation\nis that we do not rely on the common pseudo-quantization noise model. \n\n"}
{"id": "1712.06120", "contents": "Title: Hypothesis Testing for High-Dimensional Multinomials: A Selective Review Abstract: The statistical analysis of discrete data has been the subject of extensive\nstatistical research dating back to the work of Pearson. In this survey we\nreview some recently developed methods for testing hypotheses about\nhigh-dimensional multinomials. Traditional tests like the $\\chi^2$ test and the\nlikelihood ratio test can have poor power in the high-dimensional setting. Much\nof the research in this area has focused on finding tests with asymptotically\nNormal limits and developing (stringent) conditions under which tests have\nNormal limits. We argue that this perspective suffers from a significant\ndeficiency: it can exclude many high-dimensional cases when - despite having\nnon Normal null distributions - carefully designed tests can have high power.\nFinally, we illustrate that taking a minimax perspective and considering\nrefinements of this perspective can lead naturally to powerful and practical\ntests. \n\n"}
{"id": "1712.06745", "contents": "Title: Efficient Algorithms for Searching the Minimum Information Partition in\n  Integrated Information Theory Abstract: The ability to integrate information in the brain is considered to be an\nessential property for cognition and consciousness. Integrated Information\nTheory (IIT) hypothesizes that the amount of integrated information ($\\Phi$) in\nthe brain is related to the level of consciousness. IIT proposes that to\nquantify information integration in a system as a whole, integrated information\nshould be measured across the partition of the system at which information loss\ncaused by partitioning is minimized, called the Minimum Information Partition\n(MIP). The computational cost for exhaustively searching for the MIP grows\nexponentially with system size, making it difficult to apply IIT to real neural\ndata. It has been previously shown that if a measure of $\\Phi$ satisfies a\nmathematical property, submodularity, the MIP can be found in a polynomial\norder by an optimization algorithm. However, although the first version of\n$\\Phi$ is submodular, the later versions are not. In this study, we empirically\nexplore to what extent the algorithm can be applied to the non-submodular\nmeasures of $\\Phi$ by evaluating the accuracy of the algorithm in simulated\ndata and real neural data. We find that the algorithm identifies the MIP in a\nnearly perfect manner even for the non-submodular measures. Our results show\nthat the algorithm allows us to measure $\\Phi$ in large systems within a\npractical amount of time. \n\n"}
{"id": "1712.06804", "contents": "Title: Asymptotic Coupling and Its Applications in Information Theory Abstract: A coupling of two distributions $P_{X}$ and $P_{Y}$ is a joint distribution\n$P_{XY}$ with marginal distributions equal to $P_{X}$ and $P_{Y}$. Given\nmarginals $P_{X}$ and $P_{Y}$ and a real-valued function $f$ of the joint\ndistribution $P_{XY}$, what is its minimum over all couplings $P_{XY}$ of\n$P_{X}$ and $P_{Y}$? We study the asymptotics of such coupling problems with\ndifferent $f$'s and with $X$ and $Y$ replaced by $X^{n}=(X_{1},\\ldots,X_{n})$\nand $Y^{n}=(Y_{1},\\ldots,Y_{n})$ where $X_{i}$ and $Y_{i}$ are i.i.d.\\ copies\nof random variables $X$ and $Y$ with distributions $P_{X}$ and $P_{Y}$\nrespectively. These include the maximal coupling, minimum distance coupling,\nmaximal guessing coupling, and minimum entropy coupling problems. We\ncharacterize the limiting values of these coupling problems as $n$ tends to\ninfinity. We show that they typically converge at least exponentially fast to\ntheir limits. Moreover, for the problems of maximal coupling and minimum\nexcess-distance probability coupling, we also characterize (or bound) the\noptimal convergence rates (exponents). Furthermore, for the maximal guessing\ncoupling problem we show that it is equivalent to the distribution\napproximation problem. Therefore, some existing results for the latter problem\ncan be used to derive the asymptotics of the maximal guessing coupling problem.\nWe also study the asymptotics of the maximal guessing coupling problem for two\n\\emph{general} sources and a generalization of this problem, named the\n\\emph{maximal guessing coupling through a channel problem}. We apply the\npreceding results to several new information-theoretic problems, including\nexact intrinsic randomness, exact resolvability, channel capacity with input\ndistribution constraint, and perfect stealth and secrecy communication. \n\n"}
{"id": "1712.07161", "contents": "Title: Linear Block Coding for Efficient Beam Discovery in Millimeter Wave\n  Communication Networks Abstract: The surge in mobile broadband data demands is expected to surpass the\navailable spectrum capacity below 6 GHz. This expectation has prompted the\nexploration of millimeter wave (mm-wave) frequency bands as a candidate\ntechnology for next generation wireless networks. However, numerous challenges\nto deploying mm-wave communication systems, including channel estimation, need\nto be met before practical deployments are possible. This work addresses the\nmm-wave channel estimation problem and treats it as a beam discovery problem in\nwhich locating beams with strong path reflectors is analogous to locating\nerrors in linear block codes. We show that a significantly small number of\nmeasurements (compared to the original dimensions of the channel matrix) is\nsufficient to reliably estimate the channel. We also show that this can be\nachieved using a simple and energy-efficient transceiver architecture. \n\n"}
{"id": "1712.08244", "contents": "Title: How Well Can Generative Adversarial Networks Learn Densities: A\n  Nonparametric View Abstract: We study in this paper the rate of convergence for learning densities under\nthe Generative Adversarial Networks (GAN) framework, borrowing insights from\nnonparametric statistics. We introduce an improved GAN estimator that achieves\na faster rate, through simultaneously leveraging the level of smoothness in the\ntarget density and the evaluation metric, which in theory remedies the mode\ncollapse problem reported in the literature. A minimax lower bound is\nconstructed to show that when the dimension is large, the exponent in the rate\nfor the new GAN estimator is near optimal. One can view our results as\nanswering in a quantitative way how well GAN learns a wide range of densities\nwith different smoothness properties, under a hierarchy of evaluation metrics.\nAs a byproduct, we also obtain improved generalization bounds for GAN with\ndeeper ReLU discriminator network. \n\n"}
{"id": "1712.10291", "contents": "Title: Communications and Control for Wireless Drone-Based Antenna Array Abstract: In this paper, the effective use of multiple quadrotor drones as an aerial\nantenna array that provides wireless service to ground users is investigated.\nIn particular, under the goal of minimizing the airborne service time needed\nfor communicating with ground users, a novel framework for deploying and\noperating a drone-based antenna array system whose elements are single-antenna\ndrones is proposed. In the considered model, the service time is minimized by\nminimizing the wireless transmission time as well as the control time that is\nneeded for movement and stabilization of the drones. To minimize the\ntransmission time, first, the antenna array gain is maximized by optimizing the\ndrone spacing within the array. In this case, using perturbation techniques,\nthe drone spacing optimization problem is addressed by solving successive,\nperturbed convex optimization problems. Then, the optimal locations of the\ndrones around the array's center are derived such that the transmission time\nfor the user is minimized. Given the determined optimal locations of drones,\nthe drones must spend a control time to adjust their positions dynamically so\nas to serve multiple users. To minimize this control time of the quadrotor\ndrones, the speed of rotors is optimally adjusted based on both the\ndestinations of the drones and external forces (e.g., wind and gravity). In\nparticular, using bang-bang control theory, the optimal rotors' speeds as well\nas the minimum control time are derived in closed-form. Simulation results show\nthat the proposed approach can significantly reduce the service time to ground\nusers compared to a fixed-array case in which the same number of drones form a\nfixed uniform antenna array. The results also show that, in comparison with the\nfixed-array case, the network's spectral efficiency can be improved by 32%\nwhile leveraging the drone antenna array system. \n\n"}
{"id": "1801.00398", "contents": "Title: Scalable Hash-Based Estimation of Divergence Measures Abstract: We propose a scalable divergence estimation method based on hashing. Consider\ntwo continuous random variables $X$ and $Y$ whose densities have bounded\nsupport. We consider a particular locality sensitive random hashing, and\nconsider the ratio of samples in each hash bin having non-zero numbers of Y\nsamples. We prove that the weighted average of these ratios over all of the\nhash bins converges to f-divergences between the two samples sets. We show that\nthe proposed estimator is optimal in terms of both MSE rate and computational\ncomplexity. We derive the MSE rates for two families of smooth functions; the\nH\\\"{o}lder smoothness class and differentiable functions. In particular, it is\nproved that if the density functions have bounded derivatives up to the order\n$d/2$, where $d$ is the dimension of samples, the optimal parametric MSE rate\nof $O(1/N)$ can be achieved. The computational complexity is shown to be\n$O(N)$, which is optimal. To the best of our knowledge, this is the first\nempirical divergence estimator that has optimal computational complexity and\nachieves the optimal parametric MSE estimation rate. \n\n"}
{"id": "1801.01253", "contents": "Title: Approximate Ranking from Pairwise Comparisons Abstract: A common problem in machine learning is to rank a set of n items based on\npairwise comparisons. Here ranking refers to partitioning the items into sets\nof pre-specified sizes according to their scores, which includes identification\nof the top-k items as the most prominent special case. The score of a given\nitem is defined as the probability that it beats a randomly chosen other item.\nFinding an exact ranking typically requires a prohibitively large number of\ncomparisons, but in practice, approximate rankings are often adequate.\nAccordingly, we study the problem of finding approximate rankings from pairwise\ncomparisons. We analyze an active ranking algorithm that counts the number of\ncomparisons won, and decides whether to stop or which pair of items to compare\nnext, based on confidence intervals computed from the data collected in\nprevious steps. We show that this algorithm succeeds in recovering approximate\nrankings using a number of comparisons that is close to optimal up to\nlogarithmic factors. We also present numerical results, showing that in\npractice, approximation can drastically reduce the number of comparisons\nrequired to estimate a ranking. \n\n"}
{"id": "1801.02020", "contents": "Title: Decentralized Base-Graph Routing for the Quantum Internet Abstract: Quantum repeater networks are a fundamental of any future quantum Internet\nand long-distance quantum communications. The entangled quantum nodes can\ncommunicate through several different levels of entanglement, leading to a\nheterogeneous, multi-level network structure. The level of entanglement between\nthe quantum nodes determines the hop distance and the probability of the\nexistence of an entangled link in the network. Here, we define a decentralized\nrouting for entangled quantum networks. The proposed method allows an efficient\nrouting to find the shortest paths in entangled quantum networks by using only\nlocal knowledge of the quantum nodes. We give bounds on the maximum value of\nthe total number of entangled links of a path. The proposed scheme can be\ndirectly applied in practical quantum communications and quantum networking\nscenarios. \n\n"}
{"id": "1801.02061", "contents": "Title: Optimal Error Correcting Delivery Scheme for an Optimal Coded Caching\n  Scheme with Small Buffers Abstract: Optimal delivery scheme for coded caching problems with small buffer sizes\nand the number of users no less than the amount of files in the server was\nproposed by Chen, Fan and Letaief [\"Fundamental limits of caching: improved\nbounds for users with small buffers,\" (IET Communications), 2016]. This scheme\nis referred to as the CFL scheme. In this paper, the link between the server\nand the users is assumed to be error prone only during the delivery phase.\nClosed form expressions for average rate and peak rate of error correcting\ndelivery scheme for CFL prefetching scheme is obtained. An optimal error\ncorrecting delivery scheme for caching problems employing CFL prefetching is\nproposed. \n\n"}
{"id": "1801.02743", "contents": "Title: Enhancing Performance of Random Caching in Large-Scale Wireless Networks\n  with Multiple Receive Antennas Abstract: To improve signal-to-interference ratio (SIR) and make better use of file\ndiversity provided by random caching, we consider two types of linear\nreceivers, i.e., maximal ratio combining (MRC) receiver and partial zero\nforcing (PZF) receiver, at users in a large-scale cache-enabled single-input\nmulti-output (SIMO) network. First, for each receiver, by utilizing tools from\nstochastic geometry, we derive a tractable expression and a tight upper bound\nfor the successful transmission probability (STP). In the case of the MRC\nreceiver, we also derive a closed-form expression for the asymptotic outage\nprobability in the low SIR threshold regime. Then, for each receiver, we\nmaximize the STP. In the case of the MRC receiver, we consider the maximization\nof the tight upper bound on the STP by optimizing the caching distribution,\nwhich is a non-convex problem. We obtain a stationary point, by solving an\nequivalent difference of convex (DC) programming problem using concave-convex\nprocedure (CCCP). We also obtain a closed-form asymptotically optimal solution\nin the low SIR threshold regime. In the case of the PZF receiver, we consider\nthe maximization of the tight upper bound on the STP by optimizing the caching\ndistribution and the degrees of freedom (DoF) allocation (for boosting the\nsignal power), which is a mixed discrete-continuous problem. Based on\nstructural properties, we obtain a low-complexity near optimal solution by\nusing an alternating optimization approach. The analysis and optimization\nresults reveal the impact of antenna resource at users on random caching.\nFinally, by numerical results, we show that the random caching design with the\nPZF receiver achieves significant performance gains over the random caching\ndesign with the MRC receiver and some baseline caching designs. \n\n"}
{"id": "1801.03079", "contents": "Title: Asymmetry Hurts: Private Information Retrieval Under Asymmetric Traffic\n  Constraints Abstract: We consider the classical setting of private information retrieval (PIR) of a\nsingle message (file) out of $M$ messages from $N$ distributed databases under\nthe new constraint of \\emph{asymmetric traffic} from databases. In this\nproblem, the \\emph{ratios between the traffic} from the databases are\nconstrained, i.e., the ratio of the length of the answer string that the user\n(retriever) receives from the $n$th database to the total length of all answer\nstrings from all databases is constrained to be $\\tau_n$. This may happen if\nthe user's access to the databases is restricted due database availability,\nchannel quality to the databases, and other factors. For this problem, for\nfixed $M$, $N$, we develop a general upper bound $\\bar{C}(\\boldsymbol{\\tau})$,\nwhich generalizes the converse proof of Sun-Jafar, where database symmetry was\ninherently used. Our converse bound is a piece-wise affine function in the\ntraffic ratio vector $\\boldsymbol{\\tau}=(\\tau_1, \\cdots, \\tau_N)$. For the\nlower bound, we explicitly show the achievability of $\\binom{M+N-1}{M}$ corner\npoints. For the remaining traffic ratio vectors, we perform time-sharing\nbetween these corner points. The recursive structure of our achievability\nscheme is captured via a system of difference equations. The upper and lower\nbounds exactly match for $M=2$ and $M=3$ for any $N$ and any\n$\\boldsymbol{\\tau}$. The results show strict loss of PIR capacity due to the\nasymmetric traffic constraints compared with the symmetric case of Sun-Jafar\nwhich implicitly uses $\\tau_n=\\frac{1}{N}$ for all $n$. \n\n"}
{"id": "1801.03714", "contents": "Title: Multi-Band Covariance Interpolation with Applications in Massive MIMO Abstract: In this paper, we study the problem of multi-band (frequency-variant)\ncovariance interpolation with a particular emphasis towards massive MIMO\napplications. In a massive MIMO system, the communication between each BS with\n$M \\gg 1$ antennas and each single-antenna user occurs through a collection of\nscatterers in the environment, where the channel vector of each user at BS\nantennas consists in a weighted linear combination of the array responses of\nthe scatterers, where each scatterer has its own angle of arrival (AoA) and\ncomplex channel gain. The array response at a given AoA depends on the\nwavelength of the incoming planar wave and is naturally frequency dependent.\nThis results in a frequency-dependent distortion where the second order\nstatistics, i.e., the covariance matrix, of the channel vectors varies with\nfrequency. In this paper, we show that although this effect is generally\nnegligible for a small number of antennas $M$, it results in a considerable\ndistortion of the covariance matrix and especially its dominant signal subspace\nin the massive MIMO regime where $M \\to \\infty$, and can generally incur a\nserious degradation of the performance especially in frequency division\nduplexing (FDD) massive MIMO systems where the uplink (UL) and the downlink\n(DL) communication occur over different frequency bands. We propose a novel\nUL-DL covariance interpolation technique that is able to recover the covariance\nmatrix in the DL from an estimate of the covariance matrix in the UL under a\nmild reciprocity condition on the angular power spread function (PSF) of the\nusers. We analyze the performance of our proposed scheme mathematically and\nprove its robustness under a sufficiently large spatial oversampling of the\narray. We also propose several simple off-the-shelf algorithms for UL-DL\ncovariance interpolation and evaluate their performance via numerical\nsimulations. \n\n"}
{"id": "1801.03868", "contents": "Title: An entropy inequality for symmetric random variables Abstract: We establish a lower bound on the entropy of weighted sums of (possibly\ndependent) random variables $(X_1, X_2, \\dots, X_n)$ possessing a symmetric\njoint distribution. Our lower bound is in terms of the joint entropy of $(X_1,\nX_2, \\dots, X_n)$. We show that for $n \\geq 3$, the lower bound is tight if and\nonly if $X_i$'s are i.i.d.\\ Gaussian random variables. For $n=2$ there are\nnumerous other cases of equality apart from i.i.d.\\ Gaussians, which we\ncompletely characterize. Going beyond sums, we also present an inequality for\ncertain linear transformations of $(X_1, \\dots, X_n)$. Our primary technical\ncontribution lies in the analysis of the equality cases, and our approach\nrelies on the geometry and the symmetry of the problem. \n\n"}
{"id": "1801.03892", "contents": "Title: Privacy in Index Coding: Improved Bounds and Coding Schemes Abstract: It was recently observed in [1], that in index coding, learning the coding\nmatrix used by the server can pose privacy concerns: curious clients can\nextract information about the requests and side information of other clients.\nOne approach to mitigate such concerns is the use of $k$-limited-access schemes\n[1], that restrict each client to learn only part of the index coding matrix,\nand in particular, at most $k$ rows. These schemes transform a linear index\ncoding matrix of rank $T$ to an alternate one, such that each client needs to\nlearn at most $k$ of the coding matrix rows to decode its requested message.\nThis paper analyzes $k$-limited-access schemes. First, a worst-case scenario,\nwhere the total number of clients $n$ is $2^T-1$ is studied. For this case, a\nnovel construction of the coding matrix is provided and shown to be\norder-optimal in the number of transmissions. Then, the case of a general $n$\nis considered and two different schemes are designed and analytically and\nnumerically assessed in their performance. It is shown that these schemes\nperform better than the one designed for the case $n=2^T-1$. \n\n"}
{"id": "1801.04295", "contents": "Title: Generalization Error Bounds for Noisy, Iterative Algorithms Abstract: In statistical learning theory, generalization error is used to quantify the\ndegree to which a supervised machine learning algorithm may overfit to training\ndata. Recent work [Xu and Raginsky (2017)] has established a bound on the\ngeneralization error of empirical risk minimization based on the mutual\ninformation $I(S;W)$ between the algorithm input $S$ and the algorithm output\n$W$, when the loss function is sub-Gaussian. We leverage these results to\nderive generalization error bounds for a broad class of iterative algorithms\nthat are characterized by bounded, noisy updates with Markovian structure. Our\nbounds are very general and are applicable to numerous settings of interest,\nincluding stochastic gradient Langevin dynamics (SGLD) and variants of the\nstochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm. Furthermore, our\nerror bounds hold for any output function computed over the path of iterates,\nincluding the last iterate of the algorithm or the average of subsets of\niterates, and also allow for non-uniform sampling of data in successive updates\nof the algorithm. \n\n"}
{"id": "1801.04378", "contents": "Title: Fairness in Supervised Learning: An Information Theoretic Approach Abstract: Automated decision making systems are increasingly being used in real-world\napplications. In these systems for the most part, the decision rules are\nderived by minimizing the training error on the available historical data.\nTherefore, if there is a bias related to a sensitive attribute such as gender,\nrace, religion, etc. in the data, say, due to cultural/historical\ndiscriminatory practices against a certain demographic, the system could\ncontinue discrimination in decisions by including the said bias in its decision\nrule. We present an information theoretic framework for designing fair\npredictors from data, which aim to prevent discrimination against a specified\nsensitive attribute in a supervised learning setting. We use equalized odds as\nthe criterion for discrimination, which demands that the prediction should be\nindependent of the protected attribute conditioned on the actual label. To\nensure fairness and generalization simultaneously, we compress the data to an\nauxiliary variable, which is used for the prediction task. This auxiliary\nvariable is chosen such that it is decontaminated from the discriminatory\nattribute in the sense of equalized odds. The final predictor is obtained by\napplying a Bayesian decision rule to the auxiliary variable. \n\n"}
{"id": "1801.04668", "contents": "Title: The decoding failure probability of MDPC codes Abstract: Moderate Density Parity Check (MDPC) codes are defined here as codes which\nhave a parity-check matrix whose row weight is $O(\\sqrt{n})$ where $n$ is the\nlength $n$ of the code. They can be decoded like LDPC codes but they decode\nmuch less errors than LDPC codes: the number of errors they can decode in this\ncase is of order $\\Theta(\\sqrt{n})$. Despite this fact they have been proved\nvery useful in cryptography for devising key exchange mechanisms. They have\nalso been proposed in McEliece type cryptosystems. However in this case, the\nparameters that have been proposed in \\cite{MTSB13} were broken in\n\\cite{GJS16}. This attack exploits the fact that the decoding failure\nprobability is non-negligible. We show here that this attack can be thwarted by\nchoosing the parameters in a more conservative way. We first show that such\ncodes can decode with a simple bit-flipping decoder any pattern of\n$O\\left(\\frac{\\sqrt{n} \\log \\log n}{\\log n}\\right)$ errors. This avoids the\nprevious attack at the cost of significantly increasing the key size of the\nscheme. We then show that under a very reasonable assumption the decoding\nfailure probability decays almost exponentially with the codelength with just\ntwo iterations of bit-flipping. With an additional assumption it has even been\nproved that it decays exponentially with an unbounded number of iterations and\nwe show that in this case the increase of the key size which is required for\nresisting to the attack of \\cite{GJS16} is only moderate. \n\n"}
{"id": "1801.05386", "contents": "Title: Physics with Reactor Neutrinos Abstract: Neutrinos produced by nuclear reactors have played a major role in advancing\nour knowledge of the properties of neutrinos. The first direct detection of the\nneutrino, confirming its existence, was performed using reactor neutrinos. More\nrecent experiments utilizing reactor neutrinos have also found clear evidence\nfor neutrino oscillation, providing unique input for the determination of\nneutrino mass and mixing. Ongoing and future reactor neutrino experiments will\nexplore other important issues, including the neutrino mass hierarchy and the\nsearch for sterile neutrinos and other new physics beyond the standard model.\nIn this article, we review the recent progress in physics using reactor\nneutrinos and the opportunities they offer for future discoveries. \n\n"}
{"id": "1801.05655", "contents": "Title: Rate-Distortion Performance of Sequential Massive Random Access to\n  Gaussian Sources with Memory Abstract: In Sequential Massive Random Access (SMRA), a set of correlated sources is\njointly encoded and stored on a server, and clients want to access to only a\nsubset of the sources. Since the number of simultaneous clients can be huge,\nthe server is only authorized to extract a bitstream from the stored data: no\nre-encoding can be performed before the transmission of a request. In this\npaper, we investigate the SMRA performance of lossy source coding of Gaussian\nsources with memory. In practical applications such as Free Viewpoint\nTelevision, this model permits to take into account not only inter but also\nintra correlation between sources. For this model, we provide the storage and\ntransmission rates that are achievable for SMRA under some distortion\nconstraint, and we consider two particular examples of Gaussian sources with\nmemory. \n\n"}
{"id": "1801.05926", "contents": "Title: The Utility Cost of Robust Privacy Guarantees Abstract: Consider a data publishing setting for a data set with public and private\nfeatures. The objective of the publisher is to maximize the amount of\ninformation about the public features in a revealed data set, while keeping the\ninformation leaked about the private features bounded. The goal of this paper\nis to analyze the performance of privacy mechanisms that are constructed to\nmatch the distribution learned from the data set. Two distinct scenarios are\nconsidered: (i) mechanisms are designed to provide a privacy guarantee for the\nlearned distribution; and (ii) mechanisms are designed to provide a privacy\nguarantee for every distribution in a given neighborhood of the learned\ndistribution. For the first scenario, given any privacy mechanism, upper bounds\non the difference between the privacy-utility guarantees for the learned and\ntrue distributions are presented. In the second scenario, upper bounds on the\nreduction in utility incurred by providing a uniform privacy guarantee are\ndeveloped. \n\n"}
{"id": "1801.06022", "contents": "Title: Reconstruction Codes for DNA Sequences with Uniform Tandem-Duplication\n  Errors Abstract: DNA as a data storage medium has several advantages, including far greater\ndata density compared to electronic media. We propose that schemes for data\nstorage in the DNA of living organisms may benefit from studying the\nreconstruction problem, which is applicable whenever multiple reads of noisy\ndata are available. This strategy is uniquely suited to the medium, which\ninherently replicates stored data in multiple distinct ways, caused by\nmutations. We consider noise introduced solely by uniform tandem-duplication,\nand utilize the relation to constant-weight integer codes in the Manhattan\nmetric. By bounding the intersection of the cross-polytope with hyperplanes, we\nprove the existence of reconstruction codes with greater capacity than known\nerror-correcting codes, which we can determine analytically for any set of\nparameters. \n\n"}
{"id": "1801.07484", "contents": "Title: Protograph-based Quasi-Cyclic MDPC Codes for McEliece Cryptosystems Abstract: In this paper, ensembles of quasi-cyclic moderate-density parity-check (MDPC)\ncodes based on protographs are introduced and analyzed in the context of a\nMcEliece-like cryptosystem. The proposed ensembles significantly improve the\nerror correction capability of the regular MDPC code ensembles that are\ncurrently considered for post-quantum cryptosystems without increasing the\npublic key size. The proposed ensembles are analyzed in the asymptotic setting\nvia density evolution, both under the sum-product algorithm and a\nlow-complexity (error-and-erasure) message passing algorithm. The asymptotic\nanalysis is complemented at finite block lengths by Monte Carlo simulations.\nThe enhanced error correction capability remarkably improves the scheme\nrobustness with respect to (known) decoding attacks. \n\n"}
{"id": "1801.07839", "contents": "Title: Improved list-decodability of random linear binary codes Abstract: There has been a great deal of work establishing that random linear codes are\nas list-decodable as uniformly random codes, in the sense that a random linear\nbinary code of rate $1 - H(p) - \\epsilon$ is $(p,O(1/\\epsilon))$-list-decodable\nwith high probability. In this work, we show that such codes are $(p,\nH(p)/\\epsilon + 2)$-list-decodable with high probability, for any $p \\in (0,\n1/2)$ and $\\epsilon > 0$. In addition to improving the constant in known\nlist-size bounds, our argument, which is quite simple, works simultaneously for\nall values of $p$, while previous works obtaining $L = O(1/\\epsilon)$ patched\ntogether different arguments to cover different parameter regimes.\n  Our approach is to strengthen an existential argument of (Guruswami,\nH{\\aa}stad, Sudan and Zuckerman, IEEE Trans. IT, 2002) to hold with high\nprobability. To complement our upper bound for random linear codes, we also\nimprove an argument of (Guruswami, Narayanan, IEEE Trans. IT, 2014) to obtain\nan essentially tight lower bound of $1/\\epsilon$ on the list size of uniformly\nrandom codes; this implies that random linear codes are in fact more\nlist-decodable than uniformly random codes, in the sense that the list sizes\nare strictly smaller.\n  To demonstrate the applicability of these techniques, we use them to (a)\nobtain more information about the distribution of list sizes of random linear\ncodes and (b) to prove a similar result for random linear rank-metric codes. \n\n"}
{"id": "1801.09542", "contents": "Title: Quantized Constant Envelope Precoding with PSK and QAM Signaling Abstract: Coarsely quantized massive Multiple-Input Multiple-Output (MIMO) systems are\ngaining more interest due to their power efficiency. We present a new precoding\ntechnique to mitigate the Multi-User Interference (MUI) and the quantization\ndistortions in a downlink Multi-User (MU) MIMO system with coarsely Quantized\nConstant Envelope (QCE) signals at the transmitter. The transmit signal vector\nis optimized for every desired received vector taking into account the QCE\nconstraint. The optimization is based on maximizing the safety margin to the\ndecision thresholds of the receiver constellation modulation. Simulation\nresults show a significant gain in terms of the uncoded Bit Error Ratio (BER)\ncompared to the existing linear precoding techniques. \n\n"}
{"id": "1802.00107", "contents": "Title: Predicting Wireless Channel Features using Neural Networks Abstract: We investigate the viability of using machine-learning techniques for\nestimating user-channel features at a large-array base station (BS). In the\nscenario we consider, user-pilot broadcasts are observed and processed by the\nBS to extract angle-of-arrival (AoA) specific information about\npropagation-channel features, such as received signal strength and relative\npath delay. The problem of interest involves using this information to predict\nthe angle-of-departure (AoD) of the dominant propagation paths in the user\nchannels, i.e., channel features not directly observable at the BS. To\naccomplish this task, the data collected in the same propagation environment\nare used to train neural networks. Our studies rely on ray-tracing channel data\nthat have been calibrated against measurements from Shinjuku Square, a famous\nhotspot in Tokyo, Japan. We demonstrate that the observed features at the BS\nside are correlated with the angular features at the user side. We train neural\nnetworks that exploit different combinations of measured features at the BS to\ninfer the unknown parameters at the users. The evaluation based on standard\nstatistical performance metrics suggests that such data-driven methods have the\npotential to predict unobserved channel features from observed ones. \n\n"}
{"id": "1802.00263", "contents": "Title: Robust Sequential Detection in Distributed Sensor Networks Abstract: We consider the problem of sequential binary hypothesis testing with a\ndistributed sensor network in a non-Gaussian noise environment. To this end, we\npresent a general formulation of the Consensus + Innovations Sequential\nProbability Ratio Test (CISPRT). Furthermore, we introduce two different\nconcepts for robustifying the CISPRT and propose four different algorithms,\nnamely, the Least-Favorable-Density-CISPRT, the Median-CISPRT, the M-CISPRT,\nand the Myriad-CISPRT. Subsequently, we analyze their suitability for different\nbinary hypothesis tests before verifying and evaluating their performance in a\nshift-in-mean and a shift-in-variance scenario. \n\n"}
{"id": "1802.00929", "contents": "Title: On OTFS Modulation for High-Doppler Fading Channels Abstract: Orthogonal time frequency space (OTFS) modulation is a 2-dimensional (2D)\nmodulation scheme designed in the delay-Doppler domain, unlike traditional\nmodulation schemes which are designed in the time-frequency domain. Through a\nseries of 2D transformations, OTFS converts a doubly-dispersive channel into an\nalmost non-fading channel in the delay-Doppler domain. In this domain, each\nsymbol in a frame experiences an almost constant fade, thus achieving\nsignificant performance gains over existing modulation schemes such as OFDM.\nThe sparse delay-Doppler impulse response which reflects the actual physical\ngeometry of the wireless channel enables efficient channel estimation,\nespecially in high-Doppler fading channels. This paper investigates OTFS from a\nsignal detection and channel estimation perspective, and proposes a Markov\nchain Monte-Carlo sampling based detection scheme and a pseudo-random noise\n(PN) pilot based channel estimation scheme in the delay-Doppler domain. \n\n"}
{"id": "1802.01983", "contents": "Title: Storage-Latency Trade-off in Cache-Aided Fog Radio Access Networks Abstract: A fog radio access network (F-RAN) is studied, in which $K_T$ edge nodes\n(ENs) connected to a cloud server via orthogonal fronthaul links, serve $K_R$\nusers through a wireless Gaussian interference channel. Both the ENs and the\nusers have finite-capacity cache memories, which are filled before the user\ndemands are revealed. While a centralized placement phase is used for the ENs,\nwhich model static base stations, a decentralized placement is leveraged for\nthe mobile users. An achievable transmission scheme is presented, which employs\na combination of interference alignment, zero-forcing and interference\ncancellation techniques in the delivery phase, and the \\textit{normalized\ndelivery time} (NDT), which captures the worst-case latency, is analyzed. \n\n"}
{"id": "1802.02049", "contents": "Title: A Distance Between Channels: the average error of mismatched channels Abstract: Two channels are equivalent if their maximum likelihood (ML) decoders\ncoincide for every code. We show that this equivalence relation partitions the\nspace of channels into a generalized hyperplane arrangement. With this, we\ndefine a coding distance between channels in terms of their ML-decoders which\nis meaningful from the decoding point of view, in the sense that the closer two\nchannels are, the larger is the probability of them sharing the same\nML-decoder. We give explicit formulas for these probabilities. \n\n"}
{"id": "1802.02265", "contents": "Title: Hierarchical Erasure Correction of Linear Codes Abstract: Linear codes over finite extension fields have widespread applications in\ntheory and practice. In some scenarios, the decoder has a sequential access to\nthe codeword symbols, giving rise to a hierarchical erasure structure. In this\npaper we develop a mathematical framework for hierarchical erasures over\nextension fields, provide several bounds and constructions, and discuss\npotential applications in distributed storage and flash memories. Our results\nshow intimate connection to Universally Decodable Matrices, as well as to\nReed-Solomon and Gabidulin codes. \n\n"}
{"id": "1802.04838", "contents": "Title: Network Estimation from Point Process Data Abstract: Consider observing a collection of discrete events within a network that\nreflect how network nodes influence one another. Such data are common in spike\ntrains recorded from biological neural networks, interactions within a social\nnetwork, and a variety of other settings. Data of this form may be modeled as\nself-exciting point processes, in which the likelihood of future events depends\non the past events. This paper addresses the problem of estimating\nself-excitation parameters and inferring the underlying functional network\nstructure from self-exciting point process data. Past work in this area was\nlimited by strong assumptions which are addressed by the novel approach here.\nSpecifically, in this paper we (1) incorporate saturation in a point process\nmodel which both ensures stability and models non-linear thresholding effects;\n(2) impose general low-dimensional structural assumptions that include\nsparsity, group sparsity and low-rankness that allows bounds to be developed in\nthe high-dimensional setting; and (3) incorporate long-range memory effects\nthrough moving average and higher-order auto-regressive components. Using our\ngeneral framework, we provide a number of novel theoretical guarantees for\nhigh-dimensional self-exciting point processes that reflect the role played by\nthe underlying network structure and long-term memory. We also provide\nsimulations and real data examples to support our methodology and main results. \n\n"}
{"id": "1802.04923", "contents": "Title: Beamforming with Multiple One-Bit Wireless Transceivers Abstract: Classical beamforming techniques rely on highly linear transmitters and\nreceivers to allow phase-coherent combining at the transmitter and receiver.\nThe transmitter uses beamforming to steer signal power towards the receiver,\nand the receiver uses beamforming to gather and coherently combine the signals\nfrom multiple receiver antennas. When the transmitters and receivers are\ninstead constrained for power and cost reasons to be non-linear one-bit\ndevices, the potential advantages and performance metrics associated with\nbeamforming are not as well understood. We define beamforming at the\ntransmitter as a codebook design problem to maximize the minimum distance\nbetween codewords. We define beamforming at the receiver as the maximum\nlikelihood detector of the transmitted codeword. We show that beamforming with\none-bit transceivers is a constellation design problem, and that we can come\nwithin a few dB SNR of the capacity attained by linear transceivers. \n\n"}
{"id": "1802.04955", "contents": "Title: Multiterminal Secret Key Agreement at Asymptotically Zero Discussion\n  Rate Abstract: In the multiterminal secret key agreement problem, a set of users want to\ndiscuss with each other until they share a common secret key independent of\ntheir discussion. We want to characterize the maximum secret key rate, called\nthe secrecy capacity, asymptotically when the total discussion rate goes to\nzero. In the case of only two users, the capacity is equal to the\nG\\'acs-K\\\"orner common information. However, when there are more than two\nusers, the capacity is unknown. It is plausible that a multivariate extension\nof the G\\'acs-K\\\"orner common information is the capacity, however, proving the\nconverse is challenging. We resolved this for the hypergraphical sources and\nfinite linear sources, and provide efficiently computable characterizations. We\nalso give some ideas of extending the techniques to more general source models. \n\n"}
{"id": "1802.08054", "contents": "Title: VBALD - Variational Bayesian Approximation of Log Determinants Abstract: Evaluating the log determinant of a positive definite matrix is ubiquitous in\nmachine learning. Applications thereof range from Gaussian processes,\nminimum-volume ellipsoids, metric learning, kernel learning, Bayesian neural\nnetworks, Determinental Point Processes, Markov random fields to partition\nfunctions of discrete graphical models. In order to avoid the canonical, yet\nprohibitive, Cholesky $\\mathcal{O}(n^{3})$ computational cost, we propose a\nnovel approach, with complexity $\\mathcal{O}(n^{2})$, based on a constrained\nvariational Bayes algorithm. We compare our method to Taylor, Chebyshev and\nLanczos approaches and show state of the art performance on both synthetic and\nreal-world datasets. \n\n"}
{"id": "1802.09301", "contents": "Title: Dimension-free Information Concentration via Exp-Concavity Abstract: Information concentration of probability measures have important implications\nin learning theory. Recently, it is discovered that the information content of\na log-concave distribution concentrates around their differential entropy,\nalbeit with an unpleasant dependence on the ambient dimension. In this work, we\nprove that if the potentials of the log-concave distribution are exp-concave,\nwhich is a central notion for fast rates in online and statistical learning,\nthen the concentration of information can be further improved to depend only on\nthe exp-concavity parameter, and hence, it can be dimension independent.\nCentral to our proof is a novel yet simple application of the variance\nBrascamp-Lieb inequality. In the context of learning theory, our\nconcentration-of-information result immediately implies high-probability\nresults to many of the previous bounds that only hold in expectation. \n\n"}
{"id": "1803.00680", "contents": "Title: A Tutorial on UAVs for Wireless Networks: Applications, Challenges, and\n  Open Problems Abstract: The use of flying platforms such as unmanned aerial vehicles (UAVs),\npopularly known as drones, is rapidly growing. In particular, with their\ninherent attributes such as mobility, flexibility, and adaptive altitude, UAVs\nadmit several key potential applications in wireless systems. On the one hand,\nUAVs can be used as aerial base stations to enhance coverage, capacity,\nreliability, and energy efficiency of wireless networks. On the other hand,\nUAVs can operate as flying mobile terminals within a cellular network. Such\ncellular-connected UAVs can enable several applications ranging from real-time\nvideo streaming to item delivery. In this paper, a comprehensive tutorial on\nthe potential benefits and applications of UAVs in wireless communications is\npresented. Moreover, the important challenges and the fundamental tradeoffs in\nUAV-enabled wireless networks are thoroughly investigated. In particular, the\nkey UAV challenges such as three-dimensional deployment, performance analysis,\nchannel modeling, and energy efficiency are explored along with representative\nresults. Then, open problems and potential research directions pertaining to\nUAV communications are introduced. Finally, various analytical frameworks and\nmathematical tools such as optimization theory, machine learning, stochastic\ngeometry, transport theory, and game theory are described. The use of such\ntools for addressing unique UAV problems is also presented. In a nutshell, this\ntutorial provides key guidelines on how to analyze, optimize, and design\nUAV-based wireless communication systems. \n\n"}
{"id": "1803.01302", "contents": "Title: Distributed Nonparametric Regression under Communication Constraints Abstract: This paper studies the problem of nonparametric estimation of a smooth\nfunction with data distributed across multiple machines. We assume an\nindependent sample from a white noise model is collected at each machine, and\nan estimator of the underlying true function needs to be constructed at a\ncentral machine. We place limits on the number of bits that each machine can\nuse to transmit information to the central machine. Our results give both\nasymptotic lower bounds and matching upper bounds on the statistical risk under\nvarious settings. We identify three regimes, depending on the relationship\namong the number of machines, the size of the data available at each machine,\nand the communication budget. When the communication budget is small, the\nstatistical risk depends solely on this communication bottleneck, regardless of\nthe sample size. In the regime where the communication budget is large, the\nclassic minimax risk in the non-distributed estimation setting is recovered. In\nan intermediate regime, the statistical risk depends on both the sample size\nand the communication budget. \n\n"}
{"id": "1803.02731", "contents": "Title: Some binary BCH codes with length $n=2^m+1$ Abstract: Under research for near sixty years,\nBose-$\\!$Ray-$\\!$Chaudhuri-$\\!$Hocquenghem(BCH) codes have played increasingly\nimportant roles in many applications such as communication systems, data\nstorage and information security. However, the dimension and minimum distance\nof BCH codes are seldom solved until now because of their intractable\ncharacteristics. The objective of this paper is to study the dimensions of some\nBCH codes of length $n=2^m+1$ with $m=2t+1$, $4t+2$, $8t+4$ and $m\\geq 10$.\nSome new techniques are employed to investigate coset leaders modulo $n$. For\neach type of $m$ above, the first five largest coset leaders modulo $n$ are\ndetermined, the dimension of some BCH codes of length $n$ with designed\ndistance $\\delta>2^{\\lceil \\frac{m}{2} \\rceil}$ is presented. These new\ntechniques and results may be helpful to study other families of cyclic codes\nover finite fields. \n\n"}
{"id": "1803.04038", "contents": "Title: Updating Beamformers to Respond to Changes in Users Abstract: We consider a multi-user multiple-input single-output downlink system that\nprovides each user with a prespecified level of quality-of-service. The base\nstation (BS) designs the beamformers so that each user receives a certain\nsignal-to-interference-and-noise ratio (SINR). In contrast to most of the\navailable literature in the beamforming field, we focus on the required\nmodifications when the system changes. We specifically study three cases: (i)\nuser entering the system, (ii) user leaving the system, and (iii) a change in\nthe SINR target. We do so in order to avoid designing the entire system from\nscratch for every change in the requirements. In each of the three cases, we\ndescribe the modifications required to the beamforming directions and the power\nloading. We consider maximum ratio transmission (MRT), zero-forcing (ZF) and\nthe optimal beamformers. The proposed modifications provide performance that is\neither exact or very close to that obtained when we redesign the entire system,\nwhile having much lower computational cost. \n\n"}
{"id": "1803.05099", "contents": "Title: Noisy Adaptive Group Testing: Bounds and Algorithms Abstract: The group testing problem consists of determining a small set of defective\nitems from a larger set of items based on a number of possibly-noisy tests, and\nis relevant in applications such as medical testing, communication protocols,\npattern matching, and many more. One of the defining features of the group\ntesting problem is the distinction between the non-adaptive and adaptive\nsettings: In the non-adaptive case, all tests must be designed in advance,\nwhereas in the adaptive case, each test can be designed based on the previous\noutcomes. While tight information-theoretic limits and near-optimal practical\nalgorithms are known for the adaptive setting in the absence of noise,\nsurprisingly little is known in the noisy adaptive setting. In this paper, we\naddress this gap by providing information-theoretic achievability and converse\nbounds under various noise models, as well as a slightly weaker achievability\nbound for a computationally efficient variant. These bounds are shown to be\ntight or near-tight in a broad range of scaling regimes, particularly at low\nnoise levels. The algorithms used for the achievability results have the\nnotable feature of only using two or three stages of adaptivity. \n\n"}
{"id": "1803.05844", "contents": "Title: Iterative Turbo Receiver for LDPC-Coded MIMO Systems Based on\n  Semi-definite Relaxation Abstract: In this work, we develop a new iterative turbo receiver for LDPC-coded\nmulti-antenna systems based on semidefinite relaxation (SDR). For a classical\nturbo receiver, forward error correction (FEC) code is only used at decoder.\nNonetheless, by taking advantage of FEC code in the detection stage, our\nproposed SDR detector can output extrinsic information with much improved\nreliability to the decoder. We also propose a simplified SDR turbo receiver\nthat solves only one SDR problem per codeword instead of solving multiple SDR\nproblems in the iterative turbo processing. This scheme significantly reduces\nthe time complexity of SDR turbo receiver, while the error performance remains\nsimilar as before. In fact, our simplified scheme is generic in the sense that\nit is applicable to any list-based iterative receivers. \n\n"}
{"id": "1803.09314", "contents": "Title: A New Reconfigurable Antenna MIMO Architecture for mmWave Communication Abstract: The large spectrum available in the millimeter-Wave (mmWave) band has emerged\nas a promising solution for meeting the huge capacity requirements of the 5th\ngeneration (5G) wireless networks. However, to fully harness the potential of\nmmWave communications, obstacles such as severe path loss, channel sparsity and\nhardware complexity should be overcome. In this paper, we introduce a\ngeneralized reconfigurable antenna multiple-input multiple-output (MIMO)\narchitecture that takes advantage of lens-based reconfigurable antennas. The\nconsidered antennas can support multiple radiation patterns simultaneously by\nusing a single RF chain. The degrees of freedom provided by the reconfigurable\nantennas are used to, first, combat channel sparsity in MIMO mmWave systems.\nFurther, to suppress high path loss and shadowing at mmWave frequencies, we use\na rate-one space-time block code. Our analysis and simulations show that the\nproposed reconfigurable MIMO architecture achieves full-diversity gain by using\nlinear receivers and without requiring channel state information at the\ntransmitter. Moreover, simulations show that the proposed architecture\noutperforms traditional MIMO transmission schemes in mmWave channel settings. \n\n"}
{"id": "1803.10123", "contents": "Title: Task Agnostic Continual Learning Using Online Variational Bayes Abstract: Catastrophic forgetting is the notorious vulnerability of neural networks to\nthe change of the data distribution while learning. This phenomenon has long\nbeen considered a major obstacle for allowing the use of learning agents in\nrealistic continual learning settings. A large body of continual learning\nresearch assumes that task boundaries are known during training. However,\nresearch for scenarios in which task boundaries are unknown during training has\nbeen lacking. In this paper we present, for the first time, a method for\npreventing catastrophic forgetting (BGD) for scenarios with task boundaries\nthat are unknown during training --- task-agnostic continual learning. Code of\nour algorithm is available at https://github.com/igolan/bgd. \n\n"}
{"id": "1804.00335", "contents": "Title: Online learning with graph-structured feedback against adaptive\n  adversaries Abstract: We derive upper and lower bounds for the policy regret of $T$-round online\nlearning problems with graph-structured feedback, where the adversary is\nnonoblivious but assumed to have a bounded memory. We obtain upper bounds of\n$\\widetilde O(T^{2/3})$ and $\\widetilde O(T^{3/4})$ for strongly-observable and\nweakly-observable graphs, respectively, based on analyzing a variant of the\nExp3 algorithm. When the adversary is allowed a bounded memory of size 1, we\nshow that a matching lower bound of $\\widetilde\\Omega(T^{2/3})$ is achieved in\nthe case of full-information feedback. We also study the particular loss\nstructure of an oblivious adversary with switching costs, and show that in such\na setting, non-revealing strongly-observable feedback graphs achieve a lower\nbound of $\\widetilde\\Omega(T^{2/3})$, as well. \n\n"}
{"id": "1804.01619", "contents": "Title: Stability and Convergence Trade-off of Iterative Optimization Algorithms Abstract: The overall performance or expected excess risk of an iterative machine\nlearning algorithm can be decomposed into training error and generalization\nerror. While the former is controlled by its convergence analysis, the latter\ncan be tightly handled by algorithmic stability. The machine learning community\nhas a rich history investigating convergence and stability separately. However,\nthe question about the trade-off between these two quantities remains open. In\nthis paper, we show that for any iterative algorithm at any iteration, the\noverall performance is lower bounded by the minimax statistical error over an\nappropriately chosen loss function class. This implies an important trade-off\nbetween convergence and stability of the algorithm -- a faster converging\nalgorithm has to be less stable, and vice versa. As a direct consequence of\nthis fundamental tradeoff, new convergence lower bounds can be derived for\nclasses of algorithms constrained with different stability bounds. In\nparticular, when the loss function is convex (or strongly convex) and smooth,\nwe discuss the stability upper bounds of gradient descent (GD) and stochastic\ngradient descent and their variants with decreasing step sizes. For Nesterov's\naccelerated gradient descent (NAG) and heavy ball method (HB), we provide\nstability upper bounds for the quadratic loss function. Applying existing\nstability upper bounds for the gradient methods in our trade-off framework, we\nobtain lower bounds matching the well-established convergence upper bounds up\nto constants for these algorithms and conjecture similar lower bounds for NAG\nand HB. Finally, we numerically demonstrate the tightness of our stability\nbounds in terms of exponents in the rate and also illustrate via a simulated\nlogistic regression problem that our stability bounds reflect the\ngeneralization errors better than the simple uniform convergence bounds for GD\nand NAG. \n\n"}
{"id": "1804.01797", "contents": "Title: Composable, Unconditionally Secure Message Authentication without any\n  Secret Key Abstract: We consider a setup in which the channel from Alice to Bob is less noisy than\nthe channel from Eve to Bob. We show that there exist encoding and decoding\nwhich accomplish error correction and authentication simultaneously; that is,\nBob is able to correctly decode a message coming from Alice and reject a\nmessage coming from Eve with high probability. The system does not require any\nsecret key shared between Alice and Bob, provides information theoretic\nsecurity, and can safely be composed with other protocols in an arbitrary\ncontext. \n\n"}
{"id": "1804.04826", "contents": "Title: On Deep Learning-based Massive MIMO Indoor User Localization Abstract: We examine the usability of deep neural networks for multiple-input\nmultiple-output (MIMO) user positioning solely based on the orthogonal\nfrequency division multiplex (OFDM) complex channel coefficients. In contrast\nto other indoor positioning systems (IPSs), the proposed method does not\nrequire any additional piloting overhead or any other changes in the\ncommunications system itself as it is deployed on top of an existing OFDM MIMO\nsystem. Supported by actual measurements, we are mainly interested in the more\nchallenging non-line of sight (NLoS) scenario. However, gradient descent\noptimization is known to require a large amount of data-points for training,\ni.e., the required database would be too large when compared to conventional\nmethods. Thus, we propose a twostep training procedure, with training on\nsimulated line of sight (LoS) data in the first step, and finetuning on\nmeasured NLoS positions in the second step. This turns out to reduce the\nrequired measured training positions and thus, reduces the effort for data\nacquisition. \n\n"}
{"id": "1804.06561", "contents": "Title: A Mean Field View of the Landscape of Two-Layers Neural Networks Abstract: Multi-layer neural networks are among the most powerful models in machine\nlearning, yet the fundamental reasons for this success defy mathematical\nunderstanding. Learning a neural network requires to optimize a non-convex\nhigh-dimensional objective (risk function), a problem which is usually attacked\nusing stochastic gradient descent (SGD). Does SGD converge to a global optimum\nof the risk or only to a local optimum? In the first case, does this happen\nbecause local minima are absent, or because SGD somehow avoids them? In the\nsecond, why do local minima reached by SGD have good generalization properties?\n  In this paper we consider a simple case, namely two-layers neural networks,\nand prove that -in a suitable scaling limit- SGD dynamics is captured by a\ncertain non-linear partial differential equation (PDE) that we call\ndistributional dynamics (DD). We then consider several specific examples, and\nshow how DD can be used to prove convergence of SGD to networks with nearly\nideal generalization error. This description allows to 'average-out' some of\nthe complexities of the landscape of neural networks, and can be used to prove\na general convergence result for noisy SGD. \n\n"}
{"id": "1804.06679", "contents": "Title: Understanding Neural Networks and Individual Neuron Importance via\n  Information-Ordered Cumulative Ablation Abstract: In this work, we investigate the use of three information-theoretic\nquantities -- entropy, mutual information with the class variable, and a class\nselectivity measure based on Kullback-Leibler divergence -- to understand and\nstudy the behavior of already trained fully-connected feed-forward neural\nnetworks. We analyze the connection between these information-theoretic\nquantities and classification performance on the test set by cumulatively\nablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our\nresults parallel those recently published by Morcos et al., indicating that\nclass selectivity is not a good indicator for classification performance.\nHowever, looking at individual layers separately, both mutual information and\nclass selectivity are positively correlated with classification performance, at\nleast for networks with ReLU activation functions. We provide explanations for\nthis phenomenon and conclude that it is ill-advised to compare the proposed\ninformation-theoretic quantities across layers. Furthermore, we show that\ncumulative ablation of neurons with ascending or descending\ninformation-theoretic quantities can be used to formulate hypotheses regarding\nthe joint behavior of multiple neurons, such as redundancy and synergy, with\ncomparably low computational cost. We also draw connections to the information\nbottleneck theory for neural networks. \n\n"}
{"id": "1804.07809", "contents": "Title: Weights which respect support and NN-decoding Abstract: In this work we explore a family of metrics over finite fields which respect\nthe support of vectors. We show how these metrics can be obtained from the\nedge-weighted Hamming cube and, based on this representation we give a\ndescription of a group of linear isometries (with respect to the metric). Next\nwe introduce the concept of conditional sum of metrics and determine what\nconditions determine a metric respecting support, out of two such given\nmetrics. Finally we introduce the labeled-poset block metrics, a new family of\nmetrics which respects support of vector, filling a gap existing in the known\nsuch metrics. For this family we give a full description of the group of linear\nisometries and determine necessary and sufficient conditions for the existence\nof a MacWilliams identity. \n\n"}
{"id": "1804.10335", "contents": "Title: Communication, Computing and Caching for Mobile VR Delivery: Modeling\n  and Trade-off Abstract: Mobile virtual reality (VR) delivery is gaining increasing attention from\nboth industry and academia due to its ability to provide an immersive\nexperience. However, achieving mobile VR delivery requires ultra-high\ntransmission rate, deemed as a first killer application for 5G wireless\nnetworks. In this paper, in order to alleviate the traffic burden over wireless\nnetworks, we develop an implementation framework for mobile VR delivery by\nutilizing caching and computing capabilities of mobile VR device. We then\njointly optimize the caching and computation offloading policy for minimizing\nthe required average transmission rate under the latency and local average\nenergy consumption constraints. In a symmetric scenario, we obtain the optimal\njoint policy and the closed-form expression of the minimum average transmission\nrate. Accordingly, we analyze the tradeoff among communication, computing and\ncaching, and then reveal analytically the fact that the communication overhead\ncan be traded by the computing and caching capabilities of mobile VR device,\nand also what conditions must be met for it to happen. Finally, we discuss the\noptimization problem in a heterogeneous scenario, and propose an efficient\nsuboptimal algorithm with low computation complexity, which is shown to achieve\ngood performance in the numerical results. \n\n"}
{"id": "1804.10729", "contents": "Title: Secure Computation-and-Forward with Linear Codes Abstract: We discuss secure transmission via an untrusted relay when we have a multiple\naccess phase from two nodes to the relay and broadcast phase from the relay to\nthe two nodes. To realize the security, we construct a code that securely\ntransmits the modulo sum of the messages of two nodes via a multiple access\nchannel. In this code, the relay cannot obtain any information for the message\nof each node, and can decode only the messages of the two nodes. Our code is\nconstructed by simple combination of an existing liner code and universal2 hash\nfunction. \n\n"}
{"id": "1805.00061", "contents": "Title: Machine Learning for Predictive On-Demand Deployment of UAVs for\n  Wireless Communications Abstract: In this paper, a novel machine learning (ML) framework is proposed for\nenabling a predictive, efficient deployment of unmanned aerial vehicles (UAVs),\nacting as aerial base stations (BSs), to provide on-demand wireless service to\ncellular users. In order to have a comprehensive analysis of cellular traffic,\nan ML framework based on a Gaussian mixture model (GMM) and a weighted\nexpectation maximization (WEM) algorithm is introduced to predict the potential\nnetwork congestion. Then, the optimal deployment of UAVs is studied to minimize\nthe transmit power needed to satisfy the communication demand of users in the\ndownlink, while also minimizing the power needed for UAV mobility, based on the\npredicted cellular traffic. To this end, first, the optimal partition of\nservice areas of each UAV is derived, based on a fairness principle. Next, the\noptimal location of each UAV that minimizes the total power consumption is\nderived. Simulation results show that the proposed ML approach can reduce the\nrequired downlink transmit power and improve the power efficiency by over 20%,\ncompared with an optimal deployment of UAVs with no ML prediction. \n\n"}
{"id": "1805.03165", "contents": "Title: A construction of product blocks with a fixed block size Abstract: Let $M(n,d)$ be the maximum size of a permutation array on $n$ symbols with\npairwise Hamming distance at least $d$. Some permutation arrays can be\nconstructed using blocks of certain type [2] called product blocks in this\npaper. We study the problem of designing $(q,k)$-product blocks with a fixed\nblock size $k$. \n\n"}
{"id": "1805.04077", "contents": "Title: Prompt and non-prompt $J/\\psi$ and $\\psi(2\\mathrm{S})$ suppression at\n  high transverse momentum in 5.02 TeV Pb+Pb collisions with the ATLAS\n  experiment Abstract: A measurement of $J/\\psi$ and $\\psi(2\\mathrm{S})$ production is presented. It\nis based on a data sample from Pb+Pb collisions at $\\sqrt{s_{\\mathrm{NN}}}$ =\n5.02 TeV and $pp$ collisions at $\\sqrt{s}$ = 5.02 TeV recorded by the ATLAS\ndetector at the LHC in 2015, corresponding to an integrated luminosity of\n$0.42\\mathrm{nb}^{-1}$ and $25\\mathrm{pb}^{-1}$ in Pb+Pb and $pp$,\nrespectively. The measurements of per-event yields, nuclear modification\nfactors, and non-prompt fractions are performed in the dimuon decay channel for\n$9 < p_{T}^{\\mu\\mu} < 40$ GeV in dimuon transverse momentum, and $-2.0 <\ny_{\\mu\\mu} < 2.0$ in rapidity. Strong suppression is found in Pb+Pb collisions\nfor both prompt and non-prompt $J/\\psi$, as well as for prompt and non-prompt\n$\\psi(2\\mathrm{S})$, increasing with event centrality. The suppression of\nprompt $\\psi(2\\mathrm{S})$ is observed to be stronger than that of $J/\\psi$,\nwhile the suppression of non-prompt $\\psi(2\\mathrm{S})$ is equal to that of the\nnon-prompt $J/\\psi$ within uncertainties, consistent with the expectation that\nboth arise from \\textit{b}-quarks propagating through the medium. Despite\nprompt and non-prompt $J/\\psi$ arising from different mechanisms, the\ndependence of their nuclear modification factors on centrality is found to be\nquite similar. \n\n"}
{"id": "1805.04625", "contents": "Title: Strong Converse using Change of Measure Arguments Abstract: The strong converse for a coding theorem shows that the optimal asymptotic\nrate possible with vanishing error cannot be improved by allowing a fixed\nerror. Building on a method introduced by Gu and Effros for centralized coding\nproblems, we develop a general and simple recipe for proving strong converse\nthat is applicable for distributed problems as well. Heuristically, our proof\nof strong converse mimics the standard steps for proving a weak converse,\nexcept that we apply those steps to a modified distribution obtained by\nconditioning the original distribution on the event that no error occurs. A key\ncomponent of our recipe is the replacement of the hard Markov constraints\nimplied by the distributed nature of the problem with a soft information cost\nusing a variational formula introduced by Oohama. We illustrate our method by\nproviding a short proof of the strong converse for the Wyner-Ziv problem and\nstrong converse theorems for interactive function computation, common\nrandomness and secret key agreement, and the wiretap channel; the latter three\nstrong converse problems were open prior to this work. \n\n"}
{"id": "1805.06182", "contents": "Title: Covert Wireless Communications with Active Eavesdropper on AWGN Channels Abstract: Covert wireless communication can prevent an adversary from knowing the\nexistence of user's transmission, thus provide stronger security protection. In\nAWGN channels, a square root law was obtained and the result shows that Alice\ncan reliably and covertly transmit $\\mathcal{O}(\\sqrt{n})$ bits to Bob in n\nchannel uses in the presence of a passive eavesdropper (Willie). However,\nexisting work presupposes that Willie is static and only samples the channels\nat a fixed place. If Willie can dynamically adjust the testing distance between\nhim and Alice according to his sampling values, his detection probability of\nerror can be reduced significantly via a trend test. We found that, if Alice\nhas no prior knowledge about Willie, she cannot hide her transmission behavior\nin the presence of an active Willie, and the square root law does not hold in\nthis situation. We then proposed a novel countermeasure to deal with the active\nWillie. Through randomized transmission scheduling, Willie cannot detect\nAlice's transmission attempts if Alice can set her transmission probability\nbelow a threshold. Additionally, we systematically evaluated the security\nproperties of covert communications in a dense wireless network, and proposed a\ndensity-based routing scheme to deal with multi-hop covert communication in a\nwireless network. As the network grows denser, Willie's uncertainty increases,\nand finally resulting in a \"shadow\" network to Willie. \n\n"}
{"id": "1805.06597", "contents": "Title: ARUM: Polar Coded HARQ Scheme based on Incremental Channel Polarization Abstract: A hybrid ARQ (HARQ) scheme for polar code, which is called active-bit\nrelocation under masks (ARUM), is proposed. In each transmission, the data bits\nare encoded and bit-wisely XOR-masked using a binary vector before being\ntransmitted through the channel. The masking process combines multiple\ntransmissions together which forms another step of inter-transmission channel\ntransform. The reliabilities are updated after every transmission, and the less\nreliable bits in earlier ones are relocated to the more reliable positions at\nthe latest transmitted block. ARUM is a very flexible HARQ scheme which allows\neach transmission to have a different mother code length and to adopt\nindependent rate-matching scheme with sufficient channel state feedback in HARQ\nprocess. Simulation shows that ARUM can obtain near-optimal coding gain. \n\n"}
{"id": "1805.07040", "contents": "Title: UAV-Enabled Radio Access Network: Multi-Mode Communication and\n  Trajectory Design Abstract: In this paper, we consider an unmanned aerial vehicle (UAV)-enabled radio\naccess network (RAN) with the UAV acting as an aerial platform to communicate\nwith a set of ground users (GUs) in a variety of modes of practical interest,\nincluding data collection in the uplink, data transmission in the downlink, and\ndata relaying between GUs involving both the uplink and downlink. Under this\ngeneral framework, two UAV operation scenarios are considered: periodic\noperation, where the UAV serves the GUs in a periodic manner by following a\ncertain trajectory repeatedly, and one-time operation where the UAV serves the\nGUs with one single fly and then leaves for another mission. In each scenario,\nwe aim to minimize the UAV periodic flight duration or mission completion time,\nwhile satisfying the target rate requirement of each GU via a joint UAV\ntrajectory and communication resource allocation design approach. Iterative\nalgorithms are proposed to find efficient locally optimal solutions by\nutilizing successive convex optimization and block coordinate descent\ntechniques. Moreover, as the quality of the solutions obtained by the proposed\nalgorithms critically depends on the initial UAV trajectory adopted, we propose\nnew methods to design the initial trajectories for both operation scenarios by\nleveraging the existing results for solving the classic Traveling Salesman\nProblem (TSP) and Pickup-and-Delivery Problem (PDP). Numerical results show\nthat the proposed trajectory initialization designs lead to significant\nperformance gains compared to the benchmark initialization based on circular\ntrajectory. \n\n"}
{"id": "1805.07418", "contents": "Title: Sequential Learning of Principal Curves: Summarizing Data Streams on the\n  Fly Abstract: When confronted with massive data streams, summarizing data with dimension\nreduction methods such as PCA raises theoretical and algorithmic pitfalls.\nPrincipal curves act as a nonlinear generalization of PCA and the present paper\nproposes a novel algorithm to automatically and sequentially learn principal\ncurves from data streams. We show that our procedure is supported by regret\nbounds with optimal sublinear remainder terms. A greedy local search\nimplementation (called \\texttt{slpc}, for Sequential Learning Principal Curves)\nthat incorporates both sleeping experts and multi-armed bandit ingredients is\npresented, along with its regret computation and performance on synthetic and\nreal-life data. \n\n"}
{"id": "1805.09066", "contents": "Title: Asymptotic Performance Analysis of GSVD-NOMA Systems with a Large-Scale\n  Antenna Array Abstract: This paper considers a multiple-input multiple-output (MIMO) downlink\ncommunication scenario with one base station and two users, where each user is\nequipped with m antennas and the base station is equipped with n antennas. To\nefficiently exploit the spectrum resources, we propose a transmission protocol\nwhich combines generalized singular value decomposition (GSVD) and\nnon-orthogonal multiple access (NOMA). The average data rates achieved by the\ntwo users are adopted as performance metrics for evaluation of the proposed\nGSVD-NOMA scheme. In particular, we first characterize the limiting\ndistribution of the squared generalized singular values of the two users'\nchannel matrices for the asymptotic case where the numbers of transmit and\nreceive antennas approach infinity. Then, we calculate the normalized average\nindividual rates of the users in the considered asymptotic regime. Furthermore,\nwe extend the proposed GSVD-NOMA scheme to the MIMO downlink communication\nscenario with more than two users by using a hybrid multiple access (MA)\napproach, where the base station first divides the users into different groups,\nthen the proposed GSVD-NOMA scheme is implemented within each group, and\ndifferent groups are allocated with orthogonal bandwidth resources. Finally,\nnumerical results are provided to validate the effectiveness of the proposed\nGSVD-NOMA protocol, and the accuracy of the developed analytical results. \n\n"}
{"id": "1805.09081", "contents": "Title: Local Tomography of Large Networks under the Low-Observability Regime Abstract: This article studies the problem of reconstructing the topology of a network\nof interacting agents via observations of the state-evolution of the agents. We\nfocus on the large-scale network setting with the additional constraint of\n$partial$ observations, where only a small fraction of the agents can be\nfeasibly observed. The goal is to infer the underlying subnetwork of\ninteractions and we refer to this problem as $local$ $tomography$. In order to\nstudy the large-scale setting, we adopt a proper stochastic formulation where\nthe unobserved part of the network is modeled as an Erd\\\"{o}s-R\\'enyi random\ngraph, while the observable subnetwork is left arbitrary. The main result of\nthis work is establishing that, under this setting, local tomography is\nactually possible with high probability, provided that certain conditions on\nthe network model are met (such as stability and symmetry of the network\ncombination matrix). Remarkably, such conclusion is established under the\n$low$-$observability$ $regime$, where the cardinality of the observable\nsubnetwork is fixed, while the size of the overall network scales to infinity. \n\n"}
{"id": "1805.09342", "contents": "Title: Hierarchy of azimuthal anisotropy harmonics in collisions of small\n  systems from the Color Glass Condensate Abstract: We demonstrate that the striking systematics of two-particle azimuthal\nFourier harmonics $v_2$ and $v_3$ in ultrarelativistic collisions of protons,\ndeuterons and helium-3 ions off gold nuclei measured by the PHENIX\nCollaboration [arXiv:1805.02973] at the Relativistic Heavy Ion Collider (RHIC)\nis reproduced in the Color Glass Condensate (CGC) effective field theory. This\ncontradicts the claim in [arXiv:1805.02973] that their data rules out initial\nstate based explanations. The underlying systematics of the effect, as\ndiscussed previously in [arXiv:1705.00745,arXiv:1706.06260,arXiv:1801.09704],\narise from the differing structure of strong color correlations between gluon\ndomains of size $1/Q_S$ at fine ($p_\\perp \\gtrapprox Q_S$) or coarser ($p_\\perp\n\\lessapprox Q_S$) transverse momentum resolution. Further tests of the limits\nof validity of this framework can be carried out in light-heavy ion collisions\nat both RHIC and the Large Hadron Collider. Such measurements also offer novel\nopportunities for further exploration of the role of the surprisingly large\nshort-range nuclear correlations measured at Jefferson Lab. \n\n"}
{"id": "1805.11259", "contents": "Title: Statistical mechanical analysis of sparse linear regression as a\n  variable selection problem Abstract: An algorithmic limit of compressed sensing or related variable-selection\nproblems is analytically evaluated when a design matrix is given by an\novercomplete random matrix. The replica method from statistical mechanics is\nemployed to derive the result. The analysis is conducted through evaluation of\nthe entropy, an exponential rate of the number of combinations of variables\ngiving a specific value of fit error to given data which is assumed to be\ngenerated from a linear process using the design matrix. This yields the\ntypical achievable limit of the fit error when solving a representative\n$\\ell_0$ problem and includes the presence of unfavourable phase transitions\npreventing local search algorithms from reaching the minimum-error\nconfiguration. The associated phase diagrams are presented. A noteworthy\noutcome of the phase diagrams is that there exists a wide parameter region\nwhere any phase transition is absent from the high temperature to the lowest\ntemperature at which the minimum-error configuration or the ground state is\nreached. This implies that certain local search algorithms can find the ground\nstate with moderate computational costs in that region. Another noteworthy\nresult is the presence of the random first-order transition in the strong noise\ncase. The theoretical evaluation of the entropy is confirmed by extensive\nnumerical methods using the exchange Monte Carlo and the multi-histogram\nmethods. Another numerical test based on a metaheuristic optimisation algorithm\ncalled simulated annealing is conducted, which well supports the theoretical\npredictions on the local search algorithms. In the successful region with no\nphase transition, the computational cost of the simulated annealing to reach\nthe ground state is estimated as the third order polynomial of the model\ndimensionality. \n\n"}
{"id": "1805.11666", "contents": "Title: Why Botnets Work: Distributed Brute-Force Attacks Need No\n  Synchronization Abstract: In September 2017, McAffee Labs quarterly report estimated that brute force\nattacks represent 20\\% of total network attacks, making them the most prevalent\ntype of attack ex-aequo with browser based vulnerabilities. These attacks have\nsometimes catastrophic consequences, and understanding their fundamental limits\nmay play an important role in the risk assessment of password-secured systems,\nand in the design of better security protocols. While some solutions exist to\nprevent online brute-force attacks that arise from one single IP address,\nattacks performed by botnets are more challenging. In this paper, we analyze\nthese distributed attacks by using a simplified model. Our aim is to understand\nthe impact of distribution and asynchronization on the overall computational\neffort necessary to breach a system. Our result is based on Guesswork, a\nmeasure of the number of queries (guesses) required of an adversary before a\ncorrect sequence, such as a password, is found in an optimal attack. Guesswork\nis a direct surrogate for time and computational effort of guessing a sequence\nfrom a set of sequences with associated likelihoods. We model the lack of\nsynchronization by a worst-case optimization in which the queries made by\nmultiple adversarial agents are received in the worst possible order for the\nadversary, resulting in a min-max formulation. We show that, even without\nsynchronization, and for sequences of growing length, the asymptotic optimal\nperformance is achievable by using randomized guesses drawn from an appropriate\ndistribution. Therefore, randomization is key for distributed asynchronous\nattacks. In other words, asynchronous guessers can asymptotically perform\nbrute-force attacks as efficiently as synchronized guessers. \n\n"}
{"id": "1805.12451", "contents": "Title: Simulation of Random Variables under R\\'enyi Divergence Measures of All\n  Orders Abstract: The random variable simulation problem consists in using a $k$-dimensional\ni.i.d. random vector $X^{k}$ with distribution $P_{X}^{k}$ to simulate an\n$n$-dimensional i.i.d. random vector $Y^{n}$ so that its distribution is\napproximately $Q_{Y}^{n}$. In contrast to previous works, in this paper we\nconsider the standard R\\'enyi divergence and two variants of all orders to\nmeasure the level of approximation. These two variants are the max-R\\'enyi\ndivergence $D_{\\alpha}^{\\mathsf{max}}(P,Q)$ and the sum-R\\'enyi divergence\n$D_{\\alpha}^{+}(P,Q)$. When $\\alpha=\\infty$, these two measures are strong\nbecause for any $\\epsilon>0$, $D_{\\infty}^{\\mathsf{max}}(P,Q)\\leq\\epsilon$ or\n$D_{\\infty}^{+}(P,Q)\\leq\\epsilon$ implies\n$e^{-\\epsilon}\\leq\\frac{P(x)}{Q(x)}\\leq e^{\\epsilon}$ for all $x$. Under these\nR\\'enyi divergence measures, we characterize the asymptotics of normalized\ndivergences as well as the R\\'enyi conversion rates. The latter is defined as\nthe supremum of $\\frac{n}{k}$ such that the R\\'enyi divergences vanish\nasymptotically. In addition, when the R\\'enyi parameter is in the interval\n$(0,1)$, the R\\'enyi conversion rates equal the ratio of the Shannon entropies\n$\\frac{H\\left(P_{X}\\right)}{H\\left(Q_{Y}\\right)}$, which is consistent with\ntraditional results in which the total variation measure was adopted. When the\nR\\'enyi parameter is in the interval $(1,\\infty]$, the R\\'enyi conversion rates\nare, in general, smaller than\n$\\frac{H\\left(P_{X}\\right)}{H\\left(Q_{Y}\\right)}$. When specialized to the case\nin which either $P_{X}$ or $Q_{Y}$ is uniform, the simulation problem reduces\nto the source resolvability and intrinsic randomness problems. The preceding\nresults are used to characterize the asymptotics of R\\'enyi divergences and the\nR\\'enyi conversion rates for these two cases. \n\n"}
{"id": "1805.12451", "contents": "Title: Simulation of Random Variables under R\\'enyi Divergence Measures of All\n  Orders Abstract: The random variable simulation problem consists in using a $k$-dimensional\ni.i.d. random vector $X^{k}$ with distribution $P_{X}^{k}$ to simulate an\n$n$-dimensional i.i.d. random vector $Y^{n}$ so that its distribution is\napproximately $Q_{Y}^{n}$. In contrast to previous works, in this paper we\nconsider the standard R\\'enyi divergence and two variants of all orders to\nmeasure the level of approximation. These two variants are the max-R\\'enyi\ndivergence $D_{\\alpha}^{\\mathsf{max}}(P,Q)$ and the sum-R\\'enyi divergence\n$D_{\\alpha}^{+}(P,Q)$. When $\\alpha=\\infty$, these two measures are strong\nbecause for any $\\epsilon>0$, $D_{\\infty}^{\\mathsf{max}}(P,Q)\\leq\\epsilon$ or\n$D_{\\infty}^{+}(P,Q)\\leq\\epsilon$ implies\n$e^{-\\epsilon}\\leq\\frac{P(x)}{Q(x)}\\leq e^{\\epsilon}$ for all $x$. Under these\nR\\'enyi divergence measures, we characterize the asymptotics of normalized\ndivergences as well as the R\\'enyi conversion rates. The latter is defined as\nthe supremum of $\\frac{n}{k}$ such that the R\\'enyi divergences vanish\nasymptotically. In addition, when the R\\'enyi parameter is in the interval\n$(0,1)$, the R\\'enyi conversion rates equal the ratio of the Shannon entropies\n$\\frac{H\\left(P_{X}\\right)}{H\\left(Q_{Y}\\right)}$, which is consistent with\ntraditional results in which the total variation measure was adopted. When the\nR\\'enyi parameter is in the interval $(1,\\infty]$, the R\\'enyi conversion rates\nare, in general, smaller than\n$\\frac{H\\left(P_{X}\\right)}{H\\left(Q_{Y}\\right)}$. When specialized to the case\nin which either $P_{X}$ or $Q_{Y}$ is uniform, the simulation problem reduces\nto the source resolvability and intrinsic randomness problems. The preceding\nresults are used to characterize the asymptotics of R\\'enyi divergences and the\nR\\'enyi conversion rates for these two cases. \n\n"}
{"id": "1805.12469", "contents": "Title: New lower bounds to the output entropy of multi-mode quantum Gaussian\n  channels Abstract: We prove that quantum thermal Gaussian input states minimize the output\nentropy of the multi-mode quantum Gaussian attenuators and amplifiers that are\nentanglement breaking and of the multi-mode quantum Gaussian phase\ncontravariant channels among all the input states with a given entropy. This is\nthe first time that this property is proven for a multi-mode channel without\nrestrictions on the input states. A striking consequence of this result is a\nnew lower bound on the output entropy of all the multi-mode quantum Gaussian\nattenuators and amplifiers in terms of the input entropy. We apply this bound\nto determine new upper bounds to the communication rates in two different\nscenarios. The first is classical communication to two receivers with the\nquantum degraded Gaussian broadcast channel. The second is the simultaneous\nclassical communication, quantum communication and entanglement generation or\nthe simultaneous public classical communication, private classical\ncommunication and quantum key distribution with the Gaussian quantum-limited\nattenuator. \n\n"}
{"id": "1806.00985", "contents": "Title: Load Balancing User Association in Millimeter Wave MIMO Networks Abstract: User association is necessary in dense millimeter wave (mmWave) networks to\ndetermine which base station a user connects to in order to balance base\nstation loads and maximize throughput. Given that mmWave connections are highly\ndirectional and vulnerable to small channel variations, user association\nchanges these connections and hence significantly affects the user's\ninstantaneous rate as well as network interference. In this paper, we introduce\na new load balancing user association scheme for mmWave MIMO networks which\nconsiders this dependency on user association of user's transmission rates and\nnetwork interference. We formulate the user association problem as mixed\ninteger nonlinear programming and design a polynomial-time algorithm, called\nWorst Connection Swapping (WCS), to find a near-optimal solution. Simulation\nresults confirm that the proposed user association scheme improves network\nperformance significantly by moving the traffic of congested base stations to\nlightly-loaded ones and adjusting the interference accordingly. Further, the\nproposed WCS algorithm outperforms other generic algorithms for combinatorial\nprogramming such as the genetic algorithm in both accuracy and speed at several\norders of magnitude faster, and for small networks where exhaustive search is\npossible it reaches the optimal solution. \n\n"}
{"id": "1806.01259", "contents": "Title: Learning a Code: Machine Learning for Approximate Non-Linear Coded\n  Computation Abstract: Machine learning algorithms are typically run on large scale, distributed\ncompute infrastructure that routinely face a number of unavailabilities such as\nfailures and temporary slowdowns. Adding redundant computations using\ncoding-theoretic tools called \"codes\" is an emerging technique to alleviate the\nadverse effects of such unavailabilities. A code consists of an encoding\nfunction that proactively introduces redundant computation and a decoding\nfunction that reconstructs unavailable outputs using the available ones. Past\nwork focuses on using codes to provide resilience for linear computations and\nspecific iterative optimization algorithms. However, computations performed for\na variety of applications including inference on state-of-the-art machine\nlearning algorithms, such as neural networks, typically fall outside this\nrealm. In this paper, we propose taking a learning-based approach to designing\ncodes that can handle non-linear computations. We present carefully designed\nneural network architectures and a training methodology for learning encoding\nand decoding functions that produce approximate reconstructions of unavailable\ncomputation results. We present extensive experimental results demonstrating\nthe effectiveness of the proposed approach: we show that the our learned codes\ncan accurately reconstruct $64 - 98\\%$ of the unavailable predictions from\nneural-network based image classifiers on the MNIST, Fashion-MNIST, and\nCIFAR-10 datasets. To the best of our knowledge, this work proposes the first\nlearning-based approach for designing codes, and also presents the first\ncoding-theoretic solution that can provide resilience for any non-linear\n(differentiable) computation. Our results show that learning can be an\neffective technique for designing codes, and that learned codes are a highly\npromising approach for bringing the benefits of coding to non-linear\ncomputations. \n\n"}
{"id": "1806.02015", "contents": "Title: Distributed Hypothesis Testing with Privacy Constraints Abstract: We revisit the distributed hypothesis testing (or hypothesis testing with\ncommunication constraints) problem from the viewpoint of privacy. Instead of\nobserving the raw data directly, the transmitter observes a sanitized or\nrandomized version of it. We impose an upper bound on the mutual information\nbetween the raw and randomized data. Under this scenario, the receiver, which\nis also provided with side information, is required to make a decision on\nwhether the null or alternative hypothesis is in effect. We first provide a\ngeneral lower bound on the type-II exponent for an arbitrary pair of\nhypotheses. Next, we show that if the distribution under the alternative\nhypothesis is the product of the marginals of the distribution under the null\n(i.e., testing against independence), then the exponent is known exactly.\nMoreover, we show that the strong converse property holds. Using ideas from\nEuclidean information theory, we also provide an approximate expression for the\nexponent when the communication rate is low and the privacy level is high.\nFinally, we illustrate our results with a binary and a Gaussian example. \n\n"}
{"id": "1806.02951", "contents": "Title: On self-dual and LCD double circulant and double negacirculant codes\n  over $\\mathbb{F}_q + u\\mathbb{F}_q$ Abstract: Double circulant codes of length $2n$ over the semilocal ring $R =\n\\mathbb{F}_q + u\\mathbb{F}_q,\\, u^2=u,$ are studied when $q$ is an odd prime\npower, and $-1$ is a square in $\\mathbb{F}_q.$ Double negacirculant codes of\nlength $2n$ are studied over $R$ when $n$ is even and $q$ is an odd prime\npower. Exact enumeration of self-dual and LCD such codes for given length $2n$\nis given. Employing a duality-preserving Gray map, self-dual and LCD codes of\nlength $4n$ over $\\mathbb{F}_q$ are constructed. Using random coding and the\nArtin conjecture, the relative distance of these codes is bounded below. The\nparameters of examples of the modest length are computed. Several such codes\nare optimal. \n\n"}
{"id": "1806.05139", "contents": "Title: High-Dimensional Inference for Cluster-Based Graphical Models Abstract: Motivated by modern applications in which one constructs graphical models\nbased on a very large number of features, this paper introduces a new class of\ncluster-based graphical models, in which variable clustering is applied as an\ninitial step for reducing the dimension of the feature space. We employ model\nassisted clustering, in which the clusters contain features that are similar to\nthe same unobserved latent variable. Two different cluster-based Gaussian\ngraphical models are considered: the latent variable graph, corresponding to\nthe graphical model associated with the unobserved latent variables, and the\ncluster-average graph, corresponding to the vector of features averaged over\nclusters. Our study reveals that likelihood based inference for the latent\ngraph, not analyzed previously, is analytically intractable. Our main\ncontribution is the development and analysis of alternative estimation and\ninference strategies, for the precision matrix of an unobservable latent vector\n$Z$. We replace the likelihood of the data by an appropriate class of empirical\nrisk functions, that can be specialized to the latent graphical model and to\nthe simpler, but under-analyzed, cluster-average graphical model. The\nestimators thus derived can be used for inference on the graph structure, for\ninstance on edge strength or pattern recovery. Inference is based on the\nasymptotic limits of the entry-wise estimates of the precision matrices\nassociated with the conditional independence graphs under consideration. While\ntaking the uncertainty induced by the clustering step into account, we\nestablish Berry-Esseen central limit theorems for the proposed estimators. It\nis noteworthy that, although the clusters are estimated adaptively from the\ndata, the central limit theorems regarding the entries of the estimated graphs\nare proved under the same conditions one would use if the clusters were\nknown.... \n\n"}
{"id": "1806.05669", "contents": "Title: Probing the in-Medium QCD Force by Open Heavy-Flavor Observables Abstract: The determination of the color force in a quark-gluon plasma (QGP) is a key\nobjective in the investigation of strong-interaction matter. Open and hidden\nheavy-flavor observables in heavy-ion collisions (HICs) are believed to provide\ninsights into this problem by comparing calculations of heavy-quark (HQ) and\nquarkonium transport with pertinent experimental data. In this work, we utilize\nthe $T$-matrix formalism to compute charm-quark transport coefficients for\nvarious input potentials previously extracted from simultaneous fits to\nlattice-QCD data for HQ free energies, quarkonium correlators and the QGP\nequation of state. We investigate the impact of off-shell effects (spectral\nfunctions) in the QGP medium on the HQ transport, and compare to earlier\nresults using the free or internal HQ energies as potential proxies. We then\nemploy the transport coefficients in relativistic Langevin simulations for HICs\nto test the sensitivity of heavy-flavor observables to the HQ interactions in\nthe QGP. We find that a strongly-coupled $T$-matrix solution generates a HQ\nelliptic flow comparable to the results from the internal energy at low\nmomentum, driven by a long-range remnant of the confining force, while falling\noff stronger with increasing 3-momentum. The weakly coupled $T$-matrix\nsolution, whose underlying potential is close to the free energy, leads to an\nelliptic flow well below the experimentally observed range. \n\n"}
{"id": "1806.05756", "contents": "Title: The Right Complexity Measure in Locally Private Estimation: It is not\n  the Fisher Information Abstract: We identify fundamental tradeoffs between statistical utility and privacy\nunder local models of privacy in which data is kept private even from the\nstatistician, providing instance-specific bounds for private estimation and\nlearning problems by developing the \\emph{local minimax risk}. In contrast to\napproaches based on worst-case (minimax) error, which are conservative, this\nallows us to evaluate the difficulty of individual problem instances and\ndelineate the possibilities for adaptation in private estimation and inference.\nOur main results show that the local modulus of continuity of the estimand with\nrespect to the variation distance---as opposed to the Hellinger distance\ncentral to classical statistics---characterizes rates of convergence under\nlocally private estimation for many notions of privacy, including differential\nprivacy and its relaxations. As consequences of these results, we identify an\nalternative to the Fisher information for private estimation, giving a more\nnuanced understanding of the challenges of adaptivity and optimality. \n\n"}
{"id": "1806.07223", "contents": "Title: ASIC Implementation of Time-Domain Digital Backpropagation with\n  Deep-Learned Chromatic Dispersion Filters Abstract: We consider time-domain digital backpropagation with chromatic dispersion\nfilters jointly optimized and quantized using machine-learning techniques.\nCompared to the baseline implementations, we show improved BER performance and\n>40% power dissipation reductions in 28-nm CMOS. \n\n"}
{"id": "1806.07870", "contents": "Title: Sequential change-point detection in high-dimensional Gaussian graphical\n  models Abstract: High dimensional piecewise stationary graphical models represent a versatile\nclass for modelling time varying networks arising in diverse application areas,\nincluding biology, economics, and social sciences. There has been recent work\nin offline detection and estimation of regime changes in the topology of sparse\ngraphical models. However, the online setting remains largely unexplored,\ndespite its high relevance to applications in sensor networks and other\nengineering monitoring systems, as well as financial markets. To that end, this\nwork introduces a novel scalable online algorithm for detecting an unknown\nnumber of abrupt changes in the inverse covariance matrix of sparse Gaussian\ngraphical models with small delay. The proposed algorithm is based upon\nmonitoring the conditional log-likelihood of all nodes in the network and can\nbe extended to a large class of continuous and discrete graphical models. We\nalso investigate asymptotic properties of our procedure under certain mild\nregularity conditions on the graph size, sparsity level, number of samples, and\npre- and post-changes in the topology of the network. Numerical works on both\nsynthetic and real data illustrate the good performance of the proposed\nmethodology both in terms of computational and statistical efficiency across\nnumerous experimental settings. \n\n"}
{"id": "1806.08449", "contents": "Title: Generalizing Correspondence Analysis for Applications in Machine\n  Learning Abstract: Correspondence analysis (CA) is a multivariate statistical tool used to\nvisualize and interpret data dependencies by finding maximally correlated\nembeddings of pairs of random variables. CA has found applications in fields\nranging from epidemiology to social sciences; however, current methods do not\nscale to large, high-dimensional datasets. In this paper, we provide a novel\ninterpretation of CA in terms of an information-theoretic quantity called the\nprincipal inertia components. We show that estimating the principal inertia\ncomponents, which consists in solving a functional optimization problem over\nthe space of finite variance functions of two random variable, is equivalent to\nperforming CA. We then leverage this insight to design novel algorithms to\nperform CA at an unprecedented scale. Particularly, we demonstrate how the\nprincipal inertia components can be reliably approximated from data using deep\nneural networks. Finally, we show how these maximally correlated embeddings of\npairs of random variables in CA further play a central role in several learning\nproblems including visualization of classification boundary and training\nprocess, and underlying recent multi-view and multi-modal learning methods. \n\n"}
{"id": "1806.08699", "contents": "Title: Gauge and Infrared Properties of Hadronic Structure of Nucleon in\n  Neutron Beta Decay to Order O(\\alpha/\\pi) in Standard V - A Effective Theory\n  with QED and Linear Sigma Model of Strong Low--Energy Interactions Abstract: Within the standard V - A theory of weak interactions, Quantum\nElectrodynamics (QED) and the linear sigma-model (LsM) of strong low-energy\nhadronic interactions we analyse gauge and infrared properties of hadronic\nstructure of the neutron and proton in the neutron beta decay to leading order\nin the large nucleon mass expansion. We show that the complete set of Feynman\ndiagrams describing radiative corrections of order O(\\alpha/\\pi), induced by\nhadronic structure of the nucleon, to the rate of the neutron beta decay is\ngauge non-invariant and unrenormalisable. We show that a gauge non-invariant\ncontribution does not depend on the electron energy in agreement with Sirlin's\nanalysis of contributions of strong low-energy interactions (Phys. Rev. 164,\n1767 (1967)). We show that infrared divergent and dependent on the electron\nenergy contributions from the neutron radiative beta decay and neutron beta\ndecay, caused by hadronic structure of the nucleon, are cancelled in the\nneutron lifetime. Nevertheless, we find that divergent contributions of virtual\nphoton exchanges to the neutron lifetime, induced by hadronic structure of the\nnucleon, are unrenormalisable even formally. Such an unrenormalizability can be\nexplained by the fact that the effective V - A vertex of hadron-lepton\ncurrent-current interactions is not a vertex of the combined quantum field\ntheory including QED and LsM, which are renormalizable theories. \n\n"}
{"id": "1806.09471", "contents": "Title: Does data interpolation contradict statistical optimality? Abstract: We show that learning methods interpolating the training data can achieve\noptimal rates for the problems of nonparametric regression and prediction with\nsquare loss. \n\n"}
{"id": "1806.10055", "contents": "Title: Twisted Gabidulin Codes in the GPT Cryptosystem Abstract: In this paper, we investigate twisted Gabidulin codes in the GPT code-based\npublic-key cryptosystem. We show that Overbeck's attack is not feasible for a\nsubfamily of twisted Gabidulin codes. The resulting key sizes are significantly\nlower than in the original McEliece system and also slightly smaller than in\nLoidreau's unbroken GPT variant. \n\n"}
{"id": "1806.10803", "contents": "Title: Matrix Recovery from Rank-One Projection Measurements via Nonconvex\n  Minimization Abstract: In this paper, we consider the matrix recovery from rank-one projection\nmeasurements proposed in [Cai and Zhang, Ann. Statist., 43(2015), 102-138], via\nnonconvex minimization. We establish a sufficient identifiability condition,\nwhich can guarantee the exact recovery of low-rank matrix via Schatten-$p$\nminimization $\\min_{X}\\|X\\|_{S_p}^p$ for $0<p<1$ under affine constraint, and\nstable recovery of low-rank matrix under $\\ell_q$ constraint and Dantzig\nselector constraint. Our condition is also sufficient to guarantee low-rank\nmatrix recovery via least $q$ minimization $\\min_{X}\\|\\mathcal{A}(X)-b\\|_{q}^q$\nfor $0<q\\leq1$. And we also extend our result to Gaussian design distribution,\nand show that any matrix can be stably recovered for rank-one projection from\nGaussian distributions via least $1$ minimization with high probability. \n\n"}
{"id": "1807.00801", "contents": "Title: Deepcode: Feedback Codes via Deep Learning Abstract: The design of codes for communicating reliably over a statistically well\ndefined channel is an important endeavor involving deep mathematical research\nand wide-ranging practical applications. In this work, we present the first\nfamily of codes obtained via deep learning, which significantly beats\nstate-of-the-art codes designed over several decades of research. The\ncommunication channel under consideration is the Gaussian noise channel with\nfeedback, whose study was initiated by Shannon; feedback is known theoretically\nto improve reliability of communication, but no practical codes that do so have\never been successfully constructed.\n  We break this logjam by integrating information theoretic insights\nharmoniously with recurrent-neural-network based encoders and decoders to\ncreate novel codes that outperform known codes by 3 orders of magnitude in\nreliability. We also demonstrate several desirable properties of the codes: (a)\ngeneralization to larger block lengths, (b) composability with known codes, (c)\nadaptation to practical constraints. This result also has broader ramifications\nfor coding theory: even when the channel has a clear mathematical model, deep\nlearning methodologies, when combined with channel-specific\ninformation-theoretic insights, can potentially beat state-of-the-art codes\nconstructed over decades of mathematical research. \n\n"}
{"id": "1807.01170", "contents": "Title: Private Coded Computation for Machine Learning Abstract: In a distributed computing system for the master-worker framework, an erasure\ncode can mitigate the effects of slow workers, also called stragglers. The\ndistributed computing system combined with coding is referred to as coded\ncomputation. We introduce a variation of coded computation that protects the\nmaster's privacy from the workers, which is referred to as private coded\ncomputation. In private coded computation, the master needs to compute a\nfunction of its own dataset and one of the datasets in a library exclusively\nshared by the external workers. After the master recovers the result of the\ndesired function through coded computation, the workers should not know which\ndataset in the library was desired by the master, which implies that the\nmaster's privacy is protected. We propose a private coded computation scheme\nfor matrix multiplication, namely private polynomial codes, based on polynomial\ncodes for conventional coded computation. As special cases of private\npolynomial codes, we propose private one-shot polynomial codes and private\nasynchronous polynomial codes. Whereas the private one-shot polynomial code\nachieves a lower communication load from the master to each worker, the private\nasynchronous polynomial code achieves faster computation than private one-shot\npolynomial codes. In terms of computation time and communication load, we\ncompare private one-shot polynomial codes and private asynchronous polynomial\ncodes with a conventional robust private information retrieval scheme which can\nbe directly applied to coded computation. \n\n"}
{"id": "1807.01916", "contents": "Title: Privacy against a Hypothesis Testing Adversary Abstract: Privacy against an adversary (AD) that tries to detect the underlying\nprivacy-sensitive data distribution is studied. The original data sequence is\nassumed to come from one of the two known distributions, and the privacy\nleakage is measured by the probability of error of the binary hypothesis test\ncarried out by the AD. A management unit (MU) is allowed to manipulate the\noriginal data sequence in an online fashion, while satisfying an average\ndistortion constraint. The goal of the MU is to maximize the minimal type II\nprobability of error subject to a constraint on the type I probability of error\nassuming an adversarial Neyman-Pearson test, or to maximize the minimal error\nprobability assuming an adversarial Bayesian test. The asymptotic exponents of\nthe maximum minimal type II probability of error and the maximum minimal error\nprobability are shown to be characterized by a Kullback-Leibler divergence rate\nand a Chernoff information rate, respectively. Privacy performances of\nparticular management policies, the memoryless hypothesis-aware policy and the\nhypothesis-unaware policy with memory, are compared. The proposed formulation\ncan also model adversarial example generation with minimal data manipulation to\nfool classifiers. Lastly, the results are applied to a smart meter privacy\nproblem, where the user's energy consumption is manipulated by adaptively using\na renewable energy source in order to hide user's activity from the energy\nprovider. \n\n"}
{"id": "1807.02596", "contents": "Title: Validation of Geant4's G4NRF module against nuclear resonance\n  fluorescence data from $^{238}$U and $^{27}$Al Abstract: G4NRF is a simulation module for modeling nuclear resonance fluorescence\n(NRF) interactions in the Geant4 framework. In this work, we validate G4NRF\nagainst both absolute and relative measurements of three NRF interactions near\n2.2 MeV in $^{238}$U and $^{27}$Al using the transmission NRF data from the\nexperiments described in arXiv:1712.02904. Agreement between the absolute NRF\ncount rates observed in the data and predicted by extensive Geant4+G4NRF\nmodeling validate the combined Geant4+G4NRF to within $15$--$20\\%$ in the\n$^{238}$U NRF transitions and $8\\%$ in $^{27}$Al, for an average $13\\%$\ndiscrepancy across the entire study. The difference between simulation and\nexperiment in relative NRF rates, as expressed as ratios of count rates in\nvarious NRF lines, is found at the level of ${\\lesssim}4\\%$, and is\nstatistically identical to zero. Inverting the analysis, approximate values of\nthe absolute level widths and branching ratios for $^{238}$U and $^{27}$Al are\nalso obtained. \n\n"}
{"id": "1807.02643", "contents": "Title: Density Functional Theory (DFT) for atomic nuclei: a simple introduction Abstract: The present contribution does not aim at replacing the huge and often\nexcellent literature on DFT for atomic nuclei, but tries to provide an updated\nintroduction to this topic. The goal would be, ideally, to help a fresh M.Sc.\nor Ph.D. student (or a researcher from other fields) to become acquainted with\nsome basic concepts, and then move to the specialized textbooks or papers with\nsome ability for orienteering. We first introduce the basics of DFT, and show\nthe difference with the \"naive\" mean-field theory, that is doomed to fail as a\nmodel even in the simple case of uniform nuclear matter. We introduce the\nEnergy Density Functionals (EDFs) that are used in nuclear structure, with few\nexamples of their applications. The concepts of symmetry breaking and\nrestoration are briefly discussed. We also include an introduction to the\ntime-dependent extension of DFT that, so far, has been implemented essentially\nonly in the adiabatic approximation and has been applied mainly to the study of\nnuclear vibrations. With this material, we hope that any reader is able to deal\nwith the texts that go deeper into each of the topics, having understood that\nDFT is probably the best compromise in nuclear structure theory between\nsimplicity, accuracy, and broad range of applicability. \n\n"}
{"id": "1807.02683", "contents": "Title: Diffusive Molecular Communication in Biological Cylindrical Environment Abstract: Diffusive molecular communication (DMC) is one of the most promising\napproaches for realizing nano-scale communications in biological environments\nfor healthcare applications. In this paper, a DMC system in biological\ncylindrical environment is considered, inspired by blood vessel structures in\nthe body. The internal surface of the cylinder boundary is assumed to be\ncovered by the biological receptors which may irreversibly react with hitting\nmolecules. Also, information molecules diffusing in the fluid medium are\nsubject to a degradation reaction and flow. The concentration Green's function\nof diffusion in this environment is analytically derived which takes into\naccount asymmetry in all radial, axial and azimuthal coordinates. Employing\nobtained Green's function, information channel between transmitter and\ntransparent receiver of DMC is characterized. To evaluate the DMC system in the\nbiological cylinder, a simple on-off keying modulation scheme is adopted and\ncorresponding error probability is derived. Particle based simulation results\nconfirm the proposed analysis. Also, the effect of different system parameters\non the concentration Green's function are examined. Our results reveal that the\ndegradation reaction and the boundary covered by biological receptors may be\nutilized to mitigate intersymbol interference and outperform corresponding\nerror probability. \n\n"}
{"id": "1807.04239", "contents": "Title: Morse Code Datasets for Machine Learning Abstract: We present an algorithm to generate synthetic datasets of tunable difficulty\non classification of Morse code symbols for supervised machine learning\nproblems, in particular, neural networks. The datasets are spatially\none-dimensional and have a small number of input features, leading to high\ndensity of input information content. This makes them particularly challenging\nwhen implementing network complexity reduction methods. We explore how network\nperformance is affected by deliberately adding various forms of noise and\nexpanding the feature set and dataset size. Finally, we establish several\nmetrics to indicate the difficulty of a dataset, and evaluate their merits. The\nalgorithm and datasets are open-source. \n\n"}
{"id": "1807.04839", "contents": "Title: An Approximate Message Passing Framework for Side Information Abstract: Approximate message passing (AMP) methods have gained recent traction in\nsparse signal recovery. Additional information about the signal, or \\emph{side\ninformation} (SI), is commonly available and can aid in efficient signal\nrecovery. This work presents an AMP-based framework that exploits SI and can be\nreadily implemented in various settings for which the SI results in separable\ndistributions. To illustrate the simplicity and applicability of our approach,\nthis framework is applied to a Bernoulli-Gaussian (BG) model and a time-varying\nbirth-death-drift (BDD) signal model, motivated by applications in channel\nestimation. We develop a suite of algorithms, called AMP-SI, and derive\ndenoisers for the BDD and BG models. Numerical evidence demonstrating the\nadvantages of our approach are presented alongside empirical evidence of the\naccuracy of a proposed state evolution. \n\n"}
{"id": "1807.04936", "contents": "Title: Non-Gaussian Component Analysis using Entropy Methods Abstract: Non-Gaussian component analysis (NGCA) is a problem in multidimensional data\nanalysis which, since its formulation in 2006, has attracted considerable\nattention in statistics and machine learning. In this problem, we have a random\nvariable $X$ in $n$-dimensional Euclidean space. There is an unknown subspace\n$\\Gamma$ of the $n$-dimensional Euclidean space such that the orthogonal\nprojection of $X$ onto $\\Gamma$ is standard multidimensional Gaussian and the\northogonal projection of $X$ onto $\\Gamma^{\\perp}$, the orthogonal complement\nof $\\Gamma$, is non-Gaussian, in the sense that all its one-dimensional\nmarginals are different from the Gaussian in a certain metric defined in terms\nof moments. The NGCA problem is to approximate the non-Gaussian subspace\n$\\Gamma^{\\perp}$ given samples of $X$.\n  Vectors in $\\Gamma^{\\perp}$ correspond to `interesting' directions, whereas\nvectors in $\\Gamma$ correspond to the directions where data is very noisy. The\nmost interesting applications of the NGCA model is for the case when the\nmagnitude of the noise is comparable to that of the true signal, a setting in\nwhich traditional noise reduction techniques such as PCA don't apply directly.\nNGCA is also related to dimension reduction and to other data analysis problems\nsuch as ICA. NGCA-like problems have been studied in statistics for a long time\nusing techniques such as projection pursuit.\n  We give an algorithm that takes polynomial time in the dimension $n$ and has\nan inverse polynomial dependence on the error parameter measuring the angle\ndistance between the non-Gaussian subspace and the subspace output by the\nalgorithm. Our algorithm is based on relative entropy as the contrast function\nand fits under the projection pursuit framework. The techniques we develop for\nanalyzing our algorithm maybe of use for other related problems. \n\n"}
{"id": "1807.05103", "contents": "Title: Unique Informations and Deficiencies Abstract: Given two channels that convey information about the same random variable, we\nintroduce two measures of the unique information of one channel with respect to\nthe other. The two quantities are based on the notion of generalized weighted\nLe Cam deficiencies and differ on whether one channel can approximate the other\nby a randomization at either its input or output. We relate the proposed\nquantities to an existing measure of unique information which we call the\nminimum-synergy unique information. We give an operational interpretation of\nthe latter in terms of an upper bound on the one-way secret key rate and\ndiscuss the role of the unique informations in the context of nonnegative\nmutual information decompositions into unique, redundant and synergistic\ncomponents. \n\n"}
{"id": "1807.05105", "contents": "Title: Theoretical study of the $\\Delta^{++}-\\Delta^-$ configuration in the\n  deuteron using antiproton beam Abstract: We study the manifestation of the $\\Delta^{++}-\\Delta^-$ component of the\ndeuteron wave function in the exclusive reaction $\\bar p d \\to \\pi^- \\pi^-\n\\Delta^{++}$. Due to the large binding energy the internal motion in the\n$\\Delta-\\Delta$ system is relativistic. We take this into account within the\nlight-cone (LC) wave function formalism and, indeed, found large differences\nbetween calculations based on the LC and non-relativistic (NR) wave functions.\nWe demonstrate, that the consistent LC treatment of the $\\Delta-\\Delta$ system\nplays the key role in the separation of the signal and background. Within the\nLC approach, the characteristic shape of the momentum distribution of the\n$\\Delta-\\Delta$ bound system predicted by the meson-exchange model is well\nvisible on the background of usual annihilations at beam momenta between 10 and\n15 GeV/c. \n\n"}
{"id": "1807.05152", "contents": "Title: Information theory with finite vector spaces Abstract: Whereas Shannon entropy is related to the growth rate of multinomial\ncoefficients, we show that the quadratic entropy (Tsallis 2-entropy) is\nconnected to their $q$-deformation; when $q$ is a prime power, these\n$q$-multinomial coefficients count flags of finite vector spaces with\nprescribed length and dimensions. In particular, the $q$-binomial coefficients\ncount vector subspaces of given dimension. We obtain this way a combinatorial\nexplanation for the nonadditivity of the quadratic entropy, which arises from a\nrecursive counting of flags. We show that statistical systems whose\nconfigurations are described by flags provide a frequentist justification for\nthe maximum entropy principle with Tsallis statistics. We introduce then a\ndiscrete-time stochastic process associated to the $q$-binomial probability\ndistribution, that generates at time $n$ a vector subspace of $\\mathbb{F}_q^n$\n(here $\\mathbb{F}_q$ is the finite field of order $q$). The concentration of\nmeasure on certain \"typical subspaces\" allows us to extend the asymptotic\nequipartition property to this setting. The size of the typical set is\nquantified by the quadratic entropy. We discuss the applications to Shannon\ntheory, particularly to source coding, when messages correspond to vector\nspaces. \n\n"}
{"id": "1807.05306", "contents": "Title: Generative Adversarial Privacy Abstract: We present a data-driven framework called generative adversarial privacy\n(GAP). Inspired by recent advancements in generative adversarial networks\n(GANs), GAP allows the data holder to learn the privatization mechanism\ndirectly from the data. Under GAP, finding the optimal privacy mechanism is\nformulated as a constrained minimax game between a privatizer and an adversary.\nWe show that for appropriately chosen adversarial loss functions, GAP provides\nprivacy guarantees against strong information-theoretic adversaries. We also\nevaluate GAP's performance on the GENKI face database. \n\n"}
{"id": "1807.05602", "contents": "Title: Latency-Energy Tradeoff based on Channel Scheduling and Repetitions in\n  NB-IoT Systems Abstract: Narrowband IoT (NB-IoT) is the latest IoT connectivity solution presented by\nthe 3GPP. NB-IoT introduces coverage classes and introduces a significant link\nbudget improvement by allowing repeated transmissions by nodes that experience\nhigh path loss. However, those repetitions necessarily increase the energy\nconsumption and the latency in the whole NB-IoT system. The extent to which the\nwhole system is affected depends on the scheduling of the uplink and downlink\nchannels. We address this question, not treated previously, by developing a\ntractable model of NB-IoT access protocol operation, comprising message\nexchanges in random-access, control, and data channels, both in the uplink and\ndownlink. The model is then used to analyze the impact of channel scheduling as\nwell as the interaction of coexisting coverage classes, through derivation of\nthe expected latency and battery lifetime for each coverage class. These\nresults are subsequently employed in investigation of latency-energy tradeoff\nin NB-IoT channel scheduling as well as determining the optimized operation\npoints. Simulations results show validity of the analysis and confirm that\nthere is a significant impact of channel scheduling on latency and lifetime\nperformance of NBIoT devices. \n\n"}
{"id": "1807.05894", "contents": "Title: Testing coalescence and statistical-thermal production scenarios for\n  (anti-)(hyper-)nuclei and exotic QCD objects at energies available at the\n  CERN Large Hadron Collider Abstract: We present a detailed comparison of coalescence and thermal-statistical\nmodels for the production of (anti-)(hyper-)nuclei in high-energy collisions.\nFor the first time, such a study is carried out as a function of the size of\nthe object relative to the size of the particle emitting source. Our study\nreveals large differences between the two scenarios for the production of\nobjects with extended wave-functions. While both models give similar\npredictions and show similar agreement with experimental data for\n(anti-)deuterons and (anti-)3He nuclei, they largely differ in their\ndescription of (anti-)hyper-triton production. We propose to address\nexperimentally the comparison of the production models by measuring the\ncoalescence parameter systematically for different (anti-)(hyper-)nuclei in\ndifferent collision systems and differentially in multiplicity. Such\nmeasurements are feasible with the current and upgraded Large Hadron Collider\nexperiments. Our findings highlight the unique potential of ultra-relativistic\nheavy-ion collisions as a laboratory to clarify the internal structure of\nexotic QCD objects and can serve as a basis for more refined calculations in\nthe future. \n\n"}
{"id": "1807.05997", "contents": "Title: Noisy Private Information Retrieval: On Separability of Channel Coding\n  and Information Retrieval Abstract: We consider the problem of noisy private information retrieval (NPIR) from\n$N$ non-communicating databases, each storing the same set of $M$ messages. In\nthis model, the answer strings are not returned through noiseless bit pipes,\nbut rather through \\emph{noisy} memoryless channels. We aim at characterizing\nthe PIR capacity for this model as a function of the statistical information\nmeasures of the noisy channels such as entropy and mutual information. We\nderive a general upper bound for the retrieval rate in the form of a max-min\noptimization. We use the achievable schemes for the PIR problem under\nasymmetric traffic constraints and random coding arguments to derive a general\nlower bound for the retrieval rate. The upper and lower bounds match for $M=2$\nand $M=3$, for any $N$, and any noisy channel. The results imply that\nseparation between channel coding and retrieval is optimal except for adapting\nthe traffic ratio from the databases. We refer to this as \\emph{almost\nseparation}. Next, we consider the private information retrieval problem from\nmultiple access channels (MAC-PIR). In MAC-PIR, the database responses reach\nthe user through a multiple access channel (MAC) that mixes the responses\ntogether in a stochastic way. We show that for the additive MAC and the\nconjunction/disjunction MAC, channel coding and retrieval scheme are\n\\emph{inseparable} unlike in NPIR. We show that the retrieval scheme depends on\nthe properties of the MAC, in particular on the linearity aspect. For both\ncases, we provide schemes that achieve the full capacity without any loss due\nto the privacy constraint, which implies that the user can exploit the nature\nof the channel to improve privacy. Finally, we show that the full unconstrained\ncapacity is not always attainable by determining the capacity of the selection\nchannel. \n\n"}
{"id": "1807.06362", "contents": "Title: Confidence Intervals for Testing Disparate Impact in Fair Learning Abstract: We provide the asymptotic distribution of the major indexes used in the\nstatistical literature to quantify disparate treatment in machine learning. We\naim at promoting the use of confidence intervals when testing the so-called\ngroup disparate impact. We illustrate on some examples the importance of using\nconfidence intervals and not a single value. \n\n"}
{"id": "1807.06448", "contents": "Title: Resource Allocation for Secure Gaussian Parallel Relay Channels with\n  Finite-Length Coding and Discrete Constellations Abstract: We investigate the transmission of a secret message from Alice to Bob in the\npresence of an eavesdropper (Eve) and many of decode-and-forward relay nodes.\nEach link comprises a set of parallel channels, modeling for example an\northogonal frequency division multiplexing transmission. We consider the impact\nof discrete constellations and finite-length coding, defining an achievable\nsecrecy rate under a constraint on the equivocation rate at Eve. Then we\npropose a power and channel allocation algorithm that maximizes the achievable\nsecrecy rate by resorting to two coupled Gale-Shapley algorithms for stable\nmatching problem. We consider the scenarios of both full and partial channel\nstate information at Alice. In the latter case, we only guarantee an outage\nsecrecy rate, i.e., the rate of a message that remains secret with a given\nprobability. Numerical results are provided for Rayleigh fading channels in\nterms of average outage secrecy rate, showing that practical schemes achieve a\nperformance quite close to that of ideal ones. \n\n"}
{"id": "1807.07306", "contents": "Title: Bounded Information Rate Variational Autoencoders Abstract: This paper introduces a new member of the family of Variational Autoencoders\n(VAE) that constrains the rate of information transferred by the latent layer.\nThe latent layer is interpreted as a communication channel, the information\nrate of which is bound by imposing a pre-set signal-to-noise ratio. The new\nconstraint subsumes the mutual information between the input and latent\nvariables, combining naturally with the likelihood objective of the observed\ndata as used in a conventional VAE. The resulting Bounded-Information-Rate\nVariational Autoencoder (BIR-VAE) provides a meaningful latent representation\nwith an information resolution that can be specified directly in bits by the\nsystem designer. The rate constraint can be used to prevent overtraining, and\nthe method naturally facilitates quantisation of the latent variables at the\nset rate. Our experiments confirm that the BIR-VAE has a meaningful latent\nrepresentation and that its performance is at least as good as state-of-the-art\ncompeting algorithms, but with lower computational complexity. \n\n"}
{"id": "1807.08087", "contents": "Title: Capacity Analysis for Full Duplex Self-backhauled Small Cells Abstract: Full duplex (FD) communication enables simultaneous transmission and\nreception on the same frequency band. Though it has the potential of doubling\nthe throughput on isolated links, in reality, higher interference and\nasymmetric traffic demands in the uplink and downlink could significantly\nreduce the gains of FD operations. In this paper, we consider the application\nof FD operation in self-backhauled small cells, where multiple FD capable small\ncell base stations (SBS) are wirelessly backhauled by a FD capable macro-cell\nBS (MBS). To increase the capacity of the backhaul link, the MBS is equipped\nwith multiple antennas to enable space division multiple access (SDMA). A\nscheduling method using back-pressure algorithm and geometric programming is\nproposed for link selection and interference mitigation. Simulation results\nshow that with FD SDMA backhaul links, the proposed scheduler almost doubles\nthroughput under asymmetric traffic demand and various network conditions. \n\n"}
{"id": "1807.09382", "contents": "Title: On sampling from a log-concave density using kinetic Langevin diffusions Abstract: Langevin diffusion processes and their discretizations are often used for\nsampling from a target density. The most convenient framework for assessing the\nquality of such a sampling scheme corresponds to smooth and strongly\nlog-concave densities defined on $\\mathbb R^p$. The present work focuses on\nthis framework and studies the behavior of Monte Carlo algorithms based on\ndiscretizations of the kinetic Langevin diffusion. We first prove the geometric\nmixing property of the kinetic Langevin diffusion with a mixing rate that is,\nin the overdamped regime, optimal in terms of its dependence on the condition\nnumber. We then use this result for obtaining improved guarantees of sampling\nusing the kinetic Langevin Monte Carlo method, when the quality of sampling is\nmeasured by the Wasserstein distance. We also consider the situation where the\nHessian of the log-density of the target distribution is Lipschitz-continuous.\nIn this case, we introduce a new discretization of the kinetic Langevin\ndiffusion and prove that this leads to a substantial improvement of the upper\nbound on the sampling error measured in Wasserstein distance. \n\n"}
{"id": "1807.11317", "contents": "Title: Utility-Optimized Local Differential Privacy Mechanisms for Distribution\n  Estimation Abstract: LDP (Local Differential Privacy) has been widely studied to estimate\nstatistics of personal data (e.g., distribution underlying the data) while\nprotecting users' privacy. Although LDP does not require a trusted third party,\nit regards all personal data equally sensitive, which causes excessive\nobfuscation hence the loss of utility. In this paper, we introduce the notion\nof ULDP (Utility-optimized LDP), which provides a privacy guarantee equivalent\nto LDP only for sensitive data. We first consider the setting where all users\nuse the same obfuscation mechanism, and propose two mechanisms providing ULDP:\nutility-optimized randomized response and utility-optimized RAPPOR. We then\nconsider the setting where the distinction between sensitive and non-sensitive\ndata can be different from user to user. For this setting, we propose a\npersonalized ULDP mechanism with semantic tags to estimate the distribution of\npersonal data with high utility while keeping secret what is sensitive for each\nuser. We show theoretically and experimentally that our mechanisms provide much\nhigher utility than the existing LDP mechanisms when there are a lot of\nnon-sensitive data. We also show that when most of the data are non-sensitive,\nour mechanisms even provide almost the same utility as non-private mechanisms\nin the low privacy regime. \n\n"}
{"id": "1807.11921", "contents": "Title: Real-Time Millimeter-Wave MIMO Channel Sounder for Dynamic Directional\n  Measurements Abstract: In this paper, we present a novel real-time multiple-input-multiple-output\n(MIMO) channel sounder for the 28 GHz band. Until now, most investigations of\nthe directional characteristics of millimeter-wave channels have used\nmechanically rotating horn antennas. In contrast, the sounder presented here is\ncapable of performing horizontal and vertical beam steering with the help of\nphased arrays. Due to its fast beam-switching capability, the proposed sounder\ncan perform measurements that are directionally resolved both at the\ntransmitter(TX) and receiver (RX) in 1.44 milliseconds compared to the minutes\nor even hours required for rotating horn antenna sounders. This not only\nenables measurement of more TX-RX locations for a better statistical validity\nbut also allows to perform directional analysis in dynamic environments. The\nshort measurement time combined with the high phase stability limits the phase\ndrift between TX and RX, enabling phase-coherent sounding of all beam pairs\neven when TX and RX have no cabled connection for synchronization without any\ndelay ambiguity. Furthermore, the phase stability over time enables complex RX\nwaveform averaging to improve the signal to noise ratio during high path loss\nmeasurements. The paper discusses both the system design as well as the\nmeasurements performed for verification of the sounder performance.\nFurthermore, we present sample results from double directional measurements in\ndynamic environments. \n\n"}
{"id": "1808.00519", "contents": "Title: Orthogonal Time Frequency Space Modulation Abstract: This paper introduces a new two-dimensional modulation technique called\nOrthogonal Time Frequency Space (OTFS) modulation. OTFS has the novel and\nimportant feature of being designed in the delay-Doppler domain. When coupled\nwith a suitable equalizer, OTFS modulation is able to exploit the full channel\ndiversity over both time and frequency. Moreover, it converts the fading,\ntime-varying wireless channel experienced by modulated signals such as OFDM\ninto a time-independent channel with a complex channel gain that is essentially\nconstant for all symbols.\n  This design obviates the need for transmitter adaptation, and greatly\nsimplifies system operation. The paper describes the basic operating principles\nof OTFS as well as a possible implementation as an overlay to current or\nanticipated standardized systems. OTFS is shown to provide significant\nperformance improvement in systems with high Doppler, short packets, and/or\nlarge antenna array. In particular, simulation results indicate at least\nseveral dB of block error rate performance improvement for OTFS over OFDM in\nall of these settings. \n\n"}
{"id": "1808.00591", "contents": "Title: Impact of Beam Misalignment on Hybrid Beamforming NOMA for mmWave\n  Communications Abstract: This paper studies hybrid beamforming (HB)-based non-orthogonal multiple\naccess (NOMA) in multiuser millimeter wave (mmWave) communications. HB offers\npower-efficient and low-complexity precoding for downlink multiuser mmWave\nsystems which increases multiplexing gain and spectral efficiency of the\nsystem. Applying NOMA to HB-based systems, called HB-NOMA, can scale the number\nof users while offering a high spectral efficiency. However, an imperfect\ncorrelation between the effective channels of users in each NOMA cluster\nseriously degrades the achievable rate of HB-NOMA. In this paper, first a\nsum-rate maximization problem is formulated for HB-NOMA, and an algorithm is\nproposed to solve it effectively. It is then shown that the relationship\nbetween the effective channels of the users in each NOMA cluster can be\napproximated by a correlation factor. Next, the effect of imperfect correlation\nis analyzed, and a lower bound on the achievable rate of the users is derived\nfor both perfect and imperfect correlation. Finally, the rate gap resulting\nfrom an imperfect correlation is evaluated and a tight upper bound is derived\nfor that. Simulation results show that low correlation degrades the achievable\nrate of users. The lower bounds are tight in the large dimensional regime and\nin single-path channels. \n\n"}
{"id": "1808.01720", "contents": "Title: Energy-Age Tradeoff in Status Update Communication Systems with\n  Retransmission Abstract: Age-of-information is a novel performance metric in communication systems to\nindicate the freshness of the latest received data, which has wide applications\nin monitoring and control scenarios. Another important performance metric in\nthese applications is energy consumption, since monitors or sensors are usually\nenergy constrained. In this paper, we study the energy-age tradeoff in a status\nupdate system where data transmission from a source to a receiver may encounter\nfailure due to channel error. As the status sensing process consumes energy,\nwhen a transmission failure happens, the source may either retransmit the\nexisting data to save energy for sensing, or sense and transmit a new update to\nminimize age-of-information. A threshold-based retransmission policy is\nconsidered where each update is allowed to be transmitted no more than M times.\nClosed-form average age-of-information and energy consumption is derived and\nexpressed as a function of channel failure probability and maximum number of\nretransmissions M. Numerical simulations validate our analytical results, and\nillustrate the tradeoff between average age-of-information and energy\nconsumption. \n\n"}
{"id": "1808.02174", "contents": "Title: Test without Trust: Optimal Locally Private Distribution Testing Abstract: We study the problem of distribution testing when the samples can only be\naccessed using a locally differentially private mechanism and focus on two\nrepresentative testing questions of identity (goodness-of-fit) and independence\ntesting for discrete distributions. We are concerned with two settings: First,\nwhen we insist on using an already deployed, general-purpose locally\ndifferentially private mechanism such as the popular RAPPOR or the recently\nintroduced Hadamard Response for collecting data, and must build our tests\nbased on the data collected via this mechanism; and second, when no such\nrestriction is imposed, and we can design a bespoke mechanism specifically for\ntesting. For the latter purpose, we introduce the Randomized Aggregated Private\nTesting Optimal Response (RAPTOR) mechanism which is remarkably simple and\nrequires only one bit of communication per sample.\n  We propose tests based on these mechanisms and analyze their sample\ncomplexities. Each proposed test can be implemented efficiently. In each case\n(barring one), we complement our performance bounds for algorithms with\ninformation-theoretic lower bounds and establish sample optimality of our\nproposed algorithm. A peculiar feature that emerges is that our sample-optimal\nalgorithm based on RAPTOR uses public-coins, and any test based on RAPPOR or\nHadamard Response, which are both private-coin mechanisms, requires\nsignificantly more samples. \n\n"}
{"id": "1808.02477", "contents": "Title: Coded Caching in the Presence of a Wire and a Cache Tapping Adversary of\n  Type II Abstract: This paper introduces the notion of cache-tapping into the information\ntheoretic models of coded caching. The wiretap channel II in the presence of\nmultiple receivers equipped with fixed-size cache memories, and an adversary\nwhich selects symbols to tap into from cache placement and/or delivery is\nintroduced. The legitimate terminals know neither whether placement, delivery,\nor both are tapped, nor the positions in which they are tapped. Only the size\nof the overall tapped set is known. For two receivers and two files, the strong\nsecrecy capacity -- the maximum achievable file rate while keeping the overall\nlibrary strongly secure -- is identified. Lower and upper bounds on the strong\nsecrecy file rate are derived when the library has more than two files.\nAchievability relies on a code design which combines wiretap coding, security\nembedding codes, one-time pad keys, and coded caching. A genie-aided upper\nbound, in which the transmitter is provided with user demands before placement,\nestablishes the converse for the two-files case. For more than two files, the\nupper bound is constructed by three successive channel transformations. Our\nresults establish provable security guarantees against a powerful adversary\nwhich optimizes its tapping over both phases of communication in a cache-aided\nsystem. \n\n"}
{"id": "1808.05922", "contents": "Title: On the Separability of Ergodic Fading MIMO Channels: A Lattice Coding\n  Approach Abstract: This paper addresses point-to-point communication over block-fading channels\nwith independent fading blocks. When both channel state information at the\ntransmitter (CSIT) and receiver (CSIR) are available, most achievable schemes\nuse separable coding, i.e., coding independently and in parallel over different\nfading states. Unfortunately, separable coding has drawbacks including large\nmemory requirements at both communication ends. In this paper a lattice coding\nand decoding scheme is proposed that achieves the ergodic capacity without\nseparable coding, with lattice codebooks and decoding decision regions that are\nuniversal across channel realizations. We first demonstrate this result for\nfading distributions with discrete, finite support whose sequences are robustly\ntypical. Results are then extended to continuous fading distributions, as well\nas multiple-input multiple-output (MIMO) systems. In addition, a variant of the\nproposed scheme is presented for the MIMO ergodic fading channel with CSIR\nonly, where we prove the existence of a universal codebook that achieves rates\nwithin a constant gap to capacity for finite-support fading distributions. The\ngap is small compared with other schemes in the literature. Extension to\ncontinuous-valued fading is also provided. \n\n"}
{"id": "1808.08628", "contents": "Title: Secrecy Performance Analysis of UAV Transmissions Subject to\n  Eavesdropping and Jamming Abstract: Unmanned aerial vehicles (UAVs) have been undergoing fast development for\nproviding broader signal coverage and more extensive surveillance capabilities\nin military and civilian applications. Due to the broadcast nature of the\nwireless signal and the openness of the space, UAV eavesdroppers (UEDs) pose a\npotential threat to ground communications. In this paper, we consider the\ncommunications of a legitimate ground link in the presence of friendly jamming\nand UEDs within a finite area of space. The spatial distribution of the UEDs\nobeying a uniform binomial point process (BPP) is used to characterize the\nrandomness of the UEDs. The ground link is assumed to experience log-distance\npath loss and Rayleigh fading, while free space path loss with/without the\naveraged excess path loss due to the environment is used for the\nair-to-ground/air-to-air links. A piecewise function is proposed to approximate\nthe line-of-sight (LoS) probability for the air-to-ground links, which provides\na better approximation than using the existing sigmoid-based fitting. The\nanalytical expression for the secure connection probability (SCP) of the\nlegitimate ground link in the presence of non-colluding UEDs is derived. The\nanalysis reveals some useful trends in the SCP as a function of the transmit\nsignal to jamming power ratio, the location of the UAV jammer, and the height\nof UAVs. \n\n"}
{"id": "1808.10506", "contents": "Title: Maximum Entropy Principle Analysis in Network Systems with Short-time\n  Recordings Abstract: In many realistic systems, maximum entropy principle (MEP) analysis provides\nan effective characterization of the probability distribution of network\nstates. However, to implement the MEP analysis, a sufficiently long-time data\nrecording in general is often required, e.g., hours of spiking recordings of\nneurons in neuronal networks. The issue of whether the MEP analysis can be\nsuccessfully applied to network systems with data from short recordings has yet\nto be fully addressed. In this work, we investigate relationships underlying\nthe probability distributions, moments, and effective interactions in the MEP\nanalysis and then show that, with short recordings of network dynamics, the MEP\nanalysis can be applied to reconstructing probability distributions of network\nstates under the condition of asynchronous activity of nodes in the network.\nUsing spike trains obtained from both Hodgkin-Huxley neuronal networks and\nelectrophysiological experiments, we verify our results and demonstrate that\nMEP analysis provides a tool to investigate the neuronal population coding\nproperties, even for short recordings. \n\n"}
{"id": "1809.01423", "contents": "Title: Intelligent Reflecting Surface Enhanced Wireless Network: Joint Active\n  and Passive Beamforming Design Abstract: Intelligent reflecting surface (IRS) is envisioned to have abundant\napplications in future wireless networks by smartly reconfiguring the signal\npropagation for performance enhancement. Specifically, an IRS consists of a\nlarge number of low-cost passive elements each reflecting the incident signal\nwith a certain phase shift to collaboratively achieve beamforming and suppress\ninterference at one or more designated receivers. In this paper, we study an\nIRS-enhanced point-to-point multiple-input single-output (MISO) wireless system\nwhere one IRS is deployed to assist in the communication from a multi-antenna\naccess point (AP) to a single-antenna user. As a result, the user\nsimultaneously receives the signal sent directly from the AP as well as that\nreflected by the IRS. We aim to maximize the total received signal power at the\nuser by jointly optimizing the (active) transmit beamforming at the AP and\n(passive) reflect beamforming by the phase shifters at the IRS. We first\npropose a centralized algorithm based on the technique of semidefinite\nrelaxation (SDR) by assuming the global channel state information (CSI)\navailable at the IRS. Since the centralized implementation requires excessive\nchannel estimation and signal exchange overheads, we further propose a\nlow-complexity distributed algorithm where the AP and IRS independently adjust\nthe transmit beamforming and the phase shifts in an alternating manner until\nthe convergence is reached. Simulation results show that significant\nperformance gains can be achieved by the proposed algorithms as compared to\nbenchmark schemes. Moreover, it is verified that the IRS is able to drastically\nenhance the link quality and/or coverage over the conventional setup without\nthe IRS. \n\n"}
{"id": "1809.01738", "contents": "Title: Recovering a Single Community with Side Information Abstract: We study the effect of the quality and quantity of side information on the\nrecovery of a hidden community of size $K=o(n)$ in a graph of size $n$. Side\ninformation for each node in the graph is modeled by a random vector with the\nfollowing features: either the dimension of the vector is allowed to vary with\n$n$, while log-likelihood ratio (LLR) of each component with respect to the\nnode label is fixed, or the LLR is allowed to vary and the vector dimension is\nfixed. These two models represent the variation in quality and quantity of side\ninformation. Under maximum likelihood detection, we calculate tight necessary\nand sufficient conditions for exact recovery of the labels. We demonstrate how\nside information needs to evolve with $n$ in terms of either its quantity, or\nquality, to improve the exact recovery threshold. A similar set of results are\nobtained for weak recovery. Under belief propagation, tight necessary and\nsufficient conditions for weak recovery are calculated when the LLRs are\nconstant, and sufficient conditions when the LLRs vary with $n$. Moreover, we\ndesign and analyze a local voting procedure using side information that can\nachieve exact recovery when applied after belief propagation. The results for\nbelief propagation are validated via simulations on finite synthetic data-sets,\nshowing that the asymptotic results of this paper can also shed light on the\nperformance at finite $n$. \n\n"}
{"id": "1809.02707", "contents": "Title: Analysis of Thompson Sampling for Combinatorial Multi-armed Bandit with\n  Probabilistically Triggered Arms Abstract: We analyze the regret of combinatorial Thompson sampling (CTS) for the\ncombinatorial multi-armed bandit with probabilistically triggered arms under\nthe semi-bandit feedback setting. We assume that the learner has access to an\nexact optimization oracle but does not know the expected base arm outcomes\nbeforehand. When the expected reward function is Lipschitz continuous in the\nexpected base arm outcomes, we derive $O(\\sum_{i =1}^m \\log T / (p_i\n\\Delta_i))$ regret bound for CTS, where $m$ denotes the number of base arms,\n$p_i$ denotes the minimum non-zero triggering probability of base arm $i$ and\n$\\Delta_i$ denotes the minimum suboptimality gap of base arm $i$. We also\ncompare CTS with combinatorial upper confidence bound (CUCB) via numerical\nexperiments on a cascading bandit problem. \n\n"}
{"id": "1809.05515", "contents": "Title: A Statistical Learning Approach to Ultra-Reliable Low Latency\n  Communication Abstract: Mission-critical applications require Ultra-Reliable Low Latency (URLLC)\nwireless connections, where the packet error rate (PER) goes down to $10^{-9}$.\nFulfillment of the bold reliability figures becomes meaningful only if it can\nbe related to a statistical model in which the URLLC system operates. However,\nthis model is generally not known and needs to be learned by sampling the\nwireless environment. In this paper we treat this fundamental problem in the\nsimplest possible communication-theoretic setting: selecting a transmission\nrate over a dynamic wireless channel in order to guarantee high transmission\nreliability. We introduce a novel statistical framework for design and\nassessment of URLLC systems, consisting of three key components: (i) channel\nmodel selection; (ii) learning the model using training; (3) selecting the\ntransmission rate to satisfy the required reliability. As it is insufficient to\nspecify the URLLC requirements only through PER, two types of statistical\nconstraints are introduced, Averaged Reliability (AR) and Probably Correct\nReliability (PCR). The analysis and the evaluations show that adequate model\nselection and learning are indispensable for designing consistent physical\nlayer that asymptotically behaves as if the channel was known perfectly, while\nmaintaining the reliability requirements in URLLC systems. \n\n"}
{"id": "1809.06613", "contents": "Title: Open heavy-flavour measurements with ALICE at the LHC Abstract: Heavy quarks are produced in the early stages of ultra-relativistic heavy-ion\ncollisions, and their number is preserved throughout the subsequent evolution\nof the system. Therefore, they constitute ideal probes for characterising the\nQuark--Gluon Plasma (QGP) medium and for the study of its transport properties.\nIn particular, heavy quarks interact with the partonic constituents of the\nplasma, losing energy, and are expected to be sensitive to the medium\ncollective motion induced by its hydrodynamical evolution. In pp collisions,\nthe measurement of heavy-flavour hadron production provides a reference for\nheavy-ion studies, and allows also testing perturbative QCD calculations in a\nwide range of collision energies. Similar studies in p--Pb collisions help in\ndisentangling cold nuclear matter effects from modifications induced by the\npresence of a QGP medium, and are also useful to investigate the possible\nexistence of collective phenomena also in this system. The ALICE detector\nprovides excellent performances in terms of particle identification and\nvertexing capabilities. Hence, it is fully suited for the reconstruction of\ncharmed mesons and baryons and of electrons from heavy-flavour hadron decays at\ncentral rapidity. Furthermore, the ALICE muon spectrometer allows\nreconstructing heavy-flavour decay muons at forward rapidity. A review of the\nmain ALICE results on open heavy flavour production in pp, p--Pb and Pb--Pb\ncollisions is presented. Recent, more differential measurements are also shown,\nincluding azimuthal correlations of heavy-flavour particles with charged\nhadrons in p--Pb collisions, and D-meson tagged-jet production in p--Pb and\nPb--Pb collisions. \n\n"}
{"id": "1809.08263", "contents": "Title: Privacy in Index Coding: $k$-Limited-Access Schemes Abstract: In the traditional index coding problem, a server employs coding to send\nmessages to $n$ clients within the same broadcast domain. Each client already\nhas some messages as side information and requests a particular unknown message\nfrom the server. All clients learn the coding matrix so that they can decode\nand retrieve their requested data. Our starting observation is that, learning\nthe coding matrix can pose privacy concerns: it may enable a client to infer\ninformation about the requests and side information of other clients. In this\npaper, we mitigate this privacy concern by allowing each client to have limited\naccess to the coding matrix. In particular, we design coding matrices so that\neach client needs only to learn some of (and not all) the rows to decode her\nrequested message. By means of two different privacy metrics, we first show\nthat this approach indeed increases the level of privacy. Based on this, we\npropose the use of $k$-limited-access schemes: given an index coding scheme\nthat employs $T$ transmissions, we create a $k$-limited-access scheme with\n$T_k\\geq T$ transmissions, and with the property that each client needs at most\n$k$ transmissions to decode her message. We derive upper and lower bounds on\n$T_k$ for all values of $k$, and develop deterministic designs for these\nschemes, which are universal, i.e., independent of the coding matrix. We show\nthat our schemes are order-optimal when either $k$ or $n$ is large. Moreover,\nwe propose heuristics that complement the universal schemes for the case when\nboth $n$ and $k$ are small. \n\n"}
{"id": "1809.08383", "contents": "Title: Secure and Energy-Efficient Transmissions in Cache-Enabled Heterogeneous\n  Cellular Networks: Performance Analysis and Optimization Abstract: This paper studies physical-layer security for a cache-enabled heterogeneous\ncellular network comprised of a macro base station and multiple small base\nstations (SBSs). We investigate a joint design on caching placement and file\ndelivery for realizing secure and energy-efficient transmissions against\nrandomly distributed eavesdroppers. We propose a novel hybrid \"most popular\ncontent\" and \"largest content diversity\" caching placement policy to distribute\nfiles of different popularities. Depending on the availability and placement of\nthe requested file, we employ three cooperative transmission schemes, namely,\ndistributed beamforming, frequency-domain orthogonal transmission, and best SBS\nrelaying, respectively. We derive analytical expressions for the connection\noutage probability and secrecy outage probability for each transmission scheme.\nAfterwards, we design the optimal transmission rates and caching allocation\nsuccessively to achieve a maximal overall secrecy throughput and secrecy energy\nefficiency, respectively. Numerical results verify the theoretical analyses and\ndemonstrate the superiority of the proposed hybrid caching policy. \n\n"}
{"id": "1809.09879", "contents": "Title: Learning random points from geometric graphs or orderings Abstract: Suppose that there is a family of $n$ random points $X_v$ for $v \\in V$,\nindependently and uniformly distributed in the square\n$\\left[-\\sqrt{n}/2,\\sqrt{n}/2\\right]^2$ of area $n$. We do not see these\npoints, but learn about them in one of the following two ways.\n  Suppose first that we are given the corresponding random geometric graph $G$,\nwhere distinct vertices $u$ and $v$ are adjacent when the Euclidean distance\n$d_E(X_u,X_v)$ is at most $r$. If the threshold distance $r$ satisfies\n$n^{3/14} \\ll r \\ll n^{1/2}$, then the following holds with high probability.\nGiven the graph $G$ (without any geometric information), in polynomial time we\ncan approximately reconstruct the hidden embedding, in the sense that, `up to\nsymmetries', for each vertex $v$ we find a point within distance about $r$ of\n$X_v$; that is, we find an embedding with `displacement' at most about $r$.\n  Now suppose that, instead of being given the graph $G$, we are given, for\neach vertex $v$, the ordering of the other vertices by increasing Euclidean\ndistance from $v$. Then, with high probability, in polynomial time we can find\nan embedding with the much smaller displacement error $O(\\sqrt{\\log n})$. \n\n"}
{"id": "1810.00295", "contents": "Title: On Exact and $\\infty$-R\\'enyi Common Informations Abstract: Recently, two extensions of Wyner's common information\\textemdash exact and\nR\\'enyi common informations\\textemdash were introduced respectively by Kumar,\nLi, and El Gamal (KLE), and the present authors. The class of common\ninformation problems involves determining the minimum rate of the common input\nto two independent processors needed to exactly or approximately generate a\ntarget joint distribution. For the exact common information problem, exact\ngeneration of the target distribution is required, while for Wyner's and\n$\\alpha$-R\\'enyi common informations, the relative entropy and R\\'enyi\ndivergence with order $\\alpha$ were respectively used to quantify the\ndiscrepancy between the synthesized and target distributions. The exact common\ninformation is larger than or equal to Wyner's common information. However, it\nwas hitherto unknown whether the former is strictly larger than the latter for\nsome joint distributions. In this paper, we first establish the equivalence\nbetween the exact and $\\infty$-R\\'enyi common informations, and then provide\nsingle-letter upper and lower bounds for these two quantities. For doubly\nsymmetric binary sources, we show that the upper and lower bounds coincide,\nwhich implies that for such sources, the exact and $\\infty$-R\\'enyi common\ninformations are completely characterized. Interestingly, we observe that for\nsuch sources, these two common informations are strictly larger than Wyner's.\nThis answers an open problem posed by KLE. Furthermore, we extend Wyner's,\n$\\infty$-R\\'enyi, and exact common informations to sources with countably\ninfinite or continuous alphabets, including Gaussian sources. \n\n"}
{"id": "1810.00699", "contents": "Title: Constraining New Muonic Interactions Meditated by Axion-Like-Particles Abstract: ALPs (Axion Like Particle) beyond the standard model are solutions to several\nimportant problems of modern physics. One way to detect these particles is to\ndetect the new interactions they meditate. Many experiments have been performed\nto search for these new interactions in ranges from $\\sim\\mu$m to astrophysical\nrange. At present, nearly all known experiments searching for the ALP-meditated\nlong range new interactions use sources or probes containing protons, neutrons\nand electrons. Constraints for other fermions such as muons are scarce, though\nmuons might be the most suspicious particles which could take part in new\ninteractions, considering their involvement of several well known puzzles of\nmodern physics. In this work, we discuss the possibility of explaining the\nanomalous magnetic moment of muons by the long range muonic new interactions\nmediated by ALPs. We also give a constraint for the scalar-pseudo-scalar(SP)\ntype interaction meditated by muonic ALPs. We propose to further search the\nmuonic SP type interaction by muon spin rotation experiments. \n\n"}
{"id": "1810.02534", "contents": "Title: Corrections to \"Wyner's Common Information under R\\'enyi Divergence\n  Measures\" Abstract: In this correspondence, we correct an erroneous result on the achievability\npart of the R\\'enyi common information with order $1+s\\in(1,2]$ in [1]. The new\nachievability result (upper bound) of the R\\'enyi common information no longer\ncoincides with Wyner's common information. We also provide a new converse\nresult (lower bound) in this correspondence for the R\\'enyi common information\nwith order $1+s\\in(1,\\infty]$. Numerical results show that for doubly symmetric\nbinary sources, the new upper and lower bounds coincide for the order\n$1+s\\in(1,2]$ and they are both strictly larger than Wyner's common information\nfor this case. \n\n"}
{"id": "1810.02768", "contents": "Title: Open charm measurements at CERN SPS energies with the new Vertex\n  Detector of the NA61/SHINE experiment Abstract: The study of open charm meson production provides an efficient tool for\ndetailed investigations of the properties of hot and dense matter formed in\nnucleus-nucleus collisions. The interpretation of the existing data from the\nCERN SPS suffers from a lack of knowledge on the total charm production rate.\nTo overcome this limitation the heavy-ion programme of the NA61/SHINE\nexperiment at CERN SPS has been expanded to allow for precise measurements of\nparticles with a short lifetime. A new Small Acceptance Vertex Detector (SAVD)\nwas designed and constructed to meet the challenges of open charm measurements\nin nucleus-nucleus collisions. SAVD was installed in December 2016 for data\ntaking with Pb+Pb collisions at 150$A$ GeV/c. An exploratory set of collected\ndata allowed to validate the general concept of the $D^0$ mesons detection via\nits $D^0 \\rightarrow \\pi^+ + K^-$ decay channel and delivered the first direct\nobservation of open charm at SPS energies. In October and November of 2017 a\nlarge statistic data set has been taken for Xe+La at 150$A$, 75$A$, and 40$A$\nGeV/c, these data are currently under intense analysis. The physics motivation\nbehind the open charm measurements at the SPS energies will be discussed.\nMoreover, the concept of the SAVD hardware and status of the analysis will be\nshown. Also, the future plans of open charm measurements in the NA61/SHINE\nexperiment related to the upgraded Vertex Detector will be presented. \n\n"}
{"id": "1810.03861", "contents": "Title: Direct photon elliptic flow in Pb-Pb collisions at\n  $\\sqrt{s_{_{\\mathrm{NN}}}}=2.76$ TeV Abstract: The elliptic flow of inclusive and direct photons was measured by ALICE for\ncentral and semi-central Pb--Pb collisions at $\\sqrt{s_{_{\\mathrm{NN}}}}=2.76$\nTeV. The photons were reconstructed using the electromagnetic calorimeter PHOS\nand the central tracking system. The inclusive photon flow reconstructed with\nboth methods are combined and used to extract the direct photon flow, using a\ndecay photon simulation and the direct photon excess R$_{\\gamma}$, in the\ntransverse momentum range $0.9 < p_\\mathrm{T} < 6.2$ GeV/c. We find agreement\nto earlier results obtained at RHIC, and the theoretical predictions generally\nunder-predict the results. \n\n"}
{"id": "1810.04738", "contents": "Title: Probabilistic Clustering Using Maximal Matrix Norm Couplings Abstract: In this paper, we present a local information theoretic approach to\nexplicitly learn probabilistic clustering of a discrete random variable. Our\nformulation yields a convex maximization problem for which it is NP-hard to\nfind the global optimum. In order to algorithmically solve this optimization\nproblem, we propose two relaxations that are solved via gradient ascent and\nalternating maximization. Experiments on the MSR Sentence Completion Challenge,\nMovieLens 100K, and Reuters21578 datasets demonstrate that our approach is\ncompetitive with existing techniques and worthy of further investigation. \n\n"}
{"id": "1810.06017", "contents": "Title: Linear Coded Caching Scheme for Centralized Networks Abstract: Coded caching systems have been widely studied to reduce the data\ntransmission during the peak traffic time. In practice, two important\nparameters of a coded caching system should be considered, i.e., the rate which\nis the maximum amount of the data transmission during the peak traffic time,\nand the subpacketization level, the number of divided packets of each file when\nwe implement a coded caching scheme. We prefer to design a scheme with rate and\npacket number as small as possible since they reflect the transmission\nefficiency and complexity of the caching scheme, respectively.\n  In this paper, we first characterize a coded caching scheme from the\nviewpoint of linear algebra and show that designing a linear coded caching\nscheme is equivalent to constructing three classes of matrices satisfying some\nrank conditions. Then based on the invariant linear subspaces and combinatorial\ndesign theory, several classes of new coded caching schemes over $\\mathbb{F}_2$\nare obtained by constructing these three classes of matrices. It turns out that\nthe rate of our new rate is the same as the scheme construct by Yan et al.\n(IEEE Trans. Inf. Theory 63, 5821-5833, 2017), but the packet number is\nsignificantly reduced. A concatenating construction then is used for flexible\nnumber of users. Finally by means of these matrices, we show that the minimum\nstorage regenerating codes can also be used to construct coded caching schemes. \n\n"}
{"id": "1810.06049", "contents": "Title: An ETF view of Dropout regularization Abstract: Dropout is a popular regularization technique in deep learning. Yet, the\nreason for its success is still not fully understood. This paper provides a new\ninterpretation of Dropout from a frame theory perspective. By drawing a\nconnection to recent developments in analog channel coding, we suggest that for\na certain family of autoencoders with a linear encoder, optimizing the encoder\nwith dropout regularization leads to an equiangular tight frame (ETF). Since\nthis optimization is non-convex, we add another regularization that promotes\nsuch structures by minimizing the cross-correlation between filters in the\nnetwork. We demonstrate its applicability in convolutional and fully connected\nlayers in both feed-forward and recurrent networks. All these results suggest\nthat there is indeed a relationship between dropout and ETF structure of the\nregularized linear operations. \n\n"}
{"id": "1810.06397", "contents": "Title: A Priori Estimates of the Population Risk for Two-layer Neural Networks Abstract: New estimates for the population risk are established for two-layer neural\nnetworks. These estimates are nearly optimal in the sense that the error rates\nscale in the same way as the Monte Carlo error rates. They are equally\neffective in the over-parametrized regime when the network size is much larger\nthan the size of the dataset. These new estimates are a priori in nature in the\nsense that the bounds depend only on some norms of the underlying functions to\nbe fitted, not the parameters in the model, in contrast with most existing\nresults which are a posteriori in nature. Using these a priori estimates, we\nprovide a perspective for understanding why two-layer neural networks perform\nbetter than the related kernel methods. \n\n"}
{"id": "1810.07014", "contents": "Title: Bregman Divergence Bounds and Universality Properties of the Logarithmic\n  Loss Abstract: A loss function measures the discrepancy between the true values and their\nestimated fits, for a given instance of data. In classification problems, a\nloss function is said to be proper if a minimizer of the expected loss is the\ntrue underlying probability. We show that for binary classification, the\ndivergence associated with smooth, proper, and convex loss functions is upper\nbounded by the Kullback-Leibler (KL) divergence, to within a normalization\nconstant. This implies that by minimizing the logarithmic loss associated with\nthe KL divergence, we minimize an upper bound to any choice of loss from this\nset. As such the logarithmic loss is universal in the sense of providing\nperformance guarantees with respect to a broad class of accuracy measures.\nImportantly, this notion of universality is not problem-specific, enabling its\nuse in diverse applications, including predictive modeling, data clustering and\nsample complexity analysis. Generalizations to arbitrary finite alphabets are\nalso developed. The derived inequalities extend several well-known\n$f$-divergence results. \n\n"}
{"id": "1810.07390", "contents": "Title: The rank of random matrices over finite fields Abstract: We determine the rank of a random matrix A over a finite field with\nprescribed numbers of non-zero entries in each row and column. As an\napplication we obtain a formula for the rate of low-density parity check codes.\nThis formula verifies a conjecture of Lelarge [Proc. IEEE Information Theory\nWorkshop 2013]. The proofs are based on coupling arguments and the\ninterpolation method from mathematical physics. \n\n"}
{"id": "1810.07921", "contents": "Title: Concentration of the Frobenius norm of generalized matrix inverses Abstract: In many applications it is useful to replace the Moore-Penrose pseudoinverse\n(MPP) by a different generalized inverse with more favorable properties. We may\nwant, for example, to have many zero entries, but without giving up too much of\nthe stability of the MPP. One way to quantify stability is by how much the\nFrobenius norm of a generalized inverse exceeds that of the MPP. In this paper\nwe derive finite-size concentration bounds for the Frobenius norm of\n$\\ell^p$-minimal general inverses of iid Gaussian matrices, with $1 \\leq p \\leq\n2$. For $p = 1$ we prove exponential concentration of the Frobenius norm of the\nsparse pseudoinverse; for $p = 2$, we get a similar concentration bound for the\nMPP. Our proof is based on the convex Gaussian min-max theorem, but unlike\nprevious applications which give asymptotic results, we derive finite-size\nbounds. \n\n"}
{"id": "1810.09070", "contents": "Title: On the Conditional Smooth Renyi Entropy and its Applications in Guessing\n  and Source Coding Abstract: A novel definition of the conditional smooth Renyi entropy, which is\ndifferent from that of Renner and Wolf, is introduced. It is shown that our\ndefinition of the conditional smooth Renyi entropy is appropriate to give lower\nand upper bounds on the optimal guessing moment in a guessing problem where the\nguesser is allowed to stop guessing and declare an error. Further a general\nformula for the optimal guessing exponent is given. In particular, a\nsingle-letterized formula for mixture of i.i.d. sources is obtained. Another\napplication in the problem of source coding with the common side-information\navailable at the encoder and decoder is also demonstrated. \n\n"}
{"id": "1810.13421", "contents": "Title: Multiple Measurement Vectors Problem: A Decoupling Property and its\n  Applications Abstract: We study a Compressed Sensing (CS) problem known as Multiple Measurement\nVectors (MMV) problem, which arises in joint estimation of multiple signal\nrealizations when the signal samples have a common (joint) sparse support over\na fixed known dictionary. Although there is a vast literature on the analysis\nof MMV, it is not yet fully known how the number of signal samples and their\nstatistical correlations affects the performance of the joint estimation in\nMMV. Moreover, in many instances of MMV the underlying sparsifying dictionary\nmay not be precisely known, and it is still an open problem to quantify how the\ndictionary mismatch may affect the estimation performance.\n  In this paper, we focus on $\\ell_{2,1}$-norm regularized least squares\n($\\ell_{2,1}$-LS) as a well-known and widely-used MMV algorithm in the\nliterature. We prove an interesting decoupling property for $\\ell_{2,1}$-LS,\nwhere we show that it can be decomposed into two phases: i) use all the signal\nsamples to estimate the signal covariance matrix (coupled phase), ii) plug in\nthe resulting covariance estimate as the true covariance matrix into the\nMinimum Mean Squared Error (MMSE) estimator to reconstruct each signal sample\nindividually (decoupled phase). As a consequence of this decomposition, we are\nable to provide further insights on the performance of $\\ell_{2,1}$-LS for MMV.\nIn particular, we address how the signal correlations and dictionary mismatch\naffects its performance. Moreover, we show that by using the decoupling\nproperty one can obtain a variety of MMV algorithms with performances even\nbetter than that of $\\ell_{2,1}$-LS. We also provide numerical simulations to\nvalidate our theoretical results. \n\n"}
{"id": "1811.00262", "contents": "Title: Semi-Finite Length Analysis for Information Theoretic Tasks Abstract: We focus on the optimal value for various information-theoretical tasks.\nThere are several studies for the asymptotic expansion for these optimal values\nup to the order $\\sqrt{n}$ or $\\log n$. However, these expansions have errors\nof the order $o(\\sqrt{n})$ or $o(\\log n)$, which does not goes to zero\nasymptotically. To resolve this problem, we derive the asymptotic expansion up\nto the constant order for upper and lower bounds of these optimal values. While\nthe expansions of upper and lower bonds do not match, they clarify the ranges\nof these optimal values, whose errors go to zero asymptotically. \n\n"}
{"id": "1811.00687", "contents": "Title: Asynchronous Neighbor Discovery Using Coupled Compressive Sensing Abstract: The neighbor discovery paradigm finds wide application in Internet of Things\nnetworks, where the number of active devices is orders of magnitude smaller\nthan the total device population. Designing low-complexity schemes for\nasynchronous neighbor discovery has recently gained significant attention from\nthe research community. Concurrently, a divide-and-conquer framework, referred\nto as coupled compressive sensing, has been introduced for the synchronous\nmassive random access channel. This work adapts this novel algorithm to the\nproblem of asynchronous neighbor discovery with unknown transmission delays.\nSimulation results suggest that the proposed scheme requires much fewer\ntransmissions to achieve a performance level akin to that of state-of-the-art\ntechniques. \n\n"}
{"id": "1811.05910", "contents": "Title: Deep Bayesian Inversion Abstract: Characterizing statistical properties of solutions of inverse problems is\nessential for decision making. Bayesian inversion offers a tractable framework\nfor this purpose, but current approaches are computationally unfeasible for\nmost realistic imaging applications in the clinic. We introduce two novel deep\nlearning based methods for solving large-scale inverse problems using Bayesian\ninversion: a sampling based method using a WGAN with a novel mini-discriminator\nand a direct approach that trains a neural network using a novel loss function.\nThe performance of both methods is demonstrated on image reconstruction in\nultra low dose 3D helical CT. We compute the posterior mean and standard\ndeviation of the 3D images followed by a hypothesis test to assess whether a\n\"dark spot\" in the liver of a cancer stricken patient is present. Both methods\nare computationally efficient and our evaluation shows very promising\nperformance that clearly supports the claim that Bayesian inversion is usable\nfor 3D imaging in time critical applications. \n\n"}
{"id": "1811.08602", "contents": "Title: On-off Switched Interference Alignment for Diversity Multiplexing\n  Tradeoff Improvement in the 2-User X-Network with Two Antennas Abstract: To improve diversity gain in an interference channel and hence to maximize\ndiversity multiplexing tradeoff (DMT), we propose on-off switched interference\nalignment (IA) where IA is intermittently utilized by switching IA on/off. For\non-off switching, either IA with symbol extension or IA with Alamouti coding is\nadopted in this paper. Deriving and analyzing DMT of the proposed schemes, we\nreveal that the intermittent utilization of IA with simultaneous non-unique\ndecoding can improve DMT in the 2-user X-channel with two antennas. Both the\nproposed schemes are shown to achieve diversity gain of 4 and DoF per user of\n$\\frac{4}{3}$. In particular, the on-off switched IA with Alamouti coding, to\nthe best of our knowledge, surpasses any other existing schemes for the 2-user\nX-channel with two antennas and nearly approaches the ideal DMT. \n\n"}
{"id": "1811.12447", "contents": "Title: On the Performance of Reed-Muller Codes with respect to Random Errors\n  and Erasures Abstract: This work proves new results on the ability of binary Reed-Muller codes to\ndecode from random errors and erasures. We obtain these results by proving\nimproved bounds on the weight distribution of Reed-Muller codes of high\ndegrees. Specifically, given weight $\\beta \\in (0,1)$ we prove an upper bound\non the number of codewords of relative weight at most $\\beta$. We obtain new\nresults in two different settings: for weights $\\beta < 1/2$ and for weights\nthat are close to $1/2$.\n  Our new bounds on the weight distribution imply that RM codes with $m$\nvariables and degree $\\gamma m$, for some explicit constant $\\gamma$, achieve\ncapacity for random erasures (i.e. for the binary erasure channel) and for\nrandom errors (for the binary symmetric channel). Earlier, it was known that RM\ncodes achieve capacity for the binary symmetric channel for degrees $r = o(m)$.\nFor the binary erasure channel it was known that RM codes achieve capacity for\ndegree $o(m)$ or $r \\in [m/2 \\pm O(\\sqrt{m})]$. Thus, our result provide a new\nrange of parameters for which RM achieve capacity for these two well studied\nchannels. In addition, our results imply that for every $\\epsilon > 0$ (in fact\nwe can get up to $\\epsilon = \\Omega\\left(\\sqrt{\\frac{\\log m}{m}}\\right)$) RM\ncodes of degree $r<(1/2-\\epsilon)m$ can correct a fraction of $1-o(1)$ random\nerasures with high probability. We also show that, information theoretically,\nsuch codes can handle a fraction of $1/2-o(1)$ random errors with high\nprobability. Thus, for example, given noisy evaluations of a degree $0.499m$\npolynomial, it is possible to interpolate it even if a random $0.499$ fraction\nof the evaluations were corrupted, with high probability. While the $o(1)$\nterms are not the correct ones to ensure capacity, these results show that RM\ncodes of such degrees are in some sense close to achieving capacity. \n\n"}
{"id": "1812.00308", "contents": "Title: On variation of gradients of deep neural networks Abstract: We provide a theoretical explanation of the role of the number of nodes at\neach layer in deep neural networks. We prove that the largest variation of a\ndeep neural network with ReLU activation function arises when the layer with\nthe fewest nodes changes its activation pattern. An important implication is\nthat deep neural network is a useful tool to generate functions most of whose\nvariations are concentrated on a smaller area of the input space near the\nboundaries corresponding to the layer with the fewest nodes. In turn, this\nproperty makes the function more invariant to input transformation. That is,\nour theoretical result gives a clue about how to design the architecture of a\ndeep neural network to increase complexity and transformation invariancy\nsimultaneously. \n\n"}
{"id": "1812.00802", "contents": "Title: A Hybrid Beamforming Receiver with Two-Stage Analog Combining and\n  Low-Resolution ADCs Abstract: In this paper, we propose a two-stage analog combining architecture for\nmillimeter wave (mmWave) communications with hybrid analog/digital beamforming\nand low-resolution analog-to-digital converters (ADCs). We first derive a\ntwo-stage combining solution by solving a mutual information (MI) maximization\nproblem without a constant modulus constraint on analog combiners. With the\nderived solution, the proposed receiver architecture splits the analog\ncombining into a channel gain aggregation stage followed by a spreading stage\nto maximize the MI by effectively managing quantization error. We show that the\nderived two-stage combiner achieves the optimal scaling law with respect to the\nnumber of radio frequency (RF) chains and maximizes the MI for homogeneous\nsingular values of a MIMO channel. Then, we develop a two-stage analog\ncombining algorithm to implement the derived solution under a constant modulus\nconstraint for mmWave channels. Simulation results validate the algorithm\nperformance in terms of MI. \n\n"}
{"id": "1812.00819", "contents": "Title: Fast and Reliable Initial Access with Random Beamforming for mmWave\n  Networks Abstract: Millimeter-wave (mmWave) communications rely on directional transmissions to\novercome severe path loss. Nevertheless, the use of narrow beams complicates\nthe initial access procedure and increase the latency as the transmitter and\nreceiver beams should be aligned for a proper link establishment. In this\npaper, we investigate the feasibility of random beamforming for the cell-search\nphase of initial access. We develop a stochastic geometry framework to analyze\nthe performance in terms of detection failure probability and expected latency\nof initial access as well as total data transmission. Meanwhile, we compare our\nscheme with the widely used exhaustive search and iterative search schemes, in\nboth control plane and data plane. Our numerical results show that, compared to\nthe other two schemes, random beamforming can substantially reduce the latency\nof initial access with comparable failure probability in dense networks. We\nshow that the gain of the random beamforming is more prominent in light\ntraffics and low-latency services. Our work demonstrates that developing\ncomplex cell-discovery algorithms may be unnecessary in dense mmWave networks\nand thus shed new lights on mmWave network design. \n\n"}
{"id": "1812.02969", "contents": "Title: Polar-Coded Pulse Position Modulation for the Poisson Channel Abstract: A polar-coded modulation scheme for deep-space optical communication is\nproposed. The photon counting Poisson channel with pulse position modulation\n(PPM) is considered. We use the fact that PPM is particularly well suited to be\nused with multilevel codes to design a polar-coded modulation scheme for the\nsystem in consideration. The construction of polar codes for the Poisson\nchannel based on Gaussian approximation is demonstrated to be accurate. The\nproposed scheme uses a cyclic redundancy check outer code and a successive\ncancellation decoder with list decoding and it is shown that it outperforms the\ncompeting schemes. \n\n"}
{"id": "1812.02979", "contents": "Title: Power Allocation in Multi-user Cellular Networks With Deep Q Learning\n  Approach Abstract: The model-driven power allocation (PA) algorithms in the wireless cellular\nnetworks with interfering multiple-access channel (IMAC) have been investigated\nfor decades. Nowadays, the data-driven model-free machine learning-based\napproaches are rapidly developed in this field, and among them the deep\nreinforcement learning (DRL) is proved to be of great promising potential.\nDifferent from supervised learning, the DRL takes advantages of exploration and\nexploitation to maximize the objective function under certain constraints. In\nour paper, we propose a two-step training framework. First, with the off-line\nlearning in simulated environment, a deep Q network (DQN) is trained with deep\nQ learning (DQL) algorithm, which is well-designed to be in consistent with\nthis PA issue. Second, the DQN will be further fine-tuned with real data in\non-line training procedure. The simulation results show that the proposed DQN\nachieves the highest averaged sum-rate, comparing to the ones with present DQL\ntraining. With different user densities, our DQN outperforms benchmark\nalgorithms and thus a good generalization ability is verified. \n\n"}
{"id": "1812.03599", "contents": "Title: Fast convergence rates of deep neural networks for classification Abstract: We derive the fast convergence rates of a deep neural network (DNN)\nclassifier with the rectified linear unit (ReLU) activation function learned\nusing the hinge loss. We consider three cases for a true model: (1) a smooth\ndecision boundary, (2) smooth conditional class probability, and (3) the margin\ncondition (i.e., the probability of inputs near the decision boundary is\nsmall). We show that the DNN classifier learned using the hinge loss achieves\nfast rate convergences for all three cases provided that the architecture\n(i.e., the number of layers, number of nodes and sparsity). is carefully\nselected. An important implication is that DNN architectures are very flexible\nfor use in various cases without much modification. In addition, we consider a\nDNN classifier learned by minimizing the cross-entropy, and show that the DNN\nclassifier achieves a fast convergence rate under the condition that the\nconditional class probabilities of most data are sufficiently close to either 1\nor zero. This assumption is not unusual for image recognition because human\nbeings are extremely good at recognizing most images. To confirm our\ntheoretical explanation, we present the results of a small numerical study\nconducted to compare the hinge loss and cross-entropy. \n\n"}
{"id": "1812.04142", "contents": "Title: Private Polynomial Computation from Lagrange Encoding Abstract: Private computation is a generalization of private information retrieval, in\nwhich a user is able to compute a function on a distributed dataset without\nrevealing the identity of that function to the servers. In this paper it is\nshown that Lagrange encoding, a powerful technique for encoding Reed-Solomon\ncodes, enables private computation in many cases of interest. In particular, we\npresent a scheme that enables private computation of polynomials of any degree\non Lagrange encoded data, while being robust to Byzantine and straggling\nservers, and to servers colluding to attempt to deduce the identities of the\nfunctions to be evaluated. Moreover, incorporating ideas from the well-known\nShamir secret sharing scheme allows the data itself to be concealed from the\nservers as well. Our results extend private computation to high degree\npolynomials and to data-privacy, and reveal a tight connection between private\ncomputation and coded computation. \n\n"}
{"id": "1812.05292", "contents": "Title: Quantum Shannon theory with superpositions of trajectories Abstract: Shannon's theory of information was built on the assumption that the\ninformation carriers were classical systems. Its quantum counterpart, quantum\nShannon theory, explores the new possibilities arising when the information\ncarriers are quantum systems. Traditionally, quantum Shannon theory has\nfocussed on scenarios where the internal state of the information carriers is\nquantum, while their trajectory is classical. Here we propose a second level of\nquantisation where both the information and its propagation in spacetime is\ntreated quantum mechanically. The framework is illustrated with a number of\nexamples, showcasing some of the counterintuitive phenomena taking place when\ninformation travels simultaneously through multiple transmission lines. \n\n"}
{"id": "1812.07385", "contents": "Title: Perturbation Analysis of Learning Algorithms: A Unifying Perspective on\n  Generation of Adversarial Examples Abstract: Despite the tremendous success of deep neural networks in various learning\nproblems, it has been observed that adding an intentionally designed\nadversarial perturbation to inputs of these architectures leads to erroneous\nclassification with high confidence in the prediction. In this work, we propose\na general framework based on the perturbation analysis of learning algorithms\nwhich consists of convex programming and is able to recover many current\nadversarial attacks as special cases. The framework can be used to propose\nnovel attacks against learning algorithms for classification and regression\ntasks under various new constraints with closed form solutions in many\ninstances. In particular we derive new attacks against classification\nalgorithms which are shown to achieve comparable performances to notable\nexisting attacks. The framework is then used to generate adversarial\nperturbations for regression tasks which include single pixel and single subset\nattacks. By applying this method to autoencoding and image colorization tasks,\nit is shown that adversarial perturbations can effectively perturb the output\nof regression tasks as well. \n\n"}
{"id": "1812.07864", "contents": "Title: Probabilistically Shaped Multi-Level Coding with Polar Codes for Fading\n  Channels Abstract: A probabilistic shaping method for multi-level coding (MLC) is presented,\nwhere the transmitted symbols are forced to have a shaped non-uniform\ndistribution. It is shown that shaping only a single bit-level suffices to\ncompensate for most of the shaping loss on the fading channels. A polar code\nbased implementation of the proposed scheme is presented, where shaping is\nperformed by using a precoder at the transmitter without increasing the\ndecoding complexity. Simulation results show that performance improvements can\nbe obtained compared to BICM- and MLC-based polar coding without shaping on\nRayleigh fading channels. \n\n"}
{"id": "1812.09459", "contents": "Title: Optimal Cache Placement for Modified Coded Caching with Arbitrary Cache\n  Size Abstract: We consider content caching between a service provider and multiple\ncache-enabled users, using the recently proposed modified coded caching scheme\n(MCCS) that provides an improved delivery strategy for random user requests. We\ndevelop the optimal cache placement solution for the MCCS with arbitrary cache\nsize by formulating the cache placement as an optimization problem to minimize\nthe average rate during the delivery phase under random user requests. Through\nreformulation, we show that the problem is a linear programming problem. By\nexploring the properties in the caching constraints, we obtain the optimal\ncache placement solution in closed-form. We verify that the existing cache\nplacement scheme obtained at specific cache sizes is a special case of our\nsolution. Numerical studies show how the caching gain changes as the user\npopulation increases, as a result of different cache placement patterns. \n\n"}
{"id": "1812.10145", "contents": "Title: Efficiently computable bounds for magic state distillation Abstract: Magic-state distillation (or non-stabilizer state manipulation) is a crucial\ncomponent in the leading approaches to realizing scalable, fault-tolerant, and\nuniversal quantum computation. Related to non-stabilizer state manipulation is\nthe resource theory of non-stabilizer states, for which one of the goals is to\ncharacterize and quantify non-stabilizerness of a quantum state. In this paper,\nwe introduce the family of thauma measures to quantify the amount of\nnon-stabilizerness in a quantum state, and we exploit this family of measures\nto address several open questions in the resource theory of non-stabilizer\nstates. As a first application, we establish the hypothesis testing thauma as\nan efficiently computable benchmark for the one-shot distillable\nnon-stabilizerness, which in turn leads to a variety of bounds on the rate at\nwhich non-stabilizerness can be distilled, as well as on the overhead of\nmagic-state distillation. We then prove that the max-thauma can be used as an\nefficiently computable tool in benchmarking the efficiency of magic-state\ndistillation and that it can outperform pervious approaches based on mana.\nFinally, we use the min-thauma to bound a quantity known in the literature as\nthe \"regularized relative entropy of magic.\" As a consequence of this bound, we\nfind that two classes of states with maximal mana, a previously established\nnon-stabilizerness measure, cannot be interconverted in the asymptotic regime\nat a rate equal to one. This result resolves a basic question in the resource\ntheory of non-stabilizer states and reveals a difference between the resource\ntheory of non-stabilizer states and other resource theories such as\nentanglement and coherence. \n\n"}
{"id": "1812.11268", "contents": "Title: Dependence Control at Large Abstract: We study the dependence control theory, with a focus on the tail property and\ndependence transformability of wireless channel capacity, respectively, from\nthe perspective of an information theoretic model of the wireless channel and\nfrom the perspective of a functional of controllable and uncontrollable random\nparameter processes. We find that the light-tailed behavior is an intrinsic\nproperty of the wireless channel capacity, which is due to the passive nature\nof the wireless propagation environment and the power limitation in the\npractical systems. We observe that the manipulation of the marginal\ndistributions has a bias in favor of positive dependence and against negative\ndependence, e.g., when a parameter process bears negative dependence, the\nincreases of the means of marginals can not leads effectively to a better\nsystem performance. On the other hand, the dependence bias indicates that the\ndependence is a tradable resource, i.e., when the dependence resource is\nutilized another resource can be saved. For example, the negative dependence\ncan be traded for transmission power in terms of the performance measures. \n\n"}
{"id": "1901.02095", "contents": "Title: Open Heavy Flavour: Experimental summary Abstract: In this paper I will review a few of the latest experimental measurements of\nheavy-flavour hadrons presented at the Hard Probes 2018 conference. Results\nfrom experiments both at RHIC and at the LHC will be discussed. I will present\nsome of the open questions that still need to be addressed with heavy quarks in\nsmall collision systems and in A-A collisions, to better understand the\nproperties of the QGP produced in heavy-ion collisions. I will discuss some of\nthe open heavy-flavour measurements designed to give insights into these\nquestions. \n\n"}
{"id": "1901.02706", "contents": "Title: Current and future measurements of semi-inclusive hadron+jet\n  distributions with ALICE Abstract: The measurement of jets recoiling from a trigger hadron in heavy-ion\ncollisions can be used to understand the properties of the Quark Gluon Plasma.\nJet-medium interactions cause jets to lose energy in the medium and may modify\nthe jet structure. Jet deflection towards large angles due to scattering off of\nquasi-particles in the Quark-Gluon Plasma may also occur, which can be studied\nthrough a measurement of the hadron-jet acoplanarity. These phenomena can be\nstudied through the semi-inclusive distribution of track-based jets recoiling\nfrom a trigger hadron. This contribution presents the latest measurements and\nprospects of semi-inclusive hadron+jet distributions with ALICE. Constraints on\nenergy loss in p-Pb collisions and future prospects to measure energy loss in\nsmaller systems are shown. A jet shape measurement of N-subjettiness using\nrecoil jets is outlined. Finally, prospects for hadron+jet acoplanarity\nmeasurements with ALICE are presented. \n\n"}
{"id": "1901.02867", "contents": "Title: Maximally Recoverable Codes with Hierarchical Locality Abstract: Maximally recoverable codes are a class of codes which recover from all\npotentially recoverable erasure patterns given the locality constraints of the\ncode. In earlier works, these codes have been studied in the context of codes\nwith locality. The notion of locality has been extended to hierarchical\nlocality, which allows for locality to gradually increase in levels with the\nincrease in the number of erasures. We consider the locality constraints\nimposed by codes with two-level hierarchical locality and define maximally\nrecoverable codes with data-local and local hierarchical locality. We derive\ncertain properties related to their punctured codes and minimum distance. We\ngive a procedure to construct hierarchical data-local MRCs from hierarchical\nlocal MRCs. We provide a construction of hierarchical local MRCs for all\nparameters. For the case of one global parity, we provide a different\nconstruction of hierarchical local MRC over a lower field size. \n\n"}
{"id": "1901.05895", "contents": "Title: Bipartite Quantum Interactions: Entangling and Information Processing\n  Abilities Abstract: The aim of this thesis is to advance the theory behind quantum information\nprocessing tasks, by deriving fundamental limits on bipartite quantum\ninteractions and dynamics, which corresponds to an underlying Hamiltonian that\ngoverns the physical transformation of a two-body open quantum system. The goal\nis to determine entangling abilities of such arbitrary bipartite quantum\ninteractions. Doing so provides fundamental limitations on information\nprocessing tasks, including entanglement distillation and secret key\ngeneration, over a bipartite quantum network. We also discuss limitations on\nthe entropy change and its rate for dynamics of an open quantum system weakly\ninteracting with the bath. We introduce a measure of non-unitarity to\ncharacterize the deviation of a doubly stochastic quantum process from a\nnoiseless evolution.\n  Next, we introduce information processing tasks for secure read-out of\ndigital information encoded in read-only memory devices against adversaries of\nvarying capabilities. The task of reading a memory device involves the\nidentification of an interaction process between probe system, which is in\nknown state, and the memory device. Essentially, the information is stored in\nthe choice of channels, which are noisy quantum processes in general and are\nchosen from a publicly known set. Hence, it becomes pertinent to securely read\nmemory devices against scrutiny of an adversary. In particular, for a secure\nread-out task called private reading when a reader is under surveillance of a\npassive eavesdropper, we have determined upper bounds on its performance. We do\nso by leveraging the fact that private reading of digital information stored in\na memory device can be understood as secret key agreement via a specific kind\nof bipartite quantum interaction. \n\n"}
{"id": "1901.05921", "contents": "Title: On the Optimality of D2D Coded Caching with Uncoded Cache Placement and\n  One-shot Delivery Abstract: We consider a cache-aided wireless device-to-device (D2D) network of the type\nintroduced by Ji, Caire, and Molisch [1], where the placement phase is\norchestrated by a central server. We assume that the devices' caches are filled\nwith uncoded data, and the whole content database is contained in the\ncollection of caches. After the cache placement phase, the files requested by\nthe users are serviced by inter-device multicast communication. For such a\nsystem setting, we provide the exact characterization of the optimal\nload-memory trade-off under the assumptions of uncoded placement and one-shot\ndelivery. In particular, we derive both the minimum average (under uniformly\ndistributed demands) and the minimum worst-case sum-load of the D2D\ntransmissions, for given individual cache memory size at disposal of each user.\nFurthermore, we show that the performance of the proposed scheme is within\nfactor $4$ of the information-theoretic optimum. Capitalizing on the one-shot\ndelivery property, we also propose an extension of the presented scheme that\nprovides robustness against random user inactivity. \n\n"}
{"id": "1901.06587", "contents": "Title: Fitting ReLUs via SGD and Quantized SGD Abstract: In this paper we focus on the problem of finding the optimal weights of the\nshallowest of neural networks consisting of a single Rectified Linear Unit\n(ReLU). These functions are of the form $\\mathbf{x}\\rightarrow\n\\max(0,\\langle\\mathbf{w},\\mathbf{x}\\rangle)$ with $\\mathbf{w}\\in\\mathbb{R}^d$\ndenoting the weight vector. We focus on a planted model where the inputs are\nchosen i.i.d. from a Gaussian distribution and the labels are generated\naccording to a planted weight vector. We first show that mini-batch stochastic\ngradient descent when suitably initialized, converges at a geometric rate to\nthe planted model with a number of samples that is optimal up to numerical\nconstants. Next we focus on a parallel implementation where in each iteration\nthe mini-batch gradient is calculated in a distributed manner across multiple\nprocessors and then broadcast to a master or all other processors. To reduce\nthe communication cost in this setting we utilize a Quanitzed Stochastic\nGradient Scheme (QSGD) where the partial gradients are quantized. Perhaps\nunexpectedly, we show that QSGD maintains the fast convergence of SGD to a\nglobally optimal model while significantly reducing the communication cost. We\nfurther corroborate our numerical findings via various experiments including\ndistributed implementations over Amazon EC2. \n\n"}
{"id": "1901.07105", "contents": "Title: Robustness of Maximal $\\alpha$-Leakage to Side Information Abstract: Maximal $\\alpha$-leakage is a tunable measure of information leakage based on\nthe accuracy of guessing an arbitrary function of private data based on public\ndata. The parameter $\\alpha$ determines the loss function used to measure the\naccuracy of a belief, ranging from log-loss at $\\alpha=1$ to the probability of\nerror at $\\alpha=\\infty$. To study the effect of side information on this\nmeasure, we introduce and define conditional maximal $\\alpha$-leakage. We show\nthat, for a chosen mapping (channel) from the actual (viewed as private) data\nto the released (public) data and some side information, the conditional\nmaximal $\\alpha$-leakage is the supremum (over all side information) of the\nconditional Arimoto channel capacity where the conditioning is on the side\ninformation. We prove that if the side information is conditionally independent\nof the public data given the private data, the side information cannot increase\nthe information leakage. \n\n"}
{"id": "1901.07114", "contents": "Title: Training Neural Networks as Learning Data-adaptive Kernels: Provable\n  Representation and Approximation Benefits Abstract: Consider the problem: given the data pair $(\\mathbf{x}, \\mathbf{y})$ drawn\nfrom a population with $f_*(x) = \\mathbf{E}[\\mathbf{y} | \\mathbf{x} = x]$,\nspecify a neural network model and run gradient flow on the weights over time\nuntil reaching any stationarity. How does $f_t$, the function computed by the\nneural network at time $t$, relate to $f_*$, in terms of approximation and\nrepresentation? What are the provable benefits of the adaptive representation\nby neural networks compared to the pre-specified fixed basis representation in\nthe classical nonparametric literature? We answer the above questions via a\ndynamic reproducing kernel Hilbert space (RKHS) approach indexed by the\ntraining process of neural networks. Firstly, we show that when reaching any\nlocal stationarity, gradient flow learns an adaptive RKHS representation and\nperforms the global least-squares projection onto the adaptive RKHS,\nsimultaneously. Secondly, we prove that as the RKHS is data-adaptive and\ntask-specific, the residual for $f_*$ lies in a subspace that is potentially\nmuch smaller than the orthogonal complement of the RKHS. The result formalizes\nthe representation and approximation benefits of neural networks. Lastly, we\nshow that the neural network function computed by gradient flow converges to\nthe kernel ridgeless regression with an adaptive kernel, in the limit of\nvanishing regularization. The adaptive kernel viewpoint provides new angles of\nstudying the approximation, representation, generalization, and optimization\nadvantages of neural networks. \n\n"}
{"id": "1901.07453", "contents": "Title: Orbital Angular Momentum at Small $x$ Abstract: We determine the small Bjorken $x$ asymptotics of the quark and gluon orbital\nangular momentum (OAM) distributions in the proton in the double-logarithmic\napproximation (DLA), which resums powers of $\\alpha_s \\ln^2 (1/x)$ with\n$\\alpha_s$ the strong coupling constant. Starting with the operator definitions\nfor the quark and gluon OAM, we simplify them at small $x$, relating them,\nrespectively, to the polarized dipole amplitudes for the quark and gluon\nhelicities defined in our earlier works. Using the small-$x$ evolution\nequations derived for these polarized dipole amplitudes earlier we arrive at\nthe following small-$x$ asymptotics of the quark and gluon OAM distributions in\nthe large-$N_c$ limit:\n  \\begin{align}\n  L_{q + \\bar{q}} (x, Q^2) = - \\Delta \\Sigma (x, Q^2) \\sim\n  \\left(\\frac{1}{x}\\right)^{\\frac{4}{\\sqrt{3}} \\, \\sqrt{\\frac{\\alpha_s\n  \\, N_c}{2 \\pi}} }, \\ \\ \\ \\ \\\n  L_G (x, Q^2) \\sim \\Delta G (x, Q^2) \\sim\n  \\left(\\frac{1}{x}\\right)^{\\frac{13}{4 \\sqrt{3}} \\, \\sqrt{\\frac{\\alpha_s\n  \\, N_c}{2 \\pi}}} . \\end{align} \n\n"}
{"id": "1901.09559", "contents": "Title: Capacity Optimality of AMP in Coded Systems Abstract: This paper studies a large random matrix system (LRMS) model involving an\narbitrary signal distribution and forward error control (FEC) coding. We\nestablish an area property based on the so-called Turbo approximate message\npassing (Turbo-AMP) algorithm. Under the assumption that the state evolution\nfor AMP is correct for the coded system, the achievable rate of Turbo-AMP is\nanalyzed. We prove that Turbo-AMP achieves the constraint capacity of the LRMS\nwith an arbitrary signal distribution provided that a matching condition is\nsatisfied. As a byproduct, we provide an alternative derivation for the\nconstraint capacity of an LRMS using a proved property of AMP. We discuss\nrealization techniques for the matching principle of binary signaling using\nirregular low-density parity-check (LDPC) codes and provide related numerical\nresults. We show that optimized codes demonstrate significantly better\nperformance over un-matched ones under Turbo-AMP. For quadrature phase shift\nkeying (QPSK) modulation, bit error rate (BER) performance within 1 dB from the\nconstrained capacity limit is observed. \n\n"}
{"id": "1901.09885", "contents": "Title: Towards an Extremal Network Theory -- Robust GDoF Gain of Transmitter\n  Cooperation over TIN Abstract: Significant progress has been made recently in Generalized Degrees of Freedom\n(GDoF) characterizations of wireless interference channels (IC) and broadcast\nchannels (BC) under the assumption of finite precision channel state\ninformation at the transmitters (CSIT), especially for smaller or highly\nsymmetric network settings. A critical barrier in extending these results to\nlarger and asymmetric networks is the inherent combinatorial complexity of such\nnetworks. Motivated by other fields such as extremal combinatorics and extremal\ngraph theory, we explore the possibility of an extremal network theory, i.e., a\nstudy of extremal networks within particular regimes of interest. As our test\napplication, we study the GDoF benefits of transmitter cooperation in a $K$\nuser IC over the simple scheme of power control and treating interference as\nGaussian noise (TIN) for three regimes of interest -- a TIN regime where TIN\nwas shown to be GDoF optimal for the $K$ user interference channel, a CTIN\nregime where the GDoF region achievable by TIN is convex without time-sharing,\nand an SLS regime where a simple layered superposition (SLS) scheme is shown to\nbe optimal in the $K$ user MISO BC, albeit only for $K\\leq 3$. As our first\nresult, we show that under finite precision CSIT, TIN is GDoF optimal for the\n$K$ user IC throughout the CTIN regime. Furthermore, under finite precision\nCSIT, appealing to extremal network theory we obtain the following results. In\nboth TIN and CTIN regimes, we show that the extremal GDoF gain from transmitter\ncooperation over TIN is bounded regardless of the number of users: the gain is\nexactly a factor of $3/2$ in the TIN regime, and $2-1/K$ in the CTIN regime,\nfor arbitrary number of users $K>1$. However, in the SLS regime, the gain is\n$\\Theta(\\log_2(K))$, i.e., it scales logarithmically with the number of users. \n\n"}
{"id": "cs/0412111", "contents": "Title: On the asymptotic accuracy of the union bound Abstract: A new lower bound on the error probability of maximum likelihood decoding of\na binary code on a binary symmetric channel was proved in Barg and McGregor\n(2004, cs.IT/0407011). It was observed in that paper that this bound leads to a\nnew region of code rates in which the random coding exponent is asymptotically\ntight, giving a new region in which the reliability of the BSC is known\nexactly. The present paper explains the relation of these results to the union\nbound on the error probability. \n\n"}
{"id": "cs/0503063", "contents": "Title: Randomly Spread CDMA: Asymptotics via Statistical Physics Abstract: This paper studies randomly spread code-division multiple access (CDMA) and\nmultiuser detection in the large-system limit using the replica method\ndeveloped in statistical physics. Arbitrary input distributions and flat fading\nare considered. A generic multiuser detector in the form of the posterior mean\nestimator is applied before single-user decoding. The generic detector can be\nparticularized to the matched filter, decorrelator, linear MMSE detector, the\njointly or the individually optimal detector, and others. It is found that the\ndetection output for each user, although in general asymptotically non-Gaussian\nconditioned on the transmitted symbol, converges as the number of users go to\ninfinity to a deterministic function of a \"hidden\" Gaussian statistic\nindependent of the interferers. Thus the multiuser channel can be decoupled:\nEach user experiences an equivalent single-user Gaussian channel, whose\nsignal-to-noise ratio suffers a degradation due to the multiple-access\ninterference. The uncoded error performance (e.g., symbol-error-rate) and the\nmutual information can then be fully characterized using the degradation\nfactor, also known as the multiuser efficiency, which can be obtained by\nsolving a pair of coupled fixed-point equations identified in this paper. Based\non a general linear vector channel model, the results are also applicable to\nMIMO channels such as in multiantenna systems. \n\n"}
{"id": "cs/0508031", "contents": "Title: Capacity Theorems for Quantum Multiple Access Channels Abstract: We consider quantum channels with two senders and one receiver. For an\narbitrary such channel, we give multi-letter characterizations of two different\ntwo-dimensional capacity regions. The first region characterizes the rates at\nwhich it is possible for one sender to send classical information while the\nother sends quantum information. The second region gives the rates at which\neach sender can send quantum information. We give an example of a channel for\nwhich each region has a single-letter description, concluding with a\ncharacterization of the rates at which each user can simultaneously send\nclassical and quantum information. \n\n"}
{"id": "cs/0508094", "contents": "Title: Conference Key Agreement and Quantum Sharing of Classical Secrets with\n  Noisy GHZ States Abstract: We propose a wide class of distillation schemes for multi-partite entangled\nstates that are CSS-states. Our proposal provides not only superior efficiency,\nbut also new insights on the connection between CSS-states and bipartite graph\nstates. We then consider the applications of our distillation schemes for two\ncryptographic tasks--namely, (a) conference key agreement and (b) quantum\nsharing of classical secrets. In particular, we construct\n``prepare-and-measure'' protocols. Also we study the yield of those protocols\nand the threshold value of the fidelity above which the protocols can function\nsecurely. Surprisingly, our protocols will function securely even when the\ninitial state does not violate the standard Bell-inequalities for GHZ states.\nExperimental realization involving only bi-partite entanglement is also\nsuggested. \n\n"}
{"id": "cs/0512006", "contents": "Title: Capacity-Achieving Ensembles of Accumulate-Repeat-Accumulate Codes for\n  the Erasure Channel with Bounded Complexity Abstract: The paper introduces ensembles of accumulate-repeat-accumulate (ARA) codes\nwhich asymptotically achieve capacity on the binary erasure channel (BEC) with\n{\\em bounded complexity}, per information bit, of encoding and decoding. It\nalso introduces symmetry properties which play a central role in the\nconstruction of capacity-achieving ensembles for the BEC with bounded\ncomplexity. The results here improve on the tradeoff between performance and\ncomplexity provided by previous constructions of capacity-achieving ensembles\nof codes defined on graphs. The superiority of ARA codes with moderate to large\nblock length is exemplified by computer simulations which compare their\nperformance with those of previously reported capacity-achieving ensembles of\nLDPC and IRA codes. The ARA codes also have the advantage of being systematic. \n\n"}
{"id": "cs/0603123", "contents": "Title: Towards the Optimal Amplify-and-Forward Cooperative Diversity Scheme Abstract: In a slow fading channel, how to find a cooperative diversity scheme that\nachieves the transmit diversity bound is still an open problem. In fact, all\npreviously proposed amplify-and-forward (AF) and decode-and-forward (DF)\nschemes do not improve with the number of relays in terms of the diversity\nmultiplexing tradeoff (DMT) for multiplexing gains r higher than 0.5. In this\nwork, we study the class of slotted amplify-and-forward (SAF) schemes. We first\nestablish an upper bound on the DMT for any SAF scheme with an arbitrary number\nof relays N and number of slots M. Then, we propose a sequential SAF scheme\nthat can exploit the potential diversity gain in the high multiplexing gain\nregime. More precisely, in certain conditions, the sequential SAF scheme\nachieves the proposed DMT upper bound which tends to the transmit diversity\nbound when M goes to infinity. In particular, for the two-relay case, the\nthree-slot sequential SAF scheme achieves the proposed upper bound and\noutperforms the two-relay non-orthorgonal amplify-and-forward (NAF) scheme of\nAzarian et al. for multiplexing gains r < 2/3. Numerical results reveal a\nsignificant gain of our scheme over the previously proposed AF schemes,\nespecially in high spectral efficiency and large network size regime. \n\n"}
{"id": "cs/0702024", "contents": "Title: Searching for low weight pseudo-codewords Abstract: Belief Propagation (BP) and Linear Programming (LP) decodings of Low Density\nParity Check (LDPC) codes are discussed. We summarize results of\ninstanton/pseudo-codeword approach developed for analysis of the error-floor\ndomain of the codes. Instantons are special, code and decoding specific,\nconfigurations of the channel noise contributing most to the Frame-Error-Rate\n(FER). Instantons are decoded into pseudo-codewords. Instanton/pseudo-codeword\nwith the lowest weight describes the largest Signal-to-Noise-Ratio (SNR)\nasymptotic of FER, while the whole spectra of the low weight instantons is\ndescriptive of the FER vs SNR profile in the extended error-floor domain.\nFirst, we describe a general optimization method that allows to find the\ninstantons for any coding/decoding. Second, we introduce LP-specific\npseudo-codeword search algorithm that allows efficient calculations of the\npseudo-codeword spectra. Finally, we discuss results of combined BP/LP\nerror-floor exploration experiments for two model codes. \n\n"}
{"id": "cs/0703005", "contents": "Title: State Amplification Abstract: We consider the problem of transmitting data at rate R over a state dependent\nchannel p(y|x,s) with the state information available at the sender and at the\nsame time conveying the information about the channel state itself to the\nreceiver. The amount of state information that can be learned at the receiver\nis captured by the mutual information I(S^n; Y^n) between the state sequence\nS^n and the channel output Y^n. The optimal tradeoff is characterized between\nthe information transmission rate R and the state uncertainty reduction rate\n\\Delta, when the state information is either causally or noncausally available\nat the sender. This result is closely related and in a sense dual to a recent\nstudy by Merhav and Shamai, which solves the problem of masking the state\ninformation from the receiver rather than conveying it. \n\n"}
{"id": "cs/0703120", "contents": "Title: Sequential decoding for lossless streaming source coding with side\n  information Abstract: The problem of lossless fixed-rate streaming coding of discrete memoryless\nsources with side information at the decoder is studied. A random time-varying\ntree-code is used to sequentially bin strings and a Stack Algorithm with a\nvariable bias uses the side information to give a delay-universal coding system\nfor lossless source coding with side information. The scheme is shown to give\nexponentially decaying probability of error with delay, with exponent equal to\nGallager's random coding exponent for sources with side information. The mean\nof the random variable of computation for the stack decoder is bounded, and\nconditions on the bias are given to guarantee a finite $\\rho^{th}$ moment for\n$0 \\leq \\rho \\leq 1$.\n  Further, the problem is also studied in the case where there is a discrete\nmemoryless channel between encoder and decoder. The same scheme is slightly\nmodified to give a joint-source channel encoder and Stack Algorithm-based\nsequential decoder using side information. Again, by a suitable choice of bias,\nthe probability of error decays exponentially with delay and the random\nvariable of computation has a finite mean. Simulation results for several\nexamples are given. \n\n"}
{"id": "hep-ex/0202018", "contents": "Title: Comment on \"Evidence for Neutrinoless Double Beta Decay\" Abstract: We comment on the recent claim for the experimental observation of\nneutrinoless double-beta decay. We discuss several limitations in the analysis\nprovided in that paper and conclude that there is no basis for the presented\nclaim. \n\n"}
{"id": "hep-ph/0002156", "contents": "Title: Coherent Contributions of Nuclear Mesons to Electroproduction and the\n  HERMES Effect Abstract: We show that nuclear sigma, omega, and pi mesons can contribute coherently to\nenhance the electroproduction cross section on nuclei for longitudinal virtual\nphotons at low Q^2 while depleting the cross section for transverse photons. We\nare able to describe recent HERMES inelastic lepton-nucleus scattering data at\nlow Q^2 and small x using photon-meson and meson-nucleus couplings which are\nconsistent with (but not determined by) existing constraints from meson decay\nwidths, nuclear structure, deep inelastic scattering, and lepton pair\nproduction data. We find that while nuclear-coherent pion currents are not\nimportant for the present data, they could be observed at different kinematics.\nOur model for coherent meson electroproduction requires the assumption of\nmesonic currents and couplings which can be verified in separate experiments.\nThe observation of nuclear-coherent mesons in the final state would verify our\ntheory and allow the identification of a specific dynamical mechanism for\nhigher-twist processes. \n\n"}
{"id": "hep-ph/0003210", "contents": "Title: Determining the Flavour Content of the Low-Energy Solar Neutrino Flux Abstract: We study the sensitivity of the HELLAZ and Borexino solar neutrino\nexperiments on discriminating the neutrino species nu_e, anti-nu_e,\nnu_{mu,tau}, anti-nu_{mu,tau}, and nu_{sterile} using the difference in the\nrecoil electron kinetic energy spectra in elastic neutrino-electron scattering.\nWe find that one can observe a non-vanishing nu_{mu,tau} component in the solar\nneutrino flux, especially when the nu_e survival probability is low. Also, if\nthe data turn out to be consistent with nu_e <-> nu_{mu,tau} oscillations, an\nanti-nu_e component can be excluded effectively. \n\n"}
{"id": "hep-ph/0006170", "contents": "Title: QCD and the Structure of the Nucleon in Electron Scattering Abstract: The internal structure of the nucleon is discussed within the context of QCD.\nRecent progress in understanding the distribution of flavor and spin in the\nnucleon is reviewed, and prospects for extending our knowledge of nucleon\nstructure in electron scattering experiments at modern facilities such as\nJefferson Lab are outlined. \n\n"}
{"id": "hep-ph/0204194", "contents": "Title: If sterile neutrinos exist, how can one determine the total solar\n  neutrino fluxes? Abstract: The 8B solar neutrino flux inferred from a global analysis of solar neutrino\nexperiments is within 11% (1 sigma) of the predicted standard solar model value\nif only active neutrinos exist, but could be as large as 1.7 times the standard\nprediction if sterile neutrinos exist. We show that the total 8B neutrino flux\n(active plus sterile neutrinos) can be determined experimentally to about 10%\n(1 sigma) by combining charged current measurements made with the KamLAND\nreactor experiment and with the SNO CC solar neutrino experiment, provided the\nLMA neutrino oscillation solution is correct and the simulated performance of\nKamLAND is valid. Including also SNO NC data, the sterile component of the 8B\nneutrino flux can be measured by this method to an accuracy of about 12% (1\nsigma) of the standard solar model flux. Combining Super-Kamiokande and KamLAND\nmeasurements and assuming the oscillations occur only among active neutrinos,\nthe 8B neutrino flux can be measured to 6% (1 sigma); the total flux can be\nmeasured to an accuracy of about 9%. The total 7Be solar neutrino flux can be\ndetermined to an accuracy of about 28% (1 sigma) by combining measurements made\nwith the KamLAND, SNO, and gallium neutrino experiments. One can determine the\ntotal 7Be neutrino flux to a one sigma accuracy of about 11% or better by\ncomparing data from the KamLAND experiment and the BOREXINO solar neutrino\nexperiment provided both detectors work as expected. The pp neutrino flux can\nbe determined to about 15% using data from the gallium, KamLAND, BOREXINO, and\nSNO experiments. \n\n"}
{"id": "hep-ph/0208183", "contents": "Title: QED Radiative Corrections in Processes of Exclusive Pion\n  Electroproduction Abstract: Formalism for radiative correction (RC) calculation in exclusive pion\nelectroproduction on the proton is presented. A FORTRAN code EXCLURAD is\ndeveloped for the RC procedure. The numerical analysis is done in the\nkinematics of current Jefferson Lab experiments. \n\n"}
{"id": "hep-ph/0209070", "contents": "Title: $\\mu_\\nu$ Abstract: The present situation and hopes on bounding (founding) neutrino magnetic\nmoment in future are reviewed. \n\n"}
{"id": "hep-ph/0304014", "contents": "Title: Mass Spectrum of Three-Pion System in Kaluza-Klein Picture Abstract: In this note we present additional arguments in favour of Kaluza and Klein\npicture of the world. In fact, we show that formula (\\ref{KK3pi}) provided by\nKaluza-Klein approach with the fundamental scale early calculated \\cite{1}\ngives an excellent description for the mass spectrum of three-pion system. \n\n"}
{"id": "hep-ph/0306199", "contents": "Title: Roper Resonance and S_{11}(1535) from Lattice QCD Abstract: Using the constrained curve fitting method and overlap fermions with the\nlowest pion mass at $180 {\\rm MeV}$, we observe that the masses of the first\npositive and negative parity excited states of the nucleon tend to cross over\nas the quark masses are taken to the chiral limit. Both results at the physical\npion mass agree with the experimental values of the Roper resonance\n($N^{1/2+}(1440)$) and $S_{11}$ ($N^{1/2-}(1535)$). This is seen for the first\ntime in a lattice QCD calculation. These results are obtained on a quenched\nIwasaki $16^3 \\times 28$ lattice with $a = 0.2 {\\rm fm}$. We also extract the\nghost $\\eta' N$ states (a quenched artifact) which are shown to decouple from\nthe nucleon interpolation field above $m_{\\pi} \\sim 300 {\\rm MeV}$. From the\nquark mass dependence of these states in the chiral region, we conclude that\nspontaneously broken chiral symmetry dictates the dynamics of light quarks in\nthe nucleon. \n\n"}
{"id": "hep-ph/0308234", "contents": "Title: Summary of Spin Physics Parallel Sessions Abstract: We summarize the activities in the spin physics parallel sessions of the\n$8^{\\rm th}$ conference on intersections between particle and nuclear physics. \n\n"}
{"id": "hep-ph/0506083", "contents": "Title: Global analysis of three-flavor neutrino masses and mixings Abstract: We present a comprehensive phenomenological analysis of a vast amount of data\nfrom neutrino flavor oscillation and non-oscillation searches, performed within\nthe standard scenario with three massive and mixed neutrinos, and with\nparticular attention to subleading effects. The detailed results discussed in\nthis review represent a state-of-the-art, accurate and up-to-date (as of August\n2005) estimate of the three-neutrino mass-mixing parameters. \n\n"}
{"id": "hep-ph/0509008", "contents": "Title: The multiplets of finite width 0++ mesons and encounters with exotics Abstract: Complex-mass (finite-width) $0^{++}$ nonet and decuplet are investigated by\nmeans of exotic commutator method. The hypothesis of vanishing of the exotic\ncommutators leads to the system of master equations (ME). Solvability\nconditions of these equations define relations between the complex masses of\nthe nonet and decuplet mesons which, in turn, determine relations between the\nreal masses (mass formulae), as well as between the masses and widths of the\nmesons. Mass formulae are independent of the particle widths. The masses of the\nnonet and decuplet particles obey simple ordering rules. The nonet mixing angle\nand the mixing matrix of the isoscalar states of the decuplet are completely\ndetermined by solution of ME; they are real and do not depend on the widths.\nAll known scalar mesons with the mass smaller than $2000MeV$ (excluding\n$\\sigma(600)$) and one with the mass $2200\\div2400MeV$ belong to two\nmultiplets: the nonet $(a_0(980), K_0(1430), f_0(980), f_0(1710))$ and the\ndecuplet $(a_0(1450), K_0(1950), f_0(1370), f_0(1500), f_0(2200)/f_0(2330))$.\nIt is shown that the famed anomalies of the $f_0(980)$ and $a_0(980)$ widths\narise from an extra \"kinematical\" mechanism, suppressing decay, which is not\nconditioned by the flavor coupling constant. Therefore, they do not justify\nrejecting the $q\\bar{q}$ structure of them. A unitary singlet state (glueball)\nis included into the higher lying multiplet (decuplet) and is divided among the\n$f_0(1370)$ and $f_0(1500)$ mesons. The glueball contents of these particles\nare totally determined by the masses of decuplet particles. Mass ordering rules\nindicate that the meson $\\sigma(600)$ does not mix with the nonet particles. \n\n"}
{"id": "hep-ph/0701225", "contents": "Title: QCD at small x and nucleus-nucleus collisions Abstract: At large collision energy sqrt(s) and relatively low momentum transfer Q, one\nexpects a new regime of Quantum Chromo-Dynamics (QCD) known as \"saturation\".\nThis kinematical range is characterized by a very large occupation number for\ngluons inside hadrons and nuclei; this is the region where higher twist\ncontributions are as large as the leading twist contributions incorporated in\ncollinear factorization. In this talk, I discuss the onset of and dynamics in\nthe saturation regime, some of its experimental signatures, and its\nimplications for the early stages of Heavy Ion Collisions. \n\n"}
{"id": "hep-ph/0702032", "contents": "Title: Anomalous diffusion of pions at RHIC Abstract: After pointing out the difference between normal and anomalous diffusion, we\nconsider a hadron resonance cascade (HRC) model simulation for particle\nemission at RHIC and point out, that rescattering in an expanding hadron\nresonance gas leads to a heavy tail in the source distribution. The results are\ncompared to recent PHENIX measurements of the tail of the particle emitting\nsource in Au+Au collisions at RHIC. In this context, we show, how can one\ndistinguish experimentally the anomalous diffusion of hadrons from a second\norder QCD phase transition. \n\n"}
{"id": "hep-ph/0703186", "contents": "Title: Indications of the possible observation of the lowest-lying 1^{-+} QCD\n  state Abstract: We discuss properties of 1^{-+} exotic mesons within the framework of the QCD\nfield-theoretic approach. We estimate the mass of the lowest-lying 1^{-+}\nexotic meson using renormalization-improved QCD sum rules, and find that the\nmass lies around $1.26\\pm 0.15$ GeV, in good agreement with the $\\pi_1(1400)$\ndata. This state should be expected in QCD. We find that the mass for the\nlowest-lying strange 1^{-+} meson is $1.31\\pm 0.19$ GeV. Our result hints that\nthe K^*(1410) may be the lowest-lying 1^{-+} nonet state. \n\n"}
{"id": "hep-ph/9708487", "contents": "Title: A Precision Measurement of Nuclear Muon Capture on 3He Abstract: The muon capture rate in the reaction mu- 3He -> nu + 3H has been measured at\nPSI using a modular high pressure ionization chamber. The rate corresponding to\nstatistical hyperfine population of the mu-3He atom is (1496.0 +- 4.0) s^-1.\nThis result confirms the PCAC prediction for the pseudoscalar form factors of\nthe 3He-3H system and the nucleon. \n\n"}
{"id": "hep-ph/9907209", "contents": "Title: Parton saturation, production, and equilibration in high energy nuclear\n  collisions Abstract: Deeply inelastic scattering of electrons off nuclei can determine whether\nparton distributions saturate at HERA energies. If so, this phenomenon will\nalso tell us a great deal about how particles are produced, and whether they\nequilibrate, in high energy nuclear collisions. \n\n"}
{"id": "math/0208017", "contents": "Title: Packing Planes in Four Dimensions and Other Mysteries Abstract: How should you choose a good set of (say) 48 planes in four dimensions? More\ngenerally, how do you find packings in Grassmannian spaces? In this article I\ngive a brief introduction to the work that I have been doing on this problem in\ncollaboration with A. R. Calderbank, J. H. Conway, R. H. Hardin, E. M. Rains\nand P. W. Shor. We have found many nice examples of specific packings (70\n4-spaces in 8-space, for instance), several general constructions, and an\nembedding theorem which shows that a packing in Grassmannian space G(m,n) is a\nsubset of a sphere in R^D, where D = (m+2)(m-1)/2, and leads to a proof that\nmany of our packings are optimal. There are a number of interesting unsolved\nproblems. \n\n"}
{"id": "math/0401045", "contents": "Title: Unitary Space Time Constellation Analysis: An Upper Bound for the\n  Diversity Abstract: The diversity product and the diversity sum are two very important parameters\nfor a good-performing unitary space time constellation. A basic question is\nwhat the maximal diversity product (or sum) is. In this paper we are going to\nderive general upper bounds on the diversity sum and the diversity product for\nunitary constellations of any dimension $n$ and any size $m$ using packing\ntechniques on the compact Lie group U(n). \n\n"}
{"id": "nucl-ex/0003005", "contents": "Title: Fragment Kinetic Energies and Modes of Fragment Formation Abstract: Kinetic energies of light fragments A <= 10 from the decay of target\nspectators in 197Au 197Au collisions at 1000 MeV per nucleon have been measured\nwith high-resolution telescopes at backward angles. Except for protons and\napart from the observed evaporation components, the kinetic-energy spectra\nexhibit slope temperatures of about 17 MeV, independent of the particle\nspecies, but not corresponding to the thermal or chemical degrees of freedom at\nbreakup. It is suggested that these slope temperatures may reflect the\nintrinsic Fermi motion and thus the bulk density of the spectator system at the\ninstant of becoming unstable.\n  PACS numbers: 25.70.Pq, 21.65.+f, 25.70.Mn \n\n"}
{"id": "nucl-ex/0010018", "contents": "Title: High Energy Heavy Ion Collisions: The Physics of Super-dense Matter Abstract: I review experimental results from ultrarelativistic heavy ion collisions.\nSignals of new physics and observables reflecting the underlying collision\ndynamics are presented, and the evidence for new physics discussed.\nMeasurements of higher energy collisions at RHIC are described, and I give some\nof the very first results. \n\n"}
{"id": "nucl-ex/0012010", "contents": "Title: Status of experimental investigations of $\\eta$-mesic nuclei Abstract: Short history of ideas concerning a possible existence of bound states of the\n$\\eta$-meson and a nucleus is considered. First experiments at BNL and LAMPF on\nsearching for these states are discussed. Another recent experiment using the\nphoton beam of the 1 GeV electron synchrotron of LPI is described. Possible\nexperiments on studying $\\eta$-mesic nuclei using a proton beam (at Nuclotron\nof Dubna) and a $\\gamma$-beam (CEBAF, JLAB) are suggested. \n\n"}
{"id": "nucl-ex/0102009", "contents": "Title: HBT in Relativisitic Heavy Ion Collisions Abstract: A summary of current interferometry data in relativistic heavy ions is\npresented. At sqrt{s}=17GeV a sudden increase in the pion source volume is\nobserved for central PbPb collisions.\n  This seems to imply that the pion phase density has reached a limit.\n  The source size of different particles decreases with mass when the\ntransverse velocity is held constant but increases with mass when the\ntransverse mass is held constant. The antiproton source radius is larger than\nthe proton source radius. So far no long lived source has been seen. The pion\nsource size varies slowly with rapidity but more rapidly with transverse mass\nimplying strong transverse flow. There is very slow increase of pion radii with\nsqrt{s}. \n\n"}
{"id": "nucl-ex/0207019", "contents": "Title: Soft Particle Spectra at STAR Abstract: We presented the multiplicity and the spectra of many particles in Au+Au at\nsqrt(s_{_{NN}})=130 GeV measured by STAR detector. Their connections to initial\ncondition, baryon creation, freeze-out condition and strangeness enhancement\nwere discussed. \n\n"}
{"id": "nucl-ex/0212018", "contents": "Title: Fragment Charge Correlations and Spinodal Decomposition in Finite\n  Nuclear Systems Abstract: Enhanced production of events with almost equal-sized fragments is\nexperimentally revealed by charge correlations in the multifragmentation of a\nfinite nuclear system selected in $^{129}$Xe central collisions on $^{nat}$Sn.\nThe evolution of their weight with the incident energy: 32, 39, 45, 50 AMeV, is\nmeasured.Dynamical stochastic mean field simulations performed at 32 AMeV, in\nwhich spinodal instabilities are responsible for multifragmentation, exhibit a\nsimilar enhancement of this kind of events. The above experimental observation\nevidences the spinodal decomposition of hot finite nuclear matter as the origin\nof multifragmentation in the Fermi energy regime. \n\n"}
{"id": "nucl-ex/0301012", "contents": "Title: Measurement of the Polarized Structure Function $\\sigma_{LT^\\prime}$ for\n  $p(\\vec{e},e'p)\\pi^o$ in the $\\Delta(1232)$ Resonance Region Abstract: The polarized longitudinal-transverse structure function $\\sigma_{LT^\\prime}$\nhas been measured in the $\\Delta(1232)$ resonance region at $Q^2=0.40$ and 0.65\nGeV$^2$. Data for the $p(\\vec e,e'p)\\pi^o$ reaction were taken at Jefferson Lab\nwith the CEBAF Large Acceptance Spectrometer (CLAS) using longitudinally\npolarized electrons at an energy of 1.515 GeV. For the first time a complete\nangular distribution was measured, permitting the separation of different\nnon-resonant amplitudes using a partial wave analysis. Comparison with previous\nbeam asymmetry measurements at MAMI indicate a deviation from the predicted\n$Q^2$ dependence of $\\sigma_{LT^{\\prime}}$ using recent phenomenological\nmodels. \n\n"}
{"id": "nucl-ex/0305008", "contents": "Title: Particle dependence of elliptic flow in Au+Au collisions at\n  $\\sqrt{s_{NN}}=$ 200 GeV Abstract: The elliptic flow parameter ($v_2$) for $K_S^0$ and $\\Lambda+\\bar{\\Lambda}$\nhas been measured at mid-rapidity in Au + Au collisions at\n$\\sqrt{s_{_{NN}}}=200$ GeV by the STAR collaboration. The $v_2$ values for both\n$K_S^{0}$ and $\\Lambda+\\bar{\\Lambda}$ saturate at moderate $p_T$, deviating\nfrom the hydrodynamic behavior observed in the lower $p_T$ region. The\nsaturated $v_2$ values and the $p_T$ scales where the deviation begins are\nparticle dependent. The particle-type dependence of $v_2$ shows features\nexpected from the hadronization of a partonic ellipsoid by coalescence of\nco-moving quarks. These results will be discussed in relation to the nuclear\nmodification factor ($R_{CP}$) which has also been measured for $K_S^0$ and\n$\\Lambda+\\bar{\\Lambda}$ by the STAR collaboration. \n\n"}
{"id": "nucl-ex/0307005", "contents": "Title: Experimental study of pp eta dynamics in the pp --> ppeta reaction Abstract: A high statistics measurement of the pp --> ppeta reaction at an excess\nenergy of Q = 15.5 MeV has been performed at the internal beam facility\nCOSY-11. The stochastically cooled proton beam and the used detection system\nallowed to determine the momenta of the outgoing protons with a precision of 4\nMeV/c (sigma) in the center-of-mass frame. The determination of the\nfour-momentum vectors of both outgoing protons allowed to derive the complete\nkinematical information of the ppeta-system.\n  An unexpectedly large enhancement of the occupation density in the\nkinematical regions of low proton-eta relative momenta is observed. A\ndescription taking the proton-proton and the eta-proton interaction into\naccount and assuming an on-shell incoherent pairwise interaction among the\nproduced particles fails to explain this strong effect. Its understanding will\nrequire a rigorous three-body approach to the ppeta system and the precise\ndetermination of contributions from higher partial waves.\n  We also present an invariant mass spectrum of the proton-proton system\ndetermined at Q = 4.5 MeV. Interestingly, the enhancement at large relative\nmomenta between protons is visible also at such a small excess energy.\n  In contrast to all other determined angular distributions, the orientation of\nthe emission plane with respect to the beam direction is extracted to be\nanisotropic. \n\n"}
{"id": "nucl-ex/0403027", "contents": "Title: Elliptic flow of multi-strange baryons Xi and Omega in Au+Au collisions\n  at sqrt(s_NN)=200 GeV Abstract: The first measurement of the elliptic transverse flow for multi-strange\nbaryons Xi and Omega in high energy heavy ion collisions is presented, which\nmay indicate the presence of partonic collectivity. A hydrodynamically inspired\nmodel fit to the transverse momentum spectra and elliptic flow of Xi- and\nAntiXi+ indicates that these particles might be emitted from the system at a\nhigh temperature (~150 MeV) with significant radial transverse flow and that\nthe emitting system is spatially asymmetric. \n\n"}
{"id": "nucl-ex/0403046", "contents": "Title: Search for exotic baryons in double radiative capture on pionic hydrogen Abstract: We report a search for low-lying exotic baryons via double radiative capture\non pionic hydrogen. The data were collected at the TRIUMF cyclotron using the\nRMC spectrometer by detecting gamma-ray pairs from pion stops in liquid\nhydrogen. No evidence was found to support an earlier claim for exotic baryons\nof masses 1004 and 1044 MeV/$c^2$. We obtain upper limits on the branching\nratios for double radiative capture via these exotic states of $< 3 \\times\n10^{-6}$ and $< 4 \\times 10^{-6}$ respectively. \n\n"}
{"id": "nucl-ex/0404007", "contents": "Title: Scanning the phases of QCD with BRAHMS Abstract: BRAHMS has the ability to study relativistic heavy ion collisions from the\nfinal freeze-out of hadrons all the way back to the initial wave-function of\nthe gold nuclei. This is accomplished by studying hadrons with a very wide\nrange of momenta and angles. In doing so we can scan various phases of QCD,\nfrom a hadron gas, to a quark gluon plasma and perhaps to a color glass\ncondensate. \n\n"}
{"id": "nucl-ex/0406026", "contents": "Title: Bulk Observables in pp, dA and AA Collisions at RHIC Abstract: Results on charged particle production in p+p, d+Au and Au+Au collisions at\nRHIC energies (sqrt(s_NN) = 19.6 to 200 GeV) are presented. The data exhibit\nremarkable, and simple, scaling behaviors, the most prominent of which are\ndiscussed. \n\n"}
{"id": "nucl-ex/0410012", "contents": "Title: Production of phi mesons at mid-rapidity in sqrt(s_NN) = 200 GeV Au+Au\n  collisions at RHIC Abstract: We present the first results of meson production in the K^+K^- decay channel\nfrom Au+Au collisions at sqrt(s_NN) = 200 GeV as measured at mid-rapidity by\nthe PHENIX detector at RHIC. Precision resonance centroid and width values are\nextracted as a function of collision centrality. No significant variation from\nthe PDG accepted values is observed. The transverse mass spectra are fitted\nwith a linear exponential function for which the derived inverse slope\nparameter is seen to be constant as a function of centrality. These data are\nalso fitted by a hydrodynamic model with the result that the freeze-out\ntemperature and the expansion velocity values are consistent with the values\npreviously derived from fitting single hadron inclusive data. As a function of\ntransverse momentum the collisions scaled peripheral.to.central yield ratio RCP\nfor the is comparable to that of pions rather than that of protons. This result\nlends support to theoretical models which distinguish between baryons and\nmesons instead of particle mass for explaining the anomalous proton yield. \n\n"}
{"id": "nucl-ex/0411029", "contents": "Title: Precision measurement of the half-life and the decay branches of 62Ga Abstract: In an experiment performed at the Accelerator Laboratory of the University of\nJyvaskyla, the beta-decay half-life of 62Ga has been studied with high\nprecision using the IGISOL technique. A half-life of T1/2 = 116.09(17)ms was\nmeasured. Using beta-gamma coincidences, the gamma intensity of the 954keV\ntransition and an upper limit of the beta-decay feeding of the 0+_2 state have\nbeen extracted. The present experimental results are compared to previous\nmeasurements and their impact on our understanding of the weak interaction is\ndiscussed. \n\n"}
{"id": "nucl-ex/0412021", "contents": "Title: Application of PbWO4 crystal scintillators in experiment to search for\n  double beta decay of 116Cd Abstract: PbWO4 crystal scintillators are discussed as an active shield and\nlight-guides in 116Cd double beta decay experiment with CdWO4 scintillators.\nScintillation properties and radioactive contamination of PbWO4 scintillators\nwere investigated. Energy resolution of CdWO4 detector, coupled to PbWO4\ncrystal as a light-guide, was tested. Efficiency of PbWO4-based active shield\nto suppress background from the internal contamination of PbWO4 crystals was\ncalculated. Using of lead tungstate crystal scintillators as high efficiency\n4-pi active shield could allow to build sensitive double beta experiment with\n116CdWO4 crystal scintillators. \n\n"}
{"id": "nucl-ex/0504006", "contents": "Title: Correlations in STAR: interferometry and event structure Abstract: STAR observes a complex picture of RHIC collisions where correlation effects\nof different origins -- initial state geometry, semi-hard scattering,\nhadronization, as well as final state interactions such as quantum intensity\ninterference -- coexist. Presenting the measurements of flow, mini-jet\ndeformation, modified hadronization, and the Hanbury Brown and Twiss effect, we\ntrace the history of the system from the initial to the final state. The\nresulting picture is discussed in the context of identifying the relevant\ndegrees of freedom and the likely equilibration mechanism. \n\n"}
{"id": "nucl-ex/0504031", "contents": "Title: Incident energy dependence of pt correlations at relativistic energies Abstract: We present results for two-particle transverse momentum correlations, <dpt,i\ndpt,j>, as a function of event centrality for Au+Au collisions at sqrt(sNN) =\n20, 62, 130, and 200 GeV at the Relativistic Heavy Ion Collider. We observe\ncorrelations decreasing with centrality that are similar at all four incident\nenergies. The correlations multiplied by the multiplicity density increase with\nincident energy and the centrality dependence may show evidence of processes\nsuch as thermalization, minijet production, or the saturation of transverse\nflow. The square root of the correlations divided by the event-wise average\ntransverse momentum per event shows little or no beam energy dependence and\ngenerally agrees with previous measurements at the Super Proton Synchrotron. \n\n"}
{"id": "nucl-ex/0509034", "contents": "Title: Charged-Particle Pseudorapidity Distributions in Au+Au Collisions at\n  sqrt(s_NN)=62.4 GeV Abstract: The charged-particle pseudorapidity density for Au+Au collisions at\nsqrt(s_NN)=62.4 GeV has been measured over a wide range of impact parameters\nand compared to results obtained at other energies. As a function of collision\nenergy, the pseudorapidity distribution grows systematically both in height and\nwidth. The mid-rapidity density is found to grow approximately logarithmically\nbetween AGS energies and the top RHIC energy. As a function of centrality,\nthere is an approximate factorization of the centrality dependence of the\nmid-rapidity yields and the overall multiplicity scale. The new results at\nsqrt(s_NN)=62.4 GeV confirm the previously observed phenomenon of ``extended\nlongitudinal scaling'' in the pseudorapidity distributions when viewed in the\nrest frame of one of the colliding nuclei. It is also found that the evolution\nof the shape of the distribution with centrality is energy independent, when\nviewed in this reference frame. As a function of centrality, the total charged\nparticle multiplicity scales linearly with the number of participant pairs as\nit was observed at other energies. \n\n"}
{"id": "nucl-ex/0511043", "contents": "Title: Two-particle azimuthal correlations at high transverse momentum in Pb-Au\n  at 158 AGeV/c Abstract: The study of two-particle azimuthal correlations at high transverse momentum\nhas become an important tool to investigate the interaction of hard partons\nwith the medium formed in high-energy nucleus-nucleus collisions. At SPS\nenergies, pioneering studies by the CERES collaboration indicated a significant\nmodification of the away-side structure in central collisions. Here we present\nnew results emerging from the analysis of the year 2000 data set recorded with\nthe CERES Time-Projection Chamber, which provides excellent tracking efficiency\nand significantly improved momentum determination. \n\n"}
{"id": "nucl-ex/0609015", "contents": "Title: Measurements of the Electron-Helicity Dependent Cross Sections of Deeply\n  Virtual Compton Scattering with CEBAF at 12 GeV Abstract: We propose precision measurements of the helicity-dependent and helicity\nindependent cross sections for the ep->epg reaction in Deeply Virtual Compton\nScattering (DVCS) kinematics. DVCS scaling is obtained in the limits\nQ^2>>Lambda_{QCD}^2, x_Bj fixed, and -\\Delta^2=-(q-q')^2<<Q^2. We consider the\nspecific kinematic range Q^2>2 GeV^2, W>2 GeV, and -\\Delta^21 GeV^2. We will\nuse our successful technique from the 5.75 GeV Hall A DVCS experiment\n(E00-110). With polarized 6.6, 8.8, and 11 GeV beams incident on the liquid\nhydrogen target, we will detect the scattered electron in the Hall A HRS-L\nspectrometer (maximum central momentum 4.3 GeV/c) and the emitted photon in a\nslightly expanded PbF_2 calorimeter. In general, we will not detect the recoil\nproton. The H(e,e'g)X missing mass resolution is sufficient to isolate the\nexclusive channel with 3% systematic precision. \n\n"}
{"id": "nucl-ex/0611029", "contents": "Title: Heavy Flavor Production at PHENIX at RHIC Abstract: A study of heavy flavor production in different collision systems in various\nkinematic regions presents an opportunity to probe cold nuclear medium and hot\ndense matter effects. Results from the PHENIX experiment on $J/\\psi$ and open\ncharm production in Au+Au and Cu+Cu collisions at $\\sqrt{s_{NN}}$ =200 GeV are\npresented. The data show strong $J/\\psi$ suppression in central AA collisions,\nsimilar to NA50 results, and strong suppression in high $p_T$ open charm\nproduction. The $J/\\psi$ production in Au+Au and d+Au collisions is compared to\nunderstand the cold nuclear medium effects. The data show significant cold\nnuclear effects in charm production in d+Au collisions at forward and backward\nrapidity ranges. \n\n"}
{"id": "nucl-ex/0612007", "contents": "Title: A new SPS programme Abstract: A new experiemntal program to study hadron production in hadron-nucleus and\nnucleus-nucleus collisions at the CERN SPS has been recently proposed by the\nNA49-future collaboration. The physics goals of the program are: (i) search for\nthe critical point of strongly interacting matter and a study of the properties\nof the onset of deconfinemnt in nucleus-nucleus collisions, (ii) measurements\nof correlations, fluctuations and hadron spectra at high transverse momentum in\nproton-nucleus collisions needed as for better understanding of nucleus-nucleus\nresults, (iii) measurements of hadron production in hadron-nucleus interactions\nneeded for neutrino (T2K) and cosmic-ray (Pierre Auger Observatory and KASCADE)\nexpriments. The physics of the nucleus-nucleus program is reviewed in this\npresentation. \n\n"}
{"id": "nucl-ex/0612014", "contents": "Title: Open questions in quarkonium and electromagnetic probes Abstract: In my (\"not a summary\") talk at the Hard Probes 2006 conference, I gave \"a\npersonal and surely biased view on only a few of the many open questions on\nquarkonium and electromagnetic probes\". Some of the points reported in that\ntalk are exposed in this paper, having in mind the most important of all the\nopen questions: do we have, today, from experimental data on electromagnetic\nprobes and quarkonium production, convincing evidence that shows, beyond\nreasonable doubt, the existence of \"new physics\" in high-energy heavy-ion\ncollisions? \n\n"}
{"id": "nucl-ex/0701007", "contents": "Title: The WITCH Experiment: towards weak interactions studies. Status and\n  prospects Abstract: Primary goal of the WITCH experiment is to test the Standard Model for a\npossible ad-mixture of a scalar or tensor type interaction in beta-decay. This\ninformation will be inferred from the shape of the recoil energy spectrum. The\nexperimental set-up was completed and is under intensive commissioning at\nISOLDE (CERN). It combines a Penning trap to store the ions and a retardation\nspectrometer to probe the recoil ion energy. A brief overview of the WITCH\nset-up and the results of commissioning tests performed until now are\npresented. Finally, perspectives of the physics program are reviewed. \n\n"}
{"id": "nucl-ex/0702014", "contents": "Title: Scaling of the charm cross-section and modification of charm $p_{T}$\n  spectra at RHIC Abstract: Charm production from the direct reconstruction of $D^0$ ($D^0\\to K\\pi$ up to\n2 GeV/$c$) and indirect lepton measurements via charm semileptonic decays\n($c\\to e+X$ at 0.9\\textless$p_T$\\textless5.0 GeV/$c$ and $c\\to \\mu+X$ at\n0.17\\textless$p_{T}$\\textless0.25 GeV/$c$) at $\\sqrt{s_{_{NN}}}=200$ GeV Au+Au\ncollisions are analyzed. The transverse momentum ($p_T$) spectra and the\nnuclear modification factors for $D^0$ and for leptons from heavy flavor decays\nis presented. Scaling of charm cross-section with number of binary collisions\nat $\\sqrt{s_{_{NN}}}=200$ GeV from d+Au to Au+Au collisions is reported. \n\n"}
{"id": "nucl-ex/0702015", "contents": "Title: Selected results on Strong and Coulomb-induced correlations from the\n  STAR experiment Abstract: Using recent high-statistics STAR data from Au+Au and Cu+Cu collisions at\nfull RHIC energy I discuss strong and Coulomb-induced final state interaction\neffects on identical ($\\pi-\\pi$) and non-identical ($\\pi-\\Xi$) particle\ncorrelations. Analysis of $\\pi-\\Xi$ correlations reveals the strong and\nCoulomb-induced FSI effects allowing for the first time to estimate space\nextension of $\\pi$ and $\\Xi$ sources and average shift between them. Source\nimaging technique providing clean separation of these effects from effects due\nto the source function itself is applied to one-dimensional relative momentum\ncorrelation function of identical pions. For low momentum pions and/or\nnon-central collisions large departure from a single-Gaussian shape is\nobserved. \n\n"}
{"id": "nucl-ex/0702028", "contents": "Title: Heavy Ion Physics at RHIC Abstract: The status of the physics of heavy ion collisions is reviewed based on\nmeasurements over the past 6 years from the Relativistic Heavy Ion Collider\n(RHIC) at Brookhaven National Laboratory. The dense nuclear matter produced in\nAu+Au collisions with nucleon-nucleon c.m. energy $\\sqrt{s_{NN}}=200$ GeV at\nRHIC corresponds roughly to the density and temperature of the universe a few\nmicroseconds after the `big-bang' and has been described as \"a perfect liquid\"\nof quarks and gluons, rather than the gas of free quarks and gluons, ``the\nquark-gluon plasma\" as originally envisaged. The measurements and arguments\nleading to this description will be presented. \n\n"}
{"id": "nucl-ex/9612002", "contents": "Title: Probing the quantum-mechanical equivalent-photon spectrum for\n  electromagnetic dissociation of relativistic uranium projectiles Abstract: Electromagnetic fission cross sections for the reactions U + (Be, C, Al, Cu,\nIn, Au, U) at E/A = 0.6 and 1.0 GeV are compared to theoretical calculations\nusing recently proposed quantum-mechanical equivalent-photon spectra. In\ncontrast to semi-classical calculations, systematically lower cross sections\nare obtained that cannot reproduce the experimental results. Furthermore, we\npoint out that the study of electromagnetic fission cross sections or\nelectromagnetic 1-neutron removal cross sections alone cannot provide\nunambiguous information on the excitation of the double giant dipole resonance. \n\n"}
{"id": "nucl-ex/9801003", "contents": "Title: A direct measurement of short range NN correlations in nuclei via the\n  reaction C(p,2p+n) Abstract: The reaction 12C(p,2p+n) was measured at beam momenta of 5.9 and 7.5 GeV/c..\nWe established the quasi-elastic character of the reaction C(p,2p) at\n$\\theta_{cm}\\simeq 90^o$, in a kinematically complete measurement. The neutron\nmomentum was measured in triple coincidence with the two emerging high momentum\nprotons. We present the correlation between the momenta of the struck target\nproton and the neutron. The events are associated with the high momentum\ncomponents of the nuclear wave function. We conclude that two-nucleon short\nrange correlations have been seen experimentally. The conclusion is based on\nkinematical correlations and is not based on specific theoretical models. \n\n"}
{"id": "nucl-ex/9907016", "contents": "Title: Spin Correlation Coefficients in pp-->pnpi+ from 325 to 400 MeV Abstract: The spin correlation coefficient combinations Axx + Ayy, Axx - Ayy and the\nanalyzing powers Ay(theta) were measured for pp-->pnpi+ at beam energies of\n325, 350, 375 and 400 MeV. A polarized internal atomic hydrogen target and a\nstored, polarized proton beam were used. These polarization observables are\nsensitive to contributions of higher partial waves. A comparison with recent\ntheoretical calculations is provided. \n\n"}
{"id": "nucl-th/0005033", "contents": "Title: Probing the Structure of Nucleons in the Resonance Region Abstract: Status, open questions, and future prospects of the physics of excited\nnucleons are discussed. Emphasis is on the study of the structure of nucleons\nvia measurements of their electromagnetic transition form factors, the search\nfor \"missing\" resonances, the spin structure of the nucleon in the resonance\nregion, and connections between the resonance and the deep-inelastic regimes. \n\n"}
{"id": "nucl-th/0009078", "contents": "Title: Robust Nuclear Observables and Constraints on Random Interactions Abstract: The predictions of the IBM two-body random ensemble are compared to empirical\nresults on nuclei from Z=8 to 100. Heretofore unrecognized but robust empirical\ntrends are identified and related both to the distribution of valence nucleon\nnumbers and to the need for and applicability of specific, non-random\ninteractions. Applications to expected trends in exotic nuclei are discussed. \n\n"}
{"id": "nucl-th/0108004", "contents": "Title: Is early thermalization achieved only near midrapidity at RHIC ? Abstract: The pseudorapidity dependence of elliptic flow in Au+Au collisions at 130 $A$\nGeV is studied within a full three-dimensional hydrodynamic model in the\nlight-cone coordinate. First, we prepare two initial conditions in the\nhydrodynamic model for analyzing elliptic flow. Both initial conditions lead to\nreasonable agreement with single particle spectra in central and semi-central\ncollisions. Next, by using these hydrodynamic simulations, we compare elliptic\nflow as a function of pseudorapidity with experimental data recently measured\nby the PHOBOS Collaboration. Our results are in agreement with experimental\ndata only near midrapidity. This suggests that thermalization in the early\nstage of collisions is not achieved in forward and backward rapidity regions. \n\n"}
{"id": "nucl-th/0110040", "contents": "Title: Analysis of particle production in ultra-relativistic heavy ion\n  collisions within a two-source statistical model Abstract: The experimental data on hadron yields and ratios in central lead-lead and\ngold-gold collisions at 158 AGeV/$c$ (SPS) and $\\sqrt{s} = 130$ AGeV (RHIC),\nrespectively, are analysed within a two-source statistical model of an ideal\nhadron gas. A comparison with the standard thermal model is given. The two\nsources, which can reach the chemical and thermal equilibrium separately and\nmay have different temperatures, particle and strangeness densities, and other\nthermodynamic characteristics, represent the expanding system of colliding\nheavy ions, where the hot central fireball is embedded in a larger but cooler\nfireball. The volume of the central source increases with rising bombarding\nenergy. Results of the two-source model fit to RHIC experimental data at\nmidrapidity coincide with the results of the one-source thermal model fit,\nindicating the formation of an extended fireball, which is three times larger\nthan the corresponding core at SPS. \n\n"}
{"id": "nucl-th/0205064", "contents": "Title: Nuclear modification of heavy quark fragmentation function and J/psi\n  production in ultrarelativistic heavy ion collisions Abstract: In ultrarelativistic heavy ion collisions, charm quark fragmentation is\nmodified due to the melting of strings inside the high density partonic matter.\nD mesons produced in hadronization can further produce J/psi particles. Using a\nmultiphase transport model, we investigate the effect on the rapidity\ndistribution of the produced J/psi particles with two different charm quark\nfragmentation functions. It is shown that the J/psi rapidity distribution is\nsensitive to the nuclear modification of charm quark fragmentation and thus is\na good indicator of the onset of string melting and the production of\ndeconfined partonic matter. \n\n"}
{"id": "nucl-th/0301078", "contents": "Title: Bound Nucleon Form Factors, Quark-Hadron Duality, and Nuclear EMC Effect Abstract: We discuss the electromagnetic form factors, axial form factors, and\nstructure functions of a bound nucleon in the quark-meson coupling (QMC) model.\nFree space nucleon form factors are calculated using the improved cloudy bag\nmodel (ICBM). After describing finite nuclei and nuclear matter in the\nquark-based QMC model, we compute the in-medium modification of the bound\nnucleon form factors in the same framework. Finally, limits on the medium\nmodification of the bound nucleon $F_2$ structure function are obtained using\nthe calculated in-medium electromagnetic form factors and local quark-hadron\nduality. \n\n"}
{"id": "nucl-th/0412025", "contents": "Title: DVCS-Dissociation of the Deuteron and the EMC Effect Abstract: The break-up of the deuteron during deeply-virtual Compton scattering, gamma*\nd --> gamma(*) n p, is explored. In the effective field theory describing\nnucleon dynamics at momenta below the pion mass, the EMC effect results from\nfour-nucleon interactions with the twist-2 operators, appropriate for\ndescribing forward, and near-forward, matrix elements in the two-nucleon\nsystem. We point out that the break-up of the deuteron to low-energy final\nstates during deeply-virtual Compton scattering is a process with which to\nexplore strong-interaction physics closely related to that responsible for the\nEMC effect. The single-nucleon contribution to the break-up depends on the\nmoments of the spin-dependent structure functions and contributions from local\nfour-nucleon operators. Experimental deviations from the single-nucleon\nprediction would provide a probe of strong interactions complimentary to the\nEMC effect. \n\n"}
{"id": "nucl-th/0412103", "contents": "Title: HBT Interferometry: Historical Perspective Abstract: I review the history of HBT interferometry, since its discovery in the mid\n1950's, up to the recent developments and results from BNL/RHIC experiments. I\nfocus the discussion on the contributions to the subject given by members of\nour Brazilian group. \n\n"}
{"id": "nucl-th/0501083", "contents": "Title: A Novel Dynamical Approach To Relativistic Heavy Ion Collisions Abstract: A transport model for ultra-relativistic nucleus-nucleus collisions based on\nthe mean free path approach is proposed. The method is manifestly Lorentz\ninvariant. We discuss some calculations for pp and AA collisions and compare to\na previously proposed transport model and to data. We demonstrate that our\napproach gives a different impact parameter distribution already in pp\ncollisions as compared to the previous one. The role of hadronization times is\ndiscussed.\n  Comparison to data is reasonable and the model can be easily modified to take\ninto account genuine many body effects and quantum statistics similarly to low\nenergy heavy ion collisions. \n\n"}
{"id": "nucl-th/0509102", "contents": "Title: The last bursts of Quark Gluon Plasma Abstract: We study the behavior of the scalar glueball inside a Quark Gluon Plasma. We\nfollow the fireball from the plasma phase to the hadronic phase and observe\nthat an interesting phenomenon might occur which could have experimental\nconsequences as a signature of Quark Gluon Plasma. \n\n"}
{"id": "nucl-th/0606030", "contents": "Title: Box diagram in the elastic electron-proton scattering Abstract: We present an evaluation of box diagram for the elastic $ep$ scattering with\nproton in the intermediate state. Using analytic properties of the proton form\nfactors we express the amplitude via twofold integral, which involves the form\nfactors in the space-like region only. Therefore experimentally measured form\nfactors can be used in the calculations directly. The numerical calculation is\ndone with the form factors extracted by Rosenbluth, as well as by polarization\ntransfer methods. The dependence of the results on the form factor choice is\nsmall for $Q^2 < 6 GeV^2$, but becomes sizable at higher $Q^2$. \n\n"}
{"id": "nucl-th/9707048", "contents": "Title: How dense does parton matter get in Pb + Pb Collisions at the CERN SPS? Abstract: We examine the qualitative features of parton production through\nmaterialization in heavy-ion collisions within perturbative QCD, and estimate\nthe magnitude of the resulting parton density created during the early stage of\nthe collisions. The implications for ``anomalous'' $J/\\psi$ suppression\nobserved in Pb+Pb collisions at the CERN SPS are discussed. We argue that the\nA-dependence of absorption of $J/\\psi$ by (partonic) comovers is steeper than\nassumed in most phenomenological models, because the absorption process is\ndominated by quasi-perturbative QCD interactions. Our argument is supported by\nresults recently obtained in the framework of the parton cascade model. We\npredict significant ``anomalous'' suppression for Pb+Pb collisions at the\nCERN-SPS, but not for S+U collisions. \n\n"}
{"id": "nucl-th/9709056", "contents": "Title: Experimental and Computer Simulation Study of the Radionuclides Produced\n  in Thin Bi-209 Targets by 130 MeV and 1.5 GeV Protons Abstract: The results of experimental and computer simulation studies of the yields of\nresidual product nuclei in Bi-209 thin targets irradiated by 130 MeV and 1.5\nGeV protons are presented. The yields were measured by direct high-precision\ngamma-spectrometry. The gamma-spectrometer resolution was 1.8 keV in the 1332\nkeV line. The gamma-spectra were processed by the ASPRO code. The gamma-lines\nwere identified, and the cross sections defined, by the SIGMA code using the\nGDISP radioactive database. The process was monitored by the Al-27(p,x)Na-24\nreaction. Results are presented for comparisons between the 209-Bi(p,x)\nreaction yields obtained experimentally and simulated by the HETC, GNASH,\nLAHET, INUCL, CEM95, CASCADE, and ALICE codes. \n\n"}
{"id": "physics/0405044", "contents": "Title: Least Dependent Component Analysis Based on Mutual Information Abstract: We propose to use precise estimators of mutual information (MI) to find least\ndependent components in a linearly mixed signal. On the one hand this seems to\nlead to better blind source separation than with any other presently available\nalgorithm. On the other hand it has the advantage, compared to other\nimplementations of `independent' component analysis (ICA) some of which are\nbased on crude approximations for MI, that the numerical values of the MI can\nbe used for:\n  (i) estimating residual dependencies between the output components;\n  (ii) estimating the reliability of the output, by comparing the pairwise MIs\nwith those of re-mixed components;\n  (iii) clustering the output according to the residual interdependencies.\n  For the MI estimator we use a recently proposed k-nearest neighbor based\nalgorithm. For time sequences we combine this with delay embedding, in order to\ntake into account non-trivial time correlations. After several tests with\nartificial data, we apply the resulting MILCA (Mutual Information based Least\ndependent Component Analysis) algorithm to a real-world dataset, the ECG of a\npregnant woman.\n  The software implementation of the MILCA algorithm is freely available at\nhttp://www.fz-juelich.de/nic/cs/software \n\n"}
{"id": "quant-ph/0206186", "contents": "Title: General formulas for capacity of classical-quantum channels Abstract: The capacity of a classical-quantum channel (or in other words the classical\ncapacity of a quantum channel) is considered in the most general setting, where\nno structural assumptions such as the stationary memoryless property are made\non a channel. A capacity formula as well as a characterization of the strong\nconverse property is given just in parallel with the corresponding classical\nresults of Verd\\'{u}-Han which are based on the so-called information-spectrum\nmethod. The general results are applied to the stationary memoryless case with\nor without cost constraint on inputs, whereby a deep relation between the\nchannel coding theory and the hypothesis testing for two quantum states is\nelucidated. no structural assumptions such as the stationary memoryless\nproperty are made on a channel. A capacity formula as well as a\ncharacterization of the strong converse property is given just in parallel with\nthe corresponding classical results of Verdu-Han which are based on the\nso-called information-spectrum method. The general results are applied to the\nstationary memoryless case with or without cost constraint on inputs, whereby a\ndeep relation between the channel coding theory and the hypothesis testing for\ntwo quantum states is elucidated. \n\n"}
{"id": "quant-ph/0607216", "contents": "Title: The Chernoff lower bound for symmetric quantum hypothesis testing Abstract: We consider symmetric hypothesis testing in quantum statistics, where the\nhypotheses are density operators on a finite-dimensional complex Hilbert space,\nrepresenting states of a finite quantum system. We prove a lower bound on the\nasymptotic rate exponents of Bayesian error probabilities. The bound represents\na quantum extension of the Chernoff bound, which gives the best asymptotically\nachievable error exponent in classical discrimination between two probability\nmeasures on a finite set. In our framework, the classical result is reproduced\nif the two hypothetic density operators commute. Recently, it has been shown\nelsewhere [Phys. Rev. Lett. 98 (2007) 160504] that the lower bound is\nachievable also in the generic quantum (noncommutative) case. This implies that\nour result is one part of the definitive quantum Chernoff bound. \n\n"}
{"id": "quant-ph/0611013", "contents": "Title: Error Exponent in Asymmetric Quantum Hypothesis Testing and Its\n  Application to Classical-Quantum Channel coding Abstract: In the simple quantum hypothesis testing problem, upper bound with asymmetric\nsetting is shown by using a quite useful inequality by Audenaert et al,\nquant-ph/0610027, which was originally invented for symmetric setting. Using\nthis upper bound, we obtain the Hoeffding bound, which are identical with the\nclassical counter part if the hypotheses, composed of two density operators,\nare mutually commutative. Our upper bound improves the bound by Ogawa-Hayashi,\nand also provides a simpler proof of the direct part of the quantum Stein's\nlemma. Further, using this bound, we obtain a better exponential upper bound of\nthe average error probability of classical-quantum channel coding. \n\n"}
{"id": "quant-ph/0611289", "contents": "Title: The Converse Part of The Theorem for Quantum Hoeffding Bound Abstract: We prove the converse part of the theorem for quantum Hoeffding bound on the\nasymptotics of quantum hypothesis testing, essentially based on an argument\ndeveloped by Nussbaum and Szkola in proving the converse part of the quantum\nChernoff bound. Our result complements Hayashi's proof of the direct\n(achievability) part of the theorem, so that the quantum Hoeffding bound has\nnow been established. \n\n"}
{"id": "quant-ph/0703181", "contents": "Title: Quantum Block and Convolutional Codes from Self-orthogonal Product Codes Abstract: We present a construction of self-orthogonal codes using product codes. From\nthe resulting codes, one can construct both block quantum error-correcting\ncodes and quantum convolutional codes. We show that from the examples of\nconvolutional codes found, we can derive ordinary quantum error-correcting\ncodes using tail-biting with parameters [[42N,24N,3]]_2. While it is known that\nthe product construction cannot improve the rate in the classical case, we show\nthat this can happen for quantum codes: we show that a code [[15,7,3]]_2 is\nobtained by the product of a code [[5,1,3]]_2 with a suitable code. \n\n"}
{"id": "quant-ph/9808063", "contents": "Title: Strong Converse to the Quantum Channel Coding Theorem Abstract: A lower bound on the probability of decoding error of quantum communication\nchannel is presented. The strong converse to the quantum channel coding theorem\nis shown immediately from the lower bound. It is the same as Arimoto's method\nexept for the difficulty due to non-commutativity. \n\n"}
{"id": "quant-ph/9809081", "contents": "Title: Concatenating Decoherence Free Subspaces with Quantum Error Correcting\n  Codes Abstract: An operator sum representation is derived for a decoherence-free subspace\n(DFS) and used to (i) show that DFSs are the class of quantum error correcting\ncodes (QECCs) with fixed, unitary recovery operators, and (ii) find explicit\nrepresentations for the Kraus operators of collective decoherence. We\ndemonstrate how this can be used to construct a concatenated DFS-QECC code\nwhich protects against collective decoherence perturbed by independent\ndecoherence. The code yields an error threshold which depends only on the\nperturbing independent decoherence rate. \n\n"}
{"id": "quant-ph/9907087", "contents": "Title: Reliability function of general classical-quantum channel Abstract: In information theory the reliability function and its bounds, describing the\nexponential behavior of the error probability, are the most important\nquantitative characteristics of the channel performance. From a general point\nof view, these bounds provide certain measures of distinguishability of a given\nset of states. In an earlier paper we introduced quantum analogs of the random\ncoding and the expurgation lower bounds for the case of pure signal states.\nHere we discuss the general case, in particular, we prove the previously\nconjectured expurgation bound and find the quantum cutoff rate in the case of\narbitrary mixed signal states. \n\n"}
