{"id": "0704.1704", "contents": "Title: Magneto-oscillations due to electron-electron interactions in the ac\n  conductivity of a 2D electron gas Abstract: Electron-electron interactions give rise to the correction,\n\\delta\\sigma^{int}(\\omega), to the ac magnetoconductivity, \\sigma(\\omega), of a\nclean 2D electron gas that is periodic in \\omega_c^{-1}, where \\omega_c is the\ncyclotron frequency. Unlike conventional harmonics of the cyclotron resonance,\nwhich are periodic with \\omega, this correction is periodic with \\omega^{3/2}.\nOscillations in \\delta\\sigma^{int}(\\omega) develop at low magnetic fields,\n\\omega_c\\ll\\omega, when the conventional harmonics are suppressed by the\ndisorder. Their origin is a {\\em double} backscattering of an electron from the\nimpurity-induced Friedel oscillations. During the time \\sim\\omega^{-1} between\nthe two backscattering events the electron travels only a {\\em small portion}\nof the Larmour circle. \n\n"}
{"id": "0704.3704", "contents": "Title: Multimodal nested sampling: an efficient and robust alternative to MCMC\n  methods for astronomical data analysis Abstract: In performing a Bayesian analysis of astronomical data, two difficult\nproblems often emerge. First, in estimating the parameters of some model for\nthe data, the resulting posterior distribution may be multimodal or exhibit\npronounced (curving) degeneracies, which can cause problems for traditional\nMCMC sampling methods. Second, in selecting between a set of competing models,\ncalculation of the Bayesian evidence for each model is computationally\nexpensive. The nested sampling method introduced by Skilling (2004), has\ngreatly reduced the computational expense of calculating evidences and also\nproduces posterior inferences as a by-product. This method has been applied\nsuccessfully in cosmological applications by Mukherjee et al. (2006), but their\nimplementation was efficient only for unimodal distributions without pronounced\ndegeneracies. Shaw et al. (2007), recently introduced a clustered nested\nsampling method which is significantly more efficient in sampling from\nmultimodal posteriors and also determines the expectation and variance of the\nfinal evidence from a single run of the algorithm, hence providing a further\nincrease in efficiency. In this paper, we build on the work of Shaw et al. and\npresent three new methods for sampling and evidence evaluation from\ndistributions that may contain multiple modes and significant degeneracies; we\nalso present an even more efficient technique for estimating the uncertainty on\nthe evaluated evidence. These methods lead to a further substantial improvement\nin sampling efficiency and robustness, and are applied to toy problems to\ndemonstrate the accuracy and economy of the evidence calculation and parameter\nestimation. Finally, we discuss the use of these methods in performing Bayesian\nobject detection in astronomical datasets. \n\n"}
{"id": "0706.1337", "contents": "Title: A note on Poisson homogeneous spaces Abstract: We identify the cotangent bundle Lie algebroid of a Poisson homogeneous space\nG/H of a Poisson Lie group G as a quotient of a transformation Lie algebroid\nover G. As applications, we describe the modular vector fields of G/H, and we\nidentify the Poisson cohomology of G/H with coefficients in powers of its\ncanonical line bundle with relative Lie algebra cohomology of the Drinfeld Lie\nalgebra associated to G/H. We also construct a Poisson groupoid over G/H which\nis symplectic near the identity section. This note serves as preparation for\nforthcoming papers, in which we will compute explicitly the Poisson cohomology\nand study their symplectic groupoids for certain examples of Poisson\nhomogeneous spaces related to semi-simple Lie groups. \n\n"}
{"id": "0709.3113", "contents": "Title: Point Sources from a Spitzer IRAC Survey of the Galactic Center Abstract: We have obtained Spitzer/IRAC observations of the central 2.0 x 1.4 degrees\n(~280 x 200 pc) of the Galaxy at 3.6-8.0 microns. A point source catalog of\n1,065,565 objects is presented. The catalog includes magnitudes for the point\nsources at 3.6, 4.5, 5.8, and 8.0 microns, as well as JHK photometry from\n2MASS. The point source catalog is confusion limited with average limits of\n12.4, 12.1, 11.7, and 11.2 magnitudes for [3.6], [4.5], [5.8], and [8.0],\nrespectively. We find that the confusion limits are spatially variable because\nof stellar surface density, background surface brightness level, and extinction\nvariations across the survey region. The overall distribution of point source\ndensity with Galactic latitude and longitude is essentially constant, but\nstructure does appear when sources of different magnitude ranges are selected.\nBright stars show a steep decreasing gradient with Galactic latitude, and a\nslow decreasing gradient with Galactic longitude, with a peak at the position\nof the Galactic center. From IRAC color-magnitude and color-color diagrams, we\nconclude that most of the point sources in our catalog have IRAC magnitudes and\ncolors characteristic of red giant and AGB stars. \n\n"}
{"id": "0710.1204", "contents": "Title: Ion trap quantum gates with amplitude-modulated laser beams Abstract: In ion traps, entangling gate operations can be realized by a bichromatic\npair of laser beams that collectively interact with the ions. In this paper, a\nnew method of modelling the laser-ion interaction is introduced that turns out\nto be superior to standard techniques for the description of gate operations on\noptical qubits. The treatment allows for a comparison of the performance of\ngates based on $\\sigma_z\\otimes\\sigma_z$ and M{\\o}lmer-S{\\o}rensen interactions\non optical transitions where the bichromatic laser field can be realized by an\namplitude-modulated laser resonant with the qubit transition. Shaping the\namplitude of the bichromatic laser pulse is shown to make the gates more robust\nagainst experimental imperfections. \n\n"}
{"id": "0711.4894", "contents": "Title: Higher Order Couplings from Heterotic Orbifold Theory Abstract: We calculate couplings of arbitrary order from correlation functions among\ntwisted strings, using conformal field theory. Twisted strings arise in\nheterotic string compactified on orbifolds yielding matter fields in the low\nenergy limit. We calculate completely the classical and the quantum amplitude\nincluding normalization, up to a contribution from Kahler potential. The\nclassical action has saddle points which are interpreted as worldsheet\ninstantons described by metastable untwisted strings, formed by twisted strings\ndistributed at certain fixed points. This understanding generalizes the area\nrule, in the case that the locations of twisted strings do not form a polygon,\nand provides a general rule for calculating these kinds of instanton\ncorrections. An interpretation of couplings involving linearly combined states\nis given, which commonly appear in non-prime order orbifolds. The quantum part\nof the amplitude is given by ratios of gamma functions with order one\narguments. \n\n"}
{"id": "0802.0961", "contents": "Title: Toward first-principle simulations of galaxy formation: I. How should we\n  choose star formation criteria in high-resolution simulations of disk\n  galaxies? Abstract: We performed 3-dimensional N-body/SPH simulations to study how mass\nresolution and other model parameters such as the star formation efficiency\nparameter, C* and the threshold density, nth affect structures of the galactic\ngaseous/stellar disk in a static galactic potential. We employ 10^6 - 10^7\nparticles to resolve a cold and dense (T < 100 K & n_H > 100 cm^{-3}) phase. We\nfound that structures of the ISM and the distribution of young stars are\nsensitive to the assumed nth. High-nth models with nth = 100 cm^{-3} yield\nclumpy multi-phase features in the ISM. Young stars are distributed in a thin\ndisk of which half-mass scale height is 10 - 30 pc. In low-nth models with nth\n= 0.1 cm^{-3}, the stellar disk is found to be several times thicker, and the\ngas disk appears smoother than the high-nth models. A high-resolution\nsimulation with high-nth is necessary to reproduce the complex structure of the\ngas disk. The global properties of the model galaxies in low-nth models, such\nas star formation histories, are similar to those in the high-nth models when\nwe tune the value of C* so that they reproduce the observed relation between\nsurface gas density and surface star formation rate density. We however\nemphasize that high-nth models automatically reproduce the relation, regardless\nof the values of C*. The ISM structure, phase distribution, and distributions\nof young star forming region are quite similar between two runs with values of\nC* which differ by a factor of 15. We also found that the timescale of the flow\nfrom n_H ~1 cm^{-3} to n_H > 100 cm^{-3} is about 5 times as long as the local\ndynamical time and is independent of the value of C*. The use of a high-nth\ncriterion for star formation in high-resolution simulations makes numerical\nmodels fairy insensitive to the modelling of star formation. (Abridged) \n\n"}
{"id": "0805.0411", "contents": "Title: The near neutrino detector for the T2K experiment Abstract: The T2K experiment is a second generation long baseline neutrino oscillation\nexperiment designed as a sensitive search for nu_e appearance. The T2K near\nneutrino detector complex is located 280 meters from the pion production target\nand will measure both neutrino beam properties close to the production point\nand interaction cross sections. The main design features, test results and\nstatus of these detectors are presented. \n\n"}
{"id": "0808.3007", "contents": "Title: The Rise of the Vulcans Abstract: In this introductory review presented at the IAU Symposium 253 \"Transiting\nPlanets\", I summarize the path from the initial 1995 radial-velocity discovery\nof hot Jupiters to the current rich panoply of investigations that are afforded\nwhen such objects are observed to transit their parent stars. Forty transiting\nexoplanets are now known, and the time for that population to double has\ndropped below one year. It is only for these objects that we have direct\nestimates of their masses and radii, and for which (at the current time) we can\nundertake direct studies of the chemistries and dynamics of their atmospheres.\nInformed by the successes of hot Jupiter studies, I outline a path for the\nspectroscopic study of certain habitable exoplanets that obviates the need for\ndirect imaging. \n\n"}
{"id": "0809.0509", "contents": "Title: What Makes an Accretion-Powered Millisecond Pulsar? Abstract: We investigate the dependence of pulse amplitudes of accreting millisecond\npulsars on the masses of the neutron stars. Because the pulsation amplitudes\nare suppressed as the neutron stars become more massive, the probability of\ndetection of pulsations decreases in systems that have been accreting for a\nlong time. However, the probability of detectable pulsations is higher in\ntransient systems where the mass accretion is sporadic and the neutron star is\nlikely to have a low mass. We propose this mechanism as the explanation of the\nsmall number of millisecond X-ray pulsars found to date, as well as their\nemergence as fast pulsars mostly in transient, low-Mdot systems. This mechanism\ncan also quantitatively explain the lack of pulsars in the majority of LMXBs. \n\n"}
{"id": "0809.0701", "contents": "Title: Optimal strategies for gravitational wave stochastic background searches\n  in pulsar timing data Abstract: A low frequency stochastic background of gravitational waves may be detected\nby pulsar timing experiments in the next five to ten years. Using methods\ndeveloped to analyze interferometric gravitational wave data, in this paper we\nlay out the optimal techniques to detect a background of gravitational waves\nusing a pulsar timing array. We show that for pulsar distances and\ngravitational wave frequencies typical of pulsar timing experiments, neglecting\nthe effect of the metric perturbation at the pulsar does not result in a\nsignificant deviation from optimality. We discuss methods for setting upper\nlimits using the optimal statistic, show how to construct skymaps using the\npulsar timing array, and consider several issues associated with realistic\nanalysis of pulsar timing data. \n\n"}
{"id": "0810.4492", "contents": "Title: Model Categories and Quantum Gravity Abstract: We propose a mathematically concrete way of modelling the suggestion that in\nquantum gravity the spacetime disappears, replacing it with a discrete\napproximation to the causal path space described as an object in a model\ncategory. One of the versions of our models appears as a thickening of\nspacetime, which we interpret as a formulation of relational geometry. Avenues\ntoward constructing an actual quantum theory of gravity on our models are given\na preliminary exploration. \n\n"}
{"id": "0812.3467", "contents": "Title: Resonant flavor conversion of supernova neutrinos and neutrino\n  parameters Abstract: The unknown neutrino parameters may leave detectable signatures in the\nsupernova (SN) neutrino flux. However, even the contribution from the MSW\nflavor transition alone could cause ambiguity in the interpretation to the\nneutrino signals because of the uncertain local density profile of the SN\nmatter and the model-dependent SN neutrino spectral parameters. A specific\nparametrization to the unknown local density profile is proposed in this work,\nand the contribution from the standard MSW effect is investigated through a\nmulti-detector analysis of the SN neutrinos. In establishing the\nmodel-independent scheme, results based on the existing spectral models are\nincluded. The limitation of the analysis is also discussed. \n\n"}
{"id": "0901.2171", "contents": "Title: A WENO algorithm for radiative transfer with resonant scattering: the\n  time scale of the Wouthuysen-Field Coupling Abstract: We develop a numerical solver for the integral-differential equations, which\ndescribes the radiative transfer of photon distribution in the frequency space\nwith resonant scattering of Lyalpha photons by hydrogen gas in the early\nuniverse. The time-dependent solutions of this equation is crucial to the\nestimation of the effect of the Wouthuysen-Field (WF) coupling in relation to\nthe 21 cm emission and absorption at the epoch of reionization. The resonant\nscattering leads to the photon distribution in the frequency space to be\npiecewise smooth containing sharp changes. The weighted essentially\nnonoscillatory (WENO) scheme is suitable to handle this problem, as this\nalgorithm has been found to be highly stable and robust for solving Boltzmann\nequation. We test this numerical solver against analytic solutions of the\nevolution of the photon distribution in rest background, analytic solution in\nexpanding background without resonant scattering and formation of local\nBoltzmann distribution around the resonant frequency with the temperature same\nas that of atom for recoil. We find that evolution of photon distribution\nundergoes three phases; profile is similar to the initial one, a flat plateau\n(without recoil) or local Boltzmann distribution (with recoil) forms around the\nresonant frequency, and finally the distribution around the resonant frequency\nis saturated when the photons from the source is balanced by the redshift of\nthe expansion. This result indicates that the onset of the W-F coupling should\nnot be determined by the third phase, but by the time scale of the second\nphase. We found that the time scale of the W-F coupling is equal to about a few\nhundreds of the mean free flight time of photons with resonant frequency, and\nis independent of the Sobolev parameter if this parameter is much less than 1. \n\n"}
{"id": "0901.4052", "contents": "Title: Probing a Possible Vacuum Refractive Index with Gamma-Ray Telescopes Abstract: We have used a stringy model of quantum space-time foam to suggest that the\nvacuum may exhibit a non-trivial refractive index depending linearly on\ngamma-ray energy: eta -1 ~ E_gamma/M_QG1, where M_QG1 is some mass scale\ntypical of quantum gravity that may be ~ 10^18 GeV: see Phys. Lett. B 665, 412\n(2008) and references therein. The MAGIC, HESS and Fermi gamma-ray telescopes\nhave recently probed the possible existence of such an energy-dependent vacuum\nrefractive index. All find indications of time-lags for higher-energy photons,\nbut cannot exclude the possibility that they are due to intrinsic delays at the\nsources. However, the MAGIC and HESS observations of time-lags in emissions\nfrom AGNs Mkn 501 and PKS 2155-304 are compatible with each other and a\nrefractive index depending linearly on the gamma-ray energy, with M_QG1 ~ 10^18\nGeV. We combine their results to estimate the time-lag Delta t to be expected\nfor the highest-energy photon from GRB 080916c measured by the Fermi telescope,\nwhich has an energy ~ 13.2 GeV, assuming the redshift z = 4.2 \\pm 0.3 measured\nby GROND. In the case of a refractive index depending linearly on the gamma-ray\nenergy we predict Delta t = 25 \\pm 11 s. This is compatible with the time-lag\nDelta t <= 16.5 s reported by the Fermi Collaboration, whereas the time-lag\nwould be negligible in the case of a refractive index depending quadratically\non the gamma-ray energy. We suggest a strategy for future observations that\ncould distinguish between a quantum-gravitational effect and other\ninterpretations of the time-lags observed by the MAGIC, HESS and Fermi\ngamma-ray telescopes. \n\n"}
{"id": "0901.4781", "contents": "Title: Simple Treatments of the Photon Noise and the Pixelation Effect in Weak\n  Lensing Abstract: We propose easy ways of correcting for the systematic errors caused by the\nphoton noise and the pixelation effect in cosmic shear measurements. Our\ntreatment of noise can reliably remove the noise contamination to the cosmic\nshear even when the flux density of the noise is comparable with those of the\nsources. For pixelated images, we find that one can accurately reconstruct\ntheir corresponding continuous images by interpolating the logarithms of the\npixel readouts with either the Bicubic or the Bicubic Spline method. The cosmic\nshears measured from the interpolated continuous images contain negligible\nsystematic errors as long as the pixel size is about less than the scale size\nof the point spread function (PSF, including the pixel response function), a\ncondition which is almost always satisfied in practice. Our methodology is well\ndefined regardless of the morphologies of the galaxies and the PSF. Despite\nthat our discussion is based on the shear measurement method of Zhang (2008),\nour way of treating the noise can in principle be considered in other methods,\nand the interpolation method that we introduce for reconstructing continuous\nimages from pixelated ones is generally useful for digital image processing of\nall purposes. \n\n"}
{"id": "0902.0371", "contents": "Title: Simulations of Baryon Acoustic Oscillations II: Covariance matrix of the\n  matter power spectrum Abstract: We use 5000 cosmological N-body simulations of 1(Gpc/h)^3 box for the\nconcordance LCDM model in order to study the sampling variances of nonlinear\nmatter power spectrum. We show that the non-Gaussian errors can be important\neven on large length scales relevant for baryon acoustic oscillations (BAO).\nOur findings are (1) the non-Gaussian errors degrade the cumulative\nsignal-to-noise ratios (S/N) for the power spectrum amplitude by up to a factor\nof 2 and 4 for redshifts z=1 and 0, respectively. (2) There is little\ninformation on the power spectrum amplitudes in the quasi-nonlinear regime,\nconfirming the previous results. (3) The distribution of power spectrum\nestimators at BAO scales, among the realizations, is well approximated by a\nGaussian distribution with variance that is given by the diagonal covariance\ncomponent. (4) For the redshift-space power spectrum, the degradation in S/N by\nnon-Gaussian errors is mitigated due to nonlinear redshift distortions. (5) For\nan actual galaxy survey, the additional shot noise contamination compromises\nthe cosmological information inherent in the galaxy power spectrum, but also\nmitigates the impact of non-Gaussian errors. The S/N is degraded by up to 30%\nfor a WFMOS-type survey. (6) The finite survey volume causes additional\nnon-Gaussian errors via the correlations of long-wavelength fluctuations with\nthe fluctuations we want to measure, further degrading the S/N values by about\n30% even at high redshift z=3. \n\n"}
{"id": "0902.0468", "contents": "Title: On the Transits of Solar System Objects in the Forthcoming PLANCK\n  Mission: Data Flagging and Coeval Multifrequency Observations Abstract: In the context of current and future microwave surveys mainly dedicated to\nthe accurate mapping of Cosmic Microwave Background (CMB), mm and sub-mm\nemissions from Solar System will represent a potential source of contamination\nas well as an opportunity for new Solar System studies. In particular, the\nforthcoming ESA Planck mission will be able to observe the point-like thermal\nemission from planets and some large asteroids as well as the diffused Zodiacal\nLight Emission (ZLE). After a brief introduction to the field, we focus on the\nidentification of Solar System discrete objects in the Planck time ordered\ndata. \n\n"}
{"id": "0902.0472", "contents": "Title: Simulations of Nuclear Cluster formation Abstract: Preliminary results are presented about a fully self-consistent N-body\nsimulation of a sample of four massive globular clusters in close interaction\nwithin the central region of a galaxy. The N-body representation (with\nN=1.5x10^6 particles in total) of both the clusters and the galaxy allows to\ninclude in a natural and self-consistent way dynamical friction and tidal\ninteractions. The results confirm the decay and merging of globulars as a\nviable scenario for the formation/accretion of compact nuclear clusters.\nSpecifically: i) the frictional orbital decay is about 2 times faster than that\npredicted by the generalized Chandrasekhar formula; ii) the progenitor clusters\nmerge in less than 20 galactic core-crossing time; iii) the NC configuration\nkeeps a quasi-stable state at least within 70 galactic core-crossing times. \n\n"}
{"id": "0902.1412", "contents": "Title: Recent CMB observations enable to find the total gravitational energy of\n  a mass Abstract: The astronomical observations indicate that the universe expands with\nacceleration and it has a finite event horizon. The recent CMB observations\nconfirm the universe is homogeneous, isotropic and asymptotically flat. The\ntotal gravitational energy of a body having mass m is the gravitational\npotential energy originating from the gravitational interaction of the body\nwith all masses of the universe, within the event horizon. The flat geometry of\nthe universe enables to determine the total gravitational energy of the mass m\nwithin the framework of the Newtonian gravity in Euclidean space. By this\napproach, it has been found the modulus of the total gravitational energy of a\nbody is close to its rest energy E = m*c^2, which is a remarkable result.\nBesides, the smoothed gravitational potential in an arbitrary point of the\nobservable universe appears close to - c^2, where c is the speed of the light. \n\n"}
{"id": "0902.2335", "contents": "Title: The AMiBA Hexapod Telescope Mount Abstract: AMiBA is the largest hexapod astronomical telescope in current operation. We\npresent a description of this novel hexapod mount with its main mechanical\ncomponents -- the support cone, universal joints, jack screws, and platform --\nand outline the control system with the pointing model and the operating modes\nthat are supported. The AMiBA hexapod mount performance is verified based on\noptical pointing tests and platform photogrammetry measurements. The\nphotogrammetry results show that the deformations in the inner part of the\nplatform are less than 120 micron rms. This is negligible for optical pointing\ncorrections, radio alignment and radio phase errors for the currently\noperational 7-element compact configuration. The optical pointing error in\nazimuth and elevation is successively reduced by a series of corrections to\nabout 0.4 arcmin rms which meets our goal for the 7-element target\nspecifications. \n\n"}
{"id": "0902.2372", "contents": "Title: A New Era in Extragalactic Background Light Measurements: The Cosmic\n  History of Accretion, Nucleosynthesis and Reionization Abstract: (Brief Summary) What is the total radiative content of the Universe since the\nepoch of recombination? The extragalactic background light (EBL) spectrum\ncaptures the redshifted energy released from the first stellar objects,\nprotogalaxies, and galaxies throughout cosmic history. Yet, we have not\ndetermined the brightness of the extragalactic sky from UV/optical to\nfar-infrared wavelengths with sufficient accuracy to establish the radiative\ncontent of the Universe to better than an order of magnitude. Among many\nscience topics, an accurate measurement of the EBL spectrum from optical to\nfar-IR wavelengths, will address: What is the total energy released by stellar\nnucleosynthesis over cosmic history? Was significant energy released by\nnon-stellar processes? Is there a diffuse component to the EBL anywhere from\noptical to sub-millimeter? When did first stars appear and how luminous was the\nreionization epoch? Absolute optical to mid-IR EBL spectrum to an\nastrophysically interesting accuracy can be established by wide field imagingat\na distance of 5 AU or above the ecliptic plane where the zodiacal foreground is\nreduced by more than two orders of magnitude. \n\n"}
{"id": "0902.3382", "contents": "Title: Accurate laboratory rest frequencies of vibrationally excited CO up to\n  $varv = 3$ and up to 2 THz Abstract: Astronomical observations of (sub)millimeter wavelength pure rotational\nemission lines of the second most abundant molecule in the Universe, CO, hold\nthe promise of probing regions of high temperature and density in the innermost\nparts of circumstellar envelopes. The rotational spectrum of vibrationally\nexcited CO up to $\\varv = 3$ has been measured in the laboratory between 220\nand 1940 GHz with relative accuracies up to $5.2 \\times 10^{-9}$, corresponding\nto $\\sim 5$ kHz near 1 THz. The rotational constant $B$ and the quartic\ndistortion parameter $D$ have been determined with high accuracy and even the\nsextic distortion term $H$ was determined quite well for $\\varv = 1$ while\nreasonable estimates of $H$ were obtained for $\\varv = 2$ and 3. The present\ndata set allows for the prediction of accurate rest frequencies of\nvibrationally excited CO well beyond 2 THz. \n\n"}
{"id": "0902.3709", "contents": "Title: Diffuse baryonic matter beyond 2020 Abstract: The hot, diffuse gas that fills the largest overdense structures in the\nUniverse -- clusters of galaxies and a web of giant filaments connecting them\n-- provides us with tools to address a wide array of fundamental astrophysical\nand cosmological questions via observations in the X-ray band. Clusters are\nsensitive cosmological probes. To utilize their full potential for precision\ncosmology in the following decades, we must precisely understand their physics\n-- from their cool cores stirred by jets produced by the central supermassive\nblack hole (itself fed by inflow of intracluster gas), to their outskirts,\nwhere the infall of intergalactic medium (IGM) drives shocks and accelerates\ncosmic rays. Beyond the cluster confines lies the virtually unexplored warm\nIGM, believed to contain most of the baryonic matter in the present-day\nUniverse. As a depository of all the matter ever ejected from galaxies, it\ncarries unique information on the history of energy and metal production in the\nUniverse. Currently planned major observatories, such as Astro-H and IXO, will\nmake deep inroads into these areas, but to see the most interesting parts of\nthe picture will require an almost science-fiction-grade facility with tens of\nm^2 of effective area, subarcsecond angular resolution, a matching imaging\ncalorimeter and a super high-dispersion spectrograph, such as Generation-X. \n\n"}
{"id": "0903.0318", "contents": "Title: High-Energy gamma-ray Astronomy and String Theory Abstract: There have been observations, first from the MAGIC Telescope (July 2005) and\nquite recently (September 2008) from the FERMI Satellite Telescope, on\nnon-simultaneous arrival of high-energy photons from distant celestial sources.\nIn each case, the highest energy photons were delayed, as compared to their\nlower-energy counterparts. Although the astrophysics at the source of these\nenergetic photons is still not understood, and such non simultaneous arrival\nmight be due to non simultaneous emission as a result of conventional physics\neffects, nevertheless, rather surprisingly, the observed time delays can also\nfit excellently some scenarios in quantum gravity, predicting Lorentz violating\nspace-time \"foam\" backgrounds with a non-trivial subluminal vacuum refractive\nindex suppressed linearly by a quantum gravity scale of the order of the\nreduced Planck mass. In this pedagogical talk, I discuss the MAGIC and FERMI\nfindings in this context and I argue on a theoretical model of space-time foam\nin string/brane theory that can accommodate the findings of those experiments\nin agreement with all other stringent tests of Lorentz invariance. However, I\nstress the current ambiguities/uncertainties on the source mechanisms, which\nneed to be resolved first before definite conclusions are reached regarding\nquantum gravity foam scenarios. \n\n"}
{"id": "0903.0950", "contents": "Title: Absence of anti-correlations and of baryon acoustic oscillations in the\n  galaxy correlation function from the Sloan Digital Sky Survey DR7 Abstract: One of the most striking features predicted by standard models of galaxy\nformation is the presence of anti-correlations in the matter distribution at\nlarge enough scales (r>r_c). Simple arguments show that the location of the\nlength-scale r_c, marking the transition from positive to negative\ncorrelations, is the same for any class of objects as for the full matter\ndistribution, i.e. it is invariant under biasing. This scale is predicted by\nmodels to be at about the same distance of the scale signaling the baryonic\nacoustic oscillation scale r_{bao}. We test these predictions in the newest\nSDSS galaxy samples.We find that, in several MG samples, the correlation\nfunction remains positive at scales >250 Mpc/h, while in the concordance LCDM\nit should be negative beyond r_c\\approx 120 Mpc/h. In other samples the\ncorrelation function becomes negative at scales <50 Mpc/h. To investigate the\norigin of these differences we consider in detail the propagation of errors on\nthe sample density into the estimation of the correlation function. We conclude\nthat these are important at large enough separations, and that they are\nresponsible for the observed differences between different estimators and for\nthe measured sample to sample variations of the correlation function. We\nconclude that, in the newest SDSS samples, the large scale behavior of the\ngalaxy correlation function is affected by intrinsic errors andv\nolume-dependent systematic effects which make the detection of correlations to\nbe only an estimate of a lower limit of their amplitude, spatial extension and\nstatistical errors. We point out that these results represent an important\nchallenge to LCDM models as they largely differ from its predictions.(Abridged\nversion). \n\n"}
{"id": "0903.2297", "contents": "Title: Cosmological Studies With A Large-Area X-ray Telescope Abstract: A moderate investment of observing time with the International X-ray\nObservatory to study high-redshift galaxy clusters detected in future\nlarge-scale surveys, will provide cosmological measurements of fundamental\nimportance. IXO observations, combined with lensing follow-up, will measure the\nperturbation growth factor from z=0-2 with an accuracy comparable to, or\npossibly better than, that expected from observations of cosmic shear with\nJDEM, and redshift-space distortions with EUCLID. The growth of structure data\nderived from clusters will significantly improve our knowledge of the dark\nenergy equation of state and will aid in constraining non-GR models for cosmic\nacceleration. IXO observations of the largest, dynamically relaxed clusters\nwill provide a powerful, independent measurement of the cosmological expansion\nhistory using the apparent f_gas(z) trend. Systematic and statistical errors\nfrom this technique are competitive with SNIa and BAO studies, making the test\nextremely useful for improving the accuracy and reliability of the geometric\ncosmological measurements planned for LSST and JDEM. Only by employing a range\nof powerful, independent approaches, including those discussed here, can robust\nanswers to puzzles as profound as the origin of cosmic acceleration be\nexpected. \n\n"}
{"id": "0903.3411", "contents": "Title: An optical group catalogue to z = 1 from the zCOSMOS 10k sample Abstract: We present a galaxy group catalogue spanning the redshift range 0.1 <~ z <~ 1\nin the ~1.7 deg^2 COSMOS field, based on the first ~10,000 zCOSMOS spectra. The\nperformance of both the Friends-of-Friends (FOF) and Voronoi-Delaunay-Method\n(VDM) approaches to group identification has been extensively explored and\ncompared using realistic mock catalogues. We find that the performance improves\nsubstantially if groups are found by progressively optimizing the group-finding\nparameters for successively smaller groups, and that the highest fidelity\ncatalogue, in terms of completeness and purity, is obtained by combining the\nindependently created FOF and VDM catalogues. The final completeness and purity\nof this catalogue, both in terms of the groups and of individual members,\ncompares favorably with recent results in the literature. The current group\ncatalogue contains 102 groups with N >= 5 spectroscopically confirmed members,\nwith a further ~700 groups with 2 <= N <= 4. Most of the groups can be assigned\na velocity dispersion and a dark-matter mass derived from the mock catalogues,\nwith quantifiable uncertainties. The fraction of zCOSMOS galaxies in groups is\nabout 25% at low redshift and decreases toward ~15% at z ~ 0.8. The zCOSMOS\ngroup catalogue is broadly consistent with that expected from the semi-analytic\nevolution model underlying the mock catalogues. Not least, we show that the\nnumber density of groups with a given intrinsic richness increases from\nredshift z ~ 0.8 to the present, consistent with the hierarchical growth of\nstructure. \n\n"}
{"id": "0903.4588", "contents": "Title: The distribution of the dark matter in galaxies as the imprint of its\n  Nature Abstract: The standard framework within which cosmological measurements are confronted\nand interpreted nowadays, called Lambda Cold Dark Matter, presents a Universe\ndominated by unknown forms of energy and matter.\n  My Thesis is devoted to investigate the distribution of dark matter in\ngalaxies and addresses the fact that the local universe-the small objects that\norbit galaxies and the galaxy cores-turns out to be a marvelous laboratory for\nexamining the nature of dark matter and the fundamental physics involved in\nstructure formation and evolution.\n  I develop tests, based on mass modeling of rotation curves, for the\nvalidation of dark matter models on galactic scales. These tests have been\napplied in analyzing the phenomenology of the cusp vs core controversy, and the\nphenomenon of non-Keplerian rotation curves as modification of the laws of\ngravity. I further investigate the properties and scaling laws of dark matter\nhalos.\n  My conclusion is that galactic observations provide strong imprints on the\nnature of dark matter. \n\n"}
{"id": "0903.4890", "contents": "Title: An Improved Method for 21cm Foreground Removal Abstract: 21 cm tomography is expected to be difficult in part because of serious\nforeground contamination. Previous studies have found that line-of-sight\napproaches are capable of cleaning foregrounds to an acceptable level on large\nspatial scales, but not on small spatial scales. In this paper, we introduce a\nFourier-space formalism for describing the line-of-sight methods, and use it to\nintroduce an improved new method for 21 cm foreground cleaning. Heuristically,\nthis method involves fitting foregrounds in Fourier space using weighted\npolynomial fits, with each pixel weighted according to its information content.\nWe show that the new method reproduces the old one on large angular scales, and\ngives marked improvements on small scales at essentially no extra computational\ncost. \n\n"}
{"id": "0904.0850", "contents": "Title: Upper bounds on L-functions at the edge of the critical strip Abstract: The problem of finding upper bounds for L-functions at the edge of the\ncritical strip has a long and interesting history. Here, the situation for\nclassical L-functions such as Dirichlet L-functions is relatively well\nunderstood. The reason for this is because the size of the coefficients of\nthese L-functions is known to be small. Although L-functions are generally\nexpected to have coefficients which are bounded by a constant at the primes,\nthis has only been proven for a small class of familiar examples. Our main\nfocus here is on the problem of finding upper bounds for L-functions for which\nwe have comparatively bad bounds for the size of the coefficients. \n\n"}
{"id": "0904.1464", "contents": "Title: The Possible Impact of GRB Detector Thresholds on Cosmological Standard\n  Candles Abstract: GRB satellites are relatively inefficient detectors of dim hard bursts\nbecause they trigger on photon counts, which are number-biased against hard\nphotons. Therefore, for example, given two bursts of identical peak luminosity\nnear the detection threshold, a dim soft burst will be preferentially detected\nover a dim hard burst. This detector bias can create or skew an apparent\ncorrelation where increasingly hard GRBs appear increasingly bright. Although\nsuch correlations may be obfuscated by a middle step where GRBs need to be\nbright enough to have their actual redshifts determined, it is found that the\nbias is generally pervasive. This result is derived here through simulations\nconvolving a wide variety of possible GRB brightnesses and spectra with the\nBATSE Large Area Detectors (LAD) detection thresholds. The presented analyses\nindicate that the rest-frame $\\nu F_{\\nu}$ spectrum peak energy of\nlong-duration GRBs, $\\epi$, is not a good cosmological standard candle without\nsignificant corrections for selection effects. Therefore, the appearance of\n$\\epi$ in seeming correlations such as the Amati ($E_{iso}-\\epi$), Ghirlanda\n($E_{\\gamma}-\\epi$), and $L_{iso}-\\epi$ relations is statistically real but\nstrongly influenced by so far uncalibrated GRB detector thresholds. \n\n"}
{"id": "0904.1690", "contents": "Title: Invariant Einstein metrics on flag manifolds with four isotropy summands Abstract: A generalized flag manifold is a homogeneous space of the form $G/K$, where\n$K$ is the centralizer of a torus in a compact connected semisimple Lie group\n$G$. We classify all flag manifolds with four isotropy summands and we study\ntheir geometry. We present new $G$-invariant Einstein metrics by solving\nexplicity the Einstein equation. We also examine the isometric problem for\nthese Einstein metrics. \n\n"}
{"id": "0904.2016", "contents": "Title: Cosmic Infrared Background ExpeRiment (CIBER): A Probe of Extragalactic\n  Background Light from Reionization Abstract: The Cosmic Infrared Background ExpeRiment (CIBER) is a rocket-borne absolute\nphotometry imaging and spectroscopy experiment optimized to detect signatures\nof first-light galaxies present during reionization in the unresolved IR\nbackground. CIBER-I consists of a wide-field two-color camera for fluctuation\nmeasurements, a low-resolution absolute spectrometer for absolute EBL\nmeasurements, and a narrow-band imaging spectrometer to measure and correct\nscattered emission from the foreground zodiacal cloud. CIBER-I was successfully\nflown on February 25th, 2009 and has one more planned flight in early 2010. We\npropose, after several additional flights of CIBER-I, an improved CIBER-II\ncamera consisting of a wide-field 30 cm imager operating in 4 bands between 0.5\nand 2.1 microns. It is designed for a high significance detection of unresolved\nIR background fluctuations at the minimum level necessary for reionization.\nWith a FOV 50 to 2000 times largerthan existing IR instruments on satellites,\nCIBER-II will carry out the definitive study to establish the surface density\nof sources responsible for reionization. \n\n"}
{"id": "0904.2348", "contents": "Title: Dark Matter Searches with the Fermi Large Area Telescope Abstract: The Fermi Gamma-Ray Space Telescope, successfully launched on June 11th,\n2008, is the next generation satellite experiment for high-energy gamma-ray\nastronomy. The main instrument, the Fermi Large Area Telescope (LAT), with a\nwide field of view (> 2 sr), a large effective area (> 8000 cm2 at 1 GeV),\nsub-arcminute source localization, a large energy range (20 MeV - 300 GeV) and\na good energy resolution (close to 8% at 1 GeV), has excellent potential to\neither discover or to constrain a Dark Matter signal. The Fermi LAT team\npursues complementary searches for signatures of particle Dark Matter in\ndifferent search regions such as the galactic center, galactic satellites and\nsubhalos, the milky way halo, extragalactic regions as well as the search for\nspectral lines. In these proceedings we examine the potential of the LAT to\ndetect gamma-rays coming from Weakly Interacting Massive Particle annihilations\nin these regions with special focus on the galactic center region. \n\n"}
{"id": "0904.3389", "contents": "Title: Analytic Aperture Calculation and Scaling Laws for Radio Detection of\n  Lunar-Target UHE Neutrinos Abstract: We derive analytic expressions, and approximate them in closed form, for the\neffective detection aperture for Cerenkov radio emission from ultra-high-energy\nneutrinos striking the Moon. The resulting apertures are in good agreement with\nrecent Monte Carlo simulations and support the conclusion of James & Protheroe\n(2009)that neutrino flux upper limits derived from the GLUE search (Gorham et\nal.2004) were too low by an order of magnitude. We also use our analytic\nexpressions to derive scaling laws for the aperture as a function of\nobservational and lunar parameters. We find that at low frequencies\ndownward-directed neutrinos always dominate, but at higher frequencies, the\ncontribution from upward-directed neutrinos becomes increasingly important,\nespecially at low neutrino energies. Detecting neutrinos from Earth near the\nGZK regime will likely require radio telescope arrays with extremely large\ncollecting area and hundreds of hour of exposure time. Higher energy neutrinos\nare most easily detected using lower frequencies. Lunar surface roughness is a\ndecisive factor for obtaining detections at higher frequencies and higher\nenergies. \n\n"}
{"id": "0904.4725", "contents": "Title: Wavelength Accuracy of the Keck HIRES Spectrograph and Measuring Changes\n  in the Fine Structure Constant Abstract: We report on an attempt to accurately wavelength calibrate four nights of\ndata taken with the Keck HIRES spectrograph on QSO PHL957, for the purpose of\ndetermining whether the fine structure constant was different in the past.\nUsing new software and techniques, we measured the redshifts of various Ni II,\nFe II, Si II, etc. lines in a damped Ly-alpha system at z=2.309. Roughly half\nthe data was taken through the Keck iodine cell which contains thousands of\nwell calibrated iodine lines. Using these iodine exposures to calibrate the\nnormal Th-Ar Keck data pipeline output we found absolute wavelength offsets of\n500 m/s to 1000 m/s with drifts of more than 500 m/s over a single night, and\ndrifts of nearly 2000 m/s over several nights. These offsets correspond to an\nabsolute redshift of uncertainty of about Delta z=10^{-5} (Delta lambda= 0.02\nAng), with daily drifts of around Delta z=5x10^{-6} (Delta lambda =0.01 Ang),\nand multiday drifts of nearly Delta z=2x10^{-5} (0.04 Ang). The causes of the\nwavelength offsets are not known, but since claimed shifts in the fine\nstructure constant would result in velocity shifts of less than 100 m/s, this\nlevel of systematic uncertainty makes may make it difficult to use Keck HIRES\ndata to constrain the change in the fine structure constant. Using our\ncalibrated data, we applied both our own fitting software and standard fitting\nsoftware to measure (Delta alpha)/alpha, but discovered that we could obtain\nresults ranging from significant detection of either sign, to strong null\nlimits, depending upon which sets of lines and which fitting method was used.\nWe thus speculate that the discrepant results on (Delta alpha)/alpha reported\nin the literature may be due to random fluctuations coming from under-estimated\nsystematic errors in wavelength calibration and fitting procedure. \n\n"}
{"id": "0904.4823", "contents": "Title: On modeling the scalar meson dynamics with Resonance Chiral Theory Abstract: The features of the Resonance Chiral Theory (RChT) related to the description\nof the lightest scalar resonances, sigma, f0(980) and a0(980), are discussed.\nMajor attention is paid to the fits of the invariant mass distributions in the\nradiative decays of the phi(1020) meson. The study of the scalar sector in RChT\nis motivated by the success of the theory predictive power in numerous\nprocesses with other types of resonances. We conclude that RChT is sufficiently\nflexible to describe these decays, however the further quantitative improvement\nis required. The technical work-outs and related important questions are\noutlined. \n\n"}
{"id": "0905.0075", "contents": "Title: Observation number correlation in WMAP data Abstract: A remarkable similarity between the large-scale non-Gaussian pattern of\ncosmic microwave background (CMB) temperatures obtained by Wilkinson Microwave\nAnisotropy Probe (WMAP) mission and the distribution feature of observation\nnumbers is noted. Motivated from such a similarity, in this work we check the\nWMAP data for the correlation between pixel temperature t and observation\nnumber N. Systematic effect of imbalance differential observation and\nsignificant t-N correlation in magnitude, distribution non-Gaussianity and\nnorth-south asymmetry are found. Our results indicate that, for precision\ncosmology study based on WMAP observations, the observation effect on released\nWMAP temperature maps has to be further carefully studied. \n\n"}
{"id": "0905.0340", "contents": "Title: Using Spectral Flux Ratios to Standardize SN Ia Luminosities Abstract: We present a new method to standardize Type Ia supernova (SN Ia) luminosities\nto ~<0.13 magnitudes using flux ratios from a single flux-calibrated spectrum\nper SN. Using Nearby Supernova Factory spectrophotomery of 58 SNe Ia, we\nperformed an unbiased search for flux ratios which correlate with SN Ia\nluminosity. After developing the method and selecting the best ratios from a\ntraining sample, we verified the results on a separate validation sample and\nwith data from the literature. We identified multiple flux ratios whose\ncorrelations with luminosity are stronger than those of light curve shape and\ncolor, previously identified spectral feature ratios, or equivalent width\nmeasurements. In particular, the flux ratio R(642/443) = F(642 nm) / F(443 nm)\nhas a correlation of 0.95 with SN Ia absolute magnitudes. Using this single\nratio as a correction factor produces a Hubble diagram with a residual scatter\nstandard deviation of 0.125 +- 0.011 mag, compared with 0.161 +- 0.015 mag when\nfit with the SALT2 light curve shape and color parameters x1 and c. The ratio\nR(642/443) is an effective correction factor for both extrinsic dust reddening\nand instrinsic variations such as those of SN 1991T-like and SN 1999aa-like\nSNe. When combined with broad-band color measurements, spectral flux ratios can\nstandardize SN Ia magnitudes to ~0.12 mag. These are the first spectral metrics\nthat improve over the standard normalization methods based upon light curve\nshape and color and they provide among the lowest scatter Hubble diagrams ever\npublished. \n\n"}
{"id": "0905.0577", "contents": "Title: Constrained correlation functions Abstract: We show that correlation functions have to satisfy contraint relations, owing\nto the non-negativity of the power spectrum of the underlying random process.\nSpecifically, for any statistically homogeneous and (for more than one spatial\ndimension) isotropic random field with correlation function $\\xi(x)$, we derive\ninequalities for the correlation coefficients $r_n\\equiv \\xi(n x)/\\xi(0)$ (for\ninteger $n$) of the form $r_{n{\\rm l}}\\le r_n\\le r_{n{\\rm u}}$, where the lower\nand upper bounds on $r_n$ depend on the $r_j$, with $j<n$. Explicit expressions\nfor the bounds are obtained for arbitrary $n$. These constraint equations very\nsignificantly limit the set of possible correlation functions. For one\nparticular example of a fiducial cosmic shear survey, we show that the Gaussian\nlikelihood ellipsoid has a significant spill-over into the forbidden region of\ncorrelation functions, rendering the resulting best-fitting model parameters\nand their error region questionable, and indicating the need for a better\ndescription of the likelihood function.\n  We conduct some simple numerical experiments which explicitly demonstrate the\nfailure of a Gaussian description for the likelihood of $\\xi$. Instead, the\nshape of the likelihood function of the correlation coefficients appears to\nfollow approximately that of the shape of the bounds on the $r_n$, even if the\nGaussian ellipsoid lies well within the allowed region.\n  For more than one spatial dimension of the random field, the explicit\nexpressions of the bounds on the $r_n$ are not optimal. We outline a\ngeometrical method how tighter bounds may be obtained in principle. We\nillustrate this method for a few simple cases; a more general treatment awaits\nfuture work. \n\n"}
{"id": "0905.1121", "contents": "Title: Binary black holes' effects on electromagnetic fields Abstract: In addition to producing gravitational waves (GW), the dynamics of a binary\nblack hole system could induce emission of electromagnetic (EM) radiation by\naffecting the behavior of plasmas and electromagnetic fields in their vicinity.\nWe here study how the electromagnetic fields are affected by a pair of orbiting\nblack holes through the merger. In particular, we show how the binary's\ndynamics induce a variability in possible electromagnetically induced emissions\nas well as a possible enhancement of electromagnetic fields during the\nlate-merge and merger epochs. These time dependent features will likely leave\ntheir imprint in processes generating detectable emissions and can be exploited\nin the detection of electromagnetic counterparts of gravitational waves. \n\n"}
{"id": "0905.3169", "contents": "Title: Turbulent Motions and Shocks Waves in Galaxy Clusters simulated with AMR Abstract: We have implemented an Adaptive Mesh Refinement criterion explicitly designed\nto increase spatial resolution around discontinuities in the velocity field in\nENZO cosmological simulations. With this technique, shocks and turbulent eddies\ndeveloped during the hierarchical assembly of galaxy clusters are followed with\nunprecedented spatial resolution, even at large distances from the clusters\ncenter. By measuring the spectral properties of the gas velocity field, its\ntime evolution and the properties of shocks for a reference galaxy cluster, we\ninvestigate the connection between accretion processes and the onset of chaotic\nmotions in the simulated Inter Galactic Medium over a wide range of scales \n\n"}
{"id": "0905.3410", "contents": "Title: Optimizing baryon acoustic oscillation surveys II: curvature, redshifts,\n  and external datasets Abstract: We extend our study of the optimization of large baryon acoustic oscillation\n(BAO) surveys to return the best constraints on the dark energy, building on\nPaper I of this series (Parkinson et al. 2007). The survey galaxies are assumed\nto be pre-selected active, star-forming galaxies observed by their line\nemission with a constant number density across the redshift bin. Star-forming\ngalaxies have a redshift desert in the region 1.6 < z < 2, and so this redshift\nrange was excluded from the analysis. We use the Seo & Eisenstein (2007)\nfitting formula for the accuracies of the BAO measurements, using only the\ninformation for the oscillatory part of the power spectrum as distance and\nexpansion rate rulers. We go beyond our earlier analysis by examining the\neffect of including curvature on the optimal survey configuration and updating\nthe expected `prior' constraints from Planck and SDSS. We once again find that\nthe optimal survey strategy involves minimizing the exposure time and\nmaximizing the survey area (within the instrumental constraints), and that all\ntime should be spent observing in the low-redshift range (z<1.6) rather than\nbeyond the redshift desert, z>2. We find that when assuming a flat universe the\noptimal survey makes measurements in the redshift range 0.1 < z <0.7, but that\nincluding curvature as a nuisance parameter requires us to push the maximum\nredshift to 1.35, to remove the degeneracy between curvature and evolving dark\nenergy. The inclusion of expected other data sets (such as WiggleZ, BOSS and a\nstage III SN-Ia survey) removes the necessity of measurements below redshift\n0.9, and pushes the maximum redshift up to 1.5. We discuss considerations in\ndetermining the best survey strategy in light of uncertainty in the true\nunderlying cosmological model. \n\n"}
{"id": "0905.3632", "contents": "Title: Identification of All Dark Matter as Black Holes Abstract: For the universe I use dimensionless entropy $S/k = \\ln \\Omega$ for which the\nmost convenient unit is the googol ($10^{100}$) and identify all dark matter as\nblack holes whereupon the present entropy is about a thousand googols. While\nthe energy of the universe has been established to be about 0.04 baryons, 0.24\ndark matter and 0.72 dark energy, the cosmological entropy is almost entirely,\nabout $(1 - 10^{-15})$, from black holes and only $10^{-15}$ from everything\nelse. This identification of all dark matter as black holes is natural in\nstatistical mechanics. \n\n"}
{"id": "0905.4616", "contents": "Title: The Science Case for PILOT II: the Distant Universe Abstract: PILOT (the Pathfinder for an International Large Optical Telescope) is a\nproposed 2.5 m optical/infrared telescope to be located at Dome C on the\nAntarctic plateau. The atmospheric conditions at Dome C deliver a high\nsensitivity, high photometric precision, wide-field, high spatial resolution,\nand high-cadence imaging capability to the PILOT telescope. These capabilities\nenable a unique scientific potential for PILOT, which is addressed in this\nseries of papers. The current paper presents a series of projects dealing with\nthe distant (redshift >) Universe, that have been identified as key science\ndrivers for the PILOT facility. The potential for PILOT to detect the first\npopulations of stars to form in the early Universe, via infrared projects\nsearching for pair-instability supernovae and gamma-ray burst afterglows, is\ninvestigated. Two projects are proposed to examine the assembly and evolution\nof structure in the Universe: an infrared survey searching for the first\nevolved galaxies at high redshift, and an optical survey aimed at\ncharacterising moderate-redshift galaxy clusters. Finally, a large-area\nweak-lensing survey and a program to obtain supernovae infrared light-curves\nare proposed to examine the nature and evolution of dark energy and dark\nmatter. \n\n"}
{"id": "0906.0002", "contents": "Title: Inelastic Dark Matter and DAMA/LIBRA: An Experimentum Crucis Abstract: The DAMA/LIBRA collaboration has detected an annual modulation of the recoil\nrate in NaI crystals with the phase expected for WIMP scattering events. This\nsignal is dramatically inconsistent with upper limits from other experiments\nfor elastically scattering weak-scale WIMPs. However, the results are\ncompatible for the case of inelastic dark matter (iDM). The iDM theory, as\nimplemented by Tucker-Smith and Weiner, constrains the WIMP to a tight contour\nin sigma_n-delta space, where delta is the mass difference between the ground\nstate and excited WIMPs. An urgent priority in direct detection is to test this\nscenario. The crucial test of the iDM explanation of DAMA -- an \"experimentum\ncrucis\" -- is an experiment with directional sensitivity, which can measure the\ndaily modulation in direction. Because the contrast can be 100%, it is a\nsharper test than the much smaller annual modulation in the rate. We estimate\nthe significance of such an experiment as a function of the WIMP mass, cross\nsection, background rate, and other parameters. The proposed experiment\nseverely constrains the DAMA/iDM scenario even with modest exposure (~1000 kg\nday) on gaseous xenon. \n\n"}
{"id": "0906.0175", "contents": "Title: Residual noise covariance for Planck low-resolution data analysis Abstract: Aims: Develop and validate tools to estimate residual noise covariance in\nPlanck frequency maps. Quantify signal error effects and compare different\ntechniques to produce low-resolution maps.\n  Methods: We derive analytical estimates of covariance of the residual noise\ncontained in low-resolution maps produced using a number of map-making\napproaches. We test these analytical predictions using Monte Carlo simulations\nand their impact on angular power spectrum estimation. We use simulations to\nquantify the level of signal errors incurred in different resolution\ndowngrading schemes considered in this work.\n  Results: We find an excellent agreement between the optimal residual noise\ncovariance matrices and Monte Carlo noise maps. For destriping map-makers, the\nextent of agreement is dictated by the knee frequency of the correlated noise\ncomponent and the chosen baseline offset length. The significance of signal\nstriping is shown to be insignificant when properly dealt with. In map\nresolution downgrading, we find that a carefully selected window function is\nrequired to reduce aliasing to the sub-percent level at multipoles, ell >\n2Nside, where Nside is the HEALPix resolution parameter. We show that\nsufficient characterization of the residual noise is unavoidable if one is to\ndraw reliable contraints on large scale anisotropy.\n  Conclusions: We have described how to compute the low-resolution maps, with a\ncontrolled sky signal level, and a reliable estimate of covariance of the\nresidual noise. We have also presented a method to smooth the residual noise\ncovariance matrices to describe the noise correlations in smoothed, bandwidth\nlimited maps. \n\n"}
{"id": "0906.0664", "contents": "Title: Statistical techniques in cosmology Abstract: In these lectures I cover a number of topics in cosmological data analysis. I\nconcentrate on general techniques which are common in cosmology, or techniques\nwhich have been developed in a cosmological context. In fact they have very\ngeneral applicability, for problems in which the data are interpreted in the\ncontext of a theoretical model, and thus lend themselves to a Bayesian\ntreatment.\n  We consider the general problem of estimating parameters from data, and\nconsider how one can use Fisher matrices to analyse survey designs before any\ndata are taken, to see whether the survey will actually do what is required. We\noutline numerical methods for estimating parameters from data, including Monte\nCarlo Markov Chains and the Hamiltonian Monte Carlo method. We also look at\nModel Selection, which covers various scenarios such as whether an extra\nparameter is preferred by the data, or answering wider questions such as which\ntheoretical framework is favoured, using General Relativity and braneworld\ngravity as an example. These notes are not a literature review, so there are\nrelatively few references. \n\n"}
{"id": "0906.0820", "contents": "Title: Water Cherenkov Detectors response to a Gamma Ray Burst in the Large\n  Aperture GRB Observatory Abstract: In order to characterise the behaviour of Water Cherenkov Detectors (WCD)\nunder a sudden increase of 1 GeV - 1 TeV background photons from a Gamma Ray\nBurst (GRB), simulations were conducted and compared to data acquired by the\nWCD of the Large Aperture GRB Observatory (LAGO). The LAGO operates arrays of\nWCD at high altitude to detect GRBs using the single particle technique. The\nLAGO sensitivity to GRBs is derived from the reported simulations of the gamma\ninitiated particle showers in the atmosphere and the WCD response to\nsecondaries. \n\n"}
{"id": "0906.0981", "contents": "Title: Submillimeter Number Counts From Statistical Analysis of BLAST Maps Abstract: We describe the application of a statistical method to estimate submillimeter\ngalaxy number counts from confusion limited observations by the Balloon-borne\nLarge Aperture Submillimeter Telescope (BLAST). Our method is based on a\nmaximum likelihood fit to the pixel histogram, sometimes called 'P(D)', an\napproach which has been used before to probe faint counts, the difference being\nthat here we advocate its use even for sources with relatively high\nsignal-to-noise ratios. This method has an advantage over standard techniques\nof source extraction in providing an unbiased estimate of the counts from the\nbright end down to flux densities well below the confusion limit. We\nspecifically analyse BLAST observations of a roughly 10 sq. deg. map centered\non the Great Observatories Origins Deep Survey South (GOODS-S) field. We\nprovide estimates of number counts at the three BLAST wavelengths, 250, 350,\nand 500 microns; instead of counting sources in flux bins we estimate the\ncounts at several flux density nodes connected with power-laws. We observe a\ngenerally very steep slope for the counts of about -3.7 at 250 microns and -4.5\nat 350 and 500 microns, over the range ~0.02-0.5 Jy, breaking to a shallower\nslope below about 0.015 Jy at all three wavelengths. We also describe how to\nestimate the uncertainties and correlations in this method so that the results\ncan be used for model-fitting. This method should be well-suited for analysis\nof data from the Herschel satellite. \n\n"}
{"id": "0906.0993", "contents": "Title: Fisher Matrix Preloaded -- Fisher4Cast Abstract: The Fisher Matrix is the backbone of modern cosmological forecasting. We\ndescribe the Fisher4Cast software: a general-purpose, easy-to-use, Fisher\nMatrix framework. It is open source, rigorously designed and tested and\nincludes a Graphical User Interface (GUI) with automated LATEX file creation\ncapability and point-and-click Fisher ellipse generation. Fisher4Cast was\ndesigned for ease of extension and, although written in Matlab, is easily\nportable to open-source alternatives such as Octave and Scilab. Here we use\nFisher4Cast to present new 3-D and 4-D visualisations of the forecasting\nlandscape and to investigate the effects of growth and curvature on future\ncosmological surveys. Early releases have been available at\nhttp://www.cosmology.org.za since May 2008 with 750 downloads in the first\nyear. Version 2.2 is made public with this paper and includes a Quick Start\nguide and the code used to produce the figures in this paper, in the hope that\nit will be useful to the cosmology and wider scientific communities. \n\n"}
{"id": "0906.0995", "contents": "Title: Photometric Redshift Estimation Using Spectral Connectivity Analysis Abstract: The development of fast and accurate methods of photometric redshift\nestimation is a vital step towards being able to fully utilize the data of\nnext-generation surveys within precision cosmology. In this paper we apply a\nspecific approach to spectral connectivity analysis (SCA; Lee & Wasserman 2009)\ncalled diffusion map. SCA is a class of non-linear techniques for transforming\nobserved data (e.g., photometric colours for each galaxy, where the data lie on\na complex subset of p-dimensional space) to a simpler, more natural coordinate\nsystem wherein we apply regression to make redshift predictions. As SCA relies\nupon eigen-decomposition, our training set size is limited to ~ 10,000\ngalaxies; we use the Nystrom extension to quickly estimate diffusion\ncoordinates for objects not in the training set. We apply our method to 350,738\nSDSS main sample galaxies, 29,816 SDSS luminous red galaxies, and 5,223\ngalaxies from DEEP2 with CFHTLS ugriz photometry. For all three datasets, we\nachieve prediction accuracies on par with previous analyses, and find that use\nof the Nystrom extension leads to a negligible loss of prediction accuracy\nrelative to that achieved with the training sets. As in some previous analyses\n(e.g., Collister & Lahav 2004, Ball et al. 2008), we observe that our\npredictions are generally too high (low) in the low (high) redshift regimes. We\ndemonstrate that this is a manifestation of attenuation bias, wherein\nmeasurement error (i.e., uncertainty in diffusion coordinates due to\nuncertainty in the measured fluxes/magnitudes) reduces the slope of the\nbest-fit regression line. Mitigation of this bias is necessary if we are to use\nphotometric redshift estimates produced by computationally efficient empirical\nmethods in precision cosmology. \n\n"}
{"id": "0906.1735", "contents": "Title: Searching for New Physics with Ultrahigh Energy Cosmic Rays Abstract: Ultrahigh energy cosmic rays that produce giant extensive showers of charged\nparticles and photons when they interact in the Earth's atmosphere provide a\nunique tool to search for new physics. Of particular interest is the\npossibility of detecting a very small violation of Lorentz invariance such as\nmay be related to the structure of space-time near the Planck scale of $\\sim\n10^{-35}$m. We discuss here the possible signature of Lorentz invariance\nviolation on the spectrum of ultrahigh energy cosmic rays as compared with\npresent observations of giant air showers. We also discuss the possibilities of\nusing more sensitive detection techniques to improve searches for Lorentz\ninvariance violation in the future. Using the latest data from the Pierre Auger\nObservatory, we derive a best fit to the LIV parameter of $3.0^{+1.5}_{-3.0}\n\\times 10^{-23}$, corresponding to an upper limit of $4.5 \\times 10^{-23}$ at a\nproton Lorentz factor of $\\sim 2 \\times 10^{11}$. This result has fundamental\nimplications for quantum gravity models. \n\n"}
{"id": "0906.3179", "contents": "Title: Experimental search of bursts of very high energy gamma rays from\n  primordial black holes Abstract: The technical procedure of a search of bursts of very high energy gamma rays\nfrom evaporation of primordial black holes on air-shower array \"Andyrchy\" of\nBaksan Neutrino Observatory of Institute for Nuclear Research is described. The\ntheoretical model used in the present work assumes that the chromosphere around\nthe evaporating black hole does not form. For minimization of the cosmic ray\nbackground the method of multidimensional analysis of modelled as well as\nexperimentally detected events is applied. The new upper limit on the\nconcentration of evaporating primordial black holes in the local region of\nGalaxy is obtained. The comparison of the results of different experiments is\ngiven. \n\n"}
{"id": "0906.3182", "contents": "Title: Experimental search of bursts of gamma rays from primordial black holes\n  using different evaporation models Abstract: Experimental data of arrays \"Andyrchy\" and \"Carpet-2\" of Baksan Neutrino\nObservatory (Institute for Nuclear Research), obtained in the regime of a\ndetection of the single cosmic-ray component, are used for a search of the\nbursts of cosmic gamma rays from evaporating primordial black holes. Different\ntheoretical models of the evaporation process are used for the analysis.\nDistributions of the counting rate fluctuations on both arrays agree with the\nexpectations from the cosmic ray background. The new constraints on the\nconcentration of evaporating primordial black holes in the local region of\nGalaxy are obtained. The comparison of the results of different experiments is\ngiven. \n\n"}
{"id": "0906.3731", "contents": "Title: Prospects for constraining quantum gravity dispersion with near term\n  observations Abstract: We discuss the prospects for bounding and perhaps even measuring quantum\ngravity effects on the dispersion of light using the highest energy photons\nproduced in gamma ray bursts measured by the Fermi telescope. These prospects\nare brigher than might have been expected as in the first 10 months of\noperation Fermi has reported so far eight events with photons over 100 MeV seen\nby its Large Area Telescope (LAT). We review features of these events which may\nbear on Planck scale phenomenology and we discuss the possible implications for\nthe alternative scenarios for in-vacua dispersion coming from breaking or\ndeforming of Poincare invariance. Among these are semi-conservative bounds,\nwhich rely on some relatively weak assumptions about the sources, on subluminal\nand superluminal in-vacuo dispersion. We also propose that it may be possible\nto look for the arrival of still higher energy photons and neutrinos from GRB's\nwith energies in the range 10^14 - 10^17 eV. In some cases the quantum gravity\ndispersion effect would predict these arrivals to be delayed or advanced by\ndays to months from the GRB, giving a clean separation of astrophysical source\nand spacetime propagation effects. \n\n"}
{"id": "0906.4035", "contents": "Title: Wide and deep near-UV (360nm) galaxy counts and the extragalactic\n  background light with the Large Binocular Camera Abstract: Deep multicolour surveys are the main tool to explore the formation and\nevolution of the faint galaxies which are beyond the spectroscopic limit with\nthe present technology. The photometric properties of these faint galaxies are\nusually compared with current renditions of semianalytical models to provide\nconstraints on the fundamental physical processes involved in galaxy formation\nand evolution, namely the mass assembly and the star formation. Galaxy counts\nover large sky areas in the near-UV band are important because they are\ndifficult to obtain given the low efficiency of near-UV instrumentation, even\nat 8m class telescopes. A large instrumental field of view helps in minimizing\nthe biases due to the cosmic variance. We have obtained deep images in the\n360nm U band provided by the blue channel of the Large Binocular Camera at the\nprime focus of the Large Binocular Telescope. We have derived over an area of\n~0.4 sq. deg. the galaxy number counts down to U=27 in the Vega system\n(corresponding to U=27.86 in the AB system) at a completeness level of 30%\nreaching the faintest current limit for this wavelength and sky area. The shape\nof the galaxy counts in the U band can be described by a double power-law, the\nbright side being consistent with the shape of shallower surveys of comparable\nor greater areas. The slope bends over significantly at U>23.5 ensuring the\nconvergence of the contribution by star forming galaxies to the EBL in the\nnear-UV band to a value which is more than 70% of the most recent upper limits\nderived for this band. We have jointly compared our near-UV and K band counts\ncollected from the literature with few selected hierarchical CDM models\nemphasizing critical issues in the physical description of the galaxy formation\nand evolution. \n\n"}
{"id": "0906.4772", "contents": "Title: On Adiabatic Renormalization of Inflationary Perturbations Abstract: We discuss the impact of adiabatic renormalization on the power spectrum of\nscalar and tensor perturbations from inflation. We show that adiabatic\nregularization is ambiguous as it leads to very different results, for\ndifferent adiabatic subtraction schemes, both in the range $v\\equiv k/(aH)\n\\gsim 0.1$ and in the infrared regime. All these schemes agree in the far\nultraviolet, $v\\gg 1$. Therefore, we argue that in the far infrared regime,\n$v\\ll 1$, the adiabatic expansion is no longer valid, and the unrenormalized\nspectra are the physical, measurable quantities. These findings cast some doubt\non the validity of the adiabatic subtraction at horizon exit, $v=1$, to\ndetermine the perturbation spectra from inflation which has recently advocated\nin the literature. \n\n"}
{"id": "0906.5351", "contents": "Title: Shrinking the Braneworld: Black Hole in a Globular Cluster Abstract: Large extra dimensions have been proposed as a possible solution to the\nhierarchy problem in physics. One of the suggested models, the RS2 braneworld\nmodel, makes a prediction that black holes evaporate by Hawking radiation on a\nshort timescale that depends on the black hole mass and on the asymptotic\nradius of curvature of the extra dimensions. Thus the size of the extra\ndimensions can be constrained by astrophysical observations. Here we point out\nthat the black hole, recently discovered in a globular cluster in galaxy NGC\n4472, places the strongest constraint on the maximum size of the extra\ndimensions, L < 0.003 mm. This black hole has the virtues of old age and\nrelatively small mass. The derived upper limit is within an order of magnitude\nof the absolute limit afforded by astrophysical observations of black holes. \n\n"}
{"id": "0907.0006", "contents": "Title: Constant surface gravity and density profile of dark matter Abstract: Cumulative observational evidence confirm that the surface gravity of dark\nmatter (DM) halo mu_{0 D} = r_0 rho_0 where r_0 and rho_0 are the halo core\nradius and central density, respectively, is nearly constant and independent of\ngalaxy luminosity for a high number of galactic systems (spirals, dwarf\nirregular and spheroidals, elliptics) spanning over 14 magnitudes in luminosity\nand of different Hubble types. Remarkably, its numerical value mu_{0 D} = 140\nM_{sun}/pc^2 = (18.6 Mev)^3 is approximately the same (up to a factor of two)\nin all these systems. First, we present the physical consequences of the\nindependence of mu_{0 D} on r_0: the energy scales as the volume sim r_0^3\nwhile the mass and the entropy scale as the surface ~ r_0^2 and the surface\ntimes log r_0, respectively. Namely, the entropy scales similarly to the\nblack-hole entropy but with a much smaller coefficient. Second, we compute the\nsurface gravity and the density profile for small scales from first principles\nand the evolution of primordial density fluctuations since the end of inflation\ntill today using the linearized Boltzmann-Vlasov equation. The density profile\nrho_{lin}(r) obtained in this way decreases as r^{-1-n_s/2} for intermediate\nscales where n_s = 0.964 is the primordial spectral index. This scaling is in\nremarkable agreement with the empirical behaviour found observationally and in\nN-body simulations: r^{-1.6\\pm 0.4}. The observed value of mu_{0 D} indicates\nthat the DM particle mass m is in the keV scale. The theoretically derived\ndensity profiles rho_{lin}(r) turn to be cored for m in the keV scale and they\nlook as cusped for m in the GeV scale or beyond. We consider both fermions and\nbosons as DM particles decoupling either ultrarelativistically or\nnon-relativistically. Our results do not use any particle physics model and\nvary slightly with the statistics of the DM particle. \n\n"}
{"id": "0907.0461", "contents": "Title: The Atacama Cosmology Telescope (ACT): Beam Profiles and First SZ\n  Cluster Maps Abstract: The Atacama Cosmology Telescope (ACT) is currently observing the cosmic\nmicrowave background with arcminute resolution at 148 GHz, 218 GHz, and 277\nGHz. In this paper, we present ACT's first results. Data have been analyzed\nusing a maximum-likelihood map-making method which uses B-splines to model and\nremove the atmospheric signal. It has been used to make high-precision beam\nmaps from which we determine the experiment's window functions. This beam\ninformation directly impacts all subsequent analyses of the data. We also used\nthe method to map a sample of galaxy clusters via the Sunyaev-Zel'dovich (SZ)\neffect, and show five clusters previously detected with X-ray or SZ\nobservations. We provide integrated Compton-y measurements for each cluster. Of\nparticular interest is our detection of the z = 0.44 component of A3128 and our\ncurrent non-detection of the low-redshift part, providing strong evidence that\nthe further cluster is more massive as suggested by X-ray measurements. This is\na compelling example of the redshift-independent mass selection of the SZ\neffect. \n\n"}
{"id": "0907.0675", "contents": "Title: DMTPC: A dark matter detector with directional sensitivity Abstract: By correlating nuclear recoil directions with the Earth's direction of motion\nthrough the Galaxy, a directional dark matter detector can unambiguously detect\nWeakly Interacting Massive Particles (WIMPs), even in the presence of\nbackgrounds. Here, we describe the Dark Matter Time-Projection Chamber (DMTPC)\ndetector, a TPC filled with CF4 gas at low pressure (0.1 atm). Using this\ndetector, we have measured the vector direction (head-tail) of nuclear recoils\ndown to energies of 100 keV with an angular resolution of <15 degrees. To study\nour detector backgrounds, we have operated in a basement laboratory on the MIT\ncampus for several months. We are currently building a new, high-radiopurity\ndetector for deployment underground at the Waste Isolation Pilot Plant facility\nin New Mexico. \n\n"}
{"id": "0907.1093", "contents": "Title: AzTEC Half Square Degree Survey of the SHADES Fields -- I. Maps,\n  Catalogues, and Source Counts Abstract: We present the first results from the largest deep extragalactic\nmillimetre-wavelength survey undertaken to date. These results are derived from\nmaps covering over 0.7 deg^2, made at 1.1mm, using the AzTEC continuum camera\nmounted on the James Clerk Maxwell Telescope. The maps were made in the two\nfields originally targeted at 0.85mm with SCUBA in the SHADES project, namely\nthe Lockman Hole East (mapped to a depth of 0.9-1.3 mJy rms) and the Subaru XMM\nDeep Field (1.0-1.7 mJy rms). The wealth of existing and forthcoming deep\nmulti-frequency data in these two fields will allow the bright mm source\npopulation revealed by these images to be explored in detail in subsequent\npapers. Here we present the maps themselves, a catalogue of 114\nhigh-significance sub-millimetre galaxy detections, and a thorough statistical\nanalysis leading to the most robust determination to date of the 1.1mm source\nnumber counts. Through careful comparison, we find that both the COSMOS and\nGOODS North fields, also imaged with AzTEC, contain an excess of mm sources\nover the new 1.1mm source-count baseline established here. In particular, our\nnew AzTEC/SHADES results indicate that very luminous high-redshift dust\nenshrouded starbursts (S_{1.1} > 3 mJy) are 25-50% less common than would have\nbeen inferred from these smaller surveys, thus highlighting the potential roles\nof cosmic variance and clustering in such measurements. We compare number count\npredictions from recent models of the evolving mm/sub-mm source population to\nthese SMG surveys, which provide important constraints for the ongoing\nrefinement of semi-analytic and hydrodynamical models of galaxy formation, and\nfind that all recent models over-predict the number of bright sub-millimetre\ngalaxies found in this survey. \n\n"}
{"id": "0907.1710", "contents": "Title: Weak Mott insulators on the triangular lattice: possibility of a gapless\n  nematic quantum spin liquid Abstract: We study the energetics of Gutzwiller projected BCS states of various\nsymmetries for the triangular lattice antiferromagnet with a four particle ring\nexchange using variational Monte Carlo methods. In a range of parameters the\nenergetically favored state is found to be a projected $d_{x^2-y^2}$ paired\nstate which breaks lattice rotational symmetry. We show that the properties of\nthis nematic or orientationally ordered paired spin liquid state as a function\nof temperature and pressure can account for many of the experiments on organic\nmaterials. We also study the ring-exchange model with ferromagnetic Heisenberg\nexchange and find that amongst the studied ans\\\"atze, a projected $f-$wave\nstate is the most favorable. \n\n"}
{"id": "0907.2731", "contents": "Title: Improved CMB Map from WMAP Data Abstract: The cosmic microwave background (CMB) temperature maps published by the\nWilkinson Microwave Anisotropy Probe (WMAP) team are found to be inconsistent\nwith the differential time-ordered data (TOD), from which the maps are\nreconstructed. The inconsistency indicates that there is a serious problem in\nthe map making routine of the WMAP team, and it is necessary to reprocess the\nWMAP data. We develop a self-consistent software package of map-making and\npower spectrum estimation independently of the WMAP team. Our software passes a\nvariety of tests. New CMB maps are then reconstructed, which are significantly\ndifferent from the official WMAP maps. In the new maps, the inconsistency\ndisappeared, along with the hitherto unexplained high level alignment between\nthe CMB quadrupole and octopole components detected in released WMAP maps. An\nimproved CMB cross-power spectrum is then derived from the new maps which\nbetter agrees with that of BOOMRANG. Two important results are hence obtained:\nthe CMB quadrupole drops to nearly zero, and the power in multiple moment range\nbetween 200 and 675 decreases on average by about 13%, causing the best-fit\ncosmological parameters to change considerably, e.g., the total matter density\nincreases from 0.26 up to 0.32 and the dark energy density decreases from 0.74\ndown to 0.68. These new parameters match with improved accuracy those of other\nindependent experiments. Our results indicate that there is still room for\nsignificant revision in the cosmological model parameters. \n\n"}
{"id": "0907.5003", "contents": "Title: Nucleosynthesis Constraints on a Massive Gravitino in Neutralino Dark\n  Matter Scenarios Abstract: The decays of massive gravitinos into neutralino dark matter particles and\nStandard Model secondaries during or after Big-Bang nucleosynthesis (BBN) may\nalter the primordial light-element abundances. We present here details of a new\nsuite of codes for evaluating such effects, including a new treatment based on\nPYTHIA of the evolution of showers induced by hadronic decays of massive,\nunstable particles such as a gravitino. We also develop an analytical treatment\nof non-thermal hadron propagation in the early universe, and use this to derive\nanalytical estimates for light-element production and in turn on decaying\nparticle lifetimes and abundances. We then consider specifically the case of an\nunstable massive gravitino within the constrained minimal supersymmetric\nextension of the Standard Model (CMSSM). We present upper limits on its\npossible primordial abundance before decay for different possible gravitino\nmasses, with CMSSM parameters along strips where the lightest neutralino\nprovides all the astrophysical cold dark matter density. We do not find any\nCMSSM solution to the cosmological Li7 problem for small m_{3/2}. Discounting\nthis, for m_{1/2} ~ 500 GeV and tan beta = 10 the other light-element\nabundances impose an upper limit m_{3/2} n_{3/2}/n_\\gamma < 3 \\times 10^{-12}\nGeV to < 2 \\times 10^{-13} GeV for m_{3/2} = 250 GeV to 1 TeV, which is similar\nin both the coannihilation and focus-point strips and somewhat weaker for tan\nbeta = 50, particularly for larger m_{1/2}. The constraints also weaken in\ngeneral for larger m_{3/2}, and for m_{3/2} > 3 TeV we find a narrow range of\nm_{3/2} n_{3/2}/n_\\gamma, at values which increase with m_{3/2}, where the Li7\nabundance is marginally compatible with the other light-element abundances. \n\n"}
{"id": "0908.0394", "contents": "Title: A new view on the ISM of galaxies: far-infrared and submillimetre\n  spectroscopy with Herschel Abstract: The FIR/submm window is amongst the least explored spectral regions of the\nelectromagnetic spectrum. It is, however, a key to study the general properties\nof the interstellar medium of galaxies, as it contains important spectral line\ndiagnostics from the neutral, ionized and molecular ISM. The Herschel Space\nObservatory, successfully launched on 14 May 2009, is the first observatory to\ncover the entire FIR/submm range between 57 and 672 mum. We discuss the main\nresults from the ISO era on FIR spectroscopy of galaxies and the enormous\nscience potential of the Herschel mission through a presentation of its\nspectroscopic extragalactic key programs. \n\n"}
{"id": "0908.0603", "contents": "Title: 3D spectroscopic study of galactic rings: formation and kinematics Abstract: In this review we consider various ring structures that are observed in\ngalaxies. Formation and evolution of the rings are interesting problems in\nstudies of galactic morphology. They are related to such fundamental aspects of\ngalactic evolution and dynamics as the nature and distribution of the dark\nmatter in galaxies, galactic interactions and internal secular evolution of\ngalactic substructures. A significant fraction of galactic rings forms in the\ndisks due to gravitational torques from bar-like patterns. In contrast to this\ninternally driven origin, the phenomenon of the polar-ring galaxies is closely\nconnected with the processes of intergalactic interactions and merging. A rare\nclass of collisional rings reveals the density waves triggered in the stellar\nand gaseous disks after a strong head-on collision with a companion. We briefly\nreview the status of studies of gas kinematics in the rings of different\norigin. We stress that velocity fields of the ionized gas obtained with the\nFabry-Perot interferometers provide a very important information for these\nstudies. \n\n"}
{"id": "0908.2742", "contents": "Title: A Bayesian Approach Accounting for Stochastic Fluctuations in Stellar\n  Cluster Properties Abstract: The integrated spectro-photometric properties of star clusters are subject to\nlarge cluster-to-cluster variations. They are distributed in non trivial ways\naround the average properties predicted by standard population synthesis\nmodels. This results from the stochastic mass distribution of the finite\n(small) number of luminous stars in each cluster, stars which may be either\nparticularly blue or particularly red. The color distributions are broad and\nusually far from Gaussian, especially for young and intermediate age clusters,\nas found in interacting galaxies. When photometric measurements of clusters are\nused to estimate ages and masses in conjunction with standard models, biases\nare to be expected. We present a Bayesian approach that explicitly accounts for\nstochasticity when estimating ages and masses of star clusters that cannot be\nresolved into stars. Based on Monte-Carlo simulations, we are starting to\nexplore the probability distributions of star cluster properties obtained given\na set of multi-wavelength photometric data. \n\n"}
{"id": "0908.2908", "contents": "Title: A Brief Review on Dark Matter Annihilation Explanation for $e^\\pm$\n  Excesses in Cosmic Ray Abstract: Recently data from PAMELA, ATIC, FERMI-LAT and HESS show that there are\n$e^{\\pm}$ excesses in the cosmic ray energy spectrum. PAMELA observed excesses\nonly in $e^+$, but not in anti-proton spectrum. ATIC, FERMI-LAT and HESS\nobserved excesses in $e^++e^-$ spectrum, but the detailed shapes are different\nwhich requires future experimental observations to pin down the correct data\nset. Nevertheless a lot of efforts have been made to explain the observed\n$e^\\pm$ excesses, and also why PAMELA only observed excesses in $e^+$ but not\nin anti-proton. In this brief review we discuss one of the most popular\nmechanisms to explain the data, the dark matter annihilation. It has long been\nknown that about 23% of our universe is made of relic dark matter. If the relic\ndark matter was thermally produced, the annihilation rate is constrained\nresulting in the need of a large boost factor to explain the data. We will\ndiscuss in detail how a large boost factor can be obtained by the Sommerfeld\nand Briet-Wigner enhancement mechanisms. Some implications for particle physics\nmodel buildings will also be discussed. \n\n"}
{"id": "0908.4179", "contents": "Title: Compressed sensing reconstruction of a string signal from\n  interferometric observations of the cosmic microwave background Abstract: We propose an algorithm for the reconstruction of the signal induced by\ncosmic strings in the cosmic microwave background (CMB), from\nradio-interferometric data at arcminute resolution. Radio interferometry\nprovides incomplete and noisy Fourier measurements of the string signal, which\nexhibits sparse or compressible magnitude of the gradient due to the\nKaiser-Stebbins (KS) effect. In this context the versatile framework of\ncompressed sensing naturally applies for solving the corresponding inverse\nproblem. Our algorithm notably takes advantage of a model of the prior\nstatistical distribution of the signal fitted on the basis of realistic\nsimulations. Enhanced performance relative to the standard CLEAN algorithm is\ndemonstrated by simulated observations under noise conditions including primary\nand secondary CMB anisotropies. \n\n"}
{"id": "0908.4280", "contents": "Title: SNANA: A Public Software Package for Supernova Analysis Abstract: We describe a general analysis package for supernova (SN) light curves,\ncalled SNANA, that contains a simulation, light curve fitter, and cosmology\nfitter. The software is designed with the primary goal of using SNe Ia as\ndistance indicators for the determination of cosmological parameters, but it\ncan also be used to study efficiencies for analyses of SN rates, estimate\ncontamination from non-Ia SNe, and optimize future surveys. Several SN models\nare available within the same software architecture, allowing technical\nfeatures such as K-corrections to be consistently used among multiple models,\nand thus making it easier to make detailed comparisons between models. New and\nimproved light-curve models can be easily added. The software works with\narbitrary surveys and telescopes and has already been used by several\ncollaborations, leading to more robust and easy-to-use code. This software is\nnot intended as a final product release, but rather it is designed to undergo\ncontinual improvements from the community as more is learned about SNe. Below\nwe give an overview of the SNANA capabilities, as well as some of its\nlimitations. Interested users can find software downloads and more detailed\ninformation from the manuals at http://www.sdss.org/supernova/SNANA.html . \n\n"}
{"id": "0909.0001", "contents": "Title: Omniscopes: Large Area Telescope Arrays with only N log N Computational\n  Cost Abstract: We show that the class of antenna layouts for telescope arrays allowing cheap\nanalysis hardware (with correlator cost scaling as N log N rather than N^2 with\nthe number of antennas N) is encouragingly large, including not only previously\ndiscussed rectangular grids but also arbitrary hierarchies of such grids, with\narbitrary rotations and shears at each level. We show that all correlations for\nsuch a 2D array with an n-level hierarchy can be efficiently computed via a\nFast Fourier Transform in not 2 but 2n dimensions. This can allow major\ncorrelator cost reductions for science applications requiring exquisite\nsensitivity at widely separated angular scales, for example 21cm tomography\n(where short baselines are needed to probe the cosmological signal and long\nbaselines are needed for point source removal), helping enable future 21cm\nexperiments with thousands or millions of cheap dipole-like antennas. Such\nhierarchical grids combine the angular resolution advantage of traditional\narray layouts with the cost advantage of a rectangular Fast Fourier Transform\nTelescope. We also describe an algorithm for how a subclass of hierarchical\narrays can efficiently use rotation synthesis to produce global sky maps with\nminimal noise and a well-characterized synthesized beam. \n\n"}
{"id": "0909.0507", "contents": "Title: Pixel-based correction for Charge Transfer Inefficiency in the Hubble\n  Space Telescope Advanced Camera for Surveys Abstract: Charge Transfer Inefficiency (CTI) due to radiation damage above the Earth's\natmosphere creates spurious trailing in Hubble Space Telescope (HST) images.\nRadiation damage also creates unrelated warm pixels - but these happen to be\nperfect for measuring CTI. We model CTI in the Advanced Camera for Surveys\n(ACS)/Wide Field Channel (WFC) and construct a physically motivated correction\nscheme. This operates on raw data, rather than secondary science products, by\nreturning individual electrons to pixels from which they were unintentionally\ndragged during readout. We apply our correction to images from the HST COSMOS\nsurvey, successfully reducing the CTI trails by a factor of ~30 everywhere in\nthe CCD and at all flux levels. We quantify changes in galaxy photometry,\nastrometry and shape. The remarkable 97% level of correction is more than\nsufficient to enable a (forthcoming) reanalysis of downstream science products,\nand the collection of larger surveys. \n\n"}
{"id": "0909.0742", "contents": "Title: Observing gravitational wave bursts in pulsar timing measurements Abstract: We propose a novel method for observing the gravitational wave signature of\nsuper-massive black hole (SMBH) mergers. This method is based on detection of a\nspecific type of gravitational waves, namely gravitational wave burst with\nmemory (BWM), using pulsar timing. We study the unique signature produced by\nBWM in anomalous pulsar timing residuals. We show that the present day pulsar\ntiming precision allows one to detect BWM due to SMBH mergers from distances up\nto 1 Gpc (for case of equal mass 10^8 Msun SMBH). Improvements in precision of\npulsar timing together with the increase in number of observed pulsars should\neventually lead to detection of a BWM signal due to SMBH merger, thereby making\nthe proposed technique complementary to the capabilities of the planned LISA\nmission. \n\n"}
{"id": "0909.0755", "contents": "Title: Testing the Gamma-Ray Burst Pulse Start Conjecture Abstract: We test the hypothesis that prompt gamma-ray burst pulse emission starts\nsimultaneously at all energies (the Pulse Start Conjecture). Our analysis,\nusing a sample of BATSE bursts observed with four channel, 64-ms data and\nperformed using a pulse fit model, generally supports this hypothesis for the\nLong GRB class, although a few discrepant pulses belong to bursts observed\nduring times characterized by low signal-to-noise, hidden pulses, and/or\nsignificant pulse overlap. The typical uncertainty in making this statement is\n< 0.4 s for pulses in Long GRBs (and < 0.2 s for 40% of the pulses) and perhaps\n< 0.1 s for pulses in Short GRBs. When considered along with the Epk decline\nfound in GRB pulse evolution, this result implies that energy is injected at\nthe beginning of each and every GRB pulse, and the subsequent spectral\nevolution, including the pulse peak intensity, represents radiated energy\nlosses from this initial injection. \n\n"}
{"id": "0909.3584", "contents": "Title: New Constraints on variations of the fine structure constant from CMB\n  anisotropies Abstract: We demonstrate that recent measurements of Cosmic Microwave Background\ntemperature and polarization anisotropy made by the ACBAR, QUAD and BICEP\nexperiments substantially improve the cosmological constraints on possible\nvariations of the fine structure constant in the early universe. This data,\ncombined with the five year observations from the WMAP mission yield the\nconstraint alpha/alpha_0 = 0.987 \\pm 0.012 at 68% c.l.. The inclusion of the\nnew HST constraints on the Hubble constant further increases the accuracy to\nalpha/alpha_0 = 1.001 \\pm 0.007 at 68% c.l., bringing possible deviations from\nthe current value below the 1% level and improving previous constraints by a\nfactor 3. \n\n"}
{"id": "0909.3669", "contents": "Title: The ATLAS Survey of the CDFS and ELAIS-S1 Fields Abstract: The first phase of the ATLAS (Australia Telescope Large Area Survey) project\nsurveyed a total 7 square degrees down to 30 micro Jy rms at 1.4 GHz and is the\nlargest sensitive radio survey ever attempted. We report on the scientific\nachievements of ATLAS to date and plans to extend the project as a path finder\nfor the proposed EMU (Evolutionary map of the Universe) project which has been\ndesigned to use ASKAP (Australian Square Kilometre Array Pathfinder). \n\n"}
{"id": "0909.4164", "contents": "Title: Galaxies and Cladistics Abstract: The Hubble tuning fork diagram, based on morphology and established in the\n1930s, has always been the preferred scheme for classification of galaxies.\nHowever, the current large amount of multiwavelength data, most often spectra,\nfor objects up to very high distances, asks for more sophisticated statistical\napproaches. Interpreting formation and evolution of galaxies as a ?transmission\nwith modification' process, we have shown that the concepts and tools of\nphylogenetic systematics can be heuristically transposed to the case of\ngalaxies. This approach, which we call ?astrocladistics', has successfully been\napplied on several samples. Many difficulties still remain, some of them being\nspecific to the nature of both galaxies and their diversification processes,\nsome others being classical in cladistics, like the pertinence of the\ndescriptors in conveying any useful evolutionary information. \n\n"}
{"id": "0909.5303", "contents": "Title: Preparing old and recent radio source tables for the VO age: Current\n  status Abstract: Independent of established data centers, and partly for my own research, I\nhave been collecting the tabular data from nearly 1500 articles concerned with\nradio sources. Optical character recognition (OCR) was used to recover tables\nfrom nearly 600 of these. Tables from only 44 percent of these articles are\navailable in the CDS or CATS catalog collections. This fraction is 62 percent\nfor articles with over 100 sources. Surprisingly, these fractions are not\nbetter for articles published electronically since 2001, perhaps partly due to\nthe fact that often tabular data are published in formats not useful for direct\nmachine reading. The databases Simbad and NED recognize only about 60 percent\nof the bibliographic references corresponding to the existing electronic radio\nsource lists, and the number of objects associated with these references is\nmuch smaller still. Both, object databases like NED and Simbad, as well as\ncatalog browsers (VizieR, CATS) need to be consulted to obtain the most\ncomplete information on radio sources. More human resources at the data centers\nand better collaboration between authors, referees, editors, publishers, and\ndata centers are required to improve the flow of tabular data from journals to\npublic databases. Current efforts within the Virtual Observatory (VO) project,\nto provide retrieval and analysis tools for different types of published and\narchival data stored at various sites, should be balanced by an equal effort to\nrecover and include large amounts of published data not currently available in\nthis way. If human resources can be found, the data sets collected by the\nauthor will be made available for the preparation of metadata necessary for\ntheir ingression into catalog browsers. \n\n"}
{"id": "0909.5439", "contents": "Title: Analysis of galaxy SEDs from far-UV to far-IR with CIGALE: Studying a\n  SINGS test sample Abstract: Photometric data of galaxies covering the rest-frame wavelength range from\nfar-UV to far-IR make it possible to derive galaxy properties with a high\nreliability by fitting the attenuated stellar emission and the related dust\nemission at the same time. For this purpose we wrote the code CIGALE (Code\nInvestigating GALaxy Emission) that uses model spectra composed of the Maraston\n(or PEGASE) stellar population models, synthetic attenuation functions based on\na modified Calzetti law, spectral line templates, the Dale & Helou dust\nemission models, and optional spectral templates of obscured AGN. Depending on\nthe input redshifts, filter fluxes are computed for the model set and compared\nto the galaxy photometry by carrying out a Bayesian-like analysis. CIGALE was\ntested by analysing 39 nearby galaxies selected from SINGS. The reliability of\nthe different model parameters was evaluated by studying the resulting\nexpectation values and their standard deviations in relation to the input model\ngrid. Moreover, the influence of the filter set and the quality of photometric\ndata on the code results was estimated. For up to 17 filters between 0.15 and\n160 mum, we find robust results for the mass, star formation rate, effective\nage of the stellar population at 4000 A, bolometric luminosity, luminosity\nabsorbed by dust, and attenuation in the far-UV. A study of the mutual\nrelations between the reliable properties confirms the dependence of star\nformation activity on morphology in the local Universe and indicates a\nsignificant drop in this activity at about 10^11 M_sol towards higher total\nstellar masses. The dustiest sample galaxies are present in the same mass\nrange. [abridged] \n\n"}
{"id": "0910.0240", "contents": "Title: Black holes and neutron stars in the generalized tensor-vector-scalar\n  theory Abstract: Bekenstein's Tensor-Vector-Scalar (TeVeS) theory has had considerable success\nas a relativistic theory of Modified Newtonian Dynamics (MoND). However, recent\nwork suggests that the dynamics of the theory are fundamentally flawed and\nnumerous authors have subsequently begun to consider a generalization of TeVeS\nwhere the vector field is given by an Einstein-Aether action. Herein, I develop\nstrong-field solutions of the generalized TeVeS theory, in particular exploring\nneutron stars as well as neutral and charged black holes. I find that the\nsolutions are identical to the neutron star and black hole solutions of the\noriginal TeVeS theory, given a mapping between the parameters of the two\ntheories, and hence provide constraints on these values of the coupling\nconstants. I discuss the consequences of these results in detail including the\nstability of such spacetimes as well as generalizations to more complicated\ngeometries. \n\n"}
{"id": "0910.0254", "contents": "Title: Detection of IMBHs with ground-based gravitational wave observatories: A\n  biography of a binary of black holes, from birth to death Abstract: Even though the existence of intermediate-mass black holes (IMBHs, black\nholes with masses ranging between $10^{2-4}\\,M_{\\odot}$) has not yet been\ncorroborated observationally, these objects are of high interest for\nastrophysics. Our understanding of the formation and evolution of supermassive\nblack holes (SMBHs), as well as galaxy evolution modeling and cosmography would\ndramatically change if an IMBH were to be observed. From a point of view of\ntraditional photon-based astronomy, {which relies on the monitoring of\ninnermost stellar kinematics}, the {\\em direct} detection of an IMBH seems to\nbe rather far in the future. However, the prospect of the detection and\ncharacterization of an IMBH has good chances in lower-frequency\ngravitational-wave (GW) astrophysics using ground-based detectors such as LIGO,\nVirgo and the future Einstein Telescope (ET). We present an analysis of the\nsignal of a system of a binary of IMBHs (BBH from now onwards) based on a\nwaveform model obtained with numerical relativity simulations coupled with\npost-Newtonian calculations at the highest available order. IMBH binaries with\ntotal masses between $200-20000\\,M_\\odot$ would produce significant\nsignal-to-noise ratios (SNRs) in advanced LIGO and Virgo and the ET. We have\ncomputed the expected event rate of IMBH binary coalescences for different\nconfigurations of the binary, finding interesting values that depend on the\nspin of the IMBHs. The prospects for IMBH detection and characterization with\nground-based GW observatories would not only provide us with a robust test of\ngeneral relativity, but would also corroborate the existence of these systems.\nSuch detections should allow astrophysicists to probe the stellar environments\nof IMBHs and their formation processes. \n\n"}
{"id": "0910.0434", "contents": "Title: Jumping from Metric f(R) to Scalar-Tensor Theories and the relations\n  between their post-Newtonian Parameters Abstract: We review the dynamical equivalence between $f(R)$ gravity in the metric\nformalism and scalar-tensor gravity, and use this equivalence to deduce the\npost-Newtonian parameters $\\gamma$ and $\\beta$ for a $f(R)$ theory, obtaining a\nresult that is different with respect to that known in the literature. Then, we\nobtain explicit expressions of these paremeters in terms of the mass of the\nscalar field (or, differently speaking, the mass of the additional scalar\ndegree of freedom associated to a $f(R)$ theory) which can be used to constrain\n$f(R)$ gravity by means of current observations. \n\n"}
{"id": "0910.0482", "contents": "Title: A statistical test of emission from unresolved point sources Abstract: We describe a simple test of the spatial uniformity of an ensemble of\ndiscrete events. Given an estimate for the point source luminosity function and\nan instrumental point spread function (PSF), a robust upper bound on the\nfractional point source contribution to a diffuse signal can be found. We\nverify with Monte Carlo tests that the statistic has advantages over the\ntwo-point correlation function for this purpose, and derive analytic estimates\nof the statistic's mean and variance as a function of the point source\ncontribution. As a case study, we apply this statistic to recent gamma-ray data\nfrom the Fermi Large Area Telescope (LAT), and demonstrate that at energies\nabove 10 GeV, the contribution of unresolved point sources to the diffuse\nemission is small in the region relevant for study of the WMAP Haze. \n\n"}
{"id": "0910.1533", "contents": "Title: Challenges in Stellar Population Studies Abstract: The stellar populations of galaxies contain a wealth of detailed information.\n  From the youngest, most massive stars, to almost invisible remnants, the\nhistory of star formation is encoded in the stars that make up a galaxy.\nExtracting some, or all, of this informationhas long been a goal of stellar\npopulation studies. This was achieved in the last couple of decades and it is\nnow a routine task, which forms a crucial ingredient in much of observational\ngalaxy evolution, from our Galaxy out to the most distant systems found. In\nmany of these domains we are now limited not by sample size, but by systematic\nuncertainties and this will increasingly be the case in the future.\n  The aim of this review is to outline the challenges faced by stellar\npopulation studies in the coming decade within the context of upcoming\nobservational facilities. I will highlight the need to better understand the\nnear-IR spectral range and outline the difficulties presented by less well\nunderstood phases of stellar evolution such as thermally pulsing AGB stars,\nhorizontal branch stars and the very first stars. The influence of rotation and\nbinarity on stellar population modeling is also briefly discussed. \n\n"}
{"id": "0910.1587", "contents": "Title: Triplets of supermassive black holes: Astrophysics, Gravitational Waves\n  and Detection Abstract: Supermassive black holes (SMBHs) found in the centers of many galaxies have\nbeen recognized to play a fundamental active role in the cosmological structure\nformation process. In hierarchical formation scenarios, SMBHs are expected to\nform binaries following the merger of their host galaxies. If these binaries do\nnot coalesce before the merger with a third galaxy, the formation of a black\nhole triple system is possible. Numerical simulations of the dynamics of\ntriples within galaxy cores exhibit phases of very high eccentricity (as high\nas $e \\sim 0.99$). During these phases, intense bursts of gravitational\nradiation can be emitted at orbital periapsis. This produces a gravitational\nwave signal at frequencies substantially higher than the orbital frequency. The\nlikelihood of detection of these bursts with pulsar timing and the Laser\nInterferometer Space Antenna ({\\it LISA}) is estimated using several population\nmodels of SMBHs with masses $\\gtrsim 10^7 {\\rm M_\\odot}$. Assuming a fraction\nof binaries $\\ge 0.1$ in triple system, we find that few to few dozens of these\nbursts will produce residuals $>1$ ns, within the sensitivity range of\nforthcoming pulsar timing arrays (PTAs). However, most of such bursts will be\nwashed out in the underlying confusion noise produced by all the other\n'standard' SMBH binaries emitting in the same frequency window. A detailed data\nanalysis study would be required to assess resolvability of such sources.\nImplementing a basic resolvability criterion, we find that the chance of\ncatching a resolvable burst at a one nanosecond precision level is 2-50%,\ndepending on the adopted SMBH evolution model. On the other hand, the\nprobability of detecting bursts produced by massive binaries (masses $\\gtrsim\n10^7\\msun$) with {\\it LISA} is negligible. \n\n"}
{"id": "0910.1591", "contents": "Title: Stellar mass-to-light ratios from galaxy spectra: how accurate can they\n  be? Abstract: Stellar masses play a crucial role in the exploration of galaxy properties\nand the evolution of the galaxy population. In this paper, we explore the\nminimum possible uncertainties in stellar mass-to-light (M/L) ratios from the\nassumed star formation history (SFH) and metallicity distribution, with the\ngoals of providing a minimum set of requirements for observational studies. We\nuse a large Monte Carlo library of SFHs to study as a function of galaxy\nspectral type and signal-to-noise ratio (S/N) the statistical uncertainties of\nM/L values using either absorption-line data or broad band colors. The accuracy\nof M/L estimates can be significantly improved by using metal-sensitive indices\nin combination with age-sensitive indices, in particular for galaxies with\nintermediate-age or young stellar populations. While M/L accuracy clearly\ndepends on the spectral S/N ratio, there is no significant gain in improving\nthe S/N much above 50/pix and limiting uncertainties of 0.03 dex are reached.\nAssuming that dust is accurately corrected or absent and that the redshift is\nknown, color-based M/L estimates are only slightly more uncertain than\nspectroscopic estimates (at comparable spectroscopic and photometric quality),\nbut are more easily affected by systematic biases. This is the case in\nparticular for galaxies with bursty SFHs (high Hdelta at fixed D4000), the M/L\nof which cannot be constrained any better than 0.15 dex with any indicators\nexplored here. Finally, we explore the effects of the assumed prior\ndistribution in SFHs and metallicity, finding them to be higher for color-based\nestimates. \n\n"}
{"id": "0910.1741", "contents": "Title: Duality on gradient estimates and Wasserstein controls Abstract: We establish a duality between L^p-Wasserstein control and L^q-gradient\nestimate in a general framework. Our result extends a known result for a heat\nflow on a Riemannian manifold. Especially, we can derive a Wasserstein control\nof a heat flow directly from the corresponding gradient estimate of the heat\nsemigroup without using any other notion of lower curvature bound. By applying\nour result to a subelliptic heat flow on a Lie group, we obtain a coupling of\nheat distributions which carries a good control of their relative distance. \n\n"}
{"id": "0910.1792", "contents": "Title: Probing Yukawian Gravitational Potential by Numerical Simulations. II.\n  Elliptical Galaxies Abstract: Since the Newtonian gravitation is largely used to model with success the\nstructures of the universe, such as galaxies and clusters of galaxies, for\nexample, a way to probe and constrain alternative theories, in the weak field\nlimit, is to apply them to model the structures of the universe. We then\nmodified the well known Gadget-2 code to probe alternative theories of\ngravitation through galactic dynamics. In particular, we modified the Gadget-2\ncode to probe alternatives theories whose weak field limits have a Yukawa-like\ngravitational potential. As a first application of this modified Gadget-2 code\nwe simulate the evolution of elliptical galaxies. These simulations show that\ngalactic dynamics can be used to constrain the parameters associated with\nalternative theories of gravitation. \n\n"}
{"id": "0910.3039", "contents": "Title: Coherent oscillations between classically separable quantum states of a\n  superconducting loop Abstract: Ten years ago, coherent oscillations between two quantum states of a\nsuperconducting circuit differing by the presence or absence of a single Cooper\npair on a metallic island were observed for the first time. This result\nimmediately stimulated the development of several other types of\nsuperconducting quantum circuits behaving as artificial atoms, thus bridging\nmesoscopic and atomic physics. Interestingly, none of these circuits fully\nimplements the now almost 30 year old proposal of A. J. Leggett to observe\ncoherent oscillations between two states differing by the presence or absence\nof a single fluxon trapped in the superconducting loop interrupted by a\nJosephson tunnel junction. This phenomenon of reversible quantum tunneling\nbetween two classically separable states, known as Macroscopic Quantum\nCoherence (MQC), is regarded crucial for precision tests of whether macroscopic\nsystems such as circuits fully obey quantum mechanics. In this article, we\nreport the observation of such oscillations with sub-GHz frequency and quality\nfactor larger than 500. We achieved this result with two innovations. First,\nour ring has an inductance four orders of magnitude larger than that considered\nby Leggett, combined with a junction in the charging regime, a parameter choice\nnever addressed in previous experiments. Second, readout is performed with a\nnovel dispersive scheme which eliminates the electromagnetic relaxation process\ninduced by the measurement circuit (Purcell effect). Moreover, the reset of the\nsystem to its ground state is naturally built into this scheme, working even if\nthe transition energy is smaller than that of temperature fluctuations. As we\nargue, the MQC transition could therefore be, contrary to expectations, the\nbasis of a superconducting qubit of improved coherence and readout fidelity. \n\n"}
{"id": "0910.4152", "contents": "Title: Interruption of Tidal Disruption Flares By Supermassive Black Hole\n  Binaries Abstract: Supermassive black hole binaries (SMBHBs) are products of galaxy mergers, and\nare important in testing Lambda cold dark matter cosmology and locating\ngravitational-wave-radiation sources. A unique electromagnetic signature of\nSMBHBs in galactic nuclei is essential in identifying the binaries in\nobservations from the IR band through optical to X-ray. Recently, the flares in\noptical, UV, and X-ray caused by supermassive black holes (SMBHs) tidally\ndisrupting nearby stars have been successfully used to observationally probe\nsingle SMBHs in normal galaxies. In this Letter, we investigate the accretion\nof the gaseous debris of a tidally disrupted star by a SMBHB. Using both\nstability analysis of three-body systems and numerical scattering experiments,\nwe show that the accretion of stellar debris gas, which initially decays with\ntime $\\propto t^{-5/3}$, would stop at a time $T_{\\rm tr} \\simeq \\eta T_{\\rm\nb}$. Here, $\\eta \\sim0.25$ and $T_{\\rm b}$ is the orbital period of the SMBHB.\nAfter a period of interruption, the accretion recurs discretely at time $T_{\\rm\nr} \\simeq \\xi T_b$, where $\\xi \\sim 1$. Both $\\eta$ and $\\xi$ sensitively\ndepend on the orbital parameters of the tidally disrupted star at the tidal\nradius and the orbit eccentricity of SMBHB. The interrupted accretion of the\nstellar debris gas gives rise to an interrupted tidal flare, which could be\nused to identify SMBHBs in non-active galaxies in the upcoming transient\nsurveys. \n\n"}
{"id": "0910.4346", "contents": "Title: The INTEGRAL view of Gamma-Ray Bursts Abstract: After more than six and half years in orbit, the ESA space observatory\nINTEGRAL has provided new, exciting results in the soft gamma-ray energy range\n(from a few keV to a few MeV). With the discovery of about 700 hard X-Ray\nsources, it has changed our previous view of a sky composed of peculiar and\n``monster'' sources. The new high energy sky is in fact full of a large variety\nof normal, very energetic emitters, characterized by new accretion and\nacceleration processes (see also IBIS cat4, Bird et al. 2009). If compared to\nprevious IBIS/ISGRI surveys it is clear that there is a continual increase in\nthe rate of discoveries of HMXB and AGN, including a variety of distant QSOs.\nThis is basically due to increased exposure away from the Galactic Plane, while\nthe percentage of sources without an identification has remained constant. At\nthe same time, about one GRB/month is detected and imaged by the two main\ngamma-ray instruments on board: IBIS and SPI. INTEGRAL, after six and half\nyears of observations, has completed the Core Programme phase and is now fully\nopen to the scientific community for Open Time and Key Programme observations,\nwith AO7 recently announced by ESA. In this paper we review the major\nachievements of the INTEGRAL Observatory in the field of Gamma Ray Bursts. \n\n"}
{"id": "0910.4775", "contents": "Title: Hartree-Fock-Bogoliubov Theory of Dipolar Fermi Gases Abstract: We construct a fully self-consistent Hartree-Fock-Bogoliubov theory that\ndescribes a spinless Fermi gas with long-range interaction. We apply this\ntheory to a system of uniform dipolar fermionic polar molecules, which has\nattracted much attention recently, due to rapid experimental progress in\nachieving such systems. By calculating the anisotropic superfluid order\nparameter, and the critical temperature $T_{c}$, we show that, \"hign $T_c$\"\nsuperfluid can be achieved with a quite modest value of interaction strength\nfor polar molecules. In addition, we also show that the presence of the Fock\nexchange interaction enhances superfluid pairing. \n\n"}
{"id": "0910.4975", "contents": "Title: Resolved maps of stellar mass and SED of galaxies from optical/NIR\n  imaging and SPS models Abstract: We report on the method developed by Zibetti, Charlot and Rix (2009) to\nconstruct resolved stellar mass maps of galaxies from optical and NIR imaging.\nAccurate pixel-by-pixel colour information (specifically g-i and i-H) is\nconverted into stellar mass-to-light ratios with typical accuracy of 30%, based\non median likelihoods derived from a Monte Carlo library of 50,000 stellar\npopulation synthesis models that include dust and updated TP-AGB phase\nprescriptions. Hence, surface mass densities are computed. In a pilot study, we\nanalyze 9 galaxies spanning a broad range of morphologies. Among the main\nresults, we find that: i) galaxies appear much smoother in stellar mass maps\nthan at any optical or NIR wavelength; ii) total stellar mass estimates based\non unresolved photometry are biased low with respect to the integral of\nresolved stellar mass maps, by up to 40%, due to dust obscured regions being\nunder-represented in global colours; iii) within a galaxy, on local scales\ncolours correlate with surface stellar mass density; iv) the slope and\ntightness of this correlation reflect/depend on the morphology of the galaxy. \n\n"}
{"id": "0910.5007", "contents": "Title: A ground-based 21cm Baryon acoustic oscillation survey Abstract: Baryon acoustic oscillations (BAO) provide a robust standard ruler with which\nto measure the acceleration of the Universe. The BAO feature has so far been\ndetected in optical galaxy surveys. Intensity mapping of neutral hydrogen\nemission with a ground-based radio telescope provides another promising window\nfor measuring BAO at redshifts of order unity for relatively low cost. While\nthe cylindrical radio telescope (CRT) proposed for these measurements will have\nexcellent redshift resolution, it will suffer from poor angular resolution (a\nfew arcminutes at best). We investigate the effect of angular resolution on the\nstandard ruler test with BAO, using the Dark Energy Task Force Figure of Merit\nas a benchmark. We then extend the analysis to include variations in the\nparameters characterizing the telescope and the underlying physics. Finally, we\noptimize the survey parameters (holding total cost fixed) and present an\nexample of a CRT BAO survey that is competitive with Stage III dark energy\nexperiments. The tools developed here form the backbone of a publicly available\ncode that can be used to obtain estimates of cost and Figure of Merit for any\nset of parameters. \n\n"}
{"id": "0910.5480", "contents": "Title: Neutron Stars in f(R) Gravity with Perturbative Constraints Abstract: We study the structure of neutron stars in f(R) gravity theories with\nperturbative constraints. We derive the modified Tolman-Oppenheimer-Volkov\nequations and solve them for a polytropic equation of state. We investigate the\nresulting modifications to the masses and radii of neutron stars and show that\nobservations of surface phenomena alone cannot break the degeneracy between\naltering the theory of gravity versus choosing a different equation of state of\nneutron-star matter. On the other hand, observations of neutron-star cooling,\nwhich depends on the density of matter at the stellar interior, can place\nsignificant constraints on the parameters of the theory. \n\n"}
{"id": "0911.0729", "contents": "Title: The Physics and Mass Assembly of distant galaxies with the E-ELT Abstract: One of the main science goal of the future European Extremely Large Telescope\nwill be to understand the mass assembly process in galaxies as a function of\ncosmic time. To this aim, a multi-object, AO-assisted integral field\nspectrograph will be required to map the physical and chemical properties of\nvery distant galaxies. In this paper, we examine the ability of such an\ninstrument to obtain spatially resolved spectroscopy of a large sample of\nmassive (0.1<Mstellar<5e11Mo) galaxies at 2<z<6, selected from future large\narea optical-near IR surveys. We produced a set of about one thousand numerical\nsimulations of 3D observations using reasonable assumptions about the site,\ntelescope, and instrument, and about the physics of distant galaxies. These\ndata-cubes were analysed as real data to produce realistic kinematic\nmeasurements of very distant galaxies. We then studied how sensible the\nscientific goals are to the observational (i.e., site-, telescope-, and\ninstrument-related) and physical (i.e., galaxy-related) parameters. We\nspecifically investigated the impact of AO performance on the science goal. We\ndid not identify any breaking points with respect to the parameters (e.g., the\ntelescope diameter), with the exception of the telescope thermal background,\nwhich strongly limits the performance in the highest (z>5) redshift bin. We\nfind that a survey of Ngal galaxies that fulfil the range of science goals can\nbe achieved with a ~90 nights program on the E-ELT, provided a multiplex\ncapability M Ngal/8. \n\n"}
{"id": "0911.3437", "contents": "Title: Two Weight Inequalities for Discrete Positive Operators Abstract: We characterize two weight inequalities for general positive dyadic\noperators. We consider both weak and strong type inequalities, and general\n(p,q) mapping properties. Special cases include Sawyers Fractional Integral\noperator results from 1988, and the bilinear embedding inequality of\nNazarov-Treil-Volberg from 1999. The method of proof is an extension of\nSawyer's argument. \n\n"}
{"id": "0911.3820", "contents": "Title: Bayesian coherent analysis of in-spiral gravitational wave signals with\n  a detector network Abstract: The present operation of the ground-based network of gravitational-wave laser\ninterferometers in \"enhanced\" configuration brings the search for gravitational\nwaves into a regime where detection is highly plausible. The development of\ntechniques that allow us to discriminate a signal of astrophysical origin from\ninstrumental artefacts in the interferometer data and to extract the full range\nof information are some of the primary goals of the current work. Here we\nreport the details of a Bayesian approach to the problem of inference for\ngravitational wave observations using a network of instruments, for the\ncomputation of the Bayes factor between two hypotheses and the evaluation of\nthe marginalised posterior density functions of the unknown model parameters.\nThe numerical algorithm to tackle the notoriously difficult problem of the\nevaluation of large multi-dimensional integrals is based on a technique known\nas Nested Sampling, which provides an attractive alternative to more\ntraditional Markov-chain Monte Carlo (MCMC) methods. We discuss the details of\nthe implementation of this algorithm and its performance against a Gaussian\nmodel of the background noise, considering the specific case of the signal\nproduced by the in-spiral of binary systems of black holes and/or neutron\nstars, although the method is completely general and can be applied to other\nclasses of sources. We also demonstrate the utility of this approach by\nintroducing a new coherence test to distinguish between the presence of a\ncoherent signal of astrophysical origin in the data of multiple instruments and\nthe presence of incoherent accidental artefacts, and the effects on the\nestimation of the source parameters as a function of the number of instruments\nin the network. \n\n"}
{"id": "0911.3901", "contents": "Title: GRB 090313: X-shooter's first shot at a GRB Abstract: Context. X-shooter is the first second-generation instrument to become\noperative at the ESO Very Large Telescope (VLT). It is a broad-band\nmedium-resolution spectrograph designed with gamma-ray burst (GRB) afterglow\nspectroscopy as one of its main science drivers.\n  Aims. During the first commissioning night on sky with the instrument fully\nassembled, X-shooter observed the afterglow of GRB 090313 as a demonstration of\nthe instrument's capabilities.\n  Methods. GRB 090313 was observed almost two days after the burst onset, when\nthe object had already faded to R~21.6. Furthermore, the 90% illuminated Moon\nwas just 30 degrees away from the field. In spite of the adverse conditions, we\nobtained a spectrum that, for the first time in GRB research, covers\nsimultaneously the range from 5700 to 23000 Angstroms.\n  Results. The spectrum shows multiple absorption features at a redshift of\n3.3736, the redshift of the GRB. These features are composed of 3 components\nwith different ionisation levels and velocities. Some of the features have\nnever been observed before in a GRB at such a high redshift. Furthermore, we\ndetect two intervening systems at redshifts of 1.8005 and 1.9597.\n  Conclusions. These results demonstrate the potential of X-shooter in the GRB\nfield, as it was capable of observing a GRB down to a magnitude limit that\nwould include 72% of long GRB afterglows 2 hours after the burst onset. Coupled\nwith the rapid response mode available at VLT, allowing reaction times of just\na few minutes, X-shooter constitutes an important leap forward on medium\nresolution spectroscopic studies of GRBs, their host galaxies and intervening\nsystems, probing the early history of the Universe. \n\n"}
{"id": "0911.4512", "contents": "Title: Keck constraints on a varying fine-structure constant: wavelength\n  calibration errors Abstract: The Keck telescope's HIRES spectrograph has previously provided evidence for\na smaller fine-structure constant, alpha, compared to the current laboratory\nvalue, in a sample of 143 quasar absorption systems:\nda/a=(-0.57+/-0.11)x10^{-5}. This was based on a variety of metal-ion\ntransitions which, if alpha varies, experience different relative velocity\nshifts. This result is yet to be robustly contradicted, or confirmed, by\nmeasurements on other telescopes and spectrographs; it remains crucial to do\nso. It is also important to consider new possible instrumental systematic\neffects which may explain the Keck/HIRES results. Griest et al. (2009,\narXiv:0904.4725v1) recently identified distortions in the echelle order\nwavelength scales of HIRES with typical amplitudes +/-250m/s. Here we\ninvestigate the effect such distortions may have had on the Keck/HIRES varying\nalpha results. We demonstrate that they cause a random effect on da/a from\nabsorber to absorber because the systems are at different redshifts, placing\nthe relevant absorption lines at different positions in different echelle\norders. The typical magnitude of the effect on da/a is ~0.4x10^{-5} per\nabsorber which, compared to the median error on da/a in the sample,\n~1.9x10^{-5}, is relatively small. Consequently, the weighted mean value\nchanges by less than 0.05x10^{-5} if the corrections we calculate are applied.\nNevertheless, we urge caution, particularly for analyses aiming to achieve high\nprecision da/a measurements on individual systems or small samples, that a much\nmore detailed understanding of such intra-order distortions and their\ndependence on observational parameters is important if they are to be avoided\nor modelled reliably. [Abridged] \n\n"}
{"id": "0911.4829", "contents": "Title: Time Delays in the Gravitationally Lensed Quasar H1413+117 (Cloverleaf) Abstract: The quadruple quasar H1413+117 (z_s = 2.56) has been monitored with the 2.0 m\nLiverpool Telescope in the r Sloan band from 2008 February to July. This\noptical follow-up leads to accurate light curves of the four quasar images\n(A-D), which are defined by 33 epochs of observation and an average photometric\nerror of \\sim 15 mmag. We then use the observed (intrinsic) variations of \\sim\n50-100 mmag to measure the three time delays for the lens system for the first\ntime (1\\sigma confidence intervals): \\Delta \\tau_{AB} = -17 +/- 3, \\Delta\n\\tau_{AC} = -20 +/- 4, and \\Delta \\tau_{AD} = 23 +/- 4 days (\\Delta \\tau_{ij} =\n\\tau_j - \\tau_i; B and C are leading, while D is trailing). Although time\ndelays for lens systems are often used to obtain the Hubble constant (H_0), the\nunavailability of the spectroscopic lens redshift (z_l) in the system H1413+117\nprevents a determination of H_0 from the measured delays. In this paper, the\nnew time delay constraints and a concordance expansion rate (H_0 = 70 km s^{-1}\nMpc^{-1}) allow us to improve the lens model and to estimate the previously\nunknown z_l. Our 1\\sigma estimate z_l = 1.88^{+0.09}_{-0.11} is an example of\nhow to infer the redshift of very distant galaxies via gravitational lensing. \n\n"}
{"id": "0911.4955", "contents": "Title: Observational constraints on light cosmic strings from photometry and\n  pulsar timing Abstract: We constrain the cosmological density of cosmic string loops using two\nobservational signatures -- gravitational microlensing and the Kaiser-Stebbins\neffect. Photometry from RXTE and CoRoT space missions and pulsar timing from\nParkes Pulsar Timing Array, Arecibo and Green Bank radio telescopes allow us to\nprobe cosmic strings in a wide range of tensions\n$G\\mu/c^2=10^{-16}\\div10^{-10}$. We find that pulsar timing data provide the\nmost stringent constraints on the abundance of light strings at the level\n$\\Omega_s \\sim 10^{-3}$. Future observational facilities such as the Square\nKilometer Array will allow one to improve these constraints by orders of\nmagnitude. \n\n"}
{"id": "0911.4967", "contents": "Title: Galaxy rotation curves from General Relativity with Renormalization\n  Group corrections Abstract: We consider the application of quantum corrections computed using\nrenormalization group arguments in the astrophysical domain and show that, for\nthe most natural interpretation of the renormalization group scale parameter, a\ngravitational coupling parameter $G$ varying $10^{-7}$ of its value across a\ngalaxy (which is roughly a variation of $10^{-12}$ per light-year) is\nsufficient to generate galaxy rotation curves in agreement with the\nobservations. The quality of the resulting fit is similar to the Isothermal\nprofile quality once both the shape of the rotation curve and the mass-to-light\nratios are considered for evaluation. In order to perform the analysis, we use\nrecent high quality data from nine regular disk galaxies. For the sake of\ncomparison, the same set of data is modeled also for the Modified Newtonian\nDynamics (MOND) and for the recently proposed Scalar Tensor Vector Gravity\n(STVG). At face value, the model based on quantum corrections clearly leads to\nbetter fits than these two alternative theories. \n\n"}
{"id": "0911.5056", "contents": "Title: The Planck On-Flight Forecaster (POFF) Abstract: The Planck On-Fligh Forecaster (POFF) is a tool to predict when a position in\nthe sky will be within a selected angular distance from any receiver direction\nof the Planck satellite according to its pre-programmed observational strategy.\nThis tool has been developed in the framework of the Planck LFI Core Team\nactivities, but it is now used by the whole collaboration. In this paper we\nwill describe the tool and its applications to plan observations with other\ninstruments of point sources which are expected to enhance the possibilities of\nscientific exploitation of the Planck satellite data, once they will be\npublicly available. Collecting simultaneous multi-frequency data, like those\nthat can be planned with the POFF, will help, on one hand, to investigate\nvariability of point sources and, on the other, to reconstruct point source\nspectral energy distributions on wide frequency ranges minimizing the effects\ndue to source variability. POFF is a combination of IDL routines which combine\nthe publicly available information about the Planck scanning strategy and focal\nplane shape in order to identify if a given (list of) position(s) can be\nobservable by the satellite at a given frequency and/or by selected receivers\nin a given time range. The output can be displayed with the desired time\nresolution and selecting among various sorting options. The code is not a\nPlanck product, but it has been validated within the Planck LFI pipeline. The\ncode format and the large number of options make it flexible and suitable for\nmany applications, allowing to get results quickly. POFF is currently\nsuccessfully used to plan activities within the Planck collaboration, including\nobservations with several ground-based facilities, and it is distributed\noutside it. \n\n"}
{"id": "0912.0482", "contents": "Title: Status of the LUX Dark Matter Search Abstract: The Large Underground Xenon (LUX) dark matter search experiment is currently\nbeing deployed at the Homestake Laboratory in South Dakota. We will highlight\nthe main elements of design which make the experiment a very strong competitor\nin the field of direct detection, as well as an easily scalable concept. We\nwill also present its potential reach for supersymmetric dark matter detection,\nwithin various timeframes ranging from 1 year to 5 years or more. \n\n"}
{"id": "0912.0490", "contents": "Title: Mathematics of Gravitational Lensing: Multiple Imaging and Magnification Abstract: The mathematical theory of gravitational lensing has revealed many generic\nand global properties. Beginning with multiple imaging, we review\nMorse-theoretic image counting formulas and lower bound results, and\ncomplex-algebraic upper bounds in the case of single and multiple lens planes.\nWe discuss recent advances in the mathematics of stochastic lensing, discussing\na general formula for the global expected number of minimum lensed images as\nwell as asymptotic formulas for the probability densities of the microlensing\nrandom time delay functions, random lensing maps, and random shear, and an\nasymptotic expression for the global expected number of micro-minima. Multiple\nimaging in optical geometry and a spacetime setting are treated. We review\nglobal magnification relation results for model-dependent scenarios and cover\nrecent developments on universal local magnification relations for higher order\ncaustics. \n\n"}
{"id": "0912.1074", "contents": "Title: Compact Binary Coalescences in the Band of Ground-based\n  Gravitational-Wave Detectors Abstract: As the ground-based gravitational-wave telescopes LIGO, Virgo, and GEO 600\napproach the era of first detections, we review the current knowledge of the\ncoalescence rates and the mass and spin distributions of merging neutron-star\nand black-hole binaries. We emphasize the bi-directional connection between\ngravitational-wave astronomy and conventional astrophysics. Astrophysical input\nwill make possible informed decisions about optimal detector configurations and\nsearch techniques. Meanwhile, rate upper limits, detected merger rates, and the\ndistribution of masses and spins measured by gravitational-wave searches will\nconstrain astrophysical parameters through comparisons with astrophysical\nmodels. Future developments necessary to the success of gravitational-wave\nastronomy are discussed. \n\n"}
{"id": "0912.1196", "contents": "Title: EDELWEISS-II Dark Matter Search : status and first results Abstract: The EDELWEISS II experiment is devoted to the search for Weakly Interacting\nMassive Particles (WIMP) that would constitute the Dark Matter halo of our\nGalaxy. For this purpose, the experiment uses cryogenic germanium detectors,\ncooled down at 20 mK, in which the collision of a WIMP with an atomic nucleus\nproduces characteristic signals in terms of ionization and elevation of\ntemperature. We will present the preliminary results of the first operation of\nthe detectors installed in the underground laboratory of the Frejus Tunnel\n(LSM), attesting to the very low radioactive background conditions achieved so\nfar. New detectors, with a special electrode design for active rejection of\nsurface events, have been shown to be suited for searches of WIMPs with\nscattering cross-sections on nucleon well below 10-8 pb. Preliminary results of\nWIMP search performed with a first set of these detectors are presented. \n\n"}
{"id": "0912.1786", "contents": "Title: EvoL: The new Padova T-SPH parallel code for cosmological simulations -\n  I. Basic code: gravity and hydrodynamics Abstract: We present EvoL, the new release of the Padova N-body code for cosmological\nsimulations of galaxy formation and evolution. In this paper, the basic Tree +\nSPH code is presented and analysed, together with an overview on the software\narchitectures. EvoL is a flexible parallel Fortran95 code, specifically\ndesigned for simulations of cosmological structure formation on cluster,\ngalactic and sub-galactic scales. EvoL is a fully Lagrangian self-adaptive\ncode, based on the classical Oct-tree and on the Smoothed Particle\nHydrodynamics algorithm. It includes special features such as adaptive\nsoftening lengths with correcting extra-terms, and modern formulations of SPH\nand artificial viscosity. It is designed to be run in parallel on multiple CPUs\nto optimize the performance and save computational time. We describe the code\nin detail, and present the results of a number of standard hydrodynamical\ntests. \n\n"}
{"id": "0912.2341", "contents": "Title: A Method for Individual Source Brightness Estimation in Single- and\n  Multi-band Data Abstract: We present a method of reliably extracting the flux of individual sources\nfrom sky maps in the presence of noise and a source population in which number\ncounts are a steeply falling function of flux. The method is an extension of a\nstandard Bayesian procedure in the millimeter/submillimeter literature. As in\nthe standard method, the prior applied to source flux measurements is derived\nfrom an estimate of the source counts as a function of flux, dN/dS. The key\nfeature of the new method is that it enables reliable extraction of properties\nof individual sources, which previous methods in the literature do not. We\nfirst present the method for extracting individual source fluxes from data in a\nsingle observing band, then we extend the method to multiple bands, including\nprior information about the spectral behavior of the source population(s). The\nmulti-band estimation technique is particularly relevant for classifying\nindividual sources into populations according to their spectral behavior. We\nfind that proper treatment of the correlated prior information between\nobserving bands is key to avoiding significant biases in estimations of\nmulti-band fluxes and spectral behavior, biases which lead to significant\nnumbers of misclassified sources. We test the single- and multi-band versions\nof the method using simulated observations with observing parameters similar to\nthat of the South Pole Telescope data used in Vieira, et al. (2010). \n\n"}
{"id": "0912.2345", "contents": "Title: Filling the disk hollow following binary black hole merger: The\n  transient accretion afterglow Abstract: Tidal torques from a binary black hole (BHBH) empty out the central regions\nin any circumbinary gaseous accretion disk. The balance between tidal torques\nand viscosity maintain the inner edge of the disk at a radius r ~ 1.5a -- 2a,\nwhere a is the binary semimajor axis. Eventually, the inspiraling binary\ndecouples from disk and merges, leaving behind a central hollow (\"donut hole\")\nin the disk orbiting the remnant black hole. We present a simple,\ntime-dependent, Newtonian calculation that follows the secular (viscous)\nevolution of the disk as it fills up the hollow down to the black hole\ninnermost stable circular orbit and then relaxes to stationary equilibrium. We\nuse our model to calculate the electromagnetic radiation (\"afterglow\") spectrum\nemitted during this transient accretion epoch. Observing the temporal increase\nin the total electromagnetic flux and the hardening of the spectrum as the\ndonut hole fills may help confirm a BHBH merger detected by a gravitational\nwave interferometer. We show how the very existence of the initial hollow can\nlead to super-Eddington accretion during this secular phase if the rate is not\nvery far below Eddington prior to decoupling. Our model, though highly\nidealized, may be useful in establishing some of the key parameters, thermal\nemission features and scalings that characterize this transient. It can serve\nas a guide in the design and calibration of future\nradiation-magnetohydrodynamic simulations in general relativity. \n\n"}
{"id": "0912.2405", "contents": "Title: Self-shielding effect of a single phase liquid xenon detector for direct\n  dark matter search Abstract: Liquid xenon is a suitable material for a dark matter search. For future\nlarge scale experiments, single phase detectors are attractive due to their\nsimple configuration and scalability. However, in order to reduce backgrounds,\nthey need to fully rely on liquid xenon's self-shielding property. A prototype\ndetector was developed at Kamioka Observatory to establish vertex and energy\nreconstruction methods and to demonstrate the self-shielding power against\ngamma rays from outside of the detector. Sufficient self-shielding power for\nfuture experiments was obtained. \n\n"}
{"id": "0912.2738", "contents": "Title: Fast and precise map-making for massively multi-detector CMB experiments Abstract: Future cosmic microwave background (CMB) polarisation experiments aim to\nmeasure an unprecedentedly small signal - the primordial gravity wave component\nof the polarisation field B-mode. To achieve this, they will analyse huge\ndatasets, involving years worth of time-ordered data (TOD) from massively\nmulti-detector focal planes. This creates the need for fast and precise methods\nto complement the M-L approach in analysis pipelines. In this paper, we\ninvestigate fast map-making methods as applied to long duration, massively\nmulti-detector, ground-based experiments, in the context of the search for\nB-modes. We focus on two alternative map-making approaches: destriping and TOD\nfiltering, comparing their performance on simulated multi-detector polarisation\ndata. We have written an optimised, parallel destriping code, the DEStriping\nCARTographer DESCART, that is generalised for massive focal planes, including\nthe potential effect of cross-correlated TOD 1/f noise. We also determine the\nscaling of computing time for destriping as applied to a simulated full-season\ndata-set for a realistic experiment. We find that destriping can out-perform\nfiltering in estimating both the large-scale E and B-mode angular power\nspectra. In particular, filtering can produce significant spurious B-mode power\nvia EB mixing. Whilst this can be removed, it contributes to the variance of\nB-mode bandpower estimates at scales near the primordial B-mode peak. For the\nexperimental configuration we simulate, this has an effect on the possible\ndetection significance for primordial B-modes. Destriping is a viable\nalternative fast method to the full M-L approach that does not cause the\nproblems associated with filtering, and is flexible enough to fit into both M-L\nand Monte-Carlo pseudo-Cl pipelines. \n\n"}
{"id": "0912.4029", "contents": "Title: PKS 1502+106: a new and distant gamma-ray blazar in outburst discovered\n  by the Fermi Large Area Telescope Abstract: The Large Area Telescope (LAT) on board the Fermi Gamma-ray Space Telescope\ndiscovered a rapid (about 5 days duration), high-energy (E >100 MeV) gamma-ray\noutburst from a source identified with the blazar PKS 1502+106 (OR 103, S3\n1502+10, z=1.839) starting on August 05, 2008 and followed by bright and\nvariable flux over the next few months. Results on the gamma-ray localization\nand identification, as well as spectral and temporal behavior during the first\nmonths of the Fermi all-sky survey are reported here in conjunction with a\nmulti-waveband characterization as a result of one of the first Fermi\nmulti-frequency campaigns. The campaign included a Swift ToO (followed up by\n16-day observations on August 07-22, MJD 54685-54700), VLBA (within the MOJAVE\nprogram), Owens Valley (OVRO) 40m, Effelsberg-100m, Metsahovi-14m, RATAN-600\nand Kanata-Hiroshima radio/optical observations. Results from the analysis of\narchival observations by INTEGRAL, XMM-Newton and Spitzer space telescopes are\nreported for a more complete picture of this new gamma-ray blazar. \n\n"}
{"id": "0912.4038", "contents": "Title: Radio Tests of GR Abstract: Since VLBI techniques give microarcsecond position accuracy of celestial\nobjects, tests of GR using radio sources as probes of a gravitational field\nhave been made. We present the results from two recent tests using the VLBA: In\n2005, the measurement of the classical solar deflection; and in 2002, the\nmeasurement of the retarded gravitational deflection associated with Jupiter.\nThe deflection experiment measured PPN-gamma to an accuracy of 0.0003; the\nJupiter experiment measured the retarded term to 20% accuracy. The controversy\nover the interpretation of the retarded term is summarized. \n\n"}
{"id": "0912.4059", "contents": "Title: Application of XFaster power spectrum and likelihood estimator to Planck Abstract: We develop the XFaster Cosmic Microwave Background (CMB) temperature and\npolarization anisotropy power spectrum and likelihood technique for the Planck\nCMB satellite mission. We give an overview of this estimator and its current\nimplementation and present the results of applying this algorithm to simulated\nPlanck data. We show that it can accurately extract the power spectrum of\nPlanck data for the high-l multipoles range. We compare the XFaster\napproximation for the likelihood to other high-l likelihood approximations such\nas Gaussian and Offset Lognormal and a low-l pixel-based likelihood. We show\nthat the XFaster likelihood is not only accurate at high-l, but also performs\nwell at moderately low multipoles. We also present results for cosmological\nparameter Markov Chain Monte Carlo estimation with the XFaster likelihood. As\nlong as the low-l polarization and temperature power are properly accounted\nfor, e.g., by adding an adequate low-l likelihood ingredient, the input\nparameters are recovered to a high level of accuracy. \n\n"}
{"id": "0912.4405", "contents": "Title: Measuring dark matter by modeling interacting galaxies Abstract: The dark matter content of galaxies is usually determined from galaxies in\ndynamical equilibrium, mainly from rotationally supported galactic components.\nSuch determinations restrict measurements to special regions in galaxies, e.g.\nthe galactic plane(s), whereas other regions are not probed at all. Interacting\ngalaxies offer an alternative, because extended tidal tails often probe outer\nor off-plane regions of galaxies. However, these systems are neither in\ndynamical equilibrium nor simple, because they are composed of two or more\ngalaxies, by this increasing the associated parameter space.We present our\ngenetic algorithm based modeling tool which allows to investigate the extended\nparameter space of interacting galaxies. From these studies, we derive the\ndynamical history of (well observed) galaxies. Among other parameters we\nconstrain the dark matter content of the involved galaxies. We demonstrate the\napplicability of this strategy with examples ranging from stellar streams\naround theMilkyWay to extended tidal tails, from proto-typical binary galaxies\n(like M51 or the Antennae system) to small group of galaxies. \n\n"}
{"id": "0912.5531", "contents": "Title: Parameter estimation on gravitational waves from multiple coalescing\n  binaries Abstract: Future ground-based and space-borne interferometric gravitational-wave\ndetectors may capture between tens and thousands of binary coalescence events\nper year. There is a significant and growing body of work on the estimation of\nastrophysically relevant parameters, such as masses and spins, from the\ngravitational-wave signature of a single event. This paper introduces a robust\nBayesian framework for combining the parameter estimates for multiple events\ninto a parameter distribution of the underlying event population. The framework\ncan be readily deployed as a rapid post-processing tool. \n\n"}
{"id": "1001.1484", "contents": "Title: Clues from nearby galaxies to a better theory of cosmic evolution Abstract: The great advances in the network of cosmological tests show that the\nrelativistic Big Bang theory is a good description of our expanding universe.\nBut the properties of nearby galaxies that can be observed in greatest detail\nsuggest a still better theory would more rapidly gather matter into galaxies\nand groups of galaxies. This happens in theoretical ideas now under discussion. \n\n"}
{"id": "1001.2265", "contents": "Title: An S4 model for quarks and leptons with maximal atmospheric angle Abstract: We consider a model for quark and lepton masses and mixings based on S4\nflavor symmetry. The model contains six Higgs doublets where three of them give\nmass to the leptons and the other three gives mass to the quarks. Charged\nfermion and quark masses arise from renormalizable interactions while neutrino\nMajorana masses are generated through effective dimension five Weinberg\noperator. From the study of the minimization of the scalar potential we found a\nresidual mu-tau symmetry in the neutrino sector predicting zero reactor angle\nand maximal atmospheric angle and for the quark sector we found a four-zero\ntexture. We give a fit of the mass hierarchies and mixing angles in the quark\nsector. \n\n"}
{"id": "1001.2583", "contents": "Title: Unraveling Binary Evolution from Gravitational-Wave Signals and Source\n  Statistics Abstract: The next generation of ground-based gravitational-wave detectors are likely\nto observe gravitational waves from the coalescences of compact-objects\nbinaries. We describe the state of the art for predictions of the rate of\ncompact-binary coalescences and report on initial efforts to develop a\nframework for converting gravitational-wave observations into improved\nconstraints on astrophysical parameters. \n\n"}
{"id": "1001.2657", "contents": "Title: Planck pre-launch status: the Planck-LFI programme Abstract: This paper provides an overview of the Low Frequency Instrument (LFI)\nprogramme within the ESA Planck mission. The LFI instrument has been developed\nto produce high precision maps of the microwave sky at frequencies in the range\n27-77 GHz, below the peak of the cosmic microwave background (CMB) radiation\nspectrum. The scientific goals are described, ranging from fundamental\ncosmology to Galactic and extragalactic astrophysics. The instrument design and\ndevelopment are outlined, together with the model philosophy and testing\nstrategy. The instrument is presented in the context of the Planck mission. The\nLFI approach to ground and inflight calibration is described. We also describe\nthe LFI ground segment. We present the results of a number of tests\ndemonstrating the capability of the LFI data processing centre (DPC) to\nproperly reduce and analyse LFI flight data, from telemetry information to\ncalibrated and cleaned time ordered data, sky maps at each frequency (in\ntemperature and polarization), component emission maps (CMB and diffuse\nforegrounds), catalogs for various classes of sources (the Early Release\nCompact Source Catalogue and the Final Compact Source Catalogue). The\norganization of the LFI consortium is briefly presented as well as the role of\nthe core team in data analysis and scientific exploitation. All tests carried\nout on the LFI flight model demonstrate the excellent performance of the\ninstrument and its various subunits. The data analysis pipeline has been tested\nand its main steps verified. In the first three months after launch, the\ncommissioning, calibration, performance, and verification phases will be\ncompleted, after which Planck will begin its operational life, in which LFI\nwill have an integral part. \n\n"}
{"id": "1001.2983", "contents": "Title: Directional detection of galactic Dark Matter Abstract: Directional detection of galactic Dark Matter is a promising search strategy\nfor discriminating geniune WIMP events from background ones. We present\ntechnical progress on gaseous detectors as well as recent phenomenological\nstudies, allowing the design and construction of competitive experiments. \n\n"}
{"id": "1001.3391", "contents": "Title: Quantum theory, gravity, and the standard model of particle physics :\n  using the hints of today to build the final theory of tomorrow Abstract: When a mountaineer is ascending one of the great peaks of the Himalayas she\nknows that an entirely new vista awaits her at the top, whose ramifications\nwill be known only after she gets there. Her immediate goal though, is to\ntackle the obstacles on the way up, and reach the summit. In a similar vein,\none of the immediate goals of contemporary theoretical physics is to build a\nquantum, unified description of general relativity and the standard model of\nparticle physics. Once that peak has been reached, a new (yet unknown) vista\nwill open up. In this essay I propose a novel approach towards this goal. One\nmust address and resolve a fundamental unsolved problem in the presently known\nformulation of quantum theory : the unsatisfactory presence of an external\nclassical time in the formulation. Solving this problem takes us to the very\nedge of theoretical physics as we know it today! \n\n"}
{"id": "1001.3411", "contents": "Title: Parallel HOP: A Scalable Halo Finder for Massive Cosmological Data Sets Abstract: Modern N-body cosmological simulations contain billions ($10^9$) of dark\nmatter particles. These simulations require hundreds to thousands of gigabytes\nof memory, and employ hundreds to tens of thousands of processing cores on many\ncompute nodes. In order to study the distribution of dark matter in a\ncosmological simulation, the dark matter halos must be identified using a halo\nfinder, which establishes the halo membership of every particle in the\nsimulation. The resources required for halo finding are similar to the\nrequirements for the simulation itself. In particular, simulations have become\ntoo extensive to use commonly-employed halo finders, such that the\ncomputational requirements to identify halos must now be spread across multiple\nnodes and cores. Here we present a scalable-parallel halo finding method called\nParallel HOP for large-scale cosmological simulation data. Based on the halo\nfinder HOP, it utilizes MPI and domain decomposition to distribute the halo\nfinding workload across multiple compute nodes, enabling analysis of much\nlarger datasets than is possible with the strictly serial or previous parallel\nimplementations of HOP. We provide a reference implementation of this method as\na part of the toolkit yt, an analysis toolkit for Adaptive Mesh Refinement\n(AMR) data that includes complementary analysis modules. Additionally, we\ndiscuss a suite of benchmarks that demonstrate that this method scales well up\nto several hundred tasks and datasets in excess of $2000^3$ particles. The\nParallel HOP method and our implementation can be readily applied to any kind\nof N-body simulation data and is therefore widely applicable. \n\n"}
{"id": "1001.3975", "contents": "Title: Possible direct measurement of the expansion rate of the universe Abstract: A new method is proposed for directly measuring the expansion rate of the\nuniverse through very precise measurement of the fluence of extremely stable\nsources. The method is based on the definition of the luminosity distance and\nits change along the time due to the cosmic expansion. It is argued that\ngalaxies may be chosen as the targets of the observation to perform the\nmeasurement. We show that, by simultaneously increasing the observation time\nand physically adding the fluences from different galaxies, the requirement on\nthe relative precision of the detector for an observation of 1 second on a\nsingle galaxy can be relaxed to $10^{-5}$. Benefiting from the abundance of\ngalaxies in the universe, the method may be quite promising. \n\n"}
{"id": "1001.4061", "contents": "Title: Exploring the possibility of detecting dark energy in a terrestrial\n  experiment using atom interferometry Abstract: The majority of astronomers and physicists accept the reality of dark energy\nbut also believe it can only be studied indirectly through observation of the\nmotions of galaxies. This paper opens the experimental question of whether it\nis possible to directly detect dark energy on earth using atom interferometry\nthrough a force hypothetically caused by a gradient in the dark energy density.\nOur proposed experimental design is outlined. The possibility of detecting\nother weak fields is briefly discussed. \n\n"}
{"id": "1001.4639", "contents": "Title: The scaling relation between richness and mass of galaxy clusters: a\n  Bayesian approach Abstract: We use a sample of 53 galaxy clusters at 0.03 < z < 0.1 with available masses\nderived from the caustic technique and with velocity dispersions computed using\n208 galaxies on average per cluster, in order to investigate the scaling\nbetween richness, mass and velocity dispersion. A tight scaling between\nrichness and mass is found, with an intrinsic scatter of only 0.19 dex in mass\nand with a slope one, i.e. clusters which have twice as many galaxies are twice\nas massive. When richness is measured without any knowledge of the cluster mass\nor linked parameters (such as r200), it can predict mass with an uncertainty of\n0.29+/-0.01 dex. As a mass proxy, richness competes favourably with both direct\nmeasurements of mass given by the caustic method, which has typically 0.14 dex\nerrors (vs 0.29) and X-ray luminosity, which offers a similar 0.30 dex\nuncertainty. The similar performances of X-ray luminosity and richness in\npredicting cluster masses has been confirmed using cluster masses derived from\nvelocity dispersion fixed by numerical simulations. These results suggest that\ncluster masses can be reliably estimated from simple galaxy counts, at least at\nthe redshift and masses explored in this work. This has important applications\nin the estimation of cosmological parameters from optical cluster surveys,\nbecause in current surveys clusters detected in the optical range outnumber, by\nat least one order of magnitude, those detected in X-ray. Our analysis is\nrobust from astrophysical and statistical perspectives. The data and code used\nfor the stochastic computation is distributed with the paper. [Abridged] \n\n"}
{"id": "1001.5203", "contents": "Title: Light Baryons from 2+1 flavor DWF QCD Abstract: We present results from the RBC and UKQCD collaboration ensembles of 2+1\nflavor DWF QCD for the light baryon spectrum. \n\n"}
{"id": "1002.0421", "contents": "Title: Observational Testability of Kerr bound in X-ray Spectrum of Black-Hole\n  Candidates Abstract: The specific angular momentum of a Kerr black hole must not be larger than\nits mass. The observational confirmation of this bound which we call a Kerr\nbound directly suggests the existence of a black hole. In order to investigate\nobservational testability of this bound by using the X-ray energy spectrum of\nblack hole candidates, we calculate energy spectra for a super-spinning object\n(or a naked singularity) which is described by a Kerr metric but whose specific\nangular momentum is larger than its mass, and then compare the spectra of this\nobject with those of a black hole. We assume an optically thick and\ngeometrically thin disc around the super-spinning object and calculate its\nthermal energy spectrum seen by a distant observer by solving general\nrelativistic radiative transfer equations including usual special and general\nrelativistic effects such as Doppler boosting, gravitational redshift, light\nbending and frame-dragging. Surprisingly, for a given black hole, we can always\nfind its super-spinning counterpart with its spin $a_*$ in the range\n$5/3<a_*<8\\sqrt{6}/3$ whose observed spectrum is very similar to and\npractically indistinguishable from that of the black hole. As a result, we\nconclude that to confirm the Kerr bound we need more than the X-ray thermal\nspectrum of the black hole candidates. \n\n"}
{"id": "1002.0503", "contents": "Title: Primordial non-Gaussianity in density fluctuations Abstract: We present N-body cosmological numerical simulations including a primordial\nnon-Gaussianity in the density fluctuation field quantified by the non-linear\nparameter $f_{NL}$. We have used MPGRAFIC code to produce initial conditions\nand the Adaptive Mesh Refinement (AMR) code RAMSES to evolve the large scale\nstructure formation. We estimated the higher order momenta of the initial\ndistribution of density fluctuations, investigated the redshift evolution of\nthe non-linear power spectrum and estimated the discrepancy introduced by the\nprimordial non-Gaussianity in the non-linear power spectrum. \n\n"}
{"id": "1002.1895", "contents": "Title: SZ Science with an ALMA Band 1 Receiver System Abstract: We present the first full interferometric simulations of galaxy clusters\ncontaining radio plasma bubbles as observed by the proposed band 1 receiver\nsystem for the ALMA telescope. We discuss the observational requirements for\ndetecting intracluster substructure directly from the SZ signal, including\nintegration time estimates, and the advantages of these observations over those\nmade with the current generation of SZ survey instruments. \n\n"}
{"id": "1002.3614", "contents": "Title: Measuring the Reduced Shear Abstract: Neglecting the second order corrections in weak lensing measurements can lead\nto a few percent uncertainties on cosmic shears, and becomes more important for\ncluster lensing mass reconstructions. Existing methods which claim to measure\nthe reduced shears are not necessarily accurate to the second order when a\npoint spread function (PSF) is present. We show that the method of Zhang (2008)\nexactly measures the reduced shears at the second order level in the presence\nof PSF. A simple theorem is provided for further confirming our calculation,\nand for judging the accuracy of any shear measurement method at the second\norder based on its properties at the first order. The method of Zhang (2008) is\nwell defined mathematically. It does not require assumptions on the\nmorphologies of galaxies and the PSF. To reach a sub-percent level accuracy,\nthe CCD pixel size is required to be not larger than 1/3 of the Full Width at\nHalf Maximum (FWHM) of the PSF. Using a large ensemble (> 10^7) of mock\ngalaxies of unrestricted morphologies, we find that contaminations to the shear\nsignals from the noise of background photons can be removed in a well defined\nway because they are not correlated with the source shapes. The residual shear\nmeasurement errors due to background noise are consistent with zero at the\nsub-percent level even when the amplitude of such noise reaches about 1/10 of\nthe source flux within the half-light radius of the source. This limit can in\nprinciple be extended further with a larger galaxy ensemble in our simulations.\nOn the other hand, the source Poisson noise remains to be a cause of systematic\nerrors. For a sub-percent level accuracy, our method requires the amplitude of\nthe source Poisson noise to be less than 1/80 ~ 1/100 of the source flux within\nthe half-light radius of the source, corresponding to collecting roughly 10^4\nsource photons. \n\n"}
{"id": "1002.3615", "contents": "Title: Cosmic Shears Should Not Be Measured In Conventional Ways Abstract: A long standing problem in weak lensing is about how to construct cosmic\nshear estimators from galaxy images. Conventional methods average over a single\nquantity per galaxy to estimate each shear component. We show that any such\nshear estimators must reduce to a highly nonlinear form when the galaxy image\nis described by three parameters (pure ellipse), even in the absence of the\npoint spread function (PSF). In the presence of the PSF, we argue that this\nclass of shear estimators do not likely exist. Alternatively, we propose a new\nway of measuring the cosmic shear: instead of averaging over a single value\nfrom each galaxy, we average over two numbers, and then take the ratio to\nestimate the shear component. In particular, the two numbers correspond to the\nnumerator and denominators which generate the quadrupole moments of the galaxy\nimage in Fourier space, as proposed in Zhang (2008). This yields a\nstatistically unbiased estimate of the shear component. Consequently,\nmeasurements of the n-point spatial correlations of the shear fields should\nalso be modified: one needs to take the ratio of two correlation functions to\nget the desired, unbiased shear correlation. \n\n"}
{"id": "1003.0409", "contents": "Title: Dynamical Masses in Modified Gravity Abstract: Differences in masses inferred from dynamics, such as velocity dispersions or\nX-rays, and those inferred from lensing are a generic prediction of modified\ngravity theories. Viable models however must include some non-linear mechanism\nto restore General Relativity (GR) in dense environments, which is necessary to\npass Solar System constraints on precisely these deviations. In this paper, we\nstudy the dynamics within virialized structures in the context of two modified\ngravity models, f(R) gravity and DGP. The non-linear mechanisms to restore GR,\nwhich f(R) and DGP implement in very different ways, have a strong impact on\nthe dynamics in bound objects; they leave distinctive signatures in the\ndynamical mass-lensing mass relation as a function of mass and radius. We\npresent measurements from N-body simulations of f(R) and DGP, as well as\nsemi-analytical models which match the simulation results to surprising\naccuracy in both cases. The semi-analytical models are useful for making the\nconnection to observations. Our results confirm that the environment- and\nscale-dependence of the modified gravity effects have to be taken into account\nwhen confronting gravity theories with observations of dynamics in galaxies and\nclusters. \n\n"}
{"id": "1003.1043", "contents": "Title: Do primordial Lithium abundances imply there's no Dark Energy? Abstract: Explaining the well established observation that the expansion rate of the\nuniverse is apparently accelerating is one of the defining scientific problems\nof our age. Within the standard model of cosmology, the repulsive 'dark energy'\nsupposedly responsible has no explanation at a fundamental level, despite many\nvaried attempts. A further important dilemma in the standard model is the\nLithium problem, which is the substantial mismatch between the theoretical\nprediction for 7-Li from Big Bang Nucleosynthesis and the value that we observe\ntoday. This observation is one of the very few we have from along our past\nworldline as opposed to our past lightcone. By releasing the untested\nassumption that the universe is homogeneous on very large scales, both apparent\nacceleration and the Lithium problem can be easily accounted for as different\naspects of cosmic inhomogeneity, without causing problems for other\ncosmological phenomena such as the cosmic microwave background. We illustrate\nthis in the context of a void model. \n\n"}
{"id": "1003.1073", "contents": "Title: The origin of the WMAP quadrupole Abstract: The cosmic microwave background (CMB) temperature maps from the Wilkinson\nMicrowave Anisotropy Probe (WMAP) are of great importance for cosmology. In\nprevious work we had developed a pipeline for map-making independently of the\nWMAP team. The new maps produced from the WMAP raw data by our pipeline are\nnotably different to the official ones, and the power spectrum as well as the\nbest-fit cosmological parameters are significantly different too. What's more,\nby revealing the inconsistency between the WMAP raw data and their official\nmap, we had pointed out that there must exist an unexpected problem in the WMAP\nteam's pipeline. In this work, we find that the trouble comes from the\ninaccuracy of antenna pointing direction caused by a systematical time drift\nbetween the attitude data and the science data in the WMAP raw time-order data\n(TOD). The CMB quadrupole in the WMAP release can be exactly generated from a\ndifferential dipole field which is completely determined by the spacecraft\nvelocity and the antenna directions without using any CMB signal. After\ncorrecting the WMAP team's error, the CMB quadrupole component disappears.\nTherefore, the released WMAP CMB quadrupole is almost completely artificial and\nthe real quadrupole of the CMB anisotropy should be near zero. Our finding is\nimportant for understanding the early universe. \n\n"}
{"id": "1003.2480", "contents": "Title: Predictions for the Rates of Compact Binary Coalescences Observable by\n  Ground-based Gravitational-wave Detectors Abstract: We present an up-to-date, comprehensive summary of the rates for all types of\ncompact binary coalescence sources detectable by the Initial and Advanced\nversions of the ground-based gravitational-wave detectors LIGO and Virgo.\nAstrophysical estimates for compact-binary coalescence rates depend on a number\nof assumptions and unknown model parameters, and are still uncertain. The most\nconfident among these estimates are the rate predictions for coalescing binary\nneutron stars which are based on extrapolations from observed binary pulsars in\nour Galaxy. These yield a likely coalescence rate of 100 per Myr per Milky Way\nEquivalent Galaxy (MWEG), although the rate could plausibly range from 1 per\nMyr per MWEG to 1000 per Myr per MWEG. We convert coalescence rates into\ndetection rates based on data from the LIGO S5 and Virgo VSR2 science runs and\nprojected sensitivities for our Advanced detectors. Using the detector\nsensitivities derived from these data, we find a likely detection rate of 0.02\nper year for Initial LIGO-Virgo interferometers, with a plausible range between\n0.0002 and 0.2 per year. The likely binary neutron-star detection rate for the\nAdvanced LIGO-Virgo network increases to 40 events per year, with a range\nbetween 0.4 and 400 per year. \n\n"}
{"id": "1003.4757", "contents": "Title: Luminosity-variation independent location of the circum-nuclear, hot\n  dust in NGC 4151 Abstract: After recent sensitivity upgrades at the Keck Interferometer (KI), systematic\ninterferometric 2um studies of the innermost dust in nearby Seyfert nuclei are\nwithin observational reach. Here, we present the analysis of new\ninterferometric data of NGC 4151, discussed in context of the results from\nrecent dust reverberation, spectro-photometric and interferometric campaigns.\nThe complete data set gives a complex picture, in particular the measured\nvisibilities from now three different nights appear to be rather insensitive to\nthe variation of the nuclear luminosity. KI data alone indicate two scenarios:\nthe K-band emission is either dominated to ~90% by size scales smaller than\n30mpc, which falls short of any dust reverberation measurement in NGC 4151 and\nof theoretical models of circum-nuclear dust distributions. Or contrary, and\nmore likely, the K-band continuum emission is dominated by hot dust (>= 1300K)\nat linear scales of about 50mpc. The linear size estimate varies by a few tens\nof percent depending on the exact morphology observed. Our interferometric,\ndeprojected centro-nuclear dust radius estimate of 55+-5mpc is roughly\nconsistent with the earlier published expectations from circum-nuclear, dusty\nradiative transfer models, and spectro-photometric modeling. However, our data\ndo not support the notion that the dust emission size scale follows the nuclear\nvariability of NGC 4151 as a R_dust \\propto L_nuc^0.5 scaling relation. Instead\nvariable nuclear activity, lagging, and variable dust response to illumination\nchanges need to be combined to explain the observations. \n\n"}
{"id": "1003.6064", "contents": "Title: Orthographic Correlations in Astrophysics Abstract: We analyze correlations between the first letter of the name of an author and\nthe number of citations their papers receive. We look at simple mean counts,\nnumbers of highly-cited papers, and normalized h-indices, by letter. To our\nsurprise, we conclude that orthographically senior authors produce a better\nbody of work than their colleagues, despite some evidence of discrimination\nagainst them. \n\n"}
{"id": "1004.2785", "contents": "Title: The stellar mass fraction and baryon content of galaxy clusters and\n  groups Abstract: [Abridged] The analysis of a sample of 52 clusters with precise and\nhypothesis-parsimonious measurements of mass shows that low mass clusters and\ngroups are not simple scaled-down versions of their massive cousins in terms of\nstellar content: lighter clusters have more stars per unit cluster mass. The\nsame analysis also shows that the stellar content of clusters and groups\ndisplays an intrinsic spread at a given cluster mass, i.e. clusters are not\nsimilar each other in the amount of stars they contain, not even at a fixed\ncluster mass. The stellar mass fraction depends on halo mass with (logarithmic)\nslope -0.55+/-0.08 and with 0.15+/-0.02 dex of intrinsic scatter at a fixed\ncluster mass. The intrinsic scatter at a fixed cluster mass we determine for\ngas mass fractions is smaller, 0.06+/-0.01 dex. The intrinsic scatter in both\nthe stellar and gas mass fractions is a distinctive signature that the regions\nfrom which clusters and groups collected matter, a few tens of Mpc, are yet not\nrepresentative, in terms of gas and baryon content, of the mean matter content\nof the Universe. The observed stellar mass fraction values are in marked\ndisagreement with gasdynamics simulations with cooling and star formation of\nclusters and groups. We found the the baryon (gas+stellar) fraction is fairly\nconstant for clusters and groups with 13.7<lg(mass)<15.0 solar masses and it is\noffset from the WMAP-derived value by about 6 sigmas. The offset could be\nrelated to the possible non universality of the baryon fraction pointed out by\nour measurements of the intrinsic scatter. Our analysis is the first that does\nnot assume that clusters are identically equal at a given halo mass and it is\nalso more accurate in many aspects. The data and code used for the stochastic\ncomputation are distributed with the paper. \n\n"}
{"id": "1004.4318", "contents": "Title: LBT/LUCIFER Observations of the z~2 Lensed Galaxy J0900+2234 Abstract: We present rest-frame optical images and spectra of the gravitationally\nlensed, star-forming galaxy J0900+2234 (z=2.03). The observations were\nperformed with the newly commissioned LUCIFER1 near-infrared instrument mounted\non the Large Binocular Telescope (LBT). We fit lens models to the rest-frame\noptical images and find the galaxy has an intrinsic effective radius of 7.4 kpc\nwith a lens magnification factor of about 5 for the A and B components. We also\ndiscovered a new arc belonging to another lensed high-z source galaxy, which\nmakes this lens system a potential double Einstein ring system. Using the high\nS/N rest-frame optical spectra covering H+K band, we detected Hbeta, OIII,\nHalpha, NII and SII emission lines. Detailed physical properties of this high-z\ngalaxy were derived. The extinction towards the ionized HII regions (E_g(B-V))\nis computed from the flux ratio of Halpha and Hbeta and appears to be much\nhigher than that towards stellar continuum (E_s(B-V)), derived from the optical\nand NIR broad band photometry fitting. The metallicity was estimated using N2\nand O3N2 indices. It is in the range of 1/5-1/3 solar abundance, which is much\nlower than the typical z~2 star-forming galaxies. From the flux ratio of SII\n6717 and 6732, we found that the electron number density of the HII regions in\nthe high-z galaxy were >1000 cm^-3, consistent with other z~2 galaxies but much\nhigher than that in local HII regions. The star-formation rate was estimated\nvia the Halpha luminosity, after correction for the lens magnification, to be\nabout 365\\pm69 Msun/yr. Combining the FWHM of Halpha emission lines and the\nhalf-light radius, we found the dynamical mass of the lensed galaxy is\n5.8\\pm0.9x10^10 Msun. The gas mass is 5.1\\pm1.1x10^10~Msun from the H\\alpha\nflux surface density by using global Kennicutt-Schmidt Law, indicating a very\nhigh gas fraction of 0.79\\pm0.19 in J0900+2234. \n\n"}
{"id": "1005.1067", "contents": "Title: Dual Jets from Binary Black Holes Abstract: Supermassive black holes are found at the centers of most galaxies and their\ninspiral is a natural outcome when galaxies merge. The inspiral of these\nsystems is of utmost astrophysical importance as prodigious producers of\ngravitational waves and in their possible role in energetic electromagnetic\nevents. We study such binary black hole coalescence under the influence of an\nexternal magnetic field produced by the expected circumbinary disk surrounding\nthem. Solving the Einstein equations to describe the spacetime and using the\nforce-free approach for the electromagnetic fields and the tenuous plasma, we\npresent numerical evidence for possible jets driven by these systems. Extending\nthe process described by Blandford and Znajek for a single spinning black hole,\nthe picture that emerges suggests the electromagnetic field extracts energy\nfrom the orbiting black holes, which ultimately merge and settle into the\nstandard Blandford-Znajek scenario. Emissions along dual and single jets would\nbe expected that could be observable to large distances. \n\n"}
{"id": "1005.2615", "contents": "Title: Reply to the Comments on the XENON100 First Dark Matter Results Abstract: The recently submitted preprint on the first results from the XENON100 dark\nmatter experiment (arxiv:1005.0380) was followed by a criticism by J.I. Collar\nand D.N. McKinsey (arxiv:1005.0838), focused on our extrapolation of the\nscintillation efficiency L_eff to the lowest nuclear recoil energies, where no\ndata and no theoretical model exist. Here we add clarifications on our analysis\nand comment on their criticism. \n\n"}
{"id": "1006.1619", "contents": "Title: Parameterizing the flattening of galaxies rotation curves on an\n  expanding locally anisotropic background Abstract: In this paper are discussed possible many body generalizations of the\nexpanding locally anisotropic metric ansatz with respect to approximately\nNewtonian gravitational systems. This ansatz consistently describes local\npoint-like matter distributions on the expanding Universe also allowing for a\ncovariant parameterization of gravitational interactions at intermediate length\nscales.\n  As an example of applicability it is modeled a disk galaxy model matching the\nphysical parameters of the galaxy UGC2885 and it is shown that, by fine-tuning\nthe metric functional parameter, the flattening of the galaxy rotation curve is\nfully parameterized by this metric. In addition it is numerically computed the\nmass-energy density corrections due to the expanding anisotropic background and\nexplicitly shown that although there are negative contributions within the\ngalaxy plane the total mass-energy density is strictly positive both at the\ngalaxy plane and outside the galaxy plane. As the functional parameter for this\nmetric is an exponential factor is required a floating point precision of $250$\nsignificant digits for root finding routines and $200$ significant digits to\nevaluate the effective mass-energy density rendering a final precision of the\nresults presented above double precision ($16$ significant digits).\n  It is further shown that these results are consistent with the interpretation\nof the gravitational corrections as due to Dark Matter, in particular\nconstituting a novel heuristic local parameterization for the Dark Matter\ndistribution within the galaxy plane consistent with both local scale and\ncosmological scale physical laws which is useful to further investigate the\nlocal properties of Dark Matter. \n\n"}
{"id": "1006.3859", "contents": "Title: Sunyaev-Zel'dovich galaxy clusters number counts : consequences of\n  cluster scaling laws evolution Abstract: Galaxy cluster surveys based on the Sunyaev-Zeldovich effect (SZE) mapping\nare expected from ongoing experiments. Such surveys are anticipated to provide\na significant amount of information relevant to cosmology from the number\ncounts redshift distribution. We carry out an estimation of predicted SZE\ncounts and their redshift distribution taking into account the current\ncosmological constraints and the X-ray cluster temperature distribution\nfunctions. Comparison between local and distant cluster temperature\ndistribution functions provides evidence for an evolution in the abundance of\nX-ray clusters that is not consistent with the use of standard scaling\nrelations of cluster properties in the framework of the current concordance\nmodel. The hypothesis of some evolution of the scaling law driven by\nnon-gravitational processes is a natural solution to this problem. We perform a\nMCMC statistical study using COSMOMC, combining current CMB observations from\nWMAP, the SNIa Hubble diagram, the galaxy power spectrum data from SDSS and\nX-ray clusters temperature distributions to predict SZE cluster number counts.\nModels reproducing well the X-ray cluster temperature distribution function\nevolution lead to a significantly lower SZE clusters number counts with a\ndistinctive redshift distribution. Ongoing microwave SZE surveys will therefore\nshed new light on intracluster gas physics and greatly help to identify the\nrole of possible non-gravitational physics in the history of the hot gas\ncomponent of x-ray clusters. \n\n"}
{"id": "1007.1218", "contents": "Title: Detection of gravitational waves from the QCD phase transition with\n  pulsar timing arrays Abstract: If the cosmological QCD phase transition is strongly first order and lasts\nsufficiently long, it generates a background of gravitational waves which may\nbe detected via pulsar timing experiments. We estimate the amplitude and the\nspectral shape of such a background and we discuss its detectability prospects. \n\n"}
{"id": "1007.1256", "contents": "Title: Unknowns and unknown unknowns: from dark sky to dark matter and dark\n  energy Abstract: Answering well-known fundamental questions is usually regarded as the major\ngoal of science. Discovery of other unknown and fundamental questions is,\nhowever, even more important. Recognition that \"we didn't know anything\" is the\nbasic scientific driver for the next generation. Cosmology indeed enjoys such\nan exciting epoch. What is the composition of our universe? This is one of the\nwell-known fundamental questions that philosophers, astronomers and physicists\nhave tried to answer for centuries. Around the end of the last century,\ncosmologists finally recognized that \"We didn't know anything\". Except for\natoms that comprise slightly less than 5% of the universe, our universe is\napparently dominated by unknown components; 23% is the known unknown (dark\nmatter), and 72% is the unknown unknown (dark energy). In the course of\nanswering a known fundamental question, we have discovered an unknown, even\nmore fundamental, question: \"What is dark matter? What is dark energy?\" There\nare a variety of realistic particle physics models for dark matter, and its\nexperimental detection may be within reach. On the other hand, it is fair to\nsay that there is no widely accepted theoretical framework to describe the\nnature of dark energy. This is exactly why astronomical observations will play\na key role in unveiling its nature. I will review our current understanding of\nthe \"dark sky\", and then present on-going Japanese project, SuMIRe, to discover\neven more unexpected questions. \n\n"}
{"id": "1007.3065", "contents": "Title: Testing the Void against Cosmological data: fitting CMB, BAO, SN and H0 Abstract: In this paper, instead of invoking Dark Energy, we try and fit various\ncosmological observations with a large Gpc scale under-dense region (Void)\nwhich is modeled by a Lemaitre-Tolman-Bondi metric that at large distances\nbecomes a homogeneous FLRW metric. We improve on previous analyses by allowing\nfor nonzero overall curvature, accurately computing the distance to the\nlast-scattering surface and the observed scale of the Baryon Acoustic peaks,\nand investigating important effects that could arise from having nontrivial\nVoid density profiles. We mainly focus on the WMAP 7-yr data (TT and TE),\nSupernova data (SDSS SN), Hubble constant measurements (HST) and Baryon\nAcoustic Oscillation data (SDSS and LRG). We find that the inclusion of a\nnonzero overall curvature drastically improves the goodness of fit of the Void\nmodel, bringing it very close to that of a homogeneous universe containing Dark\nEnergy, while by varying the profile one can increase the value of the local\nHubble parameter which has been a challenge for these models. We also try to\ngauge how well our model can fit the large-scale-structure data, but a\ncomprehensive analysis will require the knowledge of perturbations on LTB\nmetrics. The model is consistent with the CMB dipole if the observer is about\n15 Mpc off the centre of the Void. Remarkably, such an off-center position may\nbe able to account for the recent anomalous measurements of a large bulk flow\nfrom kSZ data. Finally we provide several analytical approximations in\ndifferent regimes for the LTB metric, and a numerical module for CosmoMC, thus\nallowing for a MCMC exploration of the full parameter space. \n\n"}
{"id": "1007.4717", "contents": "Title: Dynamics of a cold trapped ion in a Bose-Einstein condensate Abstract: We investigate the interaction of a laser-cooled trapped ion (Ba$^+$ or\nRb$^+$) with an optically confined $^{87}$Rb Bose-Einstein condensate (BEC).\nThe system features interesting dynamics of the ion and the atom cloud as\ndetermined by their collisions and their motion in their respective traps.\nElastic as well as inelastic processes are observed and their respective cross\nsections are determined. We demonstrate that a single ion can be used to probe\nthe density profile of an ultracold atom cloud. \n\n"}
{"id": "1008.0641", "contents": "Title: An Alternative Approach To Measuring Reverberation Lags in Active\n  Galactic Nuclei Abstract: Motivated by recent progress in the statistical modeling of quasar\nvariability, we develop a new approach to measuring emission-line reverberation\nlags to estimate the size of broad-line regions (BLRs) in active galactic\nnuclei. Assuming that all emission-line light curves are scaled, smoothed, and\ndisplaced versions of the continuum, this alternative approach fits the light\ncurves directly using a damped random walk model and aligns them to recover the\ntime lag and its statistical confidence limits. We introduce the mathematical\nformalism of this approach and demonstrate its ability to cope with some of the\nproblems for traditional methods, such as irregular sampling, correlated\nerrors, and seasonal gaps. We redetermine the lags for 87 emission lines in 31\nquasars and reassess the BLR size--luminosity relationship using 60 H-beta\nlags. We confirm the general results from the traditional cross-correlation\nmethods, with a few exceptions. Our method, however, also supports a broad\nrange of extensions. In particular, it can simultaneously fit multiple lines\nand continuum light curves which improves the lag estimate for the lines and\nprovides estimates of the error correlations between them. Determining these\ncorrelations is of particular importance for interpreting emission-line\nvelocity--delay maps. We can also include parameters for luminosity-dependent\nlags or line responses. We use this to detect the scaling of the BLR size with\ncontinuum luminosity in NGC 5548. \n\n"}
{"id": "1008.0773", "contents": "Title: Spectral and Photometric Monitoring of Distant Core-Collapse Supernovae\n  in the SAO RAS Abstract: This paper describes the aims, objectives and first results of the\nobservational program for the study of distant core-collapse supernovae (SNe)\nwith redshifts z < 0.3. This work is done within the framework of an\ninternational cooperation program on the SNe monitoring at the 6-m BTA\ntelescope of the Special Astrophysical Observatory of the Russian Academy of\nSciences, and other telescopes. We study both the early phases of events (SN\ntype determination, redshift estimation, and a search for manifestations of a\nwind envelope), and the nebular phase (the effects of explosion asymmetry). The\nSNe, associated with cosmic gamma-ray bursts are of particular interest. An\ninterpretation of our observational data along with the data obtained on other\ntelescopes is used to test the existing theoretical models of both the SN\nexplosion, and the surrounding circumstellar medium. In 2009 we observed 30\nobjects; the spectra were obtained for 12 of them. We determined the types,\nphases after maximum, and redshifts for five SNe (SN 2009db, SN 2009dy, SN\n2009dw, SN 2009ew, SN 2009ji). Based on the obtained photometric data a\ndiscovery of two more SNe was confirmed (SN 2009bx and SN 2009cb). A study of\ntwo type II supernovae in the nebular phase (SN 2008gz and SN 2008in) is\nfinalized, four more objects (SN 2008iy, SN 2009ay, SN 2009bw, SN 2009de) are\ncurrently monitored. \n\n"}
{"id": "1008.3143", "contents": "Title: Optimal Time-Series Selection of Quasars Abstract: We present a novel method for the optimal selection of quasars using\ntime-series observations in a single photometric bandpass. Utilizing the damped\nrandom walk model of Kelly et al. (2009), we parameterize the ensemble quasar\nstructure function in Sloan Stripe 82 as a function of observed brightness. The\nensemble model fit can then be evaluated rigorously for and calibrated with\nindividual light curves with no parameter fitting. This yields a classification\nin two statistics --- one describing the fit confidence and one describing the\nprobability of a false alarm --- which can be tuned, a priori, to achieve high\nquasar detection fractions (99% completeness with default cuts), given an\nacceptable rate of false alarms. We establish the typical rate of false alarms\ndue to known variable stars as <3% (high purity). Applying the classification,\nwe increase the sample of potential quasars relative to those known in Stripe\n82 by as much as 29%, and by nearly a factor of two in the redshift range\n2.5<z<3, where selection by color is extremeley inefficient. This represents\n1875 new quasars in a 290 deg^2 field. The observed rates of both quasars and\nstars agree well with the model predictions, with >99% of quasars exhibiting\nthe expected variability profile. We discus the utility of the method at\nhigh-redshift and in the regime of noisy and sparse data. Our time series\nselection complements well independent selection based on quasar colors and has\nstrong potential for identifying high redshift quasars for BAO and other\ncosmology studies in the LSST era. \n\n"}
{"id": "1008.3607", "contents": "Title: Measuring the mass of solar system planets using pulsar timing Abstract: High-precision pulsar timing relies on a solar-system ephemeris in order to\nconvert times of arrival (TOAs) of pulses measured at an observatory to the\nsolar system barycenter. Any error in the conversion to the barycentric TOAs\nleads to a systematic variation in the observed timing residuals; specifically,\nan incorrect planetary mass leads to a predominantly sinusoidal variation\nhaving a period and phase associated with the planet's orbital motion about the\nSun. By using an array of pulsars (PSRs J0437-4715, J1744-1134, J1857+0943,\nJ1909-3744), the masses of the planetary systems from Mercury to Saturn have\nbeen determined. These masses are consistent with the best-known masses\ndetermined by spacecraft observations, with the mass of the Jovian system,\n9.547921(2)E-4 Msun, being significantly more accurate than the mass determined\nfrom the Pioneer and Voyager spacecraft, and consistent with but less accurate\nthan the value from the Galileo spacecraft. While spacecraft are likely to\nproduce the most accurate measurements for individual solar system bodies, the\npulsar technique is sensitive to planetary system masses and has the potential\nto provide the most accurate values of these masses for some planets. \n\n"}
{"id": "1008.3941", "contents": "Title: Gravitational wave background from sub-luminous GRBs: prospects for\n  second and third generation detectors Abstract: We assess the detection prospects of a gravitational wave background\nassociated with sub-luminous gamma-ray bursts (SL-GRBs). We assume that the\ncentral engines of a significant proportion of these bursts are provided by\nnewly born magnetars and consider two plausible GW emission mechanisms.\nFirstly, the deformation-induced triaxial GW emission from a newly born\nmagnetar. Secondly, the onset of a secular bar-mode instability, associated\nwith the long lived plateau observed in the X-ray afterglows of many gamma-ray\nbursts (Corsi & Meszaros 2009a). With regards to detectability, we find that\nthe onset of a secular instability is the most optimistic scenario: under the\nhypothesis that SL-GRBs associated with secularly unstable magnetars occur at a\nrate of (48; 80)Gpc^{-3}yr^{-1} or greater, cross-correlation of data from two\nEinstein Telescopes (ETs) could detect the GW background associated to this\nsignal with a signal-to-noise ratio of 3 or greater after 1 year of\nobservation. Assuming neutron star spindown results purely from triaxial GW\nemissions, we find that rates of around (130;350)Gpc^{-3}yr^{-1} will be\nrequired by ET to detect the resulting GW background. We show that a background\nsignal from secular instabilities could potentially mask a primordial GW\nbackground signal in the frequency range where ET is most sen- sitive. Finally,\nwe show how accounting for cosmic metallicity evolution can increase the\npredicted signal-to-noise ratio for background signals associated with SL-GRBs. \n\n"}
{"id": "1008.4082", "contents": "Title: The C-Band All-Sky Survey: Instrument design, status, and first-look\n  data Abstract: The C-Band All-Sky Survey (C-BASS) aims to produce sensitive, all-sky maps of\ndiffuse Galactic emission at 5 GHz in total intensity and linear polarization.\nThese maps will be used (with other surveys) to separate the several\nastrophysical components contributing to microwave emission, and in particular\nwill allow an accurate map of synchrotron emission to be produced for the\nsubtraction of foregrounds from measurements of the polarized Cosmic Microwave\nBackground. We describe the design of the analog instrument, the optics of our\n6.1 m dish at the Owens Valley Radio Observatory, the status of observations,\nand first-look data. \n\n"}
{"id": "1008.4356", "contents": "Title: Cosmological 21cm experiments: Searching for a needle in a haystack Abstract: There are several planned and ongoing experiments designed to explore the\nEpoch of Reionization (EoR), the pivotal period during which the gas in the\nintergalactic medium went from being entirely neutral to almost entirely\nionized. These experiments will probe the EoR, through the redshifted 21 cm\nline from neutral hydrogen, using radio arrays: e.g. Low Frequency Array\n(LOFAR) and Murchinson Widefield Array (MWA). Unfortunately however, the\ncosmological 21 cm signal is highly contaminated by astrophysical foregrounds\nand by non-astrophysical and instrumental effects. Therefore, to reliably\ndetect the cosmological signal, it is essential to understand very well all\ndata components, their influence on the desired signal and explore additional\ncomplementary or corroborating probes of the EoR. These proceedings give an\noverview of observational constrains of the foregrounds, present theoretical\nefforts to model the foregrounds, and discuss a problem of the foreground\nremoval. The major results are presented for the LOFAR-EoR experiment. \n\n"}
{"id": "1009.0018", "contents": "Title: A Tale of Two Jets Abstract: One of the most interesting high-energy, astrophysical phenomena are\nrelativistic jets emitted from highly localized sky location. Such jets are\ncommon in Nature, observed to high redshift and in a range of wavelengths.\nTheir precise generation mechanism remains a bit of a mystery, but they are\ngenerically believed to be powered by black holes. We here summarize the recent\nsimulations of Palenzuela, Lehner and Liebling that shed light on the jet\ngeneration mechanism. These authors studied the merger of two non-spinning\nblack holes in the presence of a magnetic field, perpendicular to the orbital\nplane and anchored by a circumbinary accretion disk, in the \"force-free\"\napproximation. They found that each black hole essentially acts as a \"straw\"\nthat stirs the magnetic field lines around the center of mass as the black\nholes inspiral. The twisting of the magnetic field lines then generates jets\naround each black hole, even though these are not spinning. Their simulations\nshow the formation of such a dual jet geometry and how it transitions to a\nsingle jet one, as the black holes merge due to gravitational wave emission. \n\n"}
{"id": "1009.0019", "contents": "Title: Constraining scalar fields with stellar kinematics and collisional dark\n  matter Abstract: The existence and detection of scalar fields could provide solutions to\nlong-standing puzzles about the nature of dark matter, the dark compact objects\nat the centre of most galaxies, and other phenomena. Yet, self-interacting\nscalar fields are very poorly constrained by astronomical observations, leading\nto great uncertainties in estimates of the mass $m_\\phi$ and the\nself-interacting coupling constant $\\lambda$ of these fields. To counter this,\nwe have systematically employed available astronomical observations to develop\nnew constraints, considerably restricting this parameter space. In particular,\nby exploiting precise observations of stellar dynamics at the centre of our\nGalaxy and assuming that these dynamics can be explained by a single boson\nstar, we determine an upper limit for the boson star compactness and impose\nsignificant limits on the values of the properties of possible scalar fields.\nRequiring the scalar field particle to follow a collisional dark matter model\nfurther narrows these constraints. Most importantly, we find that if a scalar\ndark matter particle does exist, then it cannot account for both the\ndark-matter halos and the existence of dark compact objects in galactic nuclei \n\n"}
{"id": "1009.0157", "contents": "Title: Radiatively inefficient accretion flows induced by gravitational-wave\n  emission before massive black hole coalescence Abstract: We study an accretion flow during the gravitational-wave driven evolution of\nbinary massive black holes. After the binary orbit decays due to an interaction\nwith a massive circumbinary disk, the binary is decoupled from the circumbinary\ndisk because the orbital-decay timescale due to emission of gravitational wave\nbecomes shorter than the viscous timescale evaluated at the inner edge of\ncircumbinary disk. During the subsequent evolution, the accretion disk, which\nis truncated at the tidal radius because of the tidal torque, also shrinks as\nthe orbital decay. Assuming that the disk mass changed by this process is all\naccreted, the disk becomes radiatively inefficient when the semi-major axis is\nseveral hundred Schwarzschild radii. The high-energy radiations, in spite of a\nlow bolometric luminosity, are emitted from an accretion disk around each black\nhole long before the black hole coalescence as well as the gravitational wave\nsignals. The synchrotron process can notably produce potentially observable\nradio emissions at large distances if there is a strong, dipole magnetic field\naround each black hole. In unequal mass-ratio binaries, step-like light\nvariations are seen in the observed light curve because the luminosity is\nhigher and its duration time are shorter in the radio emission by the disk\naround the secondary black hole than those of the primary black hole. Such a\nprecursor would be unique to not a single black hole system but a binary black\nhole system, and implies that binary black holes finally merge without\naccretion disks. \n\n"}
{"id": "1009.0777", "contents": "Title: The Atacama Cosmology Telescope: Calibration with WMAP Using\n  Cross-Correlations Abstract: We present a new calibration method based on cross-correlations with WMAP and\napply it to data from the Atacama Cosmology Telescope (ACT). ACT's observing\nstrategy and map making procedure allows an unbiased reconstruction of the\nmodes in the maps over a wide range of multipoles. By directly matching the ACT\nmaps to WMAP observations in the multipole range of 400 < ell < 1000, we\ndetermine the absolute calibration with an uncertainty of 2% in temperature.\nThe precise measurement of the calibration error directly impacts the\nuncertainties in the cosmological parameters estimated from the ACT power\nspectra. We also present a combined map based on ACT and WMAP data that has\nhigh signal-to-noise over a wide range of multipoles. \n\n"}
{"id": "1009.1493", "contents": "Title: Detection of new point-sources in WMAP Cosmic Microwave Background (CMB)\n  maps at high Galactic latitude. A new technique to extract point sources from\n  CMB maps Abstract: In experimental microwave maps, point-sources can strongly affect the\nestimation of the power-spectrum and/or the test of Gaussianity of the Cosmic\nMicrowave Background (CMB) component. As a consequence, their removal from the\nsky maps represents a critical step in the analysis of the CMB data. Before\nremoving a source, however, it is necessary to detect it and source extraction\nconsists of a delicate preliminary operation. In the literature, various\ntechniques have been presented to detect point-sources in the sky maps. The\nmost sophisticated ones exploit the multi-frequency nature of the observations\nthat is typical of the CMB experiments. These techniques have \"optimal\"\ntheoretical properties and, at least in principle, are capable of remarkable\nperformances. Actually, they are rather difficult to use and this deteriorates\nthe quality of the obtainable results. In this paper, we present a new\ntechnique, the \"weighted matched filter\" (WMF), that is quite simple to use and\nhence more robust in practical applications. Such technique shows particular\nefficiency in the detection of sources whose spectra have a slope different\nfrom zero. We apply this method to three Southern Hemisphere sky regions - each\nwith an area of 400 square degrees - of the seven years Wilkinson Microwave\nAnisotropy Probe (WMAP) maps and compare the resulting sources with those of\nthe two seven-year WMAP point-sources catalogues. In these selected regions we\nfind seven additional sources not previously listed in WMAP catalogues and\ndiscuss their most likely identification and spectral properties. \n\n"}
{"id": "1009.1625", "contents": "Title: RADAMESH: Cosmological Radiative Transfer for Adaptive Mesh Refinement\n  Simulations Abstract: We present a new three-dimensional radiative transfer (RT) code, RADAMESH,\nbased on a ray-tracing, photon-conserving and adaptive (in space and time)\nscheme. RADAMESH uses a novel Monte Carlo approach to sample the radiation\nfield within the computational domain on a \"cell-by-cell\" basis. Thanks to this\nalgorithm, the computational efforts are now focused where actually needed,\ni.e. within the Ionization-fronts (I-fronts). This results in an increased\naccuracy level and, at the same time, a huge gain in computational speed with\nrespect to a \"classical\" Monte Carlo RT, especially when combined with an\nAdaptive Mesh Refinement (AMR) scheme. Among several new features, RADAMESH is\nable to adaptively refine the computational mesh in correspondence of the\nI-fronts, allowing to fully resolve them within large, cosmological boxes. We\nfollow the propagation of ionizing radiation from an arbitrary number of\nsources and from the recombination radiation produced by H and He. The chemical\nstate of six species (HI, HII, HeI, HeII, HeIII, e) and gas temperatures are\ncomputed with a time-dependent, non-equilibrium chemistry solver. We present\nseveral validating tests of the code, including the standard tests from the RT\nCode Comparison Project and a new set of tests aimed at substantiating the new\ncharacteristics of RADAMESH. Using our AMR scheme, we show that properly\nresolving the I-front of a bright quasar during Reionization produces a large\nincrease of the predicted gas temperature within the whole HII region. Also, we\ndiscuss how H and He recombination radiation is able to substantially change\nthe ionization state of both species (for the classical Stroemgren sphere test)\nwith respect to the widely used \"on-the-spot\" approximation. \n\n"}
{"id": "1009.2024", "contents": "Title: Controlling intrinsic alignments in weak lensing statistics: The nulling\n  and boosting techniques Abstract: The intrinsic alignment of galaxies constitutes the major astrophysical\nsource of systematic errors in surveys of weak gravitational lensing by the\nlarge-scale structure. We discuss the principles, summarise the implementation,\nand highlight the performance of two model-independent methods that control\nintrinsic alignment signals in weak lensing data: the nulling technique which\neliminates intrinsic alignments to ensure unbiased constraints on cosmology,\nand the boosting technique which extracts intrinsic alignments and hence allows\none to further study this contribution. Making only use of the characteristic\ndependence on redshift of the signals, both approaches are robust, but reduce\nthe statistical power due to the similar redshift scaling of intrinsic\nalignment and lensing signals. \n\n"}
{"id": "1010.1266", "contents": "Title: New insight on galaxy structure from GALPHAT I. Motivation, methodology,\n  and benchmarks for Sersic models Abstract: We introduce a new galaxy image decomposition tool, GALPHAT (GALaxy\nPHotometric ATtributes), to provide full posterior probability distributions\nand reliable confidence intervals for all model parameters. GALPHAT is designed\nto yield a high speed and accurate likelihood computation, using grid\ninterpolation and Fourier rotation. We benchmark this approach using an\nensemble of simulated Sersic model galaxies over a wide range of observational\nconditions: the signal-to-noise ratio S/N, the ratio of galaxy size to the PSF\nand the image size, and errors in the assumed PSF; and a range of structural\nparameters: the half-light radius $r_e$ and the Sersic index $n$. We\ncharacterise the strength of parameter covariance in Sersic model, which\nincreases with S/N and $n$, and the results strongly motivate the need for the\nfull posterior probability distribution in galaxy morphology analyses and later\ninferences.\n  The test results for simulated galaxies successfully demonstrate that, with a\ncareful choice of Markov chain Monte Carlo algorithms and fast model image\ngeneration, GALPHAT is a powerful analysis tool for reliably inferring\nmorphological parameters from a large ensemble of galaxies over a wide range of\ndifferent observational conditions. (abridged) \n\n"}
{"id": "1010.1371", "contents": "Title: Needatool: A Needlet Analysis Tool for Cosmological Data Processing Abstract: We introduce NeedATool (Needlet Analysis Tool), a software for data analysis\nbased on needlets, a wavelet rendition which is powerful for the analysis of\nfields defined on a sphere. Needlets have been applied successfully to the\ntreatment of astrophysical and cosmological observations, and in particular to\nthe analysis of cosmic microwave background (CMB) data. Usually, such analyses\nare performed in real space as well as in its dual domain, the harmonic one.\nBoth spaces have advantages and disadvantages: for example, in pixel space it\nis easier to deal with partial sky coverage and experimental noise; in harmonic\ndomain, beam treatment and comparison with theoretical predictions are more\neffective. During the last decade, however, wavelets have emerged as a useful\ntool for CMB data analysis, since they allow to combine most of the advantages\nof the two spaces, one of the main reasons being their sharp localisation. In\nthis paper, we outline the analytical properties of needlets and discuss the\nmain features of the numerical code, which should be a valuable addition to the\nCMB analyst's toolbox. \n\n"}
{"id": "1010.4337", "contents": "Title: Pulsar timing arrays as imaging gravitational wave telescopes: angular\n  resolution and source (de)confusion Abstract: Pulsar timing arrays (PTAs) will be sensitive to a finite number of\ngravitational wave (GW) \"point\" sources (e.g. supermassive black hole\nbinaries). N quiet pulsars with accurately known distances d_{pulsar} can\ncharacterize up to 2N/7 distant chirping sources per frequency bin \\Delta\nf_{gw}=1/T, and localize them with \"diffraction limited\" precision \\delta\\theta\n\\gtrsim (1/SNR)(\\lambda_{gw}/d_{pulsar}). Even if the pulsar distances are\npoorly known, a PTA with F frequency bins can still characterize up to\n(2N/7)[1-(1/2F)] sources per bin, and the quasi-singular pattern of timing\nresiduals in the vicinity of a GW source still allows the source to be\nlocalized quasi-topologically within roughly the smallest quadrilateral of\nquiet pulsars that encircles it on the sky, down to a limiting resolution\n\\delta\\theta \\gtrsim (1/SNR) \\sqrt{\\lambda_{gw}/d_{pulsar}}. PTAs may be\nunconfused, even at the lowest frequencies, with matched filtering always\nappropriate. \n\n"}
{"id": "1011.1559", "contents": "Title: A study of relative velocity statistics in Lagrangian perturbation\n  theory with PINOCCHIO Abstract: Subject of this paper is a detailed analysis of the PINOCCHIO algorithm for\nstudying the relative velocity statistics of merging haloes in Lagrangian\nperturbation theory. Given a cosmological background model, a power spectrum of\nfluctuations as well as a Gaussian linear density contrast field $\\delta_{\\rm\nl}$ is generated on a cubic grid, which is then smoothed repeatedly with\nGaussian filters. For each Lagrangian particle at position $\\bmath{q}$ and each\nsmoothing radius $R$, the collapse time, the velocities and ellipsoidal\ntruncation are computed using Lagrangian Perturbation Theory. The collapsed\nmedium is then fragmented into isolated objects by an algorithm designed to\nmimic the accretion and merger events of hierarchical collapse. Directly after\nthe fragmentation process the mass function, merger histories of haloes and the\nstatistics of the relative velocities at merging are evaluated. We\nreimplemented the algorithm in C++, recovered the mass function and optimised\nthe construction of halo merging histories. Comparing our results with the\noutput of the Millennium simulation suggests that PINOCCHIO is well suited for\nstudying relative velocities of merging haloes and is able to reproduce the\npairwise velocity distribution. \n\n"}
{"id": "1011.1893", "contents": "Title: Extended atmospheres of AGB stars: modeling and measurement Abstract: Encoded in the time- and wavelength dependent properties of pulsating AGB\nstars are the underlying fundamental parameters of mass, composition and\nevolutionary state. However, the standard technique of placing stars on a HR\ndiagram, even with the aid of pulsation periods, can not be done easily for\nextended AGB stars, because of the difficulty of defining a radius or\ntemperature. The atmospheres of Mira variables are so extended that the optical\ndepth unity radius can vary by a factor of ~3 over the energetically important\nregion of the spectrum. Many important constituents in the radiative transfer\nare far from local thermodynamic equilibrium, and for the coolest stars, the\nprocess of dust formation and destruction requires a time-dependent model of\ngrain growth. I will describe the challenges and some of the solutions to\nmodeling these atmospheres, and describe the utility of different kinds of\nobservations in helping understand both fundamental parameters and chaotic\nprocesses in complex AGB atmospheres. \n\n"}
{"id": "1011.2319", "contents": "Title: Preliminary results of a WIMP search with EDELWEISS-II cryogenic\n  detectors Abstract: The EDELWEISS-II experiment uses cryogenic heat-and-ionization detectors in\norder to detect the rare interactions from possible WIMP dark matter particles\non Germanium nuclei. Recently, new-generation detectors with an interleaved\nelectrode geometry were developped and validated, enabling an outstanding\nrejection of gamma-rays and surface interactions. We present here preliminary\nresults of a one-year WIMP search carried out with ten of such detectors in the\nLaboratoire Souterrain de Modane. A sensitivity to the spin-independent\nWIMP-nucleon cross-section of 5 \\times 10-8 pb was achieved using a 322 kg \n\n"}
{"id": "1011.2321", "contents": "Title: Polarised foreground removal at low radio frequencies using rotation\n  measure synthesis: uncovering the signature of hydrogen reionisation Abstract: Measurement of redshifted 21-cm emission from neutral hydrogen promises to be\nthe most effective method for studying the reionisation history of hydrogen\nand, indirectly, the first galaxies. These studies will be limited not by raw\nsensitivity to the signal, but rather, by bright foreground radiation from\nGalactic and extragalactic radio sources and the Galactic continuum. In\naddition, leakage due to gain errors and non-ideal feeds conspire to further\ncontaminate low-frequency radio obsevations. This leakage leads to a portion of\nthe complex linear polarisation signal finding its way into Stokes I, and\ninhibits the detection of the non-polarised cosmological signal from the epoch\nof reionisation. In this work, we show that rotation measure synthesis can be\nused to recover the signature of cosmic hydrogen reionisation in the presence\nof contamination by polarised foregrounds. To achieve this, we apply the\nrotation measure synthesis technique to the Stokes I component of a synthetic\ndata cube containing Galactic foreground emission, the effect of instrumental\npolarisation leakage, and redshifted 21-cm emission by neutral hydrogen from\nthe epoch of reionisation. This produces an effective Stokes I Faraday\ndispersion function for each line of sight, from which instrumental\npolarisation leakage can be fitted and subtracted. Our results show that it is\npossible to recover the signature of reionisation in its late stages (z ~ 7) by\nway of the 21-cm power spectrum, as well as through tomographic imaging of\nionised cavities in the intergalactic medium. \n\n"}
{"id": "1011.2530", "contents": "Title: Do micro brown dwarf detections explain the galactic dark matter? Abstract: Context: The baryonic dark matter dominating the structures of galaxies is\nwidely considered as mysterious, but hints for it have been in fact detected in\nseveral astronomical observations at optical, infrared, and radio wavelengths.\nWe call attention to the nature of galaxy merging, the observed rapid\nmicrolensing of a quasar, the detection of \"cometary knots\" in planetary\nnebulae, and the Lyman-alpha clouds as optical phenomena revealing the compact\nobjects. Radio observations of \"extreme scattering events\" and \"parabolic arcs\"\nand microwave observations of \"cold dust cirrus\" clouds are observed at 15 - 20\nK temperatures are till now not considered in a unifying picture. Aims: The\ntheory of gravitational hydrodynamics predicts galactic dark matter arises from\nJeans clusters that are made up of almost a trillion micro brown dwarfs (mBDs)\nof earth weight. It is intended to explain the aforementioned anomalous\nobservations and to make predictions within this framework. Methods: We employ\nanalytical isothermal modeling to estimate various effects. Results: Estimates\nof their total number show that they comprise enough mass to constitute the\nmissing baryonic matter. Mysterious radio events are explained by mBD pair\nmerging in the Galaxy. The \"dust\" temperature of cold galaxy halos arises from\na thermostat setting due to a slow release of latent heat at the 14 K gas to\nsolid transition at the mBD surface. The proportionality of the central black\nhole mass of a galaxy and its number of globular clusters is explained. The\nvisibility of an early galaxy at redshift 8.6 is obvious with most hydrogen\nlocked up in mBDs. Conclusions: Numerical simulations of various steps would\nfurther test the approach. It looks promising to redo MACHO searches against\nthe Magellanic clouds. \n\n"}
{"id": "1011.3052", "contents": "Title: Magnetic Inelastic Dark Matter: Directional Signals Without a\n  Directional Detector Abstract: The magnetic inelastic dark matter (MiDM) model, in which dark matter\ninelastically scatters off nuclei through a magnetic dipole interaction, has\npreviously been shown to reconcile the DAMA/LIBRA annual modulation signal with\nnull results from other experiments. In this work, we explore the unique\ndirectional detection signature of MiDM. After the dark matter scatters into\nits excited state, it decays with a lifetime of order 1 microsecond and emits a\nphoton with energy ~100 keV. Both the nuclear recoil and the corresponding\nemitted photon can be detected by studying delayed coincidence events. The\nrecoil track and velocity of the excited state can be reconstructed from the\nnuclear interaction vertex and the photon decay vertex. The angular\ndistribution of the WIMP recoil tracks is sharply peaked and modulates daily.\nIt is therefore possible to observe the directional modulation of WIMP-nucleon\nscattering without a large-volume gaseous directional detection experiment.\nFurthermore, current experiments such as XENON100 can immediately measure this\ndirectional modulation and constrain the MiDM parameter space with an exposure\nof a few thousand kg day. \n\n"}
{"id": "1011.4148", "contents": "Title: THINGS about MOND Abstract: We present the analysis of 12 high-resolution galactic rotation curves from\nThe HI Nearby Galaxy Survey (THINGS) in the context of modified Newtonian\ndynamics (MOND). These rotation curves were selected to be the most reliable\nfor mass modelling, and they are the highest quality rotation curves currently\navailable for a sample of galaxies spanning a wide range of luminosities. We\nfit the rotation curves with the \"simple\" and \"standard\" interpolating\nfunctions of MOND, and we find that the \"simple\" function yields better\nresults. We also redetermine the value of a0, and find a median value very\nclose to the one determined in previous studies, a0 = (1.22 +- 0.33) x 10^{-8}\ncm/s^2. Leaving the distance as a free parameter within the uncertainty of its\nbest independently determined value leads to excellent quality fits for 75% of\nthe sample. Among the three exceptions, two are also known to give relatively\npoor fits also in Newtonian dynamics plus dark matter. The remaining case (NGC\n3198), presents some tension between the observations and the MOND fit, which\nmight however be explained by the presence of non-circular motions, by a small\ndistance, or by a value of a0 at the lower end of our best-fit interval, 0.9 x\n10^{-8} cm/s^2. The best-fit stellar M/L ratios are generally in remarkable\nagreement with the predictions of stellar population synthesis models. We also\nshow that the narrow range of gravitational accelerations found to be generated\nby dark matter in galaxies is consistent with the narrow range of additional\ngravity predicted by MOND. \n\n"}
{"id": "1012.0849", "contents": "Title: Physics and astrophysics with gamma-ray telescopes Abstract: In the past few years gamma-ray astronomy has entered a golden age. A modern\nsuite of telescopes is now scanning the sky over both hemispheres and over six\norders of magnitude in energy. At $\\sim$TeV energies, only a handful of sources\nwere known a decade ago, but the current generation of ground-based imaging\natmospheric Cherenkov telescopes (H.E.S.S., MAGIC, and VERITAS) has increased\nthis number to nearly one hundred. With a large field of view and duty cycle,\nthe Tibet and Milagro air shower detectors have demonstrated the promise of the\ndirect particle detection technique for TeV gamma rays. At $\\sim$GeV energies,\nthe Fermi Gamma-ray Space Telescope has increased the number of known sources\nby nearly an order of magnitude in its first year of operation. New classes of\nsources that were previously theorized to be gamma-ray emitters have now been\nconfirmed observationally. Moreover, there have been surprise discoveries of\nGeV gamma-ray emission from source classes for which no theory predicted it was\npossible. In addition to elucidating the processes of high-energy astrophysics,\ngamma-ray telescopes are making essential contributions to fundamental physics\ntopics including quantum gravity, gravitational waves, and dark matter. I\nsummarize the current census of astrophysical gamma-ray sources, highlight some\nrecent discoveries relevant to fundamental physics, and describe the synergetic\nconnections between gamma-ray and neutrino astronomy. This is a brief overview\nintended in particular for particle physicists and neutrino astronomers, based\non a presentation at the Neutrino 2010 conference in Athens, Greece. I focus in\nparticular on results from Fermi (which was launched soon after Neutrino 2008),\nand conclude with a description of the next generation of instruments, namely\nHAWC and the Cherenkov Telescope Array. \n\n"}
{"id": "1012.0871", "contents": "Title: Measured redshift invariance of photon velocity Abstract: We report the first direct photon velocity measurements for extragalactic\nobjects. A fiber-optic, photon time-of-flight instrument, optimized for\nrelatively dim sources ($m 12$), is used to measure the velocity of visible\nphotons emanating from galaxies and quasars. Lightspeed is found to be\n$3.00\\pm0.03\\times10^{8} \\mathrm{m s}^{-1}$, and is invariant, within\nexperimental error, over the range of redshifts measured ($0\\leq z\\leq1.33$).\nThis measurement provides additional validation of Einstein's theory of General\nRelativity (GR) and is consistent with the\nFriedmann-Lema\\^{i}tre-Robertson-Walker (FLRW) metricl, as well as several\nalternative cosmological models, notably the hyperbolic anti-de Sitter metric,\nthough not with the pseudo-Euclidean de Sitter metric. \n\n"}
{"id": "1012.1106", "contents": "Title: Biased total mass of cool core galaxy clusters by Sunyaev-Zel'dovich\n  effect measurements Abstract: The Sunyaev Zel'dovich (SZ) effect from galaxy clusters is one of the most\npowerful cosmological tools for investigating the large-scale Universe. The big\nadvantage of the SZ effect is its redshift independence, which is not the case\nfor visible and X-ray observations. It allows us to directly estimate the\ncluster's total mass from the integrated comptonization parameter Y, even for\ndistant clusters. However, not having a full knowing intra-cluster medium (ICM)\nphysics can affect the results. By taking self-similar temperature and density\nprofiles of the ICM into account, we studied how different ICM morphologies can\naffect the cluster total mass estimation. With the help of the high percentage\nof cool core (CC) clusters, as observed so far, the present analysis focuses on\nstudying this class of objects. A sample of eight nearby (0.1 < z < 0.5) and\nhigh-mass (M > 10^(14) M_sun) clusters observed by Chandra was considered. We\nsimulated SZ observations of these clusters through X-ray derived information\nand analyzed the mock SZ data again with the simplistic assumption of an\nisothermal beta-model profile for the ICM. The bias on the recovered cluster\ntotal mass using different sets of assumptions is estimated to be 50% higher in\nthe case of hydrostatic equilibrium. Possible contributions to the total bias\ndue to the line-of-sight integration and the considered ICM template are taken\ninto account. The large biases on total mass recovery firmly support, if still\nnecessary, cluster modeling based on more sophisticated universal profiles as\nderived by X-ray observations of local objects and hydrodynamical simulations. \n\n"}
{"id": "1012.1655", "contents": "Title: A Pilot Study for the SCUBA-2 'All-Sky' Survey Abstract: We have carried out a pilot study for the SCUBA-2 'All-Sky' Survey, SASSy, a\nwide and shallow mapping project at 850 microns, designed to find rare objects,\nboth Galactic and extragalactic. Two distinct sets of exploratory observations\nwere undertaken, and used to test the SASSy approach and data reduction\npipeline. The first was a 0.5 by 0.5 degrees map around the nearby galaxy NGC\n2559. The galaxy was easily detected at 156 mJy, but no other convincing\nsources are present in the map. Comparison with other galaxies with similar\nwavelength coverage indicates that NGC 2559 has relatively warm dust. The\nsecond observations cover 1 square degree around the W5-E HII region. As well\nas diffuse structure in the map, a filtering approach was able to extract 27\ncompact sources with signal-to-noise greater than 6. By matching with data at\nother wavelengths we can see that the SCUBA-2 data can be used to discriminate\nthe colder cores. Together these observations show that the SASSy project will\nbe able to meet its original goals of detecting new bright sources which will\nbe ideal for follow-up observations with other facilities. \n\n"}
{"id": "1012.2938", "contents": "Title: Modeling the Magnetic Field in the Galactic Disk using New Rotation\n  Measure Observations from the Very Large Array Abstract: We have determined 194 Faraday rotation measures (RMs) of polarized\nextragalactic radio sources using new, multi-channel polarization observations\nat frequencies around 1.4 GHz from the Very Large Array (VLA) in the Galactic\nplane at $17^\\circ \\leq l \\leq 63^\\circ$ and $205^\\circ \\leq l \\leq 253^\\circ$.\nThis catalog fills in gaps in the RM coverage of the Galactic plane between the\nCanadian Galactic Plane Survey and Southern Galactic Plane Survey. Using this\ncatalog we have tested the validity of recently-proposed axisymmetric and\nbisymmetric models of the large-scale (or regular) Galactic magnetic field, and\nfound that of the existing models we tested, an axisymmetric spiral model with\nreversals occurring in rings (as opposed to along spiral arms) best matched our\nobservations. Building on this, we have performed our own modeling, using RMs\nfrom both extragalactic sources and pulsars. By developing independent models\nfor the magnetic field in the outer and inner Galaxy, we conclude that in the\ninner Galaxy, the magnetic field closely follows the spiral arms, while in the\nouter Galaxy, the field is consistent with being purely azimuthal.Furthermore,\nthe models contain no reversals in the outer Galaxy, and together seem to\nsuggest the existence of a single reversed region that spirals out from the\nGalactic center. \n\n"}
{"id": "1012.3807", "contents": "Title: Ion-Channeling in Direct Dark Matter Crystalline Detectors Abstract: The channeling of the recoiling nucleus in crystalline detectors after a WIMP\ncollision would produce a larger scintillation or ionization signal in direct\ndetection experiments than otherwise expected. I present estimates of the\nimportance of this effect in NaI, Si and Ge crystals, using analytic models\ndeveloped from the 1960's onwards to describe channeling and blocking effects. \n\n"}
{"id": "1012.5299", "contents": "Title: Caching and Interpolated Likelihoods: Accelerating Cosmological Monte\n  Carlo Markov Chains Abstract: We describe a novel approach to accelerating Monte Carlo Markov Chains. Our\nfocus is cosmological parameter estimation, but the algorithm is applicable to\nany problem for which the likelihood surface is a smooth function of the free\nparameters and computationally expensive to evaluate. We generate a high-order\ninterpolating polynomial for the log-likelihood using the first points gathered\nby the Markov chains as a training set. This polynomial then accurately\ncomputes the majority of the likelihoods needed in the latter parts of the\nchains. We implement a simple version of this algorithm as a patch (InterpMC)\nto CosmoMC and show that it accelerates parameter estimatation by a factor of\nbetween two and four for well-converged chains. The current code is primarily\nintended as a \"proof of concept\", and we argue that there is considerable room\nfor further performance gains. Unlike other approaches to accelerating\nparameter fits, we make no use of precomputed training sets or special choices\nof variables, and InterpMC is almost entirely transparent to the user. \n\n"}
{"id": "1012.5335", "contents": "Title: Hubble parameter reconstruction from a principal component analysis:\n  minimizing the bias Abstract: A model-independent reconstruction of the cosmic expansion rate is essential\nto a robust analysis of cosmological observations. Our goal is to demonstrate\nthat current data are able to provide reasonable constraints on the behavior of\nthe Hubble parameter with redshift, independently of any cosmological model or\nunderlying gravity theory. Using type Ia supernova data, we show that it is\npossible to analytically calculate the Fisher matrix components in a Hubble\nparameter analysis without assumptions about the energy content of the\nUniverse. We used a principal component analysis to reconstruct the Hubble\nparameter as a linear combination of the Fisher matrix eigenvectors (principal\ncomponents). To suppress the bias introduced by the high redshift behavior of\nthe components, we considered the value of the Hubble parameter at high\nredshift as a free parameter. We first tested our procedure using a mock sample\nof type Ia supernova observations, we then applied it to the real data compiled\nby the Sloan Digital Sky Survey (SDSS) group. In the mock sample analysis, we\ndemonstrate that it is possible to drastically suppress the bias introduced by\nthe high redshift behavior of the principal components. Applying our procedure\nto the real data, we show that it allows us to determine the behavior of the\nHubble parameter with reasonable uncertainty, without introducing any ad-hoc\nparameterizations. Beyond that, our reconstruction agrees with completely\nindependent measurements of the Hubble parameter obtained from red-envelope\ngalaxies. \n\n"}
{"id": "1012.5661", "contents": "Title: Boosting jet power in black hole spacetimes Abstract: The extraction of rotational energy from a spinning black hole via the\nBlandford-Znajek mechanism has long been understood as an important component\nin models to explain energetic jets from compact astrophysical sources. Here we\nshow more generally that the kinetic energy of the black hole, both rotational\nand translational, can be tapped, thereby producing even more luminous jets\npowered by the interaction of the black hole with its surrounding plasma. We\nstudy the resulting Poynting jet that arises from single boosted black holes\nand binary black hole systems. In the latter case, we find that increasing the\norbital angular momenta of the system and/or the spins of the individual black\nholes results in an enhanced Poynting flux. \n\n"}
{"id": "1101.0701", "contents": "Title: Filter Design for the Detection/Estimation of the Modulus of a Vector.\n  Application to Polarization Data Abstract: We consider a set of M images, whose pixel intensities at a common point can\nbe treated as the components of a M-dimensional vector. We are interested in\nthe estimation of the modulus of such a vector associated to a compact source.\nFor instance, the detection/estimation of the polarized signal of compact\nsources immersed in a noisy background is relevant in some fields like\nAstrophysics. We develop two different techniques, one based on the Maximum\nLikelihood Estimator (MLE) applied to the modulus distribution, the modulus\nfilter (ModF) and other based on prefiltering the components before fusion, the\nfiltered fusion (FF), to deal with this problem. We present both methods in the\ngeneral case of M images and apply them to the particular case of three images\n(linear plus circular polarization). Numerical simulations have been performed\nto test these filters considering polarized compact sources immersed in\nstationary noise. The FF performs better than the ModF in terms of errors in\nthe estimated amplitude and position of the source, especially in the low\nsignal-to-noise case. We also compare both methods with the direct application\nof a matched filter (MF) on the polarization data. This last technique is\nclearly outperformed by the new methods. \n\n"}
{"id": "1101.0818", "contents": "Title: Extragalactic Fields Optimized for Adaptive Optics Abstract: In this paper we present the coordinates of 67 55' x 55' patches of sky which\nhave the rare combination of both high stellar surface density (>0.5\narcmin^{-2} with 13<R<16.5 mag) and low extinction (E(B-V)<0.1). These fields\nare ideal for adaptive-optics based follow-up of extragalactic targets. One\nregion of sky, situated near Baade's Window, contains most of the patches we\nhave identified. Our optimal field, centered at RA: 7h24m3s, Dec: -1deg27'15\",\nhas an additional advantage of being accessible from both hemispheres. We\npropose a figure of merit for quantifying real-world adaptive optics\nperformance, and use this to analyze the performance of multi-conjugate\nadaptive optics in these fields. We also compare our results to those that\nwould be obtained in existing deep fields. In some cases adaptive optics\nobservations undertaken in the fields given in this paper would be orders of\nmagnitude more efficient than equivalent observations undertaken in existing\ndeep fields. \n\n"}
{"id": "1101.1676", "contents": "Title: Study of possible systematics in the L*X - Ta* correlation of Gamma Ray\n  Bursts Abstract: Gamma Ray Bursts (GRBs) are the most energetic sources in the universe and\namong the farthest known astrophysical sources. These features make them\nappealing candidates as standard candles for cosmological applications so that\nstudying the physical mechanisms for the origin of the emission and\ncorrelations among their observable properties is an interesting task. We\nconsider here the luminosity L*X - break time Ta* (hereafter LT) correlation\nand investigate whether there are systematics induced by selection effects or\nredshift dependent calibra- tion. We perform this analysis both for the full\nsample of 77 GRBs with known redshift and for the subsample of GRBs having\ncanonical X-ray light curves, hereafter called U0095 sample. We do not find any\nsystematic bias thus con- firming the existence of physical GRB subclasses\nrevealed by tight correlations of their afterglow properties. Furthermore, we\nstudy the possibility of applying the LT correlation as a redshift estimator\nboth for the full distribution and for the canonical lightcurves. The large\nuncertainties and the non negligible intrin- sic scatter make the results not\nso encouraging, but there are nevertheless some hints motivating a further\nanalysis with an increased U0095 sample. \n\n"}
{"id": "1101.1969", "contents": "Title: Electromagnetic extraction of energy from black hole-neutron star\n  binaries Abstract: The coalescence of black hole-neutron star binaries is expected to be a\nprincipal source of gravitational waves for the next generation of detectors,\nAdvanced LIGO and Advanced Virgo. Ideally, these and other gravitational wave\nsources would have a distinct electromagnetic counterpart, as significantly\nmore information could be gained through two separate channels. In addition,\nsince these detectors will probe distances with non-negligible redshift, a\ncoincident observation of an electromagnetic counterpart to a gravitational\nwave signal would facilitate a novel measurement of dark energy [1]. For black\nhole masses not much larger than the neutron star mass, the tidal disruption\nand subsequent accretion of the neutron star by the black hole provides one\navenue for generating an electromagnetic counterpart [2]. However, in this\nwork, we demonstrate that, for all black hole-neutron star binaries observable\nby Advanced LIGO/Virgo, the interaction of the black hole with the magnetic\nfield of the neutron star will drive a Poynting flux. This Poynting flux\ngenerates synchrotron/curvature radiation as the electron-positron plasma in\nthe neutron star magnetosphere is accel- erated, and thermal radiation as the\nplasma is focused onto the neutron star magnetic poles, creating a \"hot spot\"\non the neutron star surface. This novel effect will gener- ate copious\nluminosity, comparable to supernovae and active galactic nuclei, so that black\nhole-neutron star coalescences detectable with gravitational waves by Advanced\nLIGO/Virgo could also potentially be detectable electromagnetically. \n\n"}
{"id": "1101.4011", "contents": "Title: The Efficacy of Galaxy Shape Parameters in Photometric Redshift\n  Estimation: A Neural Network Approach Abstract: We present a determination of the effects of including galaxy morphological\nparameters in photometric redshift estimation with an artificial neural network\nmethod. Neural networks, which recognize patterns in the information content of\ndata in an unbiased way, can be a useful estimator of the additional\ninformation contained in extra parameters, such as those describing morphology,\nif the input data are treated on an equal footing. We use imaging and five band\nphotometric magnitudes from the All-wavelength Extended Groth Strip\nInternational Survey. It is shown that certain principal components of the\nmorphology information are correlated with galaxy type. However, we find that\nfor the data used the inclusion of morphological information does not have a\nstatistically significant benefit for photometric redshift estimation with the\ntechniques employed here. The inclusion of these parameters may result in a\ntrade-off between extra information and additional noise, with the additional\nnoise becoming more dominant as more parameters are added. \n\n"}
{"id": "1101.4635", "contents": "Title: How Future Space-Based Weak Lensing Surveys Might Obtain Photometric\n  Redshifts Independently Abstract: We study how the addition of on-board optical photometric bands to future\nspace-based weak lensing instruments could affect the photometric redshift\nestimation of galaxies, and hence improve estimations of the dark energy\nparameters through weak lensing. Basing our study on the current proposed\nEuclid configuration and using a mock catalog of galaxy observations, various\non-board options are tested and compared with the use of ground-based\nobservations from the Large Synoptic Survey Telescope (LSST) and Pan-STARRS.\nComparisons are made through the use of the dark energy Figure of Merit, which\nprovides a quantifiable measure of the change in the quality of the scientific\nresults that can be obtained in each scenario. Effects of systematic offsets\nbetween LSST and Euclid photometric calibration are also studied. We find that\nadding two (U and G) or even one (U) on-board optical band-passes to the\nspace-based infrared instrument greatly improves its photometric redshift\nperformance, bringing it close to the level that would be achieved by combining\nobservations from both space-based and ground-based surveys while freeing the\nspace mission from reliance on external datasets. \n\n"}
{"id": "1101.5255", "contents": "Title: Cosmological-model-independent tests for the distance-duality relation\n  from Galaxy Clusters and Type Ia Supernova Abstract: We perform a cosmological-model-independent test for the distance-duality\n(DD) relation $\\eta(z)=D_L(z)(1+z)^{-2}/D_A(z)$, where $D_L$ and $D_A$ are the\nluminosity distance and angular diameter distance respectively, with a\ncombination of observational data for $D_L$ taken from the latest Union2 SNe Ia\nand that for $D_A$ provided by two galaxy clusters samples compiled by De\nFilippis {\\it et al.} and Bonamente {\\it et al.}. Two parameterizations for\n$\\eta(z)$, i.e., $\\eta(z)=1+\\eta_0z$ and $\\eta(z)=1+\\eta_0z/(1+z)$, are used.\nWe find that the DD relation can be accommodated at $1\\sigma$ confidence level\n(CL) for the De Filippis {\\it et al.} sample and at $3\\sigma$ CL for the\nBonamente {\\it et al.} sample. We also examine the DD relation by postulating\ntwo more general parameterizations: $\\eta(z)=\\eta_0+\\eta_1z$ and\n$\\eta(z)=\\eta_0+\\eta_1z/(1+z)$, and find that the DD relation is compatible\nwith the results from the De Filippis {\\it et al.} and the Bonamente {\\it et\nal.} samples at $1\\sigma$ and $2\\sigma$ CLs, respectively. Thus, we conclude\nthat the DD relation is compatible with present observations. \n\n"}
{"id": "1101.5306", "contents": "Title: Gravitational and electromagnetic emission by magnetized coalescing\n  binary systems Abstract: We discuss the possibility to obtain an electromagnetic emission accompanying\nthe gravitational waves emitted in the coalescence of a compact binary system.\nMotivated by the existence of black hole configurations with open magnetic\nfield lines along the rotation axis, we consider a magnetic dipole in the\nsystem, the evolution of which leads to (i) electromagnetic radiation, and (ii)\na contribution to the gravitational radiation, the luminosity of both being\nevaluated. Starting from the observations on magnetars, we impose upper limits\nfor both the electromagnetic emission and the contribution of the magnetic\ndipole to the gravitational wave emission. Adopting this model for the\nevolution of neutron star binaries leading to short gamma ray bursts, we\ncompare the correction originated by the electromagnetic field to the\ngravitational waves emission, finding that they are comparable for particular\nvalues of the magnetic field and of the orbital radius of the binary system.\nFinally we calculate the electromagnetic and gravitational wave energy outputs\nwhich result comparable for some values of magnetic field and radius. \n\n"}
{"id": "1101.5626", "contents": "Title: A terrestrial search for dark contents of the vacuum, such as dark\n  energy, using atom interferometry Abstract: We describe the theory and first experimental work on our concept for\nsearching on earth for the presence of dark content of the vacuum (DCV) using\natom interferometry. Specifically, we have in mind any DCV that has not yet\nbeen detected on a laboratory scale, but might manifest itself as dark energy\non the cosmological scale. The experimental method uses two atom\ninterferometers to cancel the effect of earth's gravity and diverse noise\nsources. It depends upon two assumptions: first, that the DCV possesses some\nspace inhomogeneity in density, and second that it exerts a sufficiently strong\nnon-gravitational force on matter. The motion of the apparatus through the DCV\nshould then lead to an irregular variation in the detected matter-wave phase\nshift. We discuss the nature of this signal and note the problem of\ndistinguishing it from instrumental noise. We also discuss the relation of our\nexperiment to what might be learned by studying the noise in gravitational wave\ndetectors such as LIGO.The paper concludes with a projection that a future\nsearch of this nature might be carried out using an atom interferometer in an\norbiting satellite. The apparatus is now being constructed. \n\n"}
{"id": "1102.0007", "contents": "Title: Cosmology with Hypervelocity Stars Abstract: In the standard cosmological model, the merger remnant of the Milky Way and\nAndromeda (Milkomeda) will be the only galaxy remaining within our event\nhorizon once the Universe has aged by another factor of ten, ~10^{11} years\nafter the Big Bang. After that time, the only extragalactic sources of light in\nthe observable cosmic volume will be hypervelocity stars being ejected\ncontinuously from Milkomeda. Spectroscopic detection of the velocity-distance\nrelation or the evolution in the Doppler shifts of these stars will allow a\nprecise measurement of the vacuum mass density as well as the local matter\ndistribution. Already in the near future, the next generation of large\ntelescopes will allow photometric detection of individual stars out to the edge\nof the Local Group, and may target the ~10^{5+-1} hypervelocity stars that\noriginated in it as cosmological tracers. \n\n"}
{"id": "1102.0559", "contents": "Title: Spider Optimization II: Optical, Magnetic and Foreground Effects Abstract: Spider is a balloon-borne instrument designed to map the polarization of the\ncosmic microwave background (CMB) with degree-scale resolution over a large\nfraction of the sky. Spider's main goal is to measure the amplitude of\nprimordial gravitational waves through their imprint on the polarization of the\nCMB if the tensor-to-scalar ratio, r, is greater than 0.03. To achieve this\ngoal, instrumental systematic errors must be controlled with unprecedented\naccuracy. Here, we build on previous work to use simulations of Spider\nobservations to examine the impact of several systematic effects that have been\ncharacterized through testing and modeling of various instrument components. In\nparticular, we investigate the impact of the non-ideal spectral response of the\nhalf-wave plates, coupling between focal plane components and the Earth's\nmagnetic field, and beam mismatches and asymmetries. We also present a model of\ndiffuse polarized foreground emission based on a three-dimensional model of the\nGalactic magnetic field and dust, and study the interaction of this foreground\nemission with our observation strategy and instrumental effects. We find that\nthe expected level of foreground and systematic contamination is sufficiently\nlow for Spider to achieve its science goals. \n\n"}
{"id": "1102.1159", "contents": "Title: A universal ultraviolet-optical colour-colour-magnitude relation of\n  galaxies Abstract: Although the optical colour-magnitude diagram of galaxies allows one to\nselect red sequence objects, neither can it be used for galaxy classification\nwithout additional observational data such as spectra or high-resolution\nimages, nor to identify blue galaxies at unknown redshifts. We show that adding\nthe near ultraviolet colour to the optical CMD reveals a tight relation in the\nthree-dimensional colour-colour-magnitude space smoothly continuing from the\n\"blue cloud\" to the \"red sequence\". We found that 98 per cent of 225,000\nlow-redshift (Z<0.27) galaxies follow a smooth surface g-r=F(M,NUV-r) with a\nstandard deviation of 0.03-0.07 mag making it the tightest known galaxy\nphotometric relation. There is a strong correlation between morphological types\nand integrated NUV-r colours. Rare galaxy classes such as E+A or tidally\nstripped systems become outliers that occupy distinct regions in the 3D\nparameter space. Using stellar population models for galaxies with different\nSFHs, we show that (a) the (NUV-r, g-r) distribution is formed by objects\nhaving constant and exponentially declining SFR with different characteristic\ntimescales; (b) colour evolution for exponentially declining models goes along\nthe relation suggesting its weak evolution up-to a redshift of 0.9; (c)\ngalaxies with truncated SFHs have very short transition phase offset from the\nrelation thus explaining the rareness of E+A galaxies. This relation can be\nused as a powerful galaxy classification tool when morphology remains\nunresolved. Its mathematical consequence is the photometric redshift estimates\nfrom 3 broad-band photometric points. This approach works better than most\nexisting photometric redshift techniques applied to multi-colour datasets.\nTherefore, the relation can be used as an efficient selection technique for\ngalaxies at intermediate redshifts (0.3<Z<0.8) using optical imaging surveys. \n\n"}
{"id": "1102.2230", "contents": "Title: On detection of the stochastic gravitational-wave background using the\n  Parkes pulsar timing array Abstract: We search for the signature of an isotropic stochastic gravitational-wave\nbackground in pulsar timing observations using a frequency-domain correlation\ntechnique. These observations, which span roughly 12 yr, were obtained with the\n64-m Parkes radio telescope augmented by public domain observations from the\nArecibo Observatory. A wide range of signal processing issues unique to pulsar\ntiming and not previously presented in the literature are discussed. These\ninclude the effects of quadratic removal, irregular sampling, and variable\nerrors which exacerbate the spectral leakage inherent in estimating the steep\nred spectrum of the gravitational-wave background. These observations are found\nto be consistent with the null hypothesis, that no gravitational-wave\nbackground is present, with 76 percent confidence. We show that the detection\nstatistic is dominated by the contributions of only a few pulsars because of\nthe inhomogeneity of this data set. The issues of detecting the signature of a\ngravitational-wave background with future observations are discussed. \n\n"}
{"id": "1102.2784", "contents": "Title: A New Limit on Planck Scale Lorentz Violation from Gamma-ray Burst\n  Polarization Abstract: Constraints on possible Lorentz invariance violation (LIV) to first order in\n$E/M_{\\rm Planck}$ for photons in the framework of effective field theory (EFT)\nare discussed, taking cosmological factors into account. Then, using the\nreported detection of polarized soft $\\gamma$-ray emission from the\n$\\gamma$-ray burst GRB041219a that is indicative of an absence of vacuum\nbirefringence, together with a very recent improved method for estimating the\nredshift of the burst, we derive constraints on the dimension 5 Lorentz\nviolating modification to the Lagrangian of an effective local QFT for QED. Our\nnew constraints are more than five orders of magnitude better than recent\nconstraints from observations of the Crab Nebula. We obtain the upper limit on\nthe Lorentz violating dimension 5 EFT parameter $|\\xi|$ of $2.4 \\times\n10^{-15}$, corresponding to a constraint on the dimension 5 standard model\nextension parameter, $k^{(5)}_{(V)00} \\le 4.2 \\times 10^{-34}$ GeV$^{-1}$. \n\n"}
{"id": "1102.2857", "contents": "Title: The Capra Research Program for Modelling Extreme Mass Ratio Inspirals Abstract: Suppose a small compact object (black hole or neutron star) of mass $m$\norbits a large black hole of mass $M \\gg m$. This system emits gravitational\nwaves (GWs) that have a radiation-reaction effect on the particle's motion.\nEMRIs (extreme--mass-ratio inspirals) of this type will be important GW sources\nfor LISA; LISA's data analysis will require highly accurate EMRI GW templates.\nIn this article I outline the \"Capra\" research program to try to model EMRIs\nand calculate their GWs \\textit{ab initio}, assuming only that $m \\ll M$ and\nthat the Einstein equations hold. Here we treat the EMRI spacetime as a\nperturbation of the large black hole's \"background\" (Schwarzschild or Kerr)\nspacetime and use the methods of black-hole perturbation theory, expanding in\nthe small parameter $m/M$. The small body's motion can be described either as\nthe result of a radiation-reaction \"self-force\" acting in the background\nspacetime or as geodesic motion in a perturbed spacetime. Several different\nlines of reasoning lead to the (same) basic $\\O(m/M)$ \"MiSaTaQuWa\" equations of\nmotion for the particle. Surprisingly, for a nonlinear field theory such as\ngeneral relativity, modelling the small body as a point particle works well.\nThe particle's own field is singular along the particle worldline so it's\ndifficult to formulate a meaningful \"perturbation\" theory or equations of\nmotion there. I discuss \"mode-sum\" and \"puncture-function\" regularization\nschemes that resolve this difficulty and allow practical self-force\ncalculations, and I outline an important recent calculation of this type.\n  Most Capra research to date has used 1st order perturbation theory. To obtain\nthe very high accuracies needed to fully exploit LISA's observations of the\nstrongest EMRIs, 2nd order perturbation theory will probably be needed. \n\n"}
{"id": "1102.3264", "contents": "Title: Global e-VLBI observations of the gamma-ray narrow line Seyfert 1 PMN\n  J0948+0022 Abstract: There is growing evidence of relativistic jets in radio-loud narrow-line\nSeyfert 1 (RL-NLS1) galaxies. We constrain the observational properties of the\nradio emission in the first RL-NLS1 galaxy ever detected in gamma-rays, PMN\nJ0948+0022, i.e., its flux density and structure in total intensity and in\npolarization, its compactness, and variability. We performed three real-time\ne-VLBI observations of PMN J0948+0022 at 22 GHz, using a global array including\ntelescopes in Europe, East Asia, and Australia. These are the first e-VLBI\nscience observations ever carried out with a global array, reaching a maximum\nbaseline length of 12458 km. The observations were part of a large\nmultiwavelength campaign in 2009. The source is detected at all three epochs.\nThe structure is dominated by a bright component, more compact than 55\nmicroarcsec, with a fainter component at a position angle theta~ 35deg.\nRelativistic beaming is required by the observed brightness temperature of\n3.4x10^11 K. Polarization is detected at a level of about 1%. The parameters\nderived by the VLBI observations, in addition to the broad-band properties,\nconfirm that PMN J0948+0022 is similar to flat spectrum radio quasars. Global\ne-VLBI is a reliable and promising technique for future studies. \n\n"}
{"id": "1102.5743", "contents": "Title: Testing Weak Lensing Maps With Redshift Surveys: A Subaru Field Abstract: We use a dense redshift survey in the foreground of the Subaru GTO2deg^2 weak\nlensing field (centered at $\\alpha_{2000}$ = 16$^h04^m44^s$;$\\delta_{2000}$\n=43^\\circ11^{\\prime}24^{\\prime\\prime}$) to assess the completeness and comment\non the purity of massive halo identification in the weak lensing map. The\nredshift survey (published here) includes 4541 galaxies; 4405 are new redshifts\nmeasured with the Hectospec on the MMT. Among the weak lensing peaks with a\nsignal-to-noise greater that 4.25, 2/3 correspond to individual massive\nsystems; this result is essentially identical to the Geller et al. (2010) test\nof the Deep Lens Survey field F2. The Subaru map, based on images in\nsubstantially better seeing than the DLS, enables detection of less massive\nhalos at fixed redshift as expected. We demonstrate that the procedure adopted\nby Miyazaki et al. (2007) for removing some contaminated peaks from the weak\nlensing map improves agreement between the lensing map and the redshift survey\nin the identification of candidate massive systems. \n\n"}
{"id": "1103.1113", "contents": "Title: On Scattering of Electromagnetic Waves by a Wormhole Abstract: We consider scattering of a plane electromagnetic wave by a wormhole. It is\nfound that the scattered wave is partially depolarized and has a specific\ninterference picture depending on parameters of the wormhole and the distance\nto the observer. It is proposed that such features can be important in the\ndirect search of wormholes. \n\n"}
{"id": "1103.1874", "contents": "Title: Effect of Fourier filters in removing periodic systematic effects from\n  CMB data Abstract: We consider the application of high-pass Fourier filters to remove periodic\nsystematic fluctuations from full-sky survey CMB datasets. We compare the\nfilter performance with destriping codes commonly used to remove the effect of\nresidual 1/f noise from timelines. As a realistic working case, we use\nsimulations of the typical Planck scanning strategy and Planck Low Frequency\nInstrument noise performance, with spurious periodic fluctuations that mimic a\ntypical thermal disturbance. We show that the application of Fourier high-pass\nfilters in chunks always requires subsequent normalisation of induced offsets\nby means of destriping. For a complex signal containing all the astrophysical\nand instrumental components, the result obtained by applying filter and\ndestriping in series is comparable to the result obtained by destriping only,\nwhich makes the usefulness of Fourier filters questionable for removing this\nkind of effects. \n\n"}
{"id": "1103.2099", "contents": "Title: Resolving Subhaloes' Lives with the Hierarchical Bound-Tracing Algorithm Abstract: We develop a new code, the Hierarchical Bound-Tracing (HBT for short) code,\nto find and trace dark matter subhaloes in simulations based on the merger\nhierarchy of dark matter haloes. Application of this code to a recent benchmark\ntest of finding subhaloes demonstrates that HBT stands as one of the best codes\nto trace the evolutionary history of subhaloes. The success of the code lies in\nits careful treatment of the complex physical processes associated with the\nevolution of subhaloes and in its robust unbinding algorithm with an adaptive\nsource subhalo management. We keep a full record of the merger hierarchy of\nhaloes and subhaloes, and allow growth of satellite subhaloes through accretion\nfrom its \"satellite-of-satellites\", hence allowing mergers among satellites.\nLocal accretion of background mass is omitted, while rebinding of stripped mass\nis allowed. The justification of these treatments is provided by case studies\nof the lives of individual subhaloes and by the success in finding the complete\nsubhalo catalogue. We compare our result to other popular subhalo finders and\nshow that HBT is able to well resolve subhaloes in high density environment and\nkeep strict physical track of subhaloes' merger history. This code is fully\nparallelized and freely available upon request to the authors. \n\n"}
{"id": "1103.3370", "contents": "Title: Forecasts of non-Gaussian parameter spaces using Box-Cox transformations Abstract: Forecasts of statistical constraints on model parameters using the Fisher\nmatrix abound in many fields of astrophysics. The Fisher matrix formalism\ninvolves the assumption of Gaussianity in parameter space and hence fails to\npredict complex features of posterior probability distributions. Combining the\nstandard Fisher matrix with Box-Cox transformations, we propose a novel method\nthat accurately predicts arbitrary posterior shapes. The Box-Cox\ntransformations are applied to parameter space to render it approximately\nmultivariate Gaussian, performing the Fisher matrix calculation on the\ntransformed parameters. We demonstrate that, after the Box-Cox parameters have\nbeen determined from an initial likelihood evaluation, the method correctly\npredicts changes in the posterior when varying various parameters of the\nexperimental setup and the data analysis, with marginally higher computational\ncost than a standard Fisher matrix calculation. We apply the Box-Cox-Fisher\nformalism to forecast cosmological parameter constraints by future weak\ngravitational lensing surveys. The characteristic non-linear degeneracy between\nmatter density parameter and normalisation of matter density fluctuations is\nreproduced for several cases, and the capabilities of breaking this degeneracy\nby weak lensing three-point statistics is investigated. Possible applications\nof Box-Cox transformations of posterior distributions are discussed, including\nthe prospects for performing statistical data analysis steps in the transformed\nGaussianised parameter space. \n\n"}
{"id": "1103.4250", "contents": "Title: Constraints on the Extremely-high Energy Cosmic Neutrino Flux with the\n  IceCube 2008-2009 Data Abstract: We report on a search for extremely-high energy neutrinos with energies\ngreater than $10^6$ GeV using the data taken with the IceCube detector at the\nSouth Pole. The data was collected between April 2008 and May 2009 with the\nhalf completed IceCube array. The absence of signal candidate events in the\nsample of 333.5 days of livetime significantly improves model independent limit\nfrom previous searches and allows to place a limit on the diffuse flux of\ncosmic neutrinos with an $E^{-2}$ spectrum in the energy range $2.0 \\times\n10^{6}$ $-$ $6.3 \\times 10^{9}$ GeV to a level of $E^2 \\phi \\leq 3.6 \\times\n10^{-8}$ ${\\rm GeV cm^{-2} sec^{-1}sr^{-1}}$. \n\n"}
{"id": "1103.5300", "contents": "Title: The reddening law of Type Ia Supernovae: separating intrinsic\n  variability from dust using equivalent widths Abstract: We employ 76 type Ia supernovae with optical spectrophotometry within 2.5\ndays of B-band maximum light obtained by the Nearby Supernova Factory to derive\nthe impact of Si and Ca features on supernovae intrinsic luminosity and\ndetermine a dust reddening law. We use the equivalent width of Si II\n{\\lambda}4131 in place of light curve stretch to account for first-order\nintrinsic luminosity variability. The resultant empirical spectral reddening\nlaw exhibits strong features associated with Ca II and Si II {\\lambda}6355.\nAfter applying a correction based on the Ca II H&K equivalent width we find a\nreddening law consistent with a Cardelli extinction law. Using the same input\ndata, we compare this result to synthetic rest-frame UBVRI-like photometry in\norder to mimic literature observations. After corrections for signatures\ncorrelated with Si II {\\lambda}4131 and Ca II H&K equivalent widths, and\nintroducing an empirical correlation between colors, we determine the dust\ncomponent in each band. We find a value of the total-to-selective extinction\nratio, RV = 2.8 \\pm 0.3. This agrees with the Milky Way value, in contrast to\nthe low RV values found in most previous analyses. This result suggests that\nthe long-standing controversy in interpreting SN Ia colors and their\ncompatibility with a classical extinction law, critical to their use as\ncosmological probes, can be explained by the treatment of the dispersion in\ncolors, and by the variability of features apparent in SN Ia spectra. \n\n"}
{"id": "1103.5739", "contents": "Title: A fully relativistic twisted disk around a slowly rotating Kerr black\n  hole: derivation of dynamical equations and the shape of stationary\n  configurations Abstract: (abbreviated) In this paper we derive equations describing dynamics and\nstationary configurations of a twisted fully relativistic thin accretion disc\naround a slowly rotating black hole. We find that the disc dynamics and\nstationary shapes are determined by a pair of equations for two complex\nvariables describing orientation of the disc rings and velocity perturbations\nin the disc. We analyse shapes of stationary twisted configurations. It is\nshown that the stationary configurations depend on two parameters - the $\\alpha\n$parameter and $\\tilde \\delta = \\delta_{*}/\\sqrt a$, where $\\delta_{*}\\sim h/r$\nis the disc opening angle (h is the disc halfthickness) and $a$ is the black\nhole rotational parameter. When $a > 0$ and $\\tilde \\delta \\ll 1$ the shapes\ndepend drastically on value of $\\alpha$. When $\\alpha $ is small the disc\ninclination angle oscillates with radius with amplitude and radial frequency of\nthe oscillations dramatically increasing towards the last stable orbit. For\nmoderate values of $\\alpha $ the oscillations do not take place but the disc\ndoes not align with the equatorial plane at small radii. Its inclination angle\nis either increasing towards $R_{ms}$ or exhibits a non-monotonic dependence on\nthe radial coordinate. Finally, when $\\alpha $ is sufficiently large the disc\naligns with the equatorial plane at small radii. When $a < 0$ the disc aligns\nwith the equatorial plane for all values of $\\alpha $. The results reported\nhere may have implications for determining structure and variability of\naccretion discs close to $R_{ms}$ as well as for modelling of emission spectra\ncoming from different sources, which are supposed to contain black holes. \n\n"}
{"id": "1104.0606", "contents": "Title: The Chinese-French SVOM mission for GRBs studies Abstract: We present the SVOM (Space-based multi-band astronomical Variable Objects\nMonitor) mission that the Chinese National Space Agency and the French Space\nAgency have decided to jointly implement. SVOM has been designed to detect all\nknown types of gamma-ray bursts (GRBs), to provide fast and reliable GRB\npositions, to measure the broadband spectral shape and temporal properties of\nthe GRB prompt emission, and to quickly identify the optical/near-infrared\nafterglows of detected GRBs, including high-redshift ones. Scheduled to be in\norbit in the second half of the present decade, the SVOM satellite will carry a\nvery innovative scientific payload combining for the first time a wide field X-\nand gamma-ray coded mask imager for GRB real-time localizations to few arcmin,\na non-imaging gamma-ray monitor, and two narrow-field instruments for the study\nof the GRB early afterglow emission in the X-ray and visible bands. The SVOM\npayload is complemented by ground-based instruments including a wide-field\ncamera to catch the GRB prompt emission in the visible band and two robotic\ntelescopes to measure the photometric properties of the early afterglow. A\nparticular attention is paid to the GRB follow-up in facilitating the\nobservation of the SVOM detected GRB by the largest ground based telescopes. \n\n"}
{"id": "1104.1399", "contents": "Title: Cosmological information in Gaussianised weak lensing signals Abstract: We investigate the information on cosmology contained in Gaussianised weak\ngravitational lensing convergence fields. Employing Box-Cox transformations to\ndetermine optimal transformations to Gaussianity, we develop analytical models\nfor the transformed power spectrum, including effects of noise and smoothing.\nWe find that optimised Box-Cox transformations perform substantially better\nthan an offset logarithmic transformation in Gaussianising the convergence, but\nboth yield very similar results for the signal-to-noise and parameter\nconstraints. None of the transformations is capable of eliminating correlations\nof the power spectra between different angular frequencies, which we\ndemonstrate to have a significant impact on the errors on cosmology. Analytic\nmodels of the Gaussianised power spectrum yield good fits to the simulations\nand produce unbiased parameter estimates in the majority of cases, where the\nexceptions can be traced back to the limitations in modelling the higher-order\ncorrelations of the original convergence. In the idealistic case, without\ngalaxy shape noise, we find an increase in cumulative signal-to-noise by a\nfactor of 2.6 for angular frequencies up to 1500, and a decrease in the area of\nthe confidence region in the Omega_m-sigma_8 plane by a factor of 4.4 in terms\nof q-values for the best-performing transformation. When adding a realistic\nlevel of shape noise, all transformations perform poorly with little\ndecorrelation of angular frequencies, a maximum increase in signal-to-noise of\n34%, and even marginally degraded errors on cosmological parameters. We argue\nthat, to find Gaussianising transformations of practical use, one will need to\ngo beyond transformations of the one-point distribution of the convergence,\nextend the analysis deeper into the non-linear regime, and resort to an\nexploration of parameter space via simulations. (abridged) \n\n"}
{"id": "1104.3562", "contents": "Title: TESS: A Relativistic Hydrodynamics Code on a Moving Voronoi Mesh Abstract: We have generalized a method for the numerical solution of hyperbolic systems\nof equations using a dynamic Voronoi tessellation of the computational domain.\nThe Voronoi tessellation is used to generate moving computational meshes for\nthe solution of multi-dimensional systems of conservation laws in finite-volume\nform. The mesh generating points are free to move with arbitrary velocity, with\nthe choice of zero velocity resulting in an Eulerian formulation. Moving the\npoints at the local fluid velocity makes the formulation effectively\nLagrangian. We have written the TESS code to solve the equations of\ncompressible hydrodynamics and magnetohydrodynamics for both relativistic and\nnon-relativistic fluids on a dynamic Voronoi mesh. When run in Lagrangian mode,\nTESS is significantly less diffusive than fixed mesh codes and thus preserves\ncontact discontinuities to high precision while also accurately capturing\nstrong shock waves. TESS is written for Cartesian, spherical and cylindrical\ncoordinates and is modular so that auxilliary physics solvers are readily\nintegrated into the TESS framework and so that the TESS framework can be\nreadily adapted to solve general systems of equations. We present results from\na series of test problems to demonstrate the performance of TESS and to\nhighlight some of the advantages of the dynamic tessellation method for solving\nchallenging problems in astrophysical fluid dynamics. \n\n"}
{"id": "1104.4881", "contents": "Title: Effects of radial flows on the chemical evolution of the Milky Way disk Abstract: The majority of chemical evolution models assume that the Galactic disk forms\nby means of infall of gas and divide the disk into several independent rings\nwithout exchange of matter between them. However, if gas infall is important,\nradial gas flows should be taken into account as a dynamical consequence of\ninfall. The aim of this paper is to test the effect of radial gas flows on\ndetailed chemical evolution models (one-infall and two-infall) for the Milky\nWay disk with different prescriptions for the infall law and star formation\nrate. We found, that with a gas radial inflow of constant speed the metallicity\ngradient tends to steepen. Taking into account a constant time scale for the\ninfall rate along the Galaxy disk and radial flows with a constant speed, we\nobtained a too flat gradient, at variance with data, implying that an\ninside-out formation and/or a variable gas flow speed are required. To\nreproduce the observed gradients the gas flow should increase in modulus with\nthe galactocentric distance, both in the one-infall and two-infall models.\nHowever, the inside-out disk formation coupled with a threshold in the gas\ndensity (only in the two-infall model) for star formation and/or a variable\nefficiency of star formation with galactocentric distance can also reproduce\nthe observed gradients without radial flows. We showed that the radial flows\ncan be the most important process in reproducing abundance gradients but only\nwith a variable gas speed. Finally, one should consider that uncertainties in\nthe data concerning gradients prevent us to draw firm conclusions. Future more\ndetailed data will help to ascertain whether the radial flows are a necessary\ningredient in the formation and evolution of the Galactic disk and disks in\ngeneral. \n\n"}
{"id": "1105.0993", "contents": "Title: Optimal strategies : theoretical approaches to the parametrization of\n  the dark energy equation of state Abstract: The absence of compelling theoretical model requires the parameterizing the\ndark energy to probe its properties. The parametrization of the equation of\nstate of the dark energy is a common method. We explore the theoretical\noptimization of the parametrization based on the Fisher information matrix. As\na suitable parametrization, it should be stable at high redshift and should\nproduce the determinant of the Fisher matrix as large as possible. For the\nillustration, we propose one parametrization which can satisfy both criteria.\nBy using the proper parametrization, we can improve the constraints on the dark\nenergy even for the same data. We also show the weakness of the so-called\nprincipal component analysis method. \n\n"}
{"id": "1105.1367", "contents": "Title: New 145-MHz Source Measurements by PAPER in the Southern Sky Abstract: We present observations from the Precision Array for Probing the Epoch of\nReionization (PAPER) in South Africa, observed in May and September 2010. Using\ntwo nights of drift scanning with PAPER's 60\\arcdeg\\ FWHM beam we have made a\nmap covering the entire sky below +10 degrees declination with an effective\ncenter frequency of 145 MHz, a 70-MHz bandwidth, and a resolution of 26\\arcmin.\nA 4800 square-degree region of this large map with the lowest Galactic emission\nreaches an RMS of 0.7 Jy. We establish an absolute flux scale using sources\nfrom the 160-MHz Culgoora catalog. Using the 408-MHz Molonglo Reference Catalog\n(MRC) as a finding survey, we identify counterparts to 480 sources in our maps,\nand compare our fluxes to the MRC and to 332 sources in the Culgoora catalog.\nFor both catalogs, the ratio of PAPER to catalog flux averages to 1, with a\nstandard deviation of 50%. This measured variation is consistent with\ncomparisons between independent catalogs observed at different bands. The PAPER\ndata represent new 145-MHz flux measurements for a large number of sources in\nthe band expected to encompass cosmic reionization, and represents a\nsignificant step toward establishing a model for removing foregrounds to the\nreionization signal. \n\n"}
{"id": "1105.2044", "contents": "Title: The Primordial Inflation Explorer (PIXIE): A Nulling Polarimeter for\n  Cosmic Microwave Background Observations Abstract: The Primordial Inflation Explorer (PIXIE) is an Explorer-class mission to\nmeasure the gravity-wave signature of primordial inflation through its\ndistinctive imprint on the linear polarization of the cosmic microwave\nbackground. The instrument consists of a polarizing Michelson interferometer\nconfigured as a nulling polarimeter to measure the difference spectrum between\northogonal linear polarizations from two co-aligned beams. Either input can\nview the sky or a temperature-controlled absolute reference blackbody\ncalibrator. PIXIE will map the absolute intensity and linear polarization\n(Stokes I, Q, and U parameters) over the full sky in 400 spectral channels\nspanning 2.5 decades in frequency from 30 GHz to 6 THz (1 cm to 50 um\nwavelength). Multi-moded optics provide background-limited sensitivity using\nonly 4 detectors, while the highly symmetric design and multiple signal\nmodulations provide robust rejection of potential systematic errors. The\nprincipal science goal is the detection and characterization of linear\npolarization from an inflationary epoch in the early universe, with\ntensor-to-scalar ratio r < 10^{-3} at 5 standard deviations. The rich PIXIE\ndata set will also constrain physical processes ranging from Big Bang cosmology\nto the nature of the first stars to physical conditions within the interstellar\nmedium of the Galaxy. \n\n"}
{"id": "1105.4426", "contents": "Title: Symmetry of the CMB sky as a new test of its statistical isotropy. Non\n  Cosmological Octupole? Abstract: In this article we propose a novel test for statistical anisotropy of the\nCMB. The test is based on the fact, that the Galactic foregrounds have a\nremarcably strong symmetry with respect to their antipodal points and with\nrespect to the Galactic plane, while the cosmological signal should not be\nsymmetric or asymmetric under these transitions. We have applied the test for\nthe octupole component of the WMAP ILC 7 map, by looking at a_3,1 and a_3,3,\nand their ratio to a_3,2 both for real and imaginary values. We find abnormal\nsymmetry of the octupole component at the level of 0.58%, compared to Monte\nCarlo simulations. By using the analysis of the phases of the octupole we found\nremarkably strong cross-correlations between the phases of kinematic dipole and\nILC 7 octupole, in full agreement with previous results. We further test the\nmultipole range 2<l<100, by investigating the ratio between the l+m=even and\nl+m=odd parts of power spectra. We compare the results to simulations of a\nGaussian random sky, and find significant departure from the statistically\nisotropic and homogeneous case, for a very broad range of multipoles. We found\nthat for the most prominent peaks of our estimator, the phases of the\ncorresponding harmonics are coherent with phases of the octupole. We believe,\nour test would be very useful for detections of various types of residuals of\nthe foreground and systematic effects at very a broad range of multipoles 2 < l\n< 1500-3000 for the forthcoming PLANCK CMB map, before any conclusions about\nprimordial non-Gaussianity and statistical anisotropy of the CMB. \n\n"}
{"id": "1105.5745", "contents": "Title: The reliability of the AIC method in Cosmological Model Selection Abstract: The Akaike information criterion (AIC) has been used as a statistical\ncriterion to compare the appropriateness of different dark energy candidate\nmodels underlying a particular data set. Under suitable conditions, the AIC is\nan indirect estimate of the Kullback-Leibler divergence D(T//A) of a candidate\nmodel A with respect to the truth T. Thus, a dark energy model with a smaller\nAIC is ranked as a better model, since it has a smaller Kullback-Leibler\ndiscrepancy with T. In this paper, we explore the impact of statistical errors\nin estimating the AIC during model comparison. Using a parametric bootstrap\ntechnique, we study the distribution of AIC differences between a set of\ncandidate models due to different realizations of noise in the data and show\nthat the shape and spread of this distribution can be quite varied. We also\nstudy the rate of success of the AIC procedure for different values of a\nthreshold parameter popularly used in the literature. For plausible choices of\ntrue dark energy models, our studies suggest that investigating such\ndistributions of AIC differences in addition to the threshold is useful in\ncorrectly interpreting comparisons of dark energy models using the AIC\ntechnique. \n\n"}
{"id": "1106.0007", "contents": "Title: How well can we measure and understand foregrounds with 21 cm\n  experiments? Abstract: Before it becomes a sensitive probe of the Epoch of Reionization, the Dark\nAges, and fundamental physics, 21 cm tomography must successfully contend with\nthe issue of foreground contamination. Broadband foreground sources are\nexpected to be roughly four orders of magnitude larger than any cosmological\nsignals, so precise foreground models will be necessary. Such foreground models\noften contain a large number of parameters, reflecting the complicated physics\nthat governs foreground sources. In this paper, we concentrate on spectral\nmodeling (neglecting, for instance, bright point source removal from spatial\nmaps) and show that 21 cm tomography experiments will likely not be able to\nmeasure these parameters without large degeneracies, simply because the\nforeground spectra are so featureless and generic. However, we show that this\nis also an advantage, because it means that the foregrounds can be\ncharacterized to a high degree of accuracy once a small number of parameters\n(likely three or four, depending on one's instrumental specifications) are\nmeasured. This provides a simple understanding for why 21 cm foreground\nsubtraction schemes are able to remove most of the contaminants by suppressing\njust a small handful of simple spectral forms. In addition, this suggests that\nthe foreground modeling process should be relatively simple and will likely not\nbe an impediment to the foreground subtraction schemes that are necessary for a\nsuccessful 21 cm tomography experiment. \n\n"}
{"id": "1106.0037", "contents": "Title: Recent results in the search for dark matter with noble liquid detectors Abstract: The field of dark matter direct detection has seen important contributions in\nrecent years from experiments involving liquid noble gases, specifically liquid\nargon and liquid xenon. These detection media offer many properties deemed\nuseful in this search, including fast scintillation response, charge readout,\n3-D position reconstruction, and nuclear recoil discrimination. Part of the\nvery rapid emergence and dominance of noble liquids is due to the fact that\nthese technologies are easily scalable to nearly arbitrary size and mass.\nHowever, the physics impact of recent results has called into question our\nunderstanding of the low-energy response of these detection media, in light of\napparent contradictions with a possible low-mass WIMP signal observed in the\nDAMA/LIBRA and CoGeNT experiments. I discuss recent results and examine the\ndetails of this inconsistency. \n\n"}
{"id": "1106.0927", "contents": "Title: On the effect of image denoising on galaxy shape measurements Abstract: Weak gravitational lensing is a very sensitive way of measuring cosmological\nparameters, including dark energy, and of testing current theories of\ngravitation. In practice, this requires exquisite measurement of the shapes of\nbillions of galaxies over large areas of the sky, as may be obtained with the\nEUCLID and WFIRST satellites. For a given survey depth, applying image\ndenoising to the data both improves the accuracy of the shape measurements and\nincreases the number density of galaxies with a measurable shape. We perform\nsimple tests of three different denoising techniques, using synthetic data. We\npropose a new and simple denoising method, based on wavelet decomposition of\nthe data and a Wiener filtering of the resulting wavelet coefficients. When\napplied to the GREAT08 challenge dataset, this technique allows us to improve\nthe quality factor of the measurement (Q; GREAT08 definition), by up to a\nfactor of two. We demonstrate that the typical pixel size of the EUCLID optical\nchannel will allow us to use image denoising. \n\n"}
{"id": "1106.1745", "contents": "Title: Probing cosmic star formation up to z = 9.4 with GRBs Abstract: We propose a novel approach, based on Principal Components Analysis, to the\nuse of Gamma-Ray Bursts (GRBs) as probes of cosmic star formation history (SFH)\nup to very high redshifts. The main advantage of such approach is to avoid the\nnecessity of assuming an \\textit{ad hoc} parameterization of the SFH. We first\nvalidate the method by reconstructing a known SFH from Monte Carlo-generated\nmock data. We then apply the method to the most recent \\textit{Swift} data of\nGRBs with known redshift and compare it against the SFH obtained by independent\nmethods. The main conclusion is that the level of star formation activity at $z\n\\approx 9.4$ could have been already as high as the present-day one ($\\approx\n0.01 M_\\odot$ yr$^{-1}$ Mpc$^{-3}$). This is a factor 3-5 times higher than\ndeduced from high-$z$ galaxy searches through drop-out techniques. If true,\nthis might alleviate the long-standing problem of a photon-starving\nreionization; it might also indicate that galaxies accounting for most of the\nstar formation activity at high redshift go undetected by even the most deep\nsearches. \n\n"}
{"id": "1106.2158", "contents": "Title: SPIDER: a balloon-borne CMB polarimeter for large angular scales Abstract: We describe SPIDER, a balloon-borne instrument to map the polarization of the\nmillimeter-wave sky with degree angular resolution. Spider consists of six\nmonochromatic refracting telescopes, each illuminating a focal plane of\nlarge-format antenna-coupled bolometer arrays. A total of 2,624 superconducting\ntransition-edge sensors are distributed among three observing bands centered at\n90, 150, and 280 GHz. A cold half-wave plate at the aperture of each telescope\nmodulates the polarization of incoming light to control systematics. Spider's\nfirst flight will be a 20-30-day Antarctic balloon campaign in December 2011.\nThis flight will map \\sim8% of the sky to achieve unprecedented sensitivity to\nthe polarization signature of the gravitational wave background predicted by\ninflationary cosmology. The Spider mission will also serve as a proving ground\nfor these detector technologies in preparation for a future satellite mission. \n\n"}
{"id": "1106.2527", "contents": "Title: A complex stellar line-of-sight velocity distribution in the lenticular\n  galaxy NGC 524 Abstract: We present the detailed study of the stellar and gaseous kinematics of the\nluminous early-type galaxy NGC 524 derived from the long-slit spectroscopic\nobservations obtained with the Russian 6-m telescope and the IFU data from the\nSAURON survey. The stellar line-of-sight velocity distribution (LOSVD) of NGC\n524 exhibits strong asymmetry. We performed the comprehensive analysis of the\nLOSVD using two complementary approaches implemented on top of the nbursts full\nspectral fitting technique, (a) a nonparametric LOSVD recovery and (b) a\nparametric recovery of two Gaussian kinematical components having different\nstellar populations. We discuss the origin of the complex stellar LOSVD of NGC\n524. \n\n"}
{"id": "1106.2607", "contents": "Title: Non-linear matter power spectrum from Time Renormalisation Group:\n  efficient computation and comparison with one-loop Abstract: We address the issue of computing the non-linear matter power spectrum on\nmildly non-linear scales with efficient semi-analytic methods. We implemented\nM. Pietroni's Time Renormalization Group (TRG) method and its Dynamical 1-Loop\n(D1L) limit in a numerical module for the new Boltzmann code CLASS. Our\npublicly released module is valid for LCDM models, and optimized in such a way\nto run in less than a minute for D1L, or in one hour (divided by number of\nnodes) for TRG. A careful comparison of the D1L, TRG and Standard 1-Loop\napproaches reveals that results depend crucially on the assumed initial\nbispectrum at high redshift. When starting from a common assumption, the three\nmethods give roughly the same results, showing that the partial resumation of\ndiagrams beyond one loop in the TRG method improves one-loop results by a\nnegligible amount. A comparison with highly accurate simulations by M. Sato &\nT. Matsubara shows that all three methods tend to over-predict non-linear\ncorrections by the same amount on small wavelengths. Percent precision is\nachieved until k~0.2 h/Mpc for z>2, or until k~0.14 h/Mpc at z=1. \n\n"}
{"id": "1106.3219", "contents": "Title: EMU: Evolutionary Map of the Universe Abstract: EMU is a wide-field radio continuum survey planned for the new Australian\nSquare Kilometre Array Pathfinder (ASKAP) telescope. The primary goal of EMU is\nto make a deep (rms ~ 10 microJy/beam) radio continuum survey of the entire\nSouthern Sky at 1.3 GHz, extending as far North as +30 degrees declination,\nwith a resolution of 10 arcsec. EMU is expected to detect and catalogue about\n70 million galaxies, including typical star-forming galaxies up to z~1,\npowerful starbursts to even greater redshifts, and AGNs to the edge of the\nvisible Universe. It will undoubtedly discover new classes of object. This\npaper defines the science goals and parameters of the survey, and describes the\ndevelopment of techniques necessary to maximise the science return from EMU. \n\n"}
{"id": "1107.0729", "contents": "Title: Cancelling out systematic uncertainties Abstract: We present a method to minimize, or even cancel out, the nuisance parameters\naffecting a measurement. Our approach is general and can be applied to any\nexperiment or observation. We compare it with the bayesian technique used to\ndeal with nuisance parameters: marginalization, and show how the method\ncompares and improves by avoiding biases. We illustrate the method with several\nexamples taken from the astrophysics and cosmology world: baryonic acoustic\noscillations, cosmic clocks, Supernova Type Ia luminosity distance, neutrino\noscillations and dark matter detection. By applying the method we recover some\nknown results but also find some interesting new ones. For baryonic acoustic\noscillation (BAO) experiments we show how to combine radial and angular BAO\nmeasurements in order to completely eliminate the dependence on the sound\nhorizon at radiation drag. In the case of exploiting SN1a as standard candles\nwe show how the uncertainty in the luminosity distance by a second parameter\nmodeled as a metallicity dependence can be eliminated or greatly reduced. When\nusing cosmic clocks to measure the expansion rate of the universe, we\ndemonstrate how a particular combination of observables nearly removes the\nmetallicity dependence of the galaxy on determining differential ages, thus\nremoving the age-metallicity degeneracy in stellar populations. We hope that\nthese findings will be useful in future surveys to obtain robust constraints on\nthe dark energy equation of state. \n\n"}
{"id": "1107.1711", "contents": "Title: Accretion disks around kicked black holes: Post-kick Dynamics Abstract: Numerical calculations of merging black hole binaries indicate that\nasymmetric emission of gravitational radiation can kick the merged black hole\nat up to thousands of km/s, and a number of systems have been observed recently\nwhose properties are consistent with an active galactic nucleus containing a\nsupermassive black hole moving with substantial velocity with respect to its\nbroader accretion disk. We study here the effect of an impulsive kick delivered\nto a black hole on the dynamical evolution of its accretion disk using a\nsmoothed particle hydrodynamics code, focusing attention on the role played by\nthe kick angle with respect to the orbital angular momentum vector of the\npre-kicked disk. We find that for more vertical kicks, for which the angle\nbetween the kick and the normal vector to the disk $\\theta\\lesssim 30^\\circ$, a\ngap remains present in the inner disk, in accordance with the prediction from\nan analytic collisionless Keplerian disk model, while for more oblique kicks\nwith $\\theta\\gtrsim 45^\\circ$, matter rapidly accretes toward the black hole.\nThere is a systematic trend for higher potential luminosities for more oblique\nkick angles for a given black hole mass, disk mass and kick velocity, and we\nfind large amplitude oscillations in time in the case of a kick oriented\n$60^\\circ$ from the vertical. \n\n"}
{"id": "1107.2395", "contents": "Title: Mass segregation and fractal substructure in young massive clusters: (I)\n  the McLuster code and method calibration Abstract: By analysing models of the young massive cluster R136 in 30 Doradus, set-up\nusing the herewith introduced and publicly made available code McLuster, we\ninvestigate and compare different methods for detecting and quantifying mass\nsegregation and substructure in non-seeing limited N-body data. For this\npurpose we generate star cluster models with different degrees of mass\nsegregation and fractal substructure and analyse them. We quantify mass\nsegregation by measuring, from the projected 2d model data, the mass function\nslope in radial annuli, by looking for colour gradients in radial colour\nprofiles, by measuring Allison's Lambda parameter, and by determining the local\nstellar surface density around each star. We find that these methods for\nquantifying mass segregation often produce ambiguous results. Most reliable for\ndetecting mass segregation is the mass function slope method, whereas the\ncolour gradient method is the least practical in an R136-like configuration.\nThe other two methods are more sensitive to low degrees of mass segregation but\nare computationally much more demanding. We also discuss the effect of binaries\non these measures. Moreover, we quantify substructure by looking at the\nprojected radial stellar density profile, by comparing projected azimuthal\nstellar density profiles, and by determining Cartwright & Whitworth's Q\nparameter. We find that only high degrees of substructure affect the projected\nradial density profile, whereas the projected azimuthal density profile is very\nsensitive to substructure. The Q parameter is also sensitive to substructure\nbut its absolute value shows a dependence on the radial density gradient of the\ncluster and is strongly influenced by binaries. (abridged) \n\n"}
{"id": "1107.2931", "contents": "Title: Oxford SWIFT IFS and multi-wavelength observations of the Eagle galaxy\n  at z=0.77 Abstract: The `Eagle' galaxy at a redshift of 0.77 is studied with the Oxford Short\nWavelength Integral Field Spectrograph (SWIFT) and multi-wavelength data from\nthe All-wavelength Extended Groth strip International Survey (AEGIS). It was\nchosen from AEGIS because of the bright and extended emission in its slit\nspectrum. Three dimensional kinematic maps of the Eagle reveal a gradient in\nvelocity dispersion which spans 35-75 +/- 10 km/s and a rotation velocity of 25\n+/- 5 km/s uncorrected for inclination. Hubble Space Telescope images suggest\nit is close to face-on. In comparison with galaxies from AEGIS at similar\nredshifts, the Eagle is extremely bright and blue in the rest-frame optical,\nhighly star-forming, dominated by unobscured star-formation, and has a low\nmetallicity for its size. This is consistent with its selection. The Eagle is\nlikely undergoing a major merger and is caught in the early stage of a\nstar-burst when it has not yet experienced metal enrichment or formed the mass\nof dust typically found in star-forming galaxies. \n\n"}
{"id": "1107.4629", "contents": "Title: Precision simulation of ground-based lensing data using observations\n  from space Abstract: Current and upcoming wide-field, ground-based, broad-band imaging surveys\npromise to address a wide range of outstanding problems in galaxy formation and\ncosmology. Several such uses of ground-based data, especially weak\ngravitational lensing, require highly precise measurements of galaxy image\nstatistics with careful correction for the effects of the point-spread function\n(PSF). In this paper, we introduce the SHERA (SHEar Reconvolution Analysis)\nsoftware to simulate ground-based imaging data with realistic galaxy\nmorphologies and observing conditions, starting from space-based data (from\nCOSMOS, the Cosmological Evolution Survey) and accounting for the effects of\nthe space-based PSF. This code simulates ground-based data, optionally with a\nweak lensing shear applied, in a model-independent way using a general Fourier\nspace formalism. The utility of this pipeline is that it allows for a precise,\nrealistic assessment of systematic errors due to the method of data processing,\nfor example in extracting weak lensing galaxy shape measurements or galaxy\nradial profiles, given user-supplied observational conditions and real galaxy\nmorphologies. Moreover, the simulations allow for the empirical test of error\nestimates and determination of parameter degeneracies, via generation of many\nnoise maps. The public release of this software, along with a large sample of\ncleaned COSMOS galaxy images (corrected for charge transfer inefficiency),\nshould enable upcoming ground-based imaging surveys to achieve their potential\nin the areas of precision weak lensing analysis, galaxy profile measurement,\nand other applications involving detailed image analysis. \n\n"}
{"id": "1107.5048", "contents": "Title: Fine-Tuning Implications of Direct Dark Matter Searches in the MSSM Abstract: We study theoretical implications of direct dark matter searches in the\nminimal supersymmetric standard model (MSSM). We assume that no accidental\ncancellations occur in the spin-independent elastic neutralino-quark scattering\ncross section, but do not impose any relations among the weak-scale MSSM\nparameters. We show that direct detection cross section below 10^-44 cm^2\nrequires the lightest supersymmetric particle (LSP) neutralino to be close to\neither a pure gaugino or pure Higgsino limit, with smaller cross sections\ncorrelated with smaller admixture of the subdominant components. The current\nXENON100 bound rules out essentially all models in which the lightest\nneutralino has the Higgsino fraction between 0.2 and 0.8. Furthermore, smaller\ndirect detection cross sections correlate with stronger fine-tuning in the\nelectroweak symmetry breaking sector. In the gaugino LSP scenario, the current\nXENON100 bound already implies some fine-tuning: for example, at least 10%\ntuning is required if the LSP mass is above 70 GeV. In both gaugino and\nHiggsino LSP scenarios, the direct dark matter searches currently being\nconducted and designed should lead to a discovery if no accidental\ncancellations or fine-tuning at a level below 1% is present. \n\n"}
{"id": "1107.5466", "contents": "Title: Avoiding bias in reconstructing the largest observable scales from\n  partial-sky data Abstract: Obscuration due to Galactic emission complicates the extraction of\ninformation from cosmological surveys, and requires some combination of the\n(typically imperfect) modeling and subtraction of foregrounds, or the removal\nof part of the sky. This particularly affects the extraction of information\nfrom the largest observable scales. Maximum-likelihood estimators for\nreconstructing the full-sky spherical harmonic coefficients from partial-sky\nmaps have recently been shown to be susceptible to contamination from within\nthe sky cut, arising due to the necessity to band-limit the data by smoothing\nprior to reconstruction. Using the WMAP 7-year data, we investigate modified\nimplementations of such estimators which are robust to the leakage of\ncontaminants from within masked regions. We provide a measure, based on the\nexpected amplitude of residual foregrounds, for selecting the most appropriate\nestimator for the task at hand. We explain why the related quadratic\nmaximum-likelihood estimator of the angular power spectrum does not suffer from\nsmoothing-induced bias. \n\n"}
{"id": "1107.5901", "contents": "Title: Variable and Transient Radio Sources in the FIRST Survey Abstract: A comprehensive search for variable and transient radio sources has been\nconducted using ~55,000 snapshot images of the FIRST survey. We present an\nanalysis leading to the discovery of 1,627 variable and transient objects down\nto mJy levels over a wide range of timescales (few minutes to years).\nVariations observed range from 20% to a factor of 25. Multi-wavelength matching\nfor counterparts reveals the diverse classes of objects exhibiting variability,\nranging from nearby stars and pulsars to galaxies and distant quasars.\nInterestingly, more than half of the objects in the sample have either no\nclassified counterparts or no corresponding sources at any other wavelength and\nrequire multi-wavelength follow-up observations. We discuss these classes of\nvariables and speculate on the identity of objects that lack multi-wavelength\ncounterparts. \n\n"}
{"id": "1108.1697", "contents": "Title: Model for common growth of supermassive black holes, bulges and globular\n  star clusters: ripping off Jeans clusters Abstract: It is assumed that a galaxy starts as a dark halo of a few million Jeans\nclusters (JCs), each of which consists of nearly a trillion micro brown dwarfs,\nMACHOs of Earth mass. JCs in the galaxy center heat up their MACHOs by tidal\nforces, which makes them expand, so that coagulation and star formation occurs.\nBeing continuously fed by matter from bypassing JCs, the central star(s) may\ntransform into a super massive black hole. It has a fast $t^3$ growth during\nthe first mega years, and a slow $t^{1/3}$ growth at giga years. JCs disrupted\nby a close encounter with this black hole can provide matter for the bulge.\nThose that survive can be so agitated that they form stars inside them and\nbecome globular star clusters. Thus black holes mostly arise together with\ngalactic bulges in their own environment and are about as old as the oldest\nglobular clusters. The age 13.2 Gyr of the star HE 1523-0901 puts forward that\nthe Galactic halo was sufficiently assembled at that moment. The star formation\nrate has a maximum at black hole mass $\\sim4 \\ 10^7M_\\odot$ and bulge mass\n$\\sim5\\,10^{10}M_\\odot$. In case of merging supermassive black holes the JCs\npassing near the galactic center provide ideal assistance to overcome the last\nparsec. \n\n"}
{"id": "1108.3950", "contents": "Title: The Cosmic Background Imager 2 Abstract: We describe an upgrade to the Cosmic Background Imager instrument to increase\nits surface brightness sensitivity at small angular scales. The upgrade\nconsisted of replacing the thirteen 0.9-m antennas with 1.4-m antennas\nincorporating a novel combination of design features, which provided excellent\nsidelobe and spillover performance for low manufacturing cost. Off-the-shelf\nspun primaries were used, and the secondary mirrors were oversized and shaped\nrelative to a standard Cassegrain in order to provide an optimum compromise\nbetween aperture efficiency and low spillover lobes. Low-order distortions in\nthe primary mirrors were compensated for by custom machining of the secondary\nmirrors. The secondaries were supported on a transparent dielectric foam cone\nto minimize scattering. The antennas were tested in the complete instrument,\nand the beam shape and spillover noise contributions were as expected. We\ndemonstrate the performance of the telescope and the inter-calibration with the\nprevious system using observations of the Sunyaev-Zel'dovich effect in the\ncluster Abell 1689. The enhanced instrument has been used to study the cosmic\nmicrowave background, the Sunyaev-Zel'dovich effect and diffuse Galactic\nemission. \n\n"}
{"id": "1108.4401", "contents": "Title: Properties of some (3+1) dimensional vortex solutions of the CP^N model Abstract: We construct new classes of vortex-like solutions of the CP^N model in (3+1)\ndimensions and discuss some of their properties. These solutions are obtained\nby generalizing to (3+1) dimensions the techniques well established for the two\ndimensional CP^N models. We show that as the total energy of these solutions is\ninfinite, they describe evolving vortices and anti-vortices with the energy\ndensity of some configurations varying in time. We also make some further\nobservations about the dynamics of these vortices. \n\n"}
{"id": "1108.5174", "contents": "Title: The butterfly effect in the extreme-mass ratio inspiral problem Abstract: Measurements of gravitational waves from the inspiral of a stellar-mass\ncompact object into a massive black hole are unique probes to test General\nRelativity (GR) and MBH properties, as well as the stellar distribution about\nthese holes in galactic nuclei. Current data analysis techniques can provide us\nwith parameter estimation with very narrow errors. However, an EMRI is not a\ntwo-body problem, since other stellar bodies orbiting nearby will influence the\ncapture orbit. Any deviation from the isolated inspiral will induce a small,\nthough observable deviation from the idealised waveform which could be\nmisinterpreted as a failure of GR. Based on conservative analysis of mass\nsegregation in a Milky Way like nucleus, we estimate that the possibility that\nanother star has a semi-major axis comparable to that of the EMRI is\nnon-negligible, although probably very small. This star introduces an\nobservable perturbation in the orbit in the case in which we consider only loss\nof energy via gravitational radiation. When considering the two first-order\nnon-dissipative post-Newtonian contributions (the periapsis shift of the\norbit), the evolution of the orbital elements of the EMRI turns out to be\nchaotic in nature. The implications of this study are twofold. From the one\nside, the application to testing GR and measuring MBHs parameters with the\ndetection of EMRIs in galactic nuclei with a millihertz mission will be even\nmore challenging than believed. From the other side, this behaviour could in\nprinciple be used as a signature of mass segregation in galactic nuclei. \n\n"}
{"id": "1108.5588", "contents": "Title: Recovering MOND from extended metric theories of gravity Abstract: We show that the Modified Newtonian Dynamics (MOND) regime can be fully\nrecovered as the weak-field limit of a particular theory of gravity formulated\nin the metric approach. This is possible when Milgrom's acceleration constant\nis taken as a fundamental quantity which couples to the theory in a very\nconsistent manner. As a consequence, the scale invariance of the gravitational\ninteraction is naturally broken. In this sense, Newtonian gravity is the\nweak-field limit of general relativity and MOND is the weak-field limit of that\nparticular extended theory of gravity. We also prove that a Noether's symmetry\napproach to the problem yields a conserved quantity coherent with this\nrelativistic MONDian extension. \n\n"}
{"id": "1108.5600", "contents": "Title: Cosmological parameter estimation using Particle Swarm Optimization\n  (PSO) Abstract: Obtaining the set of cosmological parameters consistent with observational\ndata is an important exercise in current cosmological research. It involves\nfinding the global maximum of the likelihood function in the multi-dimensional\nparameter space. Currently sampling based methods, which are in general\nstochastic in nature, like Markov-Chain Monte Carlo(MCMC), are being commonly\nused for parameter estimation. The beauty of stochastic methods is that the\ncomputational cost grows, at the most, linearly in place of exponentially (as\nin grid based approaches) with the dimensionality of the search space. MCMC\nmethods sample the full joint probability distribution (posterior) from which\none and two dimensional probability distributions, best fit (average) values of\nparameters and then error bars can be computed. In the present work we\ndemonstrate the application of another stochastic method, named Particle Swarm\nOptimization (PSO), that is widely used in the field of engineering and\nartificial intelligence, for cosmological parameter estimation from WMAP seven\nyears data. We find that there is a good agreement between the values of the\nbest fit parameters obtained from PSO and publicly available code COSMOMC.\nHowever, there is a slight disagreement between error bars mainly due to the\nfact that errors are computed differently in PSO. Apart from presenting the\nresults of our exercise, we also discuss the merits of PSO and explain its\nusefulness in more extensive search in higher dimensional parameter space. \n\n"}
{"id": "1109.0027", "contents": "Title: The Arecibo Legacy Fast ALFA Survey: The alpha.40 HI Source Catalog, its\n  Characteristics and their Impact on the Derivation of the HI Mass Function Abstract: We present a current catalog of 21 cm HI line sources extracted from the\nArecibo Legacy Fast Arecibo L-band Feed Array (ALFALFA) survey over ~2800\nsquare degrees of sky: the alpha.40 catalog. Covering 40% of the final survey\narea, the alpha.40 catalog contains 15855 sources in the regions 07h30m < R.A.\n< 16h30m, +04 deg < Dec. < +16 deg and +24 deg < Dec. < +28 deg and 22h < R.A.\n< 03h, +14 deg < Dec. < +16 deg and +24 deg < Dec. < +32 deg. Of those, 15041\nare certainly extragalactic, yielding a source density of 5.3 galaxies per\nsquare degree, a factor of 29 improvement over the catalog extracted from the\nHI Parkes All Sky Survey. In addition to the source centroid positions, HI line\nflux densities, recessional velocities and line widths, the catalog includes\nthe coordinates of the most probable optical counterpart of each HI line\ndetection, and a separate compilation provides a crossmatch to identifications\ngiven in the photometric and spectroscopic catalogs associated with the Sloan\nDigital Sky Survey Data Release 7. Fewer than 2% of the extragalactic HI line\nsources cannot be identified with a feasible optical counterpart; some of those\nmay be rare OH megamasers at 0.16 < z < 0.25. A detailed analysis is presented\nof the completeness, width dependent sensitivity function and bias inherent in\nthe current alpha.40 catalog. The impact of survey selection, distance errors,\ncurrent volume coverage and local large scale structure on the derivation of\nthe HI mass function is assessed. While alpha.40 does not yet provide a\ncompletely representative sampling of cosmological volume, derivations of the\nHI mass function using future data releases from ALFALFA will further improve\nboth statistical and systematic uncertainties. \n\n"}
{"id": "1109.0514", "contents": "Title: The influence of Galactic aberration on precession parameters determined\n  from VLBI observations Abstract: The influence of proper motions of sources due to Galactic aberration on\nprecession models based on VLBI data is determined. Comparisons of the linear\ntrends in the coordinates of the celestial pole obtained with and without\ntaking into account Galactic aberration indicate that this effect can reach 20\n$\\mu$as per century, which is important for modern precession models. It is\nalso shown that correcting for Galactic aberration influences the derived\nparameters of low-frequency nutation terms. It is therefore necessary to\ncorrect for Galactic aberration in the reduction of modern astrometric\nobservations. \n\n"}
{"id": "1109.0944", "contents": "Title: The bispectrum covariance beyond Gaussianity: A log-normal approach Abstract: To investigate and specify the statistical properties of cosmological fields\nwith particular attention to possible non-Gaussian features, accurate formulae\nfor the bispectrum and the bispectrum covariance are required. The bispectrum\nis the lowest-order statistic providing an estimate for non-Gaussianities of a\ndistribution, and the bispectrum covariance depicts the errors of the\nbispectrum measurement and their correlation on different scales. Currently,\nthere do exist fitting formulae for the bispectrum and an analytical expression\nfor the bispectrum covariance, but the former is not very accurate and the\nlatter contains several intricate terms and only one of them can be readily\nevaluated from the power spectrum of the studied field. Neglecting all\nhigher-order terms results in the Gaussian approximation of the bispectrum\ncovariance. We study the range of validity of this Gaussian approximation for\ntwo-dimensional non-Gaussian random fields. For this purpose, we simulate\nGaussian and non-Gaussian random fields, the latter represented by log-normal\nfields and obtained directly from the former by a simple transformation. From\nthe simulated fields, we calculate the power spectra, the bispectra, and the\ncovariance from the sample variance of the bispectra, for different degrees of\nnon-Gaussianity \\alpha, which is equivalent to the skewness on a given angular\nscale \\theta g. We find that the Gaussian approximation provides a good\napproximation for \\alpha<0.6 and a reasonably accurate approximation for\n\\alpha< 1, both on scales >8\\theta g. Using results from cosmic shear\nsimulations, we estimate that the cosmic shear convergence fields are described\nby \\alpha<0.7 at \\theta g~4\". We therefore conclude that the Gaussian\napproximation for the bispectrum covariance is likely to be applicable in\nongoing and future cosmic shear studies. \n\n"}
{"id": "1109.3337", "contents": "Title: The injection and feedback of Cosmic Rays in large-scale structures Abstract: We present the numerical implementation of run-time injection of Cosmic Rays\nenergy, their spatial advection and their dynamical feedack on baryonic gas in\nthe cosmological grid code ENZO. We discuss the results of its application to\nlarge-scale simulations showing that the CR energy inside clusters of galaxies\nis small compared to the gas energy (less than a few percent), while the ratio\nis larger near the accretion regions of clusters and filaments (about 0.1-0.3).\nCR feedback has a small, but significant impact on the X-ray emission and\nSunyaev-Zeldovich effect from clusters. \n\n"}
{"id": "1109.4149", "contents": "Title: On the efficiency of the Blandford-Znajek mechanism for low angular\n  momentum relativistic accretion Abstract: Blandford-Znajek (BZ) mechanism has usually been studied in the literature\nfor accretion with considerably high angular momentum leading either to the\nformation of a cold Keplerian disc, or a hot and geometrically thick\nsub-Keplerian flow as described within the framework of ADAF/RIAF. However, in\nnearby elliptical galaxies, as well as for our own Galactic centre, accretion\nwith very low angular momentum is prevalent. Such quasi-spherical strongly\nsub-Keplerian accretion has complex dynamical features and can accommodate\nstationary shocks. In this letter, we present our calculation for the maximum\nefficiency obtainable through the BZ mechanism for complete general\nrelativistic weakly rotating axisymmetric flow in the Kerr metric. Both shocked\nand shock free flow has been studied in detail for rotating and counter\nrotating accretion. Such study has never been done in the literature before. We\nfind that the energy extraction efficiency is low, about 0.1%, and increases by\na factor 15 if the ram pressure is included. Such an efficiency is still much\nhigher than the radiative efficiency of such optically thin flows. For BZ\nmechanism, shocked flow produces higher efficiency than the shock free\nsolutions and retrograde flow provides a slightly larger value of the\nefficiency than that for the prograde flow. \n\n"}
{"id": "1109.4413", "contents": "Title: Subsonic turbulence in smoothed particle hydrodynamics and moving-mesh\n  simulations Abstract: Highly supersonic, compressible turbulence is thought to be of tantamount\nimportance for star formation processes in the interstellar medium. Likewise,\ncosmic structure formation is expected to give rise to subsonic turbulence in\nthe intergalactic medium, which may substantially modify the thermodynamic\nstructure of gas in virialized dark matter halos and affect small-scale mixing\nprocesses in the gas. Numerical simulations have played a key role in\ncharacterizing the properties of astrophysical turbulence, but thus far\nsystematic code comparisons have been restricted to the supersonic regime,\nleaving it unclear whether subsonic turbulence is faithfully represented by the\nnumerical techniques commonly employed in astrophysics. Here we focus on\ncomparing the accuracy of smoothed particle hydrodynamics (SPH) and our new\nmoving-mesh technique AREPO in simulations of driven subsonic turbulence. To\nmake contact with previous results, we also analyze simulations of transsonic\nand highly supersonic turbulence. We find that the widely employed standard\nformulation of SPH yields problematic results in the subsonic regime. Instead\nof building up a Kolmogorov-like turbulent cascade, large-scale eddies are\nquickly damped close to the driving scale and decay into small-scale velocity\nnoise. Reduced viscosity settings improve the situation, but the shape of the\ndissipation range differs compared with expectations for a Kolmogorov cascade.\nIn contrast, our moving-mesh technique does yield power-law scaling laws for\nthe power spectra of velocity, vorticity and density, consistent with\nexpectations for fully developed isotropic turbulence. We show that large\nerrors in SPH's gradient estimate and the associated subsonic velocity noise\nare ultimately responsible for producing inaccurate results in the subsonic\nregime. In contrast, SPH's performance is much better for supersonic\nturbulence. [Abridged] \n\n"}
{"id": "1109.5807", "contents": "Title: Universality and the three-body parameter of helium-4 trimers Abstract: We consider a system of three helium-4 atoms, which is so far the simplest\nrealistic three-body system exhibiting the Efimov effect, in order to analyse\ndeviations from the universal Efimov three-body spectrum. We first calculate\nthe bound states using a realistic two-body potential, and then analyse how\nthey can be reproduced by simple effective models beyond Efimov's universal\ntheory. We find that the non-universal variations of the first two states can\nbe well reproduced by models parametrized with only three quantities: the\nscattering length and effective range of the original potential, and the\nstrength of a small three-body force. Furthermore, the three-body parameter\nwhich fixes the origin of the infinite set of three-body levels is found to be\nconsistent with recent experimental observations in other atomic species. \n\n"}
{"id": "1109.6620", "contents": "Title: The Formation of the Milky Way Nuclear Cluster Abstract: Nuclear Star Clusters are observed at the center of many galaxies. In\nparticular in the center of the Milky Way the Nuclear Star Cluster coexists\nwith a cen- tral supermassive black hole. The origin of these clusters is still\nunknown; a possible formation mechanism is the decay of massive globular\nclusters driven inward to the galactic center by dynamical friction and their\nsubsequent merging. By investigating this scenario by means of sophisticated\nN-body simulations we found that this process could lead to a final product\nwhich actually shows many of the observed features of the Milky Way Nuclear\nStar Cluster. \n\n"}
{"id": "1110.0191", "contents": "Title: Review on non-directional direct dark matter searches Abstract: An overview of non-directional direct detection methods is given. The\ncurrently leading experiments for spin independent WIMPs interactions are using\nsimultaneous measurement of two quantities for event-by-event background\ndiscrimination in cryogenic bolometers and noble gas like xenon. Besides these,\nseveral interesting techniques have been developped, each having a specific\nadvantage concerning e.g energy threshold lowering or strong immunity to\nionizing radiations background. Technologies used and most recent results about\nspin-dependent and spin-independent cases are presented. \n\n"}
{"id": "1110.2789", "contents": "Title: Light Loop Echoes and Blinking Black Holes Abstract: Radiation emitted near a black hole reaches the observer by multiple paths;\nand when this radiation varies in time, the time-delays between the various\npaths generate a \"blinking\" effect in the observed light curve L(t) or its\nauto-correlation function xi(T)= <L(t)L(t-T)>. For the particularly important\n\"face-on\" configuration (in which the hole is viewed roughly along its spin\naxis, while the emission comes roughly from its equatorial plane -- e.g. from\nthe inner edge of its accretion disk, or from the violent flash of a\nnearby/infalling star) we calculate the blinking in detail by computing the\ntime delay Delta t_{j}(r,a) and magnification mu_{j}(r,a) of the jth path\n(j=1,2,3,...), relative to the primary path (j=0), as a function of the\nemission radius r and black hole spin 0<a/M<1. The particular geometry and\nsymmetry of the nearly-face-on configuration enhances and \"protects\" the\nblinking signal, making it more detectable and more independent of certain\nastrophysical and observational details. The effect can be surprisingly strong:\ne.g. for radiation from the innermost stable circular orbit (\"ISCO\") of a black\nhole of critical spin (a_{crit}/M = 0.853), the j=1,2,3 fluxes are,\nrespectively, 27%, 2% and 0.1% of the j=0 flux. \n\n"}
{"id": "1110.4370", "contents": "Title: Gravitationally Consistent Halo Catalogs and Merger Trees for Precision\n  Cosmology Abstract: We present a new algorithm for generating merger trees and halo catalogs\nwhich explicitly ensures consistency of halo properties (mass, position, and\nvelocity) across timesteps. Our algorithm has demonstrated the ability to\nimprove both the completeness (through detecting and inserting otherwise\nmissing halos) and purity (through detecting and removing spurious objects) of\nboth merger trees and halo catalogs. In addition, our method is able to\nrobustly measure the self-consistency of halo finders; it is the first to\ndirectly measure the uncertainties in halo positions, halo velocities, and the\nhalo mass function for a given halo finder based on consistency between\nsnapshots in cosmological simulations. We use this algorithm to generate merger\ntrees for two large simulations (Bolshoi and Consuelo) and evaluate two halo\nfinders (ROCKSTAR and BDM). We find that both the ROCKSTAR and BDM halo finders\ntrack halos extremely well; in both, the number of halos which do not have\nphysically consistent progenitors is at the 1-2% level across all halo masses.\nOur code is publicly available at http://code.google.com/p/consistent-trees .\nOur trees and catalogs are publicly available at\nhttp://hipacc.ucsc.edu/Bolshoi/ . \n\n"}
{"id": "1110.4372", "contents": "Title: The Rockstar Phase-Space Temporal Halo Finder and the Velocity Offsets\n  of Cluster Cores Abstract: We present a new algorithm for identifying dark matter halos, substructure,\nand tidal features. The approach is based on adaptive hierarchical refinement\nof friends-of-friends groups in six phase-space dimensions and one time\ndimension, which allows for robust (grid-independent, shape-independent, and\nnoise-resilient) tracking of substructure; as such, it is named Rockstar\n(Robust Overdensity Calculation using K-Space Topologically Adaptive\nRefinement). Our method is massively parallel (up to 10^5 CPUs) and runs on the\nlargest current simulations (>10^10 particles) with high efficiency (10 CPU\nhours and 60 gigabytes of memory required per billion particles analyzed). A\nprevious paper (Knebe et al 2011) has shown Rockstar to have class-leading\nrecovery of halo properties; we expand on these comparisons with more tests and\nhigher-resolution simulations. We show a significant improvement in\nsubstructure recovery as compared to several other halo finders and discuss the\ntheoretical and practical limits of simulations in this regard. Finally, we\npresent results which demonstrate conclusively that dark matter halo cores are\nnot at rest relative to the halo bulk or satellite average velocities and have\ncoherent velocity offsets across a wide range of halo masses and redshifts. For\nmassive clusters, these offsets can be up to 350 km/s at z=0 and even higher at\nhigh redshifts. Our implementation is publicly available at\nhttp://code.google.com/p/rockstar . \n\n"}
{"id": "1110.4913", "contents": "Title: The impact of high spatial frequency atmospheric distortions on weak\n  lensing measurements Abstract: High precision cosmology with weak gravitational lensing requires a precise\nmeasure of the Point Spread Function across the imaging data where the accuracy\nto which high spatial frequency variation can be modelled is limited by the\nstellar number density across the field. We analyse dense stellar fields imaged\nat the Canada-France-Hawaii Telescope to quantify the degree of high spatial\nfrequency variation in ground-based imaging Point Spread Functions and compare\nour results to models of atmospheric turbulence. The data shows an anisotropic\nturbulence pattern with an orientation independent of the wind direction and\nwind speed. We find the amplitude of the high spatial frequencies to decrease\nwith increasing exposure time as $t^{-1/2}$, and find a negligibly small\natmospheric contribution to the Point Spread Function ellipticity variation for\nexposure times $t>180$ seconds. For future surveys analysing shorter exposure\ndata, this anisotropic turbulence will need to be taken into account as the\namplitude of the correlated atmospheric distortions becomes comparable to a\ncosmological lensing signal on scales less than $\\sim 10$ arcminutes. This\neffect could be mitigated, however, by correlating galaxy shear measured on\nexposures imaged with a time separation greater than 50 seconds, for which we\nfind the spatial turbulence patterns to be uncorrelated. \n\n"}
{"id": "1110.5339", "contents": "Title: Using CMB lensing to constrain the multiplicative bias of cosmic shear Abstract: Weak gravitational lensing is one of the key probes of cosmology. Cosmic\nshear surveys aimed at measuring the distribution of matter in the universe are\ncurrently being carried out (Pan-STARRS) or planned for the coming decade (DES,\nLSST, EUCLID, WFIRST). Crucial to the success of these surveys is the control\nof systematics. In this work a new method to constrain one such family of\nsystematics, known as multiplicative bias, is proposed. This method exploits\nthe cross-correlation between weak lensing measurements from galaxy surveys and\nthe ones obtained from high resolution CMB experiments. This cross-correlation\nis shown to have the power to break the degeneracy between the normalization of\nthe matter power spectrum and the multiplicative bias of cosmic shear and to be\nable to constrain the latter to a few percent. \n\n"}
{"id": "1110.5418", "contents": "Title: Analysis of WMAP 7-year Temperature Data: Astrophysics of the Galactic\n  Haze Abstract: We analyse WMAP 7-year temperature data, jointly modeling the cosmic\nmicrowave background (CMB) and Galactic foreground emission. We use the\nCommander code based on Gibbs sampling. Thus, from the WMAP7 data, we derive\nsimultaneously the CMB and Galactic components on scales larger than 1deg with\nsensitivity improved relative to previous work. We conduct a detailed study of\nthe low-frequency foreground with particular focus on the \"microwave haze\"\nemission around the Galactic center. We demonstrate improved performance in\nquantifying the diffuse galactic emission when Haslam 408MHz data are included\ntogether with WMAP7, and the spinning and thermal dust emission is modeled\njointly. We also address the question of whether the hypothetical galactic haze\ncan be explained by a spatial variation of the synchrotron spectral index. The\nexcess of emission around the Galactic center appears stable with respect to\nvariations of the foreground model that we study. Our results demonstrate that\nthe new galactic foreground component - the microwave haze - is indeed present. \n\n"}
{"id": "1110.5632", "contents": "Title: A Refined QSO Selection Method Using Diagnostics Tests: 663 QSO\n  Candidates in the LMC Abstract: We present 663 QSO candidates in the Large Magellanic Cloud (LMC) selected\nusing multiple diagnostics. We started with a set of 2,566 QSO candidates from\nour previous work selected using time variability of the MACHO LMC lightcurves.\nWe then obtained additional information for the candidates by crossmatching\nthem with the Spitzer SAGE, the MACHO UBVI, the 2MASS, the Chandra and the XMM\ncatalogs. Using this information, we specified six diagnostic features based on\nmid-IR colors, photometric redshifts using SED template fitting, and X-ray\nluminosities in order to further discriminate high confidence QSO candidates in\nthe absence of spectra information. We then trained a one-class SVM (Support\nVector Machine) model using the diagnostics features of the confirmed 58 MACHO\nQSOs. We applied the trained model to the original candidates and finally\nselected 663 high confidence QSO candidates. Furthermore, we crossmatched these\n663 QSO candidates with the newly confirmed 144 QSOs and 275 non-QSOs in the\nLMC fields. On the basis of the counterpart analysis, we found that the false\npositive rate is less than 1%. \n\n"}
{"id": "1110.5685", "contents": "Title: Utilizing Astroinformatics to Maximize the Science Return of the Next\n  Generation Virgo Cluster Survey Abstract: The Next Generation Virgo Cluster Survey is a 104 square degree survey of the\nVirgo Cluster, carried out using the MegaPrime camera of the\nCanada-France-Hawaii telescope, from semesters 2009A-2012A. The survey will\nprovide coverage of this nearby dense environment in the universe to\nunprecedented depth, providing profound insights into galaxy formation and\nevolution, including definitive measurements of the properties of galaxies in a\ndense environment in the local universe, such as the luminosity function. The\nlimiting magnitude of the survey is g_AB = 25.7 (10 sigma point source), and\nthe 2 sigma surface brightness limit is g_AB ~ 29 mag arcsec^-2. The data\nvolume of the survey (approximately 50 terabytes of images), while large by\ncontemporary astronomical standards, is not intractable. This renders the\nsurvey amenable to the methods of astroinformatics. The enormous dynamic range\nof objects, from the giant elliptical galaxy M87 at M(B) = -21.6, to the\nfaintest dwarf ellipticals at M(B) ~ -6, combined with photometry in 5 broad\nbands (u* g' r' i' z'), and unprecedented depth revealing many previously\nunseen structures, creates new challenges in object detection and\nclassification. We present results from ongoing work on the survey, including\nphotometric redshifts, Virgo cluster membership, and the implementation of fast\ndata mining algorithms on the infrastructure of the Canadian Astronomy Data\nCentre, as part of the Canadian Advanced Network for Astronomical Research\n(CANFAR). \n\n"}
{"id": "1110.6557", "contents": "Title: Experimental review of graphene Abstract: This review examines the properties of graphene from an experimental\nperspective. The intent is to review the most important experimental results at\na level of detail appropriate for new graduate students who are interested in a\ngeneral overview of the fascinating properties of graphene. While some\nintroductory theoretical concepts are provided, including a discussion of the\nelectronic band structure and phonon dispersion, the main emphasis is on\ndescribing relevant experiments and important results as well as some of the\nnovel applications of graphene. In particular, this review covers graphene\nsynthesis and characterization, field-effect behavior, electronic transport\nproperties, magneto-transport, integer and fractional quantum Hall effects,\nmechanical properties, transistors, optoelectronics, graphene-based sensors,\nand biosensors. This approach attempts to highlight both the means by which the\ncurrent understanding of graphene has come about and some tools for future\ncontributions. \n\n"}
{"id": "1111.0005", "contents": "Title: Towards improving the prospects for coordinated gravitational-wave and\n  electromagnetic observations Abstract: We discuss two approaches to searches for gravitational-wave (GW) and\nelectromagnetic (EM) counterparts of binary neutron star mergers. The first\napproach relies on triggering archival searches of GW detector data based on\ndetections of EM transients. We introduce a quantitative approach to evaluate\nthe improvement to GW detector reach due to the extra information gained from\nthe EM transient and the increased confidence in the presence of a signal from\na binary merger. We also advocate utilizing other transients in addition to\nshort gamma ray bursts. The second approach involves following up GW candidates\nwith targeted EM observations. We argue for the use of slower but optimal\nparameter-estimation techniques to localize the source on the sky, and for a\nmore sophisticated use of astrophysical prior information, including galaxy\ncatalogs, to find preferred followup locations. \n\n"}
{"id": "1111.1178", "contents": "Title: Probes of Lorentz Violation Abstract: Lorentz invariance is such an important principle of fundamental physics that\nit should constantly be subjected to experimental scrutiny as well as\ntheoretical questioning. Distant astrophysical sources of energetic photons\nwith rapid time variations, such as active galactic nuclei (AGNs) and gamma-ray\nbursters (GRBs), provide ideal experimental opportunities for testing Lorentz\ninvariance. The Cherenkov Telescope Array (CTA) is an excellent experimental\ntool for making such tests with sensitivities exceeding those possible using\nother detectors. \n\n"}
{"id": "1111.1255", "contents": "Title: Resolving high Reynolds numbers in SPH simulations of subsonic\n  turbulence Abstract: Accounting for the Reynolds number is critical in numerical simulations of\nturbulence, particularly for subsonic flow. For Smoothed Particle Hydrodynamics\n(SPH) with constant artificial viscosity coefficient alpha, it is shown that\nthe effective Reynolds number in the absence of explicit physical viscosity\nterms scales linearly with the Mach number - compared to mesh schemes, where\nthe effective Reynolds number is largely independent of the flow velocity. As a\nresult, SPH simulations with alpha=1 will have low Reynolds numbers in the\nsubsonic regime compared to mesh codes, which may be insufficient to resolve\nturbulent flow. This explains the failure of Bauer and Springel (2011,\narXiv:1109.4413v1) to find agreement between the moving-mesh code AREPO and the\nGADGET SPH code on simulations of driven, subsonic (v ~ 0.3 c_s) turbulence\nappropriate to the intergalactic/intracluster medium, where it was alleged that\nSPH is somehow fundamentally incapable of producing a Kolmogorov-like turbulent\ncascade. We show that turbulent flow with a Kolmogorov spectrum can be easily\nrecovered by employing standard methods for reducing alpha away from shocks. \n\n"}
{"id": "1111.1287", "contents": "Title: Algebraic Yuzvinski Formula Abstract: In 1965 Adler, Konheim and McAndrew defined the topological entropy for\ncontinuous self-maps of compact spaces. Topological entropy is very\nwell-understood for endomorphisms of compact Abelian groups. A fundamental\nresult in this context is the so-called Yuzvinski Formula, showing that the\nvalue of the topological entropy of a full solenoidal automorphism coincides\nwith the Mahler measure of its characteristic polynomial. In two papers of 1979\nand 1981 Peters gave a different definition of entropy for automorphisms of\nlocally compact Abelian groups. This notion has been appropriately modified\nforendomorphisms in two recent papers, where it is called algebraic entropy.\nThe goal of this paper is to prove a perfect analog of the Yuzvinski Formula\nfor the algebraic entropy, namely, the Algebraic Yuzvinski Formula, giving the\nvalue of the algebraic entropy of an endomorphism of a finite-dimensional\nrational vector space as the Mahler measure of its characteristic polynomial.\nFinally, several applications of the Algebraic Yuzvinski Formula and related\nopen problems are discussed. \n\n"}
{"id": "1111.3055", "contents": "Title: Eccentric black hole-neutron star mergers: effects of black hole spin\n  and equation of state Abstract: There is a high level of interest in black hole-neutron star binaries, not\nonly because their mergers may be detected by gravitational wave observatories\nin the coming years, but also because of the possibility that they could\nexplain a class of short duration gamma-ray bursts. We study black hole-neutron\nstar mergers that occur with high eccentricity as may arise from dynamical\ncapture in dense stellar regions such as nuclear or globular clusters. We\nperform general relativistic simulations of binaries with a range of impact\nparameters, three different initial black hole spins (zero, aligned and\nanti-aligned with the orbital angular momentum), and neutron stars with three\ndifferent equations of state. We find a rich diversity across these parameters\nin the resulting gravitational wave signals and matter dynamics, which should\nalso be reflected in the consequent electromagnetic emission. Before tidal\ndisruption, the gravitational wave emission is significantly larger than\nperturbative predictions suggest for periapsis distances close to effective\ninnermost stable separations, exhibiting features reflecting the zoom-whirl\ndynamics of the orbit there. Guided by the simulations, we develop a simple\nmodel for the change in orbital parameters of the binary during close\nencounters. Depending upon the initial parameters of the system, we find that\nmass transfer during non-merging close encounters can range from essentially\nzero to a sizable fraction of the initial neutron star mass. The same holds for\nthe amount of material outside the black hole post-merger, and in some cases\nroughly half of this material is estimated to be unbound. We also see that\nnon-merging close encounters generically excite large oscillations in the\nneutron star that are qualitatively consistent with f-modes. \n\n"}
{"id": "1111.3355", "contents": "Title: Gamma-ray burst afterglow scaling relations for the full blast wave\n  evolution Abstract: We demonstrate that gamma-ray burst afterglow spectra and light curves can be\ncalculated for arbitrary explosion and radiation parameters by scaling the peak\nflux and the critical frequencies connecting different spectral regimes. Only\none baseline calculation needs to be done for each jet opening angle and\nobserver angle. These calculations are done numerically using high-resolution\nrelativistic hydrodynamical afterglow blast wave simulations which include the\ntwo-dimensional dynamical features of expanding and decelerating afterglow\nblast waves. Any light curve can then be generated by applying scaling\nrelations to the baseline calculations.\n  As a result, it is now possible to fully fit for the shape of the jet break,\ne.g. at early time X-ray and optical frequencies. In addition, late-time radio\ncalorimetry can be improved since the general shape of the transition into the\nSedov-Taylor regime is now known for arbitrary explosion parameters so the\nexact moment when the Sedov-Taylor asymptote is reached in the light curve is\nno longer relevant.\n  When calculating the baselines, we find that the synchrotron critical\nfrequency and the cooling break frequency are strongly affected by the jet\nbreak. The synchrotron break temporal slope quickly drops to the steep late\ntime Sedov-Taylor slope, while the cooling break first steepens then rises to\nmeet the level of its shallow late time asymptote. \n\n"}
{"id": "1111.3377", "contents": "Title: New Electrodynamics of Pulsars Abstract: We have recently proposed that Force-Free Electrodynamics (FFE) does not\napply to pulsars -- pulsars should be described by the high-conductivity limit\nof Strong-Field Electrodynamics (SFE), which predicts an order-unity damping of\nthe Poynting flux, while FFE postulates zero damping. The strong damping result\nhas not been accepted by several pulsar experts, who claim that FFE basically\nworks and the Poynting flux damping can be arbitrarily small.\n  Here we consider a thought experiment -- cylindrical periodic pulsar. We show\nthat FFE is incapable of describing this object, while SFE predictions are\nphysically plausible. The intrinsic breakdown of FFE should mean that the FFE\ndescription of the singular current layer (the only region of magnetosphere\nwhere FFE and the high-conductivity SFE differ) is incorrect. Then the\nhigh-conductivity SFE should be the right theory for real pulsars too, and the\npure-FFE description of pulsars should be discarded. \n\n"}
{"id": "1111.4222", "contents": "Title: Statistical Tests of Noise and Harmony in Dark Matter Modulation Signals Abstract: The aim of the current work is a detailed time-series analysis of the data\nfrom Dark Matter direct detection experiments as well as related datasets. We\nexamine recent claims that the cosmic ray muon flux can be responsible for\ngenerating the modulation signals seen by DAMA and, more recently, by the\nCoGeNT collaboration. We find no evidence for such a strong correlation and\nshow that the two phenomena differ in their power spectrum, phase, and possibly\nin amplitude. In addition, we investigate in more detail, the time dependence\nof Dark Matter scattering. Since the signal is periodic with period of a year\n(due to the Earth's motion around the Sun), the presence of higher harmonics\ncan be expected. We show that the higher harmonics generically have similar\nphase to the annual modulation and the biannual mode in particular could\nprovide another handle in searching for Dark Matter in the laboratory. \n\n"}
{"id": "1111.5381", "contents": "Title: A GPU-Enabled, High-Resolution Cosmological Microlensing Parameter\n  Survey Abstract: In the era of synoptic surveys, the number of known gravitationally lensed\nquasars is set to increase by over an order of magnitude. These new discoveries\nwill enable a move from single-quasar studies to investigations of statistical\nsamples, presenting new opportunities to test theoretical models for the\nstructure of quasar accretion discs and broad emission line regions (BELRs). As\none crucial step in preparing for this influx of new lensed systems, a\nlarge-scale exploration of microlensing convergence-shear parameter space is\nwarranted, requiring the computation of O(10^5) high resolution magnification\nmaps. Based on properties of known lensed quasars, and expectations from\naccretion disc/BELR modelling, we identify regions of convergence-shear\nparameter space, map sizes, smooth matter fractions, and pixel resolutions that\nshould be covered. We describe how the computationally time-consuming task of\nproducing ~290000 magnification maps with sufficient resolution (10000^2\npixel/map) to probe scales from the inner edge of the accretion disc to the\nBELR can be achieved in ~400 days on a 100 teraflop/s high performance\ncomputing facility, where the processing performance is achieved with graphics\nprocessing units. We illustrate a use-case for the parameter survey by\ninvestigating the effects of varying the lens macro-model on accretion disc\nconstraints in the lensed quasar Q2237+0305. We find that although all\nconstraints are consistent within their current error bars, models with more\ndensely packed microlenses tend to predict shallower accretion disc radial\ntemperature profiles. With a large parameter survey such as the one described\nhere, such systematics on microlensing measurements could be fully explored. \n\n"}
{"id": "1111.5661", "contents": "Title: Stochastic backgrounds in alternative theories of gravity: overlap\n  reduction functions for pulsar timing arrays Abstract: In the next decade gravitational waves might be detected using a pulsar\ntiming array. In an effort to develop optimal detection strategies for\nstochastic backgrounds of gravitational waves in generic metric theories of\ngravity, we investigate the overlap reduction functions for these theories and\ndiscuss their features. We show that the sensitivity to non-transverse\ngravitational waves is greater than the sensitivity to transverse gravitational\nwaves and discuss the physical origin of this effect. We calculate the overlap\nreduction functions for the current NANOGrav Pulsar Timing Array (PTA) and show\nthat the sensitivity to the vector and scalar-longitudinal modes can increase\ndramatically for pulsar pairs with small angular separations. For example, the\nJ1853+1303-J1857+0943 pulsar pair, with an angular separation of about 3\ndegrees, is about 10^4 times more sensitive to the longitudinal component of\nthe stochastic background, if it is present, than the transverse components. \n\n"}
{"id": "1111.6192", "contents": "Title: Comments on \"First Results of the Phase II SIMPLE Dark Matter Search\" Abstract: The SIMPLE Collaboration has reported results from their superheated C2ClF5\ndroplet detectors, including a description of acoustic discrimination between\n\\alpha decays and nuclear recoils. Our concern is that the events in the\nneutron calibration data and the events identified as neutrons in the physics\ndata are not drawn from the same parent distribution. This fact calls into\nquestion the identification of the background events as neutrons, the use of\nthe calibration data to define the acceptance of WIMP-induced nuclear recoils,\nand the observation of discrimination against \\alpha's. \n\n"}
{"id": "1111.6501", "contents": "Title: Solutions of the Dirac equation with spin and pseudospin symmetry for\n  trigonometric Scarf potential in D-dimensions Abstract: Solutions of the Dirac equation with spin and pseudospin symmetry for the\nscalar and vector trigonometric scarf potential in $D$-dimensions within the\nframework of an approximation scheme to the centrifugal barrier are obtained.\nThe energy spectral and the two-component spinor eigenfunctions are obtained.\nThe bound state energy levels for various values of dimension $D$, $n$,\n$\\kappa$ and the potential range parameter $\\alpha$ are also presented. \n\n"}
{"id": "1111.7245", "contents": "Title: The First Public Release of South Pole Telescope Data: Maps of a\n  95-square-degree Field from 2008 Observations Abstract: The South Pole Telescope (SPT) has nearly completed a 2500-square-degree\nsurvey of the southern sky in three frequency bands. Here we present the first\npublic release of SPT maps and associated data products. We present\narcminute-resolution maps at 150 GHz and 220 GHz of an approximately\n95-square-degree field centered at R.A. 82.7 degrees, decl. -55 degrees. The\nfield was observed to a depth of approximately 17 micro-K arcmin at 150 GHz and\n41 micro-K arcmin at 220 GHz during the 2008 austral winter season. Two\nvariations on map filtering and map projection are presented, one tailored for\nproducing catalogs of galaxy clusters detected through their Sunyaev-Zel'dovich\neffect signature and one tailored for producing catalogs of emissive sources.\nWe describe the data processing pipeline, and we present instrument response\nfunctions, filter transfer functions, and map noise properties. All data\nproducts described in this paper are available for download at\nhttp://pole.uchicago.edu/public/data/maps/ra5h30dec-55 and from the NASA Legacy\nArchive for Microwave Background Data Analysis server. This is the first step\nin the eventual release of data from the full 2500-square-degree SPT survey. \n\n"}
{"id": "1112.3960", "contents": "Title: Modified Newtonian Dynamics (MOND): Observational Phenomenology and\n  Relativistic Extensions Abstract: A wealth of astronomical data indicate the presence of mass discrepancies in\nthe Universe. The motions observed in a variety of classes of extragalactic\nsystems exceed what can be explained by the mass visible in stars and gas.\nEither (i) there is a vast amount of unseen mass in some novel form - dark\nmatter - or (ii) the data indicate a breakdown of our understanding of dynamics\non the relevant scales, or (iii) both. Here, we first review a few outstanding\nchallenges for the dark matter interpretation of mass discrepancies in\ngalaxies, purely based on observations and independently of any alternative\ntheoretical framework. We then show that many of these puzzling observations\nare predicted by one single relation - Milgrom's law - involving an\nacceleration constant (or a characteristic surface density) of the order of the\nsquare-root of the cosmological constant in natural units. This relation can at\npresent most easily be interpreted as the effect of a single universal force\nlaw resulting from a modification of Newtonian dynamics (MOND) on galactic\nscales. We exhaustively review the current observational successes and problems\nof this alternative paradigm at all astrophysical scales, and summarize the\nvarious theoretical attempts (TeVeS, GEA, BIMOND, and others) made to\neffectively embed this modification of Newtonian dynamics within a relativistic\ntheory of gravity. \n\n"}
{"id": "1112.4532", "contents": "Title: Three-dimensional shapelets and an automated classification scheme for\n  dark matter haloes Abstract: We extend the two-dimensional Cartesian shapelet formalism to d-dimensions.\nConcentrating on the three-dimensional case, we derive shapelet-based equations\nfor the mass, centroid, root-mean-square radius, and components of the\nquadrupole moment and moment of inertia tensors. Using cosmological N-body\nsimulations as an application domain, we show that three-dimensional shapelets\ncan be used to replicate the complex sub-structure of dark matter halos and\ndemonstrate the basis of an automated classification scheme for halo shapes. We\ninvestigate the shapelet decomposition process from an algorithmic viewpoint,\nand consider opportunities for accelerating the computation of shapelet-based\nrepresentations using graphics processing units (GPUs). \n\n"}
{"id": "1112.4886", "contents": "Title: Powellsnakes II: a fast Bayesian approach to discrete object detection\n  in multi-frequency astronomical data sets Abstract: Powellsnakes is a Bayesian algorithm for detecting compact objects embedded\nin a diffuse background, and was selected and successfully employed by the\nPlanck consortium in the production of its first public deliverable: the Early\nRelease Compact Source Catalogue (ERCSC). We present the critical foundations\nand main directions of further development of PwS, which extend it in terms of\nformal correctness and the optimal use of all the available information in a\nconsistent unified framework, where no distinction is made between point\nsources (unresolved objects), SZ clusters, single or multi-channel detection.\nAn emphasis is placed on the necessity of a multi-frequency, multi-model\ndetection algorithm in order to achieve optimality. \n\n"}
{"id": "1112.6270", "contents": "Title: Searching for the first stars with the Gaia mission Abstract: We construct a theoretical model to predict the number of orphan afterglows\n(OA) from gamma-ray bursts (GRBs) triggered by primordial metal-free (Pop III)\nstars expected to be observed by the Gaia mission. In particular, we consider\nprimordial metal-free stars that were affected by radiation from other stars\n(Pop III.2) as a possible target. We use a semi-analytical approach that\nincludes all relevant feedback effects to construct cosmic star formation\nhistory and its connection with the cumulative number of GRBs. The OA events\nare generated using the Monte Carlo method, and realistic simulations of Gaia's\nscanning law are performed to derive the observation probability expectation.\nWe show that Gaia can observe up to 2.28 $\\pm$ 0.88 off-axis afterglows and\n2.78 $\\pm$ 1.41 on-axis during the five-year nominal mission. This implies that\na nonnegligible percentage of afterglows that may be observed by Gaia ($\\sim\n10%$) could have Pop III stars as progenitors. \n\n"}
{"id": "1201.0570", "contents": "Title: Multiscale probability mapping: groups, clusters and an algorithmic\n  search for filaments in SDSS Abstract: We have developed a multiscale structure identification algorithm for the\ndetection of overdensities in galaxy data that identifies structures having\nradii within a user-defined range. Our \"multiscale probability mapping\"\ntechnique combines density estimation with a shape statistic to identify local\npeaks in the density field. This technique takes advantage of a user-defined\nrange of scale sizes, which are used in constructing a coarse-grained map of\nthe underlying fine-grained galaxy distribution, from which overdense\nstructures are then identified. In this study we have compiled a catalogue of\ngroups and clusters at 0.025 < z < 0.24 based on the Sloan Digital Sky Survey,\nData Release 7, quantifying their significance and comparing with other\ncatalogues. Most measured velocity dispersions for these structures lie between\n50 and 400 km/s. A clear trend of increasing velocity dispersion with radius\nfrom 0.2 to 1 Mpc/h is detected, confirming the lack of a sharp division\nbetween groups and clusters. A method for quantifying elongation is also\ndeveloped to measure the elongation of group and cluster environments. By using\nour group and cluster catalogue as a coarse-grained representation of the\ngalaxy distribution for structure sizes of <~ 1 Mpc/h, we identify 53 filaments\n(from an algorithmically-derived set of 100 candidates) as elongated unions of\ngroups and clusters at 0.025 < z < 0.13. These filaments have morphologies that\nare consistent with previous samples studied. \n\n"}
{"id": "1201.1700", "contents": "Title: HI Epoch of Reionization Arrays Abstract: There are few data available with which to constrain the thermal history of\nthe intergalactic medium (IGM) following global recombination. Thus far, most\nconstraints flow from analyses of the Cosmic Microwave Background and optical\nspectroscopy along a few lines of sight. However, direct study of the IGM in\nemission or absorption against the CMB via the 1S hyperfine transition of\nHydrogen would enable broad characterization thermal history and source\npopulations. New generations of radio arrays are in development to measure this\nline signature. Bright foreground emission and the complexity of instrument\ncalibration models are significant hurdles. How to optimize these is uncertain,\nresulting in a diversity in approaches. We discuss recent limits on line\nbrightness, array efforts including the new Large Aperture Experiment to Detect\nthe Dark Ages (LEDA), and the next generation Hydrogen Reionization Array\n(HERA) concept. \n\n"}
{"id": "1201.3370", "contents": "Title: A data-driven model for spectra: Finding double redshifts in the Sloan\n  Digital Sky Survey Abstract: We present a data-driven method - heteroscedastic matrix factorization, a\nkind of probabilistic factor analysis - for modeling or performing\ndimensionality reduction on observed spectra or other high-dimensional data\nwith known but non-uniform observational uncertainties. The method uses an\niterative inverse-variance-weighted least-squares minimization procedure to\ngenerate a best set of basis functions. The method is similar to principal\ncomponents analysis, but with the substantial advantage that it uses\nmeasurement uncertainties in a responsible way and accounts naturally for\npoorly measured and missing data; it models the variance in the\nnoise-deconvolved data space. A regularization can be applied, in the form of a\nsmoothness prior (inspired by Gaussian processes) or a non-negative constraint,\nwithout making the method prohibitively slow. Because the method optimizes a\njustified scalar (related to the likelihood), the basis provides a better fit\nto the data in a probabilistic sense than any PCA basis. We test the method on\nSDSS spectra, concentrating on spectra known to contain two redshift\ncomponents: These are spectra of gravitational lens candidates and massive\nblack-hole binaries. We apply a hypothesis test to compare one-redshift and\ntwo-redshift models for these spectra, utilizing the data-driven model trained\non a random subset of all SDSS spectra. This test confirms 129 of the 131 lens\ncandidates in our sample and all of the known binary candidates, and turns up\nvery few false positives. \n\n"}
{"id": "1201.3563", "contents": "Title: A Mock Data Challenge for the Einstein Gravitational-Wave Telescope Abstract: Einstein Telescope (ET) is conceived to be a third generation\ngravitational-wave observatory. Its amplitude sensitivity would be a factor ten\nbetter than advanced LIGO and Virgo and it could also extend the low-frequency\nsensitivity down to 1--3 Hz, compared to the 10--20 Hz of advanced detectors.\nSuch an observatory will have the potential to observe a variety of different\nGW sources, including compact binary systems at cosmological distances. ET's\nexpected reach for binary neutron star (BNS) coalescences is out to redshift\n$z\\simeq 2$ and the rate of detectable BNS coalescences could be as high as one\nevery few tens or hundreds of seconds, each lasting up to several days. %in the\nsensitive frequency band of ET. With such a signal-rich environment, a key\nquestion in data analysis is whether overlapping signals can be discriminated.\nIn this paper we simulate the GW signals from a cosmological population of BNS\nand ask the following questions: Does this population create a confusion\nbackground that limits ET's ability to detect foreground sources? How efficient\nare current algorithms in discriminating overlapping BNS signals? Is it\npossible to discern the presence of a population of signals in the data by\ncross-correlating data from different detectors in the ET observatory? We find\nthat algorithms currently used to analyze LIGO and Virgo data are already\npowerful enough to detect the sources expected in ET, but new algorithms are\nrequired to fully exploit ET data. \n\n"}
{"id": "1201.4560", "contents": "Title: Recoiling Ion-Channeling in Direct Dark Matter Detectors Abstract: The channeling of the recoiling nucleus in crystalline detectors after a WIMP\ncollision would produce a larger scintillation or ionization signal in direct\ndetection experiments than otherwise expected. I present estimates of\nchanneling fractions obtained using analytic models developed from the 1960's\nonwards to describe channeling and blocking effects. We find the fractions to\nbe too small to affect the fits to potential WIMP candidates. I also examine\nthe possibility of detecting a daily modulation of the dark matter signal due\nto channeling. \n\n"}
{"id": "1201.4582", "contents": "Title: Technical aspects in dark matter investigations Abstract: Some theoretical and experimental aspects regarding the direct dark matter\nfield are mentioned. In particular some arguments, which play a relevant role\nin the evaluation of model dependent interpretations of experimental results\nand in comparisons, are shortly addressed. \n\n"}
{"id": "1201.4752", "contents": "Title: A new third-order cosmic shear statistics: Separating E/B-mode\n  correlations on a finite interval Abstract: Decomposing the shear signal into E and B-modes properly, i.e. without\nleakage of B-modes into the E-mode signal and vice versa, has been a\nlong-standing problem in weak gravitational lensing. At the two-point level\nthis problem was resolved by developing the so-called ring statistics, and\nlater the COSEBIs; however, extending these concepts to the three-point level\nis far from trivial. Currently used methods to decompose three-point shear\ncorrelation functions (3PCFs) into E- and B-modes require knowledge of the 3PCF\ndown to arbitrary small scales. This implies that the 3PCF needs to be modeled\non scales smaller than the minimum separation of 2 galaxies and subsequently\nwill be biased towards the model, or, in the absence of a model, the statistics\nis affected by E/B-mode leakage (or mixing). In this paper we derive a new\nthird-order E/B-mode statistic that performs the decomposition using the 3PCF\nonly on a finite interval, and thereby is free of any E/B-mode leakage while at\nthe same time relying solely on information from the data. In addition, we\nrelate this third-order ring statistics to the convergence field, thereby\nenabling a fast and convenient calculation of this statistic from numerical\nsimulations. We note that our new statistics should be applicable to\ncorresponding E/B-mode separation problems in the CMB polarization field. \n\n"}
{"id": "1201.5375", "contents": "Title: A New Window on Primordial non-Gaussianity Abstract: We know very little about primordial curvature perturbations on scales\nsmaller than about a Mpc. Measurements of the mu-type distortion of the CMB\nspectrum provide the unique opportunity to probe these scales over the\nunexplored range from 50 to 10^4 Mpc^-1. This is a very clean probe, in that it\nrelies only on well-understood linear evolution. We point out that correlations\nbetween mu-distortion and temperature anisotropies can be used to test\nGaussianity at these very small scales. In particular the mu-T cross\ncorrelation is proportional to the very squeezed limit of the primordial\nbispectrum and hence measures fNL^loc, while mu-mu is proportional to the\nprimordial trispectrum and measures tauNL. We present a Fisher matrix forecast\nof the observational constraints. \n\n"}
{"id": "1202.2700", "contents": "Title: New Heavy Flavor Contributions to the DIS Structure Function\n  $F_2(x,Q^2)$ at $O(\\alpha_s^3) Abstract: We report on recent results obtained for the massive Wilson coefficients\nwhich contribute to the structure function $F_2(x,Q^2)$ at $O(\\alpha_s^3)$ in\nthe region $Q^2/m^2 \\gsim 10$. In the calculation new species of harmonic sums\nand harmonic polylogarithms generated by cyclotomic polynomials arise in\nintermediary results which are briefly discussed. \n\n"}
{"id": "1202.2861", "contents": "Title: Optimal filters for detecting cosmic bubble collisions Abstract: A number of well-motivated extensions of the LCDM concordance cosmological\nmodel postulate the existence of a population of sources embedded in the cosmic\nmicrowave background (CMB). One such example is the signature of cosmic bubble\ncollisions which arise in models of eternal inflation. The most unambiguous way\nto test these scenarios is to evaluate the full posterior probability\ndistribution of the global parameters defining the theory; however, a direct\nevaluation is computationally impractical on large datasets, such as those\nobtained by the Wilkinson Microwave Anisotropy Probe (WMAP) and Planck. A\nmethod to approximate the full posterior has been developed recently, which\nrequires as an input a set of candidate sources which are most likely to give\nthe largest contribution to the likelihood. In this article, we present an\nimproved algorithm for detecting candidate sources using optimal filters, and\napply it to detect candidate bubble collision signatures in WMAP 7-year\nobservations. We show both theoretically and through simulations that this\nalgorithm provides an enhancement in sensitivity over previous methods by a\nfactor of approximately two. Moreover, no other filter-based approach can\nprovide a superior enhancement of these signatures. Applying our algorithm to\nWMAP 7-year observations, we detect eight new candidate bubble collision\nsignatures for follow-up analysis. \n\n"}
{"id": "1202.2864", "contents": "Title: General Relativistic Modeling of Magnetized Jets from Accreting Black\n  Holes Abstract: Recent advances in general relativistic magnetohydrodynamic modeling of jets\noffer unprecedented insights into the inner workings of accreting black holes\nthat power the jets in active galactic nuclei (AGN) and other accretion\nsystems. I will present the results of recent studies that determine\nspin-dependence of jet power and discuss the implications for the AGN radio\nloud/quiet dichotomy and recent observations of high jet power in a number of\nAGN. \n\n"}
{"id": "1202.5882", "contents": "Title: Turbulence in the ICM from mergers, cool-core sloshing and jets: results\n  from a new multi-scale filtering approach Abstract: We have designed a simple multi-scale method that identifies turbulent\nmotions in hydrodynamical grid simulations. The method does not assmume ant\na-priori coherence scale to distinguish laminar and turbulent flows. Instead,\nthe local mean velocity field around each cell is reconstructed with a\nmulti-scale filtering technique, yielding the maximum scale of turbulent eddies\nby means of iterations. The method is robust, fast and easily applicable to any\ngrid simulation. We present here the application of this technique to the study\nof spatial and spectral properties of turbulence in the intra cluster medium,\nmeasuring turbulent diffusion and anisotropy of the turbulent velocity field\nfor a variety of driving mechanisms: a) accretion of matter in galaxy clusters\n(simulated with ENZO); b) sloshing motions around cool-cores (simulated with\nFLASH); c) jet outflows from active galactic nuclei, AGN (simulated with\nFLASH). The turbulent velocities driven by matter accretion in galaxy clusters\nare mostly tangential in the inner regions (inside the cluster virial radius)\nand isotropic in regions close to the virial radius. The same is found for\nturbulence excited by cool core sloshing, while the jet outflowing from AGN\ndrives mostly radial turbulence motions near its sonic point and beyond.\nTurbulence leads to a diffusivity in the range =10^29-10^30 cm^2/s in the intra\ncluster medium. On average, the energetically dominant mechanism of turbulence\ndriving in the intra cluster medium is represented by accretion of matter and\nmajor mergers during clusters evolution. \n\n"}
{"id": "1203.2920", "contents": "Title: Effects of post-Newtonian Spin Alignment on the Distribution of\n  Black-Hole Recoils Abstract: Recent numerical relativity simulations have shown that the final black hole\nproduced in a binary merger can recoil with a velocity as large as 5,000 km/s.\nBecause of enhanced gravitational-wave emission in the so-called \"hang-up\"\nconfigurations, this maximum recoil occurs when the black-hole spins are\npartially aligned with the orbital angular momentum. We revisit our previous\nstatistical analysis of post-Newtonian evolutions of black-hole binaries in the\nlight of these new findings. We demonstrate that despite these new\nconfigurations with enhanced recoil velocities, spin alignment during the\npost-Newtonian stage of the inspiral will still significantly suppress (or\nenhance) kick magnitudes when the initial spin of the more massive black hole\nis more (or less) closely aligned with the orbital angular momentum than that\nof the smaller hole. We present a preliminary study of how this post-Newtonian\nspin alignment affects the ejection probabilities of supermassive black holes\nfrom their host galaxies with astrophysically motivated mass ratio and initial\nspin distributions. We find that spin alignment suppresses (enhances) ejection\nprobabilities by ~ 40% (20%) for an observationally motivated mass-dependent\ngalactic escape velocity, and by an even greater amount for a constant escape\nvelocity of 1,000 km/s. Kick suppression is thus at least a factor two more\nefficient than enhancement. \n\n"}
{"id": "1203.5790", "contents": "Title: Low Frequency Imaging of Fields at High Galactic Latitude with the\n  Murchison Widefield Array 32-Element Prototype Abstract: The Murchison Widefield Array (MWA) is a new low-frequency, wide\nfield-of-view radio interferometer under development at the Murchison\nRadio-astronomy Observatory (MRO) in Western Australia. We have used a\n32-element MWA prototype interferometer (MWA-32T) to observe two 50-degree\ndiameter fields in the southern sky in the 110 MHz to 200 MHz band in order to\nevaluate the performance of the MWA-32T, to develop techniques for epoch of\nreionization experiments, and to make measurements of astronomical foregrounds.\nWe developed a calibration and imaging pipeline for the MWA-32T, and used it to\nproduce ~15' angular resolution maps of the two fields. We perform a blind\nsource extraction using these confusion-limited images, and detect 655 sources\nat high significance with an additional 871 lower significance source\ncandidates. We compare these sources with existing low-frequency radio surveys\nin order to assess the MWA-32T system performance, wide field analysis\nalgorithms, and catalog quality. Our source catalog is found to agree well with\nexisting low-frequency surveys in these regions of the sky and with statistical\ndistributions of point sources derived from Northern Hemisphere surveys; it\nrepresents one of the deepest surveys to date of this sky field in the 110 MHz\nto 200 MHz band. \n\n"}
{"id": "1203.6835", "contents": "Title: The CRESST II Dark Matter Search Abstract: Direct Dark Matter detection with cryodetectors is briefly discussed, with\nparticular mention of the possibility of the identification of the recoil\nnucleus. Preliminary results from the CREEST II Dark Matter search, with 730\nkg-days of data, are presented. Major backgrounds and methods of identifying\nand dealing with them are indicated. \n\n"}
{"id": "1204.2546", "contents": "Title: The dark matter crisis: falsification of the current standard model of\n  cosmology Abstract: The current standard model of cosmology (SMoC) requires The Dual Dwarf Galaxy\nTheorem to be true according to which two types of dwarf galaxies must exist:\nprimordial dark-matter (DM) dominated (type A) dwarf galaxies, and tidal-dwarf\nand ram-pressure-dwarf (type B) galaxies void of DM. Type A dwarfs surround the\nhost approximately spherically, while type B dwarfs are typically correlated in\nphase-space. Type B dwarfs must exist in any cosmological theory in which\ngalaxies interact. Only one type of dwarf galaxy is observed to exist on the\nbaryonic Tully-Fisher plot and in the radius-mass plane. The Milky Way\nsatellite system forms a vast phase-space-correlated structure that includes\nglobular clusters and stellar and gaseous streams. Other galaxies also have\nphase-space correlated satellite systems. Therefore, The Dual Dwarf Galaxy\nTheorem is falsified by observation and dynamically relevant cold or warm DM\ncannot exist. It is shown that the SMoC is incompatible with a large set of\nother extragalactic observations. Other theoretical solutions to cosmological\nobservations exist. In particular, alone the empirical\nmass-discrepancy--acceleration correlation constitutes convincing evidence that\ngalactic-scale dynamics must be Milgromian. Major problems with inflationary\nbig bang cosmologies remain unresolved. \n\n"}
{"id": "1204.4096", "contents": "Title: Image Analysis for Cosmology: Shape Measurement Challenge Review &\n  Results from the Mapping Dark Matter Challenge Abstract: In this paper we present results from the Mapping Dark Matter competition\nthat expressed the weak lensing shape measurement task in its simplest form and\nas a result attracted over 700 submissions in 2 months and a factor of 3\nimprovement in shape measurement accuracy on high signal to noise galaxies,\nover previously published results, and a factor 10 improvement over methods\ntested on constant shear blind simulations. We also review weak lensing shape\nmeasurement challenges, including the Shear TEsting Programmes (STEP1 and\nSTEP2) and the GRavitational lEnsing Accuracy Testing competitions (GREAT08 and\nGREAT10). \n\n"}
{"id": "1204.6301", "contents": "Title: A Comparative Study of Local Galaxy Clusters: I. Derived X-ray\n  Observables Abstract: We examine systematic differences in the derived X-ray properties of galaxy\nclusters as reported by three different groups: Vikhlinin et al. (2009a), Mantz\net al. (2010b), and Planck Collaboration (2011b). The sample overlap between\nany two pairs of works ranges between 16 to 28 galaxy clusters in common. We\nfind systematic differences in most reported properties, including the total\ncluster mass, M500. The most extreme case is an average 45% \\pm 5% difference\nin cluster mass between the Planck Collaboration (2011b) and Mantz et al.\n(2010b), for clusters at z > 0.13 (averaged over 16 clusters). These mass\ndifferences induce differences in cluster observables defined within an R500\naperture. After accounting for aperture differences, we find very good\nagreement in gas mass estimates between the different groups. However, the\nsoft-band X-ray luminosity, LX, core-excised spectroscopic temperature, TX, and\ngas thermal energy, YX = MgasTX display mean differences at the 5%-15% level.\nWe also find that the low (z \\leq 0.13) and high (z \\geq 0.13) galaxy cluster\nsamples in Planck Collaboration (2011b) appear to be systematically different:\nthe YSZ/YX ratio for these two sub- samples is ln(YSZ/YX) = -0.06 \\pm 0.04 and\nln(YSZ/YX) = 0.08 \\pm 0.04 for the low and high redshift sub-samples\nrespectively. \n\n"}
{"id": "1205.1048", "contents": "Title: Impact of Redshift Information on Cosmological Applications with\n  Next-Generation Radio Surveys Abstract: In this paper, we explore how the forthcoming generation of large-scale radio\ncontinuum surveys, with the inclusion of some degree of redshift information,\ncan constrain cosmological parameters. By cross-matching these radio surveys\nwith shallow optical to near-infrared surveys, we can essentially separate the\nsource distribution into a low- and a high-redshift sample, thus providing a\nconstraint on the evolution of cosmological parameters such as those related to\ndark energy. We examine two radio surveys, the Evolutionary Map of the Universe\n(EMU) and the Westerbork Observations of the Deep APERTIF Northern sky (WODAN).\nA crucial advantage is their combined potential to provide a deep, full-sky\nsurvey. The surveys used for the cross-identifications are SkyMapper and SDSS,\nfor the southern and northern skies, respectively. We concentrate on the galaxy\nclustering angular power spectrum as our benchmark observable, and find that\nthe possibility of including such low redshift information yields major\nimprovements in the determination of cosmological parameters. With this\napproach, and provided a good knowledge of the galaxy bias evolution, we are\nable to put strict constraints on the dark energy parameters, i.e.\nw_0=-0.9+/-0.041 and w_a=-0.24+/-0.13, with type Ia supernovae and CMB priors\n(with a one-parameter bias in this case); this corresponds to a Figure of Merit\n(FoM) > 600, which is twice better than what is obtained by using only the\ncross-identified sources and greater than four time better than the case\nwithout any redshift information at all. \n\n"}
{"id": "1205.3089", "contents": "Title: Radio Searches of Fermi LAT Sources and Blind Search Pulsars: The Fermi\n  Pulsar Search Consortium Abstract: We present a summary of the Fermi Pulsar Search Consortium (PSC), an\ninternational collaboration of radio astronomers and members of the Large Area\nTelescope (LAT) collaboration, whose goal is to organize radio follow-up\nobservations of Fermi pulsars and pulsar candidates among the LAT gamma-ray\nsource population. The PSC includes pulsar observers with expertise using the\nworld's largest radio telescopes that together cover the full sky. We have\nperformed very deep observations of all 35 pulsars discovered in blind\nfrequency searches of the LAT data, resulting in the discovery of radio\npulsations from four of them. We have also searched over 300 LAT gamma-ray\nsources that do not have strong associations with known gamma-ray emitting\nsource classes and have pulsar-like spectra and variability characteristics.\nThese searches have led to the discovery of a total of 43 new radio millisecond\npulsars (MSPs) and four normal pulsars. These discoveries greatly increase the\nknown population of MSPs in the Galactic disk, more than double the known\npopulation of so-called `black widow' pulsars, and contain many promising\ncandidates for inclusion in pulsar timing arrays. \n\n"}
{"id": "1205.5268", "contents": "Title: Gas pile-up, gap overflow, and Type 1.5 migration in circumbinary disks:\n  application to supermassive black hole binaries Abstract: We study the interaction of a supermassive black hole (SMBH) binary and a\nstandard radiatively efficient thin accretion disk. We examine steady-state\nconfigurations of the disk and migrating SMBH system, self-consistently\naccounting for tidal and viscous torques and heating, radiative diffusion\nlimited cooling, gas and radiation pressure, and the decay of the binary's\norbit. We obtain a \"phase diagram\" of the system as a function of binary\nparameters, showing regimes in which both the disk structure and migration have\na different character. Although massive binaries can create a central gap in\nthe disk at large radii, the tidal barrier of the secondary causes a\nsignificant pile-up of gas outside of its orbit, which can lead to the closing\nof the gap. We find that this spillover occurs at an orbital separation as\nlarge as ~200 M_7^{-1/2} gravitational radii, where M = 10^7 M_7 Msun is the\ntotal binary mass. If the secondary is less massive than ~10^6 Msun, then the\ngap is closed before gravitational waves (GWs) start dominating the orbital\ndecay. In this regime, the disk is still strongly perturbed, but the piled-up\ngas continuously overflows as in a porous dam, and crosses inside the\nsecondary's orbit. The corresponding migration rate, which we label Type 1.5,\nis slower than the usual limiting cases known as Type I and II migration.\nCompared to an unperturbed disk, the steady-state disk in the overflowing\nregime is up to several hundred times brighter in the optical bands. Surveys\nsuch as PanSTARRS or LSST may discover the periodic variability of this\npopulation of binaries. Our results imply that the circumbinary disks around\nSMBHs can extend to small radii during the last stages of their merger, when\nthey are detectable by LISA, and may produce coincident electromagnetic (EM)\nemission similar to active galactic nuclei (AGN). \n\n"}
{"id": "1205.5775", "contents": "Title: Shape of Clusters as a Probe of Screening Mechanisms in Modified Gravity Abstract: Scalar fields are crucial components in high energy physics and extensions of\nGeneral Relativity. The fact they are not observed in the solar system may be\ndue to a mechanism which screens their presence in high dense regions. We show\nhow observations of the ellipticity of galaxy clusters can discriminate between\nmodels with and without scalar fields and even between different screening\nmechanisms. Using nowadays X-ray observations we put novel constraints on the\ndifferent models. \n\n"}
{"id": "1205.6495", "contents": "Title: On the anomalous afterglow seen in a chameleon afterglow search Abstract: We present data from our investigation of the anomalous orange-colored\nafterglow that was seen in the GammeV Chameleon Afterglow Search (CHASE). These\ndata includes information about the broad band color of the observed glow, the\nrelationship between the glow and the temperature of the apparatus, and other\ndata taken prior to and during the science operations of CHASE. While differing\nin several details, the generic properties of the afterglow from CHASE are\nsimilar to luminescence seen in some vacuum compounds. Contamination from this,\nor similar, luminescent signatures will likely impact the design of\nimplementation of future experiments involving single photon detectors and high\nintensity light sources in a cryogenic environment. \n\n"}
{"id": "1206.1254", "contents": "Title: The Kilo-Degree Survey Abstract: The Kilo Degree Survey (KiDS) is a 1500 square degree optical imaging survey\nwith the recently commissioned OmegaCAM wide-field imager on the VLT Survey\nTelescope (VST). A suite of data products will be delivered to the European\nSouthern Observatory (ESO) and the community by the KiDS survey team. Spread\nover Europe, the KiDS team uses Astro-WISE to collaborate efficiently and pool\nhardware resources. In Astro-WISE the team shares, calibrates and archives all\nsurvey data. The data-centric architectural design realizes a dynamic 'live\narchive' in which new KiDS survey products of improved quality can be shared\nwith the team and eventually the full astronomical community in a flexible and\ncontrollable manner. \n\n"}
{"id": "1206.2245", "contents": "Title: Pippi - painless parsing, post-processing and plotting of posterior and\n  likelihood samples Abstract: Interpreting samples from likelihood or posterior probability density\nfunctions is rarely as straightforward as it seems it should be. Producing\npublication-quality graphics of these distributions is often similarly painful.\nIn this short note I describe pippi, a simple, publicly-available package for\nparsing and post-processing such samples, as well as generating high-quality\nPDF graphics of the results. Pippi is easily and extensively configurable and\ncustomisable, both in its options for parsing and post-processing samples, and\nin the visual aspects of the figures it produces. I illustrate some of these\nusing an existing supersymmetric global fit, performed in the context of a\ngamma-ray search for dark matter. Pippi can be downloaded and followed at\nhttp://github.com/patscott/pippi . \n\n"}
{"id": "1206.3690", "contents": "Title: A six-parameter space to describe galaxy diversification Abstract: Galaxy diversification proceeds by transforming events like accretion,\ninteraction or mergers. These explain the formation and evolution of galaxies\nthat can now be described with many observables. Multivariate analyses are the\nobvious tools to tackle the datasets and understand the differences between\ndifferent kinds of objects. However, depending on the method used,\nredundancies, incompatibilities or subjective choices of the parameters can\nvoid the usefulness of such analyses. The behaviour of the available parameters\nshould be analysed before an objective reduction of dimensionality and\nsubsequent clustering analyses can be undertaken, especially in an evolutionary\ncontext. We study a sample of 424 early-type galaxies described by 25\nparameters, ten of which are Lick indices, to identify the most structuring\nparameters and determine an evolutionary classification of these objects. Four\nindependent statistical methods are used to investigate the discriminant\nproperties of the observables and the partitioning of the 424 galaxies:\nPrincipal Component Analysis, K-means cluster analysis, Minimum Contradiction\nAnalysis and Cladistics. (abridged) \n\n"}
{"id": "1206.4049", "contents": "Title: Lightcone mock catalogues from semi-analytic models of galaxy formation\n  - I. Construction and application to the BzK colour selection Abstract: We introduce a method for constructing end-to-end mock galaxy catalogues\nusing a semi-analytical model of galaxy formation, applied to the halo merger\ntrees extracted from a cosmological N-body simulation. The mocks that we\nconstruct are lightcone catalogues, in which a galaxy is placed according to\nthe epoch at which it first enters the past lightcone of the observer, and\nincorporate the evolution of galaxy properties with cosmic time. We determine\nthe position between the snapshot outputs at which a galaxy enters the\nobserver's lightcone by interpolation. As an application, we consider the\neffectiveness of the BzK colour selection technique, which was designed to\nisolate galaxies in the redshift interval 1.4<z<2.5. The mock catalogue is in\nreasonable agreement with the observed number counts of all BzK galaxies, as\nwell as with the observed counts of the subsample of BzKs that are star-forming\ngalaxies. We predict that over 75 per cent of the model galaxies with\nK_{AB}<=23, and 1.4<z<2.5, are selected by the BzK technique. Interloper\ngalaxies, outside the intended redshift range, are predicted to dominate bright\nsamples of BzK galaxies (i.e. with K_{AB}<=21). Fainter K-band cuts are\nnecessary to reduce the predicted interloper fraction. We also show that\nshallow B-band photometry can lead to confusion in classifying BzK galaxies as\nbeing star-forming or passively evolving. Overall, we conclude that the BzK\ncolour selection technique is capable of providing a sample of galaxies that is\nrepresentative of the 1.4<z<2.5 galaxy population. \n\n"}
{"id": "1206.4151", "contents": "Title: A redshift - observation-time relation for gamma-ray bursts: evidence of\n  a distinct sub-luminous population Abstract: We show how the redshift and peak-flux distributions of gamma-ray bursts\n(GRBs) have an observation time dependence that can be used to discriminate\nbetween different burst populations. We demonstrate how observation time\nrelations can be derived from the standard integral distributions and that they\ncan differentiate between GRB populations detected by both the BATSE and\n\\emph{Swift} satellites. Using \\emph{Swift} data we show that a\nredshift--observation-time relation (log\\,$Z$\\,--\\,log\\,$T$) is consistent with\nboth a peak-flux\\,--\\,observation time relation (log\\,$P$\\,--\\,log\\,$T$) and a\nstandard log\\,$N$\\,--\\,log\\,$P$ brightness distribution. As the method depends\nonly on rarer small-$z$ events, it is invariant to high-$z$ selection effects.\nWe use the log\\,$Z$\\,--\\,log\\,$T$ relation to show that sub-luminous GRBs are a\ndistinct population occurring at a higher rate of order $150^{+180}_{-90}\n\\mathrm{Gpc}^{-3}\\mathrm{yr}^{-1}$. Our analysis suggests that GRB 060505 -- a\nrelatively nearby GRB observed without any associated supernova -- is\nconsistent with a sub-luminous population of bursts. Finally, we suggest that\nour relations can be used as a consistency test for some of the proposed GRB\nspectral energy correlations. \n\n"}
{"id": "1206.5032", "contents": "Title: Gravity theories, Transverse Doppler and Gravitational Redshifts in\n  Galaxy Clusters Abstract: There is growing interest in testing alternative gravity theories using the\nsubtle gravitational redshifts in clusters of galaxies. However, current models\nall neglect a transverse Doppler redshift of similar magnitude, and some models\nare not self-consistent. An equilibrium model would fix the gravitational and\ntransverse Doppler velocity shifts to be about 6sigma^2/c and 3sigma^2/2c in\norder to fit the observed velocity dispersion sigma self-consistently. This\nresult comes from the Virial Theorem for a spherical isotropic cluster, and is\ninsensitive to the theory of gravity. A gravitational redshift signal also does\nnot directly distinguish between the Einsteinian and f(R) gravity theories,\nbecause each theory requires different dark halo mass function to keep the\nclusters in equilibrium. When this constraint is imposed, the gravitational\nredshift has no sensitivity to theory. Indeed our N-body simulations show that\nthe halo mass function differs in f(R), and that the transverse Doppler effect\nis stronger than analytically predicted due to non-equilibrium. \n\n"}
{"id": "1207.3347", "contents": "Title: Spectroscopic failures in photometric redshift calibration: cosmological\n  biases and survey requirements Abstract: We use N-body-spectro-photometric simulations to investigate the impact of\nincompleteness and incorrect redshifts in spectroscopic surveys to photometric\nredshift training and calibration and the resulting effects on cosmological\nparameter estimation from weak lensing shear-shear correlations. The photometry\nof the simulations is modeled after the upcoming Dark Energy Survey and the\nspectroscopy is based on a low/intermediate resolution spectrograph with\nwavelength coverage of 5500{\\AA} < {\\lambda} < 9500{\\AA}. The principal\nsystematic errors that such a spectroscopic follow-up encounters are\nincompleteness (inability to obtain spectroscopic redshifts for certain\ngalaxies) and wrong redshifts. Encouragingly, we find that a neural\nnetwork-based approach can effectively describe the spectroscopic\nincompleteness in terms of the galaxies' colors, so that the spectroscopic\nselection can be applied to the photometric sample. Hence, we find that\nspectroscopic incompleteness yields no appreciable biases to cosmology,\nalthough the statistical constraints degrade somewhat because the photometric\nsurvey has to be culled to match the spectroscopic selection. Unfortunately,\nwrong redshifts have a more severe impact: the cosmological biases are\nintolerable if more than a percent of the spectroscopic redshifts are\nincorrect. Moreover, we find that incorrect redshifts can also substantially\ndegrade the accuracy of training set based photo-z estimators. The main problem\nis the difficulty of obtaining redshifts, either spectroscopically or\nphotometrically, for objects at z > 1.3. We discuss several approaches for\nreducing the cosmological biases, in particular finding that photo-z error\nestimators can reduce biases appreciably. \n\n"}
{"id": "1207.4405", "contents": "Title: IR Divergence in Inflationary Tensor Perturbations from Fermion Loops Abstract: We estimate fermion loop corrections to the two-point correlation function of\nprimordial tensor perturbations in a slow-roll inflationary background. We\nparticularly compute an explicit term of one-loop correction from a massless\nfermion, and then extend to the complete Interaction Hamiltonian. After that,\nwe study one-loop corrections contributed by a massive fermion to primordial\ntensor fluctuations. The loop correction arisen from a massless fermion field\ncontains logarithms and thus may constrain the validity of perturbation theory\nin inflationary cosmology, but the situation could be relaxed once the\nfermion's mass is taken into account. Another one-loop diagram for a massive\nfermion which involves one vertex is constrained by a UV cutoff as expected by\nquantum field theory. Our result shows that loop corrections of a fermion field\nhave the same sign as those of a scalar field, and thus implies that the\ninclusion of fermion loop corrections may not help to alleviate the issue of IR\ndivergence in inflationary cosmology. \n\n"}
{"id": "1207.5034", "contents": "Title: Second Season QUIET Observations: Measurements of the CMB Polarization\n  Power Spectrum at 95 GHz Abstract: The Q/U Imaging ExperimenT (QUIET) has observed the cosmic microwave\nbackground (CMB) at 43 and 95GHz. The 43-GHz results have been published in\nQUIET Collaboration et al. (2011), and here we report the measurement of CMB\npolarization power spectra using the 95-GHz data. This data set comprises 5337\nhours of observations recorded by an array of 84 polarized coherent receivers\nwith a total array sensitivity of 87 uK sqrt(s). Four low-foreground fields\nwere observed, covering a total of ~1000 square degrees with an effective\nangular resolution of 12.8', allowing for constraints on primordial\ngravitational waves and high-signal-to-noise measurements of the E-modes across\nthree acoustic peaks. The data reduction was performed using two independent\nanalysis pipelines, one based on a pseudo-Cl (PCL) cross-correlation approach,\nand the other on a maximum-likelihood (ML) approach. All data selection\ncriteria and filters were modified until a predefined set of null tests had\nbeen satisfied before inspecting any non-null power spectrum. The results\nderived by the two pipelines are in good agreement. We characterize the EE, EB\nand BB power spectra between l=25 and 975 and find that the EE spectrum is\nconsistent with LCDM, while the BB power spectrum is consistent with zero.\nBased on these measurements, we constrain the tensor-to-scalar ratio to\nr=1.1+0.9-0.8 (r<2.8 at 95% C.L.) as derived by the ML pipeline, and\nr=1.2+0.9-0.8 (r<2.7 at 95% C.L.) as derived by the PCL pipeline. In one of the\nfields, we find a correlation with the dust component of the Planck Sky Model,\nthough the corresponding excess power is small compared to statistical errors.\nFinally, we derive limits on all known systematic errors, and demonstrate that\nthese correspond to a tensor-to-scalar ratio smaller than r=0.01, the lowest\nlevel yet reported in the literature. \n\n"}
{"id": "1207.5537", "contents": "Title: Observed versus modelled u,g,r,i,z-band photometry of local galaxies -\n  Evaluation of model performance Abstract: We test how well available stellar population models can reproduce observed\nu,g,r,i,z-band photometry of the local galaxy population (0.02<=z<=0.03) as\nprobed by the SDSS. Our study is conducted from the perspective of a user of\nthe models, who has observational data in hand and seeks to convert them into\nphysical quantities. Stellar population models for galaxies are created by\nsynthesizing star formations histories and chemical enrichments using single\nstellar populations from several groups (Starburst99, GALAXEV, Maraston2005,\nGALEV). The role of dust is addressed through a simplistic, but observationally\nmotivated, dust model that couples the amplitude of the extinction to the star\nformation history, metallicity and the viewing angle. Moreover, the influence\nof emission lines is considered (for the subset of models for which this\ncomponent is included). The performance of the models is investigated by: 1)\ncomparing their prediction with the observed galaxy population in the SDSS\nusing the (u-g)-(r-i) and (g-r)-(i-z) color planes, 2) comparing predicted\nstellar mass and luminosity weighted ages and metallicities, specific star\nformation rates, mass to light ratios and total extinctions with literature\nvalues from studies based on spectroscopy. Strong differences between the\nvarious models are seen, with several models occupying regions in the\ncolor-color diagrams where no galaxies are observed. We would therefore like to\nemphasize the importance of the choice of model. Using our preferred model we\nfind that the star formation history, metallicity and also dust content can be\nconstrained over a large part of the parameter space through the use of\nu,g,r,i,z-band photometry. However, strong local degeneracies are present due\nto overlap of models with high and low extinction in certain parts of color\nspace. \n\n"}
{"id": "1207.6129", "contents": "Title: Direct detection of dark matter axions with directional sensitivity Abstract: We study the directional effect of the expected axion dark matter signal in a\nresonant cavity of an axion haloscope detector, for cavity geometries not\nsatisfying the condition that the axion de Broglie wavelength $\\lambda_a$ is\nsufficiently larger than the cavity dimensions $L$ for a fully coherent\nconversion, i.e. $\\lambda_a \\gtrsim 2\\pi L$. We focus on long thin cavities\nimmersed in dipole magnets and find, for appropriately chosen cavity lengths,\nan O(1) modulation of the signal with the cavity orientation with respect the\nmomentum distribution of the relic axion background predicted by the isothermal\nsphere model for the galactic dark matter halo. This effect can be exploited to\ndesign directional axion dark matter detectors, providing an unmistakable\nsignature of the extraterrestrial origin of a possible positive detection.\nMoreover, the precise shape of the modulation may give information of the\ngalactic halo distribution and, for specific halo models, give extra\nsensitivity for higher axion masses. \n\n"}
{"id": "1207.7326", "contents": "Title: Spectral Classification and Redshift Measurement for the SDSS-III Baryon\n  Oscillation Spectroscopic Survey Abstract: (abridged) We describe the automated spectral classification, redshift\ndetermination, and parameter measurement pipeline in use for the Baryon\nOscillation Spectroscopic Survey (BOSS) of the Sloan Digital Sky Survey III\n(SDSS-III) as of Data Release 9, encompassing 831,000 moderate-resolution\noptical spectra. We give a review of the algorithms employed, and describe the\nchanges to the pipeline that have been implemented for BOSS relative to\nprevious SDSS-I/II versions, including new sets of stellar, galaxy, and quasar\nredshift templates. For the color-selected CMASS sample of massive galaxies at\nredshift 0.4 <~ z <~ 0.8 targeted by BOSS for the purposes of large-scale\ncosmological measurements, the pipeline achieves an automated classification\nsuccess rate of 98.7% and confirms 95.4% of unique CMASS targets as galaxies\n(with the balance being mostly M stars). Based on visual inspections of a\nsubset of BOSS galaxies, we find that ~0.2% of confidently reported CMASS\nsample classifications and redshifts are incorrect, and ~0.4% of all CMASS\nspectra are objects unclassified by the current algorithm which are potentially\nrecoverable. The BOSS pipeline confirms that ~51.5% of the quasar targets have\nquasar spectra, with the balance mainly consisting of stars. Statistical (as\nopposed to systematic) redshift errors propagated from photon noise are\ntypically a few tens of km/s for both galaxies and quasars, with a significant\ntail to a few hundreds of km/s for quasars. We test the accuracy of these\nstatistical redshift error estimates using repeat observations, finding them\nunderestimated by a factor of 1.19 to 1.34 for galaxies, and by a factor of 2\nfor quasars. We assess the impact of sky-subtraction quality, S/N, and other\nfactors on galaxy redshift success. Finally, we document known issues, and\ndescribe directions of ongoing development. \n\n"}
{"id": "1208.0026", "contents": "Title: Particle Production in pA Collisions and QCD Saturation Abstract: The forthcoming LHC measurements in proton-nucleus (pA) collisions at forward\nrapidities can discriminate between the color glass condensate (CGC) and\nalternative approaches including standard collinear factorization one. We\nreport some of our recent predictions based on gluon saturation/CGC formalism\nfor pA collisions at the LHC including the charged hadron multiplicity\ndistribution, the nuclear modification factor for single inclusive hadron and\nprompt photon production, and the azimuthal angle correlation of the\nsemi-inclusive hadron-photon production. \n\n"}
{"id": "1208.0646", "contents": "Title: The impact of point source subtraction residuals on 21 cm Epoch of\n  Reionization estimation Abstract: Precise subtraction of foreground sources is crucial for detecting and\nestimating 21cm HI signals from the Epoch of Reionization (EoR). We quantify\nhow imperfect point source subtraction due to limitations of the measurement\ndataset yields structured residual signal in the dataset. We use the Cramer-Rao\nlower bound, as a metric for quantifying the precision with which a parameter\nmay be measured, to estimate the residual signal in a visibility dataset due to\nimperfect point source subtraction. We then propagate these residuals into two\nmetrics of interest for 21cm EoR experiments - the angular and two-dimensional\npower spectrum - using a combination of full analytic covariant derivation,\nanalytic variant derivation, and covariant Monte Carlo simulations. This\nmethodology differs from previous work in two ways: (1) it uses information\ntheory to set the point source position error, rather than assuming a global\nroot-mean-square error, and (2) it describes a method for propagating the\nerrors analytically, thereby obtaining the full correlation structure of the\npower spectra. The methods are applied to two upcoming low-frequency\ninstruments: the Murchison Widefield Array and the Precision Array for Probing\nthe Epoch of Reionization. In addition to the actual antenna configurations, we\napply the methods to minimally-redundant and maximally-redundant\nconfigurations. We find that for peeling sources above 1 Jy, the amplitude of\nthe residual signal, and its variance, will be smaller than the contribution\nfrom thermal noise for the observing parameters proposed for upcoming EoR\nexperiments, and that optimal subtraction of bright point sources will not be a\nlimiting factor for EoR parameter estimation. We then use the formalism to\nprovide an ab initio analytic derivation motivating the 'wedge' feature in the\ntwo-dimensional power spectrum, complementing previous discussion in the\nliterature. \n\n"}
{"id": "1208.0833", "contents": "Title: XENON100 Implications for Naturalness in the MSSM, NMSSM and lambda-SUSY Abstract: In a recent paper arXiv:1107.5048, we discussed the correlation between the\nelastic neutralino-nucleon scattering cross section, constrained by dark matter\ndirect detection experiments, and fine-tuning at tree-level in the electroweak\nsymmetry breaking sector of the Minimal Supersymmetric Standard Model (MSSM).\nHere, we show that the correlation persists in the Next-to-Minimal\nSupersymmetric Standard Model (NMSSM), and its variant, lambda-SUSY. Both\nmodels are strongly motivated by the recent discovery of a 125 GeV Higgs-like\nparticle. We also discuss the implications of the recently published bound on\nthe direct detection cross section from 225 live days of XENON100 experiment.\nIn both the MSSM and the NMSSM, most of the parameter space with fine-tuning\nless than 10% is inconsistent with the XENON100 bound. In lambda-SUSY, on the\nother hand, large regions of completely natural electroweak symmetry breaking\nare still allowed, primarily due to a parametric suppression of fine-tuning\nwith large \\lambda. The upcoming XENON1T experiment will be able to probe most\nof the parameter space with less than 1% fine-tuning in all three models. \n\n"}
{"id": "1208.1264", "contents": "Title: A simple and robust method for automated photometric classification of\n  supernovae using neural networks Abstract: A method is presented for automated photometric classification of supernovae\n(SNe) as Type-Ia or non-Ia. A two-step approach is adopted in which: (i) the SN\nlightcurve flux measurements in each observing filter are fitted separately;\nand (ii) the fitted function parameters and their associated uncertainties,\nalong with the number of flux measurements, the maximum-likelihood value of the\nfit and Bayesian evidence for the model, are used as the input feature vector\nto a classification neural network (NN) that outputs the probability that the\nSN under consideration is of Type-Ia. The method is trained and tested using\ndata released following the SuperNova Photometric Classification Challenge\n(SNPCC). We consider several random divisions of the data into training and\ntesting sets: for instance, for our sample D_1 (D_4), a total of 10% (40%) of\nthe data are involved in training the algorithm and the remainder used for\nblind testing of the resulting classifier; we make no selection cuts. Assigning\na canonical threshold probability of p_th=0.5 on the NN output to classify a SN\nas Type-Ia, for the sample D_1 (D_4) we obtain a completeness of 0.78 (0.82),\npurity of 0.77 (0.82), and SNPCC figure-of-merit of 0.41 (0.50). Including the\nSN host-galaxy redshift and its uncertainty as additional inputs to the NN\nresults in a modest 5-10% increase in these values. We find that the\nclassification quality does not vary significantly with SN redshift. Moreover,\nour probabilistic classification method allows one to calculate the expected\ncompleteness, purity or other measures of classification quality as a function\nof the p_th, without knowing the true classes of the SNe in the testing sample.\nThe method may thus be improved further by optimising p_th and can easily be\nextended to divide non-Ia SNe into their different classes. \n\n"}
{"id": "1208.3314", "contents": "Title: X-ray polarimetry as a new tool to discriminate reflection from\n  absorption scenarios -- Predictions for MCG-6-30-15 Abstract: We present modelling of X-ray polarisation spectra emerging from the two\ncompeting scenarios that are proposed to explain the broad Fe K{\\alpha} line in\nthe Seyfert 1 galaxy MCG-6-30-15. The polarisation signature of complex\nabsorption is studied for a partial covering scenario using a clumpy wind and\ncompared to a reflection model based on the lamp-post geometry. The shape of\nthe polarisation percentage and angle as a function of photon energy are found\nto be distinctly different between the reflection and the absorption case.\nRelativistic reflection produces significantly stronger polarisation in the\n1-10 keV energy band than absorption. The spectrum of the polarisation angle\nadds additional constraints: in the absorption case it shows a constant shape,\nwhereas the relativistic reflection scenario typically leads to a smooth\nrotation of the polarisation angle with photon energy. Based on this work, we\nconclude that a soft X-ray polarimeter on-board a small X-ray satellite may\nalready discriminate between the absorption and the reflection scenario. A\npromising opportunity may arise with the X-ray Imaging Polarimetry Explorer\n(XIPE) mission, which has been proposed to ESA in response to a small-size\n(S-class) mission call due for launch in 2017. \n\n"}
{"id": "1208.5000", "contents": "Title: Superconductivity Appears in the Vicinity of an Insulating-Like Behavior\n  in CeO$_{1-x}$F$_{x}$BiS$_{2}$ Abstract: Resistive and magnetization properties have been measured in BiS$_2$-based\nsamples CeO$_{1-x}$F$_{x}$BiS$_{2}$ with a systematic substitution of O with F\n(0 $<$ x $<$ 0.6). In contrast to the band structure calculations, it is found\nthat the parent phase of CeOBiS$_2$ is a bad metal, instead of an band\ninsulator. By doping electrons into the system, it is surprising to find that\nsuperconductivity appears together with an insulating normal state. This\nevolution is clearly different from the cuprate and the iron pnictide systems,\nand is interpreted as approaching the von Hove singularity. Furthermore,\nferromagnetism which may arise from the Ce moments, has been observed in the\nlow temperature region in all samples, suggesting the co-existence of\nsuperconductivity and ferromagnetism in the superconducting samples. \n\n"}
{"id": "1208.5046", "contents": "Title: Importance of upgraded energy reconstruction for direct dark matter\n  searches with liquid xenon detectors Abstract: The usual nuclear recoil energy reconstruction employed by liquid xenon dark\nmatter search experiments relies only on the primary scintillation photon\nsignal. Energy reconstruction based on both the photon and electron signals\nyields a more accurate representation of search results. For a dark matter\nparticle mass m~10 GeV, a nuclear recoil from a scattering event is more likely\nto be observed in the lower left corner of the typical search box, rather than\nnear the nuclear recoil calibration centroid. In this region of the search box,\nthe actual nuclear recoil energies are smaller than the usual energy scale\nsuggests, by about a factor x2. Recent search results from the XENON100\nexperiment are discussed in light of these considerations. \n\n"}
{"id": "1208.5762", "contents": "Title: Comment on \"On the subtleties of searching for dark matter with liquid\n  xenon detectors\" Abstract: In a recent manuscript (arXiv:1208.5046) Peter Sorensen claims that\nXENON100's upper limits on spin-independent WIMP-nucleon cross sections for\nWIMP masses below 10 GeV \"may be understated by one order of magnitude or\nmore\". Having performed a similar, though more detailed analysis prior to the\nsubmission of our new result (arXiv:1207.5988), we do not confirm these\nfindings. We point out the rationale for not considering the described effect\nin our final analysis and list several potential problems with his study. \n\n"}
{"id": "1209.0504", "contents": "Title: Disk and elliptical galaxies within renormalization group improved\n  gravity Abstract: The paper is about possible effects of infrared quantum contributions to\nGeneral Relativity on disk and elliptical galaxies. The Renormalization Group\ncorrected General Relativity (RGGR model) is used to parametrize these quantum\neffects. The new RGGR results presented here concern the elliptical galaxy NGC\n4374 and the dwarf disk galaxy DDO 47. Using the effective approach to Quantum\nField Theory in curved background, one can argue that the proper RG energy\nscale, in the weak field limit, should be related to the Newtonian potential.\nIn the context of galaxies, this led to a remarkably small variation of the\ngravitational coupling G, while also capable of generating galaxy rotation and\ndispersion curves of similar quality to the the best dark matter profiles\n(i.e., the profiles that have a core). \n\n"}
{"id": "1209.2750", "contents": "Title: A Method to Extract the Angular Power Spectrum of the Epoch of\n  Reionization from Low-Frequency Radio Interferometers Abstract: The redshifted 21cm signal of neutral hydrogen from the epoch of reionization\n(EoR) is extremely weak and its first detection is therefore expected to be\nstatistical with first-generation low-frequency radio interferometers. In this\nletter we propose a method to extract the angular power spectrum of EoR from\nthe visibility correlation coefficients p_{ij}(u,v), instead of the\nvisibilities V_{ij}(u,v) measured directly by radio interferometers in\nconventional algorithm. The visibility correlation coefficients are defined as\np_{ij}(u,v)=V_{ij}(u,v)/\\sqrt{|V_{ii}||V_{jj}|} by introducing the\nauto-correlation terms V_{ii} and V_{jj} such that the angular power spectrum\nC_{\\ell} can be obtained through C_{\\ell}=4pi^2T_0^2<|p_{ij}(u,v)|^2>,\nindependently of the primary beams of antennas. This also removes partially the\ninfluence of receiver gains in the measurement of C_{\\ell} because the\namplitudes of the gains cancel each other out in the statistical average\noperation of <|p_{ij}(u,v)|^2>.We use the average system temperature T_0 as a\ncalibrator of C_{\\ell}, which is dominated by the Milky Way and extragalactic\nsources in our interested frequency range below 200 MHz. Finally we demonstrate\nthe feasibility of the novel method using the simulated sky maps as targets and\nthe 21 CentiMeter Array (21CMA) as interferometer. \n\n"}
{"id": "1209.3266", "contents": "Title: BAORadio: A digital pipeline for radio interferometry and 21 cm mapping\n  of large scale structures Abstract: 3D mapping of matter distribution in the universe through the 21 cm radio\nemission of atomic hydrogen HI is a complementary approach to optical surveys\nfor the study of the Large Scale Structures, in particular for measuring the\nBAO (Baryon Acoustic Oscillation) scale up to redshifts z < 3, and therefore\nconstraining dark energy parameters. We propose a novel method to map the HI\nmass distribution in three dimensions in radio, without detecting or\nidentifying individual compact sources. This method would require an instrument\nwith a large instantaneous bandwidth (> 100 MHz) and high sensitivity, while a\nrather modest angular resolution (~ 10 arcmin) should be sufficient. These\nrequirements can be met by a dense interferometric array or a phased array\n(FPA) in the focal plane of a large primary reflector, representing a total\ncollecting area of a few thousand square meters with few hundred simultaneous\nbeams covering a 20 to 100 square degrees field of view. We describe the\ndevelopment and qualification of an electronic and data processing system for\ndigital radio interferometry and beam forming suitable for such instruments\nwith several hundred receiver elements. \n\n"}
{"id": "1209.3473", "contents": "Title: The accuracy of the UV continuum as an indicator of the star formation\n  rate in galaxies Abstract: The rest-frame intrinsic UV luminosity is often used as an indicator of the\ninstantaneous star formation rate (SFR) in a galaxy. While it is in general a\nrobust indicator of the ongoing star formation activity, the precise value of\nthe calibration relating the UV luminosity to the SFR ($B_{\\nu}$), is sensitive\nto various physical properties, such as the recent star formation and metal\nenrichment histories, along with the choice of stellar initial mass function.\nThe distribution of these properties for the star-forming galaxy population\nthen suggests that the adoption of a single calibration is not appropriate\nunless properly qualified with the uncertainties on the calibration. We\ninvestigate, with the aid of the {\\sc galform} semi-analytic model of galaxy\nformation, the distribution of UV-SFR calibrations obtained using realistic\nstar formation and metal enrichment histories. At $z=0$, we find that when the\ninitial mass function is fixed (to the Kennicutt IMF), the median calibration\nis $B_{\\rm fuv}=0.9$ where ${\\rm SFR}/[{\\rm M_{\\odot}\\,yr^{-1}}]=B_{\\nu}\\times\n10^{-28}\\times L_{\\nu}/[{\\rm ergs\\,s^{-1}\\,Hz^{-1}}]$. However, the width of\nthe distribution $B_{\\rm fuv}$ suggests that for a single object there is\naround a 20% {\\em intrinsic} uncertainty (at $z=0$, rising to $\\simeq 30%$ at\n$z=6$) on the star formation rate inferred from the FUV luminosity without\nadditional constraints on the star formation history or metallicity. We also\nfind that the median value of the calibration $B_{\\rm fuv}$ is correlated with\nthe star formation rate and redshift (at $z>3$) raising implications for the\ncorrect determination of the star formation rate from the UV. \n\n"}
{"id": "1209.3810", "contents": "Title: Expected Sensitivity to Galactic/Solar Axions and Bosonic Super-WIMPs\n  based on the Axio-electric Effect in Liquid Xenon Dark Matter Detectors Abstract: We present systematic case studies to investigate the sensitivity of axion\nsearches by liquid xenon detectors, using the axio-electric effect (analogue of\nthe photoelectric effect) on xenon atoms. Liquid xenon is widely considered to\nbe one of the best target media for detection of WIMPs (Weakly Interacting\nMassive Particles which may form the galactic dark matter) using nuclear\nrecoils. Since these detectors also provide an extremely low radioactivity\nenvironment for electron recoils, very weakly-interacting low-mass particles (<\n100 keV/c^2), such as the hypothetical axion, could be detected as well - in\nthis case using the axio-electric effect. Future ton-scale liquid Xe detectors\nwill be limited in sensitivity only by irreducible neutrino background\n(pp-chain solar neutrino and the double beta decay of 136Xe) in the mass range\nbetween 1 and 100 keV/c^2. Assuming one ton-year of exposure, galactic axions\n(as non-relativistic dark matter) could be detected if the axio-electric\ncoupling g_Ae is greater than 10^-14 at 1 keV/c^2 (or $10^-13 at 100 keV/c^2).\nBelow a few keV/c^2, and independent of the mass, a solar axion search would be\nsensitive to a coupling g_Ae ~ 10^-12. This limit will set a stringent upper\nbound on axion mass for the DFSV and KSVZ models for the mass ranges m_A < 0.1\neV/c^2 and < 10 eV/c^2, respectively. Vector-boson dark matter could also be\ndetected for a coupling constant alpha'/alpha > 10^-33 (for mass 1 keV/c^2) or\n> 10^-27 (for mass 100 keV/c^2). \n\n"}
{"id": "1209.4097", "contents": "Title: Pulsations in Short GRBs from Black Hole-Neutron Star Mergers Abstract: The precise origin of short gamma ray bursts (SGRBs) remains an important\nopen question in relativistic astrophysics. Increasingly, observational\nevidence suggests the merger of a binary compact object system as the source\nfor most SGRBs, but it is currently unclear how to distinguish observationally\nbetween a binary neutron star progenitor and a black hole-neutron star\nprogenitor. We suggest the quasi-periodic signal of jet precession as an\nobservational signature of SGRBs originating in mixed binary systems, and\nquantify both the fraction of mixed binaries capable of producing SGRBs, and\nthe distributions of precession amplitudes and periods. The difficulty inherent\nin disrupting a neutron star outside the horizon of a stellar-mass black hole\nbiases the jet precession signal towards low amplitude and high frequency.\nPrecession periods of ~ 0.01-0.1 s and disk-BH spin misalignments ~10 degrees\nare generally expected, although sufficiently high viscosity may prevent the\naccumulation of multiple precession periods during the SGRB. The precessing jet\nwill naturally cover a larger solid angle in the sky than would standard SGRB\njets, enhancing observability for both prompt emission and optical afterglows. \n\n"}
{"id": "1210.0648", "contents": "Title: On the Poincar\\'{e} series of Kac-Moody Lie algebras Abstract: In this paper, we discuss the Poincar\\'{e} series of Kac-Moody Lie algebras,\nespecially for indefinite type. Firstly, we compute the Poincar\\'{e} series of\ncertain indefinite Kac-Moody Lie algebras whose Cartan matrices have the same\ntype of $2\\times 2$ principal sub-matrices. Secondly, we show that the\nPoincar\\'{e} series of Kac-Moody Lie algebras satisfy certain interesting\nproperties. Lastly we give some applications of the Poincar\\'{e} series to\nother fields. Particularly we construct some counter examples to a conjecture\nof Victor Kac\\cite{Kac_85} and a conjecture of Chapavalov, Leites and\nStekolshchik\\cite{CDR_10}. \n\n"}
{"id": "1210.0749", "contents": "Title: Gravitational Model of High Energy Particles in a Collimated Jet Abstract: Observations suggest that relativistic particles play a fundamental role in\nthe dynamics of jets emerging from active galactic nuclei as well as in their\ninteraction with the intracluster medium. However, no general consensus exists\nconcerning the acceleration mechanism of those high energy particles. A\ngravitational acceleration mechanism is here proposed, in which particles\nleaving precise regions within the ergosphere of a rotating supermassive black\nhole produce a highly collimated flow. These particles follow unbound geodesics\nwhich are asymptotically parallel to the spin axis of the black hole and are\ncharacterized by the energy $E$, the Carter constant ${\\cal Q}$ and zero\nangular momentum of the component $L_z$. If environmental effects are\nneglected, the present model predicts at distances of about 140 kpc from the\nergosphere the presence of electrons with energies around 9.4 GeV. The present\nmechanism can also accelerate protons up to the highest energies observed in\ncosmic rays by the present experiments. \n\n"}
{"id": "1210.1050", "contents": "Title: Tidal disruption flares from stars on eccentric orbits Abstract: We study tidal disruption and subsequent mass fallback for stars approaching\nsupermassive black holes on bound orbits, by performing three dimensional\nSmoothed Particle Hydrodynamics simulations with a pseudo-Newtonian potential.\nWe find that the mass fallback rate decays with the expected -5/3 power of time\nfor parabolic orbits, albeit with a slight deviation due to the self-gravity of\nthe stellar debris. For eccentric orbits, however, there is a critical value of\nthe orbital eccentricity, significantly below which all of the stellar debris\nis bound to the supermassive black hole. All the mass therefore falls back to\nthe supermassive black hole in a much shorter time than in the standard,\nparabolic case. The resultant mass fallback rate considerably exceeds the\nEddington accretion rate and substantially differs from the -5/3 power of time. \n\n"}
{"id": "1210.2413", "contents": "Title: The Baryon Acoustic Oscillation Broadband and Broad-beam Array: Design\n  Overview and Sensitivity Forecasts Abstract: This work describes a new instrument optimized for a detection of the neutral\nhydrogen 21cm power spectrum between redshifts of 0.5-1.5: the Baryon Acoustic\nOscillation Broadband and Broad-beam (BAOBAB) Array. BAOBAB will build on the\nefforts of a first generation of 21cm experiments which are targeting a\ndetection of the signal from the Epoch of Reionization at z ~ 10. At z ~ 1, the\nemission from neutral hydrogen in self-shielded overdense halos also presents\nan accessible signal, since the dominant, synchrotron foreground emission is\nconsiderably fainter than at redshift 10. The principle science driver for\nthese observations are Baryon Acoustic Oscillations in the matter power\nspectrum which have the potential to act as a standard ruler and constrain the\nnature of dark energy. BAOBAB will fully correlate dual-polarization antenna\ntiles over the 600-900MHz band with a frequency resolution of 300 kHz and a\nsystem temperature of 50K. The number of antennas will grow in staged\ndeployments, and reconfigurations of the array will allow for both traditional\nimaging and high power spectrum sensitivity operations. We present calculations\nof the power spectrum sensitivity for various array sizes, with a 35-element\narray measuring the cosmic neutral hydrogen fraction as a function of redshift,\nand a 132-element system detecting the BAO features in the power spectrum,\nyielding a 1.8% error on the z ~ 1 distance scale, and, in turn, significant\nimprovements to constraints on the dark energy equation of state over an\nunprecedented range of redshifts from ~0.5-1.5. \n\n"}
{"id": "1210.2441", "contents": "Title: Observational evidences for spinning black holes: A proof of general\n  relativity for spacetime around rotating black holes Abstract: Since it was theorized by Kerr in 1963, determining the spin of black holes\nfrom observed data was paid very little attention until few years back. The\nmain reasons behind this were the unavailability of adequate data and the lack\nof appropriate techniques. In this article, we explore determining/predicting\nthe spin of several black holes in X-ray binaries and in the center of\ngalaxies, using X-ray and gamma-ray satellite data. For X-ray binaries, in\norder to explain observed quasi-periodic oscillations, our model predicts the\nspin parameter of underlying black holes. On the other hand, the nature of spin\nparameters of black holes in BL Lacs and Flat Spectrum Radio Quasars is\npredicted by studying the total luminosities of systems based on Fermi\ngamma-ray data. All sources considered here exhibit characteristics of spinning\nblack holes, which verifies natural existence of the Kerr metric. \n\n"}
{"id": "1210.3374", "contents": "Title: Consequences of Strong Compression in Tidal Disruption Events Abstract: The tidal disruption of a star by a supermassive black hole (SMBH) is a\nhighly energetic event with consequences dependent on the degree to which the\nstar plunges inside the SMBH's tidal sphere. We introduce a new analytic model\nfor tidal disruption events (TDEs) to analyze the dependence of these events on\nbeta, the ratio of the tidal radius to the orbital pericenter. We find,\ncontrary to most previous work, that the spread in debris energy for a TDE is\nlargely constant for all beta. This result has important consequences for\noptical transient searches targeting TDEs, which we discuss. We quantify\nleading-order general relativistic corrections to this spread in energy and\nfind that they are small. We also examine the role of stellar spin, and find\nthat a combination of spin-orbit misalignment, rapid rotation, and high beta\nmay increase the spread in debris energy. Finally, we quantify for the first\ntime the gravitational wave emission due to the strong compression of a star in\na high-beta TDE. Although this signal is unlikely to be detectable for\ndisruptions of main sequence stars, the tidal disruption of a white dwarf by an\nintermediate mass black hole can produce a strong signal visible to Advanced\nLIGO at tens of megaparsecs. \n\n"}
{"id": "1210.6014", "contents": "Title: Weighing The Evidence For A Gravitational-Wave Background In The First\n  International Pulsar Timing Array Data Challenge Abstract: We describe an analysis of the First International Pulsar Timing Array Data\nChallenge. We employ a robust, unbiased Bayesian framework developed by van\nHaasteren to study the three Open and Closed datasets, testing various models\nfor each dataset and using MultiNest to recover the evidence for the purposes\nof Bayesian model-selection. The parameter constraints of the favoured model\nare confirmed using an adaptive MCMC technique. Our results for Closed1\nfavoured a gravitational-wave background with strain amplitude at f=1 yr-1, A,\nof (1.1 +/- 0.1) x 10^{-14}, power spectral-index gamma=4.30 +/- 0.15 and no\nevidence for red-timing noise or single-sources. The evidence for Closed2\nfavours a gravitational-wave background with A=(6.1 +/- 0.3) x 10^{-14},\ngamma=4.34 +/- 0.09 with no red-timing noise or single-sources. Finally, the\nevidence for Closed3 favours the presence of red-timing noise and a\ngravitational-wave background, with no single-sources. The properties of the\nbackground were A=(5 +/- 1) x 10^{-15} and gamma=4.23 +/- 0.35, while the\nproperties of the red-noise were N_{red}=(12 +/- 4) ns and gamma_{red}=1.5 +/-\n0.3. In all cases the redness of the recovered background is consistent with a\nsource-population of inspiraling supermassive black-hole binaries. We also\ninvestigate the effect that down-sampling of the datasets has on parameter\nconstraints and run-time. Finally we provide a proof-of-principle study of the\nability of the Bayesian framework used in this paper to reconstruct the angular\ncorrelation of gravitational-wave background induced timing-residuals,\ncomparing this to the Hellings and Downs curve. \n\n"}
{"id": "1210.6362", "contents": "Title: Identifying Elusive Electromagnetic Counterparts to Gravitational Wave\n  Mergers: an end-to-end simulation Abstract: Combined gravitational-wave (GW) and electromagnetic (EM) observations of\ncompact binary mergers should enable detailed studies of astrophysical\nprocesses in the strong-field gravity regime. Networks of GW interferometers\nhave poor angular resolution on the sky and their EM signatures are predicted\nto be faint. Therefore, a challenging goal will be to unambiguously pinpoint\nthe EM counterparts to GW mergers. We perform the first comprehensive\nend-to-end simulation that focuses on: i) GW sky localization, distance\nmeasures and volume errors with two compact binary populations and four\ndifferent GW networks, ii) subsequent detectability by a slew of\nmultiwavelength telescopes and, iii) final identification of the merger\ncounterpart amidst a sea of possible astrophysical false-positives. First, we\nfind that double neutron star (NS) binary mergers can be detected out to a\nmaximum distance of 400 Mpc (or 750 Mpc) by three (or five) detector GW\nnetworks respectively. NS -- black-hole (BH) mergers can be detected a factor\nof 1.5 further out. The sky localization uncertainties for NS-BH mergers are\n50--170 sq. deg. (or 6--65 sq. deg.) for a three (or five detector) GW network\nrespectively. Second, we quantify relative fractions of optical counterparts\nthat are detectable by different size telescopes. Third, we present five case\nstudies to illustrate the diversity of challenges in secure identification of\nthe EM counterpart at low and high Galactic latitudes. For the first time, we\ndemonstrate how construction of low-latency GW volumes in conjunction with\nlocal universe galaxy catalogs can help solve the problem of false positives. \n\n"}
{"id": "1210.6983", "contents": "Title: Fake plunges are very eccentric real EMRIs in disguise ... they dominate\n  the rates and are blissfully ignorant of angular momentum barriers Abstract: The capture of a compact object in a galactic nucleus by a massive black hole\n(MBH) is the best way to map space and time around it. Compact objects such as\nstellar black holes on a capture orbit with a very high eccentricity have been\nwrongly assumed to be lost for the system after an intense burst of radiation,\nwhich has been described as a \"direct plunge\". We prove that these very\neccentric capture orbits spend actually a similar number of cycles in a\nLISA-like detector as those with lower eccentricities if the central MBH is\nspinning. Although the rates are higher for high-eccentricity EMRIs, the spin\nalso enhances the rates of lower-eccentricity EMRIs. This last kind have\nreceived more attention because of the fact that high-eccentricity EMRIs were\nthought to be direct plunges and thus negligible. On the other hand, recent\nwork on stellar dynamics has demonstrated that there seems to be a complot in\nphase space acting on these lower-eccentricity captures, since their rates\ndecrease significantly by the presence of a blockade in the rate at which\norbital angular momenta change takes place. This so-called \"Schwarzschild\nbarrier\" is a result of the impact of relativistic precession on to the stellar\npotential torques, and thus it affects the enhancement on lower-eccentricity\nEMRIs that one would expect from resonant relaxation. We confirm and quantify\nthe existence of this barrier using a statitical sample of 2,500\ndirect-summation N-body simulations using both a post-Newtonian but also, and\nfor the first time, a geodesic approximation for the relativistic orbits. The\nexistence of the barrier prevents \"traditional EMRIs\" from approaching the\ncentral MBH, but if the central MBH is spinning the rate will be anyway\ndominated by highly-eccentric extreme-mass ratio inspirals, which insolently\nignore the presence of the barrier, because they are driven by two-body\nrelaxation. \n\n"}
{"id": "1210.6997", "contents": "Title: Accretion Disk Temperatures of QSOs: Constraints from the Emission Lines Abstract: QSO emission-line spectra are compared to predictions based on theoretical\nionizing continua of accretion disks. Observed line intensities do not show the\nexpected trend of higher ionization with higher accretion disk temperature as\nderived from the black hole mass and accretion rate. This suggests that, at\nleast for accretion rates close to the Eddington limit, the inner disk does not\nreach temperatures as high as expected from standard disk theory. Modified\nradial temperature profiles, taking account of winds or advection in the inner\ndisk, achieve better agreement with observation. This conclusion agrees with an\nearlier study of QSO continuum colors as a function of disk temperature. The\nemission lines of radio-detected and radio-undetected sources show different\ntrends as a function of disk temperature. \n\n"}
{"id": "1210.7186", "contents": "Title: Recovering physical properties from narrow-band photometry Abstract: Our aim in this work is to answer, using simulated narrow-band photometry\ndata, the following general question: What can we learn about galaxies from\nthese new generation cosmological surveys? For instance, can we estimate\nstellar age and metallicity distributions? Can we separate star-forming\ngalaxies from AGN? Can we measure emission lines, nebular abundances and\nextinction? With what precision?\n  To accomplish this, we selected a sample of about 300k galaxies with good S/N\nfrom the SDSS and divided them in two groups: 200k objects and a template\nlibrary of 100k. We corrected the spectra to $z = 0$ and converted them to\nfilter fluxes. Using a statistical approach, we calculated a Probability\nDistribution Function (PDF) for each property of each object and the library.\nSince we have the properties of all the data from the {\\sc starlight}-SDSS\ndatabase, we could compare them with the results obtained from summaries of the\nPDF (mean, median, etc).\n  Our results shows that we retrieve the weighted average of the log of the\ngalaxy age with a good error margin ($\\sigma \\approx 0.1 - 0.2$ dex), and\nsimilarly for the physical properties such as mass-to-light ratio, mean stellar\nmetallicity, etc. Furthermore, our main result is that we can derive emission\nline intensities and ratios with similar precision. This makes this method\nunique in comparison to the other methods on the market to analyze photometry\ndata and shows that, from the point of view of galaxy studies, future\nphotometric surveys will be much more useful than anticipated. \n\n"}
{"id": "1210.7318", "contents": "Title: Revealing Non-circular beam effect in WMAP-7 CMB maps with BipoSH\n  measures of Statistical Isotropy Abstract: Mild, unavoidable deviations from circular-symmetry of instrumental beams in\ncurrent Cosmic Microwave Background (CMB) experiments now pose a significant\nchallenge to deriving high precision inferences from the high sensitivity and\nresolution of CMB measurements. We present analytic results, verified by\nnumerical simulations, that CMB maps of cosmological signal that respect\nunderlying statistical isotropy (SI) symmetry, measured with an instrument that\nhas mildly non-circular (NC) beam would, nevertheless, exhibit SI violation.\nFurther, we show that appropriate observable measures constructed within the\nBipolar spherical harmonic (BipoSH) representation of SI violation capture\nsubtle NC-beam effects coupled with the scan strategy of the instrument.\n  Accompanying their latest 7-year data release, the WMAP team published very\nhigh significance measurements of non-zero BipoSH spectra, A^{20}_{l l} and\nA^{20}_{l-2 l}, in the \"W\" and \"V\" band of the experiment. We present a strong\ncase that the BipoSH measurement are primarily explained by the quadrupolar\n(m=2) component of the NC-beams, b_{l2}, of the respective channels. The fact\nthat subtle levels of non-circularity, e.g., WMAP beams |b_{l2}|/b_{l0} < 0.01,\nlead to measurable BipoSH spectra points to the immense promise and potential\nof the BipoSH representation. The key result of this work is that using BipoSH\nmeasurements it is possible to estimate an equivalent single hit,'parallel\ntransported' effective NC-beam that matches both the angular power spectrum and\nthe non-zero BipoSH measurements of the observed maps. Hence, BipoSH analysis\nprovides a very simple and effective characterization of CMB maps made with\nNC-beam. (Abridged) \n\n"}
{"id": "1210.7521", "contents": "Title: Radio Continuum Surveys with Square Kilometre Array Pathfinders Abstract: In the lead-up to the Square Kilometre Array (SKA) project, several\nnext-generation radio telescopes and upgrades are already being built around\nthe world. These include APERTIF (The Netherlands), ASKAP (Australia), eMERLIN\n(UK), VLA (USA), e-EVN (based in Europe), LOFAR (The Netherlands), Meerkat\n(South Africa), and the Murchison Widefield Array (MWA). Each of these new\ninstruments has different strengths, and coordination of surveys between them\ncan help maximise the science from each of them. A radio continuum survey is\nbeing planned on each of them with the primary science objective of\nunderstanding the formation and evolution of galaxies over cosmic time, and the\ncosmological parameters and large-scale structures which drive it. In pursuit\nof this objective, the different teams are developing a variety of new\ntechniques, and refining existing ones. Here we describe these projects, their\nscience goals, and the technical challenges which are being addressed to\nmaximise the science return. \n\n"}
{"id": "1210.7690", "contents": "Title: Origins of weak lensing systematics, and requirements on future\n  instrumentation (or knowledge of instrumentation) Abstract: The first half of this paper explores the origin of systematic biases in the\nmeasurement of weak gravitational lensing. Compared to previous work, we expand\nthe investigation of PSF instability and fold in for the first time the effects\nof non-idealities in electronic imaging detectors and imperfect galaxy shape\nmeasurement algorithms. Together, these now explain the additive A(l) and\nmultiplicative M(l) systematics typically reported in current lensing\nmeasurements. We find that overall performance is driven by a product of a\ntelescope/camera's *absolute performance*, and our *knowledge about its\nperformance*.\n  The second half of this paper propagates any residual shear measurement\nbiases through to their effect on cosmological parameter constraints. Fully\nexploiting the statistical power of Stage IV weak lensing surveys will require\nadditive biases A<1.8e-12 and multiplicative biases M<4.0e-3. These can be\nallocated between individual budgets in hardware, calibration data and\nsoftware, using results from the first half of the paper.\n  If instrumentation is stable and well-calibrated, we find extant shear\nmeasurement software from GREAT10 already meet requirements on galaxies\ndetected at S/N=40. Averaging over a population of galaxies with a realistic\ndistribution of sizes, it also meets requirements for a 2D cosmic shear\nanalysis from space. If used on fainter galaxies or for 3D cosmic shear\ntomography, existing algorithms would need calibration on simulations to avoid\nintroducing bias at a level similar to the statistical error. Requirements on\nhardware and calibration data are discussed in more detail in a companion\npaper. Our analysis is intentionally general, but is specifically being used to\ndrive the hardware and ground segment performance budget for the design of the\nEuropean Space Agency's recently-selected Euclid mission. \n\n"}
{"id": "1211.1695", "contents": "Title: Properties of gas clumps and gas clumping factor in the intra cluster\n  medium Abstract: The spatial distribution of gas matter inside galaxy clusters is not\ncompletely smooth, but may host gas clumps associated with substructures. These\noverdense gas substructures are generally a source of unresolved bias of X-ray\nobservations towards high density gas, but their bright luminosity peaks may be\nresolved sources within the ICM, that deep X-ray exposures may be (already)\ncapable to detect. In this paper we aim at investigating both features, using a\nset of high-resolution cosmological simulations with ENZO. First, we monitor\nhow the bias by unresolved gas clumping may yield incorrect estimates of global\ncluster parameters and affects the measurements of baryon fractions by X-ray\nobservations. We find that based on X-ray observations of narrow radial strips,\nit is difficult to recover the real baryon fraction to better than 10 - 20\npercent uncertainty. Second, we investigated the possibility of observing\nbright X-ray clumps in the nearby Universe (z<=0.3). We produced simple mock\nX-ray observations for several instruments (XMM, Suzaku and ROSAT) and\nextracted the statistics of potentially detectable bright clumps. Some of the\nbrightest clumps predicted by simulations may already have been already\ndetected in X- ray images with a large field of view. However, their small\nprojected size makes it difficult to prove their existence based on X-ray\nmorphology only. Preheating, AGN feedback and cosmic rays are found to have\nlittle impact on the statistical properties of gas clumps. \n\n"}
{"id": "1211.2036", "contents": "Title: Will Nonlinear Peculiar Velocity and Inhomogeneous Reionization Spoil\n  21cm Cosmology from the Epoch of Reionization? Abstract: The 21cm background from the epoch of reionization is a promising\ncosmological probe: line-of-sight velocity fluctuations distort redshift, so\nbrightness fluctuations in Fourier space depend upon angle, which linear theory\nshows can separate cosmological from astrophysical information. Nonlinear\nfluctuations in ionization, density and velocity change this, however. The\nvalidity and accuracy of the separation scheme are tested here for the first\ntime, by detailed reionization simulations. The scheme works reasonably well\nearly in reionization (< 40% ionized), but not late (> 80% ionized). \n\n"}
{"id": "1211.3126", "contents": "Title: Grid-based exploration of cosmological parameter space with Snake Abstract: We present a fully parallelized grid-based parameter estimation algorithm for\ninvestigating multidimensional likelihoods called Snake, and apply it to\ncosmological parameter estimation. The basic idea is to map out the likelihood\ngrid-cell by grid-cell according to decreasing likelihood, and stop when a\ncertain threshold has been reached. This approach improves vastly on the \"curse\nof dimensionality\" problem plaguing standard grid-based parameter estimation\nsimply by disregarding grid-cells with negligible likelihood. The main\nadvantages of this method compared to standard Metropolis-Hastings MCMC methods\ninclude 1) trivial extraction of arbitrary conditional distributions; 2) direct\naccess to Bayesian evidences; 3) better sampling of the tails of the\ndistribution; and 4) nearly perfect parallelization scaling. The main\ndisadvantage is, as in the case of brute-force grid-based evaluation, a\ndependency on the number of parameters, N_par. One of the main goals of the\npresent paper is to determine how large N_par can be, while still maintaining\nreasonable computational efficiency; we find that N_par = 12$ is well within\nthe capabilities of the method. The performance of the code is tested by\ncomparing cosmological parameters estimated using Snake and the WMAP-7 data\nwith those obtained using CosmoMC, the current standard code in the field. We\nfind fully consistent results, with similar computational expenses, but shorter\nwall time due to the perfect parallelization scheme. \n\n"}
{"id": "1211.4864", "contents": "Title: The Universe at Extreme Scale: Multi-Petaflop Sky Simulation on the BG/Q Abstract: Remarkable observational advances have established a compelling\ncross-validated model of the Universe. Yet, two key pillars of this model --\ndark matter and dark energy -- remain mysterious. Sky surveys that map billions\nof galaxies to explore the `Dark Universe', demand a corresponding\nextreme-scale simulation capability; the HACC (Hybrid/Hardware Accelerated\nCosmology Code) framework has been designed to deliver this level of\nperformance now, and into the future. With its novel algorithmic structure,\nHACC allows flexible tuning across diverse architectures, including accelerated\nand multi-core systems.\n  On the IBM BG/Q, HACC attains unprecedented scalable performance -- currently\n13.94 PFlops at 69.2% of peak and 90% parallel efficiency on 1,572,864 cores\nwith an equal number of MPI ranks, and a concurrency of 6.3 million. This level\nof performance was achieved at extreme problem sizes, including a benchmark run\nwith more than 3.6 trillion particles, significantly larger than any\ncosmological simulation yet performed. \n\n"}
{"id": "1211.4899", "contents": "Title: Global Deep-MOND Parameter as a Theory Discriminant Abstract: Different formulations of MOND predict somewhat different rotation curves for\nthe same mass distribution. Here I consider a global attribute of the rotation\ncurve that might provide a convenient discriminant between theories when\napplied to isolated, pure-disk galaxies that are everywhere deep in the MOND\nregime. This parameter is Q=<V^2>/V0^2, where <V^2> is the mean squared\nrotational speed of the galaxy, and V0 is the asymptotic (constant) rotational\nspeed. The comparison between the observed and predicted values of Q is\noblivious to the distance, the inclination, the mass, and the size of the disk,\nand to the form of the interpolating function. For the known modified-gravity\ntheories Q is predicted to be a universal constant (independent of the mass\ndistribution in the disk): Q=2/3. The predicted Q value for modified-inertia\ntheories does depend on the mass distribution. However, surprisingly, I find\nhere that it varies only little among a very wide range of mass distributions,\nQ=0.73+-0.01. While the difference between the theories amounts to only about 5\npercent in the predicted RMS velocity, a good enough sample of galaxies may\nprovide the first discerning test between the two classes of theories. \n\n"}
{"id": "1211.5375", "contents": "Title: Systematic investigation of the expected gravitational wave signal from\n  supermassive black hole binaries in the pulsar timing band Abstract: In this letter we carry out the first systematic investigation of the\nexpected gravitational wave (GW) background generated by supermassive black\nhole (SMBH) binaries in the nHz frequency band accessible to pulsar timing\narrays (PTAs). We take from the literature several estimates of the redshift\ndependent galaxy mass function and of the fraction of close galaxy pairs to\nderive a wide range of galaxy merger rates. We then exploit empirical black\nhole-host relations to populate merging galaxies with SMBHs. The result of our\nprocedure is a collection of a large number of phenomenological SMBH binary\nmerger rates consistent with current observational constraints on the galaxy\nassembly at z<1.5. For each merger rate we compute the associated GW signal,\neventually producing a large set of estimates of the nHz GW background that we\nuse to infer confidence intervals of its expected amplitude. When considering\nthe most recent SMBH-host relations, accounting for ultra-massive black holes\nin brightest cluster galaxies, we find that the nominal $1\\sigma$ interval of\nthe expected GW signal is only a factor of 3-to-10 below current PTA limits,\nimplying a non negligible chance of detection in the next few years. \n\n"}
{"id": "1211.5392", "contents": "Title: An approximate treatment of gravitational collapse Abstract: This work studies a simplified model of the gravitational instability of an\ninitially homogeneous infinite medium, represented by $\\TT^d$, based on the\napproximation that the mean fluid velocity is always proportional to the local\nacceleration. It is shown that, mathematically, this assumption leads to the\nrestricted Patlak-Keller-Segel model considered by J\\\"ager and Luckhaus or,\nequivalently, the Smoluchowski equation describing the motion of\nself-gravitating Brownian particles, coupled to the modified Newtonian\npotential that is appropriate for an infinite mass distribution. We discuss\nsome of the fundamental properties of a non-local generalization of this model\nwhere the effective pressure force is given by a fractional Laplacian with\n$0<\\alpha<2$, and illustrate them by means of numerical simulations. Local\nwell-posedness in Sobolev spaces is proven, and we show the smoothing effect of\nour equation, as well as a \\emph{Beale-Kato-Majda}-type criterion in terms of\n$\\rhomax$. It is also shown that the problem is ill-posed in Sobolev spaces\nwhen it is considered backward in time. Finally, we prove that, in the critical\ncase (one conservative and one dissipative derivative), $\\rhomax(t)$ is\nuniformly bounded in terms of the initial data for sufficiently large pressure\nforces. \n\n"}
{"id": "1211.5734", "contents": "Title: Self-Calibration of CMB Polarization Experiments Abstract: Precision measurements of the polarization of the cosmic microwave background\n(CMB) radiation, especially experiments seeking to detect the odd-parity\n\"B-modes\", have far-reaching implications for cosmology. To detect the B-modes\ngenerated during inflation the Flux response and polarization angle of these\nexperiments must be calibrated to exquisite precision. While suitable flux\ncalibration sources abound, polarization angle calibrators are deficient in\nmany respects. Man-made polarized sources are often not located in the\nantenna's far-field, have spectral properties that are radically different from\nthe CMB's, are cumbersome to implement and may be inherently unstable over the\n(long) duration these searches require to detect the faint signature of the\ninflationary epoch. Astrophysical sources suffer from time, frequency and\nspatial variability, are not visible from all CMB observatories, and none are\nunderstood with sufficient accuracy to calibrate future CMB polarimeters\nseeking to probe inflationary energy scales of $10^{15}$ GeV. CMB $TB$ and $EB$\nmodes, expected to identically vanish in the standard cosmological model, can\nbe used to calibrate CMB polarimeters. By enforcing the observed $EB$ and $TB$\npower spectra to be consistent with zero, CMB polarimeters can be calibrated to\nlevels not possible with man-made or astrophysical sources. All of this can be\naccomplished without any loss of observing time using a calibration source\nwhich is spectrally identical to the CMB B-modes. The calibration procedure\noutlined here can be used for any CMB polarimeter. \n\n"}
{"id": "1211.5887", "contents": "Title: Measurement and correction of variations in interstellar dispersion in\n  high-precision pulsar timing Abstract: Signals from radio pulsars show a wavelength-dependent delay due to\ndispersion in the interstellar plasma. At a typical observing wavelength, this\ndelay can vary by tens of microseconds on five-year time scales, far in excess\nof signals of interest to pulsar timing arrays, such as that induced by a\ngravitational-wave background. Measurement of these delay variations is not\nonly crucial for the detection of such signals, but also provides an\nunparallelled measurement of the turbulent interstellar plasma at au scales. In\nthis paper we demonstrate that without consideration of wavelength- independent\nred-noise, 'simple' algorithms to correct for interstellar dispersion can\nattenuate signals of interest to pulsar timing arrays. We present a robust\nmethod for this correction, which we validate through simulations, and apply it\nto observations from the Parkes Pulsar Timing Array. Correction for dispersion\nvariations comes at a cost of increased band-limited white noise. We discuss\nscheduling to minimise this additional noise, and factors, such as\nscintillation, that can exacerbate the problem. Comparison with scintillation\nmeasurements confirms previous results that the spectral exponent of electron\ndensity variations in the interstellar medium often appears steeper than\nexpected. We also find a discrete change in dispersion measure of PSR\nJ1603-7202 of ~2x10^{-3} cm^{-3}pc for about 250 days. We speculate that this\nhas a similar origin to the 'extreme scattering events' seen in other sources.\nIn addition, we find that four pulsars show a wavelength-dependent annual\nvariation, indicating a persistent gradient of electron density on an au\nspatial scale, which has not been reported previously. \n\n"}
{"id": "1211.6427", "contents": "Title: High Frequency Gravitational Waves from Supermassive Black Holes:\n  Prospects for LIGO-Virgo Detections Abstract: It is commonly assumed that ground-based gravitational wave (GW) instruments\nwill not be sensitive to supermassive black holes (SMBHs) because the\ncharacteristic GW frequencies are far below the ~ 10 - 1000 Hz sensitivity\nbands of terrestrial detectors. Here, however, we explore the possibility of\nSMBH gravitational waves to leak to higher frequencies. In particular, if the\nhigh frequency spectral tail asymptotes to h(f) ~ f^{-alpha}, where alpha<=2,\nthen the spectral amplitude is a constant or increasing function of the mass M\nat a fixed frequency f>>c^3/GM. This will happen if the time domain waveform or\nits derivative exhibits a discontinuity. Ground based instruments could search\nfor these universal spectral tails to detect or rule out such features\nirrespective of their origin. We identify the following processes which may\ngenerate high frequency signals: (i) gravitational bremsstrahlung of\nultrarelativistic objects in the vicinity of a SMBH, (ii) ringdown modes\nexcited by an external process that has a high frequency component or\nterminates abruptly, (iii) gravitational lensing echos and diffraction. In\nparticular for (iii), SMBHs produce GW echos of inspiraling stellar mass\nbinaries in galactic nuclei with a delay of a few minutes to hours. The lensed\nprimary signal and GW echo are amplified if the binary is within a ~10 deg\n(r/100M)^{-1/2} cone behind the SMBH relative to the line of sight at distance\nr from the SMBH. For the rest of the binaries near SMBHs, the amplitude of the\nGW echo is ~0.1 (r/100M)^{-1} of the primary signal on average. \n\n"}
{"id": "1211.6450", "contents": "Title: Exploring the Cosmic Reionization Epoch in Frequency Space: An Improved\n  Approach to Remove the Foreground in 21 cm Tomography Abstract: Aiming to correctly restore the redshifted 21 cm signals emitted by the\nneutral hydrogen during the cosmic reionization processes, we re-examine the\nseparation approaches based on the quadratic polynomial fitting technique in\nfrequency space to investigate whether they works satisfactorily with complex\nforeground, by quantitatively evaluate the quality of restored 21 cm signals in\nterms of sample statistics. We construct the foreground model to characterize\nboth spatial and spectral substructures of the real sky, and use it to simulate\nthe observed radio spectra. By comparing between different separation\napproaches through statistical analysis of restored 21 cm spectra and\ncorresponding power spectra, as well as their constraints on the mean halo bias\n$b$ and average ionization fraction $x_e$ of the reionization processes, at\n$z=8$ and the noise level of 60 mK we find that, although the complex\nforeground can be well approximated with quadratic polynomial expansion, a\nsignificant part of Mpc-scale components of the 21 cm signals (75% for $\\gtrsim\n6h^{-1}$ Mpc scales and 34% for $\\gtrsim 1h^{-1}$ Mpc scales) is lost because\nit tends to be mis-identified as part of the foreground when\nsingle-narrow-segment separation approach is applied. The best restoration of\nthe 21 cm signals and the tightest determination of $b$ and $x_e$ can be\nobtained with the three-narrow-segment fitting technique as proposed in this\npaper. Similar results can be obtained at other redshifts. \n\n"}
{"id": "1211.6487", "contents": "Title: Effects of Kerr Strong Gravity on Quasar X-ray Microlensing Abstract: Recent quasar microlensing observations have constrained the sizes of X-ray\nemission regions to be within about 10 gravitational radii of the central\nsupermassive black hole. Therefore, the X-ray emission from lensed quasars is\nfirst strongly lensed by the black hole before it is lensed by the foreground\ngalaxy and star fields. We present a scheme that combines the initial strong\nlensing of a Kerr black hole with standard linearized microlensing by\nintervening stars. We find that X-ray microlensed light curves incorporating\nKerr strong gravity can differ significantly from standard curves. The\namplitude of the fluctuations in the light curves can increase or decrease by\n~0.65-0.75 mag by including Kerr strong gravity. Larger inclination angles give\nlarger amplitude fluctuations in the microlensing light curves. Consequently,\ncurrent X-ray microlensing observations might have under or overestimated the\nsizes of the X-ray emission regions. We estimate this bias using a simple\nmetric based on the amplitude of magnitude fluctuations. The half light radius\nof the X-ray emission region can be underestimated up to ~50% or overestimated\nup to ~20%. Underestimates are found in most situations we have investigated.\nThe only exception is for a disk with large spin, radially flat emission\nprofile, and observed nearly face on, where an overestimate is found. Thus,\nmore accurate microlensing size constraints should be obtainable by including\nKerr lensing. The caustic crossing time can differ by months after including\nKerr strong gravity. A simultaneous monitoring of gravitational lensed quasars\nin both X-ray and optical bands with densely sampled X-ray light curves might\nreveal this feature. We conclude that it should be possible to constrain\nimportant parameters such as inclination angles and black hole spins from\ncombined Kerr and microlensing effects. \n\n"}
{"id": "1211.6515", "contents": "Title: SZ effect or Not? - Detecting most galaxy clusters' main foreground\n  effect Abstract: Galaxy clusters are the most massive objects in the Universe and comprise a\nhigh-temperature intracluster medium of about 10^7 K, believed to offer a main\nforeground effect for cosmic microwave background (CMB) data in the form of the\nthermal Sunyaev-Zel'dovich (SZ) effect. This assumption has been confirmed by\nSZ signal detection in hundreds of clusters but, in comparison with the huge\nnumbers of clusters within optically selected samples from Sloan Digital Sky\nSurvey (SDSS) data, this only accounts for a few per cent of clusters. Here we\nintroduce a model-independent new method to confirm the assumption that most\ngalaxy clusters can offer the thermal SZ signal as their main foreground\neffect. For the Wilkinson Microwave Anisotropy Probe (WMAP) seven-year data\n(and a given galaxy cluster sample), we introduced a parameter d1 as the\nnearest-neighbour cluster angular distance of each pixel, then we classified\ndata pixels as 'to be' (d1--> 0 case) or 'not to be' (d1 large enough) affected\nby the sample clusters. By comparing the statistical results of these two kinds\nof pixels, we can see how the sample clusters affect the CMB data directly. We\nfind that the Planck Early Sunyaev-Zel'dovich (ESZ) sample and X-ray samples\n(~10^2 clusters) can lead to obvious temperature depression in the WMAP\nseven-year data, which confirms the SZ effect prediction. However, each\noptically selected sample (>10^4 clusters) shows an opposite result: the mean\ntemperature rises to about 10uK. This unexpected qualitative scenario implies\nthat the main foreground effect of most clusters is $not$ always the expected\nSZ effect. This may be the reason why the SZ signal detection result is lower\nthan expected from the model. \n\n"}
{"id": "1211.6738", "contents": "Title: Sowing the seeds of massive black holes in small galaxies: Young\n  clusters as the building blocks of Ultra-Compact-Dwarf Galaxies Abstract: Interacting galaxies often have complexes of hundreds of young stellar\nclusters of individual masses $\\sim 10^{4-6}~M_\\odot$ in regions that are a few\nhundred parsecs across. These cluster complexes interact dynamically, and their\ncoalescence is a candidate for the origin of some ultracompact dwarf galaxies\n(UCDs). Individual clusters with short relaxation times are candidates for the\nproduction of intermediate-mass black holes of a few hundred solar masses, via\nrunaway stellar collisions prior to the first supernovae in a cluster. It is\ntherefore possible that a cluster complex hosts multiple intermediate-mass\nblack holes that may be ejected from their individual clusters due to mergers\nor binary processes, but bound to the complex as a whole. Here we explore the\ndynamical interaction between initially free-flying massive black holes and\nclusters in an evolving cluster complex. We find that, after hitting some\nclusters, it is plausible that the massive black hole will be captured in an\nultracompact dwarf forming near the center of the complex. In the process, the\nhole typically triggers electromagnetic flares via stellar disruptions, and is\nalso likely to be a prominent source of gravitational radiation for the\nadvanced ground-based detectors LIGO and VIRGO. We also discuss other\nimplications of this scenario, notably that the central black hole could be\nconsiderably larger than expected in other formation scenarios for ultracompact\ndwarfs. \n\n"}
{"id": "1211.6922", "contents": "Title: The sensitivity of Cherenkov telescopes to dark matter and astrophysical\n  anisotropies in the diffuse gamma-ray background Abstract: In this article, the capability of present (H.E.S.S., MAGIC, VERITAS) and\nplanned (CTA) ground-based Cherenkov telescope systems for detecting angular\nanisotropies in the diffuse gamma-ray background is investigated. Following up\non a study of the impact of instrumental characteristics (effective area, field\nof view, angular resolution, and background rejection efficiency), the first\npart examines the influence of different observational strategies, i.e. whether\na single deep observation or a splitting over multiple shallow fields is\npreferred. In the second part, the sensitivity to anisotropies generated by\nself-annihilating dark matter is studied for different common dark matter\nmodels. We find that a relative contribution of ~10% from dark matter\nannihilation to the extra-galactic diffuse gamma-ray background can be detected\nwith planned configurations of CTA. In terms of the thermally-averaged\nself-annihilation cross section, the sensitivity of CTA corresponds to values\nbelow the thermal freeze-out expectation <sigma v> = 3 x 10-26 cm3s-1 for dark\nmatter particles lighter than ~200 GeV. We stress the importance of\nconstraining anisotropies from unresolved astrophysical sources with currently\noperating instruments already, as a novel and complementary method for\ninvestigating the properties of TeV sources. \n\n"}
{"id": "1212.0538", "contents": "Title: FitSKIRT: genetic algorithms to automatically fit dusty galaxies with a\n  Monte Carlo radiative transfer code Abstract: We present FitSKIRT, a method to efficiently fit radiative transfer models to\nUV/optical images of dusty galaxies. These images have the advantage that they\nhave better spatial resolution compared to FIR/submm data. FitSKIRT uses the\nGAlib genetic algorithm library to optimize the output of the SKIRT Monte Carlo\nradiative transfer code. Genetic algorithms prove to be a valuable tool in\nhandling the multi- dimensional search space as well as the noise induced by\nthe random nature of the Monte Carlo radiative transfer code. FitSKIRT is\ntested on artificial images of a simulated edge-on spiral galaxy, where we\ngradually increase the number of fitted parameters. We find that we can recover\nall model parameters, even if all 11 model parameters are left unconstrained.\nFinally, we apply the FitSKIRT code to a V-band image of the edge-on spiral\ngalaxy NGC4013. This galaxy has been modeled previously by other authors using\ndifferent combinations of radiative transfer codes and optimization methods.\nGiven the different models and techniques and the complexity and degeneracies\nin the parameter space, we find reasonable agreement between the different\nmodels. We conclude that the FitSKIRT method allows comparison between\ndifferent models and geometries in a quantitative manner and minimizes the need\nof human intervention and biasing. The high level of automation makes it an\nideal tool to use on larger sets of observed data. \n\n"}
{"id": "1212.0805", "contents": "Title: Universality in nonequilibrium condensation of exciton-polaritons Abstract: We investigate the process of condensation of exciton-polaritons in a\none-dimensional nanowire, predicting spontaneous formation of domains of\nuncondensed excitons and condensed polaritons. We demonstrate a universal\nscaling law for the density of domains, which results from the competition\nbetween characteristic timescales present in the system. However, we find that\nthe system does not follow the standard Kibble-\\.Zurek scenario of a\nnonequilibrium phase transition. \n\n"}
{"id": "1212.1729", "contents": "Title: CMB interferometry Abstract: Interferometry has been a very successful tool for measuring anisotropies in\nthe cosmic microwave background. Interferometers provided the first constraints\non CMB anisotropies on small angular scales (l~10000) in the 1980s and then in\nthe late 1990s and early 2000s made ground-breaking measurements of the CMB\npower spectrum at intermediate and small angular scales covering the l-range\n~100-4000. In 2002 the DASI made the first detection of CMB polarization which\nremains a major goal for current and future CMB experiments. Interferometers\nhave also made major contributions to the detection and surveying of the\nSunyaev-Zel'dovich (SZ) effect in galaxy clusters. In this short review I cover\nthe key aspects that made interferometry well-suited to CMB measurements and\nsummarise some of the central observations that have been made. I look to the\nfuture and in particular to HI intensity mapping at high redshifts that could\nmake use of the advantages of interferometry. \n\n"}
{"id": "1212.2568", "contents": "Title: MOND laws of galactic dynamics Abstract: MOND predicts a number of laws that galactic systems should obey irrespective\nof their complicated, haphazard, and mostly unknowable histories -- as Kepler's\nlaws are obeyed by planetary systems. The main purpose of this work is to show\nhow, and to what extent, these MOND laws follow from only the paradigm's basic\ntenets: departure from standard dynamics at accelerations a<~a0, and space-time\nscale invariance in the limit a<<a0. Such predictions will be shared by all\nMOND theories that embody these premises. This is important because we do not\nknow which of the existing MOND theories, if any, is a step in the right\ndirection. In the Newtonian-dynamics-plus-dark-matter paradigm, the validity of\nsuch clear-cut laws -- which tightly constrain baryons, `dark matter', and\ntheir mutual relations -- is contrary to expectations. \n\n"}
{"id": "1212.2633", "contents": "Title: Tidal disruptions in circumbinary discs (I): Star formation, dynamics,\n  and binary evolution Abstract: In our current interpretation of the hierarchical structure of the universe\nit is well established that galaxies collide and merge with each other during\ntheir lifetime. If massive black holes (MBHs) reside in galactic centres, we\nexpect them to form binaries in galactic nuclei surrounded by a circumbinary\ndisc. If cooling is efficient enough, the gas in the disc will clump and\ntrigger stellar formation in situ. In this first paper we address the evolution\nof the binary under the influence of the newly formed stars, which form\nindividually and also clustered. We use SPH techniques to evolve the gas in the\ncircumbinary disc and to study the phase of star formation. When the amount of\ngas in the disc is negligible, we further evolve the system with a\nhigh-accurate direct-summation $N-$body code to follow the evolution of the\nstars, the innermost binary and tidal disruption events (TDEs). For this, we\nmodify the direct N-body code to (i) include treatment of TDEs and to (ii)\ninclude \"gas cloud particles\" that mimic the gas, so that the stellar clusters\ndo not disolve when we follow their infall on to the MBHs. We find that the\namount of stars disrupted by either infalling stellar clusters or individual\nstars is as large as 10^{-4}/yr per binary, higher than expected for typical\ngalaxies. \n\n"}
{"id": "1212.3332", "contents": "Title: MegaMorph - multi-wavelength measurement of galaxy structure: complete\n  S\\'ersic profile information from modern surveys Abstract: In this paper, we demonstrate a new method for fitting galaxy profiles which\nmakes use of the full multi-wavelength data provided by modern large\noptical-near-infrared imaging surveys. We present a new version of GALAPAGOS,\nwhich utilises a recently-developed multi-wavelength version of GALFIT, and\nenables the automated measurement of wavelength dependent S\\'ersic profile\nparameters for very large samples of galaxies. Our new technique is extensively\ntested to assess the reliability of both pieces of software, GALFIT and\nGALAPAGOS on both real ugrizY JHK imaging data from the GAMA survey and\nsimulated data made to the same specifications. We find that fitting galaxy\nlight profiles with multi-wavelength data increases the stability and accuracy\nof the measured parameters, and hence produces more complete and meaningful\nmulti-wavelength photometry than has been available previously. The improvement\nis particularly significant for magnitudes in low S/N bands and for structural\nparameters like half-light radius re and S\\'ersic index n for which a prior is\nused by constraining these parameters to a polynomial as a function of\nwavelength. This allows the fitting routines to push the magnitude of galaxies\nfor which sensible values can be derived to fainter limits. The technique\nutilises a smooth transition of galaxy parameters with wavelength, creating\nmore physically meaningful transitions than single-band fitting and allows\naccurate interpolation between passbands, perfect for derivation of rest-frame\nvalues. \n\n"}
{"id": "1212.6945", "contents": "Title: Towards efficient and optimal analysis of CMB anisotropies on a masked\n  sky Abstract: Strong foreground contamination in high resolution CMB data requires masking\nwhich introduces statistical anisotropies and renders a full maximum likelihood\nanalysis numerically intractable. Standard analysis methods like the pseudo-C_l\nframework lead to information loss due to estimator suboptimalities. We set out\nand validate a methodology for numerically efficient estimators for a masked\nsky that recover nearly as much information as a full maximum likelihood\nprocedure. In addition to the standard pseudo-C_l statistic, the approach\nintroduces an augmented basis designed to account for the mode coupling due to\nthe masking of the sky. We motivate the choice of this basis by describing the\nbasic structure of the covariance matrix. We demonstrate that the augmented\nestimator can achieve near-optimal results in the presence of a WMAP-realistic\nmask. \n\n"}
{"id": "1301.1982", "contents": "Title: Swift J1644+57 gone MAD: the case for dynamically-important magnetic\n  flux threading the black hole in a jetted tidal disruption event Abstract: The unusual transient Swift J1644+57 likely resulted from a collimated\nrelativistic jet powered by accretion onto a massive black hole (BH) following\nthe tidal disruption (TD) of a star. Several mysteries cloud the interpretation\nof this event: (1) extreme flaring and `plateau' shape of the X-ray/gamma-ray\nlight curve during the first 10 days after the gamma-ray trigger; (2)\nunexpected rebrightening of the forward shock radio emission months after\ntrigger; (3) no obvious evidence for jet precession, despite misalignment\ntypically expected between the angular momentum of the accretion disk and BH;\n(4) recent abrupt shut-off in jet X-ray emission after 1.5 years. Here we show\nthat all of these seemingly disparate mysteries are naturally resolved by one\nassumption: the presence of strong magnetic flux Phi threading the BH.\nInitially, Phi is weak relative to high fall-back mass accretion rate, Mdot,\nand the disk and jets precess about the BH axis = our line of sight. As Mdot\ndrops, Phi becomes dynamically important and leads to a magnetically-arrested\ndisk (MAD). MAD naturally aligns disk and jet axis along the BH spin axis, but\nonly after a violent rearrangement phase (jet wobbling). This explains the\nerratic light curve at early times and the lack of precession at later times.\nWe use our model for Swift J1644+57 to constrain BH and disrupted star\nproperties, finding that a solar-mass main sequence star disrupted by a\nrelatively low mass, M~10^5-10^6 Msun, BH is consistent with the data, while a\nWD disruption (though still possible) is disfavored. The magnetic flux required\nto power Swift J1644+57 is too large to be supplied by the star itself, but it\ncould be collected from a quiescent `fossil' accretion disk present in the\ngalactic nucleus prior to the TD. The presence (lack of) of such a fossil disk\ncould be a deciding factor in what TD events are accompanied by powerful\njets.[abridged] \n\n"}
{"id": "1301.2815", "contents": "Title: XMASS detector Abstract: The XMASS project aims to detect dark matter, pp and $^{7}$Be solar\nneutrinos, and neutrinoless double beta decay using ultra pure liquid xenon.\nThe first phase of the XMASS experiment searches for dark matter. In this\npaper, we describe the XMASS detector in detail, including its configuration,\ndata acquisition equipment and calibration system. \n\n"}
{"id": "1301.3010", "contents": "Title: A new method to improve photometric redshift reconstruction.\n  Applications to the Large Synoptic Survey Telescope Abstract: In the next decade, the LSST will become a major facility for the\nastronomical community. However accurately determining the redshifts of the\nobserved galaxies without using spectroscopy is a major challenge.\nReconstruction of the redshifts with high resolution and well-understood\nuncertainties is mandatory for many science goals, including the study of\nbaryonic acoustic oscillations. We investigate different approaches to\nestablish the accuracy that can be reached by the LSST six-band photometry. We\nconstruct a realistic mock galaxy catalog, based on the GOODS survey luminosity\nfunction, by simulating the expected apparent magnitude distribution for the\nLSST. To reconstruct the photometric redshifts (photo-z's), we consider a\ntemplate-fitting method and a neural network method. The photo-z reconstruction\nfrom both of these techniques is tested on real CFHTLS data and also on\nsimulated catalogs. We describe a new method to improve photo-z reconstruction\nthat efficiently removes catastrophic outliers via a likelihood ratio\nstatistical test. This test uses the posterior probability functions of the fit\nparameters and the colors. We show that the photometric redshift accuracy will\nmeet the stringent LSST requirements up to redshift $\\sim2.5$ after a selection\nthat is based on the likelihood ratio test or on the apparent magnitude for\ngalaxies with $S/N>5$ in at least 5 bands. The former selection has the\nadvantage of retaining roughly 35% more galaxies for a similar photo-z\nperformance compared to the latter. Photo-z reconstruction using a neural\nnetwork algorithm is also described. In addition, we utilize the CFHTLS\nspectro-photometric catalog to outline the possibility of combining the neural\nnetwork and template-fitting methods. We conclude that the photo-z's will be\naccurately estimated with the LSST if a Bayesian prior probability and a\ncalibration sample are used. \n\n"}
{"id": "1301.5362", "contents": "Title: Polymer Bose--Einstein Condensates Abstract: In this work we analyze a non--interacting one dimensional polymer\nBose--Einstein condensate in an harmonic trap within the semiclassical\napproximation. We use an effective Hamiltonian coming from the polymer\nquantization that arises in loop quantum gravity. We calculate the number of\nparticles in order to obtain the critical temperature. The Bose--Einstein\nfunctions are replaced by series, whose high order terms are related to powers\nof the polymer length. It is shown that the condensation temperature presents a\nshift respect to the standard case, for small values of the polymer scale. In\ntypical experimental conditions, it is possible to establish a bound for\n$\\lambda^{2}$ up to $ \\lesssim 10 ^{-16}$m$^2$. To improve this bound we should\ndecrease the frequency of the trap and also decrease the number of particles. \n\n"}
{"id": "1301.7099", "contents": "Title: Opening the 21cm EoR Window: Measurements of Foreground Isolation with\n  PAPER Abstract: We present new observations with the Precision Array for Probing the Epoch of\nReionization (PAPER) with the aim of measuring the properties of foreground\nemission for 21cm Epoch of Reionization experiments at 150 MHz. We focus on the\nfootprint of the foregrounds in cosmological Fourier space to understand which\nmodes of the 21cm power spectrum will most likely be compromised by foreground\nemission. These observations confirm predictions that foregrounds can be\nisolated to a \"wedge\"-like region of 2D (k-perpendicular, k-parallel)-space,\ncreating a window for cosmological studies at higher k-parallel values. We also\nfind that the emission extends past the nominal edge of this wedge due to\nspectral structure in the foregrounds, with this feature most prominent on the\nshortest baselines. Finally, we filter the data to retain only this \"unsmooth\"\nemission and image specific k-parallel modes of it. The resultant images show\nan excess of power at the lowest modes, but no emission can be clearly\nlocalized to any one region of the sky. This image is highly suggestive that\nthe most problematic foregrounds for 21cm EoR studies will not be easily\nidentifiable bright sources, but rather an aggregate of fainter emission. \n\n"}
{"id": "1302.0154", "contents": "Title: Linearization through symmetries for discrete equations Abstract: We show that one can define through the symmetry approach a procedure to\ncheck the linearizability of a difference equation via a point or a discrete\nCole-Hopf transformation. If the equation is linearizable the symmetry provides\nthe linearizing transformation. At the end we present few examples of\napplications for equations defined on four lattice points. \n\n"}
{"id": "1302.1705", "contents": "Title: Dynamics of test particles in thin-shell wormhole spacetimes Abstract: Geodesic motion in traversable Schwarzschild and Kerr thin-shell wormholes\nconstructed by the cut-and-paste method introduced by Visser (1989 Nucl. Phys.\nB 328 203; 1995 Wormholes: from Einstein to Hawking (Woodbury, MN: American\nInstitute of Physics)) is studied. The orbits are calculated exactly in terms\nof elliptic functions and visualized with the help of embedding diagrams. \n\n"}
{"id": "1302.4485", "contents": "Title: The 2013 Release of Cloudy Abstract: This is a summary of the 2013 release of the plasma simulation code Cloudy.\nCloudy models the ionization, chemical, and thermal state of material that may\nbe exposed to an external radiation field or other source of heating, and\npredicts observables such as emission and absorption spectra. It works in terms\nof elementary processes, so is not limited to any particular temperature or\ndensity regime. This paper summarizes advances made since the last major review\nin 1998. Much of the recent development has emphasized dusty molecular\nenvironments, improvements to the ionization / chemistry solvers, and how\natomic and molecular data are used. We present two types of simulations to\ndemonstrate the capability of the code. We consider a molecular cloud\nirradiated by an X-ray source such as an Active Nucleus and show how treating\nEUV recombination lines and the full SED affects the observed spectrum. A\nsecond example illustrates the very wide range of particle and radiation\ndensity that can be considered. \n\n"}
{"id": "1302.5430", "contents": "Title: A multiwavelength study of the Magellanic-type galaxy NGC 4449 - I.\n  Modelling the spectral energy distribution, the ionization structure and the\n  star formation history Abstract: [Abridged] We present an integrated photometric spectral energy distribution\n(SED) of the Magellanic-type galaxy NGC 4449 from the far-ultraviolet (UV) to\nthe submillimetre, including new observations acquired by the Herschel Space\nObservatory. We include integrated UV photometry from the Swift Ultraviolet and\nOptical Telescope using a measurement technique which is appropriate for\nextended sources with coincidence loss. In this paper, we examine the available\nmultiwavelength data to infer a range of ages, metallicities and star formation\nrates for the underlying stellar populations, as well as the composition and\nthe total mass of dust in NGC 4449.\n  We present an iterative scheme, which allows us to build an in-depth and\nmulticomponent representation of NGC 4449 `bottom-up', taking advantage of the\nbroad capabilities of the photoionization and radiative transfer code MOCASSIN\n(MOnte CArlo SimulationS of Ionized Nebulae). We fit the observed SED, the\nglobal ionization structure and the emission line intensities, and infer a\nrecent SFR of 0.4 Msolar/yr and a total stellar mass of approximately 1e9\nMsolar emitting with a bolometric luminosity of 5.7e9 Lsolar. Our fits yield a\ntotal dust mass of 2.9e6 Msolar including 2 per cent attributed to polycyclic\naromatic hydrocarbons. We deduce a dust to gas mass ratio of 1/190 within the\nmodelled region. While we do not consider possible additional contributions\nfrom even colder dust, we note that including the extended HI envelope and the\nmolecular gas is likely to bring the ratio down to as low as ~ 1/800. \n\n"}
{"id": "1302.6033", "contents": "Title: Stochastic gravitational wave background from hydrodynamic turbulence in\n  differentially rotating neutron stars Abstract: Hydrodynamic turbulence driven by crust-core differential rotation imposes a\nfundamental noise floor on gravitational wave observations of neutron stars.\nThe gravitational wave emission peaks at the Kolmogorov decoherence frequency\nwhich, for reasonable values of the crust-core shear, \\Delta\\Omega, occurs near\nthe most sensitive part of the frequency band for ground-based, long-baseline\ninterferometers. We calculate the energy density spectrum of the stochastic\ngravitational wave background from a cosmological population of turbulent\nneutron stars generalising previous calculations for individual sources. The\nspectrum resembles a piecewise power law,\n\\Omega_{gw}(\\nu)=\\Omega_{\\alpha}\\nu^{\\alpha}, with \\alpha=-1 and 7 above and\nbelow the decoherence frequency respectively, and its normalisation scales as\n\\Omega_{\\alpha}\\propto(\\Delta\\Omega)^{7}. Non-detection of a stochastic signal\nby Initial LIGO implies an upper limit on \\Delta\\Omega and hence by implication\non the internal relaxation time-scale for the crust and core to come into\nco-rotation, \\tau_{d}=\\Delta\\Omega/\\dot{\\Omega}, where \\dot{\\Omega} is the\nobserved electromagnetic spin-down rate, with \\tau_{d}\\lesssim 10^{7} yr for\naccreting millisecond pulsars and \\tau_{d}\\lesssim 10^{5} yr for radio-loud\npulsars. Target limits on \\tau_{d} are also estimated for future detectors,\nnamely Advanced LIGO and the Einstein Telescope, and are found to be\nastrophysically interesting. \n\n"}
{"id": "1302.7112", "contents": "Title: Muon-induced background in the EDELWEISS dark matter search Abstract: A dedicated analysis of the muon-induced background in the EDELWEISS dark\nmatter search has been performed on a data set acquired in 2009 and 2010. The\ntotal muon flux underground in the Laboratoire Souterrain de Modane (LSM) was\nmeasured to be $\\Phi_{\\mu}=(5.4\\pm 0.2 ^{+0.5}_{-0.9})$\\,muons/m$^2$/d. The\nmodular design of the muon-veto system allows the reconstruction of the muon\ntrajectory and hence the determination of the angular dependent muon flux in\nLSM. The results are in good agreement with both MC simulations and earlier\nmeasurements. Synchronization of the muon-veto system with the phonon and\nionization signals of the Ge detector array allowed identification of\nmuon-induced events. Rates for all muon-induced events $\\Gamma^{\\mu}=(0.172 \\pm\n0.012)\\, \\rm{evts}/(\\rm{kg \\cdot d})$ and of WIMP-like events $\\Gamma^{\\mu-n} =\n0.008^{+0.005}_{-0.004}\\, \\rm{evts}/(\\rm{kg \\cdot d})$ were extracted. After\nvetoing, the remaining rate of accepted muon-induced neutrons in the\nEDELWEISS-II dark matter search was determined to be $\\Gamma^{\\mu-n}_{\\rm\nirred} < 6\\cdot 10^{-4} \\, \\rm{evts}/(\\rm{kg \\cdot d})$ at 90%\\,C.L. Based on\nthese results, the muon-induced background expectation for an anticipated\nexposure of 3000\\,\\kgd\\ for EDELWEISS-3 is $N^{\\mu-n}_{3000 kg\\cdot d} < 0.6$\nevents. \n\n"}
{"id": "1303.0075", "contents": "Title: CO Component Estimation Based on the Independent Component Analysis Abstract: Fast Independent Component Analysis (FastICA) is a component separation\nalgorithm based on the levels of non-Gaussianity. Here we apply the FastICA to\nthe component separation problem of the microwave background including carbon\nmonoxide (CO) line emissions that are found to contaminate the PLANCK High\nFrequency Instrument (HFI) data. Specifically we prepare 100GHz, 143GHz, and\n217GHz mock microwave sky maps including galactic thermal dust, NANTEN CO line,\nand the Cosmic Microwave Background (CMB) emissions, and then estimate the\nindependent components based on the kurtosis. We find that the FastICA can\nsuccessfully estimate the CO component as the first independent component in\nour deflection algorithm as its distribution has the largest degree of\nnon-Gaussianity among the components. By subtracting the CO and the dust\ncomponents from the original sky maps, we will be able to make an unbiased\nestimate of the cosmological CMB angular power spectrum. \n\n"}
{"id": "1303.2107", "contents": "Title: The precision and accuracy of early Epoch of Reionization foreground\n  models: comparing MWA and PAPER 32-antenna source catalogs Abstract: As observations of the Epoch of Reionization (EoR) in redshifted 21cm\nemission begin, we asses the accuracy of the early catalog results from the\nPrecision Array for Probing the Epoch of Reionization (PAPER) and the Murchison\nWidefield Array. The MWA EoR approach derives much of its sensitivity from\nsubtracting foregrounds to <1% precision while the PAPER approach relies on the\nstability and symmetry of the primary beam. Both require an accurate flux\ncalibration to set the amplitude of the measured power spectrum. The two\ninstruments are very similar in resolution, sensitivity, sky coverage and\nspectral range and have produced catalogs from nearly contemporaneous data. We\nuse a Bayesian MCMC fitting method to estimate that the two instruments are on\nthe same flux scale to within 20% and find that the images are mostly in good\nagreement. We then investigate the source of the errors by comparing two\noverlapping MWA facets where we find that the differences are primarily related\nto an inaccurate model of the primary beam but also correlated errors in bright\nsources due to CLEAN. We conclude with suggestions for mitigating and better\ncharacterizing these effects. \n\n"}
{"id": "1303.2686", "contents": "Title: Applications of an Y-88/Be photo-neutron calibration source to Dark\n  Matter and Neutrino Experiments Abstract: The low-energy monochromatic neutron emission from an Y-88/Be source can be\nexploited to mimic the few keVnr nuclear recoils expected from low-mass Weakly\nInteracting Massive Particles (WIMPs) and coherent scattering of neutrinos off\nnuclei. Using this source, a ~<10% quenching factor is measured for sodium\nrecoils below 24 keVnr in NaI[Tl]. This is considerably smaller than the 30%\ntypically adopted in the interpretation of the DAMA/LIBRA dark matter\nexperiment, resulting in a marked increase of its tension with other searches,\nunder the standard set of phenomenological assumptions. The method is\nillustrated for other target materials (superheated and noble liquids). \n\n"}
{"id": "1303.3004", "contents": "Title: Energy Extraction from Spinning Black Holes via Relativistic Jets Abstract: It has for long been an article of faith among astrophysicists that black\nhole spin energy is responsible for powering the relativistic jets seen in\naccreting black holes. Two recent advances have strengthened the case. First,\nnumerical general relativistic magnetohydrodynamic simulations of accreting\nspinning black holes show that relativistic jets form spontaneously. In at\nleast some cases, there is unambiguous evidence that much of the jet energy\ncomes from the black hole, not the disk. Second, spin parameters of a number of\naccreting stellar-mass black holes have been measured. For ballistic jets from\nthese systems, it is found that the radio luminosity of the jet correlates with\nthe spin of the black hole. This suggests a causal relationship between black\nhole spin and jet power, presumably due to a generalized Penrose process. \n\n"}
{"id": "1303.3409", "contents": "Title: Bayesian analysis of anisotropic cosmologies: Bianchi VII_h and WMAP Abstract: We perform a definitive analysis of Bianchi VII_h cosmologies with WMAP\nobservations of the cosmic microwave background (CMB) temperature anisotropies.\nBayesian analysis techniques are developed to study anisotropic cosmologies\nusing full-sky and partial-sky, masked CMB temperature data. We apply these\ntechniques to analyse the full-sky internal linear combination (ILC) map and a\npartial-sky, masked W-band map of WMAP 9-year observations. In addition to the\nphysically motivated Bianchi VII_h model, we examine phenomenological models\nconsidered in previous studies, in which the Bianchi VII_h parameters are\ndecoupled from the standard cosmological parameters. In the two\nphenomenological models considered, Bayes factors of 1.7 and 1.1 units of\nlog-evidence favouring a Bianchi component are found in full-sky ILC data. The\ncorresponding best-fit Bianchi maps recovered are similar for both\nphenomenological models and are very close to those found in previous studies\nusing earlier WMAP data releases. However, no evidence for a phenomenological\nBianchi component is found in the partial-sky W-band data. In the physical\nBianchi VII_h model we find no evidence for a Bianchi component: WMAP data thus\ndo not favour Bianchi VII_h cosmologies over the standard Lambda Cold Dark\nMatter (LCDM) cosmology. It is not possible to discount Bianchi VII_h\ncosmologies in favour of LCDM completely, but we are able to constrain the\nvorticity of physical Bianchi VII_h cosmologies at $(\\omega/H)_0 < 8.6 \\times\n10^{-10}$ with 95% confidence. \n\n"}
{"id": "1303.5064", "contents": "Title: Planck 2013 results. III. LFI systematic uncertainties Abstract: We present the current estimate of instrumental and systematic effect\nuncertainties for the Planck-Low Frequency Instrument relevant to the first\nrelease of the Planck cosmological results. We give an overview of the main\neffects and of the tools and methods applied to assess residuals in maps and\npower spectra. We also present an overall budget of known systematic effect\nuncertainties, which are dominated sidelobe straylight pick-up and imperfect\ncalibration. However, even these two effects are at least two orders of\nmagnitude weaker than the cosmic microwave background (CMB) fluctuations as\nmeasured in terms of the angular temperature power spectrum. A residual signal\nabove the noise level is present in the multipole range $\\ell<20$, most notably\nat 30 GHz, and is likely caused by residual Galactic straylight contamination.\nCurrent analysis aims to further reduce the level of spurious signals in the\ndata and to improve the systematic effects modelling, in particular with\nrespect to straylight and calibration uncertainties. \n\n"}
{"id": "1303.5065", "contents": "Title: Planck 2013 results. IV. Low Frequency Instrument beams and window\n  functions Abstract: This paper presents the characterization of the in-flight beams, the beam\nwindow functions and the associated uncertainties for the Planck Low Frequency\nInstrument (LFI). Knowledge of the beam profiles is necessary for determining\nthe transfer function to go from the observed to the actual sky anisotropy\npower spectrum. The main beam distortions affect the beam window function,\ncomplicating the reconstruction of the anisotropy power spectrum at high\nmultipoles, whereas the sidelobes affect the low and intermediate multipoles.\nThe in-flight assessment of the LFI main beams relies on the measurements\nperformed during Jupiter observations. By stacking the data from multiple\nJupiter transits, the main beam profiles are measured down to -20 dB at 30 and\n44 GHz, and down to -25 dB at 70 GHz. The main beam solid angles are determined\nto better than 0.2% at each LFI frequency band. The Planck pre-launch optical\nmodel is conveniently tuned to characterize the main beams independently of any\nnoise effects. This approach provides an optical model whose beams fully\nreproduce the measurements in the main beam region, but also allows a\ndescription of the beams at power levels lower than can be achieved by the\nJupiter measurements themselves. The agreement between the simulated beams and\nthe measured beams is better than 1% at each LFI frequency band. The simulated\nbeams are used for the computation of the window functions for the effective\nbeams. The error budget for the window functions is estimated from both main\nbeam and sidelobe contributions, and accounts for the radiometer bandshapes.\nThe total uncertainties in the effective beam window functions are: 2% and 1.2%\nat 30 and 44 GHz, respectively (at $\\ell \\approx 600$), and 0.7% at 70 GHz (at\n$\\ell \\approx 1000$). \n\n"}
{"id": "1303.5069", "contents": "Title: Planck 2013 results. VIII. HFI photometric calibration and mapmaking Abstract: This paper describes the processing applied to the HFI cleaned time-ordered\ndata to produce photometrically calibrated maps. HFI observes the sky over a\nbroad range of frequencies, from 100 to 857 GHz. To get the best accuracy on\nthe calibration on such a large range, two different photometric calibration\nschemes have to be used. The 545 and 857 \\GHz\\ data are calibrated using Uranus\nand Neptune flux density measurements, compared with models of their\natmospheric emissions to calibrate the data. The lower frequencies (below 353\nGHz) are calibrated using the cosmological microwave background dipole.One of\nthe components of this anisotropy results from the orbital motion of the\nsatellite in the Solar System, and is therefore time-variable. Photometric\ncalibration is thus tightly linked to mapmaking, which also addresses low\nfrequency noise removal. The 2013 released HFI data show some evidence for\napparent gain variations of the HFI bolometers' detection chain. These\nvariations were identified by comparing observations taken more than one year\napart in the same configuration. We developed an effective correction to limit\nits effect on calibration, and assess its accuracy. We present several methods\nused to estimate the precision of the photometric calibration. We distinguish\nrelative (from one detector to another, or from one frequency to another) and\nabsolute uncertainties. In both cases, we found that these uncertainties range\nfrom a few $10^{-3}$ to several per cents from 100 to 857 GHz. We describe the\npipeline producing the maps from the HFI timelines, based on the photometric\ncalibration parameters and we detail the scheme used to a posteriori set the\nzero level of the maps. We also briefly discuss the cross-calibration between\nHFI and the SPIRE instrument on board Herschel. We finally summarize the basic\ncharacteristics of the set of the HFI maps from the 2013 Planck data release. \n\n"}
{"id": "1303.6763", "contents": "Title: Optical-radio positional offsets for active galactic nuclei Abstract: Context. It will soon become possible to directly link the most accurate\nradio reference frame with the Gaia optical reference frame using many common\nextragalactic objects. It is important to know the level of coincidence between\nthe radio and optical positions of compact active galactic nuclei (AGN). Aims.\nUsing the best catalogues available at present, we investigate how many AGN\nwith significantly large optical-radio positional offsets exist as well as the\npossible causes of these offsets. Methods. We performed a case study by finding\noptical counterparts to the International Celestial Reference Frame (ICRF2)\nradio sources in the Sloan Digital Sky Survey (SDSS) Data Release 9 (DR9). The\nICRF2 catalogue was used as a reference because the radio positions determined\nby Very Long Baseline Interferometry (VLBI) observations are about two orders\nof magnitude more accurate than the optical positions. Results. We find 1297\nobjects in common for ICRF2 and SDSS DR9. Statistical analysis of the\noptical-radio differences verifies that the SDSS DR9 positions are accurate to\n~55 mas in both coordinates, with no systematic offset with respect to ICRF2.\nWe find 51 sources (~4% of the sample) for which the positional offset exceeds\n170 mas (~3{\\sigma}). Astrophysical explanations must exist for most of these\noutliers. There are 3 known strong gravitational lenses among them. Dual AGN or\nrecoiling supermassive black holes may also be possible. Conclusions. The most\naccurate Gaia-VLBI reference frame link will require a careful selection of a\ncommon set of objects by eliminating the outliers. On the other hand, the\nsignificant optical-radio positional non-coincidences may offer a new tool for\nfinding e.g. gravitational lenses or dual AGN candidates. Detailed follow-up\nradio interferometric and optical spectroscopic observations are encouraged to\ninvestigate the outlier sources found in this study. \n\n"}
{"id": "1304.0315", "contents": "Title: CMB likelihood approximation for banded probability distributions Abstract: We investigate sets of random variables that can be arranged sequentially\nsuch that a given variable only depends conditionally on its immediate\npredecessor. For such sets, we show that the full joint probability\ndistribution may be expressed exclusively in terms of uni- and bivariate\nmarginals. Under the assumption that the CMB power spectrum likelihood only\nexhibits correlations within a banded multipole range, \\Delta l, we apply this\nexpression to two outstanding problems in CMB likelihood analysis. First, we\nderive a statistically well-defined hybrid likelihood estimator, merging two\nindependent (e.g., low- and high-l) likelihoods into a single expression that\nproperly accounts for correlations between the two. Applying this expression to\nthe WMAP likelihood, we verify that the effect of correlations on cosmological\nparameters in the transition region is negligible in terms of cosmological\nparameters for WMAP; the largest relative shift seen for any parameter is\n0.06\\sigma. However, because this may not hold for other experimental setups\n(e.g., for different instrumental noise properties or analysis masks), but must\nrather be verified on a case-by-case basis, we recommend our new hybridization\nscheme for future experiments for statistical self-consistency reasons. Second,\nwe use the same expression to improve the convergence rate of the Blackwell-Rao\nlikelihood estimator, reducing the required number of Monte Carlo samples by\nseveral orders of magnitude, and thereby extend it to high-l applications. \n\n"}
{"id": "1304.1802", "contents": "Title: Cosmic Chronometers in the R_h=ct Universe Abstract: The use of luminous red galaxies as cosmic chronometers provides us with an\nindispensable method of measuring the universal expansion rate H(z) in a\nmodel-independent way. Unlike many probes of the cosmological history, this\napproach does not rely on integrated quantities, such as the luminosity\ndistance, and therefore does not require the pre-assumption of any particular\nmodel, which may bias subsequent interpretations of the data. We employ three\nstatistical tools -- the Akaike, Kullback, and Bayes Information Criteria (AIC,\nKIC and BIC) -- to compare the LCDM model and the R_h=ct Universe with the\ncurrently available measurements of H(z), and show that the R_h=ct Universe is\nfavored by these model selection criteria. The parameters in each model are\nindividually optimized by maximum likelihood estimation. The R_h=ct Universe\nfits the data with a reduced chi^2_dof=0.745 for a Hubble constant\nH_0=63.2+/-2.5 km/s/Mpc, and H_0 is the sole parameter in this model. By\ncomparison, the optimal LCDM model, which has three free parameters (including\nH_0=68.9+/-2.4 km/s/Mpc, Omega_m=0.32, and a dark-energy equation of state\np_de=-rho_de), fits the H(z) data with a reduced chi^2_dof=0.777. With these\nchi^2_dof values, the AIC yields a likelihood of about 82 per cent that the\ndistance--redshift relation of the R_h=ct Universe is closer to the correct\ncosmology, than is the case for LCDM. If the alternative BIC criterion is used,\nthe respective Bayesian posterior probabilities are 91.2 per cent (R_h=ct)\nversus 8.8 per cent (LCDM). Using the concordance LCDM parameter values, rather\nthan those obtained by fitting LCDM to the cosmic chronometer data, would\nfurther disfavor LCDM. \n\n"}
{"id": "1304.3339", "contents": "Title: Lenticular galaxy IC 719: current building of the counterrotating\n  large-scale stellar disk Abstract: We have obtained and analyzed long-slit spectral data for the lenticular\ngalaxy IC 719. In this gas-rich S0 galaxy, its large-scale gaseous disk\ncounterrotates the global stellar disk. Moreover in the IC 719 disk we have\ndetected a secondary stellar component corotating the ionized gas. By using\nemission-line intensity ratios, we have proved the gas excitation by young\nstars and so are claiming current star formation, most intense in a ring-like\nzone at the radius of 10\" (1.4 kpc). The oxygen abundance of the gas in the\nstarforming ring is about half of the solar abundance. Since the stellar disk\nremains dynamically cool, we conclude that smooth prolonged accretion of the\nexternal gas from a neighboring galaxy provides urrent building of the thin\nlarge-scale stellar disk. \n\n"}
{"id": "1304.4279", "contents": "Title: Silicon Detector Dark Matter Results from the Final Exposure of CDMS II Abstract: We report results of a search for Weakly Interacting Massive Particles\n(WIMPS) with the silicon detectors of the CDMS II experiment. This blind\nanalysis of 140.2 kg-days of data taken between July 2007 and September 2008\nrevealed three WIMP-candidate events with a surface-event background estimate\nof 0.41^{+0.20}_{-0.08}(stat.)^{+0.28}_{-0.24}(syst.). Other known backgrounds\nfrom neutrons and 206Pb are limited to < 0.13 and <0.08 events at the 90%\nconfidence level, respectively. The exposure of this analysis is equivalent to\n23.4 kg-days for a recoil energy range of 7-100 keV for a WIMP of mass 10\nGeV/c2. The probability that the known backgrounds would produce three or more\nevents in the signal region is 5.4%. A profile likelihood ratio test of the\nthree events that includes the measured recoil energies gives a 0.19%\nprobability for the known-background-only hypothesis when tested against the\nalternative WIMP+background hypothesis. The highest likelihood occurs for a\nWIMP mass of 8.6 GeV/c2 and WIMP-nucleon cross section of 1.9e-41 cm2. \n\n"}
{"id": "1304.4668", "contents": "Title: Universal density scaling of disorder-limited low-temperature\n  conductivity in high-mobility two-dimensional systems Abstract: We theoretically consider the carrier density dependence of low-temperature\nelectrical conductivity in high-quality and low-disorder two-dimensional (2D)\n`metallic' electronic systems such as 2D GaAs electron or hole quantum wells or\ngated graphene. Taking into account resistive scattering by Coulomb disorder\narising from quenched random charged impurities in the environment, we show\nthat the 2D conductivity \\sigma(n) varies as \\sigma ~ n^{\\beta(n)} as a\nfunction of the 2D carrier density n where the exponent \\beta(n) is a smooth,\nbut non-monotonic, function of density with possible nontrivial extrema. In\nparticular, the density scaling exponent \\beta(n) depends qualitatively on\nwhether the Coulomb disorder arises primarily from remote or background charged\nimpurities or short-range disorder, and can, in principle, be used to\ncharacterize the nature of the dominant background disorder. A specific\nimportant prediction of the theory is that for resistive scattering by remote\ncharged impurities, the exponent \\beta can reach a value as large as 2.7 for\nk_F d ~ 1, where k_F ~\\sqrt{n} is the 2D Fermi wave vector and d is the\nseparation of the remote impurities from the 2D layer. Such an exponent \\beta\n(>5/2) is surprising because unscreened Coulomb scattering by remote impurities\ngives a limiting theoretical scaling exponent of \\beta = 5/2, and naively one\nwould expect \\beta(n) \\le 5/2 for all densities since unscreened Coulomb\nscattering should nominally be the situation bounding the resistive scattering\nfrom above. We find numerically and show theoretically that the maximum value\nof \\alpha (\\beta), the mobility (conductivity) exponent, for 2D semiconductor\nquantum wells is around 1.7 (2.7) for all values of d (and for both electrons\nand holes) with the maximum \\alpha occurring around k_F d ~ 1. We discuss\nexperimental scenarios for the verification of our theory. \n\n"}
{"id": "1304.7292", "contents": "Title: Excitation spectra from angular momentum projection of Hartree-Fock\n  states and the configuration-interaction shell-model Abstract: We make numerical comparison of spectra from angular-momentum projection on\nHartree-Fock states with spectra from configuration-interaction nuclear\nshell-model calculations, all carried out in the same model spaces (in this\ncase the sd, lower pf, and p-sd_5/2 shells) and using the same input\nHamiltonians. We find, unsurprisingly, that the low-lying excitation spectra\nfor rotational nuclides are well reproduced, but the spectra for vibrational\nnuclides, and more generally the complex specta for odd-A and odd-odd nuclides\nare less well reproduced in detail. \n\n"}
{"id": "1305.0824", "contents": "Title: The Observed Squeezed Limit of Cosmological Three-Point Functions Abstract: The squeezed limit of the three-point function of cosmological perturbations\nis a powerful discriminant of different models of the early Universe. We\npresent a conceptually simple and complete framework to relate any primordial\nbispectrum in this limit to late time observables, such as the CMB temperature\nbispectrum and the scale-dependent halo bias. We employ a series of convenient\ncoordinate transformations to capture the leading non-linear effects of\ncosmological perturbation theory on these observables. This makes crucial use\nof Fermi Normal Coordinates and their conformal generalization, which we\nintroduce here and discuss in detail. As an example, we apply our formalism to\nstandard slow-roll single-field inflation. We show explicitly that Maldacena's\nresults for the squeezed limits of the scalar bispectrum [proportional to\n(ns-1) in comoving gauge] and the tensor-scalar-scalar bispectrum lead to no\ndeviations from a Gaussian universe, except for projection effects. In\nparticular, the primordial contributions to the squeezed CMB bispectrum and\nscale dependent halo bias vanish, and there are no primordial \"fossil\"\ncorrelations between long-wavelength tensor perturbations and small-scale\nperturbations. The contributions to observed correlations are then only due to\nprojection effects such as gravitational lensing and redshift perturbations. \n\n"}
{"id": "1305.2719", "contents": "Title: Direct Dark Matter search with the XENON program Abstract: We present the most recent results from XENON100, the current phase of the\nXENON dark matter search program. XENON100 is a dual phase time-projection\nchamber operated at the Laboratori Nazionali del Gran Sasso (LNGS) whose\nultra-low electromagnetic background, about 5 x 10^-3 events/(kg x day x keV),\nallowed to set the most stringent limit to date, excluding WIMP-nucleon\nspin-independent interaction down to cross-sections of 2 x 10^-45 cm^2 for a 55\nGeV/c^2 mass at 90% confidence level and 3.5 x10^-40 for 45 GeV/c^2 in the\nspin-dependent interaction with neutrons. We also introduce the status and\nphysics goal of XENON1T, the next phase of the program, which will be able to\nachieve sensitivity down to 2 x 10^-47 cm^2 for a WIMP of 50 GeV/c^2. \n\n"}
{"id": "1305.2808", "contents": "Title: Recent status of the Dark Matter search with Edelweiss Abstract: The Edelweiss experiment uses Ge-bolometers with an improved background\nrejection (interleaved electrode design) to search for WIMP dark matter. The\nsetup is located in the underground laboratory, Laboratoire Souterrain de\nModane (LSM, France). In 2009-2010 the collaboration successfully operated ten\n400-g bolometers together with an active muon veto shielding. Published\nanalysis of this measurement campaign was optimized for WIMP masses above 50\nGeV. Recently, the analysis was extended to the low-mass WIMP region using a\nquality subset of the 2009-2010 data setting new limits on the spin-independent\nWIMP-nucleon scattering cross-section. We present the low-mass WIMP analysis,\nbackground investigations and the latest measurements with a subset of the\nforty 800-g detectors that will be installed for the Edelweiss-III. Ongoing\ninstallation works of the Edelweiss-III setup and further plans for a next\ngeneration experiment, EURECA, are discussed. \n\n"}
{"id": "1305.2811", "contents": "Title: Zooming towards the Event Horizon - mm-VLBI today and tomorrow Abstract: Global VLBI imaging at millimeter and sub-millimeter wavelength overcomes the\nopacity barrier of synchrotron self-absorption in AGN and opens the direct view\ninto sub-pc scale regions not accessible before. Since AGN variability is more\npronounced at short millimeter wavelength, mm-VLBI can reveal structural\nchanges in very early stages after outbursts. When combined with observations\nat longer wavelength, global 3mm and 1mm VLBI adds very detailed information.\nThis helps to determine fundamental physical properties at the jet base, and in\nthe vicinity of super-massive black holes at the center of AGN. Here we present\nnew results from multi-frequency mm-VLBI imaging of OJ287 during a major\noutburst. We also report on a successful 1.3mm VLBI experiment with the APEX\ntelescope in Chile. This observation sets a new record in angular resolution.\nIt also opens the path towards future mm-VLBI with ALMA, which aims at the\nmapping of the black hole event horizon in nearby galaxies, and the study of\nthe roots of jets in AGN. \n\n"}
{"id": "1305.3196", "contents": "Title: The stochastic background: scaling laws and time to detection for pulsar\n  timing arrays Abstract: We derive scaling laws for the signal-to-noise ratio of the optimal\ncross-correlation statistic, and show that the large power-law increase of the\nsignal-to-noise ratio as a function of the the observation time $T$ that is\nusually assumed holds only at early times. After enough time has elapsed,\npulsar timing arrays enter a new regime where the signal to noise only scales\nas $\\sqrt{T}$. In addition, in this regime the quality of the pulsar timing\ndata and the cadence become relatively un-important. This occurs because the\nlowest frequencies of the pulsar timing residuals become gravitational-wave\ndominated. Pulsar timing arrays enter this regime more quickly than one might\nnaively suspect. For T=10 yr observations and typical stochastic background\namplitudes, pulsars with residual RMSs of less than about $1\\,\\mu$s are already\nin that regime. The best strategy to increase the detectability of the\nbackground in this regime is to increase the number of pulsars in the array. We\nalso perform realistic simulations of the NANOGrav pulsar timing array, which\nthrough an aggressive pulsar survey campaign adds new millisecond pulsars\nregularly to its array, and show that a detection is possible within a decade,\nand could occur as early as 2016. \n\n"}
{"id": "1305.3463", "contents": "Title: Constraints on Lorentz Invariance Violation from Fermi-Large Area\n  Telescope Observations of Gamma-Ray Bursts Abstract: We analyze the MeV/GeV emission from four bright Gamma-Ray Bursts (GRBs)\nobserved by the Fermi-Large Area Telescope to produce robust, stringent\nconstraints on a dependence of the speed of light in vacuo on the photon energy\n(vacuum dispersion), a form of Lorentz invariance violation (LIV) allowed by\nsome Quantum Gravity (QG) theories. First, we use three different and\ncomplementary techniques to constrain the total degree of dispersion observed\nin the data. Additionally, using a maximally conservative set of assumptions on\npossible source-intrinsic spectral-evolution effects, we constrain any vacuum\ndispersion solely attributed to LIV. We then derive limits on the \"QG energy\nscale\" (the energy scale that LIV-inducing QG effects become important, E_QG)\nand the coefficients of the Standard Model Extension. For the subluminal case\n(where high energy photons propagate more slowly than lower energy photons) and\nwithout taking into account any source-intrinsic dispersion, our most stringent\nlimits (at 95% CL) are obtained from GRB090510 and are E_{QG,1}>7.6 times the\nPlanck energy (E_Pl) and E_{QG,2}>1.3 x 10^11 GeV for linear and quadratic\nleading order LIV-induced vacuum dispersion, respectively. These limits improve\nthe latest constraints by Fermi and H.E.S.S. by a factor of ~2. Our results\ndisfavor any class of models requiring E_{QG,1} \\lesssim E_Pl. \n\n"}
{"id": "1305.4613", "contents": "Title: A Maximum Likelihood Approach to Estimating Correlation Functions Abstract: We define a Maximum Likelihood (ML for short) estimator for the correlation\nfunction, {\\xi}, that uses the same pair counting observables (D, R, DD, DR,\nRR) as the standard Landy and Szalay (1993, LS for short) estimator. The ML\nestimator outperforms the LS estimator in that it results in smaller\nmeasurement errors at any fixed random point density. Put another way, the ML\nestimator can reach the same precision as the LS estimator with a significantly\nsmaller random point catalog. Moreover, these gains are achieved without\nsignificantly increasing the computational requirements for estimating {\\xi}.\nWe quantify the relative improvement of the ML estimator over the LS estimator,\nand discuss the regimes under which these improvements are most significant. We\npresent a short guide on how to implement the ML estimator, and emphasize that\nthe code alterations required to switch from a LS to a ML estimator are\nminimal. \n\n"}
{"id": "1305.6923", "contents": "Title: How to Zoom: Bias, Contamination, and Lagrange Volumes in Multimass\n  Cosmological Simulations Abstract: We perform a suite of multimass cosmological zoom simulations of individual\ndark matter halos and explore how to best select Lagrangian regions for\nresimulation without contaminating the halo of interest with low-resolution\nparticles. Such contamination can lead to significant errors in the gas\ndistribution of hydrodynamical simulations, as we show. For a fixed Lagrange\nvolume, we find that the chance of contamination increases systematically with\nthe level of zoom. In order to avoid contamination, the Lagrangian volume\nselected for resimulation must increase monotonically with the resolution\ndifference between parent box and the zoom region. We provide a simple formula\nfor selecting Lagrangian regions (in units of the halo virial volume) as a\nfunction of the level of zoom required. We also explore the degree to which a\nhalo's Lagrangian volume correlates with other halo properties (concentration,\nspin, formation time, shape, etc.) and find no significant correlation. There\nis a mild correlation between Lagrange volume and environment, such that halos\nliving in the most clustered regions have larger Lagrangian volumes.\nNevertheless, selecting halos to be isolated is not the best way to ensure\ninexpensive zoom simulations. We explain how one can safely choose halos with\nthe smallest Lagrangian volumes, which are the least expensive to resimulate,\nwithout biasing one's sample. \n\n"}
{"id": "1305.6928", "contents": "Title: Cosmology on Ultralarge Scales with Intensity Mapping of the Neutral\n  Hydrogen 21 cm Emission: Limits on Primordial Non-Gaussianity Abstract: The large-scale structure of the Universe supplies crucial information about\nthe physical processes at play at early times. Unresolved maps of the intensity\nof 21 cm emission from neutral hydrogen HI at redshifts z~1-5 are the best hope\nof accessing the ultralarge-scale information, directly related to the early\nUniverse. A purpose-built HI intensity experiment may be used to detect the\nlarge scale effects of primordial non-Gaussianity, placing stringent bounds on\ndifferent models of inflation. We argue that it may be possible to place tight\nconstraints on the non-Gaussianity parameter f_NL, with an error close to ~1. \n\n"}
{"id": "1306.0758", "contents": "Title: Some irreducibility results for truncated binomial expansions Abstract: For positive integers $n>k$, let $P_{n,k}(x)=\\displaystyle\\sum_{j=0}^k\n\\binom{n}{j}x^j $ be the polynomial obtained by truncating the binomial\nexpansion of $(1+x)^n$ at the $k^{th}$ stage. These polynomials arose in the\ninvestigation of Schubert calculus in Grassmannians. In this paper, the authors\nprove the irreducibility of $P_{n,k}(x)$ over the field of rational numbers\nwhen $2\\leqslant 2k \\leqslant n<(k+1)^3$. \n\n"}
{"id": "1306.0774", "contents": "Title: Extreme-mass-ratio-bursts from extragalactic sources Abstract: Extreme-mass-ratio bursts (EMRBs) are a class of potentially interesting\ngravitational wave signals. They are produced when a compact object passes\nthrough periapsis on a highly eccentric orbit about a much more massive object;\nwe consider stellar mass objects orbiting the massive black holes (MBHs) found\nin galactic centres. Such a system may emit many EMRBs before eventually\ncompleting the inspiral. There are several nearby galaxies that could yield\ndetectable bursts. For a space-borne interferometer like the Laser\nInterferometer Space Antenna, sensitivity is greatest for EMRBs from MBHs of\n~10^6-10^7 solar masses, which could be detected out to ~100 Mpc. Considering\nthe examples of M32, NGC 4945 and NGC 4395 we investigate if extragalactic EMRB\nsignals can provide information about their sources. This is possible, but only\nif the periapse radius of the orbit is small, of the order of r_p < 8 r_g,\nwhere r_g = GM/c^2 is the gravitational radius of the MBH. This limits the\nutility of EMRBs as an astronomical tool. However, if we are lucky, we could\nplace constraints on the mass and spin of nearby MBHs with 1% precision. \n\n"}
{"id": "1306.3526", "contents": "Title: A lack of short-period multiplanet systems with close-proximity pairs\n  and the curious case of Kepler 42 Abstract: Many Kepler multiplanet systems have planet pairs near low-order, mean-motion\nresonances. In addition, many Kepler multiplanet systems have planets with\norbital periods less than a few days. With the exception of Kepler-42, however,\nthere are no examples of systems with both short orbital periods and nearby\ncompanion planets while our statistical analysis predicts ~17 such pairs. For\norbital periods of the inner planet that are less than three days, the minimum\nperiod ratio of adjacent planet pairs follows the rough constraint P_2/P_1 >~\n2.3 (P_1/day)^(-2/3). This absence is not due to a lack of planets with short\norbital periods. We also show a statistically significant excess of small,\nsingle candidate systems with orbital periods below 3 days over the number of\nmultiple candidate systems with similar periods---perhaps a small-planet\ncounterpart to the hot Jupiters. \n\n"}
{"id": "1306.4968", "contents": "Title: The ALHAMBRA Survey: Bayesian Photometric Redshifts with 23 bands for 3\n  squared degrees Abstract: The ALHAMBRA (Advance Large Homogeneous Area Medium Band Redshift\nAstronomical) survey has observed 8 different regions of the sky, including\nsections of the COSMOS, DEEP2, ELAIS, GOODS-N, SDSS and Groth fields using a\nnew photometric system with 20 contiguous ~ $300\\AA$ filters covering the\noptical range, combining them with deep $JHKs$ imaging. The observations,\ncarried out with the Calar Alto 3.5m telescope using the wide field (0.25 sq.\ndeg FOV) optical camera LAICA and the NIR instrument Omega-2000, correspond to\n~700hrs on-target science images. The photometric system was designed to\nmaximize the effective depth of the survey in terms of accurate spectral-type\nand photo-zs estimation along with the capability of identification of\nrelatively faint emission lines. Here we present multicolor photometry and\nphoto-zs for ~438k galaxies, detected in synthetic F814W images, complete down\nto I~24.5 AB, taking into account realistic noise estimates, and correcting by\nPSF and aperture effects with the ColorPro software. The photometric ZP have\nbeen calibrated using stellar transformation equations and refined internally,\nusing a new technique based on the highly robust photometric redshifts measured\nfor emission line galaxies. We calculate photometric redshifts with the BPZ2\ncode, which includes new empirically calibrated templates and priors. Our\nphoto-zs have a precision of $dz/(1+z_s)=1%$ for I<22.5 and 1.4% for\n22.5<I<24.5. Precisions of less than 0.5% are reached for the brighter\nspectroscopic sample, showing the potential of medium-band photometric surveys.\nThe global $P(z)$ shows a mean redshift <z>=0.56 for I<22.5 AB and <z>=0.86 for\nI<24.5 AB. The data presented here covers an effective area of 2.79 sq. deg,\nsplit into 14 strips of 58.5'x15.5' and represents ~32 hrs of on-target. \n\n"}
{"id": "1306.5236", "contents": "Title: Star/galaxy separation at faint magnitudes: Application to a simulated\n  Dark Energy Survey Abstract: We address the problem of separating stars from galaxies in future large\nphotometric surveys. We focus our analysis on simulations of the Dark Energy\nSurvey (DES). In the first part of the paper, we derive the science\nrequirements on star/galaxy separation, for measurement of the cosmological\nparameters with the Gravitational Weak Lensing and Large Scale Structure\nprobes. These requirements are dictated by the need to control both the\nstatistical and systematic errors on the cosmological parameters, and by Point\nSpread Function calibration. We formulate the requirements in terms of the\ncompleteness and purity provided by a given star/galaxy classifier. In order to\nachieve these requirements at faint magnitudes, we propose a new method for\nstar/galaxy separation in the second part of the paper. We first use Principal\nComponent Analysis to outline the correlations between the objects parameters\nand extract from it the most relevant information. We then use the reduced set\nof parameters as input to an Artificial Neural Network. This multi-parameter\napproach improves upon purely morphometric classifiers (such as the classifier\nimplemented in SExtractor), especially at faint magnitudes: it increases the\npurity by up to 20% for stars and by up to 12% for galaxies, at i-magnitude\nfainter than 23. \n\n"}
{"id": "1307.0016", "contents": "Title: The Cosmic Infrared Background Experiment (CIBER): the Narrow Band\n  Spectrometer Abstract: We have developed a near-infrared spectrometer designed to measure the\nabsolute intensity of the Solar 854.2 nm CaII Fraunhofer line, scattered by\ninterplanetary dust, in the Zodiacal light spectrum. Based on the known\nequivalent line width in the Solar spectrum, this measurement can derive the\nZodiacal brightness, testing models of the Zodiacal light based on morphology\nthat are used to determine the extragalactic background light in absolute\nphotometry measurements. The spectrometer is based on a simple high-resolution\ntipped filter placed in front of a compact camera with wide-field refractive\noptics to provide the large optical throughput and high sensitivity required\nfor rocket-borne observations. We discuss the instrument requirements for an\naccurate measurement of the absolute Zodiacal light brightness, the measured\nlaboratory characterization, and the instrument performance in flight. \n\n"}
{"id": "1307.0562", "contents": "Title: Resolving galaxies in time and space: II: Uncertainties in the spectral\n  synthesis of datacubes Abstract: In a companion paper we have presented many products derived from the\napplication of the spectral synthesis code STARLIGHT to datacubes from the\nCALIFA survey, including 2D maps of stellar population properties and 1D\naverages in the temporal and spatial dimensions. Here we evaluate the\nuncertainties in these products. Uncertainties due to noise and spectral shape\ncalibration errors and to the synthesis method are investigated by means of a\nsuite of simulations based on 1638 CALIFA spectra for NGC 2916, with\nperturbations amplitudes gauged in terms of the expected errors. A separate\nstudy was conducted to assess uncertainties related to the choice of\nevolutionary synthesis models. We compare results obtained with the Bruzual &\nCharlot models, a preliminary update of them, and a combination of spectra\nderived from the Granada and MILES models. About 100k CALIFA spectra are used\nin this comparison.\n  Noise and shape-related errors at the level expected for CALIFA propagate to\n0.10-0.15 dex uncertainties in stellar masses, mean ages and metallicities.\nUncertainties in A_V increase from 0.06 mag in the case of random noise to 0.16\nmag for shape errors. Higher order products such as SFHs are more uncertain,\nbut still relatively stable. Due to the large number statistics of datacubes,\nspatial averaging reduces uncertainties while preserving information on the\nhistory and structure of stellar populations. Radial profiles of global\nproperties, as well as SFHs averaged over different regions are much more\nstable than for individual spaxels. Uncertainties related to the choice of base\nmodels are larger than those associated with data and method. Differences in\nmean age, mass and metallicity are ~ 0.15 to 0.25 dex, and 0.1 mag in A_V.\nSpectral residuals are ~ 1% on average, but with systematic features of up to\n4%. The origin of these features is discussed. (Abridged) \n\n"}
{"id": "1307.0652", "contents": "Title: Efficiently Extracting Energy from Cosmological Neutrinos Abstract: Detecting the extremely low-energy neutrinos that form the Cosmic Neutrino\nBackground (CNB) presents many experimental challenges, but pursuing this\nelusive goal is still worthwhile because these weakly-interacting particles\ncould provide a new window into the structure and composition of the early\nuniverse. This report examines whether cosmological neutrinos can deposit\nsufficient energy into a target system to be detectable with plausible\nextensions of current bolometric technologies. While the macroscopic\nwavelengths of cosmological neutrinos can greatly enhance their cross sections\nwith dense targets, such interactions can only be detectable if they transfer a\nsignificant fraction of each neutrino's kinetic energy into the detector\nsystem. We find that a large array of dense target masses coupled to suitable\nmotion-sensitive circuits could potentially satisfy both of these conditions\nand thus might be able to serve as the basis for a more practical cosmological\nneutrino detector. \n\n"}
{"id": "1307.1002", "contents": "Title: Variational optimization of the 2DM: approaching three-index accuracy\n  using extended cluster constraints Abstract: The reduced density matrix is variationally optimized for the two-dimensional\nHubbard model. Exploiting all symmetries present in the system, we have been\nable to study $6\\times6$ lattices at various fillings and different values for\nthe on-site repulsion, using the highly accurate but computationally expensive\nthree-index conditions. To reduce the computational cost we study the\nperformance of imposing the three-index constraints on local clusters of\n$2\\times2$ and $3\\times3$ sites. We subsequently derive new constraints which\nextend these cluster constraints to incorporate the open-system nature of a\ncluster on a larger lattice. The feasibility of implementing these new\nconstraints is demonstrated by performing a proof-of-principle calculation on\nthe $6\\times6$ lattice. It is shown that a large portion of the three-index\nresult can be recovered using these extended cluster constraints, at a fraction\nof the computational cost. \n\n"}
{"id": "1307.3684", "contents": "Title: Understanding black hole mass assembly via accretion and mergers at late\n  times in cosmological simulations Abstract: Accretion is thought to primarily contribute to the mass accumulation history\nof supermassive black holes throughout cosmic time. While this may be true at\nhigh redshifts, at lower redshifts and for the most massive black holes mergers\nthemselves might add significantly to the mass budget. We evolve SMBHs from $4\n> z > 0$ using merger trees derived from hydrodynamical cosmological\nsimulations of a cluster and void region, scaled to the observed value of the\nstellar mass fraction to account for overcooling. Mass gains from gas accretion\nproportional to bulge growth and BH-BH mergers are tracked, as are black holes\nthat remain \"orbiting\" due to insufficient dynamical friction in a merger\nremnant, as well as those that are ejected due to gravitational recoil. We find\nthat gas accretion remains the dominant source of mass accumulation in almost\nall SMBHs; mergers contribute $2.5\\pm0.1\\%$ for all SMBHs in the cluster and\n$1.0\\pm0.1\\%$ in the void since $z = 4$. However, mergers are significant for\nmassive SMBHs. The fraction of mass accumulated from mergers for central BHs\ngenerally increases for larger values of the host bulge mass: in the void, the\nfraction is $2\\%$ at $M_{*, bul} = 10^{10} M_{\\odot}$, increasing to $4\\%$ at\n$M_{*, bul} \\gtrsim 10^{11} M_{\\odot}$, and in the cluster it is $4\\%$ at\n$M_{*, bul} = 10^{10} M_{\\odot}$ and $23\\%$ at $10^{12} M_{\\odot}$. We find\nthat $40\\%$ of SMBHs and $\\approx 8\\%$ of the total SMBH mass is found orbiting\nin the cluster region at $z = 0$. The existence of orbiting and ejected SMBHs\nrequires modification of the Soltan argument. We estimate this correction to\nthe integrated accreted mass density of SMBHs to be in the range $6-21\\%$, with\na mean value of $11\\pm3\\%$. We also calculate the total energy output and\nstrain from gravitational waves emitted by merging SMBHs, and obtain a signal\npotentially detectable by pulsar timing arrays. \n\n"}
{"id": "1307.3884", "contents": "Title: Fast and precise way to calculate the posterior for the local\n  non-Gaussianity parameter $f_\\text{nl}$ from cosmic microwave background\n  observations Abstract: We present an approximate calculation of the full Bayesian posterior\nprobability distribution for the local non-Gaussianity parameter\n$f_{\\text{nl}}$ from observations of cosmic microwave background anisotropies\nwithin the framework of information field theory. The approximation that we\nintroduce allows us to dispense with numerically expensive sampling techniques.\nWe use a novel posterior validation method (DIP test) in cosmology to test the\nprecision of our method. It transfers inaccuracies of the calculated posterior\ninto deviations from a uniform distribution for a specially constructed test\nquantity. For this procedure we study toy cases that use one- and\ntwo-dimensional flat skies, as well as the full spherical sky. We find that we\nare able to calculate the posterior precisely under a flat-sky approximation,\nalbeit not in the spherical case. We argue that this is most likely due to an\ninsufficient precision of the used numerical implementation of the spherical\nharmonic transform, which might affect other non-Gaussianity estimators as\nwell. Furthermore, we present how a nonlinear reconstruction of the primordial\ngravitational potential on the full spherical sky can be obtained in principle.\nUsing the flat-sky approximation, we find deviations for the posterior of\n$f_{\\text{nl}}$ from a Gaussian shape that become more significant for larger\nvalues of the underlying true $f_{\\text{nl}}$. We also perform a comparison to\nthe well-known estimator of Komatsu et al. [Astrophys. J. 634, 14 (2005)] and\nfinally derive the posterior for the local non-Gaussianity parameter\n$g_{\\text{nl}}$ as an example of how to extend the introduced formalism to\nhigher orders of non-Gaussianity. \n\n"}
{"id": "1307.5375", "contents": "Title: Interplanetary spacecraft navigation using pulsars Abstract: We demonstrate how observations of pulsars can be used to help navigate a\nspacecraft travelling in the solar system. We make use of archival observations\nof millisecond pulsars from the Parkes radio telescope in order to demonstrate\nthe effectiveness of the method and highlight issues, such as pulsar spin\nirregularities, which need to be accounted for. We show that observations of\nfour millisecond pulsars every seven days using a realistic X-ray telescope on\nthe spacecraft throughout a journey from Earth to Mars can lead to position\ndeterminations better than approx. 20km and velocity measurements with a\nprecision of approx. 0.1m/s. \n\n"}
{"id": "1307.5580", "contents": "Title: The brightness and spatial distributions of terrestrial radio sources Abstract: Faint undetected sources of radio-frequency interference (RFI) might become\nvisible in long radio observations when they are consistently present over\ntime. Thereby, they might obstruct the detection of the weak astronomical\nsignals of interest. This issue is especially important for Epoch of\nReionisation (EoR) projects that try to detect the faint redshifted HI signals\nfrom the time of the earliest structures in the Universe. We explore the RFI\nsituation at 30-163 MHz by studying brightness histograms of visibility data\nobserved with LOFAR, similar to radio-source-count analyses that are used in\ncosmology. An empirical RFI distribution model is derived that allows the\nsimulation of RFI in radio observations. The brightness histograms show an RFI\ndistribution that follows a power-law distribution with an estimated exponent\naround -1.5. With several assumptions, this can be explained with a uniform\ndistribution of terrestrial radio sources whose radiation follows existing\npropagation models. Extrapolation of the power law implies that the current\nLOFAR EoR observations should be severely RFI limited if the strength of RFI\nsources remains strong after time integration. This is in contrast with actual\nobservations, which almost reach the thermal noise and are thought not to be\nlimited by RFI. Therefore, we conclude that it is unlikely that there are\nundetected RFI sources that will become visible in long observations.\nConsequently, there is no indication that RFI will prevent an EoR detection\nwith LOFAR. \n\n"}
{"id": "1307.5851", "contents": "Title: Discovery and redshift of an optical afterglow in 71 square degrees:\n  iPTF13bxl and GRB 130702A Abstract: We report the discovery of the optical afterglow of the gamma-ray burst (GRB)\n130702A, identified upon searching 71 square degrees surrounding the Fermi\nGamma-ray Burst Monitor (GBM) localization. Discovered and characterized by the\nintermediate Palomar Transient Factory (iPTF), iPTF13bxl is the first afterglow\ndiscovered solely based on a GBM localization. Real-time image subtraction,\nmachine learning, human vetting, and rapid response multi-wavelength follow-up\nenabled us to quickly narrow a list of 27,004 optical transient candidates to a\nsingle afterglow-like source. Detection of a new, fading X-ray source by Swift\nand a radio counterpart by CARMA and the VLA confirmed the association between\niPTF13bxl and GRB 130702A. Spectroscopy with the Magellan and Palomar 200-inch\ntelescopes showed the afterglow to be at a redshift of z=0.145, placing GRB\n130702A among the lowest redshift GRBs detected to date. The prompt gamma-ray\nenergy release and afterglow luminosity are intermediate between typical\ncosmological GRBs and nearby sub-luminous events such as GRB 980425 and GRB\n060218. The bright afterglow and emerging supernova offer an opportunity for\nextensive panchromatic follow-up. Our discovery of iPTF13bxl demonstrates the\nfirst observational proof-of-principle for ~10 Fermi-iPTF localizations\nannually. Furthermore, it represents an important step towards overcoming the\nchallenges inherent in uncovering faint optical counterparts to comparably\nlocalized gravitational wave events in the Advanced LIGO and Virgo era. \n\n"}
{"id": "1307.6090", "contents": "Title: An improved upper limit to the CMB circular polarization at large\n  angular scales Abstract: Circular polarization of the Cosmic Microwave Background (CMB) offers the\npossibility of detecting rotations of the universe and magnetic fields in the\nprimeval universe or in distant clusters of galaxies. We used the Milano\nPolarimeter (MIPOL) installed at the Testa Grigia Observatory, on the italian\nAlps, to improve the existing upper limits to the CMB circular polarization at\nlarge angular scales. We obtain 95% confidence level upper limits to the degree\nof the CMB circular polarization ranging between 5.0x10^{-4} and 0.7x10^{-4} at\nangular scales between 8 and 24 deg, improving by one order of magnitude\npreexisting upper limits at large angular scales. Our results are still far\nfrom the nK region where today expectations place the amplitude of the V Stokes\nparameter used to characterize circular polarization of the CMB but improve the\npreexisting limit at similar angular scales. Our observations offered also the\nopportunity of characterizing the atmospheric emission at 33 GHz at the Testa\nGrigia Observatory. \n\n"}
{"id": "1307.6150", "contents": "Title: Seeding supermassive black holes with a non-vortical dark-matter\n  subcomponent Abstract: A perfect irrotational fluid with the equation of state of dust, Irrotational\nDark Matter (IDM), is incapable of virializing and instead forms a\ncosmoskeleton of filaments with supermassive black holes at the joints. This\nstark difference from the standard cold dark matter (CDM) scenario arises\nbecause IDM must exhibit potential flow at all times, preventing shell-crossing\nfrom occurring. This scenario is applicable to general non-oscillating\nscalar-field theories with a small sound speed. Our model of combined IDM and\nCDM components thereby provides a solution to the problem of forming the\nobserved billion-solar-mass black holes at redshifts of six and higher. In\nparticular, as a result of the reduced vortical flow, the growth of the black\nholes is expected to be more rapid at later times as compared to the standard\nscenario. \n\n"}
{"id": "1307.7716", "contents": "Title: A Flux Scale for Southern Hemisphere 21cm EoR Experiments Abstract: We present a catalog of spectral measurements covering a 100-200 MHz band for\n32 sources, derived from observations with a 64-antenna deployment of the\nDonald C. Backer Precision Array for Probing the Epoch of Reionization (PAPER)\nin South Africa. For transit telescopes such as PAPER, calibration of the\nprimary beam is a difficult endeavor, and errors in this calibration are a\nmajor source of error in the determination of source spectra. In order to\ndecrease reliance on accurate beam calibration, we focus on calibrating sources\nin a narrow declination range from -46d to -40d. Since sources at similar\ndeclinations follow nearly identical paths through the primary beam, this\nrestriction greatly reduces errors associated with beam calibration, yielding a\ndramatic improvement in the accuracy of derived source spectra. Extrapolating\nfrom higher frequency catalogs, we derive the flux scale using a Monte-Carlo\nfit across multiple sources that includes uncertainty from both catalog and\nmeasurement errors. Fitting spectral models to catalog data and these new PAPER\nmeasurements, we derive new flux models for Pictor A and 31 other sources at\nnearby declinations. 90% of these confirm and refine a power-law model for flux\ndensity. Of note is the new Pictor A flux model, which is accurate to 1.4% and\nshows, in contrast to previous models, that between 100 MHz and 2 GHz, the\nspectrum of Pictor A is consistent with a single power law given by a flux at\n150 MHz of 382+/-5.4 Jy, and a spectral index of -0.76+/-0.01. This accuracy\nrepresents an order of magnitude improvement over previous measurements in this\nband, and is limited by the uncertainty in the catalog measurements used to\nestimate the absolute flux scale. The simplicity and improved accuracy of\nPictor A's spectrum make it an excellent calibrator for experiments seeking to\nmeasure 21cm emission from the Epoch of Reionization. \n\n"}
{"id": "1308.0034", "contents": "Title: Robustness of partially interdependent network formed of clustered\n  networks Abstract: Clustering, or transitivity has been observed in real networks and its\neffects on their structure and function has been discussed extensively. The\nfocus of these studies has been on clustering of single networks while the\neffect of clustering on the robustness of coupled networks received very little\nattention. Only the case of a pair of fully coupled networks with clustering\nhas been studied recently. Here we generalize the study of clustering of a\nfully coupled pair of networks to the study of partially interdependent network\nof networks with clustering within the network components. We show both\nanalytically and numerically, how clustering within the networks, affects the\npercolation properties of interdependent networks, including percolation\nthreshold, size of giant component and critical coupling point where first\norder phase transition changes to second order phase transition as the coupling\nbetween the networks reduces. We study two types of clustering: one type\nproposed by Newman where the average degree is kept constant while changing the\nclustering and the other proposed by Hackett $et$ $al.$ where the degree\ndistribution is kept constant. The first type of clustering is treated both\nanalytically and numerically while the second one is treated only numerically. \n\n"}
{"id": "1308.0602", "contents": "Title: Sparse Inpainting and Isotropy Abstract: Sparse inpainting techniques are gaining in popularity as a tool for\ncosmological data analysis, in particular for handling data which present\nmasked regions and missing observations. We investigate here the relationship\nbetween sparse inpainting techniques using the spherical harmonic basis as a\ndictionary and the isotropy properties of cosmological maps, as for instance\nthose arising from cosmic microwave background (CMB) experiments. In\nparticular, we investigate the possibility that inpainted maps may exhibit\nanisotropies in the behaviour of higher-order angular polyspectra. We provide\nanalytic computations and simulations of inpainted maps for a Gaussian\nisotropic model of CMB data, suggesting that the resulting angular trispectrum\nmay exhibit small but non-negligible deviations from isotropy. \n\n"}
{"id": "1308.0847", "contents": "Title: The DESI Experiment, a whitepaper for Snowmass 2013 Abstract: The Dark Energy Spectroscopic Instrument (DESI) is a massively multiplexed\nfiber-fed spectrograph that will make the next major advance in dark energy in\nthe timeframe 2018-2022. On the Mayall telescope, DESI will obtain spectra and\nredshifts for at least 18 million emission-line galaxies, 4 million luminous\nred galaxies and 3 million quasi-stellar objects, in order to: probe the\neffects of dark energy on the expansion history using baryon acoustic\noscillations (BAO), measure the gravitational growth history through\nredshift-space distortions, measure the sum of neutrino masses, and investigate\nthe signatures of primordial inflation. The resulting 3-D galaxy maps at z<2\nand Lyman-alpha forest at z>2 will make 1%-level measurements of the distance\nscale in 35 redshift bins, thus providing unprecedented constraints on\ncosmological models. \n\n"}
{"id": "1308.4150", "contents": "Title: Damn You, Little h! (or, Real-World Applications Of The Hubble Constant\n  Using Observed And Simulated Data) Abstract: The Hubble constant, H0, or its dimensionless equivalent, \"little h\", is a\nfundamental cosmological property that is now known to an accuracy better than\na few percent. Despite its cosmological nature, little h commonly appears in\nthe measured properties of individual galaxies. This can pose unique challenges\nfor users of such data, particularly with survey data. In this paper we show\nhow little h arises in the measurement of galaxies, how to compare\nlike-properties from different datasets that have assumed different little h\ncosmologies, and how to fairly compare theoretical data with observed data,\nwhere little h can manifest in vastly different ways. This last point is\nparticularly important when observations are used to calibrate galaxy formation\nmodels, as calibrating with the wrong (or no) little h can lead to disastrous\nresults when the model is later converted to the correct h cosmology. We argue\nthat in this modern age little h is an anachronism, being one of least\nuncertain parameters in astrophysics, and we propose that observers and\ntheorists instead treat this uncertainty like any other. We conclude with a\n\"cheat sheet\" of nine points that should be followed when dealing with little h\nin data analysis. \n\n"}
{"id": "1308.4855", "contents": "Title: Weak Lensing by Intergalactic Mini-Structures in Quadruple Lens Systems:\n  Simulation and Detection Abstract: We investigate the weak lensing effects of line-of-sight structures on\nquadruple images in quasar-galaxy strong lens systems based on N-body and\nray-tracing simulations that can resolve halos with a mass of 10^5 solar mass.\nThe intervening halos and voids disturb the magnification ratios of lensed\nimages as well as their relative positions due to lensing. The magnification\nratios typically change by O(10%) when the shifts of relative angular positions\nof lensed images are constrained to <0.004 arcsec. The constrained amplitudes\nof projected density perturbations due to line-of-sight structures are O(10^8)\nsolar mass per arcsec^2. These results are consistent with our new analytical\nestimate based on the two-point correlation of density fluctuations. The\nobserved mid-infrared (MIR) flux ratios for 6 quasar-galaxy lens systems with\nquadruple images agree well with the numerically estimated values without\ntaking into account of subhalos residing in the lensing galaxies. We find that\nthe constrained mean amplitudes of projected density perturbations in the\nline-of-sight are negative, which suggests that the fluxes of lensed images are\nperturbed mainly by minivoids and minihalos in underdense regions. We derive a\nnew fitting formula for estimating the probability distribution function of\nmagnification perturbation. We also find that the mean amplitude of\nmagnification perturbation roughly equals the standard deviation regardless of\nthe model parameters. \n\n"}
{"id": "1308.5480", "contents": "Title: Flaglets for studying the large-scale structure of the Universe Abstract: Pressing questions in cosmology such as the nature of dark matter and dark\nenergy can be addressed using large galaxy surveys, which measure the\npositions, properties and redshifts of galaxies in order to map the large-scale\nstructure of the Universe. We review the Fourier-Laguerre transform, a novel\ntransform in 3D spherical coordinates which is based on spherical harmonics\ncombined with damped Laguerre polynomials and appropriate for analysing galaxy\nsurveys. We also recall the construction of flaglets, 3D wavelets obtained\nthrough a tiling of the Fourier-Laguerre space, which can be used to extract\nscale-dependent, spatially localised features on the ball. We exploit a\nsampling theorem to obtain exact Fourier-Laguerre and flaglet transforms, such\nthat band-limited signals can analysed and reconstructed at floating point\naccuracy on a finite number of voxels on the ball. We present a potential\napplication of the flaglet transform for finding voids in galaxy surveys and\nstudying the large-scale structure of the Universe. \n\n"}
{"id": "1308.5733", "contents": "Title: Polarization of GRB Prompt Emission Abstract: We review the recent observational results of the gamma-ray linear\npolarization of Gamma-Ray Bursts (GRBs), and discuss some theoretical\nimplications for the prompt emission mechanism and the magnetic composition of\nGRB jets. We also report a strict observational verification of CPT invariance\nin the photon sector as a result of the GRB polarization measurements. \n\n"}
{"id": "1308.6403", "contents": "Title: Constraints on Lorentz Invariance Violation with Fermi-LAT Observations\n  of Gamma-Ray Bursts Abstract: Some Quantum Gravity (QG) theories allow for a violation of Lorentz\ninvariance (LIV), manifesting as a dependence of the velocity of light in\nvacuum on its energy. If such a dependence exists, then photons of different\nenergies emitted together by a distant source will arrive at the Earth at\ndifferent times. High-energy (GeV) transient emissions from distant\nastrophysical sources such as Gamma-ray Bursts (GRBs) and Active Galaxy Nuclei\ncan be used to search for and constrain LIV. The Fermi collaboration has\npreviously analyzed two GRBs in order to put constraints on the dispersion\nparameter in vacuum, and on the energy scale at which QG effects causing LIV\nmay arise. We used three different methods on four bright GRBs observed by the\nFermi-LAT to get more stringent and robust constraints. No delays have been\ndetected and strong limits on the QG energy scale are derived: for linear\ndispersion we set tight constraints placing the QG energy scale above the\nPlanck mass; a quadratic leading LIV effect is also constrained. \n\n"}
{"id": "1309.1691", "contents": "Title: Modelling the X-ray polarimetric signatures of complex geometry: the\n  case study of the \"changing look\" AGN NGC 1365 Abstract: \"Changing look\" Active Galactic Nuclei (AGN) are a subset of Seyfert galaxies\ncharacterized by rapid transitions between Compton-thin and Compton-thick\nregimes. In their Compton-thin state, the central engine is less obscured,\nhence spectroscopy or timing observations can probe their innermost structures.\nHowever, it is not clear if the observed emission features and the Compton hump\nare associated with relativistic reflection onto the accretion disc, or complex\nabsorption by distant, absorbing gas clouds passing by the observer's\nline-of-sight. Here, we investigate these two scenarios under the scope of\nX-ray polarimetry, providing the first polarisation predictions for an\narchetypal \"changing look\" AGN: NGC 1365. We explore the resulting polarisation\nemerging from lamp-post emission and scattering off an accretion disc in the\nimmediate vicinity of a supermassive black hole. The computed polarisation\nsignatures are compared to the results of an absorption-dominated model, where\nhigh column density gas partially covers the central source. While the shape of\nthe polarisation spectrum is similar, the two models differ in net polarisation\npercentage, with the relativistic reflection scenario producing significantly\nstronger polarisation. Additionally, the variation of the polarisation position\nangle is distinctly different between both scenarios: the reflection-dominated\nmodel produces smooth rotations of the polarisation angle with photon energy\nwhereas circumnuclear absorption causes an orthogonal switch of the\npolarisation angle between the soft and the hard X-ray bands. By comparing the\npredicted polarisation of NGC 1365 to the detectability levels of X-ray\npolarimetry mission concepts proposed in the past, we demonstrate that with a\nlarge, soft X-ray observatory or a medium-sized mission equipped with a hard (6\n- 35 keV) polarimeter, the correct interpretation would be unambiguous. \n\n"}
{"id": "1309.1831", "contents": "Title: Supermassive black hole mergers as dual sources for electromagnetic\n  flares in the jet emission and gravitational waves Abstract: We present a new type of observation relating the gravitational wave emission\nof supermassive black hole mergers to their electromagnetic counterparts. This\ndual emission involves variability of a relativistic jet arising from the\nspin-orbit precession of the supermassive black hole binary at its base. \n\n"}
{"id": "1309.2942", "contents": "Title: Galaxy mergers on a moving mesh: a comparison with smoothed-particle\n  hydrodynamics Abstract: Galaxy mergers have been investigated for decades using smoothed particle\nhydrodynamics (SPH), but recent work highlighting inaccuracies inherent in the\ntraditional SPH technique calls into question the reliability of previous\nstudies. We explore this issue by comparing a suite of Gadget-3 SPH simulations\nof idealised (i.e., non-cosmological) isolated discs and galaxy mergers with\notherwise identical calculations performed using the moving-mesh code Arepo.\nWhen black hole (BH) accretion and active galactic nucleus (AGN) feedback are\nnot included, the star formation histories (SFHs) obtained from the two codes\nagree well. When BHs are included, the code- and resolution-dependent\nvariations in the SFHs are more significant, but the agreement is still good,\nand the stellar mass formed over the course of a simulation is robust to\nvariations in the numerical method. During a merger, the gas morphology and\nphase structure are initially similar prior to the starburst phase. However,\nonce a hot gaseous halo has formed from shock heating and AGN feedback (when\nincluded), the agreement is less good. In particular, during the post-starburst\nphase, the SPH simulations feature more prominent hot gaseous haloes and\nspurious clumps, whereas with Arepo, gas clumps and filaments are less apparent\nand the hot halo gas can cool more efficiently. We discuss the origin of these\ndifferences and explain why the SPH technique yields trustworthy results for\nsome applications (such as the idealised isolated disc and galaxy merger\nsimulations presented here) but not others (e.g., gas flows onto galaxies in\ncosmological hydrodynamical simulations). \n\n"}
{"id": "1309.3259", "contents": "Title: CDMSlite: A Search for Low-Mass WIMPs using Voltage-Assisted\n  Calorimetric Ionization Detection in the SuperCDMS Experiment Abstract: SuperCDMS is an experiment designed to directly detect Weakly Interacting\nMassive Particles (WIMPs), a favored candidate for dark matter ubiquitous in\nthe Universe. In this paper, we present WIMP-search results using a\ncalorimetric technique we call CDMSlite, which relies on voltage- assisted\nLuke-Neganov amplification of the ionization energy deposited by particle\ninteractions. The data were collected with a single 0.6 kg germanium detector\nrunning for 10 live days at the Soudan Underground Laboratory. A low energy\nthreshold of 170 eVee (electron equivalent) was obtained, which allows us to\nconstrain new WIMP-nucleon spin-independent parameter space for WIMP masses\nbelow 6 GeV/c2. \n\n"}
{"id": "1309.3538", "contents": "Title: Coherent Emission in Fast Radio Bursts Abstract: The fast (ms) radio bursts reported by Thornton, {\\it et al.} have extremely\nhigh brightness temperatures if at the inferred cosmological distances. This\nimplies coherent emission by \"bunches\" of charges. We model the emission region\nas a screen of dipole radiators resonant at the frequency of observation and\ncalculate the necessary charge bunching. From this we infer the minimum\nelectron energy required to overcome electrostatic repulsion. The FRB, like the\ngiant pulses of the Crab pulsar, display banded spectra that may be harmonics\nof plasma frequency emission by plasma turbulence. If FRB are the counterparts\nof comparatively frequent Galactic events, these may be detected by radio\ntelescopes in their far sidelobes or by small arrays of dipoles. \n\n"}
{"id": "1309.3729", "contents": "Title: Clustering large number of extragalactic spectra of galaxies and quasars\n  through canopies Abstract: Cluster analysis is the distribution of objects into different groups or more\nprecisely the partitioning of a data set into subsets (clusters) so that the\ndata in subsets share some common trait according to some distance measure.\nUnlike classi cation, in clustering one has to rst decide the optimum number of\nclusters and then assign the objects into different clusters. Solution of such\nproblems for a large number of high dimensional data points is quite\ncomplicated and most of the existing algorithms will not perform properly. In\nthe present work a new clustering technique applicable to large data set has\nbeen used to cluster the spectra of 702248 galaxies and quasars having 1540\npoints in wavelength range imposed by the instrument. The proposed technique\nhas successfully discovered ve clusters from this 702248X1540 data matrix. \n\n"}
{"id": "1310.1401", "contents": "Title: Measuring nonlocal Lagrangian peak bias Abstract: We investigate nonlocal Lagrangian bias contributions involving gradients of\nthe linear density field, for which we have predictions from the excursion set\npeak formalism. We begin by writing down a bias expansion which includes all\nthe bias terms, including the nonlocal ones. Having checked that the model\nfurnishes a reasonable fit to the halo mass function, we develop a 1-point\ncross-correlation technique to measure bias factors associated with\n2-distributed quantities. We validate the method with numerical realizations of\npeaks of Gaussian random fields before we apply it to N-body simulations. We\nfocus on the lowest (quadratic) order nonlocal contributions. We can reproduce\nour measurement of \\chi_{10} if we allow for an offset between the Lagrangian\nhalo center-of-mass and the peak position. The sign and magnitude of \\chi_{10}\nis consistent with Lagrangian haloes sitting near linear density maxima. The\nresulting contribution to the halo bias can safely be ignored for M = 10^13\nMsun/h, but could become relevant at larger halo masses. For the second\nnonlocal bias \\chi_{01} however, we measure a much larger magnitude than\npredicted by our model. We speculate that some of this discrepancy might\noriginate from nonlocal Lagrangian contributions induced by nonspherical\ncollapse. \n\n"}
{"id": "1310.1421", "contents": "Title: Casimir Torque in Inhomogeneous Dielectric Plates Abstract: In this work, we consider a torque caused by the well known quantum\nmechanical Casimir effect arising from quantized field fluctuations between\nplates with inhomogeneous, sharply discontinuous, dielectric properties. While\nthe Casimir effect is a relatively well understood phenomenon, systems\nresulting in lateral or rotational forces are far less developed; to our\nknowledge, a theoretical study of discontinuous dielectric variants of such\nsystems has not been attempted. We utilize a Proximity Force Approximation in\nconjunction with the Lifshitz dielectric formula to perform theoretical\nanalyses of resultant torques in systems with bisected and quadrisected\ndielectric regions. We also develop a high precision Monte Carlo type numerical\nintegrator to approximate our derived expressions. Our calculations of an\nenergy density linear with the alignment angle result in a constant torque and\nhave implications in NEMS (nano electromechanical systems) and MEMS (micro\nelectromechanical systems), including a postulated nanoscale oscillating drive\nmechanism powered by quantum field interactions. \n\n"}
{"id": "1310.1422", "contents": "Title: Degree-Scale CMB Polarization Measurements from Three Years of BICEP1\n  Data Abstract: BICEP1 is a millimeter-wavelength telescope designed specifically to measure\nthe inflationary B-mode polarization of the Cosmic Microwave Background (CMB)\nat degree angular scales. We present results from an analysis of the data\nacquired during three seasons of observations at the South Pole (2006 to 2008).\nThis work extends the two-year result published in Chiang et al. (2010), with\nadditional data from the third season and relaxed detector-selection criteria.\nThis analysis also introduces a more comprehensive estimation of band-power\nwindow functions, improved likelihood estimation methods and a new technique\nfor deprojecting monopole temperature-to-polarization leakage which reduces\nthis class of systematic uncertainty to a negligible level. We present maps of\ntemperature, E- and B-mode polarization, and their associated angular power\nspectra. The improvement in the map noise level and polarization spectra error\nbars are consistent with the 52% increase in integration time relative to\nChiang et al. (2010). We confirm both self-consistency of the polarization data\nand consistency with the two-year results. We measure the angular power spectra\nat 21 <= l <= 335 and find that the EE spectrum is consistent with Lambda Cold\nDark Matter (LCDM) cosmology, with the first acoustic peak of the EE spectrum\nnow detected at 15sigma. The BB spectrum remains consistent with zero. From\nB-modes only, we constrain the tensor-to-scalar ratio to r = 0.03+0.27-0.23, or\nr < 0.70 at 95% confidence level. \n\n"}
{"id": "1310.2120", "contents": "Title: TempoNest: A Bayesian approach to pulsar timing analysis Abstract: A new Bayesian software package for the analysis of pulsar timing data is\npresented in the form of TempoNest which allows for the robust determination of\nthe non-linear pulsar timing solution simultaneously with a range of additional\nstochastic parameters. This includes both red spin noise and dispersion measure\nvariations using either power law descriptions of the noise, or through a\nmodel-independent method that parameterises the power at individual frequencies\nin the signal. We use TempoNest to show that at noise levels representative of\ncurrent datasets in the European Pulsar Timing Array (EPTA) and International\nPulsar Timing Array (IPTA) the linear timing model can underestimate the\nuncertainties of the timing solution by up to an order of magnitude. We also\nshow how to perform Bayesian model selection between different sets of timing\nmodel and stochastic parameters, for example, by demonstrating that in the\npulsar B1937+21 both the dispersion measure variations and spin noise in the\ndata are optimally modelled by simple power laws. Finally we show that not\nincluding the stochastic parameters simultaneously with the timing model can\nlead to unpredictable variation in the estimated uncertainties, compromising\nthe robustness of the scientific results extracted from such analysis. \n\n"}
{"id": "1310.5703", "contents": "Title: A new method for detecting velocity shifts and distortions between\n  optical spectra Abstract: Recent quasar spectroscopy from the VLT and Keck telescopes suggests that\nfundamental constants may not actually be constant. To better confirm or refute\nthis result, systematic errors between telescopes must be minimized. We present\na new method to directly compare spectra of the same object and measure any\nvelocity shifts between them. This method allows for the discovery of\nwavelength-dependent velocity shifts between spectra, i.e. velocity\ndistortions, that could produce spurious detections of cosmological variations\nin fundamental constants. This \"direct comparison\" method has several\nadvantages over alternative techniques: it is model-independent (cf.\nline-fitting approaches), blind, in that spectral features do not need to be\nidentified beforehand, and it produces meaningful uncertainty estimates for the\nvelocity shift measurements. In particular, we demonstrate that, when comparing\nechelle-resolution spectra with unresolved absorption features, the uncertainty\nestimates are reliable for signal-to-noise ratios >7 per pixel. We apply this\nmethod to spectra of quasar J2123-0050 observed with Keck and the VLT and find\nno significant distortions over long wavelength ranges (~1050 Angstroms)\ngreater than ~180 m/s. We also find no evidence for systematic velocity\ndistortions within echelle orders greater than 500 m/s. Moreover, previous\nconstraints on cosmological variations in the proton--electron mass ratio\nshould not have been affected by velocity distortions in these spectra by more\nthan 4.0 +/- 4.2 parts per million. This technique may also find application in\nmeasuring stellar radial velocities in search of extra-solar planets and\nattempts to directly observe the expansion history of the Universe using quasar\nabsorption spectra. \n\n"}
{"id": "1310.7543", "contents": "Title: Chiral non-Fermi Liquids Abstract: A non-Fermi liquid state without time-reversal and parity symmetries arises\nwhen a chiral Fermi surface is coupled with a soft collective mode in two space\ndimensions. The full Fermi surface is described by a direct sum of chiral patch\ntheories, which are decoupled from each other in the low energy limit. Each\npatch includes low energy excitations near a set of points on the Fermi surface\nwith a common tangent vector. General patch theories are classified by the\nlocal shape of the Fermi surface, the dispersion of the critical boson, and the\nsymmetry group, which form the data for distinct universality classes. We prove\nthat a large class of chiral non-Fermi liquid states exist as stable critical\nstates of matter. For this, we use a renormalization group scheme where low\nenergy excitations of the Fermi surface are interpreted as a collection of\n(1+1)-dimensional chiral fermions with a continuous flavor labelling the\nmomentum along the Fermi surface. Due to chirality, the Wilsonian effective\naction is strictly UV finite. This allows one to extract the exact scaling\nexponents although the theories flow to strongly interacting field theories at\nlow energies. In general, the low energy effective theory of the full Fermi\nsurface includes patch theories of more than one universality classes. As a\nresult, physical responses include multiple universal components at low\ntemperatures. We also point out that, in quantum field theories with extended\nFermi surface, a non-commutative structure naturally emerges between a\ncoordinate and a momentum which are orthogonal to each other. We show that the\ninvalidity of patch description for Fermi liquid states is tied with the\npresence of UV/IR mixing associated with the emergent non-commutativity. On the\nother hand, UV/IR mixing is suppressed in non-Fermi liquid states due to UV\ninsensitivity, and the patch description is valid. \n\n"}
{"id": "1310.8214", "contents": "Title: First results from the LUX dark matter experiment at the Sanford\n  Underground Research Facility Abstract: The Large Underground Xenon (LUX) experiment, a dual-phase xenon\ntime-projection chamber operating at the Sanford Underground Research Facility\n(Lead, South Dakota), was cooled and filled in February 2013. We report results\nof the first WIMP search dataset, taken during the period April to August 2013,\npresenting the analysis of 85.3 live-days of data with a fiducial volume of 118\nkg. A profile-likelihood analysis technique shows our data to be consistent\nwith the background-only hypothesis, allowing 90% confidence limits to be set\non spin-independent WIMP-nucleon elastic scattering with a minimum upper limit\non the cross section of $7.6 \\times 10^{-46}$ cm$^{2}$ at a WIMP mass of 33\nGeV/c$^2$. We find that the LUX data are in strong disagreement with low-mass\nWIMP signal interpretations of the results from several recent direct detection\nexperiments. \n\n"}
{"id": "1311.0182", "contents": "Title: The effect of recombination radiation on the temperature and ionization\n  state of partially ionized gas Abstract: A substantial fraction of all ionizing photons originate from radiative\nrecombinations. However, in radiative transfer calculations this recombination\nradiation is often assumed to be absorbed 'on-the-spot' because for most\nmethods the computational cost associated with the inclusion of gas elements as\nsources is prohibitive. We present a new, CPU and memory efficient\nimplementation for the transport of ionizing recombination radiation in the\nTRAPHIC radiative transfer scheme. TRAPHIC solves the radiative transfer\nequation by tracing photon packets at the speed of light and in a\nphoton-conserving manner in spatially adaptive smoothed particle hydrodynamics\nsimulations. Our new implementation uses existing features of the TRAPHIC\nscheme to add recombination radiation at no additional cost in the limit in\nwhich the fraction of the simulation box filled with radiation approaches 1. We\ntest the implementation by simulating an HII region in photoionization\nequilibrium and comparing to reference solutions presented in the literature,\nfinding excellent agreement. We apply our implementation to discuss the\nevolution of the HII region to equilibrium. We show that the widely used case A\nand B approximations yield accurate ionization profiles only near the source\nand near the ionization front, respectively. We also discuss the impact of\nrecombination radiation on the geometry of shadows behind optically thick\nabsorbers. We demonstrate that the shadow region may be completely ionized by\nthe diffuse recombination radiation field and discuss the important role of\nheating by recombination radiation in the shadow region. \n\n"}
{"id": "1311.2841", "contents": "Title: Snowmass Computing Frontier: Computing for the Cosmic Frontier,\n  Astrophysics, and Cosmology Abstract: This document presents (off-line) computing requrements and challenges for\nCosmic Frontier science, covering the areas of data management, analysis, and\nsimulations. We invite contributions to extend the range of covered topics and\nto enhance the current descriptions. \n\n"}
{"id": "1311.2949", "contents": "Title: Laboratory atomic transition data for precise optical quasar absorption\n  spectroscopy Abstract: Quasar spectra reveal a rich array of important astrophysical information\nabout galaxies which intersect the quasar line of sight. They also enable tests\nof the variability of fundamental constants over cosmological time and\ndistance-scales. Key to these endeavours are the laboratory frequencies,\nisotopic and hyperfine structures of various metal-ion transitions. Here we\nreview and synthesize the existing information about these quantities for 43\ntransitions which are important for measuring possible changes in the\nfine-structure constant, alpha, using optical quasar spectra, i.e. those of Na,\nMg, Al, Si, Ca, Cr, Mn, Fe, Ni and Zn. We also summarize the information\ncurrently missing that precludes more transitions being used. We present an\nup-to-date set of coefficients, q, which define the sensitivity of these\ntransitions to variations in alpha. New calculations of isotopic structures and\nq coefficients are performed for SiII and TiII, including SiII 1808 and TiII\n1910.6/1910.9 for the first time. Finally, simulated absorption-line spectra\nare used to illustrate the systematic errors expected if the isotopic/hyperfine\nstructures are omitted from profile fitting analyses.\n  To ensure transparency, repeatability and currency of the data and\ncalculations, we supply a comprehensive database as Supporting Information.\nThis will be updated as new measurements and calculations are performed. \n\n"}
{"id": "1311.3100", "contents": "Title: Controlling the coherence in a pure dephasing model for an arbitrarily\n  prescribed time span Abstract: We present an open-loop unitary strategy to control the coherence in a pure\ndephasing model (related to the phase-flip channel) that is able to recover,\nfor whatever prescribed time span, the initial coherence at the end of the\ncontrol process. The strategy's key idea is to steer the quantum state to the\nsubset of invariant states and keep it there the necessary time, using a fine\ntuned control Hamiltonian. \n\n"}
{"id": "1311.4361", "contents": "Title: JKCS041: a Coma cluster progenitor at z=1.803 Abstract: Using deep two-color near-infrared HST imaging and unbiased grism\nspectroscopy we present a detailed study of the z=1.803 JKCS041 cluster.\nUniquely, for a high redshift cluster, we confirm a mass of $\\log M=14.2$ in\nsolar units using four different techniques based on the X-ray temperature, the\nX-ray luminosity and the cluster richness. JKCS041 is thus a progenitor of a\nlocal system like the Coma cluster. Our rich dataset and the abundant\npopulation of 14 spectroscopically-confirmed red sequence galaxies allows us to\nexplore the past star formation history of this system in unprecedented detail.\nRemarkably, we find a prominent red sequence down to stellar masses as low as\n$\\log M=9.8$, corresponding to a mass range of 2 dex. These quiescent galaxies\nare concentrated around the cluster center with a core radius of 330 kpc. Blue\nmembers are few and avoid the cluster center. In JKCS041 quenching was\ntherefore largely completed by a look-back time of 10 Gyr and we can constrain\nthe epoch at which this occurred via spectroscopic age-dating of the individual\ngalaxies. Most galaxies were quenched about 1.1 Gyr prior to the epoch of\nobservation. The less massive quiescent galaxies are somewhat younger,\ncorresponding to a decrease in age of 650 Myr per mass dex, but the scatter in\nage at fixed mass is only 380 Myr (at $\\log M=11$). The size-mass relation of\nquiescent galaxies in JKCS041 is consistent with that observed for local\nclusters within our uncertainties. Comparing our data on JKCS041 with 41\nclusters at lower redshift, we find that the form of the mass function of red\nsequence galaxies has hardly evolved in the past 10 Gyr, both in terms of its\nfaint end slope and characteristic mass. Despite observing JKCS041 soon after\nits quenching and the three fold expected increase in mass in the next 10 Gyr,\nit is already remarkably similar to present-day clusters. \n\n"}
{"id": "1311.5837", "contents": "Title: Statistical Anisotropic Gaussian Simulations of the CMB Temperature\n  Field Abstract: Although theoretically expected to be Statistically Isotropic (SI), the\nobserved Cosmic Microwave Background (CMB) temperature \\& polarization field\nwould exhibit SI violation due to various inevitable effects like weak lensing,\nDoppler boost and practical limitations of observations like non-circular beam,\nmasking etc. However, presence of any SI violation beyond these effects may\nlead to a discovery of inherent cosmic SI violation in the CMB temperature \\&\npolarization field. Recently, Planck presented strong evidence of SI violation\nas a dipolar power asymmetry of the CMB temperature field in two hemispheres.\nStatistical studies of SI violation effect require non-SI (nSI) Gaussian\nrealizations of CMB temperature field. The nSI Gaussian temperature field leads\nto non-zero off-diagonal terms in the Spherical Harmonics (SH) space covariance\nmatrix encoded in the coefficients of the Bipolar Spherical Harmonics (BipoSH)\nrepresentation. We discuss an effective numerical algorithm, Code for\nNon-Isotropic Gaussian Sky (CoNIGS) to generate nSI realizations of Gaussian\nCMB temperature field of Planck like resolution with specific cases of SI\nviolation. Realizations of nSI CMB temperature field are obtained for non-zero\nquadrupolar $(L=2)$ BipoSH measurements by WMAP, dipolar asymmetry (resembles\n$L=1$ BipoSH coefficients) with a \\emph{scale dependent} modulation field as\nmeasured by Planck and for Doppler boosted CMB temperature field which also\nleads to $L=1$ BipoSH spectra. Our method, CoNIGS can incorporate any kind of\nSI violation and can produce nSI realizations efficiently. \n\n"}
{"id": "1311.7185", "contents": "Title: A supra-massive magnetar central engine for short GRB 130603B Abstract: We show that the peculiar early optical and in particular X-ray afterglow\nemission of the short duration burst GRB 130603B can be explained by continuous\nenergy injection into the blastwave from a supra-massive magnetar central\nengine. The observed energetics and temporal/spectral properties of the late\ninfrared bump (i.e., the \"kilonova\") are also found consistent with emission\nfrom the ejecta launched during an NS-NS merger and powered by a magnetar\ncentral engine. The isotropic-equivalent kinetic energies of both the GRB\nblastwave and the kilonova are about $E_{\\rm k}\\sim 10^{51}$ erg, consistent\nwith being powered by a near-isotropic magnetar wind. However, this relatively\nsmall value demands that most of the initial rotational energy of the magnetar\n$(\\sim {\\rm a~ few \\times 10^{52}~ erg})$ is carried away by gravitational wave\nradiation. Our results suggest that (i) the progenitor of GRB 130603B would be\na NS-NS binary system, whose merger product would be a supra-massive neutron\nstar that lasted for about $\\sim 1000$ seconds; (ii) the equation-of-state of\nnuclear matter would be stiff enough to allow survival of a long-lived\nsupra-massive neutron star, so that it is promising to detect bright\nelectromagnetic counterparts of gravitational wave triggers without short GRB\nassociations in the upcoming Advanced LIGO/Virgo era. \n\n"}
{"id": "1311.7231", "contents": "Title: Pulsar timing residuals due to individual non-evolving gravitational\n  wave sources Abstract: The pulsar timing residuals induced by gravitational waves from non-evolving\nsingle binary sources are affected by many parameters related to the relative\npositions of the pulsar and the gravitational wave sources. We will fully\nanalyze the effects due to different parameters one by one. The standard\ndeviations of the timing residuals will be calculated with a variable parameter\nfixing a set of other parameters. The orbits of the binary sources will be\ngenerally assumed to be elliptical. The influences of different eccentricities\non the pulsar timing residuals will also studied in detail. We find that\neffects of the related parameters are quite different, and some of them present\ncertain regularities. \n\n"}
{"id": "1312.0600", "contents": "Title: Accretion disks around binary black holes of unequal mass: GRMHD\n  simulations near decoupling Abstract: We report on simulations in general relativity of magnetized disks onto black\nhole binaries. We vary the binary mass ratio from 1:1 to 1:10 and evolve the\nsystems when they orbit near the binary-disk decoupling radius. We compare\n(surface) density profiles, accretion rates (relative to a single, non-spinning\nblack hole), variability, effective $\\alpha$-stress levels and luminosities as\nfunctions of the mass ratio. We treat the disks in two limiting regimes: rapid\nradiative cooling and no radiative cooling. The magnetic field lines clearly\nreveal jets emerging from both black hole horizons and merging into one common\njet at large distances. The magnetic fields give rise to much stronger shock\nheating than the pure hydrodynamic flows, completely alter the disk structure,\nand boost accretion rates and luminosities. Accretion streams near the horizons\nare among the densest structures; in fact, the 1:10 no-cooling evolution\nresults in a refilling of the cavity. The typical effective temperature in the\nbulk of the disk is $\\sim 10^5 (M/10^8 M_\\odot)^{-1/4} (L/L_{\\rm edd})^{1/4}\n{\\rm K}$ yielding characteristic thermal frequencies $\\sim 10^{15} (M/10^8\nM_\\odot)^{-1/4} (L/L_{\\rm edd})^{1/4}(1+z)^{-1}{\\rm Hz} $. These systems are\nthus promising targets for many extragalactic optical surveys, such as LSST,\nWFIRST, and PanSTARRS. \n\n"}
{"id": "1312.0814", "contents": "Title: Matrix Models and Large-N Behavior Abstract: Following the procedures by which O(N)-invariant real vector models and their\nlarge-N behavior have previously been solved, we extend similar techniques to\nthe study of real symmetric N x N-matrix models with O(N)-invariant\ninteractions. Proper extensions to N equal infinity are also established. While\nno 1/N-expansions are involved in our analysis, a brief comparison of our\nprocedures with traditional 1/N-expansion procedures is given. \n\n"}
{"id": "1312.1734", "contents": "Title: Complex scalar field dark matter on galactic scales Abstract: The nature of the cosmological dark matter remains elusive. Recent studies\nhave advocated the possibility that dark matter could be composed of\nultra-light, self-interacting bosons, forming a Bose-Einstein condensate in the\nvery early Universe. We consider models which are charged under a global\nU(1)-symmetry such that the dark matter number is conserved. It can then be\ndescribed as a classical complex scalar field which evolves in an expanding\nUniverse. We present a brief review on the bounds on the model parameters from\ncosmological and galactic observations, along with the properties of galactic\nhalos which result from such a dark matter candidate. \n\n"}
{"id": "1312.4841", "contents": "Title: The Clustering of Galaxies in the SDSS-III Baryon Oscillation\n  Spectroscopic Survey: Including covariance matrix errors Abstract: We present improved methodology for including covariance matrices in the\nerror budget of Baryon Oscillation Spectroscopic Survey (BOSS) galaxy\nclustering measurements, revisiting Data Release 9 (DR9) analyses, and\ndescribing a method that is used in DR10/11 analyses presented in companion\npapers. The precise analysis method adopted is becoming increasingly important,\ndue to the precision that BOSS can now reach: even using as many as 600 mock\ncatalogues to estimate covariance of 2-point clustering measurements can still\nlead to an increase in the errors of ~20%, depending on how the cosmological\nparameters of interest are measured. In this paper we extend previous work on\nthis contribution to the error budget, deriving formulae for errors measured by\nintegrating over the likelihood, and to the distribution of recovered best-fit\nparameters fitting the simulations also used to estimate the covariance matrix.\nBoth are situations that previous analyses of BOSS have considered. We apply\nthe formulae derived to Baryon Acoustic Oscillation (BAO) and Redshift-Space\nDistortion (RSD) measurements from BOSS in our companion papers. To further aid\nthese analyses, we consider the optimum number of bins to use for 2-point\nmeasurements using the monopole power spectrum or correlation function for BAO,\nand the monopole and quadrupole moments of the correlation function for\nanisotropic-BAO and RSD measurements. \n\n"}
{"id": "1312.5706", "contents": "Title: Photometric type Ia supernova surveys in narrow band filters Abstract: We study the characteristics of a narrow band type Ia supernova survey\nthrough simulations based on the upcoming Javalambre Physics of the\naccelerating universe Astrophysical Survey (J-PAS). This unique survey has the\ncapabilities of obtaining distances, redshifts, and the SN type from a single\nexperiment thereby circumventing the challenges faced by the resource-intensive\nspectroscopic follow-up observations. We analyse the flux measurements\nsignal-to-noise ratio and bias, the supernova typing performance, the ability\nto recover light curve parameters given by the SALT2 model, the photometric\nredshift precision from type Ia supernova light curves and the effects of\nsystematic errors on the data. We show that such a survey is not only feasible\nbut may yield large type Ia supernova samples (up to 250 supernovae at $z<0.5$\nper month of search) with low core collapse contamination ($\\sim 1.5$ per\ncent), good precision on the SALT2 parameters (average $\\sigma_{m_B}=0.063$,\n$\\sigma_{x_1}=0.47$ and $\\sigma_c=0.040$) and on the distance modulus (average\n$\\sigma_{\\mu}=0.16$, assuming an intrinsic scatter\n$\\sigma_{\\mathrm{int}}=0.14$), with identified systematic uncertainties\n$\\sigma_{\\mathrm{sys}}\\lesssim 0.10 \\sigma_{\\mathrm{stat}}$. Moreover, the\nfilters are narrow enough to detect most spectral features and obtain excellent\nphotometric redshift precision of $\\sigma_z=0.005$, apart from $\\sim$ 2 per\ncent of outliers. We also present a few strategies for optimising the survey's\noutcome. Together with the detailed host galaxy information, narrow band\nsurveys can be very valuable for the study of supernova rates, spectral feature\nrelations, intrinsic colour variations and correlations between supernova and\nhost galaxy properties, all of which are important information for supernova\ncosmological applications. \n\n"}
{"id": "1312.6016", "contents": "Title: Cosmological simulations of screened modified gravity out of the static\n  approximation: effects on matter distribution Abstract: In the context of scalar tensor theories for gravity, there is a universally\nadopted hypothesis when running N-body simulations that time derivatives in the\nequation of motion for the scalar field are negligible. In this work we propose\nto test this assumption for one specific scalar-tensor model with a gravity\nscreening mechanism: the symmetron. To this end, we implemented the necessary\nmodifications to include the non-static terms in the N-body code Ramses. We\npresent test cases and results from cosmological simulations. Our main finding\nwhen comparing static vs. non-static simulations is that the global power\nspectrum is only slightly modified when taking into account the inclusion of\nnon-static terms. On the contrary, we find that the calculation of the local\npower spectrum gives different measurements. Such results imply one must be\ncareful when assuming the quasi-static approximation when investigating the\nenvironmental effects of modified gravity and screening mechanisms in structure\nformation of halos and voids distributions. \n\n"}
{"id": "1401.2095", "contents": "Title: Coaxing Cosmic 21cm Fluctuations from the Polarized Sky using m-mode\n  Analysis Abstract: In this paper we continue to develop the m-mode formalism, a technique for\nefficient and optimal analysis of wide-field transit radio telescopes, targeted\nat 21 cm cosmology. We extend this formalism to give an accurate treatment of\nthe polarised sky, fully accounting for the effects of polarisation leakage and\ncross-polarisation. We use the geometry of the measured set of visibilities to\nproject down to pure temperature modes on the sky, serving as a significant\ncompression, and an effective first filter of polarised contaminants. We use\nthe m-mode formalism with the Karhunen-Loeve transform to give a highly\nefficient method for foreground cleaning, and demonstrate its success in\ncleaning realistic polarised skies observed with an instrument suffering from\nsubstantial off axis polarisation leakage. We develop an optimal quadratic\nestimator in the m-mode formalism, which can be efficiently calculated using a\nMonte-Carlo technique. This is used to assess the implications of foreground\nremoval for power spectrum constraints where we find that our method can clean\nforegrounds well below the foreground wedge, rendering only scales $k_\\parallel\n< 0.02 h \\,\\mathrm{Mpc}^{-1}$ inaccessible. As this approach assumes perfect\nknowledge of the telescope, we perform a conservative test of how essential\nthis is by simulating and analysing datasets with deviations about our assumed\ntelescope. Assuming no other techniques to mitigate bias are applied, we\nrecover unbiased power spectra when the per-feed beam width to be measured to\n0.1%, and amplifier gains to be known to 1% within each minute. Finally, as an\nexample application, we extend our forecasts to a wideband 400-800 MHz\ncosmological observation and consider the implications for probing dark energy,\nfinding a medium-sized cylinder telescope improves the DETF Figure of Merit by\naround 70% over Planck and Stage II experiments alone. \n\n"}
{"id": "1401.5468", "contents": "Title: Precursors prior to Type IIn supernova explosions are common: precursor\n  rates, properties, and correlations Abstract: There is a growing number of supernovae (SNe), mainly of Type IIn, which\npresent an outburst prior to their presumably final explosion. These precursors\nmay affect the SN display, and are likely related to some poorly charted\nphenomena in the final stages of stellar evolution. Here we present a sample of\n16 SNe IIn for which we have Palomar Transient Factory (PTF) observations\nobtained prior to the SN explosion. By coadding these images taken prior to the\nexplosion in time bins, we search for precursor events. We find five Type IIn\nSNe that likely have at least one possible precursor event, three of which are\nreported here for the first time. For each SN we calculate the control time.\nBased on this analysis we find that precursor events among SNe IIn are common:\nat the one-sided 99% confidence level, more than 50% of SNe IIn have at least\none pre-explosion outburst that is brighter than absolute magnitude -14, taking\nplace up to 1/3 yr prior to the SN explosion. The average rate of such\nprecursor events during the year prior to the SN explosion is likely larger\nthan one per year, and fainter precursors are possibly even more common. We\nalso find possible correlations between the integrated luminosity of the\nprecursor, and the SN total radiated energy, peak luminosity, and rise time.\nThese correlations are expected if the precursors are mass-ejection events, and\nthe early-time light curve of these SNe is powered by interaction of the SN\nshock and ejecta with optically thick circumstellar material. \n\n"}
{"id": "1401.6892", "contents": "Title: Breaking the spell of Gaussianity: forecasting with higher order Fisher\n  matrices Abstract: We present the new method DALI (Derivative Approximation for LIkelihoods) for\nreconstructing and forecasting posteriors. DALI extends the Fisher Matrix\nformalism but allows for a much wider range of posterior shapes. While the\nFisher Matrix formalism is limited to yield ellipsoidal confidence contours,\nour method can reproduce the often observed flexed, deformed or curved shapes\nof known posteriors. This gain in shape fidelity is obtained by expanding the\nposterior to higher order in derivatives with respect to parameters, such that\nnon-Gaussianity in the parameter space is taken into account. The resulting\nexpansion is positive definite and normalizable at every order. Here, we\npresent the new technique, highlight its advantages and limitations, and show a\nrepresentative application to a posterior of dark energy parameters from\nsupernovae measurements. \n\n"}
{"id": "1401.7258", "contents": "Title: Antimatter in the Universe : Constraints from Gamma-Ray Astronomy Abstract: We review gamma-ray observations that constrain antimatter - both baryonic\nand leptonic - in the Universe. Antimatter can be probed through ordinary\nmatter, with the resulting annihilation gamma-rays providing indirect evidence\nfor its presence. Although it is generally accepted that equal amounts of\nmatter and antimatter have been produced in the Big Bang, gamma-rays have so\nfar failed to detect substantial amounts of baryonic antimatter in the\nUniverse. Conversely, positrons are abundantly observed through their\nannihilation in the central regions of our Galaxy and, although a wealth of\nastrophysical sources are plausible, their very origin is still unknown. As\nboth antimatter questions - the source of the Galactic positrons and the baryon\nasymmetry in the Universe - can be investigated through the low energy\ngamma-ray channel, the mission concept of a dedicated space telescope is\nsketched out. \n\n"}
{"id": "1401.8178", "contents": "Title: The CTA Sensitivity to Lorentz-Violating Effects on the Gamma-Ray\n  Horizon Abstract: The arrival of TeV-energy photons from distant galaxies is expected to be\naffected by their QED interaction with intergalactic radiation fields through\nelectron-positron pair production. In theories where high-energy photons\nviolate Lorentz symmetry, the kinematics of the process $\\gamma +\n\\gamma\\rightarrow e^+ + e^-$ is altered and the cross-section suppressed.\nConsequently, one would expect more of the highest-energy photons to arrive if\nQED is modified by Lorentz violation than if it is not. We estimate the\nsensitivity of Cherenkov Telescope Array (CTA) to changes in the $\\gamma$-ray\nhorizon of the Universe due to Lorentz violation, and find that it should be\ncompetitive with other leading constraints. \n\n"}
{"id": "1402.2644", "contents": "Title: A spinning supermassive black hole binary model consistent with VLBI\n  observations of the S5 1928+738 jet Abstract: Very Long Baseline Interferometry (VLBI) allows for high-resolution and\nhigh-sensitivity observations of relativistic jets, that can reveal\nperiodicities of several years in their structure. We perform an analysis of\nlong-term VLBI data of the quasar S5 1928+738 in terms of a geometric model of\na helical structure projected onto the plane of the sky. We monitor the\ndirection of the jet axis through its inclination and position angles. We\ndecompose the variation of the inclination of the inner 2 milliarcseconds of\nthe jet of S5 1928+738 into a periodic term with amplitude of ~0.89 deg and a\nlinear decreasing trend with rate of ~0.05 deg/yr. We also decompose the\nvariation of the position angle into a periodic term with amplitude of ~3.39\ndeg and a linear increasing trend with rate of ~0.24 deg/yr. We interpret the\nperiodic components as arising from the orbital motion of a binary black hole\ninspiraling at the jet base and derive corrected values of the mass ratio and\nseparation from the accumulated 18 years of VLBI data. Then we identify the\nlinear trends in the variations as due to the slow reorientation of the spin of\nthe jet emitter black hole induced by the spin-orbit precession and we\ndetermine the precession period T_SO=4852+/-646 yr of the more massive black\nhole, acting as the jet emitter. Our study provides indications, for the first\ntime from VLBI jet kinematics, for the spinning nature of the jet-emitting\nblack hole. \n\n"}
{"id": "1402.3731", "contents": "Title: A Detailed Look at the First Results from the Large Underground Xenon\n  (LUX) Dark Matter Experiment Abstract: LUX, the world's largest dual-phase xenon time-projection chamber, with a\nfiducial target mass of 118 kg and 10,091 kg-days of exposure thus far, is\ncurrently the most sensitive direct dark matter search experiment. The initial\nnull-result limit on the spin-independent WIMP-nucleon scattering cross-section\nwas released in October 2013, with a primary scintillation threshold of 2 phe,\nroughly 3 keVnr for LUX. The detector has been deployed at the Sanford\nUnderground Research Facility (SURF) in Lead, South Dakota, and is the first\nexperiment to achieve a limit on the WIMP cross-section lower than $10^{-45}$\ncm$^{2}$. Here we present a more in-depth discussion of the novel energy scale\nemployed to better understand the nuclear recoil light and charge yields, and\nof the calibration sources, including the new internal tritium source. We found\nthe LUX data to be in conflict with low-mass WIMP signal interpretations of\nother results. \n\n"}
{"id": "1403.0044", "contents": "Title: Exhausting the Information: Novel Bayesian Combination of Photometric\n  Redshift PDFs Abstract: The estimation and utilization of photometric redshift probability density\nfunctions (photo-$z$ PDFs) has become increasingly important over the last few\nyears and currently there exist a wide variety of algorithms to compute\nphoto-$z$'s, each with their own strengths and weaknesses. In this paper, we\npresent a novel and efficient Bayesian framework that combines the results from\ndifferent photo-$z$ techniques into a more powerful and robust estimate by\nmaximizing the information from the photometric data. To demonstrate this we\nuse a supervised machine learning technique based on random forest, an\nunsupervised method based on self-organizing maps, and a standard template\nfitting method but can be easily extend to other existing techniques. We use\ndata from the DEEP2 and the SDSS surveys to explore different methods for\ncombining the predictions from these techniques. By using different performance\nmetrics, we demonstrate that we can improve the accuracy of our final photo-$z$\nestimate over the best input technique, that the fraction of outliers is\nreduced, and that the identification of outliers is significantly improved when\nwe apply a Na\\\"{\\i}ve Bayes Classifier to this combined information. Our more\nrobust and accurate photo-$z$ PDFs will allow even more precise cosmological\nconstraints to be made by using current and future photometric surveys. These\nimprovements are crucial as we move to analyze photometric data that push to or\neven past the limits of the available training data, which will be the case\nwith the Large Synoptic Survey Telescope. \n\n"}
{"id": "1403.1271", "contents": "Title: SCoPE: An efficient method of Cosmological Parameter Estimation Abstract: Markov Chain Monte Carlo (MCMC) sampler is widely used for cosmological\nparameter estimation from CMB and other data. However, due to the intrinsic\nserial nature of the MCMC sampler, convergence is often very slow. Here we\npresent a fast and independently written Monte Carlo method for cosmological\nparameter estimation named as Slick Cosmological Parameter Estimator (SCoPE),\nthat employs delayed rejection to increase the acceptance rate of a chain, and\npre-fetching that helps an individual chain to run on parallel CPUs. An\ninter-chain covariance update is also incorporated to prevent clustering of the\nchains allowing faster and better mixing of the chains. We use an adaptive\nmethod for covariance calculation to calculate and update the covariance\nautomatically as the chains progress. Our analysis shows that the acceptance\nprobability of each step in SCoPE is more than $95\\%$ and the convergence of\nthe chains are faster. Using SCoPE, we carry out some cosmological parameter\nestimations with different cosmological models using WMAP-9 and Planck results.\nOne of the current research interests in cosmology is quantifying the nature of\ndark energy. We analyze the cosmological parameters from two illustrative\ncommonly used parameterisations of dark energy models. We also asses primordial\nhelium fraction in the universe can be constrained by the present CMB data from\nWMAP-9 and Planck. The results from our MCMC analysis on the one hand helps us\nto understand the workability of the SCoPE better, on the other hand it\nprovides a completely independent estimation of cosmological parameters from\nWMAP-9 and Planck data. \n\n"}
{"id": "1403.2369", "contents": "Title: A Measurement of the Cosmic Microwave Background B-Mode Polarization\n  Power Spectrum at Sub-Degree Scales with POLARBEAR Abstract: We report a measurement of the B-mode polarization power spectrum in the\ncosmic microwave background (CMB) using the POLARBEAR experiment in Chile. The\nfaint B-mode polarization signature carries information about the Universe's\nentire history of gravitational structure formation, and the cosmic inflation\nthat may have occurred in the very early Universe. Our measurement covers the\nangular multipole range 500 < l < 2100 and is based on observations of an\neffective sky area of 25 square degrees with 3.5 arcmin resolution at 150 GHz.\nOn these angular scales, gravitational lensing of the CMB by intervening\nstructure in the Universe is expected to be the dominant source of B-mode\npolarization. Including both systematic and statistical uncertainties, the\nhypothesis of no B-mode polarization power from gravitational lensing is\nrejected at 97.1% confidence. The band powers are consistent with the standard\ncosmological model. Fitting a single lensing amplitude parameter A_BB to the\nmeasured band powers, A_BB = 1.12 +/- 0.61 (stat) +0.04/-0.12 (sys) +/- 0.07\n(multi), where A_BB = 1 is the fiducial WMAP-9 LCDM value. In this expression,\n\"stat\" refers to the statistical uncertainty, \"sys\" to the systematic\nuncertainty associated with possible biases from the instrument and\nastrophysical foregrounds, and \"multi\" to the calibration uncertainties that\nhave a multiplicative effect on the measured amplitude A_BB. \n\n"}
{"id": "1403.4302", "contents": "Title: BICEP2 II: Experiment and Three-Year Data Set Abstract: We report on the design and performance of the BICEP2 instrument and on its\nthree-year data set. BICEP2 was designed to measure the polarization of the\ncosmic microwave background (CMB) on angular scales of 1 to 5 degrees\n($\\ell$=40-200), near the expected peak of the B-mode polarization signature of\nprimordial gravitational waves from cosmic inflation. Measuring B-modes\nrequires dramatic improvements in sensitivity combined with exquisite control\nof systematics. The BICEP2 telescope observed from the South Pole with a 26~cm\naperture and cold, on-axis, refractive optics. BICEP2 also adopted a new\ndetector design in which beam-defining slot antenna arrays couple to\ntransition-edge sensor (TES) bolometers, all fabricated on a common substrate.\nThe antenna-coupled TES detectors supported scalable fabrication and\nmultiplexed readout that allowed BICEP2 to achieve a high detector count of 500\nbolometers at 150 GHz, giving unprecedented sensitivity to B-modes at degree\nangular scales. After optimization of detector and readout parameters, BICEP2\nachieved an instrument noise-equivalent temperature of 15.8 $\\mu$K sqrt(s). The\nfull data set reached Stokes Q and U map depths of 87.2 nK in square-degree\npixels (5.2 $\\mu$K arcmin) over an effective area of 384 square degrees within\na 1000 square degree field. These are the deepest CMB polarization maps at\ndegree angular scales to date. The power spectrum analysis presented in a\ncompanion paper has resulted in a significant detection of B-mode polarization\nat degree scales. \n\n"}
{"id": "1403.5067", "contents": "Title: Generic inference of inflation models by non-Gaussianity and primordial\n  power spectrum reconstruction Abstract: We present a generic inference method for inflation models from observational\ndata by the usage of higher-order statistics of the curvature perturbation on\nuniform density hypersurfaces. This method is based on the calculation of the\nposterior for the primordial non-Gaussianity parameters $f_\\text{NL}$ and\n$g_\\text{NL}$, which in general depend on specific parameters of inflation and\nreheating models, and enables to discriminate among the still viable inflation\nmodels. To keep analyticity as far as possible to dispense with numerically\nexpensive sampling techniques a saddle-point approximation is introduced, whose\nprecision is validated for a numerical toy example. The mathematical\nformulation is done in a generic way so that the approach remains applicable to\ncosmic microwave background data as well as to large scale structure data.\nAdditionally, we review a few currently interesting inflation models and\npresent numerical toy examples thereof in two and three dimensions to\ndemonstrate the efficiency of the higher-order statistics method. A second\nquantity of interest is the primordial power spectrum. Here, we present two\nBayesian methods to infer it from observational data, the so called critical\nfilter and an extension thereof with smoothness prior, both allowing for a\nnon-parametric spectrum reconstruction. These methods are able to reconstruct\nthe spectra of the observed perturbations and the primordial ones of curvature\nperturbation even in case of non-Gaussianity and partial sky coverage. We argue\nthat observables like $T-$ and $B-$modes permit to measure both spectra. This\nalso allows to infer the level of non-Gaussianity generated since inflation. \n\n"}
{"id": "1403.6327", "contents": "Title: The birth of black holes: neutron star collapse times, gamma-ray bursts\n  and fast radio bursts Abstract: Recent observations of short gamma-ray bursts (SGRBs) suggest that binary\nneutron star (NS) mergers can create highly magnetised, millisecond NSs. Sharp\ncut-offs in X-ray afterglow plateaus of some SGRBs hint at the gravitational\ncollapse of these remnant NSs to black holes. The collapse of such\n`supramassive' NSs also describes the blitzar model, a leading candidate for\nthe progenitors of fast radio bursts (FRBs). The observation of an FRB\nassociated with an SGRB would provide compelling evidence for the blitzar model\nand the binary NS merger scenario of SGRBs, and lead to interesting constraints\non the NS equation of state. We predict the collapse times of supramassive NSs\ncreated in binary NS mergers, finding that such stars collapse $\\sim10\\,{\\rm\ns}$ -- $4.4\\times10^{4}\\,{\\rm s}$ (95% confidence) after the merger. This\ndirectly impacts observations targeting NS remnants of binary NS mergers,\nproviding the optimal window for high time resolution radio and X-ray follow-up\nof SGRBs and gravitational wave bursts. \n\n"}
{"id": "1403.6763", "contents": "Title: Nonlocal Metric Realizations of MOND Abstract: I discuss relativistic extensions of MOND in which the metric couples\nnormally to matter. I argue that MOND might be a residual effect from the\nvacuum polarization of infrared gravitons produced during primordial inflation.\nIf so, MOND corrections to the gravitational field equations would be nonlocal.\nNonocality also results when one constructs metric field equations which\nreproduce the Tully-Fisher relation, along with sufficient weak lensing. I give\nthe full field equations for the simplest class of models, and I specialize\nthese equations to the geometries relevant for cosmology. I conclude by\nsketching the direction of future studies. \n\n"}
{"id": "1404.2596", "contents": "Title: The Epoch of Reionization Window: I. Mathematical Formalism Abstract: The 21 cm line provides a powerful probe of astrophysics and cosmology at\nhigh redshifts, but unlocking the potential of this probe requires the robust\nmitigation of foreground contaminants that are typically several orders of\nmagnitude brighter than the cosmological signal. Recent simulations and\nobservations have shown that the smooth spectral structure of foregrounds\ncombines with instrument chromaticity to contaminate a \"wedge\"-shaped region in\ncylindrical Fourier space. While previous efforts have explored the suppression\nof foregrounds within this wedge, as well as the avoidance of this highly\ncontaminated region, all such efforts have neglected a rigorous examination of\nthe error statistics associated with the wedge. Using a quadratic estimator\nformalism applied to the interferometric measurement equation, we provide a\nframework for such a rigorous analysis (incorporating a fully covariant\ntreatment of errors). Additionally, we find that there are strong error\ncorrelations at high spatial wavenumbers that have so far been neglected in\nsensitivity derivations. These error correlations substantially degrade the\nsensitivity of arrays relying on contributions from long baselines, compared to\nwhat one would estimate assuming uncorrelated errors. \n\n"}
{"id": "1404.3735", "contents": "Title: The Hubble Expansion is Isotropic in the Epoch of Dark Energy Abstract: The isotropy of the universal Hubble expansion is a fundamental tenet of\nphysical cosmology, but it has not been precisely tested during the current\nepoch, when dark energy is dominant. Anisotropic expansion will produce a\nshearing velocity field, causing objects to stream toward directions of faster\nexpansion and away from directions of slower expansion. This work tests the\nbasic cosmological assumption of isotropic expansion and thus the isotropy of\ndark energy. The simplest anisotropy will manifest as a quadrupolar curl-free\nproper motion vector field. We derive this theoretical signature using a\ntri-axial expanding metric with a flat geometry (Bianchi I model), generalizing\nand correcting previous work. We then employ the best current data, the Titov &\nLambert (2013) proper motion catalog of 429 objects, to measure the isotropy of\nuniversal expansion. We demonstrate that the Hubble expansion is isotropic to\n7% (1 $\\sigma$), corresponding to streaming motions of 1 microarcsecond/yr, in\nthe best-constrained directions (-19% and +17% in the least-constrained\ndirections) and does not significantly deviate from isotropy in any direction.\nThe Gaia mission, which is expected to obtain proper motions for 500,000\nquasars, will likely constrain the anisotropy below 1%. \n\n"}
{"id": "1404.4372", "contents": "Title: The Epoch of Reionization Window: II. Statistical Methods for Foreground\n  Wedge Reduction Abstract: For there to be a successful measurement of the 21 cm Epoch of Reionization\n(EoR) power spectrum, it is crucial that strong foreground contaminants be\nrobustly suppressed. These foregrounds come from a variety of sources (such as\nGalactic synchrotron emission and extragalactic point sources), but almost all\nshare the property of being spectrally smooth, and when viewed through the\nchromatic response of an interferometer, occupy a signature \"wedge\" region in\ncylindrical $k_\\perp k_\\parallel$ Fourier space. The complement of the\nforeground wedge is termed the \"EoR window\", and is expected to be mostly\nforeground-free, allowing clean measurements of the power spectrum. This paper\nis a sequel to a previous paper that established a rigorous mathematical\nframework for describing the foreground wedge and the EoR window. Here, we use\nour framework to explore statistical methods by which the EoR window can be\nenlarged, thereby increasing the sensitivity of a power spectrum measurement.\nWe adapt the FKP approximation (commonly used in galaxy surveys) for 21 cm\ncosmology, and also compare the optimal quadratic estimator to simpler\nestimators that ignore covariances between different Fourier modes. The optimal\nquadratic estimator is found to suppress foregrounds by an extra factor of\n$\\sim 10^5$ in power at the peripheries of the EoR window, boosting the\ndetection of the cosmological signal from $12\\sigma$ to $50\\sigma$ at the\nmidpoint of reionization in our fiducial models. If numerical issues can be\nfinessed, decorrelation techniques allow the EoR window to be further enlarged,\nenabling measurements to be made deep within the foreground wedge. These\ntechniques do not assume that foreground are Gaussian-distributed, and we\nadditionally prove that a final round of foreground subtraction can be\nperformed after decorrelation in a way that is guaranteed to have no\ncosmological signal loss. \n\n"}
{"id": "1404.6156", "contents": "Title: On the Performance of Quasar Reverberation Mapping in the Era of\n  Time-Domain Photometric Surveys Abstract: We quantitatively assess, by means of comprehensive numerical simulations,\nthe ability of broad-band photometric surveys to recover the broad emission\nline region (BLR) size in quasars under various observing conditions and for a\nwide range of object properties. Focusing on the general characteristics of the\nLarge Synoptic Survey Telescope (LSST), we find that the slope of the\nsize-luminosity relation for the BLR in quasars can be determined with\nunprecedented accuracy, of order a few percent, over a broad luminosity range\nand out to $z\\sim 3$. In particular, major emission lines for which the BLR\nsize can be reliably measured with LSST include H$\\alpha$, MgII $\\lambda 2799$,\nCIII] $\\lambda 1909$, CIV $\\lambda 1549$, and Ly$\\alpha$, amounting to a total\nof $\\gtrsim 10^5$ time-delay measurements for all transitions. Combined with an\nestimate for the emission line velocity dispersion, upcoming photometric\nsurveys will facilitate the estimation of black hole masses in AGN over a broad\nrange of luminosities and redshifts, allow for refined calibrations of BLR\nsize-luminosity-redshift relations in different transitions, as well as lead to\nmore reliable cross-calibration with other black hole mass estimation\ntechniques. \n\n"}
{"id": "1404.7123", "contents": "Title: Dynamics of Particles Around a Schwarzschild-like Black Hole in the\n  Presence of Quintessence and Magnetic Field Abstract: We investigate the dynamics of a neutral and a charged particle around a\nstatic and spherically symmetric black hole in the presence of quintessence\nmatter and external magnetic field. We explore the conditions under which the\nparticle moving around the black hole could escape to infinity after colliding\nwith another particle. The innermost stable circular orbit (ISCO) for the\nparticles are studied in detail. Mainly the dependence of ISCO on dark energy\nand on the presence of external magnetic field in the vicinity of black hole is\ndiscussed. By using the Lyapunov exponent, we compare the stabilities of the\norbits of the particles in the presence and absence of dark energy and magnetic\nfield. The expressions for the center of mass energies of the colliding\nparticles near the horizon of the black hole are derived. The effective force\non the particles due to dark energy and magnetic field in the vicinity of black\nhole is also discussed. \n\n"}
{"id": "1404.7525", "contents": "Title: A Tale of Two Paradigms: the Mutual Incommensurability of LCDM and MOND Abstract: The concordance model of cosmology, LCDM, provides a satisfactory description\nof the evolution of the universe and the growth of large scale structure.\nDespite considerable effort, this model does not at present provide a\nsatisfactory description of small scale structure and the dynamics of bound\nobjects like individual galaxies. In contrast, MOND provides a unique and\npredictively successful description of galaxy dynamics, but is mute on the\nsubject of cosmology. Here I briefly review these contradictory world views,\nemphasizing the wealth of distinct, interlocking lines of evidence that went\ninto the development of LCDM while highlighting the practical impossibility\nthat it can provide a satisfactory explanation of the observed MOND\nphenomenology in galaxy dynamics. I also briefly review the baryon budget in\ngroups and clusters of galaxies where neither paradigm provides an entirely\nsatisfactory description of the data. Relatively little effort has been devoted\nto the formation of structure in MOND; I review some of what has been done. The\namplitude ratio of the first to second peak in the CMB power spectrum was\ncorrectly predicted a priori, but the third peak is more natural to LCDM. MOND\nanticipates that structure forms more quickly than in LCDM. This motivated the\nprediction that reionization would happen earlier in MOND than originally\nexpected in LCDM, as subsequently observed. This also provides a natural\nexplanation for massive, early clusters of galaxies and large, empty voids.\nHowever, it is far from obvious that the mass spectrum of galaxy clusters or\nthe power spectrum of galaxies can be explained in MOND, two things that LCDM\ndoes well. Critical outstanding issues are the development of an acceptable\nrelativistic parent theory for MOND, and the reality of the non-baryonic dark\nmatter of LCDM. Do suitable dark matter particles exist, or are they a modern\naether? \n\n"}
{"id": "1404.7661", "contents": "Title: MOND theory Abstract: A general account of MOND theory is given. I start with the basic tenets of\nMOND, which posit departure from standard dynamics in the limit of low\nacceleration -- below an acceleration constant a0 -- where dynamics become\nscale invariant. I list some of the salient predictions of these tenets. The\nspecial role of a0 and its significance are then discussed. In particular, I\nstress its coincidence with cosmologically relevant accelerations. The\ndeep-MOND limit and the consequences of its scale invariance are considered in\nsome detail.\n  General aspects of MOND theories are then described, after which I list\nbriefly presently known theories, both nonrelativistic and relativistic. Most\nfull-fledged theories modify the gravitational action, hinge on a0, introduce\nan interpolating function between the low and high accelerations, and obey MOND\nrequirements in the opposite limits. These theories have much heuristic value\nas proofs of various concepts (e.g., that covariant MOND theories can be\nwritten with correct gravitational lensing). But, probably, they are, at best,\neffective theories of limited applicability.\n  I then outline several other promising approaches to constructing MOND\ntheories that strive to obtain MOND as an effective theory from deeper\nconcepts, for example, by modifying inertia and/or gravity as a result of\ninteractions with some omnipresent agent.\n  Some theories do enjoy a natural appearance of a cosmological-constant-like\ncontribution that, furthermore, exhibits the observed connection with a0.\nHowever, none were shown to address fully the mass discrepancies in cosmology\nand structure formation that are otherwise explained by cosmological dark\nmatter.\n  We have no clues as to whether and how MOND aspects enter non-gravitational\nphenomena, but I discuss briefly some possibilities. \n\n"}
{"id": "1405.0011", "contents": "Title: Frontier Fields: High-Redshift Predictions and Early Results Abstract: The Frontier Fields program is obtaining deep Hubble and Spitzer Space\nTelescope images of new \"blank\" fields and nearby fields gravitationally lensed\nby massive galaxy clusters. The Hubble images of the lensed fields are\nrevealing nJy sources (AB mag > 31), the faintest galaxies yet observed. In\nthis paper, we present high-redshift (z > 6) number count predictions for the\nfull program and candidates in three of the first Hubble Frontier Fields\nimages. The full program will transform our understanding of galaxy evolution\nin the first 600 million years (z > 9). Where previous programs yielded perhaps\na dozen z > 9 candidates, the Frontier Fields may yield ~70 (~6 per field). We\nbase this estimate on an extrapolation of luminosity functions observed between\n4 < z < 8 and gravitational lensing models submitted by the community. However,\nin the first two deep infrared Hubble images obtained to date, we find z ~ 8\ncandidates but no strong candidates at z > 9. This might suggest a deficit of\nfaint z > 9 galaxies as also reported in the Ultra Deep Field (even while\nexcesses of brighter z > 9 galaxies were reported in shallower fields). At\nthese redshifts, cosmic variance (field-to-field variation) is expected to be\nsignificant (greater than +/-50%) and include clustering of early galaxies\nformed in overdensities. The full Frontier Fields program will significantly\nmitigate this uncertainty by observing six independent sightlines each with a\nlensing cluster and nearby blank field. \n\n"}
{"id": "1405.1452", "contents": "Title: Late-time cosmology with 21cm intensity mapping experiments Abstract: We present a framework for forecasting cosmological constraints from future\nneutral hydrogen intensity mapping experiments at low to intermediate\nredshifts. In the process, we establish a simple way of comparing such surveys\nwith optical galaxy redshift surveys. We explore a wide range of experimental\nconfigurations and assess how well a number of cosmological observables (the\nexpansion rate, growth rate, and angular diameter distance) and parameters (the\ndensities of dark energy and dark matter, spatial curvature, the dark energy\nequation of state, etc.) will be measured by an extensive roster of upcoming\nexperiments. A number of potential contaminants and systematic effects are also\nstudied in detail. The overall picture is encouraging -- if autocorrelation\ncalibration can be controlled to a sufficient level, Phase I of the SKA should\nbe able to constrain the dark energy equation of state about as well as a DETF\nStage IV galaxy redshift survey like Euclid, in roughly the same timeframe. \n\n"}
{"id": "1405.4892", "contents": "Title: Alternative Algorithms for Lyndon Factorization Abstract: We present two variations of Duval's algorithm for computing the Lyndon\nfactorization of a word. The first algorithm is designed for the case of small\nalphabets and is able to skip a significant portion of the characters of the\nstring, for strings containing runs of the smallest character in the alphabet.\nExperimental results show that it is faster than Duval's original algorithm,\nmore than ten times in the case of long DNA strings. The second algorithm\ncomputes, given a run-length encoded string $R$ of length $\\rho$, the Lyndon\nfactorization of $R$ in $O(\\rho)$ time and constant space. \n\n"}
{"id": "1405.5906", "contents": "Title: First Dark Matter Search Results from the Large Underground Xenon (LUX)\n  Experiment Abstract: The Large Underground Xenon (LUX) dark matter experiment is operating 1.5 km\nunderground at the Sanford Underground Research Facility in Lead, South Dakota,\nUSA. In 2013, the experiment had a WIMP search exposure of 10,091 kg-days over\na period of 85.3 live-days. This first dark matter search placed the world's\nmost stringent limits on WIMP-nucleon interaction cross-sections over a wide\nrange of WIMP masses, and is in tension with signal hints of low-mass WIMPs\nfrom DAMA, CoGeNT and CDMS-II Si. LUX will commence a 300 day run in 2014 that\nwill improve the sensitivity by a factor of 5. Low-energy calibrations obtained\nfrom a neutron double-scattering technique will further constrain and reduce\nsystematics, particularly for low WIMP masses. \n\n"}
{"id": "1405.6568", "contents": "Title: Lensing reconstruction from a patchwork of polarization maps Abstract: The lensing signals involved in CMB polarization maps have already been\nmeasured with ground-based experiments such as SPTpol and POLARBEAR, and would\nbecome important as a probe of cosmological and astrophysical issues in the\nnear future. Sizes of polarization maps from ground-based experiments are,\nhowever, limited by contamination of long wavelength modes of observational\nnoise. To further extract the lensing signals, we explore feasibility of\nmeasuring lensing signals from a collection of small sky maps each of which is\nobserved separately by a ground-based large telescope, i.e., lensing\nreconstruction from a patchwork map of large sky coverage organized from small\nsky patches. We show that, although the B-mode power spectrum obtained from the\npatchwork map is biased due to baseline uncertainty, bias on the lensing\npotential would be negligible if the B-mode on scales larger than the blowup\nscale of $1/f$ noise is removed in the lensing reconstruction. As examples of\ncosmological applications, we also show 1) the cross-correlations between the\nreconstructed lensing potential and full-sky temperature/polarization maps from\nsatellite missions such as PLANCK and LiteBIRD, and 2) the use of the\nreconstructed potential for delensing B-mode polarization of LiteBIRD\nobservation. \n\n"}
{"id": "1406.3284", "contents": "Title: Deep Neural Networks Rival the Representation of Primate IT Cortex for\n  Core Visual Object Recognition Abstract: The primate visual system achieves remarkable visual object recognition\nperformance even in brief presentations and under changes to object exemplar,\ngeometric transformations, and background variation (a.k.a. core visual object\nrecognition). This remarkable performance is mediated by the representation\nformed in inferior temporal (IT) cortex. In parallel, recent advances in\nmachine learning have led to ever higher performing models of object\nrecognition using artificial deep neural networks (DNNs). It remains unclear,\nhowever, whether the representational performance of DNNs rivals that of the\nbrain. To accurately produce such a comparison, a major difficulty has been a\nunifying metric that accounts for experimental limitations such as the amount\nof noise, the number of neural recording sites, and the number trials, and\ncomputational limitations such as the complexity of the decoding classifier and\nthe number of classifier training examples. In this work we perform a direct\ncomparison that corrects for these experimental limitations and computational\nconsiderations. As part of our methodology, we propose an extension of \"kernel\nanalysis\" that measures the generalization accuracy as a function of\nrepresentational complexity. Our evaluations show that, unlike previous\nbio-inspired models, the latest DNNs rival the representational performance of\nIT cortex on this visual object recognition task. Furthermore, we show that\nmodels that perform well on measures of representational performance also\nperform well on measures of representational similarity to IT and on measures\nof predicting individual IT multi-unit responses. Whether these DNNs rely on\ncomputational mechanisms similar to the primate visual system is yet to be\ndetermined, but, unlike all previous bio-inspired models, that possibility\ncannot be ruled out merely on representational performance grounds. \n\n"}
{"id": "1406.3626", "contents": "Title: A challenge to the $a$-theorem in six dimensions Abstract: The possibility of a strong $a$-theorem in six dimensions is examined in\nmulti-flavor $\\phi^3$ theory. Contrary to the case in two and four dimensions,\nwe find that in perturbation theory the relevant quantity $\\tilde{a}$ increases\nmonotonically along flows away from the trivial fixed point. $\\tilde{a}$ is a\nnatural extension of the coefficient $a$ of the Euler term in the trace\nanomaly, and it arises in any even spacetime dimension from an analysis based\non Weyl consistency conditions. We also obtain the anomalous dimensions and\nbeta functions of multi-flavor $\\phi^3$ theory to two loops. Our results\nsuggest that some new intuition about the $a$-theorem is in order. \n\n"}
{"id": "1406.4664", "contents": "Title: Mapping gravitational-wave backgrounds using methods from CMB analysis:\n  Application to pulsar timing arrays Abstract: We describe an alternative approach to the analysis of gravitational-wave\nbackgrounds, based on the formalism used to characterise the polarisation of\nthe cosmic microwave background. In contrast to standard analyses, this\napproach makes no assumptions about the nature of the background and so has the\npotential to reveal much more about the physical processes that generated it.\nAn arbitrary background can be decomposed into modes whose angular dependence\non the sky is given by gradients and curls of spherical harmonics. We derive\nthe pulsar timing overlap reduction functions for the individual modes, which\nare given by simple combinations of spherical harmonics evaluated at the pulsar\nlocations. We show how these can be used to recover the components of an\narbitrary background, giving explicit results for both isotropic and\nanisotropic uncorrelated backgrounds. We also find that the response of a\npulsar timing array to curl modes is identically zero, so half of the\ngravitational-wave sky will never be observed using pulsar timing, no matter\nhow many pulsars are included in the array. An isotropic, unpolarised and\nuncorrelated background can be accurately represented using only three modes,\nand so a search of this type will be only slightly more complicated than the\nstandard cross-correlation search using the Hellings and Downs overlap\nreduction function. However, by measuring the components of individual modes of\nthe background and checking for consistency with isotropy, this approach has\nthe potential to reveal much more information. Each individual mode on its own\ndescribes a background that is correlated between different points on the sky.\nA measurement of the components that indicates the presence of correlations in\nthe background on large angular scales would suggest startling new physics. \n\n"}
{"id": "1406.4716", "contents": "Title: Limitations in timing precision due to single-pulse shape variability in\n  millisecond pulsars Abstract: High-sensitivity radio-frequency observations of millisecond pulsars usually\nshow stochastic, broadband, pulse-shape variations intrinsic to the pulsar\nemission process. These variations induce jitter noise in pulsar timing\nobservations; understanding the properties of this noise is of particular\nimportance for the effort to detect gravitational waves with pulsar timing\narrays. We assess the short-term profile and timing stability of 22 millisecond\npulsars that are part of the Parkes Pulsar Timing Array sample by examining\nintra-observation arrival time variability and single-pulse phenomenology. In 7\nof the 22 pulsars, in the band centred at approximately 1400MHz, we find that\nthe brightest observations are limited by intrinsic jitter. We find consistent\nresults, either detections or upper limits, for jitter noise in other frequency\nbands. PSR J1909-3744 shows the lowest levels of jitter noise, which we\nestimate to contribute $\\sim$10 ns root mean square error to the arrival times\nfor hour-duration observations. Larger levels of jitter noise are found in\npulsars with wider pulses and distributions of pulse intensities. The jitter\nnoise in PSR J0437-4715 decorrelates over a bandwidth of $\\sim$2 GHz. We show\nthat the uncertainties associated with timing pulsar models can be improved by\nincluding physically motivated jitter uncertainties. Pulse-shape variations\nwill limit the timing precision at future, more sensitive, telescopes; it is\nimperative to account for this noise when designing instrumentation and timing\ncampaigns for these facilities. \n\n"}
{"id": "1406.6072", "contents": "Title: On fast Generation of Cosmological Random Fields Abstract: The statistical translation invariance of cosmological random fields is\nbroken by a finite survey boundary, correlating the observable Fourier modes.\nStandard methods for generating Gaussian fields either neglect these\ncorrelations, or are costly, or both. Here we report on a fast and exact\nsimulation method applicable to a wide class of two-point statistics that\nrequires the simulation of a periodic grid of only twice the survey side with\nfast Fourier transforms. Super-survey modes, dominating the covariance of power\nspectra beyond linear scales in galaxy surveys and causing the correlation of\nlarge and small scales, \"beat coupling\", or \"super-sample\" covariance, are\nprecisely accounted for in non-linear transformations of the Gaussian field. As\nan application, we simulate the CFHTLS $\\sim 7^\\circ \\times 7^\\circ$ W1 galaxy\ndensity field, modeled as a Poisson sampling of a lognormal density field. We\nshow that our simulations produce power spectra, $A^*$-power spectra,\ncounts-in-cells probability distributions as well as covariances perfectly\nconsistent with the data. In addition, our technique reproduces the information\nplateau beyond linear scales as observed previously in Sloan Digital Sky Survey\ngalaxy catalogs and in $N$-body simulations. Our method is thus an efficient\nyet powerful simulation and prediction tool for galaxy survey data and\ncovariances. \n\n"}
{"id": "1406.6904", "contents": "Title: PLB-spaces of holomorphic functions with logarithmic growth conditions Abstract: Countable projective limits of countable inductive limits, called PLB-spaces,\nof weighted Banach spaces of continuous functions have recently been\ninvestigated by Agethen, Bierstedt and Bonet. In a previous article, the author\nextended their investigation to the case of holomorphic functions and\ncharacterized when spaces over the unit disc w.r.t. weights whose decay,\nroughly speaking, is neither faster nor slower than that of a polynomial are\nultrabornological or barrelled. In this note, we prove a similar\ncharacterization for the case of weights which tend to zero logarithmically. \n\n"}
{"id": "1407.0881", "contents": "Title: Generic inference of inflation models by local non-Gaussianity Abstract: The presence of multiple fields during inflation might seed a detectable\namount of non-Gaussianity in the curvature perturbations, which in turn becomes\nobservable in present data sets like the cosmic microwave background (CMB) or\nthe large scale structure (LSS). Within this proceeding we present a fully\nanalytic method to infer inflationary parameters from observations by\nexploiting higher-order statistics of the curvature perturbations. To keep this\nanalyticity, and thereby to dispense with numerically expensive sampling\ntechniques, a saddle-point approximation is introduced whose precision has been\nvalidated for a numerical toy example. Applied to real data, this approach\nmight enable to discriminate among the still viable models of inflation. \n\n"}
{"id": "1407.2581", "contents": "Title: Comments on \"A Dark Matter Search with MALBEK\" Abstract: CoGeNT and MALBEK use p-type point contact germanium detectors to search for\nlow-mass dark matter particles. Both detectors enjoy identical intrinsic noise\ncharacteristics. However, MALBEK's data acquisition electronics severely\ndegrade the ability to separate signals originating in the bulk of the\ngermanium crystal from surface backgrounds, through a measurement of the\npreamplifier pulse rise-time in the sub-keVee energy range of interest. The\nphysical meaning of the parameter W$_{par}$ developed by the MAJORANA\ncollaboration to compensate for this limitation is clarified here. It is shown\nthat this parameter does not correlate to rise-time at low energy, and is\npresently unable to distinguish between surface and bulk events below $\\sim$1\nkeVee. This leads to a sizable overstatement of MALBEK's sensitivity to\nlow-mass dark matter particles, when employing aggressive W$_{par}$ cuts. \n\n"}
{"id": "1407.2600", "contents": "Title: Dark Sky Simulations: Early Data Release Abstract: The Dark Sky Simulations are an ongoing series of cosmological N-body\nsimulations designed to provide a quantitative and accessible model of the\nevolution of the large-scale Universe. Such models are essential for many\naspects of the study of dark matter and dark energy, since we lack a\nsufficiently accurate analytic model of non-linear gravitational clustering. In\nJuly 2014, we made available to the general community our early data release,\nconsisting of over 55 Terabytes of simulation data products, including our\nlargest simulation to date, which used $1.07 \\times 10^{12}~(10240^3)$\nparticles in a volume $8h^{-1}\\mathrm{Gpc}$ across. Our simulations were\nperformed with 2HOT, a purely tree-based adaptive N-body method, running on\n200,000 processors of the Titan supercomputer, with data analysis enabled by\nyt. We provide an overview of the derived halo catalogs, mass function, power\nspectra and light cone data. We show self-consistency in the mass function and\nmass power spectrum at the 1% level over a range of more than 1000 in particle\nmass. We also present a novel method to distribute and access very large\ndatasets, based on an abstraction of the World Wide Web (WWW) as a file system,\nremote memory-mapped file access semantics, and a space-filling curve index.\nThis method has been implemented for our data release, and provides a means to\nnot only query stored results such as halo catalogs, but also to design and\ndeploy new analysis techniques on large distributed datasets. \n\n"}
{"id": "1407.3146", "contents": "Title: Results on low mass WIMPs using an upgraded CRESST-II detector Abstract: The CRESST-II cryogenic dark matter search aims for the detection of WIMPs\nvia elastic scattering off nuclei in CaWO$_4$ crystals. We present results from\na low-threshold analysis of a single upgraded detector module. This module\nefficiently vetoes low energy backgrounds induced by $\\alpha$-decays on inner\nsurfaces of the detector. With an exposure of \\unit[29.35]{kg live days}\ncollected in 2013 we set a limit on spin-independent WIMP-nucleon scattering\nwhich probes a new region of parameter space for WIMP masses below\n\\unit[3]{GeV/c$^2$}, previously not covered in direct detection searches. A\npossible excess over background discussed for the previous CRESST-II phase 1\n(from 2009 to 2011) is not confirmed. \n\n"}
{"id": "1407.6990", "contents": "Title: The Intrinsic Alignment of Galaxies and its Impact on Weak Gravitational\n  Lensing in an Era of Precision Cosmology Abstract: The wealth of incoming and future cosmological observations will allow us to\nmap out the structure and evolution of the observable universe to an\nunprecedented level of precision. Among these observations is the weak\ngravitational lensing of galaxies, e.g., cosmic shear that measures the minute\ndistortions of background galaxy images by intervening cosmic structure. Weak\nlensing and cosmic shear promise to be a powerful probe of astrophysics and\ncosmology, constraining models of dark energy, measuring the evolution of\nstructure in the universe, and testing theories of gravity on cosmic scales.\nHowever, the intrinsic alignment of galaxies -- their shape and orientation\nbefore being lensed -- may pose a great challenge to the use of weak\ngravitational lensing as an accurate cosmological probe, and has been\nidentified as one of the primary physical systematic biases in cosmic shear\nstudies. Correlations between this intrinsic alignment and the lensing signal\ncan persist even for large physical separations, and isolating the effect of\nintrinsic alignment from weak lensing is not trivial. A great deal of work in\nthe last two decades has been devoted to understanding and characterizing this\nintrinsic alignment, which is also a direct and complementary probe of\nstructure formation and evolution in its own right. In this review, we report\nin a systematic way the state of our understanding of the intrinsic alignment\nof galaxies, with a particular emphasis on its large-scale impact on weak\nlensing measurements and methods for its isolation or mitigation. (Abridged) \n\n"}
{"id": "1407.7862", "contents": "Title: How chameleons core dwarfs with cusps Abstract: The presence of a scalar field that couples nonminimally and universally to\nmatter can enhance gravitational forces on cosmological scales while restoring\ngeneral relativity in the Solar neighborhood. In the intermediate regime,\nkinematically inferred masses experience an additional radial dependence with\nrespect to the underlying distribution of matter, which is caused by the\nincrement of gravitational forces with increasing distance from the Milky Way\ncenter. The same effect can influence the internal kinematics of subhalos and\ncause cuspy matter distributions to appear core-like. Specializing to the\nchameleon model as a worked example, we demonstrate this effect by tracing the\nscalar field from the outskirts of the Milky Way halo to its interior,\nsimultaneously fitting observed velocity dispersions of chemo-dynamically\ndiscriminated red giant populations in the Fornax and Sculptor dwarf\nspheroidals. Whereas in standard gravity these observations suggest that the\nmatter distribution of the dwarfs is cored, we find that in the presence of a\nchameleon field the assumption of a cuspy Navarro-Frenk-White profile becomes\nperfectly compatible with the data. Importantly, chameleon models also predict\nthe existence of slopes between two stellar subcomponents that in Newtonian\ngravity would be interpreted as a depletion of matter in the dwarf center.\nHence, an observation of such an apparently pathological scenario may serve as\na smoking gun for the presence of a chameleon field or a similar modification\nof gravity, independent of baryonic feedback effects. In general, measuring the\ndynamic mass profiles of the Milky Way dwarfs provides stronger constraints\nthan those inferred from the screening scale of the Solar System since these\nare located at greater distances from the halo center. \n\n"}
{"id": "1408.0799", "contents": "Title: Mapping the Cosmic Web with the largest all-sky surveys Abstract: Our view of the low-redshift Cosmic Web has been revolutionized by galaxy\nredshift surveys such as 6dFGS, SDSS and 2MRS. However, the trade-off between\ndepth and angular coverage limits a systematic three-dimensional account of the\nentire sky beyond the Local Volume (z<0.05). In order to reliably map the\nUniverse to cosmologically significant depths over the full celestial sphere,\none must draw on multiwavelength datasets and state-of-the-art photometric\nredshift techniques. We have undertaken a dedicated program of cross-matching\nthe largest photometric all-sky surveys -- 2MASS, WISE and SuperCOSMOS -- to\nobtain accurate redshift estimates of millions of galaxies. The first outcome\nof these efforts -- the 2MASS Photometric Redshift catalog (2MPZ, Bilicki et\nal. 2014a) -- has been publicly released and includes almost 1 million galaxies\nwith a mean redshift of z=0.08. Here we summarize how this catalog was\nconstructed and how using the WISE mid-infrared sample together with\nSuperCOSMOS optical data allows us to push to redshift shells of z~0.2--0.3 on\nunprecedented angular scales. Our catalogs, with ~20 million sources in total,\nprovide access to cosmological volumes crucial for studies of local galaxy\nflows (clustering dipole, bulk flow) and cross-correlations with the cosmic\nmicrowave background such as the integrated Sachs-Wolfe effect or lensing\nstudies. \n\n"}
{"id": "1408.1617", "contents": "Title: The First Source Counts at 18 microns from the AKARI NEP Survey Abstract: We present the first galaxy counts at 18 microns using the Japanese AKARI\nsatellite's survey at the North Ecliptic Pole (NEP), produced from the images\nfrom the NEP-Deep and NEP-Wide surveys covering 0.6 and 5.8 square degrees\nrespectively. We describe a procedure using a point source filtering algorithm\nto remove background structure and a minimum variance method for our source\nextraction and photometry that delivers the optimum signal to noise for our\nextracted sources, confirming this by comparison with standard photometry\nmethods. The final source counts are complete and reliable over three orders of\nmagnitude in flux density, resulting in sensitivities (80 percent completeness)\nof 0.15mJy and 0.3mJy for the NEP-Deep and NEP-Wide surveys respectively, a\nfactor of 1.3 deeper than previous catalogues constructed from this field. The\ndifferential source counts exhibit a characteristic upturn from Euclidean\nexpectations at around a milliJansky and a corresponding evolutionary bump\nbetween 0.2-0.4 mJy consistent with previous mid-infrared surveys with ISO and\nSpitzer at 15 and 24 microns. We compare our results with galaxy evolution\nmodels confirming the striking divergence from the non-evolving scenario. The\nmodels and observations are in broad agreement implying that the source counts\nare consistent with a strongly evolving population of luminous infrared\ngalaxies at redshifts higher than unity. Integrating our source counts down to\nthe limit of the NEP survey at the 150 microJy level we calculate that AKARI\nhas resolved approximately 55 percent of the 18 micron cosmic infrared\nbackground relative to the predictions of contemporary source count models. \n\n"}
{"id": "1408.3389", "contents": "Title: Multi-redshift limits on the 21cm power spectrum from PAPER Abstract: The epoch of reionization power spectrum is expected to evolve strongly with\nredshift, and it is this variation with cosmic history that will allow us to\nbegin to place constraints on the physics of reionization. The primary obstacle\nto the measurement of the EoR power spectrum is bright foreground emission. We\npresent an analysis of observations from the Donald C. Backer Precision Array\nfor Probing the Epoch of Reionization (PAPER) telescope which place new limits\non the HI power spectrum over the redshift range of $7.5<z<10.5$, extending\npreviously published single redshift results to cover the full range accessible\nto the instrument. To suppress foregrounds, we use filtering techniques that\ntake advantage of the large instrumental bandwidth to isolate and suppress\nforeground leakage into the interesting regions of $k$-space. Our 500 hour\nintegration is the longest such yet recorded and demonstrates this method to a\ndynamic range of $10^4$. Power spectra at different points across the redshift\nrange reveal the variable efficacy of the foreground isolation. Noise limited\nmeasurements of $\\Delta^2$ at $k=$0.2hMpc$^{-1}$ and z$=7.55$ reach as low as\n(48mK)$^2$ ($1\\sigma$). We demonstrate that the size of the error bars in our\npower spectrum measurement as generated by a bootstrap method is consistent\nwith the fluctuations due to thermal noise. Relative to this thermal noise,\nmost spectra exhibit an excess of power at a few sigma. The likely sources of\nthis excess include residual foreground leakage, particularly at the highest\nredshift, and unflagged RFI. We conclude by discussing data reduction\nimprovements that promise to remove much of this excess. \n\n"}
{"id": "1408.4374", "contents": "Title: Resonating valence-bond physics on the honeycomb lattice Abstract: We study bond and spin correlations of the nearest-neighbour resonating\nvalence bond (RVB) wavefunction for a SU($2$) symmetric $S=1/2$ antiferromagnet\non the honeycomb lattice. We find that spin correlations in this wavefunction\nare short-ranged, while the bond energy correlation function takes on an\noscillatory power-law form $D(\\vec{r}) \\sim \\cos({\\mathbf Q}\\cdot {\\vec{r}})\n/|{\\vec{r}}|^{\\eta_w(2)}$, where ${\\mathbf Q} = (2\\pi/3, -2\\pi/3)$ is the\nwavevector corresponding to \"columnar\" valence-bond solid order on the\nhoneycomb lattice, and $\\eta_w(2) \\approx 1.49(3)$. We use a recently\nintroduced large-$g$ expansion approach to relate bond-energy correlators of\nthe SU($g$) wavefunction to dimer correlations of an interacting fully-packed\ndimer model with a three-dimer interaction of strength $V(g)=-\\log(1+1/g^2)$.\nPutting $g=2$, we find numerically that the dimer correlation function\n$D^{d}(\\vec{r})$ of this dimer model has power-law behaviour $D^{d}(\\vec{r})\n\\sim \\cos({\\mathbf Q}\\cdot {\\vec{r}}) /|{\\vec{r}}|^{\\eta_d(2)}$ with $\\eta_d(2)\n\\approx 1.520(15)$, in rather good agreement with the wavefunction results. We\nalso study the same quantities for $g=3,4,10$ and find that the bond-energy\ncorrelations in the SU($g$) wavefunction are consistently well-reproduced by\nthe corresponding dimer correlations in the interacting dimer model. \n\n"}
{"id": "1408.6709", "contents": "Title: The Superhorizon Test of Future B-mode Experiments Abstract: Inflation predicts B-mode polarization with correlations that span\nsuperhorizon scales at recombination. In contrast, the correlations set up by\ncausal sources, such as phase transitions or defects, necessarily vanish on\nsuperhorizon scales. Motivated by BICEP2's B-mode detection, we consider the\nprospects for measuring the inflationary superhorizon signature in future\nobservations. We explain that the finite resolution of an experiment and the\nfiltering of the raw data induces a transfer of spurious subhorizon power to\nsuperhorizon scales, and describe ways to correct for it. We also provide a\ndetailed treatment of possible sources of noise in the measurement. Finally, we\npresent forecasts for the detectability of the signal with future CMB\npolarization experiments. \n\n"}
{"id": "1409.1570", "contents": "Title: Is the quantum state real? An extended review of $\\psi$-ontology\n  theorems Abstract: Towards the end of 2011, Pusey, Barrett and Rudolph derived a theorem that\naimed to show that the quantum state must be ontic (a state of reality) in a\nbroad class of realist approaches to quantum theory. This result attracted a\nlot of attention and controversy. The aim of this review article is to review\nthe background to the Pusey--Barrett--Rudolph Theorem, to provide a clear\npresentation of the theorem itself, and to review related work that has\nappeared since the publication of the Pusey--Barrett--Rudolph paper. In\nparticular, this review: Explains what it means for the quantum state to be\nontic or epistemic (a state of knowledge); Reviews arguments for and against an\nontic interpretation of the quantum state as they existed prior to the\nPusey--Barrett--Rudolph Theorem; Explains why proving the reality of the\nquantum state is a very strong constraint on realist theories in that it would\nimply many of the known no-go theorems, such as Bell's Theorem and the need for\nan exponentially large ontic state space; Provides a comprehensive presentation\nof the Pusey--Barrett--Rudolph Theorem itself, along with subsequent\nimprovements and criticisms of its assumptions; Reviews two other arguments for\nthe reality of the quantum state: the first due to Hardy and the second due to\nColbeck and Renner, and explains why their assumptions are less compelling than\nthose of the Pusey--Barrett--Rudolph Theorem; Reviews subsequent work aimed at\nruling out stronger notions of what it means for the quantum state to be\nepistemic and points out open questions in this area. The overall aim is not\nonly to provide the background needed for the novice in this area to understand\nthe current status, but also to discuss often overlooked subtleties that should\nbe of interest to the experts. \n\n"}
{"id": "1409.2858", "contents": "Title: Monthly Modulation in Dark Matter Direct-Detection Experiments Abstract: The signals in dark matter direct-detection experiments should exhibit\nmodulation signatures due to the Earth's motion with respect to the Galactic\ndark matter halo. The annual and daily modulations, due to the Earth's\nrevolution about the Sun and rotation about its own axis, have been explored\npreviously. Monthly modulation is another such feature present in direct\ndetection signals, and provides a nearly model-independent method of\ndistinguishing dark matter signal events from background. We study here monthly\nmodulations in detail for both WIMP and WISP dark matter searches, examining\nboth the effect of the motion of the Earth about the Earth-Moon barycenter and\nthe gravitational focusing due to the Moon. For WIMP searches, we calculate the\nmonthly modulation of the count rate and show the effects are too small to be\nobserved in the foreseeable future. For WISP dark matter experiments, we show\nthat the photons generated by WISP to photon conversion have frequencies which\nundergo a monthly modulating shift which is detectable with current technology\nand which cannot in general be neglected in high resolution WISP searches. \n\n"}
{"id": "1409.3409", "contents": "Title: CosmoSIS: modular cosmological parameter estimation Abstract: Cosmological parameter estimation is entering a new era. Large collaborations\nneed to coordinate high-stakes analyses using multiple methods; furthermore\nsuch analyses have grown in complexity due to sophisticated models of cosmology\nand systematic uncertainties. In this paper we argue that modularity is the key\nto addressing these challenges: calculations should be broken up into\ninterchangeable modular units with inputs and outputs clearly defined. We\npresent a new framework for cosmological parameter estimation, CosmoSIS,\ndesigned to connect together, share, and advance development of inference tools\nacross the community. We describe the modules already available in CosmoSIS,\nincluding CAMB, Planck, cosmic shear calculations, and a suite of samplers. We\nillustrate it using demonstration code that you can run out-of-the-box with the\ninstaller available at http://bitbucket.org/joezuntz/cosmosis \n\n"}
{"id": "1409.4441", "contents": "Title: Using hybrid GPU/CPU kernel splitting to accelerate spherical\n  convolutions Abstract: We present a general method for accelerating by more than an order of\nmagnitude the convolution of pixelated functions on the sphere with a\nradially-symmetric kernel. Our method splits the kernel into a compact\nreal-space component and a compact spherical harmonic space component. These\ncomponents can then be convolved in parallel using an inexpensive commodity GPU\nand a CPU. We provide models for the computational cost of both real-space and\nFourier space convolutions and an estimate for the approximation error. Using\nthese models we can determine the optimum split that minimizes the wall clock\ntime for the convolution while satisfying the desired error bounds. We apply\nthis technique to the problem of simulating a cosmic microwave background (CMB)\nanisotropy sky map at the resolution typical of the high resolution maps\nproduced by the Planck mission. For the main Planck CMB science channels we\nachieve a speedup of over a factor of ten, assuming an acceptable fractional\nrms error of order 1.e-5 in the power spectrum of the output map. \n\n"}
{"id": "1409.5516", "contents": "Title: Implications of fast radio bursts for superconducting cosmic strings Abstract: Highly beamed, short-duration electromagnetic bursts could be produced by\nsuperconducting cosmic string (SCS) loops oscillating in cosmic magnetic\nfields. We demonstrated that the basic characteristics of SCS bursts such as\nthe electromagnetic frequency and the energy release could be consistently\nexhibited in the recently discovered fast radio bursts (FRBs). Moreover, it is\nfirst showed that the redshift distribution of the FRBs can also be well\naccounted for by the SCS burst model. Such agreements between the FRBs and SCS\nbursts suggest that the FRBs could originate from SCS bursts and thus they\ncould provide an effective probe to study SCSs. The obtained values of model\nparameters indicate that the loops generating the FRBs have a small length\nscale and they are mostly formed in the radiation-dominated cosmological epoch. \n\n"}
{"id": "1409.6543", "contents": "Title: The Good, the Bad and the Ugly: Statistical quality assessment of SZ\n  detections Abstract: We examine three approaches to the problem of source classification in\ncatalogues. Our goal is to determine the confidence with which the elements in\nthese catalogues can be distinguished in populations on the basis of their\nspectral energy distribution (SED). Our analysis is based on the projection of\nthe measurements onto a comprehensive SED model of the main signals in the\nconsidered range of frequencies. We first first consider likelihood analysis,\nwhich half way between supervised and unsupervised methods. Next, we\ninvestigate an unsupervised clustering technique. Finally, we consider a\nsupervised classifier based on Artificial Neural Networks. We illustrate the\napproach and results using catalogues from various surveys. i.e., X-Rays\n(MCXC), optical (SDSS) and millimetric (Planck Sunyaev-Zeldovich (SZ)). We show\nthat the results from the statistical classifications of the three methods are\nin very good agreement with each others, although the supervised neural\nnetwork-based classification shows better performances allowing the best\nseparation into populations of reliable and unreliable sources in catalogues.\nThe latest method was applied to the SZ sources detected by the Planck\nsatellite. It led to a classification assessing and thereby agreeing with the\nreliability assessment published in the Planck SZ catalogue. Our method could\neasily be applied to catalogues from future large survey such as SRG/eROSITA\nand Euclid. \n\n"}
{"id": "1409.7718", "contents": "Title: Comparing Planck and WMAP: Maps, Spectra, and Parameters Abstract: We examine the consistency of WMAP9 and Planck data. We compare sky maps,\npower spectra, and inferred LCDM cosmological parameters. Residual dipoles are\nseen in the WMAP and Planck sky map differences, but are consistent within the\nuncertainties and are not large enough to explain the widely-noted differences\nin angular power spectra at higher l. After removing residual dipoles and\ngalactic foregrounds, the residual difference maps exhibit a quadrupole and\nother large-scale systematic structure. We identify this structure as possibly\noriginating from Planck's beam sidelobe pick-up, but note that it appears to\nhave insignificant cosmological impact. We develop an extension of the internal\nlinear combination technique and find features that plausibly originate in the\nPlanck data. We examine LCDM model fits to the angular power spectra and\nconclude that the ~2.5% difference in the spectra at multipoles greater than\nl~100 are significant at the 3-5 sigma level. We revisit the analysis of WMAP's\nbeam data and conclude that previously-derived uncertainties are robust and\ncannot explain the power spectrum differences. Finally, we examine the\nconsistency of the LCDM parameters inferred from each data set taking into\naccount the fact that both experiments observe the same sky, but cover\ndifferent multipole ranges, apply different sky masks, and have different\nnoise. While individual parameter values agree within the uncertainties, the 6\nparameters taken together are discrepant at the ~6 sigma level, with chi2=56\nfor 6 dof (PTE = 3e-10). Of the 6 parameters, chi2 is best improved by\nmarginalizing over Omega_c h^2, giving chi2=5.2 for 5 degrees of freedom. We\nfind that perturbing the WMAP window function by its dominant beam error\nprofile has little effect on Omega_c h^2, while perturbing the Planck window\nfunction by its corresponding error profile has a much greater effect on\nOmega_c h^2. \n\n"}
{"id": "1409.8165", "contents": "Title: Theory for Baryon Number and Dark Matter at the LHC Abstract: We investigate the possibility to test the simplest theory for spontaneous\nbaryon number violation at the Large Hadron Collider. In this context the\nbaryon number is a local gauge symmetry spontaneously broken at the low scale\nthrough the Brout-Englert-Higgs mechanism. This theory predicts the existence\nof a leptophobic neutral gauge boson and a fermionic dark matter candidate with\nbaryon number. We study the gauge boson and Higgs decays, and explore the\nconnection between collider signatures and constraints coming from dark matter\nexperiments. We point out an upper bound on the symmetry breaking scale using\nthe relic density constraints which tells us that this model can be tested or\nruled out at current or future collider experiments. \n\n"}
{"id": "1409.8242", "contents": "Title: Precision Tests of Parity Violation Over Cosmological Distances Abstract: Recent measurements of the Cosmic Microwave Background $B$-mode polarization\npower spectrum by the BICEP2 and POLARBEAR experiments have demonstrated new\nprecision tools for probing fundamental physics. Regardless of origin, the fact\nthat we can detect sub-$\\mu$K CMB polarization represents a tremendous\ntechnological breakthrough. Yet more information may be latent in the CMB's\npolarization pattern. Because of its tensorial nature, CMB polarization may\nalso reveal parity-violating physics via a detection of cosmic polarization\nrotation. Although current CMB polarimeters are sensitive enough to measure one\ndegree-level polarization rotation with $>5\\sigma$ statistical significance,\nthey lack the ability to differentiate this effect from a systematic\ninstrumental polarization rotation. Here, we motivate the search for cosmic\npolarization rotation from current CMB data as well as independent radio galaxy\nand quasar polarization measurements. We argue that an improvement in\ncalibration accuracy would allow the precise measurement of parity- and\nLorentz-violating effects. We describe the CalSat space-based polarization\ncalibrator that will provide stringent control of systematic polarization angle\ncalibration uncertainties to $0.05^\\circ$ -- an order of magnitude improvement\nover current CMB polarization calibrators. CalSat-based calibration could be\nused with current CMB polarimeters searching for $B$-mode polarization,\neffectively turning them into probes of cosmic parity violation, i.e. without\nthe need to build dedicated instruments. \n\n"}
{"id": "1410.0109", "contents": "Title: Milky Way dust extinction measured with QSOs Abstract: We investigate reddening by Milky Way dust in the low-extinction regime of\n$E_{B-V}<0.15$. Using over 50,000 QSOs at $0.5<z<2.5$ from the SDSS DR7 QSO\nCatalogue we probe the residual SDSS colours after dereddening and correcting\nfor the known spectroscopic redshifts. We find that the extinction vector of\nSchlafly & Finkbeiner (2011) is a better fit to the data than that used by\nSchlegel et al. (1998, SFD). There is evidence for a non-linearity in the SFD\nreddening map, which is similarly present in the V1.2 map of the Planck\nCollaboration. This non-linearity is similarly seen when galaxies or stars are\nused as probes of the SFD map. \n\n"}
{"id": "1410.0653", "contents": "Title: First Results from the DarkSide-50 Dark Matter Experiment at Laboratori\n  Nazionali del Gran Sasso Abstract: We report the first results of DarkSide-50, a direct search for dark matter\noperating in the underground Laboratori Nazionali del Gran Sasso (LNGS) and\nsearching for the rare nuclear recoils possibly induced by weakly interacting\nmassive particles (WIMPs). The dark matter detector is a Liquid Argon Time\nProjection Chamber with a (46.4+-0.7) kg active mass, operated inside a 30 t\norganic liquid scintillator neutron veto, which is in turn installed at the\ncenter of a 1 kt water Cherenkov veto for the residual flux of cosmic rays. We\nreport here the null results of a dark matter search for a (1422+-67) kg d\nexposure with an atmospheric argon fill. This is the most sensitive dark matter\nsearch performed with an argon target, corresponding to a 90% CL upper limit on\nthe WIMP-nucleon spin-independent cross section of 6.1x10^-44 cm^2 for a WIMP\nmass of 100 GeV/c^2. \n\n"}
{"id": "1410.0685", "contents": "Title: MultiModeCode: An efficient numerical solver for multifield inflation Abstract: We present MultiModeCode, a Fortran 95/2000 package for the numerical\nexploration of multifield inflation models. This program facilitates efficient\nMonte Carlo sampling of prior probabilities for inflationary model parameters\nand initial conditions and is the first publicly available code that can\nefficiently generate large sample-sets for inflation models with $\\mathcal\nO(100)$ fields. The code numerically solves the equations of motion for the\nbackground and first-order perturbations of multi-field inflation models with\ncanonical kinetic terms and arbitrary potentials, providing the adiabatic,\nisocurvature, and tensor power spectra at the end of inflation. For models with\nsum-separable potentials MultiModeCode also computes the slow-roll prediction\nvia the $\\delta N$ formalism for easy model exploration and validation. We pay\nparticular attention to the isocurvature perturbations as the system approaches\nthe adiabatic limit, showing how to avoid numerical instabilities that affect\nsome other approaches to this problem. We demonstrate the use of MultiModeCode\nby exploring a few toy models. Finally, we give a concise review of multifield\nperturbation theory and a user's manual for the program. \n\n"}
{"id": "1410.0875", "contents": "Title: A Comparison of Cosmological Models Using Strong Gravitational Lensing\n  Galaxies Abstract: Strongly gravitationally lensed quasar-galaxy systems allow us to compare\ncompeting cosmologies as long as one can be reasonably sure of the mass\ndistribution within the intervening lens. In this paper, we assemble a catalog\nof 69 such systems, and carry out a one-on-one comparison between the standard\nmodel, LCDM, and the R_h=ct Universe. We find that both models account for the\nlens observations quite well, though the precision of these measurements does\nnot appear to be good enough to favor one model over the other. Part of the\nreason is the so-called bulge-halo conspiracy that, on average, results in a\nbaryonic velocity dispersion within a fraction of the optical effective radius\nvirtually identical to that expected for the whole luminous-dark matter\ndistribution. Given the limitations of doing precision cosmological testing\nusing the current sample, we also carry out Monte Carlo simulations based on\nthe current lens measurements to estimate how large the source catalog would\nhave to be in order to rule out either model at a ~99.7% confidence level. We\nfind that if the real cosmology is LCDM, a sample of ~200 strong gravitational\nlenses would be sufficient to rule out R_h=ct at this level of accuracy, while\n~300 strong gravitational lenses would be required to rule out LCDM if the real\nUniverse were instead R_h=ct. The difference in required sample size reflects\nthe greater number of free parameters available to fit the data with LCDM. We\npoint out that, should the R_h=ct Universe eventually emerge as the correct\ncosmology, its lack of any free parameters for this kind of work will provide a\nremarkably powerful probe of the mass structure in lensing galaxies, and a\nmeans of better understanding the origin of the bulge-halo conspiracy. \n\n"}
{"id": "1410.0958", "contents": "Title: Research Update on Extreme-Mass-Ratio Inspirals Abstract: The inspirals of stellar-mass mass compact objects into massive black holes\nin the centres of galaxies are one of the most important sources of\ngravitational radiation for space-based detectors like LISA or eLISA. These\nextreme-mass-ratio inspirals (EMRIs) will enable an ambitious research program\nwith implications for astrophysics, cosmology, and fundamental physics. This\narticle is a summary of the talks delivered at the plenary session on EMRIs at\nthe 10th International LISA Symposium. It contains research updates on the\nfollowing topics: astrophysics of EMRIs; EMRI science potential; and EMRI\nmodeling. \n\n"}
{"id": "1410.0963", "contents": "Title: Mapmaking for Precision 21 cm Cosmology Abstract: In order to study the \"Cosmic Dawn\" and the Epoch of Reionization with 21 cm\ntomography, we need to statistically separate the cosmological signal from\nforegrounds known to be orders of magnitude brighter. Over the last few years,\nwe have learned much about the role our telescopes play in creating a\nputatively foreground-free region called the \"EoR window.\" In this work, we\nexamine how an interferometer's effects can be taken into account in a way that\nallows for the rigorous estimation of 21 cm power spectra from interferometric\nmaps while mitigating foreground contamination and thus increasing sensitivity.\nThis requires a precise understanding of the statistical relationship between\nthe maps we make and the underlying true sky. While some of these calculations\nwould be computationally infeasible if performed exactly, we explore several\nwell-controlled approximations that make mapmaking and the calculation of map\nstatistics much faster, especially for compact and highly redundant\ninterferometers designed specifically for 21 cm cosmology. We demonstrate the\nutility of these methods and the parametrized trade-offs between accuracy and\nspeed using one such telescope, the upcoming Hydrogen Epoch of Reionization\nArray, as a case study. \n\n"}
{"id": "1410.1003", "contents": "Title: Maximum Likelihood Analysis of Low Energy CDMS II Germanium Data Abstract: We report on the results of a search for a Weakly Interacting Massive\nParticle (WIMP) signal in low-energy data of the Cryogenic Dark Matter Search\n(CDMS~II) experiment using a maximum likelihood analysis. A background model is\nconstructed using GEANT4 to simulate the surface-event background from\n$^{210}$Pb decay-chain events, while using independent calibration data to\nmodel the gamma background. Fitting this background model to the data results\nin no statistically significant WIMP component. In addition, we perform fits\nusing an analytic ad hoc background model proposed by Collar and Fields, who\nclaimed to find a large excess of signal-like events in our data. We confirm\nthe strong preference for a signal hypothesis in their analysis under these\nassumptions, but excesses are observed in both single- and multiple-scatter\nevents, which implies the signal is not caused by WIMPs, but rather reflects\nthe inadequacy of their background model. \n\n"}
{"id": "1410.1753", "contents": "Title: A detector module with highly efficient surface-alpha event rejection\n  operated in CRESST-II Phase 2 Abstract: The cryogenic dark matter experiment CRESST-II aims at the direct detection\nof WIMPs via elastic scattering off nuclei in scintillating CaWO$_4$ crystals.\nWe present a new, highly improved, detector design installed in the current run\nof CRESST-II Phase 2 with an efficient active rejection of surface-alpha\nbackgrounds. Using CaWO$_4$ sticks instead of metal clamps to hold the target\ncrystal, a detector housing with fully-scintillating inner surface could be\nrealized. The presented detector (TUM40) provides an excellent threshold of\n${\\sim}\\,0.60\\,$keV and a resolution of $\\sigma\\,{\\approx}\\,0.090$ keV (at\n2.60$\\,$keV). With significantly reduced background levels, TUM40 sets\nstringent limits on the spin-independent WIMP-nucleon scattering cross section\nand probes a new region of parameter space for WIMP masses below\n3$\\,$GeV/c$^2$. In this paper, we discuss the novel detector design and the\nsurface-alpha event rejection in detail. \n\n"}
{"id": "1410.2544", "contents": "Title: A CMB Gibbs sampler for localized secondary anisotropies Abstract: As well as primary fluctuations, CMB temperature maps contain a wealth of\nadditional information in the form of secondary anisotropies. Secondary effects\nthat can be identified with individual objects, such as the thermal and kinetic\nSunyaev-Zel'dovich (SZ) effects due to galaxy clusters, are difficult to\nunambiguously disentangle from foreground contamination and the primary CMB\nhowever. We develop a Bayesian formalism for rigorously characterising\nanisotropies that are localised on the sky, taking the TSZ and KSZ effects as\nan example. Using a Gibbs sampling scheme, we are able to efficiently sample\nfrom the joint posterior distribution for a multi-component model of the sky\nwith many thousands of correlated physical parameters. The posterior can then\nbe exactly marginalised to estimate properties of the secondary anisotropies,\nfully taking into account degeneracies with the other signals in the CMB map.\nWe show that this method is computationally tractable using a simple\nimplementation based on the existing Commander component separation code, and\nalso discuss how other types of secondary anisotropy can be accommodated within\nour framework. \n\n"}
{"id": "1410.2749", "contents": "Title: Directional detection of dark matter streams Abstract: Directional detection of WIMPs, in which the energies and directions of the\nrecoiling nuclei are measured, currently presents the only prospect for probing\nthe local velocity distribution of Galactic dark matter. We investigate the\nextent to which future directional detectors would be capable of probing dark\nmatter substructure in the form of streams. We analyse the signal expected from\na Sagittarius-like stream and also explore the full parameter space of stream\nspeed, direction, dispersion and density. Using a combination of non-parametric\ndirectional statistics, a profile likelihood ratio test and Bayesian parameter\ninference we find that within acceptable exposure times (O(10) kg yr for cross\nsections just below the current exclusion limits) future directional detectors\nwill be sensitive to a wide range of stream velocities and densities. We also\nexamine and discuss the importance of the energy window of the detector. \n\n"}
{"id": "1410.3323", "contents": "Title: Searching for gravitational wave memory bursts with the Parkes Pulsar\n  Timing Array Abstract: Anisotropic bursts of gravitational radiation produced by events such as\nsuper-massive black hole mergers leave permanent imprints on space. Such\ngravitational wave \"memory\" (GWM) signals are, in principle, detectable through\npulsar timing as sudden changes in the apparent pulse frequency of a pulsar. If\nan array of pulsars is monitored as a GWM signal passes over the Earth, the\npulsars would simultaneously appear to change pulse frequency by an amount that\nvaries with their sky position in a quadrupolar fashion. Here we describe a\nsearch algorithm for such events and apply the algorithm to approximately six\nyears of data from the Parkes Pulsar Timing Array. We find no GWM events and\nset an upper bound on the rate for events which could have been detected. We\nshow, using simple models of black hole coalescence rates, that this\nnon-detection is not unexpected. \n\n"}
{"id": "1410.3400", "contents": "Title: A Landesman-Lazer type result for periodic parabolic problems on\n  $\\mathbb{R}^N$ at resonance Abstract: We are concerned with $T$-periodic solutions of nonautonomous parabolic\nproblem of the form $u_t = \\Delta u + V(x) u + f(t,x,u)$, $t >0$, $x \\in\n\\mathbb{R}^N$, with $V \\in L^\\infty (\\mathbb{R}^N)+L^p(\\mathbb{R}^N)$, $p \\geq\nN$ and $T$-periodic continuous perturbation $f:\\mathbb{R}^N\\times \\mathbb{R}\n\\to \\mathbb{R}$. The so-called resonant case is considered, i.e. when ${\\cal\nN}:=\\mathrm{Ker} (\\Delta + V) \\neq \\{0\\}$ and $f$ is bounded by a\nsquare-integrable function. We derive a formula for the fixed point index of\nthe associated translation along trajectories operator in terms of the Brouwer\ntopological degree of the time average mapping $\\hat f: {\\cal N}\\to {\\cal N}$\nbeing the restriction of $f$ to ${\\cal N}$. By use of the formula and\ncontinuation techniques we show that Landesman-Lazer type conditions imply the\nexistence of $T$-periodic solutions. \n\n"}
{"id": "1410.3480", "contents": "Title: The Galaxy Population In Voids: Are All Voids The Same? Abstract: The influence of under-dense environments on the formation and evolution of\ngalaxies is studied by analysing the photometric properties of ~200 galaxies\nresiding in voids, taken from our SDSS DR10 void catalogue up to z ~0.055. We\nsplit void galaxies into two subsamples based on the luminosity density\ncontrast of their host voids: 'sparse void' {\\delta}_s = {\\delta} < -0.95 and\n'populous void' {\\delta}_p = {\\delta} > -0.87. We find that galaxies in sparse\nvoids are less massive than galaxies in populous voids. The luminosity\ndistribution of galaxies in populous voids follows the same distribution\nobserved across the SDSS survey in the same redshift range. Galaxies in the\nsparse voids are also bluer suggesting that they may be going through a\nrelatively slow and continuous star formation. Additionally, we find that the\nluminosity function of galaxies in populous voids is represented with the\nSchechter function whereas the same does not hold for sparse voids. Our\nanalysis suggests that the properties of a host void plays a significant role\nin the formation and evolution of the void galaxies and determining the large\nscale evolution of voids is an important step to understand what processes\nregulate the evolution of galaxies. \n\n"}
{"id": "1410.3660", "contents": "Title: Simulations of cm-wavelength Sunyaev-Zel'dovich galaxy cluster and point\n  source blind sky surveys and predictions for the RT32/OCRA-f and the Hevelius\n  100-m radio telescope Abstract: We investigate the effectiveness of blind surveys for radio sources and\ngalaxy cluster thermal Sunyaev-Zel'dovich effects (TSZEs) using the four-pair,\nbeam-switched OCRA-f radiometer on the 32-m radio telescope in Poland. The\npredictions are based on mock maps that include the cosmic microwave\nbackground, TSZEs from hydrodynamical simulations, and unresolved radio\nsources. We estimate the effects of source clustering towards galaxy clusters\nfrom NVSS source counts around Planck-selected cluster candidates, and include\nappropriate correlations in our mock maps. The study allows us to quantify the\neffects of halo line-of-sight alignments, source confusion, and telescope\nangular resolution on the detections of TSZEs.\n  We perform a similar analysis for the planned 100-m Hevelius radio telescope\n(RTH) equipped with a 49-beam radio camera.\n  We find that RT32/OCRA-f will be suitable for small-field blind radio source\nsurveys, and will detect $33^{+17}_{-11}$ new radio sources brighter than 0.87\nmJy at 30~GHz in a 1 deg$^2$ field at $>5\\sigma$ CL during a one-year,\nnon-continuous, observing campaign, taking account of Polish weather\nconditions. It is unlikely that any galaxy cluster will be detected at\n$3\\sigma$ CL in such a survey. A $60$-deg$^2$ survey, with field coverage of\n$2^2$ beams per pixel, at 15 GHz with the RTH, would find <1.5 galaxy clusters\nper year brighter than 60 $\\mu$Jy (at $3\\sigma$ CL), and would detect about\n$3.4 \\times 10^4$ point sources brighter than 1 mJy at $5\\sigma$ CL, with\nconfusion causing flux density errors $\\lesssim 2\\%$ (20%) in 68% (95%) of the\ndetected sources.\n  A primary goal of the planned RTH will be a wide-area ($\\pi$~sr) radio source\nsurvey at 15 GHz. This survey will detect nearly $3 \\times 10^5$ radio sources\nat $5\\sigma$ CL down to 1.3 mJy, and tens of galaxy clusters, in one year of\noperation with typical weather conditions. ABRIDGED \n\n"}
{"id": "1410.7673", "contents": "Title: DEAP-3600 Dark Matter Search Abstract: The DEAP-3600 experiment is located 2 km underground at SNOLAB, in Sudbury,\nOntario. It is a single-phase detector that searches for dark matter particle\ninteractions within a 1000-kg fiducial mass target of liquid argon. A first\ngeneration prototype detector (DEAP-1) with a 7-kg liquid argon target mass\ndemonstrated a high level of pulse-shape discrimination (PSD) for reducing\n$\\beta$/$\\gamma$ backgrounds and helped to develop low radioactivity techniques\nto mitigate surface-related $\\alpha$ backgrounds. Construction of the DEAP-3600\ndetector is nearly complete and commissioning is starting in 2014. The target\nsensitivity to spin-independent scattering of Weakly Interacting Massive\nParticles (WIMPs) on nucleons of 10$^{-46}$ cm$^2$ will allow one order of\nmagnitude improvement in sensitivity over current searches at 100 GeV WIMP\nmass. This paper presents an overview and status of the DEAP-3600 project and\ndiscusses plans for a future multi-tonne experiment, DEAP-50T. \n\n"}
{"id": "1410.8739", "contents": "Title: Constraining supernova progenitors: an integral field spectroscopic\n  survey of the explosion sites Abstract: We describe a survey of nearby core-collapse supernova (SN) explosion sites\nusing integral field spectroscopy (IFS) technique, which is an extension of the\nwork described in Kuncarayakti et al. (2013, AJ, 146, 30/31) . The project aims\nto constrain the SN progenitor properties based on the study of the SN\nimmediate environment. The stellar populations present at the SN explosion\nsites are studied by means of integral field spectroscopy, which enables the\nacquisition of both spatial and spectral information of the object\nsimultaneously. The spectrum of the SN parent stellar population gives the\nestimate of its age and metallicity. With this information, the initial mass\nand metallicity of the once coeval SN progenitor star are derived. While the\nsurvey is mostly done in optical, additionally the utilization of near-infrared\nintegral field spectroscopy assisted with adaptive optics (AO) enables us to\nexamine the explosion sites in high spatial details, down to a few parsecs.\nThis work is being carried out using multiple 2-8 m class telescopes equipped\nwith integral field spectrographs in Chile and Hawaii. \n\n"}
{"id": "1411.1189", "contents": "Title: Construction of a group of automorphisms for an infinite family of\n  Garside groups Abstract: The structure groups of non-degenerate symmetric set-theoretical solutions of\nthe quantum Yang-Baxter equation provide an infinite family of Garside groups\nwith many interesting properties. Given a non-degenerate symmetric solution, we\nconstruct for its structure group a group of automorphisms. Moreover, we show\nthis group of automorphisms admits a subgroup that preserves the Garside\nproperties of the structure group. In some cases, we could also prove the group\nof automorphisms obtained is an outer automorphism group. \n\n"}
{"id": "1411.5678", "contents": "Title: Cosmological Tests Using the Angular Size of Galaxy Clusters Abstract: We use measurements of the galaxy-cluster angular size versus redshift to\ntest and compare the standard model (LCDM) and the R_h=ct Universe. We show\nthat the latter fits the data with a reduced chi^2_dof=0.786 for a Hubble\nconstant H_0= 72.6 (-3.4+3.8) km/s/Mpc, and H_0 is the sole parameter in this\nmodel. By comparison, the optimal flat LCDM model, with two free parameters\n(including Omega_m=0.50 and H_0=73.9 (-9.5+10.6) km/s/Mpc), fits the\nangular-size data with a reduced chi^2_dof=0.806. On the basis of their\nchi^2_dof values alone, both models appear to account for the data very well in\nspite of the fact that the R_h=ct Universe expands at a constant rate, while\nLCDM does not. However, because of the different number of free parameters in\nthese models, selection tools, such as the Bayes Information Criterion, favour\nR_h=ct over LCDM with a likelihood of ~86% versus ~14%. These results impact\nthe question of galaxy growth at large redshifts. Previous work suggested an\ninconsistency with the underlying cosmological model unless elliptical and disk\ngalaxies grew in size by a surprisingly large factor ~6 from z~3 to 0. The fact\nthat both LCDM and R_h=ct fit the cluster-size measurements quite well casts\nsome doubt on the suggestion that the unexpected result with individual\ngalaxies may be due to the use of an incorrect expansion scenario, rather than\nastrophysical causes, such as mergers and/or selection effects. \n\n"}
{"id": "1411.7430", "contents": "Title: A Simple and Efficient Absorption Filter for Single Photons from a Cold\n  Atom Quantum Memory Abstract: The ability to filter unwanted light signals is critical to the operation of\nquantum memories based on neutral atom ensembles. Here we demonstrate an\nefficient frequency filter which uses a vapor cell filled with $^{85}$Rb and a\nbuffer gas to attenuate both residual laser light and noise photons by nearly\ntwo orders of magnitude with little loss to the single photons associated with\nour cold $^{87}$Rb quantum memory. This simple, passive filter provides an\nadditional 18 dB attenuation of our pump laser and erroneous spontaneous\nemissions for every 1 dB loss of the single photon signal. We show that the\naddition of a frequency filter increases the non-classical correlations and\nreadout efficiency of our quantum memory by $\\approx35\\%$. \n\n"}
{"id": "1411.7667", "contents": "Title: The MUSE 3D view of the Hubble Deep Field South Abstract: We observed the Hubble Deep Field South with the new panoramic integral field\nspectrograph MUSE that we built and just commissioned at the VLT. The data cube\nresulting from 27 hours of integration covers one arcmin^2 field of view at an\nunprecedented depth with a 1 sigma emission line surface brightness limit of\n1x$10^{-19}$ erg/s/cm$^2$/arcsec$^2$ and contains ~90,000 spectra. We present\nthe combined and calibrated data cube, and we perform a first-pass analysis of\nthe sources detected in the HDF-S imaging. We measured the redshifts of 189\nsources up to a magnitude F814W = 29.5, increasing by more than an order of\nmagnitude the number of known spectroscopic redshifts in this field. We also\ndiscovered 26 Lya emitting galaxies which are not detected in the HST WFPC2\ndeep broad band images.\n  The intermediate spectral resolution of 2.3{\\AA} allows us to separate\nresolved asymmetric Lya emitters, [O II] emitters, and C III] emitters and the\nlarge instantaneous wavelength range of 4500{\\AA} helps to identify single\nemission lines. We also show how the three dimensional information of MUSE\nhelps to resolve sources which are confused at ground-based image quality.\n  Overall, secure identifications are provided for 83% of the 227 emission line\nsources detected in the MUSE data cube and for 32% of the 586 sources\nidentified in the HST catalog of Casertano et al 2000. The overall redshift\ndistribution is fairly flat to z=6.3, with a reduction between z=1.5 to 2.9, in\nthe well-known redshift desert. The field of view of MUSE also allowed us to\ndetect 17 groups within the field. We checked that the number counts of [O II]\nand Ly-a emitters are roughly consistent with predictions from the literature.\nUsing two examples we demonstrate that MUSE is able to provide exquisite\nspatially resolved spectroscopic information on intermediate redshift galaxies\npresent in the field. \n\n"}
{"id": "1412.0871", "contents": "Title: Joint Measurability and Temporal Steering Abstract: Quintino et. al. (Phys. Rev. Lett. 113, 160402 (2014)) and Uola et. al.\n(Phys. Rev. Lett. 113, 160403 (2014)) have recently established an intrinsic\nrelation between non-joint measurability and Einstein-Podolsky- Rosen steering.\nThey showed that a set of measurements is incompatible (i.e., not jointly\nmeasurable) if and only if it can be used for the demonstration of steering. In\nthis paper, we prove the temporal analog of this result viz., a set of\nmeasurements are incompatible if and only if it exhibits temporal steering. \n\n"}
{"id": "1412.1111", "contents": "Title: The Q/U Imaging Experiment: Polarization Measurements of Radio Sources\n  at 43 and 95 GHz Abstract: We present polarization measurements of extragalactic radio sources observed\nduring the Cosmic Microwave Background polarization survey of the Q/U Imaging\nExperiment (QUIET), operating at 43 GHz (Q-band) and 95 GHz (W-band). We\nexamine sources selected at 20 GHz from the public, $>$40 mJy catalog of the\nAustralia Telescope (AT20G) survey. There are $\\sim$480 such sources within\nQUIET's four low-foreground survey patches, including the nearby radio galaxies\nCentaurus A and Pictor A. The median error on our polarized flux density\nmeasurements is 30--40 mJy per Stokes parameter. At S/N $> 3$ significance, we\ndetect linear polarization for seven sources in Q-band and six in W-band; only\n$1.3 \\pm 1.1$ detections per frequency band are expected by chance. For sources\nwithout a detection of polarized emission, we find that half of the sources\nhave polarization amplitudes below 90 mJy (Q-band) and 106 mJy (W-band), at 95%\nconfidence. Finally, we compare our polarization measurements to intensity and\npolarization measurements of the same sources from the literature. For the four\nsources with WMAP and Planck intensity measurements $>1$ Jy, the polarization\nfraction are above 1% in both QUIET bands. At high significance, we compute\npolarization fractions as much as 10--20% for some sources, but the effects of\nsource variability may cut that level in half for contemporaneous comparisons.\nOur results indicate that simple models---ones that scale a fixed polarization\nfraction with frequency---are inadequate to model the behavior of these sources\nand their contributions to polarization maps. \n\n"}
{"id": "1412.1599", "contents": "Title: A fast radio burst in the direction of the Carina dwarf spheroidal\n  galaxy Abstract: We report the real-time discovery of a fast radio burst (FRB 131104) with the\nParkes radio telescope in a targeted observation of the Carina dwarf spheroidal\ngalaxy. The dispersion measure of the burst is 779 cm$^{-3}$ pc, exceeding\npredictions for the maximum line-of-sight Galactic contribution by a factor of\n11. The temporal structure of the burst is characterized by an exponential\nscattering tail with a timescale of 2.0$^{+0.8}_{-0.5}$ ms at 1582 MHz that\nscales as frequency to the power $-$4.4$^{+1.6}_{-1.8}$ (all uncertainties\nrepresent 95% confidence intervals). We bound the intrinsic pulse width to be\n$<0.64$ ms due to dispersion smearing across a single spectrometer channel.\nSearches in 78 hours of follow-up observations with the Parkes telescope reveal\nno additional sporadic emission and no evidence for associated periodic radio\nemission. We hypothesize that the burst is associated with the Carina dwarf\ngalaxy. Follow-up observations at other wavelengths are necessary to test this\nhypothesis. \n\n"}
{"id": "1412.4079", "contents": "Title: Bayesian inference of CMB gravitational lensing Abstract: The Planck satellite, along with several ground based telescopes, have mapped\nthe cosmic microwave background (CMB) at sufficient resolution and\nsignal-to-noise so as to allow a detection of the subtle distortions due to the\ngravitational influence of the intervening matter distribution. A natural\nmodeling approach is to write a Bayesian hierarchical model for the lensed CMB\nin terms of the unlensed CMB and the lensing potential. So far there has been\nno feasible algorithm for inferring the posterior distribution of the lensing\npotential from the lensed CMB map. We propose a solution that allows efficient\nMarkov Chain Monte Carlo sampling from the joint posterior of the lensing\npotential and the unlensed CMB map using the Hamiltonian Monte Carlo technique.\nThe main conceptual step in the solution is a re-parameterization of CMB\nlensing in terms of the lensed CMB and the \"inverse lensing\" potential. We\ndemonstrate a fast implementation on simulated data including noise and a sky\ncut, that uses a further acceleration based on a very mild approximation of the\ninverse lensing potential. We find that the resulting Markov Chain has short\ncorrelation lengths and excellent convergence properties, making it promising\nfor application to high resolution CMB data sets of the future. \n\n"}
{"id": "1412.5743", "contents": "Title: Astronomy below the Survey Threshold Abstract: Astronomy at or below the 'survey threshold' has expanded significantly since\nthe publication of the original 'Science with the Square Kilometer Array' in\n1999 and its update in 2004. The techniques in this regime may be broadly (but\nfar from exclusively) defined as 'confusion' or 'P(D)' analyses (analyses of\none-point statistics), and 'stacking', accounting for the flux-density\ndistribution of noise-limited images co-added at the positions of objects\ndetected/isolated in a different waveband. Here we discuss the relevant issues,\npresent some examples of recent analyses, and consider some of the consequences\nfor the design and use of surveys with the SKA and its pathfinders. \n\n"}
{"id": "1412.6524", "contents": "Title: Dark Matter Particles in the Galactic Halo Abstract: The DAMA/LIBRA-phase1 and the former DAMA/NaI data (cumulative exposure 1.33\nton $\\times$ yr, corresponding to 14 annual cycles) give evidence at 9.3\n$\\sigma$ C.L. for the presence of Dark Matter (DM) particles in the galactic\nhalo, on the basis of the exploited model independent DM annual modulation\nsignature by using highly radio-pure NaI(Tl) target. Results and comparisons\nwill be shortly addressed as well as perspectives of the presently running\nDAMA/LIBRA-phase2. Finally, some arguments arisen in the discussion section of\nthis workshop are mentioned in the Appendix. \n\n"}
{"id": "1412.7437", "contents": "Title: Compressibility of positive semidefinite factorizations and quantum\n  models Abstract: We investigate compressibility of the dimension of positive semidefinite\nmatrices while approximately preserving their pairwise inner products. This can\neither be regarded as compression of positive semidefinite factorizations of\nnonnegative matrices or (if the matrices are subject to additional\nnormalization constraints) as compression of quantum models. We derive both\nlower and upper bounds on compressibility. Applications are broad and range\nfrom the statistical analysis of experimental data to bounding the one-way\nquantum communication complexity of Boolean functions. \n\n"}
{"id": "1412.8315", "contents": "Title: All-sky reconstruction of the primordial scalar potential from WMAP\n  temperature data Abstract: An essential quantity required to understand the physics of the early\nUniverse, in particular the inflationary epoch, is the primordial scalar\npotential $\\Phi$ and its statistics. We present for the first time an all-sky\nreconstruction of $\\Phi$ with corresponding $1\\sigma$-uncertainty from WMAP's\ncosmic microwave background (CMB) temperature data -- a map of the very early\nUniverse right after the inflationary epoch. This has been achieved by applying\na Bayesian inference method that separates the whole inverse problem of the\nreconstruction into many independent ones, each of them solved by an optimal\nlinear filter (Wiener filter). In this way, the three-dimensional potential\n$\\Phi$ gets reconstructed slice by slice resulting in a thick shell of nested\nspheres around the comoving distance to the last scattering surface. Each slice\nrepresents the primordial scalar potential $\\Phi$ projected onto a sphere with\ncorresponding distance. Furthermore, we present an advanced method for\ninferring $\\Phi$ and its power spectrum simultaneously from data, but argue\nthat applying it requires polarization data with high signal-to-noise levels\nnot available yet. Future CMB data should improve results significantly, as\npolarization data will fill the present $\\ell-$blind gaps of the\nreconstruction. \n\n"}
{"id": "1501.00495", "contents": "Title: The Needle in the 100 deg2 Haystack: Uncovering Afterglows of Fermi GRBs\n  with the Palomar Transient Factory Abstract: The Fermi Gamma-ray Space Telescope has greatly expanded the number and\nenergy window of observations of gamma-ray bursts (GRBs). However, the coarse\nlocalizations of tens to a hundred square degrees provided by the Fermi GRB\nMonitor instrument have posed a formidable obstacle to locating the bursts'\nhost galaxies, measuring their redshifts, and tracking their panchromatic\nafterglows. We have built a target-of-opportunity mode for the intermediate\nPalomar Transient Factory in order to perform targeted searches for Fermi\nafterglows. Here, we present the results of one year of this program: 8\nafterglow discoveries out of 35 searches. Two of the bursts with detected\nafterglows (GRBs 130702A and 140606B) were at low redshift (z=0.145 and 0.384\nrespectively) and had spectroscopically confirmed broad-line Type Ic\nsupernovae. We present our broadband follow-up including spectroscopy as well\nas X-ray, UV, optical, millimeter, and radio observations. We study possible\nselection effects in the context of the total Fermi and Swift GRB samples. We\nidentify one new outlier on the Amati relation. We find that two bursts are\nconsistent with a mildly relativistic shock breaking out from the progenitor\nstar, rather than the ultra-relativistic internal shock mechanism that powers\nstandard cosmological bursts. Finally, in the context of the Zwicky Transient\nFacility, we discuss how we will continue to expand this effort to find optical\ncounterparts of binary neutron star mergers that may soon be detected by\nAdvanced LIGO and Virgo. \n\n"}
{"id": "1501.00559", "contents": "Title: The Learnability of Unknown Quantum Measurements Abstract: Quantum machine learning has received significant attention in recent years,\nand promising progress has been made in the development of quantum algorithms\nto speed up traditional machine learning tasks. In this work, however, we focus\non investigating the information-theoretic upper bounds of sample complexity -\nhow many training samples are sufficient to predict the future behaviour of an\nunknown target function. This kind of problem is, arguably, one of the most\nfundamental problems in statistical learning theory and the bounds for\npractical settings can be completely characterised by a simple measure of\ncomplexity.\n  Our main result in the paper is that, for learning an unknown quantum\nmeasurement, the upper bound, given by the fat-shattering dimension, is\nlinearly proportional to the dimension of the underlying Hilbert space.\nLearning an unknown quantum state becomes a dual problem to ours, and as a\nbyproduct, we can recover Aaronson's famous result [Proc. R. Soc. A\n463:3089-3144 (2007)] solely using a classical machine learning technique. In\naddition, other famous complexity measures like covering numbers and Rademacher\ncomplexities are derived explicitly. We are able to connect measures of sample\ncomplexity with various areas in quantum information science, e.g. quantum\nstate/measurement tomography, quantum state discrimination and quantum random\naccess codes, which may be of independent interest. Lastly, with the assistance\nof general Bloch-sphere representation, we show that learning quantum\nmeasurements/states can be mathematically formulated as a neural network.\nConsequently, classical ML algorithms can be applied to efficiently accomplish\nthe two quantum learning tasks. \n\n"}
{"id": "1501.02101", "contents": "Title: Effect of noncircularity of experimental beam on CMB parameter\n  estimation Abstract: Measurement of Cosmic Microwave Background (CMB) anisotropies has been\nplaying a lead role in precision cosmology by providing some of the tightest\nconstrains on cosmological models and parameters. However, precision can only\nbe meaningful when all major systematic effects are taken into account.\nNon-circular beams in CMB experiments can cause large systematic deviation in\nthe angular power spectrum, not only by modifying the measurement at a given\nmultipole, but also introducing coupling between different multipoles through a\ndeterministic bias matrix. Here we add a mechanism for emulating the effect of\na full bias matrix to the Planck likelihood code through the parameter\nestimation code SCoPE. We show that if the angular power spectrum was measured\nwith a non-circular beam, the assumption of circular Gaussian beam or\nconsidering only the diagonal part of the bias matrix can lead to huge error in\nparameter estimation. We demonstrate that, at least for elliptical Gaussian\nbeams, use of scalar beam window functions obtained via Monte Carlo simulations\nstarting from a fiducial spectrum, as implemented in Planck analyses for\nexample, leads to em only few percent of sigma deviation of the best-fit\nparameters. However, we notice more significant differences in the posterior\ndistributions for some of the parameters, which would in turn lead to incorrect\nerrorbars. These differences can be reduced, so that the errorbars match within\nfew percent, by adding an iterative reanalysis step, where the beam window\nfunction would be recomputed using the best-fit spectrum estimated in the first\nstep. \n\n"}
{"id": "1501.03119", "contents": "Title: Constraints and tensions in testing general relativity from Planck and\n  CFHTLenS including intrinsic alignment systematics Abstract: We present constraints on testing general relativity (GR) at cosmological\nscales using recent data sets and assess the impact of galaxy intrinsic\nalignment (IA) in the CFHTLenS lensing data on those constraints. We consider\nCMB temperature data from Planck, the galaxy power spectrum from WiggleZ, weak\nlensing tomography from the CFHTLenS, ISW-galaxy cross correlations, and BAO\ndata from 6dF, SDSS DR7, and BOSS DR9. We use a parameterization of the\nmodified gravity (MG) that is binned in redshift and scale, a parameterization\nthat evolves monotonically in scale but is binned in redshift, and a functional\nparameterization that evolves only in redshift. We present the results in terms\nof the MG parameters $Q$ and $\\Sigma$. We employ an IA model with an amplitude\n$A_{CFHTLenS}$ that is included in the parameter analysis. We find an\nimprovement in the constraints on the MG parameters corresponding to $40-53\\%$\nincrease on the figure of merit compared to previous studies, and GR is found\nconsistent with the data at the $95\\%$ CL. The bounds found on $A_{CFHTLenS}$\nare sensitive to the MG parameterization used, and the correlations between\n$A_{CFHTLenS}$ and MG parameters are found to be weak to moderate. For all 3 MG\nparameterizations $A_{\\rm CFHTLenS}$ is found consistent with zero when the\nwhole lensing sample is used, however, when using the optimized early-type\ngalaxy sample a significantly non-zero $A_{\\rm CFHTLenS}$ is found for GR and\nthe third MG parameterization. We find that the tensions observed in previous\nstudies persist, and there is an indication that CMB data and lensing data\nprefer different values for MG parameters, particularly for the parameter\n$\\Sigma$. The analysis of the confidence contours and probability distributions\nsuggest that the bimodality found follows that of the known tension in the\n$\\sigma_8$ parameter. (Abridged) \n\n"}
{"id": "1501.03989", "contents": "Title: Cosmology with a SKA HI intensity mapping survey Abstract: HI intensity mapping (IM) is a novel technique capable of mapping the\nlarge-scale structure of the Universe in three dimensions and delivering\nexquisite constraints on cosmology, by using HI as a biased tracer of the dark\nmatter density field. This is achieved by measuring the intensity of the\nredshifted 21cm line over the sky in a range of redshifts without the\nrequirement to resolve individual galaxies. In this chapter, we investigate the\npotential of SKA1 to deliver HI intensity maps over a broad range of\nfrequencies and a substantial fraction of the sky. By pinning down the baryon\nacoustic oscillation and redshift space distortion features in the matter power\nspectrum -- thus determining the expansion and growth history of the Universe\n-- these surveys can provide powerful tests of dark energy models and\nmodifications to General Relativity. They can also be used to probe physics on\nextremely large scales, where precise measurements of spatial curvature and\nprimordial non-Gaussianity can be used to test inflation; on small scales, by\nmeasuring the sum of neutrino masses; and at high redshifts where non-standard\nevolution models can be probed. We discuss the impact of foregrounds as well as\nvarious instrumental and survey design parameters on the achievable\nconstraints. In particular we analyse the feasibility of using the SKA1\nautocorrelations to probe the large-scale signal. \n\n"}
{"id": "1501.03990", "contents": "Title: HI galaxy simulations for the SKA: number counts and bias Abstract: This chapter describes the assumed specifications and sensitivities for HI\ngalaxy surveys with SKA1 and SKA2. It addresses the expected galaxy number\ndensities based on available simulations as well as the clustering bias over\nthe underlying dark matter. It is shown that a SKA1 HI galaxy survey should be\nable to find around $5\\times 10^6$ galaxies over 5,000 deg$^2$ (up to $z\\sim\n0.8$), while SKA2 should find $\\sim 10^9$ galaxies over 30,000 deg$^2$ (up to\n$z\\sim 2.5$). The numbers presented here have been used throughout the\ncosmology chapters for forecasting. \n\n"}
{"id": "1502.00625", "contents": "Title: A Strategy to Minimize Dust Foregrounds in B-mode Searches Abstract: The Planck satellite has identified several patches of sky with low polarized\ndust emission, obvious targets for searches for the cosmic-microwave-background\n(CMB) B-mode signal from inflationary gravitational waves. Still, given the\nPlanck measurement uncertainties, the polarized dust foregrounds in these\ndifferent candidate patches may differ by an order of magnitude or more. Here\nwe show that a brief initial experiment to map these candidate patches more\ndeeply at a single high frequency can efficiently zero in on the cleanest\npatch(es) and thus improve significantly the sensitivity of subsequent B-mode\nsearches. A ground-based experiment with current detector technology operating\nat >~220 GHz for 3 months can efficiently identify a low-dust-amplitude patch\nand thus improve by up to a factor 2 or 3 on the sensitivity to cosmic B modes\nof the subsequent lower-frequency deep integration. A balloon experiment with\ncurrent detector sensitivities covering the set of patches and operating at\n~350 GHz can reach a similar result in less than two weeks. This strategy may\nprove crucial in accessing the smallest gravitational-wave signals possible in\nlarge-field inflation. The high-frequency data from this exploratory experiment\nshould also provide valuable foreground templates to subsequent experiments\nthat integrate on any of the candidate patches explored. \n\n"}
{"id": "1502.01023", "contents": "Title: \"Firewall\" Phenomenology with Astrophysical Neutrinos Abstract: One of the most fundamental features of a black hole in general relativity is\nits event horizon: a boundary from which nothing can escape. There has been a\nrecent surge of interest in the nature of these event horizons and their local\nneighbourhoods. In an attempt to resolve black hole information paradox(es),\nand more generally, to better understand the path towards quantum gravity,\n\"firewalls\" have been proposed as an alternative to black hole event horizons.\nIn this paper, we explore the phenomenological implications of black holes\npossessing a surface or \"firewall\", and predict a potentially detectable\nsignature of these firewalls in the form of a high energy astrophysical\nneutrino flux. We compute the spectrum of this neutrino flux in different\nmodels and show that it is a possible candidate for the source of the PeV\nneutrinos recently detected by IceCube. This opens up a new area of research,\nbridging the non-perturbative physics of quantum gravity with the observational\nblack hole and high energy astrophysics. \n\n"}
{"id": "1502.01584", "contents": "Title: Planck 2015 results. IV. Low Frequency Instrument beams and window\n  functions Abstract: This paper presents the characterization of the in-flight beams, the beam\nwindow functions, and the associated uncertainties for the Planck Low Frequency\nInstrument (LFI). The structure of the paper is similar to that presented in\nthe 2013 Planck release; the main differences concern the beam normalization\nand the delivery of the window functions to be used for polarization analysis.\nThe in-flight assessment of the LFI main beams relies on measurements performed\nduring observations of Jupiter. By stacking data from seven Jupiter transits,\nthe main beam profiles are measured down to -25 dB at 30 and 44 GHz, and down\nto -30 dB at 70 GHz. It has been confirmed that the agreement between the\nsimulated beams and the measured beams is better than 1% at each LFI frequency\nband (within the 20 dB contour from the peak, the rms values are 0.1% at 30 and\n70 GHz; 0.2% at 44 GHz). Simulated polarized beams are used for the computation\nof the effective beam window functions. The error budget for the window\nfunctions is estimated from both main beam and sidelobe contributions, and\naccounts for the radiometer band shapes. The total uncertainties in the\neffective beam window functions are 0.7% and 1% at 30 and 44 GHz, respectively\n(at $\\ell \\approx 600$); and 0.5% at 70 GHz (at $\\ell \\approx 1000$). \n\n"}
{"id": "1502.01585", "contents": "Title: Planck 2015 results. VI. LFI mapmaking Abstract: This paper describes the mapmaking procedure applied to Planck LFI (Low\nFrequency Instrument) data. The mapmaking step takes as input the calibrated\ntimelines and pointing information. The main products are sky maps of $I,Q$,\nand $U$ Stokes components. For the first time, we present polarization maps at\nLFI frequencies. The mapmaking algorithm is based on a destriping technique,\nenhanced with a noise prior. The Galactic region is masked to reduce errors\narising from bandpass mismatch and high signal gradients. We apply horn-uniform\nradiometer weights to reduce effects of beam shape mismatch. The algorithm is\nthe same as used for the 2013 release, apart from small changes in parameter\nsettings. We validate the procedure through simulations. Special emphasis is\nput on the control of systematics, which is particularly important for accurate\npolarization analysis. We also produce low-resolution versions of the maps, and\ncorresponding noise covariance matrices. These serve as input in later analysis\nsteps and parameter estimation. The noise covariance matrices are validated\nthrough noise Monte Carlo simulations. The residual noise in the map products\nis characterized through analysis of half-ring maps, noise covariance matrices,\nand simulations. \n\n"}
{"id": "1502.01587", "contents": "Title: Planck 2015 results. VIII. High Frequency Instrument data processing:\n  Calibration and maps Abstract: This paper describes the processing applied to the Planck High Frequency\nInstrument (HFI) cleaned, time-ordered information to produce photometrically\ncalibrated maps in temperature and (for the first time) in polarization. The\ndata from the entire 2.5 year HFI mission include almost five independent\nfull-sky surveys. HFI observes the sky over a broad range of frequencies, from\n100 to 857 GHz. To obtain the best accuracy on the calibration over such a\nlarge range, two different photometric calibration schemes have been used. The\n545 and 857 GHz data are calibrated using models of planetary atmospheric\nemission. The lower frequencies (from 100 to 353 GHz) are calibrated using the\ntime-variable cosmological microwave background dipole, which we call the\n\"orbital dipole\". This source of calibration only depends on the satellite\nvelocity with respect to the solar system. Using a CMB temperature of 2.7255\n+/- 0.0006 K, it permits an independent measurement of the amplitude of the CMB\nsolar dipole (3364.3 +/- 1.5 \\mu K) which is approximatively 1\\sigma\\ higher\nthan the WMAP measurement with a direction that is consistent between both\nexperiments. We describe the pipeline used to produce the maps of intensity and\nlinear polarization from the HFI timelines, and the scheme used to set the zero\nlevel of the maps a posteriori. We also summarize the noise characteristics of\nthe HFI maps in the 2015 Planck data release and present some null tests to\nassess their quality. Finally, we discuss the major systematic effects and in\nparticular the leakage induced by flux mismatch between the detectors that\nleads to spurious polarization signal. \n\n"}
{"id": "1502.01856", "contents": "Title: PolyChord: nested sampling for cosmology Abstract: PolyChord is a novel nested sampling algorithm tailored for high dimensional\nparameter spaces. In addition, it can fully exploit a hierarchy of parameter\nspeeds such as is found in CosmoMC and CAMB. It utilises slice sampling at each\niteration to sample within the hard likelihood constraint of nested sampling.\nIt can identify and evolve separate modes of a posterior semi-independently and\nis parallelised using openMPI. PolyChord is available for download at:\nhttp://ccpforge.cse.rl.ac.uk/gf/project/polychord/ \n\n"}
{"id": "1502.06001", "contents": "Title: Detection and localization of single-source gravitational waves with\n  pulsar timing arrays Abstract: Pulsar timing arrays (PTAs) can be used to search for very low frequency\n($10^{-9}$--$10^{-7}$ Hz) gravitational waves (GWs). In this paper we present a\ngeneral method for the detection and localization of single-source GWs using\nPTAs. We demonstrate the effectiveness of this new method for three types of\nsignals: monochromatic waves as expected from individual supermassive binary\nblack holes in circular orbits, GWs from eccentric binaries and GW bursts. We\nalso test its implementation in realistic data sets that include effects such\nas uneven sampling and heterogeneous data spans and measurement precision. It\nis shown that our method, which works in the frequency domain, performs as well\nas published time-domain methods. In particular, we find it equivalent to the\n$\\mathcal{F}_{e}$-statistic for monochromatic waves. We also discuss the\nconstruction of null streams -- data streams that have null response to GWs,\nand the prospect of using null streams as a consistency check in the case of\ndetected GW signals. Finally, we present sensitivities to individual\nsupermassive binary black holes in eccentric orbits. We find that a\nmonochromatic search that is designed for circular binaries can efficiently\ndetect eccentric binaries with both high and low eccentricities, while a\nharmonic summing technique provides greater sensitivities only for binaries\nwith moderate eccentricities. \n\n"}
{"id": "1502.06602", "contents": "Title: CF-HiZELS, a 10 deg$^2$ emission-line survey with spectroscopic\n  follow-up: H\\alpha, [OIII]+H\\beta\\ and [OII] luminosity functions at z=0.8,\n  1.4 and 2.2 Abstract: We present results from the largest contiguous narrow-band survey in the\nnear-infrared. We have used WIRCam/CFHT and the lowOH2 filter (1.187$\\pm$0.005\n$\\mu$m) to survey ~10 deg$^2$ of contiguous extragalactic sky in the SA22\nfield. A total of ~6000 candidate emission-line galaxies are found. We use deep\nugrizJK data to obtain robust photometric redshifts. We combine our data with\nthe High-redshift Emission Line Survey (HiZELS), explore spectroscopic surveys\n(VVDS, VIPERS) and obtain our own spectroscopic follow-up with KMOS, FMOS and\nMOSFIRE to derive large samples of high-redshift emission-line selected\ngalaxies: 3471 H$\\alpha$ emitters at z=0.8, 1343 [OIII]+H$\\beta$ emitters at\nz=1.4 and 572 [OII] emitters at z=2.2. We probe co-moving volumes of >10$^6$\nMpc$^3$ and find significant over-densities, including an 8.5$\\sigma$\n(spectroscopically confirmed) over-density of H$\\alpha$ emitters at z=0.81. We\nderive H$\\alpha$, [OIII]+H$\\beta$ and [OII] luminosity functions at\nz=0.8,1.4,2.2, respectively, and present implications for future surveys such\nas Euclid. Our uniquely large volumes/areas allow us to sub-divide the samples\nin thousands of randomised combinations of areas and provide a robust empirical\nmeasurement of sample/cosmic variance. We show that surveys for\nstar-forming/emission-line galaxies at a depth similar to ours can only\novercome cosmic-variance (errors <10%) if they are based on volumes >5x10$^{5}$\nMpc$^{3}$; errors on $L^*$ and $\\phi^*$ due to sample (cosmic) variance on\nsurveys probing ~10$^4$ Mpc$^{3}$ and ~10$^5$ Mpc$^{3}$ are typically very\nhigh: ~300% and ~40-60%, respectively. \n\n"}
{"id": "1502.07301", "contents": "Title: Cosmic Strings and the Origin of Globular Clusters Abstract: We hypothesize that cosmic string loops are the seeds about which globular\nclusters accrete. Fixing the cosmic string tension by demanding that the peak\nin the distribution of masses of objects accreting onto string loops agrees\nwith the peak in the observed mass distribution of globular clusters in our\nMilky Way galaxy, we then compute the expected number density and mass function\nof globular clusters, and compare with observations. Our hypothesis naturally\nexplains why globular clusters are the oldest and most dense objects in a\ngalaxy, and why they are found in the halo of the galaxy. \n\n"}
{"id": "1502.07583", "contents": "Title: Constraints on the dark matter sound speed from galactic scales: the\n  cases of the Modified and Extended Chaplygin Gas Abstract: We show that the observed rotation curves of spiral galaxies constrain the\nsound speed of the dark matter to be $c_s < 10^{-4} c$, where $c$ is the speed\nof light in vacuum. Using the Modified Chaplygin Gas as a representative\nexample of a class of unified dark energy models incorporating an effective\ndark matter component with a non-zero sound speed, we determine the most\nstringent constraint to date on the value of the constant contribution to the\nequation of state parameter in this class of models. Finally, we explain the\nreason why previous constraints using the Cosmic Microwave Background and\nBaryonic Acoustic Oscillations were not as competitive as the one presented in\nthis paper and discuss the limitations of the recently proposed Extended\nChaplygin Gas. \n\n"}
{"id": "1503.00562", "contents": "Title: Improving the convergence properties of the moving-mesh code AREPO Abstract: Accurate numerical solutions of the equations of hydrodynamics play an ever\nmore important role in many fields of astrophysics. In this work, we\nreinvestigate the accuracy of the moving-mesh code \\textsc{Arepo} and show how\nits convergence order can be improved for general problems. In particular, we\nclarify that for certain problems \\textsc{Arepo} only reaches first-order\nconvergence for its original formulation. This can be rectified by simple\nmodifications we propose to the time integration scheme and the spatial\ngradient estimates of the code, both improving the accuracy of the code. We\ndemonstrate that the new implementation is indeed second-order accurate under\nthe $L^1$ norm, and in particular substantially improves conservation of\nangular momentum. Interestingly, whereas these improvements can significantly\nchange the results of smooth test problems, we also find that cosmological\nsimulations of galaxy formation are unaffected, demonstrating that the\nnumerical errors eliminated by the new formulation do not impact these\nsimulations. In contrast, simulations of binary stars followed over a large\nnumber of orbital times are strongly affected, as here it is particularly\ncrucial to avoid a long-term build up of errors in angular momentum\nconservation. \n\n"}
{"id": "1503.00730", "contents": "Title: Cosmic web-type classification using decision theory Abstract: We propose a decision criterion for segmenting the cosmic web into different\nstructure types (voids, sheets, filaments, and clusters) on the basis of their\nrespective probabilities and the strength of data constraints. Our approach is\ninspired by an analysis of games of chance where the gambler only plays if a\npositive expected net gain can be achieved based on some degree of privileged\ninformation. The result is a general solution for classification problems in\nthe face of uncertainty, including the option of not committing to a class for\na candidate object. As an illustration, we produce high-resolution maps of\nweb-type constituents in the nearby Universe as probed by the Sloan Digital Sky\nSurvey main galaxy sample. Other possible applications include the selection\nand labelling of objects in catalogues derived from astronomical survey data. \n\n"}
{"id": "1503.01644", "contents": "Title: Polarization leakage in Epoch of Reionization windows: I. LOFAR\n  observations of the 3C196 field Abstract: Detection of the 21-cm signal coming from the epoch of reionization (EoR) is\nchallenging especially because, even after removing the foregrounds, the\nresidual Stokes $I$ maps contain leakage from polarized emission that can mimic\nthe signal. Here, we discuss the instrumental polarization of LOFAR and present\nrealistic simulations of the leakages between Stokes parameters. From the LOFAR\nobservations of polarized emission in the 3C196 field, we have quantified the\nlevel of polarization leakage caused by the nominal model beam of LOFAR, and\ncompared it with the EoR signal using power spectrum analysis. We found that at\n134--166 MHz, within the central 4$^\\circ$ of the field the $(Q,U)\\rightarrow\nI$ leakage power is lower than the EoR signal at $k<0.3$ Mpc$^{-1}$. The\nleakage was found to be localized around a Faraday depth of 0, and the rms of\nthe leakage as a fraction of the rms of the polarized emission was shown to\nvary between 0.2-0.3\\%, both of which could be utilized in the removal of\nleakage. Moreover, we could define an `EoR window' in terms of the polarization\nleakage in the cylindrical power spectrum above the PSF-induced wedge and below\n$k_\\parallel\\sim 0.5$ Mpc$^{-1}$, and the window extended up to\n$k_\\parallel\\sim 1$ Mpc$^{-1}$ at all $k_\\perp$ when 70\\% of the leakage had\nbeen removed. These LOFAR results show that even a modest polarimetric\ncalibration over a field of view of $\\lesssim 4^\\circ$ in the future arrays\nlike SKA will ensure that the polarization leakage remains well below the\nexpected EoR signal at the scales of 0.02-1 Mpc$^{-1}$. \n\n"}
{"id": "1503.02317", "contents": "Title: Cosmic String Loops as the Seeds of Super-Massive Black Holes Abstract: Recent discoveries of super-massive black holes at high redshifts indicate a\npossible tension with the standard Lambda CDM paradigm of early universe\ncosmology which has difficulties in explaining the origin of the required\nnonlinear compact seeds which trigger the formation of these super-massive\nblack holes. Here we show that cosmic string loops which result from a scaling\nsolution of strings formed during a phase transition in the very early universe\nlead to an additional source of compact seeds. The number density of\nstring-induced seeds dominates at high redshifts and can help trigger the\nformation of the observed super-massive black holes. \n\n"}
{"id": "1503.03285", "contents": "Title: A new map-making algorithm for CMB polarisation experiments Abstract: With the temperature power spectrum of the cosmic microwave background (CMB)\nat least four orders of magnitude larger than the B-mode polarisation power\nspectrum, any instrumental imperfections that couple temperature to\npolarisation must be carefully controlled and/or removed. Here we present two\nnew map-making algorithms that can create polarisation maps that are clean of\ntemperature-to-polarisation leakage systematics due to differential gain and\npointing between a detector pair. Where a half wave plate is used, we show that\nthe spin-2 systematic due to differential ellipticity can also by removed using\nour algorithms. The algorithms require no prior knowledge of the imperfections\nor temperature sky to remove the temperature leakage. Instead, they calculate\nthe systematic and polarisation maps in one step directly from the time ordered\ndata (TOD). The first algorithm is designed to work with scan strategies that\nhave a good range of crossing angles for each map pixel and the second for scan\nstrategies that have a limited range of crossing angles. The first algorithm\ncan also be used to identify if systematic errors that have a particular spin\nare present in a TOD. We demonstrate the use of both algorithms and the ability\nto identify systematics with simulations of TOD with realistic scan strategies\nand instrumental noise. \n\n"}
{"id": "1503.03869", "contents": "Title: Numerical solution of the non-linear Schrodinger equation using\n  smoothed-particle hydrodynamics Abstract: We formulate a smoothed-particle hydrodynamics numerical method,\ntraditionally used for the Euler equations for fluid dynamics in the context of\nastrophysical simulations, to solve the non-linear Schrodinger equation in the\nMadelung formulation. The probability density of the wavefunction is\ndiscretized into moving particles, whose properties are smoothed by a kernel\nfunction. The traditional fluid pressure is replaced by a quantum pressure\ntensor, for which a novel, robust discretization is found. We demonstrate our\nnumerical method on a variety of numerical test problems involving the simple\nharmonic oscillator, Bose-Einstein condensates, collapsing singularities, and\ndark matter halos governed by the Gross-Pitaevskii-Poisson equation. Our method\nis conservative, applicable to unbounded domains, and is automatically adaptive\nin its resolution, making it well suited to study problems with collapsing\nsolutions. \n\n"}
{"id": "1503.05052", "contents": "Title: Alcock-Paczynski Test with Model-independent BAO Data Abstract: Cosmological tests based on the statistical analysis of galaxy distributions\nusually depend on source evolution. An exception is the Alcock-Paczynski (AP)\ntest, which is based on the changing ratio of angular to spatial/redshift size\nof (presumed) spherically-symmetric source distributions with distance.\nIntrinsic redshift distortions due to gravitational effects may also have an\ninfluence, but they can now be overcome with the inclusion of a sharp feature,\nsuch as the Baryonic Acoustic Oscillation (BAO) peak. Redshift distortions\naffect the amplitude of the peak, but impact its position only negligibly. As\nwe shall show here, the use of this diagnostic, with new BAO peaks from\nSDSS-III/BOSS at average redshifts <z>=0.38, 0.61 and 2.34, disfavors the\ncurrent concordance (LCDM) model at 2.3 sigma. Within the context of expanding\nFriedmann-Robertson-Walker (FRW) cosmologies, these data instead favor the zero\nactive mass equation-of-state, rho+3p=0, where rho and p are, respectively, the\ntotal density and pressure of the cosmic fluid, the basis for the R_h=ct\nuniverse. \n\n"}
{"id": "1503.06421", "contents": "Title: The $AKARI$ Far-Infrared All-Sky Survey Maps Abstract: We present a far-infrared all-sky atlas from a sensitive all-sky survey using\nthe Japanese $AKARI$ satellite. The survey covers $> 99$% of the sky in four\nphotometric bands centred at 65 $\\mu$m, 90 $\\mu$m, 140 $\\mu$m, and 160 $\\mu$m\nwith spatial resolutions ranging from 1 to 1.5 arcmin. These data provide\ncrucial information for the investigation and characterisation of the\nproperties of dusty material in the Interstellar Medium (ISM), since\nsignificant portion of its energy is emitted between $\\sim$50 and 200 $\\mu$m.\nThe large-scale distribution of interstellar clouds, their thermal dust\ntemperatures and column densities, can be investigated with the improved\nspatial resolution compared to earlier all-sky survey observations. In addition\nto the point source distribution, the large-scale distribution of ISM cirrus\nemission, and its filamentary structure, are well traced. We have made the\nfirst public release of the full-sky data to provide a legacy data set for use\nby the astronomical community. \n\n"}
{"id": "1504.02076", "contents": "Title: On the proper kinetic quadrupole CMB removal and the quadrupole\n  anomalies Abstract: It has been pointed out recently that the quadrupole-octopole alignment in\nthe CMB data is significantly affected by the so-called kinetic Doppler\nquadrupole (DQ), which is the temperature quadrupole induced by our proper\nmotion. Assuming our velocity is the dominant contribution to the CMB dipole we\nhave v/c = beta = (1.231 +/- 0.003) * 10^{-3}, which leads to a non-negligible\nDQ of order beta^2. Here we stress that one should properly take into account\nthat CMB data are usually not presented in true thermodynamic temperature,\nwhich induces a frequency dependent boost correction. The DQ must therefore be\nmultiplied by a frequency-averaged factor, which we explicitly compute for\nseveral CMB maps finding that it varies between 1.67 and 2.47. This is often\nneglected in the literature and turns out to cause a small but non-negligible\ndifference in the significance levels of some quadrupole-related statistics.\nFor instance the alignment significance in the SMICA 2013 map goes from\n2.3sigma to 3.3sigma, with the frequency dependent DQ, instead of 2.9sigma\nignoring the frequency dependence in the DQ. Moreover as a result of a proper\nDQ removal, the agreement across different map-making techniques is improved. \n\n"}
{"id": "1504.03514", "contents": "Title: The QUIJOTE experiment: project overview and first results Abstract: QUIJOTE (Q-U-I JOint TEnerife) is a new polarimeter aimed to characterize the\npolarization of the Cosmic Microwave Background and other Galactic and\nextragalactic signals at medium and large angular scales in the frequency range\n10-40 GHz. The multi-frequency (10-20~GHz) instrument, mounted on the first\nQUIJOTE telescope, saw first light on November 2012 from the Teide Observatory\n(2400~m a.s.l). During 2014 the second telescope has been installed at this\nobservatory. A second instrument at 30~GHz will be ready for commissioning at\nthis telescope during summer 2015, and a third additional instrument at 40~GHz\nis now being developed. These instruments will have nominal sensitivities to\ndetect the B-mode polarization due to the primordial gravitational-wave\ncomponent if the tensor-to-scalar ratio is larger than r=0.05. \n\n"}
{"id": "1504.06083", "contents": "Title: From Lorentz-Chern-Simons to Massive Gravity in 2+1 Dimensions Abstract: We propose a generalization of Chiral Gravity, which follows from considering\na Chern-Simons action for the spin connection with anti-symmetric contorsion.\nThe theory corresponds to Topologically Massive Gravity at the chiral point\nnon-minimally coupled to an additional scalar mode that gathers the torsion\ndegree of freedom. In this setup, the effective cosmological constant (the\ninverse of the curvature radius of maximally symmetric solutions) is either\nnegative or zero, and it enters as an integration constant associated to the\nvalue of the contorsion at infinity. We explain how this is not in conflict\nwith the Zamolodchikov's $c$-theorem holding in the dual boundary theory. In\nfact, we conjecture that the theory formulated about three-dimensional Anti-de\nSitter space is dual to a two-dimensional conformal field theory whose right-\nand left-moving central charges are given by $c_{R}=24k$ and $c_{L}=0$,\nrespectively, being $k$ the level of the Chern-Simons action. We study the\nclassical theory both at the linear and non-linear level. In particular, we\nshow how Chiral Gravity is included as a special sector. In addition, the\ntheory has other sectors, which we explore; we exhibit analytic exact solutions\nthat are not solutions of Topologically Massive Gravity (and, consequently,\nneither of General Relativity) and still satisfy Brown-Henneaux asymptotically\nAdS$_{3}$ boundary conditions. \n\n"}
{"id": "1504.06129", "contents": "Title: cosmoabc: Likelihood-free inference via Population Monte Carlo\n  Approximate Bayesian Computation Abstract: Approximate Bayesian Computation (ABC) enables parameter inference for\ncomplex physical systems in cases where the true likelihood function is\nunknown, unavailable, or computationally too expensive. It relies on the\nforward simulation of mock data and comparison between observed and synthetic\ncatalogues. Here we present cosmoabc, a Python ABC sampler featuring a\nPopulation Monte Carlo (PMC) variation of the original ABC algorithm, which\nuses an adaptive importance sampling scheme. The code is very flexible and can\nbe easily coupled to an external simulator, while allowing to incorporate\narbitrary distance and prior functions. As an example of practical application,\nwe coupled cosmoabc with the numcosmo library and demonstrate how it can be\nused to estimate posterior probability distributions over cosmological\nparameters based on measurements of galaxy clusters number counts without\ncomputing the likelihood function. cosmoabc is published under the GPLv3\nlicense on PyPI and GitHub and documentation is available at\nhttp://goo.gl/SmB8EX \n\n"}
{"id": "1504.07245", "contents": "Title: Approximate Bayesian Computation for Forward Modeling in Cosmology Abstract: Bayesian inference is often used in cosmology and astrophysics to derive\nconstraints on model parameters from observations. This approach relies on the\nability to compute the likelihood of the data given a choice of model\nparameters. In many practical situations, the likelihood function may however\nbe unavailable or intractable due to non-gaussian errors, non-linear\nmeasurements processes, or complex data formats such as catalogs and maps. In\nthese cases, the simulation of mock data sets can often be made through forward\nmodeling. We discuss how Approximate Bayesian Computation (ABC) can be used in\nthese cases to derive an approximation to the posterior constraints using\nsimulated data sets. This technique relies on the sampling of the parameter\nset, a distance metric to quantify the difference between the observation and\nthe simulations and summary statistics to compress the information in the data.\nWe first review the principles of ABC and discuss its implementation using a\nPopulation Monte-Carlo (PMC) algorithm and the Mahalanobis distance metric. We\ntest the performance of the implementation using a Gaussian toy model. We then\napply the ABC technique to the practical case of the calibration of image\nsimulations for wide field cosmological surveys. We find that the ABC analysis\nis able to provide reliable parameter constraints for this problem and is\ntherefore a promising technique for other applications in cosmology and\nastrophysics. Our implementation of the ABC PMC method is made available via a\npublic code release. \n\n"}
{"id": "1504.07853", "contents": "Title: Primordial magnetogenesis before recombination Abstract: The origin of large magnetic fields in the Universe remains currently\nunknown. We investigate here a mechanism before recombination based on known\nphysics. The source of the vorticity is due to the changes in the photon\ndistribution function caused by the fluctuations in the background photons. We\nshow that the magnetic field generated in the MHD limit, due to the Coulomb\nscattering, is of the order $10^{-49}$~G on a coherence scale of 10 kpc. We\nexplicitly show that the magnetic fields generated from this process are\nsustainable and are not erased by resistive diffusion. We compare the results\nwith current observations and discuss the implications. Our seed magnetic\nfields are generated on small scales whereas the main mechanisms studied in the\nliterature are on scale bigger than 1 Mpc. However, compared to more exotic\ntheories generating seed magnetic fields on similar scales, the strength of our\nfields are generally smaller. \n\n"}
{"id": "1505.01584", "contents": "Title: Can Superconducting Cosmic Strings Piercing Seed Black Holes Generate\n  Supermassive Black Holes in the Early Universe? Abstract: The discovery of a large number of supermassive black holes (SMBH) at\nredshifts $z > 6$, when the Universe was only 900 million years old, raises the\nquestion of how such massive compact objects could form in a cosmologically\nshort time interval. Each of the standard scenarios proposed, involving rapid\naccretion of seed black holes or black hole mergers, faces severe theoretical\ndifficulties in explaining the short-time formation of supermassive objects. In\nthis work we propose an alternative scenario for the formation of SMBH in the\nearly Universe, in which energy transfer from superconducting cosmic strings\npiercing small seed black holes is the main physical process leading to rapid\nmass increase. As a toy model, the accretion rate of a seed black hole pierced\nby two antipodal strings carrying constant current is considered. Using an\neffective action approach, which phenomenologically incorporates a large class\nof superconducting string models, we estimate the minimum current required to\nform SMBH with masses of order $M = 2 \\times 10^{9}M_{\\odot}$ by $z = 7.085$.\nThis corresponds to the mass of the central black hole powering the quasar ULAS\nJ112001.48+064124.3 and is taken as a test case scenario for early-epoch SMBH\nformation. For GUT scale strings, the required fractional increase in the\nstring energy density, due to the presence of the current, is of order\n$10^{-7}$, so that their existence remains consistent with current\nobservational bounds on the string tension. In addition, we consider an\n\"exotic\" scenario, in which an SMBH is generated when a small seed black hole\nis pierced by a higher-dimensional $F-$string, predicted by string theory. We\nfind that both topological defect strings and fundamental strings are able to\ncarry currents large enough to generate early-epoch SMBH via our proposed\nmechanism. \n\n"}
{"id": "1505.03528", "contents": "Title: Halo detection via large-scale Bayesian inference Abstract: We present a proof-of-concept of a novel and fully Bayesian methodology\ndesigned to detect halos of different masses in cosmological observations\nsubject to noise and systematic uncertainties. Our methodology combines the\npreviously published Bayesian large-scale structure inference algorithm, HADES,\nand a Bayesian chain rule (the Blackwell-Rao Estimator), which we use to\nconnect the inferred density field to the properties of dark matter halos. To\ndemonstrate the capability of our approach we construct a realistic galaxy mock\ncatalogue emulating the wide-area 6-degree Field Galaxy Survey, which has a\nmedian redshift of approximately 0.05. Application of HADES to the catalogue\nprovides us with accurately inferred three-dimensional density fields and\ncorresponding quantification of uncertainties inherent to any cosmological\nobservation. We then use a cosmological simulation to relate the amplitude of\nthe density field to the probability of detecting a halo with mass above a\nspecified threshold. With this information we can sum over the HADES density\nfield realisations to construct maps of detection probabilities and demonstrate\nthe validity of this approach within our mock scenario. We find that the\nprobability of successful of detection of halos in the mock catalogue increases\nas a function of the signal-to-noise of the local galaxy observations. Our\nproposed methodology can easily be extended to account for more complex\nscientific questions and is a promising novel tool to analyse the cosmic\nlarge-scale structure in observations. \n\n"}
{"id": "1505.07674", "contents": "Title: Lensed: a code for the forward reconstruction of lenses and sources from\n  strong lensing observations Abstract: Robust modelling of strong lensing systems is fundamental to exploit the\ninformation they contain about the distribution of matter in galaxies and\nclusters. In this work, we present Lensed, a new code which performs forward\nparametric modelling of strong lenses. Lensed takes advantage of a massively\nparallel ray-tracing kernel to perform the necessary calculations on a modern\ngraphics processing unit (GPU). This makes the precise rendering of the\nbackground lensed sources much faster, and allows the simultaneous optimisation\nof tens of parameters for the selected model. With a single run, the code is\nable to obtain the full posterior probability distribution for the lens light,\nthe mass distribution and the background source at the same time. Lensed is\nfirst tested on mock images which reproduce realistic space-based observations\nof lensing systems. In this way, we show that it is able to recover unbiased\nestimates of the lens parameters, even when the sources do not follow exactly\nthe assumed model. Then, we apply it to a subsample of the SLACS lenses, in\norder to demonstrate its use on real data. The results generally agree with the\nliterature, and highlight the flexibility and robustness of the algorithm. \n\n"}
{"id": "1506.02040", "contents": "Title: Computing the Three-Point Correlation Function of Galaxies in\n  $\\mathcal{O}(N^2)$ Time Abstract: We present an algorithm that computes the multipole coefficients of the\ngalaxy three-point correlation function (3PCF) without explicitly considering\ntriplets of galaxies. Rather, centering on each galaxy in the survey, it\nexpands the radially-binned density field in spherical harmonics and combines\nthese to form the multipoles without ever requiring the relative angle between\na pair about the central. This approach scales with number and number density\nin the same way as the two-point correlation function, allowing runtimes that\nare comparable, and 500 times faster than a naive triplet count. It is exact in\nangle and easily handles edge correction. We demonstrate the algorithm on the\nLasDamas SDSS-DR7 mock catalogs, computing an edge corrected 3PCF out to\n$90\\;{\\rm Mpc}/h$ in under an hour on modest computing resources. We expect\nthis algorithm will render it possible to obtain the large-scale 3PCF for\nupcoming surveys such as Euclid, LSST, and DESI. \n\n"}
{"id": "1506.02892", "contents": "Title: Absolute Calibration of the Radio Astronomy Flux Density Scale at 22 to\n  43 GHz Using Planck Abstract: The Planck mission detected thousands of extragalactic radio sources at\nfrequencies from 28 to 857 GHz. Planck's calibration is absolute (in the sense\nthat it is based on the satellite's annual motion around the Sun and the\ntemperature of the cosmic microwave background), and its beams are well\ncharacterized at sub-percent levels. Thus Planck's flux density measurements of\ncompact sources are absolute in the same sense. We have made coordinated VLA\nand ATCA observations of 65 strong, unresolved Planck sources in order to\ntransfer Planck's calibration to ground-based instruments at 22, 28, and 43\nGHz. The results are compared to microwave flux density scales currently based\non planetary observations. Despite the scatter introduced by the variability of\nmany of the sources, the flux density scales are determined to 1-2% accuracy.\nAt 28 GHz, the flux density scale used by the VLA runs 3.6% +- 1.0% below\nPlanck values; at 43 GHz, the discrepancy increases to 6.2% +- 1.4% for both\nATCA and the VLA. \n\n"}
{"id": "1506.05356", "contents": "Title: Non-Gaussian forecasts of weak lensing with and without priors Abstract: Assuming a Euclid-like weak lensing data set, we compare different methods of\ndealing with its inherent parameter degeneracies. Including priors into a data\nanalysis can mask the information content of a given data set alone. However,\nsince the information content of a data set is usually estimated with the\nFisher matrix, priors are added in order to enforce an approximately Gaussian\nlikelihood. Here, we compare priorless forecasts to more conventional forecasts\nthat use priors. We find strongly non-Gaussian likelihoods for 2d-weak lensing\nif no priors are used, which we approximate with the DALI-expansion. Without\npriors, the Fisher matrix of the 2d-weak lensing likelihood includes unphysical\nvalues of $\\Omega_m$ and $h$, since it does not capture the shape of the\nlikelihood well. The Cramer-Rao inequality then does not need to apply. We find\nthat DALI and Monte Carlo Markov Chains predict the presence of a dark energy\nwith high significance, whereas a Fisher forecast of the same data set also\nallows decelerated expansion. We also find that a 2d-weak lensing analysis\nprovides a sharp lower limit on the Hubble constant of $h > 0.4$, even if the\nequation of state of dark energy is jointly constrained by the data. This is\nnot predicted by the Fisher matrix and usually masked in other works by a sharp\nprior on $h$. Additionally, we find that DALI estimates Figures of Merit in the\npresence of non-Gaussianities better than the Fisher matrix. We additionally\ndemonstrate how DALI allows switching to a Hamiltonian Monte Carlo sampling of\na highly curved likelihood with acceptance rates of $\\approx 0.5$, an effective\ncovering of the parameter space, and numerically effectively costless leapfrog\nsteps. This shows how quick forecasts can be upgraded to accurate forecasts\nwhenever needed. Results were gained with the public code from\nhttp://lnasellentin.github.io/DALI/ \n\n"}
{"id": "1506.06140", "contents": "Title: Astrophysical hydrodynamics with a high-order discontinuous Galerkin\n  scheme and adaptive mesh refinement Abstract: Solving the Euler equations of ideal hydrodynamics as accurately and\nefficiently as possible is a key requirement in many astrophysical simulations.\nIt is therefore important to continuously advance the numerical methods\nimplemented in current astrophysical codes, especially also in light of\nevolving computer technology, which favours certain computational approaches\nover others. Here we introduce the new adaptive mesh refinement (AMR) code\nTENET, which employs a high order discontinuous Galerkin (DG) scheme for\nhydrodynamics. The Euler equations in this method are solved in a weak\nformulation with a polynomial basis by means of explicit Runge-Kutta time\nintegration and Gauss-Legendre quadrature. This approach offers significant\nadvantages over commonly employed second order finite volume (FV) solvers. In\nparticular, the higher order capability renders it computationally more\nefficient, in the sense that the same precision can be obtained at\nsignificantly less computational cost. Also, the DG scheme inherently conserves\nangular momentum in regions where no limiting takes place, and it typically\nproduces much smaller numerical diffusion and advection errors than a FV\napproach. A further advantage lies in a more natural handling of AMR refinement\nboundaries, where a fall-back to first order can be avoided. Finally, DG\nrequires no wide stencils at high order, and offers an improved data locality\nand a focus on local computations, which is favourable for current and upcoming\nhighly parallel supercomputers. We describe the formulation and implementation\ndetails of our new code, and demonstrate its performance and accuracy with a\nset of two- and three-dimensional test problems. The results confirm that DG\nschemes have a high potential for astrophysical applications. \n\n"}
{"id": "1506.06150", "contents": "Title: Confirmation of Wide-Field Signatures in Redshifted 21 cm Power Spectra Abstract: We confirm our recent prediction of the \"pitchfork\" foreground signature in\npower spectra of high-redshift 21 cm measurements where the interferometer is\nsensitive to large-scale structure on all baselines. This is due to the\ninherent response of a wide-field instrument and is characterized by enhanced\npower from foreground emission in Fourier modes adjacent to those considered to\nbe the most sensitive to the cosmological H I signal. In our recent paper, many\nsignatures from the simulation that predicted this feature were validated\nagainst Murchison Widefield Array (MWA) data, but this key pitchfork signature\nwas close to the noise level. In this paper, we improve the data sensitivity\nthrough the coherent averaging of 12 independent snapshots with identical\ninstrument settings and provide the first confirmation of the prediction with a\nsignal-to-noise ratio > 10. This wide-field effect can be mitigated by careful\nantenna designs that suppress sensitivity near the horizon. Simple models for\nantenna apertures that have been proposed for future instruments such as the\nHydrogen Epoch of Reionization Array and the Square Kilometre Array indicate\nthey should suppress foreground leakage from the pitchfork by ~40 dB relative\nto the MWA and significantly increase the likelihood of cosmological signal\ndetection in these critical Fourier modes in the three-dimensional power\nspectrum. \n\n"}
{"id": "1506.07640", "contents": "Title: Precision cosmology with time delay lenses: high resolution imaging\n  requirements Abstract: Lens time delays are a powerful probe of cosmology, provided that the\ngravitational potential of the main deflector can be modeled with sufficient\nprecision. Recent work has shown that this can be achieved by detailed modeling\nof the host galaxies of lensed quasars, which appear as \"Einstein Rings\" in\nhigh resolution images. We carry out a systematic exploration of the high\nresolution imaging required to exploit the thousands of lensed quasars that\nwill be discovered by current and upcoming surveys with the next decade.\nSpecifically, we simulate realistic lens systems as imaged by the Hubble Space\nTelescope (HST), James Webb Space Telescope (JWST), and ground based adaptive\noptics images taken with Keck or the Thirty Meter Telescope (TMT). We compare\nthe performance of these pointed observations with that of images taken by the\nEuclid (VIS), Wide-Field Infrared Survey Telescope (WFIRST) and Large Synoptic\nSurvey Telescope (LSST) surveys. We use as our metric the precision with which\nthe slope $\\gamma'$ of the total mass density profile $\\rho_{tot}\\propto\nr^{-\\gamma'}$ for the main deflector can be measured. Ideally, we require that\nthe statistical error on $\\gamma'$ be less than 0.02, such that it is\nsubdominant to other sources of random and systematic uncertainties. We find\nthat survey data will likely have sufficient depth and resolution to meet the\ntarget only for the brighter gravitational lens systems, comparable to those\ndiscovered by the SDSS survey. For fainter systems, that will be discovered by\ncurrent and future surveys, targeted follow-up will be required. However, the\nexposure time required with upcoming facilitites such as JWST, the Keck Next\nGeneration Adaptive Optics System, and TMT, will only be of order a few minutes\nper system, thus making the follow-up of hundreds of systems a practical and\nefficient cosmological probe. \n\n"}
{"id": "1506.08668", "contents": "Title: Mapping gravitational-wave backgrounds in modified theories of gravity\n  using pulsar timing arrays Abstract: We extend our previous work on applying CMB techniques to the mapping of\ngravitational-wave backgrounds to backgrounds which have non-GR polarisations.\nOur analysis and results are presented in the context of pulsar-timing array\nobservations, but the overarching methods are general, and can be easily\napplied to LIGO or eLISA observations using appropriately modified response\nfunctions. Analytic expressions for the pulsar-timing response to gravitational\nwaves with non-GR polarisation are given for each mode of a spin-weighted\nspherical-harmonic decomposition of the background, which permit the signal to\nbe mapped across the sky to any desired resolution. We also derive the\npulsar-timing overlap reduction functions for the various non-GR polarisations,\nfinding analytic forms for anisotropic backgrounds with scalar-transverse\n(\"breathing\") and vector-longitudinal polarisations, and a semi-analytic form\nfor scalar-longitudinal backgrounds. Our results indicate that pulsar-timing\nobservations will be completely insensitive to scalar-transverse mode\nanisotropies in the polarisation amplitude beyond dipole, and anisotropies in\nthe power beyond quadrupole. Analogously to our previous findings that\npulsar-timing observations lack sensitivity to tensor-curl modes for a\ntransverse-traceless tensor background, we also find insensitivity to\nvector-curl modes for a vector-longitudinal background. \n\n"}
{"id": "1506.08817", "contents": "Title: Limits on anisotropy in the nanohertz stochastic gravitational-wave\n  background Abstract: The paucity of observed supermassive black hole binaries (SMBHBs) may imply\nthat the gravitational wave background (GWB) from this population is\nanisotropic, rendering existing analyses sub-optimal. We present the first\nconstraints on the angular distribution of a nanohertz stochastic GWB from\ncircular, inspiral-driven SMBHBs using the $2015$ European Pulsar Timing Array\ndata [Desvignes et al. (in prep.)]. Our analysis of the GWB in the $\\sim 2 -\n90$ nHz band shows consistency with isotropy, with the strain amplitude in\n$l>0$ spherical harmonic multipoles $\\lesssim 40\\%$ of the monopole value. We\nexpect that these more general techniques will become standard tools to probe\nthe angular distribution of source populations. \n\n"}
{"id": "1506.08939", "contents": "Title: XMASS: Recent results and status Abstract: The XMASS project is designed for multiple physics goals using\nhighly-purified liquid xenon scintillator in an ultra-low radioactivity\nenvironment. As the first stage of the project, the detector with 835 kg of\nliquid xenon was constructed and is being operated. In this paper, we present\nresults from our commissioning data, current status of the experiment, and a\nnext step of the project. \n\n"}
{"id": "1506.09024", "contents": "Title: Bayesian model selection without evidences: application to the dark\n  energy equation-of-state Abstract: A method is presented for Bayesian model selection without explicitly\ncomputing evidences, by using a combined likelihood and introducing an integer\nmodel selection parameter $n$ so that Bayes factors, or more generally\nposterior odds ratios, may be read off directly from the posterior of $n$. If\nthe total number of models under consideration is specified a priori, the full\njoint parameter space $(\\theta, n)$ of the models is of fixed dimensionality\nand can be explored using standard Markov chain Monte Carlo (MCMC) or nested\nsampling methods, without the need for reversible jump MCMC techniques. The\nposterior on $n$ is then obtained by straightforward marginalisation. We\ndemonstrate the efficacy of our approach by application to several toy models.\nWe then apply it to constraining the dark energy equation-of-state using a\nfree-form reconstruction technique. We show that $\\Lambda$CDM is significantly\nfavoured over all extensions, including the simple $w(z){=}{\\rm constant}$\nmodel. \n\n"}
{"id": "1506.09209", "contents": "Title: Non-Gaussian Structure of B-mode Polarization after Delensing Abstract: The B-mode polarization of the cosmic microwave background on large scales\nhas been considered as a probe of gravitational waves from the cosmic\ninflation. Ongoing and future experiments will, however, suffer from\ncontamination due to the B-modes of non-primordial origins, one of which is the\nlensing induced B-mode polarization. Subtraction of the lensing B-modes,\nusually referred to as delensing, will be required for further improvement of\ndetection sensitivity of the gravitational waves. In such experiments,\nknowledge of statistical properties of the B-modes after delensing is\nindispensable to likelihood analysis particularly because the lensing B-modes\nare known to be non-Gaussian. In this paper, we study non-Gaussian structure of\nthe delensed B-modes on large scales, comparing them with those of the lensing\nB-modes. In particular, we investigate the power spectrum correlation matrix\nand the probability distribution function (PDF) of the power spectrum\namplitude. Assuming an experiment in which the quadratic delensing is an almost\noptimal method, we find that delensing reduces correlations of the lensing\nB-mode power spectra between different multipoles, and that the PDF of the\npower spectrum amplitude is well described as a normal distribution function\nwith a variance larger than that in the case of a Gaussian field. These\nfeatures are well captured by an analytic model based on the 4th order\nEdgeworth expansion. As a consequence of the non-Gaussianity, the constraint on\nthe tensor-to-scalar ratio after delensing is degraded within approximately a\nfew percent, which depends on the multipole range included in the analysis. \n\n"}
{"id": "1507.04561", "contents": "Title: Simulations for single-dish intensity mapping experiments Abstract: HI intensity mapping is an emerging tool to probe dark energy. Observations\nof the redshifted HI signal will be contaminated by instrumental noise,\natmospheric and Galactic foregrounds. The latter is expected to be four orders\nof magnitude brighter than the HI emission we wish to detect. We present a\nsimulation of single-dish observations including an instrumental noise model\nwith 1/f and white noise, and sky emission with a diffuse Galactic foreground\nand HI emission. We consider two foreground cleaning methods: spectral\nparametric fitting and principal component analysis. For a smooth frequency\nspectrum of the foreground and instrumental effects, we find that the\nparametric fitting method provides residuals that are still contaminated by\nforeground and 1/f noise, but the principal component analysis can remove this\ncontamination down to the thermal noise level. This method is robust for a\nrange of different models of foreground and noise, and so constitutes a\npromising way to recover the HI signal from the data. However, it induces a\nleakage of the cosmological signal into the subtracted foreground of around 5%.\nThe efficiency of the component separation methods depends heavily on the\nsmoothness of the frequency spectrum of the foreground and the 1/f noise. We\nfind that as, long as the spectral variations over the band are slow compared\nto the channel width, the foreground cleaning method still works. \n\n"}
{"id": "1507.05617", "contents": "Title: Simulation-based marginal likelihood for cluster strong lensing\n  cosmology Abstract: Comparisons between observed and predicted strong lensing properties of\ngalaxy clusters have been routinely used to claim either tension or consistency\nwith $\\Lambda$CDM cosmology. However, standard approaches to such cosmological\ntests are unable to quantify the preference for one cosmology over another. We\nadvocate approximating the relevant Bayes factor using a marginal likelihood\nthat is based on the following summary statistic: the posterior probability\ndistribution function for the parameters of the scaling relation between\nEinstein radii and cluster mass, $\\alpha$ and $\\beta$. We demonstrate, for the\nfirst time, a method of estimating the marginal likelihood using the X-ray\nselected $z>0.5$ MACS clusters as a case in point and employing both N-body and\nhydrodynamic simulations of clusters. We investigate the uncertainty in this\nestimate and consequential ability to compare competing cosmologies, that\narises from incomplete descriptions of baryonic processes, discrepancies in\ncluster selection criteria, redshift distribution, and dynamical state. The\nrelation between triaxial cluster masses at various overdensities provide a\npromising alternative to the strong lensing test. \n\n"}
{"id": "1507.06506", "contents": "Title: Brillinger mixing of determinantal point processes and statistical\n  applications Abstract: Stationary determinantal point processes are proved to be Brillinger mixing.\nThis property is an important step towards asymptotic statistics for these\nprocesses. As an important example, a central limit theorem for a wide class of\nfunctionals of determinantal point processes is established. This result yields\nin particular the asymptotic normality of the estimator of the intensity of a\nstationary determinantal point process and of the kernel estimator of its pair\ncorrelation. \n\n"}
{"id": "1507.07234", "contents": "Title: Dark and visible matter distribution in Coma cluster: theory vs\n  observations Abstract: We investigate dark and visible matter distribution in the Coma cluster in\nthe case of the Navarro-Frenk-White (NFW) profile. A toy model where all\ngalaxies in the cluster are concentrated inside a sphere of an effective radius\n$R_{\\mathrm{eff}}$ is considered. It enables us to obtain the mean velocity\ndispersion as a function of $R_{\\mathrm{eff}}$. We show that, within the\nobservation accuracy of the NFW parameters, the calculated value of\n$R_{\\mathrm{eff}}$ can be rather close to the observable cutoff of the galaxy\ndistribution. Moreover, the comparison of our toy model with the observable\ndata and simulations leads to the following preferable NFW parameters for the\nComa cluster: $R_{200} \\approx 1.77\\,h^{-1} \\, \\mathrm{Mpc} = 2.61\\,\n\\mathrm{Mpc}$, $c=3\\div 4$ and $M_{200}= 1.29h^{-1}\\times10^{15}M_{\\odot}$. In\nthe Coma cluster the most of galaxies are concentrated inside a sphere of the\neffective radius $R_{\\mathrm{eff}}\\sim 3.7$ Mpc and the line-of-sight velocity\ndispersion is $1004\\, \\mathrm{km}\\, \\mathrm{s}^{-1}$. \n\n"}
{"id": "1507.08336", "contents": "Title: No galaxy left behind: accurate measurements with the faintest objects\n  in the Dark Energy Survey Abstract: Accurate statistical measurement with large imaging surveys has traditionally\nrequired throwing away a sizable fraction of the data. This is because most\nmeasurements have have relied on selecting nearly complete samples, where\nvariations in the composition of the galaxy population with seeing, depth, or\nother survey characteristics are small.\n  We introduce a new measurement method that aims to minimize this wastage,\nallowing precision measurement for any class of stars or galaxies detectable in\nan imaging survey. We have implemented our proposal in Balrog, a software\npackage which embeds fake objects in real imaging in order to accurately\ncharacterize measurement biases.\n  We demonstrate this technique with an angular clustering measurement using\nDark Energy Survey (DES) data. We first show that recovery of our injected\ngalaxies depends on a wide variety of survey characteristics in the same way as\nthe real data. We then construct a flux-limited sample of the faintest galaxies\nin DES, chosen specifically for their sensitivity to depth and seeing\nvariations. Using the synthetic galaxies as randoms in the standard\nLandy-Szalay correlation function estimator suppresses the effects of variable\nsurvey selection by at least two orders of magnitude. With this correction, our\nmeasured angular clustering is found to be in excellent agreement with that of\na matched sample drawn from much deeper, higher-resolution space-based\nCosmological Evolution Survey (COSMOS) imaging; over angular scales of\n$0.004^{\\circ} < \\theta < 0.2^{\\circ}$, we find a best-fit scaling amplitude\nbetween the DES and COSMOS measurements of $1.00 \\pm 0.09$.\n  We expect this methodology to be broadly useful for extending the statistical\nreach of measurements in a wide variety of coming imaging surveys. \n\n"}
{"id": "1508.00968", "contents": "Title: The Effect of Primordial Non-Gaussianities on the Seeds of Super-Massive\n  Black Holes Abstract: The origin of the seeds which develop into the observed super-massive black\nholes at high redshifts may be hard to interpret in the context of the standard\n$\\Lambda CDM$ of early universe cosmology based on Gaussian primordial\nperturbations. Here we consider the modification of the halo mass function\nobtained by introducing skewness and kurtosis of the primordial fluctuations.\nWe show that such primordial non-Gaussianities constrained by the current\nobservational bounds on the nonlinearity parameters of $f_{NL}$ and $g_{NL}$\nare not effective at greatly increasing the number density of seeds which could\ndevelop into super-massive black holes at high redshifts. This is to be\ncontrasted with the role which cosmic string loops could play in seeding\nsuper-massive black holes. \n\n"}
{"id": "1508.02682", "contents": "Title: On the Role of Self-Adjointness in the Continuum Formulation of\n  Topological Quantum Phases Abstract: Topological quantum phases of matter are characterized by an intimate\nrelationship between the Hamiltonian dynamics away from the edges and the\nappearance of bound states localized at the edges of the system. Elucidating\nthis correspondence in the continuum formulation of topological phases, even in\nthe simplest case of a one-dimensional system, touches upon fundamental\nconcepts and methods in quantum mechanics that are not commonly discussed in\ntextbooks, in particular the self-adjoint extensions of a Hermitian operator.\nWe show how such topological bound states can be derived in a prototypical\none-dimensional system. Along the way, we provide a pedagogical exposition of\nthe self-adjoint extension method as well as the role of symmetries in\ncorrectly formulating the continuum, field-theory description of topological\nmatter with boundaries. Moreover, we show that self-adjoint extensions can be\ncharacterized generally in terms of a conserved local current associated with\nthe self-adjoint operator. \n\n"}
{"id": "1508.02784", "contents": "Title: Effects of Cosmic String Velocities and the Origin of Globular Clusters Abstract: With the hypothesis that cosmic string loops act as seeds for globular\nclusters in mind, we study the role that velocities of these strings will play\nin determining the mass distribution of globular clusters. Loops with high\nenough velocities will not form compact and roughly spherical objects and can\nhence not be the seeds for globular clusters. We compute the expected number\ndensity and mass function of globular clusters as a function of both the string\ntension and the peak loop velocity, and compare the results with the\nobservational data on the mass distribution of globular clusters in our Milky\nWay. We determine the critical peak string loop velocity above which the\nagreement between the string loop model for the origin of globular clusters\n(neglecting loop velocities) and observational data is lost. \n\n"}
{"id": "1508.02948", "contents": "Title: A LOFAR census of millisecond pulsars Abstract: We report the detection of 48 millisecond pulsars (MSPs) out of 75 observed\nthus far using the LOFAR in the frequency range 110-188 MHz. We have also\ndetected three MSPs out of nine observed in the frequency range 38-77 MHz. This\nis the largest sample of MSPs ever observed at these low frequencies, and half\nof the detected MSPs were observed for the first time at frequencies below 200\nMHz. We present the average pulse profiles of the detected MSPs, their\neffective pulse widths, and flux densities and compare these with higher\nobserving frequencies. The flux-calibrated, multifrequency LOFAR pulse profiles\nare publicly available via the EPN Database of Pulsar Profiles. We also present\naverage values of dispersion measures (DM) and discuss DM and profile\nvariations. About 35% of the MSPs show strong narrow profiles, another 25%\nexhibit scattered profiles, and the rest are only weakly detected. A\nqualitative comparison of LOFAR profiles with those at higher radio frequencies\nshows constant separation between profile components. Similarly, the profile\nwidths are consistent with those observed at higher frequencies, unless\nscattering dominates at the lowest frequencies. This is very different from\nwhat is observed for normal pulsars and suggests a compact emission region in\nthe MSP magnetosphere. The amplitude ratio of the profile components, on the\nother hand, can dramatically change towards low frequencies, often with the\ntrailing component becoming dominant. As previously demonstrated this can be\ncaused by aberration and retardation. This data set enables high-precision\nstudies of pulse profile evolution with frequency, dispersion, Faraday\nrotation, and scattering in the interstellar medium. Characterising and\ncorrecting these systematic effects may improve pulsar-timing precision at\nhigher observing frequencies, where pulsar timing array projects aim to\ndirectly detect gravitational waves. \n\n"}
{"id": "1508.07850", "contents": "Title: Supernovae as cosmological probes Abstract: The cosmological standard model at present is widely accepted as containing\nmainly things we do not understand. In particular the appearance of a\nCosmological Constant, or dark energy, is puzzling. This was first inferred\nfrom the Hubble diagram of a low number of Type Ia supernovae, and later\ncorroborated by complementary cosmological probes. Today, a much larger\ncollection of supernovae is available, and here I perform a rigorous\nstatistical analysis of this dataset. Taking into account how the supernovae\nare calibrated to be standard candles, we run into some subtleties in the\nanalysis. To our surprise, this new dataset - about an order of bigger than the\nsize of the original dataset - shows, under standard assumptions, only mild\nevidence of an accelerated universe. \n\n"}
{"id": "1509.01515", "contents": "Title: Results on light dark matter particles with a low-threshold CRESST-II\n  detector Abstract: The CRESST-II experiment uses cryogenic detectors to search for nuclear\nrecoil events induced by the elastic scattering of dark matter particles in\nCaWO$_4$ crystals. Given the low energy threshold of our detectors in\ncombination with light target nuclei, low mass dark matter particles can be\nprobed with high sensitivity. In this letter we present the results from data\nof a single detector module corresponding to 52 kg live days. A blind analysis\nis carried out. With an energy threshold for nuclear recoils of 307 eV we\nsubstantially enhance the sensitivity for light dark matter. Thereby, we extend\nthe reach of direct dark matter experiments to the sub-region and demonstrate\nthat the energy threshold is the key parameter in the search for low mass dark\nmatter particles. \n\n"}
{"id": "1509.02448", "contents": "Title: WIMP-Search Results from the Second CDMSlite Run Abstract: The CDMS low ionization threshold experiment (CDMSlite) uses cryogenic\ngermanium detectors operated at a relatively high bias voltage to amplify the\nphonon signal in the search for weakly interacting massive particles (WIMPs).\nResults are presented from the second CDMSlite run with an exposure of 70 kg\ndays, which reached an energy threshold for electron recoils as low as 56 eV. A\nfiducialization cut reduces backgrounds below those previously reported by\nCDMSlite. New parameter space for the WIMP-nucleon spin-independent cross\nsection is excluded for WIMP masses between 1.6 and 5.5 GeV/$c^2$. \n\n"}
{"id": "1509.02486", "contents": "Title: Measurement of Muon Annual Modulation and Muon-Induced Phosphorescence\n  in NaI(Tl) Crystals with DM-Ice17 Abstract: We report the measurement of muons and muon-induced phosphorescence in\nDM-Ice17, a NaI(Tl) direct detection dark matter experiment at the South Pole.\nMuon interactions in the crystal are identified by their observed pulse shape\nand large energy depositions. The measured muon rate in DM-Ice17 is 2.93 +/-\n0.04 muons/crystal/day with a modulation amplitude of 12.3 +/- 1.7%, consistent\nwith expectation. Following muon interactions, we observe long-lived\nphosphorescence in the NaI(Tl) crystals with a decay time of 5.5 +/- 0.5 s. The\nprompt energy deposited by a muon is correlated to the amount of delayed\nphosphorescence, the brightest of which consist of tens of millions of photons.\nThese photons are distributed over tens of seconds with a rate and arrival\ntiming that do not mimic a scintillation signal above 2 keVee. While the\nproperties of phosphorescence vary among individual crystals, the\nannually-modulating signal observed by DAMA cannot be accounted for by\nphosphorescence with the characteristics observed in DM-Ice17. \n\n"}
{"id": "1509.02938", "contents": "Title: Investigating dark matter substructure with pulsar timing: I.\n  Constraints on ultracompact minihalos Abstract: Small-scale dark matter structure within the Milky Way is expected to affect\npulsar timing. The change in gravitational potential induced by a dark matter\nhalo passing near the line of sight to a pulsar would produce a varying delay\nin the light travel time of photons from the pulsar. Individual transits\nproduce an effect that would either be too rare or too weak to be detected in\n30-year pulsar observations. However, a population of dark matter subhalos\nwould be expected to produce a detectable effect on the measured properties of\npulsars if the subhalos constitute a significant fraction of the total halo\nmass. The effect is to increase the dispersion of measured period derivatives\nacross the pulsar population. By statistical analysis of the ATNF pulsar\ncatalogue, we place an upper limit on this dispersion of $\\log \\sigma_{\\dot{P}}\n\\leq -17.05$. We use this to place strong upper limits on the number density of\nultracompact minihalos within the Milky Way. These limits are completely\nindependent of the particle nature of dark matter. \n\n"}
{"id": "1509.03711", "contents": "Title: Subwavelength total acoustic absorption with degenerate resonators Abstract: We report the experimental realization of perfect sound absorption by\nsub-wavelength monopole and dipole resonators that exhibit degenerate resonant\nfrequencies. This is achieved through the destructive interference of two\nresonators' transmission responses, while the matching of their averaged\nimpedances to that of air implies no backscattering, thereby leading to total\nabsorption. Two examples, both using decorated membrane resonators (DMRs) as\nthe basic units, are presented. The first is a flat panel comprising a DMR and\na pair of coupled DMRs, while the second one is a ventilated short tube\ncontaining a DMR in conjunction with a sidewall DMR backed by a cavity. In both\nexamples, near perfect absorption, up to 99.7%, has been observed with the\nairborne wavelength up to 1.2 m, which is at least an order of magnitude larger\nthan the composite absorber. Excellent agreement between theory and experiment\nis obtained. \n\n"}
{"id": "1509.05058", "contents": "Title: On Weak Lensing Shape Noise Abstract: One of the most powerful techniques to study the dark sector of the Universe\nis weak gravitational lensing. In practice, to infer the reduced shear, weak\nlensing measures galaxy shapes, which are the consequence of both the intrinsic\nellipticity of the sources and of the integrated gravitational lensing effect\nalong the line of sight. Hence, a very large number of galaxies is required in\norder to average over their individual properties and to isolate the weak\nlensing cosmic shear signal. If this `shape noise' can be reduced, significant\nadvances in the power of a weak lensing surveys can be expected. This paper\ndescribes a general method for extracting the probability distributions of\nparameters from catalogues of data using Voronoi cells, which has several\napplications, and has synergies with Bayesian hierarchical modelling\napproaches. This allows us to construct a probability distribution for the\nvariance of the intrinsic ellipticity as a function of galaxy property using\nonly photometric data, allowing a reduction of shape noise. As a proof of\nconcept the method is applied to the CFHTLenS survey data. We use this approach\nto investigate trends of galaxy properties in the data and apply this to the\ncase of weak lensing power spectra. \n\n"}
{"id": "1509.06022", "contents": "Title: Multimessenger astronomy Abstract: In this paper we provide a short overview of the scope and strong future\npotential of a multi-messenger approach to gravitational-wave astronomy, that\nseeks to optimally combine gravtitational wave and electromagnetic\nobservations. We highlight the importance of a multi-messenger approach for\ndetecting gravitational wave sources, and also describe some ways in which\njoint gravitational wave and electromagnetic observations can improve the\nestimation of source parameters and better inform our understanding of the\nsources themselves -- thus enhancing their potential as probes of astrophysics\nand cosmology. \n\n"}
{"id": "1509.06750", "contents": "Title: 3D weak lensing with spin wavelets on the ball Abstract: We construct the spin flaglet transform, a wavelet transform to analyze spin\nsignals in three dimensions. Spin flaglets can probe signal content localized\nsimultaneously in space and frequency and, moreover, are separable so that\ntheir angular and radial properties can be controlled independently. They are\nparticularly suited to analyzing of cosmological observations such as the weak\ngravitational lensing of galaxies. Such observations have a unique 3D\ngeometrical setting since they are natively made on the sky, have spin angular\nsymmetries, and are extended in the radial direction by additional distance or\nredshift information. Flaglets are constructed in the harmonic space defined by\nthe Fourier-Laguerre transform, previously defined for scalar functions and\nextended here to signals with spin symmetries. Thanks to various sampling\ntheorems, both the Fourier-Laguerre and flaglet transforms are theoretically\nexact when applied to bandlimited signals. In other words, in numerical\ncomputations the only loss of information is due to the finite representation\nof floating point numbers. We develop a 3D framework relating the weak lensing\npower spectrum to covariances of flaglet coefficients. We suggest that the\nresulting novel flaglet weak lensing estimator offers a powerful alternative to\ncommon 2D and 3D approaches to accurately capture cosmological information.\nWhile standard weak lensing analyses focus on either real or harmonic space\nrepresentations (i.e., correlation functions or Fourier-Bessel power spectra,\nrespectively), a wavelet approach inherits the advantages of both techniques,\nwhere both complicated sky coverage and uncertainties associated with the\nphysical modeling of small scales can be handled effectively. Our codes to\ncompute the Fourier-Laguerre and flaglet transforms are made publicly\navailable. \n\n"}
{"id": "1509.07137", "contents": "Title: Bayesian inference on the sphere beyond statistical isotropy Abstract: We present a general method for Bayesian inference of the underlying\ncovariance structure of random fields on a sphere. We employ the Bipolar\nSpherical Harmonic (BipoSH) representation of general covariance structure on\nthe sphere. We illustrate the efficacy of the method as a principled approach\nto assess violation of statistical isotropy (SI) in the sky maps of Cosmic\nMicrowave Background (CMB) fluctuations. SI violation in observed CMB maps\narise due to known physical effects such as Doppler boost and weak lensing; yet\nunknown theoretical possibilities like cosmic topology and subtle violations of\nthe cosmological principle, as well as, expected observational artefacts of\nscanning the sky with a non-circular beam, masking, foreground residuals,\nanisotropic noise, etc. We explicitly demonstrate the recovery of the input SI\nviolation signals with their full statistics in simulated CMB maps. Our\nformalism easily adapts to exploring parametric physical models with non-SI\ncovariance, as we illustrate for the inference of the parameters of a Doppler\nboosted sky map. Our approach promises to provide a robust quantitative\nevaluation of the evidence for SI violation related anomalies in the CMB sky by\nestimating the BipoSH spectra along with their complete posterior. \n\n"}
{"id": "1509.08801", "contents": "Title: Graphene-based detectors for directional dark matter detection Abstract: Dark matter detectors with directional sensitivity have the capability to\ndistinguish dark matter induced nuclear recoils from isotropic backgrounds,\nthus providing a smoking gun signature for dark matter in the Galactic halo.\nMotivated by recent progress in graphene and two-dimensional materials\nresearch, we propose a novel class of directional dark matter detectors\nutilizing graphene-based van der Waals heterostructures. A conceptual design of\nthe detector based on graphene/hexagonal boron nitride and graphene/molybdenum\ndisulfide heterostructures is developed and analyzed. The proposed detector has\nmodular scalability, keV-scale detection threshold, nanometer position\nresolution, sensitivity down to 10 $\\mathrm{GeV}/c^2$ dark matter mass, and\nintrinsic head-tail discrimination and background rejection capabilities. \n\n"}
{"id": "1510.00019", "contents": "Title: Gaussianisation for fast and accurate inference from cosmological data Abstract: We present a method to transform multivariate unimodal non-Gaussian posterior\nprobability densities into approximately Gaussian ones via non-linear mappings,\nsuch as Box--Cox transformations and generalisations thereof. This permits an\nanalytical reconstruction of the posterior from a point sample, like a Markov\nchain, and simplifies the subsequent joint analysis with other experiments.\nThis way, a multivariate posterior density can be reported efficiently, by\ncompressing the information contained in MCMC samples. Further, the model\nevidence integral (i.e. the marginal likelihood) can be computed analytically.\nThis method is analogous to the search for normal parameters in the cosmic\nmicrowave background, but is more general. The search for the optimally\nGaussianising transformation is performed computationally through a\nmaximum-likelihood formalism; its quality can be judged by how well the\ncredible regions of the posterior are reproduced. We demonstrate that our\nmethod outperforms kernel density estimates in this objective. Further, we\nselect marginal posterior samples from Planck data with several distinct\nstrongly non-Gaussian features, and verify the reproduction of the marginal\ncontours. To demonstrate evidence computation, we Gaussianise the joint\ndistribution of data from weak lensing and baryon acoustic oscillations (BAO),\nfor different cosmological models, and find a preference for flat $\\Lambda$CDM.\nComparing to values computed with the Savage-Dickey density ratio, and\nPopulation Monte Carlo, we find good agreement of our method within the spread\nof the other two. \n\n"}
{"id": "1510.00154", "contents": "Title: Direction dependence of cosmological parameters due to cosmic\n  hemispherical asymmetry Abstract: Persistent evidence for a cosmic hemispherical asymmetry in the temperature\nfield of cosmic microwave background (CMB) as observed by both WMAP as well as\nPLANCK increases the possibility of its cosmological origin. Presence of this\nsignal may lead to different values for the standard model cosmological\nparameters in different directions, and that can have significant implications\nfor other studies where they are used. We investigate the effect of this cosmic\nhemispherical asymmetry on cosmological parameters using non-isotropic Gaussian\nrandom simulations injected with both scale dependent and scale independent\nmodulation strengths. Our analysis shows that $A_s$ and $n_s$ are the most\nsusceptible parameters to acquire position dependence across the sky for the\nkind of isotropy breaking phenomena under study. As expected, we find maximum\nvariation arises for the case of scale independent modulation of CMB\nanisotropies. We find that scale dependent modulation profile as seen in PLANCK\ndata could lead to only $1.25\\sigma$ deviation in $A_s$ in comparison to its\nestimate from isotropic CMB sky. \n\n"}
{"id": "1510.00378", "contents": "Title: DM-Ice: Current Status and Future Prospects Abstract: DM-Ice is a program towards the first direct detection search for dark matter\nin the Southern Hemisphere with a 250 kg-scale NaI(Tl) crystal array. It will\nprovide a definitive understanding of the modulation signal reported by DAMA by\nrunning an array at both Northern and Southern Hemisphere sites. A 17 kg\npredecessor, DM-Ice17, was deployed in December 2010 at a depth of 2457 m under\nthe ice at the geographic South Pole and has concluded its 3.5 yr data run. An\nactive R&D program is underway to investigate detectors with lower backgrounds\nand improved readout electronics; two crystals with 37 kg combined mass are\ncurrently operating at the Boulby Underground Laboratory. We report on the\nfinal analyses of the DM-Ice17 data and describe progress towards a 250 kg\nDM-Ice experiment. \n\n"}
{"id": "1510.00702", "contents": "Title: Results from the first use of low radioactivity argon in a dark matter\n  search Abstract: Liquid argon is a bright scintillator with potent particle identification\nproperties, making it an attractive target for direct-detection dark matter\nsearches. The DarkSide-50 dark matter search here reports the first WIMP search\nresults obtained using a target of low-radioactivity argon. DarkSide-50 is a\ndark matter detector, using two-phase liquid argon time projection chamber,\nlocated at the Laboratori Nazionali del Gran Sasso. The underground argon is\nshown to contain Ar-39 at a level reduced by a factor (1.4 +- 0.2) x 10^3\nrelative to atmospheric argon. We report a background-free null result from\n(2616 +- 43) kg d of data, accumulated over 70.9 live-days. When combined with\nour previous search using an atmospheric argon, the 90 % C.L. upper limit on\nthe WIMP-nucleon spin-independent cross section based on zero events found in\nthe WIMP search regions, is 2.0 x 10^-44 cm^2 (8.6 x 10^-44 cm^2, 8.0 x 10^-43\ncm^2) for a WIMP mass of 100 GeV/c^2 (1 TeV/c^2 , 10 TeV/c^2). \n\n"}
{"id": "1510.02363", "contents": "Title: A study of spatial correlations in pulsar timing array data Abstract: Pulsar timing array experiments search for phenomena that produce angular\ncorrelations in the arrival times of signals from millisecond pulsars. The\nprimary goal is to detect an isotropic and stochastic gravitational wave\nbackground. We use simulated data to show that this search can be affected by\nthe presence of other spatially correlated noise, such as errors in the\nreference time standard, errors in the planetary ephemeris, the solar wind and\ninstrumentation issues. All these effects can induce significant false\ndetections of gravitational waves. We test mitigation routines to account for\nclock errors, ephemeris errors and the solar wind. We demonstrate that it is\nnon-trivial to find an effective mitigation routine for the planetary ephemeris\nand emphasise that other spatially correlated signals may be present in the\ndata. \n\n"}
{"id": "1510.02454", "contents": "Title: Recovering hidden signals of statistical anisotropy from a masked or\n  partial CMB sky Abstract: Any isotropy violating phenomena on cosmic microwave background (CMB) induces\noff-diagonal correlations in the two-point function. These correlations\nthemselves can be used to estimate the underlying anisotropic signals. Masking\ndue to residual foregrounds, or availability of partial sky due to survey\nlimitation, are unavoidable circumstances in CMB studies. But, masking induces\nadditional correlations, and thus complicates the recovery of such signals. In\nthis work, we discuss a procedure based on bipolar spherical harmonic (BipoSH)\nformalism to comprehensively addresses any spurious correlations induced by\nmasking and successfully recover hidden signals of anisotropy in observed CMB\nmaps. This method is generic, and can be applied to recover a variety of\nisotropy violating phenomena. Here, we illustrate the procedure by recovering\nthe subtle Doppler boost signal from simulated boosted CMB skies, which has\nbecome possible with the unprecedented full-sky sensitivity of PLANCK probe. \n\n"}
{"id": "1510.03103", "contents": "Title: Using inpainting to construct accurate cut-sky CMB estimators Abstract: The direct evaluation of manifestly optimal, cut-sky CMB power spectrum and\nbispectrum estimators is numerically very costly, due to the presence of\ninverse-covariance filtering operations. This justifies the investigation of\nalternative approaches. In this work, we mostly focus on an inpainting\nalgorithm that was introduced in recent CMB analyses to cure cut-sky\nsuboptimalities of bispectrum estimators. First, we show that inpainting can\nequally be applied to the problem of unbiased estimation of power spectra. We\nthen compare the performance of a novel inpainted CMB temperature power\nspectrum estimator to the popular apodised pseudo-$C_l$ (PCL) method and\ndemonstrate, both numerically and with analytic arguments, that inpainted power\nspectrum estimates significantly outperform PCL estimates. Finally, we study\nthe case of cut-sky bispectrum estimators, comparing the performance of three\ndifferent approaches: inpainting, apodisation and a novel low-l leaning scheme.\nProviding an analytic argument why the local shape is typically most affected\nwe mainly focus on local type non-Gaussianity. Our results show that inpainting\nallows to achieve optimality also for bispectrum estimation, but interestingly\nalso demonstrate that appropriate apodisation, in conjunction with low-l\ncleaning, can lead to comparable accuracy. \n\n"}
{"id": "1510.06198", "contents": "Title: Test of the Equivalence Principle in the Dark Sector on Galactic Scales Abstract: The Einstein Equivalence Principle is a fundamental principle of the theory\nof General Relativity. While this principle has been thoroughly tested with\nstandard matter, the question of its validity in the Dark sector remains open.\nIn this paper, we consider a general tensor-scalar theory that allows to test\nthe equivalence principle in the Dark sector by introducing two different\nconformal couplings to standard matter and to Dark matter. We constrain these\ncouplings by considering galactic observations of strong lensing and of\nvelocity dispersion. Our analysis shows that, in the case of a violation of the\nEinstein Equivalence Principle, data favour violations through coupling\nstrengths that are of opposite signs for ordinary and Dark matter. At the same\ntime, our analysis does not show any significant deviations from General\nRelativity. \n\n"}
{"id": "1510.08815", "contents": "Title: Constraining cosmology and ionization history with combined 21 cm power\n  spectrum and global signal measurements Abstract: Improvements in current instruments and the advent of next-generation\ninstruments will soon push observational 21 cm cosmology into a new era, with\nhigh significance measurements of both the power spectrum and the mean\n(\"global\") signal of the 21 cm brightness temperature. In this paper we use the\nrecently commenced Hydrogen Epoch of Reionization Array as a worked example to\nprovide forecasts on astrophysical and cosmological parameter constraints. In\ndoing so we improve upon previous forecasts in a number of ways. First, we\nprovide updated forecasts using the latest best-fit cosmological parameters\nfrom the Planck satellite, exploring the impact of different Planck datasets on\n21 cm experiments. We also show that despite the exquisite constraints that\nother probes have placed on cosmological parameters, the remaining\nuncertainties are still large enough to have a non-negligible impact on\nupcoming 21 cm data analyses. While this complicates high-precision constraints\non reionization models, it provides an avenue for 21 cm reionization\nmeasurements to constrain cosmology. We additionally forecast HERA's ability to\nmeasure the ionization history using a combination of power spectrum\nmeasurements and semi-analytic simulations. Finally, we consider ways in which\n21 cm global signal and power spectrum measurements can be combined, and\npropose a method by which power spectrum results can be used to train a compact\nparameterization of the global signal. This parameterization reduces the number\nof parameters needed to describe the global signal, increasing the likelihood\nof a high significance measurement. \n\n"}
{"id": "1510.09194", "contents": "Title: The noise properties of 42 millisecond pulsars from the European Pulsar\n  Timing Array and their impact on gravitational wave searches Abstract: The sensitivity of Pulsar Timing Arrays to gravitational waves depends on the\nnoise present in the individual pulsar timing data. Noise may be either\nintrinsic or extrinsic to the pulsar. Intrinsic sources of noise will include\nrotational instabilities, for example. Extrinsic sources of noise include\ncontributions from physical processes which are not sufficiently well modelled,\nfor example, dispersion and scattering effects, analysis errors and\ninstrumental instabilities. We present the results from a noise analysis for 42\nmillisecond pulsars (MSPs) observed with the European Pulsar Timing Array. For\ncharacterising the low-frequency, stochastic and achromatic noise component, or\n\"timing noise\", we employ two methods, based on Bayesian and frequentist\nstatistics. For 25 MSPs, we achieve statistically significant measurements of\ntheir timing noise parameters and find that the two methods give consistent\nresults. For the remaining 17 MSPs, we place upper limits on the timing noise\namplitude at the 95% confidence level. We additionally place an upper limit on\nthe contribution to the pulsar noise budget from errors in the reference\nterrestrial time standards (below 1%), and we find evidence for a noise\ncomponent which is present only in the data of one of the four used telescopes.\nFinally, we estimate that the timing noise of individual pulsars reduces the\nsensitivity of this data set to an isotropic, stochastic GW background by a\nfactor of >9.1 and by a factor of >2.3 for continuous GWs from resolvable,\ninspiralling supermassive black-hole binaries with circular orbits. \n\n"}
{"id": "1511.00676", "contents": "Title: Status and Results from DarkSide-50 Abstract: DarkSide-50 is the first physics detector of the DarkSide dark matter search\nprogram. The detector features a dual-phase underground-argon Time Projection\nChamber (TPC) of 50 kg active mass surrounded by an organic liquid-scintillator\nneutron veto (30 tons) and a water-Cherenkov muon detector (1000 tons). The TPC\nis currently fully shielded and operating underground at Gran Sasso National\nLaboratory. A first run of 1422 kg-day exposure with atmospheric argon\nrepresents the most sensitive dark matter search using a liquid argon target.\nThe TPC is now filled with underground argon, greatly reduced in 39Ar, and\nDarkSide-50 is in its final configuration for an extended dark matter search.\nOverviews of the design, performance, and results obtained so far with\nDarkSide-50 will be presented, along with future prospects for the DarkSide\nprogram. \n\n"}
{"id": "1511.01099", "contents": "Title: Non-linear Higgs portal to Dark Matter Abstract: The Higgs portal to scalar Dark Matter is considered in the context of\nnon-linearly realised electroweak symmetry breaking. We determine the dominant\ninteractions of gauge bosons and the physical Higgs particle $h$ to a scalar\nsinglet dark matter candidate. Phenomenological consequences are also studied\nin detail, including the possibility of distinguishing this scenario from the\nstandard Higgs portal in which the electroweak symmetry breaking is linearly\nrealised. Two features of significant impact are: i) the connection between the\nelectroweak scale $v$ and the Higgs particle departs from the $(v+h)$\nfunctional dependence, as the Higgs field is not necessarily an exact\nelectroweak doublet; ii) the presence of specific couplings that arise at\ndifferent order in the non-linear and in the linear expansions. These facts\ndeeply affect the dark matter relic abundance, as well as the expected signals\nin direct and indirect searches and collider phenomenology, where Dark Matter\nproduction rates are enhanced with respect to the standard portal. \n\n"}
{"id": "1511.02232", "contents": "Title: Flaring of tidally compressed dark-matter clumps Abstract: We explore the physics and observational consequences of tidal compression\nevents (TCEs) of dark-matter clumps (DMCs) by supermassive black holes (SMBHs).\nOur analytic calculations show that a DMC approaching a SMBH much closer than\nthe tidal radius undergoes significant compression along the axis perpendicular\nto the orbital plane, shortly after pericenter passage. For DMCs composed of\nself-annihilating dark-matter particles, we find that the boosted DMC density\nand velocity dispersion lead to a flaring of the annihilation rate, most\npronounced for a velocity- dependent annihilation cross section. If the end\nproducts of the annihilation are photons, this results in a gamma-ray flare,\ndetectable (and possibly already detected) by the Fermi telescope for a range\nof model parameters. If the end products of dark-matter annihilation are\nrelativistic electrons and positrons and the local magnetic field is large\nenough, TCEs of DMCs can lead to flares of synchrotron radiation. Finally, TCEs\nof DMCs lead to a burst of gravitational waves, in addition to the ones\nradiated by the orbital motion alone, and with a different frequency spectrum.\nThese transient phenomena provide interesting new avenues to explore the\nproperties of dark matter. \n\n"}
{"id": "1511.02698", "contents": "Title: Identification of the ~3.55 keV emission line candidate objects across\n  the sky Abstract: Emission line at the energy ~3.55 keV detected in different galaxies and\ngalaxy clusters has caused a lot of discussion in high-energy astrophysics and\nparticle physics communities. To reveal the origin of the line, we analyzed\npublicly available observations of MOS cameras from XMM-Newton cosmic\nobservatory - the instrument with the largest sensitivity for narrow faint\nX-ray lines - previously combined in X-ray sky maps. Because of extremely large\ntimescale needed for detailed analysis, we used the wavelet method instead.\nExtensive simulations of the central part of Andromeda galaxy are used to check\nthe validity of this method. The resulting list of wavelet detections now\ncontains 235 sky regions. This list will be used in future works for more\ndetailed spectral analysis. \n\n"}
{"id": "1511.02985", "contents": "Title: A search for Fast Radio Bursts at low frequencies with Murchison\n  Widefield Array high time resolution imaging Abstract: We present the results of a pilot study search for Fast Radio Bursts (FRBs)\nusing the Murchison Widefield Array (MWA) at low frequencies (139 - 170 MHz).\nWe utilised MWA data obtained in a routine imaging mode from observations where\nthe primary target was a field being studied for Epoch of Reionisation\ndetection. We formed images with 2 second time resolution and 1.28~MHz\nfrequency resolution for 10.5 hours of observations, over 400 square degrees of\nthe sky. We de-dispersed the dynamic spectrum in each of 372,100 resolution\nelements of 2$\\times$2 arcmin$^{2}$, between dispersion measures of 170 and\n675~pc~cm$^{-3}$. Based on the event rate calculations in Trott, Tingay & Wayth\n(2013), which assumes a standard candle luminosity of $8\\times10^{37}$\nJs$^{-1}$, we predict that with this choice of observational parameters, the\nMWA should detect ($\\sim10$,$\\sim2$,$\\sim0$) FRBs with spectral indices\ncorresponding to ($-$2, $-$1, 0), based on a 7$\\sigma$ detection threshold. We\nfind no FRB candidates above this threshold from our search, placing an event\nrate limit of $<700$ above 700 Jy.ms per day per sky and providing evidence\nagainst spectral indices $\\alpha<-1.2$ ($S\\propto\\nu^{\\alpha}$). We compare our\nevent rate and spectral index limits with others from the literature. We\nbriefly discuss these limits in light of recent suggestions that supergiant\npulses from young neutron stars could explain FRBs. We find that such\nsupergiant pulses would have to have much flatter spectra between 150 and 1400\nMHz than have been observed from Crab giant pulses to be consistent with the\nFRB spectral index limit we derive. \n\n"}
{"id": "1511.03006", "contents": "Title: HI intensity mapping with FAST Abstract: We discuss the detectability of large-scale HI intensity fluctuations using\nthe FAST telescope. We present forecasts for the accuracy of measuring the\nBaryonic Acoustic Oscillations and constraining the properties of dark energy.\nThe FAST $19$-beam L-band receivers ($1.05$--$1.45$ GHz) can provide\nconstraints on the matter power spectrum and dark energy equation of state\nparameters ($w_{0},w_{a}$) that are comparable to the BINGO and CHIME\nexperiments. For one year of integration time we find that the optimal survey\narea is $6000\\,{\\rm deg}^2$. However, observing with larger frequency coverage\nat higher redshift ($0.95$--$1.35$ GHz) improves the projected errorbars on the\nHI power spectrum by more than $2~\\sigma$ confidence level. The combined\nconstraints from FAST, CHIME, BINGO and Planck CMB observations can provide\nreliable, stringent constraints on the dark energy equation of state. \n\n"}
{"id": "1511.03672", "contents": "Title: Estimating SI violation in CMB due to non-circular beam and complex scan\n  in minutes Abstract: Mild, unavoidable deviations from circular-symmetry of instrumental beams\nalong with scan strategy can give rise to measurable Statistical Isotropy (SI)\nviolation in Cosmic Microwave Background (CMB) experiments. If not accounted\nproperly, this spurious signal can complicate the extraction of other SI\nviolation signals (if any) in the data. However, estimation of this effect\nthrough exact numerical simulation is computationally intensive and time\nconsuming. A generalized analytical formalism not only provides a quick way of\nestimating this signal, but also gives a detailed understanding connecting the\nleading beam anisotropy components to a measurable BipoSH characterisation of\nSI violation. In this paper, we provide an approximate generic analytical\nmethod for estimating the SI violation generated due to a non-circular (NC)\nbeam and arbitrary scan strategy, in terms of the Bipolar Spherical Harmonic\n(BipoSH) spectra. Our analytical method can predict almost all the features\nintroduced by a NC beam in a complex scan and thus reduces the need for\nextensive numerical simulation worth tens of thousands of CPU hours into\nminutes long calculations. As an illustrative example, we use WMAP beams and\nscanning strategy to demonstrate the easability, usability and efficiency of\nour method. We test all our analytical results against that from exact\nnumerical simulations. \n\n"}
{"id": "1511.04398", "contents": "Title: All-sky search for long-duration gravitational wave transients with LIGO Abstract: We present the results of a search for long-duration gravitational wave\ntransients in two sets of data collected by the LIGO Hanford and LIGO\nLivingston detectors between November 5, 2005 and September 30, 2007, and July\n7, 2009 and October 20, 2010, with a total observational time of 283.0 days and\n132.9 days, respectively. The search targets gravitational wave transients of\nduration 10 - 500 s in a frequency band of 40 - 1000 Hz, with minimal\nassumptions about the signal waveform, polarization, source direction, or time\nof occurrence. All candidate triggers were consistent with the expected\nbackground; as a result we set 90% confidence upper limits on the rate of\nlong-duration gravitational wave transients for different types of\ngravitational wave signals. For signals from black hole accretion disk\ninstabilities, we set upper limits on the source rate density between $3.4\n\\times 10^{-5}$ - $9.4 \\times 10^{-4}$ Mpc$^{-3}$ yr$^{-1}$ at 90% confidence.\nThese are the first results from an all-sky search for unmodeled long-duration\ntransient gravitational waves. \n\n"}
{"id": "1511.05564", "contents": "Title: Are we there yet? Time to detection of nanohertz gravitational waves\n  based on pulsar-timing array limits Abstract: Decade-long timing observations of arrays of millisecond pulsars have placed\nhighly constraining upper limits on the amplitude of the nanohertz\ngravitational-wave stochastic signal from the mergers of supermassive\nblack-hole binaries ($\\sim 10^{-15}$ strain at $f = 1/\\mathrm{yr}$). These\nlimits suggest that binary merger rates have been overestimated, or that\nenvironmental influences from nuclear gas or stars accelerate orbital decay,\nreducing the gravitational-wave signal at the lowest, most sensitive\nfrequencies. This prompts the question whether nanohertz gravitational waves\nare likely to be detected in the near future. In this letter, we answer this\nquestion quantitatively using simple statistical estimates, deriving the range\nof true signal amplitudes that are compatible with current upper limits, and\ncomputing expected detection probabilities as a function of observation time.\nWe conclude that small arrays consisting of the pulsars with the least timing\nnoise, which yield the tightest upper limits, have discouraging prospects of\nmaking a detection in the next two decades. By contrast, we find large arrays\nare crucial to detection because the quadrupolar spatial correlations induced\nby gravitational waves can be well sampled by many pulsar pairs. Indeed, timing\nprograms which monitor a large and expanding set of pulsars have an $\\sim 80\\%$\nprobability of detecting gravitational waves within the next ten years, under\nassumptions on merger rates and environmental influences ranging from\noptimistic to conservative. Even in the extreme case where $90\\%$ of binaries\nstall before merger and environmental coupling effects diminish low-frequency\ngravitational-wave power, detection is delayed by at most a few years. \n\n"}
{"id": "1511.06105", "contents": "Title: Multiple amplitude modes in strongly-coupled phonon-mediated\n  superconductors Abstract: We study collective amplitude modes of the superconducting order parameter in\nstrongly-coupled electron-phonon systems described by the Holstein model using\nthe nonequilibrium dynamical mean-field theory with the self-consistent Migdal\napproximation as an impurity solver. The frequency of the Higgs amplitude mode\nis found to coincide with the superconducting gap even in the strongly-coupled\n(beyond BCS) regime. Besides the Higgs mode, we unravel another collective mode\ninvolving the dynamics of both the phonons and the superconducting order\nparameter. The frequency of this mode, higher than twice the renormalized\nphonon frequency in the superconducting phase, is shown to reflect a strong\nelectron-mediated phonon-phonon interaction. Both types of collective\nexcitations contribute to time-resolved photoemission spectra after a strong\nlaser pump as vertex corrections to produce resonance peaks, which allows one\nto distinguish them from quasiparticle excitations. \n\n"}
{"id": "1511.06597", "contents": "Title: LEAP: the large European array for pulsars Abstract: The Large European Array for Pulsars (LEAP) is an experiment that harvests\nthe collective power of Europe's largest radio telescopes in order to increase\nthe sensitivity of high-precision pulsar timing. As part of the ongoing effort\nof the European Pulsar Timing Array (EPTA), LEAP aims to go beyond the\nsensitivity threshold needed to deliver the first direct detection of\ngravitational waves. The five telescopes presently included in LEAP are: the\nEffelsberg telescope, the Lovell telescope at Jodrell Bank, the Nan\\c cay radio\ntelescope, the Sardinia Radio Telescope and the Westerbork Synthesis Radio\nTelescope. Dual polarization, Nyquist-sampled time-series of the incoming radio\nwaves are recorded and processed offline to form the coherent sum, resulting in\na tied-array telescope with an effective aperture equivalent to a 195-m\ndiameter circular dish. All observations are performed using a bandwidth of 128\nMHz centered at a frequency of 1396 MHz. In this paper, we present the design\nof the LEAP experiment, the instrumentation, the storage and transfer of data,\nand the processing hardware and software. In particular, we present the\nsoftware pipeline that was designed to process the Nyquist-sampled time-series,\nmeasure the phase and time delays between each individual telescope and a\nreference telescope and apply these delays to form the tied-array coherent\naddition. The pipeline includes polarization calibration and interference\nmitigation. We also present the first results from LEAP and demonstrate the\nresulting increase in sensitivity, which leads to an improvement in the pulse\narrival times. \n\n"}
{"id": "1511.07801", "contents": "Title: A precise numerical estimation of the magnetic field generated around\n  recombination Abstract: We investigate the generation of magnetic fields from non-linear effects\naround recombination. As tight-coupling is gradually lost when approaching\n$z\\simeq 1100$, the velocity difference between photons and baryons starts to\nincrease, leading to an increasing Compton drag of the photons on the\nelectrons. The protons are then forced to follow the electrons due to the\nelectric field created by the charge displacement; the same field, following\nMaxwell's laws, eventually induces a magnetic field on cosmological scales.\nSince scalar perturbations do not generate any magnetic field as they are\ncurl-free, one has to resort to second-order perturbation theory to compute the\nmagnetic field generated by this effect. We reinvestigate this problem\nnumerically using the powerful second-order Boltzmann code SONG. We show that:\ni) all previous studies do not have a high enough angular resolution to reach a\nprecise and consistent estimation of the magnetic field spectrum; ii) the\nmagnetic field is generated up to $z\\simeq 10$; iii) it is in practice\nimpossible to compute the magnetic field with a Boltzmann code for scales\nsmaller than $1\\,{\\rm Mpc}$. Finally we confirm that for scales of a few ${\\rm\nMpc}$, this magnetic field is of order $2\\times 10^{-29}{\\rm G}$, many orders\nof magnitude smaller than what is currently observed on intergalactic scales. \n\n"}
{"id": "1511.08695", "contents": "Title: Turning noise into signal: learning from the scatter in the Hubble\n  diagram Abstract: The supernova (SN) Hubble diagram residual contains valuable information on\nboth the present matter power spectrum and its growth history. In this paper we\nshow that this information can be retrieved with precision by combining both\npeculiar velocity and weak-lensing analysis on the data. To wit, peculiar\nvelocity induces correlations on the nearby SN while lensing induces a\nnon-Gaussian dispersion in faraway objects. We show that both effects have\nalmost orthogonal degeneracies and discuss how they can be extracted\nsimultaneously from the data. We analyze the JLA supernova catalog in a\n14-dimensional parameter space, assuming a flexible growth-rate index $\\gamma$.\nWe arrive at the following marginalized constraints: $\\sigma_8 =\n0.65^{+0.23}_{-0.37}$ and $\\gamma = 1.38^{+1.7}_{-0.65}$. Assuming instead GR\nas the correct gravitation theory (and thus $\\gamma \\equiv 0.55$), the\nconstraints in $\\sigma_8$ tighten further: $\\sigma_8 = 0.40^{+0.21}_{-0.23}$.\nWe show that these constraints complement well the ones obtained from other\ndatasets and that they could improve substantially with more SNe. \n\n"}
{"id": "1511.09264", "contents": "Title: Eleven-dimensional supergravity from filtered subdeformations of the\n  Poincar\\'e superalgebra Abstract: We summarise the results of our recent paper (arXiv:1511.08737) highlighting\nwhat might be considered to be a Lie-algebraic derivation of eleven-dimensional\nsupergravity. \n\n"}
{"id": "1512.00012", "contents": "Title: Wavelet-Based Techniques for the Gamma-Ray Sky Abstract: We demonstrate how the image analysis technique of wavelet decomposition can\nbe applied to the gamma-ray sky to separate emission on different angular\nscales. New structures on scales that differ from the scales of the\nconventional astrophysical foreground and background uncertainties can be\nrobustly extracted, allowing a model-independent characterization with no\npresumption of exact signal morphology. As a test case, we generate mock\ngamma-ray data to demonstrate our ability to extract extended signals without\nassuming a fixed spatial template. For some point source luminosity functions,\nour technique also allows us to differentiate a diffuse signal in gamma-rays\nfrom dark matter annihilation and extended gamma-ray point source populations\nin a data-driven way. \n\n"}
{"id": "1512.03053", "contents": "Title: Accurately simulating anisotropic thermal conduction on a moving mesh Abstract: We present a novel implementation of an extremum preserving anisotropic\ndiffusion solver for thermal conduction on the unstructured moving Voronoi mesh\nof the AREPO code. The method relies on splitting the one-sided facet fluxes\ninto normal and oblique components, with the oblique fluxes being limited such\nthat the total flux is both locally conservative and extremum preserving. The\napproach makes use of harmonic averaging points and a simple, robust\ninterpolation scheme that works well for strong heterogeneous and anisotropic\ndiffusion problems. Moreover, the required discretisation stencil is small.\nEfficient fully implicit and semi-implicit time integration schemes are also\nimplemented. We perform several numerical tests that evaluate the stability and\naccuracy of the scheme, including applications such as point explosions with\nheat conduction and calculations of convective instabilities in conducting\nplasmas. The new implementation is suitable for studying important\nastrophysical phenomena, such as the conductive heat transport in galaxy\nclusters, the evolution of supernova remnants, or the distribution of heat from\nblackhole-driven jets into the intracluster medium. \n\n"}
{"id": "1512.03506", "contents": "Title: Improved Limits on Scattering of Weakly Interacting Massive Particles\n  from Reanalysis of 2013 LUX data Abstract: We present constraints on weakly interacting massive particles (WIMP)-nucleus\nscattering from the 2013 data of the Large Underground Xenon dark matter\nexperiment, including $1.4\\times10^{4}\\;\\mathrm{kg\\; day}$ of search exposure.\nThis new analysis incorporates several advances: single-photon calibration at\nthe scintillation wavelength, improved event-reconstruction algorithms, a\nrevised background model including events originating on the detector walls in\nan enlarged fiducial volume, and new calibrations from decays of an injected\ntritium $\\beta$ source and from kinematically constrained nuclear recoils down\nto 1.1 keV. Sensitivity, especially to low-mass WIMPs, is enhanced compared to\nour previous results which modeled the signal only above a 3 keV minimum\nenergy. Under standard dark matter halo assumptions and in the mass range above\n4 $\\mathrm{GeV}\\,c^{-2}$, these new results give the most stringent direct\nlimits on the spin-independent WIMP-nucleon cross section. The 90% C.L. upper\nlimit has a minimum of 0.6 zb at 33 $\\mathrm{GeV}\\,c^{-2}$ WIMP mass. \n\n"}
{"id": "1512.03597", "contents": "Title: Learning algorithms at the service of WISE survey Abstract: We have undertaken a dedicated program of automatic source classification in\nthe WISE database merged with SuperCOSMOS scans, comprehensively identifying\ngalaxies, quasars and stars on most of the unconfused sky. We use the Support\nVector Machines classifier for that purpose, trained on SDSS spectroscopic\ndata. The classification has been applied to a photometric dataset based on\nall-sky WISE 3.4 and 4.6 $\\mu$m information cross-matched with SuperCOSMOS B\nand R bands, which provides a reliable sample of $\\sim170$ million sources,\nincluding galaxies at $z_{\\rm med}\\sim0.2$, as well as quasars and stars. The\nresults of our classification method show very high purity and completeness\n(more than 96\\%) of the separated sources, and the resultant catalogs can be\nused for sophisticated analyses, such as generating all-sky photometric\nredshifts. \n\n"}
{"id": "1512.03604", "contents": "Title: Automatised classification of WISE sources: first results, future\n  prospects Abstract: We present the first results of our dedicated programme of automatised\nclassification of galaxies, stars and quasars in the mid-infrared all-sky data\nfrom the WISE survey. We employ the Support Vector Machines (SVM) algorithm,\nwhich defines a hyperplane separating different classes of sources in a\nmultidimensional space of arbitrarily chosen parameters. This approach consists\nof four general steps: 1) selection of the training sample, 2) selection of the\noptimal parameter space, 3) training of the classifier, 4) application to\ntarget data. Here, as the training set, we use sources from a cross-correlation\nof the WISE catalogue with the SDSS spectroscopic sample. The performance of\nthe SVM classifier was tested as a function of size of the training set,\ndimension of the parameter space, WISE apparent magnitude and Galactic\nextinction. We find that our classifier provides promising results already for\nthree classification parameters: magnitude, colour and differential aperture\nmagnitude. Completeness and purity levels as high as 95% are obtained for\nquasars, while for galaxies and stars they vary between 80-95% depending on the\nmagnitude, deteriorating for fainter sources. \n\n"}
{"id": "1512.05198", "contents": "Title: Cosmology with all-sky surveys Abstract: Various aspects of cosmology require comprehensive all-sky mapping of the\ncosmic web to considerable depths. In order to probe the whole extragalactic\nsky beyond 100 Mpc, one must draw on multiwavelength datasets and\nstate-of-the-art photometric redshift techniques. Here I summarize our\ndedicated program that employs the largest photometric all-sky surveys --\n2MASS, WISE and SuperCOSMOS -- to obtain accurate redshift estimates of\nmillions of galaxies. The first outcome of these efforts -- the 2MASS\nPhotometric Redshift catalog (2MPZ) -- was publicly released in 2013 and\nincludes almost 1 million galaxies with a median redshift of z~0.1. I discuss\nhow this catalog was constructed and how it is being used for various\ncosmological tests. I also present how combining the WISE mid-infrared survey\nwith SuperCOSMOS optical data allowed us to push to depths over 1 Gpc on\nunprecedented angular scales. These photometric redshift samples, with about 20\nmillion sources in total, provide access to volumes large enough to study\nobservationally the Copernican Principle of universal homogeneity and isotropy,\nas well as to probe various aspects of dark energy and dark matter through\ncross-correlations with other data such as the cosmic microwave or gamma-ray\nbackgrounds. Last but not least, they constitute a test-bed for forthcoming\nwide-angle multi-million galaxy samples expected from such instruments as the\nSKA, Euclid, or LSST. \n\n"}
{"id": "1512.05356", "contents": "Title: Beyond $\\Lambda$CDM: Problems, solutions, and the road ahead Abstract: Despite its continued observational successes, there is a persistent (and\ngrowing) interest in extending cosmology beyond the standard model,\n$\\Lambda$CDM. This is motivated by a range of apparently serious theoretical\nissues, involving such questions as the cosmological constant problem, the\nparticle nature of dark matter, the validity of general relativity on large\nscales, the existence of anomalies in the CMB and on small scales, and the\npredictivity and testability of the inflationary paradigm. In this paper, we\nsummarize the current status of $\\Lambda$CDM as a physical theory, and review\ninvestigations into possible alternatives along a number of different lines,\nwith a particular focus on highlighting the most promising directions. While\nthe fundamental problems are proving reluctant to yield, the study of\nalternative cosmologies has led to considerable progress, with much more to\ncome if hopes about forthcoming high-precision observations and new theoretical\nideas are fulfilled. \n\n"}
{"id": "1512.06732", "contents": "Title: Diphoton and Dark Matter from Cascade Decay Abstract: We propose a simplified model to study the possible new heavy diphoton\nresonance from cascade decay of a heavier particle at colliders, which may be\nrelated to the dark matter or other new physics beyond the standard model.\nModel-independent constraints and predictions on the allowed couplings for\ngenerating the observed diphoton data are studied in detail. We demonstrate\nthat this scenario can be tested by the possible four-photon signal or the\n$WW/ZZ/Z\\gamma$ resonances. Meanwhile, this cascade decay scenario also\nprovides us with the dark matter candidates, which is consistent with the\nobserved dark matter relic density. \n\n"}
{"id": "1512.06829", "contents": "Title: Towards Robust Gravitational Wave Detection with Pulsar Timing Arrays Abstract: Precision timing of highly stable milli-second pulsars is a promising\ntechnique for the detection of very low frequency sources of gravitational\nwaves. In any single pulsar, a stochastic gravitational wave signal appears as\nan additional source of timing noise that can be absorbed by the noise model,\nand so it is only by considering the coherent response across a network of\npulsars that the signal can be distinguished from other sources of noise. In\nthe limit where there are many gravitational wave sources in the sky, or many\npulsars in the array, the signals produce a unique tensor correlation pattern\nthat depends only on the angular separation between each pulsar pair. It is\nthis distinct fingerprint that is used to search for gravitational waves using\npulsar timing arrays. Here we consider how the prospects for detection are\ndiminished when the statistical isotropy of the timing array or the\ngravitational wave signal is broken by having a finite number of pulsars and a\nfinite number of sources. We find the standard tensor-correlation analysis to\nbe remarkably robust, with a mild impact on detectability compared to the\nisotropic limit. Only when there are very few sources and very few pulsars does\nthe standard analysis begin to fail. Having established that the tensor\ncorrelations are a robust signature for detection, we study the use of\n\"sky-scrambles\" to break the correlations as a way to increase confidence in a\ndetection. This approach is analogous to the use of \"time-slides\" in the\nanalysis of data from ground based interferometric detectors. \n\n"}
{"id": "1512.06834", "contents": "Title: Foreground-Induced Biases in CMB Polarimeter Self-Calibration Abstract: Precise polarisation measurements of the cosmic microwave background (CMB)\nrequire accurate knowledge of the instrument orientation relative to the sky\nframe used to define the cosmological Stokes parameters. Suitable celestial\ncalibration sources that could be used to measure the polarimeter orientation\nangle are limited, so current experiments commonly `self-calibrate.' The\nself-calibration method exploits the theoretical fact that the $EB$ and $TB$\ncross-spectra of the CMB vanish in the standard cosmological model, so any\ndetected $EB$ and $TB$ signals must be due to systematic errors. However, this\nassumption neglects the fact that polarized Galactic foregrounds in a given\nportion of the sky may have non-zero $EB$ and $TB$ cross-spectra. If these\nforeground signals remain in the observations, then they will bias the\nself-calibrated telescope polarisation angle and produce a spurious $B$-mode\nsignal. In this paper we estimate the foreground-induced bias for various\ninstrument configurations and then expand the self-calibration formalism to\naccount for polarized foreground signals. Assuming the $EB$ correlation signal\nfor dust is in the range constrained by angular power spectrum measurements\nfrom Planck at 353 GHz (scaled down to 150 GHz), then the bias is negligible\nfor high angular resolution experiments, which have access to CMB-dominated\nhigh $\\ell$ modes with which to self-calibrate. Low-resolution experiments\nobserving particularly dusty sky patches can have a bias as large as\n$0.5^\\circ$. A miscalibration of this magnitude generates a spurious $BB$\nsignal corresponding to a tensor-to-scalar ratio of approximately\n$r\\sim2\\times10^{-3}$, within the targeted range of planned experiments. \n\n"}
{"id": "1512.07487", "contents": "Title: Selecting the top-quality item through crowd scoring Abstract: We investigate crowdsourcing algorithms for finding the top-quality item\nwithin a large collection of objects with unknown intrinsic quality values.\nThis is an important problem with many relevant applications, for example in\nnetworked recommendation systems. The core of the algorithms is that objects\nare distributed to crowd workers, who return a noisy and biased evaluation. All\nreceived evaluations are then combined, to identify the top-quality object. We\nfirst present a simple probabilistic model for the system under investigation.\nThen, we devise and study a class of efficient adaptive algorithms to assign in\nan effective way objects to workers. We compare the performance of several\nalgorithms, which correspond to different choices of the design\nparameters/metrics. In the simulations we show that some of the algorithms\nachieve near optimal performance for a suitable setting of the system\nparameters. \n\n"}
{"id": "1512.09371", "contents": "Title: Parallax of Galactic Cepheids from Spatially Scanning the Wide Field\n  Camera 3 on the Hubble Space Telescope: The Case of SS Canis Majoris Abstract: We present a high-precision measurement of the parallax for the 12-day\nCepheid SS Canis Majoris, obtained via spatial scanning with the Wide Field\nCamera 3 (WFC3) on the Hubble Space Telescope (HST). Spatial scanning enables\nastrometric measurements with a precision of 20-40 muas, an order of magnitude\nbetter than pointed observations. SS CMa is the second Cepheid targeted for\nparallax measurement with HST, and is the first of a sample of eighteen\nlong-period >~ 10 days) Cepheids selected in order to improve the calibration\nof their period-luminosity relation and eventually permit a determination of\nthe Hubble constant H_0 to better than 2%. The parallax of SS CMa is found to\nbe 348 +/- 38 muas, corresponding to a distance of 2.9 +/- 0.3 kpc. We also\npresent a refinement of the static geometric distortion of WFC3 obtained using\nspatial scanning observations of calibration fields, with a typical magnitude\n<~0.01 pixels on scales of 100 pixels. \n\n"}
{"id": "1601.03948", "contents": "Title: SKA Weak Lensing II: Simulated Performance and Survey Design\n  Considerations Abstract: We construct a pipeline for simulating weak lensing cosmology surveys with\nthe Square Kilometre Array (SKA), taking as inputs telescope sensitivity\ncurves; correlated source flux, size and redshift distributions; a simple\nionospheric model; source redshift and ellipticity measurement errors. We then\nuse this simulation pipeline to optimise a 2-year weak lensing survey performed\nwith the first deployment of the SKA (SKA1). Our assessments are based on the\ntotal signal-to-noise of the recovered shear power spectra, a metric that we\nfind to correlate very well with a standard dark energy figure of merit. We\nfirst consider the choice of frequency band, trading off increases in number\ncounts at lower frequencies against poorer resolution; our analysis strongly\nprefers the higher frequency Band 2 (950-1760 MHz) channel of the SKA-MID\ntelescope to the lower frequency Band 1 (350-1050 MHz). Best results would be\nobtained by allowing the centre of Band 2 to shift towards lower frequency,\naround 1.1 GHz. We then move on to consider survey size, finding that an area\nof 5,000 square degrees is optimal for most SKA1 instrumental configurations.\nFinally, we forecast the performance of a weak lensing survey with the second\ndeployment of the SKA. The increased survey size (3$\\pi$\\,steradian) and\nsensitivity improves both the signal-to-noise and the dark energy metrics by\ntwo orders of magnitude. \n\n"}
{"id": "1601.04447", "contents": "Title: Limits on momentum-dependent asymmetric dark matter with CRESST-II Abstract: The usual assumption in direct dark matter searches is to only consider the\nspin-dependent or spin-independent scattering of dark matter particles.\nHowever, especially in models with light dark matter particles\n$\\mathcal{O}(\\mathrm{GeV/c^2})$, operators which carry additional powers of the\nmomentum transfer $q^2$ can become dominant. One such model based on asymmetric\ndark matter has been invoked to overcome discrepancies in helioseismology and\nan indication was found for a particle with preferred mass of 3\n$\\mathrm{GeV/c^2}$ and cross section of $10^{-37} \\mathrm{cm^2}$. Recent data\nfrom the CRESST-II experiment, which uses cryogenic detectors based on\n$\\mathrm{CaWO_4}$ to search for nuclear recoils induced by dark matter\nparticles, are used to constrain these momentum-dependent models. The low\nenergy threshold of 307 eV for nuclear recoils of the detector used, allows us\nto rule out the proposed best fit value above. \n\n"}
{"id": "1601.04464", "contents": "Title: Optimal cosmic microwave background map-making in the presence of\n  cross-correlated noise Abstract: We present an extension of the ROMA map-making algorithm for the generation\nof optimal cosmic microwave background polarization maps. The new code allows\nfor a possible cross-correlated noise component among the detectors of a CMB\nexperiment. A promising application is the forthcoming LSPE balloon-borne\nexperiment, which is devoted to the accurate observation of CMB polarization at\nlarge angular scales. We generalized the noise covariance matrix in time domain\nto account for all the off-diagonal terms due to the detector cross-talk.\nHence, we performed preliminary forecasts of the LSPE-SWIPE instrument. We\nfound that considering the noise cross-correlation among the detectors results\nin a more realistic estimate of the angular power spectra. In particular, the\nextended ROMA algorithm has provided a considerable reduction of the spectra\nerror bars. We expect that this improvement could be crucial in constraining\nthe B-mode polarization at the largest scales. \n\n"}
{"id": "1601.06156", "contents": "Title: Music from the heavens - Gravitational waves from supermassive black\n  hole mergers in the EAGLE simulations Abstract: We estimate the expected event rate of gravitational wave signals from\nmergers of supermassive black holes that could be resolved by a space-based\ninterferometer, such as the Evolved Laser Interferometer Space Antenna (eLISA),\nutilising the reference cosmological hydrodynamical simulation from the EAGLE\nsuite. These simulations assume a $\\Lambda$CDM cosmogony with state-of-the-art\nsubgrid models for radiative cooling, star formation, stellar mass loss, and\nfeedback from stars and accreting black holes. They have been shown to\nreproduce the observed galaxy population with unprecedented fidelity. We\ncombine the merger rates of supermassive black holes in EAGLE with the latest\nphenomenological waveform models to calculate the gravitational waves signals\nfrom the intrinsic parameters of the merging black holes. The EAGLE models\npredict $\\sim2$ detections per year by a gravitational wave detector such as\neLISA. We find that these signals are largely dominated by mergers between seed\nmass black holes merging at redshifts between $z\\sim2$ and $z\\sim1$. In order\nto investigate the dependence on the assumed black hole seed mass, we introduce\nan additional model with a black hole seed mass an order of magnitude smaller\nthan in our reference model. We also consider a variation of the reference\nmodel where a prescription for the expected delays in the black hole merger\ntimescale has been included after their host galaxies merge. We find that the\nmerger rate is similar in all models, but that the initial black hole seed mass\ncould be distinguished through their detected gravitational waveforms. Hence,\nthe characteristic gravitational wave signals detected by eLISA will provide\nprofound insight into the origin of supermassive black holes and the initial\nmass distribution of black hole seeds. \n\n"}
{"id": "1601.06194", "contents": "Title: Prospects for High-Precision Pulsar Timing with the New Effelsberg PSRIX\n  Backend Abstract: The PSRIX backend is the primary pulsar timing instrument of the Effelsberg\n100-m radio telescope since early 2011. This new ROACH-based system enables\nbandwidths up to 500 MHz to be recorded, significantly more than what was\npossible with its predecessor, the Effelsberg-Berkeley Pulsar Processor (EBPP).\nWe review the first four years of PSRIX timing data for 33 pulsars collected as\npart of the monthly European Pulsar Timing Array (EPTA) observations. We\ndescribe the automated data analysis pipeline, CoastGuard, that we developed to\nreduce these observations. We also introduce TOASTER, the EPTA timing database\nused to store timing results, processing information and observation metadata.\nUsing these new tools, we measure the phase-averaged flux densities at 1.4 GHz\nof all 33 pulsars. For 7 of these pulsars, our flux density measurements are\nthe first values ever reported. For the other 26 pulsars, we compare our flux\ndensity measurements with previously published values. By comparing PSRIX data\nwith EBPP data, we find an improvement of ~2-5 times in signal-to-noise ratio\nachievable, which translates to an increase of ~2-5 times in pulse\ntime-of-arrival (TOA) precision. We show that such an improvement in TOA\nprecision will improve the sensitivity to the stochastic gravitational wave\nbackground. Finally, we showcase the flexibility of the new PSRIX backend by\nobserving several millisecond-period pulsars (MSPs) at 5 and 9 GHz. Motivated\nby our detections, we discuss the potential for complementing existing pulsar\ntiming array data sets with MSP monitoring campaigns at these frequencies. \n\n"}
{"id": "1601.07162", "contents": "Title: NIR Tully-Fisher in the Zone of Avoidance. - II. 21 cm HI-line spectra\n  of southern ZOA galaxies Abstract: High-accuracy HI profiles and linewidths are presented for inclined ($(b/a)^o\n< 0.5$) spiral galaxies in the southern Zone of Avoidance (ZOA). These galaxies\ndefine a sample for use in the determinations of peculiar velocities using the\nnear-infrared Tully-Fisher (TF) relation. The sample is based on the 394\nHI-selected galaxies from the Parkes HI Zone of Avoidance survey (HIZOA).\nFollow-up narrow-band Parkes HI observations were obtained in 2010 and 2015 for\n290 galaxies, while for the further 104 galaxies, sufficiently high\nsignal-to-noise spectra were available from the original HIZOA data. All 394\nspectra are reduced and parameterized in the same systematic way. Five\ndifferent types of linewidth measurements were derived, and a Bayesian mixture\nmodel was used to derive conversion equations between these five widths. Of the\nselected and measure galaxies, 342 have adequate signal-to-noise (S/N $\\geq$ 5)\nfor use in TF distance estimation. The average value of the signal-to-noise\nratio of the sample is 14.7. We present the HI parameters for these galaxies.\nThe sample will allow a more accurate determination of the flow field in the\nsouthern ZOA which bisects dynamically important large-scale structures such as\nPuppis, the Great Attractor, and the Local Void. \n\n"}
{"id": "1602.01151", "contents": "Title: On the real rank of monomials Abstract: In this paper we study the real rank of monomials and we give an upper bound\nfor the real rank of all monomials. We show that the real and the complex ranks\nof a monomial coincide if and only if the least exponent is equal to one. \n\n"}
{"id": "1602.03497", "contents": "Title: Tau Now Abstract: UHECR and UHE neutrino map correlation seem to most inconclusive. We show\nhere that a few peculiar UHECR narrow clustering might be connected to a first\nUHE muon neutrino tracks. Moreover we discuss the best filtered and amplified\nUHE neutrino astronomy painted by up-going tau airshower. Their discover by new\nprojects could be reached soon. \n\n"}
{"id": "1602.03640", "contents": "Title: The International Pulsar Timing Array: First Data Release Abstract: The highly stable spin of neutron stars can be exploited for a variety of\n(astro-)physical investigations. In particular arrays of pulsars with\nrotational periods of the order of milliseconds can be used to detect\ncorrelated signals such as those caused by gravitational waves. Three such\n\"Pulsar Timing Arrays\" (PTAs) have been set up around the world over the past\ndecades and collectively form the \"International\" PTA (IPTA). In this paper, we\ndescribe the first joint analysis of the data from the three regional PTAs,\ni.e. of the first IPTA data set. We describe the available PTA data, the\napproach presently followed for its combination and suggest improvements for\nfuture PTA research. Particular attention is paid to subtle details (such as\nunderestimation of measurement uncertainty and long-period noise) that have\noften been ignored but which become important in this unprecedentedly large and\ninhomogeneous data set. We identify and describe in detail several factors that\ncomplicate IPTA research and provide recommendations for future pulsar timing\nefforts. The first IPTA data release presented here (and available online) is\nused to demonstrate the IPTA's potential of improving upon gravitational-wave\nlimits placed by individual PTAs by a factor of ~2 and provides a 2-sigma limit\non the dimensionless amplitude of a stochastic GWB of 1.7x10^{-15} at a\nfrequency of 1 yr^{-1}. This is 1.7 times less constraining than the limit\nplaced by (Shannon et al. 2015), due mostly to the more recent, high-quality\ndata they used. \n\n"}
{"id": "1602.04198", "contents": "Title: A Dark Energy Camera Search for an Optical Counterpart to the First\n  Advanced LIGO Gravitational Wave Event GW150914 Abstract: We report initial results of a deep search for an optical counterpart to the\ngravitational wave event GW150914, the first trigger from the Advanced LIGO\ngravitational wave detectors. We used the Dark Energy Camera (DECam) to image a\n102 deg$^2$ area, corresponding to 38% of the initial trigger high-probability\nsky region and to 11% of the revised high-probability region. We observed in i\nand z bands at 4-5, 7, and 24 days after the trigger. The median $5\\sigma$\npoint-source limiting magnitudes of our search images are i=22.5 and z=21.8\nmag. We processed the images through a difference-imaging pipeline using\ntemplates from pre-existing Dark Energy Survey data and publicly available\nDECam data. Due to missing template observations and other losses, our\neffective search area subtends 40 deg$^{2}$, corresponding to 12% total\nprobability in the initial map and 3% of the final map. In this area, we search\nfor objects that decline significantly between days 4-5 and day 7, and are\nundetectable by day 24, finding none to typical magnitude limits of i=\n21.5,21.1,20.1 for object colors (i-z)=1,0,-1, respectively. Our search\ndemonstrates the feasibility of a dedicated search program with DECam and bodes\nwell for future research in this emerging field. \n\n"}
{"id": "1602.04460", "contents": "Title: Implications of the Tentative Association between GW150914 and a {\\it\n  Fermi}-GBM Transient Abstract: The merger-driven Gamma-ray Bursts (GRBs) and their associated gravitational\nwave (GW) radiation, if both successfully detected, have some far-reaching\nimplications, including for instance: (i) The statistical comparison of the\nphysical properties of the short/long-short GRBs with and without GW detection\ncan test the general origin model; (ii) Revealing the physical processes taking\nplace at the central engine; (iii) Measuring the velocity of the Gravitational\nwave directly/accurately. In this work we discuss these implications in the\ncase of possible association of GW150914/ GBM transient 150914. We compared GBM\ntransient 150914 with other SGRBs and found that such an event {may be} a\ndistinct outlier in some statistical diagrams, possibly due to its specific\nbinary-black-hole merger origin. However, the presence of a \"new\" group of\nSGRBs with \"unusual\" physical parameters is also possible. If the outflow of\nGBM transient 150914 was launched by the accretion onto the nascent black hole,\nthe magnetic activity rather than the neutrino process is likely responsible\nfor the energy extraction and the accretion disk mass is estimated to be $\\sim\n10^{-5}~M_\\odot$. The GW150914/GBM transient 150914 association, {if confirmed,\nwould} provide the first opportunity to directly measure the GW velocity and\nits departure from the speed of the light {should be within} a factor of $\\sim\n10^{-17}$. \n\n"}
{"id": "1602.04619", "contents": "Title: Size dependence of thermoelectric power of Au, Pd, Pt nanoclusters\n  deposited onto HOPG surface Abstract: The paper presents the study of tunnel current-voltage characteristics of Au,\nPd and Pt nanoclusters deposited onto the highly oriented pyrolytic graphite\n(HOPG) surface by pulsed laser deposition. The analysis of tunnel\ncurrent-voltage characteristics obtained by scanning tunneling spectroscopy\n(STS) allowed to recover the thermoelectric power value of nanoclusters. It was\nfound that the value of thermoelectric power of pulsed laser deposited\nnanoclusters depends on nanocluster material and shows qualitative difference\nin size dependence for different materials of nanoclusters. Thus,\nthermoelectric power value of PLD Pd nanoclusters decreases with increasing of\nnanocluster size, while for Au nanoclusters this value increases. The analysis\nof the results are discussed. \n\n"}
{"id": "1602.05525", "contents": "Title: Novel quark smearing for hadrons with high momenta in lattice QCD Abstract: Hadrons in lattice QCD are usually created employing smeared interpolators.\nWe introduce a new quark smearing that allows us to maintain small statistical\nerrors and good overlaps of hadronic wavefunctions with the respective ground\nstates, also at high spatial momenta. The method is successfully tested for the\npion and the nucleon at a pion mass $m_{\\pi}\\approx 295$ MeV and momenta as\nhigh as 2.8 GeV. We compare the results obtained to dispersion relations and\nsuggest further optimizations. \n\n"}
{"id": "1602.05882", "contents": "Title: Testing the speed of gravitational waves over cosmological distances\n  with strong gravitational lensing Abstract: Probing the relative speeds of gravitational waves and light acts as an\nimportant test of General Relativity and alternative theories of gravity.\nMeasuring the arrival time of gravitational waves and electromagnetic\ncounterparts can be used to measure the relative speeds, but only if the\nintrinsic time-lag between emission of the photons and gravitational waves is\nwell understood. Here we suggest a method that does not make such an\nassumption, using future strongly lensed GW events and EM counterparts;\nBiesiada et al forecast that 50-100 strongly lensed GW events will be observed\neach year with the Einstein Telescope. A single strongly lensed GW event would\nproduce robust constraints on the ratio of speeds of GWs and light at the\n$10^{-7}$ level, if a high energy EM counterpart is observed within the\nfield-of-view of an observing gamma ray burst monitor. \n\n"}
{"id": "1602.05939", "contents": "Title: First search for a dark matter annual modulation signal with NaI(Tl) in\n  the Southern Hemisphere by DM-Ice17 Abstract: We present the first search for a dark matter annual modulation signal in the\nSouthern Hemisphere conducted with NaI(Tl) detectors, performed by the DM-Ice17\nexperiment. Nuclear recoils from dark matter interactions are expected to yield\nan annually modulated signal independent of location within the Earth's\nhemispheres. DM-Ice17, the first step in the DM-Ice experimental program,\nconsists of 17 kg of NaI(Tl) located at the South Pole under 2200 m.w.e.\noverburden of Antarctic glacial ice. Taken over 3.6 years for a total exposure\nof 60.8 kg yr, DM-Ice17 data are consistent with no modulation in the energy\nrange of 4-20 keV, providing the strongest limits on weakly interacting massive\nparticle dark matter from a direct detection experiment located in the Southern\nHemisphere. The successful deployment and stable long-term operation of\nDM-Ice17 establishes the South Pole ice as a viable location for future dark\nmatter searches and in particular for a high-sensitivity NaI(Tl) dark matter\nexperiment to directly test the DAMA/LIBRA claim of the observation of dark\nmatter. \n\n"}
{"id": "1602.06277", "contents": "Title: The Hydrogen Epoch of Reionization Array Dish II: Characterization of\n  Spectral Structure with Electromagnetic Simulations and its science\n  Implications Abstract: We use time-domain electromagnetic simulations to determine the spectral\ncharacteristics of the Hydrogen Epoch of Reionization Arrays (HERA) antenna.\nThese simulations are part of a multi-faceted campaign to determine the\neffectiveness of the dish's design for obtaining a detection of redshifted 21\ncm emission from the epoch of reionization. Our simulations show the existence\nof reflections between HERA's suspended feed and its parabolic dish reflector\nthat fall below -40 dB at 150 ns and, for reasonable impedance matches, have a\nnegligible impact on HERA's ability to constrain EoR parameters. It follows\nthat despite the reflections they introduce, dishes are effective for\nincreasing the sensitivity of EoR experiments at relatively low cost. We find\nthat electromagnetic resonances in the HERA feed's cylindrical skirt, which is\nintended to reduce cross coupling and beam ellipticity, introduces significant\npower at large delays ($-40$ dB at 200 ns) which can lead to some loss of\nmeasurable Fourier modes and a modest reduction in sensitivity. Even in the\npresence of this structure, we find that the spectral response of the antenna\nis sufficiently smooth for delay filtering to contain foreground emission at\nline-of-sight wave numbers below $k_\\parallel \\lesssim 0.2$ $h$Mpc$^{-1}$, in\nthe region where the current PAPER experiment operates. Incorporating these\nresults into a Fisher Matrix analysis, we find that the spectral structure\nobserved in our simulations has only a small effect on the tight constraints\nHERA can achieve on parameters associated with the astrophysics of\nreionization. \n\n"}
{"id": "1602.07270", "contents": "Title: Disformal scalars as dark matter candidates: Branon phenomenology Abstract: Scalar particles coupled to the Standard Model fields through a disformal\ncoupling arise in different theories, such as massive gravity or brane-world\nmodels. We will review the main phenomenology associated with such particles.\nDistinctive disformal signatures could be measured at colliders and with\nastrophysical observations. The phenomenological relevance of the disformal\ncoupling demands the introduction of a set of symmetries, which may ensure the\nstability of these new degrees of freedom. In such a case, they constitute\nnatural dark matter candidates since they are generally massive and weakly\ncoupled. We will illustrate these ideas by paying particular attention to the\nbranon case, since these questions arise naturally in brane-world models with\nlow tension, where they were first discussed. \n\n"}
{"id": "1602.07526", "contents": "Title: Detecting the cosmic web with radio surveys Abstract: We study the challenges to detect the cosmic web at radio wavelengths with\nstate-of-the-art cosmological simulations of extragalactic magnetic fields. The\nincoming generation of radio surveys operating at low frequency, like LOFAR,\nSKA-LOW and MWA will have the best chance to detect the large-scale, low\nsurface brightness emission from the shocked cosmic web. The detected radio\nemission will enable to constrain the average magnetisation level of the gas in\nfilaments and the acceleration efficiency of electrons by strong shocks. In\ncase of detections, through statistical modelling (e.g. correlation functions)\nit will be possible to discriminate among competing scenarios for the\nmagnetisation of large-scale structures (i.e. astrophysical versus primordial\nscenarios), making radio surveys an important probe of cosmic magnetogenesis. \n\n"}
{"id": "1603.00465", "contents": "Title: A New Method for Wide-Field Near-IR Imaging with the Hubble Space\n  Telescope Abstract: We present a new technique for wide and shallow observations using the\nnear-infrared channel of Wide Field Camera 3 (WFC3) on the Hubble Space\nTelescope (HST). Wide-field near-IR surveys with HST are generally inefficient,\nas guide star acquisitions make it impractical to observe more than one\npointing per orbit. This limitation can be circumvented by guiding with gyros\nalone, which is possible as long as the telescope has three functional gyros.\nThe method presented here allows us to observe mosaics of eight independent\nWFC3-IR pointings in a single orbit by utilizing the fact that HST drifts by\nonly a very small amount in the 25 seconds between non-destructive reads of\nunguided exposures. By shifting the reads and treating them as independent\nexposures the full resolution of WFC3 can be restored. We use this \"drift and\nshift\" (DASH) method in the Cycle 23 COSMOS-DASH program, which will obtain 456\nWFC3 $H_{160}$ pointings in 57 orbits, covering an area of 0.6 degree$^2$ in\nthe COSMOS field down to $H_{160} = 25$. When completed, the program will more\nthan triple the area of extra-galactic survey fields covered by near-IR imaging\nat HST resolution. We demonstrate the viability of the method with the first\nfour orbits (32 pointings) of this program. We show that the resolution of the\nWFC3 camera is preserved, and that structural parameters of galaxies are\nconsistent with those measured in guided observations. \n\n"}
{"id": "1603.01950", "contents": "Title: Possible role of magnetic reconnection in the electromagnetic\n  counterpart of binary black hole merger Abstract: We propose a qualitative scenario to interpret the argued association between\nthe direct measurement of the gravitational wave event GW150914 by Laser\nInterferometer Gravitational Wave Observatory (LIGO)-Virgo collaborations and\nthe hard $X$-ray transient detected by Fermi-Gamma-ray Burst Monitor (GBM)\n$0.4$ sec after. In a binary system of two gravitationally collapsing objects\nwith a non-vanishing electric charge, the compenetration of the two\nmagnetospheres occurring during the coalescence, through magnetic reconnection,\nproduces a highly collimated relativistic outflow that becomes optically thin\nand shines in the GBM field of view. We propose that this process should be\nexpected as a commonplace in the future joint gravitational/electromagnetic\ndetections and, in case of neutron star-neutron star merger event, might lead\nto detectable $X$- or $\\gamma$-ray precursors to, or transients associated\nwith, the gravitational bursts. \n\n"}
{"id": "1603.04368", "contents": "Title: The GMRT 150 MHz All-sky Radio Survey: First Alternative Data Release\n  TGSS ADR1 Abstract: We present the first full release of a survey of the 150 MHz radio sky,\nobserved with the Giant Metrewave Radio Telescope between April 2010 and March\n2012 as part of the TGSS project. Aimed at producing a reliable compact source\nsurvey, our automated data reduction pipeline efficiently processed more than\n2000 hours of observations with minimal human interaction. Through application\nof innovative techniques such as image-based flagging, direction-dependent\ncalibration of ionospheric phase errors, correcting for systematic offsets in\nantenna pointing, and improving the primary beam model, we created good quality\nimages for over 95 percent of the 5336 pointings. Our data release covers\n36,900 square degrees (or 3.6 pi steradians) of the sky between -53 deg and +90\ndeg DEC, which is 90 percent of the total sky. The majority of pointing images\nhave a background RMS noise below 5 mJy/beam with an approximate resolution of\n25\" x 25\" (or 25\" x 25\" / cos (DEC - 19 deg) for pointings south of 19 deg\nDEC). We have produced a catalog of 0.62 Million radio sources derived from an\ninitial, high reliability source extraction at the 7 sigma level. For the bulk\nof the survey, the measured overall astrometric accuracy is better than 2\" in\nRA and DEC, while the flux density accuracy is estimated at ~10 percent. Within\nthe scope of the TGSS ADR project, the source catalog as well as 5336 mosaic\nimages (5 deg x 5 deg) and an image cutout service, are made publicly available\nonline as a service to the astronomical community. Next to enabling a wide\nrange of different scientific investigations, we anticipate that these survey\nproducts provide a solid reference for various new low-frequency radio aperture\narray telescopes (LOFAR, LWA, MWA, SKA-low), and can play an important role in\ncharacterizing the EoR foreground. The TGSS ADR project aims at continuously\nimproving the quality of the survey data products. \n\n"}
{"id": "1603.04671", "contents": "Title: Active galaxies can make axionic dark energy Abstract: AGN jets carry helical magnetic fields, which can affect dark matter if the\nlatter is axionic. This preliminary study shows that, in the presence of strong\nhelical magnetic fields, the nature of the axionic condensate may change and\nbecome dark energy. Such dark energy may affect galaxy formation and galactic\ndynamics, so this possibility should not be ignored when considering axionic\ndark matter. \n\n"}
{"id": "1603.04956", "contents": "Title: Description for rotating $C_{60}$ fullerenes via G\\\"odel-type metric Abstract: In this contribution a geometric approach to describe a rotating fullerene\nmolecule with Ih symmetry is developed. We analyze the quantum dynamics of\nquasiparticles in continuum limit considering a description of fullerene in a\nspherical solution of the G\\\"odel-type space-time with a topological defect. As\na result, we study the molecule in a rotating frame. Also we combine the well\nknow non-Abelian monopole approach with this geometric description, including\nthe case of the presence of the external Aharonov-Bohm flux. The energy levels\nand the persistent current for this study are obtained, and we show that they\ndepend on the geometrical and topological properties of the fullerene. Also, we\nverify recovering of the well known results for limiting cases. \n\n"}
{"id": "1603.06153", "contents": "Title: Rotational invariance conditions in elasticity, gradient elasticity and\n  its connection to isotropy Abstract: For homogeneous higher gradient elasticity models we discuss\nframe-indifference and isotropy requirements. To this end, we introduce the\nnotions of local versus global SO(3)-invariance and identify frame-indifference\n(traditionally) with global left SO(3)-invariance and isotropy with global\nright SO(3)-invariance. For specific restricted representations, the energy may\nalso be local left SO(3)-invariant as well as local right SO(3)-invariant. Then\nwe turn to linear models and consider a consequence of frame-indifference\ntogether with isotropy in nonlinear elasticity and apply this joint invariance\ncondition to some specific linear models. The interesting point is the\nappearance of finite rotations in transformations of a geometrically linear\nmodel. It is shown that when starting with a linear model defined already in\nthe infinitesimal symmetric strain $\\varepsilon = {\\rm sym} \\, {\\rm Grad}[u]$,\nthe new invariance condition is equivalent to isotropy of the linear\nformulation. Therefore, it may be used also in higher gradient elasticity\nmodels for a simple check of isotropy and for extensions to anisotropy. In this\nrespect we consider in more detail variational formulations of the linear\nindeterminate couple stress model, a new variant of it with symmetric force\nstresses and general linear gradient elasticity. \n\n"}
{"id": "1603.07722", "contents": "Title: RCSLenS: The Red Cluster Sequence Lensing Survey Abstract: We present the Red-sequence Cluster Lensing Survey (RCSLenS), an application\nof the methods developed for the Canada France Hawaii Telescope Lensing Survey\n(CFHTLenS) to the ~785deg$^2$, multi-band imaging data of the Red-sequence\nCluster Survey 2 (RCS2). This project represents the largest public,\nsub-arcsecond seeing, multi-band survey to date that is suited for weak\ngravitational lensing measurements. With a careful assessment of systematic\nerrors in shape measurements and photometric redshifts we extend the use of\nthis data set to allow cross-correlation analyses between weak lensing\nobservables and other data sets. We describe the imaging data, the data\nreduction, masking, multi-colour photometry, photometric redshifts, shape\nmeasurements, tests for systematic errors, and a blinding scheme to allow for\nmore objective measurements. In total we analyse 761 pointings with r-band\ncoverage, which constitutes our lensing sample. Residual large-scale B-mode\nsystematics prevent the use of this shear catalogue for cosmic shear science.\nThe effective number density of lensing sources over an unmasked area of\n571.7deg$^2$ and down to a magnitude limit of r~24.5 is 8.1 galaxies per\narcmin$^2$ (weighted: 5.5 arcmin$^{-2}$) distributed over 14 patches on the\nsky. Photometric redshifts based on 4-band griz data are available for 513\npointings covering an unmasked area of 383.5 deg$^2$ We present weak lensing\nmass reconstructions of some example clusters as well as the full survey\nrepresenting the largest areas that have been mapped in this way. All our data\nproducts are publicly available through CADC at\n  http://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/community/rcslens/query.html\n  in a format very similar to the CFHTLenS data release. \n\n"}
{"id": "1604.00950", "contents": "Title: Ultra faint dwarf galaxies: an arena for testing dark matter versus\n  modified gravity Abstract: The scenario consistent with a wealth of observations for the missing mass\nproblem is that of weakly interacting dark matter particles. However, arguments\nor proposals for a Newtonian or relativistic modified gravity scenario continue\nto be made. A distinguishing characteristic between the two scenarios is that\ndark matter particles can produce a gravitational effect, in principle, without\nthe need of baryons while this is not the case for the modified gravity\nscenario where such an effect must be correlated with the amount of baryonic\nmatter. We consider here ultra-faint dwarf (UFD) galaxies as a promising arena\nto test the two scenarios based on the above assertion. We compare the\ncorrelation of the luminosity with the velocity dispersion between samples of\nUFD and non-UFD galaxies, finding a significant loss of correlation for UFD\ngalaxies. For example, we find for 28 non-UFD galaxies a strong correlation\ncoefficient of -0.688 which drops to -0.077 for the 23 UFD galaxies. Incoming\nand future data will determine whether the observed stochasticity for UFD\ngalaxies is physical or due to systematics in the data. Such a loss of\ncorrelation (if it is to persist) is possible and consistent with the dark\nmatter scenario for UFD galaxies but would constitute a new challenge for the\nmodified gravity scenario. \n\n"}
{"id": "1604.02148", "contents": "Title: Detecting triple systems with gravitational wave observations Abstract: The Laser Interferometer Gravitational Wave Observatory (LIGO) has recently\ndiscovered gravitational waves (GWs) emitted by merging black hole binaries. We\nexamine whether future GW detections may identify triple companions of merging\nbinaries. Such a triple companion causes variations in the GW signal due to (1)\nthe varying path length along the line of sight during the orbit around the\ncenter of mass, (2) relativistic beaming, Doppler, and gravitational redshift,\n(3) the variation of the \"light\"-travel time in the gravitational field of the\ntriple companion, and (4) secular variations of the orbital elements. We find\nthat the prospects for detecting the triple companion are the highest for\nlow-mass compact object binaries which spend the longest time in the LIGO\nfrequency band. In particular, for merging neutron star binaries, LIGO may\ndetect a white dwarf or M-dwarf perturber at signal to noise ratio of 8, if it\nis within 0.4 solar radius distance from the binary and the system is within a\ndistance of 100 Mpc. Stellar mass (supermassive) black hole perturbers may be\ndetected at a factor 5x (1000x) larger separations. Such pertubers in orbit\naround the merging binary emit GWs at frequencies above 1 mHz detectable by the\nLaser Interferometer Space Antenna (LISA) in coincidence. \n\n"}
{"id": "1604.02290", "contents": "Title: Optimal scan strategies for future CMB satellite experiments Abstract: The B-mode polarisation power spectrum in the Cosmic Microwave Background\n(CMB) is about four orders of magnitude fainter than the CMB temperature power\nspectrum. Any instrumental imperfections that couple temperature fluctuations\nto B-mode polarisation must therefore be carefully controlled and/or removed.\nWe investigate the role that a scan strategy can have in mitigating certain\ncommon systematics by averaging systematic errors down with many crossing\nangles. We present approximate analytic forms for the error on the recovered\nB-mode power spectrum that would result from differential gain, differential\npointing and differential ellipticity for the case where two detector pairs are\nused in a polarisation experiment. We use these analytic predictions to search\nthe parameter space of common satellite scan strategies in order to identify\nthose features of a scan strategy that have most impact in mitigating\nsystematic effects. As an example we go on to identify a scan strategy suitable\nfor the CMB satellite proposed for the ESA M5 call. considering the practical\nconsiderations of fuel requirement, data rate and the relative orientation of\nthe telescope to the earth. Having chosen a scan strategy we then go on to\ninvestigate the suitability of the scan strategy. \n\n"}
{"id": "1604.02652", "contents": "Title: Hypergraphs in the characterization of regular vine copula structures Abstract: Vine copulas constitute a flexible way for modeling of dependences using only\npair copulas as building blocks. The pair-copula constructions introduced by\nJoe (1997) are able to encode more types of dependences in the same time since\nthey can be expressed as a product of different types of bi-variate copulas.\nThe Regular-vine structures (R-vines), as pair copulas corresponding to a\nsequence of trees, have been introduced by Bedford and Cooke (2001, 2002) and\nfurther explored by Kurowicka and Cooke (2006). The complexity of these models\nstrongly increases in larger dimensions. Therefore the so called truncated\nR-vines were introduced in Brechmann et al. (2012). In this paper we express\nthe Regular-vines using a special type of hypergraphs, which encodes the\nconditional independences. \n\n"}
{"id": "1604.04229", "contents": "Title: Towards automatic classification of all WISE sources Abstract: The WISE satellite has detected hundreds of millions sources over the entire\nsky. Classifying them reliably is however a challenging task due to\ndegeneracies in WISE multicolour space and low levels of detection in its two\nlongest-wavelength bandpasses. Here we aim at obtaining comprehensive and\nreliable star, galaxy and quasar catalogues based on automatic source\nclassification in full-sky WISE data. This means that the final classification\nwill employ only parameters available from WISE itself, in particular those\nreliably measured for a majority of sources. For the automatic classification\nwe applied the support vector machines (SVM) algorithm, which requires a\ntraining sample with relevant classes already identified, and we chose to use\nthe SDSS spectroscopic dataset for that purpose. By calibrating the classifier\non the test data drawn from SDSS, we first established that a polynomial kernel\nis preferred over a radial one for this particular dataset. Next, using three\nclassification parameters (W1 magnitude, W1-W2 colour, and a differential\naperture magnitude) we obtained very good classification efficiency in all the\ntests. At the bright end, the completeness for stars and galaxies reaches ~95%,\ndeteriorating to ~80% at W1=16 mag, while for quasars it stays at a level of\n~95% independently of magnitude. Similar numbers are obtained for purity.\nApplication of the classifier to full-sky WISE data, flux-limited to 16 mag\n(Vega) in the 3.4 {\\mu}m channel, and appropriate a posteriori cleaning allowed\nus to obtain reliably-looking catalogues of star and galaxy candidates.\nHowever, the sources flagged by the classifier as `quasars' are in fact\ndominated by dusty galaxies but also exhibit contamination from sources located\nmainly at low ecliptic latitudes, consistent with Solar System objects.\n[abridged] \n\n"}
{"id": "1604.04288", "contents": "Title: Metallicity-constrained merger rates of binary black holes and the\n  stochastic gravitational wave background Abstract: The recent detection of the binary black hole merger GW150914 demonstrates\nthe existence of black holes more massive than previously observed in X-ray\nbinaries in our Galaxy. This article explores different scenarios of black hole\nformation in the context of self-consistent cosmic chemical evolution models\nthat simultaneously match observations of the cosmic star formation rate,\noptical depth to reionization and metallicity of the interstellar medium. This\nframework is used to calculate the mass distribution of merging black hole\nbinaries and its evolution with redshift. We also study the implications of the\nblack hole mass distribution for the stochastic gravitational wave background\nfrom mergers and from core collapse events. \n\n"}
{"id": "1604.06107", "contents": "Title: Joint signal extraction from galaxy clusters in X-ray and SZ surveys: A\n  matched-filter approach Abstract: The hot ionized gas of the intra-cluster medium emits thermal radiation in\nthe X-ray band and also distorts the cosmic microwave radiation through the\nSunyaev-Zel'dovich (SZ) effect. Combining these two complementary sources of\ninformation through innovative techniques can therefore potentially improve the\ncluster detection rate when compared to using only one of the probes. Our aim\nis to build such a joint X-ray-SZ analysis tool, which will allow us to detect\nfainter or more distant clusters while maintaining high catalogue purity. We\npresent a method based on matched multifrequency filters (MMF) for extracting\ncluster catalogues from SZ and X-ray surveys. We first designed an X-ray\nmatched-filter method, analogous to the classical MMF developed for SZ\nobservations. Then, we built our joint X-ray-SZ algorithm by combining our\nX-ray matched filter with the classical SZ-MMF, for which we used the physical\nrelation between SZ and X-ray observations. We show that the proposed X-ray\nmatched filter provides correct photometry results, and that the joint matched\nfilter also provides correct photometry when the $F_{\\rm X}/Y_{500}$ relation\nof the clusters is known. Moreover, the proposed joint algorithm provides a\nbetter signal-to-noise ratio than single-map extractions, which improves the\ndetection rate even if we do not exactly know the $F_{\\rm X}/Y_{500}$ relation.\nThe proposed methods were tested using data from the ROSAT all-sky survey and\nfrom the Planck survey. \n\n"}
{"id": "1604.06211", "contents": "Title: Understanding the LIGO GW150914 event Abstract: We present a simplified method for the extraction of meaningful signals from\nHanford and Livingstone 32 seconds data for the GW150914 event made publicly\navailable by the LIGO collaboration and demonstrate its ability to reproduce\nthe LIGO collaboration's own results quantitatively given the assumption that\nall narrow peaks in the power spectrum are a consequence of physically\nuninteresting signals and can be removed. After the clipping of these peaks and\nreturn to the time domain, the GW150914 event is readily distinguished from\nbroadband background noise. This simple technique allows us to identify the\nGW150914 event without any assumption regarding its physical origin and with\nminimal assumptions regarding its shape. We also confirm that the LIGO GW150914\nevent is uniquely correlated in the Hanford and Livingston detectors for 4096\nsecond data at the level of $6-7\\,\\sigma$ with a temporal displacement of\n$\\tau=6.9 \\pm 0.4\\,$ms. We have also identified a few events that are\nmorphologically close to GW150914 but less strongly cross correlated with it. \n\n"}
{"id": "1604.08562", "contents": "Title: Unprecedented Fine Structure of a Solar Flare Revealed by the 1.6~m New\n  Solar Telescope Abstract: Solar flares signify the sudden release of magnetic energy and are sources of\nso called space weather. The fine structures (below 500 km) of flares are\nrarely observed and are accessible to only a few instruments world-wide. Here\nwe present observation of a solar flare using exceptionally high resolution\nimages from the 1.6~m New Solar Telescope (NST) equipped with high order\nadaptive optics at Big Bear Solar Observatory (BBSO). The observation reveals\nthe process of the flare in unprecedented detail, including the flare ribbon\npropagating across the sunspots, coronal rain (made of condensing plasma)\nstreaming down along the post-flare loops, and the chromosphere's response to\nthe impact of coronal rain, showing fine-scale brightenings at the footpoints\nof the falling plasma. Taking advantage of the resolving power of the NST, we\nmeasure the cross-sectional widths of flare ribbons, post-flare loops and\nfootpoint brighenings, which generally lie in the range of 80-200 km, well\nbelow the resolution of most current instruments used for flare studies.\nConfining the scale of such fine structure provides an essential piece of\ninformation in modeling the energy transport mechanism of flares, which is an\nimportant issue in solar and plasma physics. \n\n"}
{"id": "1605.00016", "contents": "Title: First Limits on the 21 cm Power Spectrum during the Epoch of X-ray\n  heating Abstract: We present first results from radio observations with the Murchison Widefield\nArray seeking to constrain the power spectrum of 21 cm brightness temperature\nfluctuations between the redshifts of 11.6 and 17.9 (113 and 75 MHz). Three\nhours of observations were conducted over two nights with significantly\ndifferent levels of ionospheric activity. We use these data to assess the\nimpact of systematic errors at low frequency, including the ionosphere and\nradio-frequency interference, on a power spectrum measurement. We find that\nafter the 1-3 hours of integration presented here, our measurements at the\nMurchison Radio Observatory are not limited by RFI, even within the FM band,\nand that the ionosphere does not appear to affect the level of power in the\nmodes that we expect to be sensitive to cosmology. Power spectrum detections,\ninconsistent with noise, due to fine spectral structure imprinted on the\nforegrounds by reflections in the signal-chain, occupy the spatial Fourier\nmodes where we would otherwise be most sensitive to the cosmological signal. We\nare able to reduce this contamination using calibration solutions derived from\nautocorrelations so that we achieve an sensitivity of $10^4$ mK on comoving\nscales $k\\lesssim 0.5 h$Mpc$^{-1}$. This represents the first upper limits on\nthe $21$ cm power spectrum fluctuations at redshifts $12\\lesssim z \\lesssim 18$\nbut is still limited by calibration systematics. While calibration improvements\nmay allow us to further remove this contamination, our results emphasize that\nfuture experiments should consider carefully the existence of and their ability\nto calibrate out any spectral structure within the EoR window. \n\n"}
{"id": "1605.00177", "contents": "Title: Solving the missing GRB neutrino and GRB-SN puzzles Abstract: Every GRB model where the progenitor is assumed to be a highly relativistic\nhadronic jet whose pions, muons and electron pair secondaries are feeding the\ngamma jets engine, necessarily (except for very fine-tuned cases) leads to a\nhigh average neutrino over photon radiant exposure (radiance), a ratio well\nabove unity, though the present observed average IceCube neutrino radiance is\nat most comparable to the gamma in the GRB one. Therefore no hadronic GRB,\nfireball or hadronic thin precessing jet, escaping exploding star in tunneled\nor penetrarting beam, can fit the actual observations. A new model is shown\nhere, based on a purely electronic progenitor jet, fed by neutrons (and relics)\nstripped from a neutron star (NS) by tidal forces of a black hole or NS\ncompanion, showering into a gamma jet. Such thin precessing spinning jets\nexplain unsolved puzzles such as the existence of the X-ray precursor in many\nGRBs. The present pure electron jet model, disentangling gamma and (absent)\nneutrinos, explains naturally why there is no gamma GRB correlates with any\nsimultaneous TeV IceCube astrophysical neutrinos. Rare unstable NS companion\nstages while feeding the jet may lead to an explosion simulating a SN event.\nRecent IceCube-160731A highest energy muon neutrino event with absent X-gamma\ntraces confirms the present model expectations. \n\n"}
{"id": "1605.01067", "contents": "Title: PRECESSION: Dynamics of spinning black-hole binaries with python Abstract: We present the numerical code PRECESSION: a new open-source python module to\nstudy the dynamics of precessing black-hole binaries in the post-Newtonian\nregime. The code provides a comprehensive toolbox to (i) study the evolution of\nthe black-hole spins along their precession cycles, (ii) perform\ngravitational-wave driven binary inspirals using both orbit-averaged and\nprecession-averaged integrations, and (iii) predict the properties of the\nmerger remnant through fitting formulae obtained from numerical-relativity\nsimulations. PRECESSION is a ready-to-use tool to add the black-hole spin\ndynamics to larger-scale numerical studies such as gravitational-wave parameter\nestimation codes, population synthesis models to predict gravitational-wave\nevent rates, galaxy merger trees and cosmological simulations of structure\nformation. PRECESSION provides fast and reliable integration methods to\npropagate statistical samples of black-hole binaries from/to large separations\nwhere they form to/from small separations where they become detectable, thus\nlinking gravitational-wave observations of spinning black-hole binaries to\ntheir astrophysical formation history. The code is also a useful tool to\ncompute initial parameters for numerical-relativity simulations targeting\nspecific precessing systems. PRECESSION can be installed from the Python\nPackage Index and it is freely distributed under version control on Github,\nwhere further documentation is provided. \n\n"}
{"id": "1605.01417", "contents": "Title: Spin-SILC: CMB polarisation component separation with spin wavelets Abstract: We present Spin-SILC, a new foreground component separation method that\naccurately extracts the cosmic microwave background (CMB) polarisation $E$ and\n$B$ modes from raw multifrequency Stokes $Q$ and $U$ measurements of the\nmicrowave sky. Spin-SILC is an internal linear combination method that uses\nspin wavelets to analyse the spin-2 polarisation signal $P = Q + iU$. The\nwavelets are additionally directional (non-axisymmetric). This allows different\nmorphologies of signals to be separated and therefore the cleaning algorithm is\nlocalised using an additional domain of information. The advantage of spin\nwavelets over standard scalar wavelets is to simultaneously and\nself-consistently probe scales and directions in the polarisation signal $P = Q\n+ iU$ and in the underlying $E$ and $B$ modes, therefore providing the ability\nto perform component separation and $E$-$B$ decomposition concurrently for the\nfirst time. We test Spin-SILC on full-mission Planck simulations and data and\nshow the capacity to correctly recover the underlying cosmological $E$ and $B$\nmodes. We also demonstrate a strong consistency of our CMB maps with those\nderived from existing component separation methods. Spin-SILC can be combined\nwith the pseudo- and pure $E$-$B$ spin wavelet estimators presented in a\ncompanion paper to reliably extract the cosmological signal in the presence of\ncomplicated sky cuts and noise. Therefore, it will provide a\ncomputationally-efficient method to accurately extract the CMB $E$ and $B$\nmodes for future polarisation experiments. \n\n"}
{"id": "1605.01531", "contents": "Title: LOFAR 150-MHz observations of the Bo\\\"otes field: Catalogue and Source\n  Counts Abstract: We present the first wide area (19 deg$^2$), deep ($\\approx120-150$ {\\mu}Jy\nbeam$^{-1}$), high resolution ($5.6 \\times 7.4$ arcsec) LOFAR High Band Antenna\nimage of the Bo\\\"otes field made at 130-169 MHz. This image is at least an\norder of magnitude deeper and 3-5 times higher in angular resolution than\npreviously achieved for this field at low frequencies. The observations and\ndata reduction, which includes full direction-dependent calibration, are\ndescribed here. We present a radio source catalogue containing 6276 sources\ndetected over an area of $19$\\,deg$^2$, with a peak flux density threshold of\n$5\\sigma$. As the first thorough test of the facet calibration strategy,\nintroduced by van Weeren et al., we investigate the flux and positional\naccuracy of the catalogue. We present differential source counts that reach an\norder of magnitude deeper in flux density than previously achieved at these low\nfrequencies, and show flattening at 150 MHz flux densities below 10 mJy\nassociated with the rise of the low flux density star-forming galaxies and\nradio-quiet AGN. \n\n"}
{"id": "1605.02146", "contents": "Title: Gravitational-Wave Background from Binary Mergers and Metallicity\n  Evolution of Galaxies Abstract: The cosmological evolution of the binary black hole (BH) merger rate and the\nenergy density of the gravitational-wave (GW) background are investigated. To\nevaluate the redshift dependence of the BH formation rate, BHs are assumed to\noriginate from low-metallicity stars, and the relations between the star\nformation rate, metallicity and stellar mass of galaxies are combined with the\nstellar mass function at each redshift. As a result, it is found that when the\nenergy density of the GW background is scaled with the merger rate at the local\nUniverse, the scaling factor does not depend on the critical metallicity for\nthe formation of BHs. Also taking into account the merger of binary neutron\nstars, a simple formula to express the energy spectrum of the GW background is\nconstructed for the inspiral phase. The relation between the local merger rate\nand the energy density of the GW background will be examined by future GW\nobservations. \n\n"}
{"id": "1605.03588", "contents": "Title: Polarization of prompt and afterglow emission of Gamma-Ray Bursts Abstract: Gamma-ray bursts and their afterglows are thought to be produced by an\nultra-relativistic jet. One of the most important open questions is the outflow\ncomposition: the energy may be carried out from the central source either as\nkinetic energy (of baryons and/or pairs), or in electromagnetic form (Poynting\nflux). While the total observable flux may be indistinguishable in both cases,\nits polarization properties are expected to differ markedly. The prompt\nemission and afterglow polarization are also a powerful diagnostic of the jet\ngeometry. Again, with subtle and hardly detectable differences in the output\nflux, we have distinct polarization predictions. In this review we briefly\ndescribe the theoretical scenarios that have been developed following the\nobservations, and the now large observational datasets that for the prompt and\nthe afterglow phases are available. Possible implications of polarimetric\nmeasurements for quantum gravity theory testing are discussed, and future\nperspectives for the field briefly mentioned. \n\n"}
{"id": "1605.03617", "contents": "Title: Monte Carlo radiation transfer simulations of photospheric emission in\n  long-duration Gamma-Ray Bursts Abstract: We present MCRaT, a Monte Carlo Radiation Transfer code for self-consistently\ncomputing the light curves and spectra of the photospheric emission from\nrelativistic, unmagnetized jets. We apply MCRaT to a relativistic hydrodynamic\nsimulation of a long duration gamma-ray burst jet, and present the resulting\nlight-curves and time-dependent spectra for observers at various angles from\nthe jet axis. We compare our results to observational results and find that\nphotospheric emission is a viable model to explain the prompt phase of\nlong-duration gamma-ray bursts at the peak frequency and above, but faces\nchallenges in reproducing the flat spectrum below the peak frequency. We\nfinally discuss possible limitations of these results both in terms of the\nhydrodynamics and the radiation transfer and how these limitations could affect\nthe conclusions that we present. \n\n"}
{"id": "1605.07256", "contents": "Title: Exploring the evolution of Reionisation using a wavelet transform and\n  the light cone effect Abstract: The Cosmic Dawn and Epoch of Reionisation, during which collapsed structures\nproduce the first ionising photons and proceed to reionise the intergalactic\nmedium, span a large range in redshift (z~30-6) and time (t_{age} ~\n0.1-1.0~Gyr). Exploration of these epochs using the redshifted 21~cm emission\nline from neutral hydrogen is currently limited to statistical detection and\nestimation metrics (e.g., the power spectrum) due to the weakness of the\nsignal. Brightness temperature fluctuations in the line-of-sight (LOS)\ndimension are probed by observing the emission line at different frequencies,\nand their structure is used as a primary discriminant between the cosmological\nsignal and contaminating foreground extragalactic and Galactic continuum\nemission. Evolution of the signal over the observing bandwidth leads to the\n`line cone effect' whereby the HI structures at the start and end of the\nobserving band are not statistically consistent, yielding a biased estimate of\nthe signal power, and potential reduction in signal detectability. We implement\na wavelet transform to wide bandwidth radio interferometry experiments to probe\nthe local statistical properties of the signal. We show that use of the wavelet\ntransform yields estimates with improved estimation performance, compared with\nthe standard Fourier Transform over a fixed bandwidth. With the suite of\ncurrent and future large bandwidth reionisation experiments, such as with the\n300~MHz instantaneous bandwidth of the Square Kilometre Array, a transform that\nretains local information will be important. \n\n"}
{"id": "1605.09261", "contents": "Title: AMiBA: Cluster Sunyaev-Zel'dovich Effect Observations with the Expanded\n  13-Element Array Abstract: The Yuan-Tseh Lee Array for Microwave Background Anisotropy (AMiBA) is a\nco-planar interferometer array operating at a wavelength of 3mm to measure the\nSunyaev-Zeldovich effect (SZE) of galaxy clusters. In the first phase of\noperation -- with a compact 7-element array with 0.6m antennas (AMiBA-7) -- we\nobserved six clusters at angular scales from 5\\arcmin to 23\\arcmin. Here, we\ndescribe the expansion of AMiBA to a 13-element array with 1.2m antennas\n(AMiBA-13), its subsequent commissioning, and our cluster SZE observing\nprogram. The most important changes compared to AMiBA-7 are (1) array\nre-configuration with baselines ranging from 1.4m to 4.8m covering angular\nscales from 2\\arcmin to 11.5\\arcmin, (2) thirteen new lightweight\ncarbon-fiber-reinforced plastic (CFRP) 1.2m reflectors, and (3) additional\ncorrelators and six new receivers. From the AMiBA-13 SZE observing program, we\npresent here maps of a subset of twelve clusters. In highlights, we combine\nAMiBA-7 and AMiBA-13 observations of Abell 1689 and perform a joint fitting\nassuming a generalized NFW pressure profile. Our cylindrically integrated\nCompton-y values for this cluster are consistent with the BIMA/OVRA, SZA, and\nPlanck results. We report the first targeted SZE detection towards the\noptically selected galaxy cluster RCS J1447+0828, and we demonstrate the\nability of AMiBA SZE data to serve as a proxy for the total cluster mass.\nFinally, we show that our AMiBA-SZE derived cluster masses are consistent with\nrecent lensing mass measurements in the literature. \n\n"}
{"id": "1605.09380", "contents": "Title: Testing the wavelength dependence of cosmological redshift down to\n  $\\Delta z \\sim 10^{-6}$ Abstract: At the core of the standard cosmological model lies the assumption that the\nredshift of distant galaxies is independent of photon wavelength. This\ninvariance of cosmological redshift with wavelength is routinely found in all\ngalaxy spectra with a precision of $\\Delta$z~10$^{-4}$. The combined use of\napproximately half a million high-quality galaxy spectra from the Sloan Digital\nSky Survey (SDSS) allows us to explore this invariance down to a nominal\nprecision in redshift of one part per million (statistical). Our analysis is\nperformed over the redshift interval 0.02<z<0.25. We use the centroids of\nspectral lines over the 3700-6800\\AA\\ rest-frame optical window. We do not find\nany difference in redshift between the blue and red sides down to a precision\nof 10$^{-6}$ at z<0.1 and 10$^{-5}$ at 0.1<z<0.25 (i.e. at least an order of\nmagnitude better than with single galaxy spectra). This is the first time the\nwavelength-independence of the (1+z) redshift law is confirmed over a wide\nspectral window at this precision level. This result holds independently of the\nstellar population of the galaxies and their kinematical properties. This\nresult is also robust against wavelength calibration issues. The limited\nspectral resolution (R~2000) of the SDSS data combined with the asymmetric\nwavelength sampling of the spectral features in the observed restframe due to\nthe (1+z) stretching of the lines prevent our methodology to achieve a\nprecision higher than 10$^{-5}$, at z>0.1. Future attempts to constrain this\nlaw will require high quality galaxy spectra at higher resolution (R>10,000). \n\n"}
{"id": "1605.09717", "contents": "Title: Detecting dark matter waves with precision measurement tools Abstract: Virialized Ultra-Light Fields (VULFs) are viable cold dark matter candidates\nand include scalar and pseudo-scalar bosonic fields, such as axions and\ndilatons. Direct searches for VULFs rely on low-energy precision measurement\ntools. While the previous proposals have focused on detecting coherent\noscillations of the VULF signals at the VULF Compton frequencies at individual\ndevices, here I consider a network of such devices. VULFs are essentially dark\nmatter {\\em waves} and as such they carry both temporal and spatial phase\ninformation. Thereby, the discovery reach can be improved by using networks of\nprecision measurement tools. To formalize this idea, I derive a spatio-temporal\ntwo-point correlation function for the ultralight dark matter fields in the\nframework of the standard halo model. Due to VULFs being Gaussian random\nfields, the derived two-point correlation function fully determines $N$-point\ncorrelation functions. For a network of $N_{d}$ devices within the coherence\nlength of the field, the sensitivity compared to a single device can be\nimproved by a factor of $\\sqrt{N_{d}}$. Further, I derive a VULF dark matter\nsignal profile for an individual device. The resulting line shape is strongly\nasymmetric due to the parabolic dispersion relation for massive\nnon-relativistic bosons. I discuss the aliasing effect that extends the\ndiscovery reach to VULF frequencies higher than the experimental sampling rate.\nI present sensitivity estimates and develop a stochastic field SNR statistic.\nFinally, I consider an application of the developed formalism to atomic clocks\nand their networks. \n\n"}
{"id": "1606.00844", "contents": "Title: A search for X-ray reprocessing echoes in the power spectral density\n  functions of AGN Abstract: We present the results of a detailed study of the X-ray power spectra density\n(PSD) functions of twelve X-ray bright AGN, using almost all the archival\nXMM-Newton data. The total net exposure of the EPIC-pn light curves is larger\nthan 350 ks in all cases (and exceeds 1 Ms in the case of 1H 0707-497). In a\nphysical scenario in which X-ray reflection occurs in the inner part of the\naccretion disc of AGN, the X-ray reflection component should be a filtered echo\nof the X-ray continuum signal and should be equal to the convolution of the\nprimary emission with the response function of the disc. Our primary objective\nis to search for these reflection features in the 5-7 keV (iron line) and 0.5-1\nkeV (soft) bands, where the X-ray reflection fraction is expected to be\ndominant. We fit to the observed periodograms two models: a simple bending\npower law model (BPL) and a BPL model convolved with the transfer function of\nthe accretion disc assuming the lamp-post geometry and X-ray reflection from a\nhomogeneous disc. We do not find any significant features in the best-fitting\nBPL model residuals either in individual PSDs in the iron band, soft and full\nband (0.3-10 keV) or in the average PSD residuals of the brightest and more\nvariable sources (with similar black hole mass estimates). The typical\namplitude of the soft and full-band residuals is around 3-5 per cent. It is\npossible that the expected general relativistic effects are not detected\nbecause they are intrinsically lower than the uncertainty of the current PSDs,\neven in the strong relativistic case in which X-ray reflection occurs on a disc\naround a fast rotating black hole having an X-ray source very close above it.\nHowever, we could place strong constrains to the X-ray reflection geometry with\nthe current data sets if we knew in advance the intrinsic shape of the X-ray\nPSDs, particularly its high frequency slope. \n\n"}
{"id": "1606.01903", "contents": "Title: Mocking the Weak Lensing universe: the LensTools python computing\n  package Abstract: We present a newly developed software package which implements a wide range\nof routines frequently used in Weak Gravitational Lensing (WL). With the\ncontinuously increasing size of the WL scientific community we feel that easy\nto use Application Program Interfaces (APIs) for common calculations are a\nnecessity to ensure efficiency and coordination across different working\ngroups. Coupled with existing open source codes, such as CAMB and Gadget2,\nLensTools brings together a cosmic shear simulation pipeline which,\ncomplemented with a variety of WL feature measurement tools and parameter\nsampling routines, provides easy access to the numerics for theoretical studies\nof WL as well as for experiment forecasts. Being implemented in python,\nLensTools takes full advantage of a range of state--of--the art techniques\ndeveloped by the large and growing open--source software community\n(scipy,pandas,astropy,scikit-learn,emcee). We made the LensTools code available\non the Python Package Index and published its documentation on\nhttp://lenstools.readthedocs.io \n\n"}
{"id": "1606.02530", "contents": "Title: A Stringent Limit on the Warm Dark Matter Particle Masses from the\n  Abundance of z=6 Galaxies in the Hubble Frontier Fields Abstract: We show that the recently measured UV luminosity functions of ultra-faint\nlensed galaxies at z= 6 in the Hubble Frontier Fields provide an unprecedented\nprobe for the mass m_X of the Warm Dark Matter candidates independent of\nbaryonic physics. Comparing the measured abundance of the faintest galaxies\nwith the maximum number density of dark matter halos in WDM cosmologies sets a\nrobust limit m_X> 2.9 keV for the mass of thermal relic WDM particles at a\n1-sigma confidence level, m_X> 2.4 keV at 2-sigma, and m_X> 2.1 keV at 3-sigma.\nThese constitute the tightest constraints on WDM particle mass derived to date\nindependently of the baryonic physics involved in galaxy formation. We discuss\nthe impact of our results on the production mechanism of sterile neutrinos. In\nparticular, if sterile neutrinos are responsible for the 3.5 keV line reported\nin observations of X-ray clusters, our results firmly rule out the\nDodelson-Widrow production mechanism, and yield m_{sterile}> 6.1 keV for\nsterile neutrinos produced via the Shi-Fuller mechanism. \n\n"}
{"id": "1606.03451", "contents": "Title: SKA Weak Lensing III: Added Value of Multi-Wavelength Synergies for the\n  Mitigation of Systematics Abstract: In this third paper of a series on radio weak lensing for cosmology with the\nSquare Kilometre Array, we scrutinise synergies between cosmic shear\nmeasurements in the radio and optical/near-IR bands for mitigating systematic\neffects. We focus on three main classes of systematics: (i) experimental\nsystematic errors in the observed shear; (ii) signal contamination by intrinsic\nalignments; and (iii) systematic effects due to an incorrect modelling of\nnon-linear scales. First, we show that a comprehensive, multi-wavelength\nanalysis provides a self-calibration method for experimental systematic\neffects, only implying <50% increment on the errors on cosmological parameters.\nWe also illustrate how the cross-correlation between radio and optical/near-IR\nsurveys alone is able to remove residual systematics with variance as large as\n0.00001, i.e. the same order of magnitude of the cosmological signal. This also\nopens the possibility of using such a cross-correlation as a means to detect\nunknown experimental systematics. Secondly, we demonstrate that, thanks to\npolarisation information, radio weak lensing surveys will be able to mitigate\ncontamination by intrinsic alignments, in a way similar but fully complementary\nto available self-calibration methods based on position-shear correlations.\nLastly, we illustrate how radio weak lensing experiments, reaching higher\nredshifts than those accessible to optical surveys, will probe dark energy and\nthe growth of cosmic structures in regimes less contaminated by non-linearities\nin the matter perturbations. For instance, the higher-redshift bins of radio\ncatalogues peak at z~0.8-1, whereas their optical/near-IR counterparts are\nlimited to z<0.5-0.7. This translates into having a cosmological signal 2 to 5\ntimes less contaminated by non-linear perturbations. \n\n"}
{"id": "1606.05151", "contents": "Title: Simulations of solitonic core mergers in ultra-light axion dark matter\n  cosmologies Abstract: Using three-dimensional simulations, we study the dynamics and final\nstructure of merging solitonic cores predicted to form in ultra-light axion\ndark matter halos. The classical, Newtonian equations of motion of a\nself-gravitating scalar field are described by the Schr\\\"odinger-Poisson\nequations. We investigate mergers of ground state (boson star) configurations\nwith varying mass ratios, relative phases, orbital angular momenta and initial\nseparation with the primary goal to understand the mass loss of the emerging\ncore by gravitational cooling. Previous results showing that the final density\nprofiles have solitonic cores and NFW-like tails are confirmed. In binary\nmergers, the final core mass does not depend on initial phase difference or\nangular momentum and only depends on mass ratio, total initial mass, and total\nenergy of the system. For non-zero angular momenta, the otherwise spherical\ncores become rotating ellipsoids. The results for mergers of multiple cores are\nqualitatively identical. \n\n"}
{"id": "1606.05337", "contents": "Title: Calibration of weak-lensing shear in the Kilo-Degree Survey Abstract: We describe and test the pipeline used to measure the weak lensing shear\nsignal from the Kilo Degree Survey (KiDS). It includes a novel method of\n`self-calibration' that partially corrects for the effect of noise bias. We\nalso discuss the `weight bias' that may arise in optimally-weighted\nmeasurements, and present a scheme to mitigate that bias. To study the residual\nbiases arising from both galaxy selection and shear measurement, and to derive\nan empirical correction to reduce the shear biases to $\\lesssim 1\\%$, we create\na suite of simulated images whose properties are close to those of the KiDS\nsurvey observations. We find that the use of `self-calibration' reduces the\nadditive and multiplicative shear biases significantly, although further\ncorrection via a calibration scheme is required, which also corrects for a\ndependence of the bias on galaxy properties. We find that the calibration\nrelation itself is biased by the use of noisy, measured galaxy properties,\nwhich may limit the final accuracy that can be achieved. We assess the accuracy\nof the calibration in the tomographic bins used for the KiDS cosmic shear\nanalysis, testing in particular the effect of possible variations in the\nuncertain distributions of galaxy size, magnitude and ellipticity, and conclude\nthat the calibration procedure is accurate at the level of multiplicative bias\n$\\lesssim 1\\%$ required for the KiDS cosmic shear analysis. \n\n"}
{"id": "1606.06268", "contents": "Title: CosmicFish Implementation Notes V1.0 Abstract: CosmicFish is a publicly available library to perform Fisher matrix forecast\nfor several cosmological observations. With the present implementation notes we\nprovide a guide to the physical and technical details of the library. We\nreproduce here the details and all the relevant equations, as they appear in\nthe code. We submit these notes to the arXiv to grant full and permanent access\nto this material which provides a useful guidance to forecasting and the use of\nCosmicFish code. We will update this set of notes when relevant modifications\nto the CosmicFish code will be released. The present version is based on\nCosmicFish Jun16. \n\n"}
{"id": "1606.06367", "contents": "Title: Will Kinematic Sunyaev-Zel'dovich Measurements Enhance the Science\n  Return from Galaxy Redshift Surveys? Abstract: Yes. Future CMB experiments such as Advanced ACTPol and CMB-S4 should achieve\nmeasurements with S/N of $> 0.1$ for the typical galaxies in redshift surveys.\nThese measurements will provide complementary measurements of the growth rate\nof large scale structure $f$ and the expansion rate of the Universe $H$ to\ngalaxy clustering measurements. This paper emphasizes that there is significant\ninformation in the anisotropy of the relative pairwise kSZ measurements. We\nexpand the relative pairwise kSZ power spectrum in Legendre polynomials and\nconsider up to its octopole. Assuming that the noise in the filtered maps is\nuncorrelated between the positions of galaxies in the survey, we derive a\nsimple analytic form for the power spectrum covariance of the relative pairwise\nkSZ temperature in redshift space. While many previous studies have assumed\noptimistically that the optical depth of the galaxies $\\tau_{\\rm T}$ in the\nsurvey is known, we marginalize over $\\tau_{\\rm T}$, to compute constraints on\nthe growth rate $f$ and the expansion rate $H$. For realistic sure parameters,\nwe find that combining kSZ and galaxy redshift survey data reduces the\nmarginalized $1$-$\\sigma$ errors on $H$ and $f$ by $\\sim50$-$70\\%$ compared to\nthe galaxy-only analysis. \n\n"}
{"id": "1606.06455", "contents": "Title: Generalisations of Fisher Matrices Abstract: Fisher matrices play an important role in experimental design and in data\nanalysis. Their primary role is to make predictions for the inference of model\nparameters - both their errors and covariances. In this short review, I outline\na number of extensions to the simple Fisher matrix formalism, covering a number\nof recent developments in the field. These are: (a) situations where the data\n(in the form of (x,y) pairs) have errors in both x and y; (b) modifications to\nparameter inference in the presence of systematic errors, or through fixing the\nvalues of some model parameters; (c) Derivative Approximation for LIkelihoods\n(DALI) - higher-order expansions of the likelihood surface, going beyond the\nGaussian shape approximation; (d) extensions of the Fisher-like formalism, to\ntreat model selection problems with Bayesian evidence. \n\n"}
{"id": "1606.06725", "contents": "Title: Technical Considerations in Magnetic Analogue Models Abstract: The analogy between vorticity and magnetic fields has been a subject of\ninterest to researchers for a considerable period of time, mainly because of\nthe structural similarities between the systems of equations that govern the\nevolution of the two fields. We recently presented the analysis of magnetic\nfields and hydrodynamics vorticity fields and argued for a formal theory of\nanalogue magnetism. This article provides in depth technical details of the\nrelevant considerations for the simulation procedures and extends the analyses\nto a range of fluids. \n\n"}
{"id": "1606.06758", "contents": "Title: Comparing cosmic web classifiers using information theory Abstract: We introduce a decision scheme for optimally choosing a classifier, which\nsegments the cosmic web into different structure types (voids, sheets,\nfilaments, and clusters). Our framework, based on information theory, accounts\nfor the design aims of different classes of possible applications: (i)\nparameter inference, (ii) model selection, and (iii) prediction of new\nobservations. As an illustration, we use cosmographic maps of web-types in the\nSloan Digital Sky Survey to assess the relative performance of the classifiers\nT-web, DIVA and ORIGAMI for: (i) analyzing the morphology of the cosmic web,\n(ii) discriminating dark energy models, and (iii) predicting galaxy colors. Our\nstudy substantiates a data-supported connection between cosmic web analysis and\ninformation theory, and paves the path towards principled design of analysis\nprocedures for the next generation of galaxy surveys. We have made the cosmic\nweb maps, galaxy catalog, and analysis scripts used in this work publicly\navailable. \n\n"}
{"id": "1606.07261", "contents": "Title: Real-time cosmography with redshift derivatives Abstract: The drift in the redshift of objects passively following the cosmological\nexpansion has long been recognized as a key model-independent probe of\ncosmology. Here, we study the cosmological relevance of measurements of time or\nredshift derivatives of this drift, arguing that the combination of first and\nsecond redshift derivatives is a powerful test of the $\\Lambda$CDM cosmological\nmodel. In particular, the latter can be obtained numerically from a set of\nmeasurements of the drift at different redshifts. We show that, in the\nlow-redshift limit, a measurement of the derivative of the drift can provide a\nconstraint on the jerk parameter, which is $j=1$ for flat $\\Lambda$CDM, while\ngenerically $j\\neq1$ for other models. We emphasize that such a measurement is\nwell within the reach of the ELT-HIRES and SKA Phase 2 array surveys. \n\n"}
{"id": "1606.07434", "contents": "Title: Cosmological Constraints with Clustering-Based Redshifts Abstract: We demonstrate that observations lacking reliable redshift information, such\nas photometric and radio continuum surveys, can produce robust measurements of\ncosmological parameters when empowered by clustering-based redshift estimation.\nThis method infers the redshift distribution based on the spatial clustering of\nsources, using cross-correlation with a reference dataset with known redshifts.\nApplying this method to the existing SDSS photometric galaxies, and projecting\nto future radio continuum surveys, we show that sources can be efficiently\ndivided into several redshift bins, increasing their ability to constrain\ncosmological parameters. We forecast constraints on the dark-energy\nequation-of-state and on local non-gaussianity parameters. We explore several\npertinent issues, including the tradeoff between including more sources versus\nminimizing the overlap between bins, the shot-noise limitations on binning, and\nthe predicted performance of the method at high redshifts. Remarkably, we find\nthat, once this technique is implemented, constraints on dynamical dark energy\nfrom the SDSS imaging catalog can be competitive with, or better than, those\nfrom the spectroscopic BOSS survey and even future planned experiments.\nFurther, constraints on primordial non-Gaussianity from future large-sky\nradio-continuum surveys can outperform those from the Planck CMB experiment,\nand rival those from future spectroscopic galaxy surveys. The application of\nthis method thus holds tremendous promise for cosmology. \n\n"}
{"id": "1606.07437", "contents": "Title: Orbital eccentricities in primordial black holes binaries Abstract: It was recently suggested that the merger of $\\sim30\\,M_\\odot$ primordial\nblack holes (PBHs) may provide a significant number of events in\ngravitational-wave observatories over the next decade, if they make up an\nappreciable fraction of the dark matter. Here we show that measurement of the\neccentricities of the inspiralling binary black holes can be used to\ndistinguish these binaries from those produced by more traditional\nastrophysical mechanisms. These PBH binaries are formed on highly eccentric\norbits and can then merge on timescales that in some cases are years or less,\nretaining some eccentricity in the last seconds before the merger. This is to\nbe contrasted with massive-stellar-binary, globular-cluster, or other\nastrophysical origins for binary black holes (BBHs) in which the orbits have\nvery effectively circularized by the time the BBH enters the observable LIGO\nwindow. Here we discuss the features of the gravitational-wave signals that\nindicate this eccentricity and forecast the sensitivity of LIGO and the\nEinstein Telescope to such effects. We show that if PBHs make up the dark\nmatter, then roughly one event should have a detectable eccentricity given\nLIGO's expected sensitivity and observing time of six years. The Einstein\nTelescope should see $O(10)$ such events after ten years. \n\n"}
{"id": "1606.09128", "contents": "Title: The Train Wreck Cluster Abell 520 and the Bullet Cluster 1E0657-558 in a\n  Generalized Theory of Gravitation Abstract: A major hurdle for modified gravity theories is to explain the dynamics of\ngalaxy clusters. A case is made for a generalized gravitational theory called\nScalar-Tensor-Vector-Gravity (STVG) or MOG (modified gravity) to explain\nmerging cluster dynamics. The paper presents the results of a re-analysis of\nthe Bullet Cluster, as well as an analysis of the Train Wreck Cluster in the\nweak gravitational field limit without dark matter. The King-$\\beta$ model is\nused to fit the X-ray data of both clusters, and the $\\kappa$-maps are computed\nusing the parameters of this fit. The amount of galaxies in the clusters is\nestimated by subtracting the predicted $\\kappa$-map from the $\\kappa$-map data.\nThe estimate for the Bullet Cluster is that $14.1\\%$ of the cluster is composed\nof galaxies. For the Train Wreck Cluster, if the Jee et al. data are used,\n$25.7\\%$ of the cluster is composed of galaxies. The baryon matter in the\ngalaxies and the enhanced strength of gravitation in MOG, shift the lensing\npeaks making them offset from the gas. The work demonstrates that this\ngeneralized gravitational theory can explain merging cluster dynamics without\ndark matter. \n\n"}
{"id": "1606.09615", "contents": "Title: The Herschel-ATLAS Data Release 1 Paper I: Maps, Catalogues and Number\n  Counts Abstract: We present the first major data release of the largest single key-project in\narea carried out in open time with the Herschel Space Observatory. The Herschel\nAstrophysical Terahertz Large Area Survey (H-ATLAS) is a survey of 600 deg^2 in\nfive photometric bands - 100, 160, 250, 350 and 500 um - with the PACS and\nSPIRE cameras. In this paper and a companion paper (Bourne et al. 2016) we\npresent the survey of three fields on the celestial equator, covering a total\narea of 161.6 deg^2 and previously observed in the Galaxy and Mass Assembly\n(GAMA) spectroscopic survey. This paper describes the Herschel images and\ncatalogues of the sources detected on the SPIRE 250 um images. The 1-sigma\nnoise for source detection, including both confusion and instrumental noise, is\n7.4, 9.4 and 10.2 mJy at 250, 350 and 500 um. Our catalogue includes 120230\nsources in total, with 113995, 46209 and 11011 sources detected at >4-sigma at\n250, 350 and 500 um. The catalogue contains detections at >3-sigma at 100 and\n160 um for 4650 and 5685 sources, and the typical noise at these wavelengths is\n44 and 49 mJy. We include estimates of the completeness of the survey and of\nthe effects of flux bias and also describe a novel method for determining the\ntrue source counts. The H-ATLAS source counts are very similar to the source\ncounts from the deeper HerMES survey at 250 and 350 um, with a small difference\nat 500 um. Appendix A provides a quick start in using the released datasets,\nincluding instructions and cautions on how to use them. \n\n"}
{"id": "1607.00270", "contents": "Title: Constraining the dark energy equation of state using Bayes theorem and\n  the Kullback-Leibler divergence Abstract: Data-driven model-independent reconstructions of the dark energy equation of\nstate $w(z)$ are presented using Planck 2015 era CMB, BAO, SNIa and\nLyman-$\\alpha$ data. These reconstructions identify the $w(z)$ behaviour\nsupported by the data and show a bifurcation of the equation of state posterior\nin the range $1.5{<}z{<}3$. Although the concordance $\\Lambda$CDM model is\nconsistent with the data at all redshifts in one of the bifurcated spaces, in\nthe other a supernegative equation of state (also known as `phantom dark\nenergy') is identified within the $1.5 \\sigma$ confidence intervals of the\nposterior distribution. To identify the power of different datasets in\nconstraining the dark energy equation of state, we use a novel formulation of\nthe Kullback--Leibler divergence. This formalism quantifies the information the\ndata add when moving from priors to posteriors for each possible dataset\ncombination. The SNIa and BAO datasets are shown to provide much more\nconstraining power in comparison to the Lyman-$\\alpha$ datasets. Further, SNIa\nand BAO constrain most strongly around redshift range $0.1-0.5$, whilst the\nLyman-$\\alpha$ data constrains weakly over a broader range. We do not attribute\nthe supernegative favouring to any particular dataset, and note that the\n$\\Lambda$CDM model was favoured at more than $2$ log-units in Bayes factors\nover all the models tested despite the weakly preferred $w(z)$ structure in the\ndata. \n\n"}
{"id": "1607.01005", "contents": "Title: CosmicFish Validation Notes V1.0 Abstract: These notes show and comment the examples that have been used to validate the\nCosmicFish code. We compare the results obtained with the code to several other\nresults available in literature finding an overall good level of agreement. We\nwill update this set of notes when relevant modifications to the CosmicFish\ncode will be released or other validation examples are worked out. The\nCosmicFish code and the package to produce all the validation results presented\nhere are publicly available at http://cosmicfish.github.io. The present version\nis based on CosmicFish Jun16. \n\n"}
{"id": "1607.02012", "contents": "Title: Analysis of the Very Inner Milky Way Dark Matter Distribution and\n  Gamma-Ray Signals Abstract: We analyze the possibility that the HESS gamma-ray source at the Galactic\nCenter could be explained as the secondary flux produced by annihilation of TeV\nDark Matter (TeVDM) particles with locally enhanced density, in a region\nspatially compatible with the HESS observations themselves. We study the inner\n100 pc considering (i) the extrapolation of several density profiles from\nstate-of-the-art N-body + Hydrodynamics simulations of Milky Way-like galaxies,\n(ii) the DM spike induced by the black hole, and (iii) the DM particles\nscattering off by bulge stars. We show that in some cases the DM spike may\nprovide the enhancement in the flux required to explain the cut-off in the HESS\nJ1745-290 gamma-ray spectra as TeVDM. In other cases, it may helps to describe\nthe spatial tail reported by HESS II at angular scales < 0.54 degrees towards\nSgr A. \n\n"}
{"id": "1607.03144", "contents": "Title: The clustering of galaxies in the completed SDSS-III Baryon Oscillation\n  Spectroscopic Survey: Angular clustering tomography and its cosmological\n  implications Abstract: We investigate the cosmological implications of studying galaxy clustering\nusing a tomographic approach applied to the final BOSS DR12 galaxy sample,\nincluding both auto- and cross-correlation functions between redshift shells.\nWe model the signal of the full shape of the angular correlation function,\n$\\omega(\\theta)$, in redshift bins using state-of-the-art modelling of\nnon-linearities, bias and redshift-space distortions. We present results on the\nredshift evolution of the linear bias of BOSS galaxies, which cannot be\nobtained with traditional methods for galaxy-clustering analysis. We also\nobtain constraints on cosmological parameters, combining this tomographic\nanalysis with measurements of the cosmic microwave background (CMB) and type Ia\nsupernova (SNIa). We explore a number of cosmological models, including the\nstandard $\\Lambda$CDM model and its most interesting extensions, such as\ndeviations from $w_\\rm{DE} = -1$, non-minimal neutrino masses, spatial\ncurvature and deviations from general relativity using the growth-index\n$\\gamma$ parametrisation. These results are, in general, comparable to the most\nprecise present-day constraints on cosmological parameters, and show very good\nagreement with the standard model. In particular, combining CMB,\n$\\omega(\\theta)$ and SNIa, we find a value of $w_\\rm{DE}$ consistent with $-1$\nto a precision better than 5\\% when it is assumed to be constant in time, and\nbetter than 6\\% when we also allow for a spatially-curved Universe. \n\n"}
{"id": "1607.03446", "contents": "Title: Unresolved versus resolved: testing the validity of young simple stellar\n  population models with VLT/MUSE observations of NGC 3603 Abstract: CONTEXT. Stellar populations are the building blocks of galaxies including\nthe Milky Way. The majority, if not all extragalactic studies are entangled\nwith the use of stellar population models given the unresolved nature of their\nobservation. Extragalactic systems contain multiple stellar populations with\ncomplex star formation histories. However, their study is mainly based upon the\nprinciples of simple stellar populations (SSP). Hence, it is critical to\nexamine the validity of SSP models. AIMS. This work aims to empirically test\nthe validity of SSP models. This is done by comparing SSP models against\nobservations of spatially resolved young stellar population in the\ndetermination of its physical properties, i.e. age and metallicity. METHODS.\nIntegral field spectroscopy of a young stellar cluster in the Milky Way, NGC\n3603, is used to study the properties of the cluster both as a resolved and\nunresolved stellar population. The unresolved stellar population is analysed\nusing the H$\\alpha$ equivalent width as an age indicator, and the ratio of\nstrong emission lines to infer metallicity. In addition, spectral energy\ndistribution (SED) fitting using STARLIGHT, is used to infer these properties\nfrom the integrated spectrum. Independently, the resolved stellar population is\nanalysed using the color-magnitude diagram (CMD) for age and metallicity\ndetermination. As the SSP model represents the unresolved stellar population,\nthe derived age and metallicity are put to test whether they agree with those\nderived from resolved stars. RESULTS. The age and metallicity estimate of NGC\n3603 derived from integrated spectroscopy are confirmed to be within the range\nof those derived from the CMD of the resolved stellar population, including\nother estimates found in the literature. The result from this pilot study\nsupports the reliability of SSP models for studying unresolved young stellar\npopulations. \n\n"}
{"id": "1607.03459", "contents": "Title: Null-stream pointing with pulsar timing arrays Abstract: Locating sources on the sky is one of the largest challenges in gravitational\nwave astronomy, owing to the omni-directional nature of gravitational wave\ndetection techniques, and the often intrinsically weak signals being observed.\nGround-based detectors can address the pointing problem by observing with a\nnetwork of detectors, effectively triangulating signal locations by observing\nthe arrival times across the network. Space-based detectors will observe\nlong-lived sources that persist while the detector moves relative to their\nlocation on the sky, using Doppler shifts of the signal to locate the sky\nposition. While these methods improve the pointing capability of a detector or\nnetwork, the angular resolution is still coarse compared to the standards one\nexpects from electromagnetic astronomy. Another technique that can be used for\nsky localization is null-stream pointing. In the case where multiple\nindependent data streams exist, a single astrophysical source of gravitational\nwaves will appear in each of the data streams. Taking the signals from multiple\ndetectors in linear combination with each other, one finds there is a two\nparameter family of coefficients that effectively null the gravitational wave\nsignal; those two parameters are the angles that define the sky location of the\nsource. This technique has been demonstrated for a network of ground-based\ninterferometric observatories, and for 6-link space interferometers. This paper\nderives and extends the null-stream pointing method to the unique case of\npulsar timing residuals. The basic method is derived and demonstrated, and the\nnecessity of using the method with multiple sub-arrays of pulsars in the pulsar\ntiming array network is considered. \n\n"}
{"id": "1607.03537", "contents": "Title: Hubble parameter measurement constraints on the redshift of the\n  deceleration-acceleration transition, dynamical dark energy, and space\n  curvature Abstract: We compile an updated list of 38 measurements of the Hubble parameter $H(z)$\nbetween redshifts $0.07 \\leq z \\leq 2.36$ and use them to place constraints on\nmodel parameters of constant and time-varying dark energy cosmological models,\nboth spatially flat and curved. We use five models to measure the redshift of\nthe cosmological deceleration-acceleration transition, $z_{\\rm da}$, from these\n$H(z)$ data. Within the error bars, the measured $z_{\\rm da}$ are insensitive\nto the model used, depending only on the value assumed for the Hubble constant\n$H_0$. The weighted mean of our measurements is $z_{\\rm da} = 0.72 \\pm 0.05\\\n(0.84 \\pm 0.03)$ for $H_0 = 68 \\pm 2.8\\ (73.24 \\pm 1.74)$ km s$^{-1}$\nMpc$^{-1}$ and should provide a reasonably model-independent estimate of this\ncosmological parameter. The $H(z)$ data are consistent with the standard\nspatially-flat $\\Lambda$CDM cosmological model but do not rule out non-flat\nmodels or dynamical dark energy models. \n\n"}
{"id": "1607.04361", "contents": "Title: On $C^1$, $C^2$, and weak type-$(1,1)$ estimates for linear elliptic\n  operators Abstract: We show that any weak solution to elliptic equations in divergence form is\ncontinuously differentiable provided that the modulus of continuity of\ncoefficients in the $L^1$-mean sense satisfies the Dini condition. This in\nparticular answers a question recently raised by Yanyan Li and allows us to\nimprove a result of Brezis. We also prove a weak type-$(1,1)$ estimate under a\nstronger assumption on the modulus of continuity. The corresponding results for\nnon-divergence form equations are also established. \n\n"}
{"id": "1607.06818", "contents": "Title: A synthetic model of the gravitational wave background from evolving\n  binary compact objects Abstract: Modeling the stochastic gravitational wave background from various\nastrophysical sources is a key objective in view of upcoming observations with\nground- and space-based gravitational wave observatories such as Advanced LIGO,\nVIRGO, eLISA and PTA. We develop a synthetic model framework that follows the\nevolution of single and binary compact objects in an astrophysical context. We\ndescribe the formation and merger rates of binaries, the evolution of their\norbital parameters with time and the spectrum of emitted gravitational waves at\ndifferent stages of binary evolution. Our approach is modular and allows us to\ntest and constrain different ingredients of the model, including stellar\nevolution, black hole formation scenarios and the properties of binary systems.\nWe use this framework in the context of a particularly well-motivated\nastrophysical setup to calculate the gravitational wave background from several\ntypes of sources, including inspiraling stellar-mass binary black holes that\nhave not merged during a Hubble time. We find that this signal, albeit weak,\nhas a characteristic shape that can help constrain the properties of binary\nblack holes in a way complementary to observations of the background from\nmerger events. We discuss possible applications of our framework in the context\nof other gravitational wave sources, such as supermassive black holes. \n\n"}
{"id": "1607.07410", "contents": "Title: Search for low-mass WIMPs in a 0.6 kg day exposure of the DAMIC\n  experiment at SNOLAB Abstract: We present results of a dark matter search performed with a 0.6 kg day\nexposure of the DAMIC experiment at the SNOLAB underground laboratory. We\nmeasure the energy spectrum of ionization events in the bulk silicon of\ncharge-coupled devices down to a signal of 60 eV electron equivalent. The data\nare consistent with radiogenic backgrounds, and constraints on the\nspin-independent WIMP-nucleon elastic-scattering cross section are accordingly\nplaced. A region of parameter space relevant to the potential signal from the\nCDMS-II Si experiment is excluded using the same target for the first time.\nThis result obtained with a limited exposure demonstrates the potential to\nexplore the low-mass WIMP region (<10 GeV/$c^{2}$) of the upcoming DAMIC100, a\n100 g detector currently being installed in SNOLAB. \n\n"}
{"id": "1607.07456", "contents": "Title: Upper limits on the rates of binary neutron star and\n  neutron-star--black-hole mergers from Advanced LIGO's first observing run Abstract: We report here the non-detection of gravitational waves from the merger of\nbinary neutron star systems and neutron-star--black-hole systems during the\nfirst observing run of Advanced LIGO. In particular we searched for\ngravitational wave signals from binary neutron star systems with component\nmasses $\\in [1,3] M_{\\odot}$ and component dimensionless spins $< 0.05$. We\nalso searched for neutron-star--black-hole systems with the same neutron star\nparameters, black hole mass $\\in [2,99] M_{\\odot}$ and no restriction on the\nblack hole spin magnitude. We assess the sensitivity of the two LIGO detectors\nto these systems, and find that they could have detected the merger of binary\nneutron star systems with component mass distributions of $1.35\\pm0.13\nM_{\\odot}$ at a volume-weighted average distance of $\\sim$ 70Mpc, and for\nneutron-star--black-hole systems with neutron star masses of $1.4M_\\odot$ and\nblack hole masses of at least $5M_\\odot$, a volume-weighted average distance of\nat least $\\sim$ 110Mpc. From this we constrain with 90% confidence the merger\nrate to be less than 12,600 Gpc$^{-3}$yr$^{-1}$ for binary-neutron star systems\nand less than 3,600 Gpc$^{-3}$yr$^{-1}$ for neutron-star--black-hole systems.\nWe find that if no detection of neutron-star binary mergers is made in the next\ntwo Advanced LIGO and Advanced Virgo observing runs we would place significant\nconstraints on the merger rates. Finally, assuming a rate of\n$10^{+20}_{-7}$Gpc$^{-3}$yr$^{-1}$ short gamma ray bursts beamed towards the\nEarth and assuming that all short gamma-ray bursts have binary-neutron-star\n(neutron-star--black-hole) progenitors we can use our 90% confidence rate upper\nlimits to constrain the beaming angle of the gamma-ray burst to be greater than\n${2.3^{+1.7}_{-1.1}}^{\\circ}$ (${4.3^{+3.1}_{-1.9}}^{\\circ}$). \n\n"}
{"id": "1607.07628", "contents": "Title: Contamination of the Epoch of Reionization power spectrum in the\n  presence of foregrounds Abstract: We construct foreground simulations comprising spatially correlated\nextragalactic and diffuse Galactic emission components and calculate the\n`intrinsic' (instrument-free) two-dimensional spatial power spectrum and the\ncylindrically and spherically averaged three-dimensional k-space power spectra\nof the Epoch of Reionization (EoR) and our foreground simulations using a\nBayesian power spectral estimation framework. This leads us to identify a model\ndependent region of optimal signal estimation for our foreground and EoR\nmodels, within which the spatial power in the EoR signal relative to\nforegrounds is maximised. We identify a target field dependent region, in\nk-space, of intrinsic foreground power spectral contamination at low k_perp and\nk_parallel and a transition to a relatively foreground-free intrinsic EoR\nwindow in the complement to this region. The contaminated region of k-space\ndemonstrates that simultaneous estimation of the EoR and foregrounds is\nimportant for obtaining statistically robust estimates of the EoR power\nspectrum; biased results will be obtained from methodologies that ignore their\ncovariance. Using simulated observations with frequency dependent uv-coverage\nand primary beam, with the former derived for HERA in 37-antenna and\n331-antenna configuration, we recover instrumental power spectra consistent\nwith their intrinsic counterparts. We discuss the implications of these results\nfor optimal strategies for unbiased estimation of the EoR power spectrum. \n\n"}
{"id": "1607.07791", "contents": "Title: Wormholes and black universes without phantom fields in Einstein-Cartan\n  theory Abstract: We obtain a family of regular static, spherically symmetric solutions in\nEinstein--Cartan theory with an electromagnetic field and a nonminimally\ncoupled scalar field with the correct sign of kinetic energy density. At\ndifferent values of its parameters, the solution, being asemptotically flat at\nlarge values of the radial coordinate, describes (i) twice asemptotically flat\nsymmetric wormholes, (ii) asymmetric wormholes with an AdS asymptotic at the\n\"far end\", (iii) regular black holes with an extremal horizon or two simple\nhorizons, and (iv) black universes with a de Sitter asymptotic at the \"far\nend\". As in other black universe models, it is a black hole as seen by a\ndistant observer, but beyond its horizon there is a nonsingular expanding\nuniverse. In all these cases, both the metric and the torsion are regular in\nthe whole space. \n\n"}
{"id": "1607.07850", "contents": "Title: GW150914: First search for the electromagnetic counterpart of a\n  gravitational-wave event by the TOROS collaboration Abstract: We present the results of the optical follow-up conducted by the TOROS\ncollaboration of the first gravitational-wave event GW150914. We conducted\nunfiltered CCD observations (0.35-1 micron) with the 1.5-m telescope at Bosque\nAlegre starting ~2.5 days after the alarm. Given our limited field of view\n(~100 square arcmin), we targeted 14 nearby galaxies that were observable from\nthe site and were located within the area of higher localization probability.\n  We analyzed the observations using two independent implementations of\ndifference-imaging algorithms, followed by a Random-Forest-based algorithm to\ndiscriminate between real and bogus transients. We did not find any bona fide\ntransient event in the surveyed area down to a 5-sigma limiting magnitude of\nr=21.7 mag (AB). Our result is consistent with the LIGO detection of a binary\nblack hole merger, for which no electromagnetic counterparts are expected, and\nwith the expected rates of other astrophysical transients. \n\n"}
{"id": "1608.00910", "contents": "Title: PYESSENCE - Generalised Coupled Quintessence Linear Perturbation Python\n  Code - User Guide Abstract: This paper is a guide to the installation and use of the Python package\nPYESSENCE. PYESSENCE is designed to evolve linear perturbations to Coupled\nQuintessence models with a arbitrary number of cold dark matter (CDM) fluids\nand dark energy (DE) scalar fields as dictated by a given model. The equations\nare sufficiently general to allow for more exotic dark matter with a non-zero\nequation of state. Several example uses are included in order to demonstrate\ntypical functionality to the potential user. PYESSENCE is released under an\nopen source modified BSD license and is available on Bitbucket. \n\n"}
{"id": "1608.02070", "contents": "Title: The HII Galaxy Hubble Diagram Strongly Favors $R_{\\rm h}=ct$ over\n  $\\Lambda$CDM Abstract: We continue to build support for the proposal to use HII galaxies (HIIGx) and\ngiant extragalactic HII regions (GEHR) as standard candles to construct the\nHubble diagram at redshifts beyond the current reach of Type Ia supernovae.\nUsing a sample of 25 high-redshift HIIGx, 107 local HIIGx, and 24 GEHR, we\nconfirm that the correlation between the emission-line luminosity and\nionized-gas velocity dispersion is a viable luminosity indicator, and use it to\ntest and compare the standard model $\\Lambda$CDM and the $R_{\\rm h}=ct$\nUniverse by optimizing the parameters in each cosmology using a maximization of\nthe likelihood function. For the flat $\\Lambda$CDM model, the best fit is\nobtained with $\\Omega_{\\rm m}= 0.40_{-0.09}^{+0.09}$. However, statistical\ntools, such as the Akaike (AIC), Kullback (KIC) and Bayes (BIC) Information\nCriteria favor $R_{\\rm h}=ct$ over the standard model with a likelihood of\n$\\approx 94.8\\%-98.8\\%$ versus only $\\approx 1.2\\%-5.2\\%$. For $w$CDM (the\nversion of $\\Lambda$CDM with a dark-energy equation of state $w_{\\rm de}\\equiv\np_{\\rm de}/\\rho_{\\rm de}$ rather than $w_{\\rm de}=w_{\\Lambda}=-1$), a\nstatistically acceptable fit is realized with $\\Omega_{\\rm\nm}=0.22_{-0.14}^{+0.16}$ and $w_{\\rm de}= -0.51_{-0.25}^{+0.15}$ which,\nhowever, are not fully consistent with their concordance values. In this case,\n$w$CDM has two more free parameters than $R_{\\rm h}=ct$, and is penalized more\nheavily by these criteria. We find that $R_{\\rm h}=ct$ is strongly favored over\n$w$CDM with a likelihood of $\\approx 92.9\\%-99.6\\%$ versus only $0.4\\%-7.1\\%$.\nThe current HIIGx sample is already large enough for the BIC to rule out\n$\\Lambda$CDM/$w$CDM in favor of $R_{\\rm h}=ct$ at a confidence level\napproaching $3\\sigma$. \n\n"}
{"id": "1608.02575", "contents": "Title: Substructure of fuzzy dark matter haloes Abstract: We derive the halo mass function (HMF) for fuzzy dark matter (FDM) by solving\nthe excursion set problem explicitly with a mass-dependent barrier function,\nwhich has not been done before. We find that compared to the naive approach of\nthe Sheth--Tormen HMF for FDM, our approach has a higher cut off mass and the\ncut off mass changes less strongly with redshifts. Using merger trees\nconstructed with a modified version of the Lacey & Cole formalism that accounts\nfor suppressed small scale power and the scale-dependent growth of FDM haloes\nand the semi-analytic GALACTICUS code, we study the statistics of halo\nsubstructure including the effects from dynamical friction and tidal stripping.\nWe find that if the dark matter is a mixture of cold dark matter (CDM) and FDM,\nthere will be a suppression on the halo substructure on small scales which may\nbe able to solve the Missing Satellites Problem faced by the pure CDM model.\nThe suppression becomes stronger with increasing FDM fraction or decreasing FDM\nmass. Thus, it may be used to constrain the FDM model. \n\n"}
{"id": "1608.03588", "contents": "Title: Measurement of the low-energy quenching factor in germanium using an\n  $^{88}$Y/Be photoneutron source Abstract: We employ an $^{88}$Y/Be photoneutron source to derive the quenching factor\nfor neutron-induced nuclear recoils in germanium, probing recoil energies from\na few hundred eV$_{nr}$ to 8.5keV$_{nr}$. A comprehensive Monte Carlo\nsimulation of our setup is compared to experimental data employing a Lindhard\nmodel with a free electronic energy loss $k$ and an adiabatic correction for\nsub-keV$_{nr}$ nuclear recoils. The best fit $k=0.179\\pm 0.001$ obtained using\na Monte Carlo Markov Chain (MCMC) ensemble sampler is in good agreement with\nprevious measurements, confirming the adequacy of the Lindhard model to\ndescribe the stopping of few-keV ions in germanium crystals at a temperature of\n$\\sim$77 K. This value of $k$ corresponds to a quenching factor of 13.7 % to\n25.3 % for nuclear recoil energies between 0.3 keV$_{nr}$ and 8.5 keV$_{nr}$,\nrespectively. \n\n"}
{"id": "1608.05356", "contents": "Title: Calibrating the Planck Cluster Mass Scale with CLASH Abstract: We determine the mass scale of Planck galaxy clusters using gravitational\nlensing mass measurements from the Cluster Lensing And Supernova survey with\nHubble (CLASH). We have compared the lensing masses to the Planck\nSunyaev-Zeldovich (SZ) mass proxy for 21 clusters in common, employing a\nBayesian analysis to simultaneously fit an idealized CLASH selection function\nand the distribution between the measured observables and true cluster mass. We\nused a tiered analysis strategy to explicitly demonstrate the importance of\npriors on weak lensing mass accuracy. In the case of an assumed constant bias,\n$b_{SZ}$, between true cluster mass, $M_{500}$, and the Planck mass proxy,\n$M_{PL}$, our analysis constrains $1- b_{SZ} = 0.73\\pm 0.10$ when moderate\npriors on weak lensing accuracy are used, including a zero-mean Gaussian with\nstandard deviation of 8% to account for possible bias in lensing mass\nestimations. Our analysis explicitly accounts for possible selection bias\neffects in this calibration sourced by the CLASH selection function. Our\nconstraint on the cluster mass scale is consistent with recent results from the\nWeighing the Giants program and the Canadian Cluster Comparison Project. It is\nalso consistent, at 1.34$\\sigma$, with the value needed to reconcile the Planck\nSZ cluster counts with Planck's base $\\Lambda$CDM model fit to the primary\ncosmic microwave background anisotropies. \n\n"}
{"id": "1608.07648", "contents": "Title: Results from a search for dark matter in the complete LUX exposure Abstract: We report constraints on spin-independent weakly interacting massive particle\n(WIMP)-nucleon scattering using a 3.35e4 kg-day exposure of the Large\nUnderground Xenon (LUX) experiment. A dual-phase xenon time projection chamber\nwith 250 kg of active mass is operated at the Sanford Underground Research\nFacility under Lead, South Dakota (USA). With roughly fourfold improvement in\nsensitivity for high WIMP masses relative to our previous results, this search\nyields no evidence of WIMP nuclear recoils. At a WIMP mass of 50 GeV/c^2,\nWIMP-nucleon spin-independent cross sections above 2.2e-46 cm^2 are excluded at\nthe 90% confidence level. When combined with the previously reported LUX\nexposure, this exclusion strengthens to 1.1e-46 cm^2 at 50 GeV/c^2. \n\n"}
{"id": "1609.03697", "contents": "Title: Measurement of Redshift Space Power Spectrum for BOSS galaxies and the\n  Growth Rate at redshift 0.57 Abstract: We present a measurement of two-dimensional (2D) redshift-space power\nspectrum for the Baryon Oscillation Spectroscopic Survey (BOSS) Data Release 11\nCMASS galaxies in the North Galactic Cap (NGC) based on the method developed by\nJing & Borner (2001). In this method, we first measure the 2D redshift-space\ncorrelation function for the CMASS galaxies, and obtain the 2D power spectrum\nbased on Fourier Transform of the correlation function. The method is tested\nwith an N-body mock galaxy catalog, which demonstrates that the method can\nyield an accurate and unbiased measurement of the redshift-space power spectrum\ngiven the input 2D correlation function is correct. Compared with previous\nmeasurements in literature that are usually based on direct Fourier Transform\nin redshift space, our method has the advantages that the window function and\nshot-noise are fully corrected. In fact, our 2D power spectrum, by its\nconstruction, can accurately reproduce the 2D correlation function, and in the\nmeanwhile can reproduce, for example, the 2D power spectrum of Beutler et al.\n(2014) accurately if ours is convolved with the window function they provided.\nThus, our measurement can facilitate a direct comparison with the theoretical\npredictions. With this accurate measurement of the 2D power spectrum, we then\ndevelop a method to measure the structure growth rate, by separating the\nanisotropic redshift-space power spectrum from the isotropic real-space power\nspectrum. We have also carefully corrected for the nonlinearities in the\nmapping from real space to redshift space, according to the theoretical model\nof Zhang et al. (2013). Finally, we obtain f(zeff)sigma_8(zeff)=0.438\\pm0.037\nat the effective redshift zeff=0.57, where f(zeff) is the linear growth rate at\nredshift zeff. The result is useful for constraining cosmological parameters.\nThe measurements of 2D power spectrum will be released soon. \n\n"}
{"id": "1609.04401", "contents": "Title: Spherical Harmonic Analyses of Intensity Mapping Power Spectra Abstract: Intensity mapping is a promising technique for surveying the large scale\nstructure of our Universe from $z=0$ to $z \\sim 150$, using the brightness\ntemperature field of spectral lines to directly observe previously unexplored\nportions of out cosmic timeline. Examples of targeted lines include the\n$21\\,\\textrm{cm}$ hyperfine transition of neutral hydrogen, rotational lines of\ncarbon monoxide, and fine structure lines of singly ionized carbon. Recent\nefforts have focused on detections of the power spectrum of spatial\nfluctuations, but have been hindered by systematics such as foreground\ncontamination. This has motivated the decomposition of data into Fourier modes\nperpendicular and parallel to the line-of-sight, which has been shown to be a\nparticularly powerful way to diagnose systematics. However, such a method is\nwell-defined only in the limit of a narrow-field, flat-sky approximation. This\nlimits the sensitivity of intensity mapping experiments, as it means that wide\nsurveys must be separately analyzed as a patchwork of smaller fields. In this\npaper, we develop a framework for analyzing intensity mapping data in a\nspherical Fourier-Bessel basis, which incorporates curved sky effects without\ndifficulty. We use our framework to generalize a number of techniques in\nintensity mapping data analysis from the flat sky to the curved sky. These\ninclude visibility-based estimators for the power spectrum, treatments of\ninterloper lines, and the \"foreground wedge\" signature of spectrally smooth\nforegrounds. \n\n"}
{"id": "1609.05572", "contents": "Title: The Bootstrap and von Neumann algebras: The Maximal Intersection Lemma Abstract: Given a suitably nested family $Z = \\langle Z(m,k,\\gamma) \\rangle_{m,k \\in\n\\mathbb N, \\gamma >0}$ of Borel subsets of matrices, and associated Borel\nmeasures and rate function, $\\mu$, an entropy, $\\chi^{\\mu}(Z)$, is introduced\nwhich generalizes the microstates free entropy in free probability theory.\nUnder weak regularity conditions there exists a finite tuple of operators $X$\nin a tracial von Neumann algebra such that \\begin{eqnarray*} \\chi^{\\mu}(X) &\n\\geq & \\chi^{\\mu}(X \\cap Z)\n  & = & \\chi^{\\mu}(Z)\\\\ \\end{eqnarray*} where $X \\cap Z = \\langle\n\\Gamma(X;m,k,\\gamma) \\cap Z(m,k,\\gamma) \\rangle_{m, k \\in \\mathbb N, \\gamma\n>0}$. This observation can be used to establish the existence of finite tuples\nof operators with finite $\\chi^{\\mu}$-entropy. The intuition and proof come\nfrom the bootstrap in statistical inference. \n\n"}
{"id": "1609.07142", "contents": "Title: Gravitational-wave cosmography with LISA and the Hubble tension Abstract: We propose that stellar-mass binary black holes like GW150914 will become a\ntool to explore the local Universe within ~100Mpc in the era of the Laser\nInterferometer Space Antenna (LISA). High calibration accuracy and annual\nmotion of LISA could enable us to localize up to ~60 binaries more accurately\nthan the error volume of ~100Mpc^3 without electromagnetic counterparts under\nmoderately optimistic assumptions. This accuracy will give us a fair chance to\ndetermine the host object solely by gravitational waves. By combining the\nluminosity distance extracted from gravitational waves with the cosmological\nredshift determined from the host, the local value of the Hubble parameter will\nbe determined up to a few % without relying on the empirically constructed\ndistance ladder. Gravitational-wave cosmography would pave the way for\nresolution of the disputed Hubble tension, where the local and global\nmeasurements disagree in the value of the Hubble parameter at 3.4sigma level,\nwhich amounts to ~9%. \n\n"}
{"id": "1609.08576", "contents": "Title: The Linear Growth of Structure in the R_h=ct Universe Abstract: We use recently published redshift space distortion measurements of the\ncosmological growth rate, f sigma_8(z), to examine whether the linear evolution\nof perturbations in the R_h=ct cosmology is consistent with the observed\ndevelopment of large scale structure. We find that these observations favour\nR_h=ct over the version of LCDM optimized with the joint analysis of Planck and\nlinear growth rate data, particularly in the redshift range 0 < z < 1, where a\nsignificant curvature in the functional form of f sigma_8(z) predicted by the\nstandard model---but not by R_h=ct---is absent in the data. When LCDM is\noptimized using solely the growth rate measurements, however, the two models\nfit the observations equally well though, in this case, the low-redshift\nmeasurements find a lower value for the fluctuation amplitude than is expected\nin Planck LCDM. Our results strongly affirm the need for more precise\nmeasurements of f sigma_8(z) at all redshifts, but especially at z < 1. \n\n"}
{"id": "1610.01577", "contents": "Title: An important role of temperature dependent scattering time in\n  understanding the high temperature thermoelectric behavior of strongly\n  correlated system: La$_{0.75}$Ba$_{0.25}$CoO$_{3}$ Abstract: In the present work, we have reported the temperature dependent thermopower\n($\\alpha$) behavior of La$_{0.75}$Ba$_{0.25}$CoO$_{3}$ compound in the\ntemperature range 300-600 K. Using the Heikes formula, the estimated value of\n$\\alpha$ corresponding to high-spin configuration of Co$^{3+}$ and Co$^{4+}$\nions is found to be $\\sim$$16$ $\\mu$V/K, which is close to the experimental\nvalue, $\\sim$13 $\\mu$V/K, observed at $\\sim$600 K. The temperature dependent TE\nbehavior of the compound is studied by combining the WIEN2K and BoltzTrap code.\nThe self consistency field calculations show that the compound have\nferromagnetic ground state structure. The electronic structure calculations\ngive half metallic characteristic with a small gap of $\\sim$50 meV for down\nspin channel. The large and positive value for down spin channel is obtained\ndue to the unique band structure shown by this spin channel. The temperature\ndependent relaxation time for both the spin-channel charge carriers is\nconsidered to study the thermopower data in temperature range 300-600 K. An\nalmost linear values of $\\tau_{up}$ and a non-linear values of $\\tau_{dn}$ are\ntaken into account for evaluation of $\\alpha$. By taking the temperature\ndependent values of relaxation time for both the spin channels, the calculated\nvalues of $\\alpha$ using two current model are found to be in good agreement\nwith experimental values in the temperature range 300-600 K. At 300 K, the\ncalculated value of electrical conductivity by using the same value of\nrelaxation time, i.e. 0.1 $\\times $10$^{-14}$ seconds for spin-up and 0.66\n$\\times $10$^{-14}$ seconds for spin-dn channel, is found to be equal to the\nexperimentally reported value. \n\n"}
{"id": "1610.02396", "contents": "Title: Readout technologies for directional WIMP Dark Matter detection Abstract: The measurement of the direction of WIMP-induced nuclear recoils is a\ncompelling but technologically challenging strategy to provide an unambiguous\nsignature of the detection of Galactic dark matter. Most directional detectors\naim to reconstruct the dark-matter-induced nuclear recoil tracks, either in gas\nor solid targets. The main challenge with directional detection is the need for\nhigh spatial resolution over large volumes, which puts strong requirements on\nthe readout technologies. In this paper we review the various detector readout\ntechnologies used by directional detectors. In particular, we summarize the\nchallenges, advantages and drawbacks of each approach, and discuss future\nprospects for these technologies. \n\n"}
{"id": "1610.02580", "contents": "Title: First results from a microwave cavity axion search at 24 micro-eV Abstract: We report on the first results from a new microwave cavity search for dark\nmatter axions with masses above $20~\\mu\\text{eV}$. We exclude axion models with\ntwo-photon coupling $g_{a\\gamma\\gamma} \\gtrsim 2\\times10^{-14}~\\text{GeV}^{-1}$\nover the range $23.55~\\mu\\text{eV} < m_a < 24.0~\\mu\\text{eV}$. These results\nrepresent two important achievements. First, we have reached cosmologically\nrelevant sensitivity an order of magnitude higher in mass than any existing\nlimits. Second, by incorporating a dilution refrigerator and Josephson\nparametric amplifier, we have demonstrated total noise approaching the standard\nquantum limit for the first time in an axion search. \n\n"}
{"id": "1610.02689", "contents": "Title: The Impact of Modeling Errors on Interferometer Calibration for 21 cm\n  Power Spectra Abstract: We study the impact of sky-based calibration errors from source mismodeling\non 21\\,cm power spectrum measurements with an interferometer and propose a\nmethod for suppressing their effects. While emission from faint sources that\nare not accounted for in calibration catalogs is believed to be spectrally\nsmooth, deviations of true visibilities from model visibilities are not, due to\nthe inherent chromaticity of the interferometer's sky-response (the \"wedge\").\nThus, unmodeled foregrounds, below the confusion limit of many instruments,\nintroduce frequency structure into gain solutions on the same line-of-sight\nscales on which we hope to observe the cosmological signal. We derive analytic\nexpressions describing these errors using linearized approximations of the\ncalibration equations and estimate the impact of this bias on measurements of\nthe 21\\,cm power spectrum during the Epoch of Reionization (EoR). Given our\ncurrent precision in primary beam and foreground modeling, this noise will\nsignificantly impact the sensitivity of existing experiments that rely on\nsky-based calibration. Our formalism describes the scaling of calibration with\narray and sky-model parameters and can be used to guide future instrument\ndesign and calibration strategy. We find that sky-based calibration that\ndown-weights long baselines can eliminate contamination in most of the region\noutside of the wedge with only a modest increase in instrumental noise. \n\n"}
{"id": "1610.07529", "contents": "Title: Radial acceleration relation from symmetron fifth forces Abstract: We show that the radial acceleration relation for rotationally-supported\ngalaxies may be explained, in the absence of cold dark matter, by a\nnon-minimally coupled scalar field, whose fifth forces are partially screened\non galactic scales by the symmetron mechanism. In addition, we show that\nsufficient energy is stored in the symmetron field to explain the dynamic\nstability of galactic disks. \n\n"}
{"id": "1610.08479", "contents": "Title: Detecting the gravitational wave background from primordial black hole\n  dark matter Abstract: The black hole merging rates inferred after the gravitational-wave detection\nby Advanced LIGO/VIRGO and the relatively high mass of the progenitors are\nconsistent with models of dark matter made of massive primordial black holes\n(PBH). PBH binaries emit gravitational waves in a broad range of frequencies\nthat will be probed by future space interferometers (LISA) and pulsar timing\narrays (PTA). The amplitude of the stochastic gravitational-wave background\nexpected for PBH dark matter is calculated taking into account various effects\nsuch as initial eccentricity of binaries, PBH velocities, mass distribution and\nclustering. It allows a detection by the LISA space interferometer, and\npossibly by the PTA of the SKA radio-telescope. Interestingly, one can\ndistinguish this background from the one of non-primordial massive binaries\nthrough a specific frequency dependence, resulting from the maximal impact\nparameter of binaries formed by PBH capture, depending on the PBH velocity\ndistribution and their clustering properties. Moreover, we find that the\ngravitational wave spectrum is boosted by the width of PBH mass distribution,\ncompared with that of the monochromatic spectrum. The current PTA constraints\nalready rule out broad-mass PBH models covering more than three decades of\nmasses, but evading the microlensing and CMB constraints due to clustering. \n\n"}
{"id": "1611.01545", "contents": "Title: Cosmological neutrino simulations at extreme scale Abstract: Constraining neutrino mass remains an elusive challenge in modern physics.\nPrecision measurements are expected from several upcoming cosmological probes\nof large-scale structure. Achieving this goal relies on an equal level of\nprecision from theoretical predictions of neutrino clustering. Numerical\nsimulations of the non-linear evolution of cold dark matter and neutrinos play\na pivotal role in this process. We incorporate neutrinos into the cosmological\nN-body code CUBEP3M and discuss the challenges associated with pushing to the\nextreme scales demanded by the neutrino problem. We highlight code\noptimizations made to exploit modern high performance computing architectures\nand present a novel method of data compression that reduces the phase-space\nparticle footprint from 24 bytes in single precision to roughly 9 bytes. We\nscale the neutrino problem to the Tianhe-2 supercomputer and provide details of\nour production run, named TianNu, which uses 86% of the machine (13,824 compute\nnodes). With a total of 2.97 trillion particles, TianNu is currently the\nworld's largest cosmological N-body simulation and improves upon previous\nneutrino simulations by two orders of magnitude in scale. We finish with a\ndiscussion of the unanticipated computational challenges that were encountered\nduring the TianNu runtime. \n\n"}
{"id": "1611.02113", "contents": "Title: Direct Dark Matter Search with the CRESST II Experiment Abstract: The quest for the particle nature of dark matter is one of the big open\nquestions of modern physics. A well motivated candidate for dark matter is the\nso-called WIMP - a weakly interacting massive particle. Recently several\ntheoretically well-motivated models with dark matter candidates in a mass\nregion below the WIMP mass-scale gained also a lot of interest, theoretically\nand experimentally. The CRESST II experiment located at the Gran Sasso\nlaboratory in Italy is optimised for the detection of the elastic scattering of\nthese low-mass dark matter particles with ordinary matter. We show the results\nobtained with an improved detector setup with increased radio purity and\nenhanced background rejection and the results obtained with a dedicated\nlow-threshold analysis of a single conventional detector module. The limit\nachieved is the most stringent limit achieved for direct dark matter\nexperiments in the mass region below 1.8 GeV/$c^{2}$. We will discuss the\nexpected performance for new small CRESST-type detectors to be used during the\nnext data taking phase. We conclude with an outlook of the future potential for\ndirect dark matter detection using further improved CRESST CaWO$_{4}$ cryogenic\ndetectors. \n\n"}
{"id": "1611.03848", "contents": "Title: Fast Radio Bursts with Extended Gamma-Ray Emission? Abstract: We consider some general implications of bright gamma-ray counterparts to\nfast radio bursts (FRBs). We show that even if these manifest in only a\nfraction of FRBs, gamma-ray detections with current satellites (including\nSwift) can provide stringent constraints on cosmological FRB models. If the\nenergy is drawn from the magnetic energy of a compact object such as a\nmagnetized neutron star, the sources should be nearby and be very rare. If the\nintergalactic medium is responsible for the observed dispersion measure, the\nrequired gamma-ray energy is comparable to that of the early afterglow or\nextended emission of short gamma-ray bursts. While this can be reconciled with\nthe rotation energy of compact objects, as expected in many merger scenarios,\nthe prompt outflow that yields the gamma-rays is too dense for radio waves to\nescape. Highly relativistic winds launched in a precursor phase, and forming a\nwind bubble, may avoid the scattering and absorption limits and could yield FRB\nemission. Largely independent of source models, we show that detectable radio\nafterglow emission from gamma-ray bright FRBs can reasonably be anticipated.\nGravitational wave searches can also be expected to provide useful tests. \n\n"}
{"id": "1611.05525", "contents": "Title: The Present and Future of Searching for Dark Matter with LUX and LZ Abstract: The LUX collaboration new results advance the search for dark matter\ncandidate particles in the 4 GeV/c^2 and higher mass range, with a maximal\nspin-independent 90% C.L. limit of 2 x 10^-46 cm^2 at 50 GeV/c^2 for its 332\nlive-day run, following after 6 x 10^-46 cm^2 cross-section for 33 GeV/c^2 mass\nfrom the re-analysis of its initial 95 live-day WIMP search data from December\n2015. LUX has performed multiple advanced in situ neutron and beta/gamma\ncalibrations of light and charge yields down to 1.1 and 0.7 keV, respectively,\nin nuclear recoil energy and 1.3 and 0.2 keV in units of electron recoil\nenergy, thereby bypassing the past practice of extrapolating yields from ex\nsitu calibrations or simulation models alone. For this conference proceedings,\nconsequences of the new calibrations for the limit on the interaction\ncross-sections for low-mass WIMPs will be highlighted. Previous claims of a\nWIMP signal, from other detectors, are now even more strongly disfavored,\nassuming isospin invariance and the standard WIMP halo model. Both\nspin-independent and spin-dependent limits will be discussed, including the\nrecent completion of LUX's 332-live-day blind run. Lastly, we highlight the\nconceptual design and future plan for its 10-ton-scale, next-generation\nsuccessor LZ, which plans on achieving < 3 x 10^-48 cm^2 sensitivity for a WIMP\nof mass 40 GeV/c^2. \n\n"}
{"id": "1611.07736", "contents": "Title: Strain in epitaxial MnSi films on Si(111) in the thick film limit\n  studied by polarization-dependent extended x-ray absorption fine structure Abstract: We report a study of the strain state of epitaxial MnSi films on Si(111)\nsubstrates in the thick film limit (100-500~\\AA) as a function of film\nthickness using polarization-dependent extended x-ray absorption fine structure\n(EXAFS). All films investigated are phase-pure and of high quality with a sharp\ninterface between MnSi and Si. The investigated MnSi films are in a thickness\nregime where the magnetic transition temperature $T_\\mathrm{c}$ assumes a\nthickness-independent enhanced value of $\\geq$43~K as compared with that of\nbulk MnSi, where $T_\\mathrm{c} \\approx 29~{\\rm K}$. A detailed refinement of\nthe EXAFS data reveals that the Mn positions are unchanged, whereas the Si\npositions vary along the out-of-plane [111]-direction, alternating in\norientation from unit cell to unit cell. Thus, for thick MnSi films, the unit\ncell volume is essentially that of bulk MnSi --- except in the vicinity of the\ninterface with the Si substrate (thin film limit). In view of the enhanced\nmagnetic transition temperature we conclude that the mere presence of the\ninterface, and its specific characteristics, strongly affects the magnetic\nproperties of the entire MnSi film, even far from the interface. Our analysis\nprovides invaluable information about the local strain at the MnSi/Si(111)\ninterface. The presented methodology of polarization dependent EXAFS can also\nbe employed to investigate the local structure of other interesting interfaces. \n\n"}
{"id": "1611.09787", "contents": "Title: Large-Scale Galaxy Bias Abstract: This review presents a comprehensive overview of galaxy bias, that is, the\nstatistical relation between the distribution of galaxies and matter. We focus\non large scales where cosmic density fields are quasi-linear. On these scales,\nthe clustering of galaxies can be described by a perturbative bias expansion,\nand the complicated physics of galaxy formation is absorbed by a finite set of\ncoefficients of the expansion, called bias parameters. The review begins with a\ndetailed derivation of this very important result, which forms the basis of the\nrigorous perturbative description of galaxy clustering, under the assumptions\nof General Relativity and Gaussian, adiabatic initial conditions. Key\ncomponents of the bias expansion are all leading local gravitational\nobservables, which include the matter density but also tidal fields and their\ntime derivatives. We hence expand the definition of local bias to encompass all\nthese contributions. This derivation is followed by a presentation of the\npeak-background split in its general form, which elucidates the physical\nmeaning of the bias parameters, and a detailed description of the connection\nbetween bias parameters and galaxy statistics. We then review the excursion-set\nformalism and peak theory which provide predictions for the values of the bias\nparameters. In the remainder of the review, we consider the generalizations of\ngalaxy bias required in the presence of various types of cosmological physics\nthat go beyond pressureless matter with adiabatic, Gaussian initial conditions:\nprimordial non-Gaussianity, massive neutrinos, baryon-CDM isocurvature\nperturbations, dark energy, and modified gravity. Finally, we discuss how the\ndescription of galaxy bias in the galaxies' rest frame is related to clustering\nstatistics measured from the observed angular positions and redshifts in actual\ngalaxy catalogs. \n\n"}
{"id": "1611.09862", "contents": "Title: Testing $\\Lambda$CDM at the lowest redshifts with SN Ia and galaxy\n  velocities Abstract: Peculiar velocities of objects in the nearby universe are correlated due to\nthe gravitational pull of large-scale structure. By measuring these velocities,\nwe have a unique opportunity to test the cosmological model at the lowest\nredshifts. We perform this test, using current data to constrain the amplitude\nof the \"signal\" covariance matrix describing the velocities and their\ncorrelations. We consider a new, well-calibrated \"Supercal\" set of low-redshift\nSNe Ia as well as a set of distances derived from the fundamental plane\nrelation of 6dFGS galaxies. Analyzing the SN and galaxy data separately, both\nresults are consistent with the peculiar velocity signal of our fiducial\n$\\Lambda$CDM model, ruling out the noise-only model with zero peculiar\nvelocities at greater than $7\\sigma$ (SNe) and $8\\sigma$ (galaxies). When the\ntwo data sets are combined appropriately, the precision of the test increases\nslightly, resulting in a constraint on the signal amplitude of $A =\n1.05_{-0.21}^{+0.25}$, where $A = 1$ corresponds to our fiducial model.\nEquivalently, we report an 11% measurement of the product of the growth rate\nand amplitude of mass fluctuations evaluated at $z_\\text{eff} = 0.02$, $f\n\\sigma_8 = 0.428_{-0.045}^{+0.048}$, valid for our fiducial $\\Lambda$CDM model.\nWe explore the robustness of the results to a number of conceivable variations\nin the analysis and find that individual variations shift the preferred signal\namplitude by less than ${\\sim}0.5\\sigma$. We briefly discuss our Supercal SN Ia\nresults in comparison with our previous results using the JLA compilation. \n\n"}
{"id": "1612.03173", "contents": "Title: NPTFit: A code package for Non-Poissonian Template Fitting Abstract: We present NPTFit, an open-source code package, written in python and cython,\nfor performing non-Poissonian template fits (NPTFs). The NPTF is a\nrecently-developed statistical procedure for characterizing the contribution of\nunresolved point sources (PSs) to astrophysical data sets. The NPTF was first\napplied to Fermi gamma-ray data to give evidence that the excess of ~GeV\ngamma-rays observed in the inner regions of the Milky Way likely arises from a\npopulation of sub-threshold point sources, and the NPTF has since found\nadditional applications studying sub-threshold extragalactic sources at high\nGalactic latitudes. The NPTF generalizes traditional astrophysical template\nfits to allow for the ability to search for populations of unresolved PSs that\nmay follow a given spatial distribution. NPTFit builds upon the framework of\nthe fluctuation analyses developed in X-ray astronomy, and thus likely has\napplications beyond those demonstrated with gamma-ray data. The NPTFit package\nutilizes novel computational methods to perform the NPTF efficiently. The code\nis available at https://github.com/bsafdi/NPTFit and up-to-date and extensive\ndocumentation may be found at http://nptfit.readthedocs.io \n\n"}
{"id": "1612.05284", "contents": "Title: Dark energy constraints from ESPRESSO tests of the stability of\n  fundamental couplings Abstract: ESPRESSO is a high-resolution-ultra-stable spectrograph for the VLT, whose\ncommissioning will start in 2017. One of its key science goals is to test the\nstability of nature's fundamental couplings with unprecedented accuracy and\ncontrol of possible systematics. A total of 27 nights of the ESPRESSO\nConsortium's guaranteed time observations (GTO) will be spent in testing the\nstability of the fine-structure constant and other fundamental couplings. A set\nof 14 priority optimal targets have been selected for the GTO period. Here we\nbriefly discuss the criteria underlying this selection and describe the\nselected targets, and then present detailed forecasts of the impact of these\nmeasurements on fundamental physics and cosmology, focusing on dark energy\nconstraints and using future supernova type Ia surveys as a comparison point.\nWe show how canonical reconstructions of the dark energy equation of state are\nimproved by the extended redshift range enabled by these spectroscopic\nmeasurements, and also quantify additional improvements foreseen for a future\nELT-HIRES instrument. \n\n"}
{"id": "1612.06282", "contents": "Title: Verlinde's emergent gravity versus MOND and the case of dwarf\n  spheroidals Abstract: In a recent paper, Erik Verlinde has developed the interesting possibility\nthat spacetime and gravity may emerge from the entangled structure of an\nunderlying microscopic theory. In this picture, dark matter arises as a\nresponse to the standard model of particle physics from the delocalized degrees\nof freedom that build up the dark energy component of the Universe. Dark matter\nphysics is then regulated by a characteristic acceleration scale $a_0$,\nidentified with the radius of the (quasi)-de Sitter universe we inhabit. For a\npoint particle matter source, or outside an extended spherically symmetric\nobject, MOND's empirical fitting formula is recovered. However, Verlinde's\ntheory critically departs from MOND when considering the inner structure of\ngalaxies, differing by a factor of 2 at the centre of a regular massive body.\nFor illustration, we use the eight classical dwarf spheroidal satellites of the\nMilky Way. These objects are perfect testbeds for the model given their\napproximate spherical symmetry, measured kinematics, and identified missing\nmass. We show that, without the assumption of a maximal deformation, Verlinde's\ntheory can fit the velocity dispersion profile in dwarf spheroidals with no\nfurther need of an extra dark particle component. If a maximal deformation is\nconsidered, the theory leads to mass-to-light ratios that are marginally larger\nthan expected from stellar population and formation history studies. We also\ncompare our results with the recent phenomenological interpolating MOND\nfunction of McGaugh {\\it et al}, and find a departure that, for these galaxies,\nis consistent with the scatter in current observations. \n\n"}
{"id": "1612.07053", "contents": "Title: The dynamics of the local group as a probe of Dark Energy and Modified\n  Gravity Abstract: In this work we study the dynamics of the Local Group (LG) within the context\nof cosmological models beyond General Relativity (GR). Using observable\nkinematic quantities to identify candidate pairs we build up samples of\nsimulated LG-like objects drawing from $f(R)$, symmetron, DGP and quintessence\nN-body simulations together with their $\\Lambda$CDM counterparts featuring the\nsame initial random phase realisations. The variables and intervals used to\ndefine LG-like objects are referred to as Local Group model; different models\nare used throughout this work and adapted to study their dynamical and\nkinematic properties. The aim is to determine how well the observed LG-dynamics\ncan be reproduced within cosmological theories beyond GR, We compute kinematic\nproperties of samples drawn from alternative theories and $\\Lambda$CDM and\ncompare them to actual observations of the LG mass, velocity and position. As a\nconsequence of the additional pull, pairwise tangential and radial velocities\nare enhanced in modified gravity and coupled dark energy with respect to\n$\\Lambda$CDM, inducing significant changes to the total angular momentum and\nenergy of the LG. For example, in models such as $f(R)$ and the symmetron this\nincrease can be as large as $60\\%$, peaking well outside of the $95\\%$\nconfidence region allowed by the data. This shows how simple considerations\nabout the LG dynamics can lead to clear small-scale observational signatures\nfor alternative scenarios, without the need of expensive high-resolution\nsimulations. \n\n"}
{"id": "1612.07426", "contents": "Title: Results from the DM-Ice17 Dark Matter Experiment at the South Pole Abstract: DM-Ice is a phased experimental program using low-background NaI(Tl) crystals\nwith the aim to unambiguously test the claim of dark matter detection by the\nDAMA experiments. DM-Ice17, consisting of 17 kg of NaI(Tl), has been\ncontinuously operating at a depth of 2457 m in the South Pole ice for over five\nyears, demonstrating the feasibility of a low-background experiment in the\nAntarctic ice. Studies of low and high energy spectra, an annual modulation\nanalysis, and a WIMP exclusion limit based on the physics run of DM-Ice17 are\npresented. We also discuss the plan and projected sensitivity of a new joint\nphysics run, COSINE-100, with upgraded detectors at the Yangyang Underground\nLaboratory in Korea. \n\n"}
{"id": "1701.00769", "contents": "Title: Search for Electronic Recoil Event Rate Modulation with 4 Years of\n  XENON100 Data Abstract: We report on a search for electronic recoil event rate modulation signatures\nin the XENON100 data accumulated over a period of 4 years, from January 2010 to\nJanuary 2014. A profile likelihood method, which incorporates the stability of\nthe XENON100 detector and the known electronic recoil background model, is used\nto quantify the significance of periodicity in the time distribution of events.\nThere is a weak modulation signature at a period of $431^{+16}_{-14}$ days in\nthe low energy region of $(2.0-5.8)$ keV in the single scatter event sample,\nwith a global significance of $1.9\\,\\sigma$, however no other more significant\nmodulation is observed. The expected annual modulation of a dark matter signal\nis not compatible with this result. Single scatter events in the low energy\nregion are thus used to exclude the DAMA/LIBRA annual modulation as being due\nto dark matter electron interactions via axial vector coupling at\n$5.7\\,\\sigma$. \n\n"}
{"id": "1701.01098", "contents": "Title: The direct localization of a fast radio burst and its host Abstract: Fast radio bursts are astronomical radio flashes of unknown physical nature\nwith durations of milliseconds. Their dispersive arrival times suggest an\nextragalactic origin and imply radio luminosities orders of magnitude larger\nthan any other kind of known short-duration radio transient. Thus far, all FRBs\nhave been detected with large single-dish telescopes with arcminute\nlocalizations, and attempts to identify their counterparts (source or host\ngalaxy) have relied on contemporaneous variability of field sources or the\npresence of peculiar field stars or galaxies. These attempts have not resulted\nin an unambiguous association with a host or multi-wavelength counterpart. Here\nwe report the sub-arcsecond localization of FRB 121102, the only known\nrepeating burst source, using high-time-resolution radio interferometric\nobservations that directly image the bursts themselves. Our precise\nlocalization reveals that FRB 121102 originates within 100 mas of a faint 180\nuJy persistent radio source with a continuum spectrum that is consistent with\nnon-thermal emission, and a faint (25th magnitude) optical counterpart. The\nflux density of the persistent radio source varies by tens of percent on day\ntimescales, and very long baseline radio interferometry yields an angular size\nless than 1.7 mas. Our observations are inconsistent with the fast radio burst\nhaving a Galactic origin or its source being located within a prominent\nstar-forming galaxy. Instead, the source appears to be co-located with a\nlow-luminosity active galactic nucleus or a previously unknown type of\nextragalactic source. [Truncated] If other fast radio bursts have similarly\nfaint radio and optical counterparts, our findings imply that direct\nsub-arcsecond localizations of FRBs may be the only way to provide reliable\nassociations. \n\n"}
{"id": "1701.01099", "contents": "Title: The Repeating Fast Radio Burst FRB 121102 as Seen on Milliarcsecond\n  Angular Scales Abstract: The millisecond-duration radio flashes known as Fast Radio Bursts (FRBs)\nrepresent an enigmatic astrophysical phenomenon. Recently, the sub-arcsecond\nlocalization (~ 100mas precision) of FRB121102 using the VLA has led to its\nunambiguous association with persistent radio and optical counterparts, and to\nthe identification of its host galaxy. However, an even more precise\nlocalization is needed in order to probe the direct physical relationship\nbetween the millisecond bursts themselves and the associated persistent\nemission. Here we report very-long-baseline radio interferometric observations\nusing the European VLBI Network and the 305-m Arecibo telescope, which\nsimultaneously detect both the bursts and the persistent radio emission at\nmilliarcsecond angular scales and show that they are co-located to within a\nprojected linear separation of < 40pc (< 12mas angular separation, at 95%\nconfidence). We detect consistent angular broadening of the bursts and\npersistent radio source (~ 2-4mas at 1.7GHz), which are both similar to the\nexpected Milky Way scattering contribution. The persistent radio source has a\nprojected size constrained to be < 0.7pc (< 0.2mas angular extent at 5.0GHz)\nand a lower limit for the brightness temperature of T_b > 5 x 10^7K. Together,\nthese observations provide strong evidence for a direct physical link between\nFRB121102 and the compact persistent radio source. We argue that a burst source\nassociated with a low-luminosity active galactic nucleus or a young neutron\nstar energizing a supernova remnant are the two scenarios for FRB121102 that\nbest match the observed data. \n\n"}
{"id": "1701.02034", "contents": "Title: Can black hole superradiance be induced by galactic plasmas? Abstract: Highly spinning Kerr black holes with masses $M = 1 - 100\\ M_{\\odot}$ are\nsubject to an efficient superradiant instability in the presence of bosons with\nmasses $\\mu \\sim 10^{-10} - 10^{-12}\\ {\\rm eV}$. We observe that this matches\nthe effective plasma-induced photon mass in diffuse galactic or intracluster\nenvironments ($\\omega_{\\rm pl} \\sim 10^{-10} - 10^{-12}\\ {\\rm eV}$). This\nsuggests that bare Kerr black holes within galactic or intracluster\nenvironments, possibly even including the ones produced in recently observed\ngravitational wave events, are unstable to formation of a photon cloud that may\ncontain a significant fraction of the mass of the original black hole. At\nmaximal efficiency, the instability timescale for a massive vector is\nmilliseconds, potentially leading to a transient rate of energy extraction from\na black hole in principle as large as $\\sim 10^{55} \\ {\\rm erg \\, s}^{-1}$. We\ndiscuss possible astrophysical effects this could give rise to, including a\nspeculative connection to Fast Radio Bursts. \n\n"}
{"id": "1701.03418", "contents": "Title: Direct Probe of Dark Energy through Gravitational Lensing Effect Abstract: We show that gravitational lensing can provide a direct method to probe the\nnature of dark energy at astrophysical scales. For lensing system as an\nisolated astrophysical object, we derive the dark energy contribution to\ngravitational potential as a repulsive power-law term, containing a generic\nequation of state parameter $w$. We find that it generates $w$-dependent and\nposition-dependent modification to the conventional light orbital equation of\n$w=-1$. With post-Newtonian approximation, we compute its direct effect for an\nisolated lensing system at astrophysical scales and find that the dark energy\nforce can deflect the path of incident light rays. We demonstrate that the\ndark-energy-induced deflection angle $\\Delta\\alpha_{DE}^{}\\propto\nM^{(1+\\frac{1}{3w})}$ (with $1+\\frac{1}{3w}>0$), which increases with the\nlensing mass $M$ and consistently approaches zero in the limit $M \\to 0$. This\neffect is distinctive because dark energy tends to diffuse the rays and\ngenerates concave lensing effect. This is in contrast to the conventional\nconvex lensing effect caused by both visible and dark matter. Measuring such\nconcave lensing effect can directly probe the existence and nature of dark\nenergy. We estimate this effect and show that the current gravitational lensing\nexperiments are sensitive to the direct probe of dark energy at astrophysical\nscales. For the special case $w=-1$, our independent study favors the previous\nworks that the cosmological constant can affect light bending, although our\nprediction qualitatively and quantitatively differ from the literature,\nincluding our consistent realization of $\\Delta\\alpha_{DE}\\to 0$ (under $M \\to\n0$) at the leading order. \n\n"}
{"id": "1701.05689", "contents": "Title: Photometric classification and redshift estimation of LSST Supernovae Abstract: Supernova (SN) classification and redshift estimation using photometric data\nonly have become very important for the Large Synoptic Survey Telescope (LSST),\ngiven the large number of SNe that LSST will observe and the impossibility of\nspectroscopically following up all the SNe. We investigate the performance of a\nSN classifier that uses SN colors to classify LSST SNe with the Random Forest\nclassification algorithm. Our classifier results in an AUC of 0.98 which\nrepresents excellent classification. We are able to obtain a photometric SN\nsample containing 99$\\%$ SNe Ia by choosing a probability threshold. We\nestimate the photometric redshifts (photo-z) of SNe in our sample by fitting\nthe SN light curves using the SALT2 model with nested sampling. We obtain a\nmean bias ($\\left<z_\\mathrm{phot}-z_\\mathrm{spec}\\right>$) of 0.012 with\n$\\sigma\\left( \\frac{z_\\mathrm{phot}-z_\\mathrm{spec}}{1+z_\\mathrm{spec}}\\right)\n= 0.0294$ without using a host-galaxy photo-z prior, and a mean bias\n($\\left<z_\\mathrm{phot}-z_\\mathrm{spec}\\right>$) of 0.0017 with $\\sigma\\left(\n\\frac{z_\\mathrm{phot}-z_\\mathrm{spec}}{1+z_\\mathrm{spec}}\\right) = 0.0116$\nusing a host-galaxy photo-z prior. Assuming a flat $\\Lambda CDM$ model with\n$\\Omega_m=0.3$, we obtain $\\Omega_m$ of $0.305\\pm0.008$ (statistical errors\nonly), using the simulated LSST sample of photometric SNe Ia (with intrinsic\nscatter $\\sigma_\\mathrm{int}=0.11$) derived using our methodology without using\nhost-galaxy photo-z prior. Our method will help boost the power of SNe from the\nLSST as cosmological probes. \n\n"}
{"id": "1701.06174", "contents": "Title: Feedback capacity and coding for the BIBO channel with a\n  no-repeated-ones input constraint Abstract: In this paper, a general binary-input binary-output (BIBO) channel is\ninvestigated in the presence of feedback and input constraints. The feedback\ncapacity and the optimal input distribution of this setting are calculated for\nthe case of an $(1,\\infty)$-RLL input constraint, that is, the input sequence\ncontains no consecutive ones. These results are obtained via explicit solution\nof a corresponding dynamic programming optimization problem. A simple coding\nscheme is designed based on the principle of posterior matching, which was\nintroduced by Shayevitz and Feder for memoryless channels. The posterior\nmatching scheme for our input-constrained setting is shown to achieve capacity\nusing two new ideas: \\textit{message history}, which captures the memory\nembedded in the setting, and \\textit{message splitting}, which eases the\nanalysis of the scheme. Additionally, in the special case of an S-channel, we\ngive a very simple zero-error coding scheme that is shown to achieve capacity.\nFor the input-constrained BSC, we show using our capacity formula that feedback\nincreases capacity when the cross-over probability is small. \n\n"}
{"id": "1701.07944", "contents": "Title: Tracing interstellar magnetic field using velocity gradient technique:\n  Application to Atomic Hydrogen data Abstract: The advancement of our understanding of MHD turbulence opens ways to develop\nnew techniques to probe magnetic fields. In MHD turbulence, the velocity\ngradients are expected to be perpendicular to magnetic fields and this fact was\nused by Gonsalvez-Casanova & Lazarian to introduce a new technique to trace\nmagnetic fields using velocity centroid gradients. The latter can be obtained\nfrom spectroscopic observations. We apply the technique to GALFA HI survey data\nand compare the directions of magnetic fields obtained with our technique with\nthe direction of magnetic fields obtained using PLANCK polarization. We find\nexcellent correspondence between the two ways of magnetic field tracing, which\nis obvious via visual comparison and through measuring of the statistics of\nmagnetic field fluctuations obtained with the polarization data and our\ntechnique. This suggests that the velocity centroid gradients can provide a\nreliable way of measuring of the foreground magnetic field fluctuations and\nthus provide a new way of separating foreground and CMB polarization signals. \n\n"}
{"id": "1701.08411", "contents": "Title: A cellular algebra with specific decomposition of the unity Abstract: Let $ \\mathbb{A}$ be a cellular algebra over a field $\\mathbb{F}$ with a\ndecomposition of the identity $ 1_{\\mathbb{A}} $ into orthogonal idempotents $\ne_i$, $i \\in I$ (for some finite set $I$) satisfying some properties. We\ndescribe the entire Loewy structure of cell modules of the algebra $ \\mathbb{A}\n$ by using the representation theory of the algebra $ e_i \\mathbb{A} e_i $ for\neach $ i $. Moreover, we also study the block theory of $\\mathbb{A}$ by using\nthis decomposition. \n\n"}
{"id": "1701.08718", "contents": "Title: Memory Augmented Neural Networks with Wormhole Connections Abstract: Recent empirical results on long-term dependency tasks have shown that neural\nnetworks augmented with an external memory can learn the long-term dependency\ntasks more easily and achieve better generalization than vanilla recurrent\nneural networks (RNN). We suggest that memory augmented neural networks can\nreduce the effects of vanishing gradients by creating shortcut (or wormhole)\nconnections. Based on this observation, we propose a novel memory augmented\nneural network model called TARDIS (Temporal Automatic Relation Discovery in\nSequences). The controller of TARDIS can store a selective set of embeddings of\nits own previous hidden states into an external memory and revisit them as and\nwhen needed. For TARDIS, memory acts as a storage for wormhole connections to\nthe past to propagate the gradients more effectively and it helps to learn the\ntemporal dependencies. The memory structure of TARDIS has similarities to both\nNeural Turing Machines (NTM) and Dynamic Neural Turing Machines (D-NTM), but\nboth read and write operations of TARDIS are simpler and more efficient. We use\ndiscrete addressing for read/write operations which helps to substantially to\nreduce the vanishing gradient problem with very long sequences. Read and write\noperations in TARDIS are tied with a heuristic once the memory becomes full,\nand this makes the learning problem simpler when compared to NTM or D-NTM type\nof architectures. We provide a detailed analysis on the gradient propagation in\ngeneral for MANNs. We evaluate our models on different long-term dependency\ntasks and report competitive results in all of them. \n\n"}
{"id": "1702.06148", "contents": "Title: FIRE-2 Simulations: Physics versus Numerics in Galaxy Formation Abstract: The Feedback In Realistic Environments (FIRE) project explores feedback in\ncosmological galaxy formation simulations. Previous FIRE simulations used an\nidentical source code (FIRE-1) for consistency. Motivated by the development of\nmore accurate numerics - including hydrodynamic solvers, gravitational\nsoftening, and supernova coupling algorithms - and exploration of new physics\n(e.g. magnetic fields), we introduce FIRE-2, an updated numerical\nimplementation of FIRE physics for the GIZMO code. We run a suite of\nsimulations and compare against FIRE-1: overall, FIRE-2 improvements do not\nqualitatively change galaxy-scale properties. We pursue an extensive study of\nnumerics versus physics. Details of the star-formation algorithm, cooling\nphysics, and chemistry have weak effects, provided that we include metal-line\ncooling and star formation occurs at higher-than-mean densities. We present new\nresolution criteria for high-resolution galaxy simulations. Most galaxy-scale\nproperties are robust to numerics we test, provided: (1) Toomre masses are\nresolved; (2) feedback coupling ensures conservation, and (3) individual\nsupernovae are time-resolved. Stellar masses and profiles are most robust to\nresolution, followed by metal abundances and morphologies, followed by\nproperties of winds and circum-galactic media (CGM). Central (~kpc) mass\nconcentrations in massive (L*) galaxies are sensitive to numerics (via\ntrapping/recycling of winds in hot halos). Multiple feedback mechanisms play\nkey roles: supernovae regulate stellar masses/winds; stellar mass-loss fuels\nlate star formation; radiative feedback suppresses accretion onto dwarfs and\ninstantaneous star formation in disks. We provide all initial conditions and\nnumerical algorithms used. \n\n"}
{"id": "1702.06529", "contents": "Title: Probing stellar binary black hole formation in galactic nuclei via the\n  imprint of their center of mass acceleration on their gravitational wave\n  signal Abstract: Multi-frequency gravitational wave (GW) observations are useful probes of the\nformation processes of coalescing stellar-mass binary black holes (BBHs). We\ndiscuss the phase drift in the GW inspiral waveform of the merging BBH caused\nby its center-of-mass acceleration. The acceleration strongly depends on the\nlocation where a BBH forms within a galaxy, allowing observations of the early\ninspiral phase of LIGO-like BBH mergers by the Laser Interferometer Space\nAntenna (LISA) to test the formation mechanism. In particular, BBHs formed in\ndense nuclear star clusters or via compact accretion disks around a nuclear\nsupermassive black hole in active galactic nuclei would suffer strong\nacceleration, and produce large phase drifts measurable by LISA. The host\ngalaxies of the coalescing BBHs in these scenarios can also be uniquely\nidentified in the LISA error volume, without electromagnetic counterparts. A\nnon-detection of phase drifts would rule out or constrain the contribution of\nthe nuclear formation channels to the stellar-mass BBH population. \n\n"}
{"id": "1702.08479", "contents": "Title: Revealing the formation of stellar-mass black hole binaries: The need\n  for deci-Hertz gravitational wave observatories Abstract: The formation of compact stellar-mass binaries is a difficult, but\ninteresting problem in astrophysics. There are two main formation channels: In\nthe field via binary star evolution, or in dense stellar systems via dynamical\ninteractions. The Laser Interferometer Gravitational-Wave Observatory (LIGO)\nhas detected black hole binaries (BHBs) via their gravitational radiation.\nThese detections provide us with information about the physical parameters of\nthe system. It has been claimed that when the Laser Interferometer Space\nAntenna (LISA) is operating, the joint observation of these binaries with LIGO\nwill allow us to derive the channels that lead to their formation. However, we\nshow that for BHBs in dense stellar systems dynamical interactions could lead\nto high eccentricities such that a fraction of the relativistic mergers are not\naudible to LISA. A non-detection by LISA puts a lower limit of about $0.005$ on\nthe eccentricity of a BHB entering the LIGO band. On the other hand, a\ndeci-Hertz observatory, like DECIGO or Tian Qin, would significantly enhance\nthe chances of a joint detection, and shed light on the formation channels of\nthese binaries. \n\n"}
{"id": "1702.08679", "contents": "Title: Upper limits on the 21-cm Epoch of Reionization power spectrum from one\n  night with LOFAR Abstract: We present the first limits on the Epoch of Reionization (EoR) 21-cm HI power\nspectra, in the redshift range $z=7.9-10.6$, using the Low-Frequency Array\n(LOFAR) High-Band Antenna (HBA). In total 13\\,h of data were used from\nobservations centred on the North Celestial Pole (NCP). After subtraction of\nthe sky model and the noise bias, we detect a non-zero $\\Delta^2_{\\rm I} = (56\n\\pm 13 {\\rm mK})^2$ (1-$\\sigma$) excess variance and a best 2-$\\sigma$ upper\nlimit of $\\Delta^2_{\\rm 21} < (79.6 {\\rm mK})^2$ at $k=0.053$$h$cMpc$^{-1}$ in\nthe range $z=$9.6-10.6. The excess variance decreases when optimizing the\nsmoothness of the direction- and frequency-dependent gain calibration, and with\nincreasing the completeness of the sky model. It is likely caused by (i)\nresidual side-lobe noise on calibration baselines, (ii) leverage due to\nnon-linear effects, (iii) noise and ionosphere-induced gain errors, or a\ncombination thereof. Further analyses of the excess variance will be discussed\nin forthcoming publications. \n\n"}
{"id": "1703.02991", "contents": "Title: The third data release of the Kilo-Degree Survey and associated data\n  products Abstract: The Kilo-Degree Survey (KiDS) is an ongoing optical wide-field imaging survey\nwith the OmegaCAM camera at the VLT Survey Telescope. It aims to image 1500\nsquare degrees in four filters (ugri). The core science driver is mapping the\nlarge-scale matter distribution in the Universe, using weak lensing shear and\nphotometric redshift measurements. Further science cases include galaxy\nevolution, Milky Way structure, detection of high-redshift clusters, and\nfinding rare sources such as strong lenses and quasars. Here we present the\nthird public data release (DR3) and several associated data products, adding\nfurther area, homogenized photometric calibration, photometric redshifts and\nweak lensing shear measurements to the first two releases. A dedicated pipeline\nembedded in the Astro-WISE information system is used for the production of the\nmain release. Modifications with respect to earlier releases are described in\ndetail. Photometric redshifts have been derived using both Bayesian template\nfitting, and machine-learning techniques. For the weak lensing measurements,\noptimized procedures based on the THELI data reduction and lensfit shear\nmeasurement packages are used. In DR3 stacked ugri images, weight maps, masks,\nand source lists for 292 new survey tiles (~300 sq.deg) are made available. The\nmulti-band catalogue, including homogenized photometry and photometric\nredshifts, covers the combined DR1, DR2 and DR3 footprint of 440 survey tiles\n(447 sq.deg). Limiting magnitudes are typically 24.3, 25.1, 24.9, 23.8 (5 sigma\nin a 2 arcsec aperture) in ugri, respectively, and the typical r-band PSF size\nis less than 0.7 arcsec. The photometric homogenization scheme ensures accurate\ncolors and an absolute calibration stable to ~2% for gri and ~3% in u.\nSeparately released are a weak lensing shear catalogue and photometric\nredshifts based on two different machine-learning techniques. \n\n"}
{"id": "1703.04885", "contents": "Title: Cosmic Voids in Evolving Dark Sector Cosmologies: the Low Redshift\n  Universe Abstract: We present a comparison of void properties between the standard model of\ncosmology, $\\Lambda$ Cold Dark Matter ($\\Lambda$CDM), and two alternative\ncosmological models with evolving and interacting dark sectors: a quintessence\nmodel ($\\phi$CDM) and a Coupled Dark Matter-Dark Energy (CDE) model. Using\n$N$-body simulations of these models, we derive several measures of void\nstatistics and properties, including distributions of void volume, ellipticity,\nprolateness, and average density. We find that the volume distribution derived\nfrom the CDE simulation deviates from the volume distribution derived from the\n$\\Lambda$CDM simulation in the present-day universe, suggesting that the\npresence of a coupled dark sector could be observable through this statistic.\nWe also find that the distributions of void ellipticity and prolateness are\npractically indistinguishable among the three models over the redshift range\n$z=0.0-1.0$, indicating that simple void shape statistics are insensitive to\nsmall changes in dark sector physics. Interestingly, we find that the\ndistributions of average void density measured in each of the three simulations\nare distinct from each other. In particular, voids on average tend to be\nemptiest under a quintessence model, and densest under the $\\Lambda$CDM model.\nOur results suggest that it is the scalar field present in both alternative\nmodels that causes emptier voids to form, while the coupling of the dark sector\nmitigates this effect by slowing down the evacuation of matter from voids. \n\n"}
{"id": "1703.06647", "contents": "Title: First results on the Epoch of Reionization from First Light with SARAS 2 Abstract: Long wavelength spectral distortions in the Cosmic Microwave Background\narising from the 21-cm transition in neutral Hydrogen are a key probe of Cosmic\nDawn and the Epoch of Reionization. These features may reveal the nature of the\nfirst stars and ultra-faint galaxies that transformed the spin temperature and\nionization state of the primordial gas. SARAS~2 is a spectral radiometer\npurposely designed for precision measurement of these monopole or all-sky\nglobal 21-cm spectral distortions. We use 63~hr night time observing of the\nradio background in the frequency band 110-200~MHz with the radiometer deployed\nat the Timbaktu Collective in Southern India to derive likelihoods for\nplausible redshifted 21-cm signals predicted by theoretical models. First light\nwith SARAS 2 disfavors the class of models that feature weak X-ray heating\n(with $f_X \\leq 0.1$) and rapid reionization (with peak $\\frac{dT_b}{dz} \\geq\n120~\\textrm{mK per unit redshift interval}$ ). \n\n"}
{"id": "1703.08323", "contents": "Title: Cluster algebras of finite type via a Coxeter element and Demazure\n  Crystals of type A Abstract: Let $G$ be a simply connected simple algebraic group over $\\mathbb{C}$, $B$\nand $B_-$ be its two opposite Borel subgroups. For two elements $u$, $v$ of the\nWeyl group $W$, it is known that the coordinate ring ${\\mathbb C}[G^{u,v}]$ of\nthe double Bruhat cell $G^{u,v}=BuB\\cap B_-vB_-$ is isomorphic to a cluster\nalgebra $\\mathcal{A}(\\textbf{i})_{{\\mathbb C}}$ [arXiv:math/0305434,\narXiv:1602.00498]. In the case $u=e$, $v=c^2$ ($c$ is a Coxeter element), the\nalgebra ${\\mathbb C}[G^{e,c^2}]$ has only finitely many cluster variables. In\nthis article, for $G={\\rm SL}_{r+1}(\\mathbb{C})$, we obtain explicit forms of\nall the cluster variables in $\\mathbb{C}[G^{e,c^2}]$ by considering its\nadditive categorification via preprojective algebras, and describe them in\nterms of monomial realizations of Demazure crystals. \n\n"}
{"id": "1703.09233", "contents": "Title: Mapping dark matter on the celestial sphere with weak gravitational\n  lensing Abstract: Convergence maps of the integrated matter distribution are a key science\nresult from weak gravitational lensing surveys. To date, recovering convergence\nmaps has been performed using a planar approximation of the celestial sphere.\nHowever, with the increasing area of sky covered by dark energy experiments,\nsuch as Euclid, the Large Synoptic Survey Telescope (LSST), and the Wide Field\nInfrared Survey Telescope (WFIRST), this assumption will no longer be valid. We\nrecover convergence fields on the celestial sphere using an extension of the\nKaiser-Squires estimator to the spherical setting. Through simulations we study\nthe error introduced by planar approximations. Moreover, we examine how best to\nrecover convergence maps in the planar setting, considering a variety of\ndifferent projections and defining the local rotations that are required when\nprojecting spin fields such as cosmic shear. For the sky coverages typical of\nfuture surveys, errors introduced by projection effects can be of order tens of\npercent, exceeding 50% in some cases. The stereographic projection, which is\nconformal and so preserves local angles, is the most effective planar\nprojection. In any case, these errors can be avoided entirely by recovering\nconvergence fields directly on the celestial sphere. We apply the spherical\nKaiser-Squires mass-mapping method presented to the public Dark Energy Survey\n(DES) science verification data to recover convergence maps directly on the\ncelestial sphere. \n\n"}
{"id": "1703.10964", "contents": "Title: Uncorrelated far AGN flaring with their delayed UHECRs events Abstract: The most distant AGN, within the allowed GZK cut-off radius, have been\nrecently candidate by many authors as the best location for observed UHECR\norigination. Indeed, the apparent homogeneity and isotropy of recent UHECR\nsignals seems to require a far cosmic isotropic and homogeneous scenario\ninvolving a proton UHECR courier: our galaxy or nearest local group or super\ngalactic plane (ruled by Virgo cluster) are too much near and apparently too\nmuch anisotropic in disagreement with PAO and TA almost homogeneous sample\ndata. However, the few and mild observed UHECR clustering, the North and South\nHot Spots, are smeared in wide solid angles. Their consequent random walk\nflight from most far GZK UHECR sources, nearly at 100 Mpc, must be delayed\n(with respect to a straight AGN photon gamma flaring arrival trajectory) at\nleast by a million years. During this time, the AGN jet blazing signal, its\nprobable axis deflection (such as the helical jet in Mrk501), its miss\nalignment or even its almost certain exhaust activity may lead to a complete\nmisleading correlation between present UHECR events and a much earlier active\nAGN ejection. UHECR maps maybe anyway related to galactic or nearest (Cen A,\nM82) AGN extragalactic UHECR sources shining in twin Hot Spot. Therefore we\ndefend our (quite different) scenarios where UHECR are mostly made by lightest\nUHECR nuclei originated by nearby AGN sources, or few galactic sources, whose\ndelayed signals reach us within few thousand years in the observed smeared sky\nareas. \n\n"}
{"id": "1704.00865", "contents": "Title: Preconditioner-free Wiener filtering with a dense noise matrix Abstract: This work extends the Elsner & Wandelt (2013) iterative method for efficient,\npreconditioner-free Wiener filtering to cases in which the noise covariance\nmatrix is dense, but can be decomposed into a sum whose parts are sparse in\nconvenient bases. The new method, which uses multiple messenger fields,\nreproduces Wiener filter solutions for test problems, and we apply it to a case\nbeyond the reach of the Elsner & Wandelt (2013) method. We compute the Wiener\nfilter solution for a simulated Cosmic Microwave Background map that contains\nspatially-varying, uncorrelated noise, isotropic $1/f$ noise, and large-scale\nhorizontal stripes (like those caused by the atmospheric noise). We discuss\nsimple extensions that can filter contaminated modes or inverse-noise filter\nthe data. These techniques help to address complications in the noise\nproperties of maps from current and future generations of ground-based\nMicrowave Background experiments, like Advanced ACTPol, Simons Observatory, and\nCMB-S4. \n\n"}
{"id": "1704.02425", "contents": "Title: Tests of Gravity Theories Using Supermassive Black Holes Abstract: Scalar-tensor theories of gravity generally violate the strong equivalence\nprinciple, namely compact objects have a suppressed coupling to the scalar\nforce, causing them to fall slower. A black hole is the extreme example where\nsuch a coupling vanishes, i.e. black hole has no scalar hair. Following earlier\nwork, we explore observational scenarios for detecting strong equivalence\nprinciple violation, focusing on galileon gravity as an example. For galaxies\nin-falling towards galaxy clusters, the supermassive black hole can be offset\nfrom the galaxy center away from the direction of the cluster. Hence, well\nresolved images of galaxies around nearby clusters can be used to identify the\ndisplaced black hole via the star cluster bound to it. We show that this signal\nis accessible with imaging surveys, both ongoing ones such as the Dark Energy\nSurvey, and future ground and space based surveys. Already, the observation of\nthe central black hole in M~87 places new constraints on the galileon\nparameters, which we present here. $\\mathcal{O}(1)$ matter couplings are\ndisfavored for a large region of the parameter space. We also find a novel\nphenomenon whereby the black hole can escape the galaxy completely in less than\none billion years. \n\n"}
{"id": "1704.02868", "contents": "Title: Limits on statistical anisotropy from BOSS DR12 galaxies using bipolar\n  spherical harmonics Abstract: We measure statistically anisotropic signatures imprinted in\nthree-dimensional galaxy clustering using bipolar spherical harmonics (BipoSHs)\nin both Fourier space and configuration space. We then constrain a well-known\nquadrupolar anisotropy parameter $g_{2M}$ in the primordial power spectrum,\nparametrized by $P(\\vec{k}) = \\bar{P}(k) [ 1 + \\sum_{M} g_{2M} Y_{2M}(\\hat{k})\n]$, with $M$ determining the direction of the anisotropy. Such an anisotropic\nsignal is easily contaminated by artificial asymmetries due to specific survey\ngeometry. We precisely estimate the contaminated signal and finally subtract it\nfrom the data. Using the galaxy samples obtained by the Baryon Oscillation\nSpectroscopic Survey Data Release 12, we find no evidence for violation of\nstatistical isotropy, $g_{2M}$ for all $M$ to be of zero within the $2\\sigma$\nlevel. The $g_{2M}$-type anisotropy can originate from the primordial curvature\npower spectrum involving a directional-dependent modulation $g_* (\\hat{k} \\cdot\n\\hat{p})^2$. The bound on $g_{2M}$ is translated into $g_*$ as $-0.09 < g_* <\n0.08$ with a $95\\%$ confidence level when $\\hat{p}$ is marginalized over. \n\n"}
{"id": "1704.06184", "contents": "Title: Anisotropy of the astrophysical gravitational wave background: analytic\n  expression of the angular power spectrum and correlation with cosmological\n  observations Abstract: Unresolved and resolved sources of gravitational waves are at the origin of a\nstochastic gravitational wave background. While the computation of its mean\ndensity as a function of frequency in a homogeneous and isotropic universe is\nstandard lore, the computation of its anisotropies requires to understand the\ncoarse graining from local systems, to galactic scales and then to cosmology.\nAn expression of the gravitational wave energy density valid in any general\nspacetime is derived. It is then specialized to a perturbed\nFriedmann-Lema\\^itre spacetime in order to determine the angular power spectrum\nof this stochastic background as well as its correlation with other\ncosmological probes, such as the galaxy number counts and weak lensing. Our\nresult for the angular power spectrum also provides an expression for the\nvariance of the gravitational wave background. \n\n"}
{"id": "1704.06286", "contents": "Title: Reliability of the measured velocity anisotropy of the Milky Way stellar\n  halo Abstract: Determining the velocity distribution of halo stars is essential for\nestimating the mass of the Milky Way and for inferring its formation history.\nSince the stellar halo is a dynamically hot system, the velocity distribution\nof halo stars is well described by the 3-dimensional velocity dispersions\n$(\\sigma_r, \\sigma_\\theta, \\sigma_\\phi)$, or by the velocity anisotropy\nparameter $\\beta=1-(\\sigma_\\theta^2+\\sigma_\\phi^2)/(2\\sigma_r^2)$. Direct\nmeasurements of $(\\sigma_r, \\sigma_\\theta, \\sigma_\\phi)$ consistently suggest\n$\\beta =0.5$-$0.7$ for nearby halo stars. In contrast, the value of $\\beta$ at\nlarge Galactocentric radius $r$ is still controversial, since reliable proper\nmotion data are available for only a handful of stars. In the last decade,\nseveral authors have tried to estimate $\\beta$ for distant halo stars by\nfitting the observed line-of-sight velocities at each radius with simple\nvelocity distribution models (local fitting methods). Some results of local\nfitting methods imply $\\beta<0$ at $r \\gtrsim 20 \\;\\rm{kpc}$, which is\ninconsistent with recent predictions from cosmological simulations. Here we\nperform mock-catalogue analyses to show that the estimates of $\\beta$ based on\nlocal fitting methods are reliable only at $r \\leq 15 \\;\\rm{kpc}$ with the\ncurrent sample size ($\\sim10^3$ stars at a given radius). As $r$ increases, the\nline-of-sight velocity (corrected for the Solar reflex motion) becomes\nincreasingly closer to the Galactocentric radial velocity, so that it becomes\nincreasingly more difficult to estimate tangential velocity dispersion\n$(\\sigma_\\theta, \\sigma_\\phi)$ from line-of-sight velocity distribution. Our\nresults suggest that the forthcoming Gaia data will be crucial for\nunderstanding the velocity distribution of halo stars at $r \\geq 20\\;\\rm{kpc}$. \n\n"}
{"id": "1704.07830", "contents": "Title: zBEAMS: A unified solution for supernova cosmology with redshift\n  uncertainties Abstract: Supernova cosmology without spectra will be an important component of future\nsurveys such as LSST. This lack of supernova spectra results in uncertainty in\nthe redshifts which, if ignored, leads to significantly biased estimates of\ncosmological parameters. Here we present a hierarchical Bayesian formalism --\nzBEAMS -- that addresses this problem by marginalising over the unknown or\nuncertain supernova redshifts to produce unbiased cosmological estimates that\nare competitive with supernova data with spectroscopically confirmed redshifts.\nzBEAMS provides a unified treatment of both photometric redshifts and host\ngalaxy misidentification (occurring due to chance galaxy alignments or faint\nhosts), effectively correcting the inevitable contamination in the Hubble\ndiagram. Like its predecessor BEAMS, our formalism also takes care of non-Ia\nsupernova contamination by marginalising over the unknown supernova type. We\nillustrate this technique with simulations of supernovae with photometric\nredshifts and host galaxy misidentification. A novel feature of the photometric\nredshift case is the important role played by the redshift distribution of the\nsupernovae. \n\n"}
{"id": "1704.08278", "contents": "Title: Redshifts for galaxies in radio continuum surveys from Bayesian model\n  fitting of HI 21-cm lines Abstract: We introduce a new Bayesian HI spectral line fitting technique capable of\nobtaining spectroscopic redshifts for millions of galaxies in radio surveys\nwith the Square Kilometere Array (SKA). This technique is especially\nwell-suited to the low signal-to-noise regime that the redshifted 21-cm HI\nemission line is expected to be observed in, especially with SKA Phase 1,\nallowing for robust source detection. After selecting a set of continuum\nobjects relevant to large, cosmological-scale surveys with the first phase of\nthe SKA dish array (SKA1-MID), we simulate data corresponding to their HI line\nemission as observed by the same telescope. We then use the MultiNest nested\nsampling code to find the best-fitting parametrised line profile, providing us\nwith a full joint posterior probability distribution for the galaxy properties,\nincluding redshift. This provides high quality redshifts, with redshift errors\n$\\Delta z / z <10^{-5}$, from radio data alone for some 1.8 million galaxies in\na representative 5000 square degree survey with the SKA1-MID instrument with\nup-to-date sensitivity profiles. Interestingly, we find that the SNR definition\ncommonly used in forecast papers does not correlate well with the actual\ndetectability of an HI line using our method. We further detail how our method\ncould be improved with per-object priors and how it may be also used to give\nrobust constraints on other observables such as the HI mass function. We also\nmake our line fitting code publicly available for application to other data\nsets. \n\n"}
{"id": "1704.08599", "contents": "Title: Multifractal Analysis of Pulsar Timing Residuals: Assessment of\n  Gravitational Wave Detection Abstract: We introduce a pipeline including multifractal detrended cross-correlation\nanalysis (MF-DXA) modified by either singular value decomposition or the\nadaptive method to examine the statistical properties of the pulsar timing\nresidual ($PTR$) induced by a gravitational wave (GW) signal. We propose a new\nalgorithm, the so-called irregular-MF-DXA, to deal with irregular data\nsampling. Inspired by the quadrupolar nature of the spatial cross-correlation\nfunction of a gravitational wave background, a new cross-correlation function,\n$\\bar{\\sigma}_{\\times}$, derived from irregular-MF-DXA will be introduced. We\nshow that, this measure reveals the quadrupolar signature in the $PTRs$ induced\nby stochastic GWB. We propose four strategies based on the $y$-intercept of\nfluctuation functions, the generalized Hurst exponent, and the width of the\nsingularity spectrum to determine the dimensionless amplitude and power-law\nexponent of the characteristic strain spectrum as\n$\\mathcal{H}_c(f)\\sim\\mathcal{A}_{yr}(f/f_{yr})^{\\zeta}$ for stochastic GWB.\nUsing the value of Hurst exponent, one can clarify the type of GWs. We apply\nour pipeline to explore 20 millisecond pulsars observed by Parkes Pulsar Timing\nArray. The computed scaling exponents confirm that all data are classified into\na nonstationary class implying the universality feature. The value of the Hurst\nexponent is in the range $H\\in [0.56,0.87]$. The $q$-dependency of the\ngeneralized Hurst exponent demonstrates that the observed $PTRs$ have\nmultifractal behavior, and the source of this multifractality is mainly\nattributed to the correlation of data which is another universality of the\nobserved datasets. Multifractal analysis of available $PTRs$ datasets reveals\nan upper bound on the dimensionless amplitude of the GWB, $\\mathcal{A}_{yr}<\n2.0\\times 10^{-15}$. \n\n"}
{"id": "1705.02366", "contents": "Title: On the universality of MOG weak field approximation at galaxy cluster\n  scale Abstract: In its weak field limit, Scalar-tensor-vector gravity theory introduces a\nYukawa-correction to the gravitational potential. Such a correction depends on\nthe two parameters, $\\alpha$ which accounts for the modification of the\ngravitational constant, and $\\mu^{*-1}$ which represents the scale length on\nwhich the scalar field propagates. These parameters were found to be universal\nwhen the modified gravitational potential was used to fit the galaxy rotation\ncurves and the mass profiles of galaxy clusters, both without Dark Matter. We\ntest the universality of these parameters using the the temperature\nanisotropies due to the thermal Sunyaev-Zeldovich effect. In our model the\nintra-cluster gas is in hydrostatic equilibrium within the modified\ngravitational potential well and it is described by a polytropic equation of\nstate. We predict the thermal Sunyaev-Zeldovich temperature anisotropies\nproduced by Coma cluster, and we compare them with those obtained using the\nPlanck 2013 Nominal maps. In our analysis, we find $\\alpha$ and the scale\nlength, respectively, to be consistent and to depart from their universal\nvalues. Our analysis points out that the assumption of the universality of the\nYukawa-correction to the gravitational potential is ruled out at more than\n$3.5\\sigma$ at galaxy clusters scale, while demonstrating that such a theory of\ngravity is capable to fit the cluster profile if the scale dependence of the\ngravitational potential is restored. \n\n"}
{"id": "1705.02563", "contents": "Title: Using the (Modified) Matrix Element Method to constrain $L_\\mu - L_\\tau$\n  Interactions Abstract: In this paper, we explore the discriminatory power of the matrix element\nmethod (MEM) in constraining the $L_\\mu-L_\\tau$ model at the LHC. The $Z'$\ngauge boson associated with the spontaneously broken $U(1)_{L_\\mu-L_\\tau}$\nsymmetry only interacts with the second and third generation of leptons at tree\nlevel, and is thus difficult to produce at the LHC. We argue that the best\nchannels for discovering this $Z'$ are in $Z \\to 4\\mu$ and\n$2\\mu+\\displaystyle{\\not}E_T$. Both these channels have a large number of\nkinematic observables, which strongly motivates the usage of a multivariate\ntechnique. The MEM is a multivariate analysis that uses the squared matrix\nelement to quantify the likelihood of the testing hypotheses. We find that with\n$300 \\, \\text{fb}^{-1}$ of integrated luminosity, we are sensitive to the\ncouplings of $ g_{Z'} \\gtrsim 0.002 ~ g_1$ and $M_{Z'} < 20 \\text{ GeV}$, and\n$g_{Z'} \\gtrsim 0.005 g_1$ and $20\\, \\text{GeV} <M_{Z'} < 40 ~ \\text{GeV}$,\nwhich is about an order of magnitude improvement over the cut-and-count method\nfor the same amount of data. \n\n"}
{"id": "1705.04367", "contents": "Title: Recognising Axionic Dark Matter by Compton and de-Broglie Scale\n  Modulation of Pulsar Timing Abstract: Light Axionic Dark Matter, motivated by string theory, is increasingly\nfavored for the \"no-WIMP era\". Galaxy formation is suppressed below a Jeans\nscale, of $\\simeq 10^8 M_\\odot$ by setting the axion mass to, $m_B \\sim\n10^{-22}$eV, and the large dark cores of dwarf galaxies are explained as\nsolitons on the de-Broglie scale. This is persuasive, but detection of the\ninherent scalar field oscillation at the Compton frequency, $\\omega_B= (2.5{\\rm\n\\, months})^{-1}(m_B/10^{-22}eV)$, would be definitive. By evolving the coupled\nSchr\\\"odinger-Poisson equation for a Bose-Einstein condensate, we predict the\ndark matter is fully modulated by de-Broglie interference, with a dense soliton\ncore of size $\\simeq 150pc$, at the Galactic center. The oscillating field\npressure induces General Relativistic time dilation in proportion to the local\ndark matter density and pulsars within this dense core have detectably large\ntiming residuals, of $\\simeq 400nsec/(m_B/10^{-22}eV)$. This is encouraging as\nmany new pulsars should be discovered near the Galactic center with planned\nradio surveys. More generally, over the whole Galaxy, differences in dark\nmatter density between pairs of pulsars imprints a pairwise Galactocentric\nsignature that can be distinguished from an isotropic gravitational wave\nbackground. \n\n"}
{"id": "1705.06655", "contents": "Title: First Dark Matter Search Results from the XENON1T Experiment Abstract: We report the first dark matter search results from XENON1T, a\n$\\sim$2000-kg-target-mass dual-phase (liquid-gas) xenon time projection chamber\nin operation at the Laboratori Nazionali del Gran Sasso in Italy and the first\nton-scale detector of this kind. The blinded search used 34.2 live days of data\nacquired between November 2016 and January 2017. Inside the (1042$\\pm$12) kg\nfiducial mass and in the [5, 40] $\\mathrm{keV}_{\\mathrm{nr}}$ energy range of\ninterest for WIMP dark matter searches, the electronic recoil background was\n$(1.93 \\pm 0.25) \\times 10^{-4}$ events/(kg $\\times$ day $\\times\n\\mathrm{keV}_{\\mathrm{ee}}$), the lowest ever achieved in a dark matter\ndetector. A profile likelihood analysis shows that the data is consistent with\nthe background-only hypothesis. We derive the most stringent exclusion limits\non the spin-independent WIMP-nucleon interaction cross section for WIMP masses\nabove 10 GeV/c${}^2$, with a minimum of 7.7 $\\times 10^{-47}$ cm${}^2$ for\n35-GeV/c${}^2$ WIMPs at 90% confidence level. \n\n"}
{"id": "1705.06745", "contents": "Title: The first-year shear catalog of the Subaru Hyper Suprime-Cam SSP Survey Abstract: We present and characterize the catalog of galaxy shape measurements that\nwill be used for cosmological weak lensing measurements in the Wide layer of\nthe first year of the Hyper Suprime-Cam (HSC) survey. The catalog covers an\narea of 136.9 deg$^2$ split into six fields, with a mean $i$-band seeing of\n$0.58$ arcsec and $5\\sigma$ point-source depth of $i\\sim 26$. Given\nconservative galaxy selection criteria for first year science, the depth and\nexcellent image quality results in unweighted and weighted source number\ndensities of 24.6 and 21.8 arcmin$^{-2}$, respectively. We define the\nrequirements for cosmological weak lensing science with this catalog, then\nfocus on characterizing potential systematics in the catalog using a series of\ninternal null tests for problems with point-spread function (PSF) modeling,\nshear estimation, and other aspects of the image processing. We find that the\nPSF models narrowly meet requirements for weak lensing science with this\ncatalog, with fractional PSF model size residuals of approximately $0.003$\n(requirement: 0.004) and the PSF model shape correlation function\n$\\rho_1<3\\times 10^{-7}$ (requirement: $4\\times 10^{-7}$) at 0.5$^\\circ$\nscales. A variety of galaxy shape-related null tests are statistically\nconsistent with zero, but star-galaxy shape correlations reveal additive\nsystematics on $>1^\\circ$ scales that are sufficiently large as to require\nmitigation in cosmic shear measurements. Finally, we discuss the dominant\nsystematics and the planned algorithmic changes to reduce them in future data\nreductions. \n\n"}
{"id": "1705.07520", "contents": "Title: Rewriting Context-free Families of String Diagrams Abstract: String diagrams provide a convenient graphical framework which may be used\nfor equational reasoning about morphisms of monoidal categories. However,\nunlike term rewriting, rewriting string diagrams results in shorter equational\nproofs, because the string diagrammatic representation allows us to formally\nestablish equalities modulo any rewrite steps which follow from the monoidal\nstructure.\n  Manipulating string diagrams by hand is a time-consuming and error-prone\nprocess, especially for large string diagrams. This can be ameliorated by using\nsoftware proof assistants, such as Quantomatic.\n  However, reasoning about concrete string diagrams may be limiting and in some\nscenarios it is necessary to reason about entire (infinite) families of string\ndiagrams. When doing so, we face the same problems as for manipulating concrete\nstring diagrams, but in addition, we risk making further mistakes if we are not\nprecise enough about the way we represent (infinite) families of string\ndiagrams.\n  The primary goal of this thesis is to design a mathematical framework for\nequational reasoning about infinite families of string diagrams which is\namenable to computer automation. We will be working with context-free families\nof string diagrams and we will represent them using context-free graph\ngrammars. We will model equations between infinite families of diagrams using\nrewrite rules between context-free grammars. Our framework represents\nequational reasoning about concrete string diagrams and context-free families\nof string diagrams using double-pushout rewriting on graphs and context-free\ngraph grammars respectively. We will prove that our representation is sound by\nshowing that it respects the concrete semantics of string diagrammatic\nreasoning and we will show that our framework is appropriate for software\nimplementation by proving important decidability properties. \n\n"}
{"id": "1705.07920", "contents": "Title: DarkBit: A GAMBIT module for computing dark matter observables and\n  likelihoods Abstract: We introduce DarkBit, an advanced software code for computing dark matter\nconstraints on various extensions to the Standard Model of particle physics,\ncomprising both new native code and interfaces to external packages. This\nrelease includes a dedicated signal yield calculator for gamma-ray\nobservations, which significantly extends current tools by implementing a\ncascade decay Monte Carlo, as well as a dedicated likelihood calculator for\ncurrent and future experiments (gamlike). This provides a general solution for\nstudying complex particle physics models that predict dark matter annihilation\nto a multitude of final states. We also supply a direct detection package that\nmodels a large range of direct detection experiments (DDcalc), and provides the\ncorresponding likelihoods for arbitrary combinations of spin-independent and\nspin-dependent scattering processes. Finally, we provide custom relic density\nroutines along with interfaces to DarkSUSY, micrOMEGAs, and the neutrino\ntelescope likelihood package nuLike. DarkBit is written in the framework of the\nGlobal And Modular Beyond the Standard Model Inference Tool (GAMBIT), providing\nseamless integration into a comprehensive statistical fitting framework that\nallows users to explore new models with both particle and astrophysics\nconstraints, and a consistent treatment of systematic uncertainties. In this\npaper we describe its main functionality, provide a guide to getting started\nquickly, and show illustrative examples for results obtained with DarkBit (both\nas a standalone tool and as a GAMBIT module). This includes a quantitative\ncomparison between two of the main dark matter codes (DarkSUSY and micrOMEGAs),\nand application of DarkBit's advanced direct and indirect detection routines to\na simple effective dark matter model. \n\n"}
{"id": "1705.07959", "contents": "Title: Comparison of statistical sampling methods with ScannerBit, the GAMBIT\n  scanning module Abstract: We introduce ScannerBit, the statistics and sampling module of the public,\nopen-source global fitting framework GAMBIT. ScannerBit provides a standardised\ninterface to different sampling algorithms, enabling the use and comparison of\nmultiple computational methods for inferring profile likelihoods, Bayesian\nposteriors, and other statistical quantities. The current version offers\nrandom, grid, raster, nested sampling, differential evolution, Markov Chain\nMonte Carlo (MCMC) and ensemble Monte Carlo samplers. We also announce the\nrelease of a new standalone differential evolution sampler, Diver, and describe\nits design, usage and interface to ScannerBit. We subject Diver and three other\nsamplers (the nested sampler MultiNest, the MCMC GreAT, and the native\nScannerBit implementation of the ensemble Monte Carlo algorithm T-Walk) to a\nbattery of statistical tests. For this we use a realistic physical likelihood\nfunction, based on the scalar singlet model of dark matter. We examine the\nperformance of each sampler as a function of its adjustable settings, and the\ndimensionality of the sampling problem. We evaluate performance on four\nmetrics: optimality of the best fit found, completeness in exploring the\nbest-fit region, number of likelihood evaluations, and total runtime. For\nBayesian posterior estimation at high resolution, T-Walk provides the most\naccurate and timely mapping of the full parameter space. For profile likelihood\nanalysis in less than about ten dimensions, we find that Diver and MultiNest\nscore similarly in terms of best fit and speed, outperforming GreAT and T-Walk;\nin ten or more dimensions, Diver substantially outperforms the other three\nsamplers on all metrics. \n\n"}
{"id": "1705.10617", "contents": "Title: The nuclear configurational entropy impact parameter dependence in the\n  Color-Glass Condensate Abstract: The impact parameter (b) dependence on the saturation scale, in the framework\nof the Color Glass Condensate (b-CGC) dipole model, is investigated from the\nconfigurational point of view. During the calculations and analysis of the\nquantum nuclear states, the critical points of stability in the configurational\nentropy setup are computed, matching the experimental parameters that define\nthe onset of the quantum regime in the b-CGC in the literature with very good\naccuracy. This new approach is crucial and important for understanding the\nstability of quantum systems in study of deep inelastic scattering processes. \n\n"}
{"id": "1705.10956", "contents": "Title: Superconducting cosmic strings as sources of cosmological fast radio\n  bursts Abstract: In this paper we calculate the radio burst signals from three kinds of\nstructures of superconducting cosmic strings. By taking into account the\nobservational factors including scattering and relativistic effects, we derive\nthe event rate of radio bursts as a function of redshift with the theoretical\nparameters $G\\mu$ and $\\mathcal{I}$ of superconducting strings. Our analyses\nshow that cusps and kinks may have noticeable contributions to the event rate\nand in most cases cusps would dominate the contribution, while the kink-kink\ncollisions tend to have secondary effects. By fitting theoretical predictions\nwith the normalized data of fast radio bursts, we for the first time constrain\nthe parameter space of superconducting strings and report that the parameter\nspace of $G\\mu \\sim [10^{-14}, 10^{-12}]$ and $\\mathcal{I} \\sim [10^{-1},\n10^{2}] ~ \\rm{GeV}$ fit the observation well although the statistic\nsignificance is low due to the lack of observational data. Moreover, we derive\ntwo types of best fittings, with one being dominated by cusps with a redshift\n$z = 1.3$, and the other dominated by kinks at the range of the maximal event\nrate. \n\n"}
{"id": "1706.01964", "contents": "Title: Identifying a light charged Higgs boson at the LHC Run II Abstract: We analyse the phenomenological implications of a light Higgs boson, $h$,\nwithin the CP-conserving 2-Higgs Doublet Model (2HDM) Type-I, for the detection\nprospects of the charged $H^\\pm$ state at Run II of the Large Hadron Collider\n(LHC), assuming $\\sqrt{s}=13$ TeV as energy and ${\\cal O}(100~{\\rm fb}^{-1})$\nas luminosity. When sufficiently light, this $h$ state can open up the bosonic\ndecay channel $H^\\pm \\to W^{\\pm(*)}h$, which may have a branching ratio\nsignificantly exceeding those of the $H^\\pm \\to \\tau\\nu$ and $H^\\pm \\to cs$\nchannels. We perform a broad scan of the 2HDM Type-I parameter space, assuming\nthe heavier of the two CP-even Higgs bosons, $H$, to be the observed SM-like\nstate with a mass near 125 GeV. Through these scans we highlight regions in\nwhich $m_{H^\\pm} < m_t +m_b$ that are still consistent with the most recent\nlimits from experimental searches. We find in these regions that, when the\n$H^\\pm \\to W^{\\pm(*)}h$ decay mode is the dominant one, the $h$ can be highly\nfermiophobic, with a considerably large decay rate in the $\\gamma\\gamma$\nchannel. This can result in the total cross section of the $\\sigma(pp\\to H^\\pm\nh \\to W^{\\pm(*)} + 4\\gamma)$ process reaching up to ${\\cal O}(100~{\\rm fb})$.\nWe therefore investigate the possibility of observing this spectacular signal\nat the LHC Run II. \n\n"}
{"id": "1706.04583", "contents": "Title: Cosmological constraints from a joint analysis of cosmic microwave\n  background and spectroscopic tracers of the large-scale structure Abstract: The standard model of cosmology, {\\Lambda}CDM, is the simplest model that\nmatches the current observations, but it relies on two hypothetical components,\nto wit, dark matter and dark energy. Future galaxy surveys and cosmic microwave\nbackground (CMB) experiments will independently shed light on these components,\nbut a joint analysis that includes cross-correlations will be necessary to\nextract as much information as possible from the observations. In this paper,\nwe carry out a multi-probe analysis based on pseudo-spectra and test it on\npublicly available data sets. We use CMB temperature anisotropies and CMB\nlensing observations from Planck as well as the spectroscopic galaxy and quasar\nsamples of SDSS-III/BOSS, taking advantage of the large areas covered by these\nsurveys. We build a likelihood to simultaneously analyse the auto and cross\nspectra of CMB lensing and tracer overdensity maps before running Monte-Carlo\nMarkov Chains (MCMC) to assess the constraining power of the combined analysis.\nWe then add the CMB temperature anisotropies likelihood and obtain constraints\non cosmological parameters ($H_0$, $\\omega_b$, $\\omega_c$, ${\\ln10^{10}A_s}$,\n$n_s$ and $z_{re}$) and galaxy biases. We demonstrate that the joint analysis\ncan additionally constrain the total mass of neutrinos ${\\Sigma m_{\\nu}}$ as\nwell as the dark energy equation of state $w$ at once (for a total of eight\ncosmological parameters), which is impossible with either of the data sets\nconsidered separately. Finally, we discuss limitations of the analysis related\nto, e.g., the theoretical precision of the models, particularly in the\nnon-linear regime. \n\n"}
{"id": "1706.06053", "contents": "Title: Measurement of low energy ionization signals from Compton scattering in\n  a CCD dark matter detector Abstract: An important source of background in direct searches for low-mass dark matter\nparticles are the energy deposits by small-angle scattering of environmental\n$\\gamma$ rays. We report detailed measurements of low-energy spectra from\nCompton scattering of $\\gamma$ rays in the bulk silicon of a charge-coupled\ndevice (CCD). Electron recoils produced by $\\gamma$ rays from $^{57}$Co and\n$^{241}$Am radioactive sources are measured between 60 eV and 4 keV. The\nobserved spectra agree qualitatively with theoretical predictions, and\ncharacteristic spectral features associated with the atomic structure of the\nsilicon target are accurately measured for the first time. A\ntheoretically-motivated parametrization of the data that describes the Compton\nspectrum at low energies for any incident $\\gamma$-ray flux is derived. The\nresult is directly applicable to background estimations for low-mass dark\nmatter direct-detection experiments based on silicon detectors, in particular\nfor the DAMIC experiment down to its current energy threshold. \n\n"}
{"id": "1706.06106", "contents": "Title: Capability of Detecting Ultra-Violet Counterparts of Gravitational Waves\n  with GLUV Abstract: With the discovery of gravitational waves (GW), attention has turned towards\ndetecting counterparts to these sources. In discussions on counterpart\nsignatures and multi-messenger follow-up strategies to GW detections,\nultra-violet (UV) signatures have largely been neglected, due to UV facilities\nbeing limited to SWIFT, which lacks high-cadence UV survey capabilities. In\nthis paper, we examine the UV signatures from merger models for the major GW\nsources, highlighting the need for further modelling, while presenting\nrequirements and a design for an effective UV survey telescope. Using $u'$-band\nmodels as an analogue, we find that a UV survey telescope requires a limiting\nmagnitude of m$_{u'}\\rm (AB)\\approx 24$ to fully complement the aLIGO range and\nsky localisation. We show that a network of small, balloon-based UV telescopes\nwith a primary mirror diameter of 30~cm could be capable of covering the aLIGO\ndetection distance from $\\sim$60--100\\% for BNS events and $\\sim$40\\% for BHNS\nevents. The sensitivity of UV emission to initial conditions suggests that a UV\nsurvey telescope would provide a unique dataset, that can act as an effective\ndiagnostic to discriminate between models. \n\n"}
{"id": "1706.06111", "contents": "Title: Probing the small-scale structure in strongly lensed systems via\n  transdimensional inference Abstract: Strong lensing is a sensitive probe of the small-scale density fluctuations\nin the Universe. We implement a novel approach to modeling strongly lensed\nsystems using probabilistic cataloging, which is a transdimensional,\nhierarchical, and Bayesian framework to sample from a metamodel (union of\nmodels with different dimensionality) consistent with observed photon count\nmaps. Probabilistic cataloging allows us to robustly characterize modeling\ncovariances within and across lens models with different numbers of subhalos.\nUnlike traditional cataloging of subhalos, it does not require model subhalos\nto improve the goodness of fit above the detection threshold. Instead, it\nallows the exploitation of all information contained in the photon count maps,\nfor instance, when constraining the subhalo mass function. We further show\nthat, by not including these small subhalos in the lens model,\nfixed-dimensional inference methods can significantly mismodel the data. Using\na simulated Hubble Space Telescope (HST) dataset, we show that the subhalo mass\nfunction can be probed even when many subhalos in the sample catalogs are\nindividually below the detection threshold and would be absent in a traditional\ncatalog. With the planned Wide Field Infrared Space Telescope (WFIRST),\nsimultaneous probabilistic cataloging of dark subhalos in high-resolution, deep\nstrong lens images has the potential to constrain the subhalo mass function at\neven lower masses. \n\n"}
{"id": "1706.07933", "contents": "Title: Toward an internally consistent astronomical distance scale Abstract: Accurate astronomical distance determination is crucial for all fields in\nastrophysics, from Galactic to cosmological scales. Despite, or perhaps because\nof, significant efforts to determine accurate distances, using a wide range of\nmethods, tracers, and techniques, an internally consistent astronomical\ndistance framework has not yet been established. We review current efforts to\nhomogenize the Local Group's distance framework, with particular emphasis on\nthe potential of RR Lyrae stars as distance indicators, and attempt to extend\nthis in an internally consistent manner to cosmological distances. Calibration\nbased on Type Ia supernovae and distance determinations based on gravitational\nlensing represent particularly promising approaches. We provide a positive\noutlook to improvements to the status quo expected from future surveys,\nmissions, and facilities. Astronomical distance determination has clearly\nreached maturity and near-consistency. \n\n"}
{"id": "1706.08353", "contents": "Title: Intrinsic scatter of caustic masses and hydrostatic bias: An\n  observational study Abstract: All estimates of cluster mass have some intrinsic scatter and perhaps some\nbias with true mass even in the absence of measurement errors for example\ncaused by cluster triaxiality and large scale structure. Knowledge of the bias\nand scatter values is fundamental for both cluster cosmology and astrophysics.\nIn this paper we show that the intrinsic scatter of a mass proxy can be\nconstrained by measurements of the gas fraction because masses with higher\nvalues of intrinsic scatter with true mass produce more scattered gas\nfractions. Moreover, the relative bias of two mass estimates can be constrained\nby comparing the mean gas fraction at the same (nominal) cluster mass. Our\nobservational study addresses the scatter between caustic (i.e., dynamically\nestimated) and true masses, and the relative bias of caustic and hydrostatic\nmasses. For these purposes, we used the X-ray Unbiased Cluster Sample, a\ncluster sample selected independently from the intracluster medium content with\nreliable masses: 34 galaxy clusters in the nearby ($0.050<z<0.135$) Universe,\nmostly with $14<\\log M_{500}/M_\\odot \\lesssim 14.5$, and with caustic masses.\nWe found a 35\\% scatter between caustic and true masses. Furthermore, we found\nthat the relative bias between caustic and hydrostatic masses is small,\n$0.06\\pm0.05$ dex, improving upon past measurements. The small scatter found\nconfirms our previous measurements of a highly variable amount of feedback from\ncluster to cluster, which is the cause of the observed large variety of\ncore-excised X-ray luminosities and gas masses. \n\n"}
{"id": "1706.08428", "contents": "Title: CMB anisotropies at all orders: the non-linear Sachs-Wolfe formula Abstract: We obtain the non-linear generalization of the Sachs-Wolfe + integrated\nSachs-Wolfe (ISW) formula describing the CMB temperature anisotropies. Our\nformula is valid at all orders in perturbation theory, is also valid in all\ngauges and includes scalar, vector and tensor modes. A direct consequence of\nour results is that the maps of the logarithmic temperature anisotropies are\nmuch cleaner than the usual CMB maps, because they automatically remove many\nsecondary anisotropies. This can for instance, facilitate the search for\nprimordial non-Gaussianity in future works. It also disentangles the non-linear\nISW from other effects. Finally, we provide a method which can iteratively be\nused to obtain the lensing solution at the desired order. \n\n"}
{"id": "1707.01632", "contents": "Title: Low-Mass Dark Matter Search with CDMSlite Abstract: The SuperCDMS experiment is designed to directly detect weakly interacting\nmassive particles (WIMPs) that may constitute the dark matter in our Galaxy.\nDuring its operation at the Soudan Underground Laboratory, germanium detectors\nwere run in the CDMSlite mode to gather data sets with sensitivity specifically\nfor WIMPs with masses ${<}$10 GeV/$c^2$. In this mode, a higher detector-bias\nvoltage is applied to amplify the phonon signals produced by drifting charges.\nThis paper presents studies of the experimental noise and its effect on the\nachievable energy threshold, which is demonstrated to be as low as 56\neV$_{\\text{ee}}$ (electron equivalent energy). The detector-biasing\nconfiguration is described in detail, with analysis corrections for voltage\nvariations to the level of a few percent. Detailed studies of the\nelectric-field geometry, and the resulting successful development of a fiducial\nparameter, eliminate poorly measured events, yielding an energy resolution\nranging from ${\\sim}$9 eV$_{\\text{ee}}$ at 0 keV to 101 eV$_{\\text{ee}}$ at\n${\\sim}$10 eV$_{\\text{ee}}$. New results are derived for astrophysical\nuncertainties relevant to the WIMP-search limits, specifically examining how\nthey are affected by variations in the most probable WIMP velocity and the\nGalactic escape velocity. These variations become more important for WIMP\nmasses below 10 GeV/$c^2$. Finally, new limits on spin-dependent low-mass\nWIMP-nucleon interactions are derived, with new parameter space excluded for\nWIMP masses $\\lesssim$3 GeV/$c^2$ \n\n"}
{"id": "1707.02863", "contents": "Title: The Impact of Redshift on Galaxy Morphometric Classification: case\n  studies for SDSS, DES, LSST and HST with Morfometryka Abstract: We have carried a detailed analysis on the impact of cosmological redshift in\nthe non-parametric approach to automated galaxy morphology classification. We\nartificially redshifted each galaxy from the EFIGI 4458 sample (re-centred at\n$z \\sim 0$) simulating SDSS, DES, LSST and HST instruments set-ups over the\nrange $0 < z < 1.5$. We then traced how the morphometry is degraded in each $z$\nusing MORFOMETRYKA. In the process, we re-sampled all catalogues to several\nresolutions and to a diverse signal-to-noise range, allowing us to understand\nthe impact of image sampling and noise on our measurements separately. We\nsummarize by exploring the impact of these effects on our capacity to perform\nautomated galaxy supervised morphological classification by investigating the\ndegradation of our classifier's metrics as a function of redshift for each\ninstrument. The overall conclusion is that we can make reliable classification\nwith MORFOMETRYKA for $z < 0.2$ with SDSS, for $z < 0.5$ with DES, for $z <\n0.8$ with LSST and for at least $z < 1.5$ with HST. \n\n"}
{"id": "1707.02981", "contents": "Title: Joint Bayesian estimation of tensor and lensing B-modes in the power\n  spectrum of CMB polarization data Abstract: We investigate the performance of a simple Bayesian fitting approach to\ncorrect the cosmic microwave background (CMB) B-mode polarization for\ngravitational lensing effects in the recovered probability distribution of the\ntensor-to-scalar ratio. We perform a two-dimensional power spectrum fit of the\namplitude of the primordial B-modes (tensor-to-scalar ratio, $r$) and the\namplitude of the lensing B-modes (parameter $A_{lens}$), jointly with the\nestimation of the astrophysical foregrounds including both synchrotron and\nthermal dust emissions. Using this Bayesian framework, we forecast the ability\nof the proposed CMB space mission LiteBIRD to constrain $r$ in the presence of\nrealistic lensing and foreground contributions. We compute the joint posterior\ndistribution of $r$ and $A_{lens}$, which we improve by adopting a prior on\n$A_{lens}$ taken from the South Pole Telescope (SPT) measurement. As it applies\nto the power spectrum, this approach cannot mitigate the uncertainty on $r$\nthat is due to E-mode cosmic variance transferred to B-modes by lensing, unlike\nstandard delensing techniques that are performed on maps. However, the method\nallows to correct for the bias on $r$ induced by lensing, at the expense of a\nlarger uncertainty due to the increased volume of the parameter space. We\nquantify, for different values of the tensor-to-scalar ratio, the trade-off\nbetween bias correction and increase of uncertainty on $r$. For LiteBIRD\nsimulations, which include foregrounds and lensing contamination, we find that\ncorrecting the foreground-cleaned CMB B-mode power spectrum for the lensing\nbias, not the lensing cosmic variance, still guarantees a $3\\sigma$ detection\nof $r=5\\times 10^{-3}$. The significance of the detection is increased to\n$6\\sigma$ when the current SPT prior on $A_{lens}$ is adopted. \n\n"}
{"id": "1707.03169", "contents": "Title: Morpho-z: improving photometric redshifts with galaxy morphology Abstract: We conduct a comprehensive study of the effects of incorporating galaxy\nmorphology information in photometric redshift estimation. Using machine\nlearning methods, we assess the changes in the scatter and catastrophic outlier\nfraction of photometric redshifts when galaxy size, ellipticity, S\\'{e}rsic\nindex and surface brightness are included in training on galaxy samples from\nthe SDSS and the CFHT Stripe-82 Survey (CS82). We show that by adding galaxy\nmorphological parameters to full $ugriz$ photometry, only mild improvements are\nobtained, while the gains are substantial in cases where fewer passbands are\navailable. For instance, the combination of $grz$ photometry and morphological\nparameters almost fully recovers the metrics of $5$-band photometric redshifts.\nWe demonstrate that with morphology it is possible to determine useful redshift\ndistribution $N(z)$ of galaxy samples without any colour information. We also\nfind that the inclusion of quasar redshifts and associated object sizes in\ntraining improves the quality of photometric redshift catalogues, compensating\nfor the lack of a good star-galaxy separator. We further show that\nmorphological information can mitigate biases and scatter due to bad\nphotometry. As an application, we derive both point estimates and posterior\ndistributions of redshifts for the official CS82 catalogue, training on\nmorphology and SDSS Stripe-82 $ugriz$ bands when available. Our redshifts yield\na 68th percentile error of $0.058(1+z)$, and a catastrophic outlier fraction of\n$5.2$ per cent. We further include a deep extension trained on morphology and\nsingle $i$-band CS82 photometry. \n\n"}
{"id": "1707.06529", "contents": "Title: Massive data compression for parameter-dependent covariance matrices Abstract: We show how the massive data compression algorithm MOPED can be used to\nreduce, by orders of magnitude, the number of simulated datasets that are\nrequired to estimate the covariance matrix required for the analysis of\ngaussian-distributed data. This is relevant when the covariance matrix cannot\nbe calculated directly. The compression is especially valuable when the\ncovariance matrix varies with the model parameters. In this case, it may be\nprohibitively expensive to run enough simulations to estimate the full\ncovariance matrix throughout the parameter space. This compression may be\nparticularly valuable for the next-generation of weak lensing surveys, such as\nproposed for Euclid and LSST, for which the number of summary data (such as\nband power or shear correlation estimates) is very large, $\\sim 10^4$, due to\nthe large number of tomographic redshift bins that the data will be divided\ninto. In the pessimistic case where the covariance matrix is estimated\nseparately for all points in an MCMC analysis, this may require an unfeasible\n$10^9$ simulations. We show here that MOPED can reduce this number by a factor\nof 1000, or a factor of $\\sim 10^6$ if some regularity in the covariance matrix\nis assumed, reducing the number of simulations required to a manageable $10^3$,\nmaking an otherwise intractable analysis feasible. \n\n"}
{"id": "1707.06619", "contents": "Title: Formation of Precessing Jets by Tilted Black-hole Discs in 3D General\n  Relativistic MHD Simulations Abstract: Gas falling into a black hole (BH) from large distances is unaware of BH spin\ndirection, and misalignment between the accretion disc and BH spin is expected\nto be common. However, the physics of tilted discs (e.g., angular momentum\ntransport and jet formation) is poorly understood. Using our new\nGPU-accelerated code H-AMR, we performed 3D general relativistic\nmagnetohydrodynamic simulations of tilted thick accretion discs around rapidly\nspinning BHs, at the highest resolution to date. We explored the limit where\ndisc thermal pressure dominates magnetic pressure, and showed for the first\ntime that, for different magnetic field strengths on the BH, these flows launch\nmagnetized relativistic jets propagating along the rotation axis of the tilted\ndisc (rather than of the BH). If strong large-scale magnetic flux reaches the\nBH, it bends the inner few gravitational radii of the disc and jets into\npartial alignment with the BH spin. On longer time scales, the simulated\ndisc-jet system as a whole undergoes Lense-Thirring precession and approaches\nalignment, demonstrating for the first time that jets can be used as probes of\ndisc precession. When the disc turbulence is well-resolved, our isolated discs\nspread out, causing both the alignment and precession to slow down. \n\n"}
{"id": "1707.07869", "contents": "Title: Quenched mass transport of particles towards a target Abstract: We consider the stochastic target problem of finding the collection of\ninitial laws of a mean-field stochastic differential equation such that we can\ncontrol its evolution to ensure that it reaches a prescribed set of terminal\nprobability distributions, at a fixed time horizon. Here, laws are considered\nconditionally to the path of the Brownian motion that drives the system. We\nestablish a version of the geometric dynamic programming principle for the\nassociated reachability sets and prove that the corresponding value function is\na viscosity solution of a geometric partial differential equation. This\nprovides a characterization of the initial masses that can be almost-surely\ntransported towards a given target, along the paths of a stochastic\ndifferential equation. Our results extend [16] to our setting. \n\n"}
{"id": "1707.08042", "contents": "Title: First results from the DEAP-3600 dark matter search with argon at SNOLAB Abstract: This paper reports the first results of a direct dark matter search with the\nDEAP-3600 single-phase liquid argon (LAr) detector. The experiment was\nperformed 2 km underground at SNOLAB (Sudbury, Canada) utilizing a large target\nmass, with the LAr target contained in a spherical acrylic vessel of 3600 kg\ncapacity. The LAr is viewed by an array of PMTs, which would register\nscintillation light produced by rare nuclear recoil signals induced by dark\nmatter particle scattering. An analysis of 4.44 live days (fiducial exposure of\n9.87 tonne-days) of data taken with the nearly full detector during the initial\nfilling phase demonstrates the detector performance and the best electronic\nrecoil rejection using pulse-shape discrimination in argon, with leakage\n$<1.2\\times 10^{-7}$ (90% C.L.) between 16 and 33 keV$_{ee}$. No candidate\nsignal events are observed, which results in the leading limit on WIMP-nucleon\nspin-independent cross section on argon, $<1.2\\times 10^{-44}$ cm$^2$ for a 100\nGeV/c$^2$ WIMP mass (90% C.L.). \n\n"}
{"id": "1707.08091", "contents": "Title: The dipole anisotropy of WISE x SuperCOSMOS number counts Abstract: We probe the isotropy of the Universe with the largest all-sky photometric\nredshift dataset currently available, namely WISE~$\\times$~SuperCOSMOS. We\nsearch for dipole anisotropy of galaxy number counts in multiple redshift\nshells within the $0.10 < z < 0.35$ range, for two subsamples drawn from the\nsame parent catalogue. Our results show that the dipole directions are in good\nagreement with most of the previous analyses in the literature, and in most\nredshift bins the dipole amplitudes are well consistent with $\\Lambda$CDM-based\nmocks in the cleanest sample of this catalogue. In the $z<0.15$ range, however,\nwe obtain a persistently large anisotropy in both subsamples of our dataset.\nOverall, we report no significant evidence against the isotropy assumption in\nthis catalogue except for the lowest redshift ranges. The origin of the latter\ndiscrepancy is unclear, and improved data may be needed to explain it. \n\n"}
{"id": "1708.01531", "contents": "Title: Dark Energy Survey Year 1 Results: Photometric Data Set for Cosmology Abstract: We describe the creation, content, and validation of the Dark Energy Survey\n(DES) internal year-one cosmology data set, Y1A1 GOLD, in support of upcoming\ncosmological analyses. The Y1A1 GOLD data set is assembled from multiple epochs\nof DES imaging and consists of calibrated photometric zeropoints, object\ncatalogs, and ancillary data products - e.g., maps of survey depth and\nobserving conditions, star-galaxy classification, and photometric redshift\nestimates - that are necessary for accurate cosmological analyses. The Y1A1\nGOLD wide-area object catalog consists of ~137 million objects detected in\ncoadded images covering ~1800 deg$^2$ in the DES grizY filters. The 10{\\sigma}\nlimiting magnitude for galaxies is g = 23.4, r = 23.2, i = 22.5, z = 21.8, and\nY = 20.1. Photometric calibration of Y1A1 GOLD was performed by combining\nnightly zeropoint solutions with stellar-locus regression, and the absolute\ncalibration accuracy is better than 2% over the survey area. DES Y1A1 GOLD is\nthe largest photometric data set at the achieved depth to date, enabling\nprecise measurements of cosmic acceleration at z $\\lesssim$ 1. \n\n"}
{"id": "1708.01617", "contents": "Title: Large Synoptic Survey Telescope Galaxies Science Roadmap Abstract: The Large Synoptic Survey Telescope (LSST) will enable revolutionary studies\nof galaxies, dark matter, and black holes over cosmic time. The LSST Galaxies\nScience Collaboration has identified a host of preparatory research tasks\nrequired to leverage fully the LSST dataset for extragalactic science beyond\nthe study of dark energy. This Galaxies Science Roadmap provides a brief\nintroduction to critical extragalactic science to be conducted ahead of LSST\noperations, and a detailed list of preparatory science tasks including the\nmotivation, activities, and deliverables associated with each. The Galaxies\nScience Roadmap will serve as a guiding document for researchers interested in\nconducting extragalactic science in anticipation of the forthcoming LSST era. \n\n"}
{"id": "1708.05303", "contents": "Title: An Inventory of Bispectrum Estimators for Redshift Space Distortions Abstract: In order to best improve constraints on cosmological parameters and on models\nof modified gravity using current and future galaxy surveys it is necessary\nmaximally exploit the available data. As redshift-space distortions mean\nstatistical translation invariance is broken for galaxy observations, this will\nrequire measurement of the monopole, quadrupole and hexadecapole of not just\nthe galaxy power spectrum, but also the galaxy bispectrum. A recent (2015)\npaper by Scoccimarro demonstrated how the standard bispectrum estimator may be\nexpressed in terms of Fast Fourier Transforms (FFTs) to afford an extremely\nefficient algorithm, allowing the bispectrum multipoles on all scales and\ntriangle shapes to be measured in comparable time to those of the power\nspectrum. In this paper we present a suite of alternative proxies to measure\nthe three-point correlation multipoles. In particular, we describe a modal (or\nplane wave) decomposition to capture the information in each multipole in a\nseries of basis coefficients, and also describe three compressed estimators\nformed using the skew-spectrum, the line correlation function and the\nintegrated bispectrum, respectively. As well as each of the estimators offering\na different measurement channel, and thereby a robustness check, it is expected\nthat some (especially the modal estimator) will offer a vast data compression,\nand so a much reduced covariance matrix. This compression may be vital to\nreduce the computational load involved in extracting the available three-point\ninformation. \n\n"}
{"id": "1708.05817", "contents": "Title: Results from EDGES High-Band: I. Constraints on Phenomenological Models\n  for the Global $21$ cm Signal Abstract: We report constraints on the global $21$ cm signal due to neutral hydrogen at\nredshifts $14.8 \\geq z \\geq 6.5$. We derive our constraints from low foreground\nobservations of the average sky brightness spectrum conducted with the EDGES\nHigh-Band instrument between September $7$ and October $26$, $2015$.\nObservations were calibrated by accounting for the effects of antenna beam\nchromaticity, antenna and ground losses, signal reflections, and receiver\nparameters. We evaluate the consistency between the spectrum and\nphenomenological models for the global $21$ cm signal. For tanh-based\nrepresentations of the ionization history during the epoch of reionization, we\nrule out, at $\\geq2\\sigma$ significance, models with duration of up to $\\Delta\nz = 1$ at $z\\approx8.5$ and higher than $\\Delta z = 0.4$ across most of the\nobserved redshift range under the usual assumption that the $21$ cm spin\ntemperature is much larger than the temperature of the cosmic microwave\nbackground (CMB) during reionization. We also investigate a `cold' IGM scenario\nthat assumes perfect Ly$\\alpha$ coupling of the $21$ cm spin temperature to the\ntemperature of the intergalactic medium (IGM), but that the IGM is not heated\nby early stars or stellar remants. Under this assumption, we reject tanh-based\nreionization models of duration $\\Delta z \\lesssim 2$ over most of the observed\nredshift range. Finally, we explore and reject a broad range of Gaussian models\nfor the $21$ cm absorption feature expected in the First Light era. As an\nexample, we reject $100$ mK Gaussians with duration (full width at half\nmaximum) $\\Delta z \\leq 4$ over the range $14.2\\geq z\\geq 6.5$ at $\\geq2\\sigma$\nsignificance. \n\n"}
{"id": "1708.06365", "contents": "Title: Optimizing measurements of cluster velocities and temperatures for\n  CCAT-prime and future surveys Abstract: Galaxy cluster velocity correlations and mass distributions are sensitive\nprobes of cosmology and the growth of structure. Upcoming microwave surveys\nwill enable extraction of velocities and temperatures from many individual\nclusters for the first time. We forecast constraints on peculiar velocities,\nelectron temperatures, and optical depths of galaxy clusters obtainable with\nupcoming multi-frequency measurements of the kinematic, thermal, and\nrelativistic Sunyaev-Zeldovich effects. The forecasted constraints are compared\nfor different measurement configurations with frequency bands between 90 GHz\nand 1 THz, and for different survey strategies for the 6-meter CCAT-prime\ntelescope. We study methods for improving cluster constraints by removing\nemission from dusty star forming galaxies, and by using X-ray temperature\npriors from eROSITA. Cluster constraints are forecast for several model cluster\nmasses. A sensitivity optimization for seven frequency bands is presented for a\nCCAT-prime first light instrument and a next generation instrument that takes\nadvantage of the large optical throughput of CCAT-prime. We find that\nCCAT-prime observations are expected to enable measurement and separation of\nthe SZ effects to characterize the velocity, temperature, and optical depth of\nindividual massive clusters ($\\sim10^{15}\\,M_\\odot$). Submillimeter\nmeasurements are shown to play an important role in separating these components\nfrom dusty galaxy contamination. Using a modular instrument configuration with\nsimilar optical throughput for each detector array, we develop a rule of thumb\nfor the number of detector arrays desired at each frequency to optimize\nextraction of these signals. Our results are relevant for a future \"Stage IV\"\ncosmic microwave background survey, which could enable galaxy cluster\nmeasurements over a larger range of masses and redshifts than will be\naccessible by other experiments. \n\n"}
{"id": "1708.06592", "contents": "Title: The Pierre Auger Observatory: Contributions to the 35th International\n  Cosmic Ray Conference (ICRC 2017) Abstract: Contributions of the Pierre Auger Collaboration to the 35th International\nCosmic Ray Conference (ICRC 2017), 12-20 July 2017, Bexco, Busan, Korea. \n\n"}
{"id": "1708.07704", "contents": "Title: Extragalactic source population studies at very high energies in the\n  Cherenkov Telescope Array era Abstract: The Cherenkov Telescope Array (CTA) is the next generation ground-based\n$\\gamma$-ray observatory. It will provide an order of magnitude better\nsensitivity and an extended energy coverage, 20 GeV - 300 TeV, relative to\ncurrent Imaging Atmospheric Cherenkov Telescopes (IACTs). IACTs, despite\nfeaturing an excellent sensitivity, are characterized by a limited field of\nview that makes the blind search of new sources very time inefficient.\nFortunately, the $\\textit{Fermi}$-LAT collaboration recently released a new\ncatalog of 1,556 sources detected in the 10 GeV - 2 TeV range by the Large Area\nTelescope (LAT) in the first 7 years of its operation (the 3FHL catalog). This\ncatalog is currently the most appropriate description of the sky that will be\nenergetically accessible to CTA. Here, we discuss a detailed analysis of the\nextragalactic source population (mostly blazars) that will be studied in the\nnear future by CTA. This analysis is based on simulations built from the\nexpected array configurations and information reported in the 3FHL catalog.\nThese results show the improvements that CTA will provide on the extragalactic\nTeV source population studies, which will be carried out by Key Science\nProjects as well as dedicated proposals. \n\n"}
{"id": "1708.08843", "contents": "Title: Uncertainties in Parameters Estimated with Neural Networks: Application\n  to Strong Gravitational Lensing Abstract: In Hezaveh et al. 2017 we showed that deep learning can be used for model\nparameter estimation and trained convolutional neural networks to determine the\nparameters of strong gravitational lensing systems. Here we demonstrate a\nmethod for obtaining the uncertainties of these parameters. We review the\nframework of variational inference to obtain approximate posteriors of Bayesian\nneural networks and apply it to a network trained to estimate the parameters of\nthe Singular Isothermal Ellipsoid plus external shear and total flux\nmagnification. We show that the method can capture the uncertainties due to\ndifferent levels of noise in the input data, as well as training and\narchitecture-related errors made by the network. To evaluate the accuracy of\nthe resulting uncertainties, we calculate the coverage probabilities of\nmarginalized distributions for each lensing parameter. By tuning a single\nhyperparameter, the dropout rate, we obtain coverage probabilities\napproximately equal to the confidence levels for which they were calculated,\nresulting in accurate and precise uncertainty estimates. Our results suggest\nthat neural networks can be a fast alternative to Monte Carlo Markov Chains for\nparameter uncertainty estimation in many practical applications, allowing more\nthan seven orders of magnitude improvement in speed. \n\n"}
{"id": "1708.08926", "contents": "Title: Sub-radian-accuracy gravitational waveforms of coalescing binary neutron\n  stars in numerical relativity Abstract: Extending our previous studies, we perform high-resolution simulations of\ninspiraling binary neutron stars in numerical relativity. We thoroughly carry\nthrough a convergence study in our currently available computational resources\nwith the smallest grid spacing of $\\approx 63$--86~meter for the neutron-star\nradius 10.9--13.7\\,km. The estimated total error in the gravitational-wave\nphase is of order 0.1~rad for the total phase of $\\gtrsim 210$\\,rad in the last\n$\\sim 15$--16 inspiral orbits. We then compare the waveforms (without\nresolution extrapolation) with those calculated by the latest\neffective-one-body formalism (tidal SEOBv2 model referred to as TEOB model). We\nfind that for any of our models of binary neutron stars, the waveforms\ncalculated by the TEOB formalism agree with the numerical-relativity waveforms\nup to $\\approx 3$\\,ms before the peak of the gravitational-wave amplitude is\nreached: For this late inspiral stage, the total phase error is $\\lesssim\n0.1$\\,rad. Although the gravitational waveforms have an inspiral-type feature\nfor the last $\\sim 3$\\,ms, this stage cannot be well reproduced by the current\nTEOB formalism, in particular, for neutron stars with large tidal deformability\n(i.e., lager radius). The reason for this is described. \n\n"}
{"id": "1709.01091", "contents": "Title: Dark energy two decades after: Observables, probes, consistency tests Abstract: The discovery of the accelerating universe in the late 1990s was a watershed\nmoment in modern cosmology, as it indicated the presence of a fundamentally\nnew, dominant contribution to the energy budget of the universe. Evidence for\ndark energy, the new component that causes the acceleration, has since become\nextremely strong, owing to an impressive variety of increasingly precise\nmeasurements of the expansion history and the growth of structure in the\nuniverse. Still, one of the central challenges of modern cosmology is to shed\nlight on the physical mechanism behind the accelerating universe. In this\nreview, we briefly summarize the developments that led to the discovery of dark\nenergy. Next, we discuss the parametric descriptions of dark energy and the\ncosmological tests that allow us to better understand its nature. We then\nreview the cosmological probes of dark energy. For each probe, we briefly\ndiscuss the physics behind it and its prospects for measuring dark energy\nproperties. We end with a summary of the current status of dark energy\nresearch. \n\n"}
{"id": "1709.01468", "contents": "Title: Off-axis prompt X-ray transients from the cocoon of short gamma-ray\n  bursts Abstract: We present the results of numerical simulations of the prompt emission of\nshort-duration gamma-ray bursts. We consider emission from the relativistic\njet, the mildly relativistic cocoon, and the non-relativistic shocked ambient\nmaterial. We find that the cocoon material is confined between off-axis angles\n15<theta<45 degrees and gives origin to X-ray transients with a duration of a\nfew to ~10 seconds, delayed by a few seconds from the time of the merger. We\nalso discuss the distance at which such transients can be detected, finding\nthat it depends sensitively on the assumptions that are made about the\nradiation spectrum. Purely thermal cocoon transients are detectable only out to\na few Mpc, Comptonized transients can instead be detected by the FERMI GBM out\nto several tens of Mpc. \n\n"}
{"id": "1709.01576", "contents": "Title: Tests of Catastrophic Outlier Prediction in Empirical Photometric\n  Redshift Estimation with Redshift Probability Distributions Abstract: We present results of using individual galaxies' redshift probability\ninformation derived from a photometric redshift (photo-z) algorithm, SPIDERz,\nto identify potential catastrophic outliers in photometric redshift\ndeterminations. By using two test data sets comprised of COSMOS multi-band\nphotometry spanning a wide redshift range (0<z<4) matched with reliable\nspectroscopic or other redshift determinations we explore the efficacy of a\nnovel method to flag potential catastrophic outliers in an analysis which\nrelies on accurate photometric redshifts. SPIDERz is a custom support vector\nmachine classification algorithm for photo-z analysis that naturally outputs a\ndistribution of redshift probability information for each galaxy in addition to\na discrete most probable photo-z value. By applying an analytic technique with\nflagging criteria to identify the presence of probability distribution features\ncharacteristic of catastrophic outlier photo-z estimates, such as multiple\nredshift probability peaks separated by substantial redshift distances, we can\nflag potential catastrophic outliers in photo-z determinations. We find that\nour proposed method can correctly flag large fractions (>50%) of the\ncatastrophic outlier galaxies, while only flagging a small fraction (<5%) of\nthe total non-outlier galaxies, depending on parameter choices. The fraction of\nnon-outlier galaxies flagged varies significantly with redshift and magnitude,\nhowever. We examine the performance of this strategy in photo-z determinations\nusing a range of flagging parameter values. These results could potentially be\nuseful for utilization of photometric redshifts in future large scale surveys\nwhere catastrophic outliers are particularly detrimental to the science goals. \n\n"}
{"id": "1709.01925", "contents": "Title: Crowded Field Galaxy Photometry: Precision Colors in the CLASH Clusters Abstract: We present a new method for photometering objects in galaxy clusters. We\nintroduce a mode-filtering technique for removing spatially variable\nbackgrounds, improving both detection and photometric accuracy (roughly halving\nthe scatter in the red sequence compared to previous catalogs of the same\nclusters). This method is based on robustly determining the distribution of\nbackground pixel values and should provide comparable improvement in\nphotometric analysis of any crowded fields. We produce new multiwavelength\ncatalogs for the 25 CLASH cluster fields in all 16 bandpasses from the UV\nthrough the near IR, as well as rest-frame magnitudes. A comparison with\nspectroscopic values from the literature finds a ~30% decrease in the redshift\ndeviation from previously-released CLASH photometry. This improvement in\nredshift precision, in combination with a detection scheme designed to maximize\npurity, yields a substantial upgrade in cluster member identification over the\nprevious CLASH galaxy catalog. We construct luminosity functions for each\ncluster, reliably reaching depths of at least 4.5 mag below M* in every case,\nand deeper still in several clusters. We measure M* , $\\alpha$, and their\nredshift evolution, assuming the cluster populations are coeval, and find\nlittle to no evolution of $\\alpha$, $-0.9\\lesssim\\langle\\alpha\\rangle\\lesssim\n-0.8$, and M* values consistent with passive evolution. We present a catalog of\ngalaxy photometry, photometric and spectroscopic redshifts, and rest-frame\nphotometry for the full fields of view of all 25 CLASH clusters. Not only will\nour new photometric catalogs enable new studies of the properties of CLASH\nclusters, but mode-filtering techniques, such as those presented here, should\ngreatly enhance the data quality of future photometric surveys of crowded\nfields. \n\n"}
{"id": "1709.03058", "contents": "Title: On the Prospects for Detecting a Net Photon Circular Polarization\n  Produced by Decaying Dark Matter Abstract: If dark matter interactions with Standard Model particles are $CP$-violating,\nthen dark matter annihilation/decay can produce photons with a net circular\npolarization. We consider the prospects for experimentally detecting evidence\nfor such a circular polarization. We identify optimal models for dark matter\ninteractions with the Standard Model, from the point of view of detectability\nof the net polarization, for the case of either symmetric or asymmetric dark\nmatter. We find that, for symmetric dark matter, evidence for net polarization\ncould be found by a search of the Galactic Center by an instrument sensitive to\ncircular polarization with an efficiency-weighted exposure of at least\n$50000~\\text{cm}^2~\\text{yr}$, provided the systematic detector uncertainties\nare constrained at the $1\\%$ level. Better sensitivity can be obtained in the\ncase of asymmetric dark matter. We discuss the prospects for achieving the\nneeded level of performance using possible detector technologies. \n\n"}
{"id": "1709.03600", "contents": "Title: Maximal compression of the redshift space galaxy power spectrum and\n  bispectrum Abstract: We explore two methods of compressing the redshift space galaxy power\nspectrum and bispectrum with respect to a chosen set of cosmological\nparameters. Both methods involve reducing the dimension of the original\ndata-vector ( e.g. 1000 elements ) to the number of cosmological parameters\nconsidered ( e.g. seven ) using the Karhunen-Lo\\`eve algorithm. In the first\ncase, we run MCMC sampling on the compressed data-vector in order to recover\nthe one-dimensional (1D) and two-dimensional (2D) posterior distributions. The\nsecond option, approximately 2000 times faster, works by orthogonalising the\nparameter space through diagonalisation of the Fisher information matrix before\nthe compression, obtaining the posterior distributions without the need of MCMC\nsampling. Using these methods for future spectroscopic redshift surveys like\nDESI, EUCLID and PFS would drastically reduce the number of simulations needed\nto compute accurate covariance matrices with minimal loss of constraining\npower. We consider a redshift bin of a DESI-like experiment. Using the power\nspectrum combined with the bispectrum as a data-vector, both compression\nmethods on average recover the 68% credible regions to within 0.7% and 2% of\nthose resulting from standard MCMC sampling respectively. These confidence\nintervals are also smaller than the ones obtained using only the power spectrum\nby (81%, 80%, 82%) respectively for the bias parameter b_1, the growth rate f\nand the scalar amplitude parameter A_s. \n\n"}
{"id": "1709.07854", "contents": "Title: Relativistic asymmetries in the galaxy cross-correlation function Abstract: We study the asymmetry in the two-point cross-correlation function of two\npopulations of galaxies focusing in particular on the relativistic effects that\ninclude the gravitational redshift. We derive the cross-correlation function on\nsmall and large scales using two different approaches: General Relativistic and\nNewtonian perturbation theory. Following recent work by Bonvin et al.,\nGaztanaga et al. and Croft, we calculate the dipole and the shell estimator\nwith the two procedures and we compare our results. We find that while General\nRelativistic Perturbation Theory (GRPT) is able to make predictions of\nrelativistic effects on very large, obviously linear scales (r > 50 Mpc/h), the\npresence of non-linearities physically occurring on much smaller scales (down\nto those describing galactic potential wells) can strongly affect the asymmetry\nestimators. These can lead to cancellations of the relativistic terms, and sign\nchanges in the estimators on scales up to r ~ 50 Mpc/h. On the other hand, with\nan appropriate non-linear gravitational potential, the results obtained using\nNewtonian theory can successfully describe the asymmetry on smaller, non-linear\nscales (r < 20 Mpc/h) where gravitational redshift is the dominant term. On\nlarger scales the asymmetry is much smaller in magnitude, and measurement is\nnot within reach of current observations. This is in agreement with the\nobservational results obtained by Gaztnaga et al. and the first detection of\nrelativistic effects (on (r < 20 Mpc/h) scales) by Alam et al. \n\n"}
{"id": "1709.07855", "contents": "Title: Relativistic distortions in the large-scale clustering of SDSS-III BOSS\n  CMASS galaxies Abstract: General relativistic effects have long been predicted to subtly influence the\nobserved large-scale structure of the universe. The current generation of\ngalaxy redshift surveys have reached a size where detection of such effects is\nbecoming feasible. In this paper, we report the first detection of the redshift\nasymmetry from the cross-correlation function of two galaxy populations which\nis consistent with relativistic effects. The dataset is taken from the Sloan\nDigital Sky Survey DR12 CMASS galaxy sample, and we detect the asymmetry at the\n$2.7\\sigma$ level by applying a shell-averaged estimator to the\ncross-correlation function. Our measurement dominates at scales around $10$\nh$^{-1}$Mpc, larger than those over which the gravitational redshift profile\nhas been recently measured in galaxy clusters, but smaller than scales for\nwhich linear perturbation theory is likely to be accurate. The detection\nsignificance varies by 0.5$\\sigma$ with the details of our measurement and\ntests for systematic effects. We have also devised two null tests to check for\nvarious survey systematics and show that both results are consistent with the\nnull hypothesis. We measure the dipole moment of the cross-correlation\nfunction, and from this the asymmetry is also detected, at the $2.8 \\sigma$\nlevel. The amplitude and scale-dependence of the clustering asymmetries are\napproximately consistent with the expectations of General Relativity and a\nbiased galaxy population, within large uncertainties. We explore theoretical\npredictions using numerical simulations in a companion paper. \n\n"}
{"id": "1709.07856", "contents": "Title: Relativistic Effects on Galaxy Redshift Samples due to Target Selection Abstract: In a galaxy redshift survey the objects to be targeted for spectra are\nselected from a photometrically observed sample. The observed magnitudes and\ncolours of galaxies in this parent sample will be affected by their peculiar\nvelocities, through relativistic Doppler and relativistic beaming effects. In\nthis paper we compute the resulting expected changes in galaxy photometry. The\nmagnitudes of the relativistic effects are a function of redshift, stellar\nmass, galaxy velocity and velocity direction. We focus on the CMASS sample from\nthe Sloan Digital Sky Survey (SDSS), Baryon Oscillation Spectroscopic Survey\n(BOSS), which is selected on the basis of colour and magnitude. We find that\n0.10\\% of the sample ($\\sim 585$ galaxies) has been scattered into the targeted\nregion of colour-magnitude space by relativistic effects, and conversely 0.09\\%\nof the sample ($\\sim 532$ galaxies) has been scattered out. Observational\nconsequences of these effects include an asymmetry in clustering statistics,\nwhich we explore in a companion paper. Here we compute a set of weights which\ncan be used to remove the effect of modulations introduced into the density\nfield inferred from a galaxy sample. We conclude by investigating the possible\neffects of these relativistic modulation on large scale clustering of the\ngalaxy sample. \n\n"}
{"id": "1709.07859", "contents": "Title: N-body simulations of gravitational redshifts and other relativistic\n  distortions of galaxy clustering Abstract: Large redshift surveys of galaxies and clusters are providing the first\nopportunities to search for distortions in the observed pattern of large-scale\nstructure due to such effects as gravitational redshift. We focus on non-linear\nscales and apply a quasi-Newtonian approach using N-body simulations to predict\nthe small asymmetries in the cross-correlation function of two galaxy different\npopulations. Following recent work by Bonvin et al., Zhao and Peacock and\nKaiser on galaxy clusters, we include effects which enter at the same order as\ngravitational redshift: the transverse Doppler effect, light-cone effects,\nrelativistic beaming, luminosity distance perturbation and wide-angle effects.\nWe find that all these effects cause asymmetries in the cross-correlation\nfunctions. Quantifying these asymmetries, we find that the total effect is\ndominated by the gravitational redshift and luminosity distance perturbation at\nsmall and large scales, respectively. By adding additional subresolution\nmodelling of galaxy structure to the large-scale structure information, we find\nthat the signal is significantly increased, indicating that structure on the\nsmallest scales is important and should be included. We report on comparison of\nour simulation results with measurements from the SDSS/BOSS galaxy redshift\nsurvey in a companion paper. \n\n"}
{"id": "1709.09721", "contents": "Title: Deep lensing with a twist: E and B modes in a field with multiple lenses Abstract: We explore the weak lensing E- and B-mode shear signals of a field of galaxy\nclusters using both large scale structure N-body simulations and multi-color\nSuprime-cam & Hubble Space Telescope observations. Using the ray-traced and\nobserved shears along with photometric redshift catalogs, we generate mass maps\nof the foreground overdensities by optimally filtering the tangential shear\nthat they induce on background galaxies. We then develop and test a method to\napproximate the foreground structure as a superposition of NFW-like halos by\nlocating these overdensities and determining their mass and redshift, thereby\nmodeling the background correlated shear field as a sum of lensings induced by\nthe foreground clusters. We demonstrate that the B-mode maps and shear\ncorrelation functions, which are generated by similarly filtering the cross\nshear in this method, are in agreement with observations and are related to the\nestimated cluster masses and locations as well as the distribution of\nbackground sources. Using the foreground mass model, we identify several\nsources of weak lensing B-modes including leakage and edge effects, source\nclustering, and multiple lensing which can be observed in deep cosmic shear\nsurveys. \n\n"}
{"id": "1710.00173", "contents": "Title: Multi-Scale Pipeline for the Search of String-Induced CMB Anisotropies Abstract: We propose a multi-scale edge-detection algorithm to search for the\nGott-Kaiser-Stebbins imprints of a cosmic string (CS) network on the Cosmic\nMicrowave Background (CMB) anisotropies. Curvelet decomposition and extended\nCanny algorithm are used to enhance the string detectability. Various\nstatistical tools are then applied to quantify the deviation of CMB maps having\na cosmic string contribution with respect to pure Gaussian anisotropies of\ninflationary origin. These statistical measures include the one-point\nprobability density function, the weighted two-point correlation function\n(TPCF) of the anisotropies, the unweighted TPCF of the peaks and of the\nup-crossing map, as well as their cross-correlation. We use this algorithm on a\nhundred of simulated Nambu-Goto CMB flat sky maps, covering approximately\n$10\\%$ of the sky, and for different string tensions $G\\mu$. On noiseless sky\nmaps with an angular resolution of $0.9'$, we show that our pipeline detects\nCSs with $G\\mu$ as low as $G\\mu\\gtrsim 4.3\\times 10^{-10}$. At the same\nresolution, but with a noise level typical to a CMB-S4 phase II experiment, the\ndetection threshold would be to $G\\mu\\gtrsim 1.2 \\times 10^{-7}$. \n\n"}
{"id": "1710.00885", "contents": "Title: Weak lensing shear calibration with simulations of the HSC survey Abstract: We present results from a set of simulations designed to constrain the weak\nlensing shear calibration for the Hyper Suprime-Cam (HSC) survey. These\nsimulations include HSC observing conditions and galaxy images from the Hubble\nSpace Telescope (HST), with fully realistic galaxy morphologies and the impact\nof nearby galaxies included. We find that the inclusion of nearby galaxies in\nthe images is critical to reproducing the observed distributions of galaxy\nsizes and magnitudes, due to the non-negligible fraction of unrecognized blends\nin ground-based data, even with the excellent typical seeing of the HSC survey\n(0.58\" in the $i$-band). Using these simulations, we detect and remove the\nimpact of selection biases due to the correlation of weights and the quantities\nused to define the sample (S/N and apparent size) with the lensing shear. We\nquantify and remove galaxy property-dependent multiplicative and additive shear\nbiases that are intrinsic to our shear estimation method, including a $\\sim 10$\nper cent-level multiplicative bias due to the impact of nearby galaxies and\nunrecognized blends. Finally, we check the sensitivity of our shear calibration\nestimates to other cuts made on the simulated samples, and find that the\nchanges in shear calibration are well within the requirements for HSC weak\nlensing analysis. Overall, the simulations suggest that the weak lensing\nmultiplicative biases in the first-year HSC shear catalog are controlled at the\n1 per cent level. \n\n"}
{"id": "1710.01723", "contents": "Title: correlcalc: A `Generic' Recipe for Calculation of Two-point Correlation\n  function Abstract: This article provides a method for quick computation of galaxy two-point\ncorrelation function(2pCF) from redshift surveys using python. One of the\nsalient features of this approach is that it can be used for calculating galaxy\nclustering for any arbitrary geometry (or Cosmology) model. Being efficient\nenough to run fast on a low-spec desktop computer, this `recipe' can be used\nfor quick validation of alternative models and for pedagogical purposes. \n\n"}
{"id": "1710.03047", "contents": "Title: Probing Primordial Gravitational Waves: Ali CMB Polarization Telescope Abstract: In this paper, we will give a general introduction to the project of Ali CMB\nPolarization Telescope (AliCPT), which is a Sino-US joint project led by the\nInstitute of High Energy Physics (IHEP) and has involved many different\ninstitutes in China. It is the first ground-based Cosmic Microwave Background\n(CMB) polarization experiment in China and an integral part of China's\nGravitational Waves Program. The main scientific goal of AliCPT project is to\nprobe the primordial gravitational waves (PGWs) originated from the very early\nUniverse.\n  The AliCPT project includes two stages. The first stage referred to as\nAliCPT-1, is to build a telescope in the Ali region of Tibet with an altitude\nof 5,250 meters. Once completed, it will be the worldwide highest ground-based\nCMB observatory and open a new window for probing PGWs in northern hemisphere.\nAliCPT-1 telescope is designed to have about 7,000 TES detectors at 90GHz and\n150GHz. The second stage is to have a more sensitive telescope (AliCPT-2) with\nthe number of detectors more than 20,000.\n  Our simulations show that AliCPT will improve the current constraint on the\ntensor-to-scalar ratio $r$ by one order of magnitude with 3 years' observation.\nBesides the PGWs, the AliCPT will also enable a precise measurement on the CMB\nrotation angle and provide a precise test on the CPT symmetry. We show 3 years'\nobservation will improve the current limit by two order of magnitude. \n\n"}
{"id": "1710.04694", "contents": "Title: Constraints from microlensing experiments on clustered primordial black\n  holes Abstract: It has recently been proposed that massive primordial black holes (PBH) could\nconstitute all of the dark matter, providing a novel scenario of structure\nformation, with early reionization and a rapid growth of the massive black\nholes at the center of galaxies and dark matter halos. The scenario arises from\nbroad peaks in the primordial power spectrum that give both a spatially\nclustered and an extended mass distribution of PBH. The constraints from the\nobserved microlensing events on the extended mass function have already been\naddressed. Here we study the impact of spatial clustering on the microlensing\nconstraints. We find that the bounds can be relaxed significantly for\nrelatively broad mass distributions if the number of primordial black holes\nwithin each cluster is typically above one hundred. On the other hand, even if\nthey arise from individual black holes within the cluster, the bounds from CMB\nanisotropies are less stringent due to the enhanced black hole velocity in such\ndense clusters. This way, the window between a few and ten solar masses has\nopened up for PBH to comprise the totality of the dark matter. \n\n"}
{"id": "1710.05632", "contents": "Title: On the information entropy of matter-waves in quasi-disorder potentials Abstract: We consider ultracold Bose gases in quasi-random potentials and quantify\nlocalization of matter waves by means of Shannon information entropy. We\nexplicitly examine the role of quasi-random potentials in producing localized\nstates in the linear and nonlinear regimes. It is seen that the information\nentropic-based approach can be more useful to quantify localization of\ndifferent types of states observed in Bose-Einstein condensates. \n\n"}
{"id": "1710.05861", "contents": "Title: Distance and properties of NGC 4993 as the host galaxy of a\n  gravitational wave source, GW170817 Abstract: Recently, the optical counterpart of a gravitational wave source GW170817 has\nbeen identified in NGC 4993 galaxy. Together with evidence from observations in\nelectromagnetic waves, the event has been suggested as a result of a merger of\ntwo neutron stars. We analyze the multi-wavelength data to characterize the\nhost galaxy property and its distance to examine if the properties of NGC 4993\nare consistent with this picture. Our analysis shows that NGC 4993 is a\nbulge-dominated galaxy with reff ~ 2-3 kpc and the Sersic index of n = 3-4 for\nthe bulge component. The spectral energy distribution from 0.15 to 24 micron\nindicates that this galaxy has no significant ongoing star formation, the mean\nstellar mass of (0.3 - 1.2) times 10^11 Msun,the mean stellar age greater than\n~3 Gyr, and the metallicity of about 20% to 100% of solar abundance. Optical\nimages reveal dust lanes and extended features that suggest a past merging\nactivity. Overall, NGC 4993 has characteristics of normal, but slightly\ndisturbed elliptical galaxies. Furthermore, we derive the distance to NGC 4993\nwith the fundamental plane relation using 17 parameter sets of 7 different\nfilters and the central stellar velocity dispersion from literature, finding an\nangular diameter distance of 37.7 +- 8.7 Mpc. NGC 4993 is similar to some host\ngalaxies of short gamma-ray bursts but much different from those of long\ngamma-ray bursts, supporting the picture of GW170817 as a result of a merger of\ntwo NSs. \n\n"}
{"id": "1710.05943", "contents": "Title: A compact, large-range interferometer for precision measurement and\n  inertial sensing Abstract: We present a compact, fibre-coupled interferometer with high sensitivity and\na large working range. We propose to use this interferometer as a readout\nmechanism for future inertial sensors, removing a major limiting noise source,\nand in precision positioning systems. The interferometers peak sensitivity is\n$2 \\times 10^{-{14}}$ m/${\\sqrt{\\rm{Hz}}}$ at 70 Hz and $8 \\times 10^{-{11}}$\nm/$\\sqrt{\\rm{Hz}}$ at 10 mHz. If deployed on a GS-13 geophone, the resulting\ninertial sensing output will be dominated by suspension thermal noise from 50\nmHz to 2 Hz. \n\n"}
{"id": "1710.06168", "contents": "Title: GW170817 Falsifies Dark Matter Emulators Abstract: On August 17, 2017 the LIGO interferometers detected the gravitational wave\n(GW) signal (GW170817) from the coalescence of binary neutron stars. This\nsignal was also simultaneously seen throughout the electromagnetic (EM)\nspectrum from radio waves to gamma-rays. We point out that this simultaneous\ndetection of GW and EM signals rules out a class of modified gravity theories,\ntermed ``dark matter emulators,'' which dispense with the need for dark matter\nby making ordinary matter couple to a different metric from that of GW. We\ndiscuss other kinds of modified gravity theories which dispense with the need\nfor dark matter and are still viable. This simultaneous observation also\nprovides the first observational test of Einstein's Weak Equivalence Principle\n(WEP) between gravitons and photons. We estimate the Shapiro time delay due to\nthe gravitational potential of the total dark matter distribution along the\nline of sight (complementary to the calculation in arXiv:1710.05834) to be\nabout 400 days. Using this estimate for the Shapiro delay and from the time\ndifference of 1.7 seconds between the GW signal and gamma-rays, we can\nconstrain violations of WEP using the parameterized post-Newtonian (PPN)\nparameter $\\gamma$, and is given by $|\\gamma_{\\rm {GW}}-\\gamma_{\\rm{EM}}|<9.8\n\\times 10^{-8}$. \n\n"}
{"id": "1710.10055", "contents": "Title: Model-independent measurement of the absolute magnitude of Type Ia\n  Supernovae with gravitational-wave sources Abstract: The similarity of the absolute luminosity profiles of Type Ia supernovae\n(SNIe), as one kind of distance indicator, has led their use in extragalactic\nastronomy as secondary standard candles. In general, the empirical relationship\nof SNIa on the absolute peak magnitude $M_{\\rm B}$ is calibrated by Cepheid\nvariables in the near distance scale and directly extrapolated to much farther\ndistances. Two main problems arise. First, their calibration, in particular the\ndetermination of $M_{\\rm B}$, depends on the empirical relationship of Cepheid\nvariables, which suffers from various uncertainties. The second is related to\nthe homogeneity of SNIa in their true $M_{\\rm B}$, which is known to be poor in\ndifferent environments. The observed GW signal of the coalescence of compact\nbinary systems and their electromagnetic counterparts provide the novel and\nmodel-independent way to address these two problems. In the era of\nsecond-generation GW detectors, the low-redshift GW sources provide a novel\nmethod to calibrate the empirical relationship of SNIa, using their\nself-calibrated distances. Here, we use the event GW170817 to calibrate the\nempirical relationship in different low redshift ranges, and find that the\ncalibration results are consistent with the ones derived from the Cepheid\nvariables. Moreover, the uncertainties of $M_{\\rm B}$ in both methods are also\ncomparable. By the observations of third-generation GW detectors, GW sources\ncan also be used to measure the values of $M_{\\rm B}$ for the high-redshift\nSNIe, which provides a unique opportunity to study the dependence of $M_{\\rm\nB}$ on the local environment, strength of gravity, and the intrinsic properties\nof the explosion, in addition to test the homogeneity of standard candles. We\nfind that the uncertainties of $M_{\\rm B}$ in both high and low redshifts are\nmore than one order of magnitude smaller than the current accuracy. \n\n"}
{"id": "1710.11107", "contents": "Title: The ALP miracle revisited Abstract: We revisit the ALP miracle scenario where the inflaton and dark matter are\nunified by a single axion-like particle (ALP). We first extend our previous\nanalysis on the inflaton dynamics to identify the whole viable parameter space\nconsistent with the CMB observation. Then, we evaluate the relic density of the\nALP dark matter by incorporating uncertainties of the model-dependent couplings\nto the weak gauge bosons as well as the dissipation effect. The preferred\nranges of the ALP mass and coupling to photons are found to be $0.01\\lesssim\nm_\\phi \\lesssim 1$\\,eV and $g_{\\phi \\gamma \\gamma} = {\\cal\nO}(10^{-11})$\\,GeV$^{-1}$, which slightly depend on these uncertainties.\nInterestingly, the preferred regions are within reach of future solar axion\nhelioscope experiments, IAXO and TASTE, and laser-based stim \n\n"}
{"id": "1711.03787", "contents": "Title: A statistical approach to identify superluminous supernovae and probe\n  their diversity Abstract: We investigate the identification of hydrogen-poor superluminous supernovae\n(SLSNe I) using a photometric analysis, without including an arbitrary\nmagnitude threshold. We assemble a homogeneous sample of previously classified\nSLSNe I from the literature, and fit their light curves using Gaussian\nprocesses. From the fits, we identify four photometric parameters that have a\nhigh statistical significance when correlated, and combine them in a parameter\nspace that conveys information on their luminosity and color evolution. This\nparameter space presents a new definition for SLSNe I, which can be used to\nanalyse existing and future transient datasets. We find that 90% of previously\nclassified SLSNe I meet our new definition. We also examine the evidence for\ntwo subclasses of SLSNe I, combining their photometric evolution with\nspectroscopic information, namely the photospheric velocity and its gradient. A\ncluster analysis reveals the presence of two distinct groups. `Fast' SLSNe show\nfast light curves and color evolution, large velocities, and a large velocity\ngradient. `Slow' SLSNe show slow light curve and color evolution, small\nexpansion velocities, and an almost non-existent velocity gradient. Finally, we\ndiscuss the impact of our analyses in the understanding of the powering engine\nof SLSNe, and their implementation as cosmological probes in current and future\nsurveys. \n\n"}
{"id": "1711.04657", "contents": "Title: Gravitational Grating Abstract: In this work, we study the interaction of the electromagnetic wave (EW) from\na distant quasar with the gravitational wave (GW) sourced by the binary stars.\nWhile in the regime of geometric optics, the light bending due to this\ninteraction is negligible, we show that the phase shifting on the wavefront of\nan EW can produce the diffraction pattern on the observer plane. The\ndiffraction of the light (with the wavelength of $\\lambda_e$) by the\ngravitational wave playing the role of {\\it gravitational grating} (with the\nwavelength of $\\lambda_g$) has the diffraction angle of $\\Delta\\beta \\sim\n\\lambda_e/\\lambda_g$. The relative motion of the observer, the source of\ngravitational wave and the quasar results in a relative motion of the observer\nthrough the interference pattern on the observer plane. The consequence of this\nfringe crossing is the modulation in the light curve of a quasar with the\nperiod of few hours in the microwave wavelength. The optical depth for the\nobservation of this phenomenon for a Quasar with the multiple images strongly\nlensed by a galaxy where the light trajectory of some of the images crosses the\nlensing galaxy is $\\tau \\simeq 0.2$. By shifting the time delay of the light\ncurves of the multiple images in a strong-lensed quasar and removing the\nintrinsic variations of a quasar, our desired signals, as a new method for\ndetection of GWs, can be detected. \n\n"}
{"id": "1711.05748", "contents": "Title: Phenomenological consequences of superfluid dark matter with\n  baryon-phonon coupling Abstract: Recently, a new form of dark matter has been suggested to naturally reproduce\nthe empirically successful aspects of Milgrom's law in galaxies. The dark\nmatter particle candidates are axion-like, with masses of order eV and strong\nself-interactions. They Bose-Einstein condense into a superfluid phase in the\ncentral regions of galaxy halos. The superfluid phonon excitations in turn\ncouple to baryons and mediate an additional long-range force. For a suitable\nchoice of the superfluid equation of state, this force can mimic Milgrom's law.\nIn this paper we develop in detail some of the main phenomenological\nconsequences of such a formalism, by revisiting the expected dark matter halo\nprofile in the presence of an extended baryon distribution. In particular, we\nshow how rotation curves of both high and low surface brightness galaxies can\nbe reproduced, with a slightly rising rotation curve at large radii in massive\nhigh surface brightness galaxies, thus subtly different from Milgrom's law. We\nfinally point out other expected differences with Milgrom's law, in particular\nin dwarf spheroidal satellite galaxies, tidal dwarf galaxies, and globular\nclusters, whose Milgromian or Newtonian behavior depends on the position with\nrespect to the superfluid core of the host galaxy. We also expect ultra-diffuse\ngalaxies within galaxy clusters to have velocities slightly above the baryonic\nTully-Fisher relation. Finally, we note that, in this framework, photons and\ngravitons follow the same geodesics, and that galaxy-galaxy lensing, probing\nlarger distances within galaxy halos than rotation curves, should follow\npredictions closer to the standard cosmological model than those of Milgrom's\nlaw. \n\n"}
{"id": "1711.07692", "contents": "Title: First results on low-mass dark matter from the CRESST-III experiment Abstract: The CRESST experiment, located at Laboratori Nazionali del Gran Sasso in\nItaly, searches for dark matter particles via their elastic scattering off\nnuclei in a target material. The CRESST target consists of scintillating\nCaWO$_4$ crystals, which are operated as cryogenic calorimeters at millikelvin\ntemperatures. Each interaction in the CaWO$_4$ target crystal produces a phonon\nsignal and a light signal that is measured by a second cryogenic calorimeter.\nSince the CRESST-II result in 2015, the experiment is leading the field of\ndirect dark matter search for dark matter masses below 1.7\\,GeV/$c^2$,\nextending the reach of direct searches to the sub-GeV/$c^2$ mass region. For\nCRESST-III, whose Phase 1 started in July 2016, detectors have been optimized\nto reach the performance required to further probe the low-mass region with\nunprecedented sensitivity. In this contribution the achievements of the\nCRESST-III detectors will be discussed together with preliminary results and\nperspectives of Phase 1. \n\n"}
{"id": "1711.09083", "contents": "Title: Fast Radio Bursts from neutron stars plunging into black holes Abstract: Fast radio bursts (FRBs) are millisecond-duration intense radio flares\noccurring at cosmological distances. Many models have been proposed to explain\nthese topical astronomical events, but none has so far been confirmed. Here we\nshow that a novel way involving enhanced giant radio pulses from a rapidly\nspun-up neutron star near a spinning black hole can explain the main properties\nof non-repeating FRBs. Independent observations of such pulses, which are not\nenhanced, from some Galactic pulsars make our model reliable. If correct, our\nmodel would imply the existence of event horizons, the Lense-Thirring effect,\nand a significant spin energy extraction from a black hole. Moreover, an FRB\nwould then probe the pulsar magnetosphere and its emission, and map the strong\ngravity region near a black hole. Besides, our model predicts simultaneous\ndetections of FRBs and gravitational waves from black hole -- neutron star\nmergers for fortuitously nearby FRB events. \n\n"}
{"id": "1711.09702", "contents": "Title: Gravitational wave energy emission and detection rates of Primordial\n  Black Hole hyperbolic encounters Abstract: We describe in detail gravitational wave bursts from Primordial Black Hole\n(PBH) hyperbolic encounters. The bursts are one-time events, with the bulk of\nthe released energy happening during the closest approach, which can be emitted\nin frequencies that could be within the range of both LIGO (10-1000Hz) and LISA\n($10^{-6}-1$ Hz). Furthermore, we correct the results for the power spectrum of\nhyperbolic encounters found in the literature and present new exact and\napproximate expressions for the peak frequency of the emission. Note that these\nGW bursts from hyperbolic encounters between PBH are complementary to the GW\nemission from the bounded orbits of BHB mergers detected by LIGO, and help\nbreaking degeneracies in the determination of the PBH mass, spin and spatial\ndistributions. \n\n"}
{"id": "1711.10458", "contents": "Title: Seven Hints for Primordial Black Hole Dark Matter Abstract: Seven observations point towards the existence of primordial black holes\n(PBH), constituting the whole or an important fraction of the dark matter in\nthe Universe: the mass and spin of black holes detected by Advanced LIGO/VIRGO,\nthe detection of micro-lensing events of distant quasars and stars in M31, the\nnon-detection of ultra-faint dwarf satellite galaxies with radius below 15\nparsecs, evidences for core galactic dark matter profiles, the correlation\nbetween X-ray and infrared cosmic backgrounds, and the existence of\nsuper-massive black holes very early in the Universe's history. Some of these\nhints are newly identified and they are all intriguingly compatible with the\nre-constructed broad PBH mass distribution from LIGO events, peaking on PBH\nmass $m_{\\rm PBH} \\approx 3 M_\\odot$ and passing all other constraints on PBH\nabundances. PBH dark matter also provides a new mechanism to explain the\nmass-to-light ratios of dwarf galaxies, including the recent detection of a\ndiffuse galaxy not dominated by dark matter. Finally we conjecture that between\n0.1% and 1% of the events detected by LIGO will involve a PBH with a mass below\nthe Chandrasekhar mass, which would unambiguously prove the existence of PBH. \n\n"}
{"id": "1711.10596", "contents": "Title: SPIDER: CMB polarimetry from the edge of space Abstract: SPIDER is a balloon-borne instrument designed to map the polarization of the\nmillimeter-wave sky at large angular scales. SPIDER targets the B-mode\nsignature of primordial gravitational waves in the cosmic microwave background\n(CMB), with a focus on mapping a large sky area with high fidelity at multiple\nfrequencies. SPIDER's first longduration balloon (LDB) flight in January 2015\ndeployed a total of 2400 antenna-coupled Transition Edge Sensors (TESs) at 90\nGHz and 150 GHz. In this work we review the design and in-flight performance of\nthe SPIDER instrument, with a particular focus on the measured performance of\nthe detectors and instrument in a space-like loading and radiation environment.\nSPIDER's second flight in December 2018 will incorporate payload upgrades and\nnew receivers to map the sky at 285 GHz, providing valuable information for\ncleaning polarized dust emission from CMB maps. \n\n"}
{"id": "1711.10793", "contents": "Title: A Two-point Diagnostic for the HII Galaxy Hubble Diagram Abstract: A previous analysis of starburst-dominated HII Galaxies and HII regions has\ndemonstrated a statistically significant preference for the\nFriedmann-Robertson-Walker cosmology with zero active mass, known as the R_h=ct\nuniverse, over LCDM and its related dark-matter parametrizations. In this\npaper, we employ a 2-point diagnostic with these data to present a\ncomplementary statistical comparison of R_h=ct with Planck LCDM. Our 2-point\ndiagnostic compares---in a pairwise fashion---the difference between the\ndistance modulus measured at two redshifts with that predicted by each\ncosmology. Our results support the conclusion drawn by a previous comparative\nanalysis demonstrating that R_h=ct is statistically preferred over Planck LCDM.\nBut we also find that the reported errors in the HII measurements may not be\npurely Gaussian, perhaps due to a partial contamination by non-Gaussian\nsystematic effects. The use of HII Galaxies and HII regions as standard candles\nmay be improved even further with a better handling of the systematics in these\nsources. \n\n"}
{"id": "1711.11264", "contents": "Title: Polariton-assisted Singlet Fission in Acene Aggregates Abstract: Singlet fission is an important candidate to increase energy conversion\nefficiency in organic photovoltaics by providing a pathway to increase the\nquantum yield of excitons per photon absorbed in select materials. We\ninvestigate the dependence of exciton quantum yield for acenes in the strong\nlight-matter interaction (polariton) regime, where the materials are embedded\nin optical microcavities. Starting from an open-quantum-systems approach, we\nbuild a kinetic model for time-evolution of species of interest in the presence\nof quenchers and show that polaritons can decrease or increase exciton quantum\nyields compared to the cavity-free case. In particular, we find that hexacene,\na typically poor singlet-fission candidate, can feature a higher yield than\ncavity-free pentacene when assisted by polaritonic effects. Similarly, we show\nthat pentacene yield can be increased when assisted by polariton states.\nFinally, we address how various relaxation processes between bright and dark\nstates in lossy microcavities affect polariton photochemistry. Our results also\nprovide insights on how to choose microcavities to enhance similarly related\nchemical processes. \n\n"}
{"id": "1711.11281", "contents": "Title: SARAS 2 constraints on global 21-cm signals from the Epoch of\n  Reionization Abstract: Spectral distortions in the cosmic microwave background over the 40--200~MHz\nband are imprinted by neutral hydrogen in the intergalactic medium prior to the\nend of reionization. This signal, produced in the redshift range $z = 6-34$ at\nthe rest frame wavelength of 21 cm, has not been detected yet; and poor\nunderstanding of high redshift astrophysics results in a large uncertainty in\nthe expected spectrum. The SARAS~2 radiometer was purposely designed to detect\nthe sky-averaged 21-cm signal. The instrument, deployed at the Timbaktu\nCollective (Southern India) in April--June 2017, collected 63~hr of science\ndata, which were examined for the presence of the cosmological 21-cm signal. In\nour previous work the first-light data from SARAS~2 radiometer were analyzed\nwith Bayesian likelihood-ratio tests using $264$ plausible astrophysical\nscenarios. In this paper we re-examine the data using an improved analysis\nbased on the frequentist approach and forward modeling. We show that SARAS~2\ndata rejects 27 models, out of which 25 are rejected at a significance\n$>5\\sigma$. All the rejected models share the scenario of inefficient heating\nof the primordial gas by the first population of X-ray sources along with rapid\nreionization. \n\n"}
{"id": "1712.01316", "contents": "Title: Emergence of the mass discrepancy-acceleration relation from dark\n  matter-baryon interactions Abstract: The observed tightness of the mass discrepancy-acceleration relation (MDAR)\nposes a fine-tuning challenge to current models of galaxy formation. We propose\nthat this relation could arise from collisional interactions between baryons\nand dark matter (DM) particles, without the need for modification of gravity or\nad hoc feedback processes. We assume that these interactions satisfy the\nfollowing three conditions: (i) the relaxation time of DM particles is\ncomparable to the dynamical time in disk galaxies; (ii) DM exchanges energy\nwith baryons due to elastic collisions; (iii) the product between the baryon-DM\ncross section and the typical energy exchanged in a collision is inversely\nproportional to the DM number density. We present an example of a particle\nphysics model that gives a DM-baryon cross section with the desired density and\nvelocity dependence. Direct detection constraints require our DM particles to\nbe either very light ($m << m_b$) or very heavy ($m >> m_b$), corresponding\nrespectively to heating and cooling of DM by baryons. In both cases, our\nmechanism applies and an equilibrium configuration can in principle be reached.\nHere, we focus on the heavy DM/cooling case as it is technically simpler. Under\nthese assumptions, we find that rotationally-supported disk galaxies could\nnaturally settle to equilibrium configurations satisfying a MDAR at all radii\nwithout invoking finely tuned feedback processes. We also discuss issues\nrelated to the small scale clumpiness of baryons, as well as predictions for\npressure-supported systems. We argue in particular that galaxy clusters do not\nfollow the MDAR despite being DM-dominated because they have not reached their\nequilibrium configuration. Finally, we revisit existing phenomenological,\nastrophysical and cosmological constraints on baryon-DM interactions in light\nof the unusual density dependence of the cross section. \n\n"}
{"id": "1712.01986", "contents": "Title: Making maps of cosmological parameters Abstract: We provide a fast algorithm to diagnose any directional dependence in the\ncosmological parameters by calculating maps of local cosmological parameter\nestimates and their joint errors. The technique implements a fast quadratic\nestimator technique based on Wiener filtering and convolution of the sky with a\npatch shape. It uses only three map-resolution spherical harmonic transforms\nper parameter and applies to any data set with full sky or a partial sky\ncoverage. We apply this method to Planck SMICA-2015 and obtain fluctuation map\nfor six cosmological parameters. Our estimate shows that the Planck data is\nconsistent with a single global value of the cosmological parameters and is not\ninfluenced by any severe local contaminations. This method is applicable also\nto other angular or 3D data sets of future missions to scrutinize any local\nvariation in the cosmological parameters. \n\n"}
{"id": "1712.03237", "contents": "Title: Late time afterglow observations reveal a collimated relativistic jet in\n  the ejecta of the binary neutron star merger GW170817 Abstract: The binary neutron star (BNS) merger GW170817 was the first astrophysical\nsource detected in gravitational waves and multi-wavelength electromagnetic\nradiation. The almost simultaneous observation of a pulse of gamma-rays proved\nthat BNS mergers are associated with at least some short gamma-ray bursts\n(GRBs). However, the gamma-ray pulse was faint, casting doubts on the\nassociation of BNS mergers with the luminous, highly relativistic outflows of\ncanonical short GRBs. Here we show that structured jets with a relativistic,\nenergetic core surrounded by slower and less energetic wings produce afterglow\nemission that brightens characteristically with time, as recently seen in the\nafterglow of GW170817. Initially, we only see the relatively slow material\nmoving towards us. As time passes, larger and larger sections of the outflow\nbecome visible, increasing the luminosity of the afterglow. The late appearance\nand increasing brightness of the multi-wavelength afterglow of GW170817 allow\nus to constrain the geometry of its ejecta and thus reveal the presence of an\noff-axis jet pointing about 30 degrees away from Earth. Our results confirm a\nsingle origin for BNS mergers and short GRBs: GW170817 produced a structured\noutflow with a highly relativistic core and a canonical short GRB. We did not\nsee the bright burst because it was beamed away from Earth. However,\napproximately one in 20 mergers detected in gravitational waves will be\naccompanied by a bright, canonical short GRB. \n\n"}
{"id": "1712.04512", "contents": "Title: COLOSSUS: A python toolkit for cosmology, large-scale structure, and\n  dark matter halos Abstract: This paper introduces Colossus, a public, open-source python package for\ncalculations related to cosmology, the large-scale structure (LSS) of matter in\nthe universe, and the properties of dark matter halos. The code is designed to\nbe fast and easy to use, with a coherent, well-documented user interface. The\ncosmology module implements Friedman-Lemaitre-Robertson-Walker cosmologies\nincluding curvature, relativistic species, and different dark energy equations\nof state, and provides fast computations of the linear matter power spectrum,\nvariance, and correlation function. The LSS module is concerned with the\nproperties of peaks in Gaussian random fields and halos in a statistical sense,\nincluding their peak height, peak curvature, halo bias, and mass function. The\nhalo module deals with spherical overdensity radii and masses, density\nprofiles, concentration, and the splashback radius. To facilitate the rapid\nexploration of these quantities, Colossus implements more than 40 different\nfitting functions from the literature. I discuss the core routines in detail,\nwith particular emphasis on their accuracy. Colossus is available at\nbitbucket.org/bdiemer/colossus. \n\n"}
{"id": "1712.06574", "contents": "Title: LIGO Lo(g)Normal MACHO: Primordial Black Holes survive SN lensing\n  constraints Abstract: It has been claimed in Ref.[arXiv:1712.02240] that massive primordial black\nholes (PBH) cannot constitute all of the dark matter (DM), because their\ngravitational-lensing imprint on the Hubble diagram of type Ia supernovae (SN)\nwould be incompatible with present observations. In this paper, we critically\nreview those constraints and find several caveats on the analysis. First of\nall, the constraints on the fraction $\\alpha$ of PBH in matter seem to be\ndriven by a very restrictive choice of priors on the cosmological parameters.\nIn particular, the degeneracy between $\\Omega_{\\rm M}$ and $\\alpha$ is ignored\nand thus, by fixing $\\Omega_{\\rm M}$, transferred the constraining power of SN\nmagnitudes to $\\alpha$. Furthermore, by considering more realistic physical\nsizes for the type-Ia supernovae, we find an effect on the SN lensing\nmagnification distribution that leads to significantly looser constraints.\nMoreover, considering a wide mass spectrum of PBH, such as a lognormal\ndistribution, further softens the constraints from SN lensing. Finally, we find\nthat the fraction of PBH that could constitute DM today is bounded by $f_{\\rm\nPBH} < 1.09\\ (1.38)$, for JLA (Union 2.1) catalogs, and thus it is perfectly\ncompatible with an all-PBH dark matter scenario in the LIGO band. \n\n"}
{"id": "1712.06607", "contents": "Title: A matched filter approach for blind joint detection of galaxy clusters\n  in X-ray and SZ surveys Abstract: The combination of X-ray and SZ observations can potentially improve the\ncluster detection efficiency when compared to using only one of these probes,\nsince both probe the same medium: the hot ionized gas of the intra-cluster\nmedium. We present a method based on matched multifrequency filters (MMF) for\ndetecting galaxy clusters from SZ and X-ray surveys. This method builds on a\npreviously proposed joint X-ray-SZ extraction method (Tarr\\'io et al. 2016) and\nallows to blindly detect clusters, that is finding new clusters without knowing\ntheir position, size or redshift, by searching on SZ and X-ray maps\nsimultaneously. The proposed method is tested using data from the ROSAT all-sky\nsurvey and from the Planck survey. The evaluation is done by comparison with\nexisting cluster catalogues in the area of the sky covered by the deep SPT\nsurvey. Thanks to the addition of the X-ray information, the joint detection\nmethod is able to achieve simultaneously better purity, better detection\nefficiency and better position accuracy than its predecessor Planck MMF, which\nis based on SZ maps only. For a purity of 85%, the X-ray-SZ method detects 141\nconfirmed clusters in the SPT region, whereas to detect the same number of\nconfirmed clusters with Planck MMF, we would need to decrease its purity to\n70%. We provide a catalogue of 225 sources selected by the proposed method in\nthe SPT footprint, with masses ranging between 0.7 and 14.5 $\\cdot 10^{14}$\nMsun and redshifts between 0.01 and 1.2. \n\n"}
{"id": "1712.07962", "contents": "Title: A Unifying Theory of Dark Energy and Dark Matter: Negative Masses and\n  Matter Creation within a Modified $\\Lambda$CDM Framework Abstract: Dark energy and dark matter constitute 95% of the observable Universe. Yet\nthe physical nature of these two phenomena remains a mystery. Einstein\nsuggested a long-forgotten solution: gravitationally repulsive negative masses,\nwhich drive cosmic expansion and cannot coalesce into light-emitting\nstructures. However, contemporary cosmological results are derived upon the\nreasonable assumption that the Universe only contains positive masses. By\nreconsidering this assumption, I have constructed a toy model which suggests\nthat both dark phenomena can be unified into a single negative mass fluid. The\nmodel is a modified $\\Lambda$CDM cosmology, and indicates that\ncontinuously-created negative masses can resemble the cosmological constant and\ncan flatten the rotation curves of galaxies. The model leads to a cyclic\nuniverse with a time-variable Hubble parameter, potentially providing\ncompatibility with the current tension that is emerging in cosmological\nmeasurements. In the first three-dimensional N-body simulations of negative\nmass matter in the scientific literature, this exotic material naturally forms\nhaloes around galaxies that extend to several galactic radii. These haloes are\nnot cuspy. The proposed cosmological model is therefore able to predict the\nobserved distribution of dark matter in galaxies from first principles. The\nmodel makes several testable predictions and seems to have the potential to be\nconsistent with observational evidence from distant supernovae, the cosmic\nmicrowave background, and galaxy clusters. These findings may imply that\nnegative masses are a real and physical aspect of our Universe, or\nalternatively may imply the existence of a superseding theory that in some\nlimit can be modelled by effective negative masses. Both cases lead to the\nsurprising conclusion that the compelling puzzle of the dark Universe may have\nbeen due to a simple sign error. \n\n"}
{"id": "1712.09788", "contents": "Title: Singular string polytopes and functorial resolutions from\n  Newton-Okounkov bodies Abstract: The main result of this note is that the toric degenerations of flag\nvarieties associated to string polytopes and certain Bott-Samelson resolutions\nof flag varieties fit into a commutative diagram which gives a resolution of\nsingularities of singular toric varieties corresponding to string polytopes.\nOur main tool is a result of Anderson which shows that the toric degenerations\narising from Newton-Okounkov bodies are functorial in an appropriate sense. We\nalso use results of Fujita which show that Newton-Okounkov bodies of\nBott-Samelson varieties with respect to a certain valuation $\\nu_{max}$\ncoincide with generalized string polytopes, as well as previous results by the\nauthors which explicitly describe the Newton-Okounkov bodies of Bott-Samelson\nvarieties with respect to a different valuation $\\nu_{min}$ in terms of\nGrossberg-Karshon twisted cubes. A key step in our argument is that, under a\ntechnical condition, these Newton-Okounkov bodies coincide. \n\n"}
{"id": "1712.10318", "contents": "Title: The future of gravitational theories in the era of the gravitational\n  wave astronomy Abstract: We discuss the future of gravitational theories in the framework of\ngravitational wave (GW) astronomy after the recent GW detections (the events\nGW150914, GW151226, GW170104, GW170814, GW170817 and GW170608). In particular,\na calculation of the frequency and angular dependent response function that a\nGW detector would see if massive modes from f(R) theories or scalar tensor\ngravity (STG) were present, allowing for sources incident from any direction on\nthe sky, is shown. In addition, through separate theoretical results which do\nnot involve the recent GW detections, we show that f(R) theories of gravity\nhaving a third massless mode are ultimately ruled out while there is still room\nfor STG having a third (massive or massless) mode and for f(R) theories of\ngravity having a third massive mode. \n\n"}
{"id": "1801.01018", "contents": "Title: Pierre Auger Observatory and Telescope Array: Joint Contributions to the\n  35th International Cosmic Ray Conference (ICRC 2017) Abstract: Joint contributions of the Telescope Array Collaboration and the Pierre Auger\nCollaboration to the 35th International Cosmic Ray Conference (ICRC 2017),\n12-20 July 2017, Bexco, Busan, Korea. \n\n"}
{"id": "1801.01496", "contents": "Title: Vector Effective Field Theories from Soft Limits Abstract: We present a bottom-up construction of vector effective field theories using\nthe infrared structure of scattering amplitudes. Our results employ two\ndistinct probes of soft kinematics: multiple soft limits and single soft limits\nafter dimensional reduction, applicable in four and general dimensions,\nrespectively. Both approaches uniquely specify the Born-Infeld (BI) model as\nthe only theory of vectors completely fixed by certain infrared conditions\nwhich generalize the Adler zero for pions. These soft properties imply new\nrecursion relations for on-shell scattering amplitudes in BI theory and suggest\nthe existence of a wider class of vector effective field theories. \n\n"}
{"id": "1801.01723", "contents": "Title: Artificial Neural Network for Constructing Type Ia Supernovae Spectrum\n  Evolution Model Abstract: We construct and train an artificial neural network called the\nback-propagation neural network to describe the evolution of the type Ia\nsupernova spectrum by using the data from the CfA Supernova Program. This\nnetwork method has many attractive features, and one of them is that the\nconstructed model is differentiable. Benefitting from this, we calculate the\nabsorption velocity and its variation. The model we constructed can well\ndescribe not only the spectrum of SNe Ia with wavelength range from $3500\\AA$\nto $8000\\AA$, but also the light-curve evolution with phase time from $-15$ to\n$50$ with different colors. Moreover, the number of parameters needed during\nthe training process is much less than the usual methods. \n\n"}
{"id": "1801.01854", "contents": "Title: The IceCube Neutrino Observatory, the Pierre Auger Observatory and the\n  Telescope Array: Joint Contribution to the 35th International Cosmic Ray\n  Conference (ICRC 2017) Abstract: Joint contributions of the IceCube Collaboration, the Telescope Array\nCollaboration, and the Pierre Auger Collaboration to the 35th International\nCosmic Ray Conference (ICRC 2017), 12-20 July 2017, Bexco, Busan, Korea. \n\n"}
{"id": "1801.03506", "contents": "Title: $r$-process nucleosynthesis in the early Universe through fast mergers\n  of compact binaries in triple systems Abstract: Surface abundance observations of halo stars hint at the occurrence of\n$r$-process nucleosynthesis at low metallicity ($\\rm{[Fe/H]< -3}$), possibly\nwithin the first $10^8$ yr after the formation of the first stars. Possible\nloci of early-Universe $r$-process nucleosynthesis are the ejecta of either\nblack hole--neutron star or neutron star--neutron star binary mergers. Here we\nstudy the effect of the inclination--eccentricity oscillations raised by a\ntertiary (e.g. a star) on the coalescence time scale of the inner compact\nobject binaries. Our results are highly sensitive to the assumed initial\ndistribution of the inner binary semi-major axes. Distributions with mostly\nwide compact object binaries are most affected by the third object, resulting\nin a strong increase (by more than a factor of 2) in the fraction of fast\ncoalescences. If instead the distribution preferentially populates very close\ncompact binaries, general relativistic precession prevents the third body from\nincreasing the inner binary eccentricity to very high values. In this last\ncase, the fraction of coalescing binaries is increased much less by tertiaries,\nbut the fraction of binaries that would coalesce within $10^8$ yr even without\na third object is already high. Our results provide additional support to the\ncompact object merger scenario for $r$-process nucleosynthesis. \n\n"}
{"id": "1801.04124", "contents": "Title: Optical Follow-up of Planck Cluster Candidates with Small Instruments Abstract: We report on the search for optical counterparts of Planck Sunyaev-Zel'dovich\n(SZ) cluster candidates using a 0.6 meter non-professional telescope. Among the\nobserved sources, an unconfirmed candidate, PSZ2 G156.24+22.32, is found to be\nassociated with a region of more than 100 galaxies within a 3 arcminutes radius\naround the Sunyaev-Zel'dovich maximum signal coordinates. Using 14 hours of\ncumulated exposure over the Sloan color filters g', r', i', and, z', we\nestimate the photometric redshift of these galaxies at zphot=0.29 +- 0.08.\nUsing the red-sequence galaxy method gives a photometric redshift of 0.30 +0.03\n-0.05. Combined with the Planck SZ proxy mass function, this would favor a\ncluster of 4.4 x 10^{14} solar masses. This result suggests that a dedicated\npool of observatories equipped with such instruments could collectively\ncontribute to optical follow-up programs of massive cluster candidates at\nmoderate redshifts. \n\n"}
{"id": "1801.04140", "contents": "Title: Cosmic String Detection with Tree-Based Machine Learning Abstract: We explore the use of random forest and gradient boosting, two powerful\ntree-based machine learning algorithms, for the detection of cosmic strings in\nmaps of the cosmic microwave background (CMB), through their unique\nGott-Kaiser-Stebbins effect on the temperature anisotropies.The information in\nthe maps is compressed into feature vectors before being passed to the learning\nunits. The feature vectors contain various statistical measures of processed\nCMB maps that boost the cosmic string detectability. Our proposed classifiers,\nafter training, give results improved over or similar to the claimed\ndetectability levels of the existing methods for string tension, $G\\mu$. They\ncan make $3\\sigma$ detection of strings with $G\\mu \\gtrsim 2.1\\times 10^{-10}$\nfor noise-free, $0.9'$-resolution CMB observations. The minimum detectable\ntension increases to $G\\mu \\gtrsim 3.0\\times 10^{-8}$ for a more realistic, CMB\nS4-like (II) strategy, still a significant improvement over the previous\nresults. \n\n"}
{"id": "1801.04945", "contents": "Title: Planck 2018 results. XI. Polarized dust foregrounds Abstract: The study of polarized dust emission has become entwined with the analysis of\nthe cosmic microwave background (CMB) polarization. We use new Planck maps to\ncharacterize Galactic dust emission as a foreground to the CMB polarization. We\npresent Planck EE, BB, and TE power spectra of dust polarization at 353 GHz for\nsix nested sky regions covering from 24 to 71 % of the sky. We present\npower-law fits to the angular power spectra, yielding evidence for\nstatistically significant variations of the exponents over sky regions and a\ndifference between the values for the EE and BB spectra. The TE correlation and\nE/B power asymmetry extend to low multipoles that were not included in earlier\nPlanck polarization papers. We also report evidence for a positive TB dust\nsignal. Combining data from Planck and WMAP, we determine the amplitudes and\nspectral energy distributions (SEDs) of polarized foregrounds, including the\ncorrelation between dust and synchrotron polarized emission, for the six sky\nregions as a function of multipole. This quantifies the challenge of the\ncomponent separation procedure required for detecting the reionization and\nrecombination peaks of primordial CMB B modes. The SED of polarized dust\nemission is fit well by a single-temperature modified blackbody emission law\nfrom 353 GHz to below 70 GHz. For a dust temperature of 19.6 K, the mean\nspectral index for dust polarization is $\\beta_{\\rm d}^{P} = 1.53\\pm0.02 $. By\nfitting multi-frequency cross-spectra, we examine the correlation of the dust\npolarization maps across frequency. We find no evidence for decorrelation. If\nthe Planck limit for the largest sky region applies to the smaller sky regions\nobserved by sub-orbital experiments, then decorrelation might not be a problem\nfor CMB experiments aiming at a primordial B-mode detection limit on the\ntensor-to-scalar ratio $r\\simeq0.01$ at the recombination peak. \n\n"}
{"id": "1801.05841", "contents": "Title: Formation of massive seed black holes via collisions and accretion Abstract: Models aiming to explain the formation of massive black hole seeds, and in\nparticular the direct collapse scenario, face substantial difficulties. These\nare rooted in rather ad hoc and fine-tuned initial conditions, such as the\nsimultaneous requirements of extremely low metallicities and strong radiation\nbackgrounds. Here we explore a modification of such scenarios where a massive\nprimordial star cluster is initially produced. Subsequent stellar collisions\ngive rise to the formation of massive (10^4 - 10^5 solar mass) objects. Our\ncalculations demonstrate that the interplay between stellar dynamics, gas\naccretion and protostellar evolution is particularly relevant. Gas accretion\nonto the protostars enhances their radii, resulting in an enhanced collisional\ncross section. We show that the fraction of collisions can increase from 0.1-1%\nof the initial population to about 10% when compared to gas-free models or\nmodels of protostellar clusters in the local Universe. We conclude that very\nmassive objects can form in spite of initial fragmentation, making the first\nmassive protostellar clusters viable candidate birth places for observed\nsupermassive black holes. \n\n"}
{"id": "1801.08541", "contents": "Title: Galaxy Zoo: Morphological classification of galaxy images from the\n  Illustris simulation Abstract: Modern cosmological simulations model the universe with increasing\nsophistication and at higher spatial and temporal resolutions. These\nenhancements permit detailed comparisons between the simulation outputs and\nreal observational data. Recent projects such as Illustris are capable of\nproducing simulated images that are comparable to those obtained from local\nsurveys. This paper tests how well Illustris achieves this goal across a\ndiverse population of galaxies using visual morphologies derived from Galaxy\nZoo citizen scientists. Morphological classifications provided by volunteers\nfor simulated galaxies are compared with similar data for a compatible sample\nof images drawn from the SDSS Legacy Survey. This paper investigates how simple\nmorphological characterization by human volunteers asked to distinguish smooth\nfrom featured systems differs between simulated and real galaxy images.\nDifferences are identified, which are likely due to the limited resolution of\nthe simulation, but which could be revealing real differences in the dynamical\nevolution of populations of galaxies in the real and model universes.\nSpecifically, for stellar masses $M_{\\star}\\lesssim10^{11}M_{\\odot}$, a larger\nproportion of Illustris galaxies that exhibit disk-like morphology or visible\nsubstructure, relative to their SDSS counterparts. Toward higher masses,\nsimulated and observed galaxies converge and exhibit similar morphology\ndistributions. The stellar mass threshold indicated by this divergent behavior\nconfirms recent works using parametric measures of morphology from Illustris\nsimulated images. When $M_{\\star}\\gtrsim10^{11}M_{\\odot}$, the Illustris\ndataset contains fewer galaxies that classifiers regard as unambiguously\nfeatured. These results suggest that comparison between the detailed properties\nof observed and simulated galaxies, even when limited to reasonably massive\nsystems, may be misleading. \n\n"}
{"id": "1801.08937", "contents": "Title: Iterative map-making with two-level preconditioning for polarized Cosmic\n  Microwave Background data sets Abstract: An estimation of the sky signal from streams of Time Ordered Data (TOD)\nacquired by Cosmic Microwave Background (\\cmb) experiments is one of the most\nimportant steps in the context of \\cmb data analysis referred to as the\nmap-making problem. The continuously growing \\cmb data sets render the \\cmb\nmap-making problem more challenging in terms of computational cost and memory\nin particular in the context of ground based experiments. In this context, we\nstudy a novel class of the Preconditioned Conjugate Gradient (PCG) solvers\nwhich invoke two-level preconditioners. We compare them against PCG solvers\ncommonly used in the map-making context considering their precision and\ntime-to-solution. We compare these new methods on realistic, simulated data\nsets reflecting the characteristics of current and forthcoming \\cmb\nground-based experiment. We develop an embarrassingly parallel implementation\nof the approach where each processor performs a sequential map-making for a\nsubset of the TOD. We find that considering the map level residuals the new\nclass of solvers permits achieving tolerance of up to 3 orders of magnitude\nbetter than the standard approach, where the residual level often saturates\nbefore convergence is reached. This corresponds to an important improvement in\nthe precision of recovered power spectra in particular on the largest angular\nscales. The new method also typically requires fewer iterations to reach a\nrequired precision and thus shorter runtimes for a single map-making solution.\nHowever, the construction of an appropriate two-level preconditioner can be as\ncostly as a single standard map-making run. Nevertheless, if the same problem\nneeds to be solved multiple times, e.g., as in Monte Carlo simulations, this\ncost has to be incurred only once, and the method should be competitive not\nonly as far as its precision but also its performance is concerned. \n\n"}
{"id": "1802.01145", "contents": "Title: The S-PASS view of polarized Galactic Synchrotron at 2.3 GHz as a\n  contaminant to CMB observations Abstract: We analyze the Southern Sky emission in linear polarization at 2.3 GHz as\nobserved by the S-band Polarization All Sky Survey S-PASS. Our purpose is to\nstudy the properties of the diffuse Galactic polarized synchrotron as a\ncontaminant to CMB B-mode observations. We study the angular distribution of\nthe S-PASS signal at intermediate and high Galactic latitudes by means of\nangular power spectra. Power spectra, show a decay of the spectral amplitude as\na function of multipole for \\ell<200, typical of the diffuse emission. Spectra\ncan be approximated by a power law C_{\\ell}\\propto\\ell^{alpha}, with alpha~-3,\nand characterized by a B-to-E ratio of ~0.5. We study the synchrotron SED in\npolarization by computing power spectra of the low frequency WMAP and Planck\nmaps. Results show that the SED, in the frequency range 2.3-33 GHz, is\ncompatible with a power law with beta_s=-3.22\\pm0.08. Combining S-PASS\npolarization maps with those coming from WMAP and Planck we derived a map of\nthe synchrotron spectral index at angular resolution of 2{\\deg} on about 30% of\nthe sky. The recovered distribution peaks at the value around -3.2. We also\nmeasure a significant spatial correlation between synchrotron and thermal dust\nsignals, as traced by the Planck 353 GHz channel. This correlation reaches\nabout 40% on the larger angular scales, decaying considerably at the degree\nscales. Finally, we use the S-PASS maps to assess the polarized synchrotron\ncontamination to CMB observations of the B-modes. Moreover, by combining S-PASS\ndata with Planck 353 GHz observations, we recover a map of the minimum level of\ntotal polarized foreground contamination to B-modes, finding that there is no\nregion of the sky, at any frequency, where this contamination lies below\nequivalent tenor-to-scalar ratio ~10^-3. This result confirms the importance of\nobserving both high and low frequency foregrounds in CMB B-mode measurements. \n\n"}
{"id": "1802.02255", "contents": "Title: Model Selection Using Cosmic Chronometers with Gaussian Processes Abstract: The use of Gaussian Processes with a measurement of the cosmic expansion rate\nbased solely on the observation of cosmic chronometers provides a completely\ncosmology-independent reconstruction of the Hubble constant H(z) suitable for\ntesting different models. The corresponding dispersion sigma_H is smaller than\n~9% over the entire redshift range (0 < z < 2) of the observations, rivaling\nmany kinds of cosmological measurements available today. We use the\nreconstructed H(z) function to test six different cosmologies, and show that it\nfavours the R_h=ct universe, which has only one free parameter (i.e., H_0) over\nother models, including Planck LCDM. The parameters of the standard model may\nbe re-optimized to improve the fits to the reconstructed H(z) function, but the\nresults have smaller p-values than one finds with R_h=ct. \n\n"}
{"id": "1802.03609", "contents": "Title: The Strong Gravitational Lens Finding Challenge Abstract: Large scale imaging surveys will increase the number of galaxy-scale strong\nlensing candidates by maybe three orders of magnitudes beyond the number known\ntoday. Finding these rare objects will require picking them out of at least\ntens of millions of images and deriving scientific results from them will\nrequire quantifying the efficiency and bias of any search method. To achieve\nthese objectives automated methods must be developed. Because gravitational\nlenses are rare objects reducing false positives will be particularly\nimportant. We present a description and results of an open gravitational lens\nfinding challenge. Participants were asked to classify 100,000 candidate\nobjects as to whether they were gravitational lenses or not with the goal of\ndeveloping better automated methods for finding lenses in large data sets. A\nvariety of methods were used including visual inspection, arc and ring finders,\nsupport vector machines (SVM) and convolutional neural networks (CNN). We find\nthat many of the methods will be easily fast enough to analyse the anticipated\ndata flow. In test data, several methods are able to identify upwards of half\nthe lenses after applying some thresholds on the lens characteristics such as\nlensed image brightness, size or contrast with the lens galaxy without making a\nsingle false-positive identification. This is significantly better than direct\ninspection by humans was able to do. (abridged) \n\n"}
{"id": "1802.04271", "contents": "Title: Machine learning cosmological structure formation Abstract: We train a machine learning algorithm to learn cosmological structure\nformation from N-body simulations. The algorithm infers the relationship\nbetween the initial conditions and the final dark matter haloes, without the\nneed to introduce approximate halo collapse models. We gain insights into the\nphysics driving halo formation by evaluating the predictive performance of the\nalgorithm when provided with different types of information about the local\nenvironment around dark matter particles. The algorithm learns to predict\nwhether or not dark matter particles will end up in haloes of a given mass\nrange, based on spherical overdensities. We show that the resulting predictions\nmatch those of spherical collapse approximations such as extended\nPress-Schechter theory. Additional information on the shape of the local\ngravitational potential is not able to improve halo collapse predictions; the\nlinear density field contains sufficient information for the algorithm to also\nreproduce ellipsoidal collapse predictions based on the Sheth-Tormen model. We\ninvestigate the algorithm's performance in terms of halo mass and radial\nposition and perform blind analyses on independent initial conditions\nrealisations to demonstrate the generality of our results. \n\n"}
{"id": "1802.04594", "contents": "Title: The QUIJOTE Experiment: Prospects for CMB B-MODE polarization detection\n  and foregrounds characterization Abstract: QUIJOTE (Q-U-I JOint TEnerife) is an experiment designed to achieve CMB\nB-mode polarization detection and sensitive enough to detect a primordial\ngravitational-wave component if the B-mode amplitude is larger than r = 0.05.\nIt consists in two telescopes and three instruments observing in the frequency\nrange 10-42 GHz installed at the Teide Observatory in the Canary Islands,\nSpain. The observing strategy includes three raster scan deep integration\nfields for cosmology, a nominal wide survey covering the Northen Sky and\nspecific raster scan deep integration observations in regions of specific\ninterest. The main goals of the project are presented and the first scientific\nresults obtained with the first instrument are reviewed. \n\n"}
{"id": "1802.05532", "contents": "Title: Strongly gravitational lensed SNe Ia as multi-messengers: Direct test of\n  the Friedmann-Lema\\^{\\i}tre-Robertson-Walker metric Abstract: We present a new idea of testing the validity of the\nFriedman-Lema\\^{\\i}tre-Robertson-Walker metric, through the multiple\nmeasurements of galactic-scale strong gravitational lensing systems with type\nIa supernovae in the role of sources. Each individual lensing system will\nprovide a model-independent measurement of the spatial curvature parameter\nreferring only to geometrical optics independently of the matter content of the\nuniverse. This will create a valuable opportunity to test the FLRW metric\ndirectly. Our results show that with hundreds of strongly lensed SNe Ia\nobserved by LSST, one would produce robust constraints on the spatial curvature\nwith accuracy $\\Delta \\Omega_k=0.04$ comparable to the Planck 2015 results. \n\n"}
{"id": "1802.07198", "contents": "Title: DarkSide-50 532-day Dark Matter Search with Low-Radioactivity Argon Abstract: The DarkSide-50 direct-detection dark matter experiment is a dual-phase argon\ntime projection chamber operating at Laboratori Nazionali del Gran Sasso. This\npaper reports on the blind analysis of a (16,660+-270) kg d exposure using a\ntarget of low-radioactivity argon extracted from underground sources. We find\nno events in the dark matter selection box and set a 90% C.L. upper limit on\nthe dark matter-nucleon spin-independent cross section of 1.14E-44 cm^2\n(3.78E-44 cm^2, 3.43E-43 cm^2) for a WIMP mass of 100 GeV/c^2 (1 TeV/c^2, 10\nTeV/c^2). \n\n"}
{"id": "1802.07206", "contents": "Title: The Fifth Force in the Local Cosmic Web Abstract: Extensions of the standard models of particle physics and cosmology often\nlead to long-range fifth forces with properties dependent on gravitational\nenvironment. Fifth forces on astrophysical scales are best studied in the\ncosmic web where perturbation theory breaks down. We present constraints on\nchameleon- and symmetron-screened fifth forces with Yukawa coupling and\nmegaparsec range -- as well as unscreened fifth forces with differential\ncoupling to galactic mass components -- by searching for the displacements they\npredict between galaxies' stars and gas. Taking data from the Alfalfa HI\nsurvey, identifying galaxies' gravitational environments with the maps of\nDesmond et al. (2018a) and forward-modelling with a Bayesian likelihood\nframework, we set upper bounds on fifth-force strength relative to Newtonian\ngravity from $\\Delta G/G_N < \\text{few} \\: \\times 10^{-4}$ for range $\\lambda_C\n= 50$ Mpc, to $\\Delta G/G_N \\lesssim 0.1$ for $\\lambda_C = 500$ kpc. In $f(R)$\ngravity this requires $f_{R0} < \\text{few} \\: \\times \\: 10^{-8}$. The analogous\nbounds without screening are $\\Delta G/G_N < \\text{few} \\: \\times 10^{-4}$ and\n$\\Delta G/G_N < \\text{few} \\times 10^{-3}$. These are the tightest and among\nthe only fifth-force constraints on galaxy scales. We show how our results may\nbe strengthened with future survey data and identify the key features of an\nobservational programme for furthering fifth-force tests beyond the Solar\nSystem. \n\n"}
{"id": "1802.09014", "contents": "Title: Reconstruction of Convergence power spectrum from SNLS weak lensing data Abstract: We estimate the lensing convergence power spectrum from supernovae\nmagnification data using real space correlation function technique. For our\nanalysis we have utilized 296 supernovae from 5-year Supernovae Legacy Survey\nin the weak lensing limit. The data we used consists of measurements from four\ndifferent patches, each of them covers almost 1 square degree of the sky,\nmerged together. We demonstrate that it is quite possible to have a good\nestimate of the convergence power spectrum from this data. Our primary\nintention is to extract meaningful informations from SNLS weak lensing data and\nto demonstrate how the power spectrum for convergence can be reconstructed\ntherefrom, without going into the nitty-gritty of errors, although we have done\nsome error analysis in the process. \n\n"}
{"id": "1802.10101", "contents": "Title: Extracting foreground-obscured $\\mu$-distortion anisotropies to\n  constrain primordial non-Gaussianity Abstract: Correlations between cosmic microwave background (CMB) temperature,\npolarization and spectral distortion anisotropies can be used as a probe of\nprimordial non-Gaussianity. Here, we perform a reconstruction of\n$\\mu$-distortion anisotropies in the presence of Galactic and extragalactic\nforegrounds, applying the so-called Constrained ILC component separation method\nto simulations of proposed CMB space missions (PIXIE, LiteBIRD, CORE, PICO).\nOur sky simulations include Galactic dust, Galactic synchrotron, Galactic\nfree-free, thermal Sunyaev-Zeldovich effect, as well as primary CMB temperature\nand $\\mu$-distortion anisotropies, the latter being added as correlated field.\nThe Constrained ILC method allows us to null the CMB temperature anisotropies\nin the reconstructed $\\mu$-map (and vice versa), in addition to mitigating the\ncontaminations from astrophysical foregrounds and instrumental noise. We\ncompute the cross-power spectrum between the reconstructed (CMB-free)\n$\\mu$-distortion map and the ($\\mu$-free) CMB temperature map, after foreground\nremoval and component separation. Since the cross-power spectrum is\nproportional to the primordial non-Gaussianity parameter, $f_{\\rm NL}$, on\nscales $k\\simeq 740$ Mpc$^{-1}$, this allows us to derive $f_{\\rm\nNL}$-detection limits for the aforementioned future CMB experiments. Our\nanalysis shows that foregrounds degrade the theoretical detection limits (based\nmostly on instrumental noise) by more than one order of magnitude, with PICO\nstanding the best chance at placing upper limits on scale-dependent\nnon-Gaussianity. We also discuss the dependence of the constraints on the\nchannel sensitivities and chosen bands. Like for $B$-mode polarization\nmeasurements, extended coverage at frequencies $\\nu\\lesssim 40\\,{\\rm GHz}$ and\n$\\nu\\gtrsim 400\\,{\\rm GHz}$ provides more leverage than increased channel\nsensitivity. \n\n"}
{"id": "1803.03236", "contents": "Title: First predictions of the angular power spectrum of the astrophysical\n  gravitational wave background Abstract: We present the first predictions for the angular power spectrum of the\nastrophysical gravitational wave background constituted of the radiation\nemitted by all resolved and unresolved astrophysical sources. Its shape and\namplitude depend on both the astrophysical properties on galactic scales and on\ncosmological properties. We show that the angular power spectrum behaves as\n$C_{\\ell}\\propto 1/{\\ell}$ on large scales and that relative fluctuations of\nthe signal are of order 30% at 100 Hz. We also present the correlations of the\nastrophysical gravitational wave background with weak-lensing and galaxy\ndistribution. These numerical results pave the way to the study of a new\nobservable at the crossroad between general relativity, astrophysics and\ncosmology. \n\n"}
{"id": "1803.04470", "contents": "Title: Conservative cosmology: combining data with allowance for unknown\n  systematics Abstract: When combining data sets to perform parameter inference, the results will be\nunreliable if there are unknown systematics in data or models. Here we\nintroduce a flexible methodology, BACCUS: BAyesian Conservative Constraints and\nUnknown Systematics, which deals in a conservative way with the problem of data\ncombination, for any degree of tension between experiments. We introduce\nhyperparameters that describe a bias in each model parameter for each class of\nexperiments. A conservative posterior for the model parameters is then obtained\nby marginalization both over these unknown shifts and over the width of their\nprior. We contrast this approach with an existing hyperparameter method in\nwhich each individual likelihood is scaled, comparing the performance of each\napproach and their combination in application to some idealized models. Using\nonly these rescaling hyperparameters is not a suitable approach for the current\nobservational situation, in which internal null tests of the errors are passed,\nand yet different experiments prefer models that are in poor agreement. The\npossible existence of large shift systematics cannot be constrained with a\nsmall number of data sets, leading to extended tails on the conservative\nposterior distributions. We illustrate our method with the case of the $H_0$\ntension between results from the cosmic distance ladder and physical\nmeasurements that rely on the standard cosmological model. \n\n"}
{"id": "1803.07298", "contents": "Title: Robust Limits on Photon Mass from Statistical Samples of Extragalactic\n  Radio Pulsars Abstract: The photon zero-mass hypothesis has been investigated for a long time using\nthe frequency-dependent time delays of radio emissions from astrophysical\nsources. However, the search for a rest mass of the photon has been hindered by\nthe similarity between the frequency-dependent dispersions due to the plasma\nand nonzero photon mass effects. Considering the contributions to the observed\ndispersion measure from both the plasma and nonzero photon mass effects, and\nassuming the dispersion induced by the plasma effect is an unknown constant, we\nobtain a robust limit on the photon mass by directly fitting a combination of\nthe dispersion measures of radio sources. Using the observed dispersion\nmeasures from two statistical samples of extragalactic pulsars, here we show\nthat at the 68\\% confidence level, the constraints on the photon mass can be as\nlow as $m_{\\gamma}\\leq1.51\\times10^{-48}~\\rm kg\\simeq8.47\\times10^{-13}~{\\rm\neV}/c^{2}$ for the sample of 22 radio pulsars in the Large Magellanic Cloud and\n$m_{\\gamma}\\leq1.58\\times10^{-48}~\\rm kg\\simeq8.86\\times10^{-13} {\\rm\neV}/c^{2}$ for the other sample of 5 radio pulsars in the Small Magellanic\nCloud, which are comparable with that obtained by a single extragalactic\npulsar. Furthermore, the statistical approach presented here can also be used\nwhen more fast radio bursts with known redshifts are detected in the future. \n\n"}
{"id": "1803.10773", "contents": "Title: Optimised angular power spectra for spectroscopic galaxy surveys Abstract: The angular power spectrum is a gauge-independent observable that is in\nprinciple the natural tool for analysing galaxy number counts. In practice, the\nproblem is that the computational requirements for next-generation\nspectroscopic surveys such as Euclid and the Square Kilometre Array are\ncurrently unfeasible. We propose a new method to save computational time for\nspectroscopic angular power spectra. This hybrid method is modelled on the\nFourier power spectrum approach of treating relatively thick redshift bins\n(redshift width ~0.1) as separate surveys. In the hybrid method, each thick bin\nis further subdivided into thin bins (redshift width ~0.01); all the\ncorrelations within each thick bin are computed, while cross-bin correlations\nbeyond the thick bins are neglected. Constraints on cosmological parameters\nfrom the hybrid method are comparable to those from the standard galaxy power\nspectrum analysis - but they have the advantage that cosmic evolution,\nwide-angle and lensing effects are naturally included, while no\nAlcock-Paczynski correction is needed. The hybrid method delivers much tighter\nconstraints than a 2D tomographic approach that is typical for photometric\nsurveys, which considers only thick bins and the correlations between them.\nFurthermore, for standard cosmological parameters our method is not biased by\nneglecting the effects of lensing on number counts, while the tomographic\nmethod is strongly biased. \n\n"}
{"id": "1804.01092", "contents": "Title: 21-cm Fluctuations from Charged Dark Matter Abstract: The epoch of the formation of the first stars, known as the cosmic dawn, has\nemerged as a new arena in the search for dark matter. In particular, the first\nclaimed 21-cm detection exhibits a deeper global absorption feature than\nexpected, which could be caused by a low baryonic temperature, and has been\ninterpreted as a sign for electromagnetic interactions between baryons and dark\nmatter. This hypothesis has a striking prediction: large temperature\nanisotropies sourced by the velocity-dependent cooling of the baryons. However,\nin order to remain consistent with the rest of cosmological observations, only\npart of the dark matter is allowed to be charged, and thus interactive. Here we\ncompute, for the first time, the 21-cm fluctuations caused by a charged\nsubcomponent of the dark matter, including both the pre- and post-recombination\nevolution of all fluids. We find that, for the same parameters that can explain\nthe anomalous 21-cm absorption signal, any percent-level fraction of charged\ndark matter would source novel 21-cm fluctuations with a unique acoustic\nspectrum, and with an amplitude above any other known effects. These\nfluctuations are uncorrelated with the usual adiabatic anisotropies, and would\nbe observable at high significance with interferometers such as LOFAR and HERA,\nthus providing a novel probe of dark matter at cosmic dawn. \n\n"}
{"id": "1804.02180", "contents": "Title: A direct dark matter search in XMASS-I Abstract: A search for dark matter using an underground single-phase liquid xenon\ndetector was conducted at the Kamioka Observatory in Japan, particularly for\nWeakly Interacting Massive Particles (WIMPs). We have used 705.9 live days of\ndata in a fiducial volume containing 97 kg of liquid xenon at the center of the\ndetector. The event rate in the fiducial volume after the data reduction was\n${\\rm (4.2 \\pm 0.2) \\times 10^{-3} \\, day^{-1}kg^{-1} keV_{ee}^{-1}}$ at ${\\rm\n5 \\, keV_{ee}}$, with a signal efficiency of ${\\rm 20\\%}$. All the remaining\nevents are consistent with our background evaluation, mostly of the\n\"mis-reconstructed events\" originated from $^{210}$Pb in the copper plates\nlining the detector's inner surface. The obtained upper limit on a\nspin-independent WIMP-nucleon cross section was ${\\rm 2.2 \\times 10^{-44} \\,\ncm^{2}}$ for a WIMP mass of ${\\rm 60 \\, GeV/c^{2}}$ at the $90\\%$ confidence\nlevel, which was the most stringent limit among results from single-phase\nliquid xenon detectors. \n\n"}
{"id": "1804.02588", "contents": "Title: `Rings' of diffuse radio emission surrounding the Bullet cluster Abstract: We present the discovery of ringlike diffuse radio emission structures in the\nperipheral regions of the Bullet cluster 1E 0657$-$55.8. Ring formations are\nspanning between 1--3 Mpc away from the center of the cluster, significantly\nfurther away from the two already reported relics. Integrated fluxes of four of\nthe sub-regions in the inner `ring' from 4.5 to 10 GHz have also been reported.\nTo understand the possible origin of these structures, here we present a maiden\nattempt of numerical modelling of a 3D and realistic `bullet' like event in a\nfull cosmological ($\\Lambda$CDM) environment with N-body plus hydrodynamics\ncode. We report a simulated `bullet' found inside a (128 Mpc)$^3$ volume\nsimulation with a speed of 2700 km s$^{-1}$, creating a high supersonic bow\nshock of Mach $M=3.5$ and a clear evidence of temporal separation of dark\nmatter and baryons, assuring no challenge to $\\Lambda$CDM cosmology from the\nbullet event as of now. We are also able to unveil the physics behind the\nformation of these observed multiple shock structures. Modelled radio emissions\nin our simulation support a complex combination of merger-associated processes\nthat accelerates and re-accelerates fossil and cosmic-ray electrons. With a\ntime evolution study and the computed radio emissions, we have shown that the\nring like formation around the bullet is originated due to the interaction of\nthe strong merger shocks with the accretion shocks at the periphery. The\nmultiple shock structures observed are possibly originated from multiple\nmergers that have taken place at different times and much before the bullet\nevent. \n\n"}
{"id": "1804.02732", "contents": "Title: Statistical tracing of magnetic fields: comparing and improving the\n  techniques Abstract: Magnetohydrodynamic(MHD) turbulence displays velocity anisotropies which\nreflect the direction of the magnetic field. This anisotropy has led to the\ndevelopment of a number of statistical techniques for studying magnetic fields\nin the interstellar medium. In this paper, we review and compare three\ntechniques that use radio position-position-velocity data for determining\nmagnetic field strength and morphology : the correlation function anisotropy\n(CFA), Principal Component Analysis of Anisotropies (PCAA), and the more recent\nVelocity Gradient Technique (VGT). We compare these three techniques and\nsuggest improvements to the CFA and PCAA techniques to increase their accuracy\nand versatility. In particular, we suggest and successfully implement a much\nfaster way of calculating non-periodic correlation functions for the CFA. We\ndiscuss possible improvements to the current implementation of the PCAA. We\nshow the advantages of the VGT in terms of magnetic field tracing and stress\nthe complementary nature with the other two techniques. \n\n"}
{"id": "1804.06406", "contents": "Title: nestcheck: diagnostic tests for nested sampling calculations Abstract: Nested sampling is an increasingly popular technique for Bayesian\ncomputation, in particular for multimodal, degenerate problems of moderate to\nhigh dimensionality. Without appropriate settings, however, nested sampling\nsoftware may fail to explore such posteriors correctly; for example producing\ncorrelated samples or missing important modes. This paper introduces new\ndiagnostic tests to assess the reliability both of parameter estimation and\nevidence calculations using nested sampling software, and demonstrates them\nempirically. We present two new diagnostic plots for nested sampling, and give\npractical advice for nested sampling software users in astronomy and beyond.\nOur diagnostic tests and diagrams are implemented in nestcheck: a publicly\navailable Python package for analysing nested sampling calculations, which is\ncompatible with output from MultiNest, PolyChord and dyPolyChord. \n\n"}
{"id": "1804.06457", "contents": "Title: Liquid Scintillator Response to Proton Recoils in the 10-100 keV Range Abstract: We study the response of EJ-301 liquid scintillator to monochromatic 244.6\n$\\pm$ 8.4 keV neutrons, targeting the 10-100 keV proton recoil energy interval.\nLimited experimental information exists for proton light yield in this range,\nfor this or any other organic scintillator. Our results confirm the adequacy of\na modified Birks' model, common to all organic scintillator formulations,\npredicting a marked increase in quenching factor as proton energy approaches\nthe few keV regime. The relevance of this behavior within the context of\nsearches for low-mass particle dark matter is mentioned. \n\n"}
{"id": "1804.07255", "contents": "Title: Scalar Dark Matter Clumps with Angular Momentum Abstract: The behavior of light scalar dark matter has been a subject of much interest\nrecently as it can lead to interesting small scale behavior. In particular,\nthis can lead to the formation of gravitationally bound clumps for these light\nscalars, including axions. In Ref. [1] we analyzed the behavior of these\nclumps, assuming spherical symmetry, allowing for both attractive and repulsive\nself-interactions. There is a maximum allowed mass for the clumps in the case\nof attractive interactions, and a minimum radius for the clumps in the case of\nrepulsive interactions, which is saturated at large mass. Here we extend this\nwork to include non-spherically symmetric clumps. Since the system tries to\nre-organize into a BEC ground state, we consider configurations with a\nconserved non-zero angular momentum, and construct minimum energy\nconfigurations at fixed particle number and fixed angular momentum. We find\ngeneralizations of the previous spherically symmetric results. In particular,\nwhile there is still a maximum mass for the attractive case, its value\nincreases with angular momentum. Also, the minimum radius in the repulsive case\nis raised to higher radii. We clarify how a recent claim in the literature of\nan upper bound on angular momentum is due to inaccurate numerics. In a\nforthcoming paper we shall investigate the possibility of resonance of axion\nclumps into both visible and hidden sector photons, and analyze how the altered\nmass and radius from non-zero angular momentum affects the resonance. \n\n"}
{"id": "1804.07261", "contents": "Title: MontePython 3: boosted MCMC sampler and other features Abstract: MontePython is a parameter inference package for cosmology. We present the\nlatest development of the code over the past couple of years. We explain, in\nparticular, two new ingredients both contributing to improve the performance of\nMetropolis-Hastings sampling: an adaptation algorithm for the jumping factor,\nand a calculation of the inverse Fisher matrix, which can be used as a proposal\ndensity. We present several examples to show that these features speed up\nconvergence and can save many hundreds of CPU-hours in the case of difficult\nruns, with a poor prior knowledge of the covariance matrix. We also summarise\nall the functionalities of MontePython in the current release, including new\nlikelihoods and plotting options. \n\n"}
{"id": "1804.08143", "contents": "Title: Maximum-Entropy Priors with Derived Parameters in a Specified\n  Distribution Abstract: We propose a method for transforming probability distributions so that\nparameters of interest are forced into a specified distribution. We prove that\nthis approach is the maximum entropy choice, and provide a motivating example\napplicable to neutrino hierarchy inference. \n\n"}
{"id": "1804.08476", "contents": "Title: Cosmic Microwave Background Constraints in Light of Priors Over\n  Reionization Histories Abstract: Non-parametric reconstruction or marginalization over the history of\nreionization using cosmic microwave background data necessarily assumes a prior\nover possible histories. We show that different but reasonable choices of\npriors can shift current and future constraints on the reionization optical\ndepth, $\\tau$, or correlated parameters such as the neutrino mass sum, $\\Sigma\nm_\\nu$, at the level of 0.3-0.4$\\sigma$, i.e., that this analysis is somewhat\nprior dependent. We point out some prior-related problems with the commonly\nused principal component reconstruction, concluding that the significance of\nsome recent hints of early reionization in Planck 2015 data has been\noverestimated. We also present the first non-parametric reconstruction applied\nto newer Planck intermediate (2016) data and find that the hints of early\nreionization disappear entirely in this more precise dataset. These results\nlimit possible explanations of the EDGES 21cm signal which would have also\nsignificantly reionized the universe at $z\\,{>}\\,15$. Our findings about the\ndependence on priors motivate the pursuit of improved data or searches for\nphysical reionization models which can reduce the prior volume. The discussion\nhere of priors is of general applicability to other non-parametric\nreconstructions, for example of the primordial power spectrum, of the\nrecombination history, or of the expansion rate. \n\n"}
{"id": "1804.09581", "contents": "Title: NIKA 150 GHz polarization observations of the Crab nebula and its\n  spectral energy distribution Abstract: The Crab nebula is a supernova remnant exhibiting a highly polarized\nsynchrotron radiation at radio and millimeter wavelengths. It is the brightest\nsource in the microwave sky with an extension of 7 by 5 arcminutes and commonly\nused as a standard candle for any experiment which aims at measuring the\npolarization of the sky. Though its spectral energy distribution has been well\ncharacterized in total intensity, polarization data are still lacking at\nmillimetre wavelengths. We report in this paper high resolution (18 arcsec\nFWHM) observations of the Crab nebula in total intensity and linear\npolarization at 150 GHz with the NIKA camera. NIKA, operated at the IRAM 30 m\ntelescope from 2012 to 2015, is a camera made of Lumped Element Kinetic\nInductance Detectors (LEKIDs) observing the sky at 150 and 260 GHz. From these\nobservations we are able to reconstruct the spatial distribution of the\npolarization degree and angle of the Crab nebula, which is found to be\ncompatible with previous observations at lower and higher frequencies.\nAveraging across the source and using other existing data sets we find that the\nCrab nebula polarization angle is consistent with being constant over a wide\nrange of frequencies with a value of -87.7$^\\circ$ +- 0.3 in Galactic\ncoordinates. We also present the first estimation of the Crab nebula spectral\nenergy distribution polarized flux in a wide frequency range: 30-353 GHz.\nAssuming a single power law emission model we find that the polarization\nspectral index $\\beta_{pol}$ = - 0.347 +- 0.026 is compatible with the\nintensity spectral index $\\beta$ = - 0.323 +- 0.001. \n\n"}
{"id": "1804.09647", "contents": "Title: Formation and structure of ultralight bosonic dark matter halos Abstract: We simulate the formation and evolution of ultralight bosonic dark matter\nhalos from cosmological initial conditions. Using zoom-in techniques we are\nable to resolve the detailed interior structure of the halos. We observe the\nformation of solitonic cores and confirm the core-halo mass relation previously\nfound by Schive et al. The cores exhibit strong quasi-normal oscillations that\nremain largely undamped on evolutionary timescales. On the other hand, no\nconclusive growth of the core mass by condensation or relaxation can be\ndetected. In the incoherent halo surrounding the cores, the scalar field\ndensity profiles and velocity distributions show no significant deviation from\ncollisionless N-body simulations on scales larger than the coherence length.\nOur results are consistent with the core properties being determined mainly by\nthe coherence length at the time of virialization, whereas the\nSchr\\\"odinger-Vlasov correspondence explains the halo properties when averaged\non scales greater than the coherence length. \n\n"}
{"id": "1804.09705", "contents": "Title: Positive Solutions of Systems of Signed Parametric Polynomial\n  Inequalities Abstract: We consider systems of strict multivariate polynomial inequalities over the\nreals. All polynomial coefficients are parameters ranging over the reals, where\nfor each coefficient we prescribe its sign. We are interested in the existence\nof positive real solutions of our system for all choices of coefficients\nsubject to our sign conditions. We give a decision procedure for the existence\nof such solutions. In the positive case our procedure yields a parametric\npositive solution as a rational function in the coefficients. Our framework\nallows to reformulate heuristic subtropical approaches for non-parametric\nsystems of polynomial inequalities that have been recently used in qualitative\nbiological network analysis and, independently, in satisfiability modulo theory\nsolving. We apply our results to characterize the incompleteness of those\nmethods. \n\n"}
{"id": "1804.11051", "contents": "Title: Gaia DR2 Gravitational Lens Systems I: New lensed quasar candidates\n  around known quasars Abstract: Context. Strong gravitationally lensed quasars are among the most interesting\nand useful observable extragalactic phenomena. Because their study constitutes\na unique tool in various fields of astronomy, they are highly sought, not\nwithout difficulty. Indeed, even in this era of all-sky surveys, their\nrecognition remains a great challenge, with barely a few hundred currently\nknown systems. Aims. In this work we aim to detect new strongly lensed quasar\ncandidates in the recently published Gaia Data Release 2 (DR2), which is the\nhighest spatial resolution astrometric and photometric all-sky survey,\nattaining effective resolutions from 0.4\" to 2.2\". Methods. We cross-matched a\nmerged list of quasars and candidates with the Gaia DR2 and found 1,839,143\ncounterparts within 0.5\". We then searched matches with more than two Gaia DR2\ncounterparts within 6\". We further narrowed the resulting list using astrometry\nand photometry compatibility criteria between the Gaia DR2 counterparts. A\nsupervised machine learning method, Extremely Randomized Trees, is finally\nadopted to assign to each remaining system a probability of being lensed.\nResults. We report the discovery of three quadruply-imaged quasar candidates\nthat are fully detected in Gaia DR2. These are the most promising new quasar\nlens candidates from Gaia DR2 and a simple singular isothermal ellipsoid lens\nmodel is able to reproduce their image positions to within $\\sim$1 mas. This\nletter demonstrates the gravitational lens discovery potential of Gaia. \n\n"}
{"id": "1805.00430", "contents": "Title: Dark Matter Axion Clump Resonance of Photons Abstract: Recently there has been interest in the physical properties of dark matter\naxion condensates. Due to gravitational attraction and self-interactions, they\ncan organize into spatial localized clumps, whose properties were examined by\nus in Refs. [1, 2]. Since the axion condensate is coherently oscillating, it\ncan conceivably lead to parametric resonance of photons, leading to exponential\ngrowth in photon occupancy number and subsequent radio wave emission. We show\nthat while resonance always exists for spatially homogeneous condensates, its\nexistence for a spatially localized clump condensate depends sensitively on the\nsize of clump, strength of axion-photon coupling, and field amplitude. By\ndecomposing the electromagnetic field into vector spherical harmonics, we are\nable to numerically compute the resonance from clumps for arbitrary parameters.\nWe find that for spherically symmetric clumps, which are the true BEC ground\nstates, the resonance is absent for conventional values of the QCD axion-photon\ncoupling, but it is present for axions with moderately large couplings, or into\nhidden sector photons, or from scalar dark matter with repulsive interactions.\nWe extend these results to non-spherically symmetric clumps, organized by\nfinite angular momentum, and find that even QCD axion clumps with conventional\ncouplings can undergo resonant decay for sufficiently large angular momentum.\nWe discuss possible astrophysical consequences of these results, including the\nidea of a pile-up of clump masses and rapid electromagnetic emission in the sky\nfrom mergers. \n\n"}
{"id": "1805.01421", "contents": "Title: Concerns about Modelling of the EDGES Data Abstract: It is predicted that the spectrum of radio emission from the whole sky should\nshow a dip arising from the action of the light from the first stars on the\nhydrogen atoms in the surrounding gas, which causes the 21-cm line to appear in\nabsorption against the cosmic microwave background. Bowman et al. 2018\nidentified a broad flat-bottomed absorption profile centred at 78 MHz, which\ncould be this feature, although the depth of the profile is much larger than\nexpected. We have examined the modelling process they used and find that their\ndata implies unphysical parameters for the foreground emission and also that\ntheir solution is not unique in the sense that we found other simple\nformulations for the signal that are different in shape but that also fit their\ndata. We argue that this calls into question the interpretation of these data\nas an unambiguous detection of the cosmological 21-cm absorption signature. \n\n"}
{"id": "1805.02577", "contents": "Title: Measuring turbulence and gas motions in galaxy clusters via synthetic\n  Athena X-IFU observations Abstract: The X-ray Integral Field Unit (X-IFU) that will be on board the Athena\ntelescope will provide an unprecedented view of the intracluster medium (ICM)\nkinematics through the observation of gas velocity, $v$, and velocity\ndispersion, $w$, via centroid-shift and broadening of emission lines,\nrespectively. The improvement of data quality and quantity requires an\nassessment of the systematics associated with this new data analysis, namely\nbiases, statistical and systematic errors, and possible correlations between\nthe different measured quantities. We have developed an end-to-end X-IFU\nsimulator that mimics a full X-ray spectral fitting analysis on a set of mock\nevent lists, obtained using SIXTE. We have applied it to three hydrodynamical\nsimulations of a Coma-like cluster that include the injection of turbulence.\nThis allowed us to assess the ability of X-IFU to map five physical quantities\nin the cluster core: emission measure, temperature, metal abundance, velocity\nand velocity dispersion. Finally, starting from our measurements maps, we\ncomputed the 2D structure function (SF) of emission measure fluctuations, $v$\nand $w$ and compared them with those derived directly from the simulations. All\nquantities match with the input projected values without bias; the systematic\nerrors were below 5%, except for velocity dispersion whose error reaches about\n15%. Moreover, all measurements prove to be statistically independent,\nindicating the robustness of the fitting method. Most importantly, we recover\nthe slope of the SFs in the inertial regime with excellent accuracy, but we\nobserve a systematic excess in the normalization of both SF$_v$ and SF$_w$\nascribed to the simplistic assumption of uniform and (bi-)Gaussian measurement\nerrors. Our work highlights the excellent capabilities of Athena X-IFU in\nprobing the thermodynamic and kinematic properties of the ICM. (abridged) \n\n"}
{"id": "1805.02646", "contents": "Title: Search for a Non-Relativistic Component in the Spectrum of Cosmic Rays\n  at Earth Abstract: Dark matter particles gravitationally bound to our galaxy should exhibit a\ncharacteristic speed distribution limited by their escape velocity at the\nposition of the Earth ($v_{esc}\\simeq$ 550 km/s). An ongoing search for\nanomalous cosmic rays at Earth, kinematically similar to cold dark matter, is\ndescribed. The technique can discriminate between these and known slow-moving\nparticles such as neutrons, would be sensitive to telltale signatures from\npresently unexplored candidates, and offers the possibility of identifying the\nmediating type of interaction (nuclear vs. electron recoils). Studies of\nbackground identification and abatement in a shallow underground site are\npresented. The expected reach of the method is discussed, and illustrated by\nobtaining the first limits for dark matter particles lighter than 100\nMeV/c$^{2}$ interacting via nuclear recoils. \n\n"}
{"id": "1805.04537", "contents": "Title: A volumetric deep Convolutional Neural Network for simulation of mock\n  dark matter halo catalogues Abstract: For modern large-scale structure survey techniques it has become standard\npractice to test data analysis pipelines on large suites of mock simulations, a\ntask which is currently prohibitively expensive for full N-body simulations.\nInstead of calculating this costly gravitational evolution, we have trained a\nthree-dimensional deep Convolutional Neural Network (CNN) to identify dark\nmatter protohalos directly from the cosmological initial conditions. Training\non halo catalogues from the Peak Patch semi-analytic code, we test various CNN\narchitectures and find they generically achieve a Dice coefficient of ~92% in\nonly 24 hours of training. We present a simple and fast geometric halo finding\nalgorithm to extract halos from this powerful pixel-wise binary classifier and\nfind that the predicted catalogues match the mass function and power spectra of\nthe ground truth simulations to within ~10%. We investigate the effect of\nlong-range tidal forces on an object-by-object basis and find that the\nnetwork's predictions are consistent with the non-linear ellipsoidal collapse\nequations used explicitly by the Peak Patch algorithm. \n\n"}
{"id": "1805.07152", "contents": "Title: Bayesian optimisation for likelihood-free cosmological inference Abstract: Many cosmological models have only a finite number of parameters of interest,\nbut a very expensive data-generating process and an intractable likelihood\nfunction. We address the problem of performing likelihood-free Bayesian\ninference from such black-box simulation-based models, under the constraint of\na very limited simulation budget (typically a few thousand). To do so, we adopt\nan approach based on the likelihood of an alternative parametric model.\nConventional approaches to approximate Bayesian computation such as\nlikelihood-free rejection sampling are impractical for the considered problem,\ndue to the lack of knowledge about how the parameters affect the discrepancy\nbetween observed and simulated data. As a response, we make use of a strategy\npreviously developed in the machine learning literature (Bayesian optimisation\nfor likelihood-free inference, BOLFI), which combines Gaussian process\nregression of the discrepancy to build a surrogate surface with Bayesian\noptimisation to actively acquire training data. We extend the method by\nderiving an acquisition function tailored for the purpose of minimising the\nexpected uncertainty in the approximate posterior density, in the parametric\napproach. The resulting algorithm is applied to the problems of summarising\nGaussian signals and inferring cosmological parameters from the Joint\nLightcurve Analysis supernovae data. We show that the number of required\nsimulations is reduced by several orders of magnitude, and that the proposed\nacquisition function produces more accurate posterior approximations, as\ncompared to common strategies. \n\n"}
{"id": "1805.07181", "contents": "Title: Multivariate analysis of cosmic void characteristics Abstract: The aim of this study is to distinguish genuine cosmic voids, found in a\ngalaxy catalog by the void finder ZOBOV-VIDE, from under-dense regions in a\nPoisson distribution of objects. For this purpose, we perform two multivariate\nanalyses using the following physical void characteristics: volume, redshift,\ndensity contrast, minimum density, contrast significance and number of member\ngalaxies of the void. The multivariate analyses are trained on a catalog of\nvoids obtained from a random Poisson distribution of points, used as\nbackground, and a catalog of voids identified in a mock galaxy catalog, used as\nsignal. The classifications are then applied to voids extracted from the Data\nRelease 12 sample of Luminous Red Galaxies in the redshift range 0.45 $\\leq$ z\n$\\leq$ 0.7 from the Sloan Digital Sky Survey Baryon Oscillation Spectroscopic\nSurvey (SDSS BOSS DR12 CMASS). Our results show that the resulting void catalog\nis nearly free of contamination by Poisson noise. We also study the effect of\ntracer sparsity and bias on the classification efficiencies. \n\n"}
{"id": "1805.07896", "contents": "Title: Dark Energy from Ratio Gravity Abstract: The theory of Ratio Gravity (RG) proposes that the curvature of 3+1 spacetime\noriginates from a deformation of a Cross Ratio, where similar mathematical\nstructure to general relativity emerges. This paper studies RG using the\nframework of the Newman-Penrose spin formalism. After proposing the general\nformalism, we move on to study a homogeneous and isotropic universe with RG. It\nis noted that the theory contains a component of dynamical dark energy with\nnovel equation of state. \n\n"}
{"id": "1805.08640", "contents": "Title: Model Selection with Strong-lensing Systems Abstract: In this paper, we use an unprecedentedly large sample (158) of confirmed\nstrong lens systems for model selection, comparing five well studied\nFriedmann-Robertson-Walker cosmologies: LCDM, wCDM (the standard model with a\nvariable dark-energy equation of state), the R_h=ct universe, the (empty) Milne\ncosmology, and the classical Einstein-de Sitter (matter dominated) universe. We\nfirst use these sources to optimize the parameters in the standard model and\nshow that they are consistent with Planck, though the quality of the best fit\nis not satisfactory. We demonstrate that this is likely due to under-reported\nerrors, or to errors yet to be included in this kind of analysis. We suggest\nthat the missing dispersion may be due to scatter about a pure single\nisothermal sphere (SIS) model that is often assumed for the mass distribution\nin these lenses. We then use the Bayes information criterion, with the\ninclusion of a suggested SIS dispersion, to calculate the relative likelihoods\nand ranking of these models, showing that Milne and Einstein-de Sitter are\ncompletely ruled out, while R_h=ct is preferred over LCDM/wCDM with a relative\nprobability of ~73% versus ~24%. The recently reported sample of new strong\nlens candidates by the Dark Energy Survey, if confirmed, may be able to\ndemonstrate which of these two models is favoured over the other at a level\nexceeding 3 sigma. \n\n"}
{"id": "1805.09903", "contents": "Title: Impact of a primordial magnetic field on cosmic microwave background $B$\n  modes with weak lensing Abstract: We discuss the manner in which the primordial magnetic field (PMF) suppresses\nthe cosmic microwave background (CMB) $B$ mode due to the weak-lensing (WL)\neffect. The WL effect depends on the lensing potential (LP) caused by matter\nperturbations, the distribution of which at cosmological scales is given by the\nmatter power spectrum (MPS). Therefore, the WL effect on the CMB $B$ mode is\naffected by the MPS. Considering the effect of the ensemble average energy\ndensity of the PMF, which we call \"the background PMF,\" on the MPS, the\namplitude of MPS is suppressed in the wave number range of $k>0.01~h$\nMpc$^{-1}$.The MPS affects the LP and the WL effect in the CMB $B$ mode;\nhowever, the PMF can damp this effect. Previous studies of the CMB $B$ mode\nwith the PMF have only considered the vector and tensor modes. These modes\nboost the CMB $B$ mode in the multipole range of $\\ell > 1000$, whereas the\nbackground PMF damps the CMB $B$ mode owing to the WL effect in the entire\nmultipole range. The matter density in the Universe controls the WL effect.\nTherefore, when we constrain the PMF and the matter density parameters from\ncosmological observational data sets, including the CMB $B$ mode, we expect\ndegeneracy between these parameters. The CMB $B$ mode also provides important\ninformation on the background gravitational waves, inflation theory, matter\ndensity fluctuations, and the structure formations at the cosmological scale\nthrough the cosmological parameter search. If we study these topics and\ncorrectly constrain the cosmological parameters from cosmological observations\nincluding the CMB $B$ mode, we need to correctly consider the background PMF. \n\n"}
{"id": "1805.11753", "contents": "Title: Optical Ring Cavity Search for Axion Dark Matter Abstract: We propose a novel experiment to search for axion dark matter which\ndifferentiates the phase velocities of the left and right-handed polarized\nphotons. Our optical cavity measures the difference of the resonant frequencies\nbetween two circular-polarizations of the laser beam. The design of our cavity\nadopts double-pass configuration to realize a null experiment and give a high\ncommon mode rejection of environmental disturbances. We estimate the potential\nsensitivity to the axion-photon coupling constant $g_{a\\gamma}$ for the axion\nmass $m \\lesssim 10^{-10}$ eV. In a low mass range $m \\lesssim 10^{-15}$ eV, we\ncan achieve $g_{a\\gamma} \\lesssim 3\\times 10^{-16} ~\\text{GeV}^{-1}$ which is\nbeyond the current bound by several orders of magnitude. \n\n"}
{"id": "1805.12221", "contents": "Title: Imprints of Chameleon f(R) Gravity on Galaxy Rotation Curves Abstract: Current constraints on gravity are relatively weak on galactic and\nintergalactic scales. Screened modified gravity models can exhibit complex\nbehaviour there without violating stringent tests of gravity within our Solar\nSystem. They might hence provide viable extensions of the theory of gravity.\nHere, we use galaxy kinematics to constrain screened modified gravity models.\nWe focus on chameleon $f(R)$ gravity and predict its impact on galaxy rotation\ncurves and radial acceleration relations. This is achieved by post-processing\nstate-of-the-art galaxy formation simulations from the \\textsc{auriga project},\nusing the \\textsc{mg-gadget} code. For a given galaxy, the surface dividing\nscreened and un-screened regions adopts an oblate shape, reflecting the disc\nmorphology of the galaxy's mass distribution. At the `screening radius'---the\nradius at which screening is triggered in the disc plane---characteristic\n`upturns' are present in both rotation curves and radial acceleration\nrelations. The locations of these features depend on various factors, such as\nthe galaxy mass, the concentration of the density profile and the value of the\nbackground field amplitude $f_{R0}$. Self-screening of stars and environmental\nscreening also play a role. For Milky Way-size galaxies, we find that a model\nwith $|f_{R0}|=10^{-7}$ results in rotation curves that are indistinguishable\nfrom $\\Lambda$CDM, while for $|f_{R0}| \\geq 2 \\times 10^{-6}$ the simulated\ngalaxies are entirely unscreened, violating Solar System constraints. For\nintermediate values, distinct upturns are present. With a careful statistical\nanalysis of existing samples of observed rotation curves, including lower mass\nobjects, constraints on $f(R)$ gravity with a sensitivity down to\n$|f_{R0}|\\sim10^{-7}$ should be possible. \n\n"}
{"id": "1805.12562", "contents": "Title: Dark Matter Search Results from a One Tonne$\\times$Year Exposure of\n  XENON1T Abstract: We report on a search for Weakly Interacting Massive Particles (WIMPs) using\n278.8 days of data collected with the XENON1T experiment at LNGS. XENON1T\nutilizes a liquid xenon time projection chamber with a fiducial mass of $(1.30\n\\pm 0.01)$ t, resulting in a 1.0 t$\\times$yr exposure. The energy region of\ninterest, [1.4, 10.6] $\\mathrm{keV_{ee}}$ ([4.9, 40.9] $\\mathrm{keV_{nr}}$),\nexhibits an ultra-low electron recoil background rate of $(82\\substack{+5 \\\\\n-3}\\textrm{ (sys)}\\pm3\\textrm{ (stat)})$\nevents/$(\\mathrm{t}\\times\\mathrm{yr}\\times\\mathrm{keV_{ee}})$. No significant\nexcess over background is found and a profile likelihood analysis parameterized\nin spatial and energy dimensions excludes new parameter space for the\nWIMP-nucleon spin-independent elastic scatter cross-section for WIMP masses\nabove 6 GeV/c${}^2$, with a minimum of $4.1\\times10^{-47}$ cm$^2$ at 30\nGeV/c${}^2$ and 90% confidence level. \n\n"}
{"id": "1806.00596", "contents": "Title: Random integral matrices: universality of surjectivity and the cokernel Abstract: For a random matrix of entries sampled independently from a fairly general\ndistribution in Z we study the probability that the cokernel is isomorphic to a\ngiven finite abelian group, or when it is cyclic. This includes the probability\nthat the linear map between the integer lattices given by the matrix is\nsurjective. We show that these statistics are asymptotically universal (as the\nsize of the matrix goes to infinity), given by precise formulas involving zeta\nvalues, and agree with distributions defined by Cohen and Lenstra, even when\nthe distribution of matrix entries is very distorted. Our method is robust and\nworks for Laplacians of random digraphs and sparse matrices with the\nprobability of an entry non-zero only n^{-1+epsilon}. \n\n"}
{"id": "1806.01718", "contents": "Title: Anisotropies in the astrophysical gravitational-wave background:\n  Predictions for the detection of compact binaries by LIGO and Virgo Abstract: We develop a detailed anisotropic model for the astrophysical\ngravitational-wave background, including binary mergers of two stellar-mass\nblack holes, two neutron stars, or one of each, which are expected to be the\nstrongest contributions in the LIGO-Virgo frequency band. The angular spectrum\nof the anisotropies, quantified by the $C_\\ell$ components, is calculated using\ntwo complementary approaches: (i) a simple, closed-form analytical expression,\nand (ii) a detailed numerical study using an all-sky mock light cone galaxy\ncatalogue from the Millennium simulation. The two approaches are in excellent\nagreement at large angular scales, and differ by a factor of order unity at\nsmaller scales. These anisotropies are considerably larger in amplitude than\ne.g. those in the temperature of the cosmic microwave background, confirming\nthat it is important to model these anisotropies, and indicating that this is a\npromising avenue for future theoretical and observational work. \n\n"}
{"id": "1806.01871", "contents": "Title: Statistical properties of paired fixed fields Abstract: The initial conditions of cosmological simulations are commonly drawn from a\nGaussian ensemble. The limited number of modes inside a simulation volume gives\nrise to statistical fluctuations known as \\textit{sample variance}, limiting\nthe accuracy of simulation predictions. Fixed fields offer an alternative\ninitialization strategy; they have the same power spectrum as standard Gaussian\nfields but without intrinsic amplitude scatter at linear order. Paired fixed\nfields consists of two fixed fields with opposite phases that cancel phase\ncorrelations which otherwise induce second-order scatter in the non-linear\npower spectrum. We study the statistical properties of those fields for 19\ndifferent quantities at different redshifts through a large set of 600 N-body\nand 506 state-of-the-art magneto-hydrodynamic simulations covering a wide range\nof scales, mass and spatial resolutions. We find that paired fixed simulations\ndo not introduce a bias on any of the examined quantities. We quantify the\nstatistical improvement brought by these simulations, over standard ones, on\ndifferent power spectra such as matter, halos, CDM, gas, stars, black-holes and\nmagnetic fields, finding that they can reduce their variance by factors as\nlarge as $10^6$. We quantify the improvement achieved by fixing and by pairing,\nshowing that sample variance in some quantities can be highly suppressed by\npairing after fixing. Paired fixed simulations do not change the scatter in\nquantities such as the probability distribution function of matter density, or\nthe halo, void or stellar mass functions. We argue that procedures aiming at\nreducing the sample variance of those quantities are unlikely to work. Our\nresults show that paired fixed simulations do not affect either mean relations\nor scatter of galaxy properties, and suggest that the information embedded in\n1-pt statistics is highly complementary to that in clustering. \n\n"}
{"id": "1806.03738", "contents": "Title: Waveband Luminosity Correlations in Flux-Limited Multiwavelength Data Abstract: We explore the general question of correlations among different waveband\nluminosities in a flux-limited multiband observational data set. Such\ncorrelations, often observed for astronomical sources, may either be intrinsic\nor induced by the redshift evolution of the luminosities and the data\ntruncation due to the flux limits. We first address this question analytically.\nWe then use simulated flux-limited data with three different known intrinsic\nluminosity correlations, and prescribed luminosity functions and evolution\nsimilar to the ones expected for quasars. We explore how the intrinsic nature\nof luminosity correlations can be deduced, including exploring the efficacy of\npartial correlation analysis with redshift binning in determining whether\nluminosity correlations are intrinsic and finding the form of the intrinsic\ncorrelation. By applying methods that we have developed in recent works, we\nshow that we can recover the true cosmological evolution of the luminosity\nfunctions and the intrinsic correlations between the luminosities. Finally, we\ndemonstrate the methods for determining intrinsic luminosity correlations on\nactual observed samples of quasars with mid-infrared, radio, and optical fluxes\nand redshifts, finding that the luminosity-luminosity correlation is\nsignificantly stronger between mid-infrared and optical than that between radio\nand optical luminosities, supporting the canonical jet-launching and heating\nmodel of active galaxies. \n\n"}
{"id": "1806.04268", "contents": "Title: p-wave Superfluid Phases of Fermi Molecules in a Bilayer Lattice Array Abstract: We investigate the emergence of superfluid p=p_x+ip_y phases in an ultracold\ngas of dipolar Fermi molecules lying in two parallel square lattices in 2D. As\nshown by a two body study, dipole moments oriented in opposite directions in\neach layer is the key ingredient in our mean field analysis from which\nunconventional superfluidity is predicted. The T=0 phase diagram summarizes our\nfindings: Stable and metastable superfluid phases appear as a function of the\ndipole-dipole interaction coupling parameter. A first order phase transition,\nand thus a mixture of superfluid phases at different densities, is revealed\nfrom the coexistence curves in the metastable region. Our model predicts that\nthese superfluid phases can be observed experimentally at 0.6 nK in molecules\nof NaK confined in optical lattices of size a =532nm \n\n"}
{"id": "1806.05991", "contents": "Title: Searching for Dark Matter with Paleo-Detectors Abstract: A large experimental program is underway to extend the sensitivity of direct\ndetection experiments, searching for interaction of Dark Matter with nuclei,\ndown to the neutrino floor. However, such experiments are becoming increasingly\ndifficult and costly due to the large target masses and exquisite background\nrejection needed for the necessary improvements in sensitivity. We investigate\nan alternative approach to the detection of Dark Matter-nucleon interactions:\nSearching for the persistent traces left by Dark Matter scattering in ancient\nminerals obtained from much deeper than current underground laboratories. We\nestimate the sensitivity of paleo-detectors, which extends far beyond current\nupper limits for a wide range of Dark Matter masses. The sensitivity of our\nproposal also far exceeds the upper limits set by Snowden-Ifft et al. more than\nthree decades ago using ancient Mica in an approach similar to paleo-detectors. \n\n"}
{"id": "1806.06185", "contents": "Title: EdgeChain: An Edge-IoT Framework and Prototype Based on Blockchain and\n  Smart Contracts Abstract: The emerging Internet of Things (IoT) is facing significant scalability and\nsecurity challenges. On the one hand, IoT devices are \"weak\" and need external\nassistance. Edge computing provides a promising direction addressing the\ndeficiency of centralized cloud computing in scaling massive number of devices.\nOn the other hand, IoT devices are also relatively \"vulnerable\" facing\nmalicious hackers due to resource constraints. The emerging blockchain and\nsmart contracts technologies bring a series of new security features for IoT\nand edge computing. In this paper, to address the challenges, we design and\nprototype an edge-IoT framework named \"EdgeChain\" based on blockchain and smart\ncontracts. The core idea is to integrate a permissioned blockchain and the\ninternal currency or \"coin\" system to link the edge cloud resource pool with\neach IoT device' account and resource usage, and hence behavior of the IoT\ndevices. EdgeChain uses a credit-based resource management system to control\nhow much resource IoT devices can obtain from edge servers, based on\npre-defined rules on priority, application types and past behaviors. Smart\ncontracts are used to enforce the rules and policies to regulate the IoT device\nbehavior in a non-deniable and automated manner. All the IoT activities and\ntransactions are recorded into blockchain for secure data logging and auditing.\nWe implement an EdgeChain prototype and conduct extensive experiments to\nevaluate the ideas. The results show that while gaining the security benefits\nof blockchain and smart contracts, the cost of integrating them into EdgeChain\nis within a reasonable and acceptable range. \n\n"}
{"id": "1806.07043", "contents": "Title: Production Rate Measurement of Tritium and Other Cosmogenic Isotopes in\n  Germanium with CDMSlite Abstract: Future direct searches for low-mass dark matter particles with germanium\ndetectors, such as SuperCDMS SNOLAB, are expected to be limited by backgrounds\nfrom radioactive isotopes activated by cosmogenic radiation inside the\ngermanium. There are limited experimental data available to constrain\nproduction rates and a large spread of theoretical predictions. We examine the\ncalculation of expected production rates, and analyze data from the second run\nof the CDMS low ionization threshold experiment (CDMSlite) to estimate the\nrates for several isotopes. We model the measured CDMSlite spectrum and fit for\ncontributions from tritium and other isotopes. Using the knowledge of the\ndetector history, these results are converted to cosmogenic production rates at\nsea level. The production rates in atoms/(kg$\\cdot$day) are 74$\\pm$9 for $^3$H,\n1.5$\\pm$0.7 for $^{55}$Fe, 17$\\pm$5 for $^{65}$Zn, and 30$\\pm$18 for $^{68}$Ge. \n\n"}
{"id": "1806.08300", "contents": "Title: A precise extragalactic test of General Relativity Abstract: Einstein's theory of gravity, General Relativity, has been precisely tested\non Solar System scales, but the long-range nature of gravity is still poorly\nconstrained. The nearby strong gravitational lens, ESO 325-G004, provides a\nlaboratory to probe the weak-field regime of gravity and measure the spatial\ncurvature generated per unit mass, $\\gamma$. By reconstructing the observed\nlight profile of the lensed arcs and the observed spatially resolved stellar\nkinematics with a single self-consistent model, we conclude that $\\gamma = 0.97\n\\pm 0.09$ at 68% confidence. Our result is consistent with the prediction of 1\nfrom General Relativity and provides a strong extragalactic constraint on the\nweak-field metric of gravity. \n\n"}
{"id": "1806.09693", "contents": "Title: Superluminal motion of a relativistic jet in the neutron star merger\n  GW170817 Abstract: The binary neutron star merger GW170817 was accompanied by radiation across\nthe electromagnetic spectrum and localized to the galaxy NGC 4993 at a distance\nof 41+/-3 Mpc. The radio and X-ray afterglows of GW170817 exhibited delayed\nonset, a gradual rise in the emission with time as t^0.8, a peak at about 150\ndays post-merger, followed by a relatively rapid decline. To date, various\nmodels have been proposed to explain the afterglow emission, including a\nchoked-jet cocoon and a successful-jet cocoon (a.k.a. structured jet). However,\nthe observational data have remained inconclusive as to whether GW170817\nlaunched a successful relativistic jet. Here we show, through Very Long\nBaseline Interferometry, that the compact radio source associated with GW170817\nexhibits superluminal motion between two epochs at 75 and 230 days post-merger.\nThis measurement breaks the degeneracy between the models and indicates that,\nwhile the early-time radio emission was powered by a wider-angle outflow\n(cocoon), the late-time emission was most likely dominated by an energetic and\nnarrowly-collimated jet, with an opening angle of <5 degrees, and observed from\na viewing angle of about 20 degrees. The imaging of a collimated relativistic\noutflow emerging from GW170817 adds substantial weight to the growing evidence\nlinking binary neutron star mergers and short gamma-ray bursts. \n\n"}
{"id": "1806.10112", "contents": "Title: A model calculation of double parton distribution functions of the pion Abstract: Two-parton correlations in the pion are investigated in terms of double\nparton distribution functions. A Poincar\\'e covariant Light-Front framework has\nbeen adopted. As non perturbative input, the pion wave function obtained within\nthe so-called soft-wall AdS/QCD model has been used. Results show how novel\ndynamical information on the structure of the pion, not accessible through\none-body parton distribution, are encoded in double parton distribution\nfunctions. \n\n"}
{"id": "1806.10122", "contents": "Title: Testing General Relativity in Cosmology Abstract: We review recent developments and results in testing general relativity (GR)\nat cosmological scales. The subject has witnessed rapid growth during the last\ntwo decades with the aim of addressing the question of cosmic acceleration and\nthe dark energy associated with it. However, with the advent of precision\ncosmology, it has also become a well-motivated endeavor by itself to test\ngravitational physics at cosmic scales. We overview cosmological probes of\ngravity, formalisms and parameterizations for testing deviations from GR at\ncosmological scales, selected modified gravity (MG) theories, gravitational\nscreening mechanisms, and computer codes developed for these tests. We then\nprovide summaries of recent cosmological constraints on MG parameters and\nselected MG models. We supplement these cosmological constraints with a summary\nof implications from the recent binary neutron star merger event. Next, we\nsummarize some results on MG parameter forecasts with and without astrophysical\nsystematics that will dominate the uncertainties. The review aims at providing\nan overall picture of the subject and an entry point to students and\nresearchers interested in joining the field. It can also serve as a quick\nreference to recent results and constraints on testing gravity at cosmological\nscales. \n\n"}
{"id": "1806.10900", "contents": "Title: A cosmology-independent calibration of type Ia supernovae data Abstract: Recently, the common methodology used to transform type Ia supernovae (SNe\nIa) into genuine standard candles has been suffering criticism. Indeed, it\nassumes a particular cosmological model (namely the flat $\\Lambda$CDM) to\ncalibrate the standardisation corrections parameters, i.e. the dependency of\nthe supernova peak absolute magnitude on its colour, post-maximum decline rate\nand host galaxy mass. As a result, this assumption could make the data\ncompliant to the assumed cosmology and thus nullify all works previously\nconducted on model comparison. In this work, we verify the viability of these\nhypotheses by developing a cosmology-independent approach to standardise SNe Ia\ndata from the recent JLA compilation. Our resulting corrections turn out to be\nvery close to the $\\Lambda$CDM-based corrections. Therefore, even if a\n$\\Lambda$CDM-based calibration is questionable from a theoretical point of\nview, the potential compliance of SNe Ia data does not happen in practice for\nthe JLA compilation. Previous works of model comparison based on these data do\nnot have to be called into question. However, as this cosmology-independent\nstandardisation method has the same degree of complexity than the\nmodel-dependent one, it is worth using it in future works, especially if\nsmaller samples are considered, such as the superluminous type Ic supernovae. \n\n"}
{"id": "1807.03824", "contents": "Title: Detecting Intermediate-Mass Ratio Inspirals From The Ground And Space Abstract: The detection of a gravitational capture of a stellar-mass compact object by\na massive black hole (MBH) will allow us to test gravity in the strong regime.\nThese sources form via two-body relaxation, by exchanging energy and angular\nmomentum, and inspiral in a slow, progressive way down to the final merger. The\nrange of frequencies is localised in the range of millihertz in the case of MBH\nof masses $\\sim 10^6\\,M_{\\odot}$, i.e. that of space-borne gravitational-wave\nobservatories such as LISA. In this article I show that, depending on their\norbital parameters, intermediate-mass ratios (IMRIs) of MBH of masses between a\nhundred and a few thousand have frequencies that make them detectable (i) with\nground-based observatories, or (ii) with both LISA and ground-based ones such\nas advanced LIGO/Virgo and third generation ones, with ET as an example. The\nbinaries have a signal-to-noise ratio large enough to ensure detection. More\nextreme values in their orbital parameters correspond to systems detectable\nonly with ground-based detectors and enter the LIGO/Virgo band in particular in\nmany different harmonics for masses up to some $2000,\\,M_{\\odot}$. I show that\nenvironmental effects are negligible, so that the source should not have this\nkind of complication. The accumulated phase-shift is measurable with LISA and\nET, and for some cases also with LIGO, so that it is possible to recover\ninformation about the eccentricity and formation scenario. For IMRIs with a\ntotal mass $\\lessapprox 2000\\,M_{\\odot}$ and initial eccentricities up to\n$0.999$, LISA can give a warning to ground-based detectors with enough time in\nadvance and seconds of precision. The possibility of detecting IMRIs from the\nground alone or combined with space-borne observatories opens new possibilities\nfor gravitational wave astronomy. \n\n"}
{"id": "1807.05155", "contents": "Title: Limits on Neutrino Lorentz Violation from Multimessenger Observations of\n  TXS 0506+056 Abstract: The observation by the IceCube Collaboration of a high-energy ($E \\gtrsim\n200$ TeV) neutrino from the direction of the blazar TXS 0506+056 and the\ncoincident observations of enhanced $\\gamma$-ray emissions from the same object\nby MAGIC and other experiments can be used to set stringent constraints on\nLorentz violation in the propagation of neutrinos that is linear in the\nneutrino energy: $\\Delta v = - E/M_1$, where $\\Delta v$ is the deviation from\nthe velocity of light, and $M_1$ is an unknown high energy scale to be\nconstrained by experiment. Allowing for a difference in neutrino and photon\npropagation times of $\\sim 10$ days, we find that $M_1 \\gtrsim 3 \\times\n10^{16}$ GeV. This improves on previous limits on linear Lorentz violation in\nneutrino propagation by many orders of magnitude, and the same is true for\nquadratic Lorentz violation. \n\n"}
{"id": "1807.05201", "contents": "Title: Constraints on differential Shapiro delay between neutrinos and photons\n  from IceCube-170922A Abstract: On 22nd September 2017, the IceCube Collaboration detected a neutrino with\nenergy of about 290 TeV from the direction of the gamma-ray blazar TXS\n0506+056, located at a distance of about 1.75 Gpc. During the same time,\nenhanced gamma-ray flaring was also simultaneously observed from multiple\ntelescopes, giving rise to only the second coincident astrophysical\nneutrino/photon observation after SN 1987A. We point out that for this event,\nboth neutrinos and photons encountered a Shapiro delay of about 6300 days along\nthe way from the source. From this delay and the relative time difference\nbetween the neutrino and photon arrival times, one can constrain violations of\nEinstein's Weak Equivalence Principle (WEP) for TeV neutrinos. We constrain\nsuch violations of WEP using the Parameterized Post-Newtonian (PPN) parameter\n$\\gamma$, which is given by $|\\gamma_{\\rm {\\nu}}-\\gamma_{\\rm{EM}}|<5.5 \\times\n10^{-2}$, after assuming time difference of 175 days between neutrino and\nphoton arrival times. \n\n"}
{"id": "1807.06014", "contents": "Title: Astrophysical black holes Abstract: In this chapter, we introduce the concept of a black hole (BH) and recount\nthe initial theoretical predictions. We then review the possible types of BHs\nin nature, from primordial, to stellar-mass, to supermassive BHs. Finally, we\nfocus on the latter category and on their intricate relation with their host\ngalaxies. \n\n"}
{"id": "1807.06243", "contents": "Title: Super-Eddington accretion; flow regimes and conditions in high-z\n  galaxies Abstract: We review and discuss theoretical studies addressing the possibility of gas\naccretion onto black holes occurring at rates exceeding the Eddington limit.\nOur focus is on the applications to the growth of black hole seeds at high\nredshift. We first present the general notion of Super-Eddington accretion, and\nthen summarize the different models and numerical simulations developed to\nstudy such regime. We consider optically thick flows in accretion disks as well\nas in spherically symmetric envelopes, and devote particular attention to the\nwidely adopted model based on the SLIM disk solution. While attractive for its\nsimplicity, the SLIM disk solution is challenged by the latest generation of\nthree-dimensional radiation (magneto)-hydrodynamical simulations, in which\nradiative losses can be an order of magnitude higher, and the mechanisms of\nradiation transport is more complex than straight advection as it takes place\nin a complex turbulent regime. We then discuss the gas supply rate to the\nsub-pc scale accretion disk or envelope from larger scales, revisiting gas\ninflow rates in protogalaxies under various conditions. We conclude that in the\ndense gaseous nuclei of high-z galaxies the conditions necessary for the onset\nof Super Eddington accretion regimes, such as a high optical depth and high gas\nsupply rates from large scales, should be naturally met. Feedback from the\ngrowing BH seed should not alter significantly such conditions according to the\nresults of radiation magneto-hydrodynamical simulations of super-critical flows\nin accretion disks. Furthermore, based on the required nuclear gas inflow rates\nand the tendency of stellar feedback to remove efficiently gas in low mass\nhalos, we argue that super-critical accretion will be more easily achieved in\nrelatively sizable halos, with virial masses $M_{\\rm vir} > 10^{10}$\nM$_{\\odot}$, which become more common at $z < 15$. \n\n"}
{"id": "1807.07113", "contents": "Title: Search for annual and diurnal rate modulations in the LUX experiment Abstract: Various dark matter models predict annual and diurnal modulations of dark\nmatter interaction rates in Earth-based experiments as a result of the Earth's\nmotion in the halo. Observation of such features can provide generic evidence\nfor detection of dark matter interactions. This paper reports a search for both\nannual and diurnal rate modulations in the LUX dark matter experiment using\nover 20 calendar months of data acquired between 2013 and 2016. This search\nfocuses on electron recoil events at low energies, where leptophilic dark\nmatter interactions are expected to occur and where the DAMA experiment has\nobserved a strong rate modulation for over two decades. By using the innermost\nvolume of the LUX detector and developing robust cuts and corrections, we\nobtained a stable event rate of 2.3$\\pm$0.2~cpd/keV$_{\\text{ee}}$/tonne, which\nis among the lowest in all dark matter experiments. No statistically\nsignificant annual modulation was observed in energy windows up to\n26~keV$_{\\text{ee}}$. Between 2 and 6~keV$_{\\text{ee}}$, this analysis\ndemonstrates the most sensitive annual modulation search up to date, with\n9.2$\\sigma$ tension with the DAMA/LIBRA result. We also report no observation\nof diurnal modulations above 0.2~cpd/keV$_{\\text{ee}}$/tonne amplitude between\n2 and 6~keV$_{\\text{ee}}$. \n\n"}
{"id": "1807.10515", "contents": "Title: Galactic magnetic field reconstruction using the polarized diffuse\n  Galactic emission: Formalism and application to $Planck$ data Abstract: The polarized Galactic synchrotron and thermal dust emission constitutes a\nmajor tool in the study of the Galactic magnetic field (GMF) and in\nconstraining its strength and geometry for the regular and turbulent\ncomponents. In this paper, we review the modeling of these two components of\nthe polarized Galactic emission and present our strategy for optimally\nexploiting the currently existing data sets. We investigate a Markov Chain\nMonte Carlo (MCMC) method to constrain the model parameter space through\nmaximum-likelihood analysis, focusing mainly on dust polarized emission.\nRelying on simulations, we demonstrate that our methodology can be used to\nconstrain the regular GMF geometry. Fitting for the reduced Stokes parameters,\nthis reconstruction is only marginally dependent of the accuracy of the\nreconstruction of the Galactic dust grain density distribution. However, the\nreconstruction degrades, apart from the pitch angle, when including a turbulent\ncomponent on the order of the regular one as suggested by current observational\nconstraints. Finally, we applied this methodology to a set of $Planck$\npolarization maps at 353 GHz to obtain the first MCMC based constrains on the\nlarge-scale regular-component of the GMF from the polarized diffuse Galactic\nthermal dust emission. By testing various models of the dust density\ndistribution and of the GMF geometry, we prove that it is possible to infer the\nlarge-scale geometrical properties of the GMF. We obtain coherent\nthree-dimensional (3D) views of the GMF, from which we infer a mean pitch angle\nof 27 degrees with 14 % scatter, which is in agreement with results obtained in\nthe literature from synchrotron emission. \n\n"}
{"id": "1807.11873", "contents": "Title: Redshift inference from the combination of galaxy colors and clustering\n  in a hierarchical Bayesian model Abstract: Powerful current and future cosmological constraints using high precision\nmeasurements of the large-scale structure of galaxies and its weak\ngravitational lensing effects rely on accurate characterization of the redshift\ndistributions of the galaxy samples using only broadband imaging. We present a\nframework for constraining both the redshift probability distributions of\ngalaxy populations and the redshifts of their individual members. We use a\nhierarchical Bayesian model (HBM) which provides full posterior distributions\non those redshift probability distributions, and, for the first time, we show\nhow to combine survey photometry of single galaxies and the information\ncontained in the galaxy clustering against a well-characterized tracer\npopulation in a robust way. One critical approximation turns the HBM into a\nsystem amenable to efficient Gibbs sampling. We show that in the absence of\nphotometric information, this method reduces to commonly used clustering\nredshift estimators. Using a simple model system, we show how the incorporation\nof clustering information with photo-$z$'s tightens redshift posteriors, and\ncan overcome biases or gaps in the coverage of a spectroscopic prior. The\nmethod enables the full propagation of redshift uncertainties into cosmological\nanalyses, and uses all the information at hand to reduce those uncertainties\nand associated potential biases. \n\n"}
{"id": "1808.01096", "contents": "Title: Existence of coated inclusions of general shape weakly neutral to\n  multiple fields in two dimensions Abstract: A two dimensional inclusion of core-shell structure is neutral to multiple\nuniform fields if and only if the core and the shell are concentric disks,\nprovided that the conductivity of the matrix is isotropic. An inclusion is said\nto be neutral if upon its insertion the uniform field is not perturbed at all.\nIn this paper we consider inclusions of core-shell structure of general shape\nwhich are weakly neutral to multiple uniform fields. An inclusion is said to be\nweakly neutral if the field perturbation is mild. We show, by an implicit\nfunction theorem, that if the core is a small perturbation of a disk then we\ncan coat it by a shell so that the resulting structure becomes weakly neutral\nto multiple uniform fields. \n\n"}
{"id": "1808.04379", "contents": "Title: COSMOS-DASH: The Evolution of the Galaxy Size-Mass Relation Since z~3\n  from new Wide Field WFC3 Imaging Combined with CANDELS/3DHST Abstract: We present COSMOS-Drift And SHift (DASH), a Hubble Space Telescope WFC3\nimaging survey of the COSMOS field in the H_160 filter. The survey comprises\n456 individual WFC3 pointings corresponding to an area of 0.49 deg^2 (0.66\ndeg^2 when including archival data) and reaches a 5 point-source limit of H_160\n=25.1 (0\".3 aperture). COSMOS-DASH is the widest HST/WFC3 imaging survey in\nH_160 filter, tripling the extragalactic survey area in the near-infrared at\nHST resolution. We make the reduced H_160 mosaic available to the community. We\nuse this dataset to measure the sizes of 162 galaxies with log(M_star/M_sun) >\n11.3 at 1.5 < z < 3.0, and augment this sample with 748 galaxies at 0.1 < z <\n1.5 using archival ACS imaging. We find that the median size of galaxies in\nthis mass range changes with redshift as r_eff = (10.4+/-0.4)(1\n+z)^(0.65+/-0.05) kpc. Separating the galaxies into star forming and quiescent\ngalaxies using their restframe U-V and V-J colors, we find no statistical\ndifference between the median sizes of the most massive star-forming and\nquiescent galaxies at z = 2.5: they are 4.9+/-0.9 kpc and 4.3 +/-0.3 kpc\nrespectively. However, we do find a significant difference in the S`ersic index\nbetween the two samples, such that massive quiescent galaxies have higher\ncentral densities than star forming galaxies. We extend the size-mass analysis\nto lower masses by combining it with the 3D-HST/CANDELS sample of van der Wel\net al. (2014), and derive empirical relations between size, mass, and redshift.\nFitting a relation of the form r_eff = A m_star^a, m_star = M_star/5x10^10\nM_sun and r_eff in kpc, we find log A = -0.25 log (1 + z) + 0.79 and a = -0.13\nlog(1 + z) + 0.27. We also provide relations for the subsamples of star forming\nand quiescent galaxies. Our results confirm previous studies that were based on\nsmaller samples or ground-based imaging. \n\n"}
{"id": "1808.04728", "contents": "Title: CosmoFlow: Using Deep Learning to Learn the Universe at Scale Abstract: Deep learning is a promising tool to determine the physical model that\ndescribes our universe. To handle the considerable computational cost of this\nproblem, we present CosmoFlow: a highly scalable deep learning application\nbuilt on top of the TensorFlow framework. CosmoFlow uses efficient\nimplementations of 3D convolution and pooling primitives, together with\nimprovements in threading for many element-wise operations, to improve training\nperformance on Intel(C) Xeon Phi(TM) processors. We also utilize the Cray PE\nMachine Learning Plugin for efficient scaling to multiple nodes. We demonstrate\nfully synchronous data-parallel training on 8192 nodes of Cori with 77%\nparallel efficiency, achieving 3.5 Pflop/s sustained performance. To our\nknowledge, this is the first large-scale science application of the TensorFlow\nframework at supercomputer scale with fully-synchronous training. These\nenhancements enable us to process large 3D dark matter distribution and predict\nthe cosmological parameters $\\Omega_M$, $\\sigma_8$ and n$_s$ with unprecedented\naccuracy. \n\n"}
{"id": "1808.05886", "contents": "Title: The lensing time delay between gravitational and electromagnetic waves Abstract: The recent detection of gravitational waves (GWs) and electromagnetic (EM)\nwaves originating from the same source marks the start of a new multi-messenger\nera in astronomy. The arrival time difference between the GW and EM signal can\nbe used to constrain differences in their propagation speed, and thus\ngravitational theories. We study to what extent a non-zero time delay can be\nexplained by gravitational lensing when the line of sight to the source passes\nnear a massive object. For galaxy scale lenses, this delay becomes relevant for\nGWs with frequencies between $10^{-6}$ and $10^{-9}$ Hz, sourced by super\nmassive binary black-holes. In addition to GWs detectable by Pulsar Timing\nArrays (PTAs), we expect to find also a unique and recognizable EM signal. We\nshow that the delay between the GW and EM signal can be of the order of days to\nmonths; within reach of future observations. The effect may become important in\nfuture multi-messenger astronomy probing of gravitational propagation and\ninteractions. \n\n"}
{"id": "1808.06615", "contents": "Title: Beyond the classical distance-redshift test: cross-correlating\n  redshift-free standard candles and sirens with redshift surveys Abstract: LSST will supply up to $10^6$ supernovae (SNe) to constrain dark energy\nthrough the distance-redshift ($D_L$-$z$) test. Obtaining spectroscopic SN\nredshifts (spec-$z$s) is unfeasible; alternatives are suboptimal and may be\nbiased. We propose a powerful multi-tracer generalization of the\nAlcock-Paczynski test that pairs redshift-free distance tracers and an\noverlapping galaxy redshift survey. Cross-correlating $5\\times 10^4$\nredshift-free SNe with DESI or Euclid outperforms the classical $D_L$-$z$ test\nwith spec-$z$s for all SN. Our method also applies to gravitational wave sirens\nor any redshift-free distance tracer. \n\n"}
{"id": "1808.07496", "contents": "Title: Cosmological inference from Bayesian forward modelling of deep galaxy\n  redshift surveys Abstract: We present a large-scale Bayesian inference framework to constrain\ncosmological parameters using galaxy redshift surveys, via an application of\nthe Alcock-Paczy\\'nski (AP) test. Our physical model of the non-linearly\nevolved density field, as probed by galaxy surveys, employs Lagrangian\nperturbation theory (LPT) to connect Gaussian initial conditions to the final\ndensity field, followed by a coordinate transformation to obtain the redshift\nspace representation for comparison with data. We generate realizations of\nprimordial and present-day matter fluctuations given a set of observations.\nThis hierarchical approach encodes a novel AP test, extracting several orders\nof magnitude more information from the cosmological expansion compared to\nclassical approaches, to infer cosmological parameters and jointly reconstruct\nthe underlying 3D dark matter density field. The novelty of this AP test lies\nin constraining the comoving-redshift transformation to infer the appropriate\ncosmology which yields isotropic correlations of the galaxy density field, with\nthe underlying assumption relying purely on the cosmological principle. Such an\nAP test does not rely explicitly on modelling the full statistics of the field.\nWe verify in depth via simulations that this renders our test robust to model\nmisspecification. This leads to another crucial advantage, namely that the\ncosmological parameters exhibit extremely weak dependence on the currently\nunresolved phenomenon of galaxy bias, thereby circumventing a potentially key\nlimitation. This is consequently among the first methods to extract a large\nfraction of information from statistics other than that of direct density\ncontrast correlations, without being sensitive to the amplitude of density\nfluctuations. We perform several statistical efficiency and consistency tests\non a mock galaxy catalogue, using the SDSS-III survey as template. \n\n"}
{"id": "1808.09331", "contents": "Title: Model-independent Test of the Cosmic Distance Duality Relation Abstract: A validation of the cosmic distance duality (CDD) relation, eta(z)=(1+z)^2\nd_A(z)/d_L(z)=1, coupling the luminosity (d_L) and angular-diameter (d_A)\ndistances, is crucial because its violation would require exotic new physics.\nWe present a model-independent test of the CDD, based on strong lensing and a\nreconstruction of the HII galaxy Hubble diagram using Gaussian Processes, to\nconfirm the validity of the CDD at a very high level of confidence. Using\nparameterizations eta(z) = 1 + eta_0 z and eta(z) = 1 + eta_1 z + eta_2 z^2,\nour best-fit results are eta_0 = 0.0147^{+0.056}_{-0.066}, and eta_1 =\n0.1091^{+0.1680}_{-0.1568} and eta_2 = -0.0603^{+0.0999}_{-0.0988},\nrespectively. In spite of these strong constraints, however, we also point out\nthat the analysis of strong lensing using a simplified single isothermal sphere\n(SIS) model for the lens produces some irreducible scatter in the inferred CDD\ndata. The use of an extended SIS approximation, with a power-law density\nstructure, yields very similar results, but does not lessen the scatter due to\nits larger number of free parameters, which weakens the best-fit constraints.\nFuture work with these strong lenses should therefore be based on more detailed\nray-tracing calculations to determine the mass distribution more precisely. \n\n"}
{"id": "1808.09973", "contents": "Title: CGM properties in VELA and NIHAO simulations; the OVI ionization\n  mechanism: dependence on redshift, halo mass and radius Abstract: We study the components of cool and warm/hot gas in the circumgalactic medium\n(CGM) of simulated galaxies and address the relative production of OVI by\nphotoionization versus collisional ionization, as a function of halo mass,\nredshift, and distance from the galaxy halo center. This is done utilizing two\ndifferent suites of zoom-in hydro-cosmological simulations, VELA (6 halos;\n$z>1$) and NIHAO (18 halos; to $z=0$), which provide a broad theoretical basis\nbecause they use different codes and physical recipes for star formation and\nfeedback. In all halos studied in this work, we find that collisional\nionization by thermal electrons dominates at high redshift, while\nphotoionization of cool or warm gas by the metagalactic radiation takes over\nnear $z\\sim2$. In halos of $\\sim 10^{12}M_{\\odot}$ and above, collisions become\nimportant again at $z<0.5$, while photoionization remains significant down to\n$z=0$ for less massive halos. In halos with $M_{\\textrm\nv}>3\\times10^{11}~M_{\\odot}$, at $z\\sim 0$ most of the photoionized OVI is in a\nwarm, not cool, gas phase ($T\\lesssim 3\\times 10^5$~K). We also find that\ncollisions are dominant in the central regions of halos, while photoionization\nis more significant at the outskirts, around $R_{\\textrm v}$, even in massive\nhalos. This too may be explained by the presence of warm gas or, in lower mass\nhalos, by cool gas inflows. \n\n"}
{"id": "1809.03806", "contents": "Title: Remark on the open string pair production enhancement Abstract: Recent studies by one of the present authors along with his collaborators in\n[1-4] show that there exist the so-called open string pair production for a\npossible simplest system of two Dp branes, placed parallel at a separation and\nwith each carrying different electric flux, in Type II superstring theories.\nFurther this pair production can be greatly enhanced when a magnetic flux,\nsharing no common field strength index with the electric one, is added,\nimplying then $p \\ge 3$. Given this, one may wonder if further enhancement can\nbe achieved by adding more magnetic flux(es) in a similar fashion. In this\npaper, we explore this possibility. It turns out that adding more such magnetic\nflux diminishes rather than enhances the pair production rate. This actually\nimplies that the largest enhancement occurs at $p = 3$ when the same realistic\nelectric and magnetic fluxes are applied for all $p \\ge 3$. Curiously one of D3\nbranes may be our own world and if so, the enhancement gives a possible\nopportunity to detect the pair production, therefore to test the underlying\nstring theories. \n\n"}
{"id": "1809.09728", "contents": "Title: Mitigating the Effects of Antenna-to-Antenna Variation on\n  Redundant-Baseline Calibration for 21 cm Cosmology Abstract: The separation of cosmological signal from astrophysical foregrounds is a\nfundamental challenge for any effort to probe the evolution of neutral hydrogen\nduring the Cosmic Dawn and epoch of reionization (EoR) using the 21 cm\nhyperfine transition. Foreground separation is made possible by their intrinsic\nspectral smoothness, making them distinguishable from spectrally complex\ncosmological signal even though they are ~5 orders of magnitude brighter.\nPrecisely calibrated radio interferometers are essential to maintaining the\nsmoothness and thus separability of the foregrounds. One powerful calibration\nstrategy is to use redundant measurements between pairs of antennas with the\nsame physical separation in order to solve for each antenna's spectral response\nwithout reference to a sky model. This strategy is being employed by the\nHydrogen Epoch of Reionization Array (HERA), a large radio telescope in South\nAfrica that is now observing while being built out to 350 14-m dishes. However,\nthe deviations from perfect redundancy inherent in any real radio telescope\ncomplicate the calibration problem. Using simulations of HERA, we show how\ncalibration with antenna-to-antenna variations in dish construction and\nplacement generally lead to spectral structure in otherwise smooth foregrounds\nthat significantly reduces the number of cosmological modes available to a 21\ncm measurement. However, we also show that this effect can be largely\neliminated by a modified redundant-baseline calibration strategy that relies\npredominantly on short baselines. \n\n"}
{"id": "1810.01245", "contents": "Title: An interior penalty discontinuous Galerkin approach for 3D\n  incompressible Navier--Stokes equation for permeability estimation of porous\n  media Abstract: Permeability estimation of porous media from direct solving Navier--Stokes\nequation has a wide spectrum of applications in petroleum industry. In this\npaper, we utilize a pressure-correction projection algorithm in conjunction\nwith the interior penalty discontinuous Galerkin scheme for space\ndiscretization to build an incompressible Navier--Stokes simulator and to use\nthis simulator to calculate permeability of real rock sample. The proposed\nmethod is accurate, numerically robust, and exhibits the potential for tackling\nrealistic problems. \n\n"}
{"id": "1810.01420", "contents": "Title: Boson Star from Repulsive Light Scalars and Gravitational Waves Abstract: We study properties of boson stars consisting of ultra-light scalar dark\nmatter with repulsive self-interactions. We investigate the origin of the\nmaximum mass of spherically symmetric stable stars which emerges only when\nsolving the full equations of motion in curved space-time, but not when solving\nthe approximated Schr\\\"odinger-Newton equations. When the repulsion is weak,\nthe backreaction of the curvature on the scalars acts as an additional source\nof attraction and can overcome the repulsion, resulting in a maximum star mass\nand compactness. We also point out that the potential in a UV completed\nparticle physics model of light scalar dark matter is generally more\ncomplicated than the widely used $\\phi^4$ interaction. Additional interactions\nbeyond $\\phi^4$ in the potential can dramatically change the properties of\nboson stars as well as modify the prospect of LIGO gravitational wave detection\nfor binary mergers of boson stars. \n\n"}
{"id": "1810.02369", "contents": "Title: Pulsar-timing arrays, astrometry, and gravitational waves Abstract: We discuss the theory of pulsar-timing and astrometry probes of a stochastic\ngravitational-wave background with a recently developed\n\"total-angular-momentum\" (TAM) formalism for cosmological perturbations. We\nreview the formalism, emphasizing in particular the features relevant for this\nwork and describe the observables we consider (i.e. the pulsar redshift and\nstellar angular displacement). Using the TAM approach, we calculate the angular\npower spectra for the observables and from them derive angular auto- and\ncross-correlation functions. We provide the full set of power spectra and\ncorrelation functions not only for the standard transverse-traceless\npropagating degrees of freedom in general relativity, but also for the four\nadditional non-Einsteinian polarizations that may arise in alternative-gravity\ntheories. We discuss how pulsar-timing and astrometry surveys can complement\nand serve as cross checks to one another and comment on the importance of\ntesting the chirality of the gravitational-wave background as a tool to\nunderstand the nature of its sources. A simple rederivation of the power\nspectra from the plane-wave formalism is provided in an Appendix. \n\n"}
{"id": "1810.02680", "contents": "Title: Fundamental Physics with the Square Kilometre Array Abstract: The Square Kilometre Array (SKA) is a planned large radio interferometer\ndesigned to operate over a wide range of frequencies, and with an order of\nmagnitude greater sensitivity and survey speed than any current radio\ntelescope. The SKA will address many important topics in astronomy, ranging\nfrom planet formation to distant galaxies. However, in this work, we consider\nthe perspective of the SKA as a facility for studying physics. We review four\nareas in which the SKA is expected to make major contributions to our\nunderstanding of fundamental physics: cosmic dawn and reionisation; gravity and\ngravitational radiation; cosmology and dark energy; and dark matter and\nastroparticle physics. These discussions demonstrate that the SKA will be a\nspectacular physics machine, which will provide many new breakthroughs and\nnovel insights on matter, energy and spacetime. \n\n"}
{"id": "1810.02916", "contents": "Title: A High-Fidelity Realization of the Euclid Code Comparison $N$-body\n  Simulation with Abacus Abstract: We present a high-fidelity realization of the cosmological $N$-body\nsimulation from the Schneider et al. (2016) code comparison project. The\nsimulation was performed with our Abacus $N$-body code, which offers high force\naccuracy, high performance, and minimal particle integration errors. The\nsimulation consists of $2048^3$ particles in a $500\\ h^{-1}\\mathrm{Mpc}$ box,\nfor a particle mass of $1.2\\times 10^9\\ h^{-1}\\mathrm{M}_\\odot$ with $10\\\nh^{-1}\\mathrm{kpc}$ spline softening. Abacus executed 1052 global time steps to\n$z=0$ in 107 hours on one dual-Xeon, dual-GPU node, for a mean rate of 23\nmillion particles per second per step. We find Abacus is in good agreement with\nRamses and Pkdgrav3 and less so with Gadget3. We validate our choice of time\nstep by halving the step size and find sub-percent differences in the power\nspectrum and 2PCF at nearly all measured scales, with $<0.3\\%$ errors at $k<10\\\n\\mathrm{Mpc}^{-1}h$. On large scales, Abacus reproduces linear theory better\nthan $0.01\\%$. Simulation snapshots are available at\nhttp://nbody.rc.fas.harvard.edu/public/S2016 . \n\n"}
{"id": "1810.03227", "contents": "Title: Parkes Pulsar Timing Array constraints on ultralight scalar-field dark\n  matter Abstract: It is widely accepted that dark matter contributes about a quarter of the\ncritical mass-energy density in our Universe. The nature of dark matter is\ncurrently unknown, with the mass of possible constituents spanning nearly one\nhundred orders of magnitude. The ultralight scalar field dark matter,\nconsisting of extremely light bosons with $m \\sim 10^{-22}$ eV and often called\n\"fuzzy\" dark matter, provides intriguing solutions to some challenges at\nsub-Galactic scales for the standard cold dark matter model. As shown by\nKhmelnitsky and Rubakov, such a scalar field in the Galaxy would produce an\noscillating gravitational potential with nanohertz frequencies, resulting in\nperiodic variations in the times of arrival of radio pulses from pulsars. The\nParkes Pulsar Timing Array (PPTA) has been monitoring 20 millisecond pulsars at\ntwo to three weeks intervals for more than a decade. In addition to the\ndetection of nanohertz gravitational waves, PPTA offers the opportunity for\ndirect searches for fuzzy dark matter in an astrophysically feasible range of\nmasses. We analyze the latest PPTA data set which includes timing observations\nfor 26 pulsars made between 2004 and 2016. We perform a search in this data set\nfor evidence of ultralight dark matter in the Galaxy using Bayesian and\nFrequentist methods. No statistically significant detection has been made. We\ntherefore place upper limits on the local dark matter density. Our limits,\nimproving on previous searches by a factor of two to five, constrain the dark\nmatter density of ultralight bosons with $m \\leq 10^{-23}$ eV to be below\n$6\\,\\text{GeV}\\,\\text{cm}^{-3}$ with 95\\% confidence in the Earth neighborhood.\nFinally, we discuss the prospect of probing the astrophysically favored mass\nrange $m \\gtrsim 10^{-22}$ eV with next-generation pulsar timing facilities. \n\n"}
{"id": "1810.04960", "contents": "Title: Testing the standard model of cosmology with the SKA: the cosmic radio\n  dipole Abstract: The dipole anisotropy seen in the {cosmic microwave background radiation} is\ninterpreted as due to our peculiar motion. The Cosmological Principle implies\nthat this cosmic dipole signal should also be present, with the same direction,\nin the large-scale distribution of matter. Measurement of the cosmic matter\ndipole constitutes a key test of the standard cosmological model. Current\nmeasurements of this dipole are barely above the expected noise and unable to\nprovide a robust test. Upcoming radio continuum surveys with the SKA should be\nable to detect the dipole at high signal to noise. We simulate number count\nmaps for SKA survey specifications in Phases 1 and 2, including all relevant\neffects. Nonlinear effects from local large-scale structure contaminate the\n{cosmic (kinematic)} dipole signal, and we find that removal of radio sources\nat low redshift ($z\\lesssim 0.5$) leads to significantly improved constraints.\nWe forecast that the SKA could determine the kinematic dipole direction in\nGalactic coordinates with an error of $(\\Delta l,\\Delta\nb)\\sim(9^\\circ,5^\\circ)$ to $(8^\\circ, 4^\\circ)$, depending on the sensitivity.\nThe predicted errors on the relative speed are $\\sim 10\\%$. These measurements\nwould significantly reduce the present uncertainty on the direction of the\nradio dipole, and thus enable the first critical test of consistency between\nthe matter and CMB dipoles. \n\n"}
{"id": "1810.07546", "contents": "Title: Science with an ngVLA. Cold gas in High-z Galaxies: The molecular gas\n  budget Abstract: The goal of this science case is to accurately pin down the molecular gas\ncontent of high redshift galaxies. By targeting the CO ground transition, we\ncircumvent uncertainties related to CO excitation. The ngVLA can observe the\nCO(1-0) line at virtually any $z>1.5$, thus exposing the evolution of gaseous\nreservoirs from the earliest epochs down to the peak of the cosmic history of\nstar formation. The order-of-magnitude improvement in the number of CO\ndetections with respect to state-of-the-art observational campaigns will\nprovide a unique insight on the evolution of galaxies through cosmic time. \n\n"}
{"id": "1810.07547", "contents": "Title: Science with an ngVLA. Cold gas in High-z Galaxies: The dense ISM Abstract: The goal of this science case is to study physical conditions of the\ninterstellar medium (ISM) in distant galaxies. In particular, its densest\ncomponent is associated with the inner cores of clouds -- this is where star\nformation takes place. Carbon monoxide is usually used to trace molecular gas\nemission; however, its transitions are practically opaque, thus preventing\nastronomers from piercing through the clouds, into the deepest layers that are\nmost intimately connected with the formation of stars. Other dense gas tracers\nare required, although they are typically too faint and/or at too low\nfrequencies to be effectively observed in high redshift galaxies. The ngVLA\nwill offer for the first time the sensitivity at radio frequencies that is\nneeded to target [CI]$_{1-0}$ (at $z>5$), as well as the ground transitions of\ndense gas tracers of the ISM such as HCN, HNC, HCO+ (at various redshifts\n$z>1$), beyond the tip of the iceberg of the hyper-luminous sources that could\nbe studied up to now. These new tools will critically contribute to our\nunderstanding of the intimate interplay between gas clouds and star formation\nin different environments and cosmic epochs. \n\n"}
{"id": "1810.08731", "contents": "Title: Understanding the Diversity of 21 cm Cosmology Analyses Abstract: 21 cm power spectrum observations have the potential to revolutionize our\nunderstanding of the Epoch of Reionization and Dark Energy, but require\nextraordinarily precise data analysis methods to separate the cosmological\nsignal from the astrophysical and instrumental contaminants. This analysis\nchallenge has led to a diversity of proposed analyses, including delay spectra,\nimaging power spectra, m-mode analysis, and numerous others. This diversity of\napproach is a strength, but has also led to confusion within the community\nabout whether insights gleaned by one group are applicable to teams working in\ndifferent analysis frameworks. In this paper we show that all existing analysis\nproposals can be classified into two distinct families based on whether they\nestimate the power spectrum of the measured or reconstructed sky. This subtle\ndifference in the statistical question posed largely determines the\nsusceptibility of the analyses to foreground emission and calibration errors,\nand ultimately the science different analyses can pursue. In this paper we\ndetail the origin of the two analysis families, categorize the analyses being\nactively developed, and explore their relative sensitivities to foreground\ncontamination and calibration errors. \n\n"}
{"id": "1810.09572", "contents": "Title: Inflation and Early Dark Energy with a Stage II Hydrogen Intensity\n  Mapping Experiment Abstract: This white paper envisions a revolutionary post-DESI, post-LSST dark energy\nprogram based on intensity mapping of the redshifted 21cm emission line from\nneutral hydrogen at radio frequencies. The proposed intensity mapping survey\nhas the unique capability to quadruple the volume of the Universe surveyed by\noptical programs, provide a percent-level measurement of the expansion history\nto $z \\sim 6$, open a window to explore physics beyond the concordance\n$\\Lambda$CDM model, and to significantly improve the precision on standard\ncosmological parameters. In addition, characterization of dark energy and new\nphysics will be powerfully enhanced by cross-correlations with optical surveys\nand cosmic microwave background measurements. The rich dataset obtained by the\nproposed intensity mapping instrument will be simultaneously useful in\nexploring the time-domain physics of fast radio transients and pulsars,\npotentially in live \"multi-messenger\" coincidence with other observatories. The\ncore dark energy/inflation science advances enabled by this program are the\nfollowing: (i) Measure the expansion history of the universe over $z=0.3-6$\nwith a single instrument, extending the range deep into the pre-acceleration\nera, providing an unexplored window for new physics; (ii) Measure the growth\nrate of structure in the universe over the same redshift range; (iii) Observe,\nor constrain, the presence of inflationary relics in the primordial power\nspectrum, improving existing constraints by an order of magnitude; (iv)\nObserve, or constrain, primordial non-Gaussianity with unprecedented precision,\nimproving constraints on several key numbers by an order of magnitude. Detailed\nmapping of the enormous, and still largely unexplored, volume of cosmic space\nwill thus provide unprecedented information on fundamental questions of the\nvacuum energy and early-universe physics. \n\n"}
{"id": "1810.12186", "contents": "Title: DeepSphere: Efficient spherical Convolutional Neural Network with\n  HEALPix sampling for cosmological applications Abstract: Convolutional Neural Networks (CNNs) are a cornerstone of the Deep Learning\ntoolbox and have led to many breakthroughs in Artificial Intelligence. These\nnetworks have mostly been developed for regular Euclidean domains such as those\nsupporting images, audio, or video. Because of their success, CNN-based methods\nare becoming increasingly popular in Cosmology. Cosmological data often comes\nas spherical maps, which make the use of the traditional CNNs more complicated.\nThe commonly used pixelization scheme for spherical maps is the Hierarchical\nEqual Area isoLatitude Pixelisation (HEALPix). We present a spherical CNN for\nanalysis of full and partial HEALPix maps, which we call DeepSphere. The\nspherical CNN is constructed by representing the sphere as a graph. Graphs are\nversatile data structures that can act as a discrete representation of a\ncontinuous manifold. Using the graph-based representation, we define many of\nthe standard CNN operations, such as convolution and pooling. With filters\nrestricted to being radial, our convolutions are equivariant to rotation on the\nsphere, and DeepSphere can be made invariant or equivariant to rotation. This\nway, DeepSphere is a special case of a graph CNN, tailored to the HEALPix\nsampling of the sphere. This approach is computationally more efficient than\nusing spherical harmonics to perform convolutions. We demonstrate the method on\na classification problem of weak lensing mass maps from two cosmological models\nand compare the performance of the CNN with that of two baseline classifiers.\nThe results show that the performance of DeepSphere is always superior or equal\nto both of these baselines. For high noise levels and for data covering only a\nsmaller fraction of the sphere, DeepSphere achieves typically 10% better\nclassification accuracy than those baselines. Finally, we show how learned\nfilters can be visualized to introspect the neural network. \n\n"}
{"id": "1810.12927", "contents": "Title: A Strong Jet Signature in the Late-Time Lightcurve of GW170817 Abstract: We present new 0.6-10 GHz observations of the binary neutron star merger\nGW170817 covering the period up to 300 days post-merger, taken with the Karl G.\nJansky Very Large Array, the Australia Telescope Compact Array, the Giant\nMetrewave Radio Telescope and the MeerKAT telescope. We use these data to\nprecisely characterize the decay phase of the late-time radio light curve. We\nfind that the temporal decay is consistent with a power-law slope of t^-2.2,\nand that the transition between the power-law rise and decay is relatively\nsharp. Such a slope cannot be produced by a quasi-isotropic (cocoon-dominated)\noutflow, but is instead the classic signature of a relativistic jet. This\nprovides strong observational evidence that GW170817 produced a successful jet,\nand directly demonstrates the link between binary neutron star mergers and\nshort-hard GRBs. Using simple analytical arguments, we derive constraints on\nthe geometry and the jet opening angle of GW170817. These results are\nconsistent with those from our companion Very Long Baseline Interferometry\n(VLBI) paper, reporting superluminal motion in GW170817. \n\n"}
{"id": "1811.02379", "contents": "Title: First Cosmology Results using Type Ia Supernova from the Dark Energy\n  Survey: Simulations to Correct Supernova Distance Biases Abstract: We describe catalog-level simulations of Type Ia supernova (SN~Ia) light\ncurves in the Dark Energy Survey Supernova Program (DES-SN), and in\nlow-redshift samples from the Center for Astrophysics (CfA) and the Carnegie\nSupernova Project (CSP). These simulations are used to model biases from\nselection effects and light curve analysis, and to determine bias corrections\nfor SN~Ia distance moduli that are used to measure cosmological parameters. To\ngenerate realistic light curves, the simulation uses a detailed SN~Ia model,\nincorporates information from observations (PSF, sky noise, zero point), and\nuses summary information (e.g., detection efficiency vs. signal to noise ratio)\nbased on 10,000 fake SN light curves whose fluxes were overlaid on images and\nprocessed with our analysis pipelines. The quality of the simulation is\nillustrated by predicting distributions observed in the data. Averaging within\nredshift bins, we find distance modulus biases up to 0.05~mag over the redshift\nranges of the low-z and DES-SN samples. For individual events, particularly\nthose with extreme red or blue color, distance biases can reach 0.4~mag.\nTherefore, accurately determining bias corrections is critical for precision\nmeasurements of cosmological parameters. Files used to make these corrections\nare available at https://des.ncsa.illinois.edu/releases/sn. \n\n"}
{"id": "1811.02380", "contents": "Title: First Cosmology Results Using Type Ia Supernovae from the Dark Energy\n  Survey: Effects of Chromatic Corrections to Supernova Photometry on\n  Measurements of Cosmological Parameters Abstract: Calibration uncertainties have been the leading systematic uncertainty in\nrecent analyses using type Ia Supernovae (SNe Ia) to measure cosmological\nparameters. To improve the calibration, we present the application of Spectral\nEnergy Distribution (SED)-dependent \"chromatic corrections\" to the supernova\nlight-curve photometry from the Dark Energy Survey (DES). These corrections\ndepend on the combined atmospheric and instrumental transmission function for\neach exposure, and they affect photometry at the 0.01 mag (1%) level,\ncomparable to systematic uncertainties in calibration and photometry. Fitting\nour combined DES and low-z SN Ia sample with Baryon Acoustic Oscillation (BAO)\nand Cosmic Microwave Background (CMB) priors for the cosmological parameters\n$\\Omega_{\\rm m}$ (the fraction of the critical density of the universe\ncomprised of matter) and w (the dark energy equation of state parameter), we\ncompare those parameters before and after applying the corrections. We find the\nchange in w and $\\Omega_{\\rm m}$ due to not including chromatic corrections are\n-0.002 and 0.000, respectively, for the DES-SN3YR sample with BAO and CMB\npriors, consistent with a larger DES-SN3YR-like simulation, which has a\nw-change of 0.0005 with an uncertainty of 0.008 and an $\\Omega_{\\rm m}$ change\nof 0.000 with an uncertainty of 0.002 . However, when considering samples on\nindividual CCDs we find large redshift-dependent biases (approximately 0.02 in\ndistance modulus) for supernova distances. \n\n"}
{"id": "1811.06552", "contents": "Title: The binary black hole explorer: on-the-fly visualizations of precessing\n  binary black holes Abstract: Binary black hole mergers are of great interest to the astrophysics\ncommunity, not least because of their promise to test general relativity in the\nhighly dynamic, strong field regime. Detections of gravitational waves from\nthese sources by LIGO and Virgo have garnered widespread media and public\nattention. Among these sources, precessing systems (with misaligned black-hole\nspin/orbital angular momentum) are of particular interest because of the rich\ndynamics they offer. However, these systems are, in turn, more complex compared\nto nonprecessing systems, making them harder to model or develop intuition\nabout. Visualizations of numerical simulations of precessing systems provide a\nmeans to understand and gain insights about these systems. However, since these\nsimulations are very expensive, they can only be performed at a small number of\npoints in parameter space. We present binaryBHexp, a tool that makes use of\nsurrogate models of numerical simulations to generate on-the-fly interactive\nvisualizations of precessing binary black holes. These visualizations can be\ngenerated in a few seconds, and at any point in the 7-dimensional parameter\nspace of the underlying surrogate models. With illustrative examples, we\ndemonstrate how this tool can be used to learn about precessing binary black\nhole systems. \n\n"}
{"id": "1811.06844", "contents": "Title: Paleo-detectors: Searching for Dark Matter with Ancient Minerals Abstract: We explore paleo-detectors as an approach to the direct detection of Weakly\nInteracting Massive Particle (WIMP) dark matter radically different from\nconventional detectors. Instead of instrumenting a (large) target mass in a\nlaboratory in order to observe WIMP-induced nuclear recoils in real time, the\napproach is to examine ancient minerals for traces of WIMP-nucleus interactions\nrecorded over timescales as large as 1 Gyr. Here, we discuss the paleo-detector\nproposal in detail, including background sources and possible target materials.\nIn order to suppress backgrounds induced by radioactive contaminants such as\nuranium, we propose to use minerals found in marine evaporites or in\nultra-basic rocks. We estimate the sensitivity of paleo-detectors to\nspin-independent and spin-dependent WIMP-nucleus interactions. The sensitivity\nto low-mass WIMPs with masses $m_\\chi \\lesssim 10$ GeV extends to WIMP-nucleon\ncross sections many orders of magnitude smaller than current upper limits. For\nheavier WIMPs with masses $m_\\chi \\gtrsim 30$ GeV cross sections a factor of a\nfew to $\\sim 100$ smaller than current upper limits can be probed by\npaleo-detectors. \n\n"}
{"id": "1811.08222", "contents": "Title: The fate of axial U(1) in 2+1 flavor QCD towards the chiral limit Abstract: The region of the Columbia plot with two light quark flavors is not yet\nconclusively understood. Non-perturbative effects, e.g. the magnitude of the\nanomalous U(1) axial symmetry breaking, decides on the nature of the phase\ntransition in this region. We report on our study of this region of the\nColumbia plot using lattice techniques. We use gauge field ensembles generated\nwithin the Highly Improved Staggered Quark discretization scheme, with the\nstrange quark mass fixed at its physical value and the light quark mass varied\nsuch that $m_l=m_s/27$ and $m_s/40$, where $m_l=m_s/27$ corresponds to the\nphysical light quark mass. We study the eigenvalue spectrum of QCD using the\noverlap Dirac operator on these gauge field ensembles at finite temperature\naround the chiral transition temperature $T_c$, as the light quark masses\napproach the chiral limit, and infer about the fate of the anomalous $U_A(1)$\nsymmetry breaking. \n\n"}
{"id": "1811.10549", "contents": "Title: Digging for Dark Matter: Spectral Analysis and Discovery Potential of\n  Paleo-Detectors Abstract: Paleo-detectors are a recently proposed method for the direct detection of\nDark Matter (DM). In such detectors, one would search for the persistent damage\nfeatures left by DM--nucleus interactions in ancient minerals. Initial\nsensitivity projections have shown that paleo-detectors could probe much of the\nremaining Weakly Interacting Massive Particle (WIMP) parameter space. In this\npaper, we improve upon the cut-and-count approach previously used to estimate\nthe sensitivity by performing a full spectral analysis of the background- and\nDM-induced signal spectra. We consider two scenarios for the systematic errors\non the background spectra: i) systematic errors on the normalization only, and\nii) systematic errors on the shape of the backgrounds. We find that the\nprojected sensitivity is rather robust to imperfect knowledge of the\nbackgrounds. Finally, we study how well the parameters of the true WIMP model\ncould be reconstructed in the hypothetical case of a WIMP discovery. \n\n"}
{"id": "1811.11241", "contents": "Title: Results of a Search for Sub-GeV Dark Matter Using 2013 LUX Data Abstract: The scattering of dark matter (DM) particles with sub-GeV masses off nuclei\nis difficult to detect using liquid xenon-based DM search instruments because\nthe energy transfer during nuclear recoils is smaller than the typical detector\nthreshold. However, the tree-level DM-nucleus scattering diagram can be\naccompanied by simultaneous emission of a Bremsstrahlung photon or a so-called\n\"Migdal\" electron. These provide an electron recoil component to the\nexperimental signature at higher energies than the corresponding nuclear\nrecoil. The presence of this signature allows liquid xenon detectors to use\nboth the scintillation and the ionization signals in the analysis where the\nnuclear recoil signal would not be otherwise visible. We report constraints on\nspin-independent DM-nucleon scattering for DM particles with masses of 0.4-5\nGeV/c$^2$ using 1.4$\\times10^4$ kg$\\cdot$day of search exposure from the 2013\ndata from the Large Underground Xenon (LUX) experiment for four different\nclasses of mediators. This analysis extends the reach of liquid xenon-based DM\nsearch instruments to lower DM masses than has been achieved previously. \n\n"}
{"id": "1811.11586", "contents": "Title: Millimeter-Wave Downlink Positioning with a Single-Antenna Receiver Abstract: The paper addresses the problem of determining the unknown position of a\nmobile station for a mmWave MISO system. This setup is motivated by the fact\nthat massive arrays will be initially implemented only on 5G base stations,\nlikely leaving mobile stations with one antenna. The maximum likelihood\nsolution to this problem is devised based on the time of flight and angle of\ndeparture of received downlink signals. While positioning in the uplink would\nrely on angle of arrival, it presents scalability limitations that are avoided\nin the downlink. To circumvent the multidimensional optimization of the optimal\njoint estimator, we propose two novel approaches amenable to practical\nimplementation thanks to their reduced complexity. A thorough analysis, which\nincludes the derivation of relevant Cram\\'er-Rao lower bounds, shows that it is\npossible to achieve quasi-optimal performance even in presence of few\ntransmissions, low SNRs, and multipath propagation effects. \n\n"}
{"id": "1811.12462", "contents": "Title: Radiative Stellar Feedback in Galaxy Formation: Methods and Physics Abstract: Radiative feedback (RFB) from stars plays a key role in galaxies, but remains\npoorly-understood. We explore this using high-resolution, multi-frequency\nradiation-hydrodynamics (RHD) simulations from the Feedback In Realistic\nEnvironments (FIRE) project. We study ultra-faint dwarf through Milky Way mass\nscales, including H+He photo-ionization; photo-electric, Lyman Werner, Compton,\nand dust heating; and single+multiple scattering radiation pressure (RP). We\ncompare distinct numerical algorithms: ray-based LEBRON (exact when\noptically-thin) and moments-based M1 (exact when optically-thick). The most\nimportant RFB channels on galaxy scales are photo-ionization heating and\nsingle-scattering RP: in all galaxies, most ionizing/far-UV luminosity (~1/2 of\nlifetime-integrated bolometric) is absorbed. In dwarfs, the most important\neffect is photo-ionization heating from the UV background suppressing\naccretion. In MW-mass galaxies, meta-galactic backgrounds have negligible\neffects; but local photo-ionization and single-scattering RP contribute to\nregulating the galactic star formation efficiency and lowering central\ndensities. Without some RFB (or other 'rapid' FB), resolved GMCs convert\ntoo-efficiently into stars, making galaxies dominated by hyper-dense, bound\nstar clusters. This makes star formation more violent and 'bursty' when SNe\nexplode in these hyper-clustered objects: thus, including RFB 'smoothes' SFHs.\nThese conclusions are robust to RHD methods, but M1 produces somewhat stronger\neffects. Like in previous FIRE simulations, IR multiple-scattering is rare\n(negligible in dwarfs, ~10% of RP in massive galaxies): absorption occurs\nprimarily in 'normal' GMCs with A_v~1. \n\n"}
{"id": "1811.12907", "contents": "Title: GWTC-1: A Gravitational-Wave Transient Catalog of Compact Binary Mergers\n  Observed by LIGO and Virgo during the First and Second Observing Runs Abstract: We present the results from three gravitational-wave searches for coalescing\ncompact binaries with component masses above 1$\\mathrm{M}_\\odot$ during the\nfirst and second observing runs of the Advanced gravitational-wave detector\nnetwork. During the first observing run (O1), from September $12^\\mathrm{th}$,\n2015 to January $19^\\mathrm{th}$, 2016, gravitational waves from three binary\nblack hole mergers were detected. The second observing run (O2), which ran from\nNovember $30^\\mathrm{th}$, 2016 to August $25^\\mathrm{th}$, 2017, saw the first\ndetection of gravitational waves from a binary neutron star inspiral, in\naddition to the observation of gravitational waves from a total of seven binary\nblack hole mergers, four of which we report here for the first time: GW170729,\nGW170809, GW170818 and GW170823. For all significant gravitational-wave events,\nwe provide estimates of the source properties. The detected binary black holes\nhave total masses between $18.6_{-0.7}^{+3.2}\\mathrm{M}_\\odot$, and\n$84.4_{-11.1}^{+15.8} \\mathrm{M}_\\odot$, and range in distance between\n$320_{-110}^{+120}$ Mpc and $2840_{-1360}^{+1400}$ Mpc. No neutron star - black\nhole mergers were detected. In addition to highly significant\ngravitational-wave events, we also provide a list of marginal event candidates\nwith an estimated false alarm rate less than 1 per 30 days. From these results\nover the first two observing runs, which include approximately one\ngravitational-wave detection per 15 days of data searched, we infer merger\nrates at the 90% confidence intervals of $110\\, -\\, 3840$\n$\\mathrm{Gpc}^{-3}\\,\\mathrm{y}^{-1}$ for binary neutron stars and $9.7\\, -\\,\n101$ $\\mathrm{Gpc}^{-3}\\,\\mathrm{y}^{-1}$ for binary black holes assuming fixed\npopulation distributions, and determine a neutron star - black hole merger rate\n90% upper limit of $610$ $\\mathrm{Gpc}^{-3}\\,\\mathrm{y}^{-1}$. \n\n"}
{"id": "1812.02654", "contents": "Title: CMB statistical isotropy confirmation at all scales using multipole\n  vectors Abstract: We present an efficient numerical code and conduct, for the first time, a\nnull and model-independent CMB test of statistical isotropy using Multipole\nVectors (MVs) at all scales. Because MVs are insensitive to the angular power\nspectrum $C_\\ell$, our results are independent from the assumed cosmological\nmodel. We avoid a posteriori choices and use pre-defined ranges of scales\n$\\ell\\in[2,30]$, $\\ell\\in[2,600]$ and $\\ell\\in[2,1500]$ in our analyses. We\nfind that all four masked Planck maps, from both 2015 and 2018 releases, are in\nagreement with statistical isotropy for $\\ell\\in[2,30]$, $\\ell\\in[2,600]$. For\n$\\ell\\in[2,1500]$ we detect anisotropies but this is indicative of simply the\nanisotropy in the noise: there is no anisotropy for $\\ell < 1300$ and an\nincreasing level of anisotropy at higher multipoles. Our findings of no\nlarge-scale anisotropies seem to be a consequence of avoiding \\emph{a\nposteriori} statistics. We also find that the degree of anisotropy in the full\nsky (i.e. unmasked) maps vary enormously (between less than 5 and over 1000\nstandard deviations) among the different mapmaking procedures and data\nreleases. \n\n"}
{"id": "1812.03170", "contents": "Title: Variational Saccading: Efficient Inference for Large Resolution Images Abstract: Image classification with deep neural networks is typically restricted to\nimages of small dimensionality such as 224 x 244 in Resnet models [24]. This\nlimitation excludes the 4000 x 3000 dimensional images that are taken by modern\nsmartphone cameras and smart devices. In this work, we aim to mitigate the\nprohibitive inferential and memory costs of operating in such large dimensional\nspaces. To sample from the high-resolution original input distribution, we\npropose using a smaller proxy distribution to learn the co-ordinates that\ncorrespond to regions of interest in the high-dimensional space. We introduce a\nnew principled variational lower bound that captures the relationship of the\nproxy distribution's posterior and the original image's co-ordinate space in a\nway that maximizes the conditional classification likelihood. We empirically\ndemonstrate on one synthetic benchmark and one real world large resolution DSLR\ncamera image dataset that our method produces comparable results with ~10x\nfaster inference and lower memory consumption than a model that utilizes the\nentire original input distribution. Finally, we experiment with a more complex\nsetting using mini-maps from Starcraft II [56] to infer the number of\ncharacters in a complex 3d-rendered scene. Even in such complicated scenes our\nmodel provides strong localization: a feature missing from traditional\nclassification models. \n\n"}
{"id": "1812.03583", "contents": "Title: Homotopy limits in the category of dg-categories in terms of\n  $\\mathrm{A}_{\\infty}$-comodules Abstract: In this paper, we apply an explicit construction of a simplicial powering in\ndg-categories, due to Holstein (2016) and Arkhipov and Poliakova (2018), as\nwell as our own results on homotopy ends (Arkhipov and {\\O}rsted 2018), to\nobtain an explicit model for the homotopy limit of a cosimplicial system of\ndg-categories. We apply this to obtain a model for homotopy descent in terms of\n$\\mathrm{A}_{\\infty}$-comodules, proving a conjecture by Block, Holstein, and\nWei (2017) in the process. \n\n"}
{"id": "1812.05113", "contents": "Title: Explicit Bayesian treatment of unknown foreground contaminations in\n  galaxy surveys Abstract: The treatment of unknown foreground contaminations will be one of the major\nchallenges for galaxy clustering analyses of coming decadal surveys. These data\ncontaminations introduce erroneous large-scale effects in recovered power\nspectra and inferred dark matter density fields. In this work, we present an\neffective solution to this problem in the form of a robust likelihood designed\nto account for effects due to unknown foreground and target contaminations.\nConceptually, this robust likelihood marginalizes over the unknown large-scale\ncontamination amplitudes. We showcase the effectiveness of this novel\nlikelihood via an application to a mock SDSS-III data set subject to dust\nextinction contamination. In order to illustrate the performance of our\nproposed likelihood, we infer the underlying dark-matter density field and\nreconstruct the matter power spectrum, being maximally agnostic about the\nforegrounds. The results are compared to those of an analysis with a standard\nPoissonian likelihood, as typically used in modern large-scale structure\nanalyses. While the standard Poissonian analysis yields excessive power for\nlarge-scale modes and introduces an overall bias in the power spectrum, our\nlikelihood provides unbiased estimates of the matter power spectrum over the\nentire range of Fourier modes considered in this work. Further, we demonstrate\nthat our approach accurately accounts for and corrects the effects of unknown\nforeground contaminations when inferring three-dimensional density fields.\nRobust likelihood approaches, as presented in this work, will be crucial to\ncontrol unknown systematic error and maximize the outcome of the decadal\nsurveys. \n\n"}
{"id": "1812.05449", "contents": "Title: Cosmology-marginalized approaches in Bayesian model comparison: the\n  neutrino mass as a case study Abstract: We propose here a \\emph{novel} method which singles out the \\emph{a priori}\nunavoidable dependence on the underlying cosmological model when extracting\nparameter constraints, providing robust limits which only depend on the\nconsidered dataset. Interestingly, when dealing with several possible\ncosmologies and interpreting the Bayesian preference in terms of the Gaussian\nstatistical evidence, the preferred model is much less favored than when only\ntwo cases are compared. As a working example, we apply our approach to the\ncosmological neutrino mass bounds, which play a fundamental role not only in\nestablishing the contribution of relic neutrinos to the dark matter of the\nUniverse, but also in the planning of future experimental searches of the\nneutrino character and of the neutrino mass ordering. \n\n"}
{"id": "1812.05609", "contents": "Title: The IllustrisTNG Simulations: Public Data Release Abstract: We present the full public release of all data from the TNG50, TNG100 and\nTNG300 simulations of the IllustrisTNG project. IllustrisTNG is a suite of\nlarge volume, cosmological, gravo-magnetohydrodynamical simulations run with\nthe moving-mesh code Arepo. TNG includes a comprehensive model for galaxy\nformation physics, and each TNG simulation self-consistently solves for the\ncoupled evolution of dark matter, cosmic gas, luminous stars, and supermassive\nblackholes from early time to the present day, z=0. Each of the flagship runs\n-- TNG50, TNG100, and TNG300 -- are accompanied by lower-resolution and\ndark-matter only counterparts, and we discuss scientific and numerical cautions\nand caveats relevant when using TNG. Full volume snapshots are available at 100\nredshifts; halo and subhalo catalogs at each snapshot and merger trees are also\nreleased. The data volume now directly accessible online is ~1.1 PB, including\n2,000 full volume snapshots and ~110,000 high time-resolution subbox snapshots.\nData access and analysis examples are available in IDL, Python, and Matlab. We\ndescribe improvements and new functionality in the web-based API, including\non-demand visualization and analysis of galaxies and halos, exploratory\nplotting of scaling relations and other relationships between galactic and halo\nproperties, and a new JupyterLab interface. This provides an online,\nbrowser-based, near-native data analysis platform which supports user\ncomputation with fully local access to TNG data, alleviating the need to\ndownload large simulated datasets. \n\n"}
{"id": "1812.05741", "contents": "Title: Posterior Projection for Inference in Constrained Spaces Abstract: Estimation of parameters that obey specific constraints is crucial in\nstatistics and machine learning; for example, when parameters are required to\nsatisfy boundedness, monotonicity, or linear inequalities. Traditional\napproaches impose these constraints via constraint-specific transformations or\nby truncating the posterior distribution. Such methods often result in\ncomputational challenges, limited flexibility, and a lack of generality. We\npropose a generalized framework for constrained Bayesian inference by\nprojecting the unconstrained posterior distribution into the space of the\nparameter constraints, providing a computationally efficient and easily\nimplementable solution for a large class of problems. We rigorously establish\nthe theoretical foundations of the projected posterior distribution, as well as\nproviding asymptotic results for posterior consistency, posterior contraction,\nand optimal coverage properties. Our methodology is validated through both\ntheoretical arguments and practical applications, including bounded-monotonic\nregression and emulation of a computer model with directional outputs. \n\n"}
{"id": "1812.05995", "contents": "Title: Core Cosmology Library: Precision Cosmological Predictions for LSST Abstract: The Core Cosmology Library (CCL) provides routines to compute basic\ncosmological observables to a high degree of accuracy, which have been verified\nwith an extensive suite of validation tests. Predictions are provided for many\ncosmological quantities, including distances, angular power spectra,\ncorrelation functions, halo bias and the halo mass function through\nstate-of-the-art modeling prescriptions available in the literature. Fiducial\nspecifications for the expected galaxy distributions for the Large Synoptic\nSurvey Telescope (LSST) are also included, together with the capability of\ncomputing redshift distributions for a user-defined photometric redshift model.\nA rigorous validation procedure, based on comparisons between CCL and\nindependent software packages, allows us to establish a well-defined numerical\naccuracy for each predicted quantity. As a result, predictions for correlation\nfunctions of galaxy clustering, galaxy-galaxy lensing and cosmic shear are\ndemonstrated to be within a fraction of the expected statistical uncertainty of\nthe observables for the models and in the range of scales of interest to LSST.\nCCL is an open source software package written in C, with a python interface\nand publicly available at https://github.com/LSSTDESC/CCL. \n\n"}
{"id": "1812.06145", "contents": "Title: Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition\n  with Multimodal Training Abstract: We present an efficient approach for leveraging the knowledge from multiple\nmodalities in training unimodal 3D convolutional neural networks (3D-CNNs) for\nthe task of dynamic hand gesture recognition. Instead of explicitly combining\nmultimodal information, which is commonplace in many state-of-the-art methods,\nwe propose a different framework in which we embed the knowledge of multiple\nmodalities in individual networks so that each unimodal network can achieve an\nimproved performance. In particular, we dedicate separate networks per\navailable modality and enforce them to collaborate and learn to develop\nnetworks with common semantics and better representations. We introduce a\n\"spatiotemporal semantic alignment\" loss (SSA) to align the content of the\nfeatures from different networks. In addition, we regularize this loss with our\nproposed \"focal regularization parameter\" to avoid negative knowledge transfer.\nExperimental results show that our framework improves the test time recognition\naccuracy of unimodal networks, and provides the state-of-the-art performance on\nvarious dynamic hand gesture recognition datasets. \n\n"}
{"id": "1812.07310", "contents": "Title: Topology and Geometry of Gaussian random fields I: on Betti Numbers,\n  Euler characteristic and Minkowski functionals Abstract: This study presents a numerical analysis of the topology of a set of\ncosmologically interesting three-dimensional Gaussian random fields in terms of\ntheir Betti numbers $\\beta_0$, $\\beta_1$ and $\\beta_2$. We show that Betti\nnumbers entail a considerably richer characterization of the topology of the\nprimordial density field. Of particular interest is that Betti numbers specify\nwhich topological features - islands, cavities or tunnels - define its spatial\nstructure.\n  A principal characteristic of Gaussian fields is that the three Betti numbers\ndominate the topology at different density ranges. At extreme density levels,\nthe topology is dominated by a single class of features. At low levels this is\na \\emph{Swiss-cheeselike} topology, dominated by isolated cavities, at high\nlevels a predominantly \\emph{Meatball-like} topology of isolated objects. At\nmoderate density levels, two Betti number define a more \\emph{Sponge-like}\ntopology. At mean density, the topology even needs three Betti numbers,\nquantifying a field consisting of several disconnected complexes, not of one\nconnected and percolating overdensity.\n  A {\\it second} important aspect of Betti number statistics is that they are\nsensitive to the power spectrum. It reveals a monotonic trend in which at a\nmoderate density range a lower spectral index corresponds to a considerably\nhigher (relative) population of cavities and islands.\n  We also assess the level of complementary information that Betti numbers\nrepresent, in addition to conventional measures such as Minkowski functionals.\nTo this end, we include an extensive description of the Gaussian Kinematic\nFormula (GKF), which represents a major theoretical underpinning for this\ndiscussion. \n\n"}
{"id": "1812.07678", "contents": "Title: Unexpected Topology of the Temperature Fluctuations in the Cosmic\n  Microwave Background Abstract: We study the topology generated by the temperature fluctuations of the Cosmic\nMicrowave Background (CMB) radiation, as quantified by the number of components\nand holes, formally given by the Betti numbers, in the growing excursion sets.\nWe compare CMB maps observed by the Planck satellite with a thousand simulated\nmaps generated according to the LCDM paradigm with Gaussian distributed\nfluctuations. The survey of the CMB over $\\mathbb{S}^2$ is incomplete due to\nobfuscation effects by bright point sources and other extended foreground\nobjects like our own galaxy. To deal with such situations, where analysis in\nthe presence of \"masks\" is of importance, we introduce the concept of relative\nhomology.\n  The parametric $\\chi^2$-test shows differences between observations and\nsimulations, yielding $p$-values at per-cent to less than per-mil levels\nroughly between 2 to 7 degrees. The highest observed deviation for $b_0$ and\n$b_1$ is approximately between $3\\sigma$-4$\\sigma$ at scales of 3 to 7 degrees.\nThere are reports of mildly unusual behaviour of the Euler characteristic at\n3.66 degrees in the literature, computed from independent measurements of the\nCMB temperature fluctuations by Planck's predecessor WMAP satellite. The mildly\nanomalous behaviour of Euler characteristic is related to the strongly\nanomalous behaviour of components and holes. These are also the scales at which\nthe observed maps exhibit low variance compared to the simulations.\nNon-parametric tests show even stronger differences at almost all scales.\nRegardless, beyond the trivial possibility that this may still be a\nmanifestation of an extreme Gaussian case, these observations, along with the\nsuper-horizon scales involved, may motivate to look at primordial\nnon-Gaussianity. Alternative scenarios worth exploring may be models with\nnon-trivial topology. \n\n"}
{"id": "1812.08701", "contents": "Title: Planet X in CMB and Optical Galaxy Surveys Abstract: We consider the possibility of detecting and tracking the hypothesized Planet\n9 or other unknown planetary-mass distant solar system members, generically\ncalled Planet X, with a combination of CMB and optical imaging surveys. Planets\nare detectable via thermal emission in CMB surveys and via reflected sunlight\nin optical surveys. Since the flux from reflected light falls off faster with\ndistance, the signal-to-noise of planetary observations with optical surveys\nfalls off faster than for CMB surveys. A promising approach to detecting new\nsolar system planets with future surveys such as the Simons Observatory, CMB-S4\nand LSST, is for a detection in CMB data followed by tracking in the synoptic\nimaging survey. Even if the parallax were not detected in CMB data, point\nsources consistent with thermal spectra could be followed up by LSST. In\naddition to expanding the Planet X discovery space, the joint datasets would\nimprove constraints on key orbital and thermal properties of outer solar system\nbodies. This approach would work for a Neptune-like planet up to distances of a\nfew thousand AU, and for an Earth-like planet up to several hundred AU. We\ndiscuss the prospects for the next decade as well as nearer-term surveys. \n\n"}
{"id": "1812.09786", "contents": "Title: Stress testing the dark energy equation of state imprint on supernova\n  data Abstract: This work determines the degree to which a standard Lambda-CDM analysis based\non type Ia supernovae can identify deviations from a cosmological constant in\nthe form of a redshift-dependent dark energy equation of state w(z). We\nintroduce and apply a novel random curve generator to simulate instances of\nw(z) from constraint families with increasing distinction from a cosmological\nconstant. After producing a series of mock catalogs of binned type Ia\nsupernovae corresponding to each w(z) curve, we perform a standard Lambda-CDM\nanalysis to estimate the corresponding posterior densities of the absolute\nmagnitude of type Ia supernovae, the present-day matter density, and the\nequation of state parameter. Using the Kullback-Leibler divergence between\nposterior densities as a difference measure, we demonstrate that a standard\ntype Ia supernova cosmology analysis has limited sensitivity to extensive\nredshift dependencies of the dark energy equation of state. In addition, we\nreport that larger redshift-dependent departures from a cosmological constant\ndo not necessarily manifest easier-detectable incompatibilities with the\nLambda-CDM model. Our results suggest that physics beyond the standard model\nmay simply be hidden in plain sight. \n\n"}
{"id": "1812.11180", "contents": "Title: Unification of inflation and dark matter in the Higgs-Starobinsky model Abstract: In this work, we study unified picture of inflation and dark matter in the\nHiggs-Starobinsky (HS) model. As pointed out in the literature, Starobinsky\n$R^2$ inflation is induced by quantum correction effect from the large\nHiggs-curvature (graviton) coupling. We start with non-minimal coupling HS\naction in Jordan frame. We then transform the Jordan frame action into the\nEinstein one using the conformal transformation. The inflation potential is\nderived from the gravitational action of non-minimal-Higgs coupling and\nStarobinsky term in Einstein frame where the $R^2$ term is dominated in the\ninflationary phase of the universe. For model of inflation, we compute the\ninflationary parameters and confront them with Planck 2015 data. We discover\nthat the predictions of the model are in excellent agreement with the Planck\nanalysis. In addition, we study the Higgs field as a candidate for dark matter.\nThe renormalization group equations (RGEs) of Higgs-Starobinsky scenario with\nstandard model at one-loop is qualitatively analyzed. By using the solutions of\nparameter spaces from RGE analysis, the remnants of the quantum effect ($R^2$\nterm) from Higgs-graviton coupling will be implied by dark matter relic\nabundance. \n\n"}
{"id": "1812.11608", "contents": "Title: Relaxation of structures resulting from head-on mergers of ultralight\n  bosonic dark matter cores Abstract: In this work we study some features of head-on mergers of equilibrium\nsolutions of the Gross-Pitaevskii-Poisson system that rules the dynamics of the\nultralight bosonic dark matter model. The importance of equilibrium solutions\nis that they play the role of halo cores in structure formation simulations. We\nconsider a given range of initial conditions in order to sample the parameter\nspace in terms of mass ratio and head-on momentum. In each case we analyze the\nrelaxation process induced by gravitational cooling in the high and low\nmomentum regimes and estimate the relaxation time scales in each case. We\ndetect a low frequency mode in the whole parameters space and it was found that\nthe resulting configuration oscillates under this mode with amplitude that\ndepends on the mass ratio and head-on momentum. In some cases the resulting\nconfiguration oscillates with changes in density of two orders of magnitude and\nwith a matter distribution that is far from isotropic. These results could\ncontribute to the collection of possible mass distributions considered in the\nreconstruction of mass profiles obtained in structure formation simulations. \n\n"}
{"id": "1901.00296", "contents": "Title: Graph Database Solution for Higher Order Spatial Statistics in the Era\n  of Big Data Abstract: We present an algorithm for the fast computation of the general $N$-point\nspatial correlation functions of any discrete point set embedded within an\nEuclidean space of $\\mathbb{R}^n$. Utilizing the concepts of kd-trees and graph\ndatabases, we describe how to count all possible $N$-tuples in binned\nconfigurations within a given length scale, e.g. all pairs of points or all\ntriplets of points with side lengths $<r_{max}$. Through bench-marking we show\nthe computational advantage of our new graph based algorithm over more\ntraditional methods. We show that all 3-point configurations up to and beyond\nthe Baryon Acoustic Oscillation scale ($\\sim$200 Mpc in physical units) can be\nperformed on current SDSS data in reasonable time. Finally we present the first\nmeasurements of the 4-point correlation function of $\\sim$0.5 million SDSS\ngalaxies over the redshift range $0.43<z<0.7$. \n\n"}
{"id": "1901.03694", "contents": "Title: Dark Disk Substructure and Superfluid Dark Matter Abstract: Dark matter substructure has the potential to discriminate between broad\nclasses of dark matter models. With this in mind, we construct novel solutions\nto the equations of motion governing condensate dark matter candidates, namely\naxion Bose-Einstein condensates and superfluids. These solutions are highly\ncompressed along one axis and thus have a disk-like geometry. We discuss linear\nstability of these solutions, consider the astrophysical implications as a\nlarge-scale dark disk or as small scale substructure, and find a characteristic\nsignal in strong gravitational lensing. This adds to the growing body of work\nthat indicates that the morphology of dark matter substructure is a powerful\nprobe of the nature of dark matter. \n\n"}
{"id": "1901.04414", "contents": "Title: Spectroscopic confirmation and modelling of two lensed quadruple quasars\n  in the Dark Energy Survey public footprint Abstract: Quadruply lensed quasars are extremely rare objects, but incredibly powerful\ncosmological tools. Only few dozen are known in the whole sky. Here we present\nthe spectroscopic confirmation of two new quadruplets WG0214-2105 and\nWG2100-4452 discovered by Agnello & Spiniello (2018) within the Dark Energy\nSurvey (DES) public footprints. We have conducted spectroscopic follow-up of\nthese systems with the Southern African Large Telescope as part of a program\nthat aims at confirming the largest possible number of optically selected\nstrong gravitational lensing systems in the Equatorial and Southern Hemisphere.\nFor both systems, we present the spectra for the sources and deflectors that\nallowed us to estimate the source redshifts and unambiguously confirm their\nlensing nature. For the brighter deflector (WG2100-4452), we measure the\nstellar velocity dispersion from the spectrum. We also obtain photometry for\nboth lenses, directly from DES multi-band images, isolating the lens galaxies\nfrom the quasar images. One of the quadruplets, WG0214-2105, was also observed\nby Pan-STARRS, allowing us to estimate the apparent brightness of each quasar\nimage at two different epochs, and thus to find evidence for flux variability.\nThis result could suggest a microlensing event for the faintest components,\nalthough intrinsic variability cannot be excluded with only two epochs.\nFinally, we present simple lens models for both quadruplets, obtaining Einstein\nradii, SIE velocity dispersions, ellipticities, and position angles of the lens\nsystems, as well as time delay predictions assuming a concordance cosmological\nmodel. \n\n"}
{"id": "1901.05039", "contents": "Title: Local symmetry rank bound for positive intermediate Ricci curvatures Abstract: We use a local argument to prove if an $r$-dimensional torus acts\nisometrically and effectively on a connected $n$-dimensional manifold which has\npositive $k^\\mathrm{th}$-intermediate Ricci curvature at some point, then $r\n\\leq \\lfloor \\frac{n+k}{2} \\rfloor$. This symmetry rank bound generalizes those\nestablished by Grove and Searle for positive sectional curvature and Wilking\nfor quasipositive curvature. As a consequence, we show that the symmetry rank\nbound in the Maximal Symmetry Rank Conjecture for manifolds of non-negative\nsectional curvature holds for those which also have positive intermediate Ricci\ncurvature at some point. In the process of proving our symmetry rank bound, we\nalso obtain an optimal dimensional restriction on isometric immersions of\nmanifolds with non-positive intermediate Ricci curvature into manifolds with\npositive intermediate Ricci curvature, generalizing a result by Otsuki. \n\n"}
{"id": "1901.07801", "contents": "Title: Galaxy structure with strong gravitational lensing: decomposing the\n  internal mass distribution of massive elliptical galaxies Abstract: We investigate how strong gravitational lensing can test contemporary models\nof massive elliptical (ME) galaxy formation, by combining a traditional\ndecomposition of their visible stellar distribution with a lensing analysis of\ntheir mass distribution. As a proof of concept, we study a sample of three ME\nlenses, observing that all are composed of two distinct baryonic structures, a\n`red' central bulge surrounded by an extended envelope of stellar material.\nWhilst these two components look photometrically similar, their distinct\nlensing effects permit a clean decomposition of their mass structure. This\nallows us to infer two key pieces of information about each lens galaxy: (i)\nthe stellar mass distribution (without invoking stellar populations models) and\n(ii) the inner dark matter halo mass. We argue that these two measurements are\ncrucial to testing models of ME formation, as the stellar mass profile provides\na diagnostic of baryonic accretion and feedback whilst the dark matter mass\nplaces each galaxy in the context of LCDM large scale structure formation. We\nalso detect large rotational offsets between the two stellar components and a\nlopsidedness in their outer mass distributions, which hold further information\non the evolution of each ME. Finally, we discuss how this approach can be\nextended to galaxies of all Hubble types and what implication our results have\nfor studies of strong gravitational lensing. \n\n"}
{"id": "1901.08008", "contents": "Title: Matrix Element Method at NLO for (anti-)$\\mathbf{k_t}$-jet algorithms Abstract: In this article, we present a method to calculate a posteriori event weights\nat next-to-leading-order (NLO) QCD accuracy for a given jet event defined by\nthe (anti-)$k_t$ algorithm relying on the conventional $2\\to 1$ recombination.\nThis is an important extension compared to existing Monte-Carlo tools which\ngenerate jet events together with the corresponding weight but do not allow one\nto calculate the weight for a given event. The method can be used to generate\nunweighted events distributed according to the fixed-order NLO cross section.\nIn addition, the method allows one to calculate NLO accurate weights for events\nrecorded by experiments. The potential of this ability is illustrated by\napplying the Matrix Element Method (MEM) to single top-quark events generated\nwith POWHEG in combination with Pythia. For the first time, a systematic study\nof parton shower effects within the MEM is provided. The method is completely\ngeneral and can be applied to arbitrary LHC processes. \n\n"}
{"id": "1901.10665", "contents": "Title: Time operators for continuous-time and discrete-time quantum walks Abstract: We construct concrete examples of time operators for both continuous and\ndiscrete-time homogeneous quantum walks, and we determine their deficiency\nindices and spectra. For a discrete-time quantum walk, the time operator can be\nself-adjoint if the time evolution operator has a non-zero winding number. In\nthis case, its spectrum becomes a discrete set of real numbers. \n\n"}
{"id": "astro-ph/0107008", "contents": "Title: Simulations of Clusters of Galaxies Abstract: Numerical simulations of clusters of galaxies provide a unique way to follow\nthe dynamics of these systems. The models reveal many characteristics of the\nmerging process of subclusters: shock structure and strength, temperature\ndistribution and gas distribution. From the models detailed observational\nsignatures of the dynamical state can be derived. The simulations also show\nthat mergers have effects on the magnetic field, on the X-ray luminosity, on\nthe metal enrichment and other physical processes. Furthermore, observational\nmethods like the mass determination can be tested. \n\n"}
{"id": "astro-ph/0107407", "contents": "Title: Penetrating the Mask: The Gravitational Torque of Bars Abstract: The Hubble classification scheme of galaxies is based on blue-light\nappearance. Atlases reveal the rich variety of responses of the Population I\ncomponent (the \"mask\") of gas and dust to the underlying, older, stellar\npopulation. However, the Population I component may only constitute 5 percent\nof the dynamical mass of the galaxy; furthermore, dusty masks are highly\neffective in hiding bars. In the 1960s, Ken Freeman presented a meticulous\nstudy of the dynamics of bars at a time when nonbarred galaxies were called\n\"normal\" spirals and barred galaxies were regarded as curiosities. Now we know\nthat it is more \"normal\" for a galaxy to be barred than to be nonbarred. What\nis the range for gravitational torques of bars? We describe here a recently\ndeveloped method for deriving relative bar torques by using gravitational\npotentials inferred from near-infrared light distributions. We incorporate a\nbar torque class into the Block/Puerari dust-penetrated galaxy classification\nsystem. We find a huge overlap in relative bar torque between Hubble (Sa, Sb,\n  ...) and (SBa, SBb, ...) classifications. Application of the method to the\nhigh redshift universe is briefly discussed. \n\n"}
{"id": "astro-ph/0207531", "contents": "Title: The ANTARES project Abstract: The ANTARES deep-sea neutrino telescope will be located at a depth of 2400 m\nin the Mediterranean Sea. Deployment of the detector will commence this Autumn\nand is expected to be completed by the end of 2004. With a surface area of the\norder of 0.1 km^2 it will be one of the largest European detectors. The aim of\nneutrino telescopes is to detect high-energy neutrinos from astrophysical\nsources whilst also providing information on the early Universe. Successful\noperation of ANTARES in a deep sea environment constitutes an important\nmilestone towards the ultimate goal of the construction of an underwater\nneutrino telescope at the cubic-kilometre scale. The sky coverage of\nastrophysical sources offered by a Mediterranean neutrino telescope is\ncomplementary to any similar device at the South Pole. The current status of\nthe project is discussed and the expected performance of the detector is\ndescribed in the context of the scientific programme of the project which\ncomprises astrophysical studies, dark matter searches and neutrino\noscillations. \n\n"}
{"id": "astro-ph/0301157", "contents": "Title: INTEGRAL spectroscopy of three powerful radio galaxies: Jet-cloud\n  interactions seen in 3-D Abstract: Integral-field spectroscopic observations are presented for three powerful\nradio galaxies, namely 3C277.3 (Coma A; z=0.0857), 3C171 (z=0.2384) and 3C265\n(z=0.811), which are known to be undergoing jet-cloud interactions. The\nmorphology, kinematics and ionization of the gas in the emission-line structure\nof these sources are mapped and analysed. One-dimensional spectra are also\nextracted and integrated over the different emission-line regions in each\ngalaxy. In two of the galaxies (3C277.3 and 3C171) the radio sizes are of\nsimilar extent to the emission-line structure. For these, enhanced\nemission-line regions are found associated with the radio structures, in\naddition to complex kinematics and low ionization states close to the radio\nhotspots, indicating that jet-induced shocks disturb and ionize the gas.\nInterestingly, the bright -- presumably shock-ionized -- emission-line region\ncoincident with the radio jet knot in 3C277.3 shows quiescent kinematics and\nhigh ionization state. Possible explanations for this puzzling result are\nproposed. The images of 3C171 and 3C265 indicate that the lateral expansion of\nthe cocoon has a significant effect on the kinematics and ionization of the\ngas, showing for the first time that the effects of the radio source are felt\nfar from the jet axis. In addition, the presence of a stellar-photoionized HII\nregion is detected in the extended emission-line nebula of the radio galaxy\n3C277.3. \n\n"}
{"id": "astro-ph/0405014", "contents": "Title: An Interpretation of the $h\\nu_{peak}$ - $E_{iso}$ Correlation for GRB Abstract: The $h\\nu_{peak}/100 KeV \\sim [E_{iso}/10^{52} \\rm{erg}]^{1/2}$ correlation\nreported recently by Amati et al. (2002) and Lamb et al. (2003) for long GRB's\ncan be interpreted as a viewing angle effect if the emitting region of the\nfireball is ring-shaped. \n\n"}
{"id": "astro-ph/0507197", "contents": "Title: Light-cone Simulations: Evolution of dark matter haloes Abstract: We present a new fast method for simulating pencil-beam type light-cones,\nusing the MLAPM-code (Multi Level Adaptive Particle Mesh) with light-cone\nadditions. We show that by a careful choice of the light-cone orientation, it\nis possible to avoid extra periodicities in the light-cone. As an example, we\napply the method to simulate a 6 Gpc deep light-cone, create the dark matter\nhalo catalogue for the light-cone and study the evolution of haloes from $z=6$\nup to the present time. We determine the spatial density of the haloes, their\nlarge-scale correlation function, and study the evolution of the mass function.\nWe find a surprisingly simple relation for the dependence of halo maximum mass\non redshift, and apply it to derive redshift limits for bright quasars. \n\n"}
{"id": "astro-ph/0601481", "contents": "Title: Nongaussian and nonscale-invariant perturbations from tachyonic\n  preheating in hybrid inflation Abstract: We show that in hybrid inflation it is possible to generate large\nsecond-order perturbations in the cosmic microwave background due to the\ninstability of the tachyonic field during preheating. We carefully calculate\nthis effect from the tachyon contribution to the gauge-invariant curvature\nperturbation, clarifying some confusion in the literature concerning nonlocal\nterms in the tachyon curvature perturbation; we show explicitly that such terms\nare absent. We quantitatively compute the nongaussianity generated by the\ntachyon field during the preheating phase and translate the experimental\nconstraints on the nonlinearity parameter f_{NL} into constraints on the\nparameters of the model. We also show that nonscale-invariant second-order\nperturbations from the tachyon field can become larger than the\ninflaton-generated first-order perturbations, leading to stronger constraints\nthan those coming from nongaussianity. The width of the excluded region in\nterms of the logarithm of the dimensionless coupling g, grows linearly with the\nlog of the ratio of the Planck mass to the tachyon VEV, \\log(M_p/v); hence very\nlarge regions are ruled out if the inflationary scale v is small. We apply\nthese results to string-theoretic brane-antibrane inflation, and find a\nstringent upper bound on the string coupling, g_s < 10^{-4.5}. \n\n"}
{"id": "astro-ph/9702014", "contents": "Title: Relativistic electrons on a rotating spherical magnetic dipole: surface\n  orbitals Abstract: The semiclassical orbitals of a relativistic electron on a rotating sphere\nthreaded by an intense magnetic dipole field are examined. Several physically\ndistinct regimes emerge, depending on the relative sizes of the mass, total\nenergy, canonical azimuthal angular momentum, and magnetic field strength.\nMagnetic flux enclosed by orbits is quantized very close to the poles,\nsuggesting a quantum Hall-like state. Application of this system to neutron\nstar surfaces is outlined. The semiclassical orbitals of a relativistic\nelectron on a rotating sphere threaded by an intense magnetic dipole field are\nexamined. Several physically distinct regimes emerge, depending on the relative\nsizes of the mass, total energy, canonical azimuthal angular momentum, and\nmagnetic field strength. Magnetic flux enclosed by orbits is quantized very\nclose to the poles, suggesting a quantum Hall-like state. Application of this\nsystem to neutron star surfaces is outlined. \n\n"}
{"id": "astro-ph/9905281", "contents": "Title: Cluster mass function in mixed models Abstract: We study the cluster mass function in mixed dark matter (MDM) models, using\ntwo COBE normalized simulations with Omega_h = 0.26 and n=1.2, and Omega_h =\n0.14 and n = 1.05, both with 2 massive nu's (MDM1 and MDM2, respectively). For\nthe sake of comparison, we also simulate a CDM model with spectral index n=0.8\n(TCDM), also COBE normalized. We argue that, in our non--hydro simulations,\nwhere CDM particles describe both actual CDM and baryons, the galaxy\ndistribution traces CDM particles. Therefore, we use them to define clusters\nand their velocities to work out cluster masses. As CDM particles are more\nclustered than HDM and therefore have, in average, greater velocities, this\nleads to significant differences from PS predictions.\n  Such predictions agree with simulations if both HDM and CDM are used to\ndefine clusters.\n  Clusters defined through CDM in MDM models, instead, are less numerous than\nPS estimates, by a factor ~0.3, at the low mass end; the factor becomes\n\\~0.6-0.8, depending on the mix, on intermediate mass scales (~4-5, h^-1 10^14\nMsun) and almost vanishes on the high mass end. Therefore: (i) MDM models\nexpected to overproduce clusters over intermediate scales are viable; (ii) the\ngreater reduction factor at small scales agrees with the observational data\ndependence on the cluster mass M (which, however, may be partially due to\nsample incompleteness); (iii) the higher spectral normalization is felt at\nlarge scales, where MDM models produce more objects (hence, large clusters)\nthan CDM. MDM1 even exceeds Donahue et al. (1998) findings, while MDM2 is\nconsistent with them. (abridged) \n\n"}
{"id": "cond-mat/0202036", "contents": "Title: The breakdown of the shear modulus at the glass transition Abstract: The glass transition is described in terms of thermally activated local\nstructural rearrangements, the secondary relaxations of the glass phase. The\ninteraction between these secondary relaxations leads to a much faster and much\nmore dramatic breakdown of the shear modulus than without interaction, thus\ncreating the impression of a separate primary process which in reality does not\nexist. The model gives a new view on the fragility and the stretching, two\npuzzling features of the glass transition. \n\n"}
{"id": "cond-mat/0206529", "contents": "Title: Glassy behavior of electrons near metal-insulator transitions Abstract: The emergence of glassy behavior of electrons is investigated for systems\nclose to the disorder and/or interaction-driven metal-insulator transitions.\nOur results indicate that Anderson localization effects strongly stabilize such\nglassy behavior, while Mott localization tends to suppress it. We predict the\nemergence of an intermediate metallic glassy phase separating the insulator\nfrom the normal metal. This effect is expected to be most pronounced for\nsufficiently disordered systems, in agreement with recent experimental\nobservations. \n\n"}
{"id": "cond-mat/0412421", "contents": "Title: Applications of Massive Integrable Quantum Field Theories to Problems in\n  Condensed Matter Physics Abstract: We review applications of the sine-Gordon model, the O(3) non-linear sigma\nmodel, the U(1) Thirring model, and the O(N) Gross--Neveu model to quasi\none-dimensional quantum magnets, Mott insulators, and carbon nanotubes. We\nfocus upon the determination of dynamical response functions for these\nproblems. These quantities are computed by means of form factor expansions of\nquantum correlation functions in integrable quantum field theories. This\napproach is reviewed here in some detail. \n\n"}
{"id": "cond-mat/0501267", "contents": "Title: Theory of the Stark Effect for P donors in Si Abstract: We develop a multi-valley effective mass theory for substitutional donors in\nsilicon in an inhomogeneous environment. Valley-orbit coupling is treated\nperturbatively. We apply the theory to the Stark effect in Si:P. The method\nbecomes more accurate at high fields, and it is designed to give correct\nexperimental binding energies at zero field. Unexpectedly, the ground state\nenergy for the donor electron is found to increase with electric field as a\nconsequence of spectrum narrowing of the 1s manifold. Our results are of\nparticular importance for the Kane quantum computer. \n\n"}
{"id": "cond-mat/0505325", "contents": "Title: Pseudo-fermionization of 1-D bosons in optical lattices Abstract: We present a model that generalizes the Bose-Fermi mapping for strongly\ncorrelated 1D bosons in an optical lattice, to cases in which the average\nnumber of atoms per site is larger than one. This model gives an accurate\naccount of equilibrium properties of such systems, in parameter regimes\nrelevant to current experiments. The application of this model to\nnon-equilibrium phenomena is explored by a study of the dynamics of an atom\ncloud subject to a sudden displacement of the confining potential. Good\nagreement is found with results of recent experiments. The simplicity and\nintuitive appeal of this model make it attractive as a general tool for\nunderstanding bosonic systems in the strongly correlated regime. \n\n"}
{"id": "cond-mat/0512222", "contents": "Title: Towards a fully automated computation of RG-functions for the 3-$d$ O(N)\n  vector model: Parametrizing amplitudes Abstract: Within the framework of field-theoretical description of second-order phase\ntransitions via the 3-dimensional O(N) vector model, accurate predictions for\ncritical exponents can be obtained from (resummation of) the perturbative\nseries of Renormalization-Group functions, which are in turn derived\n--following Parisi's approach-- from the expansions of appropriate field\ncorrelators evaluated at zero external momenta.\n  Such a technique was fully exploited 30 years ago in two seminal works of\nBaker, Nickel, Green and Meiron, which lead to the knowledge of the\n$\\beta$-function up to the 6-loop level; they succeeded in obtaining a precise\nnumerical evaluation of all needed Feynman amplitudes in momentum space by\nlowering the dimensionalities of each integration with a cleverly arranged set\nof computational simplifications. In fact, extending this computation is not\nstraightforward, due both to the factorial proliferation of relevant diagrams\nand the increasing dimensionality of their associated integrals; in any case,\nthis task can be reasonably carried on only in the framework of an automated\nenvironment.\n  On the road towards the creation of such an environment, we here show how a\nstrategy closely inspired by that of Nickel and coworkers can be stated in\nalgorithmic form, and successfully implemented on the computer. As an\napplication, we plot the minimized distributions of residual integrations for\nthe sets of diagrams needed to obtain RG-functions to the full 7-loop level;\nthey represent a good evaluation of the computational effort which will be\nrequired to improve the currently available estimates of critical exponents. \n\n"}
{"id": "cond-mat/9807250", "contents": "Title: Vortex stabilization in Bose-Einstein condensate of alkali atom gas Abstract: A quantized vortex in the Bose-Einstein condensation (BEC), which is known to\nbe unstable intrinsically, is demonstrated theoretically to be stabilized by\nthe finite temperature effect. The mean-field calculation of Popov\napproximation within the Bogoliubov theory is employed, giving rise to a\nself-consistent solution for BEC confined by a harmonic potential. Physical\norigin of this vortex stabilization is investigated. An equivalent effect is\nalso proved to be induced by an additional pinning potential at the vortex\ncenter produced by a focused laser beam even at the lowest temperature. The\nself-consistent solutions give detailed properties of a stable vortex, such as\nthe spatial profiles of the condensate and non-condensate, the particle current\ndensity around the core, the whole excitation spectrum, and their temperature\ndependences. \n\n"}
{"id": "gr-qc/0511150", "contents": "Title: An analytic model for the transition from decelerated to accelerated\n  cosmic expansion Abstract: We consider the scenario where our observable universe is devised as a\ndynamical four-dimensional hypersurface embedded in a five-dimensional bulk\nspacetime, with a large extra dimension, which is the {\\it generalization of\nthe flat FRW cosmological metric to five dimensions}. This scenario generates a\nsimple analytical model where different stages of the evolution of the universe\nare approximated by distinct parameterizations of the {\\it same} spacetime. In\nthis model the evolution from decelerated to accelerated expansion can be\ninterpreted as a \"first-order\" phase transition between two successive stages.\nThe dominant energy condition allows different parts of the universe to evolve,\nfrom deceleration to acceleration, at different redshifts within a narrow era.\nThis picture corresponds to the creation of bubbles of new phase, in the middle\nof the old one, typical of first-order phase transitions. Taking $\\Omega_{m} =\n0.3$ today, we find that the cross-over from deceleration to acceleration\noccurs at $z \\sim 1-1.5 $, regardless of the equation of state in the very\nearly universe. In the case of primordial radiation, the model predicts that\nthe deceleration parameter \"jumps\" from $q \\sim + 1.5$ to $q \\sim - 0.4$ at $z\n\\sim 1.17$. At the present time $q = - 0.55$ and the equation of state of the\nuniverse is $w = p/\\rho \\sim - 0.7 $, in agreement with observations and some\ntheoretical predictions. \n\n"}
{"id": "hep-ex/9904014", "contents": "Title: Event-by-event fluctuations of average transverse momentum in central\n  Pb+Pb collisions at 158 GeV per nucleon Abstract: We present first data on event-by-event fluctuations in the average\ntransverse momentum of charged particles produced in Pb+Pb collisions at the\nCERN SPS. This measurement provides previously unavailable information allowing\nsensitive tests of microscopic and thermodynamic collision models and to search\nfor fluctuations expected to occur in the vicinity of the predicted QCD phase\ntransition. We find that the observed variance of the event-by-event average\ntransverse momentum is consistent with independent particle production modified\nby the known two-particle correlations due to quantum statistics and final\nstate interactions and folded with the resolution of the NA49 apparatus. For\ntwo specific models of non-statistical fluctuations in transverse momentum\nlimits are derived in terms of fluctuation amplitude. We show that a\nsignificant part of the parameter space for a model of isospin fluctuations\npredicted as a consequence of chiral symmetry restoration in a non-equilibrium\nscenario is excluded by our measurement. \n\n"}
{"id": "hep-lat/0008018", "contents": "Title: Incorporating Chiral Symmetry and Heavy Quark Theory in Extrapolations\n  of Octet Baryon Charge Radii Abstract: We extrapolate lattice calculations of electric charge radii of the spin-1/2\nbaryon octet to the physical regime. The extrapolation procedure incorporates\nchiral perturbation theory and heavy quark effective theory in the appropriate\nlimits. In particular, this procedure includes the non-analytic, logarithmic\nterms from pion loops. The electric charge radii of the nucleons and $\\Sigma^-$\nobtained from the chiral extrapolations agree well with experimental data. We\nmake predictions for the charge radii of the remaining baryons in anticipation\nof future experimental measurements. \n\n"}
{"id": "hep-lat/9510046", "contents": "Title: Comments on Lattice Calculations of Proton Spin Components Abstract: Comments on the recent lattice QCD calculations of the flavor-singlet axial\ncoupling constant $g_A^0$ and individual quark and gluon spin contributions to\nthe proton spin is given. I point out the physics learned from these\ncalculations as well as some of the lessons and pitfalls. \n\n"}
{"id": "hep-ph/9604228", "contents": "Title: Study of Long Distance Contributions to $K\\to n\\pi\\nu\\bar{\\nu}$ Abstract: We calculate long distance contributions to $K\\to\\pi\\nu\\bar{\\nu}\\,,\\\n\\pi\\pi\\nu\\bar{\\nu}$, and $\\pi\\pi\\pi\\nu\\bar{\\nu}$ modes within the framework of\nchiral perturbation theory. We find that these contributions to decay rates of\n$K\\to \\pi\\nu\\bar{\\nu}$ and $K\\to \\pi\\pi\\nu\\bar{\\nu}$ in the chiral logarithmic\napproximation are at least seven orders of magnitude suppressed relative to\nthose from the short distance parts. The long distance effects in this class of\ndecays are therefore negligible. \n\n"}
{"id": "hep-ph/9611265", "contents": "Title: Topcolor Models and Scalar Spectrum Abstract: We review the motivation and main aspects of Topcolor models with emphasis on\nthe spectrum of relatively light scalars and pseudo-scalars. \n\n"}
{"id": "hep-th/0006009", "contents": "Title: Conformal Fields in Higher Dimensions Abstract: We generalize, to any space-time dimension, the unitarity bounds of highest\nweight UIR's of the conformal groups with Lie algebras $so(2,d)$. We classify\ngauge theories invariant under $so(2,d)$, both integral and half-integral\nspins. A similar analysis is carried out for the algebras $so^*(2n)$. We study\nnew unitary modules of the conformal algebra in $d>4$, that have no analogue\nfor $d\\leq 4$ as they cannot be obtained by \"squaring\" singletons. This may\nsuggest the interpretation of higher dimensional non-trivial conformal field\ntheories as theories of \"tensionless\" $p$-branes of which tensionless strings\nin $d=6$ are just particular examples. \n\n"}
{"id": "hep-th/0106025", "contents": "Title: Nonlocal regularization of abelian models with spontaneous symmetry\n  breaking Abstract: We demonstrate how nonlocal regularization is applied to gauge invariant\nmodels with spontaneous symmetry breaking. Motivated by the ability to find a\nnonlocal BRST invariance that leads to the decoupling of longitudinal gauge\nbosons from physical amplitudes, we show that the original formulation of the\nmethod leads to a nontrivial relationship between the nonlocal form factors\nthat can appear in the model. \n\n"}
{"id": "hep-th/0111044", "contents": "Title: The Heterotic Enhancon Abstract: The enhancon mechanism is studied in the heterotic string theory. We consider\nthe N_L=0 winding strings with momentum (NS1-W*) and the Kaluza-Klein dyons\n(KK5-NS5*). The NS1-W* and KK5-NS5* systems are dualized to the D4-D0* and\nD6-D2* systems, respectively, under the d=6 heterotic/IIA S-duality. The\nheterotic form has a number of advantages over the type IIA form. We study\nthese backgrounds and obtain the enhancon radii by brane probe analysis. The\nresults are consistent with S-duality. \n\n"}
{"id": "hep-th/0211208", "contents": "Title: Wigner's Little Group as a Generator of Gauge Transformations Abstract: The role of Wigner's little group, as an abelian gauge generator in different\ncontexts, is studied. \n\n"}
{"id": "hep-th/0512001", "contents": "Title: Asymptotically AdS brane black holes Abstract: We study the possibility of having a static, asymptotically AdS black hole\nlocalized on a braneworld with matter fields, within the framework of the\nRandall and Sundrum scenario. We attempt to look for such a brane black hole\nconfiguration by slicing a given bulk spacetime and taking Z_2 symmetry about\nthe slices. We find that such configurations are possible, and as an explicit\nexample, we provide a family of asymptotically AdS brane black hole solutions\nfor which both the bulk and brane metrics are regular on and outside the black\nhole horizon and brane matter fields are realistic in the sense that the\ndominant energy condition is satisfied. We also find that our braneworld models\nexhibit signature change inside the black hole horizon. \n\n"}
{"id": "hep-th/0603220", "contents": "Title: Graphical Representation of SUSY and C-Program Calculation Abstract: We present a graphical representation of the supersymmetry and a C-program\nfor the graphical calculation. Calculation is demonstrated for 4D Wess-Zumino\nmodel and for Super QED. The chiral operators are graphically expressed in an\nilluminating way. The tedious part of SUSY calculation, due to manipulating\nchiral suffixes, reduces considerably. The application is diverse. \n\n"}
{"id": "math-ph/0702055", "contents": "Title: The necklace Lie coalgebra and renormalization algebras Abstract: We give a natural monomorphism from the necklace Lie coalgebra, defined for\nany quiver, to Connes and Kreimer's Lie coalgebra of trees, and extend this to\na map from a certain quiver-theoretic Hopf algebra to Connes and Kreimer's\nrenormalization Hopf algebra, as well as to pre-Lie versions. These results are\ndirect analogues of Turaev's results in 2004, by replacing algebras of loops on\nsurfaces with algebras of paths on quivers. We also factor the morphism through\nan algebra of chord diagrams and explain the geometric version. We then explain\nhow all of the Hopf algebras are uniquely determined by the pre-Lie structures,\nand discuss noncommutative versions of the Hopf algebras. \n\n"}
{"id": "math/0103047", "contents": "Title: Nearby cycles for local models of some Shimura varieties Abstract: Kottwitz conjectured a formula for the (semi-simple) trace of Frobenius on\nthe nearby cycles for the local model of a Shimura variety with Iwahori-type\nlevel structure. In this paper, we prove his conjecture in the linear and\nsymplectic cases by adapting an argument of Gaitsgory, who proved an analogous\ntheorem in the equal characteristic case. \n\n"}
{"id": "math/0308151", "contents": "Title: Khovanov's conjecture over Z[c] Abstract: We disprove the conjecture of M. Khovanov (math.QA/9908171) on the\nfunctoriality of his link homology with polynomial coefficients. This is in\ncontrast to the case of integer coefficients, where functoriality was proved in\nmath.GT/0206303 . \n\n"}
{"id": "quant-ph/0210026", "contents": "Title: On a loss of information in a transition from quantum to a\n  quasi-classical regime Abstract: By defining information entropy in terms of probabilities densities\n$|\\Psi|^2$ ($\\Psi$ is a wave function in the coordinate representation) it is\nexplicitly shown how a loss of quantum information occurs in a transition from\na quantum to a quasi-classical regime. \n\n"}
{"id": "quant-ph/0502122", "contents": "Title: Natural multiparticle entanglement in a Fermi gas Abstract: We investigate multipartite entanglement in a non-interacting fermion gas, as\na function of fermion separation, starting from the many particle fermion\ndensity matrix. We prove that all multiparticle entanglement can be built only\nout of two-fermion entanglement. Although from the Pauli exclusion principle we\nwould always expect entanglement to decrease with fermion distance, we\nsurprisingly find the opposite effect for certain fermion configurations. The\nvon Neumann entropy is found to be proportional to the volume for a large\nnumber of particles even when they are arbitrarily close to each other. We will\nillustrate our results using different configurations of two, three, and four\nfermions at zero temperature although all our results can be applied to any\ntemperature and any number of particles. \n\n"}
