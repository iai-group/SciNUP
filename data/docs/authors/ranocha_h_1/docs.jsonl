{"id": "0704.0022", "contents": "Title: Stochastic Lie group integrators Abstract: We present Lie group integrators for nonlinear stochastic differential\nequations with non-commutative vector fields whose solution evolves on a smooth\nfinite dimensional manifold. Given a Lie group action that generates transport\nalong the manifold, we pull back the stochastic flow on the manifold to the Lie\ngroup via the action, and subsequently pull back the flow to the corresponding\nLie algebra via the exponential map. We construct an approximation to the\nstochastic flow in the Lie algebra via closed operations and then push back to\nthe Lie group and then to the manifold, thus ensuring our approximation lies in\nthe manifold. We call such schemes stochastic Munthe-Kaas methods after their\ndeterministic counterparts. We also present stochastic Lie group integration\nschemes based on Castell--Gaines methods. These involve using an underlying\nordinary differential integrator to approximate the flow generated by a\ntruncated stochastic exponential Lie series. They become stochastic Lie group\nintegrator schemes if we use Munthe-Kaas methods as the underlying ordinary\ndifferential integrator. Further, we show that some Castell--Gaines methods are\nuniformly more accurate than the corresponding stochastic Taylor schemes.\nLastly we demonstrate our methods by simulating the dynamics of a free rigid\nbody such as a satellite and an autonomous underwater vehicle both perturbed by\ntwo independent multiplicative stochastic noise processes. \n\n"}
{"id": "0705.4448", "contents": "Title: On partial polynomial interpolation Abstract: The Alexander-Hirschowitz theorem says that a general collection of $k$\ndouble points in ${\\bf P}^n$ imposes independent conditions on homogeneous\npolynomials of degree $d$ with a well known list of exceptions. We generalize\nthis theorem to arbitrary zero-dimensional schemes contained in a general union\nof double points. We work in the polynomial interpolation setting. In this\nframework our main result says that the affine space of polynomials of degree\n$\\le d$ in $n$ variables, with assigned values of any number of general linear\ncombinations of first partial derivatives, has the expected dimension if $d\\neq\n2$ with only five exceptional cases. If $d=2$ the exceptional cases are fully\ndescribed. \n\n"}
{"id": "0706.0433", "contents": "Title: Numerical Clifford Analysis for Nonlinear Schrodinger Problem Abstract: The aim of this work is to study the numerical solution of the nonlinear\nSchrodinger problem using a combination between Witt basis and finite\ndifference approximations. We construct a discrete fundamental solution for the\nnon-stationary Schrodinger operator and we show the convergence of the\nnumerical scheme. Numerical examples are given at the end of the paper. \n\n"}
{"id": "0706.3029", "contents": "Title: Using integral transforms to estimate higher order derivatives Abstract: Integral transformations are used to estimate high order derivatives of\nvarious special functions. Applications are given to numerical integration,\nwhere estimates of high order derivatives of the integrand are needed to\nachieve bounds on the error. The main idea is to find a suitable integral\nrepresentation of the function whose derivatives are to be estimated,\ndifferentiate repeatedly under the integral sign, and estimate the resulting\nintegral. \n\n"}
{"id": "0707.4470", "contents": "Title: Geometric Computational Electrodynamics with Variational Integrators and\n  Discrete Differential Forms Abstract: In this paper, we develop a structure-preserving discretization of the\nLagrangian framework for electromagnetism, combining techniques from\nvariational integrators and discrete differential forms. This leads to a\ngeneral family of variational, multisymplectic numerical methods for solving\nMaxwell's equations that automatically preserve key symmetries and invariants.\n  In doing so, we demonstrate several new results, which apply both to some\nwell-established numerical methods and to new methods introduced here. First,\nwe show that Yee's finite-difference time-domain (FDTD) scheme, along with a\nnumber of related methods, are multisymplectic and derive from a discrete\nLagrangian variational principle. Second, we generalize the Yee scheme to\nunstructured meshes, not just in space but in 4-dimensional spacetime. This\nrelaxes the need to take uniform time steps, or even to have a preferred time\ncoordinate at all. Finally, as an example of the type of methods that can be\ndeveloped within this general framework, we introduce a new asynchronous\nvariational integrator (AVI) for solving Maxwell's equations. These results are\nillustrated with some prototype simulations that show excellent energy and\nconservation behavior and lack of spurious modes, even for an irregular mesh\nwith asynchronous time stepping. \n\n"}
{"id": "0709.2222", "contents": "Title: Stochastic Variational Partitioned Runge-Kutta Integrators for\n  Constrained Systems Abstract: Stochastic variational integrators for constrained, stochastic mechanical\nsystems are developed in this paper. The main results of the paper are twofold:\nan equivalence is established between a stochastic Hamilton-Pontryagin (HP)\nprinciple in generalized coordinates and constrained coordinates via Lagrange\nmultipliers, and variational partitioned Runge-Kutta (VPRK) integrators are\nextended to this class of systems. Among these integrators are first and\nsecond-order strongly convergent RATTLE-type integrators. We prove order of\naccuracy of the methods provided. The paper also reviews the deterministic\ntreatment of VPRK integrators from the HP viewpoint. \n\n"}
{"id": "0801.4172", "contents": "Title: Computational aspects and applications of a new transform for solving\n  the complex exponentials approximation problem Abstract: Many real life problems can be reduced to the solution of a complex\nexponentials approximation problem which is usually ill posed. Recently a new\ntransform for solving this problem, formulated as a specific moments problem in\nthe plane, has been proposed in a theoretical framework. In this work some\ncomputational issues are addressed to make this new tool useful in practice. An\nalgorithm is developed and used to solve a Nuclear Magnetic Resonance\nspectrometry problem, two time series interpolation and extrapolation problems\nand a shape from moments problem. \n\n"}
{"id": "0802.1681", "contents": "Title: Symmetric tensors and symmetric tensor rank Abstract: A symmetric tensor is a higher order generalization of a symmetric matrix. In\nthis paper, we study various properties of symmetric tensors in relation to a\ndecomposition into a sum of symmetric outer product of vectors. A rank-1\norder-k tensor is the outer product of k non-zero vectors. Any symmetric tensor\ncan be decomposed into a linear combination of rank-1 tensors, each of them\nbeing symmetric or not. The rank of a symmetric tensor is the minimal number of\nrank-1 tensors that is necessary to reconstruct it. The symmetric rank is\nobtained when the constituting rank-1 tensors are imposed to be themselves\nsymmetric. It is shown that rank and symmetric rank are equal in a number of\ncases, and that they always exist in an algebraically closed field. We will\ndiscuss the notion of the generic symmetric rank, which, due to the work of\nAlexander and Hirschowitz, is now known for any values of dimension and order.\nWe will also show that the set of symmetric tensors of symmetric rank at most r\nis not closed, unless r = 1. \n\n"}
{"id": "0803.2070", "contents": "Title: Variational Integrators for Maxwell's Equations with Sources Abstract: In recent years, two important techniques for geometric numerical\ndiscretization have been developed. In computational electromagnetics, spatial\ndiscretization has been improved by the use of mixed finite elements and\ndiscrete differential forms. Simultaneously, the dynamical systems and\nmechanics communities have developed structure-preserving time integrators,\nnotably variational integrators that are constructed from a Lagrangian action\nprinciple. Here, we discuss how to combine these two frameworks to develop\nvariational spacetime integrators for Maxwell's equations. Extending our\nprevious work, which first introduced this variational perspective for\nMaxwell's equations without sources, we also show here how to incorporate free\nsources of charge and current. \n\n"}
{"id": "0805.2929", "contents": "Title: A stable absorbing boundary layer for anisotropic waves Abstract: For some anisotropic wave models, the PML (perfectly matched layer) method of\nopen boundaries can become polynomially or exponentially unstable in time. In\nthis work we present a new method of open boundaries, the phase space filter,\nwhich is stable for all wave equations.\n  Outgoing waves can be characterized as waves located near the boundary of the\ncomputational domain with group velocities pointing outward. The phase space\nfiltering algorithm consists of applying a filter to the solution that removes\noutgoing waves only.\n  The method presented here is a simplified version of the original phase space\nfilter, originally described in [22] for the Schrodinger equation. We apply\nthis method to anisotropic wave models for which the PML is unstable, namely\nthe Euler equations (linearized about a constant jet flow) and Maxwell's\nequations in an anisotropic medium. Stability of the phase space filter is\nproved. \n\n"}
{"id": "0808.0485", "contents": "Title: Spectral duality for a class of unbounded operators Abstract: We establish a spectral duality for certain unbounded operators in Hilbert\nspace. The class of operators includes discrete graph Laplacians arising from\ninfinite weighted graphs. The problem in this context is to establish a\npractical approximation of infinite models with suitable sequences of finite\nmodels which in turn allow (relatively) easy computations.\n  Let $X$ be an infinite set and let $\\H$ be a Hilbert space of functions on\n$X$ with inner product $\\ip{\\cdot}{\\cdot}=\\ip{\\cdot}{\\cdot}_{\\H}$. We will be\nassuming that the Dirac masses $\\delta_x$, for $x\\in X$, are contained in $\\H$.\nAnd we then define an associated operator $\\Delta$ in $\\H$ given by $$(\\Delta\nv)(x):=\\ip{\\delta_x}{v}_{\\H}.$$ Similarly, for every finite subset $F\\subset\nX$, we get an operator $\\Delta_F$.\n  If $F_1\\subset F_2\\subset...$ is an ascending sequence of finite subsets such\nthat $\\cup_{k\\in\\bn}F_k=X$, we are interested in the following two problems:\n  (a) obtaining an approximation formula\n$$\\lim_{k\\to\\infty}\\Delta_{F_k}=\\Delta;$$ and\n  (b) establish a computational spectral analysis for the truncated operators\n$\\Delta_F$ in (a). \n\n"}
{"id": "0809.3875", "contents": "Title: On spectral minimal partitions II, the case of the rectangle Abstract: In continuation of \\cite{HHOT}, we discuss the question of spectral minimal\n3-partitions for the rectangle $]-\\frac a2,\\frac a2[\\times ] -\\frac b2,\\frac\nb2[ $, with $0< a\\leq b$. It has been observed in \\cite{HHOT} that when\n$0<\\frac ab < \\sqrt{\\frac 38}$ the minimal 3-partition is obtained by the three\nnodal domains of the third eigenfunction corresponding to the three rectangles\n$]-\\frac a2,\\frac a2[\\times ] -\\frac b2,-\\frac b6[$, $]-\\frac a2,\\frac\na2[\\times ] -\\frac b6,\\frac b6[$ and $]-\\frac a2,\\frac a2[\\times ] \\frac b6,\n\\frac b2[$. We will describe a possible mechanism of transition for increasing\n$\\frac ab$ between these nodal minimal 3-partitions and non nodal minimal\n3-partitions at the value $ \\sqrt{\\frac 38}$ and discuss the existence of\nsymmetric candidates for giving minimal 3-partitions when $ \\sqrt{\\frac\n38}<\\frac ab \\leq 1$. Numerical analysis leads very naturally to nice questions\nof isospectrality which are solved by introducing Aharonov-Bohm Hamiltonians or\nby going on the double covering of the punctured rectangle. \n\n"}
{"id": "0810.4225", "contents": "Title: Nonnegative Factorization and The Maximum Edge Biclique Problem Abstract: Nonnegative Matrix Factorization (NMF) is a data analysis technique which\nallows compression and interpretation of nonnegative data. NMF became widely\nstudied after the publication of the seminal paper by Lee and Seung (Learning\nthe Parts of Objects by Nonnegative Matrix Factorization, Nature, 1999, vol.\n401, pp. 788--791), which introduced an algorithm based on Multiplicative\nUpdates (MU). More recently, another class of methods called Hierarchical\nAlternating Least Squares (HALS) was introduced that seems to be much more\nefficient in practice.\n  In this paper, we consider the problem of approximating a not necessarily\nnonnegative matrix with the product of two nonnegative matrices, which we refer\nto as Nonnegative Factorization (NF); this is the subproblem that HALS methods\nimplicitly try to solve at each iteration. We prove that NF is NP-hard for any\nfixed factorization rank, using a reduction to the maximum edge biclique\nproblem.\n  We also generalize the multiplicative updates to NF, which allows us to shed\nsome light on the differences between the MU and HALS algorithms for NMF and\ngive an explanation for the better performance of HALS. Finally, we link\nstationary points of NF with feasible solutions of the biclique problem to\nobtain a new type of biclique finding algorithm (based on MU) whose iterations\nhave an algorithmic complexity proportional to the number of edges in the\ngraph, and show that it performs better than comparable existing methods. \n\n"}
{"id": "0811.0882", "contents": "Title: The Lyapunov Characteristic Exponents and their computation Abstract: We present a survey of the theory of the Lyapunov Characteristic Exponents\n(LCEs) for dynamical systems, as well as of the numerical techniques developed\nfor the computation of the maximal, of few and of all of them. After some\nhistorical notes on the first attempts for the numerical evaluation of LCEs, we\ndiscuss in detail the multiplicative ergodic theorem of Oseledec \\cite{O_68},\nwhich provides the theoretical basis for the computation of the LCEs. Then, we\nanalyze the algorithm for the computation of the maximal LCE, whose value has\nbeen extensively used as an indicator of chaos, and the algorithm of the\nso--called `standard method', developed by Benettin et al. \\cite{BGGS_80b}, for\nthe computation of many LCEs. We also consider different discrete and\ncontinuous methods for computing the LCEs based on the QR or the singular value\ndecomposition techniques. Although, we are mainly interested in\nfinite--dimensional conservative systems, i. e. autonomous Hamiltonian systems\nand symplectic maps, we also briefly refer to the evaluation of LCEs of\ndissipative systems and time series. The relation of two chaos detection\ntechniques, namely the fast Lyapunov indicator (FLI) and the generalized\nalignment index (GALI), to the computation of the LCEs is also discussed. \n\n"}
{"id": "0811.2478", "contents": "Title: High Order Phase Fitted Multistep Integrators for the Schr\\\"odinger\n  Equation with Improved Frequency Tolerance Abstract: In this work we introduce a new family of 14-steps linear multistep methods\nfor the integration of the Schr\\\"odinger equation. The new methods are phase\nfitted but they are designed in order to improve the frequency tolerance. This\nis achieved by eliminating the first derivatives of the phase lag function at\nthe fitted frequency forcing the phase lag function to be '\\textit{flat}'\nenough in the neighbor of the fitted frequency. The efficiency of the new\nfamily of methods is proved via error analysis and numerical applications. \n\n"}
{"id": "0812.4691", "contents": "Title: Phase transition approach to detecting singularities of PDEs Abstract: We present a mesh refinement algorithm for detecting singularities of\ntime-dependent partial differential equations. The main idea behind the\nalgorithm is to treat the occurrence of singularities of time-dependent partial\ndifferential equations as phase transitions. We show how the mesh refinement\nalgorithm can be used to calculate the blow-up rate as we approach the\nsingularity. This calculation can be done in three different ways: i) the\ndirect approach where one monitors the blowing-up quantity as it approaches the\nsingularity and uses the data to calculate the blow-up rate ; ii) the \"phase\ntransition\" approach (\\`a la Wilson) where one treats the singularity as a\nfixed point of the renormalization flow equation and proceeds to compute the\nblow-up rate via an analysis in the vicinity of the fixed point and iii) the\n\"scaling\" approach (\\`a la Widom-Kadanoff) where one postulates the existence\nof scaling laws for different quantities close to the singularity, computes the\nassociated exponents and then uses them to estimate the blow-up rate. Our\nalgorithm allows a unified presentation of these three approaches. The inviscid\nBurgers equation and the supercritical Schrodinger equation are used as\ninstructive examples to illustrate the constructions. \n\n"}
{"id": "0903.4848", "contents": "Title: General theory for integer-type algorithm for higher order differential\n  equations Abstract: Based on functional analysis, we propose an algorithm for finite-norm\nsolutions of higher-order linear Fuchsian-type ordinary differential equations\n(ODEs) P(x,d/dx)f(x)=0 with P(x,d/dx):=[\\sum_m p_m (x) (d/dx)^m] by using only\nthe four arithmetical operations on integers. This algorithm is based on a\nband-diagonal matrix representation of the differential operator P(x,d/dx),\nthough it is quite different from the usual Galerkin methods. This\nrepresentation is made for the respective CONSs of the input Hilbert space H\nand the output Hilbert space H' of P(x,d/dx). This band-diagonal matrix enables\nthe construction of a recursive algorithm for solving the ODE. However, a\nsolution of the simultaneous linear equations represented by this matrix does\nnot necessarily correspond to the true solution of ODE. We show that when this\nsolution is an l^2 sequence, it corresponds to the true solution of ODE. We\ninvent a method based on an integer-type algorithm for extracting only l^2\ncomponents. Further, the concrete choice of Hilbert spaces H and H' is also\ngiven for our algorithm when p_m is a polynomial or a rational function with\nrational coefficients. We check how our algorithm works based on several\nnumerical demonstrations related to special functions, where the results show\nthat the accuracy of our method is extremely high. \n\n"}
{"id": "0905.2485", "contents": "Title: Minimizing Communication in Linear Algebra Abstract: In 1981 Hong and Kung proved a lower bound on the amount of communication\nneeded to perform dense, matrix-multiplication using the conventional $O(n^3)$\nalgorithm, where the input matrices were too large to fit in the small, fast\nmemory. In 2004 Irony, Toledo and Tiskin gave a new proof of this result and\nextended it to the parallel case. In both cases the lower bound may be\nexpressed as $\\Omega$(#arithmetic operations / $\\sqrt{M}$), where M is the size\nof the fast memory (or local memory in the parallel case). Here we generalize\nthese results to a much wider variety of algorithms, including LU\nfactorization, Cholesky factorization, $LDL^T$ factorization, QR factorization,\nalgorithms for eigenvalues and singular values, i.e., essentially all direct\nmethods of linear algebra. The proof works for dense or sparse matrices, and\nfor sequential or parallel algorithms. In addition to lower bounds on the\namount of data moved (bandwidth) we get lower bounds on the number of messages\nrequired to move it (latency). We illustrate how to extend our lower bound\ntechnique to compositions of linear algebra operations (like computing powers\nof a matrix), to decide whether it is enough to call a sequence of simpler\noptimal algorithms (like matrix multiplication) to minimize communication, or\nif we can do better. We give examples of both. We also show how to extend our\nlower bounds to certain graph theoretic problems.\n  We point out recently designed algorithms for dense LU, Cholesky, QR,\neigenvalue and the SVD problems that attain these lower bounds; implementations\nof LU and QR show large speedups over conventional linear algebra algorithms in\nstandard libraries like LAPACK and ScaLAPACK. Many open problems remain. \n\n"}
{"id": "0905.2764", "contents": "Title: Gradient recovery in adaptive finite element methods for parabolic\n  problems Abstract: We derive energy-norm aposteriori error bounds, using gradient recovery (ZZ)\nestimators to control the spatial error, for fully discrete schemes for the\nlinear heat equation. This appears to be the first completely rigorous\nderivation of ZZ estimators for fully discrete schemes for evolution problems,\nwithout any restrictive assumption on the timestep size. An essential tool for\nthe analysis is the elliptic reconstruction technique.\n  Our theoretical results are backed with extensive numerical experimentation\naimed at (a) testing the practical sharpness and asymptotic behaviour of the\nerror estimator against the error, and (b) deriving an adaptive method based on\nour estimators. An extra novelty provided is an implementation of a coarsening\nerror \"preindicator\", with a complete implementation guide in ALBERTA. \n\n"}
{"id": "0905.4946", "contents": "Title: The hp-BEM with quasi-uniform meshes for the electric field integral\n  equation on polyhedral surfaces: a priori error analysis Abstract: This paper presents an a priori error analysis of the hp-version of the\nboundary element method for the electric field integral equation on a piecewise\nplane (open or closed) Lipschitz surface. We use H(div)-conforming\ndiscretisations with Raviart-Thomas elements on a sequence of quasi-uniform\nmeshes of triangles and/or parallelograms. Assuming the regularity of the\nsolution to the electric field integral equation in terms of Sobolev spaces of\ntangential vector fields, we prove an a priori error estimate of the method in\nthe energy norm. This estimate proves the expected rate of convergence with\nrespect to the mesh parameter h and the polynomial degree p. \n\n"}
{"id": "0906.1360", "contents": "Title: On the effectiveness of a binless entropy estimator for generalised\n  entropic forms Abstract: In this manuscript we discuss the effectiveness of the Kozachenko-Leonenko\nentropy estimator when generalised to cope with entropic forms customarily\napplied to study systems evincing asymptotic scale invariance and dependence\n(either linear or non-linear type). We show that when the variables are\nindependently and identically distributed the estimator is only valuable along\nthe whole domain if the data follow the uniform distribution, whereas for other\ndistributions the estimator is only effectual in the limit of the\nBoltzmann-Gibbs-Shanon entropic form. We also analyse the influence of the\ndependence (linear and non-linear) between variables on the accuracy of the\nestimator between variables. As expected in the last case the estimator looses\nefficiency for the Boltzmann-Gibbs-Shanon entropic form as well. \n\n"}
{"id": "0906.2129", "contents": "Title: Convergence rates of the splitting scheme for parabolic linear\n  stochastic Cauchy problems Abstract: We study the splitting scheme associated with the linear stochastic Cauchy\nproblem dU(t) = AU(t) dt + dW(t), where A is the generator of an analytic\nC_0-semigroup S={S(t)} on a Banach space E and W={W(t)} is a Brownian motion\nwith values in a fractional domain space E_\\b associated with A. We prove that\nif \\a,\\b,\\g,\\th \\ge 0 are such that \\g + \\th < 1 and max[0,(\\a-\\b+\\th)] + \\g <\n1/2, then the approximate solutions U_n (where n is the number of time steps)\nconverge to the solution U in the Holder space C^\\g([0,T];E_\\a), both in\nL^p-means and almost surely, with rate 1/n^\\th. \n\n"}
{"id": "0909.1464", "contents": "Title: Numerical analysis of the planewave discretization of orbital-free and\n  Kohn-Sham models Part I: The Thomas-Fermi-von Weizacker model Abstract: We provide {\\it a priori} error estimates for the spectral and pseudospectral\nFourier (also called planewave) discretizations of the periodic\nThomas-Fermi-von Weizs\\\"acker (TFW) model and of the Kohn-Sham model, within\nthe local density approximation (LDA). These models allow to compute\napproximations of the ground state energy and density of molecular systems in\nthe condensed phase. The TFW model is stricly convex with respect to the\nelectronic density, and allows for a comprehensive analysis (Part I). This is\nnot the case for the Kohn-Sham LDA model, for which the uniqueness of the\nground state electronic density is not guaranteed. Under a coercivity\nassumption on the second order optimality condition, we prove in Part II that\nfor large enough energy cut-offs, the discretized Kohn-Sham LDA problem has a\nminimizer in the vicinity of any Kohn-Sham ground state, and that this\nminimizer is unique up to unitary transform. We then derive optimal {\\it a\npriori} error estimates for both the spectral and the pseudospectral\ndiscretization methods. \n\n"}
{"id": "0909.4061", "contents": "Title: Finding structure with randomness: Probabilistic algorithms for\n  constructing approximate matrix decompositions Abstract: Low-rank matrix approximations, such as the truncated singular value\ndecomposition and the rank-revealing QR decomposition, play a central role in\ndata analysis and scientific computing. This work surveys and extends recent\nresearch which demonstrates that randomization offers a powerful tool for\nperforming low-rank matrix approximation. These techniques exploit modern\ncomputational architectures more fully than classical methods and open the\npossibility of dealing with truly massive data sets.\n  This paper presents a modular framework for constructing randomized\nalgorithms that compute partial matrix decompositions. These methods use random\nsampling to identify a subspace that captures most of the action of a matrix.\nThe input matrix is then compressed---either explicitly or implicitly---to this\nsubspace, and the reduced matrix is manipulated deterministically to obtain the\ndesired low-rank factorization. In many cases, this approach beats its\nclassical competitors in terms of accuracy, speed, and robustness. These claims\nare supported by extensive numerical experiments and a detailed error analysis. \n\n"}
{"id": "0910.2092", "contents": "Title: Finite Elements for a Beam System With Nonlinear Contact Under Periodic\n  Excitation Abstract: Solar arrays are structures which are connected to satellites; during launch,\nthey are in a folded position and submitted to high vibrations. In order to\nsave mass, the flexibility of the panels is not negligible and they may strike\neach other; this may damage the structure. To prevent this, rubber snubbers are\nmounted at well chosen points of the structure; a prestress is applied to the\nsnubber; but it is quite difficult to check the amount of prestress and the\nsnubber may act only on one side; they will be modeled as one sided springs\n(see figure 2). In this article, some analysis for responses (displacements) in\nboth time and frequency domains for a clamped-clamped Euler-Bernoulli beam\nmodel with a spring are presented. This spring can be unilateral or bilateral\nfixed at a point. The mounting (beam +spring) is fixed on a rigid support which\nhas a sinusoidal motion of constant frequency. The system is also studied in\nthe frequency domain by sweeping frequencies between two fixed values, in order\nto save the maximum of displacements corresponding to each frequency. Numerical\nresults are compared with exact solutions in particular cases which already\nexist in the literature. On the other hand, a numerical and theoretical\ninvestigation of nonlinear normal mode (NNM) can be a new method to describe\nnonlinear behaviors, this work is in progress. \n\n"}
{"id": "0911.1815", "contents": "Title: The Penalized Lebesgue Constant for Surface Spline Interpolation Abstract: Problems involving approximation from scattered data where data is arranged\nquasi-uniformly have been treated by RBF methods for decades. Treating data\nwith spatially varying density has not been investigated with the same\nintensity, and is far less well understood. In this article we consider the\nstability of surface spline interpolation (a popular type of RBF interpolation)\nfor data with nonuniform arrangements. Using techniques similar to those\nrecently employed by Hangelbroek, Narcowich and Ward to demonstrate the\nstability of interpolation from quasi-uniform data on manifolds, we show that\nsurface spline interpolation on R^d is stable, but in a stronger, local sense.\nWe also obtain pointwise estimates showing that the Lagrange function decays\nvery rapidly, and at a rate determined by the local spacing of datasites. These\nresults, in conjunction with a Lebesgue lemma, show that surface spline\ninterpolation enjoys the same rates of convergence as those of the local\napproximation schemes recently developed by DeVore and Ron. \n\n"}
{"id": "0911.2011", "contents": "Title: An axisymmetric generalized harmonic evolution code Abstract: We describe the first axisymmetric numerical code based on the generalized\nharmonic formulation of the Einstein equations which is regular at the axis. We\ntest the code by investigating gravitational collapse of distributions of\ncomplex scalar field in a Kaluza-Klein spacetime. One of the key issues of the\nharmonic formulation is the choice of the gauge source functions, and we\nconclude that a damped wave gauge is remarkably robust in this case. Our\npreliminary study indicates that evolution of regular initial data leads to\nformation both of black holes with spherical and cylindrical horizon\ntopologies. Intriguingly, we find evidence that near threshold for black hole\nformation the number of outcomes proliferates. Specifically, the collapsing\nmatter splits into individual pulses, two of which travel in the opposite\ndirections along the compact dimension and one which is ejected radially from\nthe axis. Depending on the initial conditions, a curvature singularity develops\ninside the pulses. \n\n"}
{"id": "0912.3376", "contents": "Title: Convergence rates to deflation of simple shift strategies Abstract: The computation of eigenvalues of real symmetric tridiagonal matrices\nfrequently proceeds by a sequence of QR steps with shifts. We introduce simple\nshift strategies, functions sigma satisfying natural conditions, taking each n\nx n matrix T to a real number sigma(T). The strategy specifies the shift to be\napplied by the QR step at T. Rayleigh and Wilkinson's are examples of simple\nshift strategies. We show that if sigma is continuous then there exist initial\nconditions for which deflation does not occur, i.e., subdiagonal entries do not\ntend to zero. In case of deflation, we consider the rate of convergence to zero\nof the (n, n-1) entry: for simple shift strategies this is always at least\nquadratic. If the function sigma is smooth in a suitable region and the\nspectrum of T does not include three consecutive eigenvalues in arithmetic\nprogression then convergence is cubic. This implies cubic convergence to\ndeflation of Wilkinson's shift for generic spectra. The study of the algorithm\nnear deflation uses tubular coordinates, under which QR steps with shifts are\ngiven by a simple formula. \n\n"}
{"id": "1001.0149", "contents": "Title: Fast construction of hierarchical matrix representation from\n  matrix-vector multiplication Abstract: We develop a hierarchical matrix construction algorithm using matrix-vector\nmultiplications, based on the randomized singular value decomposition of\nlow-rank matrices. The algorithm uses $\\mathcal{O}(\\log n)$ applications of the\nmatrix on structured random test vectors and $\\mathcal{O}(n \\log n)$ extra\ncomputational cost, where $n$ is the dimension of the unknown matrix. Numerical\nexamples on constructing Green's functions for elliptic operators in two\ndimensions show efficiency and accuracy of the proposed algorithm. \n\n"}
{"id": "1001.2219", "contents": "Title: Asymptotic zero distribution of complex orthogonal polynomials\n  associated with Gaussian quadrature Abstract: In this paper we study the asymptotic behavior of a family of polynomials\nwhich are orthogonal with respect to an exponential weight on certain contours\nof the complex plane. The zeros of these polynomials are the nodes for complex\nGaussian quadrature of an oscillatory integral on the real axis with a high\norder stationary point, and their limit distribution is also analyzed. We show\nthat the zeros accumulate along a contour in the complex plane that has the\nS-property in an external field. In addition, the strong asymptotics of the\northogonal polynomials is obtained by applying the nonlinear Deift--Zhou\nsteepest descent method to the corresponding Riemann--Hilbert problem. \n\n"}
{"id": "1001.3128", "contents": "Title: Stochastic perturbation of sweeping process and a convergence result for\n  an associated numerical scheme Abstract: Here we present well-posedness results for first order stochastic\ndifferential inclusions, more precisely for sweeping process with a stochastic\nperturbation. These results are provided in combining both deterministic\nsweeping process theory and methods concerning the reflection of a Brownian\nmotion. In addition, we prove convergence results for a Euler scheme,\ndiscretizing theses stochastic differential inclusions. \n\n"}
{"id": "1002.0453", "contents": "Title: A finite element method with mesh adaptivity for computing vortex states\n  in fast-rotating Bose-Einstein condensates Abstract: Numerical computations of stationary states of fast-rotating Bose-Einstein\ncondensates require high spatial resolution due to the presence of a large\nnumber of quantized vortices. In this paper we propose a low-order finite\nelement method with mesh adaptivity by metric control, as an alternative\napproach to the commonly used high order (finite difference or spectral)\napproximation methods. The mesh adaptivity is used with two different numerical\nalgorithms to compute stationary vortex states: an imaginary time propagation\nmethod and a Sobolev gradient descent method. We first address the basic issue\nof the choice of the variable used to compute new metrics for the mesh\nadaptivity and show that simultaneously refinement using the real and imaginary\npart of the solution is successful. Mesh refinement using only the modulus of\nthe solution as adaptivity variable fails for complicated test cases. Then we\nsuggest an optimized algorithm for adapting the mesh during the evolution of\nthe solution towards the equilibrium state. Considerable computational time\nsaving is obtained compared to uniform mesh computations. The new method is\napplied to compute difficult cases relevant for physical experiments (large\nnonlinear interaction constant and high rotation rates). \n\n"}
{"id": "1002.0887", "contents": "Title: Convergence and Optimal Complexity of Adaptive Finite Element Methods Abstract: In this paper, we study adaptive finite element approximations in a\nperturbation framework, which makes use of the existing adaptive finite element\nanalysis of a linear symmetric elliptic problem. We prove the convergence and\ncomplexity of adaptive finite element methods for a class of elliptic partial\ndifferential equations. For illustration, we apply the general approach to\nobtain the convergence and complexity of adaptive finite element methods for a\nnonsymmetric problem, a nonlinear problem as well as an unbounded coefficient\neigenvalue problem. \n\n"}
{"id": "1002.1801", "contents": "Title: Stable and fast semi-implicit integration of the stochastic\n  Landau-Lifshitz equation Abstract: We propose new semi-implicit numerical methods for the integration of the\nstochastic Landau-Lifshitz equation with built-in angular momentum\nconservation. The performance of the proposed integrators is tested on the 1D\nHeisenberg chain. For this system, our schemes show better stability properties\nand allow us to use considerably larger time steps than standard explicit\nmethods. At the same time, these semi-implicit schemes are also of comparable\naccuracy to and computationally much cheaper than the standard midpoint\nimplicit method. The results are of key importance for atomistic spin dynamics\nsimulations and the study of spin dynamics beyond the macro spin approximation. \n\n"}
{"id": "1002.2950", "contents": "Title: Kinetic relations for undercompressive shock waves. Physical,\n  mathematical, and numerical issues Abstract: Kinetic relations are required in order to characterize nonclassical\nundercompressive shock waves and formulate a well-posed initial value problem\nfor nonlinear hyperbolic systems of conservation laws. Such nonclassical waves\narise in weak solutions of a large variety of physical models: phase\ntransitions, thin liquid films, magnetohydrodynamics, Camassa-Holm model,\nmartensite-austenite materials, semi-conductors, combustion theory, etc. This\nreview presents the research done in the last fifteen years which led the\ndevelopment of the theory of kinetic relations for undercompressive shocks and\nhas now covered many physical, mathematical, and numerical issues. The main\ndifficulty overcome here in our analysis of nonclassical entropy solutions\ncomes from their lack of monotonicity with respect to initial data.\nUndercompressive shocks of hyperbolic conservation laws turn out to exhibit\nfeatures that are very similar to shocks of nonconservative hyperbolic systems,\nwho were investigated earlier by the author. \n\n"}
{"id": "1002.4553", "contents": "Title: The VOLNA code for the numerical modelling of tsunami waves: generation,\n  propagation and inundation Abstract: A novel tool for tsunami wave modelling is presented. This tool has the\npotential of being used for operational purposes: indeed, the numerical code\n\\VOLNA is able to handle the complete life-cycle of a tsunami (generation,\npropagation and run-up along the coast). The algorithm works on unstructured\ntriangular meshes and thus can be run in arbitrary complex domains. This paper\ncontains the detailed description of the finite volume scheme implemented in\nthe code. The numerical treatment of the wet/dry transition is explained. This\npoint is crucial for accurate run-up/run-down computations. Most existing\ntsunami codes use semi-empirical techniques at this stage, which are not always\nsufficient for tsunami hazard mitigation. Indeed the decision to evacuate\ninhabitants is based on inundation maps which are produced with this type of\nnumerical tools. We present several realistic test cases that partially\nvalidate our algorithm. Comparisons with analytical solutions and experimental\ndata are performed. Finally the main conclusions are outlined and the\nperspectives for future research presented. \n\n"}
{"id": "1004.3946", "contents": "Title: On efficiency of Orthogonal Matching Pursuit Abstract: We show that if a matrix $\\Phi$ satisfies the RIP of order $[CK^{1.2}]$ with\nisometry constant $\\dt = c K^{-0.2}$ and has coherence less than $1/(20\nK^{0.8})$, then Orthogonal Matching Pursuit (OMP) will recover $K$-sparse\nsignal $x$ from $y=\\Phi x$ in at most $[CK^{1.2}]$ iterations. This result\nimplies that $K$-sparse signal can be recovered via OMP by $M=O(K^{1.6}\\log N)$\nmeasurements. \n\n"}
{"id": "1005.1252", "contents": "Title: Universal algorithms, mathematics of semirings and parallel computations Abstract: This is a survey paper on applications of mathematics of semirings to\nnumerical analysis and computing. Concepts of universal algorithm and generic\nprogram are discussed. Relations between these concepts and mathematics of\nsemirings are examined. A very brief introduction to mathematics of semirings\n(including idempotent and tropical mathematics) is presented. Concrete\napplications to optimization problems, idempotent linear algebra and interval\nanalysis are indicated. It is known that some nonlinear problems (and\nespecially optimization problems) become linear over appropriate semirings with\nidempotent addition (the so-called idempotent superposition principle). This\nlinearity over semirings is convenient for parallel computations. \n\n"}
{"id": "1005.1930", "contents": "Title: On the Existence of Energy-Preserving Symplectic Integrators Based upon\n  Gauss Collocation Formulae Abstract: We introduce a new family of symplectic integrators depending on a real\nparameter. When the paramer is zero, the corresponding method in the family\nbecomes the classical Gauss collocation formula of order 2s, where s denotes\nthe number of the internal stages. For any given non-null value of the\nparameter, the corresponding method remains symplectic and has order 2s-2:\nhence it may be interpreted as an order 2s-2 (symplectic) perturbation of the\nGauss method. Under suitable assumptions, we show that the free parameter may\nbe properly tuned, at each step of the integration procedure, so as to\nguarantee energy conservation in the numerical solution. The resulting\nsymplectic, energy conserving method shares the same order 2s as the generating\nGauss formula. \n\n"}
{"id": "1005.2201", "contents": "Title: Multi-product operator splitting as a general method of solving\n  autonomous and non-autonomous equations Abstract: Prior to the recent development of symplectic integrators, the time-stepping\noperator $\\e^{h(A+B)}$ was routinely decomposed into a sum of products of\n$\\e^{h A}$ and $\\e^{hB}$ in the study of hyperbolic partial differential\nequations. In the context of solving Hamiltonian dynamics, we show that such a\ndecomposition give rises to both {\\it even} and {\\it odd} order Runge-Kutta and\nNystr\\\"om integrators. By use of Suzuki's forward-time derivative operator to\nenforce the time-ordered exponential, we show that the same decomposition can\nbe used to solve non-autonomous equations. In particular, odd order algorithms\nare derived on the basis of a highly non-trivial {\\it time-asymmetric} kernel.\nSuch an operator approach provides a general and unified basis for\nunderstanding structure non-preserving algorithms and is especially useful in\nderiving very high-order algorithms via {\\it analytical} extrapolations. In\nthis work, algorithms up to the 100th order are tested by integrating the\nground state wave function of the hydrogen atom. For such a singular Coulomb\nproblem, the multi-product expansion showed uniform convergence and is free of\npoles usually associated with structure-preserving methods. Other examples are\nalso discussed. \n\n"}
{"id": "1005.4246", "contents": "Title: A Hybrid Godunov Method for Radiation Hydrodynamics Abstract: From a mathematical perspective, radiation hydrodynamics can be thought of as\na system of hyperbolic balance laws with dual multiscale behavior (multiscale\nbehavior associated with the hyperbolic wave speeds as well as multiscale\nbehavior associated with source term relaxation). With this outlook in mind,\nthis paper presents a hybrid Godunov method for one-dimensional radiation\nhydrodynamics that is uniformly well behaved from the photon free streaming\n(hyperbolic) limit through the weak equilibrium diffusion (parabolic) limit and\nto the strong equilibrium diffusion (hyperbolic) limit. Moreover, one finds\nthat the technique preserves certain asymptotic limits. The method incorporates\na backward Euler upwinding scheme for the radiation energy density and flux as\nwell as a modified Godunov scheme for the material density, momentum density,\nand energy density. The backward Euler upwinding scheme is first-order accurate\nand uses an implicit HLLE flux function to temporally advance the radiation\ncomponents according to the material flow scale. The modified Godunov scheme is\nsecond-order accurate and directly couples stiff source term effects to the\nhyperbolic structure of the system of balance laws. This Godunov technique is\ncomposed of a predictor step that is based on Duhamel's principle and a\ncorrector step that is based on Picard iteration. The Godunov scheme is\nexplicit on the material flow scale but is unsplit and fully couples matter and\nradiation without invoking a diffusion-type approximation for radiation\nhydrodynamics. This technique derives from earlier work by Miniati & Colella\n2007. Numerical tests demonstrate that the method is stable, robust, and\naccurate across various parameter regimes. \n\n"}
{"id": "1006.1624", "contents": "Title: Gravitational Collapse of Phantom Fluid in (2+1)-Dimensions Abstract: This investigation is devoted to the solutions of Einstein's field equations\nfor a circularly symmetric anisotropic fluid, with kinematic self-similarity of\nthe first kind, in $(2+1)$-dimensional spacetimes. In the case where the radial\npressure vanishes, we show that there exists a solution of the equations that\nrepresents the gravitational collapse of an anisotropic fluid, and this\ncollapse will eventually form a black hole, even when it is constituted by the\nphantom energy. \n\n"}
{"id": "1006.3100", "contents": "Title: A drift homotopy Monte Carlo approach to particle filtering for\n  multi-target tracking Abstract: We present a novel approach for improving particle filters for multi-target\ntracking. The suggested approach is based on drift homotopy for stochastic\ndifferential equations. Drift homotopy is used to design a Markov Chain Monte\nCarlo step which is appended to the particle filter and aims to bring the\nparticle filter samples closer to the observations. Also, we present a simple\nMetropolis Monte Carlo algorithm for tackling the target-observation\nassociation problem. We have used the proposed approach on the problem of\nmulti-target tracking for both linear and nonlinear observation models. The\nnumerical results show that the suggested approach can improve significantly\nthe performance of a particle filter. \n\n"}
{"id": "1006.3592", "contents": "Title: Boundary quasi-orthogonality and sharp inclusion bounds for large\n  Dirichlet eigenvalues Abstract: We study eigenfunctions and eigenvalues of the Dirichlet Laplacian on a\nbounded domain $\\Omega\\subset\\RR^n$ with piecewise smooth boundary. We bound\nthe distance between an arbitrary parameter $E > 0$ and the spectrum $\\{E_j \\}$\nin terms of the boundary $L^2$-norm of a normalized trial solution $u$ of the\nHelmholtz equation $(\\Delta + E)u = 0$. We also bound the $L^2$-norm of the\nerror of this trial solution from an eigenfunction. Both of these results are\nsharp up to constants, hold for all $E$ greater than a small constant, and\nimprove upon the best-known bounds of Moler--Payne by a factor of the\nwavenumber $\\sqrt{E}$. One application is to the solution of eigenvalue\nproblems at high frequency, via, for example, the method of particular\nsolutions. In the case of planar, strictly star-shaped domains we give an\ninclusion bound where the constant is also sharp. We give explicit constants in\nthe theorems, and show a numerical example where an eigenvalue around the\n2500th is computed to 14 digits of relative accuracy. The proof makes use of a\nnew quasi-orthogonality property of the boundary normal derivatives of the\neigenmodes, of interest in its own right. \n\n"}
{"id": "1006.4657", "contents": "Title: Structure preserving Stochastic Impulse Methods for stiff Langevin\n  systems with a uniform global error of order 1 or 1/2 on position Abstract: Impulse methods are generalized to a family of integrators for Langevin\nsystems with quadratic stiff potentials and arbitrary soft potentials. Uniform\nerror bounds (independent from stiff parameters) are obtained on integrated\npositions allowing for coarse integration steps. The resulting integrators are\nexplicit and structure preserving (quasi-symplectic for Langevin systems). \n\n"}
{"id": "1006.5127", "contents": "Title: On the maximum rank of a real binary form Abstract: We show that a real homogeneous polynomial f(x,y) with distinct roots and\ndegree d greater or equal than 3 has d real roots if and only if for any (a,b)\nnot equal to (0,0) the polynomial af_x+bf_y has d-1 real roots. This answers to\na question posed by P. Comon and G. Ottaviani, and shows that the interior part\nof the locus of degree d binary real binary forms of rank equal to d is given\nexactly by the forms with d real roots. \n\n"}
{"id": "1006.5252", "contents": "Title: Decomposition Approach for Low-rank Matrix Completion Abstract: In this paper, we describe a low-rank matrix completion method based on\nmatrix decomposition. An incomplete matrix is decomposed into submatrices which\nare filled with a proposed trimming step and then are recombined to form a\nlow-rank completed matrix. The divide-and-conquer approach can significantly\nreduce computation complexity and storage requirement. Moreover, the proposed\ndecomposition method can be naturally incorporated into any existing matrix\ncompletion methods to attain further gain. Unlike most existing approaches, the\nproposed method is not based on norm minimization nor SVD decomposition. This\nmakes it possible to be applied beyond real domain and can be used in arbitrary\nfields including finite fields. \n\n"}
{"id": "1007.2825", "contents": "Title: Scattered Data Interpolation on Embedded Submanifolds with Restricted\n  Positive Definite Kernels: Sobolev Error Estimates Abstract: In this paper we investigate the approximation properties of kernel\ninterpolants on manifolds. The kernels we consider will be obtained by the\nrestriction of positive definite kernels on $\\R^d$, such as radial basis\nfunctions (RBFs), to a smooth, compact embedded submanifold $\\M\\subset \\R^d$.\nFor restricted kernels having finite smoothness, we provide a complete\ncharacterization of the native space on $\\M$. After this and some preliminary\nsetup, we present Sobolev-type error estimates for the interpolation problem.\nNumerical results verifying the theory are also presented for a one-dimensional\ncurve embedded in $\\R^3$ and a two-dimensional torus. \n\n"}
{"id": "1007.2893", "contents": "Title: An unfitted $hp$-interface penalty finite element method for elliptic\n  interface problems Abstract: An $hp$ version of interface penalty finite element method ($hp$-IPFEM) is\nproposed for elliptic interface problems in two and three dimensions on\nunfitted meshes. Error estimates in broken $H^1$ norm, which are optimal with\nrespect to $h$ and suboptimal with respect to $p$ by half an order of $p$, are\nderived. Both symmetric and non-symmetric IPFEM are considered. Error estimates\nin $L^2$ norm are proved by the duality argument. \n\n"}
{"id": "1007.3612", "contents": "Title: Deformed Mittag-Leffler Polynomials Abstract: The starting point of this paper are the Mittag-Leffler polynomials\nintroduced by H. Bateman [1]. Based on generalized integer powers of real\nnumbers and deformed exponential function, we introduce deformed Mittag-Leffler\npolynomials defined by appropriate generating function. We investigate their\nrecurrence relations, differential properties and orthogonality. Since they\nhave all zeros on imaginary axes, we also consider real polynomials with real\nzeros associated to them. \n\n"}
{"id": "1007.4920", "contents": "Title: Optimally swimming Stokesian robots Abstract: We study self propelled stokesian robots composed of assemblies of balls, in\ndimensions 2 and 3, and prove that they are able to control their position and\norientation. This is a result of controllability, and its proof relies on\napplying Chow's theorem in an analytic framework, similarly to what has been\ndone in [3] for an axisymmetric system swimming along the axis of symmetry.\nHowever, we simplify drastically the analyticity result given in [3] and apply\nit to a situation where more complex swimmers move either in a plane or in\nthree-dimensional space, hence experiencing also rotations. We then focus our\nattention on energetically optimal strokes, which we are able to compute\nnumerically. Some examples of computed optimal strokes are discussed in detail. \n\n"}
{"id": "1008.0562", "contents": "Title: Discrete maximum principle and a Delaunay-type mesh condition for linear\n  finite element approximations of two-dimensional anisotropic diffusion\n  problems Abstract: The finite element solution of two-dimensional anisotropic diffusion problems\nis considered. A Delaunay-type mesh condition is developed for linear finite\nelement approximations to satisfy a discrete maximum principle. The condition\nis shown to be weaker than the existing anisotropic non-obtuse angle condition.\nIt reduces to the well known Delaunay condition for the special case with the\nidentity diffusion matrix. Numerical results are presented to verify the\ntheoretical findings. \n\n"}
{"id": "1008.2138", "contents": "Title: Analysis of Energy-Based Blended Quasicontinuum Approximations Abstract: The development of patch test consistent quasicontinuum energies for\nmulti-dimensional crystalline solids modeled by many-body potentials remains a\nchallenge. The original quasicontinuum energy (QCE) has been implemented for\nmany-body potentials in two and three space dimensions, but it is not patch\ntest consistent. We propose that by blending the atomistic and corresponding\nCauchy-Born continuum models of QCE in an interfacial region with thickness of\na small number $k$ of blended atoms, a general quasicontinuum energy (BQCE) can\nbe developed with the potential to significantly improve the accuracy of QCE\nnear lattice instabilities such as dislocation formation and motion. In this\npaper, we give an error analysis of the blended quasicontinuum energy (BQCE)\nfor a periodic one-dimensional chain of atoms with next-nearest neighbor\ninteractions. Our analysis includes the optimization of the blending function\nfor an improved convergence rate. We show that the $\\ell^2$ strain error for\nthe non-blended QCE energy (QCE), which has low order\n$\\text{O}(\\epsilon^{1/2})$ where $\\epsilon$ is the atomistic length scale, can\nbe reduced by a factor of $k^{3/2}$ for an optimized blending function where\n$k$ is the number of atoms in the blending region. The QCE energy has been\nfurther shown to suffer from a O$(1)$ error in the critical strain at which the\nlattice loses stability. We prove that the error in the critical strain of BQCE\ncan be reduced by a factor of $k^2$ for an optimized blending function, thus\ndemonstrating that the BQCE energy for an optimized blending function has the\npotential to give an accurate approximation of the deformation near lattice\ninstabilities such as crack growth. \n\n"}
{"id": "1008.3845", "contents": "Title: A stabilized mixed formulation for unsteady Brinkman equation based on\n  the method of horizontal lines Abstract: In this paper, we present a stabilized mixed formulation for unsteady\nBrinkman equation. The formulation is systematically derived based on the\nvariational multiscale formalism and the method of horizontal lines. The\nderivation does not need the assumption that the fine-scale variables do not\ndepend on the time, which is the case with the conventional derivation of\nmultiscale stabilized formulations for transient mixed problems. An expression\nfor the stabilization parameter is obtained in terms of a bubble function, and\nappropriate bubble functions for various finite elements are also presented.\nUnder the proposed formulation, equal-order interpolation for the velocity and\npressure (which is computationally the most convenient) is stable.\nRepresentative numerical results are presented to illustrate the performance of\nthe proposed formulation. Spatial and temporal convergence studies are also\nperformed, and the proposed formulation performed well. \n\n"}
{"id": "1008.3895", "contents": "Title: Discrete gradient algorithms of high order for one-dimensional systems Abstract: We show how to increase the order of one-dimensional discrete gradient\nnumerical integrator without losing its advantages, such as exceptional\nstability, exact conservation of the energy integral and exact preservation of\nthe trajectories in the phase space. The accuracy of our integrators is higher\nby several orders of magnitude as compared with the standard discrete gradient\nscheme (modified midpoint rule) and, what is more, our schemes have very high\naccuracy even for large time steps. \n\n"}
{"id": "1008.4791", "contents": "Title: Numerical comparisons among some methods for Hamiltonian problems Abstract: We report a few sumerical tests comparing some newly defined\nenergy-preserving integrators and symplectic methods, using either constant and\nvariable stepsize. \n\n"}
{"id": "1008.5035", "contents": "Title: Recovering Fourier coefficients of modular forms and factoring of\n  integers Abstract: It is shown that if a function defined on the segment [-1,1] has sufficiently\ngood approximation by partial sums of the Legendre polynomial expansion, then,\ngiven the function's Fourier coefficients $c_n$ for some subset of\n$n\\in[n_1,n_2]$, one may approximately recover them for all $n\\in[n_1,n_2]$. As\nan application, a new approach to factoring of integers is given. \n\n"}
{"id": "1009.0197", "contents": "Title: Image Inpainting Based On Coherence Transport With Adapted Distance\n  Functions Abstract: We discuss an extension of our method Image Inpainting Based on Coherence\nTransport. For the latter method the pixels of the inpainting domain have to be\nserialized into an ordered list. Up till now, to induce the serialization we\nhave used the distance to boundary map. But there are inpainting problems where\nthe distance to boundary serialization causes unsatisfactory inpainting\nresults. In the present work we demonstrate cases where we can resolve the\ndifficulties by employing other distance functions which better suit the\nproblem at hand. \n\n"}
{"id": "1009.0625", "contents": "Title: Period Doubling Renormalization for Area-Preserving Maps and Mild\n  Computer Assistance in Contraction Mapping Principle Abstract: It has been observed that the famous Feigenbaum-Coullet-Tresser period\ndoubling universality has a counterpart for area-preserving maps of ${\\fR}^2$.\nA renormalization approach has been used in a \"hard\" computer-assisted proof of\nexistence of an area-preserving map with orbits of all binary periods in\nEckmann et al (1984). As it is the case with all non-trivial universality\nproblems in non-dissipative systems in dimensions more than one, no analytic\nproof of this period doubling universality exists to date.\n  In this paper we attempt to reduce computer assistance in the argument, and\npresent a mild computer aided proof of the analyticity and compactness of the\nrenormalization operator in a neighborhood of a renormalization fixed point:\nthat is a proof that does not use generalizations of interval arithmetics to\nfunctional spaces - but rather relies on interval arithmetics on real numbers\nonly to estimate otherwise explicit expressions. The proof relies on several\ninstance of the Contraction Mapping Principle, which is, again, verified via\nmild computer assistance. \n\n"}
{"id": "1009.2065", "contents": "Title: Templates for Convex Cone Problems with Applications to Sparse Signal\n  Recovery Abstract: This paper develops a general framework for solving a variety of convex cone\nproblems that frequently arise in signal processing, machine learning,\nstatistics, and other fields. The approach works as follows: first, determine a\nconic formulation of the problem; second, determine its dual; third, apply\nsmoothing; and fourth, solve using an optimal first-order method. A merit of\nthis approach is its flexibility: for example, all compressed sensing problems\ncan be solved via this approach. These include models with objective\nfunctionals such as the total-variation norm, ||Wx||_1 where W is arbitrary, or\na combination thereof. In addition, the paper also introduces a number of\ntechnical contributions such as a novel continuation scheme, a novel approach\nfor controlling the step size, and some new results showing that the smooth and\nunsmoothed problems are sometimes formally equivalent. Combined with our\nframework, these lead to novel, stable and computationally efficient\nalgorithms. For instance, our general implementation is competitive with\nstate-of-the-art methods for solving intensively studied problems such as the\nLASSO. Further, numerical experiments show that one can solve the Dantzig\nselector problem, for which no efficient large-scale solvers exist, in a few\nhundred iterations. Finally, the paper is accompanied with a software release.\nThis software is not a single, monolithic solver; rather, it is a suite of\nprograms and routines designed to serve as building blocks for constructing\ncomplete algorithms. \n\n"}
{"id": "1009.2588", "contents": "Title: Evolution of plane curves with a curvature adjusted tangential velocity Abstract: We study evolution of a closed embedded plane curve with the normal velocity\ndepending on the curvature, the orientation and the position of the curve. We\npropose a new method of tangential redistribution of points by curvature\nadjusted control in the tangential motion of evolving curves. The tangential\nvelocity distributes grid points along the curve not only uniform but also lead\nto a suitable concentration and/or dispersion depending on the curvature. Our\nstudy is based on solutions to the governing system of nonlinear parabolic\nequations for the position vector, tangent angle and curvature of a curve. We\nfurthermore present a semi-implicit numerical discretization scheme based on\nthe flowing finite volume method. Several numerical examples illustrating\ncapability of the new tangential redistribution method are also presented in\nthis paper. \n\n"}
{"id": "1009.2738", "contents": "Title: Energy-preserving numerical schemes of high accuracy for one-dimensional\n  Hamiltonian systems Abstract: We present a class of non-standard numerical schemes which are modifications\nof the discrete gradient method. They preserve the energy integral exactly (up\nto the round-off error). The considered class contains locally exact discrete\ngradient schemes and integrators of arbitrary high order. In numerical\nexperiments we compare our integrators with some other numerical schemes,\nincluding the standard discrete gradient method, the leap-frog scheme and a\nsymplectic scheme of 4th order. We study the error accumulation for very long\ntime and the conservation of the energy integral. \n\n"}
{"id": "1009.3165", "contents": "Title: A unifying framework for the derivation and analysis of effective\n  classes of one-step methods for ODEs Abstract: In this paper, we provide a simple framework to derive and analyse several\nclasses of effective one-step methods. The framework consists in the\ndiscretization of a local Fourier expansion of the continuous problem.\nDifferent choices of the basis lead to different classes of methods, even\nthough we shall here consider only the case of an orthonormal polynomial basis,\nfrom which a large subclass of Runge-Kutta methods is derived. The obtained\nresults are then applied to prove, in a simplified way, the order and stability\nproperties of Hamiltonian BVMs (HBVMs), a recently introduced class of energy\npreserving methods for canonical Hamiltonian systems. A few numerical tests\nwith such methods are also included, in order to confirm the effectiveness of\nthe methods. \n\n"}
{"id": "1010.2745", "contents": "Title: High-order quantum algorithm for solving linear differential equations Abstract: Linear differential equations are ubiquitous in science and engineering.\nQuantum computers can simulate quantum systems, which are described by a\nrestricted type of linear differential equations. Here we extend quantum\nsimulation algorithms to general inhomogeneous sparse linear differential\nequations, which describe many classical physical systems. We examine the use\nof high-order methods to improve the efficiency. These provide scaling close to\n$\\Delta t^2$ in the evolution time $\\Delta t$. As with other algorithms of this\ntype, the solution is encoded in amplitudes of the quantum state, and it is\npossible to extract global features of the solution. \n\n"}
{"id": "1010.4839", "contents": "Title: Rational Approximation Formula for Chandrasekhar's H-function for\n  Isotropic Scattering Abstract: We first establish a simple procedure to obtain with 11-figure accuracy the\nvalues of Chandrasekhar's H-function for isotropic scattering using a\nclosed-form integral representation and the Gauss-Legendre quadrature. Based on\nthe numerical values of the function produced by this method for various values\nof the single scattering albedo and the cosine of the azimuth angle of the\ndirection of radiation emergent from or incident upon a semi-infinite\nscattering-absorbing medium, we propose a rational approximation formula, which\nallows us to reproduce the correct values of the H-function within a relative\nerror of 2.1/100000 without recourse to any iterative procedure or root-finding\nprocess. \n\n"}
{"id": "1011.3443", "contents": "Title: On the spectral vanishing viscosity method for periodic fractional\n  conservation laws Abstract: We introduce and analyze a spectral vanishing viscosity approximation of\nperiodic fractional conservation laws. The fractional part of these equations\ncan be a fractional Laplacian or other non-local operators that are generators\nof pure jump L\\'{e}vy processes. To accommodate for shock solutions, we first\nextend to the periodic setting the Kru\\v{z}kov-Alibaud entropy formulation and\nprove well-posedness. Then we introduce the numerical method, which is a\nnon-linear Fourier Galerkin method with an additional spectral viscosity term.\nThis type of approximation was first introduced by Tadmor for pure conservation\nlaws. We prove that this {\\em non-monotone} method converges to the entropy\nsolution of the problem, that it retains the spectral accuracy of the Fourier\nmethod, and that it diagonalizes the fractional term reducing dramatically the\ncomputational cost induced by this term. We also derive a robust $L^1$-error\nestimate, and provide numerical experiments for the fractional Burgers'\nequation. \n\n"}
{"id": "1012.2323", "contents": "Title: A note on the efficient implementation of Hamiltonian BVMs Abstract: We discuss the efficient implementation of Hamiltonian BVMs (HBVMs), a\nrecently introduced class of energy preserving methods for canonical\nHamiltonian systems, via their blended formulation. We also discuss the case of\nseparable problems, for which the structure of the problem can be exploited to\ngain efficiency. \n\n"}
{"id": "1012.5055", "contents": "Title: Convergence of frozen Gaussian approximation for high frequency wave\n  propagation Abstract: The frozen Gaussian approximation provides a highly efficient computational\nmethod for high frequency wave propagation. The derivation of the method is\nbased on asymptotic analysis. In this paper, for general linear strictly\nhyperbolic system, we establish the rigorous convergence result for frozen\nGaussian approximation. As a byproduct, higher order frozen Gaussian\napproximation is developed. \n\n"}
{"id": "1101.0944", "contents": "Title: Inequalities for Convex and s-Convex Functions on\n  {\\delta}=[a,b]$\\times$[c,d] Abstract: In this paper, two new lemmas are proved and inequalities are established for\nco-ordinated convex functions and co-ordinated s-convex functions. \n\n"}
{"id": "1101.1577", "contents": "Title: Sharp Support Recovery from Noisy Random Measurements by L1 minimization Abstract: In this paper, we investigate the theoretical guarantees of penalized $\\lun$\nminimization (also called Basis Pursuit Denoising or Lasso) in terms of\nsparsity pattern recovery (support and sign consistency) from noisy\nmeasurements with non-necessarily random noise, when the sensing operator\nbelongs to the Gaussian ensemble (i.e. random design matrix with i.i.d.\nGaussian entries). More precisely, we derive sharp non-asymptotic bounds on the\nsparsity level and (minimal) signal-to-noise ratio that ensure support\nidentification for most signals and most Gaussian sensing matrices by solving\nthe Lasso problem with an appropriately chosen regularization parameter. Our\nfirst purpose is to establish conditions allowing exact sparsity pattern\nrecovery when the signal is strictly sparse. Then, these conditions are\nextended to cover the compressible or nearly sparse case. In these two results,\nthe role of the minimal signal-to-noise ratio is crucial. Our third main result\ngets rid of this assumption in the strictly sparse case, but this time, the\nLasso allows only partial recovery of the support. We also provide in this case\na sharp $\\ell_2$-consistency result on the coefficient vector. The results of\nthe present work have several distinctive features compared to previous ones.\nOne of them is that the leading constants involved in all the bounds are sharp\nand explicit. This is illustrated by some numerical experiments where it is\nindeed shown that the sharp sparsity level threshold identified by our\ntheoretical results below which sparsistency of the Lasso is guaranteed meets\nthat empirically observed. \n\n"}
{"id": "1101.5546", "contents": "Title: Solvability by semigroup : Application to seismic imaging with complex\n  decomposition of wave equations and migration operators with idempotents Abstract: The classical approach of solvability using group theory is well known and\none original motivation is to solve polynomials by radicals. Radicals are\nsquare, cube, square root, cube root etc of the original coefficients for the\npolynomial. A polynomial is solvable by radicals if the permutation group is\nsolvable. This is exact solvability via group theory. With modern computers, we\nmight need to relax our definition of exact solvability and move towards\npractical solvability. We will address seismic imaging as an example of\npractical solvability by semigroup theory. The difference between semigroup and\ngroup is that the semigroup operators do not have to be invertible as in group\noperators. Using the metaphor of complex decomposition, we will decompose an\noperator into simple part and complex part. The simple part of the operator is\nsolvable by numerical methods. The complex part of the operator is\ninterpretable but not numerically solvable. It is sometimes called the\nevanescent energy in geophysics. \n\n"}
{"id": "1102.2245", "contents": "Title: Differential forms, fluids, and finite models Abstract: By rewriting the Navier-Stokes equation in terms of differential forms we\ngive a formulation which is abstracted and reproduced in a finite dimensional\nsetting. We give two examples of these finite models and, in the latter case,\nprove some approximation results. Some useful properties of these finite models\nare derived. \n\n"}
{"id": "1102.3136", "contents": "Title: Representation of the Lagrange reconstructing polynomial by combination\n  of substencils Abstract: The Lagrange reconstructing polynomial [Shu C.W.: {\\em SIAM Rev.} {\\bf 51}\n(2009) 82--126] of a function $f(x)$ on a given set of equidistant ($\\Delta\nx=\\const$) points $\\bigl\\{x_i+\\ell\\Delta x;\\;\\ell\\in\\{-M_-,...,+M_+\\}\\bigr\\}$\nis defined [Gerolymos G.A.: {\\em J. Approx. Theory} {\\bf 163} (2011) 267--305]\nas the polynomial whose sliding (with $x$) averages on $[x-\\tfrac{1}{2}\\Delta\nx,x+\\tfrac{1}{2}\\Delta x]$ are equal to the Lagrange interpolating polynomial\nof $f(x)$ on the same stencil. We first study the fundamental functions of\nLagrange reconstruction, show that these polynomials have only real and\ndistinct roots, which are never located at the cell-interfaces (half-points)\n$x_i+n\\tfrac{1}{2}\\Delta x$ ($n\\in\\mathbb{Z}$), and obtain several identities.\nUsing these identities, by analogy to the recursive Neville-Aitken-like\nalgorithm applied to the Lagrange interpolating polynomial, we show that there\nexists a unique representation of the Lagrange reconstructing polynomial on\n$\\{i-M_-,...,i+M_+\\}$ as a combination of the Lagrange reconstructing\npolynomials on the $K_\\mathrm{s}+1\\leq M:=M_-+M_+>1$ substencils\n$\\{i-M_-+k_\\mathrm{s},...,i+M_+-K_\\mathrm{s}+k_\\mathrm{s}\\}$\n($k_\\mathrm{s}\\in\\{0,...,K_\\mathrm{s}\\}$), with weights\n$\\sigma_{R_1,M_-,M_+,K_\\mathrm{s},k_\\mathrm{s}}(\\xi)$ which are rational\nfunctions of $\\xi$ ($x=x_i+\\xi\\Delta x$) [Liu Y.Y., Shu C.W., Zhang M.P.: {\\em\nActa Math. Appl. Sinica} {\\bf 25} (2009) 503--538], and give an analytical\nrecursive expression of the weight-functions. We then use the analytical\nexpression of the weight-functions\n$\\sigma_{R_1,M_-,M_+,K_\\mathrm{s},k_\\mathrm{s}}(\\xi)$ to obtain a formal proof\nof convexity (positivity of the weight-functions) in the neighborhood of\n$\\xi=\\tfrac{1}{2}$, under the condition that all of the substencils contain\neither point $i$ or point $i+1$ (or both). \n\n"}
{"id": "1102.3440", "contents": "Title: Efficient numerical computation of the Pfaffian for dense and banded\n  skew-symmetric matrices Abstract: Computing the Pfaffian of a skew-symmetric matrix is a problem that arises in\nvarious fields of physics. Both computing the Pfaffian and a related problem,\ncomputing the canonical form of a skew-symmetric matrix under unitary\ncongruence, can be solved easily once the skew-symmetric matrix has been\nreduced to skew-symmetric tridiagonal form. We develop efficient numerical\nmethods for computing this tridiagonal form based on Gauss transformations,\nusing a skew-symmetric, blocked form of the Parlett-Reid algorithm, or based on\nunitary transformations, using block Householder transformations and Givens\nrotations, that are applicable to dense and banded matrices, respectively. We\nalso give a complete and fully optimized implementation of these algorithms in\nFortran, and also provide Python, Matlab and Mathematica implementations for\nconvenience. Finally, we apply these methods to compute the topological charge\nof a class D nanowire, and show numerically the equivalence of definitions\nbased on the Hamiltonian and the scattering matrix. \n\n"}
{"id": "1103.0066", "contents": "Title: Finite Element Integration on GPUs Abstract: We present a novel finite element integration method for low order elements\non GPUs. We achieve more than 100GF for element integration on first order\ndiscretizations of both the Laplacian and Elasticity operators. \n\n"}
{"id": "1103.1986", "contents": "Title: Stochastic exponential integrators for finite element discretization of\n  SPDEs for multiplicative and additive noise Abstract: We consider the numerical approximation of a general second order\nsemi--linear parabolic stochastic partial differential equation (SPDEs) driven\nby space-time noise, for multiplicative and additive noise. We examine\nconvergence of exponential integrators for multiplicative and additive noise.\nWe consider noise that is in trace class and give a convergence proof in the\nmean square $L^{2}$ norm. We discretize in space with the finite element method\nand in our implementation we examine both the finite element and the finite\nvolume methods. We present results for a linear reaction diffusion equation in\ntwo dimensions as well as a nonlinear example of two-dimensional stochastic\nadvection diffusion reaction equation motivated from realistic porous media\nflow. \n\n"}
{"id": "1103.2948", "contents": "Title: Full analysis of the Green's function for a singularly perturbed\n  convection-diffusion problem in three dimensions Abstract: A linear singularly perturbed convection-diffusion problem with\ncharacteristic layers is considered in three dimensions. Sharp bounds for the\nassociated Green's function and its derivatives are established in the $L_1$\nnorm. The dependence of these bounds on the small perturbation parameter is\nshown explicitly. The obtained estimates will be used in a forthcoming\nnumerical analysis of the considered problem.\n  The present article is a more detailed version of our recent paper [7]. \n\n"}
{"id": "1103.4645", "contents": "Title: Variational and linearly-implicit integrators, with applications Abstract: We show that symplectic and linearly-implicit integrators proposed by [Zhang\nand Skeel, 1997] are variational linearizations of Newmark methods. When used\nin conjunction with penalty methods (i.e., methods that replace constraints by\nstiff potentials), these integrators permit coarse time-stepping of\nholonomically constrained mechanical systems and bypass the resolution of\nnonlinear systems. Although penalty methods are widely employed, an explicit\nlink to Lagrange multiplier approaches appears to be lacking; such a link is\nnow provided (in the context of two-scale flow convergence [Tao, Owhadi and\nMarsden, 2010]). The variational formulation also allows efficient simulations\nof mechanical systems on Lie groups. \n\n"}
{"id": "1104.2365", "contents": "Title: Instantaneous frequency and wave shape functions (I) Abstract: Although one can formulate an intuitive notion of instantaneous frequency,\ngeneralizing \"frequency\" as we understand it in e.g. the Fourier transform, a\nrigorous mathematical definition is lacking. In this paper, we consider a class\nof functions composed of waveforms that repeat nearly periodically, and for\nwhich the instantaneous frequency can be given a rigorous meaning. We show that\nSynchrosqueezing can be used to determine the instantaneous frequency of\nfunctions in this class, even if the waveform is not harmonic, thus\ngeneralizing earlier results for cosine wave functions. We also provide\nreal-life examples and discuss the advantages, for these examples, of\nconsidering such non-harmonic waveforms. \n\n"}
{"id": "1104.3151", "contents": "Title: Solving or resolving global tomographic models with spherical wavelets,\n  and the scale and sparsity of seismic heterogeneity Abstract: We propose a class of spherical wavelet bases for the analysis of geophysical\nmodels and forthe tomographic inversion of global seismic data. Its\nmultiresolution character allows for modeling with an effective spatial\nresolution that varies with position within the Earth. Our procedure is\nnumerically efficient and can be implemented with parallel computing. We\ndiscuss two possible types of discrete wavelet transforms in the angular\ndimension of the cubed sphere. We discuss benefits and drawbacks of these\nconstructions and apply them to analyze the information present in two\npublished seismic wavespeed models of the mantle, for the statistics and power\nof wavelet coefficients across scales. The localization and sparsity properties\nof wavelet bases allow finding a sparse solution to inverse problems by\niterative minimization of a combination of the $\\ell_2$ norm of data fit and\nthe $\\ell_1$ norm on the wavelet coefficients. By validation with realistic\nsynthetic experiments we illustrate the likely gains of our new approach in\nfuture inversions of finite-frequency seismic data and show its readiness for\nglobal seismic tomography. \n\n"}
{"id": "1105.1214", "contents": "Title: A Substitution to Bernoulli Numbers in easier computation of (\\zeta(2k)) Abstract: An alternative formula is presented for the evaluation of the zeta function\nvalues $\\zeta(2k)$ without the need for Bernoulli numbers. Our formula is\nrecursive, and improves the efficiency with which we can calculate large values\nof the zeta function. \n\n"}
{"id": "1105.1838", "contents": "Title: Alternative Jacobi Polynomials and Orthogonal Exponentials Abstract: Sequences of orthogonal polynomials that are alternative to the Jacobi\npolynomials on the interval $[0,1]$ are defined and their properties are\nestablished. An $(\\alpha,\\beta)$-parameterized system of orthogonal polynomials\nof the exponential function on the semi-axis $[0,\\infty)$ is presented. Two\nsubsystems of the alternative Jacobi polynomials, as well as orthogonal\nexponential polynomials are described. Two parameterized systems of discretely\nalmost orthogonal functions on the interval $[0,1]$ are introduced. \n\n"}
{"id": "1105.3021", "contents": "Title: Widths of embeddings of 2-microlocal Besov spaces Abstract: We consider the asymptotic behaviour of the approximation, Gelfand and\nKolmogorov numbers of compact embeddings between 2-microlocal Besov spaces with\nweights defined in terms of the distance to a $d$-set $U\\subset \\mathbb{R}^n$.\nThe sharp estimates are shown in most cases, where the quasi-Banach setting is\nincluded. \n\n"}
{"id": "1105.4095", "contents": "Title: Theoretical Considerations on the Computation of Generalized\n  Time-Periodic Waves Abstract: We present both, theory and an algorithm for solving time-harmonic wave\nproblems in a general setting. The time-harmonic solutions will be achieved by\ncomputing time-periodic solutions of the original wave equations. Thus, an\nexact controllability technique is proposed to solve the time-dependent wave\nequations. We discuss a first order Maxwell type system, which will be\nformulated in the framework of alternating differential forms. This enables us\nto investigate different kinds of classical wave problems in one fell swoop,\nsuch as acoustic, electro-magnetic or elastic wave problems. After a sufficient\ntheory is established, we formulate our exact controllability problem and\nsuggest a least-squares optimization procedure for its solution, which itself\nis solved in a natural way by a conjugate gradient algorithm operating in the\ncanonical Hilbert space. Therefore, it might be one of the biggest advances of\nthis approach that the proposed conjugate gradient algorithm does not need any\npreconditioning. \n\n"}
{"id": "1106.0598", "contents": "Title: A Two Step, Fourth Order, Nearly-Linear Method with Energy Preserving\n  Properties Abstract: We introduce a family of fourth order two-step methods that preserve the\nenergy function of canonical polynomial Hamiltonian systems. Each method in the\nfamily may be viewed as a correction of a linear two-step method, where the\ncorrection term is O(h^5) (h is the stepsize of integration). The key tools the\nnew methods are based upon are the line integral associated with a conservative\nvector field (such as the one defined by a Hamiltonian dynamical system) and\nits discretization obtained by the aid of a quadrature formula. Energy\nconservation is equivalent to the requirement that the quadrature is exact,\nwhich turns out to be always the case in the event that the Hamiltonian\nfunction is a polynomial and the degree of precision of the quadrature formula\nis high enough. The non-polynomial case is also discussed and a number of test\nproblems are finally presented in order to compare the behavior of the new\nmethods to the theoretical results. \n\n"}
{"id": "1106.2327", "contents": "Title: A framework for coupled deformation-diffusion analysis with application\n  to degradation/healing Abstract: This paper deals with the formulation and numerical implementation of a fully\ncoupled continuum model for deformation-diffusion in linearized elastic solids.\nThe mathematical model takes into account the effect of the deformation on the\ndiffusion process, and the affect of the transport of an inert chemical species\non the deformation of the solid. We then present a robust computational\nframework for solving the proposed mathematical model, which consists of\ncoupled non-linear partial differential equations. It should be noted that many\npopular numerical formulations may produce unphysical negative values for the\nconcentration, particularly, when the diffusion process is anisotropic. The\nviolation of the non-negative constraint by these numerical formulations is not\nmere numerical noise. In the proposed computational framework we employ a novel\nnumerical formulation that will ensure that the concentration of the diffusant\nbe always non-negative, which is one of the main contributions of this paper.\nRepresentative numerical examples are presented to show the robustness,\nconvergence, and performance of the proposed computational framework. Another\ncontribution of this paper is to systematically study the affect of transport\nof the diffusant on the deformation of the solid and vice-versa, and their\nimplication in modeling degradation/healing of materials. We show that the\ncoupled response is both qualitatively and quantitatively different from the\nuncoupled response. \n\n"}
{"id": "1106.3694", "contents": "Title: A time-parallel algorithm for almost integrable Hamiltonian systems Abstract: We introduce a time-parallel algorithm for solving numerically almost\nintegrable Hamiltonian systems in action-angle coordinates. This algorithm is a\nrefinement of that introduced by Saha, Stadel and Tremaine in 1997 (SST97) for\nthe same type of problems. Our refined algorithm has a better convergence\nobtained from the use of derivatives of the perturbing term not considered in\nthe original SST97 algorithm. An advantage of this algorithm is its\nindependence of the step-size for the parallelized procedures which can be\nconsider as a particular case of the parareal scheme. \n\n"}
{"id": "1106.6014", "contents": "Title: On the expected number of zeros of nonlinear equations Abstract: This paper investigates the expected number of complex roots of nonlinear\nequations. Those equations are assumed to be analytic, and to belong to certain\ninner product spaces. Those spaces are then endowed with the Gaussian\nprobability distribution.\n  The root count on a given domain is proved to be `additive' with respect to a\nproduct operation of functional spaces. This allows to deduce a general theorem\nrelating the expected number of roots for unmixed and mixed systems. Examples\nof root counts for equations that are not polynomials nor exponential sums are\ngiven at the end. \n\n"}
{"id": "1107.3424", "contents": "Title: A numerical study of infinitely renormalizable area-preserving maps Abstract: It has been shown in (Gaidashev et al, 2010) and (Gaidashev et al, 2011) that\ninfinitely renormalizable area-preserving maps admit invariant Cantor sets with\na maximal Lyapunov exponent equal to zero. Furthermore, the dynamics on these\nCantor sets for any two infinitely renormalizable maps is conjugated by a\ntransformation that extends to a differentiable function whose derivative is\nHolder continuous of exponent alpha>0.\n  In this paper we investigate numerically the specific value of alpha. We also\npresent numerical evidence that the normalized derivative cocycle with the base\ndynamics in the Cantor set is ergodic. Finally, we compute renormalization\neigenvalues to a high accuracy to support a conjecture that the renormalization\nspectrum is real. \n\n"}
{"id": "1108.4181", "contents": "Title: A fast parallel algorithm for solving block-tridiagonal systems of\n  linear equations including the domain decomposition method Abstract: In this study, we develop a new parallel algorithm for solving systems of\nlinear algebraic equations with the same block-tridiagonal matrix but with\ndifferent right-hand sides. The method is a generalization of the parallel\ndichotomy algorithm for solving systems of linear equations with tridiagonal\nmatrices \\cite{terekhov:Dichotomy}. Using this approach, we propose a parallel\nrealization of the domain decomposition method (\\mbox{the Schur} complement\nmethod). The calculation of acoustic wave fields using the spectral-difference\ntechnique improves the efficiency of the parallel algorithms. A near-linear\ndependence of the speedup with the number of processors is attained using both\nseveral and several thousands of processors. This study is innovative because\nthe parallel algorithm developed for solving block-tridiagonal systems of\nequations is an effective and simple set of procedures for solving engineering\ntasks on a supercomputer. \n\n"}
{"id": "1108.5409", "contents": "Title: An efficient second order in time scheme for approximating long time\n  statistical properties of the two dimensional Navier-Stokes equations Abstract: We investigate the long tim behavior of the following efficient second order\nin time scheme for the 2D Navier-Stokes equation in a periodic box: $$\n\\frac{3\\omega^{n+1}-4\\omega^n+\\omega^{n-1}}{2k} +\n\\nabla^\\perp(2\\psi^n-\\psi^{n-1})\\cdot\\nabla(2\\omega^n-\\omega^{n-1}) -\n\\nu\\Delta\\omega^{n+1} = f^{n+1}, \\quad -\\Delta \\psi^n = \\om^n. $$ The scheme is\na combination of a 2nd order in time backward-differentiation (BDF) and a\nspecial explicit Adams-Bashforth treatment of the advection term. Therefore\nonly a linear constant coefficient Poisson type problem needs to be solved at\neach time step. We prove uniform in time bounds on this scheme in $\\dL2$,\n$\\dH1$ and $\\dot{H}^2_{per}$ provided that the time-step is sufficiently small.\nThese time uniform estimates further lead to the convergence of long time\nstatistics (stationary statistical properties) of the scheme to that of the NSE\nitself at vanishing time-step. Fully discrete schemes with either Galerkin\nFourier or collocation Fourier spectral method are also discussed. \n\n"}
{"id": "1111.0618", "contents": "Title: A Computational Study of the Weak Galerkin Method for Second-Order\n  Elliptic Equations Abstract: The weak Galerkin finite element method is a novel numerical method that was\nfirst proposed and analyzed by Wang and Ye for general second order elliptic\nproblems on triangular meshes. The goal of this paper is to conduct a\ncomputational investigation for the weak Galerkin method for various model\nproblems with more general finite element partitions. The numerical results\nconfirm the theory established by Wang and Ye. The results also indicate that\nthe weak Galerkin method is efficient, robust, and reliable in scientific\ncomputing. \n\n"}
{"id": "1111.1524", "contents": "Title: Multiscale Finite Element approach for \"weakly\" random problems and\n  related issues Abstract: We address multiscale elliptic problems with random coefficients that are a\nperturbation of multiscale deterministic problems. Our approach consists in\ntaking benefit of the perturbative context to suitably modify the classical\nFinite Element basis into a deterministic multiscale Finite Element basis. The\nlatter essentially shares the same approximation properties as a multiscale\nFinite Element basis directly generated on the random problem. The specific\nreference method that we use is the Multiscale Finite Element Method. Using\nnumerical experiments, we demonstrate the efficiency of our approach and the\ncomputational speed-up with respect to a more standard approach. We provide a\ncomplete analysis of the approach, extending that available for the\ndeterministic setting. \n\n"}
{"id": "1111.3827", "contents": "Title: Analytical computation of moderate-degree fully-symmetric cubature rules\n  on the triangle Abstract: A method is developed to compute analytically fully symmetric cubature rules\non the triangle by using symmetric polynomials to express the two kinds of\ninvariance inherent in these rules. Rules of degree up to 15, some of them new\nand of good quality, are computed and presented. \n\n"}
{"id": "1112.1960", "contents": "Title: Convergence of the alternating split Bregman algorithm in\n  infinite-dimensional Hilbert spaces Abstract: We prove results on weak convergence for the alternating split Bregman\nalgorithm in infinite dimensional Hilbert spaces. We also show convergence of\nan approximate split Bregman algorithm, where errors are allowed at each step\nof the computation. To be able to treat the infinite dimensional case, our\nproofs focus mostly on the dual problem. We rely on Svaiter's theorem on weak\nconvergence of the Douglas-Rachford splitting algorithm and on the relation\nbetween the alternating split Bregman and Douglas-Rachford splitting algorithms\ndiscovered by Setzer. Our motivation for this study is to provide a convergent\nalgorithm for weighted least gradient problems arising in the hybrid method of\nimaging electric conductivity from interior knowledge (obtainable by MRI) of\nthe magnitude of one current. \n\n"}
{"id": "1112.1998", "contents": "Title: A convergent algorithm for the hybrid problem of reconstructing\n  conductivity from minimal interior data Abstract: We consider the hybrid problem of reconstructing the isotropic electric\nconductivity of a body $\\Omega$ from interior Current Density Imaging data\nobtainable using MRI measurements. We only require knowledge of the magnitude\n$|J|$ of one current generated by a given voltage $f$ on the boundary\n$\\partial\\Omega$. As previously shown, the corresponding voltage potential u in\n$\\Omega$ is a minimizer of the weighted least gradient problem\n  \\[u=\\hbox{argmin} \\{\\int_{\\Omega}a(x)|\\nabla u|: u \\in H^{1}(\\Omega), \\ \\\nu|_{\\partial \\Omega}=f\\},\\] with $a(x)= |J(x)|$. In this paper we present an\nalternating split Bregman algorithm for treating such least gradient problems,\nfor $a\\in L^2(\\Omega)$ non-negative and $f\\in H^{1/2}(\\partial \\Omega)$. We\ngive a detailed convergence proof by focusing to a large extent on the dual\nproblem. This leads naturally to the alternating split Bregman algorithm. The\ndual problem also turns out to yield a novel method to recover the full vector\nfield $J$ from knowledge of its magnitude, and of the voltage $f$ on the\nboundary. We then present several numerical experiments that illustrate the\nconvergence behavior of the proposed algorithm. \n\n"}
{"id": "1112.3550", "contents": "Title: Parameter Estimation of Fiber Lay-down in Nonwoven Production - An\n  Occupation Time Approach- Abstract: In this paper we investigate the parameter estimation of the fiber lay-down\nprocess in the production of nonwovens. The parameter estimation is based on\nthe mass per unit area data, which is available at least on an industrial\nscale. We introduce a stochastic model to represent the fiber lay-down and\nthrough the model's parameters we characterize this fiber lay-down. Based on\nthe occupation time, which is the equivalent quantity for the mass per unit\narea in the context of stochastic dynamical systems, an optimization procedure\nis formulated that estimates the parameters of the model. The optimization\nprocedure is tested using occupation time data given by Monte-Carlo\nsimulations. The feasibility of the optimization procedure on an industrial\nlevel is tested using the fiber paths simulated by the industrial software\nFYDIST. \n\n"}
{"id": "1112.4379", "contents": "Title: Calculating Determinants of Block Matrices Abstract: This paper presents a method for expressing the determinant of an N {\\times}\nN complex block matrix in terms of its constituent blocks. The result allows\none to reduce the determinant of a matrix with N^2 blocks to the product of the\ndeterminants of N distinct combinations of single blocks. This procedure proves\nuseful in the analytic description of physical systems with multiple discrete\nvariables, as it provides a systematic method for evaluating determinants which\nmight otherwise be analytically intractable. \n\n"}
{"id": "1112.4465", "contents": "Title: On algebraic structures of numerical integration on vector spaces and\n  manifolds Abstract: Numerical analysis of time-integration algorithms has been applying advanced\nalgebraic techniques for more than fourty years. An explicit description of the\ngroup of characters in the Butcher-Connes-Kreimer Hopf algebra first appeared\nin Butcher's work on composition of integration methods in 1972. In more recent\nyears, the analysis of structure preserving algorithms, geometric integration\ntechniques and integration algorithms on manifolds have motivated the\nincorporation of other algebraic structures in numerical analysis. In this\npaper we will survey structures that have found applications within these\nareas. This includes pre-Lie structures for the geometry of flat and torsion\nfree connections appearing in the analysis of numerical flows on vector spaces.\nThe much more recent post-Lie and D-algebras appear in the analysis of flows on\nmanifolds with flat connections with constant torsion. Dynkin and Eulerian\nidempotents appear in the analysis of non-autonomous flows and in backward\nerror analysis. Non-commutative Bell polynomials and a non-commutative Fa\\`a di\nBruno Hopf algebra are other examples of structures appearing naturally in the\nnumerical analysis of integration on manifolds. \n\n"}
{"id": "1201.0327", "contents": "Title: Local Linear Regression on Manifolds and its Geometric Interpretation Abstract: High-dimensional data analysis has been an active area, and the main focuses\nhave been variable selection and dimension reduction. In practice, it occurs\noften that the variables are located on an unknown, lower-dimensional nonlinear\nmanifold. Under this manifold assumption, one purpose of this paper is\nregression and gradient estimation on the manifold, and another is developing a\nnew tool for manifold learning. To the first aim, we suggest directly reducing\nthe dimensionality to the intrinsic dimension $d$ of the manifold, and\nperforming the popular local linear regression (LLR) on a tangent plane\nestimate. An immediate consequence is a dramatic reduction in the computation\ntime when the ambient space dimension $p\\gg d$. We provide rigorous theoretical\njustification of the convergence of the proposed regression and gradient\nestimators by carefully analyzing the curvature, boundary, and non-uniform\nsampling effects. A bandwidth selector that can handle heteroscedastic errors\nis proposed. To the second aim, we analyze carefully the behavior of our\nregression estimator both in the interior and near the boundary of the\nmanifold, and make explicit its relationship with manifold learning, in\nparticular estimating the Laplace-Beltrami operator of the manifold. In this\ncontext, we also make clear that it is important to use a smaller bandwidth in\nthe tangent plane estimation than in the LLR. Simulation studies and the Isomap\nface data example are used to illustrate the computational speed and estimation\naccuracy of our methods. \n\n"}
{"id": "1201.4090", "contents": "Title: Adaptive finite elements with anisotropic meshes Abstract: The paper presents a numerical study for the finite element method with\nanisotropic meshes. We compare the accuracy of the numerical solutions on\nquasi-uniform, isotropic, and anisotropic meshes for a test problem which\ncombines several difficulties of a corner singularity, a peak, a boundary\nlayer, and a wavefront. Numerical experiment clearly shows the advantage of\nanisotropic mesh adaptation. The conditioning of the resulting linear equation\nsystem is addressed as well. In particular, it is shown that the conditioning\nwith adaptive anisotropic meshes is not as bad as generally assumed. \n\n"}
{"id": "1201.4409", "contents": "Title: Mixed Mimetic Spectral Element Method for Stokes Flow: A Pointwise\n  Divergence-Free Solution Abstract: In this paper we apply the recently developed mimetic discretization method\nto the mixed formulation of the Stokes problem in terms of vorticity, velocity\nand pressure. The mimetic discretization presented in this paper and in [50] is\na higher-order method for curvilinear quadrilaterals and hexahedrals.\nFundamental is the underlying structure of oriented geometric objects, the\nrelation between these objects through the boundary operator and how this\ndefines the exterior derivative, representing the grad, curl and div, through\nthe generalized Stokes theorem. The mimetic method presented here uses the\nlanguage of differential $k$-forms with $k$-cochains as their discrete\ncounterpart, and the relations between them in terms of the mimetic operators:\nreduction, reconstruction and projection. The reconstruction consists of the\nrecently developed mimetic spectral interpolation functions. The most important\nresult of the mimetic framework is the commutation between differentiation at\nthe continuous level with that on the finite dimensional and discrete level. As\na result operators like gradient, curl and divergence are discretized exactly.\nFor Stokes flow, this implies a pointwise divergence-free solution. This is\nconfirmed using a set of test cases on both Cartesian and curvilinear meshes.\nIt will be shown that the method converges optimally for all admissible\nboundary conditions. \n\n"}
{"id": "1201.4465", "contents": "Title: Pathwise Holder convergence of the implicit Euler scheme for semi-linear\n  SPDEs with multiplicative noise Abstract: In this article we prove pathwise Holder convergence with optimal rates of\nthe implicit Euler scheme for semi-linear parabolic stochastic differential\nequations with multiplicative noise, set in a UMD Banach space X. We assume the\nnon-linearities to satisfy appropriate (local) Lipschitz conditions. The\nconvergence results are obtained by first proving corresponding results for the\nsplitting scheme. The results are applied to a class of second order parabolic\nSPDEs driven by multiplicative space-time white noise. \n\n"}
{"id": "1201.6009", "contents": "Title: On formation of a locally self-similar collapse in the incompressible\n  Euler equations Abstract: The paper addresses the question of existence of a locally self-similar\nblow-up for the incompressible Euler equations. Several exclusion results are\nproved based on the $L^p$-condition for velocity or vorticity and for a range\nof scaling exponents. In particular, in $N$ dimensions if in self-similar\nvariables $u \\in L^p$ and $u \\sim \\frac{1}{t^{\\a/(1+\\a)}}$, then the blow-up\ndoes not occur provided $\\a >N/2$ or $-1<\\a\\leq N/p$. This includes the $L^3$\ncase natural for the Navier-Stokes equations. For $\\a = N/2$ we exclude\nprofiles with an asymptotic power bounds of the form $ |y|^{-N-1+\\d} \\lesssim\n|u(y)| \\lesssim |y|^{1-\\d}$. Homogeneous near infinity solutions are eliminated\nas well except when homogeneity is scaling invariant. \n\n"}
{"id": "1201.6438", "contents": "Title: Weak Galerkin Methods for Second Order Elliptic Interface Problems Abstract: Weak Galerkin methods refer to general finite element methods for PDEs in\nwhich differential operators are approximated by their weak forms as\ndistributions. Such weak forms give rise to desirable flexibilities in\nenforcing boundary and interface conditions. A weak Galerkin finite element\nmethod (WG-FEM) is developed in this paper for solving elliptic partial\ndifferential equations (PDEs) with discontinuous coefficients and interfaces.\nThe paper also presents many numerical tests for validating the WG-FEM for\nsolving second order elliptic interface problems. For such interface problems,\nthe solution possesses a certain singularity due to the nonsmoothness of the\ninterface. A challenge in research is to design high order numerical methods\nthat work well for problems with low regularity in the solution. The best known\nnumerical scheme in the literature is of order one for the solution itself in\n$L_\\infty$ norm. It is demonstrated that the WG-FEM of lowest order is capable\nof delivering numerical approximations that are of order 1.75 in the usual\n$L_\\infty$ norm for $C^1$ or Lipschitz continuous interfaces associated with a\n$C^1$ or $H^2$ continuous solutions. Theoretically, it is proved that high\norder of numerical schemes can be designed by using the WG-FEM with polynomials\nof high order on each element. \n\n"}
{"id": "1202.3094", "contents": "Title: Approximating rough stochastic PDEs Abstract: We study approximations to a class of vector-valued equations of Burgers type\ndriven by a multiplicative space-time white noise. A solution theory for this\nclass of equations has been developed recently in [Hairer, Weber, Probab.\nTheory Related Fields, to appear]. The key idea was to use the theory of\ncontrolled rough paths to give definitions of weak / mild solutions and to set\nup a Picard iteration argument.\n  In this article the limiting behaviour of a rather large class of (spatial)\napproximations to these equations is studied. These approximations are shown to\nconverge and convergence rates are given, but the limit may depend on the\nparticular choice of approximation. This effect is a spatial analogue to the\nIt\\^o-Stratonovich correction in the theory of stochastic ordinary differential\nequations, where it is well known that different approximation schemes may\nconverge to different solutions. \n\n"}
{"id": "1202.5443", "contents": "Title: Divided Differences of Implicit Functions Abstract: Under general conditions, the equation $g(x,y) = 0$ implicitly defines $y$\nlocally as a function of $x$. In this article, we express divided differences\nof $y$ in terms of bivariate divided differences of $g$, generalizing a recent\nresult on divided differences of inverse functions. \n\n"}
{"id": "1202.5621", "contents": "Title: Data-Driven Time-Frequency Analysis Abstract: In this paper, we introduce a new adaptive data analysis method to study\ntrend and instantaneous frequency of nonlinear and non-stationary data. This\nmethod is inspired by the Empirical Mode Decomposition method (EMD) and the\nrecently developed compressed (compressive) sensing theory. The main idea is to\nlook for the sparsest representation of multiscale data within the largest\npossible dictionary consisting of intrinsic mode functions of the form $\\{a(t)\n\\cos(\\theta(t))\\}$, where $a \\in V(\\theta)$, $V(\\theta)$ consists of the\nfunctions smoother than $\\cos(\\theta(t))$ and $\\theta'\\ge 0$. This problem can\nbe formulated as a nonlinear $L^0$ optimization problem. In order to solve this\noptimization problem, we propose a nonlinear matching pursuit method by\ngeneralizing the classical matching pursuit for the $L^0$ optimization problem.\nOne important advantage of this nonlinear matching pursuit method is it can be\nimplemented very efficiently and is very stable to noise. Further, we provide a\nconvergence analysis of our nonlinear matching pursuit method under certain\nscale separation assumptions. Extensive numerical examples will be given to\ndemonstrate the robustness of our method and comparison will be made with the\nEMD/EEMD method. We also apply our method to study data without scale\nseparation, data with intra-wave frequency modulation, and data with incomplete\nor under-sampled data. \n\n"}
{"id": "1202.5710", "contents": "Title: Sparse grid quadrature on products of spheres Abstract: We examine sparse grid quadrature on weighted tensor products (WTP) of\nreproducing kernel Hilbert spaces on products of the unit sphere, in the case\nof worst case quadrature error for rules with arbitrary quadrature weights. We\ndescribe a dimension adaptive quadrature algorithm based on an algorithm of\nHegland (2003), and also formulate a version of Wasilkowski and Wozniakowski's\nWTP algorithm (1999), here called the WW algorithm. We prove that the dimension\nadaptive algorithm is optimal in the sense of Dantzig (1957) and therefore no\ngreater in cost than the WW algorithm. Both algorithms therefore have the\noptimal asymptotic rate of convergence given by Theorem 3 of Wasilkowski and\nWozniakowski (1999). A numerical example shows that, even though the asymptotic\nconvergence rate is optimal, if the dimension weights decay slowly enough, and\nthe dimensionality of the problem is large enough, the initial convergence of\nthe dimension adaptive algorithm can be slow. \n\n"}
{"id": "1203.0522", "contents": "Title: Idempotent/tropical analysis, the Hamilton-Jacobi and Bellman equations Abstract: Tropical and idempotent analysis with their relations to the Hamilton-Jacobi\nand matrix Bellman equations are discussed. Some dequantization procedures are\nimportant in tropical and idempotent mathematics. In particular, the\nHamilton-Jacobi-Bellman equation is treated as a result of the Maslov\ndequantization applied to the Schr\\\"{o}dinger equation. This leads to a\nlinearity of the Hamilton-Jacobi-Bellman equation over tropical algebras. The\ncorrespondence principle and the superposition principle of idempotent\nmathematics are formulated and examined. The matrix Bellman equation and its\napplications to optimization problems on graphs are discussed. Universal\nalgorithms for numerical algorithms in idempotent mathematics are investigated.\nIn particular, an idempotent version of interval analysis is briefly discussed. \n\n"}
{"id": "1203.3233", "contents": "Title: Weak attractor of the Klein-Gordon field in discrete space-time\n  interacting with a nonlinear oscillator Abstract: We consider the U(1)-invariant nonlinear Klein-Gordon equation in discrete\nspace and discrete time, which is the discretization of the nonlinear\ncontinuous Klein-Gordon equation. To obtain this equation, we use the\nenergy-conserving finite-difference scheme of Strauss-Vazquez. We prove that\neach finite energy solution converges as $t\\to\\pm\\infty$ to the\nfinite-dimensional set of all multifrequency solitary wave solutions with one,\ntwo, and four frequencies. The components of the solitary manifold\ncorresponding to the solitary waves of the first two types are generically\ntwo-dimensional, while the component corresponding to the last type is\ngenerically four-dimensional. The attraction to the set of solitary waves is\ncaused by the nonlinear energy transfer from lower harmonics to the continuous\nspectrum and subsequent radiation.\n  For the proof, we develop the well-posedness for the nonlinear wave equation\nin discrete space-time, apply the technique of quasimeasures, and also obtain\nthe version of the Titchmarsh convolution theorem for distributions on the\ncircle. \n\n"}
{"id": "1203.3279", "contents": "Title: Fifth Order Runge-Kutta-Nystr\\\"om Methods with Complex Coefficients Abstract: We present fifth order Runge-Kutta-Nystr\\\"om methods, where we allow the\ntimestep coefficients to assume complex values. Among the methods with complex\ntimesteps, we focus on the ones with the coefficients that have positive real\nparts. This property makes them suitable for problems where a negative\ncoefficient is not acceptable. In addition, the leading order terms in the\nerror expansion of these methods are purely imaginary, effectively increasing\nthe order of the methods by one for real variables. \n\n"}
{"id": "1203.4738", "contents": "Title: On post-Lie algebras, Lie--Butcher series and moving frames Abstract: Pre-Lie (or Vinberg) algebras arise from flat and torsion-free connections on\ndifferential manifolds. They have been studied extensively in recent years,\nboth from algebraic operadic points of view and through numerous applications\nin numerical analysis, control theory, stochastic differential equations and\nrenormalization. Butcher series are formal power series founded on pre-Lie\nalgebras, used in numerical analysis to study geometric properties of flows on\neuclidean spaces. Motivated by the analysis of flows on manifolds and\nhomogeneous spaces, we investigate algebras arising from flat connections with\nconstant torsion, leading to the definition of post-Lie algebras, a\ngeneralization of pre-Lie algebras. Whereas pre-Lie algebras are intimately\nassociated with euclidean geometry, post-Lie algebras occur naturally in the\ndifferential geometry of homogeneous spaces, and are also closely related to\nCartan's method of moving frames. Lie--Butcher series combine Butcher series\nwith Lie series and are used to analyze flows on manifolds. In this paper we\nshow that Lie--Butcher series are founded on post-Lie algebras. The functorial\nrelations between post-Lie algebras and their enveloping algebras, called\nD-algebras, are explored. Furthermore, we develop new formulas for computations\nin free post-Lie algebras and D-algebras, based on recursions in a magma, and\nwe show that Lie--Butcher series are related to invariants of curves described\nby moving frames. \n\n"}
{"id": "1203.5157", "contents": "Title: A characterization of Sobolev spaces on the sphere and an extension of\n  Stolarsky's invariance principle to arbitrary smoothness Abstract: In this paper we study reproducing kernel Hilbert spaces of arbitrary\nsmoothness on the sphere $\\mathbb{S}^d \\subset \\mathbb{R}^{d+1}$. The\nreproducing kernel is given by an integral representation using the truncated\npower function $(\\boldsymbol{x} \\cdot \\boldsymbol{z} - t)_+^{\\beta-1}$ defined\non spherical caps centered at $\\boldsymbol{z}$ of height $t$, which reduce to\nan integral over indicator functions of spherical caps as studied in [J.\nBrauchart, J. Dick, arXiv:1101.4448v1 [math.NA], to appear in Proc. Amer. Math.\nSoc.] for $\\beta = 1$. This is in analogy to the generalization of the\nreproducing kernel to arbitrary smoothness on the unit cube.\n  We show that the reproducing kernel is a sum of a Kamp{\\'e} de F{\\'e}riet\nfunction and the Euclidean distance $\\|\\boldsymbol{x}-\\boldsymbol{y}\\|$ of the\narguments of the kernel raised to the power of $2\\beta -1$ if $2\\beta - 1$ is\nnot an even integer; otherwise the logarithm of the distance\n$\\|\\boldsymbol{x}-\\boldsymbol{y}\\|$ appears. For $\\beta \\in \\mathbb{N}$ the\nKamp\\'e de F\\'eriet function reduces to a polynomial, giving a simple closed\nform expression for the reproducing kernel.\n  Using this space we can generalize Stolarsky's invariance principle to\narbitrary smoothness. Previously, Warnock's formula, which is the analogue to\nStolarsky's invariance principle for the unit cube $[0,1]^s$, has been\ngeneralized using similar techniques [J. Dick, Ann. Mat. Pura. Appl., (4) 187\n(2008), no. 3, 385--403]. \n\n"}
{"id": "1203.6030", "contents": "Title: Revisiting the D-iteration method: from theoretical to practical\n  computation cost Abstract: In this paper, we revisit the D-iteration algorithm in order to better\nexplain its connection to the Gauss-Seidel method and different performance\nresults that were observed. In particular, we study here the practical\ncomputation cost based on the execution runtime compared to the theoretical\nnumber of iterations. We also propose an exact formula of the error for\nPageRank class of equations. \n\n"}
{"id": "1204.0819", "contents": "Title: Numerical Analysis of Parallel Replica Dynamics Abstract: Parallel replica dynamics is a method for accelerating the computation of\nprocesses characterized by a sequence of infrequent events. In this work, the\nprocesses are governed by the overdamped Langevin equation. Such processes\nspend much of their time about the minima of the underlying potential,\noccasionally transitioning into different basins of attraction. The essential\nidea of parallel replica dynamics is that the exit time distribution from a\ngiven well for a single process can be approximated by the minimum of the exit\ntime distributions of $N$ independent identical processes, each run for only\n1/N-th the amount of time.\n  While promising, this leads to a series of numerical analysis questions about\nthe accuracy of the exit distributions. Building upon the recent work in Le\nBris et al., we prove a unified error estimate on the exit distributions of the\nalgorithm against an unaccelerated process. Furthermore, we study a dephasing\nmechanism, and prove that it will successfully complete. \n\n"}
{"id": "1204.3655", "contents": "Title: Weak Galerkin Finite Element Methods on Polytopal Meshes Abstract: This paper introduces a new weak Galerkin (WG) finite element method for\nsecond order elliptic equations on polytopal meshes. This method, called\nWG-FEM, is designed by using a discrete weak gradient operator applied to\ndiscontinuous piecewise polynomials on finite element partitions of arbitrary\npolytopes with certain shape regularity. The paper explains how the numerical\nschemes are designed and why they provide reliable numerical approximations for\nthe underlying partial differential equations. In particular, optimal order\nerror estimates are established for the corresponding WG-FEM approximations in\nboth a discrete $H^1$ norm and the standard $L^2$ norm. Numerical results are\npresented to demonstrate the robustness, reliability, and accuracy of the\nWG-FEM. All the results are derived for finite element partitions with\npolytopes. Allowing the use of discontinuous approximating functions on\narbitrary polytopal elements is a highly demanded feature for numerical\nalgorithms in scientific computing. \n\n"}
{"id": "1204.4441", "contents": "Title: Comment on `The tan {\\theta} theorem with relaxed conditions', by Y.\n  Nakatsukasa Abstract: We show that in case of the spectral norm, one of the main results of the\nrecent paper \"The tan {\\theta} theorem with relaxed conditions\", by Yuji\nNakatsukasa, published in Linear Algebra and its Applications is a corollary of\nthe tan {\\theta} theorem proven in [V.Kostrykin, K.A.Makarov, and\nA.K.Motovilov, On the existence of solutions to the operator Riccati equation\nand the tan {\\theta} theorem, IEOT 51 (2005), 121-140]. We also give an\nalternative finite-dimensional matrix formulation of another tan {\\theta}\ntheorem proven in [S.Albeverio and A.K.Motovilov, The a priori tan {\\theta}\ntheorem for spectral subspaces, IEOT 73 (2012), 413-430]. \n\n"}
{"id": "1204.5926", "contents": "Title: A micro-macro parareal algorithm: application to singularly perturbed\n  ordinary differential equations Abstract: We introduce a micro-macro parareal algorithm for the time-parallel\nintegration of multiscale-in-time systems. The algorithm first computes a\ncheap, but inaccurate, solution using a coarse propagator (simulating an\napproximate slow macroscopic model), which is iteratively corrected using a\nfine-scale propagator (accurately simulating the full microscopic dynamics).\nThis correction is done in parallel over many subintervals, thereby reducing\nthe wall-clock time needed to obtain the solution, compared to the integration\nof the full microscopic model. We provide a numerical analysis of the algorithm\nfor a prototypical example of a micro-macro model, namely singularly perturbed\nordinary differential equations. We show that the computed solution converges\nto the full microscopic solution (when the parareal iterations proceed) only if\nspecial care is taken during the coupling of the microscopic and macroscopic\nlevels of description. The convergence rate depends on the modeling error of\nthe approximate macroscopic model. We illustrate these results with numerical\nexperiments. \n\n"}
{"id": "1205.2124", "contents": "Title: Analysis of Schr\\\"odinger operators with inverse square potentials I:\n  regularity results in 3D Abstract: Let $V$ be a potential on $\\RR^3$ that is smooth everywhere except at a\ndiscrete set $\\maS$ of points, where it has singularities of the form\n$Z/\\rho^2$, with $\\rho(x) = |x - p|$ for $x$ close to $p$ and $Z$ continuous on\n$\\RR^3$ with $Z(p) > -1/4$ for $p \\in \\maS$. Also assume that $\\rho$ and $Z$\nare smooth outside $\\maS$ and $Z$ is smooth in polar coordinates around each\nsingular point. We either assume that $V$ is periodic or that the set $\\maS$ is\nfinite and $V$ extends to a smooth function on the radial compactification of\n$\\RR^3$ that is bounded outside a compact set containing $\\maS$. In the\nperiodic case, we let $\\Lambda$ be the periodicity lattice and define $\\TT :=\n\\RR^3/ \\Lambda$. We obtain regularity results in weighted Sobolev space for the\neigenfunctions of the Schr\\\"odinger-type operator $H = -\\Delta + V$ acting on\n$L^2(\\TT)$, as well as for the induced $\\vt k$--Hamiltonians $\\Hk$ obtained by\nrestricting the action of $H$ to Bloch waves. Under some additional\nassumptions, we extend these regularity and solvability results to the\nnon-periodic case. We sketch some applications to approximation of\neigenfunctions and eigenvalues that will be studied in more detail in a second\npaper. \n\n"}
{"id": "1205.4133", "contents": "Title: Constrained Overcomplete Analysis Operator Learning for Cosparse Signal\n  Modelling Abstract: We consider the problem of learning a low-dimensional signal model from a\ncollection of training samples. The mainstream approach would be to learn an\novercomplete dictionary to provide good approximations of the training samples\nusing sparse synthesis coefficients. This famous sparse model has a less well\nknown counterpart, in analysis form, called the cosparse analysis model. In\nthis new model, signals are characterised by their parsimony in a transformed\ndomain using an overcomplete (linear) analysis operator. We propose to learn an\nanalysis operator from a training corpus using a constrained optimisation\nframework based on L1 optimisation. The reason for introducing a constraint in\nthe optimisation framework is to exclude trivial solutions. Although there is\nno final answer here for which constraint is the most relevant constraint, we\ninvestigate some conventional constraints in the model adaptation field and use\nthe uniformly normalised tight frame (UNTF) for this purpose. We then derive a\npractical learning algorithm, based on projected subgradients and\nDouglas-Rachford splitting technique, and demonstrate its ability to robustly\nrecover a ground truth analysis operator, when provided with a clean training\nset, of sufficient size. We also find an analysis operator for images, using\nsome noisy cosparse signals, which is indeed a more realistic experiment. As\nthe derived optimisation problem is not a convex program, we often find a local\nminimum using such variational methods. Some local optimality conditions are\nderived for two different settings, providing preliminary theoretical support\nfor the well-posedness of the learning problem under appropriate conditions. \n\n"}
{"id": "1206.1479", "contents": "Title: Multilevel Monte Carlo methods for highly heterogeneous media Abstract: We discuss the application of multilevel Monte Carlo methods to elliptic\npartial differential equations with random coefficients. Such problems arise,\nfor example, in uncertainty quantification in subsurface flow modeling. We give\na brief review of recent advances in the numerical analysis of the multilevel\nalgorithm under minimal assumptions on the random coefficient, and extend the\nanalysis to cover also tensor--valued coefficients, as well as point\nevaluations. Our analysis includes as an example log--normal random\ncoefficients, which are frequently used in applications. \n\n"}
{"id": "1206.2446", "contents": "Title: Automatic Deformation of Riemann-Hilbert Problems with Applications to\n  the Painlev\\'e II Transcendents Abstract: The stability and convergence rate of Olver's collocation method for the\nnumerical solution of Riemann-Hilbert problems (RHPs) is known to depend very\nsensitively on the particular choice of contours used as data of the RHP. By\nmanually performing contour deformations that proved to be successful in the\nasymptotic analysis of RHPs, such as the method of nonlinear steepest descent,\nthe numerical method can basically be preconditioned, making it asymptotically\nstable. In this paper, however, we will show that most of these preconditioning\ndeformations, including lensing, can be addressed in an automatic, completely\nalgorithmic fashion that would turn the numerical method into a black-box\nsolver. To this end, the preconditioning of RHPs is recast as a discrete,\ngraph-based optimization problem: the deformed contours are obtained as a\nsystem of shortest paths within a planar graph weighted by the relative\nstrength of the jump matrices. The algorithm is illustrated for the RHP\nrepresenting the Painlev\\'e II transcendents. \n\n"}
{"id": "1206.4541", "contents": "Title: Certain upper bounds on the eigenvalues associated with prolate\n  spheroidal wave functions Abstract: Prolate spheroidal wave functions (PSWFs) play an important role in various\nareas, from physics (e.g. wave phenomena, fluid dynamics) to engineering (e.g.\nsignal processing, filter design). One of the principal reasons for the\nimportance of PSWFs is that they are a natural and efficient tool for computing\nwith bandlimited functions, that frequently occur in the abovementioned areas.\nThis is due to the fact that PSWFs are the eigenfunctions of the integral\noperator, that represents timelimiting followed by lowpassing.\n  Needless to say, the behavior of this operator is governed by the decay rate\nof its eigenvalues. Therefore, investigation of this decay rate plays a crucial\nrole in the related theory and applications - for example, in construction of\nquadratures, interpolation, filter design, etc.\n  The significance of PSWFs and, in particular, of the decay rate of the\neigenvalues of the associated integral operator, was realized at least half a\ncentury ago. Nevertheless, perhaps surprisingly, despite vast numerical\nexperience and existence of several asymptotic expansions, a non-trivial\nexplicit upper bound on the magnitude of the eigenvalues has been missing for\ndecades.\n  The principal goal of this paper is to close this gap in the theory of PSWFs.\nWe analyze the integral operator associated with PSWFs, to derive fairly tight\nnon-asymptotic upper bounds on the magnitude of its eigenvalues. Our results\nare illustrated via several numerical experiments. \n\n"}
{"id": "1206.5860", "contents": "Title: Multiscale reaction-diffusion algorithms: PDE-assisted Brownian dynamics Abstract: Two algorithms that combine Brownian dynamics (BD) simulations with\nmean-field partial differential equations (PDEs) are presented. This\nPDE-assisted Brownian dynamics (PBD) methodology provides exact particle\ntracking data in parts of the domain, whilst making use of a mean-field\nreaction-diffusion PDE description elsewhere. The first PBD algorithm couples\nBD simulations with PDEs by randomly creating new particles close to the\ninterface which partitions the domain and by reincorporating particles into the\ncontinuum PDE-description when they cross the interface. The second PBD\nalgorithm introduces an overlap region, where both descriptions exist in\nparallel. It is shown that to accurately compute variances using the PBD\nsimulation requires the overlap region. Advantages of both PBD approaches are\ndiscussed and illustrative numerical examples are presented. \n\n"}
{"id": "1206.6351", "contents": "Title: Discontinuous Galerkin hp-BEM with quasi-uniform meshes Abstract: We present and analyze a discontinuous variant of the hp-version of the\nboundary element Galerkin method with quasi-uniform meshes. The model problem\nis that of the hypersingular integral operator on an (open or closed)\npolyhedral surface. We prove a quasi-optimal error estimate and conclude\nconvergence orders which are quasi-optimal for the h-version with arbitrary\ndegree and almost quasi-optimal for the p-version. Numerical results underline\nthe theory. \n\n"}
{"id": "1207.1708", "contents": "Title: Estimators for Archimedean copulas in high dimensions Abstract: The performance of known and new parametric estimators for Archimedean\ncopulas is investigated, with special focus on large dimensions and numerical\ndifficulties. In particular, method-of-moments-like estimators based on\npairwise Kendall's tau, a multivariate extension of Blomqvist's beta, minimum\ndistance estimators, the maximum-likelihood estimator, a simulated\nmaximum-likelihood estimator, and a maximum-likelihood estimator based on the\ncopula diagonal are studied. Their performance is compared in a large-scale\nsimulation study both under known and unknown margins (pseudo-observations), in\nsmall and high dimensions, under small and large dependencies, various\ndifferent Archimedean families and sample sizes. High dimensions up to one\nhundred are considered for the first time and computational problems arising\nfrom such large dimensions are addressed in detail. All methods are implemented\nin the open source \\R{} package \\pkg{copula} and can thus be easily accessed\nand studied. \n\n"}
{"id": "1207.2012", "contents": "Title: Second order finite difference approximations for the two-dimensional\n  time-space Caputo-Riesz fractional diffusion equation Abstract: In this paper, we discuss the time-space Caputo-Riesz fractional diffusion\nequation with variable coefficients on a finite domain. The finite difference\nschemes for this equation are provided. We theoretically prove and numerically\nverify that the implicit finite difference scheme is unconditionally stable\n(the explicit scheme is conditionally stable with the stability condition\n$\\frac{\\tau^{\\gamma}}{(\\Delta x)^{\\alpha}}+\\frac{\\tau^{\\gamma}}{(\\Delta\ny)^{\\beta}} <C$) and 2nd order convergent in space direction, and\n$(2-\\gamma)$-th order convergent in time direction, where $\\gamma \\in(0,1]$. \n\n"}
{"id": "1207.4461", "contents": "Title: Quadrature by Expansion: A New Method for the Evaluation of Layer\n  Potentials Abstract: Integral equation methods for the solution of partial differential equations,\nwhen coupled with suitable fast algorithms, yield geometrically flexible,\nasymptotically optimal and well-conditioned schemes in either interior or\nexterior domains. The practical application of these methods, however, requires\nthe accurate evaluation of boundary integrals with singular, weakly singular or\nnearly singular kernels. Historically, these issues have been handled either by\nlow-order product integration rules (computed semi-analytically), by\nsingularity subtraction/cancellation, by kernel regularization and asymptotic\nanalysis, or by the construction of special purpose \"generalized Gaussian\nquadrature\" rules. In this paper, we present a systematic, high-order approach\nthat works for any singularity (including hypersingular kernels), based only on\nthe assumption that the field induced by the integral operator is locally\nsmooth when restricted to either the interior or the exterior. Discontinuities\nin the field across the boundary are permitted. The scheme, denoted QBX\n(quadrature by expansion), is easy to implement and compatible with fast\nhierarchical algorithms such as the fast multipole method. We include accuracy\ntests for a variety of integral operators in two dimensions on smooth and\ncorner domains. \n\n"}
{"id": "1207.6737", "contents": "Title: Solving integral equations on piecewise smooth boundaries using the RCIP\n  method: a tutorial Abstract: Recursively compressed inverse preconditioning (RCIP) is a kernel-independent\nand purely numerical method for solving Fredholm second kind boundary integral\nequations in situations where the boundary shape induces a non-smooth behavior\nin the solution. The method originated in 2008 within a scheme for Laplace's\nequation in two-dimensional domains with corners. In a series of subsequent\npapers the method was then refined and extended as to apply to integral\nequation formulations of a broad range of boundary value problems in physics\nand engineering. The purpose of the present tutorial is threefold: First, to\nreview the RCIP method in a simple setting. Second, to show how easily the\nmethod can be implemented in Matlab. Third, to present new applications. \n\n"}
{"id": "1208.0264", "contents": "Title: Preconditioned Recycling Krylov subspace methods for self-adjoint\n  problems Abstract: The authors propose a recycling Krylov subspace method for the solution of a\nsequence of self-adjoint linear systems. Such problems appear, for example, in\nthe Newton process for solving nonlinear equations. Ritz vectors are\nautomatically extracted from one MINRES run and then used for self-adjoint\ndeflation in the next. The method is designed to work with arbitrary inner\nproducts and arbitrary self-adjoint positive-definite preconditioners whose\ninverse can be computed with high accuracy. Numerical experiments with\nnonlinear Schr\\\"odinger equations indicate a substantial decrease in\ncomputation time when recycling is used. \n\n"}
{"id": "1208.0578", "contents": "Title: Instability of the finite-difference split-step method on the background\n  of a soliton of the nonlinear Schrodinger equation Abstract: We consider the implementation of the split-step method where the linear part\nof the nonlinear Schr\\\"odinger equation is solved using a finite-difference\ndiscretization of the spatial derivative. The von Neumann analysis predicts\nthat this method is unconditionally stable on the background of a\nconstant-amplitude plane wave. However, simulations show that the method can\nbecome unstable on the background of a soliton. We present an analysis\nexplaining this instability. Both this analysis and the instability itself are\nsubstantially different from those of the Fourier split-step method, which\ncomputes the spatial derivative by spectral discretization. We also found that\nthe modes responsible for the numerical instability are supported by the sides\nof the soliton, in contrast to unstable modes of linearized nonlinear wave\nequations, which (the modes) are supported by the soliton's core. \n\n"}
{"id": "1208.3267", "contents": "Title: QMC designs: optimal order Quasi Monte Carlo Integration schemes on the\n  sphere Abstract: We study equal weight numerical integration, or Quasi Monte Carlo (QMC)\nrules, for functions in a Sobolev space $H^s(S^d)$ with smoothness parameter\n$s>d/2$ defined over the unit sphere $S^d$ in $R^{d+1}$. Focusing on $N$-point\nsets that achieve optimal order QMC error bounds (as is the case for efficient\nspherical designs), we are led to introduce the concept of QMC designs: these\nare sequences of $N$-point node sets $X_N$ on $S^d$ such that the worst-case\nerror of the corresponding QMC rules satisfy a bound of order $O(N^{-s/d})$ as\n$N\\to\\infty$ with an implied constant that depends on the $H^s(S^d)$-norm.\n  We provide methods for generation and numerical testing of QMC designs. As a\nconsequence of a recent result of Bondarenko et al. on the existence of\nspherical designs with appropriate number of points, we show that minimizers of\nthe $N$-point energy for the reproducing kernel for $H^s(S^d)$, $s>d/2$, form a\nsequence of QMC designs for $H^s(S^d)$. Furthermore, without appealing to the\nBondarenko et al. result, we prove that point sets that maximize the sum of\nsuitable powers of the Euclidean distance between pairs of points form a\nsequence of QMC designs for $H^s(S^d)$ with $s\\in(d/2,d/2+1)$.\n  Numerical experiments suggest that many familiar sequences of point sets on\nthe sphere (equal area, spiral, minimal [Coulomb or log.] energy, and Fekete\npoints) are QMC designs for appropriate values of $s$. For comparison purposes\nwe show that sets of random points that are independently and uniformly\ndistributed on the sphere do not constitute QMC designs for any $s>d/2$.\n  If $(X_N)$ is a sequence of QMC designs for $H^s(S^d)$, we prove that it is\nalso a sequence of QMC designs for $\\mathbb{H}^{s'}(S^d)$ for all\n$s'\\in(d/2,s)$. This leads to the question of determining the supremum of such\n$s$, for which we provide estimates based on computations for the\naforementioned sequences. \n\n"}
{"id": "1208.3805", "contents": "Title: Paved with Good Intentions: Analysis of a Randomized Block Kaczmarz\n  Method Abstract: The block Kaczmarz method is an iterative scheme for solving overdetermined\nleast-squares problems. At each step, the algorithm projects the current\niterate onto the solution space of a subset of the constraints. This paper\ndescribes a block Kaczmarz algorithm that uses a randomized control scheme to\nchoose the subset at each step. This algorithm is the first block Kaczmarz\nmethod with an (expected) linear rate of convergence that can be expressed in\nterms of the geometric properties of the matrix and its submatrices. The\nanalysis reveals that the algorithm is most effective when it is given a good\nrow paving of the matrix, a partition of the rows into well-conditioned blocks.\nThe operator theory literature provides detailed information about the\nexistence and construction of good row pavings. Together, these results yield\nan efficient block Kaczmarz scheme that applies to many overdetermined\nleast-squares problem. \n\n"}
{"id": "1208.4479", "contents": "Title: Exponentially accurate Hamiltonian embeddings of symplectic A-stable\n  Runge--Kutta methods for Hamiltonian semilinear evolution equations Abstract: We prove that a class of A-stable symplectic Runge--Kutta time\nsemidiscretizations (including the Gauss--Legendre methods) applied to a class\nof semilinear Hamiltonian PDEs which are well-posed on spaces of analytic\nfunctions with analytic initial data can be embedded into a modified\nHamiltonian flow up to an exponentially small error. As a consequence, such\ntime-semidiscretizations conserve the modified Hamiltonian up to an\nexponentially small error. The modified Hamiltonian is $O(h^p)$-close to the\noriginal energy where $p$ is the order of the method and $h$ the time\nstep-size. Examples of such systems are the semilinear wave equation or the\nnonlinear Schr\\\"odinger equation with analytic nonlinearity and periodic\nboundary conditions. Standard Hamiltonian interpolation results do not apply\nhere because of the occurrence of unbounded operators in the construction of\nthe modified vector field. This loss of regularity in the construction can be\ntaken care of by projecting the PDE to a subspace where the operators occurring\nin the evolution equation are bounded and by coupling the number of excited\nmodes as well as the number of terms in the expansion of the modified vector\nfield with the step size. This way we obtain exponential estimates of the form\n$O(\\exp(-c/h^{1/(1+q)}))$ with $c>0$ and $q \\geq 0$; for the semilinear wave\nequation, $q=1$, and for the nonlinear Schr\\\"odinger equation, $q=2$. We give\nan example which shows that analyticity of the initial data is necessary to\nobtain exponential estimates. \n\n"}
{"id": "1208.6410", "contents": "Title: Convergence of a fully discrete finite difference scheme for the\n  Korteweg-de Vries equation Abstract: We prove convergence of a fully discrete finite difference scheme for the\nKorteweg--de Vries equation. Both the decaying case on the full line and the\nperiodic case are considered. If the initial data $u|_{t=0}=u_0$ is of high\nregularity, $u_0\\in H^3(\\R)$, the scheme is shown to converge to a classical\nsolution, and if the regularity of the initial data is smaller, $u_0\\in\nL^2(\\R)$, then the scheme converges strongly in\n$L^2(0,T;L^2_{\\mathrm{loc}}(\\R))$ to a weak solution. \n\n"}
{"id": "1209.1793", "contents": "Title: High order gradient, curl and divergence conforming spaces, with an\n  application to NURBS-based IsoGeometric Analysis Abstract: Conservation laws, in for example, electromagnetism, solid and fluid\nmechanics, allow an exact discrete representation in terms of line, surface and\nvolume integrals. We develop high order interpolants, from any basis that is a\npartition of unity, that satisfy these integral relations exactly, at cell\nlevel. The resulting gradient, curl and divergence conforming spaces have the\nproperty that the conservation laws become completely independent of the basis\nfunctions. This means that the conservation laws are exactly satisfied even on\ncurved meshes. As an example, we develop high order gradient, curl and\ndivergence conforming spaces from NURBS - non uniform rational B-splines - and\nthereby generalize the compatible spaces of B-splines developed by Buffa et\nal.[1]. We give several examples of 2D Stokes flow calculations which result,\namongst others, in a point wise divergence free velocity field. \n\n"}
{"id": "1209.5028", "contents": "Title: Invariant Discretization Schemes Using Evolution-Projection Techniques Abstract: Finite difference discretization schemes preserving a subgroup of the maximal\nLie invariance group of the one-dimensional linear heat equation are\ndetermined. These invariant schemes are constructed using the invariantization\nprocedure for non-invariant schemes of the heat equation in computational\ncoordinates. We propose a new methodology for handling moving discretization\ngrids which are generally indispensable for invariant numerical schemes. The\nidea is to use the invariant grid equation, which determines the locations of\nthe grid point at the next time level only for a single integration step and\nthen to project the obtained solution to the regular grid using invariant\ninterpolation schemes. This guarantees that the scheme is invariant and allows\none to work on the simpler stationary grids. The discretization errors of the\ninvariant schemes are established and their convergence rates are estimated.\nNumerical tests are carried out to shed some light on the numerical properties\nof invariant discretization schemes using the proposed evolution-projection\nstrategy. \n\n"}
{"id": "1210.0172", "contents": "Title: Generalization and variations of Pellet's theorem for matrix polynomials Abstract: We derive a generalized matrix version of Pellet's theorem, itself based on a\ngeneralized Rouch\\'{e} theorem for matrix-valued functions, to generate upper,\nlower, and internal bounds on the eigenvalues of matrix polynomials. Variations\nof the theorem are suggested to try and overcome situations where Pellet's\ntheorem cannot be applied. \n\n"}
{"id": "1210.0577", "contents": "Title: Two-step greedy algorithm for reduced order quadratures Abstract: We present an algorithm to generate application-specific, global reduced\norder quadratures (ROQ) for multiple fast evaluations of weighted inner\nproducts between parameterized functions. If a reduced basis (RB) or any other\nprojection-based model reduction technique is applied, the dimensionality of\nintegrands is reduced dramatically; however, the cost of approximating the\nintegrands by projection still scales as the size of the original problem. In\ncontrast, using discrete empirical interpolation (DEIM) points as ROQ nodes\nleads to a computational cost which depends linearly on the dimension of the\nreduced space. Generation of a reduced basis via a greedy procedure requires a\ntraining set, which for products of functions can be very large. Since this\ndirect approach can be impractical in many applications, we propose instead a\ntwo-step greedy targeted towards approximation of such products. We present\nnumerical experiments demonstrating the accuracy and the efficiency of the\ntwo-step approach. The presented ROQ are expected to display very fast\nconvergence whenever there is regularity with respect to parameter variation.\nWe find that for the particular application here considered, one driven by\ngravitational wave physics, the two-step approach speeds up the offline\ncomputations to build the ROQ by more than two orders of magnitude.\nFurthermore, the resulting ROQ rule is found to converge exponentially with the\nnumber of nodes, and a factor of ~50 savings, without loss of accuracy, is\nobserved in evaluations of inner products when ROQ are used as a downsampling\nstrategy for equidistant samples using the trapezoidal rule. While the primary\nfocus of this paper is on quadrature rules for inner products of parameterized\nfunctions, our method can be easily adapted to integrations of single\nparameterized functions, and some examples of this type are considered. \n\n"}
{"id": "1210.2148", "contents": "Title: Implementation of Pellet's theorem Abstract: Pellet's theorem determines when the zeros of a polynomial can be separated\ninto two regions, based on the presence or absence of positive roots of an\nauxiliary polynomial, but does not provide a method to verify its conditions or\nto compute the roots of the auxiliary polynomial when they exist. We derive an\nexplicit condition for these roots to exist and, when they do, propose\nefficient ways to compute them. A similar auxiliary polynomial appears for the\ngeneralized Pellet theorem for matrix polynomials and it can be treated in the\nsame way. \n\n"}
{"id": "1210.2762", "contents": "Title: Invariant meshless discretization schemes Abstract: A method is introduced for the construction of meshless discretization\nschemes which preserve Lie symmetries of the differential equations that these\nschemes approximate. The method exploits the fact that equivariant moving\nframes provide a way of associating invariant functions to non-invariant\nfunctions. An invariant meshless approximation of a nonlinear diffusion\nequation is constructed. Comparative numerical tests with a non-invariant\nmeshless scheme are presented. These tests yield that invariant meshless\nschemes can lead to substantially improved numerical solutions compared to\nnumerical solutions generated by non-invariant meshless schemes. \n\n"}
{"id": "1210.4223", "contents": "Title: Infinite-Dimensional Integration in Weighted Hilbert Spaces: Anchored\n  Decompositions, Optimal Deterministic Algorithms, and Higher Order\n  Convergence Abstract: We study numerical integration of functions depending on an infinite number\nof variables. We provide lower error bounds for general deterministic linear\nalgorithms and provide matching upper error bounds with the help of suitable\nmultilevel algorithms and changing dimension algorithms.\n  More precisely, the spaces of integrands we consider are weighted reproducing\nkernel Hilbert spaces with norms induced by an underlying anchored function\nspace decomposition. Here the weights model the relative importance of\ndifferent groups of variables. The error criterion used is the deterministic\nworst case error. We study two cost models for function evaluation which depend\non the number of active variables of the chosen sample points, and two classes\nof weights, namely product and order-dependent (POD) weights and the newly\nintroduced weights with finite active dimension. We show for these classes of\nweights that multilevel algorithms achieve the optimal rate of convergence in\nthe first cost model while changing dimension algorithms achieve the optimal\nconvergence rate in the second model.\n  As an illustrative example, we discuss the anchored Sobolev space with\nsmoothness parameter $\\alpha$ and provide new optimal quasi-Monte Carlo\nmultilevel algorithms and quasi-Monte Carlo changing dimension algorithms based\non higher-order polynomial lattice rules. \n\n"}
{"id": "1210.4939", "contents": "Title: Time-fractional and memoryful $\\Delta^{2^{k}}$ SIEs on $\\Rp\\times\\Rd$:\n  how far can we push white noise? Abstract: High order and fractional PDEs have become prominent in theory and in\nmodeling many phenomena. Here, we focus on the regularizing effect of a large\nclass of memoryful high-order or time-fractional PDEs---through their\nfundamental solutions---on stochastic integral equations (SIEs) driven by\nspace-time white noise. Surprisingly, we show that maximum spatial regularity\nis achieved in the fourth-order-bi-Laplacian case; and any further increase of\nthe spatial-Laplacian order is entirely translated into additional temporal\nregularization of the SIE. We started this program in (Allouba 2013, Allouba\n2006), where we introduced two different stochastic versions of the fourth\norder memoryful PDE associated with the Brownian-time Brownian motion (BTBM):\n(1) the BTBM SIE and (2) the BTBM SPDE, both driven by space-time white noise.\nUnder wide conditions, we showed the existence of random field locally-H\\\"older\nsolutions to the BTBM SIE with striking and unprecedented time-space H\\\"older\nexponents, in spatial dimensions $d=1,2,3$. In particular, we proved that the\nspatial regularity of such solutions is nearly locally Lipschitz in $d=1,2$.\nThis gave, for the first time, an example of a space-time white noise driven\nequation whose solutions are smoother than the corresponding Brownian sheet in\neither time or space. In this paper, we introduce the $2\\beta^{-1}$-order\n$\\beta$-inverse-stable-L\\'evy-time Brownian motion ($\\beta$-ISLTBM) SIEs,\ndriven by space-time white noise. We show that the BTBM SIE spatial regularity\nand its random field third spatial dimension limit are maximal among all\n$\\beta$-ISLTBM SIEs. Furthermore, we show that increasing the order of the\nLaplacian $\\beta^{-1}$ beyond the BTBM bi-Laplacian manifests entirely as\nincreased temporal regularity of our random field solutions that asymptotically\napproaches the temporal regularity of the Brownian sheet as $\\beta\\searrow0$. \n\n"}
{"id": "1210.6247", "contents": "Title: More Special Functions Trapped Abstract: We extend the technique of using the Trapezoidal Rule for efficient\nevaluation of the Special Functions of Mathematical Physics given by integral\nrepresentations. This technique was recently used for Bessel functions, and\nhere we treat Incomplete Gamma functions and the general Confluent\nHypergeometric Function. \n\n"}
{"id": "1210.7445", "contents": "Title: Recursive equations based models of queueing systems Abstract: An overview of the recursive equations based models and their applications in\nsimulation based analysis and optimization of queueing systems is given. These\nmodels provide a variety of systems with a convenient and unified\nrepresentation in terms of recursions for arrival and departure times of\ncustomers, which involves only the operations of maximum, minimum, and\naddition. \n\n"}
{"id": "1211.3444", "contents": "Title: Spectral Clustering: An empirical study of Approximation Algorithms and\n  its Application to the Attrition Problem Abstract: Clustering is the problem of separating a set of objects into groups (called\nclusters) so that objects within the same cluster are more similar to each\nother than to those in different clusters. Spectral clustering is a now\nwell-known method for clustering which utilizes the spectrum of the data\nsimilarity matrix to perform this separation. Since the method relies on\nsolving an eigenvector problem, it is computationally expensive for large\ndatasets. To overcome this constraint, approximation methods have been\ndeveloped which aim to reduce running time while maintaining accurate\nclassification. In this article, we summarize and experimentally evaluate\nseveral approximation methods for spectral clustering. From an applications\nstandpoint, we employ spectral clustering to solve the so-called attrition\nproblem, where one aims to identify from a set of employees those who are\nlikely to voluntarily leave the company from those who are not. Our study sheds\nlight on the empirical performance of existing approximate spectral clustering\nmethods and shows the applicability of these methods in an important business\noptimization related problem. \n\n"}
{"id": "1211.3500", "contents": "Title: Accelerated Canonical Polyadic Decomposition by Using Mode Reduction Abstract: Canonical Polyadic (or CANDECOMP/PARAFAC, CP) decompositions (CPD) are widely\napplied to analyze high order tensors. Existing CPD methods use alternating\nleast square (ALS) iterations and hence need to unfold tensors to each of the\n$N$ modes frequently, which is one major bottleneck of efficiency for\nlarge-scale data and especially when $N$ is large. To overcome this problem, in\nthis paper we proposed a new CPD method which converts the original $N$th\n($N>3$) order tensor to a 3rd-order tensor first. Then the full CPD is realized\nby decomposing this mode reduced tensor followed by a Khatri-Rao product\nprojection procedure. This way is quite efficient as unfolding to each of the\n$N$ modes are avoided, and dimensionality reduction can also be easily\nincorporated to further improve the efficiency. We show that, under mild\nconditions, any $N$th-order CPD can be converted into a 3rd-order case but\nwithout destroying the essential uniqueness, and theoretically gives the same\nresults as direct $N$-way CPD methods. Simulations show that, compared with\nstate-of-the-art CPD methods, the proposed method is more efficient and escape\nfrom local solutions more easily. \n\n"}
{"id": "1211.3796", "contents": "Title: CANDECOMP/PARAFAC Decomposition of High-order Tensors Through Tensor\n  Reshaping Abstract: In general, algorithms for order-3 CANDECOMP/-PARAFAC (CP), also coined\ncanonical polyadic decomposition (CPD), are easily to implement and can be\nextended to higher order CPD. Unfortunately, the algorithms become\ncomputationally demanding, and they are often not applicable to higher order\nand relatively large scale tensors. In this paper, by exploiting the uniqueness\nof CPD and the relation of a tensor in Kruskal form and its unfolded tensor, we\npropose a fast approach to deal with this problem. Instead of directly\nfactorizing the high order data tensor, the method decomposes an unfolded\ntensor with lower order, e.g., order-3 tensor. On basis of the order-3\nestimated tensor, a structured Kruskal tensor of the same dimension as the data\ntensor is then generated, and decomposed to find the final solution using fast\nalgorithms for the structured CPD. In addition, strategies to unfold tensors\nare suggested and practically verified in the paper. \n\n"}
{"id": "1212.3544", "contents": "Title: Tracking of a Mobile Target Using Generalized Polarization Tensors Abstract: In this paper we apply an extended Kalman filter to track both the location\nand the orientation of a mobile target from multistatic response measurements.\nWe also analyze the effect of the limited-view aspect on the stability and the\nefficiency of our tracking approach. Our algorithm is based on the use of the\ngeneralized polarization tensors, which can be reconstructed from the\nmultistatic response measurements by solving a linear system. The system has\nthe remarkable property that low order generalized polarization tensors are not\naffected by the error caused by the instability of higher orders in the\npresence of measurement noise. \n\n"}
{"id": "1212.5564", "contents": "Title: Weak convergence for a spatial approximation of the nonlinear stochastic\n  heat equation Abstract: We find the weak rate of convergence of the spatially semidiscrete finite\nelement approximation of the nonlinear stochastic heat equation. Both\nmultiplicative and additive noise is considered under different assumptions.\nThis extends an earlier result of Debussche in which time discretization is\nconsidered for the stochastic heat equation perturbed by white noise. It is\nknown that this equation has a solution only in one space dimension. In order\nto obtain results for higher dimensions, colored noise is considered here,\nbesides white noise in one dimension. Integration by parts in the Malliavin\nsense is used in the proof. The rate of weak convergence is, as expected,\nessentially twice the rate of strong convergence. \n\n"}
{"id": "1301.0908", "contents": "Title: Low-complexity computation of plate eigenmodes with Vekua approximations\n  and the Method of Particular Solutions Abstract: This paper extends the Method of Particular Solutions (MPS) to the\ncomputation of eigenfrequencies and eigenmodes of plates. Specific\napproximation schemes are developed, with plane waves (MPS-PW) or\nFourier-Bessel functions (MPS-FB). This framework also requires a suitable\nformulation of the boundary conditions. Numerical tests, on two plates with\nvarious boundary conditions, demonstrate that the proposed approach provides\ncompetitive results with standard numerical schemes such as the Finite Element\nMethod, at reduced complexity, and with large flexibility in the implementation\nchoices. \n\n"}
{"id": "1301.2367", "contents": "Title: LINE INTEGRAL METHODS and their application to the numerical solution of\n  conservative problems Abstract: These are the lecture notes of a course given by the first author on December\n27, 2012 - January 4, 2013, held at the Academy of Mathematics and Systems\nScience Chinese Academy of Sciences in Beijing. \n\n"}
{"id": "1301.4794", "contents": "Title: Weak and quasi-polynomial tractability of approximation of infinitely\n  differentiable functions Abstract: We comment on recent results in the field of information based complexity,\nwhich state (in a number of different settings), that approximation of\ninfinitely differentiable functions is intractable and suffers from the curse\nof dimensionality. We show that renorming the space of infinitely\ndifferentiable functions in a suitable way allows weakly tractable uniform\napproximation by using only function values. Moreover, the approximating\nalgorithm is based on a simple application of Taylor's expansion at the center\nof the unit cube. We discuss also the approximation on the Euclidean ball and\nthe approximation in the $L_1$-norm, which is closely related to the problem of\nnumerical integration. \n\n"}
{"id": "1301.7736", "contents": "Title: Higher order splitting methods with modified integrators for a class of\n  Hamiltonian systems Abstract: We discuss systematic extensions of the standard (St{\\\"o}rmer-Verlet)\nsplitting method for differential equations of Hamiltonian mechanics, with\nrelative accuracy of order $\\tau^2$ for a timestep of length $\\tau$, to higher\norders in $\\tau$. We present some splitting schemes, with all intermediate\ntimesteps real and positive, which increase the relative accuracy to order\n$\\tau^{N}$ (for N=4, 6, and 8) for a large class of Hamiltonian systems. \n\n"}
{"id": "1302.4317", "contents": "Title: Introducing One Step Back Iterative Approach to Solve Linear and Non\n  Linear Fixed Point Problem Abstract: In this paper, we introduce a new iterative method which we call one step\nback approach: the main idea is to anticipate the consequence of the iterative\ncomputation per coordinate and to optimize on the choice of the sequence of the\ncoordinates on which the iterative update computations are done. The method\nrequires the increase of the size of the state vectors and one iteration step\nloss from the initial vector. We illustrate the approach in linear and non\nlinear iterative equations. \n\n"}
{"id": "1303.0102", "contents": "Title: Optimizing performance of the deconvolution model reduction for large\n  ODE systems Abstract: We investigate the numerical performance of the regularized deconvolution\nclosure introduced recently by the authors. The purpose of the closure is to\nfurnish constitutive equations for Irwing-Kirkwood-Noll procedure, a well known\nmethod for deriving continuum balance equations from the Newton's equations of\nparticle dynamics. A version of this procedure used in the paper relies on\nspatial averaging developed by Hardy, and independently by Murdoch and Bedeaux.\nThe constitutive equations for the stress are given as a sum of several\noperator terms acting on the mesoscale average density and velocity. Each term\nis a \"convolution sandwich\" containing the deconvolution operator, a\ncomposition or a product operator, and the convolution (averaging) operator.\nDeconvolution is constructed using filtered regularization methods from the\ntheory of ill-posed problems. The purpose of regularization is to ensure\nnumerical stability. The particular technique used for numerical experiments is\ntruncated singular value decomposition (SVD). The accuracy of the constitutive\nequations depends on several parameters: the choice of the averaging window\nfunction, the value of the mesoscale resolution parameter, scale separation,\nthe level of truncation of singular values, and the level of spectral filtering\nof the averages. We conduct numerical experiments to determine the effect of\neach parameter on the accuracy and efficiency of the method. Partial error\nestimates are also obtained. \n\n"}
{"id": "1303.2875", "contents": "Title: On the convergence rate improvement of a primal-dual splitting algorithm\n  for solving monotone inclusion problems Abstract: We present two modified versions of the primal-dual splitting algorithm\nrelying on forward-backward splitting proposed in \\cite{vu} for solving\nmonotone inclusion problems. Under strong monotonicity assumptions for some of\nthe operators involved we obtain for the sequences of iterates that approach\nthe solution orders of convergence of O(1/n) and O(\\omega^n), for $\\omega \\in\n(0,1)$, respectively. The investigated primal-dual algorithms are fully\ndecomposable, in the sense that the operators are processed individually at\neach iteration. We also discuss the modified algorithms in the context of\nconvex optimization problems and present numerical experiments in image\nprocessing and support vector machines classification. \n\n"}
{"id": "1303.3471", "contents": "Title: The splitting in potential Crank-Nicolson scheme with discrete\n  transparent boundary conditions for the Schr\\\"odinger equation on a\n  semi-infinite strip Abstract: We consider an initial-boundary value problem for a generalized 2D\ntime-dependent Schr\u007fodinger equation (with variable coefficients) on a\nsemi-infinite strip. For the Crank-Nicolson-type finite-difference scheme with\napproximate or discrete transparent boundary conditions (TBCs), the Strang-type\nsplitting with respect to the potential is applied. For the resulting method,\nthe unconditional uniform in time $L^2$-stability is proved. Due to the\nsplitting, an effective direct algorithm using FFT is developed now to\nimplement the method with the discrete TBC for general potential. Numerical\nresults on the tunnel effect for rectangular barriers are included together\nwith the detailed practical error analysis confirming nice properties of the\nmethod. \n\n"}
{"id": "1303.4778", "contents": "Title: Greedy Feature Selection for Subspace Clustering Abstract: Unions of subspaces provide a powerful generalization to linear subspace\nmodels for collections of high-dimensional data. To learn a union of subspaces\nfrom a collection of data, sets of signals in the collection that belong to the\nsame subspace must be identified in order to obtain accurate estimates of the\nsubspace structures present in the data. Recently, sparse recovery methods have\nbeen shown to provide a provable and robust strategy for exact feature\nselection (EFS)--recovering subsets of points from the ensemble that live in\nthe same subspace. In parallel with recent studies of EFS with L1-minimization,\nin this paper, we develop sufficient conditions for EFS with a greedy method\nfor sparse signal recovery known as orthogonal matching pursuit (OMP).\nFollowing our analysis, we provide an empirical study of feature selection\nstrategies for signals living on unions of subspaces and characterize the gap\nbetween sparse recovery methods and nearest neighbor (NN)-based approaches. In\nparticular, we demonstrate that sparse recovery methods provide significant\nadvantages over NN methods and the gap between the two approaches is\nparticularly pronounced when the sampling of subspaces in the dataset is\nsparse. Our results suggest that OMP may be employed to reliably recover exact\nfeature sets in a number of regimes where NN approaches fail to reveal the\nsubspace membership of points in the ensemble. \n\n"}
{"id": "1303.6012", "contents": "Title: Are the Snapshot Difference Quotients Needed in the Proper Orthogonal\n  Decomposition? Abstract: This paper presents a theoretical and numerical investigation of the\nfollowing practical question: Should the time difference quotients of the\nsnapshots be used to generate the proper orthogonal decomposition basis\nfunctions? The answer to this question is important, since some published\nnumerical studies use the time difference quotients, whereas other numerical\nstudies do not. The criterion used in this paper to answer this question is the\nrate of convergence of the error of the reduced order model with respect to the\nnumber of proper orthogonal decomposition basis functions. Two cases are\nconsidered: the no_DQ case, in which the snapshot difference quotients are not\nused, and the DQ case, in which the snapshot difference quotients are used. The\nerror estimates suggest that the convergence rates in the $C^0(L^2)$-norm and\nin the $C^0(H^1)$-norm are optimal for the DQ case, but suboptimal for the\nno_DQ case. The convergence rates in the $L^2(H^1)$-norm are optimal for both\nthe DQ case and the no_DQ case. Numerical tests are conducted on the heat\nequation and on the Burgers equation. The numerical results support the\nconclusions drawn from the theoretical error estimates. Overall, the\ntheoretical and numerical results strongly suggest that, in order to achieve\noptimal pointwise in time rates of convergence with respect to the number of\nproper orthogonal decomposition basis functions, one should use the snapshot\ndifference quotients. \n\n"}
{"id": "1304.1222", "contents": "Title: Alternating minimal energy methods for linear systems in higher\n  dimensions. Part II: Faster algorithm and application to nonsymmetric systems Abstract: In this paper we accomplish the development of the fast rank-adaptive solver\nfor tensor-structured symmetric positive definite linear systems in higher\ndimensions. In [arXiv:1301.6068] this problem is approached by alternating\nminimization of the energy function, which we combine with steps of the basis\nexpansion in accordance with the steepest descent algorithm. In this paper we\ncombine the same steps in such a way that the resulted algorithm works with one\nor two neighboring cores at a time. The recurrent interpretation of the\nalgorithm allows to prove the global convergence and to estimate the\nconvergence rate. We also propose several strategies, both rigorous and\nheuristic, to compute new subspaces for the basis enrichment in a more\nefficient way. We test the algorithm on a number of high-dimensional problems,\nincluding the non-symmetrical Fokker-Planck and chemical master equations, for\nwhich the efficiency of the method is not fully supported by the theory. In all\nexamples we observe a convincing fast convergence and high efficiency of the\nproposed method. \n\n"}
{"id": "1304.2265", "contents": "Title: Discontinuous Galerkin methods for nonvariational problems Abstract: We extend the finite element method introduced by Lakkis and Pryer [2011] to\napproximate the solution of second order elliptic problems in nonvariational\nform to incorporate the discontinuous Galerkin (DG) framework. This is done by\nviewing the NVFEM as a mixed method whereby the finite element Hessian is an\nauxiliary variable in the formulation. Representing the finite element Hessian\nin a discontinuous setting yields a linear system of the same size and having\nthe same sparsity pattern of the compact DG methods for variational elliptic\nproblems. Furthermore, the system matrix is very easy to assemble, Thus this\napproach greatly reduces the computational complexity of the discretisation\ncompared to the continuous approach.\n  We conduct a stability and consistency analysis making use of the unified\nframework set out in Arnold et. al. [2001]. We also give an apriori analysis of\nthe method. The analysis applies to any consistent representation of the finite\nelement Hessian, thus is applicable to the previous works making use of\ncontinuous Galerkin approximations. \n\n"}
{"id": "1304.2967", "contents": "Title: Log-majorization of the moduli of the eigenvalues of a matrix polynomial\n  by tropical roots Abstract: We show that the sequence of moduli of the eigenvalues of a matrix polynomial\nis log-majorized, up to universal constants, by a sequence of \"tropical roots\"\ndepending only on the norms of the matrix coefficients. These tropical roots\nare the non-differentiability points of an auxiliary tropical polynomial, or\nequivalently, the opposites of the slopes of its Newton polygon. This extends\nto the case of matrix polynomials some bounds obtained by Hadamard, Ostrowski\nand P\\'olya for the roots of scalar polynomials. We also obtain new bounds in\nthe scalar case, which are accurate for \"fewnomials\" or when the tropical roots\nare well separated. \n\n"}
{"id": "1304.4103", "contents": "Title: A multigrid method for the Helmholtz equation with optimized coarse grid\n  corrections Abstract: We study the convergence of multigrid schemes for the Helmholtz equation,\nfocusing in particular on the choice of the coarse scale operators. Let G_c\ndenote the number of points per wavelength at the coarse level. If the coarse\nscale solutions are to approximate the true solutions, then the oscillatory\nnature of the solutions implies the requirement G_c > 2. However, in examples\nthe requirement is more like G_c >= 10, in a trade-off involving also the\namount of damping present and the number of multigrid iterations. We conjecture\nthat this is caused by the difference in phase speeds between the coarse and\nfine scale operators. Standard 5-point finite differences in 2-D are our first\nexample. A new coarse scale 9-point operator is constructed to match the fine\nscale phase speeds. We then compare phase speeds and multigrid performance of\nstandard schemes with a scheme using the new operator. The required G_c is\nreduced from about 10 to about 3.5, with less damping present so that waves\npropagate over > 100 wavelengths in the new scheme. Next we consider extensions\nof the method to more general cases. In 3-D comparable results are obtained\nwith standard 7-point differences and optimized 27-point coarse grid operators,\nleading to an order of magnitude reduction in the number of unknowns for the\ncoarsest scale linear system. Finally we show how to include PML boundary\nlayers, using a regular grid finite element method. Matching coarse scale\noperators can easily be constructed for other discretizations. The method is\ntherefore potentially useful for a large class of discretized high-frequency\nHelmholtz equations. \n\n"}
{"id": "1304.4373", "contents": "Title: Jump-sparse and sparse recovery using Potts functionals Abstract: We recover jump-sparse and sparse signals from blurred incomplete data\ncorrupted by (possibly non-Gaussian) noise using inverse Potts energy\nfunctionals. We obtain analytical results (existence of minimizers, complexity)\non inverse Potts functionals and provide relations to sparsity problems. We\nthen propose a new optimization method for these functionals which is based on\ndynamic programming and the alternating direction method of multipliers (ADMM).\nA series of experiments shows that the proposed method yields very satisfactory\njump-sparse and sparse reconstructions, respectively. We highlight the\ncapability of the method by comparing it with classical and recent approaches\nsuch as TV minimization (jump-sparse signals), orthogonal matching pursuit,\niterative hard thresholding, and iteratively reweighted $\\ell^1$ minimization\n(sparse signals). \n\n"}
{"id": "1304.4976", "contents": "Title: An Optimization-Based Atomistic-to-Continuum Coupling Method Abstract: We present a new optimization-based method for atomistic-to-continuum (AtC)\ncoupling. The main idea is to cast the coupling of the atomistic and continuum\nmodels as a constrained optimization problem with virtual Dirichlet controls on\nthe interfaces between the atomistic and continuum subdomains. The optimization\nobjective is to minimize the error between the atomistic and continuum\nsolutions on the overlap between the two subdomains, while the atomistic and\ncontinuum force balance equations provide the constraints. Splitting of the\natomistic and continuum problems instead of blending them and their subsequent\nuse as constraints in the optimization problem distinguishes our approach from\nthe existing AtC formulations. We present and analyze the method in the context\nof a one-dimensional chain of atoms modeled using a linearized two-body\nnext-nearest neighbor interactions. \n\n"}
{"id": "1304.5408", "contents": "Title: High Order Space-Time Adaptive WENO Finite Volume Schemes for\n  Non-Conservative Hyperbolic Systems Abstract: We present a class of high order finite volume schemes for the solution of\nnon-conservative hyperbolic systems that combines the one-step ADER-WENO finite\nvolume approach with space-time adaptive mesh refinement (AMR). The resulting\nalgorithm, which is particularly well suited for the treatment of material\ninterfaces in compressible multi-phase flows, is based on: (i) high order of\naccuracy in space obtained through WENO reconstruction, (ii) a high order\none-step time discretization via a local space-time discontinuous Galerkin\npredictor method, and (iii) the use of a path conservative scheme for handling\nthe non-conservative terms of the equations. The AMR property with time\naccurate local time stepping, which has been treated according to a\n'cell-by-cell' strategy, strongly relies on the high order one-step time\ndiscretization, which naturally allows a high order accurate and consistent\ncomputation of the jump terms at interfaces between elements using different\ntime steps. The new scheme has been successfully validated on some test\nproblems for the Baer-Nunziato model of compressible multiphase flows. \n\n"}
{"id": "1304.5521", "contents": "Title: Vortex Filament Equation for a Regular Polygon Abstract: In this paper, we study the evolution of the vortex filament equation (VFE),\n$$\\mathbf X_t = \\mathbf X_s \\wedge \\mathbf X_{ss},$$ with $\\mathbf X(s, 0)$\nbeing a regular planar polygon. Using algebraic techniques, supported by full\nnumerical simulations, we give strong evidence that $\\mathbf X(s, t)$ is also a\npolygon at any rational time; moreover, it can be fully characterized, up to a\nrigid movement, by a generalized quadratic Gau{\\ss} sum.\n  We also study the fractal behavior of $\\mathbf X(0, t)$, relating it with the\nso-called Riemann's non-differentiable function, that was proved by Jaffard to\nbe a multifractal. \n\n"}
{"id": "1304.6475", "contents": "Title: Revisiting Asynchronous Linear Solvers: Provable Convergence Rate\n  Through Randomization Abstract: Asynchronous methods for solving systems of linear equations have been\nresearched since Chazan and Miranker's pioneering 1969 paper on chaotic\nrelaxation. The underlying idea of asynchronous methods is to avoid processor\nidle time by allowing the processors to continue to make progress even if not\nall progress made by other processors has been communicated to them.\n  Historically, the applicability of asynchronous methods for solving linear\nequations was limited to certain restricted classes of matrices, such as\ndiagonally dominant matrices. Furthermore, analysis of these methods focused on\nproving convergence in the limit. Comparison of the asynchronous convergence\nrate with its synchronous counterpart and its scaling with the number of\nprocessors were seldom studied, and are still not well understood.\n  In this paper, we propose a randomized shared-memory asynchronous method for\ngeneral symmetric positive definite matrices. We rigorously analyze the\nconvergence rate and prove that it is linear, and is close to that of the\nmethod's synchronous counterpart if the processor count is not excessive\nrelative to the size and sparsity of the matrix. We also present an algorithm\nfor unsymmetric systems and overdetermined least-squares. Our work presents a\nsignificant improvement in the applicability of asynchronous linear solvers as\nwell as in their convergence analysis, and suggests randomization as a key\nparadigm to serve as a foundation for asynchronous methods. \n\n"}
{"id": "1304.6513", "contents": "Title: Numerical study of shock formation in the dispersionless\n  Kadomtsev-Petviashvili equation and dispersive regularizations Abstract: The formation of singularities in solutions to the dispersionless\nKadomtsev-Petviashvili (dKP) equation is studied numerically for different\nclasses of initial data. The asymptotic behavior of the Fourier coefficients is\nused to quantitatively identify the critical time and location and the type of\nthe singularity. The approach is first tested in detail in 1+1 dimensions for\nthe known case of the Hopf equation, where it is shown that the break-up of the\nsolution can be identified with prescribed accuracy. For dissipative\nregularizations of this shock formation as the Burgers' equation and for\ndispersive regularizations as the Korteweg-de Vries equation, the Fourier\ncoefficients indicate as expected global regularity of the solutions. The\nKadomtsev-Petviashvili (KP) equation can be seen as a dispersive regularization\nof the dKP equation. The behavior of KP solutions for small dispersion\nparameter $\\epsilon\\ll 1$ near a break-up of corresponding dKP solutions is\nstudied. It is found that the difference between KP and dKP solutions for the\nsame initial data at the critical point scales roughly as $\\epsilon^{2/7}$ as\nfor the Korteweg-de Vries equation. \n\n"}
{"id": "1304.6908", "contents": "Title: Physics-compatible discretization techniques on single and dual grids,\n  with application to the Poisson equation of volume forms Abstract: This paper introduces the basic concepts for physics-compatible\ndiscretization techniques. The paper gives a clear distinction between vectors\nand forms. Based on the difference between forms and pseudo-forms and the\n$\\star$-operator which switches between the two, a dual grid description and a\nsingle grid description are presented. The dual grid method resembles a\nstaggered finite volume method, whereas the single grid approach shows a strong\nresemblance with a finite element method. Both approaches are compared for the\nPoisson equation for volume forms. \n\n"}
{"id": "1304.7147", "contents": "Title: Mixed Mimetic Spectral Element method applied to Darcy's problem Abstract: We present a discretization for Darcy's problem using the recently developed\nMimetic Spectral Element Method. The gist lies in the exact discrete\nrepresentation of integral relations. In this paper, an anisotropic flow\nthrough a porous medium is considered and a discretization of a full\npermeability tensor is presented. The performance of the method is evaluated on\nstandard test problems, converging at the same rate as the best possible\napproximation. \n\n"}
{"id": "1304.7218", "contents": "Title: A Nystrom flavored Calder\\'on Calculus of order three for two\n  dimensional waves Abstract: In this paper we present and test a full discretization of all elements of\nthe Calder\\'on Calculus (layer potentials and integral operators) for the\nHelmholtz equation in smooth closed curves in the plane. The resulting integral\nequations provide approximations of order three for all variables involved.\nTest are shown for a wide array of direct, indirect and combined field integral\nequation at fixed frequency and for a Convolution Quadrature based\napproximation in the time domain. \n\n"}
{"id": "1304.7425", "contents": "Title: WSLD operators: A class of fourth order difference approximations for\n  space Riemann-Liouville derivative Abstract: Because of the nonlocal properties of fractional operators, higher order\nschemes play more important role in discretizing fractional derivatives than\nclassical ones. The striking feature is that higher order schemes of fractional\nderivatives can keep the same computation cost with first-order schemes but\ngreatly improve the accuracy. Nowadays, there are already two types of second\norder discretization schemes for space fractional derivatives: the first type\nis given and discussed in [Sousa & Li, arXiv:1109.2345; Chen & Deng,\narXiv:1304.3788; Chen et al., Appl. Numer. Math., 70, 22-41]; and the second\ntype is a class of schemes presented in [Tian et al., arXiv:1201.5949]. The\ncore object of this paper is to derive a class of fourth order approximations,\ncalled the weighted and shifted Lubich difference (WSLD) operators, for space\nfractional derivatives. Then we use the derived schemes to solve the space\nfractional diffusion equation with variable coefficients in one-dimensional and\ntwo-dimensional cases. And the unconditional stability and the convergence with\nthe global truncation error $\\mathcal{O}(\\tau^2+h^4)$ are theoretically proved\nand numerically verified. \n\n"}
{"id": "1304.7796", "contents": "Title: Adaptive Near-Optimal Rank Tensor Approximation for High-Dimensional\n  Operator Equations Abstract: We consider a framework for the construction of iterative schemes for\noperator equations that combine low-rank approximation in tensor formats and\nadaptive approximation in a basis. Under fairly general assumptions, we obtain\na rigorous convergence analysis, where all parameters required for the\nexecution of the methods depend only on the underlying infinite-dimensional\nproblem, but not on a concrete discretization. Under certain assumptions on the\nrates for the involved low-rank approximations and basis expansions, we can\nalso give bounds on the computational complexity of the iteration as a function\nof the prescribed target error. Our theoretical findings are illustrated and\nsupported by computational experiments. These demonstrate that problems in very\nhigh dimensions can be treated with controlled solution accuracy. \n\n"}
{"id": "1304.8069", "contents": "Title: Fast Approximate Polynomial Multipoint Evaluation and Applications Abstract: It is well known that, using fast algorithms for polynomial multiplication\nand division, evaluation of a polynomial $F \\in \\mathbb{C}[x]$ of degree $n$ at\n$n$ complex-valued points can be done with $\\tilde{O}(n)$ exact field\noperations in $\\mathbb{C},$ where $\\tilde{O}(\\cdot)$ means that we omit\npolylogarithmic factors. We complement this result by an analysis of\napproximate multipoint evaluation of $F$ to a precision of $L$ bits after the\nbinary point and prove a bit complexity of $\\tilde{O}(n(L + \\tau + n\\Gamma)),$\nwhere $2^\\tau$ and $2^\\Gamma,$ with $\\tau, \\Gamma \\in \\mathbb{N}_{\\ge 1},$ are\nbounds on the magnitude of the coefficients of $F$ and the evaluation points,\nrespectively. In particular, in the important case where the precision demand\ndominates the other input parameters, the complexity is soft-linear in $n$ and\n$L$.\n  Our result on approximate multipoint evaluation has some interesting\nconsequences on the bit complexity of further approximation algorithms which\nall use polynomial evaluation as a key subroutine. Of these applications, we\ndiscuss in detail an algorithm for polynomial interpolation and for computing a\nTaylor shift of a polynomial. Furthermore, our result can be used to derive\nimproved complexity bounds for algorithms to refine isolating intervals for the\nreal roots of a polynomial. For all of the latter algorithms, we derive\nnear-optimal running times. \n\n"}
{"id": "1305.0161", "contents": "Title: On some properties of the Mittag-Leffler function $E_\\alpha(-t^\\alpha)$,\n  completely monotone for $t > 0$ with $0 < \\alpha < 1$ Abstract: We analyse some peculiar properties of the function of the Mittag-Leffler\n(M-L) type, $e_\\alpha(t):= E_\\alpha(-t^\\alpha)$ for $0 <\\alpha < 1$ and $t >\n0$, which is known to be completely monotone (CM) with a non negative spectrum\nof frequencies and times, suitable to model fractional relaxation processes. We\nfirst note that these two spectra coincide so providing a universal scaling\nproperty of this function. Furthermore, we consider the problem of\napproximating our M-L function with simpler CM functions for small and large\ntimes. We provide two different sets of elementary CM functions that are\nasymptotically equivalent to $e_\\alpha(t)$ as $t \\to 0$ and $t \\to \\infty$. \n\n"}
{"id": "1305.0646", "contents": "Title: Convolution spline approximations for time domain boundary integral\n  equations Abstract: We introduce a new \"convolution spline\" temporal approximation of time domain\nboundary integral equations (TDBIEs). It shares some properties of convolution\nquadrature (CQ), but instead of being based on an underlying ODE solver the\napproximation is explicitly constructed in terms of compactly supported basis\nfunctions. This results in sparse system matrices and makes it computationally\nmore efficient than using the linear multistep version of CQ for TDBIE\ntime-stepping. We use a Volterra integral equation (VIE) to illustrate the\nderivation of this new approach: at time step $t_n = n h$ the VIE solution is\napproximated in a backwards-in-time manner in terms of basis functions $\\phi_j$\nby $u(t_n-t) \\approx \\sum_{j=0}^n u_{n-j}\\,\\phi_j(t/h)$ for $t \\in [0,t_n]$. We\nshow that using isogeometric B-splines of degree $m\\ge 1$ on $[0,\\infty)$ in\nthis framework gives a second order accurate scheme, but cubic splines with the\nparabolic runout conditions at $t=0$ are fourth order accurate. We establish a\nmethodology for the stability analysis of VIEs and demonstrate that the new\nmethods are stable for non-smooth kernels which are related to convergence\nanalysis for TDBIEs, including the case of a Bessel function kernel oscillating\nat frequency $O(1/h)$. Numerical results for VIEs and for TDBIE problems on\nboth open and closed surfaces confirm the theoretical predictions. \n\n"}
{"id": "1305.1838", "contents": "Title: Locating Multiple Multi-scale Electromagnetic Scatterers by A Single\n  Far-field Measurement Abstract: Two inverse scattering schemes were recently developed in\n\\cite{LiLiuShangSun} for locating multiple electromagnetic (EM) scatterers,\nrespectively, of small size and regular size compared to the detecting EM\nwavelength. Both schemes make use of a single far-field measurement. The scheme\nof locating regular-size scatterers requires the {\\it a priori} knowledge of\nthe possible shapes, orientations and sizes of the underlying scatterer\ncomponents. In this paper, we extend that imaging scheme to a much more\npractical setting by relaxing the requirement on the orientations and sizes. We\nalso develop an imaging scheme of locating multiple multi-scale EM scatterers,\nwhich may include at the same time, both components of regular size and small\nsize. For the second scheme, a novel local re-sampling technique is developed.\nFurthermore, more robust and accurate reconstruction can be achieved for the\nsecond scheme if an additional far-field measurement is used. Rigorous\nmathematical justifications are provided and numerical results are presented to\ndemonstrate the effectiveness and the promising features of the proposed\nimaging schemes. \n\n"}
{"id": "1305.1922", "contents": "Title: Efficient Accelerated Coordinate Descent Methods and Faster Algorithms\n  for Solving Linear Systems Abstract: In this paper we show how to accelerate randomized coordinate descent methods\nand achieve faster convergence rates without paying per-iteration costs in\nasymptotic running time. In particular, we show how to generalize and\nefficiently implement a method proposed by Nesterov, giving faster asymptotic\nrunning times for various algorithms that use standard coordinate descent as a\nblack box. In addition to providing a proof of convergence for this new general\nmethod, we show that it is numerically stable, efficiently implementable, and\nin certain regimes, asymptotically optimal.\n  To highlight the computational power of this algorithm, we show how it can\nused to create faster linear system solvers in several regimes:\n  - We show how this method achieves a faster asymptotic runtime than conjugate\ngradient for solving a broad class of symmetric positive definite systems of\nequations.\n  - We improve the best known asymptotic convergence guarantees for Kaczmarz\nmethods, a popular technique for image reconstruction and solving\noverdetermined systems of equations, by accelerating a randomized algorithm of\nStrohmer and Vershynin.\n  - We achieve the best known running time for solving Symmetric Diagonally\nDominant (SDD) system of equations in the unit-cost RAM model, obtaining an O(m\nlog^{3/2} n (log log n)^{1/2} log (log n / eps)) asymptotic running time by\naccelerating a recent solver by Kelner et al.\n  Beyond the independent interest of these solvers, we believe they highlight\nthe versatility of the approach of this paper and we hope that they will open\nthe door for further algorithmic improvements in the future. \n\n"}
{"id": "1305.3639", "contents": "Title: Local error estimates for adaptive simulation of the Reaction-Diffusion\n  Master Equation via operator splitting Abstract: The efficiency of exact simulation methods for the reaction-diffusion master\nequation (RDME) is severely limited by the large number of diffusion events if\nthe mesh is fine or if diffusion constants are large. Furthermore, inherent\nproperties of exact kinetic-Monte Carlo simulation methods limit the efficiency\nof parallel implementations. Several approximate and hybrid methods have\nappeared that enable more efficient simulation of the RDME. A common feature to\nmost of them is that they rely on splitting the system into its reaction and\ndiffusion parts and updating them sequentially over a discrete timestep. This\nuse of operator splitting enables more efficient simulation but it comes at the\nprice of a temporal discretization error that depends on the size of the\ntimestep. So far, existing methods have not attempted to estimate or control\nthis error in a systematic manner. This makes the solvers hard to use for\npractitioners since they must guess an appropriate timestep. It also makes the\nsolvers potentially less efficient than if the timesteps are adapted to control\nthe error. Here, we derive estimates of the local error and propose a strategy\nto adaptively select the timestep when the RDME is simulated via a first order\noperator splitting. While the strategy is general and applicable to a wide\nrange of approximate and hybrid methods, we exemplify it here by extending a\npreviously published approximate method, the Diffusive Finite-State Projection\n(DFSP) method, to incorporate temporal adaptivity. \n\n"}
{"id": "1305.4071", "contents": "Title: Several Approaches to Break the Curse of Dimensionality Abstract: In modern science the efficient numerical treatment of high-dimensional\nproblems becomes more and more important. A fundamental insight of the theory\nof information-based complexity (IBC for short) is that the computational\nhardness of a problem can not be described properly only by the rate of\nconvergence. There exist problems for which an exponential number of\ninformation operations is needed in order to reduce the initial error, although\nthere are algorithms which provide an arbitrary large rate of convergence.\nProblems that yield this exponential dependence are said to suffer from the\ncurse of dimensionality. While analyzing numerical problems it turns out that\nwe can often vanquish this curse by exploiting additional structural\nproperties. The aim of this thesis is to present several approaches of this\ntype. Moreover, a detailed introduction to the field of IBC is given. \n\n"}
{"id": "1305.4101", "contents": "Title: An elementary approach for the phase retrieval problem Abstract: If the phase retrieval problem can be solved by a method similar to that of\nsolving a system of linear equations under the context of FFT, the time\ncomplexity of computer based phase retrieval algorithm would be reduced. Here I\npresent such a method which is recursive but highly non-linear in nature, based\non a close look at the Fourier spectrum of the square of the function norm. In\na one dimensional problem it takes $O(N^2)$ steps of calculation to recover the\nphases of an N component complex vector. This method could work in 1, 2 or even\nhigher dimensional finite Fourier analysis without changes in the behavior of\ntime complexity. For one dimensional problem the performance of an algorithm\nbased on this method is shown, where the limitations are discussed too,\nespecially when subject to random noises which contains significant high\nfrequency components. \n\n"}
{"id": "1305.4889", "contents": "Title: From microscopic theory to macroscopic theory: a systematic study on\n  static modeling for liquid crystals Abstract: In this paper, we propose a systematic way of liquid crystal modeling to\nbuild connection between microscopic theory and macroscopic theory. A new\nQ-tensor theory based on Onsager's molecular theory which leads to liquid\ncrystals with certain shape has been proposed. Making uniaxial assumption, we\ncan recover the Oseen-Frank theory from the derived $Q$-tensor theory, and the\nOseen-Frank model coefficients can be examined. In addition, the smectic-A\nphase can also be characterized by the derived macroscopic model. \n\n"}
{"id": "1305.5481", "contents": "Title: Rosenbrock-Krylov Methods for Large Systems of Differential Equations Abstract: This paper develops a new class of Rosenbrock-type integrators based on a\nKrylov space solution of the linear systems. The new family, called\nRosenbrock-Krylov (Rosenbrock-K), is well suited for solving large scale\nsystems of ODEs or semi-discrete PDEs. The time discretization and the Krylov\nspace approximation are treated as a single computational process, and the\nKrylov space properties are an integral part of the new Rosenbrock-K order\ncondition theory developed herein. Consequently, Rosenbrock-K methods require a\nsmall number of basis vectors determined solely by the temporal order of\naccuracy. The subspace size is independent of the ODE under consideration, and\nthere is no need to monitor the errors in linear system solutions at each\nstage. Numerical results show favorable properties of Rosenbrock-K methods when\ncompared to current Rosenbrock and Rosenbrock-W schemes. \n\n"}
{"id": "1305.6818", "contents": "Title: Partitioned treatment of uncertainty in coupled domain problems: A\n  separated representation approach Abstract: This work is concerned with the propagation of uncertainty across coupled\ndomain problems with high-dimensional random inputs. A stochastic model\nreduction approach based on low-rank separated representations is proposed for\nthe partitioned treatment of the uncertainty space. The construction of the\ncoupled domain solution is achieved though a sequence of approximations with\nrespect to the dimensionality of the random inputs associated with each\nindividual sub-domain and not the combined dimensionality, hence drastically\nreducing the overall computational cost. The coupling between the sub-domain\nsolutions is done via the classical Finite Element Tearing and Interconnecting\n(FETI) method, thus providing a well suited framework for parallel computing.\nTwo high-dimensional stochastic problems, a 2D elliptic PDE with random\ndiffusion coefficient and a stochastic linear elasticity problem, have been\nconsidered to study the performance and accuracy of the proposed stochastic\ncoupling approach. \n\n"}
{"id": "1306.0612", "contents": "Title: Fast integral equation methods for the Laplace-Beltrami equation on the\n  sphere Abstract: Integral equation methods for solving the Laplace-Beltrami equation on the\nunit sphere in the presence of multiple \"islands\" are presented. The surface of\nthe sphere is first mapped to a multiply-connected region in the complex plane\nvia a stereographic projection. After discretizing the integral equation, the\nresulting dense linear system is solved iteratively using the fast multipole\nmethod for the 2D Coulomb potential in order to calculate the matrix-vector\nproducts. This numerical scheme requires only O(N) operations, where $N$ is the\nnumber of nodes in the discretization of the boundary. The performance of the\nmethod is demonstrated on several examples. \n\n"}
{"id": "1306.0936", "contents": "Title: Benchmarking the Immersed Finite Element Method for Fluid-Structure\n  Interaction Problems Abstract: We present an implementation of a fully variational formulation of an\nimmersed method for fluid-structure interaction problems based on the finite\nelement method. While typical implementation of immersed methods are\ncharacterized by the use of approximate Dirac delta distributions, fully\nvariational formulations of the method do not require the use of said\ndistributions. In our implementation the immersed solid is general in the sense\nthat it is not required to have the same mass density and the same viscous\nresponse as the surrounding fluid. We assume that the immersed solid can be\neither viscoelastic of differential type or hyperelastic. Here we focus on the\nvalidation of the method via various benchmarks for fluid-structure interaction\nnumerical schemes. This is the first time that the interaction of purely\nelastic compressible solids and an incompressible fluid is approached via an\nimmersed method allowing a direct comparison with established benchmarks. \n\n"}
{"id": "1306.1392", "contents": "Title: PyHST2: an hybrid distributed code for high speed tomographic\n  reconstruction with iterative reconstruction and a priori knowledge\n  capabilities Abstract: We present the PyHST2 code which is in service at ESRF for phase-contrast and\nabsorption tomography. This code has been engineered to sustain the high data\nflow typical of the third generation synchrotron facilities (10 terabytes per\nexperiment) by adopting a distributed and pipelined architecture. The code\nimplements, beside a default filtered backprojection reconstruction, iterative\nreconstruction techniques with a-priori knowledge. These latter are used to\nimprove the reconstruction quality or in order to reduce the required data\nvolume and reach a given quality goal. The implemented a-priori knowledge\ntechniques are based on the total variation penalisation and a new recently\nfound convex functional which is based on overlapping patches.\n  We give details of the different methods and their implementations while the\ncode is distributed under free license.\n  We provide methods for estimating, in the absence of ground-truth data, the\noptimal parameters values for a-priori techniques. \n\n"}
{"id": "1306.1987", "contents": "Title: Sign-preserving of principal eigenfunctions in P1 finite element\n  approximation of eigenvalue problems of second-order elliptic operators Abstract: This paper is concerned with the P1 finite element approximation of the\neigenvalue problem of second-order elliptic operators subject to the Dirichlet\nboundary condition. The focus is on the preservation of basic properties of the\nprincipal eigenvalue and eigenfunctions of continuous problems. It is shown\nthat when the stiffness matrix is an irreducible $M$-matrix, the algebraic\neigenvalue problem maintains those properties such as the smallest eigenvalue\nbeing real and simple and the corresponding eigenfunctions being either\npositive or negative inside the physical domain. Mesh conditions leading to\nsuch a stiffness matrix are also studied. A sufficient condition is that the\nmesh is simplicial, acute when measured in the metric specified by the inverse\nof the diffusion matrix, and interiorly connected. The acute requirement can be\nreplaced by the Delaunay condition in two dimensions. Numerical results are\npresented to verify the theoretical findings. \n\n"}
{"id": "1306.2192", "contents": "Title: Eliminating Spurious Velocities with a Stable Approximation of Viscous\n  Incompressible Two-Phase Stokes Flow Abstract: We present a parametric finite element approximation of two-phase flow. This\nfree boundary problem is given by the Stokes equations in the two phases, which\nare coupled via jump conditions across the interface. Using a novel variational\nformulation for the interface evolution gives rise to a natural discretization\nof the mean curvature of the interface. In addition, the mesh quality of the\nparametric approximation of the interface does not deteriorate, in general,\nover time; and an equidistribution property can be shown for a semidiscrete\ncontinuous-in-time variant of our scheme in two space dimensions. Moreover, on\nusing a simple XFEM pressure space enrichment, we obtain exact volume\nconservation for the two phase regions. Furthermore, our fully discrete finite\nelement approximation can be shown to be unconditionally stable. We demonstrate\nthe applicability of our method with some numerical results which, in\nparticular, demonstrate that spurious velocities can be avoided in the\nclassical test cases. \n\n"}
{"id": "1306.2269", "contents": "Title: Computation of extreme eigenvalues in higher dimensions using block\n  tensor train format Abstract: We consider an approximate computation of several minimal eigenpairs of large\nHermitian matrices which come from high--dimensional problems. We use the\ntensor train format (TT) for vectors and matrices to overcome the curse of\ndimensionality and make storage and computational cost feasible. Applying a\nblock version of the TT format to several vectors simultaneously, we compute\nthe low--lying eigenstates of a system by minimization of a block Rayleigh\nquotient performed in an alternating fashion for all dimensions. For several\nnumerical examples, we compare the proposed method with the deflation approach\nwhen the low--lying eigenstates are computed one-by-one, and also with the\nvariational algorithms used in quantum physics. \n\n"}
{"id": "1306.4075", "contents": "Title: Geometric aspects of Pellet's and related theorems Abstract: Pellet's theorem determines when the zeros of a polynomial can be separated\ninto two regions, according to their moduli. We refine one of those regions and\nreplace it with the closed interior of a lemniscate that provides more precise\ninformation on the location of the zeros. Moreover, Pellet's theorem is\nconsidered the generalization of a zero inclusion region due to Cauchy. Using\nlinear algebra tools, we derive a different generalization that leads to a\nsequence of smaller inclusion regions, which are also the closed interiors of\nlemniscates. \n\n"}
{"id": "1306.4690", "contents": "Title: Model Reduction with MapReduce-enabled Tall-and-Skinny Singular Value\n  Decomposition Abstract: We present a method for computing reduced-order models of parameterized\npartial differential equation solutions. The key analytical tool is the\nsingular value expansion of the parameterized solution, which we approximate\nwith a singular value decomposition of a parameter snapshot matrix. To evaluate\nthe reduced-order model at a new parameter, we interpolate a subset of the\nright singular vectors to generate the reduced-order model's coefficients. We\nemploy a novel method to select this subset that uses the parameter gradient of\nthe right singular vectors to split the terms in the expansion yielding a mean\nprediction and a prediction covariance---similar to a Gaussian process\napproximation. The covariance serves as a confidence measure for the reduce\norder model. We demonstrate the efficacy of the reduced-order model using a\nparameter study of heat transfer in random media. The high-fidelity simulations\nproduce more than 4TB of data; we compute the singular value decomposition and\nevaluate the reduced-order model using scalable MapReduce/Hadoop\nimplementations. We compare the accuracy of our method with a scalar response\nsurface on a set of temperature profile measurements and find that our model\nbetter captures sharp, local features in the parameter space. \n\n"}
{"id": "1306.5013", "contents": "Title: Randomized Interpolative Decomposition of Separated Representations Abstract: We introduce tensor Interpolative Decomposition (tensor ID) for the reduction\nof the separation rank of Canonical Tensor Decompositions (CTDs). Tensor ID\nselects, for a user-defined accuracy \\epsilon, a near optimal subset of terms\nof a CTD to represent the remaining terms via a linear combination of the\nselected terms. Tensor ID can be used as an alternative to or a step of the\nAlternating Least Squares (ALS) algorithm. In addition, we briefly discuss\nQ-factorization to reduce the size of components within an ALS iteration.\nCombined, tensor ID and Q-factorization lead to a new paradigm for the\nreduction of the separation rank of CTDs. In this context, we also discuss the\nspectral norm as a computational alternative to the Frobenius norm.\n  We reduce the problem of finding tensor IDs to that of constructing\nInterpolative Decompositions of certain matrices. These matrices are generated\nvia either randomized projection or randomized sampling of the given tensor. We\nprovide cost estimates and several examples of the new approach to the\nreduction of separation rank. \n\n"}
{"id": "1307.1312", "contents": "Title: A multi-level spectral deferred correction method Abstract: The spectral deferred correction (SDC) method is an iterative scheme for\ncomputing a higher-order collocation solution to an ODE by performing a series\nof correction sweeps using a low-order timestepping method. This paper examines\na variation of SDC for the temporal integration of PDEs called multi-level\nspectral deferred corrections (MLSDC), where sweeps are performed on a\nhierarchy of levels and an FAS correction term, as in nonlinear multigrid\nmethods, couples solutions on different levels. Three different strategies to\nreduce the computational cost of correction sweeps on the coarser levels are\nexamined: reducing the degrees of freedom, reducing the order of the spatial\ndiscretization, and reducing the accuracy when solving linear systems arising\nin implicit temporal integration. Several numerical examples demonstrate the\neffect of multi-level coarsening on the convergence and cost of SDC\nintegration. In particular, MLSDC can provide significant savings in compute\ntime compared to SDC for a three-dimensional problem. \n\n"}
{"id": "1307.2474", "contents": "Title: Finite difference method for a general fractional porous medium equation Abstract: We formulate a numerical method to solve the porous medium type equation with\nfractional diffusion \\[ \\frac{\\partial u}{\\partial t}+(-\\Delta)^{\\sigma/2}\n(u^m)=0 \\] posed for $x\\in \\mathbb{R}^N$, $t>0$, with $m\\geq 1$, $\\sigma \\in\n(0,2)$, and nonnegative initial data $u(x,0)$. We prove existence and\nuniqueness of the solution of the numerical method and also the convergence to\nthe theoretical solution of the equation with an order depending on $\\sigma$.\nWe also propose a two points approximation to a $\\sigma$-derivative with order\n$O(h^{2-\\sigma})$. \n\n"}
{"id": "1307.3108", "contents": "Title: Bernoulli, Ramanujan, Toeplitz and the triangular matrices Abstract: By using one of the definitions of the Bernoulli numbers, we prove that they\nsolve particular odd and even lower triangular Toeplitz (l.t.T.) systems of\nequations. In a paper Ramanujan writes down a sparse lower triangular system\nsolved by Bernoulli numbers; we observe that such system is equivalent to a\nsparse l.t.T. system. The attempt to obtain the sparse l.t.T. Ramanujan system\nfrom the l.t.T. odd and even systems, has led us to study efficient methods for\nsolving generic l.t.T. systems. Such methods are here explained in detail in\ncase n, the number of equations, is a power of b, b=2,3 and b generic. \n\n"}
{"id": "1307.6127", "contents": "Title: Sequential Monte Carlo Methods for High-Dimensional Inverse Problems: A\n  case study for the Navier-Stokes equations Abstract: We consider the inverse problem of estimating the initial condition of a\npartial differential equation, which is only observed through noisy\nmeasurements at discrete time intervals. In particular, we focus on the case\nwhere Eulerian measurements are obtained from the time and space evolving\nvector field, whose evolution obeys the two-dimensional Navier-Stokes equations\ndefined on a torus. This context is particularly relevant to the area of\nnumerical weather forecasting and data assimilation. We will adopt a Bayesian\nformulation resulting from a particular regularization that ensures the problem\nis well posed. In the context of Monte Carlo based inference, it is a\nchallenging task to obtain samples from the resulting high dimensional\nposterior on the initial condition. In real data assimilation applications it\nis common for computational methods to invoke the use of heuristics and\nGaussian approximations. The resulting inferences are biased and not\nwell-justified in the presence of non-linear dynamics and observations. On the\nother hand, Monte Carlo methods can be used to assimilate data in a principled\nmanner, but are often perceived as inefficient in this context due to the\nhigh-dimensionality of the problem. In this work we will propose a generic\nSequential Monte Carlo (SMC) sampling approach for high dimensional inverse\nproblems that overcomes these difficulties. The method builds upon Markov chain\nMonte Carlo (MCMC) techniques, which are currently considered as benchmarks for\nevaluating data assimilation algorithms used in practice. In our numerical\nexamples, the proposed SMC approach achieves the same accuracy as MCMC but in a\nmuch more efficient manner. \n\n"}
{"id": "1307.7496", "contents": "Title: A fast direct solver for scattering from periodic structures with\n  multiple material interfaces in two dimensions Abstract: We present a new integral equation method for the calculation of\ntwo-dimensional scattering from periodic structures involving triple-points\n(multiple materials meeting at a single point). The combination of a robust and\nhigh-order accurate integral representation and a fast direct solver permits\nthe efficient simulation of scattering from fixed structures at multiple angles\nof incidence. We demonstrate the performance of the scheme with several\nnumerical examples. \n\n"}
{"id": "1307.7867", "contents": "Title: A space-time parallel solver for the three-dimensional heat equation Abstract: The paper presents a combination of the time-parallel \"parallel full\napproximation scheme in space and time\" (PFASST) with a parallel multigrid\nmethod (PMG) in space, resulting in a mesh-based solver for the\nthree-dimensional heat equation with a uniquely high degree of efficient\nconcurrency. Parallel scaling tests are reported on the Cray XE6 machine \"Monte\nRosa\" on up to 16,384 cores and on the IBM Blue Gene/Q system \"JUQUEEN\" on up\nto 65,536 cores. The efficacy of the combined spatial- and temporal\nparallelization is shown by demonstrating that using PFASST in addition to PMG\nsignificantly extends the strong-scaling limit. Implications of using spatial\ncoarsening strategies in PFASST's multi-level hierarchy in large-scale parallel\nsimulations are discussed. \n\n"}
{"id": "1308.0724", "contents": "Title: On the decay of elements of inverse triangular Toeplitz matrix Abstract: We consider half-infinite triangular Toeplitz matrices with slow decay of the\nelements and prove under a monotonicity condition that elements of the inverse\nmatrix, as well as elements of the fundamental matrix, decay to zero. We also\nprovide a quantitative description of the decay of the fundamental matrix in\nterms of p-norms. Finally, we prove that for matrices with slow log-convex\ndecay the inverse matrix has fast decay, i.e. is bounded. The results are\ncompared with the classical results of Jaffard and Veccio and illustrated by\nnumerical example. \n\n"}
{"id": "1308.0802", "contents": "Title: Nitsche's method for two and three dimensional NURBS patch coupling Abstract: A Nitche's method is presented to couple non-conforming two and three\ndimensional NURBS (Non Uniform Rational B-splines) patches in the context of\nisogeometric analysis (IGA). We present results for elastic stress analyses\nunder the static condition of two and three dimensional NURBS geometries. The\ncontribution fills the gap in the literature and enlarges the applicability of\nNURBS-based isogeometric analysis. \n\n"}
{"id": "1308.3335", "contents": "Title: A Stable Parametric Finite Element Discretization of Two-Phase\n  Navier--Stokes Flow Abstract: We present a parametric finite element approximation of two-phase flow. This\nfree boundary problem is given by the Navier--Stokes equations in the two\nphases, which are coupled via jump conditions across the interface. Using a\nnovel variational formulation for the interface evolution gives rise to a\nnatural discretization of the mean curvature of the interface. The parametric\nfinite element approximation of the evolving interface is then coupled to a\nstandard finite element approximation of the two-phase Navier--Stokes equations\nin the bulk. Here enriching the pressure approximation space with the help of\nan XFEM function ensures good volume conservation properties for the two phase\nregions. In addition, the mesh quality of the parametric approximation of the\ninterface in general does not deteriorate over time, and an equidistribution\nproperty can be shown for a semidiscrete continuous-in-time variant of our\nscheme in two space dimensions. Moreover, our finite element approximation can\nbe shown to be unconditionally stable. We demonstrate the applicability of our\nmethod with some numerical results in two and three space dimensions. \n\n"}
{"id": "1308.4322", "contents": "Title: On the Optimal Rates of Convergence for Quadratures Derived from\n  Chebyshev Points Abstract: In this paper, we study the optimal general convergence rates for quadratures\nderived from Chebyshev points. By building on the aliasing errors on\nintegration of Chebyshev polynomials, together with the asymptotic formulae on\nthe coefficients of Chebyshev expansions, new and optimal convergence rates for\n$n$-point Clenshaw-Curtis, Fej\\'{e}r's first and second quadrature rules are\nestablished for Jacobi weights or Jacobi weights multiplied by $\\ln((x+1)/2)$.\nThe convergence orders are attainable for some functions of finite\nregularities. In addition, by using refined estimates on aliasing errors on\nintegration of Chebyshev polynomials by Gauss-Legendre quadrature, an improved\nconvergence rate for Gauss-Legendre is given too. \n\n"}
{"id": "1308.5049", "contents": "Title: Low-discrepancy point sets for non-uniform measures Abstract: In the present paper we prove several results concerning the existence of\nlow-discrepancy point sets with respect to an arbitrary non-uniform measure\n$\\mu$ on the $d$-dimensional unit cube. We improve a theorem of Beck, by\nshowing that for any $d \\geq 1$, $N \\geq 1,$ and any non-negative, normalized\nBorel measure $\\mu$ on $[0,1]^d$ there exists a point set $x_1, \\dots, x_N \\in\n[0,1]^d$ whose star-discrepancy with respect to $\\mu$ is of order $$ D_N^*(x_1,\n\\dots, x_N; \\mu) \\ll \\frac{(\\log N)^{(3d+1)/2}}{N}. $$ For the proof we use a\ntheorem of Banaszczyk concerning the balancing of vectors, which implies an\nupper bound for the linear discrepancy of hypergraphs. Furthermore, the theory\nof large deviation bounds for empirical processes indexed by sets is discussed,\nand we prove a numerically explicit upper bound for the inverse of the\ndiscrepancy for Vapnik--\\v{C}ervonenkis classes. Finally, using a recent\nversion of the Koksma--Hlawka inequality due to Brandolini, Colzani, Gigante\nand Travaglini, we show that our results imply the existence of cubature rules\nyielding fast convergence rates for the numerical integration of functions\nhaving discontinuities of a certain form. \n\n"}
{"id": "1308.5952", "contents": "Title: Low-rank approximation in the numerical modeling of the Farley-Buneman\n  instability in ionospheric plasma Abstract: We consider the numerical modeling of the Farley-Buneman instability\ndevelopment in the earth's ionosphere plasma. The ion behavior is governed by\nthe kinetic Landau equation in the four-dimensional phase space, and since the\nfinite difference discretization on a tensor product grid is used, this\nequation becomes the most computationally challenging part of the scheme. To\nrelax the complexity and memory consumption, an adaptive model reduction using\nthe low-rank separation of variables, namely the Tensor Train format, is\nemployed.\n  The approach was verified via the prototype MATLAB implementation. Numerical\nexperiments demonstrate the possibility of efficient separation of space and\nvelocity variables, resulting in the solution storage reduction by a factor of\norder tens. \n\n"}
{"id": "1309.0826", "contents": "Title: Truncated hierarchical preconditioning for the stochastic Galerkin FEM Abstract: Stochastic Galerkin finite element discretizations of partial differential\nequations with coefficients characterized by arbitrary distributions lead, in\ngeneral, to fully block dense linear systems. We propose two novel strategies\nfor constructing preconditioners for these systems to be used with Krylov\nsubspace iterative solvers. In particular, we present a variation on of the\nhierarchical Schur complement preconditioner, developed recently by the\nauthors, and an adaptation of the symmetric block Gauss-Seidel method. Both\npreconditioners take advantage of the hierarchical structure of global\nstochastic Galerkin matrices, and also, when applicable, of the decay of the\nnorms of the stiffness matrices obtained from the polynomial chaos expansion of\nthe coefficients. This decay allows to truncate the matrix-vector\nmultiplications in the action of the preconditioners. Also, throughout the\nglobal matrix hierarchy, we approximate solves with certain submatrices by the\nassociated diagonal block solves. The preconditioners thus require only a\nlimited number of stiffness matrices obtained from the polynomial chaos\nexpansion of the coefficients, and a preconditioner for the diagonal blocks of\nthe global matrix. The performance is illustrated by numerical experiments. \n\n"}
{"id": "1309.1317", "contents": "Title: Propagation of internal errors in explicit Runge--Kutta methods and\n  internal stability of SSP and extrapolation methods Abstract: In practical computation with Runge--Kutta methods, the stage equations are\nnot satisfied exactly, due to roundoff errors, algebraic solver errors, and so\nforth. We show by example that propagation of such errors within a single step\ncan have catastrophic effects for otherwise practical and well-known methods.\nWe perform a general analysis of internal error propagation, emphasizing that\nit depends significantly on how the method is implemented. We show that for a\nfixed method, essentially any set of internal stability polynomials can be\nobtained by modifying the implementation details. We provide bounds on the\ninternal error amplification constants for some classes of methods with many\nstages, including strong stability preserving methods and extrapolation\nmethods. These results are used to prove error bounds in the presence of\nroundoff or other internal errors. \n\n"}
{"id": "1309.2832", "contents": "Title: Energy-conserving methods for Hamiltonian Boundary Value Problems and\n  applications in astrodynamics Abstract: We introduce new methods for the numerical solution of general Hamiltonian\nboundary value problems. The main feature of the new formulae is to produce\nnumerical solutions along which the energy is precisely conserved, as is the\ncase with the analytical solution. We apply the methods to locate periodic\norbits in the circular restricted three body problem by using their energy\nvalue rather than their pe- riod as input data. We also use the methods for\nsolving optimal transfer problems in astrodynamics. \n\n"}
{"id": "1309.5560", "contents": "Title: An Efficient Numerical Scheme for the Biharmonic Equation by Weak\n  Galerkin Finite Element Methods on Polygonal or Polyhedral Meshes Abstract: This paper presents a new and efficient numerical algorithm for the\nbiharmonic equation by using weak Galerkin (WG) finite element methods. The WG\nfinite element scheme is based on a variational form of the biharmonic equation\nthat is equivalent to the usual $H^2$-semi norm. Weak partial derivatives and\ntheir approximations, called discrete weak partial derivatives, are introduced\nfor a class of discontinuous functions defined on a finite element partition of\nthe domain consisting of general polygons or polyhedra. The discrete weak\npartial derivatives serve as building blocks for the WG finite element method.\nThe resulting matrix from the WG method is symmetric, positive definite, and\nparameter free. An error estimate of optimal order is derived in an\n$H^2$-equivalent norm for the WG finite element solutions. Error estimates in\nthe usual $L^2$ norm are established, yielding optimal order of convergence for\nall the WG finite element algorithms except the one corresponding to the lowest\norder (i.e., piecewise quadratic elements). Some numerical experiments are\npresented to illustrate the efficiency and accuracy of the numerical scheme. \n\n"}
{"id": "1309.7128", "contents": "Title: A GPU cluster optimized multigrid scheme for computing unsteady\n  incompressible fluid flow Abstract: A multigrid scheme is proposed for the pressure equation of the\nincompressible unsteady fluid flow equations, allowing efficient implementation\non clusters of modern CPUs, many integrated core devices (MICs), and graphics\nprocessing units (GPUs). It is shown that the total number of the\nsynchronization events can be significantly reduced when a deep, 2h grid\nhierarchy is replaced with a two-level scheme using 16h-32h restriction,\nfitting to the the width of the SIMD engine of modern CPUs and GPUs. In\naddition, optimal memory transfer is also ensured, since no strided memory\naccess is required. We report increasing arithmetic intensity of the smoothing\nsteps when compared to the conventional additive correction multigrid (ACM),\nhowever it is counterbalanced in runtime by the decreasing number of the\nexpensive restriction steps. A systematic construction methodology for the\ncoarse grid stencil is also presented that helps in moderating the excess\narithmetic intensity associated with the aggressive coarsening. Our higher\norder interpolated stencil improves convergence rate via minimizing spurious\ninterference between the coarse and the fine scale solutions. The method is\ndemonstrated on solving the pressure equation for 2D incompressible fluid flow:\nThe benchmark setups cover shear driven laminar flow in cavity, and direct\nnumerical simulation (DNS) of a turbulent jet. We have compared our scheme to\nthe ACM in terms of the arithmetic intensity of the iterations and the number\nof the synchronization calls required. Also the strong scaling is plotted for\nour scheme when using a hybrid OpenCl/MPI based parallelization. \n\n"}
{"id": "1309.7280", "contents": "Title: A splitting higher order scheme with discrete transparent boundary\n  conditions for the Schr\\\"odinger equation in a semi-infinite parallelepiped Abstract: An initial-boundary value problem for the $n$-dimensional ($n\\geq 2$)\ntime-dependent Schr\\\"odinger equation in a semi-infinite (or infinite)\nparallelepiped is considered. Starting from the Numerov-Crank-Nicolson\nfinite-difference scheme, we first construct higher order scheme with splitting\nspace averages having much better spectral properties for $n\\geq 3$. Next we\napply the Strang-type splitting with respect to the potential and, third,\nconstruct discrete transparent boundary conditions (TBC). For the resulting\nmethod, the uniqueness of solution and the unconditional uniform in time\n$L^2$-stability (in particular, $L^2$-conservativeness) are proved. Owing to\nthe splitting, an effective direct algorithm using FFT (in the coordinate\ndirections perpendicular to the leading axis of the parallelepiped) is\napplicable for general potential. Numerical results on the 2D tunnel effect for\na P\\\"{o}schl-Teller-like potential-barrier and a rectangular potential-well are\nalso included. \n\n"}
{"id": "1309.7298", "contents": "Title: A Greedy Algorithm for the Analysis Transform Domain Abstract: Many image processing applications benefited remarkably from the theory of\nsparsity. One model of sparsity is the cosparse analysis one. It was shown that\nusing l_1-minimization one might stably recover a cosparse signal from a small\nset of random linear measurements if the operator is a frame. Another effort\nhas provided guarantees for dictionaries that have a near optimal projection\nprocedure using greedy-like algorithms. However, no claims have been given for\nframes. A common drawback of all these existing techniques is their high\ncomputational cost for large dimensional problems.\n  In this work we propose a new greedy-like technique with theoretical recovery\nguarantees for frames as the analysis operator, closing the gap between greedy\nand relaxation techniques. Our results cover both the case of bounded\nadversarial noise, where we show that the algorithm provides us with a stable\nreconstruction, and the one of random Gaussian noise, for which we prove that\nit has a denoising effect, closing another gap in the analysis framework. Our\nproposed program, unlike the previous greedy-like ones that solely act in the\nsignal domain, operates mainly in the analysis operator's transform domain.\nBesides the theoretical benefit, the main advantage of this strategy is its\ncomputational efficiency that makes it easily applicable to visually big data.\nWe demonstrate its performance on several high dimensional images. \n\n"}
{"id": "1310.2699", "contents": "Title: Construction of conformal mappings by generalized polarization tensors Abstract: We present a new systematic method to construct the conformal mapping from\noutside the unit disc to outside of a simply connected domain using the\ngeneralized polarization tensors. We also present some numerical results to\nvalidate effectiveness of the method. \n\n"}
{"id": "1310.2828", "contents": "Title: A Two-Level Method for Mimetic Finite Difference Discretizations of\n  Elliptic Problems Abstract: We propose and analyze a two-level method for mimetic finite difference\napproximations of second order elliptic boundary value problems. We prove that\nthe two-level algorithm is uniformly convergent, i.e., the number of iterations\nneeded to achieve convergence is uniformly bounded independently of the\ncharacteristic size of the underling partition. We also show that the resulting\nscheme provides a uniform preconditioner with respect to the number of degrees\nof freedom. Numerical results that validate the theory are also presented. \n\n"}
{"id": "1310.2842", "contents": "Title: Wavelet methods for shape perception in electro-sensing Abstract: This paper aims at presenting a new approach to the electro-sensing problem\nusing wavelets. It provides an efficient algorithm for recognizing the shape of\na target from micro-electrical impedance measurements. Stability and resolution\ncapabilities of the proposed algorithm are quantified in numerical simulations. \n\n"}
{"id": "1310.3240", "contents": "Title: Phase Retrieval from Coded Diffraction Patterns Abstract: This paper considers the question of recovering the phase of an object from\nintensity-only measurements, a problem which naturally appears in X-ray\ncrystallography and related disciplines. We study a physically realistic setup\nwhere one can modulate the signal of interest and then collect the intensity of\nits diffraction pattern, each modulation thereby producing a sort of coded\ndiffraction pattern. We show that PhaseLift, a recent convex programming\ntechnique, recovers the phase information exactly from a number of random\nmodulations, which is polylogarithmic in the number of unknowns. Numerical\nexperiments with noiseless and noisy data complement our theoretical analysis\nand illustrate our approach. \n\n"}
{"id": "1310.4215", "contents": "Title: Unconditionally stable high-order time integration for moving mesh\n  finite difference solution of linear convection-diffusion equations Abstract: This paper is concerned with moving mesh finite difference solution of\npartial differential equations. It is known that mesh movement introduces an\nextra convection term and its numerical treatment has a significant impact on\nthe stability of numerical schemes. Moreover, many implicit second and higher\norder schemes, such as the Crank-Nicolson scheme, will loss their unconditional\nstability. A strategy is presented for developing temporally high order,\nunconditionally stable finite difference schemes for solving linear\nconvection-diffusion equations using moving meshes. Numerical results are given\nto demonstrate the theoretical findings. \n\n"}
{"id": "1310.4715", "contents": "Title: An explicit kernel-split panel-based Nystr\\\"om scheme for integral\n  equations on axially symmetric surfaces Abstract: A high-order accurate, explicit kernel-split, panel-based, Fourier-Nystr\\\"om\ndiscretization scheme is developed for integral equations associated with the\nHelmholtz equation in axially symmetric domains. Extensive incorporation of\nanalytic information about singular integral kernels and on-the-fly computation\nof nearly singular quadrature rules allow for very high achievable accuracy,\nalso in the evaluation of fields close to the boundary of the computational\ndomain. \n\n"}
{"id": "1310.5715", "contents": "Title: Stochastic Gradient Descent, Weighted Sampling, and the Randomized\n  Kaczmarz algorithm Abstract: We obtain an improved finite-sample guarantee on the linear convergence of\nstochastic gradient descent for smooth and strongly convex objectives,\nimproving from a quadratic dependence on the conditioning $(L/\\mu)^2$ (where\n$L$ is a bound on the smoothness and $\\mu$ on the strong convexity) to a linear\ndependence on $L/\\mu$. Furthermore, we show how reweighting the sampling\ndistribution (i.e. importance sampling) is necessary in order to further\nimprove convergence, and obtain a linear dependence in the average smoothness,\ndominating previous results. We also discuss importance sampling for SGD more\nbroadly and show how it can improve convergence also in other scenarios. Our\nresults are based on a connection we make between SGD and the randomized\nKaczmarz algorithm, which allows us to transfer ideas between the separate\nbodies of literature studying each of the two methods. In particular, we recast\nthe randomized Kaczmarz algorithm as an instance of SGD, and apply our results\nto prove its exponential convergence, but to the solution of a weighted least\nsquares problem rather than the original least squares problem. We then present\na modified Kaczmarz algorithm with partially biased sampling which does\nconverge to the original least squares solution with the same exponential\nconvergence rate. \n\n"}
{"id": "1310.6098", "contents": "Title: Optimal Shape Design by Partial Spectral Data Abstract: In this paper, we are concerned with a shape design problem, in which our\ntarget is to design, up to rigid transformations and scaling, the shape of an\nobject given either its polarization tensor at multiple contrasts or the\npartial eigenvalues of its Neumann-Poincar\\'e operator, which are known as the\nFredholm eigenvalues. We begin by proposing to recover the eigenvalues of the\nNeumann-Poincar\\'e operator from the polarization tensor by means of the\nholomorphic functional calculus. Then we develop a regularized Gauss-Newton\noptimization method for the shape reconstruction process. We present numerical\nresults to demonstrate the effectiveness of the proposed methods and to\nillustrate important properties of the Fredholm eigenvalues and their\nassociated eigenfunctions. Our results are expected to have important\napplications in the design of plasmon resonances in nanoparticles as well as in\nthe multifrequency or pulsed imaging of small anomalies. \n\n"}
{"id": "1310.6331", "contents": "Title: Revisionist Integral Deferred Correction with Adaptive Stepsize Control Abstract: Adaptive stepsize control is a critical feature for the robust and efficient\nnumerical solution of initial-value problems in ordinary differential\nequations. In this paper, we show that adaptive stepsize control can be\nincorporated within a family of parallel time integrators known as Revisionist\nIntegral Deferred Correction (RIDC) methods. The RIDC framework allows for\nvarious strategies to implement stepsize control, and we report results from\nexploring a few of them. \n\n"}
{"id": "1310.8107", "contents": "Title: Scalable Frames and Convex Geometry Abstract: The recently introduced and characterized scalable frames can be considered\nas those frames which allow for perfect preconditioning in the sense that the\nframe vectors can be rescaled to yield a tight frame. In this paper we define\n$m$-scalability, a refinement of scalability based on the number of non-zero\nweights used in the rescaling process, and study the connection between this\nnotion and elements from convex geometry. Finally, we provide results on the\ntopology of scalable frames. In particular, we prove that the set of scalable\nframes with \"small\" redundancy is nowhere dense in the set of frames. \n\n"}
{"id": "1310.8219", "contents": "Title: Comparative model accuracy of a data-fitted generalized Aw-Rascle-Zhang\n  model Abstract: The Aw-Rascle-Zhang (ARZ) model can be interpreted as a generalization of the\nLighthill-Whitham-Richards (LWR) model, possessing a family of fundamental\ndiagram curves, each of which represents a class of drivers with a different\nempty road velocity. A weakness of this approach is that different drivers\npossess vastly different densities at which traffic flow stagnates. This\ndrawback can be overcome by modifying the pressure relation in the ARZ model,\nleading to the generalized Aw-Rascle-Zhang (GARZ) model. We present an approach\nto determine the parameter functions of the GARZ model from fundamental diagram\nmeasurement data. The predictive accuracy of the resulting data-fitted GARZ\nmodel is compared to other traffic models by means of a three-detector test\nsetup, employing two types of data: vehicle trajectory data, and sensor data.\nThis work also considers the extension of the ARZ and the GARZ models to models\nwith a relaxation term, and conducts an investigation of the optimal relaxation\ntime. \n\n"}
{"id": "1311.4432", "contents": "Title: On the Stable Numerical Approximation of Two-Phase Flow with Insoluble\n  Surfactant Abstract: We present a parametric finite element approximation of two-phase flow with\ninsoluble surfactant. This free boundary problem is given by the Navier--Stokes\nequations for the two-phase flow in the bulk, which are coupled to the\ntransport equation for the insoluble surfactant on the interface that separates\nthe two phases. We combine the evolving surface finite element method with an\napproach previously introduced by the authors for two-phase Navier--Stokes\nflow, which maintains good mesh properties. The derived finite element\napproximation of two-phase flow with insoluble surfactant can be shown to be\nstable. Several numerical simulations demonstrate the practicality of our\nnumerical method. \n\n"}
{"id": "1311.5414", "contents": "Title: Computational Complexity of Smooth Differential Equations Abstract: The computational complexity of the solutions $h$ to the ordinary\ndifferential equation $h(0)=0$, $h'(t) = g(t, h(t))$ under various assumptions\non the function $g$ has been investigated. Kawamura showed in 2010 that the\nsolution $h$ can be PSPACE-hard even if $g$ is assumed to be Lipschitz\ncontinuous and polynomial-time computable. We place further requirements on the\nsmoothness of $g$ and obtain the following results: the solution $h$ can still\nbe PSPACE-hard if $g$ is assumed to be of class $C^1$; for each $k\\ge2$, the\nsolution $h$ can be hard for the counting hierarchy even if $g$ is of class\n$C^k$. \n\n"}
{"id": "1311.5882", "contents": "Title: Spatially Adaptive Stochastic Methods for Fluid-Structure Interactions\n  Subject to Thermal Fluctuations in Domains with Complex Geometries Abstract: We develop stochastic mixed finite element methods for spatially adaptive\nsimulations of fluid-structure interactions when subject to thermal\nfluctuations. To account for thermal fluctuations, we introduce a discrete\nfluctuation-dissipation balance condition to develop compatible stochastic\ndriving fields for our discretization. We perform analysis that shows our\ncondition is sufficient to ensure results consistent with statistical\nmechanics. We show the Gibbs-Boltzmann distribution is invariant under the\nstochastic dynamics of the semi-discretization. To generate efficiently the\nrequired stochastic driving fields, we develop a Gibbs sampler based on\niterative methods and multigrid to generate fields with $O(N)$ computational\ncomplexity. Our stochastic methods provide an alternative to uniform\ndiscretizations on periodic domains that rely on Fast Fourier Transforms. To\ndemonstrate in practice our stochastic computational methods, we investigate\nwithin channel geometries having internal obstacles and no-slip walls how the\nmobility/diffusivity of particles depends on location. Our methods extend the\napplicability of fluctuating hydrodynamic approaches by allowing for spatially\nadaptive resolution of the mechanics and for domains that have complex\ngeometries relevant in many applications. \n\n"}
{"id": "1312.0484", "contents": "Title: Adaptive Crouzeix-Raviart Boundary Element Method Abstract: For the non-conforming Crouzeix-Raviart boundary elements from [Heuer, Sayas:\nCrouzeix-Raviart boundary elements, Numer. Math. 112, 2009], we develop and\nanalyze a posteriori error estimators based on the $h-h/2$ methodology. We\ndiscuss the optimal rate of convergence for uniform mesh refinement, and\npresent a numerical experiment with singular data where our adaptive algorithm\nrecovers the optimal rate while uniform mesh refinement is sub-optimal. We also\ndiscuss the case of reduced regularity by standard geometric singularities to\nconjecture that, in this situation, non-uniformly refined meshes are not\nsuperior to quasi-uniform meshes for Crouzeix-Raviart boundary elements. \n\n"}
{"id": "1312.1666", "contents": "Title: Semi-Stochastic Gradient Descent Methods Abstract: In this paper we study the problem of minimizing the average of a large\nnumber ($n$) of smooth convex loss functions. We propose a new method, S2GD\n(Semi-Stochastic Gradient Descent), which runs for one or several epochs in\neach of which a single full gradient and a random number of stochastic\ngradients is computed, following a geometric law. The total work needed for the\nmethod to output an $\\varepsilon$-accurate solution in expectation, measured in\nthe number of passes over data, or equivalently, in units equivalent to the\ncomputation of a single gradient of the loss, is\n$O((\\kappa/n)\\log(1/\\varepsilon))$, where $\\kappa$ is the condition number.\nThis is achieved by running the method for $O(\\log(1/\\varepsilon))$ epochs,\nwith a single gradient evaluation and $O(\\kappa)$ stochastic gradient\nevaluations in each. The SVRG method of Johnson and Zhang arises as a special\ncase. If our method is limited to a single epoch only, it needs to evaluate at\nmost $O((\\kappa/\\varepsilon)\\log(1/\\varepsilon))$ stochastic gradients. In\ncontrast, SVRG requires $O(\\kappa/\\varepsilon^2)$ stochastic gradients. To\nillustrate our theoretical results, S2GD only needs the workload equivalent to\nabout 2.1 full gradient evaluations to find an $10^{-6}$-accurate solution for\na problem with $n=10^9$ and $\\kappa=10^3$. \n\n"}
{"id": "1312.2309", "contents": "Title: A Weak Galerkin Finite Element Method for the Maxwell Equations Abstract: This paper introduces a numerical scheme for time harmonic Maxwell's\nequations by using weak Galerkin (WG) finite element methods. The WG finite\nelement method is based on two operators: discrete weak curl and discrete weak\ngradient, with appropriately defined stabilizations that enforce a weak\ncontinuity of the approximating functions. This WG method is highly flexible by\nallowing the use of discontinuous approximating functions on arbitrary shape of\npolyhedra and, at the same time, is parameter free. Optimal-order of\nconvergence is established for the weak Galerkin approximations in various\ndiscrete norms which are either $H^1$-like or $L^2$ and $L^2$-like. An\neffective implementation of the WG method is developed through variable\nreduction by following a Schur-complement approach, yielding a system of linear\nequations involving unknowns associated with element boundaries only. Numerical\nresults are presented to confirm the theory of convergence. \n\n"}
{"id": "1312.4820", "contents": "Title: Wave propagation in a fractional viscoelastic Andrade medium: diffusive\n  approximation and numerical modeling Abstract: This study focuses on the numerical modeling of wave propagation in\nfractionally-dissipative media. These viscoelastic models are such that the\nattenuation is frequency dependent and follows a power law with non-integer\nexponent. As a prototypical example, the Andrade model is chosen for its\nsimplicity and its satisfactory fits of experimental flow laws in rocks and\nmetals. The corresponding constitutive equation features a fractional\nderivative in time, a non-local term that can be expressed as a convolution\nproduct which direct implementation bears substantial memory cost. To\ncircumvent this limitation, a diffusive representation approach is deployed,\nreplacing the convolution product by an integral of a function satisfying a\nlocal time-domain ordinary differential equation. An associated quadrature\nformula yields a local-in-time system of partial differential equations, which\nis then proven to be well-posed. The properties of the resulting model are also\ncompared to those of the original Andrade model. The quadrature scheme\nassociated with the diffusive approximation, and constructed either from a\nclassical polynomial approach or from a constrained optimization method, is\ninvestigated to finally highlight the benefits of using the latter approach.\nWave propagation simulations in homogeneous domains are performed within a\nsplit formulation framework that yields an optimal stability condition and\nwhich features a joint fourth-order time-marching scheme coupled with an exact\nintegration step. A set of numerical experiments is presented to assess the\nefficiency of the diffusive approximation method for such wave propagation\nproblems. \n\n"}
{"id": "1312.5523", "contents": "Title: A Data-Driven Edge-Preserving D-bar Method for Electrical Impedance\n  Tomography Abstract: In Electrical Impedance Tomography (EIT), the internal conductivity of a body\nis recovered via current and voltage measurements taken at its surface. The\nreconstruction task is a highly ill-posed nonlinear inverse problem, which is\nvery sensitive to noise, and requires the use of regularized solution methods,\nof which D-bar is the only proven method. The resulting EIT images have low\nspatial resolution due to smoothing caused by low-pass filtered regularization.\nIn many applications, such as medical imaging, it is known \\emph{a priori} that\nthe target contains sharp features such as organ boundaries, as well as\napproximate ranges for realistic conductivity values. In this paper, we use\nthis information in a new edge-preserving EIT algorithm, based on the original\nD-bar method coupled with a deblurring flow stopped at a minimal data\ndiscrepancy. The method makes heavy use of a novel data fidelity term based on\nthe so-called {\\em CGO sinogram}. This nonlinear data step provides superior\nrobustness over traditional EIT data formats such as current-to-voltage\nmatrices or Dirichlet-to-Neumann operators, for commonly used current patterns. \n\n"}
{"id": "1312.5540", "contents": "Title: Emerging problems in approximation theory for the numerical solution of\n  nonlinear PDEs of integrable type Abstract: In this paper we present some open problems pertaining to the approximation\ntheory involved in the solution of the important class of Nonlinear Partial\nDifferential Equations (NPDEs) of integrable type. For this class of NPDEs, any\nInitial Value Problem (IVP) can be theoretically solved by the Inverse\nScattering Transform (IST) technique whose main steps involve the solution of\nVolterra equations with structured kernels on unbounded domains, the solution\nof Fredholm integral equations and the identification of coefficients and\nparameters of monomial-exponential sums. The aim of this paper is twofold:\npropose a method for solving the above mentioned problems under particular\nhypothesis and arouse interest in these problems in order to develop an\neffective method which works under more general assumptions. \n\n"}
{"id": "1312.5850", "contents": "Title: The $b$-adic tent transformation for quasi-Monte Carlo integration using\n  digital nets Abstract: In this paper we investigate quasi-Monte Carlo (QMC) integration using\ndigital nets over $\\mathbb{Z}_b$ in reproducing kernel Hilbert spaces. The tent\ntransformation, or the baker's transformation, was originally used for lattice\nrules by Hickernell (2002) to achieve higher order convergence of the\nintegration error for smooth non-periodic integrands, and later, has been\nsuccessfully applied to digital nets over $\\mathbb{Z}_2$ by Cristea et al.\n(2007) and Goda (2014). The aim of this paper is to generalize the latter two\nresults to digital nets over $\\mathbb{Z}_b$ for an arbitrary prime $b$. For\nthis purpose, we introduce the {\\em $b$-adic tent transformation} for an\narbitrary positive integer $b$ greater than 1, which is a generalization of the\noriginal (dyadic) tent transformation. Further, again for an arbitrary positive\ninteger $b$ greater than 1, we analyze the mean square worst-case error of QMC\nrules using digital nets over $\\mathbb{Z}_b$ which are randomly digitally\nshifted and then folded using the $b$-adic tent transformation in reproducing\nkernel Hilbert spaces. Using this result, for a prime $b$, we prove the\nexistence of good higher order polynomial lattice rules over $\\mathbb{Z}_b$\namong the smaller number of candidates as compared to the result by Dick and\nPillichshammer (2007), which achieve almost the optimal convergence rate of the\nmean square worst-case error in unanchored Sobolev spaces of smoothness of\narbitrary high order. \n\n"}
{"id": "1312.6092", "contents": "Title: A Simple and Efficient Preconditioning Scheme for Heaviside Enriched\n  XFEM Abstract: The eXtended Finite Element Method (XFEM) is an approach for solving problems\nwith non-smooth solutions. In the XFEM, the approximate solution is locally\nenriched to capture discontinuities without requiring a mesh which conforms to\nthe geometric features. One drawback of the XFEM is that an ill-conditioned\nsystem of equations results when the ratio of volumes on either side of the\ninterface in an element is small. In this paper, to avoid this\nill-conditioning, a simple and efficient scheme based on a geometric\npreconditioner and constraining degrees of freedom to zero for small\nintersections is proposed. This geometric preconditioner is computed from the\nnodal basis functions, and therefore may be constructed prior to building the\nsystem of equations. This feature and the low-cost of constructing the\npreconditioning matrix makes it well suited for nonlinear problems with fixed\nand moving interfaces. \n\n"}
{"id": "1312.6542", "contents": "Title: One-site density matrix renormalization group and alternating minimum\n  energy algorithm Abstract: Given in the title are two algorithms to compute the extreme eigenstate of a\nhigh-dimensional Hermitian matrix using the tensor train (TT) / matrix product\nstates (MPS) representation. Both methods empower the traditional alternating\ndirection scheme with the auxiliary (e.g. gradient) information, which\nsubstantially improves the convergence in many difficult cases. Being\nconceptually close, these methods have different derivation, implementation,\ntheoretical and practical properties. We emphasize the differences, and\nreproduce the numerical example to compare the performance of two algorithms. \n\n"}
{"id": "1312.7069", "contents": "Title: A Series of High Order Quasi-Compact Schemes for Space Fractional\n  Diffusion Equations Based on the Superconvergent Approximations for\n  Fractional Derivatives Abstract: Based on the superconvergent approximation at some point (depending on the\nfractional order $\\alpha$, but not belonging to the mesh points) for\nGr\\\"{u}nwald discretization to fractional derivative, we develop a series of\nhigh order quasi-compact schemes for space fractional diffusion equations.\nBecause of the quasi-compactness of the derived schemes, no points beyond the\ndomain are used for all the high order schemes including second order, third\norder, fourth order, and even higher order schemes; moreover, the algebraic\nequations for all the high order schemes have the completely same matrix\nstructure. The stability and convergence analysis for some typical schemes are\nmade; the techniques of treating the nonhomogeneous boundary conditions are\nintroduced; and extensive numerical experiments are performed to confirm the\ntheoretical analysis or verify the convergence orders. \n\n"}
{"id": "1401.0616", "contents": "Title: Compatible finite element methods for numerical weather prediction Abstract: This article takes the form of a tutorial on the use of a particular class of\nmixed finite element methods, which can be thought of as the finite element\nextension of the C-grid staggered finite difference method. The class is often\nreferred to as compatible finite elements, mimetic finite elements, discrete\ndifferential forms or finite element exterior calculus. We provide an\nelementary introduction in the case of the one-dimensional wave equation,\nbefore summarising recent results in applications to the rotating shallow water\nequations on the sphere, before taking an outlook towards applications in\nthree-dimensional compressible dynamical cores. \n\n"}
{"id": "1401.1390", "contents": "Title: A numerical approach to Blow-up issues for dispersive perturbations of\n  Burgers' equation Abstract: We provide a detailed numerical study of various issues pertaining to the\ndynamics of the Burgers equation perturbed by a weak dispersive term: blow-up\nin finite time versus global existence, nature of the blow-up, existence for\n\"long\" times, and the decomposition of the initial data into solitary waves\nplus radiation. We numerically construct solitons for fractionary Korteweg-de\nVries equations. \n\n"}
{"id": "1401.5373", "contents": "Title: Local a Priori Estimate on the General Scale Subdomains Abstract: The local a priori estimate for the finite element approximation is essential\nfor underlying the local and parallel technique. It is well known that the\nconstant coefficients in the inequality is independent of the mesh size. But it\nis not so clear whether the constant depends on the scale of the local\nsubdomains. The aim of this note is to derive a new local a priori estimate on\nthe general scale domains. We also show that the dependence of the constant\nappearing in the local a priori estimate on the scale of the subdomains. \n\n"}
{"id": "1402.0983", "contents": "Title: Spin-polarized transport in ferromagnetic multilayers: An\n  unconditionally convergent FEM integrator Abstract: We propose and analyze a decoupled time-marching scheme for the coupling of\nthe Landau-Lifshitz-Gilbert equation with a quasilinear diffusion equation for\nthe spin accumulation. This model describes the interplay of magnetization and\nelectron spin accumulation in magnetic and non-magnetic multilayer structures.\nDespite the strong nonlinearity of the overall PDE system, the proposed\nintegrator requires only the solution of two linear systems per time-step.\nUnconditional convergence of the integrator towards weak solutions is proved. \n\n"}
{"id": "1402.2117", "contents": "Title: Adaptive discontinuous Galerkin methods on surfaces Abstract: We present a dual weighted residual-based a posteriori error estimate for a\ndiscontinuous Galerkin (DG) approximation of a linear second-order elliptic\nproblem on compact smooth connected and oriented surfaces in $\\mathbb{R}^{3}$\nwhich are implicitly represented as level sets of a smooth function. We show\nthat the error in the energy norm may be split into a \"residual part\" and a\nhigher order \"geometric part\". Upper and lower bounds for the resulting a\nposteriori error estimator are proven and we consider a number of challenging\ntest problems to demonstrate the reliability and efficiency of the estimator.\nWe also present a novel \"geometric\" driven refinement strategy for PDEs on\nsurfaces which considerably improves the performance of the method on complex\nsurfaces. \n\n"}
{"id": "1402.3428", "contents": "Title: High order discontinuous Galerkin methods on surfaces Abstract: We derive and analyze high order discontinuous Galerkin methods for\nsecond-order elliptic problems on implicitely defined surfaces in\n$\\mathbb{R}^{3}$. This is done by carefully adapting the unified discontinuous\nGalerkin framework of Arnold et al. [2002] on a triangulated surface\napproximating the smooth surface. We prove optimal error estimates in both a\n(mesh dependent) energy norm and the $L^2$ norm. \n\n"}
{"id": "1403.2019", "contents": "Title: Boltzmann Equation Solver Adapted to Emergent Chemical Non-equilibrium Abstract: We present a novel method to solve the spatially homogeneous and isotropic\nrelativistic Boltzmann equation. We employ a basis set of orthogonal\npolynomials dynamically adapted to allow for emergence of chemical\nnon-equilibrium. Two time dependent parameters characterize the set of\northogonal polynomials, the effective temperature $T(t)$ and phase space\noccupation factor $\\Upsilon(t)$. In this first paper we address (effectively)\nmassless fermions and derive dynamical equations for $T(t)$ and $\\Upsilon(t)$\nsuch that the zeroth order term of the basis alone captures the particle number\ndensity and energy density of each particle distribution. We validate our\nmethod and illustrate the reduced computational cost and the ability to easily\nrepresent final state chemical non-equilibrium by studying a model problem that\nis motivated by the physics of the neutrino freeze-out processes in the early\nUniverse, where the essential physical characteristics include reheating from\nanother disappearing particle component ($e^\\pm$-annihilation). \n\n"}
{"id": "1403.2560", "contents": "Title: Functional A Posteriori Error Equalities for Conforming Mixed\n  Approximations of Elliptic Problems Abstract: In this paper we show how to find the exact error (not just an estimate of\nthe error) of a conforming mixed approximation by using the functional type a\nposteriori error estimates in the spirit of Repin. The error is measured in a\nmixed norm which takes into account both the primal and dual variables. We\nderive this result for elliptic partial differential equations of a certain\nclass. We first derive a special version of our main result by using a\nsimplified reaction-diffusion problem to demonstrate the strong connection to\nthe classical functional a posteriori error estimates of Repin. After this we\nderive the main result in an abstract setting. Our main result states that in\norder to obtain the exact global error value of a conforming mixed\napproximation one only needs the problem data and the mixed approximation of\nthe exact solution. There is no need for calculating any auxiliary data. The\ncalculation of the exact error consists of simply calculating two (usually\nintegral) quantities where all the quantities are known after the approximate\nsolution has been obtained by any conforming method. We also show some\nnumerical computations to confirm the results. \n\n"}
{"id": "1403.3127", "contents": "Title: An asymptotic relationship between coupling methods for stochastically\n  modeled population processes Abstract: This paper is concerned with elucidating a relationship between two common\ncoupling methods for the continuous time Markov chain models utilized in the\ncell biology literature. The couplings considered here are primarily used in a\ncomputational framework by providing reductions in variance for different Monte\nCarlo estimators, thereby allowing for significantly more accurate results for\na fixed amount of computational time. Common applications of the couplings\ninclude the estimation of parametric sensitivities via finite difference\nmethods and the estimation of expectations via multi-level Monte Carlo\nalgorithms. While a number of coupling strategies have been proposed for the\nmodels considered here, and a number of articles have experimentally compared\nthe different strategies, to date there has been no mathematical analysis\ndescribing the connections between them. Such analyses are critical in order to\ndetermine the best use for each. In the current paper, we show a connection\nbetween the common reaction path (CRP) method and the split coupling (SC)\nmethod, which is termed coupled finite differences (CFD) in the parametric\nsensitivities literature. In particular, we show that the two couplings are\nboth limits of a third coupling strategy we call the \"local-CRP\" coupling, with\nthe split coupling method arising as a key parameter goes to infinity, and the\ncommon reaction path coupling arising as the same parameter goes to zero. The\nanalysis helps explain why the split coupling method often provides a lower\nvariance than does the common reaction path method, a fact previously shown\nexperimentally. \n\n"}
{"id": "1403.4680", "contents": "Title: Likelihood-informed dimension reduction for nonlinear inverse problems Abstract: The intrinsic dimensionality of an inverse problem is affected by prior\ninformation, the accuracy and number of observations, and the smoothing\nproperties of the forward operator. From a Bayesian perspective, changes from\nthe prior to the posterior may, in many problems, be confined to a relatively\nlow-dimensional subspace of the parameter space. We present a dimension\nreduction approach that defines and identifies such a subspace, called the\n\"likelihood-informed subspace\" (LIS), by characterizing the relative influences\nof the prior and the likelihood over the support of the posterior distribution.\nThis identification enables new and more efficient computational methods for\nBayesian inference with nonlinear forward models and Gaussian priors. In\nparticular, we approximate the posterior distribution as the product of a\nlower-dimensional posterior defined on the LIS and the prior distribution\nmarginalized onto the complementary subspace. Markov chain Monte Carlo sampling\ncan then proceed in lower dimensions, with significant gains in computational\nefficiency. We also introduce a Rao-Blackwellization strategy that\nde-randomizes Monte Carlo estimates of posterior expectations for additional\nvariance reduction. We demonstrate the efficiency of our methods using two\nnumerical examples: inference of permeability in a groundwater system governed\nby an elliptic PDE, and an atmospheric remote sensing problem based on Global\nOzone Monitoring System (GOMOS) observations. \n\n"}
{"id": "1403.5948", "contents": "Title: Analysis and discretization of the volume penalized Laplace operator\n  with Neumann boundary conditions Abstract: We study the properties of an approximation of the Laplace operator with\nNeumann boundary conditions using volume penalization. For the one-dimensional\nPoisson equation we compute explicitly the exact solution of the penalized\nequation and quantify the penalization error. Numerical simulations using\nfinite differences allow then to assess the discretisation and penalization\nerrors. The eigenvalue problem of the penalized Laplace operator with Neumann\nboundary conditions is also studied. As examples in two space dimensions, we\nconsider a Poisson equation with Neumann boundary conditions in rectangular and\ncircular domains. \n\n"}
{"id": "1403.6579", "contents": "Title: On discrete least square projection in unbounded domain with random\n  evaluations and its application to parametric uncertainty quantification Abstract: This work is concerned with approximating multivariate functions in unbounded\ndomain by using discrete least-squares projection with random points\nevaluations. Particular attention are given to functions with random Gaussian\nor Gamma parameters. We first demonstrate that the traditional Hermite\n(Laguerre) polynomials chaos expansion suffers from the \\textit{instability} in\nthe sense that an \\textit{unfeasible} number of points, which is relevant to\nthe dimension of the approximation space, is needed to guarantee the stability\nin the least square framework. We then propose to use the Hermite/Laguerre {\\em\nfunctions} (rather than polynomials) as bases in the expansion. The\ncorresponding design points are obtained by mapping the uniformly distributed\nrandom points in bounded intervals to the unbounded domain, which involved a\nmapping parameter $L$. By using the Hermite/Laguerre {\\em functions} and a\nproper mapping parameter, the stability can be significantly improved even if\nthe number of design points scales \\textit{linearly} (up to a logarithmic\nfactor) with the dimension of the approximation space. Apart from the\nstability, another important issue is the rate of convergence. To speed up the\nconvergence, an effective scaling factor is introduced, and a principle for\nchoosing quasi-optimal scaling factor is discussed. Applications to parametric\nuncertainty quantification are illustrated by considering a random ODE model\ntogether with an elliptic problem with lognormal random input. \n\n"}
{"id": "1403.7543", "contents": "Title: A sparse Kaczmarz solver and a linearized Bregman method for online\n  compressed sensing Abstract: An algorithmic framework to compute sparse or minimal-TV solutions of linear\nsystems is proposed. The framework includes both the Kaczmarz method and the\nlinearized Bregman method as special cases and also several new methods such as\na sparse Kaczmarz solver. The algorithmic framework has a variety of\napplications and is especially useful for problems in which the linear\nmeasurements are slow and expensive to obtain. We present examples for online\ncompressed sensing, TV tomographic reconstruction and radio interferometry. \n\n"}
{"id": "1404.2427", "contents": "Title: Projection onto simplicial cones by a semi-smooth Newton method Abstract: By using Moreau's decomposition theorem for projecting onto cones, the\nproblem of projecting onto a simplicial cone is reduced to finding the unique\nsolution of a nonsmooth system of equations. It is shown that a semi-smooth\nNewton method applied to the system of equations associated to the problem of\nprojecting onto a simplicial cone is always well defined, and the generated\nsequence is bounded for any starting point and under a somewhat restrictive\nassumption it is finite. Besides, under a mild assumption on the simplicial\ncone, the generated sequence converges linearly to the solution of the\nassociated system of equations. \n\n"}
{"id": "1404.3614", "contents": "Title: Guaranteed upper-lower bounds on homogenized properties by FFT-based\n  Galerkin method Abstract: Guaranteed upper-lower bounds on homogenized coefficients, arising from the\nperiodic cell problem, are calculated in a scalar elliptic setting. Our\napproach builds on the recent variational reformulation of the Moulinec-Suquet\n(1994) Fast Fourier Transform (FFT) homogenization scheme by Vond\\v{r}ejc et\nal. (2014), which is based on the conforming Galerkin approximation with\ntrigonometric polynomials. Upper-lower bounds are obtained by adjusting the\nprimal-dual finite element framework developed independently by Dvo\\v{r}\\'{a}k\n(1993) and Wieckowski (1995) to the FFT-based Galerkin setting. We show that\nthe discretization procedure differs for odd and non-odd number of grid points.\nThanks to the Helmholtz decomposition inherited from the continuous\nformulation, the duality structure is fully preserved for the odd\ndiscretizations. In the latter case, a more complex primal-dual structure is\nobserved due to presence of the trigonometric polynomials associated with the\nNyquist frequencies. These theoretical findings are confirmed with numerical\nexamples. To conclude, the main advantage of the FFT-based approach over\nconventional finite-element schemes is that the primal and the dual problems\nare treated on the same basis, and this property can be extended beyond the\nscalar elliptic setting. \n\n"}
{"id": "1404.4429", "contents": "Title: Fractional differentiation matrices with applications Abstract: In this paper, the fractional differential matrices based on the Jacobi-Gauss\npoints are derived with respect to the Caputo and Riemann-Liouville fractional\nderivative operators. The spectral radii of the fractional differential\nmatrices are investigated numerically. The spectral collocation schemes are\nillustrated to solve the fractional ordinary differential equations and\nfractional partial differential equations. Numerical examples are also\npresented to illustrate the effectiveness of the derived methods, which show\nbetter performances over some existing methods. \n\n"}
{"id": "1404.4878", "contents": "Title: Analysis of Blended Atomistic/Continuum Hybrid Methods Abstract: We present a comprehensive error analysis of two prototypical\natomistic-to-continuum coupling methods of blending type: the energy-based and\nthe force-based quasicontinuum methods.\n  Our results are valid in two and three dimensions, for finite range many-body\ninteractions (e.g., EAM type), and in the presence of lattice defects (we\nconsider point defects and dislocations). The two key ingredients in the\nanalysis are (i) new force and energy consistency error estimates; and (ii) a\nnew technique for proving energy norm stability of a/c couplings that requires\nonly the assumption that the exact atomistic solution is a stable equilibrium. \n\n"}
{"id": "1404.5087", "contents": "Title: A Generalized Multiscale Finite Element Method for the Brinkman Equation Abstract: In this paper we consider the numerical upscaling of the Brinkman equation in\nthe presence of high-contrast permeability fields. We develop and analyze a\nrobust and efficient Generalized Multiscale Finite Element Method (GMsFEM) for\nthe Brinkman model. In the fine grid, we use mixed finite element method with\nthe velocity and pressure being continuous piecewise quadratic and piecewise\nconstant finite element spaces, respectively. Using the GMsFEM framework we\nconstruct suitable coarse-scale spaces for the velocity and pressure that yield\na robust mixed GMsFEM. We develop a novel approach to construct a coarse\napproximation for the velocity snapshot space and a robust small offline space\nfor the velocity space. The stability of the mixed GMsFEM and a priori error\nestimates are derived. A variety of two-dimensional numerical examples are\npresented to illustrate the effectiveness of the algorithm. \n\n"}
{"id": "1404.5519", "contents": "Title: Stable Numerical Approximation of Two-Phase Flow with a\n  Boussinesq--Scriven Surface Fluid Abstract: We consider two-phase Navier--Stokes flow with a Boussinesq--Scriven surface\nfluid. In such a fluid the rheological behaviour at the interface includes\nsurface viscosity effects, in addition to the classical surface tension\neffects. We introduce and analyze parametric finite element approximations, and\nshow, in particular, stability results for semi-discrete versions of the\nmethods, by demonstrating that a free energy inequality also holds on the\ndiscrete level. We perform several numerical simulations for various scenarios\nin two and three dimensions, which illustrate the effects of the surface\nviscosity. \n\n"}
{"id": "1404.7188", "contents": "Title: Limitations of polynomial chaos expansions in the Bayesian solution of\n  inverse problems Abstract: Polynomial chaos expansions are used to reduce the computational cost in the\nBayesian solutions of inverse problems by creating a surrogate posterior that\ncan be evaluated inexpensively. We show, by analysis and example, that when the\ndata contain significant information beyond what is assumed in the prior, the\nsurrogate posterior can be very different from the posterior, and the resulting\nestimates become inaccurate. One can improve the accuracy by adaptively\nincreasing the order of the polynomial chaos, but the cost may increase too\nfast for this to be cost effective compared to Monte Carlo sampling without a\nsurrogate posterior. \n\n"}
{"id": "1405.0707", "contents": "Title: Preconditioning the Restarted and Shifted Block FOM Algorithm for Matrix\n  Exponential Computation Abstract: The approximation of $e^{tA}B$ where $A$ is a large sparse matrix and $B$ a\nrectangular matrix is the key ingredient in many scientific and engineering\ncomputations. A powerful tool to manage the matrix exponential function is to\nresort to a suitable rational approximation such as the Carath$\\acute{\\rm\ne}$odory-Fej$\\acute{\\rm e}$r approximation, whose core reduces to solve shifted\nlinear systems with multiple right-hand sides. The restarted and shifted block\nFOM algorithm is a commonly used technique for this problem. However,\ndetermining good preconditioners for shifted systems that preserve the original\nstructure is a difficult task. In this paper, we propose a new preconditioner\nfor the restarted and shifted block FOM algorithm. The key is that the absolute\nvalues of the poles of the Carath$\\acute{\\rm e}$odory-Fej$\\acute{\\rm e}$r\napproximation are medium sized and can be much smaller than the norm of the\nmatrix in question. The advantages of the proposed strategy are that we can\nprecondition all the shifted linear systems simultaneously, and preserve the\noriginal structure of the shifted linear systems after restarting. Theoretical\nresults are provided to show the rationality of our preconditioning strategy.\nApplications of the new approach to Toeplitz matrix exponential problem are\nalso discussed. Numerical experiments illustrate the superiority of the new\nalgorithm over many state-of-the-art algorithms for matrix exponential. \n\n"}
{"id": "1405.0793", "contents": "Title: On triangular lattice Boltzmann schemes for scalar problems Abstract: We propose to extend the d'Humi\\'eres version of the lattice Boltzmann scheme\nto triangular meshes. We use Bravais lattices or more general lattices with the\nproperty that the degree of each internal vertex is supposed to be constant. On\nsuch meshes, it is possible to define the lattice Boltzmann scheme as a\ndiscrete particle method, without need of finite volume formulation or\nDelaunay-Voronoi hypothesis for the lattice. We test this idea for the heat\nequation and perform an asymptotic analysis with the Taylor expansion method\nfor two schemes named D2T4 and D2T7. The results show a convergence up to\nsecond order accuracy and set new questions concerning a possible\nsuper-convergence. \n\n"}
{"id": "1405.3494", "contents": "Title: Additive average Schwarz method for a Crouzeix-Raviart Finite Volume\n  Element Discretization of Elliptic Problems with Heterogeneous Coefficients Abstract: In this paper we introduce an additive Schwarz method for a Crouzeix-Raviart\nFinite Volume Element (CRFVE) discretization of a second order elliptic problem\nwith discontinuous coefficients, where the discontinuities are both inside the\nsubdomains and across and along the subdomain boundaries. We show that,\ndepending on the distribution of the coefficient in the model problem, the\nparameters describing the GMRES convergence rate of the proposed method depend\nlinearly or quadratically on the mesh parameters $H/h$. Also, under certain\nrestrictions on the distribution of the coefficient, the convergence of the\nGMRES method is independent of jumps in the coefficient. \n\n"}
{"id": "1405.4641", "contents": "Title: Superconvergent Two-grid Methods For Elliptic Eigenvalue Problems Abstract: Some numerical algorithms for elliptic eigenvalue problems are proposed,\nanalyzed, and numerically tested. The methods combine advantages of the\ntwo-grid algorithm, two-space method, the shifted inverse power method, and the\npolynomial preserving recovery technique . Our new algorithms compare favorably\nwith some existing methods and enjoy superconvergence property. \n\n"}
{"id": "1405.4947", "contents": "Title: Self-adjointness and conservation laws of difference equations Abstract: A general theorem on conservation laws for arbitrary difference equations is\nproved. The theorem is based on an introduction of an adjoint system related\nwith a given difference system, and it does not require the existence of a\ndifference Lagrangian. It is proved that the system, combined by the original\nsystem and its adjoint system, is governed by a variational principle, which\ninherits all symmetries of the original system. Noether's theorem can then be\napplied. With some special techniques, e.g. self-adjointness properties, this\nallows us to obtain conservation laws for difference equations, which are not\nnecessary governed by Lagrangian formalisms. \n\n"}
{"id": "1405.6122", "contents": "Title: On a Gamma-convergence analysis of a quasicontinuum method Abstract: We investigate a quasicontinuum method by means of analytical tools. More\nprecisely, we compare a discrete-to-continuum analysis of an atomistic\none-dimensional model problem with a corresponding quasicontinuum model. We\nconsider next and next-to-nearest neighbour interactions of Lennard-Jones type\nand focus on the so-called quasinonlocal quasicontinuum approximation. Our\nanalysis, which applies $\\Gamma$-convergence techniques, shows that, in an\nelastic setting, minimizers and the minimal energies of the fully atomistic\nproblem and its related quasicontinuum approximation have the same limiting\nbehaviour as the number of atoms tends to infinity. In case of fracture this is\nin general not true. It turns out that the choice of representative atoms in\nthe quasicontinuum approximation has an impact on the fracture energy and on\nthe location of fracture. We give sufficient conditions for the choice of\nrepresentative atoms such that, also in case of fracture, the minimal energies\nof the fully atomistic energy and its quasicontinuum approximation coincide in\nthe limit and such that the crack is located in the atomistic region of the\nquasicontinuum model as desired. \n\n"}
{"id": "1405.7786", "contents": "Title: Fundamental Tensor Operations for Large-Scale Data Analysis in Tensor\n  Train Formats Abstract: We discuss extended definitions of linear and multilinear operations such as\nKronecker, Hadamard, and contracted products, and establish links between them\nfor tensor calculus. Then we introduce effective low-rank tensor approximation\ntechniques including Candecomp/Parafac (CP), Tucker, and tensor train (TT)\ndecompositions with a number of mathematical and graphical representations. We\nalso provide a brief review of mathematical properties of the TT decomposition\nas a low-rank approximation technique. With the aim of breaking the\ncurse-of-dimensionality in large-scale numerical analysis, we describe basic\noperations on large-scale vectors, matrices, and high-order tensors represented\nby TT decomposition. The proposed representations can be used for describing\nnumerical methods based on TT decomposition for solving large-scale\noptimization problems such as systems of linear equations and symmetric\neigenvalue problems. \n\n"}
{"id": "1406.0724", "contents": "Title: An inertial Tseng's type proximal algorithm for nonsmooth and nonconvex\n  optimization problems Abstract: We investigate the convergence of a forward-backward-forward proximal-type\nalgorithm with inertial and memory effects when minimizing the sum of a\nnonsmooth function with a smooth one in the absence of convexity. The\nconvergence is obtained provided an appropriate regularization of the objective\nsatisfies the Kurdyka-\\L{}ojasiewicz inequality, which is for instance\nfulfilled for semi-algebraic functions. \n\n"}
{"id": "1406.1989", "contents": "Title: A multilevel adaptive reaction-splitting simulation method for\n  stochastic reaction networks Abstract: Stochastic modeling of reaction networks is a framework used to describe the\ntime evolution of many natural and artificial systems, including, biochemical\nreactive systems at the molecular level, viral kinetics, the spread of epidemic\ndiseases, and wireless communication networks, among many other examples. In\nthis work, we present a novel multilevel Monte Carlo method for kinetic\nsimulation of stochastic reaction networks that is specifically designed for\nsystems in which the set of reaction channels can be adaptively partitioned\ninto two subsets characterized by either \"high\" or \"low\" activity. Adaptive in\nthis context means that the partition evolves in time according to the states\nvisited by the stochastic paths of the system. To estimate expected values of\nobservables of the system at a prescribed final time, our method bounds the\nglobal computational error to be below a prescribed tolerance, $TOL$, within a\ngiven confidence level. This is achieved with a computational complexity of\norder $O(TOL^{-2})$, the same as with an exact method, but with a smaller\nconstant. We also present a novel control variate technique based on the\nstochastic time change representation by Kurtz, which may dramatically reduce\nthe variance of the coarsest level at a negligible computational cost. Our\nnumerical examples show substantial gains with respect to the standard\nStochastic Simulation Algorithm (SSA) by Gillespie and also our previous hybrid\nChernoff tau-leap method. \n\n"}
{"id": "1406.3515", "contents": "Title: Regularity of the diffusion-dispersion tensor and error analysis of\n  Galerkin FEMs for a porous media flow Abstract: We study Galerkin finite element methods for an incompressible miscible flow\nin porous media with the commonly-used Bear-Scheidegger diffusion-dispersion\ntensor $D({\\bf u}) = \\Phi d_m I + |{\\bf u}| \\big ( \\alpha_T I + (\\alpha_L -\n\\alpha_T) \\frac{{\\bf u} \\otimes {\\bf u}}{|{\\bf u}|^2}\\big)$. The traditional\napproach to optimal $L^\\infty((0,T);L^2)$ error estimates is based on an\nelliptic Ritz projection, which usually requires the regularity of\n$\\nabla_x\\partial_tD({\\bf u}(x,t)) \\in L^p(\\Omega_T)$. However, the\nBear-Scheidegger diffusion-dispersion tensor may not satisfy the regularity\ncondition even for a smooth velocity field ${\\bf u}$. A new approach is\npresented in this paper, in terms of a parabolic projection, which only\nrequires the Lipschitz continuity of $D({\\bf u})$. With the new approach, we\nestablish optimal $L^p((0,T);L^q)$ error estimates and an almost optimal\n$L^\\infty((0,T);L^\\infty)$ error estimate. \n\n"}
{"id": "1406.4350", "contents": "Title: Parallel eigensolvers in plane-wave Density Functional Theory Abstract: We consider the problem of parallelizing electronic structure computations in\nplane-wave Density Functional Theory. Because of the limited scalability of\nFourier transforms, parallelism has to be found at the eigensolver level. We\nshow how a recently proposed algorithm based on Chebyshev polynomials can scale\ninto the tens of thousands of processors, outperforming block conjugate\ngradient algorithms for large computations. \n\n"}
{"id": "1406.4429", "contents": "Title: High Order Asymptotic Preserving Nodal Discontinuous Galerkin IMEX\n  Schemes for the BGK Equation Abstract: In this paper, we develop high-order asymptotic preserving (AP) schemes for\nthe BGK equation in a hyperbolic scaling, which leads to the macroscopic models\nsuch as the Euler and compressible Navier-Stokes equations in the asymptotic\nlimit. Our approaches are based on the so-called micro-macro formulation of the\nkinetic equation which involves a natural decomposition of the problem to the\nequilibrium and the non-equilibrium parts. The proposed methods are formulated\nfor the BGK equation with constant or spatially variant Knudsen number. The new\ningredients for the proposed methods to achieve high order accuracy are the\nfollowing: we introduce discontinuous Galerkin (DG) discretization of arbitrary\norder of accuracy with nodal Lagrangian basis functions in space; we employ a\nhigh order globally stiffly accurate implicit-explicit (IMEX) Runge-Kutta (RK)\nscheme as time discretization. Two versions of the schemes are proposed: Scheme\nI is a direct formulation based on the micro-macro decomposition of the BGK\nequation, while Scheme II, motivated by the asymptotic analysis for the\ncontinuous problem, utilizes certain properties of the projection operator.\nCompared with Scheme I, Scheme II not only has better computational efficiency\n(the computational cost is reduced by half roughly), but also allows the\nestablishment of a formal asymptotic analysis. Specifically, it is demonstrated\nthat when $0<\\epsilon \\ll 1$, Scheme II, up to $\\mathcal{O}(\\epsilon^2)$,\nbecomes a local DG discretization with an explicit RK method for the\nmacroscopic compressible Navier-Stokes equations, a method in a similar spirit\nto the ones in [Bassi \\& Rabey 1997, Cockburn \\& Shu 1998]. Numerical results\nare presented for a wide range of Knudsen number to illustrate the\neffectiveness and high order accuracy of the methods. \n\n"}
{"id": "1406.4885", "contents": "Title: Periodic eigendecomposition and its application to Kuramoto-Sivashinsky\n  system Abstract: Periodic eigendecomposition, to be formulated in this paper, is a numerical\nmethod to compute Floquet spectrum and Floquet vectors along periodic orbits in\na dynamical system. It is rooted in numerical algorithms advances in\ncomputation of 'covariant vectors' of the linearized flow along an ergodic\ntrajectory in a chaotic system. Recent research on covariant vectors strongly\nstrongly suggests that the physical dimension of inertial manifold of a\ndissipative PDE can be characterized by a finite number of 'entangled modes',\ndynamically isolated from the residual set of transient degrees of freedom. We\nanticipate that Floquet vectors display similar properties as covariant\nvectors. In this paper we incorporate periodic Schur decomposition to the\ncomputation of dynamical Floquet vectors, compare it with other methods, and\nshow that the method can yield the full Floquet spectrum of a periodic orbit at\nevery point along the orbit to high accuracy. Its power, and in particular its\nability to resolve eigenvalues whose magnitude differs by hundreds of orders\nmagnitude, is demonstrated by applying the algorithm to computation of the full\nlinear stability spectrum of several periodic solutions in one dimensional\nKuramoto-Sivashinsky flow. \n\n"}
{"id": "1406.6632", "contents": "Title: Dual Basis Functions in Subspaces Abstract: In this paper we study dual bases functions in subspaces. These are bases\nwhich are dual to functionals on larger linear space. Our goal is construct and\nderive properties of certain bases obtained from the construction, with primary\nfocus on polynomial spaces in B-form. When they exist, our bases are always\naffine (not convex), and we define a symmetric configuration that converges to\nLagrange polynomial bases. Because of affineness of our bases, we are able to\nderive certain approximation theoretic results involving quasi-interpolation\nand a Bernstein-type operator.\n  In a broad sense, it is the aim of this paper to present a new way to view\napproximation problems in subspaces. In subsequent work, we will apply our\nresults to dual bases in subspaces of spline and multivariate polynomial\nspaces, and apply this to the construction of blended function approximants\nused for approximation in the sum of certain tensor product spaces. \n\n"}
{"id": "1406.6668", "contents": "Title: Bayesian Numerical Homogenization Abstract: Numerical homogenization, i.e. the finite-dimensional approximation of\nsolution spaces of PDEs with arbitrary rough coefficients, requires the\nidentification of accurate basis elements. These basis elements are oftentimes\nfound after a laborious process of scientific investigation and plain\nguesswork. Can this identification problem be facilitated? Is there a general\nrecipe/decision framework for guiding the design of basis elements? We suggest\nthat the answer to the above questions could be positive based on the\nreformulation of numerical homogenization as a Bayesian Inference problem in\nwhich a given PDE with rough coefficients (or multi-scale operator) is excited\nwith noise (random right hand side/source term) and one tries to estimate the\nvalue of the solution at a given point based on a finite number of\nobservations. We apply this reformulation to the identification of bases for\nthe numerical homogenization of arbitrary integro-differential equations and\nshow that these bases have optimal recovery properties. In particular we show\nhow Rough Polyharmonic Splines can be re-discovered as the optimal solution of\na Gaussian filtering problem. \n\n"}
{"id": "1406.7339", "contents": "Title: Block Kaczmarz Method with Inequalities Abstract: The randomized Kaczmarz method is an iterative algorithm that solves\noverdetermined systems of linear equations. Recently, the method was extended\nto systems of equalities and inequalities by Leventhal and Lewis. Even more\nrecently, Needell and Tropp provided an analysis of a block version of the\nmethod for systems of linear equations. This paper considers the use of a block\ntype method for systems of mixed equalities and inequalities, bridging these\ntwo bodies of work. We show that utilizing a matrix paving over the equalities\nof the system can lead to significantly improved convergence, and prove a\nlinear convergence rate as in the standard block method. We also demonstrate\nthat using blocks of inequalities offers similar improvement only when the\nsystem satisfies a certain geometric property. We support the theoretical\nanalysis with several experimental results. \n\n"}
{"id": "1406.7457", "contents": "Title: A family of conforming mixed finite elements for linear elasticity on\n  triangular grids Abstract: This paper presents a family of mixed finite elements on triangular grids for\nsolving the classical Hellinger-Reissner mixed problem of the elasticity\nequations. In these elements, the matrix-valued stress field is approximated by\nthe full $C^0$-$P_k$ space enriched by $(k-1)$ $H(\\d)$ edge bubble functions on\neach internal edge, while the displacement field by the full discontinuous\n$P_{k-1}$ vector-valued space, for the polynomial degree $k\\ge 3$. The main\nchallenge is to find the correct stress finite element space matching the full\n$C^{-1}$-$P_{k-1}$ displacement space. The discrete stability analysis for the\ninf-sup condition does not rely on the usual Fortin operator, which is\ndifficult to construct. It is done by characterizing the divergence of local\nstress space which covers the $P_{k-1}$ space of displacement orthogonal to the\nlocal rigid-motion. The well-posedness condition and the optimal a priori error\nestimate are proved for this family of finite elements. Numerical tests are\npresented to confirm the theoretical results. \n\n"}
{"id": "1407.0053", "contents": "Title: Atomistic/Continuum Blending with Ghost Force Correction Abstract: We combine the ideas of atomistic/continuum energy blending and ghost force\ncorrection to obtain an energy-based atomistic/continuum coupling scheme which\nhas, for a range of benchmark problems, the same convergence rates as optimal\nforce-based coupling schemes.\n  We present the construction of this new scheme, numerical results exploring\nits accuracy in comparison with established schemes, as well as a rigorous\nerror analysis for an instructive special case. \n\n"}
{"id": "1407.0533", "contents": "Title: Sampling by incomplete cosine expansion of the sinc function:\n  application to the Voigt/complex error function Abstract: A new sampling methodology based on incomplete cosine expansion series is\npresented as an alternative to the traditional sinc function approach.\nNumerical integration shows that this methodology is efficient and practical.\nApplying the incomplete cosine expansion we obtain a rational approximation of\nthe complex error function that with the same number of the summation terms\nprovides an accuracy exceeding the Weideman\\text{'}s approximation accuracy by\nseveral orders of the magnitude. Application of the expansion results in an\nintegration consisting of elementary function terms only. Consequently, this\napproach can be advantageous for accurate and rapid computation. \n\n"}
{"id": "1407.1925", "contents": "Title: Using Optimization to Solve Positive LPs Faster in Parallel Abstract: Positive linear programs (LP), also known as packing and covering linear\nprograms, are an important class of problems that bridges computer science,\noperations research, and optimization. Despite the consistent efforts on this\nproblem, all known nearly-linear-time algorithms require\n$\\tilde{O}(\\varepsilon^{-4})$ iterations to converge to $1\\pm \\varepsilon$\napproximate solutions. This $\\varepsilon^{-4}$ dependence has not been improved\nsince 1993, and limits the performance of parallel implementations for such\nalgorithms. Moreover, previous algorithms and their analyses rely on update\nsteps and convergence arguments that are combinatorial in nature and do not\nseem to arise naturally from an optimization viewpoint.\n  In this paper, we leverage new insights from optimization theory to construct\na novel algorithm that breaks the longstanding $\\varepsilon^{-4}$ barrier. Our\nalgorithm has a simple analysis and a clear motivation. Our work introduces a\nnumber of novel techniques, such as the combined application of gradient\ndescent and mirror descent, and a truncated, smoothed version of the standard\nmultiplicative weight update, which may be of independent interest. \n\n"}
{"id": "1407.3043", "contents": "Title: Stabilized Finite Element Approximation of the Mean Curvature Vector on\n  Closed Surfaces Abstract: We develop a stabilized discrete Laplace-Beltrami operator that is used to\ncompute an approximate mean curvature vector which enjoys convergence of order\none in L2. The stabilization is of gradient jump type and we consider both\nstandard meshed surfaces and so called cut surfaces that are level sets of\npiecewise linear distance functions. We prove a priori error estimates and\nverify the theoretical results numerically. \n\n"}
{"id": "1407.5604", "contents": "Title: Weak Galerkin method for the coupled Darcy-Stokes flow Abstract: A family of weak Galerkin finite element discretization is developed for\nsolving the coupled Darcy-Stokes equation. The equation in consideration admits\nthe Beaver-Joseph-Saffman condition on the interface. By using the weak\nGalerkin approach, in the discrete space we are able to impose the normal\ncontinuity of velocity explicitly. Or in other words, strong coupling is\nachieved in the discrete space. Different choices of weak Galerkin finite\nelement spaces are discussed, and error estimates are given. \n\n"}
{"id": "1407.7407", "contents": "Title: Numerical and analytical methods for asymptotically flat spacetimes Abstract: This article begins with a brief introduction to numerical relativity aimed\nat readers who have a background in applied mathematics but not necessarily in\ngeneral relativity. I then introduce and summarise my work on the problem of\ntreating asymptotically flat spacetimes of infinite extent with finite\ncomputational resources. Two different approaches are considered. The first\napproach is the standard one and is based on evolution on Cauchy hypersurfaces\nwith artificial timelike boundary. The well posedness of a set of\nconstraint-preserving boundary conditions for the Einstein equations in\ngeneralised harmonic gauge is analysed, their numerical performance is compared\nwith various alternate methods, and improved absorbing boundary conditions are\nconstructed and implemented. In the second approach, one solves the Einstein\nequations on hyperboloidal (asymptotically characteristic) hypersurfaces. These\nare conformally compactified towards future null infinity, where gravitational\nradiation is defined in an unambiguous way. We show how the formally singular\nterms arising in a $3+1$ reduction of the equations can be evaluated at future\nnull infinity, present stable numerical evolutions of vacuum axisymmetric black\nhole spacetimes and study late-time power-law tails of matter fields in\nspherical symmetry. \n\n"}
{"id": "1407.8107", "contents": "Title: Extra Chance Generalized Hybrid Monte Carlo Abstract: We study a method, Extra Chance Generalized Hybrid Monte Carlo, to avoid\nrejections in the Hybrid Monte Carlo method and related algorithms. In the\nspirit of delayed rejection, whenever a rejection would occur, extra work is\ndone to find a fresh proposal that, hopefully, may be accepted. We present\nexperiments that clearly indicate that the additional work per sample carried\nout in the extra chance approach clearly pays in terms of the quality of the\nsamples generated. \n\n"}
{"id": "1407.8313", "contents": "Title: Isogeometric mortar methods Abstract: The application of mortar methods in the framework of isogeometric analysis\nis investigated theoretically as well as numerically. For the Lagrange\nmultiplier two choices of uniformly stable spaces are presented, both of them\nare spline spaces but of a different degree.\n  In one case, we consider an equal order pairing for which a cross point\nmodification based on a local degree reduction is required. In the other case,\nthe degree of the dual space is reduced by two compared to the primal. This\npairing is proven to be inf-sup stable without any necessary cross point\nmodification. Several numerical examples confirm the theoretical results and\nillustrate additional aspects.\n  Keywords: isogeometric analysis, mortar methods, inf-sup stability, cross\npoint modification. \n\n"}
{"id": "1408.0545", "contents": "Title: Computing active subspaces with Monte Carlo Abstract: Active subspaces can effectively reduce the dimension of high-dimensional\nparameter studies enabling otherwise infeasible experiments with expensive\nsimulations. The key components of active subspace methods are the eigenvectors\nof a symmetric, positive semidefinite matrix whose elements are the average\nproducts of partial derivatives of the simulation's input/output map. We study\na Monte Carlo method for approximating the eigenpairs of this matrix. We offer\nboth theoretical results based on recent non-asymptotic random matrix theory\nand a practical approach based on the bootstrap. We extend the analysis to the\ncase when the gradients are approximated, for example, with finite differences.\nOur goal is to provide guidance for two questions that arise in active\nsubspaces: (i) How many gradient samples does one need to accurately\napproximate the eigenvalues and subspaces? (ii) What can be said about the\naccuracy of the estimated subspace, both theoretically and practically? We test\nthe approach on both simple quadratic functions where the active subspace is\nknown and a parameterized PDE with 100 variables characterizing the\ncoefficients of the differential operator. \n\n"}
{"id": "1408.2773", "contents": "Title: On Integration Methods Based on Scrambled Nets of Arbitrary Size Abstract: We consider the problem of evaluating $I(\\varphi):=\\int_{[0,1)^s}\\varphi(x)\ndx$ for a function $\\varphi \\in L^2[0,1)^{s}$. In situations where $I(\\varphi)$\ncan be approximated by an estimate of the form\n$N^{-1}\\sum_{n=0}^{N-1}\\varphi(x^n)$, with $\\{x^n\\}_{n=0}^{N-1}$ a point set in\n$[0,1)^s$, it is now well known that the $O_P(N^{-1/2})$ Monte Carlo\nconvergence rate can be improved by taking for $\\{x^n\\}_{n=0}^{N-1}$ the first\n$N=\\lambda b^m$ points, $\\lambda\\in\\{1,\\dots,b-1\\}$, of a scrambled\n$(t,s)$-sequence in base $b\\geq 2$. In this paper we derive a bound for the\nvariance of scrambled net quadrature rules which is of order $o(N^{-1})$\nwithout any restriction on $N$. As a corollary, this bound allows us to provide\nsimple conditions to get, for any pattern of $N$, an integration error of size\n$o_P(N^{-1/2})$ for functions that depend on the quadrature size $N$. Notably,\nwe establish that sequential quasi-Monte Carlo (M. Gerber and N. Chopin, 2015,\n\\emph{J. R. Statist. Soc. B, to appear.}) reaches the $o_P(N^{-1/2})$\nconvergence rate for any values of $N$. In a numerical study, we show that for\nscrambled net quadrature rules we can relax the constraint on $N$ without any\nloss of efficiency when the integrand $\\varphi$ is a discontinuous function\nwhile, for sequential quasi-Monte Carlo, taking $N=\\lambda b^m$ may only\nprovide moderate gains. \n\n"}
{"id": "1408.4536", "contents": "Title: Discretization of functionals involving the Monge-Amp\\`ere operator Abstract: Gradient flows in the Wasserstein space have become a powerful tool in the\nanalysis of diffusion equations, following the seminal work of Jordan,\nKinderlehrer and Otto (JKO). The numerical applications of this formulation\nhave been limited by the difficulty to compute the Wasserstein distance in\ndimension >= 2. One step of the JKO scheme is equivalent to a variational\nproblem on the space of convex functions, which involves the Monge-Amp\\`ere\noperator. Convexity constraints are notably difficult to handle numerically,\nbut in our setting the internal energy plays the role of a barrier for these\nconstraints. This enables us to introduce a consistent discretization, which\ninherits convexity properties of the continuous variational problem. We show\nthe effectiveness of our approach on nonlinear diffusion and crowd-motion\nmodels. \n\n"}
{"id": "1409.1161", "contents": "Title: Quantitative estimates on the periodic approximation of the corrector in\n  stochastic homogenization Abstract: In the present contribution we establish quantitative results on the periodic\napproximation of the corrector equation for the stochastic homogenization of\nlinear elliptic equations in divergence form, when the diffusion coefficients\nsatisfy a spectral gap estimate in probability, and for $d>2$. The main\ndifference with respect to the first part of [Gloria-Otto, arXiv:1409.0801] is\nthat we avoid here the use of Green's functions and more directly rely on the\nDe Giorgi-Nash-Moser theory. \n\n"}
{"id": "1409.2623", "contents": "Title: Point Integral Method for Solving Poisson-type Equations on Manifolds\n  from Point Clouds with Convergence Guarantees Abstract: Partial differential equations (PDE) on manifolds arise in many areas,\nincluding mathematics and many applied fields. Among all kinds of PDEs, the\nPoisson-type equations including the standard Poisson equation and the related\neigenproblem of the Laplace-Beltrami operator are of the most important. Due to\nthe complicated geometrical structure of the manifold, it is difficult to get\nefficient numerical method to solve PDE on manifold. In the paper, we propose a\nmethod called point integral method (PIM) to solve the Poisson-type equations\nfrom point clouds with convergence guarantees. In PIM, the key idea is to\nderive the integral equations which approximates the Poisson-type equations and\ncontains no derivatives but only the values of the unknown function. The latter\nmakes the integral equation easy to be approximated from point cloud. In the\npaper, we explain the derivation of the integral equations, describe the point\nintegral method and its implementation, and present the numerical experiments\nto demonstrate the convergence of PIM. \n\n"}
{"id": "1409.2808", "contents": "Title: The stability of extended Floater-Hormann interpolants Abstract: We present a new analysis of the stability of extended Floater-Hormann\ninterpolants, in which both noisy data and rounding errors are considered.\nContrary to what is claimed in the current literature, we show that the\nLebesgue constant of these interpolants can grow exponentially with the\nparameters that define them, and we emphasize the importance of using the\nproper interpretation of the Lebesgue constant in order to estimate correctly\nthe effects of noise and rounding errors. We also present a simple condition\nthat implies the backward instability of the barycentric formula used to\nimplement extended interpolants. Our experiments show that extended\ninterpolants mentioned in the literature satisfy this condition and, therefore,\nthe formula used to implement them is not backward stable. Finally, we explain\nthat the extrapolation step is a significant source of numerical instability\nfor extended interpolants based on extrapolation. \n\n"}
{"id": "1409.3666", "contents": "Title: On the $L_p$ discrepancy of two-dimensional folded Hammersley point sets Abstract: We give an explicit construction of two-dimensional point sets whose $L_p$\ndiscrepancy is of best possible order for all $1\\le p\\le \\infty$. It is\nprovided by folding Hammersley point sets in base $b$ by means of the $b$-adic\nbaker's transformation which has been introduced by Hickernell (2002) for $b=2$\nand Goda, Suzuki and Yoshiki (2013) for arbitrary $b\\in \\mathbb{N}$, $b\\ge 2$.\nWe prove that both the minimum Niederreiter-Rosenbloom-Tsfasman weight and the\nminimum Dick weight of folded Hammersley point sets are large enough to achieve\nthe best possible order of $L_p$ discrepancy for all $1\\le p\\le \\infty$. \n\n"}
{"id": "1409.3997", "contents": "Title: Energy Stable Discontinuous Galerkin Finite Element Method for the\n  Allen-Cahn Equation Abstract: Allen--Cahn equation with constant and degenerate mobility, and with\npolynomial and logarithmic energy functionals is discretized using symmetric\ninterior penalty discontinuous Galerkin (SIPG) finite elements in space. We\nshow that the energy stable average vector field (AVF) method as the time\nintegrator for gradient systems like the Allen-Cahn equation satisfies the\nenergy decreasing property for the fully discrete scheme. The numerical results\nfor one and two dimensional Allen-Cahn equation with periodic boundary\ncondition, using adaptive time stepping, reveal that the discrete energy\ndecreases monotonically, the phase separation and metastability phenomena can\nbe observed and the ripening time is detected correctly. \n\n"}
{"id": "1409.4608", "contents": "Title: Boundary integral solution of potential problems arising in the\n  modelling of electrified oil films Abstract: We consider a class of potential problems on a periodic half-space for the\nmodelling of electrified oil films, which are used in the development of novel\nswitchable liquid optical devices (diffraction gratings). A boundary integral\nformulation which reduces the problem to the study of the oil-air interface\nalone is derived and solved in a highly efficient manner using the Nystr\\\"{o}m\nmethod. The oil films encountered experimentally are typically very thin and\nthus an interface-only integral representation is important for avoiding the\nnear-singularity problems associated with boundary integral methods for long\nslender domains. The super-algebraic convergence of the proposed methods is\ndiscussed and demonstrated via appropriate numerical experiments. \n\n"}
{"id": "1409.4618", "contents": "Title: Fast MATLAB assembly of FEM matrices in 2D and 3D: Edge elements Abstract: We propose an effective and flexible way to assemble finite element stiffness\nand mass matrices in MATLAB. We apply this for problems discretized by edge\nfinite elements. Typical edge finite elements are Raviart-Thomas elements used\nin discretizations of H(div) spaces and Nedelec elements in discretizations of\nH(curl) spaces. We explain vectorization ideas and comment on a freely\navailable MATLAB code which is fast and scalable with respect to time. \n\n"}
{"id": "1409.5893", "contents": "Title: Fast evaluation of far-field signals for time-domain wave propagation Abstract: Time-domain simulation of wave phenomena on a finite computational domain\noften requires a fictitious outer boundary. An important practical issue is the\nspecification of appropriate boundary conditions on this boundary, often\nconditions of complete transparency. Attention to this issue has been paid\nelsewhere, and here we consider a different, although related, issue: far-field\nsignal recovery. Namely, from smooth data recorded on the outer boundary we\nwish to recover the far-field signal which would reach arbitrarily large\ndistances. These signals encode information about interior scatterers and often\ncorrespond to actual measurements. This article expresses far-field signal\nrecovery in terms of time-domain convolutions, each between a solution\nmultipole moment recorded at the boundary and a sum-of-exponentials kernel.\nEach exponential corresponds to a pole term in the Laplace transform of the\nkernel, a finite sum of simple poles. Greengard, Hagstrom, and Jiang have\nderived the large-$\\ell$ (spherical-harmonic index) asymptotic expansion for\nthe pole residues, and their analysis shows that, when expressed in terms of\nthe exact sum-of-exponentials, large-$\\ell$ signal recovery is plagued by\ncancellation errors. Nevertheless, through an alternative integral\nrepresentation of the kernel and its subsequent approximation by a {\\em\nsmaller} number of exponential terms (kernel compression), we are able to\nalleviate these errors and achieve accurate signal recovery. We empirically\nexamine scaling relations between the parameters which determine a compressed\nkernel, and perform numerical tests of signal \"teleportation\" from one radial\nvalue $r_1$ to another $r_2$, including the case $r_2=\\infty$. We conclude with\na brief discussion on application to other hyperbolic equations posed on\nnon-flat geometries where waves undergo backscatter. \n\n"}
{"id": "1409.6049", "contents": "Title: On the numerical solution of second order differential equations in the\n  high-frequency regime Abstract: We describe an algorithm for the numerical solution of second order linear\ndifferential equations in the highly-oscillatory regime. It is founded on the\nrecent observation that the solutions of equations of this type can be\naccurately represented using nonoscillatory phase functions. Unlike standard\nsolvers for ordinary differential equations, the running time of our algorithm\nis independent of the frequency of oscillation of the solutions. We illustrate\nthe performance of the method with several numerical experiments. \n\n"}
{"id": "1410.0201", "contents": "Title: High-Order Implicit Time-Marching Methods Based on Generalized\n  Summation-By-Parts Operators Abstract: This article extends the theory of classical finite-difference\nsummation-by-parts (FD-SBP) time-marching methods to the generalized\nsummation-by-parts (GSBP) framework. Dual-consistent GSBP time-marching methods\nare shown to retain: A and L-stability, as well as superconvergence of integral\nfunctionals when integrated with the quadrature associated with the\ndiscretization. This also implies that the solution approximated at the end of\neach time step is superconvergent. In addition GSBP time-marching methods\nconstructed with a diagonal norm are BN-stable. This article also formalizes\nthe connection between FD-SBP/GSBP time-marching methods and implicit\nRunge-Kutta methods. Through this connection, the minimum accuracy of the\nsolution approximated at the end of a time step is extended for nonlinear\nproblems. It is also exploited to derive conditions under which nonlinearly\nstable GSBP time-marching methods can be constructed. The GSBP approach to time\nmarching can simplify the construction of high-order fully-implicit Runge-Kutta\nmethods with a particular set of properties favourable for stiff initial value\nproblems, such as L-stability. It can facilitate the analysis of fully discrete\napproximations to PDEs and is amenable to to multi-dimensional spcae-time\ndiscretizations, in which case the explicit connection to Runge-Kutta methods\nis often lost. A few examples of known and novel Runge-Kutta methods associated\nwith GSBP operators are presented. The novel methods, all of which are L-stable\nand BN-stable, include a four-stage seventh-order fully-implicit method, a\nthree-stage third-order diagonally-implicit method, and a fourth-order\nfour-stage diagonally-implicit method. The relative efficiency of the schemes\nis investigated and compared with a few popular non-GSBP Runge-Kutta methods. \n\n"}
{"id": "1410.1221", "contents": "Title: Scalable and efficient algorithms for the propagation of uncertainty\n  from data through inference to prediction for large-scale problems, with\n  application to flow of the Antarctic ice sheet Abstract: The majority of research on efficient and scalable algorithms in\ncomputational science and engineering has focused on the forward problem: given\nparameter inputs, solve the governing equations to determine output quantities\nof interest. In contrast, here we consider the broader question: given a\n(large-scale) model containing uncertain parameters, (possibly) noisy\nobservational data, and a prediction quantity of interest, how do we construct\nefficient and scalable algorithms to (1) infer the model parameters from the\ndata (the deterministic inverse problem), (2) quantify the uncertainty in the\ninferred parameters (the Bayesian inference problem), and (3) propagate the\nresulting uncertain parameters through the model to issue predictions with\nquantified uncertainties (the forward uncertainty propagation problem)? We\npresent efficient and scalable algorithms for this end-to-end,\ndata-to-prediction process under the Gaussian approximation and in the context\nof modeling the flow of the Antarctic ice sheet and its effect on sea level.\nThe ice is modeled as a viscous, incompressible, creeping, shear-thinning\nfluid. The observational data come from InSAR satellite measurements of surface\nice flow velocity, and the uncertain parameter field to be inferred is the\nbasal sliding parameter. The prediction quantity of interest is the present-day\nice mass flux from the Antarctic continent to the ocean. We show that the work\nrequired for executing this data-to-prediction process is independent of the\nstate dimension, parameter dimension, data dimension, and number of processor\ncores. The key to achieving this dimension independence is to exploit the fact\nthat the observational data typically provide only sparse information on model\nparameters. This property can be exploited to construct a low rank\napproximation of the linearized parameter-to-observable map. \n\n"}
{"id": "1410.1828", "contents": "Title: Sampling and Galerkin reconstruction in reproducing kernel spaces Abstract: In this paper, we consider sampling in a reproducing kernel subspace of\n$L^p$. We introduce a pre-reconstruction operator associated with a sampling\nscheme and propose a Galerkin reconstruction in general Banach space setting.\nWe show that the proposed Galerkin method provides a quasi-optimal\napproximation, and the corresponding Galerkin equations could be solved by an\niterative approximation-projection algorithm. We also present detailed analysis\nand numerical simulations of the Galerkin method for reconstructing signals\nwith finite rate of innovation. \n\n"}
{"id": "1410.3253", "contents": "Title: A reduced basis localized orthogonal decomposition Abstract: In this work we combine the framework of the Reduced Basis method (RB) with\nthe framework of the Localized Orthogonal Decomposition (LOD) in order to solve\nparametrized elliptic multiscale problems. The idea of the LOD is to split a\nhigh dimensional Finite Element space into a low dimensional space with\ncomparably good approximation properties and a remainder space with negligible\ninformation. The low dimensional space is spanned by locally supported basis\nfunctions associated with the node of a coarse mesh obtained by solving\ndecoupled local problems. However, for parameter dependent multiscale problems,\nthe local basis has to be computed repeatedly for each choice of the parameter.\nTo overcome this issue, we propose an RB approach to compute in an \"offline\"\nstage LOD for suitable representative parameters. The online solution of the\nmultiscale problems can then be obtained in a coarse space (thanks to the LOD\ndecomposition) and for an arbitrary value of the parameters (thanks to a\nsuitable \"interpolation\" of the selected RB). The online RB-LOD has a basis\nwith local support and leads to sparse systems. Applications of the strategy to\nboth linear and nonlinear problems are given. \n\n"}
{"id": "1410.3547", "contents": "Title: Mathematical and numerical analysis of time-dependent Ginzburg--Landau\n  equations in nonconvex polygons based on Hodge decomposition Abstract: We prove well-posedness of time-dependent Ginzburg--Landau system in a\nnonconvex polygonal domain, and decompose the solution as a regular part plus a\nsingular part. We see that the magnetic potential is not in $H^1$ in general,\nand the finite element method (FEM) may give incorrect solutions. To remedy\nthis situation, we reformulate the equations into an equivalent system of\nelliptic and parabolic equations based on the Hodge decomposition, which avoids\ndirect calculation of the magnetic potential. The essential unknowns of the\nreformulated system admit $H^1$ solutions and can be solved correctly by the\nFEMs. We then propose a decoupled and linearized FEM to solve the reformulated\nequations and present error estimates based on proved regularity of the\nsolution. Numerical examples are provided to support our theoretical analysis\nand show the efficiency of the method. \n\n"}
{"id": "1410.7010", "contents": "Title: Energy conserving methods for Hamiltonian PDEs based on spectral space\n  decomposition Abstract: In this paper we discuss energy conservation issues related to the numerical\nsolution of the nonlinear wave equation, when a Fourier expansion is considered\nfor the space discretization. The obtained semi-discrete problem is then solved\nin time by means of energy-conserving Runge-Kutta methods in the HBVMs class. \n\n"}
{"id": "1411.0731", "contents": "Title: Quasi-Monte Carlo tractability of high dimensional integration over\n  products of simplices Abstract: Quasi-Monte Carlo (QMC) methods for high dimensional integrals over unit\ncubes and products of spheres are well-studied in literature. We study QMC\ntractability of integrals of functions defined over the product of $m$ copies\nof the simplex $T^d \\subset \\mathbb{R}^{d}$. The domain is a tensor product of\n$m$ reproducing kernel Hilbert spaces defined by `weights' $\\gamma_{m,j}$, for\n$j = 1,2, \\ldots, m$. Similar to the results on the unit cube in $m$\ndimensions, and the product of $m$ copies of the $d$-dimensional sphere, we\nprove that strong polynomial tractability holds iff $\\limsup_{m \\rightarrow\n\\infty} \\sum_{j=1}^m \\gamma_{m,j} < \\infty$ and polynomial tractability holds\niff $\\limsup_{m \\rightarrow \\infty} \\frac{\\sum_{j=1}^m \\gamma_{m,j}}{\\log(m + 1\n)} < \\infty$. We also show that weak tractability holds iff $\\lim_{m\n\\rightarrow \\infty} \\frac{\\sum_{j=1}^m \\gamma_{m,j}}{m} = 0$. The proofs employ\nSobolev space techniques and weighted reproducing kernel Hilbert space\ntechniques for the simplex and products of simplices as domain. Properties of\northogonal polynomials on a simplex are also used extensively. \n\n"}
{"id": "1411.1432", "contents": "Title: Numerical solution of steady-state groundwater flow and solute transport\n  problems: Discontinuous Galerkin based methods compared to the Streamline\n  Diffusion approach Abstract: In this study, we consider the simulation of subsurface flow and solute\ntransport processes in the stationary limit. In the convection-dominant case,\nthe numerical solution of the transport problem may exhibit non-physical\ndiffusion and under- and overshoots. For an interior penalty discontinuous\nGalerkin (DG) discretization, we present a $h$-adaptive refinement strategy\nand, alternatively, a new efficient approach for reducing numerical under- and\novershoots using a diffusive $L^2$-projection. Furthermore, we illustrate an\nefficient way of solving the linear system arising from the DG discretization.\nIn $2$-D and $3$-D examples, we compare the DG-based methods to the streamline\ndiffusion approach with respect to computing time and their ability to resolve\nsteep fronts. \n\n"}
{"id": "1411.1443", "contents": "Title: Boundary Integrals and Approximations of Harmonic Functions Abstract: Formulae for the value of a harmonic function at the center of a rectangle\nare found that involve boundary integrals. The central value of a harmonic\nfunction is shown to be well approximated by the mean value of the function on\nthe boundary plus a very small number (often just 1 or 2) of additional\nboundary integrals. The formulae are consequences of Steklov (spectral)\nrepresentations of the functions that converge exponentially at the center.\nSimilar approximation are found for the central values of solutions of Robin\nand Neumann boundary value problems. The results are based on explicit\nexpressions for the Steklov eigenvalues and eigenfunctions. \n\n"}
{"id": "1411.3688", "contents": "Title: Dimension-independent likelihood-informed MCMC Abstract: Many Bayesian inference problems require exploring the posterior distribution\nof high-dimensional parameters that represent the discretization of an\nunderlying function. This work introduces a family of Markov chain Monte Carlo\n(MCMC) samplers that can adapt to the particular structure of a posterior\ndistribution over functions. Two distinct lines of research intersect in the\nmethods developed here. First, we introduce a general class of\noperator-weighted proposal distributions that are well defined on function\nspace, such that the performance of the resulting MCMC samplers is independent\nof the discretization of the function. Second, by exploiting local Hessian\ninformation and any associated low-dimensional structure in the change from\nprior to posterior distributions, we develop an inhomogeneous discretization\nscheme for the Langevin stochastic differential equation that yields\noperator-weighted proposals adapted to the non-Gaussian structure of the\nposterior. The resulting dimension-independent, likelihood-informed (DILI) MCMC\nsamplers may be useful for a large class of high-dimensional problems where the\ntarget probability measure has a density with respect to a Gaussian reference\nmeasure. Two nonlinear inverse problems are used to demonstrate the efficiency\nof these DILI samplers: an elliptic PDE coefficient inverse problem and path\nreconstruction in a conditioned diffusion. \n\n"}
{"id": "1411.5631", "contents": "Title: New fully symmetric and rotationally symmetric cubature rules on the\n  triangle using minimal orthonormal bases Abstract: Cubature rules on the triangle have been extensively studied, as they are of\ngreat practical interest in numerical analysis. In most cases, the process by\nwhich new rules are obtained does not preclude the existence of similar rules\nwith better characteristics. There is therefore clear interest in searching for\nbetter cubature rules. Here we present a number of new cubature rules on the\ntriangle, exhibiting full or rotational symmetry, that improve on those\navailable in the literature either in terms of number of points or in terms of\nquality. These rules were obtained by determining and implementing minimal\northonormal polynomial bases that can express the symmetries of the cubature\nrules. As shown in specific benchmark examples, this results in significantly\nbetter performance of the employed algorithm. \n\n"}
{"id": "1411.5794", "contents": "Title: BMO and exponential Orlicz space estimates of the discrepancy function\n  in arbitrary dimension Abstract: In the current paper we obtain discrepancy estimates in exponential Orlicz\nand BMO spaces in arbitrary dimension $d \\ge 3$. In particular, we use dyadic\nharmonic analysis to prove that for the so-called digital nets of order $2$ the\nBMO${}^d$ and $\\exp \\big( L^{2/(d-1)} \\big)$ norms of the discrepancy function\nare bounded above by $(\\log N)^{\\frac{d-1}{2}}$. The latter bound has been\nrecently conjectured in several papers and is consistent with the best known\nlow-discrepancy constructions. Such estimates play an important role as an\nintermediate step between the well-understood $L_p$ bounds and the notorious\nopen problem of finding the precise $L_\\infty$ asymptotics of the discrepancy\nfunction in higher dimensions, which is still elusive. \n\n"}
{"id": "1411.7512", "contents": "Title: Eliminating the pollution effect in Helmholtz problems by local subscale\n  correction Abstract: We introduce a new Petrov-Galerkin multiscale method for the numerical\napproximation of the Helmholtz equation with large wave number $\\kappa$ in\nbounded domains in $\\mathbb{R}^d$. The discrete trial and test spaces are\ngenerated from standard mesh-based finite elements by local subscale\ncorrections in the spirit of numerical homogenization. The precomputation of\nthe corrections involves the solution of coercive cell problems on localized\nsubdomains of size $\\ell H$; $H$ being the mesh size and $\\ell$ being the\noversampling parameter. If the mesh size and the oversampling parameter are\nsuch that $H\\kappa$ and $\\log(\\kappa)/\\ell$ fall below some generic constants\nand if the cell problems are solved sufficiently accurate on some finer scale\nof discretization, then the method is stable and its error is proportional to\n$H$; pollution effects are eliminated in this regime. \n\n"}
{"id": "1412.0216", "contents": "Title: Finite element approximations of symmetric tensors on simplicial grids\n  in Rn: the lower order case Abstract: In this paper, we construct, in a unified fashion, lower order finite element\nsubspaces of spaces of symmetric tensors with square-integrable divergence on a\ndomain in any dimension. These subspaces are essentially the symmetric\nH(div)-Pk (1=<k<=n) tensor spaces, enriched, for each n-1 dimensional simplex,\nby (n+1)n/2 H(div)-Pn+1 bubble functions when 1=< k<= n-1, and by (n-1)n/2\nH(div)-P n+1 bubble functions when k= n. These spaces can be used to\napproximate the symmetric matrix field in a mixed formulation problem where the\nother variable is approximated by discontinuous piecewise Pk-1 polynomials.\nThis in particular leads to first order mixed elements on simplicial grids with\ntotal degrees of freedom per element $18$ plus $3$ in 2D, 48 plus 6 in 3D. The\nprevious record of the degrees of freedom of first order mixed elements is, 21\nplus 3 in 2D, and 156 plus 6 in 3D, on simplicial grids. We also derive, in a\nunified way and without using any tools like differential forms, a family of\nauxiliary mixed finite elements in any dimension. One example in this family is\nthe Raviart-Thomas elements in one dimension, the second example is the mixed\nfinite elements for linear elasticity in two dimensions due to Arnold and\nWinther, the third example is the mixed finite elements for linear elasticity\nin three dimensions due to Arnold, Awanou and Winther. \n\n"}
{"id": "1412.0393", "contents": "Title: Block Krylov subspace recycling for shifted systems with unrelated\n  right-hand sides Abstract: Many Krylov subspace methods for shifted linear systems take advantage of the\ninvariance of the Krylov subspace under a shift of the matrix. However,\nexploiting this fact in the non-Hermitian case introduces restrictions; e.g.,\ninitial residuals must be collinear and this collinearity must be maintained at\nrestart. Thus we cannot simultaneously solve shifted systems with unrelated\nright-hand sides using this strategy, and all shifted residuals cannot be\nsimultaneously minimized over a Krylov subspace such that collinearity is\nmaintained. It has been shown that this renders them generally incompatible\nwith techniques of subspace recycling [Soodhalter et al. APNUM '14].\n  This problem, however, can be overcome. By interpreting a family of shifted\nsystems as one Sylvester equation, we can take advantage of the known \"shift\ninvariance\" of the Krylov subspace generated by the Sylvester operator. Thus we\ncan simultaneously solve all systems over one block Krylov subspace using FOM\nor GMRES type methods, even when they have unrelated right-hand sides. Because\nresidual collinearity is no longer a requirement at restart, these methods are\nfully compatible with subspace recycling techniques. Furthermore, we realize\nthe benefits of block sparse matrix operations which arise in the context of\nhigh-performance computing applications.\n  In this paper, we discuss exploiting this Sylvester equation point of view\nwhich has yielded methods for shifted systems which are compatible with\nunrelated right-hand sides. From this, we propose a recycled GMRES method for\nsimultaneous solution of shifted systems.Numerical experiments demonstrate the\neffectiveness of the methods. \n\n"}
{"id": "1412.0427", "contents": "Title: Time-dependent Hermite-Galerkin spectral method and its applications Abstract: A time-dependent Hermite-Galerkin spectral method (THGSM) is investigated in\nthis paper for the nonlinear convection-diffusion equations in the unbounded\ndomains. The time-dependent scaling factor and translating factor are\nintroduced in the definition of the generalized Hermite functions (GHF). As a\nconsequence, the THGSM based on these GHF has many advantages, not only in\ntheorethical proofs, but also in numerical implementations. The stability and\nspectral convergence of our proposed method have been established in this\npaper. The Korteweg-de Vries-Burgers (KdVB) equation and its special cases,\nincluding the heat equation and the Burgers' equation, as the examples, have\nbeen numerically solved by our method. The numerical results are presented, and\nit surpasses the existing methods in accuracy. Our theoretical proof of the\nspectral convergence has been supported by the numerical results. \n\n"}
{"id": "1412.1352", "contents": "Title: A Study of Space-Time Discretizations for the Dirac Equation Abstract: We study several numerical discretization techniques for the one-space plus\none-time dimensional Dirac equation, including finite difference and space-time\nfinite element methods. Two finite difference schemes and several space-time\nfinite elements function spaces are analyzed with respect to known analytic\nsolutions. Further we propose a finite element discretization along the\nequations' characteristic lines, creating diamond-shaped elements in the\nspace-time plane. We show that the diamond shaped elements allow for physically\nintuitive boundary conditions, improve numerical efficiency, and reduce the\noverall error of the computed solution as compared to the other finite\ndifference and space-time finite element discretizations studied in this paper. \n\n"}
{"id": "1412.2637", "contents": "Title: A Space-Time Discontinuous Galerkin Trefftz Method for time dependent\n  Maxwell's equations Abstract: We consider the discretization of electromagnetic wave propagation problems\nby a discontinuous Galerkin Method based on Trefftz polynomials. This method\nfits into an abstract framework for space-time discontinuous Galerkin methods\nfor which we can prove consistency, stability, and energy dissipation without\nthe need to completely specify the approximation spaces in detail. Any method\nof such a general form results in an implicit time-stepping scheme with some\nbasic stability properties. For the local approximation on each space-time\nelement, we then consider Trefftz polynomials, i.e., the subspace of\npolynomials that satisfy Maxwell's equations exactly on the respective element.\nWe present an explicit construction of a basis for the local Trefftz spaces in\ntwo and three dimensions and summarize some of their basic properties. Using\nlocal properties of the Trefftz polynomials, we can establish the\nwell-posedness of the resulting discontinuous Galerkin Trefftz method.\nConsistency, stability, and energy dissipation then follow immediately from the\nresults about the abstract framework. The method proposed in this paper\ntherefore shares many of the advantages of more standard discontinuous Galerkin\nmethods, while at the same time, it yields a substantial reduction in the\nnumber of degrees of freedom and the cost for assembling. These benefits and\nthe spectral convergence of the scheme are demonstrated in numerical tests. \n\n"}
{"id": "1412.3784", "contents": "Title: Cell List Algorithms for Nonequilibrium Molecular Dynamics Abstract: We present two modifications of the standard cell list algorithm for\nnonequilibrium molecular dynamics simulations of homogeneous, linear flows.\nWhen such a flow is modeled with periodic boundary conditions, the simulation\nbox deforms with the flow, and recent progress has been made developing\nboundary conditions suitable for general 3D flows of this type. For the typical\ncase of short-ranged, pairwise interactions, the cell list algorithm reduces\ncomputational complexity of the force computation from O($N^2$) to O($N$),\nwhere $N$ is the total number of particles in the simulation box. The new\nversions of the cell list algorithm handle the dynamic, deforming simulation\ngeometry. We include a comparison of the complexity and efficiency of the two\nproposed modifications of the standard algorithm. \n\n"}
{"id": "1412.5641", "contents": "Title: Analysis of the Diffuse Domain Method for second order elliptic boundary\n  value problems Abstract: The diffuse domain method for partial differential equations on complicated\ngeometries recently received strong attention in particular from practitioners,\nbut many fundamental issues in the analysis are still widely open. In this\npaper we study the diffuse domain method for approximating second order\nelliptic boundary value problems posed on bounded domains, and show convergence\nand rates of the approximations generated by the diffuse domain method to the\nsolution of the original second order problem when complemented by Robin,\nDirichlet or Neumann conditions. The main idea of the diffuse domain method is\nto relax these boundary conditions by introducing a family of phase-field\nfunctions such that the variational integrals of the original problem are\nreplaced by a weighted average of integrals of perturbed domains. From an\nfunctional analytic point of view, the phase-field functions naturally lead to\nweighted Sobolev spaces for which we present trace and embedding results as\nwell as various type of Poincar\\'e inequalities with constants independent of\nthe domain perturbations. Our convergence analysis is carried out in such\nspaces as well, but allows to draw conclusions also about unweighted norms\napplied to restrictions on the original domain. Our convergence results are\nsupported by numerical examples. \n\n"}
{"id": "1412.6292", "contents": "Title: Strong convergence for split-step methods in stochastic jump kinetics Abstract: Mesoscopic models in the reaction-diffusion framework have gained recognition\nas a viable approach to describing chemical processes in cell biology. The\nresulting computational problem is a continuous-time Markov chain on a discrete\nand typically very large state space. Due to the many temporal and spatial\nscales involved many different types of computationally more effective\nmultiscale models have been proposed, typically coupling different types of\ndescriptions within the Markov chain framework.\n  In this work we look at the strong convergence properties of the basic first\norder Strang, or Lie-Trotter, split-step method, which is formed by decoupling\nthe dynamics in finite time-steps. Thanks to its simplicity and flexibility,\nthis approach has been tried in many different combinations.\n  We develop explicit sufficient conditions for path-wise well-posedness and\nconvergence of the method, including error estimates, and we illustrate our\nfindings with numerical examples. In doing so, we also suggest a certain\npartition of unity representation for the split-step method, which in turn\nimplies a concrete simulation algorithm under which trajectories may be\ncompared in a path-wise sense. \n\n"}
{"id": "1412.8398", "contents": "Title: Fourier-based schemes for computing the mechanical response of\n  composites with accurate local fields Abstract: We modify the Green operator involved in Fourier-based computational schemes\nin elasticity, in 2D and 3D. The new operator is derived by expressing\ncontinuum mechanics in terms of centered differences on a rotated grid. Use of\nthe modified Green operator leads, in all systems investigated, to more\naccurate strain and stress fields than using the discretizations proposed by\nMoulinec and Suquet (1994) or Willot and Pellegrini (2008). Moreover, we\ncompared the convergence rates of the \"direct\" and \"accelerated\" FFT schemes\nwith the different discretizations. The discretization method proposed in this\nwork allows for much faster FFT schemes with respect to two criteria: stress\nequilibrium and effective elastic moduli. \n\n"}
{"id": "1501.00251", "contents": "Title: A Tutorial on Inverse Problems for Anomalous Diffusion Processes Abstract: Over the last two decades, anomalous diffusion processes in which the mean\nsquares variance grows slower or faster than that in a Gaussian process have\nfound many applications. At a macroscopic level, these processes are adequately\ndescribed by fractional differential equations, which involves fractional\nderivatives in time or/and space. The fractional derivatives describe either\nhistory mechanism or long range interactions of particle motions at a\nmicroscopic level. The new physics can change dramatically the behavior of the\nforward problems. Naturally one expects that the new physics will impact\nrelated inverse problems in terms of uniqueness, stability, and degree of\nill-posedness. The last aspect is especially important from a practical point\nof view, i.e., stably reconstructing the quantities of interest.\n  In this paper, we employ a formal analytic and numerical way to examine the\ndegree of ill-posedness of several \"classical\" inverse problems for fractional\ndifferential equations involving a Djrbashian-Caputo fractional derivative in\neither time or space, which represent the fractional analogues of that for\nclassical integral order differential equations. We discuss four inverse\nproblems, i.e., backward fractional diffusion, sideways problem, inverse source\nproblem and inverse potential problem for time fractional diffusion, and\ninverse Sturm-Liouville problem, Cauchy problem, backward fractional diffusion\nand sideways problem for space fractional diffusion. It is found that contrary\nto the wide belief, the influence of anomalous diffusion on the degree of\nill-posedness is not definitive: it can either significantly improve or worsen\nthe conditioning of related inverse problems, depending crucially on the\nspecific type of given data and quantity of interest. Further, the study\nexhibits distinct new features of \"fractional\" inverse problems. \n\n"}
{"id": "1501.01800", "contents": "Title: Optimal quasi-Monte Carlo rules on order 2 digital nets for the\n  numerical integration of multivariate periodic functions Abstract: We investigate quasi-Monte Carlo rules for the numerical integration of\nmultivariate periodic functions from Besov spaces $S^r_{p,q}B(\\mathbb{T}^d)$\nwith dominating mixed smoothness $1/p<r<2$. We show that order 2 digital nets\nachieve the optimal rate of convergence $N^{-r} (\\log N)^{(d-1)(1-1/q)}$. The\nlogarithmic term does not depend on $r$ and hence improves the known bound\nprovided by J. Dick for the special case of Sobolev spaces\n$H^r_{\\text{mix}}(\\mathbb{T}^d)$. Secondly, the rate of convergence is\nindependent of the integrability $p$ of the Besov space, which allows for\nsacrificing integrability in order to gain Besov regularity. Our method\ncombines characterizations of periodic Besov spaces with dominating mixed\nsmoothness via Faber bases with sharp estimates of Haar coefficients for the\ndiscrepancy function of higher order digital nets. Moreover, we provide\nnumerical computations which indicate that this bound also holds for the case\n$r=2$. \n\n"}
{"id": "1501.03207", "contents": "Title: Detecting vortices in superconductors: Extracting one-dimensional\n  topological singularities from a discretized complex scalar field Abstract: In type-II superconductors, the dynamics of superconducting vortices\ndetermine their transport properties. In the Ginzburg-Landau theory, vortices\ncorrespond to topological defects in the complex order parameter. Extracting\ntheir precise positions and motion from discretized numerical simulation data\nis an important, but challenging task. In the past, vortices have mostly been\ndetected by analyzing the magnitude of the complex scalar field representing\nthe order parameter and visualized by corresponding contour plots and\nisosurfaces. However, these methods, primarily used for small-scale\nsimulations, blur the fine details of the vortices, scale poorly to large-scale\nsimulations, and do not easily enable isolating and tracking individual\nvortices. Here we present a method for exactly finding the vortex core lines\nfrom a complex order parameter field. With this method, vortices can be easily\ndescribed at a resolution even finer than the mesh itself. The precise\ndetermination of the vortex cores allows the interplay of the vortices inside a\nmodel superconductor to be visualized in higher resolution than has previously\nbeen possible. By representing the field as the set of vortices, this method\nalso massively reduces the data footprint of the simulations and provides the\ndata structures for further analysis and feature tracking. \n\n"}
{"id": "1501.03358", "contents": "Title: Recycling Krylov subspaces for CFD applications and a new hybrid\n  recycling solver Abstract: We focus on robust and efficient iterative solvers for the pressure Poisson\nequation in incompressible Navier-Stokes problems. Preconditioned Krylov\nsubspace methods are popular for these problems, with BiCGStab and GMRES(m)\nmost frequently used for nonsymmetric systems. BiCGStab is popular because it\nhas cheap iterations, but it may fail for stiff problems, especially early on\nas the initial guess is far from the solution. Restarted GMRES is better, more\nrobust, in this phase, but restarting may lead to very slow convergence.\nTherefore, we evaluate the rGCROT method for these systems. This method\nrecycles a selected subspace of the search space (called recycle space) after a\nrestart. This generally improves the convergence drastically compared with\nGMRES(m). Recycling subspaces is also advantageous for subsequent linear\nsystems, if the matrix changes slowly or is constant. However, rGCROT\niterations are still expensive in memory and computation time compared with\nthose of BiCGStab. Hence, we propose a new, hybrid approach that combines the\ncheap iterations of BiCGStab with the robustness of rGCROT. For the first few\ntime steps the algorithm uses rGCROT and builds an effective recycle space, and\nthen it recycles that space in the rBiCGStab solver. We evaluate rGCROT on a\nturbulent channel flow problem, and we evaluate both rGCROT and the new, hybrid\ncombination of rGCROT and rBiCGStab on a porous medium flow problem. We see\nsubstantial performance gains on both problems. \n\n"}
{"id": "1501.04414", "contents": "Title: Hierarchical Electrochemical Modeling and Simulation of Bio-Hybrid\n  Interfaces Abstract: In this article we propose and investigate a hierarchy of mathematical models\nbased on partial differential equations (PDE) and ordinary differential\nequations (ODE) for the simulation of the biophysical phenomena occurring in\nthe electrolyte fluid that connects a biological component (a single cell or a\nsystem of cells) and a solid-state device (a single silicon transistor or an\narray of transistors). The three members of the hierarchy, ordered by\ndecreasing complexity, are: (i) a 3D Poisson-Nernst-Planck (PNP) PDE system for\nion concentrations and electric potential; (ii) a 2D reduced PNP system for the\nsame dependent variables as in (i); (iii) a 2D area-contact PDE system for\nelectric potential coupled with a system of ODEs for ion concentrations. The\nbackward Euler method is adopted for temporal semi-discretization and a\nfixed-point iteration based on Gummel's map is used to decouple system\nequations. Spatial discretization is performed using piecewise linear\ntriangular finite elements stabilized via edge-based exponential fitting.\nExtensively conducted simulation results are in excellent agreement with\nexisting analytical solutions of the PNP problem in radial coordinates and\nexperimental and simulated data using simplified lumped parameter models. \n\n"}
{"id": "1501.04565", "contents": "Title: Residual-driven online Generalized Multiscale Finite Element Methods Abstract: The construction of local reduced-order models via multiscale basis functions\nhas been an area of active research. In this paper, we propose online\nmultiscale basis functions which are constructed using the offline space and\nthe current residual. Online multiscale basis functions are constructed\nadaptively in some selected regions based on our error indicators. We derive an\nerror estimator which shows that one needs to have an offline space with\ncertain properties to guarantee that additional online multiscale basis\nfunction will decrease the error. This error decrease is independent of\nphysical parameters, such as the contrast and multiple scales in the problem.\nThe offline spaces are constructed using Generalized Multiscale Finite Element\nMethods (GMsFEM). We show that if one chooses a sufficient number of offline\nbasis functions, one can guarantee that additional online multiscale basis\nfunctions will reduce the error independent of contrast. We note that the\nconstruction of online basis functions is motivated by the fact that the\noffline space construction does not take into account distant effects. Using\nthe residual information, we can incorporate the distant information provided\nthe offline approximation satisfies certain properties. In the paper,\ntheoretical and numerical results are presented. Our numerical results show\nthat if the offline space is sufficiently large (in terms of the dimension)\nsuch that the coarse space contains all multiscale spectral basis functions\nthat correspond to small eigenvalues, then the error reduction by adding online\nmultiscale basis function is independent of the contrast. We discuss various\nways computing online multiscale basis functions which include a use of small\ndimensional offline spaces. \n\n"}
{"id": "1501.05340", "contents": "Title: An unconditionally stable discontinuous Galerkin method for the elastic\n  Helmholtz equations with large frequency Abstract: In this paper we propose and analyze an interior penalty discontinuous\nGalerkin (IP-DG) method using piecewise linear polynomials for the elastic\nHelmholtz equations with the first order absorbing boundary condition. It is\nproved that the sesquilinear form for the problem satisfies a generalized weak\ncoercivity property, which immediately infers a stability estimate for the\nsolution of the differential problem in all frequency regimes. It is also\nproved that the proposed IP-DG method is unconditionally stable with respect to\nboth frequency $\\omega$ and mesh size $h$. Sub-optimal order (with respect to\n$h$) error estimates in the broken $H^1$-norm and in the $L^2$-norm are\nobtained in all mesh regimes. These estimate improve to optimal order when the\nmesh size $h$ is restricted to the pre-asymptotic regime (i.e., $\\omega^\\beta h\n=O(1)$ for some $1\\leq \\beta<2$). The novelties of the proposed IP-DG method\ninclude: first, the method penalizes not only the jumps of the function values\nacross the element edges but also the jumps of the normal derivatives; second,\nthe penalty parameters are taken as complex numbers with positive imaginary\nparts. In order to establish the desired unconditional stability estimate for\nthe numerical solution, the main idea is to exploit a (simple) property of\nlinear functions to overcome the main difficulty caused by non-Hermitian nature\nand strong indefiniteness of the Helmholtz-type problem. The error estimate is\nthen derived using a nonstandard technique adapted from \\cite{Feng_Wu09}.\nNumerical experiments are also presented to validate the theoretical results\nand to numerically examine the pollution effect (with respect to $\\omega$) in\nthe error bounds. \n\n"}
{"id": "1501.05508", "contents": "Title: High performance computing aspects of a dimension independent\n  semi-Lagrangian discontinuous Galerkin code Abstract: The recently developed semi-Lagrangian discontinuous Galerkin approach is\nused to discretize hyperbolic partial differential equations (usually first\norder equations). Since these methods are conservative, local in space, and\nable to limit numerical diffusion, they are considered a promising alternative\nto more traditional semi-Lagrangian schemes (which are usually based on\npolynomial or spline interpolation).\n  In this paper, we consider a parallel implementation of a semi-Lagrangian\ndiscontinuous Galerkin method for distributed memory systems (so-called\nclusters). Both strong and weak scaling studies are performed on the Vienna\nScientific Cluster 2 (VSC-2). In the case of weak scaling, up to 8192 cores, we\nobserve a parallel efficiency above 0.89 for both two and four dimensional\nproblems. Strong scaling results show good scalability to at least 1024 cores\n(we consider problems that can be run on a single processor in reasonable\ntime). In addition, we study the scaling of a two dimensional Vlasov--Poisson\nsolver that is implemented using the framework provided. All of the simulation\nare conducted in the context of worst case communication overhead; i.e., in a\nsetting where the CFL number increases linearly with the problem size.\n  The framework introduced in this paper facilitates a dimension independent\nimplementation (based on C++ templates) of scientific codes using both an MPI\nand a hybrid approach to parallelization. We describe the essential ingredients\nof our implementation. \n\n"}
{"id": "1501.05891", "contents": "Title: Stochastic collocation on unstructured multivariate meshes Abstract: Collocation has become a standard tool for approximation of parameterized\nsystems in the uncertainty quantification (UQ) community. Techniques for\nleast-squares regularization, compressive sampling recovery, and interpolatory\nreconstruction are becoming standard tools used in a variety of applications.\nSelection of a collocation mesh is frequently a challenge, but methods that\nconstruct geometrically \"unstructured\" collocation meshes have shown great\npotential due to attractive theoretical properties and direct, simple\ngeneration and implementation. We investigate properties of these meshes,\npresenting stability and accuracy results that can be used as guides for\ngenerating stochastic collocation grids in multiple dimensions. \n\n"}
{"id": "1501.07812", "contents": "Title: Quasiseparable Hessenberg reduction of real diagonal plus low rank\n  matrices and applications Abstract: We present a novel algorithm to perform the Hessenberg reduction of an\n$n\\times n$ matrix $A$ of the form $A = D + UV^*$ where $D$ is diagonal with\nreal entries and $U$ and $V$ are $n\\times k$ matrices with $k\\le n$. The\nalgorithm has a cost of $O(n^2k)$ arithmetic operations and is based on the\nquasiseparable matrix technology. Applications are shown to solving polynomial\neigenvalue problems and some numerical experiments are reported in order to\nanalyze the stability of the approach \n\n"}
{"id": "1502.02280", "contents": "Title: A comparison of the Extrapolated Successive Overrelaxation and the\n  Preconditioned Simultaneous Displacement methods for augmented linear systems Abstract: In this paper we study the impact of two types of preconditioning on the\nnumerical solution of large sparse augmented linear systems. The first\npreconditioning matrix is the lower triangular part whereas the second is the\nproduct of the lower triangular part with the upper triangular part of the\naugmented system's coefficient matrix. For the first preconditioning matrix we\nform the Generalized Modified Extrapolated Successive Overrelaxation (GMESOR)\nmethod, whereas the second preconditioning matrix yields the Generalized\nModified Preconditioned Simultaneous Displacement (GMPSD) method, which is an\nextrapolated form of the Symmetric Successive Overrelaxation method. We find\nsufficient conditions for each aforementioned iterative method to converge. In\naddition, we develop a geometric approach, for determining the optimum values\nof their parameters and corresponding spectral radii. It is shown that both\niterative methods studied (GMESOR and GMPSD) attain the same rate of\nconvergence. Numerical results confirm our theoretical expectations. \n\n"}
{"id": "1502.03229", "contents": "Title: Why Use Sobolev Metrics on the Space of Curves Abstract: We study reparametrization invariant Sobolev metrics on spaces of regular\ncurves. We discuss their completeness properties and the resulting usability\nfor applications in shape analysis. In particular, we will argue, that the\ndevelopment of efficient numerical methods for higher order Sobolev type\nmetrics is an extremely desirable goal. \n\n"}
{"id": "1502.05025", "contents": "Title: The Finite Element Method for the time-dependent Gross-Pitaevskii\n  equation with angular momentum rotation Abstract: We consider the time-dependent Gross-Pitaevskii equation describing the\ndynamics of rotating Bose-Einstein condensates and its discretization with the\nfinite element method. We analyze a mass conserving Crank-Nicolson-type\ndiscretization and prove corresponding a priori error estimates with respect to\nthe maximum norm in time and the $L^2$- and energy-norm in space. The estimates\nshow that we obtain optimal convergence rates under the assumption of\nadditional regularity for the solution to the Gross-Pitaevskii equation. We\ndemonstrate the performance of the method in numerical experiments. \n\n"}
{"id": "1502.05366", "contents": "Title: RSVDPACK: An implementation of randomized algorithms for computing the\n  singular value, interpolative, and CUR decompositions of matrices on\n  multi-core and GPU architectures Abstract: RSVDPACK is a library of functions for computing low rank approximations of\nmatrices. The library includes functions for computing standard (partial)\nfactorizations such as the Singular Value Decomposition (SVD), and also so\ncalled \"structure preserving\" factorizations such as the Interpolative\nDecomposition (ID) and the CUR decomposition. The ID and CUR factorizations\npick subsets of the rows/columns of a matrix to use as bases for its row/column\nspace. Such factorizations preserve properties of the matrix such as sparsity\nor non-negativity, are helpful in data interpretation, and require in certain\ncontexts less memory than a partial SVD. The package implements highly\nefficient computational algorithms based on randomized sampling, as described\nand analyzed in [N. Halko, P.G. Martinsson, J. Tropp, \"Finding structure with\nrandomness: Probabilistic algorithms for constructing approximate matrix\ndecompositions,\" SIAM Review, 53(2), 2011], and subsequent papers. This\nmanuscript presents some modifications to the basic algorithms that improve\nperformance and ease of use. The library is written in C and supports both\nmulti-core CPU and GPU architectures. \n\n"}
{"id": "1502.05528", "contents": "Title: Word series for dynamical systems and their numerical integrators Abstract: We study word series and extended word series, classes of formal series for\nthe analysis of some dynamical systems and their discretizations. These series\nare similar to but more compact than B-series. They may be composed among\nthemselves by means of a simple rule. While word series have appeared before in\nthe literature, extended word series are introduced in this paper. We exemplify\nthe use of extended word series by studying the reduction to normal form and\naveraging of some perturbed integrable problems. We also provide a detailed\nanalysis of the behaviour of splitting numerical methods for those problems. \n\n"}
{"id": "1503.02352", "contents": "Title: Infinite-dimensional $\\ell^1$ minimization and function approximation\n  from pointwise data Abstract: We consider the problem of approximating a smooth function from finitely-many\npointwise samples using $\\ell^1$ minimization techniques. In the first part of\nthis paper, we introduce an infinite-dimensional approach to this problem.\nThree advantages of this approach are as follows. First, it provides\ninterpolatory approximations in the absence of noise. Second, it does not\nrequire \\textit{a priori} bounds on the expansion tail in order to be\nimplemented. In particular, the truncation strategy we introduce as part of\nthis framework is independent of the function being approximated, provided the\nfunction has sufficient regularity. Third, it allows one to explain the key\nrole weights play in the minimization; namely, that of regularizing the problem\nand removing aliasing phenomena. In the second part of this paper we present a\nworst-case error analysis for this approach. We provide a general recipe for\nanalyzing this technique for arbitrary deterministic sets of points. Finally,\nwe use this tool to show that weighted $\\ell^1$ minimization with Jacobi\npolynomials leads to an optimal method for approximating smooth,\none-dimensional functions from scattered data. \n\n"}
{"id": "1503.04123", "contents": "Title: Perturbation theory for Markov chains via Wasserstein distance Abstract: Perturbation theory for Markov chains addresses the question how small\ndifferences in the transitions of Markov chains are reflected in differences\nbetween their distributions. We prove powerful and flexible bounds on the\ndistance of the $n$th step distributions of two Markov chains when one of them\nsatisfies a Wasserstein ergodicity condition. Our work is motivated by the\nrecent interest in approximate Markov chain Monte Carlo (MCMC) methods in the\nanalysis of big data sets. By using an approach based on Lyapunov functions, we\nprovide estimates for geometrically ergodic Markov chains under weak\nassumptions. In an autoregressive model, our bounds cannot be improved in\ngeneral. We illustrate our theory by showing quantitative estimates for\napproximate versions of two prominent MCMC algorithms, the Metropolis-Hastings\nand stochastic Langevin algorithms. \n\n"}
{"id": "1503.06160", "contents": "Title: Structure-preserving Finite Element Methods for Stationary MHD Models Abstract: In this paper, we develop a class of mixed finite element scheme for\nstationary magnetohydrodynamics (MHD) models, using magnetic field $\\bm B$ and\ncurrent density $\\bm j$ as the discretization variables. We show that the\nGauss's law for the magnetic field, namely $\\nabla\\cdot\\bm{B}=0$, and the\nenergy law for the entire system are exactly preserved in the finite element\nschemes. Based on some new basic estimates for $H^{h}(\\mathrm{div})$, we show\nthat the new finite element scheme is well-posed. Furthermore, we show the\nexistence of solutions to the nonlinear problems and the convergence of Picard\niterations and finite element methods under some conditions. \n\n"}
{"id": "1503.09157", "contents": "Title: Computational and in vitro studies of blast-induced blood-brain barrier\n  disruption Abstract: There is growing concern that blast-exposed individuals are at risk of\ndeveloping neurological disorders later in life. Therefore, it is important to\nunderstand the dynamic properties of blast forces on brain cells, including the\nendothelial cells that maintain the blood-brain barrier (BBB), which regulates\nthe passage of nutrients into the brain and protects it from toxins in the\nblood. To better understand the effect of shock waves on the BBB we have\ninvestigated an {\\em in vitro} model in which BBB endothelial cells are grown\nin transwell vessels and exposed in a shock tube, confirming that BBB integrity\nis directly related to shock wave intensity. It is difficult to directly\nmeasure the forces acting on these cells in the transwell container during the\nexperiments, and so a computational tool has been developed and presented in\nthis paper.\n  Two-dimensional axisymmetric Euler equations with the Tammann equation of\nstate were used to model the transwell materials, and a high-resolution finite\nvolume method based on Riemann solvers and the Clawpack software was used to\nsolve these equations in a mixed Eulerian/Lagrangian frame. Results indicated\nthat the geometry of the transwell plays a significant role in the observed\npressure time series in these experiments. We also found that pressures can\nfall below vapor pressure due to the interaction of reflecting and diffracting\nshock waves, suggesting that cavitation bubbles could be a damage mechanism.\nComputations that include a simulated hydrophone inserted in the transwell\nsuggest that the instrument itself could significantly alter blast wave\nproperties. These findings illustrate the need for further computational\nmodeling studies aimed at understanding possible blast-induced BBB damage. \n\n"}
{"id": "1504.01037", "contents": "Title: Sharp high-frequency estimates for the Helmholtz equation and\n  applications to boundary integral equations Abstract: We consider three problems for the Helmholtz equation in interior and\nexterior domains in R^d (d=2,3): the exterior Dirichlet-to-Neumann and\nNeumann-to-Dirichlet problems for outgoing solutions, and the interior\nimpedance problem. We derive sharp estimates for solutions to these problems\nthat, in combination, give bounds on the inverses of the combined-field\nboundary integral operators for exterior Helmholtz problems. \n\n"}
{"id": "1504.01529", "contents": "Title: Error Estimates for Approximations of Distributed Order Time Fractional\n  Diffusion with Nonsmooth Data Abstract: In this work, we consider the numerical solution of an initial boundary value\nproblem for the distributed order time fractional diffusion equation. The model\narises in the mathematical modeling of ultra-slow diffusion processes observed\nin some physical problems, whose solution decays only logarithmically as the\ntime $t$ tends to infinity. We develop a space semidiscrete scheme based on the\nstandard Galerkin finite element method, and establish error estimates optimal\nwith respect to data regularity in $L^2(D)$ and $H^1(D)$ norms for both smooth\nand nonsmooth initial data. Further, we propose two fully discrete schemes,\nbased on the Laplace transform and convolution quadrature generated by the\nbackward Euler method, respectively, and provide optimal convergence rates in\nthe $L^2(D)$ norm, which exhibits exponential convergence and first-order\nconvergence in time, respectively. Extensive numerical experiments are provided\nto verify the error estimates for both smooth and nonsmooth initial data, and\nto examine the asymptotic behavior of the solution. \n\n"}
{"id": "1504.01609", "contents": "Title: A dispersion minimizing scheme for the 3-D Helmholtz equation based on\n  ray theory Abstract: We develop a new dispersion minimizing compact finite difference scheme for\nthe Helmholtz equation in 2 and 3 dimensions. The scheme is based on a newly\ndeveloped ray theory for difference equations. A discrete Helmholtz operator\nand a discrete operator to be applied to the source and the wavefields are\nconstructed. Their coefficients are piecewise polynomial functions of $hk$,\nchosen such that phase and amplitude errors are minimal. The phase errors of\nthe scheme are very small, approximately as small as those of the 2-D\nquasi-stabilized FEM method and substantially smaller than those of\nalternatives in 3-D, assuming the same number of gridpoints per wavelength is\nused. In numerical experiments, accurate solutions are obtained in constant and\nsmoothly varying media using meshes with only five to six points per wavelength\nand wave propagation over hundreds of wavelengths. When used as a coarse level\ndiscretization in a multigrid method the scheme can even be used with downto\nthree points per wavelength. Tests on 3-D examples with up to $10^8$ degrees of\nfreedom show that with a recently developed hybrid solver, the use of coarser\nmeshes can lead to corresponding savings in computation time, resulting in good\nsimulation times compared to the literature. \n\n"}
{"id": "1504.01810", "contents": "Title: Accuracy of patch dynamics with mesoscale temporal coupling for\n  efficient exascale simulation Abstract: Massive parallelisation has lead to a dramatic increase in available\ncomputational power. However, data transfer speeds have failed to keep pace and\nare the major limiting factor in the development of exascale computing. New\nalgorithms must be developed which minimise the transfer of data. Patch\ndynamics is a computational macroscale modelling scheme which provides a coarse\nmacroscale solution of a problem defined on a fine microscale by dividing the\ndomain into many nonoverlapping, coupled patches. Patch dynamics is readily\nadaptable to massive parallelisation as each processor can evaluate the\ndynamics on one, or a few, patches. However, patch coupling conditions\ninterpolate across the unevaluated parts of the domain between patches, and are\ntypically reevaluated at every microscale time step, thus requiring almost\ncontinuous data transfer. We propose a modified patch dynamics scheme which\nminimises data transfer by only reevaluating the patch coupling conditions at\n`mesoscale' time scales which are significantly larger than the microscale time\nof the microscale problem. We analyse the error arising from patch dynamics\nwith mesoscale temporal coupling as a function of the mesoscale time interval,\npatch size, and ratio between the microscale and macroscale. \n\n"}
{"id": "1504.02646", "contents": "Title: Adaptive discontinuous Galerkin methods for nonlinear parabolic problems Abstract: This work is devoted to the study of a posteriori error estimation and\nadaptivity in parabolic problems with a particular focus on spatial\ndiscontinuous Galerkin (dG) discretisations.\n  We begin by deriving an a posteriori error estimator for a linear\nnon-stationary convection-diffusion problem that is discretised with a backward\nEuler dG method. An adaptive algorithm is then proposed to utilise the error\nestimator. The effectiveness of both the error estimator and the proposed\nalgorithm is shown through a series of numerical experiments.\n  Moving on to nonlinear problems, we investigate the numerical approximation\nof blow-up. To begin this study, we first look at the numerical approximation\nof blow-up in nonlinear ODEs through standard time stepping schemes. We then\nderive an a posteriori error estimator for an implicit-explicit (IMEX) dG\ndiscretisation of a semilinear parabolic PDE with quadratic nonlinearity. An\nadaptive algorithm is proposed that uses the error estimator to approach the\nblow-up time. The adaptive algorithm is then applied in a series of test cases\nto gauge the effectiveness of the error estimator.\n  Finally, we consider the adaptive numerical approximation of a nonlinear\ninterface problem that is used to model the mass transfer of solutes through\nsemi-permiable membranes. An a posteriori error estimator is proposed for the\nIMEX dG discretisation of the model and its effectiveness tested through a\nseries of numerical experiments. \n\n"}
{"id": "1504.03529", "contents": "Title: Analysis of the Ensemble and Polynomial Chaos Kalman Filters in Bayesian\n  Inverse Problems Abstract: We analyze the Ensemble and Polynomial Chaos Kalman filters applied to\nnonlinear stationary Bayesian inverse problems. In a sequential data\nassimilation setting such stationary problems arise in each step of either\nfilter. We give a new interpretation of the approximations produced by these\ntwo popular filters in the Bayesian context and prove that, in the limit of\nlarge ensemble or high polynomial degree, both methods yield approximations\nwhich converge to a well-defined random variable termed the analysis random\nvariable. We then show that this analysis variable is more closely related to a\nspecific linear Bayes estimator than to the solution of the associated Bayesian\ninverse problem given by the posterior measure. This suggests limited or at\nleast guarded use of these generalized Kalman filter methods for the purpose of\nuncertainty quantification. \n\n"}
{"id": "1504.04417", "contents": "Title: An online generalized multiscale discontinuous Galerkin method (GMsDGM)\n  for flows in heterogeneous media Abstract: Offline computation is an essential component in most multiscale model\nreduction techniques. However, there are multiscale problems in which offline\nprocedure is insufficient to give accurate representations of solutions, due to\nthe fact that offline computations are typically performed locally and global\ninformation is missing in these offline information. To tackle this difficulty,\nwe develop an online local adaptivity technique for local multiscale model\nreduction problems. We design new online basis functions within Discontinuous\nGalerkin method based on local residuals and some optimally estimates. The\nresulting basis functions are able to capture the solution efficiently and\naccurately, and are added to the approximation iteratively. Moreover, we show\nthat the iterative procedure is convergent with a rate independent of physical\nscales if the initial space is chosen carefully. Our analysis also gives a\nguideline on how to choose the initial space. We present some numerical\nexamples to show the performance of the proposed method. \n\n"}
{"id": "1504.06149", "contents": "Title: A low-rank approach to the computation of path integrals Abstract: We present a method for solving the reaction-diffusion equation with general\npotential in free space. It is based on the approximation of the Feynman-Kac\nformula by a sequence of convolutions on sequentially diminishing grids. For\ncomputation of the convolutions we propose a fast algorithm based on the\nlow-rank approximation of the Hankel matrices. The algorithm has complexity of\n$\\mathcal{O}(nr M \\log M + nr^2 M)$ flops and requires $\\mathcal{O}(M r)$\nfloating-point numbers in memory, where $n$ is the dimension of the integral,\n$r \\ll n$, and $M$ is the mesh size in one dimension. The presented technique\ncan be generalized to the higher-order diffusion processes. \n\n"}
{"id": "1504.06164", "contents": "Title: Adaptive 2D IGA boundary element methods Abstract: We derive and discuss a posteriori error estimators for Galerkin and\ncollocation IGA boundary element methods for weakly-singular integral equations\nof the first-kind in 2D. While recent own work considered the Faermann residual\nerror estimator for Galerkin IGA boundary element methods, the present work\nfocuses more on collocation and weighted- residual error estimators, which\nprovide reliable upper bounds for the energy error. Our analysis allows\npiecewise smooth parametrizations of the boundary, local mesh-refinement, and\nrelated standard piecewise polynomials as well as NURBS. We formulate an\nadaptive algorithm which steers the local mesh-refinement and the multiplicity\nof the knots. Numerical experiments show that the proposed adaptive strategy\nleads to optimal convergence, and related IGA boundary element methods are\nsuperior to standard boundary element methods with piecewise polynomials. \n\n"}
{"id": "1504.06289", "contents": "Title: Tensor Numerical Methods in Quantum Chemistry: from Hartree-Fock Energy\n  to Excited States Abstract: We resume the recent successes of the grid-based tensor numerical methods and\ndiscuss their prospects in real-space electronic structure calculations. These\nmethods, based on the low-rank representation of the multidimensional functions\nand integral operators, led to entirely grid-based tensor-structured 3D\nHartree-Fock eigenvalue solver. It benefits from tensor calculation of the core\nHamiltonian and two-electron integrals (TEI) in $O(n\\log n)$ complexity using\nthe rank-structured approximation of basis functions, electron densities and\nconvolution integral operators all represented on 3D $n\\times n\\times n $\nCartesian grids. The algorithm for calculating TEI tensor in a form of the\nCholesky decomposition is based on multiple factorizations using algebraic 1D\n``density fitting`` scheme. The basis functions are not restricted to separable\nGaussians, since the analytical integration is substituted by high-precision\ntensor-structured numerical quadratures. The tensor approaches to\npost-Hartree-Fock calculations for the MP2 energy correction and for the\nBethe-Salpeter excited states, based on using low-rank factorizations and the\nreduced basis method, were recently introduced. Another direction is related to\nthe recent attempts to develop a tensor-based Hartree-Fock numerical scheme for\nfinite lattice-structured systems, where one of the numerical challenges is the\nsummation of electrostatic potentials of a large number of nuclei. The 3D\ngrid-based tensor method for calculation of a potential sum on a $L\\times\nL\\times L$ lattice manifests the linear in $L$ computational work, $O(L)$,\ninstead of the usual $O(L^3 \\log L)$ scaling by the Ewald-type approaches. \n\n"}
{"id": "1504.07413", "contents": "Title: Computing Eigenvalues of Large Scale Hankel Tensors Abstract: Large scale tensors, including large scale Hankel tensors, have many\napplications in science and engineering. In this paper, we propose an inexact\ncurvilinear search optimization method to compute Z- and H-eigenvalues of $m$th\norder $n$ dimensional Hankel tensors, where $n$ is large. Owing to the fast\nFourier transform, the computational cost of each iteration of the new method\nis about $\\mathcal{O}(mn\\log(mn))$. Using the Cayley transform, we obtain an\neffective curvilinear search scheme. Then, we show that every limiting point of\niterates generated by the new algorithm is an eigen-pair of Hankel tensors.\nWithout the assumption of a second-order sufficient condition, we analyze the\nlinear convergence rate of iterate sequence by the Kurdyka-{\\L}ojasiewicz\nproperty. Finally, numerical experiments for Hankel tensors, whose dimension\nmay up to one million, are reported to show the efficiency of the proposed\ncurvilinear search method. \n\n"}
{"id": "1504.07690", "contents": "Title: Randomized estimation of spectral densities of large matrices made\n  accurate Abstract: For a large Hermitian matrix $A\\in \\mathbb{C}^{N\\times N}$, it is often the\ncase that the only affordable operation is matrix-vector multiplication. In\nsuch case, randomized method is a powerful way to estimate the spectral density\n(or density of states) of $A$. However, randomized methods developed so far for\nestimating spectral densities only extract information from different random\nvectors independently, and the accuracy is therefore inherently limited to\n$\\mathcal{O}(1/\\sqrt{N_{v}})$ where $N_{v}$ is the number of random vectors. In\nthis paper we demonstrate that the \"$\\mathcal{O}(1/\\sqrt{N_{v}})$ barrier\" can\nbe overcome by taking advantage of the correlated information of random vectors\nwhen properly filtered by polynomials of $A$. Our method uses the fact that the\nestimation of the spectral density essentially requires the computation of the\ntrace of a series of matrix functions that are numerically low rank. By\nrepeatedly applying $A$ to the same set of random vectors and taking different\nlinear combination of the results, we can sweep through the entire spectrum of\n$A$ by building such low rank decomposition at different parts of the spectrum.\nUnder some assumptions, we demonstrate that a robust and efficient\nimplementation of such spectrum sweeping method can compute the spectral\ndensity accurately with $\\mathcal{O}(N^2)$ computational cost and\n$\\mathcal{O}(N)$ memory cost. Numerical results indicate that the new method\ncan significantly outperform existing randomized methods in terms of accuracy.\nAs an application, we demonstrate a way to accurately compute a trace of a\nsmooth matrix function, by carefully balancing the smoothness of the integrand\nand the regularized density of states using a deconvolution procedure. \n\n"}
{"id": "1505.00370", "contents": "Title: A New Selection Operator for the Discrete Empirical Interpolation Method\n  -- improved a priori error bound and extensions Abstract: This paper introduces a new framework for constructing the Discrete Empirical\nInterpolation Method DEIM projection operator. The interpolation node selection\nprocedure is formulated using the QR factorization with column pivoting, and it\nenjoys a sharper error bound for the DEIM projection error. Furthermore, for a\nsubspace $\\mathcal{U}$ given as the range of an orthonormal $U$, the DEIM\nprojection does not change if $U$ is replaced by $U \\Omega$ with arbitrary\nunitary matrix $\\Omega$. In a large-scale setting, the new approach allows\nmodifications that use only randomly sampled rows of $U$, but with the\npotential of producing good approximations with corresponding probabilistic\nerror bounds. Another salient feature of the new framework is that robust and\nefficient software implementation is easily developed, based on readily\navailable high performance linear algebra packages. \n\n"}
{"id": "1505.02003", "contents": "Title: Super-polynomial convergence and tractability of multivariate\n  integration for infinitely times differentiable functions Abstract: We investigate multivariate integration for a space of infinitely times\ndifferentiable functions $\\mathcal{F}_{s, \\boldsymbol{u}} := \\{f \\in C^\\infty\n[0,1]^s \\mid \\| f \\|_{\\mathcal{F}_{s, \\boldsymbol{u}}} < \\infty \\}$, where $\\|\nf \\|_{\\mathcal{F}_{s, \\boldsymbol{u}}} := \\sup_{\\boldsymbol{\\alpha} =\n(\\alpha_1, \\dots, \\alpha_s) \\in \\mathbb{N}_0^s}\n\\|f^{(\\boldsymbol{\\alpha})}\\|_{L^1}/\\prod_{j=1}^s u_j^{\\alpha_j}$,\n$f^{(\\boldsymbol{\\alpha})} := \\frac{\\partial^{|\\boldsymbol{\\alpha}|}}{\\partial\nx_1^{\\alpha_1} \\cdots \\partial x_s^{\\alpha_s}}f$ and $\\boldsymbol{u} =\n\\{u_j\\}_{j \\geq 1}$ is a sequence of positive decreasing weights. Let $e(n,s)$\nbe the minimal worst-case error of all algorithms that use $n$ function values\nin the $s$-variate case. We prove that for any $\\boldsymbol{u}$ and $s$\nconsidered $e(n,s) \\leq C(s) \\exp(-c(s)(\\log{n})^2)$ holds for all $n$, where\n$C(s)$ and $c(s)$ are constants which may depend on $s$. Further we show that\nif the weights $\\boldsymbol{u}$ decay sufficiently fast then there exist some\n$1 < p < 2$ and absolute constants $C$ and $c$ such that $e(n,s) \\leq C\n\\exp(-c(\\log{n})^p)$ holds for all $s$ and $n$. These bounds are attained by\nquasi-Monte Carlo integration using digital nets. These convergence and\ntractability results come from those for the Walsh space into which\n$\\mathcal{F}_{s, \\boldsymbol{u}}$ is embedded. \n\n"}
{"id": "1505.04965", "contents": "Title: A Plane Wave Virtual Element Method for the Helmholtz Problem Abstract: We introduce and analyze a virtual element method (VEM) for the Helmholtz\nproblem with approximating spaces made of products of low order VEM functions\nand plane waves. We restrict ourselves to the 2D Helmholtz equation with\nimpedance boundary conditions on the whole domain boundary. The main\ningredients of the plane wave VEM scheme are: i) a low frequency space made of\nVEM functions, whose basis functions are not explicitly computed in the element\ninteriors; ii) a proper local projection operator onto the high-frequency\nspace, made of plane waves; iii) an approximate stabilization term. A\nconvergence result for the h-version of the method is proved, and numerical\nresults testing its performance on general polygonal meshes are presented. \n\n"}
{"id": "1505.05308", "contents": "Title: A practical guide to the recovery of wavelet coefficients from Fourier\n  measurements Abstract: In a series of recent papers (Adcock, Hansen and Poon, 2013, Appl. Comput.\nHarm. Anal. 45(5):3132-3167), (Adcock, Gataric and Hansen, 2014, SIAM J.\nImaging Sci. 7(3):1690-1723) and (Adcock, Hansen, Kutyniok and Ma, 2015, SIAM\nJ. Math. Anal. 47(2):1196-1233), it was shown that one can optimally recover\nthe wavelet coefficients of an unknown compactly supported function from\npointwise evaluations of its Fourier transform via the method of generalized\nsampling. While these papers focused on the optimality of generalized sampling\nin terms of its stability and error bounds, the current paper explains how this\noptimal method can be implemented to yield a computationally efficient\nalgorithm. In particular, we show that generalized sampling has a computational\ncomplexity of $\\mathcal{O}(M(N)\\log N)$ when recovering the first $N$\nboundary-corrected wavelet coefficients of an unknown compactly supported\nfunction from $M(N)$ Fourier samples. Therefore, due to the linear\ncorrespondences between the number of samples $M$ and number of coefficients\n$N$ shown previously, generalized sampling offers a computationally optimal way\nof recovering wavelet coefficients from Fourier data. \n\n"}
{"id": "1505.07204", "contents": "Title: The minimal measurement number for low-rank matrices recovery Abstract: The paper presents several results that address a fundamental question in\nlow-rank matrices recovery: how many measurements are needed to recover low\nrank matrices? We begin by investigating the complex matrices case and show\nthat $4nr-4r^2$ generic measurements are both necessary and sufficient for the\nrecovery of rank-$r$ matrices in $\\C^{n\\times n}$ by algebraic tools. Thus, we\nconfirm a conjecture which is raised by Eldar, Needell and Plan for the complex\ncase. We next consider the real case and prove that the bound $4nr-4r^2$ is\ntight provided $n=2^k+r, k\\in \\Z_+$. Motivated by Vinzant's work, we construct\n$11$ matrices in $\\R^{4\\times 4}$ by computer random search and prove they\ndefine injective measurements on rank-$1$ matrices in $\\R^{4\\times 4}$. This\ndisproves the conjecture raised by Eldar, Needell and Plan for the real case.\nFinally, we use the results in this paper to investigate the phase retrieval by\nprojection and show fewer than $2n-1$ orthogonal projections are possible for\nthe recovery of $x\\in \\R^n$ from the norm of them. \n\n"}
{"id": "1505.07529", "contents": "Title: Gaussian-Like Immersed Boundary Kernels with Three Continuous\n  Derivatives and Improved Translational Invariance Abstract: The immersed boundary (IB) method is a general mathematical framework for\nstudying problems involving fluid-structure interactions in which an elastic\nstructure is immersed in a viscous incompressible fluid. In the IB formulation,\nthe fluid described by Eulerian variables is coupled with the immersed\nstructure described by Lagrangian variables via the use of the Dirac delta\nfunction. From a numerical standpoint, the Lagrangian force spreading and the\nEulerian velocity interpolation are carried out by a regularized, compactly\nsupported discrete delta function, which is assumed to be a tensor product of a\nsingle-variable immersed-boundary kernel. IB kernels are derived from a set of\npostulates designed to achieve approximate grid translational invariance,\ninterpolation accuracy and computational efficiency. In this note, we present\nnew 5-point and 6-point immersed-boundary kernels that are $\\mathscr{C}^3$ and\nyield a substantially improved translational invariance compared to other\ncommon IB kernels. \n\n"}
{"id": "1505.07865", "contents": "Title: An Immersed Boundary Method for Rigid Bodies Abstract: We develop an immersed boundary (IB) method for modeling flows around fixed\nor moving rigid bodies that is suitable for a broad range of Reynolds numbers,\nincluding steady Stokes flow. The spatio-temporal discretization of the fluid\nequations is based on a standard staggered-grid approach. Fluid-body\ninteraction is handled using Peskin's IB method; however, unlike existing IB\napproaches to such problems, we do not rely on penalty or fractional-step\nformulations. Instead, we use an unsplit scheme that ensures the no-slip\nconstraint is enforced exactly in terms of the Lagrangian velocity field\nevaluated at the IB markers. Fractional-step approaches, by contrast, can\nimpose such constraints only approximately. Imposing these constraints exactly\nrequires the solution of a large linear system that includes the fluid velocity\nand pressure as well as Lagrange multiplier forces that impose the motion of\nthe body. To solve this system efficiently, we develop a preconditioner for the\nconstrained IB formulation that is based on an analytical approximation to the\nSchur complement. This approach is enabled by the near translational and\nrotational invariance of Peskin's IB method. We demonstrate that only a few\ncycles of a geometric multigrid method for the fluid equations are required in\neach application of the preconditioner, and we demonstrate robust convergence\nof the overall Krylov solver despite the approximations made in the\npreconditioner. We apply the method to a number of test problems at zero and\nfinite Reynolds numbers, and we demonstrate first-order convergence of the\nmethod to several analytical solutions and benchmark computations. \n\n"}
{"id": "1506.00783", "contents": "Title: Shape Analysis on Lie Groups with Applications in Computer Animation Abstract: Shape analysis methods have in the past few years become very popular, both\nfor theoretical exploration as well as from an application point of view.\nOriginally developed for planar curves, these methods have been expanded to\nhigher dimensional curves, surfaces, activities, character motions and many\nother objects. In this paper, we develop a framework for shape analysis of\ncurves in Lie groups for problems of computer animations. In particular, we\nwill use these methods to find cyclic approximations of non-cyclic character\nanimations and interpolate between existing animations to generate new ones. \n\n"}
{"id": "1506.01361", "contents": "Title: A finite element implementation of surface elasticity at finite strains\n  using the deal.II library Abstract: The potentially significant role of the surface of an elastic body in the\noverall response of the continuum can be described using the mature theory of\nsurface elasticity. The objective of this contribution is to detail the finite\nelement approximation of the underlying governing equations (both in the volume\nand on its surface) and their solution using the open-source finite element\nlibrary deal.II. The fully-nonlinear (geometric and material) setting is\nconsidered. The nonlinear problem is solved using a Newton--Raphson procedure\nwherein the tangent contributions from the volume and surface are computed\nexactly. The finite element formulation is implemented within the total\nLagrangian framework and a Bubnov-Galerkin spatial discretization of the volume\nand the surface employed. The surface is assumed material. A map between the\ndegrees of freedom on the surface and on the boundary of the volume is used to\nallocate the contribution from the surface to the global system matrix and\nresidual vector. The deal.II library greatly facilitates the computation of the\nvarious surface operators, allowing the numerical implementation to closely\nmatch the theory developed in a companion paper. Key features of the theory and\nthe numerical implementation are elucidated using a series of benchmark example\nproblems. The full, documented source code is provided. \n\n"}
{"id": "1506.01460", "contents": "Title: Inverse transport problems in quantitative PAT for molecular imaging Abstract: Fluorescence photoacoustic tomography (fPAT) is a molecular imaging modality\nthat combines photoacoustic tomography (PAT) with fluorescence imaging to\nobtain high-resolution imaging of fluorescence distributions inside\nheterogeneous media. The objective of this work is to study inverse problems in\nthe quantitative step of fPAT where we intend to reconstruct physical\ncoefficients in a coupled system of radiative transport equations using\ninternal data recovered from ultrasound measurements. We derive uniqueness and\nstability results on the inverse problems and develop some efficient algorithms\nfor image reconstructions. Numerical simulations based on synthetic data are\npresented to validate the theoretical analysis. The results we present here\ncomplement these in [Ren-Zhao, SIAM J. Imag. Sci., 2013] on the same problem\nbut in the diffusive regime. \n\n"}
{"id": "1506.02285", "contents": "Title: Fast Approximate Computations with Cauchy Matrices and Polynomials Abstract: Multipoint polynomial evaluation and interpolation are fundamental for modern\nsymbolic and numerical computing. The known algorithms solve both problems over\nany field of constants in nearly linear arithmetic time, but the cost grows to\nquadratic for numerical solution. We fix this discrepancy: our new numerical\nalgorithms run in nearly linear arithmetic time. At first we restate our goals\nas the multiplication of an n-by-n Vandermonde matrix by a vector and the\nsolution of a Vandermonde linear system of n equations. Then we transform the\nmatrix into a Cauchy structured matrix with some special features. By\nexploiting them, we approximate the matrix by a generalized hierarchically\nsemiseparable matrix, which is a structured matrix of a different class.\nFinally we accelerate our solution to the original problems by applying Fast\nMultipole Method to the latter matrix. Our resulting numerical algorithms run\nin nearly optimal arithmetic time when they perform the above fundamental\ncomputations with polynomials, Vandermonde matrices, transposed Vandermonde\nmatrices, and a large class of Cauchy and Cauchy-like matrices. Some of our\ntechniques may be of independent interest. \n\n"}
{"id": "1506.03147", "contents": "Title: Continuation of Point Clouds via Persistence Diagrams Abstract: In this paper, we present a mathematical and algorithmic framework for the\ncontinuation of point clouds by persistence diagrams. A key property used in\nthe method is that the persistence map, which assigns a persistence diagram to\na point cloud, is differentiable. This allows us to apply the Newton-Raphson\ncontinuation method in this setting. Given an original point cloud $P$, its\npersistence diagram $D$, and a target persistence diagram $D'$, we gradually\nmove from $D$ to $D'$, by successively computing intermediate point clouds\nuntil we finally find a point cloud $P'$ having $D'$ as its persistence\ndiagram. Our method can be applied to a wide variety of situations in\ntopological data analysis where it is necessary to solve an inverse problem,\nfrom persistence diagrams to point cloud data. \n\n"}
{"id": "1506.03606", "contents": "Title: A convergent point integral method for isotropic elliptic equations on\n  point cloud Abstract: In this paper, we propose a numerical method to solve isotropic elliptic\nequations on point cloud by generalizing the point integral method. The idea of\nthe point integral method is to approximate the differential operators by\nintegral operators and discretize the corresponding integral equation on point\ncloud. The key step is to get the integral approximation. In this paper, with\nproper kernel function, we get an integral approximation for the elliptic\noperators with isotropic coefficients. Moreover, the integral approximation has\nbeen proved to keep the coercivity of the original elliptic operator. The\nconvergence of the point integral method is also proved. \n\n"}
{"id": "1506.04565", "contents": "Title: Optimal Transportation Theory with Repulsive Costs Abstract: This paper intents to present the state of art and recent developments of the\noptimal transportation theory with many marginals for a class of repulsive cost\nfunctions. We introduce some aspects of the Density Functional Theory (DFT)\nfrom a mathematical point of view, and revisit the theory of optimal transport\nfrom its perspective. Moreover, in the last three sections, we describe some\nrecent and new theoretical and numerical results obtained for the Coulomb cost,\nthe repulsive harmonic cost and the determinant cost. \n\n"}
{"id": "1506.05655", "contents": "Title: Diffuse Interface Methods for Inverse Problems: Case Study for an\n  Elliptic Cauchy Problem Abstract: Many inverse problems have to deal with complex, evolving and often not\nexactly known geometries, e.g. as domains of forward problems modeled by\npartial differential equations. This makes it desirable to use methods which\nare robust with respect to perturbed or not well resolved domains, and which\nallow for efficient discretizations not resolving any fine detail of those\ngeometries. For forward problems in partial differential equations methods\nbased on diffuse interface representations gained strong attention in the last\nyears, but so far they have not been considered systematically for inverse\nproblems. In this work we introduce a diffuse domain method as a tool for the\nsolution of variational inverse problems. As a particular example we study ECG\ninversion in further detail. ECG inversion is a linear inverse source problem\nwith boundary measurements governed by an anisotropic diffusion equation, which\nnaturally cries for solutions under changing geometries, namely the beating\nheart.\n  We formulate a regularization strategy using Tikhonov regularization and,\nusing standard source conditions, we prove convergence rates. A special\nproperty of our approach is that not only operator perturbations are introduced\nby the diffuse domain method, but more important we have to deal with\ntopologies which depend on a parameter $\\eps$ in the diffuse domain method,\ni.e. we have to deal with $\\eps$-dependent forward operators and\n$\\eps$-dependent norms. In particular the appropriate function spaces for the\nunknown and the data depend on $\\eps$. This prevents to apply some standard\nconvergence techniques for inverse problems, in particular interpreting the\nperturbations as data errors in the original problem does not yield suitable\nresults. We consequently develop a novel approach based on saddle-point\nproblems. \n\n"}
{"id": "1506.05957", "contents": "Title: Inexact Krylov iterations and relaxation strategies with fast-multipole\n  boundary element method Abstract: Boundary element methods produce dense linear systems that can be accelerated\nvia multipole expansions. Solved with Krylov methods, this implies computing\nthe matrix-vector products within each iteration with some error, at an\naccuracy controlled by the order of the expansion, $p$. We take advantage of a\nunique property of Krylov iterations that allow lower accuracy of the\nmatrix-vector products as convergence proceeds, and propose a relaxation\nstrategy based on progressively decreasing $p$. In extensive numerical tests of\nthe relaxed Krylov iterations, we obtained speed-ups of between $2.1\\times$ and\n$3.3\\times$ for Laplace problems and between $1.7\\times$ and $4.0\\times$ for\nStokes problems. We include an application to Stokes flow around red blood\ncells, computing with up to 64 cells and problem size up to 131k boundary\nelements and nearly 400k unknowns. The study was done with an in-house\nmulti-threaded C++ code, on a hexa-core CPU. The code is available on its\nversion-control repository,\n\\href{https://github.com/barbagroup/fmm-bem-relaxed}{https://github.com/barbagroup/fmm-bem-relaxed}. \n\n"}
{"id": "1506.06785", "contents": "Title: A topology-motivated mixed finite element method for dynamic response of\n  porous media Abstract: In this paper, we propose a numerical method for computing solutions to\nBiot's fully dynamic model of incompressible saturated porous media\n[Biot;1956]. Our spatial discretization scheme is based on the three-field\nformulation (u-w-p) and the coupling of a lowest order Raviart-Thomas mixed\nelement [Raviart,Thomas;1977] for fluid variable fields (w, p ) and a nodal\nGalerkin finite element for skeleton variable field (u). These mixed spaces are\nconstructed based on the natural topology of the variables; hence, are\nphysically compatible and able to exactly model the kind of continuity which is\nexpected. The method automatically satisfies the well known LBB (inf-sup)\nstability condition and avoids locking that usually occurs in the numerical\ncomputations in the incompressible limit and very low hydraulic conductivity.\nIn contrast to the majority of approaches, our three-field formulation can\nfully capture dynamic behavior of porous media even in high frequency loading\nphenomena with considerable fluid acceleration such as liquefaction and\nbiomechanics of porous tissues under rapid external loading. Moreover, we\naddress the importance of consistent initial conditions for poroelasticity\nequations with the incompressibility constraint, which represent a system of\ndifferential algebraic equations. The energy balance equation is derived for\nthe full porous medium and used to assess the stability and accuracy of our\ntime integration. To highlight the capabilities of our method, a variety of\nnumerical studies are provided including verification with analytical and\nboundary element solutions, wave propagation analyses, hydraulic conductivity\neffects on damping and frequency content, energy balance analyses, mass lumping\nconsiderations, effects of mesh pattern and size, and stability analyses. We\nalso explain some discrepancies commonly found in dynamic poroelasticity\nresults in the literature. \n\n"}
{"id": "1506.08449", "contents": "Title: Smoothed corners and scattered waves Abstract: We introduce an arbitrary order, computationally efficient method to smooth\ncorners on curves in the plane, as well as edges and vertices on surfaces in\n$\\mathbb R^3$. The method is local, only modifying the original surface in a\nneighborhood of the geometric singularity, and preserves desirable features\nlike convexity and symmetry. The smoothness of the final surface is an explicit\nparameter in the method, and the bandlimit of the smoothed surface is\nproportional to its smoothness. Several numerical examples are provided in the\ncontext of acoustic scattering. In particular, we compare scattered fields from\nsmoothed geometries in two dimensions with those from polygonal domains. We\nobserve that significant reductions in computational cost can be obtained if\nmerely approximate solutions are desired in the near- or far-field. Provided\nthat it is sub-wavelength, the error of the scattered field is proportional to\nthe size of the geometry that is modified. \n\n"}
{"id": "1507.00113", "contents": "Title: Multiscale model reduction for shale gas transport in fractured media Abstract: In this paper, we develop a multiscale model reduction technique that\ndescribes shale gas transport in fractured media. Due to the pore-scale\nheterogeneities and processes, we use upscaled models to describe the matrix.\nWe follow our previous work \\cite{aes14}, where we derived an upscaled model in\nthe form of generalized nonlinear diffusion model to describe the effects of\nkerogen. To model the interaction between the matrix and the fractures, we use\nGeneralized Multiscale Finite Element Method. In this approach, the matrix and\nthe fracture interaction is modeled via local multiscale basis functions. We\ndeveloped the GMsFEM and applied for linear flows with horizontal or vertical\nfracture orientations on a Cartesian fine grid. In this paper, we consider\narbitrary fracture orientations and use triangular fine grid and developed\nGMsFEM for nonlinear flows. Moreover, we develop online basis function\nstrategies to adaptively improve the convergence. The number of multiscale\nbasis functions in each coarse region represents the degrees of freedom needed\nto achieve a certain error threshold. Our approach is adaptive in a sense that\nthe multiscale basis functions can be added in the regions of interest.\nNumerical results for two-dimensional problem are presented to demonstrate the\nefficiency of proposed approach. \n\n"}
{"id": "1507.01649", "contents": "Title: Efficient Computation of Limit Spectra of Sample Covariance Matrices Abstract: Consider an $n \\times p$ data matrix $X$ whose rows are independently sampled\nfrom a population with covariance $\\Sigma$. When $n,p$ are both large, the\neigenvalues of the sample covariance matrix are substantially different from\nthose of the true covariance. Asymptotically, as $n,p \\to \\infty$ with $p/n \\to\n\\gamma$, there is a deterministic mapping from the population spectral\ndistribution (PSD) to the empirical spectral distribution (ESD) of the\neigenvalues. The mapping is characterized by a fixed-point equation for the\nStieltjes transform.\n  We propose a new method to compute numerically the output ESD from an\narbitrary input PSD. Our method, called Spectrode, finds the support and the\ndensity of the ESD to high precision; we prove this for finite discrete\ndistributions. In computational experiments it outperforms existing methods by\nseveral orders of magnitude in speed and accuracy. We apply Spectrode to\ncompute expectations and contour integrals of the ESD. These quantities are\noften central in applications of random matrix theory (RMT).\n  We illustrate that Spectrode is directly useful in statistical problems, such\nas estimation and hypothesis testing for covariance matrices. Our proposal may\nmake it more convenient to use asymptotic RMT in aspects of high-dimensional\ndata analysis. \n\n"}
{"id": "1507.01711", "contents": "Title: Quadratic Convergence of Levenberg-Marquardt Method for Elliptic and\n  Parabolic Inverse Robin Problems Abstract: We study the Levenberg-Marquardt (L-M) method for solving the highly\nnonlinear and ill-posed inverse problem of identifying the Robin coefficients\nin elliptic and parabolic systems. The L-M method transforms the Tikhonov\nregularized nonlinear non-convex minimizations into convex minimizations. And\nthe quadratic convergence of the L-M method is rigorously established for the\nnonlinear elliptic and parabolic inverse problems for the first time, under a\nsimple novel adaptive strategy for selecting regularization parameters during\nthe L-M iteration. Then the surrogate functional approach is adopted to solve\nthe strongly ill-conditioned convex minimizations, resulting in an explicit\nsolution of the minimisation at each L-M iteration for both the elliptic and\nparabolic cases. Numerical experiments are provided to demonstrate the accuracy\nand efficiency of the methods. \n\n"}
{"id": "1507.01752", "contents": "Title: Interior Penalty Mixed Finite Element Methods of Any Order in Any\n  Dimension for Linear Elasticity with Strongly Symmetric Stress Tensor Abstract: We propose two classes of mixed finite elements for linear elasticity of any\norder, with interior penalty for nonconforming symmetric stress approximation.\nOne key point of our method is to introduce some appropriate nonconforming\nface-bubble spaces based on the local decomposition of discrete symmetric\ntensors, with which the stability can be easily established. We prove the\noptimal error estimate for both displacement and stress by adding an interior\npenalty term. The elements are easy to be implemented thanks to the explicit\nformulations of its basis functions. Moreover, the methods can be applied to\narbitrary simplicial grids for any spatial dimension in a unified fashion.\nNumerical tests for both 2D and 3D are provided to validate our theoretical\nresults. \n\n"}
{"id": "1507.02067", "contents": "Title: On the size of the largest empty box amidst a point set Abstract: The problem of finding the largest empty axis-parallel box amidst a point\nconfiguration is a classical problem in computational geometry. It is known\nthat the volume of the largest empty box is of asymptotic order $1/n$ for\n$n\\to\\infty$ and fixed dimension $d$. However, it is natural to assume that the\nvolume of the largest empty box increases as $d$ gets larger. In the present\npaper we prove that this actually is the case: for every set of $n$ points in\n$[0, 1]^d$ there exists an empty box of volume at least $c_d n^{-1}$ , where\n$c_d \\to \\infty$ as $d\\to \\infty$. More precisely, $c_d$ is at least of order\nroughly $\\log d$. \n\n"}
{"id": "1507.04008", "contents": "Title: Neumann-Neumann Waveform Relaxation Algorithm in Multiple subdomains for\n  Hyperbolic Problems in 1D and 2D Abstract: We present a Waveform Relaxation (WR) version of the Neumann-Neumann\nalgorithm for the wave equation in space-time. The method is based on a\nnon-overlapping spatial domain decomposition, and the iteration involves\nsubdomain solves in space-time with corresponding interface condition, followed\nby a correction step. Using a Fourier-Laplace transform argument, for a\nparticular relaxation parameter, we prove convergence of the algorithm in a\nfinite number of steps for finite time intervals. The number of steps depends\non the size of the subdomains and the time window length on which the algorithm\nis employed. We illustrate the performance of the algorithm with numerical\nresults, followed by a comparison with classical and optimized Schwarz WR\nmethods. \n\n"}
{"id": "1507.04011", "contents": "Title: Dirichlet-Neumann Waveform Relaxation Method for the 1D and 2D Heat and\n  Wave Equations in Multiple subdomains Abstract: We present a Waveform Relaxation (WR) version of the Dirichlet-Neumann\nalgorithm, formulated specially for multiple subdomains splitting for general\nparabolic and hyperbolic problems. This method is based on a non-overlapping\nspatial domain decomposition, and the iteration involves subdomain solves in\nspace-time with corresponding interface condition, and finally organize an\nexchange of information between neighboring subdomains. Using a Fourier-Laplace\ntransform argument, for a particular relaxation parameter, we present\nconvergence analysis of the algorithm for the heat and wave equations. We prove\nsuperlinear convergence for finite time window in case of the heat equation,\nand finite step convergence for the wave equation. The convergence behavior\nhowever depends on the size of the subdomains and the time window length on\nwhich the algorithm is employed. We illustrate the performance of the algorithm\nwith numerical results, and show a comparison with classical and optimized\nSchwarz WR methods. \n\n"}
{"id": "1507.04602", "contents": "Title: Convergence analysis of the rectangular Morley element scheme for second\n  order problem in arbitrary dimensions Abstract: In this paper, we present the convergence analysis of the rectangular Morley\nelement scheme utilised on the second order problem in arbitrary dimensions.\nSpecifically, we prove that the convergence of the scheme is of\n$\\mathcal{O}(h)$ order in energy norm and of $\\mathcal{O}(h^2)$ order in $L^2$\nnorm on general $d$-rectangular grids. Moreover, when the grid is uniform, the\nconvergence rate can be of $\\mathcal{O}(h^2)$ order in energy norm, and the\nconvergence rate in $L^2$ norm is still of $\\mathcal{O}(h^2)$ order, which can\nnot be improved. Numerical examples are presented to demonstrate our\ntheoretical results. \n\n"}
{"id": "1507.04986", "contents": "Title: Fractional discrete Laplacian versus discretized fractional Laplacian Abstract: We define and study some properties of the fractional powers of the discrete\nLaplacian $$(-\\Delta_h)^s,\\quad\\hbox{on}~\\mathbb{Z}_h = h\\mathbb{Z},$$ for\n$h>0$ and $0<s<1$. A comparison between our fractional discrete Laplacian and\nthe \\textit{discretized} continuous fractional Laplacian as $h\\to0$ is carried\nout. We get estimates in $\\ell^\\infty$ for the error of the approximation in\nterms of $h$ under minimal regularity assumptions. Moreover, we provide a\npointwise formula with an explicit kernel and deduce H\\\"older estimates for\n$(-\\Delta_h)^s$. A study of the negative powers (or discrete fractional\nintegral) $(-\\Delta_h)^{-s}$ is also sketched. Our analysis is mainly performed\nin dimension one. Nevertheless, we show certain asymptotic estimates for the\nkernel in dimension two that can be extended to higher dimensions. Some\nexamples are plotted to illustrate the comparison in both one and two\ndimensions. \n\n"}
{"id": "1507.05063", "contents": "Title: An extrapolation cascadic multigrid method combined with a fourth order\n  compact scheme for 3D poisson equation Abstract: In this paper, we develop an EXCMG method to solve the three-dimensional\nPoisson equation on rectangular domains by using the compact finite difference\n(FD) method with unequal meshsizes in different coordinate directions. The\nresulting linear system from compact FD discretization is solved by the\nconjugate gradient (CG) method with a relative residual stopping criterion. By\ncombining the Richardson extrapolation and tri-quartic Lagrange interpolation\nfor the numerical solutions from two-level of grids (current and previous\ngrids), we are able to produce an extremely accurate approximation of the\nactual numerical solution on the next finer grid, which can greatly reduce the\nnumber of relaxation sweeps needed. Additionally, a simple method based on the\nmidpoint extrapolation formula is used for the fourth-order FD solutions on\ntwo-level of grids to achieve sixth-order accuracy on the entire fine grid\ncheaply and directly. The gradient of the numerical solution can also be easily\nobtained through solving a series of tridiagonal linear systems resulting from\nthe fourth-order compact FD discretizations. Numerical results show that our\nEXCMG method is much more efficient than the classical V-cycle and W-cycle\nmultigrid methods. Moreover, only few CG iterations are required on the finest\ngrid to achieve full fourth-order accuracy in both the $L^2$-norm and\n$L^{\\infty}$-norm for the solution and its gradient when the exact solution\nbelongs to $C^6$. Finally, numerical result shows that our EXCMG method is\nstill effective when the exact solution has a lower regularity, which widens\nthe scope of applicability of our EXCMG method. \n\n"}
{"id": "1507.05585", "contents": "Title: On Fej\\'er monotone sequences and nonexpansive mappings Abstract: The notion of Fej\\'er monotonicity has proven to be a fruitful concept in\nfixed point theory and optimization. In this paper, we present new conditions\nsufficient for convergence of Fej\\'er monotone sequences and we also provide\napplications to the study of nonexpansive mappings. Various examples illustrate\nour results. \n\n"}
{"id": "1507.05925", "contents": "Title: Integral equation methods for elastance and mobility problems in two\n  dimensions Abstract: We present new integral representations in two dimensions for the elastance\nproblem in electrostatics and the mobility problem in Stokes flow. These\nrepresentations lead to resonance-free Fredholm integral equations of the\nsecond kind and well conditioned linear systems upon discretization. By\ncoupling our integral equations with high order quadrature and fast multipole\nacceleration, large-scale problems can be solved with only modest computing\nresources. We also discuss some applications of these boundary value problems\nin applied physics. \n\n"}
{"id": "1507.06709", "contents": "Title: Centrosymmetric Matrices in the Sinc Collocation Method for\n  Sturm-Liouville Problems Abstract: Recently, we used the Sinc collocation method with the double exponential\ntransformation to compute eigenvalues for singular Sturm-Liouville problems. In\nthis work, we show that the computation complexity of the eigenvalues of such a\ndifferential eigenvalue problem can be considerably reduced when its operator\ncommutes with the parity operator. In this case, the matrices resulting from\nthe Sinc collocation method are centrosymmetric. Utilizing well known\nproperties of centrosymmetric matrices, we transform the problem of solving one\nlarge eigensystem into solving two smaller eigensystems. We show that only\n1/(N+1) of all components need to be computed and stored in order to obtain all\neigenvalues, where (2N+1) corresponds to the dimension of the eigensystem. We\napplied our result to the Schr\\\"odinger equation with the anharmonic potential\nand the numerical results section clearly illustrates the substantial gain in\nefficiency and accuracy when using the proposed algorithm. \n\n"}
{"id": "1507.08243", "contents": "Title: Anisotropic mesh quality measures and adaptation for polygonal meshes Abstract: Anisotropic mesh quality measures and anisotropic mesh adaptation are studied\nfor polygonal meshes. Three sets of alignment and equidistribution measures are\ndeveloped, one based on least squares fitting, one based on generalized\nbarycentric mapping, and the other based on singular value decomposition of\nedge matrices. Numerical tests show that all three sets of mesh quality\nmeasures provide good measurements for the quality of polygonal meshes under\ngiven metrics. Based on one of these sets of quality measures and using a\nmoving mesh partial differential equation, an anisotropic adaptive polygonal\nmesh method is constructed for the numerical solution of second order elliptic\nequations. Numerical examples are presented to demonstrate the effectiveness of\nthe method. \n\n"}
{"id": "1507.08970", "contents": "Title: A fractional Laplace equation: regularity of solutions and Finite\n  Element approximations Abstract: This paper deals with the \\emph{integral} version of the Dirichlet\nhomogeneous fractional Laplace equation. For this problem weighted and\nfractional Sobolev a priori estimates are provided in terms of the H\\\"older\nregularity of the data. By relying on these results, optimal order of\nconvergence for the standard linear finite element method is proved for\nquasi-uniform as well as graded meshes. Some numerical examples are given\nshowing results in agreement with the theoretical predictions. \n\n"}
{"id": "1508.01166", "contents": "Title: Discrete exterior calculus discretization of incompressible\n  Navier-Stokes equations over surface simplicial meshes Abstract: A conservative discretization of incompressible Navier-Stokes equations is\ndeveloped based on discrete exterior calculus (DEC). A distinguishing feature\nof our method is the use of an algebraic discretization of the interior product\noperator and a combinatorial discretization of the wedge product. The governing\nequations are first rewritten using the exterior calculus notation, replacing\nvector calculus differential operators by the exterior derivative, Hodge star\nand wedge product operators. The discretization is then carried out by\nsubstituting with the corresponding discrete operators based on the DEC\nframework. Numerical experiments for flows over surfaces reveal a second order\naccuracy for the developed scheme when using structured-triangular meshes, and\nfirst order accuracy for otherwise unstructured meshes. By construction, the\nmethod is conservative in that both mass and vorticity are conserved up to\nmachine precision. The relative error in kinetic energy for inviscid flow test\ncases converges in a second order fashion with both the mesh size and the time\nstep. \n\n"}
{"id": "1508.02138", "contents": "Title: A Generalized Multiscale Finite Element Method for Poroelasticity\n  Problems II: Nonlinear Coupling Abstract: In this paper, we consider the numerical solution of some nonlinear\nporoelasticity problems that are of Biot type and develop a general algorithm\nfor solving nonlinear coupled systems. We discuss the difficulties associated\nwith flow and mechanics in heterogenous media with nonlinear coupling. The\ncentral issue being how to handle the nonlinearities and the multiscale scale\nnature of the media. To compute an efficient numerical solution we develop and\nimplement a Generalized Multiscale Finite Element Method (GMsFEM) that solves\nnonlinear problems on a coarse grid by constructing local multiscale basis\nfunctions and treating part of the nonlinearity locally as a parametric value.\nAfter linearization with a Picard Iteration, the procedure begins with\nconstruction of multiscale bases for both displacement and pressure in each\ncoarse block by treating the staggered nonlinearity as a parametric value.\nUsing a snapshot space and local spectral problems, we construct an offline\nbasis of reduced dimension. From here an online, parametric dependent, space is\nconstructed. Finally, after multiplying by a multiscale partitions of unity,\nthe multiscale basis is constructed and the coarse grid problem then can be\nsolved for arbitrary forcing and boundary conditions. We implement this\nalgorithm on a geometry with a linear and nonlinear pressure dependent\npermeability field and compute error between the multiscale solution with the\nfine-scale solutions. \n\n"}
{"id": "1508.02363", "contents": "Title: Spectral approach to D-bar problems Abstract: We present the first numerical approach to D-bar problems having spectral\nconvergence for real analytic rapidly decreasing potentials. The proposed\nmethod starts from a formulation of the problem in terms of an integral\nequation which is solved with Fourier techniques. The singular integrand is\nregularized analytically. The resulting integral equation is approximated via a\ndiscrete system which is solved with Krylov methods. As an example, the D-bar\nproblem for the Davey-Stewartson II equations is solved. The result is used to\ntest direct numerical solutions of the PDE. \n\n"}
{"id": "1508.03105", "contents": "Title: Method of lines transpose: High order L-stable O(N) schemes for\n  parabolic equations using successive convolution Abstract: We present a new solver for nonlinear parabolic problems that is L-stable and\nachieves high order accuracy in space and time. The solver is built by first\nconstructing a single-dimensional heat equation solver that uses fast O(N)\nconvolution. This fundamental solver has arbitrary order of accuracy in space,\nand is based on the use of the Green's function to invert a modified Helmholtz\nequation. Higher orders of accuracy in time are then constructed through a\nnovel technique known as successive convolution (or resolvent expansions).\nThese resolvent expansions facilitate our proofs of stability and convergence,\nand permit us to construct schemes that have provable stiff decay. The\nmulti-dimensional solver is built by repeated application of dimensionally\nsplit independent fundamental solvers. Finally, we solve nonlinear parabolic\nproblems by using the integrating factor method, where we apply the basic\nscheme to invert linear terms (that look like a heat equation), and make use of\nHermite-Birkhoff interpolants to integrate the remaining nonlinear terms. Our\nsolver is applied to several linear and nonlinear equations including heat,\nAllen-Cahn, and the Fitzhugh-Nagumo system of equations in one and two\ndimensions. \n\n"}
{"id": "1508.03280", "contents": "Title: Computing Spectra -- On the Solvability Complexity Index Hierarchy and\n  Towers of Algorithms Abstract: This paper establishes some of the fundamental barriers in the theory of\ncomputations and finally settles the long-standing computational spectral\nproblem. That is to determine the existence of algorithms that can compute\nspectra $\\mathrm{sp}(A)$ of classes of bounded operators $A = \\{a_{ij}\\}_{i,j\n\\in \\mathbb{N}} \\in \\mathcal{B}(l^2(\\mathbb{N}))$, given the matrix elements\n$\\{a_{ij}\\}_{i,j \\in \\mathbb{N}}$, that are sharp in the sense that they\nachieve the boundary of what a digital computer can achieve. Similarly, for a\nSchr\\\"odinger operator $H = -\\Delta+V$, determine the existence of algorithms\nthat can compute the spectrum $\\mathrm{sp}(H)$ given point samples of the\npotential function $V$. In order to solve these problems, we establish the\nSolvability Complexity Index (SCI) hierarchy and provide a collection of new\nalgorithms that allow for problems that were previously out of reach. The SCI\nis the smallest number of limits needed in the computation, yielding a\nclassification hierarchy for all types of problems in computational mathematics\nthat determines the boundaries of what computers can achieve in scientific\ncomputing. In addition, the SCI hierarchy provides classifications of\ncomputational problems that can be used in computer-assisted proofs. The SCI\nhierarchy captures many key computational issues in the history of mathematics\nincluding the insolvability of the quintic, Smale's problem on the existence of\niterative generally convergent algorithm for polynomial root finding, the\ncomputational spectral problem, inverse problems, optimisation etc. \n\n"}
{"id": "1508.04874", "contents": "Title: A Faster Cutting Plane Method and its Implications for Combinatorial and\n  Convex Optimization Abstract: We improve upon the running time for finding a point in a convex set given a\nseparation oracle. In particular, given a separation oracle for a convex set\n$K\\subset \\mathbb{R}^n$ contained in a box of radius $R$, we show how to either\nfind a point in $K$ or prove that $K$ does not contain a ball of radius\n$\\epsilon$ using an expected $O(n\\log(nR/\\epsilon))$ oracle evaluations and\nadditional time $O(n^3\\log^{O(1)}(nR/\\epsilon))$. This matches the oracle\ncomplexity and improves upon the $O(n^{\\omega+1}\\log(nR/\\epsilon))$ additional\ntime of the previous fastest algorithm achieved over 25 years ago by Vaidya for\nthe current matrix multiplication constant $\\omega<2.373$ when\n$R/\\epsilon=n^{O(1)}$.\n  Using a mix of standard reductions and new techniques, our algorithm yields\nimproved runtimes for solving classic problems in continuous and combinatorial\noptimization:\n  Submodular Minimization: Our weakly and strongly polynomial time algorithms\nhave runtimes of $O(n^2\\log nM\\cdot\\text{EO}+n^3\\log^{O(1)}nM)$ and\n$O(n^3\\log^2 n\\cdot\\text{EO}+n^4\\log^{O(1)}n)$, improving upon the previous\nbest of $O((n^4\\text{EO}+n^5)\\log M)$ and $O(n^5\\text{EO}+n^6)$.\n  Matroid Intersection: Our runtimes are $O(nrT_{\\text{rank}}\\log n\\log (nM)\n+n^3\\log^{O(1)}(nM))$ and $O(n^2\\log (nM) T_{\\text{ind}}+n^3 \\log^{O(1)}\n(nM))$, achieving the first quadratic bound on the query complexity for the\nindependence and rank oracles. In the unweighted case, this is the first\nimprovement since 1986 for independence oracle.\n  Submodular Flow: Our runtime is $O(n^2\\log\nnCU\\cdot\\text{EO}+n^3\\log^{O(1)}nCU)$, improving upon the previous bests from\n15 years ago roughly by a factor of $O(n^4)$.\n  Semidefinite Programming: Our runtime is $\\tilde{O}(n(n^2+m^{\\omega}+S))$,\nimproving upon the previous best of $\\tilde{O}(n(n^{\\omega}+m^{\\omega}+S))$ for\nthe regime where the number of nonzeros $S$ is small. \n\n"}
{"id": "1508.05535", "contents": "Title: Localization errors in solving stochastic partial differential equations\n  in the whole space Abstract: Cauchy problems with SPDEs on the whole space are localized to Cauchy\nproblems on a ball of radius $R$. This localization reduces various kinds of\nspatial approximation schemes to finite dimensional problems. The error is\nshown to be exponentially small. As an application, a numerical scheme is\npresented which combines the localization and the space and time\ndiscretisation, and thus is fully implementable. \n\n"}
{"id": "1508.05695", "contents": "Title: A Hybridized Formulation for the Weak Galerkin Mixed Finite Element\n  Method Abstract: This paper presents a hybridized formulation for the weak Galerkin mixed\nfinite element method (WG-MFEM) which was introduced and analyzed for second\norder elliptic equations. The WG-MFEM method was designed by using\ndiscontinuous piecewise polynomials on finite element partitions consisting of\npolygonal or polyhedral elements of arbitrary shape. The key to WG-MFEM is the\nuse of a discrete weak divergence operator which is defined and computed by\nsolving inexpensive problems locally on each element. The hybridized\nformulation of this paper leads to a significantly reduced system of linear\nequations involving only the unknowns arising from the Lagrange multiplier in\nhybridization. Optimal-order error estimates are derived for the hybridized\nWG-MFEM approximations. Some numerical results are reported to confirm the\ntheory and a superconvergence for the Lagrange multiplier. \n\n"}
{"id": "1508.06445", "contents": "Title: An Efficient Implementation of Brezzi-Douglas-Marini (BDM) Mixed Finite\n  Element Method in MATLAB Abstract: In this paper, a MATLAB package bdm_mfem for a linear Brezzi-Douglas- Marini\n(BDM) mixed finite element method is provided for the numerical solution of\nelliptic diffusion problems with mixed boundary conditions on unstructured\ngrids. BDM basis functions defined by standard barycentric coordinates are used\nin the paper. Local and global edge ordering are treated carefully. MATLAB\nbuild-in functions and vectorizations are used to guarantee the erectness of\nthe programs. The package is simple and efficient, and can be easily adapted\nfor more complicated edge-based finite element spaces. A numerical example is\nprovided to illustrate the usage of the package. \n\n"}
{"id": "1508.07743", "contents": "Title: On the Poincar\\'e's generating function and the symplectic mid-point\n  rule Abstract: The use of Liouvillian forms to obtain symplectic maps for constructing\nnumerical integrators is a natural alternative to the method of generating\nfunctions, and provides a deeper understanding of the geometry of this\nprocedure. Using Liouvillian forms we study the generating function introduced\nby Poincar\\'e (1899) and its associated symplectic map. We show that in this\nframework, Poincar\\'e's generating function does not correspond to the\nsymplectic mid-point rule, but to the identity map. We give an interpretation\nof this result based on the original framework constructed by Poincar\\'e. \n\n"}
{"id": "1509.00093", "contents": "Title: ASHEE: a compressible, equilibrium-Eulerian model for volcanic ash\n  plumes Abstract: A new fluid-dynamic model is developed to numerically simulate the\nnon-equilibrium dynamics of polydisperse gas-particle mixtures forming volcanic\nplumes. Starting from the three-dimensional N-phase Eulerian transport\nequations for a mixture of gases and solid particles, we adopt an asymptotic\nexpansion strategy to derive a compressible version of the first-order\nnon-equilibrium model, valid for low concentration regimes and small particles\nStokes $St<0.2$. When $St < 0.001$ the model reduces to the dusty-gas one. The\nnew model is significantly faster than the Eulerian model while retaining the\ncapability to describe gas-particle non-equilibrium. Direct numerical\nsimulation accurately reproduce the dynamics of isotropic turbulence in\nsubsonic regime. For gas-particle mixtures, it describes the main features of\ndensity fluctuations and the preferential concentration of particles by\nturbulence, verifying the model reliability and suitability for the simulation\nof high-Reynolds number and high-temperature regimes. On the other hand,\nLarge-Eddy Numerical Simulations of forced plumes are able to reproduce their\nobserved averaged and instantaneous properties. The self-similar radial profile\nand the development of large-scale structures are reproduced, including the\nrate of entrainment of atmospheric air. Application to the Large-Eddy\nSimulation of the injection of the eruptive mixture in a stratified atmosphere\ndescribes some of important features of turbulent volcanic plumes, including\nair entrainment, buoyancy reversal, and maximum plume height. Coarse particles\npartially decouple from the gas within eddies, modifying the turbulent\nstructure, and preferentially concentrate at the eddy periphery, eventually\nbeing lost from the plume margins due to the gravity. By these mechanisms,\ngas-particle non-equilibrium is able to influence the large-scale behavior of\nvolcanic plumes. \n\n"}
{"id": "1509.00311", "contents": "Title: Alternating Least Squares Tensor Completion in The TT-Format Abstract: We consider the problem of fitting a low rank tensor\n$A\\in\\mathbb{R}^{{\\mathcal I}}$, ${\\mathcal I} = \\{1,\\ldots,n\\}^{d}$, to a\ngiven set of data points $\\{M_i\\in\\mathbb{R}\\mid i\\in P\\}$, $P\\subset{\\mathcal\nI}$.\n  The low rank format under consideration is the hierarchical or TT or MPS\nformat. It is characterized by rank bounds $r$ on certain matricizations of the\ntensor. The number of degrees of freedom is in ${\\cal O}(r^2dn)$.\n  For a fixed rank and mode size $n$ we observe that it is possible to\nreconstruct random (but rank structured) tensors as well as certain discretized\nmultivariate (but rank structured) functions from a number of samples that is\nin ${\\cal O}(\\log N)$ for a tensor having $N=n^d$ entries.\n  We compare an alternating least squares fit (ALS) to an overrelaxation scheme\ninspired by the LMaFit method for matrix completion.\n  Both approaches aim at finding a tensor $A$ that fulfils the first order\noptimality conditions by a nonlinear Gauss-Seidel type solver that consists of\nan alternating fit cycling through the directions $\\mu=1,\\ldots,d$.\n  The least squares fit is of complexity ${\\cal O}(r^4d\\#P)$ per step, whereas\neach step of ADF is in ${\\cal O}(r^2d\\#P)$, albeit with a slightly higher\nnumber of necessary steps.\n  In the numerical experiments we observe robustness of the completion\nalgorithm with respect to noise and good reconstruction capability.\n  Our tests provide evidence that the algorithm is suitable in higher dimension\n($>$10) as well as for moderate ranks.\n  Keywords: MPS, Tensor Completion, Tensor Train, TT, Hierarchical Tucker, HT,\nALS. \n\n"}
{"id": "1509.01236", "contents": "Title: New mapping properties of the Time Domain Electric Field Integral\n  Equation Abstract: We show some improved mapping properties of the Time Domain Electric Field\nIntegral Equation and of its Galerkin semidiscretization in space. We relate\nthe weak distributional framework with a stronger class of solutions using a\ngroup of strongly continuous operators. The stability and error estimates we\nderive are sharper than those in the literature. \n\n"}
{"id": "1509.01513", "contents": "Title: Convergence of a fully discrete variational scheme for a thin-film\n  equation Abstract: This paper is concerned with a rigorous convergence analysis of a fully\ndiscrete Lagrangian scheme for the Hele-Shaw flow, which is the fourth order\nthin-film equation with linear mobility in one space dimension. The\ndiscretization is based on the equation's gradient flow structure in the\n$L^2$-Wasserstein metric. Apart from its Lagrangian character --- which\nguarantees positivity and mass conservation --- the main feature of our\ndiscretization is that it dissipates both the Dirichlet energy and the\nlogarithmic entropy. The interplay between these two dissipations paves the way\nto proving convergence of the discrete approximations to a weak solution in the\ndiscrete-to-continuous limit. Thanks to the time-implicit character of the\nscheme, no CFL-type condition is needed. Numerical experiments illustrate the\npracticability of the scheme. \n\n"}
{"id": "1509.02586", "contents": "Title: Generalized quadrature for solving singular integral equations of Abel\n  type in application to infrared tomography Abstract: We propose the generalized quadrature methods for numerical solution of\nsingular integral equation of Abel type. We overcome the singularity using the\nanalytical calculation of the singular integral expression. The problem of\nsolution of singular integral equation is reduced to nonsingular system of\nlinear algebraic equations without shift meshes techniques employment. We also\npropose generalized quadrature method for solution of Abel equation using the\nsingular integral. Relaxed errors bounds are derived. In order to improve the\naccuracy we use Tikhonov regularization method. We demonstrate the efficiency\nof proposed techniques on infrared tomography problem. Numerical experiments\nshow that it make sense to apply regularization in case of highly noisy sources\nonly. That is due to the fact that singular integral equations enjoy\nselfregularization property. \n\n"}
{"id": "1509.03136", "contents": "Title: MAP Estimators for Piecewise Continuous Inversion Abstract: We study the inverse problem of estimating a field $u$ from data comprising a\nfinite set of nonlinear functionals of $u$, subject to additive noise; we\ndenote this observed data by $y$. Our interest is in the reconstruction of\npiecewise continuous fields in which the discontinuity set is described by a\nfinite number of geometric parameters. Natural applications include groundwater\nflow and electrical impedance tomography. We take a Bayesian approach, placing\na prior distribution on $u$ and determining the conditional distribution on $u$\ngiven the data $y$. It is then natural to study maximum a posterior (MAP)\nestimators. Recently (Dashti et al 2013) it has been shown that MAP estimators\ncan be characterised as minimisers of a generalised Onsager-Machlup functional,\nin the case where the prior measure is a Gaussian random field. We extend this\ntheory to a more general class of prior distributions which allows for\npiecewise continuous fields. Specifically, the prior field is assumed to be\npiecewise Gaussian with random interfaces between the different Gaussians\ndefined by a finite number of parameters. We also make connections with recent\nwork on MAP estimators for linear problems and possibly non-Gaussian priors\n(Helin, Burger 2015) which employs the notion of Fomin derivative.\n  In showing applicability of our theory we focus on the groundwater flow and\nEIT models, though the theory holds more generally. Numerical experiments are\nimplemented for the groundwater flow model, demonstrating the feasibility of\ndetermining MAP estimators for these piecewise continuous models, but also that\nthe geometric formulation can lead to multiple nearby (local) MAP estimators.\nWe relate these MAP estimators to the behaviour of output from MCMC samples of\nthe posterior, obtained using a state-of-the-art function space\nMetropolis-Hastings method. \n\n"}
{"id": "1509.03225", "contents": "Title: Half-space Kinetic Equations with General Boundary Conditions Abstract: We study half-space linear kinetic equations with general boundary conditions\nthat consist of both given incoming data and various type of reflections,\nextending our previous work [LLS14] on half-space equations with incoming\nboundary conditions. As in [LLS14], the main technique is a damping\nadding-removing procedure. We establish the well-posedness of linear (or\nlinearized) half-space equations with general boundary conditions and\nquasi-optimality of the numerical scheme. The numerical method is validated by\nexamples including a two-species transport equation, a multi-frequency\ntransport equation, and the linearized BGK equation in 2D velocity space. \n\n"}
{"id": "1509.04235", "contents": "Title: Asymptotic-preserving Particle-In-Cell methods for the Vlasov-Maxwell\n  system near quasi-neutrality Abstract: In this article, we design Asymptotic-Preserving Particle-In-Cell methods for\nthe Vlasov-Maxwell system in the quasi-neutral limit, this limit being\ncharacterized by a Debye length negligible compared to the space scale of the\nproblem. These methods are consistent discretizations of the Vlasov-Maxwell\nsystem which, in the quasi-neutral limit, remain stable and are consistent with\na quasi-neutral model (in this quasi-neutral model, the electric field is\ncomputed by means of a generalized Ohm law). The derivation of\nAsymptotic-Preserving methods is not straightforward since the quasi-neutral\nmodel is a singular limit of the Vlasov-Maxwell model. The key step is a\nreformulation of the Vlasov-Maxwell system which unifies the two models in a\nsingle set of equations with a smooth transition from one to another. As\ndemonstrated in various and demanding numerical simulations, the\nAsymptotic-Preserving methods are able to treat efficiently both quasi-neutral\nplasmas and non-neutral plasmas, making them particularly well suited for\ncomplex problems involving dense plasmas with localized non-neutral regions. \n\n"}
{"id": "1509.04947", "contents": "Title: Perfect absorption in Schr\\\"odinger-like problems using non-equidistant\n  complex grids Abstract: Two non-equidistant grid implementations of infinite range exterior complex\nscaling are introduced that allow for perfect absorption in the time dependent\nSchr\\\"odinger equation. Finite element discrete variables grid discretizations\nprovide as efficient absorption as the corresponding finite elements basis set\ndiscretizations. This finding is at variance with results reported in\nliterature [L. Tao et al., Phys. Rev. A 48, 063419 (2009)]. For finite\ndifferences, a new class of generalized $Q$-point schemes for non-equidistant\ngrids is derived. Convergence of absorption is exponential $\\sim \\Delta\nx^{Q-1}$ and numerically robust. Local relative errors $\\sim10^{-9}$ are\nachieved in a standard problem of strong-field ionization. \n\n"}
{"id": "1509.05084", "contents": "Title: An Accelerated Dual Proximal Gradient Method for Applications in\n  Viscoplasticity Abstract: We present a very simple and fast algorithm for the numerical solution of\nviscoplastic flow problems without prior regularisation. Compared to the\nwidespread alternating direction method of multipliers (ADMM / ALG2), the new\nmethod features three key advantages: firstly, it accelerates the worst-case\nconvergence rate from $O(1/\\sqrt{k})$ to $O(1/k)$, where $k$ is the iteration\ncounter. Secondly, even for nonlinear constitutive models like those of Casson\nor Herschel-Bulkley, no nonlinear systems of equations have to be solved in the\nsubproblems of the algorithm. Thirdly, there is no need to augment the\nLagrangian, which eliminates the difficulty of choosing a penalty parameter\nheuristically.\n  In this paper, we transform the usual velocity-based formulation of\nviscoplastic flow problems to a dual formulation in terms of the stress. For\nthe numerical solution of this dual problem we apply FISTA, an accelerated\nfirst-order optimisation algorithm from the class of so-called proximal\ngradient methods. Finally, we conduct a series of numerical experiments,\nfocussing on stationary flow in two-dimensional square cavities.\n  Our results confirm that Algorithm FISTA*, the new dual-based FISTA,\noutperforms state-of-the-art algorithms such as ADMM / ALG2 by several orders\nof magnitude. We demonstrate how this speedup can be exploited to identify the\nfree boundary between yielded and unyielded regions with previously unknown\naccuracy. Since the accelerated algorithm relies solely on Stokes-type\nsubproblems and nonlinear function evaluations, existing code based on\naugmented Lagrangians would require only few minor adaptations to obtain an\nimplementation of FISTA*. \n\n"}
{"id": "1509.05705", "contents": "Title: A Computationally Optimal Randomized Proper Orthogonal Decomposition\n  Technique Abstract: In this paper, we consider the model reduction problem of large-scale\nsystems, such as systems obtained through the discretization of partial\ndifferential equations. We propose a computationally optimal randomized proper\northogonal decomposition (RPOD*) technique to obtain the reduced order model by\nperturbing the primal and adjoint system using Gaussian white noise. We show\nthat the computations required by the RPOD* algorithm is orders of magnitude\ncheaper when compared to the balanced proper orthogonal decomposition (BPOD)\nalgorithm and BPOD output projection algorithm while the performance of the\nRPOD* algorithm is much better than BPOD output projection algorithm. It is\noptimal in the sense that a minimal number of snapshots is needed. We also\nrelate the RPOD* algorithm to random projection algorithms. The method is\ntested on two advection-diffusion equations. \n\n"}
{"id": "1509.06627", "contents": "Title: QM/MM methods for crystalline defects. Part 2: Consistent energy and\n  force-mixing Abstract: QM/MM hybrid methods employ accurate quantum (QM) models only in regions of\ninterest (defects) and switch to computationally cheaper interatomic potential\n(MM) models to describe the crystalline bulk.\n  We develop two QM/MM hybrid methods for crystalline defect simulations, an\nenergy-based and a force-based formulation, employing a tight binding QM model.\nBoth methods build on two principles: (i) locality of the QM model; and (ii)\nconstructing the MM model as an explicit and controllable approximation of the\nQM model. This approach enables us to establish explicit convergence rates in\nterms of the size of QM region. \n\n"}
{"id": "1509.06935", "contents": "Title: Shared Memory Pipelined Parareal Abstract: For the parallel-in-time integration method Parareal, pipelining can be used\nto hide some of the cost of the serial correction step and improve its\nefficiency. The paper introduces a basic OpenMP implementation of pipelined\nParareal and compares it to a standard MPI-based variant. Both versions yield\nalmost identical runtimes, but, depending on the compiler, the OpenMP variant\nconsumes about 7% less energy and has a significantly smaller memory footprint.\nHowever, its higher implementation complexity might make it difficult to use in\nlegacy codes and in combination with spatial parallelisation. \n\n"}
{"id": "1509.08166", "contents": "Title: Finite Element Methods for Interface Problems: Robust and Local Optimal\n  A Priori Error Estimates Abstract: For elliptic interface problems in two- and three-dimensions, this paper\nestablishes a priori error estimates for Crouzeix-Raviart nonconforming,\nRaviart-Thomas mixed, and discontinuous Galerkin finite element approximations.\nThese estimates are robust with respect to the diffusion coefficient and\noptimal with respect to local regularity of the solution. Moreover, we obtain\nthese estimates with no assumption on the distribution of the diffusion\ncoefficient. \n\n"}
{"id": "1509.08667", "contents": "Title: LINOEP vectors, spiral of Theodorus, and nonlinear time-invariant system\n  models of mode decomposition Abstract: In this paper, we propose a general method to obtain a set of Linearly\nIndependent Non-Orthogonal yet Energy (square of the norm) Preserving (LINOEP)\nvectors using iterative filtering operation and we refer it as Filter Mode\nDecomposition (FDM). We show that the general energy preserving theorem (EPT),\nwhich is valid for both linearly independent (orthogonal and nonorthogonal) and\nlinearly dependent set of vectors, proposed by Singh P. et al. is a\ngeneralization of the discrete spiral of Theodorus (or square root spiral or\nEinstein spiral or Pythagorean spiral). From the EPT, we obtain the (2D)\ndiscrete spiral of Theodorus and show that the multidimensional discrete\nspirals (e.g. a 3D spiral) can be easily generated using a set of\nmultidimensional energy preserving unit vectors. We also establish that the\nrecently proposed methods (e.g. Empirical Mode Decomposition (EMD),\nSynchrosqueezed Wavelet Transforms (SSWT), Variational Mode Decomposition\n(VMD), Eigenvalue Decomposition (EVD), Fourier Decomposition Method (FDM),\netc.), for nonlinear and nonstationary time series analysis, are nonlinear\ntime-invariant (NTI) system models of filtering. Simulation and numerical\nresults demonstrate the efficacy of LINOEP vectors. \n\n"}
{"id": "1510.00027", "contents": "Title: Robust A Posteriori Error Estimation for Finite Element Approximation to\n  H(curl) Problem Abstract: In this paper, we introduce a novel a posteriori error estimator for the\nconforming finite element approximation to the H(curl) problem with\ninhomogeneous media and with the right-hand side only in L^2. The estimator is\nof the recovery type. Independent with the current approximation to the primary\nvariable (the electric field), an auxiliary variable (the magnetizing field) is\nrecovered in parallel by solving a similar H(curl) problem. An alternate way of\nrecovery is presented as well by localizing the error flux. The estimator is\nthen defined as the sum of the modified element residual and the residual of\nthe constitutive equation defining the auxiliary variable. It is proved that\nthe estimator is approximately equal to the true error in the energy norm\nwithout the quasi-monotonicity assumption. Finally, we present numerical\nresults for two H(curl) interface problems. \n\n"}
{"id": "1510.01190", "contents": "Title: Formulation of discontinuous Galerkin methods for relativistic\n  astrophysics Abstract: The DG algorithm is a powerful method for solving pdes, especially for\nevolution equations in conservation form. Since the algorithm involves\nintegration over volume elements, it is not immediately obvious that it will\ngeneralize easily to arbitrary time-dependent curved spacetimes. We show how to\nformulate the algorithm in such spacetimes for applications in relativistic\nastrophysics. We also show how to formulate the algorithm for equations in\nnon-conservative form, such as Einstein's field equations themselves. We find\ntwo computationally distinct formulations in both cases, one of which has\nseldom been used before for flat space in curvilinear coordinates but which may\nbe more efficient. We also give a new derivation of the ALE algorithm\n(Arbitrary Lagrangian-Eulerian) using 4-vector methods that is much simpler\nthan the usual derivation and explains why the method preserves the\nconservation form of the equations. The various formulations are explored with\nsome simple numerical experiments that also explore the effect of the metric\nidentities on the results. \n\n"}
{"id": "1510.02572", "contents": "Title: A map of contour integral-based eigensolvers for solving generalized\n  eigenvalue problems Abstract: Recently, contour integral-based methods have been actively studied for\nsolving interior eigenvalue problems that find all eigenvalues located in a\ncertain region and their corresponding eigenvectors. In this paper, we\nreconsider the algorithms of the five typical contour integral-based\neigensolvers from the viewpoint of projection methods, and then map the\nrelationships among these methods. From the analysis, we conclude that all\ncontour integral-based eigensolvers can be regarded as projection methods and\ncan be categorized based on their subspace used, the type of projection and the\nproblem to which they are applied implicitly. \n\n"}
{"id": "1510.02646", "contents": "Title: On the stability of DPG formulations of transport equations Abstract: In this paper we formulate and analyze a Discontinuous Petrov Galerkin\nformulation of linear transport equations with variable convection fields. We\nshow that a corresponding {\\em infinite dimensional} mesh-dependent variational\nformulation, in which besides the principal field also its trace on the mesh\nskeleton is an unknown, is uniformly stable with respect to the mesh, where the\ntest space is a certain product space over the underlying domain partition.\n  Our main result states then the following. For piecewise polynomial trial\nspaces of degree $m$, we show under mild assumptions on the convection field\nthat piecewise polynomial test spaces of degree $m+1$ over a refinement of the\nprimal partition with uniformly bounded refinement depth give rise to uniformly\n(with respect to the mesh size) stable Petrov-Galerkin discretizations. The\npartitions are required to be shape regular but need not be quasi-uniform. An\nimportant startup ingredient is that for a constant convection field one can\nidentify the exact optimal test functions with respect to a suitably modified\nbut uniformly equivalent broken test space norm as piecewise polynomials. These\ntest functions are then varied towards simpler and stably computable\nnear-optimal test functions for which the above result is derived via a\nperturbation analysis. We conclude indicating some consequences of the results\nthat will be treated in forthcoming work. \n\n"}
{"id": "1510.03684", "contents": "Title: On the discretisation in time of the stochastic Allen-Cahn equation Abstract: We consider the stochastic Allen--Cahn equation perturbed by smooth additive\nGaussian noise in a spatial domain with smooth boundary in dimension $d\\le 3$,\nand study the semidiscretisation in time of the equation by an Euler type\nsplit-step method. We show that the method converges strongly with a rate\n$O(\\Delta t^{\\frac12}) $. By means of a perturbation argument, we also\nestablish the strong convergence of the standard backward Euler scheme with the\nsame rate. \n\n"}
{"id": "1510.03816", "contents": "Title: A class of fast geodesic shooting algorithms for template matching and\n  its applications via the $N$-particle system of the Euler-Poincar\\'e\n  equations Abstract: The Euler-Poincar\\'e (EP) equations describe the geodesic motion on the\ndiffeomorphism group. For template matching (template deformation), the\nEuler-Lagrangian equation, arising from minimizing an energy function, falls\ninto the Euler-Poincar\\'e theory and can be recast into the EP equations. By\ncasting the EP equations in the Lagrangian (or characteristics) form, we\nformulate the equations as a finite dimensional particle system. The evolution\nof this particle system describes the geodesic motion of landmark points on a\nRiemann manifold. In this paper we present a class of novel algorithms that\ntake advantage of the structure of the particle system to achieve a fast\nmatching process between the reference and the target templates. The strong\nsuit of the proposed algorithms includes (1) the efficient feedback control\niteration, which allows one to find the initial velocity field for driving the\ndeformation from the reference template to the target one, (2) the use of the\nconical kernel in the particle system, which limits the interaction between\nparticles and thus accelerates the convergence, and (3) the availability of the\nimplementation of fast-multipole method for solving the particle system, which\ncould reduce the computational cost from $O(N^2)$ to $O(N\\log N)$, where $N$ is\nthe number of particles. The convergence properties of the proposed algorithms\nare analyzed. Finally, we present several examples for both exact and inexact\nmatchings, and numerically analyze the iterative process to illustrate the\nefficiency and the robustness of the proposed algorithms. \n\n"}
{"id": "1510.04361", "contents": "Title: Global sensitivity metrics from active subspaces Abstract: Predictions from science and engineering models depend on several input\nparameters. Global sensitivity analysis quantifies the importance of each input\nparameter, which can lead to insight into the model and reduced computational\ncost; commonly used sensitivity metrics include Sobol' total sensitivity\nindices and derivative-based global sensitivity measures. Active subspaces are\nan emerging set of tools for identifying important directions in a model's\ninput parameter space; these directions can be exploited to reduce the model's\ndimension enabling otherwise infeasible parameter studies. In this paper, we\ndevelop global sensitivity metrics called activity scores from the active\nsubspace, which yield insight into the important model parameters. We\nmathematically relate the activity scores to established sensitivity metrics,\nand we discuss computational methods to estimate the activity scores. We show\ntwo numerical examples with algebraic functions taken from simplified\nengineering models. For each model, we analyze the active subspace and discuss\nhow to exploit the low-dimensional structure. We then show that input rankings\nproduced by the activity scores are consistent with rankings produced by the\nstandard metrics. \n\n"}
{"id": "1510.04729", "contents": "Title: Strong convergence of the tamed and the semi-tamed Euler schemes for\n  stochastic differential equations with jumps under non-global Lipschitz\n  condition Abstract: We consider the explicit numerical approximations of stochastic differential\nequations (SDEs) driven by Brownian process and Poisson jump. It is well known\nthat under non-global Lipschitz condition, Euler Explicit method fails to\nconverge strongly to the exact solution of such SDEs without jumps, while\nimplicit Euler method converges but requires much computational efforts. We\ninvestigate the strong convergence, the linear and nonlinear exponential\nstabilities of tamed Euler and semi-tamed methods for stochastic differential\nequation driven by Brownian process and Poisson jumps, both in compensated and\nnon compensated forms. We prove that under non-global Lipschitz condition and\nsuperlinearly growing drift term, these schemes converge strongly with the\nstandard one-half order. Numerical simulations to substain the theoretical\nresults are provided. \n\n"}
{"id": "1510.05616", "contents": "Title: A fast algorithm for simulating multiphase flows through periodic\n  geometries of arbitrary shape Abstract: This paper presents a new boundary integral equation (BIE) method for\nsimulating particulate and multiphase flows through periodic channels of\narbitrary smooth shape in two dimensions. The authors consider a particular\nsystem---multiple vesicles suspended in a periodic channel of arbitrary\nshape---to describe the numerical method and test its performance. Rather than\nrelying on the periodic Green's function as classical BIE methods do, the\nmethod combines the free-space Green's function with a small auxiliary basis,\nand imposes periodicity as an extra linear condition. As a result, we can\nexploit existing free-space solver libraries, quadratures, and fast algorithms,\nand handle a large number of vesicles in a geometrically complex channel.\nSpectral accuracy in space is achieved using the periodic trapezoid rule and\nproduct quadratures, while a first-order semi-implicit scheme evolves particles\nby treating the vesicle-channel interactions explicitly. New\nconstraint-correction formulas are introduced that preserve reduced areas of\nvesicles, independent of the number of time steps taken. By using two types of\nfast algorithms, (i) the fast multipole method (FMM) for the computation of the\nvesicle-vesicle and the vesicle-channel hydrodynamic interaction, and (ii) a\nfast direct solver for the BIE on the fixed channel geometry, the computational\ncost is reduced to $O(N)$ per time step where $N$ is the spatial discretization\nsize. Moreover, the direct solver inverts the wall BIE operator at $t = 0$,\nstores its compressed representation and applies it at every time step to\nevolve the vesicle positions, leading to dramatic cost savings compared to\nclassical approaches. Numerical experiments illustrate that a simulation with\n$N=128, 000$ can be evolved in less than a minute per time step on a laptop. \n\n"}
{"id": "1510.06682", "contents": "Title: High order Nystr\\\"om methods for transmission problems for Helmholtz\n  equation Abstract: We present superalgebraic compatible Nystr\\\"om discretizations for the four\nHelmholtz boundary operators of Calder\\'{o}n's calculus on smooth closed curves\nin 2D. These discretizations are based on appropriate splitting of the kernels\ncombined with very accurate product-quadrature rules for the different\nsingularities that such kernels present. A Fourier based analysis shows that\nthe four discrete operators converge to the continuous ones in appropriate\nSobolev norms. This proves that Nystr\\\"om discretizations of many popular\nintegral equation formulations for Helmholtz equations are stable and\nconvergent. The convergence is actually superalgebraic for smooth solutions. \n\n"}
{"id": "1510.06899", "contents": "Title: An iterative method to reconstruct the refractive index of a medium from\n  time-of-flight measurements Abstract: The article deals with a classical inverse problem: the computation of the\nrefractive index of a medium from ultrasound time-of-flight (TOF) measurements.\nThis problem is very popular in seismics but also for tomographic problems in\ninhomogeneous media. For example ultrasound vector field tomography needs a\npriori knowledge of the sound speed. According to Fermat's principle ultrasound\nsignals travel along geodesic curves of a Riemannian metric which is associated\nwith the refractive index. The inverse problem thus consists of determining the\nindex of refraction from integrals along geodesics curves associated with the\nintegrand leading to a nonlinear problem. In this article we describe a\nnumerical solver for this problem scheme based on an iterative minimization\nmethod for an appropriate Tikhonov functional. The outcome of the method is a\nstable approximation of the sought index of refraction as well as a\ncorresponding set of geodesic curves. We prove some analytical convergence\nresults for this method and demonstrate its performance by means of several\nnumerical experiments. Another novelty in this article is the explicit\nrepresentation of the backprojection operator for the ray transform in\nRiemannian geometry and its numerical realization relying on a corresponding\nphase function that is determined by the metric. This gives a natural extension\nof the conventional backprojection from 2D computerized tomography to\ninhomogeneous geometries. \n\n"}
{"id": "1510.07230", "contents": "Title: A Parallel Orbital-updating Based Optimization Method for Electronic\n  Structure Calculations Abstract: In this paper, we propose a parallel optimization method for electronic\nstructure calculations based on a single orbital-updating approximation. It is\nshown by our numerical experiments that the method is efficient and reliable\nfor atomic and molecular systems of large scale over supercomputers. \n\n"}
{"id": "1511.01554", "contents": "Title: Low-rank methods for high-dimensional approximation and model order\n  reduction Abstract: Tensor methods are among the most prominent tools for the numerical solution\nof high-dimensional problems where functions of multiple variables have to be\napproximated. These methods exploit the tensor structure of function spaces and\napply to many problems in computational science which are formulated in tensor\nspaces, such as problems arising in stochastic calculus, uncertainty\nquantification or parametric analyses. Here, we present complexity reduction\nmethods based on low-rank approximation methods. We analyze the problem of best\napproximation in subsets of low-rank tensors and discuss its connection with\nthe problem of optimal model reduction in low-dimensional reduced spaces. We\npresent different algorithms for computing approximations of a function in\nlow-rank formats. In particular, we present constructive algorithms which are\nbased either on a greedy construction of an approximation (with successive\ncorrections in subsets of low-rank tensors) or on the greedy construction of\ntensor subspaces (for subspace-based low-rank formats). These algorithms can be\napplied for tensor compression, tensor completion or for the numerical solution\nof equations in low-rank tensor formats. A special emphasis is given to the\nsolution of stochastic or parameter-dependent models. Different approaches are\npresented for the approximation of vector-valued or multivariate functions\n(identified with tensors), based on samples of the functions (black-box\napproaches) or on the models equations which are satisfied by the functions. \n\n"}
{"id": "1511.01932", "contents": "Title: On the use of Perfectly Matched Layers at corners for scattering\n  problems with sign-changing coefficients Abstract: We investigate in a $2$D setting the scattering of time-harmonic\nelectromagnetic waves by a plasmonic device, represented as a non dissipative\nbounded and penetrable obstacle with a negative permittivity. Using the\n$\\textrm{T}$-coercivity approach, we first prove that the problem is well-posed\nin the classical framework $H^1_{\\text{loc}} $ if the negative permittivity\ndoes not lie in some critical interval whose definition depends on the shape of\nthe device. When the latter has corners, for values inside the critical\ninterval, unusual strong singularities for the electromagnetic field can\nappear. In that case, well-posedness is obtained by imposing a radiation\ncondition at the corners to select the outgoing black-hole plasmonic wave, that\nis the one which carries energy towards the corners. A simple and systematic\ncriterion is given to define what is the outgoing solution. Finally, we propose\nan original numerical method based on the use of Perfectly Matched Layers at\nthe corners. We emphasize that it is necessary to design an $\\textit{ad hoc}$\ntechnique because the field is too singular to be captured with standard finite\nelement methods. \n\n"}
{"id": "1511.02017", "contents": "Title: Caputo derivatives of fractional variable order: numerical\n  approximations Abstract: We present a new numerical tool to solve partial differential equations\ninvolving Caputo derivatives of fractional variable order. Three Caputo-type\nfractional operators are considered, and for each one of them an approximation\nformula is obtained in terms of standard (integer-order) derivatives only.\nEstimations for the error of the approximations are also provided. We then\ncompare the numerical approximation of some test function with its exact\nfractional derivative. We end with an exemplification of how the presented\nmethods can be used to solve partial fractional differential equations of\nvariable order. \n\n"}
{"id": "1511.02242", "contents": "Title: New asymptotic heat transfer model in thin liquid films Abstract: In this article, we present a model of heat transfer occurring through a\nli\\-quid film flowing down a vertical wall. This new model is formally derived\nusing the method of asymptotic expansions by introducing appropriately chosen\ndimensionless variables. In our study the small parameter, known as the film\nparameter, is chosen as the ratio of the flow depth to the characteristic\nwavelength. A new Nusselt solution should be explained, taking into account the\nhydrodynamic free surface variations and the contributions of the higher order\nterms coming from temperature variation effects. Comparisons are made with\nnumerical solutions of the full Fourier equations in a steady state frame. The\nflow and heat transfer are coupled through Marangoni and temperature dependent\nviscosity effects. Even if these effects have been considered separately\nbefore, here a fully coupled model is proposed. Another novelty consists in the\nasymptotic approach in contrast to the weighted residual approach which have\nbeen formerly applied to these problems. \n\n"}
{"id": "1511.04685", "contents": "Title: Semi-Inner-Products for Convex Functionals and Their Use in Image\n  Decomposition Abstract: Semi-inner-products in the sense of Lumer are extended to convex functionals.\nThis yields a Hilbert-space like structure to convex functionals in Banach\nspaces. In particular, a general expression for semi-inner-products with\nrespect to one homogeneous functionals is given. Thus one can use the new\noperator for the analysis of total variation and higher order functionals like\ntotal-generalized-variation (TGV). Having a semi-inner-product, an angle\nbetween functions can be defined in a straightforward manner. It is shown that\nin the one homogeneous case the Bregman distance can be expressed in terms of\nthis newly defined angle. In addition, properties of the semi-inner-product of\nnonlinear eigenfunctions induced by the functional are derived. We use this\nconstruction to state a sufficient condition for a perfect decomposition of two\nsignals and suggest numerical measures which indicate when those conditions are\napproximately met. \n\n"}
{"id": "1511.05208", "contents": "Title: HOID: Higher Order Interpolatory Decomposition for tensors based on\n  Tucker representation Abstract: We derive a CUR-type factorization for tensors in the Tucker format based on\ninterpolatory decomposition, which we will denote as Higher Order Interpolatory\nDecomposition (HOID). Given a tensor $\\mathcal{X}$, the algorithm provides a\nset of column vectors $\\{ \\mathbf{C}_n\\}_{n=1}^d$ which are columns extracted\nfrom the mode-$n$ tensor unfolding, along with a core tensor $\\mathcal{G}$ and\ntogether, they satisfy some error bounds. Compared to the Higher Order SVD\n(HOSVD) algorithm, the HOID provides a decomposition that preserves certain\nimportant features of the original tensor such as sparsity, non-negativity,\ninteger values, etc. Error bounds along with detailed estimates of\ncomputational costs are provided. The algorithms proposed in this paper have\nbeen validated against carefully chosen numerical examples which highlight the\nfavorable properties of the algorithms. Related methods for subset selection\nproposed for matrix CUR decomposition, such as Discrete Empirical Interpolation\nmethod (DEIM) and leverage score sampling, have also been extended to tensors\nand are compared against our proposed algorithms. \n\n"}
{"id": "1511.05414", "contents": "Title: Complexity of Oscillatory Integrals on the Real Line Abstract: We analyze univariate oscillatory integrals defined on the real line for\nfunctions from the standard Sobolev space $H^s({\\mathbb{R}})$ and from the\nspace $C^s({\\mathbb{R}})$ with an arbitrary integer $s\\ge1$. We find tight\nupper and lower bounds for the worst case error of optimal algorithms that use\n$n$ function values. More specifically, we study integrals of the form \\[\nI_k^\\rho (f) = \\int_{ {\\mathbb{R}}} f(x) \\,e^{-i\\,kx} \\rho(x) \\, {\\rm d} x\\ \\ \\\n\\mbox{for}\\ \\ f\\in H^s({\\mathbb{R}})\\ \\ \\mbox{or}\\ \\ f\\in C^s({\\mathbb{R}}) \\]\nwith $k\\in {\\mathbb{R}}$ and a smooth density function $\\rho$ such as $ \\rho(x)\n= \\frac{1}{\\sqrt{2 \\pi}} \\exp( -x^2/2) $. The optimal error bounds are\n$\\Theta((n+\\max(1,|k|))^{-s})$ with the factors in the $\\Theta$ notation\ndependent only on $s$ and $\\rho$. \n\n"}
{"id": "1511.07823", "contents": "Title: A-stable time discretizations preserve maximal parabolic regularity Abstract: It is shown that for a parabolic problem with maximal $L^p$-regularity (for\n$1<p<\\infty$), the time discretization by a linear multistep method or\nRunge--Kutta method has maximal $\\ell^p$-regularity uniformly in the stepsize\nif the method is A-stable (and satisfies minor additional conditions). In\nparticular, the implicit Euler method, the Crank-Nicolson method, the\nsecond-order backward difference formula (BDF), and the Radau IIA and Gauss\nRunge--Kutta methods of all orders preserve maximal regularity. The proof uses\nWeis' characterization of maximal $L^p$-regularity in terms of $R$-boundedness\nof the resolvent, a discrete operator-valued Fourier multiplier theorem by\nBlunck, and generating function techniques that have been familiar in the\nstability analysis of time discretization methods since the work of Dahlquist.\nThe A($\\alpha$)-stable higher-order BDF methods have maximal\n$\\ell^p$-regularity under an $R$-boundedness condition in a larger sector. As\nan illustration of the use of maximal regularity in the error analysis of\ndiscretized nonlinear parabolic equations, it is shown how error bounds are\nobtained without using any growth condition on the nonlinearity or for\nnonlinearities having singularities. \n\n"}
{"id": "1511.08110", "contents": "Title: Robust approximation algorithms for the detection of attraction basins\n  in dynamical systems Abstract: In dynamical systems saddle points partition the domain into basins of\nattractions of the remaining locally stable equilibria. This problem is rather\ncommon especially in population dynamics models. Precisely, a particular\nsolution of a dynamical system is completely determined by its initial\ncondition and by the parameters involved in the model. Furthermore, when the\nomega limit set reduces to a point, the trajectory of the solution evolves\ntowards the steady state. But, in case of multi-stability it is possible that\nseveral steady states originate from the same parameter set. Thus, in these\ncases the importance of accurately reconstruct the attraction basins follows.\nIn this paper we focus on dynamical systems of ordinary differential equations\npresenting three stable equilibia and we design algorithms for the detection of\nthe points lying on the manifolds determining the basins of attraction and for\nthe reconstruction of such manifolds. The latter are reconstructed by means of\nthe implicit partition of unity method which makes use of radial basis\nfunctions (RBFs) as local approximants. Extensive numerical test, carried out\nwith a Matlab package made available to the scientific community, support our\nfindings. \n\n"}
{"id": "1511.09159", "contents": "Title: Proximal gradient method for huberized support vector machine Abstract: The Support Vector Machine (SVM) has been used in a wide variety of\nclassification problems. The original SVM uses the hinge loss function, which\nis non-differentiable and makes the problem difficult to solve in particular\nfor regularized SVMs, such as with $\\ell_1$-regularization. This paper\nconsiders the Huberized SVM (HSVM), which uses a differentiable approximation\nof the hinge loss function. We first explore the use of the Proximal Gradient\n(PG) method to solving binary-class HSVM (B-HSVM) and then generalize it to\nmulti-class HSVM (M-HSVM). Under strong convexity assumptions, we show that our\nalgorithm converges linearly. In addition, we give a finite convergence result\nabout the support of the solution, based on which we further accelerate the\nalgorithm by a two-stage method. We present extensive numerical experiments on\nboth synthetic and real datasets which demonstrate the superiority of our\nmethods over some state-of-the-art methods for both binary- and multi-class\nSVMs. \n\n"}
{"id": "1512.01306", "contents": "Title: Efficient simulation of Schr\\\"odinger equation with piecewise constant\n  positive potential Abstract: In this paper we introduce a new method for the simulation of a weak solution\nof the Schr\\\"odinger-type equation where the potential is piecewise constant\nand positive. The method, called killing walk on spheres algorithm, combines\nthe classical walk of spheres algorithm with killing that can be determined by\nusing panharmonic measures. \n\n"}
{"id": "1512.01985", "contents": "Title: The shifted proper orthogonal decomposition: A mode decomposition for\n  multiple transport phenomena Abstract: Transport-dominated phenomena provide a challenge for common mode-based model\nreduction approaches. We present a model reduction method, which is suited for\nthese kind of systems. It extends the proper orthogonal decomposition (POD) by\nintroducing time-dependent shifts of the snapshot matrix. The approach, called\nshifted proper orthogonal decomposition (sPOD), features a determination of the\n{\\it multiple} transport velocities and a separation of these. One- and\ntwo-dimensional test examples reveal the good performance of the sPOD for\ntransport-dominated phenomena and its superiority in comparison to the POD. \n\n"}
{"id": "1512.02303", "contents": "Title: The $f$-Sensitivity Index Abstract: This article presents a general multivariate $f$-sensitivity index, rooted in\nthe $f$-divergence between the unconditional and conditional probability\nmeasures of a stochastic response, for global sensitivity analysis. Unlike the\nvariance-based Sobol index, the $f$-sensitivity index is applicable to random\ninput following dependent as well as independent probability distributions.\nSince the class of $f$-divergences supports a wide variety of divergence or\ndistance measures, a plethora of $f$-sensitivity indices are possible,\naffording diverse choices to sensitivity analysis. Commonly used sensitivity\nindices or measures, such as mutual information, squared-loss mutual\ninformation, and Borgonovo's importance measure, are shown to be special cases\nof the proposed sensitivity index. New theoretical results, revealing\nfundamental properties of the $f$-sensitivity index and establishing important\ninequalities, are presented. Three new approximate methods, depending on how\nthe probability densities of a stochastic response are determined, are proposed\nto estimate the sensitivity index. Four numerical examples, including a\ncomputationally intensive stochastic boundary-value problem, illustrate these\nmethods and explain when one method is more relevant than the others. \n\n"}
{"id": "1512.02713", "contents": "Title: Transformations and Hardy-Krause variation Abstract: Using a multivariable Faa di Bruno formula we give conditions on\ntransformations $\\tau:[0,1]^m\\to\\mathcal{X}$ where $\\mathcal{X}$ is a closed\nand bounded subset of $\\mathbb{R}^d$ such that $f\\circ\\tau$ is of bounded\nvariation in the sense of Hardy and Krause for all $f\\in C^d(\\mathcal{x})$. We\ngive similar conditions for $f\\circ\\tau$ to be smooth enough for scrambled net\nsampling to attain $O(n^{-3/2+\\epsilon})$ accuracy. Some popular symmetric\ntransformations to the simplex and sphere are shown to satisfy neither\ncondition. Some other transformations due to Fang and Wang (1993) satisfy the\nfirst but not the second condition. We provide transformations for the simplex\nthat makes $f\\circ\\tau$ smooth enough to fully benefit from scrambled net\nsampling for all $f$ in a class of generalized polynomials. We also find\nsufficient conditions for the Rosenblatt-Hlawka-M\\\"uck transformation in\n$\\mathbb{R}^2$ and for importance sampling to be of bounded variation in the\nsense of Hardy and Krause. \n\n"}
{"id": "1512.04049", "contents": "Title: Geometrization of symplecticity conditions for implicit schemes Abstract: In this note we give simple symplecticity conditions for implicit schemes in\nthe linear case. We consider implicit maps on generic symplectic manifold and\nwe introduce the concept of consistent implicit maps, to generalize the\nsymplecticity conditions to symplectic manifolds. Additionally, we give a\npreliminary geometrical interpretation of those conditions. \n\n"}
{"id": "1512.06025", "contents": "Title: GPU-accelerated Bernstein-Bezier discontinuous Galerkin methods for wave\n  problems Abstract: We evaluate the computational performance of the Bernstein-Bezier basis for\ndiscontinuous Galerkin (DG) discretizations and show how to exploit properties\nof derivative and lift operators specific to Bernstein polynomials for an\noptimal complexity quadrature-free evaluation of the DG formulation. Issues of\nefficiency and numerical stability are discussed in the context of a model wave\npropagation problem. We compare the performance of Bernstein-Bezier kernels to\nboth a straightforward and a block-partitioned implementation of nodal DG\nkernels in a time-explicit GPU-accelerated DG solver. Computational experiments\nconfirm the advantage of Bernstein-Bezier DG kernels over both straightforward\nand block-partitioned nodal DG kernels at high orders of approximation. \n\n"}
{"id": "1512.06513", "contents": "Title: A new discretization for mth-Laplace equations with arbitrary polynomial\n  degrees Abstract: This paper introduces new mixed formulations and discretizations for\n$m$th-Laplace equations of the form $(-1)^m\\Delta^m u=f$ for arbitrary\n$m=1,2,3,\\dots$ based on novel Helmholtz-type decompositions for tensor-valued\nfunctions. The new discretizations allow for ansatz spaces of arbitrary\npolynomial degree and the lowest-order choice coincides with the non-conforming\nFEMs of Crouzeix and Raviart for $m=1$ and of Morley for $m=2$. Since the\nderivatives are directly approximated, the lowest-order discretizations consist\nof piecewise affine and piecewise constant functions for any $m=1,2,\\dots$\nMoreover, a uniform implementation for arbitrary $m$ is possible. Besides the a\npriori and a posteriori analysis, this paper proves optimal convergence rates\nfor adaptive algorithms for the new discretizations. \n\n"}
{"id": "1512.06629", "contents": "Title: A numerical scheme for space-time fractional advection-dispersion\n  equation Abstract: In this paper, we develop a numerical resolution of the space-time fractional\nadvection-dispersion equation. After time discretization, we utilize\ncollocation technique and implement a product integration method in order to\nsimplify the evaluation of the terms involving spatial fractional order\nderivatives. Then utilizing Bernstein polynomials as basis, the problem is\ntransformed into a linear system of algebraic equations. Error analysis and\norder of convergence for the proposed method are also discussed. Some numerical\nexperiments are presented to demonstrate the effectiveness of the proposed\nmethod and to confirm the analytic results. \n\n"}
{"id": "1512.06890", "contents": "Title: Stochastic Dual Ascent for Solving Linear Systems Abstract: We develop a new randomized iterative algorithm---stochastic dual ascent\n(SDA)---for finding the projection of a given vector onto the solution space of\na linear system. The method is dual in nature: with the dual being a\nnon-strongly concave quadratic maximization problem without constraints. In\neach iteration of SDA, a dual variable is updated by a carefully chosen point\nin a subspace spanned by the columns of a random matrix drawn independently\nfrom a fixed distribution. The distribution plays the role of a parameter of\nthe method. Our complexity results hold for a wide family of distributions of\nrandom matrices, which opens the possibility to fine-tune the stochasticity of\nthe method to particular applications. We prove that primal iterates associated\nwith the dual process converge to the projection exponentially fast in\nexpectation, and give a formula and an insightful lower bound for the\nconvergence rate. We also prove that the same rate applies to dual function\nvalues, primal function values and the duality gap. Unlike traditional\niterative methods, SDA converges under no additional assumptions on the system\n(e.g., rank, diagonal dominance) beyond consistency. In fact, our lower bound\nimproves as the rank of the system matrix drops. Many existing randomized\nmethods for linear systems arise as special cases of SDA, including randomized\nKaczmarz, randomized Newton, randomized coordinate descent, Gaussian descent,\nand their variants. In special cases where our method specializes to a known\nalgorithm, we either recover the best known rates, or improve upon them.\nFinally, we show that the framework can be applied to the distributed average\nconsensus problem to obtain an array of new algorithms. The randomized gossip\nalgorithm arises as a special case. \n\n"}
{"id": "1512.07840", "contents": "Title: ArbiLoMod, a Simulation Technique Designed for Arbitrary Local\n  Modifications Abstract: Engineers manually optimizing a structure using Finite Element based\nsimulation software often employ an iterative approach where in each iteration\nthey change the structure slightly and resimulate. Standard Finite Element\nbased simulation software is usually not well suited for this workflow, as it\nrestarts in each iteration, even for tiny changes. In settings with complex\nlocal microstructure, where a fine mesh is required to capture the geometric\ndetail, localized model reduction can improve this workflow. To this end, we\nintroduce ArbiLoMod, a method which allows fast recomputation after arbitrary\nlocal modifications. It employs a domain decomposition and a localized form of\nthe Reduced Basis Method for model order reduction. It assumes that the reduced\nbasis on many of the unchanged domains can be reused after a localized change.\nThe reduced model is adapted when necessary, steered by a localized error\nindicator. The global error introduced by the model order reduction is\ncontrolled by a robust and efficient localized a posteriori error estimator,\ncertifying the quality of the result. We demonstrate ArbiLoMod for a coercive,\nparameterized example with changing structure. \n\n"}
{"id": "1512.07877", "contents": "Title: A Computational Investigation of the Finite-Time Blow-Up of the 3D\n  Incompressible Euler Equations Based on the Voigt Regularization Abstract: We report the results of a computational investigation of two blow-up\ncriteria for the 3D incompressible Euler equations. One criterion was proven in\na previous work, and a related criterion is proved here. These criteria are\nbased on an inviscid regularization of the Euler equations known as the 3D\nEuler-Voigt equations, which are known to be globally well-posed. Moreover,\nsimulations of the 3D Euler-Voigt equations also require less resolution than\nsimulations of the 3D Euler equations for fixed values of the regularization\nparameter $\\alpha>0$. Therefore, the new blow-up criteria allow one to gain\ninformation about possible singularity formation in the 3D Euler equations\nindirectly; namely, by simulating the better-behaved 3D Euler-Voigt equations.\nThe new criteria are only known to be sufficient for blow-up. Therefore, to\ntest the robustness of the inviscid-regularization approach, we also\ninvestigate analogous criteria for blow-up of the 1D Burgers equation, where\nblow-up is well-known to occur. \n\n"}
{"id": "1512.09091", "contents": "Title: Finite element approximation of the Isaacs equation Abstract: We propose and analyze a two-scale finite element method for the Isaacs\nequation. The fine scale is given by the mesh size $h$ whereas the coarse scale\n$\\varepsilon$ is dictated by an integro-differential approximation of the\npartial differential equation. We show that the method satisfies the discrete\nmaximum principle provided that the mesh is weakly acute. This, in conjunction\nwith weak operator consistency of the finite element method, allows us to\nestablish convergence of the numerical solution to the viscosity solution as\n$\\varepsilon, h\\to0$, and $\\varepsilon \\gtrsim h^{1/2}|\\log h|$. In addition,\nusing a discrete Alexandrov Bakelman Pucci estimate we deduce rates of\nconvergence, under suitable smoothness assumptions on the exact solution. \n\n"}
{"id": "1601.00583", "contents": "Title: Isogeometric analysis in electronic structure calculations Abstract: In electronic structure calculations, various material properties can be\nobtained by means of computing the total energy of a system as well as\nderivatives of the total energy w.r.t. atomic positions. The derivatives, also\nknown as Hellman-Feynman forces, require, because of practical computational\nreasons, the discretized charge density and wave functions having continuous\nsecond derivatives in the whole solution domain. We describe an application of\nisogeometric analysis (IGA), a spline modification of finite element method\n(FEM), to achieve the required continuity. The novelty of our approach is in\nemploying the technique of B\\'ezier extraction to add the IGA capabilities to\nour FEM based code for ab-initio calculations of electronic states of\nnon-periodic systems within the density-functional framework, built upon the\nopen source finite element package SfePy. We compare FEM and IGA in benchmark\nproblems and several numerical results are presented. \n\n"}
{"id": "1601.01808", "contents": "Title: Dual-Primal Isogeometric Tearing and Interconnecting solvers for\n  multipatch dG-IgA equations Abstract: In this paper we consider a new version of the dual-primal isogeometric\ntearing and interconnecting (IETI-DP) method for solving large-scale linear\nsystems of algebraic equations arising from discontinuous Galerkin (dG)\nisogeometric analysis of diffusion problems on multipatch domains with\nnon-matching meshes. The dG formulation is used to couple the local problems\nacross patch interfaces. The purpose of this paper is to present this new\nmethod and provide numerical examples indicating a polylogarithmic condition\nnumber bound for the preconditioned system and showing an incredible robustness\nwith respect to large jumps in the diffusion coefficient across the interfaces. \n\n"}
{"id": "1601.02085", "contents": "Title: Approximating Stochastic Evolution Equations with Additive White and\n  Rough Noises Abstract: In this paper, we analyze Galerkin approximations for stochastic evolution\nequations driven by an additive Gaussian noise which is temporally white and\nspatially fractional with Hurst index less than or equal to $1/2$. First we\nregularize the noise by the Wong-Zakai approximation and obtain its optimal\norder of convergence. Then we apply the Galerkin method to discretize the\nstochastic evolution equations with regularized noises. Optimal error estimates\nare obtained for the Galerkin approximations. In particular, our error\nestimates remove an infinitesimal factor which appears in the error estimates\nof various numerical methods for stochastic evolution equations in existing\nliteratures. \n\n"}
{"id": "1601.02679", "contents": "Title: On Calculating the Current-Voltage Characteristic of Multi-Diode Models\n  for Organic Solar Cells Abstract: We provide an alternative formulation of the exact calculation of the\ncurrent-voltage characteristic of solar cells which have been modeled with a\nlumped parameters equivalent circuit with one or two diodes. Such models, for\ninstance, are suitable for describing organic solar cells whose current-voltage\ncharacteristic curve has an inflection point, also known as an S-shaped\nanomaly. Our formulation avoids the risk of numerical overflow in the\ncalculation. It is suitable for implementation in Fortran, C or on\nmicro-controllers. \n\n"}
{"id": "1601.06549", "contents": "Title: Robust Numerical Upscaling of Elliptic Multiscale Problems at High\n  Contrast Abstract: We present a new approach to the numerical upscaling for elliptic problems\nwith rough diffusion coefficient at high contrast. It is based on the\nlocalizable orthogonal decomposition of $H^1$ into the image and the kernel of\nsome novel stable quasi-interpolation operators with local $L^2$-approximation\nproperties, independent of the contrast. We identify a set of sufficient\nassumptions on these quasi-interpolation operators that guarantee in principle\noptimal convergence without pre-asymptotic effects for high-contrast\ncoefficients. We then give an example of a suitable operator and establish the\nassumptions for a particular class of high-contrast coefficients. So far this\nis not possible without any pre-asymptotic effects, but the optimal convergence\nis independent of the contrast and the asymptotic range is largely improved\nover other discretisation schemes. The new framework is sufficiently flexible\nto allow also for other choices of quasi-interpolation operators and the\npotential for fully robust numerical upscaling at high contrast. \n\n"}
{"id": "1601.06977", "contents": "Title: Robust Discretization of Flow in Fractured Porous Media Abstract: Flow in fractured porous media represents a challenge for discretization\nmethods due to the disparate scales and complex geometry. Herein we propose a\nnew discretization, based on the mixed finite element method and mortar\nmethods. Our formulation is novel in that it employs the normal fluxes as the\nmortar variable within the mixed finite element framework, resulting in a\nformulation that couples the flow in the fractures with the surrounding domain\nwith a strong notion of mass conservation. The proposed discretization handles\ncomplex, non-matching grids, and allows for fracture intersections and\ntermination in a natural way, as well as spatially varying apertures. The\ndiscretization is applicable to both two and three spatial dimensions. A priori\nanalysis shows the method to be optimally convergent with respect to the chosen\nmixed finite element spaces, which is sustained by numerical examples. \n\n"}
{"id": "1601.07676", "contents": "Title: A conjugate gradient method for electronic structure calculations Abstract: In this paper, we study a conjugate gradient method for electronic structure\ncalculations. We propose a Hessian based step size strategy, which together\nwith three orthogonality approaches yields three algorithms for computing the\nground state energy of atomic and molecular systems. Under some mild\nassumptions, we prove that our algorithms converge locally. It is shown by our\nnumerical experiments that the conjugate gradient method is efficient. \n\n"}
{"id": "1601.07864", "contents": "Title: On construction of boundary preserving numerical schemes Abstract: Our aim in this note is to extend the semi discrete technique by combine it\nwith the split step method. We apply our new method to the Ait-Sahalia model\nand propose an explicit and positivity preserving numerical scheme. \n\n"}
{"id": "1602.01658", "contents": "Title: Efficient implementation of the Localized Orthogonal Decomposition\n  method Abstract: In this paper we present algorithms for an efficient implementation of the\nLocalized Orthogonal Decomposition method (LOD). The LOD is a multiscale method\nfor the numerical simulation of partial differential equations with a continuum\nof inseparable scales. We show how the method can be implemented in a fairly\nstandard Finite Element framework and discuss its realization for different\ntypes of problems, such as linear elliptic problems with rough coefficients and\nlinear eigenvalue problems. \n\n"}
{"id": "1602.01675", "contents": "Title: Symplecticity-preserving continuous-stage Runge-Kutta-Nystr\\\"{o}m\n  methods Abstract: We develop continuous-stage Runge-Kutta-Nystr\\\"{o}m (csRKN) methods for\nsolving second order ordinary differential equations (ODEs) in this paper. The\nsecond order ODEs are commonly encountered in various fields and some of them\ncan be reduced to the first order ODEs with the form of separable Hamiltonian\nsystems. The symplecticity-preserving numerical algorithm is of interest for\nsolving such special systems. We present a sufficient condition for a csRKN\nmethod to be symplecticity-preserving, and by using Legendre polynomial\nexpansion we show a simple way to construct such symplectic RKN type method. \n\n"}
{"id": "1602.02027", "contents": "Title: On the Adjoint Operator in Photoacoustic Tomography Abstract: Photoacoustic Tomography (PAT) is an emerging biomedical \"imaging from\ncoupled physics\" technique, in which the image contrast is due to optical\nabsorption, but the information is carried to the surface of the tissue as\nultrasound pulses. Many algorithms and formulae for PAT image reconstruction\nhave been proposed for the case when a complete data set is available. In many\npractical imaging scenarios, however, it is not possible to obtain the full\ndata, or the data may be sub-sampled for faster data acquisition. In such\ncases, image reconstruction algorithms that can incorporate prior knowledge to\nameliorate the loss of data are required. Hence, recently there has been an\nincreased interest in using variational image reconstruction. A crucial\ningredient for the application of these techniques is the adjoint of the PAT\nforward operator, which is described in this article from physical, theoretical\nand numerical perspectives. First, a simple mathematical derivation of the\nadjoint of the PAT forward operator in the continuous framework is presented.\nThen, an efficient numerical implementation of the adjoint using a k-space time\ndomain wave propagation model is described and illustrated in the context of\nvariational PAT image reconstruction, on both 2D and 3D examples including\ninhomogeneous sound speed. The principal advantage of this analytical adjoint\nover an algebraic adjoint (obtained by taking the direct adjoint of the\nparticular numerical forward scheme used) is that it can be implemented using\ncurrently available fast wave propagation solvers. \n\n"}
{"id": "1602.02694", "contents": "Title: WLS-ENO: Weighted-Least-Squares Based Essentially Non-Oscillatory\n  Schemes for Finite Volume Methods on Unstructured Meshes Abstract: ENO (Essentially Non-Oscillatory) and WENO (Weighted Essentially\nNon-Oscillatory) schemes are widely used high-order schemes for solving partial\ndifferential equations (PDEs), especially hyperbolic conservation laws with\npiecewise smooth solutions. For structured meshes, these techniques can achieve\nhigh order accuracy for smooth functions while being non-oscillatory near\ndiscontinuities. For unstructured meshes, which are needed for complex\ngeometries, similar schemes are required but they are much more challenging. We\npropose a new family of non-oscillatory schemes, called WLS-ENO, in the context\nof solving hyperbolic conservation laws using finite-volume methods over\nunstructured meshes. WLS-ENO is derived based on Taylor series expansion and\nsolved using a weighted least squares formulation. Unlike other non-oscillatory\nschemes, the WLS-ENO does not require constructing sub-stencils, and hence it\nprovides more flexible framework and is less sensitive to mesh quality. We\npresent rigorous analysis of the accuracy and stability of WLS-ENO, and present\nnumerical results in 1-D, 2-D, and 3-D for a number of benchmark problems, and\nalso report some comparisons against WENO. \n\n"}
{"id": "1602.02970", "contents": "Title: Analysis of a high order unfitted finite element method for elliptic\n  interface problems Abstract: In the context of unfitted finite element discretizations the realization of\nhigh order methods is challenging due to the fact that the geometry\napproximation has to be sufficiently accurate. We consider a new unfitted\nfinite element method which achieves a high order approximation of the geometry\nfor domains which are implicitly described by smooth level set functions. The\nmethod is based on a parametric mapping which transforms a piecewise planar\ninterface (or surface) reconstruction to a high order approximation. Both\ncomponents, the piecewise planar interface reconstruction and the parametric\nmapping are easy to implement. In this paper we present an a priori error\nanalysis of the method applied to an interface problem. The analysis reveals\noptimal order error bounds for the geometry approximation and for the finite\nelement approximation, for arbitrary high order discretization. The theoretical\nresults are confirmed in numerical experiments. \n\n"}
{"id": "1602.04057", "contents": "Title: Weak error estimates for trajectories of SPDEs for Spectral Galerkin\n  discretization Abstract: We consider stochastic semi-linear evolution equations which are driven by\nadditive, spatially correlated, Wiener noise, and in particular consider\nproblems of heat equation (analytic semigroup) and damped-driven wave equations\n(bounded semigroup) type. We discretize these equations by means of a spectral\nGalerkin projection, and we study the approximation of the probability\ndistribution of the trajectories: test functions are regular, but depend on the\nvalues of the process on the interval $[0,T]$.\n  We introduce a new approach in the context of quantative weak error analysis\nfor discretization of SPDEs. The weak error is formulated using a deterministic\nfunction (It\\^o map) of the stochastic convolution found when the nonlinear\nterm is dropped. The regularity properties of the It\\^o map are exploited, and\nin particular second-order Taylor expansions employed, to transfer the error\nfrom spectral approximation of the stochastic convolution into the weak error\nof interest.\n  We prove that the weak rate of convergence is twice the strong rate of\nconvergence in two situations. First, we assume that the covariance operator\ncommutes with the generator of the semigroup: the first order term in the weak\nerror expansion cancels out thanks to an independence property. Second, we\nremove the commuting assumption, and extend the previous result, thanks to the\nanalysis of a new error term depending on a commutator. \n\n"}
{"id": "1602.05217", "contents": "Title: Low rank tensor recovery via iterative hard thresholding Abstract: We study extensions of compressive sensing and low rank matrix recovery\n(matrix completion) to the recovery of low rank tensors of higher order from a\nsmall number of linear measurements. While the theoretical understanding of low\nrank matrix recovery is already well-developed, only few contributions on the\nlow rank tensor recovery problem are available so far. In this paper, we\nintroduce versions of the iterative hard thresholding algorithm for several\ntensor decompositions, namely the higher order singular value decomposition\n(HOSVD), the tensor train format (TT), and the general hierarchical Tucker\ndecomposition (HT). We provide a partial convergence result for these\nalgorithms which is based on a variant of the restricted isometry property of\nthe measurement operator adapted to the tensor decomposition at hand that\ninduces a corresponding notion of tensor rank. We show that subgaussian\nmeasurement ensembles satisfy the tensor restricted isometry property with high\nprobability under a certain almost optimal bound on the number of measurements\nwhich depends on the corresponding tensor format. These bounds are extended to\npartial Fourier maps combined with random sign flips of the tensor entries.\nFinally, we illustrate the performance of iterative hard thresholding methods\nfor tensor recovery via numerical experiments where we consider recovery from\nGaussian random measurements, tensor completion (recovery of missing entries),\nand Fourier measurements for third order tensors. \n\n"}
{"id": "1602.07033", "contents": "Title: A numerical framework for computing steady states of size-structured\n  population models and their stability Abstract: Structured population models are a class of general evolution equations which\nare widely used in the study of biological systems. Many theoretical methods\nare available for establishing existence and stability of steady states of\ngeneral evolution equations. However, except for very special cases, finding an\nanalytical form of stationary solutions for evolution equations is a\nchallenging task. In the present paper, we develop a numerical framework for\ncomputing approximations to stationary solutions of general evolution\nequations, which can also be used to produce existence and stability regions\nfor steady states. In particular, we use the Trotter-Kato Theorem to\napproximate the infinitesimal generator of an evolution equation on a finite\ndimensional space, which in turn reduces the evolution equation into a system\nof ordinary differential equations. Consequently, we approximate and study the\nasymptotic behavior of stationary solutions. We illustrate the convergence of\nour numerical framework by applying it to a linear Sinko-Streifer structured\npopulation model for which the exact form of the steady state is known. To\nfurther illustrate the utility of our approach, we apply our framework to\nnonlinear population balance equation, which is an extension of well-known\nSmoluchowksi coagulation-fragmentation model to biological populations. We also\ndemonstrate that our numerical framework can be used to gain insight about the\ntheoretical stability of the stationary solutions of the evolution equations.\nFurthermore, the open source Python program that we have developed for our\nnumerical simulations is freely available from our Github repository\n(github.com/MathBioCU). \n\n"}
{"id": "1602.07049", "contents": "Title: Limited Tomography Reconstruction via Tight Frame and Sinogram\n  Extrapolation Abstract: X-ray computed tomography (CT) is one of widely used diagnostic tools for\nmedical and dental tomographic imaging of the human body. However, the standard\nfiltered backprojection reconstruction method requires the complete knowledge\nof the projection data. In the case of limited data, the inverse problem of CT\nbecomes more ill-posed, which makes the reconstructed image deteriorated by the\nartifacts. In this paper, we consider two dimensional CT reconstruction using\nthe horizontally truncated projections. Over the decades, the numerous results\nincluding the sparsity model based approach has enabled the reconstruction of\nthe image inside the region of interest (ROI) from the limited knowledge of the\ndata. However, unlike these existing methods, we try to reconstruct the entire\nCT image from the limited knowledge of the sinogram via the tight frame\nregularization and the simultaneous sinogram extrapolation. Our proposed model\nshows more promising numerical simulation results compared with the existing\nsparsity model based approach. \n\n"}
{"id": "1602.08338", "contents": "Title: The DUNE-DPG library for solving PDEs with Discontinuous\n  Petrov--Galerkin finite elements Abstract: In the numerical solution of partial differential equations (PDEs), a central\nquestion is the one of building variational formulations that are inf-sup\nstable not only at the infinite-dimensional level, but also at the\nfinite-dimensional one. This guarantees that residuals can be used to tightly\nbound errors from below and above and is crucial for a posteriori error control\nand the development of adaptive strategies. In this framework, the so-called\nDiscontinuous Petrov--Galerkin (DPG) concept can be viewed as a systematic\nstrategy of contriving variational formulations which possess these desirable\nstability properties, see e. g. Broersen et al. [2015]. In this paper, we\npresent a C++ library, Dune-DPG, which serves to implement and solve such\nvariational formulations. The library is built upon the multipurpose finite\nelement package Dune (see Blatt et al. [2016]). One of the main features of\nDune-DPG is its flexibility which is achieved by a highly modular structure.\nThe library can solve in practice some important classes of PDEs (whose range\ngoes beyond classical second order elliptic problems and includes e. g.\ntransport dominated problems). As a result, Dune-DPG can also be used to\naddress other problems like optimal control with the DPG approach. \n\n"}
{"id": "1602.08643", "contents": "Title: On assessing the accuracy of defect free energy computations Abstract: We develop a rigorous error analysis for coarse-graining of defect-formation\nfree energy. For a one-dimensional constrained atomistic system, we establish\nthe thermodynamic limit of the defect-formation free energy and obtain\nexplicitly the rate of convergence. We then construct a sequence of\ncoarse-grained energies with the same rate but significantly reduced\ncomputational cost. We illustrate our analytical results through explicit\ncomputations for the case of harmonic potentials and through numerical\nsimulations. \n\n"}
{"id": "1603.00168", "contents": "Title: New optimized Schwarz algorithms for one dimensional Schr\\\"odinger\n  equation with general potential Abstract: The aim of this paper is to develop new optimized Schwarz algorithms for the\none dimensional Schr{\\\"o}dinger equation with linear or nonlinear potential.\nAfter presenting the classical algorithm which is an iterative process, we\npropose a new algorithm for the Schr{\\\"o}dinger equation with time-independent\nlinear potential. Thanks to two main ingredients (constructing explicitly the\ninterface problem and using a direct method on the interface problem), the new\nalgorithm turns to be a direct process. Thus, it is free to choose the\ntransmission condition. Concerning the case of time-dependent linear potential\nor nonlinear potential, we propose to use a pre-processed linear operator as\npreconditioner which leads to a preconditioned algorithm. Numerically , the\nconvergence is also independent of the transmission condition. In addition,\nboth of these new algorithms implemented in parallel cluster are robust,\nscalable up to 256 sub domains (MPI process) and take much less computation\ntime than the classical one, especially for the nonlinear case. \n\n"}
{"id": "1603.00211", "contents": "Title: On the Estimation Performance and Convergence Rate of the Generalized\n  Power Method for Phase Synchronization Abstract: An estimation problem of fundamental interest is that of phase\nsynchronization, in which the goal is to recover a collection of phases using\nnoisy measurements of relative phases. It is known that in the Gaussian noise\nsetting, the maximum likelihood estimator (MLE) has an expected squared\n$\\ell_2$-estimation error that is on the same order as the Cram\\'er-Rao lower\nbound. Moreover, even though the MLE is an optimal solution to a non-convex\nquadratic optimization problem, it can be found with high probability using\nsemidefinite programming (SDP), provided that the noise power is not too large.\nIn this paper, we study the estimation and convergence performance of a\nrecently-proposed low-complexity alternative to the SDP-based approach, namely,\nthe generalized power method (GPM). Our contribution is twofold. First, we\nbound the rate at which the estimation error decreases in each iteration of the\nGPM and use this bound to show that all iterates---not just the MLE---achieve\nan estimation error that is on the same order as the Cram\\'er-Rao bound. Our\nresult holds under the least restrictive assumption on the noise power and\ngives the best provable bound on the estimation error known to date. It also\nimplies that one can terminate the GPM at any iteration and still obtain an\nestimator that has a theoretical guarantee on its estimation error. Second, we\nshow that under the same assumption on the noise power as that for the\nSDP-based method, the GPM will converge to the MLE at a linear rate with high\nprobability. This answers a question raised in [3] and shows that the GPM is\ncompetitive in terms of both theoretical guarantees and numerical efficiency\nwith the SDP-based method. At the heart of our convergence rate analysis is a\nnew error bound for the non-convex quadratic optimization formulation of the\nphase synchronization problem, which could be of independent interest. \n\n"}
{"id": "1603.01184", "contents": "Title: Invariant domains preserving ALE approximation of hyperbolic systems\n  with continuous finite elements Abstract: A conservative invariant domain preserving Arbitrary Lagrangian Eulerian\nmethod for solving nonlinear hyperbolic systems is introduced. The method is\nexplicit in time, works with continuous finite elements and is first-order\naccurate in space. One originality of the present work is that the artificial\nviscosity is unambiguously defined irrespective of the mesh geometry/anisotropy\nand does not depend on any ad hoc parameter. The proposed method is meant to be\na stepping stone for the construction of higher-order methods in space by using\nappropriate limitation techniques. \n\n"}
{"id": "1603.01339", "contents": "Title: Numerical analysis of the Oseen-type Peterlin viscoelastic model by the\n  stabilized Lagrange-Galerkin method, Part I: A nonlinear scheme Abstract: We present a nonlinear stabilized Lagrange-Galerkin scheme for the Oseen-type\nPeterlin viscoelastic model. Our scheme is a combination of the method of\ncharacteristics and Brezzi-Pitk\\\"aranta's stabilization method for the\nconforming linear elements, which yields an efficient computation with a small\nnumber of degrees of freedom. We prove error estimates with the optimal\nconvergence order without any relation between the time increment and the mesh\nsize. The result is valid for both the diffusive and non-diffusive models for\nthe conformation tensor in two space dimensions. We introduce an additional\nterm that yields a suitable structural property and allows us to obtain\nrequired energy estimate. The theoretical convergence orders are confirmed by\nnumerical experiments. In a forthcoming paper, Part II, a linear scheme is\nproposed and the corresponding error estimates are proved in two and three\nspace dimensions for the diffusive model. \n\n"}
{"id": "1603.02429", "contents": "Title: A mixed-element two-grid discretization for Helmholtz transmission\n  eigenvalues Abstract: The Helmholtz transmission eigenvalue problem has received much concern in\nmaterials science, so it's significant to explore the efficient calculational\nmethod of the problem to mathematics and mechanics community. In this paper,\nbased on a variational formulation proposed by Cakon, Monk and Sun, we\nintroduce a mixed-element two-grid discretization and prove error estimates for\nthis method theoretically. Some numerical results are presented to confirm the\ntheoretical analysis and show that the method here is efficient. \n\n"}
{"id": "1603.04870", "contents": "Title: An Adaptive Finite Element Method in Quantitative Reconstruction of\n  Small Inclusions from Limited Observations Abstract: We consider a coefficient inverse problem for the dielectric permittivity in\nMaxwell's equations, with data consisting of boundary measurements of one or\ntwo backscattered or transmitted waves. The problem is treated using a\nLagrangian approach to the minimization of a Tikhonov functional, where an\nadaptive finite element method forms the basis of the computations. A new a\nposteriori error estimate for the coefficient is derived. The method is tested\nsuccessfully in numerical experiments for the reconstruction of two, three, and\nfour small inclusions with low contrast, as well as the reconstruction of a\nsuperposition of two Gaussian functions. \n\n"}
{"id": "1603.07008", "contents": "Title: A mixed precision semi-Lagrangian algorithm and its performance on\n  accelerators Abstract: In this paper we propose a mixed precision algorithm in the context of the\nsemi-Lagrangian discontinuous Galerkin method. The performance of this approach\nis evaluated on a traditional dual socket workstation as well as on a Xeon Phi\nand an NVIDIA K80. We find that the mixed precision algorithm can be\nimplemented efficiently on these architectures. This implies that, in addition\nto the considerable reduction in memory, a substantial increase in performance\ncan be observed as well. Moreover, we discuss the relative performance of our\nimplementations. \n\n"}
{"id": "1603.09133", "contents": "Title: \"Compress and eliminate\" solver for symmetric positive definite sparse\n  matrices Abstract: We propose a new approximate factorization for solving linear systems with\nsymmetric positive definite sparse matrices. In a nutshell the algorithm is to\napply hierarchically block Gaussian elimination and additionally compress the\nfill-in. The systems that have efficient compression of the fill-in mostly\narise from discretization of partial differential equations. We show that the\nresulting factorization can be used as an efficient preconditioner and compare\nthe proposed approach with state-of-art direct and iterative solvers. \n\n"}
{"id": "1603.09523", "contents": "Title: A multiscale method for linear elasticity reducing Poisson locking Abstract: We propose a generalized finite element method for linear elasticity\nequations with highly varying and oscillating coefficients. The method is\nformulated in the framework of localized orthogonal decomposition techniques\nintroduced by M{\\aa}lqvist and Peterseim (Math. Comp., 83(290): 2583--2603,\n2014). Assuming only $L_\\infty$-coefficients we prove linear convergence in the\n$H^1$-norm, also for materials with large Lam\\'{e} parameter $\\lambda$. The\ntheoretical a priori error estimate is confirmed by numerical examples. \n\n"}
{"id": "1604.01215", "contents": "Title: Vibrational resonance: a study with high-order word-series averaging Abstract: We study a model problem describing vibrational resonance by means of a\nhigh-order averaging technique based on so-called word series. With the tech-\nnique applied here, the tasks of constructing the averaged system and the\nassoci- ated change of variables are divided into two parts. It is first\nnecessary to build recursively a set of so-called word basis functions and,\nafter that, all the required manipulations involve only scalar coefficients\nthat are computed by means of sim- ple recursions. As distinct from the\nsituation with other approaches, with word- series, high-order averaged systems\nmay be derived without having to compute the associated change of variables. In\nthe system considered here, the construction of high-order averaged systems\nmakes it possible to obtain very precise approxima- tions to the true dynamics. \n\n"}
{"id": "1604.02614", "contents": "Title: On the performance of exponential integrators for problems in\n  magnetohydrodynamics Abstract: Exponential integrators have been introduced as an efficient alternative to\nexplicit and implicit methods for integrating large stiff systems of\ndifferential equations. Over the past decades these methods have been studied\ntheoretically and their performance was evaluated using a range of test\nproblems. While the results of these investigations showed that exponential\nintegrators can provide significant computational savings, the research on\nvalidating this hypothesis for large scale systems and understanding what\nclasses of problems can particularly benefit from the use of the new techniques\nis in its initial stages. Resistive magnetohydrodynamic (MHD) modeling is\nwidely used in studying large scale behavior of laboratory and astrophysical\nplasmas. In many problems numerical solution of MHD equations is a challenging\ntask due to the temporal stiffness of this system in the parameter regimes of\ninterest. In this paper we evaluate the performance of exponential integrators\non large MHD problems and compare them to a state-of-the-art implicit time\nintegrator. Both the variable and constant time step exponential methods of\nEpiRK-type are used to simulate magnetic reconnection and the Kelvin--Helmholtz\ninstability in plasma. Performance of these methods, which are part of the EPIC\nsoftware package, is compared to the variable time step variable order BDF\nscheme included in the CVODE (part of SUNDIALS) library. We study performance\nof the methods on parallel architectures and with respect to magnitudes of\nimportant parameters such as Reynolds, Lundquist, and Prandtl numbers. We find\nthat the exponential integrators provide superior or equal performance in most\ncircumstances and conclude that further development of exponential methods for\nMHD problems is warranted and can lead to significant computational advantages\nfor large scale stiff systems of differential equations such as MHD. \n\n"}
{"id": "1604.02810", "contents": "Title: High order approximation to non-smooth multivariate functions Abstract: Approximations of non-smooth multivariate functions return low-order\napproximations in the vicinities of the singularities. Most prior works solve\nthis problem for univariate functions. In this work we introduce a method for\napproximating non-smooth multivariate functions of the form $f = g + r_+$ where\n$g,r \\in C^{M+1}(\\mathbb{R}^n)$ and the function $r_+$ is defined by \\[ r_+(y)\n= \\left\\{ \\begin{array}{ll} r(y), & r(y) \\geq 0 \\\\ 0, & r(y) < 0 \\end{array}\n\\right. \\ , \\ \\forall y \\in \\mathbb{R}^n \\ . \\] Given scattered (or uniform)\ndata points $X \\subset \\mathbb{R}^n$, we investigate approximation by\nquasi-interpolation. We design a correction term, such that the corrected\napproximation achieves full approximation order on the entire domain. We also\nshow that the correction term is the solution to a Moving Least Squares (MLS)\nproblem, and as such can both be easily computed and is smooth. Last, we prove\nthat the suggested method includes a high-order approximation to the locations\nof the singularities. \n\n"}
{"id": "1604.04586", "contents": "Title: Robust Reduced-Order Model Stabilization for Partial Differential\n  Equations Based on Lyapunov Theory and Extremum Seeking with Application to\n  the 3D Boussinesq Equations Abstract: We present some results on stabilization for reduced-order models (ROMs) of\npartial differential equations. The stabilization is achieved using Lyapunov\ntheory to design a new closure model that is robust to parametric\nuncertainties. The free parameters in the proposed ROM stabilization method are\noptimized using a model-free multi-parametric extremum seeking (MES) algorithm.\nThe 3D Boussinesq equations provide a challenging numerical test-problem that\nis used to demonstrate the advantages of the proposed method. \n\n"}
{"id": "1604.05764", "contents": "Title: A Mixed Finite Element Method to Solve the EEG Forward Problem Abstract: Finite element methods have been shown to achieve high accuracies in\nnumerically solving the EEG forward problem and they enable the realistic\nmodeling of complex geometries and important conductive features such as\nanisotropic conductivities. To date, most of the presented approaches rely on\nthe same underlying formulation, the continuous Galerkin (CG)-FEM. In this\narticle, a novel approach to solve the EEG forward problem based on a mixed\nfinite element method (Mixed-FEM) is introduced. To obtain the Mixed-FEM\nformulation, the electric current is introduced as an additional unknown\nbesides the electric potential. As a consequence of this derivation, the\nMixed-FEM is, by construction, current preserving, in contrast to the CG-FEM.\nConsequently, a higher simulation accuracy can be achieved in certain\nscenarios, e.g., when the diameter of thin insulating structures, such as the\nskull, is in the range of the mesh resolution.\n  A theoretical derivation of the Mixed-FEM approach for EEG forward\nsimulations is presented, and the algorithms implemented for solving the\nresulting equation systems are described. Subsequently, first evaluations in\nboth sphere and realistic head models are presented, and the results are\ncompared to previously introduced CG-FEM approaches. Additional visualizations\nare shown to illustrate the current preserving property of the Mixed-FEM.\n  Based on these results, it is concluded that the newly presented Mixed-FEM\ncan at least complement and in some scenarios even outperform the established\nCG-FEM approaches, which motivates a further evaluation of the Mixed-FEM for\napplications in bioelectromagnetism. \n\n"}
{"id": "1604.05953", "contents": "Title: On the construction of Lyapunov functions with computer assistance Abstract: Computer assisted procedures of Lyapunov functions defined in given\nneighborhoods of fixed points for flows and maps are discussed. We provide a\nsystematic methodology for constructing explicit ranges where quadratic\nLyapunov functions exist in two stages; negative definiteness of associating\nmatrices and direct approach. We note that the former is equivalent to the\nprocedure of cones describing enclosures of the stable and the unstable\nmanifolds of invariant sets, which gives us flexible discussions of asymptotic\nbehavior not only around equilibria for flows but also fixed points for maps.\nAdditionally, our procedure admits a re-parameterization of trajectories in\nterms of values of Lyapunov functions. Several verification examples are shown\nfor discussions of applicability. \n\n"}
{"id": "1604.06830", "contents": "Title: Computing localized representations of the kohn-sham subspace via\n  randomization and refinement Abstract: Localized representation of the Kohn-Sham subspace plays an important role in\nquantum chemistry and materials science. The recently developed selected\ncolumns of the density matrix (SCDM) method [J. Chem. Theory Comput. 11, 1463,\n2015] is a simple and robust procedure for finding a localized representation\nof a set of Kohn-Sham orbitals from an insulating system. The SCDM method\nallows the direct construction of a well conditioned (or even orthonormal) and\nlocalized basis for the Kohn-Sham subspace. The SCDM algorithm avoids the use\nof an optimization procedure and does not depend on any adjustable parameters.\nThe most computationally expensive step of the SCDM method is a column pivoted\nQR factorization that identifies the important columns for constructing the\nlocalized basis set. In this paper, we develop a two stage approximate column\nselection strategy to find the important columns at much lower computational\ncost. We demonstrate the effectiveness of this process using the dissociation\nprocess of a BH$_3$NH$_3$ molecule, an alkane chain and a supercell with 256\nwater molecules. Numerical results for the large collection of water molecules\nshow that two stage localization procedure can be more than 30 times faster\nthan the original SCDM algorithm and compares favorably with the popular\nWannier90 package. \n\n"}
{"id": "1604.07188", "contents": "Title: Approximations for the Caputo derivative (II) Abstract: In the present paper we use the expansion formula of the polylogarithm\nfunction to construct approximations of the Caputo derivative which are related\nto the midpoint approximation of the integral in the definition of the Caputo\nderivative. The asymptotic expansion formula of the Riemann sum approximation\nof the beta function and the first terms of the expansion formulas of the\napproximations of the Caputo derivative of the power function are obtained in\nthe paper. The induced shifted approximations of the Gr\\\"unwald formula and the\napproximations of the Caputo derivative studied in the first part of the paper\nare constructed and applied for numerical solution of fractional differential\nequations. \n\n"}
{"id": "1604.07846", "contents": "Title: Approximation and orthogonality in Sobolev spaces on a triangle Abstract: Approximation by polynomials on a triangle is studied in the Sobolev space\n$W_2^r$ that consists of functions whose derivatives of up to $r$-th order have\nbounded $L^2$ norm. The first part aims at understanding the orthogonal\nstructure in the Sobolev space on the triangle, which requires explicit\nconstruction of an inner product that involves derivatives and its associated\northogonal polynomials, so that the projection operators of the corresponding\nFourier orthogonal expansion commute with partial derivatives. The second part\nestablishes the sharp estimate for the error of polynomial approximation in\n$W_2^r$, when $r = 1$ and $r=2$, where the polynomials of approximation are the\npartial sums of the Fourier expansions in orthogonal polynomials of the Sobolev\nspace. \n\n"}
{"id": "1604.07903", "contents": "Title: Conforming mixed triangular prism and nonconforming mixed tetrahedral\n  elements for the linear elasticity problem Abstract: We propose two families of mixed finite elements for solving the classical\nHellinger-Reissner mixed problem of the linear elasticity equations in three\ndimensions. First, a family of conforming mixed triangular prism elements is\nconstructed by product of elements on triangular meshes and elements in one\ndimension. The well-posedness is established for all elements with $k\\geq1$,\nwhich are of $k+1$ order convergence for both the stress and displacement.\nBesides, a family of reduced stress spaces is proposed by dropping the degrees\nof polynomial functions associated with faces. As a result, the lowest order\nconforming mixed triangular prism element has 93 plus 33 degrees of freedom on\neach element. Second, we construct a new family of nonconforming mixed\ntetrahedral elements. The shape function spaces of our stress spaces are\ndifferent from those of the elements in literature. \n\n"}
{"id": "1604.08410", "contents": "Title: Comparison between cell-centered and nodal based discretization schemes\n  for linear elasticity Abstract: In this paper we study newly developed methods for linear elasticity on\npolyhedral meshes. Our emphasis is on applications of the methods to geological\nmodels. Models of subsurface, and in particular sedimentary rocks, naturally\nlead to general polyhedral meshes. Numerical methods which can directly handle\nsuch representation are highly desirable. Many of the numerical challenges in\nsimulation of subsurface applications come from the lack of robustness and\naccuracy of numerical methods in the case of highly distorted grids. In this\npaper we investigate and compare the Multi-Point Stress Approximation (MPSA)\nand the Virtual Element Method (VEM) with regards to grid features that are\nfrequently seen in geological models and likely to lead to a lack of accuracy\nof the methods. In particular we look how the methods perform near the\nincompressible limit. This work shows that both methods are promising for\nflexible modeling of subsurface mechanics. \n\n"}
{"id": "1604.08466", "contents": "Title: Sparse Quadrature for High-Dimensional Integration with Gaussian Measure Abstract: In this work we analyze the dimension-independent convergence property of an\nabstract sparse quadrature scheme for numerical integration of functions of\nhigh-dimensional parameters with Gaussian measure. Under certain assumptions of\nthe exactness and the boundedness of univariate quadrature rules as well as the\nregularity of the parametric functions with respect to the parameters, we\nobtain the convergence rate $O(N^{-s})$, where $N$ is the number of indices,\nand $s$ is independent of the number of the parameter dimensions. Moreover, we\npropose both an a-priori and an a-posteriori schemes for the construction of a\npractical sparse quadrature rule and perform numerical experiments to\ndemonstrate their dimension-independent convergence rates. \n\n"}
{"id": "1604.08714", "contents": "Title: Iterative Multiplicative Filters for Data Labeling Abstract: Based on an idea in [4] we propose a new iterative multiplicative filtering\nalgorithm for label assignment matrices which can be used for the supervised\npartitioning of data. Starting with a row-normalized matrix containing the\naveraged distances between prior features and the observed ones the method\nassigns in a very efficient way labels to the data. We interpret the algorithm\nas a gradient ascent method with respect to a certain function on the product\nmanifold of positive numbers followed by a reprojection onto a subset of the\nprobability simplex consisting of vectors whose components are bounded away\nfrom zero by a small constant. While such boundedness away from zero is\nnecessary to avoid an arithmetic underflow, our convergence results imply that\nthey are also necessary for theoretical reasons. Numerical examples show that\nthe proposed simple and fast algorithm leads to very good results. In\nparticular we apply the method for the partitioning of manifold-valued images. \n\n"}
{"id": "1605.00397", "contents": "Title: Rank two perturbations of matrices and operators and operator model for\n  t-transformation of probability measures Abstract: Rank two parametric perturbations of operators and matrices are studied in\nvarious settings. In the finite dimensional case the formula for a\ncharacteristic polynomial is derived and the large parameter asymptotics of the\nspectrum is computed. The large parameter asymptotics of a rank one\nperturbation of singular values and condition number are discussed as well. In\nthe operator case the formula for a rank two transformation of the spectral\nmeasure is derived and it appears to be the t-transformation of a probability\nmeasure, studied previously in the free probability context. New transformation\nof measures is studied and several examples are presented. \n\n"}
{"id": "1605.01036", "contents": "Title: Orbital minimization method with $\\ell^1$ regularization Abstract: We consider a modification of the OMM energy functional which contains an\n$\\ell^1$ penalty term in order to find a sparse representation of the low-lying\neigenspace of self-adjoint operators. We analyze the local minima of the\nmodified functional as well as the convergence of the modified functional to\nthe original functional. Algorithms combining soft thresholding with gradient\ndescent are proposed for minimizing this new functional. Numerical tests\nvalidate our approach. As an added bonus, we also prove the unanticipated and\nremarkable property that every local minimum the OMM functional without the\n$\\ell^1$ term is also a global minimum. \n\n"}
{"id": "1605.01595", "contents": "Title: Inexact Arnoldi residual estimates and decay properties for functions of\n  non-Hermitian matrices Abstract: We derive a priori residual-type bounds for the Arnoldi approximation of a\nmatrix function and a strategy for setting the iteration accuracies in the\ninexact Arnoldi approximation of matrix functions. Such results are based on\nthe decay behavior of the entries of functions of banded matrices.\nSpecifically, we will use a priori decay bounds for the entries of functions of\nbanded non-Hermitian matrices by using Faber polynomial series. Numerical\nexperiments illustrate the quality of the results. \n\n"}
{"id": "1605.01805", "contents": "Title: Wave-shape function analysis -- when cepstrum meets time-frequency\n  analysis Abstract: We propose to combine cepstrum and nonlinear time-frequency (TF) analysis to\nstudy mutiple component oscillatory signals with time-varying frequency and\namplitude and with time-varying non-sinusoidal oscillatory pattern. The concept\nof cepstrum is applied to eliminate the wave-shape function influence on the TF\nanalysis, and we propose a new algorithm, named de-shape synchrosqueezing\ntransform (de-shape SST). The mathematical model, adaptive non-harmonic model,\nis introduced and the de-shape SST algorithm is theoretically analyzed. In\naddition to simulated signals, several different physiological, musical and\nbiological signals are analyzed to illustrate the proposed algorithm. \n\n"}
{"id": "1605.02141", "contents": "Title: Low Rank Approximation in $G_0W_0$ Approximation Abstract: The single particle energies obtained in a Kohn--Sham density functional\ntheory (DFT) calculation are generally known to be poor approximations to\nelectron excitation energies that are measured in transport, tunneling and\nspectroscopic experiments such as photo-emission spectroscopy. The correction\nto these energies can be obtained from the poles of a single particle Green's\nfunction derived from a many-body perturbation theory. From a computational\nperspective, the accuracy and efficiency of such an approach depends on how a\nself energy term that properly accounts for dynamic screening of electrons is\napproximated. The $G_0W_0$ approximation is a widely used technique in which\nthe self energy is expressed as the convolution of a non-interacting Green's\nfunction ($G_0$) and a screened Coulomb interaction ($W_0$) in the frequency\ndomain. The computational cost associated with such a convolution is high due\nto the high complexity of evaluating $W_0$ at multiple frequencies. In this\npaper, we discuss how the cost of $G_0W_0$ calculation can be reduced by\nconstructing a low rank approximation to the frequency dependent part of $W_0$.\nIn particular, we examine the effect of such a low rank approximation on the\naccuracy of the $G_0W_0$ approximation. We also discuss how the numerical\nconvolution of $G_0$ and $W_0$ can be evaluated efficiently and accurately by\nusing a contour deformation technique with an appropriate choice of the\ncontour. \n\n"}
{"id": "1605.02858", "contents": "Title: Preconditioned Implicit-Exponential (IMEXP) Time Integrators for Stiff\n  Differential Equations Abstract: We propose two new classes of time integrators for stiff DEs: the\nimplicit-explicit exponential (IMEXP) and the hybrid exponential methods. In\ncontrast to the existing exponential schemes, the new methods offer significant\ncomputational advantages when used with preconditioners. Any preconditioner can\nbe used with any of these new schemes. This leads to a broader applicability of\nexponential methods. The proof of stability and convergence of these\nintegrators and numerical demonstration of their efficiency are presented. \n\n"}
{"id": "1605.03400", "contents": "Title: A new Heterogeneous Multiscale Method for the Helmholtz equation with\n  high contrast Abstract: In this paper, we suggest a new Heterogeneous Multiscale Method (HMM) for the\nHelmholtz equation with high contrast. The method is constructed for a setting\nas in Bouchitt\\'e and Felbacq (C.R. Math. Acad. Sci. Paris 339(5):377--382,\n2004), where the high contrast in the parameter leads to unusual effective\nparameters in the homogenized equation. We revisit existing homogenization\napproaches for this special setting and analyze the stability of the two-scale\nsolution with respect to the wavenumber and the data. This includes a new\nstability result for solutions to the Helmholtz equation with discontinuous\ndiffusion matrix. The HMM is defined as direct discretization of the two-scale\nlimit equation.\n  With this approach we are able to show quasi-optimality and an a priori error\nestimate under a resolution condition that inherits its dependence on the\nwavenumber from the stability constant for the analytical problem. Numerical\nexperiments confirm our theoretical convergence results and examine the\nresolution condition. Moreover, the numerical simulation gives a good insight\nand explanation of the physical phenomenon of frequency band gaps. \n\n"}
{"id": "1605.03910", "contents": "Title: An efficient Monte Carlo interior penalty discontinuous Galerkin method\n  for elastic wave scattering in random media Abstract: This paper develops and analyzes an efficient Monte Carlo interior penalty\ndiscontinuous Galerkin (MCIP-DG) method for elastic wave scattering in random\nmedia. The method is constructed based on a multi-modes expansion of the\nsolution of the governing random partial differential equations. It is proved\nthat the mode functions satisfy a three-term recurrence system of partial\ndifferential equations (PDEs) which are nearly deterministic in the sense that\nthe randomness only appears in the right-hand side source terms, not in the\ncoefficients of the PDEs. Moreover, the same differential operator applies to\nall mode functions. A proven unconditionally stable and optimally convergent\nIP-DG method is used to discretize the deterministic PDE operator, an efficient\nnumerical algorithm is proposed based on combining the Monte Carlo method and\nthe IP-DG method with the $LU$ direct linear solver. It is shown that the\nalgorithm converges optimally with respect to both the mesh size $h$ and the\nsampling number $M$, and practically its total computational complexity is only\namount to solving very few deterministic elastic Helmholtz equations using the\n$LU$ direct linear solver. Numerically experiments are also presented to\ndemonstrate the performance and key features of the proposed MCIP-DG method. \n\n"}
{"id": "1605.05898", "contents": "Title: Well-posed Bayesian inverse problems and heavy-tailed stable\n  quasi-Banach space priors Abstract: This article extends the framework of Bayesian inverse problems in\ninfinite-dimensional parameter spaces, as advocated by Stuart (Acta Numer.\n19:451--559, 2010) and others, to the case of a heavy-tailed prior measure in\nthe family of stable distributions, such as an infinite-dimensional Cauchy\ndistribution, for which polynomial moments are infinite or undefined. It is\nshown that analogues of the Karhunen--Lo\\`eve expansion for square-integrable\nrandom variables can be used to sample such measures on quasi-Banach spaces.\nFurthermore, under weaker regularity assumptions than those used to date, the\nBayesian posterior measure is shown to depend Lipschitz continuously in the\nHellinger metric upon perturbations of the misfit function and observed data. \n\n"}
{"id": "1605.05921", "contents": "Title: Numerical simulation of nonlinear continuity equations by evolving\n  diffeomorphisms Abstract: In this paper we present a numerical scheme for nonlinear continuity\nequations, which is based on the gradient flow formulation of an energy\nfunctional with respect to the quadratic transportation distance. It can be\napplied to a large class of nonlinear continuity equations, whose dynamics are\ndriven by internal energies, given external potentials and/or interaction\nenergies. The solver is based on its variational formulation as a gradient flow\nwith respect to the Wasserstein distance. Positivity of solutions as well as\nenergy decrease of the semi-discrete scheme are guaranteed by its construction.\nWe illustrate this properties with various examples in spatial dimension one\nand two. \n\n"}
{"id": "1605.07031", "contents": "Title: An adaptive non-symmetric finite volume and boundary element coupling\n  method for a fluid mechanics interface problem Abstract: We consider an interface problem often arising in transport problems: a\ncoupled system of partial differential equations with one (elliptic) transport\nequation on a bounded domain and one equation (in this case the Laplace\nproblem) on the complement, an unbounded domain. Based on the non-symmetric\ncoupling of the finite volume method and boundary element method of [Erath et\nal., arXiv:1509.00440, 2015] we introduce a robust residual error estimator.\nThe upper bound of the error in an energy (semi)norm is robust against\nvariation of the model data. The lower bound, however, additionally depends on\nthe Peclet number. In several examples we use the local contributions of the\na~posteriori error estimator to steer an adaptive mesh-refining algorithm. The\nadaptive FVM-BEM coupling turns out to be an efficient method especially to\nsolve problems from fluid mechanics, mainly because of the local flux\nconservation and the stable approximation of convection dominated problems. \n\n"}
{"id": "1605.07730", "contents": "Title: Convergence analysis of the Generalized Empirical Interpolation Method Abstract: Let $F$ be a compact set of a Banach space $\\mathcal{X}$. This paper analyses\nthe \"Generalized Empirical Interpolation Method\" (GEIM) which, given a function\n$f\\in F$, builds an interpolant $\\mathcal{J}_n[f]$ in an $n$-dimensional\nsubspace $X_n \\subset \\mathcal{X}$ with the knowledge of $n$ outputs\n$(\\sigma_i(f))_{i=1}^n$, where $\\sigma_i\\in \\mathcal{X}'$ and $\\mathcal{X}'$ is\nthe dual space of $\\mathcal{X}$. The space $X_n$ is built with a greedy\nalgorithm that is adapted to $F$ in the sense that it is generated by elements\nof $F$ itself. The algorithm also selects the linear functionals\n$(\\sigma_i)_{i=1}^n$ from a dictionary $\\Sigma\\subset \\mathcal{X}'$. In this\npaper, we study the interpolation error $\\max_{f\\in F} \\Vert\nf-\\mathcal{J}_n[f]\\Vert_{\\mathcal{X}}$ by comparing it with the best possible\nperformance on an $n$-dimensional space, i.e., the Kolmogorov $n$-width of $F$\nin $\\mathcal{X}$, $d_n(F,\\mathcal{X})$. For polynomial or exponential decay\nrates of $d_n(F,\\mathcal{X})$, we prove that the interpolation error has the\nsame behavior modulo the norm of the interpolation operator. Sharper results\nare obtained in the case where $\\mathcal X$ is a Hilbert space. \n\n"}
{"id": "1605.07811", "contents": "Title: Probabilistic Numerical Methods for Partial Differential Equations and\n  Bayesian Inverse Problems Abstract: This paper develops a probabilistic numerical method for solution of partial\ndifferential equations (PDEs) and studies application of that method to\nPDE-constrained inverse problems. This approach enables the solution of\nchallenging inverse problems whilst accounting, in a statistically principled\nway, for the impact of discretisation error due to numerical solution of the\nPDE. In particular, the approach confers robustness to failure of the numerical\nPDE solver, with statistical inferences driven to be more conservative in the\npresence of substantial discretisation error. Going further, the problem of\nchoosing a PDE solver is cast as a problem in the Bayesian design of\nexperiments, where the aim is to minimise the impact of solver error on\nstatistical inferences; here the challenge of non-linear PDEs is also\nconsidered. The method is applied to parameter inference problems in which\ndiscretisation error in non-negligible and must be accounted for in order to\nreach conclusions that are statistically valid. \n\n"}
{"id": "1605.08527", "contents": "Title: Stochastic Optimization for Large-scale Optimal Transport Abstract: Optimal transport (OT) defines a powerful framework to compare probability\ndistributions in a geometrically faithful way. However, the practical impact of\nOT is still limited because of its computational burden. We propose a new class\nof stochastic optimization algorithms to cope with large-scale problems\nroutinely encountered in machine learning applications. These methods are able\nto manipulate arbitrary distributions (either discrete or continuous) by simply\nrequiring to be able to draw samples from them, which is the typical setup in\nhigh-dimensional learning problems. This alleviates the need to discretize\nthese densities, while giving access to provably convergent methods that output\nthe correct distance without discretization error. These algorithms rely on two\nmain ideas: (a) the dual OT problem can be re-cast as the maximization of an\nexpectation ; (b) entropic regularization of the primal OT problem results in a\nsmooth dual optimization optimization which can be addressed with algorithms\nthat have a provably faster convergence. We instantiate these ideas in three\ndifferent setups: (i) when comparing a discrete distribution to another, we\nshow that incremental stochastic optimization schemes can beat Sinkhorn's\nalgorithm, the current state-of-the-art finite dimensional OT solver; (ii) when\ncomparing a discrete distribution to a continuous density, a semi-discrete\nreformulation of the dual program is amenable to averaged stochastic gradient\ndescent, leading to better performance than approximately solving the problem\nby discretization ; (iii) when dealing with two continuous densities, we\npropose a stochastic gradient descent over a reproducing kernel Hilbert space\n(RKHS). This is currently the only known method to solve this problem, apart\nfrom computing OT on finite samples. We backup these claims on a set of\ndiscrete, semi-discrete and continuous benchmark problems. \n\n"}
{"id": "1605.08754", "contents": "Title: Faster Eigenvector Computation via Shift-and-Invert Preconditioning Abstract: We give faster algorithms and improved sample complexities for estimating the\ntop eigenvector of a matrix $\\Sigma$ -- i.e. computing a unit vector $x$ such\nthat $x^T \\Sigma x \\ge (1-\\epsilon)\\lambda_1(\\Sigma)$:\n  Offline Eigenvector Estimation: Given an explicit $A \\in \\mathbb{R}^{n \\times\nd}$ with $\\Sigma = A^TA$, we show how to compute an $\\epsilon$ approximate top\neigenvector in time $\\tilde O([nnz(A) + \\frac{d*sr(A)}{gap^2} ]* \\log\n1/\\epsilon )$ and $\\tilde O([\\frac{nnz(A)^{3/4} (d*sr(A))^{1/4}}{\\sqrt{gap}} ]\n* \\log 1/\\epsilon )$. Here $nnz(A)$ is the number of nonzeros in $A$, $sr(A)$\nis the stable rank, $gap$ is the relative eigengap. By separating the $gap$\ndependence from the $nnz(A)$ term, our first runtime improves upon the\nclassical power and Lanczos methods. It also improves prior work using fast\nsubspace embeddings [AC09, CW13] and stochastic optimization [Sha15c], giving\nsignificantly better dependencies on $sr(A)$ and $\\epsilon$. Our second running\ntime improves these further when $nnz(A) \\le \\frac{d*sr(A)}{gap^2}$.\n  Online Eigenvector Estimation: Given a distribution $D$ with covariance\nmatrix $\\Sigma$ and a vector $x_0$ which is an $O(gap)$ approximate top\neigenvector for $\\Sigma$, we show how to refine to an $\\epsilon$ approximation\nusing $ O(\\frac{var(D)}{gap*\\epsilon})$ samples from $D$. Here $var(D)$ is a\nnatural notion of variance. Combining our algorithm with previous work to\ninitialize $x_0$, we obtain improved sample complexity and runtime results\nunder a variety of assumptions on $D$.\n  We achieve our results using a general framework that we believe is of\nindependent interest. We give a robust analysis of the classic method of\nshift-and-invert preconditioning to reduce eigenvector computation to\napproximately solving a sequence of linear systems. We then apply fast\nstochastic variance reduced gradient (SVRG) based system solvers to achieve our\nclaims. \n\n"}
{"id": "1606.01465", "contents": "Title: Numerical Study of Nonlinear Dispersive Wave Models with SpecTraVVave Abstract: In nonlinear dispersive evolution equations, the competing effects of\nnonlinearity and dispersion make a number of interesting phenomena possible. In\nthe current work, the focus is on the numerical approximation of traveling-wave\nsolutions of such equations. We describe our efforts to write a dedicated\nPython code which is able to compute traveling-wave solutions of nonlinear\ndispersive equations of the general form \\begin{equation*} u_t + [f(u)]_{x} +\n\\mathcal{L} u_x = 0, \\end{equation*} where $\\mathcal{L}$ is a self-adjoint\noperator, and $f$ is a real-valued function with $f(0) = 0$.\n  The SpectraVVave code uses a continuation method coupled with a spectral\nprojection to compute approximations of steady symmetric solutions of this\nequation. The code is used in a number of situations to gain an understanding\nof traveling-wave solutions. The first case is the Whitham equation, where\nnumerical evidence points to the conclusion that the main bifurcation branch\nfeatures three distinct points of interest, namely a turning point, a point of\nstability inversion, and a terminal point which corresponds to a cusped wave.\n  The second case is the so-called modified Benjamin-Ono equation where the\ninteraction of two solitary waves is investigated. It is found that is possible\nfor two solitary waves to interact in such a way that the smaller wave is\nannihilated. The third case concerns the Benjamin equation which features two\ncompeting dispersive operators. In this case, it is found that bifurcation\ncurves of periodic traveling-wave solutions may cross and connect high up on\nthe branch in the nonlinear regime. \n\n"}
{"id": "1606.03650", "contents": "Title: Generalized Variational Source Condition Associated with the Bregman\n  Distance-I: Verification of the Variational Source Condition and Stability of\n  the Total Error Estimation Abstract: A general deterministic analysis to state the necessary conditions with a\ncoefficient determination for the variational source condition to hold is\nprovided. Of particular interest in terms of the choice of the regularization\nparameter, it is revealed that Morozov's discrepancy principle can be used both\nfor determining new stable lower and upper bounds for the regularization\nparameter. With these bounds, it is also possible to establish quantitative\nestimations for the index function as well as for the different definitions of\nthe Bregman distance. Inclusion of the variational source condition into the\nstability analysis enables one to re-establish convergence and convergence rate\nresults in terms of the index function. The coefficient in the variational\nsource condition is explicitly defined as a multivariable function of constants\nin Morozov's discrepancy principle. As expected, the results here are\napplicable when any strictly convex, smooth/non-smooth objective functional is\nconsidered. \n\n"}
{"id": "1606.04567", "contents": "Title: Regression-based reduced-order models to predict transient thermal\n  output for enhanced geothermal systems Abstract: The goal of this paper is to assess the utility of Reduced-Order Models\n(ROMs) developed from 3D physics-based models for predicting transient thermal\npower output for an enhanced geothermal reservoir while explicitly accounting\nfor uncertainties in the subsurface system and site-specific details. Numerical\nsimulations are performed based on Latin Hypercube Sampling (LHS) of model\ninputs drawn from uniform probability distributions. Key sensitive parameters\nare identified from these simulations, which are fracture zone permeability,\nwell/skin factor, bottom hole pressure, and injection flow rate. The inputs for\nROMs are based on these key sensitive parameters. The ROMs are then used to\nevaluate the influence of subsurface attributes on thermal power production\ncurves. The resulting ROMs are compared with field-data and the detailed\nphysics-based numerical simulations. We propose three different ROMs with\ndifferent levels of model parsimony, each describing key and essential features\nof the power production curves. ROM-1 is able to accurately reproduce the power\noutput of numerical simulations for low values of permeabilities and certain\nfeatures of the field-scale data, and is relatively parsimonious. ROM-2 is a\nmore complex model than ROM-1 but it accurately describes the field-data. At\nhigher permeabilities, ROM-2 reproduces numerical results better than ROM-1,\nhowever, there is a considerable deviation at low fracture zone permeabilities.\nROM-3 is developed by taking the best aspects of ROM-1 and ROM-2 and provides a\nmiddle ground for model parsimony. It is able to describe various features of\nnumerical simulations and field-data. From the proposed workflow, we\ndemonstrate that the proposed simple ROMs are able to capture various complex\nfeatures of the power production curves of Fenton Hill HDR system. For typical\nEGS applications, ROM-2 and ROM-3 outperform ROM-1. \n\n"}
{"id": "1606.04588", "contents": "Title: Bernstein modal basis: application to the spectral Petrov-Galerkin\n  method for fractional partial differential equations Abstract: In the spectral Petrov-Galerkin methods, the trial and test functions are\nrequired to satisfy particular boundary conditions. By a suitable linear\ncombination of orthogonal polynomials, a basis, that is called the modal basis,\nis obtained. In this paper, we extend this idea to the non-orthogonal dual\nBernstein polynomials. A compact general formula is derived for the modal basis\nfunctions based on dual Bernstein polynomials. Then, we present a\nBernstein-spectral Petrov-Galerkin method for a class of time fractional\npartial differential equations with Caputo derivative. It is shown that the\nmethod leads to banded sparse linear systems for problems with constant\ncoefficient. Some numerical examples are provided to show the efficiency and\nthe spectral accuracy of the method. \n\n"}
{"id": "1606.04804", "contents": "Title: Ambiguities in one-dimensional phase retrieval from magnitudes of a\n  linear canonical transform Abstract: Phase retrieval problems occur in a wide range of applications in physics and\nengineering. Usually, these problems consist in the recovery of an unknown\nsignal from the magnitudes of its Fourier transform. In some applications,\nhowever, the given intensity arises from a different transformation such as the\nFresnel or fractional Fourier transform. More generally, we here consider the\nphase retrieval of an unknown signal from the magnitudes of an arbitrary linear\ncanonical transform. Using the close relation between the Fourier and the\nlinear canonical transform, we investigate the arising ambiguities of these\nphase retrieval problems and transfer the well-known characterizations of the\nsolution sets from the classical Fourier phase retrieval problem to the new\nsetting. \n\n"}
{"id": "1606.05070", "contents": "Title: Localized Reduced Basis Approximation of a Nonlinear Finite Volume\n  Battery Model with Resolved Electrode Geometry Abstract: In this contribution we present first results towards localized model order\nreduction for spatially resolved, three-dimensional lithium-ionbattery models.\nWe introduce a localized reduced basis scheme based on non-conforming local\napproximation spaces stemming from a finite volume discretizationof the\nanalytical model and localized empirical operator interpolation for the\napproximation of the model's nonlinearities. Numerical examples are provided\nindicating the feasibility of our approach. \n\n"}
{"id": "1606.05306", "contents": "Title: Exact Recovery of Discrete Measures from Wigner D-Moments Abstract: In this paper, we show the possibility of recovering a sum of Dirac measures\non the rotation group $SO(3)$ from its low degree moments with respect to\nWigner D-functions only. The main Theorem of the paper states, that exact\nrecovery from moments up to degree $N$ is possible, if the support set of the\nmeasure obeys a separation distance of $\\frac{36}{N+1}$. In this case, the\nsought measure is the unique solution of a total variation minimization. The\nproof of the uniqueness requires localization estimates for interpolation\nkernels and corresponding derivatives on the rotation group $SO(3)$ with\nexplicit constants. \n\n"}
{"id": "1606.05365", "contents": "Title: Improved sampling and validation of frozen Gaussian approximation with\n  surface hopping algorithm for nonadiabatic dynamics Abstract: In the spirit of the fewest switches surface hopping, the frozen Gaussian\napproximation with surface hopping (FGA-SH) method samples a path integral\nrepresentation of the non-adiabatic dynamics in the semiclassical regime. An\nimproved sampling scheme is developed in this work for FGA-SH based on birth\nand death branching processes. The algorithm is validated for the standard test\nexamples of non-adiabatic dynamics. \n\n"}
{"id": "1606.05631", "contents": "Title: Variational formulation and numerical analysis of linear elliptic\n  equations in nondivergence form with Cordes coefficients Abstract: This paper studies formulations of second-order elliptic partial differential\nequations in nondivergence form on convex domains as equivalent variational\nproblems. The first formulation is that of Smears \\& S\\\"uli [SIAM J.\\ Numer.\\\nAnal.\\ 51(2013), pp.\\ 2088--2106.], and the second one is a new symmetric\nformulation based on a least-squares functional. These formulations enable the\nuse of standard finite element techniques for variational problems in subspaces\nof $H^2$ as well as mixed finite element methods from the context of fluid\ncomputations. Besides the immediate quasi-optimal a~priori error bounds, the\nvariational setting allows for a~posteriori error control with explicit\nconstants and adaptive mesh-refinement. The convergence of an adaptive\nalgorithm is proved. Numerical results on uniform and adaptive meshes are\nincluded. \n\n"}
{"id": "1606.07615", "contents": "Title: A new approach for solving nonlinear Thomas-Fermi equation based on\n  fractional order of rational Bessel functions Abstract: In this paper, the fractional order of rational Bessel functions collocation\nmethod (FRBC) to solve Thomas-Fermi equation which is defined in the\nsemi-infinite domain and has singularity at $x = 0$ and its boundary condition\noccurs at infinity, have been introduced. We solve the problem on semi-infinite\ndomain without any domain truncation or transformation of the domain of the\nproblem to a finite domain. This approach at first, obtains a sequence of\nlinear differential equations by using the quasilinearization method (QLM),\nthen at each iteration solves it by FRBC method. To illustrate the reliability\nof this work, we compare the numerical results of the present method with some\nwell-known results in other to show that the new method is accurate, efficient\nand applicable. \n\n"}
{"id": "1606.08740", "contents": "Title: Alternating Anderson-Richardson method: An efficient alternative to\n  preconditioned Krylov methods for large, sparse linear systems Abstract: We present the Alternating Anderson-Richardson (AAR) method: an efficient and\nscalable alternative to preconditioned Krylov solvers for the solution of\nlarge, sparse linear systems on high performance computing platforms.\nSpecifically, we generalize the recently proposed Alternating Anderson-Jacobi\n(AAJ) method (Pratapa et al., J. Comput. Phys. (2016), 306, 43--54) to include\npreconditioning, discuss efficient parallel implementation, and provide serial\nMATLAB and parallel C/C++ implementations. In serial applications to\nnonsymmetric systems, we find that AAR is comparably robust to GMRES, using the\nsame preconditioning, while often outperforming it in time to solution; and\nfind AAR to be more robust than Bi-CGSTAB for the problems considered. In\nparallel applications to the Helmholtz and Poisson equations, we find that AAR\nshows superior strong and weak scaling to GMRES, Bi-CGSTAB, and Conjugate\nGradient (CG) methods, using the same preconditioning, with consistently\nshorter times to solution at larger processor counts. Finally, in massively\nparallel applications to the Poisson equation, on up to 110,592 processors, we\nfind that AAR shows superior strong and weak scaling to CG, with shorter\nminimum time to solution. We thus find that AAR offers a robust and efficient\nalternative to current state-of-the-art solvers, with increasing advantages as\nthe number of processors grows. \n\n"}
{"id": "1606.09218", "contents": "Title: Range-separated tensor formats for numerical modeling of many-particle\n  interaction potentials Abstract: We introduce and analyze the new range-separated (RS) canonical/Tucker tensor\nformat which aims for numerical modeling of the 3D long-range interaction\npotentials in multi-particle systems. The main idea of the RS tensor format is\nthe independent grid-based low-rank representation of the localized and global\nparts in the target tensor which allows the efficient numerical approximation\nof $N$-particle interaction potentials. The single-particle reference potential\nlike $1/\\|x\\|$ is split into a sum of localized and long-range low-rank\ncanonical tensors represented on a fine 3D $n\\times n\\times n$ Cartesian grid.\nThe smoothed long-range contribution to the total potential sum is represented\non the 3D grid in $O(n)$ storage via the low-rank canonical/Tucker tensor. We\nprove that the Tucker rank parameters depend only logarithmically on the number\nof particles $N$ and the grid-size $n$. Agglomeration of the short range part\nin the sum is reduced to an independent treatment of $N$ localized terms with\nalmost disjoint effective supports, calculated in $O(N)$ operations. Thus, the\ncumulated sum of short range clusters is parametrized by a single low-rank\ncanonical reference tensor with a local support, accomplished by a list of\nparticle coordinates and their charges. The RS canonical/Tucker tensor\nrepresentations reduce the cost of multi-linear algebraic operations on the 3D\npotential sums arising in modeling of multi-dimensional data by radial basis\nfunctions, say, in computation of the electrostatic potential of a protein, in\n3D integration and convolution transforms, computation of gradients, forces and\nthe interaction energy of a many-particle systems, and in low parametric\nfitting of multi-dimensional scattered data by reducing all of them to 1D\ncalculations. \n\n"}
{"id": "1607.00310", "contents": "Title: A WENO-based Method of Line Transpose Approach for Vlasov Simulations Abstract: In this paper, a high order implicit Method of Line Transpose (MOL$^T$ )\nmethod based on a weighted essentially non-oscillatory (WENO) methodology is\ndeveloped for one-dimensional linear transport equations and further applied to\nthe Vlasov-Poisson (VP) simulations via dimensional splitting. In the MOL$^T$\nframework, the time variable is first discretized by a diagonally implicit\nstrong-stability-preserving Runge-Kutta method, resulting in a boundary value\nproblem (BVP) at the discrete time levels. Then an integral formulation coupled\nwith a high order WENO methodology is employed to solve the BVP. As a result,\nthe proposed scheme is high order accurate in both space and time and free of\noscillations even though the solution is discontinuous or has sharp gradients.\nMoreover, the scheme is able to take larger time step evolution compared with\nan explicit MOL WENO scheme with the same order of accuracy. The desired\npositivity-preserving (PP) property of the scheme is further attained by\nincorporating a newly proposed high order PP limiter. We perform numerical\nexperiments on several benchmarks including linear advection, solid body\nrotation problem; and on the Landau damping, two-stream instabilities,\nbump-on-tail, and plasma sheath by solving the VP system. The efficacy and\nefficiency of the proposed scheme is numerically verified. \n\n"}
{"id": "1607.00716", "contents": "Title: An Algebraic Approach to Non-Orthogonal General Joint Block\n  Diagonalization Abstract: The exact/approximate non-orthogonal general joint block diagonalization\n({\\sc nogjbd}) problem of a given real matrix set $\\mathcal{A}=\\{A_i\\}_{i=1}^m$\nis to find a nonsingular matrix $W\\in\\mathbb{R}^{n\\times n}$ (diagonalizer)\nsuch that $W^T A_i W$ for $i=1,2,\\dots, m$ are all exactly/approximately block\ndiagonal matrices with the same diagonal block structure and with as many\ndiagonal blocks as possible. In this paper, we show that a solution to the\nexact/approximate {\\sc nogjbd} problem can be obtained by finding the\nexact/approximate solutions to the system of linear equations $A_iZ=Z^TA_i$ for\n$i=1,\\dots, m$, followed by a block diagonalization of $Z$ via similarity\ntransformation. A necessary and sufficient condition for the equivalence of the\nsolutions to the exact {\\sc nogjbd} problem is established. Two numerical\nmethods are proposed to solve the {\\sc nogjbd} problem, and numerical examples\nare presented to show the merits of the proposed methods. \n\n"}
{"id": "1607.00769", "contents": "Title: Well-conditioned boundary integral equation formulations and Nystr\\\"om\n  discretizations for the solution of Helmholtz problems with impedance\n  boundary conditions in two-dimensional Lipschitz domains Abstract: We present a regularization strategy that leads to well-conditioned boundary\nintegral equation formulations of Helmholtz equations with impedance boundary\nconditions in two-dimensional Lipschitz domains. We consider both the case of\nclassical impedance boundary conditions, as well as the case of transmission\nimpedance conditions wherein the impedances are certain coercive operators. The\nlatter type of problems is instrumental in the speed up of the convergence of\nDomain Decomposition Methods for Helmholtz problems. Our regularized\nformulations use as unknowns the Dirichlet traces of the solution on the\nboundary of the domain. Taking advantage of the increased regularity of the\nunknowns in our formulations, we show through a variety of numerical results\nthat a graded-mesh based Nystr\\\"om discretization of these regularized\nformulations leads to efficient and accurate solutions of interior and exterior\nHelmholtz problems with impedance boundary conditions. \n\n"}
{"id": "1607.04808", "contents": "Title: Fast Ewald summation for free-space Stokes potentials Abstract: We present a spectrally accurate method for the rapid evaluation of\nfree-space Stokes potentials, i.e. sums involving a large number of free space\nGreen's functions. We consider sums involving stokeslets, stresslets and\nrotlets that appear in boundary integral methods and potential methods for\nsolving Stokes equations. The method combines the framework of the Spectral\nEwald method for periodic problems, with a very recent approach to solving the\nfree-space harmonic and biharmonic equations using fast Fourier transforms\n(FFTs) on a uniform grid. Convolution with a truncated Gaussian function is\nused to place point sources on a grid. With precomputation of a scalar grid\nquantity that does not depend on these sources, the amount of oversampling of\nthe grids with Gaussians can be kept at a factor of two, the minimum for\naperiodic convolutions by FFTs. The resulting algorithm has a computational\ncomplexity of O(N log N) for problems with N sources and targets. Comparison is\nmade with a fast multipole method (FMM) to show that the performance of the new\nmethod is competitive. \n\n"}
{"id": "1607.04879", "contents": "Title: Converse results, saturation and quasi-optimality for Lavrentiev\n  regularization of accretive problems Abstract: This paper deals with Lavrentiev regularization for solving linear ill-posed\nproblems, mostly with respect to accretive operators on Hilbert spaces. We\npresent converse and saturation results which are an important part in\nregularization theory. As a byproduct we obtain a new result on the\nquasi-optimality of a posteriori parameter choices. Results in this paper are\nformulated in Banach spaces whenever possible. \n\n"}
{"id": "1607.05893", "contents": "Title: Mathematical framework for abdominal electrical impedance tomography to\n  assess fatness Abstract: This paper presents a static electrical impedance tomography (EIT) technique\nthat evaluates abdominal obesity by estimating the thickness of subcutaneous\nfat. EIT has a fundamental drawback for absolute admittivity imaging because of\nits lack of reference data for handling the forward modeling errors. To reduce\nthe effect of boundary geometry errors in imaging abdominal fat, we develop a\ndepth-based reconstruction method that uses a specially chosen current pattern\nto construct reference-like data, which are then used to identify the border\nbetween subcutaneous fat and muscle. The performance of the proposed method is\ndemonstrated by numerical simulations using 32-channel EIT system and human\nlike domain. \n\n"}
{"id": "1607.06240", "contents": "Title: Hybrid Entropy Stable HLL-Type Riemann Solvers for Hyperbolic\n  Conservation Laws Abstract: It is known that HLL-type schemes are more dissipative than schemes based on\ncharacteristic decompositions. However, HLL-type methods offer greater\nflexibility to large systems of hyperbolic conservation laws because the\neigenstructure of the flux Jacobian is not needed. We demonstrate in the\npresent work that several HLL-type Riemann solvers are provably entropy stable.\nFurther, we provide convex combinations of standard dissipation terms to create\nhybrid HLL-type methods that have less dissipation while retaining entropy\nstability. The decrease in dissipation is demonstrated for the ideal MHD\nequations with a numerical example. \n\n"}
{"id": "1607.06948", "contents": "Title: An Analysis of the Crank-Nicolson Method for Subdiffusion Abstract: In this work, we analyze a Crank-Nicolson type time stepping scheme for the\nsubdiffusion equation, which involves a Caputo fractional derivative of order\n$\\alpha\\in (0,1)$ in time. It hybridizes the backward Euler convolution\nquadrature with a $\\theta$-type method, with the parameter $\\theta$ dependent\non the fractional order $\\alpha$ by $\\theta=\\alpha/2$, and naturally\ngeneralizes the classical Crank-Nicolson method. We develop essential initial\ncorrections at the starting two steps for the Crank-Nicolson scheme, and\ntogether with the Galerkin finite element method in space, obtain a fully\ndiscrete scheme. The overall scheme is easy to implement, and robust with\nrespect to data regularity. A complete error analysis of the fully discrete\nscheme is provided, and a second-order accuracy in time is established for both\nsmooth and nonsmooth problem data. Extensive numerical experiments are provided\nto illustrate its accuracy, efficiency and robustness, and a comparative study\nalso indicates its competitive with existing schemes. \n\n"}
{"id": "1607.07683", "contents": "Title: Splitting methods for constrained diffusion-reaction systems Abstract: We consider Lie and Strang splitting for the time integration of constrained\npartial differential equations with a nonlinear reaction term. Since such\nsystems are known to be sensitive with respect to perturbations, the splitting\nprocedure seems promising as we can treat the nonlinearity separately. This has\nsome computational advantages, since we only have to solve a linear constrained\nsystem and a nonlinear ODE. However, Strang splitting suffers from order\nreduction which limits its efficiency. This is caused by the fact that the\nnonlinear subsystem produces inconsistent initial values for the constrained\nsubsystem. The incorporation of an additional correction term resolves this\nproblem without increasing the computational cost. Numerical examples including\na coupled mechanical system illustrate the proven convergence results. \n\n"}
{"id": "1607.07704", "contents": "Title: A note on semilinear fractional elliptic equation: analysis and\n  discretization Abstract: In this paper we study existence, regularity, and approximation of solution\nto a fractional semilinear elliptic equation of order $s \\in (0,1)$. We\nidentify minimal conditions on the nonlinear term and the source which leads to\nexistence of weak solutions and uniform $L^\\infty$-bound on the solutions. Next\nwe realize the fractional Laplacian as a Dirichlet-to-Neumann map via the\nCaffarelli-Silvestre extension. We introduce a first-degree tensor product\nfinite elements space to approximate the truncated problem. We derive a priori\nerror estimates and conclude with an illustrative numerical example. \n\n"}
{"id": "1608.00034", "contents": "Title: Schur complement Domain Decomposition Methods for the solution of\n  multiple scattering problems Abstract: We present a Schur complement Domain Decomposition (DD) algorithm for the\nsolution of frequency domain multiple scattering problems. Just as in the\nclassical DD methods we (1) enclose the ensemble of scatterers in a domain\nbounded by an artificial boundary, (2) we subdivide this domain into a\ncollection of nonoverlapping subdomains so that the boundaries of the\nsubdomains do not intersect any of the scatterers, and (3) we connect the\nsolutions of the subproblems via Robin boundary conditions matching on the\ncommon interfaces between subdomains. We use subdomain Robin-to-Robin maps to\nrecast the DD problem as a sparse linear system whose unknown consists of Robin\ndata on the interfaces between subdomains---two unknowns per interface. The\nRobin-to-Robin maps are computed in terms of well-conditioned boundary integral\noperators. Unlike classical DD, we do not reformulate the Domain Decomposition\nproblem in the form a fixed point iteration, but rather we solve the ensuing\nlinear system by Gaussian elimination of the unknowns corresponding to inner\ninterfaces between subdomains via Schur complements. Once all the unknowns\ncorresponding to inner subdomains interfaces have been eliminated, we solve a\nmuch smaller linear system involving unknowns on the inner and outer artificial\nboundary. We present numerical evidence that our Schur complement DD algorithm\ncan produce accurate solutions of very large multiple scattering problems that\nare out of reach for other existing approaches. \n\n"}
{"id": "1608.00906", "contents": "Title: Embeddings of Weighted Hilbert Spaces and Applications to Multivariate\n  and Infinite-Dimensional Integration Abstract: We study embeddings and norm estimates for tensor products of weighted\nreproducing kernel Hilbert spaces. These results lead to a transfer principle\nthat is directly applicable to tractability studies of multivariate problems as\nintegration and approximation, and to their infinite-dimensional counterparts.\nIn an application we consider weighted tensor product Sobolev spaces of mixed\nsmoothness of any integer order, equipped with the classical, the anchored, or\nthe ANOVA norm. Here we derive new results for multivariate and\ninfinite-dimensional integration. \n\n"}
{"id": "1608.03170", "contents": "Title: A Convergent Adaptive Finite Element Method for Electrical Impedance\n  Tomography Abstract: In this work we develop and analyze an adaptive finite element method for\nefficiently solving electrical impedance tomography -- a severely ill-posed\nnonlinear inverse problem for recovering the conductivity from boundary voltage\nmeasurements. The reconstruction technique is based on Tikhonov regularization\nwith a Sobolev smoothness penalty and discretizing the forward model using\ncontinuous piecewise linear finite elements. We derive an adaptive finite\nelement algorithm with an a posteriori error estimator involving the concerned\nstate and adjoint variables and the recovered conductivity. The convergence of\nthe algorithm is established, in the sense that the sequence of discrete\nsolutions contains a convergent subsequence to a solution of the optimality\nsystem for the continuous formulation. Numerical results are presented to\nverify the convergence and efficiency of the algorithm. \n\n"}
{"id": "1608.04834", "contents": "Title: Asymptotic approximation of central binomial coefficients with rigorous\n  error bounds Abstract: We show that a well-known asymptotic series for the logarithm of the central\nbinomial coefficient is strictly enveloping in the sense of P\\'olya and\nSzeg\\\"o, so the error incurred in truncating the series is of the same sign as\nthe next term, and is bounded in magnitude by that term. We consider closely\nrelated asymptotic series for Binet's function, for $\\ln\\Gamma(z+1/2)$, and for\nthe Riemann-Siegel theta function, and make some historical remarks. \n\n"}
{"id": "1608.05286", "contents": "Title: Electroencephalography (EEG) Forward Modeling via H(div) Finite Element\n  Sources with Focal Interpolation Abstract: The goal of this study is to develop focal, accurate and robust finite\nelement method (FEM) based approaches which can predict the electric potential\non the surface of the computational domain given its structure and internal\nprimary source current distribution. While conducting an EEG evaluation, the\nplacement of source currents to the geometrically complex grey matter\ncompartment is a challenging but necessary task to avoid forward errors\nattributable to tissue conductivity jumps. Here, this task is approached via a\nmathematically rigorous formulation, in which the current field is modeled via\ndivergence conforming H(div) basis functions. Both linear and quadratic\nfunctions are used while the potential field is discretized via the standard\nlinear Lagrangian (nodal) basis. The resulting model includes dipolar sources\nwhich are interpolated into a random set of positions and orientations\nutilizing two alternative approaches: the position based optimization (PBO) and\nthe mean position/orientation (MPO) method. These results demonstrate that the\npresent dipolar approach can reach or even surpass, at least in some respects,\nthe accuracy of two classical reference methods, the partial integration (PI)\nand St. Venant (SV) approach which utilize monopolar loads instead of dipolar\ncurrents. \n\n"}
{"id": "1609.00048", "contents": "Title: Practical sketching algorithms for low-rank matrix approximation Abstract: This paper describes a suite of algorithms for constructing low-rank\napproximations of an input matrix from a random linear image of the matrix,\ncalled a sketch. These methods can preserve structural properties of the input\nmatrix, such as positive-semidefiniteness, and they can produce approximations\nwith a user-specified rank. The algorithms are simple, accurate, numerically\nstable, and provably correct. Moreover, each method is accompanied by an\ninformative error bound that allows users to select parameters a priori to\nachieve a given approximation quality. These claims are supported by numerical\nexperiments with real and synthetic data. \n\n"}
{"id": "1609.00246", "contents": "Title: Sparse approximation of multilinear problems with applications to\n  kernel-based methods in UQ Abstract: We provide a framework for the sparse approximation of multilinear problems\nand show that several problems in uncertainty quantification fit within this\nframework. In these problems, the value of a multilinear map has to be\napproximated using approximations of different accuracy and computational work\nof the arguments of this map. We propose and analyze a generalized version of\nSmolyak's algorithm, which provides sparse approximation formulas with\nconvergence rates that mitigate the curse of dimension that appears in\nmultilinear approximation problems with a large number of arguments. We apply\nthe general framework to response surface approximation and optimization under\nuncertainty for parametric partial differential equations using kernel-based\napproximation. The theoretical results are supplemented by numerical\nexperiments. \n\n"}
{"id": "1609.01255", "contents": "Title: Dimension reduction in MHD power generation models: dimensional analysis\n  and active subspaces Abstract: Magnetohydrodynamics (MHD)---the study of electrically conducting\nfluids---can be harnessed to produce efficient, low-emissions power generation.\nToday, computational modeling assists engineers in studying candidate designs\nfor such generators. However, these models are computationally expensive, so\nstudying the effects of the model's many input parameters on output predictions\nis typically infeasible. We study two approaches for reducing the input\ndimension of the models: (i) classical dimensional analysis based on the\ninputs' units and (ii) active subspaces, which reveal low-dimensional subspaces\nin the space of inputs that affect the outputs the most. We also review the\nmathematical connection between the two approaches that leads to consistent\napplication. The dimension reduction yields insights into the driving factors\nin the MHD power generation models. We study both the simplified Hartmann\nproblem, which admits closed form expressions for the quantities of interest,\nand a large-scale computational model with adjoint capabilities that enable the\nderivative computations needed to estimate the active subspaces. \n\n"}
{"id": "1609.01971", "contents": "Title: Optimal-order isogeometric collocation at Galerkin superconvergent\n  points Abstract: In this paper we investigate numerically the order of convergence of an\nisogeometric collocation method that builds upon the least-squares collocation\nmethod presented in [1] and the variational collocation method presented in\n[2]. The focus is on smoothest B-splines/NURBS approximations, i.e, having\nglobal $C^{p-1}$ continuity for polynomial degree $p$. Within the framework of\n[2], we select as collocation points a subset of those considered in [1], which\nare related to the Galerkin superconvergence theory. With our choice, that\nfeatures local symmetry of the collocation stencil, we improve the convergence\nbehaviour with respect to [2], achieving optimal $L^2$-convergence for odd\ndegree B-splines/NURBS approximations. The same optimal order of convergence is\nseen in [1], where, however a least-squares formulation is adopted. Further\ncareful study is needed, since the robustness of the method and its\nmathematical foundation are still unclear. \n\n"}
{"id": "1609.02814", "contents": "Title: Computation of Cournot-Nash equilibria by entropic regularization Abstract: We consider a class of games with continuum of players where equilibria can\nbe obtained by the minimization of a certain functional related to optimal\ntransport as emphasized in [7]. We then use the powerful entropic\nregularization technique to approximate the problem and solve it numerically in\nvarious cases. We also consider the extension to some models with several\npopulations of players. \n\n"}
{"id": "1609.03053", "contents": "Title: GEMPIC: Geometric ElectroMagnetic Particle-In-Cell Methods Abstract: We present a novel framework for Finite Element Particle-in-Cell methods\nbased on the discretization of the underlying Hamiltonian structure of the\nVlasov-Maxwell system. We derive a semi-discrete Poisson bracket, which retains\nthe defining properties of a bracket, anti-symmetry and the Jacobi identity, as\nwell as conservation of its Casimir invariants, implying that the semi-discrete\nsystem is still a Hamiltonian system. In order to obtain a fully discrete\nPoisson integrator, the semi-discrete bracket is used in conjunction with\nHamiltonian splitting methods for integration in time. Techniques from Finite\nElement Exterior Calculus ensure conservation of the divergence of the magnetic\nfield and Gauss' law as well as stability of the field solver. The resulting\nmethods are gauge invariant, feature exact charge conservation and show\nexcellent long-time energy and momentum behaviour. Due to the generality of our\nframework, these conservation properties are guaranteed independently of a\nparticular choice of the Finite Element basis, as long as the corresponding\nFinite Element spaces satisfy certain compatibility conditions. \n\n"}
{"id": "1609.03240", "contents": "Title: Non-square matrix sensing without spurious local minima via the\n  Burer-Monteiro approach Abstract: We consider the non-square matrix sensing problem, under restricted isometry\nproperty (RIP) assumptions. We focus on the non-convex formulation, where any\nrank-$r$ matrix $X \\in \\mathbb{R}^{m \\times n}$ is represented as $UV^\\top$,\nwhere $U \\in \\mathbb{R}^{m \\times r}$ and $V \\in \\mathbb{R}^{n \\times r}$. In\nthis paper, we complement recent findings on the non-convex geometry of the\nanalogous PSD setting [5], and show that matrix factorization does not\nintroduce any spurious local minima, under RIP. \n\n"}
{"id": "1609.03682", "contents": "Title: On asymptotic approximations to the log-Gamma and Riemann-Siegel theta\n  functions Abstract: We give bounds on the error in the asymptotic approximation of the log-Gamma\nfunction $\\ln\\Gamma(z)$ for complex $z$ in the right half-plane. These improve\non earlier bounds by Behnke and Sommer (1962), Spira (1971), and Hare (1997).\nWe show that $|R_{k+1}(z)/T_k(z)| < \\sqrt{\\pi k}$ for nonzero $z$ in the right\nhalf-plane, where $T_k(z)$ is the $k$-th term in the asymptotic series, and\n$R_{k+1}(z)$ is the error incurred in truncating the series after $k$ terms. If\n$k \\le |z|$, then the stronger bound $|R_{k+1}(z)/T_k(z)| < (k/|z|)^2/(\\pi^2-1)\n< 0.113$ holds. Similarly for the asymptotic approximation of\n$\\ln\\Gamma(z+\\frac{1}{2})$, except that a factor $\\eta_k = 1/(1-2^{1-2k})$\nmultiplies some of the bounds.\n  We deduce similar bounds for asymptotic approximation of the Riemann-Siegel\ntheta function $\\vartheta(t)$. We show that the accuracy of a well-known\napproximation to $\\vartheta(t)$ can be improved by including an exponentially\nsmall term in the approximation. This improves the attainable accuracy for real\n$t>0$ from $O(\\exp(-\\pi t))$ to $O(\\exp(-2\\pi t))$. We discuss a similar\nexample due to Olver (1964), and a connection with the Stokes phenomenon. \n\n"}
{"id": "1609.03922", "contents": "Title: Hyperbolic periodic orbits in nongradient systems and\n  small-noise-induced metastable transitions Abstract: Small noise can induce rare transitions between metastable states, which can\nbe characterized by Maximum Likelihood Paths (MLPs). Nongradient systems\ncontrast gradient systems in that MLP does not have to cross the separatrix at\na saddle point, but instead possibly at a point on a hyperbolic periodic orbit.\nA numerical approach for identifying such unstable periodic orbits is proposed\nbased on String method. In a special class of nongradient systems\n(`orthogonal-type'), there are provably local MLPs that cross such saddle point\nor hyperbolic periodic orbit, and the separatrix crossing location determines\nthe associated local maximum of transition rate. In general cases, however, the\nseparatrix crossing may not determine a unique local maximum of the rate, as we\nnumerically observed a counter-example in a sheared 2D-space Allen-Cahn SPDE.\nIt is a reasonable conjecture that there are always local MLPs associated with\neach attractor on the separatrix, such as saddle point or hyperbolic periodic\norbit; our numerical experiments did not disprove so. \n\n"}
{"id": "1609.05407", "contents": "Title: Preconditioned steepest descent-like methods for symmetric indefinite\n  systems Abstract: This paper addresses the question of what exactly is an analogue of the\npreconditioned steepest descent (PSD) algorithm in the case of a symmetric\nindefinite system with an SPD preconditioner. We show that a basic PSD-like\nscheme for an SPD-preconditioned symmetric indefinite system is mathematically\nequivalent to the restarted PMINRES, where restarts occur after every two\nsteps. A convergence bound is derived. If certain information on the spectrum\nof the preconditioned system is available, we present a simpler PSD-like\nalgorithm that performs only one-dimensional residual minimization. Our primary\ngoal is to bridge the theoretical gap between optimal (PMINRES) and PSD-like\nmethods for solving symmetric indefinite systems, as well as point out\nsituations where the PSD-like schemes can be used in practice. \n\n"}
{"id": "1609.06363", "contents": "Title: Stationary averaging for multi-scale continuous time Markov chains using\n  parallel replica dynamics Abstract: We propose two algorithms for simulating continuous time Markov chains in the\npresence of metastability. We show that the algorithms correctly estimate,\nunder the ergodicity assumption, stationary averages of the process. Both\nalgorithms, based on the idea of the parallel replica method, use parallel\ncomputing in order to explore metastable sets more efficiently. The algorithms\nrequire no assumptions on the Markov chains beyond ergodicity and the presence\nof identifiable metastability.\n  In particular, there is no assumption on reversibility. For simpler\nillustration of the algorithms, we assume that a synchronous architecture is\nused throughout of the paper. We present error analyses, as well as numerical\nsimulations on multi-scale stochastic reaction network models in order to\ndemonstrate consistency of the method and its efficiency. \n\n"}
{"id": "1609.06674", "contents": "Title: Efficient methods for the estimation of homogenized coefficients Abstract: The main goal of this paper is to define and study new methods for the\ncomputation of effective coefficients in the homogenization of divergence-form\noperators with random coefficients. The methods introduced here are proved to\nhave optimal computational complexity, and are shown numerically to display\nsmall constant prefactors. In the spirit of multiscale methods, the main idea\nis to rely on a progressive coarsening of the problem, which we implement via a\ngeneralization of the Green-Kubo formula. The technique can be applied more\ngenerally to compute the effective diffusivity of any additive functional of a\nMarkov process. In this broader context, we also discuss the alternative\npossibility of using Monte-Carlo sampling, and show how a simple one-step\nextrapolation can considerably improve the performance of this alternative\nmethod. \n\n"}
{"id": "1609.06762", "contents": "Title: Sparsity-Preserving Difference of Positive Semidefinite Matrix\n  Representation of Indefinite Matrices Abstract: We consider the problem of writing an arbitrary symmetric matrix as the\ndifference of two positive semidefinite matrices. We start with simple ideas\nsuch as eigenvalue decomposition. Then, we develop a simple adaptation of the\nCholesky that returns a difference-of-Cholesky representation of indefinite\nmatrices. Heuristics that promote sparsity can be applied directly to this\nmodification. \n\n"}
{"id": "1609.07092", "contents": "Title: A fast algorithm for Earth Mover's Distance based on optimal transport\n  and L1 type Regularization Abstract: We propose a new algorithm to approximate the Earth Mover's distance (EMD).\nOur main idea is motivated by the theory of optimal transport, in which EMD can\nbe reformulated as a familiar $L_1$ type minimization. We use a regularization\nwhich gives us a unique solution for this $L_1$ type problem. The new\nregularized minimization is very similar to problems which have been solved in\nthe fields of compressed sensing and image processing, where several fast\nmethods are available. In this paper, we adopt a primal-dual algorithm designed\nthere, which uses very simple updates at each iteration and is shown to\nconverge very rapidly. Several numerical examples are provided. \n\n"}
{"id": "1609.07154", "contents": "Title: A posteriori error estimates for a Virtual Elements Method for the\n  Steklov eigenvalue problem Abstract: The paper deals with the a posteriori error analysis of a virtual element\nmethod for the Steklov eigenvalue problem. The virtual element method has the\nadvantage of using general polygonal meshes, which allows implementing very\nefficiently mesh refinement strategies. We introduce a residual type a\nposteriori error estimator and prove its reliability and efficiency. We use the\ncorresponding error estimator to drive an adaptive scheme. Finally, we report\nthe results of a couple of numerical tests, that allow us to assess the\nperformance of this approach. \n\n"}
{"id": "1609.08180", "contents": "Title: Coupled variational formulations of linear elasticity and the DPG\n  methodology Abstract: This article presents a general approach akin to domain-decomposition methods\nto solve a single linear PDE, but where each subdomain of a partitioned domain\nis associated to a distinct variational formulation coming from a mutually\nwell-posed family of broken variational formulations of the original PDE. It\ncan be exploited to solve challenging problems in a variety of physical\nscenarios where stability or a particular mode of convergence is desired in a\npart of the domain. The linear elasticity equations are solved in this work,\nbut the approach can be applied to other equations as well. The broken\nvariational formulations, which are essentially extensions of more standard\nformulations, are characterized by the presence of mesh-dependent broken test\nspaces and interface trial variables at the boundaries of the elements of the\nmesh. This allows necessary information to be naturally transmitted between\nadjacent subdomains, resulting in coupled variational formulations which are\nthen proved to be globally well-posed. They are solved numerically using the\nDPG methodology, which is especially crafted to produce stable discretizations\nof broken formulations. Finally, expected convergence rates are verified in two\ndifferent and illustrative examples. \n\n"}
{"id": "1609.08251", "contents": "Title: Robust and efficient multi-way spectral clustering Abstract: We present a new algorithm for spectral clustering based on a column-pivoted\nQR factorization that may be directly used for cluster assignment or to provide\nan initial guess for k-means. Our algorithm is simple to implement, direct, and\nrequires no initial guess. Furthermore, it scales linearly in the number of\nnodes of the graph and a randomized variant provides significant computational\ngains. Provided the subspace spanned by the eigenvectors used for clustering\ncontains a basis that resembles the set of indicator vectors on the clusters,\nwe prove that both our deterministic and randomized algorithms recover a basis\nclose to the indicators in Frobenius norm. We also experimentally demonstrate\nthat the performance of our algorithm tracks recent information theoretic\nbounds for exact recovery in the stochastic block model. Finally, we explore\nthe performance of our algorithm when applied to a real world graph. \n\n"}
{"id": "1610.00823", "contents": "Title: An adaptive fast multipole accelerated Poisson solver for complex\n  geometries Abstract: We present a fast, direct and adaptive Poisson solver for complex\ntwo-dimensional geometries based on potential theory and fast multipole\nacceleration. More precisely, the solver relies on the standard decomposition\nof the solution as the sum of a volume integral to account for the source\ndistribution and a layer potential to enforce the desired boundary condition.\nThe volume integral is computed by applying the FMM on a square box that\nencloses the domain of interest. For the sake of efficiency and convergence\nacceleration, we first extend the source distribution (the right-hand side in\nthe Poisson equation) to the enclosing box as a $C^0$ function using a fast,\nboundary integral-based method. We demonstrate on multiply connected domains\nwith irregular boundaries that this continuous extension leads to high accuracy\nwithout excessive adaptive refinement near the boundary and, as a result, to an\nextremely efficient \"black box\" fast solver. \n\n"}
{"id": "1610.03279", "contents": "Title: $\\mathcal H_2$-Quasi-Optimal Model Order Reduction for\n  Quadratic-Bilinear Control Systems Abstract: We investigate the optimal model reduction problem for large-scale\nquadratic-bilinear (QB) control systems. Our contributions are threefold.\nFirst, we discuss the variational analysis and the Volterra series formulation\nfor QB systems. We then define the $\\mathcal H_2$-norm for a QB system based on\nthe kernels of the underlying Volterra series and also propose a truncated\n$\\mathcal H_2$-norm. Next, we derive first-order necessary conditions for an\noptimal approximation, where optimality is measured in term of the truncated\n$\\mathcal H_2$-norm of the error system. We then propose an iterative model\nreduction algorithm, which upon convergence yields a reduced-order system that\napproximately satisfies the newly derived optimality conditions. We also\ndiscuss an efficient computation of the reduced Hessian, using the special\nKronecker structure of the Hessian of the system. We illustrate the efficiency\nof the proposed method by means of several numerical examples resulting from\nsemi-discretized nonlinear partial differential equations and show its\ncompetitiveness with the existing model reduction schemes for QB systems such\nas moment-matching methods and balanced truncation. \n\n"}
{"id": "1610.03589", "contents": "Title: Perfectly-matched-layer boundary integral equation method for wave\n  scattering in a layered medium Abstract: For scattering problems of time-harmonic waves, the boundary integral\nequation (BIE) methods are highly competitive, since they are formulated on\nlower-dimension boundaries or interfaces, and can automatically satisfy\noutgoing radiation conditions. For scattering problems in a layered medium,\nstandard BIE methods based on the Green's function of the background medium\nmust evaluate the expensive Sommefeld integrals. Alternative BIE methods based\non the free-space Green's function give rise to integral equations on unbounded\ninterfaces which are not easy to truncate, since the wave fields on these\ninterfaces decay very slowly. We develop a BIE method based on the perfectly\nmatched layer (PML) technique. The PMLs are widely used to suppress outgoing\nwaves in numerical methods that directly discretize the physical space. Our\nPML-based BIE method uses the Green's function of the PML-transformed free\nspace to define the boundary integral operators. The method is efficient, since\nthe Green's function of the PML-transformed free space is easy to evaluate and\nthe PMLs are very effective in truncating the unbounded interfaces. Numerical\nexamples are presented to validate our method and demonstrate its accuracy. \n\n"}
{"id": "1610.03613", "contents": "Title: A Numerical Treatment of Energy Eigenvalues of Harmonic Oscillators\n  Perturbed by a Rational Function Abstract: In the present contribution, we apply the double exponential Sinc-collocation\nmethod (DESCM) to the one-dimensional time independent Schr\\\"odinger equation\nfor a class of rational potentials of the form $V(x) =p(x)/q(x)$. This\nalgorithm is based on the discretization of the Hamiltonian of the\nSchr\\\"odinger equation using Sinc expansions. This discretization results in a\ngeneralized eigenvalue problem where the eigenvalues correspond to\napproximations of the energy values of the corresponding Hamiltonian. A\nsystematic numerical study is conducted, beginning with test potentials with\nknown eigenvalues and moving to rational potentials of increasing degree. \n\n"}
{"id": "1610.03675", "contents": "Title: Virtual Element Method for Second Order Elliptic Eigenvalue Problems Abstract: We introduce the Virtual Element Method (VEM) for elliptic eigenvalue\nproblems. The main result of the paper states that VEM provides an optimal\norder approximation of the eigenmodes. A wide set of numerical tests confirm\nthe theoretical analysis. \n\n"}
{"id": "1610.03991", "contents": "Title: Preconditioning of a coupled Cahn--Hilliard Navier--Stokes system Abstract: Recently, Garcke et al.[Garcke, Hinze, Kahle, A stable and linear time\ndiscretization for a thermodynamically consistent model for two-phase\nincompressible flow, Applied Numerical Mathematics 99, pp. 151-171, 2016]\ndeveloped a consistent discretization scheme for a thermodynamically consistent\ndiffuse interface model for incompressible two-phase flows with different\ndensities. At the heart of this method lies the solution of large and sparse\nlinear systems that arise in a semismooth Newton method.\n  We propose the use of preconditioned Krylov subspace solvers using effective\nSchur complement approximations. Numerical results illustrate the efficiency of\nour approach. In particular, our preconditioner is shown to be robust with\nrespect to parameter changes. \n\n"}
{"id": "1610.05401", "contents": "Title: Uniquely solvable and energy stable decoupled schemes for\n  Cahn-Hilliard-Stokes-Darcy system for two-phase flows in karstic geometry Abstract: We propose and analyze two novel decoupled numerical schemes for solving the\nCahn-Hilliard-Stokes-Darcy (CHSD) model for two-phase flows in karstic\ngeometry. In the first numerical scheme, we explore a fractional step method\n(operator splitting) to decouple the phase-field (Cahn-Hilliard equation) from\nthe velocity field (Stokes-Darcy fluid equations). To further decouple the\nStokes-Darcy system, we introduce a first order pressure stabilization term in\nthe Darcy solver in the second numerical scheme so that the Stokes system is\ndecoupled from the Darcy system and hence the CHSD system can be solved in a\nfully decoupled manner. We show that both decoupled numerical schemes are\nuniquely solvable, energy stable, and mass conservative. Ample numerical\nresults are presented to demonstrate the accuracy and efficiency of our\nschemes. \n\n"}
{"id": "1610.05831", "contents": "Title: A trace finite element method for PDEs on evolving surfaces Abstract: In this paper, we propose an approach for solving PDEs on evolving surfaces\nusing a combination of the trace finite element method and a fast marching\nmethod. The numerical approach is based on the Eulerian description of the\nsurface problem and employs a time-independent background mesh that is not\nfitted to the surface. The surface and its evolution may be given implicitly,\nfor example, by the level set method. Extension of the PDE off the surface is\nnot required. The method introduced in this paper naturally allows a surface to\nundergo topological changes and experience local geometric singularities. In\nthe simplest setting, the numerical method is second order accurate in space\nand time. Higher order variants are feasible, but not studied in this paper. We\nshow results of several numerical experiments, which demonstrate the\nconvergence properties of the method and its ability to handle the case of the\nsurface with topological changes. \n\n"}
{"id": "1610.06590", "contents": "Title: Scaling Laws of Passive-Scalar Diffusion in the Interstellar Medium Abstract: Passive scalar mixing (metals, molecules, etc.) in the turbulent interstellar\nmedium (ISM) is critical for abundance patterns of stars and clusters, galaxy\nand star formation, and cooling from the circumgalactic medium. However, the\nfundamental scaling laws remain poorly understood in the highly supersonic,\nmagnetized, shearing regime relevant for the ISM. We therefore study the full\nscaling laws governing passive-scalar transport in idealized simulations of\nsupersonic turbulence. Using simple phenomenological arguments for the\nvariation of diffusivity with scale based on Richardson diffusion, we propose a\nsimple fractional diffusion equation to describe the turbulent advection of an\ninitial passive scalar distribution. These predictions agree well with the\nmeasurements from simulations, and vary with turbulent Mach number in the\nexpected manner, remaining valid even in the presence of a large-scale shear\nflow (e.g. rotation in a galactic disk). The evolution of the scalar\ndistribution is not the same as obtained using simple, constant \"effective\ndiffusivity\" as in Smagorinsky models, because the scale-dependence of\nturbulent transport means an initially Gaussian distribution quickly develops\nhighly non-Gaussian tails. We also emphasize that these are mean scalings that\nonly apply to ensemble behaviors (assuming many different, random scalar\ninjection sites): individual Lagrangian \"patches\" remain coherent\n(poorly-mixed) and simply advect for a large number of turbulent flow-crossing\ntimes. \n\n"}
{"id": "1610.07047", "contents": "Title: Convergence of the Euler-Maruyama method for multidimensional SDEs with\n  discontinuous drift and degenerate diffusion coefficient Abstract: We prove strong convergence of order $1/4-\\epsilon$ for arbitrarily small\n$\\epsilon>0$ of the Euler-Maruyama method for multidimensional stochastic\ndifferential equations (SDEs) with discontinuous drift and degenerate diffusion\ncoefficient. The proof is based on estimating the difference between the\nEuler-Maruyama scheme and another numerical method, which is constructed by\napplying the Euler-Maruyama scheme to a transformation of the SDE we aim to\nsolve. \n\n"}
{"id": "1610.07315", "contents": "Title: Discrete least-squares approximations over optimized downward closed\n  polynomial spaces in arbitrary dimension Abstract: We analyze the accuracy of the discrete least-squares approximation of a\nfunction $u$ in multivariate polynomial spaces $\\mathbb{P}_\\Lambda:={\\rm span}\n\\{y\\mapsto y^\\nu \\,: \\, \\nu\\in \\Lambda\\}$ with $\\Lambda\\subset \\mathbb{N}_0^d$\nover the domain $\\Gamma:=[-1,1]^d$, based on the sampling of this function at\npoints $y^1,\\dots,y^m \\in \\Gamma$. The samples are independently drawn\naccording to a given probability density $\\rho$ belonging to the class of\nmultivariate beta densities, which includes the uniform and Chebyshev densities\nas particular cases. We restrict our attention to polynomial spaces associated\nwith \\emph{downward closed} sets $\\Lambda$ of \\emph{prescribed} cardinality\n$n$, and we optimize the choice of the space for the given sample. This\nimplies, in particular, that the selected polynomial space depends on the\nsample. We are interested in comparing the error of this least-squares\napproximation measured in $L^2(\\Gamma,d\\rho)$ with the best achievable\npolynomial approximation error when using downward closed sets of cardinality\n$n$. We establish conditions between the dimension $n$ and the size $m$ of the\nsample, under which these two errors are proven to be comparable. Our main\nfinding is that the dimension $d$ enters only moderately in the resulting\ntrade-off between $m$ and $n$, in terms of a logarithmic factor $\\ln(d)$, and\nis even absent when the optimization is restricted to a relevant subclass of\ndownward closed sets, named {\\it anchored} sets. In principle, this allows one\nto use these methods in arbitrarily high or even infinite dimension. Our\nanalysis builds upon [2] which considered fixed and nonoptimized downward\nclosed multi-index sets. Potential applications of the proposed results are\nfound in the development and analysis of numerical methods for computing the\nsolution to high-dimensional parametric or stochastic PDEs. \n\n"}
{"id": "1611.00102", "contents": "Title: On the penalty stabilization mechanism for upwind discontinuous Galerkin\n  formulations of first order hyperbolic systems Abstract: Penalty fluxes are dissipative numerical fluxes for high order discontinuous\nGalerkin (DG) methods which depend on a penalization parameter. We investigate\nthe dependence of the spectra of high order DG discretizations on this\nparameter, and show that as its value increases, the spectra of the DG\ndiscretization splits into two disjoint sets of eigenvalues. One set converges\nto the eigenvalues of a conforming discretization, while the other set\ncorresponds to spurious eigenvalues which are damped proportionally to the\nparameter. Numerical experiments also demonstrate that undamped spurious modes\npresent in both in the limit of zero and large penalization parameters are\ndamped for moderate values of the upwind parameter. \n\n"}
{"id": "1611.00154", "contents": "Title: Regular decomposition and a framework of order reducd methods for fourth\n  order problems Abstract: This paper is devoted to the construction of order reduced method of fourth\norder problems. A framework is presented such that a problem on a\nhigh-regularity space can be deduced in a constructive way to an equivalent\nproblem on three low-regularity spaces which are connected by a regular\ndecomposition, which is corresponding to a decomposition of the figuration of\nthe regularity of the high order space. The framework is fit for various fourth\norder problems, and the numerical schemes based on the deduced problems can be\nof lower complicacy. Two fourth order problems in three dimensional are\ndiscussed under the framework. They are each corresponding to a regular\ndecomposition, and thus are discretised based on the discretised analogues of\nthe regular decompositions constructed; optimal error estimates are given. \n\n"}
{"id": "1611.00164", "contents": "Title: Finite difference methods for fractional Laplacians Abstract: The fractional Laplacian $(-\\Delta)^{\\alpha/2}$ is the prototypical non-local\nelliptic operator. While analytical theory has been advanced and understood for\nsome time, there remain many open problems in the numerical analysis of the\noperator. In this article, we study several different finite difference\ndiscretisations of the fractional Laplacian on uniform grids in one dimension\nthat takes the same form. Many properties can be compared and summarised in\nthis relatively simple setting, to tackle more important questions like the\nnonlocality, singularity and flat tails common in practical implementations.\nThe accuracy and the asymptotic behaviours of the methods are also studied,\ntogether with treatment of the far field boundary conditions, providing a\nunified perspective on the further development of the scheme in higher\ndimensions. \n\n"}
{"id": "1611.00610", "contents": "Title: Variational Methods for Biomolecular Modeling Abstract: Structure, function and dynamics of many biomolecular systems can be\ncharacterized by the energetic variational principle and the corresponding\nsystems of partial differential equations (PDEs). This principle allows us to\nfocus on the identification of essential energetic components, the optimal\nparametrization of energies, and the efficient computational implementation of\nenergy variation or minimization. Given the fact that complex biomolecular\nsystems are structurally non-uniform and their interactions occur through\ncontact interfaces, their free energies are associated with various interfaces\nas well, such as solute-solvent interface, molecular binding interface, lipid\ndomain interface, and membrane surfaces. This fact motivates the inclusion of\ninterface geometry, particular its curvatures, to the parametrization of free\nenergies. Applications of such interface geometry based energetic variational\nprinciples are illustrated through three concrete topics: the multiscale\nmodeling of biomolecular electrostatics and solvation that includes the\ncurvature energy of the molecular surface, the formation of microdomains on\nlipid membrane due to the geometric and molecular mechanics at the lipid\ninterface, and the mean curvature driven protein localization on membrane\nsurfaces. By further implicitly representing the interface using a phase field\nfunction over the entire domain, one can simulate the dynamics of the interface\nand the corresponding energy variation by evolving the phase field function,\nachieving significant reduction of the number of degrees of freedom and\ncomputational complexity. Strategies for improving the efficiency of\ncomputational implementations and for extending applications to coarse-graining\nor multiscale molecular simulations are outlined. \n\n"}
{"id": "1611.01420", "contents": "Title: An integral equation-based numerical solver for Taylor states in\n  toroidal geometries Abstract: We develop an algorithm for the numerical calculation of Taylor states in\ntoroidal and toroidal shell geometries using an analytical framework developed\nfor the solution to the time-harmonic Maxwell equations. Taylor states are a\nspecial case of what are known as Beltrami fields, or linear force-free fields.\nThe scheme of this work relies on the generalized Debye source representation\nof Maxwell fields and an integral representation of Beltrami fields which\nimmediately yields a well-conditioned second-kind integral equation. This\nintegral equation has a unique solution whenever the Beltrami parameter\n$\\lambda$ is not a member of a discrete, countable set of resonances which\nphysically correspond to spontaneous symmetry breaking. Several numerical\nexamples relevant to magnetohydrodynamic equilibria calculations are provided.\nLastly, our approach easily generalizes to arbitrary geometries, both bounded\nand unbounded, and of varying genus. \n\n"}
{"id": "1611.02072", "contents": "Title: Data-driven Structured Realization Abstract: We present a framework for constructing structured realizations of linear\ndynamical systems having transfer functions of the form $C(\\sum_{k=1}^K\nh_k(s)A_k)^{-1}B$ where $h_1,h_2,\\ldots,h_K$ are prescribed functions that\nspecify the surmised structure of the model. Our construction is data-driven in\nthe sense that an interpolant is derived entirely from measurements of a\ntransfer function. Our approach extends the Loewner realization framework to\nmore general system structure that includes second-order (and higher) systems\nas well as systems with internal delays. Numerical examples demonstrate the\nadvantages of this approach. \n\n"}
{"id": "1611.02348", "contents": "Title: A structure preserving Lanczos algorithm for computing the optical\n  absorption spectrum Abstract: We present a new structure preserving Lanczos algorithm for approximating the\noptical absorption spectrum in the context of solving full Bethe--Salpeter\nequation without Tamm--Dancoff approximation. The new algorithm is based on a\nstructure preserving Lanczos procedure, which exploits the special block\nstructure of Bethe--Salpeter Hamiltonian matrices. A recently developed\ntechnique of generalized averaged Gauss quadrature is incorporated to\naccelerate the convergence. We also establish the connection between our\nstructure preserving Lanczos procedure with several existing Lanczos procedures\ndeveloped in different contexts. Numerical examples are presented to\ndemonstrate the effectiveness of our Lanczos algorithm. \n\n"}
{"id": "1611.03225", "contents": "Title: Sharper Bounds for Regularized Data Fitting Abstract: We study matrix sketching methods for regularized variants of linear\nregression, low rank approximation, and canonical correlation analysis. Our\nmain focus is on sketching techniques which preserve the objective function\nvalue for regularized problems, which is an area that has remained largely\nunexplored. We study regularization both in a fairly broad setting, and in the\nspecific context of the popular and widely used technique of ridge\nregularization; for the latter, as applied to each of these problems, we show\nalgorithmic resource bounds in which the {\\em statistical dimension} appears in\nplaces where in previous bounds the rank would appear. The statistical\ndimension is always smaller than the rank, and decreases as the amount of\nregularization increases. In particular, for the ridge low-rank approximation\nproblem $\\min_{Y,X} \\lVert YX - A \\rVert_F^2 + \\lambda \\lVert Y\\rVert_F^2 +\n\\lambda\\lVert X \\rVert_F^2$, where $Y\\in\\mathbb{R}^{n\\times k}$ and\n$X\\in\\mathbb{R}^{k\\times d}$, we give an approximation algorithm needing \\[\nO(\\mathtt{nnz}(A)) + \\tilde{O}((n+d)\\varepsilon^{-1}k \\min\\{k,\n\\varepsilon^{-1}\\mathtt{sd}_\\lambda(Y^*)\\})+\n\\mathtt{poly}(\\mathtt{sd}_\\lambda(Y^*) \\varepsilon^{-1}) \\] time, where\n$s_{\\lambda}(Y^*)\\le k$ is the statistical dimension of $Y^*$, $Y^*$ is an\noptimal $Y$, $\\varepsilon$ is an error parameter, and $\\mathtt{nnz}(A)$ is the\nnumber of nonzero entries of $A$.This is faster than prior work, even when\n$\\lambda=0$.\n  We also study regularization in a much more general setting. For example, we\nobtain sketching-based algorithms for the low-rank approximation problem\n$\\min_{X,Y} \\lVert YX - A \\rVert_F^2 + f(Y,X)$ where $f(\\cdot,\\cdot)$ is a\nregularizing function satisfying some very general conditions (chiefly,\ninvariance under orthogonal transformations). \n\n"}
{"id": "1611.04950", "contents": "Title: The Fast Slepian Transform Abstract: The discrete prolate spheroidal sequences (DPSS's) provide an efficient\nrepresentation for discrete signals that are perfectly timelimited and nearly\nbandlimited. Due to the high computational complexity of projecting onto the\nDPSS basis - also known as the Slepian basis - this representation is often\noverlooked in favor of the fast Fourier transform (FFT). We show that there\nexist fast constructions for computing approximate projections onto the leading\nSlepian basis elements. The complexity of the resulting algorithms is\ncomparable to the FFT, and scales favorably as the quality of the desired\napproximation is increased. In the process of bounding the complexity of these\nalgorithms, we also establish new nonasymptotic results on the eigenvalue\ndistribution of discrete time-frequency localization operators. We then\ndemonstrate how these algorithms allow us to efficiently compute the solution\nto certain least-squares problems that arise in signal processing. We also\nprovide simulations comparing these fast, approximate Slepian methods to exact\nSlepian methods as well as the traditional FFT based methods. \n\n"}
{"id": "1611.05343", "contents": "Title: Finite Element Approximation for the Dynamics of Fluidic Two-Phase\n  Biomembranes Abstract: Biomembranes and vesicles consisting of multiple phases can attain a\nmultitude of shapes, undergoing complex shape transitions. We study a\nCahn--Hilliard model on an evolving hypersurface coupled to Navier--Stokes\nequations on the surface and in the surrounding medium to model these\nphenomena. The evolution is driven by a curvature energy, modelling the\nelasticity of the membrane, and by a Cahn--Hilliard type energy, modelling line\nenergy effects. A stable semidiscrete finite element approximation is\nintroduced and, with the help of a fully discrete method, several phenomena\noccurring for two-phase membranes are computed. \n\n"}
{"id": "1611.05824", "contents": "Title: HDG methods for elastodynamics Abstract: We derive and analyze a hybridizable discontinuous Galerkin (HDG) method for\napproximating weak solutions to the equations of time-harmonic linear\nelasticity on a bounded Lipschitz domain in three dimensions. The real symmetry\nof the stress tensor is strongly enforced and its coefficients as well as those\nof the displacement vector field are approximated simultaneously at optimal\nconvergence with respect to the choice of approximating spaces, wavenumber, and\nmesh size. Sufficient conditions are given so that the system is indeed\ntransferable onto a global hybrid variable that, for larger polynomial degrees,\nmay be approximated via a smaller-dimensional space than the original\nvariables. We construct several variants of this method and discuss their\nadvantages and disadvantages, and give a systematic approach to the error\nanalysis for these methods. We touch briefly on the application of this error\nanalysis to the time-dependent problem, and finally, we examine two different\nimplementations of the method over various polynomial degrees and numerically\ndemonstrate the convergence properties proven herein. \n\n"}
{"id": "1611.06094", "contents": "Title: Generalizing diffuse interface methods on graphs: non-smooth potentials\n  and hypergraphs Abstract: Diffuse interface methods have recently been introduced for the task of\nsemi-supervised learning. The underlying model is well-known in materials\nscience but was extended to graphs using a Ginzburg--Landau functional and the\ngraph Laplacian. We here generalize the previously proposed model by a\nnon-smooth potential function. Additionally, we show that the diffuse interface\nmethod can be used for the segmentation of data coming from hypergraphs. For\nthis we show that the graph Laplacian in almost all cases is derived from\nhypergraph information. Additionally, we show that the formerly introduced\nhypergraph Laplacian coming from a relaxed optimization problem is well suited\nto be used within the diffuse interface method. We present computational\nexperiments for graph and hypergraph Laplacians. \n\n"}
{"id": "1611.06288", "contents": "Title: Convergence Analysis and Numerical Implementation of a Second Order\n  Numerical Scheme for the Three-Dimensional Phase Field Crystal Equation Abstract: In this paper we analyze and implement a second-order-in-time numerical\nscheme for the three-dimensional phase field crystal (PFC) equation. The\nnumerical scheme was proposed in [46], with the unique solvability and\nunconditional energy stability established. However, its convergence analysis\nremains open. We present a detailed convergence analysis in this article, in\nwhich the maximum norm estimate of the numerical solution over grid points\nplays an essential role. Moreover, we outline the detailed multigrid method to\nsolve the highly nonlinear numerical scheme over a cubic domain, and various\nthree-dimensional numerical results are presented, including the numerical\nconvergence test, complexity test of the multigrid solver and the polycrystal\ngrowth simulation. \n\n"}
{"id": "1611.08313", "contents": "Title: A hybridizable discontinuous Galerkin method for solving nonlocal\n  optical response models Abstract: We propose Hybridizable Discontinuous Galerkin (HDG) methods for solving the\nfrequency-domain Maxwell's equations coupled to the Nonlocal Hydrodynamic Drude\n(NHD) and Generalized Nonlocal Optical Response (GNOR) models, which are\nemployed to describe the optical properties of nano-plasmonic scatterers and\nwaveguides. Brief derivations for both the NHD model and the GNOR model are\npresented. The formulations of the HDG method are given, in which we introduce\ntwo hybrid variables living only on the skeleton of the mesh. The local field\nsolutions are expressed in terms of the hybrid variables in each element. Two\nconservativity conditions are globally enforced to make the problem solvable\nand to guarantee the continuity of the tangential component of the electric\nfield and the normal component of the current density. Numerical results show\nthat the proposed HDG methods converge at optimal rate. We benchmark our\nimplementation and demonstrate that the HDG method has the potential to solve\ncomplex nanophotonic problems. \n\n"}
{"id": "1612.00657", "contents": "Title: A Stable and High-Order Accurate Discontinuous Galerkin Based Splitting\n  Method for the Incompressible Navier-Stokes Equations Abstract: In this paper we consider discontinuous Galerkin (DG) methods for the\nincompressible Navier-Stokes equations in the framework of projection methods.\nIn particular we employ symmetric interior penalty DG methods within the\nsecond-order rotational incremental pressure correction scheme. The major focus\nof the paper is threefold: i) We propose a modified upwind scheme based on the\nVijayasundaram numerical flux that has favourable properties in the context of\nDG. ii) We present a novel postprocessing technique in the Helmholtz projection\nstep based on $H(\\text{div})$ reconstruction of the pressure correction that is\ncomputed locally, is a projection in the discrete setting and ensures that the\nprojected velocity satisfies the discrete continuity equation exactly. As a\nconsequence it also provides local mass conservation of the projected velocity.\niii) Numerical results demonstrate the properties of the scheme for different\npolynomial degrees applied to two-dimensional problems with known solution as\nwell as large-scale three-dimensional problems. In particular we address\nsecond-order convergence in time of the splitting scheme as well as its\nlong-time stability. \n\n"}
{"id": "1612.00977", "contents": "Title: Ubiquitous evaluation of layer potentials using Quadrature by\n  Kernel-Independent Expansion Abstract: We introduce a quadrature scheme--QBKIX--for the high-order accurate\nevaluation of layer potentials associated with general elliptic PDEs near to\nand on the domain boundary. Relying solely on point evaluations of the\nunderlying kernel, our scheme is essentially PDE-independent; in particular, no\nanalytic expansion nor addition theorem is required. Moreover, it applies to\nboundary integrals with singular, weakly singular, and hypersingular kernels.\n  Our work builds upon Quadrature by Expansion (QBX), which approximates the\npotential by an analytic expansion in the neighborhood of each expansion\ncenter. In contrast, we use a sum of fundamental solutions lying on a ring\nenclosing the neighborhood, and solve a small dense linear system for their\ncoefficients to match the potential on a smaller concentric ring.\n  We test the new method with Laplace, Helmholtz, Yukawa, Stokes, and Navier\n(elastostatic) kernels in two dimensions (2D) using adaptive, panel-based\nboundary quadratures on smooth and corner domains. Advantages of the algorithm\ninclude its relative simplicity of implementation, immediate extension to new\nkernels, dimension-independence (allowing simple generalization to 3D), and\ncompatibility with fast algorithms such as the kernel-independent FMM. \n\n"}
{"id": "1612.02736", "contents": "Title: An accelerated Poisson solver based on multidomain spectral\n  discretization Abstract: This paper presents a numerical method for variable coefficient elliptic PDEs\nwith mostly smooth solutions on two dimensional domains. The PDE is discretized\nvia a multi-domain spectral collocation method of high local order (order 30\nand higher have been tested and work well). Local mesh refinement results in\nhighly accurate solutions even in the presence of local irregular behavior due\nto corner singularities, localized loads, etc. The system of linear equations\nattained upon discretization is solved using a direct (as opposed to iterative)\nsolver with $O(N^{1.5})$ complexity for the factorization stage and $O(N \\log\nN)$ complexity for the solve. The scheme is ideally suited for executing the\nelliptic solve required when parabolic problems are discretized via\ntime-implicit techniques. In situations where the geometry remains unchanged\nbetween time-steps, very fast execution speeds are obtained since the solution\noperator for each implicit solve can be pre-computed. \n\n"}
{"id": "1612.03124", "contents": "Title: An ultraweak DPG method for viscoelastic fluids Abstract: We explore a vexing benchmark problem for viscoelastic fluid flows with the\ndiscontinuous Petrov-Galerkin (DPG) finite element method of Demkowicz and\nGopalakrishnan [1,2]. In our analysis, we develop an intrinsic a posteriori\nerror indicator which we use for adaptive mesh generation. The DPG method is\nuseful for the problem we consider because the method is inherently\nstable---requiring no stabilization of the linearized discretization in order\nto handle the advective terms in the model. Because stabilization is a pressing\nissue in these models, this happens to become a very useful property of the\nmethod which simplifies our analysis. This built-in stability at all length\nscales and the a posteriori error indicator additionally allows for the\ngeneration of parameter-specific meshes starting from a common coarse initial\nmesh. A DPG discretization always produces a symmetric positive definite\nstiffness matrix. This feature allows us to use the most efficient direct\nsolvers for all of our computations. We use the Camellia finite element\nsoftware package [3,4] for all of our analysis. \n\n"}
{"id": "1612.05429", "contents": "Title: Parameterization of Coarse-grained Molecular Interactions through\n  Potential of Mean Force Calculations and Cluster Expansions Techniques Abstract: We present a systematic coarse-graining (CG) strategy for many particle\nmolecular systems based on cluster expansion techniques. We construct a\nhierarchy of coarse-grained Hamiltonians with interaction potentials consisting\nof two, three and higher body interactions. The accuracy of the derived cluster\nexpansion based on interatomic potentials is examined over a range of various\ntemperatures and densities and compared to direct computation of pair potential\nof mean force. The comparison of the coarse-grained simulations is done on the\nbasis of the structural properties, against the detailed all-atom data. We give\nspecific examples for methane and ethane molecules in which the coarse-grained\nvariable is the center of mass of the molecule. We investigate different\ntemperature and density regimes, and we examine differences between the methane\nand ethane systems. Results show that the cluster expansion formalism can be\nused in order to provide accurate effective pair and three-body CG potentials\nat high $T$ and low $\\rho$ regimes. In the liquid regime the three-body\neffective CG potentials give a small improvement, over the typical pair CG\nones; however in order to get significantly better results one needs to\nconsider even higher order terms. \n\n"}
{"id": "1612.06672", "contents": "Title: $hp$-Adaptive Galerkin Time Stepping Methods for Nonlinear Initial Value\n  Problems Abstract: This work is concerned with the derivation of an a posteriori error estimator\nfor Galerkin approximations to nonlinear initial value problems with an\nemphasis on finite-time existence in the context of blow-up. The stucture of\nthe derived estimator leads naturally to the development of both h and hp\nversions of an adaptive algorithm designed to approximate the blow-up time. The\nadaptive algorithms are then applied in a series of numerical experiments, and\nthe rate of convergence to the blow-up time is investigated. \n\n"}
{"id": "1612.06687", "contents": "Title: Recent results in the systematic derivation and convergence of SPH Abstract: This paper presents the derivation of SPH from principles of continuum\nmechanics via a measure-based formu- lation. Additionally, it discusses a\ntheoretical convergence result, the extensions achieved from previous works and\nthe current limitations of the proof. In support of the theoretical result,\nnumerical experiments show that SPH converges with respect to the Wasserstein\ndistance as the number of particles grows to infinity. Convergence is still\nobserved for those numerical experiments which are not covered by the\nhypotheses of the theoretical result. The latter finding suggests that it\nshould be possible to prove the theoretical result under weaker conditions. \n\n"}
{"id": "1612.06813", "contents": "Title: A partial differential equation for the strictly quasiconvex envelope Abstract: In a series of papers Barron, Goebel, and Jensen studied Partial Differential\nEquations (PDE)s for quasiconvex (QC) functions \\cite{barron2012functions,\nbarron2012quasiconvex,barron2013quasiconvex,barron2013uniqueness}. To overcome\nthe lack of uniqueness for the QC PDE, they introduced a regularization: a PDE\nfor $\\e$-robust QC functions, which is well-posed. Building on this work, we\nintroduce a stronger regularization which is amenable to numerical\napproximation. We build convergent finite difference approximations, comparing\nthe QC envelope and the two regularization. Solutions of this PDE are strictly\nconvex, and smoother than the robust-QC functions. \n\n"}
{"id": "1612.07002", "contents": "Title: A subset multicanonical Monte Carlo method for simulating rare failure\n  events Abstract: Estimating failure probabilities of engineering systems is an important\nproblem in many engineering fields. In this work we consider such problems\nwhere the failure probability is extremely small (e.g $\\leq10^{-10}$). In this\ncase, standard Monte Carlo methods are not feasible due to the extraordinarily\nlarge number of samples required. To address these problems, we propose an\nalgorithm that combines the main ideas of two very powerful failure probability\nestimation approaches: the subset simulation (SS) and the multicanonical Monte\nCarlo (MMC) methods. Unlike the standard MMC which samples in the entire domain\nof the input parameter in each iteration, the proposed subset MMC algorithm\nadaptively performs MMC simulations in a subset of the state space and thus\nimproves the sampling efficiency. With numerical examples we demonstrate that\nthe proposed method is significantly more efficient than both of the SS and the\nMMC methods. Moreover, the proposed algorithm can reconstruct the complete\ndistribution function of the parameter of interest and thus can provide more\ninformation than just the failure probabilities of the systems. \n\n"}
{"id": "1612.07550", "contents": "Title: Error Analysis of Nodal Meshless Methods Abstract: There are many application papers that solve elliptic boundary value problems\nby meshless methods, and they use various forms of generalized stiffness\nmatrices that approximate derivatives of functions from values at scattered\nnodes $x_1,\\ldots,x_M\\in \\Omega\\subset\\R^d$. If $u^*$ is the true solution in\nsome Sobolev space $S$ allowing enough smoothness for the problem in question,\nand if the calculated approximate values at the nodes are denoted by $\\tilde\nu_1,\\ldots,\\tilde u_M$, the canonical form of error bounds is $$ \\max_{1\\leq\nj\\leq M}|u^*(x_j)-\\tilde u_j|\\leq \\epsilon \\|u^*\\|_S $$ where $\\epsilon$\ndepends crucially on the problem and the discretization, but not on the\nsolution. This contribution shows how to calculate such $\\epsilon$ {\\em\nnumerically and explicitly}, for any sort of discretization of strong problems\nvia nodal values, may the discretization use Moving Least Squares, unsymmetric\nor symmetric RBF collocation, or localized RBF or polynomial stencils. This\nallows users to compare different discretizations with respect to error bounds\nof the above form, without knowing exact solutions, and admitting all possible\nways to set up generalized stiffness matrices. The error analysis is proven to\nbe sharp under mild additional assumptions. As a byproduct, it allows to\nconstruct worst cases that push discretizations to their limits. All of this is\nillustrated by numerical examples. \n\n"}
{"id": "1612.07875", "contents": "Title: Streaming GPU Singular Value and Dynamic Mode Decompositions Abstract: This work develops a parallelized algorithm to compute the dynamic mode\ndecomposition (DMD) on a graphics processing unit using the streaming method of\nsnapshots singular value decomposition. This allows the algorithm to operate\nefficiently on streaming data by avoiding redundant inner-products as new data\nbecomes available. In addition, it is possible to leverage the native\ncompressed format of many data streams, such as HD video and computational\nphysics codes that are represented sparsely in the Fourier domain, to massively\nreduce data transfer from CPU to GPU and to enable sparse matrix\nmultiplications. Taken together, these algorithms facilitate real-time\nstreaming DMD on high-dimensional data streams. We demonstrate the proposed\nmethod on numerous high-dimensional data sets ranging from video background\nmodeling to scientific computing applications, where DMD is becoming a mainstay\nalgorithm. The computational framework is developed as an open-source library\nwritten in C++ with CUDA, and the algorithms may be generalized to include\nother DMD advances, such as compressed sensing DMD, multi resolution DMD, or\nDMD with control. Keywords: Singular value decomposition, dynamic mode\ndecomposition, streaming computations, graphics processing unit, video\nbackground modeling, scientific computing. \n\n"}
{"id": "1612.08077", "contents": "Title: Optimal-transport-based mesh adaptivity on the plane and sphere using\n  finite elements Abstract: In moving mesh methods, the underlying mesh is dynamically adapted without\nchanging the connectivity of the mesh. We specifically consider the generation\nof meshes which are adapted to a scalar monitor function through\nequidistribution. Together with an optimal transport condition, this leads to a\nMonge-Amp\\`ere equation for a scalar mesh potential. We adapt an existing\nfinite element scheme for the standard Monge-Amp\\`ere equation to this mesh\ngeneration problem; this is a mixed finite element scheme, in which an extra\ndiscrete variable is introduced to represent the Hessian matrix of second\nderivatives. The problem we consider has additional nonlinearities over the\nbasic Monge-Amp\\`ere equation due to the implicit dependence of the monitor\nfunction on the resulting mesh. We also derive the equivalent\nMonge-Amp\\`ere-like equation for generating meshes on the sphere. The finite\nelement scheme is extended to the sphere, and we provide numerical examples.\nAll numerical experiments are performed using the open-source finite element\nframework Firedrake. \n\n"}
{"id": "1612.08145", "contents": "Title: Computing stationary solutions of the two-dimensional Gross-Pitaevskii\n  equation with Deflated continuation Abstract: In this work we employ a recently proposed bifurcation analysis technique,\nthe deflated continuation algorithm, to compute steady-state solitary waveforms\nin a one-component, two dimensional nonlinear Schr\\\"odinger equation with a\nparabolic trap and repulsive interactions. Despite the fact that this system\nhas been studied extensively, we discover a wide variety of previously unknown\nbranches of solutions. We analyze the stability of the newly discovered\nbranches and discuss the bifurcations that relate them to known solutions both\nin the near linear (Cartesian, as well as polar) and in the highly nonlinear\nregimes. While deflated continuation is not guaranteed to compute the full\nbifurcation diagram, this analysis is a potent demonstration that the algorithm\ncan discover new nonlinear states and provide insights into the energy\nlandscape of complex high-dimensional Hamiltonian dynamical systems. \n\n"}
{"id": "1701.00068", "contents": "Title: The Discrete Stochastic Galerkin Method for Hyperbolic Equations with\n  Non-smooth and Random Coefficients Abstract: We develop a general polynomial chaos (gPC) based stochastic Galerkin (SG)\nfor hyperbolic equations with random and singular coefficients. Due to the\nsingu- lar nature of the solution, the standard gPC-SG methods may suffer from\na poor or even non convergence. Taking advantage of the fact that the discrete\nsolution, by the central type finite difference or finite volume approximations\nin space and time for example, is smoother, we first discretize the equation by\na smooth finite difference or finite volume scheme, and then use the gPC-SG\napproximation to the discrete system. The jump condition at the interface is\ntreated using the immersed upwind methods introduced in [8, 12]. This yields a\nmethod that converges with the spectral accuracy for finite mesh size and time\nstep. We use a linear hyperbolic equation with discontinuous and random\ncoefficient, and the Liouville equation with discontinuous and random\npotential, to illustrate our idea, with both one and second order spatial\ndiscretizations. Spectral convergence is established for the first equation,\nand numerical examples for both equations show the desired accu- racy of the\nmethod. \n\n"}
{"id": "1701.00668", "contents": "Title: Error estimates for Galerkin approximations of the Serre equations Abstract: We consider the Serre system of equations which is a nonlinear dispersive\nsystem that models two-way propagation of long waves of not necessarily small\namplitude on the surface of an ideal fluid in a channel. We discretize in space\nthe periodic initial-value problem for the system using the standard Galerkin\nfinite element method with smooth splines on a uniform mesh and prove an\noptimal-order $L^{2}$-error estimate for the resulting semidiscrete\napproximation. Using the fourth-order accurate, explicit, `classical'\nRunge-Kutta scheme for time stepping we construct a highly accurate fully\ndiscrete scheme in order to approximate solutions of the system, in particular\nsolitary-wave solutions, and study numerically phenomena such as the resolution\nof general initial profiles into sequences of solitary waves, and overtaking\ncollisions of pairs of solitary waves propagating in the same direction with\ndifferent speeds. \n\n"}
{"id": "1701.00694", "contents": "Title: Mixed one-bit compressive sensing with applications to overexposure\n  correction for CT reconstruction Abstract: When a measurement falls outside the quantization or measurable range, it\nbecomes saturated and cannot be used in classical reconstruction methods. For\nexample, in C-arm angiography systems, which provide projection radiography,\nfluoroscopy, digital subtraction angiography, and are widely used for medical\ndiagnoses and interventions, the limited dynamic range of C-arm flat detectors\nleads to overexposure in some projections during an acquisition, such as\nimaging relatively thin body parts (e.g., the knee). Aiming at overexposure\ncorrection for computed tomography (CT) reconstruction, we in this paper\npropose a mixed one-bit compressive sensing (M1bit-CS) to acquire information\nfrom both regular and saturated measurements. This method is inspired by the\nrecent progress on one-bit compressive sensing, which deals with only sign\nobservations. Its successful applications imply that information carried by\nsaturated measurements is useful to improve recovery quality. For the proposed\nM1bit-CS model, alternating direction methods of multipliers is developed and\nan iterative saturation detection scheme is established. Then we evaluate\nM1bit-CS on one-dimensional signal recovery tasks. In some experiments, the\nperformance of the proposed algorithms on mixed measurements is almost the same\nas recovery on unsaturated ones with the same amount of measurements. Finally,\nwe apply the proposed method to overexposure correction for CT reconstruction\non a phantom and a simulated clinical image. The results are promising, as the\ntypical streaking artifacts and capping artifacts introduced by saturated\nprojection data are effectively reduced, yielding significant error reduction\ncompared with existing algorithms based on extrapolation. \n\n"}
{"id": "1701.01608", "contents": "Title: Fast Kinetic Scheme : efficient MPI parallelization strategy for 3D\n  Boltzmann equation Abstract: In this paper we present a parallelization strategy on distributed memory\nsystems for the Fast Kinetic Scheme --- a semi-Lagrangian scheme developed in\n[J. Comput. Phys., Vol. 255, 2013, pp 680-698] for solving kinetic equations.\nThe original algorithm was proposed for the BGK approximation of the collision\nkernel. In this work we deal with its extension to the full Boltzmann equation\nin six dimensions, where the collision operator is resolved by means of fast\nspectral method. We present close to ideal scalability of the proposed\nalgorithm on tera- and peta-scale systems. \n\n"}
{"id": "1701.02818", "contents": "Title: Numerical analysis of nonlocal fracture models in H\\\"older space Abstract: In this work, we calculate the convergence rate of the finite difference\napproximation for a class of nonlocal fracture models. We consider two point\nforce interactions characterized by a double well potential. We show the\nexistence of a evolving displacement field in H\\\"{o}lder space with H\\\"{o}lder\nexponent $\\gamma \\in (0,1]$. The rate of convergence of the finite difference\napproximation depends on the factor $C_s h^\\gamma/\\epsilon^2$ where $\\epsilon$\ngives the length scale of nonlocal interaction, $h$ is the discretization\nlength and $C_s$ is the maximum of H\\\"older norm of the solution and its second\nderivatives during the evolution. It is shown that the rate of convergence\nholds for both the forward Euler scheme as well as general single step implicit\nschemes. A stability result is established for the semi-discrete approximation.\nThe H\\\"older continuous evolutions are seen to converge to a brittle fracture\nevolution in the limit of vanishing nonlocality. \n\n"}
{"id": "1701.03672", "contents": "Title: Smoothed Combined Field Integral Equations for Exterior Helmholtz\n  Problems Abstract: This paper presents smoothed combined field integral equations for the\nsolution of Dirichlet and Neumann exterior Helmholtz problems. The integral\nequations introduced in this paper are smooth in the sense that they only\ninvolve continuously differentiable integrands in both Dirichlet and Neumann\ncases. These integral equations coincide with the well-known combined field\nequations and are therefore uniquely solvable for all frequencies. In\nparticular, a novel regularization of the hypersingular operator is obtained,\nwhich, unlike regularizations based on Maue's integration-by-parts formula,\ndoes not give rise to involved Cauchy principal value integrals. The smoothed\nintegral operators and layer potentials, on the other hand, can be numerically\nevaluated at target points that are arbitrarily close to the boundary without\nseverely compromising their accuracy. A variety of numerical examples in two\nspatial dimensions that consider three different Nystr\\\"om discretizations for\nsmooth domains and domains with corners---one of which is based on direct\napplication of the trapezoidal rule---demonstrates the effectiveness of the\nproposed integral approach. In certain aspects, this work extends to the\nuniquely solvable Dirichlet and Neumann combined field integral equations, the\nideas presented in the recent contribution R. Soc. Open Sci. 2(140520), 2015. \n\n"}
{"id": "1701.04351", "contents": "Title: Lower bounds for weak approximation errors for spatial spectral Galerkin\n  approximations of stochastic wave equations Abstract: Although for a number of semilinear stochastic wave equations existence and\nuniqueness results for corresponding solution processes are known from the\nliterature, these solution processes are typically not explicitly known and\nnumerical approximation methods are needed in order for mathematical modelling\nwith stochastic wave equations to become relevant for real world applications.\nThis, in turn, requires the numerical analysis of convergence rates for such\nnumerical approximation processes. A recent article by the authors proves upper\nbounds for weak errors for spatial spectral Galerkin approximations of a class\nof semilinear stochastic wave equations. The findings there are complemented by\nthe main result of this work, that provides lower bounds for weak errors which\nshow that in the general framework considered the established upper bounds can\nessentially not be improved. \n\n"}
{"id": "1701.04685", "contents": "Title: FFT-based homogenization on periodic anisotropic translation invariant\n  spaces Abstract: In this paper we derive a discretisation of the equation of quasi-static\nelasticity in homogenization in form of a variational formulation and the\nso-called Lippmann-Schwinger equation, in anisotropic spaces of translates of\nperiodic functions. We unify and extend the truncated Fourier series approach,\nthe constant finite element ansatz and the anisotropic lattice derivation. The\nresulting formulation of the Lippmann-Schwinger equation in anisotropic\ntranslation invariant spaces unifies and analyses for the first time both the\nFourier methods and finite element approaches in a common mathematical\nframework. We further define and characterize the resulting periodised Green\noperator. This operator coincides in case of a Dirichlet kernel corresponding\nto a diagonal matrix with the operator derived for the Galerkin projection\nstemming from the truncated Fourier series approach and to the anisotropic\nlattice derivation for all other Dirichlet kernels. Additionally, we proof the\nboundedness of the periodised Green operator. The operator further constitutes\na projection if and only if the space of translates is generated by a Dirichlet\nkernel. Numerical examples for both the de la Vall\\'ee Poussin means and Box\nsplines illustrate the flexibility of this framework. \n\n"}
{"id": "1701.05602", "contents": "Title: A split step Fourier/discontinuous Galerkin scheme for the\n  Kadomtsev--Petviashvili equation Abstract: In this paper we propose a method to solve the Kadomtsev--Petviashvili\nequation based on splitting the linear part of the equation from the nonlinear\npart. The linear part is treated using FFTs, while the nonlinear part is\napproximated using a semi-Lagrangian discontinuous Galerkin approach of\narbitrary order.\n  We demonstrate the efficiency and accuracy of the numerical method by\nproviding a range of numerical simulations. In particular, we find that our\napproach can outperform the numerical methods considered in the literature by\nup to a factor of five. Although we focus on the Kadomtsev--Petviashvili\nequation in this paper, the proposed numerical scheme can be extended to a\nrange of related models as well. \n\n"}
{"id": "1701.05805", "contents": "Title: Structured low rank decomposition of multivariate Hankel matrices Abstract: We study the decomposition of a multivariate Hankel matrix H\\_$\\sigma$ as a\nsum of Hankel matrices of small rank in correlation with the decomposition of\nits symbol $\\sigma$ as a sum of polynomial-exponential series. We present a new\nalgorithm to compute the low rank decomposition of the Hankel operator and the\ndecomposition of its symbol exploiting the properties of the associated\nArtinian Gorenstein quotient algebra A\\_$\\sigma$. A basis of A\\_$\\sigma$ is\ncomputed from the Singular Value Decomposition of a sub-matrix of the Hankel\nmatrix H\\_$\\sigma$. The frequencies and the weights are deduced from the\ngeneralized eigenvectors of pencils of shifted sub-matrices of H $\\sigma$.\nExplicit formula for the weights in terms of the eigenvectors avoid us to solve\na Vandermonde system. This new method is a multivariate generalization of the\nso-called Pencil method for solving Prony-type decomposition problems. We\nanalyse its numerical behaviour in the presence of noisy input moments, and\ndescribe a rescaling technique which improves the numerical quality of the\nreconstruction for frequencies of high amplitudes. We also present a new Newton\niteration, which converges locally to the closest multivariate Hankel matrix of\nlow rank and show its impact for correcting errors on input moments. \n\n"}
{"id": "1701.06670", "contents": "Title: Arbitrary order 2D virtual elements for polygonal meshes: Part I,\n  elastic problem Abstract: The present work deals with the formulation of a Virtual Element Method (VEM)\nfor two dimensional structural problems. The contribution is split in two\nparts: in part I, the elastic problem is discussed, while in part II [3] the\nmethod is extended to material nonlinearity, considering different inelastic\nresponses of the material. In particular, in part I a standardized procedure\nfor the construction of all the terms required for the implementation of the\nmethod in a code is explained. The procedure is initially illustrated for the\nsimplest case of quadrilateral virtual elements with linear approximation of\ndisplacement variables on the boundary of the element. Then, the case of\npolygonal elements with quadratic and, even, higher order interpolation is\nconsidered. The construction of the method is detailed, deriving the\napproximation of the consistent term, the required stabilization term and the\nloading term for all the considered virtual elements. A wide numerical\ninvestigation is performed to assess the performances of the developed virtual\nelements, considering different number of edges describing the elements and\ndifferent order of approximations of the unknown field. Numerical results are\nalso compared with the one recovered using the classical finite element method. \n\n"}
{"id": "1701.06676", "contents": "Title: Arbitrary order 2D virtual elements for polygonal meshes: Part II,\n  inelastic problem Abstract: The present paper is the second part of a twofold work, whose first part is\nreported in [3], concerning a newly developed Virtual Element Method (VEM) for\n2D continuum problems. The first part of the work proposed a study for linear\nelastic problem. The aim of this part is to explore the features of the VEM\nformulation when material nonlinearity is considered, showing that the accuracy\nand easiness of implementation discovered in the analysis inherent to the first\npart of the work are still retained. Three different nonlinear constitutive\nlaws are considered in the VEM formulation. In particular, the generalized\nviscoplastic model, the classical Mises plasticity with isotropic/kinematic\nhardening and a shape memory alloy (SMA) constitutive law are implemented. The\nversatility with respect to all the considered nonlinear material constitutive\nlaws is demonstrated through several numerical examples, also remarking that\nthe proposed 2D VEM formulation can be straightforwardly implemented as in a\nstandard nonlinear structural finite element method (FEM) framework. \n\n"}
{"id": "1701.07169", "contents": "Title: An Immersed Boundary Method with Divergence-Free Velocity Interpolation\n  and Force Spreading Abstract: The Immersed Boundary (IB) method is a mathematical framework for\nconstructing robust numerical methods to study fluid-structure interaction in\nproblems involving an elastic structure immersed in a viscous fluid. The IB\nformulation uses an Eulerian representation of the fluid and a Lagrangian\nrepresentation of the structure. The Lagrangian and Eulerian frames are coupled\nby integral transforms with delta function kernels. The discretized IB\nequations use approximations to these transforms with regularized delta\nfunction kernels to interpolate the fluid velocity to the structure, and to\nspread structural forces to the fluid. It is well-known that the conventional\nIB method can suffer from poor volume conservation since the interpolated\nLagrangian velocity field is not generally divergence-free, and so this can\ncause spurious volume changes. In practice, the lack of volume conservation is\nespecially pronounced for cases where there are large pressure differences\nacross thin structural boundaries. The aim of this paper is to greatly reduce\nthe volume error of the IB method by introducing velocity-interpolation and\nforce-spreading schemes with the properties that the interpolated velocity\nfield in which the structure moves is at least C1 and satisfies a continuous\ndivergence-free condition, and that the force-spreading operator is the adjoint\nof the velocity-interpolation operator. We confirm through numerical\nexperiments in two and three spatial dimensions that this new IB method is able\nto achieve substantial improvement in volume conservation compared to other\nexisting IB methods, at the expense of a modest increase in the computational\ncost. Further, the new method provides smoother Lagrangian forces (tractions)\nthan traditional IB methods. The method presented here is restricted to\nperiodic computational domains. Its generalization to non-periodic domains is\nimportant future work. \n\n"}
{"id": "1701.07529", "contents": "Title: Transport reversal for model reduction of hyperbolic partial\n  differential equations Abstract: Snapshot matrices built from solutions to hyperbolic partial differential\nequations exhibit slow decay in singular values, whereas fast decay is crucial\nfor the success of projection- based model reduction methods. To overcome this\nproblem, we build on previous work in symmetry reduction [Rowley and Marsden,\nPhysica D (2000), pp. 1-19] and propose an iterative algorithm that decomposes\nthe snapshot matrix into multiple shifting profiles, each with a corresponding\nspeed. Its applicability to typical hyperbolic problems is demonstrated through\nnumerical examples, and other natural extensions that modify the shift operator\nare considered. Finally, we give a geometric interpretation of the algorithm. \n\n"}
{"id": "1702.01702", "contents": "Title: A Stress/Displacement Virtual Element Method for Plane Elasticity\n  Problems Abstract: The numerical approximation of 2D elasticity problems is considered, in the\nframework of the small strain theory and in connection with the mixed\nHellinger-Reissner variational formulation. A low-order Virtual Element Method\n(VEM) with a-priori symmetric stresses is proposed. Several numerical tests are\nprovided, along with a rigorous stability and convergence analysis. \n\n"}
{"id": "1702.01814", "contents": "Title: A Fast Numerical Scheme for the Godunov-Peshkov-Romenski Model of\n  Continuum Mechanics Abstract: A new second-order numerical scheme based on an operator splitting is\nproposed for the Godunov-Peshkov-Romenski model of continuum mechanics. The\nhomogeneous part of the system is solved with a finite volume method based on a\nWENO reconstruction, and the temporal ODEs are solved using some analytic\nresults presented here. Whilst it is not possible to attain arbitrary-order\naccuracy with this scheme (as with ADER-WENO schemes used previously), the\nattainable order of accuracy is often sufficient, and solutions are\ncomputationally cheap when compared with other available schemes. The new\nscheme is compared with an ADER-WENO scheme for various test cases, and a\nconvergence study is undertaken to demonstrate its order of accuracy. \n\n"}
{"id": "1702.02594", "contents": "Title: Variational discretization of the nonequilibrium thermodynamics of\n  simple systems Abstract: In this paper, we develop variational integrators for the nonequilibrium\nthermodynamics of simple closed systems. These integrators are obtained by a\ndiscretization of the Lagrangian variational formulation of nonequilibrium\nthermodynamics developed in \\cite{GBYo2016a}, and thus extend the variational\nintegrators of Lagrangian mechanics, to include irreversible processes. In the\ncontinuous setting, we derive the structure preserving property of the flow of\nsuch systems. This property is an extension of the symplectic property of the\nflow of the Euler-Lagrange equations. In the discrete setting, we show that the\ndiscrete flow solution of our numerical scheme verifies a discrete version of\nthis property. We also present the regularity conditions which ensure the\nexistence of the discrete flow. We finally illustrate our discrete variational\nschemes with the implementation of an example of a simple and closed system. \n\n"}
{"id": "1702.03361", "contents": "Title: Quasi-Monte Carlo for discontinuous integrands with singularities along\n  the boundary of the unit cube Abstract: This paper studies randomized quasi-Monte Carlo (QMC) sampling for\ndiscontinuous integrands having singularities along the boundary of the unit\ncube $[0,1]^d$. Both discontinuities and singularities are extremely common in\nthe pricing and hedging of financial derivatives and have a tremendous impact\non the accuracy of QMC. It was previously known that the root mean square error\nof randomized QMC is only $o(n^{-1/2})$ for discontinuous functions with\nsingularities. We find that under some mild conditions, randomized QMC yields\nan expected error of $O(n^{-1/2-1/(4d-2)+\\epsilon})$ for arbitrarily small\n$\\epsilon>0$. Moreover, one can get a better rate if the boundary of\ndiscontinuities is parallel to some coordinate axes. As a by-product, we find\nthat the expected error rate attains $O(n^{-1+\\epsilon})$ if the\ndiscontinuities are QMC-friendly, in the sense that all the discontinuity\nboundaries are parallel to coordinate axes. The results can be used to assess\nthe QMC accuracy for some typical problems from financial engineering. \n\n"}
{"id": "1702.03671", "contents": "Title: Fully discrete approximation of parametric and stochastic elliptic PDEs Abstract: It has recently been demonstrated that locality of spatial supports in the\nparametrization of coefficients in elliptic PDEs can lead to improved\nconvergence rates of sparse polynomial expansions of the corresponding\nparameter-dependent solutions. These results by themselves do not yield\npractically realizable approximations, since they do not cover the\napproximation of the arising expansion coefficients, which are functions of the\nspatial variable. In this work, we study the combined spatial and parametric\napproximability for elliptic PDEs with affine or lognormal parametrizations of\nthe diffusion coefficients and corresponding Taylor, Jacobi, and Hermite\nexpansions, to obtain fully discrete approximations. Our analysis yields\nconvergence rates of the fully discrete approximation in terms of the total\nnumber of degrees of freedom. The main vehicle consists in $\\ell^p$ summability\nresults for the coefficient sequences measured in higher-order Hilbertian\nSobolev norms. We also discuss similar results for non-Hilbertian Sobolev norms\nwhich arise naturally when using adaptive spatial discretizations. \n\n"}
{"id": "1702.03673", "contents": "Title: Bayesian Probabilistic Numerical Methods Abstract: The emergent field of probabilistic numerics has thus far lacked clear\nstatistical principals. This paper establishes Bayesian probabilistic numerical\nmethods as those which can be cast as solutions to certain inverse problems\nwithin the Bayesian framework. This allows us to establish general conditions\nunder which Bayesian probabilistic numerical methods are well-defined,\nencompassing both non-linear and non-Gaussian models. For general computation,\na numerical approximation scheme is proposed and its asymptotic convergence\nestablished. The theoretical development is then extended to pipelines of\ncomputation, wherein probabilistic numerical methods are composed to solve more\nchallenging numerical tasks. The contribution highlights an important research\nfrontier at the interface of numerical analysis and uncertainty quantification,\nwith a challenging industrial application presented. \n\n"}
{"id": "1702.04048", "contents": "Title: Analysis of the Residual Type and the Recovery Type a Posteriori Error\n  Estimators for a Consistent Atomistic-to-Continuum Coupling Method in 1D Abstract: We consider the a posteriori error estimation for an atomistic-to-continuum\ncou- pling scheme for a generic one-dimensional many-body\nnext-nearest-neighbour interaction model in 1D. We derive and rigorously prove\nthe efficiency of the residual type estimator. We prove the equivalence between\nthe residual type and the gradient recovery type estima- tor in the continuum\nregion and propose a (novel) hybrid a a posteriori error estimator by combining\nthe two types of estimators. Our numerical experiments illustrate the optimal\ncon- vergence rate of the adaptive algorithms using these estimators whose\nefficiency factors are also presented. \n\n"}
{"id": "1702.04540", "contents": "Title: Dispersion optimized quadratures for isogeometric analysis Abstract: We develop and analyze quadrature blending schemes that minimize the\ndispersion error of isogeometric analysis up to polynomial order seven with\nmaximum continuity in the span ($C^{p-1}$). The schemes yield two extra orders\nof convergence (superconvergence) on the eigenvalue errors, while the\neigenfunction errors are of optimal convergence order. Both dispersion and\nspectrum analysis are unified in the form of a Taylor expansion for eigenvalue\nerrors. As a consequence, the schemes increase the accuracy and robustness of\nisogeometric analysis for wave propagation as well as the differential\neigenvalue problems. We analyze the methods' robustness and efficacy and\nutilize numerical examples to verify our analysis of the performance of the\nproposed schemes. \n\n"}
{"id": "1702.05216", "contents": "Title: Numerical Analysis of the Leray Reduced Order Model Abstract: Standard ROMs generally yield spurious numerical oscillations in the\nsimulation of convection-dominated flows. Regularized ROMs use explicit ROM\nspatial filtering to decrease these spurious numerical oscillations. The Leray\nROM is a recently introduced regularized ROM that utilizes explicit ROM spatial\nfiltering of the convective term in the Navier-Stokes equations.\n  This paper presents the numerical analysis of the finite element\ndiscretization of the Leray ROM. Error estimates for the ROM differential\nfilter, which is the explicit ROM spatial filter used in the Leray ROM, are\nproved. These ROM filtering error estimates are then used to prove error\nestimates for the Leray ROM. Finally, both the ROM filtering error estimates\nand the Leray ROM error estimates are numerically investigated in the\nsimulation of the two-dimensional Navier-Stokes equations with an analytic\nsolution. \n\n"}
{"id": "1702.06443", "contents": "Title: Phaseless Sampling and Reconstruction of Real-Valued Signals in\n  Shift-Invariant Spaces Abstract: Sampling in shift-invariant spaces is a realistic model for signals with\nsmooth spectrum. In this paper, we consider phaseless sampling and\nreconstruction of real-valued signals in a shift-invariant space from their\nmagnitude measurements on the whole Euclidean space and from their phaseless\nsamples taken on a discrete set with finite sampling density. We introduce an\nundirected graph to a signal and use connectivity of the graph to characterize\nwhether the signal can be determined, up to a sign, from its magnitude\nmeasurements on the whole Euclidean space. Under the local complement property\nassumption on a shift-invariant space, we find a discrete set with finite\nsampling density such that signals in the shift-invariant space, that are\ndetermined from their magnitude measurements on the whole Euclidean space, can\nbe reconstructed in a stable way from their phaseless samples taken on that\ndiscrete set. In this paper, we also propose a reconstruction algorithm which\nprovides a suboptimal approximation to the original signal when its noisy\nphaseless samples are available only. Finally, numerical simulations are\nperformed to demonstrate the robust reconstruction of box spline signals from\ntheir noisy phaseless samples. \n\n"}
{"id": "1702.06886", "contents": "Title: Calibrated Filtered Reduced Order Modeling Abstract: We propose a calibrated filtered reduced order model (CF-ROM) framework for\nthe numerical simulation of general nonlinear PDEs that are amenable to reduced\norder modeling. The novel CF-ROM framework consists of two steps: (i) In the\nfirst step, we use explicit ROM spatial filtering of the nonlinear PDE to\nconstruct a filtered ROM. This filtered ROM is low-dimensional, but is not\nclosed (because of the nonlinearity in the given PDE). (ii) In the second step,\nwe use a calibration procedure to close the filtered ROM, i.e., to model the\ninteraction between the resolved and unresolved modes. To this end, we use a\nlinear or quadratic ansatz to model this interaction and close the filtered\nROM. To find the new coefficients in the closed filtered ROM, we solve an\noptimization problem that minimizes the difference between the full order model\ndata and our ansatz. Although we use a fluid dynamics setting to illustrate how\nto construct and use the CF-ROM framework, we emphasize that it is built on\ngeneral ideas of spatial filtering and optimization and is independent of\n(restrictive) phenomenological arguments. Thus, the CF-ROM framework can be\napplied to a wide variety of PDEs. \n\n"}
{"id": "1702.07749", "contents": "Title: Well-balanced mesh-based and meshless schemes for the shallow-water\n  equations Abstract: We formulate a general criterion for the exact preservation of the \"lake at\nrest\" solution in general mesh-based and meshless numerical schemes for the\nstrong form of the shallow-water equations with bottom topography. The main\nidea is a careful mimetic design for the spatial derivative operators in the\nmomentum flux equation that is paired with a compatible averaging rule for the\nwater column height arising in the bottom topography source term. We prove\nconsistency of the mimetic difference operators analytically and demonstrate\nthe well-balanced property numerically using finite difference and RBF-FD\nschemes in the one- and two-dimensional cases. \n\n"}
{"id": "1702.08858", "contents": "Title: Numerical stochastic homogenization by quasilocal effective diffusion\n  tensors Abstract: This paper proposes a numerical upscaling procedure for elliptic boundary\nvalue problems with diffusion tensors that vary randomly on small scales. The\nresulting effective deterministic model is given through a quasilocal discrete\nintegral operator, which can be further compressed to an effective partial\ndifferential operator. Error estimates consisting of a priori and a posteriori\nterms are provided that allow one to quantify the impact of uncertainty in the\ndiffusion coefficient on the expected effective response of the process. \n\n"}
{"id": "1703.00008", "contents": "Title: Reduced Order Optimal Control of the Convective FitzHugh-Nagumo Equation Abstract: In this paper, we compare three model order reduction methods: the proper\northogonal decomposition (POD), discrete empirical interpolation method (DEIM)\nand dynamic mode decomposition (DMD) for the optimal control of the convective\nFitzHugh-Nagumo (FHN) equations. The convective FHN equations consists of the\nsemi-linear activator and the linear inhibitor equations, modeling blood\ncoagulation in moving excitable media. The semilinear activator equation leads\nto a non-convex optimal control problem (OCP). The most commonly used method in\nreduced optimal control is POD. We use DEIM and DMD to approximate efficiently\nthe nonlinear terms in reduced order models. We compare the accuracy and\ncomputational times of three reduced-order optimal control solutions with the\nfull order discontinuous Galerkin finite element solution of the convection\ndominated FHN equations with terminal controls. Numerical results show that POD\nis the most accurate whereas POD-DMD is the fastest. \n\n"}
{"id": "1703.02499", "contents": "Title: URV Factorization with Random Orthogonal System Mixing Abstract: The unpivoted and pivoted Householder QR factorizations are ubiquitous in\nnumerical linear algebra. A difficulty with pivoted Householder QR is the\ncommunication bottleneck introduced by pivoting. In this paper we propose using\nrandom orthogonal systems to quickly mix together the columns of a matrix\nbefore computing an unpivoted QR factorization. This method computes a URV\nfactorization which forgoes expensive pivoted QR steps in exchange for mixing\nin advance, followed by a cheaper, unpivoted QR factorization. The mixing step\ntypically reduces the variability of the column norms, and in certain\nexperiments, allows us to compute an accurate factorization where a plain,\nunpivoted QR performs poorly. We experiment with linear least-squares,\nrank-revealing factorizations, and the QLP approximation, and conclude that our\nrandomized URV factorization behaves comparably to a similar randomized\nrank-revealing URV factorization, but at a fraction of the computational cost.\nOur experiments provide evidence that our proposed factorization might be\nrank-revealing with high probability. \n\n"}
{"id": "1703.03090", "contents": "Title: Characterizing the impact of model error in hydrogeologic time series\n  recovery inverse problems Abstract: Hydrogeologic models are commonly over-smoothed relative to reality, owing to\nthe difficulty of obtaining accurate high-resolution information about the\nsubsurface. When used in an inversion context, such models may introduce\nsystematic biases which cannot be encapsulated by an unbiased \"observation\nnoise\" term of the type assumed by standard regularization theory and typical\nBayesian formulations. Despite its importance, model error is difficult to\nencapsulate systematically and is often neglected. Here, model error is\nconsidered for a hydrogeologically important class of inverse problems that\nincludes interpretation of hydraulic transients and contaminant source history\ninference: reconstruction of a time series that has been convolved against a\ntransfer function (i.e., impulse response) that is only approximately known.\nUsing established harmonic theory along with two results established here\nregarding triangular Toeplitz matrices, upper and lower error bounds are\nderived for the effect of systematic model error on time series recovery for\nboth well-determined and over-determined inverse problems. A Monte Carlo study\nof a realistic hydraulic reconstruction problem is presented, and the lower\nerror bound is seen informative about expected behavior. A possible diagnostic\ncriterion for blind transfer function characterization is also uncovered. \n\n"}
{"id": "1703.03743", "contents": "Title: The Marcinkiewicz-type discretization theorems Abstract: The paper is devoted to discretization of integral norms of functions from a\ngiven finite dimensional subspace. This problem is very important in\napplications but there is no systematic study of it. We present here a new\ntechnique, which works well for discretization of the integral norm. It is a\ncombination of probabilistic technique, based on chaining, with results on the\nentropy numbers in the uniform norm. \n\n"}
{"id": "1703.04987", "contents": "Title: Equilibrated flux a posteriori error estimates in $L^2(H^1)$-norms for\n  high-order discretizations of parabolic problems Abstract: We consider the a posteriori error analysis of fully discrete approximations\nof parabolic problems based on conforming $hp$-finite element methods in space\nand an arbitrary order discontinuous Galerkin method in time. Using an\nequilibrated flux reconstruction, we present a posteriori error estimates\nyielding guaranteed upper bounds on the $L^2(H^1)$-norm of the error, without\nunknown constants and without restrictions on the spatial and temporal meshes.\nIt is known from the literature that the analysis of the efficiency of the\nestimators represents a significant challenge for $L^2(H^1)$-norm estimates.\nHere we show that the estimator is bounded by the $L^2(H^1)$-norm of the error\nplus the temporal jumps under the one-sided parabolic condition $h^2 \\lesssim\n\\tau$. This result improves on earlier works that required stronger two-sided\nhypotheses such as $h \\simeq \\tau$ or $h^2\\simeq \\tau$; instead our result now\nencompasses the practically relevant case for computations and allows for\nlocally refined spatial meshes. The constants in our bounds are robust with\nrespect to the mesh and time-step sizes, the spatial polynomial degrees, and\nalso with respect to refinement and coarsening between time-steps, thereby\nremoving any transition condition. \n\n"}
{"id": "1703.06116", "contents": "Title: A Surface Hopping Gaussian Beam Method for High-Dimensional Transport\n  Systems Abstract: We propose a surface hopping Gaussian beam method to numerically solve a\nclass of high frequency linear transport systems in high spatial dimensions,\nbased on asymptotic analysis. The stochastic surface hopping is combined with\nGaussian beam method to deal with the multiple characteristic directions of the\ntransport system in high dimensions. The Monte Carlo nature of the proposed\nalgorithm makes it easy for parallel implementations. We validate the\nperformance of the algorithms for applications on the quantum-classical\nLiouville equations. \n\n"}
{"id": "1703.06917", "contents": "Title: On the scaling of entropy viscosity in high order methods Abstract: In this work, we outline the entropy viscosity method and discuss how the\nchoice of scaling influences the size of viscosity for a simple shock problem.\nWe present examples to illustrate the performance of the entropy viscosity\nmethod under two distinct scalings. \n\n"}
{"id": "1703.09971", "contents": "Title: A Geometric Framework for Stochastic Shape Analysis Abstract: We introduce a stochastic model of diffeomorphisms, whose action on a variety\nof data types descends to stochastic evolution of shapes, images and landmarks.\nThe stochasticity is introduced in the vector field which transports the data\nin the Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework for\nshape analysis and image registration. The stochasticity thereby models errors\nor uncertainties of the flow in following the prescribed deformation velocity.\nThe approach is illustrated in the example of finite dimensional landmark\nmanifolds, whose stochastic evolution is studied both via the Fokker-Planck\nequation and by numerical simulations. We derive two approaches for inferring\nparameters of the stochastic model from landmark configurations observed at\ndiscrete time points. The first of the two approaches matches moments of the\nFokker-Planck equation to sample moments of the data, while the second approach\nemploys an Expectation-Maximisation based algorithm using a Monte Carlo bridge\nsampling scheme to optimise the data likelihood. We derive and numerically test\nthe ability of the two approaches to infer the spatial correlation length of\nthe underlying noise. \n\n"}
{"id": "1703.10740", "contents": "Title: Fundamental Conditions for Low-CP-Rank Tensor Completion Abstract: We consider the problem of low canonical polyadic (CP) rank tensor\ncompletion. A completion is a tensor whose entries agree with the observed\nentries and its rank matches the given CP rank. We analyze the manifold\nstructure corresponding to the tensors with the given rank and define a set of\npolynomials based on the sampling pattern and CP decomposition. Then, we show\nthat finite completability of the sampled tensor is equivalent to having a\ncertain number of algebraically independent polynomials among the defined\npolynomials. Our proposed approach results in characterizing the maximum number\nof algebraically independent polynomials in terms of a simple geometric\nstructure of the sampling pattern, and therefore we obtain the deterministic\nnecessary and sufficient condition on the sampling pattern for finite\ncompletability of the sampled tensor. Moreover, assuming that the entries of\nthe tensor are sampled independently with probability $p$ and using the\nmentioned deterministic analysis, we propose a combinatorial method to derive a\nlower bound on the sampling probability $p$, or equivalently, the number of\nsampled entries that guarantees finite completability with high probability. We\nalso show that the existing result for the matrix completion problem can be\nused to obtain a loose lower bound on the sampling probability $p$. In\naddition, we obtain deterministic and probabilistic conditions for unique\ncompletability. It is seen that the number of samples required for finite or\nunique completability obtained by the proposed analysis on the CP manifold is\norders-of-magnitude lower than that is obtained by the existing analysis on the\nGrassmannian manifold. \n\n"}
{"id": "1704.02153", "contents": "Title: C-eigenvalues intervals for Piezoelectric-type tensors Abstract: C-eigenvalues of piezoelectric-type tensors which are real and always exist,\nare introduced by Chen et al. [1]. And the largest C-eigenvalue for the\npiezoelectric tensor determines the highest piezoelectric coupling constant. In\nthis paper, we give two intervals to locate all C-eigenvalues for a given\nPiezoelectric-type tensor. These intervals provide upper bounds for the largest\nC-eigenvalue. Numerical examples are also given to show the corresponding\nresults. \n\n"}
{"id": "1704.02549", "contents": "Title: Solving Parameter Estimation Problems with Discrete Adjoint Exponential\n  Integrators Abstract: The solution of inverse problems in a variational setting finds best\nestimates of the model parameters by minimizing a cost function that penalizes\nthe mismatch between model outputs and observations. The gradients required by\nthe numerical optimization process are computed using adjoint models.\nExponential integrators are a promising family of time discretizations for\nevolutionary partial differential equations. In order to allow the use of these\ndiscretizations in the context of inverse problems adjoints of exponential\nintegrators are required. This work derives the discrete adjoint formulae for a\nW-type exponential propagation iterative methods of Runge-Kutta type (EPIRK-W).\nThese methods allow arbitrary approximations of the Jacobian while maintaining\nthe overall accuracy of the forward integration. The use of Jacobian\napproximation matrices that do not depend on the model state avoids the complex\ncalculation of Hessians in the discrete adjoint formulae, and allows efficient\nadjoint code generation via algorithmic differentiation. We use the discrete\nEPIRK-W adjoints to solve inverse problems with the Lorenz-96 model and a\ncomputational magnetics benchmark test. Numerical results validate our\ntheoretical derivations. \n\n"}
{"id": "1704.05238", "contents": "Title: Babu\\v{s}ka-Osborn techniques in discontinuous Galerkin methods:\n  $L^2$-norm error estimates for unstructured meshes Abstract: We prove the inf-sup stability of the interior penalty class of discontinuous\nGalerkin schemes in unbalanced mesh-dependent norms, under a mesh condition\nallowing for a general class of meshes, which includes many examples of\ngeometrically graded element neighbourhoods. The inf-sup condition results in\nthe stability of the interior penalty Ritz projection in $L^2$ as well as, for\nthe first time, quasi-best approximations in the $L^2$-norm which in turn imply\na priori error estimates that do not depend on the global maximum meshsize in\nthat norm. Some numerical experiments are also given. \n\n"}
{"id": "1704.05690", "contents": "Title: A Fractional Gauss-Jacobi quadrature rule for approximating fractional\n  integrals and derivatives Abstract: We introduce an efficient algorithm for computing fractional integrals and\nderivatives and apply it for solving problems of the calculus of variations of\nfractional order. The proposed approximations are particularly useful for\nsolving fractional boundary value problems. As an application, we solve a\nspecial class of fractional Euler-Lagrange equations. The method is based on\nHale and Townsend algorithm for finding the roots and weights of the fractional\nGauss-Jacobi quadrature rule and the predictor-corrector method introduced by\nDiethelm for solving fractional differential equations. Illustrative examples\nshow that the given method is more accurate than the one introduced in [Comput.\nMath. Appl. 66 (2013), no. 5, 597--607], which uses the Golub-Welsch algorithm\nfor evaluating fractional directional integrals. \n\n"}
{"id": "1704.06733", "contents": "Title: A fast second-order implicit difference method for time-space fractional\n  advection-diffusion equation Abstract: In this paper, we consider a fast and second-order implicit difference method\nfor approximation of a class of time-space fractional variable coefficients\nadvection-diffusion equation. To begin with, we construct an implicit\ndifference scheme, based on $L2-1_{\\sigma}$ formula [A. A. Alikhanov, A new\ndifference scheme for the time fractional diffusion equation, \\emph{J. Comput.\nPhys.}, 280 (2015)] for the temporal discretization and weighted and shifted\nGr\\\"{u}nwald method for the spatial discretization. Then, unconditional\nstability of the implicit difference scheme is proved, and we theoretically and\nnumerically show that it converges in the $L_2$-norm with the optimal order\n$\\mathcal{O}(\\tau^2 + h^2)$ with time step $\\tau$ and mesh size $h$. Secondly,\nthree fast Krylov subspace solvers with suitable circulant preconditioners are\ndesigned to solve the discretized linear systems with the Toeplitz matrix. In\neach iterative step, these methods reduce the memory requirement of the\nresulting linear equations from $\\mathcal{O}(N^2)$ to $\\mathcal{O}(N)$ and the\ncomputational complexity from $\\mathcal{O}(N^3)$ to $\\mathcal{O}(N \\log N)$,\nwhere $N$ is the number of grid nodes. Finally, numerical experiments are\ncarried out to demonstrate that these methods are more practical than the\ntraditional direct solvers of the implicit difference methods, in terms of\nmemory requirement and computational cost. \n\n"}
{"id": "1704.07745", "contents": "Title: A hybrid numerical-asymptotic boundary element method for high frequency\n  scattering by penetrable convex polygons Abstract: We present a novel hybrid numerical-asymptotic boundary element method for\nhigh frequency acoustic and electromagnetic scattering by penetrable\n(dielectric) convex polygons. Our method is based on a standard reformulation\nof the associated transmission boundary value problem as a direct boundary\nintegral equation for the unknown Cauchy data, but with a nonstandard numerical\ndiscretization which efficiently captures the high frequency oscillatory\nbehaviour. The Cauchy data is represented as a sum of the classical geometrical\noptics approximation, computed by a beam tracing algorithm, plus a contribution\ndue to diffraction, computed by a Galerkin boundary element method using\noscillatory basis functions chosen according to the principles of the\nGeometrical Theory of Diffraction. We demonstrate with a range of numerical\nexperiments that our boundary element method can achieve a fixed accuracy of\napproximation using only a relatively small, frequency-independent number of\ndegrees of freedom. Moreover, for the scattering scenarios we consider, the\ninclusion of the diffraction term provides an order of magnitude improvement in\naccuracy over the geometrical optics approximation alone. \n\n"}
{"id": "1704.08654", "contents": "Title: An efficient method to compute solitary wave solutions of fractional\n  Korteweg-de Vries equations Abstract: Considered here is an efficient technique to compute approximate profiles of\nsolitary wave solutions of fractional Korteweg-de Vries equations. The\nnumerical method is based on a fixed-point iterative algorithm along with\nextrapolation techniques of acceleration. This combination improves the\nperformance in both the velocity of convergence and the computation of profiles\nfor limiting values of the fractional parameter. The algorithm is described and\nnumerical experiments of validation are presented. The accuracy attained by the\nprocedure can be used to investigate additional properties of the waves. This\napproach is illustrated here by analyzing the speed-amplitude relation. \n\n"}
{"id": "1705.00931", "contents": "Title: Finite Volume approximations of the Euler system with variable\n  congestion Abstract: We are interested in the numerical simulations of the Euler system with\nvariable congestion encoded by a singular pressure. This model describes for\ninstance the macroscopic motion of a crowd with individual congestion\npreferences. We propose an asymptotic preserving (AP) scheme based on a\nconservative formulation of the system in terms of density, momentum and\ndensity fraction. A second order accuracy version of the scheme is also\npresented. We validate the scheme on one-dimensional test-cases and extended\nhere to higher order accuracy. We finally carry out two dimensional numerical\nsimulations and show that the model exhibit typical crowd dynamics. \n\n"}
{"id": "1705.01503", "contents": "Title: Insights on aliasing driven instabilities for advection equations with\n  application to Gauss-Lobatto discontinuous Galerkin methods Abstract: We analyse instabilities due to aliasing errors when solving one dimensional\nnon-constant advection speed equations and discuss means to alleviate these\ntypes of errors when using high order discontinuous Galerkin (DG) schemes.\nFirst, we compare analytical bounds for the continuous and discrete version of\nthe PDEs. Whilst traditional $L^2$ norm energy bounds applied to the discrete\nPDE do not always predict the physical behaviour of the continuous version of\nthe equation, more strict elliptic norm bounds correctly bound the behaviour of\nthe continuous PDE. Having derived consistent bounds, we analyse the\neffectiveness of two stabilising techniques: over-integration and split form\nvariations (conservative, non-conservative and skew-symmetric). Whilst the\nformer is shown to not alleviate aliasing in general, the latter ensures an\naliasing-free solution if the splitting form of the discrete PDE is consistent\nwith the continuous equation. The success of split form de-aliasing is\nrestricted to DG schemes with the summation-by-parts\nsimultaneous-approximation-term (SBP-SAT) properties (e.g. DG with\nGauss-Lobatto points). Numerical experiments are included to illustrate the\ntheoretical findings. \n\n"}
{"id": "1705.01857", "contents": "Title: Avoiding order reduction when integrating diffusion-reaction boundary\n  value problems with exponential splitting methods Abstract: In this paper, we suggest a technique to avoid order reduction in time when\nintegrating reaction-diffusion boundary value problems under non-homogeneous\nboundary conditions with exponential splitting methods. More precisely, we\nconsider Lie-Trotter and Strang splitting methods and Dirichlet, Neumann and\nRobin boundary conditions. Beginning from an abstract framework in Banach\nspaces, a thorough error analysis after full discretization is performed and\nsome numerical results are shown which corroborate the theoretical results. \n\n"}
{"id": "1705.03666", "contents": "Title: Hybrid PDE solver for data-driven problems and modern branching Abstract: The numerical solution of large-scale PDEs, such as those occurring in\ndata-driven applications, unavoidably require powerful parallel computers and\ntailored parallel algorithms to make the best possible use of them. In fact,\nconsiderations about the parallelization and scalability of realistic problems\nare often critical enough to warrant acknowledgement in the modelling phase.\nThe purpose of this paper is to spread awareness of the Probabilistic Domain\nDecomposition (PDD) method, a fresh approach to the parallelization of PDEs\nwith excellent scalability properties. The idea exploits the stochastic\nrepresentation of the PDE and its approximation via Monte Carlo in combination\nwith deterministic high-performance PDE solvers. We describe the ingredients of\nPDD and its applicability in the scope of data science. In particular, we\nhighlight recent advances in stochastic representations for nonlinear PDEs\nusing branching diffusions, which have significantly broadened the scope of\nPDD.\n  We envision this work as a dictionary giving large-scale PDE practitioners\nreferences on the very latest algorithms and techniques of a non-standard, yet\nhighly parallelizable, methodology at the interface of deterministic and\nprobabilistic numerical methods. We close this work with an invitation to the\nfully nonlinear case and open research questions. \n\n"}
{"id": "1705.03969", "contents": "Title: Well-posedness and numerical approximation of tempered fractional\n  terminal value problems Abstract: For a class of tempered fractional terminal value problems of the Caputo\ntype, we study the existence and uniqueness of the solution, analyse the\ncontinuous dependence on the given data and using a shooting method, we present\nand discuss three numerical schemes for the numerical approximation of such\nproblems. Some numerical examples are considered in order to illustrate the\ntheoretical results and evidence the efficiency of the numerical methods. \n\n"}
{"id": "1705.04369", "contents": "Title: Analysis of the finite element method for the Laplace--Beltrami equation\n  on surfaces with regions of high curvature using graded meshes Abstract: We derive error estimates for the piecewise linear finite element\napproximation of the Laplace--Beltrami operator on a bounded, orientable,\n$C^3$, surface without boundary on general shape regular meshes. As an\napplication, we consider a problem where the domain is split into two regions:\none which has relatively high curvature and one that has low curvature. Using a\ngraded mesh we prove error estimates that do not depend on the curvature on the\nhigh curvature region. Numerical experiments are provided. \n\n"}
{"id": "1705.04431", "contents": "Title: Spectral Galerkin methods for transfer operators in uniformly expanding\n  dynamics Abstract: Markov expanding maps, a class of simple chaotic systems, are commonly used\nas models for chaotic dynamics, but existing numerical methods to study\nlong-time statistical properties such as invariant measures have a poor\ntrade-off between computational effort and accuracy. We develop a spectral\nGalerkin method for these maps' transfer operators, estimating statistical\nquantities using finite submatrices of the transfer operators' infinite Fourier\nor Chebyshev basis coefficient matrices. Rates of convergence of these\nestimates are obtained via quantitative bounds on the full transfer operator\nmatrix entries; we find the method furnishes up to exponentially accurate\nestimates of statistical properties in only a polynomially large computational\ntime.\n  To implement these results we suggest and demonstrate two algorithms: a\nrigorously-validated algorithm, and a fast, more convenient adaptive algorithm.\nUsing the first algorithm we prove rigorous bounds on some exemplar quantities\nthat are substantially more accurate than previous. We show that the adaptive\nalgorithm can produce double floating-point accuracy estimates in a fraction of\na second on a personal computer. \n\n"}
{"id": "1705.04481", "contents": "Title: Robust multigrid methods for isogeometric discretizations of the Stokes\n  equations Abstract: In recent publications, the author and his coworkers have proposed a\nmultigrid method for solving linear systems arizing from the discretization of\npartial differential equations in isogeometric analysis and have proven that\nthe convergence rates are robust in both the grid size and the polynomial\ndegree. So, far the method has only been discussed for the Poisson problem. In\nthe present paper, we want to face the question if it is possible to extend the\nmethod to the Stokes equations. \n\n"}
{"id": "1705.04603", "contents": "Title: Parametric Imaging of FDG-PET Data Using Physiology and Iterative\n  Regularization: Application to the Hepatic and Renal Systems Abstract: The present paper proposes a novel computational method for parametric\nimaging of nuclear medicine data. The mathematical procedure is general enough\nto work for compartmental models of diverse complexity and is effective in the\ndetermination of the parametric maps of all kinetic parameters governing tracer\nflow. We consider applications to [18F]-fluorodeoxyglucose Positron Emission\nTomography (FDG-PET) data and analyze the two-compartment catenary model\ndescribing the standard FDG metabolization by an homogeneous tissue, e.g. the\nliver, and the three-compartment non-catenary model representing the renal\nphysiology. The proposed imaging method starts from the reconstructed FDG-PET\nimages of tracer concentration and preliminarily applies image processing\nalgorithms for noise reduction and image segmentation processes for selecting\nthe region enclosing the organ of physiologic interest. The optimization scheme\nsolves pixelwise the non-linear inverse problem of determining the kinetic\nparameters from dynamic concentration data through a Gauss-Newton iterative\nalgorithm with a penalty term accounting for the ill-posedness of the problem.\nWe tested our imaging approach on FDG-PET data of murine models obtained by\nmeans of a dedicated microPET system, and we analyzed different PET slices\ncontaining axial sections of the liver and axial sections of the kidneys. The\nreconstructed parametric images proved to be reliable and qualitatively\neffective in the description of the local FDG metabolism with respect to the\ndifferent physiologies. \n\n"}
{"id": "1705.05407", "contents": "Title: Discontinuous Galerkin algorithms for fully kinetic plasmas Abstract: We present a new algorithm for the discretization of the Vlasov-Maxwell\nsystem of equations for the study of plasmas in the kinetic regime. Using the\ndiscontinuous Galerkin finite element method for the spatial discretization, we\nobtain a high order accurate solution for the plasma's distribution function.\nTime stepping for the distribution function is done explicitly with a third\norder strong-stability preserving Runge-Kutta method. Since the Vlasov equation\nin the Vlasov-Maxwell system is a high dimensional transport equation, up to\nsix dimensions plus time, we take special care to note various features we have\nimplemented to reduce the cost while maintaining the integrity of the solution,\nincluding the use of a reduced high-order basis set. A series of benchmarks,\nfrom simple wave and shock calculations, to a five dimensional turbulence\nsimulation, are presented to verify the efficacy of our set of numerical\nmethods, as well as demonstrate the power of the implemented features. \n\n"}
{"id": "1705.06807", "contents": "Title: Parallel replica dynamics method for bistable stochastic reaction\n  networks: simulation and sensitivity analysis Abstract: Stochastic reaction networks that exhibit bistability are common in many\nfields such as systems biology and materials science. Sampling of the\nstationary distribution is crucial for understanding and characterizing the\nlong term dynamics of bistable stochastic dynamical systems. However, this is\nnormally hindered by the insufficient sampling of the rare transitions between\nthe two metastable regions. In this paper, we apply the parallel replica\n(ParRep) method for continuous time Markov chain to accelerate the stationary\ndistribution sampling of bistable stochastic reaction networks. The proposed\nmethod uses parallel computing to accelerate the sampling of rare transitions\nand it is very easy to implement. We combine ParRep with the path space\ninformation bounds for parametric sensitivity analysis. We demonstrate the\nefficiency and accuracy of the method by studying the Schl\\\"{o}gl model and the\ngenetic switches network. \n\n"}
{"id": "1705.07316", "contents": "Title: Robust regularization of topology optimization problems with a\n  posteriori error estimators Abstract: Topological optimization finds a material density distribution minimizing a\nfunctional of the solution of a partial differential equation (PDE), subject to\na set of constraints (typically, a bound on the volume or mass of the\nmaterial).\n  Using a finite elements discretization (FEM) of the PDE and functional we\nobtain an integer programming problem. Due to approximation error of FEM\ndiscretization, optimization problem becomes mesh-depended and possess false,\nphysically inadequate optimums, while functional value heavily depends on\nfineness of discretization scheme used to compute it. To alleviate this\nproblem, we propose regularization of given functional by error estimate of FEM\ndiscretization. This regularization provides robustness of solutions and\nimproves obtained functional values as well.\n  While the idea is broadly applicable, in this paper we apply our method to\nthe heat conduction optimization. This type of problems are of practical\nimportance in design of heat conduction channels, heat sinks and other types of\nheat guides. \n\n"}
{"id": "1705.07507", "contents": "Title: Analysis of Krylov Subspace Approximation to Large Scale Differential\n  Riccati Equations Abstract: We consider a Krylov subspace approximation method for the symmetric\ndifferential Riccati equation $\\dot{X} = AX + XA^T + Q - XSX$, $X(0)=X_0$. The\nmethod we consider is based on projecting the large scale equation onto a\nKrylov subspace spanned by the matrix $A$ and the low rank factors of $X_0$ and\n$Q$. We prove that the method is structure preserving in the sense that it\npreserves two important properties of the exact flow, namely the positivity of\nthe exact flow, and also the property of monotonicity. We also provide a\ntheoretical a priori error analysis which shows a superlinear convergence of\nthe method. This behavior is illustrated in the numerical experiments.\nMoreover, we derive an efficient a posteriori error estimate as well as discuss\nmultiple time stepping combined with a cut of the rank of the numerical\nsolution. \n\n"}
{"id": "1705.08138", "contents": "Title: A two-level domain-decomposition preconditioner for the time-harmonic\n  Maxwell's equations Abstract: The construction of fast iterative solvers for the indefinite time-harmonic\nMaxwell's system at mid- to high-frequency is a problem of great current\ninterest. Some of the difficulties that arise are similar to those encountered\nin the case of the mid- to high-frequency Helmholtz equation. Here we\ninvestigate how two-level domain-decomposition preconditioners recently\nproposed for the Helmholtz equation work in the Maxwell case, both from the\ntheoretical and numerical points of view. \n\n"}
{"id": "1705.08445", "contents": "Title: Stratification as a general variance reduction method for Markov chain\n  Monte Carlo Abstract: The Eigenvector Method for Umbrella Sampling (EMUS) belongs to a popular\nclass of methods in statistical mechanics which adapt the principle of\nstratified survey sampling to the computation of free energies. We develop a\ndetailed theoretical analysis of EMUS. Based on this analysis, we show that\nEMUS is an efficient general method for computing averages over arbitrary\ntarget distributions. In particular, we show that EMUS can be dramatically more\nefficient than direct MCMC when the target distribution is multimodal or when\nthe goal is to compute tail probabilities. To illustrate these theoretical\nresults, we present a tutorial application of the method to a problem from\nBayesian statistics. \n\n"}
{"id": "1705.08813", "contents": "Title: A multiscale approach to hybrid RANS/LES wall modeling within a\n  high-order discontinuous Galerkin scheme using function enrichment Abstract: We present a novel approach to hybrid RANS/LES wall modeling based on\nfunction enrichment, which overcomes the common problem of the RANS-LES\ntransition and enables coarse meshes near the boundary. While the concept of\nfunction enrichment as an efficient discretization technique for turbulent\nboundary layers has been proposed in an earlier article by Krank & Wall (J.\nComput. Phys. 316 (2016) 94-116), the contribution of this work is a rigorous\nderivation of a new multiscale turbulence modeling approach and a corresponding\ndiscontinuous Galerkin discretization scheme. In the near-wall area, the\nNavier-Stokes equations are explicitly solved for an LES and a RANS component\nin one single equation. This is done by providing the Galerkin method with an\nindependent set of shape functions for each of these two methods; the standard\nhigh-order polynomial basis resolves turbulent eddies where the mesh is\nsufficiently fine and the enrichment automatically computes the\nensemble-averaged flow if the LES mesh is too coarse. As a result of the\nderivation, the RANS model is consistently applied solely to the RANS degrees\nof freedom, which effectively prevents the typical issue of a log-layer\nmismatch in attached boundary layers. As the full Navier-Stokes equations are\nsolved in the boundary layer, spatial refinement gradually yields wall-resolved\nLES with exact boundary conditions. Numerical tests show the outstanding\ncharacteristics of the wall model regarding grid independence, superiority\ncompared to equilibrium wall models in separated flows, and achieve a speed-up\nby two orders of magnitude compared to wall-resolved LES. \n\n"}
{"id": "1705.09923", "contents": "Title: An exponential integrator for the drift-kinetic model Abstract: We propose an exponential integrator for the drift-kinetic equation in\ncylindrical geometry. This approach removes the CFL condition from the linear\npart of the system (which is often the most stringent requirement in practice)\nand treats the remainder explicitly using Arakawa's finite difference scheme.\nThe present approach is mass conservative, up to machine precision, and\nsignificantly reduces the computational effort per time step.\n  In addition, we demonstrate the efficiency of our method by performing\nnumerical simulations in the context of the ion temperature gradient\ninstability. In particular, we find that our numerical method can take time\nsteps comparable to what has been reported in the literature for the\n(predominantly used) splitting approach. In addition, the proposed numerical\nmethod has significant advantages with respect to conservation of energy and\nefficient higher order methods can be obtained easily. We demonstrate this by\ninvestigating the performance of a fourth order implementation. \n\n"}
{"id": "1705.10881", "contents": "Title: A general theory of singular values with applications to signal\n  denoising Abstract: We study the Pareto frontier for two competing norms $\\|\\cdot\\|_X$ and\n$\\|\\cdot\\|_Y$ on a vector space. For a given vector $c$, the pareto frontier\ndescribes the possible values of $(\\|a\\|_X,\\|b\\|_Y)$ for a decomposition\n$c=a+b$. The singular value decomposition of a matrix is closely related to the\nPareto frontier for the spectral and nuclear norm. We will develop a general\ntheory that extends the notion of singular values of a matrix to arbitrary\nfinite dimensional euclidean vector spaces equipped with dual norms. This also\ngeneralizes the diagonal singular value decompositions for tensors introduced\nby the author in previous work. We can apply the results to denoising, where\n$c$ is a noisy signal, $a$ is a sparse signal and $b$ is noise. Applications\ninclude 1D total variation denoising, 2D total variation Rudin-Osher-Fatemi\nimage denoising, LASSO, basis pursuit denoising and tensor decompositions. \n\n"}
{"id": "1706.00078", "contents": "Title: Low-Rank Matrix Approximation in the Infinity Norm Abstract: The low-rank matrix approximation problem with respect to the entry-wise\n$\\ell_{\\infty}$-norm is the following: given a matrix $M$ and a factorization\nrank $r$, find a matrix $X$ whose rank is at most $r$ and that minimizes\n$\\max_{i,j} |M_{ij} - X_{ij}|$. In this paper, we prove that the decision\nvariant of this problem for $r=1$ is NP-complete using a reduction from the\nproblem `not all equal 3SAT'. We also analyze several cases when the problem\ncan be solved in polynomial time, and propose a simple practical heuristic\nalgorithm which we apply on the problem of the recovery of a quantized low-rank\nmatrix. \n\n"}
{"id": "1706.02132", "contents": "Title: Newton correction methods for computing real eigenpairs of symmetric\n  tensors Abstract: Real eigenpairs of symmetric tensors play an important role in multiple\napplications. In this paper we propose and analyze a fast iterative\nNewton-based method to compute real eigenpairs of symmetric tensors. We derive\nsufficient conditions for a real eigenpair to be a stable fixed point for our\nmethod, and prove that given a sufficiently close initial guess, the\nconvergence rate is quadratic. Empirically, our method converges to a\nsignificantly larger number of eigenpairs compared to previously proposed\niterative methods, and with enough random initializations typically finds all\nreal eigenpairs. In particular, for a generic symmetric tensor, the sufficient\nconditions for local convergence of our Newton-based method hold simultaneously\nfor all its real eigenpairs. \n\n"}
{"id": "1706.04380", "contents": "Title: Multiscale differential Riccati equations for linear quadratic regulator\n  problems Abstract: We consider approximations to the solutions of differential Riccati equations\nin the context of linear quadratic regulator problems, where the state equation\nis governed by a multiscale operator. Similarly to elliptic and parabolic\nproblems, standard finite element discretizations perform poorly in this\nsetting unless the grid resolves the fine-scale features of the problem. This\nresults in unfeasible amounts of computation and high memory requirements. In\nthis paper, we demonstrate how the localized orthogonal decomposition method\nmay be used to acquire accurate results also for coarse discretizations, at the\nlow cost of solving a series of small, localized elliptic problems. We prove\nsecond-order convergence (except for a logarithmic factor) in the $L^2$\noperator norm, and first-order convergence in the corresponding energy norm.\nThese results are both independent of the multiscale variations in the state\nequation. In addition, we provide a detailed derivation of the fully discrete\nmatrix-valued equations, and show how they can be handled in a low-rank setting\nfor large-scale computations. In connection to this, we also show how to\nefficiently compute the relevant operator-norm errors. Finally, our theoretical\nresults are validated by several numerical experiments. \n\n"}
{"id": "1706.06459", "contents": "Title: Selection of the Regularization Parameter in the Ambrosio-Tortorelli\n  Approximation of the Mumford-Shah Functional for Image Segmentation Abstract: The Ambrosio-Tortorelli functional is a phase-field approximation of the\nMumford-Shah functional that has been widely used for image segmentation. The\napproximation has the advantages of being easy to implement, maintaining the\nsegmentation ability, and $\\Gamma$-converging to the Mumford-Shah functional.\nHowever, it has been observed in actual computation that the segmentation\nability of the Ambrosio-Tortorelli functional varies significantly with\ndifferent values of the parameter and it even fails to $\\Gamma$-converge to the\noriginal functional for some cases. In this paper we present an asymptotic\nanalysis on the gradient flow equation of the Ambrosio-Tortorelli functional\nand show that the functional can have different segmentation behavior for small\nbut finite values of the regularization parameter and eventually loses its\nsegmentation ability as the parameter goes to zero when the input image is\ntreated as a continuous function. This is consistent with the existing\nobservation as well as the numerical examples presented in this work. A\nselection strategy for the regularization parameter and a scaling procedure for\nthe solution are devised based on the analysis. Numerical results show that\nthey lead to good segmentation of the Ambrosio-Tortorelli functional for real\nimages. \n\n"}
{"id": "1706.06781", "contents": "Title: A Hybrid High-Order method for Kirchhoff-Love plate bending problems Abstract: We present a novel Hybrid High-Order (HHO) discretization of fourth-order\nelliptic problems arising from the mechanical modeling of the bending behavior\nof Kirchhoff-Love plates, including the biharmonic equation as a particular\ncase. The proposed HHO method supports arbitrary approximation orders on\ngeneral polygonal meshes, and reproduces the key mechanical equilibrium\nrelations locally inside each element. When polynomials of degree $k \\ge 1$ are\nused as unknowns, we prove convergence in $h^{k+1}$ (with $h$ denoting, as\nusual, the meshsize) in an energy-like norm. A key ingredient in the proof are\nnovel approximation results for the energy projector on local polynomial\nspaces. Under biharmonic regularity assumptions, a sharp estimate in $h^{k+3}$\nis also derived for the $L^2$-norm of the error on the deflection. The\ntheoretical results are supported by numerical experiments, which additionally\nshow the robustness of the method with respect to the choice of the\nstabilization. \n\n"}
{"id": "1706.07965", "contents": "Title: A two-dimensional data-driven model for traffic flow on highways Abstract: Based on experimental traffic data obtained from German and US highways, we\npropose a novel two-dimensional first-order macroscopic traffic flow model. The\ngoal is to reproduce a detailed description of traffic dynamics for the real\nroad geometry. In our approach both the dynamic along the road and across the\nlanes is continuous. The closure relations, being necessary to complete the\nhydrodynamic equation, are obtained by regression on fundamental diagram data.\nComparison with prediction of one-dimensional models shows the improvement in\nperformance of the novel model. \n\n"}
{"id": "1706.08004", "contents": "Title: Methods of arbitrary optimal order with tetrahedral finite-element\n  meshes forming polyhedral approximations of curved domains Abstract: In recent papers the author introduced a simple alternative to isoparametric\nfinite elements of the n-simplex type, to enhance the accuracy of\napproximations of second-order boundary value problems with Dirichlet\nconditions, posed in smooth curved domains. This technique is based upon\ntrial-functions consisting of piecewise polynomials defined on straight-edged\ntriangular or tetrahedral meshes, interpolating the Dirichlet boundary\nconditions at points of the true boundary. In contrast the test-functions are\ndefined upon the standard degrees of freedom associated with the underlying\nmethod for polytopic domains. While method's mathematical analysis for both\nsecond- and fourth-order problems in two-dimensional domains was carried out in\narxiv NA-1701.00663 and in a submitted paper, this article is devoted to the\nstudy of the three-dimensional case, in which the method is nonconforming.\nWell-posedness, uniform stability and optimal a priori error estimates in the\nenergy norm are demonstrated for a tetrahedron-based Lagrange family of finite\nelements. Novel L2-error estimates for the class of problems considered in this\nwork are also proved. A series of numerical examples illustrates the potential\nof the new technique. In particular its better accuracy at equivalent cost as\ncompared to the isoparametric technique is highlighted. Moreover the great\ngenerality of the new approach is exemplified through a method with degrees of\nfreedom other than nodal values. \n\n"}
{"id": "1706.08621", "contents": "Title: Energy-Preserving and Passivity-Consistent Numerical Discretization of\n  Port-Hamiltonian Systems Abstract: In this paper we design discrete port-Hamiltonian systems systematically in\ntwo different ways, by applying discrete gradient methods and splitting methods\nrespectively. The discrete port-Hamiltonian systems we get satisfy a discrete\nnotion of passivity, which lets us, by choosing the input appropriately, make\nthem globally asymptotically stable with respect to an equilibrium point. We\ntest methods designed using the discrete gradient approach in numerical\nexperiments, and the results are encouraging when compared to relevant existing\nintegrators of identical order. \n\n"}
{"id": "1706.09252", "contents": "Title: On the stability of projection methods for the incompressible\n  Navier-Stokes equations based on high-order discontinuous Galerkin\n  discretizations Abstract: The present paper deals with the numerical solution of the incompressible\nNavier-Stokes equations using high-order discontinuous Galerkin (DG) methods\nfor discretization in space. For DG methods applied to the dual splitting\nprojection method, instabilities have recently been reported that occur for\ncoarse spatial resolutions and small time step sizes. By means of numerical\ninvestigation we give evidence that these instabilities are related to the\ndiscontinuous Galerkin formulation of the velocity divergence term and the\npressure gradient term that couple velocity and pressure. Integration by parts\nof these terms with a suitable definition of boundary conditions is required in\norder to obtain a stable and robust method. Since the intermediate velocity\nfield does not fulfill the boundary conditions prescribed for the velocity, a\nconsistent boundary condition is derived from the convective step of the dual\nsplitting scheme to ensure high-order accuracy with respect to the temporal\ndiscretization. This new formulation is stable in the limit of small time steps\nfor both equal-order and mixed-order polynomial approximations. Although the\ndual splitting scheme itself includes inf-sup stabilizing contributions, we\ndemonstrate that spurious pressure oscillations appear for equal-order\npolynomials and small time steps highlighting the necessity to consider inf-sup\nstability explicitly. \n\n"}
{"id": "1707.00261", "contents": "Title: Construction of Structured Incoherent Unit Norm Tight Frames Abstract: The exact recovery property of Basis pursuit (BP) and Orthogonal Matching\nPursuit (OMP) has a relation with the coherence of the underlying frame. A\nframe with low coherence provides better guarantees for exact recovery. In\nparticular, Incoherent Unit Norm Tight Frames (IUNTFs) play a significant role\nin sparse representations. IUNTFs with special structure, in particular those\ngiven by a union of several orthonormal bases, are known to satisfy better\ntheoretical guarantees for recovering sparse signals. In the present work, we\npropose to construct structured IUNTFs consisting of large number of\northonormal bases. For a given $r, k, m$ with $k$ being less than or equal to\nthe smallest prime power factor of $m$ and $r<k,$ we construct a CS matrix of\nsize $mk \\times (mk\\times m^{r})$ with coherence at most $\\frac{r}{k},$ which\nconsists of $m^{r}$ number of orthonormal bases and with density $\\frac{1}{m}$.\nWe also present numerical results of recovery performance of union of\northonormal bases as against their Gaussian counterparts. \n\n"}
{"id": "1707.00840", "contents": "Title: Optimal error estimates for Chebyshev approximations of functions with\n  limited regularity in fractional Sobolev-type spaces Abstract: In this paper, we introduce a new theoretical framework built upon fractional\nSobolev-type spaces involving Riemann-Liouville (RL) fractional\nintegrals/derivatives, which is naturally arisen from exact representations of\nChebyshev expansion coefficients, for optimal error estimates of Chebyshev\napproximations to functions with limited regularity. The essential pieces of\nthe puzzle for the error analysis include (i) fractional integration by parts\n(under the weakest possible conditions), and (ii) generalised Gegenbauer\nfunctions of fractional degree (GGF-Fs): a new family of special functions with\nnotable fractional calculus properties. Under this framework, we are able to\nestimate the optimal decay rate of Chebyshev expansion coefficients for a large\nclass of functions with interior and endpoint singularities, which are deemed\nsuboptimal or complicated to characterize in existing literature. We can then\nderive optimal error estimates for spectral expansions and the related\nChebyshev interpolation and quadrature measured in various norms, and also\nimprove the available results in usual Sobolev spaces of integer regularity\nexponentials in several senses. As a by-product, this study results in some\nanalytically perspicuous formulas particularly on GGF-Fs, which are potentially\nuseful in spectral algorithms. The idea and analysis techniques can be extended\nto general Jacobi spectral approximations. \n\n"}
{"id": "1707.01801", "contents": "Title: Metriplectic Integrators for the Landau Collision Operator Abstract: We present a novel framework for addressing the nonlinear Landau collision\nintegral in terms of finite element and other subspace projection methods. We\nemploy the underlying metriplectic structure of the Landau collision integral\nand, using a Galerkin discretization for the velocity space, we transform the\ninfinite-dimensional system into a finite-dimensional, time-continuous\nmetriplectic system. Temporal discretization is accomplished using the concept\nof discrete gradients. The conservation of energy, momentum, and particle\ndensities, as well as the production of entropy is demonstrated algebraically\nfor the fully discrete system. Due to the generality of our approach, the\nconservation properties and the monotonic behavior of entropy are guaranteed\nfor finite element discretizations in general, independently of the mesh\nconfiguration. \n\n"}
{"id": "1707.02343", "contents": "Title: Milstein-type Schemes of SDE Driven by L\\'evy Noise with Super-linear\n  Diffusion Coefficients Abstract: We present a Milstein-type scheme for stochastic differential equations\ndriven by L\\'evy noise with super-linear diffusion coefficients and establish\nits strong convergence. \n\n"}
{"id": "1707.03045", "contents": "Title: Low-rank updates of matrix functions Abstract: We consider the task of updating a matrix function $f(A)$ when the matrix\n$A\\in{\\mathbb C}^{n \\times n}$ is subject to a low-rank modification. In other\nwords, we aim at approximating $f(A+D)-f(A)$ for a matrix $D$ of rank $k \\ll\nn$. The approach proposed in this paper attains efficiency by projecting onto\ntensorized Krylov subspaces produced by matrix-vector multiplications with $A$\nand $A^*$. We prove the approximations obtained from $m$ steps of the proposed\nmethods are exact if $f$ is a polynomial of degree at most $m$ and use this as\na basis for proving a variety of convergence results, in particular for the\nmatrix exponential and for Markov functions. We illustrate the performance of\nour method by considering various examples from network analysis, where our\napproach can be used to cheaply update centrality and communicability measures. \n\n"}
{"id": "1707.03227", "contents": "Title: Variational Integrators for Ideal Magnetohydrodynamics Abstract: A variational integrator for ideal magnetohydrodynamics is derived by\napplying a discrete action principle to a formal Lagrangian. Discrete exterior\ncalculus is used for the discretisation of the field variables in order to\npreserve their geometrical character. The resulting numerical method is free of\nnumerical resistivity, thus the magnetic field line topology is preserved and\nunphysical reconnection is absent. In 2D numerical examples we find that\nimportant conservation laws like total energy, magnetic helicity and cross\nhelicity are satisfied within machine accuracy. \n\n"}
{"id": "1707.03340", "contents": "Title: Deep Learning for Real Time Crime Forecasting Abstract: Accurate real time crime prediction is a fundamental issue for public safety,\nbut remains a challenging problem for the scientific community. Crime\noccurrences depend on many complex factors. Compared to many predictable\nevents, crime is sparse. At different spatio-temporal scales, crime\ndistributions display dramatically different patterns. These distributions are\nof very low regularity in both space and time. In this work, we adapt the\nstate-of-the-art deep learning spatio-temporal predictor, ST-ResNet [Zhang et\nal, AAAI, 2017], to collectively predict crime distribution over the Los\nAngeles area. Our models are two staged. First, we preprocess the raw crime\ndata. This includes regularization in both space and time to enhance\npredictable signals. Second, we adapt hierarchical structures of residual\nconvolutional units to train multi-factor crime prediction models. Experiments\nover a half year period in Los Angeles reveal highly accurate predictive power\nof our models. \n\n"}
{"id": "1707.03407", "contents": "Title: Stable Unitary Integrators for the Numerical Implementation of\n  Continuous Unitary Transformations Abstract: The technique of continuous unitary transformations has recently been used to\nprovide physical insight into a diverse array of quantum mechanical systems.\nHowever, the question of how to best numerically implement the flow equations\nhas received little attention. The most immediately apparent approach, using\nstandard Runge-Kutta numerical integration algorithms, suffers from both severe\ninefficiency due to stiffness and the loss of unitarity. After reviewing the\nformalism of continuous unitary transformations and Wegner's original choice\nfor the infinitesimal generator of the flow, we present a number of approaches\nto resolving these issues including a choice of generator which induces what we\ncall the \"uniform tangent decay flow\" and three numerical integrators\nspecifically designed to perform continuous unitary transformations efficiently\nwhile preserving the unitarity of flow. We conclude by applying one of the flow\nalgorithms to a simple calculation that visually demonstrates the many-body\nlocalization transition. \n\n"}
{"id": "1707.04514", "contents": "Title: What makes nonholonomic integrators work? Abstract: A nonholonomic system is a mechanical system with velocity constraints not\noriginating from position constraints; rolling without slipping is the typical\nexample. A nonholonomic integrator is a numerical method specifically designed\nfor nonholonomic systems. It has been observed numerically that many\nnonholonomic integrators exhibit excellent long-time behaviour when applied to\nvarious test problems. The excellent performance is often attributed to some\nunderlying discrete version of the Lagrange--d'Alembert principle. Instead, in\nthis paper, we give evidence that reversibility is behind the observed\nbehaviour. Indeed, we show that many standard nonholonomic test problems have\nthe structure of being foliated over reversible integrable systems. As most\nnonholonomic integrators preserve the foliation and the reversible structure,\nnear conservation of the first integrals is a consequence of reversible KAM\ntheory. Therefore, to fully evaluate nonholonomic integrators one has to\nconsider also non-reversible nonholonomic systems. To this end we construct\nperturbed test problems that are integrable but no longer reversible (with\nrespect to the standard reversibility map). Applying various nonholonomic\nintegrators from the literature to these problems we observe that no method\nperforms well on all problems. This further indicates that reversibility is the\nmain mechanism behind near conservation of first integrals for nonholonomic\nintegrators. A list of relevant open problems is given. \n\n"}
{"id": "1707.04945", "contents": "Title: Stability of Overintegration Methods for Nodal Discontinuous Galerkin\n  Spectral Element Methods Abstract: We perform stability analyses for discontinuous Galerkin spectral element\napproximations of linear variable coefficient hyperbolic systems in three\ndimensional domains with curved elements. Although high order, the precision of\nthe quadratures used are typically too low with respect to polynomial order\nassociated with their arguments, which introduces aliasing errors that can\ndestabilize an approximation, especially when the solution is underresolved. We\nshow that using a larger number of points in the volume quadrature, often\ncalled \"overintegration\", can eliminate the aliasing term associated with the\nvolume, but introduces new aliasing errors at the surfaces that can destabilize\nthe solution. Increased quadrature precision on both the volume and surface\nterms, on the other hand, leads to a stable approximation. The results support\nthe findings of Mengaldo et al. [Dealiasing techniques for high-order spectral\nelement methods on regular and irregular grids. Journal of Computational\nPhysics, 299:56 -- 81, 2015] who found that fully consistent integration was\nmore robust for the solution of compressible flows than the volume only\nversion. \n\n"}
{"id": "1707.05828", "contents": "Title: A deep learning approach to diabetic blood glucose prediction Abstract: We consider the question of 30-minute prediction of blood glucose levels\nmeasured by continuous glucose monitoring devices, using clinical data. While\nmost studies of this nature deal with one patient at a time, we take a certain\npercentage of patients in the data set as training data, and test on the\nremainder of the patients; i.e., the machine need not re-calibrate on the new\npatients in the data set. We demonstrate how deep learning can outperform\nshallow networks in this example. One novelty is to demonstrate how a\nparsimonious deep representation can be constructed using domain knowledge. \n\n"}
{"id": "1707.06551", "contents": "Title: Boundary integral equation analysis for suspension of spheres in Stokes\n  flow Abstract: We show that the standard boundary integral operators, defined on the unit\nsphere, for the Stokes equations diagonalize on a specific set of vector\nspherical harmonics and provide formulas for their spectra. We also derive\nanalytical expressions for evaluating the operators away from the boundary.\nWhen two particle are located close to each other, we use a truncated series\nexpansion to compute the hydrodynamic interaction. On the other hand, we use\nthe standard spectrally accurate quadrature scheme to evaluate smooth integrals\non the far-field, and accelerate the resulting discrete sums using the fast\nmultipole method (FMM). We employ this discretization scheme to analyze several\nboundary integral formulations of interest including those arising in porous\nmedia flow, active matter and magneto-hydrodynamics of rigid particles. We\nprovide numerical results verifying the accuracy and scaling of their\nevaluation. \n\n"}
{"id": "1707.06908", "contents": "Title: Fully discrete finite element data assimilation method for the heat\n  equation Abstract: We consider a finite element discretization for the reconstruction of the\nfinal state of the heat equation, when the initial data is unknown, but\nadditional data is given in a sub domain in the space time. For the\ndiscretization in space we consider standard continuous affine finite element\napproximation, and the time derivative is discretized using a backward\ndifferentiation. We regularize the discrete system by adding a penalty of the\n$H^1$-semi-norm of the initial data, scaled with the mesh-parameter. The\nanalysis of the method uses techniques developed in E. Burman and L. Oksanen,\nData assimilation for the heat equation using stabilized finite element\nmethods, arXiv, 2016, combining discrete stability of the numerical method with\nsharp Carleman estimates for the physical problem, to derive optimal error\nestimates for the approximate solution. For the natural space time energy norm,\naway from $t=0$, the convergence is the same as for the classical problem with\nknown initial data, but contrary to the classical case, we do not obtain faster\nconvergence for the $L^2$-norm at the final time. \n\n"}
{"id": "1707.07799", "contents": "Title: Block Approximation of Tall Sparse Matrices and Block-Givens Rotations Abstract: Estimation of top singular values is one of the widely used techniques and\none of the intensively researched problems in Numerical Linear Algebra and Data\nScience. We consider here two general questions related to this problem:\n  How top singular values are affected by zeroing out a sparse rectangular\nblock of a matrix?\n  How much top singular values differ from top column norms of a tall sparse\nnon-negative matrix ? \n\n"}
{"id": "1707.08103", "contents": "Title: A Hybrid control approach to the route planning problem for sailing\n  boats Abstract: We present an optimal hybrid control approach to the problem of stochastic\nroute planning for sailing boats, especially in short course fleet races, in\nwhich minimum average time is an effective performance index. We show that the\nhybrid setting is a natural way of taking into account tacking/gybing maneuvers\nand other discrete control actions, and provide examples of increasing\ncomplexity to model the problem. Moreover, we carry out a numerical validation\nof the approach and show that results are in good agreement with theoretical\nand practical knowledge. \n\n"}
{"id": "1707.08345", "contents": "Title: Fully Finite Element Adaptive Algebraic Multigrid Method for Time-Space\n  Caputo-Riesz Fractional Diffusion Equations Abstract: The paper aims to establish a fully discrete finite element (FE) scheme and\nprovide cost-effective solutions for one-dimensional time-space Caputo-Riesz\nfractional diffusion equations on a bounded domain $\\Omega$. Firstly, we\nconstruct a fully discrete scheme of the linear FE method in both temporal and\nspatial directions, derive many characterizations on the coefficient matrix and\nnumerically verify that the fully FE approximation possesses the saturation\nerror order under $L^2(\\Omega)$ norm. Secondly, we theoretically prove the\nestimation $1+\\mathcal{O}(\\tau^\\alpha h^{-2\\beta})$ on the condition number of\nthe coefficient matrix, in which $\\tau$ and $h$ respectively denote time and\nspace step sizes. Finally, on the grounds of the estimation and fast Fourier\ntransform, we develop and analyze an adaptive algebraic multigrid (AMG) method\nwith low algorithmic complexity, reveal a reference formula to measure the\nstrength-of-connection tolerance which severely affect the robustness of AMG\nmethods in handling fractional diffusion equations, and illustrate the well\nrobustness and high efficiency of the proposed algorithm compared with the\nclassical AMG, conjugate gradient and Jacobi iterative methods. \n\n"}
{"id": "1707.09264", "contents": "Title: Projected Shadowing-based Data Assimilation Abstract: In this article we develop algorithms for data assimilation based upon a\ncomputational time dependent stable/unstable splitting. Our particular method\nis based upon shadowing refinement and synchronization techniques and is\nmotivated by work on Assimilation in the Unstable Subspace (AUS) and\nPseudo-orbit Data Assimilation (PDA). The algorithm utilizes time dependent\nprojections onto the non-stable subspace determined by employing computational\ntechniques for Lyapunov exponents/vectors. The method is extended to parameter\nestimation without changing the problem dynamics and we address techniques for\nadapting the method when (as is commonly the case) observations are not\navailable in the full model state space. We use a combination of analysis and\nnumerical experiments (with the Lorenz 63 and Lorenz 96 models) to illustrate\nthe efficacy of the techniques and show that the results compare favorably with\nother variational techniques. \n\n"}
{"id": "1707.09408", "contents": "Title: On the Relationship between the One-Corner Problem and the $M$-Corner\n  Problem for the Vortex Filament Equation Abstract: In this paper, we give evidence that the evolution of the Vortex Filament\nEquation for a regular $M$-corner polygon as initial datum can be explained at\ninfinitesimal times as the superposition of $M$ one-corner initial data.\nTherefore, and due to periodicity, the evolution at later times can be\nunderstood as the nonlinear interaction of infinitely many filaments, one for\neach corner. This interaction turns out to be some kind of nonlinear Talbot\neffect. We also give very strong numerical evidence of the transfer of energy\nand linear momentum for the $M$-corner case. \n\n"}
{"id": "1707.09713", "contents": "Title: Numerical analysis of shell-based geometric image inpainting algorithms\n  and their semi-implicit extension Abstract: In this paper we study a class of fast geometric image inpainting methods\nbased on the idea of filling the inpainting domain in successive shells from\nits boundary inwards. Image pixels are filled by assigning them a color equal\nto a weighted average of their already filled neighbors. However, there is\nflexibility in terms of the order in which pixels are filled, the weights used\nfor averaging, and the neighborhood that is averaged over. Varying these\ndegrees of freedom leads to different algorithms, and indeed the literature\ncontains several methods falling into this general class. All of them are very\nfast, but at the same time all of them leave undesirable artifacts such as\n\"kinking\" (bending) or blurring of extrapolated isophotes. Our objective in\nthis paper is to build a theoretical model, based on a continuum limit and a\nconnection to stopped random walks, in order to understand why these artifacts\noccur and what, if anything, can be done about them. At the same time, we\nconsider a semi-implicit extension in which pixels in a given shell are solved\nfor simultaneously by solving a linear system. We prove (within the continuum\nlimit) that this extension is able to completely eliminate kinking artifacts,\nwhich we also prove must always be present in the direct method. Although our\nanalysis makes the strong assumption of a square inpainting domain, it makes\nweak smoothness assumptions and is thus applicable to the low regularity\ninherent in images. \n\n"}
{"id": "1708.01148", "contents": "Title: Some practical versions of boundary variation diminishing (BVD)\n  algorithm Abstract: This short note presents some variant schemes of boundary variation\ndiminishing (BVD) algorithm in one dimension with the results of numerical\ntests for linear advection equation to facilitate practical use. In spite of\nbeing presented in 1D fashion, all the schemes are simple and easy to implement\nin multi-dimensions on structured and unstructured grids for nonlinear and\nsystem equations. \n\n"}
{"id": "1708.01722", "contents": "Title: Modified Truncated Randomized Singular Value Decomposition (MTRSVD)\n  Algorithms for Large Scale Discrete Ill-posed Problems with General-Form\n  Regularization Abstract: In this paper, we propose new randomization based algorithms for large scale\nlinear discrete ill-posed problems with general-form regularization: ${\\min}\n\\|Lx\\|$ subject to ${\\min} \\|Ax - b\\|$, where $L$ is a regularization matrix.\nOur algorithms are inspired by the modified truncated singular value\ndecomposition (MTSVD) method, which suits only for small to medium scale\nproblems, and randomized SVD (RSVD) algorithms that generate good low rank\napproximations to $A$. We use rank-$k$ truncated randomized SVD (TRSVD)\napproximations to $A$ by truncating the rank-$(k+q)$ RSVD approximations to\n$A$, where $q$ is an oversampling parameter. The resulting algorithms are\ncalled modified TRSVD (MTRSVD) methods. At every step, we use the LSQR\nalgorithm to solve the resulting inner least squares problem, which is proved\nto become better conditioned as $k$ increases so that LSQR converges faster. We\npresent sharp bounds for the approximation accuracy of the RSVDs and TRSVDs for\nseverely, moderately and mildly ill-posed problems, and substantially improve a\nknown basic bound for TRSVD approximations. We prove how to choose the stopping\ntolerance for LSQR in order to guarantee that the computed and exact best\nregularized solutions have the same accuracy. Numerical experiments illustrate\nthat the best regularized solutions by MTRSVD are as accurate as the ones by\nthe truncated generalized singular value decomposition (TGSVD) algorithm, and\nat least as accurate as those by some existing truncated randomized generalized\nsingular value decomposition (TRGSVD) algorithms. \n\n"}
{"id": "1708.02549", "contents": "Title: On the numerical Picard iterations method with collocations for the IVP Abstract: Some variants of the numerical Picard iterations method are presented to\nsolve an IVP for an ordinary differential system. The term numerical emphasizes\nthat a numerical solution is computed. The method consists in replacing the\nright hand side of the differential system by Lagrange interpolation\npolynomials followed by successive approximations. In the case when the number\nof interpolation point is fixed a convergence result is given. Finally some\nnumerical experiments are reported. \n\n"}
{"id": "1708.04740", "contents": "Title: Optimal Experimental Design for Constrained Inverse Problems Abstract: In this paper, we address the challenging problem of optimal experimental\ndesign (OED) of constrained inverse problems. We consider two OED formulations\nthat allow reducing the experimental costs by minimizing the number of\nmeasurements. The first formulation assumes a fine discretization of the design\nparameter space and uses sparsity promoting regularization to obtain an\nefficient design. The second formulation parameterizes the design and seeks\noptimal placement for these measurements by solving a small-dimensional\noptimization problem. We consider both problems in a Bayes risk as well as an\nempirical Bayes risk minimization framework. For the unconstrained inverse\nstate problem, we exploit the closed form solution for the inner problem to\nefficiently compute derivatives for the outer OED problem. The empirical\nformulation does not require an explicit solution of the inverse problem and\ntherefore allows to integrate constraints efficiently. A key contribution is an\nefficient optimization method for solving the resulting, typically\nhigh-dimensional, bilevel optimization problem using derivative-based methods.\nTo overcome the lack of non-differentiability in active set methods for\ninequality constraints problems, we use a relaxed interior point method. To\naddress the growing computational complexity of empirical Bayes OED, we\nparallelize the computation over the training models. Numerical examples and\nillustrations from tomographic reconstruction, for various data sets and under\ndifferent constraints, demonstrate the impact of constraints on the optimal\ndesign and highlight the importance of OED for constrained problems. \n\n"}
{"id": "1708.07830", "contents": "Title: Finite element approximation of steady flows of generalized Newtonian\n  fluids with concentration-dependent power-law index Abstract: We consider a system of nonlinear partial differential equations describing\nthe motion of an incompressible chemically reacting generalized Newtonian fluid\nin three space dimensions. The governing system consists of a steady\nconvection-diffusion equation for the concentration and a generalized steady\npower-law-type fluid flow model for the velocity and the pressure, where the\nviscosity depends on both the shear-rate and the concentration through a\nconcentration-dependent power-law index. The aim of the paper is to perform a\nmathematical analysis of a finite element approximation of this model. We\nformulate a regularization of the model by introducing an additional term in\nthe conservation-of-momentum equation and construct a finite element\napproximation of the regularized system. We show the convergence of the finite\nelement method to a weak solution of the regularized model and prove that weak\nsolutions of the regularized problem converge to a weak solution of the\noriginal problem. \n\n"}
{"id": "1708.08427", "contents": "Title: Hierarchical Orthogonal Matrix Generation and Matrix-Vector\n  Multiplications in Rigid Body Simulations Abstract: In this paper, we apply the hierarchical modeling technique and study some\nnumerical linear algebra problems arising from the Brownian dynamics\nsimulations of biomolecular systems where molecules are modeled as ensembles of\nrigid bodies. Given a rigid body $p$ consisting of $n$ beads, the $6 \\times 3n$\ntransformation matrix $Z$ that maps the force on each bead to $p$'s\ntranslational and rotational forces (a $6\\times 1$ vector), and $V$ the row\nspace of $Z$, we show how to explicitly construct the $(3n-6) \\times 3n$ matrix\n$\\tilde{Q}$ consisting of $(3n-6)$ orthonormal basis vectors of $V^{\\perp}$\n(orthogonal complement of $V$) using only $\\mathcal{O}(n \\log n)$ operations\nand storage. For applications where only the matrix-vector multiplications\n$\\tilde{Q}{\\bf v}$ and $\\tilde{Q}^T {\\bf v}$ are needed, we introduce\nasymptotically optimal $\\mathcal{O}(n)$ hierarchical algorithms without\nexplicitly forming $\\tilde{Q}$. Preliminary numerical results are presented to\ndemonstrate the performance and accuracy of the numerical algorithms. \n\n"}
{"id": "1708.08782", "contents": "Title: Comparisons of Some Iterative Algorithms for Biot Equations Abstract: In this paper, we aim at solving the Biot model under stabilized finite\nelement discretizations. To solve the resulting generalized saddle point linear\nsystems, some iterative methods are proposed and compared. In the first method,\nwe apply the GMRES algorithm as the outer iteration. In the second method, the\nUzawa method with variable relaxation parameters is employed as the outer\niteration method. In the third approach, Uzawa method is treated as a\nfixed-point iteration, the outer solver is the so-called Anderson acceleration.\nIn all these methods, the inner solvers are preconditioners for the generalized\nsaddle point problem. In the preconditioners, the Schur complement\napproximation is derived by using Fourier analysis approach. These\npreconditioners are implemented exactly or inexactly. Extensive experiments are\ngiven to justify the performance of the proposed preconditioners and to compare\nall the algorithms. \n\n"}
{"id": "1708.09446", "contents": "Title: An Equation-Free Approach for Second Order Multiscale Hyperbolic\n  Problems in Non-Divergence Form Abstract: The present study concerns the numerical homogenization of second order\nhyperbolic equations in non-divergence form, where the model problem includes a\nrapidly oscillating coefficient function. These small scales influence the\nlarge scale behavior, hence their effects should be accurately modelled in a\nnumerical simulation. A direct numerical simulation is prohibitively expensive\nsince a minimum of two points per wavelength are needed to resolve the small\nscales. A multiscale method, under the equation free methodology, is proposed\nto approximate the coarse scale behaviour of the exact solution at a cost\nindependent of the small scales in the problem. We prove convergence rates for\nthe upscaled quantities in one as well as in multi-dimensional periodic\nsettings. Moreover, numerical results in one and two dimensions are provided to\nsupport the theory. \n\n"}
{"id": "1708.09699", "contents": "Title: Inconsistency of uhyper and umat in Abaqus for compressible hyperelastic\n  materials Abstract: In this article, we revisited Ba\\v{z}ant's comments on the implementation of\nhyperelastic material models in commercial finite element software. We would\nlike to clarify that our assertions only apply if the material models are\nimplemented as hypoelastic, i.e. by incremental stress updates, in common\ninterfaces (including, in particular, umat in Abaqus). This assumption was not\nmade sufficiently clear in the article.\n  If, on the other hand, the stress calculations are implemented using the umat\ninterface with absolute (or \"total\") stress updates, as is also assumed in the\nuhyper interface, there is no difference in the internal processes or the\nresults between the umat and the uhyper implementation. This applies to highly\ncompressible formulations as well, where the Kirchhoff and Cauchy stress\ntensors are clearly distinguished. \n\n"}
{"id": "1709.00452", "contents": "Title: Additive average Schwarz with adaptive coarse spaces: scalable\n  algorithms for multiscale problems Abstract: We present an analysis of the additive average Schwarz preconditioner with\ntwo newly proposed adaptively enriched coarse spaces which was presented at the\n23rd International conference on domain decomposition methods in Korea, for\nsolving second order elliptic problems with highly varying and discontinuous\ncoefficients. It is shown that the condition number of the preconditioned\nsystem is bounded independently of the variations and the jumps in the\ncoefficient, and depends linearly on the mesh parameter ratio H/h, that is the\nratio between the subdomain size and the mesh size, thereby retaining the same\noptimality and scalablity of the original additive average Schwarz\npreconditioner. \n\n"}
{"id": "1709.00479", "contents": "Title: A Trace Finite Element Method for Vector-Laplacians on Surfaces Abstract: We consider a vector-Laplace problem posed on a 2D surface embedded in a 3D\ndomain, which results from the modeling of surface fluids based on exterior\nCartesian differential operators. The main topic of this paper is the\ndevelopment and analysis of a finite element method for the discretization of\nthis surface partial differential equation. We apply the trace finite element\ntechnique, in which finite element spaces on a background shape-regular\ntetrahedral mesh that is surface-independent are used for discretization. In\norder to satisfy the constraint that the solution vector field is tangential to\nthe surface we introduce a Lagrange multiplier. We show well-posedness of the\nresulting saddle point formulation. A discrete variant of this formulation is\nintroduced which contains suitable stabilization terms and is based on trace\nfinite element spaces. For this method we derive optimal discretization error\nbounds. Furthermore algebraic properties of the resulting discrete saddle point\nproblem are studied. In particular an optimal Schur complement preconditioner\nis proposed. Results of a numerical experiment are included. \n\n"}
{"id": "1709.00853", "contents": "Title: Positive definiteness and stability of parametric interval matrices Abstract: We investigate positive definiteness, Hurwitz stability and Schur stability\nof parametric interval matrices. We give a verifiable sufficient condition for\npositive definiteness of parametric interval matrices with non-linear\ndependencies. We also give several sufficient and necessary conditions for\nstability of symmetric parametric interval matrices with affine-linear\ndependencies. The presented results extend the results on positive definiteness\nand stability of interval matrices. In addition, we provide a formula for the\nradius of stability of symmetric parametric interval matrices. \n\n"}
{"id": "1709.02417", "contents": "Title: Assimilation of nearly turbulent Rayleigh-B\\'enard flow through\n  vorticity or local circulation measurements: a computational study Abstract: We introduce a continuous (downscaling) data assimilation algorithm for the\n2D B\\'enard convection problem using vorticity or local circulation\nmeasurements only. In this algorithm, a nudging term is added to the vorticity\nequation to constrain the model. Our numerical results indicate that the\napproximate solution of the algorithm is converging to the unknown reference\nsolution (vorticity and temperature) corresponding to the measurements of the\n2D B\\'enard convection problem when only spatial coarse-grain measurements of\nvorticity are assimilated. Moreover, this convergence is realized using data\nwhich is much more coarse than the resolution needed to satisfy rigorous\nanalytical estimates. \n\n"}
{"id": "1709.02803", "contents": "Title: Solving the incompressible surface Navier-Stokes equation by surface\n  finite elements Abstract: We consider a numerical approach for the incompressible surface Navier-Stokes\nequation on surfaces with arbitrary genus $g(\\mathcal{S})$. The approach is\nbased on a reformulation of the equation in Cartesian coordinates of the\nembedding $\\mathbb{R}^3$, penalization of the normal component, a Chorin\nprojection method and discretization in space by surface finite elements for\neach component. The approach thus requires only standard ingredients which most\nfinite element implementations can offer. We compare computational results with\ndiscrete exterior calculus (DEC) simulations on a torus and demonstrate the\ninterplay of the flow field with the topology by showing realizations of the\nPoincar\\'e-Hopf theorem on $n$-tori. \n\n"}
{"id": "1709.03013", "contents": "Title: Causal Set Generator and Action Computer Abstract: The causal set approach to quantum gravity has gained traction over the past\nthree decades, but numerical experiments involving causal sets have been\nlimited to relatively small scales. The software suite presented here provides\na new framework for the generation and study of causal sets. Its efficiency\nsurpasses previous implementations by several orders of magnitude. We highlight\nseveral important features of the code, including the compact data structures,\nthe $O(N^2)$ causal set generation process, and several implementations of the\n$O(N^3)$ algorithm to compute the Benincasa-Dowker action of compact regions of\nspacetime. We show that by tailoring the data structures and algorithms to take\nadvantage of low-level CPU and GPU architecture designs, we are able to\nincrease the efficiency and reduce the amount of required memory significantly.\nThe presented algorithms and their implementations rely on methods that use\nCUDA, OpenMP, x86 Assembly, SSE/AVX, Pthreads, and MPI. We also analyze the\nscaling of the algorithms' running times with respect to the problem size and\navailable resources, with suggestions on how to modify the code for future\nhardware architectures. \n\n"}
{"id": "1709.03321", "contents": "Title: Monte Carlo Methods for Uniform Approximation on Periodic Sobolev Spaces\n  with Mixed Smoothness Abstract: We consider the order of convergence for linear and nonlinear Monte Carlo\napproximation of compact embeddings from Sobolev spaces of dominating mixed\nsmoothness defined on the torus $\\mathbb{T}^d$ into the space\n$L_{\\infty}(\\mathbb{T}^d)$ via methods that use arbitrary linear information.\nThese cases are interesting because we can gain a speedup of up to $1/2$ in the\nmain rate compared to the worst case approximation. In doing so we determine\nthe rate for some cases that have been left open by Fang and Duan. \n\n"}
{"id": "1709.04072", "contents": "Title: A convergence framework for inexact nonconvex and nonsmooth algorithms\n  and its applications to several iterations Abstract: In this paper, we consider the convergence of an abstract inexact nonconvex\nand nonsmooth algorithm. We promise a pseudo sufficient descent condition and a\npseudo relative error condition, which are both related to an auxiliary\nsequence, for the algorithm; and a continuity condition is assumed to hold. In\nfact, a lot of classical inexact nonconvex and nonsmooth algorithms allow these\nthree conditions. Under a special kind of summable assumption on the auxiliary\nsequence, we prove the sequence generated by the general algorithm converges to\na critical point of the objective function if being assumed Kurdyka-\nLojasiewicz property. The core of the proofs lies in building a new Lyapunov\nfunction, whose successive difference provides a bound for the successive\ndifference of the points generated by the algorithm. And then, we apply our\nfindings to several classical nonconvex iterative algorithms and derive the\ncorresponding convergence results \n\n"}
{"id": "1709.05153", "contents": "Title: Operator Fitting for Parameter Estimation of Stochastic Differential\n  Equations Abstract: Estimation of parameters is a crucial part of model development. When models\nare deterministic, one can minimise the fitting error; for stochastic systems\none must be more careful. Broadly parameterisation methods for stochastic\ndynamical systems fit into maximum likelihood estimation- and method of\nmoment-inspired techniques. We propose a method where one matches a finite\ndimensional approximation of the Koopman operator with the implied Koopman\noperator as generated by an extended dynamic mode decomposition approximation.\nOne advantage of this approach is that the objective evaluation cost can be\nindependent the number of samples for some dynamical systems. We test our\napproach on two simple systems in the form of stochastic differential\nequations, compare to benchmark techniques, and consider limited\neigen-expansions of the operators being approximated. Other small variations on\nthe technique are also considered, and we discuss the advantages to our\nformulation. \n\n"}
{"id": "1709.05447", "contents": "Title: An efficient, partitioned ensemble algorithm for simulating ensembles of\n  evolutionary MHD flows at low magnetic Reynolds number Abstract: Studying the propagation of uncertainties in a nonlinear dynamical system\nusually involves generating a set of samples in the stochastic parameter space\nand then repeated simulations with different sampled parameters. The main\ndifficulty faced in the process is the excessive computational cost. In this\npaper, we present an efficient, partitioned ensemble algorithm to determine\nmultiple realizations of a reduced Magnetohydrodynamics (MHD) system, which\nmodels MHD flows at low magnetic Reynolds number. The algorithm decouples the\nfully coupled problem into two smaller sub-physics problems, which reduces the\nsize of the linear systems that to be solved and allows the use of optimized\ncodes for each sub-physics problem. Moreover, the resulting coefficient\nmatrices are the same for all realizations at each time step, which allows\nfaster computation of all realizations and significant savings in computational\ncost. We prove this algorithm is first order accurate and long time stable\nunder a time step condition. Numerical examples are provided to verify the\ntheoretical results and demonstrate the efficiency of the algorithm. \n\n"}
{"id": "1709.06004", "contents": "Title: Recent Advances of Isogeometric Analysis in Computational\n  Electromagnetics Abstract: In this communication the advantages and drawbacks of the isogeometric\nanalysis (IGA) are reviewed in the context of electromagnetic simulations. IGA\nextends the set of polynomial basis functions, commonly employed by the\nclassical Finite Element Method (FEM). While identical to FEM with\nN\\'ed\\'elec's basis functions in the lowest order case, it is based on B-spline\nand Non-Uniform Rational B-spline basis functions. The main benefit of this is\nthe exact representation of the geometry in the language of computer aided\ndesign (CAD) tools. This simplifies the meshing as the computational mesh is\nimplicitly created by the engineer using the CAD tool. The curl- and\ndiv-conforming spline function spaces are recapitulated and the available\nsoftware is discussed. Finally, several non-academic benchmark examples in two\nand three dimensions are shown which are used in optimization and uncertainty\nquantification workflows. \n\n"}
{"id": "1709.06424", "contents": "Title: Accelerated sampling by infinite swapping of path integral molecular\n  dynamics with surface hopping Abstract: To accelerate the thermal equilibrium sampling of multi-level quantum\nsystems, the infinite swapping limit of a recently proposed multi-level ring\npolymer representation is investigated. In the infinite swapping limit, the\nring polymer evolves according to an averaged Hamiltonian with respect to all\npossible surface index configurations of the ring polymer, thus connects the\nsurface hopping approach to the mean-field path integral molecular dynamics. A\nmultiscale integrator for the infinite swapping limit is also proposed to\nenable efficient sampling based on the limiting dynamics. Numerical results\ndemonstrate the huge improvement of sampling efficiency of the infinite\nswapping compared with the direct simulation of path integral molecular\ndynamics with surface hopping. \n\n"}
{"id": "1709.08625", "contents": "Title: HLIBCov: Parallel Hierarchical Matrix Approximation of Large Covariance\n  Matrices and Likelihoods with Applications in Parameter Identification Abstract: We provide more technical details about the HLIBCov package, which is using\nparallel hierarchical ($\\H$-) matrices to identify unknown parameters of the\ncovariance function (variance, smoothness, and covariance length). These\nparameters are estimated by maximizing the joint Gaussian log-likelihood\nfunction. The HLIBCov package approximates large dense inhomogeneous covariance\nmatrices with a log-linear computational cost and storage requirement. We\nexplain how to compute the Cholesky factorization, determinant, inverse and\nquadratic form in the H-matrix format. To demonstrate the numerical\nperformance, we identify three unknown parameters in an example with 2,000,000\nlocations on a PC-desktop. \n\n"}
{"id": "1709.09031", "contents": "Title: A note on preconditioning weighted linear least squares, with\n  consequences for weakly-constrained variational data assimilation Abstract: The effect of preconditioning linear weighted least-squares using an\napproximation of the model matrix is analyzed, showing the interplay of the\neigenstructures of both the model and weighting matrices. A small example is\ngiven illustrating the resulting potential inefficiency of such\npreconditioners. Consequences of these results in the context of the\nweakly-constrained 4D-Var data assimilation problem are finally discussed. \n\n"}
{"id": "1709.10337", "contents": "Title: An adaptive step size controller for iterative implicit methods Abstract: The automatic selection of an appropriate time step size has been considered\nextensively in the literature. However, most of the strategies developed\noperate under the assumption that the computational cost (per time step) is\nindependent of the step size. This assumption is reasonable for non-stiff\nordinary differential equations and for partial differential equations where\nthe linear systems of equations resulting from an implicit integrator are\nsolved by direct methods. It is, however, usually not satisfied if iterative\n(for example, Krylov) methods are used.\n  In this paper, we propose a step size selection strategy that adaptively\nreduces the computational cost (per unit time step) as the simulation\nprogresses, constraint by the tolerance specified. We show that the proposed\napproach yields significant improvements in performance for a range of problems\n(diffusion-advection equation, Burgers' equation with a reaction term, porous\nmedia equation, viscous Burgers' equation, Allen--Cahn equation, and the\ntwo-dimensional Brusselator system). While traditional step size controllers\nhave emphasized a smooth sequence of time step sizes, we emphasize the\nexploration of different step sizes which necessitates relatively rapid changes\nin the step size. \n\n"}
{"id": "1710.00798", "contents": "Title: Measure-Valued Variational Models with Applications to\n  Diffusion-Weighted Imaging Abstract: We develop a general mathematical framework for variational problems where\nthe unknown function assumes values in the space of probability measures on\nsome metric space. We study weak and strong topologies and define a total\nvariation seminorm for functions taking values in a Banach space. The seminorm\npenalizes jumps and is rotationally invariant under certain conditions. We\nprove existence of a minimizer for a class of variational problems based on\nthis formulation of total variation, and provide an example where uniqueness\nfails to hold. Employing the Kan\\-torovich-Rubinstein transport norm from the\ntheory of optimal transport, we propose a variational approach for the\nrestoration of orientation distribution function (ODF)-valued images, as\ncommonly used in Diffusion MRI. We demonstrate that the approach is numerically\nfeasible on several data sets. \n\n"}
{"id": "1710.02547", "contents": "Title: An isogeometric finite element formulation for phase transitions on\n  deforming surfaces Abstract: This paper presents a general theory and isogeometric finite element\nimplementation for studying mass conserving phase transitions on deforming\nsurfaces. The mathematical problem is governed by two coupled fourth-order\nnonlinear partial differential equations (PDEs) that live on an evolving\ntwo-dimensional manifold. For the phase transitions, the PDE is the\nCahn-Hilliard equation for curved surfaces, which can be derived from surface\nmass balance in the framework of irreversible thermodynamics. For the surface\ndeformation, the PDE is the (vector-valued) Kirchhoff-Love thin shell equation.\nBoth PDEs can be efficiently discretized using $C^1$-continuous interpolations\nwithout derivative degrees-of-freedom (dofs). Structured NURBS and unstructured\nspline spaces with pointwise $C^1$-continuity are utilized for these\ninterpolations. The resulting finite element formulation is discretized in time\nby the generalized-$\\alpha$ scheme with adaptive time-stepping, and it is fully\nlinearized within a monolithic Newton-Raphson approach. A curvilinear surface\nparameterization is used throughout the formulation to admit general surface\nshapes and deformations. The behavior of the coupled system is illustrated by\nseveral numerical examples exhibiting phase transitions on deforming spheres,\ntori and double-tori. \n\n"}
{"id": "1710.03604", "contents": "Title: Convergence Analysis of an Unconditionally Energy Stable Linear\n  Crank-Nicolson Scheme for the Cahn-Hilliard Equation Abstract: Efficient and unconditionally stable high order time marching schemes are\nvery important but not easy to construct for nonlinear phase dynamics. In this\npaper, we propose and analysis an efficient stabilized linear Crank-Nicolson\nscheme for the Cahn-Hilliard equation with provable unconditional stability. In\nthis scheme the nonlinear bulk force are treated explicitly with two\nsecond-order linear stabilization terms. The semi-discretized equation is a\nlinear elliptic system with constant coefficients, thus robust and efficient\nsolution procedures are guaranteed. Rigorous error analysis show that, when the\ntime step-size is small enough, the scheme is second order accurate in time\nwith aprefactor controlled by some lower degree polynomial of $1/\\varepsilon$.\nHere $\\varepsilon$ is the interface thickness parameter. Numerical results are\npresented to verify the accuracy and efficiency of the scheme. \n\n"}
{"id": "1710.06754", "contents": "Title: An upper bound on the minimal dispersion Abstract: For $\\varepsilon\\in(0,1/2)$ and a natural number $d\\ge 2$, let $N$ be a\nnatural number with \\[ N \\,\\ge\\, 2^9\\,\\log_2(d)\\,\n\\left(\\frac{\\log_2(1/\\varepsilon)}{\\varepsilon}\\right)^2. \\] We prove that\nthere is a set of $N$ points in the unit cube $[0,1]^d$, which intersects all\naxis-parallel boxes with volume $\\varepsilon$. That is, the dispersion of this\npoint set is bounded from above by $\\varepsilon$. \n\n"}
{"id": "1710.07428", "contents": "Title: Wavelet-based priors accelerate maximum-a-posteriori optimization in\n  Bayesian inverse problems Abstract: Wavelet (Besov) priors are a promising way of reconstructing indirectly\nmeasured fields in a regularized manner. We demonstrate how wavelets can be\nused as a localized basis for reconstructing permeability fields with sharp\ninterfaces from noisy pointwise pressure field measurements in the context of\nthe elliptic inverse problem. For this we derive the adjoint method of\nminimizing the Besov-norm-regularized misfit functional (this corresponds to\ndetermining the maximum a posteriori point in the Bayesian point of view) in\nthe Haar wavelet setting. As it turns out, choosing a wavelet--based prior\nallows for accelerated optimization compared to established\ntrigonometrically--based priors. \n\n"}
{"id": "1710.07678", "contents": "Title: $\\mathcal{P}_m$ Interior Penalty Nonconforming Finite Element Methods\n  for $2m$-th Order PDEs in $\\mathbb{R}^n$ Abstract: In general $n$-dimensional simplicial meshes, we propose a family of interior\npenalty nonconforming finite element methods for $2m$-th order partial\ndifferential equations, where $m \\geq 0$ and $n \\geq 1$. For this family of\nnonconforming finite elements, the shape function space consists of polynomials\nwith a degree not greater than $m$, making it minimal. This family of finite\nelement spaces exhibits natural inclusion properties, analogous to those in the\ncorresponding Sobolev spaces in the continuous case. By applying interior\npenalty to the bilinear form, we establish quasi-optimal error estimates in the\nenergy norm. Due to the weak continuity of the nonconforming finite element\nspaces, the interior penalty terms in the bilinear form take a simple form, and\nan interesting property is that the penalty parameter needs only to be a\npositive constant of $\\mathcal{O}(1)$. These theoretical results are further\nvalidated by numerical tests. \n\n"}
{"id": "1710.08082", "contents": "Title: A Conservative Flux Optimization Finite Element Method for\n  Convection-Diffusion Equations Abstract: This article presents a new finite element method for convection-diffusion\nequations by enhancing the continuous finite element space with a flux space\nfor flux approximations that preserve the important mass conservation locally\non each element. The numerical scheme is based on a constrained flux\noptimization approach where the constraint was given by local mass conservation\nequations and the flux error is minimized in a prescribed topology/metric. This\nnew scheme provides numerical approximations for both the primal and the flux\nvariables. It is shown that the numerical approximations for the primal and the\nflux variables are convergent with optimal order in some discrete Sobolev\nnorms. Numerical experiments are conducted to confirm the convergence theory.\nFurthermore, the new scheme was employed in the computational simulation of a\nsimplified two-phase flow problem in highly heterogeneous porous media. The\nnumerical results illustrate an excellent performance of the method in\nscientific computing. \n\n"}
{"id": "1710.08707", "contents": "Title: Lower Error Bounds for Strong Approximation of Scalar SDEs with\n  non-Lipschitzian Coefficients Abstract: We study pathwise approximation of scalar stochastic differential equations\nat a single time point or globally in time by means of methods that are based\non finitely many observations of the driving Brownian motion. We prove lower\nerror bounds in terms of the average number of evaluations of the driving\nBrownian motion that hold for every such method under rather mild assumptions\non the coefficients of the equation. The underlying simple idea of our analysis\nis as follows: the lower error bounds known for equations with coefficients\nthat have sufficient regularity globally in space should still apply in the\ncase of coefficients that have this regularity in space only locally, in a\nsmall neighborhood of the initial value. Our results apply to a huge variety of\nequations with coefficients that are not globally Lipschitz continuous in space\nincluding Cox-Ingersoll-Ross processes, equations with superlinearly growing\ncoefficients, and equations with discontinuous coefficients. In many of these\ncases the resulting lower error bounds even turn out to be sharp. \n\n"}
{"id": "1710.11259", "contents": "Title: Fast Poisson solvers for spectral methods Abstract: Poisson's equation is the canonical elliptic partial differential equation.\nWhile there exist fast Poisson solvers for finite difference and finite element\nmethods, fast Poisson solvers for spectral methods have remained elusive. Here,\nwe derive spectral methods for solving Poisson's equation on a square,\ncylinder, solid sphere, and cube that have an optimal complexity (up to\npolylogarithmic terms) in terms of the degrees of freedom required to represent\nthe solution. Whereas FFT-based fast Poisson solvers exploit structured\neigenvectors of finite difference matrices, our solver exploits a separated\nspectra property that holds for our spectral discretizations. Without\nparallelization, we can solve Poisson's equation on a square with 100 million\ndegrees of freedom in under two minutes on a standard laptop. \n\n"}
{"id": "1710.11284", "contents": "Title: Some regularity and convergence results for parabolic\n  Hamilton-Jacobi-Bellman equations in bounded domains Abstract: We study the approximation of parabolic Hamilton-Jacobi-Bellman (HJB)\nequations in bounded domains with strong Dirichlet boundary conditions. We work\nunder the assumption of the existence of a sufficiently regular barrier\nfunction for the problem to obtain well-posedness and regularity of a related\nswitching system and the convergence of its components to the HJB equation. In\nparticular, we show existence of a viscosity solution to the switching system\nby a novel construction of sub- and supersolutions and application of Perron's\nmethod. Error bounds for monotone schemes for the HJB equation are then derived\nfrom estimates near the boundary, where the standard regularisation procedure\nfor viscosity solutions is not applicable, and are found to be of the same\norder as known results for the whole space. We deduce error bounds for some\ncommon finite difference and truncated semi-Lagrangian schemes. \n\n"}
{"id": "1711.00260", "contents": "Title: The scaling and skewness of optimally transported meshes on the sphere Abstract: In the context of numerical solution of PDEs, dynamic mesh redistribution\nmethods (r-adaptive methods) are an important procedure for increasing the\nresolution in regions of interest, without modifying the connectivity of the\nmesh. Key to the success of these methods is that the mesh should be\nsufficiently refined (locally) and flexible in order to resolve evolving\nsolution features, but at the same time not introduce errors through skewness\nand lack of regularity. Some state-of-the-art methods are bottom-up in that\nthey attempt to prescribe both the local cell size and the alignment to\nfeatures of the solution. However, the resulting problem is overdetermined,\nnecessitating a compromise between these conflicting requirements. An\nalternative approach, described in this paper, is to prescribe only the local\ncell size and augment this an optimal transport condition to provide global\nregularity. This leads to a robust and flexible algorithm for generating meshes\nfitted to an evolving solution, with minimal need for tuning parameters. Of\nparticular interest for geophysical modelling are meshes constructed on the\nsurface of the sphere. The purpose of this paper is to demonstrate that meshes\ngenerated on the sphere using this optimal transport approach have good\na-priori regularity and that the meshes produced are naturally aligned to\nvarious simple features. It is further shown that the sphere's intrinsic\ncurvature leads to more regular meshes than the plane. In addition to these\ngeneral results, we provide a wide range of examples relevant to practical\napplications, to showcase the behaviour of optimally transported meshes on the\nsphere. These range from axisymmetric cases that can be solved analytically to\nmore general examples that are tackled numerically. Evaluation of the singular\nvalues and singular vectors of the mesh transformation provides a quantitative\nmeasure of the mesh aniso... \n\n"}
{"id": "1711.00707", "contents": "Title: Conversions between barycentric, RKFUN, and Newton representations of\n  rational interpolants Abstract: We derive explicit formulas for converting between rational interpolants in\nbarycentric, rational Krylov (RKFUN), and Newton form. We show applications of\nthese conversions when working with rational approximants produced by the AAA\nalgorithm [Y. Nakatsukasa, O. S\\`ete, L. N. Trefethen, arXiv preprint\n1612.00337, 2016] within the Rational Krylov Toolbox and for the solution of\nnonlinear eigenvalue problems. \n\n"}
{"id": "1711.01017", "contents": "Title: A Numerical Scheme for A Singular control problem:\n  Investment-Consumption Under Proportional Transaction Costs Abstract: This paper concerns the numerical solution of a fully nonlinear parabolic\ndouble obstacle problem arising from a finite portfolio selection with\nproportional transaction costs. We consider the optimal allocation of wealth\namong multiple stocks and a bank account in order to maximize the finite\nhorizon discounted utility of consumption. The problem is mainly governed by a\ntime-dependent Hamilton-Jacobi-Bellman equation with gradient constraints. We\npropose a numerical method which is composed of Monte Carlo simulation to take\nadvantage of the high-dimensional properties and finite difference method to\napproximate the gradients of the value function. Numerical results illustrate\nbehaviors of the optimal trading strategies and also satisfy all qualitative\nproperties proved in Dai et al. (2009) and Chen and Dai (2013). \n\n"}
{"id": "1711.01080", "contents": "Title: Multi-level Picard approximations of high-dimensional semilinear\n  parabolic differential equations with gradient-dependent nonlinearities Abstract: Parabolic partial differential equations (PDEs) and backward stochastic\ndifferential equations (BSDEs) have a wide range of applications. In\nparticular, high-dimensional PDEs with gradient-dependent nonlinearities appear\noften in the state-of-the-art pricing and hedging of financial derivatives. In\nthis article we prove that semilinear heat equations with gradient-dependent\nnonlinearities can be approximated under suitable assumptions with\ncomputational complexity that grows polynomially both in the dimension and the\nreciprocal of the accuracy. \n\n"}
{"id": "1711.02054", "contents": "Title: On the error control at numerical solution of reaction-difusion\n  equations Abstract: We suggest guaranteed, robust a posteriori error bounds for approximate\nsolutions of the reaction-diffusion equations, modeled by the equation $-\\Delta\nu+\\sigma u= f$ in $\\Omega$ with any $\\sigma={\\mathrm{const}}\\ge 0$. We also\nterm our bounds consistent due to one specific property. It assumes that their\norders of accuracy in respect to mesh size $h$ are the same with the respective\nnot improvable in the order a priori bounds. Additionally, it assumes that the\npointed out equality of the orders is provided by the testing flaxes not\nsubjected to equilibration. For any $\\sigma\\in [0,\\sigma_*]$, the rirght part\nof the new general bound of the paper contains, besides the usual diffusion\nterm, the $L_2$ norm of the residual with the factor $1/\\sqrt{\\sigma_*}$, where\n$\\sigma_*$ is some critical value. For solutions by the finite element method,\nit is estimated as $\\sigma_*\\ge ch^{-2},\\,\\,c={\\mathrm{const}}$, if $\\partial\n\\Omega$ is sufficiently smooth and the finite element space is of the\n1$^{\\mathrm{st}}$ order of accuracy at least. In general, at the derivation of\na posteriori bounds, consistency is achieved by taking adequately into account\nthe difference of the orders of the $L_2$ and $H^1$ error norms, that can be\ndone in various ways with accordingly introduced $\\sigma_*$. Two advantages of\nthe obtained consistent a posteriori error bounds deserve attention. They are\nbetter accuracy and the possibility to avoid the use of the equilibration in\nthe flax recovery procedures, that may greatly simplify these procedures and\nmake them much more universal. The technique of obtaining the consistent a\nposteriori bounds was briefly exposed by the author in [arXiv:1702.00433v1\n[math.NA], 1 Feb 2017] and [$Doklady Mathematics$, ${\\mathbf{96}}$ (1), 2017,\n380-383]. \n\n"}
{"id": "1711.02193", "contents": "Title: Efficient boundary corrected Strang splitting Abstract: Strang splitting is a well established tool for the numerical integration of\nevolution equations. It allows the application of tailored integrators for\ndifferent parts of the vector field. However, it is also prone to order\nreduction in the case of non-trivial boundary conditions. This order reduction\ncan be remedied by correcting the boundary values of the intermediate splitting\nstep. In this paper, three different approaches for constructing such a\ncorrection in the case of inhomogeneous Dirichlet, Neumann, and mixed boundary\nconditions are presented. Numerical examples that illustrate the effectivity\nand benefits of these corrections are included. \n\n"}
{"id": "1711.02424", "contents": "Title: Hybrid stochastic kinetic description of two-dimensional traffic\n  dynamics Abstract: In this work we present a two-dimensional kinetic traffic model which takes\ninto account speed changes both when vehicles interact along the road lanes and\nwhen they change lane. Assuming that lane changes are less frequent than\ninteractions along the same lane and considering that their mathematical\ndescription can be done up to some uncertainty in the model parameters, we\nderive a hybrid stochastic Fokker-Planck-Boltzmann equation in the\nquasi-invariant interaction limit. By means of suitable numerical methods,\nprecisely structure preserving and direct Monte Carlo schemes, we use this\nequation to compute theoretical speed-density diagrams of traffic both along\nand across the lanes, including estimates of the data dispersion, and validate\nthem against real data. \n\n"}
{"id": "1711.02907", "contents": "Title: Strong convergence rate of Runge--Kutta methods and simplified step-$N$\n  Euler schemes for SDEs driven by fractional Brownian motions Abstract: This paper focuses on the strong convergence rate of both Runge--Kutta\nmethods and simplified step-$N$ Euler schemes for stochastic differential\nequations driven by multi-dimensional fractional Brownian motions with\n$H\\in(\\frac12,1)$. Based on the continuous dependence of both stage values and\nnumerical schemes on driving noises, order conditions of Runge--Kutta methods\nare proposed for the optimal strong convergence rate $2H-\\frac12$. This\nprovides an alternative way to analyze the convergence rate of explicit schemes\nby adding `stage values' such that the schemes are comparable with Runge--Kutta\nmethods. Taking advantage of this technique, the optimal strong convergence\nrate of simplified step-N Euler scheme is obtained, which gives an answer to a\nconjecture in $[3]$ when $H\\in(\\frac12,1)$. Numerical experiments verify the\ntheoretial convergence rate. \n\n"}
{"id": "1711.03023", "contents": "Title: The Calibration of Stochastic-Local Volatility Models - An Inverse\n  Problem Perspective Abstract: We tackle the calibration of the so-called Stochastic-Local Volatility (SLV)\nmodel. This is the class of financial models that combines the local and\nstochastic volatility features and has been subject of the attention by many\nresearchers recently. More precisely, given a local volatility surface and a\nchoice of stochastic volatility parameters, we calibrate the corresponding\nleverage function. Our approach makes use of regularization techniques from the\ninverse-problem theory, respecting the integrity of the data and thus avoiding\ndata interpolation. The result is a stable and robust algorithm which is\nresilient to instabilities in the regions of low probability density of the\nspot price and of the instantaneous variance. We substantiate our claims with\nnumerical experiments using simulated as well as real data. \n\n"}
{"id": "1711.03590", "contents": "Title: Fast matrix-free evaluation of discontinuous Galerkin finite element\n  operators Abstract: We present an algorithmic framework for matrix-free evaluation of\ndiscontinuous Galerkin finite element operators based on sum factorization on\nquadrilateral and hexahedral meshes. We identify a set of kernels for fast\nquadrature on cells and faces targeting a wide class of weak forms originating\nfrom linear and nonlinear partial differential equations. Different algorithms\nand data structures for the implementation of operator evaluation are compared\nin an in-depth performance analysis. The sum factorization kernels are\noptimized by vectorization over several cells and faces and an even-odd\ndecomposition of the one-dimensional compute kernels. In isolation our\nimplementation then reaches up to 60\\% of arithmetic peak on Intel Haswell and\nBroadwell processors and up to 50\\% of arithmetic peak on Intel Knights\nLanding. The full operator evaluation reaches only about half that throughput\ndue to memory bandwidth limitations from loading the input and output vectors,\nMPI ghost exchange, as well as handling variable coefficients and the geometry.\nOur performance analysis shows that the results are often within 10\\% of the\navailable memory bandwidth for the proposed implementation, with the exception\nof the Cartesian mesh case where the cost of gather operations and MPI\ncommunication are more substantial. \n\n"}
{"id": "1711.04236", "contents": "Title: Harmonic density interpolation methods for high-order evaluation of\n  Laplace layer potentials in 2D and 3D Abstract: We present an effective harmonic density interpolation method for the\nnumerical evaluation of singular and nearly singular Laplace boundary integral\noperators and layer potentials in two and three spatial dimensions. The method\nrelies on the use of Green's third identity and local Taylor-like\ninterpolations of density functions in terms of harmonic polynomials. The\nproposed technique effectively regularizes the singularities present in\nboundary integral operators and layer potentials, and recasts the latter in\nterms of integrands that are bounded or even more regular, depending on the\norder of the density interpolation. The resulting boundary integrals can then\nbe easily, accurately, and inexpensively evaluated by means of standard\nquadrature rules. A variety of numerical examples demonstrate the effectiveness\nof the technique when used in conjunction with the classical trapezoidal rule\n(to integrate over smooth curves) in two-dimensions, and with a Chebyshev-type\nquadrature rule (to integrate over surfaces given as unions of non-overlapping\nquadrilateral patches) in three-dimensions. \n\n"}
{"id": "1711.05786", "contents": "Title: A Parameter Estimation Method Using Linear Response Statistics:\n  Numerical Scheme Abstract: This paper presents a numerical method to implement the parameter estimation\nmethod using response statistics that was recently formulated by the authors.\nThe proposed approach formulates the parameter estimation problem of It\\^o\ndrift diffusions as a nonlinear least-squares problem. To avoid solving the\nmodel repeatedly when using an iterative scheme in solving the resulting\nleast-squares problems, a polynomial surrogate model is employed on appropriate\nresponse statistics with smooth dependence on the parameters. The existence of\nminimizers of the approximate polynomial least-squares problems that converge\nto the solution of the true least square problem is established under\nappropriate regularity assumption of the essential statistics as functions of\nparameters. Numerical implementation of the proposed method is conducted on two\nprototypical examples that belong to classes of models with wide range of\napplications, including the Langevin dynamics and the stochastically forced\ngradient flows. Several important practical issues, such as the selection of\nthe appropriate response operator to ensure the identifiability of the\nparameters and the reduction of the parameter space, are discussed. From the\nnumerical experiments, it is found that the proposed approach is superior\ncompared to the conventional approach that uses equilibrium statistics to\ndetermine the parameters. \n\n"}
{"id": "1711.07090", "contents": "Title: Eigenvector continuation with subspace learning Abstract: A common challenge faced in quantum physics is finding the extremal\neigenvalues and eigenvectors of a Hamiltonian matrix in a vector space so large\nthat linear algebra operations on general vectors are not possible. There are\nnumerous efficient methods developed for this task, but they generally fail\nwhen some control parameter in the Hamiltonian matrix exceeds some threshold\nvalue. In this work we present a new technique called eigenvector continuation\nthat can extend the reach of these methods. The key insight is that while an\neigenvector resides in a linear space with enormous dimensions, the eigenvector\ntrajectory generated by smooth changes of the Hamiltonian matrix is well\napproximated by a very low-dimensional manifold. We prove this statement using\nanalytic function theory and propose an algorithm to solve for the extremal\neigenvectors. We benchmark the method using several examples from quantum\nmany-body theory. \n\n"}
{"id": "1711.07415", "contents": "Title: A high-order finite difference WENO scheme for ideal\n  magnetohydrodynamics on curvilinear meshes Abstract: A high-order finite difference numerical scheme is developed for the ideal\nmagnetohydrodynamic equations based on an alternative flux formulation of the\nweighted essentially non-oscillatory (WENO) scheme. It computes a high-order\nnumerical flux by a Taylor expansion in space, with the lowest-order term\nsolved from a Riemann solver and the higher-order terms constructed from\nphysical fluxes by limited central differences. The scheme coupled with several\nRiemann solvers, including a Lax-Friedrichs solver and HLL-type solvers, is\ndeveloped on general curvilinear meshes in two dimensions and verified on a\nnumber of benchmark problems. In particular, a HLLD solver on Cartesian meshes\nis extended to curvilinear meshes with proper modifications. A numerical\nboundary condition for the perfect electrical conductor (PEC) boundary is\nderived for general geometry and verified through a bow shock flow. Numerical\nresults also confirm the advantages of using low dissipative Riemann solvers in\nthe current framework. \n\n"}
{"id": "1711.07417", "contents": "Title: An Anisotropic Interaction Model for Simulating Fingerprints Abstract: Evidence suggests that both the interaction of so-called Merkel cells and the\nepidermal stress distribution play an important role in the formation of\nfingerprint patterns during pregnancy. To model the formation of fingerprint\npatterns in a biologically meaningful way these patterns have to become\nstationary. For the creation of synthetic fingerprints it is also very\ndesirable that rescaling the model parameters leads to rescaled distances\nbetween the stationary fingerprint ridges. Based on these observations, as well\nas the model introduced by K\\\"ucken and Champod we propose a new model for the\nformation of fingerprint patterns during pregnancy. In this anisotropic\ninteraction model the interaction forces not only depend on the distance vector\nbetween the cells and the model parameters, but additionally on an underlying\ntensor field, representing a stress field. This dependence on the tensor field\nleads to complex, anisotropic patterns. We study the resulting stationary\npatterns both analytically and numerically. In particular, we show that\nfingerprint patterns can be modeled as stationary solutions by choosing the\nunderlying tensor field appropriately. \n\n"}
{"id": "1711.08751", "contents": "Title: On the Ideal Interpolation Operator in Algebraic Multigrid Methods Abstract: Various algebraic multigrid algorithms have been developed for solving\nproblems in scientific and engineering computation over the past decades. They\nhave been shown to be well-suited for solving discretized partial differential\nequations on unstructured girds in practice. One key ingredient of algebraic\nmultigrid algorithms is a strategy for constructing an effective prolongation\noperator. Among many questions on constructing a prolongation, an important\nquestion is how to evaluate its quality. In this paper, we establish new\ncharacterizations (including sufficient condition, necessary condition, and\nequivalent condition) of the so-called ideal interpolation operator. Our result\nsuggests that, compared with common wisdom, one has more room to construct an\nideal interpolation, which can provide new insights for designing algebraic\nmultigrid algorithms. Moreover, we derive a new expression for a class of ideal\ninterpolation operators. \n\n"}
{"id": "1711.10144", "contents": "Title: The game theoretic p-Laplacian and semi-supervised learning with few\n  labels Abstract: We study the game theoretic p-Laplacian for semi-supervised learning on\ngraphs, and show that it is well-posed in the limit of finite labeled data and\ninfinite unlabeled data. In particular, we show that the continuum limit of\ngraph-based semi-supervised learning with the game theoretic p-Laplacian is a\nweighted version of the continuous p-Laplace equation. We also prove that\nsolutions to the graph p-Laplace equation are approximately Holder continuous\nwith high probability. Our proof uses the viscosity solution machinery and the\nmaximum principle on a graph. \n\n"}
{"id": "1711.10617", "contents": "Title: Towards a geometric variational discretization of compressible fluids:\n  the rotating shallow water equations Abstract: This paper presents a geometric variational discretization of compressible\nfluid dynamics. The numerical scheme is obtained by discretizing, in a\nstructure preserving way, the Lie group formulation of fluid dynamics on\ndiffeomorphism groups and the associated variational principles. Our framework\napplies to irregular mesh discretizations in 2D and 3D. It systematically\nextends work previously made for incompressible fluids to the compressible\ncase. We consider in detail the numerical scheme on 2D irregular simplicial\nmeshes and evaluate the scheme numerically for the rotating shallow water\nequations. In particular, we investigate whether the scheme conserves\nstationary solutions, represents well the nonlinear dynamics, and approximates\nwell the frequency relations of the continuous equations, while preserving\nconservation laws such as mass and total energy. \n\n"}
{"id": "1711.10715", "contents": "Title: Linear second-order IMEX-type integrator for the (eddy current)\n  Landau-Lifshitz-Gilbert equation Abstract: Combining ideas from [Alouges et al. (Numer. Math., 128, 2014)] and\n[Praetorius et al. (Comput. Math. Appl., 2017)], we propose a numerical\nalgorithm for the integration of the nonlinear and time-dependent\nLandau-Lifshitz-Gilbert (LLG) equation which is unconditionally convergent,\nformally (almost) second-order in time, and requires only the solution of one\nlinear system per time-step. Only the exchange contribution is integrated\nimplicitly in time, while the lower-order contributions like the\ncomputationally expensive stray field are treated explicitly in time. Then, we\nextend the scheme to the coupled system of the Landau-Lifshitz-Gilbert equation\nwith the eddy current approximation of Maxwell equations (ELLG). Unlike\nexisting schemes for this system, the new integrator is unconditionally\nconvergent, (almost) second-order in time, and requires only the solution of\ntwo linear systems per time-step. \n\n"}
{"id": "1711.11269", "contents": "Title: Complex best $r$-term approximations almost always exist in finite\n  dimensions Abstract: We show that in finite-dimensional nonlinear approximations, the best\n$r$-term approximant of a function $f$ almost always exists over $\\mathbb{C}$\nbut that the same is not true over $\\mathbb{R}$, i.e., the infimum\n$\\inf_{f_1,\\dots,f_r \\in Y} \\lVert f - f_1 - \\dots - f_r \\rVert$ is almost\nalways attainable by complex-valued functions $f_1,\\dots, f_r$ in $Y$, a set of\nfunctions that have some desired structures. Our result extends to functions\nthat possess special properties like symmetry or skew-symmetry under\npermutations of arguments. For the case where $Y$ is the set of separable\nfunctions, the problem becomes that of best rank-$r$ tensor approximations. We\nshow that over $\\mathbb{C}$, any tensor almost always has a unique best\nrank-$r$ approximation. This extends to other notions of tensor ranks such as\nsymmetric rank and alternating rank, to best $r$-block-terms approximations,\nand to best approximations by tensor networks. When applied to\nsparse-plus-low-rank approximations, we obtain that for any given $r$ and $k$,\na general tensor has a unique best approximation by a sum of a rank-$r$ tensor\nand a $k$-sparse tensor with a fixed sparsity pattern; this arises in, for\nexample, estimation of covariance matrices of a Gaussian hidden variable model\nwith $k$ observed variables conditionally independent given $r$ hidden\nvariables. The existential (but not the uniqueness) part of our result also\napplies to best approximations by a sum of a rank-$r$ tensor and a $k$-sparse\ntensor with no fixed sparsity pattern, as well as to tensor completion\nproblems. \n\n"}
{"id": "1712.01338", "contents": "Title: Error analysis of a fully discrete Morley finite element approximation\n  for the Cahn-Hilliard equation Abstract: This paper proposes and analyzes the Morley element method for the\nCahn-Hilliard equation. It is a fourth order nonlinear singular perturbation\nequation arises from the binary alloy problem in materials science, and its\nlimit is proved to approach the Hele-Shaw flow. If the $L^2(\\Omega)$ error\nestimate is considered directly as in paper \\cite{elliott1989nonconforming}, we\ncan only prove that the error bound depends on the exponential function of\n$\\frac{1}{\\epsilon}$. Instead, this paper derives the error bound which depends\non the polynomial function of $\\frac{1}{\\epsilon}$ by considering the discrete\n$H^{-1}$ error estimate first. There are two main difficulties in proving this\npolynomial dependence of the discrete $H^{-1}$ error estimate. Firstly, it is\ndifficult to prove discrete energy law and discrete stability results due to\nthe complex structure of the bilinear form of the Morley element\ndiscretization. This paper overcomes this difficulty by defining four types of\ndiscrete inverse Laplace operators and exploring the relations between these\ndiscrete inverse Laplace operators and continuous inverse Laplace operator.\nEach of these operators plays important roles, and their relations are crucial\nin proving the discrete energy law, discrete stability results and error\nestimates. Secondly, it is difficult to prove the discrete spectrum estimate in\nthe Morley element space because the Morley element space intersects with the\n$C^1$ conforming finite element space but they are not contained in each other.\nInstead of proving this discrete spectrum estimate in the Morley element space,\nthis paper proves a generalized coercivity result by exploring properties of\nthe enriching operators and using the discrete spectrum estimate in its $C^1$\nconforming relative finite element space, which can be obtained by using the\nspectrum estimate of the Cahn-Hilliard operator. \n\n"}
{"id": "1712.01647", "contents": "Title: Impulse Control in Finance: Numerical Methods and Viscosity Solutions Abstract: The goal of this thesis is to provide efficient and provably convergent\nnumerical methods for solving partial differential equations (PDEs) coming from\nimpulse control problems motivated by finance. Impulses, which are controlled\njumps in a stochastic process, are used to model realistic features in\nfinancial problems which cannot be captured by ordinary stochastic controls.\n  The dynamic programming equations associated with impulse control problems\nare Hamilton-Jacobi-Bellman quasi-variational inequalities (HJBQVIs) Other than\nin certain special cases, the numerical schemes that come from the\ndiscretization of HJBQVIs take the form of complicated nonlinear matrix\nequations also known as Bellman problems. We prove that a policy iteration\nalgorithm can be used to compute their solutions. In order to do so, we employ\nthe theory of weakly chained diagonally dominant (w.c.d.d.) matrices. As a\nbyproduct of our analysis, we obtain some new results regarding a particular\nfamily of Markov decision processes which can be thought of as impulse control\nproblems on a discrete state space and the relationship between w.c.d.d.\nmatrices and M-matrices. Since HJBQVIs are nonlocal PDEs, we are unable to\ndirectly use the seminal result of Barles and Souganidis (concerning the\nconvergence of monotone, stable, and consistent numerical schemes to the\nviscosity solution) to prove the convergence of our schemes. We address this\nissue by extending the work of Barles and Souganidis to nonlocal PDEs in a\nmanner general enough to apply to HJBQVIs. We apply our schemes to compute the\nsolutions of various classical problems from finance concerning optimal control\nof the exchange rate, optimal consumption with fixed and proportional\ntransaction costs, and guaranteed minimum withdrawal benefits in variable\nannuities. \n\n"}
{"id": "1712.02083", "contents": "Title: A Local Analysis of Block Coordinate Descent for Gaussian Phase\n  Retrieval Abstract: While convergence of the Alternating Direction Method of Multipliers (ADMM)\non convex problems is well studied, convergence on nonconvex problems is only\npartially understood. In this paper, we consider the Gaussian phase retrieval\nproblem, formulated as a linear constrained optimization problem with a\nbiconvex objective. The particular structure allows for a novel application of\nthe ADMM. It can be shown that the dual variable is zero at the global\nminimizer. This motivates the analysis of a block coordinate descent algorithm,\nwhich is equivalent to the ADMM with the dual variable fixed to be zero. We\nshow that the block coordinate descent algorithm converges to the global\nminimizer at a linear rate, when starting from a deterministically achievable\ninitialization point. \n\n"}
{"id": "1712.03098", "contents": "Title: Analysis of a second order discontinuous Galerkin finite element method\n  for the Allen-Cahn equation and the curvature-driven geometric flow Abstract: The paper proposes and analyzes an efficient second-order in time numerical\napproximation for the Allen-Cahn equation, which is a second order nonlinear\nequation arising from the phase separation model. We firstly present a fully\ndiscrete interior penalty discontinuous Galerkin (IPDG) finite element method,\nwhich is based on the modified Crank-Nicolson scheme and a mid-point\napproximation of the nonliner term $f(u)$. We then derive the stability\nanalysis and error estimates for the proposed IPDG method under some regularity\nassumptions on the initial function $u_0$. There are two key works in our\nanalysis, one is to establish unconditionally energy-stable scheme for the\ndiscrete solutions. The other is to use a discrete spectrum estimate to handle\nthe midpoint of the discrete solutions $u^m$ and $u^{m+1}$ in the nonlinear\nterm, instead of using the standard Gronwall inequality technique. This\ndiscrete spectrum estimate is not trivial to obtain since the IPDG space and\nthe conforming $H^1$ space are not contained in each other. We obtain that all\nour error bounds depend on reciprocal of the perturbation parameter $\\epsilon$\nonly in some lower polynomial order, instead of exponential order. These\nsharper error bounds are the key elements in proving the convergence of our\nnumerical solution to the mean curvature flow. Finally, numerical experiments\nare also provided to show the performance of the presented approach and method. \n\n"}
{"id": "1712.03795", "contents": "Title: Convergent tangent plane integrators for the simulation of chiral\n  magnetic skyrmion dynamics Abstract: We consider the numerical approximation of the Landau-Lifshitz-Gilbert\nequation, which describes the dynamics of the magnetization in ferromagnetic\nmaterials. In addition to the classical micromagnetic contributions, the energy\ncomprises the Dzyaloshinskii-Moriya interaction, which is the most important\ningredient for the enucleation and the stabilization of chiral magnetic\nskyrmions. We propose and analyze three tangent plane integrators, for which we\nprove (unconditional) convergence of the finite element solutions towards a\nweak solution of the problem. The analysis is constructive and also establishes\nexistence of weak solutions. Numerical experiments demonstrate the\napplicability of the methods for the simulation of practically relevant problem\nsizes. \n\n"}
{"id": "1712.03888", "contents": "Title: A semi-implicit scheme based on Arrow-Hurwicz method for saddle point\n  problems Abstract: We search saddle points for a large class of convex-concave Lagrangian. A\ngeneralized explicit iterative scheme based on Arrow-Hurwicz method converges\nto a saddle point of the problem. We also propose in this work, a convergent\nsemi-implicit scheme in order to accelerate the convergence of the iterative\nprocess. Numerical experiments are provided for a nontrivial numerical problem\nmodeling an optimal shape problem of thin torsion rods. This semi-implicit\nscheme is figured out in practice robustly efficient in comparison with the\nexplicit one. \n\n"}
{"id": "1712.05864", "contents": "Title: On the singular values of matrices with high displacement rank Abstract: We introduce a new ADI-based low rank solver for $AX-XB=F$, where $F$ has\nrapidly decaying singular values. Our approach results in both theoretical and\npractical gains, including (1) the derivation of new bounds on singular values\nfor classes of matrices with high displacement rank, (2) a practical algorithm\nfor solving certain Lyapunov and Sylvester matrix equations with high rank\nright-hand sides, and (3) a collection of low rank Poisson solvers that achieve\nspectral accuracy and optimal computational complexity. \n\n"}
{"id": "1712.06373", "contents": "Title: A characterization of the Non-Degenerate Source Condition in\n  Super-Resolution Abstract: In a recent article, Schiebinger et al. provided sufficient conditions for\nthe noiseless recovery of a signal made of M Dirac masses given 2M + 1\nobservations of, e.g. , its convolution with a Gaussian filter, using the Basis\nPursuit for measures. In the present work, we show that a variant of their\ncriterion provides a necessary and sufficient condition for the Non-Degenerate\nSource Condition (NDSC) which was introduced by Duval and Peyr{\\'e} to ensure\nsupport stability in super-resolution. We provide sufficient conditions which,\nfor instance, hold unconditionally for the Laplace kernel provided one has at\nleast 2M measurements. For the Gaussian filter, we show that those conditions\nare fulfilled in two very different configurations: samples which approximate\nthe uniform Lebesgue measure or, more surprisingly, samples which are all\nconfined in a sufficiently small interval. \n\n"}
{"id": "1712.06577", "contents": "Title: Parallel Complexity of Forward and Backward Propagation Abstract: We show that the forward and backward propagation can be formulated as a\nsolution of lower and upper triangular systems of equations. For standard\nfeedforward (FNNs) and recurrent neural networks (RNNs) the triangular systems\nare always block bi-diagonal, while for a general computation graph (directed\nacyclic graph) they can have a more complex triangular sparsity pattern. We\ndiscuss direct and iterative parallel algorithms that can be used for their\nsolution and interpreted as different ways of performing model parallelism.\nAlso, we show that for FNNs and RNNs with $k$ layers and $\\tau$ time steps the\nbackward propagation can be performed in parallel in O($\\log k$) and O($\\log k\n\\log \\tau$) steps, respectively. Finally, we outline the generalization of this\ntechnique using Jacobians that potentially allows us to handle arbitrary\nlayers. \n\n"}
{"id": "1712.06680", "contents": "Title: ADI schemes for valuing European options under the Bates model Abstract: This paper is concerned with the adaptation of alternating direction implicit\n(ADI) time discretization schemes for the numerical solution of partial\nintegro-differential equations (PIDEs) with application to the Bates model in\nfinance. Three different adaptations are formulated and their (von Neumann)\nstability is analyzed. Ample numerical experiments are provided for the Bates\nPIDE, illustrating the actual stability and convergence behaviour of the three\nadaptations. \n\n"}
{"id": "1712.08192", "contents": "Title: Structured eigenvalue/eigenvector backward errors of matrix pencils\n  arising in optimal control Abstract: Eigenvalue and eigenpair backward errors are computed for matrix pencils\narising in optimal control. In particular, formulas for backward errors are\ndeveloped that are obtained under block-structure-preserving and\nsymmetry-structure-preserving perturbations. It is shown that these eigenvalue\nand eigenpair backward errors are sometimes significantly larger than the\ncorresponding backward errors that are obtained under perturbations that ignore\nthe special structure of the pencil. \n\n"}
{"id": "1712.08469", "contents": "Title: Wall modeling via function enrichment: extension to detached-eddy\n  simulation Abstract: We extend the approach of wall modeling via function enrichment to\ndetached-eddy simulation. The wall model aims at using coarse cells in the\nnear-wall region by modeling the velocity profile in the viscous sublayer and\nlog-layer. However, unlike other wall models, the full Navier-Stokes equations\nare still discretely fulfilled, including the pressure gradient and convective\nterm. This is achieved by enriching the elements of the high-order\ndiscontinuous Galerkin method with the law-of-the-wall. As a result, the\nGalerkin method can \"choose\" the optimal solution among the polynomial and\nenrichment shape functions. The detached-eddy simulation methodology provides a\nsuitable turbulence model for the coarse near-wall cells. The approach is\napplied to wall-modeled LES of turbulent channel flow in a wide range of\nReynolds numbers. Flow over periodic hills shows the superiority compared to an\nequilibrium wall model under separated flow conditions. \n\n"}
{"id": "1801.00368", "contents": "Title: Stable rank one matrix completion is solved by two rounds of\n  semidefinite programming relaxation Abstract: This paper studies the problem of deterministic rank-one matrix completion.\nIt is known that the simplest semidefinite programming relaxation, involving\nminimization of the nuclear norm, does not in general return the solution for\nthis problem. In this paper, we show that in every instance where the problem\nhas a unique solution, one can provably recover the original matrix through two\nrounds of semidefinite programming relaxation with minimization of the trace\nnorm. We further show that the solution of the proposed semidefinite program is\nLipschitz-stable with respect to perturbations of the observed entries, unlike\nmore basic algorithms such as nonlinear propagation or ridge regression. Our\nproof is based on recursively building a certificate of optimality\ncorresponding to a dual sum-of-squares (SOS) polynomial. This SOS polynomial is\nbuilt from the polynomial ideal generated by the completion constraints and the\nmonomials provided by the minimization of the trace. The proposed relaxation\nfits in the framework of the Lasserre hierarchy, albeit with the key addition\nof the trace objective function. We further show how to represent and\nmanipulate the moment tensor in favorable complexity by means of a hierarchical\nlow-rank decomposition. \n\n"}
{"id": "1801.01103", "contents": "Title: A low-rank projector-splitting integrator for the Vlasov--Poisson\n  equation Abstract: Many problems encountered in plasma physics require a description by kinetic\nequations, which are posed in an up to six-dimensional phase space. A direct\ndiscretization of this phase space, often called the Eulerian approach, has\nmany advantages but is extremely expensive from a computational point of view.\nIn the present paper we propose a dynamical low-rank approximation to the\nVlasov--Poisson equation, with time integration by a particular splitting\nmethod. This approximation is derived by constraining the dynamics to a\nmanifold of low-rank functions via a tangent space projection and by splitting\nthis projection into the subprojections from which it is built. This reduces a\ntime step for the six- (or four-) dimensional Vlasov--Poisson equation to\nsolving two systems of three- (or two-) dimensional advection equations over\nthe time step, once in the position variables and once in the velocity\nvariables, where the size of each system of advection equations is equal to the\nchosen rank. By a hierarchical dynamical low-rank approximation, a time step\nfor the Vlasov--Poisson equation can be further reduced to a set of six (or\nfour) systems of one-dimensional advection equations, where the size of each\nsystem of advection equations is still equal to the rank. The resulting systems\nof advection equations can then be solved by standard techniques such as\nsemi-Lagrangian or spectral methods. Numerical simulations in two and four\ndimensions for linear Landau damping, for a two-stream instability and for a\nplasma echo problem highlight the favorable behavior of this numerical method\nand show that the proposed algorithm is able to drastically reduce the required\ncomputational effort. \n\n"}
{"id": "1801.03402", "contents": "Title: Modelling wave propagation without sampling restrictions using the\n  multiplicative calculus I: Theoretical considerations Abstract: The multiplicative (or geometric) calculus is a non-Newtonian calculus\nderived from an arithmetic in which the operations of\naddition/subtraction/multiplication are replaced by\nmultiplication/division/exponentiation. A major difference between the\nmultiplicative calculus and the classical additive calculus, and one that has\nimportant consequences in the simulation of wave propagation problems, is that\nin geometric calculus the role of polynomials is played by exponentials of a\npolynomial argument. For example, whereas a polynomial of degree one has\nconstant (classical) derivative, it is the exponential function that has\nconstant derivative in the multiplicative calculus. As we will show, this\nimplies that even low-order finite quotient approximations|the analogues of\nfinite differences in the multiplicative calculus|produce exact multiplicative\nderivatives of exponential functions. We exploit this fact to show that some\npartial differential equations (PDE) can be solved far more efficiently using\ntechniques based on the multiplicative calculus. For wave propagation models in\nparticular, we will show that it is possible to circumvent the\nminimum-points-per-wavelength sampling constraints of classical methods. In\nthis first part we develop the theoretical framework for studying\nmultiplicative partial differential equations and their connections with\nclassical models. \n\n"}
{"id": "1801.04363", "contents": "Title: Design of accurate formulas for approximating functions in weighted\n  Hardy spaces by discrete energy minimization Abstract: We propose a simple and effective method for designing approximation formulas\nfor weighted analytic functions. We consider spaces of such functions according\nto weight functions expressing the decay properties of the functions. Then, we\nadopt the minimum worst error of the $n$-point approximation formulas in each\nspace for characterizing the optimal sampling points for the approximation. In\norder to obtain approximately optimal sampling points, we consider minimization\nof a discrete energy related to the minimum worst error. Consequently, we\nobtain an approximation formula and its theoretical error estimate in each\nspace. In addition, from some numerical experiments, we observe that the\nformula generated by the proposed method outperforms the corresponding formula\nderived with sinc approximation, which is near optimal in each space. \n\n"}
{"id": "1801.04573", "contents": "Title: Computing the Reciprocal of a $\\phi$-function by Rational Approximation Abstract: In this paper we introduce a family of rational approximations of the\nreciprocal of a $\\phi$-function involved in the explicit solutions of certain\nlinear differential equations, as well as in integration schemes evolving on\nmanifolds. The derivation and properties of this family of approximations\napplied to scalar and matrix arguments are presented. Moreover, we show that\nthe matrix functions computed by these approximations exhibit decaying\nproperties comparable to the best existing theoretical bounds. Numerical\nexamples highlight the benefits of the proposed rational approximations\nw.r.t.~the classical Taylor polynomials and other rational functions. \n\n"}
{"id": "1801.06095", "contents": "Title: A Gauss-Jacobi Kernel Compression Scheme for Fractional Differential\n  Equations Abstract: A scheme for approximating the kernel $w$ of the fractional $\\alpha$-integral\nby a linear combination of exponentials is proposed and studied. The scheme is\nbased on the application of a composite Gauss-Jacobi quadrature rule to an\nintegral representation of $w$. This results in an approximation of $w$ in an\ninterval $[\\delta,T]$, with $0<\\delta$, which converges rapidly in the number\n$J$ of quadrature nodes associated with each interval of the composite rule.\nUsing error analysis for Gauss-Jacobi quadratures for analytic functions, an\nestimate of the relative pointwise error is obtained. The estimate shows that\nthe number of terms required for the approximation to satisfy a prescribed\nerror tolerance is bounded for all $\\alpha\\in(0,1)$, and that $J$ is bounded\nfor $\\alpha\\in(0,1)$, $T>0$, and $\\delta\\in(0,T)$. \n\n"}
{"id": "1801.06592", "contents": "Title: A divergence-free semi-implicit finite volume scheme for ideal, viscous\n  and resistive magnetohydrodynamics Abstract: In this paper we present a novel pressure-based semi-implicit finite volume\nsolver for the equations of compressible ideal, viscous and resistive\nmagnetohydrodynamics (MHD). The new method is conservative for mass, momentum\nand total energy and in multiple space dimensions it is constructed in such a\nway as to respect the divergence-free condition of the magnetic field exactly,\nalso in the presence of resistive effects. This is possible via the use of\nmulti-dimensional Riemann solvers on an appropriately staggered grid for the\ntime evolution of the magnetic field and a double curl formulation of the\nresistive terms. The new semi-implicit method for the MHD equations proposed\nhere discretizes all terms related to the pressure in the momentum equation and\nthe total energy equation implicitly, making again use of a properly staggered\ngrid for pressure and velocity. The time step of the scheme is restricted by a\nCFL condition based only on the fluid velocity and the Alfv\\'en wave speed and\nis not based on the speed of the magnetosonic waves. Our new method is\nparticularly well-suited for low Mach number flows and for the incompressible\nlimit of the MHD equations, for which it is well-known that explicit\ndensity-based Godunov-type finite volume solvers become increasingly\ninefficient and inaccurate due to the increasingly stringent CFL condition and\nthe wrong scaling of the numerical viscosity in the incompressible limit. We\nshow a relevant MHD test problem in the low Mach number regime where the new\nsemi-implicit algorithm is a factor of 50 faster than a traditional explicit\nfinite volume method, which is a very significant gain in terms of\ncomputational efficiency. However, our numerical results confirm that our new\nmethod performs well also for classical MHD test cases with strong shocks. In\nthis sense our new scheme is a true all Mach number flow solver. \n\n"}
{"id": "1801.07148", "contents": "Title: Robust numerical methods for nonlocal (and local) equations of porous\n  medium type. Part I: Theory Abstract: We develop a unified and easy to use framework to study robust fully discrete\nnumerical methods for nonlinear degenerate diffusion equations $$ \\partial_t\nu-\\mathfrak{L}^{\\sigma,\\mu}[\\varphi(u)]=f \\quad\\quad\\text{in}\\quad\\quad\n\\mathbb{R}^N\\times(0,T), $$ where $\\mathfrak{L}^{\\sigma,\\mu}$ is a general\nsymmetric diffusion operator of L\\'evy type and $\\varphi$ is merely continuous\nand non-decreasing. We then use this theory to prove convergence for many\ndifferent numerical schemes. In the nonlocal case most of the results are\ncompletely new. Our theory covers strongly degenerate Stefan problems, the full\nrange of porous medium equations, and for the first time for nonlocal problems,\nalso fast diffusion equations. Examples of diffusion operators\n$\\mathfrak{L}^{\\sigma,\\mu}$ are the (fractional) Laplacians $\\Delta$ and\n$-(-\\Delta)^{\\frac\\alpha2}$ for $\\alpha\\in(0,2)$, discrete operators, and\ncombinations. The observation that monotone finite difference operators are\nnonlocal L\\'evy operators, allows us to give a unified and compact {\\em\nnonlocal} theory for both local and nonlocal, linear and nonlinear diffusion\nequations. The theory includes stability, compactness, and convergence of the\nmethods under minimal assumptions -- including assumptions that lead to very\nirregular solutions. As a byproduct, we prove the new and general existence\nresult announced in \\cite{DTEnJa17b}. We also present some numerical tests, but\nextensive testing is deferred to the companion paper \\cite{DTEnJa18b} along\nwith a more detailed discussion of the numerical methods included in our\ntheory. \n\n"}
{"id": "1801.08531", "contents": "Title: A randomized and fully discrete Galerkin finite element method for\n  semilinear stochastic evolution equations Abstract: In this paper the numerical solution of non-autonomous semilinear stochastic\nevolution equations driven by an additive Wiener noise is investigated. We\nintroduce a novel fully discrete numerical approximation that combines a\nstandard Galerkin finite element method with a randomized Runge-Kutta scheme.\nConvergence of the method to the mild solution is proven with respect to the\n$L^p$-norm, $p \\in [2,\\infty)$. We obtain the same temporal order of\nconvergence as for Milstein-Galerkin finite element methods but without\nimposing any differentiability condition on the nonlinearity. The results are\nextended to also incorporate a spectral approximation of the driving Wiener\nprocess. An application to a stochastic partial differential equation is\ndiscussed and illustrated through a numerical experiment. \n\n"}
{"id": "1801.08870", "contents": "Title: Two-Stage Fourth-order Gas-kinetic Scheme for Three-dimensional Euler\n  and Navier-Stokes Solutions Abstract: For the one-stage third-order gas-kinetic scheme (GKS), success applications\nhave been achieved for the three-dimensional compressible flow computations\n[33]. The high-order accuracy of the scheme is obtained directly by integrating\na multidimensional time-accurate gas distribution function over the cell\ninterface within a time step without implementing Gaussian quadrature points\nand Runge-Kutta time-stepping technique. However, for the further increasing\nthe order of the scheme, such as the fourth-order one, the formulation becomes\nvery complicated for the multidimensional flow. Recently, a two-stage\nfourth-order GKS with high efficiency has been constructed for two-dimensional\ninviscid and viscous flow computations [22,32], and the scheme uses the time\naccurate flux function and its time derivatives. In this paper, a fourth-order\nGKS is developed for the threedimensional flows under the two-stage framework.\nBased on the three-dimensional WENO reconstruction and flux evaluation at\nGaussian quadrature points on a cell interface, the high-order accuracy in\nspace is achieved first. Then, the two-stage time stepping method provides the\nhigh accuracy in time. In comparison with the formal third-order GKS [33], the\ncurrent fourth-order method not only improves the accuracy of the scheme, but\nalso reduces the complexity of the gas-kinetic solver greatly. More\nimportantly, the fourth-order GKS has the same robustness as the second-order\nshock capturing scheme. This scheme is applied to both inviscid and viscous,\nand low and high speed flow computations. Numerical results validate the\noutstanding reliability and applicability of the scheme for three-dimensional\nflows, such as turbulent one. \n\n"}
{"id": "1801.09094", "contents": "Title: Domain decomposition for quasi-periodic scattering by layered media via\n  robust boundary-integral equations at all frequencies Abstract: We develop a non-overlapping domain decomposition method (DDM) for scalar\nwave scattering by periodic layered media. Our approach relies on robust\nboundary-integral equation formulations of Robin-to-Robin (RtR) maps throughout\nthe frequency spectrum, including cutoff (or Wood) frequencies. We overcome the\nobstacle of non-convergent quasi-periodic Green functions at these frequencies\nby incorporating newly introduced shifted Green functions. Using the latter in\nthe definition of quasi-periodic boundary-integral operators leads to\nrigorously stable computations of RtR operators. We develop Nystr\\\"om\ndiscretizations of the RtR maps that rely on trigonometric interpolation,\nsingularity resolution, and fast convergent windowed quasi-periodic Green\nfunctions. We solve the tridiagonal DDM system via recursive Schur complements\nand establish rigorously that this procedure is always completed successfully.\nWe present a variety of numerical results concerning Wood frequencies in two\nand three dimensions as well as large numbers of layers. \n\n"}
{"id": "1801.09324", "contents": "Title: Strong error analysis for stochastic gradient descent optimization\n  algorithms Abstract: Stochastic gradient descent (SGD) optimization algorithms are key ingredients\nin a series of machine learning applications. In this article we perform a\nrigorous strong error analysis for SGD optimization algorithms. In particular,\nwe prove for every arbitrarily small $\\varepsilon \\in (0,\\infty)$ and every\narbitrarily large $p\\in (0,\\infty)$ that the considered SGD optimization\nalgorithm converges in the strong $L^p$-sense with order\n$\\frac{1}{2}-\\varepsilon$ to the global minimum of the objective function of\nthe considered stochastic approximation problem under standard convexity-type\nassumptions on the objective function and relaxed assumptions on the moments of\nthe stochastic errors appearing in the employed SGD optimization algorithm. The\nkey ideas in our convergence proof are, first, to employ techniques from the\ntheory of Lyapunov-type functions for dynamical systems to develop a general\nconvergence machinery for SGD optimization algorithms based on such functions,\nthen, to apply this general machinery to concrete Lyapunov-type functions with\npolynomial structures, and, thereafter, to perform an induction argument along\nthe powers appearing in the Lyapunov-type functions in order to achieve for\nevery arbitrarily large $ p \\in (0,\\infty) $ strong $ L^p $-convergence rates.\nThis article also contains an extensive review of results on SGD optimization\nalgorithms in the scientific literature. \n\n"}
{"id": "1801.09348", "contents": "Title: Strong Approximation of Stochastic Allen-Cahn Equation with White Noise Abstract: We establish an optimal strong convergence rate of a fully discrete numerical\nscheme for second order parabolic stochastic partial differential equations\nwith monotone drifts, including the stochastic Allen-Cahn equation, driven by\nan additive space-time white noise. Our first step is to transform the original\nstochastic equation into an equivalent random equation whose solution possesses\nmore regularity than the original one. Then we use the backward Euler in time\nand spectral Galerkin in space to fully discretize this random equation. By the\nmonotone assumption, in combination with the factorization method and\nstochastic calculus in martingale-type 2 Banach spaces, we derive a uniform\nmaximum norm estimation and a H\\\"older-type regularity for both stochastic and\nrandom equations. Finally, the strong convergence rate of the proposed fully\ndiscrete scheme under the $l_t^\\infty L^2_\\omega L^2_x \\cap l_t^q L^q_\\omega\nL^q_x$-norm is obtained. Several numerical experiments are carried out to\nverify the theoretical result. \n\n"}
{"id": "1801.09767", "contents": "Title: What Is the Fractional Laplacian? Abstract: The fractional Laplacian in R^d has multiple equivalent characterizations.\nMoreover, in bounded domains, boundary conditions must be incorporated in these\ncharacterizations in mathematically distinct ways, and there is currently no\nconsensus in the literature as to which definition of the fractional Laplacian\nin bounded domains is most appropriate for a given application. The Riesz (or\nintegral) definition, for example, admits a nonlocal boundary condition, where\nthe value of a function u(x) must be prescribed on the entire exterior of the\ndomain in order to compute its fractional Laplacian. In contrast, the spectral\ndefinition requires only the standard local boundary condition. These\ndifferences, among others, lead us to ask the question: \"What is the fractional\nLaplacian?\" We compare several commonly used definitions of the fractional\nLaplacian (the Riesz, spectral, directional, and horizon-based nonlocal\ndefinitions), and we use a joint theoretical and computational approach to\nexamining their different characteristics by studying solutions of related\nfractional Poisson equations formulated on bounded domains.\n  In this work, we provide new numerical methods as well as a self-contained\ndiscussion of state-of-the-art methods for discretizing the fractional\nLaplacian, and we present new results on the differences in features,\nregularity, and boundary behaviors of solutions to equations posed with these\ndifferent definitions. We present stochastic interpretations and demonstrate\nthe equivalence between some recent formulations. Through our efforts, we aim\nto further engage the research community in open problems and assist\npractitioners in identifying the most appropriate definition and computational\napproach to use for their mathematical models in addressing anomalous transport\nin diverse applications. \n\n"}
{"id": "1802.00708", "contents": "Title: Numerical methods for conservation laws with rough flux Abstract: Finite volume methods are proposed for computing approximate pathwise\nentropy/kinetic solutions to conservation laws with a rough path dependent flux\nfunction. For a convex flux, it is demonstrated that rough path oscillations\nmay lead to \"cancellations\" in the solution. Making use of this property, we\nshow that for $\\alpha$-H{\\\"o}lder continuous rough paths the convergence rate\nof the numerical methods can improve from $\\mathcal{O}(\\text{COST}^{-\\gamma})$,\nfor some $\\gamma \\in \\left[\\alpha/(12-8\\alpha), \\alpha/(10-6\\alpha)\\right]$,\nwith $\\alpha\\in (0, 1)$, to $\\mathcal{O}(\\text{COST}^{-\\min(1/4,\\alpha/2)})$.\nNumerical examples support the theoretical results. \n\n"}
{"id": "1802.00984", "contents": "Title: Numerical Schubert Calculus via the Littlewood-Richardson Homotopy\n  Algorithm Abstract: We develop the Littlewood-Richardson homotopy algorithm, which uses numerical\ncontinuation to compute solutions to Schubert problems on Grassmannians and is\nbased on the geometric Littlewood-Richardson rule. One key ingredient of this\nalgorithm is our new optimal formulation of Schubert problems in local Stiefel\ncoordinates as systems of equations. Our implementation can solve problem\ninstances with tens of thousands of solutions. \n\n"}
{"id": "1802.01829", "contents": "Title: Average Case $(s, t)$-weak tractability of non-homogenous tensor product\n  problems Abstract: We study $d$-variate problem in the average case setting with respect to a\nzero-mean Gaussian measure. The covariance kernel of this Gaussian measure is a\nproduct of univariate kernels and satisfies some special properties. We study\n$(s, t)$-weak tractability of this multivariate problem, and obtain a necessary\nand sufficient condition for $s>0$ and $t\\in(0,1)$. Our result can apply to the\nproblems with covariance kernels corresponding to Euler and Wiener integrated\nprocesses, Korobov kernels, and analytic Korobov kernels. \n\n"}
{"id": "1802.03067", "contents": "Title: Uniformly accurate methods for Vlasov equations with non-homogeneous\n  strong magnetic field Abstract: In this paper, we consider the numerical solution of highly-oscillatory\nVlasov and Vlasov-Poisson equations with non-homogeneous magnetic field.\nDesigned in the spirit of recent uniformly accurate methods, our schemes remain\ninsensitive to the stiffness of the problem, in terms of both accuracy and\ncomputational cost. The specific difficulty (and the resulting novelty of our\napproach) stems from the presence of a non-periodic oscillation, which\nnecessitates a careful ad-hoc reformulation of the equations. Our results are\nillustrated numerically on several examples. \n\n"}
{"id": "1802.03539", "contents": "Title: Stability and convergence of a conservative finite difference scheme for\n  the modified Hunter--Saxton equation Abstract: The modified Hunter--Saxton equation models the propagation of short\ncapillary-gravity waves. As it involves a mixed derivative, its initial value\nproblem on the periodic domain is much more complicated than the standard\nevolutionary equations. Although its local well-posedness has recently been\nproved, the behavior of its solution is yet to be investigated. In this paper,\nto develop a reliable numerical method for this problem, we derive a\nconservative finite difference scheme. Then, we rigorously prove not only its\nstability in the sense of the uniform norm but also its uniform convergence to\nsufficiently smooth exact solutions. Discrete conservation laws are used to\novercome the difficulty due to the mixed derivative. \n\n"}
{"id": "1802.04628", "contents": "Title: Numerical modelling of a peripheral arterial stenosis using\n  dimensionally reduced models and kernel methods Abstract: In this work, we consider two kinds of model reduction techniques to simulate\nblood flow through the largest systemic arteries, where a stenosis is located\nin a peripheral artery i.e. in an artery that is located far away from the\nheart. For our simulations we place the stenosis in one of the tibial arteries\nbelonging to the right lower leg (right post tibial artery). The model\nreduction techniques that are used are on the one hand dimensionally reduced\nmodels (1-D and 0-D models, the so-called mixed-dimension model) and on the\nother hand surrogate models produced by kernel methods. Both methods are\ncombined in such a way that the mixed-dimension models yield training data for\nthe surrogate model, where the surrogate model is parametrised by the degree of\nnarrowing of the peripheral stenosis. By means of a well-trained surrogate\nmodel, we show that simulation data can be reproduced with a satisfactory\naccuracy and that parameter optimisation or state estimation problems can be\nsolved in a very efficient way. Furthermore it is demonstrated that a surrogate\nmodel enables us to present after a very short simulation time the impact of a\nvarying degree of stenosis on blood flow, obtaining a speedup of several orders\nover the full model. \n\n"}
{"id": "1802.04945", "contents": "Title: Improved Monte-Carlo method for solving of integral Fredholm's equations\n  of a second kind, with confidence regions in the uniform norm Abstract: We offer in this article some modification of Monte-Carlo method for solving\nof a linear integral Fredholm's equation of a second kind (Fredholm's well\nposed problem).\n  We prove that the rate of convergence of offered method is optimal under\nnatural conditions still in an uniform norm, and construct an asymptotic as\nwell as non-asymptotic confidence region, again in the uniform norm. \n\n"}
{"id": "1802.05240", "contents": "Title: Adjoint Method to Calculate Shape Gradients of Failure Probabilaties for\n  Turbomachinery Components Abstract: In the optimization of turbomachinery components, shape sensitivities for\nfluid dynamical objective functions have been used for a long time. As peak\nstress is not a differential func- tional of the shape, such highly efficient\nprocedures so far have been missing for objective functionals that stem from\nmechan- ical integrity. This changes, if deterministic lifing criteria are\nreplaced by probabilistic criteria, which have been introduced recently to the\nfield of low cycle fatigue (LCF). Here we present a finite element (FEA) based\nfirst discretize, then adjoin approach to the calculation of shape gradients\n(sen- sitivities) for the failure probability with regard to probabilistic LCF\nand apply it to simple and complex geometries, as e.g. a blisk geometry. We\nreview the computation of failure probabilities with a FEA postprocessor and\nsketch the computation of the relevant quantities for the adjoint method. We\ndemonstrate high accuracy and computational efficiency of the adjoint method\ncompared to finite difference schemes. We discuss implementation details for\nrotating components with cyclic boundary conditions. Finally, we shortly\ncomment on future development steps and on poten- tial applications in multi\ncriteria optimization. \n\n"}
{"id": "1802.05966", "contents": "Title: Multilevel quadrature for elliptic problems on random domains by the\n  coupling of FEM and BEM Abstract: Elliptic boundary value problems which are posed on a random domain can be\nmapped to a fixed, nominal domain. The randomness is thus transferred to the\ndiffusion matrix and the loading. While this domain mapping method is quite\nefficient for theory and practice, since only a single domain discretisation is\nneeded, it also requires the knowledge of the domain mapping.\n  However, in certain applications, the random domain is only described by its\nrandom boundary, while the quantity of interest is defined on a fixed,\ndeterministic subdomain. In this setting, it thus becomes necessary to compute\na random domain mapping on the whole domain, such that the domain mapping is\nthe identity on the fixed subdomain and maps the boundary of the chosen fixed,\nnominal domain on to the random boundary.\n  To overcome the necessity of computing such a mapping, we therefore couple\nthe finite element method on the fixed subdomain with the boundary element\nmethod on the random boundary. We verify the required regularity of the\nsolution with respect to the random domain mapping for the use of multilevel\nquadrature, derive the coupling formulation, and show by numerical results that\nthe approach is feasible. \n\n"}
{"id": "1802.06077", "contents": "Title: A sampling-based approximation of the complex error function and its\n  implementation without poles Abstract: Recently we developed a new sampling methodology based on incomplete cosine\nexpansion of the sinc function and applied it in numerical integration in order\nto obtain a rational approximation for the complex error function $w\\left(z\n\\right) = e^{- {z^2}}\\left(1 + \\frac{2i}{\\sqrt \\pi}\\int_0^z e^{t^2}dt\\right),$\nwhere $z = x + iy$. As a further development, in this work we show how this\nsampling-based rational approximation can be transformed into alternative form\nfor efficient computation of the complex error function $w\\left(z \\right)$ at\nsmaller values of the imaginary argument $y=\\operatorname{Im}\\left[z \\right]$.\nSuch an approach enables us to avoid poles in implementation and to cover the\nentire complex plain with high accuracy in a rapid algorithm. An optimized\nMatlab code utilizing only three rapid approximations is presented. \n\n"}
{"id": "1802.06517", "contents": "Title: Goal-Oriented Optimal Design of Experiments for Large-Scale Bayesian\n  Linear Inverse Problems Abstract: We develop a framework for goal-oriented optimal design of experiments\n(GOODE) for large-scale Bayesian linear inverse problems governed by PDEs. This\nframework differs from classical Bayesian optimal design of experiments (ODE)\nin the following sense: we seek experimental designs that minimize the\nposterior uncertainty in the experiment end-goal, e.g., a quantity of interest\n(QoI), rather than the estimated parameter itself. This is suitable for\nscenarios in which the solution of an inverse problem is an intermediate step\nand the estimated parameter is then used to compute a QoI. In such problems, a\nGOODE approach has two benefits: the designs can avoid wastage of experimental\nresources by a targeted collection of data, and the resulting design criteria\nare computationally easier to evaluate due to the often low-dimensionality of\nthe QoIs. We present two modified design criteria, A-GOODE and D-GOODE, which\nare natural analogues of classical Bayesian A- and D-optimal criteria. We\nanalyze the connections to other ODE criteria, and provide interpretations for\nthe GOODE criteria by using tools from information theory. Then, we develop an\nefficient gradient-based optimization framework for solving the GOODE\noptimization problems. Additionally, we present comprehensive numerical\nexperiments testing the various aspects of the presented approach. The driving\napplication is the optimal placement of sensors to identify the source of\ncontaminants in a diffusion and transport problem. We enforce sparsity of the\nsensor placements using an $\\ell_1$-norm penalty approach, and propose a\npractical strategy for specifying the associated penalty parameter. \n\n"}
{"id": "1802.06673", "contents": "Title: Systems of Differential Algebraic Equations in Computational\n  Electromagnetics Abstract: Starting from space-discretisation of Maxwell's equations, various classical\nformulations are proposed for the simulation of electromagnetic fields. They\ndiffer in the phenomena considered as well as in the variables chosen for\ndiscretisation. This contribution presents a literature survey of the most\ncommon approximations and formulations with a focus on their structural\nproperties. The differential-algebraic character is discussed and quantified by\nthe differential index concept. \n\n"}
{"id": "1802.07341", "contents": "Title: An entropy stable nodal discontinuous Galerkin method for the resistive\n  MHD equations. Part I: Theory and Numerical Verification Abstract: The first paper of this series presents a discretely entropy stable\ndiscontinuous Galerkin (DG) method for the resistive magnetohydrodynamics (MHD)\nequations on three-dimensional curvilinear unstructured hexahedral meshes.\nCompared to other fluid dynamics systems such as the shallow water equations or\nthe compressible Navier-Stokes equations, the resistive MHD equations need\nspecial considerations because of the divergence-free constraint on the\nmagnetic field. For instance, it is well known that for the symmetrization of\nthe ideal MHD system as well as the continuous entropy analysis a\nnon-conservative term proportional to the divergence of the magnetic field,\ntypically referred to as the Powell term, must be included. As a consequence,\nthe mimicry of the continuous entropy analysis in the discrete sense demands a\nsuitable DG approximation of the non-conservative terms in addition to the\nideal MHD terms.\n  This paper focuses on the resistive MHD equations: Our first contribution is\na proof that the resistive terms are symmetric and positive-definite when\nformulated in entropy space as gradients of the entropy variables. This enables\nus to show that the entropy inequality holds for the resistive MHD equations.\nThis continuous analysis is the key for our DG discretization and guides the\npath for the construction of an approximation that discretely mimics the\nentropy inequality, typically termed entropy stability. Our second contribution\nis a detailed derivation and analysis of the discretization on\nthree-dimensional curvilinear meshes. The discrete analysis relies on the\nsummation-by-parts property, which is satisfied by the DG spectral element\nmethod (DGSEM) with Legendre-Gauss-Lobatto (LGL) nodes. Although the\ndivergence-free constraint is included in the non-conservative terms, the\nresulting method has no particular treatment of the magnetic field divergence\nerrors... \n\n"}
{"id": "1802.07844", "contents": "Title: Fast Ewald summation for Green's functions of Stokes flow in a\n  half-space Abstract: Recently, Gimbutas et al derived an elegant representation for the Green's\nfunctions of Stokes flow in a half-space. We present a fast summation method\nfor sums involving these half-space Green's functions (stokeslets, stresslets\nand rotlets) that consolidates and builds on the work by Klinteberg et al for\nthe corresponding free-space Green's functions. The fast method is based on two\nmain ingredients: The Ewald decomposition and subsequent use of FFTs. The Ewald\ndecomposition recasts the sum into a sum of two exponentially decaying series:\none in real-space (short-range interactions) and one in Fourier-space\n(long-range interactions) with the convergence of each series controlled by a\ncommon parameter. The evaluation of short-range interactions is accelerated by\nrestricting computations to neighbours within a specified distance, while the\nuse of FFTs accelerates the computations in Fourier-space thus accelerating the\noverall sum. We demonstrate that while the method incurs extra costs for the\nhalf-space in comparison to the free-space evaluation, greater computational\nsavings is also achieved when compared to their respective direct sums. \n\n"}
{"id": "1802.09020", "contents": "Title: Entropy stable modeling of non-isothermal multi-component\n  diffuse-interface two-phase flows with realistic equations of state Abstract: In this paper, we consider mathematical modeling and numerical simulation of\nnon-isothermal compressible multi-component diffuse-interface two-phase flows\nwith realistic equations of state. A general model with general reference\nvelocity is derived rigorously through thermodynamical laws and Onsager's\nreciprocal principle, and it is capable of characterizing compressibility and\npartial miscibility between multiple fluids. We prove a novel relation among\nthe pressure, temperature and chemical potentials, which results in a new\nformulation of the momentum conservation equation indicating that the gradients\nof chemical potentials and temperature become the primary driving force of the\nfluid motion except for the external forces. A key challenge in numerical\nsimulation is to develop entropy stable numerical schemes preserving the laws\nof thermodynamics. Based on the convex-concave splitting of Helmholtz free\nenergy density with respect to molar densities and temperature, we propose an\nentropy stable numerical method, which solves the total energy balance equation\ndirectly, and thus, naturally satisfies the first law of thermodynamics.\nUnconditional entropy stability (the second law of thermodynamics) of the\nproposed method is proved by estimating the variations of Helmholtz free energy\nand kinetic energy with time steps. Numerical results validate the proposed\nmethod. \n\n"}
{"id": "1803.00947", "contents": "Title: A nonlinear Stokes-Biot model for the interaction of a non-Newtonian\n  fluid with poroelastic media Abstract: We develop and analyze a model for the interaction of a quasi-Newtonian free\nfluid with a poroelastic medium. The flow in the fluid region is described by\nthe nonlinear Stokes equations and in the poroelastic medium by the nonlinear\nquasi-static Biot model. Equilibrium and kinematic conditions are imposed on\nthe interface. We establish existence and uniqueness of a solution to the weak\nformulation and its semidiscrete continuous-in-time finite element\napproximation. We present error analysis, complemented by numerical\nexperiments. \n\n"}
{"id": "1803.01419", "contents": "Title: Image space projection for low-rank signal estimation: Modified\n  Gauss-Newton method Abstract: The paper is devoted to the solution of a weighted nonlinear least-squares\nproblem for low-rank signal estimation, which is related to Hankel structured\nlow-rank approximation problems. A modified weighted Gauss-Newton method, which\nuses projecting on the image space of the signal, is proposed to solve this\nproblem. The advantage of the proposed method is the possibility of its\nnumerically stable and fast implementation. For a weight matrix, which\ncorresponds to an autoregressive process of order $p$, the computational cost\nof iterations is $O(N r^2 + N p^2 + r N \\log N)$, where $N$ is the time series\nlength, $r$ is the rank of the approximating time series. For developing the\nmethod, some useful properties of the space of time series of rank $r$ are\nstudied. The method is compared with state-of-the-art methods based on the\nvariable projection approach in terms of numerical stability, accuracy and\ncomputational cost. \n\n"}
{"id": "1803.01805", "contents": "Title: Model Reduction for a Pulsed Detonation Combuster via Shifted Proper\n  Orthogonal Decomposition Abstract: We propose a new algorithm to compute a shifted proper orthogonal\ndecomposition (sPOD) for systems dominated by multiple transport velocities.\nThe sPOD is a recently proposed mode decomposition technique which overcomes\nthe poor performance of classical methods like the proper orthogonal\ndecomposition (POD) for transport-dominated phenomena. This is achieved by\nidentifying the transport directions and velocities and by shifting the modes\nin space to track the transports. Our new algorithm carries out a residual\nminimization in which the main computational cost arises from solving a\nnonlinear optimization problem scaling with the snapshot dimension. We apply\nthe algorithm to snapshot data from the simulation of a pulsed detonation\ncombuster and observe that very few sPOD modes are sufficient to obtain a good\napproximation. For the same accuracy, the common POD needs ten times as many\nmodes and, in contrast to the sPOD modes, the POD modes do not reflect the\nmoving front profiles properly. \n\n"}
{"id": "1803.01829", "contents": "Title: PPD-IPM: Outer primal, inner primal-dual interior-point method for\n  nonlinear programming Abstract: In this paper we present a novel numerical method for computing local\nminimizers of twice smooth differentiable non-linear programming (NLP)\nproblems.\n  So far all algorithms for NLP are based on either of the following three\nprinciples: successive quadratic programming (SQP), active sets (AS), or\ninterior-point methods (IPM). Each of them has drawbacks. These are in order:\niteration complexity, feasibility management in the sub-program, and utility of\ninitial guesses. Our novel approach attempts to overcome these drawbacks.\n  We provide: a mathematical description of the method; proof of global\nconvergence; proof of second order local convergence; an implementation in\n\\textsc{Matlab}; experimental results for large sparse NLPs from direct\ntranscription of path-constrained optimal control problems. \n\n"}
{"id": "1803.01949", "contents": "Title: Admissible perturbations and false instabilities in PT-symmetric quantum\n  systems Abstract: In ${\\cal PT}-$symmetric quantum mechanics one of the most characteristic\nmathematical features of the formalism is the explicit Hamiltonian-dependence\nof the physical Hilbert space of states ${\\cal H}={\\cal H}(H)$. Some of the\nmost important physical consequences are discussed, with emphasis on the\ndynamical regime in which the system is close to the quantum phase transition.\nConsistent perturbation treatment of such a regime is proposed. An illustrative\napplication of the innovated perturbation theory to a non-Hermitian but ${\\cal\nPT}-$symmetric user-friendly family of $J-$parametric \"discrete anharmonic\"\nquantum Hamiltonians $H=H(\\vec{\\lambda})$ is given. The models are shown to\nadmit the standard probabilistic interpretation if and only if the parameters\nremain compatible with the reality of the spectrum, $\\vec{\\lambda} \\in {\\cal\nD}^{(physical)}$. In contradiction to the conventional wisdom the systems are\nshown stable with respect to the admissible perturbations lying inside the\ndomain ${\\cal D}^{(physical)}$. This observation holds even in the immediate\nvicinity of the phase-transition boundaries $\\partial {\\cal D}^{(physical)}$. \n\n"}
{"id": "1803.01963", "contents": "Title: An Accurate and Efficient Algorithm for The Time-fractional Molecular\n  Beam Epitaxy Model with Slope Selection Abstract: In this paper, we propose a time-fractional molecular beam epitaxy (MBE)\nmodel with slope selection and its efficient, accurate, full discrete, linear\nnumerical approximation. The numerical scheme utilizes the fast algorithm for\nthe Caputo fractional derivative operator in time discretization and Fourier\nspectral method in spatial discretization. Refinement tests are conducted to\nverify the $2-\\alpha$ order of time convergence, with $\\alpha \\in (0, 1]$ the\nfractional order of derivative. Several numerical simulations are presented to\ndemonstrate the accuracy and efficiency of our newly proposed scheme. By\nexploring the fast algorithm calculating the Caputo fractional derivative, our\nnumerical scheme makes it practice for long time simulation of MBE coarsening,\nwhich is essential for MBE model in practice. With the proposed fractional MBE\nmodel, we observe that the scaling law for the energy decays as $\nO(t^{-\\frac{\\alpha}{3}})$ and the roughness increases as\n$O(t^{\\frac{\\alpha}{3}})$, during the coarsening dynamics with random initial\ncondition. That is to say, the coarsening rate of MBE model could be\nmanipulated by the fractional order $\\alpha$, and it is linearly proportional\nto $\\alpha$. This is the first time in literature to report/discover such\nscaling correlation. It provides a potential application field for fractional\ndifferential equations. Besides, the numerical approximation strategy proposed\nin this paper can be readily applied to study many classes of time-fractional\nand high dimensional phase field models. \n\n"}
{"id": "1803.01982", "contents": "Title: Low-Rank Matrix Approximations with Flip-Flop Spectrum-Revealing QR\n  Factorization Abstract: We present Flip-Flop Spectrum-Revealing QR (Flip-Flop SRQR) factorization, a\nsignificantly faster and more reliable variant of the QLP factorization of\nStewart, for low-rank matrix approximations. Flip-Flop SRQR uses SRQR\nfactorization to initialize a partial column pivoted QR factorization and then\ncompute a partial LQ factorization. As observed by Stewart in his original QLP\nwork, Flip-Flop SRQR tracks the exact singular values with \"considerable\nfidelity\". We develop singular value lower bounds and residual error upper\nbounds for Flip-Flop SRQR factorization. In situations where singular values of\nthe input matrix decay relatively quickly, the low-rank approximation computed\nby SRQR is guaranteed to be as accurate as truncated SVD. We also perform a\ncomplexity analysis to show that for the same accuracy, Flip-Flop SRQR is\nfaster than randomized subspace iteration for approximating the SVD, the\nstandard method used in Matlab tensor toolbox. We also compare Flip-Flop SRQR\nwith alternatives on two applications, tensor approximation and nuclear norm\nminimization, to demonstrate its efficiency and effectiveness. \n\n"}
{"id": "1803.02865", "contents": "Title: WNGrad: Learn the Learning Rate in Gradient Descent Abstract: Adjusting the learning rate schedule in stochastic gradient methods is an\nimportant unresolved problem which requires tuning in practice. If certain\nparameters of the loss function such as smoothness or strong convexity\nconstants are known, theoretical learning rate schedules can be applied.\nHowever, in practice, such parameters are not known, and the loss function of\ninterest is not convex in any case. The recently proposed batch normalization\nreparametrization is widely adopted in most neural network architectures today\nbecause, among other advantages, it is robust to the choice of Lipschitz\nconstant of the gradient in loss function, allowing one to set a large learning\nrate without worry. Inspired by batch normalization, we propose a general\nnonlinear update rule for the learning rate in batch and stochastic gradient\ndescent so that the learning rate can be initialized at a high value, and is\nsubsequently decreased according to gradient observations along the way. The\nproposed method is shown to achieve robustness to the relationship between the\nlearning rate and the Lipschitz constant, and near-optimal convergence rates in\nboth the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch\nsetting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We\nalso show through numerical evidence that such robustness of the proposed\nmethod extends to highly nonconvex and possibly non-smooth loss function in\ndeep learning problems.Our analysis establishes some first theoretical\nunderstanding into the observed robustness for batch normalization and weight\nnormalization. \n\n"}
{"id": "1803.03551", "contents": "Title: An iterative method for elliptic problems with rapidly oscillating\n  coefficients Abstract: We introduce a new iterative method for computing solutions of elliptic\nequations with random rapidly oscillating coefficients. Similarly to a\nmultigrid method, each step of the iteration involves different computations\nmeant to address different length scales. However, we use here the homogenized\nequation on all scales larger than a fixed multiple of the scale of oscillation\nof the coefficients. While the performance of standard multigrid methods\ndegrades rapidly under the regime of large scale separation that we consider\nhere, we show an explicit estimate on the contraction factor of our method\nwhich is independent of the size of the domain. We also present numerical\nexperiments which confirm the effectiveness of the method, with openly\navailable source code. \n\n"}
{"id": "1803.04516", "contents": "Title: Explicit inverse of tridiagonal matrix with applications in\n  autoregressive modeling Abstract: We present the explicit inverse of a class of symmetric tridiagonal matrices\nwhich is almost Toeplitz, except that the first and last diagonal elements are\ndifferent from the rest. This class of tridiagonal matrices are of special\ninterest in complex statistical models which uses the first order\nautoregression to induce dependence in the covariance structure, for instance,\nin econometrics or spatial modeling. They also arise in interpolation problems\nusing the cubic spline. We show that the inverse can be expressed as a linear\ncombination of Chebyshev polynomials of the second kind and present results on\nthe properties of the inverse, such as bounds on the row sums, the trace of the\ninverse and its square, and their limits as the order of the matrix increases. \n\n"}
{"id": "1803.04726", "contents": "Title: Generalized SART Methods for Tomographic Imaging Abstract: Nowadays, the field computed tomography (CT) encompasses a large variety of\nsettings, ranging from nanoscale to meter-sized objects imaged by different\nkinds of radiation in various acquisition modes. This experimental diversity\nchallenges the flexibility of tomographic reconstruction methods. Kaczmarz-type\nmethods, which exploit the natural block-structure of tomographic inverse\nproblems, are a promising candidate to provide the required versatility in a\ncomputationally efficient manner. In the present work, it is shown that indeed\na surprisingly general class of tomographic Kaczmarz-iterations may be\nefficiently evaluated via computational schemes of a similar structure as\nupdates of the so-called simultaneous algebraic reconstruction technique\n(SART). This enables regularized reconstructions with non-trivial\nimage-formation models as well as non-quadratic or even non-convex\ndata-fidelity terms at low computational costs. Moreover, the proposed\ngeneralized SART schemes are equally applicable in parallel- and cone-beam\nsettings and regardless of the choice of tomographic incident directions. Their\npotential is illustrated by outlining applications in several non-standard\ntomographic settings, including polychromatic CT and X-ray phase contrast\ntomography. \n\n"}
{"id": "1803.05919", "contents": "Title: Capturing near-equilibrium solutions: a comparison between high-order\n  discontinuous Galerkin methods and well-balanced schemes Abstract: Equilibrium or stationary solutions usually proceed through the exact balance\nbetween hyperbolic transport terms and source terms. Such equilibrium solutions\nare affected by truncation errors that prevent any classical numerical scheme\nfrom capturing the evolution of small amplitude waves of physical significance.\nIn order to overcome this problem, we compare two commonly adopted strategies:\ngoing to very high order and reduce drastically the truncation errors on the\nequilibrium solution, or design a specific scheme that preserves by\nconstruction the equilibrium exactly, the so-called well-balanced approach. We\npresent a modern numerical implementation of these two strategies and compare\nthem in details, using hydrostatic but also dynamical equilibrium solutions of\nseveral simple test cases. Finally, we apply our methodology to the simulation\nof a protoplanetary disc in centrifugal equilibrium around its star and model\nits interaction with an embedded planet, illustrating in a realistic\napplication the strength of both methods. \n\n"}
{"id": "1803.06893", "contents": "Title: On reference solutions and the sensitivity of the 2D Kelvin-Helmholtz\n  instability problem Abstract: Two-dimensional Kelvin-Helmholtz instability problems are popular examples\nfor assessing discretizations for incompressible flows at high Reynolds number.\nUnfortunately, the results in the literature differ considerably. This paper\npresents computational studies of a Kelvin-Helmholtz instability problem with\nhigh order divergence-free finite element methods. Reference results in several\nquantities of interest are obtained for three different Reynolds numbers up to\nthe beginning of the final vortex pairing. A mesh-independent prediction of the\nfinal pairing is not achieved due to the sensitivity of the considered problem\nwith respect to small perturbations. A theoretical explanation of this\nsensitivity to small perturbations is provided based on the theory of\nself-organization of 2D turbulence. Possible sources of perturbations that\narise in almost any numerical simulation are discussed. \n\n"}
{"id": "1803.07668", "contents": "Title: Hybrid asymptotic/numerical methods for the evaluation of layer heat\n  potentials in two dimensions Abstract: We present a hybrid asymptotic/numerical method for the accurate computation\nof single and double layer heat potentials in two dimensions. It has been shown\nin previous work that simple quadrature schemes suffer from a phenomenon called\n\"geometrically-induced stiffness,\" meaning that formally high-order accurate\nmethods require excessively small time steps before the rapid convergence rate\nis observed. This can be overcome by analytic integration in time, requiring\nthe evaluation of a collection of spatial boundary integral operators with\nnon-physical, weakly singular kernels. In our hybrid scheme, we combine a local\nasymptotic approximation with the evaluation of a few boundary integral\noperators involving only Gaussian kernels, which are easily accelerated by a\nnew version of the fast Gauss transform. This new scheme is robust, avoids\ngeometrically-induced stiffness, and is easy to use in the presence of moving\ngeometries. Its extension to three dimensions is natural and straightforward,\nand should permit layer heat potentials to become flexible and powerful tools\nfor modeling diffusion processes. \n\n"}
{"id": "1803.07683", "contents": "Title: On the Complexity of Testing Attainment of the Optimal Value in\n  Nonlinear Optimization Abstract: We prove that unless P=NP, there exists no polynomial time (or even\npseudo-polynomial time) algorithm that can test whether the optimal value of a\nnonlinear optimization problem where the objective and constraints are given by\nlow-degree polynomials is attained. If the degrees of these polynomials are\nfixed, our results along with previously-known \"Frank-Wolfe type\" theorems\nimply that exactly one of two cases can occur: either the optimal value is\nattained on every instance, or it is strongly NP-hard to distinguish attainment\nfrom non-attainment. We also show that testing for some well-known sufficient\nconditions for attainment of the optimal value, such as coercivity of the\nobjective function and closedness and boundedness of the feasible set, is\nstrongly NP-hard. As a byproduct, our proofs imply that testing the Archimedean\nproperty of a quadratic module is strongly NP-hard, a property that is of\nindependent interest to the convergence of the Lasserre hierarchy. Finally, we\ngive semidefinite programming (SDP)-based sufficient conditions for attainment\nof the optimal value, in particular a new characterization of coercive\npolynomials that lends itself to an SDP hierarchy. \n\n"}
{"id": "1803.10270", "contents": "Title: Parallel numerical tensor methods for high-dimensional PDEs Abstract: High-dimensional partial-differential equations (PDEs) arise in a number of\nfields of science and engineering, where they are used to describe the\nevolution of joint probability functions. Their examples include the Boltzmann\nand Fokker-Planck equations. We develop new parallel algorithms to solve\nhigh-dimensional PDEs. The algorithms are based on canonical and hierarchical\nnumerical tensor methods combined with alternating least squares and\nhierarchical singular value decomposition. Both implicit and explicit\nintegration schemes are presented and discussed. We demonstrate the accuracy\nand efficiency of the proposed new algorithms in computing the numerical\nsolution to both an advection equation in six variables plus time and a\nlinearized version of the Boltzmann equation. \n\n"}
{"id": "1803.11019", "contents": "Title: Optimal Convergence Rates for Tikhonov Regularization in Besov Spaces Abstract: This paper deals with Tikhonov regularization for linear and nonlinear\nill-posed operator equations with wavelet Besov norm penalties. We show order\noptimal rates of convergence for finitely smoothing operators and for the\nbackwards heat equation for a range of Besov spaces using variational source\nconditions. We also derive order optimal rates for a white noise model with the\nhelp of variational source conditions and concentration inequalities for sharp\nnegative Besov norms of the noise. \n\n"}
{"id": "1803.11191", "contents": "Title: Approximation of the Boltzmann Collision Operator Based on Hermite\n  Spectral Method Abstract: Based on the Hermite expansion of the distribution function, we introduce a\nGalerkin spectral method for the spatially homogeneous Boltzmann equation with\nthe realistic inverse-power-law models. A practical algorithm is proposed to\nevaluate the coefficients in the spectral method with high accuracy, and these\ncoefficients are also used to construct new computationally affordable\ncollision models. Numerical experiments show that our method captures the\nlow-order moments very efficiently. \n\n"}
{"id": "1804.01007", "contents": "Title: On evaluation of the confluent Heun functions Abstract: In this paper we consider the confluent Heun equation, which is a linear\ndifferential equation of second order with three singular points --- two of\nthem are regular and the third one is irregular of rank 1. The purpose of the\nwork is to propose a procedure for numerical evaluation of the equation's\nsolutions (confluent Heun functions). A scheme based on power series,\nasymptotic expansions and analytic continuation is described. Results of\nnumerical tests are given. \n\n"}
{"id": "1804.04310", "contents": "Title: Exact Reconstruction of Euclidean Distance Geometry Problem Using\n  Low-rank Matrix Completion Abstract: The Euclidean distance geometry problem arises in a wide variety of\napplications, from determining molecular conformations in computational\nchemistry to localization in sensor networks. When the distance information is\nincomplete, the problem can be formulated as a nuclear norm minimization\nproblem. In this paper, this minimization program is recast as a matrix\ncompletion problem of a low-rank $r$ Gram matrix with respect to a suitable\nbasis. The well known restricted isometry property can not be satisfied in this\nscenario. Instead, a dual basis approach is introduced to theoretically analyze\nthe reconstruction problem. If the Gram matrix satisfies certain coherence\nconditions with parameter $\\nu$, the main result shows that the underlying\nconfiguration of $n$ points can be recovered with very high probability from\n$O(nr\\nu\\log^{2}(n))$ uniformly random samples. Computationally, simple and\nfast algorithms are designed to solve the Euclidean distance geometry problem.\nNumerical tests on different three dimensional data and protein molecules\nvalidate effectiveness and efficiency of the proposed algorithms. \n\n"}
{"id": "1804.04496", "contents": "Title: On perfectly matched layers for discontinuous Petrov-Galerkin methods Abstract: In this article, several discontinuous Petrov-Galerkin (DPG) methods with\nperfectly matched layers (PMLs) are derived along with their quasi-optimal\ngraph test norms. Ultimately, two different complex coordinate stretching\nstrategies are considered in these derivations. Unlike with classical\nformulations used by Bubnov-Galerkin methods, with so-called ultraweak\nvariational formulations, these two strategies in fact deliver different\nformulations in the PML region. One of the strategies, which is argued to be\nmore physically natural, is employed for numerically solving two- and\nthree-dimensional time-harmonic acoustic, elastic, and electromagnetic wave\npropagation problems, defined in unbounded domains. Through these numerical\nexperiments, efficacy of the new DPG methods with PMLs is verified. \n\n"}
{"id": "1804.04561", "contents": "Title: A low-rank algorithm for weakly compressible flow Abstract: In this paper, we propose a numerical method for solving weakly compressible\nfluid flow based on a dynamical low-rank projector splitting. The low-rank\nsplitting scheme is applied to the Boltzmann equation with BGK collision term,\nwhich results in a set of constant coefficient advection equations. This\nprocedure is numerically efficient as a small rank is sufficient to obtain the\nrelevant dynamics (described by the Navier--Stokes equations). The resulting\nmethod can be combined with a range of different discretization strategies; in\nparticular, it is possible to implement spectral and semi-Lagrangian methods,\nwhich allows us to design numerical schemes that are not encumbered by the\nsonic CFL condition. \n\n"}
{"id": "1804.05471", "contents": "Title: Recursive linearization method for inverse medium scattering problems\n  with complex mixture Gaussian error learning Abstract: This paper is concerned with the modeling errors appeared in the numerical\nmethods of inverse medium scattering problems (IMSP). Optimization based\niterative methods are wildly employed to solve IMSP, which are computationally\nintensive due to a series of Helmholtz equations need to be solved numerically.\nHence, rough approximations of Helmholtz equations can significantly speed up\nthe iterative procedure. However, rough approximations will lead to instability\nand inaccurate estimations. Using the Bayesian inverse methods, we incorporate\nthe modelling errors brought by the rough approximations. Modelling errors are\nassumed to be some complex Gaussian mixture (CGM) random variables, and in\naddition, well-posedness of IMSP in the statistical sense has been established\nby extending the general theory to involve CGM noise. Then, we generalize the\nreal valued expectation-maximization (EM) algorithm used in the machine\nlearning community to our complex valued case to learn parameters in the CGM\ndistribution. Based on these preparations, we generalize the recursive\nlinearization method (RLM) to a new iterative method named as Gaussian mixture\nrecursive linearization method (GMRLM) which takes modelling errors into\naccount. Finally, we provide two numerical examples to illustrate the\neffectiveness of the proposed method. \n\n"}
{"id": "1804.05522", "contents": "Title: Fast solvers for two-dimensional fractional diffusion equations using\n  rank structured matrices Abstract: We consider the discretization of time-space diffusion equations with\nfractional derivatives in space and either 1D or 2D spatial domains. The use of\nimplicit Euler scheme in time and finite differences or finite elements in\nspace, leads to a sequence of dense large scale linear systems describing the\nbehavior of the solution over a time interval. We prove that the coefficient\nmatrices arising in the 1D context are rank structured and can be efficiently\nrepresented using hierarchical formats ($\\mathcal H$-matrices, HODLR).\nQuantitative estimates for the rank of the off-diagonal blocks of these\nmatrices are presented. We analyze the use of HODLR arithmetic for solving the\n1D case and we compare this strategy with existing methods that exploit the\nToeplitz-like structure to precondition the GMRES iteration. The numerical\ntests demonstrate the convenience of the HODLR format when at least a\nreasonably low number of time steps is needed. Finally, we explain how these\nproperties can be leveraged to design fast solvers for problems with 2D spatial\ndomains that can be reformulated as matrix equations. The experiments show that\nthe approach based on the use of rank-structured arithmetic is particularly\neffective and outperforms current state of the art techniques. \n\n"}
{"id": "1804.08609", "contents": "Title: A data-driven framework for sparsity-enhanced surrogates with arbitrary\n  mutually dependent randomness Abstract: The challenge of quantifying uncertainty propagation in real-world systems is\nrooted in the high-dimensionality of the stochastic input and the frequent lack\nof explicit knowledge of its probability distribution. Traditional approaches\nshow limitations for such problems. To address these difficulties, we have\ndeveloped a general framework of constructing surrogate models on spaces of\nstochastic input with arbitrary probability measure irrespective of the mutual\ndependencies between individual components and the analytical form. The present\nData-driven Sparsity-enhancing Rotation for Arbitrary Randomness (DSRAR)\nframework includes a data-driven construction of multivariate polynomial basis\nfor arbitrary mutually dependent probability measure and a sparsity enhancement\nrotation procedure. This sparsity-enhancing rotation method was initially\nproposed in our previous work [1] for Gaussian distributions, which may not be\nfeasible for non-Gaussian distributions due to the loss of orthogonality after\nthe rotation. To remedy such difficulties, we developed the new approach to\nconstruct orthonormal polynomials for arbitrary mutually dependent (amdP)\nrandomness, ensuring the constructed basis maintains the orthogonality with\nrespect to the density of the rotated random vector, where directly applying\nthe regular polynomial chaos including arbitrary polynomial chaos (aPC) [2]\nshows limitations due to the assumption of the mutual independence between the\ncomponents of the random inputs. The developed DSRAR framework leads to\naccurate recovery of a sparse representation of the target functions. The\neffectiveness of our method is demonstrated in challenging problems such as\nPDEs and realistic molecular systems where the underlying density is implicitly\nrepresented by a large collection of sample data, as well as systems with\nexplicitly given non-Gaussian probabilistic measures. \n\n"}
{"id": "1804.09811", "contents": "Title: Space-time multiscale model reduction for transport equations Abstract: In this paper, we propose a space-time GMsFEM for transport equations.\nMultiscale transport equations occur in many geoscientific applications, which\ninclude subsurface transport, atmospheric pollution transport, and so on. Most\nof existing multiscale approaches use spatial multiscale basis functions or\nupscaling, and there are very few works that design space-time multiscale\nfunctions to solve the transport equation on a coarse grid. For the time\ndependent problems, the use of space-time multiscale basis functions offers\nseveral advantages as the spatial and temporal scales are intrinsically\ncoupled. By using the GMsFEM idea with a space-time framework, one obtains a\nbetter dimension reduction taking into account features of the solutions in\nboth space and time. In addition, the time-stepping can be performed using much\ncoarser time step sizes compared to the case when spatial multiscale basis are\nused. Our scheme is based on space-time snapshot spaces and model reduction\nusing space-time spectral problems derived from the analysis. We give the\nanalysis for the well-posedness and the spectral convergence of our method. We\nalso present some numerical examples to demonstrate the performance of the\nmethod. In all examples, we observe a good accuracy with a few basis functions. \n\n"}
{"id": "1804.10320", "contents": "Title: Tensor calculus in spherical coordinates using Jacobi polynomials.\n  Part-I: Mathematical analysis and derivations Abstract: This paper presents a method for the accurate and efficient computations on\nscalar, vector and tensor fields in three-dimensional spherical polar\ncoordinates. The methods uses spin-weighted spherical harmonics in the angular\ndirections and rescaled Jacobi polynomials in the radial direction. For the\n2-sphere, spin-weighted harmonics allow for automating calculations in a\nfashion as similar to Fourier series as possible. Derivative operators act as\nwavenumber multiplication on a set of spectral coefficients. After transforming\nthe angular directions, a set of orthogonal tensor rotations put the radially\ndependent spectral coefficients into individual spaces each obeying a\nparticular regularity condition at the origin. These regularity spaces have\nremarkably simple properties under standard vector-calculus operations, such as\n\\textit{grad} and \\textit{div}. We use a hierarchy of rescaled Jacobi\npolynomials for a basis on these regularity spaces. It is possible to select\nthe Jacobi-polynomial parameters such that all relevant operators act in a\nminimally banded way. Altogether, the geometric structure allows for the\naccurate and efficient solution of general partial differential equations in\nthe unit ball. \n\n"}
{"id": "1804.10632", "contents": "Title: Construction of h-refined continuous finite element spaces with\n  arbitrary hanging node configurations and applications to multigrid\n  algorithms Abstract: We present a novel approach for the construction of basis functions to be\nemployed in selective or adaptive h-refined finite element applications with\narbitrary-level hanging node configurations. Our analysis is not restricted to\n$1$-irregular meshes, as it is usually done in the literature, allowing our\nresults to be applicable to a broader class of local refinement strategies. The\nproposed method does not require the solution of any linear system to obtain\nthe constraints necessary to enforce continuity of the basis functions and it\ncan be easily implemented. A mathematical analysis is carried out to prove that\nthe proposed basis functions are continuous and linearly independent. Finite\nelement spaces are then defined as the spanning sets of such functions, and the\nimplementation of a multigrid algorithm built on these spaces is discussed. A\nspectral analysis of the multigrid algorithm highlights superior convergence\nproperties of the proposed method over existing strategies based on a local\nsmoothing procedure. Finally, linear and nonlinear numerical examples are\ntested to show the robustness and versatility of the multigrid algorithm. \n\n"}
{"id": "1805.00114", "contents": "Title: Algebraic dual polynomials for the equivalence of curl-curl problems Abstract: In this paper we will consider two curl-curl equation in two dimensions. One\ncurl-curl problem for a scalar quantity $F$ and one problem for a vector field\n$\\bf{E}$. For Dirichlet boundary conditions $\\bf{n} \\times \\bf{E} =$ $\n\\hat{E}_{\\dashv}$ on $\\bf{E}$ and Neumann boundary conditions $\\bf{n} \\times\n\\mbox{curl}$ $F=\\hat{E}_{\\dashv}$, we expect the solutions to satisfy\n$\\bf{E}=\\mbox{curl}$ $F$. When we use algebraic dual polynomial\nrepresentations, these identities continue to hold at the discrete level.\nEquivalence will be proved and illustrated with a computational example. \n\n"}
{"id": "1805.00193", "contents": "Title: Tie-decay networks in continuous time and eigenvector-based centralities Abstract: Network theory is a useful framework for studying interconnected systems of\ninteracting entities. Many networked systems evolve continuously in time, but\nmost existing methods for the analysis of time-dependent networks rely on\ndiscrete or discretized time. In this paper, we propose an approach for\nstudying networks that evolve in continuous time by distinguishing between\n\\emph{interactions}, which we model as discrete contacts, and \\emph{ties},\nwhich encode the strengths of relationships as functions of time. To illustrate\nour tie-decay network formalism, we adapt the well-known PageRank centrality\nscore to our tie-decay framework in a mathematically tractable and\ncomputationally efficient way. We apply this framework to a synthetic example\nand then use it to study a network of retweets during the 2012 National Health\nService controversy in the United Kingdom. Our work also provides guidance for\nsimilar generalizations of other tools from network theory to continuous-time\nnetworks with tie decay, including for applications to streaming data. \n\n"}
{"id": "1805.00335", "contents": "Title: On the augmented Biot-JKD equations with Pole-Residue representation of\n  the dynamic tortuosity Abstract: In this paper, we derive the augmented Biot-JKD equations, where the memory\nterms in the original Biot-JKD equations are dealt with by introducing\nauxiliary dependent variables. The evolution in time of these new variables are\ngoverned by ordinary differential equations whose coefficients can be\nrigorously computed from the JKD dynamic tortuosity function $T^D(\\omega)$ by\nutilizing its Stieltjes function representation derived in\n\\cite{ou2014on-reconstructi}, where an algorithm for computing the pole-residue\nrepresentation of the JKD tortuosity is also proposed. The two numerical\nschemes presented in the current work for computing the poles and residues\nrepresentation of $T^D(\\omega)$ improve the previous scheme in the sense that\nthey interpolate the function at infinite frequency and have much higher\naccuracy than the one proposed in \\cite{ou2014on-reconstructi}. \n\n"}
{"id": "1805.00711", "contents": "Title: Comparison analysis on two numerical methods for fractional diffusion\n  problems based on rational approximations of $t^{\\gamma}, \\ 0 \\le t \\le 1$ Abstract: We discuss, study, and compare experimentally three methods for solving the\nsystem of algebraic equations $\\mathbb{A}^\\alpha \\bf{u}=\\bf{f}$, $0< \\alpha\n<1$, where $\\mathbb{A}$ is a symmetric and positive definite matrix obtained\nfrom finite difference or finite element approximations of second order\nelliptic problems in $\\mathbb{R}^d$, $d=1,2,3$. The first method, introduced by\nHarizanov et.al, based on the best uniform rational approximation (BURA)\n$r_\\alpha(t)$ of $t^{1-\\alpha}$ for $0 \\le t \\le 1$, is used to get the\nrational approximation of $t^{-\\alpha}$ in the form $t^{-1}r_\\alpha(t)$. Here\nwe develop another method, denoted by R-BURA, that is based on the best\nrational approximation $r_{1-\\alpha}(t)$ of $t^\\alpha$ on the interval $[0,1]$\nand approximates $t^{-\\alpha}$ via $r^{-1}_{1-\\alpha}(t)$. The third method,\nintroduced and studied by Bonito and Pasciak, is based on an exponentially\nconvergent quadrature scheme for the Dundord-Taylor integral representation of\nthe fractional powers of elliptic operators. All three methods reduce the\nsolution of the system $\\mathbb{A}^\\alpha \\bf{u}=\\bf{f}$ to solving a number of\nequations of the type $(\\mathbb{A} +c\\mathbb{I})\\bf{u}= \\bf{f}$, $c \\ge 0$.\nComprehensive numerical experiments on model problems with $\\mathbb A$ obtained\nby approximation of elliptic equations in one and two spatial dimensions are\nused to compare the efficiency of these three algorithms depending on the\nfractional power $\\alpha$. The presented results prove the concept of the new\nR-BURA method, which performs well for $\\alpha$ close to $1$ in contrast to\nBURA, which performs well for $\\alpha $ close to $0$. As a result, we show\ntheoretically and experimentally, that they have mutually complementary\nadvantages. \n\n"}
{"id": "1805.00771", "contents": "Title: A mixed discontinuous-continuous Galerkin time discretisation for Biot's\n  system Abstract: We study higher-order space-time variational discretisations for modeling\ncomplex processes in porous media that include fluid and structure interactions\nwhich are of fundamental importance in many engineering fields with\napplications in subsurface processes, battery-design and biomechanics. For the\ndiscretisation in time we deploy discontinuous Galerkin dG(r) and continuous\nGalerkin cG(q) discretisation families. Moreover we introduce a new coupled\ndG(r)-cG(q) mixed time discretisation and show numerically the stability\nadvantages in the case of incompatible initial data under massively reduced\ncomputational costs. For the discretisation in space we use a mixed finite\nelement method for the flow problem to ensure local mass conservation and a\ncontinuous Galerkin method for the mechanics. We consider solving sequentially\nthe coupling of flow and mechanics with the fixed-stress iterative approach\nsuch that we can reuse our system solver and preconditioning technologies for\nthe arising block system matrices from higher-order in time discretisations.\nNumerical experiments show firstly the undeniable advantages of discontinuous\nGalerkin time discretisations dG(0) and dG(1) over the continuous Galerkin time\ndiscretisation cG(1) in the case of incompatible initial data, secondly the\nadvantages of the new coupled dG(1)-cG(1) in time approach in the case of\nincompatible initial data with massively reduced computational costs and better\naccuracy compared to the dG(1) time discretisation and thirdly the performance\nand efficiency differences of the dG(0), cG(1), dG(1) and the new dG(1)-cG(1)\nfixed-stress solver approaches for a sophisticated and physically relevant\nthree-dimensional numerical example. \n\n"}
{"id": "1805.01595", "contents": "Title: Uniform in time error estimates for fully discrete numerical schemes of\n  a data assimilation algorithm Abstract: We consider fully discrete numerical schemes for a downscaling data\nassimilation algorithm aimed at approximating the velocity field of the 2D\nNavier-Stokes equations corresponding to given coarse mesh observational\nmeasurements. The time discretization is done by considering semi- and\nfully-implicit Euler schemes, and the spatial discretization is based on a\nspectral Galerkin method. The two fully discrete algorithms are shown to be\nunconditionally stable, with respect to the size of the time step, number of\ntime steps and the number of Galerkin modes. Moreover, explicit, uniform in\ntime error estimates between the fully discrete solution and the reference\nsolution corresponding to the observational coarse mesh measurements are\nobtained, in both the $L^2$ and $H^1$ norms. Notably, the two-dimensional\nNavier-Stokes equations, subject to the no-slip Dirichlet or periodic boundary\nconditions, are used in this work as a paradigm. The complete analysis that is\npresented here can be extended to other two- and three-dimensional dissipative\nsystems under the assumption of global existence and uniqueness. \n\n"}
{"id": "1805.01812", "contents": "Title: Mass Conservative Reduced Order Modeling of a Free Boundary Osmotic Cell\n  Swelling Problem Abstract: We consider model order reduction for a free boundary problem of an osmotic\ncell that is parameterized by material parameters as well as the initial shape\nof the cell. Our approach is based on an Arbitrary-Lagrangian-Eulerian\ndescription of the model that is discretized by a mass-conservative finite\nelement scheme. Using reduced basis techniques and empirical interpolation, we\nconstruct a parameterized reduced order model in which the mass conservation\nproperty of the full-order model is exactly preserved. Numerical experiments\nare provided that highlight the performance of the resulting reduced order\nmodel. \n\n"}
{"id": "1805.02082", "contents": "Title: Discontinuous Galerkin Discretizations of the Boltzmann Equations in 2D:\n  semi-analytic time stepping and absorbing boundary layers Abstract: We present an efficient nodal discontinuous Galerkin method for approximating\nnearly incompressible flows using the Boltzmann equations. The equations are\ndiscretized with Hermite polynomials in velocity space yielding a first order\nconservation law. A stabilized unsplit perfectly matching layer (PML)\nformulation is introduced for the resulting nonlinear flow equations. The\nproposed PML equations exponentially absorb the difference between the\nnonlinear fluctuation and the prescribed mean flow. We introduce semi-analytic\ntime discretization methods to improve the time step restrictions in small\nrelaxation times. We also introduce a multirate semi-analytic Adams-Bashforth\nmethod which preserves efficiency in stiff regimes. Accuracy and performance of\nthe method are tested using distinct cases including isothermal vortex, flow\naround square cylinder, and wall mounted square cylinder test cases. \n\n"}
{"id": "1805.03255", "contents": "Title: A Fixed Mesh Method With Immersed Finite Elements for Solving Interface\n  Inverse Problems Abstract: We present a new fixed mesh algorithm for solving a class of interface\ninverse problems for the typical elliptic interface problems. These interface\ninverse problems are formulated as shape optimization prob- lems whose\nobjective functionals depend on the shape of the interface. Regardless of the\nlocation of the interface, both the governing partial differential equations\nand the objective functional are discretized optimally, with respect to the\ninvolved polynomial space, by an immersed finite element (IFE) method on a\nfixed mesh. Furthermore, the formula for the gradient of the descritized\nobjective function is de- rived within the IFE framework that can be computed\naccurately and efficiently through the discretized adjoint procedure. Features\nof this proposed IFE method based on a fixed mesh are demonstrated by its\napplications to three representative interface inverse problems: the interface\ninverse problem with an internal measurement on a sub-domain, a\nDirichlet-Neumann type inverse problem whose data is given on the boundary, and\na heat dissipation design problem. \n\n"}
{"id": "1805.04198", "contents": "Title: A Multiscale Domain Decomposition Algorithm For Boundary Value Problems\n  For Eikonal Equations Abstract: In this paper, we present a new multiscale domain decomposition algorithm for\ncomputing solutions of static Eikonal equations. The new method is an iterative\ntwo-scale method that uses a parareal-like update scheme in combination with\nstandard Eikonal solvers. The purpose of the two scales is to accelerate\nconvergence and maintain accuracy. We adapt a weighted version of the parareal\nmethod for stability, and the optimal weights are studied via a model problem.\nNumerical examples are given to demonstrate the method. \n\n"}
{"id": "1805.04283", "contents": "Title: Nitsche's method for unilateral contact problems Abstract: We derive optimal a priori and a posteriori error estimates for Nitsche's\nmethod applied to unilateral contact problems. Our analysis is based on the\ninterpretation of Nitsche's method as a stabilised finite element method for\nthe mixed Lagrange multiplier formulation of the contact problem wherein the\nLagrange multiplier has been eliminated elementwise. To simplify the\npresentation, we focus on the scalar Signorini problem and outline only the\nproofs of the main results since most of the auxiliary results can be traced to\nour previous works on the numerical approximation of variational inequalities.\nWe end the paper by presenting results of our numerical computations which\ncorroborate the efficiency and reliability of the a posteriori estimators. \n\n"}
{"id": "1805.07618", "contents": "Title: Convexification method for a coefficient inverse problem and its\n  performance for experimental backscatter data for buried targets Abstract: We present in this paper a novel numerical reconstruction method for solving\na 3D coefficient inverse problem with scattering data generated by a single\ndirection of the incident plane wave. This inverse problem is well-known to be\na highly nonlinear and ill-posed problem. Therefore, optimization-based\nreconstruction methods for solving this problem would typically suffer from the\nlocal-minima trapping and require strong a priori information of the solution.\nTo avoid these problems, in our numerical method, we aim to construct a cost\nfunctional with a globally strictly convex property, whose minimizer can\nprovide a good approximation for the exact solution of the inverse problem. The\nkey ingredients for the construction of such functional are an\nintegro-differential formulation of the inverse problem and a Carleman weight\nfunction. Under a (partial) finite difference approximation, the global strict\nconvexity is proven using the tool of Carleman estimates. The global\nconvergence of the gradient projection method to the exact solution is proven\nas well. We demonstrate the efficiency of our reconstruction method via a\nnumerical study of experimental backscatter data for buried objects. \n\n"}
{"id": "1805.07835", "contents": "Title: An ultraweak formulation of the Kirchhoff-Love plate bending model and\n  DPG approximation Abstract: We develop and analyze an ultraweak variational formulation for a variant of\nthe Kirchhoff-Love plate bending model. Based on this formulation, we introduce\na discretization of the discontinuous Petrov-Galerkin type with optimal test\nfunctions (DPG). We prove well-posedness of the ultraweak formulation and\nquasi-optimal convergence of the DPG scheme. The variational formulation and\nits analysis require tools that control traces and jumps in $H^2$ (standard\nSobolev space of scalar functions) and $H(\\mathrm{div\\,Div})$ (symmetric tensor\nfunctions with $L_2$-components whose twice iterated divergence is in $L_2$),\nand their dualities. These tools are developed in two and three spatial\ndimensions. One specific result concerns localized traces in a dense subspace\nof $H(\\mathrm{div\\,Div})$. They are essential to construct basis functions for\nan approximation of $H(\\mathrm{div\\,Div})$. To illustrate the theory we\nconstruct basis functions of the lowest order and perform numerical experiments\nfor a smooth and a singular model solution. They confirm the expected\nconvergence behavior of the DPG method both for uniform and adaptively refined\nmeshes. \n\n"}
{"id": "1805.07923", "contents": "Title: Multi-Level Spectral Deferred Corrections Scheme for the Shallow Water\n  Equations on the Rotating Sphere Abstract: Efficient time integration schemes are necessary to capture the complex\nprocesses involved in atmospheric flows over long periods of time. In this\nwork, we propose a high-order, implicit-explicit numerical scheme that combines\nMulti-Level Spectral Deferred Corrections (MLSDC) and the Spherical Harmonics\n(SH) transform to solve the wave-propagation problems arising from the\nshallow-water equations on the rotating sphere.\n  The iterative temporal integration is based on a sequence of corrections\ndistributed on coupled space-time levels to perform a significant portion of\nthe calculations on a coarse representation of the problem and hence to reduce\nthe time-to-solution while preserving accuracy. In our scheme, referred to as\nMLSDC-SH, the spatial discretization plays a key role in the efficiency of\nMLSDC, since the SH basis allows for consistent transfer functions between\nspace-time levels that preserve important physical properties of the solution.\n  We study the performance of the MLSDC-SH scheme with shallow-water test cases\ncommonly used in numerical atmospheric modeling. We use this suite of test\ncases, which gradually adds more complexity to the nonlinear system of\ngoverning partial differential equations, to perform a detailed analysis of the\nconvergence rate of MLSDC-SH upon refinement in time. We illustrate the good\nstability properties of MLSDC-SH and show that the proposed scheme achieves up\nto eighth-order accuracy in time. Finally, we study the conditions in which\nMLSDC-SH achieves its theoretical speedup, and we show that it can\nsignificantly reduce the computational cost compared to single-level Spectral\nDeferred Corrections (SDC). \n\n"}
{"id": "1805.07962", "contents": "Title: A Nonconvex Projection Method for Robust PCA Abstract: Robust principal component analysis (RPCA) is a well-studied problem with the\ngoal of decomposing a matrix into the sum of low-rank and sparse components. In\nthis paper, we propose a nonconvex feasibility reformulation of RPCA problem\nand apply an alternating projection method to solve it. To the best of our\nknowledge, we are the first to propose a method that solves RPCA problem\nwithout considering any objective function, convex relaxation, or surrogate\nconvex constraints. We demonstrate through extensive numerical experiments on a\nvariety of applications, including shadow removal, background estimation, face\ndetection, and galaxy evolution, that our approach matches and often\nsignificantly outperforms current state-of-the-art in various ways. \n\n"}
{"id": "1805.08278", "contents": "Title: The limit shape of convex hull peeling Abstract: We prove that the convex peeling of a random point set in dimension d\napproximates motion by the 1/(d + 1) power of Gaussian curvature. We use\nviscosity solution theory to interpret the limiting partial differential\nequation. We use the Martingale method to solve the cell problem associated to\nconvex peeling. Our proof follows the program of Armstrong-Cardaliaguet for\nhomogenization of geometric motions, but with completely different ingredients. \n\n"}
{"id": "1805.08863", "contents": "Title: Langevin Markov Chain Monte Carlo with stochastic gradients Abstract: Monte Carlo sampling techniques have broad applications in machine learning,\nBayesian posterior inference, and parameter estimation. Often the target\ndistribution takes the form of a product distribution over a dataset with a\nlarge number of entries. For sampling schemes utilizing gradient information it\nis cheaper for the derivative to be approximated using a random small subset of\nthe data, introducing extra noise into the system. We present a new\ndiscretization scheme for underdamped Langevin dynamics when utilizing a\nstochastic (noisy) gradient. This scheme is shown to bias computed averages to\nsecond order in the stepsize while giving exact results in the special case of\nsampling a Gaussian distribution with a normally distributed stochastic\ngradient. \n\n"}
{"id": "1805.08864", "contents": "Title: Fully discrete DPG methods for the Kirchhoff-Love plate bending model Abstract: We extend the analysis and discretization of the Kirchhoff-Love plate bending\nproblem from [T. F\\\"uhrer, N. Heuer, A.H. Niemi, An ultraweak formulation of\nthe Kirchhoff-Love plate bending model and DPG approximation, arXiv:1805.07835,\n2018] in two aspects. First, we present a well-posed formulation and\nquasi-optimal DPG discretization that includes the gradient of the deflection.\nSecond, we construct Fortin operators that prove the well-posedness and\nquasi-optimal convergence of lowest-order discrete schemes with approximated\ntest functions for both formulations. Our results apply to the case of\nnon-convex polygonal plates where shear forces can be less than $L_2$-regular.\nNumerical results illustrate expected convergence orders. \n\n"}
{"id": "1805.09106", "contents": "Title: Transformed rank-1 lattices for high-dimensional approximation Abstract: This paper describes an extension of Fourier approximation methods for\nmultivariate functions defined on the torus $\\mathbb{T}^d$ to functions in a\nweighted Hilbert space $L_{2}(\\mathbb{R}^d, \\omega)$ via a multivariate change\nof variables $\\psi:\\left(-\\frac{1}{2},\\frac{1}{2}\\right)^d\\to\\mathbb{R}^d$. We\nestablish sufficient conditions on $\\psi$ and $\\omega$ such that the\ncomposition of a function in such a weighted Hilbert space with $\\psi$ yields a\nfunction in the Sobolev space $H_{\\mathrm{mix}}^{m}(\\mathbb{T}^d)$ of functions\non the torus with mixed smoothness of natural order $m \\in \\mathbb{N}_{0}$. In\nthis approach we adapt algorithms for the evaluation and reconstruction of\nmultivariate trigonometric polynomials on the torus $\\mathbb{T}^d$ based on\nsingle and multiple reconstructing rank-$1$ lattices. Since in applications it\nmay be difficult to choose a related function space, we make use of dimension\nincremental construction methods for sparse frequency sets. Various numerical\ntests confirm obtained theoretical results for the transformed methods. \n\n"}
{"id": "1805.10782", "contents": "Title: Numerical method for the time-fractional porous medium equation Abstract: This papers deals with a construction and convergence analysis of a finite\ndifference scheme for solving time-fractional porous medium equation. The\ngoverning equation exhibits both nonlocal and nonlinear behaviour making the\nnumerical computations challenging. Our strategy is to reduce the problem into\na single one-dimensional Volterra integral equation for the self-similar\nsolution and then to apply the discretization. The main difficulty arises due\nto the non-Lipschitzian behaviour of the equation's nonlinearity. By the\nanalysis of the recurrence relation for the error we are able to prove that\nthere exists a family of finite difference methods that is convergent for a\nlarge subset of the parameter space. We illustrate our results with a concrete\nexample of a method based on the midpoint quadrature. \n\n"}
{"id": "1805.11309", "contents": "Title: Numerical methods for time-fractional evolution equations with nonsmooth\n  data: a concise overview Abstract: Over the past few decades, there has been substantial interest in evolution\nequations that involving a fractional-order derivative of order\n$\\alpha\\in(0,1)$ in time, due to their many successful applications in\nengineering, physics, biology and finance. Thus, it is of paramount importance\nto develop and to analyze efficient and accurate numerical methods for reliably\nsimulating such models, and the literature on the topic is vast and fast\ngrowing. The present paper gives a concise overview on numerical schemes for\nthe subdiffusion model with nonsmooth problem data, which are important for the\nnumerical analysis of many problems arising in optimal control, inverse\nproblems and stochastic analysis. We focus on the following aspects of the\nsubdiffusion model: regularity theory, Galerkin finite element discretization\nin space, time-stepping schemes (including convolution quadrature and L1 type\nschemes), and space-time variational formulations, and compare the results with\nthat for standard parabolic problems. Further, these aspects are showcased with\nillustrative numerical experiments and complemented with perspectives and\npointers to relevant literature. \n\n"}
{"id": "1805.12417", "contents": "Title: A Robust Iterative Scheme for Symmetric Indefinite Systems Abstract: We propose a two-level nested preconditioned iterative scheme for solving\nsparse linear systems of equations in which the coefficient matrix is symmetric\nand indefinite with relatively small number of negative eigenvalues. The\nproposed scheme consists of an outer Minimum Residual (MINRES) iteration,\npreconditioned by an inner Conjugate Gradient (CG) iteration in which CG can be\nfurther preconditioned. The robustness of the proposed scheme is illustrated by\nsolving indefinite linear systems that arise in the solution of quadratic\neigenvalue problems in the context of model reduction methods for finite\nelement models of disk brakes as well as on other problems that arise in a\nvariety of applications. \n\n"}
{"id": "1806.00309", "contents": "Title: Fast algorithm based on TT-M FE system for space fractional Allen-Cahn\n  equations with smooth and non-smooth solutions Abstract: In this article, a fast algorithm based on time two-mesh (TT-M) finite\nelement (FE) scheme, which aims at solving nonlinear problems quickly, is\nconsidered to numerically solve the nonlinear space fractional Allen-Cahn\nequations with smooth and non-smooth solutions. The implicit second-order\n$\\theta$ scheme containing both implicit Crank-Nicolson scheme and second-order\nbackward difference method is applied to time direction, a fast TT-M method is\nused to increase the speed of calculation, and the FE method is developed to\napproximate the spacial direction. The TT-M FE algorithm includes the following\nmain computing steps: firstly, a nonlinear implicit second-order $\\theta$ FE\nscheme on the time coarse mesh $\\tau_c$ is solved by a nonlinear iterative\nmethod; secondly, based on the chosen initial iterative value, a linearized FE\nsystem on time fine mesh $\\tau<\\tau_c$ is solved, where some useful coarse\nnumerical solutions are found by the Lagrange's interpolation formula. The\nanalysis for both stability and a priori error estimates are made in detail.\nFinally, three numerical examples with smooth and non-smooth solutions are\nprovided to illustrate the computational efficiency in solving nonlinear\npartial differential equations, from which it is easy to find that the\ncomputing time can be saved. \n\n"}
{"id": "1806.00477", "contents": "Title: Fractional Sensitivity Equation Method: Applications to Fractional Model\n  Construction Abstract: Fractional differential equations provide a tractable mathematical framework\nto describe anomalous behavior in complex physical systems, yet they introduce\nnew sensitive model parameters, i.e. derivative orders, in addition to model\ncoefficients. We formulate a sensitivity analysis of fractional models by\ndeveloping a fractional sensitivity equation method. We obtain the adjoint\nfractional sensitivity equations, in which we present a fractional operator\nassociated with logarithmic-power law kernel. We further construct a\ngradient-based optimization algorithm to compute an accurate parameter\nestimation in fractional model construction. We develop a fast, stable, and\nconvergent Petrov-Galerkin spectral method to numerically solve the coupled\nsystem of original fractional model and its corresponding adjoint fractional\nsensitivity equations. \n\n"}
{"id": "1806.00732", "contents": "Title: Data-driven identification of parametric partial differential equations Abstract: In this work we present a data-driven method for the discovery of parametric\npartial differential equations (PDEs), thus allowing one to disambiguate\nbetween the underlying evolution equations and their parametric dependencies.\nGroup sparsity is used to ensure parsimonious representations of observed\ndynamics in the form of a parametric PDE, while also allowing the coefficients\nto have arbitrary time series, or spatial dependence. This work builds on\nprevious methods for the identification of constant coefficient PDEs, expanding\nthe field to include a new class of equations which until now have eluded\nmachine learning based identification methods. We show that group sequentially\nthresholded ridge regression outperforms group LASSO in identifying the fewest\nterms in the PDE along with their parametric dependency. The method is\ndemonstrated on four canonical models with and without the introduction of\nnoise. \n\n"}
{"id": "1806.01575", "contents": "Title: Error boundedness of Correction Procedure via Reconstruction / Flux\n  Reconstruction Abstract: We study the long-time error behavior of correction procedure via\nreconstruction / flux reconstruction (CPR/FR) methods for linear hyperbolic\nconservation laws. We show that not only the choice of the numerical flux\n(upwind or central) affects the growth rate and asymptotic value of the error,\nbut that the selection of bases (Gau{\\ss}-Lobatto or Gau{\\ss}-Legendre) is even\nmore important. Using a Gau{\\ss}-Legendre basis, the error reaches the\nasymptotic value faster and to a lower value than when using a Gau{\\ss}-Lobatto\nbasis. Also, the differences in the error caused by the numerical flux are not\nessential for low resolution computations in the Gau{\\ss}-Legendre case. This\nbehavior is better seen on a particular FR scheme which has a strong connection\nwith the discontinuous Galerkin framework but holds also for other flux\nreconstruction schemes with low order resolution computations. \n\n"}
{"id": "1806.02204", "contents": "Title: Geometry and Singularities of Prony varieties Abstract: We start a systematic study of the topology, geometry and singularities of\nthe Prony varieties $S_q(\\mu)$, defined by the first $q+1$ equations of the\nclassical Prony system\n  $$\\sum_{j=1}^d a_j x_j^k = \\mu_k, \\ k= 0,1,\\ldots \\ .$$ Prony varieties,\nbeing a generalization of the Vandermonde varieties, introduced in [5,21],\npresent a significant independent mathematical interest (compare [5,19,21]).\nThe importance of Prony varieties in the study of the error amplification\npatterns in solving Prony system was shown in [1-4,19]. In [19] a survey of\nthese results was given, from the point of view of Singularity Theory.\n  In the present paper we show that for $q\\ge d$ the variety $S_q(\\mu)$ is\ndiffeomerphic to an intersection of a certain affine subspace in the space\n${\\cal V}_d$ of polynomials of degree $d$, with the hyperbolic set $H_d$.\n  On the Prony curves $S_{2d-2}$ we study the behavior of the amplitudes $a_j$\nas the nodes $x_j$ collide, and the nodes escape to infinity. We discuss the\nbehavior of the Prony varieties as the right hand side $\\mu$ varies, and\npossible connections of this problem with J. Mather's result in [23] on\nsmoothness of solutions in families of linear systems. \n\n"}
{"id": "1806.02482", "contents": "Title: On the self-similar solutions of the crystalline mean curvature flow in\n  three dimensions Abstract: We present two types of self-similar shrinking solutions of positive genus\nfor the crystalline mean curvature flow in three dimensions analogous to the\nsolutions known for the standard mean curvature flow. We use them to test a\nnumerical implementation of a level set algorithm for the crystalline mean\ncurvature flow in three dimensions based on the minimizing movements scheme of\nA.~Chambolle, \\textit{Interfaces Free Bound.~6}~(2004). We implement a finite\nelement method discretization that seems to improve the handling of edges in\nthree dimensions compared to the standard finite difference method and\nillustrate its behavior on a few examples. \n\n"}
{"id": "1806.03813", "contents": "Title: Spectrally-accurate numerical method for acoustic scattering from\n  doubly-periodic 3D multilayered media Abstract: A periodizing scheme and the method of fundamental solutions are used to\nsolve acoustic wave scattering from doubly-periodic three-dimensional\nmultilayered media. A scattered wave in a unit cell is represented by the sum\nof the near and distant contribution. The near contribution uses the free-space\nGreen's function and its eight immediate neighbors. The contribution from the\ndistant sources is expressed using proxy source points over a sphere\nsurrounding the unit cell and its neighbors. The Rayleigh-Bloch radiation\ncondition is applied to the top and bottom layers. Extra unknowns produced by\nthe periodizing scheme in the linear system are eliminated using a Schur\ncomplement. The proposed numerical method avoids using singular quadratures and\nthe quasi-periodic Green's function or complicated lattice sum techniques.\nTherefore, the proposed scheme is robust at all scattering parameters including\nWood anomalies. The algorithm is also applicable to electromagnetic problems by\nusing the dyadic Green's function. Numerical examples with 10-digit accuracy\nare provided. Finally, reflection and transmission spectra are computed over a\nwide range of incident angles for device characterization. \n\n"}
{"id": "1806.05832", "contents": "Title: Dynamic Data-driven Bayesian GMsFEM Abstract: In this paper, we propose a Bayesian approach for multiscale problems with\nthe availability of dynamic observational data. Our method selects important\ndegrees of freedom probabilistically in a Generalized multiscale finite element\nmethod framework. Due to scale disparity in many multiscale applications,\ncomputational models can not resolve all scales. Dominant modes in the\nGeneralized Multiscale Finite Element Method are used as \"permanent\" basis\nfunctions, which we use to compute an inexpensive multiscale solution and the\nassociated uncertainties. Through our Bayesian framework, we can model\napproximate solutions by selecting the unresolved scales probabilistically. We\nconsider parabolic equations in heterogeneous media. The temporal domain is\npartitioned into subintervals. Using residual information and given dynamic\ndata, we design appropriate prior distribution for modeling missing subgrid\ninformation. The likelihood is designed to minimize the residual in the\nunderlying PDE problem and the mismatch of observational data. Using the\nresultant posterior distribution, the sampling process identifies important\ndegrees of freedom beyond permanent basis functions. The method adds important\ndegrees of freedom in resolving subgrid information and ensuring the accuracy\nof the observations. \n\n"}
{"id": "1806.06317", "contents": "Title: Laplacian Smoothing Gradient Descent Abstract: We propose a class of very simple modifications of gradient descent and\nstochastic gradient descent. We show that when applied to a large variety of\nmachine learning problems, ranging from logistic regression to deep neural\nnets, the proposed surrogates can dramatically reduce the variance, allow to\ntake a larger step size, and improve the generalization accuracy. The methods\nonly involve multiplying the usual (stochastic) gradient by the inverse of a\npositive definitive matrix (which can be computed efficiently by FFT) with a\nlow condition number coming from a one-dimensional discrete Laplacian or its\nhigh order generalizations. It also preserves the mean and increases the\nsmallest component and decreases the largest component. The theory of\nHamilton-Jacobi partial differential equations demonstrates that the implicit\nversion of the new algorithm is almost the same as doing gradient descent on a\nnew function which (i) has the same global minima as the original function and\n(ii) is ``more convex\". Moreover, we show that optimization algorithms with\nthese surrogates converge uniformly in the discrete Sobolev $H_\\sigma^p$ sense\nand reduce the optimality gap for convex optimization problems. The code is\navailable at:\n\\url{https://github.com/BaoWangMath/LaplacianSmoothing-GradientDescent} \n\n"}
{"id": "1806.06787", "contents": "Title: An embedded SDG method for the convection-diffusion equation Abstract: In this paper, we present an embedded staggered discontinuous Galerkin method\nfor the convection-diffusion equation. The new method combines the advantages\nof staggered discontinuous Galerkin (SDG) and embedded discontinuous Galerkin\n(EDG) method, and results in many good properties, namely local and global\nconservations, free of carefully designed stabilization terms or flux\nconditions and high computational efficiency. In applying the new method to\nconvection-dominated problems, the method provides optimal convergence in\npotential and suboptimal convergence in flux, which is comparable to other\nexisting DG methods, and achieves $L^2$ stability by making use of a\nskew-symmetric discretization of the convection term, irrespective of\ndiffusivity. We will present numerical results to show the performance of the\nmethod. \n\n"}
{"id": "1806.07261", "contents": "Title: The tensor t-function: a definition for functions of third-order tensors Abstract: A definition for functions of multidimensional arrays is presented. The\ndefinition is valid for third-order tensors in the tensor t-product formalism,\nwhich regards third-order tensors as block circulant matrices. The tensor\nfunction definition is shown to have similar properties as standard matrix\nfunction definitions in fundamental scenarios. To demonstrate the definition's\npotential in applications, the notion of network communicability is generalized\nto third-order tensors and computed for a small-scale example via block Krylov\nsubspace methods for matrix functions. A complexity analysis for these methods\nin the context of tensors is also provided. \n\n"}
{"id": "1806.08262", "contents": "Title: Lower Lipschitz Bounds for Phase Retrieval from Locally Supported\n  Measurements Abstract: In this short note, we consider the worst case noise robustness of any phase\nretrieval algorithm which aims to reconstruct all nonvanishing vectors\n$\\mathbf{x} \\in \\mathbb{C}^d$ (up to a single global phase multiple) from the\nmagnitudes of an arbitrary collection of local correlation measurements.\nExamples of such measurements include both spectrogram measurements of\n$\\mathbf{x}$ using locally supported windows and masked Fourier transform\nintensity measurements of $\\mathbf{x}$ using bandlimited masks. As a result,\nthe robustness results considered herein apply to a wide range of both\nptychographic and Fourier ptychographic imaging scenarios. In particular, the\nmain results imply that the accurate recovery of high-resolution images of\nextremely large samples using highly localized probes is likely to require an\nextremely large number of measurements in order to be robust to worst case\nmeasurement noise, independent of the recovery algorithm employed. Furthermore,\nrecent pushes to achieve high-speed and high-resolution ptychographic imaging\nof integrated circuits for process verification and failure analysis will\nlikely need to carefully balance probe design (e.g., their effective\ntime-frequency support) against the total number of measurements acquired in\norder for their imaging techniques to be stable to measurement noise, no matter\nwhat reconstruction algorithms are applied. \n\n"}
{"id": "1806.08558", "contents": "Title: Evaluation of Adjoint Methods in Photoacoustic Tomography with\n  Under-Sampled Sensors Abstract: Photo-Acoustic Tomography (PAT) can reconstruct a distribution of optical\nabsorbers acting as instantaneous sound sources in subcutaneous\nmicrovasculature of a human breast. Adjoint methods for PAT, typically\nTime-Reversal (TR) and Back-Projection (BP), are ways to refocus time-reversed\nacoustic signals on sources by wave propagation from the position of sensors.\nTR and BP have different treatments for received signals, but they are\nequivalent under continuously sampling on a closed circular sensor array in two\ndimensions. Here, we analyze image quality with discrete under-sampled sensors\nin the sense of the Shannon sampling theorem. We investigate resolution and\ncontrast of TR and BP, respectively in one source-sensor pair configuration and\nthe frequency domain. With Hankel's asymptotic expansion to the integrands of\nimaging functions, our main contribution is to demonstrate that TR and BP have\nbetter performance on contrast and resolution, respectively. We also show that\nthe integrand of TR includes additional side lobes which degrade axial\nresolution whereas that of BP conversely has relatively small amplitudes.\nMoreover, omnidirectional resolution is improved if more sensors are employed\nto collect the received signals. Nevertheless, for the under-sampled sensors,\nwe propose the Truncated Back-Projection (TBP) method to enhance the contrast\nof BP using removing higher frequency components in the received signals. We\nconduct numerical experiments on the two-dimensional projected phantom model\nextracted from OA-Breast Database. The experiments verify our theories and show\nthat the proposed TBP possesses better omnidirectional resolution as well as\ncontrast compared with TR and BP with under-sampled sensors. \n\n"}
{"id": "1806.09054", "contents": "Title: Anisotropic Error Estimates of The Linear Nonconforming Virtual Element\n  Methods Abstract: A refined a priori error analysis of the lowest order (linear) nonconforming\nVirtual Element Method (VEM) for approximating a model Poisson problem is\ndeveloped in both 2D and 3D. A set of new geometric assumptions is proposed on\nshape regularity of polytopal meshes. A new error equation for the lowest order\n(linear) nonconforming VEM is derived for any choice of stabilization, and a\nnew stabilization using a projection on an extended element patch is introduced\nfor the error analysis on anisotropic elements. \n\n"}
{"id": "1806.09922", "contents": "Title: Adaptive SOR methods based on the Wolfe conditions Abstract: Because the expense of estimating the optimal value of the relaxation\nparameter in the successive over-relaxation (SOR) method is usually\nprohibitive, the parameter is often adaptively controlled. In this paper, new\nadaptive SOR methods are presented that are applicable to a variety of\nsymmetric positive definite linear systems and do not require additional\nmatrix-vector products when updating the parameter. To this end, we regard the\nSOR method as an algorithm for minimising a certain objective function, which\nyields an interpretation of the relaxation parameter as the step size following\na certain change of variables. This interpretation enables us to adaptively\ncontrol the step size based on some line search techniques, such as the Wolfe\nconditions. Numerical examples demonstrate the favourable behaviour of the\nproposed methods. \n\n"}
{"id": "1806.10371", "contents": "Title: Simulation and validation of surfactant-laden drops in two-dimensional\n  Stokes flow Abstract: Performing highly accurate simulations of droplet systems is a challenging\nproblem. This is primarily due to the interface dynamics which is complicated\nfurther by the addition of surfactants. This paper presents a boundary integral\nmethod for computing the evolution of surfactant-covered droplets in 2D Stokes\nflow. The method has spectral accuracy in space and the adaptive time-stepping\nscheme allows for control of the temporal errors. Previously available\nsemi-analytical solutions (based on conformal-mapping techniques) are extended\nto include surfactants, and a set of algorithms is introduced to detail their\nevaluation. These semi-analytical solutions are used to validate and assess the\naccuracy of the boundary integral method, and it is demonstrated that the\npresented method maintains its high accuracy even when droplets are in close\nproximity. \n\n"}
{"id": "1806.10544", "contents": "Title: Strong linearizations of rational matrices with polynomial part\n  expressed in an orthogonal basis Abstract: We construct a new family of strong linearizations of rational matrices\nconsidering the polynomial part of them expressed in a basis that satisfies a\nthree term recurrence relation. For this purpose, we combine the theory\ndeveloped by Amparan et al., MIMS EPrint 2016.51, and the new linearizations of\npolynomial matrices introduced by Fa{\\ss}bender and Saltenberger, Linear\nAlgebra Appl., 525 (2017). In addition, we present a detailed study of how to\nrecover eigenvectors of a rational matrix from those of its linearizations in\nthis family. We complete the paper by discussing how to extend the results when\nthe polynomial part is expressed in other bases, and by presenting strong\nlinearizations that preserve the structure of symmetric or Hermitian rational\nmatrices. A conclusion of this work is that the combination of the results in\nthis paper with those in Amparan et al., MIMS EPrint 2016.51, allows us to use\nessentially all the strong linearizations of polynomial matrices developed in\nthe last fifteen years to construct strong linearizations of any rational\nmatrix by expressing such matrix in terms of its polynomial and strictly proper\nparts. \n\n"}
{"id": "1806.11566", "contents": "Title: Analysis and preconditioning of parameter-robust finite element methods\n  for Biot's consolidation model Abstract: In this paper we consider a three-field formulation of the Biot model which\nhas the displacement, the total pressure, and the pore pressure as unknowns.\nFor parameter-robust stability analysis, we first show a priori estimates of\nthe continuous problem with parameter-dependent norms. Then we study finite\nelement discretizations which provide parameter-robust error estimates and\npreconditioners. For finite element discretizations we consider standard mixed\nfinite element as well as stabilized methods for the Stokes equations, and the\ncomplete error analysis of semidiscrete solutions is given. Abstract forms of\nparameter-robust preconditioners are investigated by the operator\npreconditioning approach. The theoretical results are illustrated with\nnumerical experiments. \n\n"}
{"id": "1807.00086", "contents": "Title: Hybridized discontinuous Galerkin methods for wave propagation Abstract: We present the recent development of hybridizable and embedded discontinuous\nGalerkin (DG) methods for wave propagation problems in fluids, solids, and\nelectromagnetism. In each of these areas, we describe the methods, discuss\ntheir main features, display numerical results to illustrate their performance,\nand conclude with bibliography notes. The main ingredients in devising these DG\nmethods are (i) a local Galerkin projection of the underlying partial\ndifferential equations at the element level onto spaces of polynomials of\ndegree k to parametrize the numerical solution in terms of the numerical trace;\n(ii) a judicious choice of the numerical flux to provide stability and\nconsistency; and (iii) a global jump condition that enforces the continuity of\nthe numerical flux to obtain a global system in terms of the numerical trace.\nThese DG methods are termed hybridized DG methods, because they are amenable to\nhybridization (static condensation) and hence to more efficient\nimplementations. They share many common advantages of DG methods and possess\nsome unique features that make them well-suited to wave propagation problems. \n\n"}
{"id": "1807.00261", "contents": "Title: On the Complexity Analysis of the Primal Solutions for the Accelerated\n  Randomized Dual Coordinate Ascent Abstract: Dual first-order methods are essential techniques for large-scale constrained\nconvex optimization. However, when recovering the primal solutions, we need\n$T(\\epsilon^{-2})$ iterations to achieve an $\\epsilon$-optimal primal solution\nwhen we apply an algorithm to the non-strongly convex dual problem with\n$T(\\epsilon^{-1})$ iterations to achieve an $\\epsilon$-optimal dual solution,\nwhere $T(x)$ can be $x$ or $\\sqrt{x}$. In this paper, we prove that the\niteration complexity of the primal solutions and dual solutions have the same\n$O\\left(\\frac{1}{\\sqrt{\\epsilon}}\\right)$ order of magnitude for the\naccelerated randomized dual coordinate ascent. When the dual function further\nsatisfies the quadratic functional growth condition, by restarting the\nalgorithm at any period, we establish the linear iteration complexity for both\nthe primal solutions and dual solutions even if the condition number is\nunknown. When applied to the regularized empirical risk minimization problem,\nwe prove the iteration complexity of $O\\left(n\\log\nn+\\sqrt{\\frac{n}{\\epsilon}}\\right)$ in both primal space and dual space, where\n$n$ is the number of samples. Our result takes out the $\\left(\\log\n\\frac{1}{\\epsilon}\\right)$ factor compared with the methods based on\nsmoothing/regularization or Catalyst reduction. As far as we know, this is the\nfirst time that the optimal $O\\left(\\sqrt{\\frac{n}{\\epsilon}}\\right)$ iteration\ncomplexity in the primal space is established for the dual coordinate ascent\nbased stochastic algorithms. We also establish the accelerated linear\ncomplexity for some problems with nonsmooth loss, i.e., the least absolute\ndeviation and SVM. \n\n"}
{"id": "1807.01212", "contents": "Title: Overcoming the curse of dimensionality in the numerical approximation of\n  semilinear parabolic partial differential equations Abstract: For a long time it is well-known that high-dimensional linear parabolic\npartial differential equations (PDEs) can be approximated by Monte Carlo\nmethods with a computational effort which grows polynomially both in the\ndimension and in the reciprocal of the prescribed accuracy. In other words,\nlinear PDEs do not suffer from the curse of dimensionality. For general\nsemilinear PDEs with Lipschitz coefficients, however, it remained an open\nquestion whether these suffer from the curse of dimensionality. In this paper\nwe partially solve this open problem. More precisely, we prove in the case of\nsemilinear heat equations with gradient-independent and globally Lipschitz\ncontinuous nonlinearities that the computational effort of a variant of the\nrecently introduced multilevel Picard approximations grows polynomially both in\nthe dimension and in the reciprocal of the required accuracy. \n\n"}
{"id": "1807.01261", "contents": "Title: On the Connection between Residual Distribution Schemes and Flux\n  Reconstruction Abstract: In this short paper, we are considering the connection between the\n\\emph{Residual Distribution Schemes} (RD) and the \\emph{Flux Reconstruction}\n(FR) approach. We demonstrate that flux reconstruction can be recast into the\nRD framework and vice versa. Because of this close connection we are able to\napply known results from RD schemes to FR methods. In this context we propose a\nfirst demonstration of entropy stability for the FR schemes under consideration\nand show how to construct entropy stable numerical schemes based on our FR\nmethods. Simultaneously, we do not restrict the mesh to tensor structures or\ntriangle elements, but rather allow polygons. The key of our analysis is a\nproper choice of the correction functions for which we present an approach\nhere. \n\n"}
{"id": "1807.02338", "contents": "Title: A quasi-conservative dynamical low-rank algorithm for the Vlasov\n  equation Abstract: Numerical methods that approximate the solution of the Vlasov-Poisson\nequation by a low-rank representation have been considered recently. These\nmethods can be extremely effective from a computational point of view, but\ncontrary to most Eulerian Vlasov solvers, they do not conserve mass and\nmomentum, neither globally nor in respecting the corresponding local\nconservation laws. This can be a significant limitation for intermediate and\nlong time integration. In this paper we propose a numerical algorithm that\novercomes some of these difficulties and demonstrate its utility by presenting\nnumerical simulations. \n\n"}
{"id": "1807.02341", "contents": "Title: Arbitrary order finite volume well-balanced schemes for the Euler\n  equations with gravity Abstract: This work presents arbitrary high order well balanced finite volume schemes\nfor the Euler equations with a prescribed gravitational field. It is assumed\nthat the desired equilibrium solution is known, and we construct a scheme which\nis exactly well balanced for that particular equilibrium. The scheme is based\non high order reconstructions of the fluctuations from equilibrium of density,\nmomentum and pressure, and on a well balanced integration of the source terms,\nwhile no assumptions are needed on the numerical flux, beside consistency. This\ntechnique allows to construct well balanced methods also for a class of moving\nequilibria. Several numerical tests demonstrate the performance of the scheme\non different scenarios, from equilibrium solutions to non steady problems\ninvolving shocks. The numerical tests are carried out with methods up to fifth\norder in one dimension, and third order accuracy in 2D. \n\n"}
{"id": "1807.02356", "contents": "Title: Hybrid Monte Carlo methods for sampling probability measures on\n  submanifolds Abstract: Probability measures supported on submanifolds can be sampled by adding an\nextra momentum variable to the state of the system, and discretizing the\nassociated Hamiltonian dynamics with some stochastic perturbation in the extra\nvariable. In order to avoid biases in the invariant probability measures\nsampled by discretizations of these stochastically perturbed Hamiltonian\ndynamics, a Metropolis rejection procedure can be considered. The so-obtained\nscheme belongs to the class of generalized Hybrid Monte Carlo (GHMC)\nalgorithms. We show here how to generalize to GHMC a procedure suggested by\nGoodman, Holmes-Cerfon and Zappa for Metropolis random walks on submanifolds,\nwhere a reverse projection check is performed to enforce the reversibility of\nthe algorithm for large timesteps and hence avoid biases in the invariant\nmeasure. We also provide a full mathematical analysis of such procedures, as\nwell as numerical experiments demonstrating the importance of the reverse\nprojection check on simple toy examples. \n\n"}
{"id": "1807.02718", "contents": "Title: High-order, Dispersionless \"Fast-Hybrid\" Wave Equation Solver. Part I:\n  $\\mathcal{O}(1)$ Sampling Cost via Incident-Field Windowing and Recentering Abstract: This paper proposes a frequency/time hybrid integral-equation method for the\ntime dependent wave equation in two and three-dimensional spatial domains.\nRelying on Fourier Transformation in time, the method utilizes a fixed\n(time-independent) number of frequency-domain integral-equation solutions to\nevaluate, with superalgebraically-small errors, time domain solutions for\narbitrarily long times. The approach relies on two main elements, namely, 1) A\nsmooth time-windowing methodology that enables accurate band-limited\nrepresentations for arbitrarily-long time signals, and 2) A novel Fourier\ntransform approach which, in a time-parallel manner and without causing\nspurious periodicity effects, delivers numerically dispersionless\nspectrally-accurate solutions. A similar hybrid technique can be obtained on\nthe basis of Laplace transforms instead of Fourier transforms, but we do not\nconsider the Laplace-based method in the present contribution. The algorithm\ncan handle dispersive media, it can tackle complex physical structures, it\nenables parallelization in time in a straightforward manner, and it allows for\ntime leaping---that is, solution sampling at any given time $T$ at\n$\\mathcal{O}(1)$-bounded sampling cost, for arbitrarily large values of $T$,\nand without requirement of evaluation of the solution at intermediate times.\nThe proposed frequency-time hybridization strategy, which generalizes to any\nlinear partial differential equation in the time domain for which\nfrequency-domain solutions can be obtained (including e.g. the time-domain\nMaxwell equations), and which is applicable in a wide range of scientific and\nengineering contexts, provides significant advantages over other available\nalternatives such as volumetric discretization, time-domain integral equations,\nand convolution-quadrature approaches. \n\n"}
{"id": "1807.03973", "contents": "Title: ReLU Deep Neural Networks and Linear Finite Elements Abstract: In this paper, we investigate the relationship between deep neural networks\n(DNN) with rectified linear unit (ReLU) function as the activation function and\ncontinuous piecewise linear (CPWL) functions, especially CPWL functions from\nthe simplicial linear finite element method (FEM). We first consider the\nspecial case of FEM. By exploring the DNN representation of its nodal basis\nfunctions, we present a ReLU DNN representation of CPWL in FEM. We\ntheoretically establish that at least $2$ hidden layers are needed in a ReLU\nDNN to represent any linear finite element functions in $\\Omega \\subseteq\n\\mathbb{R}^d$ when $d\\ge2$. Consequently, for $d=2,3$ which are often\nencountered in scientific and engineering computing, the minimal number of two\nhidden layers are necessary and sufficient for any CPWL function to be\nrepresented by a ReLU DNN. Then we include a detailed account on how a general\nCPWL in $\\mathbb R^d$ can be represented by a ReLU DNN with at most\n$\\lceil\\log_2(d+1)\\rceil$ hidden layers and we also give an estimation of the\nnumber of neurons in DNN that are needed in such a representation. Furthermore,\nusing the relationship between DNN and FEM, we theoretically argue that a\nspecial class of DNN models with low bit-width are still expected to have an\nadequate representation power in applications. Finally, as a proof of concept,\nwe present some numerical results for using ReLU DNNs to solve a two point\nboundary problem to demonstrate the potential of applying DNN for numerical\nsolution of partial differential equations. \n\n"}
{"id": "1807.05384", "contents": "Title: A Domain Decomposition Method for the Poisson-Boltzmann Solvation Models Abstract: In this paper, a domain decomposition method for the Poisson-Boltzmann (PB)\nsolvation model that is widely used in computational chemistry is proposed.\nThis method, called ddLPB for short, solves the linear Poisson-Boltzmann (LPB)\nequation defined in $\\mathbb R^3$ using the van der Waals cavity as the solute\ncavity. The Schwarz domain decomposition method is used to formulate local\nproblems by decomposing the cavity into overlapping balls and only solving a\nset of coupled sub-equations in balls. A series of numerical experiments is\npresented to test the robustness and the efficiency of this method including\nthe comparisons with some existing methods. We observe exponential convergence\nof the solvation energy with respect to the number of degrees of freedom which\nallows this method to reach the required level of accuracy when coupling with\nquantum mechanical descriptions of the solute. \n\n"}
{"id": "1807.05568", "contents": "Title: Adjoint shadowing directions in hyperbolic systems for sensitivity\n  analysis Abstract: For hyperbolic diffeomorphisms, we define adjoint shadowing directions as a\nbounded inhomogeneous adjoint solution whose initial condition has zero\ncomponent in the unstable adjoint direction. For hyperbolic flows, we define\nadjoint shadowing directions similarly, with the additional requirement that\nthe average of its inner-product with the trajectory direction is zero. In both\ncases, we show unique existence of adjoint shadowing directions, and how they\ncan be used for adjoint sensitivity analysis. Our work set a theoretical\nfoundation for efficient adjoint sensitivity methods for long-time-averaged\nobjectives such as NILSAS. \n\n"}
{"id": "1807.05793", "contents": "Title: Choice of the Parameters in A Primal-Dual Algorithm for Bregman Iterated\n  Variational Regularization Abstract: Focus of this work is solving a non-smooth constraint minimization problem by\na primal-dual splitting algorithm involving proximity operators. The problem is\npenalized by the Bregman divergence associated with the non-smooth total\nvariation (TV) functional.\n  We analyse two aspects: Firstly, the convergence of the regularized solution\nof the minimization problem to the minimum norm solution. Second, the\nconvergence of the iteratively regularized minimizer to the minimum norm\nsolution by a primal-dual algorithm. For both aspects, we use the assumption of\na variational source condition (VSC). This work emphasizes the impact of the\nchoice of the parameters in stabilization of a primal-dual algorithm. Rates of\nconvergence are obtained in terms of some concave, positive definite index\nfunction.\n  The algorithm is applied to a simple two dimensional image processing\nproblem. Sufficient error analysis profiles are provided based on the size of\nthe forward operator and the noise level in the measurement. \n\n"}
{"id": "1807.08924", "contents": "Title: Numerical approximation for non-colliding particle systems Abstract: We apply the semi-discrete method, c.f. \\emph{N. Halidias and I.S. Stamatiou\n(2016), On the numerical solution of some non-linear stochastic differential\nequations using the semi-discrete method, Computational Methods in Applied\nMathematics, 16(1)}, to a class of non-colliding particle systems. The proposed\nnumerical scheme preserves the non-colliding property and strongly converges to\nthe exact solution. \n\n"}
{"id": "1807.10955", "contents": "Title: Constraint Energy Minimizing Generalized Multiscale Finite Element\n  Method for dual continuum model Abstract: The dual continuum model serves as a powerful tool in the modeling of\nsubsurface applications. It allows a systematic coupling of various components\nof the solutions. The system is of multiscale nature as it involves high\nheterogeneous and high contrast coefficients. To numerically compute the\nsolutions, some types of reduced order methods are necessary. We will develop\nand analyze a novel multiscale method based on the recent advances in\nmultiscale finite element methods. Our method will compute multiple local\nmultiscale basis functions per coarse region. The idea is based on some local\nspectral problems, which are important to identify high contrast channels, and\nan energy minimization principle. Using these concepts, we show that the basis\nfunctions are localized, even in the presence of high contrast long channels\nand fractures. In addition, we show that the convergence of the method depends\nonly on the coarse mesh size. Finally, we present several numerical tests to\nshow the performance. \n\n"}
{"id": "1807.11802", "contents": "Title: Adaptive BEM with optimal convergence rates for the Helmholtz equation Abstract: We analyze an adaptive boundary element method for the weakly-singular and\nhypersingular integral equations for the 2D and 3D Helmholtz problem. The\nproposed adaptive algorithm is steered by a residual error estimator and does\nnot rely on any a priori information that the underlying meshes are\nsufficiently fine. We prove convergence of the error estimator with optimal\nalgebraic rates, independently of the (coarse) initial mesh. As a technical\ncontribution, we prove certain local inverse-type estimates for the boundary\nintegral operators associated with the Helmholtz equation. \n\n"}
{"id": "1807.11825", "contents": "Title: Second order finite volume scheme for Euler equations with gravity which\n  is well-balanced for general equations of state and grid systems Abstract: We develop a second order well-balanced finite volume scheme for compressible\nEuler equations with a gravitational source term. The well-balanced property\nholds for arbitrary hydrostatic solutions of the corresponding Euler equations\nwithout any restriction on the equation of state. The hydrostatic solution must\nbe known a priori either as an analytical formula or as a discrete solution at\nthe grid points. The scheme can be applied on curvilinear meshes and in\ncombination with any consistent numerical flux function and time stepping\nroutines. These properties are demonstrated on a range of numerical tests. \n\n"}
{"id": "1808.00584", "contents": "Title: Certified reduced basis methods for fractional Laplace equations via\n  extension Abstract: Fractional Laplace equations are becoming important tools for mathematical\nmodeling and prediction. Recent years have shown much progress in developing\naccurate and robust algorithms to numerically solve such problems, yet most\nsolvers for fractional problems are computationally expensive. Practitioners\nare often interested in choosing the fractional exponent of the mathematical\nmodel to match experimental and/or observational data; this requires the\ncomputational solution to the fractional equation for several values of the\nboth exponent and other parameters that enter the model, which is a\ncomputationally expensive many-query problem. To address this difficulty, we\npresent a model order reduction strategy for fractional Laplace problems\nutilizing the reduced basis method (RBM). Our RBM algorithm for this fractional\npartial differential equation (PDE) allows us to accomplish significant\nacceleration compared to a traditional PDE solver while maintaining accuracy.\nOur numerical results demonstrate this accuracy and efficiency of our RBM\nalgorithm on fractional Laplace problems in two spatial dimensions. \n\n"}
{"id": "1808.01470", "contents": "Title: A note about EC-$(s,t)$-weak tractability of multivariate approximation\n  with analytic Korobov kernels Abstract: This note is devoted to discussing multivariate approximation of continuous\nfunctions on $[0,1]^d$ with analytic Korobov kernels in the worst and average\ncase settings. We only consider algorithms that use finitely many evaluations\nof arbitrary continuous linear functionals. We study EC-$(s, t)$-weak\ntractability under the absolute or normalized error criterion, and obtain\nnecessary and sufficient conditions for $0<\\min(s,t)<1$ and $\\max(s,t)\\le 1$ in\nthe worst case setting and for $s,t>0$ in the average case setting. \n\n"}
{"id": "1808.01471", "contents": "Title: On energy dissipation theory and numerical stability for time-fractional\n  phase field equations Abstract: For the time-fractional phase field models, the corresponding energy\ndissipation law has not been settled on both the continuous level and the\ndiscrete level. In this work, we shall address this open issue. More precisely,\nwe prove for the first time that the time-fractional phase field models indeed\nadmit an energy dissipation law of an integral type. In the discrete level, we\npropose a class of finite difference schemes that can inherit the theoretical\nenergy stability. Our discussion covers the time-fractional gradient systems,\nincluding the time-fractional Allen-Cahn equation, the time-fractional\nCahn-Hilliard equation, and the time-fractional molecular beam epitaxy models.\nNumerical examples are presented to confirm the theoretical results. Moreover,\na numerical study of the coarsening rate of random initial states depending on\nthe fractional parameter $\\alpha$ reveals that there are several coarsening\nstages for both time-fractional Cahn-Hilliard equation and time-fractional\nmolecular beam epitaxy model, while there exists a $-\\alpha/3$ power law\ncoarsening stage. \n\n"}
{"id": "1808.02095", "contents": "Title: A Lanczos-Stieltjes method for one-dimensional ridge function\n  approximation and integration Abstract: Many of the input-parameter-to-output-quantity-of-interest maps that arise in\ncomputational science admit a surprising low-dimensional structure, where the\noutputs vary primarily along a handful of directions in the high-dimensional\ninput space. This type of structure is well modeled by a ridge function, which\nis a composition of a low-dimensional linear transformation with a nonlinear\nfunction. If the goal is to compute statistics of the output (e.g., as in\nuncertainty quantification or robust design) then one should exploit this\nlow-dimensional structure, when present, to accelerate computations. We develop\nGaussian quadrature and the associated polynomial approximation for\none-dimensional ridge functions. The key elements of our method are (i)\napproximating the univariate density of the given linear combination of inputs\nby repeated convolutions and (ii) a Lanczos-Stieltjes method for constructing\northogonal polynomials and Gaussian quadrature. \n\n"}
{"id": "1808.02376", "contents": "Title: A multiscale neural network based on hierarchical nested bases Abstract: In recent years, deep learning has led to impressive results in many fields.\nIn this paper, we introduce a multi-scale artificial neural network for\nhigh-dimensional non-linear maps based on the idea of hierarchical nested bases\nin the fast multipole method and the $\\mathcal{H}^2$-matrices. This approach\nallows us to efficiently approximate discretized nonlinear maps arising from\npartial differential equations or integral equations. It also naturally extends\nour recent work based on the generalization of hierarchical matrices [Fan et\nal. arXiv:1807.01883] but with a reduced number of parameters. In particular,\nthe number of parameters of the neural network grows linearly with the\ndimension of the parameter space of the discretized PDE. We demonstrate the\nproperties of the architecture by approximating the solution maps of non-linear\nSchr{\\\"o}dinger equation, the radiative transfer equation, and the Kohn-Sham\nmap. \n\n"}
{"id": "1808.03021", "contents": "Title: Gradient Dynamic Approach to the Tensor Complementarity Problem Abstract: Nonlinear gradient dynamic approach for solving the tensor complementarity\nproblem (TCP) is presented. Theoretical analysis shows that each of the defined\ndynamical system models ensures the convergence performance. The computer\nsimulation results further substantiate that the considered dynamical system\ncan solve the tensor complementarity problem (TCP). \n\n"}
{"id": "1808.03374", "contents": "Title: Fast computation of the principal components of genotype matrices in\n  Julia Abstract: Finding the largest few principal components of a matrix of genetic data is a\ncommon task in genome-wide association studies (GWASs), both for dimensionality\nreduction and for identifying unwanted factors of variation. We describe a\nsimple random matrix model for matrices that arise in GWASs, showing that the\nsingular values have a bulk behavior that obeys a Marchenko-Pastur distributed\nwith a handful of large outliers. We also implement Golub-Kahan-Lanczos (GKL)\nbidiagonalization in the Julia programming language, providing thick restarting\nand a choice between full and partial reorthogonalization strategies to control\nnumerical roundoff. Our implementation of GKL bidiagonalization is up to 36\ntimes faster than software tools used commonly in genomics data analysis for\ncomputing principal components, such as EIGENSOFT and FlashPCA, which use dense\nLAPACK routines and randomized subspace iteration respectively. \n\n"}
{"id": "1808.03567", "contents": "Title: Robust adaptive hp discontinuous Galerkin finite element methods for the\n  Helmholtz equation Abstract: This paper presents an $hp$ a posteriori error analysis for the 2D Helmholtz\nequation that is robust in the polynomial degree $p$ and the wave number $k$.\nFor the discretization, we consider a discontinuous Galerkin formulation that\nis unconditionally well posed. The a posteriori error analysis is based on the\ntechnique of equilibrated fluxes applied to a shifted Poisson problem, with the\nerror due to the nonconformity of the discretization controlled by a potential\nreconstruction. We prove that the error estimator is both reliable and\nefficient, under the condition that the initial mesh size and polynomial degree\nis chosen such that the discontinuous Galerkin formulation converges, i.e., it\nis out of the regime of pollution. We confirm the efficiency of an\n$hp$-adaptive refinement strategy based on the presented robust a posteriori\nerror estimator via several numerical examples. \n\n"}
{"id": "1808.03606", "contents": "Title: Moving Frames and Noether's Finite Difference Conservation Laws II Abstract: In this second part of the paper, we consider finite difference Lagrangians\nwhich are invariant under linear and projective actions of $SL(2)$, and the\nlinear equi-affine action which preserves area in the plane.\n  We first find the generating invariants, and then use the results of the\nfirst part of the paper to write the Euler--Lagrange difference equations and\nNoether's difference conservation laws for any invariant Lagrangian, in terms\nof the invariants and a difference moving frame. We then give the details of\nthe final integration step, assuming the Euler Lagrange equations have been\nsolved for the invariants. This last step relies on understanding the Adjoint\naction of the Lie group on its Lie algebra. We also use methods to integrate\nLie group invariant difference equations developed in Part I.\n  Effectively, for all three actions, we show that solutions to the\nEuler--Lagrange equations, in terms of the original dependent variables, share\na common structure for the whole set of Lagrangians invariant under each given\ngroup action, once the invariants are known as functions on the lattice. \n\n"}
{"id": "1808.03788", "contents": "Title: Efficient implementation of ADER discontinuous Galerkin schemes for a\n  scalable hyperbolic PDE engine Abstract: In this paper we discuss a new and very efficient implementation of high\norder accurate ADER discontinuous Galerkin (ADER-DG) finite element schemes on\nmodern massively parallel supercomputers. The numerical methods apply to a very\nbroad class of nonlinear systems of hyperbolic partial differential equations.\nADER-DG schemes are by construction communication avoiding and cache blocking\nand are furthermore very well-suited for vectorization, so that they appear to\nbe a good candidate for the future generation of exascale supercomputers. We\nintroduce the numerical algorithm and show some applications to a set of\nhyperbolic equations with increasing level of complexity, ranging from the\ncompressible Euler equations over the equations of linear elasticity and the\nunified Godunov-Peshkov-Romenski (GPR) model of continuum mechanics to general\nrelativistic magnetohydrodynamics (GRMHD) and the Einstein field equations of\ngeneral relativity. We present strong scaling results of the new ADER-DG\nschemes up to 180,000 CPU cores. To our knowledge, these are the largest runs\never carried out with high order ADER-DG schemes for nonlinear hyperbolic PDE\nsystems. We also provide a detailed performance comparison with traditional\nRunge-Kutta DG schemes. \n\n"}
{"id": "1808.04542", "contents": "Title: The Discrete-Dual Minimal-Residual Method (DDMRes) for Weak\n  Advection-Reaction Problems in Banach spaces Abstract: We propose and analyse a minimal-residual method in discrete dual norms for\napproximating the solution of the advection-reaction equation in a weak\nBanach-space setting. The weak formulation allows for the direct approximation\nof solutions in the Lebesgue $L^p$-space, $1<p<\\infty$. The greater generality\nof this weak setting is natural when dealing with rough data and highly\nirregular solutions, and when enhanced qualitative features of the\napproximations are needed.\n  We first present a rigorous analysis of the well-posedness of the underlying\ncontinuous weak formulation, under natural assumptions on the\nadvection-reaction coefficients. The main contribution is the study of several\ndiscrete subspace pairs guaranteeing the discrete stability of the method and\nquasi-optimality in $L^p$, and providing numerical illustrations of these\nfindings, including the elimination of Gibbs phenomena, computation of optimal\ntest spaces, and application to 2-D advection. \n\n"}
{"id": "1808.04801", "contents": "Title: Seismic Imaging and Optimal Transport Abstract: Seismology has been an active science for a long time. It changed character\nabout 50 years ago when the earth's vibrations could be measured on the surface\nmore accurately and more frequently in space and time. The full wave field\ncould be determined, and partial differential equations (PDE) started to be\nused in the inverse process of finding properties of the interior of the earth.\nWe will briefly review earlier techniques but mainly focus on Full Waveform\nInversion (FWI) for the acoustic formulation. FWI is a PDE constrained\noptimization in which the variable velocity in a forward wave equation is\nadjusted such that the solution matches measured data on the surface. The\nminimization of the mismatch is usually coupled with the adjoint state method,\nwhich also includes the solution to an adjoint wave equation. The least-squares\nnorm is the conventional objective function measuring the difference between\nsimulated and measured data, but it often results in the minimization trapped\nin local minima. One way to mitigate this is by selecting another misfit\nfunction with better convexity properties. Here we propose using the quadratic\nWasserstein metric as a new misfit function in FWI. The optimal map defining\nthe quadratic Wasserstein metric can be computed by solving a Monge-Ampere\nequation. Theorems pointing to the advantages of using optimal transport over\nthe least-squares norm will be discussed, and a number of large-scale\ncomputational examples will be presented. \n\n"}
{"id": "1808.05311", "contents": "Title: Semi-analytical solution of a McKean-Vlasov equation with feedback\n  through hitting a boundary Abstract: In this paper, we study the non-linear diffusion equation associated with a\nparticle system where the common drift depends on the rate of absorption of\nparticles at a boundary. We provide an interpretation as a structural credit\nrisk model with default contagion in a large interconnected banking system.\nUsing the method of heat potentials, we derive a coupled system of Volterra\nintegral equations for the transition density and for the loss through\nabsorption. An approximation by expansion is given for a small interaction\nparameter. We also present a numerical solution algorithm and conduct\ncomputational tests. \n\n"}
{"id": "1808.05472", "contents": "Title: An Efficient Steady-State Solver for Microflows with High-Order Moment\n  Model Abstract: In [Z. Hu, R. Li, and Z. Qiao. Acceleration for microflow simulations of\nhigh-order moment models by using lower-order model correction. J. Comput.\nPhys., 327:225-244, 2016], it has been successfully demonstrated that using\nlower-order moment model correction is a promising idea to accelerate the\nsteady-state computation of high-order moment models of the Boltzmann equation.\nTo develop the existing solver, the following aspects are studied in this\npaper. First, the finite volume method with linear reconstruction is employed\nfor high-resolution spatial discretization so that the degrees of freedom in\nspatial space could be reduced remarkably without loss of accuracy. Second, by\nintroducing an appropriate parameter $\\tau$ in the correction step, it is found\nthat the performance of the solver can be improved significantly, i.e., more\nlevels would be involved in the solver, which further accelerates the\nconvergence of the method. Third, Heun's method is employed as the smoother in\neach level to enhance the robustness of the solver. Numerical experiments in\nmicroflows are carried out to demonstrate the efficiency and to investigate the\nbehavior of the new solver. In addition, several order reduction strategies for\nthe choice of the order sequence of the solver are tested, and the strategy\n$m_{l-1} = \\lceil m_{l} / 2 \\rceil$ is found to be most efficient. \n\n"}
{"id": "1808.08163", "contents": "Title: The entropy of the Angenent torus is approximately 1.85122 Abstract: To study the singularities that appear in mean curvature flow, one must\nunderstand self-shrinkers, surfaces that shrink by dilations under mean\ncurvature flow. The simplest examples of self-shrinkers are spheres and\ncylinders. In 1989, Angenent constructed the first nontrivial example of a\nself-shrinker, a torus. A key quantity in the study of the formation of\nsingularities is the entropy, defined by Colding and Minicozzi based on work of\nHuisken. The values of the entropy of spheres and cylinders have explicit\nformulas, but there is no known formula for the entropy of the Angenent torus.\nIn this work, we numerically estimate the entropy of the Angenent torus using\nthe discrete Euler-Lagrange equations. \n\n"}
{"id": "1808.08290", "contents": "Title: Generalized exponential basis for efficient solving of homogeneous\n  diffusion free boundary problems: Russian option pricing Abstract: This paper develops a method for solving free boundary problems for\ntime-homogeneous diffusions. We combine the complete exponential system of\nsolutions for the heat equation, transmutation operators and recently\ndiscovered Neumann series of Bessel functions representation for solutions of\nSturm-Liouville equations to construct a complete system of solutions for the\nconsidered partial differential equations. The conceptual algorithm for the\napplication of the method is presented. The valuation of Russian options with\nfinite horizon is used as a numerical illustration. The solution under\ndifferent horizons is computed and compared to the results that appear in the\nliterature. \n\n"}
{"id": "1808.08667", "contents": "Title: A Simplified Weak Galerkin Finite Element Method: Algorithm and Error\n  Estimates Abstract: In this article a simplified weak Galerkin finite element method is developed\nfor the Dirichlet boundary value problem of convection-diffusion-reaction\nequations. The simplified weak Galerkin method utilizes only the degrees of\nfreedom on the boundary of each element and, hence, has significantly reduced\ncomputational complexity over the regular weak Galerkin finite element method.\nA stability and some optimal order error estimates in the $H^1$ and $L^2$ norms\nare established for the corresponding numerical solutions. Numerical results\nare presented to verify the theory error estimates and a superconvergence\nphenomena on rectangular partitions. \n\n"}
{"id": "1808.10580", "contents": "Title: GPU-Accelerated Particle Methods for Evaluation of Sparse Observations\n  for PDE-Constrained Inverse Problems Abstract: We consider the inverse problem of estimating parameters of a driven\ndiffusion (e.g., the underlying fluid flow, diffusion coefficient, or source\nterms) from point measurements of a passive scalar (e.g., the concentration of\na pollutant). We present two particle methods that leverage the structure of\nthe inverse problem to enable efficient computation of the forward map, one for\ntime evolution problems and one for a Dirichlet boundary-value problem. The\nmethods scale in a natural fashion to modern computational architectures,\nenabling substantial speedup for applications involving sparse observations and\nhigh-dimensional unknowns. Numerical examples of applications to Bayesian\ninference and numerical optimization are provided. \n\n"}
{"id": "1808.10711", "contents": "Title: On high-order pressure-robust space discretisations, their advantages\n  for incompressible high Reynolds number generalised Beltrami flows and beyond Abstract: An improved understanding of the divergence-free constraint for the\nincompressible Navier--Stokes equations leads to the observation that a\nsemi-norm and corresponding equivalence classes of forces are fundamental for\ntheir nonlinear dynamics. The recent concept of {\\em pressure-robustness}\nallows to distinguish between space discretisations that discretise these\nequivalence classes appropriately or not. This contribution compares the\naccuracy of pressure-robust and non-pressure-robust space discretisations for\ntransient high Reynolds number flows, starting from the observation that in\ngeneralised Beltrami flows the nonlinear convection term is balanced by a\nstrong pressure gradient. Then, pressure-robust methods are shown to outperform\ncomparable non-pressure-robust space discretisations. Indeed, pressure-robust\nmethods of formal order $k$ are comparably accurate than non-pressure-robust\nmethods of formal order $2k$ on coarse meshes. Investigating the material\nderivative of incompressible Euler flows, it is conjectured that strong\npressure gradients are typical for non-trivial high Reynolds number flows.\nConnections to vortex-dominated flows are established. Thus,\npressure-robustness appears to be a prerequisite for accurate incompressible\nflow solvers at high Reynolds numbers. The arguments are supported by numerical\nanalysis and numerical experiments. \n\n"}
{"id": "1809.01588", "contents": "Title: Learning Paths from Signature Tensors Abstract: Matrix congruence extends naturally to the setting of tensors. We apply\nmethods from tensor decomposition, algebraic geometry and numerical\noptimization to this group action. Given a tensor in the orbit of another\ntensor, we compute a matrix which transforms one to the other. Our primary\napplication is an inverse problem from stochastic analysis: the recovery of\npaths from their third order signature tensors. We establish identifiability\nresults, both exact and numerical, for piecewise linear paths, polynomial\npaths, and generic dictionaries. Numerical optimization is applied for recovery\nfrom inexact data. We also compute the shortest path with a given signature\ntensor. \n\n"}
{"id": "1809.01937", "contents": "Title: Strong convergence for explicit space-time discrete numerical\n  approximation for 2D stochastic Navier-Stokes equations Abstract: In this paper we show the strong convergence of a fully explicit space-time\ndiscrete approximation scheme for the solution process of the two-dimensional\nincompressible stochastic Navier-Stokes equations on the torus driven by\nadditive noise. To do so we apply an existing result which was designed to\nprove strong convergence for the same approximation method for other stochastic\npartial differential equations with non-globally monotone non-linearities. \n\n"}
{"id": "1809.02362", "contents": "Title: A proof that artificial neural networks overcome the curse of\n  dimensionality in the numerical approximation of Black-Scholes partial\n  differential equations Abstract: Artificial neural networks (ANNs) have very successfully been used in\nnumerical simulations for a series of computational problems ranging from image\nclassification/image recognition, speech recognition, time series analysis,\ngame intelligence, and computational advertising to numerical approximations of\npartial differential equations (PDEs). Such numerical simulations suggest that\nANNs have the capacity to very efficiently approximate high-dimensional\nfunctions and, especially, indicate that ANNs seem to admit the fundamental\npower to overcome the curse of dimensionality when approximating the\nhigh-dimensional functions appearing in the above named computational problems.\nThere are a series of rigorous mathematical approximation results for ANNs in\nthe scientific literature. Some of them prove convergence without convergence\nrates and some even rigorously establish convergence rates but there are only a\nfew special cases where mathematical results can rigorously explain the\nempirical success of ANNs when approximating high-dimensional functions. The\nkey contribution of this article is to disclose that ANNs can efficiently\napproximate high-dimensional functions in the case of numerical approximations\nof Black-Scholes PDEs. More precisely, this work reveals that the number of\nrequired parameters of an ANN to approximate the solution of the Black-Scholes\nPDE grows at most polynomially in both the reciprocal of the prescribed\napproximation accuracy $\\varepsilon > 0$ and the PDE dimension $d \\in\n\\mathbb{N}$. We thereby prove, for the first time, that ANNs do indeed overcome\nthe curse of dimensionality in the numerical approximation of Black-Scholes\nPDEs. \n\n"}
{"id": "1809.03062", "contents": "Title: Analysis of the Generalization Error: Empirical Risk Minimization over\n  Deep Artificial Neural Networks Overcomes the Curse of Dimensionality in the\n  Numerical Approximation of Black-Scholes Partial Differential Equations Abstract: The development of new classification and regression algorithms based on\nempirical risk minimization (ERM) over deep neural network hypothesis classes,\ncoined deep learning, revolutionized the area of artificial intelligence,\nmachine learning, and data analysis. In particular, these methods have been\napplied to the numerical solution of high-dimensional partial differential\nequations with great success. Recent simulations indicate that deep\nlearning-based algorithms are capable of overcoming the curse of dimensionality\nfor the numerical solution of Kolmogorov equations, which are widely used in\nmodels from engineering, finance, and the natural sciences. The present paper\nconsiders under which conditions ERM over a deep neural network hypothesis\nclass approximates the solution of a $d$-dimensional Kolmogorov equation with\naffine drift and diffusion coefficients and typical initial values arising from\nproblems in computational finance up to error $\\varepsilon$. We establish that,\nwith high probability over draws of training samples, such an approximation can\nbe achieved with both the size of the hypothesis class and the number of\ntraining samples scaling only polynomially in $d$ and $\\varepsilon^{-1}$. It\ncan be concluded that ERM over deep neural network hypothesis classes overcomes\nthe curse of dimensionality for the numerical solution of linear Kolmogorov\nequations with affine coefficients. \n\n"}
{"id": "1809.03369", "contents": "Title: Computable upper error bounds for Krylov approximations to matrix\n  exponentials and associated $\\varphi$-functions Abstract: An a posteriori estimate for the error of a standard Krylov approximation to\nthe matrix exponential is derived. The estimate is based on the defect\n(residual) of the Krylov approximation and is proven to constitute a rigorous\nupper bound on the error, in contrast to existing asymptotical approximations.\nIt can be computed economically in the underlying Krylov space. In view of\ntime-stepping applications, assuming that the given matrix is scaled by a time\nstep, it is shown that the bound is asymptotically correct (with an order\nrelated to the dimension of the Krylov space) for the time step tending to\nzero. This means that the deviation of the error estimate from the true error\ntends to zero faster than the error itself. Furthermore, this result is\nextended to Krylov approximations of $\\varphi$-functions and to improved\nversions of such approximations. The accuracy of the derived bounds is\ndemonstrated by examples and compared with different variants known from the\nliterature, which are also investigated more closely. Alternative error bounds\nare tested on examples, in particular a version based on the concept of\neffective order. For the case where the matrix exponential is used in time\nintegration algorithms, a step size selection strategy is proposed and\nillustrated by experiments. \n\n"}
{"id": "1809.05487", "contents": "Title: A Second Order Fully-discrete Linear Energy Stable Scheme for a Binary\n  Compressible Viscous Fluid Model Abstract: We present a linear, second order fully discrete numerical scheme on a\nstaggered grid for a thermodynamically consistent hydrodynamic phase field\nmodel of binary compressible fluid flow mixtures derived from the generalized\nOnsager Principle. The hydrodynamic model not only possesses the variational\nstructure, but also warrants the mass, linear momentum conservation as well as\nenergy dissipation. We first reformulate the model in an equivalent form using\nthe energy quadratization method and then discretize the reformulated model to\nobtain a semi-discrete partial differential equation system using the\nCrank-Nicolson method in time. The numerical scheme so derived preserves the\nmass conservation and energy dissipation law at the semi-discrete level. Then,\nwe discretize the semi-discrete PDE system on a staggered grid in space to\narrive at a fully discrete scheme using the 2nd order finite difference method,\nwhich respects a discrete energy dissipation law. We prove the unique\nsolvability of the linear system resulting from the fully discrete scheme. Mesh\nrefinements and two numerical examples on phase separation due to the spinodal\ndecomposition in two polymeric fluids and interface evolution in the gas-liquid\nmixture are presented to show the convergence property and the usefulness of\nthe new scheme in applications. \n\n"}
{"id": "1809.05567", "contents": "Title: Multifidelity Dimension Reduction via Active Subspaces Abstract: We propose a multifidelity dimension reduction method to identify a\nlow-dimensional structure present in many engineering models. The structure of\ninterest arises when functions vary primarily on a low-dimensional subspace of\nthe high-dimensional input space, while varying little along the complementary\ndirections. Our approach builds on the gradient-based methodology of active\nsubspaces, and exploits models of different fidelities to reduce the cost of\nperforming dimension reduction through the computation of the active subspace\nmatrix. We provide a non-asymptotic analysis of the number of gradient\nevaluations sufficient to achieve a prescribed error in the active subspace\nmatrix, both in expectation and with high probability. We show that the sample\ncomplexity depends on a notion of intrinsic dimension of the problem, which can\nbe much smaller than the dimension of the input space. We illustrate the\nbenefits of such a multifidelity dimension reduction approach using numerical\nexperiments with input spaces of up to three thousand dimensions. \n\n"}
{"id": "1809.05634", "contents": "Title: Sweeping preconditioners for the iterative solution of quasiperiodic\n  Helmholtz transmission problems in layered media Abstract: We present a sweeping preconditioner for quasi-optimal Domain Decomposition\nMethods (DDM) applied to Helmholtz transmission problems in periodic layered\nmedia. Quasi-optimal DD (QO DD) for Helmholtz equations rely on transmission\noperators that are approximations of Dirichlet-to-Neumann (DtN) operators.\nEmploying shape perturbation series, we construct approximations of DtN\noperators corresponding to periodic domains, which we then use as transmission\noperators in a non-overlapping DD framework. The Robin-to-Robin (RtR) operators\nthat are the building blocks of DDM are expressed via robust boundary integral\nequation formulations. We use Nystr\\\"om discretizations of quasi-periodic\nboundary integral operators to construct high-order approximations of RtR.\nBased on the premise that the quasi-optimal transmission operators should act\nlike perfect transparent boundary conditions, we construct an approximate LU\nfactorization of the tridiagonal QO DD matrix associated with periodic layered\nmedia, which is then used as a double sweep preconditioner. We present a\nvariety of numerical results that showcase the effectiveness of the sweeping\npreconditioners applied to QO DD for the iterative solution of Helmholtz\ntransmission problems in periodic layered media. \n\n"}
{"id": "1809.05643", "contents": "Title: Kernel-based collocation methods for Heath-Jarrow-Morton models with\n  Musiela parametrization Abstract: We propose kernel-based collocation methods for numerical solutions to\nHeath-Jarrow-Morton models with Musiela parametrization. The methods can be\nseen as the Euler-Maruyama approximation of some finite dimensional stochastic\ndifferential equations, and allow us to compute the derivative prices by the\nusual Monte Carlo methods. We derive a bound on the rate of convergence under\nsome decay condition on the inverse of the interpolation matrix and some\nregularity conditions on the volatility functionals. \n\n"}
{"id": "1809.06558", "contents": "Title: Implicit LES with high-order H(div)-conforming FEM for incompressible\n  Navier-Stokes flows Abstract: Consider the transient incompressible Navier-Stokes flow at high Reynolds\nnumbers. A high-order H(div)-conforming FEM with pointwise divergence-free dis-\ncrete velocities is applied to implicit large-eddy-simulation in two limit\ncases: i) decaying turbulence in periodic domains, ii) wall bounded channel\nflow. \n\n"}
{"id": "1809.06926", "contents": "Title: Call for participation: Verification benchmarks for single-phase flow in\n  three-dimensional fractured porous media Abstract: This call for participation proposes four benchmark tests to verify and\ncompare numerical schemes to solve single-phase flow in fractured porous media.\nWith this, the two-dimensional suite of benchmark tests presented by Flemisch\net al. 2018 is extended to include three-dimensional problems. Moreover,\ntransport simulations are included as a means to compare discretization methods\nfor flow. With this publication, we invite researchers to contribute to the\nstudy by providing results to the test cases based on their applied\ndiscretization methods. \n\n"}
{"id": "1809.08516", "contents": "Title: Adversarial Defense via Data Dependent Activation Function and Total\n  Variation Minimization Abstract: We improve the robustness of Deep Neural Net (DNN) to adversarial attacks by\nusing an interpolating function as the output activation. This data-dependent\nactivation remarkably improves both the generalization and robustness of DNN.\nIn the CIFAR10 benchmark, we raise the robust accuracy of the adversarially\ntrained ResNet20 from $\\sim 46\\%$ to $\\sim 69\\%$ under the state-of-the-art\nIterative Fast Gradient Sign Method (IFGSM) based adversarial attack. When we\ncombine this data-dependent activation with total variation minimization on\nadversarial images and training data augmentation, we achieve an improvement in\nrobust accuracy by 38.9$\\%$ for ResNet56 under the strongest IFGSM attack.\nFurthermore, We provide an intuitive explanation of our defense by analyzing\nthe geometry of the feature space. \n\n"}
{"id": "1809.09815", "contents": "Title: Analysis and entropy stability of the line-based discontinuous Galerkin\n  method Abstract: We develop a discretely entropy-stable line-based discontinuous Galerkin\nmethod for hyperbolic conservation laws based on a flux differencing technique.\nBy using standard entropy-stable and entropy-conservative numerical flux\nfunctions, this method guarantees that the discrete integral of the entropy is\nnon-increasing. This nonlinear entropy stability property is important for the\nrobustness of the method, in particular when applied to problems with\ndiscontinuous solutions or when the mesh is under-resolved. This line-based\nmethod is significantly less computationally expensive than a standard DG\nmethod. Numerical results are shown demonstrating the effectiveness of the\nmethod on a variety of test cases, including Burgers' equation and the Euler\nequations, in one, two, and three spatial dimensions. \n\n"}
{"id": "1809.11003", "contents": "Title: An inverse scattering approach for geometric body generation: a machine\n  learning perspective Abstract: In this paper, we are concerned with the 2D and 3D geometric shape generation\nby prescribing a set of characteristic values of a specific geometric body. One\nof the major motivations of our study is the 3D human body generation in\nvarious applications. We develop a novel method that can generate the desired\nbody with customized characteristic values. The proposed method follows a\nmachine-learning flavour that generates the inferred geometric body with the\ninput characteristic parameters from a training dataset. One of the critical\ningredients and novelties of our method is the borrowing of inverse scattering\ntechniques in the theory of wave propagation to the body generation. This is\ndone by establishing a delicate one-to-one correspondence between a geometric\nbody and the far-field pattern of a source scattering problem governed by the\nHelmholtz system. It in turn enables us to establish a one-to-one\ncorrespondence between the geometric body space and the function space defined\nby the far-field patterns. Hence, the far-field patterns can act as the shape\ngenerators. The shape generation with prescribed characteristic parameters is\nachieved by first manipulating the shape generators and then reconstructing the\ncorresponding geometric body from the obtained shape generator by a stable\nmultiple-frequency Fourier method. Our method is easy to implement and produces\nmore efficient and stable body generations. We provide both theoretical\nanalysis and extensive numerical experiments for the proposed method. The study\nis the first attempt to introduce inverse scattering approaches in combination\nwith machine learning to the geometric body generation and it opens up many\nopportunities for further developments. \n\n"}
{"id": "1809.11101", "contents": "Title: A reduced order variational multiscale approach for turbulent flows Abstract: The purpose of this work is to present a reduced order modeling framework for\nparametrized turbulent flows with moderately high Reynolds numbers within the\nvariational multiscale (VMS) method. The Reduced Order Models (ROMs) presented\nin this manuscript are based on a POD-Galerkin approach with a VMS\nstabilization technique. Two different reduced order models are presented,\nwhich differ on the stabilization used during the Galerkin projection. In the\nfirst case the VMS stabilization method is used at both the full order and the\nreduced order level. In the second case, the VMS stabilization is used only at\nthe full order level, while the projection of the standard Navier-Stokes\nequations is performed instead at the reduced order level. The former method is\ndenoted as consistent ROM, while the latter is named non-consistent ROM, in\norder to underline the different choices made at the two levels. Particular\nattention is also devoted to the role of inf-sup stabilization by means of\nsupremizers in ROMs based on a VMS formulation. Finally, the developed methods\nare tested on a numerical benchmark. \n\n"}
{"id": "1810.00926", "contents": "Title: A note on the error estimate of the virtual element methods Abstract: This short note reports a new derivation of the optimal order of the a priori\nerror estimates for conforming virtual element methods (VEM) on 3D polyhedral\nmeshes based on an error equation. The geometric assumptions, which are\nnecessary for the optimal order of the conforming VEM error estimate in the\n$H^1$-seminorm, are relaxed for that in a bilinear form-induced energy norm. \n\n"}
{"id": "1810.01397", "contents": "Title: Numerical Methods for the Magnetic Induction Equation with Hall Effect\n  and Projections onto Divergence-Free Vector Fields Abstract: The nonlinear magnetic induction equation with Hall effect can be used to\nmodel magnetic fields, e.g. in astrophysical plasma environments. In order to\ngive reliable results, numerical simulations should be carried out using\neffective and efficient schemes. Thus, high-order stable schemes are\ninvestigated here.\n  Following the approach provided recently by Nordstr\\\"om (J Sci Comput 71.1,\npp. 365--385, 2017), an energy analysis for both the linear and the nonlinear\ninduction equation including boundary conditions is performed at first. Novel\noutflow boundary conditions for the Hall induction equation are proposed,\nresulting in an energy estimate. Based on an energy analysis of the initial\nboundary value problem at the continuous level, semidiscretisations using\nsummation by parts (SBP) operators and simultaneous approximation terms are\ncreated. Mimicking estimates at the continuous level, several energy stable\nschemes are obtained in this way and compared in numerical experiments.\nMoreover, stabilisation techniques correcting errors in the numerical\ndivergence of the magnetic field via projection methods are studied from an\nenergetic point of view in the SBP framework. In particular, the treatment of\nboundaries is investigated and a new approach with some improved properties is\nproposed. \n\n"}
{"id": "1810.02105", "contents": "Title: Thirty years of the finite volume method for solid mechanics Abstract: Since early publications in the late 1980s and early 1990s, the finite volume\nmethod has been shown suitable for solid mechanics analyses. At present, there\nare several flavours of the method, which can be classified in a variety of\nways, such as grid arrangement (cell-centred vs staggered vs vertex-centred),\nsolution algorithm (implicit vs explicit), and stabilisation strategy\n(Rhie-Chow vs Jameson-Schmidt-Turkel vs Godunov upwinding). This article gives\nan overview, historical perspective, comparison and critical analysis of the\ndifferent approaches where a close comparison with the de facto standard for\ncomputational solid mechanics, the finite element method, is given. The article\nfinishes with a look towards future research directions and steps required for\nfinite volume solid mechanics to achieve more widespread acceptance. \n\n"}
{"id": "1810.02271", "contents": "Title: A Nitsche-eXtended finite element method for distributed optimal control\n  problems of elliptic interface equations Abstract: This paper analyzes an interface-unfitted numerical method for distributed\noptimal control problems governed by elliptic interface equations. We follow\nthe variational discretization concept to discretize the optimal control\nproblems, and apply a Nitsche-eXtended finite element method to discretize the\ncorresponding state and adjoint equations, where piecewise cut basis functions\naround the interface are enriched into the standard linear element space.\nOptimal error estimates of the state, co-state and control in a mesh-dependent\nnorm and the $L^2$ norm are derived. Numerical results are provided to verify\nthe theoretical results. \n\n"}
{"id": "1810.02483", "contents": "Title: Asymptotic approximations for the close evaluation of double-layer\n  potentials Abstract: When using the boundary integral equation method to solve a boundary value\nproblem, the evaluation of the solution near the boundary is challenging to\ncompute because the layer potentials that represent the solution are\nnearly-singular integrals. To address this close evaluation problem, we apply\nan asymptotic analysis of these nearly singular integrals and obtain an\nasymptotic approximation. We derive the asymptotic approximation for the case\nof the double-layer potential in two and three dimensions, representing the\nsolution of the interior Dirichlet problem for Laplace's equation. By doing so,\nwe obtain an asymptotic approximation given by the Dirichlet data at the\nboundary point nearest to the interior evaluation point plus a nonlocal\ncorrection. We present numerical methods to compute this asymptotic\napproximation, and we demonstrate the efficiency and accuracy of the asymptotic\napproximation through several examples. These examples show that the asymptotic\napproximation is useful as it accurately approximates the close evaluation of\nthe double-layer potential while requiring only modest computational resources. \n\n"}
{"id": "1810.03275", "contents": "Title: TV-regularized CT Reconstruction and Metal Artifact Reduction Using\n  Inequality Constraints with Preconditioning Abstract: Total variation(TV) regularization is applied to X-Ray computed\ntomography(CT) in an effort to reduce metal artifacts. Tikhonov regularization\nwith $L^2$ data fidelity term and total variation regularization is augmented\nin this novel model by inequality constraints on sinogram data affected by\nmetal to model errors caused by metal. The formulated problem is discretized\nand solved using the Chambolle-Pock algorithm. Faster convergence is achieved\nusing preconditioning in a Douglas-Rachford spitting method as well as Advanced\nDirection Method of Multipliers(ADMM). The methods are applied to real and\nsynthetic data demonstrating feasibility of the model to reduce metal\nartifacts. Technical details of CT data used and its processing are given in\nthe appendix. \n\n"}
{"id": "1810.04857", "contents": "Title: Simplex-averaged finite element methods for $H({\\rm grad})$, $H({\\rm\n  curl})$ and $H({\\rm div})$ convection-diffusion problems Abstract: This paper is devoted to the construction and analysis of the finite element\napproximations for the $H(D)$ convection-diffusion problems, where $D$ can be\nchosen as ${\\rm grad}$, ${\\rm curl}$ or ${\\rm div}$ in 3D case. An essential\nfeature of these constructions is to properly average the PDE coefficients on\nthe sub-simplexes. The schemes are of the class of exponential fitting methods\nthat result in special upwind schemes when the diffusion coefficient approaches\nto zero. Their well-posedness are established for sufficiently small mesh size\nassuming that the convection-diffusion problems are uniquely solvable.\nConvergence of first order is derived under minimal smoothness of the solution.\nSome numerical examples are given to demonstrate the robustness and\neffectiveness for general convection-diffusion problems. \n\n"}
{"id": "1810.05984", "contents": "Title: A Unified Gas-kinetic Particle Method for Multiscale Photon Transport Abstract: In this work, we present a unified gas-kinetic particle (UGKP) method for the\nsimulation of multiscale photon transport. The multiscale nature of the\nparticle method mainly comes from the recovery of the time evolution flux\nfunction in the unified gas-kinetic scheme (UGKS) through a coupled dynamic\nprocess of particle transport and collision. This practice improves the\noriginal operator splitting approach in the Monte Carlo method, such as the\nseparated treatment of particle transport and collision. As a result, with the\nvariation of the ratio between numerical time step and local photon's collision\ntime, different transport physics can be fully captured in a single\ncomputation. In the diffusive limit, the UGKP method could recover the solution\nof the diffusion equation with the cell size and time step being much larger\nthan the photon's mean free path and the mean collision time. In the free\ntransport limit, it presents an exact particle tracking process as the original\nMonte Carlo method. In the transition regime, the weights of particle free\ntransport and collision are determined by the ratio of local numerical time\nstep to the photon's collision time. Several one-dimensional numerical examples\ncovering all transport regimes from the optically thin to optically thick are\ncomputed to validate the accuracy and efficiency of the current scheme. In\ncomparison with the $S_N$ discrete ordinate method, the UGKP method is based on\nparticles and avoids the discretization of particle velocity space, which does\nnot suffer from the ray effect. \n\n"}
{"id": "1810.06089", "contents": "Title: Asymptotics for Sketching in Least Squares Regression Abstract: We consider a least squares regression problem where the data has been\ngenerated from a linear model, and we are interested to learn the unknown\nregression parameters. We consider \"sketch-and-solve\" methods that randomly\nproject the data first, and do regression after. Previous works have analyzed\nthe statistical and computational performance of such methods. However, the\nexisting analysis is not fine-grained enough to show the fundamental\ndifferences between various methods, such as the Subsampled Randomized Hadamard\nTransform (SRHT) and Gaussian projections. In this paper, we make progress on\nthis problem, working in an asymptotic framework where the number of datapoints\nand dimension of features goes to infinity. We find the limits of the accuracy\nloss (for estimation and test error) incurred by popular sketching methods. We\nshow separation between different methods, so that SRHT is better than Gaussian\nprojections. Our theoretical results are verified on both real and synthetic\ndata. The analysis of SRHT relies on novel methods from random matrix theory\nthat may be of independent interest. \n\n"}
{"id": "1810.07067", "contents": "Title: An FFT-accelerated direct solver for electromagnetic scattering from\n  penetrable axisymmetric objects Abstract: Fast, high-order accurate algorithms for electromagnetic scattering from\naxisymmetric objects are of great importance when modeling physical phenomena\nin optics, materials science (e.g. meta-materials), and many other fields of\napplied science. In this paper, we develop an FFT-accelerated separation of\nvariables solver that can be used to efficiently invert integral equation\nformulations of Maxwell's equations for scattering from axisymmetric penetrable\n(dielectric) bodies. Using a standard variant of M\\\"uller's integral\nrepresentation of the fields, our numerical solver rapidly and directly inverts\nthe resulting second-kind integral equation. In particular, the algorithm of\nthis work (1) rapidly evaluates the modal Green's functions, and their\nderivatives, via kernel splitting and the use of novel recursion formulas, (2)\ndiscretizes the underlying integral equation using generalized Gaussian\nquadratures on adaptive meshes, and (3) is applicable to geometries containing\nedges. Several numerical examples are provided to demonstrate the efficiency\nand accuracy of the aforementioned algorithm in various geometries. \n\n"}
{"id": "1810.07131", "contents": "Title: Fast and accurate algorithms for the computation of spherically\n  symmetric nonlocal diffusion operators on lattices Abstract: We present a unified treatment of the Fourier spectra of spherically\nsymmetric nonlocal diffusion operators. We develop numerical and analytical\nresults for the class of kernels with weak algebraic singularity as the\ndistance between source and target tends to $0$. Rapid algorithms are derived\nfor their Fourier spectra with the computation of each eigenvalue independent\nof all others. The algorithms are trivially parallelizable, capable of\nleveraging more powerful compute environments, and the accuracy of the\neigenvalues is individually controllable. The algorithms include a Maclaurin\nseries and a full divergent asymptotic series valid for any $d$ spatial\ndimensions. Using Drummond's sequence transformation, we prove linear\ncomplexity recurrence relations for degree-graded sequences of numerators and\ndenominators in the rational approximations to the divergent asymptotic series.\nThese relations are important to ensure that the algorithms are efficient, and\nalso increase the numerical stability compared with the conventional algorithm\nwith quadratic complexity. \n\n"}
{"id": "1810.07999", "contents": "Title: POD-Galerkin reduced order methods for combined Navier-Stokes transport\n  equations based on a hybrid FV-FE solver Abstract: The purpose of this work is to introduce a novel POD-Galerkin strategy for\nthe hybrid finite volume/finite element solver introduced in Berm\\'udez et al.\n2014 and Busto et al. 2018. The interest is into the incompressible\nNavier-Stokes equations coupled with an additional transport equation. The full\norder model employed in this article makes use of staggered meshes. This\nfeature will be conveyed to the reduced order model leading to the definition\nof reduced basis spaces in both meshes. The reduced order model presented\nherein accounts for velocity, pressure, and a transport-related variable. The\npressure term at both the full order and the reduced order level is\nreconstructed making use of a projection method. More precisely, a Poisson\nequation for pressure is considered within the reduced order model. Results are\nverified against three-dimensional manufactured test cases. Moreover a modified\nversion of the classical cavity test benchmark including the transport of a\nspecies is analysed. \n\n"}
{"id": "1810.08607", "contents": "Title: Level Set Methods for Stochastic Discontinuity Detection in Nonlinear\n  Problems Abstract: Stochastic physical problems governed by nonlinear conservation laws are\nchallenging due to solution discontinuities in stochastic and physical space.\nIn this paper, we present a level set method to track discontinuities in\nstochastic space by solving a Hamilton-Jacobi equation. By introducing a speed\nfunction that vanishes at discontinuities, the iso-zero of the level set\nproblem coincide with the discontinuities of the conservation law. The level\nset problem is solved on a sequence of successively finer grids in stochastic\nspace. The method is adaptive in the sense that costly evaluations of the\nconservation law of interest are only performed in the vicinity of the\ndiscontinuities during the refinement stage. In regions of stochastic space\nwhere the solution is smooth, a surrogate method replaces expensive evaluations\nof the conservation law. The proposed method is tested in conjunction with\ndifferent sets of localized orthogonal basis functions on simplex elements, as\nwell as frames based on piecewise polynomials conforming to the level set\nfunction. The performance of the proposed method is compared to existing\nadaptive multi-element generalized polynomial chaos methods. \n\n"}
{"id": "1810.09212", "contents": "Title: Hessian recovery based finite element methods for the Cahn-Hilliard\n  Equation Abstract: In this paper, we propose a novel recovery based finite element method for\nthe Cahn-Hilliard equation. One distinguishing feature of the method is that we\ndiscretize the fourth-order differential operator in a standard $C^0$ linear\nfinite elements space. Precisely, we first transform the fourth-order\nCahn-Hilliard equation to its variational formulation in which only first-order\nand second-order derivatives are involved and then we compute the and\nsecond-order derivatives of a linear finite element function by a least-squares\nfitting recovery procedure. The intrinsic link between the second-order\nderivatives (Hessian matrix) recovery scheme and the finite difference method\nis studied in the paper. In particular, for the first time, we discover that\nthe Laplace recovery scheme is exactly the well-known five-point stencil over\nuniform meshes. The proposed discretization for the Cahn-Hilliard equation can\nbe regarded as a combination of the finite difference scheme and the finite\nelement scheme. In addition, special considerations are put on different\nmethods for imposing Neumann type boundary conditions.\n  The optimal-order convergence and energy stability are numerically proved\nthrough a series of benchmark tests. \n\n"}
{"id": "1810.10398", "contents": "Title: Edge Multiscale Methods for elliptic problems with heterogeneous\n  coefficients Abstract: In this paper, we proposed two new types of edge multiscale methods motivated\nby \\cite{GL18} to solve Partial Differential Equations (PDEs) with\nhigh-contrast heterogeneous coefficients: Edge spectral multiscale Finte\nElement method (ESMsFEM) and Wavelet-based edge multiscale Finite Element\nmethod (WEMsFEM). Their convergence rates for elliptic problems with\nhigh-contrast heterogeneous coefficients are demonstrated in terms of the\ncoarse mesh size $H$, the number of spectral basis functions and the level of\nthe wavelet space $\\ell$, which are verified by extensive numerical tests. \n\n"}
{"id": "1810.10730", "contents": "Title: Online adaptive basis enrichment for mixed CEM-GMsFEM Abstract: In this research, an online basis enrichment strategy for the constraint\nenergy minimizing generalized multiscale finite element method in mixed\nformulation is proposed. The online approach is based on the technique of\noversampling. One makes use of the information of residual and the data in the\npartial differential equation such as the source function. The analysis\npresented shows that the proposed online enrichment leads to a fast convergence\nfrom multiscale approximation to the fine-scale solution. The error reduction\ncan be made sufficiently large by suitably selecting oversampling regions and\nthe number of oversampling layers. Also, the convergence rate of the enrichment\ncan be tuned by a user-defined parameter. Numerical results are provided to\nillustrate the efficiency of the proposed method. \n\n"}
{"id": "1810.11115", "contents": "Title: Sparse approximation of multivariate functions from small datasets via\n  weighted orthogonal matching pursuit Abstract: We show the potential of greedy recovery strategies for the sparse\napproximation of multivariate functions from a small dataset of pointwise\nevaluations by considering an extension of the orthogonal matching pursuit to\nthe setting of weighted sparsity. The proposed recovery strategy is based on a\nformal derivation of the greedy index selection rule. Numerical experiments\nshow that the proposed weighted orthogonal matching pursuit algorithm is able\nto reach accuracy levels similar to those of weighted $\\ell^1$ minimization\nprograms while considerably improving the computational efficiency for small\nvalues of the sparsity level. \n\n"}
{"id": "1810.11749", "contents": "Title: Iterative Hard Thresholding for Low-Rank Recovery from Rank-One\n  Projections Abstract: A novel algorithm for the recovery of low-rank matrices acquired via\ncompressive linear measurements is proposed and analyzed. The algorithm, a\nvariation on the iterative hard thresholding algorithm for low-rank recovery,\nis designed to succeed in situations where the standard rank-restricted\nisometry property fails, e.g. in case of subexponential unstructured\nmeasurements or of subgaussian rank-one measurements. The stability and\nrobustness of the algorithm are established based on distinctive\nmatrix-analytic ingredients and its performance is substantiated numerically. \n\n"}
{"id": "1810.12219", "contents": "Title: An Automated Singularity-Capturing Scheme for Fractional Differential\n  Equations Abstract: Solutions to fractional models inherently exhibit non-smooth behavior, which\nsignificantly deteriorates the accuracy and therefore efficiency of existing\nnumerical methods. We develop a two-stage data-infused computational framework\nfor accurate time-integration of single- and multi-term fractional differential\nequations. In the first stage, we formulate a self-singularity-capturing\nscheme, given available/observable data for diminutive time. In this approach,\nthe fractional differential equation provides the necessary knowledge/insight\non how the hidden singularity can bridge between the initial and the subsequent\nshort-time solution data. We develop a new self-singularity-capturing\nfinite-difference algorithm for automatic determination of the underlying\npower-law singularities nearby the initial data, employing gradient descent\noptimization. In the second stage, we can utilize the multi-singular behavior\nof solution in a variety of numerical methods, without resorting to making any\nad-hoc/uneducated guesses for the solution singularities. Particularly, we\nemployed an implicit finite-difference method, where the captured\nsingularities, in the first stage, are taken into account through some\nLubich-like correction terms, leading to an accuracy of order\n$\\mathcal{O}(\\Delta t^{3-\\alpha})$. Our computational results demonstrate that\nthe developed framework can either fully capture or successfully control the\nsolution error in the time-integration of fractional differential equations,\nespecially in the presence of strong multi-singularities. \n\n"}
{"id": "1810.12761", "contents": "Title: A multiscale flux basis for mortar mixed discretizations of reduced\n  Darcy-Forchheimer fracture models Abstract: In this paper, a multiscale flux basis algorithm is developed to efficiently\nsolve a flow problem in fractured porous media. Here, we take into account a\nmixed-dimensional setting of the discrete fracture matrix model, where the\nfracture network is represented as lower-dimensional object. We assume the\nlinear Darcy model in the rock matrix and the non-linear Forchheimer model in\nthe fractures. In our formulation, we are able to reformulate the\nmatrix-fracture problem to only the fracture network problem and, therefore,\nsignificantly reduce the computational cost. The resulting problem is then a\nnon-linear interface problem that can be solved using a fixed-point or\nNewton-Krylov methods, which in each iteration require several solves of Robin\nproblems in the surrounding rock matrices. To achieve this, the flux exchange\n(a linear Robin-to-Neumann co-dimensional mapping) between the porous medium\nand the fracture network is done offline by pre-computing a multiscale flux\nbasis that consists of the flux response from each degree of freedom on the\nfracture network. This delivers a conserve for the basis that handles the\nsolutions in the rock matrices for each degree of freedom in the fractures\npressure space. Then, any Robin sub-domain problems are replaced by linear\ncombinations of the multiscale flux basis during the interface iteration. The\nproposed approach is, thus, agnostic to the physical model in the fracture\nnetwork. Numerical experiments demonstrate the computational gains of\npre-computing the flux exchange between the porous medium and the fracture\nnetwork against standard non-linear domain decomposition approaches. \n\n"}
{"id": "1810.13426", "contents": "Title: Optimal constants in nontrapping resolvent estimates and applications in\n  numerical analysis Abstract: We study the resolvent for nontrapping obstacles on manifolds with Euclidean\nends. It is well known that for such manifolds, the outgoing resolvent\nsatisfies $\\|\\chi R(k) \\chi\\|_{L^2\\to L^2}\\leq C{k}^{-1}$ for ${k}>1$, but the\nconstant $C$ has been little studied. We show that, for high frequencies, the\nconstant is bounded above by $2/\\pi$ times the length of the longest\ngeneralized bicharacteristic of $|\\xi|_g^2-1$ remaining in the support of\n$\\chi.$ We show that this estimate is optimal in the case of manifolds without\nboundary. We then explore the implications of this result for the numerical\nanalysis of the Helmholtz equation. \n\n"}
{"id": "1811.00068", "contents": "Title: Accurate gradient computations for shape optimization via discrete\n  adjoints in CFD-related multiphysics problems Abstract: As more and more multiphysics effects are entering the field of CFD\nsimulations, this raises the question how they can be accurately captured in\ngradient computations for shape optimization. The latter has been successfully\nenriched over the last years by the use of (discrete) adjoints. One can think\nof them as Lagrange multipliers to the flow field problem linked to an\nobjective function that depends on quantities like pressure or momentums, and\nthey will set also the framework for this paper. It is split into two main\nparts: First, we show how one can compute coupled discrete adjoints using\nautomatic differentiation in an effective way that is still easily extendable\nfor all kinds of other couplings. Second, we suppose that a valuable first\napplication are so-called conjugate heat transfer problems which are gaining\nmore and more interest from the automobile and aeronautics industry. Therefore\nwe present an implementation for this capability within the open-source solver\nSU2 as well as for the generic adjoint computation algorithm. \n\n"}
{"id": "1811.00676", "contents": "Title: A Fast, Spectrally Accurate Homotopy Based Numerical Method For Solving\n  Nonlinear Differential Equations Abstract: We present an algorithm for constructing numerical solutions to\none--dimensional nonlinear, variable coefficient boundary value problems. This\nscheme is based upon applying the Homotopy Analysis Method (HAM) to decompose a\nnonlinear differential equation into a series of linear differential equations\nthat can be solved using a sparse, spectrally accurate Gegenbauer\ndiscretisation. Uniquely for nonlinear methods, our scheme involves\nconstructing a single, sparse matrix operator that is repeatedly solved in\norder to solve the full nonlinear problem. As such, the resulting scheme scales\nquasi-linearly with respect to the grid resolution. We demonstrate the\naccuracy, and computational scaling of this method by examining a fourth-order\nnonlinear variable coefficient boundary value problem by comparing the scheme\nto Newton-Iteration and the Spectral Homotopy Analysis Method, which is the\nmost commonly used implementation of the HAM. \n\n"}
{"id": "1811.01538", "contents": "Title: On Time-Discretization of the 2d Euler Equation by a Symplectic\n  Crouch-Grossman Integrator Abstract: We consider time discretizations of the two-dimensional Euler equation\nwritten in vorticity form. The discretization method uses a Crouch-Grossman\nintegrator that proceeds in two stages: first freezing the velocity vector\nfield at the beginning of the time step, and then solve the resulting\nelementary transport equation by using a symplectic integrator to discretize in\ntime the flow of the associated Hamiltonian differential equation. We prove\nthat these schemes yield order one approximations of the exact solutions, and\nprovide error estimates in Sobolev norms. \n\n"}
{"id": "1811.01645", "contents": "Title: Extension of the nonconforming Trefftz virtual element method to the\n  Helmholtz problem with piecewise constant wave number Abstract: We extend the nonconforming Trefftz virtual element method introduced in\narXiv:1805.05634 to the case of the fluid-fluid interface problem, that is, a\nHelmholtz problem with piecewise constant wave number. With respect to the\noriginal approach, we address two additional issues: firstly, we define the\ncoupling of local approximation spaces with piecewise constant wave numbers,\nsecondly, we enrich such local spaces with special functions capturing the\nphysical behaviour of the solution to the target problem. As these two issues\nare directly related to an increase of the number of degrees of freedom, we use\na reduction strategy inspired by arXiv:1807.11237, which allows to mitigate the\ngrowth of the dimension of the approximation space when considering $h$- and\n$p$-refinements. This renders the new method highly competitive in comparison\nto other Trefftz and quasi-Trefftz technologies tailored for the Helmholtz\nproblem with piecewise constant wave number. A wide range of numerical\nexperiments, including the $p$-version with quasi-uniform meshes and the\n$hp$-version with isotropic and anisotropic mesh refinements, is presented. \n\n"}
{"id": "1811.02174", "contents": "Title: Super-resolution of time-splitting methods for the Dirac equation in the\n  nonrelativistic regime Abstract: We establish error bounds of the Lie-Trotter splitting ($S_1$) and Strang\nsplitting ($S_2$) for the Dirac equation in the nonrelativistic limit regime in\nthe absence of external magnetic potentials, with a small parameter\n$0<\\varepsilon\\leq 1$ inversely proportional to the speed of light. In this\nlimit regime, the solution propagates waves with $O(\\varepsilon^2)$ wavelength\nin time. Surprisingly, we find out that the splitting methods exhibit\nsuper-resolution, in the sense of breaking the resolution constraint under the\nShannon's sampling theorem, i.e. the methods can capture the solutions\naccurately even if the time step size $\\tau$ is much larger than the sampled\nwavelength at $O(\\varepsilon^2)$. $S_1$ shows $1/2$ order convergence uniformly\nwith respect to $\\varepsilon$, by establishing that there are two independent\nerror bounds $\\tau + \\varepsilon$ and $\\tau + \\tau/\\varepsilon$. Moreover, if\n$\\tau$ is non-resonant, i.e. $\\tau$ is away from certain region determined by\n$\\varepsilon$, $S_1$ would yield an improved uniform first order $O(\\tau)$\nerror bound. In addition, we show $S_2$ is uniformly convergent with 1/2 order\nrate for general time step size $\\tau$ and uniformly convergent with $3/2$\norder rate for non-resonant time step size. Finally, numerical examples are\nreported to validate our findings. \n\n"}
{"id": "1811.04515", "contents": "Title: External optimal control of nonlocal PDEs Abstract: Very recently M. Warma has shown that for nonlocal PDEs associated with the\nfractional Laplacian, the classical notion of controllability from the boundary\ndoes not make sense and therefore it must be replaced by a control that is\nlocalized outside the open set where the PDE is solved. Having learned from the\nabove mentioned result, in this paper we introduce a new class of source\nidentification and optimal control problems where the source/control is located\noutside the observation domain where the PDE is satisfied. The classical\ndiffusion models lack this flexibility as they assume that the source/control\nis located either inside or on the boundary. This is essentially due to the\nlocality property of the underlying operators. We use the nonlocality of the\nfractional operator to create a framework that now allows placing a\nsource/control outside the observation domain. We consider the Dirichlet, Robin\nand Neumann source identification or optimal control problems. These problems\nrequire dealing with the nonlocal normal derivative (that we shall call\ninteraction operator). We create a functional analytic framework and show\nwell-posedness and derive the first order optimality conditions for these\nproblems. We introduce a new approach to approximate, with convergence rate,\nthe Dirichlet problem with nonzero exterior condition. The numerical examples\nconfirm our theoretical findings and illustrate the practicality of our\napproach. \n\n"}
{"id": "1811.05151", "contents": "Title: An adaptive reduced basis ANOVA method for high-dimensional Bayesian\n  inverse problems Abstract: In Bayesian inverse problems sampling the posterior distribution is often a\nchallenging task when the underlying models are computationally intensive. To\nthis end, surrogates or reduced models are often used to accelerate the\ncomputation. However, in many practical problems, the parameter of interest can\nbe of high dimensionality, which renders standard model reduction techniques\ninfeasible. In this paper, we present an approach that employs the ANOVA\ndecomposition method to reduce the model with respect to the unknown\nparameters, and the reduced basis method to reduce the model with respect to\nthe physical parameters. Moreover, we provide an adaptive scheme within the\nMCMC iterations, to perform the ANOVA decomposition with respect to the\nposterior distribution. With numerical examples, we demonstrate that the\nproposed model reduction method can significantly reduce the computational cost\nof Bayesian inverse problems, without sacrificing much accuracy. \n\n"}
{"id": "1811.06301", "contents": "Title: Stable discretizations of elastic flow in Riemannian manifolds Abstract: The elastic flow, which is the $L^2$-gradient flow of the elastic energy, has\nseveral applications in geometry and elasticity theory. We present stable\ndiscretizations for the elastic flow in two-dimensional Riemannian manifolds\nthat are conformally flat, i.e.\\ conformally equivalent to the Euclidean space.\nExamples include the hyperbolic plane, the hyperbolic disk, the elliptic plane\nas well as any conformal parameterization of a two-dimensional manifold in\n${\\mathbb R}^d$, $d\\geq 3$. Numerical results show the robustness of the\nmethod, as well as quadratic convergence with respect to the space\ndiscretization. \n\n"}
{"id": "1811.08319", "contents": "Title: Advances in Reduced Order Methods for Parametric Industrial Problems in\n  Computational Fluid Dynamics Abstract: Reduced order modeling has gained considerable attention in recent decades\nowing to the advantages offered in reduced computational times and multiple\nsolutions for parametric problems. The focus of this manuscript is the\napplication of model order reduction techniques in various engineering and\nscientific applications including but not limited to mechanical, naval and\naeronautical engineering. The focus here is kept limited to computational fluid\nmechanics and related applications. The advances in the reduced order modeling\nwith proper orthogonal decomposition and reduced basis method are presented as\nwell as a brief discussion of dynamic mode decomposition and also some present\nadvances in the parameter space reduction. Here, an overview of the challenges\nfaced and possible solutions are presented with examples from various problems. \n\n"}
{"id": "1811.08522", "contents": "Title: An HDG Method for Tangential Boundary Control of Stokes Equations I:\n  High Regularity Abstract: We propose a hybridizable discontinuous Galerkin (HDG) method to approximate\nthe solution of a tangential Dirichlet boundary control problem for the Stokes\nequations with an $ L^2 $ penalty on the boundary control. The contribution of\nthis paper is twofold. First, we obtain well-posedness and regularity results\nfor the tangential Dirichlet control problem on a convex polygonal domain. The\nanalysis contains new features not found in similar Dirichlet control problems\nfor the Poisson equation; an interesting result is that the optimal control has\nhigher local regularity on the individual edges of the domain compared to the\nglobal regularity on the entire boundary. Second, under certain assumptions on\nthe domain and the target state, we prove a priori error estimates for the\ncontrol for the HDG method. In the 2D case, our theoretical convergence rate\nfor the control is superlinear and optimal with respect to the global\nregularity on the entire boundary. We present numerical experiments to\ndemonstrate the performance of the HDG method. \n\n"}
{"id": "1811.08751", "contents": "Title: Chan-Vese Reformulation for Selective Image Segmentation Abstract: Selective segmentation involves incorporating user input to partition an\nimage into foreground and background, by discriminating between objects of a\nsimilar type. Typically, such methods involve introducing additional\nconstraints to generic segmentation approaches. However, we show that this is\noften inconsistent with respect to common assumptions about the image. The\nproposed method introduces a new fitting term that is more useful in practice\nthan the Chan-Vese framework. In particular, the idea is to define a term that\nallows for the background to consist of multiple regions of inhomogeneity. We\nprovide comparitive experimental results to alternative approaches to\ndemonstrate the advantages of the proposed method, broadening the possible\napplication of these methods. \n\n"}
{"id": "1811.09334", "contents": "Title: Randomized QLP algorithm and error analysis Abstract: In this paper, we describe the randomized QLP (RQLP) algorithm and its\nenhanced version (ERQLP) for computing the low rank approximation to $A$ of\nsize $m\\times n$ efficiently such that $A\\approx QLP$, where $L$ is the\nrank-$k$ lower-triangular matrix, $Q$ and $P$ are column orthogonal matrices.\nThe theoretical cost of the implementation of RQLP and ERQLP only needs\n$\\mathcal{O}(mnk)$. Moreover, we derive the upper bounds of the expected\napproximation error $\\mathbb{E}\\left [ (\\sigma_{j}(A) - \\sigma_{j} (L))/\n\\sigma_{j}(A) \\right] $ for $j=1,\\cdots, k$, and prove that the $L$-values of\nthe proposed methods can track the singular values of $A$ accurately. These\nclaims are supported by extensive numerical experiments. \n\n"}
{"id": "1811.09592", "contents": "Title: NEP-PACK: A Julia package for nonlinear eigenproblems - v0.2 Abstract: We present NEP-PACK a novel open-source library for the solution of nonlinear\neigenvalue problems (NEPs). The package provides a framework to represent NEPs,\nas well as efficient implementations of many state-of-the-art algorithms. The\npackage makes full use of the efficiency of Julia, yet maintains usability, and\nintegrates well with other software packages. The package is designed to be\neasy to use for application researchers as well as algorithm developers.\nParticular attention is paid to algorithm neutrality, in order to make\nperformance comparisons between algorithms easier. This paper describes the\nmain functionality of NEP-PACK, as well as design decisions and theory needed\nfor the design. \n\n"}
{"id": "1811.10368", "contents": "Title: Adaptive Radial Basis Function-generated Finite Differences method for\n  contact problems Abstract: This paper proposes an original adaptive refinement framework using Radial\nBasis Functions-generated Finite Differences method. Node distributions are\ngenerated with a Poisson Disk Sampling-based algorithm from a given continuous\ndensity function, which is altered during the refinement process based on the\nerror indicator. All elements of the proposed adaptive strategy rely only on\nmeshless concepts, which leads to great flexibility and generality of the\nsolution procedure. The proposed framework is tested on four gradually more\ncomplex contact problems, governed by the Cauchy-Navier equations. First, a\ndisk under pressure is considered and the computed stress field is compared to\nthe closed form solution of the problem to assess the basic behaviour of the\nalgorithm and the influence of free parameters. Second, a Hertzian contact\nproblem, also with known closed form solution, is studied to analyse the\nproposed algorithm with an ad-hoc error indicator and to test both refinement\nand derefinement. A contact problem, typical for fretting fatigue, with no\nknown closed form solution is considered and solved next. It is demonstrated\nthat the proposed methodology can be used in practical application and produces\nresults comparable with FEM without the need for manual refinement or any human\nintervention. In the last case, generality of the proposed approach is\ndemonstrated by solving a 3-D Boussinesq's problem of the concentrated normal\ntraction acting on an isotropic half-space. \n\n"}
{"id": "1811.10680", "contents": "Title: Strong stability of explicit Runge-Kutta time discretizations Abstract: Motivated by studies on fully discrete numerical schemes for linear\nhyperbolic conservation laws, we present a framework on analyzing the strong\nstability of explicit Runge-Kutta (RK) time discretizations for semi-negative\nautonomous linear systems. The analysis is based on the energy method and can\nbe performed with the aid of a computer. Strong stability of various RK\nmethods, including a sixteen-stage embedded pair of order nine and eight, has\nbeen examined under this framework. Based on numerous numerical observations,\nwe further characterize the features of strongly stable schemes. A both\nnecessary and sufficient condition is given for the strong stability of RK\nmethods of odd linear order. \n\n"}
{"id": "1811.10680", "contents": "Title: Strong stability of explicit Runge-Kutta time discretizations Abstract: Motivated by studies on fully discrete numerical schemes for linear\nhyperbolic conservation laws, we present a framework on analyzing the strong\nstability of explicit Runge-Kutta (RK) time discretizations for semi-negative\nautonomous linear systems. The analysis is based on the energy method and can\nbe performed with the aid of a computer. Strong stability of various RK\nmethods, including a sixteen-stage embedded pair of order nine and eight, has\nbeen examined under this framework. Based on numerous numerical observations,\nwe further characterize the features of strongly stable schemes. A both\nnecessary and sufficient condition is given for the strong stability of RK\nmethods of odd linear order. \n\n"}
{"id": "1811.12212", "contents": "Title: A Structured Approach to the Construction of Stable Linear\n  Lattice-Boltzmann Collision Operators Abstract: We introduce a structured approach to the construction of linear BGK-type\ncollision operators ensuring that the resulting Lattice-Boltzmann methods are\nstable with respect to a weighted $L^2$-norm. The results hold for particular\nboundary conditions including periodic, bounce-back, and bounce-back with\nflipping of sign. This construction uses the equivalent moment-space definition\nof BGK-type collision operators and the notion of stability structures as\nguiding principle for the choice of the equilibrium moments for those moments\ninfluencing the error term only but not the order of consistency. The presented\nstructured approach is then applied to the 3D isothermal linearized Euler\nequations with non-vanishing background velocity. Finally, convergence results\nin the strong discrete $L^\\infty$-norm highlight the suitability of the\nstructured approach introduced in this manuscript. \n\n"}
{"id": "1811.12769", "contents": "Title: A natural decomposition of viscous dissipation in DG methods for\n  turbulent incompressible flows Abstract: In this note we aim at a characterisation of the discretisation of viscous\ndissipation which allows to distinguish `physical' (also frequently called\n`molecular', or `resolved') from `numerical' dissipation in DG-discretised\nincompressible flow simulations. \n\n"}
{"id": "1812.00145", "contents": "Title: Adaptive QM/MM Coupling for Crystalline Defects Abstract: QM (quantum mechenics) and MM (molecular mechenics) coupling methods are\nwidely used in simulations of crystalline defects. In this paper, we construct\na residual based a posteriori error indicator for QM/MM coupling\napproximations. We prove the reliability of the error indicator (upper bound of\nthe true approximation error) and develop some sampling techniques for its\nefficient calculation. Based on the error indicator and D\\\"{o}rfler marking\nstrategy, we design an adaptive QM/MM algorithm for crystalline defects and\ndemonstrate the efficiency with some numerical experiments. \n\n"}
{"id": "1812.00676", "contents": "Title: Efficient multistep methods for tempered fractional calculus: Algorithms\n  and Simulations Abstract: In this work, we extend the fractional linear multistep methods in [C.\nLubich, SIAM J. Math. Anal., 17 (1986), pp.704--719] to the tempered fractional\nintegral and derivative operators in the sense that the tempered fractional\nderivative operator is interpreted in terms of the Hadamard finite-part\nintegral. We develop two fast methods, Fast Method I and Fast Method II, with\nlinear complexity to calculate the discrete convolution for the approximation\nof the (tempered) fractional operator. Fast Method I is based on a local\napproximation for the contour integral that represents the convolution weight.\nFast Method II is based on a globally uniform approximation of the trapezoidal\nrule for the integral on the real line. Both methods are efficient, but\nnumerical experimentation reveals that Fast Method II outperforms Fast Method I\nin terms of accuracy, efficiency, and coding simplicity. The memory requirement\nand computational cost of Fast Method II are $O(Q)$ and $O(Qn_T)$,\nrespectively, where $n_T$ is the number of the final time steps and $Q$ is the\nnumber of quadrature points used in the trapezoidal rule. The effectiveness of\nthe fast methods is verified through a series of numerical examples for\nlong-time integration, including a numerical study of a fractional\nreaction-diffusion model. \n\n"}
{"id": "1812.00835", "contents": "Title: Sobolev gradient flow for the Gross-Pitaevskii eigenvalue problem:\n  global convergence and computational efficiency Abstract: We propose a new normalized Sobolev gradient flow for the Gross-Pitaevskii\neigenvalue problem based on an energy inner product that depends on time\nthrough the density of the flow itself. The gradient flow is well-defined and\nconverges to an eigenfunction. For ground states we can quantify the\nconvergence speed as exponentially fast where the rate depends on spectral gaps\nof a linearized operator. The forward Euler time discretization of the flow\nyields a numerical method which generalizes the inverse iteration for the\nnonlinear eigenvalue problem. For sufficiently small time steps, the method\nreduces the energy in every step and converges globally in $H^1$ to an\neigenfunction. In particular, for any nonnegative starting value, the ground\nstate is obtained. A series of numerical experiments demonstrates the\ncomputational efficiency of the method and its competitiveness with established\ndiscretizations arising from other gradient flows for this problem. \n\n"}
{"id": "1812.03052", "contents": "Title: Weighted Moore-Penrose inverses of arbitrary-order tensors Abstract: Within the field of multilinear algebra, inverses and generalized inverses of\ntensors based on the Einstein product have been investigated over the past few\nyears. In this paper, we explore the singular value decomposition and full-rank\ndecomposition of arbitrary-order tensors using {\\it reshape} operation.\nApplying range and null space of tensors along with the reshape operation; we\nfurther study the Moore-Penrose inverse of tensors and their cancellation\nproperties via the Einstein product. Then we discuss weighted Moore-Penrose\ninverses of arbitrary-order tensors using such product. Following a specific\nalgebraic approach, a few characterizations and representations of these\ninverses are explored. In addition to this, we obtain a few necessary and\nsufficient conditions for the reverse-order law to hold for weighted\nMoore-Penrose inverses of arbitrary-order tensors. \n\n"}
{"id": "1812.04256", "contents": "Title: Multivariate Newton Interpolation Abstract: For $m,n \\in \\mathbb{N}$, $m\\geq 1$ and a given function $f :\n\\mathbb{R}^m\\longrightarrow \\mathbb{R}$, the polynomial interpolation problem\n(PIP) is to determine a unisolvent node set $P_{m,n} \\subseteq \\mathbb{R}^m$ of\n$N(m,n):=|P_{m,n}|=\\binom{m+n}{n}$ points and the uniquely defined polynomial\n$Q_{m,n,f}\\in \\Pi_{m,n}$ in $m$ variables of degree\n$\\mathrm{deg}(Q_{m,n,f})\\leq n \\in \\mathbb{N}$ that fits $f$ on $P_{m,n}$,\ni.e., $Q_{m,n,f}(p) = f(p)$, $\\forall\\, p \\in P_{m,n}$. For $m=1$ the solution\nto the PIP is well known. In higher dimensions, however, no closed framework\nwas available. We here present a generalization of the classic Newton\ninterpolation from one-dimensional to arbitrary-dimensional spaces. Further we\nformulate an algorithm, termed PIP-SOLVER, based on a multivariate divided\ndifference scheme that computes the solution $Q_{m,n,f}$ in\n$\\mathcal{O}\\big(N(m,n)^2\\big)$ time using $\\mathcal{O}\\big(mN(m,n)\\big)$\nmemory. Further, we introduce unisolvent Newton-Chebyshev nodes and show that\nthese nodes avoid Runge's phenomenon in the sense that arbitrary periodic\nSobolev functions $f \\in H^k(\\Omega,\\mathbb{R}) \\subsetneq\nC^0(\\Omega,\\mathbb{R})$, $\\Omega =[-1,1]^m$ of regularity $k >m/2$ can be\nuniformly approximated, i.e., $ \\lim_{n\\rightarrow \\infty}||\\,f -Q_{m,n,f}\n\\,||_{C^0(\\Omega)}= 0$. Numerical experiments demonstrate the computational\nperformance and approximation accuracy of the PIP-SOLVER in practice. We expect\nthe presented results to be relevant for many applications, including numerical\nsolvers, quadrature, non-linear optimization, polynomial regression, adaptive\nsampling, Bayesian inference, and spectral analysis. \n\n"}
{"id": "1812.04504", "contents": "Title: Linear Second Order Energy Stable Schemes of Phase Field Model with\n  Nonlocal Constraints for Crystal Growth Abstract: We present a set of linear, second order, unconditionally energy stable\nschemes for the Allen-Cahn model with a nonlocal constraint for crystal growth\nthat conserves the mass of each phase. Solvability conditions are established\nfor the linear systems resulting from the linear schemes. Convergence rates are\nverified numerically. Dynamics obtained using the nonlocal Allen-Cahn model are\ncompared with the one obtained using the classic Allen-Cahn model as well as\nthe Cahn-Hilliard model, demonstrating slower dynamics than that of the\nAllen-Cahn model but faster dynamics than that of the Cahn-Hillard model. Thus,\nthe nonlocal Allen-Cahn model can be an alternative to the Cahn-Hilliard model\nin simulating crystal growth. Two Benchmark examples are presented to\nillustrate the prediction made with the nonlocal Allen-Cahn model in comparison\nto those made with the Allen-Cahn model and the Cahn- Hillard model. \n\n"}
{"id": "1812.04583", "contents": "Title: On the regularisation of the noise for the Euler-Maruyama scheme with\n  irregular drift Abstract: The strong rate of convergence of the Euler-Maruyama scheme for nondegenerate\nSDEs with irregular drift coefficients is considered. In the case of\n$\\alpha$-H\\\"older drift in the recent literature the rate $\\alpha/2$ was proved\nin many related situations. By exploiting the regularising effect of the noise\nmore efficiently, we show that the rate is in fact arbitrarily close to $1/2$\nfor all $\\alpha>0$. The result extends to Dini continuous coefficients, while\nin $d=1$ also to all bounded measurable coefficients. \n\n"}
{"id": "1812.04701", "contents": "Title: Numerical Methods for Fast Nonlinear Fourier Transformation, Part I:\n  Exponential Runge-Kutta and Linear Multistep Methods Abstract: The main objective of this series of papers is to explore the entire\nlandscape of numerical methods for fast nonlinear Fourier transformation (NFT)\nwithin the class of integrators known as the exponential integrators. In this\npaper, we explore the theoretical aspects of exponential Runge-Kutta (RK) and\nlinear multistep (LM) methods, in particular, the stability and convergence of\nthese methods via the transfer matrix formulation. The analysis carried out in\nthe paper shows that while the exponential LM methods are naturally amenable to\nFFT-based fast polynomial arithmetic, the RK methods require equispaced nodes\nto achieve that. Therefore, each these family of methods is capable of yielding\na family of fast NFT algorithms such that the scattering coefficients can be\ncomputed with a complexity of $\\mathscr{O}(N\\log^2N)$ and a rate of convergence\ngiven by $\\mathscr{O}(N^{-p})$ where $N$ is the number of samples of the signal\nand $p$ is order of the underlying discretization scheme. Further, while RK\nmethods can accommodate vanishing as well as periodic boundary conditions, the\nLM methods can only handle the former type of boundary conditions without\nrequiring a starting procedure. The ideas presented in this paper extend\nnaturally to the family of integrators known as general linear methods which\nwill be explored in a forthcoming paper. \n\n"}
{"id": "1812.04806", "contents": "Title: A Discontinuous Galerkin Method for the Stokes Equation by\n  Divergence-free Patch Reconstruction Abstract: A discontinuous Galerkin method by patch reconstruction is proposed for\nStokes flows. A locally divergence-free reconstruction space is employed as the\napproximation space, and the interior penalty method is adopted which imposes\nthe normal component penalty terms to cancel out the pressure term.\nConsequently, the Stokes equation can be solved as an elliptic system instead\nof a saddle-point problem due to such weak form. The number of degree of\nfreedoms of our method is the same as the number of elements in the mesh for\ndifferent order of accuracy. The error estimations of the proposed method are\ngiven in a classical style, which are then verified by some numerical examples. \n\n"}
{"id": "1812.05208", "contents": "Title: A stable added-mass partitioned (AMP) algorithm for elastic solids and\n  incompressible flow Abstract: A stable added-mass partitioned (AMP) algorithm is developed for\nfluid-structure interaction (FSI) problems involving viscous incompressible\nflow and compressible elastic solids. Deforming composite grids are used to\neffectively handle the evolving geometry and large deformations. The fluid is\nupdated with an implicit-explicit (IMEX) fractional-step scheme whereby the\nvelocity is advanced in one step, treating the viscous terms implicitly, and\nthe pressure is computed in a second step. The AMP interface conditions for the\nfluid arise from the outgoing characteristic variables in the solid and are\npartitioned into a Robin (mixed) interface condition for the pressure, and\ninterface conditions for the velocity. The latter conditions include an\nimpedance-weighted average between fluid and solid velocities using a fluid\nimpedance of a special form. A similar impedance-weighted average is used to\ndefine interface values for the solid. The new algorithm is verified for\naccuracy and stability on a number of useful benchmark problems including a\nradial-piston problem where exact solutions for radial and azimuthal motions\nare found and tested. Traveling wave exact solutions are also derived and\nnumerically verified for a solid disk surrounded by an annulus of fluid. Fluid\nflow in a channel past a deformable solid annulus is computed and errors are\nestimated from a self-convergence grid refinement study. The AMP scheme is\nfound to be stable and second-order accurate even for very difficult cases of\nvery light solids. \n\n"}
{"id": "1812.05823", "contents": "Title: High accuracy analysis of a nonconforming discrete Stokes complex over\n  rectangular meshes Abstract: This work is devoted to the high accuracy analysis of a discrete Stokes\ncomplex over rectangular meshes with a simple structure. The 0-form in the\ncomplex is a non $C^0$ nonconforming element space for biharmonic problems.\nThis plate element contains only 12 degrees of freedom (DoFs) over a\nrectangular cell with a zeroth order weak continuity for the normal derivative,\ntherefore only the lowest convergence order can be obtained by a standard\nconsistency error analysis. Nevertheless, we prove that, if the rectangular\nmesh is uniform, an $O(h^2)$ convergence rate in discrete $H^2$-norm will be\nachieved. Moreover, based on a duality argument, it has an $O(h^3)$ convergence\norder in discrete $H^1$-norm if the solution region is convex. The 1-form and\n2-form constitute a divergence-free pair for incompressible flow. We also show\nits higher accuracy than that derived from a usual error estimate under uniform\npartitions, which explains the phenomenon observed in our previous work.\nNumerical tests verify our theoretical results. \n\n"}
{"id": "1812.05967", "contents": "Title: Hypocoercivity and diffusion limit of a finite volume scheme for linear\n  kinetic equations Abstract: In this article, we are interested in the asymptotic analysis of a finite\nvolume scheme for one dimensional linear kinetic equations, with either\nFokker-Planck or linearized BGK collision operator. Thanks to appropriate\nuniform estimates, we establish that the proposed scheme is\nAsymptotic-Preserving in the diffusive limit. Moreover, we adapt to the\ndiscrete framework the hypocoercivity method proposed by [J. Dolbeault, C.\nMouhot and C. Schmeiser, Trans. Amer. Math. Soc., 367, 6 (2015)] to prove the\nexponential return to equilibrium of the approximate solution. We obtain decay\nrates that are bounded uniformly in the diffusive limit.\n  Finally, we present an efficient implementation of the proposed numerical\nschemes, and perform numerous numerical simulations assessing their accuracy\nand efficiency in capturing the correct asymptotic behaviors of the models. \n\n"}
{"id": "1812.06007", "contents": "Title: The PowerURV algorithm for computing rank-revealing full factorizations Abstract: Many applications in scientific computing and data science require the\ncomputation of a rank-revealing factorization of a large matrix. In many of\nthese instances the classical algorithms for computing the singular value\ndecomposition are prohibitively computationally expensive. The randomized\nsingular value decomposition can often be helpful, but is not effective unless\nthe numerical rank of the matrix is substantially smaller than the dimensions\nof the matrix. We introduce a new randomized algorithm for producing\nrank-revealing factorizations based on existing work by Demmel, Dumitriu and\nHoltz [Numerische Mathematik, 108(1), 2007] that excels in this regime. The\nmethod is exceptionally easy to implement, and results in close-to optimal\nlow-rank approximations to a given matrix. The vast majority of floating point\noperations are executed in level-3 BLAS, which leads to high computational\nspeeds. The performance of the method is illustrated via several numerical\nexperiments that directly compare it to alternative techniques such as the\ncolumn pivoted QR factorization, or the QLP method by Stewart. \n\n"}
{"id": "1812.07140", "contents": "Title: Method of Green's potentials for elliptic PDEs in domains with random\n  apertures Abstract: Problems with topological uncertainties appear in many fields ranging from\nnano-device engineering to the design of bridges. In many of such problems, a\npart of the domains boundaries is subjected to random perturbations making\ninefficient conventional schemes that rely on discretization of the whole\ndomain. In this paper, we study elliptic PDEs in domains with boundaries\ncomprised of a deterministic part and random apertures, and apply the method of\nmodified potentials with Green's kernels defined on the deterministic part of\nthe domain. This approach allows to reduce the dimension of the original\ndifferential problem by reformulating it as a boundary integral equation posed\non the random apertures only. The multilevel Monte Carlo method is then applied\nto this modified integral equation and its optimal $\\epsilon^{-2}$ asymptotical\ncomplexity is shown. Finally, we provide the qualitative analysis of the\nproposed technique and support it with numerical results. \n\n"}
{"id": "1812.07167", "contents": "Title: A parallel shared-memory implementation of a high-order accurate\n  solution technique for variable coefficient Helmholtz problems Abstract: The recently developed Hierarchical Poincar\\'e-Steklov (HPS) method is a\nhigh-order discretization technique that comes with a direct solver. Results\nfrom previous papers demonstrate the method's ability to solve Helmholtz\nproblems to high accuracy without the so-called pollution effect. While the\nasymptotic scaling of the direct solver's computational cost is the same as the\nnested dissection method, serial implementations of the solution technique are\nnot practical for large scale numerical simulations. This manuscript presents\nthe first parallel implementation of the HPS method. Specifically, we introduce\nan approach for a shared memory implementation of the solution technique\nutilizing parallel linear algebra. This approach is the foundation for future\nlarge scale simulations on supercomputers and clusters with large memory nodes.\nPerformance results on a desktop computer (resembling a large memory node) are\npresented. \n\n"}
{"id": "1812.07456", "contents": "Title: Electromagnetic surface wave propagation in a metallic wire and the\n  Lambert $W$ function Abstract: We revisit the solution due to Sommerfeld of a problem in classical\nelectrodynamics, namely, that of the propagation of an electromagnetic axially\nsymmetric surface wave (a low-attenuation single TM$_{01}$ mode) in a\ncylindrical metallic wire, and his iterative method to solve the transcendental\nequation that appears in the determination of the propagation wave number from\nthe boundary conditions. We present an elementary analysis of the convergence\nof Sommerfeld's iterative solution of the approximate problem and compare it\nwith both the numerical solution of the exact transcendental equation and the\nsolution of the approximate problem by means of the Lambert $W$ function. \n\n"}
{"id": "1812.08100", "contents": "Title: Sampling discretization error for function classes Abstract: The new ingredient of this paper is that we consider infinitely dimensional\nclasses of functions and instead of the relative error setting, which was used\nin previous papers on norm discretization, we consider the absolute error\nsetting. We demonstrate how known results from two areas of research --\nsupervised learning theory and numerical integration -- can be used in sampling\ndiscretization of the square norm on different function classes. \n\n"}
{"id": "1812.08146", "contents": "Title: The Weak Galerkin methods are rewritings of the Hybridizable\n  Discontinuous Galerkin methods Abstract: We establish that the Weak Galerkin methods are rewritings of the\nhybridizable discontinuous Galerkin methods. \n\n"}
{"id": "1812.08323", "contents": "Title: Isogeometric Collocation Method for the Fractional Laplacian in the 2D\n  Bounded Domain Abstract: We consider the isogeometric analysis for fractional PDEs involving the\nfractional Laplacian in two dimensions. An isogeometric collocation method is\ndeveloped to discretize the fractional Laplacian and applied to the fractional\nPoisson problem and the time-dependent fractional porous media equation.\nNumerical studies exhibit monotonous convergence with a rate of\n$\\mathcal{O}(N^{-1})$, where $N$ is the degrees of freedom. A comparison with\nfinite element analysis shows that the method enjoys higher accuracy per degree\nof freedom and has a better convergence rate. We demonstrate that isogeometric\nanalysis offers a novel and promising computational tool for nonlocal problems. \n\n"}
{"id": "1812.08413", "contents": "Title: Compressed sensing and Sequential Monte Carlo for solar hard X-ray\n  imaging Abstract: We describe two inversion methods for the reconstruction of hard X-ray solar\nimages. The methods are tested against experimental visibilities recorded by\nthe Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI) and synthetic\nvisibilities based on the design of the Spectrometer/Telescope for Imaging\nX-rays (STIX). \n\n"}
{"id": "1812.08723", "contents": "Title: A Universal Sampling Method for Reconstructing Signals with Simple\n  Fourier Transforms Abstract: Reconstructing continuous signals from a small number of discrete samples is\na fundamental problem across science and engineering. In practice, we are often\ninterested in signals with 'simple' Fourier structure, such as bandlimited,\nmultiband, and Fourier sparse signals. More broadly, any prior knowledge about\na signal's Fourier power spectrum can constrain its complexity. Intuitively,\nsignals with more highly constrained Fourier structure require fewer samples to\nreconstruct.\n  We formalize this intuition by showing that, roughly, a continuous signal\nfrom a given class can be approximately reconstructed using a number of samples\nproportional to the *statistical dimension* of the allowed power spectrum of\nthat class. Further, in nearly all settings, this natural measure tightly\ncharacterizes the sample complexity of signal reconstruction.\n  Surprisingly, we also show that, up to logarithmic factors, a universal\nnon-uniform sampling strategy can achieve this optimal complexity for *any\nclass of signals*. We present a simple and efficient algorithm for recovering a\nsignal from the samples taken. For bandlimited and sparse signals, our method\nmatches the state-of-the-art. At the same time, it gives the first\ncomputationally and sample efficient solution to a broad range of problems,\nincluding multiband signal reconstruction and kriging and Gaussian process\nregression tasks in one dimension.\n  Our work is based on a novel connection between randomized linear algebra and\nsignal reconstruction with constrained Fourier structure. We extend tools based\non statistical leverage score sampling and column-based matrix reconstruction\nto the approximation of continuous linear operators that arise in signal\nreconstruction. We believe that these extensions are of independent interest\nand serve as a foundation for tackling a broad range of continuous time\nproblems using randomized methods. \n\n"}
{"id": "1812.09284", "contents": "Title: Adaptive algorithm for electronic structure calculations using reduction\n  of Gaussian mixtures Abstract: We present a new adaptive method for electronic structure calculations based\non novel fast algorithms for reduction of multivariate mixtures. In our\ncalculations, spatial orbitals are maintained as Gaussian mixtures whose terms\nare selected in the process of solving equations.\n  Using a fixed basis leads to the so-called \"basis error\" since orbitals may\nnot lie entirely within the linear span of the basis. To avoid such an error,\nmultiresolution bases are used in adaptive algorithms so that basis functions\nare selected from a fixed collection of functions, large enough as to\napproximate solutions within any user-selected accuracy.\n  Our new method achieves adaptivity without using a multiresolution basis.\nInstead, as a part of an iteration to solve nonlinear equations, our algorithm\nselects the \"best\" subset of linearly independent terms of a Gaussian mixture\nfrom a collection that is much larger than any possible basis since the\nlocations and shapes of the Gaussian terms are not fixed in advance.\nApproximating an orbital within a given accuracy, our algorithm yields\nsignificantly fewer terms than methods using multiresolution bases.\n  We demonstrate our approach by solving the Hartree-Fock equations for two\ndiatomic molecules, HeH+ and LiH, matching the accuracy previously obtained\nusing multiwavelet bases. \n\n"}
{"id": "1812.10165", "contents": "Title: ART: adaptive residual--time restarting for Krylov subspace matrix\n  exponential evaluations Abstract: In this paper a new restarting method for Krylov subspace matrix exponential\nevaluations is proposed. Since our restarting technique essentially employs the\nresidual, some convergence results for the residual are given. We also discuss\nhow the restart length can be adjusted after each restart cycle, which leads to\nan adaptive restarting procedure. Numerical tests are presented to compare our\nrestarting with three other restarting methods. Some of the algorithms\ndescribed in this paper are a part of the Octave/Matlab package expmARPACK\navailable at http://team.kiam.ru/botchev/expm/. \n\n"}
{"id": "1812.11194", "contents": "Title: Error estimates for a tree structure algorithm solving finite horizon\n  control problems Abstract: In the Dynamic Programming approach to optimal control problems a crucial\nrole is played by the value function that is characterized as the unique\nviscosity solution of a Hamilton-Jacobi-Bellman (HJB) equation. It is well\nknown that this approach suffers of the \"curse of dimensionality\" and this\nlimitation has reduced its practical in real world applications. Here we\nanalyze a dynamic programming algorithm based on a tree structure. The tree is\nbuilt by the time discrete dynamics avoiding in this way the use of a fixed\nspace grid which is the bottleneck for high-dimensional problems, this also\ndrops the projection on the grid in the approximation of the value function. We\npresent some error estimates for a first order approximation based on the\ntree-structure algorithm. Moreover, we analyze a pruning technique for the tree\nto reduce the complexity and minimize the computational effort. Finally, we\npresent some numerical tests. \n\n"}
{"id": "1812.11519", "contents": "Title: Two-scale methods for convex envelopes Abstract: We develop two-scale methods for computing the convex envelope of a\ncontinuous function over a convex domain in any dimension.This hinges on a\nfully nonlinear obstacle formulation [A. M. Oberman, \"The convex envelope is\nthe solution of a nonlinear obstacle problem\", Proc. Amer. Math. Soc.\n135(6):1689--1694, 2007]. We prove convergence and error estimates in the max\nnorm. The proof utilizes a discrete comparison principle, a discrete barrier\nargument to deal with Dirichlet boundary values, and the property of flatness\nin one direction within the non-contact set. Our error analysis extends to a\nmodified version of the finite difference wide stencil method of [A. M.\nOberman, \"Computing the convex envelope using a nonlinear partial differential\nequation\", Math. Models Meth. Appl. Sci, 18(05):759--780, 2008]. \n\n"}
{"id": "1901.00107", "contents": "Title: Symmetric integrators based on continuous-stage Runge-Kutta-Nystrom\n  methods for reversible systems Abstract: In this paper, we study symmetric integrators for solving second-order\nordinary differential equations on the basis of the notion of continuous-stage\nRunge-Kutta-Nystrom methods. The construction of such methods heavily relies on\nthe Legendre expansion technique in conjunction with the symmetric conditions\nand simplifying assumptions for order conditions. New families of symmetric\nintegrators as illustrative examples are presented. For comparing the numerical\nbehaviors of the presented methods, some numerical experiments are also\nreported. \n\n"}
{"id": "1901.00682", "contents": "Title: A Finite Element Nonoverlapping Domain Decomposition Method with\n  Lagrange Multipliers for the Dual Total Variation Minimizations Abstract: In this paper, we consider a primal-dual domain decomposition method for\ntotal variation regularized problems appearing in mathematical image\nprocessing. The model problem is transformed into an equivalent constrained\nminimization problem by tearing-and-interconnecting domain decomposition. Then,\nthe continuity constraints on the subdomain interfaces are treated by\nintroducing Lagrange multipliers. The resulting saddle point problem is solved\nby the first order primal-dual algorithm. We apply the proposed method to image\ndenoising, inpainting, and segmentation problems with either $L^2$-fidelity or\n$L^1$-fidelity. Numerical results show that the proposed method outperforms the\nexisting state-of-the-art methods. \n\n"}
{"id": "1901.00759", "contents": "Title: Isogeometric Mortar Coupling for Electromagnetic Problems Abstract: This paper discusses and analyses two domain decomposition approaches for\nelectromagnetic problems that allow the combination of domains discretised by\neither N\\'ed\\'elec-type polynomial finite elements or spline-based isogeometric\nanalysis. The first approach is a new isogeometric mortar method and the second\none is based on a modal basis for the Lagrange multiplier space, called\nstate-space concatenation in the engineering literature. Spectral correctness\nand in particular inf-sup stability of both approaches are analytically and\nnumerically investigated. The new mortar method is shown to be unconditionally\nstable. Its construction of the discrete Lagrange multiplier space takes\nadvantage of the high continuity of splines, and does not have an analogue for\nN\\'ed\\'elec finite elements. On the other hand, the approach with modal basis\nis easier to implement but relies on application knowledge to ensure stability\nand correctness. \n\n"}
{"id": "1901.00792", "contents": "Title: An estimate of Green's function of the problem of bounded solutions in\n  the case of a triangular coefficient Abstract: An estimate of Green's function of the bounded solutions problem for the\nordinary differential equation $x'(t)-Bx(t)=f(t)$ is proposed. It is assumed\nthat the matrix coefficient $B$ is triangular. This estimate is a\ngeneralization of the estimate of the matrix exponential proved by Ch. F. Van\nLoan. \n\n"}
{"id": "1901.00917", "contents": "Title: A nonlinear thermomechanical formulation for anisotropic volume and\n  surface continua Abstract: A thermomechanical, polar continuum formulation under finite strains is\nproposed for anisotropic materials using a multiplicative decomposition of the\ndeformation gradient. First, the kinematics and conservation laws for three\ndimensional, polar and non-polar continua are obtained. Next, these kinematics\nare connected to their corresponding counterparts for surface continua based on\nKirchhoff-Love kinematics. Likewise, the conservation laws for Kirchhoff-Love\nshells are derived from their three dimensional counterparts. From this, the\nweak forms are obtained for three dimensional non-polar continua and\nKirchhoff-Love shells. These formulations are expressed in tensorial form so\nthat they can be used in both curvilinear and Cartesian coordinates. They can\nbe used to model anisotropic crystals and soft biological materials, and they\ncan be extended to other field equations, like Maxwell's equations to model\nthermo-electro-magneto-mechanical materials. \n\n"}
{"id": "1901.01044", "contents": "Title: Shape reconstruction of a conductivity inclusion using the Faber\n  polynomials Abstract: We consider the shape reconstruction of a conductivity inclusion in two\ndimensions. We use the concept of Faber polynomials Polarization Tensors (FPTs)\nintroduced in \\cite{choi:2018:GME} to derive an exact shape recovery formula\nfor an inclusion with the extreme conductivity. This shape can be a good\ninitial guess in the shape recovery optimization for an inclusion with either\nsmall or large conductivity values. We illustrate and validate our results with\nnumerical examples. \n\n"}
{"id": "1901.01206", "contents": "Title: Adaptive asynchronous time-stepping, stopping criteria, and a posteriori\n  error estimates for fixed-stress iterative schemes for coupled poromechanics\n  problems Abstract: In this paper we develop adaptive iterative coupling schemes for the Biot\nsystem modeling coupled poromechanics problems. We particularly consider the\nspace-time formulation of the fixed-stress iterative scheme, in which we first\nsolve the problem of flow over the whole space-time interval, then exploiting\nthe space-time information for solving the mechanics. Two common\ndiscretizations of this algorithm are then introduced based on two coupled\nmixed finite element methods in-space and the backward Euler scheme in-time.\nTherefrom, adaptive fixed-stress algorithms are build on conforming\nreconstructions of the pressure and displacement together with equilibrated\nflux and stresses reconstructions. These ingredients are used to derive a\nposteriori error estimates for the fixed-stress algorithms, distinguishing the\ndifferent error components, namely the spatial discretization, the temporal\ndiscretization, and the fixed-stress iteration components. Precisely, at the\niteration $k\\geq 1$ of the adaptive algorithm, we prove that our estimate gives\na guaranteed and fully computable upper bound on the energy-type error\nmeasuring the difference between the exact and approximate pressure and\ndisplacement. These error components are efficiently used to design adaptive\nasynchronous time-stepping and adaptive stopping criteria for the fixed-stress\nalgorithms. Numerical experiments illustrate the efficiency of our estimates\nand the performance of the adaptive iterative coupling algorithms. \n\n"}
{"id": "1901.02264", "contents": "Title: Symmetry-preserving finite-difference discretizations of arbitrary order\n  on structured curvilinear staggered grids Abstract: Symmetry-preserving (mimetic) discretization aims to preserve certain\nproperties of a continuous differential operator in its discrete counterpart.\nFor these discretizations, stability and (discrete) conservation of mass,\nmomentum and energy are proven in the same way as for the original continuous\nmodel.\n  This paper presents a new finite-difference symmetry-preserving space\ndiscretization. Boundary conditions and time integration are not addressed. The\nnovelty is that it combines arbitrary order of convergence, orthogonal and\nnon-orthogonal structured curvilinear staggered meshes, and the applicability\nto a wide variety of continuous operators, involving chain rules and nonlinear\nadvection, as illustrated by the shallow-water equations.\n  Experiments show exact conservation and convergence corresponding to expected\norder. \n\n"}
{"id": "1901.02520", "contents": "Title: Lattice Identification and Separation: Theory and Algorithm Abstract: Motivated by lattice mixture identification and grain boundary detection, we\npresent a framework for lattice pattern representation and comparison, and\npropose an efficient algorithm for lattice separation. We define new scale and\nshape descriptors, which helps to considerably reduce the size of equivalence\nclasses of lattice bases. These finitely many equivalence relations are fully\ncharacterized by modular group theory. We construct the lattice space\n$\\mathscr{L}$ based on the equivalent descriptors and define a metric\n$d_{\\mathscr{L}}$ to accurately quantify the visual similarities and\ndifferences between lattices. Furthermore, we introduce the Lattice\nIdentification and Separation Algorithm (LISA), which identifies each lattice\npatterns from superposed lattices. LISA finds lattice candidates from the high\nresponses in the image spectrum, then sequentially extracts different layers of\nlattice patterns one by one. Analyzing the frequency components, we reveal the\nintricate dependency of LISA's performances on particle radius, lattice\ndensity, and relative translations. Various numerical experiments are designed\nto show LISA's robustness against a large number of lattice layers, moir\\'{e}\npatterns and missing particles. \n\n"}
{"id": "1901.03453", "contents": "Title: The Fourier extension method and discrete orthogonal polynomials on an\n  arc of the circle Abstract: The Fourier extension method, also known as the Fourier continuation method,\nis a method for approximating non-periodic functions on an interval using\ntruncated Fourier series with period larger than the interval on which the\nfunction is defined. When the function being approximated is known at only\nfinitely many points, the approximation is constructed as a projection based on\nthis discrete set of points. In this paper we address the issue of estimating\nthe absolute error in the approximation. The error can be expressed in terms of\na system of discrete orthogonal polynomials on an arc of the unit circle, and\nthese polynomials are then evaluated asymptotically using Riemann--Hilbert\nmethods. \n\n"}
{"id": "1901.03780", "contents": "Title: On non-parametric density estimation on linear and non-linear manifolds\n  using generalized Radon transforms Abstract: Here we present a new non-parametric approach to density estimation and\nclassification derived from theory in Radon transforms and image\nreconstruction. We start by constructing a \"forward problem\" in which the\nunknown density is mapped to a set of one dimensional empirical distribution\nfunctions computed from the raw input data. Interpreting this mapping in terms\nof Radon-type projections provides an analytical connection between the data\nand the density with many very useful properties including stable\ninvertibility, fast computation, and significant theoretical grounding. Using\nresults from the literature in geometric inverse problems we give uniqueness\nresults and stability estimates for our methods. We subsequently extend the\nideas to address problems in manifold learning and density estimation on\nmanifolds. We introduce two new algorithms which can be readily applied to\nimplement density estimation using Radon transforms in low dimensions or on low\ndimensional manifolds embedded in $\\mathbb{R}^d$. We test our algorithms\nperformance on a range of synthetic 2-D density estimation problems, designed\nwith a mixture of sharp edges and smooth features. We show that our algorithm\ncan offer a consistently competitive performance when compared to the\nstate-of-the-art density estimation methods from the literature. \n\n"}
{"id": "1901.03840", "contents": "Title: Uncertainty in marine weather routing Abstract: Weather routing methods are essential for planning routes for commercial\nshipping and recreational craft. This paper provides a methodology for\nquantifying the significance of numerical error and performance model\nuncertainty on the predictions returned from a weather routing algorithm. The\nnumerical error of the routing algorithm is estimated by solving the optimum\npath over different discretizations of the environment. The uncertainty\nassociated with the performance model is linearly varied in order to quantify\nits significance. The methodology is applied to a sailing craft routing\nproblem: the prediction of the voyaging time for an ethnographic voyaging canoe\nacross long distance voyages in Polynesia. We find that the average numerical\nerror is $0.396\\%$, corresponding to $1.05$ hours for an average voyage length\nof $266.40$ hours. An uncertainty level of $2.5 \\%$ in the performance model is\nseen to correspond to a standard deviation of $\\pm 2.41-3.08\\%$ of the voyaging\ntime. These results illustrate the significance of considering the influence of\nnumerical error and performance uncertainty when performing a weather routing\nstudy. \n\n"}
{"id": "1901.04648", "contents": "Title: A mass conserving mixed stress formulation for Stokes flow with weakly\n  imposed stress symmetry Abstract: We introduce a new discretization of a mixed formulation of the\nincompressible Stokes equations that includes symmetric viscous stresses. The\nmethod is built upon a mass conserving mixed formulation that we recently\nstudied. The improvement in this work is a new method that directly\napproximates the viscous fluid stress $\\sigma$, enforcing its symmetry weakly.\nThe finite element space in which the stress is approximated consists of\nmatrix-valued functions having continuous \"normal-tangential\" components across\nelement interfaces. Stability is achieved by adding certain matrix bubbles that\nwere introduced earlier in the literature on finite elements for linear\nelasticity. Like the earlier work, the new method here approximates the fluid\nvelocity $u$ using $H(\\operatorname{div})$-conforming finite elements, thus\nproviding exact mass conservation. Our error analysis shows optimal convergence\nrates for the pressure and the stress variables. An additional post processing\nyields an optimally convergent velocity satisfying exact mass conservation. The\nmethod is also pressure robust. \n\n"}
{"id": "1901.05343", "contents": "Title: A Goal-Oriented Adaptive Discrete Empirical Interpolation Method Abstract: In this study we propose a-posteriori error estimation results to approximate\nthe precision loss in quantities of interests computed using reduced order\nmodels. To generate the surrogate models we employ Proper Orthogonal\nDecomposition and Discrete Empirical Interpolation Method. First order\nexpansions of the components of the quantity of interest obtained as the\nproduct between the components gradient and model residuals are summed up to\ngenerate the error estimation result. Efficient versions are derived for\nexplicit and implicit Euler schemes and require only one reduced forward and\nadjoint models and high-fidelity model residuals estimation. Then we derive an\nadaptive DEIM algorithm to enhance the accuracy of these quantities of\ninterests. The adaptive DEIM algorithm uses dual weighted residuals singular\nvectors in combination with the non-linear term basis. Both the a-posteriori\nerror estimation results and the adaptive DEIM algorithm were assessed using\nthe 1D-Burgers and Shallow Water Equation models and the numerical experiments\nshows very good agreement with the theoretical results. \n\n"}
{"id": "1901.05535", "contents": "Title: Weak convergence rates for temporal numerical approximations of\n  stochastic wave equations with multiplicative noise Abstract: In this work we establish weak convergence rates for temporal discretisations\nof stochastic wave equations with multiplicative noise, in particular, for the\nhyperbolic Anderson model. For this class of stochastic partial differential\nequations the weak convergence rates we obtain are indeed twice the known\nstrong rates. To the best of our knowledge, our findings are the first in the\nscientific literature which provide essentially sharp weak convergence rates\nfor temporal discretisations of stochastic wave equations with multiplicative\nnoise. Key ideas of our proof are a sophisticated splitting of the error and\napplications of the recently introduced mild It\\^{o} formula. We complement our\nanalytical findings by means of numerical simulations in Python for the decay\nof the weak approximation error for SPDEs for four different test functions. \n\n"}
{"id": "1901.06148", "contents": "Title: Strongly Asymptotically Optimal Schemes for the Strong Approximation of\n  Stochastic Differential Equations with respect to the Supremum Error Abstract: Our subject of study is strong approximation of stochastic differential\nequations (SDEs) with respect to the supremum error criterion, and we seek\napproximations that are strongly asymptotically optimal in specific classes of\napproximations. We hereby focus on two principal types of classes, namely, the\nclasses of approximations that are based only on the evaluation of the initial\nvalue and on at most finitely many sequential evaluations of the driving\nBrownian motion on average and the classes of approximations that are based\nonly on the evaluation of the initial value and on finitely many evaluations of\nthe driving Brownian motion at equidistant sites. For SDEs with globally\nLipschitz continuous coefficients, M\\\"uller-Gronbach [Ann. Appl. Probab. 12\n(2002), no. 2, 664-690] showed that specific Euler-Maruyama schemes relating to\nadaptive and to equidistant time discretizations perform strongly\nasymptotically optimal in these classes. In the present article, we generalize\nthese results to a significantly wider class of SDEs, such as ones with\nsuper-linearly growing coefficients. More precisely, we prove strong asymptotic\noptimality for specific coefficient-modified Euler-Maruyama schemes relating to\nadaptive and to equidistant time discretizations under rather mild assumptions\non the underlying SDE. To illustrate our findings, we present two exemplary\napplications - namely, Euler-Maruyama schemes and tamed Euler schemes - and\nthereby analyze the SDE associated with the Heston-$3/2$-model originating from\nmathematical finance. \n\n"}
{"id": "1901.06503", "contents": "Title: Photoacoustic image reconstruction from full field data in heterogeneous\n  media Abstract: We consider image reconstruction in full-field photoacoustic tomography,\nwhere 2D projections of the full 3D acoustic pressure distribution at a given\ntime T>0 are collected. We discuss existing results on the stability and\nuniqueness of the resulting image reconstruction problem and review existing\nreconstruction algorithms. Open challenges are also mentioned. Additionally, we\nintroduce novel one-step reconstruction methods allowing for a variable speed\nof sound. We apply preconditioned iterative and variational regularization\nmethods to the one-step formulation. Numerical results using the one-step\nformulation are presented, together with a comparison with the previous\ntwo-step approach for full-field photoacoustic tomography \n\n"}
{"id": "1901.07758", "contents": "Title: The Neural Network Approach to Inverse Problems in Differential\n  Equations Abstract: We proposed a framework for solving inverse problems in differential\nequations based on neural networks and automatic differentiation. Neural\nnetworks are used to approximate hidden fields. We analyze the source of errors\nin the framework and derive an error estimate for a model diffusion equation\nproblem. Besides, we propose a way for sensitivity analysis, utilizing the\nautomatic differentiation mechanism embedded in the framework. It frees people\nfrom the tedious and error-prone process of deriving the gradients. Numerical\nexamples exhibit consistency with the convergence analysis and error saturation\nis noteworthily predicted. We also demonstrate the unique benefits neural\nnetworks offer at the same time: universal approximation ability, regularizing\nthe solution, bypassing the curse of dimensionality and leveraging efficient\ncomputing frameworks. \n\n"}
{"id": "1901.07892", "contents": "Title: A DLM immersed boundary method based wave-structure interaction solver\n  for high density ratio multiphase flows Abstract: We present a robust immersed boundary (IB) method for high density ratio\nmultiphase flows that is capable of modeling complex wave-structure interaction\n(WSI) problems arising in marine and coastal engineering applications. The\nIB/WSI methodology is enabled by combining the distributed Lagrange multiplier\n(DLM) method of Sharma and Patankar (J Comp Phys, 2005) with a robust level set\nmethod based multiphase flow solver. The fluid solver integrates the\nconservative form of the variable-coefficient incompressible Navier-Stokes\nequations using a hybrid preconditioner and ensures consistent transport of\nmass and momentum at a discrete level. The consistent transport scheme\npreserves the numerical stability of the method in the presence of large\ndensity ratios found in problems involving air, water, and an immersed\nstructure. The air-water interface is captured by the level set method on an\nEulerian grid, whereas the free-surface piercing immersed structure is\nrepresented on a Lagrangian mesh. The fluid-structure interaction (FSI)\ncoupling is mediated via Peskin's regularized delta functions in an implicit\nmanner, which obviates the need to integrate the hydrodynamic stress tensor on\nthe complex surface of the immersed structure. The IB/WSI numerical scheme is\nimplemented within an adaptive mesh refinement (AMR) framework, in which the\nLagrangian structure and the air-water interface are embedded on the finest\nmesh level to capture the thin boundary layers and the vortical structures\narising from WSI. We use a well-balanced force discretization for gravity force\nthat eliminates spurious velocity currents in the hydrostatic limit due to\ndensity variation in the three phases (air, water and solid). An effective wave\ngeneration and absorption technique for a numerical wave tank is presented and\nused to simulate a benchmark case of water wave distortion due to a submerged\nstructure. \n\n"}
{"id": "1901.07977", "contents": "Title: Coupling the reduced-order model and the generative model for an\n  importance sampling estimator Abstract: In this work, we develop an importance sampling estimator by coupling the\nreduced-order model and the generative model in a problem setting of\nuncertainty quantification. The target is to estimate the probability that the\nquantity of interest (QoI) in a complex system is beyond a given threshold. To\navoid the prohibitive cost of sampling a large scale system, the reduced-order\nmodel is usually considered for a trade-off between efficiency and accuracy.\nHowever, the Monte Carlo estimator given by the reduced-order model is biased\ndue to the error from dimension reduction. To correct the bias, we still need\nto sample the fine model. An effective technique to reduce the variance\nreduction is importance sampling, where we employ the generative model to\nestimate the distribution of the data from the reduced-order model and use it\nfor the change of measure in the importance sampling estimator. To compensate\nthe approximation errors of the reduced-order model, more data that induce a\nslightly smaller QoI than the threshold need to be included into the training\nset. Although the amount of these data can be controlled by a posterior error\nestimate, redundant data, which may outnumber the effective data, will be kept\ndue to the epistemic uncertainty. To deal with this issue, we introduce a\nweighted empirical distribution to process the data from the reduced-order\nmodel. The generative model is then trained by minimizing the cross entropy\nbetween it and the weighted empirical distribution. We also introduce a penalty\nterm into the objective function to deal with the overfitting for more\nrobustness. Numerical results are presented to demonstrate the effectiveness of\nthe proposed methodology. \n\n"}
{"id": "1901.09739", "contents": "Title: A Faster Solution to Smale's 17th Problem I: Real Binomial Systems Abstract: Suppose $F:=(f_1,\\ldots,f_n)$ is a system of random $n$-variate polynomials\nwith $f_i$ having degree $\\leq\\!d_i$ and the coefficient of $x^{a_1}_1\\cdots\nx^{a_n}_n$ in $f_i$ being an independent complex Gaussian of mean $0$ and\nvariance $\\frac{d_i!}{a_1!\\cdots a_n!\\left(d_i-\\sum^n_{j=1}a_j \\right)!}$.\nRecent progress on Smale's 17th Problem by Lairez --- building upon seminal\nwork of Shub, Beltran, Pardo, B\\\"{u}rgisser, and Cucker --- has resulted in a\ndeterministic algorithm that finds a single (complex) approximate root of $F$\nusing just $N^{O(1)}$ arithmetic operations on average, where\n$N\\!:=\\!\\sum^n_{i=1}\\frac{(n+d_i)!}{n!d_i!}$ ($=n(n+\\max_i\nd_i)^{O(\\min\\{n,\\max_i d_i)\\}}$) is the maximum possible total number of\nmonomial terms for such an $F$. However, can one go faster when the number of\nterms is smaller, and we restrict to real coefficient and real roots? And can\none still maintain average-case polynomial-time with more general probability\nmeasures?\n  We show the answer is yes when $F$ is instead a binomial system --- a case\nwhose numerical solution is a key step in polyhedral homotopy algorithms for\nsolving arbitrary polynomial systems. We give a deterministic algorithm that\nfinds a real approximate root (or correctly decides there are none) using just\n$O(n^2(\\log(n)+\\log\\max_i d_i))$ arithmetic operations on average. Furthermore,\nour approach allows Gaussians with arbitrary variance. We also discuss briefly\nthe obstructions to maintaining average-case time polynomial in $n\\log \\max_i\nd_i$ when $F$ has more terms. \n\n"}
{"id": "1901.10382", "contents": "Title: Tikhonov Regularization Within Ensemble Kalman Inversion Abstract: Ensemble Kalman inversion is a parallelizable methodology for solving inverse\nor parameter estimation problems. Although it is based on ideas from Kalman\nfiltering, it may be viewed as a derivative-free optimization method. In its\nmost basic form it regularizes ill-posed inverse problems through the subspace\nproperty: the solution found is in the linear span of the initial ensemble\nemployed. In this work we demonstrate how further regularization can be\nimposed, incorporating prior information about the underlying unknown. In\nparticular we study how to impose Tikhonov-like Sobolev penalties. As well as\nintroducing this modified ensemble Kalman inversion methodology, we also study\nits continuous-time limit, proving ensemble collapse; in the language of\nmulti-agent optimization this may be viewed as reaching consensus. We also\nconduct a suite of numerical experiments to highlight the benefits of Tikhonov\nregularization in the ensemble inversion context. \n\n"}
{"id": "1901.10415", "contents": "Title: MgNet: A Unified Framework of Multigrid and Convolutional Neural Network Abstract: We develop a unified model, known as MgNet, that simultaneously recovers some\nconvolutional neural networks (CNN) for image classification and multigrid (MG)\nmethods for solving discretized partial differential equations (PDEs). This\nmodel is based on close connections that we have observed and uncovered between\nthe CNN and MG methodologies. For example, pooling operation and feature\nextraction in CNN correspond directly to restriction operation and iterative\nsmoothers in MG, respectively. As the solution space is often the dual of the\ndata space in PDEs, the analogous concept of feature space and data space\n(which are dual to each other) is introduced in CNN. With such connections and\nnew concept in the unified model, the function of various convolution\noperations and pooling used in CNN can be better understood. As a result,\nmodified CNN models (with fewer weights and hyper parameters) are developed\nthat exhibit competitive and sometimes better performance in comparison with\nexisting CNN models when applied to both CIFAR-10 and CIFAR-100 data sets. \n\n"}
{"id": "1901.10470", "contents": "Title: Bounding the spectral gap for an elliptic eigenvalue problem with\n  uniformly bounded stochastic coefficients Abstract: A key quantity that occurs in the error analysis of several numerical methods\nfor eigenvalue problems is the distance between the eigenvalue of interest and\nthe next nearest eigenvalue. When we are interested in the smallest or\nfundamental eigenvalue, we call this the spectral or fundamental gap. In a\nrecent manuscript [Gilbert et al., arXiv:1808.02639], the current authors,\ntogether with Frances Kuo, studied an elliptic eigenvalue problem with\nhomogeneous Dirichlet boundary conditions, and with coefficients that depend on\nan infinite number of uniformly distributed stochastic parameters. In this\nsetting, the eigenvalues, and in turn the eigenvalue gap, also depend on the\nstochastic parameters. Hence, for a robust error analysis one needs to be able\nto bound the gap over all possible realisations of the parameters, and because\nthe gap depends on infinitely-many random parameters, this is not trivial. This\nshort note presents, in a simplified setting, an important result that was\nshown in the paper above. Namely, that, under certain decay assumptions on the\ncoefficient, the spectral gap of such a random elliptic eigenvalue problem can\nbe bounded away from 0, uniformly over the entire infinite-dimensional\nparameter space. \n\n"}
{"id": "1901.10759", "contents": "Title: Manifold-based B-splines on unstructured meshes Abstract: We introduce new manifold-based splines that are able to exactly reproduce\nB-splines on unstructured surface meshes. Such splines can be used in\nisogeometric analysis (IGA) to represent smooth surfaces of arbitrary topology.\nSince prevalent computer-aided design (CAD) models are composed of\ntensor-product B-spline patches, any IGA suitable construction should be able\nto reproduce B-splines. To achieve this goal, we focus on univariate\nmanifold-based constructions that can reproduce B-splines. The manifold-based\nsplines are constructed by smoothly blending together polynomial interpolants\ndefined on overlapping charts. The proposed constructions automatically\nreproduce B-splines in regular parts of the mesh, with no extraordinary\nvertices, and polynomial basis functions in the remaining parts of the mesh. We\nstudy and compare analytically and numerically the finite element convergence\nof several univariate constructions. The obtained results directly carry over\nto the tensor-product case. \n\n"}
{"id": "1901.10840", "contents": "Title: Approximation to uniform distribution in SO(3) Abstract: Using the theory of determinantal point processes we give upper bounds for\nthe Green and Riesz energies for the rotation group SO(3), with Riesz parameter\nup to 3. The Green function is computed explicitly, and a lower bound for the\nGreen energy is established, enabling comparison of uniform point constructions\non SO(3). The variance of rotation matrices sampled by the determinantal point\nprocess is estimated, and formulas for the L2 -norm of Gegenbauer polynomials\nwith index 2 are deduced, which might be of independent interest. Also a simple\nbut effective algorithm to sample points in SO(3) is given. \n\n"}
{"id": "astro-ph/0012496", "contents": "Title: A Free Boundary Problem in the Theory of the Stars Abstract: We investigate numerically models of the static spherically symmetric\nboson-fermion stars in the scalar-tensor theory of gravity with massive dilaton\nfield. The proper mathematical model of such stars is interpreted as a\nnonlinear two-parametric eigenvalue problem with unknown internal boundary. To\nsolve this problem the Continuous Analogue of Newton Method is used. \n\n"}
{"id": "astro-ph/9906322", "contents": "Title: A class of symplectic integrators with adaptive timestep for separable\n  Hamiltonian systems Abstract: Symplectic integration algorithms are well-suited for long-term integrations\nof Hamiltonian systems because they preserve the geometric structure of the\nHamiltonian flow. However, this desirable property is generally lost when\nadaptive timestep control is added to a symplectic integrator. We describe an\nadaptive-timestep symplectic integrator that can be used if the Hamiltonian is\nthe sum of kinetic and potential energy components and the required timestep\ndepends only on the potential energy (e.g. test-particle integrations in fixed\npotentials). In particular, we describe an explicit, reversible, symplectic,\nleapfrog integrator for a test particle in a near-Keplerian potential; this\nintegrator has timestep proportional to distance from the attracting mass and\nhas the remarkable property of integrating orbits in an inverse-square force\nfield with only \"along-track\" errors; i.e. the phase-space shape of a Keplerian\norbit is reproduced exactly, but the orbital period is in error by O(1/N^2),\nwhere N is the number of steps per period. \n\n"}
{"id": "hep-lat/0306025", "contents": "Title: A note on Neuberger's double pass algorithm Abstract: We analyze Neuberger's double pass algorithm for the matrix-vector\nmultiplication R(H).Y (where R(H) is (n-1,n)-th degree rational polynomial of\npositive definite operator H), and show that the number of floating point\noperations is independent of the degree n, provided that the number of sites is\nmuch larger than the number of iterations in the conjugate gradient. This\nimplies that the matrix-vector product $ (H)^{-1/2} Y \\simeq R^{(n-1,n)}(H)\n\\cdot Y $ can be approximated to very high precision with sufficiently large n,\nwithout noticeably extra costs. Further, we show that there exists a threshold\n$ n_T $ such that the double pass is faster than the single pass for $ n > n_T\n$, where $ n_T \\simeq 12 - 25 $ for most platforms. \n\n"}
{"id": "hep-th/0012189", "contents": "Title: New results for the epsilon-expansion of certain one-, two- and\n  three-loop Feynman diagrams Abstract: For certain dimensionally-regulated one-, two- and three-loop diagrams,\nproblems of constructing the epsilon-expansion and the analytic continuation of\nthe results are studied. In some examples, an arbitrary term of the\nepsilon-expansion can be calculated. For more complicated cases, only a few\nhigher terms in epsilon are obtained. Apart from the one-loop two- and\nthree-point diagrams, the examples include two-loop (mainly on-shell)\npropagator-type diagrams and three-loop vacuum diagrams. As a by-product, some\nnew relations involving Clausen function, generalized log-sine integrals and\ncertain Euler--Zagier sums are established, and some useful results for the\nhypergeometric functions of argument 1/4 are presented. \n\n"}
{"id": "math-ph/0702062", "contents": "Title: Dirichlet integral dual-access collocation-kernel space analytic\n  interpolation for unit disks: DIDACKS I Abstract: This article presents a technique for analytic interpolation over the\nexterior of a unit disk using complex poles in the interior--as well as\ncorresponding techniques for the exterior of a real unit disk and for the\ninterior of a real and complex unit disk. This is accomplished by developing\nspecial kernel spaces labeled dual-access collocation-kernel spaces. Higher\norder pole and logarithmic point source kernels are also considered.\nRelationships to Szego and Bergman kernel theory are addressed. \n\n"}
{"id": "math-ph/0702063", "contents": "Title: Dirichlet integral point-source harmonic interpolation over\n  ${\\mathbb{R}}^3$ spherical interiors: DIDACKS II Abstract: This article addresses the interpolation of harmonic functions over the\ninterior of a $\\mathbb{R}^3$ unit sphere by linear combinations of\nfundamental-solution point-source basis functions, where all the sources are\nassumed to be outside the sphere. Since the source and field points are in\ndifferent domains, the fundamental-solution basis functions are bounded and can\nbe regarded as defining a new type of kernel space that is related to\nreproducing kernel Hilbert space (RKHS), but is different from it and which is\nlabeled a Dirichlet integral dual-access collocation-kernel space (DIDACKS).\nDIDACKS theory has direct implications for the method of fundamental solutions\n(MFS) and some for the fast multipole method (FMM) and boundary element method\n(BEM). \n\n"}
{"id": "math/0108163", "contents": "Title: Interval straight line fitting Abstract: I consider the task of experimental data fitting. Unlike the traditional\napproach I do not try to minimize any functional based on available\nexperimental information, instead the minimization problem is replaced with\nconstraint satisfaction procedure, which produces the interval hull of\nsolutions of desired type. The method, called 'box slicing algorithm', is\ndescribed in details. The results obtained this way need not to be labeled with\nconfidence level of any kind, they are simply certain (guaranteed). The method\neasily handles the case with uncertainties in one or both variables. There is\nno need for, always more or less arbitrary, weighting the experimental data.\nThe approach is directly applicable to other experimental data processing\nproblems like outliers detection or finding the straight line, which is tangent\nto the experimental curve. \n\n"}
{"id": "math/0202236", "contents": "Title: On comparing the writhe of a smooth curve to the writhe of an inscribed\n  polygon Abstract: We find bounds on the difference between the writhing number of a smooth\ncurve, and the writhing number of a polygon inscribed within. The proof is\nbased on an extension of Fuller's difference of writhe formula to the case of\npolygonal curves. The results establish error bounds useful in the computation\nof writhe. \n\n"}
{"id": "math/0207086", "contents": "Title: Implementation of the Combined--Nonlinear Condensation Transformation Abstract: We discuss several applications of the recently proposed combined\nnonlinear-condensation transformation (CNCT) for the evaluation of slowly\nconvergent, nonalternating series. These include certain statistical\ndistributions which are of importance in linguistics, statistical-mechanics\ntheory, and biophysics (statistical analysis of DNA sequences). We also discuss\napplications of the transformation in experimental mathematics, and we briefly\nexpand on further applications in theoretical physics. Finally, we discuss a\nrelated Mathematica program for the computation of Lerch's transcendent. \n\n"}
{"id": "math/0212035", "contents": "Title: Numerical Computation of \\prod_{n=1}^\\infty (1 - tx^n) Abstract: I present and analyze a quadratically convergent algorithm for computing the\ninfinite product \\prod_{n=1}^\\infty (1 - tx^n) for arbitrary complex t and x\nsatisfying |x| < 1, based on the identity \\prod_{n=1}^\\infty (1 - tx^n)\n  = \\sum_{m=0}^\\infty {(-t)^m x^{m(m+1)/2} \\over (1-x)(1-x^2) ... (1-x^m)} due\nto Euler. The efficiency of the algorithm deteriorates as |x| \\uparrow 1, but\nmuch more slowly than in previous algorithms. The key lemma is a two-sided\nbound on the Dedekind eta function at pure imaginary argument, \\eta(iy), that\nis sharp at the two endpoints y=0,\\infty and is accurate to within 9.1% over\nthe entire interval 0 < y < \\infty. \n\n"}
{"id": "math/0402178", "contents": "Title: Spectral Properties of Numerical Differentiation Abstract: We study the numerical differentiation formulae for functions given in grids\nwith arbitrary number of nodes. We investigate the case of the infinite number\nof points in the formulae for the calculation of the first and the second\nderivatives. The spectra of the corresponding weight coefficients sequences are\nobtained. We examine the first derivative calculation of a function given in\nodd-number points and analyze the spectra of the weight coefficients sequences\nin the cases of both finite and infinite number of nodes. We derive the\none-sided approximation for the first derivative and examine its spectral\nproperties. \n\n"}
{"id": "math/0408360", "contents": "Title: Special moments Abstract: In this article, we show that a linear combination $X$ of $n$ independent,\nunbiased Bernoulli random variables $\\{X_k\\}$ can match the first $2n$ moments\nof a random variable $Y$ which is uniform on an interval. More generally, for\neach $p \\ge 2$, each $X_k$ can be uniform on an arithmetic progression of\nlength $p$. All values of $X$ lie in the range of $Y$, and their ordering as\nreal numbers coincides with dictionary order on the vector $(X_1,...,X_n)$.\n  The construction involves the roots of truncated $q$-exponential series. It\napplies to a construction in numerical cubature using error-correcting codes\n[arXiv:math.NA/0402047]. For example, when $n=2$ and $p=2$, the values of $X$\nare the 4-point Chebyshev quadrature formula. \n\n"}
{"id": "math/0410186", "contents": "Title: Boundary value problems and layer potentials on manifolds with\n  cylindrical ends Abstract: We extend the method of layer potentials to manifolds with boundary and\ncylindrical ends. To obtain this extension along the classical lines, we have\nto deal with several technical difficulties due to the non-compactness of the\nboundary, which prevents us from using the standard characterization of\nFredholm and compact (pseudo-)differential operators between Sobolev spaces.\nOur approach, which involves the study of layer potentials depending on a\nparameter on compact manifolds as an intermediate step, yields the\ninvertibility of the relevant boundary integral operators in the global,\nnon-compact setting, which is rather unexpected. As an application, we prove\nthe well-posedness of the non-homogeneous Dirichlet problem on manifolds with\nboundary and cylindrical ends. We also prove the existence of the\nDirichlet-to-Neumann map, which we show to be a pseudodifferential operator in\nthe calculus of pseudodifferential operators that are ``almost translation\ninvariant at infinity,'' a calculus that is closely related to Melrose's\nb-calculus \\cite{me81, meaps}, which we study in this paper. The proof of the\nconvergence of the layer potentials and of the existence of the\nDirichlet-to-Neumann map are based on a good understanding of resolvents of\nelliptic operators that are translation invariant at infinity. \n\n"}
{"id": "math/0410310", "contents": "Title: Higher order accuracy in the gap-tooth scheme for large-scale solutions\n  using microscopic simulators Abstract: We are developing a framework for multiscale computation which enables models\nat a ``microscopic'' level of description, for example Lattice Boltzmann, Monte\nCarlo or Molecular Dynamics simulators, to perform modelling tasks at the\n``macroscopic'' length scales of interest. The plan is to use the microscopic\nrules restricted to small patches of the domain, the ``teeth'', followed by\ninterpolation to estimate macroscopic fields in the ``gaps''. The challenge\naddressed here is to find general boundary conditions for the patches of\nmicroscopic simulators that appropriately connect the widely separated\n``teeth'' to achieve high order accuracy over the macroscale. Here we start\nexploring the issues in the simplest case when the microscopic simulator is the\nquintessential example of a partial differential equation. For this case\nanalytic solutions provide comparisons. We argue that classic high-order\ninterpolation provides patch boundary conditions which achieve arbitrarily\nhigh-order consistency in the gap-tooth scheme, and with care are numerically\nstable. The high-order consistency is demonstrated on a class of linear partial\ndifferential equations in two ways: firstly using the dynamical systems\napproach of holistic discretisation; and secondly through the eigenvalues of\nselected numerical problems. When applied to patches of microscopic simulations\nthese patch boundary conditions should achieve efficient macroscale simulation. \n\n"}
{"id": "math/0412493", "contents": "Title: The asymptotics of Wilkinson's shift iteration Abstract: We study the rate of convergence of Wilkinson's shift iteration acting on\nJacobi matrices with simple spectrum. We show that for AP-free spectra (i.e.,\nsimple spectra containing no arithmetic progression with 3 terms), convergence\nis cubic. In order 3, there exists a tridiagonal symmetric matrix P_0 which is\nthe limit of a sequence of a Wilkinson iteration, with the additional property\nthat all iterations converging to P_0 are strictly quadratic. Among tridiagonal\nmatrices near P_0, the set X of initial conditions with convergence to P_0 is\nrather thin: it is a union of disjoint arcs X_s meeting at P_0, where s ranges\nover the Cantor set of sign sequences s: N -> {1,-1}. Wilkinson's step takes\nX_s to X_{s'}, where s' is the left shift of s. Among tridiagonal matrices\nconjugate to P_0, initial conditions near P_0 but not in X converge at a cubic\nrate. \n\n"}
{"id": "math/0508330", "contents": "Title: Discrete Routh Reduction Abstract: This paper develops the theory of abelian Routh reduction for discrete\nmechanical systems and applies it to the variational integration of mechanical\nsystems with abelian symmetry. The reduction of variational Runge-Kutta\ndiscretizations is considered, as well as the extent to which symmetry\nreduction and discretization commute. These reduced methods allow the direct\nsimulation of dynamical features such as relative equilibria and relative\nperiodic orbits that can be obscured or difficult to identify in the unreduced\ndynamics. The methods are demonstrated for the dynamics of an Earth orbiting\nsatellite with a non-spherical $J_2$ correction, as well as the double\nspherical pendulum. The $J_2$ problem is interesting because in the unreduced\npicture, geometric phases inherent in the model and those due to numerical\ndiscretization can be hard to distinguish, but this issue does not appear in\nthe reduced algorithm, where one can directly observe interesting dynamical\nstructures in the reduced phase space (the cotangent bundle of shape space), in\nwhich the geometric phases have been removed. The main feature of the double\nspherical pendulum example is that it has a nontrivial magnetic term in its\nreduced symplectic form. Our method is still efficient as it can directly\nhandle the essential non-canonical nature of the symplectic structure. In\ncontrast, a traditional symplectic method for canonical systems could require\nrepeated coordinate changes if one is evoking Darboux' theorem to transform the\nsymplectic structure into canonical form, thereby incurring additional\ncomputational cost. Our method allows one to design reduced symplectic\nintegrators in a natural way, despite the noncanonical nature of the symplectic\nstructure. \n\n"}
{"id": "math/0510070", "contents": "Title: DSC Approach to Computational Fluid Dynamics Abstract: This paper presents the Dual Scattering Channel numerical solution of the\nNavier-Stokes Equations for quasi-incompressible flow in the\nOberbeck-Boussinesq approximation. The implementation in hexahedral\nnon-orthogonal mesh is outlined. A numerical example illustrates the approach. \n\n"}
{"id": "math/0512457", "contents": "Title: The spectral approximation of multiplication operators via asymptotic\n  (structured) linear algebra Abstract: multiplication operator on a Hilbert space may be approximated with finite\nsections by choosing an orthonormal basis of the Hilbert space. Nonzero\nmultiplication operators on $L^2$ spaces of functions are never compact and\nthen such approximations cannot converge in the norm topology. Instead, we\nconsider how well the spectra of the finite sections approximate the spectrum\nof the multiplication operator whose expression is simply given by the\nessential range of the symbol (i.e. the multiplier). We discuss the case of\nreal orthogonal polynomial bases and the relations with the classical Fourier\nbasis whose choice leads to well studied Toeplitz case. The use of circulant\napproximations leads to constructive algorithms working for the separable\nmultivariate and matrix-valued cases as well. \n\n"}
{"id": "math/0512545", "contents": "Title: The a priori tan\\theta theorem for eigenvectors Abstract: Let $A$ be a self-adjoint operator on a Hilbert space $\\fH$. Assume that the\nspectrum of $A$ consists of two disjoint components $\\sigma_0$ and $\\sigma_1$\nsuch that the convex hull of the set $\\sigma_0$ does not intersect the set\n$\\sigma_1$. Let $V$ be a bounded self-adjoint operator on $\\fH$ off-diagonal\nwith respect to the orthogonal decomposition $\\fH=\\fH_0\\oplus\\fH_1$ where\n$\\fH_0$ and $\\fH_1$ are the spectral subspaces of $A$ associated with the\nspectral sets $\\sigma_0$ and $\\sigma_1$, respectively. It is known that if\n$\\|V\\|<\\sqrt{2}d$ where $d=\\dist(\\sigma_0,\\sigma_1)>0$ then the perturbation\n$V$ does not close the gaps between $\\sigma_0$ and $\\sigma_1$. Assuming that\n$f$ is an eigenvector of the perturbed operator $A+V$ associated with its\neigenvalue in the interval $(\\min(\\sigma_0)-d,\\max(\\sigma_0)+d)$ we prove that\nunder the condition $\\|V\\|<\\sqrt{2}d$ the (acute) angle $\\theta$ between $f$\nand the orthogonal projection of $f$ onto $\\fH_0$ satisfies the bound\n$\\tan\\theta\\leq\\frac{\\|V\\|}{d}$ and this bound is sharp. \n\n"}
{"id": "math/0601389", "contents": "Title: The polynomial method for random matrices Abstract: We define a class of \"algebraic\" random matrices. These are random matrices\nfor which the Stieltjes transform of the limiting eigenvalue distribution\nfunction is algebraic, i.e., it satisfies a (bivariate) polynomial equation.\nThe Wigner and Wishart matrices whose limiting eigenvalue distributions are\ngiven by the semi-circle law and the Marcenko-Pastur law are special cases.\nAlgebraicity of a random matrix sequence is shown to act as a certificate of\nthe computability of the limiting eigenvalue density function. The limiting\nmoments of algebraic random matrix sequences, when they exist, are shown to\nsatisfy a finite depth linear recursion so that they may often be efficiently\nenumerated in closed form.\n  In this article, we develop the mathematics of the polynomial method which\nallows us to describe the class of algebraic matrices by its generators and map\nthe constructive approach we employ when proving algebraicity into a software\nimplementation that is available for download in the form of the RMTool random\nmatrix \"calculator\" package. Our characterization of the closure of algebraic\nprobability distributions under free additive and multiplicative convolution\noperations allows us to simultaneously establish a framework for computational\n(non-commutative) \"free probability\" theory. We hope that the tools developed\nallow researchers to finally harness the power of the infinite random matrix\ntheory. \n\n"}
{"id": "math/0602019", "contents": "Title: The algebra of the box spline Abstract: In this paper we want to revisit results of Dahmen and Micchelli on\nbox-splines which we reinterpret and make more precise. We compare these ideas\nwith the work of Brion, Szenes, Vergne and others on polytopes and partition\nfunctions. \n\n"}
{"id": "math/0605565", "contents": "Title: Riemann Hypothesis: The Riesz-Hardy-Littlewood wave in the long\n  wavelength region Abstract: We present the results of numerical experiments in connection with the Riesz\nand Hardy-Littlewood criteria for the truth of the Riemann Hypothesis (RH). The\ncoefficients c_k of the Pochammer's expansion for the reciprocal of the Riemann\nZeta function, as well as the ``critical functions'' c_k*k^a (where a is some\nconstant), are analyzed at relatively large values of k. It appears an\noscillatory behaviour (Riesz-Hardy-Littlewood wave). The amplitudes and the\nwavelength of the wave are compared with an analytical treatment concerning the\nwave in the asymptotic region. The agreement is satisfactory. We then find\nnumerically that in the large beta limit too, the amplitudes of the waves\nappear to be bounded. For a special case the numerical experiments are\nperformed up to larger values of k, i.e k=10^9 and more. The analysis suggests\nthat RH may barely be true and an absolute bound for the amplitudes of the\nwaves in all cases should be given by |1/(zeta(1/2)+epsilon) -1|, with epsilon\narbitrarily small positive, i.e. equal to 1.68 \n\n"}
{"id": "math/0606445", "contents": "Title: On a differential equation for a gas bubbles collapse mathematical model Abstract: In this paper we present a mathematical model for estimate the collapse time\nof a gas bubble in a vane of a oil gerotor pump. This amount of time cannot be\ngreater of the total time spent by the pump for filling and then emptying out a\nvane in a single revolution, otherwise there is a loss of lubrication between\ninternal and external gears. We assume that oil is incompressible and viscous,\nthe bubble has a spherical shape and it is not translating into the external\nfluid. The analytical treatment of the model shows that the Navier-Stokes\nequations for the velocity field of the oil can be reduced to a single non\nlinear ordinary differential equation for the variation in time of the bubble\nradius. The collapse time estimated by a numerical resolution of this equation\nand the collapse time calculated from an analytical resolution of the\nlinearized equation are substantially equal. \n\n"}
{"id": "math/0609094", "contents": "Title: Pade and Hermite-Pade approximation and orthogonality Abstract: We give a short introduction to Pade approximation (rational approximation to\na function with close contact at one point) and to Hermite-Pade approximation\n(simultaneous rational approximation to several functions with close contact at\none point) and show how orthogonality plays a crucial role. We give some\ninsight into how logarithmic potential theory helps in describing the\nasymptotic behavior and the convergence properties of Pade and Hermite-Pade\napproximation. \n\n"}
{"id": "math/0611420", "contents": "Title: On convergence and stability of a numerical scheme of coupled nonlinear\n  Schr\\\"{o}dinger equations Abstract: We consider numerical solution of Coupled Nonlinear Schr\\\"{o}dinger Equation.\nWe prove stability and convergence in the $L_2$ space for an explicit scheme\nwhich estimations is used for implicit scheme and compare both method. As a\ntest we compare numerical solutions of Manakov system with known analytical\nsolitonic solutions and as example of general system - evolution of two\nimpulses with different group velocity (model of pulses interaction in optic\nfibers). Last example, a rectangular pulse evolution, shows asymptotic behavior\ntypical for Nonlinear Schr\\\"{o}dinger Equation asymptotics with the same\ninitial condition. \n\n"}
{"id": "math/9803067", "contents": "Title: Polylogarithmic ladders, hypergeometric series and the ten millionth\n  digits of $\\zeta(3)$ and $\\zeta(5)$ Abstract: We develop ladders that reduce $\\zeta(n):=\\sum_{k>0}k^{-n}$, for\n$n=3,5,7,9,11$, and $\\beta(n):=\\sum_{k\\ge0}(-1)^k(2k+1)^{-n}$, for $n=2,4,6$,\nto convergent polylogarithms and products of powers of $\\pi$ and $\\log2$. Rapid\ncomputability results because the required arguments of ${\\rm\nLi}_n(z)=\\sum_{k>0}z^k/k^n$ satisfy $z^8=1/16^p$, with $p=1,3,5$. We prove that\n$G:=\\beta(2)$, $\\pi^3$, $\\log^32$, $\\zeta(3)$, $\\pi^4$, $\\log^42$, $\\log^52$,\n$\\zeta(5)$, and six products of powers of $\\pi$ and $\\log2$ are constants whose\n$d$th hexadecimal digit can be computed in time~$=O(d\\log^3d)$ and\nspace~$=O(\\log d)$, as was shown for $\\pi$, $\\log2$, $\\pi^2$ and $\\log^22$ by\nBailey, Borwein and Plouffe. The proof of the result for $\\zeta(5)$ entails\ndetailed analysis of hypergeometric series that yield Euler sums, previously\nstudied in quantum field theory. The other 13 results follow more easily from\nKummer's functional identities. We compute digits of $\\zeta(3)$ and $\\zeta(5)$,\nstarting at the ten millionth hexadecimal place. These constants result from\ncalculations of massless Feynman diagrams in quantum chromodynamics. In a\nrelated paper, hep-th/9803091, we show that massive diagrams also entail\nconstants whose base of super-fast computation is $b=3$. \n\n"}
{"id": "math/9812031", "contents": "Title: An efficient algorithm for locating and continuing connecting orbits Abstract: A successive continuation method for locating connecting orbits in\nparametrized systems of autonomous ODEs was considered in [9]. In this paper we\npresent an improved algorithm for locating and continuing connecting orbits,\nwhich includes a new algorithm for the continuation of invariant subspaces. The\nlatter algorithm is of independent interest, and can be used in different\ncontexts than the present one. \n\n"}
{"id": "physics/0610206", "contents": "Title: Efficient numerical diagonalization of hermitian 3x3 matrices Abstract: A very common problem in science is the numerical diagonalization of\nsymmetric or hermitian 3x3 matrices. Since standard \"black box\" packages may be\ntoo inefficient if the number of matrices is large, we study several\nalternatives. We consider optimized implementations of the Jacobi, QL, and\nCuppen algorithms and compare them with an analytical method relying on\nCardano's formula for the eigenvalues and on vector cross products for the\neigenvectors. Jacobi is the most accurate, but also the slowest method, while\nQL and Cuppen are good general purpose algorithms. The analytical algorithm\noutperforms the others by more than a factor of 2, but becomes inaccurate or\nmay even fail completely if the matrix entries differ greatly in magnitude.\nThis can mostly be circumvented by using a hybrid method, which falls back to\nQL if conditions are such that the analytical calculation might become too\ninaccurate. For all algorithms, we give an overview of the underlying\nmathematical ideas, and present detailed benchmark results. C and Fortran\nimplementations of our code are available for download from\nhttp://www.mpi-hd.mpg.de/~globes/3x3/ . \n\n"}
{"id": "quant-ph/0109038", "contents": "Title: On a Problem in Quantum Summation Abstract: We consider the computation of the mean of sequences in the quantum model of\ncomputation. We determine the query complexity in the case of sequences which\nsatisfy a $p$-summability condition for $1\\le p<2$. This settles a problem left\nopen in Heinrich (2001). \n\n"}
