{"id": "0704.2981", "contents": "Title: Entanglement in the quantum Ising model Abstract: We study the asymptotic scaling of the entanglement of a block of spins for\nthe ground state of the one-dimensional quantum Ising model with transverse\nfield. When the field is sufficiently strong, the entanglement grows at most\nlogarithmically in the number of spins. The proof utilises a transformation to\na model of classical probability called the continuum random-cluster model, and\nis based on a property of the latter model termed ratio weak-mixing. Our proof\napplies equally to a large class of disordered interactions. \n\n"}
{"id": "0705.2594", "contents": "Title: Molecular Spiders in One Dimension Abstract: Molecular spiders are synthetic bio-molecular systems which have \"legs\" made\nof short single-stranded segments of DNA. Spiders move on a surface covered\nwith single-stranded DNA segments complementary to legs. Different mappings are\nestablished between various models of spiders and simple exclusion processes.\nFor spiders with simple gait and varying number of legs we compute the\ndiffusion coefficient; when the hopping is biased we also compute their\nvelocity. \n\n"}
{"id": "0706.3435", "contents": "Title: Undercomplete Blind Subspace Deconvolution via Linear Prediction Abstract: We present a novel solution technique for the blind subspace deconvolution\n(BSSD) problem, where temporal convolution of multidimensional hidden\nindependent components is observed and the task is to uncover the hidden\ncomponents using the observation only. We carry out this task for the\nundercomplete case (uBSSD): we reduce the original uBSSD task via linear\nprediction to independent subspace analysis (ISA), which we can solve. As it\nhas been shown recently, applying temporal concatenation can also reduce uBSSD\nto ISA, but the associated ISA problem can easily become `high dimensional'\n[1]. The new reduction method circumvents this dimensionality problem. We\nperform detailed studies on the efficiency of the proposed technique by means\nof numerical simulations. We have found several advantages: our method can\nachieve high quality estimations for smaller number of samples and it can cope\nwith deeper temporal convolutions. \n\n"}
{"id": "0707.0098", "contents": "Title: A multi-dimensional Markov chain and the Meixner ensemble Abstract: We show that the transition probability of the Markoc chain\n$(G(j,1),...,G(j,n))_{j\\ge 1}$, where the $G(i,j)'s$ are certain directed\nlast-passage times, is given by a determinant of a special form. An analogous\nformula has recently been obtained by Warren in a Brownian motion model.\nFurthermore we demonstrate that this formula leads to the Meixner ensemble when\nwe compute the distribution function for $G(m,n)$. We also obtain the Fredholm\ndeterminant representation of this distribution, where the kernel has a double\ncontour integral representation. \n\n"}
{"id": "0707.2116", "contents": "Title: Exact Computation of Minimum Sample size for Estimation of Poisson\n  Parameters Abstract: In this paper, we develop an approach for the exact determination of the\nminimum sample size for the estimation of a Poisson parameter with prescribed\nmargin of error and confidence level. The exact computation is made possible by\nreducing infinite many evaluations of coverage probability to finite many\nevaluations. Such reduction is based on our discovery that the minimum of\ncoverage probability with respect to a Poisson parameter bounded in an interval\nis attained at a discrete set of finite many values. \n\n"}
{"id": "0708.0512", "contents": "Title: On representing claims for coherent risk measures Abstract: We consider the problem of representing claims for coherent risk measures.\nFor this purpose we introduce the concept of (weak and strong) time-consistency\nwith respect to a portfolio of assets, generalizing the one defined by Delbaen.\n  In a similar way we extend the notion of m-stability, by introducing weak and\nstrong versions. We then prove that the two concepts of m-stability and\ntime-consistency are still equivalent, thus giving necessary and sufficient\nconditions for a coherent risk measure to be represented by a market with\nproportional transaction costs. We go on to deduce that, under a separability\nassumption, any coherent risk measure is strongly time-consistent with respect\nto a suitably chosen countable portfolio, and show the converse: that any\nmarket with proportional transaction costs is equivalent to a market priced by\na coherent risk measure, essentially establishing the equivalence of the two\nconcepts. \n\n"}
{"id": "0708.2721", "contents": "Title: Directed random growth models on the plane Abstract: This is a brief survey of laws of large numbers, fluctuation results and\nlarge deviation principles for asymmetric interacting particle systems that\nrepresent moving interfaces on the plane. We discuss the exclusion process, the\nHammersley process and the related last-passage growth models. \n\n"}
{"id": "0708.3730", "contents": "Title: Densities for Rough Differential Equations under Hoermander's Condition Abstract: We consider stochastic differential equations dY=V(Y)dX driven by a\nmultidimensional Gaussian process X in the rough path sense. Using Malliavin\nCalculus we show that Y(t) admits a density for t in (0,T] provided (i) the\nvector fields V=(V_1,...,V_d) satisfy Hoermander's condition and (ii) the\nGaussian driving signal X satisfies certain conditions. Examples of driving\nsignals include fractional Brownian motion with Hurst parameter H>1/4, the\nBrownian Bridge returning to zero after time T and the Ornstein-Uhlenbeck\nprocess. \n\n"}
{"id": "0709.3535", "contents": "Title: Maximum Likelihood Estimation in Latent Class Models For Contingency\n  Table Data Abstract: Statistical models with latent structure have a history going back to the\n1950s and have seen widespread use in the social sciences and, more recently,\nin computational biology and in machine learning. Here we study the basic\nlatent class model proposed originally by the sociologist Paul F. Lazarfeld for\ncategorical variables, and we explain its geometric structure. We draw\nparallels between the statistical and geometric properties of latent class\nmodels and we illustrate geometrically the causes of many problems associated\nwith maximum likelihood estimation and related statistical inference. In\nparticular, we focus on issues of non-identifiability and determination of the\nmodel dimension, of maximization of the likelihood function and on the effect\nof symmetric data. We illustrate these phenomena with a variety of synthetic\nand real-life tables, of different dimension and complexity. Much of the\nmotivation for this work stems from the \"100 Swiss Francs\" problem, which we\nintroduce and describe in detail. \n\n"}
{"id": "0711.1378", "contents": "Title: From random matrices to random analytic functions Abstract: We consider two families of random matrix-valued analytic functions: (1)\nG_1-zG_2 and (2) G_0 + zG_1 +z^2G_2+ ..., where G_i are n x n independent\nrandom matrices with independent standard complex Gaussian entries. The set of\nz where these matrix-valued analytic functions become singular, are shown to be\ndeterminantal point processes on the sphere and the hyperbolic plane,\nrespectively. The kernels of these determinantal processes are reproducing\nkernels of certain natural Hilbert spaces of analytic functions on the\ncorresponding surfaces. This gives a unified framework in which to view a\nresult of Peres and Virag (n=1 in the second setting) and a well known theorem\nof Ginibre on Gaussian random matrices (which may be viewed as an analogue of\nour results in the whole plane). \n\n"}
{"id": "0711.1612", "contents": "Title: Enhancing Sparsity by Reweighted L1 Minimization Abstract: It is now well understood that (1) it is possible to reconstruct sparse\nsignals exactly from what appear to be highly incomplete sets of linear\nmeasurements and (2) that this can be done by constrained L1 minimization. In\nthis paper, we study a novel method for sparse signal recovery that in many\nsituations outperforms L1 minimization in the sense that substantially fewer\nmeasurements are needed for exact recovery. The algorithm consists of solving a\nsequence of weighted L1-minimization problems where the weights used for the\nnext iteration are computed from the value of the current solution. We present\na series of experiments demonstrating the remarkable performance and broad\napplicability of this algorithm in the areas of sparse signal recovery,\nstatistical estimation, error correction and image processing. Interestingly,\nsuperior gains are also achieved when our method is applied to recover signals\nwith assumed near-sparsity in overcomplete representations--not by reweighting\nthe L1 norm of the coefficient sequence as is common, but by reweighting the L1\nnorm of the transformed object. An immediate consequence is the possibility of\nhighly efficient data acquisition protocols by improving on a technique known\nas compressed sensing. \n\n"}
{"id": "0711.1713", "contents": "Title: Bondary-connectivity via graph theory Abstract: We generalize theorems of Kesten and Deuschel-Pisztora about the\nconnectedness of the exterior boundary of a connected subset of $\\mathbb{Z}^d$,\nwhere \"connectedness\" and \"boundary\" are understood with respect to various\ngraphs on the vertices of $\\mathbb{Z}^d$. We provide simple and elementary\nproofs of their results. It turns out that the proper way of viewing these\nquestions is graph theory, instead of topology. \n\n"}
{"id": "0711.3787", "contents": "Title: Free Brownian motion and evolution towards boxplus-infinite divisibility\n  for k-tuples Abstract: Let D be the space of non-commutative distributions of k-tuples of\nselfadjoints in a C*-probability space (for a fixed k). We introduce a\nsemigroup of transformations B_t of D, such that every distribution in D\nevolves under the B_t towards infinite divisibility with respect to free\nadditive convolution. The very good properties of B_t come from some special\nconnections that we put into evidence between free additive convolution and the\noperation of Boolean convolution.\n  On the other hand we put into evidence a relation between the transformations\nB_t and free Brownian motion. More precisely, we introduce a transformation Phi\nof D which converts the free Brownian motion started at an arbitrary\ndistribution m in D into the process B_t (Phi(m)), t>0. \n\n"}
{"id": "0801.3975", "contents": "Title: First-exit-time probability density tails for a local height of a\n  non-equilibrium Gaussian interface Abstract: We study the long-time behavior of the probability density Q_t of the first\nexit time from a bounded interval [-L,L] for a stochastic non-Markovian process\nh(t) describing fluctuations at a given point of a two-dimensional, infinite in\nboth directions Gaussian interface. We show that Q_t decays when t \\to \\infty\nas a power-law $^{-1 - \\alpha}, where \\alpha is non-universal and proportional\nto the ratio of the thermal energy and the elastic energy of a fluctuation of\nsize L. The fact that \\alpha appears to be dependent on L, which is rather\nunusual, implies that the number of existing moments of Q_t depends on the size\nof the window [-L,L]. A moment of an arbitrary order n, as a function of L,\nexists for sufficiently small L, diverges when L approaches a certain threshold\nvalue L_n, and does not exist for L > L_n. For L > L_1, the probability density\nQ_t is normalizable but does not have moments. \n\n"}
{"id": "0801.4194", "contents": "Title: A statistical mechanical interpretation of algorithmic information\n  theory Abstract: We develop a statistical mechanical interpretation of algorithmic information\ntheory by introducing the notion of thermodynamic quantities, such as free\nenergy, energy, statistical mechanical entropy, and specific heat, into\nalgorithmic information theory. We investigate the properties of these\nquantities by means of program-size complexity from the point of view of\nalgorithmic randomness. It is then discovered that, in the interpretation, the\ntemperature plays a role as the compression rate of the values of all these\nthermodynamic quantities, which include the temperature itself. Reflecting this\nself-referential nature of the compression rate of the temperature, we obtain\nfixed point theorems on compression rate. \n\n"}
{"id": "0802.0529", "contents": "Title: The distribution of the maximum of a first order moving average: the\n  discrete case Abstract: We give the distribution of $M_n$, the maximum of a sequence of $n$\nobservations from a moving average of order 1. Solutions are first given in\nterms of repeated integrals and then for the case where the underlying\nindependent random variables are discrete. When the correlation is positive, $$\nP(M_n \\max^n_{i=1} X_i \\leq x) = \\sum_{j=1}^\\infty \\beta_{jx} \\nu_{jx}^{n}\n\\approx B_{x} r{1x}^{n} $$ where $\\{\\nu_{jx}\\}$ are the eigenvalues of a\ncertain matrix, $r_{1x}$ is the maximum magnitude of the eigenvalues, and $I$\ndepends on the number of possible values of the underlying random variables.\nThe eigenvalues do not depend on $x$ only on its range. \n\n"}
{"id": "0802.0837", "contents": "Title: Data-driven calibration of penalties for least-squares regression Abstract: Penalization procedures often suffer from their dependence on multiplying\nfactors, whose optimal values are either unknown or hard to estimate from the\ndata. We propose a completely data-driven calibration algorithm for this\nparameter in the least-squares regression framework, without assuming a\nparticular shape for the penalty. Our algorithm relies on the concept of\nminimal penalty, recently introduced by Birge and Massart (2007) in the context\nof penalized least squares for Gaussian homoscedastic regression. On the\npositive side, the minimal penalty can be evaluated from the data themselves,\nleading to a data-driven estimation of an optimal penalty which can be used in\npractice; on the negative side, their approach heavily relies on the\nhomoscedastic Gaussian nature of their stochastic framework. The purpose of\nthis paper is twofold: stating a more general heuristics for designing a\ndata-driven penalty (the slope heuristics) and proving that it works for\npenalized least-squares regression with a random design, even for\nheteroscedastic non-Gaussian data. For technical reasons, some exact\nmathematical results will be proved only for regressogram bin-width selection.\nThis is at least a first step towards further results, since the approach and\nthe method that we use are indeed general. \n\n"}
{"id": "0802.2377", "contents": "Title: Higher-Order Properties of Analytic Wavelets Abstract: The influence of higher-order wavelet properties on the analytic wavelet\ntransform behavior is investigated, and wavelet functions offering advantageous\nperformance are identified. This is accomplished through detailed investigation\nof the generalized Morse wavelets, a two-parameter family of exactly analytic\ncontinuous wavelets. The degree of time/frequency localization, the existence\nof a mapping between scale and frequency, and the bias involved in estimating\nproperties of modulated oscillatory signals, are proposed as important\nconsiderations. Wavelet behavior is found to be strongly impacted by the degree\nof asymmetry of the wavelet in both the frequency and the time domain, as\nquantified by the third central moments. A particular subset of the generalized\nMorse wavelets, recognized as deriving from an inhomogeneous Airy function,\nemerge as having particularly desirable properties. These \"Airy wavelets\"\nsubstantially outperform the only approximately analytic Morlet wavelets for\nhigh time localization. Special cases of the generalized Morse wavelets are\nexamined, revealing a broad range of behaviors which can be matched to the\ncharacteristics of a signal. \n\n"}
{"id": "0806.3769", "contents": "Title: Improved testing inference in mixed linear models Abstract: Mixed linear models are commonly used in repeated measures studies. They\naccount for the dependence amongst observations obtained from the same\nexperimental unit. Oftentimes, the number of observations is small, and it is\nthus important to use inference strategies that incorporate small sample\ncorrections. In this paper, we develop modified versions of the likelihood\nratio test for fixed effects inference in mixed linear models. In particular,\nwe derive a Bartlett correction to such a test and also to a test obtained from\na modified profile likelihood function. Our results generalize those in Zucker\net al. (Journal of the Royal Statistical Society B, 2000, 62, 827-838) by\nallowing the parameter of interest to be vector-valued. Additionally, our\nBartlett corrections allow for random effects nonlinear covariance matrix\nstructure. We report numerical evidence which shows that the proposed tests\ndisplay superior finite sample behavior relative to the standard likelihood\nratio test. An application is also presented and discussed. \n\n"}
{"id": "0807.1106", "contents": "Title: Principal components analysis for sparsely observed correlated\n  functional data using a kernel smoothing approach Abstract: In this paper, we consider the problem of estimating the covariance kernel\nand its eigenvalues and eigenfunctions from sparse, irregularly observed, noise\ncorrupted and (possibly) correlated functional data. We present a method based\non pre-smoothing of individual sample curves through an appropriate kernel. We\nshow that the naive empirical covariance of the pre-smoothed sample curves\ngives highly biased estimator of the covariance kernel along its diagonal. We\nattend to this problem by estimating the diagonal and off-diagonal parts of the\ncovariance kernel separately. We then present a practical and efficient method\nfor choosing the bandwidth for the kernel by using an approximation to the\nleave-one-curve-out cross validation score. We prove that under standard\nregularity conditions on the covariance kernel and assuming i.i.d. samples, the\nrisk of our estimator, under $L^2$ loss, achieves the optimal nonparametric\nrate when the number of measurements per curve is bounded. We also show that\neven when the sample curves are correlated in such a way that the noiseless\ndata has a separable covariance structure, the proposed method is still\nconsistent and we quantify the role of this correlation in the risk of the\nestimator. \n\n"}
{"id": "0807.1681", "contents": "Title: The Eyring-Kramers law for potentials with nonquadratic saddles Abstract: The Eyring-Kramers law describes the mean transition time of an overdamped\nBrownian particle between local minima in a potential landscape. In the\nweak-noise limit, the transition time is to leading order exponential in the\npotential difference to overcome. This exponential is corrected by a prefactor\nwhich depends on the principal curvatures of the potential at the starting\nminimum and at the highest saddle crossed by an optimal transition path. The\nEyring-Kramers law, however, does not hold whenever one of these principal\ncurvatures vanishes, since it would predict a vanishing or infinite transition\ntime. We derive the correct prefactor up to multiplicative errors that tend to\none in the zero-noise limit. As an illustration, we discuss the case of a\nsymmetric pitchfork bifurcation, in which the prefactor can be expressed in\nterms of modified Bessel functions, as well as bifurcations with two vanishing\neigenvalues. The corresponding transition times are studied in a full\nneighbourhood of the bifurcation point. These results extend work by Bovier,\nEckhoff, Gayrard and Klein, who rigorously analysed the case of quadratic\nsaddles, using methods from potential theory. \n\n"}
{"id": "0808.3511", "contents": "Title: Conditional probability based significance tests for sequential patterns\n  in multi-neuronal spike trains Abstract: In this paper we consider the problem of detecting statistically significant\nsequential patterns in multi-neuronal spike trains. These patterns are\ncharacterized by ordered sequences of spikes from different neurons with\nspecific delays between spikes. We have previously proposed a data mining\nscheme to efficiently discover such patterns which are frequent in the sense\nthat the count of non-overlapping occurrences of the pattern in the data stream\nis above a threshold. Here we propose a method to determine the statistical\nsignificance of these repeating patterns and to set the thresholds\nautomatically. The novelty of our approach is that we use a compound null\nhypothesis that includes not only models of independent neurons but also models\nwhere neurons have weak dependencies. The strength of interaction among the\nneurons is represented in terms of certain pair-wise conditional probabilities.\nWe specify our null hypothesis by putting an upper bound on all such\nconditional probabilities. We construct a probabilistic model that captures the\ncounting process and use this to calculate the mean and variance of the count\nfor any pattern. Using this we derive a test of significance for rejecting such\na null hypothesis. This also allows us to rank-order different significant\npatterns. We illustrate the effectiveness of our approach using spike trains\ngenerated from a non-homogeneous Poisson model with embedded dependencies. \n\n"}
{"id": "0808.3661", "contents": "Title: Degree-distribution Stability of Growing Networks Abstract: In this paper, we abstract a kind of stochastic processes from evolving\nprocesses of growing networks, this process is called growing network Markov\nchains. Thus the existence and the formulas of degree distribution are\ntransformed to the corresponding problems of growing network Markov chains.\nFirst we investigate the growing network Markov chains, and obtain the\ncondition in which the steady degree distribution exists and get its exact\nformulas. Then we apply it to various growing networks. With this method, we\nget a rigorous, exact and unified solution of the steady degree distribution\nfor growing networks. \n\n"}
{"id": "0808.4024", "contents": "Title: The Center of Mass for Spatial Branching Processes and an Application\n  for Self-Interaction Abstract: In this paper we prove that the center of mass of a supercritical\nbranching-Brownian motion, or that of a supercritical super-Brownian motion\ntends to a limiting position almost surely, which, in a sense complements a\nresult of Tribe on the final behavior of a critical super-Brownian motion. This\nis shown to be true also for a model where branching Brownian motion is\nmodified by attraction/repulsion between particles.\n  We then put this observation together with the description of the interacting\nsystem as viewed from its center of mass, and get the following asymptotic\nbehavior: the system asymptotically becomes a branching Ornstein Uhlenbeck\nprocess (inward for attraction and outward for repulsion), but the origin is\nshifted to a random point which has normal distribution, and the Ornstein\nUhlenbeck particles are not independent but constitute a system with a degree\nof freedom which is less by their number by precisely one. \n\n"}
{"id": "0810.0430", "contents": "Title: Estimating the Parameters of Binomial and Poisson Distributions via\n  Multistage Sampling Abstract: In this paper, we have developed a new class of sampling schemes for\nestimating parameters of binomial and Poisson distributions. Without any\ninformation of the unknown parameters, our sampling schemes rigorously\nguarantee prescribed levels of precision and confidence. \n\n"}
{"id": "0811.0509", "contents": "Title: Confluence of geodesic paths and separating loops in large planar\n  quadrangulations Abstract: We consider planar quadrangulations with three marked vertices and discuss\nthe geometry of triangles made of three geodesic paths joining them. We also\nstudy the geometry of minimal separating loops, i.e. paths of minimal length\namong all closed paths passing by one of the three vertices and separating the\ntwo others in the quadrangulation. We concentrate on the universal scaling\nlimit of large quadrangulations, also known as the Brownian map, where pairs of\ngeodesic paths or minimal separating loops have common parts of non-zero\nmacroscopic length. This is the phenomenon of confluence, which distinguishes\nthe geometry of random quadrangulations from that of smooth surfaces. We\ncharacterize the universal probability distribution for the lengths of these\ncommon parts. \n\n"}
{"id": "0812.0965", "contents": "Title: The two uniform infinite quadrangulations of the plane have the same law Abstract: We prove that the uniform infinite random quadrangulations defined\nrespectively by Chassaing-Durhuus and Krikun have the same distribution. \n\n"}
{"id": "0812.4483", "contents": "Title: Random complex dynamics and semigroups of holomorphic maps Abstract: We investigate the random dynamics of rational maps on the Riemann sphere and\nthe dynamics of semigroups of rational maps on the Riemann sphere. We show that\nregarding random complex dynamics of polynomials, in most cases, the chaos of\nthe averaged system disappears, due to the cooperation of the generators. We\ninvestigate the iteration and spectral properties of transition operators. We\nshow that under certain conditions, in the limit stage, \"singular functions on\nthe complex plane\" appear. In particular, we consider the functions $T$ which\nrepresent the probability of tending to infinity with respect to the random\ndynamics of polynomials. Under certain conditions these functions $T$ are\ncomplex analogues of the devil's staircase and Lebesgue's singular functions.\nMore precisely, we show that these functions $T$ are continuous on the Riemann\nsphere and vary only on the Julia sets of associated semigroups. Furthermore,\nby using ergodic theory and potential theory, we investigate the\nnon-differentiability and regularity of these functions. We find many phenomena\nwhich can hold in the random complex dynamics and the dynamics of semigroups of\nrational maps, but cannot hold in the usual iteration dynamics of a single\nholomorphic map. We carry out a systematic study of these phenomena and their\nmechanisms. \n\n"}
{"id": "0901.0401", "contents": "Title: From Physics to Economics: An Econometric Example Using Maximum Relative\n  Entropy Abstract: Econophysics, is based on the premise that some ideas and methods from\nphysics can be applied to economic situations. We intend to show in this paper\nhow a physics concept such as entropy can be applied to an economic problem. In\nso doing, we demonstrate how information in the form of observable data and\nmoment constraints are introduced into the method of Maximum relative Entropy\n(MrE). A general example of updating with data and moments is shown. Two\nspecific econometric examples are solved in detail which can then be used as\ntemplates for real world problems. A numerical example is compared to a large\ndeviation solution which illustrates some of the advantages of the MrE method. \n\n"}
{"id": "0901.3297", "contents": "Title: Limit theorems for random spatial drainage networks Abstract: Suppose that under the action of gravity, liquid drains through the unit\n$d$-cube via a minimal-length network of channels constrained to pass through\nrandom sites and to flow with nonnegative component in one of the canonical\northogonal basis directions of $\\R^d$, $d \\geq 2$. The resulting network is a\nversion of the so-called minimal directed spanning tree. We give laws of large\nnumbers and convergence in distribution results on the large-sample asymptotic\nbehaviour of the total power-weighted edge-length of the network on uniform\nrandom points in $(0,1)^d$. The distributional results exhibit a\nweight-dependent phase transition between Gaussian and boundary-effect-derived\ndistributions. These boundary contributions are characterized in terms of\nlimits of the so-called on-line nearest-neighbour graph, a natural model of\nspatial network evolution, for which we also present some new results. Also, we\ngive a convergence in distribution result for the length of the longest edge in\nthe drainage network; when $d=2$, the limit is expressed in terms of\nDickman-type variables. \n\n"}
{"id": "0901.3805", "contents": "Title: Growth Rates and Explosions in Sandpiles Abstract: We study the abelian sandpile growth model, where n particles are added at\nthe origin on a stable background configuration in Z^d. Any site with at least\n2d particles then topples by sending one particle to each neighbor. We find\nthat with constant background height h <= 2d-2, the diameter of the set of\nsites that topple has order n^{1/d}. This was previously known only for h<d.\nOur proof uses a strong form of the least action principle for sandpiles, and a\nnovel method of background modification.\n  We can extend this diameter bound to certain backgrounds in which an\narbitrarily high fraction of sites have height 2d-1. On the other hand, we show\nthat if the background height 2d-2 is augmented by 1 at an arbitrarily small\nfraction of sites chosen independently at random, then adding finitely many\nparticles creates an explosion (a sandpile that never stabilizes). \n\n"}
{"id": "0901.4760", "contents": "Title: A survey on dynamical percolation Abstract: Percolation is one of the simplest and nicest models in probability\ntheory/statistical mechanics which exhibits critical phenomena. Dynamical\npercolation is a model where a simple time dynamics is added to the (ordinary)\npercolation model. This dynamical model exhibits very interesting behavior. Our\ngoal in thissurvey is to give an overview of the work in dynamical percolation\nthat has been done (and some of which is in the process of being written up). \n\n"}
{"id": "0902.0990", "contents": "Title: Directional Clustering Tests Based on Nearest Neighbor Contingency\n  Tables Abstract: Spatial interaction between two or more classes or species has important\nimplications in various fields and causes multivariate patterns such as\nsegregation or association. Segregation occurs when members of a class or\nspecies are more likely to be found near members of the same class or\nconspecifics; while association occurs when members of a class or species are\nmore likely to be found near members of another class or species. The null\npatterns considered are random labeling (RL) and complete spatial randomness\n(CSR) of points from two or more classes, which is called \\emph{CSR\nindependence}, henceforth. The clustering tests based on nearest neighbor\ncontingency tables (NNCTs) that are in use in literature are two-sided tests.\nIn this article, we consider the directional (i.e., one-sided) versions of the\ncell-specific NNCT-tests and introduce new directional NNCT-tests for the\ntwo-class case. We analyze the distributional properties; compare the empirical\nsignificant levels and empirical power estimates of the tests using extensive\nMonte Carlo simulations. We demonstrate that the new directional tests have\ncomparable performance with the currently available NNCT-tests in terms of\nempirical size and power. We use four example data sets for illustrative\npurposes and provide guidelines for using these NNCT-tests. \n\n"}
{"id": "0902.4496", "contents": "Title: Geometric ergodicity of a bead-spring pair with stochastic Stokes\n  forcing Abstract: We consider a simple model for the fluctuating hydrodynamics of a flexible\npolymer in dilute solution, demonstrating geometric ergodicity for a pair of\nparticles that interact with each other through a nonlinear spring potential\nwhile being advected by a stochastic Stokes fluid velocity field. This is a\ngeneralization of previous models which have used linear spring forces as well\nas white-in-time fluid velocity fields.\n  We follow previous work combining control theoretic arguments, Lyapunov\nfunctions, and hypo-elliptic diffusion theory to prove exponential convergence\nvia a Harris chain argument. In addition we allow the possibility of excluding\ncertain \"bad\" sets in phase space in which the assumptions are violated but\nfrom which the system leaves with a controllable probability. This allows for\nthe treatment of singular drifts, such as those derived from the Lennard-Jones\npotential, which is a novel feature of this work. \n\n"}
{"id": "0903.1467", "contents": "Title: Smoothness of scale functions for spectrally negative Levy processes Abstract: Scale functions play a central role in the fluctuation theory of spectrally\nnegative L\\'evy processes and often appear in the context of martingale\nrelations. These relations are often complicated to establish requiring\nexcursion theory in favour of It\\^o calculus. The reason for the latter is that\nstandard It\\^o calculus is only applicable to functions with a sufficient\ndegree of smoothness and knowledge of the precise degree of smoothness of scale\nfunctions is seemingly incomplete. The aim of this article is to offer new\nresults concerning properties of scale functions in relation to the smoothness\nof the underlying L\\'evy measure. We place particular emphasis on spectrally\nnegative L\\'evy processes with a Gaussian component and processes of bounded\nvariation.\n  An additional motivation is the very intimate relation of scale functions to\nrenewal functions of subordinators. The results obtained for scale functions\nhave direct implications offering new results concerning the smoothness of such\nrenewal functions for which there seems to be very little existing literature\non this topic. \n\n"}
{"id": "0903.2672", "contents": "Title: Free point processes and free extreme values Abstract: We continue here the study of free extreme values begun in Ben Arous and\nVoiculescu (2006). We study the convergence of the free point processes\nassociated with free extreme values to a free Poisson random measure\n(Voiculescu (1998), Barndorff-Nielsen and Thorbjornsen (2005)). We relate this\nconvergence to the free extremal laws introduced in Ben Arous and Voiculescu\n(2006) and give the limit laws for free order statistics. \n\n"}
{"id": "0903.3002", "contents": "Title: Learning with Structured Sparsity Abstract: This paper investigates a new learning formulation called structured\nsparsity, which is a natural extension of the standard sparsity concept in\nstatistical learning and compressive sensing. By allowing arbitrary structures\non the feature set, this concept generalizes the group sparsity idea that has\nbecome popular in recent years. A general theory is developed for learning with\nstructured sparsity, based on the notion of coding complexity associated with\nthe structure. It is shown that if the coding complexity of the target signal\nis small, then one can achieve improved performance by using coding complexity\nregularization methods, which generalize the standard sparse regularization.\nMoreover, a structured greedy algorithm is proposed to efficiently solve the\nstructured sparsity problem. It is shown that the greedy algorithm\napproximately solves the coding complexity optimization problem under\nappropriate conditions. Experiments are included to demonstrate the advantage\nof structured sparsity over standard sparsity on some real applications. \n\n"}
{"id": "0903.5066", "contents": "Title: Modified-CS: Modifying Compressive Sensing for Problems with Partially\n  Known Support Abstract: We study the problem of reconstructing a sparse signal from a limited number\nof its linear projections when a part of its support is known, although the\nknown part may contain some errors. The ``known\" part of the support, denoted\nT, may be available from prior knowledge. Alternatively, in a problem of\nrecursively reconstructing time sequences of sparse spatial signals, one may\nuse the support estimate from the previous time instant as the ``known\" part.\nThe idea of our proposed solution (modified-CS) is to solve a convex relaxation\nof the following problem: find the signal that satisfies the data constraint\nand is sparsest outside of T. We obtain sufficient conditions for exact\nreconstruction using modified-CS. These are much weaker than those needed for\ncompressive sensing (CS) when the sizes of the unknown part of the support and\nof errors in the known part are small compared to the support size. An\nimportant extension called Regularized Modified-CS (RegModCS) is developed\nwhich also uses prior signal estimate knowledge. Simulation comparisons for\nboth sparse and compressible signals are shown. \n\n"}
{"id": "0903.5136", "contents": "Title: First passage percolation on random graphs with finite mean degrees Abstract: We study first passage percolation on the configuration model. Assuming that\neach edge has an independent exponentially distributed edge weight, we derive\nexplicit distributional asymptotics for the minimum weight between two randomly\nchosen connected vertices in the network, as well as for the number of edges on\nthe least weight path, the so-called hopcount. We analyze the configuration\nmodel with degree power-law exponent $\\tau>2$, in which the degrees are assumed\nto be i.i.d. with a tail distribution which is either of power-law form with\nexponent $\\tau-1>1$, or has even thinner tails ($\\tau=\\infty$). In this model,\nthe degrees have a finite first moment, while the variance is finite for\n$\\tau>3$, but infinite for $\\tau\\in(2,3)$. We prove a central limit theorem for\nthe hopcount, with asymptotically equal means and variances equal to\n$\\alpha\\log{n}$, where $\\alpha\\in(0,1)$ for $\\tau\\in(2,3)$, while $\\alpha>1$\nfor $\\tau>3$. Here $n$ denotes the size of the graph. For $\\tau\\in (2,3)$, it\nis known that the graph distance between two randomly chosen connected vertices\nis proportional to $\\log \\log{n}$ [Electron. J. Probab. 12 (2007) 703--766],\nthat is, distances are ultra small. Thus, the addition of edge weights causes a\nmarked change in the geometry of the network. We further study the weight of\nthe least weight path and prove convergence in distribution of an appropriately\ncentered version. This study continues the program initiated in [J. Math. Phys.\n49 (2008) 125218] of showing that $\\log{n}$ is the correct scaling for the\nhopcount under i.i.d. edge disorder, even if the graph distance between two\nrandomly chosen vertices is of much smaller order. The case of infinite mean\ndegrees ($\\tau\\in[1,2)$) is studied in [Extreme value theory,\nPoisson--Dirichlet distributions and first passage percolation on random\nnetworks (2009) Preprint] where it is proved that the hopcount remains\nuniformly bounded and converges in distribution. \n\n"}
{"id": "0904.1222", "contents": "Title: Asymptotic Normality of Statistics on Permutation Tableaux Abstract: In this paper we use a probabilistic approach to derive the expressions for\nthe characteristic functions of basic statistics defined on permutation\ntableaux. Since our expressions are exact, we can identify the distributions of\nbasic statistics (like the number of unrestricted rows, the number of rows, and\nthe number of 1s in the first row) exactly. In all three cases the\ndistributions are known to be asymptotically normal after a suitable\nnormalization. We also establish the asymptotic normality of the number of\nsuperfluous 1s. The latter result relies on a bijection between permutation\ntableaux and permutations and on a rather general sufficient condition for the\ncentral limit theorem for the sums of random variables in terms of dependency\ngraph of the summands. \n\n"}
{"id": "0904.2052", "contents": "Title: Least Squares estimation of two ordered monotone regression curves Abstract: In this paper, we consider the problem of finding the Least Squares\nestimators of two isotonic regression curves $g^\\circ_1$ and $g^\\circ_2$ under\nthe additional constraint that they are ordered; e.g., $g^\\circ_1 \\le\ng^\\circ_2$. Given two sets of $n$ data points $y_1, ..., y_n$ and $z_1,\n>...,z_n$ observed at (the same) design points, the estimates of the true\ncurves are obtained by minimizing the weighted Least Squares criterion $L_2(a,\nb) = \\sum_{j=1}^n (y_j - a_j)^2 w_{1,j}+ \\sum_{j=1}^n (z_j - b_j)^2 w_{2,j}$\nover the class of pairs of vectors $(a, b) \\in \\mathbb{R}^n \\times \\mathbb{R}^n\n$ such that $a_1 \\le a_2 \\le ...\\le a_n $, $b_1 \\le b_2 \\le ...\\le b_n $, and\n$a_i \\le b_i, i=1, ...,n$. The characterization of the estimators is\nestablished. To compute these estimators, we use an iterative projected\nsubgradient algorithm, where the projection is performed with a \"generalized\"\npool-adjacent-violaters algorithm (PAVA), a byproduct of this work. Then, we\napply the estimation method to real data from mechanical engineering. \n\n"}
{"id": "0904.4271", "contents": "Title: Large deviations of empirical zero point measures on Riemann surfaces,\n  I: $g = 0$ Abstract: We prove an LDP for the empirical measure of complex zeros of a Gaussian\nrandom complex polynomial of degree N of one variable as N tends to infinity.\nThe Gaussian measure is induced by an inner product defined by a smooth weight\n(Hermitian metric) $h$ and a Bernstein-Markov measure $\\nu$. The speed is N^2\nand the the unique minimizer of the rate function $I$ is the weighted\nequilibrium measure $\\nu_{h, K}$ with respect to $h$ on the support $K$ of\n$\\nu$. \n\n"}
{"id": "0905.2979", "contents": "Title: Extreme deconvolution: Inferring complete distribution functions from\n  noisy, heterogeneous and incomplete observations Abstract: We generalize the well-known mixtures of Gaussians approach to density\nestimation and the accompanying Expectation--Maximization technique for finding\nthe maximum likelihood parameters of the mixture to the case where each data\npoint carries an individual $d$-dimensional uncertainty covariance and has\nunique missing data properties. This algorithm reconstructs the\nerror-deconvolved or \"underlying\" distribution function common to all samples,\neven when the individual data points are samples from different distributions,\nobtained by convolving the underlying distribution with the heteroskedastic\nuncertainty distribution of the data point and projecting out the missing data\ndirections. We show how this basic algorithm can be extended with conjugate\npriors on all of the model parameters and a \"split-and-merge\" procedure\ndesigned to avoid local maxima of the likelihood. We demonstrate the full\nmethod by applying it to the problem of inferring the three-dimensional\nvelocity distribution of stars near the Sun from noisy two-dimensional,\ntransverse velocity measurements from the Hipparcos satellite. \n\n"}
{"id": "0906.3501", "contents": "Title: Semiparametric modeling of autonomous nonlinear dynamical systems with\n  applications Abstract: In this paper, we propose a semi-parametric model for autonomous nonlinear\ndynamical systems and devise an estimation procedure for model fitting. This\nmodel incorporates subject-specific effects and can be viewed as a nonlinear\nsemi-parametric mixed effects model. We also propose a computationally\nefficient model selection procedure. We prove consistency of the proposed\nestimator under suitable regularity conditions. We show by simulation studies\nthat the proposed estimation as well as model selection procedures can\nefficiently handle sparse and noisy measurements. Finally, we apply the\nproposed method to a plant growth data used to study growth displacement rates\nwithin meristems of maize roots under two different experimental conditions. \n\n"}
{"id": "0906.4329", "contents": "Title: A Bayes factor with reasonable model selection consistency for ANOVA\n  model Abstract: For the ANOVA model, we propose a new g-prior based Bayes factor without\nintegral representation, with reasonable model selection consistency for any\nasymptotic situations (either number of levels of the factor and/or number of\nreplication in each level goes to infinity). Exact analytic calculation of the\nmarginal density under a special choice of the priors enables such a Bayes\nfactor. \n\n"}
{"id": "0907.0139", "contents": "Title: Coherent frequentism Abstract: By representing the range of fair betting odds according to a pair of\nconfidence set estimators, dual probability measures on parameter space called\nfrequentist posteriors secure the coherence of subjective inference without any\nprior distribution. The closure of the set of expected losses corresponding to\nthe dual frequentist posteriors constrains decisions without arbitrarily\nforcing optimization under all circumstances. This decision theory reduces to\nthose that maximize expected utility when the pair of frequentist posteriors is\ninduced by an exact or approximate confidence set estimator or when an\nautomatic reduction rule is applied to the pair. In such cases, the resulting\nfrequentist posterior is coherent in the sense that, as a probability\ndistribution of the parameter of interest, it satisfies the axioms of the\ndecision-theoretic and logic-theoretic systems typically cited in support of\nthe Bayesian posterior. Unlike the p-value, the confidence level of an interval\nhypothesis derived from such a measure is suitable as an estimator of the\nindicator of hypothesis truth since it converges in sample-space probability to\n1 if the hypothesis is true or to 0 otherwise under general conditions. \n\n"}
{"id": "0907.2401", "contents": "Title: The Maxwell-Boltzmann Distribution is not the Equilibrium on a\n  Hyperboloid Abstract: We give a geometric formulation of the Fokker-Planck-Kramer equations for a\nparticle moving on a Lie algebra under the influence of a dissipative and a\nrandom force. Special cases of interest are fluid mechanics, the Stochastic\nLoewner Equation and the rigid body. We find that the Boltzmann distribution,\nalthough a static solution, is not normalizable when the algebra is not\nunimodular. This is because the invariant measure of integration in momentum\nspace is not the standard one. We solve the special case of the upper\nhalf-plane (hyperboloid) explicitly: there is another equilibrium solution to\nthe Fokker-Planck equation, which is integrable. It breaks rotation invariance;\nmoreover, the most likely value for velocity is not zero. \n\n"}
{"id": "0907.5499", "contents": "Title: Upper large deviations for the maximal flow through a domain of\n  $\\bolds{\\mathbb{R}^d}$ in first passage percolation Abstract: We consider the standard first passage percolation model in the rescaled\ngraph $\\mathbb {Z}^d/n$ for $d\\geq2$ and a domain $\\Omega$ of boundary $\\Gamma$\nin $\\mathbb {R}^d$. Let $\\Gamma ^1$ and $\\Gamma ^2$ be two disjoint open\nsubsets of $\\Gamma$ representing the parts of $\\Gamma$ through which some water\ncan enter and escape from $\\Omega$. We investigate the asymptotic behavior of\nthe flow $\\phi_n$ through a discrete version $\\Omega_n$ of $\\Omega$ between the\ncorresponding discrete sets $\\Gamma ^1_n$ and $\\Gamma ^2_n$. We prove that\nunder some conditions on the regularity of the domain and on the law of the\ncapacity of the edges, the upper large deviations of $\\phi_n/n^{d-1}$ above a\ncertain constant are of volume order, that is, decays exponentially fast with\n$n^d$. This article is part of a larger project in which the authors prove that\nthis constant is the a.s. limit of $\\phi_n/n^{d-1}$. \n\n"}
{"id": "0908.2098", "contents": "Title: Rigorous confidence bounds for MCMC under a geometric drift condition Abstract: We assume a drift condition towards a small set and bound the mean square\nerror of estimators obtained by taking averages along a single trajectory of a\nMarkov chain Monte Carlo algorithm. We use these bounds to construct\nfixed-width nonasymptotic confidence intervals. For a possibly unbounded\nfunction $f:\\stany \\to R,$ let $I=\\int_{\\stany} f(x) \\pi(x) dx$ be the value of\ninterest and $\\hat{I}_{t,n}=(1/n)\\sum_{i=t}^{t+n-1}f(X_i)$ its MCMC estimate.\nPrecisely, we derive lower bounds for the length of the trajectory $n$ and\nburn-in time $t$ which ensure that $$P(|\\hat{I}_{t,n}-I|\\leq \\varepsilon)\\geq\n1-\\alpha.$$ The bounds depend only and explicitly on drift parameters, on the\n$V-$norm of $f,$ where $V$ is the drift function and on precision and\nconfidence parameters $\\varepsilon, \\alpha.$ Next we analyse an MCMC estimator\nbased on the median of multiple shorter runs that allows for sharper bounds for\nthe required total simulation cost. In particular the methodology can be\napplied for computing Bayesian estimators in practically relevant models. We\nillustrate our bounds numerically in a simple example. \n\n"}
{"id": "0909.2433", "contents": "Title: On the k-gamma q-distribution Abstract: We provide combinatorial as well as probabilistic interpretations for the\nq-analogue of the Pochhammer k-symbol introduced by Diaz and Teruel. We\nintroduce q-analogues of the Mellin transform in order to study the q-analogue\nof the k-gamma distribution. \n\n"}
{"id": "0909.3052", "contents": "Title: Cross-Validation for Unsupervised Learning Abstract: Cross-validation (CV) is a popular method for model-selection. Unfortunately,\nit is not immediately obvious how to apply CV to unsupervised or exploratory\ncontexts. This thesis discusses some extensions of cross-validation to\nunsupervised learning, specifically focusing on the problem of choosing how\nmany principal components to keep. We introduce the latent factor model, define\nan objective criterion, and show how CV can be used to estimate the intrinsic\ndimensionality of a data set. Through both simulation and theory, we\ndemonstrate that cross-validation is a valuable tool for unsupervised learning. \n\n"}
{"id": "0909.3359", "contents": "Title: Some stochastic process without birth, linked to the mean curvature flow Abstract: Using Huisken results about the mean curvature flow on a strictly convex\nhypersurface, and Kendall-Cranston coupling, we will build a stochastic process\nwithout birth, and show that there exists a unique law of such process. This\nprocess has many similarities with the circular Brownian motions studied by\n\\'Emery, Schachermayer, and Arnaudon. In general, this process is not a\nstationary process, it is linked with some differential equation without\ninitial condition. We will show that this differential equation has a unique\nsolution up to a multiplicative constant. \n\n"}
{"id": "0910.0827", "contents": "Title: Performance of Statistical Tests for Single Source Detection using\n  Random Matrix Theory Abstract: This paper introduces a unified framework for the detection of a source with\na sensor array in the context where the noise variance and the channel between\nthe source and the sensors are unknown at the receiver. The Generalized Maximum\nLikelihood Test is studied and yields the analysis of the ratio between the\nmaximum eigenvalue of the sampled covariance matrix and its normalized trace.\nUsing recent results of random matrix theory, a practical way to evaluate the\nthreshold and the $p$-value of the test is provided in the asymptotic regime\nwhere the number $K$ of sensors and the number $N$ of observations per sensor\nare large but have the same order of magnitude. The theoretical performance of\nthe test is then analyzed in terms of Receiver Operating Characteristic (ROC)\ncurve. It is in particular proved that both Type I and Type II error\nprobabilities converge to zero exponentially as the dimensions increase at the\nsame rate, and closed-form expressions are provided for the error exponents.\nThese theoretical results rely on a precise description of the large deviations\nof the largest eigenvalue of spiked random matrix models, and establish that\nthe presented test asymptotically outperforms the popular test based on the\ncondition number of the sampled covariance matrix. \n\n"}
{"id": "0910.4558", "contents": "Title: Effect of indirect dependencies on \"A mutual information minimization\n  approach for a class of nonlinear recurrent separating systems\" Abstract: In a recent paper [4], Duarte and Jutten investigated the Blind Source\nSeparation (BSS) problem, for the nonlinear mixing model that they introduced\nin that paper. They proposed to solve this problem by using\ninformation-theoretic tools, more precisely by minimizing the mutual\ninformation (MI) of the outputs of the separating structure. When applying the\nMI approach to BSS problems, one usually determines the analytical expressions\nof the derivatives of the MI with respect to the parameters of the considered\nseparating model. In the literature, these calculations were mainly reported\nfor linear mixtures up to now. They are more complex for nonlinear mixtures,\ndue to dependencies between the considered quantities. Moreover, the notations\ncommonly employed by the BSS community in such calculations may become\nmisleading when using them for nonlinear mixtures, due to the above-mentioned\ndependencies. We claim that the calculations reported in [4] contain an error,\nbecause they did not take into account all these dependencies. In this\ndocument, we therefore explain this phenomenon, by showing the effect of\nindirect dependencies on the application of the MI approach to the mixing and\nseparating models considered in [4]. We thus introduce a corrected expression\nof the gradient of the considered BSS criterion based on MI. This correct\ngradient may then e.g. be used to optimize the adaptive coefficients of the\nconsidered separating system by means of the well-known gradient descent\nalgorithm. As explained hereafter, this investigation has some similarities\nwith an analysis that we previously reported in another arXiv document [3].\nHowever, these two investigations concern different problems (mixture and\nseparating structure, mathematical tools: see paper). \n\n"}
{"id": "0910.5613", "contents": "Title: Ageing in the parabolic Anderson model Abstract: The parabolic Anderson model is the Cauchy problem for the heat equation with\na random potential. We consider this model in a setting which is continuous in\ntime and discrete in space, and focus on time-constant, independent and\nidentically distributed potentials with polynomial tails at infinity. We are\nconcerned with the long-term temporal dynamics of this system. Our main result\nis that the periods, in which the profile of the solutions remains nearly\nconstant, are increasing linearly over time, a phenomenon known as ageing. We\ndescribe this phenomenon in the weak sense, by looking at the asymptotic\nprobability of a change in a given time window, and in the strong sense, by\nidentifying the almost sure upper envelope for the process of the time\nremaining until the next change of profile. We also prove functional scaling\nlimit theorems for profile and growth rate of the solution of the parabolic\nAnderson model. \n\n"}
{"id": "0911.0616", "contents": "Title: Poisson boundary of groups acting on real trees Abstract: We give a geometric description of the Poisson boundaries of certain\nextensions of free and hyperbolic groups. In particular, we get a full\ndescription of the Poisson boundaries of free-by-cyclic groups. We rely upon\nthe description of Poisson boundaries by means of a topological\ncompactification as developed by Kaimanovich. All the groups studied here share\nthe property of admitting a sufficiently complicated action on some real tree. \n\n"}
{"id": "0911.3988", "contents": "Title: On the rate of convergence of loop-erased random walk to SLE(2) Abstract: We derive a rate of convergence of the Loewner driving function for planar\nloop-erased random walk to Brownian motion with speed 2 on the unit circle, the\nLoewner driving function for radial SLE(2). The proof uses a new estimate of\nthe difference between the discrete and continuous Green's functions that is an\nimprovement over existing results for the class of domains we consider. Using\nthe rate for the driving process convergence along with additional information\nabout SLE(2), we also obtain a rate of convergence for the paths with respect\nto the Hausdorff distance. \n\n"}
{"id": "0912.1515", "contents": "Title: Local time and Tanaka formula for G-Brownian Motion Abstract: In this paper, we study the notion of local time and Tanaka formula for the\nG-Brownian motion. Moreover, the joint continuity of the local time of the\nG-Brownian motion is obtained and its quadratic variation is proven. As an\napplication, we generalize It^o's formula with respect to the G-Brownian motion\nto convex functions. \n\n"}
{"id": "0912.5200", "contents": "Title: Penalized Composite Quasi-Likelihood for Ultrahigh-Dimensional Variable\n  Selection Abstract: In high-dimensional model selection problems, penalized simple least-square\napproaches have been extensively used. This paper addresses the question of\nboth robustness and efficiency of penalized model selection methods, and\nproposes a data-driven weighted linear combination of convex loss functions,\ntogether with weighted $L_1$-penalty. It is completely data-adaptive and does\nnot require prior knowledge of the error distribution. The weighted\n$L_1$-penalty is used both to ensure the convexity of the penalty term and to\nameliorate the bias caused by the $L_1$-penalty. In the setting with\ndimensionality much larger than the sample size, we establish a strong oracle\nproperty of the proposed method that possesses both the model selection\nconsistency and estimation efficiency for the true non-zero coefficients. As\nspecific examples, we introduce a robust method of composite L1-L2, and optimal\ncomposite quantile method and evaluate their performance in both simulated and\nreal data examples. \n\n"}
{"id": "1001.2185", "contents": "Title: Improved estimators for dispersion models with dispersion covariates Abstract: In this paper we discuss improved estimators for the regression and the\ndispersion parameters in an extended class of dispersion models (J{\\o}rgensen,\n1996). This class extends the regular dispersion models by letting the\ndispersion parameter vary throughout the observations, and contains the\ndispersion models as particular case. General formulae for the second-order\nbias are obtained explicitly in dispersion models with dispersion covariates,\nwhich generalize previous results by Botter and Cordeiro (1998), Cordeiro and\nMcCullagh (1991), Cordeiro and Vasconcellos (1999), and Paula (1992). The\npractical use of the formulae is that we can derive closed-form expressions for\nthe second-order biases of the maximum likelihood estimators of the regression\nand dispersion parameters when the information matrix has a closed-form.\nVarious expressions for the second-order biases are given for special models.\nThe formulae have advantages for numerical purposes because they require only a\nsupplementary weighted linear regression. We also compare these bias-corrected\nestimators with two different estimators which are also bias-free to the\nsecond-order that are based on bootstrap methods. These estimators are compared\nby simulation. \n\n"}
{"id": "1001.2187", "contents": "Title: Skewness of maximum likelihood estimators in dispersion models Abstract: We introduce the dispersion models with a regression structure to extend the\ngeneralized linear models, the exponential family nonlinear models (Cordeiro\nand Paula, 1989) and the proper dispersion models (J{\\o}rgensen, 1997a). We\nprovide a matrix expression for the skewness of the maximum likelihood\nestimators of the regression parameters in dispersion models. The formula is\nsuitable for computer implementation and can be applied for several important\nsubmodels discussed in the literature. Expressions for the skewness of the\nmaximum likelihood estimators of the precision and dispersion parameters are\nalso derived. In particular, our results extend previous formulas obtained by\nCordeiro and Cordeiro (2001) and Cavalcanti et al. (2009). A simulation study\nis perfomed to show the practice importance of our results. \n\n"}
{"id": "1001.3262", "contents": "Title: Regularly varying time series in Banach spaces Abstract: When a spatial process is recorded over time and the observation at a given\ntime instant is viewed as a point in a function space, the result is a time\nseries taking values in a Banach space. To study the spatio-temporal extremal\ndynamics of such a time series, the latter is assumed to be jointly regularly\nvarying. This assumption is shown to be equivalent to convergence in\ndistribution of the rescaled time series conditionally on the event that at a\ngiven moment in time it is far away from the origin. The limit is called the\ntail process or the spectral process depending on the way of rescaling. These\nprocesses provide convenient starting points to study, for instance, joint\nsurvival functions, tail dependence coefficients, extremograms, extremal\nindices, and point processes of extremes. The theory applies to linear\nprocesses composed of infinite sums of linearly transformed independent random\nelements whose common distribution is regularly varying. \n\n"}
{"id": "1001.4303", "contents": "Title: Scaling limits of random skew plane partitions with arbitrarily sloped\n  back walls Abstract: The paper studies scaling limits of random skew plane partitions confined to\na box when the inner shapes converge uniformly to a piecewise linear function V\nof arbitrary slopes in [-1,1]. It is shown that the correlation kernels in the\nbulk are given by the incomplete Beta kernel, as expected. As a consequence it\nis established that the local correlation functions in the scaling limit do not\ndepend on the particular sequence of discrete inner shapes that converge to V.\nA detailed analysis of the correlation kernels at the top of the limit shape\nand of the frozen boundary is given. It is shown that depending on the slope of\nthe linear section of the back wall, the system exhibits behavior observed in\neither [OR2] or [BMRT]. \n\n"}
{"id": "1001.4766", "contents": "Title: Formulas for ASEP with Two-Sided Bernoulli Initial Condition Abstract: For the asymmetric simple exclusion process on the integer lattice with\ntwo-sided Bernoulli initial condition, we derive exact formulas for the\nfollowing quantities: (1) the probability that site x is occupied at time t;\n(2) a correlation function, the probability that site 0 is occupied at time 0\nand site x is occupied at time t; (3) the distribution function for the total\nflux across 0 at time t and its exponential generating function. \n\n"}
{"id": "1002.2702", "contents": "Title: Bayesian computational methods Abstract: In this chapter, we will first present the most standard computational\nchallenges met in Bayesian Statistics, focussing primarily on mixture\nestimation and on model choice issues, and then relate these problems with\ncomputational solutions. Of course, this chapter is only a terse introduction\nto the problems and solutions related to Bayesian computations. For more\ncomplete references, see Robert and Casella (2004, 2009), or Marin and Robert\n(2007), among others. We also restrain from providing an introduction to\nBayesian Statistics per se and for comprehensive coverage, address the reader\nto Robert (2007), (again) among others. \n\n"}
{"id": "1002.3640", "contents": "Title: Improved EM for Mixture Proportions with Applications to Nonparametric\n  ML Estimation for Censored Data Abstract: Improved EM strategies, based on the idea of efficient data augmentation\n(Meng and van Dyk 1997, 1998), are presented for ML estimation of mixture\nproportions. The resulting algorithms inherit the simplicity, ease of\nimplementation, and monotonic convergence properties of EM, but have\nconsiderably improved speed. Because conventional EM tends to be slow when\nthere exists a large overlap between the mixture components, we can improve the\nspeed without sacrificing the simplicity or stability, if we can reformulate\nthe problem so as to reduce the amount of overlap. We propose simple\n\"squeezing\" strategies for that purpose. Moreover, for high-dimensional\nproblems, such as computing the nonparametric MLE of the distribution function\nwith censored data, a natural and effective remedy for conventional EM is to\nadd exchange steps (based on improved EM) between adjacent mixture components,\nwhere the overlap is most severe. Theoretical considerations show that the\nresulting EM-type algorithms, when carefully implemented, are globally\nconvergent. Simulated and real data examples show dramatic improvement in speed\nin realistic situations. \n\n"}
{"id": "1003.0243", "contents": "Title: Perfect simulation using dominated coupling from the past with\n  application to area-interaction point processes and wavelet thresholding Abstract: We consider perfect simulation algorithms for locally stable point processes\nbased on dominated coupling from the past, and apply these methods in two\ndifferent contexts. A new version of the algorithm is developed which is\nfeasible for processes which are neither purely attractive nor purely\nrepulsive. Such processes include multiscale area-interaction processes, which\nare capable of modelling point patterns whose clustering structure varies\nacross scales. The other topic considered is nonparametric regression using\nwavelets, where we use a suitable area-interaction process on the discrete\nspace of indices of wavelet coefficients to model the notion that if one\nwavelet coefficient is non-zero then it is more likely that neighbouring\ncoefficients will be also. A method based on perfect simulation within this\nmodel shows promising results compared to the standard methods which threshold\ncoefficients independently. \n\n"}
{"id": "1003.4251", "contents": "Title: Fluctuations in random complex zeroes: Asymptotic normality revisited Abstract: By random complex zeroes we mean the zero set of a random entire function\nwhose Taylor coefficients are independent complex-valued Gaussian variables,\nand the variance of the k-th coefficient is 1/k!. This zero set is distribution\ninvariant with respect to isometries of the complex plane. Extending the\nprevious results of Sodin and Tsirelson, we compute the variance of linear\nstatistics of random complex zeroes, and find close to optimal conditions on a\ntest-function that yield asymptotic normality of fluctuations of the\ncorresponding linear statistics. We also provide examples of test-functions\nwith abnormal fluctuations of linear statistics. \n\n"}
{"id": "1004.4391", "contents": "Title: Locally most powerful sequential tests of a simple hypothesis vs.\n  One-sided alternatives for independent observations Abstract: Let $X_1,X_2,..., X_n,...$ be a stochastic process with independent values\nwhose distribution $P_\\theta$ depends on an unknown parameter $\\theta$,\n$\\theta\\in\\Theta$, where $\\Theta$ is an open subset of the real line. The\nproblem of testing $H_0:$ $\\theta=\\theta_0$ vs. a composite alternative $H_1:$\n$\\theta>\\theta_0$ is considered, where $\\theta_0\\in\\Theta$ is a fixed value of\nthe parameter. The main objective of this work is the characterization of the\nstructure of the locally most powerful (in the sense of Berk) sequential tests\nin this problem. \n\n"}
{"id": "1004.4815", "contents": "Title: Universal A Posteriori Metrics Game Abstract: Over binary input channels, uniform distribution is a universal prior, in the\nsense that it allows to maximize the worst case mutual information over all\nbinary input channels, ensuring at least 94.2% of the capacity. In this paper,\nwe address a similar question, but with respect to a universal generalized\nlinear decoder. We look for the best collection of finitely many a posteriori\nmetrics, to maximize the worst case mismatched mutual information achieved by\ndecoding with these metrics (instead of an optimal decoder such as the Maximum\nLikelihood (ML) tuned to the true channel). It is shown that for binary input\nand output channels, two metrics suffice to actually achieve the same\nperformance as an optimal decoder. In particular, this implies that there exist\na decoder which is generalized linear and achieves at least 94.2% of the\ncompound capacity on any compound set, without the knowledge of the underlying\nset. \n\n"}
{"id": "1004.5046", "contents": "Title: Area distribution and the average shape of a L\\'evy bridge Abstract: We consider a one dimensional L\\'evy bridge x_B of length n and index 0 <\n\\alpha < 2, i.e. a L\\'evy random walk constrained to start and end at the\norigin after n time steps, x_B(0) = x_B(n)=0. We compute the distribution\nP_B(A,n) of the area A = \\sum_{m=1}^n x_B(m) under such a L\\'evy bridge and\nshow that, for large n, it has the scaling form P_B(A,n) \\sim n^{-1-1/\\alpha}\nF_\\alpha(A/n^{1+1/\\alpha}), with the asymptotic behavior F_\\alpha(Y) \\sim\nY^{-2(1+\\alpha)} for large Y. For \\alpha=1, we obtain an explicit expression of\nF_1(Y) in terms of elementary functions. We also compute the average profile <\n\\tilde x_B (m) > at time m of a L\\'evy bridge with fixed area A. For large n\nand large m and A, one finds the scaling form < \\tilde x_B(m) > = n^{1/\\alpha}\nH_\\alpha({m}/{n},{A}/{n^{1+1/\\alpha}}), where at variance with Brownian bridge,\nH_\\alpha(X,Y) is a non trivial function of the rescaled time m/n and rescaled\narea Y = A/n^{1+1/\\alpha}. Our analytical results are verified by numerical\nsimulations. \n\n"}
{"id": "1005.3908", "contents": "Title: Some remarks on weighted logarithmic Sobolev inequality Abstract: We give here a simple proof of weighted logarithmic Sobolev inequality, for\nexample for Cauchy type measures, with optimal weight, sharpening results of\nBobkov-Ledoux. Some consequences are also discussed. \n\n"}
{"id": "1005.5275", "contents": "Title: The Stochastic Wave Equation with Multiplicative Fractional Noise: a\n  Malliavin calculus approach Abstract: We consider the stochastic wave equation with multiplicative noise, which is\nfractional in time with index $H>1/2$, and has a homogeneous spatial covariance\nstructure given by the Riesz kernel of order $\\alpha$. The solution is\ninterpreted using the Skorohod integral. We show that the sufficient condition\nfor the existence of the solution is $\\alpha>d-2$, which coincides with the\ncondition obtained in Dalang (1999), when the noise is white in time. Under\nthis condition, we obtain estimates for the $p$-th moments of the solution, we\ndeduce its H\\\"older continuity, and we show that the solution is Malliavin\ndifferentiable of any order. When $d \\leq 2$, we prove that the first-order\nMalliavin derivative of the solution satisfies a certain integral equation. \n\n"}
{"id": "1006.1338", "contents": "Title: Crossover distributions at the edge of the rarefaction fan Abstract: We consider the weakly asymmetric limit of simple exclusion process with\ndrift to the left, starting from step Bernoulli initial data with\n$\\rho_-<\\rho_+$ so that macroscopically one has a rarefaction fan. We study the\nfluctuations of the process observed along slopes in the fan, which are given\nby the Hopf--Cole solution of the Kardar-Parisi-Zhang (KPZ) equation, with\nappropriate initial data. For slopes strictly inside the fan, the initial data\nis a Dirac delta function and the one point distribution functions have been\ncomputed in [Comm. Pure Appl. Math. 64 (2011) 466-537] and [Nuclear Phys. B 834\n(2010) 523-542]. At the edge of the rarefaction fan, the initial data is\none-sided Brownian. We obtain a new family of crossover distributions giving\nthe exact one-point distributions of this process, which converge, as\n$T\\nearrow\\infty$ to those of the Airy $\\mathcal{A}_{2\\to \\mathrm{BM}}$\nprocess. As an application, we prove moment and large deviation estimates for\nthe equilibrium Hopf-Cole solution of KPZ. These bounds rely on the apparently\nnew observation that the FKG inequality holds for the stochastic heat equation.\nFinally, via a Feynman-Kac path integral, the KPZ equation also governs the\nfree energy of the continuum directed polymer, and thus our formula may also be\ninterpreted in those terms. \n\n"}
{"id": "1006.4818", "contents": "Title: Stability (over time) of Modified-CS and LS-CS for Recursive Causal\n  Sparse Reconstruction Abstract: In this work, we obtain sufficient conditions for the ``stability\" of our\nrecently proposed algorithms, modified-CS (for noisy measurements) and Least\nSquares CS-residual (LS-CS), designed for recursive reconstruction of sparse\nsignal sequences from noisy measurements. By ``stability\" we mean that the\nnumber of misses from the current support estimate and the number of extras in\nit remain bounded by a time-invariant value at all times. The concept is\nmeaningful only if the bound is small compared to the current signal support\nsize. A direct corollary is that the reconstruction errors are also bounded by\na time-invariant and small value. \n\n"}
{"id": "1007.0275", "contents": "Title: Coupling by reflection of diffusion processes via discrete approximation\n  under a backward Ricci flow Abstract: A coupling by reflection of a time-inhomogeneous diffusion process on a\nmanifold are studied. The condition we assume is a natural time-inhomogeneous\nextension of lower Ricci curvature bounds. In particular, it includes the case\nof backward Ricci flow. As in time-homogeneous cases, our coupling provides a\ngradient estimate of the diffusion semigroup which yields the strong Feller\nproperty. To construct the coupling via discrete approximation, we establish\nthe convergence in law of geodesic random walks as well as a uniform\nnon-explosion type estimate. \n\n"}
{"id": "1007.0312", "contents": "Title: Extremes of the standardized Gaussian noise Abstract: Let $\\{\\xi_n, n\\in\\Z^d\\}$ be a $d$-dimensional array of i.i.d. Gaussian\nrandom variables and define $\\SSS(A)=\\sum_{n\\in A} \\xi_n$, where $A$ is a\nfinite subset of $\\Z^d$. We prove that the appropriately normalized maximum of\n$\\SSS(A)/\\sqrt{|A|}$, where $A$ ranges over all discrete cubes or rectangles\ncontained in $\\{1,\\ldots,n\\}^d$, converges in the weak sense to the Gumbel\nextreme-value distribution as $n\\to\\infty$. We also prove continuous-time\ncounterparts of these results. \n\n"}
{"id": "1007.2388", "contents": "Title: p-integrable solutions to multidimensional BSDEs and degenerate systems\n  of PDEs with logarithmic nonlinearities Abstract: We study multidimensional backward stochastic differential equations (BSDEs)\nwhich cover the logarithmic nonlinearity u log u. More precisely, we establish\nthe existence and uniqueness as well as the stability of p-integrable solutions\n(p > 1) to multidimensional BSDEs with a p-integrable terminal condition and a\nsuper-linear growth generator in the both variables y and z. This is done with\na generator f(y, z) which can be neither locally monotone in the variable y nor\nlocally Lipschitz in the variable z. Moreover, it is not uniformly continuous.\nAs application, we establish the existence and uniqueness of Sobolev solutions\nto possibly degenerate systems of semilinear parabolic PDEs with super-linear\ngrowth generator and an p-integrable terminal data. Our result cover, for\ninstance, certain (systems of) PDEs arising in physics. \n\n"}
{"id": "1007.4013", "contents": "Title: Quasi-concave density estimation Abstract: Maximum likelihood estimation of a log-concave probability density is\nformulated as a convex optimization problem and shown to have an equivalent\ndual formulation as a constrained maximum Shannon entropy problem. Closely\nrelated maximum Renyi entropy estimators that impose weaker concavity\nrestrictions on the fitted density are also considered, notably a minimum\nHellinger discrepancy estimator that constrains the reciprocal of the\nsquare-root of the density to be concave. A limiting form of these estimators\nconstrains solutions to the class of quasi-concave densities. \n\n"}
{"id": "1007.4148", "contents": "Title: Reconstruction of a Low-rank Matrix in the Presence of Gaussian Noise Abstract: In this paper we study the problem of reconstruction of a low-rank matrix\nobserved with additive Gaussian noise. First we show that under mild\nassumptions (about the prior distribution of the signal matrix) we can restrict\nour attention to reconstruction methods that are based on the singular value\ndecomposition of the observed matrix and act only on its singular values\n(preserving the singular vectors). Then we determine the effect of noise on the\nSVD of low-rank matrices by building a connection between matrix reconstruction\nproblem and spiked population model in random matrix theory. Based on this\nknowledge, we propose a new reconstruction method, called RMT, that is designed\nto reverse the effect of the noise on the singular values of the signal matrix\nand adjust for its effect on the singular vectors. With an extensive simulation\nstudy we show that the proposed method outperform even oracle versions of both\nsoft and hard thresholding methods and closely matches the performance of a\ngeneral oracle scheme. \n\n"}
{"id": "1008.2850", "contents": "Title: Time reversal of Volterra processes driven stochastic differential\n  equation Abstract: We consider stochastic differential equations driven by some Volterra\nprocesses. Under time reversal, these equations are transformed into past\ndependent stochastic differential equations driven by a standard Brownian\nmotion. We are then in position to derive existence and uniqueness of solutions\nof the Volterra driven SDE considered at the beginning. \n\n"}
{"id": "1008.3936", "contents": "Title: Spectral Curve of Periodic Fisher Graphs Abstract: We study the spectral curves of dimer models on periodic Fisher graphs,\nobtained from a ferromagnetic Ising model on $\\mathbb{Z}^2$. The spectral curve\nis defined by the zero locus of the determinant of a modified weighted\nadjacency matrix. We prove that either they are disjoint from the unit torus\n($\\mathbb{T}^2=\\{(z,w):|z|=1,|w|=1\\}$) or they intersect $\\mathbb{T}^2$ at a\nsingle real point. \n\n"}
{"id": "1008.4321", "contents": "Title: The self-avoiding walk in a strip Abstract: We review the existence of the infinite length self-avoiding walk in the half\nplane and its relationship to bridges. We prove that this probability measure\nis also given by the limit as $\\beta \\rightarrow \\beta_c-$ of the probability\nmeasure on all finite length walks $\\omega$ with the probability of $\\omega$\nproportional to $\\beta_c^{|\\omega|}$ where $|\\omega|$ is the number of steps in\n$\\omega$. The self-avoiding walk in a strip $\\{z : 0<\\Im(z)<y\\}$ is defined by\nconsidering all self-avoiding walks $\\omega$ in the strip which start at the\norigin and end somewhere on the top boundary with probability proportional to\n$\\beta_c^{|\\omega|}$ We prove that this probability measure may be obtained by\nconditioning the SAW in the half plane to have a bridge at height $y$. This\nobservation is the basis for simulations to test conjectures on the\ndistribution of the endpoint of the SAW in a strip and the relationship between\nthe distribution of this strip SAW and SLE$_{8/3}$. \n\n"}
{"id": "1009.1031", "contents": "Title: A mathematical model of the Mafia game Abstract: Mafia (also called Werewolf) is a party game. The participants are divided\ninto two competing groups: citizens and a mafia. The objective is to eliminate\nthe opponent group. The game consists of two consecutive phases (day and night)\nand a certain set of actions (e.g. lynching during day). The mafia members have\nadditional powers (knowing each other, killing during night) whereas the\ncitizens are more numerous.\n  We propose a simple mathematical model of the game, which is essentially a\npure death process with discrete time. We find the closed-form solutions for\nthe mafia winning-chance, w(n,m), as well as for the evolution of the game.\nMoreover, we investigate the discrete properties of results, as well as their\ncontinuous-time approximations.\n  It turns out that a relatively small number of the mafia members, i.e.\nproportional to the square root of the total number of players, gives equal\nwinning-chance for both groups. Furthermore, the game strongly depends on the\nparity of the total number of players. \n\n"}
{"id": "1009.1042", "contents": "Title: Backward stochastic differential equations under super linear\n  G-expectation and associated Hamilton-Jacobi-Bellman equations Abstract: This paper first studies super linear G-expectation. Uniqueness and existence\ntheorem for backward stochastic differential equations (BSDEs) under super\nlinear expectation is established to provide probabilistic interpretation for\nthe viscosity solution of a class of Hamilton-Jacobi-Bellman equations,\nincluding the well known Black-Scholes-Barrenblett equation, arising in the\nuncertainty volatility model in mathematical finance. We also show that BSDEs\nunder super linear expectation could characterize a class of stochastic control\nproblems. A direct connection between recursive super (sub) strategies with\nmutually singular probability measures and classical stochastic control\nproblems is provided. By this result we give representation for solutions of\nBlack-Scholes-Barrenblett equations and G-heat equations. \n\n"}
{"id": "1009.1926", "contents": "Title: Robust Bayesian variable selection with sub-harmonic priors Abstract: This paper studies Bayesian variable selection in linear models with general\nspherically symmetric error distributions. We propose sub-harmonic priors which\narise as a class of mixtures of Zellner's g-priors for which the Bayes factors\nare independent of the underlying error distribution, as long as it is in the\nspherically symmetric class. Because of this invariance to spherically\nsymmetric error distribution, we refer to our method as a robust Bayesian\nvariable selection method. We demonstrate that our Bayes factors have model\nselection consistency and are coherent. We also develop Laplace approximations\nto Bayes factors for a number of recently studied mixtures of g-priors that\nhave recently appeared in the literature (including our own) for Gaussian\nerrors. These approximations, in each case, are given by the Gaussian Bayes\nfactor based on BIC times a simple rational function of the prior's\nhyper-parameters and the R^2's for the respective models. We also extend model\nselection consistency for several g-prior based Bayes factor methods for\nGaussian errors to the entire class of spherically symmetric error\ndistributions. Additionally we demonstrate that our class of sub-harmonic\npriors are the only ones within a large class of mixtures of g-priors studied\nin the literature which are robust in our sense. A simulation study and an\nanalysis of two real data sets indicates good performance of our robust Bayes\nfactors relative to BIC and to other mixture of g-prior based methods. \n\n"}
{"id": "1009.2838", "contents": "Title: From logarithmic to subdiffusive polynomial fluctuations for internal\n  DLA and related growth models Abstract: We consider a cluster growth model on the d-dimensional lattice, called\ninternal diffusion limited aggregation (internal DLA). In this model, random\nwalks start at the origin, one at a time, and stop moving when reaching a site\nnot occupied by previous walks. It is known that the asymptotic shape of the\ncluster is spherical. When dimension is 2 or more, we prove that fluctuations\nwith respect to a sphere are at most a power of the logarithm of its radius in\ndimension d larger than or equal to 2. In so doing, we introduce a closely\nrelated cluster growth model, that we call the flashing process, whose\nfluctuations are controlled easily and accurately. This process is coupled to\ninternal DLA to yield the desired bound. Part of our proof adapts the approach\nof Lawler, Bramson and Griffeath, on another space scale, and uses a sharp\nestimate (written by Blach\\`ere in our Appendix) on the expected time spent by\na random walk inside an annulus. \n\n"}
{"id": "1009.3513", "contents": "Title: Hitting times of Bessel processes Abstract: Let $T_1^{(\\mu)}$ be the first hitting time of the point 1 by the Bessel\nprocess with index $\\mu\\in \\R$ starting from $x>1$. Using an integral formula\nfor the density $q_x^{(\\mu)}(t)$ of $T_1^{(\\mu)}$, obtained in Byczkowski,\nRyznar (Studia Math., 173(1):19-38, 2006), we prove sharp estimates of the\ndensity of $T_1^{(\\mu)}$ which exibit the dependence both on time and space\nvariables. Our result provides optimal estimates for the density of the hitting\ntime of the unit ball by the Brownian motion in $\\mathbb{R}^n$, which improve\nexisting bounds. Another application is to provide sharp estimates for the\nPoisson kernel for half-spaces for hyperbolic Brownian motion in real\nhyperbolic spaces. \n\n"}
{"id": "1009.5511", "contents": "Title: Constructions of Coupling Processes for L\\'evy Processes Abstract: We construct optimal Markov couplings of L\\'{e}vy processes, whose L\\'evy\n(jump) measure has an absolutely continuous component. The construction is\nbased on properties of subordinate Brownian motions and the coupling of\nBrownian motions by reflection. \n\n"}
{"id": "1009.5689", "contents": "Title: Square-Root Lasso: Pivotal Recovery of Sparse Signals via Conic\n  Programming Abstract: We propose a pivotal method for estimating high-dimensional sparse linear\nregression models, where the overall number of regressors $p$ is large,\npossibly much larger than $n$, but only $s$ regressors are significant. The\nmethod is a modification of the lasso, called the square-root lasso. The method\nis pivotal in that it neither relies on the knowledge of the standard deviation\n$\\sigma$ or nor does it need to pre-estimate $\\sigma$. Moreover, the method\ndoes not rely on normality or sub-Gaussianity of noise. It achieves near-oracle\nperformance, attaining the convergence rate $\\sigma \\{(s/n)\\log p\\}^{1/2}$ in\nthe prediction norm, and thus matching the performance of the lasso with known\n$\\sigma$. These performance results are valid for both Gaussian and\nnon-Gaussian errors, under some mild moment restrictions. We formulate the\nsquare-root lasso as a solution to a convex conic programming problem, which\nallows us to implement the estimator using efficient algorithmic methods, such\nas interior-point and first-order methods. \n\n"}
{"id": "1010.0026", "contents": "Title: Well-posedness of Backward Stochastic Differential Equations with\n  General Filtration Abstract: This paper is addressed to the well-posedness of some linear and semilinear\nbackward stochastic differential equations with general filtration, without\nusing the Martingale Representation Theorem. The point of our approach is to\nintroduce a new notion of solution, i.e., the transposition solution, which\ncoincides with the usual strong solution when the filtration is natural but it\nis more flexible for the general filtration than the existing notion of\nsolutions. A comparison theorem for transposition solutions is also presented. \n\n"}
{"id": "1010.3390", "contents": "Title: Local shrinkage rules, Levy processes, and regularized regression Abstract: We use Levy processes to generate joint prior distributions, and therefore\npenalty functions, for a location parameter as p grows large. This generalizes\nthe class of local-global shrinkage rules based on scale mixtures of normals,\nilluminates new connections among disparate methods, and leads to new results\nfor computing posterior means and modes under a wide class of priors. We extend\nthis framework to large-scale regularized regression problems where p>n, and\nprovide comparisons with other methodologies. \n\n"}
{"id": "1011.0548", "contents": "Title: Sample path deviations of the Wiener and the Ornstein-Uhlenbeck process\n  from its bridges Abstract: We study sample path deviations of the Wiener process from three different\nrepresentations of its bridge: anticipative version, integral representation\nand space-time transform. Although these representations of the Wiener bridge\nare equal in law, their sample path behavior is quite different. Our results\nnicely demonstrate this fact. We calculate and compare the expected absolute,\nquadratic and conditional quadratic path deviations of the different\nrepresentations of the Wiener bridge from the original Wiener process. It is\nfurther shown that the presented qualitative behavior of sample path deviations\nis not restricted only to the Wiener process and its bridges. Sample path\ndeviations of the Ornstein-Uhlenbeck process from its bridge versions are also\nconsidered and we give some quantitative answers also in this case. \n\n"}
{"id": "1011.1703", "contents": "Title: Point process modeling for directed interaction networks Abstract: Network data often take the form of repeated interactions between senders and\nreceivers tabulated over time. A primary question to ask of such data is which\ntraits and behaviors are predictive of interaction. To answer this question, a\nmodel is introduced for treating directed interactions as a multivariate point\nprocess: a Cox multiplicative intensity model using covariates that depend on\nthe history of the process. Consistency and asymptotic normality are proved for\nthe resulting partial-likelihood-based estimators under suitable regularity\nconditions, and an efficient fitting procedure is described. Multicast\ninteractions--those involving a single sender but multiple receivers--are\ntreated explicitly. The resulting inferential framework is then employed to\nmodel message sending behavior in a corporate e-mail network. The analysis\ngives a precise quantification of which static shared traits and dynamic\nnetwork effects are predictive of message recipient selection. \n\n"}
{"id": "1011.2958", "contents": "Title: Superhedging and Dynamic Risk Measures under Volatility Uncertainty Abstract: We consider dynamic sublinear expectations (i.e., time-consistent coherent\nrisk measures) whose scenario sets consist of singular measures corresponding\nto a general form of volatility uncertainty. We derive a c\\`adl\\`ag nonlinear\nmartingale which is also the value process of a superhedging problem. The\nsuperhedging strategy is obtained from a representation similar to the optional\ndecomposition. Furthermore, we prove an optional sampling theorem for the\nnonlinear martingale and characterize it as the solution of a second order\nbackward SDE. The uniqueness of dynamic extensions of static sublinear\nexpectations is also studied. \n\n"}
{"id": "1011.5600", "contents": "Title: Discontinuous Stochastic Differential Equations Driven by L\\'evy\n  Processes Abstract: In this article we prove the pathwise uniqueness for stochastic differential\nequations in $\\mR^d$ with time-dependent Sobolev drifts, and driven by\nsymmetric $\\alpha$-stable processes provided that $\\alpha\\in(1,2)$ and its\nspectral measure is non-degenerate. In particular, the drift is allowed to have\njump discontinuity when $\\alpha\\in(\\frac{2d}{d+1},2)$. Our proof is based on\nsome estimates of Krylov's type for purely discontinuous semimartingales. \n\n"}
{"id": "1012.4818", "contents": "Title: Outliers in the spectrum of iid matrices with bounded rank perturbations Abstract: It is known that if one perturbs a large iid random matrix by a bounded rank\nerror, then the majority of the eigenvalues will remain distributed according\nto the circular law. However, the bounded rank perturbation may also create one\nor more outlier eigenvalues. We show that if the perturbation is small, then\nthe outlier eigenvalues are created next to the outlier eigenvalues of the\nbounded rank perturbation; but if the perturbation is large, then many more\noutliers can be created, and their law is governed by the zeroes of a random\nLaurent series with Gaussian coefficients. On the other hand, these outliers\nmay be eliminated by enforcing a row sum condition on the final matrix. \n\n"}
{"id": "1101.3099", "contents": "Title: On the resilience of Hamiltonicity and optimal packing of Hamilton\n  cycles in random graphs Abstract: Let $\\bk=(k_1,...,k_n)$ be a sequence of $n$ integers. For an increasing\nmonotone graph property $\\mP$ we say that a base graph $G=([n],E)$ is\n\\emph{$\\bk$-resilient} with respect to $\\mP$ if for every subgraph $H\\subseteq\nG$ such that $d_H(i)\\leq k_i$ for every $1\\leq i\\leq n$ the graph $G-H$\npossesses $\\mP$. This notion naturally extends the idea of the \\emph{local\nresilience} of graphs recently initiated by Sudakov and Vu. In this paper we\nstudy the $\\bk$-resilience of a typical graph from $\\GNP$ with respect to the\nHamiltonicity property where we let $p$ range over all values for which the\nbase graph is expected to be Hamiltonian. In particular, we prove that for\nevery $\\epsilon>0$ and $p\\geq\\frac{\\ln n+\\ln\\ln n +\\omega(1)}{n}$ if a graph is\nsampled from $\\GNP$ then with high probability removing from each vertex of\n\"small\" degree all incident edges but two and from any other vertex at most a\n$(\\frac{1}{3}-\\epsilon)$-fraction of the incident edges will result in a\nHamiltonian graph.\n  Considering this generalized approach to the notion of resilience allows to\nestablish several corollaries which improve on the best known bounds of\nHamiltonicity related questions. It implies that for every positive\n$\\epsilon>0$ and large enough values of $K$, if $p>\\frac{K\\ln n}{n}$ then with\nhigh probability the local resilience of $\\GNP$ with respect to being\nHamiltonian is at least $(1-\\epsilon)np/3$, improving on the previous bound for\nthis range of $p$. Another implication is a result on optimal packing of edge\ndisjoint Hamilton cycles in a random graph. We prove that if\n$p\\leq\\frac{1.02\\ln n}{n}$ then with high probability a graph $G$ sampled from\n$\\GNP$ contains $\\lfloor\\frac{\\delta(G)}{2}\\rfloor$ edge disjoint Hamilton\ncycles, extending the previous range of $p$ for which this was known to hold. \n\n"}
{"id": "1101.4041", "contents": "Title: Randomly biased walks on subcritical trees Abstract: As a model of trapping by biased motion in random structure, we study the\ntime taken for a biased random walk to return to the root of a subcritical\nGalton-Watson tree. We do so for trees in which these biases are randomly\nchosen, independently for distinct edges, according to a law that satisfies a\nlogarithmic non-lattice condition. The mean return time of the walk is in\nessence given by the total conductance of the tree. We determine the asymptotic\ndecay of this total conductance, finding it to have a pure power-law decay. In\nthe case of the conductance associated to a single vertex at maximal depth in\nthe tree, this asymptotic decay may be analysed by the classical defective\nrenewal theorem, due to the non-lattice edge-bias assumption.\n  However, the derivation of the decay for total conductance requires computing\nan additional constant multiple outside the power-law that allows for the\ncontribution of all vertices close to the base of the tree. This computation\nentails a detailed study of a convenient decomposition of the tree, under\nconditioning on the tree having high total conductance. As such, our principal\nconclusion may be viewed as a development of renewal theory in the context of\nrandom environments.\n  For randomly biased random walk on a supercritical Galton-Watson tree with\npositive extinction probability, our main results may be regarded as a\ndescription of the slowdown mechanism caused by the presence of subcritical\ntrees adjacent to the backbone that may act as traps that detain the walker.\nIndeed, this conclusion is exploited in \\cite{GerardAlan} to obtain a stable\nlimiting law for walker displacement in such a tree. \n\n"}
{"id": "1101.4368", "contents": "Title: Inferences in Bayesian variable selection problems with large model\n  spaces Abstract: An important aspect of Bayesian model selection is how to deal with huge\nmodel spaces, since exhaustive enumeration of all the models entertained is\nunfeasible and inferences have to be based on the very small proportion of\nmodels visited. This is the case for the variable selection problem, with a\nmoderate to large number of possible explanatory variables being considered in\nthis paper. We review some of the strategies proposed in the literature and\nargue that inferences based on empirical frequencies via Markov Chain Monte\nCarlo sampling of the posterior distribution outperforms recently proposed\nsearching methods. We give a plausible yet very simple explanation of this\neffect, showing that estimators based on frequencies are unbiased. The results\nobtained in two illustrative examples provide strong evidence in favor of our\narguments. \n\n"}
{"id": "1101.5619", "contents": "Title: A representation of exchangeable hierarchies by sampling from real trees Abstract: A hierarchy on a set $S$, also called a total partition of $S$, is a\ncollection $\\mathcal{H}$ of subsets of $S$ such that $S \\in \\mathcal{H}$, each\nsingleton subset of $S$ belongs to $\\mathcal{H}$, and if $A, B \\in \\mathcal{H}$\nthen $A \\cap B$ equals either $A$ or $B$ or $\\varnothing$. Every exchangeable\nrandom hierarchy of positive integers has the same distribution as a random\nhierarchy $\\mathcal{H}$ associated as follows with a random real tree\n$\\mathcal{T}$ equipped with root element $0$ and a random probability\ndistribution $p$ on the Borel subsets of $\\mathcal{T}$: given\n$(\\mathcal{T},p)$, let $t_1,t_2, ...$ be independent and identically\ndistributed according to $p$, and let $\\mathcal{H}$ comprise all singleton\nsubsets of $\\mathbb{N}$, and every subset of the form $\\{j: t_j \\in F_x\\}$ as\n$x$ ranges over $\\mathcal{T}$, where $F_x$ is the fringe subtree of\n$\\mathcal{T}$ rooted at $x$. There is also the alternative characterization:\nevery exchangeable random hierarchy of positive integers has the same\ndistribution as a random hierarchy $\\mathcal{H}$ derived as follows from a\nrandom hierarchy $\\mathscr{H}$ on $[0,1]$ and a family $(U_j)$ of IID uniform\n[0,1] random variables independent of $\\mathscr{H}$: let $\\mathcal{H}$ comprise\nall sets of the form $\\{j: U_j \\in B\\}$ as $B$ ranges over the members of\n$\\mathscr{H}$. \n\n"}
{"id": "1102.0712", "contents": "Title: Matchings on infinite graphs Abstract: Elek and Lippner (2010) showed that the convergence of a sequence of\nbounded-degree graphs implies the existence of a limit for the proportion of\nvertices covered by a maximum matching. We provide a characterization of the\nlimiting parameter via a local recursion defined directly on the limit of the\ngraph sequence. Interestingly, the recursion may admit multiple solutions,\nimplying non-trivial long-range dependencies between the covered vertices. We\novercome this lack of correlation decay by introducing a perturbative parameter\n(temperature), which we let progressively go to zero. This allows us to\nuniquely identify the correct solution. In the important case where the graph\nlimit is a unimodular Galton-Watson tree, the recursion simplifies into a\ndistributional equation that can be solved explicitly, leading to a new\nasymptotic formula that considerably extends the well-known one by Karp and\nSipser for Erd\\\"os-R\\'enyi random graphs. \n\n"}
{"id": "1102.2868", "contents": "Title: Interference Networks with Point-to-Point Codes Abstract: The paper establishes the capacity region of the Gaussian interference\nchannel with many transmitter-receiver pairs constrained to use point-to-point\ncodes. The capacity region is shown to be strictly larger in general than the\nachievable rate regions when treating interference as noise, using successive\ninterference cancellation decoding, and using joint decoding. The gains in\ncoverage and achievable rate using the optimal decoder are analyzed in terms of\nensemble averages using stochastic geometry. In a spatial network where the\nnodes are distributed according to a Poisson point process and the channel path\nloss exponent is $\\beta > 2$, it is shown that the density of users that can be\nsupported by treating interference as noise can scale no faster than\n$B^{2/\\beta}$ as the bandwidth $B$ grows, while the density of users can scale\nlinearly with $B$ under optimal decoding. \n\n"}
{"id": "1102.5733", "contents": "Title: On the theorem of Duminil-Copin and Smirnov about the number of\n  self-avoiding walks in the hexagonal lattice Abstract: This is an exposition of the theorem from the title, which says that the\nnumber of self-avoiding walks with n steps in the hexagonal lattice has\nasymptotics (2cos(pi/8))^{n+o(n)}. We lift the key identity to formal level and\nsimplify the part of the proof bounding the growth constant from below. In our\ncalculation the lower bound comes from an identity asserting that a linear\ncombination of 288 generating functions counting self-avoiding walks in a\ncertain domain by length, final edge direction and winding number modulo 48\nequals the geometric series 2cos(pi/8)x + (2cos(pi/8))^2x^2 + ... . \n\n"}
{"id": "1103.1498", "contents": "Title: The two-sided infinite extension of the Mallows model for random\n  permutations Abstract: We introduce a probability distribution Q on the group of permutations of the\nset Z of integers. Distribution Q is a natural extension of the Mallows\ndistribution on the finite symmetric group. A one-sided infinite counterpart of\nQ, supported by the group of permutations of the set N of natural numbers, was\nstudied previously in our paper [Gnedin and Olshanski, Ann. Prob. 38 (2010),\n2103-2135; arXiv:0907.3275]. We analyze various features of Q such as its\nsymmetries, the support, and the marginal distributions. \n\n"}
{"id": "1103.2041", "contents": "Title: Random sum-free subsets of Abelian groups Abstract: We characterize the structure of maximum-size sum-free subsets of a random\nsubset of an Abelian group $G$. In particular, we determine the threshold $p_c\n\\approx \\sqrt{\\log n / n}$ above which, with high probability as $|G| \\to\n\\infty$, each such subset is contained in a maximum-size sum-free subset of\n$G$, whenever $q$ divides $|G|$ for some (fixed) prime $q$ with $q \\equiv 2\n\\pmod 3$. Moreover, in the special case $G = \\ZZ_{2n}$, we determine a sharp\nthreshold for the above property. The proof uses recent 'transference' theorems\nof Conlon and Gowers, together with stability theorems for sum-free subsets of\nAbelian groups. \n\n"}
{"id": "1104.0341", "contents": "Title: Small-scale inference: Empirical Bayes and confidence methods for as few\n  as a single comparison Abstract: By restricting the possible values of the proportion of null hypotheses that\nare true, the local false discovery rate (LFDR) can be estimated using as few\nas one comparison. The proportion of proteins with equivalent abundance was\nestimated to be about 20% for patient group I and about 90% for group II. The\nsimultaneously-estimated LFDRs give approximately the same inferences as\nindividual-protein confidence levels for group I but are much closer to\nindividual-protein LFDR estimates for group II. Simulations confirm that\nconfidence-based inference or LFDR-based inference performs markedly better for\nlow or high proportions of true null hypotheses, respectively. \n\n"}
{"id": "1104.5218", "contents": "Title: Regularity of laws and ergodicity of hypoelliptic SDEs driven by rough\n  paths Abstract: We consider differential equations driven by rough paths and study the\nregularity of the laws and their long time behavior. In particular, we focus on\nthe case when the driving noise is a rough path valued fractional Brownian\nmotion with Hurst parameter $H\\in(\\frac{1}{3},\\frac{1}{2}]$. Our contribution\nin this work is twofold. First, when the driving vector fields satisfy\nH\\\"{o}rmander's celebrated \"Lie bracket condition,\" we derive explicit\nquantitative bounds on the inverse of the Malliavin matrix. En route to this,\nwe provide a novel \"deterministic\" version of Norris's lemma for differential\nequations driven by rough paths. This result, with the added assumption that\nthe linearized equation has moments, will then yield that the transition laws\nhave a smooth density with respect to Lebesgue measure. Our second main result\nstates that under H\\\"{o}rmander's condition, the solutions to rough\ndifferential equations driven by fractional Brownian motion with\n$H\\in(\\frac{1}{3},\\frac{1}{2}]$ enjoy a suitable version of the strong Feller\nproperty. Under a standard controllability condition, this implies that they\nadmit a unique stationary solution that is physical in the sense that it does\nnot \"look into the future.\" \n\n"}
{"id": "1105.1475", "contents": "Title: Pivotal estimation via square-root Lasso in nonparametric regression Abstract: We propose a self-tuning $\\sqrt{\\mathrm {Lasso}}$ method that simultaneously\nresolves three important practical problems in high-dimensional regression\nanalysis, namely it handles the unknown scale, heteroscedasticity and (drastic)\nnon-Gaussianity of the noise. In addition, our analysis allows for badly\nbehaved designs, for example, perfectly collinear regressors, and generates\nsharp bounds even in extreme cases, such as the infinite variance case and the\nnoiseless case, in contrast to Lasso. We establish various nonasymptotic bounds\nfor $\\sqrt{\\mathrm {Lasso}}$ including prediction norm rate and sparsity. Our\nanalysis is based on new impact factors that are tailored for bounding\nprediction norm. In order to cover heteroscedastic non-Gaussian noise, we rely\non moderate deviation theory for self-normalized sums to achieve Gaussian-like\nresults under weak conditions. Moreover, we derive bounds on the performance of\nordinary least square (ols) applied to the model selected by $\\sqrt{\\mathrm\n{Lasso}}$ accounting for possible misspecification of the selected model. Under\nmild conditions, the rate of convergence of ols post $\\sqrt{\\mathrm {Lasso}}$\nis as good as $\\sqrt{\\mathrm {Lasso}}$'s rate. As an application, we consider\nthe use of $\\sqrt{\\mathrm {Lasso}}$ and ols post $\\sqrt{\\mathrm {Lasso}}$ as\nestimators of nuisance parameters in a generic semiparametric problem\n(nonlinear moment condition or $Z$-problem), resulting in a construction of\n$\\sqrt{n}$-consistent and asymptotically normal estimators of the main\nparameters. \n\n"}
{"id": "1105.3541", "contents": "Title: Rational weak mixing in infinite measure spaces Abstract: Rational weak mixing is a measure theoretic version of Krickeberg's strong\nratio mixing property for infinite measure preserving transformations. It\nrequires \"{\\tt density}\" ratio convergence for every pair of measurable sets in\na dense hereditary ring. Rational weak mixing implies weak rational ergodicity\nand (spectral) weak mixing. It is enjoyed for example by Markov shifts with\nOrey's strong ratio limit property. The power, subsequence version of the\nproperty is generic. \n\n"}
{"id": "1105.3929", "contents": "Title: Zeroes of Gaussian Analytic Functions with Translation-Invariant\n  Distribution Abstract: We study zeroes of Gaussian analytic functions in a strip in the complex\nplane, with translation-invariant distribution. We prove that the a limiting\nhorizontal mean counting-measure of the zeroes exists almost surely, and that\nit is non-random if and only if the spectral measure is continuous (or\ndegenerate). In this case, the mean zero-counting measure is computed in terms\nof the spectral measure. We compare the behavior with Gaussian analytic\nfunction with symmetry around the real axis. These results extend a work by\nNorbert Wiener. \n\n"}
{"id": "1105.3996", "contents": "Title: On the error estimate for cubature on Wiener space Abstract: It was pointed out in Crisan, Ghazali [2] that the error estimate for the\ncubature on Wiener space algorithm developed in Lyons, Victoir [11] requires an\nadditional assumption on the drift. In this note we demonstrate that it is\nstraightforward to adopt the analysis of Kusuoka [7] to obtain a general\nestimate without an additional assumptions on the drift. In the process we\nslightly sharpen the bounds derived in [7]. \n\n"}
{"id": "1106.1916", "contents": "Title: Threshold estimation based on a p-value framework in dose-response and\n  regression settings Abstract: We use p-values to identify the threshold level at which a regression\nfunction takes off from its baseline value, a problem motivated by applications\nin toxicological and pharmacological dose-response studies and environmental\nstatistics. We study the problem in two sampling settings: one where multiple\nresponses can be obtained at a number of different covariate-levels and the\nother the standard regression setting involving limited number of response\nvalues at each covariate. Our procedure involves testing the hypothesis that\nthe regression function is at its baseline at each covariate value and then\ncomputing the potentially approximate p-value of the test. An estimate of the\nthreshold is obtained by fitting a piecewise constant function with a single\njump discontinuity, otherwise known as a stump, to these observed p-values, as\nthey behave in markedly different ways on the two sides of the threshold. The\nestimate is shown to be consistent and its finite sample properties are studied\nthrough simulations. Our approach is computationally simple and extends to the\nestimation of the baseline value of the regression function, heteroscedastic\nerrors and to time-series. It is illustrated on some real data applications. \n\n"}
{"id": "1106.2912", "contents": "Title: A simple stochastic reactive transport model Abstract: We introduce a discrete time microscopic single particle model for kinetic\ntransport. The kinetics is modeled by a two-state Markov chain, the transport\nby deterministic advection plus a random space step. The position of the\nparticle after $n$ time steps is given by a random sum of space steps, where\nthe size of the sum is given by a Markov binomial distribution (MBD). We prove\nthat by letting the length of the time steps and the intensity of the switching\nbetween states tend to zero linearly, we obtain a random variable $S(t)$, which\nis closely connected to a well known (deterministic) PDE reactive transport\nmodel from the civil engineering literature. Our model explains (via bimodality\nof the MBD) the double peaking behavior of the concentration of the free part\nof solutes in the PDE model. Moreover, we show for instantaneous injection of\nthe solute that the partial densities of the free and adsorbed part of the\nsolute at time $t$ do exist, and satisfy the partial differential equations. \n\n"}
{"id": "1106.3381", "contents": "Title: The rates of convergence for generalized entropy of the normalized sums\n  of IID random variables Abstract: We consider the generalized differential entropy of normalized sums of\nindependent and identically distributed (IID) continuous random variables. We\nprove that the R\\'{e}nyi entropy and Tsallis entropy of order $\\alpha\\\n(\\alpha>0)$ of the normalized sum of IID continuous random variables with\nbounded moments are convergent to the corresponding R\\'{e}nyi entropy and\nTsallis entropy of the Gaussian limit, and obtain sharp rates of convergence. \n\n"}
{"id": "1106.4160", "contents": "Title: Essentially ML ASN-Minimax double sampling plans Abstract: Subject of this paper is ASN-Minimax (AM) double sampling plans by variables\nfor a normally distributed quality characteristic with unknown standard\ndeviation and two-sided specification limits. Based on the estimator p* of the\nfraction defective p, which is essentially the Maximum-Likelihood (ML)\nestimator, AM-double sampling plans are calculated by using the random\nvariables p*_1 and p*_p relating to the first and pooled samples, respectively.\nGiven p_1, p_2, {\\alpha}, and {\\beta}, no other AM-double sampling plans based\non the same estimator feature a lower maximum of the average sample number\n(ASN) while fulfilling the classical two-point condition on the corresponding\noperation characteristic (OC). \n\n"}
{"id": "1106.4432", "contents": "Title: An approximate Bayesian marginal likelihood approach for estimating\n  finite mixtures Abstract: Estimation of finite mixture models when the mixing distribution support is\nunknown is an important problem. This paper gives a new approach based on a\nmarginal likelihood for the unknown support. Motivated by a Bayesian Dirichlet\nprior model, a computationally efficient stochastic approximation version of\nthe marginal likelihood is proposed and large-sample theory is presented. By\nrestricting the support to a finite grid, a simulated annealing method is\nemployed to maximize the marginal likelihood and estimate the support. Real and\nsimulated data examples show that this novel stochastic\napproximation--simulated annealing procedure compares favorably to existing\nmethods. \n\n"}
{"id": "1106.4468", "contents": "Title: Internal Aggregation Models on Comb Lattices Abstract: The two-dimensional comb lattice $C_2$ is a natural spanning tree of the\nEuclidean lattice $\\mathbb{Z}^2$. We study three related cluster growth models\non $C_2$: internal diffusion limited aggregation (IDLA), in which random\nwalkers move on the vertices of $C_2$ until reaching an unoccupied site where\nthey stop; rotor-router aggregation in which particles perform deterministic\nwalks, and stop when reaching a site previously unoccupied; and the divisible\nsandpile model where at each vertex there is a pile of sand, for which, at each\nstep, the mass exceeding 1 is distributed equally among the neighbours. We\ndescribe the shape of the divisible sandpile cluster on $C_2$, which is then\nused to give inner bounds for IDLA and rotor-router aggregation. \n\n"}
{"id": "1106.5714", "contents": "Title: Non-parametric change-point detection using string matching algorithms Abstract: Given the output of a data source taking values in a finite alphabet, we wish\nto detect change-points, that is times when the statistical properties of the\nsource change. Motivated by ideas of match lengths in information theory, we\nintroduce a novel non-parametric estimator which we call CRECHE (CRossings\nEnumeration CHange Estimator). We present simulation evidence that this\nestimator performs well, both for simulated sources and for real data formed by\nconcatenating text sources. For example, we show that we can accurately detect\nthe point at which a source changes from a Markov chain to an IID source with\nthe same stationary distribution. Our estimator requires no assumptions about\nthe form of the source distribution, and avoids the need to estimate its\nprobabilities. Further, we establish consistency of the CRECHE estimator under\na related toy model, by establishing a fluid limit and using martingale\narguments. \n\n"}
{"id": "1106.5981", "contents": "Title: Application of Bayesian model inadequacy criterion for multiple data\n  sets to radial velocity models of exoplanet systems Abstract: We present a simple mathematical criterion for determining whether a given\nstatistical model does not describe several independent sets of measurements,\nor data modes, adequately. We derive this criterion for two data sets and\ngeneralise it to several sets by using the Bayesian updating of the posterior\nprobability density. To demonstrate the usage of the criterion, we apply it to\nobservations of exoplanet host stars by re-analysing the radial velocities of\nHD 217107, Gliese 581, and \\u{psion} Andromedae and show that the currently\nused models are not necessarily adequate in describing the properties of these\nmeasurements. We show that while the two data sets of Gliese 581 can be\nmodelled reasonably well, the noise model of HD 217107 needs to be revised. We\nalso reveal some biases in the radial velocities of \\u{psion} Andromedae and\nreport updated orbital parameters for the recently proposed 4-planet model.\nBecause of the generality of our criterion, no assumptions are needed on the\nnature of the measurements, models, or model parameters. The method we propose\ncan be applied to any astronomical problems, as well as outside the field of\nastronomy, because it is a simple consequence of the Bayes' rule of conditional\nprobabilities. \n\n"}
{"id": "1107.2353", "contents": "Title: Blending Bayesian and frequentist methods according to the precision of\n  prior information with an application to hypothesis testing Abstract: The following zero-sum game between nature and a statistician blends Bayesian\nmethods with frequentist methods such as p-values and confidence intervals.\nNature chooses a posterior distribution consistent with a set of possible\npriors. At the same time, the statistician selects a parameter distribution for\ninference with the goal of maximizing the minimum Kullback-Leibler information\ngained over a confidence distribution or other benchmark distribution. An\napplication to testing a simple null hypothesis leads the statistician to\nreport a posterior probability of the hypothesis that is informed by both\nBayesian and frequentist methodology, each weighted according how well the\nprior is known.\n  Since neither the Bayesian approach nor the frequentist approach is entirely\nsatisfactory in situations involving partial knowledge of the prior\ndistribution, the proposed procedure reduces to a Bayesian method given\ncomplete knowledge of the prior, to a frequentist method given complete\nignorance about the prior, and to a blend between the two methods given partial\nknowledge of the prior. The blended approach resembles the Bayesian method\nrather than the frequentist method to the precise extent that the prior is\nknown.\n  The problem of testing a point null hypothesis illustrates the proposed\nframework. The blended probability that the null hypothesis is true is equal to\nthe p-value or a lower bound of an unknown Bayesian posterior probability,\nwhichever is greater. Thus, given total ignorance represented by a lower bound\nof 0, the p-value is used instead of any Bayesian posterior probability. At the\nopposite extreme of a known prior, the p-value is ignored. In the intermediate\ncase, the possible Bayesian posterior probability that is closest to the\np-value is used for inference. Thus, both the Bayesian method and the\nfrequentist method influence the inferences made. \n\n"}
{"id": "1108.0298", "contents": "Title: Network Model-Assisted Inference from Respondent-Driven Sampling Data Abstract: Respondent-Driven Sampling is a method to sample hard-to-reach human\npopulations by link-tracing over their social networks. Beginning with a\nconvenience sample, each person sampled is given a small number of uniquely\nidentified coupons to distribute to other members of the target population,\nmaking them eligible for enrollment in the study. This can be an effective\nmeans to collect large diverse samples from many populations.\n  Inference from such data requires specialized techniques for two reasons.\nUnlike in standard sampling designs, the sampling process is both partially\nbeyond the control of the researcher, and partially implicitly defined.\nTherefore, it is not generally possible to directly compute the sampling\nweights necessary for traditional design-based inference. Any likelihood-based\ninference requires the modeling of the complex sampling process often beginning\nwith a convenience sample. We introduce a model-assisted approach, resulting in\na design-based estimator leveraging a working model for the structure of the\npopulation over which sampling is conducted.\n  We demonstrate that the new estimator has improved performance compared to\nexisting estimators and is able to adjust for the bias induced by the selection\nof the initial sample. We present sensitivity analyses for unknown population\nsizes and the misspecification of the working network model. We develop a\nbootstrap procedure to compute measures of uncertainty. We apply the method to\nthe estimation of HIV prevalence in a population of injecting drug users (IDU)\nin the Ukraine, and show how it can be extended to include application-specific\ninformation. \n\n"}
{"id": "1108.0523", "contents": "Title: Priors for New Physics Abstract: The interpretation of data in terms of multi-parameter models of new physics,\nusing the Bayesian approach, requires the construction of multi-parameter\npriors. We propose a construction that uses elements of Bayesian reference\nanalysis. Our idea is to initiate the chain of inference with the reference\nprior for a likelihood function that depends on a single parameter of interest\nthat is a function of the parameters of the physics model. The reference\nposterior density of the parameter of interest induces on the parameter space\nof the physics model a class of posterior densities. We propose to continue the\nchain of inference with a particular density from this class, namely, the one\nfor which indistinguishable models are equiprobable and use it as the prior for\nsubsequent analysis. We illustrate our method by applying it to the constrained\nminimal supersymmetric Standard Model and two non-universal variants of it. \n\n"}
{"id": "1108.5244", "contents": "Title: Semi-supervised logistic discrimination via labeled data and unlabeled\n  data from different sampling distributions Abstract: This article addresses the problem of classification method based on both\nlabeled and unlabeled data, where we assume that a density function for labeled\ndata is different from that for unlabeled data. We propose a semi-supervised\nlogistic regression model for classification problem along with the technique\nof covariate shift adaptation. Unknown parameters involved in proposed models\nare estimated by regularization with EM algorithm. A crucial issue in the\nmodeling process is the choices of tuning parameters in our semi-supervised\nlogistic models. In order to select the parameters, a model selection criterion\nis derived from an information-theoretic approach. Some numerical studies show\nthat our modeling procedure performs well in various cases. \n\n"}
{"id": "1109.0152", "contents": "Title: Stable Graphical Model Estimation with Random Forests for Discrete,\n  Continuous, and Mixed Variables Abstract: A conditional independence graph is a concise representation of pairwise\nconditional independence among many variables. Graphical Random Forests (GRaFo)\nare a novel method for estimating pairwise conditional independence\nrelationships among mixed-type, i.e. continuous and discrete, variables. The\nnumber of edges is a tuning parameter in any graphical model estimator and\nthere is no obvious number that constitutes a good choice. Stability Selection\nhelps choosing this parameter with respect to a bound on the expected number of\nfalse positives (error control).\n  The performance of GRaFo is evaluated and compared with various other methods\nfor p = 50, 100, and 200 possibly mixed-type variables while sample size is n =\n100 (n = 500 for maximum likelihood). Furthermore, GRaFo is applied to data\nfrom the Swiss Health Survey in order to evaluate how well it can reproduce the\ninterconnection of functional health components, personal, and environmental\nfactors, as hypothesized by the World Health Organization's International\nClassification of Functioning, Disability and Health (ICF). Finally, GRaFo is\nused to identify risk factors which may be associated with adverse\nneurodevelopment of children who suffer from trisomy 21 and experienced\nopen-heart surgery.\n  GRaFo performs well with mixed data and thanks to Stability Selection it\nprovides an error control mechanism for false positive selection. \n\n"}
{"id": "1109.3517", "contents": "Title: Convergence to the Brownian Web for a generalization of the drainage\n  network model Abstract: We introduce a system of one-dimensional coalescing nonsimple random walks\nwith long range jumps allowing crossing paths and exibiting dependence before\ncoalescence. We show that under diffusive scaling this system converges in\ndistribution to the Brownian Web. \n\n"}
{"id": "1109.5010", "contents": "Title: Random permutation matrices under the generalized Ewens measure Abstract: We consider a generalization of the Ewens measure for the symmetric group,\ncalculating moments of the characteristic polynomial and similar multiplicative\nstatistics. In addition, we study the asymptotic behavior of linear statistics\n(such as the trace of a permutation matrix or of a wreath product) under this\nnew measure. \n\n"}
{"id": "1110.4167", "contents": "Title: Simulating self-avoiding walks in bounded domains Abstract: Let D be a domain in the plane containing the origin. We are interested in\nthe ensemble of self-avoiding walks (SAW's) in D which start at the origin and\nend on the boundary of the domain. We introduce an ensemble of SAW's that we\nexpect to have the same scaling limit. The advantage of our ensemble is that it\ncan be simulated using the pivot algorithm. Our ensemble makes it possible to\naccurately study SLE predictions for the SAW in bounded simply connected\ndomains. One such prediction is the distribution along the boundary of the\nendpoint of the SAW. We use the pivot algorithm to simulate our ensemble and\nstudy this density. In particular the lattice effects in this density that\npersist in the scaling limit are seen to be given by a purely local function. \n\n"}
{"id": "1110.4514", "contents": "Title: The Characteristic Polynomial of a Random Permutation Matrix at\n  Different Points Abstract: We consider the logarithm of the characteristic polynomial of random\npermutation matrices, evaluated on a finite set of different points. The\npermutations are chosen with respect to the Ewens distribution on the symmetric\ngroup. We show that the behavior at different points is independent in the\nlimit and are asymptotically normal. Our methods enables us to study more\ngeneral matrices, closely related to permutation matrices, and multiplicative\nclass functions. \n\n"}
{"id": "1111.5421", "contents": "Title: Markovian stochastic approximation with expanding projections Abstract: Stochastic approximation is a framework unifying many random iterative\nalgorithms occurring in a diverse range of applications. The stability of the\nprocess is often difficult to verify in practical applications and the process\nmay even be unstable without additional stabilisation techniques. We study a\nstochastic approximation procedure with expanding projections similar to\nAndrad\\'{o}ttir [Oper. Res. 43 (1995) 1037-1048]. We focus on Markovian noise\nand show the stability and convergence under general conditions. Our framework\nalso incorporates the possibility to use a random step size sequence, which\nallows us to consider settings with a non-smooth family of Markov kernels. We\napply the theory to stochastic approximation expectation maximisation with\nparticle independent Metropolis-Hastings sampling. \n\n"}
{"id": "1111.6174", "contents": "Title: Resolving conflicts between statistical methods by probability\n  combination: Application to empirical Bayes analyses of genomic data Abstract: In the typical analysis of a data set, a single method is selected for\nstatistical reporting even when equally applicable methods yield very different\nresults. Examples of equally applicable methods can correspond to those of\ndifferent ancillary statistics in frequentist inference and of different prior\ndistributions in Bayesian inference. More broadly, choices are made between\nparametric and nonparametric methods and between frequentist and Bayesian\nmethods.\n  Rather than choosing a single method, it can be safer, in a game-theoretic\nsense, to combine those that are equally appropriate in light of the available\ninformation. Since methods of combining subjectively assessed probability\ndistributions are not objective enough for that purpose, this paper introduces\na method of distribution combination that does not require any assignment of\ndistribution weights. It does so by formalizing a hedging strategy in terms of\na game between three players: nature, a statistician combining distributions,\nand a statistician refusing to combine distributions. The optimal move of the\nfirst statistician reduces to the solution of a simpler problem of selecting an\nestimating distribution that minimizes the Kullback-Leibler loss maximized over\nthe plausible distributions to be combined. The resulting combined distribution\nis a linear combination of the most extreme of the distributions to be combined\nthat are scientifically plausible. The optimal weights are close enough to each\nother that no extreme distribution dominates the others.\n  The new methodology is illustrated by combining conflicting empirical Bayes\nmethodologies in the context of gene expression data analysis. \n\n"}
{"id": "1111.6269", "contents": "Title: Towards a state minimizing the output entropy of a tensor product of\n  random quantum channels Abstract: We consider the image of some classes of bipartite quantum states under a\ntensor product of random quantum channels. Depending on natural assumptions\nthat we make on the states, the eigenvalues of their outputs have new\nproperties which we describe. Our motivation is provided by the additivity\nquestions in quantum information theory, and we build on the idea that a Bell\nstate sent through a product of conjugated random channels has at least one\nlarge eigenvalue. We generalize this setting in two directions. First, we\ninvestigate general entangled pure inputs and show that that Bell states give\nthe least entropy among those inputs in the asymptotic limit. We then study\nmixed input states, and obtain new multi-scale random matrix models that allow\nto quantify the difference of the outputs' eigenvalues between a quantum\nchannel and its complementary version in the case of a non-pure input. \n\n"}
{"id": "1111.7312", "contents": "Title: Fine Gaussian fluctuations on the Poisson space, I: contractions,\n  cumulants and geometric random graphs Abstract: We study the normal approximation of functionals of Poisson measures having\nthe form of a finite sum of multiple integrals. When the integrands are\nnonnegative, our results yield necessary and sufficient conditions for central\nlimit theorems. These conditions can always be expressed in terms of\ncontraction operators or, equivalently, fourth cumulants. Our findings are\nspecifically tailored to deal with the normal approximation of the geometric\n$U$-statistics introduced by Reitzner and Schulte (2011). In particular, we\nshall provide a new analytic characterization of geometric random graphs whose\nedge-counting statistics exhibit asymptotic Gaussian fluctuations, and describe\na new form of Poisson convergence for stationary random graphs with sparse\nconnections. In a companion paper, the above analysis is extended to general\n$U$-statistics of marked point processes with possibly rescaled kernels. \n\n"}
{"id": "1112.4118", "contents": "Title: The Geometry of Hamiltonian Monte Carlo Abstract: With its systematic exploration of probability distributions, Hamiltonian\nMonte Carlo is a potent Markov Chain Monte Carlo technique; it is an approach,\nhowever, ultimately contingent on the choice of a suitable Hamiltonian\nfunction. By examining both the symplectic geometry underlying Hamiltonian\ndynamics and the requirements of Markov Chain Monte Carlo, we construct the\ngeneral form of admissible Hamiltonians and propose a particular choice with\npotential application in Bayesian inference. \n\n"}
{"id": "1112.4725", "contents": "Title: Ideal mixture approximation of cluster size distributions at low density Abstract: We consider an interacting particle system in continuous configuration space.\nThe pair interaction has an attractive part. We show that, at low density, the\nsystem behaves approximately like an ideal mixture of clusters (droplets): we\nprove rigorous bounds (a) for the constrained free energy associated with a\ngiven cluster size distribution, considered as an order parameter, (b) for the\nfree energy, obtained by minimising over the order parameter, and (c) for the\nminimising cluster size distributions. It is known that, under suitable\nassumptions, the ideal mixture has a transition from a gas phase to a condensed\nphase as the density is varied; our bounds hold both in the gas phase and in\nthe coexistence region of the ideal mixture. The present paper improves our\nearlier results by taking into account the mixing entropy. \n\n"}
{"id": "1112.4982", "contents": "Title: Localization of quantum walks induced by recurrence properties of random\n  walks Abstract: We study a quantum walk (QW) whose time evolution is induced by a random walk\n(RW) first introduced by Szegedy (2004). We focus on a relation between\nrecurrent properties of the RW and localization of the corresponding QW. We\nfind the following two fundamental derivations of localization of the QW. The\nfirst one is the set of all the $\\ell^2$ summable eigenvectors of the\ncorresponding RW. The second one is the orthogonal complement, whose\neigenvalues are $\\pm 1$, of the subspace induced by the RW. In particular, as a\nconsequence, for an infinite half line, we show that localization of the QW can\nbe ensured by the positive recurrence of the corresponding RWs, and also that\nthe existence of only one self loop affects localization properties. \n\n"}
{"id": "1201.1512", "contents": "Title: Community detection and tracking on networks from a data fusion\n  perspective Abstract: Community structure in networks has been investigated from many viewpoints,\nusually with the same end result: a community detection algorithm of some kind.\nRecent research offers methods for combining the results of such algorithms\ninto timelines of community evolution. This paper investigates community\ndetection and tracking from the data fusion perspective. We avoid the kind of\nhard calls made by traditional community detection algorithms in favor of\nretaining as much uncertainty information as possible. This results in a method\nfor directly estimating the probabilities that pairs of nodes are in the same\ncommunity. We demonstrate that this method is accurate using the LFR testbed,\nthat it is fast on a number of standard network datasets, and that it is has a\nvariety of uses that complement those of standard, hard-call methods. Retaining\nuncertainty information allows us to develop a Bayesian filter for tracking\ncommunities. We derive equations for the full filter, and marginalize it to\nproduce a potentially practical version. Finally, we discuss closures for the\nmarginalized filter and the work that remains to develop this into a\nprincipled, efficient method for tracking time-evolving communities on\ntime-evolving networks. \n\n"}
{"id": "1201.4632", "contents": "Title: HodgeRank is the limit of Perron Rank Abstract: We study the map which takes an elementwise positive matrix to the k-th root\nof the principal eigenvector of its k-th Hadamard power. We show that as $k$\ntends to 0 one recovers the row geometric mean vector and discuss the geometric\nsignificance of this convergence. In the context of pairwise comparison\nranking, our result states that HodgeRank is the limit of Perron Rank, thereby\nproviding a novel mathematical link between two important pairwise ranking\nmethods. \n\n"}
{"id": "1201.4792", "contents": "Title: Block-modified Wishart matrices and free Poisson laws Abstract: We study the random matrices of type $\\tilde{W}=(id\\otimes\\varphi)W$, where\n$W$ is a complex Wishart matrix of parameters $(dn,dm)$, and\n$\\varphi:M_n(\\mathbb C)\\to M_n(\\mathbb C)$ is a self-adjoint linear map. We\nprove that, under suitable assumptions, we have the $d\\to\\infty$ eigenvalue\ndistribution formula $\\delta m\\tilde{W}\\sim\\pi_{mn\\rho}\\boxtimes\\nu$, where\n$\\rho$ is the law of $\\varphi$, viewed as a square matrix, $\\pi$ is the free\nPoisson law, $\\nu$ is the law of $D=\\varphi(1)$, and $\\delta=tr(D)$. \n\n"}
{"id": "1201.5823", "contents": "Title: Bougerol's identity in law and extensions Abstract: We present a list of equivalent expressions and extensions of Bougerol's\ncelebrated identity in law, obtained by several authors. We recall well-known\nresults and the latest progress of the research associated with this celebrated\nidentity in many directions, we give some new results and possible extensions\nand we try to point out open questions. \n\n"}
{"id": "1201.5871", "contents": "Title: Null models for network data Abstract: The analysis of datasets taking the form of simple, undirected graphs\ncontinues to gain in importance across a variety of disciplines. Two choices of\nnull model, the logistic-linear model and the implicit log-linear model, have\ncome into common use for analyzing such network data, in part because each\naccounts for the heterogeneity of network node degrees typically observed in\npractice. Here we show how these both may be viewed as instances of a broader\nclass of null models, with the property that all members of this class give\nrise to essentially the same likelihood-based estimates of link probabilities\nin sparse graph regimes. This facilitates likelihood-based computation and\ninference, and enables practitioners to choose the most appropriate null model\nfrom this family based on application context. Comparative model fits for a\nvariety of network datasets demonstrate the practical implications of our\nresults. \n\n"}
{"id": "1201.5893", "contents": "Title: A new stochastic differential equation modelling incidence and\n  prevalence with an application to systemic lupus erythematosus in England and\n  Wales, 1995 Abstract: This article reformulates a common illness-death model in terms of a new\nsystem of stochastical differential equations (SDEs). The SDEs are used to\nestimate epidemiological characteristics and burden of systemic lupus\nerythematosus in England and Wales in 1995. \n\n"}
{"id": "1202.0068", "contents": "Title: Random matrices: The Universality phenomenon for Wigner ensembles Abstract: In this paper, we survey some recent progress on rigorously establishing the\nuniversality of various spectral statistics of Wigner Hermitian random matrix\nensembles, focusing on the Four Moment Theorem and its refinements and\napplications, including the universality of the sine kernel and the Central\nlimit theorem of several spectral parameters.\n  We also take the opportunity here to issue some errata for some of our\nprevious papers in this area. \n\n"}
{"id": "1202.0190", "contents": "Title: Gumbel fluctuations for cover times in the discrete torus Abstract: This work proves that the fluctuations of the cover time of simple random\nwalk in the discrete torus of dimension at least three with large side-length\nare governed by the Gumbel extreme value distribution. This result was\nconjectured for example in the book by Aldous & Fill. We also derive some\ncorollaries which qualitatively describe \"how\" covering happens. In addition,\nwe develop a new and stronger coupling of the model of random interlacements,\nintroduced by Sznitman, and random walk in the torus. This coupling is used to\nprove the cover time result and is also of independent interest. \n\n"}
{"id": "1202.0619", "contents": "Title: On some expectation and derivative operators related to integral\n  representations of random variables with respect to a PII process Abstract: Given a process with independent increments $X$ (not necessarily a\nmartingale) and a large class of square integrable r.v. $H=f(X_T)$, $f$ being\nthe Fourier transform of a finite measure $\\mu$, we provide explicit\nKunita-Watanabe and F\\\"ollmer-Schweizer decompositions. The representation is\nexpressed by means of two significant maps: the expectation and derivative\noperators related to the characteristics of $X$. We also provide an explicit\nexpression for the variance optimal error when hedging the claim $H$ with\nunderlying process $X$. Those questions are motivated by finding the solution\nof the celebrated problem of global and local quadratic risk minimization in\nmathematical finance. \n\n"}
{"id": "1202.0958", "contents": "Title: Directed Information on Abstract spaces: Properties and Extremum\n  Problems Abstract: This paper describes a framework in which directed information is defined on\nabstract spaces. The framework is employed to derive properties of directed\ninformation such as convexity, concavity, lower semicontinuity, by using the\ntopology of weak convergence of probability measures on Polish spaces. Two\nextremum problems of directed information related to capacity of channels with\nmemory and feedback, and non-anticipative and sequential rate distortion are\nanalyzed showing existence of maximizing and minimizing distributions,\nrespectively. \n\n"}
{"id": "1202.1319", "contents": "Title: Infinite cycles in the random stirring model on trees Abstract: We prove that, in the random stirring model of parameter T on an infinite\nrooted tree each of whose vertices has at least two offspring, infinite cycles\nexist almost surely, provided that T is sufficiently high.\n  In the appendices, the bound on degree above which the result holds is\nimproved slightly. \n\n"}
{"id": "1202.1370", "contents": "Title: On a functional contraction method Abstract: Methods for proving functional limit laws are developed for sequences of\nstochastic processes which allow a recursive distributional decomposition\neither in time or space. Our approach is an extension of the so-called\ncontraction method to the space $\\mathcal{C}[0,1]$ of continuous functions\nendowed with uniform topology and the space $\\mathcal {D}[0,1]$ of\nc\\`{a}dl\\`{a}g functions with the Skorokhod topology. The contraction method\noriginated from the probabilistic analysis of algorithms and random trees where\ncharacteristics satisfy natural distributional recurrences. It is based on\nstochastic fixed-point equations, where probability metrics can be used to\nobtain contraction properties and allow the application of Banach's fixed-point\ntheorem. We develop the use of the Zolotarev metrics on the spaces\n$\\mathcal{C}[0,1]$ and $\\mathcal{D}[0,1]$ in this context. Applications are\ngiven, in particular, a short proof of Donsker's functional limit theorem is\nderived and recurrences arising in the probabilistic analysis of algorithms are\ndiscussed. \n\n"}
{"id": "1202.1377", "contents": "Title: Statistical significance in high-dimensional linear models Abstract: We propose a method for constructing p-values for general hypotheses in a\nhigh-dimensional linear model. The hypotheses can be local for testing a single\nregression parameter or they may be more global involving several up to all\nparameters. Furthermore, when considering many hypotheses, we show how to\nadjust for multiple testing taking dependence among the p-values into account.\nOur technique is based on Ridge estimation with an additional correction term\ndue to a substantial projection bias in high dimensions. We prove strong error\ncontrol for our p-values and provide sufficient conditions for detection: for\nthe former, we do not make any assumption on the size of the true underlying\nregression coefficients while regarding the latter, our procedure might not be\noptimal in terms of power. We demonstrate the method in simulated examples and\na real data application. \n\n"}
{"id": "1202.1684", "contents": "Title: Cylinders' percolation in three dimensions Abstract: We study the complementary set of a Poissonian ensemble of infinite cylinders\nin R^3, for which an intensity parameter u > 0 controls the amount of cylinders\nto be removed from the ambient space. We establish a non-trivial phase\ntransition, for the existence of an unbounded connected component of this set,\nas u crosses a critical non-degenerate intensity u*. We moreover show that this\ncomplementary set percolates in a sufficiently thick slab, in spite of the fact\nthat it does not percolate in any given plane of R^3, regardless of the choice\nof u. \n\n"}
{"id": "1202.1798", "contents": "Title: A strong uniform approximation of sub-fractional Brownian motion Abstract: Sub-fractional Brownian motion is a process analogous to fractional Brownian\nmotion but without stationary increments. In \\cite{GGL1} we proved a strong\nuniform approximation with a rate of convergence for fractional Brownian motion\nby means of transport processes. In this paper we prove a similar type of\napproximation for sub-fractional Brownian motion. \n\n"}
{"id": "1202.2439", "contents": "Title: Asymptotic analysis of Hoppe trees Abstract: We introduce and analyze a random tree model associated to Hoppe's urn. The\ntree is built successively by adding nodes to the existing tree when starting\nwith the single root node. In each step a node is added to the tree as a child\nof an existing node where these parent nodes are chosen randomly with\nprobabilities proportional to their weights. The root node has weight\n$\\vartheta>0$, a given fixed parameter, all other nodes have weight 1. This\nresembles the stochastic dynamic of Hoppe's urn. For $\\vartheta=1$ the\nresulting tree is the well-studied random recursive tree. We analyze the\nheight, internal path length and number of leaves of the Hoppe tree with $n$\nnodes as well as the depth of the last inserted node asymptotically as $n\\to\n\\infty$. Mainly expectations, variances and asymptotic distributions of these\nparameters are derived. \n\n"}
{"id": "1203.0801", "contents": "Title: Deterministic approximations of random reflectors Abstract: Within classical optics, one may add microscopic \"roughness\" to a\nmacroscopically flat mirror so that parallel rays of a given angle are\nreflected at different outgoing angles. Taking the limit (as the roughness\nbecomes increasingly microscopic) one obtains a flat surface that reflects\nrandomly, i.e., the transition from incoming to outgoing ray is described by a\nprobability kernel (whose form depends on the nature of the microscopic\nroughness).\n  We consider two-dimensional optics (a.k.a. billiards) and show that every\nrandom reflector on a line that satisfies a necessary measure-preservation\ncondition (well established in the theory of billiards) can be approximated by\ndeterministic reflectors in this way. \n\n"}
{"id": "1203.2376", "contents": "Title: Maximum penalized likelihood estimation for skew-normal and skew-$t$\n  distributions Abstract: The skew-normal and the skew-$t$ distributions are parametric families which\nare currently under intense investigation since they provide a more flexible\nformulation compared to the classical normal and $t$ distributions by\nintroducing a parameter which regulates their skewness. While these families\nenjoy attractive formal properties from the probability viewpoint, a practical\nproblem with their usage in applications is the possibility that the maximum\nlikelihood estimate of the parameter which regulates skewness diverges. This\nsituation has vanishing probability for increasing sample size, but for finite\nsamples it occurs with non-negligible probability, and its occurrence has\nunpleasant effects on the inferential process. Methods for overcoming this\nproblem have been put forward both in the classical and in the Bayesian\nformulation, but their applicability is restricted to simple situations. We\nformulate a proposal based on the idea of penalized likelihood, which has\nconnections with some of the existing methods, but it applies more generally,\nincluding in the multivariate case. \n\n"}
{"id": "1203.2821", "contents": "Title: Graphlet decomposition of a weighted network Abstract: We introduce the graphlet decomposition of a weighted network, which encodes\na notion of social information based on social structure. We develop a scalable\ninference algorithm, which combines EM with Bron-Kerbosch in a novel fashion,\nfor estimating the parameters of the model underlying graphlets using one\nnetwork sample. We explore some theoretical properties of the graphlet\ndecomposition, including computational complexity, redundancy and expected\naccuracy. We demonstrate graphlets on synthetic and real data. We analyze\nmessaging patterns on Facebook and criminal associations in the 19th century. \n\n"}
{"id": "1203.4480", "contents": "Title: Reply to \"Comment on `Inference with minimal Gibbs free energy in\n  information field theory'\" by Iatsenko, Stefanovska and McClintock Abstract: We endorse the comment on our recent paper [En{\\ss}lin and Weig, Phys. Rev. E\n82, 051112 (2010)] by Iatsenko, Stefanovska and McClintock [Phys. Rev. E 85\n033101 (2012)] and we try to clarify the origin of the apparent controversy on\ntwo issues. The aim of the minimal Gibbs free energy approach to provide a\nsignal estimate is not affected by their Comment. However, if one wants to\nextend the method to also infer the a posteriori signal uncertainty any\ntempering of the posterior has to be undone at the end of the calculations, as\nthey correctly point out. Furthermore, a distinction is made here between\nmaximum entropy, the maximum entropy principle, and the so-called maximum\nentropy method in imaging, hopefully clarifying further the second issue of\ntheir Comment paper. \n\n"}
{"id": "1203.6085", "contents": "Title: Invariance properties of random vectors and stochastic processes based\n  on the zonoid concept Abstract: Two integrable random vectors $\\xi$ and $\\xi^*$ in $\\mathbb {R}^d$ are said\nto be zonoid equivalent if, for each $u\\in \\mathbb {R}^d$, the scalar products\n$\\langle\\xi,u\\rangle$ and $\\langle\\xi^*,u\\rangle$ have the same first absolute\nmoments. The paper analyses stochastic processes whose finite-dimensional\ndistributions are zonoid equivalent with respect to time shift (zonoid\nstationarity) and permutation of its components (swap invariance). While the\nfirst concept is weaker than the stationarity, the second one is a weakening of\nthe exchangeability property. It is shown that nonetheless the ergodic theorem\nholds for swap-invariant sequences and the limits are characterised. \n\n"}
{"id": "1204.0316", "contents": "Title: Subsampling Extremes: From Block Maxima to Smooth Tail Estimation Abstract: We study a new estimator for the tail index of a distribution in the Frechet\ndomain of attraction that arises naturally by computing subsample maxima. This\nestimator is equivalent to taking a U-statistic over a Hill estimator with two\norder statistics. The estimator presents multiple advantages over the Hill\nestimator. In particular, it has asymptotically smooth sample paths as a\nfunction of the threshold k, making it considerably more stable than the Hill\nestimator. The estimator also admits a simple and intuitive threshold selection\nrule that does not require fitting a second-order model. Journal of\nMultivariate Analysis, 130, 2014 \n\n"}
{"id": "1204.0332", "contents": "Title: Max-stable models for multivariate extremes Abstract: Multivariate extreme-value analysis is concerned with the extremes in a\nmultivariate random sample, that is, points of which at least some components\nhave exceptionally large values. Mathematical theory suggests the use of\nmax-stable models for univariate and multivariate extremes. A comprehensive\naccount is given of the various ways in which max-stable models are described.\nFurthermore, a construction device is proposed for generating parametric\nfamilies of max-stable distributions. Although the device is not new, its role\nas a model generator seems not yet to have been fully exploited. \n\n"}
{"id": "1204.0505", "contents": "Title: Bond percolation on isoradial graphs: criticality and universality Abstract: In an investigation of percolation on isoradial graphs, we prove the\ncriticality of canonical bond percolation on isoradial embeddings of planar\ngraphs, thus extending celebrated earlier results for homogeneous and\ninhomogeneous square, triangular, and other lattices. This is achieved via the\nstar-triangle transformation, by transporting the box-crossing property across\nthe family of isoradial graphs. As a consequence, we obtain the universality of\nthese models at the critical point, in the sense that the one-arm and\n2j-alternating-arm critical exponents (and therefore also the connectivity and\nvolume exponents) are constant across the family of such percolation processes.\nThe isoradial graphs in question are those that satisfy certain weak conditions\non their embedding and on their track system. This class of graphs includes,\nfor example, isoradial embeddings of periodic graphs, and graphs derived from\nrhombic Penrose tilings. \n\n"}
{"id": "1204.3642", "contents": "Title: The subelliptic heat kernel on the anti-de Sitter spaces Abstract: We study the subelliptic heat kernel of the sub-Laplacian on a\n2n+1-dimensional anti-de Sitter space H2n+1 which also appears as a model space\nof a CR Sasakian manifold with constant negative sectional curvature. In\nparticular we obtain an explicit and geometrically meaningful formula for the\nsubelliptic heat kernel. The key idea is to work in a set of coordinates that\nreflects the symmetry coming from the Hopf fibration S1->H2n+1. A direct\napplication is obtaining small time asymptotics of the subelliptic heat kernel.\nAlso we derive an explicit formula for the sub-Riemannian distance on H2n+1 \n\n"}
{"id": "1204.4494", "contents": "Title: Rotation Sampling for Functional Data Abstract: This paper addresses the survey estimation of a population mean in continuous\ntime. For this purpose we extend the rotation sampling method to functional\ndata. In contrast to conventional rotation designs that select the sample\nbefore the survey, our approach randomizes each sample replacement and thus\nallows for adaptive sampling. Using Markov chain theory, we evaluate the\ncovariance structure and the integrated squared error [ISE] of the related\nHorvitz-Thompson estimator. Our sampling designs decrease the mean ISE by\nsuitably reallocating the sample across population strata during replacements.\nThey also reduce the variance of the ISE by increasing the frequency or the\nintensity of replacements. To investigate the benefits of using both current\nand past measurements in the estimation, we develop a new composite estimator.\nIn an application to electricity usage data, our rotation method outperforms\nfixed panels and conventional rotation samples. Because of the weak temporal\ndependence of the data, the composite estimator only slightly improves upon the\nHorvitz-Thompson estimator. \n\n"}
{"id": "1204.6452", "contents": "Title: Optimality of Graphlet Screening in High Dimensional Variable Selection Abstract: Consider a linear regression model where the design matrix X has n rows and p\ncolumns. We assume (a) p is much large than n, (b) the coefficient vector beta\nis sparse in the sense that only a small fraction of its coordinates is\nnonzero, and (c) the Gram matrix G = X'X is sparse in the sense that each row\nhas relatively few large coordinates (diagonals of G are normalized to 1).\n  The sparsity in G naturally induces the sparsity of the so-called graph of\nstrong dependence (GOSD). We find an interesting interplay between the signal\nsparsity and the graph sparsity, which ensures that in a broad context, the set\nof true signals decompose into many different small-size components of GOSD,\nwhere different components are disconnected.\n  We propose Graphlet Screening (GS) as a new approach to variable selection,\nwhich is a two-stage Screen and Clean method. The key methodological innovation\nof GS is to use GOSD to guide both the screening and cleaning. Compared to\nm-variate brute-forth screening that has a computational cost of p^m, the GS\nonly has a computational cost of p (up to some multi-log(p) factors) in\nscreening.\n  We measure the performance of any variable selection procedure by the minimax\nHamming distance. We show that in a very broad class of situations, GS achieves\nthe optimal rate of convergence in terms of the Hamming distance. Somewhat\nsurprisingly, the well-known procedures subset selection and the lasso are rate\nnon-optimal, even in very simple settings and even when their tuning parameters\nare ideally set. \n\n"}
{"id": "1205.0968", "contents": "Title: Information Complexity versus Corruption and Applications to\n  Orthogonality and Gap-Hamming Abstract: Three decades of research in communication complexity have led to the\ninvention of a number of techniques to lower bound randomized communication\ncomplexity. The majority of these techniques involve properties of large\nsubmatrices (rectangles) of the truth-table matrix defining a communication\nproblem. The only technique that does not quite fit is information complexity,\nwhich has been investigated over the last decade. Here, we connect information\ncomplexity to one of the most powerful \"rectangular\" techniques: the\nrecently-introduced smooth corruption (or \"smooth rectangle\") bound. We show\nthat the former subsumes the latter under rectangular input distributions. We\nconjecture that this subsumption holds more generally, under arbitrary\ndistributions, which would resolve the long-standing direct sum question for\nrandomized communication. As an application, we obtain an optimal $\\Omega(n)$\nlower bound on the information complexity---under the {\\em uniform\ndistribution}---of the so-called orthogonality problem (ORT), which is in turn\nclosely related to the much-studied Gap-Hamming-Distance (GHD). The proof of\nthis bound is along the lines of recent communication lower bounds for GHD, but\nwe encounter a surprising amount of additional technical detail. \n\n"}
{"id": "1205.3385", "contents": "Title: Infrared bound and mean-field behaviour in the quantum Ising model Abstract: We prove an infrared bound for the transverse field Ising model. This bound\nis stronger than the previously known infrared bound for the model, and allows\nus to investigate mean-field behaviour. As an application we show that the\ncritical exponent $\\gamma$ for the susceptibility attains its mean-field value\n$\\gamma=1$ in dimension at least 4 (positive temperature), respectively 3\n(ground state), with logarithmic corrections in the boundary cases. \n\n"}
{"id": "1205.4471", "contents": "Title: Sparse Signal Recovery in the Presence of Intra-Vector and Inter-Vector\n  Correlation Abstract: This work discusses the problem of sparse signal recovery when there is\ncorrelation among the values of non-zero entries. We examine intra-vector\ncorrelation in the context of the block sparse model and inter-vector\ncorrelation in the context of the multiple measurement vector model, as well as\ntheir combination. Algorithms based on the sparse Bayesian learning are\npresented and the benefits of incorporating correlation at the algorithm level\nare discussed. The impact of correlation on the limits of support recovery is\nalso discussed highlighting the different impact intra-vector and inter-vector\ncorrelations have on such limits. \n\n"}
{"id": "1205.4508", "contents": "Title: Functional Inequalities for Stable-Like Dirichlet Forms Abstract: Let $V\\in C^2(\\R^d)$ such that $\\mu_V(\\d x):= \\e^{-V(x)}\\,\\d x$ is a\nprobability measure, and let $\\aa\\in (0,2)$. Explicit criteria are presented\nfor the $\\aa$-stable-like Dirichlet form $$\\E_{\\aa,V}(f,f):=\n\\int_{\\R^d\\times\\R^d} \\ff{|f(x)-f(y)|^2}{|x-y|^{d+\\alpha}}\\,\\d\ny\\,\\e^{-V(x)}\\,\\d x$$ to satisfy Poincar\\'e-type (i.e., Poincar\\'e, weak\nPoincar\\'e and super Poincar\\'e) inequalities. As applications, sharp\nfunctional inequalities are derived for the Dirichlet form with $V$ having some\ntypical growths. Finally, the main result of \\cite{MRS} on the Poincar\\'e\ninequality is strengthened \n\n"}
{"id": "1205.4645", "contents": "Title: Covariate assisted screening and estimation Abstract: Consider a linear model $Y=X\\beta+z$, where $X=X_{n,p}$ and $z\\sim N(0,I_n)$.\nThe vector $\\beta$ is unknown but is sparse in the sense that most of its\ncoordinates are $0$. The main interest is to separate its nonzero coordinates\nfrom the zero ones (i.e., variable selection). Motivated by examples in\nlong-memory time series (Fan and Yao [Nonlinear Time Series: Nonparametric and\nParametric Methods (2003) Springer]) and the change-point problem (Bhattacharya\n[In Change-Point Problems (South Hadley, MA, 1992) (1994) 28-56 IMS]), we are\nprimarily interested in the case where the Gram matrix $G=X'X$ is nonsparse but\nsparsifiable by a finite order linear filter. We focus on the regime where\nsignals are both rare and weak so that successful variable selection is very\nchallenging but is still possible. We approach this problem by a new procedure\ncalled the covariate assisted screening and estimation (CASE). CASE first uses\na linear filtering to reduce the original setting to a new regression model\nwhere the corresponding Gram (covariance) matrix is sparse. The new covariance\nmatrix induces a sparse graph, which guides us to conduct multivariate\nscreening without visiting all the submodels. By interacting with the signal\nsparsity, the graph enables us to decompose the original problem into many\nseparated small-size subproblems (if only we know where they are!). Linear\nfiltering also induces a so-called problem of information leakage, which can be\novercome by the newly introduced patching technique. Together, these give rise\nto CASE, which is a two-stage screen and clean [Fan and Song Ann. Statist. 38\n(2010) 3567-3604; Wasserman and Roeder Ann. Statist. 37 (2009) 2178-2201]\nprocedure, where we first identify candidates of these submodels by patching\nand screening, and then re-examine each candidate to remove false positives. \n\n"}
{"id": "1205.5920", "contents": "Title: On latent position inference from doubly stochastic messaging activities Abstract: We model messaging activities as a hierarchical doubly stochastic point\nprocess with three main levels, and develop an iterative algorithm for\ninferring actors' relative latent positions from a stream of messaging activity\ndata. Each of the message-exchanging actors is modeled as a process in a latent\nspace. The actors' latent positions are assumed to be influenced by the\ndistribution of a much larger population over the latent space. Each actor's\nmovement in the latent space is modeled as being governed by two parameters\nthat we call confidence and visibility, in addition to dependence on the\npopulation distribution. The messaging frequency between a pair of actors is\nassumed to be inversely proportional to the distance between their latent\npositions. Our inference algorithm is based on a projection approach to an\nonline filtering problem. The algorithm associates each actor with a\nprobability density-valued process, and each probability density is assumed to\nbe a mixture of basis functions. For efficient numerical experiments, we\nfurther develop our algorithm for the case where the basis functions are\nobtained by translating and scaling a standard Gaussian density. \n\n"}
{"id": "1206.0867", "contents": "Title: Testing linear hypotheses in high-dimensional regressions Abstract: For a multivariate linear model, Wilk's likelihood ratio test (LRT)\nconstitutes one of the cornerstone tools. However, the computation of its\nquantiles under the null or the alternative requires complex analytic\napproximations and more importantly, these distributional approximations are\nfeasible only for moderate dimension of the dependent variable, say $p\\le 20$.\nOn the other hand, assuming that the data dimension $p$ as well as the number\n$q$ of regression variables are fixed while the sample size $n$ grows, several\nasymptotic approximations are proposed in the literature for Wilk's $\\bLa$\nincluding the widely used chi-square approximation. In this paper, we consider\nnecessary modifications to Wilk's test in a high-dimensional context,\nspecifically assuming a high data dimension $p$ and a large sample size $n$.\nBased on recent random matrix theory, the correction we propose to Wilk's test\nis asymptotically Gaussian under the null and simulations demonstrate that the\ncorrected LRT has very satisfactory size and power, surely in the large $p$ and\nlarge $n$ context, but also for moderately large data dimensions like $p=30$ or\n$p=50$. As a byproduct, we give a reason explaining why the standard chi-square\napproximation fails for high-dimensional data. We also introduce a new\nprocedure for the classical multiple sample significance test in MANOVA which\nis valid for high-dimensional data. \n\n"}
{"id": "1206.2251", "contents": "Title: A Necessary and Sufficient Condition for Edge Universality of Wigner\n  matrices Abstract: In this paper, we prove a necessary and sufficient condition for Tracy-Widom\nlaw of Wigner matrices. Consider $N \\times N$ symmetric Wigner matrices $H$\nwith $H_{ij} = N^{-1/2} x_{ij}$, whose upper right entries $x_{ij}$ $(1\\le i<\nj\\le N)$ are $i.i.d.$ random variables with distribution $\\mu$ and diagonal\nentries $x_{ii}$ $(1\\le i\\le N)$ are $i.i.d.$ random variables with\ndistribution $\\wt \\mu$. The means of $\\mu$ and $\\wt \\mu$ are zero, the variance\nof $\\mu$ is 1, and the variance of $\\wt \\mu $ is finite. We prove that\nTracy-Widom law holds if and only if $\\lim_{s\\to \\infty}s^4\\p(|x_{12}| \\ge\ns)=0$. The same criterion holds for Hermitian Wigner matrices. \n\n"}
{"id": "1206.5014", "contents": "Title: Quantitative model validation techniques: new insights Abstract: This paper develops new insights into quantitative methods for the validation\nof computational model prediction. Four types of methods are investigated,\nnamely classical and Bayesian hypothesis testing, a reliability-based method,\nand an area metric-based method. Traditional Bayesian hypothesis testing is\nextended based on interval hypotheses on distribution parameters and equality\nhypotheses on probability distributions, in order to validate models with\ndeterministic/stochastic output for given inputs. Two types of validation\nexperiments are considered - fully characterized (all the model/experimental\ninputs are measured and reported as point values) and partially characterized\n(some of the model/experimental inputs are not measured or are reported as\nintervals). Bayesian hypothesis testing can minimize the risk in model\nselection by properly choosing the model acceptance threshold, and its results\ncan be used in model averaging to avoid Type I/II errors. It is shown that\nBayesian interval hypothesis testing, the reliability-based method, and the\narea metric-based method can account for the existence of directional bias,\nwhere the mean predictions of a numerical model may be consistently below or\nabove the corresponding experimental observations. It is also found that under\nsome specific conditions, the Bayes factor metric in Bayesian equality\nhypothesis testing and the reliability-based metric can both be mathematically\nrelated to the p-value metric in classical hypothesis testing. Numerical\nstudies are conducted to apply the above validation methods to gas damping\nprediction for radio frequency (RF) microelectromechanical system (MEMS)\nswitches. The model of interest is a general polynomial chaos (gPC) surrogate\nmodel constructed based on expensive runs of a physics-based simulation model,\nand validation data are collected from fully characterized experiments. \n\n"}
{"id": "1206.5015", "contents": "Title: Calibration of multi-physics computational models using Bayesian\n  networks Abstract: This paper develops a Bayesian network-based method for the calibration of\nmulti-physics models, integrating various sources of uncertainty with\ninformation from computational models and experimental data. We adopt the\nKennedy and O'Hagan (KOH) framework for model calibration under uncertainty,\nand develop extensions to multi-physics models and various scenarios of\navailable data. Both aleatoric uncertainty (due to natural variability) and\nepistemic uncertainty (due to lack of information, including data uncertainty\nand model uncertainty) are accounted for in the calibration process.\nChallenging aspects of Bayesian calibration for multi-physics models are\ninvestigated, including: (1) calibration with different forms of experimental\ndata (e.g., interval data and time series data), (2) determination of the\nidentifiability of model parameters when the analytical expression of model is\nknown or unknown, (3) calibration of multiple physics models sharing common\nparameters, which enables efficient use of data especially when the\nexperimental resources are limited. A first-order Taylor series expansion-based\nmethod is proposed to determine which model parameters are identifiable.\nFollowing the KOH framework, a probabilistic discrepancy function is estimated\nand added to the prediction of the calibrated model, attempting to account for\nmodel uncertainty. This discrepancy function is modeled as a Gaussian process\nwhen sufficient data are available for multiple model input combinations, and\nis modeled as a random variable when the available data are limited. The\noverall approach is illustrated using two application examples related to\nmicroelectromechanical system (MEMS) devices: (1) calibration of a dielectric\ncharging model with time-series data, and (2) calibration of two physics models\n(pull-in voltage and creep) using measurements of different physical quantities\nin different devices. \n\n"}
{"id": "1206.5070", "contents": "Title: A fluctuation test for constant Spearman's rho with nuisance-free limit\n  distribution Abstract: A CUSUM type test for constant correlation that goes beyond a previously\nsuggested correlation constancy test by considering Spearman's rho in arbitrary\ndimensions is proposed. Since the new test does not require the existence of\nany moments, the applicability on usually heavy-tailed financial data is\ngreatly improved. The asymptotic null distribution is calculated using an\ninvariance principle for the sequential empirical copula process. The limit\ndistribution is free of nuisance parameters and critical values can be obtained\nwithout bootstrap techniques. A local power result and an analysis of the\nbehavior of the test in small samples is provided. \n\n"}
{"id": "1206.6367", "contents": "Title: A comparison of the discrete Kolmogorov-Smirnov statistic and the\n  Euclidean distance Abstract: Goodness-of-fit tests gauge whether a given set of observations is consistent\n(up to expected random fluctuations) with arising as independent and\nidentically distributed (i.i.d.) draws from a user-specified probability\ndistribution known as the \"model.\" The standard gauges involve the discrepancy\nbetween the model and the empirical distribution of the observed draws. Some\nmeasures of discrepancy are cumulative; others are not. The most popular\ncumulative measure is the Kolmogorov-Smirnov statistic; when all probability\ndistributions under consideration are discrete, a natural noncumulative measure\nis the Euclidean distance between the model and the empirical distributions. In\nthe present paper, both mathematical analysis and its illustration via various\ndata sets indicate that the Kolmogorov-Smirnov statistic tends to be more\npowerful than the Euclidean distance when there is a natural ordering for the\nvalues that the draws can take -- that is, when the data is ordinal -- whereas\nthe Euclidean distance is more reliable and more easily understood than the\nKolmogorov-Smirnov statistic when there is no natural ordering (or partial\norder) -- that is, when the data is nominal. \n\n"}
{"id": "1207.0149", "contents": "Title: Sharp vanishing thresholds for cohomology of random flag complexes Abstract: For every $k \\ge 1$, the $k$th cohomology group $H^k(X, \\Q)$ of the random\nflag complex $X \\sim X(n,p)$ passes through two phase transitions: one where it\nappears, and one where it vanishes. We describe the vanishing threshold and\nshow that it is sharp. Using the same spectral methods, we also find a sharp\nthreshold for the fundamental group $\\pi_1(X)$ to have Kazhdan's property (T).\nCombining with earlier results, we obtain as a corollary that for every $k \\ge\n3$ there is a regime in which the random flag complex is rationally homotopy\nequivalent to a bouquet of $k$-dimensional spheres. \n\n"}
{"id": "1207.0258", "contents": "Title: Control of probability flow in Markov chain Monte Carlo --\n  Nonreversibility and lifting Abstract: The Markov chain Monte Carlo (MCMC) method is widely used in various fields\nas a powerful numerical integration technique for systems with many degrees of\nfreedom. In MCMC methods, probabilistic state transitions can be considered as\na random walk in state space, and random walks allow for sampling from complex\ndistributions. However, paradoxically, it is necessary to carefully suppress\nthe randomness of the random walk to improve computational efficiency. By\nbreaking detailed balance, we can create a probability flow in the state space\nand perform more efficient sampling along this flow. Motivated by this idea,\npractical and efficient nonreversible MCMC methods have been developed over the\npast ten years. In particular, the lifting technique, which introduces\nprobability flows in an extended state space, has been applied to various\nsystems and has proven more efficient than conventional reversible updates. We\nreview and discuss several practical approaches to implementing nonreversible\nMCMC methods, including the shift method in the cumulative distribution and the\ndirected-worm algorithm. \n\n"}
{"id": "1207.0373", "contents": "Title: Percolation since Saint-Flour Abstract: This is a short survey of work on percolation and first-passage percolation\nsince the publication (in 1996 and 1984, respectively) of the two authors'\nSaint-Flour notes on these topics. \n\n"}
{"id": "1207.0471", "contents": "Title: The outliers among the singular values of large rectangular random\n  matrices with additive fixed rank deformation Abstract: Consider the matrix $\\Sigma_n = n^{-1/2} X_n D_n^{1/2} + P_n$ where the\nmatrix $X_n \\in \\C^{N\\times n}$ has Gaussian standard independent elements,\n$D_n$ is a deterministic diagonal nonnegative matrix, and $P_n$ is a\ndeterministic matrix with fixed rank. Under some known conditions, the spectral\nmeasures of $\\Sigma_n \\Sigma_n^*$ and $n^{-1} X_n D_n X_n^*$ both converge\ntowards a compactly supported probability measure $\\mu$ as $N,n\\to\\infty$ with\n$N/n\\to c>0$. In this paper, it is proved that finitely many eigenvalues of\n$\\Sigma_n\\Sigma_n^*$ may stay away from the support of $\\mu$ in the large\ndimensional regime. The existence and locations of these outliers in any\nconnected component of $\\R - \\support(\\mu)$ are studied. The fluctuations of\nthe largest outliers of $\\Sigma_n\\Sigma_n^*$ are also analyzed. The results\nfind applications in the fields of signal processing and radio communications. \n\n"}
{"id": "1207.6606", "contents": "Title: Weighted sampling, Maximum Likelihood and minimum divergence estimators Abstract: This paper explores Maximum Likelihood in parametric models in the context of\nSanov type Large Deviation Probabilities. MLE in parametric models under\nweighted sampling is shown to be associated with the minimization of a specific\ndivergence criterion defined with respect to the distribution of the weights.\nSome properties of the resulting inferential procedure are presented; Bahadur\nefficiency of tests are also considered in this context. \n\n"}
{"id": "1207.7207", "contents": "Title: Normal Approximations for Wavelet Coefficients on Spherical Poisson\n  Fields Abstract: We compute explicit upper bounds on the distance between the law of a\nmultivariate Gaussian distribution and the joint law of wavelets/needlets\ncoefficients based on a homogeneous spherical Poisson field. In particular, we\ndevelop some results from Peccati and Zheng (2011), based on Malliavin calculus\nand Stein's methods, to assess the rate of convergence to Gaussianity for a\ntriangular array of needlet coefficients with growing dimensions. Our results\nare motivated by astrophysical and cosmological applications, in particular\nrelated to the search for point sources in Cosmic Rays data. \n\n"}
{"id": "1208.0620", "contents": "Title: Excursions and path functionals for stochastic processes with\n  asymptotically zero drifts Abstract: We study discrete-time stochastic processes $(X_t)$ on $[0,\\infty)$ with\nasymptotically zero mean drifts. Specifically, we consider the critical\n(Lamperti-type) situation in which the mean drift at $x$ is about $c/x$. Our\nfocus is the recurrent case (when $c$ is not too large). We give sharp\nasymptotics for various functionals associated with the process and its\nexcursions, including results on maxima and return times. These results include\nimprovements on existing results in the literature in several respects, and\nalso include new results on excursion sums and additive functionals of the form\n$\\sum_{s \\leq t} X_s^\\alpha$, $\\alpha >0$. We make minimal moments assumptions\non the increments of the process. Recently there has been renewed interest in\nLamperti-type process in the context of random polymers and interfaces,\nparticularly nearest-neighbour random walks on the integers; some of our\nresults are new even in that setting. We give applications of our results to\nprocesses on the whole of $\\R$ and to a class of multidimensional `centrally\nbiased' random walks on $\\R^d$; we also apply our results to the simple\nharmonic urn, allowing us to sharpen existing results and to verify a\nconjecture of Crane et al. \n\n"}
{"id": "1208.1211", "contents": "Title: PAC-Bayesian Estimation and Prediction in Sparse Additive Models Abstract: The present paper is about estimation and prediction in high-dimensional\nadditive models under a sparsity assumption ($p\\gg n$ paradigm). A PAC-Bayesian\nstrategy is investigated, delivering oracle inequalities in probability. The\nimplementation is performed through recent outcomes in high-dimensional MCMC\nalgorithms, and the performance of our method is assessed on simulated data. \n\n"}
{"id": "1208.3386", "contents": "Title: Existence of a martingale solution of the stochastic Navier-Stokes\n  equations in unbounded 2D and 3D-domains Abstract: Stochastic Navier-Stokes equations in 2D and 3D possibly unbounded domains\ndriven by a multiplicative Gaussian noise are considered. The noise term\ndepends on the unknown velocity and its spatial derivatives. The existence of a\nmartingale solution is proved. The construction of the solution is based on the\nclassical Faedo-Galerkin approximation, the compactness method and the\nJakubowski version of the Skorokhod Theorem for non-metric spaces. Moreover,\nsome compactness and tightness criteria in non-metric spaces are proved.\nCompactness results are based on a certain generalization of the classical\nDubinsky Theorem. \n\n"}
{"id": "1208.3826", "contents": "Title: Local time on the exceptional set of dynamical percolation, and the\n  Incipient Infinite Cluster Abstract: In dynamical critical site percolation on the triangular lattice or bond\npercolation on \\Z^2, we define and study a local time measure on the\nexceptional times at which the origin is in an infinite cluster. We show that\nat a typical time with respect to this measure, the percolation configuration\nhas the law of Kesten's Incipient Infinite Cluster. In the most technical\nresult of this paper, we show that, on the other hand, at the first exceptional\ntime, the law of the configuration is different. We also study the collapse of\nthe infinite cluster near typical exceptional times, and establish a relation\nbetween static and dynamic exponents, analogous to Kesten's near-critical\nrelation. \n\n"}
{"id": "1209.0012", "contents": "Title: Residual variance and the signal-to-noise ratio in high-dimensional\n  linear models Abstract: Residual variance and the signal-to-noise ratio are important quantities in\nmany statistical models and model fitting procedures. They play an important\nrole in regression diagnostics, in determining the performance limits in\nestimation and prediction problems, and in shrinkage parameter selection in\nmany popular regularized regression methods for high-dimensional data analysis.\nWe propose new estimators for the residual variance, the l2-signal strength,\nand the signal-to-noise ratio that are consistent and asymptotically normal in\nhigh-dimensional linear models with Gaussian predictors and errors, where the\nnumber of predictors d is proportional to the number of observations n.\nExisting results on residual variance estimation in high-dimensional linear\nmodels depend on sparsity in the underlying signal. Our results require no\nsparsity assumptions and imply that the residual variance may be consistently\nestimated even when d > n and the underlying signal itself is non-estimable.\nBasic numerical work suggests that some of the distributional assumptions made\nfor our theoretical results may be relaxed. \n\n"}
{"id": "1209.0956", "contents": "Title: Conditionally Evenly Convex Sets and Evenly Quasi-Convex Maps Abstract: Evenly convex sets in a topological vector space are defined as the\nintersection of a family of open half spaces. We introduce a generalization of\nthis concept in the conditional framework and provide a generalized version of\nthe bipolar theorem. This notion is then applied to obtain the dual\nrepresentation of conditionally evenly quasi-convex maps. \n\n"}
{"id": "1209.4323", "contents": "Title: Fractal random series generated by Poisson-Voronoi tessellations Abstract: In this paper, we construct a new family of random series defined on $\\R^D$,\nindexed by one scaling parameter and two Hurst-like exponents. The model is\nclose to Takagi-Knopp functions, save for the fact that the underlying\npartitions of $\\R^D$ are not the usual dyadic meshes but random Voronoi\ntessellations generated by Poisson point processes. This approach leads us to a\ncontinuous function whose random graph is shown to be fractal with explicit and\nequal box and Hausdorff dimensions. The proof of this main result is based on\nseveral new distributional properties of the Poisson-Voronoi tessellation on\nthe one hand, an estimate of the oscillations of the function coupled with an\napplication of a Frostman-type lemma on the other hand. Finally, we introduce\ntwo related models and provide in particular a box-dimension calculation for a\nderived deterministic Takagi-Knopp series with hexagonal bases. \n\n"}
{"id": "1210.3711", "contents": "Title: Network Granger Causality with Inherent Grouping Structure Abstract: The problem of estimating high-dimensional network models arises naturally in\nthe analysis of many physical, biological and socio-economic systems. Examples\ninclude stock price fluctuations in financial markets and gene regulatory\nnetworks representing effects of regulators (transcription factors) on\nregulated genes in genetics. We aim to learn the structure of the network over\ntime employing the framework of Granger causal models under the assumptions of\nsparsity of its edges and inherent grouping structure among its nodes. We\nintroduce a thresholded variant of the Group Lasso estimator for discovering\nGranger causal interactions among the nodes of the network. Asymptotic results\non the consistency of the new estimation procedure are developed. The\nperformance of the proposed methodology is assessed through an extensive set of\nsimulation studies and comparisons with existing techniques. \n\n"}
{"id": "1210.4468", "contents": "Title: Large Deviations for the solution of a Kac-type kinetic equation Abstract: The aim of this paper is to study large deviations for the self-similar\nsolution of a Kac-type kinetic equation. Under the assumption that the initial\ncondition belongs to the domain of normal attraction of a stable law of index\n$\\alpha <2$ and under suitable assumptions on the collisional kernel, precise\nasymptotic behavior of the large deviations probability is given. \n\n"}
{"id": "1210.5590", "contents": "Title: On the asymptotic of convex hulls of Gaussian fields Abstract: We consider a Gaussian field $X = \\{X_t, t \\in T\\}$ with values in a Banach\nspace $B$ defined on a parametric set $T$ equal to $R^m$ or $Z^m.$ It is\nsupposed that the distribution $\\cal P$ of $X_t$ is independent of $t.$ We\nconsider the asymptotic behavior of closed convex hulls $$ W_n = \\conv \\{X_t, t\n\\in T_n\\} $$ where $(T_n)$ is an increasing sequence of subsets of $T$ and we\nshow that under some conditions of the weak dependence with probability 1 $$\n\\lim_{n\\rightarrow \\infty} \\frac{1}{b_n}\\,W_n = {\\cal E} $$ (in the sense of\nHausdorff distance), where the limit shape ${\\cal E}$ is the concentration\nellipsoid of $\\cal P.$\n  The asymptotic behavior of the mathematical expectations $Ef(W_n),$ where $f$\nis an homogeneous function is also studied. \n\n"}
{"id": "1210.5926", "contents": "Title: A comparison principle for stochastic integro-differential equations Abstract: A comparison principle for stochastic integro-differential equations driven\nby Levy processes is proved. This result is obtained via an extension of an Ito\nformula from [11] for the square of the norm of the positive part of\n$L_2-$valued, continuous semimartingales, to the case of discontinuous\nsemimartingales. \n\n"}
{"id": "1211.0174", "contents": "Title: Laplace approximation for logistic Gaussian process density estimation\n  and regression Abstract: Logistic Gaussian process (LGP) priors provide a flexible alternative for\nmodelling unknown densities. The smoothness properties of the density estimates\ncan be controlled through the prior covariance structure of the LGP, but the\nchallenge is the analytically intractable inference. In this paper, we present\napproximate Bayesian inference for LGP density estimation in a grid using\nLaplace's method to integrate over the non-Gaussian posterior distribution of\nlatent function values and to determine the covariance function parameters with\ntype-II maximum a posteriori (MAP) estimation. We demonstrate that Laplace's\nmethod with MAP is sufficiently fast for practical interactive visualisation of\n1D and 2D densities. Our experiments with simulated and real 1D data sets show\nthat the estimation accuracy is close to a Markov chain Monte Carlo\napproximation and state-of-the-art hierarchical infinite Gaussian mixture\nmodels. We also construct a reduced-rank approximation to speed up the\ncomputations for dense 2D grids, and demonstrate density regression with the\nproposed Laplace approach. \n\n"}
{"id": "1211.0389", "contents": "Title: Semicircle Law for a Class of Random Matrices with Dependent Entries Abstract: In this paper we study ensembles of random symmetric matrices $\\X_n =\n{X_{ij}}_{i,j = 1}^n$ with dependent entries such that $\\E X_{ij} = 0$, $\\E\nX_{ij}^2 = \\sigma_{ij}^2$, where $\\sigma_{ij}$ may be different numbers.\nAssuming that the average of the normalized sums of variances in each row\nconverges to one and Lindeberg condition holds we prove that the empirical\nspectral distribution of eigenvalues converges to Wigner's semicircle law. \n\n"}
{"id": "1211.1144", "contents": "Title: Genome-wide association studies with high-dimensional phenotypes Abstract: High-dimensional phenotypes hold promise for richer findings in association\nstudies, but testing of several phenotype traits aggravates the grand challenge\nof association studies, that of multiple testing. Several methods have recently\nbeen proposed for testing jointly all traits in a high-dimensional vector of\nphenotypes, with prospect of increased power to detect small effects that would\nbe missed if tested individually. However, the methods have rarely been\ncompared to the extent of enabling assessment of their relative merits and\nsetting up guidelines on which method to use, and how to use it. We compare the\nmethods on simulated data and with a real metabolomics data set comprising 137\nhighly correlated variables and approximately 550,000 SNPs.\n  Applying the methods to genome-wide data with hundreds of thousands of\nmarkers inevitably requires division of the problem into manageable parts\nfacilitating parallel processing, parts corresponding to individual genetic\nvariants, pathways, or genes, for example. Here we utilize a straightforward\nformulation according to which the genome is divided into blocks of nearby\ncorrelated genetic markers, tested jointly for association with the phenotypes.\nThis formulation is computationally feasible, reduces the number of tests, and\nlets the methods take advantage of combining information over several\ncorrelated variables not only on the phenotype side, but also on the genotype\nside.\n  Our experiments show that canonical correlation analysis has higher power\nthan alternative methods, while remaining computationally tractable for routine\nuse in the GWAS setting, provided the number of samples is sufficient compared\nto the numbers of phenotype and genotype variables tested. Sparse canonical\ncorrelation analysis and regression models with latent confounding factors show\npromising performance when the number of samples is small. \n\n"}
{"id": "1211.2284", "contents": "Title: Energy Landscape for large average submatrix detection problems in\n  Gaussian random matrices Abstract: The problem of finding large average submatrices of a real-valued matrix\narises in the exploratory analysis of data from a variety of disciplines,\nranging from genomics to social sciences. In this paper we provide a detailed\nasymptotic analysis of large average submatrices of an $n \\times n$ Gaussian\nrandom matrix. The first part of the paper addresses global maxima. For fixed\n$k$ we identify the average and the joint distribution of the $k \\times k$\nsubmatrix having largest average value. As a dual result, we establish that the\nsize of the largest square sub-matrix with average bigger than a fixed positive\nconstant is, with high probability, equal to one of two consecutive integers\nthat depend on the threshold and the matrix dimension $n$. The second part of\nthe paper addresses local maxima. Specifically we consider submatrices with\ndominant row and column sums that arise as the local optima of iterative search\nprocedures for large average submatrices. For fixed $k$, we identify the\nlimiting average value and joint distribution of a $k \\times k$ submatrix\nconditioned to be a local maxima. In order to understand the density of such\nlocal optima and explain the quick convergence of such iterative procedures, we\nanalyze the number $L_n(k)$ of local maxima, beginning with exact asymptotic\nexpressions for the mean and fluctuation behavior of $L_n(k)$. For fixed $k$,\nthe mean of $L_{n}(k)$ is $\\Theta(n^{k}/(\\log{n})^{(k-1)/2})$ while the\nstandard deviation is $\\Theta(n^{2k^2/(k+1)}/(\\log{n})^{k^2/(k+1)})$. Our\nprincipal result is a Gaussian central limit theorem for $L_n(k)$ that is based\non a new variant of Stein's method. \n\n"}
{"id": "1211.3209", "contents": "Title: Noncommutative martingale deviation and Poincar\\'e type inequalities\n  with applications Abstract: We prove a deviation inequality for noncommutative martingales by extending\nOliveira's argument for random matrices. By integration we obtain a Burkholder\ntype inequality with satisfactory constant. Using continuous time, we establish\nnoncommutative Poincar\\'e type inequalities for \"nice\" semigroups with a\npositive curvature condition. These results allow us to prove a general\ndeviation inequality and a noncommutative transportation inequality due to\nBobkov and G\\\"otze in the commutative case. To demonstrate our setting is\ngeneral enough, we give various examples, including certain group von Neumann\nalgebras, random matrices and classical diffusion processes, among others. \n\n"}
{"id": "1211.3868", "contents": "Title: Pathwise stochastic integration with finite variation processes\n  uniformly approximating c\\`{a}dl\\`{a}g processes Abstract: For any real-valued stochastic process $X$ with c\\'rdl\\'rg paths we define\nnon-empty family of processes which have locally finite total variation, have\njumps of the same order as the process $X$ and uniformly approximate its paths\non compacts. The application of the defined class is the definition of\nstochastic integral with semimartingale integrand and integrator as a limit of\npathwise Lebesgue-Stieltjes integrals. This construction leads to the\nstochastic integral with some correction term (different from the Stratonovich\nintegral). We compare the obtained result with classical results of Wong-Zakai\nand Bichteler on pathwise stochastic integration. As a \"byproduct\" we obtain an\nexample of a series of double Skorohod maps of a standard Brownian motion,\nwhich is not a semimartingale. \n\n"}
{"id": "1211.5290", "contents": "Title: EMMIX-uskew: An R Package for Fitting Mixtures of Multivariate Skew\n  t-distributions via the EM Algorithm Abstract: This paper describes an algorithm for fitting finite mixtures of unrestricted\nMultivariate Skew t (FM-uMST) distributions. The package EMMIX-uskew implements\na closed-form expectation-maximization (EM) algorithm for computing the maximum\nlikelihood (ML) estimates of the parameters for the (unrestricted) FM-MST model\nin R. EMMIX-uskew also supports visualization of fitted contours in two and\nthree dimensions, and random sample generation from a specified FM-uMST\ndistribution.\n  Finite mixtures of skew t-distributions have proven to be useful in modelling\nheterogeneous data with asymmetric and heavy tail behaviour, for example,\ndatasets from flow cytometry. In recent years, various versions of mixtures\nwith multivariate skew t (MST) distributions have been proposed. However, these\nmodels adopted some restricted characterizations of the component MST\ndistributions so that the E-step of the EM algorithm can be evaluated in closed\nform. This paper focuses on mixtures with unrestricted MST components, and\ndescribes an iterative algorithm for the computation of the ML estimates of its\nmodel parameters.\n  The usefulness of the proposed algorithm is demonstrated in three\napplications to real data sets. The first example illustrates the use of the\nmain function fmmst in the package by fitting a MST distribution to a bivariate\nunimodal flow cytometric sample. The second example fits a mixture of MST\ndistributions to the Australian Institute of Sport (AIS) data, and demonstrate\nthat EMMIX-uskew can provide better clustering results than mixtures with\nrestricted MST components. In the third example, EMMIX-uskew is applied to\nclassify cells in a trivariate flow cytometric dataset. Comparisons with other\navailable methods suggests that the EMMIX-uskew result achieved a lower\nmisclassification rate with respect to the labels given by benchmark gating\nanalysis. \n\n"}
{"id": "1211.7259", "contents": "Title: Densities of the Raney distributions Abstract: We prove that if $p\\ge 1$ and $0< r\\le p$ then the sequence\n$\\binom{mp+r}{m}\\frac{r}{mp+r}$, $m=0,1,2,...$, is positive definite, more\nprecisely, is the moment sequence of a probability measure $\\mu(p,r)$ with\ncompact support contained in $[0,+\\infty)$. This family of measures encompasses\nthe multiplicative free powers of the Marchenko-Pastur distribution as well as\nthe Wigner's semicircle distribution centered at $x=2$. We show that if $p>1$\nis a rational number, $0<r\\le p$, then $\\mu(p,r)$ is absolutely continuous and\nits density $W_{p,r}(x)$ can be expressed in terms of the Meijer and the\ngeneralized hypergeometric functions. In some cases, including the\nmultiplicative free square and the multiplicative free square root of the\nMarchenko-Pastur measure, $W_{p,r}(x)$ turns out to be an elementary function. \n\n"}
{"id": "1212.0442", "contents": "Title: Some New Asymptotic Theory for Least Squares Series: Pointwise and\n  Uniform Results Abstract: In applications it is common that the exact form of a conditional expectation\nis unknown and having flexible functional forms can lead to improvements.\nSeries method offers that by approximating the unknown function based on $k$\nbasis functions, where $k$ is allowed to grow with the sample size $n$. We\nconsider series estimators for the conditional mean in light of: (i) sharp LLNs\nfor matrices derived from the noncommutative Khinchin inequalities, (ii) bounds\non the Lebesgue factor that controls the ratio between the $L^\\infty$ and\n$L_2$-norms of approximation errors, (iii) maximal inequalities for processes\nwhose entropy integrals diverge, and (iv) strong approximations to series-type\nprocesses.\n  These technical tools allow us to contribute to the series literature,\nspecifically the seminal work of Newey (1997), as follows. First, we weaken the\ncondition on the number $k$ of approximating functions used in series\nestimation from the typical $k^2/n \\to 0$ to $k/n \\to 0$, up to log factors,\nwhich was available only for spline series before. Second, we derive $L_2$\nrates and pointwise central limit theorems results when the approximation error\nvanishes. Under an incorrectly specified model, i.e. when the approximation\nerror does not vanish, analogous results are also shown. Third, under stronger\nconditions we derive uniform rates and functional central limit theorems that\nhold if the approximation error vanishes or not. That is, we derive the strong\napproximation for the entire estimate of the nonparametric function.\n  We derive uniform rates, Gaussian approximations, and uniform confidence\nbands for a wide collection of linear functionals of the conditional\nexpectation function. \n\n"}
{"id": "1212.0476", "contents": "Title: Second-order BSDEs with general reflection and game options under\n  uncertainty Abstract: The aim of this paper is twofold. First, we extend the results of [33]\nconcerning the existence and uniqueness of second-order reflected 2BSDEs to the\ncase of two obstacles. Under some regularity assumptions on one of the\nbarriers, similar to the ones in [10], and when the two barriers are completely\nseparated, we provide a complete wellposedness theory for doubly reflected\nsecond-order BSDEs. We also show that these objects are related to non-standard\noptimal stopping games, thus generalizing the connection between DRBSDEs and\nDynkin games first proved by Cvitanic and Karatzas [11]. More precisely, we\nshow under a technical assumption that the second order DRBSDEs provide\nsolutions of what we call uncertain Dynkin games and that they also allow us to\nobtain super and subhedging prices for American game options (also called\nIsraeli options) in financial markets with volatility uncertainty \n\n"}
{"id": "1212.0509", "contents": "Title: Inviscid limit of stochastic damped 2D Navier-Stokes equations Abstract: We consider the inviscid limit of the stochastic damped 2D Navier- Stokes\nequations. We prove that, when the viscosity vanishes, the stationary solution\nof the stochastic damped Navier-Stokes equations converges to a stationary\nsolution of the stochastic damped Euler equation and that the rate of\ndissipation of enstrophy converges to zero. In particular, this limit obeys an\nenstrophy balance. The rates are computed with respect to a limit measure of\nthe unique invariant measure of the stochastic damped Navier-Stokes equations. \n\n"}
{"id": "1212.1197", "contents": "Title: Forward and Backward Governing EQuations for Anomalous Diffusion Models\n  Based on the Continuous Time Random Walk Abstract: Continuous Time Random Walks (CTRWs) are jump processes with random waiting\ntimes between jumps. We study scaling limits for CTRWs where the distribution\nof jumps and waiting times is coupled and varies in space and time. Such\nprocesses model e.g. anomalous diffusion processes in a space- and\ntime-dependent potential. Conditions for the process-convergence of CTRWs are\ngiven, and the limits are characterised by four coefficients. Kolmogorov\nforwards and backwards equations with non-local time operators are derived, and\nthree models for anomalous diffusion are presented: i) Subdiffusion in a\ntime-dependent potential, ii) subdiffusion with spatially varying waiting times\nand iii) L\\'evy walks with space- and time-dependent drift. \n\n"}
{"id": "1212.2014", "contents": "Title: The convex distance inequality for dependent random variables, with\n  applications to the stochastic travelling salesman and other problems Abstract: We prove concentration inequalities for general functions of weakly dependent\nrandom variables satisfying the Dobrushin condition. In particular, we show\nTalagrand's convex distance inequality for this type of dependence. We apply\nour bounds to a version of the stochastic salesman problem, the Steiner tree\nproblem, the total magnetisation of the Curie-Weiss model with external field,\nand exponential random graph models. Our proof uses the exchangeable pair\nmethod for proving concentration inequalities introduced by Chatterjee (2005).\nAnother key ingredient of the proof is a subclass of $(a,b)$-self-bounding\nfunctions, introduced by Boucheron, Lugosi and Massart (2009). \n\n"}
{"id": "1212.3816", "contents": "Title: Tail decay for the distribution of the endpoint of a directed polymer Abstract: We obtain an asymptotic expansion for the tails of the random variable\n$\\tcal=\\arg\\max_{u\\in\\mathbb{R}}(\\mathcal{A}_2(u)-u^2)$ where $\\mathcal{A}_2$\nis the Airy$_2$ process. Using the formula of Schehr \\cite{Sch} that connects\nthe density function of $\\tcal$ to the Hastings-McLeod solution of the second\nPainlev\\'e equation, we prove that as $t\\rightarrow\\infty$,\n$\\mathbb{P}(|\\tcal|>t)=Ce^{-4/3\\varphi(t)}t^{-145/32}(1+O(t^{-3/4}))$, where\n$\\varphi(t)=t^3-2t^{3/2}+3t^{3/4}$, and the constant $C$ is given explicitly. \n\n"}
{"id": "1212.5088", "contents": "Title: Bayesian data assimilation in shape registration Abstract: In this paper we apply a Bayesian framework to the problem of geodesic curve\nmatching. Given a template curve, the geodesic equations provide a mapping from\ninitial conditions for the conjugate momentum onto topologically equivalent\nshapes. Here, we aim to recover the well-defined posterior distribution on the\ninitial momentum which gives rise to observed points on the target curve; this\nis achieved by explicitly including a reparameterisation in the formulation.\nAppropriate priors are chosen for the functions which together determine this\nfield and the positions of the observation points, the initial momentum $p_0$\nand the reparameterisation vector field $\\nu$, informed by regularity results\nabout the forward model. Having done this, we illustrate how Maximum Likelihood\nEstimators (MLEs) can be used to find regions of high posterior density, but\nalso how we can apply recently developed \\SLC{Markov chain Monte Carlo (MCMC)}\nmethods on function spaces to characterise the whole of the posterior density.\nThese illustrative examples also include scenarios where the posterior\ndistribution is multimodal and irregular, leading us to the conclusion that\nknowledge of a state of global maximal posterior density does not always give\nus the whole picture, and full posterior sampling can give better\nquantification of likely states and the overall uncertainty inherent in the\nproblem. \n\n"}
{"id": "1212.5128", "contents": "Title: Remarks on differentiability in the initial data for stochastic\n  reflecting flow Abstract: Stochastic flows generated by reflected SDEs in a half-plane with an additive\ndiffusion term are considered. A derivative in the initial data is represented\na.s. as an infinite product of matrices. We use this representation and\nconstruct an example of a reflecting flow with a linear drift such that it is\nnot locally continuously differentiable. \n\n"}
{"id": "1212.6254", "contents": "Title: A Geometric Perspective on First-Passage Competition Abstract: We study the macroscopic geometry of first-passage competition on the integer\nlattice $Z^d$, with a particular interest in describing the behavior when one\nspecies initially occupies the exterior of a cone. First-passage competition is\na stochastic process modeling two infections spreading outward from initially\noccupied disjoint subsets of $Z^d$. Each infecting species transmits its\ninfection at random times from previously infected sites to neighboring\nuninfected sites. The infection times are governed by species-specific\nprobability distributions, and every vertex of $Z^d$ remains permanently\ninfected by whichever species infects it first.\n  We introduce a new, simple construction of first-passage competition that\nworks for an arbitrary pair of disjoint starting sets in $Z^d$, and we\nanalogously define a deterministic first-passage competition process in the\nEuclidean space $R^d$, providing a formal definition for a model of crystal\ngrowth that has previously been studied computationally. We then prove large\ndeviations estimates for the random $Z^d$-process, showing that on large scales\nit is well-approximated by the deterministic $R^d$-process, with high\nprobability. Analyzing the geometry of the deterministic process allows us to\nidentify critical phenomena in the random process when one of the two species\ninitially occupies the entire exterior of a cone and the other species\ninitially occupies a single interior site. Our results generalize those in a\n2007 paper of Deijfen and H\\\"aggstr\\\"om, who considered the case where the cone\nis a half-space. Moreover, we use our results about competition in cones to\nstrengthen a 2000 result of H\\\"aggstr\\\"om and Pemantle about competition from\nfinite starting configurations. \n\n"}
{"id": "1301.0811", "contents": "Title: Random loop representations for quantum spin systems Abstract: We describe random loop models and their relations to a family of quantum\nspin systems on finite graphs. The family includes spin 1/2 Heisenberg models\nwith possibly anisotropic spin interactions and certain spin 1 models with\nSU(2)-invariance. Quantum spin correlations are given by loop correlations.\nDecay of correlations is proved in 2D-like graphs, and occurrence of\nmacroscopic loops is proved in the cubic lattice in dimensions 3 and higher. As\na consequence, a magnetic long-range order is rigorously established for the\nspin 1 model, thus confirming the presence of a nematic phase. \n\n"}
{"id": "1301.0993", "contents": "Title: Asymptotic behavior of mixed power variations and statistical estimation\n  in mixed models Abstract: We obtain results on both weak and almost sure asymptotic behaviour of power\nvariations of a linear combination of independent Wiener process and fractional\nBrownian motion. These results are used to construct strongly consistent\nparameter estimators in mixed models. \n\n"}
{"id": "1301.1483", "contents": "Title: Bounds on the critical line via transfer matrix methods for an Ising\n  model coupled to causal dynamical triangulations Abstract: We introduce a transfer matrix formalism for the (annealed) Ising model\ncoupled to two-dimensional causal dynamical triangulations. Using the\nKrein-Rutman theory of positivity preserving operators we study several\nproperties of the emerging transfer matrix. In particular, we determine regions\nin the quadrant of parameters beta, mu >0 where the infinite-volume free energy\nconverges, yielding results on the convergence and asymptotic properties of the\npartition function and the Gibbs measure. \n\n"}
{"id": "1301.3154", "contents": "Title: Coherent Quantum Filtering for Physically Realizable Linear Quantum\n  Plants Abstract: The paper is concerned with a problem of coherent (measurement-free)\nfiltering for physically realizable (PR) linear quantum plants. The state\nvariables of such systems satisfy canonical commutation relations and are\ngoverned by linear quantum stochastic differential equations, dynamically\nequivalent to those of an open quantum harmonic oscillator. The problem is to\ndesign another PR quantum system, connected unilaterally to the output of the\nplant and playing the role of a quantum filter, so as to minimize a mean square\ndiscrepancy between the dynamic variables of the plant and the output of the\nfilter. This coherent quantum filtering (CQF) formulation is a simplified\nfeedback-free version of the coherent quantum LQG control problem which remains\nopen despite recent studies. The CQF problem is transformed into a constrained\ncovariance control problem which is treated by using the Frechet\ndifferentiation of an appropriate Lagrange function with respect to the\nmatrices of the filter. \n\n"}
{"id": "1301.7212", "contents": "Title: Multiscale Change-Point Inference Abstract: We introduce a new estimator SMUCE (simultaneous multiscale change-point\nestimator) for the change-point problem in exponential family regression. An\nunknown step function is estimated by minimizing the number of change-points\nover the acceptance region of a multiscale test at a level \\alpha. The\nprobability of overestimating the true number of change-points K is controlled\nby the asymptotic null distribution of the multiscale test statistic. Further,\nwe derive exponential bounds for the probability of underestimating K. By\nbalancing these quantities, \\alpha will be chosen such that the probability of\ncorrectly estimating K is maximized. All results are even non-asymptotic for\nthe normal case. Based on the aforementioned bounds, we construct\nasymptotically honest confidence sets for the unknown step function and its\nchange-points. At the same time, we obtain exponential bounds for estimating\nthe change-point locations which for example yield the minimax rate O(1/n) up\nto a log term. Finally, SMUCE asymptotically achieves the optimal detection\nrate of vanishing signals. We illustrate how dynamic programming techniques can\nbe employed for efficient computation of estimators and confidence regions. The\nperformance of the proposed multiscale approach is illustrated by simulations\nand in two cutting-edge applications from genetic engineering and photoemission\nspectroscopy. \n\n"}
{"id": "1302.2534", "contents": "Title: Stationarity and ergodicity for an affine two factor model Abstract: We study the existence of a unique stationary distribution and ergodicity for\na 2-dimensional affine process. The first coordinate is supposed to be a\nso-called alpha-root process with \\alpha\\in(1,2]. The existence of a unique\nstationary distribution for the affine process is proved in case of\n\\alpha\\in(1,2]; further, in case of \\alpha=2, the ergodicity is also shown. \n\n"}
{"id": "1302.2686", "contents": "Title: Covariance Estimation in High Dimensions via Kronecker Product\n  Expansions Abstract: This paper presents a new method for estimating high dimensional covariance\nmatrices. The method, permuted rank-penalized least-squares (PRLS), is based on\na Kronecker product series expansion of the true covariance matrix. Assuming an\ni.i.d. Gaussian random sample, we establish high dimensional rates of\nconvergence to the true covariance as both the number of samples and the number\nof variables go to infinity. For covariance matrices of low separation rank,\nour results establish that PRLS has significantly faster convergence than the\nstandard sample covariance matrix (SCM) estimator. The convergence rate\ncaptures a fundamental tradeoff between estimation error and approximation\nerror, thus providing a scalable covariance estimation framework in terms of\nseparation rank, similar to low rank approximation of covariance matrices. The\nMSE convergence rates generalize the high dimensional rates recently obtained\nfor the ML Flip-flop algorithm for Kronecker product covariance estimation. We\nshow that a class of block Toeplitz covariance matrices is approximatable by\nlow separation rank and give bounds on the minimal separation rank $r$ that\nensures a given level of bias. Simulations are presented to validate the\ntheoretical bounds. As a real world application, we illustrate the utility of\nthe proposed Kronecker covariance estimator for spatio-temporal linear least\nsquares prediction of multivariate wind speed measurements. \n\n"}
{"id": "1302.2769", "contents": "Title: Parameter dependent optimal thresholds, indifference levels and inverse\n  optimal stopping problems Abstract: Consider the classic infinite-horizon problem of stopping a one-dimensional\ndiffusion to optimise between running and terminal rewards and suppose we are\ngiven a parametrised family of such problems. We provide a general theory of\nparameter dependence in infinite-horizon stopping problems for which threshold\nstrategies are optimal. The crux of the approach is a supermodularity condition\nwhich guarantees that the family of problems is indexable by a set valued map\nwhich we call the indifference map. This map is a natural generalisation of the\nallocation (Gittins) index, a classical quantity in the theory of dynamic\nallocation. Importantly, the notion of indexability leads to a framework for\ninverse optimal stopping problems. \n\n"}
{"id": "1302.3447", "contents": "Title: Exact Methods for Multistage Estimation of a Binomial Proportion Abstract: We first review existing sequential methods for estimating a binomial\nproportion. Afterward, we propose a new family of group sequential sampling\nschemes for estimating a binomial proportion with prescribed margin of error\nand confidence level. In particular, we establish the uniform controllability\nof coverage probability and the asymptotic optimality for such a family of\nsampling schemes. Our theoretical results establish the possibility that the\nparameters of this family of sampling schemes can be determined so that the\nprescribed level of confidence is guaranteed with little waste of samples.\nAnalytic bounds for the cumulative distribution functions and expectations of\nsample numbers are derived. Moreover, we discuss the inherent connection of\nvarious sampling schemes. Numerical issues are addressed for improving the\naccuracy and efficiency of computation. Computational experiments are conducted\nfor comparing sampling schemes. Illustrative examples are given for\napplications in clinical trials. \n\n"}
{"id": "1302.4526", "contents": "Title: Hitting times of Bessel processes, volume of Wiener sausages and zeros\n  of Macdonald functions Abstract: We derive formulae for some ratios of the Macdonald functions, which are\nsimpler and easier to treat than known formulae. The result gives two\napplications in probability theory. One is the formula for the L{\\'e}vy measure\nof the distribution of the first hitting time of a Bessel process and the other\nis an explicit form for the expected volume of the Wiener sausage for an even\ndimensional Brownian motion. Moreover, the result enables us to write down the\nalgebraic equations whose roots are the zeros of Macdonald functions. \n\n"}
{"id": "1303.0383", "contents": "Title: Local Gaussian process approximation for large computer experiments Abstract: We provide a new approach to approximate emulation of large computer\nexperiments. By focusing expressly on desirable properties of the predictive\nequations, we derive a family of local sequential design schemes that\ndynamically define the support of a Gaussian process predictor based on a local\nsubset of the data. We further derive expressions for fast sequential updating\nof all needed quantities as the local designs are built-up iteratively. Then we\nshow how independent application of our local design strategy across the\nelements of a vast predictive grid facilitates a trivially parallel\nimplementation. The end result is a global predictor able to take advantage of\nmodern multicore architectures, while at the same time allowing for a\nnonstationary modeling feature as a bonus. We demonstrate our method on two\nexamples utilizing designs sized in the thousands, and tens of thousands of\ndata points. Comparisons are made to the method of compactly supported\ncovariances. \n\n"}
{"id": "1303.1229", "contents": "Title: Ratios of partition functions for the log-gamma polymer Abstract: We introduce a random walk in random environment associated to an underlying\ndirected polymer model in $1+1$ dimensions. This walk is the positive\ntemperature counterpart of the competition interface of percolation and arises\nas the limit of quenched polymer measures. We prove this limit for the exactly\nsolvable log-gamma polymer, as a consequence of almost sure limits of ratios of\npartition functions. These limits of ratios give the Busemann functions of the\nlog-gamma polymer, and furnish centered cocycles that solve a variational\nformula for the limiting free energy. Limits of ratios of point-to-point and\npoint-to-line partition functions manifest a duality between tilt and velocity\nthat comes from quenched large deviations under polymer measures. In the\nlog-gamma case, we identify a family of ergodic invariant distributions for the\nrandom walk in random environment. \n\n"}
{"id": "1303.2306", "contents": "Title: Tail asymptotics for the supercritical Galton-Watson process in the\n  heavy-tailed case Abstract: As well known, for a supercritical Galton-Watson process $Z_n$ whose\noffspring distribution has mean $m>1$, the ratio $W_n:=Z_n/m^n$ has a.s. limit,\nsay $W$. We study tail behaviour of the distributions of $W_n$ and $W$ in the\ncase where $Z_1$ has heavy-tailed distribution, that is, $\\E e^{\\lambda\nZ_1}=\\infty$ for every $\\lambda>0$. We show how different types of\ndistributions of $Z_1$ lead to different asymptotic behaviour of the tail of\n$W_n$ and $W$. We describe the most likely way how large values of the process\noccur. \n\n"}
{"id": "1304.1342", "contents": "Title: On Exceptional Times for generalized Fleming-Viot Processes with\n  Mutations Abstract: If $\\mathbf Y$ is a standard Fleming-Viot process with constant mutation rate\n(in the infinitely many sites model) then it is well known that for each $t>0$\nthe measure $\\mathbf Y_t$ is purely atomic with infinitely many atoms. However,\nSchmuland proved that there is a critical value for the mutation rate under\nwhich almost surely there are exceptional times at which $\\mathbf Y$ is a\nfinite sum of weighted Dirac masses. In the present work we discuss the\nexistence of such exceptional times for the generalized Fleming-Viot processes.\nIn the case of Beta-Fleming-Viot processes with index $\\alpha\\in\\,]1,2[$ we\nshow that - irrespectively of the mutation rate and $\\alpha$ - the number of\natoms is almost surely always infinite. The proof combines a Pitman-Yor type\nrepresentation with a disintegration formula, Lamperti's transformation for\nself-similar processes and covering results for Poisson point processes. \n\n"}
{"id": "1304.1384", "contents": "Title: Nonparametric estimation of the tree structure of a nested Archimedean\n  copula Abstract: One of the features inherent in nested Archimedean copulas, also called\nhierarchical Archimedean copulas, is their rooted tree structure. A\nnonparametric, rank-based method to estimate this structure is presented. The\nidea is to represent the target structure as a set of trivariate structures,\neach of which can be estimated individually with ease. Indeed, for any three\nvariables there are only four possible rooted tree structures and, based on a\nsample, a choice can be made by performing comparisons between the three\nbivariate margins of the empirical distribution of the three variables. The set\nof estimated trivariate structures can then be used to build an estimate of the\ntarget structure. The advantage of this estimation method is that it does not\nrequire any parametric assumptions concerning the generator functions at the\nnodes of the tree. \n\n"}
{"id": "1304.1826", "contents": "Title: Concentration inequalities for non-Lipschitz functions with bounded\n  derivatives of higher order Abstract: Building on the inequalities for homogeneous tetrahedral polynomials in\nindependent Gaussian variables due to R. Lata{\\l}a we provide a concentration\ninequality for non-necessarily Lipschitz functions $f\\colon \\R^n \\to \\R$ with\nbounded derivatives of higher orders, which hold when the underlying measure\nsatisfies a family of Sobolev type inequalities $\\|g- \\E g\\|_p \\le C(p)\\|\\nabla\ng\\|_p.$\n  Such Sobolev type inequalities hold, e.g., if the underlying measure\nsatisfies the log-Sobolev inequality (in which case $C(p) \\le C\\sqrt{p}$) or\nthe Poincar\\'e inequality (then $C(p) \\le Cp$). Our concentration estimates are\nexpressed in terms of tensor-product norms of the derivatives of $f$.\n  When the underlying measure is Gaussian and $f$ is a polynomial\n(non-necessarily tetrahedral or homogeneous), our estimates can be reversed (up\nto a constant depending only on the degree of the polynomial). We also show\nthat for polynomial functions, analogous estimates hold for arbitrary random\nvectors with independent sub-Gaussian coordinates.\n  We apply our inequalities to general additive functionals of random vectors\n(in particular linear eigenvalue statistics of random matrices) and the problem\nof counting cycles of fixed length in Erd\\H{o}s-R{\\'e}nyi random graphs,\nobtaining new estimates, optimal in a certain range of parameters. \n\n"}
{"id": "1304.3206", "contents": "Title: Multivariate Generalized Gaussian Distribution: Convexity and Graphical\n  Models Abstract: We consider covariance estimation in the multivariate generalized Gaussian\ndistribution (MGGD) and elliptically symmetric (ES) distribution. The maximum\nlikelihood optimization associated with this problem is non-convex, yet it has\nbeen proved that its global solution can be often computed via simple fixed\npoint iterations. Our first contribution is a new analysis of this likelihood\nbased on geodesic convexity that requires weaker assumptions. Our second\ncontribution is a generalized framework for structured covariance estimation\nunder sparsity constraints. We show that the optimizations can be formulated as\nconvex minimization as long the MGGD shape parameter is larger than half and\nthe sparsity pattern is chordal. These include, for example, maximum likelihood\nestimation of banded inverse covariances in multivariate Laplace distributions,\nwhich are associated with time varying autoregressive processes. \n\n"}
{"id": "1304.7198", "contents": "Title: Evidential Value in ANOVA Results in Favor of Fabrication Abstract: Some scientific publications are under suspicion of fabrication of data.\nSince humans are bad random number generators, there might be some evidential\nvalue in favor of fabrication in the statistical results as presented in such\npapers. In line with Uri Simonsohn (2012, 2013) we study the evidential value\nof the results of an ANOVA study in favor of the hypothesis of a dependence\nstructure in the underlying data. \n\n"}
{"id": "1305.0923", "contents": "Title: Random walk in a high density dynamic random environment Abstract: The goal of this note is to prove a law of large numbers for the empirical\nspeed of a green particle that performs a random walk on top of a field of red\nparticles which themselves perform independent simple random walks on $\\Z^d$,\n$d \\geq 1$. The red particles jump at rate 1 and are in a Poisson equilibrium\nwith density $\\mu$. The green particle also jumps at rate 1, but uses different\ntransition kernels $p'$ and $p''$ depending on whether it sees a red particle\nor not. It is shown that, in the limit as $\\mu\\to\\infty$, the speed of the\ngreen particle tends to the average jump under $p'$. This result is far from\nsurprising, but it is non-trivial to prove. The proof that is given in this\nnote is based on techniques that were developed in \\cite{KeSi} to deal with\nspread-of-infection models. The main difficulty is that, due to particle\nconservation, space-time correlations in the field of red particles decay\nslowly. This places the problem in a class of random walks in dynamic random\nenvironments for which scaling laws are hard to obtain. \n\n"}
{"id": "1305.2972", "contents": "Title: Discrete time q-TASEPs Abstract: We introduce two new exactly solvable (stochastic) interacting particle\nsystems which are discrete time versions of q-TASEP. We call these geometric\nand Bernoulli discrete time q-TASEP. We obtain concise formulas for\nexpectations of a large enough class of observables of the systems to\ncompletely characterize their fixed time distributions when started from step\ninitial condition. We then extract Fredholm determinant formulas for the\nmarginal distribution of the location of any given particle.\n  Underlying this work is the fact that these expectations solve closed systems\nof difference equations which can be rewritten as free evolution equations with\nk-1 two-body boundary conditions -- discrete q-deformed versions of the quantum\ndelta Bose gas. These can be solved via a nested contour integral ansatz. The\nsame solutions also arise in the study of Macdonald processes, and we show how\nthe systems of equations our expectations solve are equivalent to certain\ncommutation relations involving the Macdonald first difference operator. \n\n"}
{"id": "1305.3080", "contents": "Title: Informative Bayesian inference for the skew-normal distribution Abstract: Motivated by the analysis of the distribution of university grades, which is\nusually asymmetric, we discuss two informative priors for the shape parameter\nof the skew-normal distribution, showing that they lead to closed-form\nfull-conditional posterior distributions, particularly useful in MCMC\ncomputation. Gibbs sampling algorithms are discussed for the joint vector of\nparameters, given independent prior distributions for the location and scale\nparameters. Simulation studies are performed to assess the performance of Gibbs\nsamplers and to compare the choice of informative priors against a\nnon-informative one. The method is used to analyze the grades of the basic\nstatistics examination of the first-year undergraduate students at the School\nof Economics, University of Padua, Italy. \n\n"}
{"id": "1305.4273", "contents": "Title: Likelihood-free Simulation-based Optimal Design Abstract: Simulation-based optimal design techniques are a convenient tool for solving\na particular class of optimal design problems. The goal is to find the optimal\nconfiguration of factor settings with respect to an expected utility criterion.\nThis criterion depends on the specified probability model for the data and on\nthe assumed prior distribution for the model parameters. We develop new\nsimulation-based optimal design methods which incorporate likelihood-free\napproaches and utilize them in novel applications.\n  Most simulation-based design strategies solve the intractable expected\nutility integral at a specific design point by using Monte Carlo simulations\nfrom the probability model. Optimizing the criterion over the design points is\ncarried out in a separate step. M\\\"uller (1999) introduces an MCMC algorithm\nwhich simultaneously addresses the simulation as well as the optimization\nproblem. In principle, the optimal design can be found by detecting the utility\nmode of the sampled design points. Several improvements have been suggested to\nfacilitate this task for multidimensional design problems (see e.g. Amzal et\nal. 2006).\n  We aim to extend this simulation-based design methodology to design problems\nwhere the likelihood of the probability model is of an unknown analytical form\nbut it is possible to simulate from the probability model. We further assume\nthat prior observations are available. In such a setting it is seems natural to\nemploy approximate Bayesian computation (ABC) techniques in order to be able to\nsimulate from the conditional probability model. We provide a thorough review\nof adjacent literature and we investigate the benefits and the limitations of\nour design methodology for a particular paradigmatic example. \n\n"}
{"id": "1305.5493", "contents": "Title: Information Criteria for Deciding between Normal Regression Models Abstract: Regression models fitted to data can be assessed on their goodness of fit,\nthough models with many parameters should be disfavored to prevent\nover-fitting. Statisticians' tools for this are little known to physical\nscientists. These include the Akaike Information Criterion (AIC), a penalized\ngoodness-of-fit statistic, and the AICc, a variant including a small-sample\ncorrection. They entered the physical sciences through being used by\nastrophysicists to compare cosmological models; e.g., predictions of the\ndistance-redshift relation. The AICc is shown to have been misapplied, being\napplicable only if error variances are unknown. If error bars accompany the\ndata, the AIC should be used instead. Erroneous applications of the AICc are\nlisted in an appendix. It is also shown how the variability of the AIC\ndifference between models with a known error variance can be estimated. This\nyields a significance test that can potentially replace the use of `Akaike\nweights' for deciding between such models. Additionally, the effects of model\nmisspecification are examined. For regression models fitted to data sets\nwithout (rather than with) error bars, they are major: the AICc may be shifted\nby an unknown amount. The extent of this in the fitting of physical models\nremains to be studied. \n\n"}
{"id": "1306.0113", "contents": "Title: Trust, but verify: benefits and pitfalls of least-squares refitting in\n  high dimensions Abstract: Least-squares refitting is widely used in high dimensional regression to\nreduce the prediction bias of l1-penalized estimators (e.g., Lasso and\nSquare-Root Lasso). We present theoretical and numerical results that provide\nnew insights into the benefits and pitfalls of least-squares refitting. In\nparticular, we consider both prediction and estimation, and we pay close\nattention to the effects of correlations in the design matrices of linear\nregression models, since these correlations - although often neglected - are\ncrucial in the context of linear regression, especially in high dimensional\ncontexts. First, we demonstrate that the benefit of least-squares refitting\nstrongly depends on the setting and task under consideration: least-squares\nrefitting can be beneficial even for settings with highly correlated design\nmatrices but is not advisable for all settings, and least-squares refitting can\nbe beneficial for estimation but performs better for prediction. Finally, we\nintroduce a criterion that indicates whether least-squares refitting is\nadvisable for a specific setting and task under consideration, and we conduct a\nthorough simulation study involving the Lasso to show the usefulness of this\ncriterion. \n\n"}
{"id": "1306.1598", "contents": "Title: Bayesian factorizations of big sparse tensors Abstract: It has become routine to collect data that are structured as multiway arrays\n(tensors). There is an enormous literature on low rank and sparse matrix\nfactorizations, but limited consideration of extensions to the tensor case in\nstatistics. The most common low rank tensor factorization relies on parallel\nfactor analysis (PARAFAC), which expresses a rank $k$ tensor as a sum of rank\none tensors. When observations are only available for a tiny subset of the\ncells of a big tensor, the low rank assumption is not sufficient and PARAFAC\nhas poor performance. We induce an additional layer of dimension reduction by\nallowing the effective rank to vary across dimensions of the table. For\nconcreteness, we focus on a contingency table application. Taking a Bayesian\napproach, we place priors on terms in the factorization and develop an\nefficient Gibbs sampler for posterior computation. Theory is provided showing\nposterior concentration rates in high-dimensional settings, and the methods are\nshown to have excellent performance in simulations and several real data\napplications. \n\n"}
{"id": "1306.2359", "contents": "Title: Simple proof of Dynkin's formula for single-server systems and\n  polynomial convergence rates Abstract: An elementary and rigorous justification of Dynkin's identity with an\nextended infinitesimal operator based on the idea of a complete probability\nformula is given for queueing systems with a single server and discontinuous\nintensities of arrivals and serving. \n\n"}
{"id": "1306.2872", "contents": "Title: Hanson-Wright inequality and sub-gaussian concentration Abstract: In this expository note, we give a modern proof of Hanson-Wright inequality\nfor quadratic forms in sub-gaussian random variables. We deduce a useful\nconcentration inequality for sub-gaussian random vectors. Two examples are\ngiven to illustrate these results: a concentration of distances between random\nvectors and subspaces, and a bound on the norms of products of random and\ndeterministic matrices. \n\n"}
{"id": "1306.3449", "contents": "Title: A general smoothing inequality for disordered polymers Abstract: This note sharpens the smoothing inequality of Giacomin and Toninelli for\ndisordered polymers. This inequality is shown to be valid for any disorder\ndistribution with locally finite exponential moments, and to provide an\nasymptotically sharp constant for weak disorder. A key tool in the proof is an\nestimate that compares the effect on the free energy of tilting, respectively,\nshifting the disorder distribution. This estimate holds in large generality\n(way beyond disordered polymers) and is of independent interest. \n\n"}
{"id": "1306.4529", "contents": "Title: Conditional Least Squares and Copulae in Claims Reserving for a Single\n  Line of Business Abstract: One of the main goals in non-life insurance is to estimate the claims reserve\ndistribution. A generalized time series model, that allows for modeling the\nconditional mean and variance of the claim amounts, is proposed for the claims\ndevelopment. On contrary to the classical stochastic reserving techniques, the\nnumber of model parameters does not depend on the number of development\nperiods, which leads to a more precise forecasting.\n  Moreover, the time series innovations for the consecutive claims are not\nconsidered to be independent anymore. Conditional least squares are used for\nmodel parameter estimation and consistency of such estimate is proved. Copula\napproach is used for modeling the dependence structure, which improves the\nprecision of the reserve distribution estimate as well.\n  Real data examples are provided as an illustration of the potential benefits\nof the presented approach. \n\n"}
{"id": "1307.0612", "contents": "Title: Cyclic behavior of maxima for sums of independent variables Abstract: In a recent author's work the cyclic behavior of maxima in a hierarchical\nsummation scheme was discovered. In the present note we show how the same\nphenomenon appears in the scheme of conventional summation: the distribution of\nmaximum of $2^n$ independent copies of a sum of $n$ i.i.d. random variables\napproaches, as $n$ grows, some helix in the space of distributions. \n\n"}
{"id": "1307.1164", "contents": "Title: Statistical Inference for Stochastic Differential Equations with Memory Abstract: In this paper we construct a framework for doing statistical inference for\ndiscretely observed stochastic differential equations (SDEs) where the driving\nnoise has 'memory'. Classical SDE models for inference assume the driving noise\nto be Brownian motion, or \"white noise\", thus implying a Markov assumption. We\nfocus on the case when the driving noise is a fractional Brownian motion, which\nis a common continuous-time modeling device for capturing long-range memory.\nSince the likelihood is intractable, we proceed via data augmentation, adapting\na familiar discretization and missing data approach developed for the white\nnoise case. In addition to the other SDE parameters, we take the Hurst index to\nbe unknown and estimate it from the data. Posterior sampling is performed via a\nHybrid Monte Carlo algorithm on both the parameters and the missing data\nsimultaneously so as to improve mixing. We point out that, due to the\nlong-range correlations of the driving noise, careful discretization of the\nunderlying SDE is necessary for valid inference. Our approach can be adapted to\nother types of rough-path driving processes such as Gaussian \"colored\" noise.\nThe methodology is used to estimate the evolution of the memory parameter in US\nshort-term interest rates. \n\n"}
{"id": "1307.3000", "contents": "Title: Occupancy distributions arising in sampling from Gibbs-Poisson abundance\n  models Abstract: Estimating the number $n$ of unseen species from a $k-$sample displaying only\n$p\\leq k$ distinct sampled species has received attention for long. It requires\na model of species abundance together with a sampling model. We start with a\ndiscrete model of iid stochastic species abundances, each with Gibbs-Poisson\ndistribution. A $k-$sample drawn from the $n-$species abundances vector is the\none obtained while conditioning it on summing to $k$% . We discuss the sampling\nformulae (species occupancy distributions, frequency of frequencies) in this\ncontext. We then develop some aspects of the estimation of $n$ problem from the\nsize $k$ of the sample and the observed value of $P_{n,k}$, the number of\ndistinct sampled species. It is shown that it always makes sense to study these\noccupancy problems from a Gibbs-Poisson abundance model in the context of a\npopulation with infinitely many species. From this extension, a parameter\n$\\gamma $ naturally appears, which is a measure of richness or diversity of\nspecies. We rederive the sampling formulae for a population with infinitely\nmany species, together with the distribution of the number $P_{k}$ of distinct\nsampled species. We investigate the estimation of $\\gamma $ problem from the\nsample size $k$ and the observed value of $P_{k}$. We then exhibit a large\nspecial class of Gibbs-Poisson distributions having the property that sampling\nfrom a discrete abundance model may equivalently be viewed as a sampling\nproblem from a random partition of unity, now in the continuum. When $n$ is\nfinite, this partition may be built upon normalizing $% n$ infinitely divisible\niid positive random variables by its partial sum. It is shown that the sampling\nprocess in the continuum should generically be biased on the total length\nappearing in the latter normalization. A construction with size-biased sampling\nfrom the ranked normalized jumps of a subordinator is also supplied, would the\nproblem under study present infinitely many species. We illustrate our point of\nview with many examples, some of which being new ones. \n\n"}
{"id": "1307.4313", "contents": "Title: Coalescing Brownian flows: A new approach Abstract: The coalescing Brownian flow on $\\mathbb{R}$ is a process which was\nintroduced by Arratia [Coalescing Brownian motions on the line (1979) Univ.\nWisconsin, Madison] and T\\'{o}th and Werner [Probab. Theory Related Fields 111\n(1998) 375-452], and which formally corresponds to starting coalescing Brownian\nmotions from every space-time point. We provide a new state space and topology\nfor this process and obtain an invariance principle for coalescing random\nwalks. This result holds under a finite variance assumption and is thus\noptimal. In previous works by Fontes et al. [Ann. Probab. 32 (2004) 2857-2883],\nNewman et al. [Electron. J. Probab. 10 (2005) 21-60], the topology and\nstate-space required a moment of order $3-\\varepsilon$ for this convergence to\nhold. The proof relies crucially on recent work of Schramm and Smirnov on\nscaling limits of critical percolation in the plane. Our approach is\nsufficiently simple that we can handle substantially more complicated\ncoalescing flows with little extra work - in particular similar results are\nobtained in the case of coalescing Brownian motions on the Sierpinski gasket.\nThis is the first such result where the limiting paths do not enjoy the\nnoncrossing property. \n\n"}
{"id": "1307.5399", "contents": "Title: Density estimates for differential equations of second order satisfying\n  a weak Hoermander condition Abstract: We prove an extension of Hoermander's classical result on hypoelliptic second\norder equations, where the coefficients of the related vector fields are\nglobally Lipschitz and satisfy the classical Hoermander condition on a dense\nset while the density still exists in a classical sense. Furthermore,\nHoermander's classical result and related density estimates based on Malliavin\ncalculus are recovered from an analytical point of view. \n\n"}
{"id": "1307.7721", "contents": "Title: Geodesic PCA in the Wasserstein space Abstract: We introduce the method of Geodesic Principal Component Analysis (GPCA) on\nthe space of probability measures on the line, with finite second moment,\nendowed with the Wasserstein metric. We discuss the advantages of this\napproach, over a standard functional PCA of probability densities in the\nHilbert space of square-integrable functions. We establish the consistency of\nthe method by showing that the empirical GPCA converges to its population\ncounterpart, as the sample size tends to infinity. A key property in the study\nof GPCA is the isometry between the Wasserstein space and a closed convex\nsubset of the space of square-integrable functions, with respect to an\nappropriate measure. Therefore, we consider the general problem of PCA in a\nclosed convex subset of a separable Hilbert space, which serves as basis for\nthe analysis of GPCA and also has interest in its own right. We provide\nillustrative examples on simple statistical models, to show the benefits of\nthis approach for data analysis. The method is also applied to a real dataset\nof population pyramids. \n\n"}
{"id": "1308.1070", "contents": "Title: On the average of the Airy process and its time reversal Abstract: We show that the supremum of the average of the Airy process and its time\nreversal minus a parabola is distributed as the maximum of two independent GUE\nTracy-Widom random variables. The proof is obtained by considering a directed\nlast passage percolation model with a rotational symmetry in two different\nways. We also review other known identities between the Airy process and the\nTracy-Widom distributions. \n\n"}
{"id": "1308.2403", "contents": "Title: CDfdr: A Comparison Density Approach to Local False Discovery Rate\n  Estimation Abstract: Efron et al. (2001) proposed empirical Bayes formulation of the frequentist\nBenjamini and Hochbergs False Discovery Rate method (Benjamini and\nHochberg,1995). This article attempts to unify the `two cultures' using\nconcepts of comparison density and distribution function. We have also shown\nhow almost all of the existing local fdr methods can be viewed as proposing\nvarious model specification for comparison density - unifies the vast\nliterature of false discovery methods under one concept and notation. \n\n"}
{"id": "1308.2748", "contents": "Title: Multivalued backward doubly stochastic differential equations with time\n  delayed coefficients Abstract: In this paper, we deal with a class of multivalued backward doubly stochastic\ndifferential equations with time delayed coefficients. Based on a slight\nextension of the existence and uniqueness of solutions for backward doubly\nstochastic differential equations with time delayed coefficients, we establish\nthe existence and uniqueness of solutions for these equations by means of\nYosida approximation. \n\n"}
{"id": "1308.3475", "contents": "Title: Spectral theory for the q-Boson particle system Abstract: We develop spectral theory for the generator of the q-Boson (stochastic)\nparticle system. Our central result is a Plancherel type isomorphism theorem\nfor this system. This theorem has various implications. It proves the\ncompleteness of the Bethe ansatz for the q-Boson generator and consequently\nenables us to solve the Kolmogorov forward and backward equations for general\ninitial data. Owing to a Markov duality with q-TASEP, this leads to moment\nformulas which characterize the fixed time distribution of q-TASEP started from\ngeneral initial conditions. The theorem also implies the biorthogonality of the\nleft and right eigenfunctions.\n  We consider limits of our q-Boson results to a discrete delta Bose gas\nconsidered previously by van Diejen, as well as to another discrete delta Bose\ngas that describes the evolution of moments of the semi-discrete stochastic\nheat equation (or equivalently, the O'Connell-Yor semi-discrete directed\npolymer partition function). A further limit takes us to the delta Bose gas\nwhich arises in studying moments of the stochastic heat equation /\nKardar-Parisi-Zhang equation. \n\n"}
{"id": "1308.3600", "contents": "Title: Random Walks on Directed Networks: Inference and Respondent-driven\n  Sampling Abstract: Respondent driven sampling (RDS) is a method often used to estimate\npopulation properties (e.g. sexual risk behavior) in hard-to-reach populations.\nIt combines an effective modified snowball sampling methodology with an\nestimation procedure that yields unbiased population estimates under the\nassumption that the sampling process behaves like a random walk on the social\nnetwork of the population. Current RDS estimation methodology assumes that the\nsocial network is undirected, i.e. that all edges are reciprocal. However,\nempirical social networks in general also have non-reciprocated edges. To\naccount for this fact, we develop a new estimation method for RDS in the\npresence of directed edges on the basis of random walks on directed networks.\nWe distinguish directed and undirected edges and consider the possibility that\nthe random walk returns to its current position in two steps through an\nundirected edge. We derive estimators of the selection probabilities of\nindividuals as a function of the number of outgoing edges of sampled\nindividuals. We evaluate the performance of the proposed estimators on\nartificial and empirical networks to show that they generally perform better\nthan existing methods. This is in particular the case when the fraction of\ndirected edges in the network is large. \n\n"}
{"id": "1308.4747", "contents": "Title: Joint modeling of multiple time series via the beta process with\n  application to motion capture segmentation Abstract: We propose a Bayesian nonparametric approach to the problem of jointly\nmodeling multiple related time series. Our model discovers a latent set of\ndynamical behaviors shared among the sequences, and segments each time series\ninto regions defined by a subset of these behaviors. Using a beta process\nprior, the size of the behavior set and the sharing pattern are both inferred\nfrom data. We develop Markov chain Monte Carlo (MCMC) methods based on the\nIndian buffet process representation of the predictive distribution of the beta\nprocess. Our MCMC inference algorithm efficiently adds and removes behaviors\nvia novel split-merge moves as well as data-driven birth and death proposals,\navoiding the need to consider a truncated model. We demonstrate promising\nresults on unsupervised segmentation of human motion capture data. \n\n"}
{"id": "1308.5152", "contents": "Title: Computation of ruin probabilities for general discrete-time Markov\n  models Abstract: We study the ruin problem over a risk process described by a discrete-time\nMarkov model. In contrast to previous studies that focused on the asymptotic\nbehaviour of ruin probabilities for large values of the initial capital, we\nprovide a new technique to compute the quantity of interest for any initial\nvalue, and with any given precision. Rather than focusing on a particular model\nfor risk processes, we give a general characterization of the ruin probability\nby providing corresponding recursions and fixpoint equations. Since such\nequations for the ruin probability are ill-posed in the sense that they do not\nallow for unique solutions, we approximate the ruin probability by a\ntwo-barrier ruin probability, for which fixpoint equations are well-posed. We\nalso show how good the introduced approximation is by providing an explicit\nbound on the error and by characterizing the cases when the error converges to\nzero. The presented technique and results are supported by two computational\nexamples over models known in the literature, one of which is extremely\nheavy-tailed. \n\n"}
{"id": "1309.0461", "contents": "Title: A Non-Markovian Liquidation Problem and Backward SPDEs with Singular\n  Terminal Conditions Abstract: We establish existence, uniqueness and regularity of solution results for a\nclass of backward stochastic partial differential equations with singular\nterminal condition. The equation describes the value function of non-Markovian\nstochastic optimal control problem in which the terminal state of the\ncontrolled process is pre-specified. The analysis of such control problems is\nmotivated by models of optimal portfolio liquidation. \n\n"}
{"id": "1309.0837", "contents": "Title: Bayesian Model Selection in Complex Linear Systems, as Illustrated in\n  Genetic Association Studies Abstract: Motivated by examples from genetic association studies, this paper considers\nthe model selection problem in a general complex linear model system and in a\nBayesian framework. We discuss formulating model selection problems and\nincorporating context-dependent {\\it a priori} information through different\nlevels of prior specifications. We also derive analytic Bayes factors and their\napproximations to facilitate model selection and discuss their theoretical and\ncomputational properties. We demonstrate our Bayesian approach based on an\nimplemented Markov Chain Monte Carlo (MCMC) algorithm in simulations and a real\ndata application of mapping tissue-specific eQTLs. Our novel results on Bayes\nfactors provide a general framework to perform efficient model comparisons in\ncomplex linear model systems. \n\n"}
{"id": "1309.1007", "contents": "Title: Concentration in unbounded metric spaces and algorithmic stability Abstract: We prove an extension of McDiarmid's inequality for metric spaces with\nunbounded diameter. To this end, we introduce the notion of the {\\em\nsubgaussian diameter}, which is a distribution-dependent refinement of the\nmetric diameter. Our technique provides an alternative approach to that of\nKutin and Niyogi's method of weakly difference-bounded functions, and yields\nnontrivial, dimension-free results in some interesting cases where the former\ndoes not. As an application, we give apparently the first generalization bound\nin the algorithmic stability setting that holds for unbounded loss functions.\nWe furthermore extend our concentration inequality to strongly mixing\nprocesses. \n\n"}
{"id": "1309.1586", "contents": "Title: Stuck walks: A conjecture of Erschler, T\\'oth and Werner Abstract: In this paper, we work on a class of self-interacting nearest neighbor random\nwalks, introduced in [Probab. Theory Related Fields 154 (2012) 149-163], for\nwhich there is competition between repulsion of neighboring edges and\nattraction of next-to-neighboring edges. Erschler, T\\'{o}th and Werner proved\nin [Probab. Theory Related Fields 154 (2012) 149-163] that, for any $L\\ge1$, if\nthe parameter $\\alpha$ belongs to a certain interval $(\\alpha_{L+1},\\alpha_L)$,\nthen such random walks localize on $L+2$ sites with positive probability. They\nalso conjectured that this is the almost sure behavior. We prove this\nconjecture partially, stating that the walk localizes on $L+2$ or $L+3$ sites\nalmost surely, under the same assumptions. We also prove that, if\n$\\alpha\\in(1,+\\infty)=(\\alpha_2,\\alpha_1)$, then the walk localizes a.s. on $3$\nsites. \n\n"}
{"id": "1309.1901", "contents": "Title: Variational Bayes Approximations for Clustering via Mixtures of Normal\n  Inverse Gaussian Distributions Abstract: Parameter estimation for model-based clustering using a finite mixture of\nnormal inverse Gaussian (NIG) distributions is achieved through variational\nBayes approximations. Univariate NIG mixtures and multivariate NIG mixtures are\nconsidered. The use of variational Bayes approximations here is a substantial\ndeparture from the traditional EM approach and alleviates some of the\nassociated computational complexities and uncertainties. Our variational\nalgorithm is applied to simulated and real data. The paper concludes with\ndiscussion and suggestions for future work. \n\n"}
{"id": "1309.3459", "contents": "Title: The Stochastic Properties of $\\ell^1$-Regularized Spherical Gaussian\n  Fields Abstract: Convex regularization techniques are now widespread tools for solving inverse\nproblems in a variety of different frameworks. In some cases, the functions to\nbe reconstructed are naturally viewed as realizations from random processes; an\nimportant question is thus whether such regularization techniques preserve the\nproperties of the underlying probability measures. We focus here on a case\nwhich has produced a very lively debate in the cosmological literature, namely\nGaussian and isotropic spherical random fields, and we prove that Gaussianity\nand isotropy are not conserved in general under convex regularization over a\nFourier dictionary, such as the orthonormal system of spherical harmonics. \n\n"}
{"id": "1309.3489", "contents": "Title: Group-bound: confidence intervals for groups of variables in sparse\n  high-dimensional regression without assumptions on the design Abstract: It is in general challenging to provide confidence intervals for individual\nvariables in high-dimensional regression without making strict or unverifiable\nassumptions on the design matrix. We show here that a \"group-bound\" confidence\ninterval can be derived without making any assumptions on the design matrix.\nThe lower bound for the regression coefficient of individual variables can be\nderived via linear programming. The idea also generalises naturally to groups\nof variables, where we can derive a one-sided confidence interval for the joint\neffect of a group. While the confidence intervals of individual variables are\nby the nature of the problem often very wide, it is shown to be possible to\ndetect the contribution of groups of highly correlated predictor variables even\nwhen no variable individually shows a significant effect. The assumptions\nnecessary to detect the effect of groups of variables are shown to be weaker\nthan the weakest known assumptions to detect the effect of individual\nvariables. \n\n"}
{"id": "1309.4344", "contents": "Title: On Stein's method for products of normal random variables and zero bias\n  couplings Abstract: In this paper we extend Stein's method to the distribution of the product of\n$n$ independent mean zero normal random variables. A Stein equation is obtained\nfor this class of distributions, which reduces to the classical normal Stein\nequation in the case $n=1$. This Stein equation motivates a generalisation of\nthe zero bias transformation. We establish properties of this new\ntransformation, and illustrate how they may be used together with the Stein\nequation to assess distributional distances for statistics that are\nasymptotically distributed as the product of independent central normal random\nvariables. We end by proving some product normal approximation theorems. \n\n"}
{"id": "1309.4623", "contents": "Title: Supermartingales as Radon-Nikodym densities and related measure\n  extensions Abstract: Certain countably and finitely additive measures can be associated to a given\nnonnegative supermartingale. Under weak assumptions on the underlying\nprobability space, existence and (non)uniqueness results for such measures are\nproven. \n\n"}
{"id": "1309.4981", "contents": "Title: Extremes and first passage times of correlated fBm's Abstract: Let $\\{X_i(t),t\\ge0\\}, i=1,2$ be two standard fractional Brownian motions\nbeing jointly Gaussian with constant cross-correlation. In this paper we derive\nthe exact asymptotics of the joint survival function $$\n\\mathbb{P}\\{\\sup_{s\\in[0,1]}X_1(s)>u,\\ \\sup_{t\\in[0,1]}X_2(t)>u\\} $$ as\n$u\\rightarrow \\infty$. A novel finding of this contribution is the exponential\napproximation of the joint conditional first passage times of $X_1, X_2$. As a\nby-product we obtain generalizations of the Borell-TIS inequality and the\nPiterbarg inequality for 2-dimensional Gaussian random fields. \n\n"}
{"id": "1309.5050", "contents": "Title: Multivariate and 2D Extensions of Singular Spectrum Analysis with the\n  Rssa Package Abstract: Implementation of multivariate and 2D extensions of Singular Spectrum\nAnalysis (SSA) by means of the R-package Rssa is considered. The extensions\ninclude MSSA for simultaneous analysis and forecasting of several time series\nand 2D-SSA for analysis of digital images. A new extension of 2D-SSA analysis\ncalled Shaped 2D-SSA is introduced for analysis of images of arbitrary shape,\nnot necessary rectangular. It is shown that implementation of Shaped 2D-SSA can\nserve as a base for implementation of MSSA and other generalizations. Efficient\nimplementation of operations with Hankel and Hankel-block-Hankel matrices\nthrough FFT is suggested. Examples with code fragments in R, which explain the\nmethodology and demonstrate the proper use of Rssa, are presented. \n\n"}
{"id": "1309.5107", "contents": "Title: The Altshuler-Shklovskii Formulas for Random Band Matrices II: the\n  General Case Abstract: The Altshuler-Shklovskii formulas [1] predict, for any disordered quantum\nsystem in the diffusive regime, a universal power law behaviour for the\ncorrelation functions of the mesoscopic eigenvalue density. In this paper and\nits companion [2], we prove these formulas for random band matrices. In [2] we\nintroduced a diagrammatic approach and presented robust estimates on general\ndiagrams under certain simplifying assumptions. In this paper we remove these\nassumptions by giving a general estimate of the subleading diagrams. We also\ngive a precise analysis of the leading diagrams which give rise to the\nAltschuler-Shklovskii power laws. Moreover, we introduce a family of general\nrandom band matrices which interpolates between real symmetric $(\\beta=1)$ and\ncomplex Hermitian $(\\beta=2)$ models, and track the transition for the\nmesoscopic density-density correlation. Finally, we address the higher-order\ncorrelation functions by proving that they behave asymptotically according to a\nGaussian process whose covariance is given by the Altshuler-Shklovskii\nformulas. \n\n"}
{"id": "1309.5923", "contents": "Title: Asymptotically Normal and Efficient Estimation of Covariate-Adjusted\n  Gaussian Graphical Model Abstract: A tuning-free procedure is proposed to estimate the covariate-adjusted\nGaussian graphical model. For each finite subgraph, this estimator is\nasymptotically normal and efficient. As a consequence, a confidence interval\ncan be obtained for each edge. The procedure enjoys easy implementation and\nefficient computation through parallel estimation on subgraphs or edges. We\nfurther apply the asymptotic normality result to perform support recovery\nthrough edge-wise adaptive thresholding. This support recovery procedure is\ncalled ANTAC, standing for Asymptotically Normal estimation with Thresholding\nafter Adjusting Covariates. ANTAC outperforms other methodologies in the\nliterature in a range of simulation studies. We apply ANTAC to identify\ngene-gene interactions using an eQTL dataset. Our result achieves better\ninterpretability and accuracy in comparison with CAMPE. \n\n"}
{"id": "1309.6473", "contents": "Title: On nonnegative unbiased estimators Abstract: We study the existence of algorithms generating almost surely nonnegative\nunbiased estimators. We show that given a nonconstant real-valued function $f$\nand a sequence of unbiased estimators of $\\lambda\\in\\mathbb{R}$, there is no\nalgorithm yielding almost surely nonnegative unbiased estimators of\n$f(\\lambda)\\in\\mathbb{R}^+$. The study is motivated by pseudo-marginal Monte\nCarlo algorithms that rely on such nonnegative unbiased estimators. These\nmethods allow \"exact inference\" in intractable models, in the sense that\nintegrals with respect to a target distribution can be estimated without any\nsystematic error, even though the associated probability density function\ncannot be evaluated pointwise. We discuss the consequences of our results on\nthe applicability of pseudo-marginal algorithms and thus on the possibility of\nexact inference in intractable models. We illustrate our study with particular\nchoices of functions $f$ corresponding to known challenges in statistics, such\nas exact simulation of diffusions, inference in large datasets and doubly\nintractable distributions. \n\n"}
{"id": "1310.0800", "contents": "Title: Efficient simulation of the Ginibre point process Abstract: The Ginibre point process is one of the main examples of deter- minantal\npoint processes on the complex plane. It forms a recurring model in stochastic\nmatrix theory as well as in pratical applications. However, this model has\nmostly been studied from a probabilistic point of view in the fields of\nstochastic matrices and determinantal point processes, and thus using the\nGinibre process to model random phenomena is a topic which is for the most part\nunexplored. In order to obtain a determinantal point process more suited for\nsimulation, we introduce a modified version of the classical kernel. Then, we\ncompare three different methods to simulate the Ginibre point process and\ndiscuss the most efficient one depending on the application at hand. \n\n"}
{"id": "1310.1173", "contents": "Title: Weak approximation of second-order BSDEs Abstract: We study the weak approximation of the second-order backward SDEs (2BSDEs),\nwhen the continuous driving martingales are approximated by discrete time\nmartingales. We establish a convergence result for a class of 2BSDEs, using\nboth robustness properties of BSDEs, as proved in Briand, Delyon and M\\'{e}min\n[Stochastic Process. Appl. 97 (2002) 229-253], and tightness of solutions to\ndiscrete time BSDEs. In particular, when the approximating martingales are\ngiven by some particular controlled Markov chains, we obtain several concrete\nnumerical schemes for 2BSDEs, which we illustrate on specific examples. \n\n"}
{"id": "1310.5957", "contents": "Title: Entropy region and convolution Abstract: The entropy region is constructed from vectors of random variables by\ncollecting Shannon entropies of all subvectors. Its shape is studied here by\nmeans of polymatroidal constructions, notably by convolution. The closure of\nthe region is decomposed into the direct sum of tight and modular parts,\nreducing the study to the tight part. The relative interior of the reduction\nbelongs to the entropy region. Behavior of the decomposition under\nselfadhesivity is clarified. Results are specialized to and completed for the\nregion of four random variables. This and computer experiments help to\nvisualize approximations of a symmetrized part of the entropy region. Four-atom\nconjecture on the minimization of Ingleton score is refuted. \n\n"}
{"id": "1310.6391", "contents": "Title: Robust bounds on risk-sensitive functionals via Renyi divergence Abstract: We extend the duality between exponential integrals and relative entropy to a\nvariational formula for exponential integrals involving the Renyi divergence.\nThis formula characterizes the dependence of risk-sensitive functionals and\nrelated quantities determined by tail behavior to perturbations in the\nunderlying distributions, in terms of the Renyi divergence. The\ncharacterization gives rise to upper and lower bounds that are meaningful for\nall values of a large deviation scaling parameter, allowing one to quantify in\nexplicit terms the robustness of risk-sensitive costs. As applications we\nconsider problems of uncertainty quantification when aspects of the model are\nnot fully known, as well their use in bounding tail properties of an\nintractable model in terms of a tractable one. \n\n"}
{"id": "1310.6943", "contents": "Title: Dual and backward SDE representation for optimal control of\n  non-Markovian SDEs Abstract: We study optimal stochastic control problem for non-Markovian stochastic\ndifferential equations (SDEs) where the drift, diffusion coefficients, and gain\nfunctionals are path-dependent, and importantly we do not make any ellipticity\nassumption on the SDE. We develop a controls randomization approach, and prove\nthat the value function can be reformulated under a family of dominated\nmeasures on an enlarged filtered probability space. This value function is then\ncharacterized by a backward SDE with nonpositive jumps under a single\nprobability measure, which can be viewed as a path-dependent version of the\nHamilton-Jacobi-Bellman equation, and an extension to $G$ expectation. \n\n"}
{"id": "1310.7857", "contents": "Title: Sticky continuous processes have consistent price systems Abstract: Under proportional transaction costs, a price process is said to have a\nconsistent price system, if there is a semimartingale with an equivalent\nmartingale measure that evolves within the bid-ask spread. We show that a\ncontinuous, multi-asset price process has a consistent price system, under\narbitrarily small proportional transaction costs, if it satisfies a natural\nmulti-dimensional generalization of the stickiness condition introduced by\nGuasoni [Math. Finance 16(3), 569-582 (2006)]. \n\n"}
{"id": "1310.8013", "contents": "Title: Universal aspects of curved, flat & stationary-state Kardar-Parisi-Zhang\n  statistics Abstract: Motivated by the recent exact solution of the {\\it stationary-state}\nKardar-Parisi-Zhang (KPZ) statistics by Imamura & Sasamoto (Phys. Rev. Lett.\n{\\bf 108}, 190603 (2012)), as well as a precursor experimental signature\nunearthed by Takeuchi (Phys. Rev. Lett. {\\bf 110}, 210604 (2013)), we establish\nhere the universality of these phenomena, examining scaling behaviors of\ndirected polymers in a random medium, the stochastic heat equation with\nmultiplicative noise, and kinetically roughened KPZ growth models. We emphasize\nthe value of cross KPZ-Class universalities, revealing crossover effects of\nexperimental relevance. Finally, we illustrate the great utility of KPZ scaling\ntheory by an optimized numerical analysis of the Ulam problem of random\npermutations. \n\n"}
{"id": "1310.8147", "contents": "Title: Invariant measures via inverse limits of finite structures Abstract: Building on recent results regarding symmetric probabilistic constructions of\ncountable structures, we provide a method for constructing probability\nmeasures, concentrated on certain classes of countably infinite structures,\nthat are invariant under all permutations of the underlying set that fix all\nconstants. These measures are constructed from inverse limits of measures on\ncertain finite structures. We use this construction to obtain invariant\nprobability measures concentrated on the classes of countable models of certain\nfirst-order theories, including measures that do not assign positive measure to\nthe isomorphism class of any single model. We also characterize those\ntransitive Borel G-spaces admitting a G-invariant probability measure, when G\nis an arbitrary countable product of symmetric groups on a countable set. \n\n"}
{"id": "1311.1703", "contents": "Title: Projections of random covering sets Abstract: We show that, almost surely, the Hausdorff dimension $s_0$ of a random\ncovering set is preserved under all orthogonal projections to linear subspaces\nwith dimension $k>s_0$. The result holds for random covering sets with a\ngenerating sequence of ball-like sets, and is obtained by investigating\northogonal projections of a class of random Cantor sets. \n\n"}
{"id": "1311.3350", "contents": "Title: Sequential Tests of Multiple Hypotheses Controlling False Discovery and\n  Nondiscovery Rates Abstract: We propose a general and flexible procedure for testing multiple hypotheses\nabout sequential (or streaming) data that simultaneously controls both the\nfalse discovery rate (FDR) and false nondiscovery rate (FNR) under minimal\nassumptions about the data streams which may differ in distribution, dimension,\nand be dependent. All that is needed is a test statistic for each data stream\nthat controls the conventional type I and II error probabilities, and no\ninformation or assumptions are required about the joint distribution of the\nstatistics or data streams. The procedure can be used with sequential, group\nsequential, truncated, or other sampling schemes. The procedure is a natural\nextension of Benjamini and Hochberg's (1995) widely-used fixed sample size\nprocedure to the domain of sequential data, with the added benefit of\nsimultaneous FDR and FNR control that sequential sampling affords. We prove the\nprocedure's error control and give some tips for implementation in commonly\nencountered testing situations. \n\n"}
{"id": "1311.4175", "contents": "Title: Regularized estimation in sparse high-dimensional time series models Abstract: Many scientific and economic problems involve the analysis of\nhigh-dimensional time series datasets. However, theoretical studies in\nhigh-dimensional statistics to date rely primarily on the assumption of\nindependent and identically distributed (i.i.d.) samples. In this work, we\nfocus on stable Gaussian processes and investigate the theoretical properties\nof $\\ell _1$-regularized estimates in two important statistical problems in the\ncontext of high-dimensional time series: (a) stochastic regression with\nserially correlated errors and (b) transition matrix estimation in vector\nautoregressive (VAR) models. We derive nonasymptotic upper bounds on the\nestimation errors of the regularized estimates and establish that consistent\nestimation under high-dimensional scaling is possible via\n$\\ell_1$-regularization for a large class of stable processes under sparsity\nconstraints. A key technical contribution of the work is to introduce a measure\nof stability for stationary processes using their spectral properties that\nprovides insight into the effect of dependence on the accuracy of the\nregularized estimates. With this proposed stability measure, we establish some\nuseful deviation bounds for dependent data, which can be used to study several\nimportant regularized estimates in a time series setting. \n\n"}
{"id": "1311.6238", "contents": "Title: Exact post-selection inference, with application to the lasso Abstract: We develop a general approach to valid inference after model selection. At\nthe core of our framework is a result that characterizes the distribution of a\npost-selection estimator conditioned on the selection event. We specialize the\napproach to model selection by the lasso to form valid confidence intervals for\nthe selected coefficients and test whether all relevant variables have been\nincluded in the model. \n\n"}
{"id": "1311.6311", "contents": "Title: Bias in parametric estimation: reduction and useful side-effects Abstract: The bias of an estimator is defined as the difference of its expected value\nfrom the parameter to be estimated, where the expectation is with respect to\nthe model. Loosely speaking, small bias reflects the desire that if an\nexperiment is repeated indefinitely then the average of all the resultant\nestimates will be close to the parameter value that is estimated. The current\npaper is a review of the still-expanding repository of methods that have been\ndeveloped to reduce bias in the estimation of parametric models. The review\nprovides a unifying framework where all those methods are seen as attempts to\napproximate the solution of a simple estimating equation. Of particular focus\nis the maximum likelihood estimator, which despite being asymptotically\nunbiased under the usual regularity conditions, has finite-sample bias that can\nresult in significant loss of performance of standard inferential procedures.\nAn informal comparison of the methods is made revealing some useful practical\nside-effects in the estimation of popular models in practice including: i)\nshrinkage of the estimators in binomial and multinomial regression models that\nguarantees finiteness even in cases of data separation where the maximum\nlikelihood estimator is infinite, and ii) inferential benefits for models that\nrequire the estimation of dispersion or precision parameters. \n\n"}
{"id": "1311.7455", "contents": "Title: Semi-Penalized Inference with Direct False Discovery Rate Control in\n  High-Dimensions Abstract: We propose a new method, semi-penalized inference with direct false discovery\nrate control (SPIDR), for variable selection and confidence interval\nconstruction in high-dimensional linear regression. SPIDR first uses a\nsemi-penalized approach to constructing estimators of the regression\ncoefficients. We show that the SPIDR estimator is ideal in the sense that it\nequals an ideal least squares estimator with high probability under a sparsity\nand other suitable conditions. Consequently, the SPIDR estimator is\nasymptotically normal. Based on this distributional result, SPIDR determines\nthe selection rule by directly controlling false discovery rate. This provides\nan explicit assessment of the selection error. This also naturally leads to\nconfidence intervals for the selected coefficients with a proper confidence\nstatement. We conduct simulation studies to evaluate its finite sample\nperformance and demonstrate its application on a breast cancer gene expression\ndata set. Our simulation studies and data example suggest that SPIDR is a\nuseful method for high-dimensional statistical inference in practice. \n\n"}
{"id": "1312.1324", "contents": "Title: KPZ relation does not hold for the level lines and the SLE$_\\kappa$ flow\n  lines of the Gaussian free field Abstract: In this paper we mingle the Gaussian free field, the Schramm-Loewner\nevolution and the KPZ relation in a natural way, shedding new light on all of\nthem. Our principal result shows that the level lines and the SLE$_\\kappa$ flow\nlines of the Gaussian free field do not satisfy the usual KPZ relation. In\norder to prove this, we have to make a technical detour: by a careful study of\na certain diffusion process, we provide exact estimates of the exponential\nmoments of winding of chordal SLE curves conditioned to pass nearby a fixed\npoint. This extends previous results on winding of SLE curves by Schramm. \n\n"}
{"id": "1312.2128", "contents": "Title: On the rate of convergence in Wasserstein distance of the empirical\n  measure Abstract: Let $\\mu_N$ be the empirical measure associated to a $N$-sample of a given\nprobability distribution $\\mu$ on $\\mathbb{R}^d$. We are interested in the rate\nof convergence of $\\mu_N$ to $\\mu$, when measured in the Wasserstein distance\nof order $p>0$. We provide some satisfying non-asymptotic $L^p$-bounds and\nconcentration inequalities, for any values of $p>0$ and $d\\geq 1$. We extend\nalso the non asymptotic $L^p$-bounds to stationary $\\rho$-mixing sequences,\nMarkov chains, and to some interacting particle systems. \n\n"}
{"id": "1312.2923", "contents": "Title: Lagrangian Time Series Models for Ocean Surface Drifter Trajectories Abstract: This paper proposes stochastic models for the analysis of ocean surface\ntrajectories obtained from freely-drifting satellite-tracked instruments. The\nproposed time series models are used to summarise large multivariate datasets\nand infer important physical parameters of inertial oscillations and other\nocean processes. Nonstationary time series methods are employed to account for\nthe spatiotemporal variability of each trajectory. Because the datasets are\nlarge, we construct computationally efficient methods through the use of\nfrequency-domain modelling and estimation, with the data expressed as\ncomplex-valued time series. We detail how practical issues related to sampling\nand model misspecification may be addressed using semi-parametric techniques\nfor time series, and we demonstrate the effectiveness of our stochastic models\nthrough application to both real-world data and to numerical model output. \n\n"}
{"id": "1312.6524", "contents": "Title: Bernoulli trials of fixed parity, random and randomly oriented graphs Abstract: Suppose you can color $n$ \\emph{biased} coins with $n$ colors, all coins\nhaving the same bias. It is forbidden to color both sides of a coin with the\nsame color, but all other colors are allowed. Let $X$ be the number of\ndifferent colors after a toss of the coins. We present a method to obtain an\nupper bound on a median of $X$. Our method is based on the analysis of the\nprobability distribution of the number of vertices with even in-degree in\ngraphs whose edges are given random orientations. Our analysis applies to the\ndistribution of the number of vertices with odd degree in random sub-graphs of\nfixed graphs. It turns out that there are parity restrictions on the random\nvariables that are under consideration. Hence, in order to present our result,\nwe introduce a class of Bernoulli random variables whose total number of\nsuccesses is of fixed parity and are closely related to Poisson trials\nconditional on the event that their outcomes have fixed parity. \n\n"}
{"id": "1401.0201", "contents": "Title: Sparse Recovery with Very Sparse Compressed Counting Abstract: Compressed sensing (sparse signal recovery) often encounters nonnegative data\n(e.g., images). Recently we developed the methodology of using (dense)\nCompressed Counting for recovering nonnegative K-sparse signals. In this paper,\nwe adopt very sparse Compressed Counting for nonnegative signal recovery. Our\ndesign matrix is sampled from a maximally-skewed p-stable distribution (0<p<1),\nand we sparsify the design matrix so that on average (1-g)-fraction of the\nentries become zero. The idea is related to very sparse stable random\nprojections (Li et al 2006 and Li 2007), the prior work for estimating summary\nstatistics of the data.\n  In our theoretical analysis, we show that, when p->0, it suffices to use M=\nK/(1-exp(-gK) log N measurements, so that all coordinates can be recovered in\none scan of the coordinates. If g = 1 (i.e., dense design), then M = K log N.\nIf g= 1/K or 2/K (i.e., very sparse design), then M = 1.58K log N or M = 1.16K\nlog N. This means the design matrix can be indeed very sparse at only a minor\ninflation of the sample complexity.\n  Interestingly, as p->1, the required number of measurements is essentially M\n= 2.7K log N, provided g= 1/K. It turns out that this result is a general\nworst-case bound. \n\n"}
{"id": "1401.1710", "contents": "Title: Expected values of eigenfunction periods Abstract: Let $(M,g)$ be a compact Riemannian surface. Consider a family of $L^2$\nnormalized Laplace-Beltrami eigenfunctions, written in the semiclassical form\n$-h_j^2\\Delta_g \\phi_{h_j} = \\phi_{h_j}$, whose eigenvalues satisfy $h h_j^{-1}\n\\in (1, 1 + hD]$ for $D>0$ a large enough constant. Let $\\mathbf{P}_h$ be a\nuniform probability measure on the $L^2$ unit-sphere $S_h$ of this cluster of\neigenfunctions and take $u \\in S_h$. Given a closed curve $\\gamma \\subset M$,\nthere exists $C_{1}(\\gamma, M), C_{2}(\\gamma, M) > 0$ and $h_0>0$ such that for\nall $h \\in (0, h_0],$ \\begin{equation*}\n  C_1 h^{1/2} \\leq \\mathbf{E}_{h} \\bigg[ \\big| \\int_{\\gamma} u \\, d \\sigma\n\\big| \\bigg] \\leq C_2 h^{1/2} . \\end{equation*} This result contrasts the\ndeterministic $\\mathcal{O}(1)$ upperbounds obtained by Chen-Sogge \\cite{CS},\nReznikov \\cite{Rez}, and Zelditch \\cite{Zel}. Furthermore, we treat the higher\ndimensional cases and compute large deviation estimates. Under a measure zero\nassumption on the periodic geodesics in $S^*M$, we can consider windows of\nsmall width $D=1$ and establish a $\\mathcal{O}(h^{1/2})$ estimate. Lastly, we\ntreat probabilistic $L^q$ restriction bounds along curves. \n\n"}
{"id": "1401.2678", "contents": "Title: Inference in High Dimensions with the Penalized Score Test Abstract: In recent years, there has been considerable theoretical development\nregarding variable selection consistency of penalized regression techniques,\nsuch as the lasso. However, there has been relatively little work on\nquantifying the uncertainty in these selection procedures. In this paper, we\npropose a new method for inference in high dimensions using a score test based\non penalized regression. In this test, we perform penalized regression of an\noutcome on all but a single feature, and test for correlation of the residuals\nwith the held-out feature. This procedure is applied to each feature in turn.\nInterestingly, when an $\\ell_1$ penalty is used, the sparsity pattern of the\nlasso corresponds exactly to a decision based on the proposed test. Further,\nwhen an $\\ell_2$ penalty is used, the test corresponds precisely to a score\ntest in a mixed effects model, in which the effects of all but one feature are\nassumed to be random. We formulate the hypothesis being tested as a compromise\nbetween the null hypotheses tested in simple linear regression on each feature\nand in multiple linear regression on all features, and develop reference\ndistributions for some well-known penalties. We also examine the behavior of\nthe test on real and simulated data. \n\n"}
{"id": "1401.4853", "contents": "Title: Intrinsic volumes of set of singular matrices Abstract: We explicitly compute the intrinsic volume of the set of real (and real\nsymmetric) matrices of Frobenius norm one and given corank (the case of\nmatrices with zero determinant as a special case). We give asymptotic formulas\nfor our computations and we discuss several examples and applications. \n\n"}
{"id": "1401.6255", "contents": "Title: Triple and Simultaneous Collisions of Competing Brownian Particles Abstract: Consider a finite system of competing Brownian particles on the real line.\nEach particle moves as a Brownian motion, with drift and diffusion coefficients\ndepending only on its current rank relative to the other particles. A triple\ncollision occurs if three particles are at the same position at the same\nmoment. A simultaneous collision occurs if at a certain moment, there are two\ndistinct pairs of particles such that in each pair, both particles occupy the\nsame position. These two pairs of particles can overlap, so a triple collision\nis a particular case of a simultaneous collision. We find a necessary and\nsufficient condition for a.s. absense of triple and simultaneous collisions,\ncontinuing the work of Ichiba, Karatzas, Shkolnikov (2013). Our results are\nalso valid for the case of asymmetric collisions, when the local time of\ncollision between the particles is split unevenly between them; these systems\nwere introduced in Karatzas, Pal, Shkolnikov (2012). \n\n"}
{"id": "1401.7577", "contents": "Title: Localization in random geometric graphs with too many edges Abstract: We consider a random geometric graph $G(\\chi_n, r_n)$, given by connecting\ntwo vertices of a Poisson point process $\\chi_n$ of intensity $n$ on the unit\ntorus whenever their distance is smaller than the parameter $r_n$. The model is\nconditioned on the rare event that the number of edges observed, $|E|$, is\ngreater than $(1 + \\delta)\\mathbb{E}(|E|)$, for some fixed $\\delta >0$. This\narticle proves that upon conditioning, with high probability there exists a\nball of diameter $r_n$ which contains a clique of at least $\\sqrt{2 \\delta\n\\mathbb{E}(|E|)}(1 - \\varepsilon)$ vertices, for any given $\\varepsilon >0$.\nIntuitively, this region contains all the \"excess\" edges the graph is forced to\ncontain by the conditioning event, up to lower order corrections. As a\nconsequence of this result, we prove a large deviations principle for the upper\ntail of the edge count of the random geometric graph. The rate function of this\nlarge deviation principle turns out to be non-convex. \n\n"}
{"id": "1402.0052", "contents": "Title: Performance of the Survey Propagation-guided decimation algorithm for\n  the random NAE-K-SAT problem Abstract: We show that the Survey Propagation-guided decimation algorithm fails to find\nsatisfying assignments on random instances of the \"Not-All-Equal-$K$-SAT\"\nproblem if the number of message passing iterations is bounded by a constant\nindependent of the size of the instance and the clause-to-variable ratio is\nabove $(1+o_K(1)){2^{K-1}\\over K}\\log^2 K$ for sufficiently large $K$. Our\nanalysis in fact applies to a broad class of algorithms described as\n\"sequential local algorithms\". Such algorithms iteratively set variables based\non some local information and then recurse on the reduced instance. Survey\nPropagation-guided as well as Belief Propagation-guided decimation algorithms -\ntwo widely studied message passing based algorithms, fall under this category\nof algorithms provided the number of message passing iterations is bounded by a\nconstant. Another well-known algorithm falling into this category is the Unit\nClause algorithm. Our work constitutes the first rigorous analysis of the\nperformance of the SP-guided decimation algorithm.\n  The approach underlying our paper is based on an intricate geometry of the\nsolution space of random NAE-$K$-SAT problem. We show that above the\n$(1+o_K(1)){2^{K-1}\\over K}\\log^2 K$ threshold, the overlap structure of\n$m$-tuples of satisfying assignments exhibit a certain clustering behavior\nexpressed in the form of constraints on distances between the $m$ assignments,\nfor appropriately chosen $m$. We further show that if a sequential local\nalgorithm succeeds in finding a satisfying assignment with probability bounded\naway from zero, then one can construct an $m$-tuple of solutions violating\nthese constraints, thus leading to a contradiction. Along with (citation), this\nresult is the first work which directly links the clustering property of random\nconstraint satisfaction problems to the computational hardness of finding\nsatisfying assignments. \n\n"}
{"id": "1402.1975", "contents": "Title: A note on general sliding window processes Abstract: Let $f:\\mathbb{R}^k\\to \\mathbb{R}$ be a measurable function, and let\n$\\{U_i\\}_{i\\in\\mathbb{N}}$ be a sequence of i.i.d. random variables. Consider\nthe random process $Z_i=f(U_{i},...,U_{i+k-1})$. We show that for all $\\ell$,\nthere is a positive probability, uniform in $f$, for $Z_1,...,Z_\\ell$ to be\nmonotone. We give upper and lower bounds for this probability, and draw\ncorollaries for $k$-block factor processes with a finite range.\n  The proof is based on an application of combinatorial results from Ramsey\ntheory to the realm of continuous probability. \n\n"}
{"id": "1402.3480", "contents": "Title: The spatial distribution in infinite dimensional spaces and related\n  quantiles and depths Abstract: The spatial distribution has been widely used to develop various\nnonparametric procedures for finite dimensional multivariate data. In this\npaper, we investigate the concept of spatial distribution for data in infinite\ndimensional Banach spaces. Many technical difficulties are encountered in such\nspaces that are primarily due to the noncompactness of the closed unit ball. In\nthis work, we prove some Glivenko-Cantelli and Donsker-type results for the\nempirical spatial distribution process in infinite dimensional spaces. The\nspatial quantiles in such spaces can be obtained by inverting the spatial\ndistribution function. A Bahadur-type asymptotic linear representation and the\nassociated weak convergence results for the sample spatial quantiles in\ninfinite dimensional spaces are derived. A study of the asymptotic efficiency\nof the sample spatial median relative to the sample mean is carried out for\nsome standard probability distributions in function spaces. The spatial\ndistribution can be used to define the spatial depth in infinite dimensional\nBanach spaces, and we study the asymptotic properties of the empirical spatial\ndepth in such spaces. We also demonstrate the spatial quantiles and the spatial\ndepth using some real and simulated functional data. \n\n"}
{"id": "1403.0408", "contents": "Title: On the Intersection Property of Conditional Independence and its\n  Application to Causal Discovery Abstract: This work investigates the intersection property of conditional independence.\nIt states that for random variables $A,B,C$ and $X$ we have that $X$\nindependent of $A$ given $B,C$ and $X$ independent of $B$ given $A,C$ implies\n$X$ independent of $(A,B)$ given $C$. Under the assumption that the joint\ndistribution has a continuous density, we provide necessary and sufficient\nconditions under which the intersection property holds. The result has direct\napplications to causal inference: it leads to strictly weaker conditions under\nwhich the graphical structure becomes identifiable from the joint distribution\nof an additive noise model. \n\n"}
{"id": "1403.0873", "contents": "Title: Matroid Regression Abstract: We propose an algebraic combinatorial method for solving large sparse linear\nsystems of equations locally - that is, a method which can compute single\nevaluations of the signal without computing the whole signal. The method scales\nonly in the sparsity of the system and not in its size, and allows to provide\nerror estimates for any solution method. At the heart of our approach is the\nso-called regression matroid, a combinatorial object associated to sparsity\npatterns, which allows to replace inversion of the large matrix with the\ninversion of a kernel matrix that is constant size. We show that our method\nprovides the best linear unbiased estimator (BLUE) for this setting and the\nminimum variance unbiased estimator (MVUE) under Gaussian noise assumptions,\nand furthermore we show that the size of the kernel matrix which is to be\ninverted can be traded off with accuracy. \n\n"}
{"id": "1403.0904", "contents": "Title: Ridge Estimation of Inverse Covariance Matrices from High-Dimensional\n  Data Abstract: We study ridge estimation of the precision matrix in the high-dimensional\nsetting where the number of variables is large relative to the sample size. We\nfirst review two archetypal ridge estimators and note that their utilized\npenalties do not coincide with common ridge penalties. Subsequently, starting\nfrom a common ridge penalty, analytic expressions are derived for two\nalternative ridge estimators of the precision matrix. The alternative\nestimators are compared to the archetypes with regard to eigenvalue shrinkage\nand risk. The alternatives are also compared to the graphical lasso within the\ncontext of graphical modeling. The comparisons may give reason to prefer the\nproposed alternative estimators. \n\n"}
{"id": "1403.4111", "contents": "Title: Representation of infinite dimensional forward price models in commodity\n  markets Abstract: We study the forward price dynamics in commodity markets realized as a\nprocess with values in a Hilbert space of absolutely continuous functions\ndefined by Filipovi\\'c. The forward dynamics are defined as the mild solution\nof a certain stochastic partial differential equation driven by an infinite\ndimensional L\\'evy process. It is shown that the associated spot price dynamics\ncan be expressed as a sum of Ornstein-Uhlenbeck processes, or more generally,\nas a sum of certain stationary processes. These results link the possibly\ninfinite dimensional forward dynamics to classical commodity spot models. We\ncontinue with a detailed analysis of multiplication and integral operators on\nthe Hilbert spaces and show that Hilbert-Schmidt operators are essentially\nintegral operators. The covariance operator of the L\\'evy process driving the\nforward dynamics and the diffusion term can both be specified in terms of such\noperators, and we analyse in several examples the consequences on model\ndynamics and their probabilistic properties. Also, we represent the forward\nprice for contracts delivering over a period in terms of an integral operator,\na case being relevant for power and gas markets. In several examples we reduce\nour general model to existing commodity spot and forward dynamics. \n\n"}
{"id": "1403.4689", "contents": "Title: Exponential Family Techniques for the Lognormal Left Tail Abstract: Let $X$ be lognormal$(\\mu,\\sigma^2)$ with density $f(x)$, let $\\theta>0$ and\ndefine ${L}(\\theta)=E e^{-\\theta X}$. We study properties of the exponentially\ntilted density (Esscher transform) $f_\\theta(x) =e^{-\\theta\nx}f(x)/{L}(\\theta)$, in particular its moments, its asymptotic form as\n$\\theta\\to\\infty$ and asymptotics for the Cram\\'er function; the asymptotic\nformulas involve the Lambert W function. This is used to provide two different\nnumerical methods for evaluating the left tail probability of lognormal sum\n$S_n=X_1+\\cdots+X_n$: a saddlepoint approximation and an exponential twisting\nimportance sampling estimator. For the latter we demonstrate the asymptotic\nconsistency by proving logarithmic efficiency in terms of the mean square\nerror. Numerical examples for the c.d.f.\\ $F_n(x)$ and the p.d.f.\\ $f_n(x)$ of\n$S_n$ are given in a range of values of $\\sigma^2,n,x$ motivated from portfolio\nValue-at-Risk calculations. \n\n"}
{"id": "1403.6187", "contents": "Title: Universal statistics of longest lasting records of random walks and\n  L\\'evy flights Abstract: We study the record statistics of random walks after $n$ steps, $x_0,\nx_1,\\ldots, x_n$, with arbitrary symmetric and continuous distribution\n$p(\\eta)$ of the jumps $\\eta_i = x_i - x_{i-1}$. We consider the age of the\nrecords, i.e. the time up to which a record survives. Depending on how the age\nof the current last record is defined, we propose three distinct sequences of\nages (indexed by $\\alpha$ = I, II, III) associated to a given sequence of\nrecords. We then focus on the longest lasting record, which is the longest\nelement among this sequence of ages. To characterize the statistics of these\nlongest lasting records, we compute: (i) the probability that the record of the\nlongest age is broken at step $n$, denoted by $Q^{\\alpha}(n)$, which we call\nthe probability of record breaking and: (ii) the duration of the longest\nlasting record, $\\ell_{\\max}^{\\alpha}(n)$. We show that both $Q^{\\alpha}(n)$\nand the full statistics of $\\ell_{\\max}^{\\alpha}(n)$ are universal, i.e.\nindependent of the jump distribution $p(\\eta)$. We compute exactly the large\n$n$ asymptotic behaviors of $Q^{\\alpha}(n)$ as well as $\\langle\n\\ell_{\\max}^{\\alpha}(n)\\rangle$ (when it exists) and show that each case gives\nrise to a different universal constant associated to random walks (including\nL\\'evy flights). While two of them appeared before in the excursion theory of\nBrownian motion, for which we provide here a simpler derivation, the third case\ngives rise to a non-trivial new constant $C^{\\rm III} = 0.241749 \\ldots$\nassociated to the records of random walks. Other observables characterizing the\nages of the records, exhibiting an interesting universal behavior, are also\ndiscussed. \n\n"}
{"id": "1403.6295", "contents": "Title: Asymptotic Properties of Minimum S-Divergence Estimator for Discrete\n  Models Abstract: Robust inference based on the minimization of statistical divergences has\nproved to be a useful alternative to the classical techniques based on maximum\nlikelihood and related methods. Recently Ghosh et al. (2013) proposed a general\nclass of divergence measures, namely the S-Divergence Family and discussed its\nusefulness in robust parametric estimation through some numerical\nillustrations. In this present paper, we develop the asymptotic properties of\nthe proposed minimum S-Divergence estimators under discrete models. \n\n"}
{"id": "1403.6573", "contents": "Title: Exact Inference for Gaussian Process Regression in case of Big Data with\n  the Cartesian Product Structure Abstract: Approximation algorithms are widely used in many engineering problems. To\nobtain a data set for approximation a factorial design of experiments is often\nused. In such case the size of the data set can be very large. Therefore, one\nof the most popular algorithms for approximation - Gaussian Process regression\n- can be hardly applied due to its computational complexity. In this paper a\nnew approach for Gaussian Process regression in case of factorial design of\nexperiments is proposed. It allows to efficiently compute exact inference and\nhandle large multidimensional data sets. The proposed algorithm provides fast\nand accurate approximation and also handles anisotropic data. \n\n"}
{"id": "1403.6602", "contents": "Title: Pivot Sampling in Dual-Pivot Quicksort Abstract: The new dual-pivot Quicksort by Vladimir Yaroslavskiy - used in Oracle's Java\nruntime library since version 7 - features intriguing asymmetries in its\nbehavior. They were shown to cause a basic variant of this algorithm to use\nless comparisons than classic single-pivot Quicksort implementations. In this\npaper, we extend the analysis to the case where the two pivots are chosen as\nfixed order statistics of a random sample and give the precise leading term of\nthe average number of comparisons, swaps and executed Java Bytecode\ninstructions. It turns out that - unlike for classic Quicksort, where it is\noptimal to choose the pivot as median of the sample - the asymmetries in\nYaroslavskiy's algorithm render pivots with a systematic skew more efficient\nthan the symmetric choice. Moreover, the optimal skew heavily depends on the\nemployed cost measure; most strikingly, abstract costs like the number of swaps\nand comparisons yield a very different result than counting Java Bytecode\ninstructions, which can be assumed most closely related to actual running time. \n\n"}
{"id": "1403.6752", "contents": "Title: Confidence intervals for high-dimensional inverse covariance estimation Abstract: We propose methodology for statistical inference for low-dimensional\nparameters of sparse precision matrices in a high-dimensional setting. Our\nmethod leads to a non-sparse estimator of the precision matrix whose entries\nhave a Gaussian limiting distribution. Asymptotic properties of the novel\nestimator are analyzed for the case of sub-Gaussian observations under a\nsparsity assumption on the entries of the true precision matrix and regularity\nconditions. Thresholding the de-sparsified estimator gives guarantees for edge\nselection in the associated graphical model. Performance of the proposed method\nis illustrated in a simulation study. \n\n"}
{"id": "1403.7393", "contents": "Title: Noise-induced phase slips, log-periodic oscillations, and the Gumbel\n  distribution Abstract: When two synchronised phase oscillators are perturbed by weak noise, they\ndisplay occasional losses of synchrony, called phase slips. The slips can be\ncharacterised by their location in phase space and their duration. We show that\nwhen properly normalised, their location converges, in the vanishing noise\nlimit, to the sum of an asymptotically geometric random variable and a Gumbel\nrandom variable. The duration also converges to a Gumbel variable with\ndifferent parameters. We relate these results to recent works on the phenomenon\nof log-periodic oscillations and on links between transition path theory and\nextreme-value theory. \n\n"}
{"id": "1403.7837", "contents": "Title: On Many-Body Localization for Quantum Spin Chains Abstract: For a one-dimensional spin chain with random local interactions, we prove\nthat many-body localization follows from a physically reasonable assumption\nthat limits the amount of level attraction in the system. The construction uses\na sequence of local unitary transformations to diagonalize the Hamiltonian and\nconnect the exact many-body eigenfunctions to the original basis vectors. \n\n"}
{"id": "1404.0239", "contents": "Title: Smirnov's observable for free boundary conditions, interfaces and\n  crossing probabilities Abstract: We prove convergence results for variants of Smirnov's fermionic observable\nin the critical Ising model in presence of free boundary conditions. One\napplication of our analysis is a simple proof of a theorem by Hongler and\nKyt\\\"ol\\\"a on convergence of critical Ising interfaces with plus-minus-free\nboundary conditions to dipolar SLE(3), and generalization of this result to\narbitrary number of arcs carrying plus, minus or free boundary conditions.\nAnother application is a computation of scaling limits of crossing\nprobabilities in FK-Ising model with arbitrary number of alternating wired/free\nboundary arcs. We also deduce a new crossing formula for the spin Ising model. \n\n"}
{"id": "1404.2802", "contents": "Title: Mixing and Concentration by Ricci Curvature Abstract: We generalise the coarse Ricci curvature method of Ollivier by considering\nthe coarse Ricci curvature of multiple steps in the Markov chain. This implies\nnew spectral bounds and concentration inequalities. We also extend this\napproach to the bounds for MCMC empirical averages obtained by Joulin and\nOllivier. We prove a recursive lower bound on the coarse Ricci curvature of\nmultiple steps in the Markov chain, making our method broadly applicable.\nApplications include the split-merge random walk on partitions, Glauber\ndynamics with random scan and systemic scan for statistical physical spin\nmodels, and random walk on a binary cube with a forbidden region. \n\n"}
{"id": "1404.2854", "contents": "Title: Generalised Fisher Matrices Abstract: The Fisher Information Matrix formalism is extended to cases where the data\nis divided into two parts (X,Y), where the expectation value of Y depends on X\naccording to some theoretical model, and X and Y both have errors with\narbitrary covariance. In the simplest case, (X,Y) represent data pairs of\nabscissa and ordinate, in which case the analysis deals with the case of data\npairs with errors in both coordinates, but X can be any measured quantities on\nwhich Y depends. The analysis applies for arbitrary covariance, provided all\nerrors are gaussian, and provided the errors in X are small, both in comparison\nwith the scale over which the expected signal Y changes, and with the width of\nthe prior distribution. This generalises the Fisher Matrix approach, which\nnormally only considers errors in the `ordinate' Y. In this work, we include\nerrors in X by marginalising over latent variables, effectively employing a\nBayesian hierarchical model, and deriving the Fisher Matrix for this more\ngeneral case. The methods here also extend to likelihood surfaces which are not\ngaussian in the parameter space, and so techniques such as DALI (Derivative\nApproximation for Likelihoods) can be generalised straightforwardly to include\narbitrary gaussian data error covariances. For simple mock data and theoretical\nmodels, we compare to Markov Chain Monte Carlo experiments, illustrating the\nmethod with cosmological supernova data. We also include the new method in the\nFisher4Cast software. \n\n"}
{"id": "1404.4414", "contents": "Title: Probit transformation for nonparametric kernel estimation of the copula\n  density Abstract: Copula modelling has become ubiquitous in modern statistics. Here, the\nproblem of nonparametrically estimating a copula density is addressed. Arguably\nthe most popular nonparametric density estimator, the kernel estimator is not\nsuitable for the unit-square-supported copula densities, mainly because it is\nheavily affected by boundary bias issues. In addition, most common copulas\nadmit unbounded densities, and kernel methods are not consistent in that case.\nIn this paper, a kernel-type copula density estimator is proposed. It is based\non the idea of transforming the uniform marginals of the copula density into\nnormal distributions via the probit function, estimating the density in the\ntransformed domain, which can be accomplished without boundary problems, and\nobtaining an estimate of the copula density through back-transformation.\nAlthough natural, a raw application of this procedure was, however, seen not to\nperform very well in the earlier literature. Here, it is shown that, if\ncombined with local likelihood density estimation methods, the idea yields very\ngood and easy to implement estimators, fixing boundary issues in a natural way\nand able to cope with unbounded copula densities. The asymptotic properties of\nthe suggested estimators are derived, and a practical way of selecting the\ncrucially important smoothing parameters is devised. Finally, extensive\nsimulation studies and a real data analysis evidence their excellent\nperformance compared to their main competitors. \n\n"}
{"id": "1404.5609", "contents": "Title: Controlling the false discovery rate via knockoffs Abstract: In many fields of science, we observe a response variable together with a\nlarge number of potential explanatory variables, and would like to be able to\ndiscover which variables are truly associated with the response. At the same\ntime, we need to know that the false discovery rate (FDR) - the expected\nfraction of false discoveries among all discoveries - is not too high, in order\nto assure the scientist that most of the discoveries are indeed true and\nreplicable. This paper introduces the knockoff filter, a new variable selection\nprocedure controlling the FDR in the statistical linear model whenever there\nare at least as many observations as variables. This method achieves exact FDR\ncontrol in finite sample settings no matter the design or covariates, the\nnumber of variables in the model, or the amplitudes of the unknown regression\ncoefficients, and does not require any knowledge of the noise level. As the\nname suggests, the method operates by manufacturing knockoff variables that are\ncheap - their construction does not require any new data - and are designed to\nmimic the correlation structure found within the existing variables, in a way\nthat allows for accurate FDR control, beyond what is possible with\npermutation-based methods. The method of knockoffs is very general and\nflexible, and can work with a broad class of test statistics. We test the\nmethod in combination with statistics from the Lasso for sparse regression, and\nobtain empirical results showing that the resulting method has far more power\nthan existing selection rules when the proportion of null variables is high. \n\n"}
{"id": "1405.0427", "contents": "Title: Recent probabilistic results on covariant Schr\\\"odinger operators on\n  infinite weighted graphs Abstract: We review recent probabilistic results on covariant Schr\\\"odinger operators\non vector bundles over (possibly locally infinite) weighted graphs, and explain\napplications like semiclassical limits. We also clarify the relationship\nbetween these results and their formal analogues on smooth (possibly\nnoncompact) Riemannian manifolds. \n\n"}
{"id": "1405.2292", "contents": "Title: Statistical Causality from a Decision-Theoretic Perspective Abstract: We present an overview of the decision-theoretic framework of statistical\ncausality, which is well-suited for formulating and solving problems of\ndetermining the effects of applied causes. The approach is described in detail,\nand is related to and contrasted with other current formulations, such as\nstructural equation models and potential responses. Topics and applications\ncovered include confounding, the effect of treatment on the treated,\ninstrumental variables, and dynamic treatment strategies. \n\n"}
{"id": "1405.2601", "contents": "Title: LP Approach to Statistical Modeling Abstract: We present an approach to statistical data modeling and exploratory data\nanalysis called `LP Statistical Data Science.' It aims to generalize and unify\ntraditional and novel statistical measures, methods, and exploratory tools.\nThis article outlines fundamental concepts along with real-data examples to\nillustrate how the `LP Statistical Algorithm' can systematically tackle\ndifferent varieties of data types, data patterns, and data structures under a\ncoherent theoretical framework. A fundamental role is played by specially\ndesigned orthonormal basis of a random variable X for linear (Hilbert space\ntheory) representation of a general function of X, such as $\\mbox{E}[Y \\mid\nX]$. \n\n"}
{"id": "1405.4275", "contents": "Title: A geometric approach to archetypal analysis and non-negative matrix\n  factorization Abstract: Archetypal analysis and non-negative matrix factorization (NMF) are staples\nin a statisticians toolbox for dimension reduction and exploratory data\nanalysis. We describe a geometric approach to both NMF and archetypal analysis\nby interpreting both problems as finding extreme points of the data cloud. We\nalso develop and analyze an efficient approach to finding extreme points in\nhigh dimensions. For modern massive datasets that are too large to fit on a\nsingle machine and must be stored in a distributed setting, our approach makes\nonly a small number of passes over the data. In fact, it is possible to obtain\nthe NMF or perform archetypal analysis with just two passes over the data. \n\n"}
{"id": "1405.4882", "contents": "Title: Nonstandard regular variation of in-degree and out-degree in the\n  preferential attachment model Abstract: For the directed edge preferential attachment network growth model studied by\nBollobas et al. (2003) and Krapivsky and Redner (2001), we prove that the joint\ndistribution of in-degree and out-degree has jointly regularly varying tails.\nTypically the marginal tails of the in-degree distribution and the out-degree\ndistribution have different regular variation indices and so the joint regular\nvariation is non-standard. Only marginal regular variation has been previously\nestablished for this distribution in the cases where the marginal tail indices\nare different. \n\n"}
{"id": "1405.5239", "contents": "Title: Sequential Advantage Selection for Optimal Treatment Regimes Abstract: Variable selection for optimal treatment regime in a clinical trial or an\nobservational study is getting more attention. Most existing variable selection\ntechniques focused on selecting variables that are important for prediction,\ntherefore some variables that are poor in prediction but are critical for\ndecision-making may be ignored. A qualitative interaction of a variable with\ntreatment arises when treatment effect changes direction as the value of this\nvariable varies. The qualitative interaction indicates the importance of this\nvariable for decision-making. Gunter et al. (2011) proposed S-score which\ncharacterizes the magnitude of qualitative interaction of each variable with\ntreatment individually. In this article, we developed a sequential advantage\nselection method based on the modified S-score. Our method selects\nqualitatively interacted variables sequentially, and hence excludes marginally\nimportant but jointly unimportant variables {or vice versa}. The optimal\ntreatment regime based on variables selected via joint model is more\ncomprehensive and reliable. With the proposed stopping criteria, our method can\nhandle a large amount of covariates even if sample size is small. Simulation\nresults show our method performs well in practical settings. We further applied\nour method to data from a clinical trial for depression. \n\n"}
{"id": "1405.6531", "contents": "Title: Gaussian Random Functional Dynamic Spatio-Temporal Modeling of Discrete\n  Time Spatial Time Series Data Abstract: Discrete time spatial time series data arise routinely in meteorological and\nenvironmental studies. Inference and prediction associated with them are mostly\ncarried out using any of the several variants of the linear state space model\nthat are collectively called linear dynamic spatio-temporal models (LDSTMs).\nHowever, real world environmental processes are highly complex and are seldom\nrepresentable by models with such simple linear structure. Hence, nonlinear\ndynamic spatio-temporal models (NLDSTMs) based on the idea of nonlinear\nobservational and evolutionary equation have been proposed as an alternative.\nHowever, in that case, the caveat lies in selecting the specific form of\nnonlinearity from a large class of potentially appropriate nonlinear functions.\nMoreover, modeling by NLDSTMs requires precise knowledge about the dynamics\nunderlying the data. In this article, we address this problem by introducing\nthe Gaussian random functional dynamic spatio-temporal model (GRFDSTM). Unlike\nthe LDSTMs or NLDSTMs, in GRFDSTM both the functions governing the\nobservational and evolutionary equations are composed of Gaussian random\nfunctions. We exhibit many interesting theoretical properties of the GRFDSTM\nand demonstrate how model fitting and prediction can be carried out coherently\nin a Bayesian framework. We also conduct an extensive simulation study and\napply our model to a real, SO2 pollution data over Europe. The results are\nhighly encouraging. \n\n"}
{"id": "1405.6580", "contents": "Title: Brownian Motion on graph-like spaces Abstract: We construct Brownian motion on a wide class of metric spaces similar to\ngraphs, and show that its cover time admits an upper bound depending only on\nthe length of the space. \n\n"}
{"id": "1405.6919", "contents": "Title: Multivariate Eulerian polynomials and exclusion processes Abstract: We give a new combinatorial interpretation of the stationary distribution of\nthe (partially) asymmetric exclusion process on a finite number of sites in\nterms of decorated alternative trees and colored permutations. The\ncorresponding expressions of the multivariate partition functions are then\nrelated to multivariate generalizations of Eulerian polynomials for colored\npermutations considered recently by N. Williams and the third author, and\nothers. We also discuss stability-- and negative dependence properties\nsatisfied by the partition functions. \n\n"}
{"id": "1405.7091", "contents": "Title: Bayesian hierarchical modelling for inferring genetic interactions in\n  yeast Abstract: Identifying genetic interactions for a given microorganism such as yeast is\ndifficult. Quantitative Fitness Analysis (QFA) is a high-throughput\nexperimental and computational methodology for quantifying the fitness of\nmicrobial cultures. QFA can be used to compare between fitness observations for\ndifferent genotypes and thereby infer genetic interaction strengths. Current\n\"naive\" frequentist statistical approaches used in QFA do not model\nbetween-genotype variation or difference in genotype variation under different\nconditions. In this thesis, a Bayesian approach is introduced to evaluate\nhierarchical models that better reflect the structure or design of QFA\nexperiments. First, a two-stage approach is presented: a hierarchical logistic\nmodel is fitted to microbial culture growth curves and then a hierarchical\ninteraction model is fitted to fitness summaries inferred for each genotype.\nNext, a one-stage Bayesian approach is presented: a joint hierarchical model\nwhich does not require a univariate summary of fitness, used to pass\ninformation between models. The new hierarchical approaches are then compared\nusing a dataset examining the effect of telomere defects on yeast. By better\ndescribing the experimental structure, new evidence is found for genes and\ncomplexes which interact with the telomere cap. Various extensions of these\nmodels, including models for data transformation, batch effects, and\nintrinsically stochastic growth models are also considered. \n\n"}
{"id": "1406.0934", "contents": "Title: Betti numbers of random nodal sets of elliptic pseudo-differential\n  operators Abstract: Given an elliptic self-adjoint pseudo-differential operator $P$ bounded from\nbelow, acting on the sections of a Riemannian line bundle over a smooth closed\nmanifold $M$ equipped with some Lebesgue measure, we estimate from above, as\n$L$ grows to infinity, the Betti numbers of the vanishing locus of a random\nsection taken in the direct sum of the eigenspaces of $P$ with eigenvalues\nbelow $L$. These upper estimates follow from some equidistribution of the\ncritical points of the restriction of a fixed Morse function to this vanishing\nlocus. We then consider the examples of the Laplace-Beltrami and the\nDirichlet-to-Neumann operators associated to some Riemannian metric on $M$. \n\n"}
{"id": "1406.1248", "contents": "Title: The lower tail: Poisson approximation revisited Abstract: The well-known \"Janson's inequality\" gives Poisson-like upper bounds for the\nlower tail probability \\Pr(X \\le (1-\\eps)\\E X) when X is the sum of dependent\nindicator random variables of a special form. We show that, for large\ndeviations, this inequality is optimal whenever X is approximately Poisson,\ni.e., when the dependencies are weak. We also present correlation-based\napproaches that, in certain symmetric applications, yield related conclusions\nwhen X is no longer close to Poisson. As an illustration we, e.g., consider\nsubgraph counts in random graphs, and obtain new lower tail estimates,\nextending earlier work (for the special case \\eps=1) of Janson, Luczak and\nRucinski. \n\n"}
{"id": "1406.1396", "contents": "Title: A rate of convergence for the circular law for the complex Ginibre\n  ensemble Abstract: We prove rates of convergence for the circular law for the complex Ginibre\nensemble. Specifically, we bound the expected $L_p$-Wasserstein distance\nbetween the empirical spectral measure of the normalized complex Ginibre\nensemble and the uniform measure on the unit disc, both in expectation and\nalmost surely. For $1 \\le p \\le 2$, the bounds are of the order $n^{-1/4}$, up\nto logarithmic factors. \n\n"}
{"id": "1406.2186", "contents": "Title: Normal approximation for the net flux through a random conductor Abstract: We consider solutions to an elliptic partial differential equation in\n$\\mathbb{R}^d$ with a stationary, random conductivity coefficient. The boundary\ncondition on a square domain of width $L$ is chosen so that the solution has a\nmacroscopic unit gradient. We then consider the average flux through the\ndomain. It is known that in the limit $L \\to \\infty$, this quantity converges\nto a deterministic constant, almost surely. Our main result is about normal\napproximation for this flux when $L$ is large: we give an estimate of the\nKantorovich-Wasserstein distance between the law of this random variable and\nthat of a normal random variable. This extends a previous result of the author\nto a much larger class of random conductivity coefficients. The analysis relies\non elliptic regularity, on bounds for the Green's function, and on a normal\napproximation method developed by S. Chatterjee based on Stein's method. \n\n"}
{"id": "1406.2193", "contents": "Title: Singular Equations Driven by an Additive Noise and Applications Abstract: In the pathwise stochastic calculus framework, the paper deals with the\ngeneral study of equations driven by an additive Gaussian noise, with a drift\nfunction having an infinite limit at point zero. An ergodic theorem and the\nconvergence of the implicit Euler scheme are proved. The Malliavin calculus is\nused to study the absolute continuity of the distribution of the solution. An\nestimation procedure of the parameters of the random component of the model is\nprovided. The properties are transferred on a class of singular stochastic\ndifferential equations driven by a multiplicative noise. A fractional Heston\nmodel is introduced. \n\n"}
{"id": "1406.3521", "contents": "Title: Exact prior-free probabilistic inference on the heritability coefficient\n  in a linear mixed model Abstract: Linear mixed-effect models with two variance components are often used when\nvariability comes from two sources. In genetics applications, variation in\nobserved traits can be attributed to biological and environmental effects, and\nthe heritability coefficient is a fundamental quantity that measures the\nproportion of total variability due to the biological effect. We propose a new\ninferential model approach which yields exact prior-free probabilistic\ninference on the heritability coefficient. In particular we construct exact\nconfidence intervals and demonstrate numerically our method's efficiency\ncompared to that of existing methods. \n\n"}
{"id": "1406.3662", "contents": "Title: On the asymptotics of constrained exponential random graphs Abstract: The unconstrained exponential family of random graphs assumes no prior\nknowledge of the graph before sampling, but it is natural to consider\nsituations where partial information about the graph is known, for example the\ntotal number of edges. What does a typical random graph look like, if drawn\nfrom an exponential model subject to such constraints? Will there be a similar\nphase transition phenomenon (as one varies the parameters) as that which occurs\nin the unconstrained exponential model? We present some general results for\nthis constrained model and then apply them to get concrete answers in the\nedge-triangle model with fixed density of edges. \n\n"}
{"id": "1406.4068", "contents": "Title: Functional Regression Abstract: Functional data analysis (FDA) involves the analysis of data whose ideal\nunits of observation are functions defined on some continuous domain, and the\nobserved data consist of a sample of functions taken from some population,\nsampled on a discrete grid. Ramsay and Silverman's 1997 textbook sparked the\ndevelopment of this field, which has accelerated in the past 10 years to become\none of the fastest growing areas of statistics, fueled by the growing number of\napplications yielding this type of data. One unique characteristic of FDA is\nthe need to combine information both across and within functions, which Ramsay\nand Silverman called replication and regularization, respectively. This article\nwill focus on functional regression, the area of FDA that has received the most\nattention in applications and methodological development. First will be an\nintroduction to basis functions, key building blocks for regularization in\nfunctional regression methods, followed by an overview of functional regression\nmethods, split into three types: [1] functional predictor regression\n(scalar-on-function), [2] functional response regression (function-on-scalar)\nand [3] function-on-function regression. For each, the role of replication and\nregularization will be discussed and the methodological development described\nin a roughly chronological manner, at times deviating from the historical\ntimeline to group together similar methods. The primary focus is on modeling\nand methodology, highlighting the modeling structures that have been developed\nand the various regularization approaches employed. At the end is a brief\ndiscussion describing potential areas of future development in this field. \n\n"}
{"id": "1406.5089", "contents": "Title: Entropy along W_{1,+}-geodesics on graphs Abstract: We study the convexity of the entropy functional along particular\ninterpolating curves defined on the space of finitely supported probability\nmeasures on a graph. \n\n"}
{"id": "1406.5577", "contents": "Title: Graphical structure of conditional independencies in determinantal point\n  processes Abstract: Determinantal point process have recently been used as models in machine\nlearning and this has raised questions regarding the characterizations of\nconditional independence. In this paper we investigate characterizations of\nconditional independence. We describe some conditional independencies through\nthe conditions on the kernel of a determinantal point process, and show many\ncan be obtained using the graph induced by a kernel of the $L$-ensemble. \n\n"}
{"id": "1406.5624", "contents": "Title: Exact simulation of Brown-Resnick random fields at a finite number of\n  locations Abstract: We propose an exact simulation method for Brown-Resnick random fields,\nbuilding on new representations for these stationary max-stable fields. The\nmain idea is to apply suitable changes of measure. \n\n"}
{"id": "1406.5663", "contents": "Title: Asymptotic theory for density ridges Abstract: The large sample theory of estimators for density modes is well understood.\nIn this paper we consider density ridges, which are a higher-dimensional\nextension of modes. Modes correspond to zero-dimensional, local high-density\nregions in point clouds. Density ridges correspond to $s$-dimensional, local\nhigh-density regions in point clouds. We establish three main results. First we\nshow that under appropriate regularity conditions, the local variation of the\nestimated ridge can be approximated by an empirical process. Second, we show\nthat the distribution of the estimated ridge converges to a Gaussian process.\nThird, we establish that the bootstrap leads to valid confidence sets for\ndensity ridges. \n\n"}
{"id": "1406.6222", "contents": "Title: Law of large numbers for random walk with unbounded jumps and BDP with\n  bounded jumps in random environment Abstract: We study random walk with unbounded jumps in random environment. The\nenvironment is stationary and ergodic, uniformly elliptic and decays\npolynomially with speed $Dj^{-(3+\\varepsilon_0)}$ for some small\n$\\varepsilon_0>0$ and proper $D>0.$ We prove a law of large number with\npositive velocity under the condition that the annealed mean of the hitting\ntime of the positive half lattice is finite. Secondly, we consider birth and\ndeath process with bounded jumps in stationary and ergodic environment. Under\nthe uniformly elliptic condition, we prove a law of large number and give the\nexplicit formula of its velocity. \n\n"}
{"id": "1406.6664", "contents": "Title: Preservation of algebraicity in free probability Abstract: We show that any matrix-polynomial combination of free noncommutative random\nvariables each having an algebraic law has again an algebraic law. Our result\nanswers a question raised by a recent paper of Shlyakhtenko and Skoufranis. The\nresult belongs to a family of results with origins outside free probability\ntheory, including a result of Aomoto asserting algebraicity of the Green\nfunction of random walk of quite general type on a free group. \n\n"}
{"id": "1407.4295", "contents": "Title: Random walk loop soups and conformal loop ensembles Abstract: The random walk loop soup is a Poissonian ensemble of lattice loops; it has\nbeen extensively studied because of its connections to the discrete Gaussian\nfree field, but was originally introduced by Lawler and Trujillo Ferreras as a\ndiscrete version of the Brownian loop soup of Lawler and Werner, a conformally\ninvariant Poissonian ensemble of planar loops with deep connections to\nconformal loop ensembles (CLEs) and the Schramm-Loewner evolution (SLE).\n  Lawler and Trujillo Ferreras showed that, roughly speaking, in the continuum\nscaling limit, ``large'' lattice loops from the random walk loop soup converge\nto ``large'' loops from the Brownian loop soup. Their results, however, do not\nextend to clusters of loops, which are interesting because the connection\nbetween Brownian loop soup and CLE goes via cluster boundaries. In this paper,\nwe study the scaling limit of clusters of ``large'' lattice loops, showing that\nthey converge to Brownian loop soup clusters. In particular, our results imply\nthat the collection of outer boundaries of outermost clusters composed of\n``large'' lattice loops converges to CLE. \n\n"}
{"id": "1407.5241", "contents": "Title: Influential Feature PCA for high dimensional clustering Abstract: We consider a clustering problem where we observe feature vectors $X_i \\in\nR^p$, $i = 1, 2, \\ldots, n$, from $K$ possible classes. The class labels are\nunknown and the main interest is to estimate them. We are primarily interested\nin the modern regime of $p \\gg n$, where classical clustering methods face\nchallenges.\n  We propose Influential Features PCA (IF-PCA) as a new clustering procedure.\nIn IF-PCA, we select a small fraction of features with the largest\nKolmogorov-Smirnov (KS) scores, where the threshold is chosen by adapting the\nrecent notion of Higher Criticism, obtain the first $(K-1)$ left singular\nvectors of the post-selection normalized data matrix, and then estimate the\nlabels by applying the classical k-means to these singular vectors. It can be\nseen that IF-PCA is a tuning free clustering method.\n  We apply IF-PCA to $10$ gene microarray data sets. The method has competitive\nperformance in clustering. Especially, in three of the data sets, the error\nrates of IF-PCA are only $29\\%$ or less of the error rates by other methods. We\nhave also rediscovered a phenomenon on empirical null by \\cite{Efron} on\nmicroarray data.\n  With delicate analysis, especially post-selection eigen-analysis, we derive\ntight probability bounds on the Kolmogorov-Smirnov statistics and show that\nIF-PCA yields clustering consistency in a broad context. The clustering problem\nis connected to the problems of sparse PCA and low-rank matrix recovery, but it\nis different in important ways. We reveal an interesting phase transition\nphenomenon associated with these problems and identify the range of interest\nfor each. \n\n"}
{"id": "1407.7359", "contents": "Title: Unbiased estimation of second-order parameter sensitivities for\n  stochastic reaction networks Abstract: This paper deals with the problem of estimating second-order parameter\nsensitivities for stochastic reaction networks, where the reaction dynamics is\nmodeled as a continuous time Markov chain over a discrete state space.\nEstimation of such second-order sensitivities (the Hessian) is necessary for\nimplementing the Newton-Raphson scheme for optimization over the parameter\nspace. To perform this estimation, Wolf and Anderson have proposed an efficient\nfinite-difference method, that uses a coupling of perturbed processes to reduce\nthe estimator variance. The aim of this paper is to illustrate that the same\ncoupling can be exploited to derive an exact representation for second-order\nparameter sensitivity. Furthermore with this representation one can construct\nan unbiased estimator which is easy to implement. The ideas contained in this\npaper are extensions of the ideas presented in our recent papers on first-order\nparameter sensitivity estimation. \n\n"}
{"id": "1407.7603", "contents": "Title: On some smoothening effects of the transition semigroup of a L\\'evy\n  process Abstract: Let $(P_t)$ be the transition semigroup of a L\\'evy process $L$ taking values\nin a Hilbert space $H$. Let $\\nu$ be the L\\'evy measure of $L$. It is shown\nthat for any bounded and measurable function $f$, $$ \\int_H\\left\\vert\nP_tf(x+y)-P_tf(x)\\right\\vert ^2 \\nu (\\dif y)\\le \\frac 1 t P_tf^2(x) \\qquad\n\\text{for all $t>0$, $x\\in H$.} $$ As $\\nu$ can be infinite this formula\nestablishes some smoothening effect of the semigroup $(P_t)$. In the paper some\napplications of the formula will be presented as well. \n\n"}
{"id": "1407.8092", "contents": "Title: L\\'evy-driven Volterra equations in space and time Abstract: We investigate nonlinear stochastic Volterra equations in space and time that\nare driven by L\\'evy bases. Under a Lipschitz condition on the nonlinear term,\nwe give existence and uniqueness criteria in weighted function spaces that\ndepend on integrability properties of the kernel and the characteristics of the\nL\\'evy basis. Particular attention is devoted to equations with stationary\nsolutions, or more generally, to equations with infinite memory, that is, where\nthe time domain of integration starts at minus infinity. Here, in contrast to\nthe case where time is positive, the usual integrability conditions on the\nkernel are no longer sufficient for the existence and uniqueness of solutions,\nbut we have to impose additional size conditions on the kernel and the L\\'evy\ncharacteristics. Furthermore, once the existence of a solution is guaranteed,\nwe analyse its asymptotic stability, that is, whether its moments remain\nbounded when time goes to infinity. Stability is proved whenever kernel and\ncharacteristics are small enough, or the nonlinearity of the equation exhibits\na fractional growth of order strictly smaller than one. The results are applied\nto the stochastic heat equation for illustration. \n\n"}
{"id": "1408.0318", "contents": "Title: Jointly Sparse Global SIMPLS Regression Abstract: Partial least squares (PLS) regression combines dimensionality reduction and\nprediction using a latent variable model. Since partial least squares\nregression (PLS-R) does not require matrix inversion or diagonalization, it can\nbe applied to problems with large numbers of variables. As predictor dimension\nincreases, variable selection becomes essential to avoid over-fitting, to\nprovide more accurate predictors and to yield more interpretable parameters. We\npropose a global variable selection approach that penalizes the total number of\nvariables across all PLS components. Put another way, the proposed global\npenalty encourages the selected variables to be shared among the PLS\ncomponents. We formulate PLS-R with joint sparsity as a variational\noptimization problem with objective function equal to a novel global SIMPLS\ncriterion plus a mixed norm sparsity penalty on the weight matrix. The mixed\nnorm sparsity penalty is the $\\ell_1$ norm of the $\\ell_2$ norm on the weights\ncorresponding to the same variable used over all the PLS components. A novel\naugmented Lagrangian method is proposed to solve the optimization problem and\nsoft thresholding for sparsity occurs naturally as part of the iterative\nsolution. Experiments show that the modified PLS-R attains better or as good\nperformance with many fewer selected predictor variables. \n\n"}
{"id": "1408.0916", "contents": "Title: A system of quadratic BSDEs arising in a price impact model Abstract: We consider a financial model where the prices of risky assets are quoted by\na representative market maker who takes into account an exogenous demand. We\ncharacterize these prices in terms of a system of BSDEs with quadratic growth.\nWe show that this system admits a unique solution for every bounded demand if\nand only if the market maker's risk-aversion is sufficiently small. The\nuniqueness is established in the natural class of solutions, without any\nadditional norm restrictions. To the best of our knowledge, this is the first\nstudy that proves such (global) uniqueness result for a system of fully coupled\nquadratic BSDEs. \n\n"}
{"id": "1408.2998", "contents": "Title: Stein's method for comparison of univariate distributions Abstract: We propose a new general version of Stein's method for univariate\ndistributions. In particular we propose a canonical definition of the Stein\noperator of a probability distribution {which is based on a linear difference\nor differential-type operator}. The resulting Stein identity highlights the\nunifying theme behind the literature on Stein's method (both for continuous and\ndiscrete distributions). Viewing the Stein operator as an operator acting on\npairs of functions, we provide an extensive toolkit for distributional\ncomparisons. Several abstract approximation theorems are provided. Our approach\nis illustrated for comparison of several pairs of distributions : normal vs\nnormal, sums of independent Rademacher vs normal, normal vs Student, and\nmaximum of random variables vs exponential, Frechet and Gumbel. \n\n"}
{"id": "1408.3783", "contents": "Title: Long-term causal effects of economic mechanisms on agent incentives Abstract: Economic mechanisms administer the allocation of resources to interested\nagents based on their self-reported types. One objective in mechanism design is\nto design a strategyproof process so that no agent will have an incentive to\nmisreport its type. However, typical analyses of the incentives properties of\nmechanisms operate under strong, usually untestable assumptions. Empirical,\ndata-oriented approaches are, at best, under-developed. Furthermore,\nmechanism/policy evaluation methods usually ignore the dynamic nature of a\nmulti-agent system and are thus inappropriate for estimating long-term effects.\nWe introduce the problem of estimating the causal effects of mechanisms on\nincentives and frame it under the Rubin causal framework \\citep{rubin74,\nrubin78}. This raises unique technical challenges since the outcome of interest\n(agent truthfulness) is confounded with strategic interactions and,\ninterestingly, is typically never observed under any mechanism. We develop a\nmethodology to estimate such causal effects that using a prior that is based on\na strategic equilibrium model. Working on the domain of kidney exchanges, we\nshow how to apply our methodology to estimate causal effects of kidney\nallocation mechanisms on hospitals' incentives. Our results demonstrate that\nthe use of game-theoretic prior captures the dynamic nature of the kidney\nexchange multiagent system and shrinks the estimates towards long-term effects,\nthus improving upon typical methods that completely ignore agents' strategic\nbehavior. \n\n"}
{"id": "1408.4294", "contents": "Title: Gaps in the spectrum of the Laplacian on $3N$-Gaskets Abstract: This article develops analysis on fractal $3N$-gaskets, a class of\npost-critically finite fractals which include the Sierpinski triangle for\n$N=1$, specifically properties of the Laplacian $\\Delta$ on these gaskets. We\nfirst prove the existence of a self-similar geodesic metric on these gaskets,\nand prove heat kernel estimates for this Laplacian with respect to the geodesic\nmetric. We also compute the elements of the method of spectral decimation, a\ntechnique used to determine the spectrum of post-critically finite fractals.\nSpectral decimation on these gaskets arises from more complicated dynamics than\nin previous examples, i.e. the functions involved are rational rather than\npolynomial. Due to the nature of these dynamics, we are able to show that there\nare gaps in the spectrum. \n\n"}
{"id": "1409.2676", "contents": "Title: Efficient sampling of Gaussian graphical models using conditional Bayes\n  factors Abstract: Bayesian estimation of Gaussian graphical models has proven to be challenging\nbecause the conjugate prior distribution on the Gaussian precision matrix, the\nG-Wishart distribution, has a doubly intractable partition function. Recent\ndevelopments provide a direct way to sample from the G-Wishart distribution,\nwhich allows for more efficient algorithms for model selection than previously\npossible. Still, estimating Gaussian graphical models with more than a handful\nof variables remains a nearly infeasible task. Here, we propose two novel\nalgorithms that use the direct sampler to more efficiently approximate the\nposterior distribution of the Gaussian graphical model. The first algorithm\nuses conditional Bayes factors to compare models in a Metropolis-Hastings\nframework. The second algorithm is based on a continuous time Markov process.\nWe show that both algorithms are substantially faster than state-of-the-art\nalternatives. Finally, we show how the algorithms may be used to simultaneously\nestimate both structural and functional connectivity between subcortical brain\nregions using resting-state fMRI. \n\n"}
{"id": "1409.4732", "contents": "Title: A geometric and game-theoretic study of the conjunction of possibility\n  measures Abstract: In this paper, we study the conjunction of possibility measures when they are\ninterpreted as coherent upper probabilities, that is, as upper bounds for some\nset of probability measures. We identify conditions under which the minimum of\ntwo possibility measures remains a possibility measure. We provide graphical\nway to check these conditions, by means of a zero-sum game formulation of the\nproblem. This also gives us a nice way to adjust the initial possibility\nmeasures so their minimum is guaranteed to be a possibility measure. Finally,\nwe identify conditions under which the minimum of two possibility measures is a\ncoherent upper probability, or in other words, conditions under which the\nminimum of two possibility measures is an exact upper bound for the\nintersection of the credal sets of those two possibility measures. \n\n"}
{"id": "1409.8565", "contents": "Title: Sparse CCA: Adaptive Estimation and Computational Barriers Abstract: Canonical correlation analysis is a classical technique for exploring the\nrelationship between two sets of variables. It has important applications in\nanalyzing high dimensional datasets originated from genomics, imaging and other\nfields. This paper considers adaptive minimax and computationally tractable\nestimation of leading sparse canonical coefficient vectors in high dimensions.\nFirst, we establish separate minimax estimation rates for canonical coefficient\nvectors of each set of random variables under no structural assumption on\nmarginal covariance matrices. Second, we propose a computationally feasible\nestimator to attain the optimal rates adaptively under an additional sample\nsize condition. Finally, we show that a sample size condition of this kind is\nneeded for any randomized polynomial-time estimator to be consistent, assuming\nhardness of certain instances of the Planted Clique detection problem. The\nresult is faithful to the Gaussian models used in the paper. As a byproduct, we\nobtain the first computational lower bounds for sparse PCA under the Gaussian\nsingle spiked covariance model. \n\n"}
{"id": "1410.0752", "contents": "Title: Moment approach for singular values distribution of a large\n  auto-covariance matrix Abstract: Let $(\\varepsilon_{t})_{t>0}$ be a sequence of independent real random\nvectors of $p$-dimension and let $X_T=\n\\sum_{t=s+1}^{s+T}\\varepsilon_t\\varepsilon^T_{t-s}/T$ be the lag-$s$ ($s$ is a\nfixed positive integer) auto-covariance matrix of $\\varepsilon_t$. Since $X_T$\nis not symmetric, we consider its singular values, which are the square roots\nof the eigenvalues of $X_TX^T_T$. Therefore, the purpose of this paper is to\ninvestigate the limiting behaviors of the eigenvalues of $X_TX^T_T$ in two\naspects. First, we show that the empirical spectral distribution of its\neigenvalues converges to a nonrandom limit $F$. Second, we establish the\nconvergence of its largest eigenvalue to the right edge of $F$. Both results\nare derived using moment methods. \n\n"}
{"id": "1410.3155", "contents": "Title: Sample Size Dependent Species Models Abstract: Motivated by the fundamental problem of measuring species diversity, this\npaper introduces the concept of a cluster structure to define an exchangeable\ncluster probability function that governs the joint distribution of a random\ncount and its exchangeable random partitions. A cluster structure, naturally\narising from a completely random measure mixed Poisson process, allows the\nprobability distribution of the random partitions of a subset of a sample to be\ndependent on the sample size, a distinct and motivated feature that differs it\nfrom a partition structure. A generalized negative binomial process model is\nproposed to generate a cluster structure, where in the prior the number of\nclusters is finite and Poisson distributed, and the cluster sizes follow a\ntruncated negative binomial distribution. We construct a nonparametric Bayesian\nestimator of Simpson's index of diversity under the generalized negative\nbinomial process. We illustrate our results through the analysis of two real\nsequencing count datasets. \n\n"}
{"id": "1410.4846", "contents": "Title: Deterministic walk in an excited random environment Abstract: Deterministic walk in an excited random environment is a non-Markov\ninteger-valued process $(X_n)_{n=0}^{\\infty}$, whose jump at time $n$ depends\non the number of visits to the site $X_n$. The environment can be understood as\nstacks of cookies on each site of $\\mathbb Z$. Once all cookies are consumed at\na given site, every subsequent visit will result in a walk taking a step\naccording to the direction prescribed by the last consumed cookie. If each site\nhas exactly one cookie, then the walk ends in a loop if it ever visits the same\nsite twice. If the number of cookies per site is increased to two, the walk can\nvisit a site infinitely many times and still not end in a loop. Nevertheless\nthe moments of $X_n$ are sub-linear in $n$ and we establish monotonicity\nresults on the environment that imply large deviations. \n\n"}
{"id": "1410.5341", "contents": "Title: On obtaining simple identities for overshoots of spectrally negative\n  L\\'evy processes Abstract: For a (killed) spectrally negative L\\'evy process we provide an analytic\nexpression for the distribution of its overshoot over a fixed level in terms of\nthe infinitesimal generator and the scale function of the process. Our identity\ninvolves an auxiliary function and the simplicity of the identity depends very\nmuch on the choice of this function. In particular, for specific choices one\nrecovers various previous established formulas in the literature. We review\nseveral applications and also show that one can get in a similar way identities\nof overshoots for reflected and refracted spectrally negative L\\'evy processes. \n\n"}
{"id": "1410.6879", "contents": "Title: Sticky central limit theorems at isolated hyperbolic planar\n  singularities Abstract: We derive the limiting distribution of the barycenter $b_n$ of an i.i.d.\nsample of $n$ random points on a planar cone with angular spread larger than\n$2\\pi$. There are three mutually exclusive possibilities: (i) (fully sticky\ncase) after a finite random time the barycenter is almost surely at the origin;\n(ii) (partly sticky case) the limiting distribution of $\\sqrt{n} b_n$ comprises\na point mass at the origin, an open sector of a Gaussian, and the projection of\na Gaussian to the sector's bounding rays; or (iii) (nonsticky case) the\nbarycenter stays away from the origin and the renormalized fluctuations have a\nfully supported limit distribution---usually Gaussian but not always. We\nconclude with an alternative, topological definition of stickiness that\ngeneralizes readily to measures on general metric spaces. \n\n"}
{"id": "1410.8003", "contents": "Title: Upper bounds on product and multiplier empirical processes Abstract: We study two empirical process of special structure: firstly, the centred\nmultiplier process indexed by a class $F$, $f \\to \\left|\\sum_{i=1}^N (\\xi_i\nf(X_i) - \\E \\xi f)\\right|$, where the i.i.d. multipliers $(\\xi_i)_{i=1}^N$ need\nnot be independent of $(X_i)_{i=1}^N$, and secondly, $(f,h) \\to\n\\left|\\sum_{i=1}^N (f(X_i)h(X_i)-\\E f h) \\right|$, the centred product process\nindexed by the classes $F$ and $H$.\n  We use chaining methods to obtain high probability upper bounds on the\nsuprema of the two processes using a natural variation of Talagrand's\n$\\gamma$-functionals. \n\n"}
{"id": "1410.8257", "contents": "Title: Stochastic Komatu-Loewner evolutions and BMD domain constant Abstract: Let $D={\\mathbb H} \\setminus \\cup_{k=1}^N C_k$ be a standard slit domain,\nwhere ${\\mathbb H}$ is the upper half plane and $C_k$, $1\\leq k\\leq N$, are\nmutually disjoint horizontal line segments in $H$. Given a Jordan arc\n$\\gamma\\subset D$ starting at $\\partial H$, let $g_t$ be the unique conformal\nmap from $D\\setminus\\gamma[0,t]$ onto a standard slit domain $D_t={\\mathbb H}\n\\setminus \\cup_{k=1}^N C_k(t)$ satisfying the hydrodynamic normalization at\ninfinity. It has been established recently that $g_t$ satisfies an ODE called a\nKomatu-Loewner equation in terms of the complex Poisson kernel of the Brownian\nmotion with darning (BMD) for $D_t$.\n  We randomize the Jordan arc $\\gamma$ according to a system of probability\nmeasures on the family of equivalence classes of Jordan arcs that enjoy a\ndomain Markov property and a certain conformal invariance property. We show\nthat the induced process $(\\xi(t), {\\bf s}(t))$ satisfies a Markov type\nstochastic differential equation, where $\\xi(t)$ is a motion on $\\partial\n{\\mathbb H}$ and ${\\bf} s(t)$ represents the motion of the endpoints of the\nslits $\\{C_k(t),\\; 1\\le k\\le N \\}.$\n  Conversely, given such functions $\\alpha$ and $b$ with local Lipschitz\ncontinuity, the corresponding SDE admits a unique solution $(\\xi(t), {\\bf\ns}(t))$. The latter produces random conformal maps $g_t(z)$ via the\nKomatu-Loewner equation. The resulting family of random growing hulls $\\{F_t\\}$\nfrom the conformal mappings is called ${\\rm SKLE}_{\\alpha,b}.$ We show that it\nenjoys a certain scaling property and a domain Markov property. Among other\nthings, we further prove that ${\\rm SKLE}_{\\alpha,-b_{\\rm BMD}}$ for a constant\n$\\alpha >0$ has a locality property if and only if $\\alpha = \\sqrt{6}$, where\n$b_{\\rm BMD}$ is a BMD-domain constant that describes the discrepancy of a\nstandard slit domain from ${\\mathbb H}$ relative to BMD. \n\n"}
{"id": "1411.0610", "contents": "Title: Planting colourings silently Abstract: Let $k\\geq3$ be a fixed integer and let $Z_k(G)$ be the number of\n$k$-colourings of the graph $G$. For certain values of the average degree, the\nrandom variable $Z_k(G(n,m))$ is known to be concentrated in the sense that\n$\\frac1n(\\ln Z_k(G(n,m))-\\ln E[Z_k(G(n,m))])$ converges to $0$ in probability\n[Achlioptas and Coja-Oghlan: FOCS 2008]. In the present paper we prove a\nsignificantly stronger concentration result. Namely, we show that for a wide\nrange of average degrees, $\\frac1\\omega(\\ln Z_k(G(n,m))-\\ln E[Z_k(G(n,m))])$\nconverges to $0$ in probability for any diverging function\n$\\omega=\\omega(n)\\to\\infty$. For $k$ exceeding a certain constant $k_0$ this\nresult covers all average degrees up to the so-called condensation phase\ntransition, and this is best possible. As an application, we show that the\nexperiment of choosing a $k$-colouring of the random graph $G(n,m)$ uniformly\nat random is contiguous with respect to the so-called \"planted model\". \n\n"}
{"id": "1411.2752", "contents": "Title: Infinite Dimensional Ornstein-Uhlenbeck Processes Driven by Levy\n  Processes Abstract: We review the probabilistic properties of Ornstein-Uhlenbeck processes in\nHilbert spaces driven by L\\'{e}vy processes. The emphasis is on the different\ncontexts in which these processes arise, such as stochastic partial\ndifferential equations, continuous-state branching processes, generalised\nMehler semigroups and operator self-decomposable distributions. We also examine\ngeneralisations to the case where the driving noise is cylindrical. \n\n"}
{"id": "1411.3062", "contents": "Title: Structural Change in Sparsity Abstract: In the high-dimensional sparse modeling literature, it has been crucially\nassumed that the sparsity structure of the model is homogeneous over the entire\npopulation. That is, the identities of important regressors are invariant\nacross the population and across the individuals in the collected sample. In\npractice, however, the sparsity structure may not always be invariant in the\npopulation, due to heterogeneity across different sub-populations. We consider\na general, possibly non-smooth M-estimation framework, allowing a possible\nstructural change regarding the identities of important regressors in the\npopulation. Our penalized M-estimator not only selects covariates but also\ndiscriminates between a model with homogeneous sparsity and a model with a\nstructural change in sparsity. As a result, it is not necessary to know or\npretest whether the structural change is present, or where it occurs. We derive\nasymptotic bounds on the estimation loss of the penalized M-estimators, and\nachieve the oracle properties. We also show that when there is a structural\nchange, the estimator of the threshold parameter is super-consistent. If the\nsignal is relatively strong, the rates of convergence can be further improved\nand asymptotic distributional properties of the estimators including the\nthreshold estimator can be established using an adaptive penalization. The\nproposed methods are then applied to quantile regression and logistic\nregression models and are illustrated via Monte Carlo experiments. \n\n"}
{"id": "1411.3688", "contents": "Title: Dimension-independent likelihood-informed MCMC Abstract: Many Bayesian inference problems require exploring the posterior distribution\nof high-dimensional parameters that represent the discretization of an\nunderlying function. This work introduces a family of Markov chain Monte Carlo\n(MCMC) samplers that can adapt to the particular structure of a posterior\ndistribution over functions. Two distinct lines of research intersect in the\nmethods developed here. First, we introduce a general class of\noperator-weighted proposal distributions that are well defined on function\nspace, such that the performance of the resulting MCMC samplers is independent\nof the discretization of the function. Second, by exploiting local Hessian\ninformation and any associated low-dimensional structure in the change from\nprior to posterior distributions, we develop an inhomogeneous discretization\nscheme for the Langevin stochastic differential equation that yields\noperator-weighted proposals adapted to the non-Gaussian structure of the\nposterior. The resulting dimension-independent, likelihood-informed (DILI) MCMC\nsamplers may be useful for a large class of high-dimensional problems where the\ntarget probability measure has a density with respect to a Gaussian reference\nmeasure. Two nonlinear inverse problems are used to demonstrate the efficiency\nof these DILI samplers: an elliptic PDE coefficient inverse problem and path\nreconstruction in a conditioned diffusion. \n\n"}
{"id": "1411.4438", "contents": "Title: Solving finite time horizon Dynkin games by optimal switching Abstract: This paper uses recent results on continuous-time finite-horizon optimal\nswitching problems with negative switching costs to prove the existence of a\nsaddle point in an optimal stopping (Dynkin) game. Sufficient conditions for\nthe game's value to be continuous with respect to the time horizon are obtained\nusing recent results on norm estimates for doubly reflected backward stochastic\ndifferential equations. This theory is then demonstrated numerically for the\nspecial cases of cancellable call and put options in a Black-Scholes market. \n\n"}
{"id": "1411.4564", "contents": "Title: A comparison of inferential methods for highly non-linear state space\n  models in ecology and epidemiology Abstract: Highly non-linear, chaotic or near chaotic, dynamic models are important in\nfields such as ecology and epidemiology: for example, pest species and diseases\noften display highly non-linear dynamics. However, such models are problematic\nfrom the point of view of statistical inference. The defining feature of\nchaotic and near chaotic systems is extreme sensitivity to small changes in\nsystem states and parameters, and this can interfere with inference. There are\ntwo main classes of methods for circumventing these difficulties: information\nreduction approaches, such as Approximate Bayesian Computation or Synthetic\nLikelihood and state space methods, such as Particle Markov chain Monte Carlo,\nIterated Filtering or Parameter Cascading. The purpose of this article is to\ncompare the methods, in order to reach conclusions about how to approach\ninference with such models in practice. We show that neither class of methods\nis universally superior to the other. We show that state space methods can\nsuffer multimodality problems in settings with low process noise or model\nmis-specification, leading to bias toward stable dynamics and high process\nnoise. Information reduction methods avoid this problem but, under the correct\nmodel and with sufficient process noise, state space methods lead to\nsubstantially sharper inference than information reduction methods. More\npractically, there are also differences in the tuning requirements of different\nmethods. Our overall conclusion is that model development and checking should\nprobably be performed using an information reduction method with low tuning\nrequirements, while for final inference it is likely to be better to switch to\na state space method, checking results against the information reduction\napproach. \n\n"}
{"id": "1411.6669", "contents": "Title: Optimizing The Integrator Step Size for Hamiltonian Monte Carlo Abstract: Hamiltonian Monte Carlo can provide powerful inference in complex statistical\nproblems, but ultimately its performance is sensitive to various tuning\nparameters. In this paper we use the underlying geometry of Hamiltonian Monte\nCarlo to construct a universal optimization criteria for tuning the step size\nof the symplectic integrator crucial to any implementation of the algorithm as\nwell as diagnostics to monitor for any signs of invalidity. An immediate\noutcome of this result is that the suggested target average acceptance\nprobability of 0.651 can be relaxed to $0.6 \\lesssim a \\lesssim 0.9$ with\nlarger values more robust in practice. \n\n"}
{"id": "1411.6834", "contents": "Title: Asymptotic density of zeros of half range generalized Hermite\n  polynomials Abstract: We investigate the global density of zeros of generalized Hermite orthogonal\npolynomials, subject to certain truncated conditions on its weight. We shall\ngiven explicitly the global density of zeros under some asymptotic conditions\non the weight. Moreover we compute the asymptotic of the total energy of the\nequilibrium position of the system of $n$ movable unit charges in an external\nfield determined by the weight of the generalized Hermite polynomials. We will\nsee that for finite $n$ the energy is in direct relationship with the zeros of\nthe orthogonal polynomials. \n\n"}
{"id": "1412.0753", "contents": "Title: Convex clustering via $\\ell_1$ fusion penalization Abstract: We study the large sample behavior of a convex clustering framework, which\nminimizes the sample within cluster sum of squares under an~$\\ell_1$ fusion\nconstraint on the cluster centroids. This recently proposed approach has been\ngaining in popularity, however, its asymptotic properties have remained mostly\nunknown. Our analysis is based on a novel representation of the sample\nclustering procedure as a sequence of cluster splits determined by a sequence\nof maximization problems. We use this representation to provide a simple and\nintuitive formulation for the population clustering procedure. We then\ndemonstrate that the sample procedure consistently estimates its population\nanalog, and derive the corresponding rates of convergence. The proof conducts a\ncareful simultaneous analysis of a collection of M-estimation problems, whose\ncardinality grows together with the sample size. Based on the new perspectives\ngained from the asymptotic investigation, we propose a key post-processing\nmodification of the original clustering framework. We show, both theoretically\nand empirically, that the resulting approach can be successfully used to\nestimate the number of clusters in the population. Using simulated data, we\ncompare the proposed method with existing number of clusters and modality\nassessment approaches, and obtain encouraging results. We also demonstrate the\napplicability of our clustering method for the detection of cellular\nsubpopulations in a single-cell virology study. \n\n"}
{"id": "1412.1373", "contents": "Title: A Generalized Convolution Model and Estimation for Non-stationary Random\n  Functions Abstract: Standard geostatistical models assume second order stationarity of the\nunderlying Random Function. In some instances, there is little reason to expect\nthe spatial dependence structure to be stationary over the whole region of\ninterest. In this paper, we introduce a new model for second order\nnon-stationary Random Functions as a convolution of an orthogonal random\nmeasure with a spatially varying random weighting function. This new model is a\ngeneralization of the common convolution model where a non-random weighting\nfunction is used. The resulting class of non-stationary covariance functions is\nvery general, flexible and allows to retrieve classes of closed-form\nnon-stationary covariance functions known from the literature, for a suitable\nchoices of the random weighting functions family. Under the framework of a\nsingle realization and local stationarity, we develop parameter inference\nprocedure of these explicit classes of non-stationary covariance functions.\nFrom a local variogram non-parametric kernel estimator, a weighted local\nleast-squares approach in combination with kernel smoothing method is developed\nto estimate the parameters. Performances are assessed on two real datasets:\nsoil and rainfall data. It is shown in particular that the proposed approach\noutperforms the stationary one, according to several criteria. Beyond the\nspatial predictions, we also show how conditional simulations can be carried\nout in this non-stationary framework. \n\n"}
{"id": "1412.1559", "contents": "Title: Iterative Subsampling in Solution Path Clustering of Noisy Big Data Abstract: We develop an iterative subsampling approach to improve the computational\nefficiency of our previous work on solution path clustering (SPC). The SPC\nmethod achieves clustering by concave regularization on the pairwise distances\nbetween cluster centers. This clustering method has the important capability to\nrecognize noise and to provide a short path of clustering solutions; however,\nit is not sufficiently fast for big datasets. Thus, we propose a method that\niterates between clustering a small subsample of the full data and sequentially\nassigning the other data points to attain orders of magnitude of computational\nsavings. The new method preserves the ability to isolate noise, includes a\nsolution selection mechanism that ultimately provides one clustering solution\nwith an estimated number of clusters, and is shown to be able to extract small\ntight clusters from noisy data. The method's relatively minor losses in\naccuracy are demonstrated through simulation studies, and its ability to handle\nlarge datasets is illustrated through applications to gene expression datasets.\nAn R package, SPClustering, for the SPC method with iterative subsampling is\navailable at http://www.stat.ucla.edu/~zhou/Software.html. \n\n"}
{"id": "1412.1716", "contents": "Title: Nonparametric modal regression Abstract: Modal regression estimates the local modes of the distribution of $Y$ given\n$X=x$, instead of the mean, as in the usual regression sense, and can hence\nreveal important structure missed by usual regression methods. We study a\nsimple nonparametric method for modal regression, based on a kernel density\nestimate (KDE) of the joint distribution of $Y$ and $X$. We derive asymptotic\nerror bounds for this method, and propose techniques for constructing\nconfidence sets and prediction sets. The latter is used to select the smoothing\nbandwidth of the underlying KDE. The idea behind modal regression is connected\nto many others, such as mixture regression and density ridge estimation, and we\ndiscuss these ties as well. \n\n"}
{"id": "1412.4724", "contents": "Title: Necessary and Sufficient Conditions for Extended Noncontextuality in a\n  Broad Class of Quantum Mechanical Systems Abstract: The notion of (non)contextuality pertains to sets of properties measured one\nsubset (context) at a time. We extend this notion to include so-called\ninconsistently connected systems, in which the measurements of a given property\nin different contexts may have different distributions, due to contextual\nbiases in experimental design or physical interactions (signaling): a system of\nmeasurements has a maximally noncontextual description if they can be imposed a\njoint distribution on in which the measurements of any one property in\ndifferent contexts are equal to each other with the maximal probability allowed\nby their different distributions. We derive necessary and sufficient conditions\nfor the existence of such a description in a broad class of systems including\nKlyachko-Can-Binicio\\u{g}lu-Shumvosky-type (KCBS), EPR-Bell-type, and\nLeggett-Garg-type systems. Because these conditions allow for inconsistent\nconnectedness, they are applicable to real experiments. We illustrate this by\nanalyzing an experiment by Lapkiewicz and colleagues aimed at testing\ncontextuality in a KCBS-type system. \n\n"}
{"id": "1412.6231", "contents": "Title: Efficient strategy for the Markov chain Monte Carlo in high-dimension\n  with heavy-tailed target probability distribution Abstract: The purpose of this paper is to introduce a new Markov chain Monte Carlo\nmethod and exhibit its efficiency by simulation and high-dimensional asymptotic\ntheory. Key fact is that our algorithm has a reversible proposal transition\nkernel, which is designed to have a heavy-tailed invariant probability\ndistribution. The high-dimensional asymptotic theory is studied for a class of\nheavy-tailed target probability distribution. As the number of dimension of the\nstate space goes to infinity, we will show that our algorithm has a much better\nconvergence rate than that of the preconditioned Crank Nicolson (pCN) algorithm\nand the random-walk Metropolis (RWM) algorithm. We also show that our algorithm\nis at least as good as the pCN algorithm and better than the RWM algorithm for\nlight-tailed target probability distribution. \n\n"}
{"id": "1412.8732", "contents": "Title: Parametrix construction of the transition probability density of the\n  solution to an SDE driven by $\\alpha$-stable noise Abstract: Let $L:= -a(x) (-\\Delta)^{\\alpha/2}+ (b(x), \\nabla)$, where $\\alpha\\in\n(0,2)$, and $a:\\rd\\to (0,\\infty)$, $b: \\rd\\to \\rd$. Under certain regularity\nassumptions on the coefficients $a$ and $b$, we associate with the\n$C_\\infty(\\rd)$-closure of $(L, C_\\infty^2(\\rd))$ a Feller Markov process $X$,\nwhich possesses a transition probability density $p_t(x,y)$.\n  To construct this transition probability density and to obtain the two-sided\nestimates on it, we develop a new version of the parametrix method, which\nallows us to handle the case $0<\\alpha\\leq 1$ and $b\\neq 0$, i.e. when the\ngradient part of the generator is not dominated by the jump part.. \n\n"}
{"id": "1501.02982", "contents": "Title: On flows associated to Tanaka's SDE and related works Abstract: We review the construction of flows associated to Tanaka's SDE from [9] and\ngive an easy proof of the classification of these flows by means of probability\nmeasures on [0, 1]. Our arguments also simplify some proofs in the subsequent\npapers [2, 3, 7, 4]. \n\n"}
{"id": "1501.04541", "contents": "Title: Finite energy coordinates and vector analysis on fractals Abstract: We consider (locally) energy finite coordinates associated with a strongly\nlocal regular Dirichlet form on a metric measure space. We give coordinate\nformulas for substitutes of tangent spaces, for gradient and divergence\noperators and for the infinitesimal generator. As examples we discuss Euclidean\nspaces, Riemannian local charts, domains on the Heisenberg group and the\nmeasurable Riemannian geometry on the Sierpinski gasket. \n\n"}
{"id": "1501.06191", "contents": "Title: Global well-posedness of the dynamic $\\Phi^4$ model in the plane Abstract: We show global well-posedness of the dynamic $\\Phi^4$ model in the plane. The\nmodel is a non-linear stochastic PDE that can only be interpreted in a\n\"renormalised\" sense. Solutions take values in suitable weighted Besov spaces\nof negative regularity. \n\n"}
{"id": "1501.06822", "contents": "Title: Heat semigroup and singular PDEs Abstract: We provide in this work a semigroup approach to the study of singular PDEs,\nin the line of the paracontrolled approach developed recently by Gubinelli,\nImkeller and Perkowski. Starting from a heat semigroup, we develop a functional\ncalculus and introduce a paraproduct based on the semigroup, for which\ncommutator estimates and Schauder estimates are proved, together with their\nparacontrolled extensions. This machinery allows us to investigate singular\nPDEs in potentially unbounded Riemannian manifolds under mild geometric\nconditions. As an illustration, we study the generalized parabolic Anderson\nmodel equation and prove, under mild geometric conditions, its well-posed\ncharacter in Holders spaces, in small time on a potentially unbounded\n2-dimensional Riemannian manifold, for an equation driven by a weighted noise,\nand for all times for the linear parabolic Anderson model equation in\n2-dimensional unbounded manifolds. This machinery can be extended to an even\nmore singular setting and deal with Sobolev scales of spaces rather than Holder\nspaces. \n\n"}
{"id": "1502.00400", "contents": "Title: k-Connectivity of Random Key Graphs Abstract: Random key graphs represent topologies of secure wireless sensor networks\nthat apply the seminal Eschenauer-Gligor random key predistribution scheme to\nsecure communication between sensors. These graphs have received much attention\nand also been used in diverse application areas beyond secure sensor networks;\ne.g., cryptanalysis, social networks, and recommender systems. Formally, a\nrandom key graph with $n$ nodes is constructed by assigning each node $X_n$\nkeys selected uniformly at random from a pool of $Y_n$ keys and then putting an\nundirected edge between any two nodes sharing at least one key. Considerable\nprogress has been made in the literature to analyze connectivity and\n$k$-connectivity of random key graphs, where $k$-connectivity of a graph\nensures connectivity even after the removal of $k$ nodes or $k$ edges. Yet, it\nstill remains an open question for $k$-connectivity in random key graphs under\n$X_n \\geq 2$ and $X_n = o(\\sqrt{\\ln n})$ (the case of $X_n=1$ is trivial). In\nthis paper, we answer the above problem by providing an exact analysis of\n$k$-connectivity in random key graphs under $X_n \\geq 2$. \n\n"}
{"id": "1502.00405", "contents": "Title: Monotone Increasing Properties and Their Phase Transitions in Uniform\n  Random Intersection Graphs Abstract: Uniform random intersection graphs have received much interest and been used\nin diverse applications. A uniform random intersection graph with $n$ nodes is\nconstructed as follows: each node selects a set of $K_n$ different items\nuniformly at random from the same pool of $P_n$ distinct items, and two nodes\nestablish an undirected edge in between if and only if they share at least one\nitem. For such graph denoted by $G(n, K_n, P_n)$, we present the following\nresults in this paper. First, we provide an exact analysis on the probabilities\nof $G(n, K_n, P_n)$ having a perfect matching and having a Hamilton cycle\nrespectively, under $P_n = \\omega\\big(n (\\ln n)^5\\big)$ (all asymptotic\nnotation are understood with $n \\to \\infty$). The analysis reveals that just\nlike ($k$-)connectivity shown in prior work, for both properties of perfect\nmatching containment and Hamilton cycle containment, $G(n, K_n, P_n)$ also\nexhibits phase transitions: for each property above, as $K_n$ increases, the\nlimit of the probability that $G(n, K_n, P_n)$ has the property increases from\n$0$ to $1$. Second, we compute the phase transition widths of $G(n, K_n, P_n)$\nfor $k$-connectivity (KC), perfect matching containment (PMC), and Hamilton\ncycle containment (HCC), respectively. For a graph property $R$ and a positive\nconstant $a < \\frac{1}{2}$, with the phase transition width $d_n(R, a)$ defined\nas the difference between the minimal $K_n$ ensuring $G(n, K_n, P_n)$ having\nproperty $R$ with probability at least $1-a$ or $a$, we show for any positive\nconstants $a<\\frac{1}{2}$ and $k$: (i) If $P_n=\\Omega(n)$ and $P_n=o(n\\ln n)$,\nthen $d_n(KC, a)$ is either $0$ or $1$ for each $n$ sufficiently large. (ii) If\n$P_n=\\Theta(n\\ln n)$, then $d_n(KC, a)=\\Theta(1)$. (iii) If $P_n=\\omega(n\\ln\nn)$, then $d_n(KC, a)=\\omega(1)$. (iv) If $P_n=\\omega\\big(n (\\ln n)^5\\big)$,\n$d_n(PMC, a)$ and $d_n(HCC, a)$ are both $\\omega(1)$. \n\n"}
{"id": "1502.00532", "contents": "Title: Transition from Gaussian to non-Gaussian fluctuations for mean-field\n  diffusions in spatial interaction Abstract: We consider a system of $N$ disordered mean-field interacting diffusions\nwithin spatial constraints: each particle $\\theta_i$ is attached to one site\n$x_i$ of a periodic lattice and the interaction between particles $\\theta_i$\nand $\\theta_j$ decreases as $| x_i-x_j|^{-\\alpha}$ for $\\alpha\\in[0,1)$. In a\nprevious work, it was shown that the empirical measure of the particles\nconverges in large population to the solution of a nonlinear partial\ndifferential equation of McKean-Vlasov type. The purpose of the present paper\nis to study the fluctuations associated to this convergence. We exhibit in\nparticular a phase transition in the scaling and in the nature of the\nfluctuations: when $\\alpha\\in[0,\\frac{1}{2})$, the fluctuations are Gaussian,\ngoverned by a linear SPDE, with scaling $\\sqrt{N}$ whereas the fluctuations are\ndeterministic with scaling $N^{1-\\alpha}$ in the case\n$\\alpha\\in(\\frac{1}{2},1)$. \n\n"}
{"id": "1502.01426", "contents": "Title: Strong law of large numbers for supercritical superprocesses under\n  second moment condition Abstract: Suppose that $X=\\{X_t, t\\ge 0\\}$ is a supercritical superprocess on a locally\ncompact separable metric space $(E, m)$. Suppose that the spatial motion of $X$\nis a Hunt process satisfying certain conditions and that the branching\nmechanism is of the form $$\n\\psi(x,\\lambda)=-a(x)\\lambda+b(x)\\lambda^2+\\int_{(0,+\\infty)}(e^{-\\lambda\ny}-1+\\lambda y)n(x,dy), \\quad x\\in E, \\quad\\lambda> 0, $$ where $a\\in\n\\mathcal{B}_b(E)$, $b\\in \\mathcal{B}_b^+(E)$ and $n$ is a kernel from $E$ to\n$(0,\\infty)$ satisfying $$\n  \\sup_{x\\in E}\\int_0^\\infty y^2 n(x,dy)<\\infty. $$ Put\n$T_tf(x)=\\mathbb{P}_{\\delta_x}< f,X_t>$. Let $\\lambda_0>0$ be the largest\neigenvalue of the generator $L$ of $T_t$, and $\\phi_0$ and $\\hat{\\phi}_0$ be\nthe eigenfunctions of $L$ and $\\hat{L}$ (the dural of $L$) respectively\nassociated with $\\lambda_0$. Under some conditions on the spatial motion and\nthe $\\phi_0$-transformed semigroup of $T_t$, we prove that for a large class of\nsuitable functions $f$, we have $$ \\lim_{t\\rightarrow\\infty}e^{-\\lambda_0 t}<\nf, X_t> = W_\\infty\\int_E\\hat{\\phi}_0(y)f(y)m(dy),\\quad \\mathbb{P}_{\\mu}{-a.s.},\n$$ for any finite initial measure $\\mu$ on $E$ with compact support, where\n$W_\\infty$ is the martingale limit defined by\n$W_\\infty:=\\lim_{t\\to\\infty}e^{-\\lambda_0t}< \\phi_0, X_t>$. Moreover, the\nexceptional set in the above limit does not depend on the initial measure $\\mu$\nand the function $f$. \n\n"}
{"id": "1502.01974", "contents": "Title: Regionalization of Multiscale Spatial Processes using a Criterion for\n  Spatial Aggregation Error Abstract: The modifiable areal unit problem and the ecological fallacy are known\nproblems that occur when modeling multiscale spatial processes. We investigate\nhow these forms of spatial aggregation error can guide a regionalization over a\nspatial domain of interest. By \"regionalization\" we mean a specification of\ngeographies that define the spatial support for areal data. This topic has been\nstudied vigorously by geographers, but has been given less attention by spatial\nstatisticians. Thus, we propose a criterion for spatial aggregation error\n(CAGE), which we minimize to obtain an optimal regionalization. To define CAGE\nwe draw a connection between spatial aggregation error and a new multiscale\nrepresentation of the Karhunen-Loeve (K-L) expansion. This relationship between\nCAGE and the multiscale K-L expansion leads to illuminating theoretical\ndevelopments including: connections between spatial aggregation error, squared\nprediction error, spatial variance, and a novel extension of Obled-Creutin\neigenfunctions. The effectiveness of our approach is demonstrated through an\nanalysis of two datasets, one using the American Community Survey and one\nrelated to environmental ocean winds. \n\n"}
{"id": "1502.02008", "contents": "Title: Stochastic Newton Sampler: R Package sns Abstract: The R package sns implements Stochastic Newton Sampler (SNS), a\nMetropolis-Hastings Monte Carlo Markov Chain algorithm where the proposal\ndensity function is a multivariate Gaussian based on a local, second-order\nTaylor series expansion of log-density. The mean of the proposal function is\nthe full Newton step in Newton-Raphson optimization algorithm. Taking advantage\nof the local, multivariate geometry captured in log-density Hessian allows SNS\nto be more efficient than univariate samplers, approaching independent sampling\nas the density function increasingly resembles a multivariate Gaussian. SNS\nrequires the log-density Hessian to be negative-definite everywhere in order to\nconstruct a valid proposal function. This property holds, or can be easily\nchecked, for many GLM-like models. When initial point is far from density peak,\nrunning SNS in non-stochastic mode by taking the Newton step, augmented with\nwith line search, allows the MCMC chain to converge to high-density areas\nfaster. For high-dimensional problems, partitioning of state space into\nlower-dimensional subsets, and applying SNS to the subsets within a Gibbs\nsampling framework can significantly improve the mixing of SNS chains. In\naddition to the above strategies for improving convergence and mixing, sns\noffers diagnostics and visualization capabilities, as well as a function for\nsample-based calculation of Bayesian predictive posterior distributions. \n\n"}
{"id": "1502.02217", "contents": "Title: Bifractional Brownian motion: existence and border cases Abstract: Bifractional Brownian motion (bfBm) is a centered Gaussian process with\ncovariance \\[\n  R^{(H,K)}(s,t)=\n  2^{-K} \\left( \\left(|s|^{2H}+|t|^{2H} \\right)^{K}-|t-s|^{2HK}\\right),\n  \\qquad s,t\\in R. \\] We study the existence of bfBm for a given pair of\nparameters $(H,K)$ and encounter some related limiting processes. \n\n"}
{"id": "1502.02501", "contents": "Title: A CLT for an improved subspace estimator with observations of increasing\n  dimensions Abstract: This paper deals with subspace estimation in the small sample size regime,\nwhere the number of samples is comparable in magnitude with the observation\ndimension. The traditional estimators, mostly based on the sample correlation\nmatrix, are known to perform well as long as the number of available samples is\nmuch larger than the observation dimension. However, in the small sample size\nregime, the performance degrades. Recently, based on random matrix theory\nresults, a new subspace estimator was introduced, which was shown to be\nconsistent in the asymptotic regime where the number of samples and the\nobservation dimension converge to infinity at the same rate. In practice, this\nestimator outperforms the traditional ones even for certain scenarios where the\nobservation dimension is small and of the same order of magnitude as the number\nof samples. In this paper, we address a performance analysis of this recent\nestimator, by proving a central limit theorem in the above asymptotic regime.\nWe propose an accurate approximation of the mean square error, which can be\nevaluated numerically. \n\n"}
{"id": "1502.03391", "contents": "Title: Fast Embedding for JOFC Using the Raw Stress Criterion Abstract: The Joint Optimization of Fidelity and Commensurability (JOFC) manifold\nmatching methodology embeds an omnibus dissimilarity matrix consisting of\nmultiple dissimilarities on the same set of objects. One approach to this\nembedding optimizes the preservation of fidelity to each individual\ndissimilarity matrix together with commensurability of each given observation\nacross modalities via iterative majorization of a raw stress error criterion by\nsuccessive Guttman transforms. In this paper, we exploit the special structure\ninherent to JOFC to exactly and efficiently compute the successive Guttman\ntransforms, and as a result we are able to greatly speed up the JOFC procedure\nfor both in-sample and out-of-sample embedding. We demonstrate the scalability\nof our implementation on both real and simulated data examples. \n\n"}
{"id": "1502.05503", "contents": "Title: Classification and Bayesian Optimization for Likelihood-Free Inference Abstract: Some statistical models are specified via a data generating process for which\nthe likelihood function cannot be computed in closed form. Standard\nlikelihood-based inference is then not feasible but the model parameters can be\ninferred by finding the values which yield simulated data that resemble the\nobserved data. This approach faces at least two major difficulties: The first\ndifficulty is the choice of the discrepancy measure which is used to judge\nwhether the simulated data resemble the observed data. The second difficulty is\nthe computationally efficient identification of regions in the parameter space\nwhere the discrepancy is low. We give here an introduction to our recent work\nwhere we tackle the two difficulties through classification and Bayesian\noptimization. \n\n"}
{"id": "1502.06197", "contents": "Title: On Online Control of False Discovery Rate Abstract: Multiple hypotheses testing is a core problem in statistical inference and\narises in almost every scientific field. Given a sequence of null hypotheses\n$\\mathcal{H}(n) = (H_1,..., H_n)$, Benjamini and Hochberg\n\\cite{benjamini1995controlling} introduced the false discovery rate (FDR)\ncriterion, which is the expected proportion of false positives among rejected\nnull hypotheses, and proposed a testing procedure that controls FDR below a\npre-assigned significance level. They also proposed a different criterion,\ncalled mFDR, which does not control a property of the realized set of tests;\nrather it controls the ratio of expected number of false discoveries to the\nexpected number of discoveries.\n  In this paper, we propose two procedures for multiple hypotheses testing that\nwe will call \"LOND\" and \"LORD\". These procedures control FDR and mFDR in an\n\\emph{online manner}. Concretely, we consider an ordered --possibly infinite--\nsequence of null hypotheses $\\mathcal{H} = (H_1,H_2,H_3,...)$ where, at each\nstep $i$, the statistician must decide whether to reject hypothesis $H_i$\nhaving access only to the previous decisions. To the best of our knowledge, our\nwork is the first that controls FDR in this setting. This model was introduced\nby Foster and Stine \\cite{alpha-investing} whose alpha-investing rule only\ncontrols mFDR in online manner.\n  In order to compare different procedures, we develop lower bounds on the\ntotal discovery rate under the mixture model and prove that both LOND and LORD\nhave nearly linear number of discoveries. We further propose adjustment to LOND\nto address arbitrary correlation among the $p$-values. Finally, we evaluate the\nperformance of our procedures on both synthetic and real data comparing them\nwith alpha-investing rule, Benjamin-Hochberg method and a Bonferroni procedure. \n\n"}
{"id": "1502.06241", "contents": "Title: Mixture models with a prior on the number of components Abstract: A natural Bayesian approach for mixture models with an unknown number of\ncomponents is to take the usual finite mixture model with Dirichlet weights,\nand put a prior on the number of components---that is, to use a mixture of\nfinite mixtures (MFM). While inference in MFMs can be done with methods such as\nreversible jump Markov chain Monte Carlo, it is much more common to use\nDirichlet process mixture (DPM) models because of the relative ease and\ngenerality with which DPM samplers can be applied. In this paper, we show that,\nin fact, many of the attractive mathematical properties of DPMs are also\nexhibited by MFMs---a simple exchangeable partition distribution, restaurant\nprocess, random measure representation, and in certain cases, a stick-breaking\nrepresentation. Consequently, the powerful methods developed for inference in\nDPMs can be directly applied to MFMs as well. We illustrate with simulated and\nreal data, including high-dimensional gene expression data. \n\n"}
{"id": "1502.06267", "contents": "Title: Asymptotic analysis of symmetric functions Abstract: In this paper we consider asymptotic expansions for a class of sequences of\nsymmetric functions of many variables. Applications to classical and free\nprobability theory are discussed. \n\n"}
{"id": "1502.06449", "contents": "Title: Identifying Mixtures of Mixtures Using Bayesian Estimation Abstract: The use of a finite mixture of normal distributions in model-based clustering\nallows to capture non-Gaussian data clusters. However, identifying the clusters\nfrom the normal components is challenging and in general either achieved by\nimposing constraints on the model or by using post-processing procedures.\nWithin the Bayesian framework we propose a different approach based on sparse\nfinite mixtures to achieve identifiability. We specify a hierarchical prior\nwhere the hyperparameters are carefully selected such that they are reflective\nof the cluster structure aimed at. In addition this prior allows to estimate\nthe model using standard MCMC sampling methods. In combination with a\npost-processing approach which resolves the label switching issue and results\nin an identified model, our approach allows to simultaneously (1) determine the\nnumber of clusters, (2) flexibly approximate the cluster distributions in a\nsemi-parametric way using finite mixtures of normals and (3) identify\ncluster-specific parameters and classify observations. The proposed approach is\nillustrated in two simulation studies and on benchmark data sets. \n\n"}
{"id": "1502.06925", "contents": "Title: Modified logarithmic potential theory and applications Abstract: We develop potential theory including a Bernstein-Walsh type estimate for\nfunctions of the form $p(z)q(f(z))$ where $p,q$ are polynomials and $f$ is\nholomorphic. Such functions arise in the study of certain ensembles of\nprobability measures and our estimates lead to probabilistic results such as\nlarge deviation principles. \n\n"}
{"id": "1502.07963", "contents": "Title: Confidence Intervals for Maximin Effects in Inhomogeneous Large-Scale\n  Data Abstract: One challenge of large-scale data analysis is that the assumption of an\nidentical distribution for all samples is often not realistic. An optimal\nlinear regression might, for example, be markedly different for distinct groups\nof the data. Maximin effects have been proposed as a computationally attractive\nway to estimate effects that are common across all data without fitting a\nmixture distribution explicitly. So far just point estimators of the common\nmaximin effects have been proposed in Meinshausen and B\\\"uhlmann (2014). Here\nwe propose asymptotically valid confidence regions for these effects. \n\n"}
{"id": "1503.00357", "contents": "Title: Consistency of Importance Sampling estimates based on dependent sample\n  sets and an application to models with factorizing likelihoods Abstract: In this paper, I proof that Importance Sampling estimates based on dependent\nsample sets are consistent under certain conditions. This can be used to reduce\nvariance in Bayesian Models with factorizing likelihoods, using sample sets\nthat are much larger than the number of likelihood evaluations, a technique\ndubbed Sample Inflation. I evaluate Sample Inflation on a toy Gaussian problem\nand two Mixture Models. \n\n"}
{"id": "1503.00578", "contents": "Title: Scaling limit of fluctuations in stochastic homogenization Abstract: We investigate the global fluctuations of solutions to elliptic equations\nwith random coefficients in the discrete setting. In dimension $d\\geq 3$ and\nfor i.i.d.\\ coefficients, we show that after a suitable scaling, these\nfluctuations converge to a Gaussian field that locally resembles a\n(generalized) Gaussian free field. The paper begins with a heuristic derivation\nof the result, which can be read independently and was obtained jointly with\nScott Armstrong. \n\n"}
{"id": "1503.00917", "contents": "Title: A constant regression characterization of a Marchenko-Pastur law Abstract: Lukacs type characterization of Marchenko--Pastur distribution in free\nprobability is studied here. We prove that for free $\\mathbb{X}$ and\n$\\mathbb{Y}$ when conditional moments of order $1$ and $-1$ of\n$(\\mathbb{X+Y})^{-1/2}\\mathbb{X}(\\mathbb{X+Y})^{-1/2}$ given $\\mathbb{X+Y}$ are\nconstant then $\\mathbb{X}$ and $\\mathbb{Y}$ have Marchenko--Pastur\ndistribution. \n\n"}
{"id": "1503.01964", "contents": "Title: Quenched invariance principle for random walk in time-dependent balanced\n  random environment Abstract: We prove a quenched central limit theorem for balanced random walks in time\ndependent ergodic random environments which is not necessarily\nnearest-neigbhor. We assume that the environment satisfies appropriate\nergodicity and ellipticity conditions. The proof is based on the use of a\nmaximum principle for parabolic difference operators. \n\n"}
{"id": "1503.02255", "contents": "Title: Hypercontractivity for Functional Stochastic Partial Differential\n  Equations Abstract: Explicit sufficient conditions on the hypercontractivity are presented for\ntwo classes of functional stochastic partial differential equations driven by,\nrespectively, non-degenerate and degenerate Gaussian noises. Consequently,\nthese conditions imply that the associated Markov semigroup is $L^2$-compact\nand exponentially convergent to the stationary distribution in entropy,\nvariance and total variational norm.\n  As the log-Sobolev inequality is invalid under the framework, we apply a\ncriterion presented in the recent paper \\cite{Wang14} using Harnack inequality,\ncoupling property and Gaussian concentration property of the stationary\ndistribution. To verify the concentration property, we prove a Fernique type\ninequality for infinite-dimensional Gaussian processes which might be\ninteresting by itself. \n\n"}
{"id": "1503.03515", "contents": "Title: Bi-cross-validation for factor analysis Abstract: Factor analysis is over a century old, but it is still problematic to choose\nthe number of factors for a given data set. The scree test is popular but\nsubjective. The best performing objective methods are recommended on the basis\nof simulations. We introduce a method based on bi-cross-validation, using\nrandomly held-out submatrices of the data to choose the number of factors. We\nfind it performs better than the leading methods of parallel analysis (PA) and\nKaiser's rule. Our performance criterion is based on recovery of the underlying\nfactor-loading (signal) matrix rather than identifying the true number of\nfactors. Like previous comparisons, our work is simulation based. Recent\nadvances in random matrix theory provide principled choices for the number of\nfactors when the noise is homoscedastic, but not for the heteroscedastic case.\nThe simulations we choose are designed using guidance from random matrix\ntheory. In particular, we include factors too small to detect, factors large\nenough to detect but not large enough to improve the estimate, and two classes\nof factors large enough to be useful. Much of the advantage of\nbi-cross-validation comes from cases with factors large enough to detect but\ntoo small to be well estimated. We also find that a form of early stopping\nregularization improves the recovery of the signal matrix. \n\n"}
{"id": "1503.05614", "contents": "Title: Percolation games, probabilistic cellular automata, and the hard-core\n  model Abstract: Let each site of the square lattice $\\mathbb{Z}^2$ be independently assigned\none of three states: a \\textit{trap} with probability $p$, a \\textit{target}\nwith probability $q$, and \\textit{open} with probability $1-p-q$, where\n$0<p+q<1$. Consider the following game: a token starts at the origin, and two\nplayers take turns to move, where a move consists of moving the token from its\ncurrent site $x$ to either $x+(0,1)$ or $x+(1,0)$. A player who moves the token\nto a trap loses the game immediately, while a player who moves the token to a\ntarget wins the game immediately. Is there positive probability that the game\nis \\emph{drawn} with best play -- i.e.\\ that neither player can force a win?\nThis is equivalent to the question of ergodicity of a certain family of\nelementary one-dimensional probabilistic cellular automata (PCA). These\nautomata have been studied in the contexts of enumeration of directed lattice\nanimals, the golden-mean subshift, and the hard-core model, and their\nergodicity has been noted as an open problem by several authors. We prove that\nthese PCA are ergodic, and correspondingly that the game on $\\mathbb{Z}^2$ has\nno draws.\n  On the other hand, we prove that certain analogous games \\emph{do} exhibit\ndraws for suitable parameter values on various directed graphs in higher\ndimensions, including an oriented version of the even sublattice of\n$\\mathbb{Z}^d$ in all $d\\geq3$. This is proved via a dimension reduction to a\nhard-core lattice gas in dimension $d-1$. We show that draws occur whenever the\ncorresponding hard-core model has multiple Gibbs distributions. We conjecture\nthat draws occur also on the standard oriented lattice $\\mathbb{Z}^d$ for\n$d\\geq 3$, but here our method encounters a fundamental obstacle. \n\n"}
{"id": "1503.05909", "contents": "Title: Principal Components Analysis for Semimartingales and Stochastic PDE Abstract: In this work, we develop a novel principal component analysis (PCA) for\nsemimartingales by introducing a suitable spectral analysis for the quadratic\nvariation operator. Motivated by high-dimensional complex systems typically\nfound in interest rate markets, we investigate correlation in high-dimensional\nhigh-frequency data generated by continuous semimartingales. In contrast to the\ntraditional PCA methodology, the directions of large variations are not\ndeterministic, but rather they are bounded variation adapted processes which\nmaximize quadratic variation almost surely. This allows us to reduce\ndimensionality from high-dimensional semimartingale systems in terms of\nquadratic covariation rather than the usual covariance concept.\n  The proposed methodology allows us to investigate space-time data driven by\nmulti-dimensional latent semimartingale state processes. The theory is applied\nto discretely-observed stochastic PDEs which admit finite-dimensional\nrealizations. In particular, we provide consistent estimators for\nfinite-dimensional invariant manifolds for Heath-Jarrow-Morton models. More\nimportantly, components of the invariant manifold associated to volatility and\ndrift dynamics are consistently estimated and identified. The proposed\nmethodology is illustrated with both simulated and real data sets. \n\n"}
{"id": "1503.06249", "contents": "Title: Intermittency and multifractality: A case study via parabolic stochastic\n  PDEs Abstract: Let $\\xi$ denote space-time white noise, and consider the following\nstochastic partial differential equations:\n  (i) $\\dot{u}=\\frac{1}{2} u\" + u\\xi$, started identically at one; and (ii)\n$\\dot{Z}=\\frac12 Z\" + \\xi$, started identically at zero.\n  It is well known that the solution to (i) is intermittent, whereas the\nsolution to (ii) is not. And the two equations are known to be in different\nuniversality classes.\n  We prove that the tall peaks of both systems are multifractals in a natural\nlarge-scale sense. Some of this work is extended to also establish the\nmultifractal behavior of the peaks of stochastic PDEs on\n$\\mathbf{R}_+\\times\\mathbf{R}^d$ with $d\\ge 2$. G. Lawler has asked us if\nintermittency is the same as multifractality. The present work gives a negative\nanswer to this question.\n  As a byproduct of our methods, we prove also that the peaks of the Brownian\nmotion form a large-scale monofractal, whereas the peaks of the\nOrnstein--Uhlenbeck process on $\\mathbf{R}$ are multifractal.\n  Throughout, we make extensive use of the macroscopic fractal theory of M.T.\nBarlow and S. J. Taylor (1989, 1992). We expand on aspects of the Barlow-Taylor\ntheory, as well. \n\n"}
{"id": "1503.06426", "contents": "Title: High-dimensional inference in misspecified linear models Abstract: We consider high-dimensional inference when the assumed linear model is\nmisspecified. We describe some correct interpretations and corresponding\nsufficient assumptions for valid asymptotic inference of the model parameters,\nwhich still have a useful meaning when the model is misspecified. We largely\nfocus on the de-sparsified Lasso procedure but we also indicate some\nimplications for (multiple) sample splitting techniques. In view of available\nmethods and software, our results contribute to robustness considerations with\nrespect to model misspecification. \n\n"}
{"id": "1503.06876", "contents": "Title: Binary and Multi-Bit Coding for Stable Random Projections Abstract: We develop efficient binary (i.e., 1-bit) and multi-bit coding schemes for\nestimating the scale parameter of $\\alpha$-stable distributions. The work is\nmotivated by the recent work on one scan 1-bit compressed sensing (sparse\nsignal recovery) using $\\alpha$-stable random projections, which requires\nestimating of the scale parameter at bits-level. Our technique can be naturally\napplied to data stream computations for estimating the $\\alpha$-th frequency\nmoment. In fact, the method applies to the general scale family of\ndistributions, not limited to $\\alpha$-stable distributions.\n  Due to the heavy-tailed nature of $\\alpha$-stable distributions, using\ntraditional estimators will potentially need many bits to store each\nmeasurement in order to ensure sufficient accuracy. Interestingly, our paper\ndemonstrates that, using a simple closed-form estimator with merely 1-bit\ninformation does not result in a significant loss of accuracy if the parameter\nis chosen appropriately. For example, when $\\alpha=0+$, 1, and 2, the\ncoefficients of the optimal estimation variances using full (i.e.,\ninfinite-bit) information are 1, 2, and 2, respectively. With the 1-bit scheme\nand appropriately chosen parameters, the corresponding variance coefficients\nare 1.544, $\\pi^2/4$, and 3.066, respectively. Theoretical tail bounds are also\nprovided. Using 2 or more bits per measurements reduces the estimation variance\nand importantly, stabilizes the estimate so that the variance is not sensitive\nto parameters. With look-up tables, the computational cost is minimal. \n\n"}
{"id": "1503.08340", "contents": "Title: Statistical Properties of Convex Clustering Abstract: In this manuscript, we study the statistical properties of convex clustering.\nWe establish that convex clustering is closely related to single linkage\nhierarchical clustering and $k$-means clustering. In addition, we derive the\nrange of tuning parameter for convex clustering that yields a non-trivial\nsolution. We also provide an unbiased estimate of the degrees of freedom, and\nprovide a finite sample bound for the prediction error for convex clustering.\nWe compare convex clustering to some traditional clustering methods in\nsimulation studies. \n\n"}
{"id": "1504.00160", "contents": "Title: A new distribution function with bounded support: the reflected\n  Generalized Topp-Leone Power Series distribution Abstract: In this paper we introduce a new flexible class of distributions with bounded\nsupport, called reflected Generalized Topp-Leone Power Series (rGTL-PS),\nobtained by compounding the reflected Generalized Topp-Leone (van Drop and\nKotz, 2006) and the family of Power Series distributions. The proposed class\nincludes, as special cases, some new distributions with limited support such as\nthe rGTL-Logarithmic, the rGTL-Geometric, the rGTL-Poisson and rGTL-Binomial.\nThis work is an attempt to partially fill a gap regarding the presence, in the\nliterature, of continuous distributions with bounded support, which instead\nappear to be very useful in many real contexts, included the reliability. Some\nproperties of the class, including moments, hazard rate and quantile are\ninvestigated. Moreover, the maximum likelihood estimators of the parameters are\nexamined and the observed Fisher information matrix provided. Finally, in order\nto show the usefulness of the new class, some applications to real data are\nreported. \n\n"}
{"id": "1504.01823", "contents": "Title: Structured Matrix Completion with Applications to Genomic Data\n  Integration Abstract: Matrix completion has attracted significant recent attention in many fields\nincluding statistics, applied mathematics and electrical engineering. Current\nliterature on matrix completion focuses primarily on independent sampling\nmodels under which the individual observed entries are sampled independently.\nMotivated by applications in genomic data integration, we propose a new\nframework of structured matrix completion (SMC) to treat structured missingness\nby design. Specifically, our proposed method aims at efficient matrix recovery\nwhen a subset of the rows and columns of an approximately low-rank matrix are\nobserved. We provide theoretical justification for the proposed SMC method and\nderive lower bound for the estimation errors, which together establish the\noptimal rate of recovery over certain classes of approximately low-rank\nmatrices. Simulation studies show that the method performs well in finite\nsample under a variety of configurations. The method is applied to integrate\nseveral ovarian cancer genomic studies with different extent of genomic\nmeasurements, which enables us to construct more accurate prediction rules for\novarian cancer survival. \n\n"}
{"id": "1504.02429", "contents": "Title: Cutoff for non-backtracking random walks on sparse random graphs Abstract: A finite ergodic Markov chain is said to exhibit cutoff if its distance to\nstationarity remains close to 1 over a certain number of iterations and then\nabruptly drops to near 0 on a much shorter time scale. Discovered in the\ncontext of card shuffling (Aldous-Diaconis, 1986), this phenomenon is now\nbelieved to be rather typical among fast mixing Markov chains. Yet,\nestablishing it rigorously often requires a challengingly detailed\nunderstanding of the underlying chain. Here we consider non-backtracking random\nwalks on random graphs with a given degree sequence. Under a general sparsity\ncondition, we establish the cutoff phenomenon, determine its precise window,\nand prove that the (suitably rescaled) cutoff profile approaches a remarkably\nsimple, universal shape. \n\n"}
{"id": "1504.02887", "contents": "Title: Block-Maxima of Vines Abstract: We examine the dependence structure of finite block-maxima of multivariate\ndistributions. We provide a closed form expression for the copula density of\nthe vector of the block-maxima. Further, we show how partial derivatives of\nthree-dimensional vine copulas can be obtained by only one-dimensional\nintegration. Combining these results allows the numerical treatment of the\nblock-maxima of any three-dimensional vine copula for finite block-sizes. We\nlook at certain vine copula specifications and examine how the density of the\nblock-maxima behaves for different block-sizes. Additionally, a real data\nexample from hydrology is considered. In extreme-value theory for multivariate\nnormal distributions, a certain scaling of each variable and the correlation\nmatrix is necessary to obtain a non-trivial limiting distribution when the\nblock-size goes to infinity. This scaling is applied to different\nthree-dimensional vine copula specifications. \n\n"}
{"id": "1504.02913", "contents": "Title: A pairwise likelihood approach to simultaneous clustering and\n  dimensional reduction of ordinal data Abstract: The literature on clustering for continuous data is rich and wide;\ndifferently, that one developed for categorical data is still limited. In some\ncases, the problem is made more difficult by the presence of noise\nvariables/dimensions that do not contain information about the clustering\nstructure and could mask it. The aim of this paper is to propose a model for\nsimultaneous clustering and dimensionality reduction of ordered categorical\ndata able to detect the discriminative dimensions discarding the noise ones.\nFollowing the underlying response variable approach, the observed variables are\nconsidered as a discretization of underlying first-order latent continuous\nvariables distributed as a Gaussian mixture. To recognize discriminative and\nnoise dimensions, these variables are considered to be linear combinations of\ntwo independent sets of second-order latent variables where only one contains\nthe information about the cluster structure while the other contains noise\ndimensions. The model specification involves multidimensional integrals that\nmake the maximum likelihood estimation cumbersome and in some cases infeasible.\nTo overcome this issue the parameter estimation is carried out through an\nEM-like algorithm maximizing a pairwise log-likelihood. Examples of application\nof the model on real and simulated data are performed to show the effectiveness\nof the proposal. \n\n"}
{"id": "1504.07368", "contents": "Title: Fully Coupled Forward-backward Stochastic Differential Equations on\n  Markov Chains Abstract: We define fully coupled forward-backward stochastic differential equations on\nspaces related to continuous time, finite state Markov Chains. Existence and\nuniqueness results of the fully coupled forward-backward stochastic\ndifferential equations on Markov Chains are obtained. \n\n"}
{"id": "1505.02023", "contents": "Title: Tests for separability in nonparametric covariance operators of random\n  surfaces Abstract: The assumption of separability of the covariance operator for a random image\nor hypersurface can be of substantial use in applications, especially in\nsituations where the accurate estimation of the full covariance structure is\nunfeasible, either for computational reasons, or due to a small sample size.\nHowever, inferential tools to verify this assumption are somewhat lacking in\nhigh-dimensional or functional {data analysis} settings, where this assumption\nis most relevant. We propose here to test separability by focusing on\n$K$-dimensional projections of the difference between the covariance operator\nand a nonparametric separable approximation. The subspace we project onto is\none generated by the eigenfunctions of the covariance operator estimated under\nthe separability hypothesis, negating the need to ever estimate the full\nnon-separable covariance. We show that the rescaled difference of the sample\ncovariance operator with its separable approximation is asymptotically\nGaussian. As a by-product of this result, we derive asymptotically pivotal\ntests under Gaussian assumptions, and propose bootstrap methods for\napproximating the distribution of the test statistics. We probe the finite\nsample performance through simulations studies, and present an application to\nlog-spectrogram images from a phonetic linguistics dataset. \n\n"}
{"id": "1505.02456", "contents": "Title: Graphical Markov models, unifying results and their interpretation Abstract: Graphical Markov models combine conditional independence constraints with\ngraphical representations of stepwise data generating processes.The models\nstarted to be formulated about 40 years ago and vigorous development is\nongoing. Longitudinal observational studies as well as intervention studies are\nbest modeled via a subclass called regression graph models and, especially\ntraceable regressions. Regression graphs include two types of undirected graph\nand directed acyclic graphs in ordered sequences of joint responses. Response\ncomponents may correspond to discrete or continuous random variables and may\ndepend exclusively on variables which have been generated earlier. These\naspects are essential when causal hypothesis are the motivation for the\nplanning of empirical studies.\n  To turn the graphs into useful tools for tracing developmental pathways and\nfor predicting structure in alternative models, the generated distributions\nhave to mimic some properties of joint Gaussian distributions. Here, relevant\nresults concerning these aspects are spelled out and illustrated by examples.\nWith regression graph models, it becomes feasible, for the first time, to\nderive structural effects of (1) ignoring some of the variables, of (2)\nselecting subpopulations via fixed levels of some other variables or of (3)\nchanging the order in which the variables might get generated. Thus, the most\nimportant future applications of these models will aim at the best possible\nintegration of knowledge from related studies. \n\n"}
{"id": "1505.03161", "contents": "Title: Dual graphs and modified Barlow--Bass resistance estimates for repeated\n  barycentric subdivisions Abstract: We prove Barlow--Bass type resistance estimates for two random walks\nassociated with repeated barycentric subdivisions of a triangle. If the random\nwalk jumps between the centers of triangles in the subdivision that have common\nsides, the resistance scales as a power of a constant $\\rho$ which is\ntheoretically estimated to be in the interval $5/4\\leqslant\\rho\\leqslant3/2$,\nwith a numerical estimate $\\rho\\approx1.306$. This corresponds to the\ntheoretical estimate of spectral dimension $d_S$ between 1.63 and 1.77, with a\nnumerical estimate $d_S\\approx1.74$. On the other hand, if the random walk\njumps between the corners of triangles in the subdivision, then the resistance\nscales as a power of a constant $\\rho^T=1/\\rho$, which is theoretically\nestimated to be in the interval $2/3\\leqslant\\rho^T\\leqslant4/5$. This\ncorresponds to the spectral dimension between 2.28 and 2.38. The difference\nbetween $\\rho$ and $\\rho^T$ implies that the the limiting behavior of random\nwalks on the repeated barycentric subdivisions is more delicate than on the\ngeneralized Sierpinski Carpets, and suggests interesting possibilities for\nfurther research, including possible non-uniqueness of self-similar Dirichlet\nforms. \n\n"}
{"id": "1505.04321", "contents": "Title: Sequential Bayesian inference for implicit hidden Markov models and\n  current limitations Abstract: Hidden Markov models can describe time series arising in various fields of\nscience, by treating the data as noisy measurements of an arbitrarily complex\nMarkov process. Sequential Monte Carlo (SMC) methods have become standard tools\nto estimate the hidden Markov process given the observations and a fixed\nparameter value. We review some of the recent developments allowing the\ninclusion of parameter uncertainty as well as model uncertainty. The\nshortcomings of the currently available methodology are emphasised from an\nalgorithmic complexity perspective. The statistical objects of interest for\ntime series analysis are illustrated on a toy \"Lotka-Volterra\" model used in\npopulation ecology. Some open challenges are discussed regarding the\nscalability of the reviewed methodology to longer time series,\nhigher-dimensional state spaces and more flexible models. \n\n"}
{"id": "1505.04629", "contents": "Title: Construction of alternative hypotheses for randomization tests with\n  ordinal outcomes Abstract: For ordinal outcomes, we construct sequences of alternative hypotheses in\nincreasing departures from the sharp null hypothesis of zero treatment effect\non each experimental unit, to help assess the powers of randomization tests in\nrandomized treatment-control experiments. \n\n"}
{"id": "1505.04898", "contents": "Title: Heterogeneous Change Point Inference Abstract: We propose HSMUCE (heterogeneous simultaneous multiscale change-point\nestimator) for the detection of multiple change-points of the signal in a\nheterogeneous gaussian regression model. A piecewise constant function is\nestimated by minimizing the number of change-points over the acceptance region\nof a multiscale test which locally adapts to changes in the variance. The\nmultiscale test is a combination of local likelihood ratio tests which are\nproperly calibrated by scale dependent critical values in order to keep a\nglobal nominal level alpha, even for finite samples. We show that HSMUCE\ncontrols the error of over- and underestimation of the number of change-points.\nTo this end, new deviation bounds for F-type statistics are derived. Moreover,\nwe obtain confidence sets for the whole signal. All results are non-asymptotic\nand uniform over a large class of heterogeneous change-point models. HSMUCE is\nfast to compute, achieves the optimal detection rate and estimates the number\nof change-points at almost optimal accuracy for vanishing signals, while still\nbeing robust. We compare HSMUCE with several state of the art methods in\nsimulations and analyse current recordings of a transmembrane protein in the\nbacterial outer membrane with pronounced heterogeneity for its states. An\nR-package is available online. \n\n"}
{"id": "1505.05493", "contents": "Title: Modified log-Sobolev inequalities for convex functions on the real line.\n  Sufficient conditions Abstract: We provide a mild sufficient condition for a probability measure on the real\nline to satisfy a modified log-Sobolev inequality for convex functions,\ninterpolating between the classical log-Sobolev inequality and a Bobkov-Ledoux\ntype inequality. As a consequence we obtain dimension-free two-level\nconcentration results for convex function of independent random variables with\nsufficiently regular tail decay. We also provide a link between modified\nlog-Sobolev inequalities for convex functions and weak transport-entropy\ninequalities, complementing recent work by Gozlan, Roberto, Samson, and Tetali. \n\n"}
{"id": "1505.05770", "contents": "Title: Variational Inference with Normalizing Flows Abstract: The choice of approximate posterior distribution is one of the core problems\nin variational inference. Most applications of variational inference employ\nsimple families of posterior approximations in order to allow for efficient\ninference, focusing on mean-field or other simple structured approximations.\nThis restriction has a significant impact on the quality of inferences made\nusing variational methods. We introduce a new approach for specifying flexible,\narbitrarily complex and scalable approximate posterior distributions. Our\napproximations are distributions constructed through a normalizing flow,\nwhereby a simple initial density is transformed into a more complex one by\napplying a sequence of invertible transformations until a desired level of\ncomplexity is attained. We use this view of normalizing flows to develop\ncategories of finite and infinitesimal flows and provide a unified view of\napproaches for constructing rich posterior approximations. We demonstrate that\nthe theoretical advantages of having posteriors that better match the true\nposterior, combined with the scalability of amortized variational approaches,\nprovides a clear improvement in performance and applicability of variational\ninference. \n\n"}
{"id": "1505.07517", "contents": "Title: Within Group Variable Selection through the Exclusive Lasso Abstract: Many data sets consist of variables with an inherent group structure. The\nproblem of group selection has been well studied, but in this paper, we seek to\ndo the opposite: our goal is to select at least one variable from each group in\nthe context of predictive regression modeling. This problem is NP-hard, but we\nstudy the tightest convex relaxation: a composite penalty that is a combination\nof the $\\ell_1$ and $\\ell_2$ norms. Our so-called Exclusive Lasso method\nperforms structured variable selection by ensuring that at least one variable\nis selected from each group. We study our method's statistical properties and\ndevelop computationally scalable algorithms for fitting the Exclusive Lasso. We\nstudy the effectiveness of our method via simulations as well as using NMR\nspectroscopy data. Here, we use the Exclusive Lasso to select the appropriate\nchemical shift from a dictionary of possible chemical shifts for each molecule\nin the biological sample. \n\n"}
{"id": "1506.00053", "contents": "Title: Efficient Bayesian experimentation using an expected information gain\n  lower bound Abstract: Experimental design is crucial for inference where limitations in the data\ncollection procedure are present due to cost or other restrictions. Optimal\nexperimental designs determine parameters that in some appropriate sense make\nthe data the most informative possible. In a Bayesian setting this is\ntranslated to updating to the best possible posterior. Information theoretic\narguments have led to the formation of the expected information gain as a\ndesign criterion. This can be evaluated mainly by Monte Carlo sampling and\nmaximized by using stochastic approximation methods, both known for being\ncomputationally expensive tasks. We propose a framework where a lower bound of\nthe expected information gain is used as an alternative design criterion. In\naddition to alleviating the computational burden, this also addresses issues\nconcerning estimation bias. The problem of permeability inference in a large\ncontaminated area is used to demonstrate the validity of our approach where we\nemploy the massively parallel version of the multiphase multicomponent\nsimulator TOUGH2 to simulate contaminant transport and a Polynomial Chaos\napproximation of the forward model that further accelerates the objective\nfunction evaluations. The proposed methodology is demonstrated to a setting\nwhere field measurements are available. \n\n"}
{"id": "1506.01239", "contents": "Title: Vertex reinforced non-backtracking random walks: an example of path\n  formation Abstract: This article studies vertex reinforced random walks that are non-backtracking\n(denoted VRNBW), i.e. U-turns forbidden. With this last property and for a\nstrong reinforcement, the emergence of a path may occur with positive\nprobability. These walks are thus useful to model the path formation\nphenomenon, observed for example in ant colonies. This study is carried out in\ntwo steps. First, a large class of reinforced random walks is introduced and\nresults on the asymptotic behavior of these processes are proved. Second, these\nresults are applied to VRNBWs on complete graphs and for reinforced weights\n$W(k)=k^\\alpha$, with $\\alpha\\ge 1$. It is proved that for $\\alpha>1$ and $3\\le\nm< \\frac{3\\alpha -1}{\\alpha-1}$, the walk localizes on $m$ vertices with\npositive probability, each of these $m$ vertices being asymptotically equally\nvisited. Moreover the localization on $m>\\frac{3\\alpha -1}{\\alpha-1}$ vertices\nis a.s. impossible. \n\n"}
{"id": "1506.01370", "contents": "Title: Indistinguishability of components of random spanning forests Abstract: We prove that the infinite components of the Free Uniform Spanning Forest of\na Cayley graph are indistinguishable by any invariant property, given that the\nforest is different from its wired counterpart. Similar result is obtained for\nthe Free Minimal Spanning Forest. We also show that with the above assumptions\nthere can only be 0, 1 or infinitely many components. These answer questions by\nBenjamini, Lyons, Peres and Schramm. Our methods apply to a more general class\nof percolations, those satisfying \"weak insertion tolerance\", and work beyond\nCayley graphs, in the more general setting of unimodular random graphs. \n\n"}
{"id": "1506.01429", "contents": "Title: Branching Brownian motion with absorption and the all-time minimum of\n  branching Brownian motion with drift Abstract: We study a dyadic branching Brownian motion on the real line with absorption\nat 0, drift $\\mu \\in \\mathbb{R}$ and started from a single particle at position\n$x>0.$ When $\\mu$ is large enough so that the process has a positive\nprobability of survival, we consider $K(t),$ the number of individuals absorbed\nat 0 by time $t$ and for $s\\ge 0$ the functions $\\omega_s(x):=\n\\mathbb{E}^x[s^{K(\\infty)}].$ We show that $\\omega_s<\\infty$ if and only of\n$s\\in[0,s_0]$ for some $s_0>1$ and we study the properties of these functions.\nFurthermore, for $s=0, \\omega(x) := \\omega_0(x) =\\mathbb{P}^x(K(\\infty)=0)$ is\nthe cumulative distribution function of the all time minimum of the branching\nBrownian motion with drift started at 0 without absorption.\n  We give three descriptions of the family $\\omega_s, s\\in [0,s_0]$ through a\nsingle pair of functions, as the two extremal solutions of the\nKolmogorov-Petrovskii-Piskunov (KPP) traveling wave equation on the half-line,\nthrough a martingale representation and as an explicit series expansion. We\nalso obtain a precise result concerning the tail behavior of $K(\\infty)$. In\naddition, in the regime where $K(\\infty)>0$ almost surely, we show that $u(x,t)\n:= \\mathbb{P}^x(K(t)=0)$ suitably centered converges to the KPP critical\ntravelling wave on the whole real line. \n\n"}
{"id": "1506.01625", "contents": "Title: Spectral expansions of non-self-adjoint generalized Laguerre semigroups Abstract: We provide the spectral expansion in a weighted Hilbert space of a\nsubstantial class of invariant non-self-adjoint and non-local Markov operators\nwhich appear in limit theorems for positive-valued Markov processes. We show\nthat this class is in bijection with a subset of negative definite functions\nand we name it the class of generalized Laguerre semigroups. Our approach,\nwhich goes beyond the framework of perturbation theory, is based on an in-depth\nand original analysis of an intertwining relation that we establish between\nthis class and a self-adjoint Markov semigroup, whose spectral expansion is\nexpressed in terms of the classical Laguerre polynomials. As a by-product, we\nderive smoothness properties for the solution to the associated Cauchy problem\nas well as for the heat kernel. Our methodology also reveals a variety of\npossible decays, including the hypocoercivity type phenomena, for the speed of\nconvergence to equilibrium for this class and enables us to provide an\ninterpretation of these in terms of the rate of growth of the weighted Hilbert\nspace norms of the spectral projections. Depending on the analytic properties\nof the aforementioned negative definite functions, we are led to implement\nseveral strategies, which require new developments in a variety of contexts, to\nderive precise upper bounds for these norms. \n\n"}
{"id": "1506.02476", "contents": "Title: Pure partition functions of multiple SLEs Abstract: Multiple Schramm-Loewner Evolutions (SLE) are conformally invariant random\nprocesses of several curves, whose construction by growth processes relies on\npartition functions: M\\\"obius covariant solutions to a system of second order\npartial differential equations. In this article, we use a quantum group\ntechnique to construct a distinguished basis of solutions, which conjecturally\ncorrespond to the extremal points of the convex set of probability measures of\nmultiple SLEs. \n\n"}
{"id": "1506.03039", "contents": "Title: Measuring Sample Quality with Stein's Method Abstract: To improve the efficiency of Monte Carlo estimation, practitioners are\nturning to biased Markov chain Monte Carlo procedures that trade off asymptotic\nexactness for computational speed. The reasoning is sound: a reduction in\nvariance due to more rapid sampling can outweigh the bias introduced. However,\nthe inexactness creates new challenges for sampler and parameter selection,\nsince standard measures of sample quality like effective sample size do not\naccount for asymptotic bias. To address these challenges, we introduce a new\ncomputable quality measure based on Stein's method that quantifies the maximum\ndiscrepancy between sample and target expectations over a large class of test\nfunctions. We use our tool to compare exact, biased, and deterministic sample\nsequences and illustrate applications to hyperparameter selection, convergence\nrate assessment, and quantifying bias-variance tradeoffs in posterior\ninference. \n\n"}
{"id": "1506.03481", "contents": "Title: On the Asymptotic Efficiency of Approximate Bayesian Computation\n  Estimators Abstract: Many statistical applications involve models for which it is difficult to\nevaluate the likelihood, but from which it is relatively easy to sample.\nApproximate Bayesian computation is a likelihood-free method for implementing\nBayesian inference in such cases. We present results on the asymptotic variance\nof estimators obtained using approximate Bayesian computation in a large-data\nlimit. Our key assumption is that the data are summarized by a\nfixed-dimensional summary statistic that obeys a central limit theorem. We\nprove asymptotic normality of the mean of the approximate Bayesian computation\nposterior. This result also shows that, in terms of asymptotic variance, we\nshould use a summary statistic that is the same dimension as the parameter\nvector, p; and that any summary statistic of higher dimension can be reduced,\nthrough a linear transformation, to dimension p in a way that can only reduce\nthe asymptotic variance of the posterior mean. We look at how the Monte Carlo\nerror of an importance sampling algorithm that samples from the approximate\nBayesian computation posterior affects the accuracy of estimators. We give\nconditions on the importance sampling proposal distribution such that the\nvariance of the estimator will be the same order as that of the maximum\nlikelihood estimator based on the summary statistics used. This suggests an\niterative importance sampling algorithm, which we evaluate empirically on a\nstochastic volatility model. \n\n"}
{"id": "1506.03806", "contents": "Title: An axiomatic characterization of the Brownian map Abstract: The Brownian map is a random sphere-homeomorphic metric measure space\nobtained by \"gluing together\" the continuum trees described by the $x$ and $y$\ncoordinates of the Brownian snake. We present an alternative \"breadth-first\"\nconstruction of the Brownian map, which produces a surface from a certain\ndecorated branching process. It is closely related to the peeling process, the\nhull process, and the Brownian cactus.\n  Using these ideas, we prove that the Brownian map is the only random\nsphere-homeomorphic metric measure space with certain properties: namely, scale\ninvariance and the conditional independence of the inside and outside of\ncertain \"slices\" bounded by geodesics. We also formulate a characterization in\nterms of the so-called L\\'evy net produced by a metric exploration from one\nmeasure-typical point to another. This characterization is part of a program\nfor proving the equivalence of the Brownian map and Liouville quantum gravity\nwith parameter $\\gamma= \\sqrt{8/3}$. \n\n"}
{"id": "1506.04309", "contents": "Title: Lattice birth-and-death processes Abstract: Lattice birth-and-death Markov dynamics of particle systems with spins from\nthe set of non-negative integers are constructed as unique solutions to certain\nstochastic equations. Pathwise uniqueness, strong existence, Markov property\nand joint uniqueness in law are proven, and a martingale characterization of\nthe process is given. Sufficient conditions for the existence of an invariant\ndistribution are formulated in terms of Lyapunov functions. We apply obtained\nresults to discrete analogs of the Bolker--Pacala--Dieckmann--Law model and an\naggregation model. \n\n"}
{"id": "1506.06790", "contents": "Title: Spectral theorems for random walks on mapping class groups and\n  $\\text{Out}(F_N)$ Abstract: We establish spectral theorems for random walks on mapping class groups of\nconnected, closed, oriented, hyperbolic surfaces, and on $\\text{Out}(F_N)$. In\nboth cases, we relate the asymptotics of the stretching factor of the\ndiffeomorphism/automorphism obtained at time $n$ of the random walk to the\nLyapunov exponent of the walk, which gives the typical growth rate of the\nlength of a curve -- or of a conjugacy class in $F_N$ -- under a random product\nof diffeomorphisms/automorphisms.\n  In the mapping class group case, we first observe that the drift of the\nrandom walk in the curve complex is also equal to the linear growth rate of the\ntranslation lengths in this complex. By using a contraction property of typical\nTeichm\\\"uller geodesics, we then lift the above fact to the realization of the\nrandom walk on the Teichm\\\"uller space. For the case of $\\text{Out}(F_N)$, we\nfollow the same procedure with the free factor complex in place of the curve\ncomplex, and the outer space in place of the Teichm\\\"uller space. A general\ncriterion is given for making the lifting argument possible. \n\n"}
{"id": "1506.07447", "contents": "Title: Fraud detection with statistics: A comment on \"Evidential Value in\n  ANOVA-Regression Results in Scientific Integrity Studies\" (Klaassen, 2015) Abstract: Klaassen in (Klaassen 2015) proposed a method for the detection of data\nmanipulation given the means and standard deviations for the cells of a oneway\nANOVA design. This comment critically reviews this method. In addition,\ninspired by this analysis, an alternative approach to test sample correlations\nover several experiments is derived. The results are in close agreement with\nthe initial analysis reported by an anonymous whistlelblower. Importantly, the\nstatistic requires several similar experiments; a test for correlations between\n3 sample means based on a single experiment must be considered as unreliable. \n\n"}
{"id": "1506.07686", "contents": "Title: The exponential Lie series for continuous semimartingales Abstract: We consider stochastic differential systems driven by continuous\nsemimartingales and governed by non-commuting vector fields. We prove that the\nlogarithm of the flowmap is an exponential Lie series. This relies on a natural\nchange of basis to vector fields for the associated quadratic covariation\nprocesses, analogous to Stratonovich corrections. The flowmap can then be\nexpanded as a series in compositional powers of vector fields and the logaritm\nof the flowmap can thus be expanded in the Lie algebra of vector fields.\nFurther, we give a direct self-contained proof of the corresponding\nChen-Strichartz formula which provides an explicit formula for the Lie series\ncoefficients. Such exponential Lie series are important in the development of\nstrong Lie group integration schemes that ensure approximate solutions\nthemselves lie in any homogeneous manifold on which the solution evolves. \n\n"}
{"id": "1506.08514", "contents": "Title: Exponential Mixing for 3D Stochastic Primitive Equations Abstract: In this paper, we prove that weak solutions of 3D stochastic primitive\nequations have exponential mixing property if the noise is sufficiently smooth\nand non-degenerate. With the help of uniqueness of strong solution of 3D\nstochastic primitive equations, we obtain that all weak solutions which are\nlimitations of Galerkin approximations share the same invariant measure. In\nparticular, the invariant measure of strong solution is unique. The coupling\nmethod plays a key role. \n\n"}
{"id": "1506.09030", "contents": "Title: Continuity and strict positivity of the multi-layer extension of the\n  stochastic heat equation Abstract: We prove the continuity and strict positivity of the multi-layer extension to\nthe stochastic heat equation introduced in [OW11] which form a hierarchy of\npartition functions for the continuum directed random polymer. This shows that\nthe corresponding free energy (logarithm of the partition function) is well\ndefined. This is also a step towards proving the conjecture stated at the end\nof the above paper that an array of such partition functions has the Markov\nproperty. \n\n"}
{"id": "1507.00033", "contents": "Title: Spawning Models for the CPHD Filter Abstract: In its classical form, the Cardinalized Probability Hypothesis Density (CPHD)\nfilter does not model the appearance of new targets through spawning, yet there\nare applications for which spawning models more appropriately account for\nnewborn objects when compared to spontaneous birth models. In this paper, we\npropose a principled derivation of the CPHD filter with spawning from the\nFinite Set Statistics framework. A Gaussian Mixture implementation of the CPHD\nfilter with spawning is then presented, illustrated with three applicable\nspawning models on a simulated scenario involving two parent targets spawning a\ntotal of five objects. Results show that filter implementations with spawn\nmodels provide more accurate results when compared to a birth model\nimplementation. \n\n"}
{"id": "1507.01175", "contents": "Title: Impact of dependence on some multivariate risk indicators Abstract: The minimization of some multivariate risk indicators may be used as an\nallocation method, as proposed in C\\'enac et al. [6]. The aim of capital\nallocation is to choose a point in a simplex, according to a given criterion.\nIn a previous paper [17] we proved that the proposed allocation technique\nsatisfies a set of coherence axioms. In the present one, we study the\nproperties and asymptotic behavior of the allocation for some distribution\nmodels. We analyze also the impact of the dependence structure on the\nallocation using some copulas. \n\n"}
{"id": "1507.02741", "contents": "Title: A Nonseparable Multivariate Space-Time Model for Analyzing County-Level\n  Heart Disease Death Rates by Race and Gender Abstract: While death rates due to diseases of the heart have experienced a sharp\ndecline over the past 50 years, these diseases continue to be the leading cause\nof death in the United States, and the rate of decline varies by geographic\nlocation, race, and gender. We look to harness the power of hierarchical\nBayesian methods to obtain a clearer picture of the declines from county-level,\ntemporally varying heart disease death rates for men and women of different\nraces in the US. Specifically, we propose a nonseparable multivariate\nspatio-temporal Bayesian model which allows for group-specific temporal\ncorrelations and temporally-evolving covariance structures in the multivariate\nspatio-temporal component of the model. After verifying the effectiveness of\nour model via simulation, we apply our model to a dataset of over 200,000\ncounty-level heart disease death rates. In addition to yielding a superior fit\nthan other common approaches for handling such data, the richness of our model\nprovides insight into racial, gender, and geographic disparities underlying\nheart disease death rates in the US which are not permitted by more restrictive\nmodels. \n\n"}
{"id": "1507.03721", "contents": "Title: Some measure-theoretic properties of U-statistics applied in statistical\n  physics Abstract: This paper investigates the relationship between various measure-theoretic\nproperties of U-statistics with fixed sample size $N$ and the same properties\nof their kernels. Specifically, the random variables are replaced with elements\nin some measure space $(\\Lambda; dx)$, the resultant real-valued functions on\n$\\Lambda^N$ being called generalized $N$-means. It is shown that a.e.\nconvergence of sequences, measurability, essential boundedness and, under\ncertain conditions, integrability with respect to probability measures of\ngeneralized $N$-means and their kernels are equivalent. These results are\ncrucial for the solution of the inverse problem in classical statistical\nmechanics in the canonical formulation. \n\n"}
{"id": "1507.04398", "contents": "Title: On the use of reproducing kernel Hilbert spaces in functional\n  classification Abstract: The H\\'ajek-Feldman dichotomy establishes that two Gaussian measures are\neither mutually absolutely continuous with respect to each other (and hence\nthere is a Radon-Nikodym density for each measure with respect to the other\none) or mutually singular. Unlike the case of finite dimensional Gaussian\nmeasures, there are non-trivial examples of both situations when dealing with\nGaussian stochastic processes. This paper provides:\n  (a) Explicit expressions for the optimal (Bayes) rule and the minimal\nclassification error probability in several relevant problems of supervised\nbinary classification of mutually absolutely continuous Gaussian processes. The\napproach relies on some classical results in the theory of Reproducing Kernel\nHilbert Spaces (RKHS).\n  (b) An interpretation, in terms of mutual singularity, for the \"near perfect\nclassification\" phenomenon described by Delaigle and Hall (2012). We show that\nthe asymptotically optimal rule proposed by these authors can be identified\nwith the sequence of optimal rules for an approximating sequence of\nclassification problems in the absolutely continuous case.\n  (c) A new model-based method for variable selection in binary classification\nproblems, which arises in a very natural way from the explicit knowledge of the\nRN-derivatives and the underlying RKHS structure. Different classifiers might\nbe used from the selected variables. In particular, the classical, linear\nfinite-dimensional Fisher rule turns out to be consistent under some standard\nconditions on the underlying functional model. \n\n"}
{"id": "1507.05301", "contents": "Title: A Comparative Analysis of the Successive Lumping and the Lattice Path\n  Counting Algorithms Abstract: This article provides a comparison of the successive lumping (SL) methodology\nwith the popular lattice path counting algorithm in obtaining rate matrices for\nqueueing models, satisfying the quasi birth and death structure. The two\nmethodologies are compared both in terms of applicability requirements and\nnumerical complexity by analyzing their performance for the same classical\nqueueing models.\n  The main findings are: i) When both methods are applicable SL based\nalgorithms outperform the lattice path counting algorithm (LPCA). ii) There are\nimportant classes of problems (e.g., models with (level) non-homogenous rates\nor with finite state spaces) for which the SL methodology is applicable and for\nwhich the LPCA cannot be used. iii) Another main advantage of successive\nlumping algorithms over LPCAs is that the former includes a method to compute\nthe steady state distribution using this rate matrix. \n\n"}
{"id": "1507.05351", "contents": "Title: Multivariate Shortfall Risk Allocation and Systemic Risk Abstract: The ongoing concern about systemic risk since the outburst of the global\nfinancial crisis has highlighted the need for risk measures at the level of\nsets of interconnected financial components, such as portfolios, institutions\nor members of clearing houses. The two main issues in systemic risk measurement\nare the computation of an overall reserve level and its allocation to the\ndifferent components according to their systemic relevance. We develop here a\npragmatic approach to systemic risk measurement and allocation based on\nmultivariate shortfall risk measures, where acceptable allocations are first\ncomputed and then aggregated so as to minimize costs. We analyze the\nsensitivity of the risk allocations to various factors and highlight its\nrelevance as an indicator of systemic risk. In particular, we study the\ninterplay between the loss function and the dependence structure of the\ncomponents. Moreover, we address the computational aspects of risk allocation.\nFinally, we apply this methodology to the allocation of the default fund of a\nCCP on real data. \n\n"}
{"id": "1507.05529", "contents": "Title: Generating Partially Synthetic Geocoded Public Use Data with Decreased\n  Disclosure Risk Using Differential Smoothing Abstract: When collecting geocoded confidential data with the intent to disseminate,\nagencies often resort to altering the geographies prior to making data publicly\navailable due to data privacy obligations. An alternative to releasing\naggregated and/or perturbed data is to release multiply-imputed synthetic data,\nwhere sensitive values are replaced with draws from statistical models designed\nto capture important distributional features in the collected data. One issue\nthat has received relatively little attention, however, is how to handle\nspatially outlying observations in the collected data, as common spatial models\noften have a tendency to overfit these observations. The goal of this work is\nto bring this issue to the forefront and propose a solution, which we refer to\nas \"differential smoothing.\" After implementing our method on simulated data,\nhighlighting the effectiveness of our approach under various scenarios, we\nillustrate the framework using data consisting of sale prices of homes in San\nFrancisco. \n\n"}
{"id": "1507.05804", "contents": "Title: Spatial birth-and-death processes with a finite number of particles Abstract: Spatial birth-and-death processes with time dependent rates are obtained as\nsolutions to certain stochastic equations. The existence, uniqueness,\nuniqueness in law and the strong Markov property of unique solutions are proven\nwhen the integral of the birth rate over $\\mathbb{R} ^ \\mathrm{d}$ grows not\nfaster than linearly with the number of particles of the system. Martingale\nproperties of the constructed process provide a rigorous connection to the\nheuristic generator. We also study pathwise behavior of an aggregation model.\nThe probability of extinction and the growth rate of the number of particles\nconditioning on non-extinction are estimated. \n\n"}
{"id": "1507.06201", "contents": "Title: Extending the square root method to account for additive forecast noise\n  in ensemble methods Abstract: A square root approach is considered for the problem of accounting for model\nnoise in the forecast step of the ensemble Kalman filter (EnKF) and related\nalgorithms. The primary aim is to replace the method of simulated,\npseudo-random, additive noise so as to eliminate the associated sampling\nerrors. The core method is based on the analysis step of ensemble square root\nfilters, and consists in the deterministic computation of a transform matrix.\nThe theoretical advantages regarding dynamical consistency are surveyed,\napplying equally well to the square root method in the analysis step. A\nfundamental problem due to the limited size of the ensemble subspace is\ndiscussed, and novel solutions that complement the core method are suggested\nand studied. Benchmarks from twin experiments with simple, low-order dynamics\nindicate improved performance over standard approaches such as additive,\nsimulated noise and multiplicative inflation. \n\n"}
{"id": "1507.06489", "contents": "Title: The gradient flow approach to hydrodynamic limits for the simple\n  exclusion process Abstract: We give a new approach to the well-known convergence to the hydrodynamic\nlimit for the symmetric simple exclusion process (SSEP). More precisely, we\ncharacterize any possible limit of its empirical density measures as solutions\nto the heat equation by passing to the limit in the gradient flow structure of\nthe particle system. \n\n"}
{"id": "1507.06790", "contents": "Title: The strong renewal theorem with infinite mean via local large deviations Abstract: A necessary and sufficient condition is established for an asymptotically\nstable renewal process to satisfy the strong renewal theorem. This result is\nvalid for all alpha in (0, 1), thus completing a result for alpha in (1/2, 1)\nwhich was proved in the 1963 paper of Garsia and Lamperti [6]. This paper is\nsuperseded by arXiv:1612.07635. \n\n"}
{"id": "1507.07271", "contents": "Title: Multiscale spatial density smoothing: an application to large-scale\n  radiological survey and anomaly detection Abstract: We consider the problem of estimating a spatially varying density function,\nmotivated by problems that arise in large-scale radiological survey and anomaly\ndetection. In this context, the density functions to be estimated are the\nbackground gamma-ray energy spectra at sites spread across a large geographical\narea, such as nuclear production and waste-storage sites, military bases,\nmedical facilities, university campuses, or the downtown of a city. Several\nchallenges combine to make this a difficult problem. First, the spectral\ndensity at any given spatial location may have both smooth and non-smooth\nfeatures. Second, the spatial correlation in these density functions is neither\nstationary nor locally isotropic. Finally, at some spatial locations, there is\nvery little data. We present a method called multiscale spatial density\nsmoothing that successfully addresses these challenges. The method is based on\nrecursive dyadic partition of the sample space, and therefore shares much in\ncommon with other multiscale methods, such as wavelets and P\\'olya-tree priors.\nWe describe an efficient algorithm for finding a maximum a posteriori (MAP)\nestimate that leverages recent advances in convex optimization for non-smooth\nfunctions.\n  We apply multiscale spatial density smoothing to real data collected on the\nbackground gamma-ray spectra at locations across a large university campus. The\nmethod exhibits state-of-the-art performance for spatial smoothing in density\nestimation, and it leads to substantial improvements in power when used in\nconjunction with existing methods for detecting the kinds of radiological\nanomalies that may have important consequences for public health and safety. \n\n"}
{"id": "1507.07576", "contents": "Title: Grand Lebesgue norm estimation for binary random variables, with\n  applications Abstract: We calculate the so-called Rademacher's Grand Lebesgue Space norm for a\ncentered (shifted) indicator (Bernoulli's, binary) random variable.\n  This norm is optimal for the centered and bounded random variables (r.v.).\nUsing this result we derive a very simple bilateral sharp exponential tail\nestimates for sums of these variables, not necessary to be identical\ndistributed, under non-standard norming, and give some examples to show the\nexactness of our estimates. \n\n"}
{"id": "1507.08554", "contents": "Title: Kac's Walk on $n$-sphere mixes in $n\\log n$ steps Abstract: Determining the mixing time of Kac's random walk on the sphere\n$\\mathrm{S}^{n-1}$ is a long-standing open problem. We show that the total\nvariation mixing time of Kac's walk on $\\mathrm{S}^{n-1}$ is between\n$\\frac{1}{2} \\, n \\log(n)$ and $200 \\,n \\log(n)$. Our bound is thus optimal up\nto a constant factor, improving on the best-known upper bound of $O(n^{5}\n\\log(n)^{2})$ due to Jiang. Our main tool is a `non-Markovian' coupling\nrecently introduced by the second author for obtaining the convergence rates of\ncertain high dimensional Gibbs samplers in continuous state spaces. \n\n"}
{"id": "1508.00934", "contents": "Title: Admissibility in Partial Conjunction Testing Abstract: Meta-analysis combines results from multiple studies aiming to increase power\nin finding their common effect. It would typically reject the null hypothesis\nof no effect if any one of the studies shows strong significance. The partial\nconjunction null hypothesis is rejected only when at least $r$ of $n$ component\nhypotheses are non-null with $r = 1$ corresponding to a usual meta-analysis.\nCompared with meta-analysis, it can encourage replicable findings across\nstudies. A by-product of it when applied to different $r$ values is a\nconfidence interval of $r$ quantifying the proportion of non-null studies.\nBenjamini and Heller (2008) provided a valid test for the partial conjunction\nnull by ignoring the $r - 1$ smallest p-values and applying a valid\nmeta-analysis p-value to the remaining $n - r + 1$ p-values. We provide\nsufficient and necessary conditions of admissible combined p-value for the\npartial conjunction hypothesis among monotone tests. Non-monotone tests always\ndominate monotone tests but are usually too unreasonable to be used in\npractice. Based on these findings, we propose a generalized form of Benjamini\nand Heller's test which allows usage of various types of meta-analysis\np-values, and apply our method to an example in assessing replicable benefit of\nnew anticoagulants across subgroups of patients for stroke prevention. \n\n"}
{"id": "1508.04581", "contents": "Title: Strong convergence of the symmetrized Milstein scheme for some CEV-like\n  SDEs Abstract: In this paper we study the rate of convergence of a symmetrized version of\nthe Milstein scheme applied to the solution of the one dimensional SDE $$X_t =\nx_0 + \\int_{0}^t{b(X_s)ds}+\\int_{0}^t{\\sigma |X_s|^\\alpha dW_s},\n\\;x_0>0,\\;\\sigma>0,\\; \\alpha\\in[\\tfrac{1}{2},1).$$ Assuming $b(0)/\\sigma^2$ big\nenough, and $b$ smooth, we prove a strong rate of convergence of order one,\nrecovering the classical result of Milstein for SDEs with smooth diffusion\ncoefficient. In contrast with other recent results, our proof does not relies\non Lamperti transformation, and it can be applied to a wide class of drift\nfunctions. On the downside, our hypothesis on the critical parameter value\n$b(0)/\\sigma^2$ is more restrictive than others available in the literature.\nSome numerical experiments and comparison with various other schemes complement\nour theoretical analysis that also applies for the simple projected Milstein\nscheme with same convergence rate. \n\n"}
{"id": "1508.05261", "contents": "Title: Regularity structures and the dynamical $\\Phi^4_3$ model Abstract: We give a concise overview of the theory of regularity structures as first\nexposed in [Hai14]. In order to allow to focus on the conceptual aspects of the\ntheory, many proofs are omitted and statements are simplified. In order to\nprovide both motivation and focus, we concentrate on the study of solutions to\nthe stochastic quantisation equations for the Euclidean $\\Phi^4_3$ quantum\nfield theory which can be obtained with the help of this theory. In particular,\nwe sketch the proofs of how one can show that this model arises quite naturally\nas an idealised limiting object for several classes of smooth models. \n\n"}
{"id": "1508.05669", "contents": "Title: A stochastic two-stage innovation diffusion model on a lattice Abstract: We propose a stochastic model describing a process of awareness, evaluation\nand decision-making by agents on the d-dimensional integer lattice. Each agent\nmay be in any of the three states belonging to the set {0, 1, 2}. In this model\n0 stands for ignorants, 1 for aware and 2 for adopters. Aware and adopters\ninform its nearest ignorant neighbors about a new product innovation at rate\nlambda. At rate alpha an agent in aware state becomes an adopter due to the\ninfluence of adopters neighbors. Finally, aware and adopters forget the\ninformation about the new product, thus becoming ignorant, at rate one. Our\npurpose is to analyze the influence of the parameters on the qualitative\nbehavior of the process. We obtain sufficient conditions under which the\ninnovation diffusion (and adoption) either becomes extinct or propagates\nthrough the population with positive probability. \n\n"}
{"id": "1508.06321", "contents": "Title: When large n is not enough---Distribution-free Interval Estimators for\n  Ratios of Quantiles Abstract: Ratios of sample percentiles or of quantiles based on a single sample are\noften published for skewed income data to illustrate aspects of income\ninequality, but distribution-free confidence intervals for such ratios are to\nour knowledge not in the literature. Here we derive and compare two\nlarge-sample methods for obtaining such intervals. They both require good\ndistribution-free estimates of the quantile density at the quantiles of\ninterest, and such estimates have recently become available. Simulation studies\nfor various sample sizes are carried out for Pareto, lognormal and exponential\ndistributions, as well as fitted generalized lambda distributions, to determine\nthe coverage probabilities and widths of the intervals. Robustness of the\nestimators to contamination or a positive proportion of zero incomes is\nexamined via influence functions. The motivating example is Australian\nhousehold income data where ratios of quantiles measure inequality, but of\ncourse these results apply equally to data from other countries. \n\n"}
{"id": "1508.07422", "contents": "Title: Rate functions for symmetric markov processes via heat kernel Abstract: By making full use of heat kernel estimates, we establish the integral tests\non the zero-one laws of upper and lower bounds for the sample path ranges of\nsymmetric Markov processes. In particular, these results concerning on upper\nrate bounds are applicable for local and non-local Dirichlet forms, while lower\nrate bounds are investigated in both subcritical setting and critical setting. \n\n"}
{"id": "1508.07511", "contents": "Title: A Bayesian Hierarchical Model for Prediction of Latent Health States\n  from Multiple Data Sources with Application to Active Surveillance of\n  Prostate Cancer Abstract: In this article, we present a Bayesian hierarchical model for predicting a\nlatent health state from longitudinal clinical measurements. Model development\nis motivated by the need to integrate multiple sources of data to improve\nclinical decisions about whether to remove or irradiate a patient's prostate\ncancer. Existing modeling approaches are extended to accommodate measurement\nerror in cancer state determinations based on biopsied tissue, clinical\nmeasurements possibly not missing at random, and informative partial\nobservation of the true state. The proposed model enables estimation of whether\nan individual's underlying prostate cancer is aggressive, requiring surgery\nand/or radiation, or indolent, permitting continued surveillance. These\nindividualized predictions can then be communicated to clinicians and patients\nto inform decision-making. We demonstrate the model with data from a cohort of\nlow risk prostate cancer patients at Johns Hopkins University and assess\npredictive accuracy among a subset for whom true cancer state is observed.\nSimulation studies confirm model performance and explore the impact of\nadjusting for informative missingness on true state predictions. R code and\nsimulated data available at\nhttps://github.com/rycoley/prediction-prostate-surveillance. \n\n"}
{"id": "1509.00172", "contents": "Title: Adaptive, delayed-acceptance MCMC for targets with expensive likelihoods Abstract: When conducting Bayesian inference, delayed acceptance (DA)\nMetropolis-Hastings (MH) algorithms and DA pseudo-marginal MH algorithms can be\napplied when it is computationally expensive to calculate the true posterior or\nan unbiased estimate thereof, but a computationally cheap approximation is\navailable. A first accept-reject stage is applied, with the cheap approximation\nsubstituted for the true posterior in the MH acceptance ratio. Only for those\nproposals which pass through the first stage is the computationally expensive\ntrue posterior (or unbiased estimate thereof) evaluated, with a second\naccept-reject stage ensuring that detailed balance is satisfied with respect to\nthe intended true posterior. In some scenarios there is no obvious\ncomputationally cheap approximation. A weighted average of previous evaluations\nof the computationally expensive posterior provides a generic approximation to\nthe posterior. If only the $k$-nearest neighbours have non-zero weights then\nevaluation of the approximate posterior can be made computationally cheap\nprovided that the points at which the posterior has been evaluated are stored\nin a multi-dimensional binary tree, known as a KD-tree. The contents of the\nKD-tree are potentially updated after every computationally intensive\nevaluation. The resulting adaptive, delayed-acceptance [pseudo-marginal]\nMetropolis-Hastings algorithm is justified both theoretically and empirically.\nGuidance on tuning parameters is provided and the methodology is applied to a\ndiscretely observed Markov jump process characterising predator-prey\ninteractions and an ODE system describing the dynamics of an autoregulatory\ngene network. \n\n"}
{"id": "1509.00899", "contents": "Title: A robust approach for estimating change-points in the mean of an AR(p)\n  process Abstract: We consider the problem of change-points estimation in the mean of an AR(p)\nprocess. Taking into account the dependence structure does not allow us to use\nthe approach of the independent case. Especially, the dynamic programming\nalgorithm giving the optimal solution in the independent case cannot be used\nanymore. We propose a two-step method, based on the preliminary robust (to the\nchange-points) estimation of the autoregression parameters. Then, we propose to\nfollow the classical approach, by plugging this estimator in the criterion used\nfor change-point estimation, which is equivalent to decorrelate the series\nusing the estimated autoregression parameters. We show that the asymptotic\nproperties of these change-point location and mean estimators are the same as\nthose of the classical estimators in the independent framework. The same\nplug-in approach is then used to approximate the modified BIC and choose the\nnumber of segments, and to derive a heuristic BIC criterion to select both the\nnumber of changes and the order of the autoregression. Finally, we show, in the\nsimulation section, that for finite sample size taking into account the\ndependence structure improves the statistical performance of the change-point\nestimators and of the selection criterion. \n\n"}
{"id": "1509.01010", "contents": "Title: A method for comparing non-nested models with application to\n  astrophysical searches for new physics Abstract: Searches for unknown physics and decisions between competing astrophysical\nmodels to explain data both rely on statistical hypothesis testing. The usual\napproach in searches for new physical phenomena is based on the statistical\nLikelihood Ratio Test (LRT) and its asymptotic properties. In the common\nsituation, when neither of the two models under comparison is a special case of\nthe other i.e., when the hypotheses are non-nested, this test is not\napplicable. In astrophysics, this problem occurs when two models that reside in\ndifferent parameter spaces are to be compared. An important example is the\nrecently reported excess emission in astrophysical $\\gamma$-rays and the\nquestion whether its origin is known astrophysics or dark matter. We develop\nand study a new, simple, generally applicable, frequentist method and validate\nits statistical properties using a suite of simulations studies. We exemplify\nit on realistic simulated data of the Fermi-LAT $\\gamma$-ray satellite, where\nnon-nested hypotheses testing appears in the search for particle dark matter. \n\n"}
{"id": "1509.01154", "contents": "Title: Rough linear PDE's with discontinuous coefficients - existence of\n  solutions via regularization by fractional Brownian motion Abstract: We consider two related linear PDE's perturbed by a fractional Brownian\nmotion. We allow the drift to be discontinuous, in which case the corresponding\ndeterministic equation is ill-posed. However, the noise will be shown to have a\nregularizing effect on the equations in the sense that we can prove existence\nof solutions for almost all paths of the fractional Brownian motion. \n\n"}
{"id": "1509.01405", "contents": "Title: Latent drop-out transitions in quantile regression Abstract: Longitudinal data are characterized by the dependence between observations\ncoming from the same individual. In a regression perspective, such a dependence\ncan be usefully ascribed to unobserved features (covariates) specific to each\nindividual. On these grounds, random parameter models with time-constant or\ntime-varying structure are well established in the generalized linear model\ncontext. In the quantile regression framework, specifications based on random\nparameters have only recently known a flowering interest. We start from the\nrecent proposal by Farcomeni (2012) on longitudinal quantile hidden Markov\nmodels, and extend it to handle potentially informative missing data mechanism.\nIn particular, we focus on monotone missingness which may lead to selection\nbias and, therefore, to unreliable inferences on model parameters. We detail\nthe proposed approach by re-analyzing a well known dataset on the dynamics of\nCD4 cell counts in HIV seroconverters and by means of a simulation study. \n\n"}
{"id": "1509.04133", "contents": "Title: Extinction time for the contact process on general graphs Abstract: We consider the contact process on finite and connected graphs and study the\nbehavior of the extinction time, that is, the amount of time that it takes for\nthe infection to disappear in the process started from full occupancy. We\nprove, without any restriction on the graph $G$, that if the infection rate\n$\\lambda$ is larger than the critical rate of the one-dimensional process, then\nthe extinction time grows faster than $\\exp\\{|G|/(\\log|G|)^\\kappa\\}$ for any\nconstant $\\kappa > 1$, where $|G|$ denotes the number of vertices of $G$. Also\nfor general graphs, we show that the extinction time divided by its expectation\nconverges in distribution, as the number of vertices tends to infinity, to the\nexponential distribution with parameter 1. These results complement earlier\nwork of Mountford, Mourrat, Valesin and Yao, in which only graphs of bounded\ndegrees were considered, and the extinction time was shown to grow\nexponentially in $n$; here we also provide a simpler proof of this fact. \n\n"}
{"id": "1509.04704", "contents": "Title: Central limit theorems for network driven sampling Abstract: Respondent-Driven Sampling is a popular technique for sampling hidden\npopulations. This paper models Respondent-Driven Sampling as a Markov process\nindexed by a tree. Our main results show that the Volz-Heckathorn estimator is\nasymptotically normal below a critical threshold. The key technical\ndifficulties stem from (i) the dependence between samples and (ii) the tree\nstructure which characterizes the dependence. The theorems allow the growth\nrate of the tree to exceed one and suggest that this growth rate should not be\ntoo large. To illustrate the usefulness of these results beyond their obvious\nuse, an example shows that in certain cases the sample average is preferable to\ninverse probability weighting. We provide a test statistic to distinguish\nbetween these two cases. \n\n"}
{"id": "1509.05253", "contents": "Title: Logarithmic, Coulomb and Riesz energy of point processes Abstract: We define a notion of logarithmic, Coulomb and Riesz interactions in any\ndimension for random systems of infinite charged point configurations with a\nuniform background of opposite sign. We connect this interaction energy with\nthe \"renormalized energy\" studied by Serfaty et al., which appears in the free\nenergy functional governing the microscopic behavior of logarithmic, Coulomb\nand Riesz gases. Minimizers of this functional include the Sine-beta processes\nin the one-dimensional Log-gas case. Using our explicit expression (inspired by\nthe work of Borodin-Serfaty) we prove their convergence to the Poisson process\nin the high-temperature limit as well as a crystallization result in the\nlow-temperature limit for one-dimensional systems. \n\n"}
{"id": "1509.06428", "contents": "Title: Large-Scale Mode Identification and Data-Driven Sciences Abstract: Bump-hunting or mode identification is a fundamental problem that arises in\nalmost every scientific field of data-driven discovery. Surprisingly, very few\ndata modeling tools are available for automatic (not requiring manual\ncase-by-base investigation), objective (not subjective), and nonparametric (not\nbased on restrictive parametric model assumptions) mode discovery, which can\nscale to large data sets. This article introduces LPMode--an algorithm based on\na new theory for detecting multimodality of a probability density. We apply\nLPMode to answer important research questions arising in various fields from\nenvironmental science, ecology, econometrics, analytical chemistry to astronomy\nand cancer genomics. \n\n"}
{"id": "1509.06459", "contents": "Title: Stochastic gradient descent methods for estimation with large data sets Abstract: We develop methods for parameter estimation in settings with large-scale data\nsets, where traditional methods are no longer tenable. Our methods rely on\nstochastic approximations, which are computationally efficient as they maintain\none iterate as a parameter estimate, and successively update that iterate based\non a single data point. When the update is based on a noisy gradient, the\nstochastic approximation is known as standard stochastic gradient descent,\nwhich has been fundamental in modern applications with large data sets.\nAdditionally, our methods are numerically stable because they employ implicit\nupdates of the iterates. Intuitively, an implicit update is a shrinked version\nof a standard one, where the shrinkage factor depends on the observed Fisher\ninformation at the corresponding data point. This shrinkage prevents numerical\ndivergence of the iterates, which can be caused either by excess noise or\noutliers. Our sgd package in R offers the most extensive and robust\nimplementation of stochastic gradient descent methods. We demonstrate that sgd\ndominates alternative software in runtime for several estimation problems with\nmassive data sets. Our applications include the wide class of generalized\nlinear models as well as M-estimation for robust regression. \n\n"}
{"id": "1509.07159", "contents": "Title: From gap probabilities in random matrix theory to eigenvalue expansions Abstract: We present a method to derive asymptotics of eigenvalues for trace-class\nintegral operators $K:L^2(J;d\\lambda)\\circlearrowleft$, acting on a single\ninterval $J\\subset\\mathbb{R}$, which belong to the ring of integrable operators\n\\cite{IIKS}. Our emphasis lies on the behavior of the spectrum\n$\\{\\lambda_i(J)\\}_{i=0}^{\\infty}$ of $K$ as $|J|\\rightarrow\\infty$ and $i$ is\nfixed. We show that this behavior is intimately linked to the analysis of the\nFredholm determinant $\\det(I-\\gamma K)|_{L^2(J)}$ as $|J|\\rightarrow\\infty$ and\n$\\gamma\\uparrow 1$ in a Stokes type scaling regime. Concrete asymptotic\nformul\\ae\\, are obtained for the eigenvalues of Airy and Bessel kernels in\nrandom matrix theory. \n\n"}
{"id": "1509.08056", "contents": "Title: Discovery and Visualization of Nonstationary Causal Models Abstract: It is commonplace to encounter nonstationary data, of which the underlying\ngenerating process may change over time or across domains. The nonstationarity\npresents both challenges and opportunities for causal discovery. In this paper\nwe propose a principled framework to handle nonstationarity, and develop some\nmethods to address three important questions. First, we propose an enhanced\nconstraint-based method to detect variables whose local mechanisms are\nnonstationary and recover the skeleton of the causal structure over observed\nvariables. Second, we present a way to determine some causal directions by\ntaking advantage of information carried by changing distributions. Third, we\ndevelop a method for visualizing the nonstationarity of causal modules.\nExperimental results on various synthetic and real-world data sets are\npresented to demonstrate the efficacy of our methods. \n\n"}
{"id": "1509.08124", "contents": "Title: A testing-based approach to the discovery of differentially correlated\n  variable sets Abstract: Given data obtained under two sampling conditions, it is often of interest to\nidentify variables that behave differently in one condition than in the other.\nWe introduce a method for differential analysis of second-order behavior called\nDifferential Correlation Mining (DCM). The DCM method identifies differentially\ncorrelated sets of variables, with the property that the average pairwise\ncorrelation between variables in a set is higher under one sample condition\nthan the other. DCM is based on an iterative search procedure that adaptively\nupdates the size and elements of a candidate variable set. Updates are\nperformed via hypothesis testing of individual variables, based on the\nasymptotic distribution of their average differential correlation. We\ninvestigate the performance of DCM by applying it to simulated data as well as\nrecent experimental datasets in genomics and brain imaging. \n\n"}
{"id": "1509.08614", "contents": "Title: Free infinite divisibility for powers of random variables Abstract: We prove that $X^r$ follows an FID distribution if: (1) $X$ follows a free\nPoisson distribution without an atom at 0 and $r\\in(-\\infty,0]\\cup[1,\\infty)$;\n(2) $X$ follows a free Poisson distribution with an atom at 0 and $r\\geq1$; (3)\n$X$ follows a mixture of some HCM distributions and $|r|\\geq1$; (4) $X$ follows\nsome beta distributions and $r$ is taken from some interval. In particular, if\n$S$ is a standard semicircular element then $|S|^r$ is freely infinitely\ndivisible for $r\\in(-\\infty,0]\\cup[2,\\infty)$. Also we consider the\nsymmetrization of the above probability measures, and in particular show that\n$|S|^r \\,\\text{sign}(S)$ is freely infinitely divisible for $r\\geq2$. Therefore\n$S^n$ is freely infinitely divisible for every $n\\in\\mathbb N$. The results on\nfree Poisson and semicircular random variables have a good correspondence with\nclassical ID properties of powers of gamma and normal random variables. \n\n"}
{"id": "1509.08989", "contents": "Title: On the Maximal Displacement of Subcritical Branching Random Walks Abstract: We study the maximal displacement of a one dimensional subcritical branching\nrandom walk initiated by a single particle at the origin. For each\n$n\\in\\mathbb{N},$ let $M_{n}$ be the rightmost position reached by the\nbranching random walk up to generation $n$. Under the assumption that the\noffspring distribution has a finite third moment and the jump distribution has\nmean zero and a finite probability generating function, we show that there\nexists $\\rho>1$ such that the function \\[ g(c,n):=\\rho ^{cn} P(M_{n}\\geq cn),\n\\quad \\mbox{for each }c>0 \\mbox{ and } n\\in\\mathbb{N}, \\] satisfies the\nfollowing properties: there exist $0<\\underline{\\delta}\\leq \\overline{\\delta} <\n{\\infty}$ such that if $c<\\underline{\\delta}$, then $$\n0<\\liminf_{n\\rightarrow\\infty} g (c,n)\\leq \\limsup_{n\\rightarrow\\infty} g (c,n)\n{\\leq 1}, $$ while if $c>\\overline{\\delta}$, then \\[ \\lim_{n\\rightarrow\\infty}\ng (c,n)=0. \\] Moreover, if the jump distribution has a finite right range $R$,\nthen $\\overline{\\delta} < R$. If furthermore the jump distribution is \"nearly\nright-continuous\", then there exists $\\kappa\\in (0,1]$ such that\n$\\lim_{n\\rightarrow \\infty}g(c,n)=\\kappa$ for all $c<\\underline{\\delta}$. We\nalso show that the tail distribution of $M:=\\sup_{n\\geq 0}M_{n}$, namely, the\nrightmost position ever reached by the branching random walk, has a similar\nexponential decay (without the cutoff at $\\underline{\\delta}$). Finally, by\nduality, these results imply that the maximal displacement of supercritical\nbranching random walks conditional on extinction has a similar tail behavior. \n\n"}
{"id": "1510.01064", "contents": "Title: Boosting in the presence of outliers: adaptive classification with\n  non-convex loss functions Abstract: This paper examines the role and efficiency of the non-convex loss functions\nfor binary classification problems. In particular, we investigate how to design\na simple and effective boosting algorithm that is robust to the outliers in the\ndata. The analysis of the role of a particular non-convex loss for prediction\naccuracy varies depending on the diminishing tail properties of the gradient of\nthe loss -- the ability of the loss to efficiently adapt to the outlying data,\nthe local convex properties of the loss and the proportion of the contaminated\ndata. In order to use these properties efficiently, we propose a new family of\nnon-convex losses named $\\gamma$-robust losses. Moreover, we present a new\nboosting framework, {\\it Arch Boost}, designed for augmenting the existing work\nsuch that its corresponding classification algorithm is significantly more\nadaptable to the unknown data contamination. Along with the Arch Boosting\nframework, the non-convex losses lead to the new class of boosting algorithms,\nnamed adaptive, robust, boosting (ARB). Furthermore, we present theoretical\nexamples that demonstrate the robustness properties of the proposed algorithms.\nIn particular, we develop a new breakdown point analysis and a new influence\nfunction analysis that demonstrate gains in robustness. Moreover, we present\nnew theoretical results, based only on local curvatures, which may be used to\nestablish statistical and optimization properties of the proposed Arch boosting\nalgorithms with highly non-convex loss functions. Extensive numerical\ncalculations are used to illustrate these theoretical properties and reveal\nadvantages over the existing boosting methods when data exhibits a number of\noutliers. \n\n"}
{"id": "1510.01249", "contents": "Title: Heavy traffic approximation for the stationary distribution of a\n  generalized Jackson network: the BAR approach Abstract: In the seminal paper of Gamarnik and Zeevi (2006), the authors justify the\nsteady-state diffusion approximation of a generalized Jackson network (GJN) in\nheavy traffic. Their approach involves the so-called limit interchange\nargument, which has since become a popular tool employed by many others who\nstudy diffusion approximations. In this paper we illustrate a novel approach by\nusing it to justify the steady-state approximation of a GJN in heavy traffic.\nOur approach involves working directly with the basic adjoint relationship\n(BAR), an integral equation that characterizes the stationary distribution of a\nMarkov process. As we will show, the BAR approach is a more natural choice than\nthe limit interchange approach for justifying steady-state approximations, and\ncan potentially be applied to the study of other stochastic processing networks\nsuch as multiclass queueing networks. \n\n"}
{"id": "1510.02399", "contents": "Title: Dynamic Factor Models, Cointegration, and Error Correction Mechanisms Abstract: The paper studies Non-Stationary Dynamic Factor Models such that the factors\n$\\mathbf F_t$ are $I(1)$ and singular, i.e. $\\mathbf F_t$ has dimension $r$ and\nis driven by a $q$-dimensional white noise, the common shocks, with $q<r$. We\nshow that $\\mathbf F_t$ is driven by $r-c$ permanent shocks, where $c$ is the\ncointegration rank of $\\mathbf F_t$, and $q-(r-c)<c$ transitory shocks, thus\nthe same result as in the non-singular case for the permanent shocks but not\nfor the transitory shocks. Our main result is obtained by combining the classic\nGranger Representation Theorem with recent results by Anderson and Deistler on\nsingular stochastic vectors: if $(1-L)\\mathbf F_t$ is singular and has {\\it\nrational} spectral density then, for generic values of the parameters, $\\mathbf\nF_t$ has an autoregressive representation with a {\\it finite-degree} matrix\npolynomial fulfilling the restrictions of a Vector Error Correction Mechanism\nwith $c$ error terms. This result is the basis for consistent estimation of\nNon-Stationary Dynamic Factor Models. The relationship between cointegration of\nthe factors and cointegration of the observable variables is also discussed. \n\n"}
{"id": "1510.02502", "contents": "Title: Statistical Analysis of Persistence Intensity Functions Abstract: Persistence diagrams are two-dimensional plots that summarize the topological\nfeatures of functions and are an important part of topological data analysis. A\nproblem that has received much attention is how deal with sets of persistence\ndiagrams. How do we summarize them, average them or cluster them? One approach\n-- the persistence intensity function -- was introduced informally by\nEdelsbrunner, Ivanov, and Karasev (2012). Here we provide a modification and\nformalization of this approach. Using the persistence intensity function, we\ncan visualize multiple diagrams, perform clustering and conduct two-sample\ntests. \n\n"}
{"id": "1510.03781", "contents": "Title: A Scalable Empirical Bayes Approach to Variable Selection Abstract: We develop a model-based empirical Bayes approach to variable selection\nproblems in which the number of predictors is very large, possibly much larger\nthan the number of responses (the so-called 'large p, small n' problem). We\nconsider the multiple linear regression setting, where the response is assumed\nto be a continuous variable and it is a linear function of the predictors plus\nerror. The explanatory variables in the linear model can have a positive effect\non the response, a negative effect, or no effect. We model the effects of the\nlinear predictors as a three-component mixture in which a key assumption is\nthat only a small (unknown) fraction of the candidate predictors have a\nnon-zero effect on the response variable. By treating the coefficients as\nrandom effects we develop an approach that is computationally efficient because\nthe number of parameters that have to be estimated is small, and remains\nconstant regardless of the number of explanatory variables. The model\nparameters are estimated using the EM algorithm which is scalable and leads to\nsignificantly faster convergence, compared with simulation-based methods. \n\n"}
{"id": "1510.05390", "contents": "Title: Entropy and thinning of discrete random variables Abstract: We describe five types of results concerning information and concentration of\ndiscrete random variables, and relationships between them, motivated by their\ncounterparts in the continuous case. The results we consider are information\ntheoretic approaches to Poisson approximation, the maximum entropy property of\nthe Poisson distribution, discrete concentration (Poincar\\'{e} and logarithmic\nSobolev) inequalities, monotonicity of entropy and concavity of entropy in the\nShepp--Olkin regime. \n\n"}
{"id": "1510.06084", "contents": "Title: The exact Taylor formula of the implied volatility Abstract: In a model driven by a multi-dimensional local diffusion, we study the\nbehavior of implied volatility {\\sigma} and its derivatives with respect to\nlog-strike k and maturity T near expiry and at the money. We recover explicit\nlimits of these derivatives for (T,k) approaching the origin within the\nparabolic region |x-k|^2 < {\\lambda} T, with x denoting the spot log-price of\nthe underlying asset and where {\\lambda} is a positive and arbitrarily large\nconstant. Such limits yield the exact Taylor formula for implied volatility\nwithin the parabola |x-k|^2 < {\\lambda} T. In order to include important models\nof interest in mathematical finance, e.g. Heston, CEV, SABR, the analysis is\ncarried out under the assumption that the infinitesimal generator of the\ndiffusion is only locally elliptic. \n\n"}
{"id": "1510.08244", "contents": "Title: On convex hull and winding number of self similar processes Abstract: It is well known that for a standard Brownian motion (BM) $ \\{B(t), \\;t \\geq\n0\\}$ with values in $\\mathbb{R}^d$, its convex hull $ V(t)=\\conv \\{\\{\\,B(s),\\;s\n\\leq t \\}$ with probability $1$ for each $t > 0$ contains $0$ as an interior\npoint (see Evans (1985)). We also know that the winding number of a typical\npath of a $2$-dimensional BM is equal to $+\\infty.$\n  The aim of this article is to show that these properties aren't specifically\n\"Brownian\", but hold for a much larger class of $d$-dimensional self similar\nprocesses. This class contains in particular $d$-dimensional fractional\nBrownian motions and (concerning convex hulls) strictly stable Levy processes. \n\n"}
{"id": "1510.08659", "contents": "Title: Self-avoiding walks and amenability Abstract: The connective constant $\\mu(G)$ of an infinite transitive graph $G$ is the\nexponential growth rate of the number of self-avoiding walks from a given\norigin. The relationship between connective constants and amenability is\nexplored in the current work.\n  Various properties of connective constants depend on the existence of\nso-called 'graph height functions', namely: (i) whether $\\mu(G)$ is a local\nfunction on certain graphs derived from $G$, (ii) the equality of $\\mu(G)$ and\nthe asymptotic growth rate of bridges, and (iii) whether there exists a\nterminating algorithm for approximating $\\mu(G)$ to a given degree of accuracy.\n  In the context of amenable groups, it is proved that the Cayley graphs of\ninfinite, finitely generated, elementary amenable groups support graph height\nfunctions, which are in addition harmonic. In contrast, the Cayley graph of the\nGrigorchuk group, which is amenable but not elementary amenable, does not have\na graph height function.\n  In the context of non-amenable, transitive graphs, a lower bound is presented\nfor the connective constant in terms of the spectral bottom of the graph. This\nis a strengthening of an earlier result of the same authors. Secondly, using a\npercolation inequality of Benjamini, Nachmias, and Peres, it is explained that\nthe connective constant of a non-amenable, transitive graph with large girth is\nclose to that of a regular tree. Examples are given of non-amenable groups\nwithout graph height functions, of which one is the Higman group. \n\n"}
{"id": "1510.09072", "contents": "Title: Palindromic Bernoulli distributions Abstract: We introduce and study a subclass of joint Bernoulli distributions which has\nthe palindromic property. For such distributions the vector of joint\nprobabilities is unchanged when the order of the elements is reversed. We prove\nfor binary variables that the palindromic property is equivalent to zero\nconstraints on all odd-order interaction parameters, be it in parameterizations\nwhich are log-linear, linear or multivariate logistic. In particular, we derive\nthe one-to-one parametric transformations for these three types of model\nspecifications and give simple closed forms of maximum likelihood estimates.\nSome special cases and a case study are described. \n\n"}
{"id": "1511.01195", "contents": "Title: Small scale equidistribution of random eigenbases Abstract: We investigate small scale equidistribution of random orthonormal bases of\neigenfunctions (i.e. eigenbases) on a compact manifold M. Assume that the group\nof isometries acts transitively on M and the multiplicity of eigenfrequency\ntends to infinity at least logarithmically. We prove that, with respect to the\nnatural probability measure on the space of eigenbases, almost surely a random\neigenbasis is equidistributed at small scales; furthermore, the scales depend\non the growth rate of multiplicity. In particular, this implies that almost\nsurely random eigenbases on the n-dimensional sphere (n>=2) and the\nn-dimensional tori (n>=5) are equidistributed at polynomial scales. \n\n"}
{"id": "1511.02717", "contents": "Title: Strong existence and higher order Fr\\'echet differentiability of\n  stochastic flows of fractional Brownian motion driven SDE's with singular\n  drift Abstract: In this paper we present a new method for the construction of strong\nsolutions of SDE's with merely integrable drift coefficients driven by a\nmultidimensional fractional Brownian motion with Hurst parameter H < 1/2.\nFurthermore, we prove the rather surprising result of the higher order Frechet\ndifferentiability of stochastic flows of such SDE's in the case of a small\nHurst parameter. In establishing these results we use techniques from Malliavin\ncalculus combined with new ideas based on a \"local time variational calculus\".\nWe expect that our general approach can be also applied to the study of certain\ntypes of stochastic partial differential equations as e.g. stochastic\nconservation laws driven by rough paths. \n\n"}
{"id": "1511.03334", "contents": "Title: Goodness of fit tests for high-dimensional linear models Abstract: In this work we propose a framework for constructing goodness of fit tests in\nboth low and high-dimensional linear models. We advocate applying regression\nmethods to the scaled residuals following either an ordinary least squares or\nLasso fit to the data, and using some proxy for prediction error as the final\ntest statistic. We call this family Residual Prediction (RP) tests. We show\nthat simulation can be used to obtain the critical values for such tests in the\nlow-dimensional setting, and demonstrate using both theoretical results and\nextensive numerical studies that some form of the parametric bootstrap can do\nthe same when the high-dimensional linear model is under consideration. We show\nthat RP tests can be used to test for significance of groups or individual\nvariables as special cases, and here they compare favourably with state of the\nart methods, but we also argue that they can be designed to test for as diverse\nmodel misspecifications as heteroscedasticity and nonlinearity. \n\n"}
{"id": "1511.06250", "contents": "Title: Discrete Bochner inequalities via the Bochner-Bakry-Emery approach for\n  Markov chains Abstract: Discrete convex Sobolev inequalities and Beckner inequalities are derived for\ntime-continuous Markov chains on finite state spaces. Beckner inequalities\ninterpolate between the modified logarithmic Sobolev inequality and the\nPoincar\\'e inequality. Their proof is based on the Bakry-Emery approach and on\ndiscrete Bochner-type inequalities established by Caputo, Dai Pra, and Posta\nand recently extended by Fathi and Maas for logarithmic entropies. The abstract\nresult for convex entropies is applied to several Markov chains, including\nbirth-death processes, zero-range processes, Bernoulli-Laplace models, and\nrandom transposition models, and to a finite-volume discretization of a\none-dimensional Fokker-Planck equation, applying results by Mielke. \n\n"}
{"id": "1511.06417", "contents": "Title: Modelling Spatial Compositional Data: Reconstructions of past land cover\n  and uncertainties Abstract: In this paper, we construct a hierarchical model for spatial compositional\ndata, which is used to reconstruct past land-cover compositions (in terms of\nconiferous forest, broadleaved forest, and unforested/open land) for five time\nperiods during the past $6\\,000$ years over Europe. The model consists of a\nGaussian Markov Random Field (GMRF) with Dirichlet observations. A block\nupdated Markov chain Monte Carlo (MCMC), including an adaptive Metropolis\nadjusted Langevin step, is used to estimate model parameters. The sparse\nprecision matrix in the GMRF provides computational advantages leading to a\nfast MCMC algorithm. Reconstructions are obtained by combining pollen-based\nestimates of vegetation cover at a limited number of locations with scenarios\nof past deforestation and output from a dynamic vegetation model. To evaluate\nuncertainties in the predictions a novel way of constructing joint confidence\nregions for the entire composition at each prediction location is proposed. The\nhierarchical model's ability to reconstruct past land cover is evaluated\nthrough cross validation for all time periods, and by comparing reconstructions\nfor the recent past to a present day European forest map. The evaluation\nresults are promising and the model is able to capture known structures in past\nland-cover compositions. \n\n"}
{"id": "1511.06733", "contents": "Title: On an inferential model construction using generalized associations Abstract: The inferential model (IM) approach, like fiducial and its generalizations,\ndepends on a representation of the data-generating process. Here, a particular\nvariation on the IM construction is considered, one based on generalized\nassociations. The resulting generalized IM is more flexible than the basic IM\nin that it does not require a complete specification of the data-generating\nprocess and is provably valid under mild conditions. Computation and\nmarginalization strategies are discussed, and two applications of this\ngeneralized IM approach are presented. \n\n"}
{"id": "1511.07703", "contents": "Title: Convergence of EM Scheme for Neutral Stochastic Differential Delay\n  Equations Abstract: In this paper, we are concerned with convergence rate of Euler-Maruyama (EM)\nscheme for stochastic differential delay equations (SDDEs) of neutral type,\nwhere the neutral term, the drift term and the diffusion term are allowed to be\nof polynomial growth. More precisely, for SDDEs of neutral type driven by\nBrownian motions, we reveal that the convergence rate of the corresponding EM\nscheme is one half; Whereas for SDDEs of neutral type driven by jump processes,\nwe show that the best convergence rate of the associated EM scheme is close to\none half. \n\n"}
{"id": "1512.01065", "contents": "Title: Incorporating social contact data in spatio-temporal models for\n  infectious disease spread Abstract: Routine public health surveillance of notifiable infectious diseases gives\nrise to weekly counts of reported cases -- possibly stratified by region and/or\nage group. We investigate how an age-structured social contact matrix can be\nincorporated into a spatio-temporal endemic-epidemic model for infectious\ndisease counts. To illustrate the approach, we analyze the spread of norovirus\ngastroenteritis over 6 age groups within the 12 districts of Berlin, 2011-2015,\nusing contact data from the POLYMOD study. The proposed age-structured model\noutperforms alternative scenarios with homogeneous or no mixing between age\ngroups. An extended contact model suggests a power transformation of the\nsurvey-based contact matrix towards more within-group transmission. \n\n"}
{"id": "1512.01153", "contents": "Title: A Feynman-Kac formula for differential forms on manifolds with boundary\n  and applications Abstract: We prove a Feynman-Kac formula for differential forms satisfying absolute\nboundary conditions on Riemannian manifolds with boundary and of bounded\ngeometry. We use this to construct $L^2$ harmonic forms out of bounded ones on\nthe universal cover of a compact Riemannian manifold whose geometry displays a\npositivity property expressed in terms of a certain stochastic average of the\nWeitzenb\\\"ock operator $R_p$ acting on $p$-forms and the second fundamental\nform of the boundary. This extends previous work by Elworthy-Li-Rosenberg on\nclosed manifolds to this setting. As an application we find a geometric\nobstruction to the existence of metrics with 2-convex boundary and positive\n$R_2$ in this stochastic sense. We also discuss a version of the Feynman-Kac\nformula for spinors under suitable boundary conditions. \n\n"}
{"id": "1512.03572", "contents": "Title: Limits of subcritical random graphs and random graphs with excluded\n  minors Abstract: We prove local convergence results for the uniformly random, labelled or\nunlabelled, graphs from subcritical families. As an example special case, we\nprove Benjamini-Schramm convergence for the uniform random unlabelled tree. We\nintroduce a compactification of the space of countable (connected) rooted\ngraphs, and use it to generalise the notion of Benjamini-Schramm convergence in\norder to allow for vertices of infinite degree in the limit object. \n\n"}
{"id": "1512.04093", "contents": "Title: Multiple Change-point Detection: a Selective Overview Abstract: Very long and noisy sequence data arise from biological sciences to social\nscience including high throughput data in genomics and stock prices in\neconometrics. Often such data are collected in order to identify and understand\nshifts in trend, e.g., from a bull market to a bear market in finance or from a\nnormal number of chromosome copies to an excessive number of chromosome copies\nin genetics. Thus, identifying multiple change points in a long, possibly very\nlong, sequence is an important problem. In this article, we review both\nclassical and new multiple change-point detection strategies. Considering the\nlong history and the extensive literature on the change-point detection, we\nprovide an in-depth discussion on a normal mean change-point model from aspects\nof regression analysis, hypothesis testing, consistency and inference. In\nparticular, we present a strategy to gather and aggregate local information for\nchange-point detection that has become the cornerstone of several emerging\nmethods because of its attractiveness in both computational and theoretical\nproperties. \n\n"}
{"id": "1512.05178", "contents": "Title: Crossing probabilities for critical Bernoulli percolation on slabs Abstract: We prove that in the critical Bernoulli percolation on two dimensional\nlattice slabs the probabilities of open left-right crossings of rectangles with\nany given aspect ratio are uniformly positive. \n\n"}
{"id": "1512.06640", "contents": "Title: Peacocks nearby: approximating sequences of measures Abstract: A peacock is a family of probability measures with finite mean that increases\nin convex order. It is a classical result, in the discrete time case due to\nStrassen, that any peacock is the family of one-dimensional marginals of a\nmartingale. We study the problem whether a given sequence of probability\nmeasures can be approximated by a peacock. In our main results, the\napproximation quality is measured by the infinity Wasserstein distance.\nExistence of a peacock within a prescribed distance is reduced to a countable\ncollection of rather explicit conditions. This result has a financial\napplication (developed in a separate paper), as it allows to check European\ncall option quotes for consistency. The distance bound on the peacock than\ntakes the role of a bound on the bid-ask spread of the underlying. We also\nsolve the approximation problem for the stop-loss distance, the L\\'evy\ndistance, and the Prokhorov distance. \n\n"}
{"id": "1512.07075", "contents": "Title: A semiparametric extension of the stochastic block model for\n  longitudinal networks Abstract: To model recurrent interaction events in continuous time, an extension of the\nstochastic block model is proposed where every individual belongs to a latent\ngroup and interactions between two individuals follow a conditional\ninhomogeneous Poisson process with intensity driven by the individuals' latent\ngroups. The model is shown to be identifiable and its estimation is based on a\nsemiparametric variational expectation-maximization algorithm. Two versions of\nthe method are developed, using either a nonparametric histogram approach (with\nan adaptive choice of the partition size) or kernel intensity estimators. The\nnumber of latent groups can be selected by an integrated classification\nlikelihood criterion. Finally, we demonstrate the performance of our procedure\non synthetic experiments, analyse two datasets to illustrate the utility of our\napproach and comment on competing methods. \n\n"}
{"id": "1601.03605", "contents": "Title: Hierarchical Bayesian Level Set Inversion Abstract: The level set approach has proven widely successful in the study of inverse\nproblems for interfaces, since its systematic development in the 1990s.\nRecently it has been employed in the context of Bayesian inversion, allowing\nfor the quantification of uncertainty within the reconstruction of interfaces.\nHowever the Bayesian approach is very sensitive to the length and amplitude\nscales in the prior probabilistic model. This paper demonstrates how the\nscale-sensitivity can be circumvented by means of a hierarchical approach,\nusing a single scalar parameter. Together with careful consideration of the\ndevelopment of algorithms which encode probability measure equivalences as the\nhierarchical parameter is varied, this leads to well-defined Gibbs based MCMC\nmethods found by alternating Metropolis-Hastings updates of the level set\nfunction and the hierarchical parameter. These methods demonstrably outperform\nnon-hierarchical Bayesian level set methods. \n\n"}
{"id": "1601.03610", "contents": "Title: Non-Parametric Causality Detection: An Application to Social Media and\n  Financial Data Abstract: According to behavioral finance, stock market returns are influenced by\nemotional, social and psychological factors. Several recent works support this\ntheory by providing evidence of correlation between stock market prices and\ncollective sentiment indexes measured using social media data. However, a pure\ncorrelation analysis is not sufficient to prove that stock market returns are\ninfluenced by such emotional factors since both stock market prices and\ncollective sentiment may be driven by a third unmeasured factor. Controlling\nfor factors that could influence the study by applying multivariate regression\nmodels is challenging given the complexity of stock market data. False\nassumptions about the linearity or non-linearity of the model and inaccuracies\non model specification may result in misleading conclusions.\n  In this work, we propose a novel framework for causal inference that does not\nrequire any assumption about the statistical relationships among the variables\nof the study and can effectively control a large number of factors. We apply\nour method in order to estimate the causal impact that information posted in\nsocial media may have on stock market returns of four big companies. Our\nresults indicate that social media data not only correlate with stock market\nreturns but also influence them. \n\n"}
{"id": "1601.04891", "contents": "Title: Stochastic control, entropic interpolation and gradient flows on\n  Wasserstein product spaces Abstract: Since the early nineties, it has been observed that the Schroedinger bridge\nproblem can be formulated as a stochastic control problem with atypical\nboundary constraints. This in turn has a fluid dynamic counterpart where the\nflow of probability densities represents an entropic interpolation between the\ngiven initial and final marginals. In the zero noise limit, such entropic\ninterpolation converges in a suitable sense to the displacement interpolation\nof optimal mass transport (OMT). We consider two absolutely continuous curves\nin Wasserstein space ${\\cal W}_2$ and study the evolution of the relative\nentropy on ${\\cal W}_2\\times {\\cal W}_2$ on a finite time interval. Thus, this\nstudy differs from previous work in OMT theory concerning relative entropy from\na fixed (often equilibrium) distribution (density). We derive a gradient flow\non Wasserstein product space. We find the remarkable property that fluxes in\nthe two components are opposite. Plugging in the \"steepest descent\" into the\nevolution of the relative entropy we get what appears to be a new formula: The\ntwo flows approach each other at a faster rate than that of two solutions of\nthe same Fokker-Planck. We then study the evolution of relative entropy in the\ncase of uncontrolled-controlled diffusions. In two special cases of the\nSchroedinger bridge problem, we show that such relative entropy may be\nmonotonically decreasing or monotonically increasing. \n\n"}
{"id": "1601.05156", "contents": "Title: Bayesian Nonparametric Ordination for the Analysis of Microbial\n  Communities Abstract: Human microbiome studies use sequencing technologies to measure the abundance\nof bacterial species or Operational Taxonomic Units (OTUs) in samples of\nbiological material. Typically the data are organized in contingency tables\nwith OTU counts across heterogeneous biological samples. In the microbial\necology community, ordination methods are frequently used to investigate latent\nfactors or clusters that capture and describe variations of OTU counts across\nbiological samples. It remains important to evaluate how uncertainty in\nestimates of each biological sample's microbial distribution propagates to\nordination analyses, including visualization of clusters and projections of\nbiological samples on low dimensional spaces. We propose a Bayesian analysis\nfor dependent distributions to endow frequently used ordinations with estimates\nof uncertainty. A Bayesian nonparametric prior for dependent normalized random\nmeasures is constructed, which is marginally equivalent to the normalized\ngeneralized Gamma process, a well-known prior for nonparametric analyses. In\nour prior the dependence and similarity between microbial distributions is\nrepresented by latent factors that concentrate in a low dimensional space. We\nuse a shrinkage prior to tune the dimensionality of the latent factors. The\nresulting posterior samples of model parameters can be used to evaluate\nuncertainty in analyses routinely applied in microbiome studies. Specifically,\nby combining them with multivariate data analysis techniques we can visualize\ncredible regions in ecological ordination plots. The characteristics of the\nproposed model are illustrated through a simulation study and applications in\ntwo microbiome datasets. \n\n"}
{"id": "1601.05630", "contents": "Title: Significance-based community detection in weighted networks Abstract: Community detection is the process of grouping strongly connected nodes in a\nnetwork. Many community detection methods for un-weighted networks have a\ntheoretical basis in a null model. Communities discovered by these methods\ntherefore have interpretations in terms of statistical signficance. In this\npaper, we introduce a null for weighted networks called the continuous\nconfiguration model. We use the model both as a tool for community detection\nand for simulating weighted networks with null nodes. First, we propose a\ncommunity extraction algorithm for weighted networks which incorporates\niterative hypothesis testing under the null. We prove a central limit theorem\nfor edge-weight sums and asymptotic consistency of the algorithm under a\nweighted stochastic block model. We then incorporate the algorithm in a\ncommunity detection method called CCME. To benchmark the method, we provide a\nsimulation framework incorporating the null to plant \"background\" nodes in\nweighted networks with communities. We show that the empirical performance of\nCCME on these simulations is competitive with existing methods, particularly\nwhen overlapping communities and background nodes are present. To further\nvalidate the method, we present two real-world networks with potential\nbackground nodes and analyze them with CCME, yielding results that reveal\nmacro-features of the corresponding systems. \n\n"}
{"id": "1601.05715", "contents": "Title: Exact asymptotics in eigenproblems for fractional Brownian covariance\n  operators Abstract: Many results in the theory of Gaussian processes rely on the eigenstructure\nof the covariance operator. However, eigenproblems are notoriously hard to\nsolve explicitly and closed form solutions are known only in a limited number\nof cases. In this paper we set up a framework for the spectral analysis of the\nfractional type covariance operators, corresponding to an important family of\nprocesses, which includes the fractional Brownian motion and its noise. We\nobtain accurate asymptotic approximations for the eigenvalues and the\neigenfunctions. Our results provide a key to several problems, whose solution\nis long known in the standard Brownian case, but was missing in the more\ngeneral fractional setting. This includes computation of the exact limits of\n$L^2$-small ball probabilities and asymptotic analysis of singularly perturbed\nintegral equations, arising in mathematical physics and applied probability. \n\n"}
{"id": "1602.00199", "contents": "Title: Gaussian approximation for the sup-norm of high-dimensional\n  matrix-variate U-statistics and its applications Abstract: This paper studies the Gaussian approximation of high-dimensional and\nnon-degenerate U-statistics of order two under the supremum norm. We propose a\ntwo-step Gaussian approximation procedure that does not impose structural\nassumptions on the data distribution. Specifically, subject to mild moment\nconditions on the kernel, we establish the explicit rate of convergence that\ndecays polynomially in sample size for a high-dimensional scaling limit, where\nthe dimension can be much larger than the sample size. We also supplement a\npractical Gaussian wild bootstrap method to approximate the quantiles of the\nmaxima of centered U-statistics and prove its asymptotic validity. The wild\nbootstrap is demonstrated on statistical applications for high-dimensional\nnon-Gaussian data including: (i) principled and data-dependent tuning parameter\nselection for regularized estimation of the covariance matrix and its related\nfunctionals; (ii) simultaneous inference for the covariance and rank\ncorrelation matrices. In particular, for the thresholded covariance matrix\nestimator with the bootstrap selected tuning parameter, we show that the\nGaussian-like convergence rates can be achieved for heavy-tailed data, which\nare less conservative than those obtained by the Bonferroni technique that\nignores the dependency in the underlying data distribution. In addition, we\nalso show that even for subgaussian distributions, error bounds of the\nbootstrapped thresholded covariance matrix estimator can be much tighter than\nthose of the minimax estimator with a universal threshold. \n\n"}
{"id": "1602.00245", "contents": "Title: Statistical methods for linguistic research: Foundational Ideas - Part\n  II Abstract: We provide an introductory review of Bayesian data analytical methods, with a\nfocus on applications for linguistics, psychology, psycholinguistics, and\ncognitive science. The empirically oriented researcher will benefit from making\nBayesian methods part of their statistical toolkit due to the many advantages\nof this framework, among them easier interpretation of results relative to\nresearch hypotheses, and flexible model specification. We present an informal\nintroduction to the foundational ideas behind Bayesian data analysis, using, as\nan example, a linear mixed models analysis of data from a typical\npsycholinguistics experiment. We discuss hypothesis testing using the Bayes\nfactor, and model selection using cross-validation. We close with some examples\nillustrating the flexibility of model specification in the Bayesian framework.\nSuggestions for further reading are also provided. \n\n"}
{"id": "1602.01160", "contents": "Title: Variable selection via penalized credible regions with Dirichlet-Laplace\n  global-local shrinkage priors Abstract: The method of Bayesian variable selection via penalized credible regions\nseparates model fitting and variable selection. The idea is to search for the\nsparsest solution within the joint posterior credible regions. Although the\napproach was successful, it depended on the use of conjugate normal priors.\nMore recently, improvements in the use of global-local shrinkage priors have\nbeen made for high-dimensional Bayesian variable selection. In this paper, we\nincorporate global-local priors into the credible region selection framework.\nThe Dirichlet-Laplace (DL) prior is adapted to linear regression. Posterior\nconsistency for the normal and DL priors are shown, along with variable\nselection consistency. We further introduce a new method to tune\nhyperparameters in prior distributions for linear regression. We propose to\nchoose the hyperparameters to minimize a discrepancy between the induced\ndistribution on R-square and a prespecified target distribution. Prior\nelicitation on R-square is more natural, particularly when there are a large\nnumber of predictor variables in which elicitation on that scale is not\nfeasible. For a normal prior, these hyperparameters are available in closed\nform to minimize the Kullback-Leibler divergence between the distributions. \n\n"}
{"id": "1602.02102", "contents": "Title: The Spacey Random Walk: a Stochastic Process for Higher-order Data Abstract: Random walks are a fundamental model in applied mathematics and are a common\nexample of a Markov chain. The limiting stationary distribution of the Markov\nchain represents the fraction of the time spent in each state during the\nstochastic process. A standard way to compute this distribution for a random\nwalk on a finite set of states is to compute the Perron vector of the\nassociated transition matrix. There are algebraic analogues of this Perron\nvector in terms of transition probability tensors of higher-order Markov\nchains. These vectors are nonnegative, have dimension equal to the dimension of\nthe state space, and sum to one and are derived by making an algebraic\nsubstitution in the equation for the joint-stationary distribution of a\nhigher-order Markov chains. Here, we present the spacey random walk, a\nnon-Markovian stochastic process whose stationary distribution is given by the\ntensor eigenvector. The process itself is a vertex-reinforced random walk, and\nits discrete dynamics are related to a continuous dynamical system. We analyze\nthe convergence properties of these dynamics and discuss numerical methods for\ncomputing the stationary distribution. Finally, we provide several applications\nof the spacey random walk model in population genetics, ranking, and clustering\ndata, and we use the process to analyze taxi trajectory data in New York. This\nexample shows definite non-Markovian structure. \n\n"}
{"id": "1602.02466", "contents": "Title: Overfitting hidden Markov models with an unknown number of states Abstract: This paper presents new theory and methodology for the Bayesian estimation of\noverfitted hidden Markov models, with finite state space. The goal is then to\nachieve posterior emptying of extra states. A prior configuration is\nconstructed which favours configurations where the hidden Markov chain remains\nergodic although it empties out some of the states. Asymptotic posterior\nconvergence rates are proven theoretically, and demonstrated with a large\nsample simulation. The problem of overfitted HMMs is then considered in the\ncontext of smaller sample sizes, and due to computational and mixing issues two\nalternative prior structures are studied, one commonly used in practice, and a\nmixture of the two priors. The Prior Parallel Tempering approach of van Havre\n(2015) is also extended to HMMs to allow MCMC estimation of the complex\nposterior space. A replicate simulation study and an in-depth exploration is\nperformed to compare the three priors with hyperparameters chosen according to\nthe asymptotic constraints alongside less informative alternatives. \n\n"}
{"id": "1602.03574", "contents": "Title: A knockoff filter for high-dimensional selective inference Abstract: This paper develops a framework for testing for associations in a possibly\nhigh-dimensional linear model where the number of features/variables may far\nexceed the number of observational units. In this framework, the observations\nare split into two groups, where the first group is used to screen for a set of\npotentially relevant variables, whereas the second is used for inference over\nthis reduced set of variables; we also develop strategies for leveraging\ninformation from the first part of the data at the inference step for greater\npower. In our work, the inferential step is carried out by applying the\nrecently introduced knockoff filter, which creates a knockoff copy-a fake\nvariable serving as a control-for each screened variable. We prove that this\nprocedure controls the directional false discovery rate (FDR) in the reduced\nmodel controlling for all screened variables; this says that our\nhigh-dimensional knockoff procedure 'discovers' important variables as well as\nthe directions (signs) of their effects, in such a way that the expected\nproportion of wrongly chosen signs is below the user-specified level (thereby\ncontrolling a notion of Type S error averaged over the selected set). This\nresult is non-asymptotic, and holds for any distribution of the original\nfeatures and any values of the unknown regression coefficients, so that\ninference is not calibrated under hypothesized values of the effect sizes. We\ndemonstrate the performance of our general and flexible approach through\nnumerical studies, showing more power than existing alternatives. Finally, we\napply our method to a genome-wide association study to find locations on the\ngenome that are possibly associated with a continuous phenotype. \n\n"}
{"id": "1602.04279", "contents": "Title: On the Smoluchowski-Kramers approximation for SPDEs and its interplay\n  with large deviations and long time behavior Abstract: We discuss here the validity of the small mass limit (the so-called\nSmoluchowski-Kramers approximation) on a fixed time interval for a class of\nsemi-linear stochastic wave equations, both in the case of the presence of a\nconstant friction term and in the case of the presence of a constant magnetic\nfield. We also consider the small mass limit in an infinite time interval and\nwe see how the approximation is stable in terms of the invariant measure and of\nthe large deviation estimates and the exit problem from a bounded domain of the\nspace of square integrable functions. \n\n"}
{"id": "1602.05023", "contents": "Title: An introduction to sampling via measure transport Abstract: We present the fundamentals of a measure transport approach to sampling. The\nidea is to construct a deterministic coupling---i.e., a transport map---between\na complex \"target\" probability measure of interest and a simpler reference\nmeasure. Given a transport map, one can generate arbitrarily many independent\nand unweighted samples from the target simply by pushing forward reference\nsamples through the map. We consider two different and complementary scenarios:\nfirst, when only evaluations of the unnormalized target density are available,\nand second, when the target distribution is known only through a finite\ncollection of samples. We show that in both settings the desired transports can\nbe characterized as the solutions of variational problems. We then address\npractical issues associated with the optimization--based construction of\ntransports: choosing finite-dimensional parameterizations of the map, enforcing\nmonotonicity, quantifying the error of approximate transports, and refining\napproximate transports by enriching the corresponding approximation spaces.\nApproximate transports can also be used to \"Gaussianize\" complex distributions\nand thus precondition conventional asymptotically exact sampling schemes. We\nplace the measure transport approach in broader context, describing connections\nwith other optimization--based samplers, with inference and density estimation\nschemes using optimal transport, and with alternative transformation--based\napproaches to simulation. We also sketch current work aimed at the construction\nof transport maps in high dimensions, exploiting essential features of the\ntarget distribution (e.g., conditional independence, low-rank structure). The\napproaches and algorithms presented here have direct applications to Bayesian\ncomputation and to broader problems of stochastic simulation. \n\n"}
{"id": "1602.05125", "contents": "Title: Locally Stationary Functional Time Series Abstract: The literature on time series of functional data has focused on processes of\nwhich the probabilistic law is either constant over time or constant up to its\nsecond-order structure. Especially for long stretches of data it is desirable\nto be able to weaken this assumption. This paper introduces a framework that\nwill enable meaningful statistical inference of functional data of which the\ndynamics change over time. We put forward the concept of local stationarity in\nthe functional setting and establish a class of processes that have a\nfunctional time-varying spectral representation. Subsequently, we derive\nconditions that allow for fundamental results from nonstationary multivariate\ntime series to carry over to the function space. In particular, time-varying\nfunctional ARMA processes are investigated and shown to be functional locally\nstationary according to the proposed definition. As a side-result, we establish\na Cram\\'er representation for an important class of weakly stationary\nfunctional processes. Important in our context is the notion of a time-varying\nspectral density operator of which the properties are studied and uniqueness is\nderived. Finally, we provide a consistent nonparametric estimator of this\noperator and show it is asymptotically Gaussian using a weaker tightness\ncriterion than what is usually deemed necessary. \n\n"}
{"id": "1602.05455", "contents": "Title: Heterogeneity Adjustment with Applications to Graphical Model Inference Abstract: Heterogeneity is an unwanted variation when analyzing aggregated datasets\nfrom multiple sources. Though different methods have been proposed for\nheterogeneity adjustment, no systematic theory exists to justify these methods.\nIn this work, we propose a generic framework named ALPHA (short for Adaptive\nLow-rank Principal Heterogeneity Adjustment) to model, estimate, and adjust\nheterogeneity from the original data. Once the heterogeneity is adjusted, we\nare able to remove the biases of batch effects and to enhance the inferential\npower by aggregating the homogeneous residuals from multiple sources. Under a\npervasive assumption that the latent heterogeneity factors simultaneously\naffect a large fraction of observed variables, we provide a rigorous theory to\njustify the proposed framework. Our framework also allows the incorporation of\ninformative covariates and appeals to the \"Bless of Dimensionality\". As an\nillustrative application of this generic framework, we consider a problem of\nestimating high-dimensional precision matrix for graphical model inference\nbased on multiple datasets. We also provide thorough numerical studies on both\nsynthetic datasets and a brain imaging dataset to demonstrate the efficacy of\nthe developed theory and methods. \n\n"}
{"id": "1602.06081", "contents": "Title: Aging in Metropolis dynamics of the REM: a proof Abstract: We study the aging behavior of the Random Energy Model (REM) evolving under\nMetropolis dynamics. We prove that a classical two-time correlation function\nconverges almost surely to the arcsine law distribution function that\ncharacterizes activated aging, as predicted in the physics literature, in the\noptimal domain of the time-scale and temperature parameters where this result\ncan be expected to hold. In the course of the proof we establish that a certain\ncontinuous time clock process, after proper rescaling, converges almost surely\nto a stable subordinator, improving upon the result of Cerny and Wassmer (2015)\nwhere a closely related clock is shown to converge in probability only, and in\na restricted region of the time-scale and temperature parameters. The random\nrescaling involved in this convergence is controlled at the fine level of\nfluctuations. As a byproduct, we refine and prove a conjecture made in Cerny\nand Wassmer (2015). \n\n"}
{"id": "1602.08160", "contents": "Title: Stability of stochastic differential equations with respect to\n  time-changed Brownian motions Abstract: In this paper, the stability behaviors of stochastic differential equations\n(SDEs) driven by time-changed Brownian motions are discussed. Based on the\ngeneralized Lyapunov method and stochastic analysis, necessary conditions are\nprovided for solutions of time-changed SDEs to be stable in differential\nsenses, such as stochastic stability, stochastically asymptotic stability and\nglobally stochastically asymptotic stability. Also, a connection between the\nstability of the solution to the time-changed SDEs and that to their\ncorresponding non-time-changed SDEs is revealed by applying the duality\ntheorem. Finally, two examples are provided to illustrate the theoretical\nresults. \n\n"}
{"id": "1602.08428", "contents": "Title: Quenched invariance principles for the random conductance model on a\n  random graph with degenerate ergodic weights Abstract: We consider a stationary and ergodic random field $\\{\\omega(e) : e \\in E_d\\}$\nthat is parameterized by the edge set of the Euclidean lattice $\\mathbb{Z}^d$,\n$d \\geq 2$. The random variable $\\omega(e)$, taking values in $[0, \\infty)$ and\nsatisfying certain moment bounds, is thought of as the conductance of the edge\n$e$. Assuming that the set of edges with positive conductances give rise to a\nunique infinite cluster $\\mathcal{C}_{\\infty}(\\omega)$, we prove a quenched\ninvariance principle for the continuous-time random walk among random\nconductances under relatively mild conditions on the structure of the infinite\ncluster. An essential ingredient of our proof is a new anchored relative\nisoperimetric inequality. \n\n"}
{"id": "1603.01308", "contents": "Title: Dynamic Adaptive Mixture Models Abstract: In this paper we propose a new class of Dynamic Mixture Models (DAMMs) being\nable to sequentially adapt the mixture components as well as the mixture\ncomposition using information coming from the data. The information driven\nnature of the proposed class of models allows to exactly compute the full\nlikelihood and to avoid computer intensive simulation schemes. An extensive\nMonte Carlo experiment reveals that the new proposed model can accurately\napproximate the more complicated Stochastic Dynamic Mixture Model previously\nintroduced in the literature as well as other kind of models. The properties of\nthe new proposed class of models are discussed through the paper and an\napplication in financial econometrics is reported. \n\n"}
{"id": "1603.02791", "contents": "Title: Asymptotically optimal, sequential, multiple testing procedures with\n  prior information on the number of signals Abstract: Assuming that data are collected sequentially from independent streams, we\nconsider the simultaneous testing of multiple binary hypotheses under two\ngeneral setups; when the number of signals (correct alternatives) is known in\nadvance, and when we only have a lower and an upper bound for it. In each of\nthese setups, we propose feasible procedures that control, without any\ndistributional assumptions, the familywise error probabilities of both type I\nand type II below given, user-specified levels. Then, in the case of i.i.d.\nobservations in each stream, we show that the proposed procedures achieve the\noptimal expected sample size, under every possible signal configuration,\nasymptotically as the two error probabilities vanish at arbitrary rates. A\nsimulation study is presented in a completely symmetric case and supports\ninsights obtained from our asymptotic results, such as the fact that knowledge\nof the exact number of signals roughly halves the expected number of\nobservations compared to the case of no prior information. \n\n"}
{"id": "1603.03413", "contents": "Title: A service system with randomly behaving on-demand agents Abstract: We consider a service system where agents (or, servers) are invited\non-demand. Customers arrive as a Poisson process and join a customer queue.\nCustomer service times are i.i.d. exponential. Agents' behavior is random in\ntwo respects. First, they can be invited into the system exogenously, and join\nthe agent queue after a random time. Second, with some probability they rejoin\nthe agent queue after a service completion, and otherwise leave the system. The\nobjective is to design a real-time adaptive agent invitation scheme that keeps\nboth customer and agent queues/waiting-times small. We study an adaptive\nscheme, which controls the number of pending agent invitations, based on\nqueue-state feedback.\n  We study the system process fluid limits, in the asymptotic regime where the\ncustomer arrival rate goes to infinity. The fluid limit trajectories have\ncomplicated behavior -- there are two domains where they follow different ODEs,\nand a \"reflecting\" boundary. We use the machinery of switched linear systems\nand common quadratic Lyapunov functions to approach the stability of fluid\nlimits at the desired equilibrium point (with zero queues). We derive\nsufficient local stability conditions for the fluid limits. We conjecture that,\nfor our model, local stability is in fact sufficient for global stability of\nfluid limits; the validity of this conjecture is supported by numerical and\nsimulation experiments. When the local stability conditions do hold,\nsimulations show good overall performance of the scheme. \n\n"}
{"id": "1603.04734", "contents": "Title: Asymptotic Expansions for Stationary Distributions of Nonlinearly\n  Perturbed Semi-Markov Processes. I Abstract: New algorithms for construction of asymptotic expansions for stationary\ndistributions of nonlinearly perturbed semi-Markov processes with finite phase\nspaces are presented. These algorithms are based on a special technique of\nsequential phase space reduction, which can be applied to processes with an\narbitrary asymptotic communicative structure of phase spaces. Asymptotic\nexpansions are given in two forms, without and with explicit bounds for\nremainders. \n\n"}
{"id": "1603.05161", "contents": "Title: Dimension transformation formula for conformal maps into the complement\n  of an SLE curve Abstract: We prove a formula relating the Hausdorff dimension of a deterministic Borel\nsubset of $\\mathbb R$ and the Hausdorff dimension of its image under a\nconformal map from the upper half-plane to a complementary connected component\nof an SLE$_\\kappa$ curve for $\\kappa \\not =4$. Our proof is based on the\nrelationship between SLE and Liouville quantum gravity together with the\none-dimensional KPZ formula of Rhodes-Vargas (2011) and the KPZ formula of\nGwynne-Holden-Miller (2015). As an intermediate step we prove a KPZ formula\nwhich relates the Euclidean dimension of a subset of an SLE$_\\kappa$ curve for\n$\\kappa \\in (0,4)\\cup(4,8)$ and the dimension of the same set with respect to\nthe $\\gamma$-quantum natural parameterization of the curve induced by an\nindependent Gaussian free field, $\\gamma = \\sqrt \\kappa \\wedge\n(4/\\sqrt\\kappa)$. \n\n"}
{"id": "1603.05437", "contents": "Title: An It\\^o calculus for a class of limit processes arising from random\n  walks on the complex plane Abstract: Within the framework of the previous paper [8]. we develop a generalized\nstochastic calculus for processes associated to higher order diffusion\noperators. Applications to the study of a Cauchy problem, a Feynman-Kac formula\nand a representation formula for higher derivatives of analytic functions are\nalso given. \n\n"}
{"id": "1603.06747", "contents": "Title: Tamed EM scheme of Neutral Stochastic Differential Delay Equations Abstract: In this paper, we investigate the convergence of the tamed Euler-Maruyama\n(EM) scheme for a class of neutral stochastic differential delay equations. The\nstrong convergence results of the tamed EM scheme are presented under global\nand local non-Lipschitz conditions, respectively. Moreover, under a global\nLipschitz condition, we provide the rate of the convergence of tamed EM, which\nis smaller than the rate convergence of classical EM scheme one half. \n\n"}
{"id": "1603.06761", "contents": "Title: On bulk singularities in the random normal matrix model Abstract: We extend the method of rescaled Ward identities of Ameur-Kang-Makarov to\nstudy the distribution of eigenvalues close to a bulk singularity, i.e. a point\nin the interior of the droplet where the density of the classical equilibrium\nmeasure vanishes. We prove results to the effect that a certain \"dominant part\"\nof the Taylor expansion determines the microscopic properties near a bulk\nsingularity. A description of the distribution is given in terms of a special\nentire function, which depends on the nature of the singularity (a\nMittag-Leffler function in the case of a rotationally symmetric singularity). \n\n"}
{"id": "1603.08756", "contents": "Title: Weak error analysis via functional It\\^o calculus Abstract: We consider autonomous stochastic ordinary differential equations (SDEs) and\nweak approximations of their solutions for a general class of sufficiently\nsmooth path-dependent functionals f. Based on tools from functional It\\^o\ncalculus, such as the functional It\\^o formula and functional Kolmogorov\nequation, we derive a general representation formula for the weak error\n$E(f(X_T)-f(\\tilde X_T))$, where $X_T$ and $\\tilde X_T$ are the paths of the\nsolution process and its approximation up to time T. The functional\n$f:C([0,T],R^d)\\to R$ is assumed to be twice continuously Fr\\'echet\ndifferentiable with derivatives of polynomial growth. The usefulness of the\nformula is demonstrated in the one dimensional setting by showing that if the\nsolution to the SDE is approximated via the linearly time-interpolated explicit\nEuler method, then the rate of weak convergence for sufficiently regular f is\n1. \n\n"}
{"id": "1603.08758", "contents": "Title: Mixtures of classical and free independence Abstract: We revive the concept of Lambda-freeness of Mlotkowski, which describes a\nmixture of classical and free independence between algebras of random\nvariables. In particular, we give a description of this in terms of cumulants;\nthis will be instrumental in the subsequent paper [SW] where the quantum\nsymmetries underlying these mixtures of classical and free independences will\nbe considered. \n\n"}
{"id": "1603.09017", "contents": "Title: Tree formulas, mean first passage times and Kemeny's constant of a\n  Markov chain Abstract: In this paper, we aim to provide probabilistic and combinatorial insights\ninto tree formulas for the Green function and hitting probabilities of Markov\nchains on a finite state space. These tree formulas are closely related to\nloop-erased random walks by Wilson's algorithm for random spanning trees, and\nto mixing times by the Markov chain tree theorem. Let $m_{ij}$ be the mean\nfirst passage time from $i$ to $j$ for an irreducible chain with finite state\nspace $S$ and transition matrix $(p_{ij}; i, j \\in S)$. It is well-known that\n$m_{jj} = 1/\\pi_j = \\Sigma^{(1)}/\\Sigma_j$, where $\\pi$ is the stationary\ndistribution for the chain, $\\Sigma_j$ is the tree sum, over $n^{n-2}$ trees\n$\\textbf{t}$ spanning $S$ with root $j$ and edges $i \\rightarrow k$ directed to\n$j$, of the tree product $\\prod_{i \\rightarrow k \\in \\textbf{t} }p_{ik}$, and\n$\\Sigma^{(1)}:= \\sum_{j \\in S} \\Sigma_j$. Chebotarev and Agaev derived further\nresults from {\\em Kirchhoff's matrix tree theorem}. We deduce that for $i \\ne\nj$, $m_{ij} = \\Sigma_{ij}/\\Sigma_j$, where $\\Sigma_{ij}$ is the sum over the\nsame set of $n^{n-2}$ spanning trees of the same tree product as for\n$\\Sigma_j$, except that in each product the factor $p_{kj}$ is omitted where $k\n= k(i,j,\\textbf{t})$ is the last state before $j$ in the path from $i$ to $j$\nin $\\textbf{t}$. It follows that Kemeny's constant $\\sum_{j \\in S}\nm_{ij}/m_{jj}$ equals to $ \\Sigma^{(2)}/\\Sigma^{(1)}$, where $\\Sigma^{(r)}$ is\nthe sum, over all forests $\\textbf{f}$ labeled by $S$ with $r$ trees, of the\nproduct of $p_{ij}$ over edges $i \\rightarrow j$ of $\\textbf{t}$. We show that\nthese results can be derived without appeal to the matrix tree theorem. A list\nof relevant literature is also reviewed. \n\n"}
{"id": "1604.00695", "contents": "Title: Diagnosing Suboptimal Cotangent Disintegrations in Hamiltonian Monte\n  Carlo Abstract: When properly tuned, Hamiltonian Monte Carlo scales to some of the most\nchallenging high-dimensional problems at the frontiers of applied statistics,\nbut when that tuning is suboptimal the performance leaves much to be desired.\nIn this paper I show how suboptimal choices of one critical degree of freedom,\nthe cotangent disintegration, manifest in readily observed diagnostics that\nfacilitate the robust application of the algorithm. \n\n"}
{"id": "1604.00860", "contents": "Title: Bayesian Computing with INLA: A Review Abstract: The key operation in Bayesian inference, is to compute high-dimensional\nintegrals. An old approximate technique is the Laplace method or approximation,\nwhich dates back to Pierre- Simon Laplace (1774). This simple idea approximates\nthe integrand with a second order Taylor expansion around the mode and computes\nthe integral analytically. By developing a nested version of this classical\nidea, combined with modern numerical techniques for sparse matrices, we obtain\nthe approach of Integrated Nested Laplace Approximations (INLA) to do\napproximate Bayesian inference for latent Gaussian models (LGMs). LGMs\nrepresent an important model-abstraction for Bayesian inference and include a\nlarge proportion of the statistical models used today. In this review, we will\ndiscuss the reasons for the success of the INLA-approach, the R-INLA package,\nwhy it is so accurate, why the approximations are very quick to compute and why\nLGMs make such a useful concept for Bayesian computing. \n\n"}
{"id": "1604.01191", "contents": "Title: Functional mixed effects wavelet estimation for spectra of replicated\n  time series Abstract: Motivated by spectral analysis of replicated brain signal time series, we\npropose a functional mixed effects approach to model replicate-specific\nspectral densities as random curves varying about a deterministic\npopulation-mean spectrum. In contrast to existing work, we do not assume the\nreplicate-specific spectral curves to be independent, i.e. there may exist\nexplicit correlation between different replicates in the population. By\nprojecting the replicate-specific curves onto an orthonormal wavelet basis,\nestimation and prediction is carried out under an equivalent linear mixed\neffects model in the wavelet coefficient domain. To cope with potentially very\nlocalized features of the spectral curves, we develop estimators and predictors\nbased on a combination of generalized least squares estimation and nonlinear\nwavelet thresholding, including asymptotic confidence sets for the\npopulation-mean curve. We derive risk bounds for the nonlinear wavelet\nestimator of the population-mean curve, a result that reflects the influence of\ncorrelation between different curves in the replicate-population, and we derive\nconsistency of the estimators of the inter- and intra-curve correlation\nstructure in an appropriate sparseness class of functions. To illustrate the\nproposed functional mixed effects model and our estimation and prediction\nprocedures, we present several simulated time series data examples and we\nanalyze a motivating brain signal dataset recorded during an associative\nlearning experiment. \n\n"}
{"id": "1604.03192", "contents": "Title: Scalar-on-Image Regression via the Soft-Thresholded Gaussian Process Abstract: The focus of this work is on spatial variable selection for scalar-on-image\nregression. We propose a new class of Bayesian nonparametric models,\nsoft-thresholded Gaussian processes and develop the efficient posterior\ncomputation algorithms. Theoretically, soft-thresholded Gaussian processes\nprovide large prior support for the spatially varying coefficients that enjoy\npiecewise smoothness, sparsity and continuity, characterizing the important\nfeatures of imaging data. Also, under some mild regularity conditions, the\nsoft-thresholded Gaussian process leads to the posterior consistency for both\nparameter estimation and variable selection for scalar-on-image regression,\neven when the number of true predictors is larger than the sample size. The\nproposed method is illustrated via simulations, compared numerically with\nexisting alternatives and applied to Electroencephalography (EEG) study of\nalcoholism. \n\n"}
{"id": "1604.03826", "contents": "Title: Invariance Principle for the one-dimensional dynamic Random Conductance\n  Model under Moment Conditions Abstract: Recent progress in the understanding of quenched invariance principles (QIP)\nfor a continuous-time random walk on $\\mathbb{Z}^d$ in an environment of\ndynamical random conductances is reviewed and extended to the $1$-dimensional\ncase. The law of the conductances is assumed to be ergodic with respect to\ntime-space shifts and satisfies certain integrability conditions. \n\n"}
{"id": "1604.04497", "contents": "Title: Fluid Models of Parallel Service Systems under FCFS Abstract: We study deterministic fluid approximations of parallel service systems\noperating under first come first served policy (FCFS). The condition for\ncomplete resource pooling is identified in terms of the system structure and\nthe customer service times. The static planning linear programming approach\n(Harrison and Lopez \\cite{harrison-lopez:99}) is used to obtain a maximum\nthroughput compatibility tree and to show that FCFS using this compatibility\ntree is throughput optimal. We investigate matching rates and show by\nHotelling's $T^2$-test and simulation that they are dependent on the service\ntime distribution. \n\n"}
{"id": "1604.07087", "contents": "Title: Optimal Estimation of Slope Vector in High-dimensional Linear\n  Transformation Model Abstract: In a linear transformation model, there exists an unknown monotone nonlinear\ntransformation function such that the transformed response variable and the\npredictor variables satisfy a linear regression model. In this paper, we\npresent CENet, a new method for estimating the slope vector and simultaneously\nperforming variable selection in the high-dimensional sparse linear\ntransformation model. CENet is the solution to a convex optimization problem\nand can be computed efficiently from an algorithm with guaranteed convergence\nto the global optimum. We show that under a pairwise elliptical distribution\nassumption on each predictor-transformed-response pair and some regularity\nconditions, CENet attains the same optimal rate of convergence as the best\nregression method in the high-dimensional sparse linear regression model. To\nthe best of our limited knowledge, this is the first such result in the\nliterature. We demonstrate the empirical performance of CENet on both simulated\nand real datasets. We also discuss the connection of CENet with some nonlinear\nregression/multivariate methods proposed in the literature. \n\n"}
{"id": "1604.07354", "contents": "Title: Ultrahigh Dimensional Feature Selection via Kernel Canonical Correlation\n  Analysis Abstract: High-dimensional variable selection is an important issue in many scientific\nfields, such as genomics. In this paper, we develop a sure independence feature\nscreening pro- cedure based on kernel canonical correlation analysis (KCCA-SIS,\nfor short). KCCA- SIS is easy to be implemented and applied. Compared to the\nsure independence screen- ing procedure based on the Pearson correlation (SIS,\nfor short) developed by Fan and Lv [2008], KCCA-SIS can handle nonlinear\ndependencies among variables. Compared to the sure independence screening\nprocedure based on the distance correlation (DC- SIS, for short) proposed by Li\net al. [2012], KCCA-SIS is scale free, distribution free and has better\napproximation results based on the universal characteristic of Gaussian Kernel\n(Micchelli et al. [2006]). KCCA-SIS is more general than SIS and DC-SIS in the\nsense that SIS and DC-SIS correspond to certain choice of kernels. Compared to\nsupremum of Hilbert Schmidt independence criterion-Sure independence screening\n(sup-HSIC-SIS, for short) developed by Balasubramanian et al. [2013], KCCA-SIS\nis scale free removing the marginal variation of features and response\nvariables. No model assumption is needed between response and predictors to\napply KCCA-SIS and it can be used in ultrahigh dimensional data analysis.\nSimilar to DC-SIS and sup- HSIC-SIS, KCCA-SIS can also be used directly to\nscreen grouped predictors and for multivariate response variables. We show that\nKCCA-SIS has the sure screening prop- erty, and has better performance through\nsimulation studies. We applied KCCA-SIS to study Autism genes in a\nspatiotemporal gene expression dataset for human brain development, and\nobtained better results based on gene ontology enrichment analysis comparing to\nthe other existing methods. \n\n"}
{"id": "1604.07449", "contents": "Title: Distribution-free Detection of a Submatrix Abstract: We consider the problem of detecting the presence of a submatrix with\nlarger-than-usual values in a large data matrix. This problem was considered in\n(Butucea and Ingster, 2013) under a one-parameter exponential family, and one\nof the test they analyzed is the scan test. Taking a nonparametric stance, we\nshow that a calibration by permutation leads to the same (first-order)\nasymptotic performance. This is true for the two types of permutations we\nconsider. We also study the corresponding rank-based variants and precisely\nquantify the loss in asymptotic power. \n\n"}
{"id": "1605.00391", "contents": "Title: Recovery of non-linear cause-effect relationships from linearly mixed\n  neuroimaging data Abstract: Causal inference concerns the identification of cause-effect relationships\nbetween variables. However, often only linear combinations of variables\nconstitute meaningful causal variables. For example, recovering the signal of a\ncortical source from electroencephalography requires a well-tuned combination\nof signals recorded at multiple electrodes. We recently introduced the MERLiN\n(Mixture Effect Recovery in Linear Networks) algorithm that is able to recover,\nfrom an observed linear mixture, a causal variable that is a linear effect of\nanother given variable. Here we relax the assumption of this cause-effect\nrelationship being linear and present an extended algorithm that can pick up\nnon-linear cause-effect relationships. Thus, the main contribution is an\nalgorithm (and ready to use code) that has broader applicability and allows for\na richer model class. Furthermore, a comparative analysis indicates that the\nassumption of linear cause-effect relationships is not restrictive in analysing\nelectroencephalographic data. \n\n"}
{"id": "1605.02138", "contents": "Title: Intelligent Initialization and Adaptive Thresholding for Iterative\n  Matrix Completion; Some Statistical and Algorithmic Theory for\n  Adaptive-Impute Abstract: Over the past decade, various matrix completion algorithms have been\ndeveloped. Thresholded singular value decomposition (SVD) is a popular\ntechnique in implementing many of them. A sizable number of studies have shown\nits theoretical and empirical excellence, but choosing the right threshold\nlevel still remains as a key empirical difficulty. This paper proposes a novel\nmatrix completion algorithm which iterates thresholded SVD with\ntheoretically-justified and data-dependent values of thresholding parameters.\nThe estimate of the proposed algorithm enjoys the minimax error rate and shows\noutstanding empirical performances. The thresholding scheme that we use can be\nviewed as a solution to a non-convex optimization problem, understanding of\nwhose theoretical convergence guarantee is known to be limited. We investigate\nthis problem by introducing a simpler algorithm, generalized-\\SI, analyzing its\nconvergence behavior, and connecting it to the proposed algorithm. \n\n"}
{"id": "1605.02714", "contents": "Title: Diameter in ultra-small scale-free random graphs: Extended version Abstract: It is well known that many random graphs with infinite variance degrees are\nultrasmall. More precisely, for configuration models and preferential\nattachment models where the proportion of vertices of degree at least $k$ is\napproximately $k^{-(\\tau-1)}$ with $\\tau\\in(2,3)$, typical distances between\npairs of vertices in a graph of size $n$ are asymptotic to $\\frac{2\\log\\log\nn}{|\\log(\\tau-2)|}$ and $\\frac{4\\log\\log n}{|\\log(\\tau-2)|}$, respectively. In\nthis paper, we investigate the behavior of the diameter in such models. We show\nthat the diameter is of order $\\log\\log n$ precisely when the minimal forward\ndegree $d$ of vertices is at least $2$. We identify the exact constant, which\nequals that of the typical distances plus $2/\\log d$. Interestingly, the proof\nfor both models follows identical steps, even though the models are quite\ndifferent in nature. \n\n"}
{"id": "1605.03471", "contents": "Title: Nonparametric hierarchical Bayesian quantiles Abstract: Here we develop a method for performing nonparametric Bayesian inference on\nquantiles. Relying on geometric measure theory and employing a Hausdorff base\nmeasure, we are able to specify meaningful priors for the quantile while\ntreating the distribution of the data otherwise nonparametrically. We further\nextend the method to a hierarchical model for quantiles of subpopulations,\nlinking subgroups together solely through their quantiles. Our approach is\ncomputationally straightforward, allowing for censored and noisy data. We\ndemonstrate the proposed methodology on simulated data and an applied problem\nfrom sports statistics, where it is observed to stabilize and improve inference\nand prediction. \n\n"}
{"id": "1605.04565", "contents": "Title: Hierarchical Models for Independence Structures of Networks Abstract: We introduce a new family of network models, called hierarchical network\nmodels, that allow us to represent in an explicit manner the stochastic\ndependence among the dyads (random ties) of the network. In particular, each\nmember of this family can be associated with a graphical model defining\nconditional independence clauses among the dyads of the network, called the\ndependency graph. Every network model with dyadic independence assumption can\nbe generalized to construct members of this new family. Using this new\nframework, we generalize the Erd\\\"os-R\\'enyi and beta-models to create\nhierarchical Erd\\\"os-R\\'enyi and beta-models. We describe various methods for\nparameter estimation as well as simulation studies for models with sparse\ndependency graphs. \n\n"}
{"id": "1605.06416", "contents": "Title: Statistical Inference for Cluster Trees Abstract: A cluster tree provides a highly-interpretable summary of a density function\nby representing the hierarchy of its high-density clusters. It is estimated\nusing the empirical tree, which is the cluster tree constructed from a density\nestimator. This paper addresses the basic question of quantifying our\nuncertainty by assessing the statistical significance of topological features\nof an empirical cluster tree. We first study a variety of metrics that can be\nused to compare different trees, analyze their properties and assess their\nsuitability for inference. We then propose methods to construct and summarize\nconfidence sets for the unknown true cluster tree. We introduce a partial\nordering on cluster trees which we use to prune some of the statistically\ninsignificant features of the empirical tree, yielding interpretable and\nparsimonious cluster trees. Finally, we illustrate the proposed methods on a\nvariety of synthetic examples and furthermore demonstrate their utility in the\nanalysis of a Graft-versus-Host Disease (GvHD) data set. \n\n"}
{"id": "1605.06819", "contents": "Title: A new approach to the Stein-Tikhomirov method: with applications to the\n  second Wiener chaos and Dickman convergence Abstract: In this paper, we propose a general means of estimating the rate at which\nconvergences in law occur. Our approach, which is an extension of the classical\nStein-Tikhomirov method, rests on a new pair of linear operators acting on\ncharacteristic functions. In principle, this method is admissible for any\napproximating sequence and any target, although obviously the conjunction of\nseveral favorable factors is necessary in order for the resulting bounds to be\nof interest. As we briefly discuss, our approach is particularly promising\nwhenever some version of Stein's method applies. We apply our approach to two\nexamples. The first application concerns convergence in law towards targets\n$F_\\infty$ which belong to the second Wiener chaos (i.e. $F_{\\infty}$ is a\nlinear combination of independent centered chi-squared rvs). We detail an\napplication to $U$-statistics. The second application concerns convergence\ntowards targets belonging to the generalized Dickman family of distributions.\nWe detail an application to a theorem from number theory. In both cases our\nmethod produces bounds of the correct order (up to a logarithmic loss) in terms\nof quantities which occur naturally in Stein's method. \n\n"}
{"id": "1605.07244", "contents": "Title: Optimal Estimation of Co-heritability in High-dimensional Linear Models Abstract: Co-heritability is an important concept that characterizes the genetic\nassociations within pairs of quantitative traits. There has been significant\nrecent interest in estimating the co-heritability based on data from the\ngenome-wide association studies (GWAS). This paper introduces two measures of\nco-heritability in the high-dimensional linear model framework, including the\ninner product of the two regression vectors and a normalized inner product by\ntheir lengths. Functional de-biased estimators (FDEs) are developed to estimate\nthese two co-heritability measures. In addition, estimators of quadratic\nfunctionals of the regression vectors are proposed. Both theoretical and\nnumerical properties of the estimators are investigated. In particular, minimax\nrates of convergence are established and the proposed estimators of the inner\nproduct, the quadratic functionals and the normalized inner product are shown\nto be rate-optimal. Simulation results show that the FDEs significantly\noutperform the naive plug-in estimates. The FDEs are also applied to analyze a\nyeast segregant data set with multiple traits to estimate heritability and\nco-heritability among the traits. \n\n"}
{"id": "1605.09035", "contents": "Title: 2D Ising model: correlation functions at criticality via Riemann-type\n  boundary value problems Abstract: In this note we overview recent convergence results for correlations in the\ncritical planar nearest-neighbor Ising model. We start with a short discussion\nof the combinatorics of the model and a definition of fermionic and spinor\nobservables. After that, we illustrate our approach to spin correlations by a\nderivation of two classical explicit formulae in the infinite-volume limit.\nThen we describe the convergence results (as the mesh size tends to zero, in\narbitrary planar domains) for fermionic correlators, energy-density and spin\nexpectations. Finally, we discuss scaling limits of mixed correlators involving\nspins, disorders and fermions, and the classical fusion rules for them. \n\n"}
{"id": "1606.00293", "contents": "Title: Ergodic measures on infinite skew-symmetric matrices over\n  non-Archimedean local fields Abstract: Let $F$ be a non-discrete non-Archimedean locally compact field such that the\ncharacteristic $\\mathrm{ch}(F)\\ne 2$ and let $\\mathcal{O}_F$ be the ring of\nintegers in $F$. The main results of this paper are Theorem 1.2 that classifies\nergodic probability measures on the space $\\mathrm{Skew}(\\mathbb{N}, F)$ of\ninfinite skew-symmetric matrices with respect to the natural action of the\ngroup $\\mathrm{GL}(\\infty,\\mathcal{O}_F)$ and Theorem 1.4, that gives an\nunexpected natural correspondence between the set of\n$\\mathrm{GL}(\\infty,\\mathcal{O}_F)$-invariant Borel probability measures on\n$\\mathrm{Sym}(\\mathbb{N}, F)$ with the set of\n$\\mathrm{GL}(\\infty,\\mathcal{O}_F) \\times\n\\mathrm{GL}(\\infty,\\mathcal{O}_F)$-invariant Borel probability measures on the\nspace $\\mathrm{Mat}(\\mathbb{N}, F)$ of infinite matrices over $F$. \n\n"}
{"id": "1606.02931", "contents": "Title: Bayesian Estimation and Comparison of Moment Condition Models Abstract: In this paper we consider the problem of inference in statistical models\ncharacterized by moment restrictions by casting the problem within the\nExponentially Tilted Empirical Likelihood (ETEL) framework. Because the ETEL\nfunction has a well defined probabilistic interpretation and plays the role of\na nonparametric likelihood, a fully Bayesian semiparametric framework can be\ndeveloped. We establish a number of powerful results surrounding the Bayesian\nETEL framework in such models. One major concern driving our work is the\npossibility of misspecification. To accommodate this possibility, we show how\nthe moment conditions can be reexpressed in terms of additional nuisance\nparameters and that, even under misspecification, the Bayesian ETEL posterior\ndistribution satisfies a Bernstein-von Mises result. A second key contribution\nof the paper is the development of a framework based on marginal likelihoods\nand Bayes factors to compare models defined by different moment conditions.\nComputation of the marginal likelihoods is by the method of Chib (1995) as\nextended to Metropolis-Hastings samplers in Chib and Jeliazkov (2001). We\nestablish the model selection consistency of the marginal likelihood and show\nthat the marginal likelihood favors the model with the minimum number of\nparameters and the maximum number of valid moment restrictions. When the models\nare misspecified, the marginal likelihood model selection procedure selects the\nmodel that is closer to the (unknown) true data generating process in terms of\nthe Kullback-Leibler divergence. The ideas and results in this paper provide a\nfurther broadening of the theoretical underpinning and value of the Bayesian\nETEL framework with likely far-reaching practical consequences. The discussion\nis illuminated through several examples. \n\n"}
{"id": "1606.03645", "contents": "Title: Martingale property for the Scott correlated stochastic volatility model Abstract: In this paper, we study the martingale property for a Scott correlated\nstochastic volatility model, when the correlation coefficient between the\nBrownian motion driving the volatility and the one driving the asset price\nprocess is arbitrary. For this study we verify the martingale property by using\nthe necessary and sufficient conditions given by Bernard \\emph{et al.}\n\\cite{Bernard}. Our main results are to prove that the price process is a true\nand uniformly integrable martingale if and only if $\\rho \\in [-1,0]$ for two\ntransformations of Brownian motion describing the dynamics of the underling\nasset. \n\n"}
{"id": "1606.03836", "contents": "Title: Locally Lipschitz BSDE driven by a continuous martingale:\n  path-derivative approach Abstract: Using a new notion of path-derivative, we study well-posedness of backward\nstochastic differential equation driven by a continuous martingale $M$ when\n$f(s,\\gamma,y,z)$ is locally Lipschitz in $(y,z)$:\n\\[Y_{t}=\\xi(M_{[0,T]})+\\int_{t}^{T}f(s,M_{[0,s]},Y_{s-},Z_{s}m_{s})d{\\rm\ntr}[M,M]_{s}-\\int_{t}^{T}Z_{s}dM_{s}-N_{T}+N_{t}\\] Here, $M_{[0,t]}$ is the\npath of $M$ from $0$ to $t$ and $m$ is defined by\n$[M,M]_{t}=\\int_{0}^{t}m_{s}m_{s}^{*}d{\\rm tr}[M,M]_{s}$. When the BSDE is\none-dimensional, we could show the existence and uniqueness of solution. On the\ncontrary, when the BSDE is multidimensional, we show existence and uniqueness\nonly when $[M,M]_{T}$ is small enough: otherwise, we provide a counterexample\nthat has blowing-up solution. Then, we investigate the applications to utility\nmaximization problems. \n\n"}
{"id": "1606.05360", "contents": "Title: Transformation, normalization and batch effect in the analysis of mass\n  spectrometry data for omics studies Abstract: Data transformation, normalization and handling of batch effect are a key\npart of data analysis for almost all spectrometry-based omics data. This paper\nreviews and contrasts these three distinct aspects. We present a systematic\noverview of the key approaches and critically review some common procedures.\nMuch of this paper is inspired by mass spectrometry based experimentation, but\nmost of our discussion carries over to omics data using distinct spectrometric\napproaches generally. \n\n"}
{"id": "1606.06246", "contents": "Title: High-dimensional changepoint estimation via sparse projection Abstract: Changepoints are a very common feature of Big Data that arrive in the form of\na data stream. In this paper, we study high-dimensional time series in which,\nat certain time points, the mean structure changes in a sparse subset of the\ncoordinates. The challenge is to borrow strength across the coordinates in\norder to detect smaller changes than could be observed in any individual\ncomponent series. We propose a two-stage procedure called `inspect' for\nestimation of the changepoints: first, we argue that a good projection\ndirection can be obtained as the leading left singular vector of the matrix\nthat solves a convex optimisation problem derived from the CUSUM transformation\nof the time series. We then apply an existing univariate changepoint estimation\nalgorithm to the projected series. Our theory provides strong guarantees on\nboth the number of estimated changepoints and the rates of convergence of their\nlocations, and our numerical studies validate its highly competitive empirical\nperformance for a wide range of data generating mechanisms. Software\nimplementing the methodology is available in the R package\n`InspectChangepoint'. \n\n"}
{"id": "1606.06328", "contents": "Title: Inferring Mobility Measures from GPS Traces with Missing Data Abstract: With increasing availability of smartphones with GPS capabilities,\nlarge-scale studies relating individual-level mobility patterns to a wide\nvariety of patient-centered outcomes, from mood disorders to surgical recovery,\nare becoming a reality. Similar past studies have been small in scale and have\nprovided wearable GPS devices to subjects. These devices typically collect\nmobility traces continuously without significant gaps in the data, and\nconsequently the problem of data missingness has been safely ignored.\nLeveraging subjects' own smartphones makes it possible to scale up and extend\nthe duration of these types of studies, but at the same time introduces a\nsubstantial challenge: to preserve a smartphone's battery, GPS can be active\nonly for a small portion of the time, frequently less than $10\\%$, leading to a\ntremendous missing data problem. We introduce a principled statistical\napproach, based on weighted resampling of the observed data, to impute the\nmissing mobility traces, which we then summarize using different mobility\nmeasures. We compare the strengths of our approach to linear interpolation, a\npopular approach for dealing with missing data, both analytically and through\nsimulation of missingness for empirical data. We conclude that our imputation\napproach better mirrors human mobility both theoretically and over a sample of\nGPS mobility traces from 182 individuals in the Geolife data set, where,\nrelative to linear interpolation, imputation resulted in a 10-fold reduction in\nthe error averaged across all mobility features. \n\n"}
{"id": "1606.06645", "contents": "Title: Sensitivity to Serial Dependency of Input Processes: A Robust Approach Abstract: Procedures in assessing the impact of serial dependency on performance\nanalysis are usually built on parametrically specified models. In this paper,\nwe propose a robust, nonparametric approach to carry out this assessment, by\ncomputing the worst-case deviation of the performance measure due to arbitrary\ndependence. The approach is based on optimizations, posited on the model space,\nthat have constraints specifying the level of dependency measured by a\nnonparametric distance to some nominal i.i.d. input model. We study\napproximation methods for these optimizations via simulation and\nanalysis-of-variance (ANOVA). Numerical experiments demonstrate how the\nproposed approach can discover the hidden impacts of dependency beyond those\nrevealed by conventional parametric modeling and correlation studies. \n\n"}
{"id": "1606.06746", "contents": "Title: Approximate Recovery in Changepoint Problems, from $\\ell_2$ Estimation\n  Error Rates Abstract: In the 1-dimensional multiple changepoint detection problem, we prove that\nany procedure with a fast enough $\\ell_2$ error rate, in terms of its\nestimation of the underlying piecewise constant mean vector, automatically has\nan (approximate) changepoint screening property---specifically, each true jump\nin the underlying mean vector has an estimated jump nearby. We also show, again\nassuming only knowledge of the $\\ell_2$ error rate, that a simple\npost-processing step can be used to eliminate spurious estimated changepoints,\nand thus delivers an (approximate) changepoint recovery\nproperty---specifically, in addition to the screening property described above,\nwe are assured that each estimated jump has a true jump nearby. As a special\ncase, we focus on the application of these results to the 1-dimensional fused\nlasso, i.e., 1-dimensional total variation denoising, and compare the\nimplications with existing results from the literature. We also study\nextensions to related problems, such as changepoint detection over graphs. \n\n"}
{"id": "1606.07022", "contents": "Title: Moment convergence of balanced P\\'olya processes Abstract: It is known that in an irreducible small P\\'olya urn process, the composition\nof the urn after suitable normalization converges in distribution to a normal\ndistribution. We show that if the urn also is balanced, this normal convergence\nholds with convergence of all moments, thus giving asymptotics of (central)\nmoments. \n\n"}
{"id": "1606.08986", "contents": "Title: On the multiplicative chaos of non-Gaussian log-correlated fields Abstract: We study non-Gaussian log-correlated multiplicative chaos, where the random\nfield is defined as a sum of independent fields that satisfy suitable moment\nand regularity conditions. The convergence, existence of moments and\nanalyticity with respect to the inverse temperature are proven for the\nresulting chaos in the full subcritical range. These results are\ngeneralizations of the corresponding theorems for Gaussian multiplicative\nchaos. A basic example where our results apply is the non-Gaussian Fourier\nseries\n  \\[\\sum_{k=1}^\\infty \\frac{1}{\\sqrt{k}}(A_k \\cos(2\\pi k x) + B_k \\sin(2\\pi k\nx)),\\] where $A_k$ and $B_k$ are i.i.d. random variables. \n\n"}
{"id": "1607.00098", "contents": "Title: Fully Bayesian Classification with Heavy-tailed Priors for Selection in\n  High-dimensional Features with Grouping Structure Abstract: Feature selection is demanded in many modern scientific research problems\nthat use high-dimensional data. A typical example is to find the most useful\ngenes that are related to a certain disease (eg, cancer) from high-dimensional\ngene expressions. The expressions of genes have grouping structures, for\nexample, a group of co-regulated genes that have similar biological functions\ntend to have similar expressions. Many statistical methods have been proposed\nto take the grouping structure into consideration in feature selection,\nincluding group LASSO, supervised group LASSO, and regression on group\nrepresentatives. In this paper, we propose a fully Bayesian Robit regression\nmethod with heavy-tailed (sparsity) priors (shortened by FBRHT) for selecting\nfeatures with grouping structure. The main features of FBRHT include that it\ndiscards more aggressively unrelated features than LASSO, and it can make\nfeature selection within groups automatically without a pre-specified grouping\nstructure. In this paper, we use simulated and real datasets to demonstrate\nthat the predictive power of the sparse feature subsets selected by FBRHT are\ncomparable with other much larger feature subsets selected by LASSO, group\nLASSO, supervised group LASSO, penalized logistic regression and random forest,\nand that the succinct feature subsets selected by FBRHT have significantly\nbetter predictive power than the feature subsets of the same size taken from\nthe top features selected by the aforementioned methods. \n\n"}
{"id": "1607.00638", "contents": "Title: Time-Inconsistent Stochastic Linear-quadratic Differential Game Abstract: We consider a general time-inconsistent stochastic linear-quadratic\ndifferential game. The time-inconsistency arises from the presence of quadratic\nterms of the expected state as well as state-dependent term in the objective\nfunctionals. We define an equilibrium strategy, which is different from the\nclassical one, and derived a sufficient conditions for equilibrium strategies\nvia a system of forward-backward stochastic differential equations. When the\nstate is one-dimensional and the coefficients are all deterministic, we find an\nexplicit equilibrium strategy. The uniqueness of such equilibrium strategy is\nalso given. \n\n"}
{"id": "1607.01192", "contents": "Title: Bounded Influence Propagation {\\tau}-Estimation: A New Robust Method for\n  ARMA Model Estimation Abstract: A new robust and statistically efficient estimator for ARMA models called the\nbounded influence propagation (BIP) {\\tau}-estimator is proposed. The estimator\nincorporates an auxiliary model, which prevents the propagation of outliers.\nStrong consistency and asymptotic normality of the estimator for ARMA models\nthat are driven by independently and identically distributed (iid) innovations\nwith symmetric distributions are established. To analyze the infinitesimal\neffect of outliers on the estimator, the influence function is derived and\ncomputed explicitly for an AR(1) model with additive outliers. To obtain\nestimates for the AR(p) model, a robust Durbin-Levinson type and a\nforward-backward algorithm are proposed. An iterative algorithm to robustly\nobtain ARMA(p,q) parameter estimates is also presented. The problem of finding\na robust initialization is addressed, which for orders p+q>2 is a non-trivial\nmatter. Numerical experiments are conducted to compare the finite sample\nperformance of the proposed estimator to existing robust methodologies for\ndifferent types of outliers both in terms of average and of worst-case\nperformance, as measured by the maximum bias curve. To illustrate the practical\napplicability of the proposed estimator, a real-data example of outlier\ncleaning for R-R interval plots derived from electrocardiographic (ECG) data is\nconsidered. The proposed estimator is not limited to biomedical applications,\nbut is also useful in any real-world problem whose observations can be modeled\nas an ARMA process disturbed by outliers or impulsive noise. \n\n"}
{"id": "1607.01367", "contents": "Title: A Tutorial on Regularized Partial Correlation Networks Abstract: Recent years have seen an emergence of network modeling applied to moods,\nattitudes, and problems in the realm of psychology. In this framework,\npsychological variables are understood to directly affect each other rather\nthan being caused by an unobserved latent entity. In this tutorial, we\nintroduce the reader to estimating the most popular network model for\npsychological data: the partial correlation network. We describe how\nregularization techniques can be used to efficiently estimate a parsimonious\nand interpretable network structure in psychological data. We show how to\nperform these analyses in R and demonstrate the method in an empirical example\non post-traumatic stress disorder data. In addition, we discuss the effect of\nthe hyperparameter that needs to be manually set by the researcher, how to\nhandle non-normal data, how to determine the required sample size for a network\nanalysis, and provide a checklist with potential solutions for problems that\ncan arise when estimating regularized partial correlation networks. \n\n"}
{"id": "1607.02563", "contents": "Title: Closability of Quadratic Forms Associated to Invariant Probability\n  Measures of SPDEs Abstract: By using the integration by parts formula of a Markov operator, the\nclosability of quadratic forms associated to the corresponding invariant\nprobability measure is proved. The general result is applied to the study of\nsemilinear SPDEs, infinite-dimensional stochastic Hamiltonian systems, and\nsemilinear SPDEs with delay. \n\n"}
{"id": "1607.02896", "contents": "Title: Conjugacy properties of time-evolving Dirichlet and gamma random\n  measures Abstract: We extend classic characterisations of posterior distributions under\nDirichlet process and gamma random measures priors to a dynamic framework. We\nconsider the problem of learning, from indirect observations, two families of\ntime-dependent processes of interest in Bayesian nonparametrics: the first is a\ndependent Dirichlet process driven by a Fleming-Viot model, and the data are\nrandom samples from the process state at discrete times; the second is a\ncollection of dependent gamma random measures driven by a Dawson-Watanabe\nmodel, and the data are collected according to a Poisson point process with\nintensity given by the process state at discrete times. Both driving processes\nare diffusions taking values in the space of discrete measures whose support\nvaries with time, and are stationary and reversible with respect to Dirichlet\nand gamma priors respectively. A common methodology is developed to obtain in\nclosed form the time-marginal posteriors given past and present data. These are\nshown to belong to classes of finite mixtures of Dirichlet processes and gamma\nrandom measures for the two models respectively, yielding conjugacy of these\nclasses to the type of data we consider. We provide explicit results on the\nparameters of the mixture components and on the mixing weights, which are\ntime-varying and drive the mixtures towards the respective priors in absence of\nfurther data. Explicit algorithms are provided to recursively compute the\nparameters of the mixtures. Our results are based on the projective properties\nof the signals and on certain duality properties of their projections. \n\n"}
{"id": "1607.04395", "contents": "Title: Lotka-Volterra with randomly fluctuating environments: a full\n  description Abstract: In this note, we study the long time behavior of Lotka-Volterra systems whose\ncoefficients vary randomly. Benam and Lobry established that randomly switching\nbetween two environments that are both favorable to the same species may lead\nto four different regimes: almost sure extinction of one of the two species,\nrandom extinction of one species or the other and persistence of both species.\nOur purpose here is to provide a complete description of the model. In\nparticular, we show that any couple of environments may lead to the four\ndifferent behaviours of the stochastic process depending on the jump rates. \n\n"}
{"id": "1607.04542", "contents": "Title: Diffusions under a local strong H\\\"ormander condition. Part I: density\n  estimates Abstract: We study lower and upper bounds for the density of a diffusion process in\n${\\mathbb{R}}^n$ in a small (but not asymptotic) time, say $\\delta$. We assume\nthat the diffusion coefficients $\\sigma_1,\\ldots,\\sigma_d$ may degenerate at\nthe starting time $0$ and point $x_0$ but they satisfy a strong H\\\"ormander\ncondition involving the first order Lie brackets. The density estimates are\nwritten in terms of a norm which accounts for the non-isotropic structure of\nthe problem: in a small time $\\delta$, the diffusion process propagates with\nspeed $\\sqrt{\\delta}$ in the direction of the diffusion vector fields\n$\\sigma_{j}$ and with speed $\\delta=\\sqrt{\\delta}\\times \\sqrt{\\delta}$ in the\ndirection of $[\\sigma_{i},\\sigma_{j}]$. In the second part of this paper, such\nestimates will be used in order to study lower and upper bounds for the\nprobability that the diffusion process remains in a tube around a skeleton path\nup to a fixed time. \n\n"}
{"id": "1608.00554", "contents": "Title: On the Complexity of Constrained Determinantal Point Processes Abstract: Determinantal Point Processes (DPPs) are probabilistic models that arise in\nquantum physics and random matrix theory and have recently found numerous\napplications in computer science. DPPs define distributions over subsets of a\ngiven ground set, they exhibit interesting properties such as negative\ncorrelation, and, unlike other models, have efficient algorithms for sampling.\nWhen applied to kernel methods in machine learning, DPPs favor subsets of the\ngiven data with more diverse features. However, many real-world applications\nrequire efficient algorithms to sample from DPPs with additional constraints on\nthe subset, e.g., partition or matroid constraints that are important to ensure\npriors, resource or fairness constraints on the sampled subset. Whether one can\nefficiently sample from DPPs in such constrained settings is an important\nproblem that was first raised in a survey of DPPs by \\cite{KuleszaTaskar12} and\nstudied in some recent works in the machine learning literature.\n  The main contribution of our paper is the first resolution of the complexity\nof sampling from DPPs with constraints. We give exact efficient algorithms for\nsampling from constrained DPPs when their description is in unary. Furthermore,\nwe prove that when the constraints are specified in binary, this problem is\n#P-hard via a reduction from the problem of computing mixed discriminants\nimplying that it may be unlikely that there is an FPRAS. Our results benefit\nfrom viewing the constrained sampling problem via the lens of polynomials.\nConsequently, we obtain a few algorithms of independent interest: 1) to count\nover the base polytope of regular matroids when there are additional (succinct)\nbudget constraints and, 2) to evaluate and compute the mixed characteristic\npolynomials, that played a central role in the resolution of the Kadison-Singer\nproblem, for certain special cases. \n\n"}
{"id": "1608.00948", "contents": "Title: The bootstrap, covariance matrices and PCA in moderate and\n  high-dimensions Abstract: We consider the properties of the bootstrap as a tool for inference\nconcerning the eigenvalues of a sample covariance matrix computed from an\n$n\\times p$ data matrix $X$. We focus on the modern framework where $p/n$ is\nnot close to 0 but remains bounded as $n$ and $p$ tend to infinity.\n  Through a mix of numerical and theoretical considerations, we show that the\nbootstrap is not in general a reliable inferential tool in the setting we\nconsider. However, in the case where the population covariance matrix is\nwell-approximated by a finite rank matrix, the bootstrap performs as it does in\nfinite dimension. \n\n"}
{"id": "1608.02478", "contents": "Title: Temperature chaos in some spherical mixed $p$-spin models Abstract: We give two types of examples of the spherical mixed even-$p$-spin models for\nwhich chaos in temperature holds. These complement some known results for the\nspherical pure $p$-spin models and for models with Ising spins. For example, in\ncontrast to a recent result of Subag who showed absence of chaos in temperature\nin the spherical pure $p$-spin models for $p\\geq 3$, we show that even a\nsmaller order perturbation induces temperature chaos. \n\n"}
{"id": "1608.05430", "contents": "Title: Entropy Jumps for Radially Symmetric Random Vectors Abstract: We establish a quantitative bound on the entropy jump associated to the sum\nof independent, identically distributed (IID) radially symmetric random vectors\nhaving dimension greater than one. Following the usual approach, we first\nconsider the analogous problem of Fisher information dissipation, and then\nintegrate along the Ornstein-Uhlenbeck semigroup to obtain an entropic\ninequality. In a departure from previous work, we appeal to a result by\nDesvillettes and Villani on entropy production associated to the Landau\nequation. This obviates strong regularity assumptions, such as presence of a\nspectral gap and log-concavity of densities, but comes at the expense of radial\nsymmetry. As an application, we give a quantitative estimate of the deficit in\nthe Gaussian logarithmic Sobolev inequality for radially symmetric functions. \n\n"}
{"id": "1608.06196", "contents": "Title: A Framework for the Construction of Generative Models for Mesoscale\n  Structure in Multilayer Networks Abstract: Multilayer networks allow one to represent diverse and coupled connectivity\npatterns --- e.g., time-dependence, multiple subsystems, or both --- that arise\nin many applications and which are difficult or awkward to incorporate into\nstandard network representations. In the study of multilayer networks, it is\nimportant to investigate mesoscale (i.e., intermediate-scale) structures, such\nas dense sets of nodes known as communities, to discover network features that\nare not apparent at the microscale or the macroscale. The ill-defined nature of\nmesoscale structure and its ubiquity in empirical networks make it crucial to\ndevelop generative models that can produce the features that one encounters in\nempirical networks. Key purposes of such generative models include generating\nsynthetic networks with empirical properties of interest, benchmarking\nmesoscale-detection methods and algorithms, and inferring structure in\nempirical multilayer networks. In this paper, we introduce a framework for the\nconstruction of generative models for mesoscale structures in multilayer\nnetworks. Our framework provides a standardized set of generative models,\ntogether with an associated set of principles from which they are derived, for\nstudies of mesoscale structures in multilayer networks. It unifies and\ngeneralizes many existing models for mesoscale structures in fully-ordered\n(e.g., temporal) and unordered (e.g., multiplex) multilayer networks. One can\nalso use it to construct generative models for mesoscale structures in\npartially-ordered multilayer networks (e.g., networks that are both temporal\nand multiplex). Our framework has the ability to produce many features of\nempirical multilayer networks, and it explicitly incorporates a user-specified\ndependency structure between layers. \n\n"}
{"id": "1609.00065", "contents": "Title: Partitioned Cross-Validation for Divide-and-Conquer Density Estimation Abstract: We present an efficient method to estimate cross-validation bandwidth\nparameters for kernel density estimation in very large datasets where ordinary\ncross-validation is rendered highly inefficient, both statistically and\ncomputationally. Our approach relies on calculating multiple cross-validation\nbandwidths on partitions of the data, followed by suitable scaling and\naveraging to return a partitioned cross-validation bandwidth for the entire\ndataset. The partitioned cross-validation approach produces substantial\ncomputational gains over ordinary cross-validation. We additionally show that\npartitioned cross-validation can be statistically efficient compared to\nordinary cross-validation. We derive analytic expressions for the\nasymptotically optimal number of partitions and study its finite sample\naccuracy through a detailed simulation study. We additionally propose a\npermuted version of partitioned cross-validation which attains even higher\nefficiency. Theoretical properties of the estimators are studied and the\nmethodology is applied to the Higgs Boson dataset with 11 million observations \n\n"}
{"id": "1609.00451", "contents": "Title: Least Ambiguous Set-Valued Classifiers with Bounded Error Levels Abstract: In most classification tasks there are observations that are ambiguous and\ntherefore difficult to correctly label. Set-valued classifiers output sets of\nplausible labels rather than a single label, thereby giving a more appropriate\nand informative treatment to the labeling of ambiguous instances. We introduce\na framework for multiclass set-valued classification, where the classifiers\nguarantee user-defined levels of coverage or confidence (the probability that\nthe true label is contained in the set) while minimizing the ambiguity (the\nexpected size of the output). We first derive oracle classifiers assuming the\ntrue distribution to be known. We show that the oracle classifiers are obtained\nfrom level sets of the functions that define the conditional probability of\neach class. Then we develop estimators with good asymptotic and finite sample\nproperties. The proposed estimators build on existing single-label classifiers.\nThe optimal classifier can sometimes output the empty set, but we provide two\nsolutions to fix this issue that are suitable for various practical needs. \n\n"}
{"id": "1609.01884", "contents": "Title: A Note on Large H-Intersecting Families Abstract: A family $F$ of graphs on a fixed set of $n$ vertices is called\ntriangle-intersecting if for any $G_1,G_2 \\in F$, the intersection $G_1 \\cap\nG_2$ contains a triangle. More generally, for a fixed graph $H$, a family $F$\nis $H$-intersecting if the intersection of any two graphs in $F$ contains a\nsub-graph isomorphic to $H$.\n  In [D. Ellis, Y. Filmus, and E. Friedgut, Triangle-intersecting families of\ngraphs, J. Eur. Math. Soc. 14 (2012), pp. 841--885], Ellis, Filmus and Friedgut\nproved a 36-year old conjecture of Simonovits and S\\'{o}s stating that the\nmaximal size of a triangle-intersecting family is $(1/8)2^{n(n-1)/2}$.\nFurthermore, they proved a $p$-biased generalization, stating that for any $p\n\\leq 1/2$, we have $\\mu_{p}(F)\\le p^{3}$, where $\\mu_{p}(F)$ is the probability\nthat the random graph $G(n,p)$ belongs to $F$.\n  In the same paper, Ellis et al. conjectured that the assertion of their\nbiased theorem holds also for $1/2 < p \\le 3/4$, and more generally, that for\nany non-$t$-colorable graph $H$ and any $H$-intersecting family $F$, we have\n$\\mu_{p}(F)\\le p^{t(t+1)/2}$ for all $p \\leq (2t-1)/(2t)$.\n  In this note we construct, for any fixed $H$ and any $p>1/2$, an\n$H$-intersecting family $F$ of graphs such that $\\mu_{p}(F)\\ge 1-e^{-n^{2}/C}$,\nwhere $C$ depends only on $H$ and $p$, thus disproving both conjectures. \n\n"}
{"id": "1609.02438", "contents": "Title: Integration by parts on the law of the modulus of the Brownian bridge Abstract: We prove an infinite dimensional integration by parts formula on the law of\nthe modulus of the Brownian bridge $BB=(BB_t)_{0 \\leq t \\leq 1}$ from $0$ to\n$0$ in use of methods from white noise analysis and Dirichlet form theory.\nAdditionally to the usual drift term, this formula contains a distribution\nwhich is constructed in the space of Hida distributions by means of a Wick\nproduct with Donsker's delta (which correlates with the local time of $|BB|$ at\nzero). This additional distribution corresponds to the reflection at zero\ncaused by the modulus. \n\n"}
{"id": "1609.02818", "contents": "Title: Network Psychometrics Abstract: This chapter provides a general introduction of network modeling in\npsychometrics. The chapter starts with an introduction to the statistical model\nformulation of pairwise Markov random fields (PMRF), followed by an\nintroduction of the PMRF suitable for binary data: the Ising model. The Ising\nmodel is a model used in ferromagnetism to explain phase transitions in a field\nof particles. Following the description of the Ising model in statistical\nphysics, the chapter continues to show that the Ising model is closely related\nto models used in psychometrics. The Ising model can be shown to be equivalent\nto certain kinds of logistic regression models, loglinear models and\nmulti-dimensional item response theory (MIRT) models. The equivalence between\nthe Ising model and the MIRT model puts standard psychometrics in a new light\nand leads to a strikingly different interpretation of well-known latent\nvariable models. The chapter gives an overview of methods that can be used to\nestimate the Ising model, and concludes with a discussion on the interpretation\nof latent variables given the equivalence between the Ising model and MIRT. \n\n"}
{"id": "1609.02938", "contents": "Title: Extract fetal ECG from single-lead abdominal ECG by de-shape short time\n  Fourier transform and nonlocal median Abstract: The multiple fundamental frequency detection problem and the source\nseparation problem from a single-channel signal containing multiple oscillatory\ncomponents and a nonstationary noise are both challenging tasks. To extract the\nfetal electrocardiogram (ECG) from a single-lead maternal abdominal ECG, we\nface both challenges. In this paper, we propose a novel method to extract the\nfetal ECG signal from the single channel maternal abdominal ECG signal, without\nany additional measurement. The algorithm is composed of three main\ningredients. First, the maternal and fetal heart rates are estimated by the\nde-shape short time Fourier transform, which is a recently proposed nonlinear\ntime-frequency analysis technique; second, the beat tracking technique is\napplied to accurately obtain the maternal and fetal R peaks; third, the\nmaternal and fetal ECG waveforms are established by the nonlocal median. The\nalgorithm is evaluated on a simulated fetal ECG signal database ({\\em fecgsyn}\ndatabase), and tested on two real databases with the annotation provided by\nexperts ({\\em adfecgdb} database and {\\em CinC2013} database). In general, the\nalgorithm could be applied to solve other detection and source separation\nproblems, and reconstruct the time-varying wave-shape function of each\noscillatory component. \n\n"}
{"id": "1609.03045", "contents": "Title: Principal component analysis and the locus of the Frechet mean in the\n  space of phylogenetic trees Abstract: Most biological data are multidimensional, posing a major challenge to human\ncomprehension and computational analysis. Principal component analysis is the\nmost popular approach to rendering two- or three-dimensional representations of\nthe major trends in such multidimensional data. The problem of\nmultidimensionality is acute in the rapidly growing area of phylogenomics.\nEvolutionary relationships are represented by phylogenetic trees, and very\ntypically a phylogenomic analysis results in a collection of such trees, one\nfor each gene in the analysis. Principal component analysis offers a means of\nquantifying variation and summarizing a collection of phylogenies by\ndimensional reduction. However, the space of all possible phylogenies on a\nfixed set of species does not form a Euclidean vector space, so principal\ncomponent analysis must be reformulated in the geometry of tree-space, which is\na CAT(0) geodesic metric space. Previous work has focused on construction of\nthe first principal component, or principal geodesic. Here we propose a\ngeometric object which represents a $k$-th order principal component: the locus\nof the weighted Fr\\'echet mean of $k+1$ points in tree-space, where the weights\nvary over the standard $k$-dimensional simplex. We establish basic properties\nof these objects, in particular that locally they generically have dimension\n$k$, and we propose an efficient algorithm for projection onto these surfaces.\nCombined with a stochastic optimization algorithm, this projection algorithm\ngives a procedure for constructing a principal component of arbitrary order in\ntree-space. Simulation studies confirm these algorithms perform well, and they\nare applied to data sets of Apicomplexa gene trees and the African coelacanth\ngenome. The results enable visualizations of slices of tree-space, revealing\nstructure within these complex data sets. \n\n"}
{"id": "1609.04340", "contents": "Title: PSI ({\\Psi}): a Private data Sharing Interface Abstract: We provide an overview of PSI (\"a Private data Sharing Interface\"), a system\nwe are developing to enable researchers in the social sciences and other fields\nto share and explore privacy-sensitive datasets with the strong privacy\nprotections of differential privacy. \n\n"}
{"id": "1609.04558", "contents": "Title: Statistical Inference in a Directed Network Model with Covariates Abstract: Networks are often characterized by node heterogeneity for which nodes\nexhibit different degrees of interaction and link homophily for which nodes\nsharing common features tend to associate with each other. In this paper, we\npropose a new directed network model to capture the former via node-specific\nparametrization and the latter by incorporating covariates. In particular, this\nmodel quantifies the extent of heterogeneity in terms of outgoingness and\nincomingness of each node by different parameters, thus allowing the number of\nheterogeneity parameters to be twice the number of nodes. We study the maximum\nlikelihood estimation of the model and establish the uniform consistency and\nasymptotic normality of the resulting estimators. Numerical studies demonstrate\nour theoretical findings and a data analysis confirms the usefulness of our\nmodel. \n\n"}
{"id": "1609.05108", "contents": "Title: A multi-sensor multi-Bernoulli filter Abstract: In this paper we derive a multi-sensor multi-Bernoulli (MS-MeMBer) filter for\nmulti-target tracking. Measurements from multiple sensors are employed by the\nproposed filter to update a set of tracks modeled as a multi-Bernoulli random\nfinite set. An exact implementation of the MS-MeMBer update procedure is\ncomputationally intractable. We propose an efficient approximate implementation\nby using a greedy measurement partitioning mechanism. The proposed filter\nallows for Gaussian mixture or particle filter implementations. Numerical\nsimulations conducted for both linear-Gaussian and non-linear models highlight\nthe improved accuracy of the MS-MeMBer filter and its reduced computational\nload with respect to the multi-sensor cardinalized probability hypothesis\ndensity filter and the iterated-corrector cardinality-balanced multi-Bernoulli\nfilter especially for low probabilities of detection. \n\n"}
{"id": "1609.06144", "contents": "Title: Multilevel Monte Carlo for Scalable Bayesian Computations Abstract: Markov chain Monte Carlo (MCMC) algorithms are ubiquitous in Bayesian\ncomputations. However, they need to access the full data set in order to\nevaluate the posterior density at every step of the algorithm. This results in\na great computational burden in big data applications. In contrast to MCMC\nmethods, Stochastic Gradient MCMC (SGMCMC) algorithms such as the Stochastic\nGradient Langevin Dynamics (SGLD) only require access to a batch of the data\nset at every step. This drastically improves the computational performance and\nscales well to large data sets. However, the difficulty with SGMCMC algorithms\ncomes from the sensitivity to its parameters which are notoriously difficult to\ntune. Moreover, the Root Mean Square Error (RMSE) scales as\n$\\mathcal{O}(c^{-\\frac{1}{3}})$ as opposed to standard MCMC\n$\\mathcal{O}(c^{-\\frac{1}{2}})$ where $c$ is the computational cost.\n  We introduce a new class of Multilevel Stochastic Gradient Markov chain Monte\nCarlo algorithms that are able to mitigate the problem of tuning the step size\nand more importantly of recovering the $\\mathcal{O}(c^{-\\frac{1}{2}})$\nconvergence of standard Markov Chain Monte Carlo methods without the need to\nintroduce Metropolis-Hasting steps. A further advantage of this new class of\nalgorithms is that it can easily be parallelised over a heterogeneous computer\narchitecture. We illustrate our methodology using Bayesian logistic regression\nand provide numerical evidence that for a prescribed relative RMSE the\ncomputational cost is sublinear in the number of data items. \n\n"}
{"id": "1609.07007", "contents": "Title: Fast symmetric additive covariance smoothing Abstract: We propose a fast bivariate smoothing approach for symmetric surfaces that\nhas a wide range of applications. We show how it can be applied to estimate the\ncovariance function in longitudinal data as well as multiple additive\ncovariances in functional data with complex correlation structures. Our\nsymmetric smoother can handle (possibly noisy) data sampled on a common, dense\ngrid as well as irregularly or sparsely sampled data. Estimation is based on\nbivariate penalized spline smoothing using a mixed model representation and the\nsymmetry is used to reduce computation time compared to the usual non-symmetric\nsmoothers. We outline the application of our approach in functional principal\ncomponent analysis and demonstrate its practical value in two applications. The\napproach is evaluated in extensive simulations. We provide documented open\nsource software implementing our fast symmetric bivariate smoother building on\nestablished algorithms for additive models. \n\n"}
{"id": "1609.07235", "contents": "Title: Hereditarily Non Uniformly Perfect Sets Abstract: We introduce the concept of hereditarily non uniformly perfect sets, compact\nsets for which no compact subset is uniformly perfect, and compare them with\nthe following: Hausdorff dimension zero sets, logarithmic capacity zero sets,\nLebesgue 2-dimensional measure zero sets, and porous sets. In particular, we\ngive an example of a compact set in the plane of Hausdorff dimension 2 (and\npositive logarithmic capacity) which is hereditarily non uniformly perfect. \n\n"}
{"id": "1609.09272", "contents": "Title: A New Algorithm for Circulant Rational Covariance Extension and\n  Applications to Finite-interval Smoothing Abstract: The partial stochastic realization of periodic processes from finite\ncovariance data has recently been solved by Lindquist and Picci based on convex\noptimization of a generalized entropy functional. The meaning and the role of\nthis criterion have an unclear origin. In this paper we propose a solution\nbased on a nonlinear generalization of the classical Yule-Walker type equations\nand on a new iterative algorithm which is shown to converge to the same\n(unique) solution of the variational problem. This provides a conceptual link\nto the variational principles and at the same time yields a robust algorithm\nwhich can for example be successfully applied to finite-interval smoothing\nproblems providing a simpler procedure if compared with the classical\nRiccati-based calculations. \n\n"}
{"id": "1609.09338", "contents": "Title: Front propagation and quasi-stationary distributions for one-dimensional\n  L\\'evy processes Abstract: We jointly investigate the existence of quasi-stationary distributions for\none dimensional L\\'evy processes and the existence of traveling waves for the\nFisher-Kolmogorov-Petrovskii-Piskunov (F-KPP) equation associated with the same\nmotion. Using probabilistic ideas developed by S. Harris, we show that the\nexistence of a traveling wave for the F-KPP equation associated with a centered\nL\\'evy processes that branches at rate $r$ and travels at velocity $c$ is\nequivalent to the existence of a quasi-stationary distribution for a L\\'evy\nprocess with the same movement but drifted by $-c$ and killed at zero, with\nmean absorption time $1/r$. This also extends the known existence conditions in\nboth contexts. As it is discussed in a companion article, this is not just a\ncoincidence but the consequence of a relation between these two phenomena. \n\n"}
{"id": "1609.09380", "contents": "Title: Testing mutual independence in high dimension via distance covariance Abstract: In this paper, we introduce a ${\\mathcal L}_2$ type test for testing mutual\nindependence and banded dependence structure for high dimensional data. The\ntest is constructed based on the pairwise distance covariance and it accounts\nfor the non-linear and non-monotone dependences among the data, which cannot be\nfully captured by the existing tests based on either Pearson correlation or\nrank correlation. Our test can be conveniently implemented in practice as the\nlimiting null distribution of the test statistic is shown to be standard\nnormal. It exhibits excellent finite sample performance in our simulation\nstudies even when the sample size is small albeit dimension is high, and is\nshown to successfully identify nonlinear dependence in empirical data analysis.\nOn the theory side, asymptotic normality of our test statistic is shown under\nquite mild moment assumptions and with little restriction on the growth rate of\nthe dimension as a function of sample size. As a demonstration of good power\nproperties for our distance covariance based test, we further show that an\ninfeasible version of our test statistic has the rate optimality in the class\nof Gaussian distribution with equal correlation. \n\n"}
{"id": "1609.09529", "contents": "Title: Loss of information in feedforward social networks Abstract: We consider model social networks in which information propagates\ndirectionally across layers of rational agents. Each agent makes a locally\noptimal estimate of the state of the world, and communicates this estimate to\nagents downstream. When agents receive information from the same source their\nestimates are correlated. We show that the resulting redundancy can lead to the\nloss of information about the state of the world across layers of the network,\neven when all agents have full knowledge of the network's structure. A simple\nalgebraic condition identifies networks in which information loss occurs, and\nwe show that all such networks must contain a particular network motif. We also\nstudy random networks asymptotically as the number of agents increases, and\nfind a sharp transition in the probability of information loss at the point at\nwhich the number of agents in one layer exceeds the number in the previous\nlayer. \n\n"}
{"id": "1610.00287", "contents": "Title: Iterative Null-space Projection Method with Adaptive Thresholding in\n  Sparse Signal Recovery and Matrix Completion Abstract: Adaptive thresholding methods have proved to yield high SNRs and fast\nconvergence in finding the solution to the Compressed Sensing (CS) problems.\nRecently, it was observed that the robustness of a class of iterative sparse\nrecovery algorithms such as Iterative Method with Adaptive Thresholding (IMAT)\nhas outperformed the well-known LASSO algorithm in terms of reconstruction\nquality, convergence speed, and the sensitivity to the noise. In this paper, we\nintroduce a new method towards solving the CS problem. The logic of this method\nis based on iterative projections of the thresholded signal onto the null-space\nof the sensing matrix. The thresholding is carried out by recovering the\nsupport of the desired signal by projection on thresholding subspaces. The\nsimulations reveal that the proposed method has the capability of yielding\nnoticeable output SNR values with about as many samples as twice the sparsity\nnumber, while other methods fail to recover the signals when approaching the\nalgebraic bound for the number of samples required. The computational\ncomplexity of our method is also comparable to other methods as observed in the\nsimulations. We have also extended our Algorithm to Matrix Completion (MC)\nscenarios and compared its efficiency to other well-reputed approaches for MC\nin the literature. \n\n"}
{"id": "1610.01353", "contents": "Title: Confidence regions for high-dimensional generalized linear models under\n  sparsity Abstract: We study asymptotically normal estimation and confidence regions for\nlow-dimensional parameters in high-dimensional sparse models. Our approach is\nbased on the $\\ell_1$-penalized M-estimator which is used for construction of a\nbias corrected estimator. We show that the proposed estimator is asymptotically\nnormal, under a sparsity assumption on the high-dimensional parameter,\nsmoothness conditions on the expected loss and an entropy condition. This leads\nto uniformly valid confidence regions and hypothesis testing for\nlow-dimensional parameters. The present approach is different in that it allows\nfor treatment of loss functions that we not sufficiently differentiable, such\nas quantile loss, Huber loss or hinge loss functions. We also provide new\nresults for estimation of the inverse Fisher information matrix, which is\nnecessary for the construction of the proposed estimator. We formulate our\nresults for general models under high-level conditions, but investigate these\nconditions in detail for generalized linear models and provide mild sufficient\nconditions. As particular examples, we investigate the case of quantile loss\nand Huber loss in linear regression and demonstrate the performance of the\nestimators in a simulation study and on real datasets from genome-wide\nassociation studies. We further investigate the case of logistic regression and\nillustrate the performance of the estimator on simulated and real data. \n\n"}
{"id": "1610.01635", "contents": "Title: Laguerre and Jacobi analogues of the Warren process Abstract: We define Laguerre and Jacobi analogues of the Warren process. That is, we\nconstruct local dynamics on a triangular array of particles so that the\nprojections to each level recover the Laguerre and Jacobi eigenvalue processes\nof K\\\"onig-O'Connell and Doumerc and the fixed time distributions recover the\njoint distribution of eigenvalues in multilevel Laguerre and Jacobi random\nmatrix ensembles. Our techniques extend and generalize the framework of\nintertwining diffusions developed by Pal-Shkolnikov. One consequence is the\nconstruction of particle systems with local interactions whose fixed time\ndistribution recovers the hard edge of random matrix theory. An appendix by\nAndrey Sarantsev establishes strong existence and uniqueness for solutions to\nSDER's satisfied by these processes. \n\n"}
{"id": "1610.02753", "contents": "Title: Local M-estimation with Discontinuous Criterion for Dependent and\n  Limited Observations Abstract: This paper examines asymptotic properties of local M-estimators under three\nsets of high-level conditions. These conditions are sufficiently general to\ncover the minimum volume predictive region, conditional maximum score estimator\nfor a panel data discrete choice model, and many other widely used estimators\nin statistics and econometrics. Specifically, they allow for discontinuous\ncriterion functions of weakly dependent observations, which may be localized by\nkernel smoothing and contain nuisance parameters whose dimension may grow to\ninfinity. Furthermore, the localization can occur around parameter values\nrather than around a fixed point and the observation may take limited values,\nwhich leads to set estimators. Our theory produces three different\nnonparametric cube root rates and enables valid inference for the local\nM-estimators, building on novel maximal inequalities for weakly dependent data.\nOur results include the standard cube root asymptotics as a special case. To\nillustrate the usefulness of our results, we verify our conditions for various\nexamples such as the Hough transform estimator with diminishing bandwidth,\nmaximum score-type set estimator, and many others. \n\n"}
{"id": "1610.03103", "contents": "Title: Optimality Regions and Fluctuations for Bernoulli Last Passage Models Abstract: We study the sequence alignment problem and its independent version, the\ndiscrete Hammersley process with an exploration penalty. We obtain rigorous\nupper bounds for the number of optimality regions in both models near the soft\nedge. At zero penalty the independent model becomes an exactly solvable model\nand we identify cases for which the law of the last passage time converges to a\nTracy-Widom law. \n\n"}
{"id": "1610.03692", "contents": "Title: A $q$-Robinson-Schensted-Knuth Algorithm and a $q$-polymer Abstract: In [Matveev-Petrov 2016](arXiv:1504.00666) a $q$-deformed\nRobinson-Schensted-Knuth algorithm ($q$RSK) was introduced. In this article we\ngive reformulations of this algorithm in terms of the Noumi-Yamada description,\ngrowth diagrams and local moves. We show that the algorithm is symmetric,\nnamely the output tableaux pairs are swapped in a sense of distribution when\nthe input matrix is transposed. We also formulate a $q$-polymer model based on\nthe $q$RSK, prove the corresponding Burke property, which we use to show a\nstrong law of large numbers for the partition function given stationary\nboundary conditions and $q$-geometric weights. We use the $q$-local moves to\ndefine a generalisation of the $q$RSK taking a Young diagram-shape of array as\nthe input. We write down the joint distribution of partition functions in the\nspace-like direction of the $q$-polymer in $q$-geometric environment, formulate\na $q$-version of the multilayer polynuclear growth model ($q$PNG) and write\ndown the joint distribution of the $q$-polymer partition functions at a fixed\ntime. \n\n"}
{"id": "1610.05045", "contents": "Title: Validation of community robustness Abstract: The large amount of work on community detection and its applications leaves\nunaddressed one important question: the statistical validation of the results.\nIn this paper we present a methodology able to clearly detect if the community\nstructure found by some algorithms is statistically significant or is a result\nof chance, merely due to edge positions in the network. Given a community\ndetection method and a network of interest, our proposal examines the stability\nof the partition recovered against random perturbations of the original graph\nstructure. To address this issue, we specify a perturbation strategy and a null\nmodel to build a set of procedures based on a special measure of clustering\ndistance, namely Variation of Information, using tools set up for functional\ndata analysis. The procedures determine whether the obtained clustering departs\nsignificantly from the null model. This strongly supports the robustness\nagainst perturbation of the algorithm used to identify the community structure.\nWe show the results obtained with the proposed technique on simulated and real\ndatasets. \n\n"}
{"id": "1610.05408", "contents": "Title: Finite State Mean Field Games with Major and Minor Players Abstract: The goal of the paper is to develop the theory of finite state mean field\ngames with major and minor players when the state space of the game is finite.\nWe introduce the finite player games and derive a mean field game formulation\nin the limit when the number of minor players tends to infinity. In this limit,\nwe prove that the value functions of the optimization problems are viscosity\nsolutions of PIDEs of the HJB type, and we construct the best responses for\nboth types of players. From there, we prove existence of Nash equilibria under\nreasonable assumptions. Finally we prove that a form of propagation of chaos\nholds in the present context and use this result to prove existence of\napproximate Nash equilibria for the finite player games from the solutions of\nthe mean field games. this vindicate our formulation of the mean field game\nproblem. \n\n"}
{"id": "1610.06108", "contents": "Title: Universality of the matrix Airy and Bessel functions at spectral edges\n  of unitary ensembles Abstract: This paper deals with products and ratios of average characteristic\npolynomials for unitary ensembles. We prove universality at the soft edge of\nthe limiting eigenvalues' density, and write the universal limit in function of\nthe Kontsevich matrix model (\"matrix Airy function\", as originally named by\nKontsevich). For the case of the hard edge, universality is already known. We\nshow that also in this case the universal limit can be expressed as a matrix\nintegral (\"matrix Bessel function\") known in the literature as generalized\nKontsevich matrix model. \n\n"}
{"id": "1610.06975", "contents": "Title: Tracy-Widom fluctuations for perturbations of the log-gamma polymer in\n  intermediate disorder Abstract: The free-energy fluctuations of the discrete directed polymer in 1+1\ndimensions is conjecturally in the Tracy-Widom universality class at all finite\ntemperatures and in the intermediate disorder regime. Sepp\\\"al\\\"ainen's\nlog-gamma polymer was proven to have GUE Tracy-Widom fluctuations in a\nrestricted temperature range by Borodin et. al. (2013). We remove this\nrestriction, and extend this result into the intermediate disorder regime. This\nresult also identifies the scale of fluctuations of the log-gamma polymer in\nthe intermediate disorder regime, and thus verifies a conjecture of Alberts et.\nal. (2010). Using a perturbation argument, we show that any polymer that\nmatches a certain number of moments with the log-gamma polymer also has\nTracy-Widom fluctuations in intermediate disorder. \n\n"}
{"id": "1610.08621", "contents": "Title: Estimator Augmentation with Applications in High-Dimensional Group\n  Inference Abstract: To make inference about a group of parameters on high-dimensional data, we\ndevelop the method of estimator augmentation for the block Lasso, which is\ndefined via the block norm. By augmenting a block Lasso estimator $\\hat{\\beta}$\nwith the subgradient $S$ of the block norm evaluated at $\\hat{\\beta}$, we\nderive a closed-form density for the joint distribution of $(\\hat{\\beta},S)$\nunder a high-dimensional setting. This allows us to draw from an estimated\nsampling distribution of $\\hat{\\beta}$, or more generally any function of\n$(\\hat{\\beta},S)$, by Monte Carlo algorithms. We demonstrate the application of\nestimator augmentation in group inference with the group Lasso and a de-biased\ngroup Lasso constructed as a function of $(\\hat{\\beta},S)$. Our numerical\nresults show that importance sampling via estimator augmentation can be orders\nof magnitude more efficient than parametric bootstrap in estimating tail\nprobabilities for significance tests. This work also brings new insights into\nthe geometry of the sample space and the solution uniqueness of the block\nLasso. \n\n"}
{"id": "1610.09037", "contents": "Title: Model Criticism for Bayesian Causal Inference Abstract: The goal of causal inference is to understand the outcome of alternative\ncourses of action. However, all causal inference requires assumptions. Such\nassumptions can be more influential than in typical tasks for probabilistic\nmodeling, and testing those assumptions is important to assess the validity of\ncausal inference. We develop model criticism for Bayesian causal inference,\nbuilding on the idea of posterior predictive checks to assess model fit. Our\napproach involves decomposing the problem, separately criticizing the model of\ntreatment assignments and the model of outcomes. Conditioned on the assumption\nof unconfoundedness---that the treatments are assigned independently of the\npotential outcomes---we show how to check any additional modeling assumption.\nOur approach provides a foundation for diagnosing model-based causal\ninferences. \n\n"}
{"id": "1610.09538", "contents": "Title: Hessian formulas and estimates for parabolic Schr\\\"odinger operators Abstract: We study the Hessian of the fundamental solution to the parabolic problem for\nweighted Schr\\\"odinger operators of the form $\\frac 12 \\Delta+\\nabla h-V$\nproving a second order Feynman-Kac formula and obtaining Hessian estimates. For\nmanifolds with a pole, we use the Jacobian determinant of the exponential map\nto offset the volume growth of the Riemannian measure and use the\nsemi-classical bridge as a delta measure at $y_0$ to obtain exact Gaussian\nestimates.\n  These estimates are in terms of bounds on $Ric-2 Hess (h)$, on the curvature\noperator, and on the cyclic sum of the gradient of the Ricci tensor. \n\n"}
{"id": "1611.00328", "contents": "Title: Variational Inference via $\\chi$-Upper Bound Minimization Abstract: Variational inference (VI) is widely used as an efficient alternative to\nMarkov chain Monte Carlo. It posits a family of approximating distributions $q$\nand finds the closest member to the exact posterior $p$. Closeness is usually\nmeasured via a divergence $D(q || p)$ from $q$ to $p$. While successful, this\napproach also has problems. Notably, it typically leads to underestimation of\nthe posterior variance. In this paper we propose CHIVI, a black-box variational\ninference algorithm that minimizes $D_{\\chi}(p || q)$, the $\\chi$-divergence\nfrom $p$ to $q$. CHIVI minimizes an upper bound of the model evidence, which we\nterm the $\\chi$ upper bound (CUBO). Minimizing the CUBO leads to improved\nposterior uncertainty, and it can also be used with the classical VI lower\nbound (ELBO) to provide a sandwich estimate of the model evidence. We study\nCHIVI on three models: probit regression, Gaussian process classification, and\na Cox process model of basketball plays. When compared to expectation\npropagation and classical VI, CHIVI produces better error rates and more\naccurate estimates of posterior variance. \n\n"}
{"id": "1611.00745", "contents": "Title: Optimal Heavy-Traffic Queue Length Scaling in an Incompletely Saturated\n  Switch Abstract: We consider an input queued switch operating under the MaxWeight scheduling\nalgorithm. This system is interesting to study because it is a model for\nInternet routers and data center networks. Recently, it was shown that the\nMaxWeight algorithm has optimal heavy-traffic queue length scaling when all\nports are uniformly saturated. Here we consider the case when an arbitrary\nnumber of ports are saturated (which we call the incompletely saturated case),\nand each port is allowed to saturate at a different rate. We use a recently\ndeveloped drift technique to show that the heavy-traffic queue length under the\nMaxWeight scheduling algorithm has optimal scaling with respect to the switch\nsize even in these cases. \n\n"}
{"id": "1611.01647", "contents": "Title: Uniform Sampling through the Lov\\'asz Local Lemma Abstract: We propose a new algorithmic framework, called \"partial rejection sampling\",\nto draw samples exactly from a product distribution, conditioned on none of a\nnumber of bad events occurring. Our framework builds (perhaps surprising) new\nconnections between the variable framework of the Lov\\'asz Local Lemma and some\nclassical sampling algorithms such as the \"cycle-popping\" algorithm for rooted\nspanning trees. Among other applications, we discover new algorithms to sample\nsatisfying assignments of k-CNF formulas with bounded variable occurrences. \n\n"}
{"id": "1611.01876", "contents": "Title: Approximate solutions of inverse problems for nonlinear space fractional\n  diffusion equations with randomly perturbed data Abstract: This paper is concerned with backward problem for nonlinear space fractional\ndiffusion with additive noise on the right-hand side and the final value. To\nregularize the instable solution, we develop some new regularized method for\nsolving the problem. In the case of constant coefficients, we use the\ntruncation methods. In the case of perturbed time dependent coefficients, we\napply a new quasi-reversibility method. We also show the convergence rate\nbetween the regularized solution and the sought solution under some a priori\nassumption on the sought solution. \n\n"}
{"id": "1611.02762", "contents": "Title: Generalized Cluster Trees and Singular Measures Abstract: In this paper, we study the $\\alpha$-cluster tree ($\\alpha$-tree) under both\nsingular and nonsingular measures. The $\\alpha$-tree uses probability contents\nwithin a level set to construct a cluster tree so that it is well-defined for\nsingular measures. We first derive the convergence rate for a density level set\naround critical points, which leads to the convergence rate for estimating an\n$\\alpha$-tree under nonsingular measures. For singular measures, we study how\nthe kernel density estimator (KDE) behaves and prove that the KDE is not\nuniformly consistent but pointwisely consistent after rescaling. We further\nprove that the estimated $\\alpha$-tree fails to converge in the $L_\\infty$\nmetric but is still consistent under the integrated distance. We also observe a\nnew type of critical points--the dimensional critical points (DCPs)--of a\nsingular measure. DCPs occur only at singular measures, and similar to the\nusual critical points, DCPs contribute to cluster tree topology as well.\nBuilding on the analysis of the KDE and DCPs, we prove the topological\nconsistency of an estimated $\\alpha$-tree. \n\n"}
{"id": "1611.03146", "contents": "Title: The Control of the False Discovery Rate in Fixed Sequence Multiple\n  Testing Abstract: Controlling the false discovery rate (FDR) is a powerful approach to multiple\ntesting. In many applications, the tested hypotheses have an inherent\nhierarchical structure. In this paper, we focus on the fixed sequence structure\nwhere the testing order of the hypotheses has been strictly specified in\nadvance. We are motivated to study such a structure, since it is the most basic\nof hierarchical structures, yet it is often seen in real applications such as\nstatistical process control and streaming data analysis. We first consider a\nconventional fixed sequence method that stops testing once an acceptance\noccurs, and develop such a method controlling the FDR under both arbitrary and\nnegative dependencies. The method under arbitrary dependency is shown to be\nunimprovable without losing control of the FDR and unlike existing FDR methods;\nit cannot be improved even by restricting to the usual positive regression\ndependence on subset (PRDS) condition. To account for any potential mistakes in\nthe ordering of the tests, we extend the conventional fixed sequence method to\none that allows more but a given number of acceptances. Simulation studies show\nthat the proposed procedures can be powerful alternatives to existing FDR\ncontrolling procedures. The proposed procedures are illustrated through a real\ndata set from a microarray experiment. \n\n"}
{"id": "1611.05201", "contents": "Title: Multiscale inference for multivariate deconvolution Abstract: In this paper we provide new methodology for inference of the geometric\nfeatures of a multivariate density in deconvolution. Our approach is based on\nmultiscale tests to detect significant directional derivatives of the unknown\ndensity at arbitrary points in arbitrary directions. The multiscale method is\nused to identify regions of monotonicity and to construct a general procedure\nfor the detection of modes of the multivariate density. Moreover, as an\nimportant application a significance test for the presence of a local maximum\nat a pre-specified point is proposed. The performance of the new methods is\ninvestigated from a theoretical point of view and the finite sample properties\nare illustrated by means of a small simulation study. \n\n"}
{"id": "1611.05240", "contents": "Title: Quantum Fields and Probability Abstract: I review some recent work where ideas and methods from Quantum Field Theory\nhave proved useful in probability and vice versa. The topics discussed include\nthe use of Renormalization Group theory in Stochastic Partial Differential\nEquations driven by space-time white noise and the use of the theory of\nGaussian Multiplicative Chaos in the study of two dimensional Liouville\nConformal Field theory. \n\n"}
{"id": "1611.05475", "contents": "Title: The Bayesian Formulation and Well-Posedness of Fractional Elliptic\n  Inverse Problems Abstract: We study the inverse problem of recovering the order and the diffusion\ncoefficient of an elliptic fractional partial differential equation from a\nfinite number of noisy observations of the solution. We work in a Bayesian\nframework and show conditions under which the posterior distribution is given\nby a change of measure from the prior. Moreover, we show well-posedness of the\ninverse problem, in the sense that small perturbations of the observed solution\nlead to small Hellinger perturbations of the associated posterior measures. We\nthus provide a mathematical foundation to the Bayesian learning of the order\n---and other inputs--- of fractional models. \n\n"}
{"id": "1611.05838", "contents": "Title: A smooth transition from Wishart to GOE Abstract: It is well known that an $n \\times n$ Wishart matrix with $d$ degrees of\nfreedom is close to the appropriately centered and scaled Gaussian Orthogonal\nEnsemble (GOE) if $d$ is large enough. Recent work of Bubeck, Ding, Eldan, and\nRacz, and independently Jiang and Li, shows that the transition happens when $d\n= \\Theta ( n^{3} )$. Here we consider this critical window and explicitly\ncompute the total variation distance between the Wishart and GOE matrices when\n$d / n^{3} \\to c \\in (0, \\infty)$. This shows, in particular, that the phase\ntransition from Wishart to GOE is smooth. \n\n"}
{"id": "1611.06218", "contents": "Title: Convex functions on dual Orlicz spaces Abstract: In the dual $L_{\\Phi^*}$ of a $\\Delta_2$-Orlicz space $L_\\Phi$, that we call\na dual Orlicz space, we show that a proper (resp. finite) convex function is\nlower semicontinuous (resp. continuous) for the Mackey topology\n$\\tau(L_{\\Phi^*},L_\\Phi)$ if and only if on each order interval\n$[-\\zeta,\\zeta]=\\{\\xi: -\\zeta\\leq \\xi\\leq\\zeta\\}$ ($\\zeta\\in L_{\\Phi^*}$), it\nis lower semicontinuous (resp. continuous) for the topology of convergence in\nprobability. For this purpose, we provide the following Koml\\'os type result:\nevery norm bounded sequence $(\\xi_n)_n$ in $L_{\\Phi^*}$ admits a sequence of\nforward convex combinations $\\bar\\xi_n\\in\\mathrm{conv}(\\xi_n,\\xi_{n+1},...)$\nsuch that $\\sup_n|\\bar\\xi_n|\\in L_{\\Phi^*}$ and $\\bar\\xi_n$ converges a.s. \n\n"}
{"id": "1611.08631", "contents": "Title: Change-point detection in panel data via double CUSUM statistic Abstract: In this paper, we consider the problem of (multiple) change-point detection\nin panel data. We propose the double CUSUM statistic which utilises the\ncross-sectional change-point structure by examining the cumulative sums of\nordered CUSUMs at each point. The efficiency of the proposed change-point test\nis studied, which is reflected on the rate at which the cross-sectional size of\na change is permitted to converge to zero while it is still detectable. Also,\nthe consistency of the proposed change-point detection procedure based on the\nbinary segmentation algorithm, is established in terms of both the total number\nand locations (in time) of the estimated change-points. Motivated by the\nrepresentation properties of the Generalised Dynamic Factor Model, we propose a\nbootstrap procedure for test criterion selection, which accounts for both\ncross-sectional and within-series correlations in high-dimensional data. The\nempirical performance of the double CUSUM statistics, equipped with the\nproposed bootstrap scheme, is investigated in a comparative simulation study\nwith the state-of-the-art. As an application, we analyse the log returns of S&P\n100 component stock prices over a period of one year. \n\n"}
{"id": "1611.09476", "contents": "Title: Gaussian beta ensembles at high temperature: eigenvalue fluctuations and\n  bulk statistics Abstract: We study the limiting behavior of Gaussian beta ensembles in the regime where\n$\\beta n = const$ as $n \\to \\infty$. The results are (1) Gaussian fluctuations\nfor linear statistics of the eigenvalues, and (2) Poisson convergence of the\nbulk statistics. (2) is an alternative proof of the result by\nF.~Benaych-Georges and S.~P\\'ech\\'e (2015) with the explicit form of the\nintensity measure. \n\n"}
{"id": "1611.09790", "contents": "Title: Paired-move multiple-try stochastic search for Bayesian variable\n  selection Abstract: Variable selection is a key issue when analyzing high-dimensional data. The\nexplosion of data with large sample sizes and dimensionality brings new\nchallenges to this problem in both inference accuracy and computational\ncomplexity. To alleviate these problems, we propose a new scalable Markov chain\nMonte Carlo (MCMC) sampling algorithm for \"large $p$ small $n$\" scenarios by\ngeneralizing multiple-try Metropolis to discrete model spaces and further\nincorporating neighborhood-based stochastic search. The proof of reversibility\nof the proposed MCMC algorithm is provided. Extensive simulation studies are\nperformed to examine the efficiency of the new algorithm compared with existing\nmethods. A real data example is provided to illustrate the prediction\nperformances of the new algorithm. \n\n"}
{"id": "1611.09877", "contents": "Title: Discontinuity of the phase transition for the planar random-cluster and\n  Potts models with $q>4$ Abstract: We prove that the $q$-state Potts model and the random-cluster model with\ncluster weight $q>4$ undergo a discontinuous phase transition on the square\nlattice. More precisely, we show\n  - Existence of multiple infinite-volume measures for the critical Potts and\nrandom-cluster models,\n  - Ordering for the measures with monochromatic (resp. wired) boundary\nconditions for the critical Potts model (resp. random-cluster model), and\n  - Exponential decay of correlations for the measure with free boundary\nconditions for both the critical Potts and random-cluster models.\n  The proof is based on a rigorous computation of the Perron-Frobenius\neigenvalues of the diagonal blocks of the transfer matrix of the six-vertex\nmodel, whose ratios are then related to the correlation length of the\nrandom-cluster model.\n  As a byproduct, we rigorously compute the correlation lengths of the critical\nrandom-cluster and Potts models, and show that they behave as\n$\\exp(\\pi^2/\\sqrt{q-4})$ as $q$ tends to 4. \n\n"}
{"id": "1611.09981", "contents": "Title: Decoding from Pooled Data: Sharp Information-Theoretic Bounds Abstract: Consider a population consisting of n individuals, each of whom has one of d\ntypes (e.g. their blood type, in which case d=4). We are allowed to query this\ndatabase by specifying a subset of the population, and in response we observe a\nnoiseless histogram (a d-dimensional vector of counts) of types of the pooled\nindividuals. This measurement model arises in practical situations such as\npooling of genetic data and may also be motivated by privacy considerations. We\nare interested in the number of queries one needs to unambiguously determine\nthe type of each individual. In this paper, we study this information-theoretic\nquestion under the random, dense setting where in each query, a random subset\nof individuals of size proportional to n is chosen. This makes the problem a\nparticular example of a random constraint satisfaction problem (CSP) with a\n\"planted\" solution. We establish almost matching upper and lower bounds on the\nminimum number of queries m such that there is no solution other than the\nplanted one with probability tending to 1 as n tends to infinity. Our proof\nrelies on the computation of the exact \"annealed free energy\" of this model in\nthe thermodynamic limit, which corresponds to the exponential rate of decay of\nthe expected number of solution to this planted CSP. As a by-product of the\nanalysis, we show an identity of independent interest relating the Gaussian\nintegral over the space of Eulerian flows of a graph to its spanning tree\npolynomial. \n\n"}
{"id": "1612.00877", "contents": "Title: Bayesian sparse multiple regression for simultaneous rank reduction and\n  variable selection Abstract: We develop a Bayesian methodology aimed at simultaneously estimating low-rank\nand row-sparse matrices in a high-dimensional multiple-response linear\nregression model. We consider a carefully devised shrinkage prior on the matrix\nof regression coefficients which obviates the need to specify a prior on the\nrank, and shrinks the regression matrix towards low-rank and row-sparse\nstructures. We provide theoretical support to the proposed methodology by\nproving minimax optimality of the posterior mean under the prediction risk in\nultra-high dimensional settings where the number of predictors can grow\nsub-exponentially relative to the sample size. A one-step post-processing\nscheme induced by group lasso penalties on the rows of the estimated\ncoefficient matrix is proposed for variable selection, with default choices of\ntuning parameters. We additionally provide an estimate of the rank using a\nnovel optimization function achieving dimension reduction in the covariate\nspace. We exhibit the performance of the proposed methodology in an extensive\nsimulation study and a real data example. \n\n"}
{"id": "1612.01274", "contents": "Title: Haldane relation for interacting dimers Abstract: We consider a model of weakly interacting, close-packed, dimers on the\ntwo-dimensional square lattice. In a previous paper, we computed both the\nmultipoint dimer correlations, which display non-trivial critical exponents,\ncontinuously varying with the interaction strength; and the height\nfluctuations, which, after proper coarse graining and rescaling, converge to\nthe massless Gaussian field with a suitable interaction-dependent pre-factor\n(`amplitude'). In this paper, we prove the identity between the critical\nexponent of the two-point dimer correlation and the amplitude of this massless\nGaussian field. This identity is the restatement, in the context of interacting\ndimers, of one of the Haldane universality relations, part of his Luttinger\nliquid conjecture, originally formulated in the context of one-dimensional\ninteracting Fermi systems. Its validity is a strong confirmation of the\neffective massless Gaussian field description of the interacting dimer model,\nwhich was guessed on the basis of formal bosonization arguments. We also\nconjecture that a certain discrete curve defined at the lattice level via the\nTemperley bijection converges in the scaling limit to an SLE$_\\kappa$ process,\nwith $\\kappa$ depending non-trivially on the interaction and related in a\nsimple way to the amplitude of the limiting Gaussian field. \n\n"}
{"id": "1612.01916", "contents": "Title: Large gap asymptotics at the hard edge for product random matrices and\n  Muttalib-Borodin ensembles Abstract: We study the distribution of the smallest eigenvalue for certain classes of\npositive-definite Hermitian random matrices, in the limit where the size of the\nmatrices becomes large. Their limit distributions can be expressed as Fredholm\ndeterminants of integral operators associated to kernels built out of Meijer\n$G$-functions or Wright's generalized Bessel functions. They generalize in a\nnatural way the hard edge Bessel kernel Fredholm determinant. We express the\nlogarithmic derivatives of the Fredholm determinants identically in terms of a\n$2\\times 2$ Riemann-Hilbert problem, and use this representation to obtain the\nso-called large gap asymptotics. \n\n"}
{"id": "1612.02798", "contents": "Title: Octonionic two-qubit separability probability conjectures Abstract: We study, further, a conjectured formula for generalized two-qubit\nHilbert-Schmidt separability probabilities that has recently been proven by\nLovas and Andai (https://arxiv.org/pdf/1610.01410.pdf) for its real (two-rebit)\nasserted value ($\\frac{29}{64}$), and that has also been very strongly\nsupported numerically for its complex ($\\frac{8}{33}$), and quaternionic\n($\\frac{26}{323}$) counterparts. Now, we seek to test the presumptive\noctonionic value of $\\frac{44482}{4091349} \\approx 0.0108722$. We are somewhat\nencouraged by certain numerical computations, indicating that this\n(51-dimensional) instance of the conjecture might be fulfilled by setting a\ncertain determinantal-power parameter $a$, introduced by Forrester\n(https://arxiv.org/pdf/1610.08081.pdf), to 0 (or possibly near to 0).\nHilbert-Schmidt measure being the case $k=0$ of random induced measure, for\n$k=1$, the corresponding octonionic separability probability conjecture is\n$\\frac{7612846}{293213345} \\approx 0.0259635$, while for $k=2$, it is\n$\\frac{4893392}{95041567} \\approx 0.0514869, \\ldots$. The relation between the\nparameters $a$ and $k$ is explored. \n\n"}
{"id": "1612.03484", "contents": "Title: Interacting particle systems at the edge of multilevel Jack processes Abstract: We consider a multilevel continuous time Markov chain $X(s;N) = (X_i^j(s;N):\n1 \\leq i \\leq j \\leq N)$, which is defined by means of Jack symmetric functions\nand forms a certain discretization of the multilevel Dyson Brownian motion. The\nprocess $X(s;N)$ describes the evolution of a discrete interlacing particle\nsystem with push-block interactions between the particles, which preserve the\ninterlacing property. We study the joint asymptotic separation of the particles\nat the right edge of the ensemble as the number of levels and time tend to\ninfinity and show that the limit is described by a certain zero range process\nwith local interactions. \n\n"}
{"id": "1612.03714", "contents": "Title: Characterizations of the upper bound of Bakry-Emery curvature Abstract: In this paper, we will present some characterizations for the upper bound of\nthe Bakry-Emery curvature on a Riemannian manifold by using functional\ninequalities on path space. Moreover, some characterizations for general lower\nand upper bounds of Ricci curvature are also given, which extends the recent\nresults derived by Naber \\cite{N} and Wang-Wu\\cite{WW}. \n\n"}
{"id": "1612.04467", "contents": "Title: On Procedures Controlling the FDR for Testing Hierarchically Ordered\n  Hypotheses Abstract: Complex large-scale studies, such as those related to microarray data and\nfMRI studies, often involve testing multiple hierarchically ordered hypotheses.\nHowever, most existing false discovery rate (FDR) controlling procedures do not\nexploit the inherent hierarchical structure among the tested hypotheses. In\nthis paper, we first present a generalized stepwise procedure which generalizes\nthe usual stepwise procedure to the case where each hypothesis is tested with a\ndifferent set of critical constants. This procedure is helpful in creating a\ngeneral framework under which our hierarchical testing procedures are\ndeveloped. Then, we present several hierarchical testing procedures which\ncontrol the FDR under various forms of dependence such as positive dependence\nand block dependence. Our simulation studies show that these proposed methods\ncan be more powerful in some situations than alternative methods such as\nYekutieli's hierarchical testing procedure (Yekutieli, \\emph{JASA} \\textbf{103}\n(2008) 309-316). Finally, we apply our proposed procedures to a real data set\ninvolving abundances of microbes in different ecological environments. \n\n"}
{"id": "1612.04472", "contents": "Title: Matrix Dirichlet processes Abstract: Matrix Dirichlet processes, in reference to their reversible measure, appear\nin a natural way in many different models in probability. Applying the language\nof diffusion operators and the method of boundary equations, we describe\nDirichlet processes on the simplex and provide two models of matrix Dirichlet\nprocesses, which can be realized by various projections, through the Brownian\nmotion on the special unitary group, the polar decomposition of complex\nmatrices and also through Wishart processes. \n\n"}
{"id": "1612.08618", "contents": "Title: Scaling limits of random bipartite planar maps with a prescribed degree\n  sequence Abstract: We study the asymptotic behaviour of uniform random maps with a prescribed\nface-degree sequence, in the bipartite case, as the number of faces tends to\ninfinity. Under mild assumptions, we show that, properly rescaled, such maps\nconverge in distribution towards the Brownian map in the Gromov-Hausdorff\nsense. This result encompasses a previous one of Le Gall for uniform random\n$q$-angulations where $q$ is an even integer. It applies also to random maps\nsampled from a Boltzmann distribution, under a second moment assumption only,\nconditioned to be large in either of the sense of the number of edges,\nvertices, or faces. The proof relies on the convergence of so-called \"discrete\nsnakes\" obtained by adding spatial positions to the nodes of uniform random\nplane trees with a prescribed child sequence recently studied by Broutin &\nMarckert. This paper can alternatively be seen as a contribution to the study\nof the geometry of such trees. \n\n"}
{"id": "1612.09126", "contents": "Title: Doubly uniform complete law of large numbers for independent point\n  processes Abstract: We prove a law of large numbers in terms of complete convergence of\nindependent random variables taking values in increments of monotone functions,\nwith convergence uniform both in the initial and the final time. The result\nholds also for the random variables taking values in functions of $2$\nparameters which share similar monotonicity properties as the increments of\nmonotone functions. The assumptions for the main result are the H\\\"older\ncontinuity on the expectations as well as moment conditions, while the sample\nfunctions may contain jumps. In particular, we can apply the results to point\nprocesses (counting processes) which lack Markov or martingale type properties. \n\n"}
{"id": "1701.00223", "contents": "Title: Convergence rates of theta-method for neutral SDDEs under non-globally\n  Lipschitz continuous coefficients Abstract: This paper is concerned with strong convergence and almost sure convergence\nfor neutral stochastic differential delay equations under non-globally\nLipschitz continuous coefficients. Convergence rates of $\\theta$-EM schemes are\ngiven for these equations driven by Brownian motion and pure jumps\nrespectively, where the drift terms satisfy locally one-sided Lipschitz\nconditions, and diffusion coefficients obey locally Lipschitz conditions, and\nthe corresponding coefficients are highly nonlinear with respect to the delay\nterms. \n\n"}
{"id": "1701.00770", "contents": "Title: Estimating functional time series by moving average model fitting Abstract: Functional time series have become an integral part of both functional data\nand time series analysis. Important contributions to methodology, theory and\napplication for the prediction of future trajectories and the estimation of\nfunctional time series parameters have been made in the recent past. This paper\ncontinues this line of research by proposing a first principled approach to\nestimate invertible functional time series by fitting functional moving average\nprocesses. The idea is to estimate the coefficient operators in a functional\nlinear filter. To do this a functional Innovations Algorithm is utilized as a\nstarting point to estimate the corresponding moving average operators via\nsuitable projections into principal directions. In order to establish\nconsistency of the proposed estimators, asymptotic theory is developed for\nincreasing subspaces of these principal directions. For practical purposes,\nseveral strategies to select the number of principal directions to include in\nthe estimation procedure as well as the choice of order of the functional\nmoving average process are discussed. Their empirical performance is evaluated\nthrough simulations and an application to vehicle traffic data. \n\n"}
{"id": "1701.01485", "contents": "Title: Non interactive simulation of correlated distributions is decidable Abstract: A basic problem in information theory is the following: Let $\\mathbf{P} =\n(\\mathbf{X}, \\mathbf{Y})$ be an arbitrary distribution where the marginals\n$\\mathbf{X}$ and $\\mathbf{Y}$ are (potentially) correlated. Let Alice and Bob\nbe two players where Alice gets samples $\\{x_i\\}_{i \\ge 1}$ and Bob gets\nsamples $\\{y_i\\}_{i \\ge 1}$ and for all $i$, $(x_i, y_i) \\sim \\mathbf{P}$. What\njoint distributions $\\mathbf{Q}$ can be simulated by Alice and Bob without any\ninteraction?\n  Classical works in information theory by G{\\'a}cs-K{\\\"o}rner and Wyner answer\nthis question when at least one of $\\mathbf{P}$ or $\\mathbf{Q}$ is the\ndistribution on $\\{0,1\\} \\times \\{0,1\\}$ where each marginal is unbiased and\nidentical. However, other than this special case, the answer to this question\nis understood in very few cases. Recently, Ghazi, Kamath and Sudan showed that\nthis problem is decidable for $\\mathbf{Q}$ supported on $\\{0,1\\} \\times\n\\{0,1\\}$. We extend their result to $\\mathbf{Q}$ supported on any finite\nalphabet.\n  We rely on recent results in Gaussian geometry (by the authors) as well as a\nnew \\emph{smoothing argument} inspired by the method of \\emph{boosting} from\nlearning theory and potential function arguments from complexity theory and\nadditive combinatorics. \n\n"}
{"id": "1701.03120", "contents": "Title: The fourth moment theorem on the Poisson space Abstract: We prove an exact fourth moment bound for the normal approximation of random\nvariables belonging to the Wiener chaos of a general Poisson random measure.\nSuch a result -- that has been elusive for several years -- shows that the\nso-called `fourth moment phenomenon', first discovered by Nualart and Peccati\n(2005) in the context of Gaussian fields, also systematically emerges in a\nPoisson framework. Our main findings are based on Stein's method, Malliavin\ncalculus and Mecke-type formulae, as well as on a methodological breakthrough,\nconsisting in the use of carr\\'e-du-champ operators on the Poisson space for\ncontrolling residual terms associated with add-one cost operators. Our approach\ncan be regarded as a successful application of Markov generator techniques to\nprobabilistic approximations in a non-diffusive framework: as such, it\nrepresents a significant extension of the seminal contributions by Ledoux\n(2012) and Azmoodeh, Campese and Poly (2014). To demonstrate the flexibility of\nour results, we also provide some novel bounds for the Gamma approximation of\nnon-linear functionals of a Poisson measure. \n\n"}
{"id": "1701.03513", "contents": "Title: Nonparametric imputation by data depth Abstract: We present single imputation method for missing values which borrows the idea\nof data depth---a measure of centrality defined for an arbitrary point of a\nspace with respect to a probability distribution or data cloud. This consists\nin iterative maximization of the depth of each observation with missing values,\nand can be employed with any properly defined statistical depth function. For\neach single iteration, imputation reverts to optimization of quadratic, linear,\nor quasiconcave functions that are solved analytically by linear programming or\nthe Nelder-Mead method. As it accounts for the underlying data topology, the\nprocedure is distribution free, allows imputation close to the data geometry,\ncan make prediction in situations where local imputation (k-nearest neighbors,\nrandom forest) cannot, and has attractive robustness and asymptotic properties\nunder elliptical symmetry. It is shown that a special case---when using the\nMahalanobis depth---has direct connection to well-known methods for the\nmultivariate normal model, such as iterated regression and regularized PCA. The\nmethodology is extended to multiple imputation for data stemming from an\nelliptically symmetric distribution. Simulation and real data studies show good\nresults compared with existing popular alternatives. The method has been\nimplemented as an R-package. Supplementary materials for the article are\navailable online. \n\n"}
{"id": "1701.03772", "contents": "Title: Additive Partially Linear Models for Massive Heterogeneous Data Abstract: We consider an additive partially linear framework for modelling massive\nheterogeneous data. The major goal is to extract multiple common features\nsimultaneously across all sub-populations while exploring heterogeneity of each\nsub-population. We propose an aggregation type of estimators for the\ncommonality parameters that possess the asymptotic optimal bounds and the\nasymptotic distributions as if there were no heterogeneity. This oracle result\nholds when the number of sub-populations does not grow too fast and the tuning\nparameters are selected carefully. A plug-in estimator for the heterogeneity\nparameter is further constructed, and shown to possess the asymptotic\ndistribution as if the commonality information were available. Furthermore, we\ndevelop a heterogeneity test for the linear components and a homogeneity test\nfor the non-linear components accordingly. The performance of the proposed\nmethods is evaluated via simulation studies and an application to the Medicare\nProvider Utilization and Payment data. \n\n"}
{"id": "1701.03860", "contents": "Title: Infinite-dimensional Stochastic Differential Equations with Symmetry Abstract: We review recent progress in the study of infinite-dimensional stochastic\ndifferential equations with symmetry. This paper contains examples arising from\nrandom matrix theory. \n\n"}
{"id": "1701.04735", "contents": "Title: Asymptotic Theory and Statistical Decomposability gap Estimation for\n  Takayama's Index Abstract: In the spirit of recent asymptotic works on the General Poverty Index (GPI)\nin the field of Welfare Analysis, the asymptotic representation of the\nnon-decomposable Takayama's index, which has failed to be incorporated in the\nunified GPI approach, is addressed and established here. This representation\nallows also to extend to it, recent results of statistical decomposability gaps\nestimations. The theoretical results are applied to real databases. The\nconclusions of the undertaken applications recommend to use Takayama's index as\na practically decomposable one, in virtue of the low decomposability gaps with\nrespect to the large values of the index. \n\n"}
{"id": "1701.05091", "contents": "Title: On the tail behavior of a class of multivariate conditionally\n  heteroskedastic processes Abstract: Conditions for geometric ergodicity of multivariate autoregressive\nconditional heteroskedasticity (ARCH) processes, with the so-called BEKK (Baba,\nEngle, Kraft, and Kroner) parametrization, are considered. We show for a class\nof BEKK-ARCH processes that the invariant distribution is regularly varying. In\norder to account for the possibility of different tail indices of the\nmarginals, we consider the notion of vector scaling regular variation, in the\nspirit of Perfekt (1997, Advances in Applied Probability, 29, pp. 138-164). The\ncharacterization of the tail behavior of the processes is used for deriving the\nasymptotic properties of the sample covariance matrices. \n\n"}
{"id": "1701.07086", "contents": "Title: The Minimum Regularized Covariance Determinant estimator Abstract: The Minimum Covariance Determinant (MCD) approach robustly estimates the\nlocation and scatter matrix using the subset of given size with lowest sample\ncovariance determinant. Its main drawback is that it cannot be applied when the\ndimension exceeds the subset size. We propose the Minimum Regularized\nCovariance Determinant (MRCD) approach, which differs from the MCD in that the\nscatter matrix is a convex combination of a target matrix and the sample\ncovariance matrix of the subset. A data-driven procedure sets the weight of the\ntarget matrix, so that the regularization is only used when needed. The MRCD\nestimator is defined in any dimension, is well-conditioned by construction and\npreserves the good robustness properties of the MCD. We prove that so-called\nconcentration steps can be performed to reduce the MRCD objective function, and\nwe exploit this fact to construct a fast algorithm. We verify the accuracy and\nrobustness of the MRCD estimator in a simulation study and illustrate its\npractical use for outlier detection and regression analysis on real-life\nhigh-dimensional data sets in chemistry and criminology. \n\n"}
{"id": "1701.09185", "contents": "Title: Low-temperature behavior of the multicomponent Widom-Rowlison model on\n  finite square lattices Abstract: We consider the multicomponent Widom-Rowlison with Metropolis dynamics, which\ndescribes the evolution of a particle system where $M$ different types of\nparticles interact subject to certain hard-core constraints. Focusing on the\nscenario where the spatial structure is modeled by finite square lattices, we\nstudy the asymptotic behavior of this interacting particle system in the\nlow-temperature regime, analyzing the tunneling times between its $M$\nmaximum-occupancy configurations, and the mixing time of the corresponding\nMarkov chain. In particular, we develop a novel combinatorial method that,\nexploiting geometrical properties of the Widom-Rowlinson configurations on\nfinite square lattices, leads to the identification of the timescale at which\ntransitions between maximum-occupancy configurations occur and shows how this\ndepends on the chosen boundary conditions and the square lattice dimensions. \n\n"}
{"id": "1702.00501", "contents": "Title: Adaptive gPCA: A method for structured dimensionality reduction Abstract: When working with large biological data sets, exploratory analysis is an\nimportant first step for understanding the latent structure and for generating\nhypotheses to be tested in subsequent analyses. However, when the number of\nvariables is large compared to the number of samples, standard methods such as\nprincipal components analysis give results which are unstable and difficult to\ninterpret.\n  To mitigate these problems, we have developed a method which allows the\nanalyst to incorporate side information about the relationships between the\nvariables in a way that encourages similar variables to have similar loadings\non the principal axes. This leads to a low-dimensional representation of the\nsamples which both describes the latent structure and which has axes which are\ninterpretable in terms of groups of closely related variables.\n  The method is derived by putting a prior encoding the relationships between\nthe variables on the data and following through the analysis on the posterior\ndistributions of the samples. We show that our method does well at\nreconstructing true latent structure in simulated data and we also demonstrate\nthe method on a dataset investigating the effects of antibiotics on the\ncomposition of bacteria in the human gut. \n\n"}
{"id": "1702.00525", "contents": "Title: A powerful approach to the study of moderate effect modification in\n  observational studies Abstract: Effect modification means the magnitude or stability of a treatment effect\nvaries as a function of an observed covariate. Generally, larger and more\nstable treatment effects are insensitive to larger biases from unmeasured\ncovariates, so a causal conclusion may be considerably firmer if this pattern\nis noted if it occurs. We propose a new strategy, called the submax-method,\nthat combines exploratory and confirmatory efforts to determine whether there\nis stronger evidence of causality - that is, greater insensitivity to\nunmeasured confounding - in some subgroups of individuals. It uses the joint\ndistribution of test statistics that split the data in various ways based on\ncertain observed covariates. For $L$ binary covariates, the method splits the\npopulation $L$ times into two subpopulations, perhaps first men and women,\nperhaps then smokers and nonsmokers, computing a test statistic from each\nsubpopulation, and appends the test statistic for the whole population, making\n$2L+1$ test statistics in total. Although $L$ binary covariates define $2^{L}$\ninteraction groups, only $2L+1$ tests are performed, and at least $L+1$ of\nthese tests use at least half of the data. The submax-method achieves the\nhighest design sensitivity and the highest Bahadur efficiency of its component\ntests. Moreover, the form of the test is sufficiently tractable that its large\nsample power may be studied analytically. The simulation suggests that the\nsubmax method exhibits superior performance, in comparison with an approach\nusing CART, when there is effect modification of moderate size. Using data from\nthe NHANES I Epidemiologic Follow-Up Survey, an observational study of the\neffects of physical activity on survival is used to illustrate the method. The\nmethod is implemented in the $\\texttt{R}$ package $\\texttt{submax}$ which\ncontains the NHANES example. \n\n"}
{"id": "1702.01906", "contents": "Title: Affiliation networks with an increasing degree sequence Abstract: Affiliation network is one kind of two-mode social network with two different\nsets of nodes (namely, a set of actors and a set of social events) and edges\nrepresenting the affiliation of the actors with the social events. Although a\nnumber of statistical models are proposed to analyze affiliation networks, the\nasymptotic behaviors of the estimator are still unknown or have not been\nproperly explored. In this paper, we study an affiliation model with the degree\nsequence as the exclusively natural sufficient statistic in the exponential\nfamily distributions. We establish the uniform consistency and asymptotic\nnormality of the maximum likelihood estimator when the numbers of actors and\nevents both go to infinity. Simulation studies and a real data example\ndemonstrate our theoretical results. \n\n"}
{"id": "1702.04031", "contents": "Title: Maximum likelihood estimation in Gaussian models under total positivity Abstract: We analyze the problem of maximum likelihood estimation for Gaussian\ndistributions that are multivariate totally positive of order two (MTP2). By\nexploiting connections to phylogenetics and single-linkage clustering, we give\na simple proof that the maximum likelihood estimator (MLE) for such\ndistributions exists based on at least 2 observations, irrespective of the\nunderlying dimension. Slawski and Hein, who first proved this result, also\nprovided empirical evidence showing that the MTP2 constraint serves as an\nimplicit regularizer and leads to sparsity in the estimated inverse covariance\nmatrix, determining what we name the ML graph. We show that we can find an\nupper bound for the ML graph by adding edges corresponding to correlations in\nexcess of those explained by the maximum weight spanning forest of the\ncorrelation matrix. Moreover, we provide globally convergent coordinate descent\nalgorithms for calculating the MLE under the MTP2 constraint which are\nstructurally similar to iterative proportional scaling. We conclude the paper\nwith a discussion of signed MTP2 distributions. \n\n"}
{"id": "1702.04032", "contents": "Title: A generalization of Schur functions: applications to Nevanlinna\n  functions, orthogonal polynomials, random walks and unitary and open quantum\n  walks Abstract: Recent work on recurrence in quantum walks has provided a representation of\nSchur functions in terms of unitary operators. We propose a generalization of\nSchur functions by extending this operator representation to arbitrary\noperators on Banach spaces. Such generalized Schur functions meet the formal\nstructure of first return generating functions, thus we call them FR-functions.\nWe derive general properties of FR-functions, among them a generalization of\nthe renewal equation already known for random and quantum walks, as well as\nsplitting properties which extend useful factorizations of Schur functions.\n  When specialized to self-adjoint operators, FR-functions become Nevanlinna\nfunctions. This leads to new results on Nevanlinna functions: decomposition\nrules which are the analogue of useful factorizations of Schur functions, a\nsimple Nevanlinna version of the Schur algorithm and new operator and integral\nrepresentations of Nevanlinna functions which, in contrast to standard ones,\nare exact analogues of those already known for Schur functions, giving\nsimilarly a one-to-one correspondence between Nevanlinna functions and measures\non the real line.\n  The paper is completed with several applications of FR-functions to\northogonal polynomials and random and quantum walks which illustrate their wide\ninterest: an analogue for orthogonal polynomials on the real line of the\nKhrushchev formula for orthogonal polynomials on the unit circle, and the use\nof FR-functions to study recurrence in random walks, quantum walks and open\nquantum walks. These applications provide numerous explicit examples of\nFR-functions and their splittings and show that these new tools, despite being\nextensions of very classical ones, play an important role in the study of\nphysical problems of a highly topical nature. \n\n"}
{"id": "1702.04095", "contents": "Title: Inverse local time of one-dimensional diffusions and its comparison\n  theorem Abstract: In this paper, we study inverse local time at 0 of one-dimensional reflected\ndiffusions on $[0, \\infty)$, and establish a comparison principle for inverse\nlocal times. Applications to Green function estimates for non-local operators\nare given. \n\n"}
{"id": "1702.05472", "contents": "Title: Threshold Constraints with Guarantees for Parity Objectives in Markov\n  Decision Processes Abstract: The beyond worst-case synthesis problem was introduced recently by Bruy\\`ere\net al. [BFRR14]: it aims at building system controllers that provide strict\nworst-case performance guarantees against an antagonistic environment while\nensuring higher expected performance against a stochastic model of the\nenvironment. Our work extends the framework of [BFRR14] and follow-up papers,\nwhich focused on quantitative objectives, by addressing the case of\n$\\omega$-regular conditions encoded as parity objectives, a natural way to\nrepresent functional requirements of systems.\n  We build strategies that satisfy a main parity objective on all plays, while\nensuring a secondary one with sufficient probability. This setting raises new\nchallenges in comparison to quantitative objectives, as one cannot easily mix\ndifferent strategies without endangering the functional properties of the\nsystem. We establish that, for all variants of this problem, deciding the\nexistence of a strategy lies in ${\\sf NP} \\cap {\\sf coNP}$, the same complexity\nclass as classical parity games. Hence, our framework provides additional\nmodeling power while staying in the same complexity class.\n  [BFRR14] V\\'eronique Bruy\\`ere, Emmanuel Filiot, Mickael Randour, and\nJean-Fran\\c{c}ois Raskin. Meet your expectations with guarantees: Beyond\nworst-case synthesis in quantitative games. In Ernst W. Mayr and Natacha\nPortier, editors, 31st International Symposium on Theoretical Aspects of\nComputer Science, STACS 2014, March 5-8, 2014, Lyon, France, volume 25 of\nLIPIcs, pages 199-213. Schloss Dagstuhl - Leibniz - Zentrum fuer Informatik,\n2014. \n\n"}
{"id": "1702.06396", "contents": "Title: On edge exchangeable random graphs Abstract: We study a recent model for edge exchangeable random graphs introduced by\nCrane and Dempsey; in particular we study asymptotic properties of the random\nsimple graph obtained by merging multiple edges. We study a number of examples,\nand show that the model can produce dense, sparse and extremely sparse random\ngraphs. One example yields a power-law degree distribution. We give some\nexamples where the random graph is dense and converges a.s. in the sense of\ngraph limit theory, but also an example where a.s. every graph limit is the\nlimit of some subsequence. Another example is sparse and yields convergence to\na non-integrable generalized graphon defined on $(0,\\infty)$. \n\n"}
{"id": "1702.07283", "contents": "Title: Non-penalized variable selection in high-dimensional linear model\n  settings via generalized fiducial inference Abstract: Standard penalized methods of variable selection and parameter estimation\nrely on the magnitude of coefficient estimates to decide which variables to\ninclude in the final model. However, coefficient estimates are unreliable when\nthe design matrix is collinear. To overcome this challenge an entirely new\nperspective on variable selection is presented within a generalized fiducial\ninference framework. This new procedure is able to effectively account for\nlinear dependencies among subsets of covariates in a high-dimensional setting\nwhere $p$ can grow almost exponentially in $n$, as well as in the classical\nsetting where $p \\le n$. It is shown that the procedure very naturally assigns\nsmall probabilities to subsets of covariates which include redundancies by way\nof explicit $L_{0}$ minimization. Furthermore, with a typical sparsity\nassumption, it is shown that the proposed method is consistent in the sense\nthat the probability of the true sparse subset of covariates converges in\nprobability to 1 as $n \\to \\infty$, or as $n \\to \\infty$ and $p \\to \\infty$.\nVery reasonable conditions are needed, and little restriction is placed on the\nclass of possible subsets of covariates to achieve this consistency result. \n\n"}
{"id": "1702.07304", "contents": "Title: Conflict diagnostics for evidence synthesis in a multiple testing\n  framework Abstract: Evidence synthesis models that combine multiple datasets of varying design,\nto estimate quantities that cannot be directly observed, require the\nformulation of complex probabilistic models that can be expressed as graphical\nmodels. An assessment of whether the different datasets synthesised contribute\ninformation that is consistent with each other, and in a Bayesian context, with\nthe prior distribution, is a crucial component of the model criticism process.\nHowever, a systematic assessment of conflict suffers from the multiple testing\nproblem, through testing for conflict at multiple locations in a model. We\ndemonstrate the systematic use of conflict diagnostics, while accounting for\nthe multiple hypothesis tests of no conflict at each location in the graphical\nmodel. The method is illustrated by a network meta-analysis to estimate\ntreatment effects in smoking cessation programs and an evidence synthesis to\nestimate HIV prevalence in Poland. \n\n"}
{"id": "1702.08797", "contents": "Title: A Fused Gaussian Process Model for Very Large Spatial Data Abstract: With the development of new remote sensing technology, large or even massive\nspatial datasets covering the globe become available. Statistical analysis of\nsuch data is challenging. This article proposes a semiparametric approach to\nmodel large or massive spatial datasets. In particular, a Gaussian process with\nadditive components is proposed, with its covariance structure consisting of\ntwo components: one component is flexible without assuming a specific\nparametric covariance function but is able to achieve dimension reduction; the\nother is parametric and simultaneously induces sparsity. The inference\nalgorithm for parameter estimation and spatial prediction is devised. The\nresulting spatial prediction methodology that we call fused Gaussian process\n(FGP), is applied to simulated data and a massive satellite dataset. The\nresults demonstrate the computational and inferential benefits of FGP over\ncompeting methods and show that FGP is robust against model misspecification\nand captures spatial nonstationarity. The supplemental materials are available\nonline. \n\n"}
{"id": "1702.08846", "contents": "Title: Reduced Modeling of Unknown Trajectories Abstract: This paper deals with model order reduction of parametrical dynamical\nsystems. We consider the specific setup where the distribution of the system's\ntrajectories is unknown but the following two sources of information are\navailable: \\textit{(i)} some \"rough\" prior knowledge on the system's\nrealisations; \\textit{(ii)} a set of \"incomplete\" observations of the system's\ntrajectories. We propose a Bayesian methodological framework to build\nreduced-order models (ROMs) by exploiting these two sources of information. We\nemphasise that complementing the prior knowledge with the collected data\nprovably enhances the knowledge of the distribution of the system's\ntrajectories. We then propose an implementation of the proposed methodology\nbased on Monte-Carlo methods. In this context, we show that standard ROM\nlearning techniques, such e.g. Proper Orthogonal Decomposition or Dynamic Mode\nDecomposition, can be revisited and recast within the probabilistic framework\nconsidered in this paper.~We illustrate the performance of the proposed\napproach by numerical results obtained for a standard geophysical model. \n\n"}
{"id": "1703.00682", "contents": "Title: The Rohde--Schramm theorem, via the Gaussian free field Abstract: The Rohde--Schramm theorem states that Schramm--Loewner Evolution with\nparameter $\\kappa$ (or SLE$_\\kappa$ for short) exists as a random curve, almost\nsurely, if $\\kappa \\neq 8$. Here we give a new and concise proof of the result,\nbased on the Liouville quantum gravity coupling (or reverse coupling) with a\nGaussian free field. This transforms the problem of estimating the derivative\nof the Loewner flow into estimating certain correlated Gaussian free fields.\nWhile the correlation between these fields is not easy to understand, a\nsurprisingly simple argument allows us to recover a derivative exponent first\nobtained by Rohde and Schramm, subsequently shown to be optimal by Lawler and\nViklund, which then implies the Rohde--Schramm theorem. \n\n"}
{"id": "1703.00947", "contents": "Title: Estimation of parameter sensitivities for stochastic reaction networks\n  using tau-leap simulations Abstract: We consider the important problem of estimating parameter sensitivities for\nstochastic models of reaction networks that describe the dynamics as a\ncontinuous-time Markov process over a discrete lattice. These sensitivity\nvalues are useful for understanding network properties, validating their design\nand identifying the pivotal model parameters. Many methods for sensitivity\nestimation have been developed, but their computational feasibility suffers\nfrom the critical bottleneck of requiring time-consuming Monte Carlo\nsimulations of the exact reaction dynamics. To circumvent this problem one\nneeds to devise methods that speed up the computations while suffering\nacceptable and quantifiable loss of accuracy. We develop such a method by first\nderiving a novel integral representation of parameter sensitivity and then\ndemonstrating that this integral may be approximated by any convergent tau-leap\nmethod. Our method is easy to implement, works with any tau-leap simulation\nscheme and its accuracy is proved to be similar to that of the underlying\ntau-leap scheme. We demonstrate the efficiency of our methods through numerical\nexamples. We also compare our method with the tau-leap versions of certain\nfinite-difference schemes that are commonly used for sensitivity estimations. \n\n"}
{"id": "1703.03165", "contents": "Title: Perturbation Bootstrap in Adaptive Lasso Abstract: The Adaptive Lasso(Alasso) was proposed by Zou [\\textit{J. Amer. Statist.\nAssoc. \\textbf{101} (2006) 1418-1429}] as a modification of the Lasso for the\npurpose of simultaneous variable selection and estimation of the parameters in\na linear regression model. Zou (2006) established that the Alasso estimator is\nvariable-selection consistent as well as asymptotically Normal in the indices\ncorresponding to the nonzero regression coefficients in certain\nfixed-dimensional settings. In an influential paper, Minnier, Tian and Cai\n[\\textit{J. Amer. Statist. Assoc. \\textbf{106} (2011) 1371-1382}] proposed a\nperturbation bootstrap method and established its distributional consistency\nfor the Alasso estimator in the fixed-dimensional setting. In this paper,\nhowever, we show that this (naive) perturbation bootstrap fails to achieve\nsecond order correctness in approximating the distribution of the Alasso\nestimator. We propose a modification to the perturbation bootstrap objective\nfunction and show that a suitably studentized version of our modified\nperturbation bootstrap Alasso estimator achieves second-order correctness even\nwhen the dimension of the model is allowed to grow to infinity with the sample\nsize. As a consequence, inferences based on the modified perturbation bootstrap\nwill be more accurate than the inferences based on the oracle Normal\napproximation. We give simulation studies demonstrating good finite-sample\nproperties of our modified perturbation bootstrap method as well as an\nillustration of our method on a real data set. \n\n"}
{"id": "1703.03238", "contents": "Title: Reflected stochastic differential equations driven by $G$-Brownian\n  motion in non-convex domains Abstract: In this paper, we first review the penalization method for solving\ndeterministic Skorokhod problems in non-convex domains and establish estimates\nfor problems with $\\alpha$-H\\\"older continuous functions. With the help of\nthese results obtained previously for deterministic problems, we pathwisely\ndefine the reflected $G$-Brownian motion and prove its existence and uniqueness\nin a Banach space. Finally, multi-dimensional reflected stochastic differential\nequations driven by $G$-Brownian motion are investigated via a fixed-point\nargument. \n\n"}
{"id": "1703.06031", "contents": "Title: Modeling spatial processes with unknown extremal dependence class Abstract: Many environmental processes exhibit weakening spatial dependence as events\nbecome more extreme. Well-known limiting models, such as max-stable or\ngeneralized Pareto processes, cannot capture this, which can lead to a\npreference for models that exhibit a property known as asymptotic independence.\nHowever, weakening dependence does not automatically imply asymptotic\nindependence, and whether the process is truly asymptotically (in)dependent is\nusually far from clear. The distinction is key as it can have a large impact\nupon extrapolation, i.e., the estimated probabilities of events more extreme\nthan those observed. In this work, we present a single spatial model that is\nable to capture both dependence classes in a parsimonious manner, and with a\nsmooth transition between the two cases. The model covers a wide range of\npossibilities from asymptotic independence through to complete dependence, and\npermits weakening dependence of extremes even under asymptotic dependence.\nCensored likelihood-based inference for the implied copula is feasible in\nmoderate dimensions due to closed-form margins. The model is applied to\noceanographic datasets with ambiguous true limiting dependence structure. \n\n"}
{"id": "1703.08092", "contents": "Title: Universality in numerical computation with random data. Case studies,\n  analytic results and some speculations Abstract: We discuss various universality aspects of numerical computations using\nstandard algorithms. These aspects include empirical observations and rigorous\nresults. We also make various speculations about computation in a broader\nsense. \n\n"}
{"id": "1703.09587", "contents": "Title: Spectral statistics of the uni-modular ensemble Abstract: We investigate the spectral statistics of Hermitian matrices in which the\nelements are chosen uniformly from U (1), called the uni-modular ensemble\n(UME), in the limit of large matrix size. Using three complimentary methods; a\nsupersymmetric integration method, a combinatorial graph-theoretical analysis\nand a Brownian motion approach, we are able to derive expressions for 1/N\ncorrections to the mean spectral moments and also analyse the fluctuations\nabout this mean. By addressing the same ensemble from three different point of\nview, we can critically compare their relative advantages and derive some new\nresults. \n\n"}
{"id": "1703.09908", "contents": "Title: A probabilistic approach to the leader problem in random graphs Abstract: We study the fixation time of the identity of the leader, i.e., the most\nmassive component, in the general setting of Aldous's multiplicative coalescent\n[4, 5], which in an asymptotic sense describes the evolution of the component\nsizes of a wide array of near-critical coalescent processes, including the\nclassical Erd\\H{o}s-R\\'enyi process.\n  We show tightness of the fixation time in the \"Brownian\" regime, explicitly\ndetermining the median value of the fixation time to within an optimal $O(1)$\nwindow. This generalizes {\\L}uczak's result [31] for the Erd\\H{o}s-R\\'enyi\nrandom graph using completely different techniques.\n  In the heavy-tailed case, in which the limit of the component sizes can be\nencoded using a thinned pure-jump L\\'{e}vy process, we prove that only\none-sided tightness holds. This shows a genuine difference in the possible\nbehavior in the two regimes.\n  The solution to the leader problem in the setting of the Erd\\H{o}s-R\\'enyi\nrandom graph played an important role in the study of the scaling limit of the\nminimal spanning tree on the complete graph [2]. We believe that analogous\nresults, such as those proved herein, will be useful in establishing\nuniversality of the intrinsic geometry of the minimal spanning tree across a\nlarge class of models. \n\n"}
{"id": "1703.10136", "contents": "Title: Network Dependence Testing via Diffusion Maps and Distance-Based\n  Correlations Abstract: Deciphering the associations between network connectivity and nodal\nattributes is one of the core problems in network science. The dependency\nstructure and high-dimensionality of networks pose unique challenges to\ntraditional dependency tests in terms of theoretical guarantees and empirical\nperformance. We propose an approach to test network dependence via diffusion\nmaps and distance-based correlations. We prove that the new method yields a\nconsistent test statistic under mild distributional assumptions on the graph\nstructure, and demonstrate that it is able to efficiently identify the most\ninformative graph embedding with respect to the diffusion time. The methodology\nis illustrated on both simulated and real data. \n\n"}
{"id": "1703.10256", "contents": "Title: Predictive mean matching imputation in survey sampling Abstract: Predictive mean matching imputation is popular for handling item nonresponse\nin survey sampling. In this article, we study the asymptotic properties of the\npredictive mean matching estimator of the population mean. For variance\nestimation, the conventional bootstrap inference for matching estimators with\nfixed matches has been shown to be invalid due to the nonsmoothness nature of\nthe matching estimator. We propose asymptotically valid replication variance\nestimation. The key strategy is to construct replicates of the estimator\ndirectly based on linear terms, instead of individual records of variables.\nExtension to nearest neighbor imputation is also discussed. A simulation study\nconfirms that the new procedure provides valid variance estimation. \n\n"}
{"id": "1704.00247", "contents": "Title: Compressed Covariance Estimation With Automated Dimension Learning Abstract: We propose a method for estimating a covariance matrix that can be\nrepresented as a sum of a low-rank matrix and a diagonal matrix. The proposed\nmethod compresses high-dimensional data, computes the sample covariance in the\ncompressed space, and lifts it back to the ambient space via a decompression\noperation. A salient feature of our approach relative to existing literature on\ncombining sparsity and low-rank structures in covariance matrix estimation is\nthat we do not require the low-rank component to be sparse. A principled\nframework for estimating the compressed dimension using Stein's Unbiased Risk\nEstimation theory is demonstrated. Experimental simulation results demonstrate\nthe efficacy and scalability of our proposed approach. \n\n"}
{"id": "1704.00297", "contents": "Title: Tropical Limits of Probability Spaces, Part I: The Intrinsic\n  Kolmogorov-Sinai Distance and the Asymptotic Equipartition Property for\n  Configurations Abstract: The entropy of a finite probability space $X$ measures the observable\ncardinality of large independent products $X^{\\otimes n}$ of the probability\nspace. If two probability spaces $X$ and $Y$ have the same entropy, there is an\nalmost measure-preserving bijection between large parts of $X^{\\otimes n}$ and\n$Y^{\\otimes n}$. In this way, $X$ and $Y$ are asymptotically equivalent.\n  It turns out to be challenging to generalize this notion of asymptotic\nequivalence to configurations of probability spaces, which are collections of\nprobability spaces with measure-preserving maps between some of them.\n  In this article we introduce the intrinsic Kolmogorov-Sinai distance on the\nspace of configurations of probability spaces. Concentrating on the large-scale\ngeometry we pass to the asymptotic Kolmogorov-Sinai distance. It induces an\nasymptotic equivalence relation on sequences of configurations of probability\nspaces. We will call the equivalence classes \\emph{tropical probability\nspaces}.\n  In this context we prove an Asymptotic Equipartition Property for\nconfigurations. It states that tropical configurations can always be\napproximated by homogeneous configurations. In addition, we show that the\nsolutions to certain Information-Optimization problems are\nLipschitz-con\\-tinuous with respect to the asymptotic Kolmogorov-Sinai\ndistance. It follows from these two statements that in order to solve an\nInformation-Optimization problem, it suffices to consider homogeneous\nconfigurations.\n  Finally, we show that spaces of trajectories of length $n$ of certain\nstochastic processes, in particular stationary Markov chains, have a tropical\nlimit. \n\n"}
{"id": "1704.00916", "contents": "Title: Space and time inversions of stochastic processes and Kelvin transform Abstract: Let $X$ be a standard Markov process. We prove that a space inversion\nproperty of $X$ implies the existence of a Kelvin transform of $X$-harmonic,\nexcessive and operator-harmonic functions and that the inversion property is\ninherited by Doob $h$-transforms. We determine new classes of processes having\nspace inversion properties amongst transient processes {satisfying the} time\ninversion property. {For these processes, some explicit inversions, which are\noften not the spherical ones, and excessive functions are given explicitly.} We\ntreat in details the examples of free scaled power Bessel processes,\nnon-colliding Bessel particles, Wishart processes, Gaussian Ensemble and Dyson\nBrownian Motion. \n\n"}
{"id": "1704.00963", "contents": "Title: Correcting boundary over-exploration deficiencies in Bayesian\n  optimization with virtual derivative sign observations Abstract: Bayesian optimization (BO) is a global optimization strategy designed to find\nthe minimum of an expensive black-box function, typically defined on a compact\nsubset of $\\mathcal{R}^d$, by using a Gaussian process (GP) as a surrogate\nmodel for the objective. Although currently available acquisition functions\naddress this goal with different degree of success, an over-exploration effect\nof the contour of the search space is typically observed. However, in problems\nlike the configuration of machine learning algorithms, the function domain is\nconservatively large and with a high probability the global minimum does not\nsit on the boundary of the domain. We propose a method to incorporate this\nknowledge into the search process by adding virtual derivative observations in\nthe \\gp at the boundary of the search space. We use the properties of GPs to\nimpose conditions on the partial derivatives of the objective. The method is\napplicable with any acquisition function, it is easy to use and consistently\nreduces the number of evaluations required to optimize the objective\nirrespective of the acquisition used. We illustrate the benefits of our\napproach in an extensive experimental comparison. \n\n"}
{"id": "1704.01041", "contents": "Title: Polynomial Time and Sample Complexity for Non-Gaussian Component\n  Analysis: Spectral Methods Abstract: The problem of Non-Gaussian Component Analysis (NGCA) is about finding a\nmaximal low-dimensional subspace $E$ in $\\mathbb{R}^n$ so that data points\nprojected onto $E$ follow a non-gaussian distribution. Although this is an\nappropriate model for some real world data analysis problems, there has been\nlittle progress on this problem over the last decade.\n  In this paper, we attempt to address this state of affairs in two ways.\nFirst, we give a new characterization of standard gaussian distributions in\nhigh-dimensions, which lead to effective tests for non-gaussianness. Second, we\npropose a simple algorithm, \\emph{Reweighted PCA}, as a method for solving the\nNGCA problem. We prove that for a general unknown non-gaussian distribution,\nthis algorithm recovers at least one direction in $E$, with sample and time\ncomplexity depending polynomially on the dimension of the ambient space. We\nconjecture that the algorithm actually recovers the entire $E$. \n\n"}
{"id": "1704.01291", "contents": "Title: Universality of the GOE Tracy-Widom distribution for TASEP with\n  arbitrary particle density Abstract: We consider TASEP in continuous time with non-random initial conditions and\narbitrary fixed density of particles rho. We show GOE Tracy-Widom universality\nof the one-point fluctuations of the associated height function. The result\nphrased in last passage percolation language is the universality for the\npoint-to-line problem where the line has an arbitrary slope. \n\n"}
{"id": "1704.02381", "contents": "Title: Adaptive estimation of the rank of the coefficient matrix in high\n  dimensional multivariate response regression models Abstract: We consider the multivariate response regression problem with a regression\ncoefficient matrix of low, unknown rank. In this setting, we analyze a new\ncriterion for selecting the optimal reduced rank. This criterion differs\nnotably from the one proposed in Bunea, She and Wegkamp [7] in that it does not\nrequire estimation of the unknown variance of the noise, nor depends on a\ndelicate choice of a tuning parameter. We develop an iterative, fully\ndata-driven procedure, that adapts to the optimal signal to noise ratio. This\nprocedure finds the true rank in a few steps with overwhelming probability. At\neach step, our estimate increases, while at the same time it does not exceed\nthe true rank. Our finite sample results hold for any sample size and any\ndimension, even when the number of responses and of covariates grow much faster\nthan the number of observations. We perform an extensive simulation study that\nconfirms our theoretical findings. The new method performs better and more\nstable than that in [7] in both low- and high-dimensional settings. \n\n"}
{"id": "1704.02411", "contents": "Title: Second order Lyapunov exponents for parabolic and hyperbolic Anderson\n  models Abstract: In this article, we consider the hyperbolic and parabolic Anderson models in\narbitrary space dimension $d$, with constant initial condition, driven by a\nGaussian noise which is white in time. We consider two spatial covariance\nstructures: (i) the Fourier transform of the spectral measure of the noise is a\nnon-negative locally-integrable function; (ii) $d=1$ and the noise is a\nfractional Brownian motion in space with index $1/4<H<1/2$. In both cases, we\nshow that there is striking similarity between the Laplace transforms of the\nsecond moment of the solutions to these two models. Building on this connection\nand the recent powerful results of Huang, Le and Nualart (2015) for the\nparabolic model, we compute the second order (upper) Lyapunov exponent for the\nhyperbolic model. In case (i), when the spatial covariance of the noise is\ngiven by the Riesz kernel, we present a unified method for calculating the\nsecond order Lyapunov exponents for the two models. \n\n"}
{"id": "1704.02531", "contents": "Title: Three Skewed Matrix Variate Distributions Abstract: Three-way data can be conveniently modelled by using matrix variate\ndistributions. Although there has been a lot of work for the matrix variate\nnormal distribution, there is little work in the area of matrix skew\ndistributions. Three matrix variate distributions that incorporate skewness, as\nwell as other flexible properties such as concentration, are discussed.\nEquivalences to multivariate analogues are presented, and moment generating\nfunctions are derived. Maximum likelihood parameter estimation is discussed,\nand simulated data is used for illustration. \n\n"}
{"id": "1704.02689", "contents": "Title: Zero-sum stochastic differential game with risk-sensitive cost Abstract: Zero sum games with risk-sensitive cost criterion are considered with\nunderlying dynamics being given by controlled stochastic differential\nequations. Under the assumption of geometric stability on the dynamics , we\ncompletely characterize all possible saddle point strategies in the class of\nstationary Markov controls. In addition, we also establish existence-uniqueness\nresult for the value function of the Hamilton-Jacobi-Isaacs equation. \n\n"}
{"id": "1704.04309", "contents": "Title: Stochastic six-vertex model in a half-quadrant and half-line open ASEP Abstract: We consider the asymmetric simple exclusion process (ASEP) on the positive\nintegers with an open boundary condition. We show that, when starting devoid of\nparticles and for a certain boundary condition, the height function at the\norigin fluctuates asymptotically (in large time $\\tau$) according to the\nTracy-Widom GOE distribution on the $\\tau^{1/3}$ scale. This is the first\nexample of KPZ asymptotics for a half-space system outside the class of\nfree-fermionic/determinantal/Pfaffian models.\n  Our main tool in this analysis is a new class of probability measures on\nYoung diagrams that we call half-space Macdonald processes, as well as two\nsurprising relations. The first relates a special (Hall-Littlewood) case of\nthese measures to the half-space stochastic six-vertex model (which further\nlimits to ASEP) using a Yang-Baxter graphical argument. The second relates\ncertain averages under these measures to their half-space (or Pfaffian) Schur\nprocess analogs via a refined Littlewood identity. \n\n"}
{"id": "1704.04674", "contents": "Title: Limit Theorems for Monochromatic Stars Abstract: Let $T(K_{1, r}, G_n)$ be the number of monochromatic copies of the $r$-star\n$K_{1, r}$ in a uniformly random coloring of the vertices of the graph $G_n$.\nIn this paper we provide a complete characterization of the limiting\ndistribution of $T(K_{1, r}, G_n)$, in the regime where $\\mathbb E(T(K_{1, r},\nG_n))$ is bounded, for any growing sequence of graphs $G_n$. The asymptotic\ndistribution is a sum of mutually independent components, each term of which is\na polynomial of a single Poisson random variable of degree at most $r$.\nConversely, any limiting distribution of $T(K_{1, r}, G_n)$ has a\nrepresentation of this form. Examples and connections to the birthday problem\nare discussed. \n\n"}
{"id": "1704.05098", "contents": "Title: Statistical inference for high dimensional regression via Constrained\n  Lasso Abstract: In this paper, we propose a new method for estimation and constructing\nconfidence intervals for low-dimensional components in a high-dimensional\nmodel. The proposed estimator, called Constrained Lasso (CLasso) estimator, is\nobtained by simultaneously solving two estimating equations---one imposing a\nzero-bias constraint for the low-dimensional parameter and the other forming an\n$\\ell_1$-penalized procedure for the high-dimensional nuisance parameter. By\ncarefully choosing the zero-bias constraint, the resulting estimator of the low\ndimensional parameter is shown to admit an asymptotically normal limit\nattaining the Cram\\'{e}r-Rao lower bound in a semiparametric sense. We propose\na tuning-free iterative algorithm for implementing the CLasso. We show that\nwhen the algorithm is initialized at the Lasso estimator, the de-sparsified\nestimator proposed in van de Geer et al. [\\emph{Ann. Statist.} {\\bf 42} (2014)\n1166--1202] is asymptotically equivalent to the first iterate of the algorithm.\nWe analyse the asymptotic properties of the CLasso estimator and show the\nglobally linear convergence of the algorithm. We also demonstrate encouraging\nempirical performance of the CLasso through numerical studies. \n\n"}
{"id": "1704.06442", "contents": "Title: Stationary analysis of the shortest queue problem Abstract: A simple analytical solution is proposed for the stationary loss system of\ntwo parallel queues with finite capacity $K$, in which new customers join the\nshortest queue, or one of the two with equal probability if their lengths are\nequal. The arrival process is Poisson, service times at each queue have\nexponential distributions with the same parameter, and both queues have equal\ncapacity. Using standard generating function arguments, a simple expression for\nthe blocking probability is derived, which as far as we know is original. Using\ncoupling arguments and explicit formulas, comparisons with related loss systems\nare then provided. Bounds are similarly obtained for the average total number\nof customers, with the stationary distribution explicitly determined on $\\{K,\n\\dots, 2K \\}$, and elsewhere upper bounded. Furthermore, from the balance\nequations, all stationary probabilities are obtained as explicit combinations\nof their values at states $(0,k)$ for $0 \\le k \\le K$. These expressions extend\nto the infinite capacity and asymmetric cases, i.e., when the queues have\ndifferent service rates. For the initial symmetric finite capacity model, the\nstationary probabilities of states $(0,k)$ can be obtained recursively from the\nblocking probability. In the other cases, they are implicitly determined\nthrough a functional equation that characterizes their generating function. The\nwhole approach shows that the stationary distribution of the infinite capacity\nsymmetric process is the limit of the corresponding finite capacity\ndistributions. For the infinite capacity symmetric model, we provide an\nelementary proof of a result by Cohen which gives the solution of the\nfunctional equation in terms of an infinite product with explicit zeroes and\npoles. \n\n"}
{"id": "1704.08066", "contents": "Title: Bootstrap-Based Inference for Cube Root Asymptotics Abstract: This paper proposes a valid bootstrap-based distributional approximation for\nM-estimators exhibiting a Chernoff (1964)-type limiting distribution. For\nestimators of this kind, the standard nonparametric bootstrap is inconsistent.\nThe method proposed herein is based on the nonparametric bootstrap, but\nrestores consistency by altering the shape of the criterion function defining\nthe estimator whose distribution we seek to approximate. This modification\nleads to a generic and easy-to-implement resampling method for inference that\nis conceptually distinct from other available distributional approximations. We\nillustrate the applicability of our results with four examples in econometrics\nand machine learning. \n\n"}
{"id": "1704.08228", "contents": "Title: Density solutions to a class of integro-differential equations Abstract: We consider the integro-differential equation ${\\rm I}^{\\alpha}_{0+}f= x^m f$\non the half-line. We show that there exists a density solution, which is then\nunique and can be expressed in terms of the Beta distribution, if and only if\n$m> \\alpha.$ These density solutions extend the class of generalized one-sided\nstable distributions introduced in Schneider (1987) and more recently\ninvestigated in Pakes (2014). We study various analytical aspects of these\ndensities, and we solve the open problems about infinite divisibility\nformulated in Pakes (2014). \n\n"}
{"id": "1704.08398", "contents": "Title: Stein's method for steady-state diffusion approximations Abstract: Diffusion approximations have been a popular tool for performance analysis in\nqueueing theory, with the main reason being tractability and computational\nefficiency. This dissertation is concerned with establishing theoretical\nguarantees on the performance of steady-state diffusion approximations of\nqueueing systems. We develop a modular framework based on Stein's method that\nallows us to establish error bounds, or convergence rates, for the\napproximations. We apply this framework three queueing systems: the Erlang-C,\nErlang-A, and $M/Ph/n+M$ systems.\n  The former two systems are simpler and allow us to showcase the full\npotential of the framework. Namely, we prove that both Wasserstein and\nKolmogorov distances between the stationary distribution of a normalized\ncustomer count process, and that of an appropriately defined diffusion process\ndecrease at a rate of $1/\\sqrt{R}$, where $R$ is the offered load. Futhermore,\nthese error bounds are \\emph{universal}, valid in any load condition from\nlightly loaded to heavily loaded. For the Erlang-C model, we also show that a\ndiffusion approximation with state-dependent diffusion coefficient can achieve\na rate of convergence of $1/R$, which is an order of magnitude faster when\ncompared to approximations with constant diffusion coefficients. \n\n"}
{"id": "1705.00385", "contents": "Title: A Generalized Probabilistic Version of Modus Ponens Abstract: Modus ponens (\\emph{from $A$ and \"if $A$ then $C$\" infer $C$}, short: MP) is\none of the most basic inference rules. The probabilistic MP allows for managing\nuncertainty by transmitting assigned uncertainties from the premises to the\nconclusion (i.e., from $P(A)$ and $P(C|A)$ infer $P(C)$). In this paper, we\ngeneralize the probabilistic MP by replacing $A$ by the conditional event\n$A|H$. The resulting inference rule involves iterated conditionals (formalized\nby conditional random quantities) and propagates previsions from the premises\nto the conclusion. Interestingly, the propagation rules for the lower and the\nupper bounds on the conclusion of the generalized probabilistic MP coincide\nwith the respective bounds on the conclusion for the (non-nested) probabilistic\nMP. \n\n"}
{"id": "1705.01024", "contents": "Title: A projection pursuit framework for testing general high-dimensional\n  hypothesis Abstract: This article develops a framework for testing general hypothesis in\nhigh-dimensional models where the number of variables may far exceed the number\nof observations. Existing literature has considered less than a handful of\nhypotheses, such as testing individual coordinates of the model parameter.\nHowever, the problem of testing general and complex hypotheses remains widely\nopen. We propose a new inference method developed around the hypothesis\nadaptive projection pursuit framework, which solves the testing problems in the\nmost general case. The proposed inference is centered around a new class of\nestimators defined as $l_1$ projection of the initial guess of the unknown onto\nthe space defined by the null. This projection automatically takes into account\nthe structure of the null hypothesis and allows us to study formal inference\nfor a number of long-standing problems. For example, we can directly conduct\ninference on the sparsity level of the model parameters and the minimum signal\nstrength. This is especially significant given the fact that the former is a\nfundamental condition underlying most of the theoretical development in\nhigh-dimensional statistics, while the latter is a key condition used to\nestablish variable selection properties. Moreover, the proposed method is\nasymptotically exact and has satisfactory power properties for testing very\ngeneral functionals of the high-dimensional parameters. The simulation studies\nlend further support to our theoretical claims and additionally show excellent\nfinite-sample size and power properties of the proposed test. \n\n"}
{"id": "1705.01505", "contents": "Title: Introduction to finite mixtures Abstract: Mixture models have been around for over 150 years, as an intuitively simple\nand practical tool for enriching the collection of probability distributions\navailable for modelling data. In this chapter we describe the basic ideas of\nthe subject, present several alternative representations and perspectives on\nthese models, and discuss some of the elements of inference about the unknowns\nin the models. Our focus is on the simplest set-up, of finite mixture models,\nbut we discuss also how various simplifying assumptions can be relaxed to\ngenerate the rich landscape of modelling and inference ideas traversed in the\nrest of this book. \n\n"}
{"id": "1705.01652", "contents": "Title: Polluted Bootstrap Percolation with Threshold Two in All Dimensions Abstract: In the polluted bootstrap percolation model, the vertices of a graph are\nindependently declared initially occupied with probability p or closed with\nprobability q. At subsequent steps, a vertex becomes occupied if it is not\nclosed and it has at least r occupied neighbors. On the cubic lattice Z^d of\ndimension d>=3 with threshold r=2, we prove that the final density of occupied\nsites converges to 1 as p and q both approach 0, regardless of their relative\nscaling. Our result partially resolves a conjecture of Morris, and contrasts\nwith the d=2 case, where Gravner and McDonald proved that the critical\nparameter is q/{p^2}. \n\n"}
{"id": "1705.01715", "contents": "Title: Directed Networks with a Differentially Private Bi-degree Sequence Abstract: Although a lot of approaches are developed to release network data with a\ndifferentially privacy guarantee, inference using noisy data in many network\nmodels is still unknown or not properly explored. In this paper, we release the\nbi-degree sequences of directed networks using the Laplace mechanism and use\nthe $p_0$ model for inferring the degree parameters. The $p_0$ model is an\nexponential random graph model with the bi-degree sequence as its exclusively\nsufficient statistic. We show that the estimator of the parameter without the\ndenoised process is asymptotically consistent and normally distributed. This is\ncontrast sharply with some known results that valid inference such as the\nexistence and consistency of the estimator needs the denoised process. Along\nthe way, a new phenomenon is revealed in which an additional variance factor\nappears in the asymptotic variance of the estimator when the noise becomes\nlarge. Further, we propose an efficient algorithm for finding the closet point\nlying in the set of all graphical bi-degree sequences under the global $L_1$\noptimization problem. Numerical studies demonstrate our theoretical findings. \n\n"}
{"id": "1705.02130", "contents": "Title: A spectral approach for quenched limit theorems for random expanding\n  dynamical systems Abstract: We prove quenched versions of (i) a large deviations principle (LDP), (ii) a\ncentral limit theorem (CLT), and (iii) a local central limit theorem (LCLT) for\nnon-autonomous dynamical systems. A key advance is the extension of the\nspectral method, commonly used in limit laws for deterministic maps, to the\ngeneral random setting. We achieve this via multiplicative ergodic theory and\nthe development of a general framework to control the regularity of Lyapunov\nexponents of \\emph{twisted transfer operator cocycles} with respect to a twist\nparameter. While some versions of the LDP and CLT have previously been proved\nwith other techniques, the local central limit theorem is, to our knowledge, a\ncompletely new result, and one that demonstrates the strength of our method.\nApplications include non-autonomous (piecewise) expanding maps, defined by\nrandom compositions of the form $T_{\\sigma^{n-1}\\omega}\\circ\\cdots\\circ\nT_{\\sigma\\omega}\\circ T_\\omega$. An important aspect of our results is that we\nonly assume ergodicity and invertibility of the random driving\n$\\sigma:\\Omega\\to\\Omega$; in particular no expansivity or mixing properties are \n\n"}
{"id": "1705.02511", "contents": "Title: A generalized Gaussian process model for computer experiments with\n  binary time series Abstract: Non-Gaussian observations such as binary responses are common in some\ncomputer experiments. Motivated by the analysis of a class of cell adhesion\nexperiments, we introduce a generalized Gaussian process model for binary\nresponses, which shares some common features with standard GP models. In\naddition, the proposed model incorporates a flexible mean function that can\ncapture different types of time series structures. Asymptotic properties of the\nestimators are derived, and an optimal predictor as well as its predictive\ndistribution are constructed. Their performance is examined via two simulation\nstudies. The methodology is applied to study computer simulations for cell\nadhesion experiments. The fitted model reveals important biological information\nin repeated cell bindings, which is not directly observable in lab experiments. \n\n"}
{"id": "1705.02731", "contents": "Title: Respondent driven sampling and sparse graph convergence Abstract: We consider a particular respondent-driven sampling procedure governed by a\ngraphon. By a specific clumping procedure of the sampled vertices we construct\na sequence of sparse graphs. If the sequence of the vertex-sets is stationary\nthen the sequence of sparse graphs converge to the governing graphon in the\ncut-metric. The tools used are concentration inequality for Markov chains and\nthe Stein-Chen method. \n\n"}
{"id": "1705.03156", "contents": "Title: Entropic repulsion and lack of the $g$-measure property for Dyson models Abstract: We consider Dyson models, Ising models with slow polynomial decay, at low\ntemperature and show that its Gibbs measures deep in the phase transition\nregion are not $g$-measures. The main ingredient in the proof is the occurrence\nof an entropic repulsion effect, which follows from the mesoscopic stability of\na (single-point) interface for these long-range models in the phase transition\nregion. \n\n"}
{"id": "1705.04518", "contents": "Title: Consistency of adjacency spectral embedding for the mixed membership\n  stochastic blockmodel Abstract: The mixed membership stochastic blockmodel is a statistical model for a\ngraph, which extends the stochastic blockmodel by allowing every node to\nrandomly choose a different community each time a decision of whether to form\nan edge is made. Whereas spectral analysis for the stochastic blockmodel is\nincreasingly well established, theory for the mixed membership case is\nconsiderably less developed. Here we show that adjacency spectral embedding\ninto $\\mathbb{R}^k$, followed by fitting the minimum volume enclosing convex\n$k$-polytope to the $k-1$ principal components, leads to a consistent estimate\nof a $k$-community mixed membership stochastic blockmodel. The key is to\nidentify a direct correspondence between the mixed membership stochastic\nblockmodel and the random dot product graph, which greatly facilitates\ntheoretical analysis. Specifically, a $2 \\rightarrow \\infty$ norm and central\nlimit theorem for the random dot product graph are exploited to respectively\nshow consistency and partially correct the bias of the procedure. \n\n"}
{"id": "1705.06095", "contents": "Title: Upper bounds on the growth rate of Diffusion Limited Aggregation Abstract: We revisit Kesten's argument for the upper bound on the growth rate of DLA.\nWe are able to make the argument robust enough so that it applies to many\ngraphs, where only control of the heat kernel is required. We apply this to\nmany examples including transitive graphs of polynomial growth, graphs of\nexponential growth, non-amenable graphs, super-critical percolation on Z^d,\nhigh dimensional pre-Sierpinski carpets. We also observe that a careful\nanalysis shows that Kesten's original bound on Z^3 can be improved from t^{2/3}\nto (t log t)^{1/2} . \n\n"}
{"id": "1705.06168", "contents": "Title: Two-Sample Tests for Large Random Graphs Using Network Statistics Abstract: We consider a two-sample hypothesis testing problem, where the distributions\nare defined on the space of undirected graphs, and one has access to only one\nobservation from each model. A motivating example for this problem is comparing\nthe friendship networks on Facebook and LinkedIn. The practical approach to\nsuch problems is to compare the networks based on certain network statistics.\nIn this paper, we present a general principle for two-sample hypothesis testing\nin such scenarios without making any assumption about the network generation\nprocess. The main contribution of the paper is a general formulation of the\nproblem based on concentration of network statistics, and consequently, a\nconsistent two-sample test that arises as the natural solution for this\nproblem. We also show that the proposed test is minimax optimal for certain\nnetwork statistics. \n\n"}
{"id": "1705.06807", "contents": "Title: Parallel replica dynamics method for bistable stochastic reaction\n  networks: simulation and sensitivity analysis Abstract: Stochastic reaction networks that exhibit bistability are common in many\nfields such as systems biology and materials science. Sampling of the\nstationary distribution is crucial for understanding and characterizing the\nlong term dynamics of bistable stochastic dynamical systems. However, this is\nnormally hindered by the insufficient sampling of the rare transitions between\nthe two metastable regions. In this paper, we apply the parallel replica\n(ParRep) method for continuous time Markov chain to accelerate the stationary\ndistribution sampling of bistable stochastic reaction networks. The proposed\nmethod uses parallel computing to accelerate the sampling of rare transitions\nand it is very easy to implement. We combine ParRep with the path space\ninformation bounds for parametric sensitivity analysis. We demonstrate the\nefficiency and accuracy of the method by studying the Schl\\\"{o}gl model and the\ngenetic switches network. \n\n"}
{"id": "1705.07808", "contents": "Title: The large-N limit for two-dimensional Yang-Mills theory Abstract: The analysis of the large-$N$ limit of $U(N)$ Yang-Mills theory on a surface\nproceeds in two stages: the analysis of the Wilson loop functional for a simple\nclosed curve and the reduction of more general loops to a simple closed curve.\nIn the case of the 2-sphere, the first stage has been treated rigorously in\nrecent work of Dahlqvist and Norris, which shows that the large-$N$ limit of\nthe Wilson loop functional for a simple closed curve in $S^{2}$ exists and that\nthe associated variance goes to zero.\n  We give a rigorous treatment of the second stage of analysis in the case of\nthe 2-sphere. Dahlqvist and Norris independently performed such an analysis,\nusing a similar but not identical method. Specifically, we establish the\nexistence of the limit and the vanishing of the variance for arbitrary loops\nwith (a finite number of) simple crossings. The proof is based on the\nMakeenko-Migdal equation for the Yang-Mills measure on surfaces, as established\nrigorously by Driver, Gabriel, Hall, and Kemp, together with an explicit\nprocedure for reducing a general loop in $S^{2}$ to a simple closed curve. The\nmethods used here also give a new proof of these results in the plane case, as\na variant of the methods used by L\\'{e}vy.\n  We also consider loops on an arbitrary surface $\\Sigma$. We put forth two\nnatural conjectures about the behavior of Wilson loop functionals for\ntopologically trivial simple closed curves in $\\Sigma.$ Under the weaker of the\nconjectures, we establish the existence of the limit and the vanishing of the\nvariance for topologically trivial loops with simple crossings that satisfy a\n\"smallness\" assumption. Under the stronger of the conjectures, we establish the\nsame result without the smallness assumption. \n\n"}
{"id": "1705.08527", "contents": "Title: Causal inference for social network data Abstract: We describe semiparametric estimation and inference for causal effects using\nobservational data from a single social network. Our asymptotic results are the\nfirst to allow for dependence of each observation on a growing number of other\nunits as sample size increases. In addition, while previous methods have\nimplicitly permitted only one of two possible sources of dependence among\nsocial network observations, we allow for both dependence due to transmission\nof information across network ties and for dependence due to latent\nsimilarities among nodes sharing ties. We propose new causal effects that are\nspecifically of interest in social network settings, such as interventions on\nnetwork ties and network structure. We use our methods to reanalyze an\ninfluential and controversial study that estimated causal peer effects of\nobesity using social network data from the Framingham Heart Study; after\naccounting for network structure we find no evidence for causal peer effects. \n\n"}
{"id": "1705.10013", "contents": "Title: Small sphere distributions for directional data with application to\n  medical imaging Abstract: We propose new small-sphere distributional families for modeling multivariate\ndirectional data on $(\\mathbb{S}^{p-1})^K$ for $p \\ge 3$ and $K \\ge 1$. In a\nspecial case of univariate directions in $\\Re^3$, the new densities model\nrandom directions on $\\mathbb{S}^2$ with a tendency to vary along a small\ncircle on the sphere, and with a unique mode on the small circle. The proposed\nmultivariate densities enable us to model association among multivariate\ndirections, and are useful in medical imaging, where multivariate directions\nare used to represent shape and shape changes of 3-dimensional objects. When\nthe underlying objects are rotationally deformed under noise, for instance,\ntwisted and/or bend, corresponding directions tend to follow the proposed\nsmall-sphere distributions. The proposed models have several advantages over\nother methods analyzing small-circle-concentrated data, including inference\nprocedures on the association and small-circle fitting. We demonstrate the use\nof the proposed multivariate small-sphere distributions in analyses of\nskeletally-represented object shapes and human knee gait data. \n\n"}
{"id": "1706.01654", "contents": "Title: On the real zeros of random trigonometric polynomials with dependent\n  coefficients Abstract: We consider random trigonometric polynomials of the form \\[\nf_n(t):=\\sum_{1\\le k \\le n} a_{k} \\cos(kt) + b_{k} \\sin(kt), \\] whose entries\n$(a_{k})_{k\\ge 1}$ and $(b_{k})_{k\\ge 1}$ are given by two independent\nstationary Gaussian processes with the same correlation function $\\rho$. Under\nmild assumptions on the spectral function $\\psi_\\rho$ associated with $\\rho$,\nwe prove that the expectation of the number $N_n([0,2\\pi])$ of real roots of\n$f_n$ in the interval $[0,2\\pi]$ satisfies \\[ \\lim_{n \\to +\\infty}\n\\frac{\\mathbb E\\left [N_n([0,2\\pi])\\right]}{n} = \\frac{2}{\\sqrt{3}}. \\] The\nlatter result not only covers the well-known situation of independent\ncoefficients but allow us to deal with long range correlations. In particular\nit englobes the case where the random coefficients are given by a fractional\nBrownian noise with any Hurst parameter. \n\n"}
{"id": "1706.01752", "contents": "Title: Robust approximate Bayesian inference Abstract: We discuss an approach for deriving robust posterior distributions from\n$M$-estimating functions using Approximate Bayesian Computation (ABC) methods.\nIn particular, we use $M$-estimating functions to construct suitable summary\nstatistics in ABC algorithms. The theoretical properties of the robust\nposterior distributions are discussed. Special attention is given to the\napplication of the method to linear mixed models. Simulation results and an\napplication to a clinical study demonstrate the usefulness of the method. An R\nimplementation is also provided in the robustBLME package. \n\n"}
{"id": "1706.01954", "contents": "Title: Sparse causality network retrieval from short time series Abstract: We investigate how efficiently a known underlying sparse causality structure\nof a simulated multivariate linear process can be retrieved from the analysis\nof time-series of short lengths. Causality is quantified from conditional\ntransfer entropy and the network is constructed by retaining only the\nstatistically validated contributions. We compare results from three\nmethodologies: two commonly used regularization methods, Glasso and ridge, and\na newly introduced technique, LoGo, based on the combination of information\nfiltering network and graphical modelling. For these three methodologies we\nexplore the regions of time series lengths and model-parameters where a\nsignificant fraction of true causality links is retrieved. We conclude that,\nwhen time-series are short, with their lengths shorter than the number of\nvariables, sparse models are better suited to uncover true causality links with\nLoGo retrieving the true causality network more accurately than Glasso and\nridge. \n\n"}
{"id": "1706.03400", "contents": "Title: A Prototype Knockoff Filter for Group Selection with FDR Control Abstract: In many applications, we need to study a linear regression model that\nconsists of a response variable and a large number of potential explanatory\nvariables and determine which variables are truly associated with the response.\nIn 2015, Barber and Candes introduced a new variable selection procedure called\nthe knockoff filter to control the false discovery rate (FDR) and proved that\nthis method achieves exact FDR control. In this paper, we propose a prototype\nknockoff filter for group selection by extending the Reid-Tibshirani prototype\nmethod. Our prototype knockoff filter improves the computational efficiency and\nstatistical power of the Reid-Tibshirani prototype method when it is applied\nfor group selection. In some cases when the group features are spanned by one\nor a few hidden factors, we demonstrate that the PCA prototype knockoff filter\noutperforms the Dai-Barber group knockoff filter. We present several numerical\nexperiments to compare our prototype knockoff filter with the Reid-Tibshirani\nprototype method and the group knockoff filter. We have also conducted some\nanalysis of the knockoff filter. Our analysis reveals that some knockoff path\nmethod statistics, including the Lasso path statistic, may lead to loss of\npower for certain design matrices and a specially designed response even if\ntheir signal strengths are still relatively strong. \n\n"}
{"id": "1706.03462", "contents": "Title: Efficient Test-based Variable Selection for High-dimensional Linear\n  Models Abstract: Variable selection plays a fundamental role in high-dimensional data\nanalysis. Various methods have been developed for variable selection in recent\nyears. Well-known examples are forward stepwise regression (FSR) and least\nangle regression (LARS), among others. These methods typically add variables\ninto the model one by one. For such selection procedures, it is crucial to find\na stopping criterion that controls model complexity. One of the most commonly\nused techniques to this end is cross-validation (CV) which, in spite of its\npopularity, has two major drawbacks: expensive computational cost and lack of\nstatistical interpretation. To overcome these drawbacks, we introduce a\nflexible and efficient test-based variable selection approach that can be\nincorporated into any sequential selection procedure. The test, which is on the\noverall signal in the remaining inactive variables, is based on the maximal\nabsolute partial correlation between the inactive variables and the response\ngiven active variables. We develop the asymptotic null distribution of the\nproposed test statistic as the dimension tends to infinity uniformly in the\nsample size. We also show that the test is consistent. With this test, at each\nstep of the selection, a new variable is included if and only if the $p$-value\nis below some pre-defined level. Numerical studies show that the proposed\nmethod delivers very competitive performance in terms of variable selection\naccuracy and computational complexity compared to CV. \n\n"}
{"id": "1706.03883", "contents": "Title: Multilevel Clustering via Wasserstein Means Abstract: We propose a novel approach to the problem of multilevel clustering, which\naims to simultaneously partition data in each group and discover grouping\npatterns among groups in a potentially large hierarchically structured corpus\nof data. Our method involves a joint optimization formulation over several\nspaces of discrete probability measures, which are endowed with Wasserstein\ndistance metrics. We propose a number of variants of this problem, which admit\nfast optimization algorithms, by exploiting the connection to the problem of\nfinding Wasserstein barycenters. Consistency properties are established for the\nestimates of both local and global clusters. Finally, experiment results with\nboth synthetic and real data are presented to demonstrate the flexibility and\nscalability of the proposed approach. \n\n"}
{"id": "1706.04032", "contents": "Title: Modified Hamiltonian Monte Carlo for Bayesian inference Abstract: The Hamiltonian Monte Carlo (HMC) method has been recognized as a powerful\nsampling tool in computational statistics. We show that performance of HMC can\nbe significantly improved by incorporating importance sampling and an\nirreversible part of the dynamics into a chain. This is achieved by replacing\nHamiltonians in the Metropolis test with modified Hamiltonians, and a complete\nmomentum update with a partial momentum refreshment. We call the resulting\ngeneralized HMC importance sampler---Mix & Match Hamiltonian Monte Carlo\n(MMHMC). The method is irreversible by construction and further benefits from\n(i) the efficient algorithms for computation of modified Hamiltonians; (ii) the\nimplicit momentum update procedure and (iii) the multi-stage splitting\nintegrators specially derived for the methods sampling with modified\nHamiltonians. MMHMC has been implemented, tested on the popular statistical\nmodels and compared in sampling efficiency with HMC, Riemann Manifold\nHamiltonian Monte Carlo, Generalized Hybrid Monte Carlo, Generalized Shadow\nHybrid Monte Carlo, Metropolis Adjusted Langevin Algorithm and Random Walk\nMetropolis-Hastings. To make a fair comparison, we propose a metric that\naccounts for correlations among samples and weights, and can be readily used\nfor all methods which generate such samples. The experiments reveal the\nsuperiority of MMHMC over popular sampling techniques, especially in solving\nhigh dimensional problems. \n\n"}
{"id": "1706.04628", "contents": "Title: Simple and explicit bounds for multi-server queues with $1/(1-\\rho)$\n  scaling Abstract: We consider the FCFS $GI/GI/n$ queue, and prove the first simple and explicit\nbounds that scale as $\\frac{1}{1-\\rho}$ under only the assumption that\ninter-arrival times have finite second moment, and service times have finite\n$2+\\epsilon$ moment for some $\\epsilon > 0$. Here $\\rho$ denotes the\ncorresponding traffic intensity. Conceptually, our results can be viewed as a\nmulti-server analogue of Kingman's bound. Our main results are bounds for the\ntail of the steady-state queue length and the steady-state probability of\ndelay. The strength of our bounds (e.g. in the form of tail decay rate) is a\nfunction of how many moments of the service distribution are assumed finite.\nOur bounds scale gracefully even when the number of servers grows large and the\ntraffic intensity converges to unity simultaneously, as in the Halfin-Whitt\nscaling regime. Some of our bounds scale better than $\\frac{1}{1-\\rho}$ in\ncertain asymptotic regimes. In these same asymptotic regimes we also prove\nbounds for the tail of the steady-state number in service.\n  Our main proofs proceed by explicitly analyzing the bounding process which\narises in the stochastic comparison bounds of Gamarnik and Goldberg for\nmulti-server queues. Along the way we derive several novel results for suprema\nof random walks and pooled renewal processes which may be of independent\ninterest. We also prove several additional bounds using drift arguments (which\nhave much smaller pre-factors), and point out a conjecture which would imply\nfurther related bounds and generalizations. We also show that when all moments\nof the service distribution are finite and satisfy a mild growth rate\nassumption, our bounds can be strengthened to yield explicit tail estimates\ndecaying as $O\\big(\\exp(-x^{\\alpha})\\big)$, with $\\alpha \\in (0,1)$ depending\non the growth rate of these moments. \n\n"}
{"id": "1706.05738", "contents": "Title: Fourier-Based Testing for Families of Distributions Abstract: We study the general problem of testing whether an unknown distribution\nbelongs to a specified family of distributions. More specifically, given a\ndistribution family $\\mathcal{P}$ and sample access to an unknown discrete\ndistribution $\\mathbf{P}$, we want to distinguish (with high probability)\nbetween the case that $\\mathbf{P} \\in \\mathcal{P}$ and the case that\n$\\mathbf{P}$ is $\\epsilon$-far, in total variation distance, from every\ndistribution in $\\mathcal{P}$. This is the prototypical hypothesis testing\nproblem that has received significant attention in statistics and, more\nrecently, in theoretical computer science.\n  The sample complexity of this general inference task depends on the\nunderlying family $\\mathcal{P}$. The gold standard in distribution property\ntesting is to design sample-optimal and computationally efficient algorithms\nfor this task. The main contribution of this work is a simple and general\ntesting technique that is applicable to all distribution families whose Fourier\nspectrum satisfies a certain approximate sparsity property. To the best of our\nknowledge, ours is the first use of the Fourier transform in the context of\ndistribution testing.\n  We apply our Fourier-based framework to obtain near sample-optimal and\ncomputationally efficient testers for the following fundamental distribution\nfamilies: Sums of Independent Integer Random Variables (SIIRVs), Poisson\nMultinomial Distributions (PMDs), and Discrete Log-Concave Distributions. For\nthe first two, ours are the first non-trivial testers in the literature, vastly\ngeneralizing previous work on testing Poisson Binomial Distributions. For the\nthird, our tester improves on prior work in both sample and time complexity. \n\n"}
{"id": "1706.06184", "contents": "Title: On heavy-tail phenomena in some large deviations problems Abstract: In this paper, we revisit the proof of the large deviations principle of\nWiener chaoses partially given by Borel, and then by Ledoux in its full form.\nWe show that some heavy-tail phenomena observed in large deviations can be\nexplained by the same mechanism as for the Wiener chaoses, meaning that the\ndeviations are created, in a sense, by translations. More precisely, we prove a\ngeneral large deviations principle for a certain class of functionals $f_n :\n\\mathbb{R}^n \\to \\mathcal{X}$, where $\\mathcal{X}$ is some metric space, under\nthe $n$-fold probability measure $\\nu_{\\alpha}^n$, where $\\nu_{\\alpha}\n=Y_{\\alpha}^{-1}e^{-|x|^{\\alpha}}dx$, $\\alpha \\in (0,2]$, for which the large\ndeviations are due to translations. We retrieve, as an application, the large\ndeviations principles known for the Wigner matrices without Gaussian tails, of\nthe empirical spectral measure by Bordenave and Caputo, the largest eigenvalue\nand traces of polynomials by the author. We also apply our large deviations\nresult to the last-passage time, which yields a large deviations principle when\nthe weights have the density $Z_{\\alpha}^{-1} e^{-x^{\\alpha}}$ with respect to\nLebesgue measure on $\\mathbb{R}_+$, with $\\alpha \\in (0,1)$. \n\n"}
{"id": "1706.06976", "contents": "Title: The effect of the spatial domain in FANOVA models with ARH(1) error term Abstract: Functional Analysis of Variance (FANOVA) from Hilbert-valued correlated data\nwith spatial rectangular or circular supports is analyzed, when Dirichlet\nconditions are assumed on the boundary. Specifically, a Hilbert-valued fixed\neffect model with error term defined from an Autoregressive Hilbertian process\nof order one (ARH(1) process) is considered, extending the formulation given in\nRuiz-Medina (2016). A new statistical test is also derived to contrast the\nsignificance of the functional fixed effect parameters. The Dirichlet\nconditions established at the boundary affect the dependence range of the\ncorrelated error term. While the rate of convergence to zero of the eigenvalues\nof the covariance kernels, characterizing the Gaussian functional error\ncomponents, directly affects the stability of the generalized least-squares\nparameter estimation problem. A simulation study and a real-data application\nrelated to fMRI analysis are undertaken to illustrate the performance of the\nparameter estimator and statistical test derived. \n\n"}
{"id": "1706.07685", "contents": "Title: Model choice in separate families: A comparison between the FBST and the\n  Cox test Abstract: Tests of separate families of hypotheses were initially considered by Cox\n(1961,1962) In this work, the Fully Bayesian Significance Test, FBST, is\nevaluated for discriminating between the lognormal, gamma and Weibull models\nwhose families of distributions are separate. Considering a linear mixture\nmodel including all candidate distributions, the FBST tests the hypotheses on\nthe mixture weights in order to calculate the evidence measure in favor of each\none. Additionally, the density functions of the mixture components are\nreparametrized in terms of the common parameters, the mean and the variance of\nthe population, since the comparison between the models is based on the same\ndataset, i.e, on the same population. Reparametrizing the models in terms of\nthe common parameters also allows one to reduce the number of the parameters to\nbe estimated. In order to evaluate the performance of the procedure, some\nnumerical results based on simulated sample points are given. In these\nsimulations, the results of FBST are compared with those of the Cox test. Two\napplications examples illustrating the procedure for uncensored dataset are\nalso presented.\n  Keywords: Model choice; Separate Models; Mixture model; Significance test;\nFBST; Cox Test \n\n"}
{"id": "1706.07767", "contents": "Title: Fully Bayesian Penalized Regression with a Generalized Bridge Prior Abstract: We consider penalized regression models under a unified framework where the\nparticular method is determined by the form of the penalty term. We propose a\nfully Bayesian approach that incorporates both sparse and dense settings and\nshow how to use a type of model averaging approach to eliminate the nuisance\npenalty parameters and perform inference through the marginal posterior\ndistribution of the regression coefficients. We establish tail robustness of\nthe resulting estimator as well as conditional and marginal posterior\nconsistency. We develop an efficient component-wise Markov chain Monte Carlo\nalgorithm for sampling. Numerical results show that the method tends to select\nthe optimal penalty and performs well in both variable selection and prediction\nand is comparable to, and often better than alternative methods. Both simulated\nand real data examples are provided. \n\n"}
{"id": "1706.09726", "contents": "Title: Hausdorff Dimension of the Record Set of a Fractional Brownian Motion Abstract: We prove that the Hausdorff dimension of the record set of a fractional\nBrownian motion with Hurst parameter $H$ equals $H$. \n\n"}
{"id": "1706.09924", "contents": "Title: Deep factorisation of the stable process III: Radial excursion theory\n  and the point of closest reach Abstract: In this paper, we continue our understanding of the stable process from the\nperspective of the theory of self-similar Markov processes in the spirit of the\nrecent papers of Kyprianou (2016) and Kyprianou et al. (2017). In particular,\nwe turn our attention to the case of $d$-dimensional isotropic stable process,\nfor $d\\geq 2$. Using a completely new approach we consider the distribution of\nthe point of closest reach. This leads us to a number of other substantial new\nresults for this class of stable processes. We engage with a new radial\nexcursion theory, never before used, from which we develop the classical\nBlumenthal-Getoor-Ray identities for first entry/exit into a ball, cf.\nBlumenthal et al. (1961), to the setting of $n$-tuple laws. We identify\nexplicitly the stationary distribution of the stable process when reflected in\nits running radial supremum. Moreover, we provide a representation of the\nWiener-Hopf factorisation of the MAP that underlies the stable process through\nthe Lamperti-Kiu transform. \n\n"}
{"id": "1707.00308", "contents": "Title: Distributional Lattices on Riemannian symmetric spaces Abstract: A Riemannian symmetric space is a Riemannian manifold in which it is possible\nto reflect all geodesics through a point by an isometry of the space. On such\nspaces, we introduce the notion of a distributional lattice, generalizing the\nnotion of lattice. Distributional lattices exist in any Riemannian symmetric\nspace: the Voronoi tessellation of a stationary Poisson point process is an\nexample. We show that for an appropriate notion of amenability, the amenability\nof a distributional lattice is equivalent to the amenability of the ambient\nspace. Using this equivalence, we show that the simple random walk on any\ndistributional lattice in a nonamenable space has positive embedded speed. For\nnonpositively curved, simply connected spaces, we show that the simple random\nwalk on a Poisson--Voronoi tessellation has positive graph speed by developing\nsome additional structure for Poisson--Voronoi tessellations. \n\n"}
{"id": "1707.00732", "contents": "Title: Probability tilting of compensated fragmentations Abstract: Fragmentation processes are part of a broad class of models describing the\nevolution of a system of particles which split apart at random. These models\nare widely used in biology, materials science and nuclear physics, and their\nasymptotic behaviour at large times is interesting both mathematically and\npractically. The spine decomposition is a key tool in its study. In this work,\nwe consider the class of compensated fragmentations, or homogeneous\ngrowth-fragmentations, recently defined by Bertoin. We give a complete spine\ndecomposition of these processes in terms of a L\\'evy process with immigration,\nand apply our result to study the asymptotic properties of the derivative\nmartingale. \n\n"}
{"id": "1707.01694", "contents": "Title: Sparsity information and regularization in the horseshoe and other\n  shrinkage priors Abstract: The horseshoe prior has proven to be a noteworthy alternative for sparse\nBayesian estimation, but has previously suffered from two problems. First,\nthere has been no systematic way of specifying a prior for the global shrinkage\nhyperparameter based on the prior information about the degree of sparsity in\nthe parameter vector. Second, the horseshoe prior has the undesired property\nthat there is no possibility of specifying separately information about\nsparsity and the amount of regularization for the largest coefficients, which\ncan be problematic with weakly identified parameters, such as the logistic\nregression coefficients in the case of data separation. This paper proposes\nsolutions to both of these problems. We introduce a concept of effective number\nof nonzero parameters, show an intuitive way of formulating the prior for the\nglobal hyperparameter based on the sparsity assumptions, and argue that the\nprevious default choices are dubious based on their tendency to favor solutions\nwith more unshrunk parameters than we typically expect a priori. Moreover, we\nintroduce a generalization to the horseshoe prior, called the regularized\nhorseshoe, that allows us to specify a minimum level of regularization to the\nlargest values. We show that the new prior can be considered as the continuous\ncounterpart of the spike-and-slab prior with a finite slab width, whereas the\noriginal horseshoe resembles the spike-and-slab with an infinitely wide slab.\nNumerical experiments on synthetic and real world data illustrate the benefit\nof both of these theoretical advances. \n\n"}
{"id": "1707.02333", "contents": "Title: Robust Wald-type tests for non-homogeneous observations based on minimum\n  density power divergence estimator Abstract: This paper considers the problem of robust hypothesis testing under\nnon-identically distributed data. We propose Wald-type tests for both simple\nand composite hypothesis for independent but non-homogeneous observations based\non the robust minimum density power divergence estimator of the common\nunderlying parameter. Asymptotic and theoretical robustness properties of the\nproposed tests have been discussed. Application to the problem of testing the\ngeneral linear hypothesis in a generalized linear model with fixed-design has\nbeen considered in detail with specific illustrations for its special cases\nunder normal and Poisson distributions. \n\n"}
{"id": "1707.02507", "contents": "Title: Assouad dimension of random processes Abstract: In this paper we study the Assouad dimension of graphs of certain L\\'evy\nprocesses and functions defined by stochastic integrals. We do this by\nintroducing a convenient condition which guarantees a graph to have full\nAssouad dimension and then show that graphs of our studied processes satisfy\nthis condition. \n\n"}
{"id": "1707.04730", "contents": "Title: Reconstructing random jigsaws Abstract: A colouring of the edges of an $n \\times n$ grid is said to be\n\\emph{reconstructible} if the colouring is uniquely determined by the multiset\nof its $n^2$ \\emph{tiles}, where the tile corresponding to a vertex of the grid\nspecifies the colours of the edges incident to that vertex in some fixed order.\nIn 2015, Mossel and Ross asked the following question: if the edges of an $n\n\\times n$ grid are coloured independently and uniformly at random using\n$q=q(n)$ different colours, then is the resulting colouring reconstructible\nwith high probability? From below, Mossel and Ross showed that such a colouring\nis not reconstructible when $q = o(n^{2/3})$ and from above, Bordenave, Feige\nand Mossel and Nenadov, Pfister and Steger independently showed, for any fixed\n$\\epsilon > 0$, that such a colouring is reconstructible when $q \\ge\nn^{1+\\epsilon}$. Here, we improve on these results and prove the following:\nthere exist absolute constants $C, c > 0$ such that, as $n \\to \\infty$, the\nprobability that a random colouring as above is reconstructible tends to $1$ if\n$q \\ge Cn$ and to $0$ if $q \\le cn$. \n\n"}
{"id": "1707.07571", "contents": "Title: Asymptotic properties of the density of particles in $\\beta$-ensembles Abstract: We extend recent results on the Asymptotic Equipartition Property for the\ndensity of $n$ particles in $\\beta$-ensembles, as $n$ tends to infinity. We\nprove the Large Deviation Principle of the log-density for a general potential\nand the mod-gaussian convergence in the classical examples. \n\n"}
{"id": "1707.07762", "contents": "Title: On computing distributions of products of non-negative independent\n  random variables Abstract: We introduce a new functional representation of probability density functions\n(PDFs) of non-negative random variables via a product of a monomial factor and\nlinear combinations of decaying exponentials with complex exponents. This\napproximate representation of PDFs is obtained for any finite, user-selected\naccuracy. Using a fast algorithm involving Hankel matrices, we develop a\ngeneral numerical method for computing the PDF of the sums, products, or\nquotients of any number of non-negative random variables yielding the result in\nthe same type of functional representation. We present several examples to\ndemonstrate the accuracy of the approach. \n\n"}
{"id": "1707.07869", "contents": "Title: Quenched mass transport of particles towards a target Abstract: We consider the stochastic target problem of finding the collection of\ninitial laws of a mean-field stochastic differential equation such that we can\ncontrol its evolution to ensure that it reaches a prescribed set of terminal\nprobability distributions, at a fixed time horizon. Here, laws are considered\nconditionally to the path of the Brownian motion that drives the system. We\nestablish a version of the geometric dynamic programming principle for the\nassociated reachability sets and prove that the corresponding value function is\na viscosity solution of a geometric partial differential equation. This\nprovides a characterization of the initial masses that can be almost-surely\ntransported towards a given target, along the paths of a stochastic\ndifferential equation. Our results extend [16] to our setting. \n\n"}
{"id": "1707.08367", "contents": "Title: Generalizations of Distributions Related to ($k_1,k_2$)-runs Abstract: The paper deals with three generalized dependent setups arising from a\nsequence of Bernoulli trials. Various distributional properties, such as\nprobability generating function, probability mass function and moments are\ndiscussed for these setups and their waiting time. Also, explicit forms of\nprobability generating function and probability mass function are obtained.\nFinally, two applications to demonstrate the relevance of the results are\ngiven. \n\n"}
{"id": "1707.08405", "contents": "Title: Gaussian Processes for Individualized Continuous Treatment Rule\n  Estimation Abstract: Individualized treatment rule (ITR) recommends treatment on the basis of\nindividual patient characteristics and the previous history of applied\ntreatments and their outcomes. Despite the fact there are many ways to estimate\nITR with binary treatment, algorithms for continuous treatment have only just\nstarted to emerge. We propose a novel approach to continuous ITR estimation\nbased on explicit modelling of uncertainty in the subject's outcome as well as\ndirect estimation of the mean outcome using gaussian process regression. Our\nmethod incorporates two intuitively appealing properties - it is more inclined\nto give a treatment with the outcome of higher expected value and lower\nvariance. Experiments show that this direct incorporation of the uncertainty\ninto ITR estimation process allows to select better treatment than standard\nindirect approach that just models the average. Compared to the competitors\n(including OWL), the proposed method shows improved performance in terms of\nvalue function maximization, has better interpretability, and could be easier\ngeneralized to multiple interdependent continuous treatments setting. \n\n"}
{"id": "1707.08507", "contents": "Title: A central limit theorem for the realised covariation of a bivariate\n  Brownian semistationary process Abstract: This article presents a weak law of large numbers and a central limit theorem\nfor the scaled realised covariation of a bivariate Brownian semistationary\nprocess. The novelty of our results lies in the fact that we derive the\nsuitable asymptotic theory both in a multivariate setting and outside the\nclassical semimartingale framework. The proofs rely heavily on recent\ndevelopments in Malliavin calculus. \n\n"}
{"id": "1707.08889", "contents": "Title: Stochastic Evolution Equation Driven by Teugels Martingale and Its\n  Optimal Control Abstract: The paper is concerned with a class of stochastic evolution equations in\nHilbert space with random coefficients driven by Teugel's martingales and an\nindependent multi-dimensional Brownian motion and its optimal control problem.\nHere Teugels martingales are a family of pairwise strongly orthonormal\nmartingales associated with L\\'evy processes (see Nualart and Schoutens).\n  There are three major ingredients. The first is to prove the existence and\nuniqueness of the solutions by continuous dependence theorem of solutions\ncombining with the parameter extension method. The second is to establish the\nstochastic maximum principle and verification theorem for our optimal control\nproblem by the classic convex variation method and dual technique. The third is\nto represent an example of a Cauchy problem for a controlled stochastic partial\ndifferential equation driven by Teugels martingales which our theoretical\nresults can solve. \n\n"}
{"id": "1708.00205", "contents": "Title: Dynamic Linear Discriminant Analysis in High Dimensional Space Abstract: High-dimensional data that evolve dynamically feature predominantly in the\nmodern data era. As a partial response to this, recent years have seen\nincreasing emphasis to address the dimensionality challenge. However, the\nnon-static nature of these datasets is largely ignored. This paper addresses\nboth challenges by proposing a novel yet simple dynamic linear programming\ndiscriminant (DLPD) rule for binary classification. Different from the usual\nstatic linear discriminant analysis, the new method is able to capture the\nchanging distributions of the underlying populations by modeling their means\nand covariances as smooth functions of covariates of interest. Under an\napproximate sparse condition, we show that the conditional misclassification\nrate of the DLPD rule converges to the Bayes risk in probability uniformly over\nthe range of the variables used for modeling the dynamics, when the\ndimensionality is allowed to grow exponentially with the sample size. The\nminimax lower bound of the estimation of the Bayes risk is also established,\nimplying that the misclassification rate of our proposed rule is minimax-rate\noptimal. The promising performance of the DLPD rule is illustrated via\nextensive simulation studies and the analysis of a breast cancer dataset. \n\n"}
{"id": "1708.01390", "contents": "Title: Smooth invariant densities for random switching on the torus Abstract: We consider a random dynamical system obtained by switching between the flows\ngenerated by two smooth vector fields on the 2d-torus, with the random\nswitchings happening according to a Poisson process. Assuming that the driving\nvector fields are transversal to each other at all points of the torus and that\neach of them allows for a smooth invariant density and no periodic orbits, we\nprove that the switched system also has a smooth invariant density, for every\nswitching rate. Our approach is based on an integration by parts formula\ninspired by techniques from Malliavin calculus. \n\n"}
{"id": "1708.01961", "contents": "Title: Long time behavior of Gross-Pitaevskii equation at positive temperature Abstract: The stochastic Gross-Pitaevskii equation is used as a model to describe\nBose-Einstein condensation at positive temperature. The equation is a complex\nGinzburg Landau equation with a trapping potential and an additive space-time\nwhite noise. Two important questions for this system are the global existence\nof solutions in the support of the Gibbs measure, and the convergence of those\nsolutions to the equilibrium for large time. In this paper, we give a proof of\nthese two results in one space dimension. In order to prove the convergence to\nequilibrium, we use the associated purely dissipative equation as an auxiliary\nequation, for which the convergence may be obtained using standard techniques.\nGlobal existence is obtained for all initial data, and not almost surely with\nrespect to the invariant measure. \n\n"}
{"id": "1708.01999", "contents": "Title: Adaptive Energy Saving Approximation for Random Stationary Processes Abstract: We consider a stationary process (with either discrete or continuous time)\nand find an adaptive approximating stationary process combining approximation\nquality and supplementary good properties that can be interpreted as additional\nsmoothness or small expense of energy. The problem is solved in terms of the\nspectral characteristics of the approximated process by using classical\nanalytic methods from prediction theory. \n\n"}
{"id": "1708.02107", "contents": "Title: Adaptive Estimation of Nonparametric Geometric Graphs Abstract: This article studies the recovery of graphons when they are convolution\nkernels on compact (symmetric) metric spaces. This case is of particular\ninterest since it covers the situation where the probability of an edge depends\nonly on some unknown nonparametric function of the distance between latent\npoints, referred to as Nonparametric Geometric Graphs (NGG). In this setting,\nadaptive estimation of NGG is possible using a spectral procedure combined with\na Goldenshluger-Lepski adaptation method. The latent spaces covered by our\nframework encompass (among others) compact symmetric spaces of rank one, namely\nreal spheres and projective spaces. For these latter, explicit computations of\nthe eigen-basis and of the model complexity can be achieved, leading to\nquantitative non-asymptotic results. The time complexity of our method scales\ncubicly in the size of the graph and exponentially in the regularity of the\ngraphon. Hence, this paper offers an algorithmically and theoretically\nefficient procedure to estimate smooth NGG. As a by product, this paper shows a\nnon-asymptotic concentration result on the spectrum of integral operators\ndefined by symmetric kernels (not necessarily positive). \n\n"}
{"id": "1708.02495", "contents": "Title: Local Gaussian cross-spectrum analysis Abstract: The ordinary spectrum is restricted in its applications, since it is based on\nthe second order moments (auto and cross-covariances). Alternative approaches\nto spectrum analysis have been investigated based on other measures of\ndependence. One such approach was developed for univariate time series by the\nauthors of this paper using the local Gaussian auto-spectrum based on the local\nGaussian auto-correlations. This makes it possible to detect local structures\nin univariate time series that looks like white noise when investigated by the\nordinary auto-spectrum. In this paper the local Gaussian approach is extended\nto a local Gaussian cross-spectrum for multivariate time series. The local\nGaussian cross-spectrum has the desirable property that it coincides with the\nordinary cross-spectrum for Gaussian time series, which implies that it can be\nused to detect non-Gaussian traits in the time series under investigation. In\nparticular: If the ordinary spectrum is flat, then peaks and troughs of the\nlocal Gaussian spectrum can indicate nonlinear traits, which potentially might\nreveal local periodic phenomena that goes undetected in an ordinary spectral\nanalysis. \n\n"}
{"id": "1708.02521", "contents": "Title: Stein's method for multivariate Brownian approximations of sums under\n  dependence Abstract: We use Stein's method to obtain a bound on the distance between scaled\n$p$-dimensional random walks and a $p$-dimensional (correlated) Brownian\nMotion. We consider dependence schemes including those in which the summands in\nscaled sums are weakly dependent and their $p$ components are strongly\ncorrelated. As an example application, we prove a functional limit theorem for\nexceedances in an $m$-scans process, together with a bound on the rate of\nconvergence. We also find a bound on the rate of convergence of scaled\nU-statistics to Brownian Motion, representing an example of a sum of strongly\ndependent terms. \n\n"}
{"id": "1708.03120", "contents": "Title: On sparsity, power-law and clustering properties of graphex processes Abstract: This paper investigates properties of the class of graphs based on\nexchangeable point processes. We provide asymptotic expressions for the number\nof edges, number of nodes and degree distributions, identifying four regimes:\n(i) a dense regime, (ii) a sparse almost dense regime, (iii) a sparse regime\nwith power-law behaviour, and (iv) an almost extremely sparse regime. We show\nthat under mild assumptions, both the global and local clustering coefficients\nconverge to constants which may or may not be the same. We also derive a\ncentral limit theorem for the number of nodes. Finally, we propose a class of\nmodels within this framework where one can separately control the latent\nstructure and the global sparsity/power-law properties of the graph. \n\n"}
{"id": "1708.03813", "contents": "Title: Weighted entropy and optimal portfolios for risk-averse Kelly\n  investments Abstract: Following a series of works on capital growth investment, we analyse\nlog-optimal portfolios where the return evaluation includes `weights' of\ndifferent outcomes. The results are twofold: (A) under certain conditions, the\nlogarithmic growth rate leads to a supermartingale, and (B) the optimal\n(martingale) investment strategy is a proportional betting. We focus on\nproperties of the optimal portfolios and discuss a number of simple examples\nextending the well-known Kelly betting scheme.\n  An important restriction is that the investment does not exceed the current\ncapital value and allows the trader to cover the worst possible losses.\n  The paper deals with a class of discrete-time models. A continuous-time\nextension is a topic of an ongoing study. \n\n"}
{"id": "1708.04519", "contents": "Title: Stable matchings in high dimensions via the Poisson-weighted infinite\n  tree Abstract: We consider the stable matching of two independent Poisson processes in\n$\\mathbb{R}^d$ under an asymmetric color restriction. Blue points can only\nmatch to red points, while red points can match to points of either color. It\nis unknown whether there exists a choice of intensities of the red and blue\nprocesses under which all points are matched. We prove that for any fixed\nintensities, there are unmatched blue points in sufficiently high dimension.\nIndeed, if the ratio of red to blue intensities is $\\rho$ then the intensity of\nunmatched blue points converges to $e^{-\\rho}/(1+\\rho)$ as $d\\to\\infty$. We\nalso establish analogous results for certain multi-color variants. Our proof\nuses stable matching on the Poisson-weighted infinite tree (PWIT), which can be\nanalyzed via differential equations. The PWIT has been used in many settings as\na scaling limit for models involving complete graphs with independent edge\nweights, but we believe that this is the first rigorous application to\nhigh-dimensional Euclidean space. Finally, we analyze the asymmetric matching\nproblem under a hierarchical metric, and show that there are unmatched points\nfor all intensities. \n\n"}
{"id": "1708.06080", "contents": "Title: First passage problems for upwards skip-free random walks via the\n  $\\Phi,W,Z$ paradigm Abstract: We develop the theory of the $W$ and $Z$ scale functions for right-continuous\n(upwards skip-free) discrete-time discrete-space random walks, along the lines\nof the analogue theory for spectrally negative L\\'evy processes. Notably, we\nintroduce for the first time in this context the one and two-parameter scale\nfunctions $Z$, which appear for example in the joint problem of deficit at ruin\nand time of ruin, and in problems concerning the walk reflected at an upper\nbarrier. Comparisons are made between the various theories of scale functions\nas one makes time and/or space continuous. The theory is shown to be fruitful\nby providing a convenient unified framework for studying dividends-capital\ninjection problems under various objectives, for the so-called compound\nbinomial risk model of actuarial science. \n\n"}
{"id": "1708.06332", "contents": "Title: Efficient Nonparametric Bayesian Inference For X-Ray Transforms Abstract: We consider the statistical inverse problem of recovering a function $f: M\n\\to \\mathbb R$, where $M$ is a smooth compact Riemannian manifold with\nboundary, from measurements of general $X$-ray transforms $I_a(f)$ of $f$,\ncorrupted by additive Gaussian noise. For $M$ equal to the unit disk with\n`flat' geometry and $a=0$ this reduces to the standard Radon transform, but our\ngeneral setting allows for anisotropic media $M$ and can further model local\n`attenuation' effects -- both highly relevant in practical imaging problems\nsuch as SPECT tomography. We propose a nonparametric Bayesian inference\napproach based on standard Gaussian process priors for $f$. The posterior\nreconstruction of $f$ corresponds to a Tikhonov regulariser with a reproducing\nkernel Hilbert space norm penalty that does not require the calculation of the\nsingular value decomposition of the forward operator $I_a$. We prove\nBernstein-von Mises theorems that entail that posterior-based inferences such\nas credible sets are valid and optimal from a frequentist point of view for a\nlarge family of semi-parametric aspects of $f$. In particular we derive the\nasymptotic distribution of smooth linear functionals of the Tikhonov\nregulariser, which is shown to attain the semi-parametric Cram\\'er-Rao\ninformation bound. The proofs rely on an invertibility result for the `Fisher\ninformation' operator $I_a^*I_a$ between suitable function spaces, a result of\nindependent interest that relies on techniques from microlocal analysis. We\nillustrate the performance of the proposed method via simulations in various\nsettings. \n\n"}
{"id": "1708.06443", "contents": "Title: Bias Reduction in Instrumental Variable Estimation through First-Stage\n  Shrinkage Abstract: The two-stage least-squares (2SLS) estimator is known to be biased when its\nfirst-stage fit is poor. I show that better first-stage prediction can\nalleviate this bias. In a two-stage linear regression model with Normal noise,\nI consider shrinkage in the estimation of the first-stage instrumental variable\ncoefficients. For at least four instrumental variables and a single endogenous\nregressor, I establish that the standard 2SLS estimator is dominated with\nrespect to bias. The dominating IV estimator applies James-Stein type shrinkage\nin a first-stage high-dimensional Normal-means problem followed by a\ncontrol-function approach in the second stage. It preserves invariances of the\nstructural instrumental variable equations. \n\n"}
{"id": "1708.07394", "contents": "Title: Second order approximations for limit order books Abstract: In this paper we derive a second order approximation for an infinite\ndimensional limit order book model, in which the dynamics of the incoming order\nflow is allowed to depend on the current market price as well as on a volume\nindicator (e.g.~the volume standing at the top of the book). We study the\nfluctuations of the price and volume process relative to their first order\napproximation given in ODE-PDE form under two different scaling regimes. In the\nfirst case we suppose that price changes are really rare, yielding a constant\nfirst order approximation for the price. This leads to a measure-valued SDE\ndriven by an infinite dimensional Brownian motion in the second order\napproximation of the volume process. In the second case we use a slower\nrescaling rate, which leads to a non-degenerate first order approximation and\ngives a PDE with random coefficients in the second order approximation for the\nvolume process. Our results can be used to derive confidence intervals for\nmodels of optimal portfolio liquidation under market impact. \n\n"}
{"id": "1708.08215", "contents": "Title: Counting quadrant walks via Tutte's invariant method Abstract: In the 1970s, William Tutte developed a clever algebraic approach, based on\ncertain \"invariants\", to solve a functional equation that arises in the\nenumeration of properly colored triangulations. The enumeration of plane\nlattice walks confined to the first quadrant is governed by similar equations,\nand has led in the past 20 years to a rich collection of attractive results\ndealing with the nature (algebraic, D-finite or not) of the associated\ngenerating function, depending on the set of allowed steps, taken in $\\{-1,\n0,1\\}^2$.\n  We first adapt Tutte's approach to prove (or reprove) the algebraicity of all\nquadrant models known or conjectured to be algebraic. This includes Gessel's\nfamous model, and the first proof ever found for one model with weighted steps.\nTo be applicable, the method requires the existence of two rational functions\ncalled invariant and decoupling function respectively. When they exist,\nalgebraicity follows almost automatically.\n  Then, we move to a complex analytic viewpoint that has already proved very\npowerful, leading in particular to integral expressions for the generating\nfunction in the non-D-finite cases, as well as to proofs of non-D-finiteness.\nWe develop in this context a weaker notion of invariant. Now all quadrant\nmodels have invariants, and for those that have in addition a decoupling\nfunction, we obtain integral-free expressions for the generating function, and\na proof that this series is D-algebraic (that is, satisfies polynomial\ndifferential equations). \n\n"}
{"id": "1708.08278", "contents": "Title: Why optional stopping can be a problem for Bayesians Abstract: Recently, optional stopping has been a subject of debate in the Bayesian\npsychology community. Rouder (2014) argues that optional stopping is no problem\nfor Bayesians, and even recommends the use of optional stopping in practice, as\ndo Wagenmakers et al. (2012). This article addresses the question whether\noptional stopping is problematic for Bayesian methods, and specifies under\nwhich circumstances and in which sense it is and is not. By slightly varying\nand extending Rouder's (2014) experiments, we illustrate that, as soon as the\nparameters of interest are equipped with default or pragmatic priors - which\nmeans, in most practical applications of Bayes factor hypothesis testing -\nresilience to optional stopping can break down. We distinguish between three\ntypes of default priors, each having their own specific issues with optional\nstopping, ranging from no-problem-at-all (Type 0 priors) to quite severe (Type\nII priors). \n\n"}
{"id": "1708.08676", "contents": "Title: Testing k-monotonicity of a discrete distribution. Application to the\n  estimation of the number of classes in a population Abstract: We develop here several goodness-of-fit tests for testing the k-monotonicity\nof a discrete density, based on the empirical distribution of the observations.\nOur tests are non-parametric, easy to implement and are proved to be\nasymptotically of the desired level and consistent. We propose an estimator of\nthe degree of k-monotonicity of the distribution based on the non-parametric\ngoodness-of-fit tests. We apply our work to the estimation of the total number\nof classes in a population. A large simulation study allows to assess the\nperformances of our procedures. \n\n"}
{"id": "1708.09677", "contents": "Title: Tunneling behavior of Ising and Potts models in the low-temperature\n  regime Abstract: We consider the ferromagnetic $q$-state Potts model with zero external field\nin a finite volume and assume that the stochastic evolution of this system is\ndescribed by a Glauber-type dynamics parametrized by the inverse temperature\n$\\beta$. Our analysis concerns the low-temperature regime $\\beta \\to \\infty$,\nin which this multi-spin system has $q$ stable equilibria, corresponding to the\nconfigurations where all spins are equal. Focusing on grid graphs with various\nboundary conditions, we study the tunneling phenomena of the $q$-state Potts\nmodel. More specifically, we describe the asymptotic behavior of the first\nhitting times between stable equilibria as $\\beta \\to \\infty$ in probability,\nin expectation, and in distribution and obtain tight bounds on the mixing time\nas side-result. In the special case $q=2$, our results characterize the\ntunneling behavior of the Ising model on grid graphs. \n\n"}
{"id": "1709.00092", "contents": "Title: RANK: Large-Scale Inference with Graphical Nonlinear Knockoffs Abstract: Power and reproducibility are key to enabling refined scientific discoveries\nin contemporary big data applications with general high-dimensional nonlinear\nmodels. In this paper, we provide theoretical foundations on the power and\nrobustness for the model-free knockoffs procedure introduced recently in\nCand\\`{e}s, Fan, Janson and Lv (2016) in high-dimensional setting when the\ncovariate distribution is characterized by Gaussian graphical model. We\nestablish that under mild regularity conditions, the power of the oracle\nknockoffs procedure with known covariate distribution in high-dimensional\nlinear models is asymptotically one as sample size goes to infinity. When\nmoving away from the ideal case, we suggest the modified model-free knockoffs\nmethod called graphical nonlinear knockoffs (RANK) to accommodate the unknown\ncovariate distribution. We provide theoretical justifications on the robustness\nof our modified procedure by showing that the false discovery rate (FDR) is\nasymptotically controlled at the target level and the power is asymptotically\none with the estimated covariate distribution. To the best of our knowledge,\nthis is the first formal theoretical result on the power for the knockoffs\nprocedure. Simulation results demonstrate that compared to existing approaches,\nour method performs competitively in both FDR control and power. A real data\nset is analyzed to further assess the performance of the suggested knockoffs\nprocedure. \n\n"}
{"id": "1709.00232", "contents": "Title: Estimating functions for jump-diffusions Abstract: Asymptotic theory for approximate martingale estimating functions is\ngeneralised to diffusions with finite-activity jumps, when the sampling\nfrequency and terminal sampling time go to infinity. Rate optimality and\nefficiency are of particular concern. Under mild assumptions, it is shown that\nestimators of drift, diffusion, and jump parameters are consistent and\nasymptotically normal, as well as rate-optimal for the drift and jump\nparameters. Additional conditions are derived, which ensure rate-optimality for\nthe diffusion parameter as well as efficiency for all parameters. The findings\nindicate a potentially fruitful direction for the further development of\nestimation for jump-diffusions. \n\n"}
{"id": "1709.01449", "contents": "Title: Visualization in Bayesian workflow Abstract: Bayesian data analysis is about more than just computing a posterior\ndistribution, and Bayesian visualization is about more than trace plots of\nMarkov chains. Practical Bayesian data analysis, like all data analysis, is an\niterative process of model building, inference, model checking and evaluation,\nand model expansion. Visualization is helpful in each of these stages of the\nBayesian workflow and it is indispensable when drawing inferences from the\ntypes of modern, high-dimensional models that are used by applied researchers. \n\n"}
{"id": "1709.01498", "contents": "Title: The traffic distribution of the squared unimodular random matrix and a\n  formula for the moments of its ESD Abstract: The $k$-th moment of the mean empirical spectral distribution of the squared\nunimodular random matrix of dimension $N$ can be expressed in the form\n$N^{-2k-1} Q_k(N)$, where $Q_k(x)$ is a polynomial of degree $k+1$ with integer\ncoefficients. We use tools from traffic-free probability to express the\ncoefficients of this polynomial in terms of the number of quotients, with a\ncertain property, of some colored directed graphs. The obtained result\ndisproves the formula conjectured in A. Lakshminarayan, Z. Puchala, K.\nZyczkowski (2014). \n\n"}
{"id": "1709.01577", "contents": "Title: Auto-G-Computation of Causal Effects on a Network Abstract: Methods for inferring average causal effects have traditionally relied on two\nkey assumptions: (i) the intervention received by one unit cannot causally\ninfluence the outcome of another; and (ii) units can be organized into\nnon-overlapping groups such that outcomes of units in separate groups are\nindependent. In this paper, we develop new statistical methods for causal\ninference based on a single realization of a network of connected units for\nwhich neither assumption (i) nor (ii) holds. The proposed approach allows both\nfor arbitrary forms of interference, whereby the outcome of a unit may depend\non interventions received by other units with whom a network path through\nconnected units exists; and long range dependence, whereby outcomes for any two\nunits likewise connected by a path in the network may be dependent. Under\nnetwork versions of consistency and no unobserved confounding, inference is\nmade tractable by an assumption that the network's outcome, treatment and\ncovariate vectors are a single realization of a certain chain graph model. This\nassumption allows inferences about various network causal effects via the\nauto-g-computation algorithm, a network generalization of Robins' well-known\ng-computation algorithm previously described for causal inference under\nassumptions (i) and (ii). \n\n"}
{"id": "1709.01589", "contents": "Title: An active-learning algorithm that combines sparse polynomial chaos\n  expansions and bootstrap for structural reliability analysis Abstract: Polynomial chaos expansions (PCE) have seen widespread use in the context of\nuncertainty quantification. However, their application to structural\nreliability problems has been hindered by the limited performance of PCE in the\ntails of the model response and due to the lack of local metamodel error\nestimates. We propose a new method to provide local metamodel error estimates\nbased on bootstrap resampling and sparse PCE. An initial experimental design is\niteratively updated based on the current estimation of the limit-state surface\nin an active learning algorithm. The greedy algorithm uses the bootstrap-based\nlocal error estimates for the polynomial chaos predictor to identify the best\ncandidate set of points to enrich the experimental design. We demonstrate the\neffectiveness of this approach on a well-known analytical benchmark\nrepresenting a series system, on a truss structure and on a complex realistic\nframe structure problem. \n\n"}
{"id": "1709.04102", "contents": "Title: Delay, memory, and messaging tradeoffs in distributed service systems Abstract: We consider the following distributed service model: jobs with unit mean,\nexponentially distributed, and independent processing times arrive as a Poisson\nprocess of rate $\\lambda n$, with $0<\\lambda<1$, and are immediately dispatched\nby a centralized dispatcher to one of $n$ First-In-First-Out queues associated\nwith $n$ identical servers. The dispatcher is endowed with a finite memory, and\nwith the ability to exchange messages with the servers.\n  We propose and study a resource-constrained \"pull-based\" dispatching policy\nthat involves two parameters: (i) the number of memory bits available at the\ndispatcher, and (ii) the average rate at which servers communicate with the\ndispatcher. We establish (using a fluid limit approach) that the asymptotic, as\n$n\\to\\infty$, expected queueing delay is zero when either (i) the number of\nmemory bits grows logarithmically with $n$ and the message rate grows\nsuperlinearly with $n$, or (ii) the number of memory bits grows\nsuperlogarithmically with $n$ and the message rate is at least $\\lambda n$.\nFurthermore, when the number of memory bits grows only logarithmically with $n$\nand the message rate is proportional to $n$, we obtain a closed-form expression\nfor the (now positive) asymptotic delay.\n  Finally, we demonstrate an interesting phase transition in the\nresource-constrained regime where the asymptotic delay is non-zero. In\nparticular, we show that for any given $\\alpha>0$ (no matter how small), if our\npolicy only uses a linear message rate $\\alpha n$, the resulting asymptotic\ndelay is upper bounded, uniformly over all $\\lambda<1$; this is in sharp\ncontrast to the delay obtained when no messages are used ($\\alpha = 0$), which\ngrows as $1/(1-\\lambda)$ when $\\lambda\\uparrow 1$, or when the popular\npower-of-$d$-choices is used, in which the delay grows as\n$\\log(1/(1-\\lambda))$. \n\n"}
{"id": "1709.04342", "contents": "Title: Model Selection Confidence Sets by Likelihood Ratio Testing Abstract: The traditional activity of model selection aims at discovering a single\nmodel superior to other candidate models. In the presence of pronounced noise,\nhowever, multiple models are often found to explain the same data equally well.\nTo resolve this model selection ambiguity, we introduce the general approach of\nmodel selection confidence sets (MSCSs) based on likelihood ratio testing. A\nMSCS is defined as a list of models statistically indistinguishable from the\ntrue model at a user-specified level of confidence, which extends the familiar\nnotion of confidence intervals to the model-selection framework. Our approach\nguarantees asymptotically correct coverage probability of the true model when\nboth sample size and model dimension increase. We derive conditions under which\nthe MSCS contains all the relevant information about the true model structure.\nIn addition, we propose natural statistics based on the MSCS to measure\nimportance of variables in a principled way that accounts for the overall model\nuncertainty. When the space of feasible models is large, MSCS is implemented by\nan adaptive stochastic search algorithm which samples MSCS models with high\nprobability. The MSCS methodology is illustrated through numerical experiments\non synthetic data and real data examples. \n\n"}
{"id": "1709.04840", "contents": "Title: Semi-standard partial covariance variable selection when irrepresentable\n  conditions fail Abstract: Traditional variable selection methods could fail to be sign consistent when\nirrepresentable conditions are violated. This is especially critical in\nhigh-dimensional settings when the number of predictors exceeds the sample\nsize. In this paper, we propose a new semi-standard partial covariance (SPAC)\napproach which is capable of reducing correlation effects from other covariates\nwhile fully capturing the magnitude of coefficients. The proposed SPAC is\neffective in choosing covariates which have direct effects on the response\nvariable, while eliminating the predictors which are not directly associated\nwith the response but are highly correlated with the relevant predictors. We\nshow that the proposed SPAC method with the Lasso penalty or the smoothly\nclipped absolute deviation (SCAD) penalty possesses strong sign consistency in\nhigh-dimensional settings. Numerical studies and a post-traumatic stress\ndisorder data application also confirm that the proposed method outperforms the\nexisting Lasso, adaptive Lasso, SCAD, Peter-Clark-simple algorithm, and\nfactor-adjusted regularized model selection methods when the irrepresentable\nconditions fail. \n\n"}
{"id": "1709.05328", "contents": "Title: Granger Mediation Analysis of Multiple Time Series with an Application\n  to fMRI Abstract: It becomes increasingly popular to perform mediation analysis for complex\ndata from sophisticated experimental studies. In this paper, we present Granger\nMediation Analysis (GMA), a new framework for causal mediation analysis of\nmultiple time series. This framework is motivated by a functional magnetic\nresonance imaging (fMRI) experiment where we are interested in estimating the\nmediation effects between a randomized stimulus time series and brain activity\ntime series from two brain regions. The stable unit treatment assumption for\ncausal mediation analysis is thus unrealistic for this type of time series\ndata. To address this challenge, our framework integrates two types of models:\ncausal mediation analysis across the variables and vector autoregressive models\nacross the temporal observations. We further extend this framework to handle\nmultilevel data to address individual variability and correlated errors between\nthe mediator and the outcome variables. These models not only provide valid\ncausal mediation for time series data but also model the causal dynamics across\ntime. We show that the modeling parameters in our models are identifiable, and\nwe develop computationally efficient methods to maximize the likelihood-based\noptimization criteria. Simulation studies show that our method reduces the\nestimation bias and improve statistical power, compared to existing approaches.\nOn a real fMRI data set, our approach not only infers the causal effects of\nbrain pathways but accurately captures the feedback effect of the outcome\nregion on the mediator region. \n\n"}
{"id": "1709.08151", "contents": "Title: Second order term of cover time for planar simple random walk Abstract: We consider the cover time for a simple random walk on the two-dimensional\ndiscrete torus of side length $n$. Dembo, Peres, Rosen, and Zeitouni [Ann.\nMath. 160:433-464, 2004] identified the leading term in the asymptotics for the\ncover time as $n$ goes to infinity. In this paper, we study the exact second\norder term. This is a discrete analogue of the work on the cover time for\nplanar Brownian motion by Belius and Kistler [Probab. Theory Relat Fields.\n167:461-552, 2017]. \n\n"}
{"id": "1710.00348", "contents": "Title: Large deviations for level sets of branching Brownian motion and\n  Gaussian free fields Abstract: We study deviation probabilities for the number of high positioned particles\nin branching Brownian motion, and confirm a conjecture of Derrida and Shi\n(2016). We also solve the corresponding problem for the two-dimensional\ndiscrete Gaussian free field. Our method relies on an elementary inequality for\ninhomogeneous Galton-Watson processes. \n\n"}
{"id": "1710.00894", "contents": "Title: Detecting Epistatic Selection with Partially Observed Genotype Data\n  Using Copula Graphical Models Abstract: Recombinant Inbred Lines derived from divergent parental lines can display\nextensive segregation distortion and long-range linkage disequilibrium (LD)\nbetween distant loci. These genomic signatures are consistent with epistatic\nselection during inbreeding. Epistatic interactions affect growth and fertility\ntraits or even cause complete lethality. Detecting epistasis is challenging as\nmultiple testing approaches are under-powered and true long-range LD is\ndifficult to distinguish from drift.\n  Here we develop a method for reconstructing an underlying network of genomic\nsignatures of high-dimensional epistatic selection from multi-locus genotype\ndata. The network captures the conditionally dependent short- and long-range LD\nstructure and thus reveals \"aberrant\" marker-marker associations that are due\nto epistatic selection rather than gametic linkage. The network estimation\nrelies on penalized Gaussian copula graphical models, which accounts for a\nlarge number of markers p and a small number of individuals n.\n  A multi-core implementation of our algorithm makes it feasible to estimate\nthe graph in high-dimensions also in the presence of significant portions of\nmissing data. We demonstrate the efficiency of the proposed method on simulated\ndatasets as well as on genotyping data in A.thaliana and maize. In addition, we\nimplemented the method in the R package netgwas which is freely available at\nhttps://CRAN.R-project.org/package=netgwas. \n\n"}
{"id": "1710.01147", "contents": "Title: Fractional equations via convergence of forms Abstract: We relate the convergence of time-changed processes driven by fractional\nequations to the convergence of corresponding Dirichlet forms. The fractional\nequations we dealt with are obtained by considering a general fractional\noperator in time. \n\n"}
{"id": "1710.03133", "contents": "Title: A Semi-Automatic Method for History Matching using Sequential Monte\n  Carlo Abstract: The aim of the history matching method is to locate non-implausible regions\nof the parameter space of complex deterministic or stochastic models by\nmatching model outputs with data. It does this via a series of waves where at\neach wave an emulator is fitted to a small number of training samples. An\nimplausibility measure is defined which takes into account the closeness of\nsimulated and observed outputs as well as emulator uncertainty. As the waves\nprogress, the emulator becomes more accurate so that training samples are more\nconcentrated on promising regions of the space and poorer parts of the space\nare rejected with more confidence. Whilst history matching has proved to be\nuseful, existing implementations are not fully automated and some ad-hoc\nchoices are made during the process, which involves user intervention and is\ntime consuming. This occurs especially when the non-implausible region becomes\nsmall and it is difficult to sample this space uniformly to generate new\ntraining points. In this article we develop a sequential Monte Carlo (SMC)\nalgorithm for implementing history matching that is semi-automated. Our novel\nSMC approach reveals that the history matching method yields a non-implausible\nregion that can be multi-modal, highly irregular and very difficult to sample\nuniformly. Our SMC approach offers a much more reliable sampling of the\nnon-implausible space, which requires additional computation compared to other\napproaches used in the literature. \n\n"}
{"id": "1710.03892", "contents": "Title: Variable screening with multiple studies Abstract: Advancement in technology has generated abundant high-dimensional data that\nallows integration of multiple relevant studies. Due to their huge\ncomputational advantage, variable screening methods based on marginal\ncorrelation have become promising alternatives to the popular regularization\nmethods for variable selection. However, all these screening methods are\nlimited to single study so far. In this paper, we consider a general framework\nfor variable screening with multiple related studies, and further propose a\nnovel two-step screening procedure using a self-normalized estimator for\nhigh-dimensional regression analysis in this framework. Compared to the\none-step procedure and rank-based sure independence screening (SIS) procedure,\nour procedure greatly reduces false negative errors while keeping a low false\npositive rate. Theoretically, we show that our procedure possesses the sure\nscreening property with weaker assumptions on signal strengths and allows the\nnumber of features to grow at an exponential rate of the sample size. In\naddition, we relax the commonly used normality assumption and allow\nsub-Gaussian distributions. Simulations and a real transcriptomic application\nillustrate the advantage of our method as compared to the rank-based SIS\nmethod. \n\n"}
{"id": "1710.03921", "contents": "Title: Global spectrum fluctuations for Gaussian beta ensembles: a martingale\n  approach Abstract: The paper describes the global limiting behavior of Gaussian beta ensembles\nwhere the parameter $\\beta$ is allowed to vary with the matrix size $n$. In\nparticular, we show that as $n \\to \\infty$ with $n\\beta \\to \\infty$, the\nempirical distribution converges weakly to the semicircle distribution, almost\nsurely. The Gaussian fluctuation around the limit is then derived by a\nmartingale approach. \n\n"}
{"id": "1710.04017", "contents": "Title: $\\rho$-white noise solution to 2D stochastic Euler equations Abstract: A stochastic version of 2D Euler equations with transport type noise in the\nvorticity is considered, in the framework of Albeverio--Cruzeiro theory [1]\nwhere the equation is considered with random initial conditions related to the\nso called enstrophy measure. The equation is studied by an approximation scheme\nbased on random point vortices. Stochastic processes solving the Euler\nequations are constructed and their density with respect to the enstrophy\nmeasure is proved to satisfy a continuity equation in weak form. Relevant in\ncomparison with the case without noise is the fact that here we prove a\ngradient type estimate for the density. Although we cannot prove uniqueness for\nthe continuity equation, we discuss how the gradient type estimate may be\nrelated to this open problem. \n\n"}
{"id": "1710.05248", "contents": "Title: A Nonparametric Method for Producing Isolines of Bivariate Exceedance\n  Probabilities Abstract: We present a method for drawing isolines indicating regions of equal joint\nexceedance probability for bivariate data. The method relies on bivariate\nregular variation, a dependence framework widely used for extremes. This\nframework enables drawing isolines corresponding to very low exceedance\nprobabilities and these lines may lie beyond the range of the data. The method\nwe utilize for characterizing dependence in the tail is largely nonparametric.\nFurthermore, we extend this method to the case of asymptotic independence and\npropose a procedure which smooths the transition from asymptotic independence\nin the interior to the first-order behavior on the axes. We propose a\ndiagnostic plot for assessing isoline estimate and choice of smoothing, and a\nbootstrap procedure to visually assess uncertainty. \n\n"}
{"id": "1710.05283", "contents": "Title: Uniform Consistency in Stochastic Block Model with Continuous Community\n  Label Abstract: \\cite{bickel2009nonparametric} developed a general framework to establish\nconsistency of community detection in stochastic block model (SBM). In most\napplications of this framework, the community label is discrete. For example,\nin \\citep{bickel2009nonparametric,zhao2012consistency} the degree corrected SBM\nis assumed to have a discrete degree parameter. In this paper, we generalize\nthe method of \\cite{bickel2009nonparametric} to give consistency analysis of\nmaximum likelihood estimator (MLE) in SBM with continuous community label. We\nshow that there is a standard procedure to transform the $||\\cdot||_2$ error\nbound to the uniform error bound. We demonstrate the application of our general\nresults by proving the uniform consistency (strong consistency) of the MLE in\nthe exponential network model with interaction effect. Unfortunately, in the\ncontinuous parameter case, the condition ensuring uniform consistency we\nobtained is much stronger than that in the discrete parameter case, namely\n$n\\mu_n^5/(\\log n)^{8}\\rightarrow\\infty$ versus $n\\mu_n/\\log\nn\\rightarrow\\infty$. Where $n\\mu_n$ represents the average degree of the\nnetwork. But continuous is the limit of discrete. So it is not surprising as we\nshow that by discretizing the community label space into sufficiently small\n(but not too small) pieces and applying the MLE on the discretized community\nlabel space, uniform consistency holds under almost the same condition as in\ndiscrete community label space. Such a phenomenon is surprising since the\ndiscretization does not depend on the data or the model. This reminds us of the\nthresholding method. \n\n"}
{"id": "1710.06672", "contents": "Title: Metastability of one-dimensional, non-reversible diffusions with\n  periodic boundary conditions Abstract: We consider small perturbations of a dynamical system on the one-dimensional\ntorus. We derive sharp estimates for the pre-factor of the stationary state, we\nexamine the asymptotic behavior of the solutions of the Hamilton-Jacobi\nequation for the pre-factor, we compute the capacities between disjoint sets,\nand we prove the metastable behavior of the process among the deepest wells\nfollowing the martingale approach. We also present a bound for the probability\nthat a Markov process hits a set before some fixed time in terms of the\ncapacity of an enlarged process. \n\n"}
{"id": "1710.07154", "contents": "Title: Comparison of statistical procedures for Gaussian graphical model\n  selection Abstract: Graphical models are used in a variety of problems to uncover hidden\nstructures. There is a huge number of different identification procedures,\nconstructed for different purposes. However, it is important to research\ndifferent properties of such procedures and compare them in order to find out\nthe best procedure or the best use case for some specific procedure. In this\npaper, some statistical identification procedures are compared using different\nmeasures, such as Type I and Type II errors, ROC AUC. \n\n"}
{"id": "1710.07894", "contents": "Title: On the quadratic variation of the model-free price paths with jumps Abstract: We prove that the model-free typical (in the sense of Vovk) c\\`adl\\`ag price\npaths with mildly restricted downward jumps possess quadratic variation which\ndoes not depend on the specific sequence of partitions as long as these\npartitions are obtained from stopping times such that the oscillations of a\npath on the consecutive (half-open on the right) intervals of these partitions\ntend (in a specified sense) to 0. Finally, we also define quasi-explicit,\npartition independent quantities which tend to this quadratic variation. \n\n"}
{"id": "1710.08160", "contents": "Title: Brown measure and asymptotic freeness of elliptic and related matrices Abstract: We show that independent elliptic matrices converge to freely independent\nelliptic elements. Moreover, the elliptic matrices are asymptotically free with\ndeterministic matrices under appropriate conditions. We compute the Brown\nmeasure of the product of elliptic elements. It turns out that this Brown\nmeasure is same as the limiting spectral distribution. \n\n"}
{"id": "1710.08378", "contents": "Title: Fractional Laplacian with Hardy potential Abstract: We give sharp two-sided estimates of the semigroup generated by the\nfractional Laplacian plus the Hardy potential on $\\mathbb{R}^d$, including the\ncase of the critical constant. We use Davies' method back-to-back with a new\nmethod of integral analysis of Duhamel's formula. \n\n"}
{"id": "1710.08388", "contents": "Title: A Test for Separability in Covariance Operators of Random Surfaces Abstract: The assumption of separability is a simplifying and very popular assumption\nin the analysis of spatio-temporal or hypersurface data structures. It is often\nmade in situations where the covariance structure cannot be easily estimated,\nfor example because of a small sample size or because of computational storage\nproblems. In this paper we propose a new and very simple test to validate this\nassumption. Our approach is based on a measure of separability which is zero in\nthe case of separability and positive otherwise. The measure can be estimated\nwithout calculating the full non-separable covariance operator. We prove\nasymptotic normality of the corresponding statistic with a limiting variance,\nwhich can easily be estimated from the available data. As a consequence\nquantiles of the standard normal distribution can be used to obtain critical\nvalues and the new test of separability is very easy to implement. In\nparticular, our approach does neither require projections on subspaces\ngenerated by the eigenfunctions of the covariance operator, nor resampling\nprocedures to obtain critical values nor distributional assumptions as used by\nother available methods of constructing tests for separability. We investigate\nthe finite sample performance by means of a simulation study and also provide a\ncomparison with the currently available methodology. Finally, the new procedure\nis illustrated analyzing wind speed and temperature data. \n\n"}
{"id": "1710.08704", "contents": "Title: Near-Optimal Noisy Group Testing via Separate Decoding of Items Abstract: The group testing problem consists of determining a small set of defective\nitems from a larger set of items based on a number of tests, and is relevant in\napplications such as medical testing, communication protocols, pattern\nmatching, and more. In this paper, we revisit an efficient algorithm for noisy\ngroup testing in which each item is decoded separately (Malyutov and Mateev,\n1980), and develop novel performance guarantees via an information-theoretic\nframework for general noise models. For the special cases of no noise and\nsymmetric noise, we find that the asymptotic number of tests required for\nvanishing error probability is within a factor $\\log 2 \\approx 0.7$ of the\ninformation-theoretic optimum at low sparsity levels, and that with a small\nfraction of allowed incorrectly decoded items, this guarantee extends to all\nsublinear sparsity levels. In addition, we provide a converse bound showing\nthat if one tries to move slightly beyond our low-sparsity achievability\nthreshold using separate decoding of items and i.i.d. randomized testing, the\naverage number of items decoded incorrectly approaches that of a trivial\ndecoder. \n\n"}
{"id": "1710.10232", "contents": "Title: Metastability of hard-core dynamics on bipartite graphs Abstract: We study the metastable behaviour of a stochastic system of particles with\nhard-core interactions in a high-density regime. Particles sit on the vertices\nof a bipartite graph. New particles appear subject to a neighbourhood exclusion\nconstraint, while existing particles disappear, all according to independent\nPoisson clocks. We consider the regime in which the appearance rates are much\nlarger than the disappearance rates, and there is a slight imbalance between\nthe appearance rates on the two parts of the graph. Starting from the\nconfiguration in which the weak part is covered with particles, the system\ntakes a long time before it reaches the configuration in which the strong part\nis covered with particles. We obtain a sharp asymptotic estimate for the\nexpected transition time, show that the transition time is asymptotically\nexponentially distributed, and identify the size and shape of the critical\ndroplet representing the bottleneck for the crossover. For various types of\nbipartite graphs the computations are made explicit. Proofs rely on potential\ntheory for reversible Markov chains, and on isoperimetric results. In a\nfollow-up paper we will use our results to study the performance of\nrandom-access wireless networks. \n\n"}
{"id": "1710.10279", "contents": "Title: Wavelet Shrinkage and Thresholding based Robust Classification for Brain\n  Computer Interface Abstract: A macaque monkey is trained to perform two different kinds of tasks, memory\naided and visually aided. In each task, the monkey saccades to eight possible\ntarget locations. A classifier is proposed for direction decoding and task\ndecoding based on local field potentials (LFP) collected from the prefrontal\ncortex. The LFP time-series data is modeled in a nonparametric regression\nframework, as a function corrupted by Gaussian noise. It is shown that if the\nfunction belongs to Besov bodies, then using the proposed wavelet shrinkage and\nthresholding based classifier is robust and consistent. The classifier is then\napplied to the LFP data to achieve high decoding performance. The proposed\nclassifier is also quite general and can be applied for the classification of\nother types of time-series data as well, not necessarily brain data. \n\n"}
{"id": "1710.10709", "contents": "Title: Distributional Consistency of Lasso by Perturbation Bootstrap Abstract: Least Absolute Shrinkage and Selection Operator or the Lasso, introduced by\nTibshirani (1996), is a popular estimation procedure in multiple linear\nregression when underlying design has a sparse structure, because of its\nproperty that it sets some regression coefficients exactly equal to 0. In this\narticle, we develop a perturbation bootstrap method and establish its validity\nin approximating the distribution of the Lasso in heteroscedastic linear\nregression. We allow the underlying covariates to be either random or\nnon-random. We show that the proposed bootstrap method works irrespective of\nthe nature of the covariates, unlike the resample-based bootstrap of Freedman\n(1981) which must be tailored based on the nature (random vs non-random) of the\ncovariates. Simulation study also justifies our method in finite samples. \n\n"}
{"id": "1711.00136", "contents": "Title: Bayesian model comparison with the Hyv\\\"arinen score: computation and\n  consistency Abstract: The Bayes factor is a widely used criterion in model comparison and its\nlogarithm is a difference of out-of-sample predictive scores under the\nlogarithmic scoring rule. However, when some of the candidate models involve\nvague priors on their parameters, the log-Bayes factor features an arbitrary\nadditive constant that hinders its interpretation. As an alternative, we\nconsider model comparison using the Hyv\\\"arinen score. We propose a method to\nconsistently estimate this score for parametric models, using sequential Monte\nCarlo methods. We show that this score can be estimated for models with\ntractable likelihoods as well as nonlinear non-Gaussian state-space models with\nintractable likelihoods. We prove the asymptotic consistency of this new model\nselection criterion under strong regularity assumptions in the case of\nnon-nested models, and we provide qualitative insights for the nested case. We\nalso use existing characterizations of proper scoring rules on discrete spaces\nto extend the Hyv\\\"arinen score to discrete observations. Our numerical\nillustrations include L\\'evy-driven stochastic volatility models and diffusion\nmodels for population dynamics. \n\n"}
{"id": "1711.00484", "contents": "Title: Spatial Statistical Downscaling for Constructing High-Resolution Nature\n  Runs in Global Observing System Simulation Experiments Abstract: Observing system simulation experiments (OSSEs) have been widely used as a\nrigorous and cost-effective way to guide development of new observing systems,\nand to evaluate the performance of new data assimilation algorithms. Nature\nruns (NRs), which are outputs from deterministic models, play an essential role\nin building OSSE systems for global atmospheric processes because they are used\nboth to create synthetic observations at high spatial resolution, and to\nrepresent the \"true\" atmosphere against which the forecasts are verified.\nHowever, most NRs are generated at resolutions coarser than actual\nobservations. Here, we propose a principled statistical downscaling framework\nto construct high-resolution NRs via conditional simulation from\ncoarse-resolution numerical model output. We use nonstationary spatial\ncovariance function models that have basis function representations. This\napproach not only explicitly addresses the change-of-support problem, but also\nallows fast computation with large volumes of numerical model output. We also\npropose a data-driven algorithm to select the required basis functions\nadaptively, in order to increase the flexibility of our nonstationary\ncovariance function models. In this article we demonstrate these techniques by\ndownscaling a coarse-resolution physical NR at a native resolution of\n$1^{\\circ} \\text{ latitude} \\times 1.25^{\\circ} \\text{ longitude}$ of global\nsurface $\\text{CO}_2$ concentrations to 655,362 equal-area hexagons. \n\n"}
{"id": "1711.00572", "contents": "Title: Consistent estimation of the spectrum of trace class data augmentation\n  algorithms Abstract: Markov chain Monte Carlo is widely used in a variety of scientific\napplications to generate approximate samples from intractable distributions. A\nthorough understanding of the convergence and mixing properties of these Markov\nchains can be obtained by studying the spectrum of the associated Markov\noperator. While several methods to bound/estimate the second largest eigenvalue\nare available in the literature, very few general techniques for consistent\nestimation of the entire spectrum have been proposed. Existing methods for this\npurpose require the Markov transition density to be available in closed form,\nwhich is often not true in practice, especially in modern statistical\napplications. In this paper, we propose a novel method to consistently estimate\nthe entire spectrum of a general class of Markov chains arising from a popular\nand widely used statistical approach known as Data Augmentation. The transition\ndensities of these Markov chains can often only be expressed as intractable\nintegrals. We illustrate the applicability of our method using real and\nsimulated data. \n\n"}
{"id": "1711.01241", "contents": "Title: Bayesian Mixed Effects Models for Zero-inflated Compositions in\n  Microbiome Data Analysis Abstract: Detecting associations between microbial compositions and sample\ncharacteristics is one of the most important tasks in microbiome studies. Most\nof the existing methods apply univariate models to single microbial species\nseparately, with adjustments for multiple hypothesis testing. We propose a\nBayesian analysis for a generalized mixed effects linear model tailored to this\napplication. The marginal prior on each microbial composition is a Dirichlet\nProcess, and dependence across compositions is induced through a linear\ncombination of individual covariates, such as disease biomarkers or the\nsubject's age, and latent factors. The latent factors capture residual\nvariability and their dimensionality is learned from the data in a fully\nBayesian procedure. The proposed model is tested in data analyses and\nsimulation studies with zero-inflated compositions. In these settings, within\neach sample, a large proportion of counts per microbial species are equal to\nzero. In our Bayesian model a priori the probability of compositions with\nabsent microbial species is strictly positive. We propose an efficient\nalgorithm to sample from the posterior and visualizations of model parameters\nwhich reveal associations between covariates and microbial compositions. We\nevaluate the proposed method in simulation studies, and then analyze a\nmicrobiome dataset for infants with type 1 diabetes which contains a large\nproportion of zeros in the sample-specific microbial compositions. \n\n"}
{"id": "1711.01630", "contents": "Title: Capacity Upper Bounds for Deletion-Type Channels Abstract: We develop a systematic approach, based on convex programming and real\nanalysis, for obtaining upper bounds on the capacity of the binary deletion\nchannel and, more generally, channels with i.i.d. insertions and deletions.\nOther than the classical deletion channel, we give a special attention to the\nPoisson-repeat channel introduced by Mitzenmacher and Drinea (IEEE Transactions\non Information Theory, 2006). Our framework can be applied to obtain capacity\nupper bounds for any repetition distribution (the deletion and Poisson-repeat\nchannels corresponding to the special cases of Bernoulli and Poisson\ndistributions). Our techniques essentially reduce the task of proving capacity\nupper bounds to maximizing a univariate, real-valued, and often concave\nfunction over a bounded interval. We show the following:\n  1. The capacity of the binary deletion channel with deletion probability $d$\nis at most $(1-d)\\log\\varphi$ for $d\\geq 1/2$, and, assuming the capacity\nfunction is convex, is at most $1-d\\log(4/\\varphi)$ for $d<1/2$, where\n$\\varphi=(1+\\sqrt{5})/2$ is the golden ratio. This is the first nontrivial\ncapacity upper bound for any value of $d$ outside the limiting case $d\\to 0$\nthat is fully explicit and proved without computer assistance.\n  2. We derive the first set of capacity upper bounds for the Poisson-repeat\nchannel.\n  3. We derive several novel upper bounds on the capacity of the deletion\nchannel. All upper bounds are maximums of efficiently computable, and concave,\nunivariate real functions over a bounded domain. In turn, we upper bound these\nfunctions in terms of explicit elementary and standard special functions, whose\nmaximums can be found even more efficiently (and sometimes, analytically, for\nexample for $d=1/2$).\n  Along the way, we develop several new techniques of potentially independent\ninterest in information theory, probability, and mathematical analysis. \n\n"}
{"id": "1711.01674", "contents": "Title: A robust RUV-testing procedure via gamma-divergence Abstract: Identification of differentially expressed genes (DE-genes) is commonly\nconducted in modern biomedical researches. However, unwanted variation\ninevitably arises during the data collection process, which could make the\ndetection results heavily biased. It is suggested to remove the unwanted\nvariation while keeping the biological variation to ensure a reliable analysis\nresult. Removing Unwanted Variation (RUV) is recently proposed for this purpose\nby the virtue of negative control genes. On the other hand, outliers are\nfrequently appear in modern high-throughput genetic data that can heavily\naffect the performances of RUV and its downstream analysis. In this work, we\npropose a robust RUV-testing procedure via gamma-divergence. The advantages of\nour method are twofold: (1) it does not involve any modeling for the outlier\ndistribution, which is applicable to various situations, (2) it is easy to\nimplement in the sense that its robustness is controlled by a single tuning\nparameter gamma of gamma-divergence, and a data-driven criterion is developed\nto select $\\gamma$. In the Gender Study, our method can successfully remove\nunwanted variation, and is able to identify more DE-genes than conventional\nmethods. \n\n"}
{"id": "1711.02250", "contents": "Title: Ergodicity and Lyapunov functions for Langevin dynamics with singular\n  potentials Abstract: We study Langevin dynamics of $N$ particles on $R^d$ interacting through a\nsingular repulsive potential, e.g.~the well-known Lennard-Jones type, and show\nthat the system converges to the unique invariant Gibbs measure exponentially\nfast in a weighted total variation distance. The proof of the main result\nrelies on an explicit construction of a Lyapunov function. In contrast to\nprevious results for such systems, our result implies geometric convergence to\nequilibrium starting from an essentially optimal family of initial\ndistributions. \n\n"}
{"id": "1711.02836", "contents": "Title: Multilevel Monte Carlo for Smoothing via Transport Methods Abstract: In this article we consider recursive approximations of the smoothing\ndistribution associated to partially observed stochastic differential equations\n(SDEs), which are observed discretely in time. Such models appear in a wide\nvariety of applications including econometrics, finance and engineering. This\nproblem is notoriously challenging, as the smoother is not available\nanalytically and hence require numerical approximation. This usually consists\nby applying a time-discretization to the SDE, for instance the Euler method,\nand then applying a numerical (e.g. Monte Carlo) method to approximate the\nsmoother. This has lead to a vast literature on methodology for solving such\nproblems, perhaps the most popular of which is based upon the particle filter\n(PF) e.g. [9]. In the context of filtering for this class of problems, it is\nwell-known that the particle filter can be improved upon in terms of cost to\nachieve a given mean squared error (MSE) for estimates. This in the sense that\nthe computational effort can be reduced to achieve this target MSE, by using\nmultilevel (ML) methods [12, 13, 18], via the multilevel particle filter (MLPF)\n[16, 20, 21]. For instance, to obtain a MSE of $\\mathcal{O}(\\epsilon^2)$ for\nsome $\\epsilon > 0$ when approximating filtering distributions associated with\nEuler-discretized diffusions with constant diffusion coefficients, the cost of\nthe PF is $\\mathcal{O}(\\epsilon^{-3})$ while the cost of the MLPF is\n$\\mathcal{O}(\\epsilon^{-2}\\log(\\epsilon)^2)$. In this article we consider a new\napproach to replace the particle filter, using transport methods in [27]. In\nthe context of filtering, one expects that the proposed method improves upon\nthe MLPF by yielding, under assumptions, a MSE of $\\mathcal{O}(\\epsilon^2)$ for\na cost of $\\mathcal{O}(\\epsilon^{-2})$. This is established theoretically in an\n\"ideal\" example and numerically in numerous examples. \n\n"}
{"id": "1711.02955", "contents": "Title: Inference of signals with unknown correlation structure from nonlinear\n  measurements Abstract: We present a method to reconstruct autocorrelated signals together with their\nautocorrelation structure from nonlinear, noisy measurements for arbitrary\nmonotonous nonlinear instrument response. In the presented formulation the\nalgorithm provides a significant speedup compared to prior implementations,\nallowing for a wider range of application. The nonlinearity can be used to\nmodel instrument characteristics or to enforce properties on the underlying\nsignal, such as positivity. Uncertainties on any posterior quantities can be\nprovided due to independent samples from an approximate posterior distribution.\nWe demonstrate the methods applicability via simulated and real measurements,\nusing different measurement instruments, nonlinearities and dimensionality. \n\n"}
{"id": "1711.03170", "contents": "Title: Penalized Orthogonal Iteration for Sparse Estimation of Generalized\n  Eigenvalue Problem Abstract: We propose a new algorithm for sparse estimation of eigenvectors in\ngeneralized eigenvalue problems (GEP). The GEP arises in a number of modern\ndata-analytic situations and statistical methods, including principal component\nanalysis (PCA), multiclass linear discriminant analysis (LDA), canonical\ncorrelation analysis (CCA), sufficient dimension reduction (SDR) and invariant\nco-ordinate selection. We propose to modify the standard generalized orthogonal\niteration with a sparsity-inducing penalty for the eigenvectors. To achieve\nthis goal, we generalize the equation-solving step of orthogonal iteration to a\npenalized convex optimization problem. The resulting algorithm, called\npenalized orthogonal iteration, provides accurate estimation of the true\neigenspace, when it is sparse. Also proposed is a computationally more\nefficient alternative, which works well for PCA and LDA problems. Numerical\nstudies reveal that the proposed algorithms are competitive, and that our\ntuning procedure works well. We demonstrate applications of the proposed\nalgorithm to obtain sparse estimates for PCA, multiclass LDA, CCA and SDR.\nSupplementary materials are available online. \n\n"}
{"id": "1711.03701", "contents": "Title: Time-dependent spatially varying graphical models, with application to\n  brain fMRI data analysis Abstract: In this work, we present an additive model for space-time data that splits\nthe data into a temporally correlated component and a spatially correlated\ncomponent. We model the spatially correlated portion using a time-varying\nGaussian graphical model. Under assumptions on the smoothness of changes in\ncovariance matrices, we derive strong single sample convergence results,\nconfirming our ability to estimate meaningful graphical structures as they\nevolve over time. We apply our methodology to the discovery of time-varying\nspatial structures in human brain fMRI signals. \n\n"}
{"id": "1711.04376", "contents": "Title: Bayesian linear regression models with flexible error distributions Abstract: This work introduces a novel methodology based on finite mixtures of\nStudent-t distributions to model the errors' distribution in linear regression\nmodels. The novelty lies on a particular hierarchical structure for the mixture\ndistribution in which the first level models the number of modes, responsible\nto accommodate multimodality and skewness features, and the second level models\ntail behavior. Moreover, the latter is specified in a way that no degrees of\nfreedom parameters are estimated and, therefore, the known statistical\ndifficulties when dealing with those parameters is mitigated, and yet model\nflexibility is not compromised. Inference is performed via Markov chain Monte\nCarlo and simulation studies are conducted to evaluate the performance of the\nproposed methodology. The analysis of two real data sets are also presented. \n\n"}
{"id": "1711.04700", "contents": "Title: Localization of the continuous Anderson Hamiltonian in $1$-d Abstract: We study the bottom of the spectrum of the Anderson Hamiltonian\n$\\mathcal{H}_L := -\\partial_x^2 + \\xi$ on $[0,L]$ driven by a white noise $\\xi$\nand endowed with either Dirichlet or Neumann boundary conditions. We show that,\nas $L\\rightarrow\\infty$, the point process of the (appropriately shifted and\nrescaled) eigenvalues converges to a Poisson point process on $\\mathbb{R}$ with\nintensity $e^x dx$, and that the (appropriately rescaled) eigenfunctions\nconverge to Dirac masses located at independent and uniformly distributed\npoints. Furthermore, we show that the shape of each eigenfunction, recentered\naround its maximum and properly rescaled, is given by the inverse of a\nhyperbolic cosine. We also show that the eigenfunctions decay exponentially\nfrom their localization centers at an explicit rate, and we obtain very precise\ninformation on the zeros and local maxima of these eigenfunctions. Finally, we\nshow that the eigenvalues/eigenfunctions in the Dirichlet and Neumann cases are\nvery close to each other and converge to the same limits. \n\n"}
{"id": "1711.04702", "contents": "Title: wTO: an R package for computing weighted topological overlap and\n  consensus networks with an integrated visualization tool Abstract: Network analyses, such as of gene co-expression networks, metabolic networks\nand ecological networks have become a central approach for the systems-level\nstudy of biological data. Several software packages exist for generating and\nanalyzing such networks, either from correlation scores or the absolute value\nof a transformed score called weighted topological overlap (wTO). However,\nsince gene regulatory processes can up- or down-regulate genes, it is of great\ninterest to explicitly consider both positive and negative correlations when\nconstructing a gene co-expression network. Here, we present an R package for\ncalculating the wTO, that, in contrast to existing packages, explicitly\naddresses the sign of the wTO values, and is thus especially valuable for the\nanalysis of gene regulatory networks. The package includes the calculation of\np-values (raw and adjusted) for each pairwise gene score. Our package also\nallows the calculation of networks from time series (without replicates). Since\nnetworks from independent datasets (biological repeats or related studies) are\nnot the same due to technical and biological noise in the data, we\nadditionally, incorporated a novel method for calculating a consensus network\n(CN) from two or more networks into our R package. We compare our new wTO\npackage to state of art packages and demonstrate the application of the wTO and\nCN functions using 3 independently derived datasets from healthy human\npre-frontal cortex samples. To showcase an example for the time series\napplication we utilized a metagenomics data set. In this work, we developed a\nsoftware package that allows the computation of wTO networks, CNs and a\nvisualization tool in the R statistical environment. It is publicly available\non CRAN repositories under the GPL-2 Open Source License\n(https://cran.r-project.org/web/packages/wTO/). \n\n"}
{"id": "1711.05120", "contents": "Title: GOE and ${\\rm Airy}_{2\\to 1}$ marginal distribution via symplectic Schur\n  functions Abstract: We derive Sasamoto's Fredholm determinant formula for the Tracy-Widom GOE\ndistribution, as well as the one-point marginal distribution of the ${\\rm\nAiry}_{2\\to1}$ process, originally derived by Borodin-Ferrari-Sasamoto, as\nscaling limits of point-to-line and point-to-half-line last passage percolation\nwith exponentially distributed waiting times. The asymptotic analysis goes\nthrough new expressions for the last passage times in terms of integrals of\n(the continuous analog of) symplectic and classical Schur functions, obtained\nrecently in [BZ19a]. \n\n"}
{"id": "1711.08768", "contents": "Title: Limit Theorems for the Fractional Non-homogeneous Poisson Process Abstract: The fractional non-homogeneous Poisson process was introduced by a\ntime-change of the non-homogeneous Poisson process with the inverse\n$\\alpha$-stable subordinator. We propose a similar definition for the\n(non-homogeneous) fractional compound Poisson process. We give both\nfinite-dimensional and functional limit theorems for the fractional\nnon-homogeneous Poisson process and the fractional compound Poisson process.\nThe results are derived by using martingale methods, regular variation\nproperties and Anscombe's theorem. Eventually, some of the limit results are\nverified in a Monte Carlo simulation. \n\n"}
{"id": "1711.08986", "contents": "Title: On the Brownian separable permuton Abstract: The Brownian separable permuton is a random probability measure on the unit\nsquare, which was introduced by Bassino, Bouvel, F\\'eray, Gerin, Pierrot (2016)\nas the scaling limit of the diagram of the uniform separable permutation as\nsize grows to infinity. We show that, almost surely, the permuton is the\npushforward of the Lebesgue measure on the graph of a random measure-preserving\nfunction associated to a Brownian excursion whose strict local minima are\ndecorated with i.i.d. signs. As a consequence, its support is almost surely\ntotally disconnected, has Hausdorff dimension one, and enjoys self-similarity\nproperties inherited from those of the Brownian excursion. The density function\nof the averaged permuton is computed and a connection with the shuffling of the\nBrownian continuum random tree is explored. \n\n"}
{"id": "1711.09718", "contents": "Title: Local dimensions of random homogeneous self-similar measures: strong\n  separation and finite type Abstract: We study the multifractal analysis of self-similar measures arising from\nrandom homogeneous iterated function systems. Under the assumption of the\nuniform strong separation condition, we see that this analysis parallels that\nof the deterministic case. The overlapping case is more complicated; we\nintroduce the notion of finite type for random homogeneous iterated function\nsystems and give a formula for the local dimensions of finite type, regular,\nrandom homogeneous self-similar measures in terms of Lyapunov exponents of\ncertain transition matrices. We show that almost all points with respect to\nthis measure are described by a distinguished subset called the essential\nclass, and that the dimension of the support can be computed almost surely from\nknowledge of this essential class. For a special subcase, that we call\ncommuting, we prove that the set of attainable local dimensions is almost\nsurely a closed interval. Particular examples of such random measures are\nanalyzed in more detail. \n\n"}
{"id": "1711.09838", "contents": "Title: Torsional rigidity for cylinders with a Brownian fracture Abstract: We obtain bounds for the expected loss of torsional rigidity of a cylinder\n$\\Omega_L=(-L/2,L/2) \\times \\Omega\\subset \\R^3$ of length $L$ due to a Brownian\nfracture that starts at a random point in $\\Omega_L,$ and runs until the first\ntime it exits $\\Omega_L$. These bounds are expressed in terms of the geometry\nof the cross-section $\\Omega \\subset \\R^2$. It is shown that if $\\Omega$ is a\ndisc with radius $R$, then in the limit as $L \\rightarrow \\infty$ the expected\nloss of torsional rigidity equals $cR^5$ for some $c\\in (0,\\infty)$. We derive\nbounds for $c$ in terms of the expected Newtonian capacity of the trace of a\nBrownian path that starts at the centre of a ball in $\\R^3$ with radius $1,$\nand runs until the first time it exits this ball. \n\n"}
{"id": "1711.10819", "contents": "Title: Objective Bayesian inference with proper scoring rules Abstract: Standard Bayesian analyses can be difficult to perform when the full\nlikelihood, and consequently the full posterior distribution, is too complex\nand difficult to specify or if robustness with respect to data or to model\nmisspecifications is required. In these situations, we suggest to resort to a\nposterior distribution for the parameter of interest based on proper scoring\nrules. Scoring rules are loss functions designed to measure the quality of a\nprobability distribution for a random variable, given its observed value.\nImportant examples are the Tsallis score and the Hyv\\\"arinen score, which allow\nus to deal with model misspecifications or with complex models. Also the full\nand the composite likelihoods are both special instances of scoring rules.\n  The aim of this paper is twofold. Firstly, we discuss the use of scoring\nrules in the Bayes formula in order to compute a posterior distribution, named\nSR-posterior distribution, and we derive its asymptotic normality. Secondly, we\npropose a procedure for building default priors for the unknown parameter of\ninterest that can be used to update the information provided by the scoring\nrule in the SR-posterior distribution. In particular, a reference prior is\nobtained by maximizing the average $\\alpha-$divergence from the SR-posterior\ndistribution. For $0 \\leq |\\alpha|<1$, the result is a Jeffreys-type prior that\nis proportional to the square root of the determinant of the Godambe\ninformation matrix associated to the scoring rule. Some examples are discussed. \n\n"}
{"id": "1711.11286", "contents": "Title: Sensitivity analysis for inverse probability weighting estimators via\n  the percentile bootstrap Abstract: To identify the estimand in missing data problems and observational studies,\nit is common to base the statistical estimation on the \"missing at random\" and\n\"no unmeasured confounder\" assumptions. However, these assumptions are\nunverifiable using empirical data and pose serious threats to the validity of\nthe qualitative conclusions of the statistical inference. A sensitivity\nanalysis asks how the conclusions may change if the unverifiable assumptions\nare violated to a certain degree. In this paper we consider a marginal\nsensitivity model which is a natural extension of Rosenbaum's sensitivity model\nthat is widely used for matched observational studies. We aim to construct\nconfidence intervals based on inverse probability weighting estimators, such\nthat asymptotically the intervals have at least nominal coverage of the\nestimand whenever the data generating distribution is in the collection of\nmarginal sensitivity models. We use a percentile bootstrap and a generalized\nminimax/maximin inequality to transform this intractable problem to a linear\nfractional programming problem, which can be solved very efficiently. We\nillustrate our method using a real dataset to estimate the causal effect of\nfish consumption on blood mercury level. \n\n"}
{"id": "1712.00385", "contents": "Title: Explicit formulas for heat kernels on diamond fractals Abstract: This paper provides explicit pointwise formulas for the heat kernel on\ncompact metric measure spaces that belong to a\n$(\\mathbb{N}\\times\\mathbb{N})$-parameter family of fractals which are regarded\nas projective limits of metric measure graphs and do not satisfy the volume\ndoubling property. The formulas are applied to obtain uniform continuity\nestimates of the heat kernel and to derive an expression of the fundamental\nsolution of the free Schr\\\"odinger equation. The results also open up the\npossibility to approach infinite dimensional spaces based on this model. \n\n"}
{"id": "1712.00829", "contents": "Title: Lecture notes on Liouville theory and the DOZZ formula Abstract: The purpose of these notes, based on a series of 4 lectures given by the\nauthor at IHES, is to explain the recent proof of the DOZZ formula for the\nthree point correlation functions of Liouville conformal field theory (LCFT).\nWe first review the probabilistic construction of the $N$ point correlation\nfunctions of LCFT on the Riemann sphere for $N \\geq 3$ (based on a series of\nworks of the author with David, Kupiainen and Rhodes). We then explain the\nconstruction of the two point correlation functions of LCFT, also called\nreflection coefficient. These probabilistic constructions will be justified\nfrom the point of view of Polyakov's path integral formulation of LCFT.\nFinally, we explain the proof of the DOZZ formula for the three point\ncorrelation functions of LCFT (based on 2 papers by the author with Kupiainen\nand Rhodes). \n\n"}
{"id": "1712.04243", "contents": "Title: Approximation of Supremum of Max-Stable Stationary Processes and\n  Pickands Constants Abstract: Let $X(t),t\\in \\mathbb{R}$ be a stochastically continuous stationary\nmax-stable process with Fr\\'{e}chet marginals $\\Phi_\\alpha, \\alpha>0$ and set\n$M_X(T)=\\sup_{t \\in [0,T]} X(t),T>0$. In the light of the seminal articles\n[1,2], it follows that $A_T=M_X(T)/T^{1/\\alpha}$ converges in distribution as\n$T\\to \\infty$ to $\\mathcal{H}_Z^{1/\\alpha} X(1)$, where $\\mathcal{H}_Z$ is the\nPickands constant corresponding to the spectral process $Z$ of $X$. In this\ncontribution we derive explicit formulas for $\\mathcal{H}_Z$ in terms of $Z$\nand show necessary and sufficient conditions for its positivity. From our\nanalysis it follows that $A_T^\\beta,T>0$ is uniformly integrable for any $\\beta\n\\in (0,\\alpha)$. Further, we discuss the dissipative Rosi\\'nski (or mixed\nmoving maxima) representation of $X$. Additionally, for Brown-Resnick $X$ we\nshow the validity of the celebrated Slepian inequality and obtain lower bounds\non the growth of supremum of Gaussian processes with stationary increments by\nexploiting the link between Pickands constants and Wills functional. Moreover,\nwe derive upper bounds for supremum of centered Gaussian processes given in\nterms of Wills functional, and discuss the relation between Pickands and\nPiterbarg constants. \n\n"}
{"id": "1712.06532", "contents": "Title: Dependence and dependence structures: estimation and visualization using\n  the unifying concept of distance multivariance Abstract: Distance multivariance is a multivariate dependence measure, which can detect\ndependencies between an arbitrary number of random vectors each of which can\nhave a distinct dimension. Here we discuss several new aspects, present a\nconcise overview and use it as the basis for several new results and concepts:\nIn particular, we show that distance multivariance unifies (and extends)\ndistance covariance and the Hilbert-Schmidt independence criterion HSIC,\nmoreover also the classical linear dependence measures: covariance, Pearson's\ncorrelation and the RV coefficient appear as limiting cases. Based on distance\nmultivariance several new measures are defined: a multicorrelation which\nsatisfies a natural set of multivariate dependence measure axioms and\n$m$-multivariance which is a dependence measure yielding tests for pairwise\nindependence and independence of higher order. These tests are computationally\nfeasible and under very mild moment conditions they are consistent against all\nalternatives. Moreover, a general visualization scheme for higher order\ndependencies is proposed, including consistent estimators (based on distance\nmultivariance) for the dependence structure.\n  Many illustrative examples are provided. All functions for the use of\ndistance multivariance in applications are published in the R-package\n'multivariance'. \n\n"}
{"id": "1712.06575", "contents": "Title: Combinatorics of chemical reaction systems Abstract: We propose a concise stochastic mechanics framework for chemical reaction\nsystems that allows to formulate evolution equations for three general types of\ndata: the probability generating functions, the exponential moment generating\nfunctions and the factorial moment generating functions. This formulation\nconstitutes an intimate synergy between techniques of statistical physics and\nof combinatorics. We demonstrate how to analytically solve the evolution\nequations for all six elementary types of single-species chemical reactions by\neither combinatorial normal-ordering techniques, or, for the binary reactions,\nby means of Sobolev-Jacobi orthogonal polynomials. The former set of results in\nparticular highlights the relationship between infinitesimal generators of\nstochastic evolution and parametric transformations of probability\ndistributions. \n\n"}
{"id": "1712.06893", "contents": "Title: Wider contours and adaptive contours Abstract: Contour integrals in the complex plane are the basis of effective numerical\nmethods for computing matrix functions, such as the matrix exponential and the\nMittag-Leffler function. These methods provide successful ways to solve partial\ndifferential equations, such as convection--diffusion models. Part of the\nsuccess of these methods comes from exploiting the freedom to choose the\ncontour, by appealing to Cauchy's theorem. However, the pseudospectra of\nnon-normal matrices or operators present a challenge for these methods: if the\ncontour is too close to regions where the norm of the resolvent matrix is\nlarge, then the accuracy suffers. Important applications that involve\nnon-normal matrices or operators include the Black--Scholes equation of\nfinance, and Fokker--Planck equations for stochastic models arising in biology.\nConsequently, it is crucial to choose the contour carefully. As a remedy, we\ndiscuss choosing a contour that is wider than it might otherwise have been for\na normal matrix or operator. We also suggest a semi-analytic approach to\nadapting the contour, in the form of a parabolic bound that is derived by\nestimating the field of values. To demonstrate the utility of the approaches\nthat we advocate, we study three models in biology: a monomolecular reaction, a\nbimolecular reaction and a trimolecular reaction. Modelling and simulation of\nthese reactions is done within the framework of Markov processes. We also\nconsider non-Markov generalisations that have Mittag-Leffler waiting times\ninstead of the usual exponential waiting times of a Markov process. \n\n"}
{"id": "1712.07437", "contents": "Title: Laplace approximation and the natural gradient for Gaussian process\n  regression with the heteroscedastic Student-t model Abstract: This paper considers the Laplace method to derive approximate inference for\nthe Gaussian process (GP) regression in the location and scale parameters of\nthe Student-t probabilistic model. This allows both mean and variance of the\ndata to vary as a function of covariates with the attractive feature that the\nStudent-t model has been widely used as a useful tool for robustifying data\nanalysis. The challenge in the approximate inference for the GP regression with\nthe Student-t probabilistic model, lies in the analytical intractability of the\nposterior distribution and the lack of concavity of the log-likelihood\nfunction. We present the natural gradient adaptation for the estimation process\nwhich primarily relies on the property that the Student-t model naturally has\northogonal parametrization with respect to the location and scale paramaters.\nDue to this particular property of the model, we also introduce an alternative\nLaplace approximation by using the Fisher information matrix in place of the\nHessian matrix of the negative log-likelihood function. According to\nexperiments this alternative approximation provides very similar posterior\napproximations and predictive performance when compared to the traditional\nLaplace approximation. We also compare both of these Laplace approximations\nwith the Monte Carlo Markov Chain (MCMC) method. Moreover, we compare our\nheteroscedastic Student-t model and the GP regression with the heteroscedastic\nGaussian model. We also discuss how our approach can improve the inference\nalgorithm in cases where the probabilistic model assumed for the data is not\nlog-concave. \n\n"}
{"id": "1712.08048", "contents": "Title: Variable selection for Gaussian processes via sensitivity analysis of\n  the posterior predictive distribution Abstract: Variable selection for Gaussian process models is often done using automatic\nrelevance determination, which uses the inverse length-scale parameter of each\ninput variable as a proxy for variable relevance. This implicitly determined\nrelevance has several drawbacks that prevent the selection of optimal input\nvariables in terms of predictive performance. To improve on this, we propose\ntwo novel variable selection methods for Gaussian process models that utilize\nthe predictions of a full model in the vicinity of the training points and\nthereby rank the variables based on their predictive relevance. Our empirical\nresults on synthetic and real world data sets demonstrate improved variable\nselection compared to automatic relevance determination in terms of variability\nand predictive performance. \n\n"}
{"id": "1712.08588", "contents": "Title: Rank Pruning for Dominance Queries in CP-Nets Abstract: Conditional preference networks (CP-nets) are a graphical representation of a\nperson's (conditional) preferences over a set of discrete variables. In this\npaper, we introduce a novel method of quantifying preference for any given\noutcome based on a CP-net representation of a user's preferences. We\ndemonstrate that these values are useful for reasoning about user preferences.\nIn particular, they allow us to order (any subset of) the possible outcomes in\naccordance with the user's preferences. Further, these values can be used to\nimprove the efficiency of outcome dominance testing. That is, given a pair of\noutcomes, we can determine which the user prefers more efficiently. Through\nexperimental results, we show that this method is more effective than existing\ntechniques for improving dominance testing efficiency. We show that the above\nresults also hold for CP-nets that express indifference between variable\nvalues. \n\n"}
{"id": "1712.08804", "contents": "Title: Non-asymptotic estimation for Bell function, with probabilistic\n  applications Abstract: We deduce the non-asymptotical bilateral estimates for moment inequalities\nfor sums of non-negative independent random variables, based on the\ncorrespondent estimates for the so-called Bell functions and the Poisson\ndistribution. \n\n"}
{"id": "1712.09562", "contents": "Title: Spatial point processes intensity estimation with a diverging number of\n  covariates Abstract: Feature selection procedures for spatial point processes parametric intensity\nestimation have been recently developed since more and more applications\ninvolve a large number of covariates. In this paper, we investigate the setting\nwhere the number of covariates diverges as the domain of observation increases.\nIn particular, we consider estimating equations based on Campbell theorems\nderived from Poisson and logistic regression likelihoods regularized by a\ngeneral penalty function. We prove that, under some conditions, the\nconsistency, the sparsity, and the asymptotic normality are valid for such a\nsetting. We support the theoretical results by numerical ones obtained from\nsimulation experiments and an application to forestry datasets. \n\n"}
{"id": "1712.09816", "contents": "Title: Extremal Behavior of Aggregated Data with an Application to Downscaling Abstract: The distribution of spatially aggregated data from a stochastic process $X$\nmay exhibit a different tail behavior than its marginal distributions. For a\nlarge class of aggregating functionals $\\ell$ we introduce the $\\ell$-extremal\ncoefficient that quantifies this difference as a function of the extremal\nspatial dependence in $X$. We also obtain the joint extremal dependence for\nmultiple aggregation functionals applied to the same process. Explicit formulas\nfor the $\\ell$-extremal coefficients and multivariate dependence structures are\nderived in important special cases. The results provide a theoretical link\nbetween the extremal distribution of the aggregated data and the corresponding\nunderlying process, which we exploit to develop a method for statistical\ndownscaling. We apply our framework to downscale daily temperature maxima in\nthe south of France from a gridded data set and use our model to generate high\nresolution maps of the warmest day during the 2003 heatwave. \n\n"}
{"id": "1801.00231", "contents": "Title: Mean-Square Approximation of Iterated Ito and Stratonovich Stochastic\n  Integrals of Multiplicities 1 to 6 from the Taylor-Ito and\n  Taylor-Stratonovich Expansions Using Legendre Polynomials Abstract: The article is devoted to the practical material on expansions and\nmean-square approximations of specific iterated Ito and Stratonovich stochastic\nintegrals of multiplicities 1 to 6 with respect to components of the\nmultidimensional Wiener process on the base of the method of generalized\nmultiple Fourier series. More precisely, we used the multiple Fourier--Legendre\nseries converging in the sense of norm in the space $L_2([t, T]^k)$\n$(k=1,\\ldots,6)$ for approximation of iterated Ito and Stratonovich stochastic\nintegrals. The considered iterated Ito and Stratonovich stochastic integrals\nare part of the stochastic Taylor expansions (Taylor-Ito and\nTaylor-Stratonovich expansions). Therefore, the results of the article can be\nuseful for construction of the high-order strong numerical methods for Ito\nstochastic differential equations. Expansions of iterated Ito and Stratonovich\nstochastic integrals of multiplicities 1 to 6 using Legendre polynomials are\nderived. The convergence with probability 1 of the mentioned method of\ngeneralized multiple Fourier series is proved for iterated Ito stochastic\nintegrals of multiplicities $k$ $(k\\in\\mathbb{N})$ for the cases of multiple\nFourier-Legendre series and multiple trigonometric Fourier series. \n\n"}
{"id": "1801.00319", "contents": "Title: An Additive Approximate Gaussian Process Model for Large Spatio-Temporal\n  Data Abstract: Motivated by a large ground-level ozone dataset, we propose a new\ncomputationally efficient additive approximate Gaussian process. The proposed\nmethod incorporates a computational-complexity-reduction method and a separable\ncovariance function, which can flexibly capture various spatio-temporal\ndependence structure. The first component is able to capture nonseparable\nspatio-temporal variability while the second component captures the separable\nvariation. Based on a hierarchical formulation of the model, we are able to\nutilize the computational advantages of both components and perform efficient\nBayesian inference. To demonstrate the inferential and computational benefits\nof the proposed method, we carry out extensive simulation studies assuming\nvarious scenarios of underlying spatio-temporal covariance structure. The\nproposed method is also applied to analyze large spatio-temporal measurements\nof ground-level ozone in the Eastern United States. \n\n"}
{"id": "1801.00865", "contents": "Title: Accounting for unobserved covariates with varying degrees of\n  estimability in high dimensional biological data Abstract: An important phenomenon in high dimensional biological data is the presence\nof unobserved covariates that can have a significant impact on the measured\nresponse. When these factors are also correlated with the covariate(s) of\ninterest (i.e. disease status), ignoring them can lead to increased type I\nerror and spurious false discovery rate estimates. We show that depending on\nthe strength of this correlation and the informativeness of the observed data\nfor the latent factors, previously proposed estimators for the effect of the\ncovariate of interest that attempt to account for unobserved covariates are\nasymptotically biased, which corroborates previous practitioners' observations\nthat these estimators tend to produce inflated test statistics. We then provide\nan estimator that corrects the bias and prove it has the same asymptotic\ndistribution as the ordinary least squares estimator when every covariate is\nobserved. Lastly, we use previously published DNA methylation data to show our\nmethod can more accurately estimate the direct effect of asthma on methylation\nthan previously published methods, which underestimate the correlation between\nasthma and latent cell type heterogeneity. Our re-analysis shows that the\nmajority of the variability in methylation due to asthma in those data is\nactually mediated through cell composition. \n\n"}
{"id": "1801.01335", "contents": "Title: Covariant Schr\\\"odinger semigroups on Riemannian manifolds Abstract: This monograph develops the theory of covariant Schr\\\"odinger semigroups\nacting on sections of vector bundles over noncompact Riemannian manifolds from\nscratch.\n  Contents:\n  I. Sobolev spaces on vector bundles\n  II. Smooth heat kernels on vector bundles\n  III. Basis differential operators in Riemannian manifolds\n  IV. Some specific results for the minimal heat kernel\n  V. Wiener measure and Brownian motion on Riemannian manifolds\n  VI. Contractive Dynkin and Kato potentials\n  VII. Foundations of covariant Schr\\\"odinger semigroups\n  VIII. Compactness of $V(H^{\\nabla}+1)^{-1}$\n  IX. $L^q$-properties of covariant Schr\\\"odinger semigroups\n  X. Continuity properties of covariant Schr\\\"odinger semigroups\n  XI. Integral kernels for covariant Schr\\\"odinger semigroups\n  XII. Essential self-adjointness of covariant Schr\\\"odinger semigroups\n  XIII. Smooth compactly supported sections as form core\n  XIV. Applications (in quantum mechanics and geometric analysis) \n\n"}
{"id": "1801.01990", "contents": "Title: Procrustes Metrics on Covariance Operators and Optimal Transportation of\n  Gaussian Processes Abstract: Covariance operators are fundamental in functional data analysis, providing\nthe canonical means to analyse functional variation via the celebrated\nKarhunen--Lo\\`eve expansion. These operators may themselves be subject to\nvariation, for instance in contexts where multiple functional populations are\nto be compared. Statistical techniques to analyse such variation are intimately\nlinked with the choice of metric on covariance operators, and the intrinsic\ninfinite-dimensionality of these operators. In this paper, we describe the\nmanifold geometry of the space of trace-class infinite-dimensional covariance\noperators and associated key statistical properties, under the recently\nproposed infinite-dimensional version of the Procrustes metric. We identify\nthis space with that of centred Gaussian processes equipped with the\nWasserstein metric of optimal transportation. The identification allows us to\nprovide a complete description of those aspects of this manifold geometry that\nare important in terms of statistical inference, and establish key properties\nof the Fr\\'echet mean of a random sample of covariances, as well as generative\nmodels that are canonical for such metrics and link with the problem of\nregistration of functional data. \n\n"}
{"id": "1801.02700", "contents": "Title: Mass-structure of weighted real trees Abstract: Rooted, weighted continuum random trees are used to describe limits of\nsequences of random discrete trees. Formally, they are random quadruples\n$(\\mathcal{T},d,r,p)$, where $(\\mathcal{T},d)$ is a tree-like metric space,\n$r\\in\\mathcal{T}$ is a distinguished root, and $p$ is a probability measure on\nthis space. The underlying branching structure is carried implicitly in the\nmetric $d$. We explore various ways of describing the interaction between\nbranching structure and mass in $(\\mathcal{T},d,r,p)$ in a way that depends on\n$d$ only by way of this branching structure. We introduce a notion of\nmass-structure equivalence and show that two rooted, weighted\n$\\mathbb{R}$-trees are equivalent in this sense if and only if the discrete\nhierarchies derived by i.i.d. sampling from their weights, in a manner\nanalogous to Kingman's paintbox, have the same distribution. We introduce a\nfamily of trees, called \"interval partition trees\" that serve as\nrepresentatives of mass-structure equivalence classes, and which naturally\nrepresent the laws of the aforementioned hierarchies. \n\n"}
{"id": "1801.04090", "contents": "Title: On notions of Q-independence and Q-identical distributiveness Abstract: In a recent article A.M. Kagan and G.J.Sz\\'ekely introduced a notion of\nQ-independent and Q-identical distributed random variables. We give a complete\ndescription of polynomials which appear in these definitions. \n\n"}
{"id": "1801.04202", "contents": "Title: A Simple and Efficient Estimation Method for Models with Nonignorable\n  Missing Data Abstract: This paper proposes a simple and efficient estimation procedure for the model\nwith non-ignorable missing data studied by Morikawa and Kim (2016). Their\nsemiparametrically efficient estimator requires explicit nonparametric\nestimation and so suffers from the curse of dimensionality and requires a\nbandwidth selection. We propose an estimation method based on the Generalized\nMethod of Moments (hereafter GMM). Our method is consistent and asymptotically\nnormal regardless of the number of moments chosen. Furthermore, if the number\nof moments increases appropriately our estimator can achieve the semiparametric\nefficiency bound derived in Morikawa and Kim (2016), but under weaker\nregularity conditions. Moreover, our proposed estimator and its consistent\ncovariance matrix are easily computed with the widely available GMM package. We\npropose two data-based methods for selection of the number of moments. A small\nscale simulation study reveals that the proposed estimation indeed out-performs\nthe existing alternatives in finite samples. \n\n"}
{"id": "1801.04978", "contents": "Title: Smoothing splines on Riemannian manifolds, with applications to 3D shape\n  space Abstract: There has been increasing interest in statistical analysis of data lying in\nmanifolds. This paper generalizes a smoothing spline fitting method to\nRiemannian manifold data based on the technique of unrolling and unwrapping\noriginally proposed in Jupp and Kent (1987) for spherical data. In particular\nwe develop such a fitting procedure for shapes of configurations in general\n$m$-dimensional Euclidean space, extending our previous work for two\ndimensional shapes. We show that parallel transport along a geodesic on Kendall\nshape space is linked to the solution of a homogeneous first-order differential\nequation, some of whose coefficients are implicitly defined functions. This\nfinding enables us to approximate the procedure of unrolling and unwrapping by\nsimultaneously solving such equations numerically, and so to find numerical\nsolutions for smoothing splines fitted to higher dimensional shape data. This\nfitting method is applied to the analysis of some dynamic 3D peptide data. \n\n"}
{"id": "1801.07588", "contents": "Title: Moment and tail estimation for U-statistics with positive kernels Abstract: We deduce the non-asymptotical (bilateral) estimates for moment inequalities\nfor multiple sums of non-negative (more precisely, non-negative) independent\nrandom variables, on the other words, the well known U or V-statistics. Our\nconsideration based on the correspondent estimates for the one-dimensional case\nby means of the so-called degenerate approximation. We apply also the theory of\nBell functions as well as the properties of the Poisson distribution and the\ntheory of the so-called Grand Lebesgue Spaces (GLS). \n\n"}
{"id": "1801.08852", "contents": "Title: Calibration for Weak Variance-Alpha-Gamma Processes Abstract: The weak variance-alpha-gamma process is a multivariate L\\'evy process\nconstructed by weakly subordinating Brownian motion, possibly with correlated\ncomponents with an alpha-gamma subordinator. It generalises the\nvariance-alpha-gamma process of Semeraro constructed by traditional\nsubordination. We compare three calibration methods for the weak\nvariance-alpha-gamma process, method of moments, maximum likelihood estimation\n(MLE) and digital moment estimation (DME). We derive a condition for Fourier\ninvertibility needed to apply MLE and show in our simulations that MLE produces\na better fit when this condition holds, while DME produces a better fit when it\nis violated. We also find that the weak variance-alpha-gamma process exhibits a\nwider range of dependence and produces a significantly better fit than the\nvariance-alpha-gamma process on an S&P500-FTSE100 data set, and that DME\nproduces the best fit in this situation. \n\n"}
{"id": "1801.10576", "contents": "Title: Solving estimating equations with copulas Abstract: Thanks to their ability to capture complex dependence structures, copulas are\nfrequently used to glue random variables into a joint model with arbitrary\nmarginal distributions. More recently, they have been applied to solve\nstatistical learning problems such as regression or classification. Framing\nsuch approaches as solutions of estimating equations, we generalize them in a\nunified framework. We can then obtain simultaneous, coherent inferences across\nmultiple regression-like problems. We derive consistency, asymptotic normality,\nand validity of the bootstrap for corresponding estimators. The conditions\nallow for both continuous and discrete data as well as parametric,\nnonparametric, and semiparametric estimators of the copula and marginal\ndistributions. The versatility of this methodology is illustrated by several\ntheoretical examples, a simulation study, and an application to financial\nportfolio allocation. \n\n"}
{"id": "1802.01152", "contents": "Title: Testing to distinguish measures on metric spaces Abstract: We study the problem of distinguishing between two distributions on a metric\nspace; i.e., given metric measure spaces $({\\mathbb X}, d, \\mu_1)$ and\n$({\\mathbb X}, d, \\mu_2)$, we are interested in the problem of determining from\nfinite data whether or not $\\mu_1$ is $\\mu_2$. The key is to use pairwise\ndistances between observations and, employing a reconstruction theorem of\nGromov, we can perform such a test using a two sample Kolmogorov--Smirnov test.\nA real analysis using phylogenetic trees and flu data is presented. \n\n"}
{"id": "1802.02491", "contents": "Title: The law of a point process of Brownian excursions in a domain is\n  determined by the law of its trace Abstract: We show the result that is stated in the title of the paper, which has\nconsequences about decomposition of Brownian loop-soup clusters in two\ndimensions. \n\n"}
{"id": "1802.04037", "contents": "Title: Extinction time for the weaker of two competing SIS epidemics Abstract: We consider a simple stochastic model for the spread of a disease caused by\ntwo virus strains in a closed homogeneously mixing population of size N. The\nspread of each strain in the absence of the other one is described by the\nstochastic logistic SIS epidemic process, and we assume that there is perfect\ncross-immunity between the two strains, that is, individuals infected by one\nare temporarily immune to re-infections and infections by the other. For the\ncase where one strain has a strictly larger basic reproductive ratio than the\nother, and the stronger strain on its own is supercritical (that is, its basic\nreproductive ratio is larger than 1), we derive precise asymptotic results for\nthe distribution of the time when the weaker strain disappears from the\npopulation, that is, its extinction time. We further extend our results to\ncertain parameter values where the difference between the two reproductive\nratios may tend to 0 as $N \\to \\infty$.\n  In proving our results, we illustrate a new approach to a fluid limit\napproximation for a sequence of Markov chains in the vicinity of a stable fixed\npoint of the limit. \n\n"}
{"id": "1802.06710", "contents": "Title: Discovering Effect Modification and Randomization Inference in Air\n  Pollution Studies Abstract: Studies have shown that exposure to air pollution, even at low levels,\nsignificantly increases mortality. As regulatory actions are becoming\nprohibitively expensive, robust evidence to guide the development of targeted\ninterventions to reduce air pollution exposure is needed. In this paper, we\nintroduce a novel statistical method that splits the data into two subsamples:\n(a) Using the first subsample, we consider a data-driven search for $\\textit{de\nnovo}$ discovery of subgroups that could have exposure effects that differ from\nthe population mean; and then (b) using the second subsample, we quantify\nevidence of effect modification among the subgroups with nonparametric\nrandomization-based tests. We also develop a sensitivity analysis method to\nassess the robustness of the conclusions to unmeasured confounding bias. Via\nsimulation studies and theoretical arguments, we demonstrate that since we\ndiscover the subgroups in the first subsample, hypothesis testing on the second\nsubsample can focus on theses subgroups only, thus substantially increasing the\nstatistical power of the test. We apply our method to the data of 1,612,414\nMedicare beneficiaries in New England region in the United States for the\nperiod 2000 to 2006. We find that seniors aged between 81-85 with low income\nand seniors aged above 85 have statistically significant higher causal effects\nof exposure to PM$_{2.5}$ on 5-year mortality rate compared to the population\nmean. \n\n"}
{"id": "1802.06931", "contents": "Title: Empirical Bayes Matrix Factorization Abstract: Matrix factorization methods - including Factor analysis (FA), and Principal\nComponents Analysis (PCA) - are widely used for inferring and summarizing\nstructure in multivariate data. Many matrix factorization methods exist,\ncorresponding to different assumptions on the elements of the underlying matrix\nfactors. For example, many recent methods use a penalty or prior distribution\nto achieve sparse representations (\"Sparse FA/PCA\"). Here we introduce a\ngeneral Empirical Bayes approach to matrix factorization (EBMF), whose key\nfeature is that it uses the observed data to estimate prior distributions on\nmatrix elements. We derive a correspondingly-general variational fitting\nalgorithm, which reduces fitting EBMF to solving a simpler problem - the\nso-called \"normal means\" problem. We implement this general algorithm, but\nfocus particular attention on the use of sparsity-inducing priors that are\nuni-modal at 0. This yields a sparse EBMF approach - essentially a version of\nsparse FA/PCA - that automatically adapts the amount of sparsity to the data.\nWe demonstrate the benefits of our approach through both numerical comparisons\nwith competing methods and through analysis of data from the GTEx (Genotype\nTissue Expression) project on genetic associations across 44 human tissues. In\nnumerical comparisons EBMF often provides more accurate inferences than other\nmethods. In the GTEx data, EBMF identifies interpretable structure that\nconcords with known relationships among human tissues. Software implementing\nour approach is available at https://github.com/stephenslab/flashr \n\n"}
{"id": "1802.08114", "contents": "Title: Two-way sparsity for time-varying networks, with applications in\n  genomics Abstract: We propose a novel way of modelling time-varying networks, by inducing\ntwo-way sparsity on local models of node connectivity. This two-way sparsity\nseparately promotes sparsity across time and sparsity across variables (within\ntime). Separation of these two types of sparsity is achieved through a novel\nprior structure, which draws on ideas from the Bayesian lasso and from copula\nmodelling. We provide an efficient implementation of the proposed model via a\nGibbs sampler, and we apply the model to data from neural development. In doing\nso, we demonstrate that the proposed model is able to identify changes in\ngenomic network structure that match current biological knowledge. Such changes\nin genomic network structure can then be used by neuro-biologists to identify\npotential targets for further experimental investigation. \n\n"}
{"id": "1802.08895", "contents": "Title: A Semi-Smooth Newton Algorithm for High-Dimensional Nonconvex Sparse\n  Learning Abstract: The smoothly clipped absolute deviation (SCAD) and the minimax concave\npenalty (MCP) penalized regression models are two important and widely used\nnonconvex sparse learning tools that can handle variable selection and\nparameter estimation simultaneously, and thus have potential applications in\nvarious fields such as mining biological data in high-throughput biomedical\nstudies. Theoretically, these two models enjoy the oracle property even in the\nhigh-dimensional settings, where the number of predictors $p$ may be much\nlarger than the number of observations $n$. However, numerically, it is quite\nchallenging to develop fast and stable algorithms due to their non-convexity\nand non-smoothness. In this paper we develop a fast algorithm for SCAD and MCP\npenalized learning problems. First, we show that the global minimizers of both\nmodels are roots of the nonsmooth equations. Then, a semi-smooth Newton (SSN)\nalgorithm is employed to solve the equations. We prove that the SSN algorithm\nconverges locally and superlinearly to the Karush-Kuhn-Tucker (KKT) points.\nComputational complexity analysis shows that the cost of the SSN algorithm per\niteration is $O(np)$. Combined with the warm-start technique, the SSN algorithm\ncan be very efficient and accurate. Simulation studies and a real data example\nsuggest that our SSN algorithm, with comparable solution accuracy with the\ncoordinate descent (CD) and the difference of convex (DC) proximal Newton\nalgorithms, is more computationally efficient. \n\n"}
{"id": "1802.09057", "contents": "Title: First derivatives at the optimum analysis (\\textit{fdao}): An approach\n  to estimate the uncertainty in nonlinear regression involving stochastically\n  independent variables Abstract: An important problem of optimization analysis surges when parameters such as\n$ \\{\\theta_j\\}_{j=1,\\, \\dots \\,,k }$, determining a function $\ny=f(x\\given\\{\\theta_j\\}) $, must be estimated from a set of observables $ \\{\nx_i,y_i\\}_{i=1,\\, \\dots \\,,m} $. Where $ \\{x_i\\} $ are independent variables\nassumed to be uncertainty-free. It is known that analytical solutions are\npossible if $ y=f(x\\given\\theta_j) $ is a linear combination of $\n\\{\\theta_{j=1,\\, \\dots \\,,k} \\}.$ Here it is proposed that determining the\nuncertainty of parameters that are not \\textit{linearly independent} may be\nachieved from derivatives $ \\tfrac{\\partial f(x \\given \\{\\theta_j\\})}{\\partial\n\\theta_j} $ at an optimum, if the parameters are \\textit{stochastically\nindependent}. \n\n"}
{"id": "1802.09725", "contents": "Title: High-dimensional ABC Abstract: This Chapter, \"High-dimensional ABC\", is to appear in the forthcoming\nHandbook of Approximate Bayesian Computation (2018). It details the main ideas\nand concepts behind extending ABC methods to higher dimensions, with supporting\nexamples and illustrations. \n\n"}
{"id": "1803.00409", "contents": "Title: A simple proof of the theorem of Sklar and its extension to distribution\n  functions Abstract: In this note we provide a quick proof of the Sklar's Theorem on the existence\nof copulas by using the generalized inverse functions as in the one dimensional\ncase, but a little more sophisticated. \n\n"}
{"id": "1803.01150", "contents": "Title: Confidence intervals for high-dimensional Cox models Abstract: The purpose of this paper is to construct confidence intervals for the\nregression coefficients in high-dimensional Cox proportional hazards regression\nmodels where the number of covariates may be larger than the sample size. Our\ndebiased estimator construction is similar to those in Zhang and Zhang (2014)\nand van de Geer et al. (2014), but the time-dependent covariates and censored\nrisk sets introduce considerable additional challenges. Our theoretical\nresults, which provide conditions under which our confidence intervals are\nasymptotically valid, are supported by extensive numerical experiments. \n\n"}
{"id": "1803.01231", "contents": "Title: Bayesian Projected Calibration of Computer Models Abstract: We develop a Bayesian approach called Bayesian projected calibration to\naddress the problem of calibrating an imperfect computer model using\nobservational data from a complex physical system. The calibration parameter\nand the physical system are parametrized in an identifiable fashion via\n$L_2$-projection. The physical process is assigned a Gaussian process prior,\nwhich naturally induces a prior distribution on the calibration parameter\nthrough the $L_2$-projection constraint. The calibration parameter is estimated\nthrough its posterior distribution, which provides a natural and non-asymptotic\nway for the uncertainty quantification. We provide a rigorous large sample\njustification for the proposed approach by establishing the asymptotic\nnormality of the posterior of the calibration parameter with the efficient\ncovariance matrix. In addition, two efficient computational algorithms based on\nstochastic approximation are designed with theoretical guarantees. Through\nextensive simulation studies and two real-world datasets analyses, we show that\nthe Bayesian projected calibration can accurately estimate the calibration\nparameters, appropriately calibrate the computer models, and compare favorably\nto alternative approaches. \n\n"}
{"id": "1803.02302", "contents": "Title: Randomization inference with general interference and censoring Abstract: Interference occurs between individuals when the treatment (or exposure) of\none individual affects the outcome of another individual. Previous work on\ncausal inference methods in the presence of interference has focused on the\nsetting where a priori it is assumed there is 'partial interference,' in the\nsense that individuals can be partitioned into groups wherein there is no\ninterference between individuals in different groups. Bowers, Fredrickson, and\nPanagopoulos (2012) and Bowers, Fredrickson, and Aronow (2016) consider\nrandomization-based inferential methods that allow for more general\ninterference structures in the context of randomized experiments. In this\npaper, extensions of Bowers et al. which allow for failure time outcomes\nsubject to right censoring are proposed. Permitting right censored outcomes is\nchallenging because standard randomization-based tests of the null hypothesis\nof no treatment effect assume that whether an individual is censored does not\ndepend on treatment. The proposed extension of Bowers et al. to allow for\ncensoring entails adapting the method of Wang, Lagakos, and Gray (2010) for two\nsample survival comparisons in the presence of unequal censoring. The methods\nare examined via simulation studies and utilized to assess the effects of\ncholera vaccination in an individually-randomized trial of 73,000 children and\nwomen in Matlab, Bangladesh. \n\n"}
{"id": "1803.03348", "contents": "Title: Joint Estimation and Inference for Data Integration Problems based on\n  Multiple Multi-layered Gaussian Graphical Models Abstract: The rapid development of high-throughput technologies has enabled the\ngeneration of data from biological or disease processes that span multiple\nlayers, like genomic, proteomic or metabolomic data, and further pertain to\nmultiple sources, like disease subtypes or experimental conditions. In this\nwork, we propose a general statistical framework based on Gaussian graphical\nmodels for horizontal (i.e. across conditions or subtypes) and vertical (i.e.\nacross different layers containing data on molecular compartments) integration\nof information in such datasets. We start with decomposing the multi-layer\nproblem into a series of two-layer problems. For each two-layer problem, we\nmodel the outcomes at a node in the lower layer as dependent on those of other\nnodes in that layer, as well as all nodes in the upper layer. We use a\ncombination of neighborhood selection and group-penalized regression to obtain\nsparse estimates of all model parameters. Following this, we develop a\ndebiasing technique and asymptotic distributions of inter-layer directed edge\nweights that utilize already computed neighborhood selection coefficients for\nnodes in the upper layer. Subsequently, we establish global and simultaneous\ntesting procedures for these edge weights. Performance of the proposed\nmethodology is evaluated on synthetic and real data. \n\n"}
{"id": "1803.04521", "contents": "Title: A note on some sub-Gaussian random variables Abstract: In [8] the author of this paper continued the research on the complex-valued\ndiscrete random variables $X_l(m,N)$ ($0\\le l\\le N-1$, $1\\le M\\le N)$ recently\nintroduced and studied in [24]. Here we extend our results by considering\n$X_l(m,N)$ as sub-Gaussian random variables. Our investigation is motivated by\nthe known fact thatthe so-called Restricted Isometry Property (RIP) introduced\nin [4] holds with high probability for any matrix generated by a sub-Gaussian\nrandom variable. Notice that sensing matrices with the RIP play a crucial role\nin Theory of compressive sensing.\n  Our main results concern the proofs of the lower and upper bound estimates of\nthe expected values of the random variables $|X_l(m,N)|$, $|U_l(m,N)|$ and\n$|V_l(m,N)|$, where $U_l(m,N)$ and $U_l(m,N)$ are the real and the imaginary\npart of $X_l(m,N)$, respectively. These estimates are also given in terms of\nrelated sub-Gaussian norm $\\Vert \\cdot\\Vert_{\\psi_2}$ considered in [28].\nMoreover, we prove a refinement of the mentioned upper bound estimates for the\nreal and the imaginary part of $X_l(m,N)$. \n\n"}
{"id": "1803.04559", "contents": "Title: Weighted Bayesian Bootstrap for Scalable Bayes Abstract: We develop a weighted Bayesian Bootstrap (WBB) for machine learning and\nstatistics. WBB provides uncertainty quantification by sampling from a high\ndimensional posterior distribution. WBB is computationally fast and scalable\nusing only off-theshelf optimization software such as TensorFlow. We provide\nregularity conditions which apply to a wide range of machine learning and\nstatistical models. We illustrate our methodology in regularized regression,\ntrend filtering and deep learning. Finally, we conclude with directions for\nfuture research. \n\n"}
{"id": "1803.04582", "contents": "Title: Deep Bayesian Supervised Learning given Hypercuboidally-shaped,\n  Discontinuous Data, using Compound Tensor-Variate & Scalar-Variate Gaussian\n  Processes Abstract: We undertake Bayesian learning of the high-dimensional functional\nrelationship between a system parameter vector and an observable, that is in\ngeneral tensor-valued. The ultimate aim is Bayesian inverse prediction of the\nsystem parameters, at which test data is recorded. We attempt such learning\ngiven hypercuboidally-shaped data that displays strong discontinuities,\nrendering learning challenging. We model the sought high-dimensional function,\nwith a tensor-variate Gaussian Process (GP), and use three independent ways for\nlearning covariance matrices of the resulting likelihood, which is\nTensor-Normal. We demonstrate that the discontinuous data demands that\nimplemented covariance kernels be non-stationary--achieved by modelling each\nkernel hyperparameter, as a function of the sample function of the invoked\ntensor-variate GP. Each such function can be shown to be temporally-evolving,\nand treated as a realisation from a distinct scalar-variate GP, with covariance\ndescribed adaptively by collating information from a historical set of samples\nof chosen sample-size. We prove that deep-learning using 2-\"layers\", suffice,\nwhere the outer-layer comprises the tensor-variate GP, compounded with multiple\nscalar-variate GPs in the \"inner-layer\", and undertake inference with\nMetropolis-within-Gibbs. We apply our method to a cuboidally-shaped,\ndiscontinuous, real dataset, and subsequently perform forward prediction to\ngenerate data from our model, given our results--to perform model-checking. \n\n"}
{"id": "1803.04959", "contents": "Title: Large Deviations Optimal Scheduling of Closed Queueing Networks Abstract: We study the design of dynamic scheduling controls in closed queueing\nnetworks with a fixed number of jobs. Each time a server becomes available, the\ncontroller has (limited) flexibility in choosing the buffer from which to serve\na job. If no jobs are available at any compatible buffer, the server idles. If\nthe job is served, it relocates to a ``destination'' buffer. We study how to\nmaximize throughput in steady state via a large deviations analysis.\n  We propose a family of simple state-dependent policies called Scaled\nMaxWeight (SMW) policies that dynamically manage the distribution of jobs in\nthe network. We prove that under a complete resource pooling condition\n(analogous to the condition in Hall's marriage theorem), any SMW policy leads\nto exponential decay of throughput-loss probability as the number of jobs\nscales to infinity. Further, there is an SMW policy that achieves the optimal\nloss exponent among all scheduling policies, and we analytically specify this\npolicy in terms of the service rates and routing probabilities. The optimal SMW\npolicy maintains high job levels adjacent to structurally under-supplied\nservers. Our methodology also applies to the open network setting and leads to\nexponent-optimal policies. \n\n"}
{"id": "1803.05190", "contents": "Title: Higher order concentration in presence of Poincar\\'e-type inequalities Abstract: We show sharpened forms of the concentration of measure phenomenon typically\ncentered at stochastic expansions of order $d-1$ for any $d \\in \\mathbb{N}$.\nHere we focus on differentiable functions on the Euclidean space in presence of\na Poincar\\'e-type inequality. The bounds are based on $d$-th order derivatives. \n\n"}
{"id": "1803.06053", "contents": "Title: The world of research has gone berserk: modeling the consequences of\n  requiring \"greater statistical stringency\" for scientific publication Abstract: In response to growing concern about the reliability and reproducibility of\npublished science, researchers have proposed adopting measures of greater\nstatistical stringency, including suggestions to require larger sample sizes\nand to lower the highly criticized p<0.05 significance threshold. While pros\nand cons are vigorously debated, there has been little to no modeling of how\nadopting these measures might affect what type of science is published. In this\npaper, we develop a novel optimality model that, given current incentives to\npublish, predicts a researcher's most rational use of resources in terms of the\nnumber of studies to undertake, the statistical power to devote to each study,\nand the desirable pre-study odds to pursue. We then develop a methodology that\nallows one to estimate the reliability of published research by considering a\ndistribution of preferred research strategies. Using this approach, we\ninvestigate the merits of adopting measures of `greater statistical stringency'\nwith the goal of informing the ongoing debate. \n\n"}
{"id": "1803.06365", "contents": "Title: Inference for case-control studies with incident and prevalent cases Abstract: We propose and study a fully efficient method to estimate associations of an\nexposure with disease incidence when both, incident cases and prevalent cases,\ni.e. individuals who were diagnosed with the disease at some prior time point\nand are alive at the time of sampling, are included in a case-control study. We\nextend the exponential tilting model for the relationship between exposure and\ncase status to accommodate two case groups, and correct for the survival bias\nin the prevalent cases through a tilting term that depends on the parametric\ndistribution of the backward time, i.e. the time from disease diagnosis to\nstudy enrollment. We construct an empirical likelihood that also incorporates\nthe observed backward times for prevalent cases, obtain efficient estimates of\nodds ratio parameters that relate exposure to disease incidence and propose a\nlikelihood ratio test for model parameters that has a standard chi-squared\ndistribution. We quantify the changes in efficiency of association parameters\nwhen incident cases are supplemented with, or replaced by, prevalent cases in\nsimulations. We illustrate our methods by estimating associations of single\nnucleotide polymorphisms (SNPs) with breast cancer incidence in a sample of\ncontrols and incident and prevalent cases from the U.S. Radiologic\nTechnologists Health Study. \n\n"}
{"id": "1803.06557", "contents": "Title: Estimation of treatment effects under endogeneous heteroskedasticity Abstract: The empirical literature on program evaluation limits its scope almost\nexclusively to models where treatment effects are homogenous for\nobservationally identical individuals. This paper considers a treatment effect\nmodel in which treatment effects may be heterogeneous, even among\nobservationally identical individuals. Specifically, extending the classical\ninstrumental variables (IV) model with an endogenous binary treatment and a\nbinary instrument, we allow the heteroskedasticity of the error disturbance to\nalso depend upon the treatment variable so that treatment has both mean and\nvariance effects on the outcome. In this endogenous heteroskedasticity IV\n(EHIV) model with heterogeneous individual treatment effects, the standard IV\nestimator can be inconsistent and lead to incorrect inference. After showing\nidentification of the mean and variance treatment effects in a nonparametric\nversion of the EHIV model, we provide closed-form estimators for the linear\nEHIV for the mean and variance treatment effects and the individual treatment\neffects (ITE). Asymptotic properties of the estimators are provided. A Monte\nCarlo simulation investigates the performance of the proposed approach, and an\nempirical application regarding the effects of fertility on female labor supply\nis considered. \n\n"}
{"id": "1803.08255", "contents": "Title: A non-homogeneous hidden Markov model for partially observed\n  longitudinal responses Abstract: Dropout represents a typical issue to be addressed when dealing with\nlongitudinal studies. If the mechanism leading to missing information is\nnon-ignorable, inference based on the observed data only may be severely\nbiased. A frequent strategy to obtain reliable parameter estimates is based on\nthe use of individual-specific random coefficients that help capture sources of\nunobserved heterogeneity and, at the same time, define a reasonable structure\nof dependence between the longitudinal and the missing data process. We refer\nto elements in this class as random coefficient based dropout models (RCBDMs).\nWe propose a dynamic, semi-parametric, version of the standard RCBDM to deal\nwith discrete time to event. Time-varying random coefficients that evolve over\ntime according to a non-homogeneous hidden Markov chain are considered to model\ndependence between longitudinal responses recorded from the same subject. A\nseparate set of random coefficients is considered to model dependence between\nmissing data indicators. Last, the joint distribution of the random\ncoefficients in the two equations helps describe the dependence between the two\nprocesses. To ensure model flexibility and avoid unverifiable assumptions, we\nleave the joint distribution of the random coefficients unspecified and\nestimate it via nonparametric maximum likelihood. The proposal is applied to\ndata from the Leiden 85+ study on the evolution of cognitive functioning in the\nelderly. \n\n"}
{"id": "1803.09460", "contents": "Title: Scalable inference for crossed random effects models Abstract: We analyze the complexity of Gibbs samplers for inference in crossed random\neffect models used in modern analysis of variance. We demonstrate that for\ncertain designs the plain vanilla Gibbs sampler is not scalable, in the sense\nthat its complexity is worse than proportional to the number of parameters and\ndata. We thus propose a simple modification leading to a collapsed Gibbs\nsampler that is provably scalable. Although our theory requires some\nbalancedness assumptions on the data designs, we demonstrate in simulated and\nreal datasets that the rates it predicts match remarkably the correct rates in\ncases where the assumptions are violated. We also show that the collapsed Gibbs\nsampler, extended to sample further unknown hyperparameters, outperforms\nsignificantly alternative state of the art algorithms. \n\n"}
{"id": "1803.09488", "contents": "Title: Solving linear parabolic rough partial differential equations Abstract: We study linear rough partial differential equations in the setting of [Friz\nand Hairer, Springer, 2014, Chapter 12]. More precisely, we consider a linear\nparabolic partial differential equation driven by a deterministic rough path\n$\\mathbf{W}$ of H\\\"older regularity $\\alpha$ with $1/3 < \\alpha\n  \\le 1/2$. Based on a stochastic representation of the solution of the rough\npartial differential equation, we propose a regression Monte Carlo algorithm\nfor spatio-temporal approximation of the solution. We provide a full\nconvergence analysis of the proposed approximation method which essentially\nrelies on the new bounds for the higher order derivatives of the solution in\nspace. Finally, a comprehensive simulation study showing the applicability of\nthe proposed algorithm is presented. \n\n"}
{"id": "1803.11059", "contents": "Title: Multivariate second order Poincar\\'e inequalities for Poisson\n  functionals Abstract: Given a vector $F=(F_1,\\dots,F_m)$ of Poisson functionals $F_1,\\dots,F_m$, we\ninvestigate the proximity between $F$ and an $m$-dimensional centered Gaussian\nrandom vector $N_\\Sigma$ with covariance matrix $\\Sigma\\in\\mathbb{R}^{m\\times\nm}$. Apart from finding proximity bounds for the $d_2$- and $d_3$-distances,\nbased on classes of smooth test functions, we obtain proximity bounds for the\n$d_{convex}$-distance, based on the less tractable test functions comprised of\nindicators of convex sets. The bounds for all three distances are shown to be\nof the same order, which is presumably optimal. The bounds are multivariate\ncounterparts of the univariate second order Poincar\\'e inequalities and, as\nsuch, are expressed in terms of integrated moments of first and second order\ndifference operators. The derived second order Poincar\\'e inequalities for\nindicators of convex sets are made possible by a new bound on the second\nderivatives of the solution to the Stein equation for the multivariate normal\ndistribution. We present applications to the multivariate normal approximation\nof first order Poisson integrals and of statistics of Boolean models. \n\n"}
{"id": "1804.01034", "contents": "Title: Propagation of chaos and the many-demes limit for weakly interacting\n  diffusions in the sparse regime Abstract: Propagation of chaos is a well-studied phenomenon and shows that weakly\ninteracting diffusions may become independent as the system size converges to\ninfinity. Most of the literature focuses on the case of exchangeable systems\nwhere all involved diffusions have the same distribution and are \"of the same\nsize\". In this paper, we analyze the case where only a few diffusions start\noutside of an accessible trap. Our main result shows that in this \"sparse\nregime\" the system of weakly interacting diffusions converges in distribution\nto a forest of excursions from the trap. In particular, initial independence\npropagates in the limit and results in a forest of independent trees. \n\n"}
{"id": "1804.02646", "contents": "Title: Random walks and induced Dirichlet forms on compact spaces of\n  homogeneous type Abstract: We extend our study of random walks and induced Dirichlet forms on\nself-similar sets [arXiv:1604.05440, 1612.01708] to compact spaces of\nhomogeneous type $(K, \\rho ,\\mu)$. A successive partition on $K$ brings a\nnatural augmented tree structure $(X, E)$ that is Gromov hyperbolic, and the\nhyperbolic boundary is H\\\"older equivalent to $K$. We then introduce a class of\ntransient reversible random walks on $(X, E)$ with return ratio $\\lambda$.\nUsing Silverstein's theory of Markov chains, we prove that the random walk\ninduces an energy form on $K$ with $$ {\\mathcal E}_K [u] \\asymp \\iint_{K\\times\nK \\setminus \\Delta} \\frac{|u(\\xi) - u(\\eta)|^2}{V(\\xi, \\eta)\\rho (\\xi,\n\\eta)^\\beta} d\\mu(\\xi) d\\mu(\\eta), $$ where $V(\\xi, \\eta)$ is the $\\mu$-volume\nof the ball centered at $\\xi$ with radius $\\rho (\\xi, \\eta)$, $\\Delta$ is the\ndiagonal, and $\\beta$ depends on $\\lambda$. In particular, for an $\\alpha$-set\nin ${\\mathbb R}^d$, the kernel of the energy form is of order\n$\\frac{1}{|\\xi-\\eta|^{\\alpha +\\beta}}$. We also discuss conditions for this\nenergy form to be a non-local regular Dirichlet form. \n\n"}
{"id": "1804.03016", "contents": "Title: A Bayes-Sard Cubature Method Abstract: This paper focusses on the formulation of numerical integration as an\ninferential task. To date, research effort has largely focussed on the\ndevelopment of Bayesian cubature, whose distributional output provides\nuncertainty quantification for the integral. However, the point estimators\nassociated to Bayesian cubature can be inaccurate and acutely sensitive to the\nprior when the domain is high-dimensional. To address these drawbacks we\nintroduce Bayes-Sard cubature, a probabilistic framework that combines the\nflexibility of Bayesian cubature with the robustness of classical cubatures\nwhich are well-established. This is achieved by considering a Gaussian process\nmodel for the integrand whose mean is a parametric regression model, with an\nimproper flat prior on each regression coefficient. The features in the\nregression model consist of test functions which are guaranteed to be exactly\nintegrated, with remaining degrees of freedom afforded to the non-parametric\npart. The asymptotic convergence of the Bayes-Sard cubature method is\nestablished and the theoretical results are numerically verified. In\nparticular, we report two orders of magnitude reduction in error compared to\nBayesian cubature in the context of a high-dimensional financial integral. \n\n"}
{"id": "1804.03205", "contents": "Title: On random polynomials generated by a symmetric three-term recurrence\n  relation Abstract: We investigate the sequence $(P_{n}(z))_{n=0}^{\\infty}$ of random polynomials\ngenerated by the three-term recurrence relation $P_{n+1}(z)=z P_{n}(z)-a_{n}\nP_{n-1}(z)$, $n\\geq 1$, with initial conditions $P_{\\ell}(z)=z^{\\ell}$,\n$\\ell=0, 1$, assuming that $(a_{n})_{n\\in\\mathbb{Z}}$ is a sequence of positive\ni.i.d. random variables. $(P_{n}(z))_{n=0}^{\\infty}$ is a sequence of\northogonal polynomials on the real line, and $P_{n}$ is the characteristic\npolynomial of a Jacobi matrix $J_{n}$. We investigate the relation between the\ncommon distribution of the recurrence coefficients $a_{n}$ and two other\ndistributions obtained as weak limits of the averaged empirical and spectral\nmeasures of $J_{n}$. Our main result is a description of combinatorial\nrelations between the moments of the aforementioned distributions in terms of\ncertain classes of colored planar trees. Our approach is combinatorial, and the\nstarting point of the analysis is a formula of P. Flajolet for weight\npolynomials associated with labelled Dyck paths. \n\n"}
{"id": "1804.03366", "contents": "Title: Testing equality of spectral density operators for functional linear\n  processes Abstract: The problem of testing equality of the entire second order structure of two\nindependent functional linear processes is considered. A fully functional\n$L^2$-type test is developed which evaluates, over all frequencies, the\nHilbert-Schmidt distance between the estimated spectral density operators of\nthe two processes. The asymptotic behavior of the test statistic is\ninvestigated and its limiting distribution under the null hypothesis is\nderived. Furthermore, a novel frequency domain bootstrap method is developed\nwhich approximates more accurately the distribution of the test statistic under\nthe null than the large sample Gaussian approximation obtained. Asymptotic\nvalidity of the bootstrap procedure is established and consistency of the\nbootstrap-based test under the alternative is proved. Numerical simulations\nshow that, even for small samples, the bootstrap-based test has very good size\nand power behavior. An application to meteorological functional time series is\nalso presented. \n\n"}
{"id": "1804.05079", "contents": "Title: Robust Estimation of the Weighted Average Treatment Effect for A Target\n  Population Abstract: The weighted average treatment effect (WATE) is a causal measure for the\ncomparison of interventions in a specific target population, which may be\ndifferent from the population where data are sampled from. For instance, when\nthe goal is to introduce a new treatment to a target population, the question\nis what efficacy (or effectiveness) can be gained by switching patients from a\nstandard of care (control) to this new treatment, for which the average\ntreatment effect for the control (ATC) estimand can be applied. In this paper,\nwe propose two estimators based on augmented inverse probability weighting to\nestimate the WATE for a well defined target population (i.e., there exists a\ntarget function that describes the population of interest), using observational\ndata. The first proposed estimator is doubly robust if the target function is\nknown or can be correctly specified. The second proposed estimator is doubly\nrobust if the target function has a linear dependence on the propensity score,\nwhich can be used to estimate the average treatment effect for the treated\n(ATT) and ATC. We demonstrate the properties of the proposed estimators through\ntheoretical proof and simulation studies. We also apply our proposed methods in\na comparison of glucagon-like peptide-1 receptor agonists therapy and insulin\ntherapy among patients with type 2 diabetes, using the UK clinical practice\nresearch datalink data. \n\n"}
{"id": "1804.05545", "contents": "Title: Mendelian randomization with a binary exposure variable: interpretation\n  and presentation of causal estimates Abstract: Mendelian randomization uses genetic variants to make causal inferences about\na modifiable exposure. Subject to a genetic variant satisfying the instrumental\nvariable assumptions, an association between the variant and outcome implies a\ncausal effect of the exposure on the outcome. Complications arise with a binary\nexposure that is a dichotomization of a continuous risk factor (for example,\nhypertension is a dichotomization of blood pressure). This can lead to\nviolation of the exclusion restriction assumption: the genetic variant can\ninfluence the outcome via the continuous risk factor even if the binary\nexposure does not change. Provided the instrumental variable assumptions are\nsatisfied for the underlying continuous risk factor, causal inferences for the\nbinary exposure are valid for the continuous risk factor. Causal estimates for\nthe binary exposure assume the causal effect is a stepwise function at the\npoint of dichotomization. Even then, estimation requires further parametric\nassumptions. Under monotonicity, the causal estimate represents the average\ncausal effect in `compliers', individuals for whom the binary exposure would be\npresent if they have the genetic variant and absent otherwise. Unlike in\nrandomized trials, genetic compliers are unlikely to be a large or\nrepresentative subgroup of the population. Under homogeneity, the causal effect\nof the exposure on the outcome is assumed constant in all individuals; often an\nunrealistic assumption. We here provide methods for causal estimation with a\nbinary exposure (although subject to all the above caveats). Mendelian\nrandomization investigations with a dichotomized binary exposure should be\nconceptualized in terms of an underlying continuous variable. \n\n"}
{"id": "1804.06788", "contents": "Title: Validating Bayesian Inference Algorithms with Simulation-Based\n  Calibration Abstract: Verifying the correctness of Bayesian computation is challenging. This is\nespecially true for complex models that are common in practice, as these\nrequire sophisticated model implementations and algorithms. In this paper we\nintroduce \\emph{simulation-based calibration} (SBC), a general procedure for\nvalidating inferences from Bayesian algorithms capable of generating posterior\nsamples. This procedure not only identifies inaccurate computation and\ninconsistencies in model implementations but also provides graphical summaries\nthat can indicate the nature of the problems that arise. We argue that SBC is a\ncritical part of a robust Bayesian workflow, as well as being a useful tool for\nthose developing computational algorithms and statistical software. \n\n"}
{"id": "1804.08222", "contents": "Title: Null-free False Discovery Rate Control Using Decoy Permutations Abstract: The traditional approaches to false discovery rate (FDR) control in multiple\nhypothesis testing are usually based on the null distribution of a test\nstatistic. However, all types of null distributions, including the theoretical,\npermutation-based and empirical ones, have some inherent drawbacks. For\nexample, the theoretical null might fail because of improper assumptions on the\nsample distribution. Here, we propose a null distribution-free approach to FDR\ncontrol for multiple hypothesis testing. This approach, named target-decoy\nprocedure, simply builds on the ordering of tests by some statistic or score,\nthe null distribution of which is not required to be known. Competitive decoy\ntests are constructed from permutations of original samples and are used to\nestimate the false target discoveries. We prove that this approach controls the\nFDR when the statistics are independent between different tests. Simulation\ndemonstrates that it is more stable and powerful than two existing popular\napproaches. Evaluation is also made on a real dataset. \n\n"}
{"id": "1804.08542", "contents": "Title: From the master equation to mean field game limit theory: A central\n  limit theorem Abstract: Mean field games (MFGs) describe the limit, as $n$ tends to infinity, of\nstochastic differential games with $n$ players interacting with one another\nthrough their common empirical distribution. Under suitable smoothness\nassumptions that guarantee uniqueness of the MFG equilibrium, a form of law of\nlarge of numbers (LLN), also known as propagation of chaos, has been\nestablished to show that the MFG equilibrium arises as the limit of the\nsequence of empirical measures of the $n$-player game Nash equilibria,\nincluding the case when player dynamics are driven by both idiosyncratic and\ncommon sources of noise. The proof of convergence relies on the so-called\nmaster equation for the value function of the MFG, a partial differential\nequation on the space of probability measures. In this work, under additional\nassumptions, we establish a functional central limit theorem (CLT) that\ncharacterizes the limiting fluctuations around the LLN limit as the unique\nsolution of a linear stochastic PDE. The key idea is to use the solution to the\nmaster equation to construct an associated McKean-Vlasov interacting\n$n$-particle system that is sufficiently close to the Nash equilibrium dynamics\nof the $n$-player game for large $n$. We then derive the CLT for the latter\nfrom the CLT for the former. Along the way, we obtain a new multidimensional\nCLT for McKean-Vlasov systems. We also illustrate the broader applicability of\nour methodology by applying it to establish a CLT for a specific\nlinear-quadratic example that does not satisfy our main assumptions, and we\nexplicitly solve the resulting stochastic PDE in this case. \n\n"}
{"id": "1804.09198", "contents": "Title: The Convergence rate of the Gibbs sampler for the $2-$D Ising model via\n  a geometric bound Abstract: We study the geometric bound introduced by Diaconis and Stroock $(1991)$ of\nthe Gibbs sampler for the two-dimensional Ising model with free boundary\ncondition. The obtained result generalizes the method proposed by Shiu and Chen\n$(2015)$ from dimension one to dimension two. Furthermore we observe that the\nnew bound improves the result given by Ingrassia $(1994)$. \n\n"}
{"id": "1805.01417", "contents": "Title: A generalized spatial sign covariance matrix Abstract: The well-known spatial sign covariance matrix (SSCM) carries out a radial\ntransform which moves all data points to a sphere, followed by computing the\nclassical covariance matrix of the transformed data. Its popularity stems from\nits robustness to outliers, fast computation, and applications to correlation\nand principal component analysis. In this paper we study more general radial\nfunctions. It is shown that the eigenvectors of the generalized SSCM are still\nconsistent and the ranks of the eigenvalues are preserved. The influence\nfunction of the resulting scatter matrix is derived, and it is shown that its\nbreakdown value is as high as that of the original SSCM. A simulation study\nindicates that the best results are obtained when the inner half of the data\npoints are not transformed and points lying far away are moved to the center. \n\n"}
{"id": "1805.02044", "contents": "Title: Conditional and marginal relative risk parameters for a class of\n  recursive regression graph models Abstract: In linear regression modelling the distortion of effects after marginalizing\nover variables of the conditioning set has been widely studied in several\ncontexts. For Gaussian variables, the relationship between marginal and partial\nregression coefficients is well-established and the issue is often addressed as\na result of W. G. Cochran. Possible generalizations beyond the linear Gaussian\ncase have been developed, nevertheless the case of discrete variables is still\nchallenging, in particular in medical and social science settings. A\nmultivariate regression framework is proposed for binary data with regression\ncoefficients given by the logarithm of relative risks and a multivariate\nRelative Risk formula is derived to define the relationship between marginal\nand conditional relative risks. The method is illustrated through the analysis\nof the morphine data in order to assess the effect of preoperative oral\nmorphine administration on the postoperative pain relief. \n\n"}
{"id": "1805.02547", "contents": "Title: Learning Gene Regulatory Networks with High-Dimensional Heterogeneous\n  Data Abstract: The Gaussian graphical model is a widely used tool for learning gene\nregulatory networks with high-dimensional gene expression data. Most existing\nmethods for Gaussian graphical models assume that the data are homogeneous,\ni.e., all samples are drawn from a single Gaussian distribution. However, for\nmany real problems, the data are heterogeneous, which may contain some\nsubgroups or come from different resources. This paper proposes to model the\nheterogeneous data using a mixture Gaussian graphical model, and apply the\nimputation-consistency algorithm, combining with the $\\psi$-learning algorithm,\nto estimate the parameters of the mixture model and cluster the samples to\ndifferent subgroups. An integrated Gaussian graphical network is learned across\nthe subgroups along with the iterations of the imputation-consistency\nalgorithm. The proposed method is compared with an existing method for learning\nmixture Gaussian graphical models as well as a few other methods developed for\nhomogeneous data, such as graphical Lasso, nodewise regression and\n$\\psi$-learning. The numerical results indicate superiority of the proposed\nmethod in all aspects of parameter estimation, cluster identification and\nnetwork construction. The numerical results also indicate generality of the\nproposed method: it can be applied to homogeneous data without significant\nharms. \n\n"}
{"id": "1805.03309", "contents": "Title: Vecchia approximations of Gaussian-process predictions Abstract: Gaussian processes (GPs) are highly flexible function estimators used for\ngeospatial analysis, nonparametric regression, and machine learning, but they\nare computationally infeasible for large datasets. Vecchia approximations of\nGPs have been used to enable fast evaluation of the likelihood for parameter\ninference. Here, we study Vecchia approximations of spatial predictions at\nobserved and unobserved locations, including obtaining joint predictive\ndistributions at large sets of locations. We consider a general Vecchia\nframework for GP predictions, which contains some novel and some existing\nspecial cases. We study the accuracy and computational properties of these\napproaches theoretically and numerically, proving that our new methods exhibit\nlinear computational complexity in the total number of spatial locations. We\nshow that certain choices within the framework can have a strong effect on\nuncertainty quantification and computational cost, which leads to specific\nrecommendations on which methods are most suitable for various settings. We\nalso apply our methods to a satellite dataset of chlorophyll fluorescence,\nshowing that the new methods are faster or more accurate than existing methods,\nand reduce unrealistic artifacts in prediction maps. \n\n"}
{"id": "1805.04010", "contents": "Title: A mixture autoregressive model based on Student's $t$-distribution Abstract: A new mixture autoregressive model based on Student's $t$-distribution is\nproposed. A key feature of our model is that the conditional $t$-distributions\nof the component models are based on autoregressions that have multivariate\n$t$-distributions as their (low-dimensional) stationary distributions. That\nautoregressions with such stationary distributions exist is not immediate. Our\nformulation implies that the conditional mean of each component model is a\nlinear function of past observations and the conditional variance is also time\nvarying. Compared to previous mixture autoregressive models our model may\ntherefore be useful in applications where the data exhibits rather strong\nconditional heteroskedasticity. Our formulation also has the theoretical\nadvantage that conditions for stationarity and ergodicity are always met and\nthese properties are much more straightforward to establish than is common in\nnonlinear autoregressive models. An empirical example employing a realized\nkernel series based on S&P 500 high-frequency data shows that the proposed\nmodel performs well in volatility forecasting. \n\n"}
{"id": "1805.04344", "contents": "Title: Random Conductance Models with Stable-like Jumps: Quenched Invariance\n  Principle Abstract: We study the quenched invariance principle for random conductance models with\nlong range jumps on $\\Z^d$, where the transition probability from $x$ to $y$\nis, on average, comparable to $|x-y|^{-(d+\\alpha)}$ with $\\alpha\\in (0,2)$ but\nis allowed to be degenerate. Under some moment conditions on the conductance,\nwe prove that the scaling limit of the Markov process is a symmetric\n$\\alpha$-stable L\\'evy process on $\\R^d$.The well-known corrector method in\nhomogenization theory does not seem to work in this setting. Instead, we\nutilize probabilistic potential theory for the corresponding jump processes.\nTwo essential ingredients of our proof are the tightness estimate and the\nH\\\"{o}lder regularity of caloric functions for non-elliptic\n$\\alpha$-stable-like processes on graphs. Our method is robust enough to apply\nnot only for $\\Z^d$ but also for more general graphs whose scaling limits are\nnice metric measure spaces. \n\n"}
{"id": "1805.07562", "contents": "Title: Well-posedness of monotone semilinear SPDEs with semimartingale noise Abstract: We prove existence and uniqueness of strong solutions for a class of\nsemilinear stochastic evolution equations driven by general Hilbert\nspace-valued semimartingales, with drift equal to the sum of a linear maximal\nmonotone operator in variational form and of the superposition operator\nassociated to a random time-dependent monotone function defined on the whole\nreal line. Such a function is only assumed to satisfy a very mild symmetry-like\ncondition, but its rate of growth towards infinity can be arbitrary. Moreover,\nthe noise is of multiplicative type and can be path-dependent. The solution is\nobtained via a priori estimates on solutions to regularized equations,\ninterpreted both as stochastic equations as well as deterministic equations\nwith random coefficients, and ensuing compactness properties. A key role is\nplayed by an infinite-dimensional Doob-type inequality due to M\\'etivier and\nPellaumail. \n\n"}
{"id": "1805.08512", "contents": "Title: Non-parametric Structural Change Detection in Multivariate Systems Abstract: Structural change detection problems are often encountered in analytics and\neconometrics, where the performance of a model can be significantly affected by\nunforeseen changes in the underlying relationships. Although these problems\nhave a comparatively long history in statistics, the number of studies done in\nthe context of multivariate data under nonparametric settings is still small.\nIn this paper, we propose a consistent method for detecting multiple structural\nchanges in a system of related regressions over a large dimensional variable\nspace. In most applications, practitioners also do not have a priori\ninformation on the relevance of different variables, and therefore, both\nlocations of structural changes as well as the corresponding sparse regression\ncoefficients need to be estimated simultaneously. The method combines\nnonparametric energy distance minimization principle with penalized regression\ntechniques. After showing asymptotic consistency of the model, we compare the\nproposed approach with competing methods in a simulation study. As an example\nof a large scale application, we consider structural change point detection in\nthe context of news analytics during the recent financial crisis period. \n\n"}
{"id": "1805.09204", "contents": "Title: The first passage sets of the 2D Gaussian free field: convergence and\n  isomorphisms Abstract: In a previous article, we introduced the first passage set (FPS) of constant\nlevel $-a$ of the two-dimensional continuum Gaussian free field (GFF) on\nfinitely connected domains. Informally, it is the set of points in the domain\nthat can be connected to the boundary by a path along which the GFF is greater\nthan or equal to $-a$. This description can be taken as a definition of the FPS\nfor the metric graph GFF, and it justifies the analogy with the first hitting\ntime of $-a$ by a one-dimensional Brownian motion. In the current article, we\nprove that the metric graph FPS converges towards the continuum FPS in the\nHausdorff metric. This allows us to show that the FPS of the continuum GFF can\nbe represented as a union of clusters of Brownian excursions and Brownian\nloops, and to prove that Brownian loop soup clusters admit a non-trivial\nMinkowski content in the gauge $r\\mapsto |\\log r|^{1/2}r^2$. We also show that\ncertain natural interfaces of the metric graph GFF converge to SLE$_4$\nprocesses. \n\n"}
{"id": "1805.09392", "contents": "Title: pMSE Mechanism: Differentially Private Synthetic Data with Maximal\n  Distributional Similarity Abstract: We propose a method for the release of differentially private synthetic\ndatasets. In many contexts, data contain sensitive values which cannot be\nreleased in their original form in order to protect individuals' privacy.\nSynthetic data is a protection method that releases alternative values in place\nof the original ones, and differential privacy (DP) is a formal guarantee for\nquantifying the privacy loss. We propose a method that maximizes the\ndistributional similarity of the synthetic data relative to the original data\nusing a measure known as the pMSE, while guaranteeing epsilon-differential\nprivacy. Additionally, we relax common DP assumptions concerning the\ndistribution and boundedness of the original data. We prove theoretical results\nfor the privacy guarantee and provide simulations for the empirical failure\nrate of the theoretical results under typical computational limitations. We\nalso give simulations for the accuracy of linear regression coefficients\ngenerated from the synthetic data compared with the accuracy of\nnon-differentially private synthetic data and other differentially private\nmethods. Additionally, our theoretical results extend a prior result for the\nsensitivity of the Gini Index to include continuous predictors. \n\n"}
{"id": "1805.09840", "contents": "Title: Dynamic Chain Graph Models for Ordinal Time Series Data Abstract: This paper introduces sparse dynamic chain graph models for network inference\nin high dimensional non-Gaussian time series data. The proposed method\nparametrized by a precision matrix that encodes the intra time-slice\nconditional independence among variables at a fixed time point, and an\nautoregressive coefficient that contains dynamic conditional independences\ninteractions among time series components across consecutive time steps. The\nproposed model is a Gaussian copula vector autoregressive model, which is used\nto model sparse interactions in a high-dimensional setting. Estimation is\nachieved via a penalized EM algorithm. In this paper, we use an efficient\ncoordinate descent algorithm to optimize the penalized log-likelihood with the\nsmoothly clipped absolute deviation penalty. We demonstrate our approach on\nsimulated and genomic datasets. The method is implemented in an R package\ntsnetwork. \n\n"}
{"id": "1805.09873", "contents": "Title: Concave regression: value-constrained estimation and likelihood\n  ratio-based inference Abstract: We propose a likelihood ratio statistic for forming hypothesis tests and\nconfidence intervals for a nonparametrically estimated univariate regression\nfunction, based on the shape restriction of concavity (alternatively,\nconvexity). Dealing with the likelihood ratio statistic requires studying an\nestimator satisfying a null hypothesis, that is, studying a concave\nleast-squares estimator satisfying a further equality constraint. We study this\nnull hypothesis least-squares estimator (NLSE) here, and use it to study our\nlikelihood ratio statistic. The NLSE is the solution to a convex program, and\nwe find a set of inequality and equality constraints that characterize the\nsolution. We also study a corresponding limiting version of the convex program\nbased on observing a Brownian motion with drift. The solution to the limit\nproblem is a stochastic process. We study the optimality conditions for the\nsolution to the limit problem and find that they match those we derived for the\nsolution to the finite sample problem. This allows us to show the limit\nstochastic process yields the limit distribution of the (finite sample) NLSE.\nWe conjecture that the likelihood ratio statistic is asymptotically pivotal,\nmeaning that it has a limit distribution with no nuisance parameters to be\nestimated, which makes it a very effective tool for this difficult inference\nproblem. We provide a partial proof of this conjecture, and we also provide\nsimulation evidence strongly supporting this conjecture. \n\n"}
{"id": "1805.10540", "contents": "Title: Reliability Estimation in Coherent Systems Abstract: Usually, methods evaluating system reliability require engineers to quantify\nthe reliability of each of the system components. For series and parallel\nsystems, there are some options to handle the estimation of each component's\nreliability. We will treat the reliability estimation of complex problems of\ntwo classes of coherent systems: series-parallel, and parallel-series. In both\nof the cases, the component reliabilities may be unknown. We will present\nestimators for reliability functions at all levels of the system (component and\nsystem reliabilities). Nonparametric Bayesian estimators of all\nsub-distribution and distribution functions are derived, and a Dirichlet\nmultivariate process as a prior distribution is presented. Parametric estimator\nof the component's reliability based on Weibull model is presented for any kind\nof system. Also, some ideas in systems with masked data are discussed. \n\n"}
{"id": "1805.12377", "contents": "Title: On decoupling in Banach spaces Abstract: We consider decoupling inequalities for random variables taking values in a\nBanach space $X$. We restrict the class of distributions that appear as\nconditional distributions while decoupling and show that each adapted process\ncan be approximated by a Haar type expansion in which only the same conditional\ndistributions appear. Moreover, we show that in our framework a progressive\nenlargement of the underlying filtration does not effect the decoupling\nproperties (e.g., the constants involved). As special case we deal with\none-sided moment inequalities when decoupling dyadic (i.e., Paley-Walsh)\nmartingales. We establish the decoupling constant of $\\mathbb{R}^d$ with the\n$l^{\\infty}$-norm. As an example of an application, we demonstrate that\nBurkholder-Davis-Gundy type inequalities for stochastic integrals of $X$-valued\nprocesses can be obtained from decoupling inequalities for $X$-valued dyadic\nmartingales. \n\n"}
{"id": "1806.01238", "contents": "Title: Center-Outward Distribution Functions, Quantiles, Ranks, and Signs in\n  $\\mathbb{R}^d$ Abstract: Univariate concepts as quantile and distribution functions involving ranks\nand signs, do not canonically extend to $\\mathbb{R}^d, d\\geq 2$. Palliating\nthat has generated an abundant literature. Chapter 1 shows that, unlike the\nmany definitions that have been proposed so far, the measure\ntransportation-based ones introduced in Chernozhukov et al. (2017) enjoy all\nthe properties that make univariate quantiles and ranks successful tools for\nsemiparametric statistical inference.\n  We therefore propose a new center-outward definition of multivariate\ndistribution and quantile functions, along with their empirical counterparts,\nfor which we obtain a Glivenko-Cantelli result. Our approach is geometric and,\ncontrary to the Monge-Kantorovich one in Chernozhukov et al. (2017), does not\nrequire any moment assumptions. The resulting ranks and signs are strictly\ndistribution-free, and maximal invariant under the action of a data-driven\nclass of (order-preserving) transformations generating the family of absolutely\ncontinuous distributions; that property is the theoretical foundation of the\nsemiparametric efficiency preservation property of ranks. The corresponding\nquantiles are equivariant under the same transformations.\n  The empirical proposed distribution functions are defined at observed values\nonly. A continuous extension to the entire $\\mathbb{R}^d$, yielding continuous\nempirical quantile contours while preserving the monotonicity and\nGlivenko-Cantelli features is desirable. Such extension requires solving a\nnontrivial problem of smooth interpolation under cyclical monotonicity\nconstraints. A complete solution of that problem is given in Chapter 2; we show\nthat the resulting distribution and quantile functions are Lipschitz, and\nprovide a sharp lower bound for the Lipschitz constants. A numerical study of\nempirical center-outward quantile contours and their consistency is conducted. \n\n"}
{"id": "1806.02441", "contents": "Title: A power series identity and Bessel-type integrals over unitary groups Abstract: In 2008, Lehner, Wettig, Guhr and Wei conjectured a power series identity and\nshowed that it implied a determinantal formula for a Bessel-type integral over\nthe unitary supergroup. The integral is the supersymmetric extension of\nBessel-type integrals over the unitary group appearing as partition functions\nin quantum chromodynamics. The identity is proved by interpreting both sides as\nthe same unitary integral, which can be computed using the Cartan\ndecomposition. An equivalent identity of Schur functions is also given and\ninterpreted probabilistically. \n\n"}
{"id": "1806.02748", "contents": "Title: A stratified age-period-cohort model for spatial heterogeneity in\n  all-cause mortality Abstract: A common goal in modeling demographic rates is to compare two or more groups.\nFor ex- ample comparing mortality rates between men and women or between\ngeographic regions may reveal health inequalities. A popular class of models\nfor all-cause mortality as well as incidence of specific diseases like cancer\nis the age-period-cohort (APC) model. Extending this model to the multivariate\nsetting is not straightforward because the univariate APC model suffers from\nwell-known identifiability problems. Often APC models are fit separately for\neach strata, and then comparisons are made post hoc. This paper introduces a\nstratified APC model to directly assess the sources of heterogeneity in\nmortality rates using a Bayesian hierarchical model with matrix-normal priors\nthat share information on linear and nonlinear aspects of the APC effects\nacross strata. Computing, model selection, and prior specification are\naddressed and the model is then applied to all-cause mortality data from the\nEuropean Union. \n\n"}
{"id": "1806.03804", "contents": "Title: Central limit theorems for non-symmetric random walks on nilpotent\n  covering graphs: Part I Abstract: In the present paper, we study central limit theorems (CLTs) for\nnon-symmetric random walks on nilpotent covering graphs from a point of view of\ndiscrete geometric analysis developed by Kotani and Sunada. We establish a\nsemigroup CLT for a non-symmetric random walk on a nilpotent covering graph.\nRealizing the nilpotent covering graph into a nilpotent Lie group through a\ndiscrete harmonic map, we give a geometric characterization of the limit\nsemigroup on the nilpotent Lie group. More precisely, we show that the limit\nsemigroup is generated by the sub-Laplacian with a non-trivial drift on the\nnilpotent Lie group equipped with the Albanese metric. The drift term arises\nfrom the non-symmetry of the random walk and it vanishes when the random walk\nis symmetric. Furthermore, by imposing the \"centered condition\", we establish a\nfunctional CLT (i.e., Donsker-type invariance principle) in a Hoelder space\nover the nilpotent Lie group. The functional CLT is extended to the case where\nthe realization is not necessarily harmonic. We also obtain an explicit\nrepresentation of the limiting diffusion process on the nilpotent Lie group and\ndiscuss a relation with rough path theory. Finally, we give several examples of\nrandom walks on nilpotent covering graphs with explicit computations. \n\n"}
{"id": "1806.04119", "contents": "Title: Valid Post-selection Inference in Assumption-lean Linear Regression Abstract: Construction of valid statistical inference for estimators based on\ndata-driven selection has received a lot of attention in the recent times. Berk\net al. (2013) is possibly the first work to provide valid inference for\nGaussian homoscedastic linear regression with fixed covariates under arbitrary\ncovariate/variable selection. The setting is unrealistic and is extended by\nBachoc et al. (2016) by relaxing the distributional assumptions. A major\ndrawback of the aforementioned works is that the construction of valid\nconfidence regions is computationally intensive. In this paper, we first prove\nthat post-selection inference is equivalent to simultaneous inference and then\nconstruct valid post-selection confidence regions which are computationally\nsimple. Our construction is based on deterministic inequalities and apply to\nindependent as well as dependent random variables without the requirement of\ncorrect distributional assumptions. Finally, we compare the volume of our\nconfidence regions with the existing ones and show that under non-stochastic\ncovariates, our regions are much smaller. \n\n"}
{"id": "1806.06028", "contents": "Title: A new characterization of the Gamma distribution and associated goodness\n  of fit tests Abstract: We propose a class of weighted $L_2$-type tests of fit to the Gamma\ndistribution. Our novel procedure is based on a fixed point property of a new\ntransformation connected to a Steinian characterization of the family of Gamma\ndistributions. We derive the weak limits of the statistic under the null\nhypothesis and under contiguous alternatives. Further, we establish the global\nconsistency of the tests and apply a parametric bootstrap technique in a Monte\nCarlo simulation study to show the competitiveness to existing procedures. \n\n"}
{"id": "1806.06209", "contents": "Title: The Reduced PC-Algorithm: Improved Causal Structure Learning in Large\n  Random Networks Abstract: We consider the task of estimating a high-dimensional directed acyclic graph,\ngiven observations from a linear structural equation model with arbitrary noise\ndistribution. By exploiting properties of common random graphs, we develop a\nnew algorithm that requires conditioning only on small sets of variables. The\nproposed algorithm, which is essentially a modified version of the\nPC-Algorithm, offers significant gains in both computational complexity and\nestimation accuracy. In particular, it results in more efficient and accurate\nestimation in large networks containing hub nodes, which are common in\nbiological systems. We prove the consistency of the proposed algorithm, and\nshow that it also requires a less stringent faithfulness assumption than the\nPC-Algorithm. Simulations in low and high-dimensional settings are used to\nillustrate these findings. An application to gene expression data suggests that\nthe proposed algorithm can identify a greater number of clinically relevant\ngenes than current methods. \n\n"}
{"id": "1806.07274", "contents": "Title: Efficient data augmentation for multivariate probit models with panel\n  data: An application to general practitioner decision-making about\n  contraceptives Abstract: This article considers the problem of estimating a multivariate probit model\nin a panel data setting with emphasis on sampling a high-dimensional\ncorrelation matrix and improving the overall efficiency of the data\naugmentation approach. We reparameterise the correlation matrix in a principled\nway and then carry out efficient Bayesian inference using Hamiltonian Monte\nCarlo. We also propose a novel antithetic variable method to generate samples\nfrom the posterior distribution of the random effects and regression\ncoefficients, resulting in significant gains in efficiency. We apply the\nmethodology by analysing stated preference data obtained from Australian\ngeneral practitioners evaluating alternative contraceptive products. Our\nanalysis suggests that the joint probability of discussing combinations of\ncontraceptive products with a patient shows medical practice variation among\nthe general practitioners, which indicates some resistance to even discuss\nthese products, let alone recommend them. \n\n"}
{"id": "1806.07363", "contents": "Title: GOE Statistics for Levy Matrices Abstract: In this paper we establish eigenvector delocalization and bulk universality\nfor L\\'{e}vy matrices, which are real, symmetric, $N \\times N$ random matrices\n$\\textbf{H}$ whose upper triangular entries are independent, identically\ndistributed $\\alpha$-stable laws. First, if $\\alpha \\in (1, 2)$ and $E \\in\n\\mathbb{R}$ is any energy bounded away from $0$, we show that every eigenvector\nof $\\textbf{H}$ corresponding to an eigenvalue near $E$ is completely\ndelocalized and that the local spectral statistics of $\\textbf{H}$ around $E$\nconverge to those of the Gaussian Orthogonal Ensemble (GOE) as $N$ tends to\n$\\infty$. Second, we show for almost all $\\alpha \\in (0, 2)$, there exists a\nconstant $c(\\alpha) > 0$ such that the same statements hold if $|E| < c\n(\\alpha)$. \n\n"}
{"id": "1806.09000", "contents": "Title: Markov Kernels Local Aggregation for Noise Vanishing Distribution\n  Sampling Abstract: A novel strategy that combines a given collection of $\\pi$-reversible Markov\nkernels is proposed. At each Markov transition, one of the available kernels is\nselected via a state-dependent probability distribution. In contrast to\nrandom-scan type approaches that assume a constant (i.e. state-independent)\nselection probability distribution, the state-dependent distribution is\nspecified so as to privilege moving according to a kernel which is relevant for\nthe local topology of the target distribution. This approach leverages paths or\nother low dimensional manifolds that are typically present in noise vanishing\ndistributions. Some examples for which we show (theoretically or empirically)\nthat a locally-weighted aggregation converges substantially faster and yields\nsmaller asymptotic variances than an equivalent random-scan algorithm are\nprovided. \n\n"}
{"id": "1806.10234", "contents": "Title: Scalable Gaussian Process Inference with Finite-data Mean and Variance\n  Guarantees Abstract: Gaussian processes (GPs) offer a flexible class of priors for nonparametric\nBayesian regression, but popular GP posterior inference methods are typically\nprohibitively slow or lack desirable finite-data guarantees on quality. We\ndevelop an approach to scalable approximate GP regression with finite-data\nguarantees on the accuracy of pointwise posterior mean and variance estimates.\nOur main contribution is a novel objective for approximate inference in the\nnonparametric setting: the preconditioned Fisher (pF) divergence. We show that\nunlike the Kullback--Leibler divergence (used in variational inference), the pF\ndivergence bounds the 2-Wasserstein distance, which in turn provides tight\nbounds the pointwise difference of the mean and variance functions. We\ndemonstrate that, for sparse GP likelihood approximations, we can minimize the\npF divergence efficiently. Our experiments show that optimizing the pF\ndivergence has the same computational requirements as variational sparse GPs\nwhile providing comparable empirical performance--in addition to our novel\nfinite-data quality guarantees. \n\n"}
{"id": "1806.10705", "contents": "Title: Numerical Simulation of 2.5-Set of Iterated Stratonovich Stochastic\n  Integrals of Multiplicities 1 to 5 From the Taylor-Stratonovich Expansion Abstract: The article is devoted to construction of effective procedures of the\nmean-square approximation for iterated Stratonovich stochastic integrals of\nmultiplicities 1 to 5. We apply the method of generalized multiple Fourier\nseries for approximation of iterated stochastic integrals. More precisely, we\nuse multiple Fourier-Legendre series converging in the sense of norm in Hilbert\nspace $L_2([t,T]^k),$ $k\\in\\mathbb{N}.$ Considered iterated Stratonovich\nstochastic integrals are part of the Taylor-Stratonovich expansion. That is why\nthe results of the article can be applied to implementation of numerical\nmethods with the orders 1.0, 1.5, 2.0 and 2.5 of strong convergence for Ito\nstochastic differential equations with multidimensional non-commutative noise. \n\n"}
{"id": "1807.02535", "contents": "Title: Invertible Particle Flow-based Sequential MCMC with extension to\n  Gaussian Mixture noise models Abstract: Sequential state estimation in non-linear and non-Gaussian state spaces has a\nwide range of applications in statistics and signal processing. One of the most\neffective non-linear filtering approaches, particle filtering, suffers from\nweight degeneracy in high-dimensional filtering scenarios. Several avenues have\nbeen pursued to address high-dimensionality. Among these, particle flow\nparticle filters construct effective proposal distributions by using invertible\nflow to migrate particles continuously from the prior distribution to the\nposterior, and sequential Markov chain Monte Carlo (SMCMC) methods use a\nMetropolis-Hastings (MH) accept-reject approach to improve filtering\nperformance. In this paper, we propose to combine the strengths of invertible\nparticle flow and SMCMC by constructing a composite Metropolis-Hastings (MH)\nkernel within the SMCMC framework using invertible particle flow. In addition,\nwe propose a Gaussian mixture model (GMM)-based particle flow algorithm to\nconstruct effective MH kernels for multi-modal distributions. Simulation\nresults show that for high-dimensional state estimation example problems the\nproposed kernels significantly increase the acceptance rate with minimal\nadditional computational overhead and improve estimation accuracy compared with\nstate-of-the-art filtering algorithms. \n\n"}
{"id": "1807.03706", "contents": "Title: H\\\"older Conditions of Local Times and Exact Moduli of\n  non-differentiability for Spherical Gaussian fields Abstract: This paper investigate the local times and modulus of nondifferentiability of\nthe spherical Gaussian random fields. We extend the methods for studying the\nlocal times of Gaussian to the spherical setting. The new main ingredient is\nthe property of strong local nondeterminism established recently in Lan et al\n(2018). \n\n"}
{"id": "1807.03712", "contents": "Title: Certified dimension reduction in nonlinear Bayesian inverse problems Abstract: We propose a dimension reduction technique for Bayesian inverse problems with\nnonlinear forward operators, non-Gaussian priors, and non-Gaussian observation\nnoise. The likelihood function is approximated by a ridge function, i.e., a map\nwhich depends non-trivially only on a few linear combinations of the\nparameters. We build this ridge approximation by minimizing an upper bound on\nthe Kullback--Leibler divergence between the posterior distribution and its\napproximation. This bound, obtained via logarithmic Sobolev inequalities,\nallows one to certify the error of the posterior approximation. Computing the\nbound requires computing the second moment matrix of the gradient of the\nlog-likelihood function. In practice, a sample-based approximation of the upper\nbound is then required. We provide an analysis that enables control of the\nposterior approximation error due to this sampling. Numerical and theoretical\ncomparisons with existing methods illustrate the benefits of the proposed\nmethodology. \n\n"}
{"id": "1807.04272", "contents": "Title: Towards a Complete Picture of Stationary Covariance Functions on Spheres\n  Cross Time Abstract: With the advent of wide-spread global and continental-scale spatiotemporal\ndatasets, increased attention has been given to covariance functions on spheres\nover time. This paper provides results for stationary covariance functions of\nrandom fields defined over $d$-dimensional spheres cross time. Specifically, we\nprovide a bridge between the characterization in \\cite{berg-porcu} for\ncovariance functions on spheres cross time and Gneiting's lemma\n\\citep{gneiting2002} that deals with planar surfaces.\n  We then prove that there is a valid class of covariance functions similar in\nform to the Gneiting class of space-time covariance functions\n\\citep{gneiting2002} that replaces the squared Euclidean distance with the\ngreat circle distance. Notably, the provided class is shown to be positive\ndefinite on every $d$-dimensional sphere cross time, while the Gneiting class\nis positive definite over $\\R^d \\times \\R$ for fixed $d$ only.\n  In this context, we illustrate the value of our adapted Gneiting class by\ncomparing examples from this class to currently established nonseparable\ncovariance classes using out-of-sample predictive criteria. These comparisons\nare carried out on two climate reanalysis datasets from the National Centers\nfor Environmental Prediction and National Center for Atmospheric Research. For\nthese datasets, we show that examples from our covariance class have better\npredictive performance than competing models. \n\n"}
{"id": "1807.05420", "contents": "Title: H\\\"older continuity for the Parabolic Anderson Model with space-time\n  homogeneous Gaussian noise Abstract: In this article, we consider the Parabolic Anderson Model with constant\ninitial condition, driven by a space-time homogeneous Gaussian noise, with\ngeneral covariance function in time and spatial spectral measure satisfying\nDalang's condition. First, we prove that the solution (in the Skorohod sense)\nexists and is continuous in $L^p(\\Omega)$. Then, we show that the solution has\na modification whose sample paths are H\\\"older continuous in space and time,\nwith optimal exponents, and under the minimal condition on the spatial spectral\nmeasure of the noise (which is the same as the condition encountered in the\ncase of the white noise in time). This improves similar results which were\nobtained in Hu, Huang, Nualart and Tindel (2015), and Song (2017) under more\nrestrictive conditions, and with sub-optimal exponents for H\\\"older continuity. \n\n"}
{"id": "1807.05920", "contents": "Title: Sequential Sampling for Optimal Bayesian Classification of Sequencing\n  Count Data Abstract: High throughput technologies have become the practice of choice for\ncomparative studies in biomedical applications. Limited number of sample points\ndue to sequencing cost or access to organisms of interest necessitates the\ndevelopment of efficient sample collections to maximize the power of downstream\nstatistical analyses. We propose a method for sequentially choosing training\nsamples under the Optimal Bayesian Classification framework. Specifically\ndesigned for RNA sequencing count data, the proposed method takes advantage of\nefficient Gibbs sampling procedure with closed-form updates. Our results shows\nenhanced classification accuracy, when compared to random sampling. \n\n"}
{"id": "1807.06034", "contents": "Title: On the Local Geometry of Graphs in Terms of Their Spectra Abstract: In this paper we consider the relation between the spectrum and the number of\nshort cycles in large graphs. Suppose $G_1, G_2, G_3, \\ldots$ is a sequence of\nfinite and connected graphs that share a common universal cover $T$ and such\nthat the proportion of eigenvalues of $G_n$ that lie within the support of the\nspectrum of $T$ tends to 1 in the large $n$ limit. This is a weak notion of\nbeing Ramanujan. We prove such a sequence of graphs is asymptotically locally\ntree-like. This is deduced by way of an analogous theorem proved for certain\ninfinite sofic graphs and unimodular networks, which extends results for\nregular graphs and certain infinite Cayley graphs. \n\n"}
{"id": "1807.06858", "contents": "Title: Random walks on graphs: new bounds on hitting, meeting, coalescing and\n  returning Abstract: We prove new results on lazy random walks on finite graphs. To start, we\nobtain new estimates on return probabilities $P^t(x,x)$ and the maximum\nexpected hitting time $t_{\\rm hit}$, both in terms of the relaxation time. We\nalso prove a discrete-time version of the first-named author's ``Meeting time\nlemma\"~ that bounds the probability of random walk hitting a deterministic\ntrajectory in terms of hitting times of static vertices. The meeting time\nresult is then used to bound the expected full coalescence time of multiple\nrandom walks over a graph. This last theorem is a discrete-time version of a\nresult by the first-named author, which had been previously conjectured by\nAldous and Fill. Our bounds improve on recent results by Lyons and\nOveis-Gharan; Kanade et al; and (in certain regimes) Cooper et al. \n\n"}
{"id": "1807.06945", "contents": "Title: Cyclostationary Statistical Models and Algorithms for Anomaly Detection\n  Using Multi-Modal Data Abstract: A framework is proposed to detect anomalies in multi-modal data. A deep\nneural network-based object detector is employed to extract counts of objects\nand sub-events from the data. A cyclostationary model is proposed to model\nregular patterns of behavior in the count sequences. The anomaly detection\nproblem is formulated as a problem of detecting deviations from learned\ncyclostationary behavior. Sequential algorithms are proposed to detect\nanomalies using the proposed model. The proposed algorithms are shown to be\nasymptotically efficient in a well-defined sense. The developed algorithms are\napplied to a multi-modal data consisting of CCTV imagery and social media posts\nto detect a 5K run in New York City. \n\n"}
{"id": "1807.07765", "contents": "Title: Logarithmic Sobolev inequalities for finite spin systems and\n  applications Abstract: We derive sufficient conditions for a probability measure on a finite product\nspace (a spin system) to satisfy a (modified) logarithmic Sobolev inequality.\nWe establish these conditions for various examples, such as the\n(vertex-weighted) exponential random graph model, the random coloring and the\nhard-core model with fugacity. This leads to two separate branches of\napplications. The first branch is given by mixing time estimates of the Glauber\ndynamics. The proofs do not rely on coupling arguments, but instead use\nfunctional inequalities. As a byproduct, this also yields exponential decay of\nthe relative entropy along the Glauber semigroup. Secondly, we investigate the\nconcentration of measure phenomenon (particularly of higher order) for these\nspin systems. We show the effect of better concentration properties by\ncentering not around the mean, but a stochastic term in the exponential random\ngraph model. From there, one can deduce a central limit theorem for the number\nof triangles from the CLT of the edge count. In the Erd\\\"os-R\\'enyi model the\nfirst order approximation leads to a quantification and a proof of a central\nlimit theorem for subgraph counts. \n\n"}
{"id": "1807.07797", "contents": "Title: The Sliding Window Discrete Fourier Transform Abstract: This paper introduces a new tool for time-series analysis: the Sliding Window\nDiscrete Fourier Transform (SWDFT). The SWDFT is especially useful for\ntime-series with local- in-time periodic components. We define a 5-parameter\nmodel for noiseless local periodic signals, then study the SWDFT of this model.\nOur study illustrates several key concepts crucial to analyzing time-series\nwith the SWDFT, in particular Aliasing, Leakage, and Ringing. We also show how\nthese ideas extend to R > 1 local periodic components, using the linearity\nproperty of the Fourier transform. Next, we propose a simple procedure for\nestimating the 5 parameters of our local periodic signal model using the SWDFT.\nOur estimation procedure speeds up computation by using a trigonometric\nidentity that linearizes estimation of 2 of the 5 parameters. We conclude with\na very small Monte Carlo simulation study of our estimation procedure under\ndifferent levels of noise. \n\n"}
{"id": "1807.07932", "contents": "Title: On discrete-time semi-Markov processes Abstract: In the last years, many authors studied a class of continuous time\nsemi-Markov processes obtained by time-changing Markov processes by hitting\ntimes of independent subordinators. Such processes are governed by\nintegro-differential convolution equations of generalized fractional type. The\naim of this paper is to develop the discrete-time version of such a theory. We\nshow that a class of discrete-time semi-Markov chains can be seen as\ntime-changed Markov chains and we obtain governing convolution type equations.\nSuch processes converge weakly to those in continuous time under suitable\nscaling limits. \n\n"}
{"id": "1807.09067", "contents": "Title: Height and contour processes of Crump-Mode-Jagers forests (II): The\n  Bellman-Harris universality class Abstract: Crump-Mode-Jagers (CMJ) trees generalize Galton-Watson trees by allowing\nindividuals to live for an arbitrary duration and give birth at arbitrary times\nduring their life-time. In this paper, we exhibit a simple condition under\nwhich the height and contour processes of CMJ forests belong to the\nuniversality class of Bellman-Harris processes. This condition formalizes an\nasymptotic independence between the chronological and genealogical structures.\nWe show that it is satisfied by a large class of CMJ processes and in\nparticular, quite surprisingly, by CMJ processes with a finite variance\noffspring distribution. Along the way, we prove a general tightness result. \n\n"}
{"id": "1807.10258", "contents": "Title: Moment Varieties of Measures on Polytopes Abstract: The uniform probability measure on a convex polytope induces piecewise\npolynomial densities on its projections. For a fixed combinatorial type of\nsimplicial polytopes, the moments of these measures are rational functions in\nthe vertex coordinates. We study projective varieties that are parametrized by\nfinite collections of such rational functions. Our focus lies on determining\nthe prime ideals of these moment varieties. Special cases include Hankel\ndeterminantal ideals for polytopal splines on line segments, and the relations\namong multisymmetric functions given by the cumulants of a simplex. In general,\nour moment varieties are more complicated than in these two special cases. They\noffer challenges for both numerical and symbolic computing in algebraic\ngeometry. \n\n"}
{"id": "1807.10259", "contents": "Title: Unbiased inference for discretely observed hidden Markov model\n  diffusions Abstract: We develop a Bayesian inference method for diffusions observed discretely and\nwith noise, which is free of discretisation bias. Unlike existing unbiased\ninference methods, our method does not rely on exact simulation techniques.\nInstead, our method uses standard time-discretised approximations of\ndiffusions, such as the Euler--Maruyama scheme. Our approach is based on\nparticle marginal Metropolis--Hastings, a particle filter, randomised\nmultilevel Monte Carlo, and importance sampling type correction of approximate\nMarkov chain Monte Carlo. The resulting estimator leads to inference without a\nbias from the time-discretisation as the number of Markov chain iterations\nincreases. We give convergence results and recommend allocations for algorithm\ninputs. Our method admits a straightforward parallelisation, and can be\ncomputationally efficient. The user-friendly approach is illustrated on three\nexamples, where the underlying diffusion is an Ornstein--Uhlenbeck process, a\ngeometric Brownian motion, and a 2d non-reversible Langevin equation. \n\n"}
{"id": "1807.10797", "contents": "Title: Estimating a change point in a sequence of very high-dimensional\n  covariance matrices Abstract: This paper considers the problem of estimating a change point in the\ncovariance matrix in a sequence of high-dimensional vectors, where the\ndimension is substantially larger than the sample size. A two-stage approach is\nproposed to efficiently estimate the location of the change point. The first\nstep consists of a reduction of the dimension to identify elements of the\ncovariance matrices corresponding to significant changes. In a second step we\nuse the components after dimension reduction to determine the position of the\nchange point. Theoretical properties are developed for both steps and numerical\nstudies are conducted to support the new methodology. \n\n"}
{"id": "1807.11397", "contents": "Title: Disorder and denaturation transition in the generalized Poland-Scheraga\n  model Abstract: We investigate the generalized Poland-Scheraga model, which is used in the\nbio-physical literature to model the DNA denaturation transition, in the case\nwhere the two strands are allowed to be non-complementary (and to have\ndifferent lengths). The homogeneous model was recently studied from a\nmathematical point of view in Giacomin, Khatib (Stoch. Proc. Appl., 2017), via\na $2$-dimensional renewal approach, with a loop exponent $2+\\alpha$\n(${\\alpha>0}$): it was found to undergo a localization/delocalization phase\ntransition of order $\\nu = \\min(1,\\alpha)^{-1}$, together with -- in general --\nother phase transitions. In this paper, we turn to the disordered model, and we\naddress the question of the influence of disorder on the denaturation phase\ntransition, that is whether adding an arbitrarily small amount of disorder\n(i.e. inhomogeneities) affects the critical properties of this transition. Our\nresults are consistent with Harris' predictions for $d$-dimensional disordered\nsystems (here $d=2$). First, we prove that when $\\alpha<1$ (i.e. $\\nu>d/2$),\nthen disorder is irrelevant: the quenched and annealed critical points are\nequal, and the disordered denaturation phase transition is also of order\n$\\nu=\\alpha^{-1}$. On the other hand, when $\\alpha>1$, disorder is relevant: we\nprove that the quenched and annealed critical points differ.\n  Moreover, we discuss a number of open problems, in particular the smoothing\nphenomenon that is expected to enter the game when disorder is relevant. \n\n"}
{"id": "1808.00439", "contents": "Title: Exponential decay of truncated correlations for the Ising model in any\n  dimension for all but the critical temperature Abstract: The truncated two-point function of the ferromagnetic Ising model on $\\mathbb\nZ^d$ ($d\\ge3$) in its pure phases is proven to decay exponentially fast\nthroughout the ordered regime ($\\beta>\\beta_c$ and $h=0$). Together with the\npreviously known results, this implies that the exponential clustering property\nholds throughout the model's phase diagram except for the critical point:\n$(\\beta,h) = (\\beta_c,0)$. \n\n"}
{"id": "1808.00500", "contents": "Title: A Littlewood-Paley description of modelled distributions Abstract: We exhibit a fundamental link between Hairer's theory of regularity\nstructures and the paracontrolled calculus of Gubinelli, Imkeller and\nPerkowski. By using paraproducts we provide a Littlewood-Paley description of\nthe spaces of modelled distributions in regularity structures that is similar\nto the Besov description of classical H\\\"older spaces. \n\n"}
{"id": "1808.01431", "contents": "Title: Facets of high-dimensional Gaussian polytopes Abstract: We study the number of facets of the convex hull of n independent standard\nGaussian points in d-dimensional Euclidean space. In particular, we are\ninterested in the expected number of facets when the dimension is allowed to\ngrow with the sample size. We establish an explicit asymptotic formula that is\nvalid whenever d/n tends to zero. We also obtain the asymptotic value when d is\nclose to n. \n\n"}
{"id": "1808.01713", "contents": "Title: Mathematical Foundations of Probability Theory Abstract: In the footsteps of the book \\textit{Measure Theory and Integration By and\nFor the Learner} of our series in Probability Theory and Statistics, we\nintended to devote a special volume of the very probabilistic aspects of the\nfirst cited theory. The book might have assigned the title : From Measure\nTheory and Integration to Probability Theory. The fundamental aspects of\nProbability Theory, as described by the keywords and phrases below, are\npresented, not from experiences as in the book \\textit{A Course on Elementary\nProbability Theory}, but from a pure mathematical view based on Measure Theory.\nSuch an approach places Probability Theory in its natural frame of Functional\nAnalysis and constitutes a firm preparation to the study of Random Analysis and\nStochastic processes. At the same time, it offers a solid basis towards\nMathematical Statistics Theory. The book will be continuously updated and\nimproved on a yearly basis. \n\n"}
{"id": "1808.05889", "contents": "Title: Data Consistency Approach to Model Validation Abstract: In scientific inference problems, the underlying statistical modeling\nassumptions have a crucial impact on the end results. There exist, however,\nonly a few automatic means for validating these fundamental modelling\nassumptions. The contribution in this paper is a general criterion to evaluate\nthe consistency of a set of statistical models with respect to observed data.\nThis is achieved by automatically gauging the models' ability to generate data\nthat is similar to the observed data. Importantly, the criterion follows from\nthe model class itself and is therefore directly applicable to a broad range of\ninference problems with varying data types, ranging from independent univariate\ndata to high-dimensional time-series. The proposed data consistency criterion\nis illustrated, evaluated and compared to several well-established methods\nusing three synthetic and two real data sets. \n\n"}
{"id": "1808.06689", "contents": "Title: Bayesian Function-on-Scalars Regression for High Dimensional Data Abstract: We develop a fully Bayesian framework for function-on-scalars regression with\nmany predictors. The functional data response is modeled nonparametrically\nusing unknown basis functions, which produces a flexible and data-adaptive\nfunctional basis. We incorporate shrinkage priors that effectively remove\nunimportant scalar covariates from the model and reduce sensitivity to the\nnumber of (unknown) basis functions. For variable selection in functional\nregression, we propose a decision theoretic posterior summarization technique,\nwhich identifies a subset of covariates that retains nearly the predictive\naccuracy of the full model. Our approach is broadly applicable for Bayesian\nfunctional regression models, and unlike existing methods provides joint rather\nthan marginal selection of important predictor variables. Computationally\nscalable posterior inference is achieved using a Gibbs sampler with linear time\ncomplexity in the number of predictors. The resulting algorithm is empirically\nfaster than existing frequentist and Bayesian techniques, and provides joint\nestimation of model parameters, prediction and imputation of functional\ntrajectories, and uncertainty quantification via the posterior distribution. A\nsimulation study demonstrates improvements in estimation accuracy, uncertainty\nquantification, and variable selection relative to existing alternatives. The\nmethodology is applied to actigraphy data to investigate the association\nbetween intraday physical activity and responses to a sleep questionnaire. \n\n"}
{"id": "1808.07387", "contents": "Title: Sensitivity Analysis using Approximate Moment Condition Models Abstract: We consider inference in models defined by approximate moment conditions. We\nshow that near-optimal confidence intervals (CIs) can be formed by taking a\ngeneralized method of moments (GMM) estimator, and adding and subtracting the\nstandard error times a critical value that takes into account the potential\nbias from misspecification of the moment conditions. In order to optimize\nperformance under potential misspecification, the weighting matrix for this GMM\nestimator takes into account this potential bias, and therefore differs from\nthe one that is optimal under correct specification. To formally show the\nnear-optimality of these CIs, we develop asymptotic efficiency bounds for\ninference in the locally misspecified GMM setting. These bounds may be of\nindependent interest, due to their implications for the possibility of using\nmoment selection procedures when conducting inference in moment condition\nmodels. We apply our methods in an empirical application to automobile demand,\nand show that adjusting the weighting matrix can shrink the CIs by a factor of\n3 or more. \n\n"}
{"id": "1808.07409", "contents": "Title: The domino shuffling height process and its hydrodynamic limit Abstract: The famous domino shuffling algorithm was invented to generate the domino\ntilings of the Aztec Diamond. Using the domino height function, we view the\ndomino shuffling procedure as a discrete-time random height process on the\nplane. The hydrodynamic limit from an arbitrary continuous profile is deduced\nto be the unique viscosity solution of a Hamilton-Jacobi equation\n$u_t+H(u_x)=0$, where the determinant of the Hessian of $H$ is negative\neverywhere. The proof involves interpolation of the discrete process and\nanalysis of the limiting semigroup of the evolution. In order to identify the\nlimit, we use the theories of dimer models as well as Hamilton-Jacobi\nequations.\n  It seems that our result is the first example in $d>1$ where such a full\nhydrodynamic limit with a nonconvex Hamiltonian can be obtained for a discrete\nsystem. We also define the shuffling height process for more general periodic\ndimer models, where we expect similar results to hold. \n\n"}
{"id": "1808.08507", "contents": "Title: Mallows Ranking Models: Maximum Likelihood Estimate and Regeneration Abstract: This paper is concerned with various Mallows ranking models. We study the\nstatistical properties of the MLE of Mallows' $\\phi$ model. We also make\nconnections of various Mallows ranking models, encompassing recent progress in\nmathematics. Motivated by the infinite top-$t$ ranking model, we propose an\nalgorithm to select the model size $t$ automatically. The key idea relies on\nthe renewal property of such an infinite random permutation. Our algorithm\nshows good performance on several data sets. \n\n"}
{"id": "1808.08683", "contents": "Title: Regression adjustments for estimating the global treatment effect in\n  experiments with interference Abstract: Standard estimators of the global average treatment effect can be biased in\nthe presence of interference. This paper proposes regression adjustment\nestimators for removing bias due to interference in Bernoulli randomized\nexperiments. We use a fitted model to predict the counterfactual outcomes of\nglobal control and global treatment. Our work differs from standard regression\nadjustments in that the adjustment variables are constructed from functions of\nthe treatment assignment vector, and that we allow the researcher to use a\ncollection of any functions correlated with the response, turning the problem\nof detecting interference into a feature engineering problem. We characterize\nthe distribution of the proposed estimator in a linear model setting and\nconnect the results to the standard theory of regression adjustments under\nSUTVA. We then propose an estimator that allows for flexible machine learning\nestimators to be used for fitting a nonlinear interference functional form. We\npropose conducting statistical inference via bootstrap and resampling methods,\nwhich allow us to sidestep the complicated dependences implied by interference\nand instead rely on empirical covariance structures. Such variance estimation\nrelies on an exogeneity assumption akin to the standard unconfoundedness\nassumption invoked in observational studies. In simulation experiments, our\nmethods are better at debiasing estimates than existing inverse propensity\nweighted estimators based on neighborhood exposure modeling. We use our method\nto reanalyze an experiment concerning weather insurance adoption conducted on a\ncollection of villages in rural China. \n\n"}
{"id": "1808.09011", "contents": "Title: Cauchy combination test: a powerful test with analytic p-value\n  calculation under arbitrary dependency structures Abstract: Combining individual p-values to aggregate multiple small effects has a\nlong-standing interest in statistics, dating back to the classic Fisher's\ncombination test. In modern large-scale data analysis, correlation and sparsity\nare common features and efficient computation is a necessary requirement for\ndealing with massive data. To overcome these challenges, we propose a new test\nthat takes advantage of the Cauchy distribution. Our test statistic has a very\nsimple form and is defined as a weighted sum of Cauchy transformation of\nindividual p-values. We prove a non-asymptotic result that the tail of the null\ndistribution of our proposed test statistic can be well approximated by a\nCauchy distribution under arbitrary dependency structures. Based on this\ntheoretical result, the p-value calculation of our proposed test is not only\naccurate, but also as simple as the classic z-test or t-test, making our test\nwell suited for analyzing massive data. We further show that the power of the\nproposed test is asymptotically optimal in a strong sparsity setting. Extensive\nsimulations demonstrate that the proposed test has both strong power against\nsparse alternatives and a good accuracy with respect to p-value calculations,\nespecially for very small p-values. The proposed test has also been applied to\na genome-wide association study of Crohn's disease and compared with several\nexisting tests. \n\n"}
{"id": "1808.09521", "contents": "Title: Bounds on the conditional and average treatment effect with unobserved\n  confounding factors Abstract: For observational studies, we study the sensitivity of causal inference when\ntreatment assignments may depend on unobserved confounders. We develop a loss\nminimization approach for estimating bounds on the conditional average\ntreatment effect (CATE) when unobserved confounders have a bounded effect on\nthe odds ratio of treatment selection. Our approach is scalable and allows\nflexible use of model classes in estimation, including nonparametric and\nblack-box machine learning methods. Based on these bounds for the CATE, we\npropose a sensitivity analysis for the average treatment effect (ATE). Our\nsemi-parametric estimator extends/bounds the augmented inverse propensity\nweighted (AIPW) estimator for the ATE under bounded unobserved confounding. By\nconstructing a Neyman orthogonal score, our estimator of the bound for the ATE\nis a regular root-$n$ estimator so long as the nuisance parameters are\nestimated at the $o_p(n^{-1/4})$ rate. We complement our methodology with\noptimality results showing that our proposed bounds are tight in certain cases.\nWe demonstrate our method on simulated and real data examples, and show\naccurate coverage of our confidence intervals in practical finite sample\nregimes with rich covariate information. \n\n"}
{"id": "1808.10500", "contents": "Title: On self-avoiding polygons and walks: the snake method via polygon\n  joining Abstract: For $d \\geq 2$ and $n \\in \\mathbb{N}$, let $\\mathsf{W}_n$ denote the uniform\nlaw on self-avoiding walks beginning at the origin in the integer lattice\n$\\mathbb{Z}^d$, and write $\\Gamma$ for a $\\mathsf{W}_n$-distributed walk. We\nshow that the closing probability $\\mathsf{W}_n \\big( \\vert \\vert \\Gamma_n\n\\vert \\vert = 1 \\big)$ that $\\Gamma$'s endpoint neighbours the origin is at\nmost $n^{-4/7 + o(1)}$ for a positive density set of odd $n$ in dimension $d =\n2$. This result is proved using the snake method, a technique for proving\nclosing probability upper bounds, which originated in [3] and was made explicit\nin [8]. Our conclusion is reached by applying the snake method in unison with a\npolygon joining technique whose use was initiated by Madras in [13]. \n\n"}
{"id": "1808.10506", "contents": "Title: Maximum Entropy Principle Analysis in Network Systems with Short-time\n  Recordings Abstract: In many realistic systems, maximum entropy principle (MEP) analysis provides\nan effective characterization of the probability distribution of network\nstates. However, to implement the MEP analysis, a sufficiently long-time data\nrecording in general is often required, e.g., hours of spiking recordings of\nneurons in neuronal networks. The issue of whether the MEP analysis can be\nsuccessfully applied to network systems with data from short recordings has yet\nto be fully addressed. In this work, we investigate relationships underlying\nthe probability distributions, moments, and effective interactions in the MEP\nanalysis and then show that, with short recordings of network dynamics, the MEP\nanalysis can be applied to reconstructing probability distributions of network\nstates under the condition of asynchronous activity of nodes in the network.\nUsing spike trains obtained from both Hodgkin-Huxley neuronal networks and\nelectrophysiological experiments, we verify our results and demonstrate that\nMEP analysis provides a tool to investigate the neuronal population coding\nproperties, even for short recordings. \n\n"}
{"id": "1808.10843", "contents": "Title: Tropical Gaussians: A Brief Survey Abstract: We review the existing analogues of the Gaussian measure in the tropical\nsemiring and outline various research directions. \n\n"}
{"id": "1809.00236", "contents": "Title: Optimal Bandwidth Choice for Robust Bias Corrected Inference in\n  Regression Discontinuity Designs Abstract: Modern empirical work in Regression Discontinuity (RD) designs often employs\nlocal polynomial estimation and inference with a mean square error (MSE)\noptimal bandwidth choice. This bandwidth yields an MSE-optimal RD treatment\neffect estimator, but is by construction invalid for inference. Robust bias\ncorrected (RBC) inference methods are valid when using the MSE-optimal\nbandwidth, but we show they yield suboptimal confidence intervals in terms of\ncoverage error. We establish valid coverage error expansions for RBC confidence\ninterval estimators and use these results to propose new inference-optimal\nbandwidth choices for forming these intervals. We find that the standard\nMSE-optimal bandwidth for the RD point estimator is too large when the goal is\nto construct RBC confidence intervals with the smallest coverage error. We\nfurther optimize the constant terms behind the coverage error to derive new\noptimal choices for the auxiliary bandwidth required for RBC inference. Our\nexpansions also establish that RBC inference yields higher-order refinements\n(relative to traditional undersmoothing) in the context of RD designs. Our main\nresults cover sharp and sharp kink RD designs under conditional\nheteroskedasticity, and we discuss extensions to fuzzy and other RD designs,\nclustered sampling, and pre-intervention covariates adjustments. The\ntheoretical findings are illustrated with a Monte Carlo experiment and an\nempirical application, and the main methodological results are available in\n\\texttt{R} and \\texttt{Stata} packages. \n\n"}
{"id": "1809.00775", "contents": "Title: Stretched exponential decay of correlations in the quasiperiodic\n  continuum percolation model Abstract: We study the continuum percolation model, which is defined on\n$\\mathbb{Z}^d\\times \\mathbb{R}$ so that the connections in the continuous\ndirections are not oriented in time, with quasiperiodically disordered fields.\nThe oriented version of the model is the contact process. We consider\nintermediate strengths of disorder of the fields and show stretched exponential\ndecay of correlations. \n\n"}
{"id": "1809.02385", "contents": "Title: Mixtures of Skewed Matrix Variate Bilinear Factor Analyzers Abstract: In recent years, data have become increasingly higher dimensional and,\ntherefore, an increased need has arisen for dimension reduction techniques for\nclustering. Although such techniques are firmly established in the literature\nfor multivariate data, there is a relative paucity in the area of matrix\nvariate, or three-way, data. Furthermore, the few methods that are available\nall assume matrix variate normality, which is not always sensible if cluster\nskewness or excess kurtosis is present. Mixtures of bilinear factor analyzers\nusing skewed matrix variate distributions are proposed. In all, four such\nmixture models are presented, based on matrix variate skew-t, generalized\nhyperbolic, variance-gamma, and normal inverse Gaussian distributions,\nrespectively. \n\n"}
{"id": "1809.05800", "contents": "Title: Robust Bayesian Synthetic Likelihood via a Semi-Parametric Approach Abstract: Bayesian synthetic likelihood (BSL) is now a well established method for\nperforming approximate Bayesian parameter estimation for simulation-based\nmodels that do not possess a tractable likelihood function. BSL approximates an\nintractable likelihood function of a carefully chosen summary statistic at a\nparameter value with a multivariate normal distribution. The mean and\ncovariance matrix of this normal distribution are estimated from independent\nsimulations of the model. Due to the parametric assumption implicit in BSL, it\ncan be preferred to its non-parametric competitor, approximate Bayesian\ncomputation, in certain applications where a high-dimensional summary statistic\nis of interest. However, despite several successful applications of BSL, its\nwidespread use in scientific fields may be hindered by the strong normality\nassumption. In this paper, we develop a semi-parametric approach to relax this\nassumption to an extent and maintain the computational advantages of BSL\nwithout any additional tuning. We test our new method, semiBSL, on several\nchallenging examples involving simulated and real data and demonstrate that\nsemiBSL can be significantly more robust than BSL and another approach in the\nliterature. \n\n"}
{"id": "1809.08035", "contents": "Title: Analytic inference in finite population framework via resampling Abstract: The aim of this paper is to provide a resampling technique that allows us to\nmake inference on superpopulation parameters in finite population setting.\nUnder complex sampling designs, it is often difficult to obtain explicit\nresults about superpopulation parameters of interest, especially in terms of\nconfidence intervals and test-statistics. Computer intensive procedures, such\nas resampling, allow us to avoid this problem. To reach the above goal,\nasymptotic results about empirical processes in finite population framework are\nfirst obtained. Then, a resampling procedure is proposed, and justified via\nasymptotic considerations. Finally, the results obtained are applied to\ndifferent inferential problems and a simulation study is performed to test the\ngoodness of our proposal. \n\n"}
{"id": "1809.09276", "contents": "Title: A Berry-Esseen theorem for Pitman's $\\alpha$-diversity Abstract: This paper is concerned with the study of the random variable $K_n$ denoting\nthe number of distinct elements in a random sample $(X_1, \\dots, X_n)$ of\nexchangeable random variables driven by the two parameter Poisson-Dirichlet\ndistribution, $PD(\\alpha,\\theta)$. For $\\alpha\\in(0,1)$, Theorem 3.8 in\n\\cite{Pit(06)} shows that\n$\\frac{K_n}{n^{\\alpha}}\\stackrel{\\text{a.s.}}{\\longrightarrow}\nS_{\\alpha,\\theta}$ as $n\\rightarrow+\\infty$. Here, $S_{\\alpha,\\theta}$ is a\nrandom variable distributed according to the so-called scaled Mittag-Leffler\ndistribution. Our main result states that $$ \\sup_{x \\geq 0} \\Big|\n\\ppsf\\Big[\\frac{K_n}{n^{\\alpha}} \\leq x \\Big] - \\ppsf[S_{\\alpha,\\theta} \\leq x]\n\\Big| \\leq \\frac{C(\\alpha, \\theta)}{n^{\\alpha}} $$ holds with an explicit\nconstant $C(\\alpha, \\theta)$. The key ingredients of the proof are a novel\nprobabilistic representation of $K_n$ as compound distribution and new, refined\nversions of certain quantitative bounds for the Poisson approximation and the\ncompound Poisson distribution. \n\n"}
{"id": "1809.10476", "contents": "Title: Singular vector and singular subspace distribution for the matrix\n  denoising model Abstract: In this paper, we study the matrix denosing model $Y=S+X$, where $S$ is a\nlow-rank deterministic signal matrix and $X$ is a random noise matrix, and both\nare $M\\times n$. In the scenario that $M$ and $n$ are comparably large and the\nsignals are supercritical, we study the fluctuation of the outlier singular\nvectors of $Y$. More specifically, we derive the limiting distribution of\nangles between the principal singular vectors of $Y$ and their deterministic\ncounterparts, the singular vectors of $S$. Further, we also derive the\ndistribution of the distance between the subspace spanned by the principal\nsingular vectors of $Y$ and that spanned by the singular vectors of $S$. It\nturns out that the limiting distributions depend on the structure of the\nsingular vectors of $S$ and the distribution of $X$, and thus they are\nnon-universal. \n\n"}
{"id": "1809.11076", "contents": "Title: A Unified Approach to Construct Correlation Coefficient Between Random\n  Variables Abstract: Measuring the correlation (association) between two random variables is one\nof the important goals in statistical applications. In the literature, the\ncovariance between two random variables is a widely used criterion in measuring\nthe linear association between two random variables. In this paper, first we\npropose a covariance based unified measure of variability for a continuous\nrandom variable X and we show that several measures of variability and\nuncertainty, such as variance, Gini mean difference, cumulative residual\nentropy, etc., can be considered as special cases. Then, we propose a unified\nmeasure of correlation between two continuous random variables X and Y, with\ndistribution functions (DFs) F and G, based on the covariance between X and\nH^{-1}G(Y) (known as the Q-transformation of H on G) where H is a continuous\nDF. We show that our proposed measure of association subsumes some of the\nexisting measures of correlation. Under some mild condition on H, it is shown\nthe suggested index ranges between [-1,1] where the extremes of the range,\ni.e., -1 and 1, are attainable by the Frechet bivariate minimal and maximal\nDFs, respectively. A special case of the proposed correlation measure leads to\na variant of Pearson correlation coefficient which, as a measure of strength\nand direction of the linear relationship between X and Y, has absolute values\ngreater than or equal to the Pearson correlation. The results are examined\nnumerically for some well known bivariate DFs. \n\n"}
{"id": "1810.00274", "contents": "Title: Bayesian network marker selection via the thresholded graph Laplacian\n  Gaussian prior Abstract: Selecting informative nodes over large-scale networks becomes increasingly\nimportant in many research areas. Most existing methods focus on the local\nnetwork structure and incur heavy computational costs for the large-scale\nproblem. In this work, we propose a novel prior model for Bayesian network\nmarker selection in the generalized linear model (GLM) framework: the\nThresholded Graph Laplacian Gaussian (TGLG) prior, which adopts the graph\nLaplacian matrix to characterize the conditional dependence between neighboring\nmarkers accounting for the global network structure. Under mild conditions, we\nshow the proposed model enjoys the posterior consistency with a diverging\nnumber of edges and nodes in the network. We also develop a Metropolis-adjusted\nLangevin algorithm (MALA) for efficient posterior computation, which is\nscalable to large-scale networks. We illustrate the superiorities of the\nproposed method compared with existing alternatives via extensive simulation\nstudies and an analysis of the breast cancer gene expression dataset in the\nCancer Genome Atlas (TCGA). \n\n"}
{"id": "1810.01180", "contents": "Title: A variational formula for risk-sensitive control of diffusions in\n  $\\mathbb{R}^d$ Abstract: We address the variational problem for the generalized principal eigenvalue\non $\\mathbb{R}^d$ of linear and semilinear elliptic operators associated with\nnondegenerate diffusions controlled through the drift. We establish the\nCollatz-Wielandt formula for potentials that vanish at infinity under minimal\nhypotheses, and also for general potentials under blanket geometric ergodicity\nassumptions. We also present associated results having the flavor of a refined\nmaximum principle. \n\n"}
{"id": "1810.01625", "contents": "Title: Weak Convergence (IIA) - Functional and Random Aspects of the Univariate\n  Extreme Value Theory Abstract: The univariate extreme value theory deals with the convergence in type of\npowers of elements of sequences of cumulative distribution functions on the\nreal line when the power index gets infinite. In terms of convergence of random\nvariables, this amounts to the the weak convergence, in the sense of\nprobability measures weak convergence, of the partial maximas of a sequence of\nindependent and identically distributed random variables. In this monograph,\nthis theory is comprehensively studied in the broad frame of weak convergence\nof random vectors as exposed in Lo et al.(2016). It has two main parts. The\nfirst is devoted to its nice mathematical foundation. Most of the materials of\nthis part is taken from the most essential Lo\\`eve(1936,177) and Haan (1970),\nbased on the stunning theory of regular, pi or gamma variation. To prepare the\nstatistical applications, a number contributions I made in my PhD and my\nDoctorate of Sciences are added in the last chapter of the last chapter of that\npart. Our real concern is to put these materials together with others, among\nthem those of the authors from his PhD dissertations and Science doctorate\nthesis, in a way to have an almost full coverage of the theory on the real line\nthat may serve as a master course of one semester in our universities. As well,\nit will help the second part of the monograph. This second part will deal with\nstatistical estimations problems related to extreme values. It addresses\nvarious estimation questions and should be considered as the beginning of a\nsurvey study to be updated progressively. Research questions are tackled\ntherein. Many results of the author, either unpublished or not sufficiently\nknown, are stated and/or updated therein. \n\n"}
{"id": "1810.02043", "contents": "Title: High-dimensional general linear hypothesis tests via non-linear spectral\n  shrinkage Abstract: We are interested in testing general linear hypotheses in a high-dimensional\nmultivariate linear regression model. The framework includes many well-studied\nproblems such as two-sample tests for equality of population means, MANOVA and\nothers as special cases. A family of rotation-invariant tests is proposed that\ninvolves a flexible spectral shrinkage scheme applied to the sample error\ncovariance matrix. The asymptotic normality of the test statistic under the\nnull hypothesis is derived in the setting where dimensionality is comparable to\nsample sizes, assuming the existence of certain moments for the observations.\nThe asymptotic power of the proposed test is studied under various local\nalternatives. The power characteristics are then utilized to propose a\ndata-driven selection of the spectral shrinkage function. As an illustration of\nthe general theory, we construct a family of tests involving ridge-type\nregularization and suggest possible extensions to more complex regularizers. A\nsimulation study is carried out to examine the numerical performance of the\nproposed tests. \n\n"}
{"id": "1810.03296", "contents": "Title: Event History Analysis of Dynamic Communication Networks Abstract: Statistical analysis on networks has received growing attention due to demand\nfrom various emerging applications. In dynamic networks, one of the key\ninterests is to model the event history of time-stamped interactions amongst\nnodes. We propose to model dynamic directed communication networks via\nmultivariate counting processes. A pseudo partial likelihood approach is\nexploited to capture the network dependence structure. Asymptotic results of\nthe resulting estimation are established. Numerical results are performed to\ndemonstrate effectiveness of our proposal. \n\n"}
{"id": "1810.04630", "contents": "Title: Equivalence Test in Multi-dimensional Space with Applications in A/B\n  Testing Abstract: In this paper, we provide a statistical testing framework to check whether a\nrandom sample splitting in a multi-dimensional space is carried out in a valid\nway, which could be directly applied to A/B testing and multivariate testing to\nensure the online traffic split is truly random with respect to the covariates.\nWe believe this is an important step of quality control that is missing in many\nreal world online experiments. Here, we propose a randomized chi-square test\nmethod, compared with propensity score and distance components (DISCO) test\nmethods, to test the hypothesis that the post-split categorical data sets have\nthe same multi-dimensional distribution. The methods can be easily generalized\nto continuous data. We also propose a resampling procedure to adjust for\nmultiplicity which in practice often has higher power than some existing method\nsuch as Holm's procedure. We try the three methods on both simulated and real\ndata sets from Adobe Experience Cloud and show that each method has its own\nadvantage while all of them establish promising power. To our knowledge, we are\namong the first ones to formulate the validity of A/B testing into a\npost-experiments statistical testing problem. Our methodology is non-parametric\nand requires minimum assumption on the data, so it can also have a wide range\nof application in other areas such as clinical trials, medicine, and\nrecommendation system where random data splitting is needed. \n\n"}
{"id": "1810.05326", "contents": "Title: Central limit theorem and moderate deviations for a stochastic\n  Cahn-Hilliard equation Abstract: In this paper, we prove a central limit theorem and a moderate deviation\nprinciple for a perturbed stochastic Cahn-Hilliard equation defined on [0, T]x\n[0, \\pi]^d, with d \\in {1,2,3}. This equation is driven by a space-time white\nnoise. The weak convergence approach plays an important role. \n\n"}
{"id": "1810.05450", "contents": "Title: Fast approximate inference for variable selection in Dirichlet process\n  mixtures, with an application to pan-cancer proteomics Abstract: The Dirichlet Process (DP) mixture model has become a popular choice for\nmodel-based clustering, largely because it allows the number of clusters to be\ninferred. The sequential updating and greedy search (SUGS) algorithm (Wang and\nDunson, 2011) was proposed as a fast method for performing approximate Bayesian\ninference in DP mixture models, by posing clustering as a Bayesian model\nselection (BMS) problem and avoiding the use of computationally costly Markov\nchain Monte Carlo methods. Here we consider how this approach may be extended\nto permit variable selection for clustering, and also demonstrate the benefits\nof Bayesian model averaging (BMA) in place of BMS. Through an array of\nsimulation examples and well-studied examples from cancer transcriptomics, we\nshow that our method performs competitively with the current state-of-the-art,\nwhile also offering computational benefits. We apply our approach to\nreverse-phase protein array (RPPA) data from The Cancer Genome Atlas (TCGA) in\norder to perform a pan-cancer proteomic characterisation of 5,157 tumour\nsamples. We have implemented our approach, together with the original SUGS\nalgorithm, in an open-source R package named sugsvarsel, which accelerates\nanalysis by performing intensive computations in C++ and provides automated\nparallel processing. The R package is freely available from:\nhttps://github.com/ococrook/sugsvarsel \n\n"}
{"id": "1810.05999", "contents": "Title: Existence of differentiable curves in convex sets and the concept of\n  direction of the flow in mass transportation Abstract: In this paper we consider convex subsets of locally-convex topological vector\nspaces. Given a fixed point in such a convex subset, we show that there exists\na curve completely contained in the convex subset and leaving the point in a\ngiven direction if and only if the direction vector is contained in the\nsequential closure of the tangent cone at that point.\n  We apply this result to the characterization of the existence of weakly\ndifferentiable families of probability measures on a smooth manifold and of the\ndistributions that can arise as their derivatives. This gives us a way to\nconsider the mass transport equation in a very general context, in which the\nnotion of direction turns out to be given by an element of a Colombeau algebra. \n\n"}
{"id": "1810.06089", "contents": "Title: Asymptotics for Sketching in Least Squares Regression Abstract: We consider a least squares regression problem where the data has been\ngenerated from a linear model, and we are interested to learn the unknown\nregression parameters. We consider \"sketch-and-solve\" methods that randomly\nproject the data first, and do regression after. Previous works have analyzed\nthe statistical and computational performance of such methods. However, the\nexisting analysis is not fine-grained enough to show the fundamental\ndifferences between various methods, such as the Subsampled Randomized Hadamard\nTransform (SRHT) and Gaussian projections. In this paper, we make progress on\nthis problem, working in an asymptotic framework where the number of datapoints\nand dimension of features goes to infinity. We find the limits of the accuracy\nloss (for estimation and test error) incurred by popular sketching methods. We\nshow separation between different methods, so that SRHT is better than Gaussian\nprojections. Our theoretical results are verified on both real and synthetic\ndata. The analysis of SRHT relies on novel methods from random matrix theory\nthat may be of independent interest. \n\n"}
{"id": "1810.06191", "contents": "Title: Inverse Problems and Data Assimilation Abstract: We provide a clear and concise introduction to the subjects of inverse\nproblems and data assimilation, and their inter-relations. The first part of\nour notes covers inverse problems; this refers to the study of how to estimate\nunknown model parameters from data. The second part of our notes covers data\nassimilation; this refers to a particular class of inverse problems in which\nthe unknown parameter is the initial condition (and/or state) of a dynamical\nsystem, and the data comprises partial and noisy observations of the state. The\nthird and final part of our notes describes the use of data assimilation\nmethods to solve generic inverse problems by introducing an artificial\nalgorithmic time. Our notes cover, among other topics, maximum a posteriori\nestimation, (stochastic) gradient descent, variational Bayes, Monte Carlo,\nimportance sampling and Markov chain Monte Carlo for inverse problems; and\n3DVAR, 4DVAR, extended and ensemble Kalman filters, and particle filters for\ndata assimilation.\n  Each of parts one and two starts with a chapter on the Bayesian formulation,\nin which the problem solution is given by a posterior distribution on the\nunknown parameter. Then the following chapter specializes the Bayesian\nformulation to a linear-Gaussian setting where explicit characterization of the\nposterior is possible and insightful. The next two chapters explore methods to\nextract information from the posterior in nonlinear and non-Gaussian settings\nusing optimization and Gaussian approximations. The final two chapters describe\nsampling methods that can reproduce the full posterior in the large sample\nlimit. Each chapter closes with a bibliography containing citations to\nalternative pedagogical literature and to relevant research literature. We also\ninclude a set of exercises at the end of parts one and two. Our notes are thus\nuseful for both classroom teaching and self-guided study. \n\n"}
{"id": "1810.06781", "contents": "Title: On the local pairing behavior of critical points and roots of random\n  polynomials Abstract: We study the pairing between zeros and critical points of the polynomial\n$p_n(z) = \\prod_{j=1}^n(z-X_j)$, whose roots $X_1, \\ldots, X_n$ are\ncomplex-valued random variables. Under a regularity assumption, we show that if\nthe roots are independent and identically distributed, the Wasserstein distance\nbetween the empirical distributions of roots and critical points of $p_n$ is on\nthe order of $1/n$, up to logarithmic corrections. The proof relies on a\ncareful construction of disjoint random Jordan curves in the complex plane,\nwhich allow us to naturally pair roots and nearby critical points. In addition,\nwe establish asymptotic expansions to order $1/n^2$ for the locations of the\nnearest critical points to several fixed roots. This allows us to describe the\njoint limiting fluctuations of the critical points as $n$ tends to infinity,\nextending a recent result of Kabluchko and Seidel. Finally, we present a local\nlaw that describes the behavior of the critical points when the roots are\nneither independent nor identically distributed. \n\n"}
{"id": "1810.08316", "contents": "Title: Heteroskedastic PCA: Algorithm, Optimality, and Applications Abstract: A general framework for principal component analysis (PCA) in the presence of\nheteroskedastic noise is introduced. We propose an algorithm called HeteroPCA,\nwhich involves iteratively imputing the diagonal entries of the sample\ncovariance matrix to remove estimation bias due to heteroskedasticity. This\nprocedure is computationally efficient and provably optimal under the\ngeneralized spiked covariance model. A key technical step is a deterministic\nrobust perturbation analysis on singular subspaces, which can be of independent\ninterest. The effectiveness of the proposed algorithm is demonstrated in a\nsuite of problems in high-dimensional statistics, including singular value\ndecomposition (SVD) under heteroskedastic noise, Poisson PCA, and SVD for\nheteroskedastic and incomplete data. \n\n"}
{"id": "1810.10172", "contents": "Title: Modified Multidimensional Scaling and High Dimensional Clustering Abstract: Multidimensional scaling is an important dimension reduction tool in\nstatistics and machine learning. Yet few theoretical results characterizing its\nstatistical performance exist, not to mention any in high dimensions. By\nconsidering a unified framework that includes low, moderate and high\ndimensions, we study multidimensional scaling in the setting of clustering\nnoisy data. Our results suggest that, the classical multidimensional scaling\ncan be modified to further improve the quality of embedded samples, especially\nwhen the noise level increases. To this end, we propose {\\it modified\nmultidimensional scaling} which applies a nonlinear transformation to the\nsample eigenvalues. The nonlinear transformation depends on the dimensionality,\nsample size and moment of noise. We show that modified multidimensional scaling\nfollowed by various clustering algorithms can achieve exact recovery, i.e., all\nthe cluster labels can be recovered correctly with probability tending to one.\nNumerical simulations and two real data applications lend strong support to our\nproposed methodology. \n\n"}
{"id": "1810.10760", "contents": "Title: Quenched normal approximation for random sequences of transformations Abstract: We study random compositions of transformations having certain uniform\nfiberwise properties and prove bounds which in combination with other results\nyield a quenched central limit theorem equipped with a convergence rate, also\nin the multivariate case, assuming fiberwise centering. For the most part we\nwork with non-stationary randomness and non-invariant, non-product measures.\nIndependently, we believe our work sheds light on the mechanisms that make\nquenched central limit theorems work, by dissecting the problem into three\nseparate parts. \n\n"}
{"id": "1810.10883", "contents": "Title: Fast Exact Bayesian Inference for Sparse Signals in the Normal Sequence\n  Model Abstract: We consider exact algorithms for Bayesian inference with model selection\npriors (including spike-and-slab priors) in the sparse normal sequence model.\nBecause the best existing exact algorithm becomes numerically unstable for\nsample sizes over n=500, there has been much attention for alternative\napproaches like approximate algorithms (Gibbs sampling, variational Bayes,\netc.), shrinkage priors (e.g. the Horseshoe prior and the Spike-and-Slab LASSO)\nor empirical Bayesian methods. However, by introducing algorithmic ideas from\nonline sequential prediction, we show that exact calculations are feasible for\nmuch larger sample sizes: for general model selection priors we reach n=25000,\nand for certain spike-and-slab priors we can easily reach n=100000. We further\nprove a de Finetti-like result for finite sample sizes that characterizes\nexactly which model selection priors can be expressed as spike-and-slab priors.\nThe computational speed and numerical accuracy of the proposed methods are\ndemonstrated in experiments on simulated data, on a differential gene\nexpression data set, and to compare the effect of multiple hyper-parameter\nsettings in the beta-binomial prior. In our experimental evaluation we compute\nguaranteed bounds on the numerical accuracy of all new algorithms, which shows\nthat the proposed methods are numerically reliable whereas an alternative based\non long division is not. \n\n"}
{"id": "1810.11881", "contents": "Title: Bounded Regression with Gaussian Process Projection Abstract: Examples with bound information on the regression function and density abound\nin many real applications. We propose a novel approach for estimating such\nfunctions by incorporating the prior knowledge on the bounds. Specially, a\nGaussian process is first imposed on the regression function whose posterior\ndistribution is then projected onto the bounded space. The resulting projected\nmeasure is then used for inference. The projected sample path has closed form\nwhich facilitates efficient computations. In particular, our projection\napproach maintains a comparable computational efficiency with that of the\noriginal GP. The proposed method yield predictions that respects bound\nconstraints everywhere, while allows varying bounds across the input domain. An\nextensive simulation study is carried out which demonstrates that the\nperformance of our approach dominates that of the competitors. An application\nto real data set is also considered. \n\n"}
{"id": "1810.12014", "contents": "Title: The infinitesimal generator of the stochastic Burgers equation Abstract: We develop a martingale approach for a class of singular stochastic PDEs of\nBurgers type (including fractional and multi-component Burgers equations) by\nconstructing a domain for their infinitesimal generators. It was known that the\ndomain must have trivial intersection with the usual cylinder test functions,\nand to overcome this difficulty we import some ideas from paracontrolled\ndistributions to an infinite dimensional setting in order to construct a domain\nof controlled functions. Using the new domain, we are able to prove existence\nand uniqueness for the Kolmogorov backward equation and the martingale problem.\nWe also extend the uniqueness result for \"energy solutions\" of the stochastic\nBurgers equation of [GP18a] to a wider class of equations. \n\n"}
{"id": "1811.01520", "contents": "Title: User-Friendly Covariance Estimation for Heavy-Tailed Distributions Abstract: We offer a survey of recent results on covariance estimation for heavy-tailed\ndistributions. By unifying ideas scattered in the literature, we propose\nuser-friendly methods that facilitate practical implementation. Specifically,\nwe introduce element-wise and spectrum-wise truncation operators, as well as\ntheir $M$-estimator counterparts, to robustify the sample covariance matrix.\nDifferent from the classical notion of robustness that is characterized by the\nbreakdown property, we focus on the tail robustness which is evidenced by the\nconnection between nonasymptotic deviation and confidence level. The key\nobservation is that the estimators needs to adapt to the sample size,\ndimensionality of the data and the noise level to achieve optimal tradeoff\nbetween bias and robustness. Furthermore, to facilitate their practical use, we\npropose data-driven procedures that automatically calibrate the tuning\nparameters. We demonstrate their applications to a series of structured models\nin high dimensions, including the bandable and low-rank covariance matrices and\nsparse precision matrices. Numerical studies lend strong support to the\nproposed methods. \n\n"}
{"id": "1811.04282", "contents": "Title: An Ephemerally Self-Exciting Point Process Abstract: Across a wide variety of applications, the self-exciting Hawkes process has\nbeen used to model phenomena in which the history of events influences future\noccurrences. However, there may be many situations in which the past events\nonly influence the future as long as they remain active. For example, a person\nspreads a contagious disease only as long as they are contagious. In this\npaper, we define a novel generalization of the Hawkes process that we call the\nephemerally self-exciting process. In this new stochastic process, the\nexcitement from one arrival lasts for a randomly drawn activity duration, hence\nthe ephemerality. Our study includes exploration of the process itself as well\nas connections to well-known stochastic models such as branching processes,\nrandom walks, epidemics, preferential attachment, and Bayesian mixture models.\nFurthermore, we prove a batch scaling construction of general, marked Hawkes\nprocesses from a general ephemerally self-exciting model, and this novel limit\ntheorem both provides insight into the Hawkes process and motivates the model\ncontained herein as an attractive self-exciting process in its own right. \n\n"}
{"id": "1811.05337", "contents": "Title: Analytical Formulation of the Block-Constrained Configuration Model Abstract: We provide a novel family of generative block-models for random graphs that\nnaturally incorporates degree distributions: the block-constrained\nconfiguration model. Block-constrained configuration models build on the\ngeneralised hypergeometric ensemble of random graphs and extend the well-known\nconfiguration model by enforcing block-constraints on the edge generation\nprocess. The resulting models are analytically tractable and practical to fit\neven to large networks. These models provide a new, flexible tool for the study\nof community structure and for network science in general, where modelling\nnetworks with heterogeneous degree distributions is of central importance. \n\n"}
{"id": "1811.07025", "contents": "Title: A multilayer exponential random graph modelling approach for weighted\n  networks Abstract: A new modelling approach for the analysis of weighted networks with\nordinal/polytomous dyadic values is introduced. Specifically, it is proposed to\nmodel the weighted network connectivity structure using a hierarchical\nmultilayer exponential random graph model (ERGM) generative process where each\nnetwork layer represents a different ordinal dyadic category. The network\nlayers are assumed to be generated by an ERGM process conditional on their\nclosest lower network layers. A crucial advantage of the proposed method is the\npossibility of adopting the binary network statistics specification to describe\nboth the between-layer and across-layer network processes and thus facilitating\nthe interpretation of the parameter estimates associated to the network effects\nincluded in the model. The Bayesian approach provides a natural way to quantify\nthe uncertainty associated to the model parameters. From a computational point\nof view, an extension of the approximate exchange algorithm is proposed to\nsample from the doubly-intractable parameter posterior distribution. A\nsimulation study is carried out on artificial data and applications of the\nmethodology are illustrated on well-known datasets. Finally, a goodness-of-fit\ndiagnostic procedure for model assessment is proposed. \n\n"}
{"id": "1811.09770", "contents": "Title: Wilson loops in Ising lattice gauge theory Abstract: Wilson loop expectation in 4D $\\mathbb{Z}_2$ lattice gauge theory is computed\nto leading order in the weak coupling regime. This is the first example of a\nrigorous theoretical calculation of Wilson loop expectation in the weak\ncoupling regime of a 4D lattice gauge theory. All prior results are either\ninequalities or strong coupling expansions. \n\n"}
{"id": "1811.10110", "contents": "Title: On the cumulative Parisian ruin of multi-dimensional Brownian motion\n  models Abstract: Consider a multi-dimensional Brownian motion which models the surplus\nprocesses of multiple lines of business of an insurance company. Our main\nresult gives exact asymptotics for the cumulative Parisian ruin probability as\nthe initial capital tends to infinity. An asymptotic distribution for the\nconditional cumulative Parisian ruin time is also derived. The obtained results\non the cumulative Parisian ruin can be seen as generalizations of some of the\nresults derived in Debicki et al (2018, Stochastic Processes and Their\nApplications). As a particular interesting case, the two-dimensional Brownian\nmotion risk model is discussed in detail. \n\n"}
{"id": "1811.11733", "contents": "Title: orthoDr: Semiparametric Dimension Reduction via Orthogonality\n  Constrained Optimization Abstract: orthoDr is a package in R that solves dimension reduction problems using\northogonality constrained optimization approach. The package serves as a\nunified framework for many regression and survival analysis dimension reduction\nmodels that utilize semiparametric estimating equations. The main computational\nmachinery of orthoDr is a first-order algorithm developed by\n\\cite{wen2013feasible} for optimization within the Stiefel manifold. We\nimplement the algorithm through Rcpp and OpenMP for fast computation. In\naddition, we developed a general-purpose solver for such constrained problems\nwith user-specified objective functions, which works as a drop-in version of\noptim(). The package also serves as a platform for future methodology\ndevelopments along this line of work. \n\n"}
{"id": "1811.11930", "contents": "Title: Adaptive Sparse Estimation with Side Information Abstract: The article considers the problem of estimating a high-dimensional sparse\nparameter in the presence of side information that encodes the sparsity\nstructure. We develop a general framework that involves first using an\nauxiliary sequence to capture the side information, and then incorporating the\nauxiliary sequence in inference to reduce the estimation risk. The proposed\nmethod, which carries out adaptive SURE-thresholding using side information\n(ASUS), is shown to have robust performance and enjoy optimality properties. We\ndevelop new theories to characterize regimes in which ASUS far outperforms\ncompetitive shrinkage estimators, and establish precise conditions under which\nASUS is asymptotically optimal. Simulation studies are conducted to show that\nASUS substantially improves the performance of existing methods in many\nsettings. The methodology is applied for analysis of data from single cell\nvirology studies and microarray time course experiments. \n\n"}
{"id": "1811.12046", "contents": "Title: Problems related to conformal slit-mappings Abstract: In this note we discuss some problems related to conformal slit-mappings. On\nthe one hand, classical Loewner theory leads us to questions concerning the\nembedding of univalent functions into slit-like Loewner chains. On the other\nhand, a recent result from monotone probability theory motivates the study of\nunivalent functions from a probabilistic perspective. \n\n"}
{"id": "1811.12107", "contents": "Title: A note on the exact simulation of spherical Brownian motion Abstract: We describe an exact simulation algorithm for the increments of Brownian\nmotion on a sphere of arbitrary dimension, based on the skew-product\ndecomposition of the process with respect to the standard geodesic distance.\nThe radial process is closely related to a Wright-Fisher diffusion, increments\nof which can be simulated exactly using the recent work of Jenkins & Span\\`{o}\n(2017) [JS17]. The rapid spinning phenomenon of the skew-product decomposition\nthen yields the algorithm for the increments of the process on the sphere. \n\n"}
{"id": "1812.00258", "contents": "Title: A New Approach for Large Scale Multiple Testing with Application to FDR\n  Control for Graphically Structured Hypotheses Abstract: In many large scale multiple testing applications, the hypotheses often have\na known graphical structure, such as gene ontology in gene expression data.\nExploiting this graphical structure in multiple testing procedures can improve\npower as well as aid in interpretation. However, incorporating the structure\ninto large scale testing procedures and proving that an error rate, such as the\nfalse discovery rate (FDR), is controlled can be challenging. In this paper, we\nintroduce a new general approach for large scale multiple testing, which can\naid in developing new procedures under various settings with proven control of\ndesired error rates. This approach is particularly useful for developing FDR\ncontrolling procedures, which is simplified as the problem of developing\nper-family error rate (PFER) controlling procedures. Specifically, for testing\nhypotheses with a directed acyclic graph (DAG) structure, by using the general\napproach, under the assumption of independence, we first develop a specific\nPFER controlling procedure and based on this procedure, then develop a new FDR\ncontrolling procedure, which can preserve the desired DAG structure among the\nrejected hypotheses. Through a small simulation study and a real data analysis,\nwe illustrate nice performance of the proposed FDR controlling procedure for\nDAG-structured hypotheses. \n\n"}
{"id": "1812.01412", "contents": "Title: Necessary and Probably Sufficient Test for Finding Valid Instrumental\n  Variables Abstract: Can instrumental variables be found from data? While instrumental variable\n(IV) methods are widely used to identify causal effect, testing their validity\nfrom observed data remains a challenge. This is because validity of an IV\ndepends on two assumptions, exclusion and as-if-random, that are largely\nbelieved to be untestable from data. In this paper, we show that under certain\nconditions, testing for instrumental variables is possible. We build upon prior\nwork on necessary tests to derive a test that characterizes the odds of being a\nvalid instrument, thus yielding the name \"necessary and probably sufficient\".\nThe test works by defining the class of invalid-IV and valid-IV causal models\nas Bayesian generative models and comparing their marginal likelihood based on\nobserved data. When all variables are discrete, we also provide a method to\nefficiently compute these marginal likelihoods.\n  We evaluate the test on an extensive set of simulations for binary data,\ninspired by an open problem for IV testing proposed in past work. We find that\nthe test is most powerful when an instrument follows monotonicity---effect on\ntreatment is either non-decreasing or non-increasing---and has moderate-to-weak\nstrength; incidentally, such instruments are commonly used in observational\nstudies. Among as-if-random and exclusion, it detects exclusion violations with\nhigher power. Applying the test to IVs from two seminal studies on instrumental\nvariables and five recent studies from the American Economic Review shows that\nmany of the instruments may be flawed, at least when all variables are\ndiscretized. The proposed test opens the possibility of data-driven validation\nand search for instrumental variables. \n\n"}
{"id": "1812.01759", "contents": "Title: Optimal Stopping in General Predictable Framework Abstract: In this paper, we study the optimal stopping problem in the case where the\nreward is given by a family $(\\phi(\\tau ),\\;\\;\\tau \\in \\stopo)$ of non negative\nrandom variables indexed by predictable stopping times. We treat the problem by\nmeans of Snell's envelope techniques. We prove some properties of the value\nfunction family associated to this setting. \n\n"}
{"id": "1812.04187", "contents": "Title: Dynamic Sparse Factor Analysis Abstract: Its conceptual appeal and effectiveness has made latent factor modeling an\nindispensable tool for multivariate analysis. Despite its popularity across\nmany fields, there are outstanding methodological challenges that have hampered\npractical deployments. One major challenge is the selection of the number of\nfactors, which is exacerbated for dynamic factor models, where factors can\ndisappear, emerge, and/or reoccur over time. Existing tools that assume a fixed\nnumber of factors may provide a misguided representation of the data mechanism,\nespecially when the number of factors is crudely misspecified. Another\nchallenge is the interpretability of the factor structure, which is often\nregarded as an unattainable objective due to the lack of identifiability.\nMotivated by a topical macroeconomic application, we develop a flexible\nBayesian method for dynamic factor analysis (DFA) that can simultaneously\naccommodate a time-varying number of factors and enhance interpretability\nwithout strict identifiability constraints. To this end, we turn to dynamic\nsparsity by employing Dynamic Spike-and-Slab (DSS) priors within DFA. Scalable\nBayesian EM estimation is proposed for fast posterior mode identification via\nrotations to sparsity, enabling Bayesian data analysis at scales that would\nhave been previously time-consuming. We study a large-scale balanced panel of\nmacroeconomic variables covering multiple facets of the US economy, with a\nfocus on the Great Recession, to highlight the efficacy and usefulness of our\nproposed method. \n\n"}
{"id": "1812.05068", "contents": "Title: Asynchronous Online Testing of Multiple Hypotheses Abstract: We consider the problem of asynchronous online testing, aimed at providing\ncontrol of the false discovery rate (FDR) during a continual stream of data\ncollection and testing, where each test may be a sequential test that can start\nand stop at arbitrary times. This setting increasingly characterizes real-world\napplications in science and industry, where teams of researchers across large\norganizations may conduct tests of hypotheses in a decentralized manner. The\noverlap in time and space also tends to induce dependencies among test\nstatistics, a challenge for classical methodology, which either assumes (overly\noptimistically) independence or (overly pessimistically) arbitrary dependence\nbetween test statistics. We present a general framework that addresses both of\nthese issues via a unified computational abstraction that we refer to as\n\"conflict sets.\" We show how this framework yields algorithms with formal FDR\nguarantees under a more intermediate, local notion of dependence. We illustrate\nour algorithms in simulations by comparing to existing algorithms for online\nFDR control. \n\n"}
{"id": "1812.05456", "contents": "Title: Paracontrolled distribution approach to stochastic Volterra equations Abstract: Based on the notion of paracontrolled distributions, we provide existence and\nuniqueness results for rough Volterra equations of convolution type with\npotentially singular kernels and driven by the newly introduced class of\nconvolutional rough paths. The existence of such rough paths above a wide class\nof stochastic processes including the fractional Brownian motion is shown. As\napplications we consider various types of rough and stochastic (partial)\ndifferential equations such as rough differential equations with delay,\nstochastic Volterra equations driven by Gaussian processes and moving average\nequations driven by L\\'evy processes. \n\n"}
{"id": "1812.06406", "contents": "Title: Community Detection with Dependent Connectivity Abstract: In network analysis, within-community members are more likely to be connected\nthan between-community members, which is reflected in that the edges within a\ncommunity are intercorrelated. However, existing probabilistic models for\ncommunity detection such as the stochastic block model (SBM) are not designed\nto capture the dependence among edges. In this paper, we propose a new\ncommunity detection approach to incorporate within-community dependence of\nconnectivities through the Bahadur representation. The proposed method does not\nrequire specifying the likelihood function, which could be intractable for\ncorrelated binary connectivities. In addition, the proposed method allows for\nheterogeneity among edges between different communities. In theory, we show\nthat incorporating correlation information can lower estimation bias and\naccelerate algorithm convergence. Our simulation studies show that the proposed\nalgorithm outperforms the popular variational EM algorithm assuming conditional\nindependence among edges. We also demonstrate the application of the proposed\nmethod to agricultural product trading networks from different countries. \n\n"}
{"id": "1812.06923", "contents": "Title: A draw-down reflected spectrally negative L\\'{e}vy process Abstract: In this paper we study a spectrally negative L\\'{e}vy process that is\nreflected at its draw-down level whenever a draw-down time from the running\nsupremum arrives. Using an excursion-theoretical approach, for such a reflected\nprocess we find the Laplace transform of the upper exiting time and an\nexpression of the associated potential measure. When the reflected process is\nidentified as a risk process with capital injections, the expected total amount\nof discounted capital injections prior to the exiting time and the Laplace\ntransform of the accumulated capital injections until the exiting time are also\nobtained. The results are expressed in terms of scale functions for spectrally\nnegative L\\'{e}vy processes. \n\n"}
{"id": "1812.07365", "contents": "Title: Vertices with fixed outdegrees in large Galton-Watson trees Abstract: We are interested in nodes with fixed outdegrees in large conditioned\nGalton--Watson trees. We first study the scaling limits of processes coding the\nevolution of the number of such nodes in different explorations of the tree\n(lexicographical order and contour order) starting from the root. We give\nnecessary and sufficient conditions for the limiting processes to be centered,\nthus measuring the linearity defect of the evolution of the number of nodes\nwith fixed outdegrees. This extends results by Labarbe & Marckert in the case\nof the contour-ordered counting process of leaves in uniform plane trees. Then,\nwe extend results obtained by Janson concerning the asymptotic normality of the\nnumber of nodes with fixed outdegrees. \n\n"}
{"id": "1812.07725", "contents": "Title: Breaking Reversibility Accelerates Langevin Dynamics for Global\n  Non-Convex Optimization Abstract: Langevin dynamics (LD) has been proven to be a powerful technique for\noptimizing a non-convex objective as an efficient algorithm to find local\nminima while eventually visiting a global minimum on longer time-scales. LD is\nbased on the first-order Langevin diffusion which is reversible in time. We\nstudy two variants that are based on non-reversible Langevin diffusions: the\nunderdamped Langevin dynamics (ULD) and the Langevin dynamics with a\nnon-symmetric drift (NLD). Adopting the techniques of Tzen, Liang and Raginsky\n(2018) for LD to non-reversible diffusions, we show that for a given local\nminimum that is within an arbitrary distance from the initialization, with high\nprobability, either the ULD trajectory ends up somewhere outside a small\nneighborhood of this local minimum within a recurrence time which depends on\nthe smallest eigenvalue of the Hessian at the local minimum or they enter this\nneighborhood by the recurrence time and stay there for a potentially\nexponentially long escape time. The ULD algorithms improve upon the recurrence\ntime obtained for LD in Tzen, Liang and Raginsky (2018) with respect to the\ndependency on the smallest eigenvalue of the Hessian at the local minimum.\nSimilar result and improvement are obtained for the NLD algorithm. We also show\nthat non-reversible variants can exit the basin of attraction of a local\nminimum faster in discrete time when the objective has two local minima\nseparated by a saddle point and quantify the amount of improvement. Our\nanalysis suggests that non-reversible Langevin algorithms are more efficient to\nlocate a local minimum as well as exploring the state space. Our analysis is\nbased on the quadratic approximation of the objective around a local minimum.\nAs a by-product of our analysis, we obtain optimal mixing rates for quadratic\nobjectives in the 2-Wasserstein distance for two non-reversible Langevin\nalgorithms we consider. \n\n"}
{"id": "1812.07728", "contents": "Title: Multivariate one-sided testing in matched observational studies as an\n  adversarial game Abstract: We present a multivariate one-sided sensitivity analysis for matched\nobservational studies, appropriate when the researcher has specified that a\ngiven causal mechanism should manifest itself in effects on multiple outcome\nvariables in a known direction. The test statistic can be thought of as the\nsolution to an adversarial game, where the researcher determines the best\nlinear combination of test statistics to combat nature's presentation of the\nworst-case pattern of hidden bias. The corresponding optimization problem is\nconvex, and can be solved efficiently even for reasonably sized observational\nstudies. Asymptotically the test statistic converges to a chi-bar-squared\ndistribution under the null, a common distribution in order restricted\nstatistical inference. The test attains the largest possible design sensitivity\nover a class of coherent test statistics, and facilitates one-sided sensitivity\nanalyses for individual outcome variables while maintaining familywise error\ncontrol through is incorporation into closed testing procedures. \n\n"}
{"id": "1812.08927", "contents": "Title: Global and Local Two-Sample Tests via Regression Abstract: Two-sample testing is a fundamental problem in statistics. Despite its long\nhistory, there has been renewed interest in this problem with the advent of\nhigh-dimensional and complex data. Specifically, in the machine learning\nliterature, there have been recent methodological developments such as\nclassification accuracy tests. The goal of this work is to present a regression\napproach to comparing multivariate distributions of complex data. Depending on\nthe chosen regression model, our framework can efficiently handle different\ntypes of variables and various structures in the data, with competitive power\nunder many practical scenarios. Whereas previous work has been largely limited\nto global tests which conceal much of the local information, our approach\nnaturally leads to a local two-sample testing framework in which we identify\nlocal differences between multivariate distributions with statistical\nconfidence. We demonstrate the efficacy of our approach both theoretically and\nempirically, under some well-known parametric and nonparametric regression\nmethods. Our proposed methods are applied to simulated data as well as a\nchallenging astronomy data set to assess their practical usefulness. \n\n"}
{"id": "1812.10344", "contents": "Title: Stein-type covariance identities: Klaassen, Papathanasiou and\n  Olkin-Shepp type bounds for arbitrary target distributions Abstract: In this paper, we present a minimal formalism for Stein operators which leads\nto different probabilistic representations of solutions to Stein equations.\nThese in turn provide a wide family of Stein-Covariance identities which we put\nto use for revisiting the very classical topic of bounding the variance of\nfunctionals of random variables. Applying the Cauchy-Schwarz inequality yields\nfirst order upper and lower Klaassen-type variance bounds. A probabilistic\nrepresentation of Lagrange's identity (i.e. Cauchy-Schwarz with remainder)\nleads to Papathanasiou-type variance expansions of arbitrary order. A matrix\nCauchy-Schwarz inequality leads to Olkin-Shepp type covariance bounds. All\nresults hold for univariate target distribution under very weak assumptions (in\nparticular they hold for continuous and discrete distributions alike). Many\nconcrete illustrations are provided. \n\n"}
{"id": "1812.11433", "contents": "Title: On the Construction of Knockoffs in Case-Control Studies Abstract: Consider a case-control study in which we have a random sample, constructed\nin such a way that the proportion of cases in our sample is different from that\nin the general population---for instance, the sample is constructed to achieve\na fixed ratio of cases to controls. Imagine that we wish to determine which of\nthe potentially many covariates under study truly influence the response by\napplying the new model-X knockoffs approach. This paper demonstrates that it\nsuffices to design knockoff variables using data that may have a different\nratio of cases to controls. For example, the knockoff variables can be\nconstructed using the distribution of the original variables under any of the\nfollowing scenarios: (1) a population of controls only; (2) a population of\ncases only; (3) a population of cases and controls mixed in an arbitrary\nproportion (irrespective of the fraction of cases in the sample at hand). The\nconsequence is that knockoff variables may be constructed using unlabeled data,\nwhich is often available more easily than labeled data, while maintaining\nType-I error guarantees. \n\n"}
{"id": "1901.00663", "contents": "Title: Efficient augmentation and relaxation learning for individualized\n  treatment rules using observational data Abstract: Individualized treatment rules aim to identify if, when, which, and to whom\ntreatment should be applied. A globally aging population, rising healthcare\ncosts, and increased access to patient-level data have created an urgent need\nfor high-quality estimators of individualized treatment rules that can be\napplied to observational data. A recent and promising line of research for\nestimating individualized treatment rules recasts the problem of estimating an\noptimal treatment rule as a weighted classification problem. We consider a\nclass of estimators for optimal treatment rules that are analogous to convex\nlarge-margin classifiers. The proposed class applies to observational data and\nis doubly-robust in the sense that correct specification of either a propensity\nor outcome model leads to consistent estimation of the optimal individualized\ntreatment rule. Using techniques from semiparametric efficiency theory, we\nderive rates of convergence for the proposed estimators and use these rates to\ncharacterize the bias-variance trade-off for estimating individualized\ntreatment rules with classification-based methods. Simulation experiments\ninformed by these results demonstrate that it is possible to construct new\nestimators within the proposed framework that significantly outperform existing\nones. We illustrate the proposed methods using data from a labor training\nprogram and a study of inflammatory bowel syndrome. \n\n"}
{"id": "1901.00882", "contents": "Title: Local solution to the multi-layer KPZ equation Abstract: In this article we prove local well-posedness of the system of equations\n$\\partial_t h_{i}= \\sum_{j=1}^{i}\\partial_x^2 h_{i}+ (\\partial_x h_{i})^2 + \\xi\n$ on the circle where $1\\leq i\\leq N$ and $\\xi$ is a space-time white noise. We\nattempt to generalize the renormalization procedure which gives the Hopf-Cole\nsolution for the single layer equation and our $h_1$ (solution to the first\nlayer) coincides with this solution. However, we observe that cancellation of\nlogarithmic divergences that occurs at the first layer does not hold at higher\nlayers and develop explicit combinatorial formulae for them. \n\n"}
{"id": "1901.00886", "contents": "Title: Nonparametric graphical model for counts Abstract: Although multivariate count data are routinely collected in many application\nareas, there is surprisingly little work developing flexible models for\ncharacterizing their dependence structure. This is particularly true when\ninterest focuses on inferring the conditional independence graph. In this\narticle, we propose a new class of pairwise Markov random field-type models for\nthe joint distribution of a multivariate count vector. By employing a novel\ntype of transformation, we avoid restricting to non-negative dependence\nstructures or inducing other restrictions through truncations. Taking a\nBayesian approach to inference, we choose a Dirichlet process prior for the\ndistribution of a random effect to induce great flexibility in the\nspecification. An efficient Markov chain Monte Carlo (MCMC) algorithm is\ndeveloped for posterior computation. We prove various theoretical properties,\nincluding posterior consistency, and show that our COunt Nonparametric\nGraphical Analysis (CONGA) approach has good performance relative to\ncompetitors in simulation studies. The methods are motivated by an application\nto neuron spike count data in mice. \n\n"}
{"id": "1901.05701", "contents": "Title: Cramer-Lundberg model for some classes of extremal Markov sequences Abstract: The classical Cramer-Lundberg model was the first attempt to describe the\nfinancial condition of the insurance company. The incomes were approximated by\na steady stream of money, insurance payments were not limited and could take\nany value from zero to infinity. The society did not invest any part of its\nmoney, do not have any employees, shareholders or enterprise maintenance costs.\nThere exists many modifications of the Cramer-Lundberg model which cover at\nleast some of the problems described here, but usually they require insight\ninto the internal financial policy of the insurance company. We propose here\nanother modification based on Markov processes defined by generalized\nconvolutions. Thanks to the generalized convolutions we can approximate\nstochastically the internal financial policy of the company based on publicly\navailable data. In this paper we focus on computing the ruin probability for an\ninfinite time horizon for the Markov processes Cramer-Lundberg model where the\ntransition probabilities are defined by generalized convolutions, in particular\n$\\alpha$-convolution, maximal convolution and the Kendall convolution. \n\n"}
{"id": "1901.08390", "contents": "Title: Functional central limit theorems for multivariate Bessel processes in\n  the freezing regime Abstract: Multivariate Bessel processes $(X_{t,k})_{t\\ge0}$ describe interacting\nparticle systems of Calogero-Moser-Sutherland type and are related with\n$\\beta$-Hermite and $\\beta$-Laguerre ensembles. They depend on a root system\nand a multiplicity $k$ which corresponds to the parameter $\\beta$ in random\nmatrix theory. In the recent years, several limit theorems were derived for\n$k\\to\\infty$ with fixed $t>0$ and fixed starting point. Only recently, Andraus\nand Voit used the stochastic differential equations of $(X_{t,k})_{t\\ge0}$ to\nderive limit theorems for $k\\to\\infty$ with starting points of the form $\\sqrt\nk\\cdot x$ with $x$ in the interior of the corresponding Weyl chambers. Here we\nprovide associated functional central limit theorems which are locally uniform\nin $t$. The Gaussian limiting processes admit explicit representations in terms\nof matrix exponentials and the solutions of the associated deterministic\ndynamical systems. \n\n"}
{"id": "1901.09919", "contents": "Title: Inferring Heterogeneous Causal Effects in Presence of Spatial\n  Confounding Abstract: We address the problem of inferring the causal effect of an exposure on an\noutcome across space, using observational data. The data is possibly subject to\nunmeasured confounding variables which, in a standard approach, must be\nadjusted for by estimating a nuisance function. Here we develop a method that\neliminates the nuisance function, while mitigating the resulting\nerrors-in-variables. The result is a robust and accurate inference method for\nspatially varying heterogeneous causal effects. The properties of the method\nare demonstrated on synthetic as well as real data from Germany and the US. \n\n"}
{"id": "cond-mat/0101200", "contents": "Title: Current fluctuations for the totally asymmetric simple exclusion process Abstract: The time-integrated current of the TASEP has non-Gaussian fluctuations of\norder $t^{1/3}$. The recently discovered connection to random matrices and the\nPainlev\\'e II Riemann-Hilbert problem provides a technique through which we\nobtain the probability distribution of the current fluctuations, in particular\ntheir dependence on initial conditions, and the stationary two-point function.\nSome open problems are explained. \n\n"}
{"id": "cond-mat/0506195", "contents": "Title: Precise Asymptotics for a Random Walker's Maximum Abstract: We consider a discrete time random walk in one dimension. At each time step\nthe walker jumps by a random distance, independent from step to step, drawn\nfrom an arbitrary symmetric density function. We show that the expected\npositive maximum E[M_n] of the walk up to n steps behaves asymptotically for\nlarge n as, E[M_n]/\\sigma=\\sqrt{2n/\\pi}+ \\gamma +O(n^{-1/2}), where \\sigma^2 is\nthe variance of the step lengths. While the leading \\sqrt{n} behavior is\nuniversal and easy to derive, the leading correction term turns out to be a\nnontrivial constant \\gamma. For the special case of uniform distribution over\n[-1,1], Coffmann et. al. recently computed \\gamma=-0.516068...by exactly\nenumerating a lengthy double series. Here we present a closed exact formula for\n\\gamma valid for arbitrary symmetric distributions. We also demonstrate how\n\\gamma appears in the thermodynamic limit as the leading behavior of the\ndifference variable E[M_n]-E[|x_n|] where x_n is the position of the walker\nafter n steps. An application of these results to the equilibrium\nthermodynamics of a Rouse polymer chain is pointed out. We also generalize our\nresults to L\\'evy walks. \n\n"}
{"id": "hep-th/9912031", "contents": "Title: A non-Fock fermion toy model Abstract: Recent progress in mathematical theory of random processes provides us with\nnon-Fock product systems (continuous tensor products of Hilbert spaces) used\nhere for constructing a toy model for fermions. Some state vectors describe\ninfinitely many particles in a finite region; the particles accumulate to a\npoint. Electric charge can be assigned to the particles, the total charge being\nzero. Time dynamics is not considered yet, only kinematics (a single time\ninstant). \n\n"}
{"id": "math-ph/0010012", "contents": "Title: From Random Polynomials to Symplectic Geometry Abstract: We review some recent results on random polynomials and their generalizations\nin complex and symplectic geometry. The main theme is the universality of\nstatistics of zeros and critical points of (generalized) polynomials of degree\n$N$ on length scales of order $\\frac{D}{\\sqrt{N}}$ (complex case), resp.\n$\\frac{D}{N}$ (real case). \n\n"}
{"id": "math-ph/0112006", "contents": "Title: Fermion and boson random point processes as particle distributions of\n  infinite free Fermi and Bose gases of finite density Abstract: The aim of this paper is to show that fermion and boson random point\nprocesses naturally appear from representations of CAR and CCR which correspond\nto gauge invariant generalized free states (also called quasi-free states). We\nconsider particle density operators $\\rho(x)$, $x\\in\\R^d$, in the\nrepresentation of CAR describing an infinite free Fermi gas of finite density\nat both zero and finite temperature, and in the representation of CCR\ndescribing an infinite free Bose gas at finite temperature. We prove that the\nspectral measure of the smeared operators $\\rho(f)=\\int dx f(x)\\rho(x)$ (i.e.,\nthe measure $\\mu$ which allows to realize the $\\rho(f)$'s as multiplication\noperators by $\\la\\cdot,f\\ra$ in $L^2(d\\mu)$) is a well-known fermion, resp.\nboson measure on the space of all locally finite configurations in $\\R^d$. \n\n"}
{"id": "math-ph/0209023", "contents": "Title: Crossing Probabilities and Modular Forms Abstract: We examine crossing probabilities and free energies for conformally invariant\ncritical 2-D systems in rectangular geometries, derived via conformal field\ntheory and Stochastic L\\\"owner Evolution methods. These quantities are shown to\nexhibit interesting modular behavior, although the physical meaning of modular\ntransformations in this context is not clear. We show that in many cases these\nfunctions are completely characterized by very simple transformation\nproperties. In particular, Cardy's function for the percolation crossing\nprobability (including the conformal dimension 1/3), follows from a simple\nmodular argument. A new type of \"higher-order modular form\" arises and its\nproperties are discussed briefly. \n\n"}
{"id": "math-ph/0403007", "contents": "Title: Janossy densities, multimatrix spacing distributions and Fredholm\n  resolvents Abstract: A simple proof is given for a generalized form of a theorem of Soshnikov. The\nlatter states that the Janossy densities for multilevel determinantal ensembles\nsupported on measurable subspaces of a set of measure spaces are constructed by\ndualization of bases on dual pairs of N-dimensional function spaces with\nrespect to a pairing given by integration on the complements of the given\nmeasurable subspaces. The generalization extends this to dualization with\nrespect to measures modified by arbitrary sets of weight functions. \n\n"}
{"id": "math-ph/0509071", "contents": "Title: A Random Point Field related to Bose-Einstein Condensation Abstract: The random point field which describes the position distribution of the\nsystem of ideal boson gas in a state of Bose-Einstein condensation is obtained\nthrough the thermodynamic limit. The resulting point field is given by\nconvolution of two independent point fields: the so called boson process whose\ngenerating functional is represented by inverse of the Fredholm determinant for\nan operator related to the heat operator and the point field whose generating\nfunctional is represented by a resolvent of the operator. The construction of\nthe latter point field in an abstract formulation is also given. \n\n"}
{"id": "math-ph/0610018", "contents": "Title: A Complete Renormalization Group Trajectory Between Two Fixed Points Abstract: We give a rigorous nonperturbative construction of a massless discrete\ntrajectory for Wilson's exact renormalization group. The model is a three\ndimensional Euclidean field theory with a modified free propagator. The\ntrajectory realizes the mean field to critical crossover from the ultraviolet\nGaussian fixed point to an analog recently constructed by Brydges, Mitter and\nScoppola of the Wilson-Fisher nontrivial fixed point. \n\n"}
{"id": "math-ph/9904020", "contents": "Title: Universality and scaling of correlations between zeros on complex\n  manifolds Abstract: We study the limit as $N\\to\\infty$ of the correlations between simultaneous\nzeros of random sections of the powers $L^N$ of a positive holomorphic line\nbundle $L$ over a compact complex manifold $M$, when distances are rescaled so\nthat the average density of zeros is independent of $N$. We show that the limit\ncorrelation is independent of the line bundle and depends only on the dimension\nof $M$ and the codimension of the zero sets. We also provide some explicit\nformulas for pair correlations. In particular, we provide an alternate\nderivation of Hannay's limit pair correlation function for SU(2) polynomials,\nand we show that this correlation function holds for all compact Riemann\nsurfaces. \n\n"}
{"id": "math/0003195", "contents": "Title: Random matrix theory over finite fields: a survey Abstract: First we survey generating function methods for obtaining useful probability\nestimates about random matrices in the finite classical groups. Then we\ndescribe a probabilistic picture of conjugacy classes which is coherent and\nbeautiful. Connections are made with symmetric function theory, Markov chains,\npotential theory, Rogers-Ramanujan type identities, quivers, and various\nmeasures on partitions. \n\n"}
{"id": "math/0008079", "contents": "Title: Images of eigenvalue distributions under power maps Abstract: In [earlier work by the author], it was shown that if U is a random n x n\nunitary matrix, then for any p>=n, the eigenvalues of U^p are i.i.d. uniform;\nsimilar results were also shown for general compact Lie groups. We study what\nhappens when p<n instead. For the classical groups, we find that we can\ndescribe the eigenvalue distribution of U^p in terms of the eigenvalue\ndistributions of smaller classical groups; the earlier result is then a special\ncase. The proofs rely on the fact that a certain subgroup of the Weyl group is\nitself a Weyl group. We generalize this fact, and use it to study the power-map\nproblem for general compact Lie groups. \n\n"}
{"id": "math/0107229", "contents": "Title: On the largest eigenvalue of a sparse random subgraph of the hypercube Abstract: We consider a sparse random subraph of the $n$-cube where each edge appears\nindependently with small probability $p(n) =O(n^{-1+o(1)})$. In the most\ninteresting regime when $p(n)$ is not exponentially small we prove that the\nlargest eigenvalue of the graph is asymtotically equal to the square root of\nthe maximum degree. \n\n"}
{"id": "math/0109194", "contents": "Title: Harmonic analysis on the infinite-dimensional unitary group and\n  determinantal point processes Abstract: The infinite-dimensional unitary group U(infinity) is the inductive limit of\ngrowing compact unitary groups U(N). In this paper we solve a problem of\nharmonic analysis on U(infinity) stated in the previous paper math/0109193. The\nproblem consists in computing spectral decomposition for a remarkable\n4-parameter family of characters of U(infinity). These characters generate\nrepresentations which should be viewed as analogs of nonexisting regular\nrepresentation of U(infinity).\n  The spectral decomposition of a character of U(infinity) is described by the\nspectral measure which lives on an infinite-dimensional space Omega of\nindecomposable characters. The key idea which allows us to solve the problem is\nto embed Omega into the space of point configurations on the real line without\n2 points. This turns the spectral measure into a stochastic point process on\nthe real line. The main result of the paper is a complete description of the\nprocesses corresponding to our concrete family of characters. We prove that\neach of the processes is a determinantal point process. That is, its\ncorrelation functions have determinantal form with a certain kernel. Our\nkernels have a special `integrable' form and are expressed through the Gauss\nhypergeometric function.\n  In simpler situations of harmonic analysis on infinite symmetric group and\nharmonic analysis of unitarily invariant measures on infinite hermitian\nmatrices similar results were obtained in our papers math/9810015,\nmath/9904010, math-ph/0010015. \n\n"}
{"id": "math/0204215", "contents": "Title: Explicit Construction of the Brownian Self-Transport Operator Abstract: Applying the technique of characteristic functions developped for\none-dimensional regular surfaces (curves) with compact support, we obtain the\ndistribution of hitting probabilities for a wide class of finite membranes on\nsquare lattice. Then we generalize it to multi-dimensional finite membranes on\nhypercubic lattice. Basing on these distributions, we explicitly construct the\nBrownian self-transport operator which governs the Laplacian transfer. In order\nto verify the accuracy of the distribution of hitting probabilities, numerical\nanalysis is carried out for some particular membranes. \n\n"}
{"id": "math/0210469", "contents": "Title: Mixing Time of the Rudvalis Shuffle Abstract: We extend a technique for lower-bounding the mixing time of card-shuffling\nMarkov chains, and use it to bound the mixing time of the Rudvalis Markov\nchain, as well as two variants considered by Diaconis and Saloff-Coste. We show\nthat in each case Theta(n^3 log n) shuffles are required for the permutation to\nrandomize, which matches (up to constants) previously known upper bounds. In\ncontrast, for the two variants, the mixing time of an individual card is only\nTheta(n^2) shuffles. \n\n"}
{"id": "math/0212008", "contents": "Title: SLE and triangles Abstract: By analogy with Carleson's observation on Cardy's formula describing crossing\nprobabilities for the scaling limit of critical percolation, we exhibit\n``privileged geometries'' for Stochastic Loewner Evolutions with various\nparameters, for which certain hitting distributions are uniformly distributed.\nConsequences for limiting probabilities of events concerning various critical\nplane discrete models are then examined. \n\n"}
{"id": "math/0305262", "contents": "Title: Amenability via random walks Abstract: We answer an open question of Grigorchuk and Zuk about amenability using\nrandom walks. Our results separate the class of amenable groups from the\nclosure of subexponentially growing groups under the operations of group\nextension and direct limits; these classes are separated even within the realm\nof finitely presented groups. \n\n"}
{"id": "math/0306355", "contents": "Title: A Phase Transition for the Metric Distortion of Percolation on the\n  Hypercube Abstract: Let H_n be the hypercube {0,1}^n, and let H_{n,p} denote the same graph with\nBernoulli bond percolation with parameter p=n^-\\alpha. It is shown that at\n\\alpha=1/2 there is a phase transition for the metric distortion between H_n\nand H_{n,p}. For \\alpha<1/2, asymptotically there is a map from H_n to H_{n,p}\nwith constant distortion (depending only on \\alpha). For \\alpha>1/2 the\ndistortion tends to infinity as a power of n. We indicate the similarity to the\nexistence of a non-uniqueness phase in the context of infinite nonamenable\ngraphs. \n\n"}
{"id": "math/0309222", "contents": "Title: Fast simulation of new coins from old Abstract: Let S\\subset (0,1). Given a known function f:S\\to (0,1), we consider the\nproblem of using independent tosses of a coin with probability of heads p\n(where p\\in S is unknown) to simulate a coin with probability of heads f(p). We\nprove that if S is a closed interval and f is real analytic on S, then f has a\nfast simulation on S (the number of p-coin tosses needed has exponential\ntails). Conversely, if a function f has a fast simulation on an open set, then\nit is real analytic on that set. \n\n"}
{"id": "math/0312256", "contents": "Title: Perturbation of singular equilibria of hyperbolic two-component systems:\n  a universal hydrodynamic limit Abstract: We consider one-dimensional, locally finite interacting particle systems with\ntwo conservation laws which under Eulerian hydrodynamic limit lead to\ntwo-by-two systems of conservation laws:\n  \\pt \\rho +\\px \\Psi(\\rho, u)=0\n  \\pt u+\\px \\Phi(\\rho,u)=0,\n  with $(\\rho,u)\\in{\\cal D}\\subset\\R^2$, where ${\\cal D}$ is a convex compact\npolygon in $\\R^2$. The system is typically strictly hyperbolic in the interior\nof ${\\cal D}$ with possible non-hyperbolic degeneracies on the boundary\n$\\partial {\\cal D}$. We consider the case of isolated singular (i.e. non\nhyperbolic) point on the interior of one of the edges of ${\\cal D}$, call it\n$(\\rho_0,u_0)=(0,0)$ and assume ${\\cal D}\\subset\\{\\rho\\ge0\\}$. This can be\nachieved by a linear transformation of the conserved quantities. We investigate\nthe propagation of small nonequilibrium perturbations of the steady state of\nthe microscopic interacting particle system, corresponding to the densities\n$(\\rho_0,u_0)$ of the conserved quantities. We prove that for a very rich class\nof systems, under proper hydrodynamic limit the propagation of these small\nperturbations are \\emph{universally} driven by the two-by-two system\n  \\pt\\rho + \\px\\big(\\rho u\\big)=0\n  \\pt u + \\px\\big(\\rho + \\gamma u^2\\big) =0\n  where the parameter $\\gamma:=\\frac12 \\Phi_{uu}(\\rho_0,u_0)$ (with a proper\nchoice of space and time scale) is the only trace of the microscopic structure.\nThe proof is valid for the cases with $\\gamma>1$.\n  [truncated] \n\n"}
{"id": "math/0411487", "contents": "Title: The largest eigenvalue of small rank perturbations of Hermitian random\n  matrices Abstract: We compute the limiting eigenvalue statistics at the edge of the spectrum of\nlarge Hermitian random matrices perturbed by the addition of small rank\ndeterministic matrices. To be more precise, we consider random Hermitian\nmatrices with independent Gaussian entries $M_{ij}, i\\leq j$ with various\nexpectations. We prove that the largest eigenvalue of such random matrices\nexhibits, in the large $N$ limit, various limiting distributions depending on\nboth the eigenvalues of the matrix $(\\mathbb{E}M_{ij})_{i,j=1}^N$ and its rank. \n\n"}
{"id": "math/0412510", "contents": "Title: Sharp thresholds and percolation in the plane Abstract: Recently, the authors showed that the critical probability for random Voronoi\npercolation in the plane is 1/2. A by-product of the method was a short proof\nof the Harris-Kesten Theorem concerning bond percolation in the planar square\nlattice. The aim of this paper is to show that the same techniques can be\napplied to many other planar percolation models, both to obtain short proofs of\nknown results, and to prove new ones. \n\n"}
{"id": "math/0503251", "contents": "Title: Spherical Asymptotics for the Rotor-Router Model in Z^d Abstract: The rotor-router model is a deterministic analogue of random walk invented by\nJim Propp. It can be used to define a deterministic aggregation model analogous\nto internal diffusion limited aggregation. We prove an isoperimetric inequality\nfor the exit time of simple random walk from a finite region in Z^d, and use\nthis to prove that the shape of the rotor-router aggregation model in Z^d,\nsuitably rescaled, converges to a Euclidean ball in R^d. \n\n"}
{"id": "math/0506522", "contents": "Title: Inference Under Convex Cone Alternatives for Correlated Data Abstract: In this research, inferential theory for hypothesis testing under general\nconvex cone alternatives for correlated data is developed. While there exists\nextensive theory for hypothesis testing under smooth cone alternatives with\nindependent observations, extension to correlated data under general convex\ncone alternatives remains an open problem. This long-pending problem is\naddressed by (1) establishing that a \"generalized quasi-score\" statistic is\nasymptotically equivalent to the squared length of the projection of the\nstandard Gaussian vector onto the convex cone and (2) showing that the\nasymptotic null distribution of the test statistic is a weighted chi-squared\ndistribution, where the weights are \"mixed volumes\" of the convex cone and its\npolar cone. Explicit expressions for these weights are derived using the\nvolume-of-tube formula around a convex manifold in the unit sphere.\nFurthermore, an asymptotic lower bound is constructed for the power of the\ngeneralized quasi-score test under a sequence of local alternatives in the\nconvex cone. Applications to testing under order restricted alternatives for\ncorrelated data are illustrated. \n\n"}
{"id": "math/0510656", "contents": "Title: Lemme de coherence et th\\'{e}or\\`{e}me de Noether stochastique Abstract: The stochastic embedding procedure associates a stochastic Euler-Lagrange\nequation (SEL) to the standard Euler-Lagrange equation (EL). Can we derive\n(SEL) from a generalized least action principle? To address this question, we\ndevelop a stochastic calculus of variation initiated by Yasue. We give a\nstochastic analog F of the lagrangian action functional. We introduce a notion\nof stationarity according to which the solutions of (SEL) are the stationary\npoints of F. This notion of stationarity brings coherence to stochastic\ncalculus of variation with respect to stochastic embedding. Finally, we prove a\nstochastic Noether theorem which introduces an original notion of stochastic\nfirst integral. \n\n"}
{"id": "math/0511533", "contents": "Title: On the Limiting Distribution for the Longest Alternating Sequence in a\n  Random Permutation Abstract: Recently Richard Stanley initiated a study of the distribution of the length\nas(w) of the longest alternating subsequence in a random permutation w from the\nsymmetric group $S_n$. Among other things he found an explicit formula for the\ngenerating function (on n and k) for the probability that as(w) is at most k\nand conjectured that the distribution, suitably centered and normalized, tended\nto a Gaussian with variance 8/45. In this note we present a proof of the\nconjecture based on the generating function. \n\n"}
{"id": "math/0512201", "contents": "Title: The critical random graph, with martingales Abstract: We give a short proof that the largest component of the random graph $G(n,\n1/n)$ is of size approximately $n^{2/3}$. The proof gives explicit bounds for\nthe probability that the ratio is very large or very small. \n\n"}
{"id": "math/0512364", "contents": "Title: A quantitative investigation into the accumulation of rounding errors in\n  the numerical solution of ODEs Abstract: We examine numerical rounding errors of some deterministic solvers for\nsystems of ordinary differential equations (ODEs). We show that the\naccumulation of rounding errors results in a solution that is inherently random\nand we obtain the theoretical distribution of the trajectory as a function of\ntime, the step size and the numerical precision of the computer. We consider,\nin particular, systems which amplify the effect of the rounding errors so that\nover long time periods the solutions exhibit divergent behaviour. By performing\nmultiple repetitions with different values of the time step size, we observe\nnumerically the random distributions predicted theoretically. We mainly focus\non the explicit Euler and RK4 methods but also briefly consider more complex\nalgorithms such as the implicit solvers VODE and RADAU5. \n\n"}
{"id": "math/0512414", "contents": "Title: Occupation time fluctuations of Poisson and equilibrium finite variance\n  branching systems Abstract: Functional limit theorems are presented for the rescaled occupation time\nfluctuations process of a critical finite variance branching particle system in\n$R^d$ with symmetric a-stable motion starting off from either a standard\nPoisson random field or from the equilibrium distribution for intermediate\ndimensions a<d<2a. The limit processes are determined sub-fractional and\nfractional Brownian motion respectively. \n\n"}
{"id": "math/0603541", "contents": "Title: Probabilistic approach for granular media equations in the non uniformly\n  convex case Abstract: We use here a particle system to prove a convergence result as well as a\ndeviation inequality for solutions of granular media equation when the\nconfinement potential and the interaction potential are no more uniformly\nconvex. Proof is straightforward, simplifying deeply proofs of\nCarrillo-McCann-Villani \\cite{CMV,CMV2} and completing results of Malrieu\n\\cite{malrieu03} in the uniformly convex case. It relies on an uniform\npropagation of chaos property and a direct control in Wasserstein distance of\nsolutions starting with different initial measures. The deviation inequality is\nobtained via a $T\\_1$ transportation cost inequality replacing the logarithmic\nSobolev inequality which is no more clearly dimension free. \n\n"}
{"id": "math/0604380", "contents": "Title: Numerical Homogenization of the Acoustic Wave Equations with a Continuum\n  of Scales Abstract: In this paper, we consider numerical homogenization of acoustic wave\nequations with heterogeneous coefficients, namely, when the bulk modulus and\nthe density of the medium are only bounded. We show that under a Cordes type\ncondition the second order derivatives of the solution with respect to harmonic\ncoordinates are $L^2$ (instead $H^{-1}$ with respect to Euclidean coordinates)\nand the solution itself is in $L^{\\infty}(0,T,H^2(\\Omega))$ (instead of\n$L^{\\infty}(0,T,H^1(\\Omega))$ with respect to Euclidean coordinates). Then, we\npropose an implicit time stepping method to solve the resulted linear system on\ncoarse spatial scales, and present error estimates of the method. It follows\nthat by pre-computing the associated harmonic coordinates, it is possible to\nnumerically homogenize the wave equation without assumptions of scale\nseparation or ergodicity. \n\n"}
{"id": "math/0606183", "contents": "Title: Generalizations of Ho-Lee's binomial interest rate model I: from one- to\n  multi-factor Abstract: In this paper a multi-factor generalization of Ho-Lee model is proposed. In\nsharp contrast to the classical Ho-Lee, this generalization allows for those\nmovements other than parallel shifts, while it still is described by a\nrecombining tree, and is stationary to be compatible with principal component\nanalysis. Based on the model, generalizations of duration-based hedging are\nproposed. A continuous-time limit of the model is also discussed. \n\n"}
{"id": "math/0606338", "contents": "Title: Globally centered discrete snakes Abstract: We consider branching random walks built on Galton-Watson trees with\noffspring distribution having a bounded support, conditioned to have $n$ nodes,\nand their rescaled convergences to the Brownian snake. We exhibit a notion of\n\"globally centered discrete snake'' that extends the usual settings in which\nthe displacements are supposed centered. We show that under some additional\nmoment conditions, when $n$ goes to $+\\infty$, \"globally centered discrete\nsnakes'' converge to the Brownian snake. The proof relies on a precise study of\nthe \"lineage'' of the nodes in a Galton-Watson tree conditioned by the size,\nand their links with a multinomial process. Some consequences concerning\nGalton-Watson trees conditioned by the size are also derived. \n\n"}
{"id": "math/0606520", "contents": "Title: Multivariate risks and depth-trimmed regions Abstract: We describe a general framework for measuring risks, where the risk measure\ntakes values in an abstract cone. It is shown that this approach naturally\nincludes the classical risk measures and set-valued risk measures and yields a\nnatural definition of vector-valued risk measures. Several main constructions\nof risk measures are described in this abstract axiomatic framework.\n  It is shown that the concept of depth-trimmed (or central) regions from the\nmultivariate statistics is closely related to the definition of risk measures.\nIn particular, the halfspace trimming corresponds to the Value-at-Risk, while\nthe zonoid trimming yields the expected shortfall. In the abstract framework,\nit is shown how to establish a both-ways correspondence between risk measures\nand depth-trimmed regions. It is also demonstrated how the lattice structure of\nthe space of risk values influences this relationship. \n\n"}
{"id": "math/0609469", "contents": "Title: Escape of mass in zero-range processes with random rates Abstract: We consider zero-range processes in ${\\mathbb{Z}}^d$ with site dependent jump\nrates. The rate for a particle jump from site $x$ to $y$ in ${\\mathbb{Z}}^d$ is\ngiven by $\\lambda_xg(k)p(y-x)$, where $p(\\cdot)$ is a probability in\n${\\mathbb{Z}}^d$, $g(k)$ is a bounded nondecreasing function of the number $k$\nof particles in $x$ and $\\lambda =\\{\\lambda_x\\}$ is a collection of i.i.d.\nrandom variables with values in $(c,1]$, for some $c>0$. For almost every\nrealization of the environment $\\lambda$ the zero-range process has product\ninvariant measures $\\{{\\nu_{\\lambda, v}}:0\\le v\\le c\\}$ parametrized by $v$,\nthe average total jump rate from any given site. The density of a measure,\ndefined by the asymptotic average number of particles per site, is an\nincreasing function of $v$. There exists a product invariant measure ${\\nu\n_{\\lambda, c}}$, with maximal density. Let $\\mu$ be a probability measure\nconcentrating mass on configurations whose number of particles at site $x$\ngrows less than exponentially with $\\|x\\|$. Denoting by $S_{\\lambda}(t)$ the\nsemigroup of the process, we prove that all weak limits of $\\{\\mu\nS_{\\lambda}(t),t\\ge 0\\}$ as $t\\to \\infty$ are dominated, in the natural partial\norder, by ${\\nu_{\\lambda, c}}$. In particular, if $\\mu$ dominates ${\\nu\n_{\\lambda, c}}$, then $\\mu S_{\\lambda}(t)$ converges to ${\\nu_{\\lambda, c}}$.\nThe result is particularly striking when the maximal density is finite and the\ninitial measure has a density above the maximal. \n\n"}
{"id": "math/0610682", "contents": "Title: Critical exponents of planar gradient percolation Abstract: We study gradient percolation for site percolation on the triangular lattice.\nThis is a percolation model where the percolation probability depends linearly\non the location of the site. We prove the results predicted by physicists for\nthis model. More precisely, we describe the fluctuations of the interfaces\naround their (straight) scaling limits, and the expected and typical lengths of\nthese interfaces. These results build on the recent results for critical\npercolation on this lattice by Smirnov, Lawler, Schramm and Werner, and on the\nscaling ideas developed by Kesten. \n\n"}
{"id": "math/0612315", "contents": "Title: Scaling limits of bipartite planar maps are homeomorphic to the 2-sphere Abstract: We prove that scaling limits of random planar maps which are uniformly\ndistributed over the set of all rooted 2k-angulations are a.s. homeomorphic to\nthe two-dimensional sphere. Our methods rely on the study of certain random\ngeodesic laminations of the disk. \n\n"}
{"id": "math/0702622", "contents": "Title: Well-posedness and invariant measures for HJM models with deterministic\n  volatility and L\\'evy noise Abstract: We give sufficient conditions for existence, uniqueness and ergodicity of\ninvariant measures for Musiela's stochastic partial differential equation with\ndeterministic volatility and a Hilbert space valued driving L\\'evy noise.\nConditions for the absence of arbitrage and for the existence of mild solutions\nare also discussed. \n\n"}
{"id": "math/0703559", "contents": "Title: Kakeya Sets and Directional Maximal Operators in the Plane Abstract: We completely characterize the boundedness of planar directional maximal\noperators on L^p. More precisely, if Omega is a set of directions, we show that\nM_Omega, the maximal operator associated to line segments in the directions\nOmega, is unbounded on L^p, for all p < infinity, precisely when Omega admits\nKakeya-type sets. In fact, we show that if Omega does not admit Kakeya sets,\nthen Omega is a generalized lacunary set, and hence M_Omega is bounded on L^p,\nfor p>1. \n\n"}
{"id": "math/9810015", "contents": "Title: Point processes and the infinite symmetric group. Part VI: Summary of\n  results Abstract: We give a summary of the results from Parts I-V (math.RT/9804086,\nmath.RT/9804087, math.RT/9804088, math.RT/9810013, math.RT/9810014).\n  Our work originated from harmonic analysis on the infinite symmetric group.\nThe problem of spectral decomposition for certain representations of this group\nleads to a family of probability measures on an infinite-dimensional simplex,\nwhich is a kind of dual object for the infinite symmetric group. To understand\nthe nature of these measures we interpret them as stochastic point processes on\nthe punctured real line and compute their correlation functions. The\ncorrelation functions are given by multidimensional integrals which can be\nexpressed in terms of a multivariate hypergeometric series (the Lauricella\nfunction of type B). It turns out that after a slight modification (`lifting')\nof the processes the correlation functions take a common in Random Matrix\nTheory (RMT) determinantal form with a certain kernel.\n  The kernel is expressed through the classical Whittaker functions. It depends\non two parameters and admits a variety of degenerations. They include the\nwell-known in RMT sine and Bessel kernels as well as some other Bessel-type\nkernels which, to our best knowledge, are new.\n  The explicit knowledge of the correlation functions enables us to derive a\nnumber of conclusions about the initial probability measures.\n  We also study the structure of our kernel; this finally leads to a\nconstructive description of the initial measures.\n  We believe that this work provides a new promising connection between RMT and\nRepresentation Theory. \n\n"}
{"id": "q-bio/0610057", "contents": "Title: Second look at the spread of epidemics on networks Abstract: In an important paper, M.E.J. Newman claimed that a general network-based\nstochastic Susceptible-Infectious-Removed (SIR) epidemic model is isomorphic to\na bond percolation model, where the bonds are the edges of the contact network\nand the bond occupation probability is equal to the marginal probability of\ntransmission from an infected node to a susceptible neighbor. In this paper, we\nshow that this isomorphism is incorrect and define a semi-directed random\nnetwork we call the epidemic percolation network that is exactly isomorphic to\nthe SIR epidemic model in any finite population. In the limit of a large\npopulation, (i) the distribution of (self-limited) outbreak sizes is identical\nto the size distribution of (small) out-components, (ii) the epidemic threshold\ncorresponds to the phase transition where a giant strongly-connected component\nappears, (iii) the probability of a large epidemic is equal to the probability\nthat an initial infection occurs in the giant in-component, and (iv) the\nrelative final size of an epidemic is equal to the proportion of the network\ncontained in the giant out-component. For the SIR model considered by Newman,\nwe show that the epidemic percolation network predicts the same mean outbreak\nsize below the epidemic threshold, the same epidemic threshold, and the same\nfinal size of an epidemic as the bond percolation model. However, the bond\npercolation model fails to predict the correct outbreak size distribution and\nprobability of an epidemic when there is a nondegenerate infectious period\ndistribution. We confirm our findings by comparing predictions from percolation\nnetworks and bond percolation models to the results of simulations. In an\nappendix, we show that an isomorphism to an epidemic percolation network can be\ndefined for any time-homogeneous stochastic SIR model. \n\n"}
{"id": "q-bio/0612024", "contents": "Title: Single-crossover dynamics: finite versus infinite populations Abstract: Populations evolving under the joint influence of recombination and\nresampling (traditionally known as genetic drift) are investigated. First, we\nsummarise and adapt a deterministic approach, as valid for infinite\npopulations, which assumes continuous time and single crossover events. The\ncorresponding nonlinear system of differential equations permits a closed\nsolution, both in terms of the type frequencies and via linkage disequilibria\nof all orders. To include stochastic effects, we then consider the\ncorresponding finite-population model, the Moran model with single crossovers,\nand examine it both analytically and by means of simulations. Particular\nemphasis is on the connection with the deterministic solution. If there is only\nrecombination and every pair of recombined offspring replaces their pair of\nparents (i.e., there is no resampling), then the {\\em expected} type\nfrequencies in the finite population, of arbitrary size, equal the type\nfrequencies in the infinite population. If resampling is included, the\nstochastic process converges, in the infinite-population limit, to the\ndeterministic dynamics, which turns out to be a good approximation already for\npopulations of moderate size. \n\n"}
