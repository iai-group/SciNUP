{"id": "0802.2159", "contents": "Title: A Distributed Merge and Split Algorithm for Fair Cooperation in Wireless\n  Networks Abstract: This paper introduces a novel concept from coalitional game theory which\nallows the dynamic formation of coalitions among wireless nodes. A simple and\ndistributed merge and split algorithm for coalition formation is constructed.\nThis algorithm is applied to study the gains resulting from the cooperation\namong single antenna transmitters for virtual MIMO formation. The aim is to\nfind an ultimate transmitters coalition structure that allows cooperating users\nto maximize their utilities while accounting for the cost of coalition\nformation. Through this novel game theoretical framework, the wireless network\ntransmitters are able to self-organize and form a structured network composed\nof disjoint stable coalitions. Simulation results show that the proposed\nalgorithm can improve the average individual user utility by 26.4% as well as\ncope with the mobility of the distributed users. \n\n"}
{"id": "0808.3746", "contents": "Title: A game-theoretic version of Oakes' example for randomized forecasting Abstract: Using the game-theoretic framework for probability, Vovk and Shafer. have\nshown that it is always possible, using randomization, to make sequential\nprobability forecasts that pass any countable set of well-behaved statistical\ntests. This result generalizes work by other authors, who consider only tests\nof calbration.\n  We complement this result with a lower bound. We show that Vovk and Shafer's\nresult is valid only when the forecasts are computed with unrestrictedly\nincreasing degree of accuracy.\n  When some level of discreteness is fixed, we present a game-theoretic\ngeneralization of Oakes' example for randomized forecasting that is a test\nfailing any given method of deferministic forecasting; originally, this example\nwas presented for deterministic calibration. \n\n"}
{"id": "0809.3170", "contents": "Title: A New Framework of Multistage Hypothesis Tests Abstract: In this paper, we have established a general framework of multistage\nhypothesis tests which applies to arbitrarily many mutually exclusive and\nexhaustive composite hypotheses. Within the new framework, we have constructed\nspecific multistage tests which rigorously control the risk of committing\ndecision errors and are more efficient than previous tests in terms of average\nsample number and the number of sampling operations. Without truncation, the\nsample numbers of our testing plans are absolutely bounded. \n\n"}
{"id": "0904.2541", "contents": "Title: Disproof of the Neighborhood Conjecture with Implications to SAT Abstract: We study a Maker/Breaker game described by Beck. As a result we disprove a\nconjecture of Beck on positional games, establish a connection between this\ngame and SAT and construct an unsatisfiable k-CNF formula with few occurrences\nper variable, thereby improving a previous result by Hoory and Szeider and\nshowing that the bound obtained from the Lovasz Local Lemma is tight up to a\nconstant factor. The Maker/Breaker game we study is as follows. Maker and\nBreaker take turns in choosing vertices from a given n-uniform hypergraph F,\nwith Maker going first. Maker's goal is to completely occupy a hyperedge and\nBreaker tries to avoid this. Beck conjectures that if the maximum neighborhood\nsize of F is at most 2^(n-1) then Breaker has a winning strategy. We disprove\nthis conjecture by establishing an n-uniform hypergraph with maximum\nneighborhood size 3*2^(n - 3) where Maker has a winning strategy. Moreover, we\nshow how to construct an n-uniform hypergraph with maximum degree (2^(n-1))/n\nwhere maker has a winning strategy. Finally, we establish a connection between\nSAT and the Maker/Breaker game we study. We can use this connection to derive\nnew results in SAT. Kratochvil, Savicky and Tuza showed that for every k >= 3\nthere is an integer f(k) such that every (k,f(k))-formula is satisfiable, but\n(k,f(k) + 1)-SAT is already NP-complete (it is not known whether f(k) is\ncomputable). Kratochvil, Savicky and Tuza also gave the best known lower bound\nf(k) = Omega(2^k/k), which is a consequence of the Lovasz Local Lemma. We prove\nthat, in fact, f(k) = Theta(2^k/k), improving upon the best known upper bound\nO((log k) * 2^k/k) by Hoory and Szeider. \n\n"}
{"id": "0906.4321", "contents": "Title: Reasoning About Knowledge of Unawareness Revisited Abstract: In earlier work, we proposed a logic that extends the Logic of General\nAwareness of Fagin and Halpern [1988] by allowing quantification over primitive\npropositions. This makes it possible to express the fact that an agent knows\nthat there are some facts of which he is unaware. In that logic, it is not\npossible to model an agent who is uncertain about whether he is aware of all\nformulas. To overcome this problem, we keep the syntax of the earlier paper,\nbut allow models where, with each world, a possibly different language is\nassociated. We provide a sound and complete axiomatization for this logic and\nshow that, under natural assumptions, the quantifier-free fragment of the logic\nis characterized by exactly the same axioms as the logic of Heifetz, Meier, and\nSchipper [2008]. \n\n"}
{"id": "0906.4827", "contents": "Title: Physical Layer Security: Coalitional Games for Distributed Cooperation Abstract: Cooperation between wireless network nodes is a promising technique for\nimproving the physical layer security of wireless transmission, in terms of\nsecrecy capacity, in the presence of multiple eavesdroppers. While existing\nphysical layer security literature answered the question \"what are the\nlink-level secrecy capacity gains from cooperation?\", this paper attempts to\nanswer the question of \"how to achieve those gains in a practical decentralized\nwireless network and in the presence of a secrecy capacity cost for information\nexchange?\". For this purpose, we model the physical layer security cooperation\nproblem as a coalitional game with non-transferable utility and propose a\ndistributed algorithm for coalition formation. Through the proposed algorithm,\nthe wireless users can autonomously cooperate and self-organize into disjoint\nindependent coalitions, while maximizing their secrecy capacity taking into\naccount the security costs during information exchange. We analyze the\nresulting coalitional structures, discuss their properties, and study how the\nusers can self-adapt the network topology to environmental changes such as\nmobility. Simulation results show that the proposed algorithm allows the users\nto cooperate and self-organize while improving the average secrecy capacity per\nuser up to 25.32% relative to the non-cooperative case. \n\n"}
{"id": "1001.0436", "contents": "Title: Truthful Assignment without Money Abstract: We study the design of truthful mechanisms that do not use payments for the\ngeneralized assignment problem (GAP) and its variants. An instance of the GAP\nconsists of a bipartite graph with jobs on one side and machines on the other.\nMachines have capacities and edges have values and sizes; the goal is to\nconstruct a welfare maximizing feasible assignment. In our model of private\nvaluations, motivated by impossibility results, the value and sizes on all\njob-machine pairs are public information; however, whether an edge exists or\nnot in the bipartite graph is a job's private information.\n  We study several variants of the GAP starting with matching. For the\nunweighted version, we give an optimal strategyproof mechanism; for maximum\nweight bipartite matching, however, we show give a 2-approximate strategyproof\nmechanism and show by a matching lowerbound that this is optimal. Next we study\nknapsack-like problems, which are APX-hard. For these problems, we develop a\ngeneral LP-based technique that extends the ideas of Lavi and Swamy to reduce\ndesigning a truthful mechanism without money to designing such a mechanism for\nthe fractional version of the problem, at a loss of a factor equal to the\nintegrality gap in the approximation ratio. We use this technique to obtain\nstrategyproof mechanisms with constant approximation ratios for these problems.\nWe then design an O(log n)-approximate strategyproof mechanism for the GAP by\nreducing, with logarithmic loss in the approximation, to our solution for the\nvalue-invariant GAP. Our technique may be of independent interest for designing\ntruthful mechanisms without money for other LP-based problems. \n\n"}
{"id": "1004.2079", "contents": "Title: Bargaining dynamics in exchange networks Abstract: We consider a one-sided assignment market or exchange network with\ntransferable utility and propose a model for the dynamics of bargaining in such\na market. Our dynamical model is local, involving iterative updates of 'offers'\nbased on estimated best alternative matches, in the spirit of pairwise Nash\nbargaining. We establish that when a balanced outcome (a generalization of the\npairwise Nash bargaining solution to networks) exists, our dynamics converges\nrapidly to such an outcome. We extend our results to the cases of (i) general\nagent 'capacity constraints', i.e., an agent may be allowed to participate in\nmultiple matches, and (ii) 'unequal bargaining powers' (where we also find a\nsurprising change in rate of convergence). \n\n"}
{"id": "1005.2638", "contents": "Title: Hierarchical Clustering for Finding Symmetries and Other Patterns in\n  Massive, High Dimensional Datasets Abstract: Data analysis and data mining are concerned with unsupervised pattern finding\nand structure determination in data sets. \"Structure\" can be understood as\nsymmetry and a range of symmetries are expressed by hierarchy. Such symmetries\ndirectly point to invariants, that pinpoint intrinsic properties of the data\nand of the background empirical domain of interest. We review many aspects of\nhierarchy here, including ultrametric topology, generalized ultrametric,\nlinkages with lattices and other discrete algebraic structures and with p-adic\nnumber representations. By focusing on symmetries in data we have a powerful\nmeans of structuring and analyzing massive, high dimensional data stores. We\nillustrate the powerfulness of hierarchical clustering in case studies in\nchemistry and finance, and we provide pointers to other published case studies. \n\n"}
{"id": "1007.3801", "contents": "Title: On the Approximability of Budget Feasible Mechanisms Abstract: Budget feasible mechanisms, recently initiated by Singer (FOCS 2010), extend\nalgorithmic mechanism design problems to a realistic setting with a budget\nconstraint. We consider the problem of designing truthful budget feasible\nmechanisms for general submodular functions: we give a randomized mechanism\nwith approximation ratio $7.91$ (improving the previous best-known result 112),\nand a deterministic mechanism with approximation ratio $8.34$. Further we study\nthe knapsack problem, which is special submodular function, give a $2+\\sqrt{2}$\napproximation deterministic mechanism (improving the previous best-known result\n6), and a 3 approximation randomized mechanism. We provide a similar result for\nan extended knapsack problem with heterogeneous items, where items are divided\ninto groups and one can pick at most one item from each group.\n  Finally we show a lower bound of approximation ratio of $1+\\sqrt{2}$ for\ndeterministic mechanisms and 2 for randomized mechanisms for knapsack, as well\nas the general submodular functions. Our lower bounds are unconditional, which\ndo not rely on any computational or complexity assumptions. \n\n"}
{"id": "1010.0056", "contents": "Title: Online Learning in Opportunistic Spectrum Access: A Restless Bandit\n  Approach Abstract: We consider an opportunistic spectrum access (OSA) problem where the\ntime-varying condition of each channel (e.g., as a result of random fading or\ncertain primary users' activities) is modeled as an arbitrary finite-state\nMarkov chain. At each instance of time, a (secondary) user probes a channel and\ncollects a certain reward as a function of the state of the channel (e.g., good\nchannel condition results in higher data rate for the user). Each channel has\npotentially different state space and statistics, both unknown to the user, who\ntries to learn which one is the best as it goes and maximizes its usage of the\nbest channel. The objective is to construct a good online learning algorithm so\nas to minimize the difference between the user's performance in total rewards\nand that of using the best channel (on average) had it known which one is the\nbest from a priori knowledge of the channel statistics (also known as the\nregret). This is a classic exploration and exploitation problem and results\nabound when the reward processes are assumed to be iid. Compared to prior work,\nthe biggest difference is that in our case the reward process is assumed to be\nMarkovian, of which iid is a special case. In addition, the reward processes\nare restless in that the channel conditions will continue to evolve independent\nof the user's actions. This leads to a restless bandit problem, for which there\nexists little result on either algorithms or performance bounds in this\nlearning context to the best of our knowledge. In this paper we introduce an\nalgorithm that utilizes regenerative cycles of a Markov chain and computes a\nsample-mean based index policy, and show that under mild conditions on the\nstate transition probabilities of the Markov chains this algorithm achieves\nlogarithmic regret uniformly over time, and that this regret bound is also\noptimal. \n\n"}
{"id": "1010.5081", "contents": "Title: Dynamics of Profit-Sharing Games Abstract: An important task in the analysis of multiagent systems is to understand how\ngroups of selfish players can form coalitions, i.e., work together in teams. In\nthis paper, we study the dynamics of coalition formation under bounded\nrationality. We consider settings where each team's profit is given by a convex\nfunction, and propose three profit-sharing schemes, each of which is based on\nthe concept of marginal utility. The agents are assumed to be myopic, i.e.,\nthey keep changing teams as long as they can increase their payoff by doing so.\nWe study the properties (such as closeness to Nash equilibrium or total profit)\nof the states that result after a polynomial number of such moves, and prove\nbounds on the price of anarchy and the price of stability of the corresponding\ngames. \n\n"}
{"id": "1011.4752", "contents": "Title: The Non-Bayesian Restless Multi-Armed Bandit: a Case of Near-Logarithmic\n  Regret Abstract: In the classic Bayesian restless multi-armed bandit (RMAB) problem, there are\n$N$ arms, with rewards on all arms evolving at each time as Markov chains with\nknown parameters. A player seeks to activate $K \\geq 1$ arms at each time in\norder to maximize the expected total reward obtained over multiple plays. RMAB\nis a challenging problem that is known to be PSPACE-hard in general. We\nconsider in this work the even harder non-Bayesian RMAB, in which the\nparameters of the Markov chain are assumed to be unknown \\emph{a priori}. We\ndevelop an original approach to this problem that is applicable when the\ncorresponding Bayesian problem has the structure that, depending on the known\nparameter values, the optimal solution is one of a prescribed finite set of\npolicies. In such settings, we propose to learn the optimal policy for the\nnon-Bayesian RMAB by employing a suitable meta-policy which treats each policy\nfrom this finite set as an arm in a different non-Bayesian multi-armed bandit\nproblem for which a single-arm selection policy is optimal. We demonstrate this\napproach by developing a novel sensing policy for opportunistic spectrum access\nover unknown dynamic channels. We prove that our policy achieves\nnear-logarithmic regret (the difference in expected reward compared to a\nmodel-aware genie), which leads to the same average reward that can be achieved\nby the optimal policy under a known model. This is the first such result in the\nliterature for a non-Bayesian RMAB. \n\n"}
{"id": "1011.5384", "contents": "Title: Spectrum Sharing as Spatial Congestion Games Abstract: In this paper, we present and analyze the properties of a new class of games\n- the spatial congestion game (SCG), which is a generalization of the classical\ncongestion game (CG). In a classical congestion game, multiple users share the\nsame set of resources and a user's payoff for using any resource is a function\nof the total number of users sharing it. As a potential game, this game enjoys\nsome very appealing properties, including the existence of a pure strategy Nash\nequilibrium (NE) and that every improvement path is finite and leads to such a\nNE (also called the finite improvement property or FIP). While it's tempting to\nuse this model to study spectrum sharing, it does not capture the spatial reuse\nfeature of wireless communication, where resources (interpreted as channels)\nmay be reused without increasing congestion provided that users are located far\naway from each other. This motivates us to study an extended form of the\ncongestion game where a user's payoff for using a resource is a function of the\nnumber of its interfering users sharing it. This naturally results in a spatial\ncongestion game (SCG), where users are placed over a network (or a conflict\ngraph). We study fundamental properties of a spatial congestion game; in\nparticular, we seek to answer under what conditions this game possesses the\nfinite improvement property or a Nash equilibrium. We also discuss the\nimplications of these results when applied to wireless spectrum sharing. \n\n"}
{"id": "1012.0866", "contents": "Title: Generalized Species Sampling Priors with Latent Beta reinforcements Abstract: Many popular Bayesian nonparametric priors can be characterized in terms of\nexchangeable species sampling sequences. However, in some applications,\nexchangeability may not be appropriate. We introduce a {novel and\nprobabilistically coherent family of non-exchangeable species sampling\nsequences characterized by a tractable predictive probability function with\nweights driven by a sequence of independent Beta random variables. We compare\ntheir theoretical clustering properties with those of the Dirichlet Process and\nthe two parameters Poisson-Dirichlet process. The proposed construction\nprovides a complete characterization of the joint process, differently from\nexisting work. We then propose the use of such process as prior distribution in\na hierarchical Bayes modeling framework, and we describe a Markov Chain Monte\nCarlo sampler for posterior inference. We evaluate the performance of the prior\nand the robustness of the resulting inference in a simulation study, providing\na comparison with popular Dirichlet Processes mixtures and Hidden Markov\nModels. Finally, we develop an application to the detection of chromosomal\naberrations in breast cancer by leveraging array CGH data. \n\n"}
{"id": "1102.2975", "contents": "Title: Decentralized Restless Bandit with Multiple Players and Unknown Dynamics Abstract: We consider decentralized restless multi-armed bandit problems with unknown\ndynamics and multiple players. The reward state of each arm transits according\nto an unknown Markovian rule when it is played and evolves according to an\narbitrary unknown random process when it is passive. Players activating the\nsame arm at the same time collide and suffer from reward loss. The objective is\nto maximize the long-term reward by designing a decentralized arm selection\npolicy to address unknown reward models and collisions among players. A\ndecentralized policy is constructed that achieves a regret with logarithmic\norder when an arbitrary nontrivial bound on certain system parameters is known.\nWhen no knowledge about the system is available, we extend the policy to\nachieve a regret arbitrarily close to the logarithmic order. The result finds\napplications in communication networks, financial investment, and industrial\nengineering. \n\n"}
{"id": "1102.3508", "contents": "Title: Online Learning of Rested and Restless Bandits Abstract: In this paper we study the online learning problem involving rested and\nrestless multiarmed bandits with multiple plays. The system consists of a\nsingle player/user and a set of K finite-state discrete-time Markov chains\n(arms) with unknown state spaces and statistics. At each time step the player\ncan play M arms. The objective of the user is to decide for each step which M\nof the K arms to play over a sequence of trials so as to maximize its long term\nreward. The restless multiarmed bandit is particularly relevant to the\napplication of opportunistic spectrum access (OSA), where a (secondary) user\nhas access to a set of K channels, each of time-varying condition as a result\nof random fading and/or certain primary users' activities. \n\n"}
{"id": "1104.0458", "contents": "Title: On the Payoff Mechanisms in Peer-Assisted Services with Multiple Content\n  Providers: Rationality and Fairness Abstract: This paper studies an incentive structure for cooperation and its stability\nin peer-assisted services when there exist multiple content providers, using a\ncoalition game theoretic approach. We first consider a generalized coalition\nstructure consisting of multiple providers with many assisting peers, where\npeers assist providers to reduce the operational cost in content distribution.\nTo distribute the profit from cost reduction to players (i.e., providers and\npeers), we then establish a generalized formula for individual payoffs when a\n\"Shapley-like\" payoff mechanism is adopted. We show that the grand coalition is\nunstable, even when the operational cost functions are concave, which is in\nsharp contrast to the recently studied case of a single provider where the\ngrand coalition is stable. We also show that irrespective of stability of the\ngrand coalition, there always exist coalition structures which are not\nconvergent to the grand coalition under a dynamic among coalition structures.\nOur results give us an incontestable fact that a provider does not tend to\ncooperate with other providers in peer-assisted services, and be separated from\nthem. Three facets of the noncooperative (selfish) providers are illustrated;\n(i) underpaid peers, (ii) service monopoly, and (iii) oscillatory coalition\nstructure. Lastly, we propose a stable payoff mechanism which improves fairness\nof profit-sharing by regulating the selfishness of the players as well as\ngrants the content providers a limited right of realistic bargaining. Our study\nopens many new questions such as realistic and efficient incentive structures\nand the tradeoffs between fairness and individual providers' competition in\npeer-assisted services. \n\n"}
{"id": "1104.1872", "contents": "Title: Convex and Network Flow Optimization for Structured Sparsity Abstract: We consider a class of learning problems regularized by a structured\nsparsity-inducing norm defined as the sum of l_2- or l_infinity-norms over\ngroups of variables. Whereas much effort has been put in developing fast\noptimization techniques when the groups are disjoint or embedded in a\nhierarchy, we address here the case of general overlapping groups. To this end,\nwe present two different strategies: On the one hand, we show that the proximal\noperator associated with a sum of l_infinity-norms can be computed exactly in\npolynomial time by solving a quadratic min-cost flow problem, allowing the use\nof accelerated proximal gradient methods. On the other hand, we use proximal\nsplitting techniques, and address an equivalent formulation with\nnon-overlapping groups, but in higher dimension and with additional\nconstraints. We propose efficient and scalable algorithms exploiting these two\nstrategies, which are significantly faster than alternative approaches. We\nillustrate these methods with several problems such as CUR matrix\nfactorization, multi-task learning of tree-structured dictionaries, background\nsubtraction in video sequences, image denoising with wavelets, and topographic\ndictionary learning of natural image patches. \n\n"}
{"id": "1104.3055", "contents": "Title: Deciding the Value 1 Problem of Probabilistic Leaktight Automata Abstract: The value 1 problem is a decision problem for probabilistic automata over\nfinite words: given a probabilistic automaton A, are there words accepted by A\nwith probability arbitrarily close to 1? This problem was proved undecidable\nrecently. We sharpen this result, showing that the undecidability result holds\neven if the probabilistic automata have only one probabilistic transition. Our\nmain contribution is to introduce a new class of probabilistic automata, called\nleaktight automata, for which the value 1 problem is shown decidable (and\nPSPACE-complete). We construct an algorithm based on the computation of a\nmonoid abstracting the behaviours of the automaton, and rely on algebraic\ntechniques developed by Simon for the correctness proof. The class of leaktight\nautomata is decidable in PSPACE, subsumes all subclasses of probabilistic\nautomata whose value 1 problem is known to be decidable (in particular\ndeterministic automata), and is closed under two natural composition operators. \n\n"}
{"id": "1105.0558", "contents": "Title: If more than Analytical Modeling is Needed to Predict Real Agents'\n  Strategic Interaction Abstract: This paper presents the research on the interdisciplinary research\ninfrastructure for understanding human reasoning in game-theoretic terms.\nStrategic reasoning is considered to impact human decision making in social,\neconomical and competitive interactions. The provided introduction explains and\nconnects concepts from AI, game theory and psychology. First result is a\nconcept of interdisciplinary game description language as a part of the focused\ninterdisciplinary research infrastructure. The need of this domain-specific\nlanguage is motivated and is aimed to accelerate the current developments. As\nsecond result, the paper provides a summary of ongoing research and its\nsignificance. \n\n"}
{"id": "1107.1744", "contents": "Title: Stochastic convex optimization with bandit feedback Abstract: This paper addresses the problem of minimizing a convex, Lipschitz function\n$f$ over a convex, compact set $\\xset$ under a stochastic bandit feedback\nmodel. In this model, the algorithm is allowed to observe noisy realizations of\nthe function value $f(x)$ at any query point $x \\in \\xset$. The quantity of\ninterest is the regret of the algorithm, which is the sum of the function\nvalues at algorithm's query points minus the optimal function value. We\ndemonstrate a generalization of the ellipsoid algorithm that incurs\n$\\otil(\\poly(d)\\sqrt{T})$ regret. Since any algorithm has regret at least\n$\\Omega(\\sqrt{T})$ on this problem, our algorithm is optimal in terms of the\nscaling with $T$. \n\n"}
{"id": "1107.2021", "contents": "Title: Multi-Instance Learning with Any Hypothesis Class Abstract: In the supervised learning setting termed Multiple-Instance Learning (MIL),\nthe examples are bags of instances, and the bag label is a function of the\nlabels of its instances. Typically, this function is the Boolean OR. The\nlearner observes a sample of bags and the bag labels, but not the instance\nlabels that determine the bag labels. The learner is then required to emit a\nclassification rule for bags based on the sample. MIL has numerous\napplications, and many heuristic algorithms have been used successfully on this\nproblem, each adapted to specific settings or applications. In this work we\nprovide a unified theoretical analysis for MIL, which holds for any underlying\nhypothesis class, regardless of a specific application or problem domain. We\nshow that the sample complexity of MIL is only poly-logarithmically dependent\non the size of the bag, for any underlying hypothesis class. In addition, we\nintroduce a new PAC-learning algorithm for MIL, which uses a regular supervised\nlearning algorithm as an oracle. We prove that efficient PAC-learning for MIL\ncan be generated from any efficient non-MIL supervised learning algorithm that\nhandles one-sided error. The computational complexity of the resulting\nalgorithm is only polynomially dependent on the bag size. \n\n"}
{"id": "1109.1528", "contents": "Title: Dynamics of Boltzmann Q-Learning in Two-Player Two-Action Games Abstract: We consider the dynamics of Q-learning in two-player two-action games with a\nBoltzmann exploration mechanism. For any non-zero exploration rate the dynamics\nis dissipative, which guarantees that agent strategies converge to rest points\nthat are generally different from the game's Nash Equlibria (NE). We provide a\ncomprehensive characterization of the rest point structure for different games,\nand examine the sensitivity of this structure with respect to the noise due to\nexploration. Our results indicate that for a class of games with multiple NE\nthe asymptotic behavior of learning dynamics can undergo drastic changes at\ncritical exploration rates. Furthermore, we demonstrate that for certain games\nwith a single NE, it is possible to have additional rest points (not\ncorresponding to any NE) that persist for a finite range of the exploration\nrates and disappear when the exploration rates of both players tend to zero. \n\n"}
{"id": "1109.4250", "contents": "Title: Complex dynamics in learning complicated games Abstract: Game theory is the standard tool used to model strategic interactions in\nevolutionary biology and social science. Traditional game theory studies the\nequilibria of simple games. But is traditional game theory applicable if the\ngame is complicated, and if not, what is? We investigate this question here,\ndefining a complicated game as one with many possible moves, and therefore many\npossible payoffs conditional on those moves. We investigate two-person games in\nwhich the players learn based on experience. By generating games at random we\nshow that under some circumstances the strategies of the two players converge\nto fixed points, but under others they follow limit cycles or chaotic\nattractors. The dimension of the chaotic attractors can be very high, implying\nthat the dynamics of the strategies are effectively random. In the chaotic\nregime the payoffs fluctuate intermittently, showing bursts of rapid change\npunctuated by periods of quiescence, similar to what is observed in fluid\nturbulence and financial markets. Our results suggest that such intermittency\nis a highly generic phenomenon, and that there is a large parameter regime for\nwhich complicated strategic interactions generate inherently unpredictable\nbehavior that is best described in the language of dynamical systems theory \n\n"}
{"id": "1110.1785", "contents": "Title: Voting with Limited Information and Many Alternatives Abstract: The traditional axiomatic approach to voting is motivated by the problem of\nreconciling differences in subjective preferences. In contrast, a dominant line\nof work in the theory of voting over the past 15 years has considered a\ndifferent kind of scenario, also fundamental to voting, in which there is a\ngenuinely \"best\" outcome that voters would agree on if they only had enough\ninformation. This type of scenario has its roots in the classical Condorcet\nJury Theorem; it includes cases such as jurors in a criminal trial who all want\nto reach the correct verdict but disagree in their inferences from the\navailable evidence, or a corporate board of directors who all want to improve\nthe company's revenue, but who have different information that favors different\noptions.\n  This style of voting leads to a natural set of questions: each voter has a\n{\\em private signal} that provides probabilistic information about which option\nis best, and a central question is whether a simple plurality voting system,\nwhich tabulates votes for different options, can cause the group decision to\narrive at the correct option. We show that plurality voting is powerful enough\nto achieve this: there is a way for voters to map their signals into votes for\noptions in such a way that --- with sufficiently many voters --- the correct\noption receives the greatest number of votes with high probability. We show\nfurther, however, that any process for achieving this is inherently expensive\nin the number of voters it requires: succeeding in identifying the correct\noption with probability at least $1 - \\eta$ requires $\\Omega(n^3 \\epsilon^{-2}\n\\log \\eta^{-1})$ voters, where $n$ is the number of options and $\\epsilon$ is a\ndistributional measure of the minimum difference between the options. \n\n"}
{"id": "1111.7299", "contents": "Title: Les crashs sont rationnels Abstract: As we show by using notions of equilibrium in infinite sequential games,\ncrashes or financial escalations are rational for economic or environmental\nagents, who have a vision of an infinite world. This contradicts a picture of a\nself-regulating, wise and pacific economic world. In other words, in this\ncontext, equilibrium is not synonymous of stability. We try to draw, from this\nstatement, methodological consequences and new ways of thinking, especially in\neconomic game theory. Among those new paths, coinduction is the basis of our\nreasoning in infinite games. \n\n"}
{"id": "1112.2318", "contents": "Title: Low-rank optimization with trace norm penalty Abstract: The paper addresses the problem of low-rank trace norm minimization. We\npropose an algorithm that alternates between fixed-rank optimization and\nrank-one updates. The fixed-rank optimization is characterized by an efficient\nfactorization that makes the trace norm differentiable in the search space and\nthe computation of duality gap numerically tractable. The search space is\nnonlinear but is equipped with a particular Riemannian structure that leads to\nefficient computations. We present a second-order trust-region algorithm with a\nguaranteed quadratic rate of convergence. Overall, the proposed optimization\nscheme converges super-linearly to the global solution while maintaining\ncomplexity that is linear in the number of rows and columns of the matrix. To\ncompute a set of solutions efficiently for a grid of regularization parameters\nwe propose a predictor-corrector approach that outperforms the naive\nwarm-restart approach on the fixed-rank quotient manifold. The performance of\nthe proposed algorithm is illustrated on problems of low-rank matrix completion\nand multivariate linear regression. \n\n"}
{"id": "1112.3330", "contents": "Title: Quantum strategies are better than classical in almost any XOR game Abstract: We initiate a study of random instances of nonlocal games. We show that\nquantum strategies are better than classical for almost any 2-player XOR game.\nMore precisely, for large n, the entangled value of a random 2-player XOR game\nwith n questions to every player is at least 1.21... times the classical value,\nfor 1-o(1) fraction of all 2-player XOR games. \n\n"}
{"id": "1202.1089", "contents": "Title: Bargaining Dynamics in Exchange Networks Abstract: We consider a dynamical system for computing Nash bargaining solutions on\ngraphs and focus on its rate of convergence. More precisely, we analyze the\nedge-balanced dynamical system by Azar et al and fully specify its convergence\nfor an important class of elementary graph structures that arise in Kleinberg\nand Tardos' procedure for computing a Nash bargaining solution on general\ngraphs. We show that all these dynamical systems are either linear or\neventually become linear and that their convergence times are quadratic in the\nnumber of matched edges. \n\n"}
{"id": "1202.6258", "contents": "Title: A Stochastic Gradient Method with an Exponential Convergence Rate for\n  Finite Training Sets Abstract: We propose a new stochastic gradient method for optimizing the sum of a\nfinite set of smooth functions, where the sum is strongly convex. While\nstandard stochastic gradient methods converge at sublinear rates for this\nproblem, the proposed method incorporates a memory of previous gradient values\nin order to achieve a linear convergence rate. In a machine learning context,\nnumerical experiments indicate that the new algorithm can dramatically\noutperform standard algorithms, both in terms of optimizing the training error\nand reducing the test error quickly. \n\n"}
{"id": "1203.5181", "contents": "Title: $k$-MLE: A fast algorithm for learning statistical mixture models Abstract: We describe $k$-MLE, a fast and efficient local search algorithm for learning\nfinite statistical mixtures of exponential families such as Gaussian mixture\nmodels. Mixture models are traditionally learned using the\nexpectation-maximization (EM) soft clustering technique that monotonically\nincreases the incomplete (expected complete) likelihood. Given prescribed\nmixture weights, the hard clustering $k$-MLE algorithm iteratively assigns data\nto the most likely weighted component and update the component models using\nMaximum Likelihood Estimators (MLEs). Using the duality between exponential\nfamilies and Bregman divergences, we prove that the local convergence of the\ncomplete likelihood of $k$-MLE follows directly from the convergence of a dual\nadditively weighted Bregman hard clustering. The inner loop of $k$-MLE can be\nimplemented using any $k$-means heuristic like the celebrated Lloyd's batched\nor Hartigan's greedy swap updates. We then show how to update the mixture\nweights by minimizing a cross-entropy criterion that implies to update weights\nby taking the relative proportion of cluster points, and reiterate the mixture\nparameter update and mixture weight update processes until convergence. Hard EM\nis interpreted as a special case of $k$-MLE when both the component update and\nthe weight update are performed successively in the inner loop. To initialize\n$k$-MLE, we propose $k$-MLE++, a careful initialization of $k$-MLE guaranteeing\nprobabilistically a global bound on the best possible complete likelihood. \n\n"}
{"id": "1204.4717", "contents": "Title: Energy-Efficient Building HVAC Control Using Hybrid System LBMPC Abstract: Improving the energy-efficiency of heating, ventilation, and air-conditioning\n(HVAC) systems has the potential to realize large economic and societal\nbenefits. This paper concerns the system identification of a hybrid system\nmodel of a building-wide HVAC system and its subsequent control using a hybrid\nsystem formulation of learning-based model predictive control (LBMPC). Here,\nthe learning refers to model updates to the hybrid system model that\nincorporate the heating effects due to occupancy, solar effects, outside air\ntemperature (OAT), and equipment, in addition to integrator dynamics inherently\npresent in low-level control. Though we make significant modeling\nsimplifications, our corresponding controller that uses this model is able to\nexperimentally achieve a large reduction in energy usage without any\ndegradations in occupant comfort. It is in this way that we justify the\nmodeling simplifications that we have made. We conclude by presenting results\nfrom experiments on our building HVAC testbed, which show an average of 1.5MWh\nof energy savings per day (p = 0.002) with a 95% confidence interval of 1.0MWh\nto 2.1MWh of energy savings. \n\n"}
{"id": "1205.0047", "contents": "Title: $QD$-Learning: A Collaborative Distributed Strategy for Multi-Agent\n  Reinforcement Learning Through Consensus + Innovations Abstract: The paper considers a class of multi-agent Markov decision processes (MDPs),\nin which the network agents respond differently (as manifested by the\ninstantaneous one-stage random costs) to a global controlled state and the\ncontrol actions of a remote controller. The paper investigates a distributed\nreinforcement learning setup with no prior information on the global state\ntransition and local agent cost statistics. Specifically, with the agents'\nobjective consisting of minimizing a network-averaged infinite horizon\ndiscounted cost, the paper proposes a distributed version of $Q$-learning,\n$\\mathcal{QD}$-learning, in which the network agents collaborate by means of\nlocal processing and mutual information exchange over a sparse (possibly\nstochastic) communication network to achieve the network goal. Under the\nassumption that each agent is only aware of its local online cost data and the\ninter-agent communication network is \\emph{weakly} connected, the proposed\ndistributed scheme is almost surely (a.s.) shown to yield asymptotically the\ndesired value function and the optimal stationary control policy at each\nnetwork agent. The analytical techniques developed in the paper to address the\nmixed time-scale stochastic dynamics of the \\emph{consensus + innovations}\nform, which arise as a result of the proposed interactive distributed scheme,\nare of independent interest. \n\n"}
{"id": "1205.4471", "contents": "Title: Sparse Signal Recovery in the Presence of Intra-Vector and Inter-Vector\n  Correlation Abstract: This work discusses the problem of sparse signal recovery when there is\ncorrelation among the values of non-zero entries. We examine intra-vector\ncorrelation in the context of the block sparse model and inter-vector\ncorrelation in the context of the multiple measurement vector model, as well as\ntheir combination. Algorithms based on the sparse Bayesian learning are\npresented and the benefits of incorporating correlation at the algorithm level\nare discussed. The impact of correlation on the limits of support recovery is\nalso discussed highlighting the different impact intra-vector and inter-vector\ncorrelations have on such limits. \n\n"}
{"id": "1206.0333", "contents": "Title: Sparse Trace Norm Regularization Abstract: We study the problem of estimating multiple predictive functions from a\ndictionary of basis functions in the nonparametric regression setting. Our\nestimation scheme assumes that each predictive function can be estimated in the\nform of a linear combination of the basis functions. By assuming that the\ncoefficient matrix admits a sparse low-rank structure, we formulate the\nfunction estimation problem as a convex program regularized by the trace norm\nand the $\\ell_1$-norm simultaneously. We propose to solve the convex program\nusing the accelerated gradient (AG) method and the alternating direction method\nof multipliers (ADMM) respectively; we also develop efficient algorithms to\nsolve the key components in both AG and ADMM. In addition, we conduct\ntheoretical analysis on the proposed function estimation scheme: we derive a\nkey property of the optimal solution to the convex program; based on an\nassumption on the basis functions, we establish a performance bound of the\nproposed function estimation scheme (via the composite regularization).\nSimulation studies demonstrate the effectiveness and efficiency of the proposed\nalgorithms. \n\n"}
{"id": "1206.0981", "contents": "Title: An Informed Model of Personal Information Release in Social Networking\n  Sites Abstract: The emergence of online social networks and the growing popularity of digital\ncommunication has resulted in an increasingly amount of information about\nindividuals available on the Internet. Social network users are given the\nfreedom to create complex digital identities, and enrich them with truthful or\neven fake personal information. However, this freedom has led to serious\nsecurity and privacy incidents, due to the role users' identities play in\nestablishing social and privacy settings.\n  In this paper, we take a step toward a better understanding of online\ninformation exposure. Based on the detailed analysis of a sample of real-world\ndata, we develop a deception model for online users. The model uses a game\ntheoretic approach to characterizing a user's willingness to release, withhold\nor lie about information depending on the behavior of individuals within the\nuser's circle of friends. In the model, we take into account both the\nheterogeneous nature of users and their different attitudes, as well as the\ndifferent types of information they may expose online. \n\n"}
{"id": "1206.1270", "contents": "Title: Factoring nonnegative matrices with linear programs Abstract: This paper describes a new approach, based on linear programming, for\ncomputing nonnegative matrix factorizations (NMFs). The key idea is a\ndata-driven model for the factorization where the most salient features in the\ndata are used to express the remaining features. More precisely, given a data\nmatrix X, the algorithm identifies a matrix C such that X approximately equals\nCX and some linear constraints. The constraints are chosen to ensure that the\nmatrix C selects features; these features can then be used to find a low-rank\nNMF of X. A theoretical analysis demonstrates that this approach has guarantees\nsimilar to those of the recent NMF algorithm of Arora et al. (2012). In\ncontrast with this earlier work, the proposed method extends to more general\nnoise models and leads to efficient, scalable algorithms. Experiments with\nsynthetic and real datasets provide evidence that the new approach is also\nsuperior in practice. An optimized C++ implementation can factor a\nmultigigabyte matrix in a matter of minutes. \n\n"}
{"id": "1206.2372", "contents": "Title: PRISMA: PRoximal Iterative SMoothing Algorithm Abstract: Motivated by learning problems including max-norm regularized matrix\ncompletion and clustering, robust PCA and sparse inverse covariance selection,\nwe propose a novel optimization algorithm for minimizing a convex objective\nwhich decomposes into three parts: a smooth part, a simple non-smooth Lipschitz\npart, and a simple non-smooth non-Lipschitz part. We use a time variant\nsmoothing strategy that allows us to obtain a guarantee that does not depend on\nknowing in advance the total number of iterations nor a bound on the domain. \n\n"}
{"id": "1206.5533", "contents": "Title: Practical recommendations for gradient-based training of deep\n  architectures Abstract: Learning algorithms related to artificial neural networks and in particular\nfor Deep Learning may seem to involve many bells and whistles, called\nhyper-parameters. This chapter is meant as a practical guide with\nrecommendations for some of the most commonly used hyper-parameters, in\nparticular in the context of learning algorithms based on back-propagated\ngradient and gradient-based optimization. It also discusses how to deal with\nthe fact that more interesting results can be obtained when allowing one to\nadjust many hyper-parameters. Overall, it describes elements of the practice\nused to successfully and efficiently train and debug large-scale and often deep\nmulti-layer neural networks. It closes with open questions about the training\ndifficulties observed with deeper architectures. \n\n"}
{"id": "1207.0037", "contents": "Title: The Uniform Distribution in Incentive Dynamics Abstract: The uniform distribution is an important counterexample in game theory as\nmany of the canonical game dynamics have been shown not to converge to the\nequilibrium in certain cases. In particular none of the canonical game dynamics\nconverge to the uniform distribution in a form of rock-paper-scissors where the\namount an agent can lose is more than the agent can win, despite this fact, it\nis the unique Nash equilibrium. I will show that certain incentive dynamics are\nasymptotically stable at the uniform distribution when it is an incentive\nequilibrium. \n\n"}
{"id": "1207.0099", "contents": "Title: Density-Difference Estimation Abstract: We address the problem of estimating the difference between two probability\ndensities. A naive approach is a two-step procedure of first estimating two\ndensities separately and then computing their difference. However, such a\ntwo-step procedure does not necessarily work well because the first step is\nperformed without regard to the second step and thus a small error incurred in\nthe first stage can cause a big error in the second stage. In this paper, we\npropose a single-shot procedure for directly estimating the density difference\nwithout separately estimating two densities. We derive a non-parametric\nfinite-sample error bound for the proposed single-shot density-difference\nestimator and show that it achieves the optimal convergence rate. The\nusefulness of the proposed method is also demonstrated experimentally. \n\n"}
{"id": "1208.1237", "contents": "Title: Fast and Robust Recursive Algorithms for Separable Nonnegative Matrix\n  Factorization Abstract: In this paper, we study the nonnegative matrix factorization problem under\nthe separability assumption (that is, there exists a cone spanned by a small\nsubset of the columns of the input nonnegative data matrix containing all\ncolumns), which is equivalent to the hyperspectral unmixing problem under the\nlinear mixing model and the pure-pixel assumption. We present a family of fast\nrecursive algorithms, and prove they are robust under any small perturbations\nof the input data matrix. This family generalizes several existing\nhyperspectral unmixing algorithms and hence provides for the first time a\ntheoretical justification of their better practical performance. \n\n"}
{"id": "1208.5076", "contents": "Title: Opinion Dynamics in Social Networks: A Local Interaction Game with\n  Stubborn Agents Abstract: The process by which new ideas, innovations, and behaviors spread through a\nlarge social network can be thought of as a networked interaction game: Each\nagent obtains information from certain number of agents in his friendship\nneighborhood, and adapts his idea or behavior to increase his benefit. In this\npaper, we are interested in how opinions, about a certain topic, form in social\nnetworks. We model opinions as continuous scalars ranging from 0 to 1 with 1(0)\nrepresenting extremely positive(negative) opinion. Each agent has an initial\nopinion and incurs some cost depending on the opinions of his neighbors, his\ninitial opinion, and his stubbornness about his initial opinion. Agents\niteratively update their opinions based on their own initial opinions and\nobserving the opinions of their neighbors. The iterative update of an agent can\nbe viewed as a myopic cost-minimization response (i.e., the so-called best\nresponse) to the others' actions. We study whether an equilibrium can emerge as\na result of such local interactions and how such equilibrium possibly depends\non the network structure, initial opinions of the agents, and the location of\nstubborn agents and the extent of their stubbornness. We also study the\nconvergence speed to such equilibrium and characterize the convergence time as\na function of aforementioned factors. We also discuss the implications of such\nresults in a few well-known graphs such as Erdos-Renyi random graphs and\nsmall-world graphs. \n\n"}
{"id": "1209.2139", "contents": "Title: Fused Multiple Graphical Lasso Abstract: In this paper, we consider the problem of estimating multiple graphical\nmodels simultaneously using the fused lasso penalty, which encourages adjacent\ngraphs to share similar structures. A motivating example is the analysis of\nbrain networks of Alzheimer's disease using neuroimaging data. Specifically, we\nmay wish to estimate a brain network for the normal controls (NC), a brain\nnetwork for the patients with mild cognitive impairment (MCI), and a brain\nnetwork for Alzheimer's patients (AD). We expect the two brain networks for NC\nand MCI to share common structures but not to be identical to each other;\nsimilarly for the two brain networks for MCI and AD. The proposed formulation\ncan be solved using a second-order method. Our key technical contribution is to\nestablish the necessary and sufficient condition for the graphs to be\ndecomposable. Based on this key property, a simple screening rule is presented,\nwhich decomposes the large graphs into small subgraphs and allows an efficient\nestimation of multiple independent (small) subgraphs, dramatically reducing the\ncomputational cost. We perform experiments on both synthetic and real data; our\nresults demonstrate the effectiveness and efficiency of the proposed approach. \n\n"}
{"id": "1209.2194", "contents": "Title: Cooperative learning in multi-agent systems from intermittent\n  measurements Abstract: Motivated by the problem of tracking a direction in a decentralized way, we\nconsider the general problem of cooperative learning in multi-agent systems\nwith time-varying connectivity and intermittent measurements. We propose a\ndistributed learning protocol capable of learning an unknown vector $\\mu$ from\nnoisy measurements made independently by autonomous nodes. Our protocol is\ncompletely distributed and able to cope with the time-varying, unpredictable,\nand noisy nature of inter-agent communication, and intermittent noisy\nmeasurements of $\\mu$. Our main result bounds the learning speed of our\nprotocol in terms of the size and combinatorial features of the (time-varying)\nnetworks connecting the nodes. \n\n"}
{"id": "1210.2457", "contents": "Title: Down the Borel Hierarchy: Solving Muller Games via Safety Games Abstract: We transform a Muller game with n vertices into a safety game with (n!)^3\nvertices whose solution allows to determine the winning regions of the Muller\ngame and to compute a finite-state winning strategy for one player. This yields\na novel antichain-based memory structure and a natural notion of permissive\nstrategies for Muller games. Moreover, we generalize our construction by\npresenting a new type of game reduction from infinite games to safety games and\nshow its applicability to several other winning conditions. \n\n"}
{"id": "1210.4537", "contents": "Title: Coalgebraic Analysis of Subgame-perfect Equilibria in Infinite Games\n  without Discounting Abstract: We present a novel coalgebraic formulation of infinite extensive games. We\ndefine both the game trees and the strategy profiles by possibly infinite\nsystems of corecursive equations. Certain strategy profiles are proved to be\nsubgame perfect equilibria using a novel proof principle of predicate\ncoinduction. We characterize all subgame perfect equilibria for the dollar\nauction game. The economically interesting feature is that in order to prove\nthese results we do not need to rely on continuity assumptions on the payoffs\nwhich amount to discounting the future. In particular, we prove a form of\none-deviation principle without any such assumptions. This suggests that\ncoalgebra supports a more adequate treatment of infinite-horizon models in game\ntheory and economics. \n\n"}
{"id": "1211.2304", "contents": "Title: Probabilistic Combination of Classifier and Cluster Ensembles for\n  Non-transductive Learning Abstract: Unsupervised models can provide supplementary soft constraints to help\nclassify new target data under the assumption that similar objects in the\ntarget set are more likely to share the same class label. Such models can also\nhelp detect possible differences between training and target distributions,\nwhich is useful in applications where concept drift may take place. This paper\ndescribes a Bayesian framework that takes as input class labels from existing\nclassifiers (designed based on labeled data from the source domain), as well as\ncluster labels from a cluster ensemble operating solely on the target data to\nbe classified, and yields a consensus labeling of the target data. This\nframework is particularly useful when the statistics of the target data drift\nor change from those of the training data. We also show that the proposed\nframework is privacy-aware and allows performing distributed learning when\ndata/models have sharing restrictions. Experiments show that our framework can\nyield superior results to those provided by applying classifier ensembles only. \n\n"}
{"id": "1211.6244", "contents": "Title: A Computational Model and Convergence Theorem for Rumor Dissemination in\n  Social Networks Abstract: The spread of rumors, which are known as unverified statements of uncertain\norigin, may cause tremendous number of social problems. If it would be possible\nto identify factors affecting spreading a rumor (such as agents' desires, trust\nnetwork, etc.), then this could be used to slowdown or stop its spreading. A\ncomputational model that includes rumor features and the way a rumor is spread\namong society's members, based on their desires, is therefore needed. Our\nresearch is centering on the relation between the homogeneity of the society\nand rumor convergence in it and result shows that the homogeneity of the\nsociety is a necessary condition for convergence of the spreading rumor. \n\n"}
{"id": "1212.2002", "contents": "Title: A simpler approach to obtaining an O(1/t) convergence rate for the\n  projected stochastic subgradient method Abstract: In this note, we present a new averaging technique for the projected\nstochastic subgradient method. By using a weighted average with a weight of t+1\nfor each iterate w_t at iteration t, we obtain the convergence rate of O(1/t)\nwith both an easy proof and an easy implementation. The new scheme is compared\nempirically to existing techniques, with similar performance behavior. \n\n"}
{"id": "1212.3782", "contents": "Title: Can Selfish Groups be Self-Enforcing? Abstract: Algorithmic graph theory has thoroughly analyzed how, given a network\ndescribing constraints between various nodes, groups can be formed among these\nso that the resulting configuration optimizes a \\emph{global} metric. In\ncontrast, for various social and economic networks, groups are formed \\emph{de\nfacto} by the choices of selfish players. A fundamental problem in this setting\nis the existence and convergence to a \\emph{self-enforcing} configuration:\nassignment of players into groups such that no player has an incentive to move\ninto another group than hers. Motivated by information sharing on social\nnetworks -- and the difficult tradeoff between its benefits and the associated\nprivacy risk -- we study the possible emergence of such stable configurations\nin a general selfish group formation game.\n  Our paper considers this general game for the first time, and it completes\nits analysis. We show that convergence critically depends on the level of\n\\emph{collusions} among the players -- which allow multiple players to move\nsimultaneously as long as \\emph{all of them} benefit. Solving a previously open\nproblem we exactly show when, depending on collusions, convergence occurs\nwithin polynomial time, non-polynomial time, and when it never occurs. We also\nprove that previously known bounds on convergence time are all loose: by a\nnovel combinatorial analysis of the evolution of this game we are able to\nprovide the first \\emph{asymptotically exact} formula on its convergence.\nMoreover, we extend these results by providing a complete analysis when groups\nmay \\emph{overlap}, and for general utility functions representing\n\\emph{multi-modal} interactions. Finally, we prove that collusions have a\nsignificant and \\emph{positive} effect on the \\emph{efficiency} of the\nequilibrium that is attained. \n\n"}
{"id": "1212.5637", "contents": "Title: Random Spanning Trees and the Prediction of Weighted Graphs Abstract: We investigate the problem of sequentially predicting the binary labels on\nthe nodes of an arbitrary weighted graph. We show that, under a suitable\nparametrization of the problem, the optimal number of prediction mistakes can\nbe characterized (up to logarithmic factors) by the cutsize of a random\nspanning tree of the graph. The cutsize is induced by the unknown adversarial\nlabeling of the graph nodes. In deriving our characterization, we obtain a\nsimple randomized algorithm achieving in expectation the optimal mistake bound\non any polynomially connected weighted graph. Our algorithm draws a random\nspanning tree of the original graph and then predicts the nodes of this tree in\nconstant expected amortized time and linear space. Experiments on real-world\ndatasets show that our method compares well to both global (Perceptron) and\nlocal (label propagation) methods, while being generally faster in practice. \n\n"}
{"id": "1301.1420", "contents": "Title: Is it ever safe to vote strategically? Abstract: There are many situations in which mis-coordinated strategic voting can leave\nstrategic voters worse off than they would have been had they not tried to\nstrategize. We analyse the simplest of such scenarios, in which the set of\nstrategic voters all have the same sincere preferences and all cast the same\nstrategic vote, while all other voters vote sincerely. Most mis-coordinations\nin this framework can be classified as instances of either strategic\novershooting (too many voted strategically) or strategic undershooting (too\nfew). If mis-coordination can result in strategic voters ending up worse off\nthan they would have been had they all just voted sincerely, we call the\nrelevant strategic vote unsafe. We show that under every onto and\nnon-dictatorial social choice rule there exist circumstances where a voter has\nan incentive to cast a safe strategic vote. We extend the Gibbard-Satterthwaite\nTheorem by proving that every onto and non-dictatorial social choice rule can\nbe individually manipulated by a voter casting a safe strategic vote. \n\n"}
{"id": "1301.2533", "contents": "Title: A Novel Analytical Method for Evolutionary Graph Theory Problems Abstract: Evolutionary graph theory studies the evolutionary dynamics of populations\nstructured on graphs. A central problem is determining the probability that a\nsmall number of mutants overtake a population. Currently, Monte Carlo\nsimulations are used for estimating such fixation probabilities on general\ndirected graphs, since no good analytical methods exist. In this paper, we\nintroduce a novel deterministic framework for computing fixation probabilities\nfor strongly connected, directed, weighted evolutionary graphs under neutral\ndrift. We show how this framework can also be used to calculate the expected\nnumber of mutants at a given time step (even if we relax the assumption that\nthe graph is strongly connected), how it can extend to other related models\n(e.g. voter model), how our framework can provide non-trivial bounds for\nfixation probability in the case of an advantageous mutant, and how it can be\nused to find a non-trivial lower bound on the mean time to fixation. We provide\nvarious experimental results determining fixation probabilities and expected\nnumber of mutants on different graphs. Among these, we show that our method\nconsistently outperforms Monte Carlo simulations in speed by several orders of\nmagnitude. Finally we show how our approach can provide insight into synaptic\ncompetition in neurology. \n\n"}
{"id": "1301.5844", "contents": "Title: Ranking Games that have Competitiveness-based Strategies Abstract: An extensive literature in economics and social science addresses contests,\nin which players compete to outperform each other on some measurable criterion,\noften referred to as a player's score, or output. Players incur costs that are\nan increasing function of score, but receive prizes for obtaining higher score\nthan their competitors. In this paper we study finite games that are\ndiscretized contests, and the problems of computing exact and approximate Nash\nequilibria. Our motivation is the worst-case hardness of Nash equilibrium\ncomputation, and the resulting interest in important classes of games that\nadmit polynomial-time algorithms. For games that have a tie-breaking rule for\nplayers' scores, we present a polynomial-time algorithm for computing an exact\nequilibrium in the 2-player case, and for multiple players, a characterization\nof Nash equilibria that shows an interesting parallel between these games and\nunrestricted 2-player games in normal form. When ties are allowed, via a\nreduction from these games to a subclass of anonymous games, we give\napproximation schemes for two special cases: constant-sized set of strategies,\nand constant number of players. \n\n"}
{"id": "1302.2576", "contents": "Title: The trace norm constrained matrix-variate Gaussian process for multitask\n  bipartite ranking Abstract: We propose a novel hierarchical model for multitask bipartite ranking. The\nproposed approach combines a matrix-variate Gaussian process with a generative\nmodel for task-wise bipartite ranking. In addition, we employ a novel trace\nconstrained variational inference approach to impose low rank structure on the\nposterior matrix-variate Gaussian process. The resulting posterior covariance\nfunction is derived in closed form, and the posterior mean function is the\nsolution to a matrix-variate regression with a novel spectral elastic net\nregularizer. Further, we show that variational inference for the trace\nconstrained matrix-variate Gaussian process combined with maximum likelihood\nparameter estimation for the bipartite ranking model is jointly convex. Our\nmotivating application is the prioritization of candidate disease genes. The\ngoal of this task is to aid the identification of unobserved associations\nbetween human genes and diseases using a small set of observed associations as\nwell as kernels induced by gene-gene interaction networks and disease\nontologies. Our experimental results illustrate the performance of the proposed\nmodel on real world datasets. Moreover, we find that the resulting low rank\nsolution improves the computational scalability of training and testing as\ncompared to baseline models. \n\n"}
{"id": "1302.2671", "contents": "Title: Latent Self-Exciting Point Process Model for Spatial-Temporal Networks Abstract: We propose a latent self-exciting point process model that describes\ngeographically distributed interactions between pairs of entities. In contrast\nto most existing approaches that assume fully observable interactions, here we\nconsider a scenario where certain interaction events lack information about\nparticipants. Instead, this information needs to be inferred from the available\nobservations. We develop an efficient approximate algorithm based on\nvariational expectation-maximization to infer unknown participants in an event\ngiven the location and the time of the event. We validate the model on\nsynthetic as well as real-world data, and obtain very promising results on the\nidentity-inference task. We also use our model to predict the timing and\nparticipants of future events, and demonstrate that it compares favorably with\nbaseline approaches. \n\n"}
{"id": "1303.2643", "contents": "Title: Revealing Cluster Structure of Graph by Path Following Replicator\n  Dynamic Abstract: In this paper, we propose a path following replicator dynamic, and\ninvestigate its potentials in uncovering the underlying cluster structure of a\ngraph. The proposed dynamic is a generalization of the discrete replicator\ndynamic. The replicator dynamic has been successfully used to extract dense\nclusters of graphs; however, it is often sensitive to the degree distribution\nof a graph, and usually biased by vertices with large degrees, thus may fail to\ndetect the densest cluster. To overcome this problem, we introduce a dynamic\nparameter, called path parameter, into the evolution process. The path\nparameter can be interpreted as the maximal possible probability of a current\ncluster containing a vertex, and it monotonically increases as evolution\nprocess proceeds. By limiting the maximal probability, the phenomenon of some\nvertices dominating the early stage of evolution process is suppressed, thus\nmaking evolution process more robust. To solve the optimization problem with a\nfixed path parameter, we propose an efficient fixed point algorithm. The time\ncomplexity of the path following replicator dynamic is only linear in the\nnumber of edges of a graph, thus it can analyze graphs with millions of\nvertices and tens of millions of edges on a common PC in a few minutes.\nBesides, it can be naturally generalized to hypergraph and graph with edges of\ndifferent orders. We apply it to four important problems: maximum clique\nproblem, densest k-subgraph problem, structure fitting, and discovery of\nhigh-density regions. The extensive experimental results clearly demonstrate\nits advantages, in terms of robustness, scalability and flexility. \n\n"}
{"id": "1304.0539", "contents": "Title: A Real-time Group Auction System for Efficient Allocation of Cloud\n  Internet Applications Abstract: Increasing number of the cloud-based Internet applications demands for\nefficient resource and cost management. This paper proposes a real-time group\nauction system for the cloud instance market. The system is designed based on a\ncombinatorial double auction, and its applicability and effectiveness are\nevaluated in terms of resource efficiency and monetary benefits to auction\nparticipants (e.g., cloud users and providers). The proposed auction system\nassists them to decide when and how providers allocate their resources to which\nusers. Furthermore, we propose a distributed algorithm using a group formation\ngame that determines which users and providers will trade resources by their\ncooperative decisions. To find how to allocate the resources, the utility\noptimization problem is formulated as a binary integer programming problem, and\nthe nearly optimal solution is obtained by a heuristic algorithm with quadratic\ntime complexity. In comparison studies, the proposed real-time group auction\nsystem with cooperation outperforms an individual auction in terms of the\nresource efficiency (e.g., the request acceptance rate for users and resource\nutilization for providers) and monetary benefits (e.g., average payments for\nusers and total profits for providers). \n\n"}
{"id": "1304.0730", "contents": "Title: Representation, Approximation and Learning of Submodular Functions Using\n  Low-rank Decision Trees Abstract: We study the complexity of approximate representation and learning of\nsubmodular functions over the uniform distribution on the Boolean hypercube\n$\\{0,1\\}^n$. Our main result is the following structural theorem: any\nsubmodular function is $\\epsilon$-close in $\\ell_2$ to a real-valued decision\ntree (DT) of depth $O(1/\\epsilon^2)$. This immediately implies that any\nsubmodular function is $\\epsilon$-close to a function of at most\n$2^{O(1/\\epsilon^2)}$ variables and has a spectral $\\ell_1$ norm of\n$2^{O(1/\\epsilon^2)}$. It also implies the closest previous result that states\nthat submodular functions can be approximated by polynomials of degree\n$O(1/\\epsilon^2)$ (Cheraghchi et al., 2012). Our result is proved by\nconstructing an approximation of a submodular function by a DT of rank\n$4/\\epsilon^2$ and a proof that any rank-$r$ DT can be $\\epsilon$-approximated\nby a DT of depth $\\frac{5}{2}(r+\\log(1/\\epsilon))$.\n  We show that these structural results can be exploited to give an\nattribute-efficient PAC learning algorithm for submodular functions running in\ntime $\\tilde{O}(n^2) \\cdot 2^{O(1/\\epsilon^{4})}$. The best previous algorithm\nfor the problem requires $n^{O(1/\\epsilon^{2})}$ time and examples (Cheraghchi\net al., 2012) but works also in the agnostic setting. In addition, we give\nimproved learning algorithms for a number of related settings.\n  We also prove that our PAC and agnostic learning algorithms are essentially\noptimal via two lower bounds: (1) an information-theoretic lower bound of\n$2^{\\Omega(1/\\epsilon^{2/3})}$ on the complexity of learning monotone\nsubmodular functions in any reasonable model; (2) computational lower bound of\n$n^{\\Omega(1/\\epsilon^{2/3})}$ based on a reduction to learning of sparse\nparities with noise, widely-believed to be intractable. These are the first\nlower bounds for learning of submodular functions over the uniform\ndistribution. \n\n"}
{"id": "1304.7158", "contents": "Title: Irreflexive and Hierarchical Relations as Translations Abstract: We consider the problem of embedding entities and relations of knowledge\nbases in low-dimensional vector spaces. Unlike most existing approaches, which\nare primarily efficient for modeling equivalence relations, our approach is\ndesigned to explicitly model irreflexive relations, such as hierarchies, by\ninterpreting them as translations operating on the low-dimensional embeddings\nof the entities. Preliminary experiments show that, despite its simplicity and\na smaller number of parameters than previous approaches, our approach achieves\nstate-of-the-art performance according to standard evaluation protocols on data\nfrom WordNet and Freebase. \n\n"}
{"id": "1305.3120", "contents": "Title: Optimization with First-Order Surrogate Functions Abstract: In this paper, we study optimization methods consisting of iteratively\nminimizing surrogates of an objective function. By proposing several\nalgorithmic variants and simple convergence analyses, we make two main\ncontributions. First, we provide a unified viewpoint for several first-order\noptimization techniques such as accelerated proximal gradient, block coordinate\ndescent, or Frank-Wolfe algorithms. Second, we introduce a new incremental\nscheme that experimentally matches or outperforms state-of-the-art solvers for\nlarge-scale optimization problems typically arising in machine learning. \n\n"}
{"id": "1305.3334", "contents": "Title: Online Learning in a Contract Selection Problem Abstract: In an online contract selection problem there is a seller which offers a set\nof contracts to sequentially arriving buyers whose types are drawn from an\nunknown distribution. If there exists a profitable contract for the buyer in\nthe offered set, i.e., a contract with payoff higher than the payoff of not\naccepting any contracts, the buyer chooses the contract that maximizes its\npayoff. In this paper we consider the online contract selection problem to\nmaximize the sellers profit. Assuming that a structural property called ordered\npreferences holds for the buyer's payoff function, we propose online learning\nalgorithms that have sub-linear regret with respect to the best set of\ncontracts given the distribution over the buyer's type. This problem has many\napplications including spectrum contracts, wireless service provider data plans\nand recommendation systems. \n\n"}
{"id": "1305.4778", "contents": "Title: Zero-sum repeated games: Counterexamples to the existence of the\n  asymptotic value and the conjecture\n  $\\operatorname{maxmin}=\\operatorname{lim}v_n$ Abstract: Mertens [In Proceedings of the International Congress of Mathematicians\n(Berkeley, Calif., 1986) (1987) 1528-1577 Amer. Math. Soc.] proposed two\ngeneral conjectures about repeated games: the first one is that, in any\ntwo-person zero-sum repeated game, the asymptotic value exists, and the second\none is that, when Player 1 is more informed than Player 2, in the long run\nPlayer 1 is able to guarantee the asymptotic value. We disprove these two\nlong-standing conjectures by providing an example of a zero-sum repeated game\nwith public signals and perfect observation of the actions, where the value of\nthe $\\lambda$-discounted game does not converge when $\\lambda$ goes to 0. The\naforementioned example involves seven states, two actions and two signals for\neach player. Remarkably, players observe the payoffs, and play in turn. \n\n"}
{"id": "1306.2672", "contents": "Title: R3MC: A Riemannian three-factor algorithm for low-rank matrix completion Abstract: We exploit the versatile framework of Riemannian optimization on quotient\nmanifolds to develop R3MC, a nonlinear conjugate-gradient method for low-rank\nmatrix completion. The underlying search space of fixed-rank matrices is\nendowed with a novel Riemannian metric that is tailored to the least-squares\ncost. Numerical comparisons suggest that R3MC robustly outperforms\nstate-of-the-art algorithms across different problem instances, especially\nthose that combine scarcely sampled and ill-conditioned data. \n\n"}
{"id": "1306.2759", "contents": "Title: Horizontal and Vertical Ensemble with Deep Representation for\n  Classification Abstract: Representation learning, especially which by using deep learning, has been\nwidely applied in classification. However, how to use limited size of labeled\ndata to achieve good classification performance with deep neural network, and\nhow can the learned features further improve classification remain indefinite.\nIn this paper, we propose Horizontal Voting Vertical Voting and Horizontal\nStacked Ensemble methods to improve the classification performance of deep\nneural networks. In the ICML 2013 Black Box Challenge, via using these methods\nindependently, Bing Xu achieved 3rd in public leaderboard, and 7th in private\nleaderboard; Jingjing Xie achieved 4th in public leaderboard, and 5th in\nprivate leaderboard. \n\n"}
{"id": "1306.5918", "contents": "Title: A Randomized Nonmonotone Block Proximal Gradient Method for a Class of\n  Structured Nonlinear Programming Abstract: We propose a randomized nonmonotone block proximal gradient (RNBPG) method\nfor minimizing the sum of a smooth (possibly nonconvex) function and a\nblock-separable (possibly nonconvex nonsmooth) function. At each iteration,\nthis method randomly picks a block according to any prescribed probability\ndistribution and solves typically several associated proximal subproblems that\nusually have a closed-form solution, until a certain progress on objective\nvalue is achieved. In contrast to the usual randomized block coordinate descent\nmethod [23,20], our method has a nonmonotone flavor and uses variable stepsizes\nthat can partially utilize the local curvature information of the smooth\ncomponent of objective function. We show that any accumulation point of the\nsolution sequence of the method is a stationary point of the problem {\\it\nalmost surely} and the method is capable of finding an approximate stationary\npoint with high probability. We also establish a sublinear rate of convergence\nfor the method in terms of the minimal expected squared norm of certain\nproximal gradients over the iterations. When the problem under consideration is\nconvex, we show that the expected objective values generated by RNBPG converge\nto the optimal value of the problem. Under some assumptions, we further\nestablish a sublinear and linear rate of convergence on the expected objective\nvalues generated by a monotone version of RNBPG. Finally, we conduct some\npreliminary experiments to test the performance of RNBPG on the\n$\\ell_1$-regularized least-squares problem and a dual SVM problem in machine\nlearning. The computational results demonstrate that our method substantially\noutperforms the randomized block coordinate {\\it descent} method with fixed or\nvariable stepsizes. \n\n"}
{"id": "1307.0781", "contents": "Title: Distributed Online Big Data Classification Using Context Information Abstract: Distributed, online data mining systems have emerged as a result of\napplications requiring analysis of large amounts of correlated and\nhigh-dimensional data produced by multiple distributed data sources. We propose\na distributed online data classification framework where data is gathered by\ndistributed data sources and processed by a heterogeneous set of distributed\nlearners which learn online, at run-time, how to classify the different data\nstreams either by using their locally available classification functions or by\nhelping each other by classifying each other's data. Importantly, since the\ndata is gathered at different locations, sending the data to another learner to\nprocess incurs additional costs such as delays, and hence this will be only\nbeneficial if the benefits obtained from a better classification will exceed\nthe costs. We model the problem of joint classification by the distributed and\nheterogeneous learners from multiple data sources as a distributed contextual\nbandit problem where each data is characterized by a specific context. We\ndevelop a distributed online learning algorithm for which we can prove\nsublinear regret. Compared to prior work in distributed online data mining, our\nwork is the first to provide analytic regret results characterizing the\nperformance of the proposed algorithm. \n\n"}
{"id": "1307.7322", "contents": "Title: Complexity of Manipulation, Bribery, and Campaign Management in Bucklin\n  and Fallback Voting Abstract: A central theme in computational social choice is to study the extent to\nwhich voting systems computationally resist manipulative attacks seeking to\ninfluence the outcome of elections, such as manipulation (i.e., strategic\nvoting), control, and bribery. Bucklin and fallback voting are among the voting\nsystems with the broadest resistance (i.e., NP-hardness) to control attacks.\nHowever, only little is known about their behavior regarding manipulation and\nbribery attacks. We comprehensively investigate the computational resistance of\nBucklin and fallback voting for many of the common manipulation and bribery\nscenarios; we also complement our discussion by considering several campaign\nmanagement problems for Bucklin and fallback. \n\n"}
{"id": "1307.7838", "contents": "Title: Asymmetric-valued Spectrum Auction and Competition in Wireless Broadband\n  Services Abstract: We study bidding and pricing competition between two spiteful mobile network\noperators (MNOs) with considering their existing spectrum holdings. Given\nasymmetric-valued spectrum blocks are auctioned off to them via a first-price\nsealed-bid auction, we investigate the interactions between two spiteful MNOs\nand users as a three-stage dynamic game and characterize the dynamic game's\nequilibria. We show an asymmetric pricing structure and different market share\nbetween two spiteful MNOs. Perhaps counter-intuitively, our results show that\nthe MNO who acquires the less-valued spectrum block always lowers his service\nprice despite providing double-speed LTE service to users. We also show that\nthe MNO who acquires the high-valued spectrum block, despite charing a higher\nprice, still achieves more market share than the other MNO. We further show\nthat the competition between two MNOs leads to some loss of their revenues. By\ninvestigating a cross-over point at which the MNOs' profits are switched, it\nserves as the benchmark of practical auction designs. \n\n"}
{"id": "1308.4568", "contents": "Title: Distributed Online Learning via Cooperative Contextual Bandits Abstract: In this paper we propose a novel framework for decentralized, online learning\nby many learners. At each moment of time, an instance characterized by a\ncertain context may arrive to each learner; based on the context, the learner\ncan select one of its own actions (which gives a reward and provides\ninformation) or request assistance from another learner. In the latter case,\nthe requester pays a cost and receives the reward but the provider learns the\ninformation. In our framework, learners are modeled as cooperative contextual\nbandits. Each learner seeks to maximize the expected reward from its arrivals,\nwhich involves trading off the reward received from its own actions, the\ninformation learned from its own actions, the reward received from the actions\nrequested of others and the cost paid for these actions - taking into account\nwhat it has learned about the value of assistance from each other learner. We\ndevelop distributed online learning algorithms and provide analytic bounds to\ncompare the efficiency of these with algorithms with the complete knowledge\n(oracle) benchmark (in which the expected reward of every action in every\ncontext is known by every learner). Our estimates show that regret - the loss\nincurred by the algorithm - is sublinear in time. Our theoretical framework can\nbe used in many practical applications including Big Data mining, event\ndetection in surveillance sensor networks and distributed online recommendation\nsystems. \n\n"}
{"id": "1308.4915", "contents": "Title: Minimal Dirichlet energy partitions for graphs Abstract: Motivated by a geometric problem, we introduce a new non-convex graph\npartitioning objective where the optimality criterion is given by the sum of\nthe Dirichlet eigenvalues of the partition components. A relaxed formulation is\nidentified and a novel rearrangement algorithm is proposed, which we show is\nstrictly decreasing and converges in a finite number of iterations to a local\nminimum of the relaxed objective function. Our method is applied to several\nclustering problems on graphs constructed from synthetic data, MNIST\nhandwritten digits, and manifold discretizations. The model has a\nsemi-supervised extension and provides a natural representative for the\nclusters as well. \n\n"}
{"id": "1308.5835", "contents": "Title: Backhaul-Aware Interference Management in the Uplink of Wireless Small\n  Cell Networks Abstract: The design of distributed mechanisms for interference management is one of\nthe key challenges in emerging wireless small cell networks whose backhaul is\ncapacity limited and heterogeneous (wired, wireless and a mix thereof). In this\npaper, a novel, backhaul-aware approach to interference management in wireless\nsmall cell networks is proposed. The proposed approach enables macrocell user\nequipments (MUEs) to optimize their uplink performance, by exploiting the\npresence of neighboring small cell base stations. The problem is formulated as\na noncooperative game among the MUEs that seek to optimize their delay-rate\ntradeoff, given the conditions of both the radio access network and the --\npossibly heterogeneous -- backhaul. To solve this game, a novel, distributed\nlearning algorithm is proposed using which the MUEs autonomously choose their\noptimal uplink transmission strategies, given a limited amount of available\ninformation. The convergence of the proposed algorithm is shown and its\nproperties are studied. Simulation results show that, under various types of\nbackhauls, the proposed approach yields significant performance gains, in terms\nof both average throughput and delay for the MUEs, when compared to existing\nbenchmark algorithms. \n\n"}
{"id": "1309.1007", "contents": "Title: Concentration in unbounded metric spaces and algorithmic stability Abstract: We prove an extension of McDiarmid's inequality for metric spaces with\nunbounded diameter. To this end, we introduce the notion of the {\\em\nsubgaussian diameter}, which is a distribution-dependent refinement of the\nmetric diameter. Our technique provides an alternative approach to that of\nKutin and Niyogi's method of weakly difference-bounded functions, and yields\nnontrivial, dimension-free results in some interesting cases where the former\ndoes not. As an application, we give apparently the first generalization bound\nin the algorithmic stability setting that holds for unbounded loss functions.\nWe furthermore extend our concentration inequality to strongly mixing\nprocesses. \n\n"}
{"id": "1309.6301", "contents": "Title: Solving OSCAR regularization problems by proximal splitting algorithms Abstract: The OSCAR (octagonal selection and clustering algorithm for regression)\nregularizer consists of a L_1 norm plus a pair-wise L_inf norm (responsible for\nits grouping behavior) and was proposed to encourage group sparsity in\nscenarios where the groups are a priori unknown. The OSCAR regularizer has a\nnon-trivial proximity operator, which limits its applicability. We reformulate\nthis regularizer as a weighted sorted L_1 norm, and propose its grouping\nproximity operator (GPO) and approximate proximity operator (APO), thus making\nstate-of-the-art proximal splitting algorithms (PSAs) available to solve\ninverse problems with OSCAR regularization. The GPO is in fact the APO followed\nby additional grouping and averaging operations, which are costly in time and\nstorage, explaining the reason why algorithms with APO are much faster than\nthat with GPO. The convergences of PSAs with GPO are guaranteed since GPO is an\nexact proximity operator. Although convergence of PSAs with APO is may not be\nguaranteed, we have experimentally found that APO behaves similarly to GPO when\nthe regularization parameter of the pair-wise L_inf norm is set to an\nappropriately small value. Experiments on recovery of group-sparse signals\n(with unknown groups) show that PSAs with APO are very fast and accurate. \n\n"}
{"id": "1310.0432", "contents": "Title: Online Learning of Dynamic Parameters in Social Networks Abstract: This paper addresses the problem of online learning in a dynamic setting. We\nconsider a social network in which each individual observes a private signal\nabout the underlying state of the world and communicates with her neighbors at\neach time period. Unlike many existing approaches, the underlying state is\ndynamic, and evolves according to a geometric random walk. We view the scenario\nas an optimization problem where agents aim to learn the true state while\nsuffering the smallest possible loss. Based on the decomposition of the global\nloss function, we introduce two update mechanisms, each of which generates an\nestimate of the true state. We establish a tight bound on the rate of change of\nthe underlying state, under which individuals can track the parameter with a\nbounded variance. Then, we characterize explicit expressions for the steady\nstate mean-square deviation(MSD) of the estimates from the truth, per\nindividual. We observe that only one of the estimators recovers the optimal\nMSD, which underscores the impact of the objective function decomposition on\nthe learning quality. Finally, we provide an upper bound on the regret of the\nproposed methods, measured as an average of errors in estimating the parameter\nin a finite time. \n\n"}
{"id": "1310.1934", "contents": "Title: Discriminative Features via Generalized Eigenvectors Abstract: Representing examples in a way that is compatible with the underlying\nclassifier can greatly enhance the performance of a learning system. In this\npaper we investigate scalable techniques for inducing discriminative features\nby taking advantage of simple second order structure in the data. We focus on\nmulticlass classification and show that features extracted from the generalized\neigenvectors of the class conditional second moments lead to classifiers with\nexcellent empirical performance. Moreover, these features have attractive\ntheoretical properties, such as inducing representations that are invariant to\nlinear transformations of the input. We evaluate classifiers built from these\nfeatures on three different tasks, obtaining state of the art results. \n\n"}
{"id": "1310.5485", "contents": "Title: Behavior-Based online Incentive Mechanism for Crowd Sensing with Budget\n  Constraints Abstract: Crowd sensing is a new paradigm which leverages the ubiquity of\nsensor-equipped mobile devices to collect data. To achieve good quality for\ncrowd sensing, incentive mechanisms are indispensable to attract more\nparticipants. Most of existing mechanisms focus on the expected utility prior\nto sensing, ignoring the risk of low quality solution and privacy leakage.\nTraditional incentive mechanisms such as the Vickrey-Clarke-Groves (VCG)\nmechanism and its variants are not applicable here. In this paper, to address\nthese challenges, we propose a behavior based incentive mechanism for crowd\nsensing applications with budget constraints by applying sequential all-pay\nauctions in mobile social networks (MSNs), not only to consider the effects of\nextensive user participation, but also to maximize high quality of the context\nbased sensing content submission for crowd sensing platform under the budget\nconstraints, where users arrive in a sequential order. Through an extensive\nsimulation, results indicate that incentive mechanisms in our proposed\nframework outperform the best existing solution. \n\n"}
{"id": "1310.7991", "contents": "Title: Learning Sparsely Used Overcomplete Dictionaries via Alternating\n  Minimization Abstract: We consider the problem of sparse coding, where each sample consists of a\nsparse linear combination of a set of dictionary atoms, and the task is to\nlearn both the dictionary elements and the mixing coefficients. Alternating\nminimization is a popular heuristic for sparse coding, where the dictionary and\nthe coefficients are estimated in alternate steps, keeping the other fixed.\nTypically, the coefficients are estimated via $\\ell_1$ minimization, keeping\nthe dictionary fixed, and the dictionary is estimated through least squares,\nkeeping the coefficients fixed. In this paper, we establish local linear\nconvergence for this variant of alternating minimization and establish that the\nbasin of attraction for the global optimum (corresponding to the true\ndictionary and the coefficients) is $\\order{1/s^2}$, where $s$ is the sparsity\nlevel in each sample and the dictionary satisfies RIP. Combined with the recent\nresults of approximate dictionary estimation, this yields provable guarantees\nfor exact recovery of both the dictionary elements and the coefficients, when\nthe dictionary elements are incoherent. \n\n"}
{"id": "1311.0913", "contents": "Title: Bidding Games and Efficient Allocations Abstract: Richman games are zero-sum games, where in each turn players bid in order to\ndetermine who will play next [Lazarus et al.'99]. We extend the theory to\nimpartial general-sum two player games called \\emph{bidding games}, showing the\nexistence of pure subgame-perfect equilibria (PSPE). In particular, we show\nthat PSPEs form a semilattice, with a unique and natural \\emph{Bottom\nEquilibrium}.\n  Our main result shows that if only two actions available to the players in\neach node, then the Bottom Equilibrium has additional properties: (a) utilities\nare monotone in budget; (b) every outcome is Pareto-efficient; and (c) any\nPareto-efficient outcome is attained for some budget.\n  In the context of combinatorial bargaining, we show that a player with a\nfraction of X% of the total budget prefers her allocation to X% of the possible\nallocations. In addition, we provide a polynomial-time algorithm to compute the\nBottom Equilibrium of a binary bidding game. \n\n"}
{"id": "1311.2109", "contents": "Title: How to Gamble Against All Odds Abstract: A decision maker observes the evolving state of the world while constantly\ntrying to predict the next state given the history of past states. The ability\nto benefit from such predictions depends not only on the ability to recognize\npatters in history, but also on the range of actions available to the decision\nmaker.\n  We assume there are two possible states of the world. The decision maker is a\ngambler who has to bet a certain amount of money on the bits of an announced\nbinary sequence of states. If he makes a correct prediction he wins his wager,\notherwise he loses it.\n  We compare the power of betting strategies (aka martingales) whose wagers\ntake values in different sets of reals. A martingale whose wagers take values\nin a set $A$ is called an $A$-martingale. A set of reals $B$ anticipates a set\n$A$, if for every $A$-martingale there is a countable set of $B$-martingales,\nsuch that on every binary sequence on which the $A$-martingale gains an\ninfinite amount at least one of the $B$-martingales gains an infinite amount,\ntoo.\n  We show that for two important classes of pairs of sets $A$ and $B$, $B$\nanticipates $A$ if and only if the closure of $B$ contains $rA$, for some\npositive $r$. One class is when $A$ is bounded and $B$ is bounded away from\nzero; the other class is when $B$ is well ordered (has no left-accumulation\npoints). Our results generalize several recent results in algorithmic\nrandomness and answer a question posed by Chalcraft et al. (2012). \n\n"}
{"id": "1311.2483", "contents": "Title: Global Sensitivity Analysis with Dependence Measures Abstract: Global sensitivity analysis with variance-based measures suffers from several\ntheoretical and practical limitations, since they focus only on the variance of\nthe output and handle multivariate variables in a limited way. In this paper,\nwe introduce a new class of sensitivity indices based on dependence measures\nwhich overcomes these insufficiencies. Our approach originates from the idea to\ncompare the output distribution with its conditional counterpart when one of\nthe input variables is fixed. We establish that this comparison yields\npreviously proposed indices when it is performed with Csiszar f-divergences, as\nwell as sensitivity indices which are well-known dependence measures between\nrandom variables. This leads us to investigate completely new sensitivity\nindices based on recent state-of-the-art dependence measures, such as distance\ncorrelation and the Hilbert-Schmidt independence criterion. We also emphasize\nthe potential of feature selection techniques relying on such dependence\nmeasures as alternatives to screening in high dimension. \n\n"}
{"id": "1311.3088", "contents": "Title: Endogenous games with goals: side-payments among goal-directed\n  artificial agents Abstract: Artificial agents are typically oriented to the realization of an externally\nassigned task and try to optimize over secondary aspects of plan execution such\ntime lapse or power consumption, technically displaying a quasi-dichotomous\npreference relation. Boolean games have been developed as a paradigm for\nmodelling societies of agents with this type of preference. In boolean games\nagents exercise control over propositional variables and strive to achieve a\ngoal formula whose realization might require the opponents' cooperation.\nRecently, a theory of incentive engineering for such games has been devised,\nwhere an external authority steers the outcome of the game towards certain\ndesirable properties consistent with players' goals, by imposing a taxation\nmechanism on the players that makes the outcomes that do not comply with those\nproperties less appealing to them. The present contribution stems from a\ncomplementary perspective and studies, instead, how games with\nquasi-dichotomous preferences can be transformed from inside, rather than from\noutside, by endowing players with the possibility of sacrificing a part of\ntheir payoff received at a certain outcome in order to convince other players\nto play a certain strategy. Concretely we explore the properties of endogenous\ngames with goals, obtained coupling strategic games with goals, a\ngeneralization of boolean games, with the machinery of endogenous games coming\nfrom game theory. We analyze equilibria in those structures, showing the\npreconditions needed for desirable outcomes to be achieved without external\nintervention. What our results show is that endogenous games with goals display\nspecific irreducible features - with respect to what already known for\nendogenous games - which makes them worth studying in their own sake. \n\n"}
{"id": "1311.4721", "contents": "Title: Economic Efficiency Requires Interaction Abstract: We study the necessity of interaction between individuals for obtaining\napproximately efficient allocations. The role of interaction in markets has\nreceived significant attention in economic thinking, e.g. in Hayek's 1945\nclassic paper.\n  We consider this problem in the framework of simultaneous communication\ncomplexity. We analyze the amount of simultaneous communication required for\nachieving an approximately efficient allocation. In particular, we consider two\nsettings: combinatorial auctions with unit demand bidders (bipartite matching)\nand combinatorial auctions with subadditive bidders. For both settings we first\nshow that non-interactive systems have enormous communication costs relative to\ninteractive ones. On the other hand, we show that limited interaction enables\nus to find approximately efficient allocations. \n\n"}
{"id": "1311.6230", "contents": "Title: Privacy-Preserving Verifiable Incentive Mechanism for Crowdsourcing\n  Market Applications Abstract: Recently, a novel class of incentive mechanisms is proposed to attract\nextensive users to truthfully participate in crowd sensing applications with a\ngiven budget constraint. The class mechanisms also bring good service quality\nfor the requesters in crowd sensing applications. Although it is so important,\nthere still exists many verification and privacy challenges, including users'\nbids and subtask information privacy and identification privacy, winners' set\nprivacy of the platform, and the security of the payment outcomes. In this\npaper, we present a privacy-preserving verifiable incentive mechanism for crowd\nsensing applications with the budget constraint, not only to explore how to\nprotect the privacies of users and the platform, but also to make the\nverifiable payment correct between the platform and users for crowd sensing\napplications. Results indicate that our privacy-preserving verifiable incentive\nmechanism achieves the same results as the generic one without privacy\npreservation. \n\n"}
{"id": "1311.7198", "contents": "Title: ADMM Algorithm for Graphical Lasso with an $\\ell_{\\infty}$ Element-wise\n  Norm Constraint Abstract: We consider the problem of Graphical lasso with an additional $\\ell_{\\infty}$\nelement-wise norm constraint on the precision matrix. This problem has\napplications in high-dimensional covariance decomposition such as in\n\\citep{Janzamin-12}. We propose an ADMM algorithm to solve this problem. We\nalso use a continuation strategy on the penalty parameter to have a fast\nimplemenation of the algorithm. \n\n"}
{"id": "1312.0659", "contents": "Title: Prioritizing Consumers in Smart Grid: A Game Theoretic Approach Abstract: This paper proposes an energy management technique for a consumer-to-grid\nsystem in smart grid. The benefit to consumers is made the primary concern to\nencourage consumers to participate voluntarily in energy trading with the\ncentral power station (CPS) in situations of energy deficiency. A novel system\nmodel motivating energy trading under the goal of social optimality is\nproposed. A single-leader multiple-follower Stackelberg game is then studied to\nmodel the interactions between the CPS and a number of energy consumers (ECs),\nand to find optimal distributed solutions for the optimization problem based on\nthe system model. The CPS is considered as a leader seeking to minimize its\ntotal cost of buying energy from the ECs, and the ECs are the followers who\ndecide on how much energy they will sell to the CPS for maximizing their\nutilities. It is shown that the game, which can be implemented distributedly,\npossesses a socially optimal solution, in which the benefits-sum to all\nconsumers is maximized, as the total cost to the CPS is minimized. Numerical\nanalysis confirms the effectiveness of the game. \n\n"}
{"id": "1312.2132", "contents": "Title: Robust Subspace System Identification via Weighted Nuclear Norm\n  Optimization Abstract: Subspace identification is a classical and very well studied problem in\nsystem identification. The problem was recently posed as a convex optimization\nproblem via the nuclear norm relaxation. Inspired by robust PCA, we extend this\nframework to handle outliers. The proposed framework takes the form of a convex\noptimization problem with an objective that trades off fit, rank and sparsity.\nAs in robust PCA, it can be problematic to find a suitable regularization\nparameter. We show how the space in which a suitable parameter should be sought\ncan be limited to a bounded open set of the two dimensional parameter space. In\npractice, this is very useful since it restricts the parameter space that is\nneeded to be surveyed. \n\n"}
{"id": "1312.5753", "contents": "Title: SOMz: photometric redshift PDFs with self organizing maps and random\n  atlas Abstract: In this paper we explore the applicability of the unsupervised machine\nlearning technique of Self Organizing Maps (SOM) to estimate galaxy photometric\nredshift probability density functions (PDFs). This technique takes a\nspectroscopic training set, and maps the photometric attributes, but not the\nredshifts, to a two dimensional surface by using a process of competitive\nlearning where neurons compete to more closely resemble the training data\nmultidimensional space. The key feature of a SOM is that it retains the\ntopology of the input set, revealing correlations between the attributes that\nare not easily identified. We test three different 2D topological mapping:\nrectangular, hexagonal, and spherical, by using data from the DEEP2 survey. We\nalso explore different implementations and boundary conditions on the map and\nalso introduce the idea of a random atlas where a large number of different\nmaps are created and their individual predictions are aggregated to produce a\nmore robust photometric redshift PDF. We also introduced a new metric, the\n$I$-score, which efficiently incorporates different metrics, making it easier\nto compare different results (from different parameters or different\nphotometric redshift codes). We find that by using a spherical topology mapping\nwe obtain a better representation of the underlying multidimensional topology,\nwhich provides more accurate results that are comparable to other,\nstate-of-the-art machine learning algorithms. Our results illustrate that\nunsupervised approaches have great potential for many astronomical problems,\nand in particular for the computation of photometric redshifts. \n\n"}
{"id": "1401.4092", "contents": "Title: Redrawing the Boundaries on Purchasing Data from Privacy-Sensitive\n  Individuals Abstract: We prove new positive and negative results concerning the existence of\ntruthful and individually rational mechanisms for purchasing private data from\nindividuals with unbounded and sensitive privacy preferences. We strengthen the\nimpossibility results of Ghosh and Roth (EC 2011) by extending it to a much\nwider class of privacy valuations. In particular, these include privacy\nvaluations that are based on ({\\epsilon}, {\\delta})-differentially private\nmechanisms for non-zero {\\delta}, ones where the privacy costs are measured in\na per-database manner (rather than taking the worst case), and ones that do not\ndepend on the payments made to players (which might not be observable to an\nadversary). To bypass this impossibility result, we study a natural special\nsetting where individuals have mono- tonic privacy valuations, which captures\ncommon contexts where certain values for private data are expected to lead to\nhigher valuations for privacy (e.g. having a particular disease). We give new\nmech- anisms that are individually rational for all players with monotonic\nprivacy valuations, truthful for all players whose privacy valuations are not\ntoo large, and accurate if there are not too many players with too-large\nprivacy valuations. We also prove matching lower bounds showing that in some\nrespects our mechanism cannot be improved significantly. \n\n"}
{"id": "1401.4786", "contents": "Title: Common Information based Markov Perfect Equilibria for Linear-Gaussian\n  Games with Asymmetric Information Abstract: We consider a class of two-player dynamic stochastic nonzero-sum games where\nthe state transition and observation equations are linear, and the primitive\nrandom variables are Gaussian. Each controller acquires possibly different\ndynamic information about the state process and the other controller's past\nactions and observations. This leads to a dynamic game of asymmetric\ninformation among the controllers. Building on our earlier work on finite games\nwith asymmetric information, we devise an algorithm to compute a Nash\nequilibrium by using the common information among the controllers. We call such\nequilibria common information based Markov perfect equilibria of the game,\nwhich can be viewed as a refinement of Nash equilibrium in games with\nasymmetric information. If the players' cost functions are quadratic, then we\nshow that under certain conditions a unique common information based Markov\nperfect equilibrium exists. Furthermore, this equilibrium can be computed by\nsolving a sequence of linear equations. We also show through an example that\nthere could be other Nash equilibria in a game of asymmetric information, not\ncorresponding to common information based Markov perfect equilibria. \n\n"}
{"id": "1401.7020", "contents": "Title: A Stochastic Quasi-Newton Method for Large-Scale Optimization Abstract: The question of how to incorporate curvature information in stochastic\napproximation methods is challenging. The direct application of classical\nquasi- Newton updating techniques for deterministic optimization leads to noisy\ncurvature estimates that have harmful effects on the robustness of the\niteration. In this paper, we propose a stochastic quasi-Newton method that is\nefficient, robust and scalable. It employs the classical BFGS update formula in\nits limited memory form, and is based on the observation that it is beneficial\nto collect curvature information pointwise, and at regular intervals, through\n(sub-sampled) Hessian-vector products. This technique differs from the\nclassical approach that would compute differences of gradients, and where\ncontrolling the quality of the curvature estimates can be difficult. We present\nnumerical results on problems arising in machine learning that suggest that the\nproposed method shows much promise. \n\n"}
{"id": "1402.2333", "contents": "Title: Modeling sequential data using higher-order relational features and\n  predictive training Abstract: Bi-linear feature learning models, like the gated autoencoder, were proposed\nas a way to model relationships between frames in a video. By minimizing\nreconstruction error of one frame, given the previous frame, these models learn\n\"mapping units\" that encode the transformations inherent in a sequence, and\nthereby learn to encode motion. In this work we extend bi-linear models by\nintroducing \"higher-order mapping units\" that allow us to encode\ntransformations between frames and transformations between transformations.\n  We show that this makes it possible to encode temporal structure that is more\ncomplex and longer-range than the structure captured within standard bi-linear\nmodels. We also show that a natural way to train the model is by replacing the\ncommonly used reconstruction objective with a prediction objective which forces\nthe model to correctly predict the evolution of the input multiple steps into\nthe future. Learning can be achieved by back-propagating the multi-step\nprediction through time. We test the model on various temporal prediction\ntasks, and show that higher-order mappings and predictive training both yield a\nsignificant improvement over bi-linear models in terms of prediction accuracy. \n\n"}
{"id": "1402.2667", "contents": "Title: On Zeroth-Order Stochastic Convex Optimization via Random Walks Abstract: We propose a method for zeroth order stochastic convex optimization that\nattains the suboptimality rate of $\\tilde{\\mathcal{O}}(n^{7}T^{-1/2})$ after\n$T$ queries for a convex bounded function $f:{\\mathbb R}^n\\to{\\mathbb R}$. The\nmethod is based on a random walk (the \\emph{Ball Walk}) on the epigraph of the\nfunction. The randomized approach circumvents the problem of gradient\nestimation, and appears to be less sensitive to noisy function evaluations\ncompared to noiseless zeroth order methods. \n\n"}
{"id": "1402.4419", "contents": "Title: Incremental Majorization-Minimization Optimization with Application to\n  Large-Scale Machine Learning Abstract: Majorization-minimization algorithms consist of successively minimizing a\nsequence of upper bounds of the objective function. These upper bounds are\ntight at the current estimate, and each iteration monotonically drives the\nobjective function downhill. Such a simple principle is widely applicable and\nhas been very popular in various scientific fields, especially in signal\nprocessing and statistics. In this paper, we propose an incremental\nmajorization-minimization scheme for minimizing a large sum of continuous\nfunctions, a problem of utmost importance in machine learning. We present\nconvergence guarantees for non-convex and convex optimization when the upper\nbounds approximate the objective up to a smooth error; we call such upper\nbounds \"first-order surrogate functions\". More precisely, we study asymptotic\nstationary point guarantees for non-convex problems, and for convex ones, we\nprovide convergence rates for the expected objective function value. We apply\nour scheme to composite optimization and obtain a new incremental proximal\ngradient algorithm with linear convergence rate for strongly convex functions.\nIn our experiments, we show that our method is competitive with the state of\nthe art for solving machine learning problems such as logistic regression when\nthe number of training samples is large enough, and we demonstrate its\nusefulness for sparse estimation with non-convex penalties. \n\n"}
{"id": "1402.5728", "contents": "Title: Machine Learning Methods in the Computational Biology of Cancer Abstract: The objectives of this \"perspective\" paper are to review some recent advances\nin sparse feature selection for regression and classification, as well as\ncompressed sensing, and to discuss how these might be used to develop tools to\nadvance personalized cancer therapy. As an illustration of the possibilities, a\nnew algorithm for sparse regression is presented, and is applied to predict the\ntime to tumor recurrence in ovarian cancer. A new algorithm for sparse feature\nselection in classification problems is presented, and its validation in\nendometrial cancer is briefly discussed. Some open problems are also presented. \n\n"}
{"id": "1402.6779", "contents": "Title: Resourceful Contextual Bandits Abstract: We study contextual bandits with ancillary constraints on resources, which\nare common in real-world applications such as choosing ads or dynamic pricing\nof items. We design the first algorithm for solving these problems that handles\nconstrained resources other than time, and improves over a trivial reduction to\nthe non-contextual case. We consider very general settings for both contextual\nbandits (arbitrary policy sets, e.g. Dudik et al. (UAI'11)) and bandits with\nresource constraints (bandits with knapsacks, Badanidiyuru et al. (FOCS'13)),\nand prove a regret guarantee with near-optimal statistical properties. \n\n"}
{"id": "1402.7344", "contents": "Title: An Incidence Geometry approach to Dictionary Learning Abstract: We study the Dictionary Learning (aka Sparse Coding) problem of obtaining a\nsparse representation of data points, by learning \\emph{dictionary vectors}\nupon which the data points can be written as sparse linear combinations. We\nview this problem from a geometry perspective as the spanning set of a subspace\narrangement, and focus on understanding the case when the underlying hypergraph\nof the subspace arrangement is specified. For this Fitted Dictionary Learning\nproblem, we completely characterize the combinatorics of the associated\nsubspace arrangements (i.e.\\ their underlying hypergraphs). Specifically, a\ncombinatorial rigidity-type theorem is proven for a type of geometric incidence\nsystem. The theorem characterizes the hypergraphs of subspace arrangements that\ngenerically yield (a) at least one dictionary (b) a locally unique dictionary\n(i.e.\\ at most a finite number of isolated dictionaries) of the specified size.\nWe are unaware of prior application of combinatorial rigidity techniques in the\nsetting of Dictionary Learning, or even in machine learning. We also provide a\nsystematic classification of problems related to Dictionary Learning together\nwith various algorithms, their assumptions and performance. \n\n"}
{"id": "1403.3881", "contents": "Title: Complexity of Equilibrium in Diffusion Games on Social Networks Abstract: In this paper, we consider the competitive diffusion game, and study the\nexistence of its pure-strategy Nash equilibrium when defined over general\nundirected networks. We first determine the set of pure-strategy Nash\nequilibria for two special but well-known classes of networks, namely the\nlattice and the hypercube. Characterizing the utility of the players in terms\nof graphical distances of their initial seed placements to other nodes in the\nnetwork, we show that in general networks the decision process on the existence\nof pure-strategy Nash equilibrium is an NP-hard problem. Following this, we\nprovide some necessary conditions for a given profile to be a Nash equilibrium.\nFurthermore, we study players' utilities in the competitive diffusion game over\nErdos-Renyi random graphs and show that as the size of the network grows, the\nutilities of the players are highly concentrated around their expectation, and\nare bounded below by some threshold based on the parameters of the network.\nFinally, we obtain a lower bound for the maximum social welfare of the game\nwith two players, and study sub-modularity of the players' utilities. \n\n"}
{"id": "1404.1592", "contents": "Title: The Power of Online Learning in Stochastic Network Optimization Abstract: In this paper, we investigate the power of online learning in stochastic\nnetwork optimization with unknown system statistics {\\it a priori}. We are\ninterested in understanding how information and learning can be efficiently\nincorporated into system control techniques, and what are the fundamental\nbenefits of doing so. We propose two \\emph{Online Learning-Aided Control}\ntechniques, $\\mathtt{OLAC}$ and $\\mathtt{OLAC2}$, that explicitly utilize the\npast system information in current system control via a learning procedure\ncalled \\emph{dual learning}. We prove strong performance guarantees of the\nproposed algorithms: $\\mathtt{OLAC}$ and $\\mathtt{OLAC2}$ achieve the\nnear-optimal $[O(\\epsilon), O([\\log(1/\\epsilon)]^2)]$ utility-delay tradeoff\nand $\\mathtt{OLAC2}$ possesses an $O(\\epsilon^{-2/3})$ convergence time.\n$\\mathtt{OLAC}$ and $\\mathtt{OLAC2}$ are probably the first algorithms that\nsimultaneously possess explicit near-optimal delay guarantee and sub-linear\nconvergence time. Simulation results also confirm the superior performance of\nthe proposed algorithms in practice. To the best of our knowledge, our attempt\nis the first to explicitly incorporate online learning into stochastic network\noptimization and to demonstrate its power in both theory and practice. \n\n"}
{"id": "1404.2655", "contents": "Title: Open problem: Tightness of maximum likelihood semidefinite relaxations Abstract: We have observed an interesting, yet unexplained, phenomenon: Semidefinite\nprogramming (SDP) based relaxations of maximum likelihood estimators (MLE) tend\nto be tight in recovery problems with noisy data, even when MLE cannot exactly\nrecover the ground truth. Several results establish tightness of SDP based\nrelaxations in the regime where exact recovery from MLE is possible. However,\nto the best of our knowledge, their tightness is not understood beyond this\nregime. As an illustrative example, we focus on the generalized Procrustes\nproblem. \n\n"}
{"id": "1404.3591", "contents": "Title: Hybrid Conditional Gradient - Smoothing Algorithms with Applications to\n  Sparse and Low Rank Regularization Abstract: We study a hybrid conditional gradient - smoothing algorithm (HCGS) for\nsolving composite convex optimization problems which contain several terms over\na bounded set. Examples of these include regularization problems with several\nnorms as penalties and a norm constraint. HCGS extends conditional gradient\nmethods to cases with multiple nonsmooth terms, in which standard conditional\ngradient methods may be difficult to apply. The HCGS algorithm borrows\ntechniques from smoothing proximal methods and requires first-order\ncomputations (subgradients and proximity operations). Unlike proximal methods,\nHCGS benefits from the advantages of conditional gradient methods, which render\nit more efficient on certain large scale optimization problems. We demonstrate\nthese advantages with simulations on two matrix optimization problems:\nregularization of matrices with combined $\\ell_1$ and trace norm penalties; and\na convex relaxation of sparse PCA. \n\n"}
{"id": "1405.4324", "contents": "Title: Active Semi-Supervised Learning Using Sampling Theory for Graph Signals Abstract: We consider the problem of offline, pool-based active semi-supervised\nlearning on graphs. This problem is important when the labeled data is scarce\nand expensive whereas unlabeled data is easily available. The data points are\nrepresented by the vertices of an undirected graph with the similarity between\nthem captured by the edge weights. Given a target number of nodes to label, the\ngoal is to choose those nodes that are most informative and then predict the\nunknown labels. We propose a novel framework for this problem based on our\nrecent results on sampling theory for graph signals. A graph signal is a\nreal-valued function defined on each node of the graph. A notion of frequency\nfor such signals can be defined using the spectrum of the graph Laplacian\nmatrix. The sampling theory for graph signals aims to extend the traditional\nNyquist-Shannon sampling theory by allowing us to identify the class of graph\nsignals that can be reconstructed from their values on a subset of vertices.\nThis approach allows us to define a criterion for active learning based on\nsampling set selection which aims at maximizing the frequency of the signals\nthat can be reconstructed from their samples on the set. Experiments show the\neffectiveness of our method. \n\n"}
{"id": "1405.5300", "contents": "Title: Fast Distributed Coordinate Descent for Non-Strongly Convex Losses Abstract: We propose an efficient distributed randomized coordinate descent method for\nminimizing regularized non-strongly convex loss functions. The method attains\nthe optimal $O(1/k^2)$ convergence rate, where $k$ is the iteration counter.\nThe core of the work is the theoretical study of stepsize parameters. We have\nimplemented the method on Archer - the largest supercomputer in the UK - and\nshow that the method is capable of solving a (synthetic) LASSO optimization\nproblem with 50 billion variables. \n\n"}
{"id": "1406.0533", "contents": "Title: Distributed bargaining in dyadic-exchange networks Abstract: This paper considers dyadic-exchange networks in which individual agents\nautonomously form coalitions of size two and agree on how to split a\ntransferable utility. Valid results for this game include stable (if agents\nhave no unilateral incentive to deviate), balanced (if matched agents obtain\nsimilar benefits from collaborating), or Nash (both stable and balanced)\noutcomes. We design provably-correct continuous-time algorithms to find each of\nthese classes of outcomes in a distributed way. Our algorithmic design to find\nNash bargaining solutions builds on the other two algorithms by having the\ndynamics for finding stable outcomes feeding into the one for finding balanced\nones. Our technical approach to establish convergence and robustness combines\nnotions and tools from optimization, graph theory, nonsmooth analysis, and\nLyapunov stability theory and provides a useful framework for further\nextensions. We illustrate our results in a wireless communication scenario\nwhere single-antenna devices have the possibility of working as 2-antenna\nvirtual devices to improve channel capacity. \n\n"}
{"id": "1406.1305", "contents": "Title: Faster Rates for the Frank-Wolfe Method over Strongly-Convex Sets Abstract: The Frank-Wolfe method (a.k.a. conditional gradient algorithm) for smooth\noptimization has regained much interest in recent years in the context of large\nscale optimization and machine learning. A key advantage of the method is that\nit avoids projections - the computational bottleneck in many applications -\nreplacing it by a linear optimization step. Despite this advantage, the known\nconvergence rates of the FW method fall behind standard first order methods for\nmost settings of interest. It is an active line of research to derive faster\nlinear optimization-based algorithms for various settings of convex\noptimization.\n  In this paper we consider the special case of optimization over strongly\nconvex sets, for which we prove that the vanila FW method converges at a rate\nof $\\frac{1}{t^2}$. This gives a quadratic improvement in convergence rate\ncompared to the general case, in which convergence is of the order\n$\\frac{1}{t}$, and known to be tight. We show that various balls induced by\n$\\ell_p$ norms, Schatten norms and group norms are strongly convex on one hand\nand on the other hand, linear optimization over these sets is straightforward\nand admits a closed-form solution. We further show how several previous\nfast-rate results for the FW method follow easily from our analysis. \n\n"}
{"id": "1406.4248", "contents": "Title: On values of repeated games with signals Abstract: We study the existence of different notions of value in two-person zero-sum\nrepeated games where the state evolves and players receive signals. We provide\nsome examples showing that the limsup value (and the uniform value) may not\nexist in general. Then we show the existence of the value for any Borel payoff\nfunction if the players observe a public signal including the actions played.\nWe also prove two other positive results without assumptions on the signaling\nstructure: the existence of the $\\sup$ value in any game and the existence of\nthe uniform value in recursive games with nonnegative payoffs. \n\n"}
{"id": "1406.5295", "contents": "Title: Rows vs Columns for Linear Systems of Equations - Randomized Kaczmarz or\n  Coordinate Descent? Abstract: This paper is about randomized iterative algorithms for solving a linear\nsystem of equations $X \\beta = y$ in different settings. Recent interest in the\ntopic was reignited when Strohmer and Vershynin (2009) proved the linear\nconvergence rate of a Randomized Kaczmarz (RK) algorithm that works on the rows\nof $X$ (data points). Following that, Leventhal and Lewis (2010) proved the\nlinear convergence of a Randomized Coordinate Descent (RCD) algorithm that\nworks on the columns of $X$ (features). The aim of this paper is to simplify\nour understanding of these two algorithms, establish the direct relationships\nbetween them (though RK is often compared to Stochastic Gradient Descent), and\nexamine the algorithmic commonalities or tradeoffs involved with working on\nrows or columns. We also discuss Kernel Ridge Regression and present a\nKaczmarz-style algorithm that works on data points and having the advantage of\nsolving the problem without ever storing or forming the Gram matrix, one of the\nrecognized problems encountered when scaling kernelized methods. \n\n"}
{"id": "1406.5298", "contents": "Title: Semi-Supervised Learning with Deep Generative Models Abstract: The ever-increasing size of modern data sets combined with the difficulty of\nobtaining label information has made semi-supervised learning one of the\nproblems of significant practical importance in modern data analysis. We\nrevisit the approach to semi-supervised learning with generative models and\ndevelop new models that allow for effective generalisation from small labelled\ndata sets to large unlabelled ones. Generative approaches have thus far been\neither inflexible, inefficient or non-scalable. We show that deep generative\nmodels and approximate Bayesian inference exploiting recent advances in\nvariational methods can be used to provide significant improvements, making\ngenerative approaches highly competitive for semi-supervised learning. \n\n"}
{"id": "1407.0753", "contents": "Title: Global convergence of splitting methods for nonconvex composite\n  optimization Abstract: We consider the problem of minimizing the sum of a smooth function $h$ with a\nbounded Hessian, and a nonsmooth function. We assume that the latter function\nis a composition of a proper closed function $P$ and a surjective linear map\n$\\cal M$, with the proximal mappings of $\\tau P$, $\\tau > 0$, simple to\ncompute. This problem is nonconvex in general and encompasses many important\napplications in engineering and machine learning. In this paper, we examined\ntwo types of splitting methods for solving this nonconvex optimization problem:\nalternating direction method of multipliers and proximal gradient algorithm.\nFor the direct adaptation of the alternating direction method of multipliers,\nwe show that, if the penalty parameter is chosen sufficiently large and the\nsequence generated has a cluster point, then it gives a stationary point of the\nnonconvex problem. We also establish convergence of the whole sequence under an\nadditional assumption that the functions $h$ and $P$ are semi-algebraic.\nFurthermore, we give simple sufficient conditions to guarantee boundedness of\nthe sequence generated. These conditions can be satisfied for a wide range of\napplications including the least squares problem with the $\\ell_{1/2}$\nregularization. Finally, when $\\cal M$ is the identity so that the proximal\ngradient algorithm can be efficiently applied, we show that any cluster point\nis stationary under a slightly more flexible constant step-size rule than what\nis known in the literature for a nonconvex $h$. \n\n"}
{"id": "1407.2576", "contents": "Title: The size of the core in assignment markets Abstract: Assignment markets involve matching with transfers, as in labor markets and\nhousing markets. We consider a two-sided assignment market with agent types and\nstochastic structure similar to models used in empirical studies, and\ncharacterize the size of the core in such markets. Each agent has a randomly\ndrawn productivity with respect to each type of agent on the other side. The\nvalue generated from a match between a pair of agents is the sum of the two\nproductivity terms, each of which depends only on the type but not the identity\nof one of the agents, and a third deterministic term driven by the pair of\ntypes. We allow the number of agents to grow, keeping the number of agent types\nfixed. Let $n$ be the number of agents and $K$ be the number of types on the\nside of the market with more types. We find, under reasonable assumptions, that\nthe relative variation in utility per agent over core outcomes is bounded as\n$O^*(1/n^{1/K})$, where polylogarithmic factors have been suppressed. Further,\nwe show that this bound is tight in worst case. We also provide a tighter bound\nunder more restrictive assumptions. Our results provide partial justification\nfor the typical assumption of a unique core outcome in empirical studies. \n\n"}
{"id": "1407.5373", "contents": "Title: On the Complexity of Dynamic Mechanism Design Abstract: We introduce a dynamic mechanism design problem in which the designer wants\nto offer for sale an item to an agent, and another item to the same agent at\nsome point in the future. The agent's joint distribution of valuations for the\ntwo items is known, and the agent knows the valuation for the current item (but\nnot for the one in the future). The designer seeks to maximize expected\nrevenue, and the auction must be deterministic, truthful, and ex post\nindividually rational. The optimum mechanism involves a protocol whereby the\nseller elicits the buyer's current valuation, and based on the bid makes two\ntake-it-or-leave-it offers, one for now and one for the future. We show that\nfinding the optimum deterministic mechanism in this situation - arguably the\nsimplest meaningful dynamic mechanism design problem imaginable - is NP-hard.\nWe also prove several positive results, among them a polynomial linear\nprogramming-based algorithm for the optimum randomized auction (even for many\nbidders and periods), and we show strong separations in revenue between\nnon-adaptive, adaptive, and randomized auctions, even when the valuations in\nthe two periods are uncorrelated. Finally, for the same problem in an\nenvironment in which contracts cannot be enforced, and thus perfection of\nequilibrium is necessary, we show that the optimum randomized mechanism\nrequires multiple rounds of cheap talk-like interactions. \n\n"}
{"id": "1408.1211", "contents": "Title: A Unifying Hierarchy of Valuations with Complements and Substitutes Abstract: We introduce a new hierarchy over monotone set functions, that we refer to as\n$\\mathcal{MPH}$ (Maximum over Positive Hypergraphs). Levels of the hierarchy\ncorrespond to the degree of complementarity in a given function. The highest\nlevel of the hierarchy, $\\mathcal{MPH}$-$m$ (where $m$ is the total number of\nitems) captures all monotone functions. The lowest level, $\\mathcal{MPH}$-$1$,\ncaptures all monotone submodular functions, and more generally, the class of\nfunctions known as $\\mathcal{XOS}$. Every monotone function that has a positive\nhypergraph representation of rank $k$ (in the sense defined by Abraham,\nBabaioff, Dughmi and Roughgarden [EC 2012]) is in $\\mathcal{MPH}$-$k$. Every\nmonotone function that has supermodular degree $k$ (in the sense defined by\nFeige and Izsak [ITCS 2013]) is in $\\mathcal{MPH}$-$(k+1)$. In both cases, the\nconverse direction does not hold, even in an approximate sense. We present\nadditional results that demonstrate the expressiveness power of\n$\\mathcal{MPH}$-$k$.\n  One can obtain good approximation ratios for some natural optimization\nproblems, provided that functions are required to lie in low levels of the\n$\\mathcal{MPH}$ hierarchy. We present two such applications. One shows that the\nmaximum welfare problem can be approximated within a ratio of $k+1$ if all\nplayers hold valuation functions in $\\mathcal{MPH}$-$k$. The other is an upper\nbound of $2k$ on the price of anarchy of simultaneous first price auctions.\n  Being in $\\mathcal{MPH}$-$k$ can be shown to involve two requirements -- one\nis monotonicity and the other is a certain requirement that we refer to as\n$\\mathcal{PLE}$ (Positive Lower Envelope). Removing the monotonicity\nrequirement, one obtains the $\\mathcal{PLE}$ hierarchy over all non-negative\nset functions (whether monotone or not), which can be fertile ground for\nfurther research. \n\n"}
{"id": "1408.3467", "contents": "Title: Evaluating Visual Properties via Robust HodgeRank Abstract: Nowadays, how to effectively evaluate visual properties has become a popular\ntopic for fine-grained visual comprehension. In this paper we study the problem\nof how to estimate such visual properties from a ranking perspective with the\nhelp of the annotators from online crowdsourcing platforms. The main challenges\nof our task are two-fold. On one hand, the annotations often contain\ncontaminated information, where a small fraction of label flips might ruin the\nglobal ranking of the whole dataset. On the other hand, considering the large\ndata capacity, the annotations are often far from being complete. What is\nworse, there might even exist imbalanced annotations where a small subset of\nsamples are frequently annotated. Facing such challenges, we propose a robust\nranking framework based on the principle of Hodge decomposition of imbalanced\nand incomplete ranking data. According to the HodgeRank theory, we find that\nthe major source of the contamination comes from the cyclic ranking component\nof the Hodge decomposition. This leads us to an outlier detection formulation\nas sparse approximations of the cyclic ranking projection. Taking a step\nfurther, it facilitates a novel outlier detection model as Huber's LASSO in\nrobust statistics. Moreover, simple yet scalable algorithms are developed based\non Linearized Bregman Iteration to achieve an even less biased estimator.\nStatistical consistency of outlier detection is established in both cases under\nnearly the same conditions. Our studies are supported by experiments with both\nsimulated examples and real-world data. The proposed framework provides us a\npromising tool for robust ranking with large scale crowdsourcing data arising\nfrom computer vision. \n\n"}
{"id": "1408.3693", "contents": "Title: Stability and Performance Limits of Adaptive Primal-Dual Networks Abstract: This work studies distributed primal-dual strategies for adaptation and\nlearning over networks from streaming data. Two first-order methods are\nconsidered based on the Arrow-Hurwicz (AH) and augmented Lagrangian (AL)\ntechniques. Several revealing results are discovered in relation to the\nperformance and stability of these strategies when employed over adaptive\nnetworks. The conclusions establish that the advantages that these methods have\nfor deterministic optimization problems do not necessarily carry over to\nstochastic optimization problems. It is found that they have narrower stability\nranges and worse steady-state mean-square-error performance than primal methods\nof the consensus and diffusion type. It is also found that the AH technique can\nbecome unstable under a partial observation model, while the other techniques\nare able to recover the unknown under this scenario. A method to enhance the\nperformance of AL strategies is proposed by tying the selection of the\nstep-size to their regularization parameter. It is shown that this method\nallows the AL algorithm to approach the performance of consensus and diffusion\nstrategies but that it remains less stable than these other strategies. \n\n"}
{"id": "1409.0272", "contents": "Title: Multi-task Sparse Structure Learning Abstract: Multi-task learning (MTL) aims to improve generalization performance by\nlearning multiple related tasks simultaneously. While sometimes the underlying\ntask relationship structure is known, often the structure needs to be estimated\nfrom data at hand. In this paper, we present a novel family of models for MTL,\napplicable to regression and classification problems, capable of learning the\nstructure of task relationships. In particular, we consider a joint estimation\nproblem of the task relationship structure and the individual task parameters,\nwhich is solved using alternating minimization. The task relationship structure\nlearning component builds on recent advances in structure learning of Gaussian\ngraphical models based on sparse estimators of the precision (inverse\ncovariance) matrix. We illustrate the effectiveness of the proposed model on a\nvariety of synthetic and benchmark datasets for regression and classification.\nWe also consider the problem of combining climate model outputs for better\nprojections of future climate, with focus on temperature in South America, and\nshow that the proposed model outperforms several existing methods for the\nproblem. \n\n"}
{"id": "1409.2045", "contents": "Title: Global Convergence of Online Limited Memory BFGS Abstract: Global convergence of an online (stochastic) limited memory version of the\nBroyden-Fletcher- Goldfarb-Shanno (BFGS) quasi-Newton method for solving\noptimization problems with stochastic objectives that arise in large scale\nmachine learning is established. Lower and upper bounds on the Hessian\neigenvalues of the sample functions are shown to suffice to guarantee that the\ncurvature approximation matrices have bounded determinants and traces, which,\nin turn, permits establishing convergence to optimal arguments with probability\n1. Numerical experiments on support vector machines with synthetic data\nshowcase reductions in convergence time relative to stochastic gradient descent\nalgorithms as well as reductions in storage and computation relative to other\nonline quasi-Newton methods. Experimental evaluation on a search engine\nadvertising problem corroborates that these advantages also manifest in\npractical applications. \n\n"}
{"id": "1409.5718", "contents": "Title: Convolutional Neural Networks over Tree Structures for Programming\n  Language Processing Abstract: Programming language processing (similar to natural language processing) is a\nhot research topic in the field of software engineering; it has also aroused\ngrowing interest in the artificial intelligence community. However, different\nfrom a natural language sentence, a program contains rich, explicit, and\ncomplicated structural information. Hence, traditional NLP models may be\ninappropriate for programs. In this paper, we propose a novel tree-based\nconvolutional neural network (TBCNN) for programming language processing, in\nwhich a convolution kernel is designed over programs' abstract syntax trees to\ncapture structural information. TBCNN is a generic architecture for programming\nlanguage processing; our experiments show its effectiveness in two different\nprogram analysis tasks: classifying programs according to functionality, and\ndetecting code snippets of certain patterns. TBCNN outperforms baseline\nmethods, including several neural models for NLP. \n\n"}
{"id": "1409.6111", "contents": "Title: Distributed Clustering and Learning Over Networks Abstract: Distributed processing over networks relies on in-network processing and\ncooperation among neighboring agents. Cooperation is beneficial when agents\nshare a common objective. However, in many applications agents may belong to\ndifferent clusters that pursue different objectives. Then, indiscriminate\ncooperation will lead to undesired results. In this work, we propose an\nadaptive clustering and learning scheme that allows agents to learn which\nneighbors they should cooperate with and which other neighbors they should\nignore. In doing so, the resulting algorithm enables the agents to identify\ntheir clusters and to attain improved learning and estimation accuracy over\nnetworks. We carry out a detailed mean-square analysis and assess the error\nprobabilities of Types I and II, i.e., false alarm and mis-detection, for the\nclustering mechanism. Among other results, we establish that these\nprobabilities decay exponentially with the step-sizes so that the probability\nof correct clustering can be made arbitrarily close to one. \n\n"}
{"id": "1410.3688", "contents": "Title: A Game Theoretic Model for Network Virus Protection Abstract: The network virus propagation is influenced by various factors, and some of\nthem are neglected in most of the existed models in the literature. In this\npaper, we study the network virus propagation based on the the epidemiological\nviewpoint. We assume that nodes can be equipped with protection against virus\nand the security of a node depends not only on his protection strategy but also\nby those chosen by other nodes in the network. A crucial aspect is whether\nowners of device, e.g., either smartphones, machines or tablets, are willing to\nbe equipped to protect themselves or to take the risk to be contaminated in\norder to avoid the payment for a new antivirus. We model the interaction\nbetween nodes as a non-cooperative games where the node has two strategies:\neither to update the antivirus or not. To this aim, we provide a full\ncharacterization of the equilibria of the game and we investigate the impact of\nthe price of protection on the equilibrium as well as the efficiency of the\nprotection at equilibrium. Further we consider more realistic scenarios in\nwhich the dynamic of sources that disseminate the virus, evolves as function of\nthe popularity of virus. In this work, the interest in the virus by sources\nevolves under the Influence Linear Threshold (HILT) model. \n\n"}
{"id": "1410.4828", "contents": "Title: Generalized Conditional Gradient for Sparse Estimation Abstract: Structured sparsity is an important modeling tool that expands the\napplicability of convex formulations for data analysis, however it also creates\nsignificant challenges for efficient algorithm design. In this paper we\ninvestigate the generalized conditional gradient (GCG) algorithm for solving\nstructured sparse optimization problems---demonstrating that, with some\nenhancements, it can provide a more efficient alternative to current state of\nthe art approaches. After providing a comprehensive overview of the convergence\nproperties of GCG, we develop efficient methods for evaluating polar operators,\na subroutine that is required in each GCG iteration. In particular, we show how\nthe polar operator can be efficiently evaluated in two important scenarios:\ndictionary learning and structured sparse estimation. A further improvement is\nachieved by interleaving GCG with fixed-rank local subspace optimization. A\nseries of experiments on matrix completion, multi-class classification,\nmulti-view dictionary learning and overlapping group lasso shows that the\nproposed method can significantly reduce the training cost of current\nalternatives. \n\n"}
{"id": "1410.6387", "contents": "Title: On Lower and Upper Bounds in Smooth Strongly Convex Optimization - A\n  Unified Approach via Linear Iterative Methods Abstract: In this thesis we develop a novel framework to study smooth and strongly\nconvex optimization algorithms, both deterministic and stochastic. Focusing on\nquadratic functions we are able to examine optimization algorithms as a\nrecursive application of linear operators. This, in turn, reveals a powerful\nconnection between a class of optimization algorithms and the analytic theory\nof polynomials whereby new lower and upper bounds are derived. In particular,\nwe present a new and natural derivation of Nesterov's well-known Accelerated\nGradient Descent method by employing simple 'economic' polynomials. This rather\nnatural interpretation of AGD contrasts with earlier ones which lacked a\nsimple, yet solid, motivation. Lastly, whereas existing lower bounds are only\nvalid when the dimensionality scales with the number of iterations, our lower\nbound holds in the natural regime where the dimensionality is fixed. \n\n"}
{"id": "1410.7472", "contents": "Title: A note on two notions of compliance Abstract: We establish a relation between two models of contracts: binary session\ntypes, and a model based on event structures and game-theoretic notions. In\nparticular, we show that compliance in session types corresponds to the\nexistence of certain winning strategies in game-based contracts. \n\n"}
{"id": "1411.0972", "contents": "Title: Convex Optimization for Big Data Abstract: This article reviews recent advances in convex optimization algorithms for\nBig Data, which aim to reduce the computational, storage, and communications\nbottlenecks. We provide an overview of this emerging field, describe\ncontemporary approximation techniques like first-order methods and\nrandomization for scalability, and survey the important role of parallel and\ndistributed computation. The new Big Data algorithms are based on surprisingly\nsimple principles and attain staggering accelerations even on classical\nproblems. \n\n"}
{"id": "1411.1158", "contents": "Title: On the Complexity of Learning with Kernels Abstract: A well-recognized limitation of kernel learning is the requirement to handle\na kernel matrix, whose size is quadratic in the number of training examples.\nMany methods have been proposed to reduce this computational cost, mostly by\nusing a subset of the kernel matrix entries, or some form of low-rank matrix\napproximation, or a random projection method. In this paper, we study lower\nbounds on the error attainable by such methods as a function of the number of\nentries observed in the kernel matrix or the rank of an approximate kernel\nmatrix. We show that there are kernel learning problems where no such method\nwill lead to non-trivial computational savings. Our results also quantify how\nthe problem difficulty depends on parameters such as the nature of the loss\nfunction, the regularization parameter, the norm of the desired predictor, and\nthe kernel matrix rank. Our results also suggest cases where more efficient\nkernel learning might be possible. \n\n"}
{"id": "1411.5873", "contents": "Title: Randomized Dual Coordinate Ascent with Arbitrary Sampling Abstract: We study the problem of minimizing the average of a large number of smooth\nconvex functions penalized with a strongly convex regularizer. We propose and\nanalyze a novel primal-dual method (Quartz) which at every iteration samples\nand updates a random subset of the dual variables, chosen according to an\narbitrary distribution. In contrast to typical analysis, we directly bound the\ndecrease of the primal-dual error (in expectation), without the need to first\nanalyze the dual error. Depending on the choice of the sampling, we obtain\nefficient serial, parallel and distributed variants of the method. In the\nserial case, our bounds match the best known bounds for SDCA (both with uniform\nand importance sampling). With standard mini-batching, our bounds predict\ninitial data-independent speedup as well as additional data-driven speedup\nwhich depends on spectral and sparsity properties of the data. We calculate\ntheoretical speedup factors and find that they are excellent predictors of\nactual speedup in practice. Moreover, we illustrate that it is possible to\ndesign an efficient mini-batch importance sampling. The distributed variant of\nQuartz is the first distributed SDCA-like method with an analysis for\nnon-separable data. \n\n"}
{"id": "1411.6243", "contents": "Title: Structure Regularization for Structured Prediction: Theories and\n  Experiments Abstract: While there are many studies on weight regularization, the study on structure\nregularization is rare. Many existing systems on structured prediction focus on\nincreasing the level of structural dependencies within the model. However, this\ntrend could have been misdirected, because our study suggests that complex\nstructures are actually harmful to generalization ability in structured\nprediction. To control structure-based overfitting, we propose a structure\nregularization framework via \\emph{structure decomposition}, which decomposes\ntraining samples into mini-samples with simpler structures, deriving a model\nwith better generalization power. We show both theoretically and empirically\nthat structure regularization can effectively control overfitting risk and lead\nto better accuracy. As a by-product, the proposed method can also substantially\naccelerate the training speed. The method and the theoretical results can apply\nto general graphical models with arbitrary structures. Experiments on\nwell-known tasks demonstrate that our method can easily beat the benchmark\nsystems on those highly-competitive tasks, achieving state-of-the-art\naccuracies yet with substantially faster training speed. \n\n"}
{"id": "1411.7200", "contents": "Title: Localized Complexities for Transductive Learning Abstract: We show two novel concentration inequalities for suprema of empirical\nprocesses when sampling without replacement, which both take the variance of\nthe functions into account. While these inequalities may potentially have broad\napplications in learning theory in general, we exemplify their significance by\nstudying the transductive setting of learning theory. For which we provide the\nfirst excess risk bounds based on the localized complexity of the hypothesis\nclass, which can yield fast rates of convergence also in the transductive\nlearning setting. We give a preliminary analysis of the localized complexities\nfor the prominent case of kernel classes. \n\n"}
{"id": "1411.7245", "contents": "Title: Heuristics for Exact Nonnegative Matrix Factorization Abstract: The exact nonnegative matrix factorization (exact NMF) problem is the\nfollowing: given an $m$-by-$n$ nonnegative matrix $X$ and a factorization rank\n$r$, find, if possible, an $m$-by-$r$ nonnegative matrix $W$ and an $r$-by-$n$\nnonnegative matrix $H$ such that $X = WH$. In this paper, we propose two\nheuristics for exact NMF, one inspired from simulated annealing and the other\nfrom the greedy randomized adaptive search procedure. We show that these two\nheuristics are able to compute exact nonnegative factorizations for several\nclasses of nonnegative matrices (namely, linear Euclidean distance matrices,\nslack matrices, unique-disjointness matrices, and randomly generated matrices)\nand as such demonstrate their superiority over standard multi-start strategies.\nWe also consider a hybridization between these two heuristics that allows us to\ncombine the advantages of both methods. Finally, we discuss the use of these\nheuristics to gain insight on the behavior of the nonnegative rank, i.e., the\nminimum factorization rank such that an exact NMF exists. In particular, we\ndisprove a conjecture on the nonnegative rank of a Kronecker product, propose a\nnew upper bound on the extension complexity of generic $n$-gons and conjecture\nthe exact value of (i) the extension complexity of regular $n$-gons and (ii)\nthe nonnegative rank of a submatrix of the slack matrix of the correlation\npolytope. \n\n"}
{"id": "1412.0180", "contents": "Title: Empirical Q-Value Iteration Abstract: We propose a new simple and natural algorithm for learning the optimal\nQ-value function of a discounted-cost Markov Decision Process (MDP) when the\ntransition kernels are unknown. Unlike the classical learning algorithms for\nMDPs, such as Q-learning and actor-critic algorithms, this algorithm doesn't\ndepend on a stochastic approximation-based method. We show that our algorithm,\nwhich we call the empirical Q-value iteration (EQVI) algorithm, converges to\nthe optimal Q-value function. We also give a rate of convergence or a\nnon-asymptotic sample complexity bound, and also show that an asynchronous (or\nonline) version of the algorithm will also work. Preliminary experimental\nresults suggest a faster rate of convergence to a ball park estimate for our\nalgorithm compared to stochastic approximation-based algorithms. \n\n"}
{"id": "1412.6452", "contents": "Title: Algorithmic Robustness for Learning via $(\\epsilon, \\gamma, \\tau)$-Good\n  Similarity Functions Abstract: The notion of metric plays a key role in machine learning problems such as\nclassification, clustering or ranking. However, it is worth noting that there\nis a severe lack of theoretical guarantees that can be expected on the\ngeneralization capacity of the classifier associated to a given metric. The\ntheoretical framework of $(\\epsilon, \\gamma, \\tau)$-good similarity functions\n(Balcan et al., 2008) has been one of the first attempts to draw a link between\nthe properties of a similarity function and those of a linear classifier making\nuse of it. In this paper, we extend and complete this theory by providing a new\ngeneralization bound for the associated classifier based on the algorithmic\nrobustness framework. \n\n"}
{"id": "1412.6493", "contents": "Title: A la Carte - Learning Fast Kernels Abstract: Kernel methods have great promise for learning rich statistical\nrepresentations of large modern datasets. However, compared to neural networks,\nkernel methods have been perceived as lacking in scalability and flexibility.\nWe introduce a family of fast, flexible, lightly parametrized and general\npurpose kernel learning methods, derived from Fastfood basis function\nexpansions. We provide mechanisms to learn the properties of groups of spectral\nfrequencies in these expansions, which require only O(mlogd) time and O(m)\nmemory, for m basis functions and d input dimensions. We show that the proposed\nmethods can learn a wide class of kernels, outperforming the alternatives in\naccuracy, speed, and memory consumption. \n\n"}
{"id": "1412.6630", "contents": "Title: Neural Network Regularization via Robust Weight Factorization Abstract: Regularization is essential when training large neural networks. As deep\nneural networks can be mathematically interpreted as universal function\napproximators, they are effective at memorizing sampling noise in the training\ndata. This results in poor generalization to unseen data. Therefore, it is no\nsurprise that a new regularization technique, Dropout, was partially\nresponsible for the now-ubiquitous winning entry to ImageNet 2012 by the\nUniversity of Toronto. Currently, Dropout (and related methods such as\nDropConnect) are the most effective means of regularizing large neural\nnetworks. These amount to efficiently visiting a large number of related models\nat training time, while aggregating them to a single predictor at test time.\nThe proposed FaMe model aims to apply a similar strategy, yet learns a\nfactorization of each weight matrix such that the factors are robust to noise. \n\n"}
{"id": "1412.7938", "contents": "Title: Adjusting Leverage Scores by Row Weighting: A Practical Approach to\n  Coherent Matrix Completion Abstract: Low-rank matrix completion is an important problem with extensive real-world\napplications. When observations are uniformly sampled from the underlying\nmatrix entries, existing methods all require the matrix to be incoherent. This\npaper provides the first working method for coherent matrix completion under\nthe standard uniform sampling model. Our approach is based on the weighted\nnuclear norm minimization idea proposed in several recent work, and our key\ncontribution is a practical method to compute the weighting matrices so that\nthe leverage scores become more uniform after weighting. Under suitable\nconditions, we are able to derive theoretical results, showing the\neffectiveness of our approach. Experiments on synthetic data show that our\napproach recovers highly coherent matrices with high precision, whereas the\nstandard unweighted method fails even on noise-free data. \n\n"}
{"id": "1412.8060", "contents": "Title: Coordinate Descent with Arbitrary Sampling I: Algorithms and Complexity Abstract: We study the problem of minimizing the sum of a smooth convex function and a\nconvex block-separable regularizer and propose a new randomized coordinate\ndescent method, which we call ALPHA. Our method at every iteration updates a\nrandom subset of coordinates, following an arbitrary distribution. No\ncoordinate descent methods capable to handle an arbitrary sampling have been\nstudied in the literature before for this problem. ALPHA is a remarkably\nflexible algorithm: in special cases, it reduces to deterministic and\nrandomized methods such as gradient descent, coordinate descent, parallel\ncoordinate descent and distributed coordinate descent -- both in nonaccelerated\nand accelerated variants. The variants with arbitrary (or importance) sampling\nare new. We provide a complexity analysis of ALPHA, from which we deduce as a\ndirect corollary complexity bounds for its many variants, all matching or\nimproving best known bounds. \n\n"}
{"id": "1412.8063", "contents": "Title: Coordinate Descent with Arbitrary Sampling II: Expected Separable\n  Overapproximation Abstract: The design and complexity analysis of randomized coordinate descent methods,\nand in particular of variants which update a random subset (sampling) of\ncoordinates in each iteration, depends on the notion of expected separable\noverapproximation (ESO). This refers to an inequality involving the objective\nfunction and the sampling, capturing in a compact way certain smoothness\nproperties of the function in a random subspace spanned by the sampled\ncoordinates. ESO inequalities were previously established for special classes\nof samplings only, almost invariably for uniform samplings. In this paper we\ndevelop a systematic technique for deriving these inequalities for a large\nclass of functions and for arbitrary samplings. We demonstrate that one can\nrecover existing ESO results using our general approach, which is based on the\nstudy of eigenvalues associated with samplings and the data describing the\nfunction. \n\n"}
{"id": "1412.8493", "contents": "Title: An ADMM algorithm for solving a proximal bound-constrained quadratic\n  program Abstract: We consider a proximal operator given by a quadratic function subject to\nbound constraints and give an optimization algorithm using the alternating\ndirection method of multipliers (ADMM). The algorithm is particularly efficient\nto solve a collection of proximal operators that share the same quadratic form,\nor if the quadratic program is the relaxation of a binary quadratic problem. \n\n"}
{"id": "1412.8501", "contents": "Title: Formation Games of Reliable Networks Abstract: We establish a network formation game for the Internet's Autonomous System\n(AS) interconnection topology. The game includes different types of players,\naccounting for the heterogeneity of ASs in the Internet. We incorporate\nreliability considerations in the player's utility function, and analyze static\nproperties of the game as well as its dynamic evolution. We provide dynamic\nanalysis of its topological quantities, and explain the prevalence of some\n\"network motifs\" in the Internet graph. We assess our predictions with\nreal-world data. \n\n"}
{"id": "1412.8736", "contents": "Title: Sharing Information Without Regret in Managed Stochastic Games Abstract: This paper considers information sharing in a multi-player repeated game.\nEvery round, each player observes a subset of components of a random vector and\nthen takes a control action. The utility earned by each player depends on the\nfull random vector and on the actions of others. An example is a game where\ndifferent rewards are placed over multiple locations, each player only knows\nthe rewards in a subset of the locations, and players compete to collect the\nrewards. Sharing information can help others, but can also increase competition\nfor desirable locations. Standard Nash equilibrium and correlated equilibrium\nconcepts are inadequate in this scenario. Instead, this paper develops an\nalgorithm where, every round, all players pass their information and intended\nactions to a game manager. The manager provides suggested actions for each\nplayer that, if taken, maximize a concave function of average utilities subject\nto the constraint that each player gets an average utility no worse than it\nwould get without sharing. The algorithm acts online using information given at\neach round and does not require a specific model of random events or player\nactions. Thus, the analytical results of this paper apply in non-ergodic\nsituations with any sequence of actions taken by human players. \n\n"}
{"id": "1501.00263", "contents": "Title: Communication-Efficient Distributed Optimization of Self-Concordant\n  Empirical Loss Abstract: We consider distributed convex optimization problems originated from sample\naverage approximation of stochastic optimization, or empirical risk\nminimization in machine learning. We assume that each machine in the\ndistributed computing system has access to a local empirical loss function,\nconstructed with i.i.d. data sampled from a common distribution. We propose a\ncommunication-efficient distributed algorithm to minimize the overall empirical\nloss, which is the average of the local empirical losses. The algorithm is\nbased on an inexact damped Newton method, where the inexact Newton steps are\ncomputed by a distributed preconditioned conjugate gradient method. We analyze\nits iteration complexity and communication efficiency for minimizing\nself-concordant empirical loss functions, and discuss the results for\ndistributed ridge regression, logistic regression and binary classification\nwith a smoothed hinge loss. In a standard setting for supervised learning, the\nrequired number of communication rounds of the algorithm does not increase with\nthe sample size, and only grows slowly with the number of machines. \n\n"}
{"id": "1501.03227", "contents": "Title: Using Riemannian geometry for SSVEP-based Brain Computer Interface Abstract: Riemannian geometry has been applied to Brain Computer Interface (BCI) for\nbrain signals classification yielding promising results. Studying\nelectroencephalographic (EEG) signals from their associated covariance matrices\nallows a mitigation of common sources of variability (electronic, electrical,\nbiological) by constructing a representation which is invariant to these\nperturbations. While working in Euclidean space with covariance matrices is\nknown to be error-prone, one might take advantage of algorithmic advances in\ninformation geometry and matrix manifold to implement methods for Symmetric\nPositive-Definite (SPD) matrices. This paper proposes a comprehensive review of\nthe actual tools of information geometry and how they could be applied on\ncovariance matrices of EEG. In practice, covariance matrices should be\nestimated, thus a thorough study of all estimators is conducted on real EEG\ndataset. As a main contribution, this paper proposes an online implementation\nof a classifier in the Riemannian space and its subsequent assessment in\nSteady-State Visually Evoked Potential (SSVEP) experimentations. \n\n"}
{"id": "1502.00182", "contents": "Title: High Dimensional Low Rank plus Sparse Matrix Decomposition Abstract: This paper is concerned with the problem of low rank plus sparse matrix\ndecomposition for big data. Conventional algorithms for matrix decomposition\nuse the entire data to extract the low-rank and sparse components, and are\nbased on optimization problems with complexity that scales with the dimension\nof the data, which limits their scalability. Furthermore, existing randomized\napproaches mostly rely on uniform random sampling, which is quite inefficient\nfor many real world data matrices that exhibit additional structures (e.g.\nclustering). In this paper, a scalable subspace-pursuit approach that\ntransforms the decomposition problem to a subspace learning problem is\nproposed. The decomposition is carried out using a small data sketch formed\nfrom sampled columns/rows. Even when the data is sampled uniformly at random,\nit is shown that the sufficient number of sampled columns/rows is roughly\nO(r\\mu), where \\mu is the coherency parameter and r the rank of the low rank\ncomponent. In addition, adaptive sampling algorithms are proposed to address\nthe problem of column/row sampling from structured data. We provide an analysis\nof the proposed method with adaptive sampling and show that adaptive sampling\nmakes the required number of sampled columns/rows invariant to the distribution\nof the data. The proposed approach is amenable to online implementation and an\nonline scheme is proposed. \n\n"}
{"id": "1502.00598", "contents": "Title: Lock in Feedback in Sequential Experiments Abstract: We often encounter situations in which an experimenter wants to find, by\nsequential experimentation, $x_{max} = \\arg\\max_{x} f(x)$, where $f(x)$ is a\n(possibly unknown) function of a well controllable variable $x$. Taking\ninspiration from physics and engineering, we have designed a new method to\naddress this problem. In this paper, we first introduce the method in\ncontinuous time, and then present two algorithms for use in sequential\nexperiments. Through a series of simulation studies, we show that the method is\neffective for finding maxima of unknown functions by experimentation, even when\nthe maximum of the functions drifts or when the signal to noise ratio is low. \n\n"}
{"id": "1502.02125", "contents": "Title: Contextual Online Learning for Multimedia Content Aggregation Abstract: The last decade has witnessed a tremendous growth in the volume as well as\nthe diversity of multimedia content generated by a multitude of sources (news\nagencies, social media, etc.). Faced with a variety of content choices,\nconsumers are exhibiting diverse preferences for content; their preferences\noften depend on the context in which they consume content as well as various\nexogenous events. To satisfy the consumers' demand for such diverse content,\nmultimedia content aggregators (CAs) have emerged which gather content from\nnumerous multimedia sources. A key challenge for such systems is to accurately\npredict what type of content each of its consumers prefers in a certain\ncontext, and adapt these predictions to the evolving consumers' preferences,\ncontexts and content characteristics. We propose a novel, distributed, online\nmultimedia content aggregation framework, which gathers content generated by\nmultiple heterogeneous producers to fulfill its consumers' demand for content.\nSince both the multimedia content characteristics and the consumers'\npreferences and contexts are unknown, the optimal content aggregation strategy\nis unknown a priori. Our proposed content aggregation algorithm is able to\nlearn online what content to gather and how to match content and users by\nexploiting similarities between consumer types. We prove bounds for our\nproposed learning algorithms that guarantee both the accuracy of the\npredictions as well as the learning speed. Importantly, our algorithms operate\nefficiently even when feedback from consumers is missing or content and\npreferences evolve over time. Illustrative results highlight the merits of the\nproposed content aggregation system in a variety of settings. \n\n"}
{"id": "1502.02551", "contents": "Title: Deep Learning with Limited Numerical Precision Abstract: Training of large-scale deep neural networks is often constrained by the\navailable computational resources. We study the effect of limited precision\ndata representation and computation on neural network training. Within the\ncontext of low-precision fixed-point computations, we observe the rounding\nscheme to play a crucial role in determining the network's behavior during\ntraining. Our results show that deep networks can be trained using only 16-bit\nwide fixed-point number representation when using stochastic rounding, and\nincur little to no degradation in the classification accuracy. We also\ndemonstrate an energy-efficient hardware accelerator that implements\nlow-precision fixed-point arithmetic with stochastic rounding. \n\n"}
{"id": "1502.03505", "contents": "Title: Supervised LogEuclidean Metric Learning for Symmetric Positive Definite\n  Matrices Abstract: Metric learning has been shown to be highly effective to improve the\nperformance of nearest neighbor classification. In this paper, we address the\nproblem of metric learning for Symmetric Positive Definite (SPD) matrices such\nas covariance matrices, which arise in many real-world applications. Naively\nusing standard Mahalanobis metric learning methods under the Euclidean geometry\nfor SPD matrices is not appropriate, because the difference of SPD matrices can\nbe a non-SPD matrix and thus the obtained solution can be uninterpretable. To\ncope with this problem, we propose to use a properly parameterized LogEuclidean\ndistance and optimize the metric with respect to kernel-target alignment, which\nis a supervised criterion for kernel learning. Then the resulting non-trivial\noptimization problem is solved by utilizing the Riemannian geometry. Finally,\nwe experimentally demonstrate the usefulness of our LogEuclidean metric\nlearning algorithm on real-world classification tasks for EEG signals and\ntexture patches. \n\n"}
{"id": "1502.04585", "contents": "Title: The Ladder: A Reliable Leaderboard for Machine Learning Competitions Abstract: The organizer of a machine learning competition faces the problem of\nmaintaining an accurate leaderboard that faithfully represents the quality of\nthe best submission of each competing team. What makes this estimation problem\nparticularly challenging is its sequential and adaptive nature. As participants\nare allowed to repeatedly evaluate their submissions on the leaderboard, they\nmay begin to overfit to the holdout data that supports the leaderboard. Few\ntheoretical results give actionable advice on how to design a reliable\nleaderboard. Existing approaches therefore often resort to poorly understood\nheuristics such as limiting the bit precision of answers and the rate of\nre-submission.\n  In this work, we introduce a notion of \"leaderboard accuracy\" tailored to the\nformat of a competition. We introduce a natural algorithm called \"the Ladder\"\nand demonstrate that it simultaneously supports strong theoretical guarantees\nin a fully adaptive model of estimation, withstands practical adversarial\nattacks, and achieves high utility on real submission files from an actual\ncompetition hosted by Kaggle.\n  Notably, we are able to sidestep a powerful recent hardness result for\nadaptive risk estimation that rules out algorithms such as ours under a\nseemingly very similar notion of accuracy. On a practical note, we provide a\ncompletely parameter-free variant of our algorithm that can be deployed in a\nreal competition with no tuning required whatsoever. \n\n"}
{"id": "1502.04635", "contents": "Title: Parameter estimation in softmax decision-making models with linear\n  objective functions Abstract: With an eye towards human-centered automation, we contribute to the\ndevelopment of a systematic means to infer features of human decision-making\nfrom behavioral data. Motivated by the common use of softmax selection in\nmodels of human decision-making, we study the maximum likelihood parameter\nestimation problem for softmax decision-making models with linear objective\nfunctions. We present conditions under which the likelihood function is convex.\nThese allow us to provide sufficient conditions for convergence of the\nresulting maximum likelihood estimator and to construct its asymptotic\ndistribution. In the case of models with nonlinear objective functions, we show\nhow the estimator can be applied by linearizing about a nominal parameter\nvalue. We apply the estimator to fit the stochastic UCL (Upper Credible Limit)\nmodel of human decision-making to human subject data. We show statistically\nsignificant differences in behavior across related, but distinct, tasks. \n\n"}
{"id": "1502.05577", "contents": "Title: Adaptive system optimization using random directions stochastic\n  approximation Abstract: We present novel algorithms for simulation optimization using random\ndirections stochastic approximation (RDSA). These include first-order\n(gradient) as well as second-order (Newton) schemes. We incorporate both\ncontinuous-valued as well as discrete-valued perturbations into both our\nalgorithms. The former are chosen to be independent and identically distributed\n(i.i.d.) symmetric, uniformly distributed random variables (r.v.), while the\nlatter are i.i.d., asymmetric, Bernoulli r.v.s. Our Newton algorithm, with a\nnovel Hessian estimation scheme, requires N-dimensional perturbations and three\nloss measurements per iteration, whereas the simultaneous perturbation Newton\nsearch algorithm of [1] requires 2N-dimensional perturbations and four loss\nmeasurements per iteration. We prove the unbiasedness of both gradient and\nHessian estimates and asymptotic (strong) convergence for both first-order and\nsecond-order schemes. We also provide asymptotic normality results, which in\nparticular establish that the asymmetric Bernoulli variant of Newton RDSA\nmethod is better than 2SPSA of [1]. Numerical experiments are used to validate\nthe theoretical results. \n\n"}
{"id": "1502.08053", "contents": "Title: Stochastic Dual Coordinate Ascent with Adaptive Probabilities Abstract: This paper introduces AdaSDCA: an adaptive variant of stochastic dual\ncoordinate ascent (SDCA) for solving the regularized empirical risk\nminimization problems. Our modification consists in allowing the method\nadaptively change the probability distribution over the dual variables\nthroughout the iterative process. AdaSDCA achieves provably better complexity\nbound than SDCA with the best fixed probability distribution, known as\nimportance sampling. However, it is of a theoretical character as it is\nexpensive to implement. We also propose AdaSDCA+: a practical variant which in\nour experiments outperforms existing non-adaptive methods. \n\n"}
{"id": "1503.00024", "contents": "Title: Influence Maximization with Bandits Abstract: We consider the problem of \\emph{influence maximization}, the problem of\nmaximizing the number of people that become aware of a product by finding the\n`best' set of `seed' users to expose the product to. Most prior work on this\ntopic assumes that we know the probability of each user influencing each other\nuser, or we have data that lets us estimate these influences. However, this\ninformation is typically not initially available or is difficult to obtain. To\navoid this assumption, we adopt a combinatorial multi-armed bandit paradigm\nthat estimates the influence probabilities as we sequentially try different\nseed sets. We establish bounds on the performance of this procedure under the\nexisting edge-level feedback as well as a novel and more realistic node-level\nfeedback. Beyond our theoretical results, we describe a practical\nimplementation and experimentally demonstrate its efficiency and effectiveness\non four real datasets. \n\n"}
{"id": "1503.01057", "contents": "Title: Kernel Interpolation for Scalable Structured Gaussian Processes\n  (KISS-GP) Abstract: We introduce a new structured kernel interpolation (SKI) framework, which\ngeneralises and unifies inducing point methods for scalable Gaussian processes\n(GPs). SKI methods produce kernel approximations for fast computations through\nkernel interpolation. The SKI framework clarifies how the quality of an\ninducing point approach depends on the number of inducing (aka interpolation)\npoints, interpolation strategy, and GP covariance kernel. SKI also provides a\nmechanism to create new scalable kernel methods, through choosing different\nkernel interpolation strategies. Using SKI, with local cubic kernel\ninterpolation, we introduce KISS-GP, which is 1) more scalable than inducing\npoint alternatives, 2) naturally enables Kronecker and Toeplitz algebra for\nsubstantial additional gains in scalability, without requiring any grid data,\nand 3) can be used for fast and expressive kernel learning. KISS-GP costs O(n)\ntime and storage for GP inference. We evaluate KISS-GP for kernel matrix\napproximation, kernel learning, and natural sound modelling. \n\n"}
{"id": "1503.01444", "contents": "Title: Partial Sum Minimization of Singular Values in Robust PCA: Algorithm and\n  Applications Abstract: Robust Principal Component Analysis (RPCA) via rank minimization is a\npowerful tool for recovering underlying low-rank structure of clean data\ncorrupted with sparse noise/outliers. In many low-level vision problems, not\nonly it is known that the underlying structure of clean data is low-rank, but\nthe exact rank of clean data is also known. Yet, when applying conventional\nrank minimization for those problems, the objective function is formulated in a\nway that does not fully utilize a priori target rank information about the\nproblems. This observation motivates us to investigate whether there is a\nbetter alternative solution when using rank minimization. In this paper,\ninstead of minimizing the nuclear norm, we propose to minimize the partial sum\nof singular values, which implicitly encourages the target rank constraint. Our\nexperimental analyses show that, when the number of samples is deficient, our\napproach leads to a higher success rate than conventional rank minimization,\nwhile the solutions obtained by the two approaches are almost identical when\nthe number of samples is more than sufficient. We apply our approach to various\nlow-level vision problems, e.g. high dynamic range imaging, motion edge\ndetection, photometric stereo, image alignment and recovery, and show that our\nresults outperform those obtained by the conventional nuclear norm rank\nminimization method. \n\n"}
{"id": "1503.01800", "contents": "Title: EmoNets: Multimodal deep learning approaches for emotion recognition in\n  video Abstract: The task of the emotion recognition in the wild (EmotiW) Challenge is to\nassign one of seven emotions to short video clips extracted from Hollywood\nstyle movies. The videos depict acted-out emotions under realistic conditions\nwith a large degree of variation in attributes such as pose and illumination,\nmaking it worthwhile to explore approaches which consider combinations of\nfeatures from multiple modalities for label assignment. In this paper we\npresent our approach to learning several specialist models using deep learning\ntechniques, each focusing on one modality. Among these are a convolutional\nneural network, focusing on capturing visual information in detected faces, a\ndeep belief net focusing on the representation of the audio stream, a K-Means\nbased \"bag-of-mouths\" model, which extracts visual features around the mouth\nregion and a relational autoencoder, which addresses spatio-temporal aspects of\nvideos. We explore multiple methods for the combination of cues from these\nmodalities into one common classifier. This achieves a considerably greater\naccuracy than predictions from our strongest single-modality classifier. Our\nmethod was the winning submission in the 2013 EmotiW challenge and achieved a\ntest set accuracy of 47.67% on the 2014 dataset. \n\n"}
{"id": "1503.06833", "contents": "Title: On Lower and Upper Bounds for Smooth and Strongly Convex Optimization\n  Problems Abstract: We develop a novel framework to study smooth and strongly convex optimization\nalgorithms, both deterministic and stochastic. Focusing on quadratic functions\nwe are able to examine optimization algorithms as a recursive application of\nlinear operators. This, in turn, reveals a powerful connection between a class\nof optimization algorithms and the analytic theory of polynomials whereby new\nlower and upper bounds are derived. Whereas existing lower bounds for this\nsetting are only valid when the dimensionality scales with the number of\niterations, our lower bound holds in the natural regime where the\ndimensionality is fixed. Lastly, expressing it as an optimal solution for the\ncorresponding optimization problem over polynomials, as formulated by our\nframework, we present a novel systematic derivation of Nesterov's well-known\nAccelerated Gradient Descent method. This rather natural interpretation of AGD\ncontrasts with earlier ones which lacked a simple, yet solid, motivation. \n\n"}
{"id": "1503.08855", "contents": "Title: Decentralized learning for wireless communications and networking Abstract: This chapter deals with decentralized learning algorithms for in-network\nprocessing of graph-valued data. A generic learning problem is formulated and\nrecast into a separable form, which is iteratively minimized using the\nalternating-direction method of multipliers (ADMM) so as to gain the desired\ndegree of parallelization. Without exchanging elements from the distributed\ntraining sets and keeping inter-node communications at affordable levels, the\nlocal (per-node) learners consent to the desired quantity inferred globally,\nmeaning the one obtained if the entire training data set were centrally\navailable. Impact of the decentralized learning framework to contemporary\nwireless communications and networking tasks is illustrated through case\nstudies including target tracking using wireless sensor networks, unveiling\nInternet traffic anomalies, power system state estimation, as well as spectrum\ncartography for wireless cognitive radio networks. \n\n"}
{"id": "1504.07545", "contents": "Title: Matroids are Immune to Braess Paradox Abstract: The famous Braess paradox describes the following phenomenon: It might happen\nthat the improvement of resources, like building a new street within a\ncongested network, may in fact lead to larger costs for the players in an\nequilibrium. In this paper we consider general nonatomic congestion games and\ngive a characterization of the maximal combinatorial property of strategy\nspaces for which Braess paradox does not occur. In a nutshell, bases of\nmatroids are exactly this maximal structure. We prove our characterization by\ntwo novel sensitivity results for convex separable optimization problems over\npolymatroid base polyhedra which may be of independent interest. \n\n"}
{"id": "1504.08167", "contents": "Title: Multi-user lax communications: a multi-armed bandit approach Abstract: Inspired by cognitive radio networks, we consider a setting where multiple\nusers share several channels modeled as a multi-user multi-armed bandit (MAB)\nproblem. The characteristics of each channel are unknown and are different for\neach user. Each user can choose between the channels, but her success depends\non the particular channel chosen as well as on the selections of other users:\nif two users select the same channel their messages collide and none of them\nmanages to send any data. Our setting is fully distributed, so there is no\ncentral control. As in many communication systems, the users cannot set up a\ndirect communication protocol, so information exchange must be limited to a\nminimum. We develop an algorithm for learning a stable configuration for the\nmulti-user MAB problem. We further offer both convergence guarantees and\nexperiments inspired by real communication networks, including comparison to\nstate-of-the-art algorithms. \n\n"}
{"id": "1504.08333", "contents": "Title: Revenue-Maximizing Mechanism Design for Quasi-Proportional Auctions Abstract: In quasi-proportional auctions, each bidder receives a fraction of the\nallocation equal to the weight of their bid divided by the sum of weights of\nall bids, where each bid's weight is determined by a weight function. We study\nthe relationship between the weight function, bidders' private values, number\nof bidders, and the seller's revenue in equilibrium. It has been shown that if\none bidder has a much higher private value than the others, then a nearly flat\nweight function maximizes revenue. Essentially, threatening the bidder who has\nthe highest valuation with having to share the allocation maximizes the\nrevenue. We show that as bidder private values approach parity, steeper weight\nfunctions maximize revenue by making the quasi-proportional auction more like a\nwinner-take-all auction. We also show that steeper weight functions maximize\nrevenue as the number of bidders increases. For flatter weight functions, there\nis known to be a unique pure-strategy Nash equilibrium. We show that a\npure-strategy Nash equilibrium also exists for steeper weight functions, and we\ngive lower bounds for bids at an equilibrium. For a special case that includes\nthe two-bidder auction, we show that the pure-strategy Nash equilibrium is\nunique, and we show how to compute the revenue at equilibrium. We also show\nthat selecting a weight function based on private value ratios and number of\nbidders is necessary for a quasi-proportional auction to produce more revenue\nthan a second-price auction. \n\n"}
{"id": "1505.00482", "contents": "Title: Risk Bounds For Mode Clustering Abstract: Density mode clustering is a nonparametric clustering method. The clusters\nare the basins of attraction of the modes of a density estimator. We study the\nrisk of mode-based clustering. We show that the clustering risk over the\ncluster cores --- the regions where the density is high --- is very small even\nin high dimensions. And under a low noise condition, the overall cluster risk\nis small even beyond the cores, in high dimensions. \n\n"}
{"id": "1505.00870", "contents": "Title: An $O(n\\log(n))$ Algorithm for Projecting Onto the Ordered Weighted\n  $\\ell_1$ Norm Ball Abstract: The ordered weighted $\\ell_1$ (OWL) norm is a newly developed generalization\nof the Octogonal Shrinkage and Clustering Algorithm for Regression (OSCAR)\nnorm. This norm has desirable statistical properties and can be used to perform\nsimultaneous clustering and regression. In this paper, we show how to compute\nthe projection of an $n$-dimensional vector onto the OWL norm ball in\n$O(n\\log(n))$ operations. In addition, we illustrate the performance of our\nalgorithm on a synthetic regression test. \n\n"}
{"id": "1505.01809", "contents": "Title: Language Models for Image Captioning: The Quirks and What Works Abstract: Two recent approaches have achieved state-of-the-art results in image\ncaptioning. The first uses a pipelined process where a set of candidate words\nis generated by a convolutional neural network (CNN) trained on images, and\nthen a maximum entropy (ME) language model is used to arrange these words into\na coherent sentence. The second uses the penultimate activation layer of the\nCNN as input to a recurrent neural network (RNN) that then generates the\ncaption sequence. In this paper, we compare the merits of these different\nlanguage modeling approaches for the first time by using the same\nstate-of-the-art CNN as input. We examine issues in the different approaches,\nincluding linguistic irregularities, caption repetition, and data set overlap.\nBy combining key aspects of the ME and RNN methods, we achieve a new record\nperformance over previously published results on the benchmark COCO dataset.\nHowever, the gains we see in BLEU do not translate to human judgments. \n\n"}
{"id": "1505.01866", "contents": "Title: DART: Dropouts meet Multiple Additive Regression Trees Abstract: Multiple Additive Regression Trees (MART), an ensemble model of boosted\nregression trees, is known to deliver high prediction accuracy for diverse\ntasks, and it is widely used in practice. However, it suffers an issue which we\ncall over-specialization, wherein trees added at later iterations tend to\nimpact the prediction of only a few instances, and make negligible contribution\ntowards the remaining instances. This negatively affects the performance of the\nmodel on unseen data, and also makes the model over-sensitive to the\ncontributions of the few, initially added tress. We show that the commonly used\ntool to address this issue, that of shrinkage, alleviates the problem only to a\ncertain extent and the fundamental issue of over-specialization still remains.\nIn this work, we explore a different approach to address the problem that of\nemploying dropouts, a tool that has been recently proposed in the context of\nlearning deep neural networks. We propose a novel way of employing dropouts in\nMART, resulting in the DART algorithm. We evaluate DART on ranking, regression\nand classification tasks, using large scale, publicly available datasets, and\nshow that DART outperforms MART in each of the tasks, with a significant\nmargin. We also show that DART overcomes the issue of over-specialization to a\nconsiderable extent. \n\n"}
{"id": "1505.02074", "contents": "Title: Exploring Models and Data for Image Question Answering Abstract: This work aims to address the problem of image-based question-answering (QA)\nwith new models and datasets. In our work, we propose to use neural networks\nand visual semantic embeddings, without intermediate stages such as object\ndetection and image segmentation, to predict answers to simple questions about\nimages. Our model performs 1.8 times better than the only published results on\nan existing image QA dataset. We also present a question generation algorithm\nthat converts image descriptions, which are widely available, into QA form. We\nused this algorithm to produce an order-of-magnitude larger dataset, with more\nevenly distributed answers. A suite of baseline results on this new dataset are\nalso presented. \n\n"}
{"id": "1505.03001", "contents": "Title: Detecting the large entries of a sparse covariance matrix in\n  sub-quadratic time Abstract: The covariance matrix of a $p$-dimensional random variable is a fundamental\nquantity in data analysis. Given $n$ i.i.d. observations, it is typically\nestimated by the sample covariance matrix, at a computational cost of\n$O(np^{2})$ operations. When $n,p$ are large, this computation may be\nprohibitively slow. Moreover, in several contemporary applications, the\npopulation matrix is approximately sparse, and only its few large entries are\nof interest. This raises the following question, at the focus of our work:\nAssuming approximate sparsity of the covariance matrix, can its large entries\nbe detected much faster, say in sub-quadratic time, without explicitly\ncomputing all its $p^{2}$ entries? In this paper, we present and theoretically\nanalyze two randomized algorithms that detect the large entries of an\napproximately sparse sample covariance matrix using only $O(np\\text{ poly log }\np)$ operations. Furthermore, assuming sparsity of the population matrix, we\nderive sufficient conditions on the underlying random variable and on the\nnumber of samples $n$, for the sample covariance matrix to satisfy our\napproximate sparsity requirements. Finally, we illustrate the performance of\nour algorithms via several simulations. \n\n"}
{"id": "1505.04252", "contents": "Title: Global Convergence of Unmodified 3-Block ADMM for a Class of Convex\n  Minimization Problems Abstract: The alternating direction method of multipliers (ADMM) has been successfully\napplied to solve structured convex optimization problems due to its superior\npractical performance. The convergence properties of the 2-block ADMM have been\nstudied extensively in the literature. Specifically, it has been proven that\nthe 2-block ADMM globally converges for any penalty parameter $\\gamma>0$. In\nthis sense, the 2-block ADMM allows the parameter to be free, i.e., there is no\nneed to restrict the value for the parameter when implementing this algorithm\nin order to ensure convergence. However, for the 3-block ADMM, Chen \\etal\n\\cite{Chen-admm-failure-2013} recently constructed a counter-example showing\nthat it can diverge if no further condition is imposed. The existing results on\nstudying further sufficient conditions on guaranteeing the convergence of the\n3-block ADMM usually require $\\gamma$ to be smaller than a certain bound, which\nis usually either difficult to compute or too small to make it a practical\nalgorithm. In this paper, we show that the 3-block ADMM still globally\nconverges with any penalty parameter $\\gamma>0$ if the third function $f_3$ in\nthe objective is smooth and strongly convex, and its condition number is in\n$[1,1.0798)$, besides some other mild conditions. This requirement covers an\nimportant class of problems to be called regularized least squares\ndecomposition (RLSD) in this paper. \n\n"}
{"id": "1505.04771", "contents": "Title: DopeLearning: A Computational Approach to Rap Lyrics Generation Abstract: Writing rap lyrics requires both creativity to construct a meaningful,\ninteresting story and lyrical skills to produce complex rhyme patterns, which\nform the cornerstone of good flow. We present a rap lyrics generation method\nthat captures both of these aspects. First, we develop a prediction model to\nidentify the next line of existing lyrics from a set of candidate next lines.\nThis model is based on two machine-learning techniques: the RankSVM algorithm\nand a deep neural network model with a novel structure. Results show that the\nprediction model can identify the true next line among 299 randomly selected\nlines with an accuracy of 17%, i.e., over 50 times more likely than by random.\nSecond, we employ the prediction model to combine lines from existing songs,\nproducing lyrics with rhyme and a meaning. An evaluation of the produced lyrics\nshows that in terms of quantitative rhyme density, the method outperforms the\nbest human rappers by 21%. The rap lyrics generator has been deployed as an\nonline tool called DeepBeat, and the performance of the tool has been assessed\nby analyzing its usage logs. This analysis shows that machine-learned rankings\ncorrelate with user preferences. \n\n"}
{"id": "1505.06813", "contents": "Title: Surrogate Functions for Maximizing Precision at the Top Abstract: The problem of maximizing precision at the top of a ranked list, often dubbed\nPrecision@k (prec@k), finds relevance in myriad learning applications such as\nranking, multi-label classification, and learning with severe label imbalance.\nHowever, despite its popularity, there exist significant gaps in our\nunderstanding of this problem and its associated performance measure.\n  The most notable of these is the lack of a convex upper bounding surrogate\nfor prec@k. We also lack scalable perceptron and stochastic gradient descent\nalgorithms for optimizing this performance measure. In this paper we make key\ncontributions in these directions. At the heart of our results is a family of\ntruly upper bounding surrogates for prec@k. These surrogates are motivated in a\nprincipled manner and enjoy attractive properties such as consistency to prec@k\nunder various natural margin/noise conditions.\n  These surrogates are then used to design a class of novel perceptron\nalgorithms for optimizing prec@k with provable mistake bounds. We also devise\nscalable stochastic gradient descent style methods for this problem with\nprovable convergence bounds. Our proofs rely on novel uniform convergence\nbounds which require an in-depth analysis of the structural properties of\nprec@k and its surrogates. We conclude with experimental results comparing our\nalgorithms with state-of-the-art cutting plane and stochastic gradient\nalgorithms for maximizing prec@k. \n\n"}
{"id": "1506.00165", "contents": "Title: Labeled compression schemes for extremal classes Abstract: It is a long-standing open problem whether there always exists a compression\nscheme whose size is of the order of the Vapnik-Chervonienkis (VC) dimension\n$d$. Recently compression schemes of size exponential in $d$ have been found\nfor any concept class of VC dimension $d$. Previously, compression schemes of\nsize $d$ have been given for maximum classes, which are special concept classes\nwhose size equals an upper bound due to Sauer-Shelah. We consider a\ngeneralization of maximum classes called extremal classes. Their definition is\nbased on a powerful generalization of the Sauer-Shelah bound called the\nSandwich Theorem, which has been studied in several areas of combinatorics and\ncomputer science. The key result of the paper is a construction of a sample\ncompression scheme for extremal classes of size equal to their VC dimension. We\nalso give a number of open problems concerning the combinatorial structure of\nextremal classes and the existence of unlabeled compression schemes for them. \n\n"}
{"id": "1506.00552", "contents": "Title: Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than\n  Random Selection Abstract: There has been significant recent work on the theory and application of\nrandomized coordinate descent algorithms, beginning with the work of Nesterov\n[SIAM J. Optim., 22(2), 2012], who showed that a random-coordinate selection\nrule achieves the same convergence rate as the Gauss-Southwell selection rule.\nThis result suggests that we should never use the Gauss-Southwell rule, as it\nis typically much more expensive than random selection. However, the empirical\nbehaviours of these algorithms contradict this theoretical result: in\napplications where the computational costs of the selection rules are\ncomparable, the Gauss-Southwell selection rule tends to perform substantially\nbetter than random coordinate selection. We give a simple analysis of the\nGauss-Southwell rule showing that---except in extreme cases---its convergence\nrate is faster than choosing random coordinates. Further, in this work we (i)\nshow that exact coordinate optimization improves the convergence rate for\ncertain sparse problems, (ii) propose a Gauss-Southwell-Lipschitz rule that\ngives an even faster convergence rate given knowledge of the Lipschitz\nconstants of the partial derivatives, (iii) analyze the effect of approximate\nGauss-Southwell rules, and (iv) analyze proximal-gradient variants of the\nGauss-Southwell rule. \n\n"}
{"id": "1506.00999", "contents": "Title: Combining Two And Three-Way Embeddings Models for Link Prediction in\n  Knowledge Bases Abstract: This paper tackles the problem of endogenous link prediction for Knowledge\nBase completion. Knowledge Bases can be represented as directed graphs whose\nnodes correspond to entities and edges to relationships. Previous attempts\neither consist of powerful systems with high capacity to model complex\nconnectivity patterns, which unfortunately usually end up overfitting on rare\nrelationships, or in approaches that trade capacity for simplicity in order to\nfairly model all relationships, frequent or not. In this paper, we propose\nTatec a happy medium obtained by complementing a high-capacity model with a\nsimpler one, both pre-trained separately and then combined. We present several\nvariants of this model with different kinds of regularization and combination\nstrategies and show that this approach outperforms existing methods on\ndifferent types of relationships by achieving state-of-the-art results on four\nbenchmarks of the literature. \n\n"}
{"id": "1506.02719", "contents": "Title: Non-parametric Revenue Optimization for Generalized Second Price\n  Auctions Abstract: We present an extensive analysis of the key problem of learning optimal\nreserve prices for generalized second price auctions. We describe two\nalgorithms for this task: one based on density estimation, and a novel\nalgorithm benefiting from solid theoretical guarantees and with a very\nfavorable running-time complexity of $O(n S \\log (n S))$, where $n$ is the\nsample size and $S$ the number of slots. Our theoretical guarantees are more\nfavorable than those previously presented in the literature. Additionally, we\nshow that even if bidders do not play at an equilibrium, our second algorithm\nis still well defined and minimizes a quantity of interest. To our knowledge,\nthis is the first attempt to apply learning algorithms to the problem of\nreserve price optimization in GSP auctions. Finally, we present the first\nconvergence analysis of empirical equilibrium bidding functions to the unique\nsymmetric Bayesian-Nash equilibrium of a GSP. \n\n"}
{"id": "1506.02761", "contents": "Title: WordRank: Learning Word Embeddings via Robust Ranking Abstract: Embedding words in a vector space has gained a lot of attention in recent\nyears. While state-of-the-art methods provide efficient computation of word\nsimilarities via a low-dimensional matrix embedding, their motivation is often\nleft unclear. In this paper, we argue that word embedding can be naturally\nviewed as a ranking problem due to the ranking nature of the evaluation\nmetrics. Then, based on this insight, we propose a novel framework WordRank\nthat efficiently estimates word representations via robust ranking, in which\nthe attention mechanism and robustness to noise are readily achieved via the\nDCG-like ranking losses. The performance of WordRank is measured in word\nsimilarity and word analogy benchmarks, and the results are compared to the\nstate-of-the-art word embedding techniques. Our algorithm is very competitive\nto the state-of-the- arts on large corpora, while outperforms them by a\nsignificant margin when the training set is limited (i.e., sparse and noisy).\nWith 17 million tokens, WordRank performs almost as well as existing methods\nusing 7.2 billion tokens on a popular word similarity benchmark. Our multi-node\ndistributed implementation of WordRank is publicly available for general usage. \n\n"}
{"id": "1506.03137", "contents": "Title: Symmetric Tensor Completion from Multilinear Entries and Learning\n  Product Mixtures over the Hypercube Abstract: We give an algorithm for completing an order-$m$ symmetric low-rank tensor\nfrom its multilinear entries in time roughly proportional to the number of\ntensor entries. We apply our tensor completion algorithm to the problem of\nlearning mixtures of product distributions over the hypercube, obtaining new\nalgorithmic results. If the centers of the product distribution are linearly\nindependent, then we recover distributions with as many as $\\Omega(n)$ centers\nin polynomial time and sample complexity. In the general case, we recover\ndistributions with as many as $\\tilde\\Omega(n)$ centers in quasi-polynomial\ntime, answering an open problem of Feldman et al. (SIAM J. Comp.) for the\nspecial case of distributions with incoherent bias vectors.\n  Our main algorithmic tool is the iterated application of a low-rank matrix\ncompletion algorithm for matrices with adversarially missing entries. \n\n"}
{"id": "1506.04449", "contents": "Title: Compressing Convolutional Neural Networks Abstract: Convolutional neural networks (CNN) are increasingly used in many areas of\ncomputer vision. They are particularly attractive because of their ability to\n\"absorb\" great quantities of labeled data through millions of parameters.\nHowever, as model sizes increase, so do the storage and memory requirements of\nthe classifiers. We present a novel network architecture, Frequency-Sensitive\nHashed Nets (FreshNets), which exploits inherent redundancy in both\nconvolutional layers and fully-connected layers of a deep learning model,\nleading to dramatic savings in memory and storage consumption. Based on the key\nobservation that the weights of learned convolutional filters are typically\nsmooth and low-frequency, we first convert filter weights to the frequency\ndomain with a discrete cosine transform (DCT) and use a low-cost hash function\nto randomly group frequency parameters into hash buckets. All parameters\nassigned the same hash bucket share a single value learned with standard\nback-propagation. To further reduce model size we allocate fewer hash buckets\nto high-frequency components, which are generally less important. We evaluate\nFreshNets on eight data sets, and show that it leads to drastically better\ncompressed performance than several relevant baselines. \n\n"}
{"id": "1506.04488", "contents": "Title: Distilling Word Embeddings: An Encoding Approach Abstract: Distilling knowledge from a well-trained cumbersome network to a small one\nhas recently become a new research topic, as lightweight neural networks with\nhigh performance are particularly in need in various resource-restricted\nsystems. This paper addresses the problem of distilling word embeddings for NLP\ntasks. We propose an encoding approach to distill task-specific knowledge from\na set of high-dimensional embeddings, which can reduce model complexity by a\nlarge margin as well as retain high accuracy, showing a good compromise between\nefficiency and performance. Experiments in two tasks reveal the phenomenon that\ndistilling knowledge from cumbersome embeddings is better than directly\ntraining neural networks with small embeddings. \n\n"}
{"id": "1506.05148", "contents": "Title: Elements of Game Theory - Part I: Foundations, acts and mechanisms Abstract: In this paper, a gentle introduction to Game Theory is presented in the form\nof basic concepts and examples. Minimax and Nash's theorem are introduced as\nthe formal definitions for optimal strategies and equilibria in zero-sum and\nnonzero-sum games. Several elements of cooperative gaming, coalitions, voting\nensembles, voting power and collective efficiency are described in brief.\nAnalytical (matrix) and extended (tree-graph) forms of game representation is\nillustrated as the basic tools for identifying optimal strategies and\n\"solutions\" in games of any kind. Next, a typology of four standard nonzero-sum\ngames is investigated, analyzing the Nash equilibria and the optimal strategies\nin each case. Signaling, stance and third-party intermediates are described as\nvery important properties when analyzing strategic moves, while credibility and\nreputation is described as crucial factors when signaling promises or threats.\nUtility is introduced as a generalization of typical cost/gain functions and it\nis used to explain the incentives of irrational players under the scope of\n\"rational irrationality\". Finally, a brief reference is presented for several\nother more advanced concepts of gaming, including emergence of cooperation,\nevolutionary stable strategies, two-level games, metagames, hypergames and the\nHarsanyi transformation. \n\n"}
{"id": "1506.07942", "contents": "Title: A Comprehensive Survey of Potential Game Approaches to Wireless Networks Abstract: Potential games form a class of non-cooperative games where unilateral\nimprovement dynamics are guaranteed to converge in many practical cases. The\npotential game approach has been applied to a wide range of wireless network\nproblems, particularly to a variety of channel assignment problems. In this\npaper, the properties of potential games are introduced, and games in wireless\nnetworks that have been proven to be potential games are comprehensively\ndiscussed. \n\n"}
{"id": "1507.00825", "contents": "Title: Ridge Regression, Hubness, and Zero-Shot Learning Abstract: This paper discusses the effect of hubness in zero-shot learning, when ridge\nregression is used to find a mapping between the example space to the label\nspace. Contrary to the existing approach, which attempts to find a mapping from\nthe example space to the label space, we show that mapping labels into the\nexample space is desirable to suppress the emergence of hubs in the subsequent\nnearest neighbor search step. Assuming a simple data model, we prove that the\nproposed approach indeed reduces hubness. This was verified empirically on the\ntasks of bilingual lexicon extraction and image labeling: hubness was reduced\nwith both of these tasks and the accuracy was improved accordingly. \n\n"}
{"id": "1507.01160", "contents": "Title: Correlated Multiarmed Bandit Problem: Bayesian Algorithms and Regret\n  Analysis Abstract: We consider the correlated multiarmed bandit (MAB) problem in which the\nrewards associated with each arm are modeled by a multivariate Gaussian random\nvariable, and we investigate the influence of the assumptions in the Bayesian\nprior on the performance of the upper credible limit (UCL) algorithm and a new\ncorrelated UCL algorithm. We rigorously characterize the influence of accuracy,\nconfidence, and correlation scale in the prior on the decision-making\nperformance of the algorithms. Our results show how priors and correlation\nstructure can be leveraged to improve performance. \n\n"}
{"id": "1507.01476", "contents": "Title: Semi-proximal Mirror-Prox for Nonsmooth Composite Minimization Abstract: We propose a new first-order optimisation algorithm to solve high-dimensional\nnon-smooth composite minimisation problems. Typical examples of such problems\nhave an objective that decomposes into a non-smooth empirical risk part and a\nnon-smooth regularisation penalty. The proposed algorithm, called Semi-Proximal\nMirror-Prox, leverages the Fenchel-type representation of one part of the\nobjective while handling the other part of the objective via linear\nminimization over the domain. The algorithm stands in contrast with more\nclassical proximal gradient algorithms with smoothing, which require the\ncomputation of proximal operators at each iteration and can therefore be\nimpractical for high-dimensional problems. We establish the theoretical\nconvergence rate of Semi-Proximal Mirror-Prox, which exhibits the optimal\ncomplexity bounds, i.e. $O(1/\\epsilon^2)$, for the number of calls to linear\nminimization oracle. We present promising experimental results showing the\ninterest of the approach in comparison to competing methods. \n\n"}
{"id": "1507.02528", "contents": "Title: Faster Convex Optimization: Simulated Annealing with an Efficient\n  Universal Barrier Abstract: This paper explores a surprising equivalence between two seemingly-distinct\nconvex optimization methods. We show that simulated annealing, a well-studied\nrandom walk algorithms, is directly equivalent, in a certain sense, to the\ncentral path interior point algorithm for the the entropic universal barrier\nfunction. This connection exhibits several benefits. First, we are able improve\nthe state of the art time complexity for convex optimization under the\nmembership oracle model. We improve the analysis of the randomized algorithm of\nKalai and Vempala by utilizing tools developed by Nesterov and Nemirovskii that\nunderly the central path following interior point algorithm. We are able to\ntighten the temperature schedule for simulated annealing which gives an\nimproved running time, reducing by square root of the dimension in certain\ninstances. Second, we get an efficient randomized interior point method with an\nefficiently computable universal barrier for any convex set described by a\nmembership oracle. Previously, efficiently computable barriers were known only\nfor particular convex sets. \n\n"}
{"id": "1507.04734", "contents": "Title: Variational Gram Functions: Convex Analysis and Optimization Abstract: We propose a new class of convex penalty functions, called \\emph{variational\nGram functions} (VGFs), that can promote pairwise relations, such as\northogonality, among a set of vectors in a vector space. These functions can\nserve as regularizers in convex optimization problems arising from hierarchical\nclassification, multitask learning, and estimating vectors with disjoint\nsupports, among other applications. We study convexity for VGFs, and give\nefficient characterizations for their convex conjugates, subdifferentials, and\nproximal operators. We discuss efficient optimization algorithms for\nregularized loss minimization problems where the loss admits a common, yet\nsimple, variational representation and the regularizer is a VGF. These\nalgorithms enjoy a simple kernel trick, an efficient line search, as well as\ncomputational advantages over first order methods based on the subdifferential\nor proximal maps. We also establish a general representer theorem for such\nlearning problems. Lastly, numerical experiments on a hierarchical\nclassification problem are presented to demonstrate the effectiveness of VGFs\nand the associated optimization algorithms. \n\n"}
{"id": "1507.04798", "contents": "Title: Exploratory topic modeling with distributional semantics Abstract: As we continue to collect and store textual data in a multitude of domains,\nwe are regularly confronted with material whose largely unknown thematic\nstructure we want to uncover. With unsupervised, exploratory analysis, no prior\nknowledge about the content is required and highly open-ended tasks can be\nsupported. In the past few years, probabilistic topic modeling has emerged as a\npopular approach to this problem. Nevertheless, the representation of the\nlatent topics as aggregations of semi-coherent terms limits their\ninterpretability and level of detail.\n  This paper presents an alternative approach to topic modeling that maps\ntopics as a network for exploration, based on distributional semantics using\nlearned word vectors. From the granular level of terms and their semantic\nsimilarity relations global topic structures emerge as clustered regions and\ngradients of concepts. Moreover, the paper discusses the visual interactive\nrepresentation of the topic map, which plays an important role in supporting\nits exploration. \n\n"}
{"id": "1507.06228", "contents": "Title: Training Very Deep Networks Abstract: Theoretical and empirical evidence indicates that the depth of neural\nnetworks is crucial for their success. However, training becomes more difficult\nas depth increases, and training of very deep networks remains an open problem.\nHere we introduce a new architecture designed to overcome this. Our so-called\nhighway networks allow unimpeded information flow across many layers on\ninformation highways. They are inspired by Long Short-Term Memory recurrent\nnetworks and use adaptive gating units to regulate the information flow. Even\nwith hundreds of layers, highway networks can be trained directly through\nsimple gradient descent. This enables the study of extremely deep and efficient\narchitectures. \n\n"}
{"id": "1508.00506", "contents": "Title: A variational approach to path estimation and parameter inference of\n  hidden diffusion processes Abstract: We consider a hidden Markov model, where the signal process, given by a\ndiffusion, is only indirectly observed through some noisy measurements. The\narticle develops a variational method for approximating the hidden states of\nthe signal process given the full set of observations. This, in particular,\nleads to systematic approximations of the smoothing densities of the signal\nprocess. The paper then demonstrates how an efficient inference scheme, based\non this variational approach to the approximation of the hidden states, can be\ndesigned to estimate the unknown parameters of stochastic differential\nequations. Two examples at the end illustrate the efficacy and the accuracy of\nthe presented method. \n\n"}
{"id": "1508.01928", "contents": "Title: A variational approach to the consistency of spectral clustering Abstract: This paper establishes the consistency of spectral approaches to data\nclustering. We consider clustering of point clouds obtained as samples of a\nground-truth measure. A graph representing the point cloud is obtained by\nassigning weights to edges based on the distance between the points they\nconnect. We investigate the spectral convergence of both unnormalized and\nnormalized graph Laplacians towards the appropriate operators in the continuum\ndomain. We obtain sharp conditions on how the connectivity radius can be scaled\nwith respect to the number of sample points for the spectral convergence to\nhold.\n  We also show that the discrete clusters obtained via spectral clustering\nconverge towards a continuum partition of the ground truth measure. Such\ncontinuum partition minimizes a functional describing the continuum analogue of\nthe graph-based spectral partitioning. Our approach, based on variational\nconvergence, is general and flexible. \n\n"}
{"id": "1508.02087", "contents": "Title: A Linearly-Convergent Stochastic L-BFGS Algorithm Abstract: We propose a new stochastic L-BFGS algorithm and prove a linear convergence\nrate for strongly convex and smooth functions. Our algorithm draws heavily from\na recent stochastic variant of L-BFGS proposed in Byrd et al. (2014) as well as\na recent approach to variance reduction for stochastic gradient descent from\nJohnson and Zhang (2013). We demonstrate experimentally that our algorithm\nperforms well on large-scale convex and non-convex optimization problems,\nexhibiting linear convergence and rapidly solving the optimization problems to\nhigh levels of precision. Furthermore, we show that our algorithm performs well\nfor a wide-range of step sizes, often differing by several orders of magnitude. \n\n"}
{"id": "1508.02440", "contents": "Title: Energy Structure of Optimal Positional Strategies in Mean Payoff Games Abstract: This note studies structural aspects concerning Optimal Positional Strategies\n(OPSs) in Mean Payoff Games (MPGs), it is a contribution to understanding the\nrelationship between OPSs in MPGs and Small Energy-Progress Measures (SEPMs) in\nreweighted Energy Games (EGs). Firstly, it is observed that the space of all\nOPSs, $\\texttt{opt}_{\\Gamma}\\Sigma^M_0$, admits a unique complete decomposition\nin terms of so-called extremal-SEPM{s} in reweighted EG{s}; this points out\nwhat we called the \"Energy-Lattice $\\mathcal{X}^*_{\\Gamma}$ of\n$\\texttt{opt}_{\\Gamma}\\Sigma^M_0$\". Secondly, it is offered a pseudo-polynomial\ntotal-time recursive procedure for enumerating (w/o repetitions) all the\nelements of $\\mathcal{X}^*_{\\Gamma}$, and for computing the corresponding\npartitioning of $\\texttt{opt}_{\\Gamma}\\Sigma^M_0$. It is observed that the\ncorresponding recursion tree defines an additional lattice\n$\\mathcal{B}^*_{\\Gamma}$, whose elements are certain subgames $\\Gamma'\\subseteq\n\\Gamma$ that we call basic subgames. The extremal-SEPMs of a given \\MPG\n$\\Gamma$ coincide with the least-SEPMs of the basic subgames of $\\Gamma$; so,\n$\\mathcal{X}^*_{\\Gamma}$ is the energy-lattice comprising all and only the\nleast-SEPMs of the \\emph{basic} subgames of $\\Gamma$. The complexity of the\nproposed enumeration for both $\\mathcal{B}^*_{\\Gamma}$ and\n$\\mathcal{X}^*_{\\Gamma}$ is $O(|V|^3|E|W |\\mathcal{B}^*_{\\Gamma}|)$ total time\nand $O(|V||E|)+\\Theta\\big(|E| \\mathcal{B}^*_{\\Gamma}|\\big)$ working space.\nFinally, it is constructed an \\MPG $\\Gamma$ for which $|\\mathcal{B}^*_{\\Gamma}|\n> |\\mathcal{X}^*_\\Gamma|$, this proves that $\\mathcal{B}^*_{\\Gamma}$ and\n$\\mathcal{X}^*_\\Gamma$ are not isomorphic. \n\n"}
{"id": "1508.02452", "contents": "Title: Primal-Dual Active-Set Methods for Isotonic Regression and Trend\n  Filtering Abstract: Isotonic regression (IR) is a non-parametric calibration method used in\nsupervised learning. For performing large-scale IR, we propose a primal-dual\nactive-set (PDAS) algorithm which, in contrast to the state-of-the-art Pool\nAdjacent Violators (PAV) algorithm, can be parallized and is easily\nwarm-started thus well-suited in the online settings. We prove that, like the\nPAV algorithm, our PDAS algorithm for IR is convergent and has a work\ncomplexity of O(n), though our numerical experiments suggest that our PDAS\nalgorithm is often faster than PAV. In addition, we propose PDAS variants (with\nsafeguarding to ensure convergence) for solving related trend filtering (TF)\nproblems, providing the results of experiments to illustrate their\neffectiveness. \n\n"}
{"id": "1508.03391", "contents": "Title: Reward Shaping with Recurrent Neural Networks for Speeding up On-Line\n  Policy Learning in Spoken Dialogue Systems Abstract: Statistical spoken dialogue systems have the attractive property of being\nable to be optimised from data via interactions with real users. However in the\nreinforcement learning paradigm the dialogue manager (agent) often requires\nsignificant time to explore the state-action space to learn to behave in a\ndesirable manner. This is a critical issue when the system is trained on-line\nwith real users where learning costs are expensive. Reward shaping is one\npromising technique for addressing these concerns. Here we examine three\nrecurrent neural network (RNN) approaches for providing reward shaping\ninformation in addition to the primary (task-orientated) environmental\nfeedback. These RNNs are trained on returns from dialogues generated by a\nsimulated user and attempt to diffuse the overall evaluation of the dialogue\nback down to the turn level to guide the agent towards good behaviour faster.\nIn both simulated and real user scenarios these RNNs are shown to increase\npolicy learning speed. Importantly, they do not require prior knowledge of the\nuser's goal. \n\n"}
{"id": "1508.03735", "contents": "Title: Coordination Complexity: Small Information Coordinating Large\n  Populations Abstract: We initiate the study of a quantity that we call coordination complexity. In\na distributed optimization problem, the information defining a problem instance\nis distributed among $n$ parties, who need to each choose an action, which\njointly will form a solution to the optimization problem. The coordination\ncomplexity represents the minimal amount of information that a centralized\ncoordinator, who has full knowledge of the problem instance, needs to broadcast\nin order to coordinate the $n$ parties to play a nearly optimal solution.\n  We show that upper bounds on the coordination complexity of a problem imply\nthe existence of good jointly differentially private algorithms for solving\nthat problem, which in turn are known to upper bound the price of anarchy in\ncertain games with dynamically changing populations.\n  We show several results. We fully characterize the coordination complexity\nfor the problem of computing a many-to-one matching in a bipartite graph by\ngiving almost matching lower and upper bounds.Our upper bound in fact extends\nmuch more generally, to the problem of solving a linearly separable convex\nprogram. We also give a different upper bound technique, which we use to bound\nthe coordination complexity of coordinating a Nash equilibrium in a routing\ngame, and of computing a stable matching. \n\n"}
{"id": "1508.05288", "contents": "Title: Dynamics of Human Cooperation in Economic Games Abstract: Human decision behaviour is quite diverse. In many games humans on average do\nnot achieve maximal payoff and the behaviour of individual players remains\ninhomogeneous even after playing many rounds. For instance, in repeated\nprisoner dilemma games humans do not always optimize their mean reward and\nfrequently exhibit broad distributions of cooperativity. The reasons for these\nfailures of maximization are not known. Here we show that the dynamics\nresulting from the tendency to shift choice probabilities towards previously\nrewarding choices in closed loop interaction with the strategy of the opponent\ncan not only explain systematic deviations from 'rationality', but also\nreproduce the diversity of choice behaviours. As a representative example we\ninvestigate the dynamics of choice probabilities in prisoner dilemma games with\nopponents using strategies with different degrees of extortion and generosity.\nWe find that already a simple model for human learning can account for a\nsurprisingly wide range of human decision behaviours. It reproduces suppression\nof cooperation against extortionists and increasing cooperation when playing\nwith generous opponents, explains the broad distributions of individual choices\nin ensembles of players, and predicts the evolution of individual subjects'\ncooperation rates over the course of the games. We conclude that important\naspects of human decision behaviours are rooted in elementary learning\nmechanisms realised in the brain. \n\n"}
{"id": "1508.06585", "contents": "Title: Towards universal neural nets: Gibbs machines and ACE Abstract: We study from a physics viewpoint a class of generative neural nets, Gibbs\nmachines, designed for gradual learning. While including variational\nauto-encoders, they offer a broader universal platform for incrementally adding\nnewly learned features, including physical symmetries. Their direct connection\nto statistical physics and information geometry is established. A variational\nPythagorean theorem justifies invoking the exponential/Gibbs class of\nprobabilities for creating brand new objects. Combining these nets with\nclassifiers, gives rise to a brand of universal generative neural nets -\nstochastic auto-classifier-encoders (ACE). ACE have state-of-the-art\nperformance in their class, both for classification and density estimation for\nthe MNIST data set. \n\n"}
{"id": "1508.07192", "contents": "Title: Varying-coefficient models with isotropic Gaussian process priors Abstract: We study learning problems in which the conditional distribution of the\noutput given the input varies as a function of additional task variables. In\nvarying-coefficient models with Gaussian process priors, a Gaussian process\ngenerates the functional relationship between the task variables and the\nparameters of this conditional. Varying-coefficient models subsume hierarchical\nBayesian multitask models, but also generalizations in which the conditional\nvaries continuously, for instance, in time or space. However, Bayesian\ninference in varying-coefficient models is generally intractable. We show that\ninference for varying-coefficient models with isotropic Gaussian process priors\nresolves to standard inference for a Gaussian process that can be solved\nefficiently. MAP inference in this model resolves to multitask learning using\ntask and instance kernels, and inference for hierarchical Bayesian multitask\nmodels can be carried out efficiently using graph-Laplacian kernels. We report\non experiments for geospatial prediction. \n\n"}
{"id": "1508.07933", "contents": "Title: Coordinate Dual Averaging for Decentralized Online Optimization with\n  Nonseparable Global Objectives Abstract: We consider a decentralized online convex optimization problem in a network\nof agents, where each agent controls only a coordinate (or a part) of the\nglobal decision vector. For such a problem, we propose two decentralized\nvariants (ODA-C and ODA-PS) of Nesterov's primal-dual algorithm with dual\naveraging. In ODA-C, to mitigate the disagreements on the primal-vector\nupdates, the agents implement a generalization of the local\ninformation-exchange dynamics recently proposed by Li and Marden over a static\nundirected graph. In ODA-PS, the agents implement the broadcast-based push-sum\ndynamics over a time-varying sequence of uniformly connected digraphs. We show\nthat the regret bounds in both cases have sublinear growth of $O(\\sqrt{T})$,\nwith the time horizon $T$, when the stepsize is of the form $1/\\sqrt{t}$ and\nthe objective functions are Lipschitz-continuous convex functions with\nLipschitz gradients. We also implement the proposed algorithms on a sensor\nnetwork to complement our theoretical analysis. \n\n"}
{"id": "1509.04640", "contents": "Title: Dynamic Poisson Factorization Abstract: Models for recommender systems use latent factors to explain the preferences\nand behaviors of users with respect to a set of items (e.g., movies, books,\nacademic papers). Typically, the latent factors are assumed to be static and,\ngiven these factors, the observed preferences and behaviors of users are\nassumed to be generated without order. These assumptions limit the explorative\nand predictive capabilities of such models, since users' interests and item\npopularity may evolve over time. To address this, we propose dPF, a dynamic\nmatrix factorization model based on the recent Poisson factorization model for\nrecommendations. dPF models the time evolving latent factors with a Kalman\nfilter and the actions with Poisson distributions. We derive a scalable\nvariational inference algorithm to infer the latent factors. Finally, we\ndemonstrate dPF on 10 years of user click data from arXiv.org, one of the\nlargest repository of scientific papers and a formidable source of information\nabout the behavior of scientists. Empirically we show performance improvement\nover both static and, more recently proposed, dynamic recommendation models. We\nalso provide a thorough exploration of the inferred posteriors over the latent\nvariables. \n\n"}
{"id": "1509.05497", "contents": "Title: Quadratic Gaussian Privacy Games Abstract: A game-theoretic model for analysing the effects of privacy on strategic\ncommunication between agents is devised. In the model, a sender wishes to\nprovide an accurate measurement of the state to a receiver while also\nprotecting its private information (which is correlated with the state) private\nfrom a malicious agent that may eavesdrop on its communications with the\nreceiver. A family of nontrivial equilibria, in which the communicated messages\ncarry information, is constructed and its properties are studied. \n\n"}
{"id": "1509.06791", "contents": "Title: Learning Deep Control Policies for Autonomous Aerial Vehicles with\n  MPC-Guided Policy Search Abstract: Model predictive control (MPC) is an effective method for controlling robotic\nsystems, particularly autonomous aerial vehicles such as quadcopters. However,\napplication of MPC can be computationally demanding, and typically requires\nestimating the state of the system, which can be challenging in complex,\nunstructured environments. Reinforcement learning can in principle forego the\nneed for explicit state estimation and acquire a policy that directly maps\nsensor readings to actions, but is difficult to apply to unstable systems that\nare liable to fail catastrophically during training before an effective policy\nhas been found. We propose to combine MPC with reinforcement learning in the\nframework of guided policy search, where MPC is used to generate data at\ntraining time, under full state observations provided by an instrumented\ntraining environment. This data is used to train a deep neural network policy,\nwhich is allowed to access only the raw observations from the vehicle's onboard\nsensors. After training, the neural network policy can successfully control the\nrobot without knowledge of the full state, and at a fraction of the\ncomputational cost of MPC. We evaluate our method by learning obstacle\navoidance policies for a simulated quadrotor, using simulated onboard sensors\nand no explicit state estimation at test time. \n\n"}
{"id": "1509.07078", "contents": "Title: Detecting phase transitions in collective behavior using manifold's\n  curvature Abstract: If a given behavior of a multi-agent system restricts the phase variable to a\ninvariant manifold, then we define a phase transition as change of physical\ncharacteristics such as speed, coordination, and structure. We define such a\nphase transition as splitting an underlying manifold into two sub-manifolds\nwith distinct dimensionalities around the singularity where the phase\ntransition physically exists. Here, we propose a method of detecting phase\ntransitions and splitting the manifold into phase transitions free\nsub-manifolds. Therein, we utilize a relationship between curvature and\nsingular value ratio of points sampled in a curve, and then extend the\nassertion into higher-dimensions using the shape operator. Then we attest that\nthe same phase transition can also be approximated by singular value ratios\ncomputed locally over the data in a neighborhood on the manifold. We validate\nthe phase transitions detection method using one particle simulation and three\nreal world examples. \n\n"}
{"id": "1509.07577", "contents": "Title: A Review of Feature Selection Methods Based on Mutual Information Abstract: In this work we present a review of the state of the art of information\ntheoretic feature selection methods. The concepts of feature relevance,\nredundance and complementarity (synergy) are clearly defined, as well as Markov\nblanket. The problem of optimal feature selection is defined. A unifying\ntheoretical framework is described, which can retrofit successful heuristic\ncriteria, indicating the approximations made by each method. A number of open\nproblems in the field are presented. \n\n"}
{"id": "1509.08581", "contents": "Title: Optimization over Sparse Symmetric Sets via a Nonmonotone Projected\n  Gradient Method Abstract: We consider the problem of minimizing a Lipschitz differentiable function\nover a class of sparse symmetric sets that has wide applications in engineering\nand science. For this problem, it is known that any accumulation point of the\nclassical projected gradient (PG) method with a constant stepsize $1/L$\nsatisfies the $L$-stationarity optimality condition that was introduced in [3].\nIn this paper we introduce a new optimality condition that is stronger than the\n$L$-stationarity optimality condition. We also propose a nonmonotone projected\ngradient (NPG) method for this problem by incorporating some support-changing\nand coordintate-swapping strategies into a projected gradient method with\nvariable stepsizes. It is shown that any accumulation point of NPG satisfies\nthe new optimality condition and moreover it is a coordinatewise stationary\npoint. Under some suitable assumptions, we further show that it is a global or\na local minimizer of the problem. Numerical experiments are conducted to\ncompare the performance of PG and NPG. The computational results demonstrate\nthat NPG has substantially better solution quality than PG, and moreover, it is\nat least comparable to, but sometimes can be much faster than PG in terms of\nspeed. \n\n"}
{"id": "1509.09130", "contents": "Title: Learning From Missing Data Using Selection Bias in Movie Recommendation Abstract: Recommending items to users is a challenging task due to the large amount of\nmissing information. In many cases, the data solely consist of ratings or tags\nvoluntarily contributed by each user on a very limited subset of the available\nitems, so that most of the data of potential interest is actually missing.\nCurrent approaches to recommendation usually assume that the unobserved data is\nmissing at random. In this contribution, we provide statistical evidence that\nexisting movie recommendation datasets reveal a significant positive\nassociation between the rating of items and the propensity to select these\nitems. We propose a computationally efficient variational approach that makes\nit possible to exploit this selection bias so as to improve the estimation of\nratings from small populations of users. Results obtained with this approach\napplied to neighborhood-based collaborative filtering illustrate its potential\nfor improving the reliability of the recommendation. \n\n"}
{"id": "1510.00259", "contents": "Title: A Generative Model of Words and Relationships from Multiple Sources Abstract: Neural language models are a powerful tool to embed words into semantic\nvector spaces. However, learning such models generally relies on the\navailability of abundant and diverse training examples. In highly specialised\ndomains this requirement may not be met due to difficulties in obtaining a\nlarge corpus, or the limited range of expression in average use. Such domains\nmay encode prior knowledge about entities in a knowledge base or ontology. We\npropose a generative model which integrates evidence from diverse data sources,\nenabling the sharing of semantic information. We achieve this by generalising\nthe concept of co-occurrence from distributional semantics to include other\nrelationships between entities or words, which we model as affine\ntransformations on the embedding space. We demonstrate the effectiveness of\nthis approach by outperforming recent models on a link prediction task and\ndemonstrating its ability to profit from partially or fully unobserved data\ntraining labels. We further demonstrate the usefulness of learning from\ndifferent data sources with overlapping vocabularies. \n\n"}
{"id": "1510.01378", "contents": "Title: Batch Normalized Recurrent Neural Networks Abstract: Recurrent Neural Networks (RNNs) are powerful models for sequential data that\nhave the potential to learn long-term dependencies. However, they are\ncomputationally expensive to train and difficult to parallelize. Recent work\nhas shown that normalizing intermediate representations of neural networks can\nsignificantly improve convergence rates in feedforward neural networks . In\nparticular, batch normalization, which uses mini-batch statistics to\nstandardize features, was shown to significantly reduce training time. In this\npaper, we show that applying batch normalization to the hidden-to-hidden\ntransitions of our RNNs doesn't help the training procedure. We also show that\nwhen applied to the input-to-hidden transitions, batch normalization can lead\nto a faster convergence of the training criterion but doesn't seem to improve\nthe generalization performance on both our language modelling and speech\nrecognition tasks. All in all, applying batch normalization to RNNs turns out\nto be more challenging than applying it to feedforward networks, but certain\nvariants of it can still be beneficial. \n\n"}
{"id": "1510.03495", "contents": "Title: Privacy Constrained Information Processing Abstract: This paper studies communication scenarios where the transmitter and the\nreceiver have different objectives due to privacy concerns, in the context of a\nvariation of the strategic information transfer (SIT) model of Sobel and\nCrawford. We first formulate the problem as the minimization of a common\ndistortion by the transmitter and the receiver subject to a privacy constrained\ntransmitter. We show the equivalence of this formulation to a Stackelberg\nequilibrium of the SIT problem. Assuming an entropy based privacy measure, a\nquadratic distortion measure and jointly Gaussian variables, we characterize\nthe Stackelberg equilibrium. Next, we consider asymptotically optimal\ncompression at the transmitter which inherently provides some level of privacy,\nand study equilibrium conditions. We finally analyze the impact of the presence\nof an average power constrained Gaussian communication channel between the\ntransmitter and the receiver on the equilibrium conditions. \n\n"}
{"id": "1510.06684", "contents": "Title: Dual Free Adaptive Mini-batch SDCA for Empirical Risk Minimization Abstract: In this paper we develop dual free mini-batch SDCA with adaptive\nprobabilities for regularized empirical risk minimization. This work is\nmotivated by recent work of Shai Shalev-Shwartz on dual free SDCA method,\nhowever, we allow a non-uniform selection of \"dual\" coordinates in SDCA.\nMoreover, the probability can change over time, making it more efficient than\nfix uniform or non-uniform selection. We also propose an efficient procedure to\ngenerate a random non-uniform mini-batch through iterative process. The work is\nconcluded with multiple numerical experiments to show the efficiency of\nproposed algorithms. \n\n"}
{"id": "1510.06688", "contents": "Title: Partitioning Data on Features or Samples in Communication-Efficient\n  Distributed Optimization? Abstract: In this paper we study the effect of the way that the data is partitioned in\ndistributed optimization. The original DiSCO algorithm [Communication-Efficient\nDistributed Optimization of Self-Concordant Empirical Loss, Yuchen Zhang and\nLin Xiao, 2015] partitions the input data based on samples. We describe how the\noriginal algorithm has to be modified to allow partitioning on features and\nshow its efficiency both in theory and also in practice. \n\n"}
{"id": "1510.08983", "contents": "Title: Highway Long Short-Term Memory RNNs for Distant Speech Recognition Abstract: In this paper, we extend the deep long short-term memory (DLSTM) recurrent\nneural networks by introducing gated direct connections between memory cells in\nadjacent layers. These direct links, called highway connections, enable\nunimpeded information flow across different layers and thus alleviate the\ngradient vanishing problem when building deeper LSTMs. We further introduce the\nlatency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole\nhistory while keeping the latency under control. Efficient algorithms are\nproposed to train these novel networks using both frame and sequence\ndiscriminative criteria. Experiments on the AMI distant speech recognition\n(DSR) task indicate that we can train deeper LSTMs and achieve better\nimprovement from sequence training with highway LSTMs (HLSTMs). Our novel model\nobtains $43.9/47.7\\%$ WER on AMI (SDM) dev and eval sets, outperforming all\nprevious works. It beats the strong DNN and DLSTM baselines with $15.7\\%$ and\n$5.3\\%$ relative improvement respectively. \n\n"}
{"id": "1511.01865", "contents": "Title: Convolutional Neural Network for Stereotypical Motor Movement Detection\n  in Autism Abstract: Autism Spectrum Disorders (ASDs) are often associated with specific atypical\npostural or motor behaviors, of which Stereotypical Motor Movements (SMMs) have\na specific visibility. While the identification and the quantification of SMM\npatterns remain complex, its automation would provide support to accurate\ntuning of the intervention in the therapy of autism. Therefore, it is essential\nto develop automatic SMM detection systems in a real world setting, taking care\nof strong inter-subject and intra-subject variability. Wireless accelerometer\nsensing technology can provide a valid infrastructure for real-time SMM\ndetection, however such variability remains a problem also for machine learning\nmethods, in particular whenever handcrafted features extracted from\naccelerometer signal are considered. Here, we propose to employ the deep\nlearning paradigm in order to learn discriminating features from multi-sensor\naccelerometer signals. Our results provide preliminary evidence that feature\nlearning and transfer learning embedded in the deep architecture achieve higher\naccurate SMM detectors in longitudinal scenarios. \n\n"}
{"id": "1511.04143", "contents": "Title: Deep Reinforcement Learning in Parameterized Action Space Abstract: Recent work has shown that deep neural networks are capable of approximating\nboth value functions and policies in reinforcement learning domains featuring\ncontinuous state and action spaces. However, to the best of our knowledge no\nprevious work has succeeded at using deep neural networks in structured\n(parameterized) continuous action spaces. To fill this gap, this paper focuses\non learning within the domain of simulated RoboCup soccer, which features a\nsmall set of discrete action types, each of which is parameterized with\ncontinuous variables. The best learned agent can score goals more reliably than\nthe 2012 RoboCup champion agent. As such, this paper represents a successful\nextension of deep reinforcement learning to the class of parameterized action\nspace MDPs. \n\n"}
{"id": "1511.04813", "contents": "Title: Budget Online Multiple Kernel Learning Abstract: Online learning with multiple kernels has gained increasing interests in\nrecent years and found many applications. For classification tasks, Online\nMultiple Kernel Classification (OMKC), which learns a kernel based classifier\nby seeking the optimal linear combination of a pool of single kernel\nclassifiers in an online fashion, achieves superior accuracy and enjoys great\nflexibility compared with traditional single-kernel classifiers. Despite being\nstudied extensively, existing OMKC algorithms suffer from high computational\ncost due to their unbounded numbers of support vectors. To overcome this\ndrawback, we present a novel framework of Budget Online Multiple Kernel\nLearning (BOMKL) and propose a new Sparse Passive Aggressive learning to\nperform effective budget online learning. Specifically, we adopt a simple yet\neffective Bernoulli sampling to decide if an incoming instance should be added\nto the current set of support vectors. By limiting the number of support\nvectors, our method can significantly accelerate OMKC while maintaining\nsatisfactory accuracy that is comparable to that of the existing OMKC\nalgorithms. We theoretically prove that our new method achieves an optimal\nregret bound in expectation, and empirically found that the proposed algorithm\noutperforms various OMKC algorithms and can easily scale up to large-scale\ndatasets. \n\n"}
{"id": "1511.05932", "contents": "Title: On the Global Linear Convergence of Frank-Wolfe Optimization Variants Abstract: The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularity\nthanks in particular to its ability to nicely handle the structured constraints\nappearing in machine learning applications. However, its convergence rate is\nknown to be slow (sublinear) when the solution lies at the boundary. A simple\nless-known fix is to add the possibility to take 'away steps' during\noptimization, an operation that importantly does not require a feasibility\noracle. In this paper, we highlight and clarify several variants of the\nFrank-Wolfe optimization algorithm that have been successfully applied in\npractice: away-steps FW, pairwise FW, fully-corrective FW and Wolfe's minimum\nnorm point algorithm, and prove for the first time that they all enjoy global\nlinear convergence, under a weaker condition than strong convexity of the\nobjective. The constant in the convergence rate has an elegant interpretation\nas the product of the (classical) condition number of the function with a novel\ngeometric quantity that plays the role of a 'condition number' of the\nconstraint set. We provide pointers to where these algorithms have made a\ndifference in practice, in particular with the flow polytope, the marginal\npolytope and the base polytope for submodular optimization. \n\n"}
{"id": "1511.06429", "contents": "Title: Patterns for Learning with Side Information Abstract: Supervised, semi-supervised, and unsupervised learning estimate a function\ngiven input/output samples. Generalization of the learned function to unseen\ndata can be improved by incorporating side information into learning. Side\ninformation are data that are neither from the input space nor from the output\nspace of the function, but include useful information for learning it. In this\npaper we show that learning with side information subsumes a variety of related\napproaches, e.g. multi-task learning, multi-view learning and learning using\nprivileged information. Our main contributions are (i) a new perspective that\nconnects these previously isolated approaches, (ii) insights about how these\nmethods incorporate different types of prior knowledge, and hence implement\ndifferent patterns, (iii) facilitating the application of these methods in\nnovel tasks, as well as (iv) a systematic experimental evaluation of these\npatterns in two supervised learning tasks. \n\n"}
{"id": "1511.06430", "contents": "Title: Deconstructing the Ladder Network Architecture Abstract: The Manual labeling of data is and will remain a costly endeavor. For this\nreason, semi-supervised learning remains a topic of practical importance. The\nrecently proposed Ladder Network is one such approach that has proven to be\nvery successful. In addition to the supervised objective, the Ladder Network\nalso adds an unsupervised objective corresponding to the reconstruction costs\nof a stack of denoising autoencoders. Although the empirical results are\nimpressive, the Ladder Network has many components intertwined, whose\ncontributions are not obvious in such a complex architecture. In order to help\nelucidate and disentangle the different ingredients in the Ladder Network\nrecipe, this paper presents an extensive experimental investigation of variants\nof the Ladder Network in which we replace or remove individual components to\ngain more insight into their relative importance. We find that all of the\ncomponents are necessary for achieving optimal performance, but they do not\ncontribute equally. For semi-supervised tasks, we conclude that the most\nimportant contribution is made by the lateral connection, followed by the\napplication of noise, and finally the choice of what we refer to as the\n`combinator function' in the decoder path. We also find that as the number of\nlabeled training examples increases, the lateral connections and reconstruction\ncriterion become less important, with most of the improvement in generalization\nbeing due to the injection of noise in each layer. Furthermore, we present a\nnew type of combinator function that outperforms the original design in both\nfully- and semi-supervised tasks, reducing record test error rates on\nPermutation-Invariant MNIST to 0.57% for the supervised setting, and to 0.97%\nand 1.0% for semi-supervised settings with 1000 and 100 labeled examples\nrespectively. \n\n"}
{"id": "1511.06909", "contents": "Title: BlackOut: Speeding up Recurrent Neural Network Language Models With Very\n  Large Vocabularies Abstract: We propose BlackOut, an approximation algorithm to efficiently train massive\nrecurrent neural network language models (RNNLMs) with million word\nvocabularies. BlackOut is motivated by using a discriminative loss, and we\ndescribe a new sampling strategy which significantly reduces computation while\nimproving stability, sample efficiency, and rate of convergence. One way to\nunderstand BlackOut is to view it as an extension of the DropOut strategy to\nthe output layer, wherein we use a discriminative training loss and a weighted\nsampling scheme. We also establish close connections between BlackOut,\nimportance sampling, and noise contrastive estimation (NCE). Our experiments,\non the recently released one billion word language modeling benchmark,\ndemonstrate scalability and accuracy of BlackOut; we outperform the\nstate-of-the art, and achieve the lowest perplexity scores on this dataset.\nMoreover, unlike other established methods which typically require GPUs or CPU\nclusters, we show that a carefully implemented version of BlackOut requires\nonly 1-10 days on a single machine to train a RNNLM with a million word\nvocabulary and billions of parameters on one billion words. Although we\ndescribe BlackOut in the context of RNNLM training, it can be used to any\nnetworks with large softmax output layers. \n\n"}
{"id": "1511.07125", "contents": "Title: What Happened to My Dog in That Network: Unraveling Top-down Generators\n  in Convolutional Neural Networks Abstract: Top-down information plays a central role in human perception, but plays\nrelatively little role in many current state-of-the-art deep networks, such as\nConvolutional Neural Networks (CNNs). This work seeks to explore a path by\nwhich top-down information can have a direct impact within current deep\nnetworks. We explore this path by learning and using \"generators\" corresponding\nto the network internal effects of three types of transformation (each a\nrestriction of a general affine transformation): rotation, scaling, and\ntranslation. We demonstrate how these learned generators can be used to\ntransfer top-down information to novel settings, as mediated by the \"feature\nflows\" that the transformations (and the associated generators) correspond to\ninside the network. Specifically, we explore three aspects: 1) using generators\nas part of a method for synthesizing transformed images --- given a previously\nunseen image, produce versions of that image corresponding to one or more\nspecified transformations, 2) \"zero-shot learning\" --- when provided with a\nfeature flow corresponding to the effect of a transformation of unknown amount,\nleverage learned generators as part of a method by which to perform an accurate\ncategorization of the amount of transformation, even for amounts never observed\nduring training, and 3) (inside-CNN) \"data augmentation\" --- improve the\nclassification performance of an existing network by using the learned\ngenerators to directly provide additional training \"inside the CNN\". \n\n"}
{"id": "1511.07902", "contents": "Title: Performance Limits of Stochastic Sub-Gradient Learning, Part I: Single\n  Agent Case Abstract: In this work and the supporting Part II, we examine the performance of\nstochastic sub-gradient learning strategies under weaker conditions than\nusually considered in the literature. The new conditions are shown to be\nautomatically satisfied by several important cases of interest including SVM,\nLASSO, and Total-Variation denoising formulations. In comparison, these\nproblems do not satisfy the traditional assumptions used in prior analyses and,\ntherefore, conclusions derived from these earlier treatments are not directly\napplicable to these problems. The results in this article establish that\nstochastic sub-gradient strategies can attain linear convergence rates, as\nopposed to sub-linear rates, to the steady-state regime. A realizable\nexponential-weighting procedure is employed to smooth the intermediate iterates\nand guarantee useful performance bounds in terms of convergence rate and\nexcessive risk performance. Part I of this work focuses on single-agent\nscenarios, which are common in stand-alone learning applications, while Part II\nextends the analysis to networked learners. The theoretical conclusions are\nillustrated by several examples and simulations, including comparisons with the\nFISTA procedure. \n\n"}
{"id": "1511.08062", "contents": "Title: Relaxed Majorization-Minimization for Non-smooth and Non-convex\n  Optimization Abstract: We propose a new majorization-minimization (MM) method for non-smooth and\nnon-convex programs, which is general enough to include the existing MM\nmethods. Besides the local majorization condition, we only require that the\ndifference between the directional derivatives of the objective function and\nits surrogate function vanishes when the number of iterations approaches\ninfinity, which is a very weak condition. So our method can use a surrogate\nfunction that directly approximates the non-smooth objective function. In\ncomparison, all the existing MM methods construct the surrogate function by\napproximating the smooth component of the objective function. We apply our\nrelaxed MM methods to the robust matrix factorization (RMF) problem with\ndifferent regularizations, where our locally majorant algorithm shows\nadvantages over the state-of-the-art approaches for RMF. This is the first\nalgorithm for RMF ensuring, without extra assumptions, that any limit point of\nthe iterates is a stationary point. \n\n"}
{"id": "1511.09180", "contents": "Title: Asynchronous adaptive networks Abstract: In a recent article [1] we surveyed advances related to adaptation, learning,\nand optimization over synchronous networks. Various distributed strategies were\ndiscussed that enable a collection of networked agents to interact locally in\nresponse to streaming data and to continually learn and adapt to track drifts\nin the data and models. Under reasonable technical conditions on the data, the\nadaptive networks were shown to be mean-square stable in the slow adaptation\nregime, and their mean-square-error performance and convergence rate were\ncharacterized in terms of the network topology and data statistical moments\n[2]. Classical results for single-agent adaptation and learning were recovered\nas special cases. Following the works [3]-[5], this chapter complements the\nexposition from [1] and extends the results to asynchronous networks. The\noperation of this class of networks can be subject to various sources of\nuncertainties that influence their dynamic behavior, including randomly\nchanging topologies, random link failures, random data arrival times, and\nagents turning on and off randomly. In an asynchronous environment, agents may\nstop updating their solutions or may stop sending or receiving information in a\nrandom manner and without coordination with other agents. The presentation will\nreveal that the mean-square-error performance of asynchronous networks remains\nlargely unaltered compared to synchronous networks. The results justify the\nremarkable resilience of cooperative networks in the face of random events. \n\n"}
{"id": "1512.03549", "contents": "Title: Words are not Equal: Graded Weighting Model for building Composite\n  Document Vectors Abstract: Despite the success of distributional semantics, composing phrases from word\nvectors remains an important challenge. Several methods have been tried for\nbenchmark tasks such as sentiment classification, including word vector\naveraging, matrix-vector approaches based on parsing, and on-the-fly learning\nof paragraph vectors. Most models usually omit stop words from the composition.\nInstead of such an yes-no decision, we consider several graded schemes where\nwords are weighted according to their discriminatory relevance with respect to\nits use in the document (e.g., idf). Some of these methods (particularly\ntf-idf) are seen to result in a significant improvement in performance over\nprior state of the art. Further, combining such approaches into an ensemble\nbased on alternate classifiers such as the RNN model, results in an 1.6%\nperformance improvement on the standard IMDB movie review dataset, and a 7.01%\nimprovement on Amazon product reviews. Since these are language free models and\ncan be obtained in an unsupervised manner, they are of interest also for\nunder-resourced languages such as Hindi as well and many more languages. We\ndemonstrate the language free aspects by showing a gain of 12% for two review\ndatasets over earlier results, and also release a new larger dataset for future\ntesting (Singh,2015). \n\n"}
{"id": "1512.04017", "contents": "Title: The price of anarchy and stability in general noisy best-response\n  dynamics Abstract: Logit-response dynamics (Alos-Ferrer and Netzer, Games and Economic Behavior\n2010) are a rich and natural class of noisy best-response dynamics. In this\nwork we revise the price of anarchy and the price of stability by considering\nthe quality of long-run equilibria in these dynamics. Our results show that\nprior studies on simpler dynamics of this type can strongly depend on a\nsynchronous schedule of the players' moves. In particular, a small noise by\nitself is not enough to improve the quality of equilibria as soon as other very\nnatural schedules are used. \n\n"}
{"id": "1601.03754", "contents": "Title: Dual-tree $k$-means with bounded iteration runtime Abstract: k-means is a widely used clustering algorithm, but for $k$ clusters and a\ndataset size of $N$, each iteration of Lloyd's algorithm costs $O(kN)$ time.\nAlthough there are existing techniques to accelerate single Lloyd iterations,\nnone of these are tailored to the case of large $k$, which is increasingly\ncommon as dataset sizes grow. We propose a dual-tree algorithm that gives the\nexact same results as standard $k$-means; when using cover trees, we use\nadaptive analysis techniques to, under some assumptions, bound the\nsingle-iteration runtime of the algorithm as $O(N + k log k)$. To our knowledge\nthese are the first sub-$O(kN)$ bounds for exact Lloyd iterations. We then show\nthat this theoretically favorable algorithm performs competitively in practice,\nespecially for large $N$ and $k$ in low dimensions. Further, the algorithm is\ntree-independent, so any type of tree may be used. \n\n"}
{"id": "1601.04737", "contents": "Title: Sub-Sampled Newton Methods I: Globally Convergent Algorithms Abstract: Large scale optimization problems are ubiquitous in machine learning and data\nanalysis and there is a plethora of algorithms for solving such problems. Many\nof these algorithms employ sub-sampling, as a way to either speed up the\ncomputations and/or to implicitly implement a form of statistical\nregularization. In this paper, we consider second-order iterative optimization\nalgorithms and we provide bounds on the convergence of the variants of Newton's\nmethod that incorporate uniform sub-sampling as a means to estimate the\ngradient and/or Hessian. Our bounds are non-asymptotic and quantitative. Our\nalgorithms are global and are guaranteed to converge from any initial iterate.\n  Using random matrix concentration inequalities, one can sub-sample the\nHessian to preserve the curvature information. Our first algorithm incorporates\nHessian sub-sampling while using the full gradient. We also give additional\nconvergence results for when the sub-sampled Hessian is regularized by\nmodifying its spectrum or ridge-type regularization. Next, in addition to\nHessian sub-sampling, we also consider sub-sampling the gradient as a way to\nfurther reduce the computational complexity per iteration. We use approximate\nmatrix multiplication results from randomized numerical linear algebra to\nobtain the proper sampling strategy. In all these algorithms, computing the\nupdate boils down to solving a large scale linear system, which can be\ncomputationally expensive. As a remedy, for all of our algorithms, we also give\nglobal convergence results for the case of inexact updates where such linear\nsystem is solved only approximately.\n  This paper has a more advanced companion paper, [42], in which we demonstrate\nthat, by doing a finer-grained analysis, we can get problem-independent bounds\nfor local convergence of these algorithms and explore trade-offs to improve\nupon the basic results of the present paper. \n\n"}
{"id": "1601.04738", "contents": "Title: Sub-Sampled Newton Methods II: Local Convergence Rates Abstract: Many data-fitting applications require the solution of an optimization\nproblem involving a sum of large number of functions of high dimensional\nparameter. Here, we consider the problem of minimizing a sum of $n$ functions\nover a convex constraint set $\\mathcal{X} \\subseteq \\mathbb{R}^{p}$ where both\n$n$ and $p$ are large. In such problems, sub-sampling as a way to reduce $n$\ncan offer great amount of computational efficiency.\n  Within the context of second order methods, we first give quantitative local\nconvergence results for variants of Newton's method where the Hessian is\nuniformly sub-sampled. Using random matrix concentration inequalities, one can\nsub-sample in a way that the curvature information is preserved. Using such\nsub-sampling strategy, we establish locally Q-linear and Q-superlinear\nconvergence rates. We also give additional convergence results for when the\nsub-sampled Hessian is regularized by modifying its spectrum or Levenberg-type\nregularization.\n  Finally, in addition to Hessian sub-sampling, we consider sub-sampling the\ngradient as way to further reduce the computational complexity per iteration.\nWe use approximate matrix multiplication results from randomized numerical\nlinear algebra (RandNLA) to obtain the proper sampling strategy and we\nestablish locally R-linear convergence rates. In such a setting, we also show\nthat a very aggressive sample size increase results in a R-superlinearly\nconvergent algorithm.\n  While the sample size depends on the condition number of the problem, our\nconvergence rates are problem-independent, i.e., they do not depend on the\nquantities related to the problem. Hence, our analysis here can be used to\ncomplement the results of our basic framework from the companion paper, [38],\nby exploring algorithmic trade-offs that are important in practice. \n\n"}
{"id": "1602.02159", "contents": "Title: Daleel: Simplifying Cloud Instance Selection Using Machine Learning Abstract: Decision making in cloud environments is quite challenging due to the\ndiversity in service offerings and pricing models, especially considering that\nthe cloud market is an incredibly fast moving one. In addition, there are no\nhard and fast rules, each customer has a specific set of constraints (e.g.\nbudget) and application requirements (e.g. minimum computational resources).\nMachine learning can help address some of the complicated decisions by carrying\nout customer-specific analytics to determine the most suitable instance type(s)\nand the most opportune time for starting or migrating instances. We employ\nmachine learning techniques to develop an adaptive deployment policy, providing\nan optimal match between the customer demands and the available cloud service\nofferings. We provide an experimental study based on extensive set of job\nexecutions over a major public cloud infrastructure. \n\n"}
{"id": "1602.02726", "contents": "Title: Local and Global Convergence of a General Inertial Proximal Splitting\n  Scheme Abstract: This paper is concerned with convex composite minimization problems in a\nHilbert space. In these problems, the objective is the sum of two closed,\nproper, and convex functions where one is smooth and the other admits a\ncomputationally inexpensive proximal operator. We analyze a general family of\ninertial proximal splitting algorithms (GIPSA) for solving such problems. We\nestablish finiteness of the sum of squared increments of the iterates and\noptimality of the accumulation points. Weak convergence of the entire sequence\nthen follows if the minimum is attained. Our analysis unifies and extends\nseveral previous results.\n  We then focus on $\\ell_1$-regularized optimization, which is the ubiquitous\nspecial case where the nonsmooth term is the $\\ell_1$-norm. For certain\nparameter choices, GIPSA is amenable to a local analysis for this problem. For\nthese choices we show that GIPSA achieves finite \"active manifold\nidentification\", i.e. convergence in a finite number of iterations to the\noptimal support and sign, after which GIPSA reduces to minimizing a local\nsmooth function. Local linear convergence then holds under certain conditions.\nWe determine the rate in terms of the inertia, stepsize, and local curvature.\nOur local analysis is applicable to certain recent variants of the Fast\nIterative Shrinkage-Thresholding Algorithm (FISTA), for which we establish\nactive manifold identification and local linear convergence. Our analysis\nmotivates the use of a momentum restart scheme in these FISTA variants to\nobtain the optimal local linear convergence rate. \n\n"}
{"id": "1602.06053", "contents": "Title: First-order Methods for Geodesically Convex Optimization Abstract: Geodesic convexity generalizes the notion of (vector space) convexity to\nnonlinear metric spaces. But unlike convex optimization, geodesically convex\n(g-convex) optimization is much less developed. In this paper we contribute to\nthe understanding of g-convex optimization by developing iteration complexity\nanalysis for several first-order algorithms on Hadamard manifolds.\nSpecifically, we prove upper bounds for the global complexity of deterministic\nand stochastic (sub)gradient methods for optimizing smooth and nonsmooth\ng-convex functions, both with and without strong g-convexity. Our analysis also\nreveals how the manifold geometry, especially \\emph{sectional curvature},\nimpacts convergence rates. To the best of our knowledge, our work is the first\nto provide global complexity analysis for first-order algorithms for general\ng-convex optimization. \n\n"}
{"id": "1602.06294", "contents": "Title: Stacking for machine learning redshifts applied to SDSS galaxies Abstract: We present an analysis of a general machine learning technique called\n'stacking' for the estimation of photometric redshifts. Stacking techniques can\nfeed the photometric redshift estimate, as output by a base algorithm, back\ninto the same algorithm as an additional input feature in a subsequent learning\nround. We shown how all tested base algorithms benefit from at least one\nadditional stacking round (or layer). To demonstrate the benefit of stacking,\nwe apply the method to both unsupervised machine learning techniques based on\nself-organising maps (SOMs), and supervised machine learning methods based on\ndecision trees. We explore a range of stacking architectures, such as the\nnumber of layers and the number of base learners per layer. Finally we explore\nthe effectiveness of stacking even when using a successful algorithm such as\nAdaBoost. We observe a significant improvement of between 1.9% and 21% on all\ncomputed metrics when stacking is applied to weak learners (such as SOMs and\ndecision trees). When applied to strong learning algorithms (such as AdaBoost)\nthe ratio of improvement shrinks, but still remains positive and is between\n0.4% and 2.5% for the explored metrics and comes at almost no additional\ncomputational cost. \n\n"}
{"id": "1602.06865", "contents": "Title: An Empirical Study on Computing Equilibria in Polymatrix Games Abstract: The Nash equilibrium is an important benchmark for behaviour in systems of\nstrategic autonomous agents. Polymatrix games are a succinct and expressive\nrepresentation of multiplayer games that model pairwise interactions between\nplayers. The empirical performance of algorithms to solve these games has\nreceived little attention, despite their wide-ranging applications. In this\npaper we carry out a comprehensive empirical study of two prominent algorithms\nfor computing a sample equilibrium in these games, Lemke's algorithm that\ncomputes an exact equilibrium, and a gradient descent method that computes an\napproximate equilibrium. Our study covers games arising from a number of\ninteresting applications. We find that Lemke's algorithm can compute exact\nequilibria in relatively large games in a reasonable amount of time. If we are\nwilling to accept (high-quality) approximate equilibria, then we can deal with\nmuch larger games using the descent method. We also report on which games are\nmost challenging for each of the algorithms. \n\n"}
{"id": "1602.07630", "contents": "Title: Online Dual Coordinate Ascent Learning Abstract: The stochastic dual coordinate-ascent (S-DCA) technique is a useful\nalternative to the traditional stochastic gradient-descent algorithm for\nsolving large-scale optimization problems due to its scalability to large data\nsets and strong theoretical guarantees. However, the available S-DCA\nformulation is limited to finite sample sizes and relies on performing multiple\npasses over the same data. This formulation is not well-suited for online\nimplementations where data keep streaming in. In this work, we develop an {\\em\nonline} dual coordinate-ascent (O-DCA) algorithm that is able to respond to\nstreaming data and does not need to revisit the past data. This feature embeds\nthe resulting construction with continuous adaptation, learning, and tracking\nabilities, which are particularly attractive for online learning scenarios. \n\n"}
{"id": "1602.07726", "contents": "Title: Adaptive Learning with Robust Generalization Guarantees Abstract: The traditional notion of generalization---i.e., learning a hypothesis whose\nempirical error is close to its true error---is surprisingly brittle. As has\nrecently been noted in [DFH+15b], even if several algorithms have this\nguarantee in isolation, the guarantee need not hold if the algorithms are\ncomposed adaptively. In this paper, we study three notions of\ngeneralization---increasing in strength---that are robust to postprocessing and\namenable to adaptive composition, and examine the relationships between them.\nWe call the weakest such notion Robust Generalization. A second, intermediate,\nnotion is the stability guarantee known as differential privacy. The strongest\nguarantee we consider we call Perfect Generalization. We prove that every\nhypothesis class that is PAC learnable is also PAC learnable in a robustly\ngeneralizing fashion, with almost the same sample complexity. It was previously\nknown that differentially private algorithms satisfy robust generalization. In\nthis paper, we show that robust generalization is a strictly weaker concept,\nand that there is a learning task that can be carried out subject to robust\ngeneralization guarantees, yet cannot be carried out subject to differential\nprivacy. We also show that perfect generalization is a strictly stronger\nguarantee than differential privacy, but that, nevertheless, many learning\ntasks can be carried out subject to the guarantees of perfect generalization. \n\n"}
{"id": "1602.08017", "contents": "Title: Meta-learning within Projective Simulation Abstract: Learning models of artificial intelligence can nowadays perform very well on\na large variety of tasks. However, in practice different task environments are\nbest handled by different learning models, rather than a single, universal,\napproach. Most non-trivial models thus require the adjustment of several to\nmany learning parameters, which is often done on a case-by-case basis by an\nexternal party. Meta-learning refers to the ability of an agent to autonomously\nand dynamically adjust its own learning parameters, or meta-parameters. In this\nwork we show how projective simulation, a recently developed model of\nartificial intelligence, can naturally be extended to account for meta-learning\nin reinforcement learning settings. The projective simulation approach is based\non a random walk process over a network of clips. The suggested meta-learning\nscheme builds upon the same design and employs clip networks to monitor the\nagent's performance and to adjust its meta-parameters \"on the fly\". We\ndistinguish between \"reflexive adaptation\" and \"adaptation through learning\",\nand show the utility of both approaches. In addition, a trade-off between\nflexibility and learning-time is addressed. The extended model is examined on\nthree different kinds of reinforcement learning tasks, in which the agent has\ndifferent optimal values of the meta-parameters, and is shown to perform well,\nreaching near-optimal to optimal success rates in all of them, without ever\nneeding to manually adjust any meta-parameter. \n\n"}
{"id": "1603.00226", "contents": "Title: Finding the Nucleoli of Large Cooperative Games: A Disproof with\n  Counter-Example Abstract: Nguyen and Thomas (2016) claimed that they have found a method to compute the\nnucleoli of games with more than $50$ players using nested linear programs\n(LP). Unfortunately, this claim is false. They incorrectly applied the indirect\nproof by \"$A \\land \\neg B$ implies $A \\land \\neg A$\" to conclude that \"if $A$\nthen $B$\" is valid. In fact, they prove that a truth implies a falsehood. As\nestablished by Meinhardt (2015a), this is a wrong statement. Therefore, instead\nof giving a proof of their main Theorem 4b, they give a disproof. It comes as\nno surprise to us that the flow game example presented by these authors to\nsupport their arguments is obviously a counter-example of their algorithm. We\nshow that the computed solution by this algorithm is neither the nucleolus nor\na core element of the flow game. Moreover, the stopping criterion of all\nproposed methods is wrong, since it does not satisfy one of Kohlberg's\nproperties (cf. Kohlberg (1971)). As a consequence, none of these algorithms is\nrobust. \n\n"}
{"id": "1603.00286", "contents": "Title: Redividing the Cake Abstract: The paper considers fair allocation of resources that are already allocated\nin an unfair way. This setting requires a careful balance between the fairness\nconsiderations and the rights of the present owners.\n  The paper presents re-division algorithms that attain various trade-off\npoints between fairness and ownership rights, in various settings differing in\nthe geometric constraints on the allotments: (a) no geometric constraints; (b)\nconnectivity -- the cake is a one-dimensional interval and each piece must be a\ncontiguous interval; (c) rectangularity -- the cake is a two-dimensional\nrectangle or rectilinear polygon and the pieces should be rectangles; (d)\nconvexity -- the cake is a two-dimensional convex polygon and the pieces should\nbe convex.\n  These re-division algorithms have implications on another problem: the\nprice-of-fairness -- the loss of social welfare caused by fairness\nrequirements. Each algorithm implies an upper bound on the price-of-fairness\nwith the respective geometric constraints. \n\n"}
{"id": "1603.01913", "contents": "Title: A Latent Variable Recurrent Neural Network for Discourse Relation\n  Language Models Abstract: This paper presents a novel latent variable recurrent neural network\narchitecture for jointly modeling sequences of words and (possibly latent)\ndiscourse relations between adjacent sentences. A recurrent neural network\ngenerates individual words, thus reaping the benefits of\ndiscriminatively-trained vector representations. The discourse relations are\nrepresented with a latent variable, which can be predicted or marginalized,\ndepending on the task. The resulting model can therefore employ a training\nobjective that includes not only discourse relation classification, but also\nword prediction. As a result, it outperforms state-of-the-art alternatives for\ntwo tasks: implicit discourse relation classification in the Penn Discourse\nTreebank, and dialog act classification in the Switchboard corpus. Furthermore,\nby marginalizing over latent discourse relations at test time, we obtain a\ndiscourse informed language model, which improves over a strong LSTM baseline. \n\n"}
{"id": "1603.02185", "contents": "Title: Distributed Multi-Task Learning with Shared Representation Abstract: We study the problem of distributed multi-task learning with shared\nrepresentation, where each machine aims to learn a separate, but related, task\nin an unknown shared low-dimensional subspaces, i.e. when the predictor matrix\nhas low rank. We consider a setting where each task is handled by a different\nmachine, with samples for the task available locally on the machine, and study\ncommunication-efficient methods for exploiting the shared structure. \n\n"}
{"id": "1603.02412", "contents": "Title: Stochastic dual averaging methods using variance reduction techniques\n  for regularized empirical risk minimization problems Abstract: We consider a composite convex minimization problem associated with\nregularized empirical risk minimization, which often arises in machine\nlearning. We propose two new stochastic gradient methods that are based on\nstochastic dual averaging method with variance reduction. Our methods generate\na sparser solution than the existing methods because we do not need to take the\naverage of the history of the solutions. This is favorable in terms of both\ninterpretability and generalization. Moreover, our methods have theoretical\nsupport for both a strongly and a non-strongly convex regularizer and achieve\nthe best known convergence rates among existing nonaccelerated stochastic\ngradient methods. \n\n"}
{"id": "1603.04245", "contents": "Title: A Variational Perspective on Accelerated Methods in Optimization Abstract: Accelerated gradient methods play a central role in optimization, achieving\noptimal rates in many settings. While many generalizations and extensions of\nNesterov's original acceleration method have been proposed, it is not yet clear\nwhat is the natural scope of the acceleration concept. In this paper, we study\naccelerated methods from a continuous-time perspective. We show that there is a\nLagrangian functional that we call the \\emph{Bregman Lagrangian} which\ngenerates a large class of accelerated methods in continuous time, including\n(but not limited to) accelerated gradient descent, its non-Euclidean extension,\nand accelerated higher-order gradient methods. We show that the continuous-time\nlimit of all of these methods correspond to traveling the same curve in\nspacetime at different speeds. From this perspective, Nesterov's technique and\nmany of its generalizations can be viewed as a systematic way to go from the\ncontinuous-time curves generated by the Bregman Lagrangian to a family of\ndiscrete-time accelerated algorithms. \n\n"}
{"id": "1603.04981", "contents": "Title: An Approximate Dynamic Programming Approach to Adversarial Online\n  Learning Abstract: We describe an approximate dynamic programming (ADP) approach to compute\napproximations of the optimal strategies and of the minimal losses that can be\nguaranteed in discounted repeated games with vector-valued losses. Such games\nprominently arise in the analysis of regret in repeated decision-making in\nadversarial environments, also known as adversarial online learning. At the\ncore of our approach is a characterization of the lower Pareto frontier of the\nset of expected losses that a player can guarantee in these games as the unique\nfixed point of a set-valued dynamic programming operator. When applied to the\nproblem of regret minimization with discounted losses, our approach yields\nalgorithms that achieve markedly improved performance bounds compared to\noff-the-shelf online learning algorithms like Hedge. These results thus suggest\nthe significant potential of ADP-based approaches in adversarial online\nlearning. \n\n"}
{"id": "1603.06060", "contents": "Title: DASA: Domain Adaptation in Stacked Autoencoders using Systematic Dropout Abstract: Domain adaptation deals with adapting behaviour of machine learning based\nsystems trained using samples in source domain to their deployment in target\ndomain where the statistics of samples in both domains are dissimilar. The task\nof directly training or adapting a learner in the target domain is challenged\nby lack of abundant labeled samples. In this paper we propose a technique for\ndomain adaptation in stacked autoencoder (SAE) based deep neural networks (DNN)\nperformed in two stages: (i) unsupervised weight adaptation using systematic\ndropouts in mini-batch training, (ii) supervised fine-tuning with limited\nnumber of labeled samples in target domain. We experimentally evaluate\nperformance in the problem of retinal vessel segmentation where the SAE-DNN is\ntrained using large number of labeled samples in the source domain (DRIVE\ndataset) and adapted using less number of labeled samples in target domain\n(STARE dataset). The performance of SAE-DNN measured using $logloss$ in source\ndomain is $0.19$, without and with adaptation are $0.40$ and $0.18$, and $0.39$\nwhen trained exclusively with limited samples in target domain. The area under\nROC curve is observed respectively as $0.90$, $0.86$, $0.92$ and $0.87$. The\nhigh efficiency of vessel segmentation with DASA strongly substantiates our\nclaim. \n\n"}
{"id": "1603.06159", "contents": "Title: Fast Incremental Method for Nonconvex Optimization Abstract: We analyze a fast incremental aggregated gradient method for optimizing\nnonconvex problems of the form $\\min_x \\sum_i f_i(x)$. Specifically, we analyze\nthe SAGA algorithm within an Incremental First-order Oracle framework, and show\nthat it converges to a stationary point provably faster than both gradient\ndescent and stochastic gradient descent. We also discuss a Polyak's special\nclass of nonconvex problems for which SAGA converges at a linear rate to the\nglobal optimum. Finally, we analyze the practically valuable regularized and\nminibatch variants of SAGA. To our knowledge, this paper presents the first\nanalysis of fast convergence for an incremental aggregated gradient method for\nnonconvex problems. \n\n"}
{"id": "1603.06160", "contents": "Title: Stochastic Variance Reduction for Nonconvex Optimization Abstract: We study nonconvex finite-sum problems and analyze stochastic variance\nreduced gradient (SVRG) methods for them. SVRG and related methods have\nrecently surged into prominence for convex optimization given their edge over\nstochastic gradient descent (SGD); but their theoretical analysis almost\nexclusively assumes convexity. In contrast, we prove non-asymptotic rates of\nconvergence (to stationary points) of SVRG for nonconvex optimization, and show\nthat it is provably faster than SGD and gradient descent. We also analyze a\nsubclass of nonconvex problems on which SVRG attains linear convergence to the\nglobal optimum. We extend our analysis to mini-batch variants of SVRG, showing\n(theoretical) linear speedup due to mini-batching in parallel settings. \n\n"}
{"id": "1603.06560", "contents": "Title: Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization Abstract: Performance of machine learning algorithms depends critically on identifying\na good set of hyperparameters. While recent approaches use Bayesian\noptimization to adaptively select configurations, we focus on speeding up\nrandom search through adaptive resource allocation and early-stopping. We\nformulate hyperparameter optimization as a pure-exploration non-stochastic\ninfinite-armed bandit problem where a predefined resource like iterations, data\nsamples, or features is allocated to randomly sampled configurations. We\nintroduce a novel algorithm, Hyperband, for this framework and analyze its\ntheoretical properties, providing several desirable guarantees. Furthermore, we\ncompare Hyperband with popular Bayesian optimization methods on a suite of\nhyperparameter optimization problems. We observe that Hyperband can provide\nover an order-of-magnitude speedup over our competitor set on a variety of\ndeep-learning and kernel-based learning problems. \n\n"}
{"id": "1603.08861", "contents": "Title: Revisiting Semi-Supervised Learning with Graph Embeddings Abstract: We present a semi-supervised learning framework based on graph embeddings.\nGiven a graph between instances, we train an embedding for each instance to\njointly predict the class label and the neighborhood context in the graph. We\ndevelop both transductive and inductive variants of our method. In the\ntransductive variant of our method, the class labels are determined by both the\nlearned embeddings and input feature vectors, while in the inductive variant,\nthe embeddings are defined as a parametric function of the feature vectors, so\npredictions can be made on instances not seen during training. On a large and\ndiverse set of benchmark tasks, including text classification, distantly\nsupervised entity extraction, and entity classification, we show improved\nperformance over many of the existing models. \n\n"}
{"id": "1603.09630", "contents": "Title: Differentiable Pooling for Unsupervised Acoustic Model Adaptation Abstract: We present a deep neural network (DNN) acoustic model that includes\nparametrised and differentiable pooling operators. Unsupervised acoustic model\nadaptation is cast as the problem of updating the decision boundaries\nimplemented by each pooling operator. In particular, we experiment with two\ntypes of pooling parametrisations: learned $L_p$-norm pooling and weighted\nGaussian pooling, in which the weights of both operators are treated as\nspeaker-dependent. We perform investigations using three different large\nvocabulary speech recognition corpora: AMI meetings, TED talks and Switchboard\nconversational telephone speech. We demonstrate that differentiable pooling\noperators provide a robust and relatively low-dimensional way to adapt acoustic\nmodels, with relative word error rates reductions ranging from 5--20% with\nrespect to unadapted systems, which themselves are better than the baseline\nfully-connected DNN-based acoustic models. We also investigate how the proposed\ntechniques work under various adaptation conditions including the quality of\nadaptation data and complementarity to other feature- and model-space\nadaptation methods, as well as providing an analysis of the characteristics of\neach of the proposed approaches. \n\n"}
{"id": "1603.09638", "contents": "Title: Detection under Privileged Information Abstract: For well over a quarter century, detection systems have been driven by models\nlearned from input features collected from real or simulated environments. An\nartifact (e.g., network event, potential malware sample, suspicious email) is\ndeemed malicious or non-malicious based on its similarity to the learned model\nat runtime. However, the training of the models has been historically limited\nto only those features available at runtime. In this paper, we consider an\nalternate learning approach that trains models using \"privileged\"\ninformation--features available at training time but not at runtime--to improve\nthe accuracy and resilience of detection systems. In particular, we adapt and\nextend recent advances in knowledge transfer, model influence, and distillation\nto enable the use of forensic or other data unavailable at runtime in a range\nof security domains. An empirical evaluation shows that privileged information\nincreases precision and recall over a system with no privileged information: we\nobserve up to 7.7% relative decrease in detection error for fast-flux bot\ndetection, 8.6% for malware traffic detection, 7.3% for malware classification,\nand 16.9% for face recognition. We explore the limitations and applications of\ndifferent privileged information techniques in detection systems. Such\ntechniques provide a new means for detection systems to learn from data that\nwould otherwise not be available at runtime. \n\n"}
{"id": "1604.02218", "contents": "Title: A Low Complexity Algorithm with $O(\\sqrt{T})$ Regret and $O(1)$\n  Constraint Violations for Online Convex Optimization with Long Term\n  Constraints Abstract: This paper considers online convex optimization over a complicated constraint\nset, which typically consists of multiple functional constraints and a set\nconstraint. The conventional online projection algorithm (Zinkevich, 2003) can\nbe difficult to implement due to the potentially high computation complexity of\nthe projection operation. In this paper, we relax the functional constraints by\nallowing them to be violated at each round but still requiring them to be\nsatisfied in the long term. This type of relaxed online convex optimization\n(with long term constraints) was first considered in Mahdavi et al. (2012).\nThat prior work proposes an algorithm to achieve $O(\\sqrt{T})$ regret and\n$O(T^{3/4})$ constraint violations for general problems and another algorithm\nto achieve an $O(T^{2/3})$ bound for both regret and constraint violations when\nthe constraint set can be described by a finite number of linear constraints. A\nrecent extension in \\citet{Jenatton16ICML} can achieve\n$O(T^{\\max\\{\\theta,1-\\theta\\}})$ regret and $O(T^{1-\\theta/2})$ constraint\nviolations where $\\theta\\in (0,1)$. The current paper proposes a new simple\nalgorithm that yields improved performance in comparison to prior works. The\nnew algorithm achieves an $O(\\sqrt{T})$ regret bound with $O(1)$ constraint\nviolations. \n\n"}
{"id": "1604.05024", "contents": "Title: Empirical study of PROXTONE and PROXTONE$^+$ for Fast Learning of Large\n  Scale Sparse Models Abstract: PROXTONE is a novel and fast method for optimization of large scale\nnon-smooth convex problem \\cite{shi2015large}. In this work, we try to use\nPROXTONE method in solving large scale \\emph{non-smooth non-convex} problems,\nfor example training of sparse deep neural network (sparse DNN) or sparse\nconvolutional neural network (sparse CNN) for embedded or mobile device.\nPROXTONE converges much faster than first order methods, while first order\nmethod is easy in deriving and controlling the sparseness of the solutions.\nThus in some applications, in order to train sparse models fast, we propose to\ncombine the merits of both methods, that is we use PROXTONE in the first\nseveral epochs to reach the neighborhood of an optimal solution, and then use\nthe first order method to explore the possibility of sparsity in the following\ntraining. We call such method PROXTONE plus (PROXTONE$^+$). Both PROXTONE and\nPROXTONE$^+$ are tested in our experiments, and which demonstrate both methods\nimproved convergence speed twice as fast at least on diverse sparse model\nlearning problems, and at the same time reduce the size to 0.5\\% for DNN\nmodels. The source of all the algorithms is available upon request. \n\n"}
{"id": "1604.07484", "contents": "Title: Deep Multi-fidelity Gaussian Processes Abstract: We develop a novel multi-fidelity framework that goes far beyond the\nclassical AR(1) Co-kriging scheme of Kennedy and O'Hagan (2000). Our method can\nhandle general discontinuous cross-correlations among systems with different\nlevels of fidelity. A combination of multi-fidelity Gaussian Processes (AR(1)\nCo-kriging) and deep neural networks enables us to construct a method that is\nimmune to discontinuities. We demonstrate the effectiveness of the new\ntechnology using standard benchmark problems designed to resemble the outputs\nof complicated high- and low-fidelity codes. \n\n"}
{"id": "1605.00042", "contents": "Title: Improved Sparse Low-Rank Matrix Estimation Abstract: We address the problem of estimating a sparse low-rank matrix from its noisy\nobservation. We propose an objective function consisting of a data-fidelity\nterm and two parameterized non-convex penalty functions. Further, we show how\nto set the parameters of the non-convex penalty functions, in order to ensure\nthat the objective function is strictly convex. The proposed objective function\nbetter estimates sparse low-rank matrices than a convex method which utilizes\nthe sum of the nuclear norm and the $\\ell_1$ norm. We derive an algorithm (as\nan instance of ADMM) to solve the proposed problem, and guarantee its\nconvergence provided the scalar augmented Lagrangian parameter is set\nappropriately. We demonstrate the proposed method for denoising an audio signal\nand an adjacency matrix representing protein interactions in the `Escherichia\ncoli' bacteria. \n\n"}
{"id": "1605.00057", "contents": "Title: Distributed Cell Association for Energy Harvesting IoT Devices in Dense\n  Small Cell Networks: A Mean-Field Multi-Armed Bandit Approach Abstract: The emerging Internet of Things (IoT)-driven ultra-dense small cell networks\n(UD-SCNs) will need to combat a variety of challenges. On one hand, massive\nnumber of devices sharing the limited wireless resources will render\ncentralized control mechanisms infeasible due to the excessive cost of\ninformation acquisition and computations. On the other hand, to reduce energy\nconsumption from fixed power grid and/or battery, many IoT devices may need to\ndepend on the energy harvested from the ambient environment (e.g., from RF\ntransmissions, environmental sources). However, due to the opportunistic nature\nof energy harvesting, this will introduce uncertainty in the network operation.\nIn this article, we study the distributed cell association problem for energy\nharvesting IoT devices in UD-SCNs. After reviewing the state-of-the-art\nresearch on the cell association problem in small cell networks, we outline the\nmajor challenges for distributed cell association in IoT-driven UD-SCNs where\nthe IoT devices will need to perform cell association in a distributed manner\nin presence of uncertainty (e.g., limited knowledge on channel/network) and\nlimited computational capabilities. To this end, we propose an approach based\non mean-field multi-armed bandit games to solve the uplink cell association\nproblem for energy harvesting IoT devices in a UD-SCN. This approach is\nparticularly suitable to analyze large multi-agent systems under uncertainty\nand lack of information. We provide some theoretical results as well as\npreliminary performance evaluation results for the proposed approach. \n\n"}
{"id": "1605.00391", "contents": "Title: Recovery of non-linear cause-effect relationships from linearly mixed\n  neuroimaging data Abstract: Causal inference concerns the identification of cause-effect relationships\nbetween variables. However, often only linear combinations of variables\nconstitute meaningful causal variables. For example, recovering the signal of a\ncortical source from electroencephalography requires a well-tuned combination\nof signals recorded at multiple electrodes. We recently introduced the MERLiN\n(Mixture Effect Recovery in Linear Networks) algorithm that is able to recover,\nfrom an observed linear mixture, a causal variable that is a linear effect of\nanother given variable. Here we relax the assumption of this cause-effect\nrelationship being linear and present an extended algorithm that can pick up\nnon-linear cause-effect relationships. Thus, the main contribution is an\nalgorithm (and ready to use code) that has broader applicability and allows for\na richer model class. Furthermore, a comparative analysis indicates that the\nassumption of linear cause-effect relationships is not restrictive in analysing\nelectroencephalographic data. \n\n"}
{"id": "1605.02105", "contents": "Title: Distributed Learning with Infinitely Many Hypotheses Abstract: We consider a distributed learning setup where a network of agents\nsequentially access realizations of a set of random variables with unknown\ndistributions. The network objective is to find a parametrized distribution\nthat best describes their joint observations in the sense of the\nKullback-Leibler divergence. Apart from recent efforts in the literature, we\nanalyze the case of countably many hypotheses and the case of a continuum of\nhypotheses. We provide non-asymptotic bounds for the concentration rate of the\nagents' beliefs around the correct hypothesis in terms of the number of agents,\nthe network parameters, and the learning abilities of the agents. Additionally,\nwe provide a novel motivation for a general set of distributed Non-Bayesian\nupdate rules as instances of the distributed stochastic mirror descent\nalgorithm. \n\n"}
{"id": "1605.02536", "contents": "Title: Random Fourier Features for Operator-Valued Kernels Abstract: Devoted to multi-task learning and structured output learning,\noperator-valued kernels provide a flexible tool to build vector-valued\nfunctions in the context of Reproducing Kernel Hilbert Spaces. To scale up\nthese methods, we extend the celebrated Random Fourier Feature methodology to\nget an approximation of operator-valued kernels. We propose a general principle\nfor Operator-valued Random Fourier Feature construction relying on a\ngeneralization of Bochner's theorem for translation-invariant operator-valued\nMercer kernels. We prove the uniform convergence of the kernel approximation\nfor bounded and unbounded operator random Fourier features using appropriate\nBernstein matrix concentration inequality. An experimental proof-of-concept\nshows the quality of the approximation and the efficiency of the corresponding\nlinear models on example datasets. \n\n"}
{"id": "1605.03529", "contents": "Title: On the Iteration Complexity of Oblivious First-Order Optimization\n  Algorithms Abstract: We consider a broad class of first-order optimization algorithms which are\n\\emph{oblivious}, in the sense that their step sizes are scheduled regardless\nof the function under consideration, except for limited side-information such\nas smoothness or strong convexity parameters. With the knowledge of these two\nparameters, we show that any such algorithm attains an iteration complexity\nlower bound of $\\Omega(\\sqrt{L/\\epsilon})$ for $L$-smooth convex functions, and\n$\\tilde{\\Omega}(\\sqrt{L/\\mu}\\ln(1/\\epsilon))$ for $L$-smooth $\\mu$-strongly\nconvex functions. These lower bounds are stronger than those in the traditional\noracle model, as they hold independently of the dimension. To attain these, we\nabandon the oracle model in favor of a structure-based approach which builds\nupon a framework recently proposed in (Arjevani et al., 2015). We further show\nthat without knowing the strong convexity parameter, it is impossible to attain\nan iteration complexity better than\n$\\tilde{\\Omega}\\left((L/\\mu)\\ln(1/\\epsilon)\\right)$. This result is then used\nto formalize an observation regarding $L$-smooth convex functions, namely, that\nthe iteration complexity of algorithms employing time-invariant step sizes must\nbe at least $\\Omega(L/\\epsilon)$. \n\n"}
{"id": "1605.03843", "contents": "Title: Asymptotic sequential Rademacher complexity of a finite function class Abstract: For a finite function class we describe the large sample limit of the\nsequential Rademacher complexity in terms of the viscosity solution of a\n$G$-heat equation. In the language of Peng's sublinear expectation theory, the\nsame quantity equals to the expected value of the largest order statistics of a\nmultidimensional $G$-normal random variable. We illustrate this result by\nderiving upper and lower bounds for the asymptotic sequential Rademacher\ncomplexity. \n\n"}
{"id": "1605.04131", "contents": "Title: Barzilai-Borwein Step Size for Stochastic Gradient Descent Abstract: One of the major issues in stochastic gradient descent (SGD) methods is how\nto choose an appropriate step size while running the algorithm. Since the\ntraditional line search technique does not apply for stochastic optimization\nalgorithms, the common practice in SGD is either to use a diminishing step\nsize, or to tune a fixed step size by hand, which can be time consuming in\npractice. In this paper, we propose to use the Barzilai-Borwein (BB) method to\nautomatically compute step sizes for SGD and its variant: stochastic variance\nreduced gradient (SVRG) method, which leads to two algorithms: SGD-BB and\nSVRG-BB. We prove that SVRG-BB converges linearly for strongly convex objective\nfunctions. As a by-product, we prove the linear convergence result of SVRG with\nOption I proposed in [10], whose convergence result is missing in the\nliterature. Numerical experiments on standard data sets show that the\nperformance of SGD-BB and SVRG-BB is comparable to and sometimes even better\nthan SGD and SVRG with best-tuned step sizes, and is superior to some advanced\nSGD variants. \n\n"}
{"id": "1605.06049", "contents": "Title: A Multi-Batch L-BFGS Method for Machine Learning Abstract: The question of how to parallelize the stochastic gradient descent (SGD)\nmethod has received much attention in the literature. In this paper, we focus\ninstead on batch methods that use a sizeable fraction of the training set at\neach iteration to facilitate parallelism, and that employ second-order\ninformation. In order to improve the learning process, we follow a multi-batch\napproach in which the batch changes at each iteration. This can cause\ndifficulties because L-BFGS employs gradient differences to update the Hessian\napproximations, and when these gradients are computed using different data\npoints the process can be unstable. This paper shows how to perform stable\nquasi-Newton updating in the multi-batch setting, illustrates the behavior of\nthe algorithm in a distributed computing platform, and studies its convergence\nproperties for both the convex and nonconvex cases. \n\n"}
{"id": "1605.06203", "contents": "Title: Faster Projection-free Convex Optimization over the Spectrahedron Abstract: Minimizing a convex function over the spectrahedron, i.e., the set of all\npositive semidefinite matrices with unit trace, is an important optimization\ntask with many applications in optimization, machine learning, and signal\nprocessing. It is also notoriously difficult to solve in large-scale since\nstandard techniques require expensive matrix decompositions. An alternative, is\nthe conditional gradient method (aka Frank-Wolfe algorithm) that regained much\ninterest in recent years, mostly due to its application to this specific\nsetting. The key benefit of the CG method is that it avoids expensive matrix\ndecompositions all together, and simply requires a single eigenvector\ncomputation per iteration, which is much more efficient. On the downside, the\nCG method, in general, converges with an inferior rate. The error for\nminimizing a $\\beta$-smooth function after $t$ iterations scales like\n$\\beta/t$. This convergence rate does not improve even if the function is also\nstrongly convex.\n  In this work we present a modification of the CG method tailored for convex\noptimization over the spectrahedron. The per-iteration complexity of the method\nis essentially identical to that of the standard CG method: only a single\neigenvecor computation is required. For minimizing an $\\alpha$-strongly convex\nand $\\beta$-smooth function, the expected approximation error of the method\nafter $t$ iterations is: $$O\\left({\\min\\{\\frac{\\beta{}}{t}\n,\\left({\\frac{\\beta\\sqrt{\\textrm{rank}(\\textbf{X}^*)}}{\\alpha^{1/4}t}}\\right)^{4/3},\n\\left({\\frac{\\beta}{\\sqrt{\\alpha}\\lambda_{\\min}(\\textbf{X}^*)t}}\\right)^{2}\\}}\\right)\n,$$ where $\\textbf{X}^*$ is the optimal solution. To the best of our knowledge,\nthis is the first result that attains provably faster convergence rates for a\nCG variant for optimization over the spectrahedron. We also present encouraging\npreliminary empirical results. \n\n"}
{"id": "1605.06492", "contents": "Title: Linear-memory and Decomposition-invariant Linearly Convergent\n  Conditional Gradient Algorithm for Structured Polytopes Abstract: Recently, several works have shown that natural modifications of the\nclassical conditional gradient method (aka Frank-Wolfe algorithm) for\nconstrained convex optimization, provably converge with a linear rate when: i)\nthe feasible set is a polytope, and ii) the objective is smooth and\nstrongly-convex. However, all of these results suffer from two significant\nshortcomings: large memory requirement due to the need to store an explicit\nconvex decomposition of the current iterate, and as a consequence, large\nrunning-time overhead per iteration, and worst case convergence rate that\ndepends unfavorably on the dimension.\n  In this work we present a new conditional gradient variant and a\ncorresponding analysis that improves on both of the above shortcomings. In\nparticular: both memory and computation overheads are only linear in the\ndimension. Moreover, in case the optimal solution is sparse, the new\nconvergence rate replaces a factor which is at least linear in the dimension in\nprevious works, with a linear dependence on the number of non-zeros in the\noptimal solution.\n  At the heart of our method, and corresponding analysis, is a novel way to\ncompute decomposition-invariant away-steps. While our theoretical guarantees do\nnot apply to any polytope, they apply to several important structured polytopes\nthat capture central concepts such as paths in graphs, perfect matchings in\nbipartite graphs, marginal distributions that arise in structured prediction\ntasks, and more. Our theoretical findings are complemented by empirical\nevidence which shows that our method delivers state-of-the-art performance. \n\n"}
{"id": "1605.06676", "contents": "Title: Learning to Communicate with Deep Multi-Agent Reinforcement Learning Abstract: We consider the problem of multiple agents sensing and acting in environments\nwith the goal of maximising their shared utility. In these environments, agents\nmust learn communication protocols in order to share information that is needed\nto solve the tasks. By embracing deep neural networks, we are able to\ndemonstrate end-to-end learning of protocols in complex environments inspired\nby communication riddles and multi-agent computer vision problems with partial\nobservability. We propose two approaches for learning in these domains:\nReinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning\n(DIAL). The former uses deep Q-learning, while the latter exploits the fact\nthat, during learning, agents can backpropagate error derivatives through\n(noisy) communication channels. Hence, this approach uses centralised learning\nbut decentralised execution. Our experiments introduce new environments for\nstudying the learning of communication protocols and present a set of\nengineering innovations that are essential for success in these domains. \n\n"}
{"id": "1605.06711", "contents": "Title: Learning From Hidden Traits: Joint Factor Analysis and Latent Clustering Abstract: Dimensionality reduction techniques play an essential role in data analytics,\nsignal processing and machine learning. Dimensionality reduction is usually\nperformed in a preprocessing stage that is separate from subsequent data\nanalysis, such as clustering or classification. Finding reduced-dimension\nrepresentations that are well-suited for the intended task is more appealing.\nThis paper proposes a joint factor analysis and latent clustering framework,\nwhich aims at learning cluster-aware low-dimensional representations of matrix\nand tensor data. The proposed approach leverages matrix and tensor\nfactorization models that produce essentially unique latent representations of\nthe data to unravel latent cluster structure -- which is otherwise obscured\nbecause of the freedom to apply an oblique transformation in latent space. At\nthe same time, latent cluster structure is used as prior information to enhance\nthe performance of factorization. Specific contributions include several\ncustom-built problem formulations, corresponding algorithms, and discussion of\nassociated convergence properties. Besides extensive simulations, real-world\ndatasets such as Reuters document data and MNIST image data are also employed\nto showcase the effectiveness of the proposed approaches. \n\n"}
{"id": "1605.06900", "contents": "Title: Fast Stochastic Methods for Nonsmooth Nonconvex Optimization Abstract: We analyze stochastic algorithms for optimizing nonconvex, nonsmooth\nfinite-sum problems, where the nonconvex part is smooth and the nonsmooth part\nis convex. Surprisingly, unlike the smooth case, our knowledge of this\nfundamental problem is very limited. For example, it is not known whether the\nproximal stochastic gradient method with constant minibatch converges to a\nstationary point. To tackle this issue, we develop fast stochastic algorithms\nthat provably converge to a stationary point for constant minibatches.\nFurthermore, using a variant of these algorithms, we show provably faster\nconvergence than batch proximal gradient descent. Finally, we prove global\nlinear convergence rate for an interesting subclass of nonsmooth nonconvex\nfunctions, that subsumes several recent works. This paper builds upon our\nrecent series of papers on fast stochastic methods for smooth nonconvex\noptimization [22, 23], with a novel analysis for nonconvex and nonsmooth\nfunctions. \n\n"}
{"id": "1605.07133", "contents": "Title: Towards Multi-Agent Communication-Based Language Learning Abstract: We propose an interactive multimodal framework for language learning. Instead\nof being passively exposed to large amounts of natural text, our learners\n(implemented as feed-forward neural networks) engage in cooperative referential\ngames starting from a tabula rasa setup, and thus develop their own language\nfrom the need to communicate in order to succeed at the game. Preliminary\nexperiments provide promising results, but also suggest that it is important to\nensure that agents trained in this way do not develop an adhoc communication\ncode only effective for the game they are playing \n\n"}
{"id": "1605.07147", "contents": "Title: Riemannian SVRG: Fast Stochastic Optimization on Riemannian Manifolds Abstract: We study optimization of finite sums of geodesically smooth functions on\nRiemannian manifolds. Although variance reduction techniques for optimizing\nfinite-sums have witnessed tremendous attention in the recent years, existing\nwork is limited to vector space problems. We introduce Riemannian SVRG (RSVRG),\na new variance reduced Riemannian optimization method. We analyze RSVRG for\nboth geodesically convex and nonconvex (smooth) functions. Our analysis reveals\nthat RSVRG inherits advantages of the usual SVRG method, but with factors\ndepending on curvature of the manifold that influence its convergence. To our\nknowledge, RSVRG is the first provably fast stochastic Riemannian method.\nMoreover, our paper presents the first non-asymptotic complexity analysis\n(novel even for the batch setting) for nonconvex Riemannian optimization. Our\nresults have several implications; for instance, they offer a Riemannian\nperspective on variance reduced PCA, which promises a short, transparent\nconvergence analysis. \n\n"}
{"id": "1605.07571", "contents": "Title: Sequential Neural Models with Stochastic Layers Abstract: How can we efficiently propagate uncertainty in a latent state representation\nwith recurrent neural networks? This paper introduces stochastic recurrent\nneural networks which glue a deterministic recurrent neural network and a state\nspace model together to form a stochastic and sequential neural generative\nmodel. The clear separation of deterministic and stochastic layers allows a\nstructured variational inference network to track the factorization of the\nmodel's posterior distribution. By retaining both the nonlinear recursive\nstructure of a recurrent neural network and averaging over the uncertainty in a\nlatent path, like a state space model, we improve the state of the art results\non the Blizzard and TIMIT speech modeling data sets by a large margin, while\nachieving comparable performances to competing methods on polyphonic music\nmodeling. \n\n"}
{"id": "1605.07747", "contents": "Title: NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and\n  Stochastic Optimization Abstract: We study a stochastic and distributed algorithm for nonconvex problems whose\nobjective consists of a sum of $N$ nonconvex $L_i/N$-smooth functions, plus a\nnonsmooth regularizer. The proposed NonconvEx primal-dual SpliTTing (NESTT)\nalgorithm splits the problem into $N$ subproblems, and utilizes an augmented\nLagrangian based primal-dual scheme to solve it in a distributed and stochastic\nmanner. With a special non-uniform sampling, a version of NESTT achieves\n$\\epsilon$-stationary solution using\n$\\mathcal{O}((\\sum_{i=1}^N\\sqrt{L_i/N})^2/\\epsilon)$ gradient evaluations,\nwhich can be up to $\\mathcal{O}(N)$ times better than the (proximal) gradient\ndescent methods. It also achieves Q-linear convergence rate for nonconvex\n$\\ell_1$ penalized quadratic problems with polyhedral constraints. Further, we\nreveal a fundamental connection between primal-dual based methods and a few\nprimal only methods such as IAG/SAG/SAGA. \n\n"}
{"id": "1605.08003", "contents": "Title: Tight Complexity Bounds for Optimizing Composite Objectives Abstract: We provide tight upper and lower bounds on the complexity of minimizing the\naverage of $m$ convex functions using gradient and prox oracles of the\ncomponent functions. We show a significant gap between the complexity of\ndeterministic vs randomized optimization. For smooth functions, we show that\naccelerated gradient descent (AGD) and an accelerated variant of SVRG are\noptimal in the deterministic and randomized settings respectively, and that a\ngradient oracle is sufficient for the optimal rate. For non-smooth functions,\nhaving access to prox oracles reduces the complexity and we present optimal\nmethods based on smoothing that improve over methods using just gradient\naccesses. \n\n"}
{"id": "1605.08108", "contents": "Title: FLAG n' FLARE: Fast Linearly-Coupled Adaptive Gradient Methods Abstract: We consider first order gradient methods for effectively optimizing a\ncomposite objective in the form of a sum of smooth and, potentially, non-smooth\nfunctions. We present accelerated and adaptive gradient methods, called FLAG\nand FLARE, which can offer the best of both worlds. They can achieve the\noptimal convergence rate by attaining the optimal first-order oracle complexity\nfor smooth convex optimization. Additionally, they can adaptively and\nnon-uniformly re-scale the gradient direction to adapt to the limited curvature\navailable and conform to the geometry of the domain. We show theoretically and\nempirically that, through the compounding effects of acceleration and\nadaptivity, FLAG and FLARE can be highly effective for many data fitting and\nmachine learning applications. \n\n"}
{"id": "1605.08527", "contents": "Title: Stochastic Optimization for Large-scale Optimal Transport Abstract: Optimal transport (OT) defines a powerful framework to compare probability\ndistributions in a geometrically faithful way. However, the practical impact of\nOT is still limited because of its computational burden. We propose a new class\nof stochastic optimization algorithms to cope with large-scale problems\nroutinely encountered in machine learning applications. These methods are able\nto manipulate arbitrary distributions (either discrete or continuous) by simply\nrequiring to be able to draw samples from them, which is the typical setup in\nhigh-dimensional learning problems. This alleviates the need to discretize\nthese densities, while giving access to provably convergent methods that output\nthe correct distance without discretization error. These algorithms rely on two\nmain ideas: (a) the dual OT problem can be re-cast as the maximization of an\nexpectation ; (b) entropic regularization of the primal OT problem results in a\nsmooth dual optimization optimization which can be addressed with algorithms\nthat have a provably faster convergence. We instantiate these ideas in three\ndifferent setups: (i) when comparing a discrete distribution to another, we\nshow that incremental stochastic optimization schemes can beat Sinkhorn's\nalgorithm, the current state-of-the-art finite dimensional OT solver; (ii) when\ncomparing a discrete distribution to a continuous density, a semi-discrete\nreformulation of the dual program is amenable to averaged stochastic gradient\ndescent, leading to better performance than approximately solving the problem\nby discretization ; (iii) when dealing with two continuous densities, we\npropose a stochastic gradient descent over a reproducing kernel Hilbert space\n(RKHS). This is currently the only known method to solve this problem, apart\nfrom computing OT on finite samples. We backup these claims on a set of\ndiscrete, semi-discrete and continuous benchmark problems. \n\n"}
{"id": "1605.08833", "contents": "Title: Muffled Semi-Supervised Learning Abstract: We explore a novel approach to semi-supervised learning. This approach is\ncontrary to the common approach in that the unlabeled examples serve to\n\"muffle,\" rather than enhance, the guidance provided by the labeled examples.\nWe provide several variants of the basic algorithm and show experimentally that\nthey can achieve significantly higher AUC than boosted trees, random forests\nand logistic regression when unlabeled examples are available. \n\n"}
{"id": "1605.08882", "contents": "Title: Optimal Rates for Multi-pass Stochastic Gradient Methods Abstract: We analyze the learning properties of the stochastic gradient method when\nmultiple passes over the data and mini-batches are allowed. We study how\nregularization properties are controlled by the step-size, the number of passes\nand the mini-batch size. In particular, we consider the square loss and show\nthat for a universal step-size choice, the number of passes acts as a\nregularization parameter, and optimal finite sample bounds can be achieved by\nearly-stopping. Moreover, we show that larger step-sizes are allowed when\nconsidering mini-batches. Our analysis is based on a unifying approach,\nencompassing both batch and stochastic gradient methods as special cases. As a\nbyproduct, we derive optimal convergence results for batch gradient methods\n(even in the non-attainable cases). \n\n"}
{"id": "1605.09066", "contents": "Title: Distributed Asynchronous Dual Free Stochastic Dual Coordinate Ascent Abstract: The primal-dual distributed optimization methods have broad large-scale\nmachine learning applications. Previous primal-dual distributed methods are not\napplicable when the dual formulation is not available, e.g. the\nsum-of-non-convex objectives. Moreover, these algorithms and theoretical\nanalysis are based on the fundamental assumption that the computing speeds of\nmultiple machines in a cluster are similar. However, the straggler problem is\nan unavoidable practical issue in the distributed system because of the\nexistence of slow machines. Therefore, the total computational time of the\ndistributed optimization methods is highly dependent on the slowest machine. In\nthis paper, we address these two issues by proposing distributed asynchronous\ndual free stochastic dual coordinate ascent algorithm for distributed\noptimization. Our method does not need the dual formulation of the target\nproblem in the optimization. We tackle the straggler problem through\nasynchronous communication and the negative effect of slow machines is\nsignificantly alleviated. We also analyze the convergence rate of our method\nand prove the linear convergence rate even if the individual functions in\nobjective are non-convex. Experiments on both convex and non-convex loss\nfunctions are used to validate our statements. \n\n"}
{"id": "1605.09477", "contents": "Title: A Neural Autoregressive Approach to Collaborative Filtering Abstract: This paper proposes CF-NADE, a neural autoregressive architecture for\ncollaborative filtering (CF) tasks, which is inspired by the Restricted\nBoltzmann Machine (RBM) based CF model and the Neural Autoregressive\nDistribution Estimator (NADE). We first describe the basic CF-NADE model for CF\ntasks. Then we propose to improve the model by sharing parameters between\ndifferent ratings. A factored version of CF-NADE is also proposed for better\nscalability. Furthermore, we take the ordinal nature of the preferences into\nconsideration and propose an ordinal cost to optimize CF-NADE, which shows\nsuperior performance. Finally, CF-NADE can be extended to a deep model, with\nonly moderately increased computational complexity. Experimental results show\nthat CF-NADE with a single hidden layer beats all previous state-of-the-art\nmethods on MovieLens 1M, MovieLens 10M, and Netflix datasets, and adding more\nhidden layers can further improve the performance. \n\n"}
{"id": "1605.09782", "contents": "Title: Adversarial Feature Learning Abstract: The ability of the Generative Adversarial Networks (GANs) framework to learn\ngenerative models mapping from simple latent distributions to arbitrarily\ncomplex data distributions has been demonstrated empirically, with compelling\nresults showing that the latent space of such generators captures semantic\nvariation in the data distribution. Intuitively, models trained to predict\nthese semantic latent representations given data may serve as useful feature\nrepresentations for auxiliary problems where semantics are relevant. However,\nin their existing form, GANs have no means of learning the inverse mapping --\nprojecting data back into the latent space. We propose Bidirectional Generative\nAdversarial Networks (BiGANs) as a means of learning this inverse mapping, and\ndemonstrate that the resulting learned feature representation is useful for\nauxiliary supervised discrimination tasks, competitive with contemporary\napproaches to unsupervised and self-supervised feature learning. \n\n"}
{"id": "1606.00068", "contents": "Title: Quantifying the probable approximation error of probabilistic inference\n  programs Abstract: This paper introduces a new technique for quantifying the approximation error\nof a broad class of probabilistic inference programs, including ones based on\nboth variational and Monte Carlo approaches. The key idea is to derive a\nsubjective bound on the symmetrized KL divergence between the distribution\nachieved by an approximate inference program and its true target distribution.\nThe bound's validity (and subjectivity) rests on the accuracy of two auxiliary\nprobabilistic programs: (i) a \"reference\" inference program that defines a gold\nstandard of accuracy and (ii) a \"meta-inference\" program that answers the\nquestion \"what internal random choices did the original approximate inference\nprogram probably make given that it produced a particular result?\" The paper\nincludes empirical results on inference problems drawn from linear regression,\nDirichlet process mixture modeling, HMMs, and Bayesian networks. The\nexperiments show that the technique is robust to the quality of the reference\ninference program and that it can detect implementation bugs that are not\napparent from predictive performance. \n\n"}
{"id": "1606.00720", "contents": "Title: Differentially Private Gaussian Processes Abstract: A major challenge for machine learning is increasing the availability of data\nwhile respecting the privacy of individuals. Here we combine the provable\nprivacy guarantees of the differential privacy framework with the flexibility\nof Gaussian processes (GPs). We propose a method using GPs to provide\ndifferentially private (DP) regression. We then improve this method by crafting\nthe DP noise covariance structure to efficiently protect the training data,\nwhile minimising the scale of the added noise. We find that this cloaking\nmethod achieves the greatest accuracy, while still providing privacy\nguarantees, and offers practical DP for regression over multi-dimensional\ninputs. Together these methods provide a starter toolkit for combining\ndifferential privacy and GPs. \n\n"}
{"id": "1606.03196", "contents": "Title: Phase Retrieval via Incremental Truncated Wirtinger Flow Abstract: In the phase retrieval problem, an unknown vector is to be recovered given\nquadratic measurements. This problem has received considerable attention in\nrecent times. In this paper, we present an algorithm to solve a nonconvex\nformulation of the phase retrieval problem, that we call $\\textit{Incremental\nTruncated Wirtinger Flow}$. Given random Gaussian sensing vectors, we prove\nthat it converges linearly to the solution, with an optimal sample complexity.\nWe also provide stability guarantees of the algorithm under noisy measurements.\nPerformance and comparisons with existing algorithms are illustrated via\nnumerical experiments on simulated and real data, with both random and\nstructured sensing vectors. \n\n"}
{"id": "1606.03366", "contents": "Title: How Hard Is It to Control A Group? Abstract: We consider group identification models in which the aggregation of\nindividual opinions concerning who is qualified in a given society determines\nthe set of socially qualified persons. In this setting, we study the extent to\nwhich social qualification can be changed when societies expand, shrink, or\npartition themselves. The answers we provide are with respect to the\ncomputational complexity of the corresponding control problems and fully cover\nthe class of consent aggregation rules introduced by Samet & Schmeidler (2003)\nas well as procedural rules for group identification. We obtain both\npolynomial-time solvability results and NP-hardness results. In addition, we\nalso study these problems from the parameterized complexity perspective, and\nobtain some fixed-parameter tractability results. \n\n"}
{"id": "1606.03508", "contents": "Title: Distributed Machine Learning in Materials that Couple Sensing,\n  Actuation, Computation and Communication Abstract: This paper reviews machine learning applications and approaches to detection,\nclassification and control of intelligent materials and structures with\nembedded distributed computation elements. The purpose of this survey is to\nidentify desired tasks to be performed in each type of material or structure\n(e.g., damage detection in composites), identify and compare common approaches\nto learning such tasks, and investigate models and training paradigms used.\nMachine learning approaches and common temporal features used in the domains of\nstructural health monitoring, morphable aircraft, wearable computing and\nrobotic skins are explored. As the ultimate goal of this research is to\nincorporate the approaches described in this survey into a robotic material\nparadigm, the potential for adapting the computational models used in these\napplications, and corresponding training algorithms, to an amorphous network of\ncomputing nodes is considered. Distributed versions of support vector machines,\ngraphical models and mixture models developed in the field of wireless sensor\nnetworks are reviewed. Potential areas of investigation, including possible\narchitectures for incorporating machine learning into robotic nodes, training\napproaches, and the possibility of using deep learning approaches for automatic\nfeature extraction, are discussed. \n\n"}
{"id": "1606.03841", "contents": "Title: Efficient Learning with a Family of Nonconvex Regularizers by\n  Redistributing Nonconvexity Abstract: The use of convex regularizers allows for easy optimization, though they\noften produce biased estimation and inferior prediction performance. Recently,\nnonconvex regularizers have attracted a lot of attention and outperformed\nconvex ones. However, the resultant optimization problem is much harder. In\nthis paper, for a large class of nonconvex regularizers, we propose to move the\nnonconvexity from the regularizer to the loss. The nonconvex regularizer is\nthen transformed to a familiar convex regularizer, while the resultant loss\nfunction can still be guaranteed to be smooth. Learning with the convexified\nregularizer can be performed by existing efficient algorithms originally\ndesigned for convex regularizers (such as the proximal algorithm, Frank-Wolfe\nalgorithm, alternating direction method of multipliers and stochastic gradient\ndescent). Extensions are made when the convexified regularizer does not have\nclosed-form proximal step, and when the loss function is nonconvex, nonsmooth.\nExtensive experiments on a variety of machine learning application scenarios\nshow that optimizing the transformed problem is much faster than running the\nstate-of-the-art on the original problem. \n\n"}
{"id": "1606.04080", "contents": "Title: Matching Networks for One Shot Learning Abstract: Learning from a few examples remains a key challenge in machine learning.\nDespite recent advances in important domains such as vision and language, the\nstandard supervised deep learning paradigm does not offer a satisfactory\nsolution for learning new concepts rapidly from little data. In this work, we\nemploy ideas from metric learning based on deep neural features and from recent\nadvances that augment neural networks with external memories. Our framework\nlearns a network that maps a small labelled support set and an unlabelled\nexample to its label, obviating the need for fine-tuning to adapt to new class\ntypes. We then define one-shot learning problems on vision (using Omniglot,\nImageNet) and language tasks. Our algorithm improves one-shot accuracy on\nImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to\ncompeting approaches. We also demonstrate the usefulness of the same model on\nlanguage modeling by introducing a one-shot task on the Penn Treebank. \n\n"}
{"id": "1606.04142", "contents": "Title: Mutual information for symmetric rank-one matrix estimation: A proof of\n  the replica formula Abstract: Factorizing low-rank matrices has many applications in machine learning and\nstatistics. For probabilistic models in the Bayes optimal setting, a general\nexpression for the mutual information has been proposed using heuristic\nstatistical physics computations, and proven in few specific cases. Here, we\nshow how to rigorously prove the conjectured formula for the symmetric rank-one\ncase. This allows to express the minimal mean-square-error and to characterize\nthe detectability phase transitions in a large set of estimation problems\nranging from community detection to sparse PCA. We also show that for a large\nset of parameters, an iterative algorithm called approximate message-passing is\nBayes optimal. There exists, however, a gap between what currently known\npolynomial algorithms can do and what is expected information theoretically.\nAdditionally, the proof technique has an interest of its own and exploits three\nessential ingredients: the interpolation method introduced in statistical\nphysics by Guerra, the analysis of the approximate message-passing algorithm\nand the theory of spatial coupling and threshold saturation in coding. Our\napproach is generic and applicable to other open problems in statistical\nestimation where heuristic statistical physics predictions are available. \n\n"}
{"id": "1606.04244", "contents": "Title: Optimal control and zero-sum games for Markov chains of mean-field type Abstract: We establish existence of Markov chains of mean-field type with unbounded\njump intensities by means of a fixed point argument using the Total Variation\ndistance. We further show existence of nearly-optimal controls and, using a\nMarkov chain backward SDE approach, we suggest conditions for existence of an\noptimal control and a saddle-point for respectively a control problem and a\nzero-sum differential game associated with payoff functionals of mean-field\ntype, under dynamics driven by such Markov chains of mean-field type. \n\n"}
{"id": "1606.04809", "contents": "Title: ASAGA: Asynchronous Parallel SAGA Abstract: We describe ASAGA, an asynchronous parallel version of the incremental\ngradient algorithm SAGA that enjoys fast linear convergence rates. Through a\nnovel perspective, we revisit and clarify a subtle but important technical\nissue present in a large fraction of the recent convergence rate proofs for\nasynchronous parallel optimization algorithms, and propose a simplification of\nthe recently introduced \"perturbed iterate\" framework that resolves it. We\nthereby prove that ASAGA can obtain a theoretical linear speedup on multi-core\nsystems even without sparsity assumptions. We present results of an\nimplementation on a 40-core architecture illustrating the practical speedup as\nwell as the hardware overhead. \n\n"}
{"id": "1606.09333", "contents": "Title: Dimension-Free Iteration Complexity of Finite Sum Optimization Problems Abstract: Many canonical machine learning problems boil down to a convex optimization\nproblem with a finite sum structure. However, whereas much progress has been\nmade in developing faster algorithms for this setting, the inherent limitations\nof these problems are not satisfactorily addressed by existing lower bounds.\nIndeed, current bounds focus on first-order optimization algorithms, and only\napply in the often unrealistic regime where the number of iterations is less\nthan $\\mathcal{O}(d/n)$ (where $d$ is the dimension and $n$ is the number of\nsamples). In this work, we extend the framework of (Arjevani et al., 2015) to\nprovide new lower bounds, which are dimension-free, and go beyond the\nassumptions of current bounds, thereby covering standard finite sum\noptimization methods, e.g., SAG, SAGA, SVRG, SDCA without duality, as well as\nstochastic coordinate-descent methods, such as SDCA and accelerated proximal\nSDCA. \n\n"}
{"id": "1606.09458", "contents": "Title: Vote-boosting ensembles Abstract: Vote-boosting is a sequential ensemble learning method in which the\nindividual classifiers are built on different weighted versions of the training\ndata. To build a new classifier, the weight of each training instance is\ndetermined in terms of the degree of disagreement among the current ensemble\npredictions for that instance. For low class-label noise levels, especially\nwhen simple base learners are used, emphasis should be made on instances for\nwhich the disagreement rate is high. When more flexible classifiers are used\nand as the noise level increases, the emphasis on these uncertain instances\nshould be reduced. In fact, at sufficiently high levels of class-label noise,\nthe focus should be on instances on which the ensemble classifiers agree. The\noptimal type of emphasis can be automatically determined using\ncross-validation. An extensive empirical analysis using the beta distribution\nas emphasis function illustrates that vote-boosting is an effective method to\ngenerate ensembles that are both accurate and robust. \n\n"}
{"id": "1607.00076", "contents": "Title: Multi-class classification: mirror descent approach Abstract: We consider the problem of multi-class classification and a stochastic opti-\nmization approach to it. We derive risk bounds for stochastic mirror descent\nalgorithm and provide examples of set geometries that make the use of the\nalgorithm efficient in terms of error in k. \n\n"}
{"id": "1607.00101", "contents": "Title: Randomized block proximal damped Newton method for composite\n  self-concordant minimization Abstract: In this paper we consider the composite self-concordant (CSC) minimization\nproblem, which minimizes the sum of a self-concordant function $f$ and a\n(possibly nonsmooth) proper closed convex function $g$. The CSC minimization is\nthe cornerstone of the path-following interior point methods for solving a\nbroad class of convex optimization problems. It has also found numerous\napplications in machine learning. The proximal damped Newton (PDN) methods have\nbeen well studied in the literature for solving this problem that enjoy a nice\niteration complexity. Given that at each iteration these methods typically\nrequire evaluating or accessing the Hessian of $f$ and also need to solve a\nproximal Newton subproblem, the cost per iteration can be prohibitively high\nwhen applied to large-scale problems. Inspired by the recent success of block\ncoordinate descent methods, we propose a randomized block proximal damped\nNewton (RBPDN) method for solving the CSC minimization. Compared to the PDN\nmethods, the computational cost per iteration of RBPDN is usually significantly\nlower. The computational experiment on a class of regularized logistic\nregression problems demonstrate that RBPDN is indeed promising in solving\nlarge-scale CSC minimization problems. The convergence of RBPDN is also\nanalyzed in the paper. In particular, we show that RBPDN is globally convergent\nwhen $g$ is Lipschitz continuous. It is also shown that RBPDN enjoys a local\nlinear convergence. Moreover, we show that for a class of $g$ including the\ncase where $g$ is Lipschitz differentiable, RBPDN enjoys a global linear\nconvergence. As a striking consequence, it shows that the classical damped\nNewton methods [22,40] and the PDN [31] for such $g$ are globally linearly\nconvergent, which was previously unknown in the literature. Moreover, this\nresult can be used to sharpen the existing iteration complexity of these\nmethods. \n\n"}
{"id": "1607.00148", "contents": "Title: LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection Abstract: Mechanical devices such as engines, vehicles, aircrafts, etc., are typically\ninstrumented with numerous sensors to capture the behavior and health of the\nmachine. However, there are often external factors or variables which are not\ncaptured by sensors leading to time-series which are inherently unpredictable.\nFor instance, manual controls and/or unmonitored environmental conditions or\nload may lead to inherently unpredictable time-series. Detecting anomalies in\nsuch scenarios becomes challenging using standard approaches based on\nmathematical models that rely on stationarity, or prediction models that\nutilize prediction errors to detect anomalies. We propose a Long Short Term\nMemory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD)\nthat learns to reconstruct 'normal' time-series behavior, and thereafter uses\nreconstruction error to detect anomalies. We experiment with three publicly\navailable quasi predictable time-series datasets: power demand, space shuttle,\nand ECG, and two real-world engine datasets with both predictive and\nunpredictable behavior. We show that EncDec-AD is robust and can detect\nanomalies from predictable, unpredictable, periodic, aperiodic, and\nquasi-periodic time-series. Further, we show that EncDec-AD is able to detect\nanomalies from short time-series (length as small as 30) as well as long\ntime-series (length as large as 500). \n\n"}
{"id": "1607.00345", "contents": "Title: Convergence Rate of Frank-Wolfe for Non-Convex Objectives Abstract: We give a simple proof that the Frank-Wolfe algorithm obtains a stationary\npoint at a rate of $O(1/\\sqrt{t})$ on non-convex objectives with a Lipschitz\ncontinuous gradient. Our analysis is affine invariant and is the first, to the\nbest of our knowledge, giving a similar rate to what was already proven for\nprojected gradient methods (though on slightly different measures of\nstationarity). \n\n"}
{"id": "1607.01027", "contents": "Title: Accelerate Stochastic Subgradient Method by Leveraging Local Growth\n  Condition Abstract: In this paper, a new theory is developed for first-order stochastic convex\noptimization, showing that the global convergence rate is sufficiently\nquantified by a local growth rate of the objective function in a neighborhood\nof the optimal solutions. In particular, if the objective function $F(\\mathbf\nw)$ in the $\\epsilon$-sublevel set grows as fast as $\\|\\mathbf w - \\mathbf\nw_*\\|_2^{1/\\theta}$, where $\\mathbf w_*$ represents the closest optimal\nsolution to $\\mathbf w$ and $\\theta\\in(0,1]$ quantifies the local growth rate,\nthe iteration complexity of first-order stochastic optimization for achieving\nan $\\epsilon$-optimal solution can be $\\widetilde O(1/\\epsilon^{2(1-\\theta)})$,\nwhich is optimal at most up to a logarithmic factor. To achieve the faster\nglobal convergence, we develop two different accelerated stochastic subgradient\nmethods by iteratively solving the original problem approximately in a local\nregion around a historical solution with the size of the local region gradually\ndecreasing as the solution approaches the optimal set. Besides the theoretical\nimprovements, this work also includes new contributions towards making the\nproposed algorithms practical: (i) we present practical variants of accelerated\nstochastic subgradient methods that can run without the knowledge of\nmultiplicative growth constant and even the growth rate $\\theta$; (ii) we\nconsider a broad family of problems in machine learning to demonstrate that the\nproposed algorithms enjoy faster convergence than traditional stochastic\nsubgradient method. We also characterize the complexity of the proposed\nalgorithms for ensuring the gradient is small without the smoothness\nassumption. \n\n"}
{"id": "1607.01231", "contents": "Title: Stochastic Quasi-Newton Methods for Nonconvex Stochastic Optimization Abstract: In this paper we study stochastic quasi-Newton methods for nonconvex\nstochastic optimization, where we assume that noisy information about the\ngradients of the objective function is available via a stochastic first-order\noracle (SFO). We propose a general framework for such methods, for which we\nprove almost sure convergence to stationary points and analyze its worst-case\niteration complexity. When a randomly chosen iterate is returned as the output\nof such an algorithm, we prove that in the worst-case, the SFO-calls complexity\nis $O(\\epsilon^{-2})$ to ensure that the expectation of the squared norm of the\ngradient is smaller than the given accuracy tolerance $\\epsilon$. We also\npropose a specific algorithm, namely a stochastic damped L-BFGS (SdLBFGS)\nmethod, that falls under the proposed framework. {Moreover, we incorporate the\nSVRG variance reduction technique into the proposed SdLBFGS method, and analyze\nits SFO-calls complexity. Numerical results on a nonconvex binary\nclassification problem using SVM, and a multiclass classification problem using\nneural networks are reported. \n\n"}
{"id": "1607.01313", "contents": "Title: Scenario-based decision-making for power systems investment planning Abstract: The optimization of power systems involves complex uncertainties, such as\ntechnological progress, political context, geopolitical constraints.\nNegotiations at COP21 are complicated by the huge number of scenarios that\nvarious people want to consider; these scenarios correspond to many\nuncertainties. These uncertainties are difficult to modelize as probabilities,\ndue to the lack of data for future technologies and due to partially\nadversarial geopolitical decision makers. Tools for such difficult decision\nmaking problems include Wald and Savage criteria, possibilistic reasoning and\nNash equilibria. We investigate the rationale behind the use of a two-player\nNash equilibrium approach in such a difficult context; we show that the\ncomputational cost is indeed smaller than for simpler criteria. Moreover, it\nnaturally provides a selection of decisions and scenarios, and it has a natural\ninterpretation in the sense that Nature does not make decisions taking into\naccount our own decisions. The algorithm naturally provides a matrix of\nresults, namely the matrix of outcomes in the most interesting decisions and\nfor the most critical scenarios. These decisions and scenarios are also\nequipped with a ranking. \n\n"}
{"id": "1607.02793", "contents": "Title: On Faster Convergence of Cyclic Block Coordinate Descent-type Methods\n  for Strongly Convex Minimization Abstract: The cyclic block coordinate descent-type (CBCD-type) methods, which performs\niterative updates for a few coordinates (a block) simultaneously throughout the\nprocedure, have shown remarkable computational performance for solving strongly\nconvex minimization problems. Typical applications include many popular\nstatistical machine learning methods such as elastic-net regression, ridge\npenalized logistic regression, and sparse additive regression. Existing\noptimization literature has shown that for strongly convex minimization, the\nCBCD-type methods attain iteration complexity of\n$\\mathcal{O}(p\\log(1/\\epsilon))$, where $\\epsilon$ is a pre-specified accuracy\nof the objective value, and $p$ is the number of blocks. However, such\niteration complexity explicitly depends on $p$, and therefore is at least $p$\ntimes worse than the complexity $\\mathcal{O}(\\log(1/\\epsilon))$ of gradient\ndescent (GD) methods. To bridge this theoretical gap, we propose an improved\nconvergence analysis for the CBCD-type methods. In particular, we first show\nthat for a family of quadratic minimization problems, the iteration complexity\n$\\mathcal{O}(\\log^2(p)\\cdot\\log(1/\\epsilon))$ of the CBCD-type methods matches\nthat of the GD methods in term of dependency on $p$, up to a $\\log^2 p$ factor.\nThus our complexity bounds are sharper than the existing bounds by at least a\nfactor of $p/\\log^2(p)$. We also provide a lower bound to confirm that our\nimproved complexity bounds are tight (up to a $\\log^2 (p)$ factor), under the\nassumption that the largest and smallest eigenvalues of the Hessian matrix do\nnot scale with $p$. Finally, we generalize our analysis to other strongly\nconvex minimization problems beyond quadratic ones. \n\n"}
{"id": "1607.03195", "contents": "Title: Multi-Step Bayesian Optimization for One-Dimensional Feasibility\n  Determination Abstract: Bayesian optimization methods allocate limited sampling budgets to maximize\nexpensive-to-evaluate functions. One-step-lookahead policies are often used,\nbut computing optimal multi-step-lookahead policies remains a challenge. We\nconsider a specialized Bayesian optimization problem: finding the superlevel\nset of an expensive one-dimensional function, with a Markov process prior. We\ncompute the Bayes-optimal sampling policy efficiently, and characterize the\nsuboptimality of one-step lookahead. Our numerical experiments demonstrate that\nthe one-step lookahead policy is close to optimal in this problem, performing\nwithin 98% of optimal in the experimental settings considered. \n\n"}
{"id": "1607.08254", "contents": "Title: Stochastic Frank-Wolfe Methods for Nonconvex Optimization Abstract: We study Frank-Wolfe methods for nonconvex stochastic and finite-sum\noptimization problems. Frank-Wolfe methods (in the convex case) have gained\ntremendous recent interest in machine learning and optimization communities due\nto their projection-free property and their ability to exploit structured\nconstraints. However, our understanding of these algorithms in the nonconvex\nsetting is fairly limited. In this paper, we propose nonconvex stochastic\nFrank-Wolfe methods and analyze their convergence properties. For objective\nfunctions that decompose into a finite-sum, we leverage ideas from variance\nreduction techniques for convex optimization to obtain new variance reduced\nnonconvex Frank-Wolfe methods that have provably faster convergence than the\nclassical Frank-Wolfe method. Finally, we show that the faster convergence\nrates of our variance reduced methods also translate into improved convergence\nrates for the stochastic setting. \n\n"}
{"id": "1607.08863", "contents": "Title: Exponentially fast convergence to (strict) equilibrium via hedging Abstract: Motivated by applications to data networks where fast convergence is\nessential, we analyze the problem of learning in generic N-person games that\nadmit a Nash equilibrium in pure strategies. Specifically, we consider a\nscenario where players interact repeatedly and try to learn from past\nexperience by small adjustments based on local - and possibly imperfect -\npayoff information. For concreteness, we focus on the so-called \"hedge\" variant\nof the exponential weights algorithm where players select an action with\nprobability proportional to the exponential of the action's cumulative payoff\nover time. When players have perfect information on their mixed payoffs, the\nalgorithm converges locally to a strict equilibrium and the rate of convergence\nis exponentially fast - of the order of\n$\\mathcal{O}(\\exp(-a\\sum_{j=1}^{t}\\gamma_{j}))$ where $a>0$ is a constant and\n$\\gamma_{j}$ is the algorithm's step-size. In the presence of uncertainty,\nconvergence requires a more conservative step-size policy, but with high\nprobability, the algorithm remains locally convergent and achieves an\nexponential convergence rate. \n\n"}
{"id": "1608.03333", "contents": "Title: Temporal Learning and Sequence Modeling for a Job Recommender System Abstract: We present our solution to the job recommendation task for RecSys Challenge\n2016. The main contribution of our work is to combine temporal learning with\nsequence modeling to capture complex user-item activity patterns to improve job\nrecommendations. First, we propose a time-based ranking model applied to\nhistorical observations and a hybrid matrix factorization over time re-weighted\ninteractions. Second, we exploit sequence properties in user-items activities\nand develop a RNN-based recommendation model. Our solution achieved 5$^{th}$\nplace in the challenge among more than 100 participants. Notably, the strong\nperformance of our RNN approach shows a promising new direction in employing\nsequence modeling for recommendation systems. \n\n"}
{"id": "1608.03475", "contents": "Title: Data Collection and Wireless Communication in Internet of Things (IoT)\n  Using Economic Analysis and Pricing Models: A Survey Abstract: This paper provides a state-of-the-art literature review on economic analysis\nand pricing models for data collection and wireless communication in Internet\nof Things (IoT). Wireless Sensor Networks (WSNs) are the main component of IoT\nwhich collect data from the environment and transmit the data to the sink\nnodes. For long service time and low maintenance cost, WSNs require adaptive\nand robust designs to address many issues, e.g., data collection, topology\nformation, packet forwarding, resource and power optimization, coverage\noptimization, efficient task allocation, and security. For these issues,\nsensors have to make optimal decisions from current capabilities and available\nstrategies to achieve desirable goals. This paper reviews numerous applications\nof the economic and pricing models, known as intelligent rational\ndecision-making methods, to develop adaptive algorithms and protocols for WSNs.\nBesides, we survey a variety of pricing strategies in providing incentives for\nphone users in crowdsensing applications to contribute their sensing data.\nFurthermore, we consider the use of some pricing models in Machine-to-Machine\n(M2M) communication. Finally, we highlight some important open research issues\nas well as future research directions of applying economic and pricing models\nto IoT. \n\n"}
{"id": "1608.06879", "contents": "Title: AIDE: Fast and Communication Efficient Distributed Optimization Abstract: In this paper, we present two new communication-efficient methods for\ndistributed minimization of an average of functions. The first algorithm is an\ninexact variant of the DANE algorithm that allows any local algorithm to return\nan approximate solution to a local subproblem. We show that such a strategy\ndoes not affect the theoretical guarantees of DANE significantly. In fact, our\napproach can be viewed as a robustification strategy since the method is\nsubstantially better behaved than DANE on data partition arising in practice.\nIt is well known that DANE algorithm does not match the communication\ncomplexity lower bounds. To bridge this gap, we propose an accelerated variant\nof the first method, called AIDE, that not only matches the communication lower\nbounds but can also be implemented using a purely first-order oracle. Our\nempirical results show that AIDE is superior to other communication efficient\nalgorithms in settings that naturally arise in machine learning applications. \n\n"}
{"id": "1608.07005", "contents": "Title: Multi-View Fuzzy Clustering with Minimax Optimization for Effective\n  Clustering of Data from Multiple Sources Abstract: Multi-view data clustering refers to categorizing a data set by making good\nuse of related information from multiple representations of the data. It\nbecomes important nowadays because more and more data can be collected in a\nvariety of ways, in different settings and from different sources, so each data\nset can be represented by different sets of features to form different views of\nit. Many approaches have been proposed to improve clustering performance by\nexploring and integrating heterogeneous information underlying different views.\nIn this paper, we propose a new multi-view fuzzy clustering approach called\nMinimaxFCM by using minimax optimization based on well-known Fuzzy c means. In\nMinimaxFCM the consensus clustering results are generated based on minimax\noptimization in which the maximum disagreements of different weighted views are\nminimized. Moreover, the weight of each view can be learned automatically in\nthe clustering process. In addition, there is only one parameter to be set\nbesides the fuzzifier. The detailed problem formulation, updating rules\nderivation, and the in-depth analysis of the proposed MinimaxFCM are provided\nhere. Experimental studies on nine multi-view data sets including real world\nimage and document data sets have been conducted. We observed that MinimaxFCM\noutperforms related multi-view clustering approaches in terms of clustering\naccuracy, demonstrating the great potential of MinimaxFCM for multi-view data\nanalysis. \n\n"}
{"id": "1608.08337", "contents": "Title: Data Dependent Convergence for Distributed Stochastic Optimization Abstract: In this dissertation we propose alternative analysis of distributed\nstochastic gradient descent (SGD) algorithms that rely on spectral properties\nof the data covariance. As a consequence we can relate questions pertaining to\nspeedups and convergence rates for distributed SGD to the data distribution\ninstead of the regularity properties of the objective functions. More precisely\nwe show that this rate depends on the spectral norm of the sample covariance\nmatrix. An estimate of this norm can provide practitioners with guidance\ntowards a potential gain in algorithm performance. For example many sparse\ndatasets with low spectral norm prove to be amenable to gains in distributed\nsettings. Towards establishing this data dependence we first study a\ndistributed consensus-based SGD algorithm and show that the rate of convergence\ninvolves the spectral norm of the sample covariance matrix when the underlying\ndata is assumed to be independent and identically distributed (homogenous).\nThis dependence allows us to identify network regimes that prove to be\nbeneficial for datasets with low sample covariance spectral norm. Existing\nconsensus based analyses prove to be sub-optimal in the homogenous setting. Our\nanalysis method also allows us to find data-dependent convergence rates as we\nlimit the amount of communication. Spreading a fixed amount of data across more\nnodes slows convergence; in the asymptotic regime we show that adding more\nmachines can help when minimizing twice-differentiable losses. Since the\nmini-batch results don't follow from the consensus results we propose a\ndifferent data dependent analysis thereby providing theoretical validation for\nwhy certain datasets are more amenable to mini-batching. We also provide\nempirical evidence for results in this thesis. \n\n"}
{"id": "1609.03126", "contents": "Title: Energy-based Generative Adversarial Network Abstract: We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN)\nwhich views the discriminator as an energy function that attributes low\nenergies to the regions near the data manifold and higher energies to other\nregions. Similar to the probabilistic GANs, a generator is seen as being\ntrained to produce contrastive samples with minimal energies, while the\ndiscriminator is trained to assign high energies to these generated samples.\nViewing the discriminator as an energy function allows to use a wide variety of\narchitectures and loss functionals in addition to the usual binary classifier\nwith logistic output. Among them, we show one instantiation of EBGAN framework\nas using an auto-encoder architecture, with the energy being the reconstruction\nerror, in place of the discriminator. We show that this form of EBGAN exhibits\nmore stable behavior than regular GANs during training. We also show that a\nsingle-scale architecture can be trained to generate high-resolution images. \n\n"}
{"id": "1609.06826", "contents": "Title: Bibliographic Analysis with the Citation Network Topic Model Abstract: Bibliographic analysis considers author's research areas, the citation\nnetwork and paper content among other things. In this paper, we combine these\nthree in a topic model that produces a bibliographic model of authors, topics\nand documents using a non-parametric extension of a combination of the Poisson\nmixed-topic link model and the author-topic model. We propose a novel and\nefficient inference algorithm for the model to explore subsets of research\npublications from CiteSeerX. Our model demonstrates improved performance in\nboth model fitting and a clustering task compared to several baselines. \n\n"}
{"id": "1609.07537", "contents": "Title: A Tutorial on Distributed (Non-Bayesian) Learning: Problem, Algorithms\n  and Results Abstract: We overview some results on distributed learning with focus on a family of\nrecently proposed algorithms known as non-Bayesian social learning. We consider\ndifferent approaches to the distributed learning problem and its algorithmic\nsolutions for the case of finitely many hypotheses. The original centralized\nproblem is discussed at first, and then followed by a generalization to the\ndistributed setting. The results on convergence and convergence rate are\npresented for both asymptotic and finite time regimes. Various extensions are\ndiscussed such as those dealing with directed time-varying networks, Nesterov's\nacceleration technique and a continuum sets of hypothesis. \n\n"}
{"id": "1610.01314", "contents": "Title: Nash-Peering: A New Techno-Economic Framework for Internet\n  Interconnections Abstract: The current framework of Internet interconnections, based on transit and\nsettlement-free peering relations, has systemic problems that often cause\npeering disputes. We propose a new techno-economic interconnection framework\ncalled Nash-Peering, which is based on the principles of Nash Bargaining in\ngame theory and economics. Nash-Peering constitutes a radical departure from\ncurrent interconnection practices, providing a broader and more economically\nefficient set of interdomain relations. In particular, the direction of payment\nis not determined by the direction of traffic or by rigid customer-provider\nrelationships but based on which AS benefits more from the interconnection. We\nargue that Nash-Peering can address the root cause of various types of peering\ndisputes. \n\n"}
{"id": "1610.03474", "contents": "Title: The Core of the Participatory Budgeting Problem Abstract: In participatory budgeting, communities collectively decide on the allocation\nof public tax dollars for local public projects. In this work, we consider the\nquestion of fairly aggregating the preferences of community members to\ndetermine an allocation of funds to projects. This problem is different from\nstandard fair resource allocation because of public goods: The allocated goods\nbenefit all users simultaneously. Fairness is crucial in participatory decision\nmaking, since generating equitable outcomes is an important goal of these\nprocesses. We argue that the classic game theoretic notion of core captures\nfairness in the setting. To compute the core, we first develop a novel\ncharacterization of a public goods market equilibrium called the Lindahl\nequilibrium, which is always a core solution. We then provide the first (to our\nknowledge) polynomial time algorithm for computing such an equilibrium for a\nbroad set of utility functions; our algorithm also generalizes (in a\nnon-trivial way) the well-known concept of proportional fairness. We use our\ntheoretical insights to perform experiments on real participatory budgeting\nvoting data. We empirically show that the core can be efficiently computed for\nutility functions that naturally model our practical setting, and examine the\nrelation of the core with the familiar welfare objective. Finally, we address\nconcerns of incentives and mechanism design by developing a randomized\napproximately dominant-strategy truthful mechanism building on the exponential\nmechanism from differential privacy. \n\n"}
{"id": "1610.04454", "contents": "Title: A Budget Feasible Mechanism for Hiring Doctors in E-Healthcare Abstract: Throughout the past decade, there has been an extensive research on\nscheduling the hospital resources such as the operation theatre(s) (OTs) and\nthe experts (such as nurses, doctors etc.) inside the hospitals. With the\ntechnological growth, mainly advancement in communication media (such as smart\nphones, video conferencing, smart watches etc.) one may think of taking the\nexpertise by the doctors (distributed around the globe) from outside the\nin-house hospitals. Earlier this interesting situation of hiring doctors from\noutside the hospitals has been studied from monetary (with patient having\ninfinite budget) and non-monetary perspectives in strategic setting. In this\npaper, the more realistic situation is studied in terms of hiring the doctors\nfrom outside the hospital when a patient is constrained by budget. Our proposed\nmechanisms follow the two pass mechanism design framework each consisting of\nallocation rule and payment rule. Through simulations, we evaluate the\nperformance and validate our proposed mechanisms. \n\n"}
{"id": "1610.05246", "contents": "Title: BET on Independence Abstract: We study the problem of nonparametric dependence detection. Many existing\nmethods may suffer severe power loss due to non-uniform consistency, which we\nillustrate with a paradox. To avoid such power loss, we approach the\nnonparametric test of independence through the new framework of binary\nexpansion statistics (BEStat) and binary expansion testing (BET), which examine\ndependence through a novel binary expansion filtration approximation of the\ncopula. Through a Hadamard transform, we find that the symmetry statistics in\nthe filtration are complete sufficient statistics for dependence. These\nstatistics are also uncorrelated under the null. By utilizing symmetry\nstatistics, the BET avoids the problem of non-uniform consistency and improves\nupon a wide class of commonly used methods (a) by achieving the minimax rate in\nsample size requirement for reliable power and (b) by providing clear\ninterpretations of global relationships upon rejection of independence. The\nbinary expansion approach also connects the symmetry statistics with the\ncurrent computing system to facilitate efficient bitwise implementation. We\nillustrate the BET with a study of the distribution of stars in the night sky\nand with an exploratory data analysis of the TCGA breast cancer data. \n\n"}
{"id": "1610.07797", "contents": "Title: Frank-Wolfe Algorithms for Saddle Point Problems Abstract: We extend the Frank-Wolfe (FW) optimization algorithm to solve constrained\nsmooth convex-concave saddle point (SP) problems. Remarkably, the method only\nrequires access to linear minimization oracles. Leveraging recent advances in\nFW optimization, we provide the first proof of convergence of a FW-type saddle\npoint solver over polytopes, thereby partially answering a 30 year-old\nconjecture. We also survey other convergence results and highlight gaps in the\ntheoretical underpinnings of FW-style algorithms. Motivating applications\nwithout known efficient alternatives are explored through structured prediction\nwith combinatorial penalties as well as games over matching polytopes involving\nan exponential number of constraints. \n\n"}
{"id": "1610.07858", "contents": "Title: Bounding Average-energy Games Abstract: We consider average-energy games, where the goal is to minimize the long-run\naverage of the accumulated energy. While several results have been obtained on\nthese games recently, decidability of average-energy games with a lower-bound\nconstraint on the energy level (but no upper bound) remained open; in\nparticular, so far there was no known upper bound on the memory that is\nrequired for winning strategies.\n  By reducing average-energy games with lower-bounded energy to infinite-state\nmean-payoff games and analyzing the density of low-energy configurations, we\nshow an almost tight doubly-exponential upper bound on the necessary memory,\nand that the winner of average-energy games with lower-bounded energy can be\ndetermined in doubly-exponential time. We also prove EXPSPACE-hardness of this\nproblem.\n  Finally, we consider multi-dimensional extensions of all types of\naverage-energy games: without bounds, with only a lower bound, and with both a\nlower and an upper bound on the energy. We show that the fully-bounded version\nis the only case to remain decidable in multiple dimensions. \n\n"}
{"id": "1610.08738", "contents": "Title: Compressive K-means Abstract: The Lloyd-Max algorithm is a classical approach to perform K-means\nclustering. Unfortunately, its cost becomes prohibitive as the training dataset\ngrows large. We propose a compressive version of K-means (CKM), that estimates\ncluster centers from a sketch, i.e. from a drastically compressed\nrepresentation of the training dataset. We demonstrate empirically that CKM\nperforms similarly to Lloyd-Max, for a sketch size proportional to the number\nof cen-troids times the ambient dimension, and independent of the size of the\noriginal dataset. Given the sketch, the computational complexity of CKM is also\nindependent of the size of the dataset. Unlike Lloyd-Max which requires several\nreplicates, we further demonstrate that CKM is almost insensitive to\ninitialization. For a large dataset of 10^7 data points, we show that CKM can\nrun two orders of magnitude faster than five replicates of Lloyd-Max, with\nsimilar clustering performance on artificial data. Finally, CKM achieves lower\nclassification errors on handwritten digits classification. \n\n"}
{"id": "1611.00347", "contents": "Title: Surpassing Gradient Descent Provably: A Cyclic Incremental Method with\n  Linear Convergence Rate Abstract: Recently, there has been growing interest in developing optimization methods\nfor solving large-scale machine learning problems. Most of these problems boil\ndown to the problem of minimizing an average of a finite set of smooth and\nstrongly convex functions where the number of functions $n$ is large. Gradient\ndescent method (GD) is successful in minimizing convex problems at a fast\nlinear rate; however, it is not applicable to the considered large-scale\noptimization setting because of the high computational complexity. Incremental\nmethods resolve this drawback of gradient methods by replacing the required\ngradient for the descent direction with an incremental gradient approximation.\nThey operate by evaluating one gradient per iteration and executing the average\nof the $n$ available gradients as a gradient approximate. Although, incremental\nmethods reduce the computational cost of GD, their convergence rates do not\njustify their advantage relative to GD in terms of the total number of gradient\nevaluations until convergence. In this paper, we introduce a Double Incremental\nAggregated Gradient method (DIAG) that computes the gradient of only one\nfunction at each iteration, which is chosen based on a cyclic scheme, and uses\nthe aggregated average gradient of all the functions to approximate the full\ngradient. The iterates of the proposed DIAG method uses averages of both\niterates and gradients in oppose to classic incremental methods that utilize\ngradient averages but do not utilize iterate averages. We prove that not only\nthe proposed DIAG method converges linearly to the optimal solution, but also\nits linear convergence factor justifies the advantage of incremental methods on\nGD. In particular, we prove that the worst case performance of DIAG is better\nthan the worst case performance of GD. \n\n"}
{"id": "1611.01578", "contents": "Title: Neural Architecture Search with Reinforcement Learning Abstract: Neural networks are powerful and flexible models that work well for many\ndifficult learning tasks in image, speech and natural language understanding.\nDespite their success, neural networks are still hard to design. In this paper,\nwe use a recurrent network to generate the model descriptions of neural\nnetworks and train this RNN with reinforcement learning to maximize the\nexpected accuracy of the generated architectures on a validation set. On the\nCIFAR-10 dataset, our method, starting from scratch, can design a novel network\narchitecture that rivals the best human-invented architecture in terms of test\nset accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is\n0.09 percent better and 1.05x faster than the previous state-of-the-art model\nthat used a similar architectural scheme. On the Penn Treebank dataset, our\nmodel can compose a novel recurrent cell that outperforms the widely-used LSTM\ncell, and other state-of-the-art baselines. Our cell achieves a test set\nperplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than\nthe previous state-of-the-art model. The cell can also be transferred to the\ncharacter language modeling task on PTB and achieves a state-of-the-art\nperplexity of 1.214. \n\n"}
{"id": "1611.01673", "contents": "Title: Generative Multi-Adversarial Networks Abstract: Generative adversarial networks (GANs) are a framework for producing a\ngenerative model by way of a two-player minimax game. In this paper, we propose\nthe \\emph{Generative Multi-Adversarial Network} (GMAN), a framework that\nextends GANs to multiple discriminators. In previous work, the successful\ntraining of GANs requires modifying the minimax objective to accelerate\ntraining early on. In contrast, GMAN can be reliably trained with the original,\nuntampered objective. We explore a number of design perspectives with the\ndiscriminator role ranging from formidable adversary to forgiving teacher.\nImage generation tasks comparing the proposed framework to standard GANs\ndemonstrate GMAN produces higher quality samples in a fraction of the\niterations when measured by a pairwise GAM-type metric. \n\n"}
{"id": "1611.01957", "contents": "Title: Linear Convergence of SVRG in Statistical Estimation Abstract: SVRG and its variants are among the state of art optimization algorithms for\nlarge scale machine learning problems. It is well known that SVRG converges\nlinearly when the objective function is strongly convex. However this setup can\nbe restrictive, and does not include several important formulations such as\nLasso, group Lasso, logistic regression, and some non-convex models including\ncorrected Lasso and SCAD. In this paper, we prove that, for a class of\nstatistical M-estimators covering examples mentioned above, SVRG solves the\nformulation with {\\em a linear convergence rate} without strong convexity or\neven convexity. Our analysis makes use of {\\em restricted strong convexity},\nunder which we show that SVRG converges linearly to the fundamental statistical\nprecision of the model, i.e., the difference between true unknown parameter\n$\\theta^*$ and the optimal solution $\\hat{\\theta}$ of the model. \n\n"}
{"id": "1611.03218", "contents": "Title: Learning to Play Guess Who? and Inventing a Grounded Language as a\n  Consequence Abstract: Acquiring your first language is an incredible feat and not easily\nduplicated. Learning to communicate using nothing but a few pictureless books,\na corpus, would likely be impossible even for humans. Nevertheless, this is the\ndominating approach in most natural language processing today. As an\nalternative, we propose the use of situated interactions between agents as a\ndriving force for communication, and the framework of Deep Recurrent Q-Networks\nfor evolving a shared language grounded in the provided environment. We task\nthe agents with interactive image search in the form of the game Guess Who?.\nThe images from the game provide a non trivial environment for the agents to\ndiscuss and a natural grounding for the concepts they decide to encode in their\ncommunication. Our experiments show that the agents learn not only to encode\nphysical concepts in their words, i.e. grounding, but also that the agents\nlearn to hold a multi-step dialogue remembering the state of the dialogue from\nstep to step. \n\n"}
{"id": "1611.04361", "contents": "Title: Attending to Characters in Neural Sequence Labeling Models Abstract: Sequence labeling architectures use word embeddings for capturing similarity,\nbut suffer when handling previously unseen or rare words. We investigate\ncharacter-level extensions to such models and propose a novel architecture for\ncombining alternative word representations. By using an attention mechanism,\nthe model is able to dynamically decide how much information to use from a\nword- or character-level component. We evaluated different architectures on a\nrange of sequence labeling datasets, and character-level extensions were found\nto improve performance on every benchmark. In addition, the proposed\nattention-based architecture delivered the best results even with a smaller\nnumber of trainable parameters. \n\n"}
{"id": "1611.04982", "contents": "Title: Oracle Complexity of Second-Order Methods for Finite-Sum Problems Abstract: Finite-sum optimization problems are ubiquitous in machine learning, and are\ncommonly solved using first-order methods which rely on gradient computations.\nRecently, there has been growing interest in \\emph{second-order} methods, which\nrely on both gradients and Hessians. In principle, second-order methods can\nrequire much fewer iterations than first-order methods, and hold the promise\nfor more efficient algorithms. Although computing and manipulating Hessians is\nprohibitive for high-dimensional problems in general, the Hessians of\nindividual functions in finite-sum problems can often be efficiently computed,\ne.g. because they possess a low-rank structure. Can second-order information\nindeed be used to solve such problems more efficiently? In this paper, we\nprovide evidence that the answer -- perhaps surprisingly -- is negative, at\nleast in terms of worst-case guarantees. However, we also discuss what\nadditional assumptions and algorithmic approaches might potentially circumvent\nthis negative result. \n\n"}
{"id": "1611.06440", "contents": "Title: Pruning Convolutional Neural Networks for Resource Efficient Inference Abstract: We propose a new formulation for pruning convolutional kernels in neural\nnetworks to enable efficient inference. We interleave greedy criteria-based\npruning with fine-tuning by backpropagation - a computationally efficient\nprocedure that maintains good generalization in the pruned network. We propose\na new criterion based on Taylor expansion that approximates the change in the\ncost function induced by pruning network parameters. We focus on transfer\nlearning, where large pretrained networks are adapted to specialized tasks. The\nproposed criterion demonstrates superior performance compared to other\ncriteria, e.g. the norm of kernel weights or feature map activation, for\npruning large CNNs after adaptation to fine-grained classification tasks\n(Birds-200 and Flowers-102) relaying only on the first order gradient\ninformation. We also show that pruning can lead to more than 10x theoretical\n(5x practical) reduction in adapted 3D-convolutional filters with a small drop\nin accuracy in a recurrent gesture classifier. Finally, we show results for the\nlarge-scale ImageNet dataset to emphasize the flexibility of our approach. \n\n"}
{"id": "1611.06910", "contents": "Title: Simple Mechanisms for Subadditive Buyers via Duality Abstract: We provide simple and approximately revenue-optimal mechanisms in the\nmulti-item multi-bidder settings. We unify and improve all previous results, as\nwell as generalize the results to broader cases. In particular, we prove that\nthe better of the following two simple, deterministic and Dominant Strategy\nIncentive Compatible mechanisms, a sequential posted price mechanism or an\nanonymous sequential posted price mechanism with entry fee, achieves a constant\nfraction of the optimal revenue among all randomized, Bayesian Incentive\nCompatible mechanisms, when buyers' valuations are XOS over independent items.\nIf the buyers' valuations are subadditive over independent items, the\napproximation factor degrades to $O(\\log m)$, where $m$ is the number of items.\nWe obtain our results by first extending the Cai-Devanur-Weinberg duality\nframework to derive an effective benchmark of the optimal revenue for\nsubadditive bidders, and then analyzing this upper bound with new techniques. \n\n"}
{"id": "1611.07429", "contents": "Title: TreeView: Peeking into Deep Neural Networks Via Feature-Space\n  Partitioning Abstract: With the advent of highly predictive but opaque deep learning models, it has\nbecome more important than ever to understand and explain the predictions of\nsuch models. Existing approaches define interpretability as the inverse of\ncomplexity and achieve interpretability at the cost of accuracy. This\nintroduces a risk of producing interpretable but misleading explanations. As\nhumans, we are prone to engage in this kind of behavior \\cite{mythos}. In this\npaper, we take a step in the direction of tackling the problem of\ninterpretability without compromising the model accuracy. We propose to build a\nTreeview representation of the complex model via hierarchical partitioning of\nthe feature space, which reveals the iterative rejection of unlikely class\nlabels until the correct association is predicted. \n\n"}
{"id": "1611.07567", "contents": "Title: Feature Importance Measure for Non-linear Learning Algorithms Abstract: Complex problems may require sophisticated, non-linear learning methods such\nas kernel machines or deep neural networks to achieve state of the art\nprediction accuracies. However, high prediction accuracies are not the only\nobjective to consider when solving problems using machine learning. Instead,\nparticular scientific applications require some explanation of the learned\nprediction function. Unfortunately, most methods do not come with out of the\nbox straight forward interpretation. Even linear prediction functions are not\nstraight forward to explain if features exhibit complex correlation structure.\n  In this paper, we propose the Measure of Feature Importance (MFI). MFI is\ngeneral and can be applied to any arbitrary learning machine (including kernel\nmachines and deep learning). MFI is intrinsically non-linear and can detect\nfeatures that by itself are inconspicuous and only impact the prediction\nfunction through their interaction with other features. Lastly, MFI can be used\nfor both --- model-based feature importance and instance-based feature\nimportance (i.e, measuring the importance of a feature for a particular data\npoint). \n\n"}
{"id": "1611.10041", "contents": "Title: Subsampled online matrix factorization with convergence guarantees Abstract: We present a matrix factorization algorithm that scales to input matrices\nthat are large in both dimensions (i.e., that contains morethan 1TB of data).\nThe algorithm streams the matrix columns while subsampling them, resulting in\nlow complexity per iteration andreasonable memory footprint. In contrast to\nprevious online matrix factorization methods, our approach relies on\nlow-dimensional statistics from past iterates to control the extra variance\nintroduced by subsampling. We present a convergence analysis that guarantees us\nto reach a stationary point of the problem. Large speed-ups can be obtained\ncompared to previous online algorithms that do not perform subsampling, thanks\nto the feature redundancy that often exists in high-dimensional settings. \n\n"}
{"id": "1612.00100", "contents": "Title: Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling Abstract: We study the problem of recovering an incomplete $m\\times n$ matrix of rank\n$r$ with columns arriving online over time. This is known as the problem of\nlife-long matrix completion, and is widely applied to recommendation system,\ncomputer vision, system identification, etc. The challenge is to design\nprovable algorithms tolerant to a large amount of noises, with small sample\ncomplexity. In this work, we give algorithms achieving strong guarantee under\ntwo realistic noise models. In bounded deterministic noise, an adversary can\nadd any bounded yet unstructured noise to each column. For this problem, we\npresent an algorithm that returns a matrix of a small error, with sample\ncomplexity almost as small as the best prior results in the noiseless case. For\nsparse random noise, where the corrupted columns are sparse and drawn randomly,\nwe give an algorithm that exactly recovers an $\\mu_0$-incoherent matrix by\nprobability at least $1-\\delta$ with sample complexity as small as\n$O\\left(\\mu_0rn\\log (r/\\delta)\\right)$. This result advances the\nstate-of-the-art work and matches the lower bound in a worst case. We also\nstudy the scenario where the hidden matrix lies on a mixture of subspaces and\nshow that the sample complexity can be even smaller. Our proposed algorithms\nperform well experimentally in both synthetic and real-world datasets. \n\n"}
{"id": "1612.00516", "contents": "Title: Canonical Correlation Analysis for Analyzing Sequences of Medical\n  Billing Codes Abstract: We propose using canonical correlation analysis (CCA) to generate features\nfrom sequences of medical billing codes. Applying this novel use of CCA to a\ndatabase of medical billing codes for patients with diverticulitis, we first\ndemonstrate that the CCA embeddings capture meaningful relationships among the\ncodes. We then generate features from these embeddings and establish their\nusefulness in predicting future elective surgery for diverticulitis, an\nimportant marker in efforts for reducing costs in healthcare. \n\n"}
{"id": "1612.00542", "contents": "Title: Breast Mass Classification from Mammograms using Deep Convolutional\n  Neural Networks Abstract: Mammography is the most widely used method to screen breast cancer. Because\nof its mostly manual nature, variability in mass appearance, and low\nsignal-to-noise ratio, a significant number of breast masses are missed or\nmisdiagnosed. In this work, we present how Convolutional Neural Networks can be\nused to directly classify pre-segmented breast masses in mammograms as benign\nor malignant, using a combination of transfer learning, careful pre-processing\nand data augmentation to overcome limited training data. We achieve\nstate-of-the-art results on the DDSM dataset, surpassing human performance, and\nshow interpretability of our model. \n\n"}
{"id": "1612.00554", "contents": "Title: Higher Order Mutual Information Approximation for Feature Selection Abstract: Feature selection is a process of choosing a subset of relevant features so\nthat the quality of prediction models can be improved. An extensive body of\nwork exists on information-theoretic feature selection, based on maximizing\nMutual Information (MI) between subsets of features and class labels. The prior\nmethods use a lower order approximation, by treating the joint entropy as a\nsummation of several single variable entropies. This leads to locally optimal\nselections and misses multi-way feature combinations. We present a higher order\nMI based approximation technique called Higher Order Feature Selection (HOFS).\nInstead of producing a single list of features, our method produces a ranked\ncollection of feature subsets that maximizes MI, giving better comprehension\n(feature ranking) as to which features work best together when selected, due to\ntheir underlying interdependent structure. Our experiments demonstrate that the\nproposed method performs better than existing feature selection approaches\nwhile keeping similar running times and computational complexity. \n\n"}
{"id": "1612.01086", "contents": "Title: Deep Learning of Robotic Tasks without a Simulator using Strong and Weak\n  Human Supervision Abstract: We propose a scheme for training a computerized agent to perform complex\nhuman tasks such as highway steering. The scheme is designed to follow a\nnatural learning process whereby a human instructor teaches a computerized\ntrainee. The learning process consists of five elements: (i) unsupervised\nfeature learning; (ii) supervised imitation learning; (iii) supervised reward\ninduction; (iv) supervised safety module construction; and (v) reinforcement\nlearning. We implemented the last four elements of the scheme using deep\nconvolutional networks and applied it to successfully create a computerized\nagent capable of autonomous highway steering over the well-known racing game\nAssetto Corsa. We demonstrate that the use of the last four elements is\nessential to effectively carry out the steering task using vision alone,\nwithout access to a driving simulator internals, and operating in wall-clock\ntime. This is made possible also through the introduction of a safety network,\na novel way for preventing the agent from performing catastrophic mistakes\nduring the reinforcement learning stage. \n\n"}
{"id": "1612.01600", "contents": "Title: Distributed Gaussian Learning over Time-varying Directed Graphs Abstract: We present a distributed (non-Bayesian) learning algorithm for the problem of\nparameter estimation with Gaussian noise. The algorithm is expressed as\nexplicit updates on the parameters of the Gaussian beliefs (i.e. means and\nprecision). We show a convergence rate of $O(1/k)$ with the constant term\ndepending on the number of agents and the topology of the network. Moreover, we\nshow almost sure convergence to the optimal solution of the estimation problem\nfor the general case of time-varying directed graphs. \n\n"}
{"id": "1612.02712", "contents": "Title: Scalable Influence Maximization for Multiple Products in Continuous-Time\n  Diffusion Networks Abstract: A typical viral marketing model identifies influential users in a social\nnetwork to maximize a single product adoption assuming unlimited user\nattention, campaign budgets, and time. In reality, multiple products need\ncampaigns, users have limited attention, convincing users incurs costs, and\nadvertisers have limited budgets and expect the adoptions to be maximized soon.\nFacing these user, monetary, and timing constraints, we formulate the problem\nas a submodular maximization task in a continuous-time diffusion model under\nthe intersection of a matroid and multiple knapsack constraints. We propose a\nrandomized algorithm estimating the user influence in a network\n($|\\mathcal{V}|$ nodes, $|\\mathcal{E}|$ edges) to an accuracy of $\\epsilon$\nwith $n=\\mathcal{O}(1/\\epsilon^2)$ randomizations and\n$\\tilde{\\mathcal{O}}(n|\\mathcal{E}|+n|\\mathcal{V}|)$ computations. By\nexploiting the influence estimation algorithm as a subroutine, we develop an\nadaptive threshold greedy algorithm achieving an approximation factor $k_a/(2+2\nk)$ of the optimal when $k_a$ out of the $k$ knapsack constraints are active.\nExtensive experiments on networks of millions of nodes demonstrate that the\nproposed algorithms achieve the state-of-the-art in terms of effectiveness and\nscalability. \n\n"}
{"id": "1612.03349", "contents": "Title: An Empirical Study of ADMM for Nonconvex Problems Abstract: The alternating direction method of multipliers (ADMM) is a common\noptimization tool for solving constrained and non-differentiable problems. We\nprovide an empirical study of the practical performance of ADMM on several\nnonconvex applications, including l0 regularized linear regression, l0\nregularized image denoising, phase retrieval, and eigenvector computation. Our\nexperiments suggest that ADMM performs well on a broad class of non-convex\nproblems. Moreover, recently proposed adaptive ADMM methods, which\nautomatically tune penalty parameters as the method runs, can improve algorithm\nefficiency and solution quality compared to ADMM with a non-tuned penalty. \n\n"}
{"id": "1612.04022", "contents": "Title: Distributed Multi-Task Relationship Learning Abstract: Multi-task learning aims to learn multiple tasks jointly by exploiting their\nrelatedness to improve the generalization performance for each task.\nTraditionally, to perform multi-task learning, one needs to centralize data\nfrom all the tasks to a single machine. However, in many real-world\napplications, data of different tasks may be geo-distributed over different\nlocal machines. Due to heavy communication caused by transmitting the data and\nthe issue of data privacy and security, it is impossible to send data of\ndifferent task to a master machine to perform multi-task learning. Therefore,\nin this paper, we propose a distributed multi-task learning framework that\nsimultaneously learns predictive models for each task as well as task\nrelationships between tasks alternatingly in the parameter server paradigm. In\nour framework, we first offer a general dual form for a family of regularized\nmulti-task relationship learning methods. Subsequently, we propose a\ncommunication-efficient primal-dual distributed optimization algorithm to solve\nthe dual problem by carefully designing local subproblems to make the dual\nproblem decomposable. Moreover, we provide a theoretical convergence analysis\nfor the proposed algorithm, which is specific for distributed multi-task\nrelationship learning. We conduct extensive experiments on both synthetic and\nreal-world datasets to evaluate our proposed framework in terms of\neffectiveness and convergence. \n\n"}
{"id": "1612.04440", "contents": "Title: Disentangling Space and Time in Video with Hierarchical Variational\n  Auto-encoders Abstract: There are many forms of feature information present in video data. Principle\namong them are object identity information which is largely static across\nmultiple video frames, and object pose and style information which continuously\ntransforms from frame to frame. Most existing models confound these two types\nof representation by mapping them to a shared feature space. In this paper we\npropose a probabilistic approach for learning separable representations of\nobject identity and pose information using unsupervised video data. Our\napproach leverages a deep generative model with a factored prior distribution\nthat encodes properties of temporal invariances in the hidden feature set.\nLearning is achieved via variational inference. We present results of learning\nidentity and pose information on a dataset of moving characters as well as a\ndataset of rotating 3D objects. Our experimental results demonstrate our\nmodel's success in factoring its representation, and demonstrate that the model\nachieves improved performance in transfer learning tasks. \n\n"}
{"id": "1612.05708", "contents": "Title: Mutual information for fitting deep nonlinear models Abstract: Deep nonlinear models pose a challenge for fitting parameters due to lack of\nknowledge of the hidden layer and the potentially non-affine relation of the\ninitial and observed layers. In the present work we investigate the use of\ninformation theoretic measures such as mutual information and Kullback-Leibler\n(KL) divergence as objective functions for fitting such models without\nknowledge of the hidden layer. We investigate one model as a proof of concept\nand one application of cogntive performance. We further investigate the use of\noptimizers with these methods. Mutual information is largely successful as an\nobjective, depending on the parameters. KL divergence is found to be similarly\nsuccesful, given some knowledge of the statistics of the hidden layer. \n\n"}
{"id": "1612.06340", "contents": "Title: Computing Human-Understandable Strategies Abstract: Algorithms for equilibrium computation generally make no attempt to ensure\nthat the computed strategies are understandable by humans. For instance the\nstrategies for the strongest poker agents are represented as massive binary\nfiles. In many situations, we would like to compute strategies that can\nactually be implemented by humans, who may have computational limitations and\nmay only be able to remember a small number of features or components of the\nstrategies that have been computed. We study poker games where private\ninformation distributions can be arbitrary. We create a large training set of\ngame instances and solutions, by randomly selecting the information\nprobabilities, and present algorithms that learn from the training instances in\norder to perform well in games with unseen information distributions. We are\nable to conclude several new fundamental rules about poker strategy that can be\neasily implemented by humans. \n\n"}
{"id": "1612.06347", "contents": "Title: On-demand or Spot? Selling the cloud to risk-averse customers Abstract: In Amazon EC2, cloud resources are sold through a combination of an on-demand\nmarket, in which customers buy resources at a fixed price, and a spot market,\nin which customers bid for an uncertain supply of excess resources. Standard\nmarket environments suggest that an optimal design uses just one type of\nmarket. We show the prevalence of a dual market system can be explained by\nheterogeneous risk attitudes of customers. In our stylized model, we consider\nunit demand risk-averse bidders. We show the model admits a unique equilibrium,\nwith higher revenue and higher welfare than using only spot markets.\nFurthermore, as risk aversion increases, the usage of the on-demand market\nincreases. We conclude that risk attitudes are an important factor in cloud\nresource allocation and should be incorporated into models of cloud markets. \n\n"}
{"id": "1612.06623", "contents": "Title: Supervised Learning for Optimal Power Flow as a Real-Time Proxy Abstract: In this work we design and compare different supervised learning algorithms\nto compute the cost of Alternating Current Optimal Power Flow (ACOPF). The\nmotivation for quick calculation of OPF cost outcomes stems from the growing\nneed of algorithmic-based long-term and medium-term planning methodologies in\npower networks. Integrated in a multiple time-horizon coordination framework,\nwe refer to this approximation module as a proxy for predicting short-term\ndecision outcomes without the need of actual simulation and optimization of\nthem. Our method enables fast approximate calculation of OPF cost with less\nthan 1% error on average, achieved in run-times that are several orders of\nmagnitude lower than of exact computation. Several test-cases such as\nIEEE-RTS96 are used to demonstrate the efficiency of our approach. \n\n"}
{"id": "1612.06669", "contents": "Title: Enhancing Observability in Distribution Grids using Smart Meter Data Abstract: Due to limited metering infrastructure, distribution grids are currently\nchallenged by observability issues. On the other hand, smart meter data,\nincluding local voltage magnitudes and power injections, are communicated to\nthe utility operator from grid buses with renewable generation and\ndemand-response programs. This work employs grid data from metered buses\ntowards inferring the underlying grid state. To this end, a coupled formulation\nof the power flow problem (CPF) is put forth. Exploiting the high variability\nof injections at metered buses, the controllability of solar inverters, and the\nrelative time-invariance of conventional loads, the idea is to solve the\nnon-linear power flow equations jointly over consecutive time instants. An\nintuitive and easily verifiable rule pertaining to the locations of metered and\nnon-metered buses on the physical grid is shown to be a necessary and\nsufficient criterion for local observability in radial networks. To account for\nnoisy smart meter readings, a coupled power system state estimation (CPSSE)\nproblem is further developed. Both CPF and CPSSE tasks are tackled via\naugmented semi-definite program relaxations. The observability criterion along\nwith the CPF and CPSSE solvers are numerically corroborated using synthetic and\nactual solar generation and load data on the IEEE 34-bus benchmark feeder. \n\n"}
{"id": "1612.07179", "contents": "Title: Nash Equilibrium Seeking with Non-doubly Stochastic Communication Weight\n  Matrix Abstract: A distributed Nash equilibrium seeking algorithm is presented for networked\ngames. We assume an incomplete information available to each player about the\nother players' actions. The players communicate over a strongly connected\ndigraph to send/receive the estimates of the other players' actions to/from the\nother local players according to a gossip communication protocol. Due to\nasymmetric information exchange between the players, a non-doubly (row)\nstochastic weight matrix is defined. We show that, due to the non-doubly\nstochastic property, the total average of all players' estimates is not\npreserved for the next iteration which results in having no exact convergence.\nWe present an almost sure convergence proof of the algorithm to a Nash\nequilibrium of the game. Then, we extend the algorithm for graphical games in\nwhich all players' cost functions are only dependent on the local neighboring\nplayers over an interference digraph. We design an assumption on the\ncommunication digraph such that the players are able to update all the\nestimates of the players who interfere with their cost functions. It is shown\nthat the communication digraph needs to be a superset of a transitive reduction\nof the interference digraph. Finally, we verify the efficacy of the algorithm\nvia a simulation on a social media behavioral case. \n\n"}
{"id": "1612.07182", "contents": "Title: Multi-Agent Cooperation and the Emergence of (Natural) Language Abstract: The current mainstream approach to train natural language systems is to\nexpose them to large amounts of text. This passive learning is problematic if\nwe are interested in developing interactive machines, such as conversational\nagents. We propose a framework for language learning that relies on multi-agent\ncommunication. We study this learning in the context of referential games. In\nthese games, a sender and a receiver see a pair of images. The sender is told\none of them is the target and is allowed to send a message from a fixed,\narbitrary vocabulary to the receiver. The receiver must rely on this message to\nidentify the target. Thus, the agents develop their own language interactively\nout of the need to communicate. We show that two networks with simple\nconfigurations are able to learn to coordinate in the referential game. We\nfurther explore how to make changes to the game environment to cause the \"word\nmeanings\" induced in the game to better reflect intuitive semantic properties\nof the images. In addition, we present a simple strategy for grounding the\nagents' code into natural language. Both of these are necessary steps towards\ndeveloping machines that are able to communicate with humans productively. \n\n"}
{"id": "1612.07976", "contents": "Title: DeMIAN: Deep Modality Invariant Adversarial Network Abstract: Obtaining common representations from different modalities is important in\nthat they are interchangeable with each other in a classification problem. For\nexample, we can train a classifier on image features in the common\nrepresentations and apply it to the testing of the text features in the\nrepresentations. Existing multi-modal representation learning methods mainly\naim to extract rich information from paired samples and train a classifier by\nthe corresponding labels; however, collecting paired samples and their labels\nsimultaneously involves high labor costs. Addressing paired modal samples\nwithout their labels and single modal data with their labels independently is\nmuch easier than addressing labeled multi-modal data. To obtain the common\nrepresentations under such a situation, we propose to make the distributions\nover different modalities similar in the learned representations, namely\nmodality-invariant representations. In particular, we propose a novel algorithm\nfor modality-invariant representation learning, named Deep Modality Invariant\nAdversarial Network (DeMIAN), which utilizes the idea of Domain Adaptation\n(DA). Using the modality-invariant representations learned by DeMIAN, we\nachieved better classification accuracy than with the state-of-the-art methods,\nespecially for some benchmark datasets of zero-shot learning. \n\n"}
{"id": "1612.08461", "contents": "Title: Randomized Block Frank-Wolfe for Convergent Large-Scale Learning Abstract: Owing to their low-complexity iterations, Frank-Wolfe (FW) solvers are well\nsuited for various large-scale learning tasks. When block-separable constraints\nare present, randomized block FW (RB-FW) has been shown to further reduce\ncomplexity by updating only a fraction of coordinate blocks per iteration. To\ncircumvent the limitations of existing methods, the present work develops step\nsizes for RB-FW that enable a flexible selection of the number of blocks to\nupdate per iteration while ensuring convergence and feasibility of the\niterates. To this end, convergence rates of RB-FW are established through\ncomputational bounds on a primal sub-optimality measure and on the duality gap.\nThe novel bounds extend the existing convergence analysis, which only applies\nto a step-size sequence that does not generally lead to feasible iterates.\nFurthermore, two classes of step-size sequences that guarantee feasibility of\nthe iterates are also proposed to enhance flexibility in choosing decay rates.\nThe novel convergence results are markedly broadened to encompass also\nnonconvex objectives, and further assert that RB-FW with exact line-search\nreaches a stationary point at rate $\\mathcal{O}(1/\\sqrt{t})$. Performance of\nRB-FW with different step sizes and number of blocks is demonstrated in two\napplications, namely charging of electrical vehicles and structural support\nvector machines. Extensive simulated tests demonstrate the performance\nimprovement of RB-FW relative to existing randomized single-block FW methods. \n\n"}
{"id": "1612.09034", "contents": "Title: Geometric descent method for convex composite minimization Abstract: In this paper, we extend the geometric descent method recently proposed by\nBubeck, Lee and Singh to tackle nonsmooth and strongly convex composite\nproblems. We prove that our proposed algorithm, dubbed geometric proximal\ngradient method (GeoPG), converges with a linear rate $(1-1/\\sqrt{\\kappa})$ and\nthus achieves the optimal rate among first-order methods, where $\\kappa$ is the\ncondition number of the problem. Numerical results on linear regression and\nlogistic regression with elastic net regularization show that GeoPG compares\nfavorably with Nesterov's accelerated proximal gradient method, especially when\nthe problem is ill-conditioned. \n\n"}
{"id": "1701.00485", "contents": "Title: Two-Bit Networks for Deep Learning on Resource-Constrained Embedded\n  Devices Abstract: With the rapid proliferation of Internet of Things and intelligent edge\ndevices, there is an increasing need for implementing machine learning\nalgorithms, including deep learning, on resource-constrained mobile embedded\ndevices with limited memory and computation power. Typical large Convolutional\nNeural Networks (CNNs) need large amounts of memory and computational power,\nand cannot be deployed on embedded devices efficiently. We present Two-Bit\nNetworks (TBNs) for model compression of CNNs with edge weights constrained to\n(-2, -1, 1, 2), which can be encoded with two bits. Our approach can reduce the\nmemory usage and improve computational efficiency significantly while achieving\ngood performance in terms of classification accuracy, thus representing a\nreasonable tradeoff between model size and performance. \n\n"}
{"id": "1701.03537", "contents": "Title: Perishability of Data: Dynamic Pricing under Varying-Coefficient Models Abstract: We consider a firm that sells a large number of products to its customers in\nan online fashion. Each product is described by a high dimensional feature\nvector, and the market value of a product is assumed to be linear in the values\nof its features. Parameters of the valuation model are unknown and can change\nover time. The firm sequentially observes a product's features and can use the\nhistorical sales data (binary sale/no sale feedbacks) to set the price of\ncurrent product, with the objective of maximizing the collected revenue. We\nmeasure the performance of a dynamic pricing policy via regret, which is the\nexpected revenue loss compared to a clairvoyant that knows the sequence of\nmodel parameters in advance.\n  We propose a pricing policy based on projected stochastic gradient descent\n(PSGD) and characterize its regret in terms of time $T$, features dimension\n$d$, and the temporal variability in the model parameters, $\\delta_t$. We\nconsider two settings. In the first one, feature vectors are chosen\nantagonistically by nature and we prove that the regret of PSGD pricing policy\nis of order $O(\\sqrt{T} + \\sum_{t=1}^T \\sqrt{t}\\delta_t)$. In the second\nsetting (referred to as stochastic features model), the feature vectors are\ndrawn independently from an unknown distribution. We show that in this case,\nthe regret of PSGD pricing policy is of order $O(d^2 \\log T + \\sum_{t=1}^T\nt\\delta_t/d)$. \n\n"}
{"id": "1701.03961", "contents": "Title: Communication-Efficient Algorithms for Decentralized and Stochastic\n  Optimization Abstract: We present a new class of decentralized first-order methods for nonsmooth and\nstochastic optimization problems defined over multiagent networks. Considering\nthat communication is a major bottleneck in decentralized optimization, our\nmain goal in this paper is to develop algorithmic frameworks which can\nsignificantly reduce the number of inter-node communications. We first propose\na decentralized primal-dual method which can find an $\\epsilon$-solution both\nin terms of functional optimality gap and feasibility residual in\n$O(1/\\epsilon)$ inter-node communication rounds when the objective functions\nare convex and the local primal subproblems are solved exactly. Our major\ncontribution is to present a new class of decentralized primal-dual type\nalgorithms, namely the decentralized communication sliding (DCS) methods, which\ncan skip the inter-node communications while agents solve the primal\nsubproblems iteratively through linearizations of their local objective\nfunctions. By employing DCS, agents can still find an $\\epsilon$-solution in\n$O(1/\\epsilon)$ (resp., $O(1/\\sqrt{\\epsilon})$) communication rounds for\ngeneral convex functions (resp., strongly convex functions), while maintaining\nthe $O(1/\\epsilon^2)$ (resp., $O(1/\\epsilon)$) bound on the total number of\nintra-node subgradient evaluations. We also present a stochastic counterpart\nfor these algorithms, denoted by SDCS, for solving stochastic optimization\nproblems whose objective function cannot be evaluated exactly. In comparison\nwith existing results for decentralized nonsmooth and stochastic optimization,\nwe can reduce the total number of inter-node communication rounds by orders of\nmagnitude while still maintaining the optimal complexity bounds on intra-node\nstochastic subgradient evaluations. The bounds on the subgradient evaluations\nare actually comparable to those required for centralized nonsmooth and\nstochastic optimization. \n\n"}
{"id": "1701.05517", "contents": "Title: PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture\n  Likelihood and Other Modifications Abstract: PixelCNNs are a recently proposed class of powerful generative models with\ntractable likelihood. Here we discuss our implementation of PixelCNNs which we\nmake available at https://github.com/openai/pixel-cnn. Our implementation\ncontains a number of modifications to the original model that both simplify its\nstructure and improve its performance. 1) We use a discretized logistic mixture\nlikelihood on the pixels, rather than a 256-way softmax, which we find to speed\nup training. 2) We condition on whole pixels, rather than R/G/B sub-pixels,\nsimplifying the model structure. 3) We use downsampling to efficiently capture\nstructure at multiple resolutions. 4) We introduce additional short-cut\nconnections to further speed up optimization. 5) We regularize the model using\ndropout. Finally, we present state-of-the-art log likelihood results on\nCIFAR-10 to demonstrate the usefulness of these modifications. \n\n"}
{"id": "1701.06511", "contents": "Title: Aggressive Sampling for Multi-class to Binary Reduction with\n  Applications to Text Classification Abstract: We address the problem of multi-class classification in the case where the\nnumber of classes is very large. We propose a double sampling strategy on top\nof a multi-class to binary reduction strategy, which transforms the original\nmulti-class problem into a binary classification problem over pairs of\nexamples. The aim of the sampling strategy is to overcome the curse of\nlong-tailed class distributions exhibited in majority of large-scale\nmulti-class classification problems and to reduce the number of pairs of\nexamples in the expanded data. We show that this strategy does not alter the\nconsistency of the empirical risk minimization principle defined over the\ndouble sample reduction. Experiments are carried out on DMOZ and Wikipedia\ncollections with 10,000 to 100,000 classes where we show the efficiency of the\nproposed approach in terms of training and prediction time, memory consumption,\nand predictive performance with respect to state-of-the-art approaches. \n\n"}
{"id": "1702.00709", "contents": "Title: IQN: An Incremental Quasi-Newton Method with Local Superlinear\n  Convergence Rate Abstract: The problem of minimizing an objective that can be written as the sum of a\nset of $n$ smooth and strongly convex functions is considered. The Incremental\nQuasi-Newton (IQN) method proposed here belongs to the family of stochastic and\nincremental methods that have a cost per iteration independent of $n$. IQN\niterations are a stochastic version of BFGS iterations that use memory to\nreduce the variance of stochastic approximations. The convergence properties of\nIQN bridge a gap between deterministic and stochastic quasi-Newton methods.\nDeterministic quasi-Newton methods exploit the possibility of approximating the\nNewton step using objective gradient differences. They are appealing because\nthey have a smaller computational cost per iteration relative to Newton's\nmethod and achieve a superlinear convergence rate under customary regularity\nassumptions. Stochastic quasi-Newton methods utilize stochastic gradient\ndifferences in lieu of actual gradient differences. This makes their\ncomputational cost per iteration independent of the number of objective\nfunctions $n$. However, existing stochastic quasi-Newton methods have sublinear\nor linear convergence at best. IQN is the first stochastic quasi-Newton method\nproven to converge superlinearly in a local neighborhood of the optimal\nsolution. IQN differs from state-of-the-art incremental quasi-Newton methods in\nthree aspects: (i) The use of aggregated information of variables, gradients,\nand quasi-Newton Hessian approximation matrices to reduce the noise of gradient\nand Hessian approximations. (ii) The approximation of each individual function\nby its Taylor's expansion in which the linear and quadratic terms are evaluated\nwith respect to the same iterate. (iii) The use of a cyclic scheme to update\nthe functions in lieu of a random selection routine. We use these fundamental\nproperties of IQN to establish its local superlinear convergence rate. \n\n"}
{"id": "1702.05548", "contents": "Title: Bi-Level Online Control without Regret Abstract: This paper considers a bi-level discrete-time control framework with\nreal-time constraints, consisting of several local controllers and a central\ncontroller. The objective is to bridge the gap between the online convex\noptimization and real-time control literature by proposing an online control\nalgorithm with small dynamic regret, which is a natural performance criterion\nin nonstationary environments related to real-time control problems. We\nillustrate how the proposed algorithm can be applied to real-time control of\npower setpoints in an electrical grid. \n\n"}
{"id": "1702.07064", "contents": "Title: Learning Model Predictive Control for Iterative Tasks: A Computationally\n  Efficient Approach for Linear System Abstract: A Learning Model Predictive Controller (LMPC) for linear system in presented.\nThe proposed controller is an extension of the LMPC [1] and it aims to decrease\nthe computational burden. The control scheme is reference-free and is able to\nimprove its performance by learning from previous iterations. A convex safe set\nand a terminal cost function are used in order to guarantee recursive\nfeasibility and non-increasing performance at each iteration. The paper\npresents the control design approach, and shows how to recursively construct\nthe convex terminal set and the terminal cost from state and input trajectories\nof previous iterations. Simulation results show the effectiveness of the\nproposed control logic. \n\n"}
{"id": "1702.08165", "contents": "Title: Reinforcement Learning with Deep Energy-Based Policies Abstract: We propose a method for learning expressive energy-based policies for\ncontinuous states and actions, which has been feasible only in tabular domains\nbefore. We apply our method to learning maximum entropy policies, resulting\ninto a new algorithm, called soft Q-learning, that expresses the optimal policy\nvia a Boltzmann distribution. We use the recently proposed amortized Stein\nvariational gradient descent to learn a stochastic sampling network that\napproximates samples from this distribution. The benefits of the proposed\nalgorithm include improved exploration and compositionality that allows\ntransferring skills between tasks, which we confirm in simulated experiments\nwith swimming and walking robots. We also draw a connection to actor-critic\nmethods, which can be viewed performing approximate inference on the\ncorresponding energy-based model. \n\n"}
{"id": "1702.08536", "contents": "Title: Fast Threshold Tests for Detecting Discrimination Abstract: Threshold tests have recently been proposed as a useful method for detecting\nbias in lending, hiring, and policing decisions. For example, in the case of\ncredit extensions, these tests aim to estimate the bar for granting loans to\nwhite and minority applicants, with a higher inferred threshold for minorities\nindicative of discrimination. This technique, however, requires fitting a\ncomplex Bayesian latent variable model for which inference is often\ncomputationally challenging. Here we develop a method for fitting threshold\ntests that is two orders of magnitude faster than the existing approach,\nreducing computation from hours to minutes. To achieve these performance gains,\nwe introduce and analyze a flexible family of probability distributions on the\ninterval [0, 1] -- which we call discriminant distributions -- that is\ncomputationally efficient to work with. We demonstrate our technique by\nanalyzing 2.7 million police stops of pedestrians in New York City. \n\n"}
{"id": "1702.08887", "contents": "Title: Stabilising Experience Replay for Deep Multi-Agent Reinforcement\n  Learning Abstract: Many real-world problems, such as network packet routing and urban traffic\ncontrol, are naturally modeled as multi-agent reinforcement learning (RL)\nproblems. However, existing multi-agent RL methods typically scale poorly in\nthe problem size. Therefore, a key challenge is to translate the success of\ndeep learning on single-agent RL to the multi-agent setting. A major stumbling\nblock is that independent Q-learning, the most popular multi-agent RL method,\nintroduces nonstationarity that makes it incompatible with the experience\nreplay memory on which deep Q-learning relies. This paper proposes two methods\nthat address this problem: 1) using a multi-agent variant of importance\nsampling to naturally decay obsolete data and 2) conditioning each agent's\nvalue function on a fingerprint that disambiguates the age of the data sampled\nfrom the replay memory. Results on a challenging decentralised variant of\nStarCraft unit micromanagement confirm that these methods enable the successful\ncombination of experience replay with multi-agent RL. \n\n"}
{"id": "1703.00096", "contents": "Title: Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence\n  Labelling Abstract: Most existing sequence labelling models rely on a fixed decomposition of a\ntarget sequence into a sequence of basic units. These methods suffer from two\nmajor drawbacks: 1) the set of basic units is fixed, such as the set of words,\ncharacters or phonemes in speech recognition, and 2) the decomposition of\ntarget sequences is fixed. These drawbacks usually result in sub-optimal\nperformance of modeling sequences. In this pa- per, we extend the popular CTC\nloss criterion to alleviate these limitations, and propose a new loss function\ncalled Gram-CTC. While preserving the advantages of CTC, Gram-CTC automatically\nlearns the best set of basic units (grams), as well as the most suitable\ndecomposition of tar- get sequences. Unlike CTC, Gram-CTC allows the model to\noutput variable number of characters at each time step, which enables the model\nto capture longer term dependency and improves the computational efficiency. We\ndemonstrate that the proposed Gram-CTC improves CTC in terms of both\nperformance and efficiency on the large vocabulary speech recognition task at\nmultiple scales of data, and that with Gram-CTC we can outperform the\nstate-of-the-art on a standard speech benchmark. \n\n"}
{"id": "1703.00144", "contents": "Title: Theoretical Properties for Neural Networks with Weight Matrices of Low\n  Displacement Rank Abstract: Recently low displacement rank (LDR) matrices, or so-called structured\nmatrices, have been proposed to compress large-scale neural networks. Empirical\nresults have shown that neural networks with weight matrices of LDR matrices,\nreferred as LDR neural networks, can achieve significant reduction in space and\ncomputational complexity while retaining high accuracy. We formally study LDR\nmatrices in deep learning. First, we prove the universal approximation property\nof LDR neural networks with a mild condition on the displacement operators. We\nthen show that the error bounds of LDR neural networks are as efficient as\ngeneral neural networks with both single-layer and multiple-layer structure.\nFinally, we propose back-propagation based training algorithm for general LDR\nneural networks. \n\n"}
{"id": "1703.00380", "contents": "Title: Privacy-Preserving Personal Model Training Abstract: Many current Internet services rely on inferences from models trained on user\ndata. Commonly, both the training and inference tasks are carried out using\ncloud resources fed by personal data collected at scale from users. Holding and\nusing such large collections of personal data in the cloud creates privacy\nrisks to the data subjects, but is currently required for users to benefit from\nsuch services. We explore how to provide for model training and inference in a\nsystem where computation is pushed to the data in preference to moving data to\nthe cloud, obviating many current privacy risks. Specifically, we take an\ninitial model learnt from a small set of users and retrain it locally using\ndata from a single user. We evaluate on two tasks: one supervised learning\ntask, using a neural network to recognise users' current activity from\naccelerometer traces; and one unsupervised learning task, identifying topics in\na large set of documents. In both cases the accuracy is improved. We also\nanalyse the robustness of our approach against adversarial attacks, as well as\nits feasibility by presenting a performance evaluation on a representative\nresource-constrained device (a Raspberry Pi). \n\n"}
{"id": "1703.00439", "contents": "Title: Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for\n  Regularized Empirical Risk Minimization Abstract: In this paper, we develop a new accelerated stochastic gradient method for\nefficiently solving the convex regularized empirical risk minimization problem\nin mini-batch settings. The use of mini-batches is becoming a golden standard\nin the machine learning community, because mini-batch settings stabilize the\ngradient estimate and can easily make good use of parallel computing. The core\nof our proposed method is the incorporation of our new \"double acceleration\"\ntechnique and variance reduction technique. We theoretically analyze our\nproposed method and show that our method much improves the mini-batch\nefficiencies of previous accelerated stochastic methods, and essentially only\nneeds size $\\sqrt{n}$ mini-batches for achieving the optimal iteration\ncomplexities for both non-strongly and strongly convex objectives, where $n$ is\nthe training set size. Further, we show that even in non-mini-batch settings,\nour method achieves the best known convergence rate for both non-strongly and\nstrongly convex objectives. \n\n"}
{"id": "1703.00810", "contents": "Title: Opening the Black Box of Deep Neural Networks via Information Abstract: Despite their great success, there is still no comprehensive theoretical\nunderstanding of learning with Deep Neural Networks (DNNs) or their inner\norganization. Previous work proposed to analyze DNNs in the \\textit{Information\nPlane}; i.e., the plane of the Mutual Information values that each layer\npreserves on the input and output variables. They suggested that the goal of\nthe network is to optimize the Information Bottleneck (IB) tradeoff between\ncompression and prediction, successively, for each layer.\n  In this work we follow up on this idea and demonstrate the effectiveness of\nthe Information-Plane visualization of DNNs. Our main results are: (i) most of\nthe training epochs in standard DL are spent on {\\emph compression} of the\ninput to efficient representation and not on fitting the training labels. (ii)\nThe representation compression phase begins when the training errors becomes\nsmall and the Stochastic Gradient Decent (SGD) epochs change from a fast drift\nto smaller training error into a stochastic relaxation, or random diffusion,\nconstrained by the training error value. (iii) The converged layers lie on or\nvery close to the Information Bottleneck (IB) theoretical bound, and the maps\nfrom the input to any hidden layer and from this hidden layer to the output\nsatisfy the IB self-consistent equations. This generalization through noise\nmechanism is unique to Deep Neural Networks and absent in one layer networks.\n(iv) The training time is dramatically reduced when adding more hidden layers.\nThus the main advantage of the hidden layers is computational. This can be\nexplained by the reduced relaxation time, as this it scales super-linearly\n(exponentially for simple diffusion) with the information compression from the\nprevious layer. \n\n"}
{"id": "1703.01610", "contents": "Title: Improving Regret Bounds for Combinatorial Semi-Bandits with\n  Probabilistically Triggered Arms and Its Applications Abstract: We study combinatorial multi-armed bandit with probabilistically triggered\narms (CMAB-T) and semi-bandit feedback. We resolve a serious issue in the prior\nCMAB-T studies where the regret bounds contain a possibly exponentially large\nfactor of $1/p^*$, where $p^*$ is the minimum positive probability that an arm\nis triggered by any action. We address this issue by introducing a triggering\nprobability modulated (TPM) bounded smoothness condition into the general\nCMAB-T framework, and show that many applications such as influence\nmaximization bandit and combinatorial cascading bandit satisfy this TPM\ncondition. As a result, we completely remove the factor of $1/p^*$ from the\nregret bounds, achieving significantly better regret bounds for influence\nmaximization and cascading bandits than before. Finally, we provide lower bound\nresults showing that the factor $1/p^*$ is unavoidable for general CMAB-T\nproblems, suggesting that the TPM condition is crucial in removing this factor. \n\n"}
{"id": "1703.02618", "contents": "Title: Bootstrapped Graph Diffusions: Exposing the Power of Nonlinearity Abstract: Graph-based semi-supervised learning (SSL) algorithms predict labels for all\nnodes based on provided labels of a small set of seed nodes. Classic methods\ncapture the graph structure through some underlying diffusion process that\npropagates through the graph edges. Spectral diffusion, which includes\npersonalized page rank and label propagation, propagates through random walks.\nSocial diffusion propagates through shortest paths. A common ground to these\ndiffusions is their {\\em linearity}, which does not distinguish between\ncontributions of few \"strong\" relations and many \"weak\" relations.\n  Recently, non-linear methods such as node embeddings and graph convolutional\nnetworks (GCN) demonstrated a large gain in quality for SSL tasks. These\nmethods introduce multiple components and greatly vary on how the graph\nstructure, seed label information, and other features are used.\n  We aim here to study the contribution of non-linearity, as an isolated\ningredient, to the performance gain. To do so, we place classic linear graph\ndiffusions in a self-training framework. Surprisingly, we observe that SSL\nusing the resulting {\\em bootstrapped diffusions} not only significantly\nimproves over the respective non-bootstrapped baselines but also outperform\nstate-of-the-art non-linear SSL methods. Moreover, since the self-training\nwrapper retains the scalability of the base method, we obtain both higher\nquality and better scalability. \n\n"}
{"id": "1703.04697", "contents": "Title: On the benefits of output sparsity for multi-label classification Abstract: The multi-label classification framework, where each observation can be\nassociated with a set of labels, has generated a tremendous amount of attention\nover recent years. The modern multi-label problems are typically large-scale in\nterms of number of observations, features and labels, and the amount of labels\ncan even be comparable with the amount of observations. In this context,\ndifferent remedies have been proposed to overcome the curse of dimensionality.\nIn this work, we aim at exploiting the output sparsity by introducing a new\nloss, called the sparse weighted Hamming loss. This proposed loss can be seen\nas a weighted version of classical ones, where active and inactive labels are\nweighted separately. Leveraging the influence of sparsity in the loss function,\nwe provide improved generalization bounds for the empirical risk minimizer, a\nsuitable property for large-scale problems. For this new loss, we derive rates\nof convergence linear in the underlying output-sparsity rather than linear in\nthe number of labels. In practice, minimizing the associated risk can be\nperformed efficiently by using convex surrogates and modern convex optimization\nalgorithms. We provide experiments on various real-world datasets demonstrating\nthe pertinence of our approach when compared to non-weighted techniques. \n\n"}
{"id": "1703.05430", "contents": "Title: Cost-complexity pruning of random forests Abstract: Random forests perform bootstrap-aggregation by sampling the training samples\nwith replacement. This enables the evaluation of out-of-bag error which serves\nas a internal cross-validation mechanism. Our motivation lies in using the\nunsampled training samples to improve each decision tree in the ensemble. We\nstudy the effect of using the out-of-bag samples to improve the generalization\nerror first of the decision trees and second the random forest by post-pruning.\nA preliminary empirical study on four UCI repository datasets show consistent\ndecrease in the size of the forests without considerable loss in accuracy. \n\n"}
{"id": "1703.07822", "contents": "Title: Information-theoretic Model Identification and Policy Search using\n  Physics Engines with Application to Robotic Manipulation Abstract: We consider the problem of a robot learning the mechanical properties of\nobjects through physical interaction with the object, and introduce a\npractical, data-efficient approach for identifying the motion models of these\nobjects. The proposed method utilizes a physics engine, where the robot seeks\nto identify the inertial and friction parameters of the object by simulating\nits motion under different values of the parameters and identifying those that\nresult in a simulation which matches the observed real motions. The problem is\nsolved in a Bayesian optimization framework. The same framework is used for\nboth identifying the model of an object online and searching for a policy that\nwould minimize a given cost function according to the identified model.\nExperimental results both in simulation and using a real robot indicate that\nthe proposed method outperforms state-of-the-art model-free reinforcement\nlearning approaches. \n\n"}
{"id": "1703.08928", "contents": "Title: Resource-monotonicity and Population-monotonicity in Connected\n  Cake-cutting Abstract: In the classic cake-cutting problem (Steinhaus, 1948), a heterogeneous\nresource has to be divided among n agents with different valuations in a\nproportional way --- giving each agent a piece with a value of at least 1/n of\nthe total. In many applications, such as dividing a land-estate or a\ntime-interval, it is also important that the pieces are connected. We propose\ntwo additional requirements: resource-monotonicity (RM) and\npopulation-monotonicity (PM). When either the cake or the set of agents changes\nand the cake is re-divided using the same rule, the utility of all remaining\nagents must change in the same direction.\n  Classic cake-cutting protocols are neither RM nor PM. Moreover, we prove that\nno Pareto-optimal proportional division rule can be either RM or PM. Motivated\nby this negative result, we search for division rules that are\nweakly-Pareto-optimal --- no other division is strictly better for all agents.\n  We present two such rules. The relative-equitable rule, which assigns the\nmaximum possible relative value equal for all agents, is proportional and PM.\nThe so-called rightmost-mark rule, which is an improved version of the Cut and\nChoose protocol, is proportional and RM for two agents. \n\n"}
{"id": "1703.09452", "contents": "Title: SEGAN: Speech Enhancement Generative Adversarial Network Abstract: Current speech enhancement techniques operate on the spectral domain and/or\nexploit some higher-level feature. The majority of them tackle a limited number\nof noise conditions and rely on first-order statistics. To circumvent these\nissues, deep networks are being increasingly used, thanks to their ability to\nlearn complex functions from large example sets. In this work, we propose the\nuse of generative adversarial networks for speech enhancement. In contrast to\ncurrent techniques, we operate at the waveform level, training the model\nend-to-end, and incorporate 28 speakers and 40 different noise conditions into\nthe same model, such that model parameters are shared across them. We evaluate\nthe proposed model using an independent, unseen test set with two speakers and\n20 alternative noise conditions. The enhanced samples confirm the viability of\nthe proposed model, and both objective and subjective evaluations confirm the\neffectiveness of it. With that, we open the exploration of generative\narchitectures for speech enhancement, which may progressively incorporate\nfurther speech-centric design choices to improve their performance. \n\n"}
{"id": "1703.09669", "contents": "Title: On the Efficiency of Sharing Economy Networks Abstract: We consider a sharing economy network where agents embedded in a graph share\ntheir resources. This is a fundamental model that abstracts numerous emerging\napplications of collaborative consumption systems. The agents generate a random\namount of spare resource that they can exchange with their one-hop neighbours,\nseeking to maximize the amount of desirable resource items they receive in the\nlong run. We study this system from three different perspectives: a) the\ncentral designer who seeks the resource allocation that achieves the most fair\nendowments after the exchange; b) the game theoretic where the nodes seek to\nform sharing coalitions within teams, attempting to maximize the benefit of\ntheir team only; c) the market where the nodes are engaged in trade with their\nneighbours trying to improve their own benefit. It is shown that there is a\nunique family of sharing allocations that are at the same time most fair,\nstable with respect to continuous coalition formation among the nodes and\nachieving equilibrium in the market perspective. A dynamic sharing policy is\ngiven then where each node observes the sharing rates of its neighbours and\nallocates its resource accordingly. That policy is shown to achieve long term\nsharing ratios that are within the family of equilibrium allocations of the\nstatic problem. The equilibrium allocations have interesting properties that\nhighlight the dependence of the sharing ratios of each node to the structure of\nthe topology graph and the effect of the isolation of a node on the benefit may\nextract from his neighbours. \n\n"}
{"id": "1703.09947", "contents": "Title: Efficient Private ERM for Smooth Objectives Abstract: In this paper, we consider efficient differentially private empirical risk\nminimization from the viewpoint of optimization algorithms. For strongly convex\nand smooth objectives, we prove that gradient descent with output perturbation\nnot only achieves nearly optimal utility, but also significantly improves the\nrunning time of previous state-of-the-art private optimization algorithms, for\nboth $\\epsilon$-DP and $(\\epsilon, \\delta)$-DP. For non-convex but smooth\nobjectives, we propose an RRPSGD (Random Round Private Stochastic Gradient\nDescent) algorithm, which provably converges to a stationary point with privacy\nguarantee. Besides the expected utility bounds, we also provide guarantees in\nhigh probability form. Experiments demonstrate that our algorithm consistently\noutperforms existing method in both utility and running time. \n\n"}
{"id": "1704.00196", "contents": "Title: Faster Subgradient Methods for Functions with H\\\"olderian Growth Abstract: The purpose of this manuscript is to derive new convergence results for\nseveral subgradient methods applied to minimizing nonsmooth convex functions\nwith H\\\"olderian growth. The growth condition is satisfied in many applications\nand includes functions with quadratic growth and weakly sharp minima as special\ncases. To this end there are three main contributions. First, for a constant\nand sufficiently small stepsize, we show that the subgradient method achieves\nlinear convergence up to a certain region including the optimal set, with error\nof the order of the stepsize. Second, if appropriate problem parameters are\nknown, we derive a decaying stepsize which obtains a much faster convergence\nrate than is suggested by the classical $O(1/\\sqrt{k})$ result for the\nsubgradient method. Thirdly we develop a novel \"descending stairs\" stepsize\nwhich obtains this faster convergence rate and also obtains linear convergence\nfor the special case of weakly sharp functions. We also develop an adaptive\nvariant of the \"descending stairs\" stepsize which achieves the same convergence\nrate without requiring an error bound constant which is difficult to estimate\nin practice. \n\n"}
{"id": "1704.00637", "contents": "Title: Semi-Supervised Generation with Cluster-aware Generative Models Abstract: Deep generative models trained with large amounts of unlabelled data have\nproven to be powerful within the domain of unsupervised learning. Many real\nlife data sets contain a small amount of labelled data points, that are\ntypically disregarded when training generative models. We propose the\nCluster-aware Generative Model, that uses unlabelled information to infer a\nlatent representation that models the natural clustering of the data, and\nadditional labelled data points to refine this clustering. The generative\nperformances of the model significantly improve when labelled information is\nexploited, obtaining a log-likelihood of -79.38 nats on permutation invariant\nMNIST, while also achieving competitive semi-supervised classification\naccuracies. The model can also be trained fully unsupervised, and still improve\nthe log-likelihood performance with respect to related methods. \n\n"}
{"id": "1704.00805", "contents": "Title: On the Properties of the Softmax Function with Application in Game\n  Theory and Reinforcement Learning Abstract: In this paper, we utilize results from convex analysis and monotone operator\ntheory to derive additional properties of the softmax function that have not\nyet been covered in the existing literature. In particular, we show that the\nsoftmax function is the monotone gradient map of the log-sum-exp function. By\nexploiting this connection, we show that the inverse temperature parameter\ndetermines the Lipschitz and co-coercivity properties of the softmax function.\nWe then demonstrate the usefulness of these properties through an application\nin game-theoretic reinforcement learning. \n\n"}
{"id": "1704.01427", "contents": "Title: AMIDST: a Java Toolbox for Scalable Probabilistic Machine Learning Abstract: The AMIDST Toolbox is a software for scalable probabilistic machine learning\nwith a spe- cial focus on (massive) streaming data. The toolbox supports a\nflexible modeling language based on probabilistic graphical models with latent\nvariables and temporal dependencies. The specified models can be learnt from\nlarge data sets using parallel or distributed implementa- tions of Bayesian\nlearning algorithms for either streaming or batch data. These algorithms are\nbased on a flexible variational message passing scheme, which supports discrete\nand continu- ous variables from a wide range of probability distributions.\nAMIDST also leverages existing functionality and algorithms by interfacing to\nsoftware tools such as Flink, Spark, MOA, Weka, R and HUGIN. AMIDST is an open\nsource toolbox written in Java and available at http://www.amidsttoolbox.com\nunder the Apache Software License version 2.0. \n\n"}
{"id": "1704.01700", "contents": "Title: Accelerated Stochastic Quasi-Newton Optimization on Riemann Manifolds Abstract: We propose an L-BFGS optimization algorithm on Riemannian manifolds using\nminibatched stochastic variance reduction techniques for fast convergence with\nconstant step sizes, without resorting to linesearch methods designed to\nsatisfy Wolfe conditions. We provide a new convergence proof for strongly\nconvex functions without using curvature conditions on the manifold, as well as\na convergence discussion for nonconvex functions. We discuss a couple of ways\nto obtain the correction pairs used to calculate the product of the gradient\nwith the inverse Hessian, and empirically demonstrate their use in synthetic\nexperiments on computation of Karcher means for symmetric positive definite\nmatrices and leading eigenvalues of large scale data matrices. We compare our\nmethod to VR-PCA for the latter experiment, along with Riemannian SVRG for both\ncases, and show strong convergence results for a range of datasets. \n\n"}
{"id": "1704.02232", "contents": "Title: Rapid Mixing Swendsen-Wang Sampler for Stochastic Partitioned Attractive\n  Models Abstract: The Gibbs sampler is a particularly popular Markov chain used for learning\nand inference problems in Graphical Models (GMs). These tasks are\ncomputationally intractable in general, and the Gibbs sampler often suffers\nfrom slow mixing. In this paper, we study the Swendsen-Wang dynamics which is a\nmore sophisticated Markov chain designed to overcome bottlenecks that impede\nthe Gibbs sampler. We prove O(\\log n) mixing time for attractive binary\npairwise GMs (i.e., ferromagnetic Ising models) on stochastic partitioned\ngraphs having n vertices, under some mild conditions, including low temperature\nregions where the Gibbs sampler provably mixes exponentially slow. Our\nexperiments also confirm that the Swendsen-Wang sampler significantly\noutperforms the Gibbs sampler when they are used for learning parameters of\nattractive GMs. \n\n"}
{"id": "1704.02239", "contents": "Title: \\'Echantillonnage de signaux sur graphes via des processus\n  d\\'eterminantaux Abstract: We consider the problem of sampling k-bandlimited graph signals, ie, linear\ncombinations of the first k graph Fourier modes. We know that a set of k nodes\nembedding all k-bandlimited signals always exists, thereby enabling their\nperfect reconstruction after sampling. Unfortunately, to exhibit such a set,\none needs to partially diagonalize the graph Laplacian, which becomes\nprohibitive at large scale. We propose a novel strategy based on determinantal\npoint processes that side-steps partial diagonalisation and enables\nreconstruction with only O(k) samples. While doing so, we exhibit a new general\nalgorithm to sample determinantal process, faster than the state-of-the-art\nalgorithm by an order k. \n\n"}
{"id": "1704.02657", "contents": "Title: Solving Zero-sum Games using Best Response Oracles with Applications to\n  Search Games Abstract: We present efficient algorithms for computing optimal or approximately\noptimal strategies in a zero-sum game for which Player I has n pure strategies\nand Player II has an arbitrary number of pure strategies. We assume that for\nany given mixed strategy of Player I, a best response or \"approximate\" best\nresponse of Player II can be found by an oracle in time polynomial in n. We\nthen show how our algorithms may be applied to several search games with\napplications to security and counter-terrorism. We evaluate our main algorithm\nexperimentally on a prototypical search game. Our results show it performs well\ncompared to an existing, well-known algorithm for solving zero-sum games that\ncan also be used to solve search games, given a best response oracle. \n\n"}
{"id": "1704.02718", "contents": "Title: Distributed Learning for Cooperative Inference Abstract: We study the problem of cooperative inference where a group of agents\ninteract over a network and seek to estimate a joint parameter that best\nexplains a set of observations. Agents do not know the network topology or the\nobservations of other agents. We explore a variational interpretation of the\nBayesian posterior density, and its relation to the stochastic mirror descent\nalgorithm, to propose a new distributed learning algorithm. We show that, under\nappropriate assumptions, the beliefs generated by the proposed algorithm\nconcentrate around the true parameter exponentially fast. We provide explicit\nnon-asymptotic bounds for the convergence rate. Moreover, we develop explicit\nand computationally efficient algorithms for observation models belonging to\nexponential families. \n\n"}
{"id": "1704.02771", "contents": "Title: Group Importance Sampling for Particle Filtering and MCMC Abstract: Bayesian methods and their implementations by means of sophisticated Monte\nCarlo techniques have become very popular in signal processing over the last\nyears. Importance Sampling (IS) is a well-known Monte Carlo technique that\napproximates integrals involving a posterior distribution by means of weighted\nsamples. In this work, we study the assignation of a single weighted sample\nwhich compresses the information contained in a population of weighted samples.\nPart of the theory that we present as Group Importance Sampling (GIS) has been\nemployed implicitly in different works in the literature. The provided analysis\nyields several theoretical and practical consequences. For instance, we discuss\nthe application of GIS into the Sequential Importance Resampling framework and\nshow that Independent Multiple Try Metropolis schemes can be interpreted as a\nstandard Metropolis-Hastings algorithm, following the GIS approach. We also\nintroduce two novel Markov Chain Monte Carlo (MCMC) techniques based on GIS.\nThe first one, named Group Metropolis Sampling method, produces a Markov chain\nof sets of weighted samples. All these sets are then employed for obtaining a\nunique global estimator. The second one is the Distributed Particle\nMetropolis-Hastings technique, where different parallel particle filters are\njointly used to drive an MCMC algorithm. Different resampled trajectories are\ncompared and then tested with a proper acceptance probability. The novel\nschemes are tested in different numerical experiments such as learning the\nhyperparameters of Gaussian Processes, two localization problems in a wireless\nsensor network (with synthetic and real data) and the tracking of vegetation\nparameters given satellite observations, where they are compared with several\nbenchmark Monte Carlo techniques. Three illustrative Matlab demos are also\nprovided. \n\n"}
{"id": "1704.02882", "contents": "Title: Dynamic Safe Interruptibility for Decentralized Multi-Agent\n  Reinforcement Learning Abstract: In reinforcement learning, agents learn by performing actions and observing\ntheir outcomes. Sometimes, it is desirable for a human operator to\n\\textit{interrupt} an agent in order to prevent dangerous situations from\nhappening. Yet, as part of their learning process, agents may link these\ninterruptions, that impact their reward, to specific states and deliberately\navoid them. The situation is particularly challenging in a multi-agent context\nbecause agents might not only learn from their own past interruptions, but also\nfrom those of other agents. Orseau and Armstrong defined \\emph{safe\ninterruptibility} for one learner, but their work does not naturally extend to\nmulti-agent systems. This paper introduces \\textit{dynamic safe\ninterruptibility}, an alternative definition more suited to decentralized\nlearning problems, and studies this notion in two learning frameworks:\n\\textit{joint action learners} and \\textit{independent learners}. We give\nrealistic sufficient conditions on the learning algorithm to enable dynamic\nsafe interruptibility in the case of joint action learners, yet show that these\nconditions are not sufficient for independent learners. We show however that if\nagents can detect interruptions, it is possible to prune the observations to\nensure dynamic safe interruptibility even for independent learners. \n\n"}
{"id": "1704.04960", "contents": "Title: Adversarial and Clean Data Are Not Twins Abstract: Adversarial attack has cast a shadow on the massive success of deep neural\nnetworks. Despite being almost visually identical to the clean data, the\nadversarial images can fool deep neural networks into wrong predictions with\nvery high confidence. In this paper, however, we show that we can build a\nsimple binary classifier separating the adversarial apart from the clean data\nwith accuracy over 99%. We also empirically show that the binary classifier is\nrobust to a second-round adversarial attack. In other words, it is difficult to\ndisguise adversarial samples to bypass the binary classifier. Further more, we\nempirically investigate the generalization limitation which lingers on all\ncurrent defensive methods, including the binary classifier approach. And we\nhypothesize that this is the result of intrinsic property of adversarial\ncrafting algorithms. \n\n"}
{"id": "1704.06209", "contents": "Title: ADMM Penalty Parameter Selection by Residual Balancing Abstract: Appropriate selection of the penalty parameter is crucial to obtaining good\nperformance from the Alternating Direction Method of Multipliers (ADMM). While\nanalytic results for optimal selection of this parameter are very limited,\nthere is a heuristic method that appears to be relatively successful in a\nnumber of different problems. The contribution of this paper is to demonstrate\nthat their is a potentially serious flaw in this heuristic approach, and to\npropose a modification that at least partially addresses it. \n\n"}
{"id": "1704.06933", "contents": "Title: Adversarial Neural Machine Translation Abstract: In this paper, we study a new learning paradigm for Neural Machine\nTranslation (NMT). Instead of maximizing the likelihood of the human\ntranslation as in previous works, we minimize the distinction between human\ntranslation and the translation given by an NMT model. To achieve this goal,\ninspired by the recent success of generative adversarial networks (GANs), we\nemploy an adversarial training architecture and name it as Adversarial-NMT. In\nAdversarial-NMT, the training of the NMT model is assisted by an adversary,\nwhich is an elaborately designed Convolutional Neural Network (CNN). The goal\nof the adversary is to differentiate the translation result generated by the\nNMT model from that by human. The goal of the NMT model is to produce high\nquality translations so as to cheat the adversary. A policy gradient method is\nleveraged to co-train the NMT model and the adversary. Experimental results on\nEnglish$\\rightarrow$French and German$\\rightarrow$English translation tasks\nshow that Adversarial-NMT can achieve significantly better translation quality\nthan several strong baselines. \n\n"}
{"id": "1704.07597", "contents": "Title: Learning Agents in Black-Scholes Financial Markets: Consensus Dynamics\n  and Volatility Smiles Abstract: Black-Scholes (BS) is the standard mathematical model for option pricing in\nfinancial markets. Option prices are calculated using an analytical formula\nwhose main inputs are strike (at which price to exercise) and volatility. The\nBS framework assumes that volatility remains constant across all strikes,\nhowever, in practice it varies. How do traders come to learn these parameters?\nWe introduce natural models of learning agents, in which they update their\nbeliefs about the true implied volatility based on the opinions of other\ntraders. We prove convergence of these opinion dynamics using techniques from\ncontrol theory and leader-follower models, thus providing a resolution between\ntheory and market practices. We allow for two different models, one with\nfeedback and one with an unknown leader. \n\n"}
{"id": "1704.07943", "contents": "Title: Reward Maximization Under Uncertainty: Leveraging Side-Observations on\n  Networks Abstract: We study the stochastic multi-armed bandit (MAB) problem in the presence of\nside-observations across actions that occur as a result of an underlying\nnetwork structure. In our model, a bipartite graph captures the relationship\nbetween actions and a common set of unknowns such that choosing an action\nreveals observations for the unknowns that it is connected to. This models a\ncommon scenario in online social networks where users respond to their friends'\nactivity, thus providing side information about each other's preferences. Our\ncontributions are as follows: 1) We derive an asymptotic lower bound (with\nrespect to time) as a function of the bi-partite network structure on the\nregret of any uniformly good policy that achieves the maximum long-term average\nreward. 2) We propose two policies - a randomized policy; and a policy based on\nthe well-known upper confidence bound (UCB) policies - both of which explore\neach action at a rate that is a function of its network position. We show,\nunder mild assumptions, that these policies achieve the asymptotic lower bound\non the regret up to a multiplicative factor, independent of the network\nstructure. Finally, we use numerical examples on a real-world social network\nand a routing example network to demonstrate the benefits obtained by our\npolicies over other existing policies. \n\n"}
{"id": "1704.07953", "contents": "Title: Linear Convergence of Accelerated Stochastic Gradient Descent for\n  Nonconvex Nonsmooth Optimization Abstract: In this paper, we study the stochastic gradient descent (SGD) method for the\nnonconvex nonsmooth optimization, and propose an accelerated SGD method by\ncombining the variance reduction technique with Nesterov's extrapolation\ntechnique. Moreover, based on the local error bound condition, we establish the\nlinear convergence of our method to obtain a stationary point of the nonconvex\noptimization. In particular, we prove that not only the sequence generated\nlinearly converges to a stationary point of the problem, but also the\ncorresponding sequence of objective values is linearly convergent. Finally,\nsome numerical experiments demonstrate the effectiveness of our method. To the\nbest of our knowledge, it is first proved that the accelerated SGD method\nconverges linearly to the local minimum of the nonconvex optimization. \n\n"}
{"id": "1705.00574", "contents": "Title: Forced to Learn: Discovering Disentangled Representations Without\n  Exhaustive Labels Abstract: Learning a better representation with neural networks is a challenging\nproblem, which was tackled extensively from different prospectives in the past\nfew years. In this work, we focus on learning a representation that could be\nused for a clustering task and introduce two novel loss components that\nsubstantially improve the quality of produced clusters, are simple to apply to\nan arbitrary model and cost function, and do not require a complicated training\nprocedure. We evaluate them on two most common types of models, Recurrent\nNeural Networks and Convolutional Neural Networks, showing that the approach we\npropose consistently improves the quality of KMeans clustering in terms of\nAdjusted Mutual Information score and outperforms previously proposed methods. \n\n"}
{"id": "1705.02955", "contents": "Title: Safe and Nested Subgame Solving for Imperfect-Information Games Abstract: In imperfect-information games, the optimal strategy in a subgame may depend\non the strategy in other, unreached subgames. Thus a subgame cannot be solved\nin isolation and must instead consider the strategy for the entire game as a\nwhole, unlike perfect-information games. Nevertheless, it is possible to first\napproximate a solution for the whole game and then improve it by solving\nindividual subgames. This is referred to as subgame solving. We introduce\nsubgame-solving techniques that outperform prior methods both in theory and\npractice. We also show how to adapt them, and past subgame-solving techniques,\nto respond to opponent actions that are outside the original action\nabstraction; this significantly outperforms the prior state-of-the-art\napproach, action translation. Finally, we show that subgame solving can be\nrepeated as the game progresses down the game tree, leading to far lower\nexploitability. These techniques were a key component of Libratus, the first AI\nto defeat top humans in heads-up no-limit Texas hold'em poker. \n\n"}
{"id": "1705.03501", "contents": "Title: Socially Trusted Collaborative Edge Computing in Ultra Dense Networks Abstract: Small cell base stations (SBSs) endowed with cloud-like computing\ncapabilities are considered as a key enabler of edge computing (EC), which\nprovides ultra-low latency and location-awareness for a variety of emerging\nmobile applications and the Internet of Things. However, due to the limited\ncomputation resources of an individual SBS, providing computation services of\nhigh quality to its users faces significant challenges when it is overloaded\nwith an excessive amount of computation workload. In this paper, we propose\ncollaborative edge computing among SBSs by forming SBS coalitions to share\ncomputation resources with each other, thereby accommodating more computation\nworkload in the edge system and reducing reliance on the remote cloud. A novel\nSBS coalition formation algorithm is developed based on the coalitional game\ntheory to cope with various new challenges in small-cell-based edge systems,\nincluding the co-provisioning of radio access and computing services,\ncooperation incentives, and potential security risks. To address these\nchallenges, the proposed method (1) allows collaboration at both the user-SBS\nassociation stage and the SBS peer offloading stage by exploiting the ultra\ndense deployment of SBSs, (2) develops a payment-based incentive mechanism that\nimplements proportionally fair utility division to form stable SBS coalitions,\nand (3) builds a social trust network for managing security risks among SBSs\ndue to collaboration. Systematic simulations in practical scenarios are carried\nout to evaluate the efficacy and performance of the proposed method, which\nshows that tremendous edge computing performance improvement can be achieved. \n\n"}
{"id": "1705.04770", "contents": "Title: Bayesian Decision Making in Groups is Hard Abstract: We study the computations that Bayesian agents undertake when exchanging\nopinions over a network. The agents act repeatedly on their private information\nand take myopic actions that maximize their expected utility according to a\nfully rational posterior belief. We show that such computations are NP-hard for\ntwo natural utility functions: one with binary actions, and another where\nagents reveal their posterior beliefs. In fact, we show that distinguishing\nbetween posteriors that are concentrated on different states of the world is\nNP-hard. Therefore, even approximating the Bayesian posterior beliefs is hard.\nWe also describe a natural search algorithm to compute agents' actions, which\nwe call elimination of impossible signals, and show that if the network is\ntransitive, the algorithm can be modified to run in polynomial time. \n\n"}
{"id": "1705.06211", "contents": "Title: An Investigation of Newton-Sketch and Subsampled Newton Methods Abstract: Sketching, a dimensionality reduction technique, has received much attention\nin the statistics community. In this paper, we study sketching in the context\nof Newton's method for solving finite-sum optimization problems in which the\nnumber of variables and data points are both large. We study two forms of\nsketching that perform dimensionality reduction in data space: Hessian\nsubsampling and randomized Hadamard transformations. Each has its own\nadvantages, and their relative tradeoffs have not been investigated in the\noptimization literature. Our study focuses on practical versions of the two\nmethods in which the resulting linear systems of equations are solved\napproximately, at every iteration, using an iterative solver. The advantages of\nusing the conjugate gradient method vs. a stochastic gradient iteration are\nrevealed through a set of numerical experiments, and a complexity analysis of\nthe Hessian subsampling method is presented. \n\n"}
{"id": "1705.07070", "contents": "Title: EE-Grad: Exploration and Exploitation for Cost-Efficient Mini-Batch SGD Abstract: We present a generic framework for trading off fidelity and cost in computing\nstochastic gradients when the costs of acquiring stochastic gradients of\ndifferent quality are not known a priori. We consider a mini-batch oracle that\ndistributes a limited query budget over a number of stochastic gradients and\naggregates them to estimate the true gradient. Since the optimal mini-batch\nsize depends on the unknown cost-fidelity function, we propose an algorithm,\n{\\it EE-Grad}, that sequentially explores the performance of mini-batch oracles\nand exploits the accumulated knowledge to estimate the one achieving the best\nperformance in terms of cost-efficiency. We provide performance guarantees for\nEE-Grad with respect to the optimal mini-batch oracle, and illustrate these\nresults in the case of strongly convex objectives. We also provide a simple\nnumerical example that corroborates our theoretical findings. \n\n"}
{"id": "1705.07199", "contents": "Title: The High-Dimensional Geometry of Binary Neural Networks Abstract: Recent research has shown that one can train a neural network with binary\nweights and activations at train time by augmenting the weights with a\nhigh-precision continuous latent variable that accumulates small changes from\nstochastic gradient descent. However, there is a dearth of theoretical analysis\nto explain why we can effectively capture the features in our data with binary\nweights and activations. Our main result is that the neural networks with\nbinary weights and activations trained using the method of Courbariaux, Hubara\net al. (2016) work because of the high-dimensional geometry of binary vectors.\nIn particular, the ideal continuous vectors that extract out features in the\nintermediate representations of these BNNs are well-approximated by binary\nvectors in the sense that dot products are approximately preserved. Compared to\nprevious research that demonstrated the viability of such BNNs, our work\nexplains why these BNNs work in terms of the HD geometry. Our theory serves as\na foundation for understanding not only BNNs but a variety of methods that seek\nto compress traditional neural networks. Furthermore, a better understanding of\nmultilayer binary neural networks serves as a starting point for generalizing\nBNNs to other neural network architectures such as recurrent neural networks. \n\n"}
{"id": "1705.07210", "contents": "Title: Two-temperature logistic regression based on the Tsallis divergence Abstract: We develop a variant of multiclass logistic regression that is significantly\nmore robust to noise. The algorithm has one weight vector per class and the\nsurrogate loss is a function of the linear activations (one per class). The\nsurrogate loss of an example with linear activation vector $\\mathbf{a}$ and\nclass $c$ has the form $-\\log_{t_1} \\exp_{t_2} (a_c - G_{t_2}(\\mathbf{a}))$\nwhere the two temperatures $t_1$ and $t_2$ ''temper'' the $\\log$ and $\\exp$,\nrespectively, and $G_{t_2}(\\mathbf{a})$ is a scalar value that generalizes the\nlog-partition function. We motivate this loss using the Tsallis divergence. Our\nmethod allows transitioning between non-convex and convex losses by the choice\nof the temperature parameters. As the temperature $t_1$ of the logarithm\nbecomes smaller than the temperature $t_2$ of the exponential, the surrogate\nloss becomes ''quasi convex''. Various tunings of the temperatures recover\nprevious methods and tuning the degree of non-convexity is crucial in the\nexperiments. In particular, quasi-convexity and boundedness of the loss provide\nsignificant robustness to the outliers. We explain this by showing that $t_1 <\n1$ caps the surrogate loss and $t_2 >1$ makes the predictive distribution have\na heavy tail.\n  We show that the surrogate loss is Bayes-consistent, even in the non-convex\ncase. Additionally, we provide efficient iterative algorithms for calculating\nthe log-partition value only in a few number of iterations. Our compelling\nexperimental results on large real-world datasets show the advantage of using\nthe two-temperature variant in the noisy as well as the noise free case. \n\n"}
{"id": "1705.07878", "contents": "Title: TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep\n  Learning Abstract: High network communication cost for synchronizing gradients and parameters is\nthe well-known bottleneck of distributed training. In this work, we propose\nTernGrad that uses ternary gradients to accelerate distributed deep learning in\ndata parallelism. Our approach requires only three numerical levels {-1,0,1},\nwhich can aggressively reduce the communication time. We mathematically prove\nthe convergence of TernGrad under the assumption of a bound on gradients.\nGuided by the bound, we propose layer-wise ternarizing and gradient clipping to\nimprove its convergence. Our experiments show that applying TernGrad on AlexNet\ndoes not incur any accuracy loss and can even improve accuracy. The accuracy\nloss of GoogLeNet induced by TernGrad is less than 2% on average. Finally, a\nperformance model is proposed to study the scalability of TernGrad. Experiments\nshow significant speed gains for various deep neural networks. Our source code\nis available. \n\n"}
{"id": "1705.07957", "contents": "Title: Large Scale Empirical Risk Minimization via Truncated Adaptive Newton\n  Method Abstract: We consider large scale empirical risk minimization (ERM) problems, where\nboth the problem dimension and variable size is large. In these cases, most\nsecond order methods are infeasible due to the high cost in both computing the\nHessian over all samples and computing its inverse in high dimensions. In this\npaper, we propose a novel adaptive sample size second-order method, which\nreduces the cost of computing the Hessian by solving a sequence of ERM problems\ncorresponding to a subset of samples and lowers the cost of computing the\nHessian inverse using a truncated eigenvalue decomposition. We show that while\nwe geometrically increase the size of the training set at each stage, a single\niteration of the truncated Newton method is sufficient to solve the new ERM\nwithin its statistical accuracy. Moreover, for a large number of samples we are\nallowed to double the size of the training set at each stage, and the proposed\nmethod subsequently reaches the statistical accuracy of the full training set\napproximately after two effective passes. In addition to this theoretical\nresult, we show empirically on a number of well known data sets that the\nproposed truncated adaptive sample size algorithm outperforms stochastic\nalternatives for solving ERM problems. \n\n"}
{"id": "1705.08030", "contents": "Title: Parallel Stochastic Gradient Descent with Sound Combiners Abstract: Stochastic gradient descent (SGD) is a well known method for regression and\nclassification tasks. However, it is an inherently sequential algorithm at each\nstep, the processing of the current example depends on the parameters learned\nfrom the previous examples. Prior approaches to parallelizing linear learners\nusing SGD, such as HOGWILD! and ALLREDUCE, do not honor these dependencies\nacross threads and thus can potentially suffer poor convergence rates and/or\npoor scalability. This paper proposes SYMSGD, a parallel SGD algorithm that, to\na first-order approximation, retains the sequential semantics of SGD. Each\nthread learns a local model in addition to a model combiner, which allows local\nmodels to be combined to produce the same result as what a sequential SGD would\nhave produced. This paper evaluates SYMSGD's accuracy and performance on 6\ndatasets on a shared-memory machine shows upto 11x speedup over our heavily\noptimized sequential baseline on 16 cores and 2.2x, on average, faster than\nHOGWILD!. \n\n"}
{"id": "1705.08711", "contents": "Title: Non-orthogonal Multiple Access for High-reliable and Low-latency V2X\n  Communications Abstract: In this paper, we consider a dense vehicular communication network where each\nvehicle broadcasts its safety information to its neighborhood in each\ntransmission period. Such applications require low latency and high\nreliability, and thus, we propose a non-orthogonal multiple access scheme to\nreduce the latency and to improve the packet reception probability. In the\nproposed scheme, the BS performs the semi-persistent scheduling to optimize the\ntime scheduling and allocate frequency resources in a non-orthogonal manner\nwhile the vehicles autonomously perform distributed power control. We formulate\nthe centralized scheduling and resource allocation problem as equivalent to a\nmulti-dimensional stable roommate matching problem, in which the users and\ntime/frequency resources are considered as disjoint sets of players to be\nmatched with each other. We then develop a novel rotation matching algorithm,\nwhich converges to a q-exchange stable matching after a limited number of\niterations. Simulation results show that the proposed scheme outperforms the\ntraditional orthogonal multiple access scheme in terms of the latency and\nreliability. \n\n"}
{"id": "1705.08922", "contents": "Title: Exploring the Regularity of Sparse Structure in Convolutional Neural\n  Networks Abstract: Sparsity helps reduce the computational complexity of deep neural networks by\nskipping zeros. Taking advantage of sparsity is listed as a high priority in\nnext generation DNN accelerators such as TPU. The structure of sparsity, i.e.,\nthe granularity of pruning, affects the efficiency of hardware accelerator\ndesign as well as the prediction accuracy. Coarse-grained pruning creates\nregular sparsity patterns, making it more amenable for hardware acceleration\nbut more challenging to maintain the same accuracy. In this paper we\nquantitatively measure the trade-off between sparsity regularity and prediction\naccuracy, providing insights in how to maintain accuracy while having more a\nmore structured sparsity pattern. Our experimental results show that\ncoarse-grained pruning can achieve a sparsity ratio similar to unstructured\npruning without loss of accuracy. Moreover, due to the index saving effect,\ncoarse-grained pruning is able to obtain a better compression ratio than\nfine-grained sparsity at the same accuracy threshold. Based on the recent\nsparse convolutional neural network accelerator (SCNN), our experiments further\ndemonstrate that coarse-grained sparsity saves about 2x the memory references\ncompared to fine-grained sparsity. Since memory reference is more than two\norders of magnitude more expensive than arithmetic operations, the regularity\nof sparse structure leads to more efficient hardware design. \n\n"}
{"id": "1705.09303", "contents": "Title: Latent Geometry and Memorization in Generative Models Abstract: It can be difficult to tell whether a trained generative model has learned to\ngenerate novel examples or has simply memorized a specific set of outputs. In\npublished work, it is common to attempt to address this visually, for example\nby displaying a generated example and its nearest neighbor(s) in the training\nset (in, for example, the L2 metric). As any generative model induces a\nprobability density on its output domain, we propose studying this density\ndirectly. We first study the geometry of the latent representation and\ngenerator, relate this to the output density, and then develop techniques to\ncompute and inspect the output density. As an application, we demonstrate that\n\"memorization\" tends to a density made of delta functions concentrated on the\nmemorized examples. We note that without first understanding the geometry, the\nmeasurement would be essentially impossible to make. \n\n"}
{"id": "1705.09319", "contents": "Title: Diagonal Rescaling For Neural Networks Abstract: We define a second-order neural network stochastic gradient training\nalgorithm whose block-diagonal structure effectively amounts to normalizing the\nunit activations. Investigating why this algorithm lacks in robustness then\nreveals two interesting insights. The first insight suggests a new way to scale\nthe stepsizes, clarifying popular algorithms such as RMSProp as well as old\nneural network tricks such as fanin stepsize scaling. The second insight\nstresses the practical importance of dealing with fast changes of the curvature\nof the cost. \n\n"}
{"id": "1705.09396", "contents": "Title: Approximate and Stochastic Greedy Optimization Abstract: We consider two greedy algorithms for minimizing a convex function in a\nbounded convex set: an algorithm by Jones [1992] and the Frank-Wolfe (FW)\nalgorithm. We first consider approximate versions of these algorithms. For\nsmooth convex functions, we give sufficient conditions for convergence, a\nunified analysis for the well-known convergence rate of O(1/k) together with a\nresult showing that this rate is the best obtainable from the proof technique,\nand an equivalence result for the two algorithms. We also consider approximate\nstochastic greedy algorithms for minimizing expectations. We show that\nreplacing the full gradient by a single stochastic gradient can fail even on\nsmooth convex functions. We give a convergent approximate stochastic Jones\nalgorithm and a convergent approximate stochastic FW algorithm for smooth\nconvex functions. In addition, we give a convergent approximate stochastic FW\nalgorithm for nonsmooth convex functions. Convergence rates for these\nalgorithms are given and proved. \n\n"}
{"id": "1705.09675", "contents": "Title: Fisher GAN Abstract: Generative Adversarial Networks (GANs) are powerful models for learning\ncomplex distributions. Stable training of GANs has been addressed in many\nrecent works which explore different metrics between distributions. In this\npaper we introduce Fisher GAN which fits within the Integral Probability\nMetrics (IPM) framework for training GANs. Fisher GAN defines a critic with a\ndata dependent constraint on its second order moments. We show in this paper\nthat Fisher GAN allows for stable and time efficient training that does not\ncompromise the capacity of the critic, and does not need data independent\nconstraints such as weight clipping. We analyze our Fisher IPM theoretically\nand provide an algorithm based on Augmented Lagrangian for Fisher GAN. We\nvalidate our claims on both image sample generation and semi-supervised\nclassification using Fisher GAN. \n\n"}
{"id": "1705.10883", "contents": "Title: Optimization of Tree Ensembles Abstract: Tree ensemble models such as random forests and boosted trees are among the\nmost widely used and practically successful predictive models in applied\nmachine learning and business analytics. Although such models have been used to\nmake predictions based on exogenous, uncontrollable independent variables, they\nare increasingly being used to make predictions where the independent variables\nare controllable and are also decision variables. In this paper, we study the\nproblem of tree ensemble optimization: given a tree ensemble that predicts some\ndependent variable using controllable independent variables, how should we set\nthese variables so as to maximize the predicted value? We formulate the problem\nas a mixed-integer optimization problem. We theoretically examine the strength\nof our formulation, provide a hierarchy of approximate formulations with bounds\non approximation quality and exploit the structure of the problem to develop\ntwo large-scale solution methods, one based on Benders decomposition and one\nbased on iteratively generating tree split constraints. We test our methodology\non real data sets, including two case studies in drug design and customized\npricing, and show that our methodology can efficiently solve large-scale\ninstances to near or full optimality, and outperforms solutions obtained by\nheuristic approaches. In our drug design case, we show how our approach can\nidentify compounds that efficiently trade-off predicted performance and novelty\nwith respect to existing, known compounds. In our customized pricing case, we\nshow how our approach can efficiently determine optimal store-level prices\nunder a random forest model that delivers excellent predictive accuracy. \n\n"}
{"id": "1706.01566", "contents": "Title: Open Loop Hyperparameter Optimization and Determinantal Point Processes Abstract: Driven by the need for parallelizable hyperparameter optimization methods,\nthis paper studies \\emph{open loop} search methods: sequences that are\npredetermined and can be generated before a single configuration is evaluated.\nExamples include grid search, uniform random search, low discrepancy sequences,\nand other sampling distributions. In particular, we propose the use of\n$k$-determinantal point processes in hyperparameter optimization via random\nsearch. Compared to conventional uniform random search where hyperparameter\nsettings are sampled independently, a $k$-DPP promotes diversity. We describe\nan approach that transforms hyperparameter search spaces for efficient use with\na $k$-DPP. In addition, we introduce a novel Metropolis-Hastings algorithm\nwhich can sample from $k$-DPPs defined over any space from which uniform\nsamples can be drawn, including spaces with a mixture of discrete and\ncontinuous dimensions or tree structure. Our experiments show significant\nbenefits in realistic scenarios with a limited budget for training supervised\nlearners, whether in serial or parallel. \n\n"}
{"id": "1706.01686", "contents": "Title: Limitations on Variance-Reduction and Acceleration Schemes for Finite\n  Sum Optimization Abstract: We study the conditions under which one is able to efficiently apply\nvariance-reduction and acceleration schemes on finite sum optimization\nproblems. First, we show that, perhaps surprisingly, the finite sum structure\nby itself, is not sufficient for obtaining a complexity bound of\n$\\tilde{\\cO}((n+L/\\mu)\\ln(1/\\epsilon))$ for $L$-smooth and $\\mu$-strongly\nconvex individual functions - one must also know which individual function is\nbeing referred to by the oracle at each iteration. Next, we show that for a\nbroad class of first-order and coordinate-descent finite sum algorithms\n(including, e.g., SDCA, SVRG, SAG), it is not possible to get an `accelerated'\ncomplexity bound of $\\tilde{\\cO}((n+\\sqrt{n L/\\mu})\\ln(1/\\epsilon))$, unless\nthe strong convexity parameter is given explicitly. Lastly, we show that when\nthis class of algorithms is used for minimizing $L$-smooth and convex finite\nsums, the optimal complexity bound is $\\tilde{\\cO}(n+L/\\epsilon)$, assuming\nthat (on average) the same update rule is used in every iteration, and\n$\\tilde{\\cO}(n+\\sqrt{nL/\\epsilon})$, otherwise. \n\n"}
{"id": "1706.03161", "contents": "Title: Toeplitz Inverse Covariance-Based Clustering of Multivariate Time Series\n  Data Abstract: Subsequence clustering of multivariate time series is a useful tool for\ndiscovering repeated patterns in temporal data. Once these patterns have been\ndiscovered, seemingly complicated datasets can be interpreted as a temporal\nsequence of only a small number of states, or clusters. For example, raw sensor\ndata from a fitness-tracking application can be expressed as a timeline of a\nselect few actions (i.e., walking, sitting, running). However, discovering\nthese patterns is challenging because it requires simultaneous segmentation and\nclustering of the time series. Furthermore, interpreting the resulting clusters\nis difficult, especially when the data is high-dimensional. Here we propose a\nnew method of model-based clustering, which we call Toeplitz Inverse\nCovariance-based Clustering (TICC). Each cluster in the TICC method is defined\nby a correlation network, or Markov random field (MRF), characterizing the\ninterdependencies between different observations in a typical subsequence of\nthat cluster. Based on this graphical representation, TICC simultaneously\nsegments and clusters the time series data. We solve the TICC problem through\nalternating minimization, using a variation of the expectation maximization\n(EM) algorithm. We derive closed-form solutions to efficiently solve the two\nresulting subproblems in a scalable way, through dynamic programming and the\nalternating direction method of multipliers (ADMM), respectively. We validate\nour approach by comparing TICC to several state-of-the-art baselines in a\nseries of synthetic experiments, and we then demonstrate on an automobile\nsensor dataset how TICC can be used to learn interpretable clusters in\nreal-world scenarios. \n\n"}
{"id": "1706.03369", "contents": "Title: On the Sampling Problem for Kernel Quadrature Abstract: The standard Kernel Quadrature method for numerical integration with random\npoint sets (also called Bayesian Monte Carlo) is known to converge in root mean\nsquare error at a rate determined by the ratio $s/d$, where $s$ and $d$ encode\nthe smoothness and dimension of the integrand. However, an empirical\ninvestigation reveals that the rate constant $C$ is highly sensitive to the\ndistribution of the random points. In contrast to standard Monte Carlo\nintegration, for which optimal importance sampling is well-understood, the\nsampling distribution that minimises $C$ for Kernel Quadrature does not admit a\nclosed form. This paper argues that the practical choice of sampling\ndistribution is an important open problem. One solution is considered; a novel\nautomatic approach based on adaptive tempering and sequential Monte Carlo.\nEmpirical results demonstrate a dramatic reduction in integration error of up\nto 4 orders of magnitude can be achieved with the proposed method. \n\n"}
{"id": "1706.03847", "contents": "Title: Recurrent Neural Networks with Top-k Gains for Session-based\n  Recommendations Abstract: RNNs have been shown to be excellent models for sequential data and in\nparticular for data that is generated by users in an session-based manner. The\nuse of RNNs provides impressive performance benefits over classical methods in\nsession-based recommendations. In this work we introduce novel ranking loss\nfunctions tailored to RNNs in the recommendation setting. The improved\nperformance of these losses over alternatives, along with further tricks and\nrefinements described in this work, allow for an overall improvement of up to\n35% in terms of MRR and Recall@20 over previous session-based RNN solutions and\nup to 53% over classical collaborative filtering approaches. Unlike data\naugmentation-based improvements, our method does not increase training times\nsignificantly. We further demonstrate the performance gain of the RNN over\nbaselines in an online A/B test. \n\n"}
{"id": "1706.03958", "contents": "Title: Accelerated Dual Learning by Homotopic Initialization Abstract: Gradient descent and coordinate descent are well understood in terms of their\nasymptotic behavior, but less so in a transient regime often used for\napproximations in machine learning. We investigate how proper initialization\ncan have a profound effect on finding near-optimal solutions quickly. We show\nthat a certain property of a data set, namely the boundedness of the\ncorrelations between eigenfeatures and the response variable, can lead to\nfaster initial progress than expected by commonplace analysis. Convex\noptimization problems can tacitly benefit from that, but this automatism does\nnot apply to their dual formulation. We analyze this phenomenon and devise\nprovably good initialization strategies for dual optimization as well as\nheuristics for the non-convex case, relevant for deep learning. We find our\npredictions and methods to be experimentally well-supported. \n\n"}
{"id": "1706.04601", "contents": "Title: Provable benefits of representation learning Abstract: There is general consensus that learning representations is useful for a\nvariety of reasons, e.g. efficient use of labeled data (semi-supervised\nlearning), transfer learning and understanding hidden structure of data.\nPopular techniques for representation learning include clustering, manifold\nlearning, kernel-learning, autoencoders, Boltzmann machines, etc.\n  To study the relative merits of these techniques, it's essential to formalize\nthe definition and goals of representation learning, so that they are all\nbecome instances of the same definition. This paper introduces such a formal\nframework that also formalizes the utility of learning the representation. It\nis related to previous Bayesian notions, but with some new twists. We show the\nusefulness of our framework by exhibiting simple and natural settings -- linear\nmixture models and loglinear models, where the power of representation learning\ncan be formally shown. In these examples, representation learning can be\nperformed provably and efficiently under plausible assumptions (despite being\nNP-hard), and furthermore: (i) it greatly reduces the need for labeled data\n(semi-supervised learning) and (ii) it allows solving classification tasks when\nsimpler approaches like nearest neighbors require too much data (iii) it is\nmore powerful than manifold learning methods. \n\n"}
{"id": "1706.05730", "contents": "Title: Addressing Item-Cold Start Problem in Recommendation Systems using Model\n  Based Approach and Deep Learning Abstract: Traditional recommendation systems rely on past usage data in order to\ngenerate new recommendations. Those approaches fail to generate sensible\nrecommendations for new users and items into the system due to missing\ninformation about their past interactions. In this paper, we propose a solution\nfor successfully addressing item-cold start problem which uses model-based\napproach and recent advances in deep learning. In particular, we use latent\nfactor model for recommendation, and predict the latent factors from item's\ndescriptions using convolutional neural network when they cannot be obtained\nfrom usage data. Latent factors obtained by applying matrix factorization to\nthe available usage data are used as ground truth to train the convolutional\nneural network. To create latent factor representations for the new items, the\nconvolutional neural network uses their textual description. The results from\nthe experiments reveal that the proposed approach significantly outperforms\nseveral baseline estimators. \n\n"}
{"id": "1706.07001", "contents": "Title: Improved Optimization of Finite Sums with Minibatch Stochastic Variance\n  Reduced Proximal Iterations Abstract: We present novel minibatch stochastic optimization methods for empirical risk\nminimization problems, the methods efficiently leverage variance reduced\nfirst-order and sub-sampled higher-order information to accelerate the\nconvergence speed. For quadratic objectives, we prove improved iteration\ncomplexity over state-of-the-art under reasonable assumptions. We also provide\nempirical evidence of the advantages of our method compared to existing\napproaches in the literature. \n\n"}
{"id": "1706.08359", "contents": "Title: GPU-acceleration for Large-scale Tree Boosting Abstract: In this paper, we present a novel massively parallel algorithm for\naccelerating the decision tree building procedure on GPUs (Graphics Processing\nUnits), which is a crucial step in Gradient Boosted Decision Tree (GBDT) and\nrandom forests training. Previous GPU based tree building algorithms are based\non parallel multi-scan or radix sort to find the exact tree split, and thus\nsuffer from scalability and performance issues. We show that using a histogram\nbased algorithm to approximately find the best split is more efficient and\nscalable on GPU. By identifying the difference between classical GPU-based\nimage histogram construction and the feature histogram construction in decision\ntree training, we develop a fast feature histogram building kernel on GPU with\ncarefully designed computational and memory access sequence to reduce atomic\nupdate conflict and maximize GPU utilization. Our algorithm can be used as a\ndrop-in replacement for histogram construction in popular tree boosting systems\nto improve their scalability. As an example, to train GBDT on epsilon dataset,\nour method using a main-stream GPU is 7-8 times faster than histogram based\nalgorithm on CPU in LightGBM and 25 times faster than the exact-split finding\nalgorithm in XGBoost on a dual-socket 28-core Xeon server, while achieving\nsimilar prediction accuracy. \n\n"}
{"id": "1707.01477", "contents": "Title: Like trainer, like bot? Inheritance of bias in algorithmic content\n  moderation Abstract: The internet has become a central medium through which `networked publics'\nexpress their opinions and engage in debate. Offensive comments and personal\nattacks can inhibit participation in these spaces. Automated content moderation\naims to overcome this problem using machine learning classifiers trained on\nlarge corpora of texts manually annotated for offence. While such systems could\nhelp encourage more civil debate, they must navigate inherently normatively\ncontestable boundaries, and are subject to the idiosyncratic norms of the human\nraters who provide the training data. An important objective for platforms\nimplementing such measures might be to ensure that they are not unduly biased\ntowards or against particular norms of offence. This paper provides some\nexploratory methods by which the normative biases of algorithmic content\nmoderation systems can be measured, by way of a case study using an existing\ndataset of comments labelled for offence. We train classifiers on comments\nlabelled by different demographic subsets (men and women) to understand how\ndifferences in conceptions of offence between these groups might affect the\nperformance of the resulting models on various test sets. We conclude by\ndiscussing some of the ethical choices facing the implementers of algorithmic\nmoderation systems, given various desired levels of diversity of viewpoints\namongst discussion participants. \n\n"}
{"id": "1707.01939", "contents": "Title: High-Performance FPGA Implementation of Equivariant Adaptive Separation\n  via Independence Algorithm for Independent Component Analysis Abstract: Independent Component Analysis (ICA) is a dimensionality reduction technique\nthat can boost efficiency of machine learning models that deal with probability\ndensity functions, e.g. Bayesian neural networks. Algorithms that implement\nadaptive ICA converge slower than their nonadaptive counterparts, however, they\nare capable of tracking changes in underlying distributions of input features.\nThis intrinsically slow convergence of adaptive methods combined with existing\nhardware implementations that operate at very low clock frequencies necessitate\nfundamental improvements in both algorithm and hardware design. This paper\npresents an algorithm that allows efficient hardware implementation of ICA.\nCompared to previous work, our FPGA implementation of adaptive ICA improves\nclock frequency by at least one order of magnitude and throughput by at least\ntwo orders of magnitude. Our proposed algorithm is not limited to ICA and can\nbe used in various machine learning problems that use stochastic gradient\ndescent optimization. \n\n"}
{"id": "1707.02058", "contents": "Title: Controlling a Population Abstract: We introduce a new setting where a population of agents, each modelled by a\nfinite-state system, are controlled uniformly: the controller applies the same\naction to every agent. The framework is largely inspired by the control of a\nbiological system, namely a population of yeasts, where the controller may only\nchange the environment common to all cells. We study a synchronisation problem\nfor such populations: no matter how individual agents react to the actions of\nthe controller , the controller aims at driving all agents synchronously to a\ntarget state. The agents are naturally represented by a non-deterministic\nfinite state automaton (NFA), the same for every agent, and the whole system is\nencoded as a 2-player game. The first player (Controller) chooses actions, and\nthe second player (Agents) resolves non-determinism for each agent. The game\nwith m agents is called the m-population game. This gives rise to a\nparameterized control problem (where control refers to 2 player games), namely\nthe population control problem: can Controller control the m-population game\nfor all $m $\\in$ N$ whatever Agents does? In this paper, we prove that the\npopulation control problem is decidable, and it is a EXPTIME-complete problem.\nAs far as we know, this is one of the first results on parameterized control.\nOur algorithm, not based on cutoff techniques, produces winning strategies\nwhich are symbolic, that is, they do not need to count precisely how the\npopulation is spread between states. We also show that if there is no winning\nstrategy, then there is a population size M such that Controller wins the\nm-population game if and only if $m $\\le$ M$. Surprisingly, M can be doubly\nexponential in the number of states of the NFA, with tight upper and lower\nbounds. \n\n"}
{"id": "1707.03505", "contents": "Title: Proximally Guided Stochastic Subgradient Method for Nonsmooth, Nonconvex\n  Problems Abstract: In this paper, we introduce a stochastic projected subgradient method for\nweakly convex (i.e., uniformly prox-regular) nonsmooth, nonconvex functions---a\nwide class of functions which includes the additive and convex composite\nclasses. At a high-level, the method is an inexact proximal point iteration in\nwhich the strongly convex proximal subproblems are quickly solved with a\nspecialized stochastic projected subgradient method. The primary contribution\nof this paper is a simple proof that the proposed algorithm converges at the\nsame rate as the stochastic gradient method for smooth nonconvex problems. This\nresult appears to be the first convergence rate analysis of a stochastic (or\neven deterministic) subgradient method for the class of weakly convex\nfunctions. \n\n"}
{"id": "1707.04791", "contents": "Title: Non-Asymptotic Analysis of Robust Control from Coarse-Grained\n  Identification Abstract: This work explores the trade-off between the number of samples required to\naccurately build models of dynamical systems and the degradation of performance\nin various control objectives due to a coarse approximation. In particular, we\nshow that simple models can be easily fit from input/output data and are\nsufficient for achieving various control objectives. We derive bounds on the\nnumber of noisy input/output samples from a stable linear time-invariant system\nthat are sufficient to guarantee that the corresponding finite impulse response\napproximation is close to the true system in the $\\mathcal{H}_\\infty$-norm. We\ndemonstrate that these demands are lower than those derived in prior art which\naimed to accurately identify dynamical models. We also explore how different\nphysical input constraints, such as power constraints, affect the sample\ncomplexity. Finally, we show how our analysis fits within the established\nframework of robust control, by demonstrating how a controller designed for an\napproximate system provably meets performance objectives on the true system. \n\n"}
{"id": "1707.05422", "contents": "Title: Don't relax: early stopping for convex regularization Abstract: We consider the problem of designing efficient regularization algorithms when\nregularization is encoded by a (strongly) convex functional. Unlike classical\npenalization methods based on a relaxation approach, we propose an iterative\nmethod where regularization is achieved via early stopping. Our results show\nthat the proposed procedure achieves the same recovery accuracy as penalization\nmethods, while naturally integrating computational considerations. An empirical\nanalysis on a number of problems provides promising results with respect to the\nstate of the art. \n\n"}
{"id": "1707.05841", "contents": "Title: Linear Time Complexity Deep Fourier Scattering Network and Extension to\n  Nonlinear Invariants Abstract: In this paper we propose a scalable version of a state-of-the-art\ndeterministic time-invariant feature extraction approach based on consecutive\nchanges of basis and nonlinearities, namely, the scattering network. The first\nfocus of the paper is to extend the scattering network to allow the use of\nhigher order nonlinearities as well as extracting nonlinear and Fourier based\nstatistics leading to the required invariants of any inherently structured\ninput. In order to reach fast convolutions and to leverage the intrinsic\nstructure of wavelets, we derive our complete model in the Fourier domain. In\naddition of providing fast computations, we are now able to exploit sparse\nmatrices due to extremely high sparsity well localized in the Fourier domain.\nAs a result, we are able to reach a true linear time complexity with inputs in\nthe Fourier domain allowing fast and energy efficient solutions to machine\nlearning tasks. Validation of the features and computational results will be\npresented through the use of these invariant coefficients to perform\nclassification on audio recordings of bird songs captured in multiple different\nsoundscapes. In the end, the applicability of the presented solutions to deep\nartificial neural networks is discussed. \n\n"}
{"id": "1707.05878", "contents": "Title: On-line Building Energy Optimization using Deep Reinforcement Learning Abstract: Unprecedented high volumes of data are becoming available with the growth of\nthe advanced metering infrastructure. These are expected to benefit planning\nand operation of the future power system, and to help the customers transition\nfrom a passive to an active role. In this paper, we explore for the first time\nin the smart grid context the benefits of using Deep Reinforcement Learning, a\nhybrid type of methods that combines Reinforcement Learning with Deep Learning,\nto perform on-line optimization of schedules for building energy management\nsystems. The learning procedure was explored using two methods, Deep Q-learning\nand Deep Policy Gradient, both of them being extended to perform multiple\nactions simultaneously. The proposed approach was validated on the large-scale\nPecan Street Inc. database. This highly-dimensional database includes\ninformation about photovoltaic power generation, electric vehicles as well as\nbuildings appliances. Moreover, these on-line energy scheduling strategies\ncould be used to provide real-time feedback to consumers to encourage more\nefficient use of electricity. \n\n"}
{"id": "1707.06468", "contents": "Title: Breaking the Nonsmooth Barrier: A Scalable Parallel Method for Composite\n  Optimization Abstract: Due to their simplicity and excellent performance, parallel asynchronous\nvariants of stochastic gradient descent have become popular methods to solve a\nwide range of large-scale optimization problems on multi-core architectures.\nYet, despite their practical success, support for nonsmooth objectives is still\nlacking, making them unsuitable for many problems of interest in machine\nlearning, such as the Lasso, group Lasso or empirical risk minimization with\nconvex constraints.\n  In this work, we propose and analyze ProxASAGA, a fully asynchronous sparse\nmethod inspired by SAGA, a variance reduced incremental gradient algorithm. The\nproposed method is easy to implement and significantly outperforms the state of\nthe art on several nonsmooth, large-scale problems. We prove that our method\nachieves a theoretical linear speedup with respect to the sequential version\nunder assumptions on the sparsity of gradients and block-separability of the\nproximal term. Empirical benchmarks on a multi-core architecture illustrate\npractical speedups of up to 12x on a 20-core machine. \n\n"}
{"id": "1707.07328", "contents": "Title: Adversarial Examples for Evaluating Reading Comprehension Systems Abstract: Standard accuracy metrics indicate that reading comprehension systems are\nmaking rapid progress, but the extent to which these systems truly understand\nlanguage remains unclear. To reward systems with real language understanding\nabilities, we propose an adversarial evaluation scheme for the Stanford\nQuestion Answering Dataset (SQuAD). Our method tests whether systems can answer\nquestions about paragraphs that contain adversarially inserted sentences, which\nare automatically generated to distract computer systems without changing the\ncorrect answer or misleading humans. In this adversarial setting, the accuracy\nof sixteen published models drops from an average of $75\\%$ F1 score to $36\\%$;\nwhen the adversary is allowed to add ungrammatical sequences of words, average\naccuracy on four models decreases further to $7\\%$. We hope our insights will\nmotivate the development of new models that understand language more precisely. \n\n"}
{"id": "1707.08352", "contents": "Title: General Latent Feature Modeling for Data Exploration Tasks Abstract: This paper introduces a general Bayesian non- parametric latent feature model\nsuitable to per- form automatic exploratory analysis of heterogeneous datasets,\nwhere the attributes describing each object can be either discrete, continuous\nor mixed variables. The proposed model presents several important properties.\nFirst, it accounts for heterogeneous data while can be inferred in linear time\nwith respect to the number of objects and attributes. Second, its Bayesian\nnonparametric nature allows us to automatically infer the model complexity from\nthe data, i.e., the number of features necessary to capture the latent\nstructure in the data. Third, the latent features in the model are\nbinary-valued variables, easing the interpretability of the obtained latent\nfeatures in data exploration tasks. \n\n"}
{"id": "1707.08423", "contents": "Title: Non-Stationary Bandits with Habituation and Recovery Dynamics Abstract: Many settings involve sequential decision-making where a set of actions can\nbe chosen at each time step, each action provides a stochastic reward, and the\ndistribution for the reward of each action is initially unknown. However,\nfrequent selection of a specific action may reduce its expected reward, while\nabstaining from choosing an action may cause its expected reward to increase.\nSuch non-stationary phenomena are observed in many real world settings such as\npersonalized healthcare-adherence improving interventions and targeted online\nadvertising. Though finding an optimal policy for general models with\nnon-stationarity is PSPACE-complete, we propose and analyze a new class of\nmodels called ROGUE (Reducing or Gaining Unknown Efficacy) bandits, which we\nshow in this paper can capture these phenomena and are amenable to the design\nof effective policies. We first present a consistent maximum likelihood\nestimator for the parameters of these models. Next, we construct finite sample\nconcentration bounds that lead to an upper confidence bound policy called the\nROGUE Upper Confidence Bound (ROGUE-UCB) algorithm. We prove that under proper\nconditions the ROGUE-UCB algorithm achieves logarithmic in time regret, unlike\nexisting algorithms which result in linear regret. We conclude with a numerical\nexperiment using real data from a personalized healthcare-adherence improving\nintervention to increase physical activity. In this intervention, the goal is\nto optimize the selection of messages (e.g., confidence increasing vs.\nknowledge increasing) to send to each individual each day to increase adherence\nand physical activity. Our results show that ROGUE-UCB performs better in terms\nof regret and average reward as compared to state of the art algorithms, and\nthe use of ROGUE-UCB increases daily step counts by roughly 1,000 steps a day\n(about a half-mile more of walking) as compared to other algorithms. \n\n"}
{"id": "1707.08552", "contents": "Title: A Robust Multi-Batch L-BFGS Method for Machine Learning Abstract: This paper describes an implementation of the L-BFGS method designed to deal\nwith two adversarial situations. The first occurs in distributed computing\nenvironments where some of the computational nodes devoted to the evaluation of\nthe function and gradient are unable to return results on time. A similar\nchallenge occurs in a multi-batch approach in which the data points used to\ncompute function and gradients are purposely changed at each iteration to\naccelerate the learning process. Difficulties arise because L-BFGS employs\ngradient differences to update the Hessian approximations, and when these\ngradients are computed using different data points the updating process can be\nunstable. This paper shows how to perform stable quasi-Newton updating in the\nmulti-batch setting, studies the convergence properties for both convex and\nnonconvex functions, and illustrates the behavior of the algorithm in a\ndistributed computing platform on binary classification logistic regression and\nneural network training problems that arise in machine learning. \n\n"}
{"id": "1707.08689", "contents": "Title: Multi-Robot Transfer Learning: A Dynamical System Perspective Abstract: Multi-robot transfer learning allows a robot to use data generated by a\nsecond, similar robot to improve its own behavior. The potential advantages are\nreducing the time of training and the unavoidable risks that exist during the\ntraining phase. Transfer learning algorithms aim to find an optimal transfer\nmap between different robots. In this paper, we investigate, through a\ntheoretical study of single-input single-output (SISO) systems, the properties\nof such optimal transfer maps. We first show that the optimal transfer learning\nmap is, in general, a dynamic system. The main contribution of the paper is to\nprovide an algorithm for determining the properties of this optimal dynamic map\nincluding its order and regressors (i.e., the variables it depends on). The\nproposed algorithm does not require detailed knowledge of the robots' dynamics,\nbut relies on basic system properties easily obtainable through simple\nexperimental tests. We validate the proposed algorithm experimentally through\nan example of transfer learning between two different quadrotor platforms.\nExperimental results show that an optimal dynamic map, with correct properties\nobtained from our proposed algorithm, achieves 60-70% reduction of transfer\nlearning error compared to the cases when the data is directly transferred or\ntransferred using an optimal static map. \n\n"}
{"id": "1707.09132", "contents": "Title: Network Formation in the Sky: Unmanned Aerial Vehicles for Multi-hop\n  Wireless Backhauling Abstract: To reap the benefits of dense small base station (SBS) deployment, innovative\nbackhaul solutions are needed in order to manage scenarios in which high-speed\nground backhaul links are either unavailable or limited in capacity. In this\npaper, a novel backhaul scheme that utilizes unmanned aerial vehicles (UAVs) as\nan on-demand flying network linking ground SBSs and the core network is\nproposed. The design of the aerial backhaul scheme is formulated as a network\nformation game among UAVs that seek to form a multi-hop backhaul network in the\nair. To solve this game, a myopic network formation algorithm which reaches a\npairwise stable network upon convergence, is introduced. The proposed network\nformation algorithm enables the UAVs to form the necessary multi-hop backhaul\nnetwork in a decentralized manner thus adapting the backhaul architecture to\nthe dynamics of the network. Simulation results show that the proposed network\nformation algorithm achieves substantial performance gains in terms of both\nrate and delay reaching, respectively, up to 40% and 41% compared to the\nformation of direct communication links with the gateway node (for a network\nwith 15 UAVs). \n\n"}
{"id": "1707.09871", "contents": "Title: Feature Extraction via Recurrent Random Deep Ensembles and its\n  Application in Gruop-level Happiness Estimation Abstract: This paper presents a novel ensemble framework to extract highly\ndiscriminative feature representation of image and its application for\ngroup-level happpiness intensity prediction in wild. In order to generate\nenough diversity of decisions, n convolutional neural networks are trained by\nbootstrapping the training set and extract n features for each image from them.\nA recurrent neural network (RNN) is then used to remember which network\nextracts better feature and generate the final feature representation for one\nindividual image. Several group emotion models (GEM) are used to aggregate face\nfea- tures in a group and use parameter-optimized support vector regressor\n(SVR) to get the final results. Through extensive experiments, the great\neffectiveness of the proposed recurrent random deep ensembles (RRDE) is\ndemonstrated in both structural and decisional ways. The best result yields a\n0.55 root-mean-square error (RMSE) on validation set of HAPPEI dataset,\nsignificantly better than the baseline of 0.78. \n\n"}
{"id": "1708.00807", "contents": "Title: Adversarial-Playground: A Visualization Suite Showing How Adversarial\n  Examples Fool Deep Learning Abstract: Recent studies have shown that attackers can force deep learning models to\nmisclassify so-called \"adversarial examples\": maliciously generated images\nformed by making imperceptible modifications to pixel values. With growing\ninterest in deep learning for security applications, it is important for\nsecurity experts and users of machine learning to recognize how learning\nsystems may be attacked. Due to the complex nature of deep learning, it is\nchallenging to understand how deep models can be fooled by adversarial\nexamples. Thus, we present a web-based visualization tool,\nAdversarial-Playground, to demonstrate the efficacy of common adversarial\nmethods against a convolutional neural network (CNN) system.\nAdversarial-Playground is educational, modular and interactive. (1) It enables\nnon-experts to compare examples visually and to understand why an adversarial\nexample can fool a CNN-based image classifier. (2) It can help security experts\nexplore more vulnerability of deep learning as a software module. (3) Building\nan interactive visualization is challenging in this domain due to the large\nfeature space of image classification (generating adversarial examples is slow\nin general and visualizing images are costly). Through multiple novel design\nchoices, our tool can provide fast and accurate responses to user requests.\nEmpirically, we find that our client-server division strategy reduced the\nresponse time by an average of 1.5 seconds per sample. Our other innovation, a\nfaster variant of JSMA evasion algorithm, empirically performed twice as fast\nas JSMA and yet maintains a comparable evasion rate.\n  Project source code and data from our experiments available at:\nhttps://github.com/QData/AdversarialDNN-Playground \n\n"}
{"id": "1708.01422", "contents": "Title: Exploring the Function Space of Deep-Learning Machines Abstract: The function space of deep-learning machines is investigated by studying\ngrowth in the entropy of functions of a given error with respect to a reference\nfunction, realized by a deep-learning machine. Using physics-inspired methods\nwe study both sparsely and densely-connected architectures to discover a\nlayer-wise convergence of candidate functions, marked by a corresponding\nreduction in entropy when approaching the reference function, gain insight into\nthe importance of having a large number of layers, and observe phase\ntransitions as the error increases. \n\n"}
{"id": "1708.01519", "contents": "Title: A Latent Variable Model for Two-Dimensional Canonical Correlation\n  Analysis and its Variational Inference Abstract: Describing the dimension reduction (DR) techniques by means of probabilistic\nmodels has recently been given special attention. Probabilistic models, in\naddition to a better interpretability of the DR methods, provide a framework\nfor further extensions of such algorithms. One of the new approaches to the\nprobabilistic DR methods is to preserving the internal structure of data. It is\nmeant that it is not necessary that the data first be converted from the matrix\nor tensor format to the vector format in the process of dimensionality\nreduction. In this paper, a latent variable model for matrix-variate data for\ncanonical correlation analysis (CCA) is proposed. Since in general there is not\nany analytical maximum likelihood solution for this model, we present two\napproaches for learning the parameters. The proposed methods are evaluated\nusing the synthetic data in terms of convergence and quality of mappings. Also,\nreal data set is employed for assessing the proposed methods with several\nprobabilistic and none-probabilistic CCA based approaches. The results confirm\nthe superiority of the proposed methods with respect to the competing\nalgorithms. Moreover, this model can be considered as a framework for further\nextensions. \n\n"}
{"id": "1708.04781", "contents": "Title: Racing Thompson: an Efficient Algorithm for Thompson Sampling with\n  Non-conjugate Priors Abstract: Thompson sampling has impressive empirical performance for many multi-armed\nbandit problems. But current algorithms for Thompson sampling only work for the\ncase of conjugate priors since these algorithms require to infer the posterior,\nwhich is often computationally intractable when the prior is not conjugate. In\nthis paper, we propose a novel algorithm for Thompson sampling which only\nrequires to draw samples from a tractable distribution, so our algorithm is\nefficient even when the prior is non-conjugate. To do this, we reformulate\nThompson sampling as an optimization problem via the Gumbel-Max trick. After\nthat we construct a set of random variables and our goal is to identify the one\nwith highest mean. Finally, we solve it with techniques in best arm\nidentification. \n\n"}
{"id": "1708.05033", "contents": "Title: Corrupt Bandits for Preserving Local Privacy Abstract: We study a variant of the stochastic multi-armed bandit (MAB) problem in\nwhich the rewards are corrupted. In this framework, motivated by privacy\npreservation in online recommender systems, the goal is to maximize the sum of\nthe (unobserved) rewards, based on the observation of transformation of these\nrewards through a stochastic corruption process with known parameters. We\nprovide a lower bound on the expected regret of any bandit algorithm in this\ncorrupted setting. We devise a frequentist algorithm, KLUCB-CF, and a Bayesian\nalgorithm, TS-CF and give upper bounds on their regret. We also provide the\nappropriate corruption parameters to guarantee a desired level of local privacy\nand analyze how this impacts the regret. Finally, we present some experimental\nresults that confirm our analysis. \n\n"}
{"id": "1708.05924", "contents": "Title: A Deep Q-Network for the Beer Game: A Deep Reinforcement Learning\n  algorithm to Solve Inventory Optimization Problems Abstract: The beer game is a widely used in-class game that is played in supply chain\nmanagement classes to demonstrate the bullwhip effect. The game is a\ndecentralized, multi-agent, cooperative problem that can be modeled as a serial\nsupply chain network in which agents cooperatively attempt to minimize the\ntotal cost of the network even though each agent can only observe its own local\ninformation. Each agent chooses order quantities to replenish its stock. Under\nsome conditions, a base-stock replenishment policy is known to be optimal.\nHowever, in a decentralized supply chain in which some agents (stages) may act\nirrationally (as they do in the beer game), there is no known optimal policy\nfor an agent wishing to act optimally.\n  We propose a machine learning algorithm, based on deep Q-networks, to\noptimize the replenishment decisions at a given stage. When playing alongside\nagents who follow a base-stock policy, our algorithm obtains near-optimal order\nquantities. It performs much better than a base-stock policy when the other\nagents use a more realistic model of human ordering behavior. Unlike most other\nalgorithms in the literature, our algorithm does not have any limits on the\nbeer game parameter values. Like any deep learning algorithm, training the\nalgorithm can be computationally intensive, but this can be performed ahead of\ntime; the algorithm executes in real time when the game is played. Moreover, we\npropose a transfer learning approach so that the training performed for one\nagent and one set of cost coefficients can be adapted quickly for other agents\nand costs. Our algorithm can be extended to other decentralized multi-agent\ncooperative games with partially observed information, which is a common type\nof situation in real-world supply chain problems. \n\n"}
{"id": "1708.06046", "contents": "Title: nuts-flow/ml: data pre-processing for deep learning Abstract: Data preprocessing is a fundamental part of any machine learning application\nand frequently the most time-consuming aspect when developing a machine\nlearning solution. Preprocessing for deep learning is characterized by\npipelines that lazily load data and perform data transformation, augmentation,\nbatching and logging. Many of these functions are common across applications\nbut require different arrangements for training, testing or inference. Here we\nintroduce a novel software framework named nuts-flow/ml that encapsulates\ncommon preprocessing operations as components, which can be flexibly arranged\nto rapidly construct efficient preprocessing pipelines for deep learning. \n\n"}
{"id": "1708.07061", "contents": "Title: Forecasting day-ahead electricity prices in Europe: the importance of\n  considering market integration Abstract: Motivated by the increasing integration among electricity markets, in this\npaper we propose two different methods to incorporate market integration in\nelectricity price forecasting and to improve the predictive performance. First,\nwe propose a deep neural network that considers features from connected markets\nto improve the predictive accuracy in a local market. To measure the importance\nof these features, we propose a novel feature selection algorithm that, by\nusing Bayesian optimization and functional analysis of variance, evaluates the\neffect of the features on the algorithm performance. In addition, using market\nintegration, we propose a second model that, by simultaneously predicting\nprices from two markets, improves the forecasting accuracy even further. As a\ncase study, we consider the electricity market in Belgium and the improvements\nin forecasting accuracy when using various French electricity features. We show\nthat the two proposed models lead to improvements that are statistically\nsignificant. Particularly, due to market integration, the predictive accuracy\nis improved from 15.7% to 12.5% sMAPE (symmetric mean absolute percentage\nerror). In addition, we show that the proposed feature selection algorithm is\nable to perform a correct assessment, i.e. to discard the irrelevant features. \n\n"}
{"id": "1708.07120", "contents": "Title: Super-Convergence: Very Fast Training of Neural Networks Using Large\n  Learning Rates Abstract: In this paper, we describe a phenomenon, which we named \"super-convergence\",\nwhere neural networks can be trained an order of magnitude faster than with\nstandard training methods. The existence of super-convergence is relevant to\nunderstanding why deep networks generalize well. One of the key elements of\nsuper-convergence is training with one learning rate cycle and a large maximum\nlearning rate. A primary insight that allows super-convergence training is that\nlarge learning rates regularize the training, hence requiring a reduction of\nall other forms of regularization in order to preserve an optimal\nregularization balance. We also derive a simplification of the Hessian Free\noptimization method to compute an estimate of the optimal learning rate.\nExperiments demonstrate super-convergence for Cifar-10/100, MNIST and Imagenet\ndatasets, and resnet, wide-resnet, densenet, and inception architectures. In\naddition, we show that super-convergence provides a greater boost in\nperformance relative to standard training when the amount of labeled training\ndata is limited. The architectures and code to replicate the figures in this\npaper are available at github.com/lnsmith54/super-convergence. See\nhttp://www.fast.ai/2018/04/30/dawnbench-fastai/ for an application of\nsuper-convergence to win the DAWNBench challenge (see\nhttps://dawn.cs.stanford.edu/benchmark/). \n\n"}
{"id": "1708.07827", "contents": "Title: Second-Order Optimization for Non-Convex Machine Learning: An Empirical\n  Study Abstract: While first-order optimization methods such as stochastic gradient descent\n(SGD) are popular in machine learning (ML), they come with well-known\ndeficiencies, including relatively-slow convergence, sensitivity to the\nsettings of hyper-parameters such as learning rate, stagnation at high training\nerrors, and difficulty in escaping flat regions and saddle points. These issues\nare particularly acute in highly non-convex settings such as those arising in\nneural networks. Motivated by this, there has been recent interest in\nsecond-order methods that aim to alleviate these shortcomings by capturing\ncurvature information. In this paper, we report detailed empirical evaluations\nof a class of Newton-type methods, namely sub-sampled variants of trust region\n(TR) and adaptive regularization with cubics (ARC) algorithms, for non-convex\nML problems. In doing so, we demonstrate that these methods not only can be\ncomputationally competitive with hand-tuned SGD with momentum, obtaining\ncomparable or better generalization performance, but also they are highly\nrobust to hyper-parameter settings. Further, in contrast to SGD with momentum,\nwe show that the manner in which these Newton-type methods employ curvature\ninformation allows them to seamlessly escape flat regions and saddle points. \n\n"}
{"id": "1708.08917", "contents": "Title: CirCNN: Accelerating and Compressing Deep Neural Networks Using\n  Block-CirculantWeight Matrices Abstract: Large-scale deep neural networks (DNNs) are both compute and memory\nintensive. As the size of DNNs continues to grow, it is critical to improve the\nenergy efficiency and performance while maintaining accuracy. For DNNs, the\nmodel size is an important factor affecting performance, scalability and energy\nefficiency. Weight pruning achieves good compression ratios but suffers from\nthree drawbacks: 1) the irregular network structure after pruning; 2) the\nincreased training complexity; and 3) the lack of rigorous guarantee of\ncompression ratio and inference accuracy. To overcome these limitations, this\npaper proposes CirCNN, a principled approach to represent weights and process\nneural networks using block-circulant matrices. CirCNN utilizes the Fast\nFourier Transform (FFT)-based fast multiplication, simultaneously reducing the\ncomputational complexity (both in inference and training) from O(n2) to\nO(nlogn) and the storage complexity from O(n2) to O(n), with negligible\naccuracy loss. Compared to other approaches, CirCNN is distinct due to its\nmathematical rigor: it can converge to the same effectiveness as DNNs without\ncompression. The CirCNN architecture, a universal DNN inference engine that can\nbe implemented on various hardware/software platforms with configurable network\narchitecture. To demonstrate the performance and energy efficiency, we test\nCirCNN in FPGA, ASIC and embedded processors. Our results show that CirCNN\narchitecture achieves very high energy efficiency and performance with a small\nhardware footprint. Based on the FPGA implementation and ASIC synthesis\nresults, CirCNN achieves 6-102X energy efficiency improvements compared with\nthe best state-of-the-art results. \n\n"}
{"id": "1709.00228", "contents": "Title: Learning Multi-item Auctions with (or without) Samples Abstract: We provide algorithms that learn simple auctions whose revenue is\napproximately optimal in multi-item multi-bidder settings, for a wide range of\nvaluations including unit-demand, additive, constrained additive, XOS, and\nsubadditive. We obtain our learning results in two settings. The first is the\ncommonly studied setting where sample access to the bidders' distributions over\nvaluations is given, for both regular distributions and arbitrary distributions\nwith bounded support. Our algorithms require polynomially many samples in the\nnumber of items and bidders. The second is a more general max-min learning\nsetting that we introduce, where we are given \"approximate distributions,\" and\nwe seek to compute an auction whose revenue is approximately optimal\nsimultaneously for all \"true distributions\" that are close to the given ones.\nThese results are more general in that they imply the sample-based results, and\nare also applicable in settings where we have no sample access to the\nunderlying distributions but have estimated them indirectly via market research\nor by observation of previously run, potentially non-truthful auctions.\n  Our results hold for valuation distributions satisfying the standard (and\nnecessary) independence-across-items property. They also generalize and improve\nupon recent works, which have provided algorithms that learn approximately\noptimal auctions in more restricted settings with additive, subadditive and\nunit-demand valuations using sample access to distributions. We generalize\nthese results to the complete unit-demand, additive, and XOS setting, to i.i.d.\nsubadditive bidders, and to the max-min setting.\n  Our results are enabled by new uniform convergence bounds for hypotheses\nclasses under product measures. Our bounds result in exponential savings in\nsample complexity compared to bounds derived by bounding the VC dimension, and\nare of independent interest. \n\n"}
{"id": "1709.01062", "contents": "Title: A hierarchical loss and its problems when classifying non-hierarchically Abstract: Failing to distinguish between a sheepdog and a skyscraper should be worse\nand penalized more than failing to distinguish between a sheepdog and a poodle;\nafter all, sheepdogs and poodles are both breeds of dogs. However, existing\nmetrics of failure (so-called \"loss\" or \"win\") used in textual or visual\nclassification/recognition via neural networks seldom leverage a-priori\ninformation, such as a sheepdog being more similar to a poodle than to a\nskyscraper. We define a metric that, inter alia, can penalize failure to\ndistinguish between a sheepdog and a skyscraper more than failure to\ndistinguish between a sheepdog and a poodle. Unlike previously employed\npossibilities, this metric is based on an ultrametric tree associated with any\ngiven tree organization into a semantically meaningful hierarchy of a\nclassifier's classes. An ultrametric tree is a tree with a so-called\nultrametric distance metric such that all leaves are at the same distance from\nthe root. Unfortunately, extensive numerical experiments indicate that the\nstandard practice of training neural networks via stochastic gradient descent\nwith random starting points often drives down the hierarchical loss nearly as\nmuch when minimizing the standard cross-entropy loss as when trying to minimize\nthe hierarchical loss directly. Thus, this hierarchical loss is unreliable as\nan objective for plain, randomly started stochastic gradient descent to\nminimize; the main value of the hierarchical loss may be merely as a meaningful\nmetric of success of a classifier. \n\n"}
{"id": "1709.01230", "contents": "Title: On the Suboptimality of Proximal Gradient Descent for $\\ell^{0}$ Sparse\n  Approximation Abstract: We study the proximal gradient descent (PGD) method for $\\ell^{0}$ sparse\napproximation problem as well as its accelerated optimization with randomized\nalgorithms in this paper. We first offer theoretical analysis of PGD showing\nthe bounded gap between the sub-optimal solution by PGD and the globally\noptimal solution for the $\\ell^{0}$ sparse approximation problem under\nconditions weaker than Restricted Isometry Property widely used in compressive\nsensing literature. Moreover, we propose randomized algorithms to accelerate\nthe optimization by PGD using randomized low rank matrix approximation\n(PGD-RMA) and randomized dimension reduction (PGD-RDR). Our randomized\nalgorithms substantially reduces the computation cost of the original PGD for\nthe $\\ell^{0}$ sparse approximation problem, and the resultant sub-optimal\nsolution still enjoys provable suboptimality, namely, the sub-optimal solution\nto the reduced problem still has bounded gap to the globally optimal solution\nto the original problem. \n\n"}
{"id": "1709.01674", "contents": "Title: Probabilistic Rule Realization and Selection Abstract: Abstraction and realization are bilateral processes that are key in deriving\nintelligence and creativity. In many domains, the two processes are approached\nthrough rules: high-level principles that reveal invariances within similar yet\ndiverse examples. Under a probabilistic setting for discrete input spaces, we\nfocus on the rule realization problem which generates input sample\ndistributions that follow the given rules. More ambitiously, we go beyond a\nmechanical realization that takes whatever is given, but instead ask for\nproactively selecting reasonable rules to realize. This goal is demanding in\npractice, since the initial rule set may not always be consistent and thus\nintelligent compromises are needed. We formulate both rule realization and\nselection as two strongly connected components within a single and symmetric\nbi-convex problem, and derive an efficient algorithm that works at large scale.\nTaking music compositional rules as the main example throughout the paper, we\ndemonstrate our model's efficiency in not only music realization (composition)\nbut also music interpretation and understanding (analysis). \n\n"}
{"id": "1709.01982", "contents": "Title: Stabilizing Weighted Graphs Abstract: An edge-weighted graph $G=(V,E)$ is called stable if the value of a\nmaximum-weight matching equals the value of a maximum-weight fractional\nmatching. Stable graphs play an important role in some interesting game theory\nproblems, such as network bargaining games and cooperative matching games,\nbecause they characterize instances which admit stable outcomes. Motivated by\nthis, in the last few years many researchers have investigated the algorithmic\nproblem of turning a given graph into a stable one, via edge- and\nvertex-removal operations. However, all the algorithmic results developed in\nthe literature so far only hold for unweighted instances, i.e., assuming unit\nweights on the edges of $G$.\n  We give the first polynomial-time algorithm to find a minimum cardinality\nsubset of vertices whose removal from $G$ yields a stable graph, for any\nweighted graph $G$. The algorithm is combinatorial and exploits new structural\nproperties of basic fractional matchings, which are of independent interest. In\nparticular, one of the main ingredients of our result is the development of a\npolynomial-time algorithm to compute a basic maximum-weight fractional matching\nwith minimum number of odd cycles in its support. This generalizes a\nfundamental and classical result on unweighted matchings given by Balas more\nthan 30 years ago, which we expect to prove useful beyond this particular\napplication.\n  In contrast, we show that the problem of finding a minimum cardinality subset\nof edges whose removal from a weighted graph $G$ yields a stable graph, does\nnot admit any constant-factor approximation algorithm, unless $P=NP$. In this\nsetting, we develop an $O(\\Delta)$-approximation algorithm for the problem,\nwhere $\\Delta$ is the maximum degree of a node in $G$. \n\n"}
{"id": "1709.02956", "contents": "Title: Deep Residual Networks and Weight Initialization Abstract: Residual Network (ResNet) is the state-of-the-art architecture that realizes\nsuccessful training of really deep neural network. It is also known that good\nweight initialization of neural network avoids problem of vanishing/exploding\ngradients. In this paper, simplified models of ResNets are analyzed. We argue\nthat goodness of ResNet is correlated with the fact that ResNets are relatively\ninsensitive to choice of initial weights. We also demonstrate how batch\nnormalization improves backpropagation of deep ResNets without tuning initial\nvalues of weights. \n\n"}
{"id": "1709.03539", "contents": "Title: Finite-state Strategies in Delay Games Abstract: What is a finite-state strategy in a delay game? We answer this surprisingly\nnon-trivial question and present a very general framework for computing such\nstrategies: they exist for all winning conditions that are recognized by\nautomata with acceptance conditions that satisfy a certain aggregation\nproperty. Our framework also yields upper bounds on the complexity of\ndetermining the winner of such delay games and upper bounds on the necessary\nlookahead to win the game. In particular, we cover all previous results of that\nkind as special cases of our uniform approach. \n\n"}
{"id": "1709.04511", "contents": "Title: A Study of AI Population Dynamics with Million-agent Reinforcement\n  Learning Abstract: We conduct an empirical study on discovering the ordered collective dynamics\nobtained by a population of intelligence agents, driven by million-agent\nreinforcement learning. Our intention is to put intelligent agents into a\nsimulated natural context and verify if the principles developed in the real\nworld could also be used in understanding an artificially-created intelligent\npopulation. To achieve this, we simulate a large-scale predator-prey world,\nwhere the laws of the world are designed by only the findings or logical\nequivalence that have been discovered in nature. We endow the agents with the\nintelligence based on deep reinforcement learning (DRL). In order to scale the\npopulation size up to millions agents, a large-scale DRL training platform with\nredesigned experience buffer is proposed. Our results show that the population\ndynamics of AI agents, driven only by each agent's individual self-interest,\nreveals an ordered pattern that is similar to the Lotka-Volterra model studied\nin population biology. We further discover the emergent behaviors of collective\nadaptations in studying how the agents' grouping behaviors will change with the\nenvironmental resources. Both of the two findings could be explained by the\nself-organization theory in nature. \n\n"}
{"id": "1709.06129", "contents": "Title: When is a Convolutional Filter Easy To Learn? Abstract: We analyze the convergence of (stochastic) gradient descent algorithm for\nlearning a convolutional filter with Rectified Linear Unit (ReLU) activation\nfunction. Our analysis does not rely on any specific form of the input\ndistribution and our proofs only use the definition of ReLU, in contrast with\nprevious works that are restricted to standard Gaussian input. We show that\n(stochastic) gradient descent with random initialization can learn the\nconvolutional filter in polynomial time and the convergence rate depends on the\nsmoothness of the input distribution and the closeness of patches. To the best\nof our knowledge, this is the first recovery guarantee of gradient-based\nalgorithms for convolutional filter on non-Gaussian input distributions. Our\ntheory also justifies the two-stage learning rate strategy in deep neural\nnetworks. While our focus is theoretical, we also present experiments that\nillustrate our theoretical findings. \n\n"}
{"id": "1709.06560", "contents": "Title: Deep Reinforcement Learning that Matters Abstract: In recent years, significant progress has been made in solving challenging\nproblems across various domains using deep reinforcement learning (RL).\nReproducing existing work and accurately judging the improvements offered by\nnovel methods is vital to sustaining this progress. Unfortunately, reproducing\nresults for state-of-the-art deep RL methods is seldom straightforward. In\nparticular, non-determinism in standard benchmark environments, combined with\nvariance intrinsic to the methods, can make reported results tough to\ninterpret. Without significance metrics and tighter standardization of\nexperimental reporting, it is difficult to determine whether improvements over\nthe prior state-of-the-art are meaningful. In this paper, we investigate\nchallenges posed by reproducibility, proper experimental techniques, and\nreporting procedures. We illustrate the variability in reported metrics and\nresults when comparing against common baselines and suggest guidelines to make\nfuture results in deep RL more reproducible. We aim to spur discussion about\nhow to ensure continued progress in the field by minimizing wasted effort\nstemming from results that are non-reproducible and easily misinterpreted. \n\n"}
{"id": "1709.06620", "contents": "Title: Learning of Coordination Policies for Robotic Swarms Abstract: Inspired by biological swarms, robotic swarms are envisioned to solve\nreal-world problems that are difficult for individual agents. Biological swarms\ncan achieve collective intelligence based on local interactions and simple\nrules; however, designing effective distributed policies for large-scale\nrobotic swarms to achieve a global objective can be challenging. Although it is\noften possible to design an optimal centralized strategy for smaller numbers of\nagents, those methods can fail as the number of agents increases. Motivated by\nthe growing success of machine learning, we develop a deep learning approach\nthat learns distributed coordination policies from centralized policies. In\ncontrast to traditional distributed control approaches, which are usually based\non human-designed policies for relatively simple tasks, this learning-based\napproach can be adapted to more difficult tasks. We demonstrate the efficacy of\nour proposed approach on two different tasks, the well-known rendezvous problem\nand a more difficult particle assignment problem. For the latter, no known\ndistributed policy exists. From extensive simulations, it is shown that the\nperformance of the learned coordination policies is comparable to the\ncentralized policies, surpassing state-of-the-art distributed policies.\nThereby, our proposed approach provides a promising alternative for real-world\ncoordination problems that would be otherwise computationally expensive to\nsolve or intangible to explore. \n\n"}
{"id": "1709.07172", "contents": "Title: SpectralLeader: Online Spectral Learning for Single Topic Models Abstract: We study the problem of learning a latent variable model from a stream of\ndata. Latent variable models are popular in practice because they can explain\nobserved data in terms of unobserved concepts. These models have been\ntraditionally studied in the offline setting. In the online setting, on the\nother hand, the online EM is arguably the most popular algorithm for learning\nlatent variable models. Although the online EM is computationally efficient, it\ntypically converges to a local optimum. In this work, we develop a new online\nlearning algorithm for latent variable models, which we call SpectralLeader.\nSpectralLeader always converges to the global optimum, and we derive a\nsublinear upper bound on its $n$-step regret in the bag-of-words model. In both\nsynthetic and real-world experiments, we show that SpectralLeader performs\nsimilarly to or better than the online EM with tuned hyper-parameters. \n\n"}
{"id": "1709.09625", "contents": "Title: How regularization affects the critical points in linear networks Abstract: This paper is concerned with the problem of representing and learning a\nlinear transformation using a linear neural network. In recent years, there has\nbeen a growing interest in the study of such networks in part due to the\nsuccesses of deep learning. The main question of this body of research and also\nof this paper pertains to the existence and optimality properties of the\ncritical points of the mean-squared loss function. The primary concern here is\nthe robustness of the critical points with regularization of the loss function.\nAn optimal control model is introduced for this purpose and a learning\nalgorithm (regularized form of backprop) derived for the same using the\nHamilton's formulation of optimal control. The formulation is used to provide a\ncomplete characterization of the critical points in terms of the solutions of a\nnonlinear matrix-valued equation, referred to as the characteristic equation.\nAnalytical and numerical tools from bifurcation theory are used to compute the\ncritical points via the solutions of the characteristic equation. The main\nconclusion is that the critical point diagram can be fundamentally different\neven with arbitrary small amounts of regularization. \n\n"}
{"id": "1709.10030", "contents": "Title: Sparse Hierarchical Regression with Polynomials Abstract: We present a novel method for exact hierarchical sparse polynomial\nregression. Our regressor is that degree $r$ polynomial which depends on at\nmost $k$ inputs, counting at most $\\ell$ monomial terms, which minimizes the\nsum of the squares of its prediction errors. The previous hierarchical sparse\nspecification aligns well with modern big data settings where many inputs are\nnot relevant for prediction purposes and the functional complexity of the\nregressor needs to be controlled as to avoid overfitting. We present a two-step\napproach to this hierarchical sparse regression problem. First, we discard\nirrelevant inputs using an extremely fast input ranking heuristic. Secondly, we\ntake advantage of modern cutting plane methods for integer optimization to\nsolve our resulting reduced hierarchical $(k, \\ell)$-sparse problem exactly.\nThe ability of our method to identify all $k$ relevant inputs and all $\\ell$\nmonomial terms is shown empirically to experience a phase transition.\nCrucially, the same transition also presents itself in our ability to reject\nall irrelevant features and monomials as well. In the regime where our method\nis statistically powerful, its computational complexity is interestingly on par\nwith Lasso based heuristics. The presented work fills a void in terms of a lack\nof powerful disciplined nonlinear sparse regression methods in high-dimensional\nsettings. Our method is shown empirically to scale to regression problems with\n$n\\approx 10,000$ observations for input dimension $p\\approx 1,000$. \n\n"}
{"id": "1709.10082", "contents": "Title: Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep\n  Reinforcement Learning Abstract: Developing a safe and efficient collision avoidance policy for multiple\nrobots is challenging in the decentralized scenarios where each robot generate\nits paths without observing other robots' states and intents. While other\ndistributed multi-robot collision avoidance systems exist, they often require\nextracting agent-level features to plan a local collision-free action, which\ncan be computationally prohibitive and not robust. More importantly, in\npractice the performance of these methods are much lower than their centralized\ncounterparts.\n  We present a decentralized sensor-level collision avoidance policy for\nmulti-robot systems, which directly maps raw sensor measurements to an agent's\nsteering commands in terms of movement velocity. As a first step toward\nreducing the performance gap between decentralized and centralized methods, we\npresent a multi-scenario multi-stage training framework to find an optimal\npolicy which is trained over a large number of robots on rich, complex\nenvironments simultaneously using a policy gradient based reinforcement\nlearning algorithm. We validate the learned sensor-level collision avoidance\npolicy in a variety of simulated scenarios with thorough performance\nevaluations and show that the final learned policy is able to find time\nefficient, collision-free paths for a large-scale robot system. We also\ndemonstrate that the learned policy can be well generalized to new scenarios\nthat do not appear in the entire training period, including navigating a\nheterogeneous group of robots and a large-scale scenario with 100 robots.\nVideos are available at https://sites.google.com/view/drlmaca \n\n"}
{"id": "1710.01688", "contents": "Title: On the Sample Complexity of the Linear Quadratic Regulator Abstract: This paper addresses the optimal control problem known as the Linear\nQuadratic Regulator in the case when the dynamics are unknown. We propose a\nmulti-stage procedure, called Coarse-ID control, that estimates a model from a\nfew experimental trials, estimates the error in that model with respect to the\ntruth, and then designs a controller using both the model and uncertainty\nestimate. Our technique uses contemporary tools from random matrix theory to\nbound the error in the estimation procedure. We also employ a recently\ndeveloped approach to control synthesis called System Level Synthesis that\nenables robust control design by solving a convex optimization problem. We\nprovide end-to-end bounds on the relative error in control cost that are nearly\noptimal in the number of parameters and that highlight salient properties of\nthe system to be controlled such as closed-loop sensitivity and optimal control\nmagnitude. We show experimentally that the Coarse-ID approach enables efficient\ncomputation of a stabilizing controller in regimes where simple control schemes\nthat do not take the model uncertainty into account fail to stabilize the true\nsystem. \n\n"}
{"id": "1710.01782", "contents": "Title: On the Tree Conjecture for the Network Creation Game Abstract: Selfish Network Creation focuses on modeling real world networks from a\ngame-theoretic point of view. One of the classic models by Fabrikant et al.\n[PODC'03] is the network creation game, where agents correspond to nodes in a\nnetwork which buy incident edges for the price of $\\alpha$ per edge to minimize\ntheir total distance to all other nodes. The model is well-studied but still\nhas intriguing open problems. The most famous conjectures state that the price\nof anarchy is constant for all $\\alpha$ and that for $\\alpha \\geq n$ all\nequilibrium networks are trees.\n  We introduce a novel technique for analyzing stable networks for high\nedge-price $\\alpha$ and employ it to improve on the best known bounds for both\nconjectures. In particular we show that for $\\alpha > 4n-13$ all equilibrium\nnetworks must be trees, which implies a constant price of anarchy for this\nrange of $\\alpha$. Moreover, we also improve the constant upper bound on the\nprice of anarchy for equilibrium trees. \n\n"}
{"id": "1710.02277", "contents": "Title: Efficient K-Shot Learning with Regularized Deep Networks Abstract: Feature representations from pre-trained deep neural networks have been known\nto exhibit excellent generalization and utility across a variety of related\ntasks. Fine-tuning is by far the simplest and most widely used approach that\nseeks to exploit and adapt these feature representations to novel tasks with\nlimited data. Despite the effectiveness of fine-tuning, itis often sub-optimal\nand requires very careful optimization to prevent severe over-fitting to small\ndatasets. The problem of sub-optimality and over-fitting, is due in part to the\nlarge number of parameters used in a typical deep convolutional neural network.\nTo address these problems, we propose a simple yet effective regularization\nmethod for fine-tuning pre-trained deep networks for the task of k-shot\nlearning. To prevent overfitting, our key strategy is to cluster the model\nparameters while ensuring intra-cluster similarity and inter-cluster diversity\nof the parameters, effectively regularizing the dimensionality of the parameter\nsearch space. In particular, we identify groups of neurons within each layer of\na deep network that shares similar activation patterns. When the network is to\nbe fine-tuned for a classification task using only k examples, we propagate a\nsingle gradient to all of the neuron parameters that belong to the same group.\nThe grouping of neurons is non-trivial as neuron activations depend on the\ndistribution of the input data. To efficiently search for optimal groupings\nconditioned on the input data, we propose a reinforcement learning search\nstrategy using recurrent networks to learn the optimal group assignments for\neach network layer. Experimental results show that our method can be easily\napplied to several popular convolutional neural networks and improve upon other\nstate-of-the-art fine-tuning based k-shot learning strategies by more than10% \n\n"}
{"id": "1710.02338", "contents": "Title: Projection Based Weight Normalization for Deep Neural Networks Abstract: Optimizing deep neural networks (DNNs) often suffers from the ill-conditioned\nproblem. We observe that the scaling-based weight space symmetry property in\nrectified nonlinear network will cause this negative effect. Therefore, we\npropose to constrain the incoming weights of each neuron to be unit-norm, which\nis formulated as an optimization problem over Oblique manifold. A simple yet\nefficient method referred to as projection based weight normalization (PBWN) is\nalso developed to solve this problem. PBWN executes standard gradient updates,\nfollowed by projecting the updated weight back to Oblique manifold. This\nproposed method has the property of regularization and collaborates well with\nthe commonly used batch normalization technique. We conduct comprehensive\nexperiments on several widely-used image datasets including CIFAR-10,\nCIFAR-100, SVHN and ImageNet for supervised learning over the state-of-the-art\nconvolutional neural networks, such as Inception, VGG and residual networks.\nThe results show that our method is able to improve the performance of DNNs\nwith different architectures consistently. We also apply our method to Ladder\nnetwork for semi-supervised learning on permutation invariant MNIST dataset,\nand our method outperforms the state-of-the-art methods: we obtain test errors\nas 2.52%, 1.06%, and 0.91% with only 20, 50, and 100 labeled samples,\nrespectively. \n\n"}
{"id": "1710.03695", "contents": "Title: Fast and Safe: Accelerated gradient methods with optimality certificates\n  and underestimate sequences Abstract: In this work we introduce the concept of an Underestimate Sequence (UES),\nwhich is motivated by Nesterov's estimate sequence. Our definition of a UES\nutilizes three sequences, one of which is a lower bound (or under-estimator) of\nthe objective function. The question of how to construct an appropriate\nsequence of lower bounds is addressed, and we present lower bounds for strongly\nconvex smooth functions and for strongly convex composite functions, which\nadhere to the UES framework. Further, we propose several first order methods\nfor minimizing strongly convex functions in both the smooth and composite\ncases. The algorithms, based on efficiently updating lower bounds on the\nobjective functions, have natural stopping conditions that provide the user\nwith a certificate of optimality. Convergence of all algorithms is guaranteed\nthrough the UES framework, and we show that all presented algorithms converge\nlinearly, with the accelerated variants enjoying the optimal linear rate of\nconvergence. \n\n"}
{"id": "1710.04062", "contents": "Title: Decentralized Online Learning with Kernels Abstract: We consider multi-agent stochastic optimization problems over reproducing\nkernel Hilbert spaces (RKHS). In this setting, a network of interconnected\nagents aims to learn decision functions, i.e., nonlinear statistical models,\nthat are optimal in terms of a global convex functional that aggregates data\nacross the network, with only access to locally and sequentially observed\nsamples. We propose solving this problem by allowing each agent to learn a\nlocal regression function while enforcing consensus constraints. We use a\npenalized variant of functional stochastic gradient descent operating\nsimultaneously with low-dimensional subspace projections. These subspaces are\nconstructed greedily by applying orthogonal matching pursuit to the sequence of\nkernel dictionaries and weights. By tuning the projection-induced bias, we\npropose an algorithm that allows for each individual agent to learn, based upon\nits locally observed data stream and message passing with its neighbors only, a\nregression function that is close to the globally optimal regression function.\nThat is, we establish that with constant step-size selections agents' functions\nconverge to a neighborhood of the globally optimal one while satisfying the\nconsensus constraints as the penalty parameter is increased. Moreover, the\ncomplexity of the learned regression functions is guaranteed to remain finite.\nOn both multi-class kernel logistic regression and multi-class kernel support\nvector classification with data generated from class-dependent Gaussian mixture\nmodels, we observe stable function estimation and state of the art performance\nfor distributed online multi-class classification. Experiments on the Brodatz\ntextures further substantiate the empirical validity of this approach. \n\n"}
{"id": "1710.04246", "contents": "Title: Monotonicity axioms in approval-based multi-winner voting rules Abstract: In this paper we study several monotonicity axioms in approval-based\nmulti-winner voting rules. We consider monotonicity with respect to the support\nreceived by the winners and also monotonicity in the size of the committee.\nMonotonicity with respect to the support is studied when the set of voters does\nnot change and when new voters enter the election. For each of these two cases\nwe consider a strong and a weak version of the axiom. We observe certain\nincompatibilities between the monotonicity axioms and well-known representation\naxioms (extended/proportional justified representation) for the voting rules\nthat we analyze and provide formal proofs of incompatibility between some of\nthese axioms and perfect representation. \n\n"}
{"id": "1710.04837", "contents": "Title: Recent Advances in Zero-shot Recognition Abstract: With the recent renaissance of deep convolution neural networks, encouraging\nbreakthroughs have been achieved on the supervised recognition tasks, where\neach class has sufficient training data and fully annotated training data.\nHowever, to scale the recognition to a large number of classes with few or now\ntraining samples for each class remains an unsolved problem. One approach to\nscaling up the recognition is to develop models capable of recognizing unseen\ncategories without any training instances, or zero-shot recognition/ learning.\nThis article provides a comprehensive review of existing zero-shot recognition\ntechniques covering various aspects ranging from representations of models, and\nfrom datasets and evaluation settings. We also overview related recognition\ntasks including one-shot and open set recognition which can be used as natural\nextensions of zero-shot recognition when limited number of class samples become\navailable or when zero-shot recognition is implemented in a real-world setting.\nImportantly, we highlight the limitations of existing approaches and point out\nfuture research directions in this existing new research area. \n\n"}
{"id": "1710.04908", "contents": "Title: Graph Convolutional Networks for Classification with a Structured Label\n  Space Abstract: It is a usual practice to ignore any structural information underlying\nclasses in multi-class classification. In this paper, we propose a graph\nconvolutional network (GCN) augmented neural network classifier to exploit a\nknown, underlying graph structure of labels. The proposed approach resembles an\n(approximate) inference procedure in, for instance, a conditional random field\n(CRF). We evaluate the proposed approach on document classification and object\nrecognition and report both accuracies and graph-theoretic metrics that\ncorrespond to the consistency of the model's prediction. The experiment results\nreveal that the proposed model outperforms a baseline method which ignores the\ngraph structures of a label space in terms of graph-theoretic metrics. \n\n"}
{"id": "1710.05941", "contents": "Title: Searching for Activation Functions Abstract: The choice of activation functions in deep networks has a significant effect\non the training dynamics and task performance. Currently, the most successful\nand widely-used activation function is the Rectified Linear Unit (ReLU).\nAlthough various hand-designed alternatives to ReLU have been proposed, none\nhave managed to replace it due to inconsistent gains. In this work, we propose\nto leverage automatic search techniques to discover new activation functions.\nUsing a combination of exhaustive and reinforcement learning-based search, we\ndiscover multiple novel activation functions. We verify the effectiveness of\nthe searches by conducting an empirical evaluation with the best discovered\nactivation function. Our experiments show that the best discovered activation\nfunction, $f(x) = x \\cdot \\text{sigmoid}(\\beta x)$, which we name Swish, tends\nto work better than ReLU on deeper models across a number of challenging\ndatasets. For example, simply replacing ReLUs with Swish units improves top-1\nclassification accuracy on ImageNet by 0.9\\% for Mobile NASNet-A and 0.6\\% for\nInception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it\neasy for practitioners to replace ReLUs with Swish units in any neural network. \n\n"}
{"id": "1710.06763", "contents": "Title: A complete characterization of optimal dictionaries for least squares\n  representation Abstract: Dictionaries are collections of vectors used for representations of elements\nin Euclidean spaces. While recent research on optimal dictionaries is focussed\non providing sparse (i.e., $\\ell_0$-optimal,) representations, here we consider\nthe problem of finding optimal dictionaries such that representations of\nsamples of a random vector are optimal in an $\\ell_2$-sense. For us, optimality\nof representation is equivalent to minimization of the average $\\ell_2$-norm of\nthe coefficients used to represent the random vector, with the lengths of the\ndictionary vectors being specified a priori. With the help of recent results on\nrank-$1$ decompositions of symmetric positive semidefinite matrices and the\ntheory of majorization, we provide a complete characterization of\n$\\ell_2$-optimal dictionaries. Our results are accompanied by polynomial time\nalgorithms that construct $\\ell_2$-optimal dictionaries from given data. \n\n"}
{"id": "1710.06940", "contents": "Title: Concept Drift Learning with Alternating Learners Abstract: Data-driven predictive analytics are in use today across a number of\nindustrial applications, but further integration is hindered by the requirement\nof similarity among model training and test data distributions. This paper\naddresses the need of learning from possibly nonstationary data streams, or\nunder concept drift, a commonly seen phenomenon in practical applications. A\nsimple dual-learner ensemble strategy, alternating learners framework, is\nproposed. A long-memory model learns stable concepts from a long relevant time\nwindow, while a short-memory model learns transient concepts from a small\nrecent window. The difference in prediction performance of these two models is\nmonitored and induces an alternating policy to select, update and reset the two\nmodels. The method features an online updating mechanism to maintain the\nensemble accuracy, and a concept-dependent trigger to focus on relevant data.\nThrough empirical studies the method demonstrates effective tracking and\nprediction when the steaming data carry abrupt and/or gradual changes. \n\n"}
{"id": "1710.06952", "contents": "Title: Asynchronous Decentralized Parallel Stochastic Gradient Descent Abstract: Most commonly used distributed machine learning systems are either\nsynchronous or centralized asynchronous. Synchronous algorithms like\nAllReduce-SGD perform poorly in a heterogeneous environment, while asynchronous\nalgorithms using a parameter server suffer from 1) communication bottleneck at\nparameter servers when workers are many, and 2) significantly worse convergence\nwhen the traffic to parameter server is congested. Can we design an algorithm\nthat is robust in a heterogeneous environment, while being communication\nefficient and maintaining the best-possible convergence rate? In this paper, we\npropose an asynchronous decentralized stochastic gradient decent algorithm\n(AD-PSGD) satisfying all above expectations. Our theoretical analysis shows\nAD-PSGD converges at the optimal $O(1/\\sqrt{K})$ rate as SGD and has linear\nspeedup w.r.t. number of workers. Empirically, AD-PSGD outperforms the best of\ndecentralized parallel SGD (D-PSGD), asynchronous parallel SGD (A-PSGD), and\nstandard data parallel SGD (AllReduce-SGD), often by orders of magnitude in a\nheterogeneous environment. When training ResNet-50 on ImageNet with up to 128\nGPUs, AD-PSGD converges (w.r.t epochs) similarly to the AllReduce-SGD, but each\nepoch can be up to 4-8X faster than its synchronous counterparts in a\nnetwork-sharing HPC environment. To the best of our knowledge, AD-PSGD is the\nfirst asynchronous algorithm that achieves a similar epoch-wise convergence\nrate as AllReduce-SGD, at an over 100-GPU scale. \n\n"}
{"id": "1710.06975", "contents": "Title: Consequentialist conditional cooperation in social dilemmas with\n  imperfect information Abstract: Social dilemmas, where mutual cooperation can lead to high payoffs but\nparticipants face incentives to cheat, are ubiquitous in multi-agent\ninteraction. We wish to construct agents that cooperate with pure cooperators,\navoid exploitation by pure defectors, and incentivize cooperation from the\nrest. However, often the actions taken by a partner are (partially) unobserved\nor the consequences of individual actions are hard to predict. We show that in\na large class of games good strategies can be constructed by conditioning one's\nbehavior solely on outcomes (ie. one's past rewards). We call this\nconsequentialist conditional cooperation. We show how to construct such\nstrategies using deep reinforcement learning techniques and demonstrate, both\nanalytically and experimentally, that they are effective in social dilemmas\nbeyond simple matrix games. We also show the limitations of relying purely on\nconsequences and discuss the need for understanding both the consequences of\nand the intentions behind an action. \n\n"}
{"id": "1710.07462", "contents": "Title: Tracking the gradients using the Hessian: A new look at variance\n  reducing stochastic methods Abstract: Our goal is to improve variance reducing stochastic methods through better\ncontrol variates. We first propose a modification of SVRG which uses the\nHessian to track gradients over time, rather than to recondition, increasing\nthe correlation of the control variates and leading to faster theoretical\nconvergence close to the optimum. We then propose accurate and computationally\nefficient approximations to the Hessian, both using a diagonal and a low-rank\nmatrix. Finally, we demonstrate the effectiveness of our method on a wide range\nof problems. \n\n"}
{"id": "1710.07735", "contents": "Title: ADA: A Game-Theoretic Perspective on Data Augmentation for Object\n  Detection Abstract: The use of random perturbations of ground truth data, such as random\ntranslation or scaling of bounding boxes, is a common heuristic used for data\naugmentation that has been shown to prevent overfitting and improve\ngeneralization. Since the design of data augmentation is largely guided by\nreported best practices, it is difficult to understand if those design choices\nare optimal. To provide a more principled perspective, we develop a\ngame-theoretic interpretation of data augmentation in the context of object\ndetection. We aim to find an optimal adversarial perturbations of the ground\ntruth data (i.e., the worst case perturbations) that forces the object bounding\nbox predictor to learn from the hardest distribution of perturbed examples for\nbetter test-time performance. We establish that the game theoretic solution,\nthe Nash equilibrium, provides both an optimal predictor and optimal data\naugmentation distribution. We show that our adversarial method of training a\npredictor can significantly improve test time performance for the task of\nobject detection. On the ImageNet object detection task, our adversarial\napproach improves performance by over 16\\% compared to the best performing data\naugmentation method \n\n"}
{"id": "1710.07746", "contents": "Title: Stochastic Backward Euler: An Implicit Gradient Descent Algorithm for\n  $k$-means Clustering Abstract: In this paper, we propose an implicit gradient descent algorithm for the\nclassic $k$-means problem. The implicit gradient step or backward Euler is\nsolved via stochastic fixed-point iteration, in which we randomly sample a\nmini-batch gradient in every iteration. It is the average of the fixed-point\ntrajectory that is carried over to the next gradient step. We draw connections\nbetween the proposed stochastic backward Euler and the recent entropy\nstochastic gradient descent (Entropy-SGD) for improving the training of deep\nneural networks. Numerical experiments on various synthetic and real datasets\nshow that the proposed algorithm provides better clustering results compared to\n$k$-means algorithms in the sense that it decreased the objective function (the\ncluster) and is much more robust to initialization. \n\n"}
{"id": "1710.08005", "contents": "Title: Smart \"Predict, then Optimize\" Abstract: Many real-world analytics problems involve two significant challenges:\nprediction and optimization. Due to the typically complex nature of each\nchallenge, the standard paradigm is predict-then-optimize. By and large,\nmachine learning tools are intended to minimize prediction error and do not\naccount for how the predictions will be used in the downstream optimization\nproblem. In contrast, we propose a new and very general framework, called Smart\n\"Predict, then Optimize\" (SPO), which directly leverages the optimization\nproblem structure, i.e., its objective and constraints, for designing better\nprediction models. A key component of our framework is the SPO loss function\nwhich measures the decision error induced by a prediction.\n  Training a prediction model with respect to the SPO loss is computationally\nchallenging, and thus we derive, using duality theory, a convex surrogate loss\nfunction which we call the SPO+ loss. Most importantly, we prove that the SPO+\nloss is statistically consistent with respect to the SPO loss under mild\nconditions. Our SPO+ loss function can tractably handle any polyhedral, convex,\nor even mixed-integer optimization problem with a linear objective. Numerical\nexperiments on shortest path and portfolio optimization problems show that the\nSPO framework can lead to significant improvement under the\npredict-then-optimize paradigm, in particular when the prediction model being\ntrained is misspecified. We find that linear models trained using SPO+ loss\ntend to dominate random forest algorithms, even when the ground truth is highly\nnonlinear. \n\n"}
{"id": "1710.09447", "contents": "Title: Stochastic Non-convex Optimization with Strong High Probability\n  Second-order Convergence Abstract: In this paper, we study stochastic non-convex optimization with non-convex\nrandom functions. Recent studies on non-convex optimization revolve around\nestablishing second-order convergence, i.e., converging to a nearly\nsecond-order optimal stationary points. However, existing results on stochastic\nnon-convex optimization are limited, especially with a high probability\nsecond-order convergence. We propose a novel updating step (named NCG-S) by\nleveraging a stochastic gradient and a noisy negative curvature of a stochastic\nHessian, where the stochastic gradient and Hessian are based on a proper\nmini-batch of random functions. Building on this step, we develop two\nalgorithms and establish their high probability second-order convergence. To\nthe best of our knowledge, the proposed stochastic algorithms are the first\nwith a second-order convergence in {\\it high probability} and a time complexity\nthat is {\\it almost linear} in the problem's dimensionality. \n\n"}
{"id": "1710.09805", "contents": "Title: Improving Negative Sampling for Word Representation using Self-embedded\n  Features Abstract: Although the word-popularity based negative sampler has shown superb\nperformance in the skip-gram model, the theoretical motivation behind\noversampling popular (non-observed) words as negative samples is still not well\nunderstood. In this paper, we start from an investigation of the gradient\nvanishing issue in the skipgram model without a proper negative sampler. By\nperforming an insightful analysis from the stochastic gradient descent (SGD)\nlearning perspective, we demonstrate that, both theoretically and intuitively,\nnegative samples with larger inner product scores are more informative than\nthose with lower scores for the SGD learner in terms of both convergence rate\nand accuracy. Understanding this, we propose an alternative sampling algorithm\nthat dynamically selects informative negative samples during each SGD update.\nMore importantly, the proposed sampler accounts for multi-dimensional\nself-embedded features during the sampling process, which essentially makes it\nmore effective than the original popularity-based (one-dimensional) sampler.\nEmpirical experiments further verify our observations, and show that our\nfine-grained samplers gain significant improvement over the existing ones\nwithout increasing computational complexity. \n\n"}
{"id": "1710.10016", "contents": "Title: Regularization via Mass Transportation Abstract: The goal of regression and classification methods in supervised learning is\nto minimize the empirical risk, that is, the expectation of some loss function\nquantifying the prediction error under the empirical distribution. When facing\nscarce training data, overfitting is typically mitigated by adding\nregularization terms to the objective that penalize hypothesis complexity. In\nthis paper we introduce new regularization techniques using ideas from\ndistributionally robust optimization, and we give new probabilistic\ninterpretations to existing techniques. Specifically, we propose to minimize\nthe worst-case expected loss, where the worst case is taken over the ball of\nall (continuous or discrete) distributions that have a bounded transportation\ndistance from the (discrete) empirical distribution. By choosing the radius of\nthis ball judiciously, we can guarantee that the worst-case expected loss\nprovides an upper confidence bound on the loss on test data, thus offering new\ngeneralization bounds. We prove that the resulting regularized learning\nproblems are tractable and can be tractably kernelized for many popular loss\nfunctions. We validate our theoretical out-of-sample guarantees through\nsimulated and empirical experiments. \n\n"}
{"id": "1710.10117", "contents": "Title: Reality-Aware Social Choice Abstract: Social Choice theory generalizes voting on one proposal to ranking multiple\nproposals. Yet, while a vote on a single proposal has the status quo (Reality)\nas a default, Reality has been forsaken during this generalization. Here, we\npropose to restore this default social state and to incorporate Reality\nexplicitly into Social Choice. We show that doing so gives rise to a new\ntheory, complete with its domain restrictions, voting rules with their\nReality-aware axiomatic properties, and certain game-theoretic aspects. In\nparticular, we show how Reality can be used in a principled way to break\nCondorcet cycles and develop an efficient Reality-aware Condorcet-consistent\nagenda. We then discuss several applications of Reality-Aware Social Choice. \n\n"}
{"id": "1710.10329", "contents": "Title: Lower Bounds for Higher-Order Convex Optimization Abstract: State-of-the-art methods in convex and non-convex optimization employ\nhigher-order derivative information, either implicitly or explicitly. We\nexplore the limitations of higher-order optimization and prove that even for\nconvex optimization, a polynomial dependence on the approximation guarantee and\nhigher-order smoothness parameters is necessary. As a special case, we show\nNesterov's accelerated cubic regularization method to be nearly tight. \n\n"}
{"id": "1710.10363", "contents": "Title: Diff-DAC: Distributed Actor-Critic for Average Multitask Deep\n  Reinforcement Learning Abstract: We propose a fully distributed actor-critic algorithm approximated by deep\nneural networks, named \\textit{Diff-DAC}, with application to single-task and\nto average multitask reinforcement learning (MRL). Each agent has access to\ndata from its local task only, but it aims to learn a policy that performs well\non average for the whole set of tasks. During the learning process, agents\ncommunicate their value-policy parameters to their neighbors, diffusing the\ninformation across the network, so that they converge to a common policy, with\nno need for a central node. The method is scalable, since the computational and\ncommunication costs per agent grow with its number of neighbors. We derive\nDiff-DAC's from duality theory and provide novel insights into the standard\nactor-critic framework, showing that it is actually an instance of the dual\nascent method that approximates the solution of a linear program. Experiments\nsuggest that Diff-DAC can outperform the single previous distributed MRL\napproach (i.e., Dist-MTLPS) and even the centralized architecture. \n\n"}
{"id": "1710.10595", "contents": "Title: Social Welfare Maximization Auction in Edge Computing Resource\n  Allocation for Mobile Blockchain Abstract: Blockchain, an emerging decentralized security system, has been applied in\nmany applications, such as bitcoin, smart grid, and Internet-of-Things.\nHowever, running the mining process may cost too much energy consumption and\ncomputing resource usage on handheld devices, which restricts the use of\nblockchain in mobile environments. In this paper, we consider deploying edge\ncomputing service to support the mobile blockchain. We propose an auction-based\nedge computing resource market of the edge computing service provider. Since\nthere is competition among miners, the allocative externalities (positive and\nnegative) are taken into account in the model. In our auction mechanism, we\nmaximize the social welfare while guaranteeing the truthfulness, individual\nrationality and computational efficiency. Based on blockchain mining experiment\nresults, we define a hash power function that characterizes the probability of\nsuccessfully mining a block. Through extensive simulations, we evaluate the\nperformance of our auction mechanism which shows that our edge computing\nresources market model can efficiently solve the social welfare maximization\nproblem for the edge computing service provider. \n\n"}
{"id": "1710.10737", "contents": "Title: Linearly convergent stochastic heavy ball method for minimizing\n  generalization error Abstract: In this work we establish the first linear convergence result for the\nstochastic heavy ball method. The method performs SGD steps with a fixed\nstepsize, amended by a heavy ball momentum term. In the analysis, we focus on\nminimizing the expected loss and not on finite-sum minimization, which is\ntypically a much harder problem. While in the analysis we constrain ourselves\nto quadratic loss, the overall objective is not necessarily strongly convex. \n\n"}
{"id": "1710.10753", "contents": "Title: Computational Social Choice and Computational Complexity: BFFs? Abstract: We discuss the connection between computational social choice (comsoc) and\ncomputational complexity. We stress the work so far on, and urge continued\nfocus on, two less-recognized aspects of this connection. Firstly, this is very\nmuch a two-way street: Everyone knows complexity classification is used in\ncomsoc, but we also highlight benefits to complexity that have arisen from its\nuse in comsoc. Secondly, more subtle, less-known complexity tools often can be\nvery productively used in comsoc. \n\n"}
{"id": "1710.10770", "contents": "Title: Riemannian Optimization via Frank-Wolfe Methods Abstract: We study projection-free methods for constrained Riemannian optimization. In\nparticular, we propose the Riemannian Frank-Wolfe (RFW) method. We analyze\nnon-asymptotic convergence rates of RFW to an optimum for (geodesically) convex\nproblems, and to a critical point for nonconvex objectives. We also present a\npractical setting under which RFW can attain a linear convergence rate. As a\nconcrete example, we specialize RFW to the manifold of positive definite\nmatrices and apply it to two tasks: (i) computing the matrix geometric mean\n(Riemannian centroid); and (ii) computing the Bures-Wasserstein barycenter.\nBoth tasks involve geodesically convex interval constraints, for which we show\nthat the Riemannian \"linear\" oracle required by RFW admits a closed-form\nsolution; this result may be of independent interest. We further specialize RFW\nto the special orthogonal group and show that here too, the Riemannian \"linear\"\noracle can be solved in closed form. Here, we describe an application to the\nsynchronization of data matrices (Procrustes problem). We complement our\ntheoretical results with an empirical comparison of RFW against\nstate-of-the-art Riemannian optimization methods and observe that RFW performs\ncompetitively on the task of computing Riemannian centroids. \n\n"}
{"id": "1710.10784", "contents": "Title: How deep learning works --The geometry of deep learning Abstract: Why and how that deep learning works well on different tasks remains a\nmystery from a theoretical perspective. In this paper we draw a geometric\npicture of the deep learning system by finding its analogies with two existing\ngeometric structures, the geometry of quantum computations and the geometry of\nthe diffeomorphic template matching. In this framework, we give the geometric\nstructures of different deep learning systems including convolutional neural\nnetworks, residual networks, recursive neural networks, recurrent neural\nnetworks and the equilibrium prapagation framework. We can also analysis the\nrelationship between the geometrical structures and their performance of\ndifferent networks in an algorithmic level so that the geometric framework may\nguide the design of the structures and algorithms of deep learning systems. \n\n"}
{"id": "1710.10793", "contents": "Title: Understanding GANs: the LQG Setting Abstract: Generative Adversarial Networks (GANs) have become a popular method to learn\na probability model from data. In this paper, we aim to provide an\nunderstanding of some of the basic issues surrounding GANs including their\nformulation, generalization and stability on a simple benchmark where the data\nhas a high-dimensional Gaussian distribution. Even in this simple benchmark,\nthe GAN problem has not been well-understood as we observe that existing\nstate-of-the-art GAN architectures may fail to learn a proper generative\ndistribution owing to (1) stability issues (i.e., convergence to bad local\nsolutions or not converging at all), (2) approximation issues (i.e., having\nimproper global GAN optimizers caused by inappropriate GAN's loss functions),\nand (3) generalizability issues (i.e., requiring large number of samples for\ntraining). In this setup, we propose a GAN architecture which recovers the\nmaximum-likelihood solution and demonstrates fast generalization. Moreover, we\nanalyze global stability of different computational approaches for the proposed\nGAN optimization and highlight their pros and cons. Finally, we outline an\nextension of our model-based approach to design GANs in more complex setups\nthan the considered Gaussian benchmark. \n\n"}
{"id": "1710.11272", "contents": "Title: Empirical analysis of non-linear activation functions for Deep Neural\n  Networks in classification tasks Abstract: We provide an overview of several non-linear activation functions in a neural\nnetwork architecture that have proven successful in many machine learning\napplications. We conduct an empirical analysis on the effectiveness of using\nthese function on the MNIST classification task, with the aim of clarifying\nwhich functions produce the best results overall. Based on this first set of\nresults, we examine the effects of building deeper architectures with an\nincreasing number of hidden layers. We also survey the impact of using, on the\nsame task, different initialisation schemes for the weights of our neural\nnetwork. Using these sets of experiments as a base, we conclude by providing a\noptimal neural network architecture that yields impressive results in accuracy\non the MNIST classification task. \n\n"}
{"id": "1710.11351", "contents": "Title: ChainerMN: Scalable Distributed Deep Learning Framework Abstract: One of the keys for deep learning to have made a breakthrough in various\nfields was to utilize high computing powers centering around GPUs. Enabling the\nuse of further computing abilities by distributed processing is essential not\nonly to make the deep learning bigger and faster but also to tackle unsolved\nchallenges. We present the design, implementation, and evaluation of ChainerMN,\nthe distributed deep learning framework we have developed. We demonstrate that\nChainerMN can scale the learning process of the ResNet-50 model to the ImageNet\ndataset up to 128 GPUs with the parallel efficiency of 90%. \n\n"}
{"id": "1710.11383", "contents": "Title: Flexible Prior Distributions for Deep Generative Models Abstract: We consider the problem of training generative models with deep neural\nnetworks as generators, i.e. to map latent codes to data points. Whereas the\ndominant paradigm combines simple priors over codes with complex deterministic\nmodels, we argue that it might be advantageous to use more flexible code\ndistributions. We demonstrate how these distributions can be induced directly\nfrom the data. The benefits include: more powerful generative models, better\nmodeling of latent structure and explicit control of the degree of\ngeneralization. \n\n"}
{"id": "1711.00832", "contents": "Title: A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning Abstract: To achieve general intelligence, agents must learn how to interact with\nothers in a shared environment: this is the challenge of multiagent\nreinforcement learning (MARL). The simplest form is independent reinforcement\nlearning (InRL), where each agent treats its experience as part of its\n(non-stationary) environment. In this paper, we first observe that policies\nlearned using InRL can overfit to the other agents' policies during training,\nfailing to sufficiently generalize during execution. We introduce a new metric,\njoint-policy correlation, to quantify this effect. We describe an algorithm for\ngeneral MARL, based on approximate best responses to mixtures of policies\ngenerated using deep reinforcement learning, and empirical game-theoretic\nanalysis to compute meta-strategies for policy selection. The algorithm\ngeneralizes previous ones such as InRL, iterated best response, double oracle,\nand fictitious play. Then, we present a scalable implementation which reduces\nthe memory requirement using decoupled meta-solvers. Finally, we demonstrate\nthe generality of the resulting policies in two partially observable settings:\ngridworld coordination games and poker. \n\n"}
{"id": "1711.01431", "contents": "Title: The Case for Meta-Cognitive Machine Learning: On Model Entropy and\n  Concept Formation in Deep Learning Abstract: Machine learning is usually defined in behaviourist terms, where external\nvalidation is the primary mechanism of learning. In this paper, I argue for a\nmore holistic interpretation in which finding more probable, efficient and\nabstract representations is as central to learning as performance. In other\nwords, machine learning should be extended with strategies to reason over its\nown learning process, leading to so-called meta-cognitive machine learning. As\nsuch, the de facto definition of machine learning should be reformulated in\nthese intrinsically multi-objective terms, taking into account not only the\ntask performance but also internal learning objectives. To this end, we suggest\na \"model entropy function\" to be defined that quantifies the efficiency of the\ninternal learning processes. It is conjured that the minimization of this model\nentropy leads to concept formation. Besides philosophical aspects, some initial\nillustrations are included to support the claims. \n\n"}
{"id": "1711.01569", "contents": "Title: Double Q($\\sigma$) and Q($\\sigma, \\lambda$): Unifying Reinforcement\n  Learning Control Algorithms Abstract: Temporal-difference (TD) learning is an important field in reinforcement\nlearning. Sarsa and Q-Learning are among the most used TD algorithms. The\nQ($\\sigma$) algorithm (Sutton and Barto (2017)) unifies both. This paper\nextends the Q($\\sigma$) algorithm to an online multi-step algorithm Q($\\sigma,\n\\lambda$) using eligibility traces and introduces Double Q($\\sigma$) as the\nextension of Q($\\sigma$) to double learning. Experiments suggest that the new\nQ($\\sigma, \\lambda$) algorithm can outperform the classical TD control methods\nSarsa($\\lambda$), Q($\\lambda$) and Q($\\sigma$). \n\n"}
{"id": "1711.01744", "contents": "Title: KGAN: How to Break The Minimax Game in GAN Abstract: Generative Adversarial Networks (GANs) were intuitively and attractively\nexplained under the perspective of game theory, wherein two involving parties\nare a discriminator and a generator. In this game, the task of the\ndiscriminator is to discriminate the real and generated (i.e., fake) data,\nwhilst the task of the generator is to generate the fake data that maximally\nconfuses the discriminator. In this paper, we propose a new viewpoint for GANs,\nwhich is termed as the minimizing general loss viewpoint. This viewpoint shows\na connection between the general loss of a classification problem regarding a\nconvex loss function and a f-divergence between the true and fake data\ndistributions. Mathematically, we proposed a setting for the classification\nproblem of the true and fake data, wherein we can prove that the general loss\nof this classification problem is exactly the negative f-divergence for a\ncertain convex function f. This allows us to interpret the problem of learning\nthe generator for dismissing the f-divergence between the true and fake data\ndistributions as that of maximizing the general loss which is equivalent to the\nmin-max problem in GAN if the Logistic loss is used in the classification\nproblem. However, this viewpoint strengthens GANs in two ways. First, it allows\nus to employ any convex loss function for the discriminator. Second, it\nsuggests that rather than limiting ourselves in NN-based discriminators, we can\nalternatively utilize other powerful families. Bearing this viewpoint, we then\npropose using the kernel-based family for discriminators. This family has two\nappealing features: i) a powerful capacity in classifying non-linear nature\ndata and ii) being convex in the feature space. Using the convexity of this\nfamily, we can further develop Fenchel duality to equivalently transform the\nmax-min problem to the max-max dual problem. \n\n"}
{"id": "1711.01754", "contents": "Title: Learning Solving Procedure for Artificial Neural Network Abstract: It is expected that progress toward true artificial intelligence will be\nachieved through the emergence of a system that integrates representation\nlearning and complex reasoning (LeCun et al. 2015). In response to this\nprediction, research has been conducted on implementing the symbolic reasoning\nof a von Neumann computer in an artificial neural network (Graves et al. 2016;\nGraves et al. 2014; Reed et al. 2015). However, these studies have many\nlimitations in realizing neural-symbolic integration (Jaeger. 2016). Here, we\npresent a new learning paradigm: a learning solving procedure (LSP) that learns\nthe procedure for solving complex problems. This is not accomplished merely by\nlearning input-output data, but by learning algorithms through a solving\nprocedure that obtains the output as a sequence of tasks for a given input\nproblem. The LSP neural network system not only learns simple problems of\naddition and multiplication, but also the algorithms of complicated problems,\nsuch as complex arithmetic expression, sorting, and Hanoi Tower. To realize\nthis, the LSP neural network structure consists of a deep neural network and\nlong short-term memory, which are recursively combined. Through\nexperimentation, we demonstrate the efficiency and scalability of LSP and its\nvalidity as a mechanism of complex reasoning. \n\n"}
{"id": "1711.01761", "contents": "Title: AdaBatch: Efficient Gradient Aggregation Rules for Sequential and\n  Parallel Stochastic Gradient Methods Abstract: We study a new aggregation operator for gradients coming from a mini-batch\nfor stochastic gradient (SG) methods that allows a significant speed-up in the\ncase of sparse optimization problems. We call this method AdaBatch and it only\nrequires a few lines of code change compared to regular mini-batch SGD\nalgorithms. We provide a theoretical insight to understand how this new class\nof algorithms is performing and show that it is equivalent to an implicit\nper-coordinate rescaling of the gradients, similarly to what Adagrad methods\ncan do. In theory and in practice, this new aggregation allows to keep the same\nsample efficiency of SG methods while increasing the batch size.\nExperimentally, we also show that in the case of smooth convex optimization,\nour procedure can even obtain a better loss when increasing the batch size for\na fixed number of samples. We then apply this new algorithm to obtain a\nparallelizable stochastic gradient method that is synchronous but allows\nspeed-up on par with Hogwild! methods as convergence does not deteriorate with\nthe increase of the batch size. The same approach can be used to make\nmini-batch provably efficient for variance-reduced SG methods such as SVRG. \n\n"}
{"id": "1711.02211", "contents": "Title: Social welfare and profit maximization from revealed preferences Abstract: Consider the seller's problem of finding optimal prices for her $n$\n(divisible) goods when faced with a set of $m$ consumers, given that she can\nonly observe their purchased bundles at posted prices, i.e., revealed\npreferences. We study both social welfare and profit maximization with revealed\npreferences. Although social welfare maximization is a seemingly non-convex\noptimization problem in prices, we show that (i) it can be reduced to a dual\nconvex optimization problem in prices, and (ii) the revealed preferences can be\ninterpreted as supergradients of the concave conjugate of valuation, with which\nsubgradients of the dual function can be computed. We thereby obtain a simple\nsubgradient-based algorithm for strongly concave valuations and convex cost,\nwith query complexity $O(m^2/\\epsilon^2)$, where $\\epsilon$ is the additive\ndifference between the social welfare induced by our algorithm and the optimum\nsocial welfare. We also study social welfare maximization under the online\nsetting, specifically the random permutation model, where consumers arrive\none-by-one in a random order. For the case where consumer valuations can be\narbitrary continuous functions, we propose a price posting mechanism that\nachieves an expected social welfare up to an additive factor of $O(\\sqrt{mn})$\nfrom the maximum social welfare. Finally, for profit maximization (which may be\nnon-convex in simple cases), we give nearly matching upper and lower bounds on\nthe query complexity for separable valuations and cost (i.e., each good can be\ntreated independently). \n\n"}
{"id": "1711.02844", "contents": "Title: Optimal Auction For Edge Computing Resource Management in Mobile\n  Blockchain Networks: A Deep Learning Approach Abstract: Blockchain has recently been applied in many applications such as bitcoin,\nsmart grid, and Internet of Things (IoT) as a public ledger of transactions.\nHowever, the use of blockchain in mobile environments is still limited because\nthe mining process consumes too much computing and energy resources on mobile\ndevices. Edge computing offered by the Edge Computing Service Provider can be\nadopted as a viable solution for offloading the mining tasks from the mobile\ndevices, i.e., miners, in the mobile blockchain environment. However, a\nmechanism needs to be designed for edge resource allocation to maximize the\nrevenue for the Edge Computing Service Provider and to ensure incentive\ncompatibility and individual rationality is still open. In this paper, we\ndevelop an optimal auction based on deep learning for the edge resource\nallocation. Specifically, we construct a multi-layer neural network\narchitecture based on an analytical solution of the optimal auction. The neural\nnetworks first perform monotone transformations of the miners' bids. Then, they\ncalculate allocation and conditional payment rules for the miners. We use\nvaluations of the miners as the data training to adjust parameters of the\nneural networks so as to optimize the loss function which is the expected,\nnegated revenue of the Edge Computing Service Provider. We show the\nexperimental results to confirm the benefits of using the deep learning for\nderiving the optimal auction for mobile blockchain with high revenue \n\n"}
{"id": "1711.03016", "contents": "Title: DLVM: A modern compiler infrastructure for deep learning systems Abstract: Deep learning software demands reliability and performance. However, many of\nthe existing deep learning frameworks are software libraries that act as an\nunsafe DSL in Python and a computation graph interpreter. We present DLVM, a\ndesign and implementation of a compiler infrastructure with a linear algebra\nintermediate representation, algorithmic differentiation by adjoint code\ngeneration, domain-specific optimizations and a code generator targeting GPU\nvia LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM\nis more modular and more generic than existing deep learning compiler\nframeworks, and supports tensor DSLs with high expressivity. With our\nprototypical staged DSL embedded in Swift, we argue that the DLVM system\nenables a form of modular, safe and performant frameworks for deep learning. \n\n"}
{"id": "1711.03404", "contents": "Title: A random matrix analysis and improvement of semi-supervised learning for\n  large dimensional data Abstract: This article provides an original understanding of the behavior of a class of\ngraph-oriented semi-supervised learning algorithms in the limit of large and\nnumerous data. It is demonstrated that the intuition at the root of these\nmethods collapses in this limit and that, as a result, most of them become\ninconsistent. Corrective measures and a new data-driven parametrization scheme\nare proposed along with a theoretical analysis of the asymptotic performances\nof the resulting approach. A surprisingly close behavior between theoretical\nperformances on Gaussian mixture models and on real datasets is also\nillustrated throughout the article, thereby suggesting the importance of the\nproposed analysis for dealing with practical data. As a result, significant\nperformance gains are observed on practical data classification using the\nproposed parametrization. \n\n"}
{"id": "1711.04066", "contents": "Title: Communication Complexity of Discrete Fair Division Abstract: We initiate the study of the communication complexity of fair division with\nindivisible goods. We focus on some of the most well-studied fairness notions\n(envy-freeness, proportionality, and approximations thereof) and valuation\nclasses (submodular, subadditive and unrestricted). Within these parameters,\nour results completely resolve whether the communication complexity of\ncomputing a fair allocation (or determining that none exist) is polynomial or\nexponential (in the number of goods), for every combination of fairness notion,\nvaluation class, and number of players, for both deterministic and randomized\nprotocols. \n\n"}
{"id": "1711.04291", "contents": "Title: Scale out for large minibatch SGD: Residual network training on\n  ImageNet-1K with improved accuracy and reduced time to train Abstract: For the past 5 years, the ILSVRC competition and the ImageNet dataset have\nattracted a lot of interest from the Computer Vision community, allowing for\nstate-of-the-art accuracy to grow tremendously. This should be credited to the\nuse of deep artificial neural network designs. As these became more complex,\nthe storage, bandwidth, and compute requirements increased. This means that\nwith a non-distributed approach, even when using the most high-density server\navailable, the training process may take weeks, making it prohibitive.\nFurthermore, as datasets grow, the representation learning potential of deep\nnetworks grows as well by using more complex models. This synchronicity\ntriggers a sharp increase in the computational requirements and motivates us to\nexplore the scaling behaviour on petaflop scale supercomputers. In this paper\nwe will describe the challenges and novel solutions needed in order to train\nResNet-50 in this large scale environment. We demonstrate above 90\\% scaling\nefficiency and a training time of 28 minutes using up to 104K x86 cores. This\nis supported by software tools from Intel's ecosystem. Moreover, we show that\nwith regular 90 - 120 epoch train runs we can achieve a top-1 accuracy as high\nas 77\\% for the unmodified ResNet-50 topology. We also introduce the novel\nCollapsed Ensemble (CE) technique that allows us to obtain a 77.5\\% top-1\naccuracy, similar to that of a ResNet-152, while training a unmodified\nResNet-50 topology for the same fixed training budget. All ResNet-50 models as\nwell as the scripts needed to replicate them will be posted shortly. \n\n"}
{"id": "1711.05225", "contents": "Title: CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep\n  Learning Abstract: We develop an algorithm that can detect pneumonia from chest X-rays at a\nlevel exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer\nconvolutional neural network trained on ChestX-ray14, currently the largest\npublicly available chest X-ray dataset, containing over 100,000 frontal-view\nX-ray images with 14 diseases. Four practicing academic radiologists annotate a\ntest set, on which we compare the performance of CheXNet to that of\nradiologists. We find that CheXNet exceeds average radiologist performance on\nthe F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and\nachieve state of the art results on all 14 diseases. \n\n"}
{"id": "1711.05305", "contents": "Title: An Accelerated Communication-Efficient Primal-Dual Optimization\n  Framework for Structured Machine Learning Abstract: Distributed optimization algorithms are essential for training machine\nlearning models on very large-scale datasets. However, they often suffer from\ncommunication bottlenecks. Confronting this issue, a communication-efficient\nprimal-dual coordinate ascent framework (CoCoA) and its improved variant CoCoA+\nhave been proposed, achieving a convergence rate of $\\mathcal{O}(1/t)$ for\nsolving empirical risk minimization problems with Lipschitz continuous losses.\nIn this paper, an accelerated variant of CoCoA+ is proposed and shown to\npossess a convergence rate of $\\mathcal{O}(1/t^2)$ in terms of reducing\nsuboptimality. The analysis of this rate is also notable in that the\nconvergence rate bounds involve constants that, except in extreme cases, are\nsignificantly reduced compared to those previously provided for CoCoA+. The\nresults of numerical experiments are provided to show that acceleration can\nlead to significant performance gains. \n\n"}
{"id": "1711.05828", "contents": "Title: BoostJet: Towards Combining Statistical Aggregates with Neural\n  Embeddings for Recommendations Abstract: Recommenders have become widely popular in recent years because of their\nbroader applicability in many e-commerce applications. These applications rely\non recommenders for generating advertisements for various offers or providing\ncontent recommendations. However, the quality of the generated recommendations\ndepends on user features (like demography, temporality), offer features (like\npopularity, price), and user-offer features (like implicit or explicit\nfeedback). Current state-of-the-art recommenders do not explore such diverse\nfeatures concurrently while generating the recommendations.\n  In this paper, we first introduce the notion of Trackers which enables us to\ncapture the above-mentioned features and thus incorporate users' online\nbehaviour through statistical aggregates of different features (demography,\ntemporality, popularity, price). We also show how to capture offer-to-offer\nrelations, based on their consumption sequence, leveraging neural embeddings\nfor offers in our Offer2Vec algorithm. We then introduce BoostJet, a novel\nrecommender which integrates the Trackers along with the neural embeddings\nusing MatrixNet, an efficient distributed implementation of gradient boosted\ndecision tree, to improve the recommendation quality significantly. We provide\nan in-depth evaluation of BoostJet on Yandex's dataset, collecting online\nbehaviour from tens of millions of online users, to demonstrate the\npracticality of BoostJet in terms of recommendation quality as well as\nscalability. \n\n"}
{"id": "1711.07033", "contents": "Title: Decentralized High-Dimensional Bayesian Optimization with Factor Graphs Abstract: This paper presents a novel decentralized high-dimensional Bayesian\noptimization (DEC-HBO) algorithm that, in contrast to existing HBO algorithms,\ncan exploit the interdependent effects of various input components on the\noutput of the unknown objective function f for boosting the BO performance and\nstill preserve scalability in the number of input dimensions without requiring\nprior knowledge or the existence of a low (effective) dimension of the input\nspace. To realize this, we propose a sparse yet rich factor graph\nrepresentation of f to be exploited for designing an acquisition function that\ncan be similarly represented by a sparse factor graph and hence be efficiently\noptimized in a decentralized manner using distributed message passing. Despite\nrichly characterizing the interdependent effects of the input components on the\noutput of f with a factor graph, DEC-HBO can still guarantee no-regret\nperformance asymptotically. Empirical evaluation on synthetic and real-world\nexperiments (e.g., sparse Gaussian process model with 1811 hyperparameters)\nshows that DEC-HBO outperforms the state-of-the-art HBO algorithms. \n\n"}
{"id": "1711.07059", "contents": "Title: Morphisms of open games Abstract: We define a notion of morphisms between open games, exploiting a surprising\nconnection between lenses in computer science and compositional game theory.\nThis extends the more intuitively obvious definition of globular morphisms as\nmappings between strategy profiles that preserve best responses, and hence in\nparticular preserve Nash equilibria. We construct a symmetric monoidal double\ncategory in which the horizontal 1-cells are open games, vertical 1-morphisms\nare lenses, and 2-cells are morphisms of open games. States (morphisms out of\nthe monoidal unit) in the vertical category give a flexible solution concept\nthat includes both Nash and subgame perfect equilibria. Products in the\nvertical category give an external choice operator that is reminiscent of\nproducts in game semantics, and is useful in practical examples. We illustrate\nthe above two features with a simple worked example from microeconomics, the\nmarket entry game. \n\n"}
{"id": "1711.08172", "contents": "Title: Run-and-Inspect Method for Nonconvex Optimization and Global Optimality\n  Bounds for R-Local Minimizers Abstract: Many optimization algorithms converge to stationary points. When the\nunderlying problem is nonconvex, they may get trapped at local minimizers and\noccasionally stagnate near saddle points. We propose the Run-and-Inspect\nMethod, which adds an \"inspect\" phase to existing algorithms that helps escape\nfrom non-global stationary points. The inspection samples a set of points in a\nradius $R$ around the current point. When a sample point yields a sufficient\ndecrease in the objective, we move there and resume an existing algorithm. If\nno sufficient decrease is found, the current point is called an approximate\n$R$-local minimizer. We show that an $R$-local minimizer is globally optimal,\nup to a specific error depending on $R$, if the objective function can be\nimplicitly decomposed into a smooth convex function plus a restricted function\nthat is possibly nonconvex, nonsmooth. For high-dimensional problems, we\nintroduce blockwise inspections to overcome the curse of dimensionality while\nstill maintaining optimality bounds up to a factor equal to the number of\nblocks. Our method performs well on a set of artificial and realistic nonconvex\nproblems by coupling with gradient descent, coordinate descent, EM, and\nprox-linear algorithms. \n\n"}
{"id": "1711.08277", "contents": "Title: Few-shot Learning by Exploiting Visual Concepts within CNNs Abstract: Convolutional neural networks (CNNs) are one of the driving forces for the\nadvancement of computer vision. Despite their promising performances on many\ntasks, CNNs still face major obstacles on the road to achieving ideal machine\nintelligence. One is that CNNs are complex and hard to interpret. Another is\nthat standard CNNs require large amounts of annotated data, which is sometimes\nhard to obtain, and it is desirable to learn to recognize objects from few\nexamples. In this work, we address these limitations of CNNs by developing\nnovel, flexible, and interpretable models for few-shot learning. Our models are\nbased on the idea of encoding objects in terms of visual concepts (VCs), which\nare interpretable visual cues represented by the feature vectors within CNNs.\nWe first adapt the learning of VCs to the few-shot setting, and then uncover\ntwo key properties of feature encoding using VCs, which we call category\nsensitivity and spatial pattern. Motivated by these properties, we present two\nintuitive models for the problem of few-shot learning. Experiments show that\nour models achieve competitive performances, while being more flexible and\ninterpretable than alternative state-of-the-art few-shot learning methods. We\nconclude that using VCs helps expose the natural capability of CNNs for\nfew-shot learning. \n\n"}
{"id": "1711.08477", "contents": "Title: Benchmarking Relief-Based Feature Selection Methods for Bioinformatics\n  Data Mining Abstract: Modern biomedical data mining requires feature selection methods that can (1)\nbe applied to large scale feature spaces (e.g. `omics' data), (2) function in\nnoisy problems, (3) detect complex patterns of association (e.g. gene-gene\ninteractions), (4) be flexibly adapted to various problem domains and data\ntypes (e.g. genetic variants, gene expression, and clinical data) and (5) are\ncomputationally tractable. To that end, this work examines a set of\nfilter-style feature selection algorithms inspired by the `Relief' algorithm,\ni.e. Relief-Based algorithms (RBAs). We implement and expand these RBAs in an\nopen source framework called ReBATE (Relief-Based Algorithm Training\nEnvironment). We apply a comprehensive genetic simulation study comparing\nexisting RBAs, a proposed RBA called MultiSURF, and other established feature\nselection methods, over a variety of problems. The results of this study (1)\nsupport the assertion that RBAs are particularly flexible, efficient, and\npowerful feature selection methods that differentiate relevant features having\nunivariate, multivariate, epistatic, or heterogeneous associations, (2) confirm\nthe efficacy of expansions for classification vs. regression, discrete vs.\ncontinuous features, missing data, multiple classes, or class imbalance, (3)\nidentify previously unknown limitations of specific RBAs, and (4) suggest that\nwhile MultiSURF* performs best for explicitly identifying pure 2-way\ninteractions, MultiSURF yields the most reliable feature selection performance\nacross a wide range of problem types. \n\n"}
{"id": "1711.09576", "contents": "Title: Extracting Automata from Recurrent Neural Networks Using Queries and\n  Counterexamples Abstract: We present a novel algorithm that uses exact learning and abstraction to\nextract a deterministic finite automaton describing the state dynamics of a\ngiven trained RNN. We do this using Angluin's L* algorithm as a learner and the\ntrained RNN as an oracle. Our technique efficiently extracts accurate automata\nfrom trained RNNs, even when the state vectors are large and require fine\ndifferentiation. \n\n"}
{"id": "1711.10168", "contents": "Title: Semi-supervised learning of hierarchical representations of molecules\n  using neural message passing Abstract: With the rapid increase of compound databases available in medicinal and\nmaterial science, there is a growing need for learning representations of\nmolecules in a semi-supervised manner. In this paper, we propose an\nunsupervised hierarchical feature extraction algorithm for molecules (or more\ngenerally, graph-structured objects with fixed number of types of nodes and\nedges), which is applicable to both unsupervised and semi-supervised tasks. Our\nmethod extends recently proposed Paragraph Vector algorithm and incorporates\nneural message passing to obtain hierarchical representations of subgraphs. We\napplied our method to an unsupervised task and demonstrated that it outperforms\nexisting proposed methods in several benchmark datasets. We also experimentally\nshowed that semi-supervised tasks enhanced predictive performance compared with\nsupervised ones with labeled molecules only. \n\n"}
{"id": "1711.10589", "contents": "Title: Contextual Outlier Interpretation Abstract: Outlier detection plays an essential role in many data-driven applications to\nidentify isolated instances that are different from the majority. While many\nstatistical learning and data mining techniques have been used for developing\nmore effective outlier detection algorithms, the interpretation of detected\noutliers does not receive much attention. Interpretation is becoming\nincreasingly important to help people trust and evaluate the developed models\nthrough providing intrinsic reasons why the certain outliers are chosen. It is\ndifficult, if not impossible, to simply apply feature selection for explaining\noutliers due to the distinct characteristics of various detection models,\ncomplicated structures of data in certain applications, and imbalanced\ndistribution of outliers and normal instances. In addition, the role of\ncontrastive contexts where outliers locate, as well as the relation between\noutliers and contexts, are usually overlooked in interpretation. To tackle the\nissues above, in this paper, we propose a novel Contextual Outlier\nINterpretation (COIN) method to explain the abnormality of existing outliers\nspotted by detectors. The interpretability for an outlier is achieved from\nthree aspects: outlierness score, attributes that contribute to the\nabnormality, and contextual description of its neighborhoods. Experimental\nresults on various types of datasets demonstrate the flexibility and\neffectiveness of the proposed framework compared with existing interpretation\napproaches. \n\n"}
{"id": "1711.10856", "contents": "Title: Semi-Supervised and Active Few-Shot Learning with Prototypical Networks Abstract: We consider the problem of semi-supervised few-shot classification where a\nclassifier needs to adapt to new tasks using a few labeled examples and\n(potentially many) unlabeled examples. We propose a clustering approach to the\nproblem. The features extracted with Prototypical Networks are clustered using\n$K$-means with the few labeled examples guiding the clustering process. We note\nthat in many real-world applications the adaptation performance can be\nsignificantly improved by requesting the few labels through user feedback. We\ndemonstrate good performance of the active adaptation strategy using image\ndata. \n\n"}
{"id": "1712.00004", "contents": "Title: Learnings Options End-to-End for Continuous Action Tasks Abstract: We present new results on learning temporally extended actions for\ncontinuoustasks, using the options framework (Suttonet al.[1999b], Precup\n[2000]). In orderto achieve this goal we work with the option-critic\narchitecture (Baconet al.[2017])using a deliberation cost and train it with\nproximal policy optimization (Schulmanet al.[2017]) instead of vanilla policy\ngradient. Results on Mujoco domains arepromising, but lead to interesting\nquestions aboutwhena given option should beused, an issue directly connected to\nthe use of initiation sets. \n\n"}
{"id": "1712.00378", "contents": "Title: Time Limits in Reinforcement Learning Abstract: In reinforcement learning, it is common to let an agent interact for a fixed\namount of time with its environment before resetting it and repeating the\nprocess in a series of episodes. The task that the agent has to learn can\neither be to maximize its performance over (i) that fixed period, or (ii) an\nindefinite period where time limits are only used during training to diversify\nexperience. In this paper, we provide a formal account for how time limits\ncould effectively be handled in each of the two cases and explain why not doing\nso can cause state aliasing and invalidation of experience replay, leading to\nsuboptimal policies and training instability. In case (i), we argue that the\nterminations due to time limits are in fact part of the environment, and thus a\nnotion of the remaining time should be included as part of the agent's input to\navoid violation of the Markov property. In case (ii), the time limits are not\npart of the environment and are only used to facilitate learning. We argue that\nthis insight should be incorporated by bootstrapping from the value of the\nstate at the end of each partial episode. For both cases, we illustrate\nempirically the significance of our considerations in improving the performance\nand stability of existing reinforcement learning algorithms, showing\nstate-of-the-art results on several control tasks. \n\n"}
{"id": "1712.00912", "contents": "Title: Deep Learning Diffuse Optical Tomography Abstract: Diffuse optical tomography (DOT) has been investigated as an alternative\nimaging modality for breast cancer detection thanks to its excellent contrast\nto hemoglobin oxidization level. However, due to the complicated non-linear\nphoton scattering physics and ill-posedness, the conventional reconstruction\nalgorithms are sensitive to imaging parameters such as boundary conditions. To\naddress this, here we propose a novel deep learning approach that learns\nnon-linear photon scattering physics and obtains an accurate three dimensional\n(3D) distribution of optical anomalies. In contrast to the traditional\nblack-box deep learning approaches, our deep network is designed to invert the\nLippman-Schwinger integral equation using the recent mathematical theory of\ndeep convolutional framelets. As an example of clinical relevance, we applied\nthe method to our prototype DOT system. We show that our deep neural network,\ntrained with only simulation data, can accurately recover the location of\nanomalies within biomimetic phantoms and live animals without the use of an\nexogenous contrast agent. \n\n"}
{"id": "1712.03141", "contents": "Title: Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning Abstract: Learning-based pattern classifiers, including deep networks, have shown\nimpressive performance in several application domains, ranging from computer\nvision to cybersecurity. However, it has also been shown that adversarial input\nperturbations carefully crafted either at training or at test time can easily\nsubvert their predictions. The vulnerability of machine learning to such wild\npatterns (also referred to as adversarial examples), along with the design of\nsuitable countermeasures, have been investigated in the research field of\nadversarial machine learning. In this work, we provide a thorough overview of\nthe evolution of this research area over the last ten years and beyond,\nstarting from pioneering, earlier work on the security of non-deep learning\nalgorithms up to more recent work aimed to understand the security properties\nof deep learning algorithms, in the context of computer vision and\ncybersecurity tasks. We report interesting connections between these\napparently-different lines of work, highlighting common misconceptions related\nto the security evaluation of machine-learning algorithms. We review the main\nthreat models and attacks defined to this end, and discuss the main limitations\nof current work, along with the corresponding future challenges towards the\ndesign of more secure learning algorithms. \n\n"}
{"id": "1712.03298", "contents": "Title: Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural\n  Networks Abstract: Progress in deep learning is slowed by the days or weeks it takes to train\nlarge models. The natural solution of using more hardware is limited by\ndiminishing returns, and leads to inefficient use of additional resources. In\nthis paper, we present a large batch, stochastic optimization algorithm that is\nboth faster than widely used algorithms for fixed amounts of computation, and\nalso scales up substantially better as more computational resources become\navailable. Our algorithm implicitly computes the inverse Hessian of each\nmini-batch to produce descent directions; we do so without either an explicit\napproximation to the Hessian or Hessian-vector products. We demonstrate the\neffectiveness of our algorithm by successfully training large ImageNet models\n(Inception-V3, Resnet-50, Resnet-101 and Inception-Resnet-V2) with mini-batch\nsizes of up to 32000 with no loss in validation error relative to current\nbaselines, and no increase in the total number of steps. At smaller mini-batch\nsizes, our optimizer improves the validation error in these models by 0.8-0.9%.\nAlternatively, we can trade off this accuracy to reduce the number of training\nsteps needed by roughly 10-30%. Our work is practical and easily usable by\nothers -- only one hyperparameter (learning rate) needs tuning, and\nfurthermore, the algorithm is as computationally cheap as the commonly used\nAdam optimizer. \n\n"}
{"id": "1712.03999", "contents": "Title: Eye In-Painting with Exemplar Generative Adversarial Networks Abstract: This paper introduces a novel approach to in-painting where the identity of\nthe object to remove or change is preserved and accounted for at inference\ntime: Exemplar GANs (ExGANs). ExGANs are a type of conditional GAN that utilize\nexemplar information to produce high-quality, personalized in painting results.\nWe propose using exemplar information in the form of a reference image of the\nregion to in-paint, or a perceptual code describing that object. Unlike\nprevious conditional GAN formulations, this extra information can be inserted\nat multiple points within the adversarial network, thus increasing its\ndescriptive power. We show that ExGANs can produce photo-realistic personalized\nin-painting results that are both perceptually and semantically plausible by\napplying them to the task of closed to-open eye in-painting in natural\npictures. A new benchmark dataset is also introduced for the task of eye\nin-painting for future comparisons. \n\n"}
{"id": "1712.04104", "contents": "Title: Convergence Rates for Deterministic and Stochastic Subgradient Methods\n  Without Lipschitz Continuity Abstract: We extend the classic convergence rate theory for subgradient methods to\napply to non-Lipschitz functions. For the deterministic projected subgradient\nmethod, we present a global $O(1/\\sqrt{T})$ convergence rate for any convex\nfunction which is locally Lipschitz around its minimizers. This approach is\nbased on Shor's classic subgradient analysis and implies generalizations of the\nstandard convergence rates for gradient descent on functions with Lipschitz or\nH\\\"older continuous gradients. Further, we show a $O(1/\\sqrt{T})$ convergence\nrate for the stochastic projected subgradient method on convex functions with\nat most quadratic growth, which improves to $O(1/T)$ under either strong\nconvexity or a weaker quadratic lower bound condition. \n\n"}
{"id": "1712.05134", "contents": "Title: Learning Compact Recurrent Neural Networks with Block-Term Tensor\n  Decomposition Abstract: Recurrent Neural Networks (RNNs) are powerful sequence modeling tools.\nHowever, when dealing with high dimensional inputs, the training of RNNs\nbecomes computational expensive due to the large number of model parameters.\nThis hinders RNNs from solving many important computer vision tasks, such as\nAction Recognition in Videos and Image Captioning. To overcome this problem, we\npropose a compact and flexible structure, namely Block-Term tensor\ndecomposition, which greatly reduces the parameters of RNNs and improves their\ntraining efficiency. Compared with alternative low-rank approximations, such as\ntensor-train RNN (TT-RNN), our method, Block-Term RNN (BT-RNN), is not only\nmore concise (when using the same rank), but also able to attain a better\napproximation to the original RNNs with much fewer parameters. On three\nchallenging tasks, including Action Recognition in Videos, Image Captioning and\nImage Generation, BT-RNN outperforms TT-RNN and the standard RNN in terms of\nboth prediction accuracy and convergence rate. Specifically, BT-LSTM utilizes\n17,388 times fewer parameters than the standard LSTM to achieve an accuracy\nimprovement over 15.6\\% in the Action Recognition task on the UCF11 dataset. \n\n"}
{"id": "1712.05902", "contents": "Title: NSML: A Machine Learning Platform That Enables You to Focus on Your\n  Models Abstract: Machine learning libraries such as TensorFlow and PyTorch simplify model\nimplementation. However, researchers are still required to perform a\nnon-trivial amount of manual tasks such as GPU allocation, training status\ntracking, and comparison of models with different hyperparameter settings. We\npropose a system to handle these tasks and help researchers focus on models. We\npresent the requirements of the system based on a collection of discussions\nfrom an online study group comprising 25k members. These include automatic GPU\nallocation, learning status visualization, handling model parameter snapshots\nas well as hyperparameter modification during learning, and comparison of\nperformance metrics between models via a leaderboard. We describe the system\narchitecture that fulfills these requirements and present a proof-of-concept\nimplementation, NAVER Smart Machine Learning (NSML). We test the system and\nconfirm substantial efficiency improvements for model development. \n\n"}
{"id": "1712.06585", "contents": "Title: Third-order Smoothness Helps: Even Faster Stochastic Optimization\n  Algorithms for Finding Local Minima Abstract: We propose stochastic optimization algorithms that can find local minima\nfaster than existing algorithms for nonconvex optimization problems, by\nexploiting the third-order smoothness to escape non-degenerate saddle points\nmore efficiently. More specifically, the proposed algorithm only needs\n$\\tilde{O}(\\epsilon^{-10/3})$ stochastic gradient evaluations to converge to an\napproximate local minimum $\\mathbf{x}$, which satisfies $\\|\\nabla\nf(\\mathbf{x})\\|_2\\leq\\epsilon$ and $\\lambda_{\\min}(\\nabla^2 f(\\mathbf{x}))\\geq\n-\\sqrt{\\epsilon}$ in the general stochastic optimization setting, where\n$\\tilde{O}(\\cdot)$ hides logarithm polynomial terms and constants. This\nimproves upon the $\\tilde{O}(\\epsilon^{-7/2})$ gradient complexity achieved by\nthe state-of-the-art stochastic local minima finding algorithms by a factor of\n$\\tilde{O}(\\epsilon^{-1/6})$. For nonconvex finite-sum optimization, our\nalgorithm also outperforms the best known algorithms in a certain regime. \n\n"}
{"id": "1712.07027", "contents": "Title: Snake: a Stochastic Proximal Gradient Algorithm for Regularized Problems\n  over Large Graphs Abstract: A regularized optimization problem over a large unstructured graph is\nstudied, where the regularization term is tied to the graph geometry. Typical\nregularization examples include the total variation and the Laplacian\nregularizations over the graph. When applying the proximal gradient algorithm\nto solve this problem, there exist quite affordable methods to implement the\nproximity operator (backward step) in the special case where the graph is a\nsimple path without loops. In this paper, an algorithm, referred to as \"Snake\",\nis proposed to solve such regularized problems over general graphs, by taking\nbenefit of these fast methods. The algorithm consists in properly selecting\nrandom simple paths in the graph and performing the proximal gradient algorithm\nover these simple paths. This algorithm is an instance of a new general\nstochastic proximal gradient algorithm, whose convergence is proven.\nApplications to trend filtering and graph inpainting are provided among others.\nNumerical experiments are conducted over large graphs. \n\n"}
{"id": "1712.07106", "contents": "Title: Exploring High-Dimensional Structure via Axis-Aligned Decomposition of\n  Linear Projections Abstract: Two-dimensional embeddings remain the dominant approach to visualize high\ndimensional data. The choice of embeddings ranges from highly non-linear ones,\nwhich can capture complex relationships but are difficult to interpret\nquantitatively, to axis-aligned projections, which are easy to interpret but\nare limited to bivariate relationships. Linear project can be considered as a\ncompromise between complexity and interpretability, as they allow explicit axes\nlabels, yet provide significantly more degrees of freedom compared to\naxis-aligned projections. Nevertheless, interpreting the axes directions, which\nare linear combinations often with many non-trivial components, remains\ndifficult. To address this problem we introduce a structure aware decomposition\nof (multiple) linear projections into sparse sets of axis aligned projections,\nwhich jointly capture all information of the original linear ones. In\nparticular, we use tools from Dempster-Shafer theory to formally define how\nrelevant a given axis aligned project is to explain the neighborhood relations\ndisplayed in some linear projection. Furthermore, we introduce a new approach\nto discover a diverse set of high quality linear projections and show that in\npractice the information of $k$ linear projections is often jointly encoded in\n$\\sim k$ axis aligned plots. We have integrated these ideas into an interactive\nvisualization system that allows users to jointly browse both linear\nprojections and their axis aligned representatives. Using a number of case\nstudies we show how the resulting plots lead to more intuitive visualizations\nand new insight. \n\n"}
{"id": "1712.08091", "contents": "Title: Multiview Deep Learning for Predicting Twitter Users' Location Abstract: The problem of predicting the location of users on large social networks like\nTwitter has emerged from real-life applications such as social unrest detection\nand online marketing. Twitter user geolocation is a difficult and active\nresearch topic with a vast literature. Most of the proposed methods follow\neither a content-based or a network-based approach. The former exploits\nuser-generated content while the latter utilizes the connection or interaction\nbetween Twitter users. In this paper, we introduce a novel method combining the\nstrength of both approaches. Concretely, we propose a multi-entry neural\nnetwork architecture named MENET leveraging the advances in deep learning and\nmultiview learning. The generalizability of MENET enables the integration of\nmultiple data representations. In the context of Twitter user geolocation, we\nrealize MENET with textual, network, and metadata features. Considering the\nnatural distribution of Twitter users across the concerned geographical area,\nwe subdivide the surface of the earth into multi-scale cells and train MENET\nwith the labels of the cells. We show that our method outperforms the state of\nthe art by a large margin on three benchmark datasets. \n\n"}
{"id": "1712.08160", "contents": "Title: Combining Static and Dynamic Features for Multivariate Sequence\n  Classification Abstract: Model precision in a classification task is highly dependent on the feature\nspace that is used to train the model. Moreover, whether the features are\nsequential or static will dictate which classification method can be applied as\nmost of the machine learning algorithms are designed to deal with either one or\nanother type of data. In real-life scenarios, however, it is often the case\nthat both static and dynamic features are present, or can be extracted from the\ndata. In this work, we demonstrate how generative models such as Hidden Markov\nModels (HMM) and Long Short-Term Memory (LSTM) artificial neural networks can\nbe used to extract temporal information from the dynamic data. We explore how\nthe extracted information can be combined with the static features in order to\nimprove the classification performance. We evaluate the existing techniques and\nsuggest a hybrid approach, which outperforms other methods on several public\ndatasets. \n\n"}
{"id": "1712.08523", "contents": "Title: Contemporary machine learning: a guide for practitioners in the physical\n  sciences Abstract: Machine learning is finding increasingly broad application in the physical\nsciences. This most often involves building a model relationship between a\ndependent, measurable output and an associated set of controllable, but\ncomplicated, independent inputs. We present a tutorial on current techniques in\nmachine learning -- a jumping-off point for interested researchers to advance\ntheir work. We focus on deep neural networks with an emphasis on demystifying\ndeep learning. We begin with background ideas in machine learning and some\nexample applications from current research in plasma physics. We discuss\nsupervised learning techniques for modeling complicated functions, beginning\nwith familiar regression schemes, then advancing to more sophisticated deep\nlearning methods. We also address unsupervised learning and techniques for\nreducing the dimensionality of input spaces. Along the way, we describe methods\nfor practitioners to help ensure that their models generalize from their\ntraining data to as-yet-unseen test data. We describe classes of tasks --\npredicting scalars, handling images, fitting time-series -- and prepare the\nreader to choose an appropriate technique. We finally point out some\nlimitations to modern machine learning and speculate on some ways that\npractitioners from the physical sciences may be particularly suited to help. \n\n"}
{"id": "1712.08713", "contents": "Title: Query-limited Black-box Attacks to Classifiers Abstract: We study black-box attacks on machine learning classifiers where each query\nto the model incurs some cost or risk of detection to the adversary. We focus\nexplicitly on minimizing the number of queries as a major objective.\nSpecifically, we consider the problem of attacking machine learning classifiers\nsubject to a budget of feature modification cost while minimizing the number of\nqueries, where each query returns only a class and confidence score. We\ndescribe an approach that uses Bayesian optimization to minimize the number of\nqueries, and find that the number of queries can be reduced to approximately\none tenth of the number needed through a random strategy for scenarios where\nthe feature modification cost budget is low. \n\n"}
{"id": "1801.02042", "contents": "Title: Learning from Neighbors about a Changing State Abstract: Agents learn about a changing state using private signals and their\nneighbors' past estimates of the state. We present a model in which Bayesian\nagents in equilibrium use neighbors' estimates simply by taking weighted sums\nwith time-invariant weights. The dynamics thus parallel those of the tractable\nDeGroot model of learning in networks, but arise as an equilibrium outcome\nrather than a behavioral assumption. We examine whether information aggregation\nis nearly optimal as neighborhoods grow large. A key condition for this is\nsignal diversity: each individual's neighbors have private signals that not\nonly contain independent information, but also have sufficiently different\ndistributions. Without signal diversity $\\unicode{x2013}$ e.g., if private\nsignals are i.i.d. $\\unicode{x2013}$ learning is suboptimal in all networks and\nhighly inefficient in some. Turning to social influence, we find it is much\nmore sensitive to one's signal quality than to one's number of neighbors, in\ncontrast to standard models with exogenous updating rules. \n\n"}
{"id": "1801.03749", "contents": "Title: Improved asynchronous parallel optimization analysis for stochastic\n  incremental methods Abstract: As datasets continue to increase in size and multi-core computer\narchitectures are developed, asynchronous parallel optimization algorithms\nbecome more and more essential to the field of Machine Learning. Unfortunately,\nconducting the theoretical analysis asynchronous methods is difficult, notably\ndue to the introduction of delay and inconsistency in inherently sequential\nalgorithms. Handling these issues often requires resorting to simplifying but\nunrealistic assumptions. Through a novel perspective, we revisit and clarify a\nsubtle but important technical issue present in a large fraction of the recent\nconvergence rate proofs for asynchronous parallel optimization algorithms, and\npropose a simplification of the recently introduced \"perturbed iterate\"\nframework that resolves it. We demonstrate the usefulness of our new framework\nby analyzing three distinct asynchronous parallel incremental optimization\nalgorithms: Hogwild (asynchronous SGD), KROMAGNON (asynchronous SVRG) and\nASAGA, a novel asynchronous parallel version of the incremental gradient\nalgorithm SAGA that enjoys fast linear convergence rates. We are able to both\nremove problematic assumptions and obtain better theoretical results. Notably,\nwe prove that ASAGA and KROMAGNON can obtain a theoretical linear speedup on\nmulti-core systems even without sparsity assumptions. We present results of an\nimplementation on a 40-core architecture illustrating the practical speedups as\nwell as the hardware overhead. Finally, we investigate the overlap constant, an\nill-understood but central quantity for the theoretical analysis of\nasynchronous parallel algorithms. We find that it encompasses much more\ncomplexity than suggested in previous work, and often is order-of-magnitude\nbigger than traditionally thought. \n\n"}
{"id": "1801.05159", "contents": "Title: GitGraph - Architecture Search Space Creation through Frequent\n  Computational Subgraph Mining Abstract: The dramatic success of deep neural networks across multiple application\nareas often relies on experts painstakingly designing a network architecture\nspecific to each task. To simplify this process and make it more accessible, an\nemerging research effort seeks to automate the design of neural network\narchitectures, using e.g. evolutionary algorithms or reinforcement learning or\nsimple search in a constrained space of neural modules.\n  Considering the typical size of the search space (e.g. $10^{10}$ candidates\nfor a $10$-layer network) and the cost of evaluating a single candidate,\ncurrent architecture search methods are very restricted. They either rely on\nstatic pre-built modules to be recombined for the task at hand, or they define\na static hand-crafted framework within which they can generate new\narchitectures from the simplest possible operations.\n  In this paper, we relax these restrictions, by capitalizing on the collective\nwisdom contained in the plethora of neural networks published in online code\nrepositories. Concretely, we (a) extract and publish GitGraph, a corpus of\nneural architectures and their descriptions; (b) we create problem-specific\nneural architecture search spaces, implemented as a textual search mechanism\nover GitGraph; (c) we propose a method of identifying unique common subgraphs\nwithin the architectures solving each problem (e.g., image processing,\nreinforcement learning), that can then serve as modules in the newly created\nproblem specific neural search space. \n\n"}
{"id": "1801.05413", "contents": "Title: Combinatorial Preconditioners for Proximal Algorithms on Graphs Abstract: We present a novel preconditioning technique for proximal optimization\nmethods that relies on graph algorithms to construct effective preconditioners.\nSuch combinatorial preconditioners arise from partitioning the graph into\nforests. We prove that certain decompositions lead to a theoretically optimal\ncondition number. We also show how ideal decompositions can be realized using\nmatroid partitioning and propose efficient greedy variants thereof for\nlarge-scale problems. Coupled with specialized solvers for the resulting scaled\nproximal subproblems, the preconditioned algorithm achieves competitive\nperformance in machine learning and vision applications. \n\n"}
{"id": "1801.05852", "contents": "Title: Network Representation Learning: A Survey Abstract: With the widespread use of information technologies, information networks are\nbecoming increasingly popular to capture complex relationships across various\ndisciplines, such as social networks, citation networks, telecommunication\nnetworks, and biological networks. Analyzing these networks sheds light on\ndifferent aspects of social life such as the structure of societies,\ninformation diffusion, and communication patterns. In reality, however, the\nlarge scale of information networks often makes network analytic tasks\ncomputationally expensive or intractable. Network representation learning has\nbeen recently proposed as a new learning paradigm to embed network vertices\ninto a low-dimensional vector space, by preserving network topology structure,\nvertex content, and other side information. This facilitates the original\nnetwork to be easily handled in the new vector space for further analysis. In\nthis survey, we perform a comprehensive review of the current literature on\nnetwork representation learning in the data mining and machine learning field.\nWe propose new taxonomies to categorize and summarize the state-of-the-art\nnetwork representation learning techniques according to the underlying learning\nmechanisms, the network information intended to preserve, as well as the\nalgorithmic designs and methodologies. We summarize evaluation protocols used\nfor validating network representation learning including published benchmark\ndatasets, evaluation methods, and open source algorithms. We also perform\nempirical studies to compare the performance of representative algorithms on\ncommon datasets, and analyze their computational complexity. Finally, we\nsuggest promising research directions to facilitate future study. \n\n"}
{"id": "1801.06287", "contents": "Title: What Does a TextCNN Learn? Abstract: TextCNN, the convolutional neural network for text, is a useful deep learning\nalgorithm for sentence classification tasks such as sentiment analysis and\nquestion classification. However, neural networks have long been known as black\nboxes because interpreting them is a challenging task. Researchers have\ndeveloped several tools to understand a CNN for image classification by deep\nvisualization, but research about deep TextCNNs is still insufficient. In this\npaper, we are trying to understand what a TextCNN learns on two classical NLP\ndatasets. Our work focuses on functions of different convolutional kernels and\ncorrelations between convolutional kernels. \n\n"}
{"id": "1801.07215", "contents": "Title: Get Your Workload in Order: Game Theoretic Prioritization of Database\n  Auditing Abstract: For enhancing the privacy protections of databases, where the increasing\namount of detailed personal data is stored and processed, multiple mechanisms\nhave been developed, such as audit logging and alert triggers, which notify\nadministrators about suspicious activities; however, the two main limitations\nin common are: 1) the volume of such alerts is often substantially greater than\nthe capabilities of resource-constrained organizations, and 2) strategic\nattackers may disguise their actions or carefully choosing which records they\ntouch, making incompetent the statistical detection models. For solving them,\nwe introduce a novel approach to database auditing that explicitly accounts for\nadversarial behavior by 1) prioritizing the order in which types of alerts are\ninvestigated and 2) providing an upper bound on how much resource to allocate\nfor each type. We model the interaction between a database auditor and\npotential attackers as a Stackelberg game in which the auditor chooses an\nauditing policy and attackers choose which records to target. A corresponding\napproach combining linear programming, column generation, and heuristic search\nis proposed to derive an auditing policy. For testing the policy-searching\nperformance, a publicly available credit card application dataset are adopted,\non which it shows that our methods produce high-quality mixed strategies as\ndatabase audit policies, and our general approach significantly outperforms\nnon-game-theoretic baselines. \n\n"}
{"id": "1801.07222", "contents": "Title: Rover Descent: Learning to optimize by learning to navigate on\n  prototypical loss surfaces Abstract: Learning to optimize - the idea that we can learn from data algorithms that\noptimize a numerical criterion - has recently been at the heart of a growing\nnumber of research efforts. One of the most challenging issues within this\napproach is to learn a policy that is able to optimize over classes of\nfunctions that are fairly different from the ones that it was trained on. We\npropose a novel way of framing learning to optimize as a problem of learning a\ngood navigation policy on a partially observable loss surface. To this end, we\ndevelop Rover Descent, a solution that allows us to learn a fairly broad\noptimization policy from training on a small set of prototypical\ntwo-dimensional surfaces that encompasses the classically hard cases such as\nvalleys, plateaus, cliffs and saddles and by using strictly zero-order\ninformation. We show that, without having access to gradient or curvature\ninformation, we achieve state-of-the-art convergence speed on optimization\nproblems not presented at training time such as the Rosenbrock function and\nother hard cases in two dimensions. We extend our framework to optimize over\nhigh dimensional landscapes, while still handling only two-dimensional local\nlandscape information and show good preliminary results. \n\n"}
{"id": "1802.00002", "contents": "Title: DxNAT - Deep Neural Networks for Explaining Non-Recurring Traffic\n  Congestion Abstract: Non-recurring traffic congestion is caused by temporary disruptions, such as\naccidents, sports games, adverse weather, etc. We use data related to real-time\ntraffic speed, jam factors (a traffic congestion indicator), and events\ncollected over a year from Nashville, TN to train a multi-layered deep neural\nnetwork. The traffic dataset contains over 900 million data records. The\nnetwork is thereafter used to classify the real-time data and identify\nanomalous operations. Compared with traditional approaches of using statistical\nor machine learning techniques, our model reaches an accuracy of 98.73 percent\nwhen identifying traffic congestion caused by football games. Our approach\nfirst encodes the traffic across a region as a scaled image. After that the\nimage data from different timestamps is fused with event- and time-related\ndata. Then a crossover operator is used as a data augmentation method to\ngenerate training datasets with more balanced classes. Finally, we use the\nreceiver operating characteristic (ROC) analysis to tune the sensitivity of the\nclassifier. We present the analysis of the training time and the inference time\nseparately. \n\n"}
{"id": "1802.00673", "contents": "Title: Representation Learning for Resource Usage Prediction Abstract: Creating a model of a computer system that can be used for tasks such as\npredicting future resource usage and detecting anomalies is a challenging\nproblem. Most current systems rely on heuristics and overly simplistic\nassumptions about the workloads and system statistics. These heuristics are\ntypically a one-size-fits-all solution so as to be applicable in a wide range\nof applications and systems environments.\n  With this paper, we present our ongoing work of integrating systems telemetry\nranging from standard resource usage statistics to kernel and library calls of\napplications into a machine learning model. Intuitively, such a ML model\napproximates, at any point in time, the state of a system and allows us to\nsolve tasks such as resource usage prediction and anomaly detection. To achieve\nthis goal, we leverage readily-available information that does not require any\nchanges to the applications run on the system. We train recurrent neural\nnetworks to learn a model of the system under consideration. As a proof of\nconcept, we train models specifically to predict future resource usage of\nrunning applications. \n\n"}
{"id": "1802.00868", "contents": "Title: Bayesian Renewables Scenario Generation via Deep Generative Networks Abstract: We present a method to generate renewable scenarios using Bayesian\nprobabilities by implementing the Bayesian generative adversarial\nnetwork~(Bayesian GAN), which is a variant of generative adversarial networks\nbased on two interconnected deep neural networks. By using a Bayesian\nformulation, generators can be constructed and trained to produce scenarios\nthat capture different salient modes in the data, allowing for better diversity\nand more accurate representation of the underlying physical process. Compared\nto conventional statistical models that are often hard to scale or sample from,\nthis method is model-free and can generate samples extremely efficiently. For\nvalidation, we use wind and solar times-series data from NREL integration data\nsets to train the Bayesian GAN. We demonstrate that proposed method is able to\ngenerate clusters of wind scenarios with different variance and mean value, and\nis able to distinguish and generate wind and solar scenarios simultaneously\neven if the historical data are intentionally mixed. \n\n"}
{"id": "1802.01379", "contents": "Title: Online Compact Convexified Factorization Machine Abstract: Factorization Machine (FM) is a supervised learning approach with a powerful\ncapability of feature engineering. It yields state-of-the-art performance in\nvarious batch learning tasks where all the training data is made available\nprior to the training. However, in real-world applications where the data\narrives sequentially in a streaming manner, the high cost of re-training with\nbatch learning algorithms has posed formidable challenges in the online\nlearning scenario. The initial challenge is that no prior formulations of FM\ncould fulfill the requirements in Online Convex Optimization (OCO) -- the\nparamount framework for online learning algorithm design. To address the\naforementioned challenge, we invent a new convexification scheme leading to a\nCompact Convexified FM (CCFM) that seamlessly meets the requirements in OCO.\nHowever for learning Compact Convexified FM (CCFM) in the online learning\nsetting, most existing algorithms suffer from expensive projection operations.\nTo address this subsequent challenge, we follow the general projection-free\nalgorithmic framework of Online Conditional Gradient and propose an Online\nCompact Convex Factorization Machine (OCCFM) algorithm that eschews the\nprojection operation with efficient linear optimization steps. In support of\nthe proposed OCCFM in terms of its theoretical foundation, we prove that the\ndeveloped algorithm achieves a sub-linear regret bound. To evaluate the\nempirical performance of OCCFM, we conduct extensive experiments on 6\nreal-world datasets for online recommendation and binary classification tasks.\nThe experimental results show that OCCFM outperforms the state-of-art online\nlearning algorithms. \n\n"}
{"id": "1802.01504", "contents": "Title: Linear Convergence of the Primal-Dual Gradient Method for Convex-Concave\n  Saddle Point Problems without Strong Convexity Abstract: We consider the convex-concave saddle point problem $\\min_{x}\\max_{y}\nf(x)+y^\\top A x-g(y)$ where $f$ is smooth and convex and $g$ is smooth and\nstrongly convex. We prove that if the coupling matrix $A$ has full column rank,\nthe vanilla primal-dual gradient method can achieve linear convergence even if\n$f$ is not strongly convex. Our result generalizes previous work which either\nrequires $f$ and $g$ to be quadratic functions or requires proximal mappings\nfor both $f$ and $g$. We adopt a novel analysis technique that in each\niteration uses a \"ghost\" update as a reference, and show that the iterates in\nthe primal-dual gradient method converge to this \"ghost\" sequence. Using the\nsame technique we further give an analysis for the primal-dual stochastic\nvariance reduced gradient (SVRG) method for convex-concave saddle point\nproblems with a finite-sum structure. \n\n"}
{"id": "1802.01568", "contents": "Title: Selective Sampling and Mixture Models in Generative Adversarial Networks Abstract: In this paper, we propose a multi-generator extension to the adversarial\ntraining framework, in which the objective of each generator is to represent a\nunique component of a target mixture distribution. In the training phase, the\ngenerators cooperate to represent, as a mixture, the target distribution while\nmaintaining distinct manifolds. As opposed to traditional generative models,\ninference from a particular generator after training resembles selective\nsampling from a unique component in the target distribution. We demonstrate the\nfeasibility of the proposed architecture both analytically and with basic\nMulti-Layer Perceptron (MLP) models trained on the MNIST dataset. \n\n"}
{"id": "1802.01572", "contents": "Title: MotifNet: a motif-based Graph Convolutional Network for directed graphs Abstract: Deep learning on graphs and in particular, graph convolutional neural\nnetworks, have recently attracted significant attention in the machine learning\ncommunity. Many of such techniques explore the analogy between the graph\nLaplacian eigenvectors and the classical Fourier basis, allowing to formulate\nthe convolution as a multiplication in the spectral domain. One of the key\ndrawback of spectral CNNs is their explicit assumption of an undirected graph,\nleading to a symmetric Laplacian matrix with orthogonal eigendecomposition. In\nthis work we propose MotifNet, a graph CNN capable of dealing with directed\ngraphs by exploiting local graph motifs. We present experimental evidence\nshowing the advantage of our approach on real data. \n\n"}
{"id": "1802.02988", "contents": "Title: Stochastic subgradient method converges at the rate $O(k^{-1/4})$ on\n  weakly convex functions Abstract: We prove that the proximal stochastic subgradient method, applied to a weakly\nconvex problem, drives the gradient of the Moreau envelope to zero at the rate\n$O(k^{-1/4})$. As a consequence, we resolve an open question on the convergence\nrate of the proximal stochastic gradient method for minimizing the sum of a\nsmooth nonconvex function and a convex proximable function. \n\n"}
{"id": "1802.03050", "contents": "Title: Thompson Sampling for Dynamic Pricing Abstract: In this paper we apply active learning algorithms for dynamic pricing in a\nprominent e-commerce website. Dynamic pricing involves changing the price of\nitems on a regular basis, and uses the feedback from the pricing decisions to\nupdate prices of the items. Most popular approaches to dynamic pricing use a\npassive learning approach, where the algorithm uses historical data to learn\nvarious parameters of the pricing problem, and uses the updated parameters to\ngenerate a new set of prices. We show that one can use active learning\nalgorithms such as Thompson sampling to more efficiently learn the underlying\nparameters in a pricing problem. We apply our algorithms to a real e-commerce\nsystem and show that the algorithms indeed improve revenue compared to pricing\nalgorithms that use passive learning. \n\n"}
{"id": "1802.03236", "contents": "Title: Learning Robust Options Abstract: Robust reinforcement learning aims to produce policies that have strong\nguarantees even in the face of environments/transition models whose parameters\nhave strong uncertainty. Existing work uses value-based methods and the usual\nprimitive action setting. In this paper, we propose robust methods for learning\ntemporally abstract actions, in the framework of options. We present a Robust\nOptions Policy Iteration (ROPI) algorithm with convergence guarantees, which\nlearns options that are robust to model uncertainty. We utilize ROPI to learn\nrobust options with the Robust Options Deep Q Network (RO-DQN) that solves\nmultiple tasks and mitigates model misspecification due to model uncertainty.\nWe present experimental results which suggest that policy iteration with linear\nfeatures may have an inherent form of robustness when using coarse feature\nrepresentations. In addition, we present experimental results which demonstrate\nthat robustness helps policy iteration implemented on top of deep neural\nnetworks to generalize over a much broader range of dynamics than non-robust\npolicy iteration. \n\n"}
{"id": "1802.03268", "contents": "Title: Efficient Neural Architecture Search via Parameter Sharing Abstract: We propose Efficient Neural Architecture Search (ENAS), a fast and\ninexpensive approach for automatic model design. In ENAS, a controller learns\nto discover neural network architectures by searching for an optimal subgraph\nwithin a large computational graph. The controller is trained with policy\ngradient to select a subgraph that maximizes the expected reward on the\nvalidation set. Meanwhile the model corresponding to the selected subgraph is\ntrained to minimize a canonical cross entropy loss. Thanks to parameter sharing\nbetween child models, ENAS is fast: it delivers strong empirical performances\nusing much fewer GPU-hours than all existing automatic model design approaches,\nand notably, 1000x less expensive than standard Neural Architecture Search. On\nthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves a\ntest perplexity of 55.8, establishing a new state-of-the-art among all methods\nwithout post-training processing. On the CIFAR-10 dataset, ENAS designs novel\narchitectures that achieve a test error of 2.89%, which is on par with NASNet\n(Zoph et al., 2018), whose test error is 2.65%. \n\n"}
{"id": "1802.03284", "contents": "Title: Mini-Batch Stochastic ADMMs for Nonconvex Nonsmooth Optimization Abstract: With the large rising of complex data, the nonconvex models such as nonconvex\nloss function and nonconvex regularizer are widely used in machine learning and\npattern recognition. In this paper, we propose a class of mini-batch stochastic\nADMMs (alternating direction method of multipliers) for solving large-scale\nnonconvex nonsmooth problems. We prove that, given an appropriate mini-batch\nsize, the mini-batch stochastic ADMM without variance reduction (VR) technique\nis convergent and reaches a convergence rate of $O(1/T)$ to obtain a stationary\npoint of the nonconvex optimization, where $T$ denotes the number of\niterations. Moreover, we extend the mini-batch stochastic gradient method to\nboth the nonconvex SVRG-ADMM and SAGA-ADMM proposed in our initial manuscript\n\\cite{huang2016stochastic}, and prove these mini-batch stochastic ADMMs also\nreaches the convergence rate of $O(1/T)$ without condition on the mini-batch\nsize. In particular, we provide a specific parameter selection for step size\n$\\eta$ of stochastic gradients and penalty parameter $\\rho$ of augmented\nLagrangian function. Finally, extensive experimental results on both simulated\nand real-world data demonstrate the effectiveness of the proposed algorithms. \n\n"}
{"id": "1802.03497", "contents": "Title: Modeling Global Dynamics from Local Snapshots with Deep Generative\n  Neural Networks Abstract: Complex high dimensional stochastic dynamic systems arise in many\napplications in the natural sciences and especially biology. However, while\nthese systems are difficult to describe analytically, \"snapshot\" measurements\nthat sample the output of the system are often available. In order to model the\ndynamics of such systems given snapshot data, or local transitions, we present\na deep neural network framework we call Dynamics Modeling Network or DyMoN.\nDyMoN is a neural network framework trained as a deep generative Markov model\nwhose next state is a probability distribution based on the current state.\nDyMoN is trained using samples of current and next-state pairs, and thus does\nnot require longitudinal measurements. We show the advantage of DyMoN over\nshallow models such as Kalman filters and hidden Markov models, and other deep\nmodels such as recurrent neural networks in its ability to embody the dynamics\n(which can be studied via perturbation of the neural network) and generate\nlongitudinal hypothetical trajectories. We perform three case studies in which\nwe apply DyMoN to different types of biological systems and extract features of\nthe dynamics in each case by examining the learned model. \n\n"}
{"id": "1802.03801", "contents": "Title: SGD and Hogwild! Convergence Without the Bounded Gradients Assumption Abstract: Stochastic gradient descent (SGD) is the optimization algorithm of choice in\nmany machine learning applications such as regularized empirical risk\nminimization and training deep neural networks. The classical convergence\nanalysis of SGD is carried out under the assumption that the norm of the\nstochastic gradient is uniformly bounded. While this might hold for some loss\nfunctions, it is always violated for cases where the objective function is\nstrongly convex. In (Bottou et al.,2016), a new analysis of convergence of SGD\nis performed under the assumption that stochastic gradients are bounded with\nrespect to the true gradient norm. Here we show that for stochastic problems\narising in machine learning such bound always holds; and we also propose an\nalternative convergence analysis of SGD with diminishing learning rate regime,\nwhich results in more relaxed conditions than those in (Bottou et al.,2016). We\nthen move on the asynchronous parallel setting, and prove convergence of\nHogwild! algorithm in the same regime, obtaining the first convergence results\nfor this method in the case of diminished learning rate. \n\n"}
{"id": "1802.03885", "contents": "Title: ClosNets: a Priori Sparse Topologies for Faster DNN Training Abstract: Fully-connected layers in deep neural networks (DNN) are often the throughput\nand power bottleneck during training. This is due to their large size and low\ndata reuse. Pruning dense layers can significantly reduce the size of these\nnetworks, but this approach can only be applied after training. In this work we\npropose a novel fully-connected layer that reduces the memory requirements of\nDNNs without sacrificing accuracy. We replace a dense matrix with products of\nsparse matrices whose topologies we pick in advance. This allows us to: (1)\ntrain significantly smaller networks without a loss in accuracy, and (2) store\nthe network weights without having to store connection indices. We therefore\nachieve significant training speedups due to the smaller network size, and a\nreduced amount of computation per epoch. We tested several sparse layer\ntopologies and found that Clos networks perform well due to their high path\ndiversity, shallowness, and high model accuracy. With the ClosNets, we are able\nto reduce dense layer sizes by as much as an order of magnitude without hurting\nmodel accuracy. \n\n"}
{"id": "1802.04307", "contents": "Title: A Fast Proximal Point Method for Computing Exact Wasserstein Distance Abstract: Wasserstein distance plays increasingly important roles in machine learning,\nstochastic programming and image processing. Major efforts have been under way\nto address its high computational complexity, some leading to approximate or\nregularized variations such as Sinkhorn distance. However, as we will\ndemonstrate, regularized variations with large regularization parameter will\ndegradate the performance in several important machine learning applications,\nand small regularization parameter will fail due to numerical stability issues\nwith existing algorithms. We address this challenge by developing an Inexact\nProximal point method for exact Optimal Transport problem (IPOT) with the\nproximal operator approximately evaluated at each iteration using projections\nto the probability simplex. The algorithm (a) converges to exact Wasserstein\ndistance with theoretical guarantee and robust regularization parameter\nselection, (b) alleviates numerical stability issue, (c) has similar\ncomputational complexity to Sinkhorn, and (d) avoids the shrinking problem when\napply to generative models. Furthermore, a new algorithm is proposed based on\nIPOT to obtain sharper Wasserstein barycenter. \n\n"}
{"id": "1802.04397", "contents": "Title: Identifiability of Nonparametric Mixture Models and Bayes Optimal\n  Clustering Abstract: Motivated by problems in data clustering, we establish general conditions\nunder which families of nonparametric mixture models are identifiable, by\nintroducing a novel framework involving clustering overfitted \\emph{parametric}\n(i.e. misspecified) mixture models. These identifiability conditions generalize\nexisting conditions in the literature, and are flexible enough to include for\nexample mixtures of Gaussian mixtures. In contrast to the recent literature on\nestimating nonparametric mixtures, we allow for general nonparametric mixture\ncomponents, and instead impose regularity assumptions on the underlying mixing\nmeasure. As our primary application, we apply these results to partition-based\nclustering, generalizing the notion of a Bayes optimal partition from classical\nparametric model-based clustering to nonparametric settings. Furthermore, this\nframework is constructive so that it yields a practical algorithm for learning\nidentified mixtures, which is illustrated through several examples on real\ndata. The key conceptual device in the analysis is the convex, metric geometry\nof probability measures on metric spaces and its connection to the Wasserstein\nconvergence of mixing measures. The result is a flexible framework for\nnonparametric clustering with formal consistency guarantees. \n\n"}
{"id": "1802.04697", "contents": "Title: Learning to Search with MCTSnets Abstract: Planning problems are among the most important and well-studied problems in\nartificial intelligence. They are most typically solved by tree search\nalgorithms that simulate ahead into the future, evaluate future states, and\nback-up those evaluations to the root of a search tree. Among these algorithms,\nMonte-Carlo tree search (MCTS) is one of the most general, powerful and widely\nused. A typical implementation of MCTS uses cleverly designed rules, optimized\nto the particular characteristics of the domain. These rules control where the\nsimulation traverses, what to evaluate in the states that are reached, and how\nto back-up those evaluations. In this paper we instead learn where, what and\nhow to search. Our architecture, which we call an MCTSnet, incorporates\nsimulation-based search inside a neural network, by expanding, evaluating and\nbacking-up a vector embedding. The parameters of the network are trained\nend-to-end using gradient-based optimisation. When applied to small searches in\nthe well known planning problem Sokoban, the learned search algorithm\nsignificantly outperformed MCTS baselines. \n\n"}
{"id": "1802.04918", "contents": "Title: Prophit: Causal inverse classification for multiple continuously valued\n  treatment policies Abstract: Inverse classification uses an induced classifier as a queryable oracle to\nguide test instances towards a preferred posterior class label. The result\nproduced from the process is a set of instance-specific feature perturbations,\nor recommendations, that optimally improve the probability of the class label.\nIn this work, we adopt a causal approach to inverse classification, eliciting\ntreatment policies (i.e., feature perturbations) for models induced with causal\nproperties. In so doing, we solve a long-standing problem of eliciting\nmultiple, continuously valued treatment policies, using an updated framework\nand corresponding set of assumptions, which we term the inverse classification\npotential outcomes framework (ICPOF), along with a new measure, referred to as\nthe individual future estimated effects ($i$FEE). We also develop the\napproximate propensity score (APS), based on Gaussian processes, to weight\ntreatments, much like the inverse propensity score weighting used in past\nworks. We demonstrate the viability of our methods on student performance. \n\n"}
{"id": "1802.05074", "contents": "Title: L4: Practical loss-based stepsize adaptation for deep learning Abstract: We propose a stepsize adaptation scheme for stochastic gradient descent. It\noperates directly with the loss function and rescales the gradient in order to\nmake fixed predicted progress on the loss. We demonstrate its capabilities by\nconclusively improving the performance of Adam and Momentum optimizers. The\nenhanced optimizers with default hyperparameters consistently outperform their\nconstant stepsize counterparts, even the best ones, without a measurable\nincrease in computational cost. The performance is validated on multiple\narchitectures including dense nets, CNNs, ResNets, and the recurrent\nDifferential Neural Computer on classical datasets MNIST, fashion MNIST,\nCIFAR10 and others. \n\n"}
{"id": "1802.05374", "contents": "Title: A Progressive Batching L-BFGS Method for Machine Learning Abstract: The standard L-BFGS method relies on gradient approximations that are not\ndominated by noise, so that search directions are descent directions, the line\nsearch is reliable, and quasi-Newton updating yields useful quadratic models of\nthe objective function. All of this appears to call for a full batch approach,\nbut since small batch sizes give rise to faster algorithms with better\ngeneralization properties, L-BFGS is currently not considered an algorithm of\nchoice for large-scale machine learning applications. One need not, however,\nchoose between the two extremes represented by the full batch or highly\nstochastic regimes, and may instead follow a progressive batching approach in\nwhich the sample size increases during the course of the optimization. In this\npaper, we present a new version of the L-BFGS algorithm that combines three\nbasic components - progressive batching, a stochastic line search, and stable\nquasi-Newton updating - and that performs well on training logistic regression\nand deep neural networks. We provide supporting convergence theory for the\nmethod. \n\n"}
{"id": "1802.05394", "contents": "Title: Cost-Effective Training of Deep CNNs with Active Model Adaptation Abstract: Deep convolutional neural networks have achieved great success in various\napplications. However, training an effective DNN model for a specific task is\nrather challenging because it requires a prior knowledge or experience to\ndesign the network architecture, repeated trial-and-error process to tune the\nparameters, and a large set of labeled data to train the model. In this paper,\nwe propose to overcome these challenges by actively adapting a pre-trained\nmodel to a new task with less labeled examples. Specifically, the pre-trained\nmodel is iteratively fine tuned based on the most useful examples. The examples\nare actively selected based on a novel criterion, which jointly estimates the\npotential contribution of an instance on optimizing the feature representation\nas well as improving the classification model for the target task. On one hand,\nthe pre-trained model brings plentiful information from its original task,\navoiding redesign of the network architecture or training from scratch; and on\nthe other hand, the labeling cost can be significantly reduced by active label\nquerying. Experiments on multiple datasets and different pre-trained models\ndemonstrate that the proposed approach can achieve cost-effective training of\nDNNs. \n\n"}
{"id": "1802.05846", "contents": "Title: Train on Validation: Squeezing the Data Lemon Abstract: Model selection on validation data is an essential step in machine learning.\nWhile the mixing of data between training and validation is considered taboo,\npractitioners often violate it to increase performance. Here, we offer a\nsimple, practical method for using the validation set for training, which\nallows for a continuous, controlled trade-off between performance and\noverfitting of model selection. We define the notion of\non-average-validation-stable algorithms as one in which using small portions of\nvalidation data for training does not overfit the model selection process. We\nthen prove that stable algorithms are also validation stable. Finally, we\ndemonstrate our method on the MNIST and CIFAR-10 datasets using stable\nalgorithms as well as state-of-the-art neural networks. Our results show\nsignificant increase in test performance with a minor trade-off in bias\nadmitted to the model selection process. \n\n"}
{"id": "1802.06132", "contents": "Title: Interaction Matters: A Note on Non-asymptotic Local Convergence of\n  Generative Adversarial Networks Abstract: Motivated by the pursuit of a systematic computational and algorithmic\nunderstanding of Generative Adversarial Networks (GANs), we present a simple\nyet unified non-asymptotic local convergence theory for smooth two-player\ngames, which subsumes several discrete-time gradient-based saddle point\ndynamics. The analysis reveals the surprising nature of the off-diagonal\ninteraction term as both a blessing and a curse. On the one hand, this\ninteraction term explains the origin of the slow-down effect in the convergence\nof Simultaneous Gradient Ascent (SGA) to stable Nash equilibria. On the other\nhand, for the unstable equilibria, exponential convergence can be proved thanks\nto the interaction term, for four modified dynamics proposed to stabilize GAN\ntraining: Optimistic Mirror Descent (OMD), Consensus Optimization (CO),\nImplicit Updates (IU) and Predictive Method (PM). The analysis uncovers the\nintimate connections among these stabilizing techniques, and provides detailed\ncharacterization on the choice of learning rate. As a by-product, we present a\nnew analysis for OMD proposed in Daskalakis, Ilyas, Syrgkanis, and Zeng [2017]\nwith improved rates. \n\n"}
{"id": "1802.06181", "contents": "Title: Semi-supervised multi-task learning for lung cancer diagnosis Abstract: Early detection of lung nodules is of great importance in lung cancer\nscreening. Existing research recognizes the critical role played by CAD systems\nin early detection and diagnosis of lung nodules. However, many CAD systems,\nwhich are used as cancer detection tools, produce a lot of false positives (FP)\nand require a further FP reduction step. Furthermore, guidelines for early\ndiagnosis and treatment of lung cancer are consist of different shape and\nvolume measurements of abnormalities. Segmentation is at the heart of our\nunderstanding of nodules morphology making it a major area of interest within\nthe field of computer aided diagnosis systems. This study set out to test the\nhypothesis that joint learning of false positive (FP) nodule reduction and\nnodule segmentation can improve the computer aided diagnosis (CAD) systems'\nperformance on both tasks. To support this hypothesis we propose a 3D deep\nmulti-task CNN to tackle these two problems jointly. We tested our system on\nLUNA16 dataset and achieved an average dice similarity coefficient (DSC) of 91%\nas segmentation accuracy and a score of nearly 92% for FP reduction. As a proof\nof our hypothesis, we showed improvements of segmentation and FP reduction\ntasks over two baselines. Our results support that joint training of these two\ntasks through a multi-task learning approach improves system performance on\nboth. We also showed that a semi-supervised approach can be used to overcome\nthe limitation of lack of labeled data for the 3D segmentation task. \n\n"}
{"id": "1802.06384", "contents": "Title: Spurious Valleys in Two-layer Neural Network Optimization Landscapes Abstract: Neural networks provide a rich class of high-dimensional, non-convex\noptimization problems. Despite their non-convexity, gradient-descent methods\noften successfully optimize these models. This has motivated a recent spur in\nresearch attempting to characterize properties of their loss surface that may\nexplain such success.\n  In this paper, we address this phenomenon by studying a key topological\nproperty of the loss: the presence or absence of spurious valleys, defined as\nconnected components of sub-level sets that do not include a global minimum.\nFocusing on a class of two-layer neural networks defined by smooth (but\ngenerally non-linear) activation functions, we identify a notion of intrinsic\ndimension and show that it provides necessary and sufficient conditions for the\nabsence of spurious valleys. More concretely, finite intrinsic dimension\nguarantees that for sufficiently overparametrised models no spurious valleys\nexist, independently of the data distribution. Conversely, infinite intrinsic\ndimension implies that spurious valleys do exist for certain data\ndistributions, independently of model overparametrisation. Besides these\npositive and negative results, we show that, although spurious valleys may\nexist in general, they are confined to low risk levels and avoided with high\nprobability on overparametrised models. \n\n"}
{"id": "1802.06403", "contents": "Title: RadialGAN: Leveraging multiple datasets to improve target-specific\n  predictive models using Generative Adversarial Networks Abstract: Training complex machine learning models for prediction often requires a\nlarge amount of data that is not always readily available. Leveraging these\nexternal datasets from related but different sources is therefore an important\ntask if good predictive models are to be built for deployment in settings where\ndata can be rare. In this paper we propose a novel approach to the problem in\nwhich we use multiple GAN architectures to learn to translate from one dataset\nto another, thereby allowing us to effectively enlarge the target dataset, and\ntherefore learn better predictive models than if we simply used the target\ndataset. We show the utility of such an approach, demonstrating that our method\nimproves the prediction performance on the target domain over using just the\ntarget dataset and also show that our framework outperforms several other\nbenchmarks on a collection of real-world medical datasets. \n\n"}
{"id": "1802.07091", "contents": "Title: An Efficient Semismooth Newton Based Algorithm for Convex Clustering Abstract: Clustering may be the most fundamental problem in unsupervised learning which\nis still active in machine learning research because its importance in many\napplications. Popular methods like K-means, may suffer from instability as they\nare prone to get stuck in its local minima. Recently, the sum-of-norms (SON)\nmodel (also known as clustering path), which is a convex relaxation of\nhierarchical clustering model, has been proposed in [7] and [5] Although\nnumerical algorithms like ADMM and AMA are proposed to solve convex clustering\nmodel [2], it is known to be very challenging to solve large-scale problems. In\nthis paper, we propose a semi-smooth Newton based augmented Lagrangian method\nfor large-scale convex clustering problems. Extensive numerical experiments on\nboth simulated and real data demonstrate that our algorithm is highly efficient\nand robust for solving large-scale problems. Moreover, the numerical results\nalso show the superior performance and scalability of our algorithm compared to\nexisting first-order methods. \n\n"}
{"id": "1802.07176", "contents": "Title: Adaptive Sampling for Coarse Ranking Abstract: We consider the problem of active coarse ranking, where the goal is to sort\nitems according to their means into clusters of pre-specified sizes, by\nadaptively sampling from their reward distributions. This setting is useful in\nmany social science applications involving human raters and the approximate\nrank of every item is desired. Approximate or coarse ranking can significantly\nreduce the number of ratings required in comparison to the number needed to\nfind an exact ranking. We propose a computationally efficient PAC algorithm\nLUCBRank for coarse ranking, and derive an upper bound on its sample\ncomplexity. We also derive a nearly matching distribution-dependent lower\nbound. Experiments on synthetic as well as real-world data show that LUCBRank\nperforms better than state-of-the-art baseline methods, even when these methods\nhave the advantage of knowing the underlying parametric model. \n\n"}
{"id": "1802.07187", "contents": "Title: Leader-follower based Coalition Formation in Large-scale UAV Networks, A\n  Quantum Evolutionary Approach Abstract: The problem of decentralized multiple Point of Interests (PoIs) detection and\nassociated task completion in an unknown environment with multiple\nresource-constrained and self-interested Unmanned Aerial Vehicles (UAVs) is\nstudied. The UAVs form several coalitions to efficiently complete the compound\ntasks which are impossible to be performed individually. The objectives of such\ncoalition formation are to firstly minimize resource consumption in completing\nthe encountered tasks on time, secondly to enhance the reliability of the\ncoalitions, and lastly in segregating the most trusted UAVs amid the self\ninterested of them. As many previous publications have merely focused on\nminimizing costs, this study considers a multi-objective optimization coalition\nformation problem that considers the three aforementioned objectives. In doing\nso, a leader-follower- inspired coalition formation algorithm amalgamating the\nthree objectives to address the problem of the computational complexity of\ncoalition formation in large-scale UAV networks is proposed. This algorithm\nattempts to form the coalitions with minimally exceeding the required resources\nfor the encountered tasks while maximizing the number of completed tasks. The\nproposed algorithm is based on Quantum Evolutionary Algorithms(QEA) which are a\ncombination of quantum computing and evolutionary algorithms. Results from\nsimulations show that the proposed algorithm significantly outperforms the\nexisting coalition formation algorithms such as merge-and-split and a famous\nmulti-objective genetic algorithm called NSGA-II. \n\n"}
{"id": "1802.07372", "contents": "Title: Stochastic Variance-Reduced Cubic Regularization for Nonconvex\n  Optimization Abstract: Cubic regularization (CR) is an optimization method with emerging popularity\ndue to its capability to escape saddle points and converge to second-order\nstationary solutions for nonconvex optimization. However, CR encounters a high\nsample complexity issue for finite-sum problems with a large data size.\n%Various inexact variants of CR have been proposed to improve the sample\ncomplexity. In this paper, we propose a stochastic variance-reduced\ncubic-regularization (SVRC) method under random sampling, and study its\nconvergence guarantee as well as sample complexity. We show that the iteration\ncomplexity of SVRC for achieving a second-order stationary solution within\n$\\epsilon$ accuracy is $O(\\epsilon^{-3/2})$, which matches the state-of-art\nresult on CR types of methods. Moreover, our proposed variance reduction scheme\nsignificantly reduces the per-iteration sample complexity. The resulting total\nHessian sample complexity of our SVRC is ${\\Oc}(N^{2/3} \\epsilon^{-3/2})$,\nwhich outperforms the state-of-art result by a factor of $O(N^{2/15})$. We also\nstudy our SVRC under random sampling without replacement scheme, which yields a\nlower per-iteration sample complexity, and hence justifies its practical\napplicability. \n\n"}
{"id": "1802.07834", "contents": "Title: Learning to Gather without Communication Abstract: A standard belief on emerging collective behavior is that it emerges from\nsimple individual rules. Most of the mathematical research on such collective\nbehavior starts from imperative individual rules, like always go to the center.\nBut how could an (optimal) individual rule emerge during a short period within\nthe group lifetime, especially if communication is not available. We argue that\nsuch rules can actually emerge in a group in a short span of time via\ncollective (multi-agent) reinforcement learning, i.e learning via rewards and\npunishments. We consider the gathering problem: several agents (social animals,\nswarming robots...) must gather around a same position, which is not determined\nin advance. They must do so without communication on their planned decision,\njust by looking at the position of other agents. We present the first\nexperimental evidence that a gathering behavior can be learned without\ncommunication in a partially observable environment. The learned behavior has\nthe same properties as a self-stabilizing distributed algorithm, as processes\ncan gather from any initial state (and thus tolerate any transient failure).\nBesides, we show that it is possible to tolerate the brutal loss of up to 90\\%\nof agents without significant impact on the behavior. \n\n"}
{"id": "1802.08054", "contents": "Title: VBALD - Variational Bayesian Approximation of Log Determinants Abstract: Evaluating the log determinant of a positive definite matrix is ubiquitous in\nmachine learning. Applications thereof range from Gaussian processes,\nminimum-volume ellipsoids, metric learning, kernel learning, Bayesian neural\nnetworks, Determinental Point Processes, Markov random fields to partition\nfunctions of discrete graphical models. In order to avoid the canonical, yet\nprohibitive, Cholesky $\\mathcal{O}(n^{3})$ computational cost, we propose a\nnovel approach, with complexity $\\mathcal{O}(n^{2})$, based on a constrained\nvariational Bayes algorithm. We compare our method to Taylor, Chebyshev and\nLanczos approaches and show state of the art performance on both synthetic and\nreal-world datasets. \n\n"}
{"id": "1802.08534", "contents": "Title: Weighted Double Deep Multiagent Reinforcement Learning in Stochastic\n  Cooperative Environments Abstract: Recently, multiagent deep reinforcement learning (DRL) has received\nincreasingly wide attention. Existing multiagent DRL algorithms are inefficient\nwhen facing with the non-stationarity due to agents update their policies\nsimultaneously in stochastic cooperative environments. This paper extends the\nrecently proposed weighted double estimator to the multiagent domain and\npropose a multiagent DRL framework, named weighted double deep Q-network\n(WDDQN). By utilizing the weighted double estimator and the deep neural\nnetwork, WDDQN can not only reduce the bias effectively but also be extended to\nscenarios with raw visual inputs. To achieve efficient cooperation in the\nmultiagent domain, we introduce the lenient reward network and the scheduled\nreplay strategy. Experiments show that the WDDQN outperforms the existing DRL\nand multiaent DRL algorithms, i.e., double DQN and lenient Q-learning, in terms\nof the average reward and the convergence rate in stochastic cooperative\nenvironments. \n\n"}
{"id": "1802.08604", "contents": "Title: Limiting gaming opportunities on incentive-based demand response\n  programs Abstract: Demand Response (DR) is a program designed to match supply and demand by\nmodifying consumption profile. Some of these programs are based on economic\nincentives, in which, a user is paid to reduce his energy requirements\naccording to an estimated baseline. Literature review and practice have shown\nthat the counter-factual models of employing baselines are vulnerable for\ngaming. Classical solutions of mechanism design require that agents communicate\ntheir full types which result in greater difficulties for its practical\nimplementation. In this paper, a novel contract is developed to induce\nindividual rationality (voluntary participation) and asymptotic\nincentive-compatibility (truthfulness) through probability of call, where an\nagent does not require to report the marginal utility. In this approach, a\nconsumer only announces the baseline and reduction capacity, given a payment\nscheme that includes cost of electricity, incentive price, and penalty caused\nby any deviation between self-reported and actual energy consumption. The\naggregator decides randomly what users are called to perform the energy\nreduction. As result, asymptotic truth-telling behavior in incentive-based DR\nis managed by the aggregator through the probability of call for each agent.\nMathematical proofs and numerical studies are provided to demonstrate the\nproperties and advantages of this contract in limiting gaming opportunities and\nin terms of its implementation. \n\n"}
{"id": "1802.09747", "contents": "Title: Accelerating Asynchronous Algorithms for Convex Optimization by Momentum\n  Compensation Abstract: Asynchronous algorithms have attracted much attention recently due to the\ncrucial demands on solving large-scale optimization problems. However, the\naccelerated versions of asynchronous algorithms are rarely studied. In this\npaper, we propose the \"momentum compensation\" technique to accelerate\nasynchronous algorithms for convex problems. Specifically, we first accelerate\nthe plain Asynchronous Gradient Descent, which achieves a faster\n$O(1/\\sqrt{\\epsilon})$ (v.s. $O(1/\\epsilon)$) convergence rate for non-strongly\nconvex functions, and $O(\\sqrt{\\kappa}\\log(1/\\epsilon))$ (v.s. $O(\\kappa\n\\log(1/\\epsilon))$) for strongly convex functions to reach an $\\epsilon$-\napproximate minimizer with the condition number $\\kappa$. We further apply the\ntechnique to accelerate modern stochastic asynchronous algorithms such as\nAsynchronous Stochastic Coordinate Descent and Asynchronous Stochastic Gradient\nDescent. Both of the resultant practical algorithms are faster than existing\nones by order. To the best of our knowledge, we are the first to consider\naccelerated algorithms that allow updating by delayed gradients and are the\nfirst to propose truly accelerated asynchronous algorithms. Finally, the\nexperimental results on a shared memory system show that acceleration can lead\nto significant performance gains on ill-conditioned problems. \n\n"}
{"id": "1802.09841", "contents": "Title: Adversarial Active Learning for Deep Networks: a Margin Based Approach Abstract: We propose a new active learning strategy designed for deep neural networks.\nThe goal is to minimize the number of data annotation queried from an oracle\nduring training. Previous active learning strategies scalable for deep networks\nwere mostly based on uncertain sample selection. In this work, we focus on\nexamples lying close to the decision boundary. Based on theoretical works on\nmargin theory for active learning, we know that such examples may help to\nconsiderably decrease the number of annotations. While measuring the exact\ndistance to the decision boundaries is intractable, we propose to rely on\nadversarial examples. We do not consider anymore them as a threat instead we\nexploit the information they provide on the distribution of the input space in\norder to approximate the distance to decision boundaries. We demonstrate\nempirically that adversarial active queries yield faster convergence of CNNs\ntrained on MNIST, the Shoe-Bag and the Quick-Draw datasets. \n\n"}
{"id": "1802.09914", "contents": "Title: High-Dimensional Vector Semantics Abstract: In this paper we explore the \"vector semantics\" problem from the perspective\nof \"almost orthogonal\" property of high-dimensional random vectors. We show\nthat this intriguing property can be used to \"memorize\" random vectors by\nsimply adding them, and we provide an efficient probabilistic solution to the\nset membership problem. Also, we discuss several applications to word context\nvector embeddings, document sentences similarity, and spam filtering. \n\n"}
{"id": "1802.10168", "contents": "Title: ADMM-based Networked Stochastic Variational Inference Abstract: Owing to the recent advances in \"Big Data\" modeling and prediction tasks,\nvariational Bayesian estimation has gained popularity due to their ability to\nprovide exact solutions to approximate posteriors. One key technique for\napproximate inference is stochastic variational inference (SVI). SVI poses\nvariational inference as a stochastic optimization problem and solves it\niteratively using noisy gradient estimates. It aims to handle massive data for\npredictive and classification tasks by applying complex Bayesian models that\nhave observed as well as latent variables. This paper aims to decentralize it\nallowing parallel computation, secure learning and robustness benefits. We use\nAlternating Direction Method of Multipliers in a top-down setting to develop a\ndistributed SVI algorithm such that independent learners running inference\nalgorithms only require sharing the estimated model parameters instead of their\nprivate datasets. Our work extends the distributed SVI-ADMM algorithm that we\nfirst propose, to an ADMM-based networked SVI algorithm in which not only are\nthe learners working distributively but they share information according to\nrules of a graph by which they form a network. This kind of work lies under the\numbrella of `deep learning over networks' and we verify our algorithm for a\ntopic-modeling problem for corpus of Wikipedia articles. We illustrate the\nresults on latent Dirichlet allocation (LDA) topic model in large document\nclassification, compare performance with the centralized algorithm, and use\nnumerical experiments to corroborate the analytical results. \n\n"}
{"id": "1802.10592", "contents": "Title: Model-Ensemble Trust-Region Policy Optimization Abstract: Model-free reinforcement learning (RL) methods are succeeding in a growing\nnumber of tasks, aided by recent advances in deep learning. However, they tend\nto suffer from high sample complexity, which hinders their use in real-world\ndomains. Alternatively, model-based reinforcement learning promises to reduce\nsample complexity, but tends to require careful tuning and to date have\nsucceeded mainly in restrictive domains where simple models are sufficient for\nlearning. In this paper, we analyze the behavior of vanilla model-based\nreinforcement learning methods when deep neural networks are used to learn both\nthe model and the policy, and show that the learned policy tends to exploit\nregions where insufficient data is available for the model to be learned,\ncausing instability in training. To overcome this issue, we propose to use an\nensemble of models to maintain the model uncertainty and regularize the\nlearning process. We further show that the use of likelihood ratio derivatives\nyields much more stable learning than backpropagation through time. Altogether,\nour approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO)\nsignificantly reduces the sample complexity compared to model-free deep RL\nmethods on challenging continuous control benchmark tasks. \n\n"}
{"id": "1803.00162", "contents": "Title: Towards Cooperation in Sequential Prisoner's Dilemmas: a Deep Multiagent\n  Reinforcement Learning Approach Abstract: The Iterated Prisoner's Dilemma has guided research on social dilemmas for\ndecades. However, it distinguishes between only two atomic actions: cooperate\nand defect. In real-world prisoner's dilemmas, these choices are temporally\nextended and different strategies may correspond to sequences of actions,\nreflecting grades of cooperation. We introduce a Sequential Prisoner's Dilemma\n(SPD) game to better capture the aforementioned characteristics. In this work,\nwe propose a deep multiagent reinforcement learning approach that investigates\nthe evolution of mutual cooperation in SPD games. Our approach consists of two\nphases. The first phase is offline: it synthesizes policies with different\ncooperation degrees and then trains a cooperation degree detection network. The\nsecond phase is online: an agent adaptively selects its policy based on the\ndetected degree of opponent cooperation. The effectiveness of our approach is\ndemonstrated in two representative SPD 2D games: the Apple-Pear game and the\nFruit Gathering game. Experimental results show that our strategy can avoid\nbeing exploited by exploitative opponents and achieve cooperation with\ncooperative opponents. \n\n"}
{"id": "1803.00183", "contents": "Title: Learning with Correntropy-induced Losses for Regression with Mixture of\n  Symmetric Stable Noise Abstract: In recent years, correntropy and its applications in machine learning have\nbeen drawing continuous attention owing to its merits in dealing with\nnon-Gaussian noise and outliers. However, theoretical understanding of\ncorrentropy, especially in the statistical learning context, is still limited.\nIn this study, within the statistical learning framework, we investigate\ncorrentropy based regression in the presence of non-Gaussian noise or outliers.\nMotivated by the practical way of generating non-Gaussian noise or outliers, we\nintroduce mixture of symmetric stable noise, which include Gaussian noise,\nCauchy noise, and their mixture as special cases, to model non-Gaussian noise\nor outliers. We demonstrate that under the mixture of symmetric stable noise\nassumption, correntropy based regression can learn the conditional mean\nfunction or the conditional median function well without resorting to the\nfinite-variance or even the finite first-order moment condition on the noise.\nIn particular, for the above two cases, we establish asymptotic optimal\nlearning rates for correntropy based regression estimators that are\nasymptotically of type $\\mathcal{O}(n^{-1})$. These results justify the\neffectiveness of the correntropy based regression estimators in dealing with\noutliers as well as non-Gaussian noise. We believe that the present study\ncompletes our understanding towards correntropy based regression from a\nstatistical learning viewpoint, and may also shed some light on robust\nstatistical learning for regression. \n\n"}
{"id": "1803.00225", "contents": "Title: Global Convergence of Block Coordinate Descent in Deep Learning Abstract: Deep learning has aroused extensive attention due to its great empirical\nsuccess. The efficiency of the block coordinate descent (BCD) methods has been\nrecently demonstrated in deep neural network (DNN) training. However,\ntheoretical studies on their convergence properties are limited due to the\nhighly nonconvex nature of DNN training. In this paper, we aim at providing a\ngeneral methodology for provable convergence guarantees for this type of\nmethods. In particular, for most of the commonly used DNN training models\ninvolving both two- and three-splitting schemes, we establish the global\nconvergence to a critical point at a rate of ${\\cal O}(1/k)$, where $k$ is the\nnumber of iterations. The results extend to general loss functions which have\nLipschitz continuous gradients and deep residual networks (ResNets). Our key\ndevelopment adds several new elements to the Kurdyka-{\\L}ojasiewicz inequality\nframework that enables us to carry out the global convergence analysis of BCD\nin the general scenario of deep learning. \n\n"}
{"id": "1803.00916", "contents": "Title: Deep Learning for Signal Authentication and Security in Massive Internet\n  of Things Systems Abstract: Secure signal authentication is arguably one of the most challenging problems\nin the Internet of Things (IoT) environment, due to the large-scale nature of\nthe system and its susceptibility to man-in-the-middle and eavesdropping\nattacks. In this paper, a novel deep learning method is proposed for dynamic\nauthentication of IoT signals to detect cyber attacks. The proposed learning\nframework, based on a long short-term memory (LSTM) structure, enables the IoT\ndevices (IoTDs) to extract a set of stochastic features from their generated\nsignal and dynamically watermark these features into the signal. This method\nenables the cloud, which collects signals from the IoT devices, to effectively\nauthenticate the reliability of the signals. Moreover, in massive IoT\nscenarios, since the cloud cannot authenticate all the IoTDs simultaneously due\nto computational limitations, a game-theoretic framework is proposed to improve\nthe cloud's decision making process by predicting vulnerable IoTDs. The\nmixed-strategy Nash equilibrium (MSNE) for this game is derived and the\nuniqueness of the expected utility at the equilibrium is proven. In the massive\nIoT system, due to a large set of available actions for the cloud, it is shown\nthat analytically deriving the MSNE is challenging and, thus, a learning\nalgorithm proposed that converges to the MSNE. Moreover, in order to cope with\nthe incomplete information case in which the cloud cannot access the state of\nthe unauthenticated IoTDs, a deep reinforcement learning algorithm is proposed\nto dynamically predict the state of unauthenticated IoTDs and allow the cloud\nto decide on which IoTDs to authenticate. Simulation results show that, with an\nattack detection delay of under 1 second the messages can be transmitted from\nIoT devices with an almost 100% reliability. \n\n"}
{"id": "1803.01370", "contents": "Title: A Distributed Quasi-Newton Algorithm for Empirical Risk Minimization\n  with Nonsmooth Regularization Abstract: We propose a communication- and computation-efficient distributed\noptimization algorithm using second-order information for solving ERM problems\nwith a nonsmooth regularization term. Current second-order and quasi-Newton\nmethods for this problem either do not work well in the distributed setting or\nwork only for specific regularizers. Our algorithm uses successive quadratic\napproximations, and we describe how to maintain an approximation of the Hessian\nand solve subproblems efficiently in a distributed manner. The proposed method\nenjoys global linear convergence for a broad range of non-strongly convex\nproblems that includes the most commonly used ERMs, thus requiring lower\ncommunication complexity. It also converges on non-convex problems, so has the\npotential to be used on applications such as deep learning. Initial\ncomputational results on convex problems demonstrate that our method\nsignificantly improves on communication cost and running time over the current\nstate-of-the-art methods. \n\n"}
{"id": "1803.01465", "contents": "Title: Query and Output: Generating Words by Querying Distributed Word\n  Representations for Paraphrase Generation Abstract: Most recent approaches use the sequence-to-sequence model for paraphrase\ngeneration. The existing sequence-to-sequence model tends to memorize the words\nand the patterns in the training dataset instead of learning the meaning of the\nwords. Therefore, the generated sentences are often grammatically correct but\nsemantically improper. In this work, we introduce a novel model based on the\nencoder-decoder framework, called Word Embedding Attention Network (WEAN). Our\nproposed model generates the words by querying distributed word representations\n(i.e. neural word embeddings), hoping to capturing the meaning of the according\nwords. Following previous work, we evaluate our model on two\nparaphrase-oriented tasks, namely text simplification and short text\nabstractive summarization. Experimental results show that our model outperforms\nthe sequence-to-sequence baseline by the BLEU score of 6.3 and 5.5 on two\nEnglish text simplification datasets, and the ROUGE-2 F1 score of 5.7 on a\nChinese summarization dataset. Moreover, our model achieves state-of-the-art\nperformances on these three benchmark datasets. \n\n"}
{"id": "1803.01814", "contents": "Title: Norm matters: efficient and accurate normalization schemes in deep\n  networks Abstract: Over the past few years, Batch-Normalization has been commonly used in deep\nnetworks, allowing faster training and high performance for a wide variety of\napplications. However, the reasons behind its merits remained unanswered, with\nseveral shortcomings that hindered its use for certain tasks. In this work, we\npresent a novel view on the purpose and function of normalization methods and\nweight-decay, as tools to decouple weights' norm from the underlying optimized\nobjective. This property highlights the connection between practices such as\nnormalization, weight decay and learning-rate adjustments. We suggest several\nalternatives to the widely used $L^2$ batch-norm, using normalization in $L^1$\nand $L^\\infty$ spaces that can substantially improve numerical stability in\nlow-precision implementations as well as provide computational and memory\nbenefits. We demonstrate that such methods enable the first batch-norm\nalternative to work for half-precision implementations. Finally, we suggest a\nmodification to weight-normalization, which improves its performance on\nlarge-scale tasks. \n\n"}
{"id": "1803.02251", "contents": "Title: Deep Information Networks Abstract: We describe a novel classifier with a tree structure, designed using\ninformation theory concepts. This Information Network is made of information\nnodes, that compress the input data, and multiplexers, that connect two or more\ninput nodes to an output node. Each information node is trained, independently\nof the others, to minimize a local cost function that minimizes the mutual\ninformation between its input and output with the constraint of keeping a given\nmutual information between its output and the target (information bottleneck).\nWe show that the system is able to provide good results in terms of accuracy,\nwhile it shows many advantages in terms of modularity and reduced complexity. \n\n"}
{"id": "1803.03880", "contents": "Title: Combating Adversarial Attacks Using Sparse Representations Abstract: It is by now well-known that small adversarial perturbations can induce\nclassification errors in deep neural networks (DNNs). In this paper, we make\nthe case that sparse representations of the input data are a crucial tool for\ncombating such attacks. For linear classifiers, we show that a sparsifying\nfront end is provably effective against $\\ell_{\\infty}$-bounded attacks,\nreducing output distortion due to the attack by a factor of roughly $K / N$\nwhere $N$ is the data dimension and $K$ is the sparsity level. We then extend\nthis concept to DNNs, showing that a \"locally linear\" model can be used to\ndevelop a theoretical foundation for crafting attacks and defenses.\nExperimental results for the MNIST dataset show the efficacy of the proposed\nsparsifying front end. \n\n"}
{"id": "1803.04223", "contents": "Title: Leveraging Crowdsourcing Data For Deep Active Learning - An Application:\n  Learning Intents in Alexa Abstract: This paper presents a generic Bayesian framework that enables any deep\nlearning model to actively learn from targeted crowds. Our framework inherits\nfrom recent advances in Bayesian deep learning, and extends existing work by\nconsidering the targeted crowdsourcing approach, where multiple annotators with\nunknown expertise contribute an uncontrolled amount (often limited) of\nannotations. Our framework leverages the low-rank structure in annotations to\nlearn individual annotator expertise, which then helps to infer the true labels\nfrom noisy and sparse annotations. It provides a unified Bayesian model to\nsimultaneously infer the true labels and train the deep learning model in order\nto reach an optimal learning efficacy. Finally, our framework exploits the\nuncertainty of the deep learning model during prediction as well as the\nannotators' estimated expertise to minimize the number of required annotations\nand annotators for optimally training the deep learning model.\n  We evaluate the effectiveness of our framework for intent classification in\nAlexa (Amazon's personal assistant), using both synthetic and real-world\ndatasets. Experiments show that our framework can accurately learn annotator\nexpertise, infer true labels, and effectively reduce the amount of annotations\nin model training as compared to state-of-the-art approaches. We further\ndiscuss the potential of our proposed framework in bridging machine learning\nand crowdsourcing towards improved human-in-the-loop systems. \n\n"}
{"id": "1803.04244", "contents": "Title: The generalized stochastic preference choice model Abstract: We propose a new discrete choice model, called the generalized stochastic\npreference (GSP) model, that incorporates non-rationality into the stochastic\npreference (SP) choice model, also known as the rank- based choice model. Our\nmodel can explain several choice phenomena that cannot be represented by any SP\nmodel such as the compromise and attraction effects, but still subsumes the SP\nmodel class. The GSP model is defined as a distribution over consumer types,\nwhere each type extends the choice behavior of rational types in the SP model.\nWe build on existing methods for estimating the SP model and propose an\niterative estimation algorithm for the GSP model that finds new types by\nsolving a integer linear program in each iteration. We further show that our\nproposed notion of non-rationality can be incorporated into other choice\nmodels, like the random utility maximization (RUM) model class as well as any\nof its subclasses. As a concrete example, we introduce the non-rational\nextension of the classical MNL model, which we term the generalized MNL (GMNL)\nmodel and present an efficient expectation-maximization (EM) algorithm for\nestimating the GMNL model. Numerical evaluation on real choice data shows that\nthe GMNL and GSP models can outperform their rational counterparts in\nout-of-sample prediction accuracy. \n\n"}
{"id": "1803.04439", "contents": "Title: From Nodes to Networks: Evolving Recurrent Neural Networks Abstract: Gated recurrent networks such as those composed of Long Short-Term Memory\n(LSTM) nodes have recently been used to improve state of the art in many\nsequential processing tasks such as speech recognition and machine translation.\nHowever, the basic structure of the LSTM node is essentially the same as when\nit was first conceived 25 years ago. Recently, evolutionary and reinforcement\nlearning mechanisms have been employed to create new variations of this\nstructure. This paper proposes a new method, evolution of a tree-based encoding\nof the gated memory nodes, and shows that it makes it possible to explore new\nvariations more effectively than other methods. The method discovers nodes with\nmultiple recurrent paths and multiple memory cells, which lead to significant\nimprovement in the standard language modeling benchmark task. The paper also\nshows how the search process can be speeded up by training an LSTM network to\nestimate performance of candidate structures, and by encouraging exploration of\nnovel solutions. Thus, evolutionary design of complex neural network structures\npromises to improve performance of deep learning architectures beyond human\nability to do so. \n\n"}
{"id": "1803.04497", "contents": "Title: Automated software vulnerability detection with machine learning Abstract: Thousands of security vulnerabilities are discovered in production software\neach year, either reported publicly to the Common Vulnerabilities and Exposures\ndatabase or discovered internally in proprietary code. Vulnerabilities often\nmanifest themselves in subtle ways that are not obvious to code reviewers or\nthe developers themselves. With the wealth of open source code available for\nanalysis, there is an opportunity to learn the patterns of bugs that can lead\nto security vulnerabilities directly from data. In this paper, we present a\ndata-driven approach to vulnerability detection using machine learning,\nspecifically applied to C and C++ programs. We first compile a large dataset of\nhundreds of thousands of open-source functions labeled with the outputs of a\nstatic analyzer. We then compare methods applied directly to source code with\nmethods applied to artifacts extracted from the build process, finding that\nsource-based models perform better. We also compare the application of deep\nneural network models with more traditional models such as random forests and\nfind the best performance comes from combining features learned by deep models\nwith tree-based models. Ultimately, our highest performing model achieves an\narea under the precision-recall curve of 0.49 and an area under the ROC curve\nof 0.87. \n\n"}
{"id": "1803.04756", "contents": "Title: A pseudo-quasi-polynomial algorithm for solving mean-payoff parity games Abstract: In a mean-payoff parity game, one of the two players aims both to achieve a\nqualitative parity objective and to minimize a quantitative long-term average\nof payoffs (aka. mean payoff). The game is zero-sum and hence the aim of the\nother player is to either foil the parity objective or to maximize the mean\npayoff.\n  Our main technical result is a pseudo-quasi-polynomial algorithm for solving\nmean-payoff parity games. All algorithms for the problem that have been\ndeveloped for over a decade have a pseudo-polynomial and an exponential factors\nin their running times; in the running time of our algorithm the latter is\nreplaced with a quasi-polynomial one. By the results of Chatterjee and Doyen\n(2012) and of Schewe, Weinert, and Zimmermann (2018), our main technical result\nimplies that there are pseudo-quasi-polynomial algorithms for solving parity\nenergy games and for solving parity games with weights.\n  Our main conceptual contributions are the definitions of strategy\ndecompositions for both players, and a notion of progress measures for\nmean-payoff parity games that generalizes both parity and energy progress\nmeasures. The former provides normal forms for and succinct representations of\nwinning strategies, and the latter enables the application to mean-payoff\nparity games of the order-theoretic machinery that underpins a recent\nquasi-polynomial algorithm for solving parity games. \n\n"}
{"id": "1803.04765", "contents": "Title: Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust\n  Deep Learning Abstract: Deep neural networks (DNNs) enable innovative applications of machine\nlearning like image recognition, machine translation, or malware detection.\nHowever, deep learning is often criticized for its lack of robustness in\nadversarial settings (e.g., vulnerability to adversarial inputs) and general\ninability to rationalize its predictions. In this work, we exploit the\nstructure of deep learning to enable new learning-based inference and decision\nstrategies that achieve desirable properties such as robustness and\ninterpretability. We take a first step in this direction and introduce the Deep\nk-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest\nneighbors algorithm with representations of the data learned by each layer of\nthe DNN: a test input is compared to its neighboring training points according\nto the distance that separates them in the representations. We show the labels\nof these neighboring points afford confidence estimates for inputs outside the\nmodel's training manifold, including on malicious inputs like adversarial\nexamples--and therein provides protections against inputs that are outside the\nmodels understanding. This is because the nearest neighbors can be used to\nestimate the nonconformity of, i.e., the lack of support for, a prediction in\nthe training data. The neighbors also constitute human-interpretable\nexplanations of predictions. We evaluate the DkNN algorithm on several\ndatasets, and show the confidence estimates accurately identify inputs outside\nthe model, and that the explanations provided by nearest neighbors are\nintuitive and useful in understanding model failures. \n\n"}
{"id": "1803.05392", "contents": "Title: Automated Construction of Bounded-Loss Imperfect-Recall Abstractions in\n  Extensive-Form Games Abstract: Extensive-form games (EFGs) model finite sequential interactions between\nplayers. The amount of memory required to represent these games is the main\nbottleneck of algorithms for computing optimal strategies and the size of these\nstrategies is often impractical for real-world applications. A common approach\nto tackle the memory bottleneck is to use information abstraction that removes\nparts of information available to players thus reducing the number of decision\npoints in the game. However, existing information-abstraction techniques are\neither specific for a particular domain, they do not provide any quality\nguarantees, or they are applicable to very small subclasses of EFGs. We present\ndomain-independent abstraction methods for creating imperfect recall\nabstractions in extensive-form games that allow computing strategies that are\n(near) optimal in the original game. To this end, we introduce two novel\nalgorithms, FPIRA and CFR+IRA, based on fictitious play and counterfactual\nregret minimization. These algorithms can start with an arbitrary domain\nspecific, or the coarsest possible, abstraction of the original game. The\nalgorithms iteratively detect the missing information they require for\ncomputing a strategy for the abstract game that is (near) optimal in the\noriginal game. This information is then included back into the abstract game.\nMoreover, our algorithms are able to exploit imperfect-recall abstractions that\nallow players to forget even history of their own actions. However, the\nalgorithms require traversing the complete unabstracted game tree. We\nexperimentally show that our algorithms can closely approximate Nash\nequilibrium of large games using abstraction with as little as 0.9% of\ninformation sets of the original game. Moreover, the results suggest that\nmemory savings increase with the increasing size of the original games. \n\n"}
{"id": "1803.05591", "contents": "Title: On the insufficiency of existing momentum schemes for Stochastic\n  Optimization Abstract: Momentum based stochastic gradient methods such as heavy ball (HB) and\nNesterov's accelerated gradient descent (NAG) method are widely used in\npractice for training deep networks and other supervised learning models, as\nthey often provide significant improvements over stochastic gradient descent\n(SGD). Rigorously speaking, \"fast gradient\" methods have provable improvements\nover gradient descent only for the deterministic case, where the gradients are\nexact. In the stochastic case, the popular explanations for their wide\napplicability is that when these fast gradient methods are applied in the\nstochastic case, they partially mimic their exact gradient counterparts,\nresulting in some practical gain. This work provides a counterpoint to this\nbelief by proving that there exist simple problem instances where these methods\ncannot outperform SGD despite the best setting of its parameters. These\nnegative problem instances are, in an informal sense, generic; they do not look\nlike carefully constructed pathological instances. These results suggest (along\nwith empirical evidence) that HB or NAG's practical performance gains are a\nby-product of mini-batching.\n  Furthermore, this work provides a viable (and provable) alternative, which,\non the same set of problem instances, significantly improves over HB, NAG, and\nSGD's performance. This algorithm, referred to as Accelerated Stochastic\nGradient Descent (ASGD), is a simple to implement stochastic algorithm, based\non a relatively less popular variant of Nesterov's Acceleration. Extensive\nempirical results in this paper show that ASGD has performance gains over HB,\nNAG, and SGD. \n\n"}
{"id": "1803.06453", "contents": "Title: Constrained Deep Learning using Conditional Gradient and Applications in\n  Computer Vision Abstract: A number of results have recently demonstrated the benefits of incorporating\nvarious constraints when training deep architectures in vision and machine\nlearning. The advantages range from guarantees for statistical generalization\nto better accuracy to compression. But support for general constraints within\nwidely used libraries remains scarce and their broader deployment within many\napplications that can benefit from them remains under-explored. Part of the\nreason is that Stochastic gradient descent (SGD), the workhorse for training\ndeep neural networks, does not natively deal with constraints with global scope\nvery well. In this paper, we revisit a classical first order scheme from\nnumerical optimization, Conditional Gradients (CG), that has, thus far had\nlimited applicability in training deep models. We show via rigorous analysis\nhow various constraints can be naturally handled by modifications of this\nalgorithm. We provide convergence guarantees and show a suite of immediate\nbenefits that are possible -- from training ResNets with fewer layers but\nbetter accuracy simply by substituting in our version of CG to faster training\nof GANs with 50% fewer epochs in image inpainting applications to provably\nbetter generalization guarantees using efficiently implementable forms of\nrecently proposed regularizers. \n\n"}
{"id": "1803.06523", "contents": "Title: Stochastic model-based minimization of weakly convex functions Abstract: We consider a family of algorithms that successively sample and minimize\nsimple stochastic models of the objective function. We show that under\nreasonable conditions on approximation quality and regularity of the models,\nany such algorithm drives a natural stationarity measure to zero at the rate\n$O(k^{-1/4})$. As a consequence, we obtain the first complexity guarantees for\nthe stochastic proximal point, proximal subgradient, and regularized\nGauss-Newton methods for minimizing compositions of convex functions with\nsmooth maps. The guiding principle, underlying the complexity guarantees, is\nthat all algorithms under consideration can be interpreted as approximate\ndescent methods on an implicit smoothing of the problem, given by the Moreau\nenvelope. Specializing to classical circumstances, we obtain the long-sought\nconvergence rate of the stochastic projected gradient method, without batching,\nfor minimizing a smooth function on a closed convex set. \n\n"}
{"id": "1803.07043", "contents": "Title: Projective Splitting with Forward Steps: Asynchronous and\n  Block-Iterative Operator Splitting Abstract: This work is concerned with the classical problem of finding a zero of a sum\nof maximal monotone operators. For the projective splitting framework recently\nproposed by Combettes and Eckstein, we show how to replace the fundamental\nsubproblem calculation using a backward step with one based on two forward\nsteps. The resulting algorithms have the same kind of coordination procedure\nand can be implemented in the same block-iterative and highly flexible manner,\nbut may perform backward steps on some operators and forward steps on others.\nPrior algorithms in the projective splitting family have used only backward\nsteps. Forward steps can be used for any Lipschitz-continuous operators\nprovided the stepsize is bounded by the inverse of the Lipschitz constant. If\nthe Lipschitz constant is unknown, a simple backtracking linesearch procedure\nmay be used. For affine operators, the stepsize can be chosen adaptively\nwithout knowledge of the Lipschitz constant and without any additional forward\nsteps. We close the paper by empirically studying the performance of several\nkinds of splitting algorithms on a large-scale rare feature selection problem. \n\n"}
{"id": "1803.07348", "contents": "Title: Frank-Wolfe with Subsampling Oracle Abstract: We analyze two novel randomized variants of the Frank-Wolfe (FW) or\nconditional gradient algorithm. While classical FW algorithms require solving a\nlinear minimization problem over the domain at each iteration, the proposed\nmethod only requires to solve a linear minimization problem over a small\n\\emph{subset} of the original domain. The first algorithm that we propose is a\nrandomized variant of the original FW algorithm and achieves a\n$\\mathcal{O}(1/t)$ sublinear convergence rate as in the deterministic\ncounterpart. The second algorithm is a randomized variant of the Away-step FW\nalgorithm, and again as its deterministic counterpart, reaches linear (i.e.,\nexponential) convergence rate making it the first provably convergent\nrandomized variant of Away-step FW. In both cases, while subsampling reduces\nthe convergence rate by a constant factor, the linear minimization step can be\na fraction of the cost of that of the deterministic versions, especially when\nthe data is streamed. We illustrate computational gains of the algorithms on\nregression problems, involving both $\\ell_1$ and latent group lasso penalties. \n\n"}
{"id": "1803.08416", "contents": "Title: Demystifying Deep Learning: A Geometric Approach to Iterative\n  Projections Abstract: Parametric approaches to Learning, such as deep learning (DL), are highly\npopular in nonlinear regression, in spite of their extremely difficult training\nwith their increasing complexity (e.g. number of layers in DL). In this paper,\nwe present an alternative semi-parametric framework which foregoes the\nordinarily required feedback, by introducing the novel idea of geometric\nregularization. We show that certain deep learning techniques such as residual\nnetwork (ResNet) architecture are closely related to our approach. Hence, our\ntechnique can be used to analyze these types of deep learning. Moreover, we\npresent preliminary results which confirm that our approach can be easily\ntrained to obtain complex structures. \n\n"}
{"id": "1803.08475", "contents": "Title: Attention, Learn to Solve Routing Problems! Abstract: The recently presented idea to learn heuristics for combinatorial\noptimization problems is promising as it can save costly development. However,\nto push this idea towards practical implementation, we need better models and\nbetter ways of training. We contribute in both directions: we propose a model\nbased on attention layers with benefits over the Pointer Network and we show\nhow to train this model using REINFORCE with a simple baseline based on a\ndeterministic greedy rollout, which we find is more efficient than using a\nvalue function. We significantly improve over recent learned heuristics for the\nTravelling Salesman Problem (TSP), getting close to optimal results for\nproblems up to 100 nodes. With the same hyperparameters, we learn strong\nheuristics for two variants of the Vehicle Routing Problem (VRP), the\nOrienteering Problem (OP) and (a stochastic variant of) the Prize Collecting\nTSP (PCTSP), outperforming a wide range of baselines and getting results close\nto highly optimized and specialized algorithms. \n\n"}
{"id": "1803.08841", "contents": "Title: The Convergence of Stochastic Gradient Descent in Asynchronous Shared\n  Memory Abstract: Stochastic Gradient Descent (SGD) is a fundamental algorithm in machine\nlearning, representing the optimization backbone for training several classic\nmodels, from regression to neural networks. Given the recent practical focus on\ndistributed machine learning, significant work has been dedicated to the\nconvergence properties of this algorithm under the inconsistent and noisy\nupdates arising from execution in a distributed environment. However,\nsurprisingly, the convergence properties of this classic algorithm in the\nstandard shared-memory model are still not well-understood.\n  In this work, we address this gap, and provide new convergence bounds for\nlock-free concurrent stochastic gradient descent, executing in the classic\nasynchronous shared memory model, against a strong adaptive adversary. Our\nresults give improved upper and lower bounds on the \"price of asynchrony\" when\nexecuting the fundamental SGD algorithm in a concurrent setting. They show that\nthis classic optimization tool can converge faster and with a wider range of\nparameters than previously known under asynchronous iterations. At the same\ntime, we exhibit a fundamental trade-off between the maximum delay in the\nsystem and the rate at which SGD can converge, which governs the set of\nparameters under which this algorithm can still work efficiently. \n\n"}
{"id": "1803.09370", "contents": "Title: Popular Matching in Roommates Setting is NP-hard Abstract: An input to the Popular Matching problem, in the roommates setting, consists\nof a graph $G$ and each vertex ranks its neighbors in strict order, known as\nits preference. In the Popular Matching problem the objective is to test\nwhether there exists a matching $M^\\star$ such that there is no matching $M$\nwhere more people are happier with $M$ than with $M^\\star$. In this paper we\nsettle the computational complexity of the Popular Matching problem in the\nroommates setting by showing that the problem is NP-complete. Thus, we resolve\nan open question that has been repeatedly, explicitly asked over the last\ndecade. \n\n"}
{"id": "1803.10520", "contents": "Title: Quantum algorithms for training Gaussian Processes Abstract: Gaussian processes (GPs) are important models in supervised machine learning.\nTraining in Gaussian processes refers to selecting the covariance functions and\nthe associated parameters in order to improve the outcome of predictions, the\ncore of which amounts to evaluating the logarithm of the marginal likelihood\n(LML) of a given model. LML gives a concrete measure of the quality of\nprediction that a GP model is expected to achieve. The classical computation of\nLML typically carries a polynomial time overhead with respect to the input\nsize. We propose a quantum algorithm that computes the logarithm of the\ndeterminant of a Hermitian matrix, which runs in logarithmic time for sparse\nmatrices. This is applied in conjunction with a variant of the quantum linear\nsystem algorithm that allows for logarithmic time computation of the form\n$\\mathbf{y}^TA^{-1}\\mathbf{y}$, where $\\mathbf{y}$ is a dense vector and $A$ is\nthe covariance matrix. We hence show that quantum computing can be used to\nestimate the LML of a GP with exponentially improved efficiency under certain\nconditions. \n\n"}
{"id": "1803.10760", "contents": "Title: Unsupervised Predictive Memory in a Goal-Directed Agent Abstract: Animals execute goal-directed behaviours despite the limited range and scope\nof their sensors. To cope, they explore environments and store memories\nmaintaining estimates of important information that is not presently available.\nRecently, progress has been made with artificial intelligence (AI) agents that\nlearn to perform tasks from sensory input, even at a human level, by merging\nreinforcement learning (RL) algorithms with deep neural networks, and the\nexcitement surrounding these results has led to the pursuit of related ideas as\nexplanations of non-human animal learning. However, we demonstrate that\ncontemporary RL algorithms struggle to solve simple tasks when enough\ninformation is concealed from the sensors of the agent, a property called\n\"partial observability\". An obvious requirement for handling partially observed\ntasks is access to extensive memory, but we show memory is not enough; it is\ncritical that the right information be stored in the right format. We develop a\nmodel, the Memory, RL, and Inference Network (MERLIN), in which memory\nformation is guided by a process of predictive modeling. MERLIN facilitates the\nsolution of tasks in 3D virtual reality environments for which partial\nobservability is severe and memories must be maintained over long durations.\nOur model demonstrates a single learning agent architecture that can solve\ncanonical behavioural tasks in psychology and neurobiology without strong\nsimplifying assumptions about the dimensionality of sensory input or the\nduration of experiences. \n\n"}
{"id": "1803.11485", "contents": "Title: QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent\n  Reinforcement Learning Abstract: In many real-world settings, a team of agents must coordinate their behaviour\nwhile acting in a decentralised way. At the same time, it is often possible to\ntrain the agents in a centralised fashion in a simulated or laboratory setting,\nwhere global state information is available and communication constraints are\nlifted. Learning joint action-values conditioned on extra state information is\nan attractive way to exploit centralised learning, but the best strategy for\nthen extracting decentralised policies is unclear. Our solution is QMIX, a\nnovel value-based method that can train decentralised policies in a centralised\nend-to-end fashion. QMIX employs a network that estimates joint action-values\nas a complex non-linear combination of per-agent values that condition only on\nlocal observations. We structurally enforce that the joint-action value is\nmonotonic in the per-agent values, which allows tractable maximisation of the\njoint action-value in off-policy learning, and guarantees consistency between\nthe centralised and decentralised policies. We evaluate QMIX on a challenging\nset of StarCraft II micromanagement tasks, and show that QMIX significantly\noutperforms existing value-based multi-agent reinforcement learning methods. \n\n"}
{"id": "1804.00810", "contents": "Title: StarCraft Micromanagement with Reinforcement Learning and Curriculum\n  Transfer Learning Abstract: Real-time strategy games have been an important field of game artificial\nintelligence in recent years. This paper presents a reinforcement learning and\ncurriculum transfer learning method to control multiple units in StarCraft\nmicromanagement. We define an efficient state representation, which breaks down\nthe complexity caused by the large state space in the game environment. Then a\nparameter sharing multi-agent gradientdescent Sarsa({\\lambda}) (PS-MAGDS)\nalgorithm is proposed to train the units. The learning policy is shared among\nour units to encourage cooperative behaviors. We use a neural network as a\nfunction approximator to estimate the action-value function, and propose a\nreward function to help units balance their move and attack. In addition, a\ntransfer learning method is used to extend our model to more difficult\nscenarios, which accelerates the training process and improves the learning\nperformance. In small scale scenarios, our units successfully learn to combat\nand defeat the built-in AI with 100% win rates. In large scale scenarios,\ncurriculum transfer learning method is used to progressively train a group of\nunits, and shows superior performance over some baseline methods in target\nscenarios. With reinforcement learning and curriculum transfer learning, our\nunits are able to learn appropriate strategies in StarCraft micromanagement\nscenarios. \n\n"}
{"id": "1804.01622", "contents": "Title: Image Generation from Scene Graphs Abstract: To truly understand the visual world our models should be able not only to\nrecognize images but also generate them. To this end, there has been exciting\nrecent progress on generating images from natural language descriptions. These\nmethods give stunning results on limited domains such as descriptions of birds\nor flowers, but struggle to faithfully reproduce complex sentences with many\nobjects and relationships. To overcome this limitation we propose a method for\ngenerating images from scene graphs, enabling explicitly reasoning about\nobjects and their relationships. Our model uses graph convolution to process\ninput graphs, computes a scene layout by predicting bounding boxes and\nsegmentation masks for objects, and converts the layout to an image with a\ncascaded refinement network. The network is trained adversarially against a\npair of discriminators to ensure realistic outputs. We validate our approach on\nVisual Genome and COCO-Stuff, where qualitative results, ablations, and user\nstudies demonstrate our method's ability to generate complex images with\nmultiple objects. \n\n"}
{"id": "1804.02339", "contents": "Title: Adaptive Three Operator Splitting Abstract: We propose and analyze an adaptive step-size variant of the Davis-Yin three\noperator splitting. This method can solve optimization problems composed by a\nsum of a smooth term for which we have access to its gradient and an arbitrary\nnumber of potentially non-smooth terms for which we have access to their\nproximal operator. The proposed method sets the step-size based on local\ninformation of the objective --hence allowing for larger step-sizes--, only\nrequires two extra function evaluations per iteration and does not depend on\nany step-size hyperparameter besides an initial estimate. We provide an\niteration complexity analysis that matches the best known results for the\nnon-adaptive variant: sublinear convergence for general convex functions and\nlinear convergence under strong convexity of the smooth term and smoothness of\none of the proximal terms. Finally, an empirical comparison with related\nmethods on 6 different problems illustrates the computational advantage of the\nproposed method. \n\n"}
{"id": "1804.02884", "contents": "Title: Policy Gradient With Value Function Approximation For Collective\n  Multiagent Planning Abstract: Decentralized (PO)MDPs provide an expressive framework for sequential\ndecision making in a multiagent system. Given their computational complexity,\nrecent research has focused on tractable yet practical subclasses of\nDec-POMDPs. We address such a subclass called CDEC-POMDP where the collective\nbehavior of a population of agents affects the joint-reward and environment\ndynamics. Our main contribution is an actor-critic (AC) reinforcement learning\nmethod for optimizing CDEC-POMDP policies. Vanilla AC has slow convergence for\nlarger problems. To address this, we show how a particular decomposition of the\napproximate action-value function over agents leads to effective updates, and\nalso derive a new way to train the critic based on local reward signals.\nComparisons on a synthetic benchmark and a real-world taxi fleet optimization\nproblem show that our new AC approach provides better quality solutions than\nprevious best approaches. \n\n"}
{"id": "1804.03176", "contents": "Title: Frank-Wolfe Splitting via Augmented Lagrangian Method Abstract: Minimizing a function over an intersection of convex sets is an important\ntask in optimization that is often much more challenging than minimizing it\nover each individual constraint set. While traditional methods such as\nFrank-Wolfe (FW) or proximal gradient descent assume access to a linear or\nquadratic oracle on the intersection, splitting techniques take advantage of\nthe structure of each sets, and only require access to the oracle on the\nindividual constraints. In this work, we develop and analyze the Frank-Wolfe\nAugmented Lagrangian (FW-AL) algorithm, a method for minimizing a smooth\nfunction over convex compact sets related by a \"linear consistency\" constraint\nthat only requires access to a linear minimization oracle over the individual\nconstraints. It is based on the Augmented Lagrangian Method (ALM), also known\nas Method of Multipliers, but unlike most existing splitting methods, it only\nrequires access to linear (instead of quadratic) minimization oracles. We use\nrecent advances in the analysis of Frank-Wolfe and the alternating direction\nmethod of multipliers algorithms to prove a sublinear convergence rate for\nFW-AL over general convex compact sets and a linear convergence rate for\npolytopes. \n\n"}
{"id": "1804.03980", "contents": "Title: Emergent Communication through Negotiation Abstract: Multi-agent reinforcement learning offers a way to study how communication\ncould emerge in communities of agents needing to solve specific problems. In\nthis paper, we study the emergence of communication in the negotiation\nenvironment, a semi-cooperative model of agent interaction. We introduce two\ncommunication protocols -- one grounded in the semantics of the game, and one\nwhich is \\textit{a priori} ungrounded and is a form of cheap talk. We show that\nself-interested agents can use the pre-grounded communication channel to\nnegotiate fairly, but are unable to effectively use the ungrounded channel.\nHowever, prosocial agents do learn to use cheap talk to find an optimal\nnegotiating strategy, suggesting that cooperation is necessary for language to\nemerge. We also study communication behaviour in a setting where one agent\ninteracts with agents in a community with different levels of prosociality and\nshow how agent identifiability can aid negotiation. \n\n"}
{"id": "1804.03984", "contents": "Title: Emergence of Linguistic Communication from Referential Games with\n  Symbolic and Pixel Input Abstract: The ability of algorithms to evolve or learn (compositional) communication\nprotocols has traditionally been studied in the language evolution literature\nthrough the use of emergent communication tasks. Here we scale up this research\nby using contemporary deep learning methods and by training\nreinforcement-learning neural network agents on referential communication\ngames. We extend previous work, in which agents were trained in symbolic\nenvironments, by developing agents which are able to learn from raw pixel data,\na more challenging and realistic input representation. We find that the degree\nof structure found in the input data affects the nature of the emerged\nprotocols, and thereby corroborate the hypothesis that structured compositional\nlanguage is most likely to emerge when agents perceive the world as being\nstructured. \n\n"}
{"id": "1804.04205", "contents": "Title: Learning Topics using Semantic Locality Abstract: The topic modeling discovers the latent topic probability of the given text\ndocuments. To generate the more meaningful topic that better represents the\ngiven document, we proposed a new feature extraction technique which can be\nused in the data preprocessing stage. The method consists of three steps.\nFirst, it generates the word/word-pair from every single document. Second, it\napplies a two-way TF-IDF algorithm to word/word-pair for semantic filtering.\nThird, it uses the K-means algorithm to merge the word pairs that have the\nsimilar semantic meaning.\n  Experiments are carried out on the Open Movie Database (OMDb), Reuters\nDataset and 20NewsGroup Dataset. The mean Average Precision score is used as\nthe evaluation metric. Comparing our results with other state-of-the-art topic\nmodels, such as Latent Dirichlet allocation and traditional Restricted\nBoltzmann Machines. Our proposed data preprocessing can improve the generated\ntopic accuracy by up to 12.99\\%. \n\n"}
{"id": "1804.04372", "contents": "Title: Infinite-Duration Poorman-Bidding Games Abstract: In two-player games on graphs, the players move a token through a graph to\nproduce an infinite path, which determines the winner or payoff of the game.\nSuch games are central in formal verification since they model the interaction\nbetween a non-terminating system and its environment. We study {\\em bidding\ngames} in which the players bid for the right to move the token. Two bidding\nrules have been defined. In {\\em Richman} bidding, in each round, the players\nsimultaneously submit bids, and the higher bidder moves the token and pays the\nother player. {\\em Poorman} bidding is similar except that the winner of the\nbidding pays the \"bank\" rather than the other player. While poorman\nreachability games have been studied before, we present, for the first time,\nresults on {\\em infinite-duration} poorman games. A central quantity in these\ngames is the {\\em ratio} between the two players' initial budgets. The\nquestions we study concern a necessary and sufficient ratio with which a player\ncan achieve a goal. For reachability objectives, such {\\em threshold ratios}\nare known to exist for both bidding rules. We show that the properties of\npoorman reachability games extend to complex qualitative objectives such as\nparity, similarly to the Richman case. Our most interesting results concern\nquantitative poorman games, namely poorman mean-payoff games, where we\nconstruct optimal strategies depending on the initial ratio, by showing a\nconnection with {\\em random-turn based games}. The connection in itself is\ninteresting, because it does not hold for reachability poorman games. We also\nsolve the complexity problems that arise in poorman bidding games. \n\n"}
{"id": "1804.04577", "contents": "Title: Feature-Based Aggregation and Deep Reinforcement Learning: A Survey and\n  Some New Implementations Abstract: In this paper we discuss policy iteration methods for approximate solution of\na finite-state discounted Markov decision problem, with a focus on\nfeature-based aggregation methods and their connection with deep reinforcement\nlearning schemes. We introduce features of the states of the original problem,\nand we formulate a smaller \"aggregate\" Markov decision problem, whose states\nrelate to the features. We discuss properties and possible implementations of\nthis type of aggregation, including a new approach to approximate policy\niteration. In this approach the policy improvement operation combines\nfeature-based aggregation with feature construction using deep neural networks\nor other calculations. We argue that the cost function of a policy may be\napproximated much more accurately by the nonlinear function of the features\nprovided by aggregation, than by the linear function of the features provided\nby neural network-based reinforcement learning, thereby potentially leading to\nmore effective policy improvement. \n\n"}
{"id": "1804.05464", "contents": "Title: On Gradient-Based Learning in Continuous Games Abstract: We formulate a general framework for competitive gradient-based learning that\nencompasses a wide breadth of multi-agent learning algorithms, and analyze the\nlimiting behavior of competitive gradient-based learning algorithms using\ndynamical systems theory. For both general-sum and potential games, we\ncharacterize a non-negligible subset of the local Nash equilibria that will be\navoided if each agent employs a gradient-based learning algorithm. We also shed\nlight on the issue of convergence to non-Nash strategies in general- and\nzero-sum games, which may have no relevance to the underlying game, and arise\nsolely due to the choice of algorithm. The existence and frequency of such\nstrategies may explain some of the difficulties encountered when using gradient\ndescent in zero-sum games as, e.g., in the training of generative adversarial\nnetworks. To reinforce the theoretical contributions, we provide empirical\nresults that highlight the frequency of linear quadratic dynamic games (a\nbenchmark for multi-agent reinforcement learning) that admit global Nash\nequilibria that are almost surely avoided by policy gradient. \n\n"}
{"id": "1804.05837", "contents": "Title: Walk-Steered Convolution for Graph Classification Abstract: Graph classification is a fundamental but challenging issue for numerous\nreal-world applications. Despite recent great progress in image/video\nclassification, convolutional neural networks (CNNs) cannot yet cater to graphs\nwell because of graphical non-Euclidean topology. In this work, we propose a\nwalk-steered convolutional (WSC) network to assemble the essential success of\nstandard convolutional neural networks as well as the powerful representation\nability of random walk. Instead of deterministic neighbor searching used in\nprevious graphical CNNs, we construct multi-scale walk fields (a.k.a. local\nreceptive fields) with random walk paths to depict subgraph structures and\nadvocate graph scalability. To express the internal variations of a walk field,\nGaussian mixture models are introduced to encode principal components of walk\npaths therein. As an analogy to a standard convolution kernel on image,\nGaussian models implicitly coordinate those unordered vertices/nodes and edges\nin a local receptive field after projecting to the gradient space of Gaussian\nparameters. We further stack graph coarsening upon Gaussian encoding by using\ndynamic clustering, such that high-level semantics of graph can be well learned\nlike the conventional pooling on image. The experimental results on several\npublic datasets demonstrate the superiority of our proposed WSC method over\nmany state-of-the-arts for graph classification. \n\n"}
{"id": "1804.06459", "contents": "Title: On Learning Intrinsic Rewards for Policy Gradient Methods Abstract: In many sequential decision making tasks, it is challenging to design reward\nfunctions that help an RL agent efficiently learn behavior that is considered\ngood by the agent designer. A number of different formulations of the\nreward-design problem, or close variants thereof, have been proposed in the\nliterature. In this paper we build on the Optimal Rewards Framework of Singh\net.al. that defines the optimal intrinsic reward function as one that when used\nby an RL agent achieves behavior that optimizes the task-specifying or\nextrinsic reward function. Previous work in this framework has shown how good\nintrinsic reward functions can be learned for lookahead search based planning\nagents. Whether it is possible to learn intrinsic reward functions for learning\nagents remains an open problem. In this paper we derive a novel algorithm for\nlearning intrinsic rewards for policy-gradient based learning agents. We\ncompare the performance of an augmented agent that uses our algorithm to\nprovide additive intrinsic rewards to an A2C-based policy learner (for Atari\ngames) and a PPO-based policy learner (for Mujoco domains) with a baseline\nagent that uses the same policy learners but with only extrinsic rewards. Our\nresults show improved performance on most but not all of the domains. \n\n"}
{"id": "1804.06909", "contents": "Title: Modeling and Simultaneously Removing Bias via Adversarial Neural\n  Networks Abstract: In real world systems, the predictions of deployed Machine Learned models\naffect the training data available to build subsequent models. This introduces\na bias in the training data that needs to be addressed. Existing solutions to\nthis problem attempt to resolve the problem by either casting this in the\nreinforcement learning framework or by quantifying the bias and re-weighting\nthe loss functions. In this work, we develop a novel Adversarial Neural Network\n(ANN) model, an alternative approach which creates a representation of the data\nthat is invariant to the bias. We take the Paid Search auction as our working\nexample and ad display position features as the confounding features for this\nsetting. We show the success of this approach empirically on both synthetic\ndata as well as real world paid search auction data from a major search engine. \n\n"}
{"id": "1804.07795", "contents": "Title: Stochastic subgradient method converges on tame functions Abstract: This work considers the question: what convergence guarantees does the\nstochastic subgradient method have in the absence of smoothness and convexity?\nWe prove that the stochastic subgradient method, on any semialgebraic locally\nLipschitz function, produces limit points that are all first-order stationary.\nMore generally, our result applies to any function with a Whitney stratifiable\ngraph. In particular, this work endows the stochastic subgradient method, and\nits proximal extension, with rigorous convergence guarantees for a wide class\nof problems arising in data science---including all popular deep learning\narchitectures. \n\n"}
{"id": "1804.08219", "contents": "Title: Adaptive Performance Assessment For Drivers Through Behavioral Advantage Abstract: The potential positive impact of autonomous driving and driver assistance\ntechnolo- gies have been a major impetus over the last decade. On the flip\nside, it has been a challenging problem to analyze the performance of human\ndrivers or autonomous driving agents quantitatively. In this work, we propose a\ngeneric method that compares the performance of drivers or autonomous driving\nagents even if the environmental conditions are different, by using the driver\nbehavioral advantage instead of absolute metrics, which efficiently removes the\nenvironmental factors. A concrete application of the method is also presented,\nwhere the performance of more than 100 truck drivers was evaluated and ranked\nin terms of fuel efficiency, covering more than 90,000 trips spanning an\naverage of 300 miles in a variety of driving conditions and environments. \n\n"}
{"id": "1804.09554", "contents": "Title: Stochastic Conditional Gradient Methods: From Convex Minimization to\n  Submodular Maximization Abstract: This paper considers stochastic optimization problems for a large class of\nobjective functions, including convex and continuous submodular. Stochastic\nproximal gradient methods have been widely used to solve such problems;\nhowever, their applicability remains limited when the problem dimension is\nlarge and the projection onto a convex set is costly. Instead, stochastic\nconditional gradient methods are proposed as an alternative solution relying on\n(i) Approximating gradients via a simple averaging technique requiring a single\nstochastic gradient evaluation per iteration; (ii) Solving a linear program to\ncompute the descent/ascent direction. The averaging technique reduces the noise\nof gradient approximations as time progresses, and replacing projection step in\nproximal methods by a linear program lowers the computational complexity of\neach iteration. We show that under convexity and smoothness assumptions, our\nproposed method converges to the optimal objective function value at a\nsublinear rate of $O(1/t^{1/3})$. Further, for a monotone and continuous\nDR-submodular function and subject to a general convex body constraint, we\nprove that our proposed method achieves a $((1-1/e)OPT-\\eps)$ guarantee with\n$O(1/\\eps^3)$ stochastic gradient computations. This guarantee matches the\nknown hardness results and closes the gap between deterministic and stochastic\ncontinuous submodular maximization. Additionally, we obtain $((1/e)OPT -\\eps)$\nguarantee after using $O(1/\\eps^3)$ stochastic gradients for the case that the\nobjective function is continuous DR-submodular but non-monotone and the\nconstraint set is down-closed. By using stochastic continuous optimization as\nan interface, we provide the first $(1-1/e)$ tight approximation guarantee for\nmaximizing a monotone but stochastic submodular set function subject to a\nmatroid constraint and $(1/e)$ approximation guarantee for the non-monotone\ncase. \n\n"}
{"id": "1804.09672", "contents": "Title: Flow Equilibria via Online Surge Pricing Abstract: We explore issues of dynamic supply and demand in ride sharing services such\nas Lyft and Uber, where demand fluctuates over time and geographic location. We\nseek to maximize social welfare which depends on taxicab and passenger\nlocations, passenger valuations for service, and the distances between taxicabs\nand passengers. Our only means of control is to set surge prices, then taxicabs\nand passengers maximize their utilities subject to these prices. We study two\nrelated models: a continuous passenger-taxicab setting, similar to the Wardrop\nmodel, and a discrete passenger-taxicab setting. In the continuous setting,\nevery location is occupied by a set of infinitesimal strategic taxicabs and a\nset of infinitesimal non-strategic passengers. In the discrete setting every\nlocation is occupied by a set of strategic agents, taxicabs and passengers,\npassengers have differing values for service. We expand the continuous model to\na time-dependent setting and study the corresponding online environment.\n  Surge prices are in passenger-taxicab equilibrium if there exists a min cost\nflow that moves taxicabs about such that (a) every taxicab follows a best\nresponse, (b) all strategic passengers at $v$ with value above the surge price\n$r_v$ for $v$, are served and (c) no strategic passengers with value below\n$r_v$ are served (non-strategic infinitesimal passengers are always served).\n  This paper computes surge prices such that resulting passenger-taxicab\nequilibrium maximizes social welfare, and the computation of such surge prices\nis in poly time. Moreover, it is a dominant strategy for passengers to reveal\ntheir true values.\n  We seek to maximize social welfare in the online environment, and derive\ntight competitive ratio bounds to this end. Our online algorithms make use of\nthe surge prices computed over time and geographic location, inducing\nsuccessive passenger-taxicab equilibria. \n\n"}
{"id": "1804.10204", "contents": "Title: End-to-End Speech Separation with Unfolded Iterative Phase\n  Reconstruction Abstract: This paper proposes an end-to-end approach for single-channel\nspeaker-independent multi-speaker speech separation, where time-frequency (T-F)\nmasking, the short-time Fourier transform (STFT), and its inverse are\nrepresented as layers within a deep network. Previous approaches, rather than\ncomputing a loss on the reconstructed signal, used a surrogate loss based on\nthe target STFT magnitudes. This ignores reconstruction error introduced by\nphase inconsistency. In our approach, the loss function is directly defined on\nthe reconstructed signals, which are optimized for best separation. In\naddition, we train through unfolded iterations of a phase reconstruction\nalgorithm, represented as a series of STFT and inverse STFT layers. While mask\nvalues are typically limited to lie between zero and one for approaches using\nthe mixture phase for reconstruction, this limitation is less relevant if the\nestimated magnitudes are to be used together with phase reconstruction. We thus\npropose several novel activation functions for the output layer of the T-F\nmasking, to allow mask values beyond one. On the publicly-available wsj0-2mix\ndataset, our approach achieves state-of-the-art 12.6 dB scale-invariant\nsignal-to-distortion ratio (SI-SDR) and 13.1 dB SDR, revealing new\npossibilities for deep learning based phase reconstruction and representing a\nfundamental progress towards solving the notoriously-hard cocktail party\nproblem. \n\n"}
{"id": "1804.10272", "contents": "Title: Network Transplanting Abstract: This paper focuses on a new task, i.e., transplanting a\ncategory-and-task-specific neural network to a generic, modular network without\nstrong supervision. We design an functionally interpretable structure for the\ngeneric network. Like building LEGO blocks, we teach the generic network a new\ncategory by directly transplanting the module corresponding to the category\nfrom a pre-trained network with a few or even without sample annotations. Our\nmethod incrementally adds new categories to the generic network but does not\naffect representations of existing categories. In this way, our method breaks\nthe typical bottleneck of learning a net for massive tasks and categories, i.e.\nthe requirement of collecting samples for all tasks and categories at the same\ntime before the learning begins. Thus, we use a new distillation algorithm,\nnamely back-distillation, to overcome specific challenges of network\ntransplanting. Our method without training samples even outperformed the\nbaseline with 100 training samples. \n\n"}
{"id": "1804.10273", "contents": "Title: A telescoping Bregmanian proximal gradient method without the global\n  Lipschitz continuity assumption Abstract: The problem of minimization of the sum of two convex functions has various\ntheoretical and real-world applications. One of the popular methods for solving\nthis problem is the proximal gradient method (proximal forward-backward\nalgorithm). A very common assumption in the use of this method is that the\ngradient of the smooth term is globally Lipschitz continuous. However, this\nassumption is not always satisfied in practice, thus casting a limitation on\nthe method. In this paper, we discuss, in a wide class of finite and\ninfinite-dimensional spaces, a new variant of the proximal gradient method\nwhich does not impose the above-mentioned global Lipschitz continuity\nassumption. A key contribution of the method is the dependence of the iterative\nsteps on a certain telescopic decomposition of the constraint set into subsets.\nMoreover, we use a Bregman divergence in the proximal forward-backward\noperation. Under certain practical conditions, a non-asymptotic rate of\nconvergence (that is, in the function values) is established, as well as the\nweak convergence of the whole sequence to a minimizer. We also obtain a few\nauxiliary results of independent interest. \n\n"}
{"id": "1804.10488", "contents": "Title: Offline Evaluation of Ranking Policies with Click Models Abstract: Many web systems rank and present a list of items to users, from recommender\nsystems to search and advertising. An important problem in practice is to\nevaluate new ranking policies offline and optimize them before they are\ndeployed. We address this problem by proposing evaluation algorithms for\nestimating the expected number of clicks on ranked lists from historical logged\ndata. The existing algorithms are not guaranteed to be statistically efficient\nin our problem because the number of recommended lists can grow exponentially\nwith their length. To overcome this challenge, we use models of user\ninteraction with the list of items, the so-called click models, to construct\nestimators that learn statistically efficiently. We analyze our estimators and\nprove that they are more efficient than the estimators that do not use the\nstructure of the click model, under the assumption that the click model holds.\nWe evaluate our estimators in a series of experiments on a real-world dataset\nand show that they consistently outperform prior estimators. \n\n"}
{"id": "1804.10512", "contents": "Title: Probabilistic Verification for Obviously Strategyproof Mechanisms Abstract: Obviously strategyproof (OSP) mechanisms maintain the incentive compatibility\nof agents that are not fully rational. They have been object of a number of\nstudies since their recent definition. A research agenda, initiated in\n[Ferraioli&Ventre, AAAI 2017], is to find a small (possibly, the smallest) set\nof conditions allowing to implement an OSP mechanism. To this aim, we define a\nmodel of probabilistic verification wherein agents are caught misbehaving with\na certain probability, and show how OSP mechanisms can implement every social\nchoice function at the cost of either imposing very large fines for lies or\nverifying a linear number of agents. \n\n"}
{"id": "1804.10742", "contents": "Title: Novel Prediction Techniques Based on Clusterwise Linear Regression Abstract: In this paper we explore different regression models based on Clusterwise\nLinear Regression (CLR). CLR aims to find the partition of the data into $k$\nclusters, such that linear regressions fitted to each of the clusters minimize\noverall mean squared error on the whole data. The main obstacle preventing to\nuse found regression models for prediction on the unseen test points is the\nabsence of a reasonable way to obtain CLR cluster labels when the values of\ntarget variable are unknown. In this paper we propose two novel approaches on\nhow to solve this problem. The first approach, predictive CLR builds a separate\nclassification model to predict test CLR labels. The second approach,\nconstrained CLR utilizes a set of user-specified constraints that enforce\ncertain points to go to the same clusters. Assuming the constraint values are\nknown for the test points, they can be directly used to assign CLR labels. We\nevaluate these two approaches on three UCI ML datasets as well as on a large\ncorpus of health insurance claims. We show that both of the proposed algorithms\nsignificantly improve over the known CLR-based regression methods. Moreover,\npredictive CLR consistently outperforms linear regression and random forest,\nand shows comparable performance to support vector regression on UCI ML\ndatasets. The constrained CLR approach achieves the best performance on the\nhealth insurance dataset, while enjoying only $\\approx 20$ times increased\ncomputational time over linear regression. \n\n"}
{"id": "1805.00521", "contents": "Title: Direct Runge-Kutta Discretization Achieves Acceleration Abstract: We study gradient-based optimization methods obtained by directly\ndiscretizing a second-order ordinary differential equation (ODE) related to the\ncontinuous limit of Nesterov's accelerated gradient method. When the function\nis smooth enough, we show that acceleration can be achieved by a stable\ndiscretization of this ODE using standard Runge-Kutta integrators.\nSpecifically, we prove that under Lipschitz-gradient, convexity and\norder-$(s+2)$ differentiability assumptions, the sequence of iterates generated\nby discretizing the proposed second-order ODE converges to the optimal solution\nat a rate of $\\mathcal{O}({N^{-2\\frac{s}{s+1}}})$, where $s$ is the order of\nthe Runge-Kutta numerical integrator. Furthermore, we introduce a new local\nflatness condition on the objective, under which rates even faster than\n$\\mathcal{O}(N^{-2})$ can be achieved with low-order integrators and only\ngradient information. Notably, this flatness condition is satisfied by several\nstandard loss functions used in machine learning. We provide numerical\nexperiments that verify the theoretical rates predicted by our results. \n\n"}
{"id": "1805.00982", "contents": "Title: k-SVRG: Variance Reduction for Large Scale Optimization Abstract: Variance reduced stochastic gradient (SGD) methods converge significantly\nfaster than the vanilla SGD counterpart. However, these methods are not very\npractical on large scale problems, as they either i) require frequent passes\nover the full data to recompute gradients---without making any progress during\nthis time (like for SVRG), or ii)~they require additional memory that can\nsurpass the size of the input problem (like for SAGA). In this work, we propose\n$k$-SVRG that addresses these issues by making best use of the \\emph{available}\nmemory and minimizes the stalling phases without progress. We prove linear\nconvergence of $k$-SVRG on strongly convex problems and convergence to\nstationary points on non-convex problems. Numerical experiments show the\neffectiveness of our method. \n\n"}
{"id": "1805.02087", "contents": "Title: A Constraint-Based Algorithm For Causal Discovery with Cycles, Latent\n  Variables and Selection Bias Abstract: Causal processes in nature may contain cycles, and real datasets may violate\ncausal sufficiency as well as contain selection bias. No constraint-based\ncausal discovery algorithm can currently handle cycles, latent variables and\nselection bias (CLS) simultaneously. I therefore introduce an algorithm called\nCyclic Causal Inference (CCI) that makes sound inferences with a conditional\nindependence oracle under CLS, provided that we can represent the cyclic causal\nprocess as a non-recursive linear structural equation model with independent\nerrors. Empirical results show that CCI outperforms CCD in the cyclic case as\nwell as rivals FCI and RFCI in the acyclic case. \n\n"}
{"id": "1805.02587", "contents": "Title: Sharp Analysis of a Simple Model for Random Forests Abstract: Random forests have become an important tool for improving accuracy in\nregression and classification problems since their inception by Leo Breiman in\n2001. In this paper, we revisit a historically important random forest model\noriginally proposed by Breiman in 2004 and later studied by G\\'erard Biau in\n2012, where a feature is selected at random and the splits occurs at the\nmidpoint of the node along the chosen feature. If the regression function is\nLipschitz and depends only on a small subset of $ S $ out of $ d $ features, we\nshow that, given access to $ n $ observations and properly tuned split\nprobabilities, the mean-squared prediction error is $ O((n(\\log\nn)^{(S-1)/2})^{-\\frac{1}{S\\log2+1}}) $. This positively answers an outstanding\nquestion of Biau about whether the rate of convergence for this random forest\nmodel could be improved. Furthermore, by a refined analysis of the\napproximation and estimation errors for linear models, we show that this rate\ncannot be improved in general. Finally, we generalize our analysis and improve\nextant prediction error bounds for another random forest model in which each\ntree is constructed from subsampled data and the splits are performed at the\nempirical median along a chosen feature. \n\n"}
{"id": "1805.03581", "contents": "Title: Loyalty Programs in the Sharing Economy: Optimality and Competition Abstract: Loyalty programs are important tools for sharing platforms seeking to grow\nsupply. Online sharing platforms use loyalty programs to heavily subsidize\nresource providers, encouraging participation and boosting supply. As the\nsharing economy has evolved and competition has increased, the design of\nloyalty programs has begun to play a crucial role in the pursuit of maximal\nrevenue. In this paper, we first characterize the optimal loyalty program for a\nplatform with homogeneous users. We then show that optimal revenue in a\nheterogeneous market can be achieved by a class of multi-threshold loyalty\nprogram (MTLP) which admits a simple implementation-friendly structure. We also\nstudy the performance of loyalty programs in a setting with two competing\nsharing platforms, showing that the degree of heterogeneity is a crucial factor\nfor both loyalty programs and pricing strategies. Our results show that\nsophisticated loyalty programs that reward suppliers via stepwise linear\nfunctions outperform simple sign-up bonuses, which give them a one time reward\nfor participating. \n\n"}
{"id": "1805.03642", "contents": "Title: Adversarial Contrastive Estimation Abstract: Learning by contrasting positive and negative samples is a general strategy\nadopted by many methods. Noise contrastive estimation (NCE) for word embeddings\nand translating embeddings for knowledge graphs are examples in NLP employing\nthis approach. In this work, we view contrastive learning as an abstraction of\nall such methods and augment the negative sampler into a mixture distribution\ncontaining an adversarially learned sampler. The resulting adaptive sampler\nfinds harder negative examples, which forces the main model to learn a better\nrepresentation of the data. We evaluate our proposal on learning word\nembeddings, order embeddings and knowledge graph embeddings and observe both\nfaster convergence and improved results on multiple metrics. \n\n"}
{"id": "1805.03737", "contents": "Title: Graph Neural Networks for Learning Robot Team Coordination Abstract: This paper shows how Graph Neural Networks can be used for learning\ndistributed coordination mechanisms in connected teams of robots. We capture\nthe relational aspect of robot coordination by modeling the robot team as a\ngraph, where each robot is a node, and edges represent communication links.\nDuring training, robots learn how to pass messages and update internal states,\nso that a target behavior is reached. As a proxy for more complex problems,\nthis short paper considers the problem where each robot must locally estimate\nthe algebraic connectivity of the team's network topology. \n\n"}
{"id": "1805.04276", "contents": "Title: Leveraging Grammar and Reinforcement Learning for Neural Program\n  Synthesis Abstract: Program synthesis is the task of automatically generating a program\nconsistent with a specification. Recent years have seen proposal of a number of\nneural approaches for program synthesis, many of which adopt a sequence\ngeneration paradigm similar to neural machine translation, in which\nsequence-to-sequence models are trained to maximize the likelihood of known\nreference programs. While achieving impressive results, this strategy has two\nkey limitations. First, it ignores Program Aliasing: the fact that many\ndifferent programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many\nsemantically correct programs, which can adversely affect the synthesizer\nperformance. Second, this strategy overlooks the fact that programs have a\nstrict syntax that can be efficiently checked. To address the first limitation,\nwe perform reinforcement learning on top of a supervised model with an\nobjective that explicitly maximizes the likelihood of generating semantically\ncorrect programs. For addressing the second limitation, we introduce a training\nprocedure that directly maximizes the probability of generating syntactically\ncorrect programs that fulfill the specification. We show that our contributions\nlead to improved accuracy of the models, especially in cases where the training\ndata is limited. \n\n"}
{"id": "1805.05838", "contents": "Title: Gradient-Leaks: Understanding and Controlling Deanonymization in\n  Federated Learning Abstract: Federated Learning (FL) systems are gaining popularity as a solution to\ntraining Machine Learning (ML) models from large-scale user data collected on\npersonal devices (e.g., smartphones) without their raw data leaving the device.\nAt the core of FL is a network of anonymous user devices sharing training\ninformation (model parameter updates) computed locally on personal data.\nHowever, the type and degree to which user-specific information is encoded in\nthe model updates is poorly understood. In this paper, we identify model\nupdates encode subtle variations in which users capture and generate data. The\nvariations provide a strong statistical signal, allowing an adversary to\neffectively deanonymize participating devices using a limited set of auxiliary\ndata. We analyze resulting deanonymization attacks on diverse tasks on\nreal-world (anonymized) user-generated data across a range of closed- and\nopen-world scenarios. We study various strategies to mitigate the risks of\ndeanonymization. As random perturbation methods do not offer convincing\noperating points, we propose data-augmentation strategies which introduces\nadversarial biases in device data and thereby, offer substantial protection\nagainst deanonymization threats with little effect on utility. \n\n"}
{"id": "1805.06126", "contents": "Title: Market Self-Learning of Signals, Impact and Optimal Trading: Invisible\n  Hand Inference with Free Energy Abstract: We present a simple model of a non-equilibrium self-organizing market where\nasset prices are partially driven by investment decisions of a bounded-rational\nagent. The agent acts in a stochastic market environment driven by various\nexogenous \"alpha\" signals, agent's own actions (via market impact), and noise.\nUnlike traditional agent-based models, our agent aggregates all traders in the\nmarket, rather than being a representative agent. Therefore, it can be\nidentified with a bounded-rational component of the market itself, providing a\nparticular implementation of an Invisible Hand market mechanism. In such\nsetting, market dynamics are modeled as a fictitious self-play of such\nbounded-rational market-agent in its adversarial stochastic environment. As\nrewards obtained by such self-playing market agent are not observed from market\ndata, we formulate and solve a simple model of such market dynamics based on a\nneuroscience-inspired Bounded Rational Information Theoretic Inverse\nReinforcement Learning (BRIT-IRL). This results in effective asset price\ndynamics with a non-linear mean reversion - which in our model is generated\ndynamically, rather than being postulated. We argue that our model can be used\nin a similar way to the Black-Litterman model. In particular, it represents, in\na simple modeling framework, market views of common predictive signals, market\nimpacts and implied optimal dynamic portfolio allocations, and can be used to\nassess values of private signals. Moreover, it allows one to quantify a\n\"market-implied\" optimal investment strategy, along with a measure of market\nrationality. Our approach is numerically light, and can be implemented using\nstandard off-the-shelf software such as TensorFlow. \n\n"}
{"id": "1805.06137", "contents": "Title: An Algorithmic Framework of Variable Metric Over-Relaxed Hybrid Proximal\n  Extra-Gradient Method Abstract: We propose a novel algorithmic framework of Variable Metric Over-Relaxed\nHybrid Proximal Extra-gradient (VMOR-HPE) method with a global convergence\nguarantee for the maximal monotone operator inclusion problem. Its iteration\ncomplexities and local linear convergence rate are provided, which\ntheoretically demonstrate that a large over-relaxed step-size contributes to\naccelerating the proposed VMOR-HPE as a byproduct. Specifically, we find that a\nlarge class of primal and primal-dual operator splitting algorithms are all\nspecial cases of VMOR-HPE. Hence, the proposed framework offers a new insight\ninto these operator splitting algorithms. In addition, we apply VMOR-HPE to the\nKarush-Kuhn-Tucker (KKT) generalized equation of linear equality constrained\nmulti-block composite convex optimization, yielding a new algorithm, namely\nnonsymmetric Proximal Alternating Direction Method of Multipliers with a\npreconditioned Extra-gradient step in which the preconditioned metric is\ngenerated by a blockwise Barzilai-Borwein line search technique (PADMM-EBB). We\nalso establish iteration complexities of PADMM-EBB in terms of the KKT\nresidual. Finally, we apply PADMM-EBB to handle the nonnegative dual graph\nregularized low-rank representation problem. Promising results on synthetic and\nreal datasets corroborate the efficacy of PADMM-EBB. \n\n"}
{"id": "1805.06191", "contents": "Title: Fair Allocation of Indivisible Items With Externalities Abstract: One of the important yet insufficiently studied subjects in fair allocation\nis the externality effect among agents. For a resource allocation problem,\nexternalities imply that a bundle allocated to an agent may affect the\nutilities of other agents.\n  In this paper, we conduct a study of fair allocation of indivisible goods\nwhen the externalities are not negligible. We present a simple and natural\nmodel, namely \\emph{network externalities}, to capture the externalities. To\nevaluate fairness in the network externalities model, we generalize the idea\nbehind the notion of maximin-share ($\\MMS$) to achieve a new criterion, namely,\n\\emph{extended-maximin-share} ($\\EMMS$). Next, we consider two problems\nconcerning our model.\n  First, we discuss the computational aspects of finding the value of $\\EMMS$\nfor every agent. For this, we introduce a generalized form of partitioning\nproblem that includes many famous partitioning problems such as maximin,\nminimax, and leximin partitioning problems. We show that a $1/2$-approximation\nalgorithm exists for this partitioning problem.\n  Next, we investigate on finding approximately optimal $\\EMMS$ allocations.\nThat is, allocations that guarantee every agent a utility of at least a\nfraction of his extended-maximin-share. We show that under a natural assumption\nthat the agents are $\\alpha$-self-reliant, an $\\alpha/2$-$\\EMMS$ allocation\nalways exists. The combination of this with the former result yields a\npolynomial-time $\\alpha/4$-$\\EMMS$ allocation algorithm. \n\n"}
{"id": "1805.06387", "contents": "Title: Near-Optimal Communication Lower Bounds for Approximate Nash Equilibria Abstract: We prove an $N^{2-o(1)}$ lower bound on the randomized communication\ncomplexity of finding an $\\epsilon$-approximate Nash equilibrium (for constant\n$\\epsilon>0$) in a two-player $N\\times N$ game. \n\n"}
{"id": "1805.06605", "contents": "Title: Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using\n  Generative Models Abstract: In recent years, deep neural network approaches have been widely adopted for\nmachine learning tasks, including classification. However, they were shown to\nbe vulnerable to adversarial perturbations: carefully crafted small\nperturbations can cause misclassification of legitimate images. We propose\nDefense-GAN, a new framework leveraging the expressive capability of generative\nmodels to defend deep neural networks against such attacks. Defense-GAN is\ntrained to model the distribution of unperturbed images. At inference time, it\nfinds a close output to a given image which does not contain the adversarial\nchanges. This output is then fed to the classifier. Our proposed method can be\nused with any classification model and does not modify the classifier structure\nor training procedure. It can also be used as a defense against any attack as\nit does not assume knowledge of the process for generating the adversarial\nexamples. We empirically show that Defense-GAN is consistently effective\nagainst different attack methods and improves on existing defense strategies.\nOur code has been made publicly available at\nhttps://github.com/kabkabm/defensegan \n\n"}
{"id": "1805.07010", "contents": "Title: Learning Permutations with Sinkhorn Policy Gradient Abstract: Many problems at the intersection of combinatorics and computer science\nrequire solving for a permutation that optimally matches, ranks, or sorts some\ndata. These problems usually have a task-specific, often non-differentiable\nobjective function that data-driven algorithms can use as a learning signal. In\nthis paper, we propose the Sinkhorn Policy Gradient (SPG) algorithm for\nlearning policies on permutation matrices. The actor-critic neural network\narchitecture we introduce for SPG uniquely decouples representation learning of\nthe state space from the highly-structured action space of permutations with a\ntemperature-controlled Sinkhorn layer. The Sinkhorn layer produces continuous\nrelaxations of permutation matrices so that the actor-critic architecture can\nbe trained end-to-end. Our empirical results show that agents trained with SPG\ncan perform competitively on sorting, the Euclidean TSP, and matching tasks. We\nalso observe that SPG is significantly more data efficient at the matching task\nthan the baseline methods, which indicates that SPG is conducive to learning\nrepresentations that are useful for reasoning about permutations. \n\n"}
{"id": "1805.07762", "contents": "Title: Selfishness need not be bad: a general proof Abstract: This article studies the user behavior in non-atomic congestion games. We\nconsider non-atomic congestion games with continuous and non-decreasing\nfunctions and investigate the limit of the price of anarchy when the total user\nvolume approaches infinity. We deepen the knowledge on {\\em asymptotically well\ndesigned games} \\cite{Wu2017Selfishness}, {\\em limit games}\n\\cite{Wu2017Selfishness}, {\\em scalability} \\cite{Wu2017Selfishness} and {\\em\ngaugeability} \\cite{Colini2017b} that were recently used in the limit analyses\nof the price of anarchy for non-atomic congestion games. We develop a unified\nframework and derive new techniques that allow a general limit analysis of the\nprice of anarchy. With these new techniques, we are able to prove a global\nconvergence on the price of anarchy for non-atomic congestion games with\narbitrary polynomial price functions and arbitrary user volume vector\nsequences. Moreover, we show that these new techniques are very flexible and\nrobust and apply also to non-atomic congestion games with price functions of\nother types. In particular, we prove that non-atomic congestion games with\nregularly varying price functions are also asymptotically well designed,\nprovided that the price functions are slightly restricted. Our results greatly\ngeneralize recent results. In particular, our results further support the view\nwith a general proof that selfishness need not be bad for non-atomic congestion\ngames. \n\n"}
{"id": "1805.07984", "contents": "Title: Adversarial Attacks on Neural Networks for Graph Data Abstract: Deep learning models for graphs have achieved strong performance for the task\nof node classification. Despite their proliferation, currently there is no\nstudy of their robustness to adversarial attacks. Yet, in domains where they\nare likely to be used, e.g. the web, adversaries are common. Can deep learning\nmodels for graphs be easily fooled? In this work, we introduce the first study\nof adversarial attacks on attributed graphs, specifically focusing on models\nexploiting ideas of graph convolutions. In addition to attacks at test time, we\ntackle the more challenging class of poisoning/causative attacks, which focus\non the training phase of a machine learning model. We generate adversarial\nperturbations targeting the node's features and the graph structure, thus,\ntaking the dependencies between instances in account. Moreover, we ensure that\nthe perturbations remain unnoticeable by preserving important data\ncharacteristics. To cope with the underlying discrete domain we propose an\nefficient algorithm Nettack exploiting incremental computations. Our\nexperimental study shows that accuracy of node classification significantly\ndrops even when performing only few perturbations. Even more, our attacks are\ntransferable: the learned attacks generalize to other state-of-the-art node\nclassification models and unsupervised approaches, and likewise are successful\neven when only limited knowledge about the graph is given. \n\n"}
{"id": "1805.08268", "contents": "Title: Optimal Sketching Bounds for Exp-concave Stochastic Minimization Abstract: We derive optimal statistical and computational complexity bounds for\nexp-concave stochastic minimization in terms of the effective dimension. For\ncommon eigendecay patterns of the population covariance matrix, this quantity\nis significantly smaller than the ambient dimension. Our results reveal\ninteresting connections to sketching results in numerical linear algebra. In\nparticular, our statistical analysis highlights a novel and natural\nrelationship between algorithmic stability of empirical risk minimization and\nridge leverage scores, which play significant role in sketching-based methods.\nOur main computational result is a fast implementation of a\nsketch-to-precondition approach in the context of exp-concave empirical risk\nminimization. \n\n"}
{"id": "1805.08311", "contents": "Title: AgileNet: Lightweight Dictionary-based Few-shot Learning Abstract: The success of deep learning models is heavily tied to the use of massive\namount of labeled data and excessively long training time. With the emergence\nof intelligent edge applications that use these models, the critical challenge\nis to obtain the same inference capability on a resource-constrained device\nwhile providing adaptability to cope with the dynamic changes in the data. We\npropose AgileNet, a novel lightweight dictionary-based few-shot learning\nmethodology which provides reduced complexity deep neural network for efficient\nexecution at the edge while enabling low-cost updates to capture the dynamics\nof the new data. Evaluations of state-of-the-art few-shot learning benchmarks\ndemonstrate the superior accuracy of AgileNet compared to prior arts.\nAdditionally, AgileNet is the first few-shot learning approach that prevents\nmodel updates by eliminating the knowledge obtained from the primary training.\nThis property is ensured through the dictionaries learned by our novel\nend-to-end structured decomposition, which also reduces the memory footprint\nand computation complexity to match the edge device constraints. \n\n"}
{"id": "1805.08622", "contents": "Title: Transitions, Losses, and Re-parameterizations: Elements of Prediction\n  Games Abstract: This thesis presents some geometric insights into three different types of\ntwo player prediction games -- namely general learning task, prediction with\nexpert advice, and online convex optimization. These games differ in the nature\nof the opponent (stochastic, adversarial, or intermediate), the order of the\nplayers' move, and the utility function. The insights shed some light on the\nunderstanding of the intrinsic barriers of the prediction problems and the\ndesign of computationally efficient learning algorithms with strong theoretical\nguarantees (such as generalizability, statistical consistency, and constant\nregret etc.). \n\n"}
{"id": "1805.08832", "contents": "Title: The Impact of Uncle Rewards on Selfish Mining in Ethereum Abstract: Many of today's crypto currencies use blockchains as decentralized ledgers\nand secure them with proof of work. In case of a fork of the chain, Bitcoin's\nrule for achieving consensus is selecting the longest chain and discarding the\nother chain as stale. It has been demonstrated that this consensus rule has a\nweakness against selfish mining in which the selfish miner exploits the\nvariance in block generation by partially withholding blocks. In Ethereum,\nhowever, under certain conditions stale blocks don't have to be discarded but\ncan be referenced from the main chain as uncle blocks yielding a partial\nreward. This concept limits the impact of network delays on the expected\nrevenue for miners. But the concept also reduces the risk for a selfish miner\nto gain no rewards from withholding a freshly minted block. This paper uses a\nMonte Carlo simulation to quantify the effect of uncle blocks both to the\nprofitability of selfish mining and the blockchain's security in Ethereum\n(ETH). A brief outlook about a recent Ethereum Classic (ETC) improvement\nproposal that weighs uncle blocks during the selection of the main chain will\nbe given. \n\n"}
{"id": "1805.08845", "contents": "Title: Counterfactual Mean Embeddings Abstract: Counterfactual inference has become a ubiquitous tool in online\nadvertisement, recommendation systems, medical diagnosis, and econometrics.\nAccurate modeling of outcome distributions associated with different\ninterventions -- known as counterfactual distributions -- is crucial for the\nsuccess of these applications. In this work, we propose to model counterfactual\ndistributions using a novel Hilbert space representation called counterfactual\nmean embedding (CME). The CME embeds the associated counterfactual distribution\ninto a reproducing kernel Hilbert space (RKHS) endowed with a positive definite\nkernel, which allows us to perform causal inference over the entire landscape\nof the counterfactual distribution. Based on this representation, we propose a\ndistributional treatment effect (DTE) that can quantify the causal effect over\nentire outcome distributions. Our approach is nonparametric as the CME can be\nestimated under the unconfoundedness assumption from observational data without\nrequiring any parametric assumption about the underlying distributions. We also\nestablish a rate of convergence of the proposed estimator which depends on the\nsmoothness of the conditional mean and the Radon-Nikodym derivative of the\nunderlying marginal distributions. Furthermore, our framework allows for more\ncomplex outcomes such as images, sequences, and graphs. Our experimental\nresults on synthetic data and off-policy evaluation tasks demonstrate the\nadvantages of the proposed estimator. \n\n"}
{"id": "1805.09298", "contents": "Title: Learning towards Minimum Hyperspherical Energy Abstract: Neural networks are a powerful class of nonlinear functions that can be\ntrained end-to-end on various applications. While the over-parametrization\nnature in many neural networks renders the ability to fit complex functions and\nthe strong representation power to handle challenging tasks, it also leads to\nhighly correlated neurons that can hurt the generalization ability and incur\nunnecessary computation cost. As a result, how to regularize the network to\navoid undesired representation redundancy becomes an important issue. To this\nend, we draw inspiration from a well-known problem in physics -- Thomson\nproblem, where one seeks to find a state that distributes N electrons on a unit\nsphere as evenly as possible with minimum potential energy. In light of this\nintuition, we reduce the redundancy regularization problem to generic energy\nminimization, and propose a minimum hyperspherical energy (MHE) objective as\ngeneric regularization for neural networks. We also propose a few novel\nvariants of MHE, and provide some insights from a theoretical point of view.\nFinally, we apply neural networks with MHE regularization to several\nchallenging tasks. Extensive experiments demonstrate the effectiveness of our\nintuition, by showing the superior performance with MHE regularization. \n\n"}
{"id": "1805.09386", "contents": "Title: Predictive Local Smoothness for Stochastic Gradient Methods Abstract: Stochastic gradient methods are dominant in nonconvex optimization especially\nfor deep models but have low asymptotical convergence due to the fixed\nsmoothness. To address this problem, we propose a simple yet effective method\nfor improving stochastic gradient methods named predictive local smoothness\n(PLS). First, we create a convergence condition to build a learning rate which\nvaries adaptively with local smoothness. Second, the local smoothness can be\npredicted by the latest gradients. Third, we use the adaptive learning rate to\nupdate the stochastic gradients for exploring linear convergence rates. By\napplying the PLS method, we implement new variants of three popular algorithms:\nPLS-stochastic gradient descent (PLS-SGD), PLS-accelerated SGD (PLS-AccSGD),\nand PLS-AMSGrad. Moreover, we provide much simpler proofs to ensure their\nlinear convergence. Empirical results show that the variants have better\nperformance gains than the popular algorithms, such as, faster convergence and\nalleviating explosion and vanish of gradients. \n\n"}
{"id": "1805.09547", "contents": "Title: Interpretable and Compositional Relation Learning by Joint Training with\n  an Autoencoder Abstract: Embedding models for entities and relations are extremely useful for\nrecovering missing facts in a knowledge base. Intuitively, a relation can be\nmodeled by a matrix mapping entity vectors. However, relations reside on low\ndimension sub-manifolds in the parameter space of arbitrary matrices---for one\nreason, composition of two relations $\\boldsymbol{M}_1,\\boldsymbol{M}_2$ may\nmatch a third $\\boldsymbol{M}_3$ (e.g. composition of relations\ncurrency_of_country and country_of_film usually matches\ncurrency_of_film_budget), which imposes compositional constraints to be\nsatisfied by the parameters (i.e. $\\boldsymbol{M}_1\\cdot\n\\boldsymbol{M}_2\\approx \\boldsymbol{M}_3$). In this paper we investigate a\ndimension reduction technique by training relations jointly with an\nautoencoder, which is expected to better capture compositional constraints. We\nachieve state-of-the-art on Knowledge Base Completion tasks with strongly\nimproved Mean Rank, and show that joint training with an autoencoder leads to\ninterpretable sparse codings of relations, helps discovering compositional\nconstraints and benefits from compositional training. Our source code is\nreleased at github.com/tianran/glimvec. \n\n"}
{"id": "1805.09639", "contents": "Title: Online Regularized Nonlinear Acceleration Abstract: Regularized nonlinear acceleration (RNA) estimates the minimum of a function\nby post-processing iterates from an algorithm such as the gradient method. It\ncan be seen as a regularized version of Anderson acceleration, a classical\nacceleration scheme from numerical analysis. The new scheme provably improves\nthe rate of convergence of fixed step gradient descent, and its empirical\nperformance is comparable to that of quasi-Newton methods. However, RNA cannot\naccelerate faster multistep algorithms like Nesterov's method and often\ndiverges in this context. Here, we adapt RNA to overcome these issues, so that\nour scheme can be used on fast algorithms such as gradient methods with\nmomentum. We show optimal complexity bounds for quadratics and asymptotically\noptimal rates on general convex minimization problems. Moreover, this new\nscheme works online, i.e., extrapolated solution estimates can be reinjected at\neach iteration, significantly improving numerical performance over classical\naccelerated methods. \n\n"}
{"id": "1805.10111", "contents": "Title: Double Quantization for Communication-Efficient Distributed Optimization Abstract: Modern distributed training of machine learning models suffers from high\ncommunication overhead for synchronizing stochastic gradients and model\nparameters. In this paper, to reduce the communication complexity, we propose\n\\emph{double quantization}, a general scheme for quantizing both model\nparameters and gradients. Three communication-efficient algorithms are proposed\nunder this general scheme. Specifically, (i) we propose a low-precision\nalgorithm AsyLPG with asynchronous parallelism, (ii) we explore integrating\ngradient sparsification with double quantization and develop Sparse-AsyLPG,\n(iii) we show that double quantization can also be accelerated by momentum\ntechnique and design accelerated AsyLPG. We establish rigorous performance\nguarantees for the algorithms, and conduct experiments on a multi-server\ntest-bed to demonstrate that our algorithms can effectively save transmitted\nbits without performance degradation. \n\n"}
{"id": "1805.10265", "contents": "Title: Training verified learners with learned verifiers Abstract: This paper proposes a new algorithmic framework, predictor-verifier training,\nto train neural networks that are verifiable, i.e., networks that provably\nsatisfy some desired input-output properties. The key idea is to simultaneously\ntrain two networks: a predictor network that performs the task at hand,e.g.,\npredicting labels given inputs, and a verifier network that computes a bound on\nhow well the predictor satisfies the properties being verified. Both networks\ncan be trained simultaneously to optimize a weighted combination of the\nstandard data-fitting loss and a term that bounds the maximum violation of the\nproperty. Experiments show that not only is the predictor-verifier architecture\nable to train networks to achieve state of the art verified robustness to\nadversarial examples with much shorter training times (outperforming previous\nalgorithms on small datasets like MNIST and SVHN), but it can also be scaled to\nproduce the first known (to the best of our knowledge) verifiably robust\nnetworks for CIFAR-10. \n\n"}
{"id": "1805.10309", "contents": "Title: Learning Self-Imitating Diverse Policies Abstract: The success of popular algorithms for deep reinforcement learning, such as\npolicy-gradients and Q-learning, relies heavily on the availability of an\ninformative reward signal at each timestep of the sequential decision-making\nprocess. When rewards are only sparsely available during an episode, or a\nrewarding feedback is provided only after episode termination, these algorithms\nperform sub-optimally due to the difficultly in credit assignment.\nAlternatively, trajectory-based policy optimization methods, such as\ncross-entropy method and evolution strategies, do not require per-timestep\nrewards, but have been found to suffer from high sample complexity by\ncompleting forgoing the temporal nature of the problem. Improving the\nefficiency of RL algorithms in real-world problems with sparse or episodic\nrewards is therefore a pressing need. In this work, we introduce a\nself-imitation learning algorithm that exploits and explores well in the sparse\nand episodic reward settings. We view each policy as a state-action visitation\ndistribution and formulate policy optimization as a divergence minimization\nproblem. We show that with Jensen-Shannon divergence, this divergence\nminimization problem can be reduced into a policy-gradient algorithm with\nshaped rewards learned from experience replays. Experimental results indicate\nthat our algorithm works comparable to existing algorithms in environments with\ndense rewards, and significantly better in environments with sparse and\nepisodic rewards. We then discuss limitations of self-imitation learning, and\npropose to solve them by using Stein variational policy gradient descent with\nthe Jensen-Shannon kernel to learn multiple diverse policies. We demonstrate\nits effectiveness on a challenging variant of continuous-control MuJoCo\nlocomotion tasks. \n\n"}
{"id": "1805.10572", "contents": "Title: BRITS: Bidirectional Recurrent Imputation for Time Series Abstract: Time series are widely used as signals in many classification/regression\ntasks. It is ubiquitous that time series contains many missing values. Given\nmultiple correlated time series data, how to fill in missing values and to\npredict their class labels? Existing imputation methods often impose strong\nassumptions of the underlying data generating process, such as linear dynamics\nin the state space. In this paper, we propose BRITS, a novel method based on\nrecurrent neural networks for missing value imputation in time series data. Our\nproposed method directly learns the missing values in a bidirectional recurrent\ndynamical system, without any specific assumption. The imputed values are\ntreated as variables of RNN graph and can be effectively updated during the\nbackpropagation.BRITS has three advantages: (a) it can handle multiple\ncorrelated missing values in time series; (b) it generalizes to time series\nwith nonlinear dynamics underlying; (c) it provides a data-driven imputation\nprocedure and applies to general settings with missing data.We evaluate our\nmodel on three real-world datasets, including an air quality dataset, a\nhealth-care data, and a localization data for human activity. Experiments show\nthat our model outperforms the state-of-the-art methods in both imputation and\nclassification/regression accuracies. \n\n"}
{"id": "1805.10579", "contents": "Title: Robust Accelerated Gradient Methods for Smooth Strongly Convex Functions Abstract: We study the trade-offs between convergence rate and robustness to gradient\nerrors in designing a first-order algorithm. We focus on gradient descent (GD)\nand accelerated gradient (AG) methods for minimizing strongly convex functions\nwhen the gradient has random errors in the form of additive white noise. With\ngradient errors, the function values of the iterates need not converge to the\noptimal value; hence, we define the robustness of an algorithm to noise as the\nasymptotic expected suboptimality of the iterate sequence to input noise power.\nFor this robustness measure, we provide exact expressions for the quadratic\ncase using tools from robust control theory and tight upper bounds for the\nsmooth strongly convex case using Lyapunov functions certified through matrix\ninequalities. We use these characterizations within an optimization problem\nwhich selects parameters of each algorithm to achieve a particular trade-off\nbetween rate and robustness. Our results show that AG can achieve acceleration\nwhile being more robust to random gradient errors. This behavior is quite\ndifferent than previously reported in the deterministic gradient noise setting.\nWe also establish some connections between the robustness of an algorithm and\nhow quickly it can converge back to the optimal solution if it is perturbed\nfrom the optimal point with deterministic noise. Our framework also leads to\npractical algorithms that can perform better than other state-of-the-art\nmethods in the presence of random gradient noise. \n\n"}
{"id": "1805.10829", "contents": "Title: Sigsoftmax: Reanalysis of the Softmax Bottleneck Abstract: Softmax is an output activation function for modeling categorical probability\ndistributions in many applications of deep learning. However, a recent study\nrevealed that softmax can be a bottleneck of representational capacity of\nneural networks in language modeling (the softmax bottleneck). In this paper,\nwe propose an output activation function for breaking the softmax bottleneck\nwithout additional parameters. We re-analyze the softmax bottleneck from the\nperspective of the output set of log-softmax and identify the cause of the\nsoftmax bottleneck. On the basis of this analysis, we propose sigsoftmax, which\nis composed of a multiplication of an exponential function and sigmoid\nfunction. Sigsoftmax can break the softmax bottleneck. The experiments on\nlanguage modeling demonstrate that sigsoftmax and mixture of sigsoftmax\noutperform softmax and mixture of softmax, respectively. \n\n"}
{"id": "1805.11074", "contents": "Title: Reward Constrained Policy Optimization Abstract: Solving tasks in Reinforcement Learning is no easy feat. As the goal of the\nagent is to maximize the accumulated reward, it often learns to exploit\nloopholes and misspecifications in the reward signal resulting in unwanted\nbehavior. While constraints may solve this issue, there is no closed form\nsolution for general constraints. In this work we present a novel\nmulti-timescale approach for constrained policy optimization, called `Reward\nConstrained Policy Optimization' (RCPO), which uses an alternative penalty\nsignal to guide the policy towards a constraint satisfying one. We prove the\nconvergence of our approach and provide empirical evidence of its ability to\ntrain constraint satisfying policies. \n\n"}
{"id": "1805.11450", "contents": "Title: Model-based Pricing for Machine Learning in a Data Marketplace Abstract: Data analytics using machine learning (ML) has become ubiquitous in science,\nbusiness intelligence, journalism and many other domains. While a lot of work\nfocuses on reducing the training cost, inference runtime and storage cost of ML\nmodels, little work studies how to reduce the cost of data acquisition, which\npotentially leads to a loss of sellers' revenue and buyers' affordability and\nefficiency.\n  In this paper, we propose a model-based pricing (MBP) framework, which\ninstead of pricing the data, directly prices ML model instances. We first\nformally describe the desired properties of the MBP framework, with a focus on\navoiding arbitrage. Next, we show a concrete realization of the MBP framework\nvia a noise injection approach, which provably satisfies the desired formal\nproperties. Based on the proposed framework, we then provide algorithmic\nsolutions on how the seller can assign prices to models under different market\nscenarios (such as to maximize revenue). Finally, we conduct extensive\nexperiments, which validate that the MBP framework can provide high revenue to\nthe seller, high affordability to the buyer, and also operate on low runtime\ncost. \n\n"}
{"id": "1805.11710", "contents": "Title: Active and Adaptive Sequential learning Abstract: A framework is introduced for actively and adaptively solving a sequence of\nmachine learning problems, which are changing in bounded manner from one time\nstep to the next. An algorithm is developed that actively queries the labels of\nthe most informative samples from an unlabeled data pool, and that adapts to\nthe change by utilizing the information acquired in the previous steps. Our\nanalysis shows that the proposed active learning algorithm based on stochastic\ngradient descent achieves a near-optimal excess risk performance for maximum\nlikelihood estimation. Furthermore, an estimator of the change in the learning\nproblems using the active learning samples is constructed, which provides an\nadaptive sample size selection rule that guarantees the excess risk is bounded\nfor sufficiently large number of time steps. Experiments with synthetic and\nreal data are presented to validate our algorithm and theoretical results. \n\n"}
{"id": "1805.12017", "contents": "Title: Robustifying Models Against Adversarial Attacks by Langevin Dynamics Abstract: Adversarial attacks on deep learning models have compromised their\nperformance considerably. As remedies, a lot of defense methods were proposed,\nwhich however, have been circumvented by newer attacking strategies. In the\nmidst of this ensuing arms race, the problem of robustness against adversarial\nattacks still remains unsolved. This paper proposes a novel, simple yet\neffective defense strategy where adversarial samples are relaxed onto the\nunderlying manifold of the (unknown) target class distribution. Specifically,\nour algorithm drives off-manifold adversarial samples towards high density\nregions of the data generating distribution of the target class by the\nMetroplis-adjusted Langevin algorithm (MALA) with perceptual boundary taken\ninto account. Although the motivation is similar to projection methods, e.g.,\nDefense-GAN, our algorithm, called MALA for DEfense (MALADE), is equipped with\nsignificant dispersion - projection is distributed broadly, and therefore any\nwhitebox attack cannot accurately align the input so that the MALADE moves it\nto a targeted untrained spot where the model predicts a wrong label. In our\nexperiments, MALADE exhibited state-of-the-art performance against various\nelaborate attacking strategies. \n\n"}
{"id": "1805.12375", "contents": "Title: Sample-Efficient Deep Reinforcement Learning via Episodic Backward\n  Update Abstract: We propose Episodic Backward Update (EBU) - a novel deep reinforcement\nlearning algorithm with a direct value propagation. In contrast to the\nconventional use of the experience replay with uniform random sampling, our\nagent samples a whole episode and successively propagates the value of a state\nto its previous states. Our computationally efficient recursive algorithm\nallows sparse and delayed rewards to propagate directly through all transitions\nof the sampled episode. We theoretically prove the convergence of the EBU\nmethod and experimentally demonstrate its performance in both deterministic and\nstochastic environments. Especially in 49 games of Atari 2600 domain, EBU\nachieves the same mean and median human normalized performance of DQN by using\nonly 5% and 10% of samples, respectively. \n\n"}
{"id": "1806.00047", "contents": "Title: Following High-level Navigation Instructions on a Simulated Quadcopter\n  with Imitation Learning Abstract: We introduce a method for following high-level navigation instructions by\nmapping directly from images, instructions and pose estimates to continuous\nlow-level velocity commands for real-time control. The Grounded Semantic\nMapping Network (GSMN) is a fully-differentiable neural network architecture\nthat builds an explicit semantic map in the world reference frame by\nincorporating a pinhole camera projection model within the network. The\ninformation stored in the map is learned from experience, while the\nlocal-to-world transformation is computed explicitly. We train the model using\nDAggerFM, a modified variant of DAgger that trades tabular convergence\nguarantees for improved training speed and memory use. We test GSMN in virtual\nenvironments on a realistic quadcopter simulator and show that incorporating an\nexplicit mapping and grounding modules allows GSMN to outperform strong neural\nbaselines and almost reach an expert policy performance. Finally, we analyze\nthe learned map representations and show that using an explicit map leads to an\ninterpretable instruction-following model. \n\n"}
{"id": "1806.00250", "contents": "Title: TAPAS: Train-less Accuracy Predictor for Architecture Search Abstract: In recent years an increasing number of researchers and practitioners have\nbeen suggesting algorithms for large-scale neural network architecture search:\ngenetic algorithms, reinforcement learning, learning curve extrapolation, and\naccuracy predictors. None of them, however, demonstrated high-performance\nwithout training new experiments in the presence of unseen datasets. We propose\na new deep neural network accuracy predictor, that estimates in fractions of a\nsecond classification performance for unseen input datasets, without training.\nIn contrast to previously proposed approaches, our prediction is not only\ncalibrated on the topological network information, but also on the\ncharacterization of the dataset-difficulty which allows us to re-tune the\nprediction without any training. Our predictor achieves a performance which\nexceeds 100 networks per second on a single GPU, thus creating the opportunity\nto perform large-scale architecture search within a few minutes. We present\nresults of two searches performed in 400 seconds on a single GPU. Our best\ndiscovered networks reach 93.67% accuracy for CIFAR-10 and 81.01% for\nCIFAR-100, verified by training. These networks are performance competitive\nwith other automatically discovered state-of-the-art networks however we only\nneeded a small fraction of the time to solution and computational resources. \n\n"}
{"id": "1806.00370", "contents": "Title: Nonlinear Acceleration of CNNs Abstract: The Regularized Nonlinear Acceleration (RNA) algorithm is an acceleration\nmethod capable of improving the rate of convergence of many optimization\nschemes such as gradient descend, SAGA or SVRG. Until now, its analysis is\nlimited to convex problems, but empirical observations shows that RNA may be\nextended to wider settings. In this paper, we investigate further the benefits\nof RNA when applied to neural networks, in particular for the task of image\nrecognition on CIFAR10 and ImageNet. With very few modifications of exiting\nframeworks, RNA improves slightly the optimization process of CNNs, after\ntraining. \n\n"}
{"id": "1806.00437", "contents": "Title: Large-Margin Classification in Hyperbolic Space Abstract: Representing data in hyperbolic space can effectively capture latent\nhierarchical relationships. With the goal of enabling accurate classification\nof points in hyperbolic space while respecting their hyperbolic geometry, we\nintroduce hyperbolic SVM, a hyperbolic formulation of support vector machine\nclassifiers, and elucidate through new theoretical work its connection to the\nEuclidean counterpart. We demonstrate the performance improvement of hyperbolic\nSVM for multi-class prediction tasks on real-world complex networks as well as\nsimulated datasets. Our work allows analytic pipelines that take the inherent\nhyperbolic geometry of the data into account in an end-to-end fashion without\nresorting to ill-fitting tools developed for Euclidean space. \n\n"}
{"id": "1806.00458", "contents": "Title: Improved Sample Complexity for Stochastic Compositional Variance Reduced\n  Gradient Abstract: Convex composition optimization is an emerging topic that covers a wide range\nof applications arising from stochastic optimal control, reinforcement learning\nand multi-stage stochastic programming. Existing algorithms suffer from\nunsatisfactory sample complexity and practical issues since they ignore the\nconvexity structure in the algorithmic design. In this paper, we develop a new\nstochastic compositional variance-reduced gradient algorithm with the sample\ncomplexity of $O((m+n)\\log(1/\\epsilon)+1/\\epsilon^3)$ where $m+n$ is the total\nnumber of samples. Our algorithm is near-optimal as the dependence on $m+n$ is\noptimal up to a logarithmic factor. Experimental results on real-world datasets\ndemonstrate the effectiveness and efficiency of the new algorithm. \n\n"}
{"id": "1806.00548", "contents": "Title: A Fast and Scalable Joint Estimator for Integrating Additional Knowledge\n  in Learning Multiple Related Sparse Gaussian Graphical Models Abstract: We consider the problem of including additional knowledge in estimating\nsparse Gaussian graphical models (sGGMs) from aggregated samples, arising often\nin bioinformatics and neuroimaging applications. Previous joint sGGM estimators\neither fail to use existing knowledge or cannot scale-up to many tasks (large\n$K$) under a high-dimensional (large $p$) situation. In this paper, we propose\na novel \\underline{J}oint \\underline{E}lementary \\underline{E}stimator\nincorporating additional \\underline{K}nowledge (JEEK) to infer multiple related\nsparse Gaussian Graphical models from large-scale heterogeneous data. Using\ndomain knowledge as weights, we design a novel hybrid norm as the minimization\nobjective to enforce the superposition of two weighted sparsity constraints,\none on the shared interactions and the other on the task-specific structural\npatterns. This enables JEEK to elegantly consider various forms of existing\nknowledge based on the domain at hand and avoid the need to design\nknowledge-specific optimization. JEEK is solved through a fast and entry-wise\nparallelizable solution that largely improves the computational efficiency of\nthe state-of-the-art $O(p^5K^4)$ to $O(p^2K^4)$. We conduct a rigorous\nstatistical analysis showing that JEEK achieves the same convergence rate\n$O(\\log(Kp)/n_{tot})$ as the state-of-the-art estimators that are much harder\nto compute. Empirically, on multiple synthetic datasets and two real-world\ndata, JEEK outperforms the speed of the state-of-arts significantly while\nachieving the same level of prediction accuracy. Available as R tool @\nhttp://jointnets.org/ \n\n"}
{"id": "1806.00628", "contents": "Title: A Novel Framework for Recurrent Neural Networks with Enhancing\n  Information Processing and Transmission between Units Abstract: This paper proposes a novel framework for recurrent neural networks (RNNs)\ninspired by the human memory models in the field of cognitive neuroscience to\nenhance information processing and transmission between adjacent RNNs' units.\nThe proposed framework for RNNs consists of three stages that is working\nmemory, forget, and long-term store. The first stage includes taking input data\ninto sensory memory and transferring it to working memory for preliminary\ntreatment. And the second stage mainly focuses on proactively forgetting the\nsecondary information rather than the primary in the working memory. And\nfinally, we get the long-term store normally using some kind of RNN's unit. Our\nframework, which is generalized and simple, is evaluated on 6 datasets which\nfall into 3 different tasks, corresponding to text classification, image\nclassification and language modelling. Experiments reveal that our framework\ncan obviously improve the performance of traditional recurrent neural networks.\nAnd exploratory task shows the ability of our framework of correctly forgetting\nthe secondary information. \n\n"}
{"id": "1806.00892", "contents": "Title: Conservative Exploration using Interleaving Abstract: In many practical problems, a learning agent may want to learn the best\naction in hindsight without ever taking a bad action, which is significantly\nworse than the default production action. In general, this is impossible\nbecause the agent has to explore unknown actions, some of which can be bad, to\nlearn better actions. However, when the actions are combinatorial, this may be\npossible if the unknown action can be evaluated by interleaving it with the\nproduction action. We formalize this concept as learning in stochastic\ncombinatorial semi-bandits with exchangeable actions. We design efficient\nlearning algorithms for this problem, bound their n-step regret, and evaluate\nthem on both synthetic and real-world problems. Our real-world experiments show\nthat our algorithms can learn to recommend K most attractive movies without\never violating a strict production constraint, both overall and subject to a\ndiversity constraint. \n\n"}
{"id": "1806.01248", "contents": "Title: Dynamically Hierarchy Revolution: DirNet for Compressing Recurrent\n  Neural Network on Mobile Devices Abstract: Recurrent neural networks (RNNs) achieve cutting-edge performance on a\nvariety of problems. However, due to their high computational and memory\ndemands, deploying RNNs on resource constrained mobile devices is a challenging\ntask. To guarantee minimum accuracy loss with higher compression rate and\ndriven by the mobile resource requirement, we introduce a novel model\ncompression approach DirNet based on an optimized fast dictionary learning\nalgorithm, which 1) dynamically mines the dictionary atoms of the projection\ndictionary matrix within layer to adjust the compression rate 2) adaptively\nchanges the sparsity of sparse codes cross the hierarchical layers.\nExperimental results on language model and an ASR model trained with a 1000h\nspeech dataset demonstrate that our method significantly outperforms prior\napproaches. Evaluated on off-the-shelf mobile devices, we are able to reduce\nthe size of original model by eight times with real-time model inference and\nnegligible accuracy loss. \n\n"}
{"id": "1806.01445", "contents": "Title: Embedding Logical Queries on Knowledge Graphs Abstract: Learning low-dimensional embeddings of knowledge graphs is a powerful\napproach used to predict unobserved or missing edges between entities. However,\nan open challenge in this area is developing techniques that can go beyond\nsimple edge prediction and handle more complex logical queries, which might\ninvolve multiple unobserved edges, entities, and variables. For instance, given\nan incomplete biological knowledge graph, we might want to predict \"em what\ndrugs are likely to target proteins involved with both diseases X and Y?\" -- a\nquery that requires reasoning about all possible proteins that {\\em might}\ninteract with diseases X and Y. Here we introduce a framework to efficiently\nmake predictions about conjunctive logical queries -- a flexible but tractable\nsubset of first-order logic -- on incomplete knowledge graphs. In our approach,\nwe embed graph nodes in a low-dimensional space and represent logical operators\nas learned geometric operations (e.g., translation, rotation) in this embedding\nspace. By performing logical operations within a low-dimensional embedding\nspace, our approach achieves a time complexity that is linear in the number of\nquery variables, compared to the exponential complexity required by a naive\nenumeration-based approach. We demonstrate the utility of this framework in two\napplication studies on real-world datasets with millions of relations:\npredicting logical relationships in a network of drug-gene-disease interactions\nand in a graph-based representation of social interactions derived from a\npopular web forum. \n\n"}
{"id": "1806.01477", "contents": "Title: An Explainable Adversarial Robustness Metric for Deep Learning Neural\n  Networks Abstract: Deep Neural Networks(DNN) have excessively advanced the field of computer\nvision by achieving state of the art performance in various vision tasks. These\nresults are not limited to the field of vision but can also be seen in speech\nrecognition and machine translation tasks. Recently, DNNs are found to poorly\nfail when tested with samples that are crafted by making imperceptible changes\nto the original input images. This causes a gap between the validation and\nadversarial performance of a DNN. An effective and generalizable robustness\nmetric for evaluating the performance of DNN on these adversarial inputs is\nstill missing from the literature. In this paper, we propose Noise Sensitivity\nScore (NSS), a metric that quantifies the performance of a DNN on a specific\ninput under different forms of fix-directional attacks. An insightful\nmathematical explanation is provided for deeply understanding the proposed\nmetric. By leveraging the NSS, we also proposed a skewness based dataset\nrobustness metric for evaluating a DNN's adversarial performance on a given\ndataset. Extensive experiments using widely used state of the art architectures\nalong with popular classification datasets, such as MNIST, CIFAR-10, CIFAR-100,\nand ImageNet, are used to validate the effectiveness and generalization of our\nproposed metrics. Instead of simply measuring a DNN's adversarial robustness in\nthe input domain, as previous works, the proposed NSS is built on top of\ninsightful mathematical understanding of the adversarial attack and gives a\nmore explicit explanation of the robustness. \n\n"}
{"id": "1806.01793", "contents": "Title: Gradient-based Filter Design for the Dual-tree Wavelet Transform Abstract: The wavelet transform has seen success when incorporated into neural network\narchitectures, such as in wavelet scattering networks. More recently, it has\nbeen shown that the dual-tree complex wavelet transform can provide better\nrepresentations than the standard transform. With this in mind, we extend our\nprevious method for learning filters for the 1D and 2D wavelet transforms into\nthe dual-tree domain. We show that with few modifications to our original\nmodel, we can learn directional filters that leverage the properties of the\ndual-tree wavelet transform. \n\n"}
{"id": "1806.01879", "contents": "Title: An explicit analysis of the entropic penalty in linear programming Abstract: Solving linear programs by using entropic penalization has recently attracted\nnew interest in the optimization community, since this strategy forms the basis\nfor the fastest-known algorithms for the optimal transport problem, with many\napplications in modern large-scale machine learning. Crucial to these\napplications has been an analysis of how quickly solutions to the penalized\nprogram approach true optima to the original linear program. More than 20 years\nago, Cominetti and San Mart\\'in showed that this convergence is exponentially\nfast; however, their proof is asymptotic and does not give any indication of\nhow accurately the entropic program approximates the original program for any\nparticular choice of the penalization parameter. We close this long-standing\ngap in the literature regarding entropic penalization by giving a new proof of\nthe exponential convergence, valid for any linear program. Our proof is\nnon-asymptotic, yields explicit constants, and has the virtue of being\nextremely simple. We provide matching lower bounds and show that the entropic\napproach does not lead to a near-linear time approximation scheme for the\nlinear assignment problem. \n\n"}
{"id": "1806.02136", "contents": "Title: Efficient Differentiable Programming in a Functional Array-Processing\n  Language Abstract: We present a system for the automatic differentiation of a higher-order\nfunctional array-processing language. The core functional language underlying\nthis system simultaneously supports both source-to-source automatic\ndifferentiation and global optimizations such as loop transformations. Thanks\nto this feature, we demonstrate how for some real-world machine learning and\ncomputer vision benchmarks, the system outperforms the state-of-the-art\nautomatic differentiation tools. \n\n"}
{"id": "1806.02371", "contents": "Title: Adversarial Attack on Graph Structured Data Abstract: Deep learning on graph structures has shown exciting results in various\napplications. However, few attentions have been paid to the robustness of such\nmodels, in contrast to numerous research work for image or text adversarial\nattack and defense. In this paper, we focus on the adversarial attacks that\nfool the model by modifying the combinatorial structure of data. We first\npropose a reinforcement learning based attack method that learns the\ngeneralizable attack policy, while only requiring prediction labels from the\ntarget classifier. Also, variants of genetic algorithms and gradient methods\nare presented in the scenario where prediction confidence or gradients are\navailable. We use both synthetic and real-world data to show that, a family of\nGraph Neural Network models are vulnerable to these attacks, in both\ngraph-level and node-level classification tasks. We also show such attacks can\nbe used to diagnose the learned classifiers. \n\n"}
{"id": "1806.02812", "contents": "Title: Towards Riemannian Accelerated Gradient Methods Abstract: We propose a Riemannian version of Nesterov's Accelerated Gradient algorithm\n(RAGD), and show that for geodesically smooth and strongly convex problems,\nwithin a neighborhood of the minimizer whose radius depends on the condition\nnumber as well as the sectional curvature of the manifold, RAGD converges to\nthe minimizer with acceleration. Unlike the algorithm in (Liu et al., 2017)\nthat requires the exact solution to a nonlinear equation which in turn may be\nintractable, our algorithm is constructive and computationally tractable. Our\nproof exploits a new estimate sequence and a novel bound on the nonlinear\nmetric distortion, both ideas may be of independent interest. \n\n"}
{"id": "1806.02954", "contents": "Title: Using Social Network Information in Bayesian Truth Discovery Abstract: We investigate the problem of truth discovery based on opinions from multiple\nagents who may be unreliable or biased. We consider the case where agents'\nreliabilities or biases are correlated if they belong to the same community,\nwhich defines a group of agents with similar opinions regarding a particular\nevent. An agent can belong to different communities for different events, and\nthese communities are unknown a priori. We incorporate knowledge of the agents'\nsocial network in our truth discovery framework and develop Laplace variational\ninference methods to estimate agents' reliabilities, communities, and the event\nstates. We also develop a stochastic variational inference method to scale our\nmodel to large social networks. Simulations and experiments on real data\nsuggest that when observations are sparse, our proposed methods perform better\nthan several other inference methods, including majority voting, TruthFinder,\nAccuSim, the Confidence-Aware Truth Discovery method, the Bayesian Classifier\nCombination (BCC) method, and the Community BCC method. \n\n"}
{"id": "1806.03207", "contents": "Title: Learning in Integer Latent Variable Models with Nested Automatic\n  Differentiation Abstract: We develop nested automatic differentiation (AD) algorithms for exact\ninference and learning in integer latent variable models. Recently, Winner,\nSujono, and Sheldon showed how to reduce marginalization in a class of integer\nlatent variable models to evaluating a probability generating function which\ncontains many levels of nested high-order derivatives. We contribute faster and\nmore stable AD algorithms for this challenging problem and a novel algorithm to\ncompute exact gradients for learning. These contributions lead to significantly\nfaster and more accurate learning algorithms, and are the first AD algorithms\nwhose running time is polynomial in the number of levels of nesting. \n\n"}
{"id": "1806.03920", "contents": "Title: Convergence Rates for Projective Splitting Abstract: Projective splitting is a family of methods for solving inclusions involving\nsums of maximal monotone operators. First introduced by Eckstein and Svaiter in\n2008, these methods have enjoyed significant innovation in recent years,\nbecoming one of the most flexible operator splitting frameworks available.\nWhile weak convergence of the iterates to a solution has been established,\nthere have been few attempts to study convergence rates of projective\nsplitting. The purpose of this paper is to do so under various assumptions. To\nthis end, there are three main contributions. First, in the context of convex\noptimization, we establish an $O(1/k)$ ergodic function convergence rate.\nSecond, for strongly monotone inclusions, strong convergence is established as\nwell as an ergodic $O(1/\\sqrt{k})$ convergence rate for the distance of the\niterates to the solution. Finally, for inclusions featuring strong monotonicity\nand cocoercivity, linear convergence is established. \n\n"}
{"id": "1806.03925", "contents": "Title: Gear Training: A new way to implement high-performance model-parallel\n  training Abstract: The training of Deep Neural Networks usually needs tremendous computing\nresources. Therefore many deep models are trained in large cluster instead of\nsingle machine or GPU. Though major researchs at present try to run whole model\non all machines by using asynchronous asynchronous stochastic gradient descent\n(ASGD), we present a new approach to train deep model parallely -- split the\nmodel and then seperately train different parts of it in different speed. \n\n"}
{"id": "1806.05069", "contents": "Title: Minimizing Regret of Bandit Online Optimization in Unconstrained Action\n  Spaces Abstract: We consider online convex optimization with a zero-order oracle feedback. In\nparticular, the decision maker does not know the explicit representation of the\ntime-varying cost functions, or their gradients. At each time step, she\nobserves the value of the corresponding cost function evaluated at her chosen\naction (zero-order oracle). The objective is to minimize the regret, that is,\nthe difference between the sum of the costs she accumulates and that of a\nstatic optimal action had she known the sequence of cost functions a priori. We\npresent a novel algorithm to minimize regret in unconstrained action spaces.\nOur algorithm hinges on a classical idea of one-point estimation of the\ngradients of the cost functions based on their observed values. The algorithm\nis independent of problem parameters. Letting $T$ denote the number of queries\nof the zero-order oracle and $n$ the problem dimension, the regret rate\nachieved is $O(n^{2/3}T^{2/3})$. Moreover, we adapt the presented algorithm to\nthe setting with two-point feedback and demonstrate that the adapted procedure\nachieves the theoretical lower bound on the regret of $(n^{1/2}T^{1/2})$. \n\n"}
{"id": "1806.05151", "contents": "Title: On Landscape of Lagrangian Functions and Stochastic Search for\n  Constrained Nonconvex Optimization Abstract: We study constrained nonconvex optimization problems in machine learning,\nsignal processing, and stochastic control. It is well-known that these problems\ncan be rewritten to a minimax problem in a Lagrangian form. However, due to the\nlack of convexity, their landscape is not well understood and how to find the\nstable equilibria of the Lagrangian function is still unknown. To bridge the\ngap, we study the landscape of the Lagrangian function. Further, we define a\nspecial class of Lagrangian functions. They enjoy two properties: 1.Equilibria\nare either stable or unstable (Formal definition in Section 2); 2.Stable\nequilibria correspond to the global optima of the original problem. We show\nthat a generalized eigenvalue (GEV) problem, including canonical correlation\nanalysis and other problems, belongs to the class. Specifically, we\ncharacterize its stable and unstable equilibria by leveraging an invariant\ngroup and symmetric property (more details in Section 3). Motivated by these\nneat geometric structures, we propose a simple, efficient, and stochastic\nprimal-dual algorithm solving the online GEV problem. Theoretically, we provide\nsufficient conditions, based on which we establish an asymptotic convergence\nrate and obtain the first sample complexity result for the online GEV problem\nby diffusion approximations, which are widely used in applied probability and\nstochastic control. Numerical results are provided to support our theory. \n\n"}
{"id": "1806.05250", "contents": "Title: What About Applied Fairness? Abstract: Machine learning practitioners are often ambivalent about the ethical aspects\nof their products. We believe anything that gets us from that current state to\none in which our systems are achieving some degree of fairness is an\nimprovement that should be welcomed. This is true even when that progress does\nnot get us 100% of the way to the goal of \"complete\" fairness or perfectly\nalign with our personal belief on which measure of fairness is used. Some\nmeasure of fairness being built would still put us in a better position than\nthe status quo. Impediments to getting fairness and ethical concerns applied in\nreal applications, whether they are abstruse philosophical debates or technical\noverhead such as the introduction of ever more hyper-parameters, should be\navoided. In this paper we further elaborate on our argument for this viewpoint\nand its importance. \n\n"}
{"id": "1806.05403", "contents": "Title: On the Perceptron's Compression Abstract: We study and provide exposition to several phenomena that are related to the\nperceptron's compression. One theme concerns modifications of the perceptron\nalgorithm that yield better guarantees on the margin of the hyperplane it\noutputs. These modifications can be useful in training neural networks as well,\nand we demonstrate them with some experimental data. In a second theme, we\ndeduce conclusions from the perceptron's compression in various contexts. \n\n"}
{"id": "1806.06086", "contents": "Title: Minibatch Gibbs Sampling on Large Graphical Models Abstract: Gibbs sampling is the de facto Markov chain Monte Carlo method used for\ninference and learning on large scale graphical models. For complicated factor\ngraphs with lots of factors, the performance of Gibbs sampling can be limited\nby the computational cost of executing a single update step of the Markov\nchain. This cost is proportional to the degree of the graph, the number of\nfactors adjacent to each variable. In this paper, we show how this cost can be\nreduced by using minibatching: subsampling the factors to form an estimate of\ntheir sum. We introduce several minibatched variants of Gibbs, show that they\ncan be made unbiased, prove bounds on their convergence rates, and show that\nunder some conditions they can result in asymptotic single-update-run-time\nspeedups over plain Gibbs sampling. \n\n"}
{"id": "1806.07259", "contents": "Title: Learning Equations for Extrapolation and Control Abstract: We present an approach to identify concise equations from data using a\nshallow neural network approach. In contrast to ordinary black-box regression,\nthis approach allows understanding functional relations and generalizing them\nfrom observed data to unseen parts of the parameter space. We show how to\nextend the class of learnable equations for a recently proposed equation\nlearning network to include divisions, and we improve the learning and model\nselection strategy to be useful for challenging real-world data. For systems\ngoverned by analytical expressions, our method can in many cases identify the\ntrue underlying equation and extrapolate to unseen domains. We demonstrate its\neffectiveness by experiments on a cart-pendulum system, where only 2 random\nrollouts are required to learn the forward dynamics and successfully achieve\nthe swing-up task. \n\n"}
{"id": "1806.07336", "contents": "Title: Neural Code Comprehension: A Learnable Representation of Code Semantics Abstract: With the recent success of embeddings in natural language processing,\nresearch has been conducted into applying similar methods to code analysis.\nMost works attempt to process the code directly or use a syntactic tree\nrepresentation, treating it like sentences written in a natural language.\nHowever, none of the existing methods are sufficient to comprehend program\nsemantics robustly, due to structural features such as function calls,\nbranching, and interchangeable order of statements. In this paper, we propose a\nnovel processing technique to learn code semantics, and apply it to a variety\nof program analysis tasks. In particular, we stipulate that a robust\ndistributional hypothesis of code applies to both human- and machine-generated\nprograms. Following this hypothesis, we define an embedding space, inst2vec,\nbased on an Intermediate Representation (IR) of the code that is independent of\nthe source programming language. We provide a novel definition of contextual\nflow for this IR, leveraging both the underlying data- and control-flow of the\nprogram. We then analyze the embeddings qualitatively using analogies and\nclustering, and evaluate the learned representation on three different\nhigh-level tasks. We show that even without fine-tuning, a single RNN\narchitecture and fixed inst2vec embeddings outperform specialized approaches\nfor performance prediction (compute device mapping, optimal thread coarsening);\nand algorithm classification from raw code (104 classes), where we set a new\nstate-of-the-art. \n\n"}
{"id": "1806.07373", "contents": "Title: Few-Shot Segmentation Propagation with Guided Networks Abstract: Learning-based methods for visual segmentation have made progress on\nparticular types of segmentation tasks, but are limited by the necessary\nsupervision, the narrow definitions of fixed tasks, and the lack of control\nduring inference for correcting errors. To remedy the rigidity and annotation\nburden of standard approaches, we address the problem of few-shot segmentation:\ngiven few image and few pixel supervision, segment any images accordingly. We\npropose guided networks, which extract a latent task representation from any\namount of supervision, and optimize our architecture end-to-end for fast,\naccurate few-shot segmentation. Our method can switch tasks without further\noptimization and quickly update when given more guidance. We report the first\nresults for segmentation from one pixel per concept and show real-time\ninteractive video segmentation. Our unified approach propagates pixel\nannotations across space for interactive segmentation, across time for video\nsegmentation, and across scenes for semantic segmentation. Our guided segmentor\nis state-of-the-art in accuracy for the amount of annotation and time. See\nhttp://github.com/shelhamer/revolver for code, models, and more details. \n\n"}
{"id": "1806.07572", "contents": "Title: Neural Tangent Kernel: Convergence and Generalization in Neural Networks Abstract: At initialization, artificial neural networks (ANNs) are equivalent to\nGaussian processes in the infinite-width limit, thus connecting them to kernel\nmethods. We prove that the evolution of an ANN during training can also be\ndescribed by a kernel: during gradient descent on the parameters of an ANN, the\nnetwork function $f_\\theta$ (which maps input vectors to output vectors)\nfollows the kernel gradient of the functional cost (which is convex, in\ncontrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel\n(NTK). This kernel is central to describe the generalization features of ANNs.\nWhile the NTK is random at initialization and varies during training, in the\ninfinite-width limit it converges to an explicit limiting kernel and it stays\nconstant during training. This makes it possible to study the training of ANNs\nin function space instead of parameter space. Convergence of the training can\nthen be related to the positive-definiteness of the limiting NTK. We prove the\npositive-definiteness of the limiting NTK when the data is supported on the\nsphere and the non-linearity is non-polynomial. We then focus on the setting of\nleast-squares regression and show that in the infinite-width limit, the network\nfunction $f_\\theta$ follows a linear differential equation during training. The\nconvergence is fastest along the largest kernel principal components of the\ninput data with respect to the NTK, hence suggesting a theoretical motivation\nfor early stopping. Finally we study the NTK numerically, observe its behavior\nfor wide networks, and compare it to the infinite-width limit. \n\n"}
{"id": "1806.07963", "contents": "Title: Latent heterogeneous multilayer community detection Abstract: We propose a method for simultaneously detecting shared and unshared\ncommunities in heterogeneous multilayer weighted and undirected networks. The\nmultilayer network is assumed to follow a generative probabilistic model that\ntakes into account the similarities and dissimilarities between the\ncommunities. We make use of a variational Bayes approach for jointly inferring\nthe shared and unshared hidden communities from multilayer network\nobservations. We show that our approach outperforms state-of-the-art algorithms\nin detecting disparate (shared and private) communities on synthetic data as\nwell as on real genome-wide fibroblast proliferation dataset. \n\n"}
{"id": "1806.08079", "contents": "Title: GrCAN: Gradient Boost Convolutional Autoencoder with Neural Decision\n  Forest Abstract: Random forest and deep neural network are two schools of effective\nclassification methods in machine learning. While the random forest is robust\nirrespective of the data domain, the deep neural network has advantages in\nhandling high dimensional data. In view that a differentiable neural decision\nforest can be added to the neural network to fully exploit the benefits of both\nmodels, in our work, we further combine convolutional autoencoder with neural\ndecision forest, where autoencoder has its advantages in finding the hidden\nrepresentations of the input data. We develop a gradient boost module and embed\nit into the proposed convolutional autoencoder with neural decision forest to\nimprove the performance. The idea of gradient boost is to learn and use the\nresidual in the prediction. In addition, we design a structure to learn the\nparameters of the neural decision forest and gradient boost module at\ncontiguous steps. The extensive experiments on several public datasets\ndemonstrate that our proposed model achieves good efficiency and prediction\nperformance compared with a series of baseline methods. \n\n"}
{"id": "1806.08840", "contents": "Title: Deep SNP: An End-to-end Deep Neural Network with Attention-based\n  Localization for Break-point Detection in SNP Array Genomic data Abstract: Diagnosis and risk stratification of cancer and many other diseases require\nthe detection of genomic breakpoints as a prerequisite of calling copy number\nalterations (CNA). This, however, is still challenging and requires\ntime-consuming manual curation. As deep-learning methods outperformed classical\nstate-of-the-art algorithms in various domains and have also been successfully\napplied to life science problems including medicine and biology, we here\npropose Deep SNP, a novel Deep Neural Network to learn from genomic data.\nSpecifically, we used a manually curated dataset from 12 genomic single\nnucleotide polymorphism array (SNPa) profiles as truth-set and aimed at\npredicting the presence or absence of genomic breakpoints, an indicator of\nstructural chromosomal variations, in windows of 40,000 probes. We compare our\nresults with well-known neural network models as well as Rawcopy though this\ntool is designed to predict breakpoints and in addition genomic segments with\nhigh sensitivity. We show, that Deep SNP is capable of successfully predicting\nthe presence or absence of a breakpoint in large genomic windows and\noutperforms state-of-the-art neural network models. Qualitative examples\nsuggest that integration of a localization unit may enable breakpoint detection\nand prediction of genomic segments, even if the breakpoint coordinates were not\nprovided for network training. These results warrant further evaluation of\nDeepSNP for breakpoint localization and subsequent calling of genomic segments. \n\n"}
{"id": "1806.09460", "contents": "Title: A Tour of Reinforcement Learning: The View from Continuous Control Abstract: This manuscript surveys reinforcement learning from the perspective of\noptimization and control with a focus on continuous control applications. It\nsurveys the general formulation, terminology, and typical experimental\nimplementations of reinforcement learning and reviews competing solution\nparadigms. In order to compare the relative merits of various techniques, this\nsurvey presents a case study of the Linear Quadratic Regulator (LQR) with\nunknown dynamics, perhaps the simplest and best-studied problem in optimal\ncontrol. The manuscript describes how merging techniques from learning theory\nand control can provide non-asymptotic characterizations of LQR performance and\nshows that these characterizations tend to match experimental behavior. In\nturn, when revisiting more complex applications, many of the observed phenomena\nin LQR persist. In particular, theory and experiment demonstrate the role and\nimportance of models and the cost of generality in reinforcement learning\nalgorithms. This survey concludes with a discussion of some of the challenges\nin designing learning systems that safely and reliably interact with complex\nand uncertain environments and how tools from reinforcement learning and\ncontrol might be combined to approach these challenges. \n\n"}
{"id": "1806.09602", "contents": "Title: A Machine-learning framework for automatic reference-free quality\n  assessment in MRI Abstract: Magnetic resonance (MR) imaging offers a wide variety of imaging techniques.\nA large amount of data is created per examination which needs to be checked for\nsufficient quality in order to derive a meaningful diagnosis. This is a manual\nprocess and therefore time- and cost-intensive. Any imaging artifacts\noriginating from scanner hardware, signal processing or induced by the patient\nmay reduce the image quality and complicate the diagnosis or any image\npost-processing. Therefore, the assessment or the ensurance of sufficient image\nquality in an automated manner is of high interest. Usually no reference image\nis available or difficult to define. Therefore, classical reference-based\napproaches are not applicable. Model observers mimicking the human observers\n(HO) can assist in this task. Thus, we propose a new machine-learning-based\nreference-free MR image quality assessment framework which is trained on\nHO-derived labels to assess MR image quality immediately after each\nacquisition. We include the concept of active learning and present an efficient\nblinded reading platform to reduce the effort in the HO labeling procedure.\nDerived image features and the applied classifiers (support-vector-machine,\ndeep neural network) are investigated for a cohort of 250 patients. The MR\nimage quality assessment framework can achieve a high test accuracy of 93.7$\\%$\nfor estimating quality classes on a 5-point Likert-scale. The proposed MR image\nquality assessment framework is able to provide an accurate and efficient\nquality estimation which can be used as a prospective quality assurance\nincluding automatic acquisition adaptation or guided MR scanner operation,\nand/or as a retrospective quality assessment including support of diagnostic\ndecisions or quality control in cohort studies. \n\n"}
{"id": "1806.09620", "contents": "Title: A DCA-Like Algorithm and its Accelerated Version with Application in\n  Data Visualization Abstract: In this paper, we present two variants of DCA (Different of Convex functions\nAlgorithm) to solve the constrained sum of differentiable function and\ncomposite functions minimization problem, with the aim of increasing the\nconvergence speed of DCA. In the first variant, DCA-Like, we introduce a new\ntechnique to iteratively modify the decomposition of the objective function.\nThis successive decomposition could lead to a better majorization and\nconsequently a better convergence speed than the basic DCA. We then incorporate\nthe Nesterov's acceleration technique into DCA-Like to give rise to the second\nvariant, named Accelerated DCA-Like. The convergence properties and the\nconvergence rate under Kudyka-Lojasiewicz assumption of both variants are\nrigorously studied. As an application, we investigate our algorithms for the\nt-distributed stochastic neighbor embedding. Numerical experiments on several\nbenchmark datasets illustrate the efficiency of our algorithms. \n\n"}
{"id": "1806.09708", "contents": "Title: Mimic and Classify : A meta-algorithm for Conditional Independence\n  Testing Abstract: Given independent samples generated from the joint distribution\n$p(\\mathbf{x},\\mathbf{y},\\mathbf{z})$, we study the problem of Conditional\nIndependence (CI-Testing), i.e., whether the joint equals the CI distribution\n$p^{CI}(\\mathbf{x},\\mathbf{y},\\mathbf{z})= p(\\mathbf{z})\np(\\mathbf{y}|\\mathbf{z})p(\\mathbf{x}|\\mathbf{z})$ or not. We cast this problem\nunder the purview of the proposed, provable meta-algorithm, \"Mimic and\nClassify\", which is realized in two-steps: (a) Mimic the CI distribution close\nenough to recover the support, and (b) Classify to distinguish the joint and\nthe CI distribution. Thus, as long as we have a good generative model and a\ngood classifier, we potentially have a sound CI Tester. With this modular\nparadigm, CI Testing becomes amiable to be handled by state-of-the-art, both\ngenerative and classification methods from the modern advances in Deep\nLearning, which in general can handle issues related to curse of dimensionality\nand operation in small sample regime. We show intensive numerical experiments\non synthetic and real datasets where new mimic methods such conditional GANs,\nRegression with Neural Nets, outperform the current best CI Testing performance\nin the literature. Our theoretical results provide analysis on the estimation\nof null distribution as well as allow for general measures, i.e., when either\nsome of the random variables are discrete and some are continuous or when one\nor more of them are discrete-continuous mixtures. \n\n"}
{"id": "1806.10069", "contents": "Title: Deep $k$-Means: Jointly clustering with $k$-Means and learning\n  representations Abstract: We study in this paper the problem of jointly clustering and learning\nrepresentations. As several previous studies have shown, learning\nrepresentations that are both faithful to the data to be clustered and adapted\nto the clustering algorithm can lead to better clustering performance, all the\nmore so that the two tasks are performed jointly. We propose here such an\napproach for $k$-Means clustering based on a continuous reparametrization of\nthe objective function that leads to a truly joint solution. The behavior of\nour approach is illustrated on various datasets showing its efficacy in\nlearning representations for objects while clustering them. \n\n"}
{"id": "1806.10188", "contents": "Title: A Tight Convergence Analysis for Stochastic Gradient Descent with\n  Delayed Updates Abstract: We provide tight finite-time convergence bounds for gradient descent and\nstochastic gradient descent on quadratic functions, when the gradients are\ndelayed and reflect iterates from $\\tau$ rounds ago. First, we show that\nwithout stochastic noise, delays strongly affect the attainable optimization\nerror: In fact, the error can be as bad as non-delayed gradient descent ran on\nonly $1/\\tau$ of the gradients. In sharp contrast, we quantify how stochastic\nnoise makes the effect of delays negligible, improving on previous work which\nonly showed this phenomenon asymptotically or for much smaller delays. Also, in\nthe context of distributed optimization, the results indicate that the\nperformance of gradient descent with delays is competitive with synchronous\napproaches such as mini-batching. Our results are based on a novel technique\nfor analyzing convergence of optimization algorithms using generating\nfunctions. \n\n"}
{"id": "1806.10748", "contents": "Title: Towards automatic initialization of registration algorithms using\n  simulated endoscopy images Abstract: Registering images from different modalities is an active area of research in\ncomputer aided medical interventions. Several registration algorithms have been\ndeveloped, many of which achieve high accuracy. However, these results are\ndependent on many factors, including the quality of the extracted features or\nsegmentations being registered as well as the initial alignment. Although\nseveral methods have been developed towards improving segmentation algorithms\nand automating the segmentation process, few automatic initialization\nalgorithms have been explored. In many cases, the initial alignment from which\na registration is initiated is performed manually, which interferes with the\nclinical workflow. Our aim is to use scene classification in endoscopic\nprocedures to achieve coarse alignment of the endoscope and a preoperative\nimage of the anatomy. In this paper, we show using simulated scenes that a\nneural network can predict the region of anatomy (with respect to a\npreoperative image) that the endoscope is located in by observing a single\nendoscopic video frame. With limited training and without any hyperparameter\ntuning, our method achieves an accuracy of 76.53 (+/-1.19)%. There are several\navenues for improvement, making this a promising direction of research. Code is\navailable at https://github.com/AyushiSinha/AutoInitialization. \n\n"}
{"id": "1806.10909", "contents": "Title: ResNet with one-neuron hidden layers is a Universal Approximator Abstract: We demonstrate that a very deep ResNet with stacked modules with one neuron\nper hidden layer and ReLU activation functions can uniformly approximate any\nLebesgue integrable function in $d$ dimensions, i.e. $\\ell_1(\\mathbb{R}^d)$.\nBecause of the identity mapping inherent to ResNets, our network has\nalternating layers of dimension one and $d$. This stands in sharp contrast to\nfully connected networks, which are not universal approximators if their width\nis the input dimension $d$ [Lu et al, 2017; Hanin and Sellke, 2017]. Hence, our\nresult implies an increase in representational power for narrow deep networks\nby the ResNet architecture. \n\n"}
{"id": "1807.00099", "contents": "Title: Generating Titles for Web Tables Abstract: Descriptive titles provide crucial context for interpreting tables that are\nextracted from web pages and are a key component of table-based web\napplications. Prior approaches have attempted to produce titles by selecting\nexisting text snippets associated with the table. These approaches, however,\nare limited by their dependence on suitable titles existing a priori. In our\nuser study, we observe that the relevant information for the title tends to be\nscattered across the page, and often--more than 80% of the time--does not\nappear verbatim anywhere in the page. We propose instead the application of a\nsequence-to-sequence neural network model as a more generalizable means of\ngenerating high-quality titles. This is accomplished by extracting many text\nsnippets that have potentially relevant information to the table, encoding them\ninto an input sequence, and using both copy and generation mechanisms in the\ndecoder to balance relevance and readability of the generated title. We\nvalidate this approach with human evaluation on sample web tables and report\nthat while sequence models with only a copy mechanism or only a generation\nmechanism are easily outperformed by simple selection-based baselines, the\nmodel with both capabilities outperforms them all, approaching the quality of\ncrowdsourced titles while training on fewer than ten thousand examples. To the\nbest of our knowledge, the proposed technique is the first to consider text\ngeneration methods for table titles and establishes a new state of the art. \n\n"}
{"id": "1807.00172", "contents": "Title: Algorithms for solving optimization problems arising from deep neural\n  net models: smooth problems Abstract: Machine Learning models incorporating multiple layered learning networks have\nbeen seen to provide effective models for various classification problems. The\nresulting optimization problem to solve for the optimal vector minimizing the\nempirical risk is, however, highly nonlinear. This presents a challenge to\napplication and development of appropriate optimization algorithms for solving\nthe problem. In this paper, we summarize the primary challenges involved and\npresent the case for a Newton-based method incorporating directions of negative\ncurvature, including promising numerical results on data arising from security\nanomally deetection. \n\n"}
{"id": "1807.00255", "contents": "Title: Stochastic model-based minimization under high-order growth Abstract: Given a nonsmooth, nonconvex minimization problem, we consider algorithms\nthat iteratively sample and minimize stochastic convex models of the objective\nfunction. Assuming that the one-sided approximation quality and the variation\nof the models is controlled by a Bregman divergence, we show that the scheme\ndrives a natural stationarity measure to zero at the rate $O(k^{-1/4})$. Under\nadditional convexity and relative strong convexity assumptions, the function\nvalues converge to the minimum at the rate of $O(k^{-1/2})$ and\n$\\widetilde{O}(k^{-1})$, respectively. We discuss consequences for stochastic\nproximal point, mirror descent, regularized Gauss-Newton, and saddle point\nalgorithms. \n\n"}
{"id": "1807.00448", "contents": "Title: Speeding up the Metabolism in E-commerce by Reinforcement Mechanism\n  Design Abstract: In a large E-commerce platform, all the participants compete for impressions\nunder the allocation mechanism of the platform. Existing methods mainly focus\non the short-term return based on the current observations instead of the\nlong-term return. In this paper, we formally establish the lifecycle model for\nproducts, by defining the introduction, growth, maturity and decline stages and\ntheir transitions throughout the whole life period. Based on such model, we\nfurther propose a reinforcement learning based mechanism design framework for\nimpression allocation, which incorporates the first principal component based\npermutation and the novel experiences generation method, to maximize short-term\nas well as long-term return of the platform. With the power of trial-and-error,\nit is possible to optimize impression allocation strategies globally which is\ncontribute to the healthy development of participants and the platform itself.\nWe evaluate our algorithm on a simulated environment built based on one of the\nlargest E-commerce platforms, and a significant improvement has been achieved\nin comparison with the baseline solutions. \n\n"}
{"id": "1807.01083", "contents": "Title: A Mean-Field Optimal Control Formulation of Deep Learning Abstract: Recent work linking deep neural networks and dynamical systems opened up new\navenues to analyze deep learning. In particular, it is observed that new\ninsights can be obtained by recasting deep learning as an optimal control\nproblem on difference or differential equations. However, the mathematical\naspects of such a formulation have not been systematically explored. This paper\nintroduces the mathematical formulation of the population risk minimization\nproblem in deep learning as a mean-field optimal control problem. Mirroring the\ndevelopment of classical optimal control, we state and prove optimality\nconditions of both the Hamilton-Jacobi-Bellman type and the Pontryagin type.\nThese mean-field results reflect the probabilistic nature of the learning\nproblem. In addition, by appealing to the mean-field Pontryagin's maximum\nprinciple, we establish some quantitative relationships between population and\nempirical learning problems. This serves to establish a mathematical foundation\nfor investigating the algorithmic and theoretical connections between optimal\ncontrol and deep learning. \n\n"}
{"id": "1807.01622", "contents": "Title: Neural Processes Abstract: A neural network (NN) is a parameterised function that can be tuned via\ngradient descent to approximate a labelled collection of data with high\nprecision. A Gaussian process (GP), on the other hand, is a probabilistic model\nthat defines a distribution over possible functions, and is updated in light of\ndata via the rules of probabilistic inference. GPs are probabilistic,\ndata-efficient and flexible, however they are also computationally intensive\nand thus limited in their applicability. We introduce a class of neural latent\nvariable models which we call Neural Processes (NPs), combining the best of\nboth worlds. Like GPs, NPs define distributions over functions, are capable of\nrapid adaptation to new observations, and can estimate the uncertainty in their\npredictions. Like NNs, NPs are computationally efficient during training and\nevaluation but also learn to adapt their priors to data. We demonstrate the\nperformance of NPs on a range of learning tasks, including regression and\noptimisation, and compare and contrast with related models in the literature. \n\n"}
{"id": "1807.02629", "contents": "Title: Optimistic mirror descent in saddle-point problems: Going the extra\n  (gradient) mile Abstract: Owing to their connection with generative adversarial networks (GANs),\nsaddle-point problems have recently attracted considerable interest in machine\nlearning and beyond. By necessity, most theoretical guarantees revolve around\nconvex-concave (or even linear) problems; however, making theoretical inroads\ntowards efficient GAN training depends crucially on moving beyond this classic\nframework. To make piecemeal progress along these lines, we analyze the\nbehavior of mirror descent (MD) in a class of non-monotone problems whose\nsolutions coincide with those of a naturally associated variational inequality\n- a property which we call coherence. We first show that ordinary, \"vanilla\" MD\nconverges under a strict version of this condition, but not otherwise; in\nparticular, it may fail to converge even in bilinear models with a unique\nsolution. We then show that this deficiency is mitigated by optimism: by taking\nan \"extra-gradient\" step, optimistic mirror descent (OMD) converges in all\ncoherent problems. Our analysis generalizes and extends the results of\nDaskalakis et al. (2018) for optimistic gradient descent (OGD) in bilinear\nproblems, and makes concrete headway for establishing convergence beyond\nconvex-concave games. We also provide stochastic analogues of these results,\nand we validate our analysis by numerical experiments in a wide array of GAN\nmodels (including Gaussian mixture models, as well as the CelebA and CIFAR-10\ndatasets). \n\n"}
{"id": "1807.03257", "contents": "Title: Data Efficient Lithography Modeling with Transfer Learning and Active\n  Data Selection Abstract: Lithography simulation is one of the key steps in physical verification,\nenabled by the substantial optical and resist models. A resist model bridges\nthe aerial image simulation to printed patterns. While the effectiveness of\nlearning-based solutions for resist modeling has been demonstrated, they are\nconsiderably data-demanding. Meanwhile, a set of manufactured data for a\nspecific lithography configuration is only valid for the training of one single\nmodel, indicating low data efficiency. Due to the complexity of the\nmanufacturing process, obtaining enough data for acceptable accuracy becomes\nvery expensive in terms of both time and cost, especially during the evolution\nof technology generations when the design space is intensively explored. In\nthis work, we propose a new resist modeling framework for contact layers,\nutilizing existing data from old technology nodes and active selection of data\nin a target technology node, to reduce the amount of data required from the\ntarget lithography configuration. Our framework based on transfer learning and\nactive learning techniques is effective within a competitive range of accuracy,\ni.e., 3-10X reduction on the amount of training data with comparable accuracy\nto the state-of-the-art learning approach. \n\n"}
{"id": "1807.03907", "contents": "Title: The Limit Points of (Optimistic) Gradient Descent in Min-Max\n  Optimization Abstract: Motivated by applications in Optimization, Game Theory, and the training of\nGenerative Adversarial Networks, the convergence properties of first order\nmethods in min-max problems have received extensive study. It has been\nrecognized that they may cycle, and there is no good understanding of their\nlimit points when they do not. When they converge, do they converge to local\nmin-max solutions? We characterize the limit points of two basic first order\nmethods, namely Gradient Descent/Ascent (GDA) and Optimistic Gradient Descent\nAscent (OGDA). We show that both dynamics avoid unstable critical points for\nalmost all initializations. Moreover, for small step sizes and under mild\nassumptions, the set of \\{OGDA\\}-stable critical points is a superset of\n\\{GDA\\}-stable critical points, which is a superset of local min-max solutions\n(strict in some cases). The connecting thread is that the behavior of these\ndynamics can be studied from a dynamical systems perspective. \n\n"}
{"id": "1807.04106", "contents": "Title: VFunc: a Deep Generative Model for Functions Abstract: We introduce a deep generative model for functions. Our model provides a\njoint distribution p(f, z) over functions f and latent variables z which lets\nus efficiently sample from the marginal p(f) and maximize a variational lower\nbound on the entropy H(f). We can thus maximize objectives of the form\nE_{f~p(f)}[R(f)] + c*H(f), where R(f) denotes, e.g., a data log-likelihood term\nor an expected reward. Such objectives encompass Bayesian deep learning in\nfunction space, rather than parameter space, and Bayesian deep RL with\nrepresentations of uncertainty that offer benefits over bootstrapping and\nparameter noise. In this short paper we describe our model, situate it in the\ncontext of prior work, and present proof-of-concept experiments for regression\nand RL. \n\n"}
{"id": "1807.04428", "contents": "Title: Convergence Rate of Block-Coordinate Maximization Burer-Monteiro Method\n  for Solving Large SDPs Abstract: Semidefinite programming (SDP) with diagonal constraints arise in many\noptimization problems, such as Max-Cut, community detection and group\nsynchronization. Although SDPs can be solved to arbitrary precision in\npolynomial time, generic convex solvers do not scale well with the dimension of\nthe problem. In order to address this issue, Burer and Monteiro proposed to\nreduce the dimension of the problem by appealing to a low-rank factorization\nand solve the subsequent non-convex problem instead. In this paper, we present\ncoordinate ascent based methods to solve this non-convex problem with provable\nconvergence guarantees. More specifically, we prove that the block-coordinate\nmaximization algorithm applied to the non-convex Burer-Monteiro method globally\nconverges to a first-order stationary point with a sublinear rate without any\nassumptions on the problem. We further show that this algorithm converges\nlinearly around a local maximum provided that the objective function exhibits\nquadratic decay. We establish that this condition generically holds when the\nrank of the factorization is sufficiently large. Furthermore, incorporating\nLanczos method to the block-coordinate maximization, we propose an algorithm\nthat is guaranteed to return a solution that provides $1-O(1/r)$ approximation\nto the original SDP without any assumptions, where $r$ is the rank of the\nfactorization. This approximation ratio is known to be optimal (up to\nconstants) under the unique games conjecture, and we can explicitly quantify\nthe number of iterations to obtain such a solution. \n\n"}
{"id": "1807.05595", "contents": "Title: Global Optimality in Separable Dictionary Learning with Applications to\n  the Analysis of Diffusion MRI Abstract: Sparse dictionary learning is a popular method for representing signals as\nlinear combinations of a few elements from a dictionary that is learned from\nthe data. In the classical setting, signals are represented as vectors and the\ndictionary learning problem is posed as a matrix factorization problem where\nthe data matrix is approximately factorized into a dictionary matrix and a\nsparse matrix of coefficients. However, in many applications in computer vision\nand medical imaging, signals are better represented as matrices or tensors\n(e.g. images or videos), where it may be beneficial to exploit the\nmulti-dimensional structure of the data to learn a more compact representation.\nOne such approach is separable dictionary learning, where one learns separate\ndictionaries for different dimensions of the data. However, typical\nformulations involve solving a non-convex optimization problem; thus\nguaranteeing global optimality remains a challenge. In this work, we propose a\nframework that builds upon recent developments in matrix factorization to\nprovide theoretical and numerical guarantees of global optimality for separable\ndictionary learning. We propose an algorithm to find such a globally optimal\nsolution, which alternates between following local descent steps and checking a\ncertificate for global optimality. We illustrate our approach on diffusion\nmagnetic resonance imaging (dMRI) data, a medical imaging modality that\nmeasures water diffusion along multiple angular directions in every voxel of an\nMRI volume. State-of-the-art methods in dMRI either learn dictionaries only for\nthe angular domain of the signals or in some cases learn spatial and angular\ndictionaries independently. In this work, we apply the proposed separable\ndictionary learning framework to learn spatial and angular dMRI dictionaries\njointly and provide preliminary validation on denoising phantom and real dMRI\nbrain data. \n\n"}
{"id": "1807.05832", "contents": "Title: Manifold Adversarial Learning Abstract: Recently proposed adversarial training methods show the robustness to both\nadversarial and original examples and achieve state-of-the-art results in\nsupervised and semi-supervised learning. All the existing adversarial training\nmethods consider only how the worst perturbed examples (i.e., adversarial\nexamples) could affect the model output. Despite their success, we argue that\nsuch setting may be in lack of generalization, since the output space (or label\nspace) is apparently less informative.In this paper, we propose a novel method,\ncalled Manifold Adversarial Training (MAT). MAT manages to build an adversarial\nframework based on how the worst perturbation could affect the distributional\nmanifold rather than the output space. Particularly, a latent data space with\nthe Gaussian Mixture Model (GMM) will be first derived.On one hand, MAT tries\nto perturb the input samples in the way that would rough the distributional\nmanifold the worst. On the other hand, the deep learning model is trained\ntrying to promote in the latent space the manifold smoothness, measured by the\nvariation of Gaussian mixtures (given the local perturbation around the data\npoint). Importantly, since the latent space is more informative than the output\nspace, the proposed MAT can learn better a robust and compact data\nrepresentation, leading to further performance improvement. The proposed MAT is\nimportant in that it can be considered as a superset of one recently-proposed\ndiscriminative feature learning approach called center loss. We conducted a\nseries of experiments in both supervised and semi-supervised learning on three\nbenchmark data sets, showing that the proposed MAT can achieve remarkable\nperformance, much better than those of the state-of-the-art adversarial\napproaches. We also present a series of visualization which could generate\nfurther understanding or explanation on adversarial examples. \n\n"}
{"id": "1807.05836", "contents": "Title: Forecasting market states Abstract: We propose a novel methodology to define, analyze and forecast market states.\nIn our approach market states are identified by a reference sparse precision\nmatrix and a vector of expectation values. In our procedure, each multivariate\nobservation is associated with a given market state accordingly to a\nminimization of a penalized Mahalanobis distance. The procedure is made\ncomputationally very efficient and can be used with a large number of assets.\nWe demonstrate that this procedure is successful at clustering different states\nof the markets in an unsupervised manner. In particular, we describe an\nexperiment with one hundred log-returns and two states in which the methodology\nautomatically associates states prevalently to pre- and post- crisis periods\nwith one state gathering periods with average positive returns and the other\nstate periods with average negative returns, therefore discovering\nspontaneously the common classification of `bull' and `bear' markets. In\nanother experiment, with again one hundred log-returns and two states, we\ndemonstrate that this procedure can be efficiently used to forecast off-sample\nfuture market states with significant prediction accuracy. This methodology\nopens the way to a range of applications in risk management and trading\nstrategies in the context where the correlation structure plays a central role. \n\n"}
{"id": "1807.06712", "contents": "Title: Evaluating Gaussian Process Metamodels and Sequential Designs for Noisy\n  Level Set Estimation Abstract: We consider the problem of learning the level set for which a noisy black-box\nfunction exceeds a given threshold. To efficiently reconstruct the level set,\nwe investigate Gaussian process (GP) metamodels. Our focus is on strongly\nstochastic samplers, in particular with heavy-tailed simulation noise and low\nsignal-to-noise ratio. To guard against noise misspecification, we assess the\nperformance of three variants: (i) GPs with Student-$t$ observations; (ii)\nStudent-$t$ processes (TPs); and (iii) classification GPs modeling the sign of\nthe response. In conjunction with these metamodels, we analyze several\nacquisition functions for guiding the sequential experimental designs,\nextending existing stepwise uncertainty reduction criteria to the stochastic\ncontour-finding context. This also motivates our development of (approximate)\nupdating formulas to efficiently compute such acquisition functions. Our\nschemes are benchmarked by using a variety of synthetic experiments in 1--6\ndimensions. We also consider an application of level set estimation for\ndetermining the optimal exercise policy of Bermudan options in finance. \n\n"}
{"id": "1807.07187", "contents": "Title: Efficient Training on Very Large Corpora via Gramian Estimation Abstract: We study the problem of learning similarity functions over very large corpora\nusing neural network embedding models. These models are typically trained using\nSGD with sampling of random observed and unobserved pairs, with a number of\nsamples that grows quadratically with the corpus size, making it expensive to\nscale to very large corpora. We propose new efficient methods to train these\nmodels without having to sample unobserved pairs. Inspired by matrix\nfactorization, our approach relies on adding a global quadratic penalty to all\npairs of examples and expressing this term as the matrix-inner-product of two\ngeneralized Gramians. We show that the gradient of this term can be efficiently\ncomputed by maintaining estimates of the Gramians, and develop variance\nreduction schemes to improve the quality of the estimates. We conduct\nlarge-scale experiments that show a significant improvement in training time\nand generalization quality compared to traditional sampling methods. \n\n"}
{"id": "1807.07603", "contents": "Title: Doubly Stochastic Adversarial Autoencoder Abstract: Any autoencoder network can be turned into a generative model by imposing an\narbitrary prior distribution on its hidden code vector. Variational Autoencoder\n(VAE) [2] uses a KL divergence penalty to impose the prior, whereas Adversarial\nAutoencoder (AAE) [1] uses {\\it generative adversarial networks} GAN [3]. GAN\ntrades the complexities of {\\it sampling} algorithms with the complexities of\n{\\it searching} Nash equilibrium in minimax games. Such minimax architectures\nget trained with the help of data examples and gradients flowing through a\ngenerator and an adversary. A straightforward modification of AAE is to replace\nthe adversary with the maximum mean discrepancy (MMD) test [4-5]. This\nreplacement leads to a new type of probabilistic autoencoder, which is also\ndiscussed in our paper. We propose a novel probabilistic autoencoder in which\nthe adversary of AAE is replaced with a space of {\\it stochastic} functions.\nThis replacement introduces a new source of randomness, which can be considered\nas a continuous control for encouraging {\\it explorations}. This prevents the\nadversary from fitting too closely to the generator and therefore leads to a\nmore diverse set of generated samples. \n\n"}
{"id": "1807.07610", "contents": "Title: Unsupervised Metric Learning in Presence of Missing Data Abstract: For many machine learning tasks, the input data lie on a low-dimensional\nmanifold embedded in a high dimensional space and, because of this\nhigh-dimensional structure, most algorithms are inefficient. The typical\nsolution is to reduce the dimension of the input data using standard dimension\nreduction algorithms such as ISOMAP, LAPLACIAN EIGENMAPS or LLES. This\napproach, however, does not always work in practice as these algorithms require\nthat we have somewhat ideal data. Unfortunately, most data sets either have\nmissing entries or unacceptably noisy values. That is, real data are far from\nideal and we cannot use these algorithms directly. In this paper, we focus on\nthe case when we have missing data. Some techniques, such as matrix completion,\ncan be used to fill in missing data but these methods do not capture the\nnon-linear structure of the manifold. Here, we present a new algorithm\nMR-MISSING that extends these previous algorithms and can be used to compute\nlow dimensional representation on data sets with missing entries. We\ndemonstrate the effectiveness of our algorithm by running three different\nexperiments. We visually verify the effectiveness of our algorithm on synthetic\nmanifolds, we numerically compare our projections against those computed by\nfirst filling in data using nlPCA and mDRUR on the MNIST data set, and we also\nshow that we can do classification on MNIST with missing data. We also provide\na theoretical guarantee for MR-MISSING under some simplifying assumptions. \n\n"}
{"id": "1807.09586", "contents": "Title: Perturb and Combine to Identify Influential Spreaders in Real-World\n  Networks Abstract: Some of the most effective influential spreader detection algorithms are\nunstable to small perturbations of the network structure. Inspired by bagging\nin Machine Learning, we propose the first Perturb and Combine (P&C) procedure\nfor networks. It (1) creates many perturbed versions of a given graph, (2)\napplies a node scoring function separately to each graph, and (3) combines the\nresults. Experiments conducted on real-world networks of various sizes with the\nk-core, generalized k-core, and PageRank algorithms reveal that P&C brings\nsubstantial improvements. Moreover, this performance boost can be obtained at\nalmost no extra cost through parallelization. Finally, a bias-variance analysis\nsuggests that P&C works mainly by reducing bias, and that therefore, it should\nbe capable of improving the performance of all vertex scoring functions,\nincluding stable ones. \n\n"}
{"id": "1807.09842", "contents": "Title: Understanding and representing the semantics of large structured\n  documents Abstract: Understanding large, structured documents like scholarly articles, requests\nfor proposals or business reports is a complex and difficult task. It involves\ndiscovering a document's overall purpose and subject(s), understanding the\nfunction and meaning of its sections and subsections, and extracting low level\nentities and facts about them. In this research, we present a deep learning\nbased document ontology to capture the general purpose semantic structure and\ndomain specific semantic concepts from a large number of academic articles and\nbusiness documents. The ontology is able to describe different functional parts\nof a document, which can be used to enhance semantic indexing for a better\nunderstanding by human beings and machines. We evaluate our models through\nextensive experiments on datasets of scholarly articles from arXiv and Request\nfor Proposal documents. \n\n"}
{"id": "1807.09979", "contents": "Title: Bayesian Optimal Design of Experiments For Inferring The Statistical\n  Expectation Of A Black-Box Function Abstract: Bayesian optimal design of experiments (BODE) has been successful in\nacquiring information about a quantity of interest (QoI) which depends on a\nblack-box function. BODE is characterized by sequentially querying the function\nat specific designs selected by an infill-sampling criterion. However, most\ncurrent BODE methods operate in specific contexts like optimization, or\nlearning a universal representation of the black-box function. The objective of\nthis paper is to design a BODE for estimating the statistical expectation of a\nphysical response surface. This QoI is omnipresent in uncertainty propagation\nand design under uncertainty problems. Our hypothesis is that an optimal BODE\nshould be maximizing the expected information gain in the QoI. We represent the\ninformation gain from a hypothetical experiment as the Kullback-Liebler (KL)\ndivergence between the prior and the posterior probability distributions of the\nQoI. The prior distribution of the QoI is conditioned on the observed data and\nthe posterior distribution of the QoI is conditioned on the observed data and a\nhypothetical experiment. The main contribution of this paper is the derivation\nof a semi-analytic mathematical formula for the expected information gain about\nthe statistical expectation of a physical response. The developed BODE is\nvalidated on synthetic functions with varying number of input-dimensions. We\ndemonstrate the performance of the methodology on a steel wire manufacturing\nproblem. \n\n"}
{"id": "1807.10328", "contents": "Title: Selective Clustering Annotated using Modes of Projections Abstract: Selective clustering annotated using modes of projections (SCAMP) is a new\nclustering algorithm for data in $\\mathbb{R}^p$. SCAMP is motivated from the\npoint of view of non-parametric mixture modeling. Rather than maximizing a\nclassification likelihood to determine cluster assignments, SCAMP casts\nclustering as a search and selection problem. One consequence of this problem\nformulation is that the number of clusters is $\\textbf{not}$ a SCAMP tuning\nparameter. The search phase of SCAMP consists of finding sub-collections of the\ndata matrix, called candidate clusters, that obey shape constraints along each\ncoordinate projection. An extension of the dip test of Hartigan and Hartigan\n(1985) is developed to assist the search. Selection occurs by scoring each\ncandidate cluster with a preference function that quantifies prior belief about\nthe mixture composition. Clustering proceeds by selecting candidates to\nmaximize their total preference score. SCAMP concludes by annotating each\nselected cluster with labels that describe how cluster-level statistics compare\nto certain dataset-level quantities. SCAMP can be run multiple times on a\nsingle data matrix. Comparison of annotations obtained across iterations\nprovides a measure of clustering uncertainty. Simulation studies and\napplications to real data are considered. A C++ implementation with R interface\nis $\\href{https://github.com/RGLab/scamp}{available\\ online}$. \n\n"}
{"id": "1807.10363", "contents": "Title: Message-passing neural networks for high-throughput polymer screening Abstract: Machine learning methods have shown promise in predicting molecular\nproperties, and given sufficient training data machine learning approaches can\nenable rapid high-throughput virtual screening of large libraries of compounds.\nGraph-based neural network architectures have emerged in recent years as the\nmost successful approach for predictions based on molecular structure, and have\nconsistently achieved the best performance on benchmark quantum chemical\ndatasets. However, these models have typically required optimized 3D structural\ninformation for the molecule to achieve the highest accuracy. These 3D\ngeometries are costly to compute for high levels of theory, limiting the\napplicability and practicality of machine learning methods in high-throughput\nscreening applications. In this study, we present a new database of candidate\nmolecules for organic photovoltaic applications, comprising approximately\n91,000 unique chemical structures.Compared to existing datasets, this dataset\ncontains substantially larger molecules (up to 200 atoms) as well as\nextrapolated properties for long polymer chains. We show that message-passing\nneural networks trained with and without 3D structural information for these\nmolecules achieve similar accuracy, comparable to state-of-the-art methods on\nexisting benchmark datasets. These results therefore emphasize that for larger\nmolecules with practical applications, near-optimal prediction results can be\nobtained without using optimized 3D geometry as an input. We further show that\nlearned molecular representations can be leveraged to reduce the training data\nrequired to transfer predictions to a new DFT functional. \n\n"}
{"id": "1807.10487", "contents": "Title: Pull Message Passing for Nonparametric Belief Propagation Abstract: We present a \"pull\" approach to approximate products of Gaussian mixtures\nwithin message updates for Nonparametric Belief Propagation (NBP) inference.\nExisting NBP methods often represent messages between continuous-valued latent\nvariables as Gaussian mixture models. To avoid computational intractability in\nloopy graphs, NBP necessitates an approximation of the product of such\nmixtures. Sampling-based product approximations have shown effectiveness for\nNBP inference. However, such approximations used within the traditional \"push\"\nmessage update procedures quickly become computationally prohibitive for\nmulti-modal distributions over high-dimensional variables. In contrast, we\npropose a \"pull\" method, as the Pull Message Passing for Nonparametric Belief\npropagation (PMPNBP) algorithm, and demonstrate its viability for efficient\ninference. We report results using an experiment from an existing NBP method,\nPAMPAS, for inferring the pose of an articulated structure in clutter. Results\nfrom this illustrative problem found PMPNBP has a greater ability to\nefficiently scale the number of components in its mixtures and, consequently,\nimprove inference accuracy. \n\n"}
{"id": "1807.10588", "contents": "Title: A Modality-Adaptive Method for Segmenting Brain Tumors and\n  Organs-at-Risk in Radiation Therapy Planning Abstract: In this paper we present a method for simultaneously segmenting brain tumors\nand an extensive set of organs-at-risk for radiation therapy planning of\nglioblastomas. The method combines a contrast-adaptive generative model for\nwhole-brain segmentation with a new spatial regularization model of tumor shape\nusing convolutional restricted Boltzmann machines. We demonstrate\nexperimentally that the method is able to adapt to image acquisitions that\ndiffer substantially from any available training data, ensuring its\napplicability across treatment sites; that its tumor segmentation accuracy is\ncomparable to that of the current state of the art; and that it captures most\norgans-at-risk sufficiently well for radiation therapy planning purposes. The\nproposed method may be a valuable step towards automating the delineation of\nbrain tumors and organs-at-risk in glioblastoma patients undergoing radiation\ntherapy. \n\n"}
{"id": "1807.10997", "contents": "Title: Optimal Tap Setting of Voltage Regulation Transformers Using Batch\n  Reinforcement Learning Abstract: In this paper, we address the problem of setting the tap positions of load\ntap changers (LTCs) for voltage regulation in radial power distribution systems\nunder uncertain load dynamics. The objective is to find a policy to determine\nthe tap positions that only uses measurements of voltage magnitudes and\ntopology information so as to minimize the voltage deviation across the system.\nWe formulate this problem as a Markov decision process (MDP), and propose a\nbatch reinforcement learning (RL) algorithm to solve it. By taking advantage of\na linearized power flow model, we propose an effective algorithm to estimate\nthe voltage magnitudes under different tap settings, which allows the RL\nalgorithm to explore the state and action spaces freely offline without\nimpacting the system operation. To circumvent the \"curse of dimensionality\"\nresulted from the large state and action spaces, we propose a sequential\nlearning algorithm to learn an action-value function for each LTC, based on\nwhich the optimal tap positions can be directly determined. The effectiveness\nof the proposed algorithm is validated via numerical simulations on the IEEE\n13-bus and 123-bus distribution test feeders. \n\n"}
{"id": "1807.11560", "contents": "Title: Efficient Gauss-Newton-Krylov momentum conservation constrained\n  PDE-LDDMM using the band-limited vector field parameterization Abstract: The class of non-rigid registration methods proposed in the framework of\nPDE-constrained Large Deformation Diffeomorphic Metric Mapping is a\nparticularly interesting family of physically meaningful diffeomorphic\nregistration methods. PDE-constrained LDDMM methods are formulated as\nconstrained variational problems, where the different physical models are\nimposed using the associated partial differential equations as hard\nconstraints. Inexact Newton-Krylov optimization has shown an excellent\nnumerical accuracy and an extraordinarily fast convergence rate in this\nframework. However, the Galerkin representation of the non-stationary velocity\nfields does not provide proper geodesic paths. In a previous work, we proposed\na method for PDE-constrained LDDMM parameterized in the space of initial\nvelocity fields under the EPDiff equation. The proposed method provided\ngeodesics in the framework of PDE-constrained LDDMM, and it showed performance\ncompetitive to benchmark PDE-constrained LDDMM and EPDiff-LDDMM methods.\nHowever, the major drawback of this method was the large memory load inherent\nto PDE-constrained LDDMM methods and the increased computational time with\nrespect to the benchmark methods. In this work we optimize the computational\ncomplexity of the method using the band-limited vector field parameterization\nclosing the loop with our previous works. \n\n"}
{"id": "1807.11876", "contents": "Title: Predicting Tactical Solutions to Operational Planning Problems under\n  Imperfect Information Abstract: This paper offers a methodological contribution at the intersection of\nmachine learning and operations research. Namely, we propose a methodology to\nquickly predict expected tactical descriptions of operational solutions\n(TDOSs). The problem we address occurs in the context of two-stage stochastic\nprogramming where the second stage is demanding computationally. We aim to\npredict at a high speed the expected TDOS associated with the second stage\nproblem, conditionally on the first stage variables. This may be used in\nsupport of the solution to the overall two-stage problem by avoiding the online\ngeneration of multiple second stage scenarios and solutions. We formulate the\ntactical prediction problem as a stochastic optimal prediction program, whose\nsolution we approximate with supervised machine learning. The training dataset\nconsists of a large number of deterministic operational problems generated by\ncontrolled probabilistic sampling. The labels are computed based on solutions\nto these problems (solved independently and offline), employing appropriate\naggregation and subselection methods to address uncertainty. Results on our\nmotivating application on load planning for rail transportation show that deep\nlearning models produce accurate predictions in very short computing time\n(milliseconds or less). The predictive accuracy is close to the lower bounds\ncalculated based on sample average approximation of the stochastic prediction\nprograms. \n\n"}
{"id": "1808.00300", "contents": "Title: Learning Visual Question Answering by Bootstrapping Hard Attention Abstract: Attention mechanisms in biological perception are thought to select subsets\nof perceptual information for more sophisticated processing which would be\nprohibitive to perform on all sensory inputs. In computer vision, however,\nthere has been relatively little exploration of hard attention, where some\ninformation is selectively ignored, in spite of the success of soft attention,\nwhere information is re-weighted and aggregated, but never filtered out. Here,\nwe introduce a new approach for hard attention and find it achieves very\ncompetitive performance on a recently-released visual question answering\ndatasets, equalling and in some cases surpassing similar soft attention\narchitectures while entirely ignoring some features. Even though the hard\nattention mechanism is thought to be non-differentiable, we found that the\nfeature magnitudes correlate with semantic relevance, and provide a useful\nsignal for our mechanism's attentional selection criterion. Because hard\nattention selects important features of the input information, it can also be\nmore efficient than analogous soft attention mechanisms. This is especially\nimportant for recent approaches that use non-local pairwise operations, whereby\ncomputational and memory costs are quadratic in the size of the set of\nfeatures. \n\n"}
{"id": "1808.00380", "contents": "Title: A Differentially Private Kernel Two-Sample Test Abstract: Kernel two-sample testing is a useful statistical tool in determining whether\ndata samples arise from different distributions without imposing any parametric\nassumptions on those distributions. However, raw data samples can expose\nsensitive information about individuals who participate in scientific studies,\nwhich makes the current tests vulnerable to privacy breaches. Hence, we design\na new framework for kernel two-sample testing conforming to differential\nprivacy constraints, in order to guarantee the privacy of subjects in the data.\nUnlike existing differentially private parametric tests that simply add noise\nto data, kernel-based testing imposes a challenge due to a complex dependence\nof test statistics on the raw data, as these statistics correspond to\nestimators of distances between representations of probability measures in\nHilbert spaces. Our approach considers finite dimensional approximations to\nthose representations. As a result, a simple chi-squared test is obtained,\nwhere a test statistic depends on a mean and covariance of empirical\ndifferences between the samples, which we perturb for a privacy guarantee. We\ninvestigate the utility of our framework in two realistic settings and conclude\nthat our method requires only a relatively modest increase in sample size to\nachieve a similar level of power to the non-private tests in both settings. \n\n"}
{"id": "1808.00529", "contents": "Title: Open Category Detection with PAC Guarantees Abstract: Open category detection is the problem of detecting \"alien\" test instances\nthat belong to categories or classes that were not present in the training\ndata. In many applications, reliably detecting such aliens is central to\nensuring the safety and accuracy of test set predictions. Unfortunately, there\nare no algorithms that provide theoretical guarantees on their ability to\ndetect aliens under general assumptions. Further, while there are algorithms\nfor open category detection, there are few empirical results that directly\nreport alien detection rates. Thus, there are significant theoretical and\nempirical gaps in our understanding of open category detection. In this paper,\nwe take a step toward addressing this gap by studying a simple, but\npractically-relevant variant of open category detection. In our setting, we are\nprovided with a \"clean\" training set that contains only the target categories\nof interest and an unlabeled \"contaminated\" training set that contains a\nfraction $\\alpha$ of alien examples. Under the assumption that we know an upper\nbound on $\\alpha$, we develop an algorithm with PAC-style guarantees on the\nalien detection rate, while aiming to minimize false alarms. Empirical results\non synthetic and standard benchmark datasets demonstrate the regimes in which\nthe algorithm can be effective and provide a baseline for further advancements. \n\n"}
{"id": "1808.01531", "contents": "Title: Global Convergence to the Equilibrium of GANs using Variational\n  Inequalities Abstract: In optimization, the negative gradient of a function denotes the direction of\nsteepest descent. Furthermore, traveling in any direction orthogonal to the\ngradient maintains the value of the function. In this work, we show that these\northogonal directions that are ignored by gradient descent can be critical in\nequilibrium problems. Equilibrium problems have drawn heightened attention in\nmachine learning due to the emergence of the Generative Adversarial Network\n(GAN). We use the framework of Variational Inequalities to analyze popular\ntraining algorithms for a fundamental GAN variant: the Wasserstein\nLinear-Quadratic GAN. We show that the steepest descent direction causes\ndivergence from the equilibrium, and convergence to the equilibrium is achieved\nthrough following a particular orthogonal direction. We call this successful\ntechnique Crossing-the-Curl, named for its mathematical derivation as well as\nits intuition: identify the game's axis of rotation and move \"across\" space in\nthe direction towards smaller \"curling\". \n\n"}
{"id": "1808.01563", "contents": "Title: Solutions of partition function-based TU games for cooperative\n  communication networking Abstract: In networked communications nodes choose among available actions and benefit\nfrom exchanging information through edges, while continuous technological\nprogress fosters system functionings that increasingly often rely on\ncooperation. Growing attention is being placed on coalition formation, where\neach node chooses what coalition to join, while the surplus generated by\ncooperation is an amount of TU (transferable utility) quantified by a\nreal-valued function defined on partitions -or even embedded coalitions- of\nnodes. A TU-sharing rule is thus essential, as how players are rewarded\ndetermines their behavior. This work offers a new option for distributing\npartition function-based surpluses, dealing with cooperative game theory in\nterms of both global games and games in partition function form, namely lattice\nfunctions, while the sharing rule is a point-valued solution or value. The\nnovelty is grounded on the combinatorial definition of such solutions as\nlattice functions whose M\\\"obius inversion lives only on atoms, i.e. on the\nfirst level of the lattice. While simply rephrasing the traditional solution\nconcept for standard coalitional games, this leads to distribute the surplus\ngenerated by partitions across the edges of the network, as the atoms among\npartitions are unordered pairs of players. These shares of edges are further\ndivided between nodes, but the corresponding Shapley value is very different\nfrom the traditional one and leads to two alternative forms, obtained by\nfocusing either on marginal contributions along maximal chains, or else on the\nuniform division of Harsanyi dividends. The core is also addressed, and\nsupermodularity is no longer sufficient for its non-emptiness. \n\n"}
{"id": "1808.02174", "contents": "Title: Test without Trust: Optimal Locally Private Distribution Testing Abstract: We study the problem of distribution testing when the samples can only be\naccessed using a locally differentially private mechanism and focus on two\nrepresentative testing questions of identity (goodness-of-fit) and independence\ntesting for discrete distributions. We are concerned with two settings: First,\nwhen we insist on using an already deployed, general-purpose locally\ndifferentially private mechanism such as the popular RAPPOR or the recently\nintroduced Hadamard Response for collecting data, and must build our tests\nbased on the data collected via this mechanism; and second, when no such\nrestriction is imposed, and we can design a bespoke mechanism specifically for\ntesting. For the latter purpose, we introduce the Randomized Aggregated Private\nTesting Optimal Response (RAPTOR) mechanism which is remarkably simple and\nrequires only one bit of communication per sample.\n  We propose tests based on these mechanisms and analyze their sample\ncomplexities. Each proposed test can be implemented efficiently. In each case\n(barring one), we complement our performance bounds for algorithms with\ninformation-theoretic lower bounds and establish sample optimality of our\nproposed algorithm. A peculiar feature that emerges is that our sample-optimal\nalgorithm based on RAPTOR uses public-coins, and any test based on RAPPOR or\nHadamard Response, which are both private-coin mechanisms, requires\nsignificantly more samples. \n\n"}
{"id": "1808.02180", "contents": "Title: Instance-Dependent PU Learning by Bayesian Optimal Relabeling Abstract: When learning from positive and unlabelled data, it is a strong assumption\nthat the positive observations are randomly sampled from the distribution of\n$X$ conditional on $Y = 1$, where X stands for the feature and Y the label.\nMost existing algorithms are optimally designed under the assumption. However,\nfor many real-world applications, the observed positive examples are dependent\non the conditional probability $P(Y = 1|X)$ and should be sampled biasedly. In\nthis paper, we assume that a positive example with a higher $P(Y = 1|X)$ is\nmore likely to be labelled and propose a probabilistic-gap based PU learning\nalgorithms. Specifically, by treating the unlabelled data as noisy negative\nexamples, we could automatically label a group positive and negative examples\nwhose labels are identical to the ones assigned by a Bayesian optimal\nclassifier with a consistency guarantee. The relabelled examples have a biased\ndomain, which is remedied by the kernel mean matching technique. The proposed\nalgorithm is model-free and thus do not have any parameters to tune.\nExperimental results demonstrate that our method works well on both generated\nand real-world datasets. \n\n"}
{"id": "1808.03258", "contents": "Title: Application of Bounded Total Variation Denoising in Urban Traffic\n  Analysis Abstract: While it is believed that denoising is not always necessary in many big data\napplications, we show in this paper that denoising is helpful in urban traffic\nanalysis by applying the method of bounded total variation denoising to the\nurban road traffic prediction and clustering problem. We propose two\neasy-to-implement methods to estimate the noise strength parameter in the\ndenoising algorithm, and apply the denoising algorithm to GPS-based traffic\ndata from Beijing taxi system. For the traffic prediction problem, we combine\nneural network and history matching method for roads randomly chosen from an\nurban area of Beijing. Numerical experiments show that the predicting accuracy\nis improved significantly by applying the proposed bounded total variation\ndenoising algorithm. We also test the algorithm on clustering problem, where a\nrecently developed clustering analysis method is applied to more than one\nhundred urban road segments in Beijing based on their velocity profiles. Better\nclustering result is obtained after denoising. \n\n"}
{"id": "1808.03265", "contents": "Title: A Hybrid Recommender System for Patient-Doctor Matchmaking in Primary\n  Care Abstract: We partner with a leading European healthcare provider and design a mechanism\nto match patients with family doctors in primary care. We define the\nmatchmaking process for several distinct use cases given different levels of\navailable information about patients. Then, we adopt a hybrid recommender\nsystem to present each patient a list of family doctor recommendations. In\nparticular, we model patient trust of family doctors using a large-scale\ndataset of consultation histories, while accounting for the temporal dynamics\nof their relationships. Our proposed approach shows higher predictive accuracy\nthan both a heuristic baseline and a collaborative filtering approach, and the\nproposed trust measure further improves model performance. \n\n"}
{"id": "1808.03314", "contents": "Title: Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term\n  Memory (LSTM) Network Abstract: Because of their effectiveness in broad practical applications, LSTM networks\nhave received a wealth of coverage in scientific journals, technical blogs, and\nimplementation guides. However, in most articles, the inference formulas for\nthe LSTM network and its parent, RNN, are stated axiomatically, while the\ntraining formulas are omitted altogether. In addition, the technique of\n\"unrolling\" an RNN is routinely presented without justification throughout the\nliterature. The goal of this paper is to explain the essential RNN and LSTM\nfundamentals in a single document. Drawing from concepts in signal processing,\nwe formally derive the canonical RNN formulation from differential equations.\nWe then propose and prove a precise statement, which yields the RNN unrolling\ntechnique. We also review the difficulties with training the standard RNN and\naddress them by transforming the RNN into the \"Vanilla LSTM\" network through a\nseries of logical arguments. We provide all equations pertaining to the LSTM\nsystem together with detailed descriptions of its constituent entities. Albeit\nunconventional, our choice of notation and the method for presenting the LSTM\nsystem emphasizes ease of understanding. As part of the analysis, we identify\nnew opportunities to enrich the LSTM system and incorporate these extensions\ninto the Vanilla LSTM network, producing the most general LSTM variant to date.\nThe target reader has already been exposed to RNNs and LSTM networks through\nnumerous available resources and is open to an alternative pedagogical\napproach. A Machine Learning practitioner seeking guidance for implementing our\nnew augmented LSTM model in software for experimentation and research will find\nthe insights and derivations in this tutorial valuable as well. \n\n"}
{"id": "1808.04228", "contents": "Title: DFTerNet: Towards 2-bit Dynamic Fusion Networks for Accurate Human\n  Activity Recognition Abstract: Deep Convolutional Neural Networks (DCNNs) are currently popular in human\nactivity recognition applications. However, in the face of modern artificial\nintelligence sensor-based games, many research achievements cannot be\npractically applied on portable devices. DCNNs are typically resource-intensive\nand too large to be deployed on portable devices, thus this limits the\npractical application of complex activity detection. In addition, since\nportable devices do not possess high-performance Graphic Processing Units\n(GPUs), there is hardly any improvement in Action Game (ACT) experience.\nBesides, in order to deal with multi-sensor collaboration, all previous human\nactivity recognition models typically treated the representations from\ndifferent sensor signal sources equally. However, distinct types of activities\nshould adopt different fusion strategies. In this paper, a novel scheme is\nproposed. This scheme is used to train 2-bit Convolutional Neural Networks with\nweights and activations constrained to {-0.5,0,0.5}. It takes into account the\ncorrelation between different sensor signal sources and the activity types.\nThis model, which we refer to as DFTerNet, aims at producing a more reliable\ninference and better trade-offs for practical applications. Our basic idea is\nto exploit quantization of weights and activations directly in pre-trained\nfilter banks and adopt dynamic fusion strategies for different activity types.\nExperiments demonstrate that by using dynamic fusion strategy can exceed the\nbaseline model performance by up to ~5% on activity recognition like\nOPPORTUNITY and PAMAP2 datasets. Using the quantization method proposed, we\nwere able to achieve performances closer to that of full-precision counterpart.\nThese results were also verified using the UniMiB-SHAR dataset. In addition,\nthe proposed method can achieve ~9x acceleration on CPUs and ~11x memory\nsaving. \n\n"}
{"id": "1808.04256", "contents": "Title: CT Super-resolution GAN Constrained by the Identical, Residual, and\n  Cycle Learning Ensemble(GAN-CIRCLE) Abstract: Computed tomography (CT) is widely used in screening, diagnosis, and\nimage-guided therapy for both clinical and research purposes. Since CT involves\nionizing radiation, an overarching thrust of related technical research is\ndevelopment of novel methods enabling ultrahigh quality imaging with fine\nstructural details while reducing the X-ray radiation. In this paper, we\npresent a semi-supervised deep learning approach to accurately recover\nhigh-resolution (HR) CT images from low-resolution (LR) counterparts.\nSpecifically, with the generative adversarial network (GAN) as the building\nblock, we enforce the cycle-consistency in terms of the Wasserstein distance to\nestablish a nonlinear end-to-end mapping from noisy LR input images to denoised\nand deblurred HR outputs. We also include the joint constraints in the loss\nfunction to facilitate structural preservation. In this deep imaging process,\nwe incorporate deep convolutional neural network (CNN), residual learning, and\nnetwork in network techniques for feature extraction and restoration. In\ncontrast to the current trend of increasing network depth and complexity to\nboost the CT imaging performance, which limit its real-world applications by\nimposing considerable computational and memory overheads, we apply a parallel\n$1\\times1$ CNN to compress the output of the hidden layer and optimize the\nnumber of layers and the number of filters for each convolutional layer.\nQuantitative and qualitative evaluations demonstrate that our proposed model is\naccurate, efficient and robust for super-resolution (SR) image restoration from\nnoisy LR input images. In particular, we validate our composite SR networks on\nthree large-scale CT datasets, and obtain promising results as compared to the\nother state-of-the-art methods. \n\n"}
{"id": "1808.04759", "contents": "Title: An Overview and a Benchmark of Active Learning for Outlier Detection\n  with One-Class Classifiers Abstract: Active learning methods increase classification quality by means of user\nfeedback. An important subcategory is active learning for outlier detection\nwith one-class classifiers. While various methods in this category exist,\nselecting one for a given application scenario is difficult. This is because\nexisting methods rely on different assumptions, have different objectives, and\noften are tailored to a specific use case. All this calls for a comprehensive\ncomparison, the topic of this article. This article starts with a\ncategorization of the various methods. We then propose ways to evaluate active\nlearning results. Next, we run extensive experiments to compare existing\nmethods, for a broad variety of scenarios. Based on our results, we formulate\nguidelines on how to select active learning methods for outlier detection with\none-class classifiers. \n\n"}
{"id": "1808.04875", "contents": "Title: Multi-user Communication Networks: A Coordinated Multi-armed Bandit\n  Approach Abstract: Communication networks shared by many users are a widespread challenge\nnowadays. In this paper we address several aspects of this challenge\nsimultaneously: learning unknown stochastic network characteristics, sharing\nresources with other users while keeping coordination overhead to a minimum.\nThe proposed solution combines Multi-Armed Bandit learning with a lightweight\nsignalling-based coordination scheme, and ensures convergence to a stable\nallocation of resources. Our work considers single-user level algorithms for\ntwo scenarios: an unknown fixed number of users, and a dynamic number of users.\nAnalytic performance guarantees, proving convergence to stable marriage\nconfigurations, are presented for both setups. The algorithms are designed\nbased on a system-wide perspective, rather than focusing on single user\nwelfare. Thus, maximal resource utilization is ensured. An extensive\nexperimental analysis covers convergence to a stable configuration as well as\nreward maximization. Experiments are carried out over a wide range of setups,\ndemonstrating the advantages of our approach over existing state-of-the-art\nmethods. \n\n"}
{"id": "1808.05140", "contents": "Title: A Framework for Automated Cellular Network Tuning with Reinforcement\n  Learning Abstract: Tuning cellular network performance against always occurring wireless\nimpairments can dramatically improve reliability to end users. In this paper,\nwe formulate cellular network performance tuning as a reinforcement learning\n(RL) problem and provide a solution to improve the performance for indoor and\noutdoor environments. By leveraging the ability of Q-learning to estimate\nfuture performance improvement rewards, we propose two algorithms: (1) closed\nloop power control (PC) for downlink voice over LTE (VoLTE) and (2)\nself-organizing network (SON) fault management. The VoLTE PC algorithm uses RL\nto adjust the indoor base station transmit power so that the signal to\ninterference plus noise ratio (SINR) of a user equipment (UE) meets the target\nSINR. It does so without the UE having to send power control requests. The SON\nfault management algorithm uses RL to improve the performance of an outdoor\nbase station cluster by resolving faults in the network through configuration\nmanagement. Both algorithms exploit measurements from the connected users,\nwireless impairments, and relevant configuration parameters to solve a\nnon-convex performance optimization problem using RL. Simulation results show\nthat our proposed RL based algorithms outperform the industry standards today\nin realistic cellular communication environments. \n\n"}
{"id": "1808.05160", "contents": "Title: Backtracking gradient descent method for general $C^1$ functions, with\n  applications to Deep Learning Abstract: While Standard gradient descent is one very popular optimisation method, its\nconvergence cannot be proven beyond the class of functions whose gradient is\nglobally Lipschitz continuous. As such, it is not actually applicable to\nrealistic applications such as Deep Neural Networks. In this paper, we prove\nthat its backtracking variant behaves very nicely, in particular convergence\ncan be shown for all Morse functions. The main theoretical result of this paper\nis as follows.\n  Theorem. Let $f:\\mathbb{R}^k\\rightarrow \\mathbb{R}$ be a $C^1$ function, and\n$\\{z_n\\}$ a sequence constructed from the Backtracking gradient descent\nalgorithm. (1) Either $\\lim _{n\\rightarrow\\infty}||z_n||=\\infty$ or $\\lim\n_{n\\rightarrow\\infty}||z_{n+1}-z_n||=0$. (2) Assume that $f$ has at most\ncountably many critical points. Then either $\\lim\n_{n\\rightarrow\\infty}||z_n||=\\infty$ or $\\{z_n\\}$ converges to a critical point\nof $f$. (3) More generally, assume that all connected components of the set of\ncritical points of $f$ are compact. Then either $\\lim\n_{n\\rightarrow\\infty}||z_n||=\\infty$ or $\\{z_n\\}$ is bounded. Moreover, in the\nlatter case the set of cluster points of $\\{z_n\\}$ is connected.\n  Some generalised versions of this result, including an inexact version, are\nincluded. Another result in this paper concerns the problem of saddle points.\nWe then present a heuristic argument to explain why Standard gradient descent\nmethod works so well, and modifications of the backtracking versions of GD, MMT\nand NAG. Experiments with datasets CIFAR10 and CIFAR100 on various popular\narchitectures verify the heuristic argument also for the mini-batch practice\nand show that our new algorithms, while automatically fine tuning learning\nrates, perform better than current state-of-the-art methods such as MMT, NAG,\nAdagrad, Adadelta, RMSProp, Adam and Adamax. \n\n"}
{"id": "1808.06910", "contents": "Title: Scalable Population Synthesis with Deep Generative Modeling Abstract: Population synthesis is concerned with the generation of synthetic yet\nrealistic representations of populations. It is a fundamental problem in the\nmodeling of transport where the synthetic populations of micro-agents represent\na key input to most agent-based models. In this paper, a new methodological\nframework for how to 'grow' pools of micro-agents is presented. The model\nframework adopts a deep generative modeling approach from machine learning\nbased on a Variational Autoencoder (VAE). Compared to the previous population\nsynthesis approaches, including Iterative Proportional Fitting (IPF), Gibbs\nsampling and traditional generative models such as Bayesian Networks or Hidden\nMarkov Models, the proposed method allows fitting the full joint distribution\nfor high dimensions. The proposed methodology is compared with a conventional\nGibbs sampler and a Bayesian Network by using a large-scale Danish trip diary.\nIt is shown that, while these two methods outperform the VAE in the\nlow-dimensional case, they both suffer from scalability issues when the number\nof modeled attributes increases. It is also shown that the Gibbs sampler\nessentially replicates the agents from the original sample when the required\nconditional distributions are estimated as frequency tables. In contrast, the\nVAE allows addressing the problem of sampling zeros by generating agents that\nare virtually different from those in the original data but have similar\nstatistical properties. The presented approach can support agent-based modeling\nat all levels by enabling richer synthetic populations with smaller zones and\nmore detailed individual characteristics. \n\n"}
{"id": "1808.07382", "contents": "Title: Convergence of Cubic Regularization for Nonconvex Optimization under KL\n  Property Abstract: Cubic-regularized Newton's method (CR) is a popular algorithm that guarantees\nto produce a second-order stationary solution for solving nonconvex\noptimization problems. However, existing understandings of the convergence rate\nof CR are conditioned on special types of geometrical properties of the\nobjective function. In this paper, we explore the asymptotic convergence rate\nof CR by exploiting the ubiquitous Kurdyka-Lojasiewicz (KL) property of\nnonconvex objective functions. In specific, we characterize the asymptotic\nconvergence rate of various types of optimality measures for CR including\nfunction value gap, variable distance gap, gradient norm and least eigenvalue\nof the Hessian matrix. Our results fully characterize the diverse convergence\nbehaviors of these optimality measures in the full parameter regime of the KL\nproperty. Moreover, we show that the obtained asymptotic convergence rates of\nCR are order-wise faster than those of first-order gradient descent algorithms\nunder the KL property. \n\n"}
{"id": "1808.07384", "contents": "Title: A Note on Inexact Condition for Cubic Regularized Newton's Method Abstract: This note considers the inexact cubic-regularized Newton's method (CR), which\nhas been shown in \\cite{Cartis2011a} to achieve the same order-level\nconvergence rate to a secondary stationary point as the exact CR\n\\citep{Nesterov2006}. However, the inexactness condition in \\cite{Cartis2011a}\nis not implementable due to its dependence on future iterates variable. This\nnote fixes such an issue by proving the same convergence rate for nonconvex\noptimization under an inexact adaptive condition that depends on only the\ncurrent iterate. Our proof controls the sufficient decrease of the function\nvalue over the total iterations rather than each iteration as used in the\nprevious studies, which can be of independent interest in other contexts. \n\n"}
{"id": "1808.08166", "contents": "Title: An Empirical Study of Rich Subgroup Fairness for Machine Learning Abstract: Kearns et al. [2018] recently proposed a notion of rich subgroup fairness\nintended to bridge the gap between statistical and individual notions of\nfairness. Rich subgroup fairness picks a statistical fairness constraint (say,\nequalizing false positive rates across protected groups), but then asks that\nthis constraint hold over an exponentially or infinitely large collection of\nsubgroups defined by a class of functions with bounded VC dimension. They give\nan algorithm guaranteed to learn subject to this constraint, under the\ncondition that it has access to oracles for perfectly learning absent a\nfairness constraint. In this paper, we undertake an extensive empirical\nevaluation of the algorithm of Kearns et al. On four real datasets for which\nfairness is a concern, we investigate the basic convergence of the algorithm\nwhen instantiated with fast heuristics in place of learning oracles, measure\nthe tradeoffs between fairness and accuracy, and compare this approach with the\nrecent algorithm of Agarwal et al. [2018], which implements weaker and more\ntraditional marginal fairness constraints defined by individual protected\nattributes. We find that in general, the Kearns et al. algorithm converges\nquickly, large gains in fairness can be obtained with mild costs to accuracy,\nand that optimizing accuracy subject only to marginal fairness leads to\nclassifiers with substantial subgroup unfairness. We also provide a number of\nanalyses and visualizations of the dynamics and behavior of the Kearns et al.\nalgorithm. Overall we find this algorithm to be effective on real data, and\nrich subgroup fairness to be a viable notion in practice. \n\n"}
{"id": "1808.08316", "contents": "Title: A Trio Neural Model for Dynamic Entity Relatedness Ranking Abstract: Measuring entity relatedness is a fundamental task for many natural language\nprocessing and information retrieval applications. Prior work often studies\nentity relatedness in static settings and an unsupervised manner. However,\nentities in real-world are often involved in many different relationships,\nconsequently entity-relations are very dynamic over time. In this work, we\npropose a neural networkbased approach for dynamic entity relatedness,\nleveraging the collective attention as supervision. Our model is capable of\nlearning rich and different entity representations in a joint framework.\nThrough extensive experiments on large-scale datasets, we demonstrate that our\nmethod achieves better results than competitive baselines. \n\n"}
{"id": "1808.08833", "contents": "Title: Gradient-based Training of Slow Feature Analysis by Differentiable\n  Approximate Whitening Abstract: We propose Power Slow Feature Analysis, a gradient-based method to extract\ntemporally slow features from a high-dimensional input stream that varies on a\nfaster time-scale, as a variant of Slow Feature Analysis (SFA) that allows\nend-to-end training of arbitrary differentiable architectures and thereby\nsignificantly extends the class of models that can effectively be used for slow\nfeature extraction. We provide experimental evidence that PowerSFA is able to\nextract meaningful and informative low-dimensional features in the case of (a)\nsynthetic low-dimensional data, (b) ego-visual data, and also for (c) a general\ndataset for which symmetric non-temporal similarities between points can be\ndefined. \n\n"}
{"id": "1808.09105", "contents": "Title: SOLAR: Deep Structured Representations for Model-Based Reinforcement\n  Learning Abstract: Model-based reinforcement learning (RL) has proven to be a data efficient\napproach for learning control tasks but is difficult to utilize in domains with\ncomplex observations such as images. In this paper, we present a method for\nlearning representations that are suitable for iterative model-based policy\nimprovement, even when the underlying dynamical system has complex dynamics and\nimage observations, in that these representations are optimized for inferring\nsimple dynamics and cost models given data from the current policy. This\nenables a model-based RL method based on the linear-quadratic regulator (LQR)\nto be used for systems with image observations. We evaluate our approach on a\nrange of robotics tasks, including manipulation with a real-world robotic arm\ndirectly from images. We find that our method produces substantially better\nfinal performance than other model-based RL methods while being significantly\nmore efficient than model-free RL. \n\n"}
{"id": "1808.10101", "contents": "Title: DP-ADMM: ADMM-based Distributed Learning with Differential Privacy Abstract: Alternating Direction Method of Multipliers (ADMM) is a widely used tool for\nmachine learning in distributed settings, where a machine learning model is\ntrained over distributed data sources through an interactive process of local\ncomputation and message passing. Such an iterative process could cause privacy\nconcerns of data owners. The goal of this paper is to provide differential\nprivacy for ADMM-based distributed machine learning. Prior approaches on\ndifferentially private ADMM exhibit low utility under high privacy guarantee\nand often assume the objective functions of the learning problems to be smooth\nand strongly convex. To address these concerns, we propose a novel\ndifferentially private ADMM-based distributed learning algorithm called\nDP-ADMM, which combines an approximate augmented Lagrangian function with\ntime-varying Gaussian noise addition in the iterative process to achieve higher\nutility for general objective functions under the same differential privacy\nguarantee. We also apply the moments accountant method to bound the end-to-end\nprivacy loss. The theoretical analysis shows that DP-ADMM can be applied to a\nwider class of distributed learning problems, is provably convergent, and\noffers an explicit utility-privacy tradeoff. To our knowledge, this is the\nfirst paper to provide explicit convergence and utility properties for\ndifferentially private ADMM-based distributed learning algorithms. The\nevaluation results demonstrate that our approach can achieve good convergence\nand model accuracy under high end-to-end differential privacy guarantee. \n\n"}
{"id": "1808.10350", "contents": "Title: IEA: Inner Ensemble Average within a convolutional neural network Abstract: Ensemble learning is a method of combining multiple trained models to improve\nmodel accuracy. We propose the usage of such methods, specifically ensemble\naverage, inside Convolutional Neural Network (CNN) architectures by replacing\nthe single convolutional layers with Inner Average Ensembles (IEA) of multiple\nconvolutional layers. Empirical results on different benchmarking datasets show\nthat CNN models using IEA outperform those with regular convolutional layers. A\nvisual and a similarity score analysis of the features generated from IEA\nexplains why it boosts the model performance. \n\n"}
{"id": "1809.00947", "contents": "Title: Finding Dory in the Crowd: Detecting Social Interactions using\n  Multi-Modal Mobile Sensing Abstract: Remembering our day-to-day social interactions is challenging even if you\naren't a blue memory challenged fish. The ability to automatically detect and\nremember these types of interactions is not only beneficial for individuals\ninterested in their behavior in crowded situations, but also of interest to\nthose who analyze crowd behavior. Currently, detecting social interactions is\noften performed using a variety of methods including ethnographic studies,\ncomputer vision techniques and manual annotation-based data analysis. However,\nmobile phones offer easier means for data collection that is easy to analyze\nand can preserve the user's privacy. In this work, we present a system for\ndetecting stationary social interactions inside crowds, leveraging multi-modal\nmobile sensing data such as Bluetooth Smart (BLE), accelerometer and gyroscope.\nTo inform the development of such system, we conducted a study with 24\nparticipants, where we asked them to socialize with each other for 45 minutes.\nWe built a machine learning system based on gradient-boosted trees that\npredicts both 1:1 and group interactions with 77.8% precision and 86.5% recall,\na 30.2% performance increase compared to a proximity-based approach. By\nutilizing a community detection-based method, we further detected the various\ngroup formation that exist within the crowd. Using mobile phone sensors already\ncarried by the majority of people in a crowd makes our approach particularly\nwell suited to real-life analysis of crowd behavior and influence strategies. \n\n"}
{"id": "1809.01130", "contents": "Title: Nash equilibrium in asymmetric multi-players zero-sum game with two\n  strategic variables and only one alien Abstract: We consider a partially asymmetric multi-players zero-sum game with two\nstrategic variables. All but one players have the same payoff functions, and\none player (Player $n$) does not. Two strategic variables are $t_i$'s and\n$s_i$'s for each player $i$. Mainly we will show the following results. 1) The\nequilibrium when all players choose $t_i$'s is equivalent to the equilibrium\nwhen all but one players choose $t_i$'s and Player $n$ chooses $s_n$ as their\nstrategic variables. 2) The equilibrium when all players choose $s_i$'s is\nequivalent to the equilibrium when all but one players choose $s_i$'s and\nPlayer $n$ chooses $t_n$ as their strategic variables. The equilibrium when all\nplayers choose $t_i$'s and the equilibrium when all players choose $s_i$'s are\nnot equivalent although they are equivalent in a symmetric game in which all\nplayers have the same payoff functions. \n\n"}
{"id": "1809.01496", "contents": "Title: Learning Gender-Neutral Word Embeddings Abstract: Word embedding models have become a fundamental component in a wide range of\nNatural Language Processing (NLP) applications. However, embeddings trained on\nhuman-generated corpora have been demonstrated to inherit strong gender\nstereotypes that reflect social constructs. To address this concern, in this\npaper, we propose a novel training procedure for learning gender-neutral word\nembeddings. Our approach aims to preserve gender information in certain\ndimensions of word vectors while compelling other dimensions to be free of\ngender influence. Based on the proposed method, we generate a Gender-Neutral\nvariant of GloVe (GN-GloVe). Quantitative and qualitative experiments\ndemonstrate that GN-GloVe successfully isolates gender information without\nsacrificing the functionality of the embedding model. \n\n"}
{"id": "1809.01534", "contents": "Title: Utilizing Character and Word Embeddings for Text Normalization with\n  Sequence-to-Sequence Models Abstract: Text normalization is an important enabling technology for several NLP tasks.\nRecently, neural-network-based approaches have outperformed well-established\nmodels in this task. However, in languages other than English, there has been\nlittle exploration in this direction. Both the scarcity of annotated data and\nthe complexity of the language increase the difficulty of the problem. To\naddress these challenges, we use a sequence-to-sequence model with\ncharacter-based attention, which in addition to its self-learned character\nembeddings, uses word embeddings pre-trained with an approach that also models\nsubword information. This provides the neural model with access to more\nlinguistic information especially suitable for text normalization, without\nlarge parallel corpora. We show that providing the model with word-level\nfeatures bridges the gap for the neural network approach to achieve a\nstate-of-the-art F1 score on a standard Arabic language correction shared task\ndataset. \n\n"}
{"id": "1809.01575", "contents": "Title: Bounded Rational Decision-Making with Adaptive Neural Network Priors Abstract: Bounded rationality investigates utility-optimizing decision-makers with\nlimited information-processing power. In particular, information theoretic\nbounded rationality models formalize resource constraints abstractly in terms\nof relative Shannon information, namely the Kullback-Leibler Divergence between\nthe agents' prior and posterior policy. Between prior and posterior lies an\nanytime deliberation process that can be instantiated by sample-based\nevaluations of the utility function through Markov Chain Monte Carlo (MCMC)\noptimization. The most simple model assumes a fixed prior and can relate\nabstract information-theoretic processing costs to the number of sample\nevaluations. However, more advanced models would also address the question of\nlearning, that is how the prior is adapted over time such that generated prior\nproposals become more efficient. In this work we investigate generative neural\nnetworks as priors that are optimized concurrently with anytime sample-based\ndecision-making processes such as MCMC. We evaluate this approach on toy\nexamples. \n\n"}
{"id": "1809.01712", "contents": "Title: Coverage-Based Designs Improve Sample Mining and Hyper-Parameter\n  Optimization Abstract: Sampling one or more effective solutions from large search spaces is a\nrecurring idea in machine learning, and sequential optimization has become a\npopular solution. Typical examples include data summarization, sample mining\nfor predictive modeling and hyper-parameter optimization. Existing solutions\nattempt to adaptively trade-off between global exploration and local\nexploitation, wherein the initial exploratory sample is critical to their\nsuccess. While discrepancy-based samples have become the de facto approach for\nexploration, results from computer graphics suggest that coverage-based\ndesigns, e.g. Poisson disk sampling, can be a superior alternative. In order to\nsuccessfully adopt coverage-based sample designs to ML applications, which were\noriginally developed for 2-d image analysis, we propose fundamental advances by\nconstructing a parameterized family of designs with provably improved coverage\ncharacteristics, and by developing algorithms for effective sample synthesis.\nUsing experiments in sample mining and hyper-parameter optimization for\nsupervised learning, we show that our approach consistently outperforms\nexisting exploratory sampling methods in both blind exploration, and sequential\nsearch with Bayesian optimization. \n\n"}
{"id": "1809.01728", "contents": "Title: Attention-based Audio-Visual Fusion for Robust Automatic Speech\n  Recognition Abstract: Automatic speech recognition can potentially benefit from the lip motion\npatterns, complementing acoustic speech to improve the overall recognition\nperformance, particularly in noise. In this paper we propose an audio-visual\nfusion strategy that goes beyond simple feature concatenation and learns to\nautomatically align the two modalities, leading to enhanced representations\nwhich increase the recognition accuracy in both clean and noisy conditions. We\ntest our strategy on the TCD-TIMIT and LRS2 datasets, designed for large\nvocabulary continuous speech recognition, applying three types of noise at\ndifferent power ratios. We also exploit state of the art Sequence-to-Sequence\narchitectures, showing that our method can be easily integrated. Results show\nrelative improvements from 7% up to 30% on TCD-TIMIT over the acoustic modality\nalone, depending on the acoustic noise level. We anticipate that the fusion\nstrategy can easily generalise to many other multimodal tasks which involve\ncorrelated modalities. Code available online on GitHub:\nhttps://github.com/georgesterpu/Sigmedia-AVSR \n\n"}
{"id": "1809.01765", "contents": "Title: Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method\n  for Stochastic Sparse Linear Regression with Limited Attribute Observation Abstract: We develop new stochastic gradient methods for efficiently solving sparse\nlinear regression in a partial attribute observation setting, where learners\nare only allowed to observe a fixed number of actively chosen attributes per\nexample at training and prediction times. It is shown that the methods achieve\nessentially a sample complexity of $O(1/\\varepsilon)$ to attain an error of\n$\\varepsilon$ under a variant of restricted eigenvalue condition, and the rate\nhas better dependency on the problem dimension than existing methods.\nParticularly, if the smallest magnitude of the non-zero components of the\noptimal solution is not too small, the rate of our proposed {\\it Hybrid}\nalgorithm can be boosted to near the minimax optimal sample complexity of {\\it\nfull information} algorithms. The core ideas are (i) efficient construction of\nan unbiased gradient estimator by the iterative usage of the hard thresholding\noperator for configuring an exploration algorithm; and (ii) an adaptive\ncombination of the exploration and an exploitation algorithms for quickly\nidentifying the support of the optimum and efficiently searching the optimal\nparameter in its support. Experimental results are presented to validate our\ntheoretical findings and the superiority of our proposed methods. \n\n"}
{"id": "1809.02341", "contents": "Title: A Fast Anderson-Chebyshev Acceleration for Nonlinear Optimization Abstract: Anderson acceleration (or Anderson mixing) is an efficient acceleration\nmethod for fixed point iterations $x_{t+1}=G(x_t)$, e.g., gradient descent can\nbe viewed as iteratively applying the operation $G(x) \\triangleq x-\\alpha\\nabla\nf(x)$. It is known that Anderson acceleration is quite efficient in practice\nand can be viewed as an extension of Krylov subspace methods for nonlinear\nproblems. In this paper, we show that Anderson acceleration with Chebyshev\npolynomial can achieve the optimal convergence rate\n$O(\\sqrt{\\kappa}\\ln\\frac{1}{\\epsilon})$, which improves the previous result\n$O(\\kappa\\ln\\frac{1}{\\epsilon})$ provided by (Toth and Kelley, 2015) for\nquadratic functions. Moreover, we provide a convergence analysis for minimizing\ngeneral nonlinear problems. Besides, if the hyperparameters (e.g., the\nLipschitz smooth parameter $L$) are not available, we propose a guessing\nalgorithm for guessing them dynamically and also prove a similar convergence\nrate. Finally, the experimental results demonstrate that the proposed\nAnderson-Chebyshev acceleration method converges significantly faster than\nother algorithms, e.g., vanilla gradient descent (GD), Nesterov's Accelerated\nGD. Also, these algorithms combined with the proposed guessing algorithm\n(guessing the hyperparameters dynamically) achieve much better performance. \n\n"}
{"id": "1809.02505", "contents": "Title: Stochastically Controlled Stochastic Gradient for the Convex and\n  Non-convex Composition problem Abstract: In this paper, we consider the convex and non-convex composition problem with\nthe structure $\\frac{1}{n}\\sum\\nolimits_{i = 1}^n {{F_i}( {G( x )} )}$, where\n$G( x )=\\frac{1}{n}\\sum\\nolimits_{j = 1}^n {{G_j}( x )} $ is the inner\nfunction, and $F_i(\\cdot)$ is the outer function. We explore the variance\nreduction based method to solve the composition optimization. Due to the fact\nthat when the number of inner function and outer function are large, it is not\nreasonable to estimate them directly, thus we apply the stochastically\ncontrolled stochastic gradient (SCSG) method to estimate the gradient of the\ncomposition function and the value of the inner function. The query complexity\nof our proposed method for the convex and non-convex problem is equal to or\nbetter than the current method for the composition problem. Furthermore, we\nalso present the mini-batch version of the proposed method, which has the\nimproved the query complexity with related to the size of the mini-batch. \n\n"}
{"id": "1809.02589", "contents": "Title: HyperGCN: A New Method of Training Graph Convolutional Networks on\n  Hypergraphs Abstract: In many real-world network datasets such as co-authorship, co-citation, email\ncommunication, etc., relationships are complex and go beyond pairwise.\nHypergraphs provide a flexible and natural modeling tool to model such complex\nrelationships. The obvious existence of such complex relationships in many\nreal-world networks naturaly motivates the problem of learning with\nhypergraphs. A popular learning paradigm is hypergraph-based semi-supervised\nlearning (SSL) where the goal is to assign labels to initially unlabeled\nvertices in a hypergraph. Motivated by the fact that a graph convolutional\nnetwork (GCN) has been effective for graph-based SSL, we propose HyperGCN, a\nnovel GCN for SSL on attributed hypergraphs. Additionally, we show how HyperGCN\ncan be used as a learning-based approach for combinatorial optimisation on\nNP-hard hypergraph problems. We demonstrate HyperGCN's effectiveness through\ndetailed experimentation on real-world hypergraphs. \n\n"}
{"id": "1809.02740", "contents": "Title: Ensembles of Nested Dichotomies with Multiple Subset Evaluation Abstract: A system of nested dichotomies is a method of decomposing a multi-class\nproblem into a collection of binary problems. Such a system recursively applies\nbinary splits to divide the set of classes into two subsets, and trains a\nbinary classifier for each split. Many methods have been proposed to perform\nthis split, each with various advantages and disadvantages. In this paper, we\npresent a simple, general method for improving the predictive performance of\nnested dichotomies produced by any subset selection techniques that employ\nrandomness to construct the subsets. We provide a theoretical expectation for\nperformance improvements, as well as empirical results showing that our method\nimproves the root mean squared error of nested dichotomies, regardless of\nwhether they are employed as an individual model or in an ensemble setting. \n\n"}
{"id": "1809.03054", "contents": "Title: SEGA: Variance Reduction via Gradient Sketching Abstract: We propose a randomized first order optimization method--SEGA (SkEtched\nGrAdient method)-- which progressively throughout its iterations builds a\nvariance-reduced estimate of the gradient from random linear measurements\n(sketches) of the gradient obtained from an oracle. In each iteration, SEGA\nupdates the current estimate of the gradient through a sketch-and-project\noperation using the information provided by the latest sketch, and this is\nsubsequently used to compute an unbiased estimate of the true gradient through\na random relaxation procedure. This unbiased estimate is then used to perform a\ngradient step. Unlike standard subspace descent methods, such as coordinate\ndescent, SEGA can be used for optimization problems with a non-separable\nproximal term. We provide a general convergence analysis and prove linear\nconvergence for strongly convex objectives. In the special case of coordinate\nsketches, SEGA can be enhanced with various techniques such as importance\nsampling, minibatching and acceleration, and its rate is up to a small constant\nfactor identical to the best-known rate of coordinate descent. \n\n"}
{"id": "1809.03093", "contents": "Title: Parameterized Games and Parameterized Automata Abstract: We introduce a way to parameterize automata and games on finite graphs with\nnatural numbers. The parameters are accessed essentially by allowing counting\ndown from the parameter value to 0 and branching depending on whether 0 has\nbeen reached. The main technical result is that in games, a player can win for\nsome values of the parameters at all, if she can win for some values below an\nexponential bound. For many winning conditions, this implies decidability of\nany statements about a player being able to win with arbitrary quantification\nover the parameter values.\n  While the result seems broadly applicable, a specific motivation comes from\nthe study of chains of strategies in games. Chains of games were recently\nsuggested as a means to define a rationality notion based on dominance that\nworks well with quantitative games by Bassett, Jecker, P., Raskin and Van den\nBoogard. From the main result of this paper, we obtain generalizations of their\ndecidability results with much simpler proofs.\n  As both a core technical notion in the proof of the main result, and as a\nnotion of potential independent interest, we look at boolean functions defined\nvia graph game forms. Graph game forms have properties akin to monotone\ncircuits, albeit are more concise. We raise some open questions regarding how\nconcise they are exactly, which have a flavour similar to circuit complexity.\nAnswers to these questions could improve the bounds in the main theorem. \n\n"}
{"id": "1809.03152", "contents": "Title: A Multi-Agent Reinforcement Learning Method for Impression Allocation in\n  Online Display Advertising Abstract: In online display advertising, guaranteed contracts and real-time bidding\n(RTB) are two major ways to sell impressions for a publisher. Despite the\nincreasing popularity of RTB, there is still half of online display advertising\nrevenue generated from guaranteed contracts. Therefore, simultaneously selling\nimpressions through both guaranteed contracts and RTB is a straightforward\nchoice for a publisher to maximize its yield. However, deriving the optimal\nstrategy to allocate impressions is not a trivial task, especially when the\nenvironment is unstable in real-world applications. In this paper, we formulate\nthe impression allocation problem as an auction problem where each contract can\nsubmit virtual bids for individual impressions. With this formulation, we\nderive the optimal impression allocation strategy by solving the optimal\nbidding functions for contracts. Since the bids from contracts are decided by\nthe publisher, we propose a multi-agent reinforcement learning (MARL) approach\nto derive cooperative policies for the publisher to maximize its yield in an\nunstable environment. The proposed approach also resolves the common challenges\nin MARL such as input dimension explosion, reward credit assignment, and\nnon-stationary environment. Experimental evaluations on large-scale real\ndatasets demonstrate the effectiveness of our approach. \n\n"}
{"id": "1809.03474", "contents": "Title: Universal Multi-Party Poisoning Attacks Abstract: In this work, we demonstrate universal multi-party poisoning attacks that\nadapt and apply to any multi-party learning process with arbitrary interaction\npattern between the parties. More generally, we introduce and study\n$(k,p)$-poisoning attacks in which an adversary controls $k\\in[m]$ of the\nparties, and for each corrupted party $P_i$, the adversary submits some\npoisoned data $\\mathcal{T}'_i$ on behalf of $P_i$ that is still\n``$(1-p)$-close'' to the correct data $\\mathcal{T}_i$ (e.g., $1-p$ fraction of\n$\\mathcal{T}'_i$ is still honestly generated). We prove that for any ``bad''\nproperty $B$ of the final trained hypothesis $h$ (e.g., $h$ failing on a\nparticular test example or having ``large'' risk) that has an arbitrarily small\nconstant probability of happening without the attack, there always is a\n$(k,p)$-poisoning attack that increases the probability of $B$ from $\\mu$ to by\n$\\mu^{1-p \\cdot k/m} = \\mu + \\Omega(p \\cdot k/m)$. Our attack only uses clean\nlabels, and it is online.\n  More generally, we prove that for any bounded function $f(x_1,\\dots,x_n) \\in\n[0,1]$ defined over an $n$-step random process $\\mathbf{X} = (x_1,\\dots,x_n)$,\nan adversary who can override each of the $n$ blocks with even dependent\nprobability $p$ can increase the expected output by at least $\\Omega(p \\cdot\n\\mathrm{Var}[f(\\mathbf{x})])$. \n\n"}
{"id": "1809.04632", "contents": "Title: Efficient Global Optimization using Deep Gaussian Processes Abstract: Efficient Global Optimization (EGO) is widely used for the optimization of\ncomputationally expensive black-box functions. It uses a surrogate modeling\ntechnique based on Gaussian Processes (Kriging). However, due to the use of a\nstationary covariance, Kriging is not well suited for approximating non\nstationary functions. This paper explores the integration of Deep Gaussian\nprocesses (DGP) in EGO framework to deal with the non-stationary issues and\ninvestigates the induced challenges and opportunities. Numerical\nexperimentations are performed on analytical problems to highlight the\ndifferent aspects of DGP and EGO. \n\n"}
{"id": "1809.05042", "contents": "Title: Hamiltonian Descent Methods Abstract: We propose a family of optimization methods that achieve linear convergence\nusing first-order gradient information and constant step sizes on a class of\nconvex functions much larger than the smooth and strongly convex ones. This\nlarger class includes functions whose second derivatives may be singular or\nunbounded at their minima. Our methods are discretizations of conformal\nHamiltonian dynamics, which generalize the classical momentum method to model\nthe motion of a particle with non-standard kinetic energy exposed to a\ndissipative force and the gradient field of the function of interest. They are\nfirst-order in the sense that they require only gradient computation. Yet,\ncrucially the kinetic gradient map can be designed to incorporate information\nabout the convex conjugate in a fashion that allows for linear convergence on\nconvex functions that may be non-smooth or non-strongly convex. We study in\ndetail one implicit and two explicit methods. For one explicit method, we\nprovide conditions under which it converges to stationary points of non-convex\nfunctions. For all, we provide conditions on the convex function and kinetic\nenergy pair that guarantee linear convergence, and show that these conditions\ncan be satisfied by functions with power growth. In sum, these methods expand\nthe class of convex functions on which linear convergence is possible with\nfirst-order computation. \n\n"}
{"id": "1809.05188", "contents": "Title: CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement\n  Learning Abstract: A variety of cooperative multi-agent control problems require agents to\nachieve individual goals while contributing to collective success. This\nmulti-goal multi-agent setting poses difficulties for recent algorithms, which\nprimarily target settings with a single global reward, due to two new\nchallenges: efficient exploration for learning both individual goal attainment\nand cooperation for others' success, and credit-assignment for interactions\nbetween actions and goals of different agents. To address both challenges, we\nrestructure the problem into a novel two-stage curriculum, in which\nsingle-agent goal attainment is learned prior to learning multi-agent\ncooperation, and we derive a new multi-goal multi-agent policy gradient with a\ncredit function for localized credit assignment. We use a function augmentation\nscheme to bridge value and policy functions across the curriculum. The complete\narchitecture, called CM3, learns significantly faster than direct adaptations\nof existing algorithms on three challenging multi-goal multi-agent problems:\ncooperative navigation in difficult formations, negotiating multi-vehicle lane\nchanges in the SUMO traffic simulator, and strategic cooperation in a Checkers\nenvironment. \n\n"}
{"id": "1809.05527", "contents": "Title: Gradient descent in higher codimension Abstract: We consider the behavior of gradient flow and of discrete and noisy gradient\ndescent. It is commonly noted that the addition of noise to the process of\ndiscrete gradient descent can affect the trajectory of gradient descent. In\nprevious work, we observed such effects. There, we considered the case where\nthe minima had codimension 1. In this note, we do some computer experiments and\nobserve the behavior of noisy gradient descent in the more complex setting of\nminima of higher codimension. \n\n"}
{"id": "1809.05650", "contents": "Title: Detecting and Explaining Drifts in Yearly Grant Applications Abstract: During the lifetime of a Business Process changes can be made to the\nworkflow, the required resources, required documents, . . . . Different traces\nfrom the same Business Process within a single log file can thus differ\nsubstantially due to these changes. We propose a method that is able to detect\nconcept drift in multivariate log files with a dozen attributes. We test our\napproach on the BPI Challenge 2018 data con- sisting of applications for EU\ndirect payment from farmers in Germany where we use it to detect Concept Drift.\nIn contrast to other methods our algorithm does not require the manual\nselection of the features used to detect drift. Our method first creates a\nmodel that captures the re- lations between attributes and between events of\ndifferent time steps. This model is then used to score every event and trace.\nThese scores can be used to detect outlying cases and concept drift. Thanks to\nthe decomposability of the score we are able to perform detailed root-cause\nanalysis. \n\n"}
{"id": "1809.05786", "contents": "Title: GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation\n  with Generative Adversarial Networks Abstract: In the last decade, supervised deep learning approaches have been extensively\nemployed in visual odometry (VO) applications, which is not feasible in\nenvironments where labelled data is not abundant. On the other hand,\nunsupervised deep learning approaches for localization and mapping in unknown\nenvironments from unlabelled data have received comparatively less attention in\nVO research. In this study, we propose a generative unsupervised learning\nframework that predicts 6-DoF pose camera motion and monocular depth map of the\nscene from unlabelled RGB image sequences, using deep convolutional Generative\nAdversarial Networks (GANs). We create a supervisory signal by warping view\nsequences and assigning the re-projection minimization to the objective loss\nfunction that is adopted in multi-view pose estimation and single-view depth\ngeneration network. Detailed quantitative and qualitative evaluations of the\nproposed framework on the KITTI and Cityscapes datasets show that the proposed\nmethod outperforms both existing traditional and unsupervised deep VO methods\nproviding better results for both pose estimation and depth recovery. \n\n"}
{"id": "1809.06213", "contents": "Title: Context-Dependent Diffusion Network for Visual Relationship Detection Abstract: Visual relationship detection can bridge the gap between computer vision and\nnatural language for scene understanding of images. Different from pure object\nrecognition tasks, the relation triplets of subject-predicate-object lie on an\nextreme diversity space, such as \\textit{person-behind-person} and\n\\textit{car-behind-building}, while suffering from the problem of combinatorial\nexplosion. In this paper, we propose a context-dependent diffusion network\n(CDDN) framework to deal with visual relationship detection. To capture the\ninteractions of different object instances, two types of graphs, word semantic\ngraph and visual scene graph, are constructed to encode global context\ninterdependency. The semantic graph is built through language priors to model\nsemantic correlations across objects, whilst the visual scene graph defines the\nconnections of scene objects so as to utilize the surrounding scene\ninformation. For the graph-structured data, we design a diffusion network to\nadaptively aggregate information from contexts, which can effectively learn\nlatent representations of visual relationships and well cater to visual\nrelationship detection in view of its isomorphic invariance to graphs.\nExperiments on two widely-used datasets demonstrate that our proposed method is\nmore effective and achieves the state-of-the-art performance. \n\n"}
{"id": "1809.06432", "contents": "Title: Node Classification for Signed Social Networks Using Diffuse Interface\n  Methods Abstract: Signed networks contain both positive and negative kinds of interactions like\nfriendship and enmity. The task of node classification in non-signed graphs has\nproven to be beneficial in many real world applications, yet extensions to\nsigned networks remain largely unexplored. In this paper we introduce the first\nanalysis of node classification in signed social networks via diffuse interface\nmethods based on the Ginzburg-Landau functional together with different\nextensions of the graph Laplacian to signed networks. We show that blending the\ninformation from both positive and negative interactions leads to performance\nimprovement in real signed social networks, consistently outperforming the\ncurrent state of the art. \n\n"}
{"id": "1809.06477", "contents": "Title: Active Anomaly Detection via Ensembles Abstract: In critical applications of anomaly detection including computer security and\nfraud prevention, the anomaly detector must be configurable by the analyst to\nminimize the effort on false positives. One important way to configure the\nanomaly detector is by providing true labels for a few instances. We study the\nproblem of label-efficient active learning to automatically tune anomaly\ndetection ensembles and make four main contributions. First, we present an\nimportant insight into how anomaly detector ensembles are naturally suited for\nactive learning. This insight allows us to relate the greedy querying strategy\nto uncertainty sampling, with implications for label-efficiency. Second, we\npresent a novel formalism called compact description to describe the discovered\nanomalies and show that it can also be employed to improve the diversity of the\ninstances presented to the analyst without loss in the anomaly discovery rate.\nThird, we present a novel data drift detection algorithm that not only detects\nthe drift robustly, but also allows us to take corrective actions to adapt the\ndetector in a principled manner. Fourth, we present extensive experiments to\nevaluate our insights and algorithms in both batch and streaming settings. Our\nresults show that in addition to discovering significantly more anomalies than\nstate-of-the-art unsupervised baselines, our active learning algorithms under\nthe streaming-data setup are competitive with the batch setup. \n\n"}
{"id": "1809.07122", "contents": "Title: Capacity Control of ReLU Neural Networks by Basis-path Norm Abstract: Recently, path norm was proposed as a new capacity measure for neural\nnetworks with Rectified Linear Unit (ReLU) activation function, which takes the\nrescaling-invariant property of ReLU into account. It has been shown that the\ngeneralization error bound in terms of the path norm explains the empirical\ngeneralization behaviors of the ReLU neural networks better than that of other\ncapacity measures. Moreover, optimization algorithms which take path norm as\nthe regularization term to the loss function, like Path-SGD, have been shown to\nachieve better generalization performance. However, the path norm counts the\nvalues of all paths, and hence the capacity measure based on path norm could be\nimproperly influenced by the dependency among different paths. It is also known\nthat each path of a ReLU network can be represented by a small group of\nlinearly independent basis paths with multiplication and division operation,\nwhich indicates that the generalization behavior of the network only depends on\nonly a few basis paths. Motivated by this, we propose a new norm\n\\emph{Basis-path Norm} based on a group of linearly independent paths to\nmeasure the capacity of neural networks more accurately. We establish a\ngeneralization error bound based on this basis path norm, and show it explains\nthe generalization behaviors of ReLU networks more accurately than previous\ncapacity measures via extensive experiments. In addition, we develop\noptimization algorithms which minimize the empirical risk regularized by the\nbasis-path norm. Our experiments on benchmark datasets demonstrate that the\nproposed regularization method achieves clearly better performance on the test\nset than the previous regularization approaches. \n\n"}
{"id": "1809.07180", "contents": "Title: Projective Splitting with Forward Steps only Requires Continuity Abstract: A recent innovation in projective splitting algorithms for monotone operator\ninclusions has been the development of a procedure using two forward steps\ninstead of the customary proximal steps for operators that are Lipschitz\ncontinuous. This paper shows that the Lipschitz assumption is unnecessary when\nthe forward steps are performed in finite-dimensional spaces: a backtracking\nlinesearch yields a convergent algorithm for operators that are merely\ncontinuous with full domain. \n\n"}
{"id": "1809.07703", "contents": "Title: Fighting Redundancy and Model Decay with Embeddings Abstract: Every day, hundreds of millions of new Tweets containing over 40 languages of\never-shifting vernacular flow through Twitter. Models that attempt to extract\ninsight from this firehose of information must face the torrential covariate\nshift that is endemic to the Twitter platform. While regularly-retrained\nalgorithms can maintain performance in the face of this shift, fixed model\nfeatures that fail to represent new trends and tokens can quickly become stale,\nresulting in performance degradation. To mitigate this problem we employ\nlearned features, or embedding models, that can efficiently represent the most\nrelevant aspects of a data distribution. Sharing these embedding models across\nteams can also reduce redundancy and multiplicatively increase cross-team\nmodeling productivity. In this paper, we detail the commoditized tools,\nalgorithms and pipelines that we have developed and are developing at Twitter\nto regularly generate high quality, up-to-date embeddings and share them\nbroadly across the company. \n\n"}
{"id": "1809.07802", "contents": "Title: Playing the Game of Universal Adversarial Perturbations Abstract: We study the problem of learning classifiers robust to universal adversarial\nperturbations. While prior work approaches this problem via robust\noptimization, adversarial training, or input transformation, we instead phrase\nit as a two-player zero-sum game. In this new formulation, both players\nsimultaneously play the same game, where one player chooses a classifier that\nminimizes a classification loss whilst the other player creates an adversarial\nperturbation that increases the same loss when applied to every sample in the\ntraining set. By observing that performing a classification (respectively\ncreating adversarial samples) is the best response to the other player, we\npropose a novel extension of a game-theoretic algorithm, namely fictitious\nplay, to the domain of training robust classifiers. Finally, we empirically\nshow the robustness and versatility of our approach in two defence scenarios\nwhere universal attacks are performed on several image classification datasets\n-- CIFAR10, CIFAR100 and ImageNet. \n\n"}
{"id": "1809.07857", "contents": "Title: In-Edge AI: Intelligentizing Mobile Edge Computing, Caching and\n  Communication by Federated Learning Abstract: Recently, along with the rapid development of mobile communication\ntechnology, edge computing theory and techniques have been attracting more and\nmore attentions from global researchers and engineers, which can significantly\nbridge the capacity of cloud and requirement of devices by the network edges,\nand thus can accelerate the content deliveries and improve the quality of\nmobile services. In order to bring more intelligence to the edge systems,\ncompared to traditional optimization methodology, and driven by the current\ndeep learning techniques, we propose to integrate the Deep Reinforcement\nLearning techniques and Federated Learning framework with the mobile edge\nsystems, for optimizing the mobile edge computing, caching and communication.\nAnd thus, we design the \"In-Edge AI\" framework in order to intelligently\nutilize the collaboration among devices and edge nodes to exchange the learning\nparameters for a better training and inference of the models, and thus to carry\nout dynamic system-level optimization and application-level enhancement while\nreducing the unnecessary system communication load. \"In-Edge AI\" is evaluated\nand proved to have near-optimal performance but relatively low overhead of\nlearning, while the system is cognitive and adaptive to the mobile\ncommunication systems. Finally, we discuss several related challenges and\nopportunities for unveiling a promising upcoming future of \"In-Edge AI\". \n\n"}
{"id": "1809.07945", "contents": "Title: SCC: Automatic Classification of Code Snippets Abstract: Determining the programming language of a source code file has been\nconsidered in the research community; it has been shown that Machine Learning\n(ML) and Natural Language Processing (NLP) algorithms can be effective in\nidentifying the programming language of source code files. However, determining\nthe programming language of a code snippet or a few lines of source code is\nstill a challenging task. Online forums such as Stack Overflow and code\nrepositories such as GitHub contain a large number of code snippets. In this\npaper, we describe Source Code Classification (SCC), a classifier that can\nidentify the programming language of code snippets written in 21 different\nprogramming languages. A Multinomial Naive Bayes (MNB) classifier is employed\nwhich is trained using Stack Overflow posts. It is shown to achieve an accuracy\nof 75% which is higher than that with Programming Languages Identification (PLI\na proprietary online classifier of snippets) whose accuracy is only 55.5%. The\naverage score for precision, recall and the F1 score with the proposed tool are\n0.76, 0.75 and 0.75, respectively. In addition, it can distinguish between code\nsnippets from a family of programming languages such as C, C++ and C#, and can\nalso identify the programming language version such as C# 3.0, C# 4.0 and C#\n5.0. \n\n"}
{"id": "1809.08530", "contents": "Title: Provably Correct Automatic Subdifferentiation for Qualified Programs Abstract: The Cheap Gradient Principle (Griewank 2008) --- the computational cost of\ncomputing the gradient of a scalar-valued function is nearly the same (often\nwithin a factor of $5$) as that of simply computing the function itself --- is\nof central importance in optimization; it allows us to quickly obtain (high\ndimensional) gradients of scalar loss functions which are subsequently used in\nblack box gradient-based optimization procedures. The current state of affairs\nis markedly different with regards to computing subderivatives: widely used ML\nlibraries, including TensorFlow and PyTorch, do not correctly compute\n(generalized) subderivatives even on simple examples. This work considers the\nquestion: is there a Cheap Subgradient Principle? Our main result shows that,\nunder certain restrictions on our library of nonsmooth functions (standard in\nnonlinear programming), provably correct generalized subderivatives can be\ncomputed at a computational cost that is within a (dimension-free) factor of\n$6$ of the cost of computing the scalar function itself. \n\n"}
{"id": "1809.08700", "contents": "Title: Envy-Free Classification Abstract: In classic fair division problems such as cake cutting and rent division,\nenvy-freeness requires that each individual (weakly) prefer his allocation to\nanyone else's. On a conceptual level, we argue that envy-freeness also provides\na compelling notion of fairness for classification tasks. Our technical focus\nis the generalizability of envy-free classification, i.e., understanding\nwhether a classifier that is envy free on a sample would be almost envy free\nwith respect to the underlying distribution with high probability. Our main\nresult establishes that a small sample is sufficient to achieve such\nguarantees, when the classifier in question is a mixture of deterministic\nclassifiers that belong to a family of low Natarajan dimension. \n\n"}
{"id": "1809.08771", "contents": "Title: Modeling longitudinal data using matrix completion Abstract: In clinical practice and biomedical research, measurements are often\ncollected sparsely and irregularly in time while the data acquisition is\nexpensive and inconvenient. Examples include measurements of spine bone mineral\ndensity, cancer growth through mammography or biopsy, a progression of\ndefective vision, or assessment of gait in patients with neurological\ndisorders. Since the data collection is often costly and inconvenient,\nestimation of progression from sparse observations is of great interest for\npractitioners.\n  From the statistical standpoint, such data is often analyzed in the context\nof a mixed-effect model where time is treated as both a fixed-effect\n(population progression curve) and a random-effect (individual variability).\nAlternatively, researchers analyze Gaussian processes or functional data where\nobservations are assumed to be drawn from a certain distribution of processes.\nThese models are flexible but rely on probabilistic assumptions, require very\ncareful implementation, specific to the given problem, and tend to be slow in\npractice.\n  In this study, we propose an alternative elementary framework for analyzing\nlongitudinal data, relying on matrix completion. Our method yields estimates of\nprogression curves by iterative application of the Singular Value\nDecomposition. Our framework covers multivariate longitudinal data, regression,\nand can be easily extended to other settings. As it relies on existing tools\nfor matrix algebra it is efficient and easy to implement.\n  We apply our methods to understand trends of progression of motor impairment\nin children with Cerebral Palsy. Our model approximates individual progression\ncurves and explains 30% of the variability. Low-rank representation of\nprogression trends enables identification of different progression trends in\nsubtypes of Cerebral Palsy. \n\n"}
{"id": "1809.08830", "contents": "Title: Wasserstein Distributionally Robust Kalman Filtering Abstract: We study a distributionally robust mean square error estimation problem over\na nonconvex Wasserstein ambiguity set containing only normal distributions. We\nshow that the optimal estimator and the least favorable distribution form a\nNash equilibrium. Despite the non-convex nature of the ambiguity set, we prove\nthat the estimation problem is equivalent to a tractable convex program. We\nfurther devise a Frank-Wolfe algorithm for this convex program whose\ndirection-searching subproblem can be solved in a quasi-closed form. Using\nthese ingredients, we introduce a distributionally robust Kalman filter that\nhedges against model risk. \n\n"}
{"id": "1809.09244", "contents": "Title: No Multiplication? No Floating Point? No Problem! Training Networks for\n  Efficient Inference Abstract: For successful deployment of deep neural networks on\nhighly--resource-constrained devices (hearing aids, earbuds, wearables), we\nmust simplify the types of operations and the memory/power resources used\nduring inference. Completely avoiding inference-time floating-point operations\nis one of the simplest ways to design networks for these highly-constrained\nenvironments. By discretizing both our in-network non-linearities and our\nnetwork weights, we can move to simple, compact networks without floating point\noperations, without multiplications, and avoid all non-linear function\ncomputations. Our approach allows us to explore the spectrum of possible\nnetworks, ranging from fully continuous versions down to networks with bi-level\nweights and activations. Our results show that discretization can be done\nwithout loss of performance and that we can train a network that will\nsuccessfully operate without floating-point, without multiplication, and with\nless RAM on both regression tasks (auto encoding) and multi-class\nclassification tasks (ImageNet). The memory needed to deploy our discretized\nnetworks is less than one third of the equivalent architecture that does use\nfloating-point operations. \n\n"}
{"id": "1809.09258", "contents": "Title: Asynchronous decentralized accelerated stochastic gradient descent Abstract: In this work, we introduce an asynchronous decentralized accelerated\nstochastic gradient descent type of method for decentralized stochastic\noptimization, considering communication and synchronization are the major\nbottlenecks. We establish $\\mathcal{O}(1/\\epsilon)$ (resp.,\n$\\mathcal{O}(1/\\sqrt{\\epsilon})$) communication complexity and\n$\\mathcal{O}(1/\\epsilon^2)$ (resp., $\\mathcal{O}(1/\\epsilon)$) sampling\ncomplexity for solving general convex (resp., strongly convex) problems. \n\n"}
{"id": "1809.09853", "contents": "Title: Stochastic Second-order Methods for Non-convex Optimization with Inexact\n  Hessian and Gradient Abstract: Trust region and cubic regularization methods have demonstrated good\nperformance in small scale non-convex optimization, showing the ability to\nescape from saddle points. Each iteration of these methods involves computation\nof gradient, Hessian and function value in order to obtain the search direction\nand adjust the radius or cubic regularization parameter. However, exactly\ncomputing those quantities are too expensive in large-scale problems such as\ntraining deep networks. In this paper, we study a family of stochastic trust\nregion and cubic regularization methods when gradient, Hessian and function\nvalues are computed inexactly, and show the iteration complexity to achieve\n$\\epsilon$-approximate second-order optimality is in the same order with\nprevious work for which gradient and function values are computed exactly. The\nmild conditions on inexactness can be achieved in finite-sum minimization using\nrandom sampling. We show the algorithm performs well on training convolutional\nneural networks compared with previous second-order methods. \n\n"}
{"id": "1809.10121", "contents": "Title: Safely Learning to Control the Constrained Linear Quadratic Regulator Abstract: We study the constrained linear quadratic regulator with unknown dynamics,\naddressing the tension between safety and exploration in data-driven control\ntechniques. We present a framework which allows for system identification\nthrough persistent excitation, while maintaining safety by guaranteeing the\nsatisfaction of state and input constraints. This framework involves a novel\nmethod for synthesizing robust constraint-satisfying feedback controllers,\nleveraging newly developed tools from system level synthesis. We connect\nstatistical results with cost sub-optimality bounds to give non-asymptotic\nguarantees on both estimation and controller performance. \n\n"}
{"id": "1809.10680", "contents": "Title: Supervised Nonnegative Matrix Factorization to Predict ICU Mortality\n  Risk Abstract: ICU mortality risk prediction is a tough yet important task. On one hand, due\nto the complex temporal data collected, it is difficult to identify the\neffective features and interpret them easily; on the other hand, good\nprediction can help clinicians take timely actions to prevent the mortality.\nThese correspond to the interpretability and accuracy problems. Most existing\nmethods lack of the interpretability, but recently Subgraph Augmented\nNonnegative Matrix Factorization (SANMF) has been successfully applied to time\nseries data to provide a path to interpret the features well. Therefore, we\nadopted this approach as the backbone to analyze the patient data. One\nlimitation of the raw SANMF method is its poor prediction ability due to its\nunsupervised nature. To deal with this problem, we proposed a supervised SANMF\nalgorithm by integrating the logistic regression loss function into the NMF\nframework and solved it with an alternating optimization procedure. We used the\nsimulation data to verify the effectiveness of this method, and then we applied\nit to ICU mortality risk prediction and demonstrated its superiority over other\nconventional supervised NMF methods. \n\n"}
{"id": "1809.10855", "contents": "Title: Minimax Lower Bounds for $\\mathcal{H}_\\infty$-Norm Estimation Abstract: The problem of estimating the $\\mathcal{H}_\\infty$-norm of an LTI system from\nnoisy input/output measurements has attracted recent attention as an\nalternative to parameter identification for bounding unmodeled dynamics in\nrobust control. In this paper, we study lower bounds for\n$\\mathcal{H}_\\infty$-norm estimation under a query model where at each\niteration the algorithm chooses a bounded input signal and receives the\nresponse of the chosen signal corrupted by white noise. We prove that when the\nunderlying system is an FIR filter, $\\mathcal{H}_\\infty$-norm estimation is no\nmore efficient than model identification for passive sampling. For active\nsampling, we show that norm estimation is at most a factor of $\\log{r}$ more\nsample efficient than model identification, where $r$ is the length of the\nfilter. We complement our theoretical results with experiments which\ndemonstrate that a simple non-adaptive estimator of the norm is competitive\nwith state-of-the-art adaptive norm estimation algorithms. \n\n"}
{"id": "1809.10858", "contents": "Title: Efficiently testing local optimality and escaping saddles for ReLU\n  networks Abstract: We provide a theoretical algorithm for checking local optimality and escaping\nsaddles at nondifferentiable points of empirical risks of two-layer ReLU\nnetworks. Our algorithm receives any parameter value and returns: local\nminimum, second-order stationary point, or a strict descent direction. The\npresence of $M$ data points on the nondifferentiability of the ReLU divides the\nparameter space into at most $2^M$ regions, which makes analysis difficult. By\nexploiting polyhedral geometry, we reduce the total computation down to one\nconvex quadratic program (QP) for each hidden node, $O(M)$ (in)equality tests,\nand one (or a few) nonconvex QP. For the last QP, we show that our specific\nproblem can be solved efficiently, in spite of nonconvexity. In the benign\ncase, we solve one equality constrained QP, and we prove that projected\ngradient descent solves it exponentially fast. In the bad case, we have to\nsolve a few more inequality constrained QPs, but we prove that the time\ncomplexity is exponential only in the number of inequality constraints. Our\nexperiments show that either benign case or bad case with very few inequality\nconstraints occurs, implying that our algorithm is efficient in most cases. \n\n"}
{"id": "1809.11034", "contents": "Title: Peer-to-Peer Energy Trading with Sustainable User Participation: A Game\n  Theoretic Approach Abstract: This paper explores the feasibility of social cooperation between prosumers\nwithin an energy network in establishing their sustainable participation in\npeer-to-peer (P2P) energy trading. In particular, a canonical coalition game\n(CCG) is utilized to propose a P2P energy trading scheme, in which a set of\nparticipating prosumers form a coalition group to trade their energy, if there\nis any, with one another. By exploring the concept of the core of the designed\nCCG framework, the mid-market rate is utilized as a pricing mechanism of the\nproposed P2P trading to confirm the stability of the coalition as well as to\nguarantee the benefit to the prosumers for forming the social coalition. The\npaper further introduces the motivational psychology models that are relevant\nto the proposed P2P scheme and it is shown that the outcomes of proposed P2P\nenergy trading scheme satisfy the discussed models. Consequently, it is proven\nthat the proposed scheme is consumer-centric that has the potential to\ncorroborate sustainable prosumers participation in P2P energy trading. Finally,\nsome numerical examples are provided to demonstrate the beneficial properties\nof the proposed scheme. \n\n"}
{"id": "1810.00031", "contents": "Title: Active Fairness in Algorithmic Decision Making Abstract: Society increasingly relies on machine learning models for automated decision\nmaking. Yet, efficiency gains from automation have come paired with concern for\nalgorithmic discrimination that can systematize inequality. Recent work has\nproposed optimal post-processing methods that randomize classification\ndecisions for a fraction of individuals, in order to achieve fairness measures\nrelated to parity in errors and calibration. These methods, however, have\nraised concern due to the information inefficiency, intra-group unfairness, and\nPareto sub-optimality they entail. The present work proposes an alternative\nactive framework for fair classification, where, in deployment, a\ndecision-maker adaptively acquires information according to the needs of\ndifferent groups or individuals, towards balancing disparities in\nclassification performance. We propose two such methods, where information\ncollection is adapted to group- and individual-level needs respectively. We\nshow on real-world datasets that these can achieve: 1) calibration and single\nerror parity (e.g., equal opportunity); and 2) parity in both false positive\nand false negative rates (i.e., equal odds). Moreover, we show that by\nleveraging their additional degree of freedom, active approaches can\nsubstantially outperform randomization-based classifiers previously considered\noptimal, while avoiding limitations such as intra-group unfairness. \n\n"}
{"id": "1810.00147", "contents": "Title: M$^3$RL: Mind-aware Multi-agent Management Reinforcement Learning Abstract: Most of the prior work on multi-agent reinforcement learning (MARL) achieves\noptimal collaboration by directly controlling the agents to maximize a common\nreward. In this paper, we aim to address this from a different angle. In\nparticular, we consider scenarios where there are self-interested agents (i.e.,\nworker agents) which have their own minds (preferences, intentions, skills,\netc.) and can not be dictated to perform tasks they do not wish to do. For\nachieving optimal coordination among these agents, we train a super agent\n(i.e., the manager) to manage them by first inferring their minds based on both\ncurrent and past observations and then initiating contracts to assign suitable\ntasks to workers and promise to reward them with corresponding bonuses so that\nthey will agree to work together. The objective of the manager is maximizing\nthe overall productivity as well as minimizing payments made to the workers for\nad-hoc worker teaming. To train the manager, we propose Mind-aware Multi-agent\nManagement Reinforcement Learning (M^3RL), which consists of agent modeling and\npolicy learning. We have evaluated our approach in two environments, Resource\nCollection and Crafting, to simulate multi-agent management problems with\nvarious task settings and multiple designs for the worker agents. The\nexperimental results have validated the effectiveness of our approach in\nmodeling worker agents' minds online, and in achieving optimal ad-hoc teaming\nwith good generalization and fast adaptation. \n\n"}
{"id": "1810.00303", "contents": "Title: Newton-MR: Inexact Newton Method With Minimum Residual Sub-problem\n  Solver Abstract: We consider a variant of inexact Newton Method, called Newton-MR, in which\nthe least-squares sub-problems are solved approximately using Minimum Residual\nmethod. By construction, Newton-MR can be readily applied for unconstrained\noptimization of a class of non-convex problems known as invex, which subsumes\nconvexity as a sub-class. For invex optimization, instead of the classical\nLipschitz continuity assumptions on gradient and Hessian, Newton-MR's global\nconvergence can be guaranteed under a weaker notion of joint regularity of\nHessian and gradient. We also obtain Newton-MR's problem-independent local\nconvergence to the set of minima. We show that fast local/global convergence\ncan be guaranteed under a novel inexactness condition, which, to our knowledge,\nis much weaker than the prior related works. Numerical results demonstrate the\nperformance of Newton-MR as compared with several other Newton-type\nalternatives on a few machine learning problems. \n\n"}
{"id": "1810.00510", "contents": "Title: Interactive Agent Modeling by Learning to Probe Abstract: The ability of modeling the other agents, such as understanding their\nintentions and skills, is essential to an agent's interactions with other\nagents. Conventional agent modeling relies on passive observation from\ndemonstrations. In this work, we propose an interactive agent modeling scheme\nenabled by encouraging an agent to learn to probe. In particular, the probing\nagent (i.e. a learner) learns to interact with the environment and with a\ntarget agent (i.e., a demonstrator) to maximize the change in the observed\nbehaviors of that agent. Through probing, rich behaviors can be observed and\nare used for enhancing the agent modeling to learn a more accurate mind model\nof the target agent. Our framework consists of two learning processes: i)\nimitation learning for an approximated agent model and ii) pure\ncuriosity-driven reinforcement learning for an efficient probing policy to\ndiscover new behaviors that otherwise can not be observed. We have validated\nour approach in four different tasks. The experimental results suggest that the\nagent model learned by our approach i) generalizes better in novel scenarios\nthan the ones learned by passive observation, random probing, and other\ncuriosity-driven approaches do, and ii) can be used for enhancing performance\nin multiple applications including distilling optimal planning to a policy net,\ncollaboration, and competition. A video demo is available at\nhttps://www.dropbox.com/s/8mz6rd3349tso67/Probing_Demo.mov?dl=0 \n\n"}
{"id": "1810.00679", "contents": "Title: Direct optimization of F-measure for retrieval-based personal question\n  answering Abstract: Recent advances in spoken language technologies and the introduction of many\ncustomer facing products, have given rise to a wide customer reliance on smart\npersonal assistants for many of their daily tasks. In this paper, we present a\nsystem to reduce users' cognitive load by extending personal assistants with\nlong-term personal memory where users can store and retrieve by voice,\narbitrary pieces of information. The problem is framed as a neural retrieval\nbased question answering system where answers are selected from previously\nstored user memories. We propose to directly optimize the end-to-end retrieval\nperformance, measured by the F1-score, using reinforcement learning, leading to\nbetter performance on our experimental test set(s). \n\n"}
{"id": "1810.00800", "contents": "Title: Optimal Pricing For MHR and $\\lambda$-Regular Distributions Abstract: We study the performance of anonymous posted-price selling mechanisms for a\nstandard Bayesian auction setting, where $n$ bidders have i.i.d. valuations for\na single item. We show that for the natural class of Monotone Hazard Rate (MHR)\ndistributions, offering the same, take-it-or-leave-it price to all bidders can\nachieve an (asymptotically) optimal revenue. In particular, the approximation\nratio is shown to be $1+O(\\ln \\ln n/\\ln n)$, matched by a tight lower bound for\nthe case of exponential distributions. This improves upon the previously\nbest-known upper bound of $e/(e-1)\\approx 1.58$ for the slightly more general\nclass of regular distributions. In the worst case (over $n$), we still show a\nglobal upper bound of $1.35$. We give a simple, closed-form description of our\nprices which, interestingly enough, relies only on minimal knowledge of the\nprior distribution, namely just the expectation of its second-highest order\nstatistic.\n  Furthermore, we extend our techniques to handle the more general class of\n$\\lambda$-regular distributions that interpolate between MHR ($\\lambda=0$) and\nregular ($\\lambda=1$). Our anonymous pricing rule now results in an asymptotic\napproximation ratio that ranges smoothly, with respect to $\\lambda$, from $1$\n(MHR distributions) to $e/(e-1)$ (regular distributions). Finally, we\nexplicitly give a class of continuous distributions that provide matching lower\nbounds, for every $\\lambda$. \n\n"}
{"id": "1810.00825", "contents": "Title: Set Transformer: A Framework for Attention-based Permutation-Invariant\n  Neural Networks Abstract: Many machine learning tasks such as multiple instance learning, 3D shape\nrecognition, and few-shot image classification are defined on sets of\ninstances. Since solutions to such problems do not depend on the order of\nelements of the set, models used to address them should be permutation\ninvariant. We present an attention-based neural network module, the Set\nTransformer, specifically designed to model interactions among elements in the\ninput set. The model consists of an encoder and a decoder, both of which rely\non attention mechanisms. In an effort to reduce computational complexity, we\nintroduce an attention scheme inspired by inducing point methods from sparse\nGaussian process literature. It reduces the computation time of self-attention\nfrom quadratic to linear in the number of elements in the set. We show that our\nmodel is theoretically attractive and we evaluate it on a range of tasks,\ndemonstrating the state-of-the-art performance compared to recent methods for\nset-structured data. \n\n"}
{"id": "1810.00950", "contents": "Title: Omega-Regular Objectives in Model-Free Reinforcement Learning Abstract: We provide the first solution for model-free reinforcement learning of\n{\\omega}-regular objectives for Markov decision processes (MDPs). We present a\nconstructive reduction from the almost-sure satisfaction of {\\omega}-regular\nobjectives to an almost- sure reachability problem and extend this technique to\nlearning how to control an unknown model so that the chance of satisfying the\nobjective is maximized. A key feature of our technique is the compilation of\n{\\omega}-regular properties into limit- deterministic Buechi automata instead\nof the traditional Rabin automata; this choice sidesteps difficulties that have\nmarred previous proposals. Our approach allows us to apply model-free,\noff-the-shelf reinforcement learning algorithms to compute optimal strategies\nfrom the observations of the MDP. We present an experimental evaluation of our\ntechnique on benchmark learning problems. \n\n"}
{"id": "1810.01269", "contents": "Title: A fast quasi-Newton-type method for large-scale stochastic optimisation Abstract: During recent years there has been an increased interest in stochastic\nadaptations of limited memory quasi-Newton methods, which compared to pure\ngradient-based routines can improve the convergence by incorporating second\norder information. In this work we propose a direct least-squares approach\nconceptually similar to the limited memory quasi-Newton methods, but that\ncomputes the search direction in a slightly different way. This is achieved in\na fast and numerically robust manner by maintaining a Cholesky factor of low\ndimension. This is combined with a stochastic line search relying upon\nfulfilment of the Wolfe condition in a backtracking manner, where the step\nlength is adaptively modified with respect to the optimisation progress. We\nsupport our new algorithm by providing several theoretical results guaranteeing\nits performance. The performance is demonstrated on real-world benchmark\nproblems which shows improved results in comparison with already established\nmethods. \n\n"}
{"id": "1810.02022", "contents": "Title: Convergence of the Expectation-Maximization Algorithm Through\n  Discrete-Time Lyapunov Stability Theory Abstract: In this paper, we propose a dynamical systems perspective of the\nExpectation-Maximization (EM) algorithm. More precisely, we can analyze the EM\nalgorithm as a nonlinear state-space dynamical system. The EM algorithm is\nwidely adopted for data clustering and density estimation in statistics,\ncontrol systems, and machine learning. This algorithm belongs to a large class\nof iterative algorithms known as proximal point methods. In particular, we\nre-interpret limit points of the EM algorithm and other local maximizers of the\nlikelihood function it seeks to optimize as equilibria in its dynamical system\nrepresentation. Furthermore, we propose to assess its convergence as asymptotic\nstability in the sense of Lyapunov. As a consequence, we proceed by leveraging\nrecent results regarding discrete-time Lyapunov stability theory in order to\nestablish asymptotic stability (and thus, convergence) in the dynamical system\nrepresentation of the EM algorithm. \n\n"}
{"id": "1810.02060", "contents": "Title: Weakly-Convex Concave Min-Max Optimization: Provable Algorithms and\n  Applications in Machine Learning Abstract: Min-max problems have broad applications in machine learning, including\nlearning with non-decomposable loss and learning with robustness to data\ndistribution. Convex-concave min-max problem is an active topic of research\nwith efficient algorithms and sound theoretical foundations developed. However,\nit remains a challenge to design provably efficient algorithms for non-convex\nmin-max problems with or without smoothness. In this paper, we study a family\nof non-convex min-max problems, whose objective function is weakly convex in\nthe variables of minimization and is concave in the variables of maximization.\nWe propose a proximally guided stochastic subgradient method and a proximally\nguided stochastic variance-reduced method for the non-smooth and smooth\ninstances, respectively, in this family of problems. We analyze the time\ncomplexities of the proposed methods for finding a nearly stationary point of\nthe outer minimization problem corresponding to the min-max problem. \n\n"}
{"id": "1810.02244", "contents": "Title: Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks Abstract: In recent years, graph neural networks (GNNs) have emerged as a powerful\nneural architecture to learn vector representations of nodes and graphs in a\nsupervised, end-to-end fashion. Up to now, GNNs have only been evaluated\nempirically -- showing promising results. The following work investigates GNNs\nfrom a theoretical point of view and relates them to the $1$-dimensional\nWeisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs have\nthe same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic\n(sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on\nthis, we propose a generalization of GNNs, so-called $k$-dimensional GNNs\n($k$-GNNs), which can take higher-order graph structures at multiple scales\ninto account. These higher-order structures play an essential role in the\ncharacterization of social networks and molecule graphs. Our experimental\nevaluation confirms our theoretical findings as well as confirms that\nhigher-order information is useful in the task of graph classification and\nregression. \n\n"}
{"id": "1810.02423", "contents": "Title: Generalizing the theory of cooperative inference Abstract: Cooperation information sharing is important to theories of human learning\nand has potential implications for machine learning. Prior work derived\nconditions for achieving optimal Cooperative Inference given strong, relatively\nrestrictive assumptions. We relax these assumptions by demonstrating\nconvergence for any discrete joint distribution, robustness through equivalence\nclasses and stability under perturbation, and effectiveness by deriving bounds\nfrom structural properties of the original joint distribution. We provide\ngeometric interpretations, connections to and implications for optimal\ntransport, and connections to importance sampling, and conclude by outlining\nopen questions and challenges to realizing the promise of Cooperative\nInference. \n\n"}
{"id": "1810.02453", "contents": "Title: Correcting the bias in least squares regression with volume-rescaled\n  sampling Abstract: Consider linear regression where the examples are generated by an unknown\ndistribution on $R^d\\times R$. Without any assumptions on the noise, the linear\nleast squares solution for any i.i.d. sample will typically be biased w.r.t.\nthe least squares optimum over the entire distribution. However, we show that\nif an i.i.d. sample of any size k is augmented by a certain small additional\nsample, then the solution of the combined sample becomes unbiased. We show this\nwhen the additional sample consists of d points drawn jointly according to the\ninput distribution that is rescaled by the squared volume spanned by the\npoints. Furthermore, we propose algorithms to sample from this volume-rescaled\ndistribution when the data distribution is only known through an i.i.d sample. \n\n"}
{"id": "1810.02565", "contents": "Title: Continuous-time Models for Stochastic Optimization Algorithms Abstract: We propose new continuous-time formulations for first-order stochastic\noptimization algorithms such as mini-batch gradient descent and\nvariance-reduced methods. We exploit these continuous-time models, together\nwith simple Lyapunov analysis as well as tools from stochastic calculus, in\norder to derive convergence bounds for various types of non-convex functions.\nGuided by such analysis, we show that the same Lyapunov arguments hold in\ndiscrete-time, leading to matching rates. In addition, we use these models and\nIto calculus to infer novel insights on the dynamics of SGD, proving that a\ndecreasing learning rate acts as time warping or, equivalently, as landscape\nstretching. \n\n"}
{"id": "1810.02789", "contents": "Title: Doubly Semi-Implicit Variational Inference Abstract: We extend the existing framework of semi-implicit variational inference\n(SIVI) and introduce doubly semi-implicit variational inference (DSIVI), a way\nto perform variational inference and learning when both the approximate\nposterior and the prior distribution are semi-implicit. In other words, DSIVI\nperforms inference in models where the prior and the posterior can be expressed\nas an intractable infinite mixture of some analytic density with a highly\nflexible implicit mixing distribution. We provide a sandwich bound on the\nevidence lower bound (ELBO) objective that can be made arbitrarily tight.\nUnlike discriminator-based and kernel-based approaches to implicit variational\ninference, DSIVI optimizes a proper lower bound on ELBO that is asymptotically\nexact. We evaluate DSIVI on a set of problems that benefit from implicit\npriors. In particular, we show that DSIVI gives rise to a simple modification\nof VampPrior, the current state-of-the-art prior for variational autoencoders,\nwhich improves its performance. \n\n"}
{"id": "1810.02797", "contents": "Title: RCCNet: An Efficient Convolutional Neural Network for Histological\n  Routine Colon Cancer Nuclei Classification Abstract: Efficient and precise classification of histological cell nuclei is of utmost\nimportance due to its potential applications in the field of medical image\nanalysis. It would facilitate the medical practitioners to better understand\nand explore various factors for cancer treatment. The classification of\nhistological cell nuclei is a challenging task due to the cellular\nheterogeneity. This paper proposes an efficient Convolutional Neural Network\n(CNN) based architecture for classification of histological routine colon\ncancer nuclei named as RCCNet. The main objective of this network is to keep\nthe CNN model as simple as possible. The proposed RCCNet model consists of only\n1,512,868 learnable parameters which are significantly less compared to the\npopular CNN models such as AlexNet, CIFARVGG, GoogLeNet, and WRN. The\nexperiments are conducted over publicly available routine colon cancer\nhistological dataset \"CRCHistoPhenotypes\". The results of the proposed RCCNet\nmodel are compared with five state-of-the-art CNN models in terms of the\naccuracy, weighted average F1 score and training time. The proposed method has\nachieved a classification accuracy of 80.61% and 0.7887 weighted average F1\nscore. The proposed RCCNet is more efficient and generalized terms of the\ntraining time and data over-fitting, respectively. \n\n"}
{"id": "1810.03372", "contents": "Title: Detecting Memorization in ReLU Networks Abstract: We propose a new notion of `non-linearity' of a network layer with respect to\nan input batch that is based on its proximity to a linear system, which is\nreflected in the non-negative rank of the activation matrix. We measure this\nnon-linearity by applying non-negative factorization to the activation matrix.\nConsidering batches of similar samples, we find that high non-linearity in deep\nlayers is indicative of memorization. Furthermore, by applying our approach\nlayer-by-layer, we find that the mechanism for memorization consists of\ndistinct phases. We perform experiments on fully-connected and convolutional\nneural networks trained on several image and audio datasets. Our results\ndemonstrate that as an indicator for memorization, our technique can be used to\nperform early stopping. \n\n"}
{"id": "1810.03552", "contents": "Title: Multi-Source Cross-Lingual Model Transfer: Learning What to Share Abstract: Modern NLP applications have enjoyed a great boost utilizing neural networks\nmodels. Such deep neural models, however, are not applicable to most human\nlanguages due to the lack of annotated training data for various NLP tasks.\nCross-lingual transfer learning (CLTL) is a viable method for building NLP\nmodels for a low-resource target language by leveraging labeled data from other\n(source) languages. In this work, we focus on the multilingual transfer setting\nwhere training data in multiple source languages is leveraged to further boost\ntarget language performance.\n  Unlike most existing methods that rely only on language-invariant features\nfor CLTL, our approach coherently utilizes both language-invariant and\nlanguage-specific features at instance level. Our model leverages adversarial\nnetworks to learn language-invariant features, and mixture-of-experts models to\ndynamically exploit the similarity between the target language and each\nindividual source language. This enables our model to learn effectively what to\nshare between various languages in the multilingual setup. Moreover, when\ncoupled with unsupervised multilingual embeddings, our model can operate in a\nzero-resource setting where neither target language training data nor\ncross-lingual resources are available. Our model achieves significant\nperformance gains over prior art, as shown in an extensive set of experiments\nover multiple text classification and sequence tagging tasks including a\nlarge-scale industry dataset. \n\n"}
{"id": "1810.03743", "contents": "Title: JOBS: Joint-Sparse Optimization from Bootstrap Samples Abstract: Classical signal recovery based on $\\ell_1$ minimization solves the least\nsquares problem with all available measurements via sparsity-promoting\nregularization. In practice, it is often the case that not all measurements are\navailable or required for recovery. Measurements might be corrupted/missing or\nthey arrive sequentially in streaming fashion. In this paper, we propose a\nglobal sparse recovery strategy based on subsets of measurements, named JOBS,\nin which multiple measurements vectors are generated from the original pool of\nmeasurements via bootstrapping, and then a joint-sparse constraint is enforced\nto ensure support consistency among multiple predictors. The final estimate is\nobtained by averaging over the $K$ predictors. The performance limits\nassociated with different choices of number of bootstrap samples $L$ and number\nof estimates $K$ is analyzed theoretically. Simulation results validate some of\nthe theoretical analysis, and show that the proposed method yields\nstate-of-the-art recovery performance, outperforming $\\ell_1$ minimization and\na few other existing bootstrap-based techniques in the challenging case of low\nlevels of measurements and is preferable over other bagging-based methods in\nthe streaming setting since it performs better with small $K$ and $L$ for\ndata-sets with large sizes. \n\n"}
{"id": "1810.03763", "contents": "Title: Cubic Regularization with Momentum for Nonconvex Optimization Abstract: Momentum is a popular technique to accelerate the convergence in practical\ntraining, and its impact on convergence guarantee has been well-studied for\nfirst-order algorithms. However, such a successful acceleration technique has\nnot yet been proposed for second-order algorithms in nonconvex optimization.In\nthis paper, we apply the momentum scheme to cubic regularized (CR) Newton's\nmethod and explore the potential for acceleration. Our numerical experiments on\nvarious nonconvex optimization problems demonstrate that the momentum scheme\ncan substantially facilitate the convergence of cubic regularization, and\nperform even better than the Nesterov's acceleration scheme for CR.\nTheoretically, we prove that CR under momentum achieves the best possible\nconvergence rate to a second-order stationary point for nonconvex optimization.\nMoreover, we study the proposed algorithm for solving problems satisfying an\nerror bound condition and establish a local quadratic convergence rate. Then,\nparticularly for finite-sum problems, we show that the proposed algorithm can\nallow computational inexactness that reduces the overall sample complexity\nwithout degrading the convergence rate. \n\n"}
{"id": "1810.03806", "contents": "Title: The Adversarial Attack and Detection under the Fisher Information Metric Abstract: Many deep learning models are vulnerable to the adversarial attack, i.e.,\nimperceptible but intentionally-designed perturbations to the input can cause\nincorrect output of the networks. In this paper, using information geometry, we\nprovide a reasonable explanation for the vulnerability of deep learning models.\nBy considering the data space as a non-linear space with the Fisher information\nmetric induced from a neural network, we first propose an adversarial attack\nalgorithm termed one-step spectral attack (OSSA). The method is described by a\nconstrained quadratic form of the Fisher information matrix, where the optimal\nadversarial perturbation is given by the first eigenvector, and the model\nvulnerability is reflected by the eigenvalues. The larger an eigenvalue is, the\nmore vulnerable the model is to be attacked by the corresponding eigenvector.\nTaking advantage of the property, we also propose an adversarial detection\nmethod with the eigenvalues serving as characteristics. Both our attack and\ndetection algorithms are numerically optimized to work efficiently on large\ndatasets. Our evaluations show superior performance compared with other\nmethods, implying that the Fisher information is a promising approach to\ninvestigate the adversarial attacks and defenses. \n\n"}
{"id": "1810.04100", "contents": "Title: Characterization of Convex Objective Functions and Optimal Expected\n  Convergence Rates for SGD Abstract: We study Stochastic Gradient Descent (SGD) with diminishing step sizes for\nconvex objective functions. We introduce a definitional framework and theory\nthat defines and characterizes a core property, called curvature, of convex\nobjective functions. In terms of curvature we can derive a new inequality that\ncan be used to compute an optimal sequence of diminishing step sizes by solving\na differential equation. Our exact solutions confirm known results in\nliterature and allows us to fully characterize a new regularizer with its\ncorresponding expected convergence rates. \n\n"}
{"id": "1810.04723", "contents": "Title: Tight Dimension Independent Lower Bound on the Expected Convergence Rate\n  for Diminishing Step Sizes in SGD Abstract: We study the convergence of Stochastic Gradient Descent (SGD) for strongly\nconvex objective functions. We prove for all $t$ a lower bound on the expected\nconvergence rate after the $t$-th SGD iteration; the lower bound is over all\npossible sequences of diminishing step sizes. It implies that recently proposed\nsequences of step sizes at ICML 2018 and ICML 2019 are {\\em universally} close\nto optimal in that the expected convergence rate after {\\em each} iteration is\nwithin a factor $32$ of our lower bound. This factor is independent of\ndimension $d$. We offer a framework for comparing with lower bounds in\nstate-of-the-art literature and when applied to SGD for strongly convex\nobjective functions our lower bound is a significant factor $775\\cdot d$ larger\ncompared to existing work. \n\n"}
{"id": "1810.05846", "contents": "Title: Nesterov Acceleration of Alternating Least Squares for Canonical Tensor\n  Decomposition: Momentum Step Size Selection and Restart Mechanisms Abstract: We present Nesterov-type acceleration techniques for Alternating Least\nSquares (ALS) methods applied to canonical tensor decomposition. While Nesterov\nacceleration turns gradient descent into an optimal first-order method for\nconvex problems by adding a momentum term with a specific weight sequence, a\ndirect application of this method and weight sequence to ALS results in erratic\nconvergence behaviour. This is so because the tensor decomposition problem is\nnon-convex and ALS is accelerated instead of gradient descent. Instead, we\nconsider various restart mechanisms and suitable choices of momentum weights\nthat enable effective acceleration. Our extensive empirical results show that\nthe Nesterov-accelerated ALS methods with restart can be dramatically more\nefficient than the stand-alone ALS or Nesterov accelerated gradient methods,\nwhen problems are ill-conditioned or accurate solutions are desired. The\nresulting methods perform competitively with or superior to existing\nacceleration methods for ALS, including ALS acceleration by NCG, NGMRES, or\nLBFGS, and additionally enjoy the benefit of being much easier to implement. We\nalso compare with Nesterov-type updates where the momentum weight is determined\nby a line search, which are equivalent or closely related to existing line\nsearch methods for ALS. On a large and ill-conditioned\n71$\\times$1000$\\times$900 tensor consisting of readings from chemical sensors\nto track hazardous gases, the restarted Nesterov-ALS method shows desirable\nrobustness properties and outperforms any of the existing methods by a large\nfactor. There is clear potential for extending our Nesterov-type acceleration\napproach to accelerating other optimization algorithms than ALS applied to\nother non-convex problems, such as Tucker tensor decomposition. Our Matlab code\nis available at\nhttps://github.com/hansdesterck/nonlinear-preconditioning-for-optimization. \n\n"}
{"id": "1810.06177", "contents": "Title: Revisit Batch Normalization: New Understanding from an Optimization View\n  and a Refinement via Composition Optimization Abstract: Batch Normalization (BN) has been used extensively in deep learning to\nachieve faster training process and better resulting models. However, whether\nBN works strongly depends on how the batches are constructed during training\nand it may not converge to a desired solution if the statistics on a batch are\nnot close to the statistics over the whole dataset. In this paper, we try to\nunderstand BN from an optimization perspective by formulating the optimization\nproblem which motivates BN. We show when BN works and when BN does not work by\nanalyzing the optimization problem. We then propose a refinement of BN based on\ncompositional optimization techniques called Full Normalization (FN) to\nalleviate the issues of BN when the batches are not constructed ideally. We\nprovide convergence analysis for FN and empirically study its effectiveness to\nrefine BN. \n\n"}
{"id": "1810.06313", "contents": "Title: Regret vs. Bandwidth Trade-off for Recommendation Systems Abstract: We consider recommendation systems that need to operate under wireless\nbandwidth constraints, measured as number of broadcast transmissions, and\ndemonstrate a (tight for some instances) tradeoff between regret and bandwidth\nfor two scenarios: the case of multi-armed bandit with context, and the case\nwhere there is a latent structure in the message space that we can exploit to\nreduce the learning phase. \n\n"}
{"id": "1810.06999", "contents": "Title: Efficient Greedy Coordinate Descent for Composite Problems Abstract: Coordinate descent with random coordinate selection is the current state of\nthe art for many large scale optimization problems. However, greedy selection\nof the steepest coordinate on smooth problems can yield convergence rates\nindependent of the dimension $n$, and requiring upto $n$ times fewer\niterations.\n  In this paper, we consider greedy updates that are based on subgradients for\na class of non-smooth composite problems, which includes $L1$-regularized\nproblems, SVMs and related applications. For these problems we provide (i) the\nfirst linear rates of convergence independent of $n$, and show that our greedy\nupdate rule provides speedups similar to those obtained in the smooth case.\nThis was previously conjectured to be true for a stronger greedy coordinate\nselection strategy.\n  Furthermore, we show that (ii) our new selection rule can be mapped to\ninstances of maximum inner product search, allowing to leverage standard\nnearest neighbor algorithms to speed up the implementation. We demonstrate the\nvalidity of the approach through extensive numerical experiments. \n\n"}
{"id": "1810.07076", "contents": "Title: Stochastic Negative Mining for Learning with Large Output Spaces Abstract: We consider the problem of retrieving the most relevant labels for a given\ninput when the size of the output space is very large. Retrieval methods are\nmodeled as set-valued classifiers which output a small set of classes for each\ninput, and a mistake is made if the label is not in the output set. Despite its\npractical importance, a statistically principled, yet practical solution to\nthis problem is largely missing. To this end, we first define a family of\nsurrogate losses and show that they are calibrated and convex under certain\nconditions on the loss parameters and data distribution, thereby establishing a\nstatistical and analytical basis for using these losses. Furthermore, we\nidentify a particularly intuitive class of loss functions in the aforementioned\nfamily and show that they are amenable to practical implementation in the large\noutput space setting (i.e. computation is possible without evaluating scores of\nall labels) by developing a technique called Stochastic Negative Mining. We\nalso provide generalization error bounds for the losses in the family. Finally,\nwe conduct experiments which demonstrate that Stochastic Negative Mining yields\nbenefits over commonly used negative sampling approaches. \n\n"}
{"id": "1810.07590", "contents": "Title: Graphical Convergence of Subgradients in Nonconvex Optimization and\n  Learning Abstract: We investigate the stochastic optimization problem of minimizing population\nrisk, where the loss defining the risk is assumed to be weakly convex.\nCompositions of Lipschitz convex functions with smooth maps are the primary\nexamples of such losses. We analyze the estimation quality of such nonsmooth\nand nonconvex problems by their sample average approximations. Our main results\nestablish dimension-dependent rates on subgradient estimation in full\ngenerality and dimension-independent rates when the loss is a generalized\nlinear model. As an application of the developed techniques, we analyze the\nnonsmooth landscape of a robust nonlinear regression problem. \n\n"}
{"id": "1810.07725", "contents": "Title: RIn-Close_CVC2: an even more efficient enumerative algorithm for\n  biclustering of numerical datasets Abstract: RIn-Close_CVC is an efficient (take polynomial time per bicluster), complete\n(find all maximal biclusters), correct (all biclusters attend the user-defined\nlevel of consistency) and non-redundant (all the obtained biclusters are\nmaximal and the same bicluster is not enumerated more than once) enumerative\nalgorithm for mining maximal biclusters with constant values on columns in\nnumerical datasets. Despite RIn-Close_CVC has all these outstanding properties,\nit has a high computational cost in terms of memory usage because it must keep\na symbol table in memory to prevent a maximal bicluster to be found more than\nonce. In this paper, we propose a new version of RIn-Close_CVC, named\nRIn-Close_CVC2, that does not use a symbol table to prevent redundant\nbiclusters, and keeps all these four properties. We also prove that these\nalgorithms actually possess these properties. Experiments are carried out with\nsynthetic and real-world datasets to compare RIn-Close_CVC and RIn-Close_CVC2\nin terms of memory usage and runtime. The experimental results show that\nRIn-Close_CVC2 brings a large reduction in memory usage and, in average,\nsignificant runtime gain when compared to its predecessor. \n\n"}
{"id": "1810.08171", "contents": "Title: Testing Matrix Rank, Optimally Abstract: We show that for the problem of testing if a matrix $A \\in F^{n \\times n}$\nhas rank at most $d$, or requires changing an $\\epsilon$-fraction of entries to\nhave rank at most $d$, there is a non-adaptive query algorithm making\n$\\widetilde{O}(d^2/\\epsilon)$ queries. Our algorithm works for any field $F$.\nThis improves upon the previous $O(d^2/\\epsilon^2)$ bound (SODA'03), and\nbypasses an $\\Omega(d^2/\\epsilon^2)$ lower bound of (KDD'14) which holds if the\nalgorithm is required to read a submatrix. Our algorithm is the first such\nalgorithm which does not read a submatrix, and instead reads a carefully\nselected non-adaptive pattern of entries in rows and columns of $A$. We\ncomplement our algorithm with a matching query complexity lower bound for\nnon-adaptive testers over any field. We also give tight bounds of\n$\\widetilde{\\Theta}(d^2)$ queries in the sensing model for which query access\ncomes in the form of $\\langle X_i, A\\rangle:=tr(X_i^\\top A)$; perhaps\nsurprisingly these bounds do not depend on $\\epsilon$.\n  We next develop a novel property testing framework for testing numerical\nproperties of a real-valued matrix $A$ more generally, which includes the\nstable rank, Schatten-$p$ norms, and SVD entropy. Specifically, we propose a\nbounded entry model, where $A$ is required to have entries bounded by $1$ in\nabsolute value. We give upper and lower bounds for a wide range of problems in\nthis model, and discuss connections to the sensing model above. \n\n"}
{"id": "1810.08727", "contents": "Title: Condition Number Analysis of Logistic Regression, and its Implications\n  for Standard First-Order Solution Methods Abstract: Logistic regression is one of the most popular methods in binary\nclassification, wherein estimation of model parameters is carried out by\nsolving the maximum likelihood (ML) optimization problem, and the ML estimator\nis defined to be the optimal solution of this problem. It is well known that\nthe ML estimator exists when the data is non-separable, but fails to exist when\nthe data is separable. First-order methods are the algorithms of choice for\nsolving large-scale instances of the logistic regression problem. In this\npaper, we introduce a pair of condition numbers that measure the degree of\nnon-separability or separability of a given dataset in the setting of binary\nclassification, and we study how these condition numbers relate to and inform\nthe properties and the convergence guarantees of first-order methods. When the\ntraining data is non-separable, we show that the degree of non-separability\nnaturally enters the analysis and informs the properties and convergence\nguarantees of two standard first-order methods: steepest descent (for any given\nnorm) and stochastic gradient descent. Expanding on the work of Bach, we also\nshow how the degree of non-separability enters into the analysis of linear\nconvergence of steepest descent (without needing strong convexity), as well as\nthe adaptive convergence of stochastic gradient descent. When the training data\nis separable, first-order methods rather curiously have good empirical success,\nwhich is not well understood in theory. In the case of separable data, we\ndemonstrate how the degree of separability enters into the analysis of $\\ell_2$\nsteepest descent and stochastic gradient descent for delivering\napproximate-maximum-margin solutions with associated computational guarantees\nas well. This suggests that first-order methods can lead to statistically\nmeaningful solutions in the separable case, even though the ML solution does\nnot exist. \n\n"}
{"id": "1810.08732", "contents": "Title: Named Entity Recognition on Twitter for Turkish using Semi-supervised\n  Learning with Word Embeddings Abstract: Recently, due to the increasing popularity of social media, the necessity for\nextracting information from informal text types, such as microblog texts, has\ngained significant attention. In this study, we focused on the Named Entity\nRecognition (NER) problem on informal text types for Turkish. We utilized a\nsemi-supervised learning approach based on neural networks. We applied a fast\nunsupervised method for learning continuous representations of words in vector\nspace. We made use of these obtained word embeddings, together with language\nindependent features that are engineered to work better on informal text types,\nfor generating a Turkish NER system on microblog texts. We evaluated our\nTurkish NER system on Twitter messages and achieved better F-score performances\nthan the published results of previously proposed NER systems on Turkish\ntweets. Since we did not employ any language dependent features, we believe\nthat our method can be easily adapted to microblog texts in other\nmorphologically rich languages. \n\n"}
{"id": "1810.08743", "contents": "Title: Quantifying the Burden of Exploration and the Unfairness of Free Riding Abstract: We consider the multi-armed bandit setting with a twist. Rather than having\njust one decision maker deciding which arm to pull in each round, we have $n$\ndifferent decision makers (agents). In the simple stochastic setting, we show\nthat a \"free-riding\" agent observing another \"self-reliant\" agent can achieve\njust $O(1)$ regret, as opposed to the regret lower bound of $\\Omega (\\log t)$\nwhen one decision maker is playing in isolation. This result holds whenever the\nself-reliant agent's strategy satisfies either one of two assumptions: (1) each\narm is pulled at least $\\gamma \\ln t$ times in expectation for a constant\n$\\gamma$ that we compute, or (2) the self-reliant agent achieves $o(t)$\nrealized regret with high probability. Both of these assumptions are satisfied\nby standard zero-regret algorithms. Under the second assumption, we further\nshow that the free rider only needs to observe the number of times each arm is\npulled by the self-reliant agent, and not the rewards realized.\n  In the linear contextual setting, each arm has a distribution over parameter\nvectors, each agent has a context vector, and the reward realized when an agent\npulls an arm is the inner product of that agent's context vector with a\nparameter vector sampled from the pulled arm's distribution. We show that the\nfree rider can achieve $O(1)$ regret in this setting whenever the free rider's\ncontext is a small (in $L_2$-norm) linear combination of other agents' contexts\nand all other agents pull each arm $\\Omega (\\log t)$ times with high\nprobability. Again, this condition on the self-reliant players is satisfied by\nstandard zero-regret algorithms like UCB. We also prove a number of lower\nbounds. \n\n"}
{"id": "1810.08907", "contents": "Title: Understanding the Acceleration Phenomenon via High-Resolution\n  Differential Equations Abstract: Gradient-based optimization algorithms can be studied from the perspective of\nlimiting ordinary differential equations (ODEs). Motivated by the fact that\nexisting ODEs do not distinguish between two fundamentally different\nalgorithms---Nesterov's accelerated gradient method for strongly convex\nfunctions (NAG-SC) and Polyak's heavy-ball method---we study an alternative\nlimiting process that yields high-resolution ODEs. We show that these ODEs\npermit a general Lyapunov function framework for the analysis of convergence in\nboth continuous and discrete time. We also show that these ODEs are more\naccurate surrogates for the underlying algorithms; in particular, they not only\ndistinguish between NAG-SC and Polyak's heavy-ball method, but they allow the\nidentification of a term that we refer to as \"gradient correction\" that is\npresent in NAG-SC but not in the heavy-ball method and is responsible for the\nqualitative difference in convergence of the two methods. We also use the\nhigh-resolution ODE framework to study Nesterov's accelerated gradient method\nfor (non-strongly) convex functions, uncovering a hitherto unknown\nresult---that NAG-C minimizes the squared gradient norm at an inverse cubic\nrate. Finally, by modifying the high-resolution ODE of NAG-C, we obtain a\nfamily of new optimization methods that are shown to maintain the accelerated\nconvergence rates of NAG-C for smooth convex functions. \n\n"}
{"id": "1810.09113", "contents": "Title: The Bregman chord divergence Abstract: Distances are fundamental primitives whose choice significantly impacts the\nperformances of algorithms in machine learning and signal processing. However\nselecting the most appropriate distance for a given task is an endeavor.\nInstead of testing one by one the entries of an ever-expanding dictionary of\n{\\em ad hoc} distances, one rather prefers to consider parametric classes of\ndistances that are exhaustively characterized by axioms derived from first\nprinciples. Bregman divergences are such a class. However fine-tuning a Bregman\ndivergence is delicate since it requires to smoothly adjust a functional\ngenerator. In this work, we propose an extension of Bregman divergences called\nthe Bregman chord divergences. This new class of distances does not require\ngradient calculations, uses two scalar parameters that can be easily tailored\nin applications, and generalizes asymptotically Bregman divergences. \n\n"}
{"id": "1810.09270", "contents": "Title: A Model Parallel Proximal Stochastic Gradient Algorithm for Partially\n  Asynchronous Systems Abstract: Large models are prevalent in modern machine learning scenarios, including\ndeep learning, recommender systems, etc., which can have millions or even\nbillions of parameters. Parallel algorithms have become an essential solution\ntechnique to many large-scale machine learning jobs. In this paper, we propose\na model parallel proximal stochastic gradient algorithm, AsyB-ProxSGD, to deal\nwith large models using model parallel blockwise updates while in the meantime\nhandling a large amount of training data using proximal stochastic gradient\ndescent (ProxSGD). In our algorithm, worker nodes communicate with the\nparameter servers asynchronously, and each worker performs proximal stochastic\ngradient for only one block of model parameters during each iteration. Our\nproposed algorithm generalizes ProxSGD to the asynchronous and model parallel\nsetting. We prove that AsyB-ProxSGD achieves a convergence rate of\n$O(1/\\sqrt{K})$ to stationary points for nonconvex problems under\n\\emph{constant} minibatch sizes, where $K$ is the total number of block\nupdates. This rate matches the best-known rates of convergence for a wide range\nof gradient-like algorithms. Furthermore, we show that when the number of\nworkers is bounded by $O(K^{1/4})$, we can expect AsyB-ProxSGD to achieve\nlinear speedup as the number of workers increases. We implement the proposed\nalgorithm on MXNet and demonstrate its convergence behavior and near-linear\nspeedup on a real-world dataset involving both a large model size and large\namounts of data. \n\n"}
{"id": "1810.10085", "contents": "Title: A Proximal Zeroth-Order Algorithm for Nonconvex Nonsmooth Problems Abstract: In this paper, we focus on solving an important class of nonconvex\noptimization problems which includes many problems for example signal\nprocessing over a networked multi-agent system and distributed learning over\nnetworks. Motivated by many applications in which the local objective function\nis the sum of smooth but possibly nonconvex part, and non-smooth but convex\npart subject to a linear equality constraint, this paper proposes a proximal\nzeroth-order primal dual algorithm (PZO-PDA) that accounts for the information\nstructure of the problem. This algorithm only utilize the zeroth-order\ninformation (i.e., the functional values) of smooth functions, yet the\nflexibility is achieved for applications that only noisy information of the\nobjective function is accessible, where classical methods cannot be applied. We\nprove convergence and rate of convergence for PZO-PDA. Numerical experiments\nare provided to validate the theoretical results. \n\n"}
{"id": "1810.10358", "contents": "Title: Implicit Modeling with Uncertainty Estimation for Intravoxel Incoherent\n  Motion Imaging Abstract: Intravoxel incoherent motion (IVIM) imaging allows contrast-agent free in\nvivo perfusion quantification with magnetic resonance imaging (MRI). However,\nits use is limited by typically low accuracy due to low signal-to-noise ratio\n(SNR) at large gradient encoding magnitudes as well as dephasing artefacts\ncaused by subject motion, which is particularly challenging in fetal MRI. To\nmitigate this problem, we propose an implicit IVIM signal acquisition model\nwith which we learn full posterior distribution of perfusion parameters using\nartificial neural networks. This posterior then encapsulates the uncertainty of\nthe inferred parameter estimates, which we validate herein via numerical\nexperiments with rejection-based Bayesian sampling. Compared to\nstate-of-the-art IVIM estimation method of segmented least-squares fitting, our\nproposed approach improves parameter estimation accuracy by 65% on synthetic\nanisotropic perfusion data. On paired rescans of in vivo fetal MRI, our method\nincreases repeatability of parameter estimation in placenta by 46%. \n\n"}
{"id": "1810.10690", "contents": "Title: SpiderBoost and Momentum: Faster Stochastic Variance Reduction\n  Algorithms Abstract: SARAH and SPIDER are two recently developed stochastic variance-reduced\nalgorithms, and SPIDER has been shown to achieve a near-optimal first-order\noracle complexity in smooth nonconvex optimization. However, SPIDER uses an\naccuracy-dependent stepsize that slows down the convergence in practice, and\ncannot handle objective functions that involve nonsmooth regularizers. In this\npaper, we propose SpiderBoost as an improved scheme, which allows to use a much\nlarger constant-level stepsize while maintaining the same near-optimal oracle\ncomplexity, and can be extended with proximal mapping to handle composite\noptimization (which is nonsmooth and nonconvex) with provable convergence\nguarantee. In particular, we show that proximal SpiderBoost achieves an oracle\ncomplexity of $\\mathcal{O}(\\min\\{n^{1/2}\\epsilon^{-2},\\epsilon^{-3}\\})$ in\ncomposite nonconvex optimization, improving the state-of-the-art result by a\nfactor of $\\mathcal{O}(\\min\\{n^{1/6},\\epsilon^{-1/3}\\})$. We further develop a\nnovel momentum scheme to accelerate SpiderBoost for composite optimization,\nwhich achieves the near-optimal oracle complexity in theory and substantial\nimprovement in experiments. \n\n"}
{"id": "1810.11066", "contents": "Title: Automating Generation of Low Precision Deep Learning Operators Abstract: State of the art deep learning models have made steady progress in the fields\nof computer vision and natural language processing, at the expense of growing\nmodel sizes and computational complexity. Deploying these models on low power\nand mobile devices poses a challenge due to their limited compute capabilities\nand strict energy budgets. One solution that has generated significant research\ninterest is deploying highly quantized models that operate on low precision\ninputs and weights less than eight bits, trading off accuracy for performance.\nThese models have a significantly reduced memory footprint (up to 32x\nreduction) and can replace multiply-accumulates with bitwise operations during\ncompute intensive convolution and fully connected layers.\n  Most deep learning frameworks rely on highly engineered linear algebra\nlibraries such as ATLAS or Intel's MKL to implement efficient deep learning\noperators. To date, none of the popular deep learning directly support low\nprecision operators, partly due to a lack of optimized low precision libraries.\nIn this paper we introduce a work flow to quickly generate high performance low\nprecision deep learning operators for arbitrary precision that target multiple\nCPU architectures and include optimizations such as memory tiling and\nvectorization. We present an extensive case study on low power ARM Cortex-A53\nCPU, and show how we can generate 1-bit, 2-bit convolutions with speedups up to\n16x over an optimized 16-bit integer baseline and 2.3x better than handwritten\nimplementations. \n\n"}
{"id": "1810.11216", "contents": "Title: Packing Returning Secretaries Abstract: We study online secretary problems with returns in combinatorial packing\ndomains with $n$ candidates that arrive sequentially over time in random order.\nThe goal is to accept a feasible packing of candidates of maximum total value.\nIn the first variant, each candidate arrives exactly twice. All $2n$ arrivals\noccur in random order. We propose a simple 0.5-competitive algorithm that can\nbe combined with arbitrary approximation algorithms for the packing domain,\neven when the total value of candidates is a subadditive function. For\nbipartite matching, we obtain an algorithm with competitive ratio at least\n$0.5721 - o(1)$ for growing $n$, and an algorithm with ratio at least $0.5459$\nfor all $n \\ge 1$. We extend all algorithms and ratios to $k \\ge 2$ arrivals\nper candidate.\n  In the second variant, there is a pool of undecided candidates. In each\nround, a random candidate from the pool arrives. Upon arrival a candidate can\nbe either decided (accept/reject) or postponed (returned into the pool). We\nmainly focus on minimizing the expected number of postponements when computing\nan optimal solution. An expected number of $\\Theta(n \\log n)$ is always\nsufficient. For matroids, we show that the expected number can be reduced to\n$O(r \\log (n/r))$, where $r \\le n/2$ is the minimum of the ranks of matroid and\ndual matroid. For bipartite matching, we show a bound of $O(r \\log n)$, where\n$r$ is the size of the optimum matching. For general packing, we show a lower\nbound of $\\Omega(n \\log \\log n)$, even when the size of the optimum is $r =\n\\Theta(\\log n)$. \n\n"}
{"id": "1810.11514", "contents": "Title: Learning and Interpreting Multi-Multi-Instance Learning Networks Abstract: We introduce an extension of the multi-instance learning problem where\nexamples are organized as nested bags of instances (e.g., a document could be\nrepresented as a bag of sentences, which in turn are bags of words). This\nframework can be useful in various scenarios, such as text and image\nclassification, but also supervised learning over graphs. As a further\nadvantage, multi-multi instance learning enables a particular way of\ninterpreting predictions and the decision function. Our approach is based on a\nspecial neural network layer, called bag-layer, whose units aggregate bags of\ninputs of arbitrary size. We prove theoretically that the associated class of\nfunctions contains all Boolean functions over sets of sets of instances and we\nprovide empirical evidence that functions of this kind can be actually learned\non semi-synthetic datasets. We finally present experiments on text\nclassification, on citation graphs, and social graph data, which show that our\nmodel obtains competitive results with respect to accuracy when compared to\nother approaches such as convolutional networks on graphs, while at the same\ntime it supports a general approach to interpret the learnt model, as well as\nexplain individual predictions. \n\n"}
{"id": "1810.11650", "contents": "Title: On the Equivalence of Convolutional and Hadamard Networks using DFT Abstract: In this paper we introduce activation functions that move the entire\ncomputation of Convolutional Networks into the frequency domain, where they are\nactually Hadamard Networks. To achieve this result we employ the properties of\nDiscrete Fourier Transform. We present some implementation details and\nexperimental results, as well as some insights into why convolutional networks\nperform well in learning use cases. \n\n"}
{"id": "1810.11677", "contents": "Title: The Variational Deficiency Bottleneck Abstract: We introduce a bottleneck method for learning data representations based on\ninformation deficiency, rather than the more traditional information\nsufficiency. A variational upper bound allows us to implement this method\nefficiently. The bound itself is bounded above by the variational information\nbottleneck objective, and the two methods coincide in the regime of single-shot\nMonte Carlo approximations. The notion of deficiency provides a principled way\nof approximating complicated channels by relatively simpler ones. We show that\nthe deficiency of one channel with respect to another has an operational\ninterpretation in terms of the optimal risk gap of decision problems, capturing\nclassification as a special case. Experiments demonstrate that the deficiency\nbottleneck can provide advantages in terms of minimal sufficiency as measured\nby information bottleneck curves, while retaining robust test performance in\nclassification tasks. \n\n"}
{"id": "1810.11959", "contents": "Title: An Amalgamation of Classical and Quantum Machine Learning For the\n  Classification of Adenocarcinoma and Squamous Cell Carcinoma Patients Abstract: The ability to accurately classify disease subtypes is of vital importance,\nespecially in oncology where this capability could have a life saving impact.\nHere we report a classification between two subtypes of non-small cell lung\ncancer, namely Adeno- carcinoma vs Squamous cell carcinoma. The data consists\nof approximately 20,000 gene expression values for each of 104 patients. The\ndata was curated from [1] [2]. We used an amalgamation of classical and and\nquantum machine learning models to successfully classify these patients. We\nutilized feature selection methods based on univariate statistics in addition\nto XGBoost [3]. A novel and proprietary data representation method developed by\none of the authors called QCrush was also used as it was designed to\nincorporate a maximal amount of information under the size constraints of the\nD-Wave quantum annealing computer. The machine learning was performed by a\nQuantum Boltzmann Machine. This paper will report our results, the various\nclassical methods, and the quantum machine learning approach we utilized. \n\n"}
{"id": "1810.12582", "contents": "Title: DSKG: A Deep Sequential Model for Knowledge Graph Completion Abstract: Knowledge graph (KG) completion aims to fill the missing facts in a KG, where\na fact is represented as a triple in the form of $(subject, relation, object)$.\nCurrent KG completion models compel two-thirds of a triple provided (e.g.,\n$subject$ and $relation$) to predict the remaining one. In this paper, we\npropose a new model, which uses a KG-specific multi-layer recurrent neural\nnetwork (RNN) to model triples in a KG as sequences. It outperformed several\nstate-of-the-art KG completion models on the conventional entity prediction\ntask for many evaluation metrics, based on two benchmark datasets and a more\ndifficult dataset. Furthermore, our model is enabled by the sequential\ncharacteristic and thus capable of predicting the whole triples only given one\nentity. Our experiments demonstrated that our model achieved promising\nperformance on this new triple prediction task. \n\n"}
{"id": "1810.13069", "contents": "Title: Dynamic Assortment Optimization with Changing Contextual Information Abstract: In this paper, we study the dynamic assortment optimization problem under a\nfinite selling season of length $T$. At each time period, the seller offers an\narriving customer an assortment of substitutable products under a cardinality\nconstraint, and the customer makes the purchase among offered products\naccording to a discrete choice model. Most existing work associates each\nproduct with a real-valued fixed mean utility and assumes a multinomial logit\nchoice (MNL) model. In many practical applications, feature/contexutal\ninformation of products is readily available. In this paper, we incorporate the\nfeature information by assuming a linear relationship between the mean utility\nand the feature. In addition, we allow the feature information of products to\nchange over time so that the underlying choice model can also be\nnon-stationary. To solve the dynamic assortment optimization under this\nchanging contextual MNL model, we need to simultaneously learn the underlying\nunknown coefficient and makes the decision on the assortment. To this end, we\ndevelop an upper confidence bound (UCB) based policy and establish the regret\nbound on the order of $\\widetilde O(d\\sqrt{T})$, where $d$ is the dimension of\nthe feature and $\\widetilde O$ suppresses logarithmic dependence. We further\nestablished the lower bound $\\Omega(d\\sqrt{T}/K)$ where $K$ is the cardinality\nconstraint of an offered assortment, which is usually small. When $K$ is a\nconstant, our policy is optimal up to logarithmic factors. In the exploitation\nphase of the UCB algorithm, we need to solve a combinatorial optimization for\nassortment optimization based on the learned information. We further develop an\napproximation algorithm and an efficient greedy heuristic. The effectiveness of\nthe proposed policy is further demonstrated by our numerical studies. \n\n"}
{"id": "1810.13084", "contents": "Title: Provably Accelerated Randomized Gossip Algorithms Abstract: In this work we present novel provably accelerated gossip algorithms for\nsolving the average consensus problem. The proposed protocols are inspired from\nthe recently developed accelerated variants of the randomized Kaczmarz method -\na popular method for solving linear systems. In each gossip iteration all nodes\nof the network update their values but only a pair of them exchange their\nprivate information. Numerical experiments on popular wireless sensor networks\nshowing the benefits of our protocols are also presented. \n\n"}
{"id": "1811.00112", "contents": "Title: Generating Photo-Realistic Training Data to Improve Face Recognition\n  Accuracy Abstract: In this paper we investigate the feasibility of using synthetic data to\naugment face datasets. In particular, we propose a novel generative adversarial\nnetwork (GAN) that can disentangle identity-related attributes from\nnon-identity-related attributes. This is done by training an embedding network\nthat maps discrete identity labels to an identity latent space that follows a\nsimple prior distribution, and training a GAN conditioned on samples from that\ndistribution. Our proposed GAN allows us to augment face datasets by generating\nboth synthetic images of subjects in the training set and synthetic images of\nnew subjects not in the training set. By using recent advances in GAN training,\nwe show that the synthetic images generated by our model are photo-realistic,\nand that training with augmented datasets can indeed increase the accuracy of\nface recognition models as compared with models trained with real images alone. \n\n"}
{"id": "1811.00152", "contents": "Title: Mixture Density Generative Adversarial Networks Abstract: Generative Adversarial Networks have surprising ability for generating sharp\nand realistic images, though they are known to suffer from the so-called mode\ncollapse problem. In this paper, we propose a new GAN variant called Mixture\nDensity GAN that while being capable of generating high-quality images,\novercomes this problem by encouraging the Discriminator to form clusters in its\nembedding space, which in turn leads the Generator to exploit these and\ndiscover different modes in the data. This is achieved by positioning Gaussian\ndensity functions in the corners of a simplex, using the resulting Gaussian\nmixture as a likelihood function over discriminator embeddings, and formulating\nan objective function for GAN training that is based on these likelihoods. We\ndemonstrate empirically (1) the quality of the generated images in Mixture\nDensity GAN and their strong similarity to real images, as measured by the\nFr\\'echet Inception Distance (FID), which compares very favourably with\nstate-of-the-art methods, and (2) the ability to avoid mode collapse and\ndiscover all data modes. \n\n"}
{"id": "1811.00164", "contents": "Title: Deep Counterfactual Regret Minimization Abstract: Counterfactual Regret Minimization (CFR) is the leading framework for solving\nlarge imperfect-information games. It converges to an equilibrium by\niteratively traversing the game tree. In order to deal with extremely large\ngames, abstraction is typically applied before running CFR. The abstracted game\nis solved with tabular CFR, and its solution is mapped back to the full game.\nThis process can be problematic because aspects of abstraction are often manual\nand domain specific, abstraction algorithms may miss important strategic\nnuances of the game, and there is a chicken-and-egg problem because determining\na good abstraction requires knowledge of the equilibrium of the game. This\npaper introduces Deep Counterfactual Regret Minimization, a form of CFR that\nobviates the need for abstraction by instead using deep neural networks to\napproximate the behavior of CFR in the full game. We show that Deep CFR is\nprincipled and achieves strong performance in large poker games. This is the\nfirst non-tabular variant of CFR to be successful in large games. \n\n"}
{"id": "1811.00183", "contents": "Title: Designing an Effective Metric Learning Pipeline for Speaker Diarization Abstract: State-of-the-art speaker diarization systems utilize knowledge from external\ndata, in the form of a pre-trained distance metric, to effectively determine\nrelative speaker identities to unseen data. However, much of recent focus has\nbeen on choosing the appropriate feature extractor, ranging from pre-trained\n$i-$vectors to representations learned via different sequence modeling\narchitectures (e.g. 1D-CNNs, LSTMs, attention models), while adopting\noff-the-shelf metric learning solutions. In this paper, we argue that,\nregardless of the feature extractor, it is crucial to carefully design a metric\nlearning pipeline, namely the loss function, the sampling strategy and the\ndiscrimnative margin parameter, for building robust diarization systems.\nFurthermore, we propose to adopt a fine-grained validation process to obtain a\ncomprehensive evaluation of the generalization power of metric learning\npipelines. To this end, we measure diarization performance across different\nlanguage speakers, and variations in the number of speakers in a recording.\nUsing empirical studies, we provide interesting insights into the effectiveness\nof different design choices and make recommendations. \n\n"}
{"id": "1811.00648", "contents": "Title: Prediction Error Meta Classification in Semantic Segmentation: Detection\n  via Aggregated Dispersion Measures of Softmax Probabilities Abstract: We present a method that \"meta\" classifies whether seg-ments predicted by a\nsemantic segmentation neural networkintersect with the ground truth. For this\npurpose, we employ measures of dispersion for predicted pixel-wise class\nprobability distributions, like classification entropy, that yield heat maps of\nthe input scene's size. We aggregate these dispersion measures segment-wise and\nderive metrics that are well-correlated with the segment-wise IoU of prediction\nand ground truth. This procedure yields an almost plug and play post-processing\ntool to rate the prediction quality of semantic segmentation networks on\nsegment level. This is especially relevant for monitoring neural networks in\nonline applications like automated driving or medical imaging where reliability\nis of utmost importance. In our tests, we use publicly available\nstate-of-the-art networks trained on the Cityscapes dataset and the BraTS2017\ndataset and analyze the predictive power of different metrics as well as\ndifferent sets of metrics. To this end, we compute logistic LASSO regression\nfits for the task of classifying IoU=0 vs. IoU>0 per segment and obtain AUROC\nvalues of up to 91.55%. We complement these tests with linear regression fits\nto predict the segment-wise IoU and obtain prediction standard deviations of\ndown to 0.130 as well as $R^2$ values of up to 84.15%. We show that these\nresults clearly outperform standard approaches. \n\n"}
{"id": "1811.00741", "contents": "Title: Stronger Data Poisoning Attacks Break Data Sanitization Defenses Abstract: Machine learning models trained on data from the outside world can be\ncorrupted by data poisoning attacks that inject malicious points into the\nmodels' training sets. A common defense against these attacks is data\nsanitization: first filter out anomalous training points before training the\nmodel. In this paper, we develop three attacks that can bypass a broad range of\ncommon data sanitization defenses, including anomaly detectors based on nearest\nneighbors, training loss, and singular-value decomposition. By adding just 3%\npoisoned data, our attacks successfully increase test error on the Enron spam\ndetection dataset from 3% to 24% and on the IMDB sentiment classification\ndataset from 12% to 29%. In contrast, existing attacks which do not explicitly\naccount for these data sanitization defenses are defeated by them. Our attacks\nare based on two ideas: (i) we coordinate our attacks to place poisoned points\nnear one another, and (ii) we formulate each attack as a constrained\noptimization problem, with constraints designed to ensure that the poisoned\npoints evade detection. As this optimization involves solving an expensive\nbilevel problem, our three attacks correspond to different ways of\napproximating this problem, based on influence functions; minimax duality; and\nthe Karush-Kuhn-Tucker (KKT) conditions. Our results underscore the need to\ndevelop more robust defenses against data poisoning attacks. \n\n"}
{"id": "1811.01182", "contents": "Title: Stochastic Primal-Dual Method for Empirical Risk Minimization with\n  $\\mathcal{O}(1)$ Per-Iteration Complexity Abstract: Regularized empirical risk minimization problem with linear predictor appears\nfrequently in machine learning. In this paper, we propose a new stochastic\nprimal-dual method to solve this class of problems. Different from existing\nmethods, our proposed methods only require O(1) operations in each iteration.\nWe also develop a variance-reduction variant of the algorithm that converges\nlinearly. Numerical experiments suggest that our methods are faster than\nexisting ones such as proximal SGD, SVRG and SAGA on high-dimensional problems. \n\n"}
{"id": "1811.01305", "contents": "Title: Block-wise Partitioning for Extreme Multi-label Classification Abstract: Extreme multi-label classification aims to learn a classifier that annotates\nan instance with a relevant subset of labels from an extremely large label set.\nMany existing solutions embed the label matrix to a low-dimensional linear\nsubspace, or examine the relevance of a test instance to every label via a\nlinear scan. In practice, however, those approaches can be computationally\nexorbitant. To alleviate this drawback, we propose a Block-wise Partitioning\n(BP) pretreatment that divides all instances into disjoint clusters, to each of\nwhich the most frequently tagged label subset is attached. One multi-label\nclassifier is trained on one pair of instance and label clusters, and the label\nset of a test instance is predicted by first delivering it to the most\nappropriate instance cluster. Experiments on benchmark multi-label data sets\nreveal that BP pretreatment significantly reduces prediction time, and retains\nalmost the same level of prediction accuracy. \n\n"}
{"id": "1811.01747", "contents": "Title: The Knowref Coreference Corpus: Removing Gender and Number Cues for\n  Difficult Pronominal Anaphora Resolution Abstract: We introduce a new benchmark for coreference resolution and NLI, Knowref,\nthat targets common-sense understanding and world knowledge. Previous\ncoreference resolution tasks can largely be solved by exploiting the number and\ngender of the antecedents, or have been handcrafted and do not reflect the\ndiversity of naturally occurring text. We present a corpus of over 8,000\nannotated text passages with ambiguous pronominal anaphora. These instances are\nboth challenging and realistic. We show that various coreference systems,\nwhether rule-based, feature-rich, or neural, perform significantly worse on the\ntask than humans, who display high inter-annotator agreement. To explain this\nperformance gap, we show empirically that state-of-the art models often fail to\ncapture context, instead relying on the gender or number of candidate\nantecedents to make a decision. We then use problem-specific insights to\npropose a data-augmentation trick called antecedent switching to alleviate this\ntendency in models. Finally, we show that antecedent switching yields promising\nresults on other tasks as well: we use it to achieve state-of-the-art results\non the GAP coreference task. \n\n"}
{"id": "1811.02091", "contents": "Title: Simple, Distributed, and Accelerated Probabilistic Programming Abstract: We describe a simple, low-level approach for embedding probabilistic\nprogramming in a deep learning ecosystem. In particular, we distill\nprobabilistic programming down to a single abstraction---the random variable.\nOur lightweight implementation in TensorFlow enables numerous applications: a\nmodel-parallel variational auto-encoder (VAE) with 2nd-generation tensor\nprocessing units (TPUv2s); a data-parallel autoregressive model (Image\nTransformer) with TPUv2s; and multi-GPU No-U-Turn Sampler (NUTS). For both a\nstate-of-the-art VAE on 64x64 ImageNet and Image Transformer on 256x256\nCelebA-HQ, our approach achieves an optimal linear speedup from 1 to 256 TPUv2\nchips. With NUTS, we see a 100x speedup on GPUs over Stan and 37x over PyMC3. \n\n"}
{"id": "1811.02319", "contents": "Title: Fast Hyperparameter Optimization of Deep Neural Networks via Ensembling\n  Multiple Surrogates Abstract: The performance of deep neural networks crucially depends on good\nhyperparameter configurations. Bayesian optimization is a powerful framework\nfor optimizing the hyperparameters of DNNs. These methods need sufficient\nevaluation data to approximate and minimize the validation error function of\nhyperparameters. However, the expensive evaluation cost of DNNs leads to very\nfew evaluation data within a limited time, which greatly reduces the efficiency\nof Bayesian optimization. Besides, the previous researches focus on using the\ncomplete evaluation data to conduct Bayesian optimization, and ignore the\nintermediate evaluation data generated by early stopping methods. To alleviate\nthe insufficient evaluation data problem, we propose a fast hyperparameter\noptimization method, HOIST, that utilizes both the complete and intermediate\nevaluation data to accelerate the hyperparameter optimization of DNNs.\nSpecifically, we train multiple basic surrogates to gather information from the\nmixed evaluation data, and then combine all basic surrogates using weighted\nbagging to provide an accurate ensemble surrogate. Our empirical studies show\nthat HOIST outperforms the state-of-the-art approaches on a wide range of DNNs,\nincluding feed forward neural networks, convolutional neural networks,\nrecurrent neural networks, and variational autoencoder. \n\n"}
{"id": "1811.02361", "contents": "Title: Kalman Filter Modifier for Neural Networks in Non-stationary\n  Environments Abstract: Learning in a non-stationary environment is an inevitable problem when\napplying machine learning algorithm to real world environment. Learning new\ntasks without forgetting the previous knowledge is a challenge issue in machine\nlearning. We propose a Kalman Filter based modifier to maintain the performance\nof Neural Network models under non-stationary environments. The result shows\nthat our proposed model can preserve the key information and adapts better to\nthe changes. The accuracy of proposed model decreases by 0.4% in our\nexperiments, while the accuracy of conventional model decreases by 90% in the\ndrifts environment. \n\n"}
{"id": "1811.02564", "contents": "Title: On exponential convergence of SGD in non-convex over-parametrized\n  learning Abstract: Large over-parametrized models learned via stochastic gradient descent (SGD)\nmethods have become a key element in modern machine learning. Although SGD\nmethods are very effective in practice, most theoretical analyses of SGD\nsuggest slower convergence than what is empirically observed. In our recent\nwork [8] we analyzed how interpolation, common in modern over-parametrized\nlearning, results in exponential convergence of SGD with constant step size for\nconvex loss functions. In this note, we extend those results to a much broader\nnon-convex function class satisfying the Polyak-Lojasiewicz (PL) condition. A\nnumber of important non-convex problems in machine learning, including some\nclasses of neural networks, have been recently shown to satisfy the PL\ncondition. We argue that the PL condition provides a relevant and attractive\nsetting for many machine learning problems, particularly in the\nover-parametrized regime. \n\n"}
{"id": "1811.02628", "contents": "Title: Learning Bone Suppression from Dual Energy Chest X-rays using\n  Adversarial Networks Abstract: Suppressing bones on chest X-rays such as ribs and clavicle is often expected\nto improve pathologies classification. These bones can interfere with a broad\nrange of diagnostic tasks on pulmonary disease except for musculoskeletal\nsystem. Current conventional method for acquisition of bone suppressed X-rays\nis dual energy imaging, which captures two radiographs at a very short interval\nwith different energy levels; however, the patient is exposed to radiation\ntwice and the artifacts arise due to heartbeats between two shots. In this\npaper, we introduce a deep generative model trained to predict bone suppressed\nimages on single energy chest X-rays, analyzing a finite set of previously\nacquired dual energy chest X-rays. Since the relatively small amount of data is\navailable, such approach relies on the methodology maximizing the data\nutilization. Here we integrate the following two approaches. First, we use a\nconditional generative adversarial network that complements the traditional\nregression method minimizing the pairwise image difference. Second, we use Haar\n2D wavelet decomposition to offer a perceptual guideline in frequency details\nto allow the model to converge quickly and efficiently. As a result, we achieve\nstate-of-the-art performance on bone suppression as compared to the existing\napproaches with dual energy chest X-rays. \n\n"}
{"id": "1811.02642", "contents": "Title: Computational Histological Staining and Destaining of Prostate Core\n  Biopsy RGB Images with Generative Adversarial Neural Networks Abstract: Histopathology tissue samples are widely available in two states:\nparaffin-embedded unstained and non-paraffin-embedded stained whole slide RGB\nimages (WSRI). Hematoxylin and eosin stain (H&E) is one of the principal stains\nin histology but suffers from several shortcomings related to tissue\npreparation, staining protocols, slowness and human error. We report two novel\napproaches for training machine learning models for the computational H&E\nstaining and destaining of prostate core biopsy RGB images. The staining model\nuses a conditional generative adversarial network that learns hierarchical\nnon-linear mappings between whole slide RGB image (WSRI) pairs of prostate core\nbiopsy before and after H&E staining. The trained staining model can then\ngenerate computationally H&E-stained prostate core WSRIs using previously\nunseen non-stained biopsy images as input. The destaining model, by learning\nmappings between an H&E stained WSRI and a non-stained WSRI of the same biopsy,\ncan computationally destain previously unseen H&E-stained images. Structural\nand anatomical details of prostate tissue and colors, shapes, geometries,\nlocations of nuclei, stroma, vessels, glands and other cellular components were\ngenerated by both models with structural similarity indices of 0.68 (staining)\nand 0.84 (destaining). The proposed staining and destaining models can engender\ncomputational H&E staining and destaining of WSRI biopsies without additional\nequipment and devices. \n\n"}
{"id": "1811.02654", "contents": "Title: A Volumetric Convolutional Neural Network for Brain Tumor Segmentation Abstract: Brain cancer can be very fatal, but chances of survival increase through\nearly detection and treatment. Doctors use Magnetic Resonance Imaging (MRI) to\ndetect and locate tumors in the brain, and very carefully analyze scans to\nsegment brain tumors. Manual segmentation is time consuming and tiring for\ndoctors, and it can be difficult for them to notice extremely small\nabnormalities. Automated segmentations performed by computers offer quicker\ndiagnoses, the ability to notice small details, and more accurate\nsegmentations. Advances in deep learning and computer hardware have allowed for\nhigh-performing automated segmentation approaches. However, several problems\npersist in practice: increased training time, class imbalance, and low\nperformance. In this paper, I propose applying V-Net, a volumetric, fully\nconvolutional neural network, to segment brain tumors in MRI scans from the\nBraTS Challenges. With this approach, I achieve a whole tumor dice score of\n0.89 and train the network in a short time while addressing class imbalance\nwith the use of a dice loss layer. Then, I propose applying an existing\ntechnique to improve automated segmentation performance in practice. \n\n"}
{"id": "1811.02798", "contents": "Title: Multi-Task Graph Autoencoders Abstract: We examine two fundamental tasks associated with graph representation\nlearning: link prediction and node classification. We present a new autoencoder\narchitecture capable of learning a joint representation of local graph\nstructure and available node features for the simultaneous multi-task learning\nof unsupervised link prediction and semi-supervised node classification. Our\nsimple, yet effective and versatile model is efficiently trained end-to-end in\na single stage, whereas previous related deep graph embedding methods require\nmultiple training steps that are difficult to optimize. We provide an empirical\nevaluation of our model on five benchmark relational, graph-structured datasets\nand demonstrate significant improvement over three strong baselines for graph\nrepresentation learning. Reference code and data are available at\nhttps://github.com/vuptran/graph-representation-learning \n\n"}
{"id": "1811.02834", "contents": "Title: Fused Gromov-Wasserstein distance for structured objects: theoretical\n  foundations and mathematical properties Abstract: Optimal transport theory has recently found many applications in machine\nlearning thanks to its capacity for comparing various machine learning objects\nconsidered as distributions. The Kantorovitch formulation, leading to the\nWasserstein distance, focuses on the features of the elements of the objects\nbut treat them independently, whereas the Gromov-Wasserstein distance focuses\nonly on the relations between the elements, depicting the structure of the\nobject, yet discarding its features.\n  In this paper we propose to extend these distances in order to encode\nsimultaneously both the feature and structure informations, resulting in the\nFused Gromov-Wasserstein distance. We develop the mathematical framework for\nthis novel distance, prove its metric and interpolation properties and provide\na concentration result for the convergence of finite samples. We also\nillustrate and interpret its use in various contexts where structured objects\nare involved. \n\n"}
{"id": "1811.02934", "contents": "Title: Model Inconsistent but Correlated Noise: Multi-view Subspace Learning\n  with Regularized Mixture of Gaussians Abstract: Multi-view subspace learning (MSL) aims to find a low-dimensional subspace of\nthe data obtained from multiple views. Different from single view case, MSL\nshould take both common and specific knowledge among different views into\nconsideration. To enhance the robustness of model, the complexity,\nnon-consistency and similarity of noise in multi-view data should be fully\ntaken into consideration. Most current MSL methods only assume a simple\nGaussian or Laplacian distribution for the noise while neglect the complex\nnoise configurations in each view and noise correlations among different views\nof practical data. To this issue, this work initiates a MSL method by encoding\nthe multi-view-shared and single-view-specific noise knowledge in data.\nSpecifically, we model data noise in each view as a separated Mixture of\nGaussians (MoG), which can fit a wider range of complex noise types than\nconventional Gaussian/Laplacian. Furthermore, we link all single-view-noise as\na whole by regularizing them by a common MoG component, encoding the shared\nnoise knowledge among them. Such regularization component can be formulated as\na concise KL-divergence regularization term under a MAP framework, leading to\ngood interpretation of our model and simple EM-based solving strategy to the\nproblem. Experimental results substantiate the superiority of our method. \n\n"}
{"id": "1811.03066", "contents": "Title: Prototypical Clustering Networks for Dermatological Disease Diagnosis Abstract: We consider the problem of image classification for the purpose of aiding\ndoctors in dermatological diagnosis. Dermatological diagnosis poses two major\nchallenges for standard off-the-shelf techniques: First, the data distribution\nis typically extremely long tailed. Second, intra-class variability is often\nlarge. To address the first issue, we formulate the problem as low-shot\nlearning, where once deployed, a base classifier must rapidly generalize to\ndiagnose novel conditions given very few labeled examples. To model diverse\nclasses effectively, we propose Prototypical Clustering Networks (PCN), an\nextension to Prototypical Networks that learns a mixture of prototypes for each\nclass. Prototypes are initialized for each class via clustering and refined via\nan online update scheme. Classification is performed by measuring similarity to\na weighted combination of prototypes within a class, where the weights are the\ninferred cluster responsibilities. We demonstrate the strengths of our approach\nin effective diagnosis on a realistic dataset of dermatological conditions. \n\n"}
{"id": "1811.03129", "contents": "Title: Global Optimality in Distributed Low-rank Matrix Factorization Abstract: We study the convergence of a variant of distributed gradient descent (DGD)\non a distributed low-rank matrix approximation problem wherein some\noptimization variables are used for consensus (as in classical DGD) and some\noptimization variables appear only locally at a single node in the network. We\nterm the resulting algorithm DGD+LOCAL. Using algorithmic connections to\ngradient descent and geometric connections to the well-behaved landscape of the\ncentralized low-rank matrix approximation problem, we identify sufficient\nconditions where DGD+LOCAL is guaranteed to converge with exact consensus to a\nglobal minimizer of the original centralized problem. For the distributed\nlow-rank matrix approximation problem, these guarantees are stronger---in terms\nof consensus and optimality---than what appear in the literature for classical\nDGD and more general problems. \n\n"}
{"id": "1811.03422", "contents": "Title: Explaining Deep Learning Models - A Bayesian Non-parametric Approach Abstract: Understanding and interpreting how machine learning (ML) models make\ndecisions have been a big challenge. While recent research has proposed various\ntechnical approaches to provide some clues as to how an ML model makes\nindividual predictions, they cannot provide users with an ability to inspect a\nmodel as a complete entity. In this work, we propose a novel technical approach\nthat augments a Bayesian non-parametric regression mixture model with multiple\nelastic nets. Using the enhanced mixture model, we can extract generalizable\ninsights for a target model through a global approximation. To demonstrate the\nutility of our approach, we evaluate it on different ML models in the context\nof image recognition. The empirical results indicate that our proposed approach\nnot only outperforms the state-of-the-art techniques in explaining individual\ndecisions but also provides users with an ability to discover the\nvulnerabilities of the target ML models. \n\n"}
{"id": "1811.03516", "contents": "Title: Learning from Demonstration in the Wild Abstract: Learning from demonstration (LfD) is useful in settings where hand-coding\nbehaviour or a reward function is impractical. It has succeeded in a wide range\nof problems but typically relies on manually generated demonstrations or\nspecially deployed sensors and has not generally been able to leverage the\ncopious demonstrations available in the wild: those that capture behaviours\nthat were occurring anyway using sensors that were already deployed for another\npurpose, e.g., traffic camera footage capturing demonstrations of natural\nbehaviour of vehicles, cyclists, and pedestrians. We propose Video to Behaviour\n(ViBe), a new approach to learn models of behaviour from unlabelled raw video\ndata of a traffic scene collected from a single, monocular, initially\nuncalibrated camera with ordinary resolution. Our approach calibrates the\ncamera, detects relevant objects, tracks them through time, and uses the\nresulting trajectories to perform LfD, yielding models of naturalistic\nbehaviour. We apply ViBe to raw videos of a traffic intersection and show that\nit can learn purely from videos, without additional expert knowledge. \n\n"}
{"id": "1811.04194", "contents": "Title: R-SPIDER: A Fast Riemannian Stochastic Optimization Algorithm with\n  Curvature Independent Rate Abstract: We study smooth stochastic optimization problems on Riemannian manifolds. Via\nadapting the recently proposed SPIDER algorithm \\citep{fang2018spider} (a\nvariance reduced stochastic method) to Riemannian manifold, we can achieve\nfaster rate than known algorithms in both the finite sum and stochastic\nsettings. Unlike previous works, by \\emph{not} resorting to bounding iterate\ndistances, our analysis yields curvature independent convergence rates for both\nthe nonconvex and strongly convex cases. \n\n"}
{"id": "1811.04393", "contents": "Title: Gaussian-Induced Convolution for Graphs Abstract: Learning representation on graph plays a crucial role in numerous tasks of\npattern recognition. Different from grid-shaped images/videos, on which local\nconvolution kernels can be lattices, however, graphs are fully coordinate-free\non vertices and edges. In this work, we propose a Gaussian-induced convolution\n(GIC) framework to conduct local convolution filtering on irregular graphs.\nSpecifically, an edge-induced Gaussian mixture model is designed to encode\nvariations of subgraph region by integrating edge information into weighted\nGaussian models, each of which implicitly characterizes one component of\nsubgraph variations. In order to coarsen a graph, we derive a vertex-induced\nGaussian mixture model to cluster vertices dynamically according to the\nconnection of edges, which is approximately equivalent to the weighted graph\ncut. We conduct our multi-layer graph convolution network on several public\ndatasets of graph classification. The extensive experiments demonstrate that\nour GIC is effective and can achieve the state-of-the-art results. \n\n"}
{"id": "1811.05975", "contents": "Title: Machine Learning Analysis of Heterogeneity in the Effect of Student\n  Mindset Interventions Abstract: We study heterogeneity in the effect of a mindset intervention on\nstudent-level performance through an observational dataset from the National\nStudy of Learning Mindsets (NSLM). Our analysis uses machine learning (ML) to\naddress the following associated problems: assessing treatment group overlap\nand covariate balance, imputing conditional average treatment effects, and\ninterpreting imputed effects. By comparing several different model families we\nillustrate the flexibility of both off-the-shelf and purpose-built estimators.\nWe find that the mindset intervention has a positive average effect of 0.26,\n95%-CI [0.22, 0.30], and that heterogeneity in the range of [0.1, 0.4] is\nmoderated by school-level achievement level, poverty concentration, urbanicity,\nand student prior expectations. \n\n"}
{"id": "1811.06126", "contents": "Title: Cooperation Enforcement and Collusion Resistance in Repeated Public\n  Goods Games Abstract: Enforcing cooperation among substantial agents is one of the main objectives\nfor multi-agent systems. However, due to the existence of inherent social\ndilemmas in many scenarios, the free-rider problem may arise during agents'\nlong-run interactions and things become even severer when self-interested\nagents work in collusion with each other to get extra benefits. It is commonly\naccepted that in such social dilemmas, there exists no simple strategy for an\nagent whereby she can simultaneously manipulate on the utility of each of her\nopponents and further promote mutual cooperation among all agents. Here, we\nshow that such strategies do exist. Under the conventional repeated public\ngoods game, we novelly identify them and find that, when confronted with such\nstrategies, a single opponent can maximize his utility only via global\ncooperation and any colluding alliance cannot get the upper hand. Since a full\ncooperation is individually optimal for any single opponent, a stable\ncooperation among all players can be achieved. Moreover, we experimentally show\nthat these strategies can still promote cooperation even when the opponents are\nboth self-learning and collusive. \n\n"}
{"id": "1811.06225", "contents": "Title: Reward-estimation variance elimination in sequential decision processes Abstract: Policy gradient methods are very attractive in reinforcement learning due to\ntheir model-free nature and convergence guarantees. These methods, however,\nsuffer from high variance in gradient estimation, resulting in poor sample\nefficiency. To mitigate this issue, a number of variance-reduction approaches\nhave been proposed. Unfortunately, in the challenging problems with delayed\nrewards, these approaches either bring a relatively modest improvement or do\nreduce variance at expense of introducing a bias and undermining convergence.\nThe unbiased methods of gradient estimation, in general, only partially reduce\nvariance, without eliminating it completely even in the limit of exact\nknowledge of the value functions and problem dynamics, as one might have\nwished. In this work we propose an unbiased method that does completely\neliminate variance under some, commonly encountered, conditions. Of practical\ninterest is the limit of deterministic dynamics and small policy stochasticity.\nIn the case of a quadratic value function, as in linear quadratic Gaussian\nmodels, the policy randomness need not be small. We use such a model to analyze\nperformance of the proposed variance-elimination approach and compare it with\nstandard variance-reduction methods. The core idea behind the approach is to\nuse control variates at all future times down the trajectory. We present both a\nmodel-based and model-free formulations. \n\n"}
{"id": "1811.07006", "contents": "Title: Projected BNNs: Avoiding weight-space pathologies by learning latent\n  representations of neural network weights Abstract: As machine learning systems get widely adopted for high-stake decisions,\nquantifying uncertainty over predictions becomes crucial. While modern neural\nnetworks are making remarkable gains in terms of predictive accuracy,\ncharacterizing uncertainty over the parameters of these models is challenging\nbecause of the high dimensionality and complex correlations of the network\nparameter space. This paper introduces a novel variational inference framework\nfor Bayesian neural networks that (1) encodes complex distributions in\nhigh-dimensional parameter space with representations in a low-dimensional\nlatent space, and (2) performs inference efficiently on the low-dimensional\nrepresentations. Across a large array of synthetic and real-world datasets, we\nshow that our method improves uncertainty characterization and model\ngeneralization when compared with methods that work directly in the parameter\nspace. \n\n"}
{"id": "1811.07073", "contents": "Title: Semi-Supervised Semantic Image Segmentation with Self-correcting\n  Networks Abstract: Building a large image dataset with high-quality object masks for semantic\nsegmentation is costly and time consuming. In this paper, we introduce a\nprincipled semi-supervised framework that only uses a small set of fully\nsupervised images (having semantic segmentation labels and box labels) and a\nset of images with only object bounding box labels (we call it the weak set).\nOur framework trains the primary segmentation model with the aid of an\nancillary model that generates initial segmentation labels for the weak set and\na self-correction module that improves the generated labels during training\nusing the increasingly accurate primary model. We introduce two variants of the\nself-correction module using either linear or convolutional functions.\nExperiments on the PASCAL VOC 2012 and Cityscape datasets show that our models\ntrained with a small fully supervised set perform similar to, or better than,\nmodels trained with a large fully supervised set while requiring ~7x less\nannotation effort. \n\n"}
{"id": "1811.07131", "contents": "Title: High SNR Consistent Compressive Sensing Without Signal and Noise\n  Statistics Abstract: Recovering the support of sparse vectors in underdetermined linear regression\nmodels, \\textit{aka}, compressive sensing is important in many signal\nprocessing applications. High SNR consistency (HSC), i.e., the ability of a\nsupport recovery technique to correctly identify the support with increasing\nsignal to noise ratio (SNR) is an increasingly popular criterion to qualify the\nhigh SNR optimality of support recovery techniques. The HSC results available\nin literature for support recovery techniques applicable to underdetermined\nlinear regression models like least absolute shrinkage and selection operator\n(LASSO), orthogonal matching pursuit (OMP) etc. assume \\textit{a priori}\nknowledge of noise variance or signal sparsity. However, both these parameters\nare unavailable in most practical applications. Further, it is extremely\ndifficult to estimate noise variance or signal sparsity in underdetermined\nregression models. This limits the utility of existing HSC results. In this\narticle, we propose two techniques, \\textit{viz.}, residual ratio minimization\n(RRM) and residual ratio thresholding with adaptation (RRTA) to operate OMP\nalgorithm without the \\textit{a priroi} knowledge of noise variance and signal\nsparsity and establish their HSC analytically and numerically. To the best of\nour knowledge, these are the first and only noise statistics oblivious\nalgorithms to report HSC in underdetermined regression models. \n\n"}
{"id": "1811.07134", "contents": "Title: Deep Discriminative Learning for Unsupervised Domain Adaptation Abstract: The primary objective of domain adaptation methods is to transfer knowledge\nfrom a source domain to a target domain that has similar but different data\ndistributions. Thus, in order to correctly classify the unlabeled target domain\nsamples, the standard approach is to learn a common representation for both\nsource and target domain, thereby indirectly addressing the problem of learning\na classifier in the target domain. However, such an approach does not address\nthe task of classification in the target domain directly. In contrast, we\npropose an approach that directly addresses the problem of learning a\nclassifier in the unlabeled target domain. In particular, we train a classifier\nto correctly classify the training samples while simultaneously classifying the\nsamples in the target domain in an unsupervised manner. The corresponding model\nis referred to as Discriminative Encoding for Domain Adaptation (DEDA). We show\nthat this simple approach for performing unsupervised domain adaptation is\nindeed quite powerful. Our method achieves state of the art results in\nunsupervised adaptation tasks on various image classification benchmarks. We\nalso obtained state of the art performance on domain adaptation in Amazon\nreviews sentiment classification dataset. We perform additional experiments\nwhen the source data has less labeled examples and also on zero-shot domain\nadaptation task where no target domain samples are used for training. \n\n"}
{"id": "1811.07375", "contents": "Title: The Taboo Trap: Behavioural Detection of Adversarial Samples Abstract: Deep Neural Networks (DNNs) have become a powerful toolfor a wide range of\nproblems. Yet recent work has found an increasing variety of adversarial\nsamplesthat can fool them. Most existing detection mechanisms against\nadversarial attacksimpose significant costs, either by using additional\nclassifiers to spot adversarial samples, or by requiring the DNN to be\nrestructured. In this paper, we introduce a novel defence. We train our DNN so\nthat, as long as it is workingas intended on the kind of inputs we expect, its\nbehavior is constrained, in that some set of behaviors are taboo. If it is\nexposed to adversarial samples, they will often cause a taboo behavior, which\nwe can detect. Taboos can be both subtle and diverse, so their choice can\nencode and hide information. It is a well-established design principle that the\nsecurity of a system should not depend on the obscurity of its design, but on\nsome variable (the key) which can differ between implementations and bechanged\nas necessary. We discuss how taboos can be used to equip a classifier with just\nsuch a key, and how to tune the keying mechanism to adversaries of various\ncapabilities. We evaluate the performance of a prototype against a wide range\nof attacks and show how our simple defense can defend against cheap attacks at\nscale with zero run-time computation overhead, making it a suitable defense\nmethod for IoT devices. \n\n"}
{"id": "1811.07476", "contents": "Title: Best Arm Identification in Linked Bandits Abstract: We consider the problem of best arm identification in a variant of\nmulti-armed bandits called linked bandits. In a single interaction with linked\nbandits, multiple arms are played sequentially until one of them receives a\npositive reward. Since each interaction provides feedback about more than one\narm, the sample complexity can be much lower than in the regular bandit\nsetting. We propose an algorithm for linked bandits, that combines a novel\nsubroutine to perform uniform sampling with a known optimal algorithm for\nregular bandits. We prove almost matching upper and lower bounds on the sample\ncomplexity of best arm identification in linked bandits. These bounds have an\ninteresting structure, with an explicit dependence on the mean rewards of the\narms, not just the gaps. We also corroborate our theoretical results with\nexperiments. \n\n"}
{"id": "1811.07591", "contents": "Title: Deep Frank-Wolfe For Neural Network Optimization Abstract: Learning a deep neural network requires solving a challenging optimization\nproblem: it is a high-dimensional, non-convex and non-smooth minimization\nproblem with a large number of terms. The current practice in neural network\noptimization is to rely on the stochastic gradient descent (SGD) algorithm or\nits adaptive variants. However, SGD requires a hand-designed schedule for the\nlearning rate. In addition, its adaptive variants tend to produce solutions\nthat generalize less well on unseen data than SGD with a hand-designed\nschedule. We present an optimization method that offers empirically the best of\nboth worlds: our algorithm yields good generalization performance while\nrequiring only one hyper-parameter. Our approach is based on a composite\nproximal framework, which exploits the compositional nature of deep neural\nnetworks and can leverage powerful convex optimization algorithms by design.\nSpecifically, we employ the Frank-Wolfe (FW) algorithm for SVM, which computes\nan optimal step-size in closed-form at each time-step. We further show that the\ndescent direction is given by a simple backward pass in the network, yielding\nthe same computational cost per iteration as SGD. We present experiments on the\nCIFAR and SNLI data sets, where we demonstrate the significant superiority of\nour method over Adam, Adagrad, as well as the recently proposed BPGrad and\nAMSGrad. Furthermore, we compare our algorithm to SGD with a hand-designed\nlearning rate schedule, and show that it provides similar generalization while\nconverging faster. The code is publicly available at\nhttps://github.com/oval-group/dfw. \n\n"}
{"id": "1811.07768", "contents": "Title: Handwriting Recognition of Historical Documents with few labeled data Abstract: Historical documents present many challenges for offline handwriting\nrecognition systems, among them, the segmentation and labeling steps. Carefully\nannotated textlines are needed to train an HTR system. In some scenarios,\ntranscripts are only available at the paragraph level with no text-line\ninformation. In this work, we demonstrate how to train an HTR system with few\nlabeled data. Specifically, we train a deep convolutional recurrent neural\nnetwork (CRNN) system on only 10% of manually labeled text-line data from a\ndataset and propose an incremental training procedure that covers the rest of\nthe data. Performance is further increased by augmenting the training set with\nspecially crafted multiscale data. We also propose a model-based normalization\nscheme which considers the variability in the writing scale at the recognition\nphase. We apply this approach to the publicly available READ dataset. Our\nsystem achieved the second best result during the ICDAR2017 competition. \n\n"}
{"id": "1811.07769", "contents": "Title: Addressing the Invisible: Street Address Generation for Developing\n  Countries with Deep Learning Abstract: More than half of the world's roads lack adequate street addressing systems.\nLack of addresses is even more visible in daily lives of people in developing\ncountries. We would like to object to the assumption that having an address is\na luxury, by proposing a generative address design that maps the world in\naccordance with streets. The addressing scheme is designed considering several\ntraditional street addressing methodologies employed in the urban development\nscenarios around the world. Our algorithm applies deep learning to extract\nroads from satellite images, converts the road pixel confidences into a road\nnetwork, partitions the road network to find neighborhoods, and labels the\nregions, roads, and address units using graph- and proximity-based algorithms.\nWe present our results on a sample US city, and several developing cities,\ncompare travel times of users using current ad hoc and new complete addresses,\nand contrast our addressing solution to current industrial and open geocoding\nalternatives. \n\n"}
{"id": "1811.08039", "contents": "Title: Fenchel Lifted Networks: A Lagrange Relaxation of Neural Network\n  Training Abstract: Despite the recent successes of deep neural networks, the corresponding\ntraining problem remains highly non-convex and difficult to optimize. Classes\nof models have been proposed that introduce greater structure to the objective\nfunction at the cost of lifting the dimension of the problem. However, these\nlifted methods sometimes perform poorly compared to traditional neural\nnetworks. In this paper, we introduce a new class of lifted models, Fenchel\nlifted networks, that enjoy the same benefits as previous lifted models,\nwithout suffering a degradation in performance over classical networks. Our\nmodel represents activation functions as equivalent biconvex constraints and\nuses Lagrange Multipliers to arrive at a rigorous lower bound of the\ntraditional neural network training problem. This model is efficiently trained\nusing block-coordinate descent and is parallelizable across data points and/or\nlayers. We compare our model against standard fully connected and convolutional\nnetworks and show that we are able to match or beat their performance. \n\n"}
{"id": "1811.08308", "contents": "Title: Economics of disagreement -- financial intuition for the R\\'enyi\n  divergence Abstract: Disagreement is an essential element of science and life in general. The\nlanguage of probabilities and statistics is often used to describe\ndisagreements quantitatively. In practice, however, we want much more than\nthat. We want disagreements to be resolved. This leaves us with a substantial\nknowledge gap which is often perceived as a lack of practical intuition\nregarding probabilistic and statistical concepts.\n  Take for instance the R\\'enyi divergence which is a well-known statistical\nquantity specifically designed as a measure of disagreement between\nprobabilistic models. Despite its widespread use in science and engineering,\nthe R\\'enyi divergence remains a highly abstract axiomatically-motivated\nmeasure. Certainly, it offers no practical insight as to how disagreements can\nbe resolved.\n  Here we propose to address disagreements using the methods of financial\neconomics. In particular, we show how a large class of disagreements can be\ntransformed into investment opportunities. The expected financial performance\nof such investments quantifies the amount of disagreement in a tangible way.\nThis provides intuition for statistical concepts such as the R\\'enyi divergence\nwhich becomes connected to the financial performance of optimized investments.\nInvestment optimization takes into account individual opinions as well as\nattitudes towards risk. The result is a market-like social mechanism by which\nfunds flow naturally to support a more accurate view. Such social mechanisms\ncan help us with difficult disagreements (e.g., financial arguments concerning\nthe future climate).\n  In terms of scientific validation, we used the findings of independent\nneurophysiological experiments as well as our own research on the equity\npremium. \n\n"}
{"id": "1811.08359", "contents": "Title: Strong mixed-integer programming formulations for trained neural\n  networks Abstract: We present an ideal mixed-integer programming (MIP) formulation for a\nrectified linear unit (ReLU) appearing in a trained neural network. Our\nformulation requires a single binary variable and no additional continuous\nvariables beyond the input and output variables of the ReLU. We contrast it\nwith an ideal \"extended\" formulation with a linear number of additional\ncontinuous variables, derived through standard techniques. An apparent drawback\nof our formulation is that it requires an exponential number of inequality\nconstraints, but we provide a routine to separate the inequalities in linear\ntime. We also prove that these exponentially-many constraints are\nfacet-defining under mild conditions. Finally, we study network verification\nproblems and observe that dynamically separating from the exponential\ninequalities 1) is much more computationally efficient and scalable than the\nextended formulation, 2) decreases the solve time of a state-of-the-art MIP\nsolver by a factor of 7 on smaller instances, and 3) nearly matches the dual\nbounds of a state-of-the-art MIP solver on harder instances, after just a few\nrounds of separation and in orders of magnitude less time. \n\n"}
{"id": "1811.08723", "contents": "Title: Sequential Neural Methods for Likelihood-free Inference Abstract: Likelihood-free inference refers to inference when a likelihood function\ncannot be explicitly evaluated, which is often the case for models based on\nsimulators. Most of the literature is based on sample-based `Approximate\nBayesian Computation' methods, but recent work suggests that approaches based\non deep neural conditional density estimators can obtain state-of-the-art\nresults with fewer simulations. The neural approaches vary in how they choose\nwhich simulations to run and what they learn: an approximate posterior or a\nsurrogate likelihood. This work provides some direct controlled comparisons\nbetween these choices. \n\n"}
{"id": "1811.08990", "contents": "Title: Markov Chain Block Coordinate Descent Abstract: The method of block coordinate gradient descent (BCD) has been a powerful\nmethod for large-scale optimization. This paper considers the BCD method that\nsuccessively updates a series of blocks selected according to a Markov chain.\nThis kind of block selection is neither i.i.d. random nor cyclic. On the other\nhand, it is a natural choice for some applications in distributed optimization\nand Markov decision process, where i.i.d. random and cyclic selections are\neither infeasible or very expensive. By applying mixing-time properties of a\nMarkov chain, we prove convergence of Markov chain BCD for minimizing Lipschitz\ndifferentiable functions, which can be nonconvex. When the functions are convex\nand strongly convex, we establish both sublinear and linear convergence rates,\nrespectively. We also present a method of Markov chain inertial BCD. Finally,\nwe discuss potential applications. \n\n"}
{"id": "1811.09714", "contents": "Title: Structure-Based Networks for Drug Validation Abstract: Classifying chemicals according to putative modes of action (MOAs) is of\nparamount importance in the context of risk assessment. However, current\nmethods are only able to handle a very small proportion of the existing\nchemicals. We address this issue by proposing an integrative deep learning\narchitecture that learns a joint representation from molecular structures of\ndrugs and their effects on human cells. Our choice of architecture is motivated\nby the significant influence of a drug's chemical structure on its MOA. We\nimprove on the strong ability of a unimodal architecture (F1 score of 0.803) to\nclassify drugs by their toxic MOAs (Verhaar scheme) through adding another\nlearning stream that processes transcriptional responses of human cells\naffected by drugs. Our integrative model achieves an even higher classification\nperformance on the LINCS L1000 dataset - the error is reduced by 4.6%. We\nbelieve that our method can be used to extend the current Verhaar scheme and\nconstitute a basis for fast drug validation and risk assessment. \n\n"}
{"id": "1811.10740", "contents": "Title: Mixture of Regression Experts in fMRI Encoding Abstract: fMRI semantic category understanding using linguistic encoding models attempt\nto learn a forward mapping that relates stimuli to the corresponding brain\nactivation. Classical encoding models use linear multi-variate methods to\npredict the brain activation (all voxels) given the stimulus. However, these\nmethods essentially assume multiple regions as one large uniform region or\nseveral independent regions, ignoring connections among them. In this paper, we\npresent a mixture of experts-based model where a group of experts captures\nbrain activity patterns related to particular regions of interest (ROI) and\nalso show the discrimination across different experts. The model is trained\nword stimuli encoded as 25-dimensional feature vectors as input and the\ncorresponding brain responses as output. Given a new word (25-dimensional\nfeature vector), it predicts the entire brain activation as the linear\ncombination of multiple experts brain activations. We argue that each expert\nlearns a certain region of brain activations corresponding to its category of\nwords, which solves the problem of identifying the regions with a simple\nencoding model. We showcase that proposed mixture of experts-based model indeed\nlearns region-based experts to predict the brain activations with high spatial\naccuracy. \n\n"}
{"id": "1811.10799", "contents": "Title: What is Interpretable? Using Machine Learning to Design Interpretable\n  Decision-Support Systems Abstract: Recent efforts in Machine Learning (ML) interpretability have focused on\ncreating methods for explaining black-box ML models. However, these methods\nrely on the assumption that simple approximations, such as linear models or\ndecision-trees, are inherently human-interpretable, which has not been\nempirically tested. Additionally, past efforts have focused exclusively on\ncomprehension, neglecting to explore the trust component necessary to convince\nnon-technical experts, such as clinicians, to utilize ML models in practice. In\nthis paper, we posit that reinforcement learning (RL) can be used to learn what\nis interpretable to different users and, consequently, build their trust in ML\nmodels. To validate this idea, we first train a neural network to provide risk\nassessments for heart failure patients. We then design a RL-based clinical\ndecision-support system (DSS) around the neural network model, which can learn\nfrom its interactions with users. We conduct an experiment involving a diverse\nset of clinicians from multiple institutions in three different countries. Our\nresults demonstrate that ML experts cannot accurately predict which system\noutputs will maximize clinicians' confidence in the underlying neural network\nmodel, and suggest additional findings that have broad implications to the\nfuture of research into ML interpretability and the use of ML in medicine. \n\n"}
{"id": "1811.11989", "contents": "Title: Sample Efficient Stochastic Variance-Reduced Cubic Regularization Method Abstract: We propose a sample efficient stochastic variance-reduced cubic\nregularization (Lite-SVRC) algorithm for finding the local minimum efficiently\nin nonconvex optimization. The proposed algorithm achieves a lower sample\ncomplexity of Hessian matrix computation than existing cubic regularization\nbased methods. At the heart of our analysis is the choice of a constant batch\nsize of Hessian matrix computation at each iteration and the stochastic\nvariance reduction techniques. In detail, for a nonconvex function with $n$\ncomponent functions, Lite-SVRC converges to the local minimum within\n$\\tilde{O}(n+n^{2/3}/\\epsilon^{3/2})$ Hessian sample complexity, which is\nfaster than all existing cubic regularization based methods. Numerical\nexperiments with different nonconvex optimization problems conducted on real\ndatasets validate our theoretical results. \n\n"}
{"id": "1811.12069", "contents": "Title: Multi-Scale Distributed Representation for Deep Learning and its\n  Application to b-Jet Tagging Abstract: Recently machine learning algorithms based on deep layered artificial neural\nnetworks (DNNs) have been applied to a wide variety of high energy physics\nproblems such as jet tagging or event classification. We explore a simple but\neffective preprocessing step which transforms each real-valued observational\nquantity or input feature into a binary number with a fixed number of digits.\nEach binary digit represents the quantity or magnitude in different scales. We\nhave shown that this approach improves the performance of DNNs significantly\nfor some specific tasks without any further complication in feature\nengineering. We apply this multi-scale distributed binary representation to\ndeep learning on b-jet tagging using daughter particles' momenta and vertex\ninformation. \n\n"}
{"id": "1811.12199", "contents": "Title: A Visual Interaction Framework for Dimensionality Reduction Based Data\n  Exploration Abstract: Dimensionality reduction is a common method for analyzing and visualizing\nhigh-dimensional data. However, reasoning dynamically about the results of a\ndimensionality reduction is difficult. Dimensionality-reduction algorithms use\ncomplex optimizations to reduce the number of dimensions of a dataset, but\nthese new dimensions often lack a clear relation to the initial data\ndimensions, thus making them difficult to interpret. Here we propose a visual\ninteraction framework to improve dimensionality-reduction based exploratory\ndata analysis. We introduce two interaction techniques, forward projection and\nbackward projection, for dynamically reasoning about dimensionally reduced\ndata. We also contribute two visualization techniques, prolines and feasibility\nmaps, to facilitate the effective use of the proposed interactions. We apply\nour framework to PCA and autoencoder-based dimensionality reductions. Through\ndata-exploration examples, we demonstrate how our visual interactions can\nimprove the use of dimensionality reduction in exploratory data analysis. \n\n"}
{"id": "1811.12403", "contents": "Title: New Convergence Aspects of Stochastic Gradient Algorithms Abstract: The classical convergence analysis of SGD is carried out under the assumption\nthat the norm of the stochastic gradient is uniformly bounded. While this might\nhold for some loss functions, it is violated for cases where the objective\nfunction is strongly convex. In Bottou et al. (2018), a new analysis of\nconvergence of SGD is performed under the assumption that stochastic gradients\nare bounded with respect to the true gradient norm. We show that for stochastic\nproblems arising in machine learning such bound always holds; and we also\npropose an alternative convergence analysis of SGD with diminishing learning\nrate regime. We then move on to the asynchronous parallel setting, and prove\nconvergence of Hogwild! algorithm in the same regime in the case of diminished\nlearning rate. It is well-known that SGD converges if a sequence of learning\nrates $\\{\\eta_t\\}$ satisfies $\\sum_{t=0}^\\infty \\eta_t \\rightarrow \\infty$ and\n$\\sum_{t=0}^\\infty \\eta^2_t < \\infty$. We show the convergence of SGD for\nstrongly convex objective function without using bounded gradient assumption\nwhen $\\{\\eta_t\\}$ is a diminishing sequence and $\\sum_{t=0}^\\infty \\eta_t\n\\rightarrow \\infty$. In other words, we extend the current state-of-the-art\nclass of learning rates satisfying the convergence of SGD. \n\n"}
{"id": "1811.12583", "contents": "Title: Rethinking clinical prediction: Why machine learning must consider year\n  of care and feature aggregation Abstract: Machine learning for healthcare often trains models on de-identified datasets\nwith randomly-shifted calendar dates, ignoring the fact that data were\ngenerated under hospital operation practices that change over time. These\nchanging practices induce definitive changes in observed data which confound\nevaluations which do not account for dates and limit the generalisability of\ndate-agnostic models. In this work, we establish the magnitude of this problem\non MIMIC, a public hospital dataset, and showcase a simple solution. We augment\nMIMIC with the year in which care was provided and show that a model trained\nusing standard feature representations will significantly degrade in quality\nover time. We find a deterioration of 0.3 AUC when evaluating mortality\nprediction on data from 10 years later. We find a similar deterioration of 0.15\nAUC for length-of-stay. In contrast, we demonstrate that clinically-oriented\naggregates of raw features significantly mitigate future deterioration. Our\nsuggested aggregated representations, when retrained yearly, have prediction\nquality comparable to year-agnostic models. \n\n"}
{"id": "1812.00002", "contents": "Title: The Graph-Based Behavior-Aware Recommendation for Interactive News Abstract: Interactive news recommendation has been launched and attracted much\nattention recently. In this scenario, user's behavior evolves from single click\nbehavior to multiple behaviors including like, comment, share etc. However,\nmost of the existing methods still use single click behavior as the unique\ncriterion of judging user's preferences. Further, although heterogeneous graphs\nhave been applied in different areas, a proper way to construct a heterogeneous\ngraph for interactive news data with an appropriate learning mechanism on it is\nstill desired. To address the above concerns, we propose a graph-based\nbehavior-aware network, which simultaneously considers six different types of\nbehaviors as well as user's demand on the news diversity. We have three main\nsteps. First, we build an interaction behavior graph for multi-level and\nmulti-category data. Second, we apply DeepWalk on the behavior graph to obtain\nentity semantics, then build a graph-based convolutional neural network called\nG-CNN to learn news representations, and an attention-based LSTM to learn\nbehavior sequence representations. Third, we introduce core and coritivity\nfeatures for the behavior graph, which measure the concentration degree of\nuser's interests. These features affect the trade-off between accuracy and\ndiversity of our personalized recommendation system. Taking these features into\naccount, our system finally achieves recommending news to different users at\ntheir different levels of concentration degrees. \n\n"}
{"id": "1812.00279", "contents": "Title: Interpretable Graph Convolutional Neural Networks for Inference on Noisy\n  Knowledge Graphs Abstract: In this work, we provide a new formulation for Graph Convolutional Neural\nNetworks (GCNNs) for link prediction on graph data that addresses common\nchallenges for biomedical knowledge graphs (KGs). We introduce a regularized\nattention mechanism to GCNNs that not only improves performance on clean\ndatasets, but also favorably accommodates noise in KGs, a pervasive issue in\nreal-world applications. Further, we explore new visualization methods for\ninterpretable modelling and to illustrate how the learned representation can be\nexploited to automate dataset denoising. The results are demonstrated on a\nsynthetic dataset, the common benchmark dataset FB15k-237, and a large\nbiomedical knowledge graph derived from a combination of noisy and clean data\nsources. Using these improvements, we visualize a learned model's\nrepresentation of the disease cystic fibrosis and demonstrate how to\ninterrogate a neural network to show the potential of PPARG as a candidate\ntherapeutic target for rheumatoid arthritis. \n\n"}
{"id": "1812.00877", "contents": "Title: Automatic lesion boundary detection in dermoscopy Abstract: This manuscript addresses the problem of the automatic lesion boundary\ndetection in dermoscopy, using deep neural networks. An approach is based on\nthe adaptation of the U-net convolutional neural network with skip connections\nfor lesion boundary segmentation task. I hope this paper could serve, to some\nextent, as an experiment of using deep convolutional networks in biomedical\nsegmentation task and as a guideline of the boundary detection benchmark,\ninspiring further attempts and researches. \n\n"}
{"id": "1812.00885", "contents": "Title: AsyncQVI: Asynchronous-Parallel Q-Value Iteration for Discounted Markov\n  Decision Processes with Near-Optimal Sample Complexity Abstract: In this paper, we propose AsyncQVI, an asynchronous-parallel Q-value\niteration for discounted Markov decision processes whose transition and reward\ncan only be sampled through a generative model. Given such a problem with\n$|\\mathcal{S}|$ states, $|\\mathcal{A}|$ actions, and a discounted factor\n$\\gamma\\in(0,1)$, AsyncQVI uses memory of size $\\mathcal{O}(|\\mathcal{S}|)$ and\nreturns an $\\varepsilon$-optimal policy with probability at least $1-\\delta$\nusing\n$$\\tilde{\\mathcal{O}}\\big(\\frac{|\\mathcal{S}||\\mathcal{A}|}{(1-\\gamma)^5\\varepsilon^2}\\log(\\frac{1}{\\delta})\\big)$$\nsamples. AsyncQVI is also the first asynchronous-parallel algorithm for\ndiscounted Markov decision processes that has a sample complexity, which nearly\nmatches the theoretical lower bound. The relatively low memory footprint and\nparallel ability make AsyncQVI suitable for large-scale applications. In\nnumerical tests, we compare AsyncQVI with four sample-based value iteration\nmethods. The results show that our algorithm is highly efficient and achieves\nlinear parallel speedup. \n\n"}
{"id": "1812.00974", "contents": "Title: Online Graph-Adaptive Learning with Scalability and Privacy Abstract: Graphs are widely adopted for modeling complex systems, including financial,\nbiological, and social networks. Nodes in networks usually entail attributes,\nsuch as the age or gender of users in a social network. However, real-world\nnetworks can have very large size, and nodal attributes can be unavailable to a\nnumber of nodes, e.g., due to privacy concerns. Moreover, new nodes can emerge\nover time, which can necessitate real-time evaluation of their nodal\nattributes. In this context, the present paper deals with scalable learning of\nnodal attributes by estimating a nodal function based on noisy observations at\na subset of nodes. A multikernel-based approach is developed which is scalable\nto large-size networks. Unlike most existing methods that re-solve the function\nestimation problem over all existing nodes whenever a new node joins the\nnetwork, the novel method is capable of providing real-time evaluation of the\nfunction values on newly-joining nodes without resorting to a batch solver.\nInterestingly, the novel scheme only relies on an encrypted version of each\nnode's connectivity in order to learn the nodal attributes, which promotes\nprivacy. Experiments on both synthetic and real datasets corroborate the\neffectiveness of the proposed methods. \n\n"}
{"id": "1812.01267", "contents": "Title: A Game-Theoretic Learning Framework for Multi-Agent Intelligent Wireless\n  Networks Abstract: In this article, we introduce a game-theoretic learning framework for the\nmulti-agent wireless network. By combining learning in artificial intelligence\n(AI) with game theory, several promising properties emerge such as obtaining\nhigh payoff in the unknown and dynamic environment, coordinating the actions of\nagents and making the adversarial decisions with the existence of malicious\nusers. Unfortunately, there is no free lunch. To begin with, we discuss the\nconnections between learning in AI and game theory mainly in three levels,\ni.e., pattern recognition, prediction and decision making. Then, we discuss the\nchallenges and requirements of the combination for the intelligent wireless\nnetwork, such as constrained capabilities of agents, incomplete information\nobtained from the environment and the distributed, dynamically scalable and\nheterogeneous characteristics of wireless network. To cope with these, we\npropose a game-theoretic learning framework for the wireless network, including\nthe internal coordination (resource optimization) and external adversarial\ndecision-making (anti-jamming). Based on the framework, we introduce several\nattractive game-theoretic learning methods combining with the typical\napplications that we have proposed. What's more, we developed a real-life\ntestbed for the multi-agent anti-jamming problem based on the game-theoretic\nlearning framework. The experiment results verify the effectiveness of the\nproposed game-theoretic learning method. \n\n"}
{"id": "1812.01552", "contents": "Title: Exploration versus exploitation in reinforcement learning: a stochastic\n  control approach Abstract: We consider reinforcement learning (RL) in continuous time and study the\nproblem of achieving the best trade-off between exploration of a black box\nenvironment and exploitation of current knowledge. We propose an\nentropy-regularized reward function involving the differential entropy of the\ndistributions of actions, and motivate and devise an exploratory formulation\nfor the feature dynamics that captures repetitive learning under exploration.\nThe resulting optimization problem is a revitalization of the classical relaxed\nstochastic control. We carry out a complete analysis of the problem in the\nlinear--quadratic (LQ) setting and deduce that the optimal feedback control\ndistribution for balancing exploitation and exploration is Gaussian. This in\nturn interprets and justifies the widely adopted Gaussian exploration in RL,\nbeyond its simplicity for sampling. Moreover, the exploitation and exploration\nare captured, respectively and mutual-exclusively, by the mean and variance of\nthe Gaussian distribution. We also find that a more random environment contains\nmore learning opportunities in the sense that less exploration is needed. We\ncharacterize the cost of exploration, which, for the LQ case, is shown to be\nproportional to the entropy regularization weight and inversely proportional to\nthe discount rate. Finally, as the weight of exploration decays to zero, we\nprove the convergence of the solution of the entropy-regularized LQ problem to\nthe one of the classical LQ problem. \n\n"}
{"id": "1812.01677", "contents": "Title: A Pixel-Based Framework for Data-Driven Clothing Abstract: With the aim of creating virtual cloth deformations more similar to real\nworld clothing, we propose a new computational framework that recasts three\ndimensional cloth deformation as an RGB image in a two dimensional pattern\nspace. Then a three dimensional animation of cloth is equivalent to a sequence\nof two dimensional RGB images, which in turn are driven/choreographed via\nanimation parameters such as joint angles. This allows us to leverage popular\nCNNs to learn cloth deformations in image space. The two dimensional cloth\npixels are extended into the real world via standard body skinning techniques,\nafter which the RGB values are interpreted as texture offsets and displacement\nmaps. Notably, we illustrate that our approach does not require accurate\nunclothed body shapes or robust skinning techniques. Additionally, we discuss\nhow standard image based techniques such as image partitioning for higher\nresolution, GANs for merging partitioned image regions back together, etc., can\nreadily be incorporated into our framework. \n\n"}
{"id": "1812.01699", "contents": "Title: Assigning a Grade: Accurate Measurement of Road Quality Using Satellite\n  Imagery Abstract: Roads are critically important infrastructure to societal and economic\ndevelopment, with huge investments made by governments every year. However,\nmethods for monitoring those investments tend to be time-consuming, laborious,\nand expensive, placing them out of reach for many developing regions. In this\nwork, we develop a model for monitoring the quality of road infrastructure\nusing satellite imagery. For this task, we harness two trends: the increasing\navailability of high-resolution, often-updated satellite imagery, and the\nenormous improvement in speed and accuracy of convolutional neural\nnetwork-based methods for performing computer vision tasks. We employ a unique\ndataset of road quality information on 7000km of roads in Kenya combined with\n50cm resolution satellite imagery. We create models for a binary classification\ntask as well as a comprehensive 5-category classification task, with accuracy\nscores of 88 and 73 percent respectively. We also provide evidence of the\nrobustness of our methods with challenging held-out scenarios, though we note\nsome improvement is still required for confident analysis of a never before\nseen road. We believe these results are well-positioned to have substantial\nimpact on a broad set of transport applications. \n\n"}
{"id": "1812.01710", "contents": "Title: GANtruth - an unpaired image-to-image translation method for driving\n  scenarios Abstract: Synthetic image translation has significant potentials in autonomous\ntransportation systems. That is due to the expense of data collection and\nannotation as well as the unmanageable diversity of real-words situations. The\nmain issue with unpaired image-to-image translation is the ill-posed nature of\nthe problem. In this work, we propose a novel method for constraining the\noutput space of unpaired image-to-image translation. We make the assumption\nthat the environment of the source domain is known (e.g. synthetically\ngenerated), and we propose to explicitly enforce preservation of the\nground-truth labels on the translated images.\n  We experiment on preserving ground-truth information such as semantic\nsegmentation, disparity, and instance segmentation. We show significant\nevidence that our method achieves improved performance over the\nstate-of-the-art model of UNIT for translating images from SYNTHIA to\nCityscapes. The generated images are perceived as more realistic in human\nsurveys and outperforms UNIT when used in a domain adaptation scenario for\nsemantic segmentation. \n\n"}
{"id": "1812.01712", "contents": "Title: Multiview Based 3D Scene Understanding On Partial Point Sets Abstract: Deep learning within the context of point clouds has gained much research\ninterest in recent years mostly due to the promising results that have been\nachieved on a number of challenging benchmarks, such as 3D shape recognition\nand scene semantic segmentation. In many realistic settings however, snapshots\nof the environment are often taken from a single view, which only contains a\npartial set of the scene due to the field of view restriction of commodity\ncameras. 3D scene semantic understanding on partial point clouds is considered\nas a challenging task. In this work, we propose a processing approach for 3D\npoint cloud data based on a multiview representation of the existing 360{\\deg}\npoint clouds. By fusing the original 360{\\deg} point clouds and their\ncorresponding 3D multiview representations as input data, a neural network is\nable to recognize partial point sets while improving the general performance on\ncomplete point sets, resulting in an overall increase of 31.9% and 4.3% in\nsegmentation accuracy for partial and complete scene semantic understanding,\nrespectively. This method can also be applied in a wider 3D recognition context\nsuch as 3D part segmentation. \n\n"}
{"id": "1812.01815", "contents": "Title: Uncertainty Sampling is Preconditioned Stochastic Gradient Descent on\n  Zero-One Loss Abstract: Uncertainty sampling, a popular active learning algorithm, is used to reduce\nthe amount of data required to learn a classifier, but it has been observed in\npractice to converge to different parameters depending on the initialization\nand sometimes to even better parameters than standard training on all the data.\nIn this work, we give a theoretical explanation of this phenomenon, showing\nthat uncertainty sampling on a convex loss can be interpreted as performing a\npreconditioned stochastic gradient step on a smoothed version of the population\nzero-one loss that converges to the population zero-one loss. Furthermore,\nuncertainty sampling moves in a descent direction and converges to stationary\npoints of the smoothed population zero-one loss. Experiments on synthetic and\nreal datasets support this connection. \n\n"}
{"id": "1812.02849", "contents": "Title: A Survey of Unsupervised Deep Domain Adaptation Abstract: Deep learning has produced state-of-the-art results for a variety of tasks.\nWhile such approaches for supervised learning have performed well, they assume\nthat training and testing data are drawn from the same distribution, which may\nnot always be the case. As a complement to this challenge, single-source\nunsupervised domain adaptation can handle situations where a network is trained\non labeled data from a source domain and unlabeled data from a related but\ndifferent target domain with the goal of performing well at test-time on the\ntarget domain. Many single-source and typically homogeneous unsupervised deep\ndomain adaptation approaches have thus been developed, combining the powerful,\nhierarchical representations from deep learning with domain adaptation to\nreduce reliance on potentially-costly target data labels. This survey will\ncompare these approaches by examining alternative methods, the unique and\ncommon elements, results, and theoretical insights. We follow this with a look\nat application areas and open research directions. \n\n"}
{"id": "1812.02886", "contents": "Title: Nonlinear Conjugate Gradients For Scaling Synchronous Distributed DNN\n  Training Abstract: Nonlinear conjugate gradient (NLCG) based optimizers have shown superior loss\nconvergence properties compared to gradient descent based optimizers for\ntraditional optimization problems. However, in Deep Neural Network (DNN)\ntraining, the dominant optimization algorithm of choice is still Stochastic\nGradient Descent (SGD) and its variants. In this work, we propose and evaluate\nthe stochastic preconditioned nonlinear conjugate gradient algorithm for large\nscale DNN training tasks. We show that a nonlinear conjugate gradient algorithm\nimproves the convergence speed of DNN training, especially in the large\nmini-batch scenario, which is essential for scaling synchronous distributed DNN\ntraining to large number of workers. We show how to efficiently use second\norder information in the NLCG pre-conditioner for improving DNN training\nconvergence. For the ImageNet classification task, at extremely large\nmini-batch sizes of greater than 65k, NLCG optimizer is able to improve top-1\naccuracy by more than 10 percentage points for standard training of the\nResnet-50 model for 90 epochs. For the CIFAR-100 classification task, at\nextremely large mini-batch sizes of greater than 16k, NLCG optimizer is able to\nimprove top-1 accuracy by more than 15 percentage points for standard training\nof the Resnet-32 model for 200 epochs. \n\n"}
{"id": "1812.02890", "contents": "Title: Three Tools for Practical Differential Privacy Abstract: Differentially private learning on real-world data poses challenges for\nstandard machine learning practice: privacy guarantees are difficult to\ninterpret, hyperparameter tuning on private data reduces the privacy budget,\nand ad-hoc privacy attacks are often required to test model privacy. We\nintroduce three tools to make differentially private machine learning more\npractical: (1) simple sanity checks which can be carried out in a centralized\nmanner before training, (2) an adaptive clipping bound to reduce the effective\nnumber of tuneable privacy parameters, and (3) we show that large-batch\ntraining improves model performance. \n\n"}
{"id": "1812.03049", "contents": "Title: On Batch Orthogonalization Layers Abstract: Batch normalization has become ubiquitous in many state-of-the-art nets. It\naccelerates training and yields good performance results. However, there are\nvarious other alternatives to normalization, e.g. orthonormalization. The\nobjective of this paper is to explore the possible alternatives to channel\nnormalization with orthonormalization layers. The performance of the algorithms\nare compared together with BN with prescribed performance measures. \n\n"}
{"id": "1812.03235", "contents": "Title: Improved Knowledge Graph Embedding using Background Taxonomic\n  Information Abstract: Knowledge graphs are used to represent relational information in terms of\ntriples. To enable learning about domains, embedding models, such as tensor\nfactorization models, can be used to make predictions of new triples. Often\nthere is background taxonomic information (in terms of subclasses and\nsubproperties) that should also be taken into account. We show that existing\nfully expressive (a.k.a. universal) models cannot provably respect subclass and\nsubproperty information. We show that minimal modifications to an existing\nknowledge graph completion method enables injection of taxonomic information.\nMoreover, we prove that our model is fully expressive, assuming a lower-bound\non the size of the embeddings. Experimental results on public knowledge graphs\nshow that despite its simplicity our approach is surprisingly effective. \n\n"}
{"id": "1812.03239", "contents": "Title: Communication-Efficient Policy Gradient Methods for Distributed\n  Reinforcement Learning Abstract: This paper deals with distributed policy optimization in reinforcement\nlearning, which involves a central controller and a group of learners. In\nparticular, two typical settings encountered in several applications are\nconsidered: multi-agent reinforcement learning (RL) and parallel RL, where\nfrequent information exchanges between the learners and the controller are\nrequired. For many practical distributed systems, however, the overhead caused\nby these frequent communication exchanges is considerable, and becomes the\nbottleneck of the overall performance. To address this challenge, a novel\npolicy gradient approach is developed for solving distributed RL. The novel\napproach adaptively skips the policy gradient communication during iterations,\nand can reduce the communication overhead without degrading learning\nperformance. It is established analytically that: i) the novel algorithm has\nconvergence rate identical to that of the plain-vanilla policy gradient; while\nii) if the distributed learners are heterogeneous in terms of their reward\nfunctions, the number of communication rounds needed to achieve a desirable\nlearning accuracy is markedly reduced. Numerical experiments corroborate the\ncommunication reduction attained by the novel algorithm compared to\nalternatives. \n\n"}
{"id": "1812.03315", "contents": "Title: A deep learning-based remaining useful life prediction approach for\n  bearings Abstract: In industrial applications, nearly half the failures of motors are caused by\nthe degradation of rolling element bearings (REBs). Therefore, accurately\nestimating the remaining useful life (RUL) for REBs are of crucial importance\nto ensure the reliability and safety of mechanical systems. To tackle this\nchallenge, model-based approaches are often limited by the complexity of\nmathematical modeling. Conventional data-driven approaches, on the other hand,\nrequire massive efforts to extract the degradation features and construct\nhealth index. In this paper, a novel online data-driven framework is proposed\nto exploit the adoption of deep convolutional neural networks (CNN) in\npredicting the RUL of bearings. More concretely, the raw vibrations of training\nbearings are first processed using the Hilbert-Huang transform (HHT) and a\nnovel nonlinear degradation indicator is constructed as the label for learning.\nThe CNN is then employed to identify the hidden pattern between the extracted\ndegradation indicator and the vibration of training bearings, which makes it\npossible to estimate the degradation of the test bearings automatically.\nFinally, testing bearings' RULs are predicted by using a $\\epsilon$-support\nvector regression model. The superior performance of the proposed RUL\nestimation framework, compared with the state-of-the-art approaches, is\ndemonstrated through the experimental results. The generality of the proposed\nCNN model is also validated by transferring to bearings undergoing different\noperating conditions. \n\n"}
{"id": "1812.03467", "contents": "Title: A note on solving nonlinear optimization problems in variable precision Abstract: This short note considers an efficient variant of the trust-region algorithm\nwith dynamic accuracy proposed Carter (1993) and Conn, Gould and Toint (2000)\nas a tool for very high-performance computing, an area where it is critical to\nallow multi-precision computations for keeping the energy dissipation under\ncontrol. Numerical experiments are presented indicating that the use of the\nconsidered method can bring substantial savings in objective function's and\ngradient's evaluation \"energy costs\" by efficiently exploiting multi-precision\ncomputations. \n\n"}
{"id": "1812.03965", "contents": "Title: Guided Dropout Abstract: Dropout is often used in deep neural networks to prevent over-fitting.\nConventionally, dropout training invokes \\textit{random drop} of nodes from the\nhidden layers of a Neural Network. It is our hypothesis that a guided selection\nof nodes for intelligent dropout can lead to better generalization as compared\nto the traditional dropout. In this research, we propose \"guided dropout\" for\ntraining deep neural network which drop nodes by measuring the strength of each\nnode. We also demonstrate that conventional dropout is a specific case of the\nproposed guided dropout. Experimental evaluation on multiple datasets including\nMNIST, CIFAR10, CIFAR100, SVHN, and Tiny ImageNet demonstrate the efficacy of\nthe proposed guided dropout. \n\n"}
{"id": "1812.04145", "contents": "Title: Learning Sharing Behaviors with Arbitrary Numbers of Agents Abstract: We propose a method for modeling and learning turn-taking behaviors for\naccessing a shared resource. We model the individual behavior for each agent in\nan interaction and then use a multi-agent fusion model to generate a summary\nover the expected actions of the group to render the model independent of the\nnumber of agents. The individual behavior models are weighted finite state\ntransducers (WFSTs) with weights dynamically updated during interactions, and\nthe multi-agent fusion model is a logistic regression classifier.\n  We test our models in a multi-agent tower-building environment, where a\nQ-learning agent learns to interact with rule-based agents. Our approach\naccurately models the underlying behavior patterns of the rule-based agents\nwith accuracy ranging between 0.63 and 1.0 depending on the stochasticity of\nthe other agent behaviors. In addition we show using KL-divergence that the\nmodel accurately captures the distribution of next actions when interacting\nwith both a single agent (KL-divergence < 0.1) and with multiple agents\n(KL-divergence < 0.37). Finally, we demonstrate that our behavior model can be\nused by a Q-learning agent to take turns in an interactive turn-taking\nenvironment. \n\n"}
{"id": "1812.04276", "contents": "Title: Deep Unfolding of a Proximal Interior Point Method for Image Restoration Abstract: Variational methods are widely applied to ill-posed inverse problems for they\nhave the ability to embed prior knowledge about the solution. However, the\nlevel of performance of these methods significantly depends on a set of\nparameters, which can be estimated through computationally expensive and\ntime-consuming methods. In contrast, deep learning offers very generic and\nefficient architectures, at the expense of explainability, since it is often\nused as a black-box, without any fine control over its output. Deep unfolding\nprovides a convenient approach to combine variational-based and deep learning\napproaches. Starting from a variational formulation for image restoration, we\ndevelop iRestNet, a neural network architecture obtained by unfolding a\nproximal interior point algorithm. Hard constraints, encoding desirable\nproperties for the restored image, are incorporated into the network thanks to\na logarithmic barrier, while the barrier parameter, the stepsize, and the\npenalization weight are learned by the network. We derive explicit expressions\nfor the gradient of the proximity operator for various choices of constraints,\nwhich allows training iRestNet with gradient descent and backpropagation. In\naddition, we provide theoretical results regarding the stability of the network\nfor a common inverse problem example. Numerical experiments on image deblurring\nproblems show that the proposed approach compares favorably with both\nstate-of-the-art variational and machine learning methods in terms of image\nquality. \n\n"}
{"id": "1812.04352", "contents": "Title: Layer-Parallel Training of Deep Residual Neural Networks Abstract: Residual neural networks (ResNets) are a promising class of deep neural\nnetworks that have shown excellent performance for a number of learning tasks,\ne.g., image classification and recognition. Mathematically, ResNet\narchitectures can be interpreted as forward Euler discretizations of a\nnonlinear initial value problem whose time-dependent control variables\nrepresent the weights of the neural network. Hence, training a ResNet can be\ncast as an optimal control problem of the associated dynamical system. For\nsimilar time-dependent optimal control problems arising in engineering\napplications, parallel-in-time methods have shown notable improvements in\nscalability. This paper demonstrates the use of those techniques for efficient\nand effective training of ResNets. The proposed algorithms replace the\nclassical (sequential) forward and backward propagation through the network\nlayers by a parallel nonlinear multigrid iteration applied to the layer domain.\nThis adds a new dimension of parallelism across layers that is attractive when\ntraining very deep networks. From this basic idea, we derive multiple\nlayer-parallel methods. The most efficient version employs a simultaneous\noptimization approach where updates to the network parameters are based on\ninexact gradient information in order to speed up the training process. Using\nnumerical examples from supervised classification, we demonstrate that the new\napproach achieves similar training performance to traditional methods, but\nenables layer-parallelism and thus provides speedup over layer-serial methods\nthrough greater concurrency. \n\n"}
{"id": "1812.04549", "contents": "Title: Controlling Covariate Shift using Balanced Normalization of Weights Abstract: We introduce a new normalization technique that exhibits the fast convergence\nproperties of batch normalization using a transformation of layer weights\ninstead of layer outputs. The proposed technique keeps the contribution of\npositive and negative weights to the layer output balanced. We validate our\nmethod on a set of standard benchmarks including CIFAR-10/100, SVHN and ILSVRC\n2012 ImageNet. \n\n"}
{"id": "1812.05473", "contents": "Title: Learning Features of Network Structures Using Graphlets Abstract: Networks are fundamental to the study of complex systems, ranging from social\ncontacts, message transactions, to biological regulations and economical\nnetworks. In many realistic applications, these networks may vary over time.\nModeling and analyzing such temporal properties is of additional interest as it\ncan provide a richer characterization of relations between nodes in networks.\nIn this paper, we explore the role of \\emph{graphlets} in network\nclassification for both static and temporal networks. Graphlets are small\nnon-isomorphic induced subgraphs representing connected patterns in a network\nand their frequency can be used to assess network structures. We show that\ngraphlet features, which are not captured by state-of-the-art methods, play a\nsignificant role in enhancing the performance of network classification. To\nthat end, we propose two novel graphlet-based techniques, \\emph{gl2vec} for\nnetwork embedding, and \\emph{gl-DCNN} for diffusion-convolutional neural\nnetworks. We demonstrate the efficacy and usability of \\emph{gl2vec} and\n\\emph{gl-DCNN} through extensive experiments using several real-world static\nand temporal networks. We find that features learned from graphlets can bring\nnotable performance increases to state-of-the-art methods in network analysis. \n\n"}
{"id": "1812.05477", "contents": "Title: Gaussian Process Deep Belief Networks: A Smooth Generative Model of\n  Shape with Uncertainty Propagation Abstract: The shape of an object is an important characteristic for many vision\nproblems such as segmentation, detection and tracking. Being independent of\nappearance, it is possible to generalize to a large range of objects from only\nsmall amounts of data. However, shapes represented as silhouette images are\nchallenging to model due to complicated likelihood functions leading to\nintractable posteriors. In this paper we present a generative model of shapes\nwhich provides a low dimensional latent encoding which importantly resides on a\nsmooth manifold with respect to the silhouette images. The proposed model\npropagates uncertainty in a principled manner allowing it to learn from small\namounts of data and providing predictions with associated uncertainty. We\nprovide experiments that show how our proposed model provides favorable\nquantitative results compared with the state-of-the-art while simultaneously\nproviding a representation that resides on a low-dimensional interpretable\nmanifold. \n\n"}
{"id": "1812.06070", "contents": "Title: The Boosted DC Algorithm for nonsmooth functions Abstract: The Boosted Difference of Convex functions Algorithm (BDCA) was recently\nproposed for minimizing smooth difference of convex (DC) functions. BDCA\naccelerates the convergence of the classical Difference of Convex functions\nAlgorithm (DCA) thanks to an additional line search step. The purpose of this\npaper is twofold. Firstly, to show that this scheme can be generalized and\nsuccessfully applied to certain types of nonsmooth DC functions, namely, those\nthat can be expressed as the difference of a smooth function and a possibly\nnonsmooth one. Secondly, to show that there is complete freedom in the choice\nof the trial step size for the line search, which is something that can further\nimprove its performance. We prove that any limit point of the BDCA iterative\nsequence is a critical point of the problem under consideration, and that the\ncorresponding objective value is monotonically decreasing and convergent. The\nglobal convergence and convergent rate of the iterations are obtained under the\nKurdyka-Lojasiewicz property. Applications and numerical experiments for two\nproblems in data science are presented, demonstrating that BDCA outperforms\nDCA. Specifically, for the Minimum Sum-of-Squares Clustering problem, BDCA was\non average sixteen times faster than DCA, and for the Multidimensional Scaling\nproblem, BDCA was three times faster than DCA. \n\n"}
{"id": "1812.06127", "contents": "Title: Federated Optimization in Heterogeneous Networks Abstract: Federated Learning is a distributed learning paradigm with two key challenges\nthat differentiate it from traditional distributed optimization: (1)\nsignificant variability in terms of the systems characteristics on each device\nin the network (systems heterogeneity), and (2) non-identically distributed\ndata across the network (statistical heterogeneity). In this work, we introduce\na framework, FedProx, to tackle heterogeneity in federated networks. FedProx\ncan be viewed as a generalization and re-parametrization of FedAvg, the current\nstate-of-the-art method for federated learning. While this re-parameterization\nmakes only minor modifications to the method itself, these modifications have\nimportant ramifications both in theory and in practice. Theoretically, we\nprovide convergence guarantees for our framework when learning over data from\nnon-identical distributions (statistical heterogeneity), and while adhering to\ndevice-level systems constraints by allowing each participating device to\nperform a variable amount of work (systems heterogeneity). Practically, we\ndemonstrate that FedProx allows for more robust convergence than FedAvg across\na suite of realistic federated datasets. In particular, in highly heterogeneous\nsettings, FedProx demonstrates significantly more stable and accurate\nconvergence behavior relative to FedAvg---improving absolute test accuracy by\n22% on average. \n\n"}
{"id": "1812.06469", "contents": "Title: The Adverse Effects of Code Duplication in Machine Learning Models of\n  Code Abstract: The field of big code relies on mining large corpora of code to perform some\nlearning task. A significant threat to this approach has been recently\nidentified by Lopes et al. (2017) who found a large amount of near-duplicate\ncode on GitHub. However, the impact of code duplication has not been noticed by\nresearchers devising machine learning models for source code. In this work, we\nexplore the effects of code duplication on machine learning models showing that\nreported performance metrics are sometimes inflated by up to 100% when testing\non duplicated code corpora compared to the performance on de-duplicated corpora\nwhich more accurately represent how machine learning models of code are used by\nsoftware engineers. We present a duplication index for widely used datasets,\nlist best practices for collecting code corpora and evaluating machine learning\nmodels on them. Finally, we release tools to help the community avoid this\nproblem in future research. \n\n"}
{"id": "1812.07319", "contents": "Title: Evaluating the squared-exponential covariance function in Gaussian\n  processes with integral observations Abstract: This paper deals with the evaluation of double line integrals of the squared\nexponential covariance function. We propose a new approach in which the double\nintegral is reduced to a single integral using the error function. This single\nintegral is then computed with efficiently implemented numerical techniques.\nThe performance is compared against existing state of the art methods and the\nresults show superior properties in numerical robustness and accuracy per\ncomputation time. \n\n"}
{"id": "1812.07351", "contents": "Title: Monte Carlo Continual Resolving for Online Strategy Computation in\n  Imperfect Information Games Abstract: Online game playing algorithms produce high-quality strategies with a\nfraction of memory and computation required by their offline alternatives.\nContinual Resolving (CR) is a recent theoretically sound approach to online\ngame playing that has been used to outperform human professionals in poker.\nHowever, parts of the algorithm were specific to poker, which enjoys many\nproperties not shared by other imperfect information games. We present a\ndomain-independent formulation of CR applicable to any two-player zero-sum\nextensive-form games that works with an abstract resolving algorithm. We\nfurther describe and implement its Monte Carlo variant (MCCR) which uses Monte\nCarlo Counterfactual Regret Minimization (MCCFR) as a resolver. We prove the\ncorrectness of CR and show an $O(T^{-1/2})$-dependence of MCCR's exploitability\non the computation time. Furthermore, we present an empirical comparison of\nMCCR with incremental tree building to Online Outcome Sampling and\nInformation-set MCTS on several domains. \n\n"}
{"id": "1812.07518", "contents": "Title: Deep UL2DL: Channel Knowledge Transfer from Uplink to Downlink Abstract: Knowledge of the channel state information (CSI) at the transmitter side is\none of the primary sources of information that can be used for the efficient\nallocation of wireless resources. Obtaining downlink (DL) CSI in Frequency\nDivision Duplexing (FDD) systems from uplink (UL) CSI is not as straightforward\nas in TDD systems. Therefore, users usually feed the DL-CSI back to the\ntransmitter. To remove the need for feedback (and thus having less signaling\noverhead), we propose to use two recent deep neural network structures, i.e.,\nconvolutional neural networks and generative adversarial networks (GANs) to\ninfer the DL-CSI by observing the UL-CSI. The core idea of our data-driven\nscheme is exploiting the fact that both DL and UL channels share the same\npropagation environment. As such, we extracted the environment information from\nthe UL channel response to a latent domain and then transferred the derived\nenvironment information from the latent domain to predict the DL channel. To\novercome incorrect latent domain and the problem of oversimplistic assumptions,\nin this work, we did not use any specific parametric model and instead used\ndata-driven approaches to discover the underlying structure of data without any\nprior model assumptions. To overcome the challenge of capturing the UL-DL joint\ndistribution, we used a mean square error-based variant of the GAN structure\nwith improved convergence properties called boundary equilibrium GAN (BEGAN).\nFor training and testing we used simulated data of Extended Vehicular-A (EVA)\nand Extended Typical Urban (ETU) models. Simulation results verified that our\nmethods can accurately infer and predict the downlink CSI from the uplink CSI\nfor different multipath environments in FDD communications. \n\n"}
{"id": "1812.07725", "contents": "Title: Breaking Reversibility Accelerates Langevin Dynamics for Global\n  Non-Convex Optimization Abstract: Langevin dynamics (LD) has been proven to be a powerful technique for\noptimizing a non-convex objective as an efficient algorithm to find local\nminima while eventually visiting a global minimum on longer time-scales. LD is\nbased on the first-order Langevin diffusion which is reversible in time. We\nstudy two variants that are based on non-reversible Langevin diffusions: the\nunderdamped Langevin dynamics (ULD) and the Langevin dynamics with a\nnon-symmetric drift (NLD). Adopting the techniques of Tzen, Liang and Raginsky\n(2018) for LD to non-reversible diffusions, we show that for a given local\nminimum that is within an arbitrary distance from the initialization, with high\nprobability, either the ULD trajectory ends up somewhere outside a small\nneighborhood of this local minimum within a recurrence time which depends on\nthe smallest eigenvalue of the Hessian at the local minimum or they enter this\nneighborhood by the recurrence time and stay there for a potentially\nexponentially long escape time. The ULD algorithms improve upon the recurrence\ntime obtained for LD in Tzen, Liang and Raginsky (2018) with respect to the\ndependency on the smallest eigenvalue of the Hessian at the local minimum.\nSimilar result and improvement are obtained for the NLD algorithm. We also show\nthat non-reversible variants can exit the basin of attraction of a local\nminimum faster in discrete time when the objective has two local minima\nseparated by a saddle point and quantify the amount of improvement. Our\nanalysis suggests that non-reversible Langevin algorithms are more efficient to\nlocate a local minimum as well as exploring the state space. Our analysis is\nbased on the quadratic approximation of the objective around a local minimum.\nAs a by-product of our analysis, we obtain optimal mixing rates for quadratic\nobjectives in the 2-Wasserstein distance for two non-reversible Langevin\nalgorithms we consider. \n\n"}
{"id": "1812.08997", "contents": "Title: Stochastic Doubly Robust Gradient Abstract: When training a machine learning model with observational data, it is often\nencountered that some values are systemically missing. Learning from the\nincomplete data in which the missingness depends on some covariates may lead to\nbiased estimation of parameters and even harm the fairness of decision outcome.\nThis paper proposes how to adjust the causal effect of covariates on the\nmissingness when training models using stochastic gradient descent (SGD).\nInspired by the design of doubly robust estimator and its theoretical property\nof double robustness, we introduce stochastic doubly robust gradient (SDRG)\nconsisting of two models: weight-corrected gradients for inverse propensity\nscore weighting and per-covariate control variates for regression adjustment.\nAlso, we identify the connection between double robustness and variance\nreduction in SGD by demonstrating the SDRG algorithm with a unifying framework\nfor variance reduced SGD. The performance of our approach is empirically tested\nby showing the convergence in training image classifiers with several examples\nof missing data. \n\n"}
{"id": "1812.09954", "contents": "Title: Self-Attention Equipped Graph Convolutions for Disease Prediction Abstract: Multi-modal data comprising imaging (MRI, fMRI, PET, etc.) and non-imaging\n(clinical test, demographics, etc.) data can be collected together and used for\ndisease prediction. Such diverse data gives complementary information about the\npatient\\'s condition to make an informed diagnosis. A model capable of\nleveraging the individuality of each multi-modal data is required for better\ndisease prediction. We propose a graph convolution based deep model which takes\ninto account the distinctiveness of each element of the multi-modal data. We\nincorporate a novel self-attention layer, which weights every element of the\ndemographic data by exploring its relation to the underlying disease. We\ndemonstrate the superiority of our developed technique in terms of\ncomputational speed and performance when compared to state-of-the-art methods.\nOur method outperforms other methods with a significant margin. \n\n"}
{"id": "1812.10004", "contents": "Title: Overparameterized Nonlinear Learning: Gradient Descent Takes the\n  Shortest Path? Abstract: Many modern learning tasks involve fitting nonlinear models to data which are\ntrained in an overparameterized regime where the parameters of the model exceed\nthe size of the training dataset. Due to this overparameterization, the\ntraining loss may have infinitely many global minima and it is critical to\nunderstand the properties of the solutions found by first-order optimization\nschemes such as (stochastic) gradient descent starting from different\ninitializations. In this paper we demonstrate that when the loss has certain\nproperties over a minimally small neighborhood of the initial point, first\norder methods such as (stochastic) gradient descent have a few intriguing\nproperties: (1) the iterates converge at a geometric rate to a global optima\neven when the loss is nonconvex, (2) among all global optima of the loss the\niterates converge to one with a near minimal distance to the initial point, (3)\nthe iterates take a near direct route from the initial point to this global\noptima. As part of our proof technique, we introduce a new potential function\nwhich captures the precise tradeoff between the loss function and the distance\nto the initial point as the iterations progress. For Stochastic Gradient\nDescent (SGD), we develop novel martingale techniques that guarantee SGD never\nleaves a small neighborhood of the initialization, even with rather large\nlearning rates. We demonstrate the utility of our general theory for a variety\nof problem domains spanning low-rank matrix recovery to neural network\ntraining. Underlying our analysis are novel insights that may have implications\nfor training and generalization of more sophisticated learning problems\nincluding those involving deep neural network architectures. \n\n"}
{"id": "1812.10401", "contents": "Title: Word Embedding based on Low-Rank Doubly Stochastic Matrix Decomposition Abstract: Word embedding, which encodes words into vectors, is an important starting\npoint in natural language processing and commonly used in many text-based\nmachine learning tasks. However, in most current word embedding approaches, the\nsimilarity in embedding space is not optimized in the learning. In this paper\nwe propose a novel neighbor embedding method which directly learns an embedding\nsimplex where the similarities between the mapped words are optimal in terms of\nminimal discrepancy to the input neighborhoods. Our method is built upon\ntwo-step random walks between words via topics and thus able to better reveal\nthe topics among the words. Experiment results indicate that our method,\ncompared with another existing word embedding approach, is more favorable for\nvarious queries. \n\n"}
{"id": "1812.10426", "contents": "Title: Stochastic Trust Region Inexact Newton Method for Large-scale Machine\n  Learning Abstract: Nowadays stochastic approximation methods are one of the major research\ndirection to deal with the large-scale machine learning problems. From\nstochastic first order methods, now the focus is shifting to stochastic second\norder methods due to their faster convergence and availability of computing\nresources. In this paper, we have proposed a novel Stochastic Trust RegiOn\nInexact Newton method, called as STRON, to solve large-scale learning problems\nwhich uses conjugate gradient (CG) to inexactly solve trust region subproblem.\nThe method uses progressive subsampling in the calculation of gradient and\nHessian values to take the advantage of both, stochastic and full-batch\nregimes. We have extended STRON using existing variance reduction techniques to\ndeal with the noisy gradients and using preconditioned conjugate gradient (PCG)\nas subproblem solver, and empirically proved that they do not work as expected,\nfor the large-scale learning problems. Finally, our empirical results prove\nefficacy of the proposed method against existing methods with bench marked\ndatasets. \n\n"}
{"id": "1812.10563", "contents": "Title: The Prophet Inequality Can Be Solved Optimally with a Single Set of\n  Samples Abstract: The setting of the classic prophet inequality is as follows: a gambler is\nshown the probability distributions of $n$ independent, non-negative random\nvariables with finite expectations. In their indexed order, a value is drawn\nfrom each distribution, and after every draw the gambler may choose to accept\nthe value and end the game, or discard the value permanently and continue the\ngame. What is the best performance that the gambler can achieve in comparison\nto a prophet who can always choose the highest value? Krengel, Sucheston, and\nGarling solved this problem in 1978, showing that there exists a strategy for\nwhich the gambler can achieve half as much reward as the prophet in\nexpectation. Furthermore, this result is tight.\n  In this work, we consider a setting in which the gambler is allowed much less\ninformation. Suppose that the gambler can only take one sample from each of the\ndistributions before playing the game, instead of knowing the full\ndistributions. We provide a simple and intuitive algorithm that recovers the\noriginal approximation of $\\frac{1}{2}$. Our algorithm works against even an\nalmighty adversary who always chooses a worst-case ordering, rather than the\nstandard offline adversary. The result also has implications for mechanism\ndesign -- there is much interest in designing competitive auctions with a\nfinite number of samples from value distributions rather than full\ndistributional knowledge. \n\n"}
{"id": "1812.11202", "contents": "Title: State representation learning with recurrent capsule networks Abstract: Unsupervised learning of compact and relevant state representations has been\nproved very useful at solving complex reinforcement learning tasks. In this\npaper, we propose a recurrent capsule network that learns such representations\nby trying to predict the future observations in an agent's trajectory. \n\n"}
{"id": "1812.11293", "contents": "Title: DeGroot-Friedkin Map in Opinion Dynamics is Mirror Descent Abstract: We provide a variational interpretation of the DeGroot-Friedkin map in\nopinion dynamics. Specifically, we show that the nonlinear dynamics for the\nDeGroot-Friedkin map can be viewed as mirror descent on the standard simplex\nwith the associated Bregman divergence being equal to the generalized\nKullback-Leibler divergence, i.e., an entropic mirror descent. Our results\nreveal that the DeGroot-Friedkin map elicits an individual's social power to be\nclose to her social influence while minimizing the so called \"extropy\" -- the\nentropy of the complimentary opinion. \n\n"}
{"id": "1812.11473", "contents": "Title: ORIGAMI: A Heterogeneous Split Architecture for In-Memory Acceleration\n  of Learning Abstract: Memory bandwidth bottleneck is a major challenges in processing machine\nlearning (ML) algorithms. In-memory acceleration has potential to address this\nproblem; however, it needs to address two challenges. First, in-memory\naccelerator should be general enough to support a large set of different ML\nalgorithms. Second, it should be efficient enough to utilize bandwidth while\nmeeting limited power and area budgets of logic layer of a 3D-stacked memory.\nWe observe that previous work fails to simultaneously address both challenges.\nWe propose ORIGAMI, a heterogeneous set of in-memory accelerators, to support\ncompute demands of different ML algorithms, and also uses an off-the-shelf\ncompute platform (e.g.,FPGA,GPU,TPU,etc.) to utilize bandwidth without\nviolating strict area and power budgets. ORIGAMI offers a pattern-matching\ntechnique to identify similar computation patterns of ML algorithms and\nextracts a compute engine for each pattern. These compute engines constitute\nheterogeneous accelerators integrated on logic layer of a 3D-stacked memory.\nCombination of these compute engines can execute any type of ML algorithms. To\nutilize available bandwidth without violating area and power budgets of logic\nlayer, ORIGAMI comes with a computation-splitting compiler that divides an ML\nalgorithm between in-memory accelerators and an out-of-the-memory platform in a\nbalanced way and with minimum inter-communications. Combination of pattern\nmatching and split execution offers a new design point for acceleration of ML\nalgorithms. Evaluation results across 12 popular ML algorithms show that\nORIGAMI outperforms state-of-the-art accelerator with 3D-stacked memory in\nterms of performance and energy-delay product (EDP) by 1.5x and 29x (up to 1.6x\nand 31x), respectively. Furthermore, results are within a 1% margin of an ideal\nsystem that has unlimited compute resources on logic layer of a 3D-stacked\nmemory. \n\n"}
{"id": "1901.00660", "contents": "Title: Deep Speech Enhancement for Reverberated and Noisy Signals using Wide\n  Residual Networks Abstract: This paper proposes a deep speech enhancement method which exploits the high\npotential of residual connections in a wide neural network architecture, a\ntopology known as Wide Residual Network. This is supported on single\ndimensional convolutions computed alongside the time domain, which is a\npowerful approach to process contextually correlated representations through\nthe temporal domain, such as speech feature sequences. We find the residual\nmechanism extremely useful for the enhancement task since the signal always has\na linear shortcut and the non-linear path enhances it in several steps by\nadding or subtracting corrections. The enhancement capacity of the proposal is\nassessed by objective quality metrics and the performance of a speech\nrecognition system. This was evaluated in the framework of the REVERB Challenge\ndataset, including simulated and real samples of reverberated and noisy speech\nsignals. Results showed that enhanced speech from the proposed method succeeded\nfor both, the enhancement task with intelligibility purposes and the speech\nrecognition system. The DNN model, trained with artificial synthesized\nreverberation data, was able to deal with far-field reverberated speech from\nreal scenarios. Furthermore, the method was able to take advantage of the\nresidual connection achieving to enhance signals with low noise level, which is\nusually a strong handicap of traditional enhancement methods. \n\n"}
{"id": "1901.01030", "contents": "Title: Multi-Product Dynamic Pricing in High-Dimensions with Heterogeneous\n  Price Sensitivity Abstract: We consider the problem of multi-product dynamic pricing, in a contextual\nsetting, for a seller of differentiated products. In this environment, the\ncustomers arrive over time and products are described by high-dimensional\nfeature vectors. Each customer chooses a product according to the widely used\nMultinomial Logit (MNL) choice model and her utility depends on the product\nfeatures as well as the prices offered. The seller a-priori does not know the\nparameters of the choice model but can learn them through interactions with\ncustomers. The seller's goal is to design a pricing policy that maximizes her\ncumulative revenue. This model is motivated by online marketplaces such as\nAirbnb platform and online advertising. We measure the performance of a pricing\npolicy in terms of regret, which is the expected revenue loss with respect to a\nclairvoyant policy that knows the parameters of the choice model in advance and\nalways sets the revenue-maximizing prices. We propose a pricing policy, named\nM3P, that achieves a $T$-period regret of $O(\\log(Td) ( \\sqrt{T}+ d\\log(T)))$\nunder heterogeneous price sensitivity for products with features of dimension\n$d$. We also use tools from information theory to prove that no policy can\nachieve worst-case $T$-regret better than $\\Omega(\\sqrt{T})$. \n\n"}
{"id": "1901.01379", "contents": "Title: Deep Reinforcement Learning for Imbalanced Classification Abstract: Data in real-world application often exhibit skewed class distribution which\nposes an intense challenge for machine learning. Conventional classification\nalgorithms are not effective in the case of imbalanced data distribution, and\nmay fail when the data distribution is highly imbalanced. To address this\nissue, we propose a general imbalanced classification model based on deep\nreinforcement learning. We formulate the classification problem as a sequential\ndecision-making process and solve it by deep Q-learning network. The agent\nperforms a classification action on one sample at each time step, and the\nenvironment evaluates the classification action and returns a reward to the\nagent. The reward from minority class sample is larger so the agent is more\nsensitive to the minority class. The agent finally finds an optimal\nclassification policy in imbalanced data under the guidance of specific reward\nfunction and beneficial learning environment. Experiments show that our\nproposed model outperforms the other imbalanced classification algorithms, and\nit can identify more minority samples and has great classification performance. \n\n"}
{"id": "1901.01558", "contents": "Title: Self-Expressive Subspace Clustering to Recognize Motion Dynamics of a\n  Multi-Joint Coordination for Chronic Ankle Instability Abstract: Ankle sprains and instability are major public health concerns. Up to 70% of\nindividuals do not fully recover from a single ankle sprain and eventually\ndevelop chronic ankle instability (CAI). The diagnosis of CAI has been mainly\nbased on self-report rather than objective biomechanical measures. The goal of\nthis study is to quantitatively recognize the motion pattern of a multi-joint\ncoordination using biosensor data from bilateral hip, knee, and ankle joints,\nand further distinguish between CAI and healthy cohorts. We propose an analytic\nframework, where a nonlinear subspace clustering method is developed to learn\nthe motion dynamic patterns from an inter-connected network of multiply joints.\nA support vector machine model is trained with a leave-one-subject-out cross\nvalidation to validate the learned measures compared to traditional statistical\nmeasures. The computational results showed >70% classification accuracy on\naverage based on the dataset of 48 subjects (25 with CAI and 23 normal\ncontrols) examined in our designed experiment. It is found that CAI can be\nobserved from other joints (e.g., hips) significantly, which reflects the fact\nthat there are interactions in the multi-joint coordination system. The\ndeveloped method presents a potential to support the decisions with motion\npatterns during diagnosis, treatment, rehabilitation of gait abnormality caused\nby physical injury (e.g., ankle sprains in this study) or even central nervous\nsystem disorders. \n\n"}
{"id": "1901.01598", "contents": "Title: Toward a Theory of Cyber Attacks Abstract: We provide a general methodology for analyzing defender-attacker based\n\"games\" in which we model such games as Markov models and introduce a capacity\nregion to analyze how defensive and adversarial strategies impact security.\nSuch a framework allows us to analyze under what kind of conditions we can\nprove statements (about an attack objective $k$) of the form \"if the attacker\nhas a time budget $T_{bud}$, then the probability that the attacker can reach\nan attack objective $\\geq k$ is at most $poly(T_{bud})negl(k)$\". We are\ninterested in such rigorous cryptographic security guarantees (that describe\nworst-case guarantees) as these shed light on the requirements of a defender's\nstrategy for preventing more and more the progress of an attack, in terms of\nthe \"learning rate\" of a defender's strategy. We explain the damage an attacker\ncan achieve by a \"containment parameter\" describing the maximally reached\nattack objective within a specific time window. \n\n"}
{"id": "1901.01624", "contents": "Title: Composite optimization for robust blind deconvolution Abstract: The blind deconvolution problem seeks to recover a pair of vectors from a set\nof rank one bilinear measurements. We consider a natural nonsmooth formulation\nof the problem and show that under standard statistical assumptions, its moduli\nof weak convexity, sharpness, and Lipschitz continuity are all dimension\nindependent. This phenomenon persists even when up to half of the measurements\nare corrupted by noise. Consequently, standard algorithms, such as the\nsubgradient and prox-linear methods, converge at a rapid dimension-independent\nrate when initialized within constant relative error of the solution. We then\ncomplete the paper with a new initialization strategy, complementing the local\nsearch algorithms. The initialization procedure is both provably efficient and\nrobust to outlying measurements. Numerical experiments, on both simulated and\nreal data, illustrate the developed theory and methods. \n\n"}
{"id": "1901.01992", "contents": "Title: Large-Scale Markov Decision Problems via the Linear Programming Dual Abstract: We consider the problem of controlling a fully specified Markov decision\nprocess (MDP), also known as the planning problem, when the state space is very\nlarge and calculating the optimal policy is intractable. Instead, we pursue the\nmore modest goal of optimizing over some small family of policies.\nSpecifically, we show that the family of policies associated with a\nlow-dimensional approximation of occupancy measures yields a tractable\noptimization. Moreover, we propose an efficient algorithm, scaling with the\nsize of the subspace but not the state space, that is able to find a policy\nwith low excess loss relative to the best policy in this class. To the best of\nour knowledge, such results did not exist in the literature previously. We\nbound excess loss in the average cost and discounted cost cases, which are\ntreated separately. Preliminary experiments show the effectiveness of the\nproposed algorithms in a queueing application. \n\n"}
{"id": "1901.02051", "contents": "Title: DPPNet: Approximating Determinantal Point Processes with Deep Networks Abstract: Determinantal Point Processes (DPPs) provide an elegant and versatile way to\nsample sets of items that balance the point-wise quality with the set-wise\ndiversity of selected items. For this reason, they have gained prominence in\nmany machine learning applications that rely on subset selection. However,\nsampling from a DPP over a ground set of size $N$ is a costly operation,\nrequiring in general an $O(N^3)$ preprocessing cost and an $O(Nk^3)$ sampling\ncost for subsets of size $k$. We approach this problem by introducing DPPNets:\ngenerative deep models that produce DPP-like samples for arbitrary ground sets.\nWe develop an inhibitive attention mechanism based on transformer networks that\ncaptures a notion of dissimilarity between feature vectors. We show\ntheoretically that such an approximation is sensible as it maintains the\nguarantees of inhibition or dissimilarity that makes DPPs so powerful and\nunique. Empirically, we demonstrate that samples from our model receive high\nlikelihood under the more expensive DPP alternative. \n\n"}
{"id": "1901.02731", "contents": "Title: A Comprehensive guide to Bayesian Convolutional Neural Network with\n  Variational Inference Abstract: Artificial Neural Networks are connectionist systems that perform a given\ntask by learning on examples without having prior knowledge about the task.\nThis is done by finding an optimal point estimate for the weights in every\nnode. Generally, the network using point estimates as weights perform well with\nlarge datasets, but they fail to express uncertainty in regions with little or\nno data, leading to overconfident decisions.\n  In this paper, Bayesian Convolutional Neural Network (BayesCNN) using\nVariational Inference is proposed, that introduces probability distribution\nover the weights. Furthermore, the proposed BayesCNN architecture is applied to\ntasks like Image Classification, Image Super-Resolution and Generative\nAdversarial Networks. The results are compared to point-estimates based\narchitectures on MNIST, CIFAR-10 and CIFAR-100 datasets for Image\nCLassification task, on BSD300 dataset for Image Super Resolution task and on\nCIFAR10 dataset again for Generative Adversarial Network task.\n  BayesCNN is based on Bayes by Backprop which derives a variational\napproximation to the true posterior. We, therefore, introduce the idea of\napplying two convolutional operations, one for the mean and one for the\nvariance. Our proposed method not only achieves performances equivalent to\nfrequentist inference in identical architectures but also incorporate a\nmeasurement for uncertainties and regularisation. It further eliminates the use\nof dropout in the model. Moreover, we predict how certain the model prediction\nis based on the epistemic and aleatoric uncertainties and empirically show how\nthe uncertainty can decrease, allowing the decisions made by the network to\nbecome more deterministic as the training accuracy increases. Finally, we\npropose ways to prune the Bayesian architecture and to make it more\ncomputational and time effective. \n\n"}
{"id": "1901.03299", "contents": "Title: An Analysis of the Accuracy of the P300 BCI Abstract: The P300 Brain-Computer Interface (BCI) is a well-established communication\nchannel for severely disabled people. The P300 event-related potential is\nmostly characterized by its amplitude or its area, which correlate with the\nspelling accuracy of the P300 speller. Here, we introduce a novel approach for\nestimating the efficiency of this BCI by considering the P300 signal-to-noise\nratio (SNR), a parameter that estimates the spatial and temporal noise levels\nand has a significantly stronger correlation with spelling accuracy.\nFurthermore, we suggest a Gaussian noise model, which utilizes the P300\nevent-related potential SNR to predict spelling accuracy under various\nconditions for LDA-based classification. We demonstrate the utility of this\nanalysis using real data and discuss its potential applications, such as\nspeeding up the process of electrode selection. \n\n"}
{"id": "1901.03327", "contents": "Title: A New Tensioning Method using Deep Reinforcement Learning for Surgical\n  Pattern Cutting Abstract: Surgeons normally need surgical scissors and tissue grippers to cut through a\ndeformable surgical tissue. The cutting accuracy depends on the skills to\nmanipulate these two tools. Such skills are part of basic surgical skills\ntraining as in the Fundamentals of Laparoscopic Surgery. The gripper is used to\npinch a point on the surgical sheet and pull the tissue to a certain direction\nto maintain the tension while the scissors cut through a trajectory. As the\nsurgical materials are deformable, it requires a comprehensive tensioning\npolicy to yield appropriate tensioning direction at each step of the cutting\nprocess. Automating a tensioning policy for a given cutting trajectory will\nsupport not only the human surgeons but also the surgical robots to improve the\ncutting accuracy and reliability. This paper presents a multiple pinch point\napproach to modelling an autonomous tensioning planner based on a deep\nreinforcement learning algorithm. Experiments on a simulator show that the\nproposed method is superior to existing methods in terms of both performance\nand robustness. \n\n"}
{"id": "1901.03559", "contents": "Title: An investigation of model-free planning Abstract: The field of reinforcement learning (RL) is facing increasingly challenging\ndomains with combinatorial complexity. For an RL agent to address these\nchallenges, it is essential that it can plan effectively. Prior work has\ntypically utilized an explicit model of the environment, combined with a\nspecific planning algorithm (such as tree search). More recently, a new family\nof methods have been proposed that learn how to plan, by providing the\nstructure for planning via an inductive bias in the function approximator (such\nas a tree structured neural network), trained end-to-end by a model-free RL\nalgorithm. In this paper, we go even further, and demonstrate empirically that\nan entirely model-free approach, without special structure beyond standard\nneural network components such as convolutional networks and LSTMs, can learn\nto exhibit many of the characteristics typically associated with a model-based\nplanner. We measure our agent's effectiveness at planning in terms of its\nability to generalize across a combinatorial and irreversible state space, its\ndata efficiency, and its ability to utilize additional thinking time. We find\nthat our agent has many of the characteristics that one might expect to find in\na planning algorithm. Furthermore, it exceeds the state-of-the-art in\nchallenging combinatorial domains such as Sokoban and outperforms other\nmodel-free approaches that utilize strong inductive biases toward planning. \n\n"}
{"id": "1901.04028", "contents": "Title: Sales Demand Forecast in E-commerce using a Long Short-Term Memory\n  Neural Network Methodology Abstract: Generating accurate and reliable sales forecasts is crucial in the E-commerce\nbusiness. The current state-of-the-art techniques are typically univariate\nmethods, which produce forecasts considering only the historical sales data of\na single product. However, in a situation where large quantities of related\ntime series are available, conditioning the forecast of an individual time\nseries on past behaviour of similar, related time series can be beneficial.\nSince the product assortment hierarchy in an E-commerce platform contains large\nnumbers of related products, in which the sales demand patterns can be\ncorrelated, our attempt is to incorporate this cross-series information in a\nunified model. We achieve this by globally training a Long Short-Term Memory\nnetwork (LSTM) that exploits the non-linear demand relationships available in\nan E-commerce product assortment hierarchy. Aside from the forecasting\nframework, we also propose a systematic pre-processing framework to overcome\nthe challenges in the E-commerce business. We also introduce several product\ngrouping strategies to supplement the LSTM learning schemes, in situations\nwhere sales patterns in a product portfolio are disparate. We empirically\nevaluate the proposed forecasting framework on a real-world online marketplace\ndataset from Walmart.com. Our method achieves competitive results on category\nlevel and super-departmental level datasets, outperforming state-of-the-art\ntechniques. \n\n"}
{"id": "1901.04195", "contents": "Title: Integrating Learning and Reasoning with Deep Logic Models Abstract: Deep learning is very effective at jointly learning feature representations\nand classification models, especially when dealing with high dimensional input\npatterns. Probabilistic logic reasoning, on the other hand, is capable to take\nconsistent and robust decisions in complex environments. The integration of\ndeep learning and logic reasoning is still an open-research problem and it is\nconsidered to be the key for the development of real intelligent agents. This\npaper presents Deep Logic Models, which are deep graphical models integrating\ndeep learning and logic reasoning both for learning and inference. Deep Logic\nModels create an end-to-end differentiable architecture, where deep learners\nare embedded into a network implementing a continuous relaxation of the logic\nknowledge. The learning process allows to jointly learn the weights of the deep\nlearners and the meta-parameters controlling the high-level reasoning. The\nexperimental results show that the proposed methodology overtakes the\nlimitations of the other approaches that have been proposed to bridge deep\nlearning and reasoning. \n\n"}
{"id": "1901.04420", "contents": "Title: Data Augmentation with Manifold Exploring Geometric Transformations for\n  Increased Performance and Robustness Abstract: In this paper we propose a novel augmentation technique that improves not\nonly the performance of deep neural networks on clean test data, but also\nsignificantly increases their robustness to random transformations, both affine\nand projective. Inspired by ManiFool, the augmentation is performed by a\nline-search manifold-exploration method that learns affine geometric\ntransformations that lead to the misclassification on an image, while ensuring\nthat it remains on the same manifold as the training data.\n  This augmentation method populates any training dataset with images that lie\non the border of the manifolds between two-classes and maximizes the variance\nthe network is exposed to during training. Our method was thoroughly evaluated\non the challenging tasks of fine-grained skin lesion classification from\nlimited data, and breast tumor classification of mammograms. Compared with\ntraditional augmentation methods, and with images synthesized by Generative\nAdversarial Networks our method not only achieves state-of-the-art performance\nbut also significantly improves the network's robustness. \n\n"}
{"id": "1901.04615", "contents": "Title: AutoPhase: Compiler Phase-Ordering for High Level Synthesis with Deep\n  Reinforcement Learning Abstract: The performance of the code generated by a compiler depends on the order in\nwhich the optimization passes are applied. In high-level synthesis, the quality\nof the generated circuit relates directly to the code generated by the\nfront-end compiler. Choosing a good order--often referred to as the\nphase-ordering problem--is an NP-hard problem. In this paper, we evaluate a new\ntechnique to address the phase-ordering problem: deep reinforcement learning.\nWe implement a framework in the context of the LLVM compiler to optimize the\nordering for HLS programs and compare the performance of deep reinforcement\nlearning to state-of-the-art algorithms that address the phase-ordering\nproblem. Overall, our framework runs one to two orders of magnitude faster than\nthese algorithms, and achieves a 16% improvement in circuit performance over\nthe -O3 compiler flag. \n\n"}
{"id": "1901.05134", "contents": "Title: DINGO: Distributed Newton-Type Method for Gradient-Norm Optimization Abstract: For optimization of a sum of functions in a distributed computing\nenvironment, we present a novel communication efficient Newton-type algorithm\nthat enjoys a variety of advantages over similar existing methods. Similar to\nNewton-MR, our algorithm, DINGO, is derived by optimization of the gradient's\nnorm as a surrogate function. DINGO does not impose any specific form on the\nunderlying functions, and its application range extends far beyond convexity.\nIn addition, the distribution of the data across the computing environment can\nbe arbitrary. Further, the underlying sub-problems of DINGO are simple linear\nleast-squares, for which a plethora of efficient algorithms exist. Lastly,\nDINGO involves a few hyper-parameters that are easy to tune. Moreover, we\ntheoretically show that DINGO is not sensitive to the choice of its\nhyper-parameters in that a strict reduction in the gradient norm is guaranteed,\nregardless of the selected hyper-parameters. We demonstrate empirical evidence\nof the effectiveness, stability and versatility of our method compared to other\nrelevant algorithms. \n\n"}
{"id": "1901.05331", "contents": "Title: Optimization Problems for Machine Learning: A Survey Abstract: This paper surveys the machine learning literature and presents in an\noptimization framework several commonly used machine learning approaches.\nParticularly, mathematical optimization models are presented for regression,\nclassification, clustering, deep learning, and adversarial learning, as well as\nnew emerging applications in machine teaching, empirical model learning, and\nBayesian network structure learning. Such models can benefit from the\nadvancement of numerical optimization techniques which have already played a\ndistinctive role in several machine learning settings. The strengths and the\nshortcomings of these models are discussed and potential research directions\nand open problems are highlighted. \n\n"}
{"id": "1901.06086", "contents": "Title: WALL-E: An Efficient Reinforcement Learning Research Framework Abstract: There are two halves to RL systems: experience collection time and policy\nlearning time. For a large number of samples in rollouts, experience collection\ntime is the major bottleneck. Thus, it is necessary to speed up the rollout\ngeneration time with multi-process architecture support. Our work, dubbed\nWALL-E, utilizes multiple rollout samplers running in parallel to rapidly\ngenerate experience. Due to our parallel samplers, we experience not only\nfaster convergence times, but also higher average reward thresholds. For\nexample, on the MuJoCo HalfCheetah-v2 task, with $N = 10$ parallel sampler\nprocesses, we are able to achieve much higher average return than those from\nusing only a single process architecture. \n\n"}
{"id": "1901.06247", "contents": "Title: Micro- and Macro-Level Churn Analysis of Large-Scale Mobile Games Abstract: As mobile devices become more and more popular, mobile gaming has emerged as\na promising market with billion-dollar revenues. A variety of mobile game\nplatforms and services have been developed around the world. A critical\nchallenge for these platforms and services is to understand the churn behavior\nin mobile games, which usually involves churn at micro level (between an app\nand a specific user) and macro level (between an app and all its users).\nAccurate micro-level churn prediction and macro-level churn ranking will\nbenefit many stakeholders such as game developers, advertisers, and platform\noperators. In this paper, we present the first large-scale churn analysis for\nmobile games that supports both micro-level churn prediction and macro-level\nchurn ranking. For micro-level churn prediction, in view of the common\nlimitations of the state-of-the-art methods built upon traditional machine\nlearning models, we devise a novel semi-supervised and inductive embedding\nmodel that jointly learns the prediction function and the embedding function\nfor user-app relationships. We model these two functions by deep neural\nnetworks with a unique edge embedding technique that is able to capture both\ncontextual information and relationship dynamics. We also design a novel\nattributed random walk technique that takes into consideration both topological\nadjacency and attribute similarities. To address macro-level churn ranking, we\npropose to construct a relationship graph with estimated micro-level churn\nprobabilities as edge weights and adapt link analysis algorithms on the graph.\nWe devise a simple algorithm SimSum and adapt two more advanced algorithms\nPageRank and HITS. The performance of our solutions for the two-level churn\nanalysis problems is evaluated on real-world data collected from the Samsung\nGame Launcher platform. \n\n"}
{"id": "1901.07165", "contents": "Title: Generation High resolution 3D model from natural language by Generative\n  Adversarial Network Abstract: We present a method of generating high resolution 3D shapes from natural\nlanguage descriptions. To achieve this goal, we propose two steps that\ngenerating low resolution shapes which roughly reflect texts and generating\nhigh resolution shapes which reflect the detail of texts. In a previous paper,\nthe authors have shown a method of generating low resolution shapes. We improve\nit to generate 3D shapes more faithful to natural language and test the\neffectiveness of the method. To generate high resolution 3D shapes, we use the\nframework of Conditional Wasserstein GAN. We propose two roles of Critic\nseparately, which calculate the Wasserstein distance between two probability\ndistribution, so that we achieve generating high quality shapes or acceleration\nof learning speed of model. To evaluate our approach, we performed quantitive\nevaluation with several numerical metrics for Critic models. Our method is\nfirst to realize the generation of high quality model by propagating text\nembedding information to high resolution task when generating 3D model. \n\n"}
{"id": "1901.07487", "contents": "Title: Non-Asymptotic Analysis of Fractional Langevin Monte Carlo for\n  Non-Convex Optimization Abstract: Recent studies on diffusion-based sampling methods have shown that Langevin\nMonte Carlo (LMC) algorithms can be beneficial for non-convex optimization, and\nrigorous theoretical guarantees have been proven for both asymptotic and\nfinite-time regimes. Algorithmically, LMC-based algorithms resemble the\nwell-known gradient descent (GD) algorithm, where the GD recursion is perturbed\nby an additive Gaussian noise whose variance has a particular form. Fractional\nLangevin Monte Carlo (FLMC) is a recently proposed extension of LMC, where the\nGaussian noise is replaced by a heavy-tailed {\\alpha}-stable noise. As opposed\nto its Gaussian counterpart, these heavy-tailed perturbations can incur large\njumps and it has been empirically demonstrated that the choice of\n{\\alpha}-stable noise can provide several advantages in modern machine learning\nproblems, both in optimization and sampling contexts. However, as opposed to\nLMC, only asymptotic convergence properties of FLMC have been yet established.\nIn this study, we analyze the non-asymptotic behavior of FLMC for non-convex\noptimization and prove finite-time bounds for its expected suboptimality. Our\nresults show that the weak-error of FLMC increases faster than LMC, which\nsuggests using smaller step-sizes in FLMC. We finally extend our results to the\ncase where the exact gradients are replaced by stochastic gradients and show\nthat similar results hold in this setting as well. \n\n"}
{"id": "1901.07621", "contents": "Title: Single Deep Counterfactual Regret Minimization Abstract: Counterfactual Regret Minimization (CFR) is the most successful algorithm for\nfinding approximate Nash equilibria in imperfect information games. However,\nCFR's reliance on full game-tree traversals limits its scalability. For this\nreason, the game's state- and action-space is often abstracted (i.e.\nsimplified) for CFR, and the resulting strategy is then translated back to the\nfull game, which requires extensive expert-knowledge and often converges to\nhighly exploitable policies. A recently proposed method, Deep CFR, applies deep\nlearning directly to CFR, allowing the agent to intrinsically abstract and\ngeneralize over the state-space from samples, without requiring expert\nknowledge. In this paper, we introduce Single Deep CFR (SD-CFR), a simplified\nvariant of Deep CFR that has a lower overall approximation error by avoiding\nthe training of an average strategy network. We show that SD-CFR is more\nattractive from a theoretical perspective and empirically outperforms Deep CFR\nwith respect to exploitability and one-on-one play in poker. \n\n"}
{"id": "1901.08021", "contents": "Title: Robust Temporal Difference Learning for Critical Domains Abstract: We present a new Q-function operator for temporal difference (TD) learning\nmethods that explicitly encodes robustness against significant rare events\n(SRE) in critical domains. The operator, which we call the $\\kappa$-operator,\nallows to learn a robust policy in a model-based fashion without actually\nobserving the SRE. We introduce single- and multi-agent robust TD methods using\nthe operator $\\kappa$. We prove convergence of the operator to the optimal\nrobust Q-function with respect to the model using the theory of Generalized\nMarkov Decision Processes. In addition we prove convergence to the optimal\nQ-function of the original MDP given that the probability of SREs vanishes.\nEmpirical evaluations demonstrate the superior performance of $\\kappa$-based TD\nmethods both in the early learning phase as well as in the final converged\nstage. In addition we show robustness of the proposed method to small model\nerrors, as well as its applicability in a multi-agent context. \n\n"}
{"id": "1901.08022", "contents": "Title: A Universally Optimal Multistage Accelerated Stochastic Gradient Method Abstract: We study the problem of minimizing a strongly convex, smooth function when we\nhave noisy estimates of its gradient. We propose a novel multistage accelerated\nalgorithm that is universally optimal in the sense that it achieves the optimal\nrate both in the deterministic and stochastic case and operates without\nknowledge of noise characteristics. The algorithm consists of stages that use a\nstochastic version of Nesterov's method with a specific restart and parameters\nselected to achieve the fastest reduction in the bias-variance terms in the\nconvergence rate bounds. \n\n"}
{"id": "1901.08087", "contents": "Title: Model Function Based Conditional Gradient Method with Armijo-like Line\n  Search Abstract: The Conditional Gradient Method is generalized to a class of non-smooth\nnon-convex optimization problems with many applications in machine learning.\nThe proposed algorithm iterates by minimizing so-called model functions over\nthe constraint set. Complemented with an Amijo line search procedure, we prove\nthat subsequences converge to a stationary point. The abstract framework of\nmodel functions provides great flexibility for the design of concrete\nalgorithms. As special cases, for example, we develop an algorithm for additive\ncomposite problems and an algorithm for non-linear composite problems which\nleads to a Gauss--Newton-type algorithm. Both instances are novel in non-smooth\nnon-convex optimization and come with numerous applications in machine\nlearning. Moreover, we obtain a hybrid version of Conditional Gradient and\nProximal Minimization schemes for free, which combines advantages of both. Our\nalgorithm is shown to perform favorably on a sparse non-linear robust\nregression problem and we discuss the flexibility of the proposed framework in\nseveral matrix factorization formulations. \n\n"}
{"id": "1901.08125", "contents": "Title: Interpretable Neural Networks for Predicting Mortality Risk using\n  Multi-modal Electronic Health Records Abstract: We present an interpretable neural network for predicting an important\nclinical outcome (1-year mortality) from multi-modal Electronic Health Record\n(EHR) data. Our approach builds on prior multi-modal machine learning models by\nnow enabling visualization of how individual factors contribute to the overall\noutcome risk, assuming other factors remain constant, which was previously\nimpossible.\n  We demonstrate the value of this approach using a large multi-modal clinical\ndataset including both EHR data and 31,278 echocardiographic videos of the\nheart from 26,793 patients. We generated separate models for (i) clinical data\nonly (CD) (e.g. age, sex, diagnoses and laboratory values), (ii) numeric\nvariables derived from the videos, which we call echocardiography-derived\nmeasures (EDM), and (iii) CD+EDM+raw videos (pixel data). The interpretable\nmulti-modal model maintained performance compared to non-interpretable models\n(Random Forest, XGBoost), and also performed significantly better than a model\nusing a single modality (average AUC=0.82). Clinically relevant insights and\nmulti-modal variable importance rankings were also facilitated by the new\nmodel, which have previously been impossible. \n\n"}
{"id": "1901.08227", "contents": "Title: Trajectory Normalized Gradients for Distributed Optimization Abstract: Recently, researchers proposed various low-precision gradient compression,\nfor efficient communication in large-scale distributed optimization. Based on\nthese work, we try to reduce the communication complexity from a new direction.\nWe pursue an ideal bijective mapping between two spaces of gradient\ndistribution, so that the mapped gradient carries greater information entropy\nafter the compression. In our setting, all servers should share a reference\ngradient in advance, and they communicate via the normalized gradients, which\nare the subtraction or quotient, between current gradients and the reference.\nTo obtain a reference vector that yields a stronger signal-to-noise ratio,\ndynamically in each iteration, we extract and fuse information from the past\ntrajectory in hindsight, and search for an optimal reference for compression.\nWe name this to be the trajectory-based normalized gradients (TNG). It bridges\nthe research from different societies, like coding, optimization, systems, and\nlearning. It is easy to implement and can universally combine with existing\nalgorithms. Our experiments on benchmarking hard non-convex functions, convex\nproblems like logistic regression demonstrate that TNG is more\ncompression-efficient for communication of distributed optimization of general\nfunctions. \n\n"}
{"id": "1901.08511", "contents": "Title: A Unified Analysis of Extra-gradient and Optimistic Gradient Methods for\n  Saddle Point Problems: Proximal Point Approach Abstract: In this paper we consider solving saddle point problems using two variants of\nGradient Descent-Ascent algorithms, Extra-gradient (EG) and Optimistic Gradient\nDescent Ascent (OGDA) methods. We show that both of these algorithms admit a\nunified analysis as approximations of the classical proximal point method for\nsolving saddle point problems. This viewpoint enables us to develop a new\nframework for analyzing EG and OGDA for bilinear and strongly convex-strongly\nconcave settings. Moreover, we use the proximal point approximation\ninterpretation to generalize the results for OGDA for a wide range of\nparameters. \n\n"}
{"id": "1901.08523", "contents": "Title: Curvature-Exploiting Acceleration of Elastic Net Computations Abstract: This paper introduces an efficient second-order method for solving the\nelastic net problem. Its key innovation is a computationally efficient\ntechnique for injecting curvature information in the optimization process which\nadmits a strong theoretical performance guarantee. In particular, we show\nimproved run time over popular first-order methods and quantify the speed-up in\nterms of statistical measures of the data matrix. The improved time complexity\nis the result of an extensive exploitation of the problem structure and a\ncareful combination of second-order information, variance reduction techniques,\nand momentum acceleration. Beside theoretical speed-up, experimental results\ndemonstrate great practical performance benefits of curvature information,\nespecially for ill-conditioned data sets. \n\n"}
{"id": "1901.08571", "contents": "Title: Nonparametric Inference under B-bits Quantization Abstract: Statistical inference based on lossy or incomplete samples is often needed in\nresearch areas such as signal/image processing, medical image storage, remote\nsensing, signal transmission. In this paper, we propose a nonparametric testing\nprocedure based on samples quantized to $B$ bits through a computationally\nefficient algorithm. Under mild technical conditions, we establish the\nasymptotic properties of the proposed test statistic and investigate how the\ntesting power changes as $B$ increases. In particular, we show that if $B$\nexceeds a certain threshold, the proposed nonparametric testing procedure\nachieves the classical minimax rate of testing (Shang and Cheng, 2015) for\nspline models. We further extend our theoretical investigations to a\nnonparametric linearity test and an adaptive nonparametric test, expanding the\napplicability of the proposed methods. Extensive simulation studies {together\nwith a real-data analysis} are used to demonstrate the validity and\neffectiveness of the proposed tests. \n\n"}
{"id": "1901.08817", "contents": "Title: State-Regularized Recurrent Neural Networks Abstract: Recurrent neural networks are a widely used class of neural architectures.\nThey have, however, two shortcomings. First, it is difficult to understand what\nexactly they learn. Second, they tend to work poorly on sequences requiring\nlong-term memorization, despite having this capacity in principle. We aim to\naddress both shortcomings with a class of recurrent networks that use a\nstochastic state transition mechanism between cell applications. This\nmechanism, which we term state-regularization, makes RNNs transition between a\nfinite set of learnable states. We evaluate state-regularized RNNs on (1)\nregular languages for the purpose of automata extraction; (2) nonregular\nlanguages such as balanced parentheses, palindromes, and the copy task where\nexternal memory is required; and (3) real-word sequence learning tasks for\nsentiment analysis, visual object recognition, and language modeling. We show\nthat state-regularization (a) simplifies the extraction of finite state\nautomata modeling an RNN's state transition dynamics; (b) forces RNNs to\noperate more like automata with external memory and less like finite state\nmachines; (c) makes RNNs have better interpretability and explainability. \n\n"}
{"id": "1901.08949", "contents": "Title: Subspace Robust Wasserstein Distances Abstract: Making sense of Wasserstein distances between discrete measures in\nhigh-dimensional settings remains a challenge. Recent work has advocated a\ntwo-step approach to improve robustness and facilitate the computation of\noptimal transport, using for instance projections on random real lines, or a\npreliminary quantization of the measures to reduce the size of their support.\nWe propose in this work a \"max-min\" robust variant of the Wasserstein distance\nby considering the maximal possible distance that can be realized between two\nmeasures, assuming they can be projected orthogonally on a lower\n$k$-dimensional subspace. Alternatively, we show that the corresponding\n\"min-max\" OT problem has a tight convex relaxation which can be cast as that of\nfinding an optimal transport plan with a low transportation cost, where the\ncost is alternatively defined as the sum of the $k$ largest eigenvalues of the\nsecond order moment matrix of the displacements (or matchings) corresponding to\nthat plan (the usual OT definition only considers the trace of that matrix). We\nshow that both quantities inherit several favorable properties from the OT\ngeometry. We propose two algorithms to compute the latter formulation using\nentropic regularization, and illustrate the interest of this approach\nempirically. \n\n"}
{"id": "1901.09181", "contents": "Title: Sparse evolutionary Deep Learning with over one million artificial\n  neurons on commodity hardware Abstract: Artificial Neural Networks (ANNs) have emerged as hot topics in the research\ncommunity. Despite the success of ANNs, it is challenging to train and deploy\nmodern ANNs on commodity hardware due to the ever-increasing model size and the\nunprecedented growth in the data volumes. Particularly for microarray data, the\nvery-high dimensionality and the small number of samples make it difficult for\nmachine learning techniques to handle. Furthermore, specialized hardware such\nas Graphics Processing Unit (GPU) is expensive. Sparse neural networks are the\nleading approaches to address these challenges. However, off-the-shelf sparsity\ninducing techniques either operate from a pre-trained model or enforce the\nsparse structure via binary masks. The training efficiency of sparse neural\nnetworks cannot be obtained practically. In this paper, we introduce a\ntechnique allowing us to train truly sparse neural networks with fixed\nparameter count throughout training. Our experimental results demonstrate that\nour method can be applied directly to handle high dimensional data, while\nachieving higher accuracy than the traditional two phases approaches. Moreover,\nwe have been able to create truly sparse MultiLayer Perceptrons (MLPs) models\nwith over one million neurons and to train them on a typical laptop without\nGPU, this being way beyond what is possible with any state-of-the-art\ntechniques. \n\n"}
{"id": "1901.09192", "contents": "Title: SelectiveNet: A Deep Neural Network with an Integrated Reject Option Abstract: We consider the problem of selective prediction (also known as reject option)\nin deep neural networks, and introduce SelectiveNet, a deep neural architecture\nwith an integrated reject option. Existing rejection mechanisms are based\nmostly on a threshold over the prediction confidence of a pre-trained network.\nIn contrast, SelectiveNet is trained to optimize both classification (or\nregression) and rejection simultaneously, end-to-end. The result is a deep\nneural network that is optimized over the covered domain. In our experiments,\nwe show a consistently improved risk-coverage trade-off over several well-known\nclassification and regression datasets, thus reaching new state-of-the-art\nresults for deep selective classification. \n\n"}
{"id": "1901.09216", "contents": "Title: Modelling Bounded Rationality in Multi-Agent Interactions by Generalized\n  Recursive Reasoning Abstract: Though limited in real-world decision making, most multi-agent reinforcement\nlearning (MARL) models assume perfectly rational agents -- a property hardly\nmet due to individual's cognitive limitation and/or the tractability of the\ndecision problem. In this paper, we introduce generalized recursive reasoning\n(GR2) as a novel framework to model agents with different \\emph{hierarchical}\nlevels of rationality; our framework enables agents to exhibit varying levels\nof \"thinking\" ability thereby allowing higher-level agents to best respond to\nvarious less sophisticated learners. We contribute both theoretically and\nempirically. On the theory side, we devise the hierarchical framework of GR2\nthrough probabilistic graphical models and prove the existence of a perfect\nBayesian equilibrium. Within the GR2, we propose a practical actor-critic\nsolver, and demonstrate its convergent property to a stationary point in\ntwo-player games through Lyapunov analysis. On the empirical side, we validate\nour findings on a variety of MARL benchmarks. Precisely, we first illustrate\nthe hierarchical thinking process on the Keynes Beauty Contest, and then\ndemonstrate significant improvements compared to state-of-the-art opponent\nmodeling baselines on the normal-form games and the cooperative navigation\nbenchmark. \n\n"}
{"id": "1901.09367", "contents": "Title: A Privacy Preserving Randomized Gossip Algorithm via Controlled Noise\n  Insertion Abstract: In this work we present a randomized gossip algorithm for solving the average\nconsensus problem while at the same time protecting the information about the\ninitial private values stored at the nodes. We give iteration complexity bounds\nfor the method and perform extensive numerical experiments. \n\n"}
{"id": "1901.09712", "contents": "Title: Ising Models with Latent Conditional Gaussian Variables Abstract: Ising models describe the joint probability distribution of a vector of\nbinary feature variables. Typically, not all the variables interact with each\nother and one is interested in learning the presumably sparse network structure\nof the interacting variables. However, in the presence of latent variables, the\nconventional method of learning a sparse model might fail. This is because the\nlatent variables induce indirect interactions of the observed variables. In the\ncase of only a few latent conditional Gaussian variables these spurious\ninteractions contribute an additional low-rank component to the interaction\nparameters of the observed Ising model. Therefore, we propose to learn a sparse\n+ low-rank decomposition of the parameters of an Ising model using a convex\nregularized likelihood problem. We show that the same problem can be obtained\nas the dual of a maximum-entropy problem with a new type of relaxation, where\nthe sample means collectively need to match the expected values only up to a\ngiven tolerance. The solution to the convex optimization problem has\nconsistency properties in the high-dimensional setting, where the number of\nobserved binary variables and the number of latent conditional Gaussian\nvariables are allowed to grow with the number of training samples. \n\n"}
{"id": "1901.09888", "contents": "Title: Federated Collaborative Filtering for Privacy-Preserving Personalized\n  Recommendation System Abstract: The increasing interest in user privacy is leading to new privacy preserving\nmachine learning paradigms. In the Federated Learning paradigm, a master\nmachine learning model is distributed to user clients, the clients use their\nlocally stored data and model for both inference and calculating model updates.\nThe model updates are sent back and aggregated on the server to update the\nmaster model then redistributed to the clients. In this paradigm, the user data\nnever leaves the client, greatly enhancing the user' privacy, in contrast to\nthe traditional paradigm of collecting, storing and processing user data on a\nbackend server beyond the user's control. In this paper we introduce, as far as\nwe are aware, the first federated implementation of a Collaborative Filter. The\nfederated updates to the model are based on a stochastic gradient approach. As\na classical case study in machine learning, we explore a personalized\nrecommendation system based on users' implicit feedback and demonstrate the\nmethod's applicability to both the MovieLens and an in-house dataset. Empirical\nvalidation confirms a collaborative filter can be federated without a loss of\naccuracy compared to a standard implementation, hence enhancing the user's\nprivacy in a widely used recommender application while maintaining recommender\nperformance. \n\n"}
{"id": "1901.09895", "contents": "Title: Modularization of End-to-End Learning: Case Study in Arcade Games Abstract: Complex environments and tasks pose a difficult problem for holistic\nend-to-end learning approaches. Decomposition of an environment into\ninteracting controllable and non-controllable objects allows supervised\nlearning for non-controllable objects and universal value function approximator\nlearning for controllable objects. Such decomposition should lead to a shorter\nlearning time and better generalisation capability. Here, we consider\narcade-game environments as sets of interacting objects (controllable,\nnon-controllable) and propose a set of functional modules that are specialized\non mastering different types of interactions in a broad range of environments.\nThe modules utilize regression, supervised learning, and reinforcement learning\nalgorithms. Results of this case study in different Atari games suggest that\nhuman-level performance can be achieved by a learning agent within a human\namount of game experience (10-15 minutes game time) when a proper decomposition\nof an environment or a task is provided. However, automatization of such\ndecomposition remains a challenging problem. This case study shows how a model\nof a causal structure underlying an environment or a task can benefit learning\ntime and generalization capability of the agent, and argues in favor of\nexploiting modular structure in contrast to using pure end-to-end learning\napproaches. \n\n"}
{"id": "1901.09997", "contents": "Title: Quasi-Newton Methods for Machine Learning: Forget the Past, Just Sample Abstract: We present two sampled quasi-Newton methods (sampled LBFGS and sampled LSR1)\nfor solving empirical risk minimization problems that arise in machine\nlearning. Contrary to the classical variants of these methods that sequentially\nbuild Hessian or inverse Hessian approximations as the optimization progresses,\nour proposed methods sample points randomly around the current iterate at every\niteration to produce these approximations. As a result, the approximations\nconstructed make use of more reliable (recent and local) information, and do\nnot depend on past iterate information that could be significantly stale. Our\nproposed algorithms are efficient in terms of accessed data points (epochs) and\nhave enough concurrency to take advantage of parallel/distributed computing\nenvironments. We provide convergence guarantees for our proposed methods.\nNumerical tests on a toy classification problem as well as on popular\nbenchmarking binary classification and neural network training tasks reveal\nthat the methods outperform their classical variants. \n\n"}
{"id": "1901.10059", "contents": "Title: A Regulation Enforcement Solution for Multi-agent Reinforcement Learning Abstract: Human behaviors are regularized by a variety of norms or regulations, either\nto maintain orders or to enhance social welfare. If artificially intelligent\n(AI) agents make decisions on behalf of human beings, we would hope they can\nalso follow established regulations while interacting with humans or other AI\nagents. However, it is possible that an AI agent can opt to disobey the\nregulations (being defective) for self-interests. In this paper, we aim to\nanswer the following question: Consider a multi-agent decentralized\nenvironment. Agents make decisions in complete isolation of other agents. Each\nagent knows the state of its own MDP and its own actions but it does not know\nthe states and the actions taken by other players. There is a set of\nregulations for all agents to follow. Although most agents are benign and will\ncomply to regulations but not all agents are compliant at first, can we develop\na framework such that it is in the self-interest of non-compliant agents to\ncomply after all?. We first introduce the problem as Regulation Enforcement and\nformulate it using reinforcement learning and game theory under the scenario\nwhere agents make decisions in complete isolation of other agents. We then\npropose a solution based on the key idea that although we could not alter how\ndefective agents choose to behave, we can, however, leverage the aggregated\npower of compliant agents to boycott the defective ones. We conducted simulated\nexperiments on two scenarios: Replenishing Resource Management Dilemma and\nDiminishing Reward Shaping Enforcement, using deep multi-agent reinforcement\nlearning algorithms. We further use empirical game-theoretic analysis to show\nthat the method alters the resulting empirical payoff matrices in a way that\npromotes compliance (making mutual compliant a Nash Equilibrium). \n\n"}
{"id": "1901.10159", "contents": "Title: An Investigation into Neural Net Optimization via Hessian Eigenvalue\n  Density Abstract: To understand the dynamics of optimization in deep neural networks, we\ndevelop a tool to study the evolution of the entire Hessian spectrum throughout\nthe optimization process. Using this, we study a number of hypotheses\nconcerning smoothness, curvature, and sharpness in the deep learning\nliterature. We then thoroughly analyze a crucial structural feature of the\nspectra: in non-batch normalized networks, we observe the rapid appearance of\nlarge isolated eigenvalues in the spectrum, along with a surprising\nconcentration of the gradient in the corresponding eigenspaces. In batch\nnormalized networks, these two effects are almost absent. We characterize these\neffects, and explain how they affect optimization speed through both theory and\nexperiments. As part of this work, we adapt advanced tools from numerical\nlinear algebra that allow scalable and accurate estimation of the entire\nHessian spectrum of ImageNet-scale neural networks; this technique may be of\nindependent interest in other applications. \n\n"}
{"id": "1901.10923", "contents": "Title: Coordinating the Crowd: Inducing Desirable Equilibria in Non-Cooperative\n  Systems Abstract: Many real-world systems such as taxi systems, traffic networks and smart\ngrids involve self-interested actors that perform individual tasks in a shared\nenvironment. However, in such systems, the self-interested behaviour of agents\nproduces welfare inefficient and globally suboptimal outcomes that are\ndetrimental to all - some common examples are congestion in traffic networks,\ndemand spikes for resources in electricity grids and over-extraction of\nenvironmental resources such as fisheries. We propose an incentive-design\nmethod which modifies agents' rewards in non-cooperative multi-agent systems\nthat results in independent, self-interested agents choosing actions that\nproduce optimal system outcomes in strategic settings. Our framework combines\nmulti-agent reinforcement learning to simulate (real-world) agent behaviour and\nblack-box optimisation to determine the optimal modifications to the agents'\nrewards or incentives given some fixed budget that results in optimal system\nperformance. By modifying the reward functions and generating agents'\nequilibrium responses within a sequence of offline Markov games, our method\nenables optimal incentive structures to be determined offline through iterative\nupdates of the reward functions of a simulated game. Our theoretical results\nshow that our method converges to reward modifications that induce system\noptimality. We demonstrate the applications of our framework by tackling a\nchallenging problem within economics that involves thousands of selfish agents\nand tackle a traffic congestion problem. \n\n"}
{"id": "1901.11224", "contents": "Title: Lower Bounds for Smooth Nonconvex Finite-Sum Optimization Abstract: Smooth finite-sum optimization has been widely studied in both convex and\nnonconvex settings. However, existing lower bounds for finite-sum optimization\nare mostly limited to the setting where each component function is (strongly)\nconvex, while the lower bounds for nonconvex finite-sum optimization remain\nlargely unsolved. In this paper, we study the lower bounds for smooth nonconvex\nfinite-sum optimization, where the objective function is the average of $n$\nnonconvex component functions. We prove tight lower bounds for the complexity\nof finding $\\epsilon$-suboptimal point and $\\epsilon$-approximate stationary\npoint in different settings, for a wide regime of the smallest eigenvalue of\nthe Hessian of the objective function (or each component function). Given our\nlower bounds, we can show that existing algorithms including KatyushaX\n(Allen-Zhu, 2018), Natasha (Allen-Zhu, 2017), RapGrad (Lan and Yang, 2018) and\nStagewiseKatyusha (Chen and Yang, 2018) have achieved optimal Incremental\nFirst-order Oracle (IFO) complexity (i.e., number of IFO calls) up to logarithm\nfactors for nonconvex finite-sum optimization. We also point out potential ways\nto further improve these complexity results, in terms of making stronger\nassumptions or by a different convergence analysis. \n\n"}
{"id": "1901.11356", "contents": "Title: Functional Regularisation for Continual Learning with Gaussian Processes Abstract: We introduce a framework for Continual Learning (CL) based on Bayesian\ninference over the function space rather than the parameters of a deep neural\nnetwork. This method, referred to as functional regularisation for Continual\nLearning, avoids forgetting a previous task by constructing and memorising an\napproximate posterior belief over the underlying task-specific function. To\nachieve this we rely on a Gaussian process obtained by treating the weights of\nthe last layer of a neural network as random and Gaussian distributed. Then,\nthe training algorithm sequentially encounters tasks and constructs posterior\nbeliefs over the task-specific functions by using inducing point sparse\nGaussian process methods. At each step a new task is first learnt and then a\nsummary is constructed consisting of (i) inducing inputs -- a fixed-size subset\nof the task inputs selected such that it optimally represents the task -- and\n(ii) a posterior distribution over the function values at these inputs. This\nsummary then regularises learning of future tasks, through Kullback-Leibler\nregularisation terms. Our method thus unites approaches focused on\n(pseudo-)rehearsal with those derived from a sequential Bayesian inference\nperspective in a principled way, leading to strong results on accepted\nbenchmarks. \n\n"}
{"id": "1901.11457", "contents": "Title: Improving SGD convergence by online linear regression of gradients in\n  multiple statistically relevant directions Abstract: Deep neural networks are usually trained with stochastic gradient descent\n(SGD), which minimizes objective function using very rough approximations of\ngradient, only averaging to the real gradient. Standard approaches like\nmomentum or ADAM only consider a single direction, and do not try to model\ndistance from extremum - neglecting valuable information from calculated\nsequence of gradients, often stagnating in some suboptimal plateau. Second\norder methods could exploit these missed opportunities, however, beside\nsuffering from very large cost and numerical instabilities, many of them\nattract to suboptimal points like saddles due to negligence of signs of\ncurvatures (as eigenvalues of Hessian).\n  Saddle-free Newton method is a rare example of addressing this issue -\nchanges saddle attraction into repulsion, and was shown to provide essential\nimprovement for final value this way. However, it neglects noise while\nmodelling second order behavior, focuses on Krylov subspace for numerical\nreasons, and requires costly eigendecomposion.\n  Maintaining SFN advantages, there are proposed inexpensive ways for\nexploiting these opportunities. Second order behavior is linear dependence of\nfirst derivative - we can optimally estimate it from sequence of noisy\ngradients with least square linear regression, in online setting here: with\nweakening weights of old gradients. Statistically relevant subspace is\nsuggested by PCA of recent noisy gradients - in online setting it can be made\nby slowly rotating considered directions toward new gradients, gradually\nreplacing old directions with recent statistically relevant. Eigendecomposition\ncan be also performed online: with regularly performed step of QR method to\nmaintain diagonal Hessian. Outside the second order modeled subspace we can\nsimultaneously perform gradient descent. \n\n"}
{"id": "1901.11463", "contents": "Title: Distributionally Robust Removal of Malicious Nodes from Networks Abstract: An important problem in networked systems is detection and removal of\nsuspected malicious nodes. A crucial consideration in such settings is the\nuncertainty endemic in detection, coupled with considerations of network\nconnectivity, which impose indirect costs from mistakely removing benign nodes\nas well as failing to remove malicious nodes. A recent approach proposed to\naddress this problem directly tackles these considerations, but has a\nsignificant limitation: it assumes that the decision maker has accurate\nknowledge of the joint maliciousness probability of the nodes on the network.\nThis is clearly not the case in practice, where such a distribution is at best\nan estimate from limited evidence. To address this problem, we propose a\ndistributionally robust framework for optimal node removal. While the problem\nis NP-Hard, we propose a principled algorithmic technique for solving it\napproximately based on duality combined with Semidefinite Programming\nrelaxation. A combination of both theoretical and empirical analysis, the\nlatter using both synthetic and real data, provide strong evidence that our\nalgorithmic approach is highly effective and, in particular, is significantly\nmore robust than the state of the art. \n\n"}
{"id": "cs/0204041", "contents": "Title: Trust Brokerage Systems for the Internet Abstract: This thesis addresses the problem of providing trusted individuals with\nconfidential information about other individuals, in particular, granting\naccess to databases of personal records using the World-Wide Web. It proposes\nan access rights management system for distributed databases which aims to\ncreate and implement organisation structures based on the wishes of the owners\nand of demands of the users of the databases. The dissertation describes how\ncurrent software components could be used to implement this system; it\nre-examines the theory of collective choice to develop mechanisms for\ngenerating hierarchies of authorities; it analyses organisational processes for\nstability and develops a means of measuring the similarity of their\nhierarchies. \n\n"}
{"id": "cs/0602090", "contents": "Title: On the Approximation and Smoothed Complexity of Leontief Market\n  Equilibria Abstract: We show that the problem of finding an \\epsilon-approximate Nash equilibrium\nof an n by n two-person games can be reduced to the computation of an\n(\\epsilon/n)^2-approximate market equilibrium of a Leontief economy. Together\nwith a recent result of Chen, Deng and Teng, this polynomial reduction implies\nthat the Leontief market exchange problem does not have a fully polynomial-time\napproximation scheme, that is, there is no algorithm that can compute an\n\\epsilon-approximate market equilibrium in time polynomial in m, n, and\n1/\\epsilon, unless PPAD is not in P, We also extend the analysis of our\nreduction to show, unless PPAD is not in RP, that the smoothed complexity of\nthe Scarf's general fixed-point approximation algorithm (when applying to solve\nthe approximate Leontief market exchange problem) or of any algorithm for\ncomputing an approximate market equilibrium of Leontief economies is not\npolynomial in n and 1/\\sigma, under Gaussian or uniform perturbations with\nmagnitude \\sigma. \n\n"}
{"id": "cs/0606091", "contents": "Title: On computing fixpoints in well-structured regular model checking, with\n  applications to lossy channel systems Abstract: We prove a general finite convergence theorem for \"upward-guarded\" fixpoint\nexpressions over a well-quasi-ordered set. This has immediate applications in\nregular model checking of well-structured systems, where a main issue is the\neventual convergence of fixpoint computations. In particular, we are able to\ndirectly obtain several new decidability results on lossy channel systems. \n\n"}
{"id": "quant-ph/0211191", "contents": "Title: An invitation to Quantum Game Theory Abstract: Recent development in quantum computation and quantum information theory\nallows to extend the scope of game theory for the quantum world. The paper\npresents the history, basic ideas and recent development in quantum game\ntheory. In this context, a new application of the Ising chain model is\nproposed. \n\n"}
